<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.8091085">
Error mining in parsing results
Benoît Sagot and Éric de la Clergerie
</title>
<author confidence="0.56523">
Projet ATOLL - INRIA
</author>
<affiliation confidence="0.5127395">
Domaine de Voluceau, B.P. 105
78153 Le Chesnay Cedex, France
</affiliation>
<email confidence="0.996435">
{benoit.sagot,eric.de_la_clergerie}@inria.fr
</email>
<sectionHeader confidence="0.997361" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999859">
We introduce an error mining technique
for automatically detecting errors in re-
sources that are used in parsing systems.
We applied this technique on parsing re-
sults produced on several million words by
two distinct parsing systems, which share
the syntactic lexicon and the pre-parsing
processing chain. We were thus able to
identify missing and erroneous informa-
tion in these resources.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99993484375">
Natural language parsing is a hard task, partly be-
cause of the complexity and the volume of infor-
mation that have to be taken into account about
words and syntactic constructions. However, it
is necessary to have access to such information,
stored in resources such as lexica and grammars,
and to try and minimize the amount of missing
and erroneous information in these resources. To
achieve this, the use of these resources at a large-
scale in parsers is a very promising approach (van
Noord, 2004), and in particular the analysis of sit-
uations that lead to a parsing failure: one can learn
from one’s own mistakes.
We introduce a probabilistic model that allows
to identify forms and form bigrams that may be
the source of errors, thanks to a corpus of parsed
sentences. In order to facilitate the exploitation of
forms and form bigrams detected by the model,
and in particular to identify causes of errors, we
have developed a visualization environment. The
whole system has been tested on parsing results
produced for several multi-million-word corpora
and with two different parsers for French, namely
SXLFG and FRMG.
However, the error mining technique which
is the topic of this paper is fully system- and
language-independent. It could be applied with-
out any change on parsing results produced by any
system working on any language. The only infor-
mation that is needed is a boolean value for each
sentence which indicates if it has been success-
fully parsed or not.
</bodyText>
<sectionHeader confidence="0.995486" genericHeader="introduction">
2 Principles
</sectionHeader>
<subsectionHeader confidence="0.815295">
2.1 General idea
</subsectionHeader>
<bodyText confidence="0.962040230769231">
The idea we implemented is inspired from (van
Noord, 2004). In order to identify missing and er-
roneous information in a parsing system, one can
analyze a large corpus and study with statistical
tools what differentiates sentences for which pars-
ing succeeded from sentences for which it failed.
The simplest application of this idea is to look
for forms, called suspicious forms, that are found
more frequently in sentences that could not be
parsed. This is what van Noord (2004) does, with-
out trying to identify a suspicious form in any sen-
tence whose parsing failed, and thus without tak-
ing into account the fact that there is (at least)
one cause of error in each unparsable sentence.1
On the contrary, we will look, in each sentence
on which parsing failed, for the form that has
the highest probability of being the cause of this
failure: it is the main suspect of the sentence.
This form may be incorrectly or only partially de-
scribed in the lexicon, it may take part in construc-
tions that are not described in the grammar, or it
may exemplify imperfections of the pre-syntactic
processing chain. This idea can be easily extended
to sequences of forms, which is what we do by tak-
1Indeed, he defines the suspicion rate of a form f as the
rate of unparsable sentences among sentences that contain f.
</bodyText>
<page confidence="0.978364">
329
</page>
<note confidence="0.6968455">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 329–336,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.510889">
ing form bigrams into account, but also to lemmas
(or sequences of lemmas).
compute the n + 1-th estimation of the mean sus-
picion rate of each form f, denoted by S(n+1)
f :
</bodyText>
<subsectionHeader confidence="0.982382">
2.2 Form-level probabilistic model
</subsectionHeader>
<bodyText confidence="0.999235047619048">
We suppose that the corpus is split in sentences,
sentences being segmented in forms. We denote
by si the i-th sentence. We denote by oi,j, (1 ≤
j ≤ |si|) the occurrences of forms that constitute
si, and by F(oi,j) the corresponding forms. Fi-
nally, we call error the function that associates to
each sentence si either 1, if si’s parsing failed, and
0 if it succeeded.
Let Of be the set of the occurrences of a form
f in the corpus: Of = {oi,j|F(oi,j) = f}. The
number of occurrences of f in the corpus is there-
fore |Of |.
Let us define at first the mean global suspicion
rate S, that is the mean probability that a given oc-
currence of a form be the cause of a parsing fail-
ure. We make the assumption that the failure of
the parsing of a sentence has a unique cause (here,
a unique form... ). This assumption, which is not
necessarily exactly verified, simplifies the model
and leads to good results. If we call occtotal the
total amount of forms in the corpus, we have then:
</bodyText>
<equation confidence="0.948636">
Σierror(si)
S =
occtotal
</equation>
<bodyText confidence="0.999705736842105">
Let f be a form, that occurs as the j-th form of
sentence si, which means that F(oi,j) = f. Let us
assume that si’s parsing failed: error(si) = 1. We
call suspicion rate of the j-th form oi,j of sentence
si the probability, denoted by Si,j, that the occur-
rence oi,j of form form f be the cause of the si’s
parsing failure. If, on the contrary, si’s parsing
succeeded, its occurrences have a suspicion rate
that is equal to zero.
We then define the mean suspicion rate Sf of
a form f as the mean of all suspicion rates of its
occurrences:
gorithm by iterating a certain amount of times the
following computations. Let us assume that we
just completed the n-th iteration: we know, for
each sentence si, and for each occurrence oi,j of
this sentence, the estimation of its suspicion rate
Si,j as computed by the n-th iteration, estimation
that is denoted by S(n)
</bodyText>
<equation confidence="0.632723">
i,j . From this estimation, we
f . E S(n)
INZ,j
oi,j∈Of
</equation>
<bodyText confidence="0.998731">
This rate2 allows us to compute a new estima-
tion of the suspicion rate of all occurrences, by
giving to each occurrence if a sentence si a sus-
</bodyText>
<equation confidence="0.922302333333333">
picion rate S(n+1)
i,j that is exactly the estimation
S(n+1)
</equation>
<bodyText confidence="0.997370333333333">
f of the mean suspicion rate of Sf of the cor-
responding form, and then to perform a sentence-
level normalization. Thus:
</bodyText>
<equation confidence="0.9995215">
S(n+1)
S(n+1) F(oi,j)
i,j=error(si)·E1≤j≤|si |S(n+1)
F (oi,j)
</equation>
<bodyText confidence="0.866122714285714">
At this point, the n+1-th iteration is completed,
and we can resume again these computations, un-
til convergence on a fix-point. To begin the whole
process, we just say, for an occurrence oi,j of sen-
tence si, that S(0)
i,j = error(si)/|si|. This means
that for a non-parsable sentence, we start from a
baseline where all of its occurrences have an equal
probability of being the cause of the failure.
After a few dozens of iterations, we get stabi-
lized estimations of the mean suspicion rate each
form, which allows:
also performed experiment in which Sf was esti-
mated by another estimator, namely the smoothed mean sus-
picion rate, denoted by
that takes into account the num-
ber of occurrences of
the confidence we can have
in the estimation
is lower if the number of occurrences
of f is lower. Hence the idea to smooth
</bodyText>
<subsectionHeader confidence="0.248063">
by replacing it
</subsectionHeader>
<bodyText confidence="0.430704">
with a weighted mean
</bodyText>
<equation confidence="0.842522588235294">
between
and S, where
2We
˜S(n)
f ,
f. Indeed,
S(n)
f
S(n)
f
˜S(n)
f
S(n)
f
the
weights a and 1
a depend on
</equation>
<bodyText confidence="0.365286">
if
</bodyText>
<listItem confidence="0.998773666666667">
• to identify the forms that most probably cause
errors,
• for each form
</listItem>
<bodyText confidence="0.678894666666667">
to identify non-parsable sen-
tences si where an occurrence
Of of f
</bodyText>
<equation confidence="0.836024823529412">
is a main suspect and where
has a very
f,
oi,j∈
oi,j
˜S(n)
f
will be close from S(n)
f ; if it is low, it will be closer from S:
=
+ (1
S.
˜S(n)
f
a(|Of|)·S(n)
f
−a(|Of|))·
</equation>
<bodyText confidence="0.9369915">
In these experiments, we used the smoothing function
= 1
with Q = 0.1. But this model,
used with the ranking according to Mf = Sf
(see
below), leads results that are very similar to those obtained
without smoothing. Therefore, we describe the smoothing-
less model, which has the advantage not to use an
</bodyText>
<equation confidence="0.946248833333333">
a(|Of|)
−e−β|Of |
·ln|Of |
empirically
chosen smoothing function.
f  |11 · Si,j
</equation>
<bodyText confidence="0.640135">
oi,j∈Of
To compute these rates, we use a fix-point al-
</bodyText>
<equation confidence="0.999155285714286">
1
Sf =
O
−
|Of |:
|Of |is high,
S(n+1) = 1
</equation>
<page confidence="0.964157">
330
</page>
<bodyText confidence="0.999909142857143">
high suspicion rate among all occurrences of
form f.
We implemented this algorithm as a perl script,
with strong optimizations of data structures so as
to reduce memory and time usage. In particu-
lar, form-level structures are shared between sen-
tences.
</bodyText>
<subsectionHeader confidence="0.999584">
2.3 Extensions of the model
</subsectionHeader>
<bodyText confidence="0.9999671875">
This model gives already very good results, as we
shall see in section 4. However, it can be extended
in different ways, some of which we already im-
plemented.
First of all, it is possible not to stick to forms.
Indeed, we do not only work on forms, but on cou-
ples made out of a form (a lexical entry) and one
or several token(s) that correspond to this form in
the raw text (a token is a portion of text delimited
by spaces or punctuation tokens).
Moreover, one can look for the cause of the fail-
ure of the parsing of a sentence not only in the
presence of a form in this sentence, but also in the
presence of a bigram3 of forms. To perform this,
one just needs to extend the notions of form and
occurrence, by saying that a (generalized) form is
a unigram or a bigram of forms, and that a (gen-
eralized) occurrence is an occurrence of a gener-
alized form, i.e., an occurrence of a unigram or a
bigram of forms. The results we present in sec-
tion 4 includes this extension, as well as the previ-
ous one.
Another possible generalization would be to
take into account facts about the sentence that are
not simultaneous (such as form unigrams and form
bigrams) but mutually exclusive, and that must
therefore be probabilized as well. We have not yet
implemented such a mechanism, but it would be
very interesting, because it would allow to go be-
yond forms or n-grams of forms, and to manipu-
late also lemmas (since a given form has usually
several possible lemmas).
</bodyText>
<sectionHeader confidence="0.999862" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.99986">
In order to validate our approach, we applied
these principles to look for error causes in pars-
ing results given by two deep parsing systems for
French, FRMG and SXLFG, on large corpora.
</bodyText>
<footnote confidence="0.832243666666667">
3One could generalize this to n-grams, but as n gets
higher the number of occurrences of n-grams gets lower,
hence leading to non-significant statistics.
</footnote>
<subsectionHeader confidence="0.99033">
3.1 Parsers
</subsectionHeader>
<bodyText confidence="0.986804">
Both parsing systems we used are based on deep
non-probabilistic parsers. They share:
</bodyText>
<listItem confidence="0.907677928571428">
• the Lefff 2 syntactic lexicon for French
(Sagot et al., 2005), that contains 500,000 en-
tries (representing 400,000 different forms) ;
each lexical entry contains morphological in-
formation, sub-categorization frames (when
relevant), and complementary syntactic infor-
mation, in particular for verbal forms (con-
trols, attributives, impersonals,... ),
• the SXPipe pre-syntactic processing chain
(Sagot and Boullier, 2005), that converts a
raw text in a sequence of DAGs of forms that
are present in the Lefff ; SXPipe contains,
among other modules, a sentence-level seg-
menter, a tokenization and spelling-error cor-
</listItem>
<bodyText confidence="0.984172878787879">
rection module, named-entities recognizers,
and a non-deterministic multi-word identifier.
But FRMG and SXLFG use completely different
parsers, that rely on different formalisms, on dif-
ferent grammars and on different parser builder.
Therefore, the comparison of error mining results
on the output of these two systems makes it possi-
ble to distinguish errors coming from the Lefff or
from SXPipe from those coming to one grammar
or the other. Let us describe in more details the
characteristics of these two parsers.
The FRMG parser (Thomasset and Villemonte
de la Clergerie, 2005) is based on a compact TAG
for French that is automatically generated from
a meta-grammar. The compilation and execution
of the parser is performed in the framework of
the DYALOG system (Villemonte de la Clergerie,
2005).
The SXLFG parser (Boullier and Sagot, 2005b;
Boullier and Sagot, 2005a) is an efficient and ro-
bust LFG parser. Parsing is performed in two
steps. First, an Earley-like parser builds a shared
forest that represents all constituent structures that
satisfy the context-free skeleton of the grammar.
Then functional structures are built, in one or more
bottom-up passes. Parsing efficiency is achieved
thanks to several techniques such as compact data
representation, systematic use of structure and
computation sharing, lazy evaluation and heuristic
and almost non-destructive pruning during pars-
ing.
Both parsers implement also advanced error re-
covery and tolerance techniques, but they were
</bodyText>
<page confidence="0.986637">
331
</page>
<table confidence="0.9994272">
corpus #sentences #success (%) #forms #occ S (%) Date
MD/FRMG 330,938 136,885 (41.30%) 255,616 10,422,926 1.86% Jul. 05
MD/SXLFG 567,039 343,988 (60.66%) 327,785 14,482,059 1.54% Mar. 05
EASy/FRMG 39,872 16,477 (41.32%) 61,135 878,156 2.66% Dec. 05
EASy/SXLFG 39,872 21,067 (52.84%) 61,135 878,156 2.15% Dec. 05
</table>
<tableCaption confidence="0.999943">
Table 1: General information on corpora and parsing results
</tableCaption>
<bodyText confidence="0.86763225">
useless for the experiments described here, since
we want only to distinguish sentences that receive
a full parse (without any recovery technique) from
those that do not.
</bodyText>
<subsectionHeader confidence="0.994662">
3.2 Corpora
</subsectionHeader>
<bodyText confidence="0.999705037037037">
We parsed with these two systems the following
corpora:
MD corpus : This corpus is made out of 14.5
million words (570,000 sentences) of general
journalistic corpus that are articles from the
Monde diplomatique.
EASy corpus : This is the 40,000-sentence cor-
pus that has been built for the EASy parsing
evaluation campaign for French (Paroubek et
al., 2005). We only used the raw corpus
(without taking into account the fact that a
manual parse is available for 10% of all sen-
tences). The EASy corpus contains several
sub-corpora of varied style: journalistic, lit-
eracy, legal, medical, transcription of oral, e-
mail, questions, etc.
Both corpora are raw in the sense that no clean-
ing whatsoever has been performed so as to elimi-
nate some sequences of characters that can not re-
ally be considered as sentences.
Table 1 gives some general information on these
corpora as well as the results we got with both
parsing systems. It shall be noticed that both
parsers did not parse exactly the same set and the
same number of sentences for the MD corpus, and
that they do not define in the exactly same way the
notion of sentence.
</bodyText>
<subsectionHeader confidence="0.7304">
3.3 Results visualization environment
</subsectionHeader>
<bodyText confidence="0.991504156862745">
We developed a visualization tool for the results of
the error mining, that allows to examine and an-
notate them. It has the form of an HTML page
that uses dynamic generation methods, in particu-
lar javascript. An example is shown on Figure 1.
To achieve this, suspicious forms are ranked ac-
cording to a measure Mf that models, for a given
form f, the benefit there is to try and correct the
(potential) corresponding error in the resources. A
user who wants to concentrate on almost certain
errors rather than on most frequent ones can visu-
alize suspicious forms ranked according to Mf =
Sf. On the contrary, a user who wants to concen-
trate on most frequent potential errors, rather than
on the confidence that the algorithm has given to
errors, can visualize suspicious forms ranked ac-
cording to4 Mf = Sf|Of |. The default choice,
which is adopted to produce all tables shown in
this paper, is a balance between these two possi-
bilities, and ranks suspicious forms according to
Mf = Sf · ln |Of|.
The visualization environment allows to browse
through (ranked) suspicious forms in a scrolling
list on the left part of the page (A). When the suspi-
cious form is associated to a token that is the same
as the form, only the form is shown. Otherwise,
the token is separated from the form by the sym-
bol “ / ”. The right part of the page shows various
pieces of information about the currently selected
form. After having given its rank according to the
ranking measure Mf that has been chosen (B), a
field is available to add or edit an annotation as-
sociated with the suspicious form (D). These an-
notations, aimed to ease the analysis of the error
mining results by linguists and by the developers
of parsers and resources (lexica, grammars), are
saved in a database (SQLITE). Statistical informa-
tion is also given about f (E), including its number
of occurrences occf, the number of occurrences of
f in non-parsable sentences, the final estimation
of its mean suspicion rate Sf and the rate err(f)
of non-parsable sentences among those where f
appears. This indications are complemented by a
brief summary of the iterative process that shows
the convergence of the successive estimations of
Sf. The lower part of the page gives a mean to
identify the cause of f-related errors by showing
4Let f be a form. The suspicion rate Sf can be considered
as the probability for a particular occurrence of f to cause
a parsing error. Therefore, Sf|Of  |models the number of
occurrences of f that do cause a parsing error.
</bodyText>
<page confidence="0.985249">
332
</page>
<figure confidence="0.999853875">
A
B
H
C
D
G
F
E
</figure>
<figureCaption confidence="0.999995">
Figure 1: Error mining results visualization environment (results are shown for MD/FRMG).
</figureCaption>
<bodyText confidence="0.999914875">
f’s entries in the Lefff lexicon (G) as well as non-
parsable sentences where f is the main suspect
and where one of its occurrences has a particularly
high suspicion rate5 (H).
The whole page (with annotations) can be sent
by e-mail, for example to the developer of the lex-
icon or to the developer of one parser or the other
(C).
</bodyText>
<sectionHeader confidence="0.999966" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.9983139375">
In this section, we mostly focus on the results of
our error mining algorithm on the parsing results
provided by SXLFG on the MD corpus. We first
present results when only forms are taken into ac-
count, and then give an insight on results when
both forms and form bigrams are considered.
5Such an information, which is extremely valuable for the
developers of the resources, can not be obtained by global
(form-level and not occurrence-level) approaches such as the
err(f)-based approach of (van Noord, 2004). Indeed, enu-
merating all sentences which include a given form f, and
which did not receive a full parse, is not precise enough:
it would show at the same time sentences wich fail be-
cause of f (e.g., because its lexical entry lacks a given sub-
categorization frame) and sentences which fail for an other
independent reason.
</bodyText>
<subsectionHeader confidence="0.999531">
4.1 Finding suspicious forms
</subsectionHeader>
<bodyText confidence="0.999994375">
The execution of our error mining script on
MD/SXLFG, with imax = 50 iterations and when
only (isolated) forms are taken into account, takes
less than one hour on a 3.2 GHz PC running
Linux with a 1.5 Go RAM. It outputs 18,334 rele-
vant suspicious forms (out of the 327,785 possible
ones), where a relevant suspicious form is defined
as a form f that satisfies the following arbitrary
</bodyText>
<equation confidence="0.6653175">
constraints:6 5(imax) &gt; 1, 5 · 5 and |Of |&gt; 5.
f
</equation>
<bodyText confidence="0.996312444444444">
We still can not prove theoretically the conver-
gence of the algorithm.7 But among the 1000 best-
ranked forms, the last iteration induces a mean
variation of the suspicion rate that is less than
0.01%.
On a smaller corpus like the EASy corpus, 200
iterations take 260s. The algorithm outputs less
than 3,000 relevant suspicious forms (out of the
61,125 possible ones). Convergence information
</bodyText>
<footnote confidence="0.922429428571429">
6These constraints filter results, but all forms are taken
into account during all iterations of the algorithm.
7However, the algorithms shares many common points
with iterative algorithm that are known to converge and that
have been proposed to find maximum entropy probability dis-
tributions under a set of constraints (Berger et al., 1996).
Such an algorithm is compared to ours later on in this paper.
</footnote>
<page confidence="0.998819">
333
</page>
<bodyText confidence="0.99253775">
is the same as what has been said above for the
MD corpus.
Table 2 gives an idea of the repartition of sus-
picious forms w.r.t. their frequency (for FRMG on
MD), showing that rare forms have a greater prob-
ability to be suspicious. The most frequent suspi-
cious form is the double-quote, with (only) 5f =
9%, partly because of segmentation problems.
</bodyText>
<subsectionHeader confidence="0.999834">
4.2 Analyzing results
</subsectionHeader>
<bodyText confidence="0.999971269230769">
Table 3 gives an insight on the output of our algo-
rithm on parsing results obtained by SXLFG on the
MD corpus. For each form f (in fact, for each cou-
ple of the form (token,form)), this table displays its
suspicion rate and its number of occurrences, as
well as the rate err(f) of non-parsable sentences
among those where f appears and a short manual
analysis of the underlying error.
In fact, a more in-depth manual analysis of the
results shows that they are very good: errors are
correctly identified, that can be associated with
four error sources: (1) the Lefff lexicon, (2) the
SXPipe pre-syntactic processing chain, (3) imper-
fections of the grammar, but also (4) problems re-
lated to the corpus itself (and to the fact that it
is a raw corpus, with meta-data and typographic
noise).
On the EASy corpus, results are also relevant,
but sometimes more difficult to interpret, because
of the relative small size of the corpus and because
of its heterogeneity. In particular, it contains e-
mail and oral transcriptions sub-corpora that in-
troduce a lot of noise. Segmentation problems
(caused both by SXPipe and by the corpus itself,
which is already segmented) play an especially
important role.
</bodyText>
<subsectionHeader confidence="0.9882825">
4.3 Comparing results with results of other
algorithms
</subsectionHeader>
<bodyText confidence="0.992747">
In order to validate our approach, we compared
our results with results given by two other relevant
algorithms:
</bodyText>
<listItem confidence="0.961979">
• van Noord’s (van Noord, 2004) (form-level
and non-iterative) evaluation of err(f) (the
rate of non-parsable sentences among sen-
tences containing the form f),
• a standard (occurrence-level and iterative)
maximum entropy evaluation of each form’s
</listItem>
<bodyText confidence="0.977656413793103">
contribution to the success or the failure of
a sentence (we used the MEGAM package
(Daumé III, 2004)).
As done for our algorithm, we do not rank forms
directly according to the suspicion rate 5f com-
puted by these algorithms. Instead, we use the Mf
measure presented above (Mf = 5f ·ln |Of |). Us-
ing directly van Noord’s measure selects as most
suspicious words very rare words, which shows
the importance of a good balance between suspi-
cion rate and frequency (as noted by (van Noord,
2004) in the discussion of his results). This remark
applies to the maximum entropy measure as well.
Table 4 shows for all algorithms the 10 best-
ranked suspicious forms, complemented by a man-
ual evaluation of their relevance. One clearly sees
that our approach leads to the best results. Van
Noord’s technique has been initially designed to
find errors in resources that already ensured a very
high coverage. On our systems, whose develop-
ment is less advanced, this technique ranks as most
suspicious forms those which are simply the most
frequent ones. It seems to be the case for the stan-
dard maximum entropy algorithm, thus showing
the importance to take into account the fact that
there is at least one cause of error in any sentence
whose parsing failed, not only to identify a main
suspicious form in each sentence, but also to get
relevant global results.
</bodyText>
<subsectionHeader confidence="0.998467">
4.4 Comparing results for both parsers
</subsectionHeader>
<bodyText confidence="0.999971153846154">
We complemented the separated study of error
mining results on the output of both parsers by
an analysis of merged results. We computed for
each form the harmonic mean of both measures
Mf = 5f · ln |Of  |obtained for each parsing sys-
tem. Results (not shown here) are very interest-
ing, because they identify errors that come mostly
from resources that are shared by both systems
(the Lefff lexicon and the pre-syntactic processing
chain SXPipe). Although some errors come from
common lacks of coverage in both grammars, it
is nevertheless a very efficient mean to get a first
repartition between error sources.
</bodyText>
<subsectionHeader confidence="0.849201">
4.5 Introducing form bigrams
</subsectionHeader>
<bodyText confidence="0.986329222222222">
As said before, we also performed experiments
where not only forms but also form bigrams are
treated as potential causes of errors. This approach
allows to identify situations where a form is not in
itself a relevant cause of error, but leads often to
a parse failure when immediately followed or pre-
ceded by an other form.
Table 5 shows best-ranked form bigrams (forms
that are ranked in-between are not shown, to em-
</bodyText>
<page confidence="0.992927">
334
</page>
<table confidence="0.998771">
#occ &gt; 100 000 &gt; 10 000 &gt; 1000 &gt; 100 &gt; 10
#forms 13 84 947 8345 40 393
#suspicious forms (%) 1 (7.6%) 13 (15.5%) 177 (18.7%) 1919 (23%) 12 022 (29.8%)
</table>
<tableCaption confidence="0.818269">
Table 2: Suspicious forms repartition for MD/FRMG
</tableCaption>
<table confidence="0.997859666666667">
Rank Token(s)/form S(50) |Of  |err(f) Mf Error cause
f
1 _____/_UNDERSCORE 100% 6399 100% 8.76 corpus: typographic noise
2 (...) 46% 2168 67% 2.82 SXPipe: should be treated as skippable words
3 2_]/_NUMBER 76% 30 93% 2.58 SXPipe: bad treatment of list constructs
4 privées 39% 589 87% 2.53 Lefff: misses as an adjective
5 Haaretz/_Uw 51% 149 70% 2.53 SXPipe: needs local grammars for references
6 contesté 52% 122 90% 2.52 Lefff: misses as an adjective
7 occupés 38% 601 86% 2.42 Lefff: misses as an adjective
8 privée 35% 834 82% 2.38 Lefff: misses as an adjective
9 [...] 44% 193 71% 2.33 SXPipe: should be treated as skippable words
10 faudrait 36% 603 85% 2.32 Lefff: can have a nominal object
</table>
<tableCaption confidence="0.992472">
Table 3: Analysis of the 10 best-ranked forms (ranked according to Mf = 5f · ln |Of |)
</tableCaption>
<table confidence="0.8991825">
this paper global maxent
Rank Token(s)/form Eval Token(s)/form Eval Token(s)/form Eval
1 _____/_UNDERSCORE ++ * + pour -
2 (...) ++ , - ) -
3 2_]/_NUMBER ++ livre - à -
4 privées ++ . - qu’il/qu’ -
5 Haaretz/_Uw ++ de - sont -
6 contesté ++ ; - le -
7 occupés ++ : - qu’un/qu’ +
8 privée ++ la - qu’un/un +
9 [...] ++ ´étrangères - que -
10 faudrait ++ lecteurs - pourrait -
</table>
<tableCaption confidence="0.991554333333333">
Table 4: The 10 best-ranked suspicious forms, according the the Mf measure, as computed by different
algorithms: ours (this paper), a standard maximum entropy algorithm (maxent) and van Noord’s rate
err(f) (global).
</tableCaption>
<table confidence="0.749224875">
Rank Tokens and forms Mf Error cause
4 Toutes/toutes les 2.73 grammar: badly treated pre-determiner adjective
6 y en 2,34 grammar: problem with the construction il y en a...
7 in “ 1.81 Lefff: in misses as a preposition, which happends before book titles (hence the “)
10 donne à 1.44 Lefff: donner should sub-categorize à-vcomps (donner à voir... )
11 de demain 1.19 Lefff: demain misses as common noun (standard adv are not preceded by prep)
16 ( 22/_NUMBER 0.86 grammar: footnote references not treated
16 22/_NUMBER ) 0.86 as above
</table>
<tableCaption confidence="0.869671">
Table 5: Best ranked form bigrams (forms ranked inbetween are not shown; ranked according to Mf =
</tableCaption>
<footnote confidence="0.551141">
5f · ln |Of |). These results have been computed on a subset of the MD corpus (60,000 sentences).
</footnote>
<page confidence="0.9987">
335
</page>
<bodyText confidence="0.98748875">
phasize bigram results), with the same data as in
table 3.
and robust LFG parsing: SxLfg. In Proceedings of
IWPT’05, Vancouver, Canada, October.
</bodyText>
<sectionHeader confidence="0.995326" genericHeader="conclusions">
5 Conclusions and perspectives
</sectionHeader>
<bodyText confidence="0.999948194444444">
As we have shown, parsing large corpora allows
to set up error mining techniques, so as to identify
missing and erroneous information in the differ-
ent resources that are used by full-featured pars-
ing systems. The technique described in this pa-
per and its implementation on forms and form bi-
grams has already allowed us to detect many errors
and omissions in the Lefff lexicon, to point out in-
appropriate behaviors of the SXPipe pre-syntactic
processing chain, and to reveal the lack of cover-
age of the grammars for certain phenomena.
We intend to carry on and extend this work.
First of all, the visualization environment can be
enhanced, as is the case for the implementation of
the algorithm itself.
We would also like to integrate to the model
the possibility that facts taken into account (to-
day, forms and form bigrams) are not necessar-
ily certain, because some of them could be the
consequence of an ambiguity. For example, for
a given form, several lemmas are often possible.
The probabilization of these lemmas would thus
allow to look for most suspicious lemmas.
We are already working on a module that will
allow not only to detect errors, for example in
the lexicon, but also to propose a correction. To
achieve this, we want to parse anew all non-
parsable sentences, after having replaced their
main suspects by a special form that receives
under-specified lexical information. These infor-
mation can be either very general, or can be com-
puted by appropriate generalization patterns ap-
plied on the information associated by the lexicon
with the original form. A statistical study of the
new parsing results will make it possible to pro-
pose corrections concerning the involved forms.
</bodyText>
<sectionHeader confidence="0.999614" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999496325">
A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A
maximun entropy approach to natural language pro-
cessing. Computational Linguistics, 22(1):pp. 39–
71.
Pierre Boullier and Benoît Sagot. 2005a. Analyse syn-
taxique profonde à grande échelle: SXLFG. Traite-
mentAutomatique des Langues (T.A.L.), 46(2).
Pierre Boullier and Benoît Sagot. 2005b. Efficient
Hal Daumé III. 2004. Notes on CG and LM-BFGS
optimization of logistic regression. Paper available
at http://www.isi.edu/~hdaume/docs/
daume04cg-bfgs.ps, implementation avail-
able at http://www.isi.edu/~hdaume/
megam/.
Patrick Paroubek, Louis-Gabriel Pouillot, Isabelle
Robba, and Anne Vilnat. 2005. EASy : cam-
pagne d’évaluation des analyseurs syntaxiques. In
Proceedings of the EASy workshop of TALN 2005,
Dourdan, France.
Benoît Sagot and Pierre Boullier. 2005. From raw cor-
pus to word lattices: robust pre-parsing processing.
In Proceedings ofL&amp;TC 2005, Pozna´n, Pologne.
Benoît Sagot, Lionel Clément, Éric Villemonte de la
Clergerie, and Pierre Boullier. 2005. Vers un
méta-lexique pour le français : architecture, acqui-
sition, utilisation. Journée d’étude de l’ATALA sur
l’interface lexique-grammaire et les lexiques syntax-
iques et sémantiques, March.
François Thomasset and Éric Villemonte de la Clerg-
erie. 2005. Comment obtenir plus des méta-
grammaires. In Proceedings of TALN’05, Dourdan,
France, June. ATALA.
Gertjan van Noord. 2004. Error mining for wide-
coverage grammar engineering. In Proc. of ACL
2004, Barcelona, Spain.
Éric Villemonte de la Clergerie. 2005. DyALog: a
tabular logic programming based environment for
NLP. In Proceedings of 2nd International Work-
shop on Constraint Solving and Language Process-
ing (CSLP’05), Barcelona, Spain, October.
</reference>
<page confidence="0.999141">
336
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.462946">
<title confidence="0.99491">Error mining in parsing results</title>
<author confidence="0.740828">Benoît Sagot</author>
<author confidence="0.740828">Éric de_la Clergerie</author>
<affiliation confidence="0.703678">Projet ATOLL - INRIA</affiliation>
<address confidence="0.812241">Domaine de Voluceau, B.P. 105 78153 Le Chesnay Cedex, France</address>
<email confidence="0.99771">benoit.sagot@inria.fr</email>
<email confidence="0.99771">eric.de_la_clergerie@inria.fr</email>
<abstract confidence="0.997246090909091">We introduce an error mining technique for automatically detecting errors in resources that are used in parsing systems. We applied this technique on parsing results produced on several million words by two distinct parsing systems, which share the syntactic lexicon and the pre-parsing processing chain. We were thus able to identify missing and erroneous information in these resources.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Berger</author>
<author>S Della Pietra</author>
<author>V Della Pietra</author>
</authors>
<title>A maximun entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<pages>71</pages>
<contexts>
<context position="18880" citStr="Berger et al., 1996" startWordPosition="3267" endWordPosition="3270"> last iteration induces a mean variation of the suspicion rate that is less than 0.01%. On a smaller corpus like the EASy corpus, 200 iterations take 260s. The algorithm outputs less than 3,000 relevant suspicious forms (out of the 61,125 possible ones). Convergence information 6These constraints filter results, but all forms are taken into account during all iterations of the algorithm. 7However, the algorithms shares many common points with iterative algorithm that are known to converge and that have been proposed to find maximum entropy probability distributions under a set of constraints (Berger et al., 1996). Such an algorithm is compared to ours later on in this paper. 333 is the same as what has been said above for the MD corpus. Table 2 gives an idea of the repartition of suspicious forms w.r.t. their frequency (for FRMG on MD), showing that rare forms have a greater probability to be suspicious. The most frequent suspicious form is the double-quote, with (only) 5f = 9%, partly because of segmentation problems. 4.2 Analyzing results Table 3 gives an insight on the output of our algorithm on parsing results obtained by SXLFG on the MD corpus. For each form f (in fact, for each couple of the for</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>A. Berger, S. Della Pietra, and V. Della Pietra. 1996. A maximun entropy approach to natural language processing. Computational Linguistics, 22(1):pp. 39– 71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Boullier</author>
<author>Benoît Sagot</author>
</authors>
<title>Analyse syntaxique profonde à grande échelle:</title>
<date>2005</date>
<booktitle>SXLFG. TraitementAutomatique des Langues (T.A.L.),</booktitle>
<volume>46</volume>
<issue>2</issue>
<contexts>
<context position="11533" citStr="Boullier and Sagot, 2005" startWordPosition="2015" endWordPosition="2018">ser builder. Therefore, the comparison of error mining results on the output of these two systems makes it possible to distinguish errors coming from the Lefff or from SXPipe from those coming to one grammar or the other. Let us describe in more details the characteristics of these two parsers. The FRMG parser (Thomasset and Villemonte de la Clergerie, 2005) is based on a compact TAG for French that is automatically generated from a meta-grammar. The compilation and execution of the parser is performed in the framework of the DYALOG system (Villemonte de la Clergerie, 2005). The SXLFG parser (Boullier and Sagot, 2005b; Boullier and Sagot, 2005a) is an efficient and robust LFG parser. Parsing is performed in two steps. First, an Earley-like parser builds a shared forest that represents all constituent structures that satisfy the context-free skeleton of the grammar. Then functional structures are built, in one or more bottom-up passes. Parsing efficiency is achieved thanks to several techniques such as compact data representation, systematic use of structure and computation sharing, lazy evaluation and heuristic and almost non-destructive pruning during parsing. Both parsers implement also advanced error r</context>
</contexts>
<marker>Boullier, Sagot, 2005</marker>
<rawString>Pierre Boullier and Benoît Sagot. 2005a. Analyse syntaxique profonde à grande échelle: SXLFG. TraitementAutomatique des Langues (T.A.L.), 46(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Boullier</author>
<author>Benoît Sagot</author>
</authors>
<date>2005</date>
<publisher>Efficient</publisher>
<contexts>
<context position="11533" citStr="Boullier and Sagot, 2005" startWordPosition="2015" endWordPosition="2018">ser builder. Therefore, the comparison of error mining results on the output of these two systems makes it possible to distinguish errors coming from the Lefff or from SXPipe from those coming to one grammar or the other. Let us describe in more details the characteristics of these two parsers. The FRMG parser (Thomasset and Villemonte de la Clergerie, 2005) is based on a compact TAG for French that is automatically generated from a meta-grammar. The compilation and execution of the parser is performed in the framework of the DYALOG system (Villemonte de la Clergerie, 2005). The SXLFG parser (Boullier and Sagot, 2005b; Boullier and Sagot, 2005a) is an efficient and robust LFG parser. Parsing is performed in two steps. First, an Earley-like parser builds a shared forest that represents all constituent structures that satisfy the context-free skeleton of the grammar. Then functional structures are built, in one or more bottom-up passes. Parsing efficiency is achieved thanks to several techniques such as compact data representation, systematic use of structure and computation sharing, lazy evaluation and heuristic and almost non-destructive pruning during parsing. Both parsers implement also advanced error r</context>
</contexts>
<marker>Boullier, Sagot, 2005</marker>
<rawString>Pierre Boullier and Benoît Sagot. 2005b. Efficient</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hal Daumé</author>
</authors>
<title>Notes on CG and LM-BFGS optimization of logistic regression. Paper available at http://www.isi.edu/~hdaume/docs/ daume04cg-bfgs.ps, implementation available at http://www.isi.edu/~hdaume/ megam/.</title>
<date>2004</date>
<marker>Daumé, 2004</marker>
<rawString>Hal Daumé III. 2004. Notes on CG and LM-BFGS optimization of logistic regression. Paper available at http://www.isi.edu/~hdaume/docs/ daume04cg-bfgs.ps, implementation available at http://www.isi.edu/~hdaume/ megam/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Paroubek</author>
<author>Louis-Gabriel Pouillot</author>
<author>Isabelle Robba</author>
<author>Anne Vilnat</author>
</authors>
<title>EASy : campagne d’évaluation des analyseurs syntaxiques.</title>
<date>2005</date>
<booktitle>In Proceedings of the EASy workshop of TALN 2005,</booktitle>
<location>Dourdan, France.</location>
<contexts>
<context position="13096" citStr="Paroubek et al., 2005" startWordPosition="2253" endWordPosition="2256"> 878,156 2.15% Dec. 05 Table 1: General information on corpora and parsing results useless for the experiments described here, since we want only to distinguish sentences that receive a full parse (without any recovery technique) from those that do not. 3.2 Corpora We parsed with these two systems the following corpora: MD corpus : This corpus is made out of 14.5 million words (570,000 sentences) of general journalistic corpus that are articles from the Monde diplomatique. EASy corpus : This is the 40,000-sentence corpus that has been built for the EASy parsing evaluation campaign for French (Paroubek et al., 2005). We only used the raw corpus (without taking into account the fact that a manual parse is available for 10% of all sentences). The EASy corpus contains several sub-corpora of varied style: journalistic, literacy, legal, medical, transcription of oral, email, questions, etc. Both corpora are raw in the sense that no cleaning whatsoever has been performed so as to eliminate some sequences of characters that can not really be considered as sentences. Table 1 gives some general information on these corpora as well as the results we got with both parsing systems. It shall be noticed that both pars</context>
</contexts>
<marker>Paroubek, Pouillot, Robba, Vilnat, 2005</marker>
<rawString>Patrick Paroubek, Louis-Gabriel Pouillot, Isabelle Robba, and Anne Vilnat. 2005. EASy : campagne d’évaluation des analyseurs syntaxiques. In Proceedings of the EASy workshop of TALN 2005, Dourdan, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoît Sagot</author>
<author>Pierre Boullier</author>
</authors>
<title>From raw corpus to word lattices: robust pre-parsing processing.</title>
<date>2005</date>
<booktitle>In Proceedings ofL&amp;TC 2005,</booktitle>
<location>Pozna´n, Pologne.</location>
<contexts>
<context position="10495" citStr="Sagot and Boullier, 2005" startWordPosition="1849" endWordPosition="1852"> gets higher the number of occurrences of n-grams gets lower, hence leading to non-significant statistics. 3.1 Parsers Both parsing systems we used are based on deep non-probabilistic parsers. They share: • the Lefff 2 syntactic lexicon for French (Sagot et al., 2005), that contains 500,000 entries (representing 400,000 different forms) ; each lexical entry contains morphological information, sub-categorization frames (when relevant), and complementary syntactic information, in particular for verbal forms (controls, attributives, impersonals,... ), • the SXPipe pre-syntactic processing chain (Sagot and Boullier, 2005), that converts a raw text in a sequence of DAGs of forms that are present in the Lefff ; SXPipe contains, among other modules, a sentence-level segmenter, a tokenization and spelling-error correction module, named-entities recognizers, and a non-deterministic multi-word identifier. But FRMG and SXLFG use completely different parsers, that rely on different formalisms, on different grammars and on different parser builder. Therefore, the comparison of error mining results on the output of these two systems makes it possible to distinguish errors coming from the Lefff or from SXPipe from those </context>
</contexts>
<marker>Sagot, Boullier, 2005</marker>
<rawString>Benoît Sagot and Pierre Boullier. 2005. From raw corpus to word lattices: robust pre-parsing processing. In Proceedings ofL&amp;TC 2005, Pozna´n, Pologne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benoît Sagot</author>
<author>Lionel Clément</author>
</authors>
<title>Éric Villemonte de la Clergerie, and</title>
<date>2005</date>
<marker>Sagot, Clément, 2005</marker>
<rawString>Benoît Sagot, Lionel Clément, Éric Villemonte de la Clergerie, and Pierre Boullier. 2005. Vers un méta-lexique pour le français : architecture, acquisition, utilisation. Journée d’étude de l’ATALA sur l’interface lexique-grammaire et les lexiques syntaxiques et sémantiques, March.</rawString>
</citation>
<citation valid="true">
<title>François Thomasset and Éric Villemonte de la Clergerie.</title>
<date>2005</date>
<booktitle>In Proceedings of TALN’05,</booktitle>
<publisher>ATALA.</publisher>
<location>Dourdan, France,</location>
<marker>2005</marker>
<rawString>François Thomasset and Éric Villemonte de la Clergerie. 2005. Comment obtenir plus des métagrammaires. In Proceedings of TALN’05, Dourdan, France, June. ATALA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gertjan van Noord</author>
</authors>
<title>Error mining for widecoverage grammar engineering.</title>
<date>2004</date>
<booktitle>In Proc. of ACL 2004,</booktitle>
<location>Barcelona,</location>
<marker>van Noord, 2004</marker>
<rawString>Gertjan van Noord. 2004. Error mining for widecoverage grammar engineering. In Proc. of ACL 2004, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Éric Villemonte de la Clergerie</author>
</authors>
<title>DyALog: a tabular logic programming based environment for NLP.</title>
<date>2005</date>
<booktitle>In Proceedings of 2nd International Workshop on Constraint Solving and Language Processing (CSLP’05),</booktitle>
<location>Barcelona, Spain,</location>
<contexts>
<context position="11269" citStr="Clergerie, 2005" startWordPosition="1974" endWordPosition="1975">tokenization and spelling-error correction module, named-entities recognizers, and a non-deterministic multi-word identifier. But FRMG and SXLFG use completely different parsers, that rely on different formalisms, on different grammars and on different parser builder. Therefore, the comparison of error mining results on the output of these two systems makes it possible to distinguish errors coming from the Lefff or from SXPipe from those coming to one grammar or the other. Let us describe in more details the characteristics of these two parsers. The FRMG parser (Thomasset and Villemonte de la Clergerie, 2005) is based on a compact TAG for French that is automatically generated from a meta-grammar. The compilation and execution of the parser is performed in the framework of the DYALOG system (Villemonte de la Clergerie, 2005). The SXLFG parser (Boullier and Sagot, 2005b; Boullier and Sagot, 2005a) is an efficient and robust LFG parser. Parsing is performed in two steps. First, an Earley-like parser builds a shared forest that represents all constituent structures that satisfy the context-free skeleton of the grammar. Then functional structures are built, in one or more bottom-up passes. Parsing eff</context>
</contexts>
<marker>Clergerie, 2005</marker>
<rawString>Éric Villemonte de la Clergerie. 2005. DyALog: a tabular logic programming based environment for NLP. In Proceedings of 2nd International Workshop on Constraint Solving and Language Processing (CSLP’05), Barcelona, Spain, October.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>