<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.85976">
Strong Lexicalization of Tree Adjoining Grammars
</title>
<author confidence="0.83158">
Andreas Maletti*
</author>
<affiliation confidence="0.570182">
IMS, Universit¨at Stuttgart
</affiliation>
<address confidence="0.5702935">
Pfaffenwaldring 5b
70569 Stuttgart, Germany
</address>
<email confidence="0.921983">
maletti@ims.uni-stuttgart.de
</email>
<author confidence="0.954312">
Joost Engelfriet
</author>
<affiliation confidence="0.972828">
LIACS, Leiden University
</affiliation>
<address confidence="0.904138">
P.O. Box 9512
2300 RA Leiden, The Netherlands
</address>
<email confidence="0.993897">
engelfri@liacs.nl
</email>
<sectionHeader confidence="0.994333" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9990775">
Recently, it was shown (KUHLMANN, SATTA:
Tree-adjoining grammars are not closed un-
der strong lexicalization. Comput. Linguist.,
2012) that finitely ambiguous tree adjoining
grammars cannot be transformed into a nor-
mal form (preserving the generated tree lan-
guage), in which each production contains a
lexical symbol. A more powerful model, the
simple context-free tree grammar, admits such
a normal form. It can be effectively con-
structed and the maximal rank of the non-
terminals only increases by 1. Thus, simple
context-free tree grammars strongly lexicalize
tree adjoining grammars and themselves.
</bodyText>
<sectionHeader confidence="0.998125" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999905470588235">
Tree adjoining grammars [TAG] (Joshi et al., 1969;
Joshi et al., 1975) are a mildly context-sensitive
grammar formalism that can handle certain non-
local dependencies (Kuhlmann and Mohl, 2006),
which occur in several natural languages. A good
overview on TAG, their formal properties, their lin-
guistic motivation, and their applications is pre-
sented by Joshi and Schabes (1992) and Joshi and
Schabes (1997), in which also strong lexicalization
is discussed. In general, lexicalization is the process
of transforming a grammar into an equivalent one
(potentially expressed in another formalism) such
that each production contains a lexical item (or an-
chor). Each production can then be viewed as lex-
ical information on its anchor. It demonstrates a
syntactical construction in which the anchor can oc-
cur. Since a lexical item is a letter of the string
</bodyText>
<note confidence="0.5027975">
* Financially supported by the German Research Founda-
tion (DFG) grant MA 4959 / 1-1.
</note>
<bodyText confidence="0.999423303030303">
alphabet, each production of a lexicalized gram-
mar produces at least one letter of the generated
string. Consequently, lexicalized grammars offer
significant parsing benefits (Schabes et al., 1988)
as the number of applications of productions (i.e.,
derivation steps) is clearly bounded by the length
of the input string. In addition, the lexical items
in the productions guide the production selection in
a derivation, which works especially well in sce-
narios with large alphabets.1 The GREIBACH nor-
mal form (Hopcroft et al., 2001; Blum and Koch,
1999) offers those benefits for context-free gram-
mars [CFG], but it changes the parse trees. Thus,
we distinguish between two notions of equivalence:
Weak equivalence (Bar-Hillel et al., 1960) only re-
quires that the generated string languages coincide,
whereas strong equivalence (Chomsky, 1963) re-
quires that even the generated tree languages coin-
cide. Correspondingly, we obtain weak and strong
lexicalization based on the required equivalence.
The GREIBACH normal form shows that CFG
can weakly lexicalize themselves, but they cannot
strongly lexicalize themselves (Schabes, 1990). It is
a prominent feature of tree adjoining grammars that
they can strongly lexicalize CFG (Schabes, 1990),2
and it was claimed and widely believed that they can
strongly lexicalize themselves. Recently, Kuhlmann
and Satta (2012) proved that TAG actually can-
not strongly lexicalize themselves. In fact, they
prove that TAG cannot even strongly lexicalize the
weaker tree insertion grammars (Schabes and Wa-
ters, 1995). However, TAG can weakly lexicalize
themselves (Fujiyoshi, 2005).
</bodyText>
<footnote confidence="0.463068">
1Chen (2001) presents a detailed account.
</footnote>
<note confidence="0.8070956">
2Good algorithmic properties and the good coverage of lin-
guistic phenomena are other prominent features.
506
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506–515,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.998847725">
Simple (i.e., linear and nondeleting) context-free
tree grammars [CFTG] (Rounds, 1969; Rounds,
1970) are a more powerful grammar formalism than
TAG (M¨onnich, 1997). However, the monadic vari-
ant is strongly equivalent to a slightly extended ver-
sion of TAG, which is called non-strict TAG (Kepser
and Rogers, 2011). A GREIBACH normal form for a
superclass of CFTG (viz., second-order abstract cat-
egorial grammars) was discussed by Kanazawa and
Yoshinaka (2005) and Yoshinaka (2006). In particu-
lar, they also demonstrate that monadic CFTG can
strongly lexicalize regular tree grammars (G´ecseg
and Steinby, 1984; G´ecseg and Steinby, 1997).
CFTG are weakly equivalent to the simple macro
grammars of Fischer (1968), which are a notational
variant of the well-nested linear context-free rewrit-
ing systems (LCFRS) of Vijay-Shanker et al. (1987)
and the well-nested multiple context-free grammars
(MCFG) of Seki et al. (1991).3 Thus, CFTG are
mildly context-sensitive since their generated string
languages are semi-linear and can be parsed in poly-
nomial time (G´omez-Rodr´ıguez et al., 2010).
In this contribution, we show that CFTG can
strongly lexicalize TAG and also themselves, thus
answering the second question in the conclusion
of Kuhlmann and Satta (2012). This is achieved
by a series of normalization steps (see Section 4)
and a final lexicalization step (see Section 5), in
which a lexical item is guessed for each produc-
tion that does not already contain one. This item
is then transported in an additional argument until
it is exchanged for the same item in a terminal pro-
duction. The lexicalization is effective and increases
the maximal rank (number of arguments) of the non-
terminals by at most 1. In contrast to a transforma-
tion into GREIBACH normal form, our lexicalization
does not radically change the structure of the deriva-
tions. Overall, our result shows that if we consider
only lexicalization, then CFTG are a more natural
generalization of CFG than TAG.
</bodyText>
<sectionHeader confidence="0.979883" genericHeader="introduction">
2 Notation
</sectionHeader>
<bodyText confidence="0.999793666666667">
We write [k] for the set {i E N  |1 G i G k},
where N denotes the set of nonnegative integers. We
use a fixed countably infinite set X = {x1, x2,... }
</bodyText>
<footnote confidence="0.503095">
3Kuhlmann (2010), M¨onnich (2010), and Kanazawa (2009)
discuss well-nestedness.
</footnote>
<bodyText confidence="0.976822621621622">
of (mutually distinguishable) variables, and we let
Xk = {xi  |i E [k]} be the first k variables from X
for every k E N. As usual, an alphabet E is a finite
set of symbols, and a ranked alphabet (E, rk) adds a
ranking rk: E —* N. We let Ek = {σ  |rk(σ) = k}
be the set of k-ary symbols. Moreover, we just
write E for the ranked alphabet (E, rk).4 We build
trees over the ranked alphabet E such that the nodes
are labeled by elements of E and the rank of the node
label determines the number of its children. In addi-
tion, elements of X can label leaves. Formally, the
set TΣ(X) of E-trees indexed by X is the smallest
set T such that X C_ T and σ(t1, ... , tk) E T for all
k E N, σ E Ek, and t1, ... , tk E T.5
We use positions to address the nodes of a tree. A
position is a sequence of nonnegative integers indi-
cating successively in which subtree the addressed
node is. More precisely, the root is at position ε and
the position ip with i E N and p E N* refers to
the position p in the ith direct subtree. Formally, the
set pos(t) C_ N* of positions of a tree t E TΣ(X) is
defined by pos(x) = {ε} for x E X and
pos(σ(t1, ... , tk)) = {ε} U {ip  |i E [k],p E pos(ti)}
for all symbols σ E Ek and t1, ... , tk E TΣ(X).
The positions are indicated as superscripts of the la-
bels in the tree of Figure 1. The subtree of t at posi-
tion p E pos(t) is denoted by t|p, and the label of t
at position p by t(p). Moreover, t[u]p denotes the
tree obtained from t by replacing the subtree at p by
the tree u E TΣ(X). For every label set S C_ E,
we let posS(t) = {p E pos(t)  |t(p) E S} be
the S-labeled positions of t. For every σ E E,
we let posa(t) = pos{a}(t). The set CΣ(Xk) con-
tains all trees t of TΣ(X), in which every x E Xk
occurs exactly once and posX\Xk(t) = 0. Given
u1, ... , uk E TΣ(X), the first-order substitution
t[u1, ... , uk] is inductively defined by
</bodyText>
<equation confidence="0.9932028">
�
ui if i E [k]
xi[u1, ... , uk] =
xi otherwise
t[u1, ... , uk] = σ(t1[u1, ... , uk], ... , tk[u1, ... , uk]�
</equation>
<bodyText confidence="0.998443333333333">
for every i E N and t = σ(t1, ... , tk) with σ E Ek
and t1, ... , tk E TΣ(X). First-order substitution is
illustrated in Figure 1.
</bodyText>
<footnote confidence="0.8701685">
4We often decorate a symbol Q with its rank k [e.g. Q(k)].
5We will often drop quantifications like ‘for all k E N’.
</footnote>
<figure confidence="0.984619866666666">
507
0&apos;
0&apos;
0&apos;[1]
α[11] x212]
0&apos;[2]
x[121] α[22]
x1 ] =
0&apos;
1 0&apos; 0&apos; =
0&apos;[E]
[ry
α
α x1
0&apos;
α
ry
0&apos;
α
α 0&apos;
0&apos;
α α
le +—
α x2
x1 α
0&apos;
0&apos;
α 0&apos;
α α
α α
</figure>
<figureCaption confidence="0.999757">
Figure 1: Tree in Cr(X2) C Tr(X) with indicated po-
</figureCaption>
<bodyText confidence="0.983546611111111">
sitions, where E = {0&apos;, ry, α} with rk(0&apos;) = 2, rk(ry) = 1,
and rk(α) = 0, and an example first-order substitution.
In first-order substitution we replace leaves (ele-
ments of X), whereas in second-order substitution
we replace an internal node (labeled by a symbol
of E). Let p E pos(t) be such that t(p) E Ek,
and let u E CΣ(Xk) be a tree in which the vari-
ables Xk occur exactly once. The second-order sub-
stitution t[p +— u] replaces the subtree at position p
by the tree u into which the children of p are (first-
order) substituted. In essence, u is “folded” into t at
position p. Formally, t[p +— u] = t[u[t|1, ... , t|k]] p.
Given P C_ posa(t) with 0&apos; E Ek, we let t[P +— u]
be t[p1 +— u] • • • [p,,, +— u], where P = {p1, ... , p,,,}
and p1 &gt; ••• &gt; p,,, in the lexicographic order.
Second-order substitution is illustrated in Figure 2.
G´ecseg and Steinby (1997) present a detailed intro-
duction to trees and tree languages.
</bodyText>
<sectionHeader confidence="0.881713" genericHeader="method">
3 Context-free tree grammars
</sectionHeader>
<bodyText confidence="0.992929">
In this section, we recall linear and nondeleting
context-free tree grammars [CFTG] (Rounds, 1969;
Rounds, 1970). The property ‘linear and nondelet-
ing’ is often called ‘simple’. The nonterminals of
regular tree grammars only occur at the leaves and
are replaced using first-order substitution. In con-
trast, the nonterminals of a CFTG are ranked sym-
bols, can occur anywhere in a tree, and are replaced
using second-order substitution.6 Consequently, the
nonterminals N of a CFTG form a ranked alpha-
bet. In the left-hand sides of productions we write
A(x1, ... , xk) for a nonterminal A E Nk to indi-
cate the variables that hold the direct subtrees of a
particular occurrence of A.
</bodyText>
<construct confidence="0.5798835">
Definition 1. A (simple) context-free tree gram-
mar [CFTG] is a system (N, E, S, P) such that
</construct>
<listItem confidence="0.965494">
• N is a ranked alphabet of nonterminal symbols,
• E is a ranked alphabet of terminal symbols,7
</listItem>
<footnote confidence="0.8667235">
6see Sections 6 and 15 of (G´ecseg and Steinby, 1997)
7We assume that E n N = 0.
</footnote>
<figureCaption confidence="0.9594245">
Figure 2: Example second-order substitution, in which
the boxed symbol 0&apos; is replaced.
</figureCaption>
<listItem confidence="0.999193">
• S E N0 is the start nonterminal of rank 0, and
• P is a finite set of productions of the form
A(x1, ... , xk) —* r, where r E CNUΣ(Xk)
and A E Nk.
</listItem>
<bodyText confidence="0.95256675">
The components f and r are called left- and right-
hand side of the production f —* r in P. We say
that it is an A-production if f = A(x1, ... , xk). The
right-hand side is simply a tree using terminal and
nonterminal symbols according to their rank. More-
over, it contains all the variables of Xk exactly once.
Let us illustrate the syntax on an example CFTG. We
use an abstract language for simplicity and clarity.
We use lower-case Greek letters for terminal sym-
bols and upper-case Latin letters for nonterminals.
Example 2. As a running example, we consider the
CFTG Gex = ({S(0), A(2)}, E, S, P) where
</bodyText>
<listItem confidence="0.9884975">
• E = {0&apos;(2), α(0), 0(0)} and
• P contains the productions (see Figure 3):8
</listItem>
<equation confidence="0.9963615">
S —* A(α, α)  |A(,3,,3)  |0&apos;(α, ,3)
A(x1, x2) —* A(0&apos;(x1, S), 0&apos;(x2, S))  |0&apos;(x1, x2) .
</equation>
<bodyText confidence="0.997985533333333">
We recall the (term) rewrite semantics (Baader
and Nipkow, 1998) of the CFTG G = (N, E, S, P).
Since G is simple, the actual rewriting strategy
is irrelevant. The sentential forms of G are sim-
ply SF(G) = TNUΣ(X). This is slightly more gen-
eral than necessary (for the semantics of G), but the
presence of variables in sentential forms will be use-
ful in the next section because it allows us to treat
right-hand sides as sentential forms. In essence in a
rewrite step we just select a nonterminal A E N and
an A-production p E P. Then we replace an occur-
rence of A in the sentential form by the right-hand
side of p using second-order substitution.
Definition 3. Let �, ( E SF(G) be sentential forms.
Given an A-production p = f —* r in P and an
</bodyText>
<figure confidence="0.692013">
8We separate several right-hand sides with ‘|’.
508
</figure>
<figureCaption confidence="0.999597">
Figure 3: Productions of Example 2.
</figureCaption>
<bodyText confidence="0.844625833333333">
A-labeled position p ∈ posA(ξ) in ξ, we write
ξ ⇒GP ξ[p ← r]. If there exist ρ ∈ P and
p ∈ pos(ξ) such that ξ ⇒��P
G ζ, then ξ ⇒G ζ.9 The
semantics QG� of G is {t ∈ TE  |S ⇒G t}, where
⇒G is the reflexive, transitive closure of ⇒G.
Two CFTG G1 and G2 are (strongly) equivalent if
QG1� = QG2�. In this contribution we are only con-
cerned with strong equivalence (Chomsky, 1963).
Although we recall the string corresponding to a tree
later on (via its yield), we will not investigate weak
equivalence (Bar-Hillel et al., 1960).
</bodyText>
<figureCaption confidence="0.9530055">
Example 4. Reconsider the CFTG Gex of Exam-
ple 2. A derivation to a tree of TE is illustrated in
Figure 4. It demonstrates that the final tree in that
derivation is in the language QGex� generated by Gex.
</figureCaption>
<bodyText confidence="0.9998935">
Finally, let us recall the relation between CFTG
and tree adjoining grammars [TAG] (Joshi et al.,
1969; Joshi et al., 1975). Joshi et al. (1975)
show that TAG are special footed CFTG (Kepser
and Rogers, 2011), which are weakly equivalent
to monadic CFTG, i.e., CFTG whose nonterminals
have rank at most 1 (M¨onnich, 1997; Fujiyoshi
and Kasai, 2000). Kepser and Rogers (2011) show
the strong equivalence of those CFTG to non-strict
TAG, which are slightly more powerful than tradi-
tional TAG. In general, TAG are a natural formalism
to describe the syntax of natural language.10
</bodyText>
<sectionHeader confidence="0.995811" genericHeader="method">
4 Normal forms
</sectionHeader>
<bodyText confidence="0.951196375">
In this section, we first recall an existing normal
form for CFTG. Then we introduce the property of
finite ambiguity in the spirit of (Schabes, 1990; Joshi
and Schabes, 1992; Kuhlmann and Satta, 2012),
which allows us to normalize our CFTG even fur-
ther. A major tool is a simple production elimination
9For all k E N and � =:�-c C we note that � E CNUr(Xk) if
and only if C E CNur(Xk).
</bodyText>
<note confidence="0.229131">
10XTAG Research Group (2001) wrote a TAG for English.
</note>
<bodyText confidence="0.999213575757576">
scheme, which we present in detail. From now on,
let G = (N, E, S, P) be the considered CFTG.
The CFTG G is start-separated if posS(r) = ∅
for every production ` → r ∈ P. In other words, the
start nonterminal S is not allowed in the right-hand
sides of the productions. It is clear that each CFTG
can be transformed into an equivalent start-separated
CFTG. In such a CFTG we call each production of
the form S → r initial. From now on, we assume,
without loss of generality, that G is start-separated.
Example 5. Let Gex = (N, E, S, P) be the CFTG
of Example 2. An equivalent start-separated CFTG
is G&apos;ex = ({S&apos;(0)} ∪ N, E, S&apos;, P ∪ {S&apos; → S}).
We start with the growing normal form of Stamer
and Otto (2007) and Stamer (2009). It requires that
the right-hand side of each non-initial production
contains at least two terminal or nonterminal sym-
bols. In particular, it eliminates projection produc-
tions A(x1) → x1 and unit productions, in which
the right-hand side has the same shape as the left-
hand side (potentially with a different root symbol
and a different order of the variables).
Definition 6. A production ` → r is growing if
|posNUE(r) |≥ 2. The CFTG G is growing if all
of its non-initial productions are growing.
The next theorem is Proposition 2 of (Stamer and
Otto, 2007). Stamer (2009) provides a full proof.
Theorem 7. For every start-separated CFTG there
exists an equivalent start-separated, growing CFTG.
Example 8. Let us transform the CFTG G&apos;ex of Ex-
ample 5 into growing normal form. We obtain the
CFTG G&apos;&apos;ex = ({S&apos;(0), S(0), A(2)}, E, S&apos;, P&apos;&apos;) where
P&apos;&apos; contains S&apos; → S and for each δ ∈ {α, β}
</bodyText>
<equation confidence="0.998655333333333">
S → A(δ,δ)  |σ(δ,δ)  |σ(α,β) (1)
A(x1, x2) → A(σ(x1, S), σ(x2, S)) (2)
A(x1, x2) → σ(σ(x1, S), σ(x2, S)) .
</equation>
<bodyText confidence="0.912440875">
From now on, we assume that G is growing. Next,
we recall the notion of finite ambiguity from (Sch-
abes, 1990; Joshi and Schabes, 1992; Kuhlmann and
Satta, 2012).11 We distinguish a subset A ⊆ E0 of
lexical symbols, which are the symbols that are pre-
served by the yield mapping. The yield of a tree is
11It should not be confused with the notion of ‘finite ambigu-
ity’ of (Goldstine et al., 1992; Klimann et al., 2004).
</bodyText>
<figure confidence="0.999779781818182">
x1 S
x2 S
A
σ
A
→
σ
σ
x1 x2
A
A
α α
A
β β
σ
α β
→
x1 x2
x1 x2
S →
S →
S →
509
A
S
A
α α
α S
⇒G
⇒G
σ σ
α S
⇒G
⇒G
⇒*G
β β
A
σ σ
σ
σ σ
α σ
σ
α A
A
α
σ
S
α σ
α
A
β β
α β
β β
α β
α σ
</figure>
<figureCaption confidence="0.999452">
Figure 4: Derivation using the CFTG Gex of Example 2. The selected positions are boxed.
</figureCaption>
<bodyText confidence="0.8440365">
a string of lexical symbols. All other symbols are
simply dropped (in a pre-order traversal). Formally,
</bodyText>
<equation confidence="0.904000666666667">
ydΔ : TΣ → A* is such that for all t = σ(t1, ... , tk)
with σ ∈ Ek and t1,...,tk ∈ TΣ
�
σ ydΔ(t1) ··· ydΔ(tk) if σ ∈ A
ydΔ(t) =
ydΔ(t1) · · · ydΔ(tk) otherwise.
</equation>
<bodyText confidence="0.991723685714286">
Definition 9. The tree language L ⊆ TΣ has finite
A-ambiguity if {t ∈ L  |ydΔ(t) = w} is finite for
every w ∈ A*.
Roughly speaking, we can say that the set L has
finite A-ambiguity if each w ∈ A* has finitely many
parses in L (where t is a parse of w if ydΔ(t) = w).
Our example CFTG Gex is such that QGex� has finite
{α,β}-ambiguity (because E1 = ∅).
In this contribution, we want to (strongly) lexical-
ize CFTG, which means that for each CFTG G such
that QG� has finite A-ambiguity, we want to con-
struct an equivalent CFTG such that each non-initial
production contains at least one lexical symbol.
This is typically called strong lexicalization (Sch-
abes, 1990; Joshi and Schabes, 1992; Kuhlmann
and Satta, 2012) because we require strong equiva-
lence.12 Let us formalize our lexicalization property.
Definition 10. The production ` → r is A-lexical-
ized if posΔ(r) =6 ∅. The CFTG G is A-lexicalized
if all its non-initial productions are A-lexicalized.
Note that the CFTG G&apos;&apos;ex of Example 8 is not yet
{α, β}-lexicalized. We will lexicalize it in the next
section. To do this in general, we need some auxil-
iary normal forms. First, we define our simple pro-
duction elimination scheme, which we will use in
the following. Roughly speaking, a non-initial A-
production such that A does not occur in its right-
hand side can be eliminated from G by applying it in
12The corresponding notion for weak equivalence is called
weak lexicalization (Joshi and Schabes, 1992).
all possible ways to occurrences in right-hand sides
of the remaining productions.
Definition 11. Let ρ = A(x1, ... , xk) → r in P
be a non-initial production such that posA(r) = ∅.
For every other production ρ&apos; = `&apos; → r&apos; in P and
</bodyText>
<equation confidence="0.743605">
J ⊆ posA(r&apos;), let ρ&apos;J = `&apos; → r&apos;[J ← r]. The CFTG
Elim(G, ρ) = (N, E, S, P&apos;) is such that
P&apos; = U {ρ&apos;J  |J ⊆ posA(r&apos;)} .
ρ&apos;=`&apos;—r&apos;EP\{ρ}
</equation>
<bodyText confidence="0.999592074074074">
In particular, ρ&apos; � = ρ&apos; for every production ρ&apos;,
so every production besides the eliminated produc-
tion ρ is preserved. We obtained the CFTG G&apos;&apos;ex of
Example 8 as Elim(G&apos;ex, A(x1, x2) → σ(x1, x2))
from G&apos;ex of Example 5.
Lemma 12. The CFTG G and G&apos; ρ Elim(G, ρ)
are equivalent for every non-initial A-production
ρ = ` → r in P such that posA(r) = ∅.
Proof. Clearly, every single derivation step of G&apos;ρ
can be simulated by a derivation of G using poten-
tially several steps. Conversely, a derivation of G
can be simulated directly by G&apos;ρ except for deriva-
tion steps ⇒ρ,p G using the eliminated production ρ.
Since S =6 A, we know that the nonterminal at po-
sition p was generated by another production ρ&apos;. In
the given derivation of G we examine which non-
terminals in the right-hand side of the instance of ρ&apos;
were replaced using ρ. Let J be the set of positions
corresponding to those nonterminals (thus p ∈ J).
Then instead of applying ρ&apos; and potentially several
times ρ, we equivalently apply ρ&apos;J of G&apos;ρ.
In the next normalization step we use our pro-
duction elimination scheme. The goal is to make
sure that non-initial monic productions (i.e., produc-
tions of which the right-hand side contains at most
one nonterminal) contain at least one lexical sym-
bol. We define the relevant property and then present
</bodyText>
<page confidence="0.564243">
510
</page>
<bodyText confidence="0.9881967">
the construction. A sentential form ξ ∈ SF(G)
is monic if |posN(ξ) |≤ 1. The set of all monic
sentential forms is denoted by SF≤1(G). A pro-
duction ` → r is monic if r is monic. The next
construction is similar to the simultaneous removal
of epsilon-productions A → ε and unit productions
A → B for context-free grammars (Hopcroft et al.,
2001). Instead of computing the closure under those
productions, we compute a closure under non-A-
lexicalized productions.
Theorem 13. If QG� has finite A-ambiguity, then
there exists an equivalent CFTG such that all its non-
initial monic productions are A-lexicalized.
Proof. Without loss of generality, we assume that
G is start-separated and growing by Theorem 7.
Moreover, we assume that each nonterminal is use-
ful. For every A ∈ N with A =6 S, we compute
all monic sentential forms without a lexical sym-
bol that are reachable from A(x1, ... , xk), where
k = rk(A). Formally, let
</bodyText>
<equation confidence="0.996964">
°A = {ξ ∈ SF≤1(G)  |A(x1, ... , xk) ⇒G0 ξ} ,
</equation>
<bodyText confidence="0.995573375">
where ⇒G0 is the transitive closure of ⇒G0 and the
CFTG G0 = (N, E, S, P0) is such that P0 contains
exactly the non-A-lexicalized productions of P.
The set °A is finite since only finitely many non-
A-lexicalized productions can be used due to the
finite A-ambiguity of QG�. Moreover, no senten-
tial form in °A contains A for the same reason
and the fact that G is growing. We construct the
</bodyText>
<equation confidence="0.75107">
CFTG G1 = (N, E, S, P ∪ P1) such that
P1 = {A(x1, ... , xk) → ξ  |A ∈ Nk, ξ ∈ °A} .
</equation>
<bodyText confidence="0.9994813">
Clearly, G and G1 are equivalent. Next, we elimi-
nate all productions of P1 from G1 using Lemma 12
to obtain an equivalent CFTG G2 with the produc-
tions P2. In the final step, we drop all non-A-
lexicalized monic productions of P2 to obtain the
CFTG G, in which all monic productions are A-
lexicalized. It is easy to see that G is growing, start-
separated, and equivalent to G2.
The CFTG G00ex only has {α, β}-lexicalized non-
initial monic productions, so we use a new example.
</bodyText>
<note confidence="0.401689">
Example 14. Let ({S(°), A(1), B(1)}, E, S, P) be
the CFTG such that E = {σ(2), α(°), β(°)} and
</note>
<figureCaption confidence="0.9889595">
Figure 5: The relevant derivations using only productions
that are not A-lexicalized (see Example 14).
</figureCaption>
<bodyText confidence="0.794011">
P contains the productions
</bodyText>
<equation confidence="0.9996935">
A(x1) → σ(β, B(x1)) B(x1) → σ(x1,β) (3)
B(x1) → σ(α,A(x1)) S → A(α) .
</equation>
<bodyText confidence="0.9744465">
This CFTG Gex2 is start-separated and growing.
Moreover, all its productions are monic, and QGex2�
is finitely A-ambiguous for the set A = {α} of
lexical symbols. Then the productions (3) are non-
initial and not A-lexicalized. So we can run the
construction in the proof of Theorem 13. The rel-
evant derivations using only non-A-lexicalized pro-
ductions are shown in Figure 5. We observe that
|°A |= 2 and |°B |= 1, so we obtain the CFTG
({S(°), B(1)}, E, S, P0), where P0 contains13
</bodyText>
<equation confidence="0.999873">
S → σ(β, B(α))  |σ(β, σ(α, β))
B(x1) → σ(α,σ(β,B(x1)))
B(x1) → σ(α, σ(β, σ(x1,β))) . (4)
</equation>
<bodyText confidence="0.997719947368421">
We now do one more normalization step before
we present our lexicalization. We call a production
` → r terminal if r ∈ TE(X); i.e., it does not con-
tain nonterminal symbols. Next, we show that for
each CFTG G such that QG� has finite A-ambiguity
we can require that each non-initial terminal produc-
tion contains at least two occurrences of A-symbols.
Theorem 15. If QG� has finite A-ambiguity, then
there exists an equivalent CFTG (N, E, S, P0) such
that |poso(r) |≥ 2 for all its non-initial terminal
productions ` → r ∈ P0.
Proof. Without loss of generality, we assume that
G is start-separated and growing by Theorem 7.
Moreover, we assume that each nonterminal is use-
ful and that each of its non-initial monic produc-
tions is A-lexicalized by Theorem 13. We obtain
the desired CFTG by simply eliminating each non-
initial terminal production ` → r ∈ P such that
|poso(r) |= 1. By Lemma 12 the obtained CFTG
</bodyText>
<figure confidence="0.999445488372093">
13The nonterminal A became useless, so we just removed it.
A ⇒G0
x1
σ
β B
x1
σ
β σ
x1 β
B
⇒G0
x1
σ
x1 β
⇒G0
511
(A, α)
σ
(A, α)
σ
x3
—*
x1 x2 x3
x1 (S, β)
β
x2 S
x1 S
x2 S
—*
x1 x2 x3
(A, α)
σ
σ
x3
(A, α)
A
A
σ
σ
x1 S
—*
x1 x2
x2 S
</figure>
<figureCaption confidence="0.9938755">
Figure 6: Production ρ = ` —* r of (2) [left], a corresponding production ρ« of P&apos; [middle] with right-hand side r«,2,
and a corresponding production of P&amp;quot;&apos; [right] with right-hand side (r«,2)0 (see Theorem 17).
</figureCaption>
<bodyText confidence="0.999955833333333">
is equivalent to G. The elimination process termi-
nates because a new terminal production can only be
constructed from a monic production and a terminal
production or several terminal productions, but those
combinations already contain two occurrences of Δ-
symbols since non-initial monic productions are al-
ready Δ-lexicalized.
Example 16. Reconsider the CFTG obtained in Ex-
ample 14. Recall that Δ = {α}. Production (4) is
the only non-initial terminal production that violates
the requirement of Theorem 15. We eliminate it and
obtain the CFTG with the productions
</bodyText>
<equation confidence="0.9970855">
S σ(β, B(α))  |σ(β, σ(α,β))
S σ(β, σ(α, σ(β, σ(α,β))))
B(x1) σ(α, σ(β, B(x1)))
B(x1) σ(α, σ(β, σ(α, σ(β, σ(x1,β))))) .
</equation>
<sectionHeader confidence="0.977095" genericHeader="evaluation">
5 Lexicalization
</sectionHeader>
<bodyText confidence="0.999904">
In this section, we present the main lexicalization
step, which lexicalizes non-monic productions. We
assume that QG� has finite Δ-ambiguity and is nor-
malized according to the results of Section 4: no
useless nonterminals, start-separated, growing (see
Theorem 7), non-initial monic productions are Δ-
lexicalized (see Theorem 13), and non-initial termi-
nal productions contain at least two occurrences of
Δ-symbols (see Theorem 15).
The basic idea of the construction is that we guess
a lexical symbol for each non-Δ-lexicalized produc-
tion. The guessed symbol is put into a new param-
eter of a nonterminal. It will be kept in the pa-
rameter until we reach a terminal production, where
we exchange the same lexical symbol by the pa-
rameter. This is the reason why we made sure
that we have two occurrences of lexical symbols in
the terminal productions. After we exchanged one
for a parameter, the resulting terminal production is
still Δ-lexicalized. Lexical items that are guessed
for distinct (occurrences of) productions are trans-
ported to distinct (occurrences of) terminal produc-
tions [cf. Section 3 of (Potthoff and Thomas, 1993)
and page 346 of (Hoogeboom and ten Pas, 1997)].
Theorem 17. For every CFTG G such that QG�
has finite Δ-ambiguity there exists an equivalent
Δ-lexicalized CFTG.
Proof. We can assume that G = (N, Σ, S, P) has
the properties mentioned before the theorem without
loss of generality. We let N&apos; = N x Δ be a new set
of nonterminals such that rk((A, δ)) = rk(A) + 1
for every A E N and δ E Δ. Intuitively, (A, δ)
represents the nonterminal A, which has the lexical
symbol δ in its last (new) parameter. This parameter
is handed to the (lexicographically) first nonterminal
in the right-hand side until it is resolved in a termi-
nal production. Formally, for each right-hand side
r E TNUNIUE(X) such that posN(r) =� 0 (i.e., it
contains an original nonterminal), each k E ICY, and
each δ E Δ, let rg,k and rg be such that
</bodyText>
<equation confidence="0.767388">
rg,k = r[(B, δ)(r1, ... , rn, xk+1)]p
rg = r[(B, δ)(r1, ... , rn, δ)]p ,
</equation>
<bodyText confidence="0.971449090909091">
where p is the lexicographically smallest element
of posN(r) and r|p = B(r1, ... , rn) with B E N
and r1, ... , rn E TNUNIUE(X). For each non-
terminal A-production ρ = ` —* r in P let
ρg = (A, δ)(x1, ... , xk+1) —* rg,k ,
where k = rk(A). This construction is illustrated
in Figure 6. Roughly speaking, we select the lexi-
cographically smallest occurrence of a nonterminal
in the right-hand side and pass the lexical symbol δ
in the extra parameter to it. The extra parameter is
used in terminal productions, so let ρ = ` —* r in P
</bodyText>
<figure confidence="0.884584">
512
S →
x1 α
</figure>
<figureCaption confidence="0.994759">
Figure 7: Original terminal production ρ from (1) [left]
and the production ρ (see Theorem 17).
</figureCaption>
<bodyText confidence="0.9777715">
be a terminal /A-production. Then we define
ρ = hA, r(p)i (x1, ... , xk+1) → r[xk+1lP ,
where p is the lexicographically smallest element
of posΔ(r) and k = rk(A). This construction is
illustrated in Figure 7. With these productions we
obtain the CFTG G0 = (N ∪ N0, E, S, P), where
</bodyText>
<equation confidence="0.99544">
P = P ∪ P0 ∪ P00 and
�P 0 = {ρa  |δ ∈ A} P00 = � {ρ} .
P6=S,posN (r)6=∅
P=&amp;4r∈P
W,posN (r)=0
P=&amp;4r∈P rrhh
</equation>
<bodyText confidence="0.999990375">
It is easy to prove that those new productions man-
age the desired transport of the extra parameter if it
holds the value indicated in the nonterminal.
Finally, we replace each non-initial non-A-lexi-
calized production in G0 by new productions that
guess a lexical symbol and add it to the new parame-
ter of the (lexicographically) first nonterminal of N
in the right-hand side. Formally, we let
</bodyText>
<equation confidence="0.999248">
Pnil = {` → r ∈ P  |` =6S,posΔ(r) = ∅}
P000 = {` → ra  |` → r ∈ Pnil,δ ∈ A} ,
</equation>
<bodyText confidence="0.995524083333334">
of which P000 is added to the productions. Note that
each production ` → r ∈ Pnil contains at least one
occurrence of a nonterminal of N (because all monic
productions of G are A-lexicalized). Now all non-
initial non-A-lexicalized productions from P can be
removed, so we obtain the CFTG G00, which is given
by (N ∪ N0, E, S, R) with R = (P ∪ P000) \ Pnil. It
can be verified that G00 is A-lexicalized and equiva-
lent to G (using the provided argumentation).
Instead of taking the lexicographically smallest
element of posN(r) or posΔ(r) in the previous
proof, we can take any fixed element of that set. In
the definition of P0 we can change posN(r) =6 ∅
to |posΔ(r) |≤ 1, and simultaneously in the defini-
tion of P00 change posN(r) = ∅ to |posΔ(r) |≥ 2.
With the latter changes the guessed lexical item is
only transported until it is resolved in a production
with at least two lexical items.
Example 18. For the last time, we consider the
CFTG G00 of Example 8. We already illustrated the
ex
parts of the construction of Theorem 17 in Figures
6 and 7. The obtained {α, β}-lexicalized CFTG has
the following 25 productions for all δ, δ0 ∈ {α, β}:
</bodyText>
<equation confidence="0.994006875">
S&apos; → S
S → A(δ,δ)  |σ(δ,δ)  |σ(α,β)
Sδ(x1) → Aδ(δ&apos;,δ&apos;,x1)  |σ(x1,δ)
Sα(x1) → σ(x1,β)
A(x1, x2) → Aδ(σ(x1, S), σ(x2, S), δ) (5)
Aδ(x1, x2, x3) →Aδ(σ(x1, Sδ&apos;(δ&apos;)), σ(x2, S), x3)
A(x1, x2) → σ(σ(x1, Sδ(δ)), σ(x2, S))
Aδ(x1, x2, x3) → σ(σ(x1, Sδ(x3)), σ(x2, Sδ&apos;(δ&apos;))) ,
</equation>
<bodyText confidence="0.998273666666667">
where Aa = hA, δi and Sa = hS, δi.
If we change the lexicalization construction as
indicated before this example, then all the produc-
tions Sa(x1) → Aa(δ0, δ0, x1) are replaced by the
productions Sa(x1) → A(x1, δ). Moreover, the
productions (5) can be replaced by the productions
A(x1, x2) → A(σ(x1, Sa(δ)), σ(x2, S)), and then
the nonterminals Aa and their productions can be re-
moved, which leaves only 15 productions.
</bodyText>
<sectionHeader confidence="0.929355" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999938454545455">
For k ∈ ICY, let CFTG(k) be the set of those CFTG
whose nonterminals have rank at most k. Since the
normal form constructions preserve the nonterminal
rank, the proof of Theorem 17 shows that CFTG(k)
are strongly lexicalized by CFTG(k+1). Kepser and
Rogers (2011) show that non-strict TAG are strongly
equivalent to CFTG(1). Hence, non-strict TAG are
strongly lexicalized by CFTG(2).
It follows from Section 6 of Engelfriet et al.
(1980) that the classes CFTG(k) with k ∈ ICY in-
duce an infinite hierarchy of string languages, but it
remains an open problem whether the rank increase
in our lexicalization construction is necessary.
G´omez-Rodriguez et al. (2010) show that well-
nested LCFRS of maximal fan-out k can be parsed
in time O(n2k+2), where n is the length of the in-
put string w ∈ A∗. From this result we conclude
that CFTG(k) can be parsed in time O(n2k+4), in
the sense that we can produce a parse tree t that
is generated by the CFTG with ydΔ(t) = w. It is
not clear yet whether lexicalized CFTG(k) can be
parsed more efficiently in practice.
</bodyText>
<figure confidence="0.7561604">
σ hS, αi
→
α α x1
σ
513
</figure>
<sectionHeader confidence="0.965163" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999777439252337">
Franz Baader and Tobias Nipkow. 1998. Term Rewriting
and All That. Cambridge University Press.
Yehoshua Bar-Hillel, Haim Gaifman, and Eli Shamir.
1960. On categorial and phrase-structure grammars.
Bulletin of the Research Council ofIsrael, 9F(1):1–16.
Norbert Blum and Robert Koch. 1999. Greibach normal
form transformation revisited. Inform. and Comput.,
150(1):112–118.
John Chen. 2001. Towards Efficient Statistical Parsing
using Lexicalized Grammatical Information. Ph.D.
thesis, University of Delaware, Newark, USA.
Noam Chomsky. 1963. Formal properties of gram-
mar. In R. Duncan Luce, Robert R. Bush, and Eugene
Galanter, editors, Handbook of Mathematical Psychol-
ogy, volume 2, pages 323–418. John Wiley and Sons,
Inc.
Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki.
1980. Tree transducers, L systems, and two-way ma-
chines. J. Comput. System Sci., 20(2):150–202.
Michael J. Fischer. 1968. Grammars with macro-like
productions. In Proc. 9th Ann. Symp. Switching and
Automata Theory, pages 131–142. IEEE Computer
Society.
Akio Fujiyoshi. 2005. Epsilon-free grammars and
lexicalized grammars that generate the class of the
mildly context-sensitive languages. In Proc. 7th Int.
Workshop Tree Adjoining Grammar and Related For-
malisms, pages 16–23.
Akio Fujiyoshi and Takumi Kasai. 2000. Spinal-formed
context-free tree grammars. Theory Comput. Syst.,
33(1):59–83.
Ferenc G´ecseg and Magnus Steinby. 1984. Tree Au-
tomata. Akad´emiai Kiad´o, Budapest.
Ferenc G´ecseg and Magnus Steinby. 1997. Tree lan-
guages. In Grzegorz Rozenberg and Arto Salomaa,
editors, Handbook of Formal Languages, volume 3,
chapter 1, pages 1–68. Springer.
Jonathan Goldstine, Hing Leung, and Detlef Wotschke.
1992. On the relation between ambiguity and nonde-
terminism in finite automata. Inform. and Comput.,
100(2):261–270.
Carlos G´omez-Rodriguez, Marco Kuhlmann, and Gior-
gio Satta. 2010. Efficient parsing of well-nested lin-
ear context-free rewriting systems. In Proc. Ann. Conf.
North American Chapter of the ACL, pages 276–284.
Association for Computational Linguistics.
Hendrik Jan Hoogeboom and Paulien ten Pas. 1997.
Monadic second-order definable text languages. The-
ory Comput. Syst., 30(4):335–354.
John E. Hopcroft, Rajeev Motwani, and Jeffrey D. Ull-
man. 2001. Introduction to automata theory, lan-
guages, and computation. Addison-Wesley series in
computer science. Addison Wesley, 2nd edition.
Aravind K. Joshi, S. Rao Kosaraju, and H. Yamada.
1969. String adjunct grammars. In Proc. 10th Ann.
Symp. Switching and Automata Theory, pages 245–
262. IEEE Computer Society.
Aravind K. Joshi, Leon S. Levy, and Masako Takahashi.
1975. Tree adjunct grammars. J. Comput. System Sci.,
10(1):136–163.
Aravind K. Joshi and Yves Schabes. 1992. Tree-
adjoining grammars and lexicalized grammars. In
Maurice Nivat and Andreas Podelski, editors, Tree Au-
tomata and Languages. North-Holland.
Aravind K. Joshi and Yves Schabes. 1997. Tree-
adjoining grammars. In Grzegorz Rozenberg and Arto
Salomaa, editors, Beyond Words, volume 3 of Hand-
book of Formal Languages, pages 69–123. Springer.
Makoto Kanazawa. 2009. The convergence of well-
nested mildly context-sensitive grammar formalisms.
Invited talk at the 14th Int. Conf. Formal Gram-
mar. slides available at: research.nii.ac.jp/
˜kanazawa.
Makoto Kanazawa and Ryo Yoshinaka. 2005. Lexical-
ization of second-order ACGs. Technical Report NII-
2005-012E, National Institute of Informatics, Tokyo,
Japan.
Stephan Kepser and James Rogers. 2011. The equiv-
alence of tree adjoining grammars and monadic lin-
ear context-free tree grammars. J. Log. Lang. Inf.,
20(3):361–384.
Ines Klimann, Sylvain Lombardy, Jean Mairesse, and
Christophe Prieur. 2004. Deciding unambiguity and
sequentiality from a finitely ambiguous max-plus au-
tomaton. Theoret. Comput. Sci., 327(3):349–373.
Marco Kuhlmann. 2010. Dependency Structures and
Lexicalized Grammars: An Algebraic Approach, vol-
ume 6270 of LNAI. Springer.
Marco Kuhlmann and Mathias Mohl. 2006. Extended
cross-serial dependencies in tree adjoining grammars.
In Proc. 8th Int. Workshop Tree Adjoining Grammars
and Related Formalisms, pages 121–126. ACL.
Marco Kuhlmann and Giorgio Satta. 2012. Tree-
adjoining grammars are not closed under strong lex-
icalization. Comput. Linguist. available at: dx.doi.
org/10.1162/COLI_a_00090.
Uwe M¨onnich. 1997. Adjunction as substitution: An
algebraic formulation of regular, context-free and tree
adjoining languages. In Proc. 3rd Int. Conf. Formal
Grammar, pages 169–178. Universit´e de Provence,
France. available at: arxiv.org/abs/cmp-lg/
9707012v1.
Uwe M¨onnich. 2010. Well-nested tree languages and at-
tributed tree transducers. In Proc. 10th Int. Conf. Tree
Adjoining Grammars and Related Formalisms. Yale
University. available at: www2.research.att.
com/˜srini/TAG+10/papers/uwe.pdf.
</reference>
<page confidence="0.552193">
514
</page>
<reference confidence="0.999827833333333">
Andreas Potthoff and Wolfgang Thomas. 1993. Reg-
ular tree languages without unary symbols are star-
free. In Proc. 9th Int. Symp. Fundamentals of Compu-
tation Theory, volume 710 of LNCS, pages 396–405.
Springer.
William C. Rounds. 1969. Context-free grammars on
trees. In Proc. 1st ACM Symp. Theory of Comput.,
pages 143–148. ACM.
William C. Rounds. 1970. Tree-oriented proofs of some
theorems on context-free and indexed languages. In
Proc. 2nd ACM Symp. Theory of Comput., pages 109–
116. ACM.
Yves Schabes. 1990. Mathematical and Computational
Aspects of Lexicalized Grammars. Ph.D. thesis, Uni-
versity of Pennsylvania, Philadelphia, USA.
Yves Schabes, Anne Abeill´e, and Aravind K. Joshi.
1988. Parsing strategies with ‘lexicalized’ grammars:
Application to tree adjoining grammars. In Proc. 12th
Int. Conf. Computational Linguistics, pages 578–583.
John von Neumann Society for Computing Sciences,
Budapest.
Yves Schabes and Richard C. Waters. 1995. Tree in-
sertion grammar: A cubic-time parsable formalism
that lexicalizes context-free grammars without chang-
ing the trees produced. Comput. Linguist., 21(4):479–
513.
Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and
Tadao Kasami. 1991. On multiple context-free gram-
mars. Theoret. Comput. Sci., 88(2):191–229.
Heiko Stamer. 2009. Restarting Tree Automata: Formal
Properties and Possible Variations. Ph.D. thesis, Uni-
versity of Kassel, Germany.
Heiko Stamer and Friedrich Otto. 2007. Restarting tree
automata and linear context-free tree languages. In
Proc. 2nd Int. Conf. Algebraic Informatics, volume
4728 of LNCS, pages 275–289. Springer.
K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi.
1987. Characterizing structural descriptions produced
by various grammatical formalisms. In Proc. 25th
Ann. Meeting of the Association for Computational
Linguistics, pages 104–111. Association for Compu-
tational Linguistics.
XTAG Research Group. 2001. A lexicalized tree adjoin-
ing grammar for English. Technical Report IRCS-01-
03, University of Pennsylvania, Philadelphia, USA.
Ryo Yoshinaka. 2006. Extensions and Restrictions of
Abstract Categorial Grammars. Ph.D. thesis, Univer-
sity of Tokyo.
</reference>
<page confidence="0.935006">
515
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.187345">
<title confidence="0.994984">Strong Lexicalization of Tree Adjoining Grammars</title>
<affiliation confidence="0.4820235">IMS, Universit¨at Pfaffenwaldring</affiliation>
<address confidence="0.990259">70569 Stuttgart,</address>
<email confidence="0.997934">maletti@ims.uni-stuttgart.de</email>
<affiliation confidence="0.626914">Joost</affiliation>
<address confidence="0.921024333333333">LIACS, Leiden P.O. Box 2300 RA Leiden, The</address>
<email confidence="0.996698">engelfri@liacs.nl</email>
<abstract confidence="0.999134666666667">it was shown Tree-adjoining grammars are not closed unstrong Comput. Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol. A more powerful model, the simple context-free tree grammar, admits such a normal form. It can be effectively constructed and the maximal rank of the nononly increases by Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Franz Baader</author>
<author>Tobias Nipkow</author>
</authors>
<title>Term Rewriting and All That.</title>
<date>1998</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="11387" citStr="Baader and Nipkow, 1998" startWordPosition="2009" endWordPosition="2012">onterminal symbols according to their rank. Moreover, it contains all the variables of Xk exactly once. Let us illustrate the syntax on an example CFTG. We use an abstract language for simplicity and clarity. We use lower-case Greek letters for terminal symbols and upper-case Latin letters for nonterminals. Example 2. As a running example, we consider the CFTG Gex = ({S(0), A(2)}, E, S, P) where • E = {0&apos;(2), α(0), 0(0)} and • P contains the productions (see Figure 3):8 S —* A(α, α) |A(,3,,3) |0&apos;(α, ,3) A(x1, x2) —* A(0&apos;(x1, S), 0&apos;(x2, S)) |0&apos;(x1, x2) . We recall the (term) rewrite semantics (Baader and Nipkow, 1998) of the CFTG G = (N, E, S, P). Since G is simple, the actual rewriting strategy is irrelevant. The sentential forms of G are simply SF(G) = TNUΣ(X). This is slightly more general than necessary (for the semantics of G), but the presence of variables in sentential forms will be useful in the next section because it allows us to treat right-hand sides as sentential forms. In essence in a rewrite step we just select a nonterminal A E N and an A-production p E P. Then we replace an occurrence of A in the sentential form by the right-hand side of p using second-order substitution. Definition 3. Let</context>
</contexts>
<marker>Baader, Nipkow, 1998</marker>
<rawString>Franz Baader and Tobias Nipkow. 1998. Term Rewriting and All That. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yehoshua Bar-Hillel</author>
<author>Haim Gaifman</author>
<author>Eli Shamir</author>
</authors>
<title>On categorial and phrase-structure grammars.</title>
<date>1960</date>
<journal>Bulletin of the Research Council ofIsrael,</journal>
<pages>9--1</pages>
<contexts>
<context position="2573" citStr="Bar-Hillel et al., 1960" startWordPosition="384" endWordPosition="387">y, lexicalized grammars offer significant parsing benefits (Schabes et al., 1988) as the number of applications of productions (i.e., derivation steps) is clearly bounded by the length of the input string. In addition, the lexical items in the productions guide the production selection in a derivation, which works especially well in scenarios with large alphabets.1 The GREIBACH normal form (Hopcroft et al., 2001; Blum and Koch, 1999) offers those benefits for context-free grammars [CFG], but it changes the parse trees. Thus, we distinguish between two notions of equivalence: Weak equivalence (Bar-Hillel et al., 1960) only requires that the generated string languages coincide, whereas strong equivalence (Chomsky, 1963) requires that even the generated tree languages coincide. Correspondingly, we obtain weak and strong lexicalization based on the required equivalence. The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990). It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG (Schabes, 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves. Recently, Kuh</context>
<context position="12677" citStr="Bar-Hillel et al., 1960" startWordPosition="2260" endWordPosition="2263">r in P and an 8We separate several right-hand sides with ‘|’. 508 Figure 3: Productions of Example 2. A-labeled position p ∈ posA(ξ) in ξ, we write ξ ⇒GP ξ[p ← r]. If there exist ρ ∈ P and p ∈ pos(ξ) such that ξ ⇒��P G ζ, then ξ ⇒G ζ.9 The semantics QG� of G is {t ∈ TE |S ⇒G t}, where ⇒G is the reflexive, transitive closure of ⇒G. Two CFTG G1 and G2 are (strongly) equivalent if QG1� = QG2�. In this contribution we are only concerned with strong equivalence (Chomsky, 1963). Although we recall the string corresponding to a tree later on (via its yield), we will not investigate weak equivalence (Bar-Hillel et al., 1960). Example 4. Reconsider the CFTG Gex of Example 2. A derivation to a tree of TE is illustrated in Figure 4. It demonstrates that the final tree in that derivation is in the language QGex� generated by Gex. Finally, let us recall the relation between CFTG and tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975). Joshi et al. (1975) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (M¨onnich, 1997; Fujiyoshi and Kasai, 2000). Kepser and Rogers (2011) show the strong equ</context>
</contexts>
<marker>Bar-Hillel, Gaifman, Shamir, 1960</marker>
<rawString>Yehoshua Bar-Hillel, Haim Gaifman, and Eli Shamir. 1960. On categorial and phrase-structure grammars. Bulletin of the Research Council ofIsrael, 9F(1):1–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Norbert Blum</author>
<author>Robert Koch</author>
</authors>
<title>Greibach normal form transformation revisited.</title>
<date>1999</date>
<journal>Inform. and Comput.,</journal>
<volume>150</volume>
<issue>1</issue>
<contexts>
<context position="2386" citStr="Blum and Koch, 1999" startWordPosition="356" endWordPosition="359">orted by the German Research Foundation (DFG) grant MA 4959 / 1-1. alphabet, each production of a lexicalized grammar produces at least one letter of the generated string. Consequently, lexicalized grammars offer significant parsing benefits (Schabes et al., 1988) as the number of applications of productions (i.e., derivation steps) is clearly bounded by the length of the input string. In addition, the lexical items in the productions guide the production selection in a derivation, which works especially well in scenarios with large alphabets.1 The GREIBACH normal form (Hopcroft et al., 2001; Blum and Koch, 1999) offers those benefits for context-free grammars [CFG], but it changes the parse trees. Thus, we distinguish between two notions of equivalence: Weak equivalence (Bar-Hillel et al., 1960) only requires that the generated string languages coincide, whereas strong equivalence (Chomsky, 1963) requires that even the generated tree languages coincide. Correspondingly, we obtain weak and strong lexicalization based on the required equivalence. The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990). It is a prominent fe</context>
</contexts>
<marker>Blum, Koch, 1999</marker>
<rawString>Norbert Blum and Robert Koch. 1999. Greibach normal form transformation revisited. Inform. and Comput., 150(1):112–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Chen</author>
</authors>
<title>Towards Efficient Statistical Parsing using Lexicalized Grammatical Information.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Delaware,</institution>
<location>Newark, USA.</location>
<contexts>
<context position="3461" citStr="Chen (2001)" startWordPosition="515" endWordPosition="516">rm shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990). It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG (Schabes, 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves. Recently, Kuhlmann and Satta (2012) proved that TAG actually cannot strongly lexicalize themselves. In fact, they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars (Schabes and Waters, 1995). However, TAG can weakly lexicalize themselves (Fujiyoshi, 2005). 1Chen (2001) presents a detailed account. 2Good algorithmic properties and the good coverage of linguistic phenomena are other prominent features. 506 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is c</context>
</contexts>
<marker>Chen, 2001</marker>
<rawString>John Chen. 2001. Towards Efficient Statistical Parsing using Lexicalized Grammatical Information. Ph.D. thesis, University of Delaware, Newark, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Formal properties of grammar. In</title>
<date>1963</date>
<booktitle>Handbook of Mathematical Psychology,</booktitle>
<volume>2</volume>
<pages>323--418</pages>
<editor>R. Duncan Luce, Robert R. Bush, and Eugene Galanter, editors,</editor>
<publisher>John Wiley and Sons, Inc.</publisher>
<contexts>
<context position="2676" citStr="Chomsky, 1963" startWordPosition="400" endWordPosition="401">f productions (i.e., derivation steps) is clearly bounded by the length of the input string. In addition, the lexical items in the productions guide the production selection in a derivation, which works especially well in scenarios with large alphabets.1 The GREIBACH normal form (Hopcroft et al., 2001; Blum and Koch, 1999) offers those benefits for context-free grammars [CFG], but it changes the parse trees. Thus, we distinguish between two notions of equivalence: Weak equivalence (Bar-Hillel et al., 1960) only requires that the generated string languages coincide, whereas strong equivalence (Chomsky, 1963) requires that even the generated tree languages coincide. Correspondingly, we obtain weak and strong lexicalization based on the required equivalence. The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990). It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG (Schabes, 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves. Recently, Kuhlmann and Satta (2012) proved that TAG actually cannot strongly lexicalize themselves. In fact, they pr</context>
<context position="12529" citStr="Chomsky, 1963" startWordPosition="2238" endWordPosition="2239"> right-hand side of p using second-order substitution. Definition 3. Let �, ( E SF(G) be sentential forms. Given an A-production p = f —* r in P and an 8We separate several right-hand sides with ‘|’. 508 Figure 3: Productions of Example 2. A-labeled position p ∈ posA(ξ) in ξ, we write ξ ⇒GP ξ[p ← r]. If there exist ρ ∈ P and p ∈ pos(ξ) such that ξ ⇒��P G ζ, then ξ ⇒G ζ.9 The semantics QG� of G is {t ∈ TE |S ⇒G t}, where ⇒G is the reflexive, transitive closure of ⇒G. Two CFTG G1 and G2 are (strongly) equivalent if QG1� = QG2�. In this contribution we are only concerned with strong equivalence (Chomsky, 1963). Although we recall the string corresponding to a tree later on (via its yield), we will not investigate weak equivalence (Bar-Hillel et al., 1960). Example 4. Reconsider the CFTG Gex of Example 2. A derivation to a tree of TE is illustrated in Figure 4. It demonstrates that the final tree in that derivation is in the language QGex� generated by Gex. Finally, let us recall the relation between CFTG and tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975). Joshi et al. (1975) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monad</context>
</contexts>
<marker>Chomsky, 1963</marker>
<rawString>Noam Chomsky. 1963. Formal properties of grammar. In R. Duncan Luce, Robert R. Bush, and Eugene Galanter, editors, Handbook of Mathematical Psychology, volume 2, pages 323–418. John Wiley and Sons, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joost Engelfriet</author>
<author>Grzegorz Rozenberg</author>
<author>Giora Slutzki</author>
</authors>
<title>Tree transducers, L systems, and two-way machines.</title>
<date>1980</date>
<journal>J. Comput. System Sci.,</journal>
<volume>20</volume>
<issue>2</issue>
<contexts>
<context position="30330" citStr="Engelfriet et al. (1980)" startWordPosition="5569" endWordPosition="5572"> can be replaced by the productions A(x1, x2) → A(σ(x1, Sa(δ)), σ(x2, S)), and then the nonterminals Aa and their productions can be removed, which leaves only 15 productions. Conclusion For k ∈ ICY, let CFTG(k) be the set of those CFTG whose nonterminals have rank at most k. Since the normal form constructions preserve the nonterminal rank, the proof of Theorem 17 shows that CFTG(k) are strongly lexicalized by CFTG(k+1). Kepser and Rogers (2011) show that non-strict TAG are strongly equivalent to CFTG(1). Hence, non-strict TAG are strongly lexicalized by CFTG(2). It follows from Section 6 of Engelfriet et al. (1980) that the classes CFTG(k) with k ∈ ICY induce an infinite hierarchy of string languages, but it remains an open problem whether the rank increase in our lexicalization construction is necessary. G´omez-Rodriguez et al. (2010) show that wellnested LCFRS of maximal fan-out k can be parsed in time O(n2k+2), where n is the length of the input string w ∈ A∗. From this result we conclude that CFTG(k) can be parsed in time O(n2k+4), in the sense that we can produce a parse tree t that is generated by the CFTG with ydΔ(t) = w. It is not clear yet whether lexicalized CFTG(k) can be parsed more efficien</context>
</contexts>
<marker>Engelfriet, Rozenberg, Slutzki, 1980</marker>
<rawString>Joost Engelfriet, Grzegorz Rozenberg, and Giora Slutzki. 1980. Tree transducers, L systems, and two-way machines. J. Comput. System Sci., 20(2):150–202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Fischer</author>
</authors>
<title>Grammars with macro-like productions.</title>
<date>1968</date>
<booktitle>In Proc. 9th Ann. Symp. Switching and Automata Theory,</booktitle>
<pages>131--142</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="4506" citStr="Fischer (1968)" startWordPosition="669" endWordPosition="670">0) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is called non-strict TAG (Kepser and Rogers, 2011). A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (G´ecseg and Steinby, 1984; G´ecseg and Steinby, 1997). CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al. (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al. (1991).3 Thus, CFTG are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (G´omez-Rodr´ıguez et al., 2010). In this contribution, we show that CFTG can strongly lexicalize TAG and also themselves, thus answering the second question in the conclusion of Kuhlmann and Satta (2012). This is achieved by a series of normalization steps</context>
</contexts>
<marker>Fischer, 1968</marker>
<rawString>Michael J. Fischer. 1968. Grammars with macro-like productions. In Proc. 9th Ann. Symp. Switching and Automata Theory, pages 131–142. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akio Fujiyoshi</author>
</authors>
<title>Epsilon-free grammars and lexicalized grammars that generate the class of the mildly context-sensitive languages.</title>
<date>2005</date>
<booktitle>In Proc. 7th Int. Workshop Tree Adjoining Grammar and Related Formalisms,</booktitle>
<pages>16--23</pages>
<contexts>
<context position="3447" citStr="Fujiyoshi, 2005" startWordPosition="513" endWordPosition="514"> GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990). It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG (Schabes, 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves. Recently, Kuhlmann and Satta (2012) proved that TAG actually cannot strongly lexicalize themselves. In fact, they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars (Schabes and Waters, 1995). However, TAG can weakly lexicalize themselves (Fujiyoshi, 2005). 1Chen (2001) presents a detailed account. 2Good algorithmic properties and the good coverage of linguistic phenomena are other prominent features. 506 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic variant is strongly equivalent to a slightly extended version of T</context>
</contexts>
<marker>Fujiyoshi, 2005</marker>
<rawString>Akio Fujiyoshi. 2005. Epsilon-free grammars and lexicalized grammars that generate the class of the mildly context-sensitive languages. In Proc. 7th Int. Workshop Tree Adjoining Grammar and Related Formalisms, pages 16–23.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Akio Fujiyoshi</author>
<author>Takumi Kasai</author>
</authors>
<title>Spinal-formed context-free tree grammars.</title>
<date>2000</date>
<journal>Theory Comput. Syst.,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="13231" citStr="Fujiyoshi and Kasai, 2000" startWordPosition="2357" endWordPosition="2360">eld), we will not investigate weak equivalence (Bar-Hillel et al., 1960). Example 4. Reconsider the CFTG Gex of Example 2. A derivation to a tree of TE is illustrated in Figure 4. It demonstrates that the final tree in that derivation is in the language QGex� generated by Gex. Finally, let us recall the relation between CFTG and tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975). Joshi et al. (1975) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (M¨onnich, 1997; Fujiyoshi and Kasai, 2000). Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG. In general, TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section, we first recall an existing normal form for CFTG. Then we introduce the property of finite ambiguity in the spirit of (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012), which allows us to normalize our CFTG even further. A major tool is a simple production elimination 9For all k E N and � =:�-c C we note that � E CNUr(Xk</context>
</contexts>
<marker>Fujiyoshi, Kasai, 2000</marker>
<rawString>Akio Fujiyoshi and Takumi Kasai. 2000. Spinal-formed context-free tree grammars. Theory Comput. Syst., 33(1):59–83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferenc G´ecseg</author>
<author>Magnus Steinby</author>
</authors>
<title>Tree Automata. Akad´emiai Kiad´o,</title>
<date>1984</date>
<location>Budapest.</location>
<marker>G´ecseg, Steinby, 1984</marker>
<rawString>Ferenc G´ecseg and Magnus Steinby. 1984. Tree Automata. Akad´emiai Kiad´o, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferenc G´ecseg</author>
<author>Magnus Steinby</author>
</authors>
<title>Tree languages.</title>
<date>1997</date>
<booktitle>In Grzegorz Rozenberg and Arto Salomaa, editors, Handbook of Formal Languages,</booktitle>
<volume>3</volume>
<pages>1--68</pages>
<publisher>Springer.</publisher>
<marker>G´ecseg, Steinby, 1997</marker>
<rawString>Ferenc G´ecseg and Magnus Steinby. 1997. Tree languages. In Grzegorz Rozenberg and Arto Salomaa, editors, Handbook of Formal Languages, volume 3, chapter 1, pages 1–68. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Goldstine</author>
<author>Hing Leung</author>
<author>Detlef Wotschke</author>
</authors>
<title>On the relation between ambiguity and nondeterminism in finite automata.</title>
<date>1992</date>
<journal>Inform. and Comput.,</journal>
<volume>100</volume>
<issue>2</issue>
<contexts>
<context position="16028" citStr="Goldstine et al., 1992" startWordPosition="2875" endWordPosition="2878">normal form. We obtain the CFTG G&apos;&apos;ex = ({S&apos;(0), S(0), A(2)}, E, S&apos;, P&apos;&apos;) where P&apos;&apos; contains S&apos; → S and for each δ ∈ {α, β} S → A(δ,δ) |σ(δ,δ) |σ(α,β) (1) A(x1, x2) → A(σ(x1, S), σ(x2, S)) (2) A(x1, x2) → σ(σ(x1, S), σ(x2, S)) . From now on, we assume that G is growing. Next, we recall the notion of finite ambiguity from (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012).11 We distinguish a subset A ⊆ E0 of lexical symbols, which are the symbols that are preserved by the yield mapping. The yield of a tree is 11It should not be confused with the notion of ‘finite ambiguity’ of (Goldstine et al., 1992; Klimann et al., 2004). x1 S x2 S A σ A → σ σ x1 x2 A A α α A β β σ α β → x1 x2 x1 x2 S → S → S → 509 A S A α α α S ⇒G ⇒G σ σ α S ⇒G ⇒G ⇒*G β β A σ σ σ σ σ α σ σ α A A α σ S α σ α A β β α β β β α β α σ Figure 4: Derivation using the CFTG Gex of Example 2. The selected positions are boxed. a string of lexical symbols. All other symbols are simply dropped (in a pre-order traversal). Formally, ydΔ : TΣ → A* is such that for all t = σ(t1, ... , tk) with σ ∈ Ek and t1,...,tk ∈ TΣ � σ ydΔ(t1) ··· ydΔ(tk) if σ ∈ A ydΔ(t) = ydΔ(t1) · · · ydΔ(tk) otherwise. Definition 9. The tree language L ⊆ TΣ has f</context>
</contexts>
<marker>Goldstine, Leung, Wotschke, 1992</marker>
<rawString>Jonathan Goldstine, Hing Leung, and Detlef Wotschke. 1992. On the relation between ambiguity and nondeterminism in finite automata. Inform. and Comput., 100(2):261–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carlos G´omez-Rodriguez</author>
<author>Marco Kuhlmann</author>
<author>Giorgio Satta</author>
</authors>
<title>Efficient parsing of well-nested linear context-free rewriting systems.</title>
<date>2010</date>
<booktitle>In Proc. Ann. Conf. North American Chapter of the ACL,</booktitle>
<pages>276--284</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<marker>G´omez-Rodriguez, Kuhlmann, Satta, 2010</marker>
<rawString>Carlos G´omez-Rodriguez, Marco Kuhlmann, and Giorgio Satta. 2010. Efficient parsing of well-nested linear context-free rewriting systems. In Proc. Ann. Conf. North American Chapter of the ACL, pages 276–284. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hendrik Jan</author>
</authors>
<title>Hoogeboom and Paulien ten Pas.</title>
<date>1997</date>
<journal>Syst.,</journal>
<volume>30</volume>
<issue>4</issue>
<marker>Jan, 1997</marker>
<rawString>Hendrik Jan Hoogeboom and Paulien ten Pas. 1997. Monadic second-order definable text languages. Theory Comput. Syst., 30(4):335–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John E Hopcroft</author>
<author>Rajeev Motwani</author>
<author>Jeffrey D Ullman</author>
</authors>
<title>Introduction to automata theory, languages, and computation. Addison-Wesley series in computer science.</title>
<date>2001</date>
<publisher>Addison Wesley,</publisher>
<note>2nd edition.</note>
<contexts>
<context position="2364" citStr="Hopcroft et al., 2001" startWordPosition="352" endWordPosition="355">ring * Financially supported by the German Research Foundation (DFG) grant MA 4959 / 1-1. alphabet, each production of a lexicalized grammar produces at least one letter of the generated string. Consequently, lexicalized grammars offer significant parsing benefits (Schabes et al., 1988) as the number of applications of productions (i.e., derivation steps) is clearly bounded by the length of the input string. In addition, the lexical items in the productions guide the production selection in a derivation, which works especially well in scenarios with large alphabets.1 The GREIBACH normal form (Hopcroft et al., 2001; Blum and Koch, 1999) offers those benefits for context-free grammars [CFG], but it changes the parse trees. Thus, we distinguish between two notions of equivalence: Weak equivalence (Bar-Hillel et al., 1960) only requires that the generated string languages coincide, whereas strong equivalence (Chomsky, 1963) requires that even the generated tree languages coincide. Correspondingly, we obtain weak and strong lexicalization based on the required equivalence. The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990)</context>
<context position="20061" citStr="Hopcroft et al., 2001" startWordPosition="3672" endWordPosition="3675">step we use our production elimination scheme. The goal is to make sure that non-initial monic productions (i.e., productions of which the right-hand side contains at most one nonterminal) contain at least one lexical symbol. We define the relevant property and then present 510 the construction. A sentential form ξ ∈ SF(G) is monic if |posN(ξ) |≤ 1. The set of all monic sentential forms is denoted by SF≤1(G). A production ` → r is monic if r is monic. The next construction is similar to the simultaneous removal of epsilon-productions A → ε and unit productions A → B for context-free grammars (Hopcroft et al., 2001). Instead of computing the closure under those productions, we compute a closure under non-Alexicalized productions. Theorem 13. If QG� has finite A-ambiguity, then there exists an equivalent CFTG such that all its noninitial monic productions are A-lexicalized. Proof. Without loss of generality, we assume that G is start-separated and growing by Theorem 7. Moreover, we assume that each nonterminal is useful. For every A ∈ N with A =6 S, we compute all monic sentential forms without a lexical symbol that are reachable from A(x1, ... , xk), where k = rk(A). Formally, let °A = {ξ ∈ SF≤1(G) |A(x1</context>
</contexts>
<marker>Hopcroft, Motwani, Ullman, 2001</marker>
<rawString>John E. Hopcroft, Rajeev Motwani, and Jeffrey D. Ullman. 2001. Introduction to automata theory, languages, and computation. Addison-Wesley series in computer science. Addison Wesley, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>S Rao Kosaraju</author>
<author>H Yamada</author>
</authors>
<title>String adjunct grammars.</title>
<date>1969</date>
<booktitle>In Proc. 10th Ann. Symp. Switching and Automata Theory,</booktitle>
<pages>245--262</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="947" citStr="Joshi et al., 1969" startWordPosition="128" endWordPosition="131">djoining grammars are not closed under strong lexicalization. Comput. Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol. A more powerful model, the simple context-free tree grammar, admits such a normal form. It can be effectively constructed and the maximal rank of the nonterminals only increases by 1. Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves. 1 Introduction Tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975) are a mildly context-sensitive grammar formalism that can handle certain nonlocal dependencies (Kuhlmann and Mohl, 2006), which occur in several natural languages. A good overview on TAG, their formal properties, their linguistic motivation, and their applications is presented by Joshi and Schabes (1992) and Joshi and Schabes (1997), in which also strong lexicalization is discussed. In general, lexicalization is the process of transforming a grammar into an equivalent one (potentially expressed in another formalism) such that each production contains a lexical item (or an</context>
<context position="12985" citStr="Joshi et al., 1969" startWordPosition="2316" endWordPosition="2319">ive closure of ⇒G. Two CFTG G1 and G2 are (strongly) equivalent if QG1� = QG2�. In this contribution we are only concerned with strong equivalence (Chomsky, 1963). Although we recall the string corresponding to a tree later on (via its yield), we will not investigate weak equivalence (Bar-Hillel et al., 1960). Example 4. Reconsider the CFTG Gex of Example 2. A derivation to a tree of TE is illustrated in Figure 4. It demonstrates that the final tree in that derivation is in the language QGex� generated by Gex. Finally, let us recall the relation between CFTG and tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975). Joshi et al. (1975) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (M¨onnich, 1997; Fujiyoshi and Kasai, 2000). Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG. In general, TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section, we first recall an existing normal form for CFTG. Then we introduce the property of finite am</context>
</contexts>
<marker>Joshi, Kosaraju, Yamada, 1969</marker>
<rawString>Aravind K. Joshi, S. Rao Kosaraju, and H. Yamada. 1969. String adjunct grammars. In Proc. 10th Ann. Symp. Switching and Automata Theory, pages 245– 262. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Leon S Levy</author>
<author>Masako Takahashi</author>
</authors>
<title>Tree adjunct grammars.</title>
<date>1975</date>
<journal>J. Comput. System Sci.,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="968" citStr="Joshi et al., 1975" startWordPosition="132" endWordPosition="135">e not closed under strong lexicalization. Comput. Linguist., 2012) that finitely ambiguous tree adjoining grammars cannot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol. A more powerful model, the simple context-free tree grammar, admits such a normal form. It can be effectively constructed and the maximal rank of the nonterminals only increases by 1. Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves. 1 Introduction Tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975) are a mildly context-sensitive grammar formalism that can handle certain nonlocal dependencies (Kuhlmann and Mohl, 2006), which occur in several natural languages. A good overview on TAG, their formal properties, their linguistic motivation, and their applications is presented by Joshi and Schabes (1992) and Joshi and Schabes (1997), in which also strong lexicalization is discussed. In general, lexicalization is the process of transforming a grammar into an equivalent one (potentially expressed in another formalism) such that each production contains a lexical item (or anchor). Each productio</context>
<context position="13006" citStr="Joshi et al., 1975" startWordPosition="2320" endWordPosition="2323">wo CFTG G1 and G2 are (strongly) equivalent if QG1� = QG2�. In this contribution we are only concerned with strong equivalence (Chomsky, 1963). Although we recall the string corresponding to a tree later on (via its yield), we will not investigate weak equivalence (Bar-Hillel et al., 1960). Example 4. Reconsider the CFTG Gex of Example 2. A derivation to a tree of TE is illustrated in Figure 4. It demonstrates that the final tree in that derivation is in the language QGex� generated by Gex. Finally, let us recall the relation between CFTG and tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975). Joshi et al. (1975) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (M¨onnich, 1997; Fujiyoshi and Kasai, 2000). Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG. In general, TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section, we first recall an existing normal form for CFTG. Then we introduce the property of finite ambiguity in the spirit</context>
</contexts>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>Aravind K. Joshi, Leon S. Levy, and Masako Takahashi. 1975. Tree adjunct grammars. J. Comput. System Sci., 10(1):136–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Yves Schabes</author>
</authors>
<title>Treeadjoining grammars and lexicalized grammars.</title>
<date>1992</date>
<booktitle>In Maurice Nivat and Andreas Podelski, editors, Tree Automata and Languages.</booktitle>
<publisher>North-Holland.</publisher>
<contexts>
<context position="1274" citStr="Joshi and Schabes (1992)" startWordPosition="178" endWordPosition="181"> grammar, admits such a normal form. It can be effectively constructed and the maximal rank of the nonterminals only increases by 1. Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves. 1 Introduction Tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975) are a mildly context-sensitive grammar formalism that can handle certain nonlocal dependencies (Kuhlmann and Mohl, 2006), which occur in several natural languages. A good overview on TAG, their formal properties, their linguistic motivation, and their applications is presented by Joshi and Schabes (1992) and Joshi and Schabes (1997), in which also strong lexicalization is discussed. In general, lexicalization is the process of transforming a grammar into an equivalent one (potentially expressed in another formalism) such that each production contains a lexical item (or anchor). Each production can then be viewed as lexical information on its anchor. It demonstrates a syntactical construction in which the anchor can occur. Since a lexical item is a letter of the string * Financially supported by the German Research Foundation (DFG) grant MA 4959 / 1-1. alphabet, each production of a lexicalize</context>
<context position="13649" citStr="Joshi and Schabes, 1992" startWordPosition="2427" endWordPosition="2430">) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (M¨onnich, 1997; Fujiyoshi and Kasai, 2000). Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG. In general, TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section, we first recall an existing normal form for CFTG. Then we introduce the property of finite ambiguity in the spirit of (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012), which allows us to normalize our CFTG even further. A major tool is a simple production elimination 9For all k E N and � =:�-c C we note that � E CNUr(Xk) if and only if C E CNur(Xk). 10XTAG Research Group (2001) wrote a TAG for English. scheme, which we present in detail. From now on, let G = (N, E, S, P) be the considered CFTG. The CFTG G is start-separated if posS(r) = ∅ for every production ` → r ∈ P. In other words, the start nonterminal S is not allowed in the right-hand sides of the productions. It is clear that each CFTG can be transformed into an equivalen</context>
<context position="15768" citStr="Joshi and Schabes, 1992" startWordPosition="2826" endWordPosition="2829">xt theorem is Proposition 2 of (Stamer and Otto, 2007). Stamer (2009) provides a full proof. Theorem 7. For every start-separated CFTG there exists an equivalent start-separated, growing CFTG. Example 8. Let us transform the CFTG G&apos;ex of Example 5 into growing normal form. We obtain the CFTG G&apos;&apos;ex = ({S&apos;(0), S(0), A(2)}, E, S&apos;, P&apos;&apos;) where P&apos;&apos; contains S&apos; → S and for each δ ∈ {α, β} S → A(δ,δ) |σ(δ,δ) |σ(α,β) (1) A(x1, x2) → A(σ(x1, S), σ(x2, S)) (2) A(x1, x2) → σ(σ(x1, S), σ(x2, S)) . From now on, we assume that G is growing. Next, we recall the notion of finite ambiguity from (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012).11 We distinguish a subset A ⊆ E0 of lexical symbols, which are the symbols that are preserved by the yield mapping. The yield of a tree is 11It should not be confused with the notion of ‘finite ambiguity’ of (Goldstine et al., 1992; Klimann et al., 2004). x1 S x2 S A σ A → σ σ x1 x2 A A α α A β β σ α β → x1 x2 x1 x2 S → S → S → 509 A S A α α α S ⇒G ⇒G σ σ α S ⇒G ⇒G ⇒*G β β A σ σ σ σ σ α σ σ α A A α σ S α σ α A β β α β β β α β α σ Figure 4: Derivation using the CFTG Gex of Example 2. The selected positions are boxed. a string of lexical symbols. All other symbols ar</context>
<context position="17269" citStr="Joshi and Schabes, 1992" startWordPosition="3161" endWordPosition="3164">if {t ∈ L |ydΔ(t) = w} is finite for every w ∈ A*. Roughly speaking, we can say that the set L has finite A-ambiguity if each w ∈ A* has finitely many parses in L (where t is a parse of w if ydΔ(t) = w). Our example CFTG Gex is such that QGex� has finite {α,β}-ambiguity (because E1 = ∅). In this contribution, we want to (strongly) lexicalize CFTG, which means that for each CFTG G such that QG� has finite A-ambiguity, we want to construct an equivalent CFTG such that each non-initial production contains at least one lexical symbol. This is typically called strong lexicalization (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012) because we require strong equivalence.12 Let us formalize our lexicalization property. Definition 10. The production ` → r is A-lexicalized if posΔ(r) =6 ∅. The CFTG G is A-lexicalized if all its non-initial productions are A-lexicalized. Note that the CFTG G&apos;&apos;ex of Example 8 is not yet {α, β}-lexicalized. We will lexicalize it in the next section. To do this in general, we need some auxiliary normal forms. First, we define our simple production elimination scheme, which we will use in the following. Roughly speaking, a non-initial Aproduction such that A does not o</context>
</contexts>
<marker>Joshi, Schabes, 1992</marker>
<rawString>Aravind K. Joshi and Yves Schabes. 1992. Treeadjoining grammars and lexicalized grammars. In Maurice Nivat and Andreas Podelski, editors, Tree Automata and Languages. North-Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aravind K Joshi</author>
<author>Yves Schabes</author>
</authors>
<title>Treeadjoining grammars.</title>
<date>1997</date>
<booktitle>In Grzegorz Rozenberg and Arto Salomaa, editors, Beyond Words,</booktitle>
<volume>3</volume>
<pages>69--123</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="1303" citStr="Joshi and Schabes (1997)" startWordPosition="183" endWordPosition="186">l form. It can be effectively constructed and the maximal rank of the nonterminals only increases by 1. Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves. 1 Introduction Tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975) are a mildly context-sensitive grammar formalism that can handle certain nonlocal dependencies (Kuhlmann and Mohl, 2006), which occur in several natural languages. A good overview on TAG, their formal properties, their linguistic motivation, and their applications is presented by Joshi and Schabes (1992) and Joshi and Schabes (1997), in which also strong lexicalization is discussed. In general, lexicalization is the process of transforming a grammar into an equivalent one (potentially expressed in another formalism) such that each production contains a lexical item (or anchor). Each production can then be viewed as lexical information on its anchor. It demonstrates a syntactical construction in which the anchor can occur. Since a lexical item is a letter of the string * Financially supported by the German Research Foundation (DFG) grant MA 4959 / 1-1. alphabet, each production of a lexicalized grammar produces at least o</context>
</contexts>
<marker>Joshi, Schabes, 1997</marker>
<rawString>Aravind K. Joshi and Yves Schabes. 1997. Treeadjoining grammars. In Grzegorz Rozenberg and Arto Salomaa, editors, Beyond Words, volume 3 of Handbook of Formal Languages, pages 69–123. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Kanazawa</author>
</authors>
<title>The convergence of wellnested mildly context-sensitive grammar formalisms. Invited talk at the 14th Int. Conf. Formal Grammar. slides available at: research.nii.ac.jp/ ˜kanazawa.</title>
<date>2009</date>
<contexts>
<context position="5984" citStr="Kanazawa (2009)" startWordPosition="916" endWordPosition="917">al production. The lexicalization is effective and increases the maximal rank (number of arguments) of the nonterminals by at most 1. In contrast to a transformation into GREIBACH normal form, our lexicalization does not radically change the structure of the derivations. Overall, our result shows that if we consider only lexicalization, then CFTG are a more natural generalization of CFG than TAG. 2 Notation We write [k] for the set {i E N |1 G i G k}, where N denotes the set of nonnegative integers. We use a fixed countably infinite set X = {x1, x2,... } 3Kuhlmann (2010), M¨onnich (2010), and Kanazawa (2009) discuss well-nestedness. of (mutually distinguishable) variables, and we let Xk = {xi |i E [k]} be the first k variables from X for every k E N. As usual, an alphabet E is a finite set of symbols, and a ranked alphabet (E, rk) adds a ranking rk: E —* N. We let Ek = {σ |rk(σ) = k} be the set of k-ary symbols. Moreover, we just write E for the ranked alphabet (E, rk).4 We build trees over the ranked alphabet E such that the nodes are labeled by elements of E and the rank of the node label determines the number of its children. In addition, elements of X can label leaves. Formally, the set TΣ(X)</context>
</contexts>
<marker>Kanazawa, 2009</marker>
<rawString>Makoto Kanazawa. 2009. The convergence of wellnested mildly context-sensitive grammar formalisms. Invited talk at the 14th Int. Conf. Formal Grammar. slides available at: research.nii.ac.jp/ ˜kanazawa.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Makoto Kanazawa</author>
<author>Ryo Yoshinaka</author>
</authors>
<title>Lexicalization of second-order ACGs.</title>
<date>2005</date>
<tech>Technical Report NII2005-012E,</tech>
<institution>National Institute of Informatics,</institution>
<location>Tokyo, Japan.</location>
<contexts>
<context position="4253" citStr="Kanazawa and Yoshinaka (2005)" startWordPosition="629" endWordPosition="632">Annual Meeting of the Association for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is called non-strict TAG (Kepser and Rogers, 2011). A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (G´ecseg and Steinby, 1984; G´ecseg and Steinby, 1997). CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al. (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al. (1991).3 Thus, CFTG are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (G´o</context>
</contexts>
<marker>Kanazawa, Yoshinaka, 2005</marker>
<rawString>Makoto Kanazawa and Ryo Yoshinaka. 2005. Lexicalization of second-order ACGs. Technical Report NII2005-012E, National Institute of Informatics, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Kepser</author>
<author>James Rogers</author>
</authors>
<title>The equivalence of tree adjoining grammars and monadic linear context-free tree grammars.</title>
<date>2011</date>
<journal>J. Log. Lang. Inf.,</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="4107" citStr="Kepser and Rogers, 2011" startWordPosition="607" endWordPosition="610">ccount. 2Good algorithmic properties and the good coverage of linguistic phenomena are other prominent features. 506 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is called non-strict TAG (Kepser and Rogers, 2011). A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (G´ecseg and Steinby, 1984; G´ecseg and Steinby, 1997). CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al. (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al.</context>
<context position="13091" citStr="Kepser and Rogers, 2011" startWordPosition="2335" endWordPosition="2338"> we are only concerned with strong equivalence (Chomsky, 1963). Although we recall the string corresponding to a tree later on (via its yield), we will not investigate weak equivalence (Bar-Hillel et al., 1960). Example 4. Reconsider the CFTG Gex of Example 2. A derivation to a tree of TE is illustrated in Figure 4. It demonstrates that the final tree in that derivation is in the language QGex� generated by Gex. Finally, let us recall the relation between CFTG and tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975). Joshi et al. (1975) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (M¨onnich, 1997; Fujiyoshi and Kasai, 2000). Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG. In general, TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section, we first recall an existing normal form for CFTG. Then we introduce the property of finite ambiguity in the spirit of (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012), which allows </context>
<context position="30156" citStr="Kepser and Rogers (2011)" startWordPosition="5542" endWordPosition="5545">nstruction as indicated before this example, then all the productions Sa(x1) → Aa(δ0, δ0, x1) are replaced by the productions Sa(x1) → A(x1, δ). Moreover, the productions (5) can be replaced by the productions A(x1, x2) → A(σ(x1, Sa(δ)), σ(x2, S)), and then the nonterminals Aa and their productions can be removed, which leaves only 15 productions. Conclusion For k ∈ ICY, let CFTG(k) be the set of those CFTG whose nonterminals have rank at most k. Since the normal form constructions preserve the nonterminal rank, the proof of Theorem 17 shows that CFTG(k) are strongly lexicalized by CFTG(k+1). Kepser and Rogers (2011) show that non-strict TAG are strongly equivalent to CFTG(1). Hence, non-strict TAG are strongly lexicalized by CFTG(2). It follows from Section 6 of Engelfriet et al. (1980) that the classes CFTG(k) with k ∈ ICY induce an infinite hierarchy of string languages, but it remains an open problem whether the rank increase in our lexicalization construction is necessary. G´omez-Rodriguez et al. (2010) show that wellnested LCFRS of maximal fan-out k can be parsed in time O(n2k+2), where n is the length of the input string w ∈ A∗. From this result we conclude that CFTG(k) can be parsed in time O(n2k+</context>
</contexts>
<marker>Kepser, Rogers, 2011</marker>
<rawString>Stephan Kepser and James Rogers. 2011. The equivalence of tree adjoining grammars and monadic linear context-free tree grammars. J. Log. Lang. Inf., 20(3):361–384.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ines Klimann</author>
<author>Sylvain Lombardy</author>
<author>Jean Mairesse</author>
<author>Christophe Prieur</author>
</authors>
<title>Deciding unambiguity and sequentiality from a finitely ambiguous max-plus automaton.</title>
<date>2004</date>
<journal>Theoret. Comput. Sci.,</journal>
<volume>327</volume>
<issue>3</issue>
<contexts>
<context position="16051" citStr="Klimann et al., 2004" startWordPosition="2879" endWordPosition="2882">he CFTG G&apos;&apos;ex = ({S&apos;(0), S(0), A(2)}, E, S&apos;, P&apos;&apos;) where P&apos;&apos; contains S&apos; → S and for each δ ∈ {α, β} S → A(δ,δ) |σ(δ,δ) |σ(α,β) (1) A(x1, x2) → A(σ(x1, S), σ(x2, S)) (2) A(x1, x2) → σ(σ(x1, S), σ(x2, S)) . From now on, we assume that G is growing. Next, we recall the notion of finite ambiguity from (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012).11 We distinguish a subset A ⊆ E0 of lexical symbols, which are the symbols that are preserved by the yield mapping. The yield of a tree is 11It should not be confused with the notion of ‘finite ambiguity’ of (Goldstine et al., 1992; Klimann et al., 2004). x1 S x2 S A σ A → σ σ x1 x2 A A α α A β β σ α β → x1 x2 x1 x2 S → S → S → 509 A S A α α α S ⇒G ⇒G σ σ α S ⇒G ⇒G ⇒*G β β A σ σ σ σ σ α σ σ α A A α σ S α σ α A β β α β β β α β α σ Figure 4: Derivation using the CFTG Gex of Example 2. The selected positions are boxed. a string of lexical symbols. All other symbols are simply dropped (in a pre-order traversal). Formally, ydΔ : TΣ → A* is such that for all t = σ(t1, ... , tk) with σ ∈ Ek and t1,...,tk ∈ TΣ � σ ydΔ(t1) ··· ydΔ(tk) if σ ∈ A ydΔ(t) = ydΔ(t1) · · · ydΔ(tk) otherwise. Definition 9. The tree language L ⊆ TΣ has finite A-ambiguity if {t</context>
</contexts>
<marker>Klimann, Lombardy, Mairesse, Prieur, 2004</marker>
<rawString>Ines Klimann, Sylvain Lombardy, Jean Mairesse, and Christophe Prieur. 2004. Deciding unambiguity and sequentiality from a finitely ambiguous max-plus automaton. Theoret. Comput. Sci., 327(3):349–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
</authors>
<title>Dependency Structures and Lexicalized Grammars: An Algebraic Approach,</title>
<date>2010</date>
<volume>6270</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="5946" citStr="Kuhlmann (2010)" startWordPosition="911" endWordPosition="912">xchanged for the same item in a terminal production. The lexicalization is effective and increases the maximal rank (number of arguments) of the nonterminals by at most 1. In contrast to a transformation into GREIBACH normal form, our lexicalization does not radically change the structure of the derivations. Overall, our result shows that if we consider only lexicalization, then CFTG are a more natural generalization of CFG than TAG. 2 Notation We write [k] for the set {i E N |1 G i G k}, where N denotes the set of nonnegative integers. We use a fixed countably infinite set X = {x1, x2,... } 3Kuhlmann (2010), M¨onnich (2010), and Kanazawa (2009) discuss well-nestedness. of (mutually distinguishable) variables, and we let Xk = {xi |i E [k]} be the first k variables from X for every k E N. As usual, an alphabet E is a finite set of symbols, and a ranked alphabet (E, rk) adds a ranking rk: E —* N. We let Ek = {σ |rk(σ) = k} be the set of k-ary symbols. Moreover, we just write E for the ranked alphabet (E, rk).4 We build trees over the ranked alphabet E such that the nodes are labeled by elements of E and the rank of the node label determines the number of its children. In addition, elements of X can</context>
</contexts>
<marker>Kuhlmann, 2010</marker>
<rawString>Marco Kuhlmann. 2010. Dependency Structures and Lexicalized Grammars: An Algebraic Approach, volume 6270 of LNAI. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Mathias Mohl</author>
</authors>
<title>Extended cross-serial dependencies in tree adjoining grammars.</title>
<date>2006</date>
<booktitle>In Proc. 8th Int. Workshop Tree Adjoining Grammars and Related Formalisms,</booktitle>
<pages>121--126</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="1089" citStr="Kuhlmann and Mohl, 2006" startWordPosition="149" endWordPosition="152">annot be transformed into a normal form (preserving the generated tree language), in which each production contains a lexical symbol. A more powerful model, the simple context-free tree grammar, admits such a normal form. It can be effectively constructed and the maximal rank of the nonterminals only increases by 1. Thus, simple context-free tree grammars strongly lexicalize tree adjoining grammars and themselves. 1 Introduction Tree adjoining grammars [TAG] (Joshi et al., 1969; Joshi et al., 1975) are a mildly context-sensitive grammar formalism that can handle certain nonlocal dependencies (Kuhlmann and Mohl, 2006), which occur in several natural languages. A good overview on TAG, their formal properties, their linguistic motivation, and their applications is presented by Joshi and Schabes (1992) and Joshi and Schabes (1997), in which also strong lexicalization is discussed. In general, lexicalization is the process of transforming a grammar into an equivalent one (potentially expressed in another formalism) such that each production contains a lexical item (or anchor). Each production can then be viewed as lexical information on its anchor. It demonstrates a syntactical construction in which the anchor</context>
</contexts>
<marker>Kuhlmann, Mohl, 2006</marker>
<rawString>Marco Kuhlmann and Mathias Mohl. 2006. Extended cross-serial dependencies in tree adjoining grammars. In Proc. 8th Int. Workshop Tree Adjoining Grammars and Related Formalisms, pages 121–126. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Giorgio Satta</author>
</authors>
<title>Treeadjoining grammars are not closed under strong lexicalization.</title>
<date>2012</date>
<journal>Comput. Linguist.</journal>
<note>available at: dx.doi. org/10.1162/COLI_a_00090.</note>
<contexts>
<context position="3195" citStr="Kuhlmann and Satta (2012)" startWordPosition="474" endWordPosition="477">60) only requires that the generated string languages coincide, whereas strong equivalence (Chomsky, 1963) requires that even the generated tree languages coincide. Correspondingly, we obtain weak and strong lexicalization based on the required equivalence. The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990). It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG (Schabes, 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves. Recently, Kuhlmann and Satta (2012) proved that TAG actually cannot strongly lexicalize themselves. In fact, they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars (Schabes and Waters, 1995). However, TAG can weakly lexicalize themselves (Fujiyoshi, 2005). 1Chen (2001) presents a detailed account. 2Good algorithmic properties and the good coverage of linguistic phenomena are other prominent features. 506 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics S</context>
<context position="5053" citStr="Kuhlmann and Satta (2012)" startWordPosition="749" endWordPosition="752">97). CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al. (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al. (1991).3 Thus, CFTG are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (G´omez-Rodr´ıguez et al., 2010). In this contribution, we show that CFTG can strongly lexicalize TAG and also themselves, thus answering the second question in the conclusion of Kuhlmann and Satta (2012). This is achieved by a series of normalization steps (see Section 4) and a final lexicalization step (see Section 5), in which a lexical item is guessed for each production that does not already contain one. This item is then transported in an additional argument until it is exchanged for the same item in a terminal production. The lexicalization is effective and increases the maximal rank (number of arguments) of the nonterminals by at most 1. In contrast to a transformation into GREIBACH normal form, our lexicalization does not radically change the structure of the derivations. Overall, our</context>
<context position="13676" citStr="Kuhlmann and Satta, 2012" startWordPosition="2431" endWordPosition="2434">al footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (M¨onnich, 1997; Fujiyoshi and Kasai, 2000). Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG. In general, TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section, we first recall an existing normal form for CFTG. Then we introduce the property of finite ambiguity in the spirit of (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012), which allows us to normalize our CFTG even further. A major tool is a simple production elimination 9For all k E N and � =:�-c C we note that � E CNUr(Xk) if and only if C E CNur(Xk). 10XTAG Research Group (2001) wrote a TAG for English. scheme, which we present in detail. From now on, let G = (N, E, S, P) be the considered CFTG. The CFTG G is start-separated if posS(r) = ∅ for every production ` → r ∈ P. In other words, the start nonterminal S is not allowed in the right-hand sides of the productions. It is clear that each CFTG can be transformed into an equivalent start-separated CFTG. In </context>
<context position="15795" citStr="Kuhlmann and Satta, 2012" startWordPosition="2830" endWordPosition="2833"> 2 of (Stamer and Otto, 2007). Stamer (2009) provides a full proof. Theorem 7. For every start-separated CFTG there exists an equivalent start-separated, growing CFTG. Example 8. Let us transform the CFTG G&apos;ex of Example 5 into growing normal form. We obtain the CFTG G&apos;&apos;ex = ({S&apos;(0), S(0), A(2)}, E, S&apos;, P&apos;&apos;) where P&apos;&apos; contains S&apos; → S and for each δ ∈ {α, β} S → A(δ,δ) |σ(δ,δ) |σ(α,β) (1) A(x1, x2) → A(σ(x1, S), σ(x2, S)) (2) A(x1, x2) → σ(σ(x1, S), σ(x2, S)) . From now on, we assume that G is growing. Next, we recall the notion of finite ambiguity from (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012).11 We distinguish a subset A ⊆ E0 of lexical symbols, which are the symbols that are preserved by the yield mapping. The yield of a tree is 11It should not be confused with the notion of ‘finite ambiguity’ of (Goldstine et al., 1992; Klimann et al., 2004). x1 S x2 S A σ A → σ σ x1 x2 A A α α A β β σ α β → x1 x2 x1 x2 S → S → S → 509 A S A α α α S ⇒G ⇒G σ σ α S ⇒G ⇒G ⇒*G β β A σ σ σ σ σ α σ σ α A A α σ S α σ α A β β α β β β α β α σ Figure 4: Derivation using the CFTG Gex of Example 2. The selected positions are boxed. a string of lexical symbols. All other symbols are simply dropped (in a pre-</context>
<context position="17296" citStr="Kuhlmann and Satta, 2012" startWordPosition="3165" endWordPosition="3168"> finite for every w ∈ A*. Roughly speaking, we can say that the set L has finite A-ambiguity if each w ∈ A* has finitely many parses in L (where t is a parse of w if ydΔ(t) = w). Our example CFTG Gex is such that QGex� has finite {α,β}-ambiguity (because E1 = ∅). In this contribution, we want to (strongly) lexicalize CFTG, which means that for each CFTG G such that QG� has finite A-ambiguity, we want to construct an equivalent CFTG such that each non-initial production contains at least one lexical symbol. This is typically called strong lexicalization (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012) because we require strong equivalence.12 Let us formalize our lexicalization property. Definition 10. The production ` → r is A-lexicalized if posΔ(r) =6 ∅. The CFTG G is A-lexicalized if all its non-initial productions are A-lexicalized. Note that the CFTG G&apos;&apos;ex of Example 8 is not yet {α, β}-lexicalized. We will lexicalize it in the next section. To do this in general, we need some auxiliary normal forms. First, we define our simple production elimination scheme, which we will use in the following. Roughly speaking, a non-initial Aproduction such that A does not occur in its righthand side </context>
</contexts>
<marker>Kuhlmann, Satta, 2012</marker>
<rawString>Marco Kuhlmann and Giorgio Satta. 2012. Treeadjoining grammars are not closed under strong lexicalization. Comput. Linguist. available at: dx.doi. org/10.1162/COLI_a_00090.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uwe M¨onnich</author>
</authors>
<title>Adjunction as substitution: An algebraic formulation of regular, context-free and tree adjoining languages.</title>
<date>1997</date>
<booktitle>In Proc. 3rd Int. Conf. Formal Grammar,</booktitle>
<pages>169--178</pages>
<marker>M¨onnich, 1997</marker>
<rawString>Uwe M¨onnich. 1997. Adjunction as substitution: An algebraic formulation of regular, context-free and tree adjoining languages. In Proc. 3rd Int. Conf. Formal Grammar, pages 169–178. Universit´e de Provence, France. available at: arxiv.org/abs/cmp-lg/ 9707012v1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Uwe M¨onnich</author>
</authors>
<title>Well-nested tree languages and attributed tree transducers.</title>
<date>2010</date>
<booktitle>In Proc. 10th Int. Conf. Tree</booktitle>
<pages>2--10</pages>
<marker>M¨onnich, 2010</marker>
<rawString>Uwe M¨onnich. 2010. Well-nested tree languages and attributed tree transducers. In Proc. 10th Int. Conf. Tree Adjoining Grammars and Related Formalisms. Yale University. available at: www2.research.att. com/˜srini/TAG+10/papers/uwe.pdf.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Potthoff</author>
<author>Wolfgang Thomas</author>
</authors>
<title>Regular tree languages without unary symbols are starfree.</title>
<date>1993</date>
<booktitle>In Proc. 9th Int. Symp. Fundamentals of Computation Theory,</booktitle>
<volume>710</volume>
<pages>396--405</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="25672" citStr="Potthoff and Thomas, 1993" startWordPosition="4690" endWordPosition="4693">each non-Δ-lexicalized production. The guessed symbol is put into a new parameter of a nonterminal. It will be kept in the parameter until we reach a terminal production, where we exchange the same lexical symbol by the parameter. This is the reason why we made sure that we have two occurrences of lexical symbols in the terminal productions. After we exchanged one for a parameter, the resulting terminal production is still Δ-lexicalized. Lexical items that are guessed for distinct (occurrences of) productions are transported to distinct (occurrences of) terminal productions [cf. Section 3 of (Potthoff and Thomas, 1993) and page 346 of (Hoogeboom and ten Pas, 1997)]. Theorem 17. For every CFTG G such that QG� has finite Δ-ambiguity there exists an equivalent Δ-lexicalized CFTG. Proof. We can assume that G = (N, Σ, S, P) has the properties mentioned before the theorem without loss of generality. We let N&apos; = N x Δ be a new set of nonterminals such that rk((A, δ)) = rk(A) + 1 for every A E N and δ E Δ. Intuitively, (A, δ) represents the nonterminal A, which has the lexical symbol δ in its last (new) parameter. This parameter is handed to the (lexicographically) first nonterminal in the right-hand side until it </context>
</contexts>
<marker>Potthoff, Thomas, 1993</marker>
<rawString>Andreas Potthoff and Wolfgang Thomas. 1993. Regular tree languages without unary symbols are starfree. In Proc. 9th Int. Symp. Fundamentals of Computation Theory, volume 710 of LNCS, pages 396–405. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Rounds</author>
</authors>
<title>Context-free grammars on trees.</title>
<date>1969</date>
<booktitle>In Proc. 1st ACM Symp. Theory of Comput.,</booktitle>
<pages>143--148</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3879" citStr="Rounds, 1969" startWordPosition="572" endWordPosition="573">, they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars (Schabes and Waters, 1995). However, TAG can weakly lexicalize themselves (Fujiyoshi, 2005). 1Chen (2001) presents a detailed account. 2Good algorithmic properties and the good coverage of linguistic phenomena are other prominent features. 506 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is called non-strict TAG (Kepser and Rogers, 2011). A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (G´ecseg and Steinby, 1984; G´ecseg and Steinby, 1997). CFTG are weakly equivalent to the simple macro</context>
<context position="9470" citStr="Rounds, 1969" startWordPosition="1654" endWordPosition="1655">tree at position p by the tree u into which the children of p are (firstorder) substituted. In essence, u is “folded” into t at position p. Formally, t[p +— u] = t[u[t|1, ... , t|k]] p. Given P C_ posa(t) with 0&apos; E Ek, we let t[P +— u] be t[p1 +— u] • • • [p,,, +— u], where P = {p1, ... , p,,,} and p1 &gt; ••• &gt; p,,, in the lexicographic order. Second-order substitution is illustrated in Figure 2. G´ecseg and Steinby (1997) present a detailed introduction to trees and tree languages. 3 Context-free tree grammars In this section, we recall linear and nondeleting context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970). The property ‘linear and nondeleting’ is often called ‘simple’. The nonterminals of regular tree grammars only occur at the leaves and are replaced using first-order substitution. In contrast, the nonterminals of a CFTG are ranked symbols, can occur anywhere in a tree, and are replaced using second-order substitution.6 Consequently, the nonterminals N of a CFTG form a ranked alphabet. In the left-hand sides of productions we write A(x1, ... , xk) for a nonterminal A E Nk to indicate the variables that hold the direct subtrees of a particular occurrence of A. Definition 1. A (s</context>
</contexts>
<marker>Rounds, 1969</marker>
<rawString>William C. Rounds. 1969. Context-free grammars on trees. In Proc. 1st ACM Symp. Theory of Comput., pages 143–148. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Rounds</author>
</authors>
<title>Tree-oriented proofs of some theorems on context-free and indexed languages.</title>
<date>1970</date>
<booktitle>In Proc. 2nd ACM Symp. Theory of Comput.,</booktitle>
<pages>109--116</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="3894" citStr="Rounds, 1970" startWordPosition="574" endWordPosition="575">hat TAG cannot even strongly lexicalize the weaker tree insertion grammars (Schabes and Waters, 1995). However, TAG can weakly lexicalize themselves (Fujiyoshi, 2005). 1Chen (2001) presents a detailed account. 2Good algorithmic properties and the good coverage of linguistic phenomena are other prominent features. 506 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is called non-strict TAG (Kepser and Rogers, 2011). A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (G´ecseg and Steinby, 1984; G´ecseg and Steinby, 1997). CFTG are weakly equivalent to the simple macro grammars of Fi</context>
<context position="9485" citStr="Rounds, 1970" startWordPosition="1656" endWordPosition="1657">on p by the tree u into which the children of p are (firstorder) substituted. In essence, u is “folded” into t at position p. Formally, t[p +— u] = t[u[t|1, ... , t|k]] p. Given P C_ posa(t) with 0&apos; E Ek, we let t[P +— u] be t[p1 +— u] • • • [p,,, +— u], where P = {p1, ... , p,,,} and p1 &gt; ••• &gt; p,,, in the lexicographic order. Second-order substitution is illustrated in Figure 2. G´ecseg and Steinby (1997) present a detailed introduction to trees and tree languages. 3 Context-free tree grammars In this section, we recall linear and nondeleting context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970). The property ‘linear and nondeleting’ is often called ‘simple’. The nonterminals of regular tree grammars only occur at the leaves and are replaced using first-order substitution. In contrast, the nonterminals of a CFTG are ranked symbols, can occur anywhere in a tree, and are replaced using second-order substitution.6 Consequently, the nonterminals N of a CFTG form a ranked alphabet. In the left-hand sides of productions we write A(x1, ... , xk) for a nonterminal A E Nk to indicate the variables that hold the direct subtrees of a particular occurrence of A. Definition 1. A (simple) context-</context>
</contexts>
<marker>Rounds, 1970</marker>
<rawString>William C. Rounds. 1970. Tree-oriented proofs of some theorems on context-free and indexed languages. In Proc. 2nd ACM Symp. Theory of Comput., pages 109– 116. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
</authors>
<title>Mathematical and Computational Aspects of Lexicalized Grammars.</title>
<date>1990</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, USA.</location>
<contexts>
<context position="2964" citStr="Schabes, 1990" startWordPosition="441" endWordPosition="442">t et al., 2001; Blum and Koch, 1999) offers those benefits for context-free grammars [CFG], but it changes the parse trees. Thus, we distinguish between two notions of equivalence: Weak equivalence (Bar-Hillel et al., 1960) only requires that the generated string languages coincide, whereas strong equivalence (Chomsky, 1963) requires that even the generated tree languages coincide. Correspondingly, we obtain weak and strong lexicalization based on the required equivalence. The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990). It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG (Schabes, 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves. Recently, Kuhlmann and Satta (2012) proved that TAG actually cannot strongly lexicalize themselves. In fact, they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars (Schabes and Waters, 1995). However, TAG can weakly lexicalize themselves (Fujiyoshi, 2005). 1Chen (2001) presents a detailed account. 2Good algorithmic properties and the good coverage of linguistic phenomen</context>
<context position="13624" citStr="Schabes, 1990" startWordPosition="2425" endWordPosition="2426">hi et al. (1975) show that TAG are special footed CFTG (Kepser and Rogers, 2011), which are weakly equivalent to monadic CFTG, i.e., CFTG whose nonterminals have rank at most 1 (M¨onnich, 1997; Fujiyoshi and Kasai, 2000). Kepser and Rogers (2011) show the strong equivalence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG. In general, TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section, we first recall an existing normal form for CFTG. Then we introduce the property of finite ambiguity in the spirit of (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012), which allows us to normalize our CFTG even further. A major tool is a simple production elimination 9For all k E N and � =:�-c C we note that � E CNUr(Xk) if and only if C E CNur(Xk). 10XTAG Research Group (2001) wrote a TAG for English. scheme, which we present in detail. From now on, let G = (N, E, S, P) be the considered CFTG. The CFTG G is start-separated if posS(r) = ∅ for every production ` → r ∈ P. In other words, the start nonterminal S is not allowed in the right-hand sides of the productions. It is clear that each CFTG can be tran</context>
<context position="15743" citStr="Schabes, 1990" startWordPosition="2823" endWordPosition="2825">growing. The next theorem is Proposition 2 of (Stamer and Otto, 2007). Stamer (2009) provides a full proof. Theorem 7. For every start-separated CFTG there exists an equivalent start-separated, growing CFTG. Example 8. Let us transform the CFTG G&apos;ex of Example 5 into growing normal form. We obtain the CFTG G&apos;&apos;ex = ({S&apos;(0), S(0), A(2)}, E, S&apos;, P&apos;&apos;) where P&apos;&apos; contains S&apos; → S and for each δ ∈ {α, β} S → A(δ,δ) |σ(δ,δ) |σ(α,β) (1) A(x1, x2) → A(σ(x1, S), σ(x2, S)) (2) A(x1, x2) → σ(σ(x1, S), σ(x2, S)) . From now on, we assume that G is growing. Next, we recall the notion of finite ambiguity from (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012).11 We distinguish a subset A ⊆ E0 of lexical symbols, which are the symbols that are preserved by the yield mapping. The yield of a tree is 11It should not be confused with the notion of ‘finite ambiguity’ of (Goldstine et al., 1992; Klimann et al., 2004). x1 S x2 S A σ A → σ σ x1 x2 A A α α A β β σ α β → x1 x2 x1 x2 S → S → S → 509 A S A α α α S ⇒G ⇒G σ σ α S ⇒G ⇒G ⇒*G β β A σ σ σ σ σ α σ σ α A A α σ S α σ α A β β α β β β α β α σ Figure 4: Derivation using the CFTG Gex of Example 2. The selected positions are boxed. a string of lexical symb</context>
<context position="17244" citStr="Schabes, 1990" startWordPosition="3158" endWordPosition="3160">te A-ambiguity if {t ∈ L |ydΔ(t) = w} is finite for every w ∈ A*. Roughly speaking, we can say that the set L has finite A-ambiguity if each w ∈ A* has finitely many parses in L (where t is a parse of w if ydΔ(t) = w). Our example CFTG Gex is such that QGex� has finite {α,β}-ambiguity (because E1 = ∅). In this contribution, we want to (strongly) lexicalize CFTG, which means that for each CFTG G such that QG� has finite A-ambiguity, we want to construct an equivalent CFTG such that each non-initial production contains at least one lexical symbol. This is typically called strong lexicalization (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012) because we require strong equivalence.12 Let us formalize our lexicalization property. Definition 10. The production ` → r is A-lexicalized if posΔ(r) =6 ∅. The CFTG G is A-lexicalized if all its non-initial productions are A-lexicalized. Note that the CFTG G&apos;&apos;ex of Example 8 is not yet {α, β}-lexicalized. We will lexicalize it in the next section. To do this in general, we need some auxiliary normal forms. First, we define our simple production elimination scheme, which we will use in the following. Roughly speaking, a non-initial Aproducti</context>
</contexts>
<marker>Schabes, 1990</marker>
<rawString>Yves Schabes. 1990. Mathematical and Computational Aspects of Lexicalized Grammars. Ph.D. thesis, University of Pennsylvania, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Anne Abeill´e</author>
<author>Aravind K Joshi</author>
</authors>
<title>Parsing strategies with ‘lexicalized’ grammars: Application to tree adjoining grammars.</title>
<date>1988</date>
<booktitle>In Proc. 12th Int. Conf. Computational Linguistics,</booktitle>
<pages>578--583</pages>
<institution>John von Neumann Society for Computing Sciences,</institution>
<location>Budapest.</location>
<marker>Schabes, Abeill´e, Joshi, 1988</marker>
<rawString>Yves Schabes, Anne Abeill´e, and Aravind K. Joshi. 1988. Parsing strategies with ‘lexicalized’ grammars: Application to tree adjoining grammars. In Proc. 12th Int. Conf. Computational Linguistics, pages 578–583. John von Neumann Society for Computing Sciences, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Schabes</author>
<author>Richard C Waters</author>
</authors>
<title>Tree insertion grammar: A cubic-time parsable formalism that lexicalizes context-free grammars without changing the trees produced.</title>
<date>1995</date>
<journal>Comput. Linguist.,</journal>
<volume>21</volume>
<issue>4</issue>
<pages>513</pages>
<contexts>
<context position="3382" citStr="Schabes and Waters, 1995" startWordPosition="502" endWordPosition="506">tain weak and strong lexicalization based on the required equivalence. The GREIBACH normal form shows that CFG can weakly lexicalize themselves, but they cannot strongly lexicalize themselves (Schabes, 1990). It is a prominent feature of tree adjoining grammars that they can strongly lexicalize CFG (Schabes, 1990),2 and it was claimed and widely believed that they can strongly lexicalize themselves. Recently, Kuhlmann and Satta (2012) proved that TAG actually cannot strongly lexicalize themselves. In fact, they prove that TAG cannot even strongly lexicalize the weaker tree insertion grammars (Schabes and Waters, 1995). However, TAG can weakly lexicalize themselves (Fujiyoshi, 2005). 1Chen (2001) presents a detailed account. 2Good algorithmic properties and the good coverage of linguistic phenomena are other prominent features. 506 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic v</context>
</contexts>
<marker>Schabes, Waters, 1995</marker>
<rawString>Yves Schabes and Richard C. Waters. 1995. Tree insertion grammar: A cubic-time parsable formalism that lexicalizes context-free grammars without changing the trees produced. Comput. Linguist., 21(4):479– 513.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Seki</author>
<author>Takashi Matsumura</author>
<author>Mamoru Fujii</author>
<author>Tadao Kasami</author>
</authors>
<title>On multiple context-free grammars.</title>
<date>1991</date>
<journal>Theoret. Comput. Sci.,</journal>
<volume>88</volume>
<issue>2</issue>
<contexts>
<context position="4714" citStr="Seki et al. (1991)" startWordPosition="698" endWordPosition="701">gers, 2011). A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (G´ecseg and Steinby, 1984; G´ecseg and Steinby, 1997). CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al. (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al. (1991).3 Thus, CFTG are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (G´omez-Rodr´ıguez et al., 2010). In this contribution, we show that CFTG can strongly lexicalize TAG and also themselves, thus answering the second question in the conclusion of Kuhlmann and Satta (2012). This is achieved by a series of normalization steps (see Section 4) and a final lexicalization step (see Section 5), in which a lexical item is guessed for each production that does not already contain one. This item is then transported in an additional argum</context>
</contexts>
<marker>Seki, Matsumura, Fujii, Kasami, 1991</marker>
<rawString>Hiroyuki Seki, Takashi Matsumura, Mamoru Fujii, and Tadao Kasami. 1991. On multiple context-free grammars. Theoret. Comput. Sci., 88(2):191–229.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heiko Stamer</author>
</authors>
<title>Restarting Tree Automata: Formal Properties and Possible Variations.</title>
<date>2009</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Kassel,</institution>
<contexts>
<context position="14640" citStr="Stamer (2009)" startWordPosition="2625" endWordPosition="2626">rt-separated if posS(r) = ∅ for every production ` → r ∈ P. In other words, the start nonterminal S is not allowed in the right-hand sides of the productions. It is clear that each CFTG can be transformed into an equivalent start-separated CFTG. In such a CFTG we call each production of the form S → r initial. From now on, we assume, without loss of generality, that G is start-separated. Example 5. Let Gex = (N, E, S, P) be the CFTG of Example 2. An equivalent start-separated CFTG is G&apos;ex = ({S&apos;(0)} ∪ N, E, S&apos;, P ∪ {S&apos; → S}). We start with the growing normal form of Stamer and Otto (2007) and Stamer (2009). It requires that the right-hand side of each non-initial production contains at least two terminal or nonterminal symbols. In particular, it eliminates projection productions A(x1) → x1 and unit productions, in which the right-hand side has the same shape as the lefthand side (potentially with a different root symbol and a different order of the variables). Definition 6. A production ` → r is growing if |posNUE(r) |≥ 2. The CFTG G is growing if all of its non-initial productions are growing. The next theorem is Proposition 2 of (Stamer and Otto, 2007). Stamer (2009) provides a full proof. Th</context>
</contexts>
<marker>Stamer, 2009</marker>
<rawString>Heiko Stamer. 2009. Restarting Tree Automata: Formal Properties and Possible Variations. Ph.D. thesis, University of Kassel, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heiko Stamer</author>
<author>Friedrich Otto</author>
</authors>
<title>Restarting tree automata and linear context-free tree languages.</title>
<date>2007</date>
<booktitle>In Proc. 2nd Int. Conf. Algebraic Informatics,</booktitle>
<volume>4728</volume>
<pages>275--289</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="14622" citStr="Stamer and Otto (2007)" startWordPosition="2620" endWordPosition="2623">red CFTG. The CFTG G is start-separated if posS(r) = ∅ for every production ` → r ∈ P. In other words, the start nonterminal S is not allowed in the right-hand sides of the productions. It is clear that each CFTG can be transformed into an equivalent start-separated CFTG. In such a CFTG we call each production of the form S → r initial. From now on, we assume, without loss of generality, that G is start-separated. Example 5. Let Gex = (N, E, S, P) be the CFTG of Example 2. An equivalent start-separated CFTG is G&apos;ex = ({S&apos;(0)} ∪ N, E, S&apos;, P ∪ {S&apos; → S}). We start with the growing normal form of Stamer and Otto (2007) and Stamer (2009). It requires that the right-hand side of each non-initial production contains at least two terminal or nonterminal symbols. In particular, it eliminates projection productions A(x1) → x1 and unit productions, in which the right-hand side has the same shape as the lefthand side (potentially with a different root symbol and a different order of the variables). Definition 6. A production ` → r is growing if |posNUE(r) |≥ 2. The CFTG G is growing if all of its non-initial productions are growing. The next theorem is Proposition 2 of (Stamer and Otto, 2007). Stamer (2009) provide</context>
</contexts>
<marker>Stamer, Otto, 2007</marker>
<rawString>Heiko Stamer and Friedrich Otto. 2007. Restarting tree automata and linear context-free tree languages. In Proc. 2nd Int. Conf. Algebraic Informatics, volume 4728 of LNCS, pages 275–289. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>David J Weir</author>
<author>Aravind K Joshi</author>
</authors>
<title>Characterizing structural descriptions produced by various grammatical formalisms.</title>
<date>1987</date>
<booktitle>In Proc. 25th Ann. Meeting of the Association for Computational Linguistics,</booktitle>
<pages>104--111</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="4634" citStr="Vijay-Shanker et al. (1987)" startWordPosition="686" endWordPosition="689">lent to a slightly extended version of TAG, which is called non-strict TAG (Kepser and Rogers, 2011). A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (G´ecseg and Steinby, 1984; G´ecseg and Steinby, 1997). CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al. (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al. (1991).3 Thus, CFTG are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (G´omez-Rodr´ıguez et al., 2010). In this contribution, we show that CFTG can strongly lexicalize TAG and also themselves, thus answering the second question in the conclusion of Kuhlmann and Satta (2012). This is achieved by a series of normalization steps (see Section 4) and a final lexicalization step (see Section 5), in which a lexical item is guessed for each production that do</context>
</contexts>
<marker>Vijay-Shanker, Weir, Joshi, 1987</marker>
<rawString>K. Vijay-Shanker, David J. Weir, and Aravind K. Joshi. 1987. Characterizing structural descriptions produced by various grammatical formalisms. In Proc. 25th Ann. Meeting of the Association for Computational Linguistics, pages 104–111. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>XTAG Research Group</author>
</authors>
<title>A lexicalized tree adjoining grammar for English.</title>
<date>2001</date>
<tech>Technical Report IRCS-01-03,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, USA.</location>
<contexts>
<context position="13890" citStr="Group (2001)" startWordPosition="2477" endWordPosition="2478">valence of those CFTG to non-strict TAG, which are slightly more powerful than traditional TAG. In general, TAG are a natural formalism to describe the syntax of natural language.10 4 Normal forms In this section, we first recall an existing normal form for CFTG. Then we introduce the property of finite ambiguity in the spirit of (Schabes, 1990; Joshi and Schabes, 1992; Kuhlmann and Satta, 2012), which allows us to normalize our CFTG even further. A major tool is a simple production elimination 9For all k E N and � =:�-c C we note that � E CNUr(Xk) if and only if C E CNur(Xk). 10XTAG Research Group (2001) wrote a TAG for English. scheme, which we present in detail. From now on, let G = (N, E, S, P) be the considered CFTG. The CFTG G is start-separated if posS(r) = ∅ for every production ` → r ∈ P. In other words, the start nonterminal S is not allowed in the right-hand sides of the productions. It is clear that each CFTG can be transformed into an equivalent start-separated CFTG. In such a CFTG we call each production of the form S → r initial. From now on, we assume, without loss of generality, that G is start-separated. Example 5. Let Gex = (N, E, S, P) be the CFTG of Example 2. An equivalen</context>
</contexts>
<marker>Group, 2001</marker>
<rawString>XTAG Research Group. 2001. A lexicalized tree adjoining grammar for English. Technical Report IRCS-01-03, University of Pennsylvania, Philadelphia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryo Yoshinaka</author>
</authors>
<title>Extensions and Restrictions of Abstract Categorial Grammars.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Tokyo.</institution>
<contexts>
<context position="4274" citStr="Yoshinaka (2006)" startWordPosition="634" endWordPosition="635">for Computational Linguistics, pages 506–515, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics Simple (i.e., linear and nondeleting) context-free tree grammars [CFTG] (Rounds, 1969; Rounds, 1970) are a more powerful grammar formalism than TAG (M¨onnich, 1997). However, the monadic variant is strongly equivalent to a slightly extended version of TAG, which is called non-strict TAG (Kepser and Rogers, 2011). A GREIBACH normal form for a superclass of CFTG (viz., second-order abstract categorial grammars) was discussed by Kanazawa and Yoshinaka (2005) and Yoshinaka (2006). In particular, they also demonstrate that monadic CFTG can strongly lexicalize regular tree grammars (G´ecseg and Steinby, 1984; G´ecseg and Steinby, 1997). CFTG are weakly equivalent to the simple macro grammars of Fischer (1968), which are a notational variant of the well-nested linear context-free rewriting systems (LCFRS) of Vijay-Shanker et al. (1987) and the well-nested multiple context-free grammars (MCFG) of Seki et al. (1991).3 Thus, CFTG are mildly context-sensitive since their generated string languages are semi-linear and can be parsed in polynomial time (G´omez-Rodr´ıguez et al.</context>
</contexts>
<marker>Yoshinaka, 2006</marker>
<rawString>Ryo Yoshinaka. 2006. Extensions and Restrictions of Abstract Categorial Grammars. Ph.D. thesis, University of Tokyo.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>