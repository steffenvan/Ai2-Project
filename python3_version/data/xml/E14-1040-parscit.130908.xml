<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000121">
<title confidence="0.984822">
Sentiment Propagation via Implicature Constraints
</title>
<author confidence="0.954133">
Lingjia Deng Janyce Wiebe
</author>
<affiliation confidence="0.963262">
Intelligent Systems Program Department of Computer Science
University of Pittsburgh University of Pittsburgh
</affiliation>
<email confidence="0.998356">
lid29@pitt.edu wiebe@cs.pitt.edu
</email>
<sectionHeader confidence="0.993841" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999770428571429">
Opinions may be expressed implicitly via
inference over explicit sentiments and
events that positively/negatively affect en-
tities (goodFor/badFor events). We in-
vestigate how such inferences may be
exploited to improve sentiment analysis,
given goodFor/badFor event information.
We apply Loopy Belief Propagation to
propagate sentiments among entities. The
graph-based model improves over explicit
sentiment classification by 10 points in
precision and, in an evaluation of the
model itself, we find it has an 89% chance
of propagating sentiments correctly.
</bodyText>
<sectionHeader confidence="0.998931" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99871852631579">
Previous research in sentiment analysis and
opinion extraction has largely focused on the
interpretation of explicitly stated opinions. How-
ever, many opinions are expressed implicitly
via opinion implicature (i.e., opinion-oriented
defeasible inference). Consider the following
sentence:
EX(1) The bill would lower health care costs, which would
be a tremendous positive change across the entire health-care
system.
The writer is clearly positive toward the idea of
lowering health care costs. But how does s/he feel
about the costs? If s/he is positive toward the idea
of lowering them, then, presumably, she is nega-
tive toward the costs themselves (specifically, how
high they are). The only explicit sentiment expres-
sion, tremendous positive change, is positive, yet
we can infer a negative attitude toward the object
of the event itself (i.e., health care costs).
Going further, since the bill is the agent of an
event toward which the writer is positive, we may
(defeasibly) infer that the writer is positive toward
the bill, even though there are no explicit senti-
ment expressions describing it.
Now, consider The bill would curb skyrocketing
health care costs. The writer expresses an explicit
negative sentiment (skyrocketing) toward the ob-
ject (health care costs) of the event. Note that
curbing costs, like lowering them, is bad for them
(the costs are reduced). We can reason that, be-
cause the event is bad for something toward which
the writer is negative, the writer is positive toward
the event. We can reason from there, as above,
that the writer is positive toward the bill, since it
is the agent of the positive event.
These examples illustrate how explicit sen-
timents toward one entity may be propagated
to other entities via opinion implicature rules.
The rules involve events that positively or nega-
tively affect entities. We call such events good-
For/badFor (hereafter gfbf)events.
This work investigates how gfbf event interac-
tions among entities, combined with opinion in-
ferences, may be exploited to improve classifica-
tion of the writer’s sentiments toward entities men-
tioned in the text. We introduce four rule schemas
which reveal sentiment constraints among gfbf
events and their agents and objects. Those con-
straints are incorporated into a graph-based model,
where a node represents an entity (agent/object),
and an edge exists between two nodes if the two
entities participate in one or more gfbf events with
each other. Scores on the nodes represent the ex-
plicit sentiments, if any, expressed by the writer
toward the entities. Scores on the edges are based
on constraints derived from the rules. Loopy Be-
lief Propagation (LBP) (Pearl, 1982) is applied to
</bodyText>
<page confidence="0.971108">
377
</page>
<note confidence="0.9932185">
Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 377–385,
Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.9972818125">
accomplish sentiment propagation in the graph.
Two evaluations are performed. The first shows
that the graph-based model improves over an ex-
plicit sentiment classification system. The second
evaluates the graph-based model itself (and hence
the implicature rules), assessing its ability to cor-
rectly propagate sentiments to nodes whose polar-
ities are unknown. We find it has an 89% chance
of propagating sentiment values correctly.
This is the first paper to address this type of
sentiment propagation to improve sentiment anal-
ysis. To eliminate interference introduced by other
components, we use manually annotated gfbf in-
formation to build the graph. Thus, the evaluations
in this paper are able to demonstrate the promise
of the overall framework itself.
</bodyText>
<sectionHeader confidence="0.999812" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999909344262295">
Much work in sentiment analysis has been on
document-level classification. Since different sen-
timents may be expressed toward different entities
in a document, fine-grained analysis may be more
informative for applications.
However, fine-grained sentiment analysis re-
mains a challenging task for NLP systems. For
fully-automatic systems evaluated on the MPQA
corpus (Wiebe et al., 2005), for example, a recent
paper (Johansson and Moschitti, 2013) reports re-
sults that improve over previous work, yet the F-
measures are in the 40s and 50s.
Most work in NLP addresses explicit sentiment,
but some address implicit sentiment. For example,
(Zhang and Liu, 2011) identify noun product fea-
tures that imply opinions, and (Feng et al., 2013)
identify objective words that have positive or neg-
ative connotations. However, identifying terms
that imply opinions is a different task than senti-
ment propagation between entities. (Dasigi et al.,
2012) search for implicit attitudes shared between
authors, while we address inferences within a sin-
gle text.
Several papers apply compositional semantics
to determine polarity (e.g., (Moilanen and Pul-
man, 2007; Choi and Cardie, 2008; Moilanen et
al., 2010); see (Liu, 2012) for an overview). The
goal of such work is to determine one overall po-
larity of an expression or sentence. In contrast, our
framework commits to a holder having sentiments
toward various events and entities in the sentence,
possibly of different polarities.
The idea of gfbf events in sentiment analysis is
not entirely new. For example, two papers men-
tioned above (Zhang and Liu, 2011; Choi and
Cardie, 2008) include linguistic patterns for the
tasks that they address that include gfbf events,
but they don’t define general implicature rules re-
lating sentiments and gfbf events, agents, and ob-
jects as we do. Recently, in linguistics, Anand
and Reschke (2010; 2011) identify classes of
gfbf terms, and carry out studies involving artifi-
cially constructed gfbf triples and corpus exam-
ples matching fixed linguistic templates. Our work
focuses on gfbf triples in naturally-occurring data
and uses generalized implicature rules. Goyal et
al. (2012) generate a lexicon of patient polar-
ity verbs, which correspond to gfbf events whose
spans are verbs. Riloff et al. (2013) investigate
sarcasm where the writer holds a positive senti-
ment toward a negative situation. However, nei-
ther of these works performs sentiment inference.
Graph-based models have been used for various
tasks in sentiment analysis. Some work (Wang et
al., 2011; Tan et al., 2011) apply LBP on a graph
capturing the relations between users and tweets in
Twitter data. However, they assume the nodes and
the neighbors of nodes share the same sentiments.
In contrast, we don’t assume that neighbors share
the same sentiment, and the task we address is dif-
ferent.
</bodyText>
<sectionHeader confidence="0.995434" genericHeader="method">
3 Opinion Implicatures
</sectionHeader>
<bodyText confidence="0.974239947368421">
This section describes the opinion-implicature
framework motivating the design of the graph-
based method for sentiment analysis proposed be-
low. The components of the framework are gfbf
events, explicit sentiments, and rules operating
over gfbf events and sentiments.
The definition of a gfbf event is from (Deng et
al., 2013). A GOODFOR event is an event that
positively affects an entity (similarly, for BADFOR
events). (Deng et al., 2013) point out that gfbf ob-
jects are not equivalent to benefactive/malefactive
semantic roles. An example they give is She baked
a cake for me: a cake is the object of GOOD-
FOR event baked (creating something is good for
it (Anand and Reschke, 2010)), while me is the
filler of its benefactive semantic role (Z´u˜niga and
Kittil¨a, 2010).
Four implicature rule schemas are relevant for
this paper.1 Four individual rules are covered by
</bodyText>
<footnote confidence="0.992138">
1Implicatures “normally accompany the utterances of a
given sentence unless special factors exclude that possibility
</footnote>
<page confidence="0.997776">
378
</page>
<bodyText confidence="0.9998856">
each schema. sent(α) = Q means that the writer’s
sentiment toward α is Q, where α is a GOODFOR
event, a BADFOR event, or the agent or object of
a gfbf event, and Q is either positive or negative
(pos or neg, for short). P —* Q is to infer Q from P.
</bodyText>
<listItem confidence="0.62549275">
Rule1: sent(gfbf event) —* sent(object)
1.1 sent(GOODFOR) = pos —* sent(object) = pos
1.2 sent(GOODFOR) = neg —* sent(object) = neg
1.3 sent(BADFOR) = pos —* sent(object) = neg
1.4 sent(BADFOR) = neg —* sent(object) = pos
Rule2: sent(object) —* sent(gfbf event)
2.1 sent(object) = pos —* sent(GOODFOR) = pos
2.2 sent(object) = neg —* sent(GOODFOR) = neg
2.3 sent(object) = pos —* sent(BADFOR) = neg
2.4 sent(object) = neg —* sent(BADFOR) = pos
Rule3: sent(gfbf event) —* sent(agent)
3.1 sent(GOODFOR) = pos —* sent(agent) = pos
3.2 sent(GOODFOR) = neg —* sent(agent) = neg
3.3 sent(BADFOR) = pos —* sent(agent) = pos
3.4 sent(BADFOR) = neg —* sent(agent) = neg
Rule4: sent(agent) —* sent(gfbf event)
4.1 sent(agent) = pos —* sent(GOODFOR) = pos
4.2 sent(agent) = neg —* sent(GOODFOR) = neg
4.3 sent(agent) = pos —* sent(BADFOR) = pos
4.4 sent(agent) = neg —* sent(BADFOR) = neg
</listItem>
<bodyText confidence="0.9896403">
To explain the rules, we step through an example:
EX(2) Why would [President Obama] support [health care
reform]? Because [reform] could lower [skyrocketing health
care costs], and prohibit [private insurance companies] from
overcharging [patients].
Suppose a sentiment analysis system recognizes
only one explicit sentiment expression, skyrock-
eting. According to the annotations, there are
several gfbf events. Each is listed below in the
form (agent, gfbf, object).
</bodyText>
<listItem confidence="0.923651">
E1: (reform, lower, costs)
E2: (reform, prohibit, E3 )
E3: (companies, overcharge, patients)
E4: (Obama, support, reform)
</listItem>
<bodyText confidence="0.994934225">
In E1, from the negative sentiment expressed
by skyrocketing (the writer is negative toward the
(p. 39).” (Huddleston and Pullum, 2002)
costs because they are too high), and the fact that
costs is the object of a BADFOR event (lower),
Rule2.4 infers a positive attitude toward E1 .
Now, Rule3.3 applies. We infer the writer is
positive toward the reform, since it is the agent
of E1, toward which the writer is positive.
E2 illustrates the case where the object is an
event. Specifically, the object of E2 is E3, a BAD-
FOR event (overcharging). As we can see, E2
keeps E3 from happening. Events such as E2
are REVERSERs, because they reverse the polar-
ity of a gfbf event (from BADFOR to GOODFOR,
or vice versa). Note that REVERSERs may be seen
as BADFOR events, because they make their ob-
jects irrealis (i.e., not happen). Similarly, a RE-
TAINER such as help in “help Mary save Bill” can
be viewed as a GOODFOR event. (We call a RE-
VERSER or a RETAINER an INFLUENCER.) In this
paper, RETAINERS are treated as GOODFOR events
and REVERSERS are treated as BADFOR events.
Above, we inferred that the writer is positive to-
ward reform, the agent of E2. By Rule 4.3, the
writer is positive toward E2; then by Rule 1.3, the
writer is negative toward E3, the object of E2.
For E3, using Rule 1.4 we know the writer is
positive toward patients and using Rule 3.4 we
know the writer is negative toward companies.
Turning to E4, support health care reform is
GOODFOR reform. We already inferred the writer
is positive toward reform. Rule 2.1 infers that the
writer is positive toward E4. Rule 3.1 then infers
that the writer is positive toward the agent of E4,
Obama.
In summary, we infer that the writer is positive
toward E1, health care reform, E2, patients, E4,
and Obama, and negative toward E3 and private
insurance companies.
</bodyText>
<sectionHeader confidence="0.9963" genericHeader="method">
4 Data
</sectionHeader>
<bodyText confidence="0.999844818181818">
We use the data described in (Deng et al., 2013),2
which consists of 134 documents about a contro-
versial topic, “the Affordable Care Act.” The doc-
uments are editorials and blogs, and are full of
opinions.
In the data, gfbf triples are annotated specifying
the spans of the gfbf event, its agent, and its object,
as well as the polarity of the gfbf event (GOODFOR
or BADFOR), and the writer’s attitude toward the
agent and object (positive, negative, or neutral).
Influencers are also annotated. The agents of gfbf
</bodyText>
<footnote confidence="0.998521">
2Available at http://mpqa.cs.pitt.edu
</footnote>
<page confidence="0.998574">
379
</page>
<bodyText confidence="0.999946666666667">
and influencer events are noun phrases. The ob-
ject of a gfbf event is a noun phrase, but the object
of an influencer is a gfbf event or another influ-
encer. A triple chain is a chain of zero or more
influencers ending in a gfbf event, where the ob-
ject of each element of the chain is the following
element in the chain. (e.g. in EX(2), the two event
prohibit and overcharging is a triple chain.)
In total, there are 1,762 annotated gfbf triples,
out of which 692 are GOODFOR or RETAINER
and 1,070 are BADFOR or REVERSER. From the
writer’s perspective, 1,495 noun phrases are anno-
tated positive, 1,114 are negative and the remain-
ing 8 are neutral. This is not surprising, given that
most of the sentences in the data are opinionated.
</bodyText>
<sectionHeader confidence="0.999555" genericHeader="method">
5 Graph-based Model
</sectionHeader>
<bodyText confidence="0.9999945">
We propose a graph-based model of entities and
the gfbf relations between them to enable senti-
ment propagation between entities. In this section,
we introduce the definition of the graph (in 5.1),
the LBP algorithm (in 5.2), and the definition of
its functions for our task (in 5.3 and 5.4).
</bodyText>
<subsectionHeader confidence="0.991986">
5.1 Definition of the Entity Graph
</subsectionHeader>
<bodyText confidence="0.998465428571429">
We define a gfbf entity graph EG = IN, E},
in which the node set N consists of nodes, each
representing an annotated noun phrase agent or
object span. The edge set E consists of edges,
each linking two nodes if they co-occur in a triple
chain with each other. Consider the triples of
EX(2) in Section 3 below.
</bodyText>
<listItem confidence="0.91621775">
E1: (reform, lower, costs)
E2: (reform, prohibit, E3 )
E3: (companies, overcharge, patients)
E4: (Obama, support, reform)
</listItem>
<bodyText confidence="0.9917535">
The node of reform is linked to nodes of costs via
E1 and Obama via E4.3 Note that, for E2 and
E3, the two are linked in a chain: (reform, pro-
hibit, (companies, overcharge, patients) ). The
three nodes reform, companies and patients partic-
ipate in this triple chain; thus, pairwise edges ex-
ist among them. The edge linking companies and
patients is BADFOR (because of overcharging).
The edge linking reform and companies is also a
BADFOR since we treat a REVERSER as BADFOR.
3This assumes that the two instances of “reform” co-refer.
However, the system does not resolve co-reference – the
methods that we tried did not improve overall performance.
The edge linking reform and patients encodes two
BADFOR events (prohibit-overcharge); computa-
tionally we say two BADFORs result in a GOOD-
FOR, so the edge linking the two is GOODFOR.4
Given a text, we get the spans of gfbf events
and their agents and objects plus the polarities of
the events (GOODFOR/BADFOR) from the manual
annotations, and then build the graph upon them.
However, the manual annotations of the writer’s
sentiments toward the agents and objects are used
as the gold standard for evaluation.
</bodyText>
<subsectionHeader confidence="0.930884">
5.2 Sentiment Inference via LBP
</subsectionHeader>
<tableCaption confidence="0.98568">
Table 1: Loopy Belief Propagation
</tableCaption>
<bodyText confidence="0.999860238095238">
With graph EG containing cycles and no appar-
ent structure, we utilize an approximate collective
classification algorithm, loopy belief propagation
(LBP) (Pearl, 1982; Yedidia et al., 2005), to clas-
sify nodes through belief message passing. The
algorithm is shown in Table 1.
In LBP, each node has a score, Φi(y), and each
edge has a score, &apos;Fij(yi, yj). In our case, Φi(y)
represents the writer’s explicit sentiment toward
ni. &apos;Fij(yi, yj) is the score on edge eij, represent-
ing the likelihood that node ni has polarity yi and
nj has polarity yj. The specific definitions of the
two functions are given in Sections 5.3 and 5.4.
LBP is an iterative message passing algorithm.
A message from ni to nj over edge eij has
two values: mi→j(pos) is how much information
from node ni indicates node nj is positive, and
mi→j(neg) is how much information from node
ni indicates node nj is negative. In each iteration,
the two are normalized such that mi→j(pos) +
mi→j(neg) = 1. The message from ni to its
</bodyText>
<footnote confidence="0.47327">
4Also, GOODFOR+BADFOR=BADFOR; GOOD-
FOR+GOODFOR=GOODFOR
</footnote>
<figure confidence="0.8764274">
initialize all mi→j(pos) = mi→j(neg) = 1
repeat
foreach ni E N do
foreach nj E Neighbor(ni) do
foreach y E pos, neg do
calculate mi→j(y)
normalize mi→j(pos) + mi→j(neg) = 1
until all mi→j stop changing;
for each ni E N assign its polarity as
argmax Φi(y) ∗ FInk∈Neighbor(ni) m k→i(y)
y∈pos,neg
neutral, in case of a tie
380
neighbor nj is computed as:
mi→j(pos) =
Tij(pos, pos)∗Φi(pos)∗
nk∈Neighbor(ni)/nj
ri
Tij(neg, pos)∗Φi(neg)∗
nk∈Neighbor(ni)/nj
mi→j(neg) =
Tij(neg, neg)∗Φi(neg)∗ ri
nk∈Neighbor(ni)/nj
ri
Tij(pos, neg)∗Φi(pos)∗
nk∈Neighbor(ni)/nj
mk→i(pos)+
mk→i(neg)
mk→i(neg)+
mk→i(pos)
</figure>
<bodyText confidence="0.996727794117647">
A table of Rule schemas 2 and 4 would be
exactly the same, except that the inference (→)
would be in the opposite direction (←).
From Table 2, we see that, regardless of the
writer’s sentiment toward the event, if the event
is GOODFOR, then the writer’s sentiment toward
the agent and object are the same, while if the
event is BADFOR, the writer’s sentiment toward
the agent and object are opposite. Thus, the event
type and the writer’s sentiments toward the agents
and objects give us constraints. Therefore, we de-
fine Ψij(pos, pos) and Ψij(neg, neg) to be 1 if the
two nodes are linked by a GOODFOR edge; oth-
erwise, it is 0; and we define Ψij(neg,pos) and
Ψij(pos, neg) to be 1 if the two nodes are linked
by a BADFOR edge; otherwise, it is 0.
For example, the first part of Equation (1)
means that the positive message ni conveys to
nj (i.e., mi→j(pos)) comes from ni being pos-
itive itself (Φi(pos)), the likelihood of edge eij
with its nodes ni being positive and nj being
positive (Ψij(pos, pos)), and the positive mes-
sage ni’s neighbors (besides nj) convey to it
(11k∈Neighbor(ni)/nj mk→i(pos)).
After convergence, the polarity of each node is
determined by its explicit sentiment and the mes-
sages its neighbors convey to it, as shown at the
end of the algorithm in Table 1.
By this method, we take into account both sen-
timents and the interactions between entities via
gfbf events in order to discover implicit attitudes.
Note that the node and edge scores are deter-
mined initially and do not change. Only mi→j
changes from iteration to iteration.
</bodyText>
<subsectionHeader confidence="0.878178">
5.3 Ψij(yi, yj): GFBF Implicature Relations
</subsectionHeader>
<bodyText confidence="0.999649">
The score Ψi,j encodes constraints based on the
gfbf relationships that nodes ni and nj participate
in, together with the implicature rules given above.
Rule schemas 1 and 3 infer sentiments to-
ward entities (agent/object) from sentiments to-
ward gfbf events. All cases covered by them are
shown in Table 2 (use s(α) to represent sent(α)).
</bodyText>
<table confidence="0.999161333333333">
Rule 3 Rule1
s(gfbf) gfbf type → s(agent) s(object)
pos GOODFOR → pos pos
neg GOODFOR → neg neg
pos BADFOR → pos neg
neg BADFOR → neg pos
</table>
<tableCaption confidence="0.99638">
Table 2: Rule 1 &amp; Rule 3
</tableCaption>
<subsectionHeader confidence="0.492488">
5.4 Φi(y): Explicit Sentiment Classifier
</subsectionHeader>
<bodyText confidence="0.999948931034483">
The score of a node, Φi(y), represents the sen-
timent explicitly expressed by the writer toward
that entity in the document. Since y ranges over
(pos, neg), each node has a positive and a nega-
tive score; the scores sum to 1. If it is a positive
node, then its positive value ranges from 0.5 to 1,
and its negative value ranges from 0 to 0.5 (sim-
ilarly for negative nodes). For any node without
explicit sentiment, both the positive and negative
values are 0.5, indicating a neutral node.
Thus, we build a sentiment classifier that takes a
node as input and outputs a positive and a negative
score. It is built from widely-used, freely available
resources: the OpinionFinder (Wilson et al., 2005)
and General Inquirer (Stone et al., 1966) lexicons
and the OpinionFinder system.5 We also use a new
Opinion Extraction system (Johansson and Mos-
chitti, 2013) that shows better performance than
previous work on fine-grained sentiment analy-
sis,6 and a new automatically developed connota-
tion lexicon (Feng et al., 2013).7
We implement a weighted voting method
among these various sentiment resources. After
that, for nodes that have not yet been assigned po-
lar values (positive or negative), we implement a
simple local discourse heuristic to try to assign
them polar values.
The particular strategies were chosen based
only on a separate development set, which is not
</bodyText>
<footnote confidence="0.9998148">
5http://mpqa.cs.pitt.edu and
http://www.wjh.harvard.edu/ inquirer/
6As evaluated on the MPQA corpus. Note that the authors
ran their system for us on the data we use.
7http://www.cs.stonybrook.edu/∼ychoi/connotation
</footnote>
<page confidence="0.998193">
381
</page>
<bodyText confidence="0.960844">
included in the data used in the experiments.
</bodyText>
<subsectionHeader confidence="0.62933">
5.4.1 Explicit Sentiment Tools
</subsectionHeader>
<bodyText confidence="0.999809454545455">
Opinion Extraction outputs a polarity expression
with its source, and OpinionFinder outputs a po-
larity word. But neither of the tools extracts the
target. To extract the target, for each word in the
opinion expression, we select other words in the
sentence which are in a mod, obj dependency pars-
ing relation with it.
We match up the extracted expressions and the
gfbf annotations according to their offsets in the
text. For an opinion expression appearing in the
sentence with no gfbf annotation, if the root word
(in the dependency parse) of the expression span
is the same as the root word of a gfbf span, or the
root word of an agent span, or the root word of an
object span, we assume they match up. Then we
assign polarity as follows. If the expression refers
only to the agent or object, then the agent or object
is assigned the polarity of the expression. If the
expression covers the gfbf event and its object, we
assume the sentiment is toward the gfbf event and
then assign sentiment according to Rule schema 1
(sent(gfbf event) → sent(object)).
</bodyText>
<subsectionHeader confidence="0.834022">
5.4.2 Lexicons
</subsectionHeader>
<bodyText confidence="0.9999951">
To classify the sentiment expressed within the
span of an agent or object, we check whether the
words in the span appear in one or more of the
lexicons.8 If a lexicon finds both positive and neg-
ative words in the span, we resolve the conflict
by choosing the polarity of the root word in the
span. If the root word does not have a polar value,
we choose the majority polarity of the sentiment
words. If there are an equal number of positive
and negative words, the polarity is neutral.
</bodyText>
<subsectionHeader confidence="0.897778">
5.4.3 Voting Scheme among Resources
</subsectionHeader>
<bodyText confidence="0.9999527">
All together we have two sentiment systems and
three lexicons. Before explicit sentiment classi-
fying, each node has a positive value of 0.5 and
a negative value of 0.5. We give the five votes
equal weight (0.1), and add the number of posi-
tive votes multiplied by 0.1 to the positive value,
and the number of negative votes multiplied by 0.1
to the negative value. After this addition, both val-
ues are in the range 0.5 to 1. If the positive value
is larger, we maintain the positive value and assign
</bodyText>
<footnote confidence="0.755258333333333">
8The comparison is done after lemmatization, using the
wordNet lemmatization in NLTK, and with the same POS,
according to the Stanford POStagger toolkit.
</footnote>
<bodyText confidence="0.997173">
the negative value to be 1-positive value (similarly
if the negative value is larger).
</bodyText>
<sectionHeader confidence="0.497878" genericHeader="method">
5.4.4 Discourse
</sectionHeader>
<bodyText confidence="0.997933625">
For a sentence s, we assume the writer’s senti-
ments toward the gfbf events in the clauses of s,
the previous sentence, and the next sentence, are
the same. Consider EX(3):
EX(3) ... health-insurance regulations that will prohibit (a)
denying coverage for pre-existing conditions, (b) dropping
coverage if the client gets sick, and (c) capping insurance
company reimbursement...
EX(3) has three clauses, (a)-(c). Suppose the ex-
plicit sentiment classifier recognizes that event (a),
denying coverage for pre-existing conditions, is
negative and it does not find any other explicit sen-
timents in the sentence. The system assumes the
writer’s sentiments toward (b) and (c) are negative
as well.
After assigning all possible polarities to events
within a sentence, polarities are propagated to the
other still-neutral gfbf events in the previous and
next sentences.
Finally, event-level polarities are propagated to
still-neutral objects using Rule schema 1.9 If there
is a conflict, we take the majority sentiment; if
there is a tie, the object remains neutral.
However, the confidence of the discourse voting
is smaller than the explicit sentiment voting, since
discourse structure is complex. If by discourse an
object node is classified as positive, the positive
value is 0.5 + random(0, 0.1) and the negative
value is 1-positive value. Thus, the positive value
of a positive node is larger than its negative value,
but not exceeding too much (similarly for negative
nodes).
</bodyText>
<sectionHeader confidence="0.990637" genericHeader="evaluation">
6 Experiments and Results
</sectionHeader>
<subsectionHeader confidence="0.998953">
6.1 Experiment Data
</subsectionHeader>
<bodyText confidence="0.999991333333333">
Of the 134 documents in the dataset, 6 were used
as a development set, and 3 do not have any anno-
tation. We use the remaining 125 for experiment.
</bodyText>
<subsectionHeader confidence="0.999039">
6.2 Evaluation Metrics
</subsectionHeader>
<bodyText confidence="0.9846685">
To evaluate the performance of classifying the
writer’s sentiments toward agents and objects, we
</bodyText>
<footnote confidence="0.979775666666667">
9Note that, in the gfbf entity graph, sentiments can be
propagated from objects to agents, conceptually via Rule
schemas 2 and 3. Thus, here we only classify objects.
</footnote>
<page confidence="0.9959">
382
</page>
<bodyText confidence="0.9982308">
define three metrics to evaluate performance. For
the entire dataset, accuracy evaluates the percent-
age of nodes that are classified correctly. Preci-
sion and recall are defined to evaluate polar (non-
neutral) classification.
</bodyText>
<equation confidence="0.470242714285714">
Accuracy = #node auto=gold 3
#nodes ( )
#node auto=gold &amp; gold != neutral
Precision = (4)
#node auto != neutral
Recall = #node auto=gold &amp; gold != neutral 5
#node gold != neutral ( )
</equation>
<bodyText confidence="0.9971645">
In the equations, auto is the system’s output and
gold is the gold-standard label from annotation.
</bodyText>
<subsectionHeader confidence="0.99917">
6.3 Overall Performance
</subsectionHeader>
<bodyText confidence="0.991100181818182">
In this section, we evaluate the performance of
the overall system. In 6.5, we evaluate the graph
model itself.
Two baselines are defined. One is assigning
the majority class label, which is positive, to all
agents/objects (Majority(+)). The second is as-
suming that agents/objects in a GOODFOR relation
are positive and agents/objects in a BADFOR rela-
tion are negative (GFBF). In addition, we eval-
uate the explicit sentiment classifier introduced in
Section 5.4 (Explicit). The results are shown in
</bodyText>
<tableCaption confidence="0.92416">
Table 3.
</tableCaption>
<table confidence="0.9998282">
Accuracy Precision Recall
Majority(+) 0.5438 0.5621 0.5443
GFBF 0.5437 0.5523 0.5444
Explicit 0.3703 0.5698 0.3703
Graph-LBP 0.5412 0.6660 0.5419
</table>
<tableCaption confidence="0.999904">
Table 3: Performance of baselines and graph.
</tableCaption>
<bodyText confidence="0.999864923076923">
As can be seen, Majority and GFBF give ap-
proximately 56% precision. Explicit sentiment
classification alone performs hardly better in pre-
cision and much lower in recall. As mentioned
in Section 2, fine-grained sentiment analysis is
still very difficult for NLP systems. However, the
graph model improves greatly over Explicit in
both precision and recall. While recall of the graph
model is comparable to the Majority, precision
is much higher.
During the experiment, if the LBP does not con-
verge until 100 iterations, it is forced to stop. The
average number of iteration is 34.192.
</bodyText>
<subsectionHeader confidence="0.978758">
6.4 Error Analysis
</subsectionHeader>
<bodyText confidence="0.998658">
Table 4 shows the results of an error analysis to
determine what contributes to the graph model’s
errors.
</bodyText>
<table confidence="0.9994336">
1 wrong sentiment from voting 0.2132
2 wrong sentiment from discourse 0.0462
3 subgraph with wrong polarity 0.3189
4 subgraph with no polarity 0.4160
5 other 0.0056
</table>
<tableCaption confidence="0.997946">
Table 4: Errors for graph model.
</tableCaption>
<bodyText confidence="0.998237352941176">
Rows 1-2 are the error sources for nodes as-
signed a polar value before graph propagation.
Row 1 errors are due to the sentiment-voting sys-
tem, Row 2 are due to discourse processing.
Rows 3-4 are the error sources for nodes that
have not been assigned a polar value by Explicit.
Such a node receives a polar value only via prop-
agation from other nodes in its subgraph (i.e., the
connected component of the graph containing the
node). Row 5 is the percentage of other errors.
As shown in Rows 1-2, 25.94% of the errors
are due to Explicit. These may propagate incor-
rect labels to other nodes in the graph. As shown
in Row 3, 31.89% of the errors are due to nodes
not classified polar by Explicit, but given incor-
rect values because their subgraph has an incorrect
polarity. Row 4 shows that 41.60% of the errors
are due to nodes that are not assigned any polar
value. Given non-ideal input from sentiment anal-
ysis, how does the graph model increase precision
by 10 percentage points?
There are two main ways. For nodes which re-
main neutral after Explicit, they might be clas-
sified correctly via the graph. For nodes which
are given incorrect polar labels by Explicit, they
might be fixed by the graph. Table 5 shows the
best the graph model could do, given the noisy in-
put from Explicit. Over all of the nodes, more
propagated labels are incorrect than correct. How-
ever, if there are no incorrect, or more correct than
incorrect sentiments in the subgraph (connected
component), then many more of the propagated la-
bels are correct than incorrect. In all cases, more
of the changed labels are correct than incorrect.
</bodyText>
<subsectionHeader confidence="0.9502225">
6.5 Consistency and Isolated Performance of
Graph Model
</subsectionHeader>
<bodyText confidence="0.998132">
The implicature rules are defeasible. In this sec-
tion we introduce an experiment to valid the con-
</bodyText>
<page confidence="0.996724">
383
</page>
<table confidence="0.994296">
propagated propagated changed changed
label correct label incorrect correctly incorrectly
all subgraphs
399 536 424 274
subgraphs having no incorrect sentiment
347 41 260 23
subgraphs having more correct than incorrect sentiment
356 42 288 35
</table>
<tableCaption confidence="0.832812">
Table 5: Effects of graph model given Explicit
input
</tableCaption>
<bodyText confidence="0.99988605">
sistency of implicature rule. Recall that in Section
5.3, the definition of Ψi,j is based on implicature
rules and sentiment is propagated based on Ψi,j.
Thus, this is also an evaluation of the performance
of the graph model itself. We performed an experi-
ment to assess the chance of a node being correctly
classified only via the graph.
In each subgraph (connected component), we
assign one of the nodes in the subgraph with its
gold-standard polarity. Then we run LBP on the
subgraph and record whether the other nodes in
the subgraph are classified correctly or not. The
experiment is run on the subgraph |S |times, where
|S |is the number of nodes in the subgraph, so
that each node is assigned its gold-standard polar-
ity exactly once. Each node is given a propagated
value |S |− 1 times, as each of the other nodes in
its subgraph receives its gold-standard polarity.
To evaluate the chance of a node given a correct
propagated label, we use Equations (6) and (7).
</bodyText>
<equation confidence="0.9051962">
� 1 a is correct
correct(a|b) = (6)
0 otherwise
Eb∈Sm baa correct(a|b) correctness(a) = (7)
|Sa |− 1
</equation>
<bodyText confidence="0.999968043478261">
where Sa is the set of nodes in a’s subgraph. Given
b being assigned its gold-standard polarity, if a is
classified correctly, then correct(a|b) is 1; other-
wise 0. |Sa |is the number of nodes in a’s sub-
graph. correctness(a) is the percentage of as-
signments to a that are correct. If it is 1, then a
is correctly classified given the correct classifica-
tion of any single node in its subgraph.
For example, suppose there are three nodes in
a subgraph, A, B and C. For A we (1) as-
sign B its gold label and carry out propagation
on the subgraph, (2) assign C its gold label and
carry out propagation again, then (3) calculate
correctness(A). Then the same process is re-
peated for B and C.
Some subgraphs contain only two nodes, the
agent and the object. In this case, graph propa-
gation corresponds to single applications of two
implicature rules. Other subgraphs contain more
nodes. Two results are shown in Table 6. One is
the result on the whole experiment data, the other
is the result for all nodes whose subgraphs have
more than two nodes.
</bodyText>
<table confidence="0.990946333333333">
Dataset # subgraph correctness
all subgraphs 983 0.8874
multi-node subgraphs 169 0.9030
</table>
<tableCaption confidence="0.999138">
Table 6: Performance of graph model itself.
</tableCaption>
<bodyText confidence="0.9999167">
As we can see, a node has an 89% chance of
being correct if there is one correct explicit sub-
jectivity node in its subgraph. If we only consider
subgraphs with more than two nodes, the correct-
ness chance is higher. The results indicate that, if
given correct sentiments, the graph model will as-
sign the unknown nodes with correct labels 90% of
the time. Further, the results indicate that the im-
plicature rules are consistent for most of the times
across the corpus.
</bodyText>
<sectionHeader confidence="0.999208" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999897904761905">
We developed a graph-based model based on
implicature rules to propagate sentiments among
entities. The model improves over explicit
sentiment classification by 10 points in precision
and, in an evaluation of the model itself, we find
it has an 89% chance of propagating sentiments
correctly. An important question for future work
is under what conditions do the implicatures
not go through in context. Two cases we have
discovered involve Rule schema 3: the inference
toward the agent is defeated if the action was
accidental or if the agent was forced to perform it.
We are investigating lexical clues for recognizing
such cases.
Acknowledgments. This work was supported
in part by DARPA-BAA-12-47 DEFT grant
#12475008 and National Science Foundation
grant #IIS-0916046. We would like to thank
Richard Johansson and Alessandro Moschitti for
running their Opinion Extraction systems on our
data.
</bodyText>
<page confidence="0.998127">
384
</page>
<sectionHeader confidence="0.9903" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999872158878505">
Pranav Anand and Kevin Reschke. 2010. Verb classes
as evaluativity functor classes. In Interdisciplinary
Workshop on Verbs. The Identification and Repre-
sentation of Verb Features.
Yejin Choi and Claire Cardie. 2008. Learning with
compositional semantics as structural inference for
subsentential sentiment analysis. In Proceedings of
the 2008 Conference on Empirical Methods in Nat-
ural Language Processing, pages 793–801, Hon-
olulu, Hawaii, October. Association for Computa-
tional Linguistics.
Pradeep Dasigi, Weiwei Guo, and Mona Diab. 2012.
Genre independent subgroup detection in online dis-
cussion threads: A study of implicit attitude us-
ing textual latent semantics. In Proceedings of the
50th Annual Meeting of the Association for Com-
putational Linguistics (Volume 2: Short Papers),
pages 65–69, Jeju Island, Korea, July. Association
for Computational Linguistics.
Lingjia Deng, Yoonjung Choi, and Janyce Wiebe.
2013. Benefactive and malefactive event and writer
attitude annotation. In 51st Annual Meeting of the
Association for Computational Linguistics (ACL-
2013, short paper).
Song Feng, Jun Sak Kang, Polina Kuznetsova, and
Yejin Choi. 2013. Connotation lexicon: A dash of
sentiment beneath the surface meaning. In Proceed-
ings of the 51th Annual Meeting of the Association
for Computational Linguistics (Volume 2: Short Pa-
pers), Sofia, Bulgaria, Angust. Association for Com-
putational Linguistics.
Amit Goyal, Ellen Riloff, and Hal Daum III. 2012. A
computational model for plot units. Computational
Intelligence, pages 466–488.
Rodney D. Huddleston and Geoffrey K. Pullum. 2002.
The Cambridge Grammar of the English Language.
Cambridge University Press, April.
Richard Johansson and Alessandro Moschitti. 2013.
Relational features in fine-grained opinion analysis.
Computational Linguistics, 39(3).
Bing Liu. 2012. Sentiment Analysis and Opinion Min-
ing. Morgan &amp; Claypool.
Karo Moilanen and Stephen Pulman. 2007. Senti-
ment composition. In Proceedings of RANLP 2007,
Borovets, Bulgaria.
Karo Moilanen, Stephen Pulman, and Yue Zhang.
2010. Packed feelings and ordered sentiments:
Sentiment parsing with quasi-compositional polar-
ity sequencing and compression. In Proceedings of
the 1st Workshop on Computational Approaches to
Subjectivity and Sentiment Analysis (WASSA 2010),
pages 36–43.
J. Pearl. 1982. Reverend bayes on inference engines:
A distributed hierarchical approach. In Proceedings
of the American Association ofArtificial Intelligence
National Conference on AI, pages 133–136, Pitts-
burgh, PA.
Kevin Reschke and Pranav Anand. 2011. Extracting
contextual evaluativity. In Proceedings of the Ninth
International Conference on Computational Seman-
tics, IWCS ’11, pages 370–374, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-
dra De Silva, Nathan Gilbert, and Ruihong Huang.
2013. Sarcasm as contrast between a positive sen-
timent and negative situation. In Proceedings of
the 2013 Conference on Empirical Methods in Nat-
ural Language Processing, pages 704–714, Seattle,
Washington, USA, October. Association for Com-
putational Linguistics.
P.J. Stone, D.C. Dunphy, M.S. Smith, and D.M.
Ogilvie. 1966. The General Inquirer: A Computer
Approach to Content Analysis. MIT Press, Cam-
bridge.
Chenhao Tan, Lillian Lee, Jie Tang, Long Jiang, Ming
Zhou, and Ping Li. 2011. User-level sentiment
analysis incorporating social networks. In Proceed-
ings of the 17th ACM SIGKDD international con-
ference on Knowledge discovery and data mining,
pages 1397–1405. ACM.
Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming zhou,
and Ming Zhang. 2011. Topic sentiment anaylsis in
twitter: A graph-based hashtag sentiment classifica-
tion appraoch. In CIKM, pages 1031–1040.
Janyce Wiebe, Theresa Wilson, and Claire Cardie.
2005. Annotating expressions of opinions and emo-
tions in language ann. Language Resources and
Evaluation, 39(2/3):164–210.
Theresa Wilson, Janyce Wiebe, and Paul Hoffmann.
2005. Recognizing contextual polarity in phrase-
level sentiment analysis. In HLT/EMNLP, pages
347–354.
Jonathan S Yedidia, William T Freeman, and Yair
Weiss. 2005. Constructing free-energy approx-
imations and generalized belief propagation algo-
rithms. Information Theory, IEEE Transactions on,
51(7):2282–2312.
Lei Zhang and Bing Liu. 2011. Identifying noun prod-
uct features that imply opinions. In Proceedings of
the 49th Annual Meeting of the Association for Com-
putational Linguistics: Human Language Technolo-
gies, pages 575–580, Portland, Oregon, USA, June.
Association for Computational Linguistics.
F. Z´u˜niga and S. Kittil¨a. 2010. Introduction. In
F. Z´u˜niga and S. Kittil¨a, editors, Benefactives and
malefactives, Typological studies in language. J.
Benjamins Publishing Company.
</reference>
<page confidence="0.999087">
385
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.981641">
<title confidence="0.999817">Sentiment Propagation via Implicature Constraints</title>
<author confidence="0.998448">Lingjia Deng Janyce Wiebe</author>
<affiliation confidence="0.999599">Intelligent Systems Program Department of Computer Science University of Pittsburgh University of Pittsburgh</affiliation>
<email confidence="0.998768">lid29@pitt.eduwiebe@cs.pitt.edu</email>
<abstract confidence="0.9988064">Opinions may be expressed implicitly via inference over explicit sentiments and events that positively/negatively affect en- We investigate how such inferences may be exploited to improve sentiment analysis, given goodFor/badFor event information. We apply Loopy Belief Propagation to propagate sentiments among entities. The graph-based model improves over explicit sentiment classification by 10 points in precision and, in an evaluation of the model itself, we find it has an 89% chance of propagating sentiments correctly.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Pranav Anand</author>
<author>Kevin Reschke</author>
</authors>
<title>Verb classes as evaluativity functor classes. In Interdisciplinary Workshop on Verbs. The Identification and Representation of Verb Features.</title>
<date>2010</date>
<contexts>
<context position="6341" citStr="Anand and Reschke (2010" startWordPosition="970" endWordPosition="973">rk is to determine one overall polarity of an expression or sentence. In contrast, our framework commits to a holder having sentiments toward various events and entities in the sentence, possibly of different polarities. The idea of gfbf events in sentiment analysis is not entirely new. For example, two papers mentioned above (Zhang and Liu, 2011; Choi and Cardie, 2008) include linguistic patterns for the tasks that they address that include gfbf events, but they don’t define general implicature rules relating sentiments and gfbf events, agents, and objects as we do. Recently, in linguistics, Anand and Reschke (2010; 2011) identify classes of gfbf terms, and carry out studies involving artificially constructed gfbf triples and corpus examples matching fixed linguistic templates. Our work focuses on gfbf triples in naturally-occurring data and uses generalized implicature rules. Goyal et al. (2012) generate a lexicon of patient polarity verbs, which correspond to gfbf events whose spans are verbs. Riloff et al. (2013) investigate sarcasm where the writer holds a positive sentiment toward a negative situation. However, neither of these works performs sentiment inference. Graph-based models have been used f</context>
<context position="8015" citStr="Anand and Reschke, 2010" startWordPosition="1241" endWordPosition="1244">tivating the design of the graphbased method for sentiment analysis proposed below. The components of the framework are gfbf events, explicit sentiments, and rules operating over gfbf events and sentiments. The definition of a gfbf event is from (Deng et al., 2013). A GOODFOR event is an event that positively affects an entity (similarly, for BADFOR events). (Deng et al., 2013) point out that gfbf objects are not equivalent to benefactive/malefactive semantic roles. An example they give is She baked a cake for me: a cake is the object of GOODFOR event baked (creating something is good for it (Anand and Reschke, 2010)), while me is the filler of its benefactive semantic role (Z´u˜niga and Kittil¨a, 2010). Four implicature rule schemas are relevant for this paper.1 Four individual rules are covered by 1Implicatures “normally accompany the utterances of a given sentence unless special factors exclude that possibility 378 each schema. sent(α) = Q means that the writer’s sentiment toward α is Q, where α is a GOODFOR event, a BADFOR event, or the agent or object of a gfbf event, and Q is either positive or negative (pos or neg, for short). P —* Q is to infer Q from P. Rule1: sent(gfbf event) —* sent(object) 1.1</context>
</contexts>
<marker>Anand, Reschke, 2010</marker>
<rawString>Pranav Anand and Kevin Reschke. 2010. Verb classes as evaluativity functor classes. In Interdisciplinary Workshop on Verbs. The Identification and Representation of Verb Features.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yejin Choi</author>
<author>Claire Cardie</author>
</authors>
<title>Learning with compositional semantics as structural inference for subsentential sentiment analysis.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>793--801</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Honolulu, Hawaii,</location>
<contexts>
<context position="5639" citStr="Choi and Cardie, 2008" startWordPosition="854" endWordPosition="857">work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to determine one overall polarity of an expression or sentence. In contrast, our framework commits to a holder having sentiments toward various events and entities in the sentence, possibly of different polarities. The idea of gfbf events in sentiment analysis is not entirely new. For example, two papers mentioned above (Zhang and Liu, 2011; Choi and Cardie, 2008) include linguistic patterns for the tasks that they address that include gfbf events, but they don’t define general implicature rules relating senti</context>
</contexts>
<marker>Choi, Cardie, 2008</marker>
<rawString>Yejin Choi and Claire Cardie. 2008. Learning with compositional semantics as structural inference for subsentential sentiment analysis. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 793–801, Honolulu, Hawaii, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pradeep Dasigi</author>
<author>Weiwei Guo</author>
<author>Mona Diab</author>
</authors>
<title>Genre independent subgroup detection in online discussion threads: A study of implicit attitude using textual latent semantics.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>65--69</pages>
<institution>Jeju Island, Korea, July. Association for Computational Linguistics.</institution>
<contexts>
<context position="5411" citStr="Dasigi et al., 2012" startWordPosition="820" endWordPosition="823">y-automatic systems evaluated on the MPQA corpus (Wiebe et al., 2005), for example, a recent paper (Johansson and Moschitti, 2013) reports results that improve over previous work, yet the Fmeasures are in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to determine one overall polarity of an expression or sentence. In contrast, our framework commits to a holder having sentiments toward various events and entities in the sentence, possibly of different polarities. The idea of gfbf events in sentiment analysis is not entirely new. For e</context>
</contexts>
<marker>Dasigi, Guo, Diab, 2012</marker>
<rawString>Pradeep Dasigi, Weiwei Guo, and Mona Diab. 2012. Genre independent subgroup detection in online discussion threads: A study of implicit attitude using textual latent semantics. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 65–69, Jeju Island, Korea, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lingjia Deng</author>
<author>Yoonjung Choi</author>
<author>Janyce Wiebe</author>
</authors>
<title>Benefactive and malefactive event and writer attitude annotation.</title>
<date>2013</date>
<booktitle>In 51st Annual Meeting of the Association for Computational Linguistics (ACL2013,</booktitle>
<pages>short paper).</pages>
<contexts>
<context position="7656" citStr="Deng et al., 2013" startWordPosition="1178" endWordPosition="1181"> on a graph capturing the relations between users and tweets in Twitter data. However, they assume the nodes and the neighbors of nodes share the same sentiments. In contrast, we don’t assume that neighbors share the same sentiment, and the task we address is different. 3 Opinion Implicatures This section describes the opinion-implicature framework motivating the design of the graphbased method for sentiment analysis proposed below. The components of the framework are gfbf events, explicit sentiments, and rules operating over gfbf events and sentiments. The definition of a gfbf event is from (Deng et al., 2013). A GOODFOR event is an event that positively affects an entity (similarly, for BADFOR events). (Deng et al., 2013) point out that gfbf objects are not equivalent to benefactive/malefactive semantic roles. An example they give is She baked a cake for me: a cake is the object of GOODFOR event baked (creating something is good for it (Anand and Reschke, 2010)), while me is the filler of its benefactive semantic role (Z´u˜niga and Kittil¨a, 2010). Four implicature rule schemas are relevant for this paper.1 Four individual rules are covered by 1Implicatures “normally accompany the utterances of a </context>
<context position="11913" citStr="Deng et al., 2013" startWordPosition="1907" endWordPosition="1910">f E2. For E3, using Rule 1.4 we know the writer is positive toward patients and using Rule 3.4 we know the writer is negative toward companies. Turning to E4, support health care reform is GOODFOR reform. We already inferred the writer is positive toward reform. Rule 2.1 infers that the writer is positive toward E4. Rule 3.1 then infers that the writer is positive toward the agent of E4, Obama. In summary, we infer that the writer is positive toward E1, health care reform, E2, patients, E4, and Obama, and negative toward E3 and private insurance companies. 4 Data We use the data described in (Deng et al., 2013),2 which consists of 134 documents about a controversial topic, “the Affordable Care Act.” The documents are editorials and blogs, and are full of opinions. In the data, gfbf triples are annotated specifying the spans of the gfbf event, its agent, and its object, as well as the polarity of the gfbf event (GOODFOR or BADFOR), and the writer’s attitude toward the agent and object (positive, negative, or neutral). Influencers are also annotated. The agents of gfbf 2Available at http://mpqa.cs.pitt.edu 379 and influencer events are noun phrases. The object of a gfbf event is a noun phrase, but the</context>
</contexts>
<marker>Deng, Choi, Wiebe, 2013</marker>
<rawString>Lingjia Deng, Yoonjung Choi, and Janyce Wiebe. 2013. Benefactive and malefactive event and writer attitude annotation. In 51st Annual Meeting of the Association for Computational Linguistics (ACL2013, short paper).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Jun Sak Kang</author>
<author>Polina Kuznetsova</author>
<author>Yejin Choi</author>
</authors>
<title>Connotation lexicon: A dash of sentiment beneath the surface meaning.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics</booktitle>
<volume>2</volume>
<institution>Short Papers), Sofia, Bulgaria, Angust. Association for Computational Linguistics.</institution>
<contexts>
<context position="5207" citStr="Feng et al., 2013" startWordPosition="790" endWordPosition="793">sed toward different entities in a document, fine-grained analysis may be more informative for applications. However, fine-grained sentiment analysis remains a challenging task for NLP systems. For fully-automatic systems evaluated on the MPQA corpus (Wiebe et al., 2005), for example, a recent paper (Johansson and Moschitti, 2013) reports results that improve over previous work, yet the Fmeasures are in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to determine one overall polarity of an expression or sentence. In contrast, our fr</context>
<context position="19955" citStr="Feng et al., 2013" startWordPosition="3279" endWordPosition="3282">xplicit sentiment, both the positive and negative values are 0.5, indicating a neutral node. Thus, we build a sentiment classifier that takes a node as input and outputs a positive and a negative score. It is built from widely-used, freely available resources: the OpinionFinder (Wilson et al., 2005) and General Inquirer (Stone et al., 1966) lexicons and the OpinionFinder system.5 We also use a new Opinion Extraction system (Johansson and Moschitti, 2013) that shows better performance than previous work on fine-grained sentiment analysis,6 and a new automatically developed connotation lexicon (Feng et al., 2013).7 We implement a weighted voting method among these various sentiment resources. After that, for nodes that have not yet been assigned polar values (positive or negative), we implement a simple local discourse heuristic to try to assign them polar values. The particular strategies were chosen based only on a separate development set, which is not 5http://mpqa.cs.pitt.edu and http://www.wjh.harvard.edu/ inquirer/ 6As evaluated on the MPQA corpus. Note that the authors ran their system for us on the data we use. 7http://www.cs.stonybrook.edu/∼ychoi/connotation 381 included in the data used in t</context>
</contexts>
<marker>Feng, Kang, Kuznetsova, Choi, 2013</marker>
<rawString>Song Feng, Jun Sak Kang, Polina Kuznetsova, and Yejin Choi. 2013. Connotation lexicon: A dash of sentiment beneath the surface meaning. In Proceedings of the 51th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), Sofia, Bulgaria, Angust. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amit Goyal</author>
<author>Ellen Riloff</author>
<author>Hal Daum</author>
</authors>
<title>A computational model for plot units.</title>
<date>2012</date>
<journal>Computational Intelligence,</journal>
<pages>466--488</pages>
<contexts>
<context position="6628" citStr="Goyal et al. (2012)" startWordPosition="1012" endWordPosition="1015"> example, two papers mentioned above (Zhang and Liu, 2011; Choi and Cardie, 2008) include linguistic patterns for the tasks that they address that include gfbf events, but they don’t define general implicature rules relating sentiments and gfbf events, agents, and objects as we do. Recently, in linguistics, Anand and Reschke (2010; 2011) identify classes of gfbf terms, and carry out studies involving artificially constructed gfbf triples and corpus examples matching fixed linguistic templates. Our work focuses on gfbf triples in naturally-occurring data and uses generalized implicature rules. Goyal et al. (2012) generate a lexicon of patient polarity verbs, which correspond to gfbf events whose spans are verbs. Riloff et al. (2013) investigate sarcasm where the writer holds a positive sentiment toward a negative situation. However, neither of these works performs sentiment inference. Graph-based models have been used for various tasks in sentiment analysis. Some work (Wang et al., 2011; Tan et al., 2011) apply LBP on a graph capturing the relations between users and tweets in Twitter data. However, they assume the nodes and the neighbors of nodes share the same sentiments. In contrast, we don’t assum</context>
</contexts>
<marker>Goyal, Riloff, Daum, 2012</marker>
<rawString>Amit Goyal, Ellen Riloff, and Hal Daum III. 2012. A computational model for plot units. Computational Intelligence, pages 466–488.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rodney D Huddleston</author>
<author>Geoffrey K Pullum</author>
</authors>
<title>The Cambridge Grammar of the English Language.</title>
<date>2002</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="10175" citStr="Huddleston and Pullum, 2002" startWordPosition="1591" endWordPosition="1594">th care reform]? Because [reform] could lower [skyrocketing health care costs], and prohibit [private insurance companies] from overcharging [patients]. Suppose a sentiment analysis system recognizes only one explicit sentiment expression, skyrocketing. According to the annotations, there are several gfbf events. Each is listed below in the form (agent, gfbf, object). E1: (reform, lower, costs) E2: (reform, prohibit, E3 ) E3: (companies, overcharge, patients) E4: (Obama, support, reform) In E1, from the negative sentiment expressed by skyrocketing (the writer is negative toward the (p. 39).” (Huddleston and Pullum, 2002) costs because they are too high), and the fact that costs is the object of a BADFOR event (lower), Rule2.4 infers a positive attitude toward E1 . Now, Rule3.3 applies. We infer the writer is positive toward the reform, since it is the agent of E1, toward which the writer is positive. E2 illustrates the case where the object is an event. Specifically, the object of E2 is E3, a BADFOR event (overcharging). As we can see, E2 keeps E3 from happening. Events such as E2 are REVERSERs, because they reverse the polarity of a gfbf event (from BADFOR to GOODFOR, or vice versa). Note that REVERSERs may </context>
</contexts>
<marker>Huddleston, Pullum, 2002</marker>
<rawString>Rodney D. Huddleston and Geoffrey K. Pullum. 2002. The Cambridge Grammar of the English Language. Cambridge University Press, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Johansson</author>
<author>Alessandro Moschitti</author>
</authors>
<title>Relational features in fine-grained opinion analysis.</title>
<date>2013</date>
<journal>Computational Linguistics,</journal>
<volume>39</volume>
<issue>3</issue>
<contexts>
<context position="4921" citStr="Johansson and Moschitti, 2013" startWordPosition="741" endWordPosition="744">we use manually annotated gfbf information to build the graph. Thus, the evaluations in this paper are able to demonstrate the promise of the overall framework itself. 2 Related Work Much work in sentiment analysis has been on document-level classification. Since different sentiments may be expressed toward different entities in a document, fine-grained analysis may be more informative for applications. However, fine-grained sentiment analysis remains a challenging task for NLP systems. For fully-automatic systems evaluated on the MPQA corpus (Wiebe et al., 2005), for example, a recent paper (Johansson and Moschitti, 2013) reports results that improve over previous work, yet the Fmeasures are in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Sever</context>
<context position="19795" citStr="Johansson and Moschitti, 2013" startWordPosition="3254" endWordPosition="3258">. If it is a positive node, then its positive value ranges from 0.5 to 1, and its negative value ranges from 0 to 0.5 (similarly for negative nodes). For any node without explicit sentiment, both the positive and negative values are 0.5, indicating a neutral node. Thus, we build a sentiment classifier that takes a node as input and outputs a positive and a negative score. It is built from widely-used, freely available resources: the OpinionFinder (Wilson et al., 2005) and General Inquirer (Stone et al., 1966) lexicons and the OpinionFinder system.5 We also use a new Opinion Extraction system (Johansson and Moschitti, 2013) that shows better performance than previous work on fine-grained sentiment analysis,6 and a new automatically developed connotation lexicon (Feng et al., 2013).7 We implement a weighted voting method among these various sentiment resources. After that, for nodes that have not yet been assigned polar values (positive or negative), we implement a simple local discourse heuristic to try to assign them polar values. The particular strategies were chosen based only on a separate development set, which is not 5http://mpqa.cs.pitt.edu and http://www.wjh.harvard.edu/ inquirer/ 6As evaluated on the MP</context>
</contexts>
<marker>Johansson, Moschitti, 2013</marker>
<rawString>Richard Johansson and Alessandro Moschitti. 2013. Relational features in fine-grained opinion analysis. Computational Linguistics, 39(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment Analysis and Opinion Mining.</title>
<date>2012</date>
<publisher>Morgan &amp; Claypool.</publisher>
<contexts>
<context position="5680" citStr="Liu, 2012" startWordPosition="863" endWordPosition="864">ddress implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to determine one overall polarity of an expression or sentence. In contrast, our framework commits to a holder having sentiments toward various events and entities in the sentence, possibly of different polarities. The idea of gfbf events in sentiment analysis is not entirely new. For example, two papers mentioned above (Zhang and Liu, 2011; Choi and Cardie, 2008) include linguistic patterns for the tasks that they address that include gfbf events, but they don’t define general implicature rules relating sentiments and gfbf events, agents, and object</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment Analysis and Opinion Mining. Morgan &amp; Claypool.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karo Moilanen</author>
<author>Stephen Pulman</author>
</authors>
<title>Sentiment composition.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP</booktitle>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="5616" citStr="Moilanen and Pulman, 2007" startWordPosition="849" endWordPosition="853">e in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to determine one overall polarity of an expression or sentence. In contrast, our framework commits to a holder having sentiments toward various events and entities in the sentence, possibly of different polarities. The idea of gfbf events in sentiment analysis is not entirely new. For example, two papers mentioned above (Zhang and Liu, 2011; Choi and Cardie, 2008) include linguistic patterns for the tasks that they address that include gfbf events, but they don’t define general implicatu</context>
</contexts>
<marker>Moilanen, Pulman, 2007</marker>
<rawString>Karo Moilanen and Stephen Pulman. 2007. Sentiment composition. In Proceedings of RANLP 2007, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karo Moilanen</author>
<author>Stephen Pulman</author>
<author>Yue Zhang</author>
</authors>
<title>Packed feelings and ordered sentiments: Sentiment parsing with quasi-compositional polarity sequencing and compression.</title>
<date>2010</date>
<booktitle>In Proceedings of the 1st Workshop on Computational Approaches to Subjectivity and Sentiment Analysis (WASSA</booktitle>
<pages>36--43</pages>
<contexts>
<context position="5663" citStr="Moilanen et al., 2010" startWordPosition="858" endWordPosition="861">xplicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to determine one overall polarity of an expression or sentence. In contrast, our framework commits to a holder having sentiments toward various events and entities in the sentence, possibly of different polarities. The idea of gfbf events in sentiment analysis is not entirely new. For example, two papers mentioned above (Zhang and Liu, 2011; Choi and Cardie, 2008) include linguistic patterns for the tasks that they address that include gfbf events, but they don’t define general implicature rules relating sentiments and gfbf events, a</context>
</contexts>
<marker>Moilanen, Pulman, Zhang, 2010</marker>
<rawString>Karo Moilanen, Stephen Pulman, and Yue Zhang. 2010. Packed feelings and ordered sentiments: Sentiment parsing with quasi-compositional polarity sequencing and compression. In Proceedings of the 1st Workshop on Computational Approaches to Subjectivity and Sentiment Analysis (WASSA 2010), pages 36–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pearl</author>
</authors>
<title>Reverend bayes on inference engines: A distributed hierarchical approach.</title>
<date>1982</date>
<booktitle>In Proceedings of the American Association ofArtificial Intelligence National Conference on AI,</booktitle>
<pages>133--136</pages>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="3470" citStr="Pearl, 1982" startWordPosition="529" endWordPosition="530">’s sentiments toward entities mentioned in the text. We introduce four rule schemas which reveal sentiment constraints among gfbf events and their agents and objects. Those constraints are incorporated into a graph-based model, where a node represents an entity (agent/object), and an edge exists between two nodes if the two entities participate in one or more gfbf events with each other. Scores on the nodes represent the explicit sentiments, if any, expressed by the writer toward the entities. Scores on the edges are based on constraints derived from the rules. Loopy Belief Propagation (LBP) (Pearl, 1982) is applied to 377 Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 377–385, Gothenburg, Sweden, April 26-30 2014. c�2014 Association for Computational Linguistics accomplish sentiment propagation in the graph. Two evaluations are performed. The first shows that the graph-based model improves over an explicit sentiment classification system. The second evaluates the graph-based model itself (and hence the implicature rules), assessing its ability to correctly propagate sentiments to nodes whose polarities are unknown. We find it</context>
<context position="15321" citStr="Pearl, 1982" startWordPosition="2489" endWordPosition="2490">n a GOODFOR, so the edge linking the two is GOODFOR.4 Given a text, we get the spans of gfbf events and their agents and objects plus the polarities of the events (GOODFOR/BADFOR) from the manual annotations, and then build the graph upon them. However, the manual annotations of the writer’s sentiments toward the agents and objects are used as the gold standard for evaluation. 5.2 Sentiment Inference via LBP Table 1: Loopy Belief Propagation With graph EG containing cycles and no apparent structure, we utilize an approximate collective classification algorithm, loopy belief propagation (LBP) (Pearl, 1982; Yedidia et al., 2005), to classify nodes through belief message passing. The algorithm is shown in Table 1. In LBP, each node has a score, Φi(y), and each edge has a score, &apos;Fij(yi, yj). In our case, Φi(y) represents the writer’s explicit sentiment toward ni. &apos;Fij(yi, yj) is the score on edge eij, representing the likelihood that node ni has polarity yi and nj has polarity yj. The specific definitions of the two functions are given in Sections 5.3 and 5.4. LBP is an iterative message passing algorithm. A message from ni to nj over edge eij has two values: mi→j(pos) is how much information fr</context>
</contexts>
<marker>Pearl, 1982</marker>
<rawString>J. Pearl. 1982. Reverend bayes on inference engines: A distributed hierarchical approach. In Proceedings of the American Association ofArtificial Intelligence National Conference on AI, pages 133–136, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Reschke</author>
<author>Pranav Anand</author>
</authors>
<title>Extracting contextual evaluativity.</title>
<date>2011</date>
<booktitle>In Proceedings of the Ninth International Conference on Computational Semantics, IWCS ’11,</booktitle>
<pages>370--374</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Reschke, Anand, 2011</marker>
<rawString>Kevin Reschke and Pranav Anand. 2011. Extracting contextual evaluativity. In Proceedings of the Ninth International Conference on Computational Semantics, IWCS ’11, pages 370–374, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Ashequl Qadir</author>
<author>Prafulla Surve</author>
<author>Lalindra De Silva</author>
<author>Nathan Gilbert</author>
<author>Ruihong Huang</author>
</authors>
<title>Sarcasm as contrast between a positive sentiment and negative situation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>704--714</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<marker>Riloff, Qadir, Surve, De Silva, Gilbert, Huang, 2013</marker>
<rawString>Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra De Silva, Nathan Gilbert, and Ruihong Huang. 2013. Sarcasm as contrast between a positive sentiment and negative situation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 704–714, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Stone</author>
<author>D C Dunphy</author>
<author>M S Smith</author>
<author>D M Ogilvie</author>
</authors>
<title>The General Inquirer: A Computer Approach to Content Analysis.</title>
<date>1966</date>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="19679" citStr="Stone et al., 1966" startWordPosition="3237" endWordPosition="3240">ument. Since y ranges over (pos, neg), each node has a positive and a negative score; the scores sum to 1. If it is a positive node, then its positive value ranges from 0.5 to 1, and its negative value ranges from 0 to 0.5 (similarly for negative nodes). For any node without explicit sentiment, both the positive and negative values are 0.5, indicating a neutral node. Thus, we build a sentiment classifier that takes a node as input and outputs a positive and a negative score. It is built from widely-used, freely available resources: the OpinionFinder (Wilson et al., 2005) and General Inquirer (Stone et al., 1966) lexicons and the OpinionFinder system.5 We also use a new Opinion Extraction system (Johansson and Moschitti, 2013) that shows better performance than previous work on fine-grained sentiment analysis,6 and a new automatically developed connotation lexicon (Feng et al., 2013).7 We implement a weighted voting method among these various sentiment resources. After that, for nodes that have not yet been assigned polar values (positive or negative), we implement a simple local discourse heuristic to try to assign them polar values. The particular strategies were chosen based only on a separate deve</context>
</contexts>
<marker>Stone, Dunphy, Smith, Ogilvie, 1966</marker>
<rawString>P.J. Stone, D.C. Dunphy, M.S. Smith, and D.M. Ogilvie. 1966. The General Inquirer: A Computer Approach to Content Analysis. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chenhao Tan</author>
<author>Lillian Lee</author>
<author>Jie Tang</author>
<author>Long Jiang</author>
<author>Ming Zhou</author>
<author>Ping Li</author>
</authors>
<title>User-level sentiment analysis incorporating social networks.</title>
<date>2011</date>
<booktitle>In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining,</booktitle>
<pages>1397--1405</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="7028" citStr="Tan et al., 2011" startWordPosition="1077" endWordPosition="1080">g artificially constructed gfbf triples and corpus examples matching fixed linguistic templates. Our work focuses on gfbf triples in naturally-occurring data and uses generalized implicature rules. Goyal et al. (2012) generate a lexicon of patient polarity verbs, which correspond to gfbf events whose spans are verbs. Riloff et al. (2013) investigate sarcasm where the writer holds a positive sentiment toward a negative situation. However, neither of these works performs sentiment inference. Graph-based models have been used for various tasks in sentiment analysis. Some work (Wang et al., 2011; Tan et al., 2011) apply LBP on a graph capturing the relations between users and tweets in Twitter data. However, they assume the nodes and the neighbors of nodes share the same sentiments. In contrast, we don’t assume that neighbors share the same sentiment, and the task we address is different. 3 Opinion Implicatures This section describes the opinion-implicature framework motivating the design of the graphbased method for sentiment analysis proposed below. The components of the framework are gfbf events, explicit sentiments, and rules operating over gfbf events and sentiments. The definition of a gfbf event</context>
</contexts>
<marker>Tan, Lee, Tang, Jiang, Zhou, Li, 2011</marker>
<rawString>Chenhao Tan, Lillian Lee, Jie Tang, Long Jiang, Ming Zhou, and Ping Li. 2011. User-level sentiment analysis incorporating social networks. In Proceedings of the 17th ACM SIGKDD international conference on Knowledge discovery and data mining, pages 1397–1405. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaolong Wang</author>
<author>Furu Wei</author>
<author>Xiaohua Liu</author>
<author>Ming zhou</author>
<author>Ming Zhang</author>
</authors>
<title>Topic sentiment anaylsis in twitter: A graph-based hashtag sentiment classification appraoch.</title>
<date>2011</date>
<booktitle>In CIKM,</booktitle>
<pages>1031--1040</pages>
<contexts>
<context position="7009" citStr="Wang et al., 2011" startWordPosition="1073" endWordPosition="1076">ut studies involving artificially constructed gfbf triples and corpus examples matching fixed linguistic templates. Our work focuses on gfbf triples in naturally-occurring data and uses generalized implicature rules. Goyal et al. (2012) generate a lexicon of patient polarity verbs, which correspond to gfbf events whose spans are verbs. Riloff et al. (2013) investigate sarcasm where the writer holds a positive sentiment toward a negative situation. However, neither of these works performs sentiment inference. Graph-based models have been used for various tasks in sentiment analysis. Some work (Wang et al., 2011; Tan et al., 2011) apply LBP on a graph capturing the relations between users and tweets in Twitter data. However, they assume the nodes and the neighbors of nodes share the same sentiments. In contrast, we don’t assume that neighbors share the same sentiment, and the task we address is different. 3 Opinion Implicatures This section describes the opinion-implicature framework motivating the design of the graphbased method for sentiment analysis proposed below. The components of the framework are gfbf events, explicit sentiments, and rules operating over gfbf events and sentiments. The definit</context>
</contexts>
<marker>Wang, Wei, Liu, zhou, Zhang, 2011</marker>
<rawString>Xiaolong Wang, Furu Wei, Xiaohua Liu, Ming zhou, and Ming Zhang. 2011. Topic sentiment anaylsis in twitter: A graph-based hashtag sentiment classification appraoch. In CIKM, pages 1031–1040.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Claire Cardie</author>
</authors>
<title>Annotating expressions of opinions and emotions in language ann. Language Resources and Evaluation,</title>
<date>2005</date>
<pages>39--2</pages>
<contexts>
<context position="4860" citStr="Wiebe et al., 2005" startWordPosition="732" endWordPosition="735">nate interference introduced by other components, we use manually annotated gfbf information to build the graph. Thus, the evaluations in this paper are able to demonstrate the promise of the overall framework itself. 2 Related Work Much work in sentiment analysis has been on document-level classification. Since different sentiments may be expressed toward different entities in a document, fine-grained analysis may be more informative for applications. However, fine-grained sentiment analysis remains a challenging task for NLP systems. For fully-automatic systems evaluated on the MPQA corpus (Wiebe et al., 2005), for example, a recent paper (Johansson and Moschitti, 2013) reports results that improve over previous work, yet the Fmeasures are in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between aut</context>
</contexts>
<marker>Wiebe, Wilson, Cardie, 2005</marker>
<rawString>Janyce Wiebe, Theresa Wilson, and Claire Cardie. 2005. Annotating expressions of opinions and emotions in language ann. Language Resources and Evaluation, 39(2/3):164–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Paul Hoffmann</author>
</authors>
<title>Recognizing contextual polarity in phraselevel sentiment analysis.</title>
<date>2005</date>
<booktitle>In HLT/EMNLP,</booktitle>
<pages>347--354</pages>
<contexts>
<context position="19637" citStr="Wilson et al., 2005" startWordPosition="3230" endWordPosition="3233">by the writer toward that entity in the document. Since y ranges over (pos, neg), each node has a positive and a negative score; the scores sum to 1. If it is a positive node, then its positive value ranges from 0.5 to 1, and its negative value ranges from 0 to 0.5 (similarly for negative nodes). For any node without explicit sentiment, both the positive and negative values are 0.5, indicating a neutral node. Thus, we build a sentiment classifier that takes a node as input and outputs a positive and a negative score. It is built from widely-used, freely available resources: the OpinionFinder (Wilson et al., 2005) and General Inquirer (Stone et al., 1966) lexicons and the OpinionFinder system.5 We also use a new Opinion Extraction system (Johansson and Moschitti, 2013) that shows better performance than previous work on fine-grained sentiment analysis,6 and a new automatically developed connotation lexicon (Feng et al., 2013).7 We implement a weighted voting method among these various sentiment resources. After that, for nodes that have not yet been assigned polar values (positive or negative), we implement a simple local discourse heuristic to try to assign them polar values. The particular strategies</context>
</contexts>
<marker>Wilson, Wiebe, Hoffmann, 2005</marker>
<rawString>Theresa Wilson, Janyce Wiebe, and Paul Hoffmann. 2005. Recognizing contextual polarity in phraselevel sentiment analysis. In HLT/EMNLP, pages 347–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan S Yedidia</author>
<author>William T Freeman</author>
<author>Yair Weiss</author>
</authors>
<title>Constructing free-energy approximations and generalized belief propagation algorithms. Information Theory,</title>
<date>2005</date>
<journal>IEEE Transactions on,</journal>
<volume>51</volume>
<issue>7</issue>
<contexts>
<context position="15344" citStr="Yedidia et al., 2005" startWordPosition="2491" endWordPosition="2494">so the edge linking the two is GOODFOR.4 Given a text, we get the spans of gfbf events and their agents and objects plus the polarities of the events (GOODFOR/BADFOR) from the manual annotations, and then build the graph upon them. However, the manual annotations of the writer’s sentiments toward the agents and objects are used as the gold standard for evaluation. 5.2 Sentiment Inference via LBP Table 1: Loopy Belief Propagation With graph EG containing cycles and no apparent structure, we utilize an approximate collective classification algorithm, loopy belief propagation (LBP) (Pearl, 1982; Yedidia et al., 2005), to classify nodes through belief message passing. The algorithm is shown in Table 1. In LBP, each node has a score, Φi(y), and each edge has a score, &apos;Fij(yi, yj). In our case, Φi(y) represents the writer’s explicit sentiment toward ni. &apos;Fij(yi, yj) is the score on edge eij, representing the likelihood that node ni has polarity yi and nj has polarity yj. The specific definitions of the two functions are given in Sections 5.3 and 5.4. LBP is an iterative message passing algorithm. A message from ni to nj over edge eij has two values: mi→j(pos) is how much information from node ni indicates no</context>
</contexts>
<marker>Yedidia, Freeman, Weiss, 2005</marker>
<rawString>Jonathan S Yedidia, William T Freeman, and Yair Weiss. 2005. Constructing free-energy approximations and generalized belief propagation algorithms. Information Theory, IEEE Transactions on, 51(7):2282–2312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lei Zhang</author>
<author>Bing Liu</author>
</authors>
<title>Identifying noun product features that imply opinions.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>575--580</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="5131" citStr="Zhang and Liu, 2011" startWordPosition="777" endWordPosition="780">een on document-level classification. Since different sentiments may be expressed toward different entities in a document, fine-grained analysis may be more informative for applications. However, fine-grained sentiment analysis remains a challenging task for NLP systems. For fully-automatic systems evaluated on the MPQA corpus (Wiebe et al., 2005), for example, a recent paper (Johansson and Moschitti, 2013) reports results that improve over previous work, yet the Fmeasures are in the 40s and 50s. Most work in NLP addresses explicit sentiment, but some address implicit sentiment. For example, (Zhang and Liu, 2011) identify noun product features that imply opinions, and (Feng et al., 2013) identify objective words that have positive or negative connotations. However, identifying terms that imply opinions is a different task than sentiment propagation between entities. (Dasigi et al., 2012) search for implicit attitudes shared between authors, while we address inferences within a single text. Several papers apply compositional semantics to determine polarity (e.g., (Moilanen and Pulman, 2007; Choi and Cardie, 2008; Moilanen et al., 2010); see (Liu, 2012) for an overview). The goal of such work is to dete</context>
</contexts>
<marker>Zhang, Liu, 2011</marker>
<rawString>Lei Zhang and Bing Liu. 2011. Identifying noun product features that imply opinions. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 575–580, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Z´u˜niga</author>
<author>S Kittil¨a</author>
</authors>
<date>2010</date>
<booktitle>Benefactives and malefactives, Typological studies in</booktitle>
<editor>Introduction. In F. Z´u˜niga and S. Kittil¨a, editors,</editor>
<publisher>Benjamins Publishing Company.</publisher>
<marker>Z´u˜niga, Kittil¨a, 2010</marker>
<rawString>F. Z´u˜niga and S. Kittil¨a. 2010. Introduction. In F. Z´u˜niga and S. Kittil¨a, editors, Benefactives and malefactives, Typological studies in language. J. Benjamins Publishing Company.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>