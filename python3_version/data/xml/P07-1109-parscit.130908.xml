<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001208">
<title confidence="0.9984675">
Bootstrapping a Stochastic Transducer
for Arabic-English Transliteration Extraction
</title>
<author confidence="0.994439">
Tarek Sherif and Grzegorz Kondrak
</author>
<affiliation confidence="0.998934">
Department of Computing Science
University of Alberta
</affiliation>
<address confidence="0.565349">
Edmonton, Alberta, Canada T6G 2E8
</address>
<email confidence="0.999001">
{tarek,kondrak}@cs.ualberta.ca
</email>
<sectionHeader confidence="0.998601" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9961345">
We propose a bootstrapping approach to
training a memoriless stochastic transducer
for the task of extracting transliterations
from an English-Arabic bitext. The trans-
ducer learns its similarity metric from the
data in the bitext, and thus can func-
tion directly on strings written in different
writing scripts without any additional lan-
guage knowledge. We show that this boot-
strapped transducer performs as well or bet-
ter than a model designed specifically to de-
tect Arabic-English transliterations.
</bodyText>
<sectionHeader confidence="0.999524" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999548098039216">
Transliterations are words that are converted from
one writing script to another on the basis of their pro-
nunciation, rather than being translated on the basis
of their meaning. Transliterations include named en-
tities (e.g.Xð10-.t.g./Jane Austen) and lexical loans
(e.g.vñK��Q��aÊ�K/television).
An algorithm to detect transliterations automati-
cally in a bitext can be an effective tool for many
tasks. Models of machine transliteration such as
those presented in (Al-Onaizan and Knight, 2002) or
(AbdulJaleel and Larkey, 2003) require a large set of
sample transliterations to use for training. If such a
training set is unavailable for a particular language
pair, a detection algorithm would lead to a signif-
icant gain in time over attempting to build the set
manually. Algorithms for cross-language informa-
tion retrieval often encounter the problem of out-of-
vocabulary words, or words not present in the algo-
rithm’s lexicon. Often, a significant proportion of
these words are named entities and thus are candi-
dates for transliteration. A transliteration detection
algorithm could be used to map named entities in a
query to potential transliterations in the target lan-
guage text.
The main challenge in transliteration detection
lies in the fact that transliteration is a lossy process.
In other words, information can be lost about the
original word when it is transliterated. This can oc-
cur because of phonetic gaps in one language or the
other. For example, the English [p] sound does not
exist in Arabic, and the Arabic [s] sound (made by
the letter ¨) does not exist in English. Thus, Paul is
transliterated as ÈñK.[bul], and Î« [sali] is translit-
erated as Ali. Another form of l6ss occurs when the
relationship between the orthographic and phonetic
representations of a word are unclear. For example,
the [k] sound will always be written with the letter1/4
in Arabic, but in English it can be written as c, k ch,
ck, cc or kk (not to mention being one of the sounds
produced by x). Finally, letters may be deleted in
one language or the other. In Arabic, short vowels
will often be omitted (e.g. �/Yousef), while in
English the ArabicZand¨are often deleted (e.g.
ÉJ�«AÖÞ...VIsmael).
We explore the use of word similarity metrics on
the task of Arabic-English transliteration detection
and extraction. One of our primary goals in explor-
ing these metrics is to assess whether it is possible
maintain high performance without making the al-
gorithms language-specific. Many word-similarity
metrics require that the strings being compared be
</bodyText>
<page confidence="0.991392">
864
</page>
<note confidence="0.9254495">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 864–871,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.99997118">
written in the same script. Levenshtein edit distance,
for example, does not produce a meaningful score in
the absence of character identities. Thus, if these
metrics are to be used for transliteration extraction,
modifications must be made to allow them to com-
pare different scripts.
Freeman et al. (2006) take the approach of man-
ually encoding a great deal of language knowl-
edge directly into their Arabic-English fuzzy match-
ing algorithm. They define equivalence classes be-
tween letters in the two scripts and perform several
rule-based transformations to make word pairs more
comparable. This approach is unattractive for two
reasons. Firstly, predicting all possible relationships
between letters in English and Arabic is difficult.
For example, allowances have to be made for un-
usual pronunciations in foreign words such as the ch
in clich´e or the c in Milosevic. Secondly, the algo-
rithm becomes completely language-specific, which
means that it cannot be used for any other language
pair.
We propose a method to learn letter relation-
ships directly from the bitext containing the translit-
erations. Our model is based on the memoriless
stochastic transducer proposed by Ristad and Yian-
ilos (1998), which derives a probabilistic word-
similarity function from a set of examples. The
transducer is able to learn edit distance costs be-
tween disjoint sets of characters representing dif-
ferent writing scripts without any language-specific
knowledge. The transducer approach, however, re-
quires a large set of training examples, which is a
limitation not present in the fuzzy matching algo-
rithm. Thus, we propose a bootstrapping approach
(Yarowsky, 1995) to train the stochastic transducer
iteratively as it extracts transliterations from a bi-
text. The bootstrapped stochastic transducer is com-
pletely language-independent, and we show that it is
able to perform at least as well as the Arabic-English
specific fuzzy matching algorithm.
The remainder of this paper is organized as fol-
lows. Section 2 presents our bootstrapping method
to train a stochastic transducer. Section 3 outlines
the Arabic-English fuzzy matching algorithm. Sec-
tion 4 discusses other word-similarity models used
for comparison. Section 5 describes the results of
two experiments performed to test the models. Sec-
tion 6 briefly discusses previous approaches to de-
tecting transliterations. Section 7 presents our con-
clusions and possibilities for future work.
</bodyText>
<subsectionHeader confidence="0.5112995">
2 Bootstrapping with a Stochastic
Transducer
</subsectionHeader>
<bodyText confidence="0.999953428571428">
Ristad and Yianilos (1998) propose a probabilistic
framework for word similarity, in which the simi-
larity of a pair of words is defined as the sum of
the probabilities of all paths through a memoriless
stochastic transducer that generate the pair of words.
This is referred to as the forward score of the pair of
words. They outline a forward-backward algorithm
to train the model and show that it outperforms Lev-
enshtein edit distance on the task of pronunciation
classification.
The training algorithm begins by calling the for-
ward (Equation 1) and backward (Equation 2) func-
tions to fill in the F and B tables for training pair s
and t with respective lengths I and J.
</bodyText>
<equation confidence="0.994615">
F(0, 0) = 1
F(i,j) = P(si, ǫ)F(i − 1,j)
+P(ǫ, tj)F(i, j − 1)
+P(si, tj)F(i − 1, j − 1)
B(I, J) = 1
B(i, j) = P(si+1, ǫ)B(i + 1,j)
+P(ǫ,tj+1)B(i,j + 1)
+P(si+1, tj+1)B(i + 1, j + 1)
</equation>
<bodyText confidence="0.999927909090909">
The forward value at each position (i, j) in the F
matrix signifies the sum of the probabilities of all
paths through the transducer that produce the prefix
pair (si1, tj1), while B(i, j) contains the sum of the
probabilities of all paths through the transducer that
generate the suffix pair (sIi+1,tJj+1). These tables
can then be used to collect partial counts to update
the probabilities. For example, the mapping (si, tj)
would contribute a count according to Equation 3.
These counts are then normalized to produce the up-
dated probability distribution.
</bodyText>
<equation confidence="0.909558333333333">
F(i − 1, j − 1)P(si, tj)B(i, j)
C(si,tj)+ = (3)
F(I, J)
</equation>
<bodyText confidence="0.984152">
The major issue in porting the memoriless trans-
ducer over to our task of transliteration extraction
</bodyText>
<page confidence="0.997454">
865
</page>
<bodyText confidence="0.9998895625">
is that its training is supervised. In other words, it
would require a relatively large set of known translit-
erations for training, and this is exactly what we
would like the model to acquire. In order to over-
come this problem, we look to the bootstrapping
method outlined in (Yarowsky, 1995). Yarowsky
trains a rule-based classifier for word sense disam-
biguation by starting with a small set of seed ex-
amples for which the sense is known. The trained
classifier is then used to label examples for which
the sense is unknown, and these newly labeled ex-
amples are then used to retrain the classifier. The
process is repeated until convergence.
Our method uses a similar approach to train the
stochastic transducer. The algorithm proceeds as
follows:
</bodyText>
<listItem confidence="0.9963867">
1. Initialize the training set with the seed pairs.
2. Train the transducer using the forward-
backward algorithm on the current training set.
3. Calculate the forward score for all word pairs
under consideration.
4. If the forward score for a pair of words is above
a predetermined acceptance threshold, add the
pair to the training set.
5. Repeat steps 2-4 until the training set ceases to
grow.
</listItem>
<bodyText confidence="0.998484666666667">
Once training stops, the transducer can be used
to score pairs of words not in the training set. For
our experiments, the acceptance threshold was op-
timized on a separate development set. Forward
scores were normalized by the average of the lengths
of the two words.
</bodyText>
<sectionHeader confidence="0.96031" genericHeader="method">
3 Arabic-English Fuzzy String Matching
</sectionHeader>
<bodyText confidence="0.9998526">
In this section, we outline the fuzzy string matching
algorithm proposed by Freeman et al. (2006). The
algorithm is based on the standard Levenshtein dis-
tance approach, but encodes a great deal of knowl-
edge about the relationships between English and
Arabic letters.
Initially, the candidate word pair is modified in
two ways. The first transformation is a rule-based
letter normalization of both words. Some examples
of normalization include:
</bodyText>
<listItem confidence="0.950583">
• English double letter collapse: e.g.
Miller—*Miler.
</listItem>
<table confidence="0.9973775">
I,I,ÆI,øH a,e,i,o,u H.H b,p,v
�H,,�HH t h.H j,g
H d,z ,e,o,u
¨,ZH� ,c,a,i
†H q,g,k `=Hk,c,s
ø H y,i,e,j o H a,e
</table>
<tableCaption confidence="0.994074">
Table 1: A sample of the letter equivalence classes
for fuzzy string matching.
</tableCaption>
<construct confidence="0.44608275">
Algorithm VowelNorm (Estring, Astring)
for each i := 0 to min(|Estring|, |Astring|)
for each j := 0 to min(|Estring|, |Astring|)
if Astringi = Estringj
</construct>
<equation confidence="0.977593357142857">
Outstring. = Estringj; i + +; j + +;
if vowel(Astringi) n vowel(Estringj)
Outstring. = Estringj; i + +; j + +;
if -vowel(Astringi) n vowel(Estringj)
j + +;
if j &lt; |Estringj|
Outstring. = Estringj; i + +; j + +;
else
Outstring. = Estringj; i + +; j + +;
while j &lt; |Estring|
if -vowel(Estringj)
Outstring. = Estringj;
j + +;
return Outstring;
</equation>
<figureCaption confidence="0.9847355">
Figure 1: Pseudocode for the vowel transformation
procedure.
</figureCaption>
<bodyText confidence="0.312876">
L
</bodyText>
<listItem confidence="0.975008">
• Arabic hamza collapse: e.g. ¬Qå~... i _Q I.
• Individual letter normalizations: e.g. Hen-
drix—*Hendriks or
</listItem>
<bodyText confidence="0.9995158">
The second transformation is an iteration through
both words to remove any vowels in the English
word for which there is no similarly positioned
vowel in the Arabic word. The pseudocode for our
implementation of this vowel transformation is pre-
sented in Figure 1.
After letter and vowel transformations, the Leven-
shtein distance is computed using the letter equiva-
lences as matches instead of identities. Some equiv-
alence classes between English and Arabic letters
are shown in Table 1. The Arabic and English letters
within a class are treated as identities. For example,
the Arabicjcan match both f and v in English with
no cost. The resulting Levenshtein distance is nor-
malized by the sum of the lengths of both words.
</bodyText>
<page confidence="0.988845">
866
</page>
<table confidence="0.9988295">
Levenshtein ALINE Fuzzy Match Bootstrap
Lang.-specific No No Yes No
Preprocessing Romanization Phon. Conversion None None
Data-driven No No No Yes
</table>
<tableCaption confidence="0.999847">
Table 2: Comparison of the word-similarity models.
</tableCaption>
<bodyText confidence="0.999459571428572">
Several other modifications, such as light stem-
ming and multiple passes to discover more diffi-
cult mappings, were also proposed, but they were
found to influence performance minimally. Thus,
the equivalence classes and transformations are the
only modifications we reproduce for our experi-
ments here.
</bodyText>
<sectionHeader confidence="0.998524" genericHeader="method">
4 Other Models of Word Similarity
</sectionHeader>
<bodyText confidence="0.9999675">
In this section, we present two models of word simi-
larity used for purposes of comparison. Levenshtein
distance and ALINE are not language-specific per
se, but require that the words being compared be
written in a common script. Thus, they require some
language knowledge in order to convert one or both
of the words into the common script. A comparison
of all the models presented is given in Table 2.
</bodyText>
<subsectionHeader confidence="0.991418">
4.1 Levenshtein Edit Distance
</subsectionHeader>
<bodyText confidence="0.999977333333333">
As a baseline for our experiments, we used Leven-
shtein edit distance. The algorithm simply counts
the minimum number of insertions, deletions and
substitutions required to convert one string into an-
other. Levenshtein distance depends on finding iden-
tical letters, so both words must use the same al-
phabet. Prior to comparison, we convert the Ara-
bic words into the Latin alphabet using the intuitive
mappings for each letter shown in Table 3. The
distances are also normalized by the length of the
longer of the two words to avoid excessively penal-
izing longer words.
</bodyText>
<subsectionHeader confidence="0.868083">
4.2 ALINE
</subsectionHeader>
<bodyText confidence="0.999214857142857">
Unlike other algorithms presented here, the ALINE
algorithm (Kondrak, 2000) operates in the phonetic,
rather than the orthographic, domain. It was orig-
inally designed to identify cognates in related lan-
guages, but it can be used to compute similarity be-
tween any pair of words, provided that they are ex-
pressed in a standard phonetic notation. Individual
</bodyText>
<table confidence="0.99775525">
~,Æ aH.→ b�H,→
��,Z→ t
�,h,è→ �H→ th h.→ j
a
�è→ hp→ khX,�•→
� d
X, th P→ r
€,•→ s �€→ sh ¨→ ’
���→ ¬→ f �P→ z
¨→ g �†→ q
1/4→ k È→ l �→ m
à→ n ð→ w ø�→ y
</table>
<tableCaption confidence="0.862017">
Table 3: Arabic Romanization for Levenshtein dis-
tance.
</tableCaption>
<bodyText confidence="0.999723625">
phonemes input to the algorithm are decomposed
into a dozen phonetic features, such as Place, Man-
ner and Voice. A substitution score between a pair
of phonemes is based on the similarity as assessed
by a comparison of the individual features. After
an optimal alignment of the two words is computed
with a dynamic programming algorithm, the overall
similarity score is set to the sum of the scores of all
links in the alignment normalized by the length of
the longer of the two words.
In our experiments, the Arabic and English words
were converted into phonetic transcriptions using a
deterministic rule-based transformation. The tran-
scriptions were only approximate, especially for En-
glish vowels. Arabic emphatic consonants were de-
pharyngealized.
</bodyText>
<sectionHeader confidence="0.999475" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999771375">
The word-similarity metrics were evaluated on two
separate tasks. In experiment 1 (Section 5.1) the
task was to extract transliterations from a sentence
aligned bitext. Experiment 2 (Section 5.2) provides
the algorithms with named entities from an English
document and requires them to extract the transliter-
ations from the document’s Arabic translation.
The two bitexts used in the experiments were the
</bodyText>
<page confidence="0.996685">
867
</page>
<figureCaption confidence="0.999796">
Figure 2: Precision per number of words extracted for the various algorithms from a sentence-aligned bitext.
</figureCaption>
<bodyText confidence="0.99988775">
Arabic Treebank Part 1-10k word English Transla-
tion corpus and the Arabic English Parallel News
Part 1 corpus (approx. 2.5M words). Both bi-
texts contain Arabic news articles and their English
translations aligned at the sentence level, and both
are available from the Linguistic Date Consortium.
The Treebank data was used as a development set
to optimize the acceptance threshold used by the
bootstrapped transducer. Testing for the sentence-
aligned extraction task was done on the first 20k
sentences (approx. 50k words) of the parallel news
data, while the named entity extraction task was per-
formed on the first 1000 documents of the paral-
lel news data. The seed set for bootstrapping the
stochastic transducer was manually constructed and
consisted of 14 names and their transliterations.
</bodyText>
<subsectionHeader confidence="0.995555">
5.1 Experiment 1: Sentence-Aligned Data
</subsectionHeader>
<bodyText confidence="0.99336075">
The first task used to test the models was to compare
and score the words remaining in each bitext sen-
tence pair after preprocessing the bitext in the fol-
lowing way:
</bodyText>
<listItem confidence="0.99971425">
• The English corpus is tokenized using a modi-
fied1 version of Word Splitter2.
• All uncapitalized English words are removed.
• Stop words (mainly prepositions and auxiliary
</listItem>
<footnote confidence="0.99966075">
1The way the program handles apostrophes(’) had to be
modified since they are sometimes used to represent glottal
stops in transliterations of Arabic words, e.g. qala’a.
2Available at http://l2r.cs.uiuc.edu/˜cogcomp/tools.php.
</footnote>
<listItem confidence="0.837235">
verbs) are removed from both sides of the bi-
text.
• Any English words of length less than 4 and
Arabic words of length less than 3 are removed.
</listItem>
<bodyText confidence="0.999908807692308">
Each algorithm finds the top match for each En-
glish word and the top match for each Arabic word.
If two words mark each other as their top scorers,
then the pair is marked as a transliteration pair. This
one-to-one constraint is meant to boost precision,
though it will also lower recall. This is because for
many of the tasks in which transliteration extraction
would be useful (such as building a lexicon), preci-
sion is deemed more important. Transliteration pairs
are sorted according to their scores, and the top 500
hundred scoring pairs are returned.
The results for the sentence-aligned extraction
task are presented in Figure 2. Since the number
of actual transliterations in the data was unknown,
there was no way to compute recall. The measure
used here is the precision for each 100 words ex-
tracted up to 500. The bootstrapping method is equal
to or outperforms the other methods at all levels, in-
cluding the Arabic-English specific fuzzy match al-
gorithm. Fuzzy matching does well for the first few
hundred words extracted, but eventually falls below
the level of the baseline Levenshtein.
Interestingly, the bootstrapped transducer does
not seem to have trouble with digraphs, despite the
one-to-one nature of the character operations. Word
pairs with two-to-one mappings such as sh/�,_ror
</bodyText>
<page confidence="0.995985">
868
</page>
<table confidence="0.999600714285714">
Metric Arabic Romanized English
1 Bootstrap vK�HBl alakhyryn Algerian
2 Bootstrap ÕÎƒð wslm Islam
3 Fuzzy M. É3/4Ë lkl Alkella
H.A“ ��
4 Fuzzy M. JAÔ« ’mAn common
1/4PAÓ
5 ALINE Qºƒ skr sugar
�àñJ�ƒðP
6 Leven. asab Arab
7 All 1/2�KQ�¯ mark Marks
8 All rwsywn Russian
9 All �éJ�j.���K�Q��ƒ�istratyjya strategic
All 10 frnk French
</table>
<tableCaption confidence="0.976613">
Table 4: A sample of the errors made by the word-
similarity metrics.
</tableCaption>
<bodyText confidence="0.990484153846154">
x/�Stend to score lower than their counterparts
composed of only one-to-one mappings, but never-
theless score highly.
A sample of the errors made by each word-
similarity metric is presented in Table 4. Errors 1-
6 are indicative of the weaknesses of each individ-
ual algorithm. The bootstrapping method encoun-
ters problems when erroneous pairs become part of
the training data, thereby reinforcing the errors. The
only problematic mapping in Error 1 is thetg map-
ping, and thus the pair has little trouble getting into
the training data. Once the pair is part of training
data, the algorithm learns that the mapping is ac-
ceptable and uses it to acquire other training pairs
that contain the same erroneous mapping. The prob-
lem with the fuzzy matching algorithm seems to be
that it creates too large a class of equivalent words.
The pairs in errors 3 and 4 are given a total edit cost
of 0. This is possible because of the overly gen-
eral letter and vowel transformations, as well as un-
usual choices made for letter equivalences (e.g.�!c
in error 4). ALINE’s errors tend to occur when it
links two letters, based on phonetic similarity, that
are never mapped to each other in transliteration be-
cause they each have a more direct equivalent in the
other language (error 5). Although the Arabic,J[k]
is phonetically similar to the English g, they would
never be mapped to each other since English has sev-
eral ways of representing an actual [k] sound. Errors
made by Levenshtein distance (error 6) are simply
due to the fact that it considers all non-identity map-
pings to be equivalent.
Errors 7-10 are examples of general errors made
by all the algorithms. The most common error was
related to inflection (error 7). The words are essen-
tially transliterations of each other, but one or the
other of the two words takes a plural or some other
inflectional ending that corrupts the phonetic match.
Error 8 represents the common problem of inciden-
tal letter similarity. The English -ian ending used for
nationalities is very similar to the Arabicv)�.[ijun]
andv�����[ijin] endings which are used for the same
purpose. They are similar phonetically and, since
they are functionally similar, will tend to co-occur.
Since neither can be said to be derived from the
other, however, they cannot be considered translit-
erations. Error 9 is a case of two words of common
origin taking on language-specific derivational end-
ings that corrupt the phonetic match. Finally, error
10 shows a mapping (,J/c) that is often correct in
transliteration, but is inappropriate in this particular
case.
</bodyText>
<subsectionHeader confidence="0.999459">
5.2 Experiment 2: Document-Aligned Named
Entity Recognition
</subsectionHeader>
<bodyText confidence="0.99997652173913">
The second experiment provides a more challenging
task for the evaluation of the models. It is struc-
tured as a cross-language named entity recognition
task similar to those outlined in (Lee and Chang,
2003) and (Klementiev and Roth, 2006). Essen-
tially, the goal is to use a language for which named
entity recognition software is readily available as a
reference for tagging named entities in a language
for which such software is not available. For this
task, the sentence alignment of the bitext is ignored.
For each named entity in an English document, the
models must select a transliteration from within the
document’s entire Arabic translation. This is meant
to be a loose approximation of the “comparable”
corpora used in (Klementiev and Roth, 2006). The
comparable corpora are related documents in differ-
ent languages that are not translations (e.g. news ar-
ticles describing the same event), and thus sentence
alignment is not possible.
The first 1000 documents in the parallel news data
were used for testing. The English side of the bi-
text was tagged with Named Entity Tagger3, which
labels named entities as person, location, organiza-
</bodyText>
<footnote confidence="0.995892">
3Available at http://l2r.cs.uiuc.edu/˜cogcomp/tools.php.
</footnote>
<page confidence="0.991786">
869
</page>
<table confidence="0.9993472">
Method Accuracy
Levenshtein 69.3
ALINE 71.9
Fuzzy Match 74.6
Bootstrapping 74.6
</table>
<tableCaption confidence="0.901962">
Table 5: Precision of the various algorithms on the
NER detection task.
</tableCaption>
<table confidence="0.9984705">
Metric Arabic Romanized English
1 Both A..c ’bd Abdallah
2 Bootstrap A, A J I al’dyd Alhadidi
3 Fuzzy Match �f c thmn Othman
</table>
<tableCaption confidence="0.905607">
Table 6: A sample of errors made on the NER detec-
tion task.
</tableCaption>
<bodyText confidence="0.999944351351352">
tion or miscellaneous. The words labeled as per-
son were extracted. Person names are almost always
transliterated, while for the other categories this is
far less certain. The list was then hand-checked to
ensure that all names were candidates for transliter-
ation, leaving 822 names. The restrictions on word
length and stop words were the same as before, but
in this task each of the English person names from
a given document were compared to all valid words
in the corresponding Arabic document, and the top
scorer for each English name was returned.
The results for the NER detection task are pre-
sented in Table 5. It seems the bootstrapped trans-
ducer’s advantage is relative to the proportion of
correct transliteration pairs to the total number of
candidates. As this proportion becomes smaller the
transducer is given more opportunities to corrupt its
training data and performance is affected accord-
ingly. Nevertheless, the transducer is able to per-
form as well as the language-specific fuzzy match-
ing algorithm on this task, despite the greater chal-
lenge posed by selecting candidates from entire doc-
uments.
A sample of errors made by the bootstrapped
transducer and fuzzy matching algorithms is shown
in Table 6. Error 1 was due to the fact that names are
sometimes split differently in Arabic and English.
The ArabicaJJ1a���(2 words) is generally written
as Abdallah in English, leading to partial matches
with part of the Arabic name. Error 2 shows an issue
with the one-to-one nature of the transducer. The
deleted h can be learned in mappings such as sh/��
or ph/i, but it is generally inappropriate to delete
an h on its own. Error 3 again shows that the fuzzy
matching algorithm’s letter transformations are too
general. The vowel removals lead to a 0 cost match
in this case.
</bodyText>
<sectionHeader confidence="0.999984" genericHeader="evaluation">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999607948717949">
Several other methods for detecting transliterations
between various language pairs have been proposed.
These methods differ in their complexity as well as
in their applicability to language pairs other than the
pair for which they were originally designed.
Collier et al. (1997) present a method for identi-
fying transliterations in an English-Japanese bitext.
Their model first transcribes the Japanese word ex-
pressed in the katakana syllabic script as the con-
catenation of all possible transliterations of the in-
dividual symbols. A depth-first search is then ap-
plied to compute the number of matches between
this transcription and a candidate English transliter-
ation. The method requires a manual enumeration of
the possible transliterations for each katakana sym-
bol, which is unfeasible for many language pairs.
In the method developed by Tsuji (2002),
katakana strings are first split into their mora units,
and then the transliterations of the units are assessed
manually from a set of training pairs. For each
katakana string in a bitext, all possible translitera-
tions are produced based on the transliteration units
determined from the training set. The translitera-
tion candidates are then compared to the English
words according to the Dice score. The manual enu-
meration of possible mappings makes this approach
unattractive for many language pairs, and the gen-
eration of all possible transliteration candidates is
problematic in terms of computational complexity.
Lee and Chang (2003) detect transliterations with
a generative noisy channel transliteration model
similar to the transducer presented in (Knight and
Graehl, 1998). The English side of the corpus is
tagged with a named entity tagger, and the model
is used to isolate the transliterations in the Chinese
translation. This model, like the transducer pro-
posed by Ristad and Yianilos (1998), must be trained
on a large number of sample transliterations, mean-
ing it cannot be used if such a resource is not avail-
</bodyText>
<page confidence="0.98438">
870
</page>
<bodyText confidence="0.9921292">
able.
Klementiev and Roth (2006) bootstrap with a per-
ceptron and use temporal analysis to detect translit-
erations in comparable Russian-English news cor-
pora. The English side is first tagged by a named
entity tagger, and the perceptron proposes transliter-
ations for the named entities. The candidate translit-
eration pairs are then reranked according the similar-
ity of their distributions across dates, as calculated
by a discrete Fourier transform.
</bodyText>
<sectionHeader confidence="0.997215" genericHeader="conclusions">
7 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999993875">
We presented a bootstrapping approach to training
a stochastic transducer, which learns scoring param-
eters automatically from a bitext. The approach is
completely language-independent, and was shown
to perform as well or better than an Arabic-English
specific similarity metric on the task of Arabic-
English transliteration extraction.
Although the bootstrapped transducer is
language-independent, it learns only one-to-one
letter relationships, which is a potential drawback in
terms of porting it to other languages. Our model is
able to capture English digraphs and trigraphs, but,
as of yet, we cannot guarantee the model’s success
on languages with more complex letter relationships
(e.g. a logographic writing system such as Chinese).
More research is necessary to evaluate the model’s
performance on other languages.
Another area open to future research is the use
of more complex transducers for word comparison.
For example, Linden (2006) presents a model which
learns probabilities for edit operations by taking into
account the context in which the characters appear.
It remains to be seen how such a model could be
adapted to a bootstrapping setting.
</bodyText>
<sectionHeader confidence="0.999332" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9998784">
We would like to thank the members of the NLP re-
search group at the University of Alberta for their
helpful comments and suggestions. This research
was supported by the Natural Sciences and Engi-
neering Research Council of Canada.
</bodyText>
<sectionHeader confidence="0.998472" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999816239130435">
N. AbdulJaleel and L. S. Larkey. 2003. Statistical
transliteration for English-Arabic cross language in-
formation retrieval. In CIKM, pages 139–146.
Y. Al-Onaizan and K. Knight. 2002. Machine translit-
eration of names in Arabic text. In ACL Workshop on
Comp. Approaches to Semitic Languages.
N. Collier, A. Kumano, and H. Hirakawa. 1997. Acqui-
sition of English-Japanese proper nouns from noisy-
parallel newswire articles using Katakana matching.
In Natural Language Pacific Rim Symposium (NL-
PRS’97), Phuket, Thailand, pages 309–314, Decem-
ber.
A. Freeman, S. Condon, and C. Ackerman. 2006.
Cross linguistic name matching in English and Ara-
bic. In Human Language Technology Conference of
the NAACL, pages 471–478, New York City, USA,
June. Association for Computational Linguistics.
A. Klementiev and D. Roth. 2006. Named entity translit-
eration and discovery from multilingual comparable
corpora. In Human Language Technology Conference
of the NAACL, pages 82–88, New York City, USA,
June. Association for Computational Linguistics.
K. Knight and J. Graehl. 1998. Machine transliteration.
Computational Linguistics, 24(4):599–612.
G. Kondrak. 2000. A new algorithm for the alignment of
phonetic sequences. In NAACL 2000, pages 288–295.
C. Lee and J. S. Chang. 2003. Acquisition of English-
Chinese transliterated word pairs from parallel-aligned
texts using a statistical machine transliteration model.
In HLT-NAACL 2003 Workshop on Building and using
parallel texts, pages 96–103, Morristown, NJ, USA.
Association for Computational Linguistics.
K. Linden. 2006. Multilingual modeling of cross-lingual
spelling variants. Information Retrieval, 9(3):295–
310, June.
E. S. Ristad and P. N. Yianilos. 1998. Learning string-
edit distance. IEEE Transactions on Pattern Analysis
and Machine Intelligence, 20(5):522–532.
K. Tsuji. 2002. Automatic extraction of translational
Japanese-katakana and English word pairs. Interna-
tional Journal of Computer Processing of Oriental
Languages, 15(3):261–279.
D. Yarowsky. 1995. Unsupervised word sense disam-
biguation rivaling supervised methods. In Meeting of
the Association for Computational Linguistics, pages
189–196.
</reference>
<page confidence="0.998447">
871
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.864449">
<title confidence="0.9991445">Bootstrapping a Stochastic Transducer for Arabic-English Transliteration Extraction</title>
<author confidence="0.999569">Sherif Kondrak</author>
<affiliation confidence="0.9999765">Department of Computing Science University of Alberta</affiliation>
<address confidence="0.994321">Edmonton, Alberta, Canada T6G 2E8</address>
<abstract confidence="0.989396846153846">We propose a bootstrapping approach to training a memoriless stochastic transducer for the task of extracting transliterations from an English-Arabic bitext. The transducer learns its similarity metric from the data in the bitext, and thus can function directly on strings written in different writing scripts without any additional language knowledge. We show that this bootstrapped transducer performs as well or better than a model designed specifically to detect Arabic-English transliterations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>N AbdulJaleel</author>
<author>L S Larkey</author>
</authors>
<title>Statistical transliteration for English-Arabic cross language information retrieval.</title>
<date>2003</date>
<booktitle>In CIKM,</booktitle>
<pages>139--146</pages>
<contexts>
<context position="1288" citStr="AbdulJaleel and Larkey, 2003" startWordPosition="177" endWordPosition="180">r better than a model designed specifically to detect Arabic-English transliterations. 1 Introduction Transliterations are words that are converted from one writing script to another on the basis of their pronunciation, rather than being translated on the basis of their meaning. Transliterations include named entities (e.g.Xð10-.t.g./Jane Austen) and lexical loans (e.g.vñK��Q��aÊ�K/television). An algorithm to detect transliterations automatically in a bitext can be an effective tool for many tasks. Models of machine transliteration such as those presented in (Al-Onaizan and Knight, 2002) or (AbdulJaleel and Larkey, 2003) require a large set of sample transliterations to use for training. If such a training set is unavailable for a particular language pair, a detection algorithm would lead to a significant gain in time over attempting to build the set manually. Algorithms for cross-language information retrieval often encounter the problem of out-ofvocabulary words, or words not present in the algorithm’s lexicon. Often, a significant proportion of these words are named entities and thus are candidates for transliteration. A transliteration detection algorithm could be used to map named entities in a query to </context>
</contexts>
<marker>AbdulJaleel, Larkey, 2003</marker>
<rawString>N. AbdulJaleel and L. S. Larkey. 2003. Statistical transliteration for English-Arabic cross language information retrieval. In CIKM, pages 139–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Al-Onaizan</author>
<author>K Knight</author>
</authors>
<title>Machine transliteration of names in Arabic text.</title>
<date>2002</date>
<booktitle>In ACL Workshop on Comp. Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="1254" citStr="Al-Onaizan and Knight, 2002" startWordPosition="172" endWordPosition="175">ped transducer performs as well or better than a model designed specifically to detect Arabic-English transliterations. 1 Introduction Transliterations are words that are converted from one writing script to another on the basis of their pronunciation, rather than being translated on the basis of their meaning. Transliterations include named entities (e.g.Xð10-.t.g./Jane Austen) and lexical loans (e.g.vñK��Q��aÊ�K/television). An algorithm to detect transliterations automatically in a bitext can be an effective tool for many tasks. Models of machine transliteration such as those presented in (Al-Onaizan and Knight, 2002) or (AbdulJaleel and Larkey, 2003) require a large set of sample transliterations to use for training. If such a training set is unavailable for a particular language pair, a detection algorithm would lead to a significant gain in time over attempting to build the set manually. Algorithms for cross-language information retrieval often encounter the problem of out-ofvocabulary words, or words not present in the algorithm’s lexicon. Often, a significant proportion of these words are named entities and thus are candidates for transliteration. A transliteration detection algorithm could be used to</context>
</contexts>
<marker>Al-Onaizan, Knight, 2002</marker>
<rawString>Y. Al-Onaizan and K. Knight. 2002. Machine transliteration of names in Arabic text. In ACL Workshop on Comp. Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Collier</author>
<author>A Kumano</author>
<author>H Hirakawa</author>
</authors>
<title>Acquisition of English-Japanese proper nouns from noisyparallel newswire articles using Katakana matching.</title>
<date>1997</date>
<booktitle>In Natural Language Pacific Rim Symposium (NLPRS’97),</booktitle>
<pages>309--314</pages>
<location>Phuket, Thailand,</location>
<contexts>
<context position="23965" citStr="Collier et al. (1997)" startWordPosition="3921" endWordPosition="3924">sue with the one-to-one nature of the transducer. The deleted h can be learned in mappings such as sh/�� or ph/i, but it is generally inappropriate to delete an h on its own. Error 3 again shows that the fuzzy matching algorithm’s letter transformations are too general. The vowel removals lead to a 0 cost match in this case. 6 Related Work Several other methods for detecting transliterations between various language pairs have been proposed. These methods differ in their complexity as well as in their applicability to language pairs other than the pair for which they were originally designed. Collier et al. (1997) present a method for identifying transliterations in an English-Japanese bitext. Their model first transcribes the Japanese word expressed in the katakana syllabic script as the concatenation of all possible transliterations of the individual symbols. A depth-first search is then applied to compute the number of matches between this transcription and a candidate English transliteration. The method requires a manual enumeration of the possible transliterations for each katakana symbol, which is unfeasible for many language pairs. In the method developed by Tsuji (2002), katakana strings are fi</context>
</contexts>
<marker>Collier, Kumano, Hirakawa, 1997</marker>
<rawString>N. Collier, A. Kumano, and H. Hirakawa. 1997. Acquisition of English-Japanese proper nouns from noisyparallel newswire articles using Katakana matching. In Natural Language Pacific Rim Symposium (NLPRS’97), Phuket, Thailand, pages 309–314, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Freeman</author>
<author>S Condon</author>
<author>C Ackerman</author>
</authors>
<title>Cross linguistic name matching in English and Arabic.</title>
<date>2006</date>
<booktitle>In Human Language Technology Conference of the NAACL,</booktitle>
<pages>471--478</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="3802" citStr="Freeman et al. (2006)" startWordPosition="583" endWordPosition="586">ce without making the algorithms language-specific. Many word-similarity metrics require that the strings being compared be 864 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 864–871, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics written in the same script. Levenshtein edit distance, for example, does not produce a meaningful score in the absence of character identities. Thus, if these metrics are to be used for transliteration extraction, modifications must be made to allow them to compare different scripts. Freeman et al. (2006) take the approach of manually encoding a great deal of language knowledge directly into their Arabic-English fuzzy matching algorithm. They define equivalence classes between letters in the two scripts and perform several rule-based transformations to make word pairs more comparable. This approach is unattractive for two reasons. Firstly, predicting all possible relationships between letters in English and Arabic is difficult. For example, allowances have to be made for unusual pronunciations in foreign words such as the ch in clich´e or the c in Milosevic. Secondly, the algorithm becomes com</context>
<context position="9090" citStr="Freeman et al. (2006)" startWordPosition="1458" endWordPosition="1461">l word pairs under consideration. 4. If the forward score for a pair of words is above a predetermined acceptance threshold, add the pair to the training set. 5. Repeat steps 2-4 until the training set ceases to grow. Once training stops, the transducer can be used to score pairs of words not in the training set. For our experiments, the acceptance threshold was optimized on a separate development set. Forward scores were normalized by the average of the lengths of the two words. 3 Arabic-English Fuzzy String Matching In this section, we outline the fuzzy string matching algorithm proposed by Freeman et al. (2006). The algorithm is based on the standard Levenshtein distance approach, but encodes a great deal of knowledge about the relationships between English and Arabic letters. Initially, the candidate word pair is modified in two ways. The first transformation is a rule-based letter normalization of both words. Some examples of normalization include: • English double letter collapse: e.g. Miller—*Miler. I,I,ÆI,øH a,e,i,o,u H.H b,p,v �H,,�HH t h.H j,g H d,z ,e,o,u ¨,ZH� ,c,a,i †H q,g,k `=Hk,c,s ø H y,i,e,j o H a,e Table 1: A sample of the letter equivalence classes for fuzzy string matching. Algorith</context>
</contexts>
<marker>Freeman, Condon, Ackerman, 2006</marker>
<rawString>A. Freeman, S. Condon, and C. Ackerman. 2006. Cross linguistic name matching in English and Arabic. In Human Language Technology Conference of the NAACL, pages 471–478, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Klementiev</author>
<author>D Roth</author>
</authors>
<title>Named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Human Language Technology Conference of the NAACL,</booktitle>
<pages>82--88</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="20574" citStr="Klementiev and Roth, 2006" startWordPosition="3363" endWordPosition="3366">from the other, however, they cannot be considered transliterations. Error 9 is a case of two words of common origin taking on language-specific derivational endings that corrupt the phonetic match. Finally, error 10 shows a mapping (,J/c) that is often correct in transliteration, but is inappropriate in this particular case. 5.2 Experiment 2: Document-Aligned Named Entity Recognition The second experiment provides a more challenging task for the evaluation of the models. It is structured as a cross-language named entity recognition task similar to those outlined in (Lee and Chang, 2003) and (Klementiev and Roth, 2006). Essentially, the goal is to use a language for which named entity recognition software is readily available as a reference for tagging named entities in a language for which such software is not available. For this task, the sentence alignment of the bitext is ignored. For each named entity in an English document, the models must select a transliteration from within the document’s entire Arabic translation. This is meant to be a loose approximation of the “comparable” corpora used in (Klementiev and Roth, 2006). The comparable corpora are related documents in different languages that are not</context>
<context position="25702" citStr="Klementiev and Roth (2006)" startWordPosition="4195" endWordPosition="4198">le transliteration candidates is problematic in terms of computational complexity. Lee and Chang (2003) detect transliterations with a generative noisy channel transliteration model similar to the transducer presented in (Knight and Graehl, 1998). The English side of the corpus is tagged with a named entity tagger, and the model is used to isolate the transliterations in the Chinese translation. This model, like the transducer proposed by Ristad and Yianilos (1998), must be trained on a large number of sample transliterations, meaning it cannot be used if such a resource is not avail870 able. Klementiev and Roth (2006) bootstrap with a perceptron and use temporal analysis to detect transliterations in comparable Russian-English news corpora. The English side is first tagged by a named entity tagger, and the perceptron proposes transliterations for the named entities. The candidate transliteration pairs are then reranked according the similarity of their distributions across dates, as calculated by a discrete Fourier transform. 7 Conclusion and Future Work We presented a bootstrapping approach to training a stochastic transducer, which learns scoring parameters automatically from a bitext. The approach is co</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>A. Klementiev and D. Roth. 2006. Named entity transliteration and discovery from multilingual comparable corpora. In Human Language Technology Conference of the NAACL, pages 82–88, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>24--4</pages>
<contexts>
<context position="25322" citStr="Knight and Graehl, 1998" startWordPosition="4128" endWordPosition="4131">ach katakana string in a bitext, all possible transliterations are produced based on the transliteration units determined from the training set. The transliteration candidates are then compared to the English words according to the Dice score. The manual enumeration of possible mappings makes this approach unattractive for many language pairs, and the generation of all possible transliteration candidates is problematic in terms of computational complexity. Lee and Chang (2003) detect transliterations with a generative noisy channel transliteration model similar to the transducer presented in (Knight and Graehl, 1998). The English side of the corpus is tagged with a named entity tagger, and the model is used to isolate the transliterations in the Chinese translation. This model, like the transducer proposed by Ristad and Yianilos (1998), must be trained on a large number of sample transliterations, meaning it cannot be used if such a resource is not avail870 able. Klementiev and Roth (2006) bootstrap with a perceptron and use temporal analysis to detect transliterations in comparable Russian-English news corpora. The English side is first tagged by a named entity tagger, and the perceptron proposes transli</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>K. Knight and J. Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4):599–612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Kondrak</author>
</authors>
<title>A new algorithm for the alignment of phonetic sequences.</title>
<date>2000</date>
<booktitle>In NAACL</booktitle>
<pages>288--295</pages>
<contexts>
<context position="12690" citStr="Kondrak, 2000" startWordPosition="2053" endWordPosition="2054">used Levenshtein edit distance. The algorithm simply counts the minimum number of insertions, deletions and substitutions required to convert one string into another. Levenshtein distance depends on finding identical letters, so both words must use the same alphabet. Prior to comparison, we convert the Arabic words into the Latin alphabet using the intuitive mappings for each letter shown in Table 3. The distances are also normalized by the length of the longer of the two words to avoid excessively penalizing longer words. 4.2 ALINE Unlike other algorithms presented here, the ALINE algorithm (Kondrak, 2000) operates in the phonetic, rather than the orthographic, domain. It was originally designed to identify cognates in related languages, but it can be used to compute similarity between any pair of words, provided that they are expressed in a standard phonetic notation. Individual ~,Æ aH.→ b�H,→ ��,Z→ t �,h,è→ �H→ th h.→ j a �è→ hp→ khX,�•→ � d X, th P→ r €,•→ s �€→ sh ¨→ ’ ���→ ¬→ f �P→ z ¨→ g �†→ q 1/4→ k È→ l �→ m à→ n ð→ w ø�→ y Table 3: Arabic Romanization for Levenshtein distance. phonemes input to the algorithm are decomposed into a dozen phonetic features, such as Place, Manner and Voice</context>
</contexts>
<marker>Kondrak, 2000</marker>
<rawString>G. Kondrak. 2000. A new algorithm for the alignment of phonetic sequences. In NAACL 2000, pages 288–295.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lee</author>
<author>J S Chang</author>
</authors>
<title>Acquisition of EnglishChinese transliterated word pairs from parallel-aligned texts using a statistical machine transliteration model.</title>
<date>2003</date>
<booktitle>In HLT-NAACL 2003 Workshop on Building and using parallel texts,</booktitle>
<pages>96--103</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="20542" citStr="Lee and Chang, 2003" startWordPosition="3358" endWordPosition="3361">can be said to be derived from the other, however, they cannot be considered transliterations. Error 9 is a case of two words of common origin taking on language-specific derivational endings that corrupt the phonetic match. Finally, error 10 shows a mapping (,J/c) that is often correct in transliteration, but is inappropriate in this particular case. 5.2 Experiment 2: Document-Aligned Named Entity Recognition The second experiment provides a more challenging task for the evaluation of the models. It is structured as a cross-language named entity recognition task similar to those outlined in (Lee and Chang, 2003) and (Klementiev and Roth, 2006). Essentially, the goal is to use a language for which named entity recognition software is readily available as a reference for tagging named entities in a language for which such software is not available. For this task, the sentence alignment of the bitext is ignored. For each named entity in an English document, the models must select a transliteration from within the document’s entire Arabic translation. This is meant to be a loose approximation of the “comparable” corpora used in (Klementiev and Roth, 2006). The comparable corpora are related documents in </context>
<context position="25179" citStr="Lee and Chang (2003)" startWordPosition="4109" endWordPosition="4112">are first split into their mora units, and then the transliterations of the units are assessed manually from a set of training pairs. For each katakana string in a bitext, all possible transliterations are produced based on the transliteration units determined from the training set. The transliteration candidates are then compared to the English words according to the Dice score. The manual enumeration of possible mappings makes this approach unattractive for many language pairs, and the generation of all possible transliteration candidates is problematic in terms of computational complexity. Lee and Chang (2003) detect transliterations with a generative noisy channel transliteration model similar to the transducer presented in (Knight and Graehl, 1998). The English side of the corpus is tagged with a named entity tagger, and the model is used to isolate the transliterations in the Chinese translation. This model, like the transducer proposed by Ristad and Yianilos (1998), must be trained on a large number of sample transliterations, meaning it cannot be used if such a resource is not avail870 able. Klementiev and Roth (2006) bootstrap with a perceptron and use temporal analysis to detect transliterat</context>
</contexts>
<marker>Lee, Chang, 2003</marker>
<rawString>C. Lee and J. S. Chang. 2003. Acquisition of EnglishChinese transliterated word pairs from parallel-aligned texts using a statistical machine transliteration model. In HLT-NAACL 2003 Workshop on Building and using parallel texts, pages 96–103, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Linden</author>
</authors>
<title>Multilingual modeling of cross-lingual spelling variants.</title>
<date>2006</date>
<journal>Information Retrieval,</journal>
<volume>9</volume>
<issue>3</issue>
<pages>310</pages>
<marker>Linden, 2006</marker>
<rawString>K. Linden. 2006. Multilingual modeling of cross-lingual spelling variants. Information Retrieval, 9(3):295– 310, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E S Ristad</author>
<author>P N Yianilos</author>
</authors>
<title>Learning stringedit distance.</title>
<date>1998</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>20</volume>
<issue>5</issue>
<contexts>
<context position="4698" citStr="Ristad and Yianilos (1998)" startWordPosition="723" endWordPosition="727">ore comparable. This approach is unattractive for two reasons. Firstly, predicting all possible relationships between letters in English and Arabic is difficult. For example, allowances have to be made for unusual pronunciations in foreign words such as the ch in clich´e or the c in Milosevic. Secondly, the algorithm becomes completely language-specific, which means that it cannot be used for any other language pair. We propose a method to learn letter relationships directly from the bitext containing the transliterations. Our model is based on the memoriless stochastic transducer proposed by Ristad and Yianilos (1998), which derives a probabilistic wordsimilarity function from a set of examples. The transducer is able to learn edit distance costs between disjoint sets of characters representing different writing scripts without any language-specific knowledge. The transducer approach, however, requires a large set of training examples, which is a limitation not present in the fuzzy matching algorithm. Thus, we propose a bootstrapping approach (Yarowsky, 1995) to train the stochastic transducer iteratively as it extracts transliterations from a bitext. The bootstrapped stochastic transducer is completely la</context>
<context position="5997" citStr="Ristad and Yianilos (1998)" startWordPosition="918" endWordPosition="921">ll as the Arabic-English specific fuzzy matching algorithm. The remainder of this paper is organized as follows. Section 2 presents our bootstrapping method to train a stochastic transducer. Section 3 outlines the Arabic-English fuzzy matching algorithm. Section 4 discusses other word-similarity models used for comparison. Section 5 describes the results of two experiments performed to test the models. Section 6 briefly discusses previous approaches to detecting transliterations. Section 7 presents our conclusions and possibilities for future work. 2 Bootstrapping with a Stochastic Transducer Ristad and Yianilos (1998) propose a probabilistic framework for word similarity, in which the similarity of a pair of words is defined as the sum of the probabilities of all paths through a memoriless stochastic transducer that generate the pair of words. This is referred to as the forward score of the pair of words. They outline a forward-backward algorithm to train the model and show that it outperforms Levenshtein edit distance on the task of pronunciation classification. The training algorithm begins by calling the forward (Equation 1) and backward (Equation 2) functions to fill in the F and B tables for training </context>
<context position="25545" citStr="Ristad and Yianilos (1998)" startWordPosition="4166" endWordPosition="4169">ing to the Dice score. The manual enumeration of possible mappings makes this approach unattractive for many language pairs, and the generation of all possible transliteration candidates is problematic in terms of computational complexity. Lee and Chang (2003) detect transliterations with a generative noisy channel transliteration model similar to the transducer presented in (Knight and Graehl, 1998). The English side of the corpus is tagged with a named entity tagger, and the model is used to isolate the transliterations in the Chinese translation. This model, like the transducer proposed by Ristad and Yianilos (1998), must be trained on a large number of sample transliterations, meaning it cannot be used if such a resource is not avail870 able. Klementiev and Roth (2006) bootstrap with a perceptron and use temporal analysis to detect transliterations in comparable Russian-English news corpora. The English side is first tagged by a named entity tagger, and the perceptron proposes transliterations for the named entities. The candidate transliteration pairs are then reranked according the similarity of their distributions across dates, as calculated by a discrete Fourier transform. 7 Conclusion and Future Wo</context>
</contexts>
<marker>Ristad, Yianilos, 1998</marker>
<rawString>E. S. Ristad and P. N. Yianilos. 1998. Learning stringedit distance. IEEE Transactions on Pattern Analysis and Machine Intelligence, 20(5):522–532.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Tsuji</author>
</authors>
<title>Automatic extraction of translational Japanese-katakana and English word pairs.</title>
<date>2002</date>
<journal>International Journal of Computer Processing of Oriental Languages,</journal>
<volume>15</volume>
<issue>3</issue>
<contexts>
<context position="24540" citStr="Tsuji (2002)" startWordPosition="4012" endWordPosition="4013">nally designed. Collier et al. (1997) present a method for identifying transliterations in an English-Japanese bitext. Their model first transcribes the Japanese word expressed in the katakana syllabic script as the concatenation of all possible transliterations of the individual symbols. A depth-first search is then applied to compute the number of matches between this transcription and a candidate English transliteration. The method requires a manual enumeration of the possible transliterations for each katakana symbol, which is unfeasible for many language pairs. In the method developed by Tsuji (2002), katakana strings are first split into their mora units, and then the transliterations of the units are assessed manually from a set of training pairs. For each katakana string in a bitext, all possible transliterations are produced based on the transliteration units determined from the training set. The transliteration candidates are then compared to the English words according to the Dice score. The manual enumeration of possible mappings makes this approach unattractive for many language pairs, and the generation of all possible transliteration candidates is problematic in terms of computa</context>
</contexts>
<marker>Tsuji, 2002</marker>
<rawString>K. Tsuji. 2002. Automatic extraction of translational Japanese-katakana and English word pairs. International Journal of Computer Processing of Oriental Languages, 15(3):261–279.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Meeting of the Association for Computational Linguistics,</booktitle>
<pages>189--196</pages>
<contexts>
<context position="5148" citStr="Yarowsky, 1995" startWordPosition="794" endWordPosition="795">tionships directly from the bitext containing the transliterations. Our model is based on the memoriless stochastic transducer proposed by Ristad and Yianilos (1998), which derives a probabilistic wordsimilarity function from a set of examples. The transducer is able to learn edit distance costs between disjoint sets of characters representing different writing scripts without any language-specific knowledge. The transducer approach, however, requires a large set of training examples, which is a limitation not present in the fuzzy matching algorithm. Thus, we propose a bootstrapping approach (Yarowsky, 1995) to train the stochastic transducer iteratively as it extracts transliterations from a bitext. The bootstrapped stochastic transducer is completely language-independent, and we show that it is able to perform at least as well as the Arabic-English specific fuzzy matching algorithm. The remainder of this paper is organized as follows. Section 2 presents our bootstrapping method to train a stochastic transducer. Section 3 outlines the Arabic-English fuzzy matching algorithm. Section 4 discusses other word-similarity models used for comparison. Section 5 describes the results of two experiments p</context>
<context position="7834" citStr="Yarowsky, 1995" startWordPosition="1249" endWordPosition="1250"> example, the mapping (si, tj) would contribute a count according to Equation 3. These counts are then normalized to produce the updated probability distribution. F(i − 1, j − 1)P(si, tj)B(i, j) C(si,tj)+ = (3) F(I, J) The major issue in porting the memoriless transducer over to our task of transliteration extraction 865 is that its training is supervised. In other words, it would require a relatively large set of known transliterations for training, and this is exactly what we would like the model to acquire. In order to overcome this problem, we look to the bootstrapping method outlined in (Yarowsky, 1995). Yarowsky trains a rule-based classifier for word sense disambiguation by starting with a small set of seed examples for which the sense is known. The trained classifier is then used to label examples for which the sense is unknown, and these newly labeled examples are then used to retrain the classifier. The process is repeated until convergence. Our method uses a similar approach to train the stochastic transducer. The algorithm proceeds as follows: 1. Initialize the training set with the seed pairs. 2. Train the transducer using the forwardbackward algorithm on the current training set. 3.</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Meeting of the Association for Computational Linguistics, pages 189–196.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>