<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012602">
<title confidence="0.9904875">
A Graph-based Cross-lingual Projection Approach for
Weakly Supervised Relation Extraction
</title>
<author confidence="0.985613">
Seokhwan Kim
</author>
<affiliation confidence="0.9787995">
Human Language Technology Dept.
Institute for Infocomm Research
</affiliation>
<address confidence="0.959079">
Singapore 138632
</address>
<email confidence="0.992497">
kims@i2r.a-star.edu.sg
</email>
<author confidence="0.982442">
Gary Geunbae Lee
</author>
<affiliation confidence="0.9999175">
Dept. of Computer Science and Engineering
Pohang University of Science and Technology
</affiliation>
<address confidence="0.677126">
Pohang, 790-784, Korea
</address>
<email confidence="0.995463">
gblee@postech.ac.kr
</email>
<sectionHeader confidence="0.998585" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999896">
Although researchers have conducted exten-
sive studies on relation extraction in the last
decade, supervised approaches are still limited
because they require large amounts of training
data to achieve high performances. To build
a relation extractor without significant anno-
tation effort, we can exploit cross-lingual an-
notation projection, which leverages parallel
corpora as external resources for supervision.
This paper proposes a novel graph-based pro-
jection approach and demonstrates the mer-
its of it by using a Korean relation extrac-
tion system based on projected dataset from
an English-Korean parallel corpus.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999961846153846">
Relation extraction aims to identify semantic rela-
tions of entities in a document. Although many
supervised machine learning approaches have been
successfully applied to relation extraction tasks (Ze-
lenko et al., 2003; Kambhatla, 2004; Bunescu and
Mooney, 2005; Zhang et al., 2006), applications of
these approaches are still limited because they re-
quire a sufficient number of training examples to ob-
tain good extraction results. Several datasets that
provide manual annotations of semantic relation-
ships are available from MUC (Grishman and Sund-
heim, 1996) and ACE (Doddington et al., 2004)
projects, but these datasets contain labeled training
examples in only a few major languages, includ-
ing English, Chinese, and Arabic. Although these
datasets encourage the development of relation ex-
tractors for these major languages, there are few la-
beled training samples for learning new systems in
other languages, such as Korean. Because manual
annotation of semantic relations for such resource-
poor languages is very expensive, we instead con-
sider weakly supervised learning techniques (Riloff
and Jones, 1999; Agichtein and Gravano, 2000;
Zhang, 2004; Chen et al., 2006) to learn the rela-
tion extractors without significant annotation efforts.
But these techniques still face cost problems when
preparing quality seed examples, which plays a cru-
cial role in obtaining good extractions.
Recently, some researchers attempted to use ex-
ternal resources, such as treebank (Banko et al.,
2007) and Wikipedia (Wu and Weld, 2010), that
were not specially constructed for relation extraction
instead of using task-specific training or seed exam-
ples. We previously proposed to leverage parallel
corpora as a new kind of external resource for rela-
tion extraction (Kim et al., 2010). To obtain training
examples in the resource-poor target language, this
approach exploited a cross-lingual annotation pro-
jection by propagating annotations that were gener-
ated by a relation extraction system in a resource-
rich source language. In this approach, projected
annotations were determined in a single pass pro-
cess by considering only alignments between entity
candidates; we call this action direct projection.
In this paper, we propose a graph-based projec-
tion approach for weakly supervised relation extrac-
tion. This approach utilizes a graph that is con-
stucted with both instance and context information
and that is operated in an iterative manner. The goal
of our graph-based approach is to improve the ro-
bustness of the extractor with respect to errors that
are generated and accumulated by preprocessors.
</bodyText>
<page confidence="0.993561">
48
</page>
<note confidence="0.815348">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 48–53,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<figure confidence="0.7687985">
fE (&lt;Barack Obama, Honolulu&gt;) = 1
(beo-rak-o-ba-ma) (ho-nol-rul-ru)
</figure>
<figureCaption confidence="0.9609895">
Figure 1: An example of annotation projection for rela-
tion extraction of a bitext in English and Korean
</figureCaption>
<sectionHeader confidence="0.9312555" genericHeader="introduction">
2 Cross-lingual Annotation Projection for
Relation Extraction
</sectionHeader>
<bodyText confidence="0.998285">
Relation extraction can be considered to be a classi-
fication problem by the following classifier:
</bodyText>
<equation confidence="0.829386333333333">
f (ei, ej) = ( 1 if ei and ej have a relation,
,
−1 otherwise.
</equation>
<bodyText confidence="0.999862785714286">
where ei and ej are entities in a sentence.
Cross-lingual annotation projection intends to
learn an extractor ft for good performance with-
out significant effort toward building resources for
a resource-poor target language Lt. To accomplish
that goal, the method automatically creates a set of
annotated text for ft, utilizing a well-made extractor
fs for a resource-rich source language Ls and a par-
allel corpus of Ls and Lt. Figure 1 shows an exam-
ple of annotation projection for relation extraction
with a bi-text in Lt Korean and Ls English. Given an
English sentence, an instance (Barack Obama, Hon-
olulu) is extracted as positive. Then, its translational
counterpart (beo-rak-o-ba-ma, ho-nol-rul-ru) in the
Korean sentence also has a positive annotation by
projection.
Early studies in cross-lingual annotation projec-
tion were accomplished for various natural lan-
guage processing tasks (Yarowsky and Ngai, 2001;
Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and
Florian, 2008; Pado and Lapata, 2009). These stud-
ies adopted a simple direct projection strategy that
propagates the annotations in the source language
sentences to word-aligned target sentences, and a
target system can bootstrap from these projected an-
notations.
For relation extraction, the direct projection strat-
egy can be formularized as follows: ft (eit, et ) =
</bodyText>
<equation confidence="0.536283">
� �
fs A(eit), A(ej t ) , where A(et) is the aligned entity
</equation>
<bodyText confidence="0.999901133333333">
of et. However, these automatic annotations can be
unreliable because of source text mis-classification
and word alignment errors; thus, it can cause a criti-
cal falling-off in the annotation projection quality.
Although some noise reduction strategies for pro-
jecting semantic relations were proposed (Kim et al.,
2010), the direct projection approach is still vulner-
able to erroneous inputs generated by submodules.
We note two main causes for this limitation: (1)
the direct projection approach considers only align-
ments between entity candidates, and it does not
consider any contextual information; and, (2) it is
performed by a single pass process. To solve both of
these problems at once, we propose a graph-based
projection approach for relation extraction.
</bodyText>
<sectionHeader confidence="0.995635" genericHeader="method">
3 Graph Construction
</sectionHeader>
<bodyText confidence="0.999974357142857">
The most crucial factor in the success of graph-
based learning approaches is how to construct a
graph that is appropriate for the target task. Das
and Petrov (Das and Petrov, 2011) proposed a graph-
based bilingual projection of part-of-speech tagging
by considering the tagged words in the source lan-
guage as labeled examples and connecting them to
the unlabeled words in the target language, while re-
ferring to the word alignments. Graph construction
for projecting semantic relationships is more com-
plicated than part-of-speech tagging because the unit
instance of projection is a pair of entities and not a
word or morpheme that is equivalent to the align-
ment unit.
</bodyText>
<subsectionHeader confidence="0.998357">
3.1 Graph Vertices
</subsectionHeader>
<bodyText confidence="0.9999519">
To construct a graph for a relation projection, we
define two types of vertices: instance vertices V and
context vertices U.
Instance vertices are defined for all pairs of en-
tity candidates in the source and target languages.
Each instance vertex has a soft label vector Y =
[ y+ y− ], which contains the probabilities that
the instance is positive or negative, respectively. The
larger the y+ value, the more likely the instance has
a semantic relationship. The initial label values of an
</bodyText>
<equation confidence="0.697259">
C &gt;
</equation>
<bodyText confidence="0.9055024">
instance vertex vij s E Vs for the instance eis, ej s in
the source language are assigned based on the con-
fidence score of the extractor fs. With respect to the
target language, every instance vertex vij
t E Vt has
</bodyText>
<figure confidence="0.988794631578947">
, Hawaii .
Honolulu
was born in
49+61
(ha-wa-i)
91
(ui)
��-*-&apos;i-
(ho-nol-rul-ru)
�
(neun)
fK ( &lt; 13)ut Q4731 , &amp;*-*-&apos;i- &gt; ) = 1
401xk4.
(tae-eo-nat-da)
Oil�
(e-seo)
Barack Obama
IiiUt Q4731
(beo-rak-o-ba-ma)
</figure>
<page confidence="0.996518">
49
</page>
<bodyText confidence="0.999848714285714">
the same initial values of 0.5 in both y+ and y−.
The other type of vertices, context vertices, are
used for identifying relation descriptors that are con-
textual subtexts that represent semantic relationships
of the positive instances. Because the characteristics
of these descriptive contexts vary depending on the
language, context vertices should be defined to be
language-specific. In the case of English, we define
the context vertex for each trigram that is located be-
tween a given entity pair that is semantically related.
If the context vertices Us for the source language
sentences are defined, then the units of context in
the target language can also be created based on the
word alignments. The aligned counterpart of each
source language context vertex is used for generat-
ing a context vertex uit E Ut in the target language.
Each context vertex us E Us and ut E Ut also has
y+ and y−, which represent how likely the context
is to denote semantic relationships. The probability
values for all of the context vertices in both of the
languages are initially assigned to y+ = y− = 0.5.
</bodyText>
<subsectionHeader confidence="0.998568">
3.2 Edge Weights
</subsectionHeader>
<bodyText confidence="0.999972285714286">
The graph for our graph-based projection is con-
structed by connecting related vertex pairs by
weighted edges. If a given pair of vertices is likely to
have the same label, then the edge connecting these
vertices should have a large weight value.
We define three types of edges according to com-
binations of connected vertices. The first type of
edges consists of connections between an instance
vertex and a context vertex in the same language.
For a pair of an instance vertex vi,j and a context
vertex uk, these vertices are connected if the context
sequence of vi,j contains uk as a subsequence. If
vij is matched to uk, the edge weight w (vi,j, uk))
is assigned to 1. Otherwise, it should be 0.
Another edge category is for the pairs of context
vertices in a language. Because each context vertex
is considered to be an n-gram pattern in our work,
the weight value for each edge of this type represents
the pattern similarity between two context vertices.
The edge weight w(uk, ul) is computed by Jaccard’s
coefficient between uk and ul.
While the previous two categories of edges are
concerned with monolingual connections, the other
type addresses bilingual alignments of context ver-
tices between the source language and the target lan-
guage. We define the weight for a bilingual edge
connecting uks and ult as the relative frequency of
alignments, as follows:
</bodyText>
<equation confidence="0.862339">
w(uk ult) = count (uks ut) / count (uks, utm) ,
uM
�
</equation>
<bodyText confidence="0.997546">
where count (us, ut) is the number of alignments
between us and ut across the whole parallel corpus.
</bodyText>
<sectionHeader confidence="0.997301" genericHeader="method">
4 Label Propagation
</sectionHeader>
<bodyText confidence="0.999982333333333">
To induce labels for all of the unlabeled vertices on
the graph constructed in Section 3, we utilize the
label propagation algorithm (Zhu and Ghahramani,
2002), which is a graph-based semi-supervised
learning algorithm.
First, we construct an n x n matrix T that rep-
resents transition probabilities for all of the vertex
pairs. After assigning all of the values on the ma-
trix, we normalize the matrix for each row, to make
the element values be probabilities. The other input
to the algorithm is an n x 2 matrix Y , which indi-
cates the probabilities of whether a given vertex vi is
positive or not. The matrix T and Y are initialized
by the values described in Section 3.
For the input matrices T and Y , label propagation
is performed by multiplying the two matrices, to up-
date the Y matrix. This multiplication is repeated
until Y converges or until the number of iterations
exceeds a specific number. The Y matrix, after fin-
ishing its iterations, is considered to be the result of
the algorithm.
</bodyText>
<sectionHeader confidence="0.99813" genericHeader="method">
5 Implementation
</sectionHeader>
<bodyText confidence="0.9996185">
To demonstrate the effectiveness of the graph-based
projection approach for relation extraction, we de-
veloped a Korean relation extraction system that was
trained with projected annotations from English re-
sources. We used an English-Korean parallel cor-
pus 1 that contains 266,892 bi-sentence pairs in En-
glish and Korean. We obtained 155,409 positive in-
stances from the English sentences using an off-the-
shelf relation extraction system, ReVerb 2 (Fader et
al., 2011).
</bodyText>
<footnote confidence="0.999951333333333">
1The parallel corpus collected is available in our website:
http://isoft.postech.ac.kr/˜megaup/acl/datasets
2http://reverb.cs.washington.edu/
</footnote>
<page confidence="0.99791">
50
</page>
<tableCaption confidence="0.881918333333333">
Table 1: Comparison between direct and graph-based
projection approaches to extract semantic relationships
for four relation types
</tableCaption>
<table confidence="0.999483285714286">
Type P Direct F Graph-based
R P R F
Acquisition 51.6 87.7 64.9 55.3 91.2 68.9
Birthplace 69.8 84.5 76.4 73.8 87.3 80.0
Inventor Of 62.4 85.3 72.1 66.3 89.7 76.3
Won Prize 73.3 80.5 76.7 76.4 82.9 79.5
Total 63.9 84.2 72.7 67.7 87.4 76.3
</table>
<bodyText confidence="0.9994820625">
The English sentence annotations in the parallel
corpus were then propagated into the correspond-
ing Korean sentences. We used the GIZA++ soft-
ware 3 (Och and Ney, 2003) to obtain the word align-
ments for each bi-sentence in the parallel corpus.
The graph-based projection was performed by the
Junto toolkit 4 with the maximum number of itera-
tions of 10 for each execution.
Projected instances were utilized as training ex-
amples to learn the Korean relation extractor. We
built a tree kernel-based support vector machine
model using SVM-Light 5 (Joachims, 1998) and
Tree Kernel tools 6 (Moschitti, 2006). In our model,
we adopted the subtree kernel method for the short-
est path dependency kernel (Bunescu and Mooney,
2005).
</bodyText>
<sectionHeader confidence="0.999237" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.999915142857143">
The experiments were performed on the manu-
ally annotated Korean test dataset. The dataset
was built following the approach of Bunescu and
Mooney (Bunescu and Mooney, 2007). The dataset
consists of 500 sentences for four relation types: Ac-
quisition, Birthplace, Inventor of, and Won Prize. Of
these, 278 sentences were annotated as positive in-
stances.
The first experiment aimed to compare two sys-
tems constructed by the direct projection (Kim et al.,
2010) and graph-based projection approach. Table 1
shows the performances of the relation extraction of
the two systems. The graph-based system achieved
better performances in precision and recall than the
</bodyText>
<footnote confidence="0.999956">
3http://code.google.com/p/giza-pp/
4http://code.google.com/p/junto/
5http://svmlight.joachims.org/
6http://disi.unitn.it/ moschitt/Tree-Kernel.htm
</footnote>
<tableCaption confidence="0.994662">
Table 2: Comparisons of our projection approach to
</tableCaption>
<table confidence="0.9987294">
heuristic and Wikipedia-based approaches
Approach P R F
Heuristic-based 92.31 17.27 29.09
Wikipedia-based 66.67 66.91 66.79
Projection-based 67.69 87.41 76.30
</table>
<bodyText confidence="0.996408647058823">
system with direct projection for all of the four re-
lation types. It outperformed the baseline system by
an F-measure of 3.63.
To demonstrate the merits of our work against
other approaches based on monolingual external re-
sources, we performed comparisons with the fol-
lowing two baselines: heuristic-based (Banko et
al., 2007) and Wikipedia-based approaches (Wu and
Weld, 2010). The heuristic-based baseline was built
on the Sejong treebank corpus (Kim, 2006) and the
Wikipedia-based baseline used Korean Wikipedia
articles 7. Table 2 compares the performances of the
two baseline systems and our method. Our proposed
projection-based approach obtained better perfor-
mance than the other systems. It outperformed the
heuristic-based system by 47.21 and the Wikipedia-
based system by 9.51 in the F-measure.
</bodyText>
<sectionHeader confidence="0.995303" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999981833333333">
This paper presented a novel graph-based projection
approach for relation extraction. Our approach per-
formed a label propagation algorithm on a proposed
graph that represented the instance and context fea-
tures of both the source and target languages. The
feasibility of our approach was demonstrated by our
Korean relation extraction system. Experimental re-
sults show that our graph-based projection helped to
improve the performance of the cross-lingual anno-
tation projection of the semantic relations, and our
system outperforms the other systems, which incor-
porate monolingual external resources.
In this work, we operated the graph-based pro-
jection under very restricted conditions, because of
high complexity of the algorithm. For future work,
we plan to relieve the complexity problem for deal-
ing with more expanded graph structure to improve
the performance of our proposed approach.
</bodyText>
<footnote confidence="0.988458">
7We used the Korean Wikipedia database dump as of June
2011.
</footnote>
<page confidence="0.998773">
51
</page>
<sectionHeader confidence="0.995228" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999756">
This research was supported by the MKE(The
Ministry of Knowledge Economy), Korea, un-
der the ITRC(Information Technology Research
Center) support program (NIPA-2012-(H0301-12-
3001)) supervised by the NIPA(National IT Industry
Promotion Agency) and Industrial Strategic technol-
ogy development program, 10035252, development
of dialog-based spontaneous speech interface tech-
nology on mobile platform, funded by the Ministry
of Knowledge Economy(MKE, Korea).
</bodyText>
<sectionHeader confidence="0.99938" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999314655555556">
E. Agichtein and L. Gravano. 2000. Snowball: Ex-
tracting relations from large plain-text collections. In
Proceedings of the fifth ACM conference on Digital li-
braries, pages 85–94.
M. Banko, M. J Cafarella, S. Soderland, M. Broadhead,
and O. Etzioni. 2007. Open information extrac-
tion from the web. In Proceedings of the 20th In-
ternational Joint Conference on Artificial Intelligence,
pages 2670–2676.
R. Bunescu and R. Mooney. 2005. A shortest path de-
pendency kernel for relation extraction. In Proceed-
ings of the conference on Human Language Technol-
ogy and Empirical Methods in Natural Language Pro-
cessing, pages 724–731.
R. Bunescu and R. Mooney. 2007. Learning to extract
relations from the web using minimal supervision. In
Proceedings of the 45th annual meeting of the Associ-
ation for Computational Linguistics, volume 45, pages
576–583.
J. Chen, D. Ji, C. L Tan, and Z. Niu. 2006. Relation ex-
traction using label propagation based semi-supervised
learning. In Proceedings of the 21st International
Conference on Computational Linguistics and the 44th
annual meeting of the Association for Computational
Linguistics, pages 129–136.
D. Das and S. Petrov. 2011. Unsupervised part-of-
speech tagging with bilingual graph-based projections.
In Proceedings of the 49th Annual Meeting of the As-
sociation for Computational Linguistics: Human Lan-
guage Technologies, pages 600–609.
G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw,
S. Strassel, and R. Weischedel. 2004. The auto-
matic content extraction (ACE) program–tasks, data,
and evaluation. In Proceedings of LREC, volume 4,
pages 837–840.
A. Fader, S. Soderland, and O. Etzioni. 2011. Identify-
ing relations for open information extraction. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing, pages 1535–1545.
R. Grishman and B. Sundheim. 1996. Message under-
standing conference-6: A brief history. In Proceedings
of the 16th conference on Computational linguistics,
volume 1, pages 466–471.
R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Ko-
lak. 2005. Bootstrapping parsers via syntactic projec-
tion across parallel texts. Natural language engineer-
ing, 11(3):311–325.
T. Joachims. 1998. Text categorization with support vec-
tor machines: Learning with many relevant features.
In Proceedings of the European Conference on Ma-
chine Learning, pages 137–142.
N. Kambhatla. 2004. Combining lexical, syntactic,
and semantic features with maximum entropy mod-
els for extracting relations. In Proceedings of the
ACL 2004 on Interactive poster and demonstration
sessions, pages 22–25.
S. Kim, M. Jeong, J. Lee, and G. G Lee. 2010. A cross-
lingual annotation projection approach for relation de-
tection. In Proceedings of the 23rd International Con-
ference on Computational Linguistics, pages 564–571.
H. Kim. 2006. Korean national corpus in the 21st cen-
tury sejong project. In Proceedings of the 13th NIJL
International Symposium, pages 49–54.
A. Moschitti. 2006. Making tree kernels practical for
natural language learning. In Proceedings of the 11th
Conference of the European Chapter of the Associa-
tion for Computational Linguistics, volume 6, pages
113–120.
F. J Och and H. Ney. 2003. A systematic comparison of
various statistical alignment models. Computational
linguistics, 29(1):19–51.
S. Pado and M. Lapata. 2009. Cross-lingual annotation
projection of semantic roles. Journal ofArtificial In-
telligence Research, 36(1):307–340.
E. Riloff and R. Jones. 1999. Learning dictionaries for
information extraction by multi-level bootstrapping.
In Proceedings of the National Conference on Artifi-
cial Intelligence, pages 474–479.
F. Wu and D. Weld. 2010. Open information extraction
using wikipedia. In Proceedings of the 48th Annual
Meeting ofthe Association for Computational Linguis-
tics, pages 118–127.
D. Yarowsky and G. Ngai. 2001. Inducing multilingual
POS taggers and NP bracketers via robust projection
across aligned corpora. In Proceedings of the Second
Meeting of the North American Chapter of the Associ-
ation for Computational Linguistics, pages 1–8.
D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. In-
ducing multilingual text analysis tools via robust pro-
jection across aligned corpora. In Proceedings of the
</reference>
<page confidence="0.975261">
52
</page>
<reference confidence="0.997049913043478">
First International Conference on Human Language
Technology Research, pages 1–8.
D. Zelenko, C. Aone, and A. Richardella. 2003. Kernel
methods for relation extraction. The Journal of Ma-
chine Learning Research, 3:1083–1106.
M. Zhang, J. Zhang, J. Su, and G. Zhou. 2006. A com-
posite kernel to extract relations between entities with
both flat and structured features. In Proceedings of the
21st International Conference on Computational Lin-
guistics and the 44th annual meeting of the Associa-
tion for Computational Linguistics, pages 825–832.
Z. Zhang. 2004. Weakly-supervised relation classifica-
tion for information extraction. In Proceedings of the
thirteenth ACM international conference on Informa-
tion and knowledge management, pages 581–588.
X. Zhu and Z. Ghahramani. 2002. Learning from labeled
and unlabeled data with label propagation. School
Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA,
Tech. Rep. CMU-CALD-02-107.
I. Zitouni and R. Florian. 2008. Mention detection cross-
ing the language barrier. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 600–609.
</reference>
<page confidence="0.999348">
53
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.421203">
<title confidence="0.918057333333333">A Graph-based Cross-lingual Projection Approach Weakly Supervised Relation Extraction Seokhwan</title>
<author confidence="0.559472">Human Language Technology</author>
<affiliation confidence="0.867416">Institute for Infocomm</affiliation>
<address confidence="0.767915">Singapore</address>
<email confidence="0.9766">kims@i2r.a-star.edu.sg</email>
<author confidence="0.993856">Gary Geunbae</author>
<affiliation confidence="0.9999345">Dept. of Computer Science and Pohang University of Science and</affiliation>
<address confidence="0.985532">Pohang, 790-784,</address>
<email confidence="0.993495">gblee@postech.ac.kr</email>
<abstract confidence="0.998528333333333">Although researchers have conducted extensive studies on relation extraction in the last decade, supervised approaches are still limited because they require large amounts of training data to achieve high performances. To build a relation extractor without significant annotation effort, we can exploit cross-lingual annotation projection, which leverages parallel corpora as external resources for supervision. This paper proposes a novel graph-based projection approach and demonstrates the merits of it by using a Korean relation extraction system based on projected dataset from an English-Korean parallel corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agichtein</author>
<author>L Gravano</author>
</authors>
<title>Snowball: Extracting relations from large plain-text collections.</title>
<date>2000</date>
<booktitle>In Proceedings of the fifth ACM conference on Digital libraries,</booktitle>
<pages>85--94</pages>
<contexts>
<context position="2131" citStr="Agichtein and Gravano, 2000" startWordPosition="302" endWordPosition="305"> available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relat</context>
</contexts>
<marker>Agichtein, Gravano, 2000</marker>
<rawString>E. Agichtein and L. Gravano. 2000. Snowball: Extracting relations from large plain-text collections. In Proceedings of the fifth ACM conference on Digital libraries, pages 85–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Banko</author>
<author>M J Cafarella</author>
<author>S Soderland</author>
<author>M Broadhead</author>
<author>O Etzioni</author>
</authors>
<title>Open information extraction from the web.</title>
<date>2007</date>
<booktitle>In Proceedings of the 20th International Joint Conference on Artificial Intelligence,</booktitle>
<pages>2670--2676</pages>
<contexts>
<context position="2481" citStr="Banko et al., 2007" startWordPosition="356" endWordPosition="359">or learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relation extraction (Kim et al., 2010). To obtain training examples in the resource-poor target language, this approach exploited a cross-lingual annotation projection by propagating annotations that were generated by a relation extraction system in a resourcerich source language. In this approach, projected annotations were determined in a single pass </context>
<context position="14686" citStr="Banko et al., 2007" startWordPosition="2324" endWordPosition="2327">to/ 5http://svmlight.joachims.org/ 6http://disi.unitn.it/ moschitt/Tree-Kernel.htm Table 2: Comparisons of our projection approach to heuristic and Wikipedia-based approaches Approach P R F Heuristic-based 92.31 17.27 29.09 Wikipedia-based 66.67 66.91 66.79 Projection-based 67.69 87.41 76.30 system with direct projection for all of the four relation types. It outperformed the baseline system by an F-measure of 3.63. To demonstrate the merits of our work against other approaches based on monolingual external resources, we performed comparisons with the following two baselines: heuristic-based (Banko et al., 2007) and Wikipedia-based approaches (Wu and Weld, 2010). The heuristic-based baseline was built on the Sejong treebank corpus (Kim, 2006) and the Wikipedia-based baseline used Korean Wikipedia articles 7. Table 2 compares the performances of the two baseline systems and our method. Our proposed projection-based approach obtained better performance than the other systems. It outperformed the heuristic-based system by 47.21 and the Wikipediabased system by 9.51 in the F-measure. 7 Conclusions This paper presented a novel graph-based projection approach for relation extraction. Our approach performed</context>
</contexts>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>M. Banko, M. J Cafarella, S. Soderland, M. Broadhead, and O. Etzioni. 2007. Open information extraction from the web. In Proceedings of the 20th International Joint Conference on Artificial Intelligence, pages 2670–2676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bunescu</author>
<author>R Mooney</author>
</authors>
<title>A shortest path dependency kernel for relation extraction.</title>
<date>2005</date>
<booktitle>In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing,</booktitle>
<pages>724--731</pages>
<contexts>
<context position="1255" citStr="Bunescu and Mooney, 2005" startWordPosition="169" endWordPosition="172">annotation effort, we can exploit cross-lingual annotation projection, which leverages parallel corpora as external resources for supervision. This paper proposes a novel graph-based projection approach and demonstrates the merits of it by using a Korean relation extraction system based on projected dataset from an English-Korean parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training sa</context>
<context position="13331" citStr="Bunescu and Mooney, 2005" startWordPosition="2135" endWordPosition="2138">nding Korean sentences. We used the GIZA++ software 3 (Och and Ney, 2003) to obtain the word alignments for each bi-sentence in the parallel corpus. The graph-based projection was performed by the Junto toolkit 4 with the maximum number of iterations of 10 for each execution. Projected instances were utilized as training examples to learn the Korean relation extractor. We built a tree kernel-based support vector machine model using SVM-Light 5 (Joachims, 1998) and Tree Kernel tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on the manually annotated Korean test dataset. The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). The dataset consists of 500 sentences for four relation types: Acquisition, Birthplace, Inventor of, and Won Prize. Of these, 278 sentences were annotated as positive instances. The first experiment aimed to compare two systems constructed by the direct projection (Kim et al., 2010) and graph-based projection approach. Table 1 shows the performances of the relation extraction of the two systems. The graph-bas</context>
</contexts>
<marker>Bunescu, Mooney, 2005</marker>
<rawString>R. Bunescu and R. Mooney. 2005. A shortest path dependency kernel for relation extraction. In Proceedings of the conference on Human Language Technology and Empirical Methods in Natural Language Processing, pages 724–731.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bunescu</author>
<author>R Mooney</author>
</authors>
<title>Learning to extract relations from the web using minimal supervision.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th annual meeting of the Association for Computational Linguistics,</booktitle>
<volume>45</volume>
<pages>576--583</pages>
<contexts>
<context position="13517" citStr="Bunescu and Mooney, 2007" startWordPosition="2164" endWordPosition="2167">med by the Junto toolkit 4 with the maximum number of iterations of 10 for each execution. Projected instances were utilized as training examples to learn the Korean relation extractor. We built a tree kernel-based support vector machine model using SVM-Light 5 (Joachims, 1998) and Tree Kernel tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on the manually annotated Korean test dataset. The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). The dataset consists of 500 sentences for four relation types: Acquisition, Birthplace, Inventor of, and Won Prize. Of these, 278 sentences were annotated as positive instances. The first experiment aimed to compare two systems constructed by the direct projection (Kim et al., 2010) and graph-based projection approach. Table 1 shows the performances of the relation extraction of the two systems. The graph-based system achieved better performances in precision and recall than the 3http://code.google.com/p/giza-pp/ 4http://code.google.com/p/junto/ 5http://svmlight.joachims.org/ 6http://disi.un</context>
</contexts>
<marker>Bunescu, Mooney, 2007</marker>
<rawString>R. Bunescu and R. Mooney. 2007. Learning to extract relations from the web using minimal supervision. In Proceedings of the 45th annual meeting of the Association for Computational Linguistics, volume 45, pages 576–583.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chen</author>
<author>D Ji</author>
<author>C L Tan</author>
<author>Z Niu</author>
</authors>
<title>Relation extraction using label propagation based semi-supervised learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>129--136</pages>
<contexts>
<context position="2164" citStr="Chen et al., 2006" startWordPosition="308" endWordPosition="311">, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relation extraction (Kim et al., 2010)</context>
</contexts>
<marker>Chen, Ji, Tan, Niu, 2006</marker>
<rawString>J. Chen, D. Ji, C. L Tan, and Z. Niu. 2006. Relation extraction using label propagation based semi-supervised learning. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 129–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Das</author>
<author>S Petrov</author>
</authors>
<title>Unsupervised part-ofspeech tagging with bilingual graph-based projections.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>600--609</pages>
<contexts>
<context position="6538" citStr="Das and Petrov, 2011" startWordPosition="991" endWordPosition="994">pproach is still vulnerable to erroneous inputs generated by submodules. We note two main causes for this limitation: (1) the direct projection approach considers only alignments between entity candidates, and it does not consider any contextual information; and, (2) it is performed by a single pass process. To solve both of these problems at once, we propose a graph-based projection approach for relation extraction. 3 Graph Construction The most crucial factor in the success of graphbased learning approaches is how to construct a graph that is appropriate for the target task. Das and Petrov (Das and Petrov, 2011) proposed a graphbased bilingual projection of part-of-speech tagging by considering the tagged words in the source language as labeled examples and connecting them to the unlabeled words in the target language, while referring to the word alignments. Graph construction for projecting semantic relationships is more complicated than part-of-speech tagging because the unit instance of projection is a pair of entities and not a word or morpheme that is equivalent to the alignment unit. 3.1 Graph Vertices To construct a graph for a relation projection, we define two types of vertices: instance ver</context>
</contexts>
<marker>Das, Petrov, 2011</marker>
<rawString>D. Das and S. Petrov. 2011. Unsupervised part-ofspeech tagging with bilingual graph-based projections. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 600–609.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
<author>A Mitchell</author>
<author>M Przybocki</author>
<author>L Ramshaw</author>
<author>S Strassel</author>
<author>R Weischedel</author>
</authors>
<title>The automatic content extraction (ACE) program–tasks, data, and evaluation.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>4</volume>
<pages>837--840</pages>
<contexts>
<context position="1587" citStr="Doddington et al., 2004" startWordPosition="221" endWordPosition="224">parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation </context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw, S. Strassel, and R. Weischedel. 2004. The automatic content extraction (ACE) program–tasks, data, and evaluation. In Proceedings of LREC, volume 4, pages 837–840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fader</author>
<author>S Soderland</author>
<author>O Etzioni</author>
</authors>
<title>Identifying relations for open information extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1535--1545</pages>
<contexts>
<context position="12097" citStr="Fader et al., 2011" startWordPosition="1942" endWordPosition="1945">of iterations exceeds a specific number. The Y matrix, after finishing its iterations, is considered to be the result of the algorithm. 5 Implementation To demonstrate the effectiveness of the graph-based projection approach for relation extraction, we developed a Korean relation extraction system that was trained with projected annotations from English resources. We used an English-Korean parallel corpus 1 that contains 266,892 bi-sentence pairs in English and Korean. We obtained 155,409 positive instances from the English sentences using an off-theshelf relation extraction system, ReVerb 2 (Fader et al., 2011). 1The parallel corpus collected is available in our website: http://isoft.postech.ac.kr/˜megaup/acl/datasets 2http://reverb.cs.washington.edu/ 50 Table 1: Comparison between direct and graph-based projection approaches to extract semantic relationships for four relation types Type P Direct F Graph-based R P R F Acquisition 51.6 87.7 64.9 55.3 91.2 68.9 Birthplace 69.8 84.5 76.4 73.8 87.3 80.0 Inventor Of 62.4 85.3 72.1 66.3 89.7 76.3 Won Prize 73.3 80.5 76.7 76.4 82.9 79.5 Total 63.9 84.2 72.7 67.7 87.4 76.3 The English sentence annotations in the parallel corpus were then propagated into the</context>
</contexts>
<marker>Fader, Soderland, Etzioni, 2011</marker>
<rawString>A. Fader, S. Soderland, and O. Etzioni. 2011. Identifying relations for open information extraction. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1535–1545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>B Sundheim</author>
</authors>
<title>Message understanding conference-6: A brief history.</title>
<date>1996</date>
<booktitle>In Proceedings of the 16th conference on Computational linguistics,</booktitle>
<volume>1</volume>
<pages>466--471</pages>
<contexts>
<context position="1553" citStr="Grishman and Sundheim, 1996" startWordPosition="214" endWordPosition="218">jected dataset from an English-Korean parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et</context>
</contexts>
<marker>Grishman, Sundheim, 1996</marker>
<rawString>R. Grishman and B. Sundheim. 1996. Message understanding conference-6: A brief history. In Proceedings of the 16th conference on Computational linguistics, volume 1, pages 466–471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Hwa</author>
<author>P Resnik</author>
<author>A Weinberg</author>
<author>C Cabezas</author>
<author>O Kolak</author>
</authors>
<title>Bootstrapping parsers via syntactic projection across parallel texts. Natural language engineering,</title>
<date>2005</date>
<pages>11--3</pages>
<contexts>
<context position="5132" citStr="Hwa et al., 2005" startWordPosition="767" endWordPosition="770">xtractor fs for a resource-rich source language Ls and a parallel corpus of Ls and Lt. Figure 1 shows an example of annotation projection for relation extraction with a bi-text in Lt Korean and Ls English. Given an English sentence, an instance (Barack Obama, Honolulu) is extracted as positive. Then, its translational counterpart (beo-rak-o-ba-ma, ho-nol-rul-ru) in the Korean sentence also has a positive annotation by projection. Early studies in cross-lingual annotation projection were accomplished for various natural language processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These studies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strategy can be formularized as follows: ft (eit, et ) = � � fs A(eit), A(ej t ) , where A(et) is the aligned entity of et. However, these automatic annotations can be unreliable because of source text mis-classification and word alignment errors; thus, it can cause a critic</context>
</contexts>
<marker>Hwa, Resnik, Weinberg, Cabezas, Kolak, 2005</marker>
<rawString>R. Hwa, P. Resnik, A. Weinberg, C. Cabezas, and O. Kolak. 2005. Bootstrapping parsers via syntactic projection across parallel texts. Natural language engineering, 11(3):311–325.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Text categorization with support vector machines: Learning with many relevant features.</title>
<date>1998</date>
<booktitle>In Proceedings of the European Conference on Machine Learning,</booktitle>
<pages>137--142</pages>
<contexts>
<context position="13170" citStr="Joachims, 1998" startWordPosition="2110" endWordPosition="2111"> 76.7 76.4 82.9 79.5 Total 63.9 84.2 72.7 67.7 87.4 76.3 The English sentence annotations in the parallel corpus were then propagated into the corresponding Korean sentences. We used the GIZA++ software 3 (Och and Ney, 2003) to obtain the word alignments for each bi-sentence in the parallel corpus. The graph-based projection was performed by the Junto toolkit 4 with the maximum number of iterations of 10 for each execution. Projected instances were utilized as training examples to learn the Korean relation extractor. We built a tree kernel-based support vector machine model using SVM-Light 5 (Joachims, 1998) and Tree Kernel tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on the manually annotated Korean test dataset. The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). The dataset consists of 500 sentences for four relation types: Acquisition, Birthplace, Inventor of, and Won Prize. Of these, 278 sentences were annotated as positive instances. The first experiment aimed to compare two systems constructed by the dire</context>
</contexts>
<marker>Joachims, 1998</marker>
<rawString>T. Joachims. 1998. Text categorization with support vector machines: Learning with many relevant features. In Proceedings of the European Conference on Machine Learning, pages 137–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Kambhatla</author>
</authors>
<title>Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>22--25</pages>
<contexts>
<context position="1229" citStr="Kambhatla, 2004" startWordPosition="167" endWordPosition="168">hout significant annotation effort, we can exploit cross-lingual annotation projection, which leverages parallel corpora as external resources for supervision. This paper proposes a novel graph-based projection approach and demonstrates the merits of it by using a Korean relation extraction system based on projected dataset from an English-Korean parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there a</context>
</contexts>
<marker>Kambhatla, 2004</marker>
<rawString>N. Kambhatla. 2004. Combining lexical, syntactic, and semantic features with maximum entropy models for extracting relations. In Proceedings of the ACL 2004 on Interactive poster and demonstration sessions, pages 22–25.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kim</author>
<author>M Jeong</author>
<author>J Lee</author>
<author>G G Lee</author>
</authors>
<title>A crosslingual annotation projection approach for relation detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics,</booktitle>
<pages>564--571</pages>
<contexts>
<context position="2764" citStr="Kim et al., 2010" startWordPosition="401" endWordPosition="404">hen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relation extraction (Kim et al., 2010). To obtain training examples in the resource-poor target language, this approach exploited a cross-lingual annotation projection by propagating annotations that were generated by a relation extraction system in a resourcerich source language. In this approach, projected annotations were determined in a single pass process by considering only alignments between entity candidates; we call this action direct projection. In this paper, we propose a graph-based projection approach for weakly supervised relation extraction. This approach utilizes a graph that is constucted with both instance and co</context>
<context position="5892" citStr="Kim et al., 2010" startWordPosition="887" endWordPosition="890">in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strategy can be formularized as follows: ft (eit, et ) = � � fs A(eit), A(ej t ) , where A(et) is the aligned entity of et. However, these automatic annotations can be unreliable because of source text mis-classification and word alignment errors; thus, it can cause a critical falling-off in the annotation projection quality. Although some noise reduction strategies for projecting semantic relations were proposed (Kim et al., 2010), the direct projection approach is still vulnerable to erroneous inputs generated by submodules. We note two main causes for this limitation: (1) the direct projection approach considers only alignments between entity candidates, and it does not consider any contextual information; and, (2) it is performed by a single pass process. To solve both of these problems at once, we propose a graph-based projection approach for relation extraction. 3 Graph Construction The most crucial factor in the success of graphbased learning approaches is how to construct a graph that is appropriate for the targ</context>
<context position="13802" citStr="Kim et al., 2010" startWordPosition="2210" endWordPosition="2213">l tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on the manually annotated Korean test dataset. The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). The dataset consists of 500 sentences for four relation types: Acquisition, Birthplace, Inventor of, and Won Prize. Of these, 278 sentences were annotated as positive instances. The first experiment aimed to compare two systems constructed by the direct projection (Kim et al., 2010) and graph-based projection approach. Table 1 shows the performances of the relation extraction of the two systems. The graph-based system achieved better performances in precision and recall than the 3http://code.google.com/p/giza-pp/ 4http://code.google.com/p/junto/ 5http://svmlight.joachims.org/ 6http://disi.unitn.it/ moschitt/Tree-Kernel.htm Table 2: Comparisons of our projection approach to heuristic and Wikipedia-based approaches Approach P R F Heuristic-based 92.31 17.27 29.09 Wikipedia-based 66.67 66.91 66.79 Projection-based 67.69 87.41 76.30 system with direct projection for all of t</context>
</contexts>
<marker>Kim, Jeong, Lee, Lee, 2010</marker>
<rawString>S. Kim, M. Jeong, J. Lee, and G. G Lee. 2010. A crosslingual annotation projection approach for relation detection. In Proceedings of the 23rd International Conference on Computational Linguistics, pages 564–571.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kim</author>
</authors>
<title>Korean national corpus in the 21st century sejong project.</title>
<date>2006</date>
<booktitle>In Proceedings of the 13th NIJL International Symposium,</booktitle>
<pages>49--54</pages>
<contexts>
<context position="14819" citStr="Kim, 2006" startWordPosition="2345" endWordPosition="2346">c and Wikipedia-based approaches Approach P R F Heuristic-based 92.31 17.27 29.09 Wikipedia-based 66.67 66.91 66.79 Projection-based 67.69 87.41 76.30 system with direct projection for all of the four relation types. It outperformed the baseline system by an F-measure of 3.63. To demonstrate the merits of our work against other approaches based on monolingual external resources, we performed comparisons with the following two baselines: heuristic-based (Banko et al., 2007) and Wikipedia-based approaches (Wu and Weld, 2010). The heuristic-based baseline was built on the Sejong treebank corpus (Kim, 2006) and the Wikipedia-based baseline used Korean Wikipedia articles 7. Table 2 compares the performances of the two baseline systems and our method. Our proposed projection-based approach obtained better performance than the other systems. It outperformed the heuristic-based system by 47.21 and the Wikipediabased system by 9.51 in the F-measure. 7 Conclusions This paper presented a novel graph-based projection approach for relation extraction. Our approach performed a label propagation algorithm on a proposed graph that represented the instance and context features of both the source and target l</context>
</contexts>
<marker>Kim, 2006</marker>
<rawString>H. Kim. 2006. Korean national corpus in the 21st century sejong project. In Proceedings of the 13th NIJL International Symposium, pages 49–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<volume>6</volume>
<pages>113--120</pages>
<contexts>
<context position="13212" citStr="Moschitti, 2006" startWordPosition="2117" endWordPosition="2118"> 67.7 87.4 76.3 The English sentence annotations in the parallel corpus were then propagated into the corresponding Korean sentences. We used the GIZA++ software 3 (Och and Ney, 2003) to obtain the word alignments for each bi-sentence in the parallel corpus. The graph-based projection was performed by the Junto toolkit 4 with the maximum number of iterations of 10 for each execution. Projected instances were utilized as training examples to learn the Korean relation extractor. We built a tree kernel-based support vector machine model using SVM-Light 5 (Joachims, 1998) and Tree Kernel tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on the manually annotated Korean test dataset. The dataset was built following the approach of Bunescu and Mooney (Bunescu and Mooney, 2007). The dataset consists of 500 sentences for four relation types: Acquisition, Birthplace, Inventor of, and Won Prize. Of these, 278 sentences were annotated as positive instances. The first experiment aimed to compare two systems constructed by the direct projection (Kim et al., 2010) and graph</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>A. Moschitti. 2006. Making tree kernels practical for natural language learning. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics, volume 6, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F J Och</author>
<author>H Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational linguistics,</journal>
<pages>29--1</pages>
<contexts>
<context position="12779" citStr="Och and Ney, 2003" startWordPosition="2045" endWordPosition="2048">tp://isoft.postech.ac.kr/˜megaup/acl/datasets 2http://reverb.cs.washington.edu/ 50 Table 1: Comparison between direct and graph-based projection approaches to extract semantic relationships for four relation types Type P Direct F Graph-based R P R F Acquisition 51.6 87.7 64.9 55.3 91.2 68.9 Birthplace 69.8 84.5 76.4 73.8 87.3 80.0 Inventor Of 62.4 85.3 72.1 66.3 89.7 76.3 Won Prize 73.3 80.5 76.7 76.4 82.9 79.5 Total 63.9 84.2 72.7 67.7 87.4 76.3 The English sentence annotations in the parallel corpus were then propagated into the corresponding Korean sentences. We used the GIZA++ software 3 (Och and Ney, 2003) to obtain the word alignments for each bi-sentence in the parallel corpus. The graph-based projection was performed by the Junto toolkit 4 with the maximum number of iterations of 10 for each execution. Projected instances were utilized as training examples to learn the Korean relation extractor. We built a tree kernel-based support vector machine model using SVM-Light 5 (Joachims, 1998) and Tree Kernel tools 6 (Moschitti, 2006). In our model, we adopted the subtree kernel method for the shortest path dependency kernel (Bunescu and Mooney, 2005). 6 Evaluation The experiments were performed on</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>F. J Och and H. Ney. 2003. A systematic comparison of various statistical alignment models. Computational linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pado</author>
<author>M Lapata</author>
</authors>
<title>Cross-lingual annotation projection of semantic roles.</title>
<date>2009</date>
<journal>Journal ofArtificial Intelligence Research,</journal>
<volume>36</volume>
<issue>1</issue>
<contexts>
<context position="5183" citStr="Pado and Lapata, 2009" startWordPosition="775" endWordPosition="778">ge Ls and a parallel corpus of Ls and Lt. Figure 1 shows an example of annotation projection for relation extraction with a bi-text in Lt Korean and Ls English. Given an English sentence, an instance (Barack Obama, Honolulu) is extracted as positive. Then, its translational counterpart (beo-rak-o-ba-ma, ho-nol-rul-ru) in the Korean sentence also has a positive annotation by projection. Early studies in cross-lingual annotation projection were accomplished for various natural language processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These studies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strategy can be formularized as follows: ft (eit, et ) = � � fs A(eit), A(ej t ) , where A(et) is the aligned entity of et. However, these automatic annotations can be unreliable because of source text mis-classification and word alignment errors; thus, it can cause a critical falling-off in the annotation projection quality</context>
</contexts>
<marker>Pado, Lapata, 2009</marker>
<rawString>S. Pado and M. Lapata. 2009. Cross-lingual annotation projection of semantic roles. Journal ofArtificial Intelligence Research, 36(1):307–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Riloff</author>
<author>R Jones</author>
</authors>
<title>Learning dictionaries for information extraction by multi-level bootstrapping.</title>
<date>1999</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence,</booktitle>
<pages>474--479</pages>
<contexts>
<context position="2102" citStr="Riloff and Jones, 1999" startWordPosition="298" endWordPosition="301">mantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind o</context>
</contexts>
<marker>Riloff, Jones, 1999</marker>
<rawString>E. Riloff and R. Jones. 1999. Learning dictionaries for information extraction by multi-level bootstrapping. In Proceedings of the National Conference on Artificial Intelligence, pages 474–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Wu</author>
<author>D Weld</author>
</authors>
<title>Open information extraction using wikipedia.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics,</booktitle>
<pages>118--127</pages>
<contexts>
<context position="2515" citStr="Wu and Weld, 2010" startWordPosition="362" endWordPosition="365">nguages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relation extraction (Kim et al., 2010). To obtain training examples in the resource-poor target language, this approach exploited a cross-lingual annotation projection by propagating annotations that were generated by a relation extraction system in a resourcerich source language. In this approach, projected annotations were determined in a single pass process by considering only alignm</context>
<context position="14737" citStr="Wu and Weld, 2010" startWordPosition="2331" endWordPosition="2334">n.it/ moschitt/Tree-Kernel.htm Table 2: Comparisons of our projection approach to heuristic and Wikipedia-based approaches Approach P R F Heuristic-based 92.31 17.27 29.09 Wikipedia-based 66.67 66.91 66.79 Projection-based 67.69 87.41 76.30 system with direct projection for all of the four relation types. It outperformed the baseline system by an F-measure of 3.63. To demonstrate the merits of our work against other approaches based on monolingual external resources, we performed comparisons with the following two baselines: heuristic-based (Banko et al., 2007) and Wikipedia-based approaches (Wu and Weld, 2010). The heuristic-based baseline was built on the Sejong treebank corpus (Kim, 2006) and the Wikipedia-based baseline used Korean Wikipedia articles 7. Table 2 compares the performances of the two baseline systems and our method. Our proposed projection-based approach obtained better performance than the other systems. It outperformed the heuristic-based system by 47.21 and the Wikipediabased system by 9.51 in the F-measure. 7 Conclusions This paper presented a novel graph-based projection approach for relation extraction. Our approach performed a label propagation algorithm on a proposed graph </context>
</contexts>
<marker>Wu, Weld, 2010</marker>
<rawString>F. Wu and D. Weld. 2010. Open information extraction using wikipedia. In Proceedings of the 48th Annual Meeting ofthe Association for Computational Linguistics, pages 118–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
</authors>
<title>Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="5091" citStr="Yarowsky and Ngai, 2001" startWordPosition="759" endWordPosition="762">f annotated text for ft, utilizing a well-made extractor fs for a resource-rich source language Ls and a parallel corpus of Ls and Lt. Figure 1 shows an example of annotation projection for relation extraction with a bi-text in Lt Korean and Ls English. Given an English sentence, an instance (Barack Obama, Honolulu) is extracted as positive. Then, its translational counterpart (beo-rak-o-ba-ma, ho-nol-rul-ru) in the Korean sentence also has a positive annotation by projection. Early studies in cross-lingual annotation projection were accomplished for various natural language processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These studies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strategy can be formularized as follows: ft (eit, et ) = � � fs A(eit), A(ej t ) , where A(et) is the aligned entity of et. However, these automatic annotations can be unreliable because of source text mis-classification and word alig</context>
</contexts>
<marker>Yarowsky, Ngai, 2001</marker>
<rawString>D. Yarowsky and G. Ngai. 2001. Inducing multilingual POS taggers and NP bracketers via robust projection across aligned corpora. In Proceedings of the Second Meeting of the North American Chapter of the Association for Computational Linguistics, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
<author>G Ngai</author>
<author>R Wicentowski</author>
</authors>
<title>Inducing multilingual text analysis tools via robust projection across aligned corpora.</title>
<date>2001</date>
<booktitle>In Proceedings of the First International Conference on Human Language Technology Research,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="5114" citStr="Yarowsky et al., 2001" startWordPosition="763" endWordPosition="766">utilizing a well-made extractor fs for a resource-rich source language Ls and a parallel corpus of Ls and Lt. Figure 1 shows an example of annotation projection for relation extraction with a bi-text in Lt Korean and Ls English. Given an English sentence, an instance (Barack Obama, Honolulu) is extracted as positive. Then, its translational counterpart (beo-rak-o-ba-ma, ho-nol-rul-ru) in the Korean sentence also has a positive annotation by projection. Early studies in cross-lingual annotation projection were accomplished for various natural language processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These studies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strategy can be formularized as follows: ft (eit, et ) = � � fs A(eit), A(ej t ) , where A(et) is the aligned entity of et. However, these automatic annotations can be unreliable because of source text mis-classification and word alignment errors; thus, it </context>
</contexts>
<marker>Yarowsky, Ngai, Wicentowski, 2001</marker>
<rawString>D. Yarowsky, G. Ngai, and R. Wicentowski. 2001. Inducing multilingual text analysis tools via robust projection across aligned corpora. In Proceedings of the First International Conference on Human Language Technology Research, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Zelenko</author>
<author>C Aone</author>
<author>A Richardella</author>
</authors>
<title>Kernel methods for relation extraction.</title>
<date>2003</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>3--1083</pages>
<contexts>
<context position="1212" citStr="Zelenko et al., 2003" startWordPosition="162" endWordPosition="166">relation extractor without significant annotation effort, we can exploit cross-lingual annotation projection, which leverages parallel corpora as external resources for supervision. This paper proposes a novel graph-based projection approach and demonstrates the merits of it by using a Korean relation extraction system based on projected dataset from an English-Korean parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major l</context>
</contexts>
<marker>Zelenko, Aone, Richardella, 2003</marker>
<rawString>D. Zelenko, C. Aone, and A. Richardella. 2003. Kernel methods for relation extraction. The Journal of Machine Learning Research, 3:1083–1106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Zhang</author>
<author>J Zhang</author>
<author>J Su</author>
<author>G Zhou</author>
</authors>
<title>A composite kernel to extract relations between entities with both flat and structured features.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>825--832</pages>
<contexts>
<context position="1276" citStr="Zhang et al., 2006" startWordPosition="173" endWordPosition="176">exploit cross-lingual annotation projection, which leverages parallel corpora as external resources for supervision. This paper proposes a novel graph-based projection approach and demonstrates the merits of it by using a Korean relation extraction system based on projected dataset from an English-Korean parallel corpus. 1 Introduction Relation extraction aims to identify semantic relations of entities in a document. Although many supervised machine learning approaches have been successfully applied to relation extraction tasks (Zelenko et al., 2003; Kambhatla, 2004; Bunescu and Mooney, 2005; Zhang et al., 2006), applications of these approaches are still limited because they require a sufficient number of training examples to obtain good extraction results. Several datasets that provide manual annotations of semantic relationships are available from MUC (Grishman and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning ne</context>
</contexts>
<marker>Zhang, Zhang, Su, Zhou, 2006</marker>
<rawString>M. Zhang, J. Zhang, J. Su, and G. Zhou. 2006. A composite kernel to extract relations between entities with both flat and structured features. In Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 825–832.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Zhang</author>
</authors>
<title>Weakly-supervised relation classification for information extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of the thirteenth ACM international conference on Information and knowledge management,</booktitle>
<pages>581--588</pages>
<contexts>
<context position="2144" citStr="Zhang, 2004" startWordPosition="306" endWordPosition="307"> and Sundheim, 1996) and ACE (Doddington et al., 2004) projects, but these datasets contain labeled training examples in only a few major languages, including English, Chinese, and Arabic. Although these datasets encourage the development of relation extractors for these major languages, there are few labeled training samples for learning new systems in other languages, such as Korean. Because manual annotation of semantic relations for such resourcepoor languages is very expensive, we instead consider weakly supervised learning techniques (Riloff and Jones, 1999; Agichtein and Gravano, 2000; Zhang, 2004; Chen et al., 2006) to learn the relation extractors without significant annotation efforts. But these techniques still face cost problems when preparing quality seed examples, which plays a crucial role in obtaining good extractions. Recently, some researchers attempted to use external resources, such as treebank (Banko et al., 2007) and Wikipedia (Wu and Weld, 2010), that were not specially constructed for relation extraction instead of using task-specific training or seed examples. We previously proposed to leverage parallel corpora as a new kind of external resource for relation extractio</context>
</contexts>
<marker>Zhang, 2004</marker>
<rawString>Z. Zhang. 2004. Weakly-supervised relation classification for information extraction. In Proceedings of the thirteenth ACM international conference on Information and knowledge management, pages 581–588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
<author>Z Ghahramani</author>
</authors>
<title>Learning from labeled and unlabeled data with label propagation. School Comput. Sci.,</title>
<date>2002</date>
<tech>Tech. Rep. CMU-CALD-02-107.</tech>
<location>Carnegie Mellon Univ., Pittsburgh, PA,</location>
<contexts>
<context position="10774" citStr="Zhu and Ghahramani, 2002" startWordPosition="1718" endWordPosition="1721">s of edges are concerned with monolingual connections, the other type addresses bilingual alignments of context vertices between the source language and the target language. We define the weight for a bilingual edge connecting uks and ult as the relative frequency of alignments, as follows: w(uk ult) = count (uks ut) / count (uks, utm) , uM � where count (us, ut) is the number of alignments between us and ut across the whole parallel corpus. 4 Label Propagation To induce labels for all of the unlabeled vertices on the graph constructed in Section 3, we utilize the label propagation algorithm (Zhu and Ghahramani, 2002), which is a graph-based semi-supervised learning algorithm. First, we construct an n x n matrix T that represents transition probabilities for all of the vertex pairs. After assigning all of the values on the matrix, we normalize the matrix for each row, to make the element values be probabilities. The other input to the algorithm is an n x 2 matrix Y , which indicates the probabilities of whether a given vertex vi is positive or not. The matrix T and Y are initialized by the values described in Section 3. For the input matrices T and Y , label propagation is performed by multiplying the two </context>
</contexts>
<marker>Zhu, Ghahramani, 2002</marker>
<rawString>X. Zhu and Z. Ghahramani. 2002. Learning from labeled and unlabeled data with label propagation. School Comput. Sci., Carnegie Mellon Univ., Pittsburgh, PA, Tech. Rep. CMU-CALD-02-107.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Zitouni</author>
<author>R Florian</author>
</authors>
<title>Mention detection crossing the language barrier.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>600--609</pages>
<contexts>
<context position="5159" citStr="Zitouni and Florian, 2008" startWordPosition="771" endWordPosition="774">resource-rich source language Ls and a parallel corpus of Ls and Lt. Figure 1 shows an example of annotation projection for relation extraction with a bi-text in Lt Korean and Ls English. Given an English sentence, an instance (Barack Obama, Honolulu) is extracted as positive. Then, its translational counterpart (beo-rak-o-ba-ma, ho-nol-rul-ru) in the Korean sentence also has a positive annotation by projection. Early studies in cross-lingual annotation projection were accomplished for various natural language processing tasks (Yarowsky and Ngai, 2001; Yarowsky et al., 2001; Hwa et al., 2005; Zitouni and Florian, 2008; Pado and Lapata, 2009). These studies adopted a simple direct projection strategy that propagates the annotations in the source language sentences to word-aligned target sentences, and a target system can bootstrap from these projected annotations. For relation extraction, the direct projection strategy can be formularized as follows: ft (eit, et ) = � � fs A(eit), A(ej t ) , where A(et) is the aligned entity of et. However, these automatic annotations can be unreliable because of source text mis-classification and word alignment errors; thus, it can cause a critical falling-off in the annot</context>
</contexts>
<marker>Zitouni, Florian, 2008</marker>
<rawString>I. Zitouni and R. Florian. 2008. Mention detection crossing the language barrier. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 600–609.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>