<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<sectionHeader confidence="0.290121" genericHeader="abstract">
USING CLASSIFICATION TO GENERATE TEXT
</sectionHeader>
<author confidence="0.497516">
Ehud Reiter* and Chris Mellisht
</author>
<affiliation confidence="0.76787">
Department of Artificial Intelligence
University of Edinburgh
</affiliation>
<address confidence="0.553226">
80 South Bridge
Edinburgh EH1 1HN
</address>
<sectionHeader confidence="0.9439055" genericHeader="categories and subject descriptors">
BRITAIN
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999687625">
The IDAS natural-language generation system
uses a KL-ONE type classifier to perform content
determination, surface realisation, and part of text
planning. Generation-by-classification allows IDAS
to use a single representation and reasoning com-
ponent for both domain and linguistic knowledge,
which is difficult for systems based on unification
or systemic generation techniques.
</bodyText>
<sectionHeader confidence="0.975502" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999970266666667">
Classification is the name for the procedure of
automatically inserting new classes into the cor-
rect position in a KL-ONE type class taxonomy
[Brachman and Schmolze, 19851 When combined
with an attribute inheritance system, classifica-
tion provides a general pattern-matching and uni-
fication capability that can be used to do much
of the processing needed by NL generation sys-
tems, including content-determination, surface-
realisation, and portions of text planning. Classi-
fication and inheritance are used in this manner by
the IDAS natural language generation system [Re-
iter et al., 1992], and their use has allowed IDAS to
use a single knowledge representation system for
both linguistic and domain knowledge.
</bodyText>
<sectionHeader confidence="0.9447965" genericHeader="method">
IDAS and II.
IDAS
</sectionHeader>
<bodyText confidence="0.999757111111111">
IDAS is a natural-language generation system that
generates on-line documentation and help mes-
sages for users of complex equipment. It supports
user-tailoring and has a hypertext-like interface
that allows users to pose follow-up questions.
The input to WAS is a point in question
space, which specifies a basic question type (e.g.,
What-is-it), a component the question is being
asked about (e.g., Computer23), the user&apos;s task
</bodyText>
<footnote confidence="0.776749333333333">
(e.g. Replace-Part), the user&apos;s expertise-level
*E-mail address is E.Reitereed.ac.uk
tE-mail address is C.MellishOed.ac.uk
</footnote>
<bodyText confidence="0.980915333333333">
(e.g., Skilled), and the discourse in-focus list. The
generation process in IDAS uses the three stages
described in [Grosz et al., 1986]:
</bodyText>
<listItem confidence="0.746825583333333">
• Content Determination: A content-determin-
ation rule is chosen based on the inputs; this
rule specifies what information from the KB
should be communicated to the user, and
what overall format the response should use.
• Text Planning: An expression in the ISI
Sentence Planning Language (sPL) [Kasper,
1989] is formed from the information speci-
fied in the content-determination rule.
• Surface Realisation: The SPL is converted into
a surface form, i.e., actual words interspersed
with text-formatting commands.
</listItem>
<bodyText confidence="0.962221833333333">
Ii
Il is the knowledge representation system used
in WAS to represent domain knowledge, grammar
rules, lexicons, user tasks, user-expertise models,
and content-determination rules. The Il system
includes:
</bodyText>
<listItem confidence="0.99328">
• an automatic classifier;
• a default-inheritance system that inherits
properties from superclass to subclass, us-
ing Touretsky&apos;s [1986] minimal inferential dis-
tance principle to resolve conflicts;
• various support tools, such as a graphical
browser and editor.
</listItem>
<bodyText confidence="0.999615583333333">
An Il knowledge base (KB) consists of classes,
roles, and user-expertise models. User-expertise
models are represented as KB overlays, in a simi-
lar fashion to the FN system [Reiter, 1990]. Roles
are either definitional or assertional; only defini-
tional roles are used in the classification process.
Roles can be defined as having one filler or an arbi-
trary number of fillers, i.e., as having an inherent
&apos;number restriction&apos; of one or infinity.
An 11 class definition consists of at least one ex-
plicitly specified parent class, primitive? and in-
dividual? flags, value restrictions for definitional
</bodyText>
<page confidence="0.996206">
265
</page>
<bodyText confidence="0.994540125">
roles, and value specifications for assertional roles.
Ii does not support the more complex definitional
constructs of KL-ONE, such as structural descrip-
tions. The language for specifying assertional role
values is richer than that for specifying definitional
role value restrictions, and allows, for example:
measurements that specify a quantity and a unit;
references that specify the value of a role in terms
of a KL-ONE type role chain; and templates that
specify a parametrized class definition as a role
value. The general design goal of Il is to use a very
simple definitional language, so that classification
is computationally fast, but a rich assertional lan-
guage, so that complex things can be stated about
entities in the knowledge base.
An example Il class definition is:
</bodyText>
<figure confidence="0.84544685">
(define-class open-door
:parent open
:type defined
:prop
((actor animate-object)
(actee door)
(decomposition
((*template*
grasp
(actor = actor *sells)
(actee = (handle part) actee *sells))
(*template*
turn
(actor = actor *self*)
(actee = (handle part) actee *sells))
(*templates
pull
(actor = actor *sells)
(actee = (handle part) actee *sells))
))))
</figure>
<bodyText confidence="0.997679933333333">
This defines the class Open-door to be a
defined (non-primitive and non-individual) child
of the class Open. Actor and Actee are defini-
tional roles, so the values given for them in the
above definition are treated as definitional value
restrictions; i.e., an Open-Door entity is any
Open entity whose Actor role has a filler sub-
sumed by Animate-Object, and whose Actee
role has a filler subsumed by Door.
Decomposition is an assertional role, whose
value is a list of three templates. Each tem-
plate defines a class whose ancestor is an action
(Grasp, Turn, Pull) that has the same Actor as
the Open-Door action and that has an Actee
that is the filler of the Part role of the Actee
of the Open-Door action which is subsumed by
Handle (i.e., (handle part) is a differentiation
of Part onto Handle).
For example, if Open-12 was defined as an
Open action with role fillers Actor:Sam and
Actee:Door-6, then Open-12 would be classified
beneath Open-Door by the classifier on the basis
of its Actor and Actee values. If an inquiry was
issued for the value of Decomposition for Open-
12, the above definition from Open-Door would
be inherited, and, if Door-6 had Handle-6 as
one of its fillers for Part, the templates would be
expanded into a list of three actions, (Grasp-12
Turn-12 Pull-12), each of which had an Actor
of Sam and an Actee of Handle-6.
</bodyText>
<sectionHeader confidence="0.5367065" genericHeader="method">
Using Classification in
Generation
</sectionHeader>
<subsectionHeader confidence="0.997696">
Content Determination
</subsectionHeader>
<bodyText confidence="0.999578153846154">
The input to IDAS is a point in question space,
which specifies a basic question, component, user-
task, user-expertise model, and discourse in-focus
list. The first three members of this tuple are
used to pick a content-determination rule, which
specifies the information the generated response
should communicate. This is done by forming a
rule-instance with fillers that specify the basic-
question, component, and user-task; classifying
this rule-instance into a taxonomy of content-rule
classes, and reading off inherited values for vari-
ous attributive roles. A (simplified) example of a
content-rule class definition is:
</bodyText>
<figure confidence="0.974004777777778">
(define-class what-operations-rule
:parent content-rule
:type defined
:prop
((rule-question what)
(rule-task operations)
(rule-rolegroup
(manufacturer model-number colour))
(rule-funct ion
</figure>
<figureCaption confidence="0.479027">
(identify-schema :bullet? nil))))
</figureCaption>
<bodyText confidence="0.994489380952381">
Rule-Question and Rule-Task are definitional
roles that specify which queries a content rule
applies to; What-Operations-Rule is used for
&amp;quot;What&amp;quot; questions issued under an Operations task
(for any component). Rule-Rolegroup specifies
the role fillers of the target component that the
response should communicate to the user; What-
Operations-Rule specifies that the manufac-
turer, model-number, and colour of the target
component should be communicated to the user.
Rule-Function specifies a Lisp text-planning func-
tion that is called with these role fillers in or-
der to generate SPL. Content-rule class defini-
tions can also contain attributive roles that spec-
ify a human-readable title for the query; followup
queries that will be presented as hypertext click-
able buttons in the response window; objects to be
added to the discourse in-focus list; and a testing
function that determines if a query is answerable.
Content-determination in IDAS is therefore done
entirely by classification and feature inheritance;
</bodyText>
<page confidence="0.996532">
266
</page>
<bodyText confidence="0.999866272727273">
once the rule-instance has been formed from the
input query, the classifier is used to find the most
specific content-rule which applies to the rule-
instance, and the inheritance mechanism is then
used to obtain a specification for the KB informa-
tion that the response should communicate, the
text-planning function to be used, and other rele-
vant information.
IDAS &apos;s content-determination system is primar-
ily designed to allow human domain experts to rel-
atively easily specify the desired contents of short
(paragraph or smaller) responses. As such, it is
quite different from systems that depend on deeper
plan-based reasoning (e.g. [Wahlster et al., 1991;
Moore and Paris, 1989]). Authorability is stressed
in IDAS because we believe this is the best way to
achieve IDAs&apos;s goal of fairly broad, but not neces-
sarily deep, domain coverage; short responses are
stressed because IDAs&apos;s hypertext interface should
allow users to dynamically choose the paragraphs
they wish to read, i.e., perform their own high-
level text-planning [Reiter et cd., 19921.
</bodyText>
<subsectionHeader confidence="0.991299">
Text Planning
</subsectionHeader>
<bodyText confidence="0.998845285714286">
Text planning is the only part of the generation
process that is not entirely done by classification
in WAS. The job of IDAs&apos;s text-planning system
is to produce an SPL expression that communi-
cates the information specified by the content-
determination system. This involves, in partic-
ular:
</bodyText>
<listItem confidence="0.982303857142857">
• Determining how many sentences to use, and
what information each sentence should com-
municate (text structuring).
• Generating referring expressions that identify
domain entities to the user.
• Choosing lexical units (words) to express do-
main concepts to the user.
</listItem>
<bodyText confidence="0.99018187012987">
Classification is currently used only in the lexical-
choice portion of the text-planning process, and
even there it only performs part of this task.
Text structuring in IDAS is currently done in
a fairly trivial way; this could perhaps be im-
plemented with classification, but this would not
demonstrate anything interesting about the capa-
bilities of classification by generation. More so-
phisticated text-structuring techniques have been
discussed by, among others, Mann and Moore
[1981], who used a hill-climbing algorithm based
on an explicit preference function. We have not
to date investigated whether classification could
be used to implement this or other such text-
structuring algorithms.
Referring expressions in WAS are generated by
the algorithm described in [Reiter and Dale, 1992].
This algorithm is most naturally stated iteratively
in a conventional programming language; there
does not seem to be much point in attempting to
re-express it in terms of classification.
Lexical choice in IDAS is based on the ideas pre-
sented in [Reiter, 1991]. When an entity needs to
be lexicalized, it is classified into the main domain
taxonomy, and all ancestors of the class that have
lexical realisations in the current user-expertise
model are retrieved. Classes that are too general
to fulfill the system&apos;s communicative goal are re-
jected, and preference criteria (largely based on
lexical preferences recorded in the user-expertise
model) are then used to choose between the re-
maining lexicalizable ancestors.
For example, to lexicalize the action (Activate
with role fillers Actor:Sam and Actee:Toggle-
Switch-23) under the Skilled user-expertise
model, the classifier is called to place this action
in the taxonomy. In the current WAS knowledge
base, this action would have have two realisable
ancestors that are sufficiently informative to meet
an instructional communicative goal,&apos; Activate
(realisation &amp;quot;activate&amp;quot;) and (Activate with role
filler Actee:Switch) (realisation &amp;quot;flip&amp;quot;). Prefer-
ence criteria would pick the second ancestor, be-
cause it is marked as basic-level [Rosch, 1978] in
the Skilled user-expertise model. Hence, if &amp;quot;the
switch&amp;quot; is a valid referring expression for Toggle-
Switch-23, the entire action will be realised as
&amp;quot;Flip the switch&amp;quot;.
In short, lexical-choice in IDAS uses classification
to produce a set of possible lexicalizations, but
other considerations are used to choose the most
appropriate member of this set. The lexical-choice
system could be made entirely classification-based
if it was acceptable to always use the most spe-
cific realisable class that subsumed an entity, but
ignoring communicative goals and the user&apos;s pref-
erences in this way can cause inappropriate text
to be generated [Reiter, 1991].
In general, it may be the case that an entirely
classification-based approach is not appropriate
for tasks which require taking into consideration
complex pragmatic criteria, such as the user&apos;s lex-
ical preferences or the current discourse context
(classification may still be usefully used to per-
form part of these tasks, however, as is the case
in IDAs&apos;s lexical-choice module). It is not clear
to the authors how the user&apos;s lexical preferences
or the discourse context could even be encoded in
a manner that would make them easily accessi-
ble to a classifier-based generation algorithm, al-
though perhaps this simply means that more re-
search needs to be done on this issue.
&apos;The general class Action is an example of an an-
cestor class that is too general to meet the communica-
tive goal; if the user is simply told &amp;quot;Perform an action
on the switch&amp;quot;, he will not know that he is supposed
to activate the switch.
</bodyText>
<page confidence="0.976794">
267
</page>
<subsectionHeader confidence="0.96481">
Surface Realisation
</subsectionHeader>
<bodyText confidence="0.97304225">
Surface realisation is performed entirely by clas-
sification in IDAS. The SPL input to the surface
realisation system is interpreted as an Il class def-
inition, and is classified beneath an upper model
[Bateman et al., 1990]. The upper model dis-
tinguishes, for example, between Relational and
Nonrelational propositions, and Animate and
Inanimate objects.2 A new class is then created
whose parent is the desired grammatical unit (typ-
ically Complete-Phrase), and which has the SPL
class as a filler for the definitional Semantics role.
This class is classified, and the realisation of the
sentence is obtained by requesting the value of its
Realisation role (an attributive role).
A simplified example of an Il class that defines
a grammatical unit is:
</bodyText>
<figure confidence="0.989311666666667">
(define-class sentence
:parent complete-phrase
:type defined
:prop
((semantics predication)
(realisation
((*reference*
realisation subject *self*)
(*references
realisation predicate *self*)))
(number
(*reference* number subject *self*))
(subject
(*template*
noun-phrase
(semantics = actor semantics *self*)))
(predicate ...)
...))
</figure>
<bodyText confidence="0.9902674">
Semantics is a definitional role, so the above
definition is for children of Complete-Phrase
whose Semantics role is filled by something clas-
sified beneath Predication in the upper model.
It states that
</bodyText>
<listItem confidence="0.999059545454545">
• the Realisation of the class is formed by con-
catenating the realisation of the Subject of
the class with the realisation of the Predicate
of the class;
• the Number of the class is the Number of
the Subject of the class;
• the Subject of the class is obtained by creat-
ing a new class beneath Noun-Phrase whose
semantics is the Actor of the Semantics of
the class; this in essence is a recursive call to
realise a semantic constituent.
</listItem>
<footnote confidence="0.601104">
If some specialized types of Sentence need dif-
ferent values for Realisation, Number, Subject,
21Immksuppernuxhdisshuilartoasubsetofthe
PENMAN upper model.
</footnote>
<bodyText confidence="0.9710785">
or another attributive role value, this can be spec-
ified by creating a child of Sentence that uses
Il&apos;s default inheritance mechanism to selectively
override the relevant role fillers. For example,
</bodyText>
<figure confidence="0.645765375">
(define-class imperative
:parent sentence
:type defined
:prop
((semantics command)
(realisation
(*reference*
realisation predicate *self*))))
</figure>
<bodyText confidence="0.999172933333333">
This defines a new class Imperative that ap-
plies to Sentences whose Semantics filler is clas-
sified beneath Command in the upper model
(Command is a child of Predication). This
class inherits the values of the Number and Sub-
ject fillers from Sentence, but specifies a new
filler for Realisation, which is just the Realisation
of the Predicate of the class. In other words, the
above class informs the generation system of the
grammatical fact that imperative sentences do not
contain surface subjects. The classification system
places classes beneath their most specific parent in
the taxonomy, so to-be-realised classes always in-
herit realisation information from the most specific
grammatical-unit class that applies to them.
</bodyText>
<subsectionHeader confidence="0.939991">
The Role of Conflict Resolution
</subsectionHeader>
<bodyText confidence="0.999971">
In general terms, a classification system can be
thought of as supporting a pattern-matching pro-
cess, in which the definitional role fillers of a class
represent the pattern (e.g. (semantics command)
in Imperative), and the attributive roles (e.g.,
Realisation) specify some sort of action. In other
words, a classification system is in essence a way
of encoding pattern-action rules of the form:
</bodyText>
<equation confidence="0.894694">
al /31
a2 )32
</equation>
<bodyText confidence="0.999447705882353">
If several classes subsume an input, then clas-
sification systems use the attributive roles speci-
fied (or inherited by) the most specific subsuming
class; in production rule terminology, this means
that if several as &apos;s match an input, only the fl as-
sociated with the most specific matching ai is trig-
gered. In other words, classification systems use
the conflict resolution principle of always choosing
the most specific matching pattern-action rule.
This conflict-resolution principle is used in dif-
ferent ways by different parts of IDAS. The
content-determination system uses it as a prefer-
ence mechanism; if several content-determination
rules subsume an input query, any of these rules
can be used to generate a response, but presum-
ably the most appropriate response will be gener-
ated by the most specific subsuming rule. The
</bodyText>
<page confidence="0.987789">
268
</page>
<bodyText confidence="0.999738739130435">
lexical-choice system, in contrast, effectively ig-
nores the &apos;prefer most specific&apos; principle, and in-
stead uses its own preference criteria to choose
among the lexemes that subsume an entity. The
surface-generation system is different yet again, in
that it uses the conflict-resolution mechanism to
exclude inapplicable grammar rules. If a partic-
ular term is classified beneath Imperative, for
example, it also must be subsumed by Sentence,
but using the Realisation specified in Sentence
to realise this term would result in text that is
incorrect, not just stylistically inferior.
The &apos;use most specific matching rule&apos; conflict-
resolution principle is thus just a tool that can
be used by the system designer. In some cases it
can be used to implement preferences (as in mAs&apos;s
content-determination system); in some cases it
can be used to exclude incorrect rules which would
cause an error if they were used (as in IDAS&apos;S
surface-generation system); and in some cases it
needs to be overridden by a more appropriate
choice mechanism (as in iDAs&apos;s lexical choice sys-
tem).
</bodyText>
<sectionHeader confidence="0.7274225" genericHeader="method">
Classification vs. Other
Approaches
</sectionHeader>
<bodyText confidence="0.999629555555556">
Perhaps the most popular alternative approaches
to generation are unification (especially functional
unification) and systemic grammars. As with clas-
sification, the unification and systemic approaches
can be applied to all phases of the generation pro-
cess [McKeown et al., 1990; Patten, 1988].3 How-
ever, most of the published work on unification
and systemic systems deals with surface realisa-
tion, so it is easiest to focus on this task when
making a comparison with classification systems.
Like classification, unification and systemic sys-
tems can be thought of as supporting a recursive
pattern-matching process. All three frameworks
allow grammar rules to be written declaratively.
They also all support unrestricted recursion, i.e.,
they all allow a grammar rule to specify that a
constituent of the input should be recursively pro-
cessed by the grammar (mAs does this with Il&apos;s
template mechanism). In particular, this means
that all three approaches are Turing-equivalent.
There are differences in how patterns and actions
are specified in the three formalisms, but it is prob-
ably fair to say that all three approaches are suf-
ficiently flexible to be able to encode most desir-
able grammars. The choice between them must
therefore be made on the basis of which is easiest
to incorporate into a real NL generation system.
&apos;Although it is unclear whether unification or sys-
temic systems can do any better at the text-planning
tasks that are difficult for classification systems, such
as generating referring expressions.
We believe that classification has a significant ad-
vantage here because many generation systems al-
ready include a classifier to support reasoning on
a domain knowledge base; hence, using classifi-
cation for generation means the same knowledge
representation (KR) system can be used to sup-
port both domain and linguistic knowledge. Thus,
IDAS uses only one KR system — Ii — whereas
systems such as COMET (unification) [McKeown
et al., 1990] and PENMAN (systemic) [Penman
Natural Language Group, 1989] use two different
KR systems: a classifier-based system for domain
knowledge, and a unification or systemic system
for grammatical knowledge.
</bodyText>
<subsectionHeader confidence="0.850746">
Unification Systems
</subsectionHeader>
<bodyText confidence="0.989072">
The most popular unification formalism for gener-
ation up to now has probably been functional uni-
fication (FUG) [Kay, 1979]. FUG systems work by
searching for patterns (alternations) in the gram-
mar that unify with the system&apos;s input (i.e., uni-
fication is used for pattern-matching); inheriting
syntactic (output) feature values from the gram-
mar patterns (the actions); and recursively pro-
cessing members of the constituent set (the recur-
sion). That is, pattern-action rules of the above
kind are encoded as something like:
(al Ath) V (a2 A /62) V •••
If a unification system is based on a typed feature
logic, then its grammar can include classification-
like subsumption tests [Elhadad, 1990], and thus
be as expressive in specifying patterns as a classi-
fication system.
An initial formal comparison of unification with
classification is given in the Appendix. Perhaps
the most important practical differences are:
</bodyText>
<listItem confidence="0.995855285714286">
• Classification grammars cannot be used bidi-
rectionally, while unification grammars can
[Sheiber, 1988].
• Unification systems produce (at least in prin-
ciple) all surface forms that agree (unify) with
the semantic input; classification systems pro-
duce a single surface form output.
</listItem>
<bodyText confidence="0.999884090909091">
These differences are in a sense a result of the fact
that unification grammars represent general map-
pings between semantic and surface forms (and
hence can be used bidirectionally, and produce
all compatible surface forms), while classification
systems generate a single surface form from a se-
mantic input. In McDonald&apos;s [1983] terminology,
classification-based generation systems determin-
istically and indelibly make choices about alter-
nate surface-form constructs as the choices arise,
with no backtracking;4 unification-based systems,
</bodyText>
<footnote confidence="0.992469666666667">
4McDonald claims, incidentally, that indelible
decision-making is more plausible than backtracking
from a psycholinguistic perspective.
</footnote>
<page confidence="0.998437">
269
</page>
<bodyText confidence="0.999838142857143">
in contrast, produce the set of all syntactically cor-
rect surface-forms that are compatible with the
semantic input.5
In practice, all generation systems must possess
a &apos;preference filter&apos; of some kind that chooses a
single output surface-form from the set of possi-
bilities. In unification approaches, choosing a par-
ticular surface form to output tends to be regarded
(at least theoretically) as a separate task from gen-
erating the set of syntactically and semantically
correct surface forms; in classification approaches,
in contrast, the process of making choices between
possible surface forms is interwoven with the main
generation algorithm.
</bodyText>
<subsectionHeader confidence="0.95659">
Systemic approaches
</subsectionHeader>
<bodyText confidence="0.99944403030303">
Systemic grammars [Halliday, 19851 are another
popular formalism for generation systems. Sys-
temic systems vary substantially in the input lan-
guage they accept; we will here focus on the NIGEL
system [Mann, 19831, since it uses the same in-
put language (sPL) as IDAS&apos;S surface realisation
system.6 Other systemic systems (e.g., [Patten,
1988]) tend to use systemic features as their in-
put language (i.e., they don&apos;t have an equivalent
of NIGEL&apos;s chooser mechanism), which makes com-
parisons more difficult.
NIGEL works by traversing a network of systems,
each with an associated chooser. The choosers de-
termine features, by performing tests on the se-
mantic input. Choosers can be arbitrary Lisp
code, which means that NIGEL can in principle use
more general &apos;patterns&apos; in its rules than IDAS can;
in practice it is not clear to what extent this ex-
tra expressive power is used in NIGEL, since many
choosers seem to be based on subsumption tests
between semantic components and the system&apos;s
upper model. In any case, once a set of features
has been chosen, these features trigger gates and
their associated realisation rules; these rules as-
sert information about the output text. From the
pattern-matching perspective, choosers and gates
provide the patterns ai of rules, while realisation
rules specify the actions to be performed on the
output text.
Like classification systems (but unlike unifica-
tion systems), systemic generation systems are,
in McDonald&apos;s terminology, deterministic and in-
delible choice-makers; NIGEL makes choices about
</bodyText>
<footnote confidence="0.959911222222222">
5 Of course these differences are in a sense more
theoretical than practical, since one can design a uni-
fication system to only return a single surface form
instead of a set of surface forms, and one can include
backtracking-like mechanisms in a classification-based
system.
6Strictly speaking, SPL is an input language to PEN-
MAN, not NIGEL; we will here ignore the difference be-
tween PENMAN and NIGEL.
</footnote>
<bodyText confidence="0.998943636363636">
alternative surface-form constructs as they arise
during the generation process, and does not back-
track. Systemic generation systems are thus prob-
ably closer to classification systems than unifica-
tion systems are; indeed, in a sense the biggest
difference between systemic and classification sys-
tems is that systemic systems use a notation and
inference system that was developed by the lin-
guistic community, while classification systems use
a notation and inference system that was devel-
oped by the Al community.
</bodyText>
<sectionHeader confidence="0.907965" genericHeader="method">
Other Related Work
</sectionHeader>
<bodyText confidence="0.999599608695652">
ROsner [1986] describes a generation system that
uses object-oriented techniques. sPL-like input
specifications are converted into objects, and then
realised by activating their To-Realise methods.
Rosner does not use a declarative grammar; his
grammar rules are implicitly encoded in his Lisp
methods. He also does not use classification as an
inference technique (his taxonomy is hand-built).
DATR [Evans and Gazdar, 1989] is a system that
declaratively represents morphological rules, using
a representation that in some ways is similar to Il.
In particular, DATR allows default inheritance and
supports role-chain-like constructs. DATR does not
include a classifier, and also has no equivalent of
Il&apos;s template mechanism for specifying recursion.
PSI-KLONE [Brachman and Schmolze, 1985,
appendix] is an NL understanding system that
makes some use of classification, in particular to
map surface cases onto semantic cases. Syntactic
forms are classified into an appropriate taxonomy,
and by virtue of their position inherit semantic
rules that state which semantic cases (e.g., Actee)
correspond to which surface cases (e.g., Object).
</bodyText>
<sectionHeader confidence="0.660565" genericHeader="method">
Conclusion
</sectionHeader>
<bodyText confidence="0.99995575">
In summary, classification can be used to
perform much of the necessary processing in
natural-language generation, including content-
determination, surface-realisation, and part of
text-planning. Classification-based generation al-
lows a single knowledge representation system to
be used for both domain and linguistic knowledge;
this means that a classification-based generation
system can have a significantly simpler overall ar-
chitecture than a unification or systemic genera,-
tion system, and thus be easier to build and main-
tain.
</bodyText>
<sectionHeader confidence="0.985656" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99974775">
The IDAS project is partially funded by UK
SERC grant GR/F/36750 and UK DTI grant IED
4/1/1072, and we are grateful to SERC and DTI
for their support of this work. We would also like
</bodyText>
<page confidence="0.986002">
270
</page>
<bodyText confidence="0.80727675">
to thank the IDAS industrial collaborators — Infer-
ence Europe, Ltd.; Racal Instruments, Ltd.; and
Racal Research, Ltd. — for all the help they have
given us in performing this research.
</bodyText>
<sectionHeader confidence="0.99419" genericHeader="method">
Appendix: A Comparison of
Classification and Unification
</sectionHeader>
<bodyText confidence="0.9999115">
FUG is only one of a number of grammar for-
malisms based on feature logics. The logic under-
lying FUG is relatively simple, but much more ex-
pressive logics are now being implemented [Emele
and Zajac, 1990; Dorre and Seiffert, 1991; DOrre
and Eisele, 1991]. Here we provide an initial for-
mal characterisation of the relation between classi-
fication and unification, but abstracting away from
the differences between the different unification
systems.
Crucial to all approaches in unification-based
generation (or parsing) is the idea that at every
level an input description (i.e. logical form or sim-
ilar) 7 is combined with a set of axioms (type spec-
ifications, grammar functional descriptions, rules)
and the resulting logical expression is then reduced
to a normal form that can be used straightfor-
wardly to construct the set of models for the com-
bined axioms and description.
Classification is an appropriate operation to use
in normal form construction when the axioms take
the form ai —0 , with -0 interpreted as logical
implication, and where each a; and /3i is a term
in a feature logic. If the input description is &apos;com-
plete&apos; with respect to the conditions of these ax-
ioms (that is, if 7 A ai I exactly when 7 C ai,
where C is subsumption), then it follows that for
every model M:
</bodyText>
<equation confidence="0.8913015">
M fai U {7} iff
M g cel} u {7}
</equation>
<bodyText confidence="0.999925931818182">
(the relationship is more complex if the gram-
mar is recursive, though the same basic principle
holds). The first step of the computation of the
models of 7 and the axioms then just needs quick
access to ffliI7 C ad. The classification approach
is to have the different a; ordered in a subsump-
tion taxonomy. An input description 7 is placed
in this taxonomy and the A corresponding to its
ancestors are collected.
Input descriptions are &apos;complete&apos; if every input
description is fully specified as regards the condi-
tions that will be tested on it. This implies a rigid
distinction between &apos;input&apos; and &apos;output&apos; informa-
tion which, in particular, means that classification
will not be able to implement bidirectional gram-
mars. If all the axioms are of the above form,
input descriptions are complete and conjunctive,
and the f3i&apos;s are conjunctive (as is the case in IDAS)
then there will always only be a single model.
The above assumption about the form of ax-
ioms is clearly very restrictive compared to what
is allowed in many modern unification formalisms.
In IDAS, the notation is restricted even further
by requiring the ai and A to be purely con-
junctive. In spite of these restrictions, the sys-
tem is still in some respects more expressive than
the simpler unification formalisms. In Definite
Clause Grammars (DCGs) [Pereira and Warren,
1980], for instance, it is not possible to specify
al —0 A. and also a2 —o 132, whilst allowing that
(a1 A a2) —0 (,(31A132) (unless al and a2 are related
by subsumption) [Mellish, 1991].
The comparison between unification and clas-
sification is, unfortunately, made more complex
when default inheritance is allowed in the classifi-
cation system (as it is in nits). Partly, the use of
defaults may be viewed formally as simply a mech-
anism to make it easier to specify &apos;complete&apos; in-
put descriptions. The extent to which defaults are
used in an essential way in IDAS still remains to be
investigated. Certainly for the grammar writer the
ability to specify defaults is very valuable, and this
has been widely acknowledged in grammar frame-
works and implementations.
</bodyText>
<sectionHeader confidence="0.976596" genericHeader="references">
References
</sectionHeader>
<bodyText confidence="0.9503807">
[Bateman et al., 1990] John Bateman, Robert
Kasper, Johanna Moore, and Richard Whitney.
A general organization of knowledge for nat-
ural language processing: the Penman upper
model. Technical report, Information Sciences
Institute, Marina del Rey, CA 90292, 1990.
[Brachman and Schmolze, 19851
Ronald Brachman and James Schmolze. An
overview of the KL-ONE knowledge representa-
tion system. Cognitive Science, 9:171-216, 1985.
</bodyText>
<reference confidence="0.748218">
IDOrre and Eisele, 1991] Jochen DOrre and An-
reas Eisele. A comprehensive unification for-
malism, 1991. Deliverable R3.1.B, DYANA -
ESPRIT Basic Research Action BR3175.
[DOrre and Seiffert, 1991] Jochen Dorre and
Roland Seiffert. Sorted feature terms and re-
lational dependencies. IWBS Report 153, IBM
Deutschland, 1991.
[Elhadad, 1990] Michael Elhadad. Types in func-
tional unification grammars. In Proceedings of
the 28th Annual Meeting of the Association for
Computational Linguistics (ACL-1990), pages
157-164, 1990.
[Emele and Zajac, 1990] Martin Emele and Remi
Zajac. Typed unification grammars. In Pro-
ceedings of the 13th International Conference
on Computational Linguistics (COLING-1990),
volume 3, pages 293-298, 1990.
</reference>
<page confidence="0.972313">
271
</page>
<reference confidence="0.999599783018868">
[Evans and Gazdar, 1989] Roger Evans and Ger-
ald Gazdar. Inference in DATR. In Proceedings
of Fourth Meeting of the European Chapter of
the Association for Computational Linguistics
(EACL-1989), pages 66-71,1989.
[Grosz et al., 1986] Barbara Grosz, Karen Sparck
Jones, and Bonnie Webber, editors. Readings
in Natural Language Processing. Morgan Kauf-
mann, Los Altos, California, 1986.
[Halliday, 1985] M. A. K. Halliday. An Introduc-
tion to Functional Grammar. Edward Arnold,
London, 1985.
[Kasper, 1989] Robert Kasper. A flexible interface
for linking applications to Penman&apos;s sentence
generator. In Proceedings of the 1989 DARPA
Speech and Natural Language Workshop, pages
153-158, Philadelphia, 1989.
[Kay, 1979] Martin Kay. Functional grammar. In
Proceedings of the Fifth Meeting of the Berke-
ley Linguistics Society, pages 142-158, Berkeley,
CA, 17-19 Febuary 1979.
[Mann, 1983] William Mann. An overview of the
NIGEL text generation grammar. In Proceed-
ings of the 21st Annual Meeting of the As-
sociation for Computational Linguistics (ACL-
1983), pages 79-84,1983.
[Mann and Moore, 1981] William Mann and
James Moore. Computer generation of multi-
paragraph English text. American Journal of
Computational Linguistics, 7:17-29,1981.
[McDonald, 1983] David McDonald. Description
directed control. Computers and Mathematics,
9:111-130,1983.
[McKeown et al., 1990] Kathleen McKeown,
Michael Elhadad, Yumiko Fukumoto, Jong
Lim, Christine Lombardi, Jacques Robin, and
Frank Smadja. Natural language generation in
COMET. In Robert Dale, Chris Mellish, and
Michael Zock, editors, Current Research in Nat-
ural Language Generation, pages 103-139. Aca-
demic Press, London, 1990.
[Mellish, 1991] Chris Mellish. Approaches to re-
alisation in natural language generation. In
E. Klein and F. Veltman, editors, Natural Lan-
guage and Speech. Springer-Verlag, 1991.
[Moore and Paris, 19891 Johanna Moore and Ce-
cile Paris. Planning text for advisory dialogues.
In Proceedings of the 27th Annual Meeting of
the Association for Computational Linguistics
(ACL-1989), pages 203-211,1989.
[Patten, 1988] Terry Patten. Systemic Text Gen-
eration as Problem Solving. Cambridge Univer-
sity Press, 1988.
[Penman Natural Language Group, 1989]
Penman Natural Language Group. The Pen-
man user guide. Technical report, Information
Sciences Institute, Marina del Rey, CA 90292,
1989.
[Pereira and Warren, 1980] Fernando Pereira and
David Warren. Definite clause grammars
for language analysis. Artificial Intelligence,
13:231-278,1980.
[Reiter, 1990] Ehud Reiter. Generating descrip-
tions that exploit a user&apos;s domain knowledge. In
Robert Dale, Chris Mellish, and Michael Zock,
editors, Current Research in Natural Language
Generation, pages 257-285. Academic Press,
London, 1990.
[Reiter, 1991] Ehud Reiter. A new model of lexical
choice for nouns. Computational Intelligence,
7(4), 1991.
[Reiter and Dale, 1992] Ehud Reiter and Robert
Dale. A fast algorithm for the generation of re-
ferring expressions. In Proceedings of the Four-
teenth International Conference on Computa-
tional Linguistics (COLING-1992), 1992.
[Reiter et al., 1992] Ehud Reiter, Chris Mellish,
and John Levine. Automatic generation of
on-line documentation in the IDAS project.
In Proceedings of the Third Conference on
Applied Natural Language Processing (ANLP-
1992), pages 64-71,1992.
[Rosch, 1978] Eleanor Rosch. Principles of cat-
egorization. In E. Rosch and B. Lloyd, edi-
tors, Cognition and Categorization, pages 27-
48. Lawrence Erlbaum, Hillsdale, NJ, 1978.
[Rosner, 1986] Dietmar Rosner. Ein System zur
Generierung von deutschen Texten aus seman-
tischen Reprdsentationen. PhD thesis, Institut
fiir Informatik, University of Stuttgart, 1986.
[Sheiber, 1988] Stuart Sheiber. A uniform archi-
tecture for parsing and generation. In Pro-
ceedings of the 12th International Conference
on Computational Linguistics (COLING-88),
pages 614-619,1988.
[Touretzky, 1986] David Touretzky. The Mathe-
matics of Inheritance Systems. Morgan Kauf-
mann, Los Altos, California, 1986.
[Wahlster et al., 1991] Wolfgang Wahlster, Elis-
abeth Andre, Som Bandyopadhyay, Winfried
Graf, and Thomas Rist. WIP: The coordinated
generation of multimodal presentations from a
common representation. In Oliverio Stock, John
Slack, and Andrew Ortony, editors, Compu-
tational Theories of Communication and their
Applications. Springer-Verlag, 1991.
</reference>
<page confidence="0.99732">
272
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.207318">
<title confidence="0.998423">USING CLASSIFICATION TO GENERATE TEXT</title>
<author confidence="0.99896">Ehud Reiter</author>
<author confidence="0.99896">Chris Mellisht</author>
<affiliation confidence="0.99969">Department of Artificial Intelligence University of Edinburgh</affiliation>
<address confidence="0.828394">80 South Bridge Edinburgh EH1 1HN</address>
<abstract confidence="0.9392628">BRITAIN ABSTRACT generation system a classifier to perform content determination, surface realisation, and part of text Generation-by-classification allows to use a single representation and reasoning component for both domain and linguistic knowledge, which is difficult for systems based on unification or systemic generation techniques.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>IDOrre</author>
<author>Eisele</author>
</authors>
<title>Jochen DOrre and Anreas Eisele. A comprehensive unification formalism,</title>
<date>1991</date>
<booktitle>Deliverable R3.1.B, DYANA -ESPRIT Basic Research Action BR3175.</booktitle>
<marker>IDOrre, Eisele, 1991</marker>
<rawString> IDOrre and Eisele, 1991] Jochen DOrre and Anreas Eisele. A comprehensive unification formalism, 1991. Deliverable R3.1.B, DYANA -ESPRIT Basic Research Action BR3175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jochen Dorre</author>
<author>Roland Seiffert</author>
</authors>
<title>Sorted feature terms and relational dependencies.</title>
<date>1991</date>
<tech>IWBS Report 153, IBM Deutschland,</tech>
<marker>[DOrre and Seiffert, 1991]</marker>
<rawString>Jochen Dorre and Roland Seiffert. Sorted feature terms and relational dependencies. IWBS Report 153, IBM Deutschland, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Elhadad</author>
</authors>
<title>Types in functional unification grammars.</title>
<date>1990</date>
<booktitle>In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics (ACL-1990),</booktitle>
<pages>157--164</pages>
<marker>[Elhadad, 1990]</marker>
<rawString>Michael Elhadad. Types in functional unification grammars. In Proceedings of the 28th Annual Meeting of the Association for Computational Linguistics (ACL-1990), pages 157-164, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emele</author>
<author>Remi Zajac</author>
</authors>
<title>Typed unification grammars.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics (COLING-1990),</booktitle>
<volume>3</volume>
<pages>293--298</pages>
<marker>[Emele and Zajac, 1990]</marker>
<rawString>Martin Emele and Remi Zajac. Typed unification grammars. In Proceedings of the 13th International Conference on Computational Linguistics (COLING-1990), volume 3, pages 293-298, 1990.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Roger Evans</author>
<author>Gerald Gazdar</author>
</authors>
<title>Inference in DATR.</title>
<booktitle>In Proceedings of Fourth Meeting of the European Chapter of the Association for Computational Linguistics (EACL-1989),</booktitle>
<pages>66--71</pages>
<marker>[Evans and Gazdar, 1989]</marker>
<rawString>Roger Evans and Gerald Gazdar. Inference in DATR. In Proceedings of Fourth Meeting of the European Chapter of the Association for Computational Linguistics (EACL-1989), pages 66-71,1989.</rawString>
</citation>
<citation valid="true">
<date>1986</date>
<booktitle>Readings in Natural Language Processing.</booktitle>
<editor>Barbara Grosz, Karen Sparck Jones, and Bonnie Webber, editors.</editor>
<publisher>Morgan Kaufmann,</publisher>
<location>Los Altos, California,</location>
<marker>[Grosz et al., 1986]</marker>
<rawString>Barbara Grosz, Karen Sparck Jones, and Bonnie Webber, editors. Readings in Natural Language Processing. Morgan Kaufmann, Los Altos, California, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Halliday</author>
</authors>
<title>An Introduction to Functional Grammar.</title>
<date>1985</date>
<location>Edward Arnold, London,</location>
<marker>[Halliday, 1985]</marker>
<rawString>M. A. K. Halliday. An Introduction to Functional Grammar. Edward Arnold, London, 1985.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Kasper</author>
</authors>
<title>A flexible interface for linking applications to Penman&apos;s sentence generator.</title>
<date>1989</date>
<booktitle>In Proceedings of the 1989 DARPA Speech and Natural Language Workshop,</booktitle>
<pages>153--158</pages>
<location>Philadelphia,</location>
<marker>[Kasper, 1989]</marker>
<rawString>Robert Kasper. A flexible interface for linking applications to Penman&apos;s sentence generator. In Proceedings of the 1989 DARPA Speech and Natural Language Workshop, pages 153-158, Philadelphia, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional grammar.</title>
<date>1979</date>
<booktitle>In Proceedings of the Fifth Meeting of the Berkeley Linguistics Society,</booktitle>
<pages>142--158</pages>
<location>Berkeley, CA,</location>
<marker>[Kay, 1979]</marker>
<rawString>Martin Kay. Functional grammar. In Proceedings of the Fifth Meeting of the Berkeley Linguistics Society, pages 142-158, Berkeley, CA, 17-19 Febuary 1979.</rawString>
</citation>
<citation valid="false">
<authors>
<author>William Mann</author>
</authors>
<title>An overview of the NIGEL text generation grammar.</title>
<booktitle>In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics (ACL1983),</booktitle>
<pages>79--84</pages>
<marker>[Mann, 1983]</marker>
<rawString>William Mann. An overview of the NIGEL text generation grammar. In Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics (ACL1983), pages 79-84,1983.</rawString>
</citation>
<citation valid="false">
<authors>
<author>William Mann</author>
<author>James Moore</author>
</authors>
<title>Computer generation of multiparagraph English text.</title>
<journal>American Journal of Computational Linguistics,</journal>
<pages>7--17</pages>
<marker>[Mann and Moore, 1981]</marker>
<rawString>William Mann and James Moore. Computer generation of multiparagraph English text. American Journal of Computational Linguistics, 7:17-29,1981.</rawString>
</citation>
<citation valid="false">
<authors>
<author>David McDonald</author>
</authors>
<title>Description directed control.</title>
<journal>Computers and Mathematics,</journal>
<pages>9--111</pages>
<marker>[McDonald, 1983]</marker>
<rawString>David McDonald. Description directed control. Computers and Mathematics, 9:111-130,1983.</rawString>
</citation>
<citation valid="true">
<title>Smadja. Natural language generation in COMET.</title>
<date>1990</date>
<booktitle>Current Research in Natural Language Generation,</booktitle>
<pages>103--139</pages>
<editor>Kathleen McKeown, Michael Elhadad, Yumiko Fukumoto, Jong Lim, Christine Lombardi, Jacques Robin, and Frank</editor>
<publisher>Academic Press,</publisher>
<location>London,</location>
<marker>[McKeown et al., 1990]</marker>
<rawString>Kathleen McKeown, Michael Elhadad, Yumiko Fukumoto, Jong Lim, Christine Lombardi, Jacques Robin, and Frank Smadja. Natural language generation in COMET. In Robert Dale, Chris Mellish, and Michael Zock, editors, Current Research in Natural Language Generation, pages 103-139. Academic Press, London, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Mellish</author>
</authors>
<title>Approaches to realisation in natural language generation.</title>
<date>1991</date>
<booktitle>Natural Language and Speech.</booktitle>
<pages>203--211</pages>
<editor>In E. Klein and F. Veltman, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<marker>[Mellish, 1991]</marker>
<rawString>Chris Mellish. Approaches to realisation in natural language generation. In E. Klein and F. Veltman, editors, Natural Language and Speech. Springer-Verlag, 1991. [Moore and Paris, 19891 Johanna Moore and Cecile Paris. Planning text for advisory dialogues. In Proceedings of the 27th Annual Meeting of the Association for Computational Linguistics (ACL-1989), pages 203-211,1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Terry Patten</author>
</authors>
<title>Systemic Text Generation as Problem Solving.</title>
<date>1988</date>
<publisher>Cambridge University Press,</publisher>
<marker>[Patten, 1988]</marker>
<rawString>Terry Patten. Systemic Text Generation as Problem Solving. Cambridge University Press, 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Penman</author>
</authors>
<title>Natural Language Group. The Penman user guide.</title>
<date>1989</date>
<tech>Technical report,</tech>
<institution>Information Sciences Institute, Marina</institution>
<location>CA 90292,</location>
<marker>[Penman Natural Language Group, 1989]</marker>
<rawString> Penman Natural Language Group. The Penman user guide. Technical report, Information Sciences Institute, Marina del Rey, CA 90292, 1989.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fernando Pereira</author>
<author>David Warren</author>
</authors>
<title>Definite clause grammars for language analysis.</title>
<journal>Artificial Intelligence,</journal>
<pages>13--231</pages>
<marker>[Pereira and Warren, 1980]</marker>
<rawString>Fernando Pereira and David Warren. Definite clause grammars for language analysis. Artificial Intelligence, 13:231-278,1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>Generating descriptions that exploit a user&apos;s domain knowledge.</title>
<date>1990</date>
<booktitle>Current Research in Natural Language Generation,</booktitle>
<pages>257--285</pages>
<editor>In Robert Dale, Chris Mellish, and Michael Zock, editors,</editor>
<publisher>Academic Press,</publisher>
<location>London,</location>
<marker>[Reiter, 1990]</marker>
<rawString>Ehud Reiter. Generating descriptions that exploit a user&apos;s domain knowledge. In Robert Dale, Chris Mellish, and Michael Zock, editors, Current Research in Natural Language Generation, pages 257-285. Academic Press, London, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>A new model of lexical choice for nouns.</title>
<date>1991</date>
<journal>Computational Intelligence,</journal>
<volume>7</volume>
<issue>4</issue>
<marker>[Reiter, 1991]</marker>
<rawString>Ehud Reiter. A new model of lexical choice for nouns. Computational Intelligence, 7(4), 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Robert Dale</author>
</authors>
<title>A fast algorithm for the generation of referring expressions.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourteenth International Conference on Computational Linguistics (COLING-1992),</booktitle>
<marker>[Reiter and Dale, 1992]</marker>
<rawString>Ehud Reiter and Robert Dale. A fast algorithm for the generation of referring expressions. In Proceedings of the Fourteenth International Conference on Computational Linguistics (COLING-1992), 1992.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Ehud Reiter</author>
<author>Chris Mellish</author>
<author>John Levine</author>
</authors>
<title>Automatic generation of on-line documentation in the IDAS project.</title>
<booktitle>In Proceedings of the Third Conference on Applied Natural Language Processing (ANLP1992),</booktitle>
<pages>64--71</pages>
<marker>[Reiter et al., 1992]</marker>
<rawString>Ehud Reiter, Chris Mellish, and John Levine. Automatic generation of on-line documentation in the IDAS project. In Proceedings of the Third Conference on Applied Natural Language Processing (ANLP1992), pages 64-71,1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eleanor Rosch</author>
</authors>
<title>Principles of categorization.</title>
<date>1978</date>
<booktitle>Cognition and Categorization,</booktitle>
<pages>27--48</pages>
<editor>In E. Rosch and B. Lloyd, editors,</editor>
<location>Hillsdale, NJ,</location>
<marker>[Rosch, 1978]</marker>
<rawString>Eleanor Rosch. Principles of categorization. In E. Rosch and B. Lloyd, editors, Cognition and Categorization, pages 27-48. Lawrence Erlbaum, Hillsdale, NJ, 1978.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dietmar Rosner</author>
</authors>
<title>Ein System zur Generierung von deutschen Texten aus semantischen Reprdsentationen.</title>
<date>1986</date>
<tech>PhD thesis,</tech>
<institution>Institut fiir Informatik, University of Stuttgart,</institution>
<marker>[Rosner, 1986]</marker>
<rawString>Dietmar Rosner. Ein System zur Generierung von deutschen Texten aus semantischen Reprdsentationen. PhD thesis, Institut fiir Informatik, University of Stuttgart, 1986.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Stuart Sheiber</author>
</authors>
<title>A uniform architecture for parsing and generation.</title>
<booktitle>In Proceedings of the 12th International Conference on Computational Linguistics (COLING-88),</booktitle>
<pages>614--619</pages>
<marker>[Sheiber, 1988]</marker>
<rawString>Stuart Sheiber. A uniform architecture for parsing and generation. In Proceedings of the 12th International Conference on Computational Linguistics (COLING-88), pages 614-619,1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Touretzky</author>
</authors>
<title>The Mathematics of Inheritance Systems.</title>
<date>1986</date>
<publisher>Morgan Kaufmann,</publisher>
<location>Los Altos, California,</location>
<marker>[Touretzky, 1986]</marker>
<rawString>David Touretzky. The Mathematics of Inheritance Systems. Morgan Kaufmann, Los Altos, California, 1986.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
</authors>
<title>Elisabeth Andre, Som Bandyopadhyay, Winfried Graf, and Thomas Rist. WIP: The coordinated generation of multimodal presentations from a common representation.</title>
<date>1991</date>
<booktitle>Computational Theories of Communication and their Applications.</booktitle>
<editor>In Oliverio Stock, John Slack, and Andrew Ortony, editors,</editor>
<publisher>Springer-Verlag,</publisher>
<marker>[Wahlster et al., 1991]</marker>
<rawString>Wolfgang Wahlster, Elisabeth Andre, Som Bandyopadhyay, Winfried Graf, and Thomas Rist. WIP: The coordinated generation of multimodal presentations from a common representation. In Oliverio Stock, John Slack, and Andrew Ortony, editors, Computational Theories of Communication and their Applications. Springer-Verlag, 1991.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>