<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.378722">
ABSTRACTS OF CURRENT LITERATURE
</title>
<figure confidence="0.775281111111111">
Recent memoranda in computer and cognitive science related to natural language processing. For copies of the
technical reports listed below, write to:
Memoranda Series
Computing Research Laboratory
Box 30001
New Mexico State University
Las Cruces, NM 88003
USA
NEW REPORTS AND MEMOS
Knowledge Acquisition With A
Machine Lexicon
Guo, C-M.
MCCS-88-131
A Survey Distributed Processing
Models from a Computation
Perspective
Balogh, I.L.
MCCS-88-133
</figure>
<subsectionHeader confidence="0.70440425">
An Investigation Into The Minimum
Structures of Programming Languages
and Natural Languages
Hill, R.
</subsectionHeader>
<bodyText confidence="0.259955">
MCCS-88-134
</bodyText>
<note confidence="0.763388">
Philosophy of Language and Artificial
Intelligence
Wilks, Y.
</note>
<page confidence="0.961604">
MCCS-88-132
</page>
<bodyText confidence="0.999949486486486">
This paper describes the construction of a machine lexicon and
its use in acquiring general world knowledge from natural
language text. Two types of text are identified, dictionary
definition text and unrestricted general text. Knowledge
acquisition from dictionary definition text helps to construct the
lexicon, whereas knowledge acquisition from unrestricted general
text expands the lexicon. Knowledge acquisition with the
machine lexicon represented a continued process of learning,
beginning with acquiring lexical and world and knowledge from
dictionary definition text, continuing on to acquiring more
knowledge from unrestricted general text.
Many distributed models of computations have been proposed
over the years. On the surface they seem to be quite different
from more traditional models, and often from each other. But
do they offer a fundamentally different type of computation?
Some of the more prominent models are investigated from this
computational perspective. A brief description is given of each
model, followed by a discussion of their capability with respect
to each other and in relation to classical models of
computation.
A phenomenon that is regarded as .UL theory based must have
some foundation (namely, that theory), a grasp of which is
necessary and sufficient to a grasp of the whole phenomenon in
all of its manifestations. In other words, it must have some
minimum structures on which the whole is grounded, so that
analysis of any of those manifestations unravels into a tracing
back to those structures, and nothing else.
If we look at language systems, we have, on the one hand,
natural languages, the use of which is guided by the demands
of the users, people. On the other, we have programming
languages, the use of which is guided by the theory underlying
them. Can their respective minimum structures shed light on
each other?
The paper surveys the relationship between Al and the
philosophy of language. Al is normally described either as an
engineering task, one of simulating certain interesting human
functions (i.e., not arithmetic) with digital computers or, at a
</bodyText>
<page confidence="0.930798">
130 Computational Linguistics, Volume 15, Number 2, June 1989
</page>
<subsectionHeader confidence="0.764279">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.999847909090909">
higher level, as an attempt to explicate computationally the
nature of intelligence. The history of practice in AI owes far
more to the Leibnizian goal of a mechanical logic than to, say,
robotics, the view of Al always taken by cartoonists. The point
of view behind the survey is probably that of Wittgenstein&apos;s
&amp;quot;Philosophy leaves everything as it is&amp;quot;. One might extend that,
with no greater respect for philosophy, as &amp;quot;Artificial intelligence
leaves philosophy as it is&amp;quot;, which is to say that no
philosophical consequences follow from any piece of research in
artificial intelligence and no particular philosophical assumptions
are ended to carry out such research.
</bodyText>
<figure confidence="0.889106583333333">
Form and Content in Semantics
Wilks, Y.
MCCS-88-137
Belief Ascription, Metaphor, and
Intensional Identification
Bairn, A., Wilks, Y. &amp; Barnden, J.
MCCS-88-138
Connectionist Parallel Machines and
Turing Machines as Models of the
Mind
Wilks, Y.
MCCS-86-79
</figure>
<bodyText confidence="0.989865911111111">
This paper continues a long wail of intellectual complaints
against the presumptions of certain kinds of formal semantics
(the qualification is important) and their bad effects on those
areas of artificial intelligence concerned with machine
understanding of human language. The paper begins with a
critical examination of Lifschitz&apos;s (out of McCarthy) use of
epistemological adequacy. The paper then moves, rather more
positively, to contrast forms of formal semantics with a possible
alternative: commonsense semantics. Finally, as an in-between
case of considerable interest, it examines various positions held
by McDermott on these issues and concludes, reluctantly, that,
although he has reversed himself on the issue, there was no
time when he was right.
The purpose of this paper, and the mechanisms it describes, is
the extension of View gen, an algorithm for belief ascription in a
model of nested viewpoints of agents, to the areas of metaphor,
intensional object identification and speech acts, and the
addition to the basic &amp;quot;belief engine&amp;quot; of a relevance calculus.
That system, summarized here, represents the beliefs of agents
as partitioned sets of propositions known as environments. A
general defense is given of partitioning approach to belief
computation. Environments are convenient, even essential, for
addressing important pragmatic issues of reasoning, and are the
basis for an existing ascriptional-reasoning program, ViewGen. It
is shown that belief ascription, metaphor generation, and
intensional object identification can all be seen as processes that
involve the amalgamation of a number of environments, and
may be seen as manifestations of a single process.
The paper makes some initial remarks about whether or not
connectionist parallel machines can be considered Turing
machines and what the consequences, in principle, for AI&apos;s task
of mental modeling might be. Since the application of much
connectionist work is in natural language processing, the paper
reviews some current work in that area and argues that,
whether or not the processes used are genuinely different from
conventional symbolic natural language processing, the
arguments used by connectionists to support what they are
doing do not in fact distinguish them very clearly from their
symbolic predecessors.
The heart of the paper is a comparison and contrast between
a current radical argument for connectionism and a radical
argument against. It is not clear that the very same version of
connectionism is defended by Smolensky as is attacked by
Fodor, but since I do not bring the two arguments directly in
Computational Linguistics, Volume 15, Number 2, June 1989 131
</bodyText>
<subsectionHeader confidence="0.968433">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.999393">
contact, that will not matter. My own inconclusive view is that
the jury is still out, and that, in the meantime, while there is
no convincing evidence to believe what Smolensky says, though
one may respect it and be stimulated by it, neither should one
reject the whole enterprise on the grounds Fodor gives. One
can legitimately be, in a narrow and strict sense, an agnostic,
without giving that word the force of active disbelief it is often
made to carry.
</bodyText>
<figure confidence="0.9522134">
Reference and Its Role in
Computational Models of Mental
Representations
Wilks, Y.
MCCS-85-30
</figure>
<figureCaption confidence="0.7021345">
Pronouns in Mind: Quasi-Indexicals
and the &amp;quot;Language of Thought&amp;quot;
</figureCaption>
<bodyText confidence="0.995693395348837">
Wilks, Y., BaMm, A. and Dietrich, E.
MCCS-87-92
This paper is written from a standpoint that still has
considerable support within that part of the Al community
concerned with modeling or simulating mental representations
and processes, but which does not accord with the currently
fashionable emphasis on the role of logic in those
representations. I would characterize the position as &amp;quot;procedural
intensionalist&amp;quot;: not a very clear phrase, perhaps, but one which
is intended to capture a set of claims that mental
representations, in so far as they can be modeled by computer
processes are a. symbolic; b. such that their semantics are to
be given ultimately by procedures and not (except in a
circumscribable set of cases) by sets of referents or by the
standard semantics of predicate logic, and c. that semantic
decomposition to some set of primitives, which may be domain
dependent or (as some would argue) universal, plays a plausible
role in the construction of those representations.
In this paper, I want indirectly to defend that club, of which
I happen to be a member, by critically examining the recent
claims of two writers concerning the role of reference in mental
and computational representations. These two, Johnson-Laird
(1981) and Smith (1982), are not from the extreme logicist
camp; on the contrary, both of them distinguish themselves, in
their quite different ways, from the claims of the sort
associated with McCarthy and Hayes (1969), or, more recently,
Barwise and Perry (1983), who assume that some variant of
standard first order logic and its semantics is adequate for the
description of meaning and knowledge.
The paper examines the role of the natural-formal language
distinction in connection with the language of thought (LOT)
issue. In particular, it distinguishes a realist-uniform/attributist-
uniform approach to LOT and seeks to link that distinction to
the issue of whether artificial intelligence is fundamentally a
science or engineering. In a second section, we examine a
particular aspect of natural language in relation to LOT:
pronouns/indexicals. The focus there is Rapaport&apos;s claims about
indexicals in belief representations. We dispute these claims and
argue that he confuses claims about English sentences and truth
conditions, on the one hand, with claims about beliefs, on the
other. In a final section we defend the representational capacity
of the belief manipulation system of Wilks, Bien and Ballim
against Rapaport&apos;s published criticisms.
</bodyText>
<page confidence="0.921882">
132 Computational Linguistics, Volume 15, Number 2, June 1989
</page>
<subsectionHeader confidence="0.799001">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.860396">
The following new papers from the project group KIT can be obtained free of charge from:
</bodyText>
<figure confidence="0.961530181818182">
PROJEKTGRUPPE KIT
Technische Universitat Berlin
Fachbereich Informatik
Sekr. FR 5-12 Franklinstr. 28/29
D-1000 Berlin 10
Fed. Rep. of Germany
KIT-Report 59
A Constructive Version of GPSG for
Machine Translation
Hauenschild, Christa, and Busemann,
Stephan
</figure>
<table confidence="0.765330217391304">
February 1988, 25 p.
To appear in: Steiner, E.; Schmidt, P.;
and Zelinsky-Wibbelt, C. (eds.): From
Syntax to Semantics-Insights From
Machine Translation.
Frances Pinter, London, 1988.
KIT-Report 60
A Constructive View of GPSG or How
to Make it Work
Busemann, Stephan, and Hauenschild,
Christa
April 1988, 6 pp. To appear in:
Proceedings of the 12th Conference on
Computational Linguistics (COLING),
Budapest, 1988.
KIT-Report 61
Using Constraints in a Constructive
Version of GPSG
Weisweber, Wilhelm
April 1988, 6 pp. To appear in:
Proceedings of the 12th Conference on
Computational Linguistics (COLING),
Budapest, 1988.
</table>
<bodyText confidence="0.999596913043478">
The paper discusses the applicability of generalized phrase
structure grammar (GPSG) for machine translation (MT). After
sketching the underlying conception of MT in general and
defining the part that GPSG is to play within it, the paper
concentrates on the problems raised by the claim that GPSG in
its 1985 version is not amenable to computer implementation. It
is shown that a straightforward implementation of the formalism
would lead to a combinatorial explosion of the number of
categories to be computed. Instead a constructive view of
GPSG is adopted, which allows for grammatical structures in a
direct manner but still under the control of the different GPSG
devices, which have been redefined. The constructive version of
GPSG forms the basis of the Berlin GPSG system, which is
modularized according to the needs of MT. It is fully
implemented for parsing and generation with one and the same
grammar. Some aspects of using grammars bidirectionally are
focused on as well as different ways of utilizing the GPSG
formalism and their consequences.
A straightforward implementation of generalized phrase structure
grammar (GPSG) in its 1985 version would involve a vast
overgeneration of categories and structures as well as processes
to filter out everything but the admissible tree(s). We therefore
argue for a constructive version of GPSG where information is
gathered in subsequent steps to produce syntactic structures. As
a result, we consider it necessary to incorporate procedural
aspects into the formalism in order to use it as a linguistic
basis for NL parsing and generation. The paper discusses the
major implications of such a modified view of GPSG, thereby
including a new proposal for handling agreement in a simple
and sufficiently general manner.
Complex categories are characteristic of unification grammars
as, for example, GPSG. They are sets of pairs of features and
values and have crucial influence on the efficiency of the
parsing algorithm. This is one problem from using complex
categories; another one arises when using a constructive version
of GPSG in which the feature values are propagated among the
categories of a local tree. Namely that the application of
admissibility conditions, i.e. linear precedence (LP) statements
and feature co-occurrence restrictions (FCRs), to a local tree t
is prevented because particular feature values of categories in t
are not yet specified, but they will be instantiated later
somewhere else in the complete tree. The paper describes the
latter problem and will present a solution working with
computation, evaluation and propagation of constraints within
local trees. The constraint evaluation will reject local trees if
the constraints of the subtrees of the daughters are violated.
</bodyText>
<table confidence="0.87186375">
Computational Linguistics, Volume 15, Number 2, June 1989 133
Abstracts of Current Literature
MT-Report 62
Discourse Structure-Some Implications
for Machine Translation
Hauenschild, Christa
April 1988, 15 pp.
To appear in: Proceedings of &amp;quot;New
Directions in Machine Translation&amp;quot;,
International Conference, Budapest, 18-19
August 1988, organized by BSO/Research
(Utrecht) and the John von Neumann
Society (Budapest).
MT-Publication List:
Reports, Working Papers, and other
publications July 1988, 18 pp.
</table>
<bodyText confidence="0.99924275">
The paper discusses the importance of discourse structure for
translation in general and for machine translation, regarded as a
special case of translation. After some general remarks on the
role of discourse structure for human and machine translation,
the interrelation between the stipulation of invariants in
translation and the interlingual approach is examined. As a kind
of counter-evidence some language-particular ways of expressing
the thematic structuring of a text are introduced, which leads
us to an argumentation in favour of the transfer approach to
translation. The conclusion is that both aspects of translation
ought to be considered in machine translation, which yields an
argumentation in favour of a &amp;quot;mixed approach&amp;quot;.
</bodyText>
<figure confidence="0.887971555555556">
LILOG-REPORT 3
Implementation Aspects of a Natural
Language Understanding System in a
PROLOG/DB Environment
Studer, Rudi, and Walter, Bernd
September 1986, 12 pp.
LILOG-Report 6
Mathematical Logic and Artificial
Intelligence
</figure>
<figureCaption confidence="0.773663">
Schmitt, P. H.
January 1987, 17 pp.
</figureCaption>
<bodyText confidence="0.982770518518519">
For capturing static and dynamic aspects of an application
domain on a conceptual level, THM-Nets based on a semantic
data model and Petri net concepts have been proposed. In this
paper THM-Nets are generalized to timed THM-Nets, thus
providing modeling concepts for capturing physical and logical
time aspects of a slice of reality. These modeling concepts are
based on an appropriate notion of physical and logical time
within the semantic data model THM.
LILOG is a project for exploring linguistic and logic methods
for an automatic understanding of German texts and for an
adequate representation of the acquired knowledge. In order to
maintain knowledge bases of realistic size, database technology
will be used. This paper discusses some of the problems that
occur when an existing database system (SQL/DS) is used for
representing the various types of knowledge. Additionally, the
design of a rapid prototype PROLOG/SQL system will be
presented, which supports the exploration of various mapping
and access schemes and considers the fact that the used
knowledge representation methods will most certainly evolve
during the course of the project.
This paper discusses some research topics of mutual interest in
mathematical logic and artificial intelligence. Among the topics
treated are mathematical theorem proving, modal logic, many-
valued logic, reasoning under uncertainty and monotonic logic.
While some issues are treated in detail for others only a
selected guide to the literature is given.
The following reports can be ordered from:
</bodyText>
<figure confidence="0.84407">
IBM Deutschland GmbH
WT LILOG / Dept. 3504
P. 0. Box 80 08 80
D-7000 Stuttgart 80
Fed. Rep. of Germany
LILOG-Report 2
A Conceptual Model for Time
Studer, Rudi
December 1986, 20 pp.
</figure>
<page confidence="0.568558">
134 Computational Linguistics, Volume 15, Number 2, June 1989
</page>
<table confidence="0.83964955">
Abstracts of Current Literature
LILOG-Report 7
The Semantics of Asserting and
Retracting Clauses to Logic Programs
Pletat, Udo, Beierk, Christoph
July 1987, 22 pp.
LILOG-Report 8
An Approach to Manage Large
Inheritance Networks
Studner, Rudi, Borner, Stefan
March 1987, 12 pp.
LILOG-Report 12
On Structuring Domain-Specific
Knowledge
Wachsmuth, Ipke
March 1987, 15 pp.
LILOG-Report 13
Word Order and Focus Projection
Wesche, Birgit, Renz, Ingrid
April 1987, 20 pp.
</table>
<bodyText confidence="0.999945826923077">
We discuss two approaches for defining the operational
semantics of modifying logic programs by means of asserting
and retracting clauses. The first approach defines a &amp;quot;logically
clean&amp;quot; behavior for assert and retract. Logically clean means
that this operational semantics for logic programs including
asserts and retracts is equivalent to the model theoretic
semantics of the logical skeleton of a program, i.e., where the
asserts and retracts are removed. This is achieved by delaying
the modification of the program due to the asserts and retracts
passed during a proof after the successful evaluation of a goal.
We contrast this clean semantics with the PROLOG style of
modifying logic programs and discuss the reasons for losing the
logical cleanness.
When developing large-scale knowledge-based systems, concepts
are required for handling knowledge bases on external storage.
In this paper we present an approach for managing structured
inheritance networks in a database. Actually, we develop a
representation of a KL-ONE-like formalism in an extended
relational database system supporting non-first-normal-form
relations. Of special importance is the handling of the general
hierarchical structure provided by KL-ONE within the tree
structure offered by non-first-normal-form relations.
This paper presents a proposal on how domain-specific
knowledge of both conceptual and assertional nature can be
structured. The aim is to devise a way that allows large
amounts of domain-dependent knowledge to be used by a
knowledge-based system while keeping the system manageable.
The proposal grounds on findings from empirical research on
the acquisition of domain-specific knowledge. It is presented
abstractly in the form of principles that are to be understood as
a specification rather than a symbol-level description for a
representation scheme. The model comprised by these principles
suggests domain-specific knowledge be organized in nested
packets of knowledge elements. The central notions of &amp;quot;visible&amp;quot;
and &amp;quot;reachable&amp;quot; knowledge are used to characterize static and
dynamic access conditions.
One of the major problems that has to be confronted in a
natural language system for German is its relatively free word
order. If one takes into account, however, that word order is
to a large extent motivated by pragmatic considerations the
choices for placing the single constituents within a sentence
narrow down considerably. A factor by which pragmatic aspects
are reflected quite explicitly is stress. In this paper we will
outline the regularities that result from the strong interaction of
word order and stress in German, and show how these can be
exploited even within an NL system which is based on written
input only. Taking such an approach will have an impact on
the encoding of lexical entries, on the formulation of syntactic
rules, on parsing strategies, and it will, furthermore, support the
component of semantic representation in that we will have a
clearer insight as to which elements constitute the core message
of a sentence.
</bodyText>
<table confidence="0.8738055625">
Computational Linguistics, Volume 15, Number 2, June 1989 135
Abstracts of Current Literature
LILOG-Report 20
Mental Images and Route Descriptions
(in German)
Rehkamper, Kalus
August 1987, 10 pp.
LILOG-Report 22
Chart Parsing of Unification-Based
Grammars with ID/LP Rules
Seiffert, Roland
September 1987, 19 pp.
LILOG-Report 23
At Ease with &amp;quot;at&amp;quot;
Wesche, Birgit
August 1987, 12 pp.
</table>
<bodyText confidence="0.999200821428571">
Mental images are of great importance in the text
comprehension of human beings. Text understanding computer
systems which intend to meet the demands of cognitive
adequacy must take this fact into account. Human beings use
these images to represent knowledge. Thus images are-in
addition to propositions-another way of gaining and representing
knowledge. In this paper I want to show some of the new
possibilities opened up by this second form of representation as
well as the restrictions connected with it. Route descriptions
form a class of texts which obviously require mental images for
their generation and comprehension. During the generation of a
route description the informant uses a cognitive map of a quasi-
pictorial format, on which he locates his position, the
destination and the route between them. To understand the
following description the hearer must re-transform the verbal
information into an appropriate format-presumably a combination
of propositional and quasi-pictorial representation.
Earley-style chart parsers for unification-based grammars are
now commonly used in implementations of formalisms like
PATR-II and others. Some of the most essential extensions to
the standard Earley algorithm are shown: the subsumption
check for the insertion of new edges into the chart and the
restriction of feature structures within the predictor step.
Graham et al. (1980) propose a method for the efficient
encoding of all parse trees for context-free grammars. The
representation of the parse forest provides efficient access to
every single parse tree for a given sentence. This method is
slightly extended for unification-based grammars. It is shown
that the parse forest can be built at very little extra cost while
the Earley chart is being constructed.
To combine the well-known advantages of the ID/LP
formalism with the full power of unification-based grammars,
Unification-ID/LP (UID/LP for short) grammars are defined.
ULP acceptability of parse trees for UID/LP grammars can be
decided for every complete analysis of an input sentence by
checking every local tree in the analysis, just as it is the case
for simple ID/LP grammars. The problems with UID/LP parsing
that arise from allowing unrestricted unification in combination
with constraining LP rules are discussed.
A parsing algorithm consisting of two steps is proposed. In
the first step, an extension of the Earley/Shieber algorithm for
unification grammars is used to build a chart with a
representation of the parse forest for the input sentence. In the
second step, every single parse tree is extracted from the forest
and is checked for ULP acceptability.
In representing the meaning of a preposition, the main question
that arises is whether to assume a polysemous lexem or a
number of homonyms according to the various senses the
respective preposition can adopt. In this paper it will be shown
that by taking a prototypical approach each preposition can be
represented as one coherent concept. Exemplified by the
concept of the English preposition &amp;quot;at&apos; —distinguished by its
diverse range of meanings such as spatial, temporal, causal,
etc.—the systematic relation between the different senses will
be illustrated. The argumentation is centered around the
assumption of a prototypical concept, which in the case of &amp;quot;at&amp;quot;
</bodyText>
<page confidence="0.960268">
136 Computational Linguistics, Volume 15, Number 2, June 1989
</page>
<table confidence="0.343301058823529">
Abstracts of Current Literature
LILOG-Report 24
Representation and Accessibility of
Discourse Referents
Bosch, Peter
September 1987, 23 pp.
LILOG-Report 25
Text Understanding in LILOG-Sorts
and Reference Objects
Rollinger, Clause, Studer, Rudi, Uszkoreit,
Hans and Wachsmuth, Ipke
August 1987, 14 pp.
LILOG-Report 26
Computational Aspects of Three-valued
Logic
Schmitt, P. H.
August 1987, 11 pp.
</table>
<bodyText confidence="0.967546689655172">
is a spatial one. Departing from this prototype new senses
develop successively, motivated by the fact that a certain
domain is conceptualized similarly or analogously to an already
existing concept of the respective preposition.
Linguists and philosophers long looked upon definite reference
as if it were entirely a matter of the descriptive content of
referential expressions. In ordinary discourse, however, such
information is usually insufficient to bring about unambiguous
reference, certainly for pronouns with their extremely attenuate
semantic content, but also for full NPs.
As a framework for the questions I want to discuss I shall
adopt a proposal for a division in short-term working memory
which was put forward by Sanford and Garrod (1981) (Section
1.1). Subsequently I shall amend this proposal to account for
the role of the descriptive content of referential expressions in
accessing the different memory registers. The remainder of
Section 1 provides some linguistic evidence for this amended
model. Section 2 discusses some problems which this model
faces with regard to antecedentless pronouns (2.1) and
contrastive reference (2.2) and leads up to the final version of
our model for the relation between the representation and
accessibility of focused referents, which I shall present in
Section 2.2.
The main objective of the project LILOG (linguistic and logic
methods) is to develop concepts and methods for understanding
German texts and dialogs. &amp;quot;Understanding&amp;quot;, in this context,
refers to the construction of a semantic representation of a
piece of text or of a dialog statement, that is a (partial) model
of the situation described in the text. This representation is
held in a computer memory and is used by the knowledge
processing component, e.g., for extracting information to
augment a knowledge base, or for answering questions about
the text, etc. As a prerequisite, appropriate means for
constructing such a model must be available in a permanent
knowledge base. These means must be retrieved and applied to
the actual situation by appropriate processes.
This paper investigates a three-valued logic L , that has been
introduced in the study of natural language semantics. A
complete proof system based on a three-valued analogon of
negative resolution is presented. A subclass of L.sub.3
corresponding to Horn clauses in two-valued logic is defined.
Its model theoretic properties are studied and it is shown to
admit a PROLOG-style procedure.
Copies of the following abstracts can be obtained at:
Advanced Computational Methods Center
The University of Georgia
Athens, GA 30602
ACMC Research Report 01-0015
Implicature, Disjunction, and Non-
monotonic Logic
Nute, Donald and Covington, Michael
Natural language utterances imply certain facts in the absence
of which they would not be true; they also implicate additional
facts in the absence of which the utterance would probably
have been expressed another way. For example, &amp;quot;There are
five books on the table&amp;quot; implies that there are five books and
implicates that there are not more than five.
Computational Linguistics, Volume 15, Number 2, June 1989 137
</bodyText>
<subsectionHeader confidence="0.826248">
Abstracts of Current Literature
</subsectionHeader>
<bodyText confidence="0.999927">
This paper presents a formal representation of one case of
implicature (Pelletier&apos;s analysis of &amp;quot;or&amp;quot;) using LDR1, a non-
monotonic logic that was originally developed to encode
generalizations that have exceptions.
</bodyText>
<page confidence="0.945636">
138 Computational Linguistics, Volume 15, Number 2, June 1989
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.69947275">ABSTRACTS OF CURRENT LITERATURE Recent memoranda in computer and cognitive science related to natural language processing. For copies of the technical reports listed below, write to: Memoranda Series</title>
<affiliation confidence="0.999432">Computing Research Laboratory</affiliation>
<address confidence="0.999933">Box 30001</address>
<affiliation confidence="0.995195">New Mexico State University</affiliation>
<address confidence="0.9978505">Las Cruces, NM 88003 USA</address>
<title confidence="0.669596666666667">NEW REPORTS AND MEMOS Knowledge Acquisition With A Machine Lexicon</title>
<author confidence="0.280593">C-M Guo</author>
<pubnum confidence="0.548499">MCCS-88-131</pubnum>
<title confidence="0.850677666666667">A Survey Distributed Processing Models from a Computation Perspective</title>
<address confidence="0.416878">Balogh, I.L.</address>
<pubnum confidence="0.546054">MCCS-88-133</pubnum>
<title confidence="0.986808666666667">An Investigation Into The Minimum Structures of Programming Languages and Natural Languages</title>
<author confidence="0.787779">R Hill</author>
<pubnum confidence="0.79693">MCCS-88-134</pubnum>
<abstract confidence="0.953043203703704">Philosophy of Language and Artificial Intelligence Wilks, Y. MCCS-88-132 This paper describes the construction of a machine lexicon and its use in acquiring general world knowledge from natural language text. Two types of text are identified, dictionary definition text and unrestricted general text. Knowledge acquisition from dictionary definition text helps to construct the lexicon, whereas knowledge acquisition from unrestricted general text expands the lexicon. Knowledge acquisition with the machine lexicon represented a continued process of learning, beginning with acquiring lexical and world and knowledge from dictionary definition text, continuing on to acquiring more knowledge from unrestricted general text. Many distributed models of computations have been proposed over the years. On the surface they seem to be quite different from more traditional models, and often from each other. But do they offer a fundamentally different type of computation? Some of the more prominent models are investigated from this computational perspective. A brief description is given of each model, followed by a discussion of their capability with respect to each other and in relation to classical models of computation. A phenomenon that is regarded as .UL theory based must have some foundation (namely, that theory), a grasp of which is necessary and sufficient to a grasp of the whole phenomenon in all of its manifestations. In other words, it must have some minimum structures on which the whole is grounded, so that analysis of any of those manifestations unravels into a tracing back to those structures, and nothing else. If we look at language systems, we have, on the one hand, natural languages, the use of which is guided by the demands of the users, people. On the other, we have programming languages, the use of which is guided by the theory underlying them. Can their respective minimum structures shed light on each other? The paper surveys the relationship between Al and the philosophy of language. Al is normally described either as an engineering task, one of simulating certain interesting human functions (i.e., not arithmetic) with digital computers or, at a 130 Computational Linguistics, Volume 15, Number 2, June 1989 Abstracts of Current Literature higher level, as an attempt to explicate computationally the of intelligence. The history of practice in far more to the Leibnizian goal of a mechanical logic than to, say, robotics, the view of Al always taken by cartoonists. The point of view behind the survey is probably that of Wittgenstein&apos;s &amp;quot;Philosophy leaves everything as it is&amp;quot;. One might extend that, with no greater respect for philosophy, as &amp;quot;Artificial intelligence leaves philosophy as it is&amp;quot;, which is to say that no philosophical consequences follow from any piece of research in artificial intelligence and no particular philosophical assumptions are ended to carry out such research.</abstract>
<note confidence="0.621042333333333">Form and Content in Semantics Wilks, Y. MCCS-88-137 Belief Ascription, Metaphor, and Intensional Identification Bairn, A., Wilks, Y. &amp; Barnden, J.</note>
<pubnum confidence="0.551403">MCCS-88-138</pubnum>
<abstract confidence="0.939833288135593">Connectionist Parallel Machines and Turing Machines as Models of the Mind Wilks, Y. MCCS-86-79 This paper continues a long wail of intellectual complaints against the presumptions of certain kinds of formal semantics (the qualification is important) and their bad effects on those areas of artificial intelligence concerned with machine understanding of human language. The paper begins with a critical examination of Lifschitz&apos;s (out of McCarthy) use of epistemological adequacy. The paper then moves, rather more positively, to contrast forms of formal semantics with a possible alternative: commonsense semantics. Finally, as an in-between case of considerable interest, it examines various positions held by McDermott on these issues and concludes, reluctantly, that, although he has reversed himself on the issue, there was no time when he was right. The purpose of this paper, and the mechanisms it describes, is extension of gen, algorithm for belief ascription in a model of nested viewpoints of agents, to the areas of metaphor, intensional object identification and speech acts, and the addition to the basic &amp;quot;belief engine&amp;quot; of a relevance calculus. That system, summarized here, represents the beliefs of agents as partitioned sets of propositions known as environments. A general defense is given of partitioning approach to belief computation. Environments are convenient, even essential, for addressing important pragmatic issues of reasoning, and are the basis for an existing ascriptional-reasoning program, ViewGen. It is shown that belief ascription, metaphor generation, and intensional object identification can all be seen as processes that involve the amalgamation of a number of environments, and may be seen as manifestations of a single process. The paper makes some initial remarks about whether or not connectionist parallel machines can be considered Turing machines and what the consequences, in principle, for AI&apos;s task of mental modeling might be. Since the application of much connectionist work is in natural language processing, the paper reviews some current work in that area and argues that, whether or not the processes used are genuinely different from conventional symbolic natural language processing, the arguments used by connectionists to support what they are doing do not in fact distinguish them very clearly from their symbolic predecessors. The heart of the paper is a comparison and contrast between a current radical argument for connectionism and a radical argument against. It is not clear that the very same version of connectionism is defended by Smolensky as is attacked by Fodor, but since I do not bring the two arguments directly in Computational Linguistics, Volume 15, Number 2, June 1989 131 Abstracts of Current Literature contact, that will not matter. My own inconclusive view is that the jury is still out, and that, in the meantime, while there is no convincing evidence to believe what Smolensky says, though one may respect it and be stimulated by it, neither should one reject the whole enterprise on the grounds Fodor gives. One can legitimately be, in a narrow and strict sense, an agnostic, without giving that word the force of active disbelief it is often made to carry.</abstract>
<note confidence="0.427914">Reference and Its Role in Computational Models of Mental Representations Wilks, Y. MCCS-85-30 Pronouns in Mind: Quasi-Indexicals and the &amp;quot;Language of Thought&amp;quot; Wilks, Y., BaMm, A. and Dietrich, E.</note>
<pubnum confidence="0.392535">MCCS-87-92</pubnum>
<abstract confidence="0.997588146341463">This paper is written from a standpoint that still has support within that part of the concerned with modeling or simulating mental representations and processes, but which does not accord with the currently fashionable emphasis on the role of logic in those representations. I would characterize the position as &amp;quot;procedural intensionalist&amp;quot;: not a very clear phrase, perhaps, but one which is intended to capture a set of claims that mental representations, in so far as they can be modeled by computer processes are a. symbolic; b. such that their semantics are to be given ultimately by procedures and not (except in a circumscribable set of cases) by sets of referents or by the standard semantics of predicate logic, and c. that semantic decomposition to some set of primitives, which may be domain dependent or (as some would argue) universal, plays a plausible role in the construction of those representations. In this paper, I want indirectly to defend that club, of which I happen to be a member, by critically examining the recent claims of two writers concerning the role of reference in mental and computational representations. These two, Johnson-Laird (1981) and Smith (1982), are not from the extreme logicist camp; on the contrary, both of them distinguish themselves, in their quite different ways, from the claims of the sort associated with McCarthy and Hayes (1969), or, more recently, Barwise and Perry (1983), who assume that some variant of standard first order logic and its semantics is adequate for the description of meaning and knowledge. The paper examines the role of the natural-formal language in connection with the of thought issue. In particular, it distinguishes a realist-uniform/attributistuniform approach to LOT and seeks to link that distinction to the issue of whether artificial intelligence is fundamentally a science or engineering. In a second section, we examine a particular aspect of natural language in relation to LOT: pronouns/indexicals. The focus there is Rapaport&apos;s claims about indexicals in belief representations. We dispute these claims and argue that he confuses claims about English sentences and truth conditions, on the one hand, with claims about beliefs, on the other. In a final section we defend the representational capacity of the belief manipulation system of Wilks, Bien and Ballim against Rapaport&apos;s published criticisms.</abstract>
<note confidence="0.942239">Linguistics, Volume 15, Number 2, June 1989</note>
<title confidence="0.708638">Abstracts of Current Literature</title>
<author confidence="0.335458">The following new papers from the project group KIT can be obtained free of charge from</author>
<affiliation confidence="0.778828666666667">PROJEKTGRUPPE KIT Technische Universitat Berlin Fachbereich Informatik</affiliation>
<address confidence="0.8874905">Sekr. FR 5-12 Franklinstr. 28/29 D-1000 Berlin 10</address>
<author confidence="0.391446">Rep of Germany</author>
<phone confidence="0.267418">KIT-Report 59</phone>
<title confidence="0.989529666666667">A Constructive Version of GPSG for Machine Translation Hauenschild, Christa, and Busemann,</title>
<author confidence="0.919919">Stephan</author>
<note confidence="0.8395365">February 1988, 25 p. appear in: Steiner, E.; Schmidt, Zelinsky-Wibbelt, C. (eds.): Syntax to Semantics-Insights From Machine Translation. Frances Pinter, London, 1988. KIT-Report 60 A Constructive View of GPSG or How to Make it Work Busemann, Stephan, and Hauenschild, Christa April 1988, 6 pp. To appear in: Proceedings of the 12th Conference on Linguistics Budapest, 1988. KIT-Report 61</note>
<title confidence="0.6883295">Using Constraints in a Constructive Version of GPSG</title>
<author confidence="0.625422">Wilhelm Weisweber</author>
<note confidence="0.94139125">April 1988, 6 pp. To appear in: Proceedings of the 12th Conference on Linguistics Budapest, 1988.</note>
<abstract confidence="0.953785836734694">The paper discusses the applicability of generalized phrase structure grammar (GPSG) for machine translation (MT). After sketching the underlying conception of MT in general and defining the part that GPSG is to play within it, the paper concentrates on the problems raised by the claim that GPSG in its 1985 version is not amenable to computer implementation. It is shown that a straightforward implementation of the formalism would lead to a combinatorial explosion of the number of categories to be computed. Instead a constructive view of GPSG is adopted, which allows for grammatical structures in a direct manner but still under the control of the different GPSG devices, which have been redefined. The constructive version of GPSG forms the basis of the Berlin GPSG system, which is modularized according to the needs of MT. It is fully implemented for parsing and generation with one and the same grammar. Some aspects of using grammars bidirectionally are focused on as well as different ways of utilizing the GPSG formalism and their consequences. A straightforward implementation of generalized phrase structure grammar (GPSG) in its 1985 version would involve a vast overgeneration of categories and structures as well as processes to filter out everything but the admissible tree(s). We therefore argue for a constructive version of GPSG where information is gathered in subsequent steps to produce syntactic structures. As a result, we consider it necessary to incorporate procedural aspects into the formalism in order to use it as a linguistic basis for NL parsing and generation. The paper discusses the major implications of such a modified view of GPSG, thereby including a new proposal for handling agreement in a simple and sufficiently general manner. Complex categories are characteristic of unification grammars as, for example, GPSG. They are sets of pairs of features and values and have crucial influence on the efficiency of the parsing algorithm. This is one problem from using complex categories; another one arises when using a constructive version of GPSG in which the feature values are propagated among the categories of a local tree. Namely that the application of admissibility conditions, i.e. linear precedence (LP) statements and feature co-occurrence restrictions (FCRs), to a local tree t is prevented because particular feature values of categories in t are not yet specified, but they will be instantiated later somewhere else in the complete tree. The paper describes the latter problem and will present a solution working with computation, evaluation and propagation of constraints within local trees. The constraint evaluation will reject local trees if the constraints of the subtrees of the daughters are violated. Computational Linguistics, Volume 15, Number 2, June 1989 133 Abstracts of Current Literature MT-Report 62</abstract>
<title confidence="0.9751995">Discourse Structure-Some Implications for Machine Translation</title>
<author confidence="0.591447">Christa Hauenschild</author>
<note confidence="0.875558125">April 1988, 15 pp. appear in: of &amp;quot;New Directions in Machine Translation&amp;quot;, International Conference, Budapest, 18-19 August 1988, organized by BSO/Research (Utrecht) and the John von Neumann Society (Budapest). MT-Publication List:</note>
<abstract confidence="0.971473173076924">Reports, Working Papers, and other publications July 1988, 18 pp. paper discusses the importance of discourse structure general and machine translation, regarded as a special case of translation. After some general remarks on the role of discourse structure for human and machine translation, the interrelation between the stipulation of invariants in translation and the interlingual approach is examined. As a kind of counter-evidence some language-particular ways of expressing the thematic structuring of a text are introduced, which leads us to an argumentation in favour of the transfer approach to translation. The conclusion is that both aspects of translation ought to be considered in machine translation, which yields an argumentation in favour of a &amp;quot;mixed approach&amp;quot;. LILOG-REPORT 3 Implementation Aspects of a Natural Language Understanding System in a PROLOG/DB Environment Studer, Rudi, and Walter, Bernd September 1986, 12 pp. LILOG-Report 6 Mathematical Logic and Artificial Intelligence Schmitt, P. H. January 1987, 17 pp. For capturing static and dynamic aspects of an application domain on a conceptual level, THM-Nets based on a semantic data model and Petri net concepts have been proposed. In this paper THM-Nets are generalized to timed THM-Nets, thus providing modeling concepts for capturing physical and logical time aspects of a slice of reality. These modeling concepts are based on an appropriate notion of physical and logical time within the semantic data model THM. LILOG is a project for exploring linguistic and logic methods for an automatic understanding of German texts and for an adequate representation of the acquired knowledge. In order to maintain knowledge bases of realistic size, database technology will be used. This paper discusses some of the problems that occur when an existing database system (SQL/DS) is used for representing the various types of knowledge. Additionally, the design of a rapid prototype PROLOG/SQL system will be presented, which supports the exploration of various mapping and access schemes and considers the fact that the used knowledge representation methods will most certainly evolve during the course of the project. This paper discusses some research topics of mutual interest in mathematical logic and artificial intelligence. Among the topics treated are mathematical theorem proving, modal logic, manyvalued logic, reasoning under uncertainty and monotonic logic. While some issues are treated in detail for others only a selected guide to the literature is given. The following reports can be ordered from:</abstract>
<affiliation confidence="0.965763">IBM Deutschland GmbH</affiliation>
<address confidence="0.824366333333333">WT LILOG / Dept. 3504 80 08 80 D-7000 Stuttgart 80</address>
<author confidence="0.3538805">Rep of Germany LILOG-Report</author>
<title confidence="0.986383">A Conceptual Model for Time</title>
<author confidence="0.985372">Rudi Studer</author>
<note confidence="0.52726375">December 1986, 20 pp. 134 Computational Linguistics, Volume 15, Number 2, June 1989 Abstracts of Current Literature LILOG-Report 7</note>
<title confidence="0.937566">The Semantics of Asserting and Retracting Clauses to Logic Programs</title>
<author confidence="0.712841">Udo Pletat</author>
<author confidence="0.712841">Christoph Beierk</author>
<date confidence="0.481373">July 1987, 22 pp.</date>
<note confidence="0.647007">LILOG-Report 8</note>
<title confidence="0.9100745">An Approach to Manage Large Inheritance Networks</title>
<author confidence="0.919107">Rudi Studner</author>
<author confidence="0.919107">Stefan Borner</author>
<note confidence="0.537839">March 1987, 12 pp. LILOG-Report 12</note>
<title confidence="0.8059185">On Structuring Domain-Specific Knowledge</title>
<author confidence="0.401317">Ipke Wachsmuth</author>
<note confidence="0.3636165">March 1987, 15 pp. LILOG-Report 13</note>
<title confidence="0.838943">Word Order and Focus Projection</title>
<author confidence="0.810746">Birgit Wesche</author>
<author confidence="0.810746">Ingrid Renz</author>
<abstract confidence="0.999389480769231">April 1987, 20 pp. We discuss two approaches for defining the operational semantics of modifying logic programs by means of asserting and retracting clauses. The first approach defines a &amp;quot;logically clean&amp;quot; behavior for assert and retract. Logically clean means that this operational semantics for logic programs including asserts and retracts is equivalent to the model theoretic semantics of the logical skeleton of a program, i.e., where the asserts and retracts are removed. This is achieved by delaying the modification of the program due to the asserts and retracts passed during a proof after the successful evaluation of a goal. We contrast this clean semantics with the PROLOG style of modifying logic programs and discuss the reasons for losing the logical cleanness. When developing large-scale knowledge-based systems, concepts are required for handling knowledge bases on external storage. In this paper we present an approach for managing structured inheritance networks in a database. Actually, we develop a representation of a KL-ONE-like formalism in an extended relational database system supporting non-first-normal-form relations. Of special importance is the handling of the general hierarchical structure provided by KL-ONE within the tree structure offered by non-first-normal-form relations. This paper presents a proposal on how domain-specific knowledge of both conceptual and assertional nature can be structured. The aim is to devise a way that allows large amounts of domain-dependent knowledge to be used by a knowledge-based system while keeping the system manageable. The proposal grounds on findings from empirical research on the acquisition of domain-specific knowledge. It is presented abstractly in the form of principles that are to be understood as a specification rather than a symbol-level description for a representation scheme. The model comprised by these principles suggests domain-specific knowledge be organized in nested packets of knowledge elements. The central notions of &amp;quot;visible&amp;quot; and &amp;quot;reachable&amp;quot; knowledge are used to characterize static and One of the major problems that has to be confronted in a natural language system for German is its relatively free word order. If one takes into account, however, that word order is to a large extent motivated by pragmatic considerations the choices for placing the single constituents within a sentence narrow down considerably. A factor by which pragmatic aspects are reflected quite explicitly is stress. In this paper we will outline the regularities that result from the strong interaction of word order and stress in German, and show how these can be exploited even within an NL system which is based on written input only. Taking such an approach will have an impact on the encoding of lexical entries, on the formulation of syntactic rules, on parsing strategies, and it will, furthermore, support the component of semantic representation in that we will have a clearer insight as to which elements constitute the core message of a sentence.</abstract>
<note confidence="0.610447846153846">Computational Linguistics, Volume 15, Number 2, June 1989 135 Abstracts of Current Literature LILOG-Report 20 Mental Images and Route Descriptions (in German) Rehkamper, Kalus August 1987, 10 pp. LILOG-Report 22 Chart Parsing of Unification-Based Grammars with ID/LP Rules Seiffert, Roland September 1987, 19 pp. LILOG-Report 23</note>
<title confidence="0.334499">At Ease with &amp;quot;at&amp;quot;</title>
<author confidence="0.336466">Birgit Wesche</author>
<abstract confidence="0.978919816666667">August 1987, 12 pp. images of great importance in the text comprehension of human beings. Text understanding computer systems which intend to meet the demands of cognitive adequacy must take this fact into account. Human beings use these images to represent knowledge. Thus images are-in addition to propositions-another way of gaining and representing knowledge. In this paper I want to show some of the new possibilities opened up by this second form of representation as well as the restrictions connected with it. Route descriptions form a class of texts which obviously require mental images for their generation and comprehension. During the generation of a route description the informant uses a cognitive map of a quasipictorial format, on which he locates his position, the destination and the route between them. To understand the following description the hearer must re-transform the verbal information into an appropriate format-presumably a combination of propositional and quasi-pictorial representation. Earley-style chart parsers for unification-based grammars are now commonly used in implementations of formalisms like PATR-II and others. Some of the most essential extensions to the standard Earley algorithm are shown: the subsumption check for the insertion of new edges into the chart and the restriction of feature structures within the predictor step. Graham et al. (1980) propose a method for the efficient encoding of all parse trees for context-free grammars. The representation of the parse forest provides efficient access to every single parse tree for a given sentence. This method is slightly extended for unification-based grammars. It is shown that the parse forest can be built at very little extra cost while the Earley chart is being constructed. To combine the well-known advantages of the ID/LP formalism with the full power of unification-based grammars, Unification-ID/LP (UID/LP for short) grammars are defined. ULP acceptability of parse trees for UID/LP grammars can be decided for every complete analysis of an input sentence by checking every local tree in the analysis, just as it is the case for simple ID/LP grammars. The problems with UID/LP parsing that arise from allowing unrestricted unification in combination with constraining LP rules are discussed. A parsing algorithm consisting of two steps is proposed. In the first step, an extension of the Earley/Shieber algorithm for unification grammars is used to build a chart with a representation of the parse forest for the input sentence. In the second step, every single parse tree is extracted from the forest and is checked for ULP acceptability. In representing the meaning of a preposition, the main question that arises is whether to assume a polysemous lexem or a number of homonyms according to the various senses the respective preposition can adopt. In this paper it will be shown that by taking a prototypical approach each preposition can be represented as one coherent concept. Exemplified by the concept of the English preposition &amp;quot;at&apos; —distinguished by its diverse range of meanings such as spatial, temporal, causal, etc.—the systematic relation between the different senses will be illustrated. The argumentation is centered around the assumption of a prototypical concept, which in the case of &amp;quot;at&amp;quot; Linguistics, Volume 2, June 1989 Abstracts of Current Literature LILOG-Report 24</abstract>
<title confidence="0.8051695">Representation and Accessibility of Discourse Referents</title>
<author confidence="0.700719">Peter Bosch</author>
<date confidence="0.287956">September 1987, 23 pp.</date>
<note confidence="0.50831">LILOG-Report 25</note>
<title confidence="0.786002">Text Understanding in LILOG-Sorts and Reference Objects</title>
<author confidence="0.3082255">Clause Rollinger</author>
<author confidence="0.3082255">Rudi Studer</author>
<author confidence="0.3082255">Hans Uszkoreit</author>
<author confidence="0.3082255">Ipke Wachsmuth</author>
<abstract confidence="0.92307893877551">August 1987, 14 pp. LILOG-Report 26 Computational Aspects of Three-valued Logic Schmitt, P. H. August 1987, 11 pp. is a spatial one. Departing from this prototype new senses develop successively, motivated by the fact that a certain domain is conceptualized similarly or analogously to an already existing concept of the respective preposition. Linguists and philosophers long looked upon definite reference as if it were entirely a matter of the descriptive content of referential expressions. In ordinary discourse, however, such information is usually insufficient to bring about unambiguous reference, certainly for pronouns with their extremely attenuate semantic content, but also for full NPs. As a framework for the questions I want to discuss I shall adopt a proposal for a division in short-term working memory which was put forward by Sanford and Garrod (1981) (Section 1.1). Subsequently I shall amend this proposal to account for the role of the descriptive content of referential expressions in accessing the different memory registers. The remainder of Section 1 provides some linguistic evidence for this amended model. Section 2 discusses some problems which this model faces with regard to antecedentless pronouns (2.1) and contrastive reference (2.2) and leads up to the final version of our model for the relation between the representation and accessibility of focused referents, which I shall present in Section 2.2. The main objective of the project LILOG (linguistic and logic methods) is to develop concepts and methods for understanding German texts and dialogs. &amp;quot;Understanding&amp;quot;, in this context, refers to the construction of a semantic representation of a piece of text or of a dialog statement, that is a (partial) model of the situation described in the text. This representation is held in a computer memory and is used by the knowledge processing component, e.g., for extracting information to augment a knowledge base, or for answering questions about the text, etc. As a prerequisite, appropriate means for constructing such a model must be available in a permanent knowledge base. These means must be retrieved and applied to the actual situation by appropriate processes. This paper investigates a three-valued logic L , that has been introduced in the study of natural language semantics. A complete proof system based on a three-valued analogon of negative resolution is presented. A subclass of L.sub.3 corresponding to Horn clauses in two-valued logic is defined. Its model theoretic properties are studied and it is shown to admit a PROLOG-style procedure.</abstract>
<affiliation confidence="0.850225">Copies of the following abstracts can be obtained at: Advanced Computational Methods Center The University of Georgia</affiliation>
<address confidence="0.996821">Athens, GA 30602</address>
<pubnum confidence="0.940534">Report 01-0015</pubnum>
<title confidence="0.3256915">Implicature, Disjunction, and Nonmonotonic Logic</title>
<author confidence="0.162238">Donald Nute</author>
<author confidence="0.162238">Michael Covington</author>
<abstract confidence="0.952200833333333">Natural language utterances imply certain facts in the absence of which they would not be true; they also implicate additional facts in the absence of which the utterance would probably have been expressed another way. For example, &amp;quot;There are five books on the table&amp;quot; implies that there are five books and implicates that there are not more than five. Computational Linguistics, Volume 15, Number 2, June 1989 137 Abstracts of Current Literature This paper presents a formal representation of one case of implicature (Pelletier&apos;s analysis of &amp;quot;or&amp;quot;) using LDR1, a nonmonotonic logic that was originally developed to encode generalizations that have exceptions.</abstract>
<intro confidence="0.678761">138 Computational Linguistics, Volume 15, Number 2, June 1989</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>