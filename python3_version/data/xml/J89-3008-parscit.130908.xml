<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000072">
<note confidence="0.706286">
Book Reviews Machine Translation: Linguistic Characteristics of MT Systems and General Methodology of Evaluation
</note>
<sectionHeader confidence="0.602123333333333" genericHeader="method">
MACHINE TRANSLATION: LINGUISTIC
CHARACTERISTICS OF MT SYSTEMS AND GENERAL
METHODOLOGY OF EVALUATION
</sectionHeader>
<bodyText confidence="0.727223285714286">
John Lehrberger and Laurent Bourbeau
(Lingvisticx investigationes: Supplementa: Studies in
French and general linguistics / Etudes en
linguistique frangaise et generale 15)
Amsterdam and Philadelphia: John Benjamins
Publishing Company, 1988, xiii + 240 pp.
ISBN 90-272-3124-9, £30.00 (hb)
</bodyText>
<figure confidence="0.529153">
Reviewed by
Rita McCardell
</figure>
<affiliation confidence="0.937861">
University of Maryland, Baltimore County
</affiliation>
<bodyText confidence="0.983013680000001">
This book (which has been long in the making!) is a
compilation of a large number of papers written over the
years (1971-1981) dating from the first attempts (circa
1968) at this system. It describes in full detail TAUM
(Traduction Automatique de l&apos;Universite de Montreal),
a second-generation transfer-based MT system, as op-
posed to a first-generation, direct (i.e., word-for-word)
translation or a third-generation, knowledge-based (i.e.,
interlingua MT system). (For illustrative purposes, the
authors include a detailed flowchart of a typical second-
generation MT system in Appendix B.)
In particular, this book highlights the operational
system produced by the TAUM project—TAum METE0
—which translates telegraphic weather reports issued
by Environment Canada from English into French. (The
experimental systems produced from TAUM were
TAum-71, TAum-73, TAum-76 and TAUM-AVIATION.)
TAUM METE() has been operational since 1977 and is
universally acclaimed as &amp;quot;the closest approximation to
fully automated high-quality (machine) translation
among currently operational systems&amp;quot; (Nirenburg
1987). Because of METEo&apos;s stereotypic format, the
research from this project has led to a very important
development in a branch of linguistic analysis con-
cerned with the sublanguage concept, connected with
the names of Lehrberger, Richard Kittredge, and Ralph
Grishman (see a discussion in Hutchins 1986).
In Chapter 2, five characteristics of MT systems are
identified. The first pertains to the degree of automation
in the system, whether it be machine-aided human
translation, human-aided machine translation, or fully
automatic machine translation. Secondly, the extent to
which the source language is analyzed, either locally or
at the sentence level, is discussed. The authors stress
the major presupposition of fully automatic (high-
quality) MT—the depth of analysis of an MT system is
indicative of the level of understanding implicit in the
system.
Next, the type of information transfer (e.g., direct or
use of a pivot language) between source and target
language is considered. The authors conclude that de-
signing a universal pivot language, one that is &amp;quot;totally
independent of any particular natural language&amp;quot; is not
feasible. This conclusion seems somewhat dated. A
recent experimental MT system KBMT-89, developed
at Carnegie Mellon University (CMU-CMT 1989) for
bidirectional Japanese-English translation of computer
hardware manuals is based on this model. What makes
KBMT-89 different from previous attempts at building
such interlingual systems is its systematic reliance on a
large ann independently motivated model of the domain
of translation, which serves as the basis for developing
the interlingual representations.
The last two system characteristics deal with the
organization (and advantages) of modular MT process-
ing and the domain dependency of the lexical and
syntactic aspects of an MT system, respectively. Addi-
tionally, the authors stress the fact that the performance
of an MT system depends very much on the domain of
application, given its restricted vocabulary and, in some
cases, a restricted syntax as well. Consequently, they
leave the reader pondering if one domain is necessarily
easier to translate than another.
Chapter 3 takes a closer look at the characteristics of
an MT system by giving an idea of its architecture in
terms of the major linguistic components: lexical, mor-
phological, syntactic, and semantic. The lexical compo-
nent discusses the number and structure of dictionaries
to be used and the information content and form of each
lexical entry (including idioms) contained within each
lexicon. The morphological component explains the
processing and strategies behind inflectional, deriva-
tional, and compositional morphology. Simple and com-
plex sentence structure as well as complex constituents
are analyzed in the section on syntax. Because local
analysis is insufficient for any reasonable level of un-
derstanding, the semantic component describes finding
the total meaning of a sentence at both the word and
syntagmatic levels—resolving homography at the word
level and using selectional restrictions and subcategori-
zation information at the syntagmatic.
Chapter 4 discusses two opposing approaches to
designing an MT system: the corpus-based approach
and the standard grammar approach. The advantages
and disadvantages of each are explained. Both ap-
proaches have a direct effect on determining the content
of the linguistic information present in the dictionaries
and grammars of an MT system.
Chapter 5 deals with the methodology for linguistic
evaluation: identifying the user&apos;s needs and constraints
of translation, evaluating the performance of the linguis-
tic components of the system, and evaluating the poten-
tial of a system. Additionally, because of the effect on
the human translators and revisers who must use the
machine, the evaluation of the user environment is also
discussed. The authors suggest steps to be followed in
deciding on the acceptability of a system and then
summarize the fundamental aspects and limitations of
the proposed methodology for evaluating MT systems.
An important feature of this book, which sets it aside
</bodyText>
<page confidence="0.966543">
194 Computational Linguistics, Volume 15, Number 3, September 1989
</page>
<bodyText confidence="0.9749314375">
Book Reviews Medical Language Processing: Computer Management of Narrative Data
from many other writings on the subject, is its discus-
sion of the problem of evaluating MT systems. The
proposed methodology is decomposed into three dis-
tinct areas: (i) evaluation by the system&apos;s designer; (ii)
cost/benefit evaluation by the user; and (iii) linguistic
evaluation by the user. This delineation serves as the
framework for a more detailed and impressive, though
by no means final, study contained in Appendix A.
In the conclusion, Lehrberger and Bourbeau discuss
the feasibility of MT, its future prospects, and the
impact of evaluation methodology on those prospects.
To summarize: I thought that this book was very well
written and intended for the mature MT researcher. The
impact of the book would be even greater had it been
published earlier in the decade.
</bodyText>
<sectionHeader confidence="0.933669" genericHeader="method">
REFERENCES
</sectionHeader>
<bodyText confidence="0.720530692307692">
CMU-CBT 1989, KBMT-89, Technical Report, Carnegie Mellon
University, Center for Machine Translation.
Hutchins, W.J. 1986 Machine translation: Past, present, future.
Chichester, England: Ellis Horwood Limited.
Nirenburg, Sergei (ed.) 1987 Machine translation: Theoretical and
methodological issues. Cambridge, England: Cambridge Univer-
sity Press.
Rita McCarden is a Ph.D. candidate at the Computer Science
Department of the University of Maryland, Baltimore County.
Her interests include machine translation and natural language
generation. McCardell&apos;s address is: 111 Rodeo Circle, Balti-
more, MD 21220 E-mail: rita@nl.cs.cmu.edu or mccardel@
umbc3.umd.edu
</bodyText>
<sectionHeader confidence="0.8771065" genericHeader="method">
MEDICAL LANGUAGE PROCESSING: COMPUTER
MANAGEMENT OF NARRATIVE DATA
</sectionHeader>
<author confidence="0.18136">
Naomi Sager, Carol Friedman, and Margaret S.
</author>
<figure confidence="0.458533333333333">
Lyman
(New York University)
Reading, MA: Addison-Wesley, 1987, xiii + 348 pp.
ISBN 0-201-16810-3, $41.95 (hb)
Reviewed by
Nicoletta Calzolari
</figure>
<subsubsectionHeader confidence="0.496882">
University of Pisa
</subsubsectionHeader>
<bodyText confidence="0.999849138888889">
The book under review builds on and is an extension of
the New York University Linguistic String Project
system applied to medical language processing. The
system analyzes free text and converts the information
&apos;hidden&apos; in it, the syntactic and semantic regularities,
into an informationally equivalent structured form,
which is best suited for information retrieval and auto-
matic summarization. From the computational linguis-
tics point of view, the main interesting results consist on
the one hand of the demonstration that a real world text
processing application of linguistic analysis is possible
(i.e., the processing of real textual input), and on the
other hand in the fact that the methodology and the
techniques used here and described for medical Ian-
guage are by and large also applicable to other, com-
pletely different, environments. The work also has links
to knowledge representation, given that a method for
representing and processing semantic information is
provided, and the data supplied could be a testbed for
knowledge-based systems.
In Chapter 1 a general overview is given of the
problems, the methodology, and the theoretical support
involved in processing natural language and sublan-
guage in particular. It is by syntactic clues that a set of
semantic statement types are individuated, and there-
fore semantic results are achieved, but the main meth-
ods of analysis are dictionary look-up and pattern
matching.
Chapter 2 is of less relevance for linguistics; it is
mainly concerned with the medical aspects of the proj-
ect, and with its practical applications purely from the
physician&apos;s point of view.
Chapter 3 describes the types of information struc-
tures that are typical of the sublanguage of medical
narrative and the way in which they are mapped into
computer representations, i.e., rather simple informa-
tion formats. Grammatical paraphrase, deletion of re-
dundant words, and regularization procedures are some
of the main procedures used to obtain the information
formats from the surface grammatical structure. These
format structures, although resembling `classical&apos;
frames, are specifically designed to &amp;quot;reflect the linguis-
tic regularities observed in sublanguage texts, and
therefore differ from most uses of frames in artificial
intelligence applications.&amp;quot; Whether they really differ is
perhaps questionable: they both try to capture similar
types of regularities and formalize underlying grammat-
ical relations into predicational structures. In my opin-
ion, the real difference is in their suitability as to their
application to (and empirical derivation from) real texts.
It is interesting to learn that only six types of infor-
mation formats, plus seven types of modifier formats,
are sufficient for representing information in clinical
narrative texts. How many would be necessary if deal-
ing with other types of sublanguage texts? How many
for general language? An evaluation of them in other
fields and a comparison would be interesting.
Chapter 4 describes how the system uses lists of
sublanguage word subclasses, with constraints on the
syntactic relations occurring between them, in order to
accomplish some linguistic tasks, e.g., to rule out
inappropriate prepositional phrase attachments (a typi-
cal problem unsolved with pure syntactic analysis) and
to select the attachments permitted in the domain. The
same method, i.e., checking against a list of well-formed
word class patterns, is used for homograph disambigu-
ation. An essential tool is therefore the possibility of
classifying lexical entries into a well-defined set of
semantic word classes, for which it is possible to state a
number of syntactic and semantic properties in the
sublanguage being analyzed. These entries do all the
work. This approach, which gives good results, is of
</bodyText>
<page confidence="0.287738">
Computational Linguistics, Volume 15, Number 3, September 1989 195
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.015166">
<title confidence="0.95344025">Book Reviews Machine Translation: Linguistic Characteristics of MT Systems and General Methodology of Evaluation MACHINE TRANSLATION: LINGUISTIC OF SYSTEMS GENERAL METHODOLOGY OF EVALUATION</title>
<author confidence="0.988248">John Lehrberger</author>
<author confidence="0.988248">Laurent Bourbeau</author>
<note confidence="0.951731">(Lingvisticx investigationes: Supplementa: Studies in French and general linguistics / Etudes en linguistique frangaise et generale 15) Amsterdam and Philadelphia: John Benjamins Publishing Company, 1988, xiii + 240 pp. ISBN 90-272-3124-9, £30.00 (hb) Reviewed by</note>
<author confidence="0.999085">Rita McCardell</author>
<affiliation confidence="0.993519">University of Maryland, Baltimore County</affiliation>
<abstract confidence="0.992610871794872">This book (which has been long in the making!) is a compilation of a large number of papers written over the years (1971-1981) dating from the first attempts (circa 1968) at this system. It describes in full detail TAUM (Traduction Automatique de l&apos;Universite de Montreal), a second-generation transfer-based MT system, as opposed to a first-generation, direct (i.e., word-for-word) translation or a third-generation, knowledge-based (i.e., system). (For illustrative purposes, the authors include a detailed flowchart of a typical second- MT system in Appendix In particular, this book highlights the operational produced by the —which translates telegraphic weather reports issued by Environment Canada from English into French. (The systems produced from TAum-73, TAum-76 and METE() been operational since 1977 and is universally acclaimed as &amp;quot;the closest approximation to fully automated high-quality (machine) translation among currently operational systems&amp;quot; (Nirenburg 1987). Because of METEo&apos;s stereotypic format, the research from this project has led to a very important development in a branch of linguistic analysis concerned with the sublanguage concept, connected with the names of Lehrberger, Richard Kittredge, and Ralph Grishman (see a discussion in Hutchins 1986). In Chapter 2, five characteristics of MT systems are identified. The first pertains to the degree of automation in the system, whether it be machine-aided human translation, human-aided machine translation, or fully automatic machine translation. Secondly, the extent to which the source language is analyzed, either locally or at the sentence level, is discussed. The authors stress presupposition of fully automatic (highquality) MT—the depth of analysis of an MT system is indicative of the level of understanding implicit in the system. Next, the type of information transfer (e.g., direct or use of a pivot language) between source and target language is considered. The authors conclude that dea language, one that is &amp;quot;totally independent of any particular natural language&amp;quot; is not feasible. This conclusion seems somewhat dated. A recent experimental MT system KBMT-89, developed at Carnegie Mellon University (CMU-CMT 1989) for bidirectional Japanese-English translation of computer hardware manuals is based on this model. What makes KBMT-89 different from previous attempts at building such interlingual systems is its systematic reliance on a large ann independently motivated model of the domain of translation, which serves as the basis for developing the interlingual representations. The last two system characteristics deal with the (and advantages) of modular MT processing and the domain dependency of the lexical and syntactic aspects of an MT system, respectively. Additionally, the authors stress the fact that the performance of an MT system depends very much on the domain of application, given its restricted vocabulary and, in some cases, a restricted syntax as well. Consequently, they leave the reader pondering if one domain is necessarily easier to translate than another. Chapter 3 takes a closer look at the characteristics of an MT system by giving an idea of its architecture in terms of the major linguistic components: lexical, morphological, syntactic, and semantic. The lexical component discusses the number and structure of dictionaries to be used and the information content and form of each lexical entry (including idioms) contained within each lexicon. The morphological component explains the processing and strategies behind inflectional, derivational, and compositional morphology. Simple and complex sentence structure as well as complex constituents are analyzed in the section on syntax. Because local analysis is insufficient for any reasonable level of understanding, the semantic component describes finding the total meaning of a sentence at both the word and syntagmatic levels—resolving homography at the word level and using selectional restrictions and subcategorization information at the syntagmatic. Chapter 4 discusses two opposing approaches to designing an MT system: the corpus-based approach and the standard grammar approach. The advantages and disadvantages of each are explained. Both approaches have a direct effect on determining the content of the linguistic information present in the dictionaries and grammars of an MT system. Chapter 5 deals with the methodology for linguistic evaluation: identifying the user&apos;s needs and constraints of translation, evaluating the performance of the linguistic components of the system, and evaluating the potential of a system. Additionally, because of the effect on the human translators and revisers who must use the machine, the evaluation of the user environment is also discussed. The authors suggest steps to be followed in deciding on the acceptability of a system and then summarize the fundamental aspects and limitations of the proposed methodology for evaluating MT systems. An important feature of this book, which sets it aside 194 Computational Linguistics, Volume 15, Number 3, September 1989 Reviews Language Processing: Computer Management of Narrative Data from many other writings on the subject, is its discussion of the problem of evaluating MT systems. The proposed methodology is decomposed into three distinct areas: (i) evaluation by the system&apos;s designer; (ii) cost/benefit evaluation by the user; and (iii) linguistic evaluation by the user. This delineation serves as the framework for a more detailed and impressive, though by no means final, study contained in Appendix A. In the conclusion, Lehrberger and Bourbeau discuss the feasibility of MT, its future prospects, and the impact of evaluation methodology on those prospects. To summarize: I thought that this book was very well written and intended for the mature MT researcher. The impact of the book would be even greater had it been published earlier in the decade.</abstract>
<note confidence="0.936020785714286">REFERENCES CMU-CBT 1989, KBMT-89, Technical Report, Carnegie Mellon University, Center for Machine Translation. W.J. 1986 translation: Past, present, future. Chichester, England: Ellis Horwood Limited. Sergei (ed.) 1987 translation: Theoretical and issues. England: Cambridge University Press. McCarden is Ph.D. candidate at the Computer Science Department of the University of Maryland, Baltimore County. Her interests include machine translation and natural language generation. McCardell&apos;s address is: 111 Rodeo Circle, Baltimore, MD 21220 E-mail: rita@nl.cs.cmu.edu or mccardel@ umbc3.umd.edu</note>
<title confidence="0.581894">MEDICAL LANGUAGE PROCESSING: COMPUTER MANAGEMENT OF NARRATIVE DATA</title>
<author confidence="0.635477">Naomi Sager</author>
<author confidence="0.635477">Carol Friedman</author>
<author confidence="0.635477">Margaret S Lyman</author>
<affiliation confidence="0.628028">(New York University)</affiliation>
<address confidence="0.416364">Reading, MA: Addison-Wesley, 1987, xiii + 348 pp.</address>
<note confidence="0.971801">ISBN 0-201-16810-3, $41.95 (hb) Reviewed by</note>
<author confidence="0.996335">Nicoletta Calzolari</author>
<affiliation confidence="0.995722">University of Pisa</affiliation>
<abstract confidence="0.998461577464789">The book under review builds on and is an extension of the New York University Linguistic String Project system applied to medical language processing. The system analyzes free text and converts the information &apos;hidden&apos; in it, the syntactic and semantic regularities, into an informationally equivalent structured form, which is best suited for information retrieval and automatic summarization. From the computational linguistics point of view, the main interesting results consist on the one hand of the demonstration that a real world text processing application of linguistic analysis is possible (i.e., the processing of real textual input), and on the other hand in the fact that the methodology and the used here and described for medical Ianguage are by and large also applicable to other, completely different, environments. The work also has links to knowledge representation, given that a method for representing and processing semantic information is provided, and the data supplied could be a testbed for knowledge-based systems. In Chapter 1 a general overview is given of the problems, the methodology, and the theoretical support involved in processing natural language and sublanguage in particular. It is by syntactic clues that a set of semantic statement types are individuated, and therefore semantic results are achieved, but the main methods of analysis are dictionary look-up and pattern matching. Chapter 2 is of less relevance for linguistics; it is mainly concerned with the medical aspects of the project, and with its practical applications purely from the physician&apos;s point of view. Chapter 3 describes the types of information structures that are typical of the sublanguage of medical narrative and the way in which they are mapped into computer representations, i.e., rather simple information formats. Grammatical paraphrase, deletion of redundant words, and regularization procedures are some of the main procedures used to obtain the information formats from the surface grammatical structure. These format structures, although resembling `classical&apos; frames, are specifically designed to &amp;quot;reflect the linguistic regularities observed in sublanguage texts, and therefore differ from most uses of frames in artificial intelligence applications.&amp;quot; Whether they really differ is perhaps questionable: they both try to capture similar types of regularities and formalize underlying grammatical relations into predicational structures. In my opinion, the real difference is in their suitability as to their application to (and empirical derivation from) real texts. It is interesting to learn that only six types of information formats, plus seven types of modifier formats, are sufficient for representing information in clinical narrative texts. How many would be necessary if dealing with other types of sublanguage texts? How many for general language? An evaluation of them in other fields and a comparison would be interesting. Chapter 4 describes how the system uses lists of sublanguage word subclasses, with constraints on the syntactic relations occurring between them, in order to accomplish some linguistic tasks, e.g., to rule out inappropriate prepositional phrase attachments (a typical problem unsolved with pure syntactic analysis) and to select the attachments permitted in the domain. The same method, i.e., checking against a list of well-formed word class patterns, is used for homograph disambiguation. An essential tool is therefore the possibility of classifying lexical entries into a well-defined set of semantic word classes, for which it is possible to state a number of syntactic and semantic properties in the sublanguage being analyzed. These entries do all the</abstract>
<note confidence="0.634407">work. This approach, which gives good results, is of Computational Linguistics, Volume 15, Number 3, September 1989 195</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>