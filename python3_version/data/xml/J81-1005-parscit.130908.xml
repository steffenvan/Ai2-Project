<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002202">
<bodyText confidence="0.929713933333333">
Technical Correspondence On the Utility of Computing Inferences in Data Base Query Systems
these implementations were significantly more effi-
cient, but checked a somewhat narrower class of pre-
sumptions than CO-OP.
6. Damerau mentions that queries with non-empty
responses can also make presumptions. This is cer-
tainly true, even in more subtle ways than noted. (For
example, &amp;quot;What is the youngest assistant professors
salary?&amp;quot; presumes that there is more than one assistant
professor.) Issues such as these are indeed currently
under investigation.
Overall, we are pleased to see that Damerau has
raised some very important issues and we hope that
this exchange will be helpful to the natural language
processing community.
</bodyText>
<author confidence="0.704502">
Aravind K. Joshi
</author>
<affiliation confidence="0.90613425">
Dept. of Computer and
Information Science
University of Pennsylvania
Philadelphia, Pennsylvania 19104
</affiliation>
<author confidence="0.903055">
S. Jerrold Kaplan
</author>
<affiliation confidence="0.9687325">
Computer Science Department
Stanford University
</affiliation>
<address confidence="0.44949">
Stanford, California 94305
</address>
<subsectionHeader confidence="0.749328">
Reply to Joshi and Kaplan
</subsectionHeader>
<bodyText confidence="0.971808708333333">
In general, there is little to disagree with in Joshi
and Kaplan&apos;s comments, but perhaps a couple of
points could be clarified.
As Joshi and Kaplan suspected (point 3), the users
of this system did indeed thoroughly understand the
data base. This makes quite a difference in thinking
about the relative importance of facilities in a natural
language query system. In particular, such users tend
to check strange answers, so that a reply of &amp;quot;no&amp;quot;, as
in their point 4, would probably result in an additional
question of &amp;quot;How many parcels ... &amp;quot;.
With regard to their remarks on implementations
that incur no additional cost (points 2 and 5), I would
be interested in seeing how presupposition analysis can
be done without extra data base retrievals. It would
seem that the system would either have to make spe-
cial retrievals at marked times, as in CO-OP, or would
have to make the relevant retrievals for every question
so as to have the results available when needed. How-
ever, even if the execution time increase were to be
zero, we still have a great many other things which we
would like to add to our system before we add infer-
ence checking.
Fred J. Damerau
</bodyText>
<subsectionHeader confidence="0.88630275">
Book Reviews
Logic For Problem Solving
Robert Kowalski
Elsevier North Holland, New York, 1979,
</subsectionHeader>
<bodyText confidence="0.986492898148149">
287 pp., Paperback, $9.95, ISBN 0-444-00365-7.
This is a textbook introduction to logic program-
ming. Logic programming is based on the premise that
programming a task on a computer should begin with a
precise formulation of what is wanted. This formula-
tion defines the task clearly; it serves as a theory of
the task which can be studied for its implications and
limitations. Usually this formulation is computational-
ly inefficient if implemented straightforwardly, but it
can be reformulated so that it becomes an efficient
program when interpreted by a theorem prover. In
this form the logic program is closer to the theory than
a PASCAL or LISP program would be, making it easi-
er to verify its correctness and also easier to under-
stand directly.
Logic programming has been applied mostly to
formal software specifications, data base systems and
problem solving, but it is being applied increasingly to
natural language understanding systems [1,2,4,5,6]. In
these systems axioms specify the relationship between
the input text and whatever representation it is to be
parsed into, and between this and whatever the output
is to be (e.g., an updated database or the answer to a
question). Since these axioms specify the relation
between the text and its representation, they form a
grammar for the text language, and, as such, are com-
parable to the rules in a linguist&apos;s grammar. When
interpreted by a suitable theorem prover, such as a
version of PROLOG, they can transform a text into its
representation (and often a representation into a text)
with practical efficiency.
With logic programming the computational linguist
may be able to develop theories of language that are
both conceptually well-organized and practical to com-
pute, but this book includes only the most elementary
introduction to natural language processing. It uses
parsing as an example to show that problems can be
solved in ways that correspond to top-down parsing,
bottom-up parsing, or an arbitrary mixture of the two,
all depending on how the theorem prover decides to
American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981 45
Book Reviews Logic for Problem Solving
apply the axioms. But Kowalski&apos;s examples do not
show how to build up a representation structure for a
sentence; to learn how to do that it is necessary to
consult the natural language papers cited above.
This book is organized into three parts. The first
part introduces logic syntax and semantics. The nota-
tion is the clausal form of logic, in which all axioms
look like implications. This form allows the elimina-
tion of &apos;not&apos; as an explicit logical operator, which
makes the form psychologically easier to understand; it
is in fact a disguised form of the clauses used in reso-
lution theorem proving. This introduction to logic
includes a discussion about clauses and semantic net-
works. Clauses can be embedded in networks if the
arcs corresponding to the atomic formulas are grouped
together in a set, and the arcs are further grouped
according to their roles. By restricting all atomic for-
mulas to be binary relations, clauses become a linear
representation of a simple network structure. This
embedding of clauses is thus a practical way to build
logical inference into semantic network-based knowl-
edge systems. (cf. [3].)
The second part of the book explores various infer-
ence procedures and heuristics for logic programming
and applications of logic programming to problem
solving. Most of the procedures are seen to be appli-
cations to the clausal formalism of well-known heuris-
tics and search procedures, such as pre-processing the
problem-independent parts of the computation, using
evaluation functions, indicating when an axiom is to be
applied in a forward manner and when in a backward
manner, choosing the path that branches the least, etc.
This part of the book is thus an introduction to the
heuristic search methods often covered in introductory
courses on artificial intelligence. Most of this section
limits the clauses to those having only one conclusion;
these are called Horn clauses and have direct interpre-
tations as programs and as rules for problem reduc-
tion. Several chapters discuss the problems and tech-
niques for processing axioms in full clausal form, how-
ever, which shows that this book presents logic pro-
gramming as a concept that is independent of any
particular PROLOG implementation.
The last part of the book introduces more advanced
topics. These include extensions of logic programming
to the standard form of logic, addition and deletion of
redundant goals, traps to prevent useless looping, al-
lowing the provability of some formulas to depend on
the unprovability of others, and the combining of ob-
ject language with meta-language. The final chapter
axiomatizes the four ways that an information system
or belief system might change when a new fact is add-
ed to it. Only the top level axioms are given, howev-
er; many of the relations named in the axioms need to
be further defined before there is a full theory of ra-
tional belief maintenance.
This book is intended to be a textbook that intro-
duces the undergraduate to logic, problem solving and
computer programming. Except for one chapter that
compares Horn clauses to conventional programming
languages, it assumes the student has no background
in any of these areas. It covers many topics, but cov-
ers most of them briefly, so that one has to look up
some of the many references if one wants more than
an elementary treatment.
Daniel Chester, University of Delaware
</bodyText>
<sectionHeader confidence="0.996015" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.999959789473684">
[1] Colmerauer, A. Metamorphosis Grammars. in L. Bolc, ed.,
Natural Language Communication with Computers, Springer-
Verlag, Berlin, 1978, 133-189.
[2] Dahl, Veronica. Quantification in a Three-valued Logic for
Natural Language Question-answering Systems. Proceedings of
the Sixth International Joint Conference on Artificial Intelligence,
Tokyo, August 1979, 182-187.
[3] Deliyanni, Amaryllis, and Kowalski, Robert A. Logic and
Semantic Networks. Comm. ACM 22, 3, (March 1979), 184-
192.
[4] LeVine, Sharon H. Questioning English Text with Clausal
Logic. M.A. Thesis, University of Texas at Austin, December
1980.
[5] Pereira, F.C.N., and Warren, D.H.D. Definite Clause Gram-
mars for Language Analysis - A Survey of the Formalism and a
Comparison with Augmented Transition Networks. Artificial
Intelligence 13, 3, (May 1980), 231-278.
[6] Silva, Georgette, and Dwiggins, Don. Toward a PROLOG Text
Grammar. ACM Sigart Newsletter 73, (October 1980), 20-25.
</reference>
<page confidence="0.968701">
46 American Journal of Computational Linguistics, Volume 7, Number 1, January-March 1981
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.123978">
<title confidence="0.987271">Technical Correspondence On the Utility of Computing Inferences in Data Base Query Systems</title>
<abstract confidence="0.996186071428571">these implementations were significantly more efficient, but checked a somewhat narrower class of presumptions than CO-OP. 6. Damerau mentions that queries with non-empty responses can also make presumptions. This is certainly true, even in more subtle ways than noted. (For example, &amp;quot;What is the youngest assistant professors salary?&amp;quot; presumes that there is more than one assistant professor.) Issues such as these are indeed currently under investigation. Overall, we are pleased to see that Damerau has raised some very important issues and we hope that this exchange will be helpful to the natural language processing community.</abstract>
<author confidence="0.99756">Aravind K Joshi</author>
<affiliation confidence="0.999909">Dept. of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.99978">Philadelphia, Pennsylvania 19104</address>
<author confidence="0.998912">S Jerrold Kaplan</author>
<affiliation confidence="0.9998955">Computer Science Department Stanford University</affiliation>
<address confidence="0.999698">Stanford, California 94305</address>
<abstract confidence="0.960258875">Reply to Joshi and Kaplan In general, there is little to disagree with in Joshi and Kaplan&apos;s comments, but perhaps a couple of points could be clarified. As Joshi and Kaplan suspected (point 3), the users of this system did indeed thoroughly understand the data base. This makes quite a difference in thinking about the relative importance of facilities in a natural language query system. In particular, such users tend to check strange answers, so that a reply of &amp;quot;no&amp;quot;, as in their point 4, would probably result in an additional question of &amp;quot;How many parcels ... &amp;quot;. With regard to their remarks on implementations that incur no additional cost (points 2 and 5), I would be interested in seeing how presupposition analysis can be done without extra data base retrievals. It would seem that the system would either have to make special retrievals at marked times, as in CO-OP, or would have to make the relevant retrievals for every question so as to have the results available when needed. However, even if the execution time increase were to be zero, we still have a great many other things which we would like to add to our system before we add inference checking.</abstract>
<author confidence="0.996787">Fred J Damerau</author>
<title confidence="0.89879">Book Reviews Logic For Problem Solving</title>
<author confidence="0.999933">Robert Kowalski</author>
<affiliation confidence="0.372555">Elsevier North Holland, New York, 1979,</affiliation>
<address confidence="0.845034">287 pp., Paperback, $9.95, ISBN 0-444-00365-7.</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Colmerauer</author>
</authors>
<title>Metamorphosis Grammars.</title>
<date>1978</date>
<booktitle>Natural Language Communication with Computers,</booktitle>
<pages>133--189</pages>
<editor>in L. Bolc, ed.,</editor>
<publisher>SpringerVerlag,</publisher>
<location>Berlin,</location>
<contexts>
<context position="3171" citStr="[1,2,4,5,6]" startWordPosition="512" endWordPosition="512">s implications and limitations. Usually this formulation is computationally inefficient if implemented straightforwardly, but it can be reformulated so that it becomes an efficient program when interpreted by a theorem prover. In this form the logic program is closer to the theory than a PASCAL or LISP program would be, making it easier to verify its correctness and also easier to understand directly. Logic programming has been applied mostly to formal software specifications, data base systems and problem solving, but it is being applied increasingly to natural language understanding systems [1,2,4,5,6]. In these systems axioms specify the relationship between the input text and whatever representation it is to be parsed into, and between this and whatever the output is to be (e.g., an updated database or the answer to a question). Since these axioms specify the relation between the text and its representation, they form a grammar for the text language, and, as such, are comparable to the rules in a linguist&apos;s grammar. When interpreted by a suitable theorem prover, such as a version of PROLOG, they can transform a text into its representation (and often a representation into a text) with pra</context>
</contexts>
<marker>[1]</marker>
<rawString>Colmerauer, A. Metamorphosis Grammars. in L. Bolc, ed., Natural Language Communication with Computers, SpringerVerlag, Berlin, 1978, 133-189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Veronica Dahl</author>
</authors>
<title>Quantification in a Three-valued Logic for Natural Language Question-answering Systems.</title>
<date>1979</date>
<booktitle>Proceedings of the Sixth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>182--187</pages>
<location>Tokyo,</location>
<contexts>
<context position="3171" citStr="[1,2,4,5,6]" startWordPosition="512" endWordPosition="512">s implications and limitations. Usually this formulation is computationally inefficient if implemented straightforwardly, but it can be reformulated so that it becomes an efficient program when interpreted by a theorem prover. In this form the logic program is closer to the theory than a PASCAL or LISP program would be, making it easier to verify its correctness and also easier to understand directly. Logic programming has been applied mostly to formal software specifications, data base systems and problem solving, but it is being applied increasingly to natural language understanding systems [1,2,4,5,6]. In these systems axioms specify the relationship between the input text and whatever representation it is to be parsed into, and between this and whatever the output is to be (e.g., an updated database or the answer to a question). Since these axioms specify the relation between the text and its representation, they form a grammar for the text language, and, as such, are comparable to the rules in a linguist&apos;s grammar. When interpreted by a suitable theorem prover, such as a version of PROLOG, they can transform a text into its representation (and often a representation into a text) with pra</context>
</contexts>
<marker>[2]</marker>
<rawString>Dahl, Veronica. Quantification in a Three-valued Logic for Natural Language Question-answering Systems. Proceedings of the Sixth International Joint Conference on Artificial Intelligence, Tokyo, August 1979, 182-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amaryllis Deliyanni</author>
<author>Robert A Kowalski</author>
</authors>
<title>Logic and Semantic Networks.</title>
<date>1979</date>
<journal>Comm. ACM</journal>
<volume>22</volume>
<pages>184--192</pages>
<contexts>
<context position="5515" citStr="[3]" startWordPosition="897" endWordPosition="897">t is in fact a disguised form of the clauses used in resolution theorem proving. This introduction to logic includes a discussion about clauses and semantic networks. Clauses can be embedded in networks if the arcs corresponding to the atomic formulas are grouped together in a set, and the arcs are further grouped according to their roles. By restricting all atomic formulas to be binary relations, clauses become a linear representation of a simple network structure. This embedding of clauses is thus a practical way to build logical inference into semantic network-based knowledge systems. (cf. [3].) The second part of the book explores various inference procedures and heuristics for logic programming and applications of logic programming to problem solving. Most of the procedures are seen to be applications to the clausal formalism of well-known heuristics and search procedures, such as pre-processing the problem-independent parts of the computation, using evaluation functions, indicating when an axiom is to be applied in a forward manner and when in a backward manner, choosing the path that branches the least, etc. This part of the book is thus an introduction to the heuristic search </context>
</contexts>
<marker>[3]</marker>
<rawString>Deliyanni, Amaryllis, and Kowalski, Robert A. Logic and Semantic Networks. Comm. ACM 22, 3, (March 1979), 184-192.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon H LeVine</author>
</authors>
<title>Questioning English Text with Clausal Logic.</title>
<date>1980</date>
<tech>M.A. Thesis,</tech>
<institution>University of Texas at Austin,</institution>
<contexts>
<context position="3171" citStr="[1,2,4,5,6]" startWordPosition="512" endWordPosition="512">s implications and limitations. Usually this formulation is computationally inefficient if implemented straightforwardly, but it can be reformulated so that it becomes an efficient program when interpreted by a theorem prover. In this form the logic program is closer to the theory than a PASCAL or LISP program would be, making it easier to verify its correctness and also easier to understand directly. Logic programming has been applied mostly to formal software specifications, data base systems and problem solving, but it is being applied increasingly to natural language understanding systems [1,2,4,5,6]. In these systems axioms specify the relationship between the input text and whatever representation it is to be parsed into, and between this and whatever the output is to be (e.g., an updated database or the answer to a question). Since these axioms specify the relation between the text and its representation, they form a grammar for the text language, and, as such, are comparable to the rules in a linguist&apos;s grammar. When interpreted by a suitable theorem prover, such as a version of PROLOG, they can transform a text into its representation (and often a representation into a text) with pra</context>
</contexts>
<marker>[4]</marker>
<rawString>LeVine, Sharon H. Questioning English Text with Clausal Logic. M.A. Thesis, University of Texas at Austin, December 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C N Pereira</author>
<author>D H D Warren</author>
</authors>
<title>Definite Clause Grammars for Language Analysis - A Survey of the Formalism and a Comparison with Augmented Transition Networks.</title>
<date>1980</date>
<journal>Artificial Intelligence</journal>
<volume>13</volume>
<pages>231--278</pages>
<contexts>
<context position="3171" citStr="[1,2,4,5,6]" startWordPosition="512" endWordPosition="512">s implications and limitations. Usually this formulation is computationally inefficient if implemented straightforwardly, but it can be reformulated so that it becomes an efficient program when interpreted by a theorem prover. In this form the logic program is closer to the theory than a PASCAL or LISP program would be, making it easier to verify its correctness and also easier to understand directly. Logic programming has been applied mostly to formal software specifications, data base systems and problem solving, but it is being applied increasingly to natural language understanding systems [1,2,4,5,6]. In these systems axioms specify the relationship between the input text and whatever representation it is to be parsed into, and between this and whatever the output is to be (e.g., an updated database or the answer to a question). Since these axioms specify the relation between the text and its representation, they form a grammar for the text language, and, as such, are comparable to the rules in a linguist&apos;s grammar. When interpreted by a suitable theorem prover, such as a version of PROLOG, they can transform a text into its representation (and often a representation into a text) with pra</context>
</contexts>
<marker>[5]</marker>
<rawString>Pereira, F.C.N., and Warren, D.H.D. Definite Clause Grammars for Language Analysis - A Survey of the Formalism and a Comparison with Augmented Transition Networks. Artificial Intelligence 13, 3, (May 1980), 231-278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgette Silva</author>
<author>Don Dwiggins</author>
</authors>
<title>Toward a PROLOG Text Grammar.</title>
<date>1980</date>
<journal>ACM Sigart Newsletter</journal>
<volume>73</volume>
<contexts>
<context position="3171" citStr="[1,2,4,5,6]" startWordPosition="512" endWordPosition="512">s implications and limitations. Usually this formulation is computationally inefficient if implemented straightforwardly, but it can be reformulated so that it becomes an efficient program when interpreted by a theorem prover. In this form the logic program is closer to the theory than a PASCAL or LISP program would be, making it easier to verify its correctness and also easier to understand directly. Logic programming has been applied mostly to formal software specifications, data base systems and problem solving, but it is being applied increasingly to natural language understanding systems [1,2,4,5,6]. In these systems axioms specify the relationship between the input text and whatever representation it is to be parsed into, and between this and whatever the output is to be (e.g., an updated database or the answer to a question). Since these axioms specify the relation between the text and its representation, they form a grammar for the text language, and, as such, are comparable to the rules in a linguist&apos;s grammar. When interpreted by a suitable theorem prover, such as a version of PROLOG, they can transform a text into its representation (and often a representation into a text) with pra</context>
</contexts>
<marker>[6]</marker>
<rawString>Silva, Georgette, and Dwiggins, Don. Toward a PROLOG Text Grammar. ACM Sigart Newsletter 73, (October 1980), 20-25.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>