<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9983085">
Optimal Head-Driven Parsing Complexity
for Linear Context-Free Rewriting Systems
</title>
<author confidence="0.604295">
Pierluigi Crescenzi Daniel Gildea Andrea Marino
</author>
<affiliation confidence="0.4213395">
Dip. di Sistemi e Informatica Computer Science Dept. Dip. di Sistemi e Informatica
Universit`a di Firenze University of Rochester Universit`a di Firenze
</affiliation>
<author confidence="0.679947">
Gianluca Rossi
</author>
<affiliation confidence="0.396123">
Dip. di Matematica
Universit`a di Roma Tor Vergata
</affiliation>
<sectionHeader confidence="0.961791" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999938222222222">
We study the problem of finding the best head-
driven parsing strategy for Linear Context-
Free Rewriting System productions. A head-
driven strategy must begin with a specified
righthand-side nonterminal (the head) and add
the remaining nonterminals one at a time in
any order. We show that it is NP-hard to find
the best head-driven strategy in terms of either
the time or space complexity of parsing.
</bodyText>
<sectionHeader confidence="0.997802" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9861021">
Linear Context-Free Rewriting Systems (LCFRSs)
(Vijay-Shankar et al., 1987) constitute a very general
grammatical formalism which subsumes context-
free grammars (CFGs) and tree adjoining grammars
(TAGs), as well as the synchronous context-free
grammars (SCFGs) and synchronous tree adjoin-
ing grammars (STAGs) used as models in machine
translation.1 LCFRSs retain the fundamental prop-
erty of CFGs that grammar nonterminals rewrite
independently, but allow nonterminals to generate
discontinuous phrases, that is, to generate more
than one span in the string being produced. This
important feature has been recently exploited by
Maier and Søgaard (2008) and Kallmeyer and Maier
(2010) for modeling phrase structure treebanks with
discontinuous constituents, and by Kuhlmann and
Satta (2009) for modeling non-projective depen-
dency treebanks.
The rules of a LCFRS can be analyzed in terms
of the properties of rank and fan-out. Rank is the
</bodyText>
<footnote confidence="0.98263875">
1To be more precise, SCFGs and STAGs generate languages
composed by pair of strings, while LCFRSs generate string lan-
guages. We can abstract away from this difference by assuming
concatenation of components in a string pair.
</footnote>
<subsectionHeader confidence="0.365505">
Giorgio Satta
</subsectionHeader>
<bodyText confidence="0.981615842105263">
Dip. di Ingegneria dell’Informazione
Universit`a di Padova
number of nonterminals on the right-hand side (rhs)
of a rule, while fan-out is the number of spans of
the string generated by the nonterminal in the left-
hand side (lhs) of the rule. CFGs are equivalent to
LCFRSs with fan-out one, while TAGs are one type
of LCFRSs with fan-out two. Rambow and Satta
(1999) show that rank and fan-out induce an infi-
nite, two-dimensional hierarchy in terms of gener-
ative power; while CFGs can always be reduced to
rank two (Chomsky Normal Form), this is not the
case for LCFRSs with any fan-out greater than one.
General algorithms for parsing LCFRSs build a
dynamic programming chart of recognized nonter-
minals bottom-up, in a manner analogous to the
CKY algorithm for CFGs (Hopcroft and Ullman,
1979), but with time and space complexity that are
dependent on the rank and fan-out of the gram-
mar rules. Whenever it is possible, binarization of
LCFRS rules, or reduction of rank to two, is there-
fore important for parsing, as it reduces the time
complexity needed for dynamic programming. This
has lead to a number of binarization algorithms for
LCFRSs, as well as factorization algorithms that
factor rules into new rules with smaller rank, with-
out necessarily reducing rank all the way to two.
Kuhlmann and Satta (2009) present an algorithm
for binarizing certain LCFRS rules without increas-
ing their fan-out, and Sagot and Satta (2010) show
how to reduce rank to the lowest value possible for
LCFRS rules of fan-out two, again without increas-
ing fan-out. G´omez-Rodriguez et al. (2010) show
how to factorize well-nested LCFRS rules of arbi-
trary fan-out for efficient parsing.
In general there may be a trade-off required
between rank and fan-out, and a few recent pa-
pers have investigated this trade-off taking gen-
</bodyText>
<page confidence="0.969668">
450
</page>
<note confidence="0.9794655">
Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics, pages 450–459,
Portland, Oregon, June 19-24, 2011. c�2011 Association for Computational Linguistics
</note>
<bodyText confidence="0.997389354430379">
eral LCFRS rules as input. G´omez-Rodriguez et
al. (2009) present an algorithm for binarization of
LCFRSs while keeping fan-out as small as possi-
ble. The algorithm is exponential in the resulting
fan-out, and G´omez-Rodriguez et al. (2009) mention
as an important open question whether polynomial-
time algorithms to minimize fan-out are possible.
Gildea (2010) presents a related method for bina-
rizing rules while keeping the time complexity of
parsing as small as possible. Binarization turns out
to be possible with no penalty in time complexity,
but, again, the factorization algorithm is exponen-
tial in the resulting time complexity. Gildea (2011)
shows that a polynomial time algorithm for factor-
izing LCFRSs in order to minimize time complexity
would imply an improved approximation algorithm
for the well-studied graph-theoretic property known
as treewidth. However, whether the problem of fac-
torizing LCFRSs in order to minimize time com-
plexity is NP-hard is still an open question in the
above works.
Similar questions have arisen in the context of
machine translation, as the SCFGs used to model
translation are also instances of LCFRSs, as already
mentioned. For SCFG, Satta and Peserico (2005)
showed that the exponent in the time complexity
of parsing algorithms must grow at least as fast as
the square root of the rule rank, and Gildea and
ˇStefankoviˇc (2007) tightened this bound to be lin-
ear in the rank. However, neither paper provides an
algorithm for finding the best parsing strategy, and
Huang et al. (2009) mention that whether finding the
optimal parsing strategy for an SCFG rule is NP-
hard is an important problem for future work.
In this paper, we investigate the problem of rule
binarization for LCFRSs in the context of head-
driven parsing strategies. Head-driven strategies be-
gin with one rhs symbol, and add one nontermi-
nal at a time. This rules out any factorization in
which two subsets of nonterminals of size greater
than one are combined in a single step. Head-driven
strategies allow for the techniques of lexicalization
and Markovization that are widely used in (projec-
tive) statistical parsing (Collins, 1997). The statis-
tical LCFRS parser of Kallmeyer and Maier (2010)
binarizes rules head-outward, and therefore adopts
what we refer to as a head-driven strategy. How-
ever, the binarization used by Kallmeyer and Maier
(2010) simply proceeds left to right through the rule,
without considering the impact of the parsing strat-
egy on either time or space complexity. We examine
the question of whether we can efficiently find the
strategy that minimizes either the time complexity
or the space complexity of parsing. While a naive
algorithm can evaluate all r! head-driven strategies
in time O(n · r!), where r is the rule’s rank and n
is the total length of the rule’s description, we wish
to determine whether a polynomial-time algorithm
is possible.
Since parsing problems can be cast in terms of
logic programming (Shieber et al., 1995), we note
that our problem can be thought of as a type of
query optimization for logic programming. Query
optimization for logic programming is NP-complete
since query optimization for even simple conjunc-
tive database queries is NP-complete (Chandra and
Merlin, 1977). However, the fact that variables in
queries arising from LCFRS rules correspond to the
endpoints of spans in the string to be parsed means
that these queries have certain structural properties
(Gildea, 2011). We wish to determine whether the
structure of LCFRS rules makes efficient factoriza-
tion algorithms possible.
In the following, we show both the the time- and
space-complexity problems to be NP-hard for head-
driven strategies. We provide what is to our knowl-
edge the first NP-hardness result for a grammar fac-
torization problem, which we hope will aid in under-
standing parsing algorithms in general.
</bodyText>
<sectionHeader confidence="0.506593" genericHeader="introduction">
2 LCFRSs and parsing complexity
</sectionHeader>
<bodyText confidence="0.996372428571428">
In this section we briefly introduce LCFRSs and de-
fine the problem of optimizing head-driven parsing
complexity for these formalisms. For a positive in-
teger n, we write [n] to denote the set {1,. . . , n}.
As already mentioned in the introduction,
LCFRSs generate tuples of strings over some finite
alphabet. This is done by associating each produc-
tion p of a grammar with a function g that takes as
input the tuples generated by the nonterminals in p’s
rhs, and rearranges their string components into a
new tuple, possibly adding some alphabet symbols.
Let V be some finite alphabet. We write V ∗ for
the set of all (finite) strings over V . For natural num-
bers r &gt; 0 and f, fl, ... , fr &gt; 1, consider a func-
</bodyText>
<page confidence="0.997564">
451
</page>
<bodyText confidence="0.990765961538462">
tiong : (V ∗)f1 × · · · × (V ∗)fr → (V ∗)f defined by
an equation of the form
g(hx1,1,...,x1,f1i, ... , hxr,1, ..., xr,fri) = α~.
Here the xz,�’s denote variables over strings in V ∗,
and α~ = hα1, ... , αfi is an f-tuple of strings over
g’s argument variables and symbols in V . We say
that g is linear, non-erasing if α~ contains exactly
one occurrence of each argument variable. We call r
and f the rank and the fan-out of g, respectively,
and write r(g) and f(g) to denote these quantities.
Example 1 g1(hx1,1, x1,2i) = hx1,1x1,2i takes as
input a tuple with two strings and returns a tuple
with a single string, obtained by concatenating the
components in the input tuple. g2(hx1,1, x1,2i) =
hax1,1b, cx1,2di takes as input a tuple with two
strings and wraps around these strings with sym-
bols a, b, c, d ∈ V . Both functions are linear, non-
erasing, and we have r(g1) = r(g2) = 1, f(g1) = 1
and f(g2) = 2. �
A linear context-free rewriting system is a tuple
G = (VN, VT, P, S), where VN and VT are finite,
disjoint alphabets of nonterminal and terminal sym-
bols, respectively. Each A ∈ VN is associated with
a value f(A), called its fan-out. The nonterminal S
is the start symbol, with f(S) = 1. Finally, P is a
set of productions of the form
</bodyText>
<equation confidence="0.850561">
p : A → g(A1,A2, ... ,Ar(g)) , (1)
</equation>
<bodyText confidence="0.999213117647059">
where A, A1, ... , Ar(g) ∈ VN, and g : (VT∗)f(A1)
× ··· × (VT∗)f(Ar(9)) → (VT∗)f(A) is a linear, non-
erasing function.
Production (1) can be used to transform the
r(g) string tuples generated by the nonterminals
A1, ... , Ar(g) into a tuple of f(A) strings gener-
ated by A. The values r(g) and f(g) are called the
rank and fan-out of p, respectively, written r(p) and
f(p). Given that f(S) = 1, S generates a set of
strings, defining the language L(G).
Example 2 Let g1 and g2 be as in Example 1, and
let g3() = hε, εi. Consider the LCFRS G defined by
the productions p1 : S → g1(A), p2 : A → g2(A)
and p3 : A → g3(). We have f(S) = 1, f(A) =
f(G) = 2, r(p3) = 0 and r(p1) = r(p2) = r(G) =
1. We have L(G) = {anbncndn  |n ≥ 1}. For in-
stance, the string a3b3c3d3 is generated by means
</bodyText>
<figure confidence="0.793335">
fan-out strategy
4 ((A1 ⊕ A4) ⊕ A3)∗ ⊕ A2
3 (A1 ⊕ A4)∗ ⊕ (A2 ⊕ A3)
3 ((A1 ⊕ A2)∗ ⊕ A4) ⊕ A3
2 ((A∗2 ⊕ A3) ⊕ A4) ⊕ A1
</figure>
<figureCaption confidence="0.6202008">
Figure 1: Some parsing strategies for production p in Ex-
ample 3, and the associated maximum value for fan-out.
Symbol ⊕ denotes the merging operation, and superscript
∗ marks the first step in the strategy in which the highest
fan-out is realized.
</figureCaption>
<bodyText confidence="0.992388823529412">
of the following bottom-up process. First, the tuple
hε, εi is generated by A through p3. We then iterate
three times the application of p2 to hε, εi, resulting
in the tuple ha3b3, c3d3i. Finally, the tuple (string)
ha3b3c3d3i is generated by S through application of
p1. ❑
Existing parsing algorithms for LCFRSs exploit
dynamic programming. These algorithms compute
partial parses of the input string w, represented by
means of specialized data structures called items.
Each item indexes the boundaries of the segments
of w that are spanned by the partial parse. In the
special case of parsing based on CFGs, an item con-
sists of two indices, while for TAGs four indices are
required.
In the general case of LCFRSs, parsing of a pro-
duction p as in (1) can be carried out in r(g) − 1
steps, collecting already available parses for nonter-
minals A1, ... , Ar(g) one at a time, and ‘merging’
these into intermediate partial parses. We refer to the
order in which nonterminals are merged as a pars-
ing strategy, or, equivalently, a factorization of the
original grammar rule. Any parsing strategy results
in a complete parse of p, spanning f(p) = f(A)
segments of w and represented by some item with
2f(A) indices. However, intermediate items ob-
tained in the process might span more than f(A)
segments. We illustrate this through an example.
Example 3 Consider a linear non-erasing function
g(hx1,1, x1,2i, hx2,1, x2,2i, hx3,1, x3,2i, hx4,1, x4,2i)
= hx1,1x2,1x3,1x4,1, x3,2x2,2x4,2x1,2i, and a pro-
duction p : A → g(A1, A2, A3, A4), where all the
nonterminals involved have fan-out 2. We could
parse p starting from A1, and then merging with A4,
</bodyText>
<page confidence="0.993459">
452
</page>
<bodyText confidence="0.999191419354839">
A3, and A2. In this case, after we have collected the
first three nonterminals, we have obtained a partial
parse having fan-out 4, that is, an item spanning 4
segments of the input string. Alternatively, we could
first merge A1 and A4, then merge A2 and A3, and
finally merge the two obtained partial parses. This
strategy is slightly better, resulting in a maximum
fan-out of 3. Other possible strategies can be ex-
plored, displayed in Figure 1. It turns out that the
best parsing strategy leads to fan-out 2. ❑
The maximum fan-out f realized by a parsing
strategy determines the space complexity of the
parsing algorithm. For an input string w, items will
require (in the worst-case) 2f indices, each taking
O(|w|) possible values. This results in space com-
plexity of O(|w|2f). In the special cases of parsing
based on CFGs and TAGs, this provides the well-
known space complexity of O(|w|2) and O(|w|4),
respectively.
It can also be shown that, if a partial parse hav-
ing fan-out f is obtained by means of the combi-
nation of two partial parses with fan-out f1 and f2,
respectively, the resulting time complexity will be
O(|w|f+f1+f2) (Seki et al., 1991; Gildea, 2010). As
an example, in the case of parsing based on CFGs,
nonterminals as well as partial parses all have fan-
out one, resulting in the standard time complexity of
O(|w|3) of dynamic programming methods. When
parsing with TAGs, we have to manipulate objects
with fan-out two (in the worst case), resulting in time
complexity of O(|w|6).
We investigate here the case of general LCFRS
productions, whose internal structure is consider-
ably more complex than the context-free or the tree
adjoining case. Optimizing the parsing complexity
for a production means finding a parsing strategy
that results in minimum space or time complexity.
We now turn the above optimization problems
into decision problems. In the MIN SPACE STRAT-
EGY problem one takes as input an LCFRS produc-
tion p and an integer k, and must decide whether
there exists a parsing strategy for p with maximum
fan-out not larger than k. In the MIN TIME STRAT-
EGY problem one is given p and k as above and must
decide whether there exists a parsing strategy for
p such that, in any of its steps merging two partial
parses with fan-out f1 and f2 and resulting in a par-
tial parse with fan-out f, the relation f +f1+f2 &lt; k
holds.
In this paper we investigate the above problems in
the context of a specific family of linguistically mo-
tivated parsing strategies for LCFRSs, called head-
driven. In a head-driven strategy, one always starts
parsing a production p from a fixed nonterminal in
its rhs, called the head of p, and merges the remain-
ing nonterminals one at a time with the partial parse
containing the head. Thus, under these strategies,
the construction of partial parses that do not include
the head is forbidden, and each parsing step involves
at most one partial parse. In Figure 1, all of the dis-
played strategies but the one in the second line are
head-driven (for different choices of the head).
</bodyText>
<sectionHeader confidence="0.997281" genericHeader="method">
3 NP-completeness results
</sectionHeader>
<bodyText confidence="0.999595684210526">
For an LCFRS production p, let H be its head non-
terminal, and let A1, ... , An be all the non-head
nonterminals in p’s rhs, with n + 1 = r(p). A head-
driven parsing strategy can be represented as a per-
mutation π over the set [n], prescribing that the non-
head nonterminals in p’s rhs should be merged with
H in the order Aπ(1), Aπ(2), ... , Aπ(n). Note that
there are n! possible head-driven parsing strategies.
To show that MIN SPACE STRATEGY is NP-
hard under head-driven parsing strategies, we reduce
from the MIN CUT LINEAR ARRANGEMENT prob-
lem, which is a decision problem over (undirected)
graphs. Given a graph M = (V, E) with set of ver-
tices V and set of edges E, a linear arrangement
of M is a bijective function h from V to [n], where
|V  |= n. The cutwidth of M at gap i E [n − 1] and
with respect to a linear arrangement h is the number
of edges crossing the gap between the i-th vertex and
its successor:
</bodyText>
<equation confidence="0.5938555">
cw(M, h, i) = |1(u, v) E E  |h(u) &lt; i &lt; h(v)J |.
e1
v2
v1
e3
e4
v3 v4
e2
</equation>
<figureCaption confidence="0.9451205">
Figure 2: Example input graph for our construction of an
LCFRS production.
</figureCaption>
<page confidence="0.963864">
453
</page>
<equation confidence="0.4841576">
p : A → g(H, A1, A2, A3, A4)
g((xH,e1, xH,e2, xH,e3, xH,e4), (xA1,e1,l, xA1,e1,r, xA1,e3,l, xA1,e3,r), (xA2,e1,l, xA2,e1,r, xA2,e2,l, xA2,e2,r),
(xA3,e2,l, xA3,e2,r, xA3,e3,l, xA3,e3,r, xA3,e4,l, xA3,e4,r), (xA4,e4,l, xA4,e4,r)) =
( xA1,e1,lxA2,e1,lxH,e1xA1,e1,rxA2,e1,r, xA2,e2,lxA3,e2,lxH,e2xA2,e2,rxA3,e2,r,
xA1,e3,lxA3,e3,lxH,e3xA1,e3,rxA3,e3,r, xA3,e4,lxA4,e4,lxH,e4xA3,e4,rxA4,e4,r )
</equation>
<figureCaption confidence="0.993636">
Figure 3: The construction used to prove Theorem 1 builds the LCFRS production p shown, when given as input the
graph of Figure 2.
</figureCaption>
<bodyText confidence="0.745014">
The cutwidth of M is then defined as
</bodyText>
<equation confidence="0.7627625">
cw(M) =min max
h i∈[n−1]
</equation>
<bodyText confidence="0.986679368421053">
In the MIN CUT LINEAR ARRANGEMENT problem,
one is given as input a graph M and an integer k, and
must decide whether cw(M) ≤ k. This problem has
been shown to be NP-complete (Gavril, 1977).
Theorem 1 The MIN SPACE STRATEGY problem
restricted to head-driven parsing strategies is NP-
complete.
PROOF We start with the NP-hardness part. Let
M = (V, E) and k be an input instance for
MIN CUT LINEAR ARRANGEMENT, and let V =
{v1, ... , vn} and E = {e1, ... , eq}. We assume
there are no self loops in M, since these loops do not
affect the value of the cutwidth and can therefore be
removed. We construct an LCFRS production p and
an integer k′ as follows.
Production p has a head nonterminal H and a non-
head nonterminal Ai for each vertex vi E V . We let
H generate tuples with a string component for each
edge ei E E. Thus, we have f(H) = q. Accord-
ingly, we use variables xH,ei, for each ei E E, to
denote the string components in tuples generated by
H.
For each vi E V , let E(vi) ⊆ E be the set of
edges impinging on vi; thus |E(vi) |is the degree
of vi. We let Ai generate a tuple with two string
components for each ej E E(vi). Thus, we have
f(Ai) = 2 · |E(vi)|. Accordingly, we use variables
xAi,ej,l and xAi,ej,r, for each ej E E(vi), to de-
note the string components in tuples generated by
Ai (here subscripts l and r indicate left and right
positions, respectively; see below).
We set r(p) = n + 1 and f(p) = q, and
define p by A → g(H, A1, A2, ... , An), with
g(tH, tA1, ... , tAn) = (α1, ... , αq). Here tH is the
tuple of variables for H and each tAi, i E [n], is the
tuple of variables for Ai. Each string αi, i E [q], is
specified as follows. Let vs and vt be the endpoints
of ei, with vs, vt E V and s &lt; t. We define
</bodyText>
<equation confidence="0.592066">
αi = xAs,ei,lxAt,ei,lxH,eixAs,ei,rxAt,ei,r .
</equation>
<bodyText confidence="0.984873133333333">
Observe that whenever edge ei impinges on vertex
vj, then the left and right strings generated by Aj
and associated with ei wrap around the string gen-
erated by H and associated with the same edge. Fi-
nally, we set k′ = q + k.
Example 4 Given the input graph of Figure 2, our
reduction constructs the LCFRS production shown
in Figure 3. Figure 4 gives a visualization of how the
spans in this production fit together. For each edge
in the graph of Figure 2, we have a group of five
spans in the production: one for the head nontermi-
nal, and two spans for each of the two nonterminals
corresponding to the edge’s endpoints. ❑
Assume now some head-driven parsing strategy
7r for p. For each i E [n], we define Dπi to be the
partial parse obtained after step i in 7r, consisting
of the merge of nonterminals H, Aπ(1), ... , Aπ(i).
Consider some edge ej = (vs, vt). We observe that
for any Dπi that includes or excludes both nontermi-
nals As and At, the αj component in the definition
of p is associated with a single string, and therefore
contributes with a single unit to the fan-out of the
partial parse. On the other hand, if Dπi includes only
one nonterminal between As and At, the αj compo-
nent is associated with two strings and contributes
with two units to the fan-out of the partial parse.
We can associate with 7r a linear arrangement hπ
of M by letting hπ(vπ(i)) = i, for each vi E V .
From the above observation on the fan-out of Dπi ,
cw(M, h, i) .
</bodyText>
<page confidence="0.997806">
454
</page>
<figure confidence="0.991794833333334">
XA1,e1,lXA2,e1,l XH,e1 XA1,e1,rXA2,e1,r XA2,e2,lXA3,e2,l XH,e2 XA2,e2,rXA3,e2,r XA1,e3,lXA3,e3,l XH,e3 XA1,e3,rXA3,e3,r XA3,e4,lXA4,e4,l XH,e4 XA3,e4,rXA4,e4,r
H
A1
A2
A3
A4
</figure>
<figureCaption confidence="0.9968355">
Figure 4: A visualization of how the spans for each nonterminal fit together in the left-to-right order defined by the
production of Figure 3.
</figureCaption>
<bodyText confidence="0.987956633333333">
we have the following relation, for every i E [n−1]:
f(DZ ) = q + cw(M, h, i) .
We can then conclude that M, k is a positive instance
of MIN CUT LINEAR ARRANGEMENT if and only
if p, k′ is a positive instance of MIN SPACE STRAT-
EGY. This proves that MIN SPACE STRATEGY is
NP-hard.
To show that MIN SPACE STRATEGY is in NP,
consider a nondeterministic algorithm that, given an
LCFRS production p and an integer k, guesses a
parsing strategy π for p, and tests whether f(DZ ) &lt;
k for each i E [n]. The algorithm accepts or rejects
accordingly. Such an algorithm can clearly be im-
plemented to run in polynomial time. 0
We now turn to the MIN TIME STRATEGY prob-
lem, restricted to head-driven parsing strategies. Re-
call that we are now concerned with the quantity
f1 + f2 + f, where f1 is the fan-out of some partial
parse D, f2 is the fan-out of a nonterminal A, and f
is the fan out of the partial parse resulting from the
merge of the two previous analyses.
We need to introduce the MODIFIED CUTWIDTH
problem, which is a variant of the MIN CUT LIN-
EAR ARRANGEMENT problem. Let M = (V, E) be
some graph with |V  |= n, and let h be a linear ar-
rangement for M. The modified cutwidth of M at
position i E [n] and with respect to h is the number
of edges crossing over the i-th vertex:
mcw(M, h, i) = |{(u, v) E E  |h(u) &lt; i &lt; h(v)} |.
The modified cutwidth of M is defined as
</bodyText>
<equation confidence="0.9257485">
mcw(M) = min max
h iE[n]
</equation>
<bodyText confidence="0.999112809523809">
In the MODIFIED CUTWIDTH problem one is given
as input a graph M and an integer k, and must
decide whether mcw(M) &lt; k. The MODIFIED
CUTWIDTH problem has been shown to be NP-
complete by Lengauer (1981). We strengthen this
result below; recall that a cubic graph is a graph
without self loops where each vertex has degree
three.
Lemma 1 The MODIFIED CUTWIDTH problem re-
stricted to cubic graphs is NP-complete.
PROOF The MODIFIED CUTWIDTH problem has
been shown to be NP-complete when restricted to
graphs of maximum degree three by Makedon et al.
(1985), reducing from a graph problem known as
bisection width (see also Monien and Sudborough
(1988)). Specifically, the authors construct a graph
G′ of maximum degree three and an integer k′ from
an input graph G = (V, E) with an even number n
of vertices and an integer k, such that mcw(G′) &lt; k′
if and only if the bisection width bw(G) of G is not
greater than k, where
</bodyText>
<equation confidence="0.8960775">
bw(G) = min |{(u,v) E E |u E A n v E B}|
A,BCV
</equation>
<bodyText confidence="0.945251">
withAnB=O,AUB= V , and |A |= |B|.
The graph G′ has vertices of degree two and three
only, and it is based on a grid-like gadget R(r, c); see
Figure 5. For each vertex of G, G′ includes a com-
ponent R(2n4, 8n4+8). Moreover, G′ has a compo-
nent called an H-shaped graph, containing left and
right columns R(3n4,12n4 + 12) connected by a
middle bar R(2n4,12n4 + 9); see Figure 6. From
each of the n vertex components there is a sheaf of
2n2 edges connecting distinct degree 2 vertices in
the component to 2n2 distinct degree 2 vertices in
mcw(M, h, i) .
</bodyText>
<page confidence="0.988612">
455
</page>
<figure confidence="0.9662039">
x2
x
x3
x4
x3
x5
x5
x4
x x1
x x1 x2
</figure>
<figureCaption confidence="0.9995505">
Figure 5: The R(5,10) component (left), the modification of its degree 2 vertex x (middle), and the corresponding
arrangement (right).
</figureCaption>
<bodyText confidence="0.9998698125">
the middle bar of the H-shaped graph. Finally, for
each edge (vi, vj) of G there is an edge in G′ con-
necting a degree 2 vertex in the component corre-
sponding to the vertex vi with a degree 2 vertex in
the component corresponding to the vertex vj. The
integer k′ is set to 3n4 + n3 + k − 1.
Makedon et al. (1985) show that the modified
cutwidth of R(r, c) is r − 1 whenever r &gt; 3 and
c &gt; 4r + 8. They also show that an optimal lin-
ear arrangement for G′ has the form depicted in Fig-
ure 6, where half of the vertex components are to
the left of the H-shaped graph and all the other ver-
tex components are to the right. In this arrangement,
the modified cutwidth is attested by the number of
edges crossing over the vertices in the left and right
columns of the H-shaped graph, which is equal to
</bodyText>
<equation confidence="0.758896">
3n4 − 1 + n 2n2 + γ = 3n4 + n3 + γ − 1 (2)
2
</equation>
<bodyText confidence="0.991329863636364">
where γ denotes the number of edges connecting
vertices to the left with vertices to the right of the
H-shaped graph. Thus, bw(G) &lt; k if and only if
mcw(G′) &lt; k′.
All we need to show now is how to modify the
components of G′ in order to make it cubic.
Modifying the vertex components All vertices
x of degree 2 of the components corresponding to
a vertex in G can be transformed into a vertex of
degree 3 by adding five vertices x1,... , x5 con-
nected as shown in the middle bar of Figure 5. Ob-
serve that these five vertices can be positioned in
the arrangement immediately after x in the order
x1, x2, x5, x3, x4 (see the right part of the figure).
The resulting maximum modified cutwidth can in-
crease by 2 in correspondence of vertex x5. Since
the vertices of these components, in the optimal
arrangement, have modified cutwidth smaller than
2n4 + n3 + n2, an increase by 2 is still smaller than
the maximum modified cutwidth of the entire graph,
which is 3n4 + O(n3).
Modifying the middle bar of the H-shaped graph
The vertices of degree 2 of this part of the graph can
be modified as in the previous paragraph. Indeed, in
the optimal arrangement, these vertices have mod-
ified cutwidth smaller than 2n4 + 2n3 + n2, and
an increase by 2 is still smaller than the maximum
cutwidth of the entire graph.
Modifying the left/right columns of the H-shaped
graph We replace the two copies of component
R(3n4,12n4 + 12) with two copies of the new
component D(3n4, 24n4 + 16) shown in Figure 7,
which is a cubic graph. In order to prove that rela-
tion (2) still holds, it suffices to show that the modi-
fied cutwidth of the component D(r, c) is still r − 1
whenever r &gt; 3 and c = 8r + 16.
We first observe that the linear arrangement ob-
tained by visiting the vertices of D(r, c) from top to
bottom and from left to right has modified cutwidth
r − 1. Let us now prove that, for any partition of the
vertices into two subsets V1 and V2 with |V1|, |V2 |&gt;
4r2, there exist at least r disjoint paths between ver-
tices of V1 and vertices of V2. To this aim, we dis-
tinguish the following three cases.
</bodyText>
<listItem confidence="0.97987925">
• Any row has (at least) one vertex in V1 and one
vertex in V2: in this case, it is easy to see there
exist at least r disjoint paths between vertices
of V1 and vertices of V2.
• There exist at least 3r ‘mixed’ columns, that is,
columns with (at least) one vertex in V1 and one
vertex in V2. Again, it is easy to see that there
exist at least r disjoint paths between vertices
</listItem>
<page confidence="0.9988">
456
</page>
<figureCaption confidence="0.999933">
Figure 6: The optimal arrangement of G′.
</figureCaption>
<bodyText confidence="0.9695795">
of V1 and vertices of V2 (at least one path every
three columns).
• The previous two cases do not apply. Hence,
there exists a row entirely formed by vertices
of V1 (or, equivalently, of V2). The worst case
is when this row is the smallest one, that is, the
</bodyText>
<equation confidence="0.689892">
one with (c−�−1)
2 + 1 = 4r + 7 vertices. Since
</equation>
<bodyText confidence="0.986007892857143">
at most 3r − 1 columns are mixed, we have
that at most (3r − 1)(r − 2) = 3r2 − 7r +
2 vertices of V2 are on these mixed columns.
Since IV21 &gt; 4r2, this implies that at least r
columns are fully contained in V2. On the other
hand, at least 4r+7−(3r−1) = r+8 columns
are fully contained in V1. If the V1-columns
interleave with the V2-columns, then there exist
at least 2(r −1) disjoint paths between vertices
of V1 and vertices of V2. Otherwise, all the V1-
columns precede or follow all the V2-columns
(this corresponds to the optimal arrangement):
in this case, there are r disjoint paths between
vertices of V1 and vertices of V2.
Observe now that any linear arrangement partitions
the set of vertices in D(r, c) into the sets V1, consist-
ing of the first 4r2 vertices in the arrangement, and
V2, consisting of all the remaining vertices. Since
there are r disjoint paths connecting V1 and V2, there
must be at least r−1 edges passing over every vertex
in the arrangement which is assigned to a position
between the (4r2 + 1)-th and the position 4r2 + 1
from the right end of the arrangement: thus, the
modified cutwidth of any linear arrangement of the
vertices of D(r, c) is at least r − 1.
We can then conclude that the original proof
of Makedon et al. (1985) still applies, according to
relation (2). 0
</bodyText>
<figureCaption confidence="0.999884">
Figure 7: The D(5,10) component.
</figureCaption>
<bodyText confidence="0.999576681818182">
We can now reduce from the MODIFIED
CUTWIDTH problem for cubic graphs to the MIN
TIME STRATEGY problem restricted to head-driven
parsing strategies.
Theorem 2 The MIN TIME STRATEGY problem re-
stricted to head-driven parsing strategies is NP-
complete.
PROOF We consider hardness first. Let M and k
be an input instance of the MODIFIED CUTWIDTH
problem restricted to cubic graphs, where M =
(V, E) and V = {v1, ... , vnJ. We construct an
LCFRS production p exactly as in the proof of The-
orem 1, with rhs nonterminals H, A1, ... , An. We
also set k′ = 2 • k + 2 • JEJ+9.
Assume now some head-driven parsing strategy 7r
for p. After parsing step i E [n], we have a partial
parse Dπi consisting of the merge of nonterminals
H, Aπ(1), ..., Aπ(i). We write tc(p, 7r, i) to denote
the exponent of the time complexity due to step i.
As already mentioned, this quantity is defined as the
sum of the fan-out of the two antecedents involved
in the parsing step and the fan-out of its result:
</bodyText>
<equation confidence="0.919335">
tc(p, 7r, i) = f(Dπi−1) + f(Aπ(i)) + f(Dπi ) .
</equation>
<bodyText confidence="0.99992925">
Again, we associate with 7r a linear arrangement
hπ of M by letting hπ(vπ(i)) = i, for each vi E V .
As in the proof of Theorem 1, the fan-out of Dπi
is then related to the cutwidth of the linear arrange-
</bodyText>
<page confidence="0.994882">
457
</page>
<bodyText confidence="0.973104">
ment hπ of M at position i by
f(Dπi ) = |E |+ cw(M, hπ, i) .
From the proof of Theorem 1, the fan-out of nonter-
minal Aπ(i) is twice the degree of vertex vπ(i), de-
noted by |E(vπ(i))|. We can then rewrite the above
equation in terms of our graph M:
</bodyText>
<equation confidence="0.991424">
tc(p, 7r, i) = 2 · |E |+ cw(M, hπ, i − 1) +
+ 2 · |E(vπ(i)) |+ cw(M, hπ, i) .
</equation>
<bodyText confidence="0.9999635">
The following general relation between cutwidth
and modified cutwidth is rather intuitive:
</bodyText>
<equation confidence="0.975799833333333">
1
mcw(M, hπ, i) = 2 · [cw(M, hπ,i − 1) +
− |E(vπ(i)) |+ cw(M, hπ, i)] .
Combining the two equations above we obtain:
tc(p,7r,i) = 2 · |E |+ 3 · |E(vπ(i)) |+
+ 2 · mcw(M, hπ, i) .
</equation>
<bodyText confidence="0.998654">
Because we are restricting M to the class of cubic
graphs, we can write:
</bodyText>
<equation confidence="0.907433">
tc(p, 7r, i) = 2 · |E |+ 9 + 2 · mcw(M, hπ, i) .
</equation>
<bodyText confidence="0.996460857142857">
We can thus conclude that there exists a head-driven
parsing strategy for p with time complexity not
greater than 2 · |E |+ 9 + 2 · k = k′ if and only
if mcw(M) G k.
The membership of MODIFIED CUTWIDTH in NP
follows from an argument similar to the one in the
proof of Theorem 1. 0
We have established the NP-completeness of both
the MIN SPACE STRATEGY and the MIN TIME
STRATEGY decision problems. It is now easy to see
that the problem of finding a space- or time-optimal
parsing strategy for a LCFRS production is NP-hard
as well, and thus cannot be solved in polynomial (de-
terministic) time unless P = NP.
</bodyText>
<sectionHeader confidence="0.990794" genericHeader="method">
4 Concluding remarks
</sectionHeader>
<bodyText confidence="0.999996093023256">
Head-driven strategies are important in parsing
based on LCFRSs, both in order to allow statistical
modeling of head-modifier dependencies and in or-
der to generalize the Markovization of CFG parsers
to parsers with discontinuous spans. However, there
are n! possible head-driven strategies for an LCFRS
production with a head and n modifiers. Choosing
among these possible strategies affects both the time
and the space complexity of parsing. In this paper
we have shown that optimizing the choice according
to either metric is NP-hard. To our knowledge, our
results are the first NP-hardness results for a gram-
mar factorization problem.
SCFGs and STAGs are specific instances of
LCFRSs. Grammar factorization for synchronous
models is an important component of current ma-
chine translation systems (Zhang et al., 2006), and
algorithms for factorization have been studied by
Gildea et al. (2006) for SCFGs and by Nesson et al.
(2008) for STAGs. These algorithms do not result
in what we refer as head-driven strategies, although,
as machine translation systems improve, lexicalized
rules may become important in this setting as well.
However, the results we have presented in this pa-
per do not carry over to the above mentioned syn-
chronous models, since the fan-out of these models
is bounded by two, while in our reductions in Sec-
tion 3 we freely use unbounded values for this pa-
rameter. Thus the computational complexity of opti-
mizing the choice of the parsing strategy for SCFGs
is still an open problem.
Finally, our results for LCFRSs only apply when
we restrict ourselves to head-driven strategies. This
is in contrast to the findings of Gildea (2011), which
show that, for unrestricted parsing strategies, a poly-
nomial time algorithm for minimizing parsing com-
plexity would imply an improved approximation al-
gorithm for finding the treewidth of general graphs.
Our result is stronger, in that it shows strict NP-
hardness, but also weaker, in that it applies only to
head-driven strategies. Whether NP-hardness can be
shown for unrestricted parsing strategies is an im-
portant question for future work.
</bodyText>
<sectionHeader confidence="0.998854" genericHeader="method">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9872495">
The first and third authors are partially supported
from the Italian PRIN project DISCO. The sec-
ond author is partially supported by NSF grants IIS-
0546554 and IIS-0910611.
</bodyText>
<page confidence="0.997391">
458
</page>
<figureCaption confidence="0.4382212">
References Marco Kuhlmann and Giorgio Satta. 2009. Treebank
Ashok K. Chandra and Philip M. Merlin. 1977. Op- grammar techniques for non-projective dependency
timal implementation of conjunctive queries in rela- parsing. In Proc. 12th Conference of the European
tional databases. In Proc. ninth annual ACM sympo- Chapter of the ACL (EACL-09), pages 478–486.
sium on Theory of computing, STOC ’77, pages 77–90. Thomas Lengauer. 1981. Black-white pebbles and graph
</figureCaption>
<reference confidence="0.98414332">
Michael Collins. 1997. Three generative, lexicalised separation. Acta Informatica, 16:465–475.
models for statistical parsing. In Proc. 35th Annual Wolfgang Maier and Anders Søgaard. 2008. Treebanks
Conference of the Association for Computational Lin- and mild context-sensitivity. In Philippe de Groote,
guistics (ACL-97), pages 16–23. editor, Proc. 13th Conference on Formal Grammar
F. Gavril. 1977. Some NP-complete problems on graphs. (FG-2008), pages 61–76, Hamburg, Germany. CSLI
In Proc. 11th Conf. on Information Sciences and Sys- Publications.
tems, pages 91–95. F. S. Makedon, C. H. Papadimitriou, and I. H. Sudbor-
Daniel Gildea and Daniel ˇStefankoviˇc. 2007. Worst-case ough. 1985. Topological bandwidth. SIAM J. Alg.
synchronous grammar rules. In Proc. 2007 Meeting Disc. Meth., 6(3):418–444.
of the North American chapter of the Association for B. Monien and I.H. Sudborough. 1988. Min cut is NP-
Computational Linguistics (NAACL-07), pages 147– complete for edge weighted trees. Theor. Comput.
154, Rochester, NY. Sci., 58:209–229.
Daniel Gildea, Giorgio Satta, and Hao Zhang. 2006. Rebecca Nesson, Giorgio Satta, and Stuart M. Shieber.
Factoring synchronous grammars by sorting. In 2008. Optimal k-arization of synchronous tree adjoin-
Proc. International Conference on Computational ing grammar. In Proc. 46th Annual Meeting of the
Linguistics/Association for Computational Linguistics Association for Computational Linguistics (ACL-08),
(COLING/ACL-06) Poster Session, pages 279–286. pages 604–612.
Daniel Gildea. 2010. Optimal parsing strategies for Lin- Owen Rambow and Giorgio Satta. 1999. Independent
ear Context-Free Rewriting Systems. In Proc. 2010 parallelism in finite copying parallel rewriting sys-
Meeting of the North American chapter of the Associa- tems. Theor. Comput. Sci., 223(1-2):87–120.
tion for Computational Linguistics (NAACL-10), pages Benoit Sagot and Giorgio Satta. 2010. Optimal rank re-
769–776. duction for linear context-free rewriting systems with
Daniel Gildea. 2011. Grammar factorization by tree de- fan-out two. In Proc. 48th Annual Meeting ofthe Asso-
composition. Computational Linguistics, 37(1):231– ciation for Computational Linguistics, pages 525–533,
248. Uppsala, Sweden.
Carlos G´omez-Rodriguez, Marco Kuhlmann, Giorgio Giorgio Satta and Enoch Peserico. 2005. Some com-
Satta, and David Weir. 2009. Optimal reduction of putational complexity results for synchronous context-
rule length in Linear Context-Free Rewriting Systems. free grammars. In Proceedings of Human Lan-
In Proc. 2009 Meeting of the North American chap- guage Technology Conference and Conference on
ter of the Association for Computational Linguistics Empirical Methods in Natural Language Processing
(NAACL-09), pages 539–547. (HLT/EMNLP), pages 803–810, Vancouver, Canada.
Carlos G´omez-Rodriguez, Marco Kuhlmann, and Gior- H. Seki, T. Matsumura, M. Fujii, and T. Kasami. 1991.
gio Satta. 2010. Efficient parsing of well-nested linear On multiple context-free grammars. Theoretical Com-
context-free rewriting systems. In Proc. 2010 Meeting puter Science, 88:191–229.
of the North American chapter of the Association for Stuart M. Shieber, Yves Schabes, and Fernando C. N.
Computational Linguistics (NAACL-10), pages 276– Pereira. 1995. Principles and implementation of de-
284, Los Angeles, California. ductive parsing. The Journal of Logic Programming,
John E. Hopcroft and Jeffrey D. Ullman. 1979. Intro- 24(1-2):3–36.
duction to Automata Theory, Languages, and Compu- K. Vijay-Shankar, D. L. Weir, and A. K. Joshi. 1987.
tation. Addison-Wesley, Reading, MA. Characterizing structural descriptions produced by
Liang Huang, Hao Zhang, Daniel Gildea, and Kevin various grammatical formalisms. In Proc. 25th An-
Knight. 2009. Binarization of synchronous nual Conference of the Association for Computational
context-free grammars. Computational Linguistics, Linguistics (ACL-87), pages 104–111.
35(4):559–595. Hao Zhang, Liang Huang, Daniel Gildea, and Kevin
Laura Kallmeyer and Wolfgang Maier. 2010. Data- Knight. 2006. Synchronous binarization for machine
driven parsing with probabilistic linear context-free translation. In Proc. 2006 Meeting of the North Ameri-
rewriting systems. In Proc. 23rd International Con- can chapter of the Association for Computational Lin-
ference on Computational Linguistics (Coling 2010), guistics (NAACL-06), pages 256–263.
pages 537–545.
459
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.586499">
<title confidence="0.9999375">Optimal Head-Driven Parsing for Linear Context-Free Rewriting Systems</title>
<author confidence="0.997482">Pierluigi Crescenzi Daniel Gildea Andrea Marino</author>
<affiliation confidence="0.9903435">Dip. di Sistemi e Informatica Computer Science Dept. Dip. di Sistemi e Informatica Universit`a di Firenze University of Rochester Universit`a di Firenze</affiliation>
<author confidence="0.852219">di_Matematica di_Roma Vergata</author>
<abstract confidence="0.9935133">study the problem of finding the best headstrategy for Linear Context- Free Rewriting System productions. A headdriven strategy must begin with a specified righthand-side nonterminal (the head) and add the remaining nonterminals one at a time in any order. We show that it is NP-hard to find the best head-driven strategy in terms of either the time or space complexity of parsing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>