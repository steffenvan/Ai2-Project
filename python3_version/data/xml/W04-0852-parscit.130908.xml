<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.047454">
<affiliation confidence="0.523364333333333">
SENSEVAL-3: Third International Workshop on the Evaluation of Systems
for the Semantic Analysis of Text, Barcelona, Spain, July 2004
Association for Computational Linguistics
</affiliation>
<note confidence="0.973289846153846">
System Task Training Data Description
Prob0 ELS None Most frequent sense baseline — combina-
tion of the two unsupervised modules
Probl ELS Training data provided All 26 modules.
Prob2 ELS Training data provided Trigram modules, surrounding part of
speech modules, head word modules, and
the baseline modules.
Prob3 EAW None Most frequent sense baseline.
Prob4 EAW Semcor &amp; ELS training All 26 modules.
data (excluding verbs)
Prob5 EAW Semcor &amp; ELS training Trigram modules, surrounding part of
data (excluding verbs) speech modules, head word modules, and
the baseline modules.
</note>
<tableCaption confidence="0.998638">
Table 1: System descriptions
</tableCaption>
<bodyText confidence="0.999950428571429">
lustration, we present three frequency distribu-
tions from the pos0 module for the word shirt
(P(pos0 = NN1 Ishirt,), P(pos0 = NN2Ishirt,),
and P(pos0 = VVD Ishirt,)) in Table 2. In this
table, f (sense n pos) denotes the number of oc-
currences of w in the given sense with the given
PoS tag, and f (sense) is the number of occur-
rences of shirt in the given sense.
The probability distributions produced by the
modules need to be smoothed. We use Lid-
stone&apos;s smoothing (e.g., (Manning and Schiitze,
1999)), where the optimum smoothing values
are empirically determined on a development
corpus by an exhaustive search. Using Lid-
stone&apos;s smoothing, we can make the smooth-
ing values word and module specific, and so can
make the probability distributions generated re-
semble uniform distributions if we are not very
confident in the module for a given word.
The probability distributions produced by the
26 modules are combined using Bayes Rule:
</bodyText>
<equation confidence="0.970232">
P(A n B)
P(AIB) =
</equation>
<bodyText confidence="0.999890777777778">
The prior distribution comes from the unsu-
pervised PoS and frequency modules, and this is
augmented using the remaining modules to pro-
duce the best updated estimate in the form of a
posterior distribution. Combining modules us-
ing Bayes Rule is the best combination method
that was tested, and outperforms the natural
combination method based on Dempster—Shafer
theory.
</bodyText>
<sectionHeader confidence="0.999332" genericHeader="abstract">
3 Results
</sectionHeader>
<bodyText confidence="0.999987038461538">
There were three versions of the probabilistic
WSD system submitted to the English lexical
sample (ELS) task (Mihalcea et al., 2004), and
to the English all words (EAW) task (Palmer,
2004). The descriptions of the systems and their
training data can be found in Table 1. For the
English all words task, the system was trained
on SEMCOR 1.6 converted into 1.7.1 using (a
heuristics based) automatic mapping method.
Although the output of our probabilistic sys-
tem is a probability distribution on senses, this
was converted a one sense assignment per in-
stance for evaluation.2 For the English lexical
sample task, the &amp;quot;U&amp;quot; (unassignable) tag was
output whenever our system gave the highest
probability to none of the available senses being
relevant. The system also occasionally entirely
missed annotating words due to combined er-
rors arising from the morphological decomposi-
tion component and the tagger, these were also
given the &amp;quot;U&amp;quot; tag, resulting in 100% coverage.
In the English all words task, the system always
found an available sense. The lower coverage
(97.4%) was due to the errors from the mor-
phological and tagger components. The official
system performances can be found in Table 3.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="keywords">
4 Discussion
</sectionHeader>
<bodyText confidence="0.999851285714286">
Both Prob2 and Prob5 systems were investigat-
ing whether a lower number of modules would
yield better performance; when a large number
of modules are combined, the difference in prob-
abilities of senses can become quite small. How-
ever, the combination chosen3 was only opti-
mal for the English all words tasks. Subsequent
</bodyText>
<footnote confidence="0.9325578">
2Note that outputting the probability distribution on
senses directly would have quite a low maximal possible
precision as no sense is assigned a zero probability.
3This choice of modules was based on a prelimi-
nary investigation with the SENSEVAL-2 English all words
</footnote>
<figure confidence="0.473816">
P(tag = t &apos;sense - s,) no. of occurrences of w in sense s, when the PoS tag of w is t
-
no. of occurrences of w in sense s,
</figure>
<figureCaption confidence="0.999045">
Figure 1: Probability of tag t given the sense is s, in the pos0 module
</figureCaption>
<table confidence="0.999528111111111">
Sense id PoS (t) f (sense n pos) f (sense) P(tis)
shirt%1:06:00:: NN1 8 9 8
9
shirt%2:29:00:: NN1 0 1 0
shirt%1:06:00:: NN2 1 9 1
9
shirt%2:29:00:: NN2 0 1 0
shirt%1:06:00:: VVD 0 9 0
shirt%2:29:00:: VVD 1 1 1
</table>
<tableCaption confidence="0.975463">
Table 2: Part of speech distributions for the word shirt
</tableCaption>
<table confidence="0.999935666666667">
System Precision Recall Coverage Precision Recall Coverage
ELS Coarse-grained Fine-grained
Prob0 63.6% 63.6% 100.0% 54.7% 54.7% 100.0%
Probl 71.6% 71.6% 100.0% 65.1% 65.1% 100.0%
Prob2 69.3% 69.3% 100.0% 61.9% 61.9% 100.0%
EAW With &amp;quot;U&amp;quot; Without &amp;quot;U&amp;quot;
Prob3 55,1% 55.1% 100.0% 57.3% 54.7% 97.4%
Prob4 55.4% 55.4% 100.0% 57.5% 55.0% 97.4%
Prob5 57.2% 57.2% 100.0% 58.5% 56.8% 97.4%
</table>
<tableCaption confidence="0.999942">
Table 3: Results on the EAW and ELS tasks
</tableCaption>
<bodyText confidence="0.999883777777778">
to the evaluation taking place, we ran a search
through the possible module combinations4 re-
sulting in a better performance with a combi-
nation of the most frequent sense modules, the
trigram modules, the window module, and the
root of word 3 to the left, 1 to the right and 2 to
the right. The &apos;without U&apos; performance for the
English all words task with this module combi-
nation is 59.5% precision and 58.0% recall.
</bodyText>
<sectionHeader confidence="0.990421" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999845857142857">
We have presented the results of our probabilis-
tic WSD system on the SENSEVAL-3 English lex-
ical sample and the English all words tasks. In
both cases, our system outperformed the base-
line for the task.5 We have shown that the sys-
tem can be further optimized, but even in its
raw form it performs well.
</bodyText>
<footnote confidence="0.937366">
task.
4This search was run on the English all words task.
5This baseline does not have access to perfect part of
speech, or untagged word information.
</footnote>
<sectionHeader confidence="0.992201" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999768">
I would like to thank my supervisor, Ted
Briscoe, and Joe Hurd for proof reading pre-
vious versions of this paper.
</bodyText>
<sectionHeader confidence="0.996551" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993380083333333">
D. Elworthy. 1994. Does Baum-Welch re-
estimation help taggers? In Proceedings of
the 4th Conference on Applied NLP, pages
53-58.
C. D. Manning and H. Schiitze. 1999. Founda-
tions of Statistical Natural Language Process-
ing. MIT Press.
R. Mihalcea, A. Kilarriff, and T. Chklovski.
2004. English lexical sample task. In Pro-
ceedings of SENSEVAL-3.
R. Mihalcea. 2002. Word sense disambiguation
using pattern learning and automatic feature
selection. Journal of Natural Language and
Engineering, 8(4):343-358.
M. Palmer. 2004. English all words task. In
Proceedings of SENSEVAL-3.
T. Pedersen. 2002. Machine learning with
lexical features: The Duluth approach to
Senseval-2. In J. Preiss and D. Yarowsky, ed-
itors, Proceedings of SENSEVAL-2: Second
International Workshop on Evaluating Word
Sense Disambiguating Systems, pages 139-
142.
J. Preiss. 2004. Probabilistic word sense disam-
biguation. Computer Speech and Language.
Forthcoming.
M. Stevenson and Y. Wilks. 2001. The inter-
action of knowledge sources in word sense
disambiguation. Computational Linguistics,
27(3):321-349.
M. Stevenson. 2003. Word Sense Disambigua-
tion: The Case for Combining Knowledge
Sources. CSLI Publications, Stanford, CA.
D. Yarowsky. 2000. Hierarchical decision lists
for word sense disambiguation. Computers
and the Humanities, 34(1/2):179-186.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000062">
<note confidence="0.901467636363636">SENSEVAL-3: Third International Workshop on the Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain, July 2004 Association for Computational Linguistics System Task Training Data Description Prob0 ELS None Most frequent sense baseline — combina-tion of the two unsupervised modules Probl ELS Training data provided modules. Prob2 ELS Training data provided Trigram modules, surrounding part of speech modules, head word modules, and the baseline modules. Prob3 EAW None Most frequent sense baseline. Prob4 EAW Semcor &amp; ELS training data (excluding verbs) modules. Prob5 EAW Semcor &amp; ELS training data (excluding verbs) Trigram modules, surrounding part of</note>
<abstract confidence="0.996361772151899">speech modules, head word modules, and the baseline modules. Table 1: System descriptions lustration, we present three frequency distribufrom the for the word (P(pos0 = NN1 Ishirt,), P(pos0 = NN2Ishirt,), and P(pos0 = VVD Ishirt,)) in Table 2. In this n pos) denotes the number of occurrences of w in the given sense with the given tag, and is the number of occurof the given sense. The probability distributions produced by the modules need to be smoothed. We use Lidstone&apos;s smoothing (e.g., (Manning and Schiitze, 1999)), where the optimum smoothing values are empirically determined on a development corpus by an exhaustive search. Using Lidstone&apos;s smoothing, we can make the smoothing values word and module specific, and so can make the probability distributions generated resemble uniform distributions if we are not very confident in the module for a given word. The probability distributions produced by the 26 modules are combined using Bayes Rule: P(An P(AIB) = The prior distribution comes from the unsupervised PoS and frequency modules, and this is augmented using the remaining modules to produce the best updated estimate in the form of a posterior distribution. Combining modules using Bayes Rule is the best combination method that was tested, and outperforms the natural combination method based on Dempster—Shafer theory. 3 Results There were three versions of the probabilistic WSD system submitted to the English lexical sample (ELS) task (Mihalcea et al., 2004), and to the English all words (EAW) task (Palmer, 2004). The descriptions of the systems and their training data can be found in Table 1. For the English all words task, the system was trained converted into 1.7.1 using (a heuristics based) automatic mapping method. Although the output of our probabilistic system is a probability distribution on senses, this was converted a one sense assignment per infor For the English lexical sample task, the &amp;quot;U&amp;quot; (unassignable) tag was output whenever our system gave the highest probability to none of the available senses being relevant. The system also occasionally entirely missed annotating words due to combined errors arising from the morphological decomposition component and the tagger, these were also given the &amp;quot;U&amp;quot; tag, resulting in 100% coverage. In the English all words task, the system always found an available sense. The lower coverage (97.4%) was due to the errors from the morphological and tagger components. The official system performances can be found in Table 3. 4 Discussion Both Prob2 and Prob5 systems were investigating whether a lower number of modules would yield better performance; when a large number of modules are combined, the difference in probabilities of senses can become quite small. Howthe combination was only optimal for the English all words tasks. Subsequent that outputting the probability distribution on senses directly would have quite a low maximal possible precision as no sense is assigned a zero probability. choice of modules was based on a prelimiinvestigation with the all words = of occurrences of w in sense the PoS tag of w is of occurrences of w in sense 1: Probability of tag the sense is the Sense id P(tis)</abstract>
<phone confidence="0.582208">shirt%1:06:00:: NN1 8 9 8</phone>
<date confidence="0.359677">9</date>
<phone confidence="0.901618">shirt%2:29:00:: NN1 0 1 0 shirt%1:06:00:: NN2 1 9 1</phone>
<date confidence="0.521951">9</date>
<phone confidence="0.823995666666667">shirt%2:29:00:: NN2 0 1 0 shirt%1:06:00:: VVD 0 9 0 shirt%2:29:00:: VVD 1 1 1</phone>
<title confidence="0.636703">2: Part of speech distributions for the word System Precision Recall Coverage Precision Recall Coverage</title>
<note confidence="0.550364285714286">ELS Coarse-grained Fine-grained Prob0 63.6% 63.6% 100.0% 54.7% 54.7% 100.0% Probl 71.6% 71.6% 100.0% 65.1% 65.1% 100.0% Prob2 69.3% 69.3% 100.0% 61.9% 61.9% 100.0% EAW With &amp;quot;U&amp;quot; Without &amp;quot;U&amp;quot; Prob3 55,1% 55.1% 100.0% 57.3% 54.7% 97.4% Prob4 55.4% 55.4% 100.0% 57.5% 55.0% 97.4%</note>
<abstract confidence="0.794176682926829">Prob5 57.2% 57.2% 100.0% 58.5% 56.8% 97.4% Table 3: Results on the EAW and ELS tasks to the evaluation taking place, we ran a search the possible module resulting in a better performance with a combination of the most frequent sense modules, the trigram modules, the window module, and the root of word 3 to the left, 1 to the right and 2 to the right. The &apos;without U&apos; performance for the English all words task with this module combination is 59.5% precision and 58.0% recall. 5 Conclusion We have presented the results of our probabilis- WSD system on the lexical sample and the English all words tasks. In both cases, our system outperformed the basefor the We have shown that the system can be further optimized, but even in its raw form it performs well. task. search was run on the English all words task. baseline does not have access to perfect part of speech, or untagged word information. Acknowledgements like to thank my supervisor, Ted Briscoe, and Joe Hurd for proof reading previous versions of this paper. References D. Elworthy. 1994. Does Baum-Welch rehelp taggers? In of 4th Conference on Applied NLP, 53-58. D. Manning and H. Schiitze. 1999. Foundations of Statistical Natural Language Process- Press. R. Mihalcea, A. Kilarriff, and T. Chklovski. English lexical sample task. In Proceedings of SENSEVAL-3. R. Mihalcea. 2002. Word sense disambiguation using pattern learning and automatic feature of Natural Language and</abstract>
<note confidence="0.798352">M. Palmer. 2004. English all words task. In Proceedings of SENSEVAL-3. T. Pedersen. 2002. Machine learning with lexical features: The Duluth approach to Senseval-2. In J. Preiss and D. Yarowsky, edof SENSEVAL-2: Second International Workshop on Evaluating Word Disambiguating Systems, 139- 142. J. Preiss. 2004. Probabilistic word sense disam- Speech and Language. Forthcoming. M. Stevenson and Y. Wilks. 2001. The interaction of knowledge sources in word sense Linguistics, 27(3):321-349. Stevenson. 2003. Sense Disambiguation: The Case for Combining Knowledge Publications, Stanford, CA. D. Yarowsky. 2000. Hierarchical decision lists word sense disambiguation. the Humanities,</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Elworthy</author>
</authors>
<title>Does Baum-Welch reestimation help taggers?</title>
<date>1994</date>
<booktitle>In Proceedings of the 4th Conference on Applied NLP,</booktitle>
<pages>53--58</pages>
<marker>Elworthy, 1994</marker>
<rawString>D. Elworthy. 1994. Does Baum-Welch reestimation help taggers? In Proceedings of the 4th Conference on Applied NLP, pages 53-58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Manning</author>
<author>H Schiitze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="1282" citStr="Manning and Schiitze, 1999" startWordPosition="202" endWordPosition="205">ding part of data (excluding verbs) speech modules, head word modules, and the baseline modules. Table 1: System descriptions lustration, we present three frequency distributions from the pos0 module for the word shirt (P(pos0 = NN1 Ishirt,), P(pos0 = NN2Ishirt,), and P(pos0 = VVD Ishirt,)) in Table 2. In this table, f (sense n pos) denotes the number of occurrences of w in the given sense with the given PoS tag, and f (sense) is the number of occurrences of shirt in the given sense. The probability distributions produced by the modules need to be smoothed. We use Lidstone&apos;s smoothing (e.g., (Manning and Schiitze, 1999)), where the optimum smoothing values are empirically determined on a development corpus by an exhaustive search. Using Lidstone&apos;s smoothing, we can make the smoothing values word and module specific, and so can make the probability distributions generated resemble uniform distributions if we are not very confident in the module for a given word. The probability distributions produced by the 26 modules are combined using Bayes Rule: P(A n B) P(AIB) = The prior distribution comes from the unsupervised PoS and frequency modules, and this is augmented using the remaining modules to produce the be</context>
</contexts>
<marker>Manning, Schiitze, 1999</marker>
<rawString>C. D. Manning and H. Schiitze. 1999. Foundations of Statistical Natural Language Processing. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>A Kilarriff</author>
<author>T Chklovski</author>
</authors>
<title>English lexical sample task.</title>
<date>2004</date>
<booktitle>In Proceedings of SENSEVAL-3.</booktitle>
<contexts>
<context position="2248" citStr="Mihalcea et al., 2004" startWordPosition="357" endWordPosition="360">ord. The probability distributions produced by the 26 modules are combined using Bayes Rule: P(A n B) P(AIB) = The prior distribution comes from the unsupervised PoS and frequency modules, and this is augmented using the remaining modules to produce the best updated estimate in the form of a posterior distribution. Combining modules using Bayes Rule is the best combination method that was tested, and outperforms the natural combination method based on Dempster—Shafer theory. 3 Results There were three versions of the probabilistic WSD system submitted to the English lexical sample (ELS) task (Mihalcea et al., 2004), and to the English all words (EAW) task (Palmer, 2004). The descriptions of the systems and their training data can be found in Table 1. For the English all words task, the system was trained on SEMCOR 1.6 converted into 1.7.1 using (a heuristics based) automatic mapping method. Although the output of our probabilistic system is a probability distribution on senses, this was converted a one sense assignment per instance for evaluation.2 For the English lexical sample task, the &amp;quot;U&amp;quot; (unassignable) tag was output whenever our system gave the highest probability to none of the available senses b</context>
</contexts>
<marker>Mihalcea, Kilarriff, Chklovski, 2004</marker>
<rawString>R. Mihalcea, A. Kilarriff, and T. Chklovski. 2004. English lexical sample task. In Proceedings of SENSEVAL-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
</authors>
<title>Word sense disambiguation using pattern learning and automatic feature selection.</title>
<date>2002</date>
<journal>Journal of Natural Language and Engineering,</journal>
<pages>8--4</pages>
<marker>Mihalcea, 2002</marker>
<rawString>R. Mihalcea. 2002. Word sense disambiguation using pattern learning and automatic feature selection. Journal of Natural Language and Engineering, 8(4):343-358.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Palmer</author>
</authors>
<title>English all words task.</title>
<date>2004</date>
<booktitle>In Proceedings of SENSEVAL-3.</booktitle>
<contexts>
<context position="2304" citStr="Palmer, 2004" startWordPosition="369" endWordPosition="370"> combined using Bayes Rule: P(A n B) P(AIB) = The prior distribution comes from the unsupervised PoS and frequency modules, and this is augmented using the remaining modules to produce the best updated estimate in the form of a posterior distribution. Combining modules using Bayes Rule is the best combination method that was tested, and outperforms the natural combination method based on Dempster—Shafer theory. 3 Results There were three versions of the probabilistic WSD system submitted to the English lexical sample (ELS) task (Mihalcea et al., 2004), and to the English all words (EAW) task (Palmer, 2004). The descriptions of the systems and their training data can be found in Table 1. For the English all words task, the system was trained on SEMCOR 1.6 converted into 1.7.1 using (a heuristics based) automatic mapping method. Although the output of our probabilistic system is a probability distribution on senses, this was converted a one sense assignment per instance for evaluation.2 For the English lexical sample task, the &amp;quot;U&amp;quot; (unassignable) tag was output whenever our system gave the highest probability to none of the available senses being relevant. The system also occasionally entirely mis</context>
</contexts>
<marker>Palmer, 2004</marker>
<rawString>M. Palmer. 2004. English all words task. In Proceedings of SENSEVAL-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
</authors>
<title>Machine learning with lexical features: The Duluth approach to Senseval-2.</title>
<date>2002</date>
<booktitle>Proceedings of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguating Systems,</booktitle>
<pages>139--142</pages>
<editor>In J. Preiss and D. Yarowsky, editors,</editor>
<marker>Pedersen, 2002</marker>
<rawString>T. Pedersen. 2002. Machine learning with lexical features: The Duluth approach to Senseval-2. In J. Preiss and D. Yarowsky, editors, Proceedings of SENSEVAL-2: Second International Workshop on Evaluating Word Sense Disambiguating Systems, pages 139-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Preiss</author>
</authors>
<title>Probabilistic word sense disambiguation.</title>
<date>2004</date>
<journal>Computer Speech and Language. Forthcoming.</journal>
<marker>Preiss, 2004</marker>
<rawString>J. Preiss. 2004. Probabilistic word sense disambiguation. Computer Speech and Language. Forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stevenson</author>
<author>Y Wilks</author>
</authors>
<title>The interaction of knowledge sources in word sense disambiguation.</title>
<date>2001</date>
<journal>Computational Linguistics,</journal>
<pages>27--3</pages>
<marker>Stevenson, Wilks, 2001</marker>
<rawString>M. Stevenson and Y. Wilks. 2001. The interaction of knowledge sources in word sense disambiguation. Computational Linguistics, 27(3):321-349.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stevenson</author>
</authors>
<title>Word Sense Disambiguation: The Case for Combining Knowledge Sources.</title>
<date>2003</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<marker>Stevenson, 2003</marker>
<rawString>M. Stevenson. 2003. Word Sense Disambiguation: The Case for Combining Knowledge Sources. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Hierarchical decision lists for word sense disambiguation. Computers and the Humanities,</title>
<date>2000</date>
<pages>34--1</pages>
<marker>Yarowsky, 2000</marker>
<rawString>D. Yarowsky. 2000. Hierarchical decision lists for word sense disambiguation. Computers and the Humanities, 34(1/2):179-186.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>