<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.997332">
Reversibility and Re-usability of Resources
in NLG and Natural Language Dialog Systems
</title>
<author confidence="0.986942">
Martin Klarner
</author>
<affiliation confidence="0.861861">
3SOFT GmbH
</affiliation>
<address confidence="0.859577">
Frauenweiherstr. 14, D-91058 Erlangen, Germany
</address>
<email confidence="0.994594">
martin.klarner@3soft.de
</email>
<sectionHeader confidence="0.995561" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997236">
Reversibility is a key to efficient and maintain-
able NLG systems. In this paper, we present
a formal definition of reversible NLG systems
and develop a classification of existing natural
language dialog systems in this framework.
</bodyText>
<sectionHeader confidence="0.998796" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999859133333333">
Reversibility is a key factor in building efficient and
maintainable NLG and natural language dialog systems
(NLDSs). But previous formal descriptions of reversibil-
ity are still lacking in coverage and applicability to exist-
ing systems. In this paper, we extend former approaches
to this matter by formally defining reversibility in NLDSs
and developing a proper classification of such systems
in terms of reversibility. After that, existing NLG and
generic dialog systems are used as examples for the fea-
sibility and applicability of our classification.
In our point of view, it is useless to consider reversibil-
ity for an NLG system alone, because parsing and dia-
log management are equally important for developing an
NLDS. Hence, our classification applies to complete di-
alog systems and not only NLG systems.
</bodyText>
<sectionHeader confidence="0.985746" genericHeader="introduction">
2 A Formal Description of Reversibility
</sectionHeader>
<bodyText confidence="0.999015666666667">
In this section, we will provide a formal definition of
reversibility which is based on previous work [Neumann
and van Noord, 1994]. To this end, we will first give
a short overview of the results obtained there in sect.
2.1. After that, we will present our extended definition
in sect. 2.2.
</bodyText>
<subsectionHeader confidence="0.976808">
2.1 Previous definitions of Reversibility
</subsectionHeader>
<bodyText confidence="0.964624111111111">
In [Neumann and van Noord, 1994], a definition of re-
versibility for programs is provided. The authors start
with a definition for computing a relation r in both di-
rections (def. 1).
Definition 1. (Computing a relation in both directions
according to NEUMANN and VAN NOORD)
A program P computes a relation r in both di-
rections, iff for a given input (dir, e) it recursively enu-
merates the set
</bodyText>
<equation confidence="0.424973">
{x  |((e, x) E r A dir = 0) V ((x, e) E r A dir = 1)}.
</equation>
<bodyText confidence="0.9672035">
In this definition, the parameter dir denotes the di-
rection in which the input is computed, and e represents
the content of the input for which the appropriate output
has to be obtained.
Let us state a simple corollary to def. 1 which relates
the notion of computing a relation in both directions to
the notion of inverse relations.
Corollary 1. A program P computes the relation r in
both directions, if P computes r and the inverse relation
of r, r−1.
Proof. According to def. 1, P recursively enumerates the
set {x  |(e, x) E r} for dir = 0 and the set {x  |(x, e) E r}
for dir = 1. Hence, it computes r for dir = 0 and
(using the standard definition of inverse relations) r−1
for dir = 1.
Based on def. 1, the following definitions for r-
reversibility of programs and relations are provided in
[Neumann and van Noord, 1994] (def. 2).
Definition 2. (Reversibility of programs and relations
according to NEUMANN and VAN NOORD)
</bodyText>
<listItem confidence="0.99831825">
1. A program P is r-reversible if it computes r in
both directions.
2. A relation r is reversible iff an r-reversible pro-
gram exists.
</listItem>
<bodyText confidence="0.99600475">
The notion of reversible programs in def. 1 and 2 is
very general: In an extreme case, such a program can
consist of two completely independent parts tied to-
gether only by an initial conditional statement. This
statement decides, depending on the value of the direc-
tion parameter dir, whether the program part computing
relation r (for dir = 0) or the one computing r−1 (for
dir = 1) is used. In our opinion, such a program should
not be called reversible any more. Hence, definitions 1
and 2 are too general.
On the other hand, they are too specific; this is due
to three reasons:
</bodyText>
<listItem confidence="0.861530666666667">
1. Program and data are not distinguished.
2. Thus, different resources and resource types1 are
also not addressed.
lsuch as linguistic and pragmatic resources
3. The availability time for a program or a resource2
is not considered.
</listItem>
<bodyText confidence="0.999741">
Hence, in the next section we will replace these def-
initions by a more general description of reversibility
for generic program systems before we will describe re-
versibility in current NLDSs.
</bodyText>
<subsectionHeader confidence="0.997439">
2.2 Extended definition of reversibility
</subsectionHeader>
<bodyText confidence="0.8512606">
In this section, we will present our definition of reversibil-
ity. We start with definitions of a generic program sys-
tem and of system and program relations (def. 3).
Definition 3. (Program system, system relations, and
program relations)
</bodyText>
<listItem confidence="0.950401">
1. A program system S consists of a triplet
(COMPS, PROGS, RESS) of
(a) a set of preprocessing programs COMPS =
{C1, ... , Ck} which are executed before system
start,
(b) a set of runtime programs PROGS =
{P1, ... ,Pl},
(c) and a set of resources RESS = {R1, ... , Rm}.
2. The set of relations RELS = {r1, ... , rn} computed
by the programs of PROGS is called the set of sys-
</listItem>
<subsectionHeader confidence="0.282207">
tem relations of S.
</subsectionHeader>
<bodyText confidence="0.924326692307692">
3. The set of relations RELP = {r1,... , rp} computed
by a single program Pi  PROGS is called the set
of program relations of P.
By resources we denote every data structure needed by
a runtime program for its execution3. More precisely, the
resource RP,,r,, provides a necessary (but not sufficient)
condition for the runtime program Pi to compute one of
its program relations rk. All of these resources must be
available at system start, but they may be generated by
preprocessing programs.
Before we can state our definition of reversibility, we
have to give a formal description of inverse programs and
resources (def. 4).
</bodyText>
<construct confidence="0.929174454545455">
Definition 4. (Inverse program and inverse resource)
Let S be a program system, R  RESS a system re-
source, and P  PROGS a program with a program re-
lation r  RELP. Let R be a resource needed by P for
computing r.
1. Then every program P−1 computing the inverse re-
lation r−1 is called an inverse program to P with
respect to r.
2. The transformation of a resource R needed by P−1
to compute r−1 is called inverse resource R−1 to
R with respect to r.
</construct>
<bodyText confidence="0.923602">
A simple corollary relates self-inverse programs to r-
reversible programs.
</bodyText>
<footnote confidence="0.79832425">
2i.e. whether it is available only at runtime or already at
compile time
3contrary to the terminology used e.g. in operating sys-
tems programming
</footnote>
<construct confidence="0.9015215">
Corollary 2. If P  P−1 holds, i.e. if P is self-inverse
with respect to r, then P is r-reversible.
</construct>
<bodyText confidence="0.99404075">
Proof. If P computes r, P−1 computes r−1, and P 
P−1 holds, then P computes r−1 as well. Then, accord-
ing to def. 1, P computes r in both directions, and with
def. 2 P is r-reversible.
</bodyText>
<subsectionHeader confidence="0.9491">
Algorithmic reversibility
</subsectionHeader>
<bodyText confidence="0.997938">
For any program system of def. 3, we define algorithmic
reversibility in the following way (def. 5).
</bodyText>
<construct confidence="0.8217266">
Definition 5. (Algorithmic reversibility)
Let S be a program system, P  PROGS a program
in S, and r  RELP a program relation of P.
Then S is algorithmic-reversible in P and r if P
is r-reversible.
</construct>
<bodyText confidence="0.991774">
Hence, P (and no other program Q  PROGS with
Q = P)4 has to compute r and r−1 as well.
</bodyText>
<subsectionHeader confidence="0.980791">
Data reversibility
</subsectionHeader>
<bodyText confidence="0.96812">
Data reversibility, the counterpart of algorithmic re-
versibility, can be defined as follows (def. 6).
</bodyText>
<construct confidence="0.899070857142857">
Definition 6. (Data reversibility)
Let S be a program system, R  RESS a system re-
source of S, and r  RELS a system relation of S.
Then S is data-reversible to R and r if two programs
P1, P2  PROGS exist which both need R to be executed
and for both of which r  RELP, and r−1  RELP,
holds.
</construct>
<bodyText confidence="0.93627075">
Thus, P1 must compute r using R, and P2 must com-
pute the inverse relation r−1 (also by using R). If
P1  P2  P holds, S is also algorithmic-reversible to P
and r.
Static and dynamic reversibility
A different dimension of reversibility dealing with the
availability time of a program or a resource can be de-
scribed as follows (def. 7).
</bodyText>
<subsectionHeader confidence="0.665313">
Definition 7. (Static and dynamic reversibility)
</subsectionHeader>
<bodyText confidence="0.9556745">
Let S be a program system, R  RESS a system re-
source and r  RELS a system relation of S.
</bodyText>
<listItem confidence="0.988887857142857">
1. S is static-reversible with respect to R and r if
(a) a program P  PROGS with r  RELP exists
which needs R for its execution,
(b) also r−1  RELS, P−1  PROGS, and R−1 
RESS holds,
and additionally
(c) at least one preprocessing program C 
</listItem>
<footnote confidence="0.774290428571428">
COMPS is needed for the construction of R−1
from R or of P−1 from P.
2. If no such program C is needed, S is called
dynamic-reversible with respect to R and r.
4By Q =� P we denote syntactic in-equivalence here. This
is easily decidable, whereas semantic equivalence of programs
is certainly not.
</footnote>
<bodyText confidence="0.999860333333333">
If, under the preconditions of def. 7, the inverse
program P−1 is constructed, S is also algorithmic-
reversible with respect to P and r. However, if the in-
verse resource R−1 is constructed, S is data-reversible
with respect to R and r. Obviously, both algorithmic
and data reversibility can occur simultaneously.
</bodyText>
<sectionHeader confidence="0.989092" genericHeader="method">
3 Reversibility in Dialog Systems
</sectionHeader>
<bodyText confidence="0.9996874">
Consider the special relation sps between phonetic and
semantic structures. This is the relation computed by
the analysis part of a natural language dialog system
(NLDS). By applying our definitions of reversibility pre-
sented in sect. 2.2 on sps, we face an important ques-
tion of natural language processing: To what extent is
a given NLDS reversible? But before we consider this
question in more detail, we have to define our notion of
an NLDS first. Based on def. 3, we formally describe an
NLDS as follows (def. 8).
</bodyText>
<sectionHeader confidence="0.404524" genericHeader="method">
Definition 8. (NLDS)
</sectionHeader>
<bodyText confidence="0.986873636363636">
Let rps be the relation between phonological and se-
mantic structures and r−1
ps the inverse relation of rps.5
An NLDS is a program system S with rps E RELS
and r−1
ps - rsp E RELS.
Hence, an NLDS must contain both the relations rps
and rsp as system relations. This is quite obvious, since
natural language dialog requires both natural language
understanding (NLU) and natural language generation
(NLG).
</bodyText>
<sectionHeader confidence="0.976207" genericHeader="method">
4 Classification of Reversibility Types
</sectionHeader>
<bodyText confidence="0.999879695652174">
As we have seen in the previous sections, generic pro-
gram systems and NLDSs in particular can be reversible
in two independent dimensions: On the one hand, they
can be static ors dynamic, and on the other hand, al-
gorithms and/or data can be reversible. Given that a
system may also be not reversible at all in both dimen-
sions just mentioned, we obtain a classification of nine
possible reversibility types.
[Neumann, 1994], however, describes just four types of
reversibility in dialog systems and takes only the gram-
mar as a linguistic resource into account: Type A has
static reversibility (in terms of data and algorithms),
while type B has dynamic data reversibility. Type C has
statistically reversible data and dynamically reversible
algorithms, while type D has dynamic data and algo-
rithmic reversibility.
By further exploring the notions of algorithmic and
data reversibility introduced above, both of which can be
realized in three different variants (none, static, and dy-
namic), we are able to extend the classification in [Neu-
mann, 1994] by two more types: Type E is statically re-
versible in terms of data and algorithms, and type F has
dynamic data and static algorithmic reversibility. Our
</bodyText>
<footnote confidence="0.86924">
5Henceforth, we will denote r−1
v�3 just r3,v for obvious
simplicity reasons.
6The “or” here must be read as an “exclusive or”.
</footnote>
<bodyText confidence="0.99986488372093">
extended classification of reversible dialog systems is de-
picted in fig. 1.
There are three more possible types in our classifi-
cation, all of them without data reversibility: Type G
has statically and type H dynamically reversible algo-
rithms, whereas type I does not have any reversibility
at all. While types G and H are just not desirable for
real-world NLDSs, type I is even unacceptable. Hence
we decided to exclude types G, H, and I from fig. 1 and
depict them separately in fig. 2. However, the legend
displayed there applies to fig. 1 as well.
It has to be pointed out here that any classification of
reversible dialog systems must not be restricted to the
grammar, but has to be extended to the other resources
used in an NLDS as well. Apart from the grammar,
we distinguish five additional system resources: Lexicon
and morphology component are linguistic resources (to-
gether with the grammar), whereas discourse memory,
domain model, and user model are pragmatic system
resources. Hence, the reversibility of an NLDS can be
classified depending on (at least) six different resource
categories. Together with the six reversibility types in-
troduced above, these six resources form a 6-tuple which
enables us to describe the reversibility of an NLDS for-
mally and completely.
Let us take the CONALD dialog system [Ludwig, 2003]
as an example. The system lexicon is precompiled into
an NLG lexicon at development time, hence we have
static reversibility of type E here. On the other hand, the
morphology component is used by both the parser and
the generator at runtime in a uniform way (cf. [Klarner
and Ludwig, 2004]), resulting in dynamic reversibility for
this component. Discourse memory and domain model
are used in the dialog manager for pragmatic integra-
tion and by the NLG component. The data structures
are identical, but the algorithms are different. Thus, we
have type B reversibility for these two resources. The
user model, however, is not used for parsing, only for
generation, hence the system is not reversible with re-
spect to the user model.
In table 1 the reversibility types of the different re-
sources are put together. They form a tuple (E, D, A, B,
B, none) completely describing reversibility in CONALD.
</bodyText>
<sectionHeader confidence="0.6792405" genericHeader="method">
Resource Type
Lexicon E
Morphology D
Grammar A
Discourse Memory B
Domain Model B
</sectionHeader>
<subsectionHeader confidence="0.517163">
User Model none
</subsectionHeader>
<tableCaption confidence="0.99245">
Table 1: Reversibility of CONALD.
</tableCaption>
<bodyText confidence="0.999599">
The AMALiA system [Gabrilovich et al., 1998] is a typ-
ical example for PROLOG-based reversible NLG systems.
The system grammar is first inverted and then compiled
into two different versions, one for parsing and one for
generation. Thus, we have type C reversibility here. The
</bodyText>
<figure confidence="0.9634455">
data: static; algorithms: none
data: dynamic; algorithms: none
Generator
Parser
Type A
System
Resource
Parsing
Resource
Generation
Resource
Parser
Generator
Type B
System
Resource
Type C
System
Resource
Parsing
Resource
Generation
Resource
Uniform
Algorithm
data: static; algorithms: dynamic
Type D
Uniform
Algorithm
data: dynamic; algorithms: dynamic
System
Resource
</figure>
<figureCaption confidence="0.6698815">
data: static; algorithms: static
data: dynamic; algorithms: static
</figureCaption>
<figure confidence="0.999393555555555">
Type E
Parsing
Resource
Parser
Uniform Source
Algorithm
System
Resource
Generation
Resource
Generator
Type F
Parser
Uniform Source
Algorithm
System
Resource
Generator
</figure>
<figureCaption confidence="0.989908">
Figure 1: Reversible dialog systems.
</figureCaption>
<figure confidence="0.997624060606061">
Generator
Parser
Parsing
Resource
Generation
Resource
Type G
Uniform Source
Algorithm
data: none; algorithms: static
Type H
Parsing
Resource
Generation
Resource
Uniform
Algorithm
Parsing
Resource
Parser
Generation
Resource
Generator
Type I
Legend
uses resource
Program A is compiled into B
A
Program
B
is compiled into
A B
Resource
</figure>
<figureCaption confidence="0.999707">
Figure 2: Not-so-reversible dialog systems.
</figureCaption>
<bodyText confidence="0.9411454">
same applies to the lexicon. As there are no pragmatic
resources and no morphology component, we can skip
their analysis here. Hence, AMALiA can be characterized
by the reversibility tuple (C, n/a, C, n/a, n/a, n/a); cf.
table 2.
</bodyText>
<table confidence="0.766679857142857">
Resource Type
Lexicon C
Morphology n/a
Grammar C
Discourse Memory n/a
Domain Model n/a
User Model n/a
</table>
<tableCaption confidence="0.993184">
Table 2: Reversibility of AMALiA.
</tableCaption>
<bodyText confidence="0.999950222222222">
Our third and final example is TRiPS [Ferguson and
Allen, 1998]. In this system, the Discourse Context and
the Reference component are shared between the Inter-
pretation Manager (which is used for parsing) and the
Generation Manager (cf. [Allen et al., 2001]). This re-
sults in type B for the discourse memory. The same
holds for the ontology of TRiPS (cf. [Stent, 2001], p.
139): Its domain model is of type B as well. As there
is no specific user model contained in the system, there
is also no degree of reversibility to be found there. For
various reasons, the Generation Manager uses its own
grammar and morphology component (cf. [Stent, 2001],
p. 180 &amp; 182). The NLG lexicon of TRiPS is obtained
semi-automatically from various system resources and
off-line extraction (cf. [Stent, 2001], p. 180). Hence, we
have type A reversibility here. We therefore conclude
that TRiPS can be described by the reversibility tuple
(A, none, C, B, B, n/a); cf. table 3.
</bodyText>
<sectionHeader confidence="0.693666" genericHeader="method">
Resource Type
</sectionHeader>
<table confidence="0.526947166666667">
Lexicon A
Morphology none
Grammar none
Discourse Memory B
Domain Model B
User Model n/a
</table>
<tableCaption confidence="0.994691">
Table 3: Reversibility of TRiPS.
</tableCaption>
<sectionHeader confidence="0.9973505" genericHeader="method">
5 Re-usability as Static Reversibility of
Resources
</sectionHeader>
<bodyText confidence="0.999978047619048">
Given our definitions of reversibility in sect. 2, we can
view re-using resources in an NLDS as static or dynamic
reversibility of the system for these resources. Compared
to the definition in [Neumann and van Noord, 1994] re-
ferred in sect. 2.1, this is a more general definition which
can be applied to a lot of existing NLDSs.
Let us again use the CoNALD system as an example,
this time only taking the data structures into account,
in order to search for possible re-use of resources. Two
core linguistic resources of its parsing branch are re-used
in its NLG component HYPERBUG [Klarner and Ludwig,
2004]: The system lexicon and the morphology compo-
nent are both used by the parser and the generator, with
static reversibility for the system lexicon and dynamic re-
versibility for the morphology component. As mentioned
in sect. 4, re-use is also done for the pragmatic resources,
namely discourse memory and domain model.
Generally speaking, the more linguistic and pragmatic
resources are re-used in an NLDS, the higher its degree of
reversibility becomes, and the more efficient the system
will be to develop and maintain.
</bodyText>
<sectionHeader confidence="0.993263" genericHeader="conclusions">
6 Conclusion and Further Work
</sectionHeader>
<bodyText confidence="0.999992228571429">
We have developed a formal description of reversibility
for NLDSs, using definitions for program systems, sys-
tem relations, and system resources. Based on these def-
initions, we have presented a classification of reversible
NLDSs in general and NLG systems in particular. Our
classification extends previous approaches in three di-
mensions: First, it covers static and dynamic reversibil-
ity, second, it considers algorithmic and data reversibil-
ity, and third, it takes the different resources of a dialog
system into account.
The 6-tuple used in our classification can, of course,
be extended to incorporate different linguistic and prag-
matic resources, should they prove useful for an NLDS.
However, we identified the set of resources mentioned
above by thorough investigation of existing systems
based on the results presented in [Maier, 1999] for text
planning; presently, we do not think we need additional
ones.
Unfortunately, our definition of reversibility does not
yet completely reflect all aspects of current NLDSs: For
example, it does not cover systems where preprocessing
and runtime programs cannot be clearly separated, be-
cause such systems allow a flexible choice for a given
resource and/or algorithm to be computed beforehand
(by preprocessing) or at runtime.? This extended de-
gree of dynamic has yet to be taken into account in our
definitions.
The obvious practical application of our classification
is twofold: First, using it in a descriptive way to analyze
existing systems. Second, and more practical, using it in
a normative way to further develop one’s one NLDS to
be as reversible as possible (i.e., to obtain a “D” in all
six positions of the 6-tuple of reversibility types). Both
applications are important, but the second is the one we
are going to pursue in the near future.
</bodyText>
<sectionHeader confidence="0.998874" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9511367">
Most of the work described here was done while complet-
ing my PhD thesis [Klarner, 2005] at the Chair for Artifi-
cal Intelligence of the University of Erlangen-Nuremberg.
This is why I want to thank my former colleagues there,
7While such systems are certainly an attractive theoretical
possibility, we are not aware of real-world existing ones so far.
especially Bernd Ludwig and Peter Reiß, for their en-
during cooperation and support. Many thanks to the
anonymous reviewers as well for providing very helpful
comments to the initial version of this paper.
</bodyText>
<sectionHeader confidence="0.996089" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998363380952381">
[Allen et al., 2001] J. Allen, G. Ferguson, and A. Stent.
An architecture for more realistic conversational sys-
tems. In Proc. 6th Int. Conf. on Intelligent User In-
terfaces (IUI-2001), pages 1–8, Santa Fe, 2001.
[Ferguson and Allen, 1998] George Ferguson and James
Allen. Trips: An intelligent integrated problem-
solving assistant. In Proc. AAAI-98, Madison, WI,
1998.
[Gabrilovich et al., 1998] Evgeniy Gabrilovich, Nissim
Francez, and Shuly Wintner. Natural language gen-
eration with abstract machine. In Proc. INLG-98,
Niagara-on-the-Lake, 1998.
[Klarner and Ludwig, 2004] Martin Klarner and Bernd
Ludwig. Hybrid natural language generation in a
spoken language dialog system. In Susanne Biundo,
Thom Fr¨uhwirth, and G¨unther Palm, editors, Proc.
KI-2004, pages 97–112, Ulm, 2004.
[Klarner, 2005] Martin Klarner. Hybride, pragma-
tisch eingebettete Realisierung mittels Bottom-Up-
Generierung in einem nat¨urlichsprachlichen Di-
alogsystem. PhD thesis, Erlangen-N¨urnberg, 2005.
[Ludwig, 2003] Bernd Ludwig. Ein konfigurierbares
Dialogsystem f¨ur Mensch-Maschine-Interaktion in
gesprochener Sprache. PhD thesis, Universit¨at
Erlangen-N¨urnberg, 2003.
[Maier, 1999] Elisabeth Maier. Entwurf und Implemen-
tierung von Wissensquellen f¨ur die Textplanung – eine
modulare Architektur. Berlin, 1999.
[Neumann and van Noord, 1994] G¨unther Neumann
and Gertjaan van Noord. Reversibility and self-
monitoring in natural language generation. In Tomek
Strzalkowski, editor, Reversible Grammars in Natural
Language Processing. Boston, Dordrecht, London,
1994.
[Neumann, 1994] G¨unter Neumann. A Uniform Compu-
tation Model for Natural Language Parsing and Gen-
eration. PhD thesis, Universit¨at des Saarlands, 1994.
[Stent, 2001] Amanda J. Stent. Dialogue Systems as
Conversational Partners: Applying Conversation Acts
Theory to Natural Language Generation for Task-
Oriented Mixed-Initiative Spoken Dialogue. PhD the-
sis, University of Massachusetts Amherst, 2001.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.254122">
<title confidence="0.998395">Reversibility and Re-usability of in NLG and Natural Language Dialog Systems</title>
<author confidence="0.949868">Martin</author>
<note confidence="0.5105025">3SOFT Frauenweiherstr. 14, D-91058 Erlangen,</note>
<email confidence="0.848646">martin.klarner@3soft.de</email>
<abstract confidence="0.998031166666667">Reversibility is a key to efficient and maintainable NLG systems. In this paper, we present a formal definition of reversible NLG systems and develop a classification of existing natural language dialog systems in this framework.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Allen</author>
<author>G Ferguson</author>
<author>A Stent</author>
</authors>
<title>An architecture for more realistic conversational systems.</title>
<date>2001</date>
<booktitle>In Proc. 6th Int. Conf. on Intelligent User Interfaces (IUI-2001),</booktitle>
<pages>1--8</pages>
<location>Santa Fe,</location>
<marker>[Allen et al., 2001]</marker>
<rawString>J. Allen, G. Ferguson, and A. Stent. An architecture for more realistic conversational systems. In Proc. 6th Int. Conf. on Intelligent User Interfaces (IUI-2001), pages 1–8, Santa Fe, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Ferguson</author>
<author>James Allen</author>
</authors>
<title>Trips: An intelligent integrated problemsolving assistant.</title>
<date>1998</date>
<booktitle>In Proc. AAAI-98,</booktitle>
<location>Madison, WI,</location>
<marker>[Ferguson and Allen, 1998]</marker>
<rawString>George Ferguson and James Allen. Trips: An intelligent integrated problemsolving assistant. In Proc. AAAI-98, Madison, WI, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Nissim Francez</author>
<author>Shuly Wintner</author>
</authors>
<title>Natural language generation with abstract machine.</title>
<date>1998</date>
<booktitle>In Proc. INLG-98,</booktitle>
<location>Niagara-on-the-Lake,</location>
<marker>[Gabrilovich et al., 1998]</marker>
<rawString>Evgeniy Gabrilovich, Nissim Francez, and Shuly Wintner. Natural language generation with abstract machine. In Proc. INLG-98, Niagara-on-the-Lake, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Klarner</author>
<author>Bernd Ludwig</author>
</authors>
<title>Hybrid natural language generation in a spoken language dialog system.</title>
<date>2004</date>
<booktitle>Proc. KI-2004,</booktitle>
<pages>97--112</pages>
<editor>In Susanne Biundo, Thom Fr¨uhwirth, and G¨unther Palm, editors,</editor>
<location>Ulm,</location>
<marker>[Klarner and Ludwig, 2004]</marker>
<rawString>Martin Klarner and Bernd Ludwig. Hybrid natural language generation in a spoken language dialog system. In Susanne Biundo, Thom Fr¨uhwirth, and G¨unther Palm, editors, Proc. KI-2004, pages 97–112, Ulm, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Klarner</author>
</authors>
<title>Hybride, pragmatisch eingebettete Realisierung mittels Bottom-UpGenerierung in einem nat¨urlichsprachlichen Dialogsystem.</title>
<date>2005</date>
<tech>PhD thesis,</tech>
<location>Erlangen-N¨urnberg,</location>
<marker>[Klarner, 2005]</marker>
<rawString>Martin Klarner. Hybride, pragmatisch eingebettete Realisierung mittels Bottom-UpGenerierung in einem nat¨urlichsprachlichen Dialogsystem. PhD thesis, Erlangen-N¨urnberg, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Ludwig</author>
</authors>
<title>Ein konfigurierbares Dialogsystem f¨ur Mensch-Maschine-Interaktion in gesprochener Sprache.</title>
<date>2003</date>
<tech>PhD thesis,</tech>
<institution>Universit¨at Erlangen-N¨urnberg,</institution>
<marker>[Ludwig, 2003]</marker>
<rawString>Bernd Ludwig. Ein konfigurierbares Dialogsystem f¨ur Mensch-Maschine-Interaktion in gesprochener Sprache. PhD thesis, Universit¨at Erlangen-N¨urnberg, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisabeth Maier</author>
</authors>
<title>Entwurf und Implementierung von Wissensquellen f¨ur die Textplanung – eine modulare Architektur.</title>
<date>1999</date>
<location>Berlin,</location>
<marker>[Maier, 1999]</marker>
<rawString>Elisabeth Maier. Entwurf und Implementierung von Wissensquellen f¨ur die Textplanung – eine modulare Architektur. Berlin, 1999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unther Neumann</author>
<author>Gertjaan van Noord</author>
</authors>
<title>Reversibility and selfmonitoring in natural language generation.</title>
<date>1994</date>
<booktitle>Reversible Grammars in Natural Language Processing.</booktitle>
<editor>In Tomek Strzalkowski, editor,</editor>
<location>Boston, Dordrecht, London,</location>
<marker>[Neumann and van Noord, 1994]</marker>
<rawString>G¨unther Neumann and Gertjaan van Noord. Reversibility and selfmonitoring in natural language generation. In Tomek Strzalkowski, editor, Reversible Grammars in Natural Language Processing. Boston, Dordrecht, London, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unter Neumann</author>
</authors>
<title>A Uniform Computation Model for Natural Language Parsing and Generation.</title>
<date>1994</date>
<booktitle>PhD thesis, Universit¨at des Saarlands,</booktitle>
<marker>[Neumann, 1994]</marker>
<rawString>G¨unter Neumann. A Uniform Computation Model for Natural Language Parsing and Generation. PhD thesis, Universit¨at des Saarlands, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amanda J Stent</author>
</authors>
<title>Dialogue Systems as Conversational Partners: Applying Conversation Acts Theory to Natural Language Generation for TaskOriented Mixed-Initiative Spoken Dialogue.</title>
<date>2001</date>
<tech>PhD thesis,</tech>
<institution>University of Massachusetts</institution>
<location>Amherst,</location>
<marker>[Stent, 2001]</marker>
<rawString>Amanda J. Stent. Dialogue Systems as Conversational Partners: Applying Conversation Acts Theory to Natural Language Generation for TaskOriented Mixed-Initiative Spoken Dialogue. PhD thesis, University of Massachusetts Amherst, 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>