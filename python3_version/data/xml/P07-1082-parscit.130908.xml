<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003338">
<title confidence="0.9966575">
Collapsed Consonant and Vowel Models: New Approaches for
English-Persian Transliteration and Back-Transliteration
</title>
<author confidence="0.998065">
Sarvnaz Karimi Falk Scholer Andrew Turpin
</author>
<affiliation confidence="0.895931">
School of Computer Science and Information Technology
RMIT University, GPO Box 2476V, Melbourne 3001, Australia
</affiliation>
<email confidence="0.997784">
{sarvnaz,fscholer,aht}@cs.rmit.edu.au
</email>
<sectionHeader confidence="0.995632" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999821866666667">
We propose a novel algorithm for English
to Persian transliteration. Previous meth-
ods proposed for this language pair apply
a word alignment tool for training. By
contrast, we introduce an alignment algo-
rithm particularly designed for translitera-
tion. Our new model improves the English
to Persian transliteration accuracy by 14%
over an n-gram baseline. We also propose
a novel back-transliteration method for this
language pair, a previously unstudied prob-
lem. Experimental results demonstrate that
our algorithm leads to an absolute improve-
ment of 25% over standard transliteration
approaches.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970551020408">
Translation of a text from a source language to
a target language requires dealing with technical
terms and proper names. These occur in almost
any text, but rarely appear in bilingual dictionar-
ies. The solution is the transliteration of such out-of-
dictionary terms: a word from the source language
is transformed to a word in the target language, pre-
serving its pronunciation. Recovering the original
word from the transliterated target is called back-
transliteration. Automatic transliteration is impor-
tant for many different applications, including ma-
chine translation, cross-lingual information retrieval
and cross-lingual question answering.
Transliteration methods can be categorized into
grapheme-based (AbdulJaleel and Larkey, 2003; Li
et al., 2004), phoneme-based (Knight and Graehl,
1998; Jung et al., 2000), and combined (Bilac and
Tanaka, 2005) approaches. Grapheme-based meth-
ods perform a direct orthographical mapping be-
tween source and target words, while phoneme-
based approaches use an intermediate phonetic rep-
resentation. Both grapheme- or phoneme-based
methods usually begin by breaking the source word
into segments, and then use a source segment to tar-
get segment mapping to generate the target word.
The rules of this mapping are obtained by aligning
already available transliterated word pairs (training
data); alternatively, such rules can be handcrafted.
From this perspective, past work is roughly divided
into those methods which apply a word alignment
tool such as GIZA++ (Och and Ney, 2003), and ap-
proaches that combine the alignment step into their
main transliteration process.
Transliteration is language dependent, and meth-
ods that are effective for one language pair may
not work as well for another. In this paper, we
investigate the English-Persian transliteration prob-
lem. Persian (Farsi) is an Indo-European language,
written in Arabic script from right to left, but with
an extended alphabet and different pronunciation
from Arabic. Our previous approach to English-
Persian transliteration introduced the grapheme-
based collapsed-vowel method, employing GIZA++
for source to target alignment (Karimi et al., 2006).
We propose a new transliteration approach that ex-
tends the collapsed-vowel method. To meet Per-
sian language transliteration requirements, we also
propose a novel alignment algorithm in our training
stage, which makes use of statistical information of
</bodyText>
<page confidence="0.965992">
648
</page>
<note confidence="0.9257695">
Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 648–655,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
</note>
<bodyText confidence="0.99983784">
the corpus, transliteration specifications, and simple
language properties. This approach handles possi-
ble consequences of elision (omission of sounds to
make the word easier to read) and epenthesis (adding
extra sounds to a word to make it fluent) in written
target words that happen due to the change of lan-
guage. Our method shows an absolute accuracy im-
provement of 14.2% over an n-gram baseline.
In addition, we investigate the problem of back-
transliteration from Persian to English. To our
knowledge, this is the first report of such a study.
There are two challenges in Persian to English
transliteration that makes it particularly difficult.
First, written Persian omits short vowels, while only
long vowels appear in texts. Second, monophthon-
gization (changing diphthongs to monophthongs) is
popular among Persian speakers when adapting for-
eign words into their language. To take these into
account, we propose a novel method to form trans-
formation rules by changing the normal segmenta-
tion algorithm. We find that this method signifi-
cantly improves the Persian to English translitera-
tion effectiveness, demonstrating an absolute perfor-
mance gain of 25.1% over standard transliteration
approaches.
</bodyText>
<sectionHeader confidence="0.971096" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.996747819672131">
In general, transliteration consists of a training stage
(running on a bilingual training corpus), and a gen-
eration – also called testing – stage.
The training step of a transliteration develops
transformation rules mapping characters in the
source to characters in the target language using
knowledge of corresponding characters in translit-
erated pairs provided by an alignment. For example,
for the source-target word pair (pat,H Iu), an align-
ment may map “p” to “H” and “a” to “ I”, and the
training stage may develop the rule pa →I, with
as the transliteration of “a” in the context of “pa”.
The generation stage applies these rules on a seg-
mented source word, transforming it to a word in
the target language.
Previous work on transliteration either employs a
word alignment tool (usually GIZA++), or develops
specific alignment strategies. Transliteration meth-
ods that use GIZA++ as their word pair aligner (Ab-
dulJaleel and Larkey, 2003; Virga and Khudanpur,
2003; Karimi et al., 2006) have based their work on
the assumption that the provided alignments are re-
liable. Gao et al. (2004) argue that precise align-
ment can improve transliteration effectiveness, ex-
perimenting on English-Chinese data and compar-
ing IBM models (Brown et al., 1993) with phoneme-
based alignments using direct probabilities.
Other transliteration systems focus on alignment
for transliteration, for example the joint source-
channel model suggested by Li et al. (2004). Their
method outperforms the noisy channel model in
direct orthographical mapping for English-Chinese
transliteration. Li et al. also find that grapheme-
based methods that use the joint source-channel
model are more effective than phoneme-based meth-
ods due to removing the intermediate phonetic
transformation step. Alignment has also been in-
vestigated for transliteration by adopting Coving-
ton’s algorithm on cognate identification (Coving-
ton, 1996); this is a character alignment algorithm
based on matching or skipping of characters, with
a manually assigned cost of association. Coving-
ton considers consonant to consonant and vowel to
vowel correspondence more valid than consonant to
vowel. Kang and Choi (2000) revise this method for
transliteration where a skip is defined as inserting a
null in the target string when two characters do not
match based on their phonetic similarities or their
consonant and vowel nature. Oh and Choi (2002)
revise this method by introducing binding, in which
many to many correspondences are allowed. How-
ever, all of these approaches rely on the manually
assigned penalties that need to be defined for each
possible matching.
In addition, some recent studies investigate dis-
criminative transliteration methods (Klementiev and
Roth, 2006; Zelenko and Aone, 2006) in which each
segment of the source can be aligned to each seg-
ment of the target, where some restrictive conditions
based on the distance of the segments and phonetic
similarities are applied.
</bodyText>
<sectionHeader confidence="0.997616" genericHeader="method">
3 The Proposed Alignment Approach
</sectionHeader>
<bodyText confidence="0.99976325">
We propose an alignment method based on segment
occurrence frequencies, thereby avoiding predefined
matching patterns and penalty assignments. We also
apply the observed tendency of aligning consonants
</bodyText>
<page confidence="0.96661">
649
</page>
<bodyText confidence="0.993007833333334">
to consonants, and vowels to vowels, as a substi- Step 1 (Consonant-Vowel based)
tute for phonetic similarities. Many to many, one to For any word pair (S, T) E B, the corresponding
many, one to null and many to one alignments can reduced consonant-vowel sequences, qS and qT , are
be generated. generated. If the sequences match, then the aligned
3.1 Formulation consonant clusters and vowel sequences are added
Our alignment approach consists of two steps: the to the alignment set A. If qS does not match with
first is based on the consonant and vowel nature qT , the word pair remains unaligned in Step 1.
of the word’s letters, while the second uses a The assumption in this step is that transliteration
frequency-based sequential search. of each vowel sequence of the source is a vowel se-
Definition 1 A bilingual corpus B is the set quence in the target language, and similarly for con-
{(S, T)}, where S = s1..st, T = t1..tm, sz is a sonants. However, consonants do not always map to
letter in the source language alphabet, and tj is a consonants, or vowels to vowels (for example, the
letter in the target language alphabet. English letter “s” may be written as “�I” in Persian
Definition 2 Given some word, w, the consonant- which consists of one vowel and one consonant). Al-
vowel sequence p = (C|V )+ for w is obtained ternatively, they might be omitted altogether, which
by replacing each consonant with C and each vowel can be specified as the null string, ε. We therefore
with V . require a second step.
Definition 3 Given some consonant-vowel se- Step 2 (Frequency based)
quence, p, a reduced consonant-vowel sequence q For most natural languages, the maximum length
replaces all runs of C’s with C, and all runs of V’s of corresponding phonemes of each grapheme is a
with V; hence q = q′|q″, q′ = V(CV)*(C|ǫ) digraph (two letters) or at most a trigraph. Hence,
and q″= C(VC)*(V|ǫ). alignment can be defined as a search problem that
For each natural language word, we can determine seeks for units with a maximum length of two or
the consonant-vowel sequence (p) from which the three in both strings that need to be aligned. In our
reduced consonant-vowel sequence (q) can be de- approach, we search based on statistical occurrence
rived, giving a common notation between two dif- data available from Step 1.
ferent languages, no matter which script either of In Step 2, only those words that remain unaligned
them use. To simplify, semi-vowels and approxi- at the end of Step 1 need to be considered. For each
mants (sounds intermediate between consonants and pair of words (S, T), matching proceeds from left to
vowels, such as “w” and “y” in English) are treated right, examining one of the three possible options of
according to their target language counterparts. transliteration: single letter to single letter, digraph
In general, for all the word pairs (S, T) in a corpus to single letter and single letter to digraph. Trigraphs
B, an alignment can be achieved using the function are unnecessary in alignment as they can be effec-
f : B → A; (S, T) H (S, T�, r). tively captured during transliteration generation, as
The function f maps the word pair (S, T) E B to we explain below.
the triple ( S, T�, r) E A where S� and T� are sub- We define four different valid alignments for the
strings of S and T respectively. The frequency of source (S = s1s2 ... si ... sl) and target (T =
this correspondence is denoted by r. A represents a t1t2 ... tj ... tm) strings: (si, tj, r), (sisi+1, tj, r),
set of substring alignments, and we use a per word (si, tjtj+1, r) and (si, ε, r). These four options are
alignment notation of ae2p when aligning English to considered as the only possible valid alignments,
Persian and ap2e for Persian to English. and the most frequently occurring alignment (high-
3.2 Algorithm Details est r) is chosen. These frequencies are dynamically
Our algorithm consists of two steps. updated after successfully aligning a pair. For ex-
650 ceptional situations, where there is no character in
the target string to match with the source character
si, it is aligned with the empty string.
It is possible that none of the four valid alignment
options have occurred previously (that is, r = 0
for each). This situation can arise in two ways:
first, such a tuple may simply not have occurred in
the training data; and, second, the previous align-
ment in the current string pair may have been incor-
rect. To account for this second possibility, a par-
tial backtracking is considered. Most misalignments
are derived from the simultaneous comparison of
alignment possibilities, giving the highest priority to
the most frequent. For example if S=bbc, T=u�,_r
and A = {(b,u,100),(bb,u,40),(c,,_r,60)}, starting
from the initial position sl and tl, the first alignment
choice is (b,u,101). However immediately after, we
face the problem of aligning the second “b”. There
are two solutions: inserting e and adding the triple
(b,e,1), or backtracking the previous alignment and
substituting that with the less frequent but possible
alignment of (bb,u,41). The second solution is a
better choice as it adds less ambiguous alignments
containing e. At the end, the alignment set is up-
dated as A = {(b,u�,100),(bb,u�,41),(c,,_r,61)}.
In case of equal frequencies, we check possible
subsequent alignments to decide on which align-
ment should be chosen. For example, if (b, u�,100)
and (bb,u,100) both exist as possible options, we
consider if choosing the former leads to a subse-
quent e insertion. If so, we opt for the latter.
At the end of a string, if just one character in the
target string remains unaligned while the last align-
ment is a e insertion, that final alignment will be sub-
stituted for e. This usually happens when the align-
ment of final characters is not yet registered in the
alignment set, mainly because Persian speakers tend
to transliterate the final vowels to consonants to pre-
serve their existence in the word. For example, in
the word “Jose” the final “e” might be transliterated
to “o” which is a consonant (“h”) and therefore is not
captured in Step 1.
Backparsing
The process of aligning words explained above
can handle words with already known components
in the alignment set A (the frequency of occurrence
is greater than zero). However, when this is not the
case, the system may repeatedly insert e while part
or all of the target characters are left intact (unsuc-
cessful alignment). In such cases, processing the
source and target backwards helps to find the prob-
lematic substrings: backparsing.
The poorly aligned substrings of the source and
target are taken as new pairs of strings, which are
then reintroduced into the system as new entries.
Note that they themselves are not subject to back-
parsing. Most strings of repeating nulls can be bro-
ken up this way, and in the worst case will remain as
one tuple in the alignment set.
To clarify, consider the example given in Figure 1.
For the word pair (patricia,uu,S�,_r S1), where an
association between “c” and “�,_r” is not yet regis-
tered. Forward parsing, as shown in the figure, does
not resolve all target characters; after the incorrect
alignment of “c” with “e”, subsequent characters are
also aligned with null, and the substring “ ,_rS1” re-
mains intact. Backward parsing, shown in the next
line of the figure, is also not successful. It is able to
correctly align the last two characters of the string,
before generating repeated null alignments. There-
fore, the central region — substrings of the source
and target which remained unaligned plus one extra
aligned segment to the left and right — is entered
as a new pair to the system (ici,S ,_rS), as shown
in the line labelled Input 2 in the figure. This new
input meets Step 1 requirements, and is aligned suc-
cessfully. The resulting tuples are then merged with
the alignment set A.
An advantage of our backparsing strategy is that
it takes care of casual transliterations happening due
to elision and epenthesis (adding or removing ex-
tra sounds). It is not only in translation that people
may add extra words to make fluent target text; for
transliteration also, it is possible that spurious char-
acters are introduced for fluency. However, this of-
ten follows patterns, such as adding vowels to the
target form. These irregularities are consistently
covered in the backparsing strategy, where they re-
main connected to their previous character.
</bodyText>
<sectionHeader confidence="0.99689" genericHeader="method">
4 Transliteration Method
</sectionHeader>
<bodyText confidence="0.9996162">
Transliteration algorithms use aligned data (the out-
put from the alignment process, ae,, or a,,e align-
ment tuples) for training to derive transformation
rules. These rules are then used to generate a tar-
get word T given a new input source word S.
</bodyText>
<page confidence="0.942442">
651
</page>
<equation confidence="0.886015916666667">
Initial alignment set:
A = {(p,v,42),(a,1,320),(a,e,99),(a,1ø,10),(a,ø,35),(r,P,200),(i,ø,60),(i,e,5),(c,€,80),(c,�-,25),(t, D,51)}
Input: (patricia,vvPø�€ø� qS = CVCVCV q, = CVCV
Step 1: qS =6 q,,
Forward alignment: (p,v,43), (a,e,100), (t,v,52), (r,P,201), (i,ø,61), (c,e,1), (i,e,6), (a,e,100)
Backward alignment: (a,1,321), (i,ø,61), (c,e,1), (i,e,6), (r,e,1), (t,e,1), (a,e,100), (p,e,1)
Input 2: (ici,øk�wø) qS =VCV q, = VCV
(i,ø,61),(c,�€,1), (i,ø,61)
Step 1:
Final Alignment: ae2p
Updated alignment set:
A = {(p,y,43),(a,1,321),(a,e,100),(a,lø,10),(a,ø,35),(r,P,201),(i,ø,62),(i,e,5),(c,€,80),(c,�-,25),(c,€`,1),(t,v,52)}
</equation>
<figureCaption confidence="0.9680195">
Figure 1: A backparsing example. Note middle tuples in forward and backward parsings are not merged in
A till the alignment is successfully completed.
</figureCaption>
<figure confidence="0.4944784">
Method Intermediate Sequence Segment(Pattern) Backoff
Bigram N/A #s, sh, he, el, ll, le, ey s,h,e,l,e,y
CV-MODEL1 CCVCCV sh(CC), hel(CVC), ll(CC), lley(CV) s(C), h(C), e(V), l(C), e(V), y(V)
CV-MODEL2 CCVCCV sh(CC), e(CVC), ll(CC), ey(CV) As Above.
CV-MODEL3 CVCV #sh(C), e(CVC), ll(C), ey(CV) sh(C), s(C), h(C), e(V), l(C), e(V), y(V)
</figure>
<figureCaption confidence="0.9735035">
Figure 2: An example of transliteration for the word pair (shelley,��JS). Underlined characters are actually
transliterated for each segment.
</figureCaption>
<subsectionHeader confidence="0.954012">
4.1 Baseline
</subsectionHeader>
<bodyText confidence="0.99996775">
Most transliteration methods reported in the litera-
ture — either grapheme- or phoneme-based — use
n-grams (AbdulJaleel and Larkey, 2003; Jung et al.,
2000). The n-gram-based methods differ mainly in
the way that words are segmented, both for train-
ing and transliteration generation. A simple n-
gram based method works only on single charac-
ters (unigram) and transformation rules are defined
as si → tj, while an advanced method may take
the surrounding context into account (Jung et al.,
2000). We found that using one past symbol (bigram
model) works better than other n-gram based meth-
ods for English to Persian transliteration (Karimi et
al., 2006).
Our collapsed-vowel methods consider language
knowledge to improve the string segmentation of
n-gram techniques (Karimi et al., 2006). The pro-
cess begins by generating the consonant-vowel se-
quence (Definition 2) of a source word. For ex-
ample, the word “shelley” is represented by the se-
quence p = CCVCCVV. Then, following the col-
lapsed vowel concept (Definition 3), this sequence
becomes “CCVCCV”. These approaches, which
we refer to as CV-MODEL1 and CV-MODEL2 re-
spectively, partition these sequences using basic pat-
terns (C and V) and main patterns (CC, CVC, VC
and CV). In the training phase, transliteration rules
are formed according to the boundaries of the de-
fined patterns and their aligned counterparts (based
on ae2p or ap2e) in the target language word T. Simi-
lar segmentation is applied during the transliteration
generation stage.
</bodyText>
<subsectionHeader confidence="0.970046">
4.2 The Proposed Transliteration Approach
</subsectionHeader>
<bodyText confidence="0.99995075">
The restriction on the context length of consonants
imposed by CV-MODEL1 and CV-MODEL2 makes
the transliteration of consecutive consonants map-
ping to a particular character in the target language
difficult. For example, “ght” in English maps to
only one character in Persian: “u”. Dealing with
languages which have different alphabets, and for
which the number of characters in their alphabets
also differs (such as 26 and 32 for English and Per-
sian), increases the possibility of facing these cases,
especially when moving from the language with
smaller alphabet size to the one with a larger size.
To more effectively address this, we propose a col-
lapsed consonant and vowel method (CV-MODEL3)
which uses the full reduced sequence (Definition 3),
rather than simply reduced vowel sequences. Al-
though recognition of consonant segments is based
on the vowel positions, consonants are considered as
independent blocks in each string. Conversely, vow-
els are transliterated in the context of surrounding
</bodyText>
<page confidence="0.997403">
652
</page>
<bodyText confidence="0.999913966666667">
consonants, as demonstrated in the example below.
A special symbol is used to indicate the start
and/or end of each word if the beginning and end
of the word is a consonant respectively. Therefore,
for the words starting or ending with consonants, the
symbol “#” is added, which is treated as a consonant
and therefore grouped in the consonant segment.
An example of applying this technique is shown in
Figure 2 for the string “shelley”. In this example,
“sh” and “ll” are treated as two consonant segments,
where the transliteration of individual characters in-
side a segment is dependent on the other members
but not the surrounding segments. However, this is
not the case for vowel sequences which incorporate
a level of knowledge about any segment neighbours.
Therefore, for the example “shelley”, the first seg-
ment is “sh” which belongs to C pattern. During
transliteration, if “#sh” does not appear in any ex-
isting rules, a backoff splits the segment to smaller
segments: “#” and “sh”, or “s”and “h”. The second
segment contains the vowel “e”. Since this vowel
is surrounded by consonants, the segment pattern is
CVC. In this case, backoff only applies for vowels as
consonants are supposed to be part of their own in-
dependent segments. That is, if search in the rules of
pattern CVC was unsuccessful, it looks for “e” in V
pattern. Similarly, segmentation for this word con-
tinues with “ll” in C pattern and “ey” in CV pattern
(“y” is an approximant, and therefore considered as
a vowel when transliterating English to Persian).
</bodyText>
<subsectionHeader confidence="0.996899">
4.3 Rules for Back-Transliteration
</subsectionHeader>
<bodyText confidence="0.98850185">
Written Persian ignores short vowels, and only long
vowels appear in text. This causes most English
vowels to disappear when transliterating from En-
glish to Persian; hence, these vowels must be re-
stored during back-transliteration.
When the initial transliteration happens from En-
glish to Persian, the transliterator (whether hu-
man or machine) uses the rules of transliterat-
ing from English as the source language. There-
fore, transliterating back to the original language
should consider the original process, to avoid los-
ing essential information. In terms of segmenta-
tion in collapsed-vowel models, different patterns
define segment boundaries in which vowels are
necessary clues. Although we do not have most
of these vowels in the transliteration generation
phase, it is possible to benefit from their existence
in the training phase. For example, using C V-
MODEL3, the pair (�P¸È,merkel) with qS=C and
produces just one
transformation rule “ P¸È→ merkel” based on a
C pattern. That is, the Persian string contains no
vowel characters. If, during the transliteration gen-
eration phase, a source word “É¿QÓ” (S=�P¸È) is
entered, there would be one and only one output
of “merkel”, while an alternative such as “mercle”
might be required instead. To avoid overfitting the
system by long consonant clusters, we perform seg-
mentation based on the English q sequence, but cate-
gorise the rules based on their Persian segment coun-
terparts. That is, for the pair (�P¸È,merkel) with
these rules
are generated (with category patterns given in paren-
thesis): � → m (C), P¸→ rk (C), È → l (C), �P¸
→ merk (C),P¸È→ rkel (C). We call the suggested
training approach reverse segmentation.
Reverse segmentation avoids clustering all the
consonants in one rule, since many English words
might be transliterated to all-consonant Persian
words.
</bodyText>
<subsectionHeader confidence="0.999611">
4.4 Transliteration Generation and Ranking
</subsectionHeader>
<bodyText confidence="0.99985575">
In the transliteration generation stage, the source
word is segmented following the same process of
segmenting words in training stage, and a probabil-
ity is computed for each generated target word:
</bodyText>
<equation confidence="0.862486">
P( t|�Sk),
</equation>
<bodyText confidence="0.8351235">
where |K |is the number of distinct source seg-
ments. P( �Tk |Sk) is the probability of the �Sk→�Tk
transformation rule, as obtained from the training
stage:
</bodyText>
<equation confidence="0.971472">
P(�Tk|�Sk) = frequency of
</equation>
<bodyText confidence="0.971043666666667">
frequency of Sk ,
where frequency of Sk is the number of its oc-
currence in the transformation rules. We apply a
tree structure, following Dijkstra’s α-shortest path,
to generate the α highest scoring (most probable)
transliterations, ranked based on their probabilities.
</bodyText>
<equation confidence="0.9976024">
|K|
H
k_1
P(T|S) =
�Sk — t
</equation>
<page confidence="0.998569">
653
</page>
<table confidence="0.9998177">
Corpus Baseline CV-MODEL3
Bigram CV-MODEL1 CV-MODEL2 GIZA++ New Alignment
Small Corpus
TOP-1 58.0 (2.2) 61.7 (3.0) 60.0 (3.9) 67.4 (5.5) 72.2 (2.2)
TOP-5 85.6 (3.4) 80.9 (2.2) 86.0 (2.8) 90.9 (2.1) 92.9 (1.6)
TOP-10 89.4 (2.9) 82.0 (2.1) 91.2 (2.5) 93.8 (2.1) 93.5 (1.7)
Large Corpus
TOP-1 47.2 (1.0) 50.6 (2.5) 47.4 (1.0) 55.3 (0.8) 59.8 (1.1)
TOP-5 77.6 (1.4) 79.8 (3.4) 79.2 (1.0) 84.5 (0.7) 85.4 (0.8)
TOP-10 83.3 (1.5) 84.9 (3.1) 87.0 (0.9) 89.5 (0.4) 92.6 (0.7)
</table>
<tableCaption confidence="0.999925">
Table 1: Mean (standard deviation) word accuracy (%) for English to Persian transliteration.
</tableCaption>
<sectionHeader confidence="0.994907" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.998839045454545">
To investigate the effectiveness of CV-MODEL3 and
the new alignment approach on transliteration, we
first compare CV-MODEL3 with baseline systems,
employing GIZA++ for alignment generation during
system training. We then evaluate the same sys-
tems, using our new alignment approach. Back-
transliteration is also investigated, applying both
alignment systems and reverse segmentation. In all
our experiments, we used ten-fold cross-validation.
The statistical significance of different performance
levels are evaluated using a paired t-test. The no-
tation TOP-X indicates the first X transliterations
prodcued by the automatic methods.
We used two corpora of word pairs in English
and Persian: the first, called Large, contains 16,670
word pairs; the second, Small, contains 1,857 word
pairs, and are described fully in our previous paper
(Karimi et al., 2006).
The results of transliteration experiments are eval-
uated using word accuracy (Kang and Choi, 2000)
which measures the proportion of transliterations
that are correct out of the test corpus.
</bodyText>
<subsectionHeader confidence="0.999073">
5.1 Accuracy of Transliteration Approaches
</subsectionHeader>
<bodyText confidence="0.999981565217391">
The results of our experiments for transliterating En-
glish to Persian, using GIZA++ for alignment gen-
eration, are shown in Table 1. CV-MODEL3 out-
performs all three baseline systems significantly in
TOP-1 and TOP-5 results, for both Persian corpora.
TOP-1 results were improved by 9.2% to 16.2%
(p&lt;0.0001, paired t-test) relative to the baseline sys-
tems for the Small corpus. For the Large corpus,
CV-MODEL3 was 9.3% to 17.2% (p&lt;0.0001) more
accurate relative to the baseline systems.
The results of applying our new alignment al-
gorithm are presented in the last column of Ta-
ble 1, comparing word accuracy of CV-MODEL3 us-
ing GIZA++ and the new alignment for English to
Persian transliteration. Transliteration accuracy in-
creases in TOP-1 for both corpora (a relative increase
of 7.1% (p=0.002) for the Small corpus and 8.1%
(p&lt;0.0001) for the Large corpus). The TOP-10 re-
sults of the Large corpus again show a relative in-
crease of 3.5% (p=0.004). Although the new align-
ment also increases the performance for TOP-5 and
TOP-10 of the Small corpus, these increases are not
statistically significant.
</bodyText>
<subsectionHeader confidence="0.999951">
5.2 Accuracy of Back-Transliteration
</subsectionHeader>
<bodyText confidence="0.999824086956522">
The results of back-transliteration are shown in Ta-
ble 2. We first consider performance improvements
gained from using CV-MODEL3: CV-MODEL3 using
GIZA++ outperforms Bigram, CV-MODEL1 and CV-
MODEL2 by 12.8% to 40.7% (p&lt;0.0001) in TOP-
1 for the Small corpus. The corresponding im-
provement for the Large corpus is 12.8% to 74.2%
(p&lt;0.0001).
The fifth column of the table shows the perfor-
mance increase when using CV-MODEL3 with the
new alignment algorithm: for the Large corpus, the
new alignment approach gives a relative increase in
accuracy of 15.5% for TOP-5 (p&lt;0.0001) and 10%
for TOP-10 (p=0.005). The new alignment method
does not show a significant difference using CV-
MODEL3 for the Small corpus.
The final column of Table 2 shows the perfor-
mance of the CV-MODEL3 with the new reverse seg-
mentation approach. Reverse segmentation leads to
a significant improvement over the new alignment
approach in TOP-1 results for the Small corpus by
40.1% (p&lt;0.0001), and 49.4% (p&lt;0.0001) for the
Large corpus.
</bodyText>
<page confidence="0.997182">
654
</page>
<table confidence="0.9998376">
Corpus Bigram CV-MODEL1 CV-MODEL2 CV-MODEL3
GIZA++ New Alignment Reverse
Small Corpus
TOP-1 23.1 (2.0) 28.8 (4.6) 24.9 (2.8) 32.5 (3.6) 34.4 (3.8) 48.2 (2.9)
TOP-5 40.8 (3.1) 51.0 (4.8) 52.9 (3.4) 56.0 (3.5) 54.8 (3.7) 68.1 (4.9)
TOP-10 50.1 (4.1) 58.2 (5.3) 63.2 (3.1) 64.2 (3.2) 63.8 (3.6) 75.7 (4.2)
Large Corpus
TOP-1 10.1 (0.6) 15.6 (1.0) 12.0 (1.0) 17.6 (0.8) 18.0 (1.2) 26.9 (0.7)
TOP-5 20.6 (1.2) 31.7 (0.9) 28.0 (0.7) 36.2 (0.5) 41.8 (1.2) 41.3 (1.7)
TOP-10 27.2 (1.0) 40.1 (1.1) 37.4 (0.8) 46.0 (0.8) 50.6 (1.1) 49.3 (1.6)
</table>
<tableCaption confidence="0.999789">
Table 2: Comparison of mean (standard deviation) word accuracy (%) for Persian to English transliteration.
</tableCaption>
<sectionHeader confidence="0.998956" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99995525">
We have presented a new algorithm for English to
Persian transliteration, and a novel alignment al-
gorithm applicable for transliteration. Our new
transliteration method (CV-MODEL3) outperforms
the previous approaches for English to Persian, in-
creasing word accuracy by a relative 9.2% to 17.2%
(TOP-1), when using GIZA++ for alignment in train-
ing. This method shows further 7.1% to 8.1% in-
crease in word accuracy (TOP-1) with our new align-
ment algorithm.
Persian to English back-transliteration is also in-
vestigated, with CV-MODEL3 significantly outper-
forming other methods. Enriching this model with
a new reverse segmentation algorithm gives rise to
further accuracy gains in comparison to directly ap-
plying English to Persian methods.
In future work we will investigate whether pho-
netic information can help refine our CV-MODEL3,
and experiment with manually constructed rules as
a baseline system.
</bodyText>
<sectionHeader confidence="0.99838" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.984345333333333">
This work was supported in part by the Australian
government IPRS program (SK) and an ARC Dis-
covery Project Grant (AT).
</bodyText>
<sectionHeader confidence="0.999029" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999864018867925">
Nasreen AbdulJaleel and Leah S. Larkey. 2003. Statistical
transliteration for English-Arabic cross language informa-
tion retrieval. In Conference on Information and Knowledge
Management, pages 139–146.
Slaven Bilac and Hozumi Tanaka. 2005. Direct combination
of spelling and pronunciation information for robust back-
transliteration. In Conferences on Computational Linguis-
tics and Intelligent Text Processing, pages 413–424.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra,
and Robert L. Mercer. 1993. The mathematics of statisti-
cal machine translation: Parameter estimation. Computional
Linguistics, 19(2):263–311.
Michael A. Covington. 1996. An algorithm to align
words for historical comparison. Computational Linguistics,
22(4):481–496.
Wei Gao, Kam-Fai Wong, and Wai Lam. 2004. Improving
transliteration with precise alignment of phoneme chunks
and using contextual features. In Asia Information Retrieval
Symposium, pages 106–117.
Sung Young Jung, Sung Lim Hong, and Eunok Paek. 2000. An
English to Korean transliteration model of extended Markov
window. In Conference on Computational Linguistics, pages
383–389.
Byung-Ju Kang and Key-Sun Choi. 2000. Automatic translit-
eration and back-transliteration by decision tree learning. In
Conference on Language Resources and Evaluation, pages
1135–1411.
Sarvnaz Karimi, Andrew Turpin, and Falk Scholer. 2006. En-
glish to Persian transliteration. In String Processing and In-
formation Retrieval, pages 255–266.
Alexandre Klementiev and Dan Roth. 2006. Weakly super-
vised named entity transliteration and discovery from mul-
tilingual comparable corpora. In Association for Computa-
tional Linguistics, pages 817–824.
Kevin Knight and Jonathan Graehl. 1998. Machine translitera-
tion. Computational Linguistics, 24(4):599–612.
Haizhou Li, Min Zhang, and Jian Su. 2004. A joint source-
channel model for machine transliteration. In Association
for Computational Linguistics, pages 159–166.
Franz Josef Och and Hermann Ney. 2003. A systematic com-
parison of various statistical alignment models. Computa-
tional Linguistics, 29(1):19–51.
Jong-Hoon Oh and Key-Sun Choi. 2002. An English-Korean
transliteration model using pronunciation and contextual
rules. In Conference on Computational Linguistics.
Paola Virga and Sanjeev Khudanpur. 2003. Transliteration of
proper names in cross-language applications. In ACMSIGIR
Conference on Research and Development on Information
Retrieval, pages 365–366.
Dmitry Zelenko and Chinatsu Aone. 2006. Discriminative
methods for transliteration. In Proceedings of the 2006 Con-
ference on Empirical Methods in Natural Language Process-
ing., pages 612–617.
</reference>
<page confidence="0.998881">
655
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.799671">
<title confidence="0.9993005">Collapsed Consonant and Vowel Models: New Approaches for English-Persian Transliteration and Back-Transliteration</title>
<author confidence="0.999949">Sarvnaz Karimi Falk Scholer Andrew Turpin</author>
<affiliation confidence="0.999903">School of Computer Science and Information Technology</affiliation>
<address confidence="0.839903">RMIT University, GPO Box 2476V, Melbourne 3001, Australia</address>
<abstract confidence="0.9969425">We propose a novel algorithm for English to Persian transliteration. Previous methods proposed for this language pair apply a word alignment tool for training. By contrast, we introduce an alignment algorithm particularly designed for transliteration. Our new model improves the English to Persian transliteration accuracy by 14% an baseline. We also propose a novel back-transliteration method for this language pair, a previously unstudied problem. Experimental results demonstrate that our algorithm leads to an absolute improvement of 25% over standard transliteration approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nasreen AbdulJaleel</author>
<author>Leah S Larkey</author>
</authors>
<title>Statistical transliteration for English-Arabic cross language information retrieval.</title>
<date>2003</date>
<booktitle>In Conference on Information and Knowledge Management,</booktitle>
<pages>139--146</pages>
<contexts>
<context position="1665" citStr="AbdulJaleel and Larkey, 2003" startWordPosition="226" endWordPosition="229">oper names. These occur in almost any text, but rarely appear in bilingual dictionaries. The solution is the transliteration of such out-ofdictionary terms: a word from the source language is transformed to a word in the target language, preserving its pronunciation. Recovering the original word from the transliterated target is called backtransliteration. Automatic transliteration is important for many different applications, including machine translation, cross-lingual information retrieval and cross-lingual question answering. Transliteration methods can be categorized into grapheme-based (AbdulJaleel and Larkey, 2003; Li et al., 2004), phoneme-based (Knight and Graehl, 1998; Jung et al., 2000), and combined (Bilac and Tanaka, 2005) approaches. Grapheme-based methods perform a direct orthographical mapping between source and target words, while phonemebased approaches use an intermediate phonetic representation. Both grapheme- or phoneme-based methods usually begin by breaking the source word into segments, and then use a source segment to target segment mapping to generate the target word. The rules of this mapping are obtained by aligning already available transliterated word pairs (training data); alter</context>
<context position="5681" citStr="AbdulJaleel and Larkey, 2003" startWordPosition="841" endWordPosition="845">ding characters in transliterated pairs provided by an alignment. For example, for the source-target word pair (pat,H Iu), an alignment may map “p” to “H” and “a” to “ I”, and the training stage may develop the rule pa →I, with as the transliteration of “a” in the context of “pa”. The generation stage applies these rules on a segmented source word, transforming it to a word in the target language. Previous work on transliteration either employs a word alignment tool (usually GIZA++), or develops specific alignment strategies. Transliteration methods that use GIZA++ as their word pair aligner (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Karimi et al., 2006) have based their work on the assumption that the provided alignments are reliable. Gao et al. (2004) argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models (Brown et al., 1993) with phonemebased alignments using direct probabilities. Other transliteration systems focus on alignment for transliteration, for example the joint sourcechannel model suggested by Li et al. (2004). Their method outperforms the noisy channel model in direct orthographical mapping for English</context>
<context position="18006" citStr="AbdulJaleel and Larkey, 2003" startWordPosition="2847" endWordPosition="2850">. Method Intermediate Sequence Segment(Pattern) Backoff Bigram N/A #s, sh, he, el, ll, le, ey s,h,e,l,e,y CV-MODEL1 CCVCCV sh(CC), hel(CVC), ll(CC), lley(CV) s(C), h(C), e(V), l(C), e(V), y(V) CV-MODEL2 CCVCCV sh(CC), e(CVC), ll(CC), ey(CV) As Above. CV-MODEL3 CVCV #sh(C), e(CVC), ll(C), ey(CV) sh(C), s(C), h(C), e(V), l(C), e(V), y(V) Figure 2: An example of transliteration for the word pair (shelley,��JS). Underlined characters are actually transliterated for each segment. 4.1 Baseline Most transliteration methods reported in the literature — either grapheme- or phoneme-based — use n-grams (AbdulJaleel and Larkey, 2003; Jung et al., 2000). The n-gram-based methods differ mainly in the way that words are segmented, both for training and transliteration generation. A simple ngram based method works only on single characters (unigram) and transformation rules are defined as si → tj, while an advanced method may take the surrounding context into account (Jung et al., 2000). We found that using one past symbol (bigram model) works better than other n-gram based methods for English to Persian transliteration (Karimi et al., 2006). Our collapsed-vowel methods consider language knowledge to improve the string segme</context>
</contexts>
<marker>AbdulJaleel, Larkey, 2003</marker>
<rawString>Nasreen AbdulJaleel and Leah S. Larkey. 2003. Statistical transliteration for English-Arabic cross language information retrieval. In Conference on Information and Knowledge Management, pages 139–146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slaven Bilac</author>
<author>Hozumi Tanaka</author>
</authors>
<title>Direct combination of spelling and pronunciation information for robust backtransliteration.</title>
<date>2005</date>
<booktitle>In Conferences on Computational Linguistics and Intelligent Text Processing,</booktitle>
<pages>413--424</pages>
<contexts>
<context position="1782" citStr="Bilac and Tanaka, 2005" startWordPosition="245" endWordPosition="248">on of such out-ofdictionary terms: a word from the source language is transformed to a word in the target language, preserving its pronunciation. Recovering the original word from the transliterated target is called backtransliteration. Automatic transliteration is important for many different applications, including machine translation, cross-lingual information retrieval and cross-lingual question answering. Transliteration methods can be categorized into grapheme-based (AbdulJaleel and Larkey, 2003; Li et al., 2004), phoneme-based (Knight and Graehl, 1998; Jung et al., 2000), and combined (Bilac and Tanaka, 2005) approaches. Grapheme-based methods perform a direct orthographical mapping between source and target words, while phonemebased approaches use an intermediate phonetic representation. Both grapheme- or phoneme-based methods usually begin by breaking the source word into segments, and then use a source segment to target segment mapping to generate the target word. The rules of this mapping are obtained by aligning already available transliterated word pairs (training data); alternatively, such rules can be handcrafted. From this perspective, past work is roughly divided into those methods which</context>
</contexts>
<marker>Bilac, Tanaka, 2005</marker>
<rawString>Slaven Bilac and Hozumi Tanaka. 2005. Direct combination of spelling and pronunciation information for robust backtransliteration. In Conferences on Computational Linguistics and Intelligent Text Processing, pages 413–424.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computional Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="5987" citStr="Brown et al., 1993" startWordPosition="891" endWordPosition="894">e rules on a segmented source word, transforming it to a word in the target language. Previous work on transliteration either employs a word alignment tool (usually GIZA++), or develops specific alignment strategies. Transliteration methods that use GIZA++ as their word pair aligner (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Karimi et al., 2006) have based their work on the assumption that the provided alignments are reliable. Gao et al. (2004) argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models (Brown et al., 1993) with phonemebased alignments using direct probabilities. Other transliteration systems focus on alignment for transliteration, for example the joint sourcechannel model suggested by Li et al. (2004). Their method outperforms the noisy channel model in direct orthographical mapping for English-Chinese transliteration. Li et al. also find that graphemebased methods that use the joint source-channel model are more effective than phoneme-based methods due to removing the intermediate phonetic transformation step. Alignment has also been investigated for transliteration by adopting Covington’s alg</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: Parameter estimation. Computional Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A Covington</author>
</authors>
<title>An algorithm to align words for historical comparison.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>4</issue>
<contexts>
<context position="6637" citStr="Covington, 1996" startWordPosition="983" endWordPosition="985">g direct probabilities. Other transliteration systems focus on alignment for transliteration, for example the joint sourcechannel model suggested by Li et al. (2004). Their method outperforms the noisy channel model in direct orthographical mapping for English-Chinese transliteration. Li et al. also find that graphemebased methods that use the joint source-channel model are more effective than phoneme-based methods due to removing the intermediate phonetic transformation step. Alignment has also been investigated for transliteration by adopting Covington’s algorithm on cognate identification (Covington, 1996); this is a character alignment algorithm based on matching or skipping of characters, with a manually assigned cost of association. Covington considers consonant to consonant and vowel to vowel correspondence more valid than consonant to vowel. Kang and Choi (2000) revise this method for transliteration where a skip is defined as inserting a null in the target string when two characters do not match based on their phonetic similarities or their consonant and vowel nature. Oh and Choi (2002) revise this method by introducing binding, in which many to many correspondences are allowed. However, </context>
</contexts>
<marker>Covington, 1996</marker>
<rawString>Michael A. Covington. 1996. An algorithm to align words for historical comparison. Computational Linguistics, 22(4):481–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Gao</author>
<author>Kam-Fai Wong</author>
<author>Wai Lam</author>
</authors>
<title>Improving transliteration with precise alignment of phoneme chunks and using contextual features.</title>
<date>2004</date>
<booktitle>In Asia Information Retrieval Symposium,</booktitle>
<pages>106--117</pages>
<contexts>
<context position="5831" citStr="Gao et al. (2004)" startWordPosition="868" endWordPosition="871">” to “ I”, and the training stage may develop the rule pa →I, with as the transliteration of “a” in the context of “pa”. The generation stage applies these rules on a segmented source word, transforming it to a word in the target language. Previous work on transliteration either employs a word alignment tool (usually GIZA++), or develops specific alignment strategies. Transliteration methods that use GIZA++ as their word pair aligner (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Karimi et al., 2006) have based their work on the assumption that the provided alignments are reliable. Gao et al. (2004) argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models (Brown et al., 1993) with phonemebased alignments using direct probabilities. Other transliteration systems focus on alignment for transliteration, for example the joint sourcechannel model suggested by Li et al. (2004). Their method outperforms the noisy channel model in direct orthographical mapping for English-Chinese transliteration. Li et al. also find that graphemebased methods that use the joint source-channel model are more effective than phoneme-based</context>
</contexts>
<marker>Gao, Wong, Lam, 2004</marker>
<rawString>Wei Gao, Kam-Fai Wong, and Wai Lam. 2004. Improving transliteration with precise alignment of phoneme chunks and using contextual features. In Asia Information Retrieval Symposium, pages 106–117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sung Young Jung</author>
<author>Sung Lim Hong</author>
<author>Eunok Paek</author>
</authors>
<title>An English to Korean transliteration model of extended Markov window.</title>
<date>2000</date>
<booktitle>In Conference on Computational Linguistics,</booktitle>
<pages>383--389</pages>
<contexts>
<context position="1743" citStr="Jung et al., 2000" startWordPosition="239" endWordPosition="242"> The solution is the transliteration of such out-ofdictionary terms: a word from the source language is transformed to a word in the target language, preserving its pronunciation. Recovering the original word from the transliterated target is called backtransliteration. Automatic transliteration is important for many different applications, including machine translation, cross-lingual information retrieval and cross-lingual question answering. Transliteration methods can be categorized into grapheme-based (AbdulJaleel and Larkey, 2003; Li et al., 2004), phoneme-based (Knight and Graehl, 1998; Jung et al., 2000), and combined (Bilac and Tanaka, 2005) approaches. Grapheme-based methods perform a direct orthographical mapping between source and target words, while phonemebased approaches use an intermediate phonetic representation. Both grapheme- or phoneme-based methods usually begin by breaking the source word into segments, and then use a source segment to target segment mapping to generate the target word. The rules of this mapping are obtained by aligning already available transliterated word pairs (training data); alternatively, such rules can be handcrafted. From this perspective, past work is r</context>
<context position="18026" citStr="Jung et al., 2000" startWordPosition="2851" endWordPosition="2854"> Segment(Pattern) Backoff Bigram N/A #s, sh, he, el, ll, le, ey s,h,e,l,e,y CV-MODEL1 CCVCCV sh(CC), hel(CVC), ll(CC), lley(CV) s(C), h(C), e(V), l(C), e(V), y(V) CV-MODEL2 CCVCCV sh(CC), e(CVC), ll(CC), ey(CV) As Above. CV-MODEL3 CVCV #sh(C), e(CVC), ll(C), ey(CV) sh(C), s(C), h(C), e(V), l(C), e(V), y(V) Figure 2: An example of transliteration for the word pair (shelley,��JS). Underlined characters are actually transliterated for each segment. 4.1 Baseline Most transliteration methods reported in the literature — either grapheme- or phoneme-based — use n-grams (AbdulJaleel and Larkey, 2003; Jung et al., 2000). The n-gram-based methods differ mainly in the way that words are segmented, both for training and transliteration generation. A simple ngram based method works only on single characters (unigram) and transformation rules are defined as si → tj, while an advanced method may take the surrounding context into account (Jung et al., 2000). We found that using one past symbol (bigram model) works better than other n-gram based methods for English to Persian transliteration (Karimi et al., 2006). Our collapsed-vowel methods consider language knowledge to improve the string segmentation of n-gram te</context>
</contexts>
<marker>Jung, Hong, Paek, 2000</marker>
<rawString>Sung Young Jung, Sung Lim Hong, and Eunok Paek. 2000. An English to Korean transliteration model of extended Markov window. In Conference on Computational Linguistics, pages 383–389.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Byung-Ju Kang</author>
<author>Key-Sun Choi</author>
</authors>
<title>Automatic transliteration and back-transliteration by decision tree learning.</title>
<date>2000</date>
<booktitle>In Conference on Language Resources and Evaluation,</booktitle>
<pages>1135--1411</pages>
<contexts>
<context position="6903" citStr="Kang and Choi (2000)" startWordPosition="1023" endWordPosition="1026">hinese transliteration. Li et al. also find that graphemebased methods that use the joint source-channel model are more effective than phoneme-based methods due to removing the intermediate phonetic transformation step. Alignment has also been investigated for transliteration by adopting Covington’s algorithm on cognate identification (Covington, 1996); this is a character alignment algorithm based on matching or skipping of characters, with a manually assigned cost of association. Covington considers consonant to consonant and vowel to vowel correspondence more valid than consonant to vowel. Kang and Choi (2000) revise this method for transliteration where a skip is defined as inserting a null in the target string when two characters do not match based on their phonetic similarities or their consonant and vowel nature. Oh and Choi (2002) revise this method by introducing binding, in which many to many correspondences are allowed. However, all of these approaches rely on the manually assigned penalties that need to be defined for each possible matching. In addition, some recent studies investigate discriminative transliteration methods (Klementiev and Roth, 2006; Zelenko and Aone, 2006) in which each </context>
<context position="26076" citStr="Kang and Choi, 2000" startWordPosition="4138" endWordPosition="4141">h alignment systems and reverse segmentation. In all our experiments, we used ten-fold cross-validation. The statistical significance of different performance levels are evaluated using a paired t-test. The notation TOP-X indicates the first X transliterations prodcued by the automatic methods. We used two corpora of word pairs in English and Persian: the first, called Large, contains 16,670 word pairs; the second, Small, contains 1,857 word pairs, and are described fully in our previous paper (Karimi et al., 2006). The results of transliteration experiments are evaluated using word accuracy (Kang and Choi, 2000) which measures the proportion of transliterations that are correct out of the test corpus. 5.1 Accuracy of Transliteration Approaches The results of our experiments for transliterating English to Persian, using GIZA++ for alignment generation, are shown in Table 1. CV-MODEL3 outperforms all three baseline systems significantly in TOP-1 and TOP-5 results, for both Persian corpora. TOP-1 results were improved by 9.2% to 16.2% (p&lt;0.0001, paired t-test) relative to the baseline systems for the Small corpus. For the Large corpus, CV-MODEL3 was 9.3% to 17.2% (p&lt;0.0001) more accurate relative to the</context>
</contexts>
<marker>Kang, Choi, 2000</marker>
<rawString>Byung-Ju Kang and Key-Sun Choi. 2000. Automatic transliteration and back-transliteration by decision tree learning. In Conference on Language Resources and Evaluation, pages 1135–1411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sarvnaz Karimi</author>
<author>Andrew Turpin</author>
<author>Falk Scholer</author>
</authors>
<title>English to Persian transliteration.</title>
<date>2006</date>
<booktitle>In String Processing and Information Retrieval,</booktitle>
<pages>255--266</pages>
<contexts>
<context position="3076" citStr="Karimi et al., 2006" startWordPosition="438" endWordPosition="441">aches that combine the alignment step into their main transliteration process. Transliteration is language dependent, and methods that are effective for one language pair may not work as well for another. In this paper, we investigate the English-Persian transliteration problem. Persian (Farsi) is an Indo-European language, written in Arabic script from right to left, but with an extended alphabet and different pronunciation from Arabic. Our previous approach to EnglishPersian transliteration introduced the graphemebased collapsed-vowel method, employing GIZA++ for source to target alignment (Karimi et al., 2006). We propose a new transliteration approach that extends the collapsed-vowel method. To meet Persian language transliteration requirements, we also propose a novel alignment algorithm in our training stage, which makes use of statistical information of 648 Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 648–655, Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics the corpus, transliteration specifications, and simple language properties. This approach handles possible consequences of elision (omission of sounds to ma</context>
<context position="5730" citStr="Karimi et al., 2006" startWordPosition="850" endWordPosition="853">ignment. For example, for the source-target word pair (pat,H Iu), an alignment may map “p” to “H” and “a” to “ I”, and the training stage may develop the rule pa →I, with as the transliteration of “a” in the context of “pa”. The generation stage applies these rules on a segmented source word, transforming it to a word in the target language. Previous work on transliteration either employs a word alignment tool (usually GIZA++), or develops specific alignment strategies. Transliteration methods that use GIZA++ as their word pair aligner (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Karimi et al., 2006) have based their work on the assumption that the provided alignments are reliable. Gao et al. (2004) argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models (Brown et al., 1993) with phonemebased alignments using direct probabilities. Other transliteration systems focus on alignment for transliteration, for example the joint sourcechannel model suggested by Li et al. (2004). Their method outperforms the noisy channel model in direct orthographical mapping for English-Chinese transliteration. Li et al. also find tha</context>
<context position="18521" citStr="Karimi et al., 2006" startWordPosition="2933" endWordPosition="2936">eported in the literature — either grapheme- or phoneme-based — use n-grams (AbdulJaleel and Larkey, 2003; Jung et al., 2000). The n-gram-based methods differ mainly in the way that words are segmented, both for training and transliteration generation. A simple ngram based method works only on single characters (unigram) and transformation rules are defined as si → tj, while an advanced method may take the surrounding context into account (Jung et al., 2000). We found that using one past symbol (bigram model) works better than other n-gram based methods for English to Persian transliteration (Karimi et al., 2006). Our collapsed-vowel methods consider language knowledge to improve the string segmentation of n-gram techniques (Karimi et al., 2006). The process begins by generating the consonant-vowel sequence (Definition 2) of a source word. For example, the word “shelley” is represented by the sequence p = CCVCCVV. Then, following the collapsed vowel concept (Definition 3), this sequence becomes “CCVCCV”. These approaches, which we refer to as CV-MODEL1 and CV-MODEL2 respectively, partition these sequences using basic patterns (C and V) and main patterns (CC, CVC, VC and CV). In the training phase, tra</context>
<context position="25976" citStr="Karimi et al., 2006" startWordPosition="4123" endWordPosition="4126">me systems, using our new alignment approach. Backtransliteration is also investigated, applying both alignment systems and reverse segmentation. In all our experiments, we used ten-fold cross-validation. The statistical significance of different performance levels are evaluated using a paired t-test. The notation TOP-X indicates the first X transliterations prodcued by the automatic methods. We used two corpora of word pairs in English and Persian: the first, called Large, contains 16,670 word pairs; the second, Small, contains 1,857 word pairs, and are described fully in our previous paper (Karimi et al., 2006). The results of transliteration experiments are evaluated using word accuracy (Kang and Choi, 2000) which measures the proportion of transliterations that are correct out of the test corpus. 5.1 Accuracy of Transliteration Approaches The results of our experiments for transliterating English to Persian, using GIZA++ for alignment generation, are shown in Table 1. CV-MODEL3 outperforms all three baseline systems significantly in TOP-1 and TOP-5 results, for both Persian corpora. TOP-1 results were improved by 9.2% to 16.2% (p&lt;0.0001, paired t-test) relative to the baseline systems for the Smal</context>
</contexts>
<marker>Karimi, Turpin, Scholer, 2006</marker>
<rawString>Sarvnaz Karimi, Andrew Turpin, and Falk Scholer. 2006. English to Persian transliteration. In String Processing and Information Retrieval, pages 255–266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Dan Roth</author>
</authors>
<title>Weakly supervised named entity transliteration and discovery from multilingual comparable corpora.</title>
<date>2006</date>
<booktitle>In Association for Computational Linguistics,</booktitle>
<pages>817--824</pages>
<contexts>
<context position="7463" citStr="Klementiev and Roth, 2006" startWordPosition="1111" endWordPosition="1114">pondence more valid than consonant to vowel. Kang and Choi (2000) revise this method for transliteration where a skip is defined as inserting a null in the target string when two characters do not match based on their phonetic similarities or their consonant and vowel nature. Oh and Choi (2002) revise this method by introducing binding, in which many to many correspondences are allowed. However, all of these approaches rely on the manually assigned penalties that need to be defined for each possible matching. In addition, some recent studies investigate discriminative transliteration methods (Klementiev and Roth, 2006; Zelenko and Aone, 2006) in which each segment of the source can be aligned to each segment of the target, where some restrictive conditions based on the distance of the segments and phonetic similarities are applied. 3 The Proposed Alignment Approach We propose an alignment method based on segment occurrence frequencies, thereby avoiding predefined matching patterns and penalty assignments. We also apply the observed tendency of aligning consonants 649 to consonants, and vowels to vowels, as a substi- Step 1 (Consonant-Vowel based) tute for phonetic similarities. Many to many, one to For any</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>Alexandre Klementiev and Dan Roth. 2006. Weakly supervised named entity transliteration and discovery from multilingual comparable corpora. In Association for Computational Linguistics, pages 817–824.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
<author>Jonathan Graehl</author>
</authors>
<date>1998</date>
<booktitle>Machine transliteration. Computational Linguistics,</booktitle>
<pages>24--4</pages>
<contexts>
<context position="1723" citStr="Knight and Graehl, 1998" startWordPosition="235" endWordPosition="238">n bilingual dictionaries. The solution is the transliteration of such out-ofdictionary terms: a word from the source language is transformed to a word in the target language, preserving its pronunciation. Recovering the original word from the transliterated target is called backtransliteration. Automatic transliteration is important for many different applications, including machine translation, cross-lingual information retrieval and cross-lingual question answering. Transliteration methods can be categorized into grapheme-based (AbdulJaleel and Larkey, 2003; Li et al., 2004), phoneme-based (Knight and Graehl, 1998; Jung et al., 2000), and combined (Bilac and Tanaka, 2005) approaches. Grapheme-based methods perform a direct orthographical mapping between source and target words, while phonemebased approaches use an intermediate phonetic representation. Both grapheme- or phoneme-based methods usually begin by breaking the source word into segments, and then use a source segment to target segment mapping to generate the target word. The rules of this mapping are obtained by aligning already available transliterated word pairs (training data); alternatively, such rules can be handcrafted. From this perspec</context>
</contexts>
<marker>Knight, Graehl, 1998</marker>
<rawString>Kevin Knight and Jonathan Graehl. 1998. Machine transliteration. Computational Linguistics, 24(4):599–612.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haizhou Li</author>
<author>Min Zhang</author>
<author>Jian Su</author>
</authors>
<title>A joint sourcechannel model for machine transliteration.</title>
<date>2004</date>
<booktitle>In Association for Computational Linguistics,</booktitle>
<pages>159--166</pages>
<contexts>
<context position="1683" citStr="Li et al., 2004" startWordPosition="230" endWordPosition="233">ost any text, but rarely appear in bilingual dictionaries. The solution is the transliteration of such out-ofdictionary terms: a word from the source language is transformed to a word in the target language, preserving its pronunciation. Recovering the original word from the transliterated target is called backtransliteration. Automatic transliteration is important for many different applications, including machine translation, cross-lingual information retrieval and cross-lingual question answering. Transliteration methods can be categorized into grapheme-based (AbdulJaleel and Larkey, 2003; Li et al., 2004), phoneme-based (Knight and Graehl, 1998; Jung et al., 2000), and combined (Bilac and Tanaka, 2005) approaches. Grapheme-based methods perform a direct orthographical mapping between source and target words, while phonemebased approaches use an intermediate phonetic representation. Both grapheme- or phoneme-based methods usually begin by breaking the source word into segments, and then use a source segment to target segment mapping to generate the target word. The rules of this mapping are obtained by aligning already available transliterated word pairs (training data); alternatively, such rul</context>
<context position="6186" citStr="Li et al. (2004)" startWordPosition="919" endWordPosition="922">nt strategies. Transliteration methods that use GIZA++ as their word pair aligner (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Karimi et al., 2006) have based their work on the assumption that the provided alignments are reliable. Gao et al. (2004) argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models (Brown et al., 1993) with phonemebased alignments using direct probabilities. Other transliteration systems focus on alignment for transliteration, for example the joint sourcechannel model suggested by Li et al. (2004). Their method outperforms the noisy channel model in direct orthographical mapping for English-Chinese transliteration. Li et al. also find that graphemebased methods that use the joint source-channel model are more effective than phoneme-based methods due to removing the intermediate phonetic transformation step. Alignment has also been investigated for transliteration by adopting Covington’s algorithm on cognate identification (Covington, 1996); this is a character alignment algorithm based on matching or skipping of characters, with a manually assigned cost of association. Covington consid</context>
</contexts>
<marker>Li, Zhang, Su, 2004</marker>
<rawString>Haizhou Li, Min Zhang, and Jian Su. 2004. A joint sourcechannel model for machine transliteration. In Association for Computational Linguistics, pages 159–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="2445" citStr="Och and Ney, 2003" startWordPosition="346" endWordPosition="349"> direct orthographical mapping between source and target words, while phonemebased approaches use an intermediate phonetic representation. Both grapheme- or phoneme-based methods usually begin by breaking the source word into segments, and then use a source segment to target segment mapping to generate the target word. The rules of this mapping are obtained by aligning already available transliterated word pairs (training data); alternatively, such rules can be handcrafted. From this perspective, past work is roughly divided into those methods which apply a word alignment tool such as GIZA++ (Och and Ney, 2003), and approaches that combine the alignment step into their main transliteration process. Transliteration is language dependent, and methods that are effective for one language pair may not work as well for another. In this paper, we investigate the English-Persian transliteration problem. Persian (Farsi) is an Indo-European language, written in Arabic script from right to left, but with an extended alphabet and different pronunciation from Arabic. Our previous approach to EnglishPersian transliteration introduced the graphemebased collapsed-vowel method, employing GIZA++ for source to target </context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, 29(1):19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Key-Sun Choi</author>
</authors>
<title>An English-Korean transliteration model using pronunciation and contextual rules.</title>
<date>2002</date>
<booktitle>In Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="7133" citStr="Oh and Choi (2002)" startWordPosition="1062" endWordPosition="1065">s also been investigated for transliteration by adopting Covington’s algorithm on cognate identification (Covington, 1996); this is a character alignment algorithm based on matching or skipping of characters, with a manually assigned cost of association. Covington considers consonant to consonant and vowel to vowel correspondence more valid than consonant to vowel. Kang and Choi (2000) revise this method for transliteration where a skip is defined as inserting a null in the target string when two characters do not match based on their phonetic similarities or their consonant and vowel nature. Oh and Choi (2002) revise this method by introducing binding, in which many to many correspondences are allowed. However, all of these approaches rely on the manually assigned penalties that need to be defined for each possible matching. In addition, some recent studies investigate discriminative transliteration methods (Klementiev and Roth, 2006; Zelenko and Aone, 2006) in which each segment of the source can be aligned to each segment of the target, where some restrictive conditions based on the distance of the segments and phonetic similarities are applied. 3 The Proposed Alignment Approach We propose an ali</context>
</contexts>
<marker>Oh, Choi, 2002</marker>
<rawString>Jong-Hoon Oh and Key-Sun Choi. 2002. An English-Korean transliteration model using pronunciation and contextual rules. In Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Virga</author>
<author>Sanjeev Khudanpur</author>
</authors>
<title>Transliteration of proper names in cross-language applications.</title>
<date>2003</date>
<booktitle>In ACMSIGIR Conference on Research and Development on Information Retrieval,</booktitle>
<pages>365--366</pages>
<contexts>
<context position="5708" citStr="Virga and Khudanpur, 2003" startWordPosition="846" endWordPosition="849">ted pairs provided by an alignment. For example, for the source-target word pair (pat,H Iu), an alignment may map “p” to “H” and “a” to “ I”, and the training stage may develop the rule pa →I, with as the transliteration of “a” in the context of “pa”. The generation stage applies these rules on a segmented source word, transforming it to a word in the target language. Previous work on transliteration either employs a word alignment tool (usually GIZA++), or develops specific alignment strategies. Transliteration methods that use GIZA++ as their word pair aligner (AbdulJaleel and Larkey, 2003; Virga and Khudanpur, 2003; Karimi et al., 2006) have based their work on the assumption that the provided alignments are reliable. Gao et al. (2004) argue that precise alignment can improve transliteration effectiveness, experimenting on English-Chinese data and comparing IBM models (Brown et al., 1993) with phonemebased alignments using direct probabilities. Other transliteration systems focus on alignment for transliteration, for example the joint sourcechannel model suggested by Li et al. (2004). Their method outperforms the noisy channel model in direct orthographical mapping for English-Chinese transliteration. L</context>
</contexts>
<marker>Virga, Khudanpur, 2003</marker>
<rawString>Paola Virga and Sanjeev Khudanpur. 2003. Transliteration of proper names in cross-language applications. In ACMSIGIR Conference on Research and Development on Information Retrieval, pages 365–366.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Zelenko</author>
<author>Chinatsu Aone</author>
</authors>
<title>Discriminative methods for transliteration.</title>
<date>2006</date>
<booktitle>In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing.,</booktitle>
<pages>612--617</pages>
<contexts>
<context position="7488" citStr="Zelenko and Aone, 2006" startWordPosition="1115" endWordPosition="1118">nsonant to vowel. Kang and Choi (2000) revise this method for transliteration where a skip is defined as inserting a null in the target string when two characters do not match based on their phonetic similarities or their consonant and vowel nature. Oh and Choi (2002) revise this method by introducing binding, in which many to many correspondences are allowed. However, all of these approaches rely on the manually assigned penalties that need to be defined for each possible matching. In addition, some recent studies investigate discriminative transliteration methods (Klementiev and Roth, 2006; Zelenko and Aone, 2006) in which each segment of the source can be aligned to each segment of the target, where some restrictive conditions based on the distance of the segments and phonetic similarities are applied. 3 The Proposed Alignment Approach We propose an alignment method based on segment occurrence frequencies, thereby avoiding predefined matching patterns and penalty assignments. We also apply the observed tendency of aligning consonants 649 to consonants, and vowels to vowels, as a substi- Step 1 (Consonant-Vowel based) tute for phonetic similarities. Many to many, one to For any word pair (S, T) E B, th</context>
</contexts>
<marker>Zelenko, Aone, 2006</marker>
<rawString>Dmitry Zelenko and Chinatsu Aone. 2006. Discriminative methods for transliteration. In Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing., pages 612–617.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>