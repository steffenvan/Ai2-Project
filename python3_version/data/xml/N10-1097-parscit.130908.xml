<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.007179">
<title confidence="0.965932">
Making Conversational Structure Explicit:
Identification of Initiation-response Pairs within Online Discussions
</title>
<author confidence="0.997958">
Yi-Chia Wang Carolyn P. Rosé
</author>
<affiliation confidence="0.950635">
Language Technologies Institute Language Technologies Institute
Carnegie Mellon University Carnegie Mellon University
Pittsburgh, PA 15213, USA Pittsburgh, PA 15213, USA
</affiliation>
<email confidence="0.99779">
yichiaw@cs.cmu.edu cprose@cs.cmu.edu
</email>
<sectionHeader confidence="0.995044" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9954219375">
In this paper we investigate how to identify
initiation-response pairs in asynchronous,
multi-threaded, multi-party conversations.
We formulate the task of identifying initia-
tion-response pairs as a pairwise ranking
problem. A novel variant of Latent Semantic
Analysis (LSA) is proposed to overcome a li-
mitation of standard LSA models, namely that
uncommon words, which are critical for sig-
naling initiation-response links, tend to be
deemphasized as it is the more frequent terms
that end up closer to the latent factors selected
through singular value decomposition. We
present experimental results demonstrating
significantly better performance of the novel
variant of LSA over standard LSA.
</bodyText>
<sectionHeader confidence="0.998781" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999935210526316">
In recent years, research in the analysis of social
media (e.g., weblogs, discussion boards, and mes-
sengers) has grown in popularity. Unlike exposito-
ry text, the data produced through use of social
media is often conversational, multi-threaded, and
more complex because of the involvement of nu-
merous participants who are distributed both across
time and across space. Recovering the multi-
threaded structure is an active area of research.
In this paper, we form the foundation for a
broader study of this type of data by investigating
the basic unit of interaction, referred to as an initi-
ation-response pair (Schegloff, 2007). Initiation-
response pairs are pairs of utterances that are typi-
cally contributed by different participants, and
where the first pair part sets up an expectation for
the second pair part. Types of common initiation-
response pairs include question-answer, assess-
ment-agreement, blame-denial, etc. Note that al-
though sometimes discussion forum interfaces
make the thread structure of the interaction expli-
cit, these affordances are not always present. And
even in forums that have these affordances, the
apparent structure of the discourse as represented
through the interface may not capture all of the
contingencies between contributions in the unfold-
ing conversation. Thus, the goal of this investiga-
tion is to investigate approaches for automatically
identifying initiation-response pairs in conversa-
tions.
One of the challenges in identifying initiation-
response pairs is that the related messages are not
necessarily adjacent to each other in the stream of
contributed messages, especially within the asyn-
chronous environment of social media. Further-
more, individual differences related to writing style
or creative expression of self may also complicate
the identification of the intended connections be-
tween contributions. Identification of initiation-
response pairs is an important step towards auto-
matic processing of conversational data. One po-
tential application of this work is conversation
summarization. A summary should include both
the initiation and response as a coherent unit or it
may fail to capture the intended meaning.
We formulate the task of identifying initiation-
response pairs as a pairwise ranking problem. The
goal is to distinguish message pairs that constitute
an initiation-response pair from those that do not.
We believe a ranking approach, where the degree
of relatedness between a message pair can be con-
sidered in light of the relatedness between each of
them and the surrounding messages within the
same thread, is a more suitable paradigm for this
task than a discrete classification-based paradigm.
Previous work on recovering conversational
structure has relied on simple lexical cohesion
</bodyText>
<page confidence="0.98625">
673
</page>
<subsubsectionHeader confidence="0.578312">
Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 673–676,
</subsubsectionHeader>
<subsectionHeader confidence="0.276913">
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.9994954">
measures (i.e., cosine similarity), temporal infor-
mation (Lewis and Knowles, 1997; Wang et al.,
2008), and meta-data (Minkov et al., 2006). How-
ever, relatively little work has investigated the im-
portance of specifically in-focus connections
between initiation-response pairs and utilized them
as clues for the task. Consider, for example, the
following excerpt discussing whether congress
should pass a bill requiring the use of smaller cars
to save the environment:
</bodyText>
<listItem confidence="0.8362574">
a) Regressing to smaller vehicles would discourage
business from producing more pollution.
b) If CO2 emissions are lowered, wouldn&apos;t tax revenues
be lowered as well? Are the democrats going to wil-
lingly give up Medicaid and social security?
</listItem>
<bodyText confidence="0.999519142857143">
Although segment (b) is a reply to segment (a), the
amount of word overlap is minimal. Nonetheless,
we can determine that (b) is a response to (a) by
recognizing the in-focus connections, such as &amp;quot;ve-
hicles-CO2&amp;quot; and &amp;quot;pollution-CO2.&amp;quot; To properly
account for connections between initiations and
responses, we introduce a novel variant of Latent
Semantic Analysis (LSA) into our ranking model.
In section 2, we describe the Usenet data and
how we extract a large corpus of initiation-
response pairs from it. Section 3 explains our rank-
ing model as well as the proposed novel LSA vari-
ation. The experimental results and discussion are
detailed in Section 4 and Section 5, respectively.
</bodyText>
<sectionHeader confidence="0.526471" genericHeader="introduction">
2 Usenet and Generation of Data
</sectionHeader>
<bodyText confidence="0.999979928571429">
The experiment for this paper was conducted using
data crawled from the alt.politics.usa Usenet (User
Network) discussion forum, including all posts
from the period between June 2003 and June 2008.
The resulting set contains 784,708 posts. The posts
in this dataset also contain meta-data that makes
parent-child relationships explicit (i.e., through the
References field). Thus, we know 625,116 of the
posts are explicit responses to others posts. The
messages are organized into a total of 77,985 dis-
cussion threads, each of which has 2 or more posts.
In order to evaluate the quality of using the ex-
plicit reply structure as our gold standard for initia-
tion-response links, we asked human judges to
annotate the response structure of a random-
selected medium-length discussion (19 posts)
where we had removed the meta-data that indi-
cated the initiation-reply structure. The result
shows the accuracy of our gold standard is 0.89.
To set up the data as a pairwise ranking prob-
lem, we arranged the posts in the corpus into in-
stances containing three messages each, one of
which is a response message, one of which is the
actual initiating message, and the other of which is
a foil selected from the same thread. The idea is
that the ranking model will be trained to prefer the
actual initiating message in contrast to the foil.
The grain size of our examples is finer than
whole messages. More specifically, positive exam-
ples are pairs of spans of text that have an initia-
tion-reply relationship. We began the process with
pairs of messages where the meta-data indicates
that an initiation-reply relationship exits, but we
didn’t stop there. For our task it is important to
narrow down to the specific spans of text that have
the initiation-response relation. For this, we used
the indication of quoted material within a message.
We observed that when users explicitly quote a
portion of a previously posted message, the portion
of text immediately following the quoted material
tends to have an explicit discourse connection with
it. Consider the following example:
</bodyText>
<construct confidence="0.808593555555556">
&gt;&gt; Why is the quality of life of the child, mother,
&gt;&gt; and society at large, more important than the
&gt;&gt; sanctity of life?
&gt; Because in the case of anencephaly at least,
&gt; the life is ended before it begins.
We disagree on this point. Why do you refuse to
provide your very own positive definition of life?
Do you believe life begins before birth? At birth?
After birth? Never?
</construct>
<bodyText confidence="0.9998681">
In this thread, the reply expresses an opinion
against the first level quote, but not the second lev-
el quote. Thus, we used segments of text with sin-
gle quotes as an initiation and the immediately
following non-quoted text as the response. We ex-
tracted positive examples by scanning each post to
locate the first level quote that is immediately fol-
lowed by unquoted content. If such quoted material
was found, the quoted material and the unquoted
response were both extracted to form a positive
example. Otherwise, the message was discarded.
For each post P where we extracted a positive
example, we also extracted a negative example by
picking a random post R from the same thread as
P. We selected the negative example in such a way
to make the task difficult in a realistic way. Choos-
ing R from other threads would make the task too
easy because the topics of P and R would most
likely be different. We also stipulated that R cannot
be the parent, grandparent, sibling, or child of P.
</bodyText>
<page confidence="0.996235">
674
</page>
<bodyText confidence="0.995918909090909">
Together the non-quoted text of P and R forms a
negative instance. Thus, the final dataset consists
of pairs of message pairs ((pi, pj), (pi, pk)), where
they have the same reply message pi, and pj is the
correct quote message of pi, but pk is not. In other
words, (pi, pj) is considered as a positive example;
(pi, pk) is a negative example. We constructed a
total of 100,028 instances for our dataset, 10,000
(~10%) of which were used for testing, and 90,028
(~90%) of which were the learning set used to con-
struct the LSA space described in the next section.
</bodyText>
<sectionHeader confidence="0.961454" genericHeader="method">
3 Ranking Models for Identification of
Initiation-Response Pairs
</sectionHeader>
<bodyText confidence="0.999372625">
Our pairwise ranking model1 takes as input an or-
dered pair of message pairs ((pi, pj), (pi, pk)) and
computes their relatedness using a similarity func-
tion sim. Specifically,
( xij, xik ) = ( sim (pi, pj), sim (pi, pk) )
where xij is the similarity value between post pi and
pj; xik is the similarity value between post pi and pk.
To determine which of the two message pairs ranks
higher regarding initiation-response relatedness,
we use the following scoring function to compare
their corresponding similarity values:
score (xij, xik) = xij – xik
If the score is positive, the model ranks (pi, pj)
higher than (pi, pk) and vice versa. A message pair
ranked higher means it has more evidence of being
an initiation-reply link, compared to the other pair.
</bodyText>
<subsectionHeader confidence="0.997162">
3.1 Alternative Similarity Functions
</subsectionHeader>
<bodyText confidence="0.977316083333333">
We introduce and motivate 3 alternative similarity
functions, where the first two are considered as
baseline approaches and the third one is a novel
variation of LSA. We argue that the proposed LSA
variation is an appropriate semantic similarity
measurement for identifying topic continuation and
initiation-reply pairs in online discussions.
Cosine Similarity (cossim). We choose an ap-
proach that uses only lexical cohesion as our base-
line. Previous work (Lewis and Knowles, 1997;
Wang et al., 2008) has verified its usefulness for
the thread identification task. In this case,
</bodyText>
<footnote confidence="0.8167344">
1 We cast the problem as a pairwise ranking problem in order
to focus specifically on the issue of characterizing how initia-
tion-response links are encoded in language through lexical
choice. Note that once trained, pairwise ranking models can
be used to rank multiple instances.
</footnote>
<equation confidence="0.885281">
sim(pi,pj) = cossim(pi,pj)
</equation>
<bodyText confidence="0.999837277777778">
where cossim(pi,pj) computes the cosine of the an-
gle between two posts pi and pj while they are
represented as term vectors.
LSA Average Similarity (lsaavg). LSA is a well-
known method for grouping semantically related
words (Landauer et al., 1998). It represents word
meanings in a concept space with dimensionality k.
Before we describe how to compute average simi-
larity given an LSA space, we explain how the
LSA space was constructed in our work. First, we
construct a term-by-document matrix, where we
use the 90,028 message learning set mentioned at
the end of Section 2. Next, LSA applies singular
value decomposition to the matrix, and reduces the
dimensionality of the feature space to a k dimen-
sional concept space. This generated LSA space is
used by both lsaavg and lsacart later.
For lsaavg, we follow Foltz et al. (1998):
</bodyText>
<equation confidence="0.740856">
 ∑ta ∑
sim(pi,pj)=lsaavg (pi ,pj)=cosVA ,t Epj 
pj
</equation>
<bodyText confidence="0.998228357142857">
The meaning of each post is represented as a vec-
tor in the LSA space by averaging across the LSA
representations for each of its words. The similari-
ty between the two posts is then determined by
computing the cosine value of their LSA vectors.
This is the typical method for using LSA in text
similarity comparisons. However, note that not all
words carry equal weight within the vector that
results from this averaging process. Words that are
closer to the &amp;quot;semantic prototypes&amp;quot; represented by
each of the k dimensions of the reduced vector
space will have vectors with longer lengths than
words that are less prototypical. Thus, those words
that are closer to those prototypes will have a larg-
er effect on the direction of the resulting vector and
therefore on the comparison with other texts. An
important consideration is whether this is a desira-
ble effect. It would lead to deemphasizing those
unusual types of information that might be being
discussed as part of a post. However, one might
expect that those things that are unusual types of
information might actually be more likely to be the
in-focus information within an initiation that res-
ponses may be likely to refer to. In that case, for
our purposes, we would not expect this typical me-
thod for applying LSA to work well.
LSA Cartesian Similarity (lsacart). To properly
account for connections between initiations and
</bodyText>
<equation confidence="0.512487">
tb
pi
</equation>
<page confidence="0.993839">
675
</page>
<bodyText confidence="0.999850090909091">
responses that include unusual words, we introduce
the following similarity function:
where we take the mean of the cosine values for all
the word pairs in the Cartesian product of posts pi
and pj. Note that in this formulation, all words have
an equal chance to affect the overall similarity be-
tween vectors since it is the angle represented by
each word in a pair that comes to play when cosine
distance is applied to a word pair. Length is no
longer a factor. Moreover, the averaging is across
cosine similarity scores rather than LSA vectors.
</bodyText>
<sectionHeader confidence="0.999098" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.9772255">
The results are found in Table 1. For comparison,
we also report the random baseline (0.50).
</bodyText>
<table confidence="0.997423666666667">
Random Cos- LSA- LSA-
Baseline Similarity Average Cart
Accuracy 0.50 0.66 0.60 0.71
</table>
<tableCaption confidence="0.999784">
Table 1. Overview of results
</tableCaption>
<bodyText confidence="0.999915043478261">
Besides the random baseline, LSA-Average per-
forms the worst (0.60), with simple Cosine similar-
ity (0.66) in the middle, and LSA-Cart (0.71) the
best, with each of the pairwise contrasts being sta-
tistically significant. We believe the reason why
LSA-Average performs so poorly on this task is
precisely because, as discussed in last section, it
deemphasizes those words that contribute the most
unusual content. LSA-Cart addresses this issue.
To further understand this effect, we conducted
an error analysis. We divided the instances into 4
sets based on the lexical cohesion between the re-
sponse and the true initiation and between the re-
sponse and the foil, by taking the median split on
the distributions of these two cohesion scores. Our
finding is that model performances vary by subset.
In particular, we find that it is only in cases where
the positive example has low lexical cohesion (e.g.
our &amp;quot;vehicles-CO2&amp;quot; and &amp;quot;pollution-CO2&amp;quot; example
from the earlier section), that we see the benefit of
the LSA-Cart approach. In other cases, where the
cohesion between the reply and the true initiation
is high, Cos-Similarity performs best.
</bodyText>
<sectionHeader confidence="0.996776" genericHeader="conclusions">
5 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.99999475">
We have argued why the task of detecting initia-
tion-response pairs in multi-party discussions is
important and challenging. We proposed a method
for acquiring a large corpus for use to identify init-
iation-response pairs. In our experiments, we have
shown that the ranking model using a variant of
LSA performs best, which affirms our hypothesis
that unusual information and uncommon words
tends to be the focus of ongoing discussions and
therefore to be the key in identifying initiation-
response links.
In future work, we plan to further investigate the
connection between an initiation-response pairs
from multiple dimensions, such as topical cohe-
rence, semantic relatedness, conversation acts, etc.
One important current direction is to develop a
richer operationalization of the interaction that ac-
counts for the way posts sometimes respond to a
user, a collection of users, or a user’s posting histo-
ry, rather than specific posts per se.
</bodyText>
<sectionHeader confidence="0.998301" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999409">
We thank Mary McGlohon for sharing her data
with us. This research was funded through NSF
grant DRL-0835426.
</bodyText>
<sectionHeader confidence="0.998693" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99721732">
David D. Lewis and Kimberly A. Knowles. 1997.
Threading electronic mail: A preliminary study. In-
formation Processing and Management, 33(2), 209–
217.
Einat Minkov, William W. Cohen, Andrew Y. Ng.
2006. Contextual Search and Name Disambiguation
in Email using Graphs. In Proceedings of the Inter-
national ACM Conference on Research and Devel-
opment in Information Retrieval (SIGIR), pages 35–
42. ACM Press, 2006.
Peter W. Foltz, Walter Kintsch, Thomas K. Landauer.
1998. Textual coherence using latent semantic analy-
sis. Discourse Processes, 25, 285–307.
Thomas K. Landauer, Peter W. Foltz, and Darrell La-
ham. 1998. Introduction to latent semantic analysis.
Discourse Processes, 25, 259-284.
Schegloff, E. 2007. Sequence Organization in Interac-
tion: A Primer in Conversation Analysis, Cambridge
University Press.
Yi-Chia Wang, Mahesh Joshi, William W. Cohen, Ca-
rolyn P. Rosé. 2008. Recovering Implicit Thread
Structure in Newsgroup Style Conversations. In Pro-
ceedings of the 2nd International Conference on
Weblogs and Social Media (ICWSM II), Seattle,
USA.
</reference>
<figure confidence="0.996627875">
( )
t t
,
a b
∑ cos
simpi, pj = lsacart(pi, pj = (ta ,tb )∈ pi ×pj
pi
pj
</figure>
<page confidence="0.983746">
676
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.962109">
<title confidence="0.9998225">Making Conversational Structure Identification of Initiation-response Pairs within Online Discussions</title>
<author confidence="0.999736">Yi-Chia Wang Carolyn P Rosé</author>
<affiliation confidence="0.997954">Language Technologies Institute Language Technologies Institute Carnegie Mellon University Carnegie Mellon University</affiliation>
<address confidence="0.997857">Pittsburgh, PA 15213, USA Pittsburgh, PA 15213, USA</address>
<email confidence="0.99967">yichiaw@cs.cmu.educprose@cs.cmu.edu</email>
<abstract confidence="0.998153235294118">In this paper we investigate how to identify initiation-response pairs in asynchronous, multi-threaded, multi-party conversations. We formulate the task of identifying initiation-response pairs as a pairwise ranking problem. A novel variant of Latent Semantic Analysis (LSA) is proposed to overcome a limitation of standard LSA models, namely that uncommon words, which are critical for signaling initiation-response links, tend to be deemphasized as it is the more frequent terms that end up closer to the latent factors selected through singular value decomposition. We present experimental results demonstrating significantly better performance of the novel variant of LSA over standard LSA.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David D Lewis</author>
<author>Kimberly A Knowles</author>
</authors>
<title>Threading electronic mail: A preliminary study.</title>
<date>1997</date>
<booktitle>Information Processing and Management,</booktitle>
<volume>33</volume>
<issue>2</issue>
<pages>209--217</pages>
<contexts>
<context position="4103" citStr="Lewis and Knowles, 1997" startWordPosition="594" endWordPosition="597">e of relatedness between a message pair can be considered in light of the relatedness between each of them and the surrounding messages within the same thread, is a more suitable paradigm for this task than a discrete classification-based paradigm. Previous work on recovering conversational structure has relied on simple lexical cohesion 673 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 673–676, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics measures (i.e., cosine similarity), temporal information (Lewis and Knowles, 1997; Wang et al., 2008), and meta-data (Minkov et al., 2006). However, relatively little work has investigated the importance of specifically in-focus connections between initiation-response pairs and utilized them as clues for the task. Consider, for example, the following excerpt discussing whether congress should pass a bill requiring the use of smaller cars to save the environment: a) Regressing to smaller vehicles would discourage business from producing more pollution. b) If CO2 emissions are lowered, wouldn&apos;t tax revenues be lowered as well? Are the democrats going to willingly give up Med</context>
<context position="10777" citStr="Lewis and Knowles, 1997" startWordPosition="1716" endWordPosition="1719">r ranked higher means it has more evidence of being an initiation-reply link, compared to the other pair. 3.1 Alternative Similarity Functions We introduce and motivate 3 alternative similarity functions, where the first two are considered as baseline approaches and the third one is a novel variation of LSA. We argue that the proposed LSA variation is an appropriate semantic similarity measurement for identifying topic continuation and initiation-reply pairs in online discussions. Cosine Similarity (cossim). We choose an approach that uses only lexical cohesion as our baseline. Previous work (Lewis and Knowles, 1997; Wang et al., 2008) has verified its usefulness for the thread identification task. In this case, 1 We cast the problem as a pairwise ranking problem in order to focus specifically on the issue of characterizing how initiation-response links are encoded in language through lexical choice. Note that once trained, pairwise ranking models can be used to rank multiple instances. sim(pi,pj) = cossim(pi,pj) where cossim(pi,pj) computes the cosine of the angle between two posts pi and pj while they are represented as term vectors. LSA Average Similarity (lsaavg). LSA is a wellknown method for groupi</context>
</contexts>
<marker>Lewis, Knowles, 1997</marker>
<rawString>David D. Lewis and Kimberly A. Knowles. 1997. Threading electronic mail: A preliminary study. Information Processing and Management, 33(2), 209– 217.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Einat Minkov</author>
<author>William W Cohen</author>
<author>Andrew Y Ng</author>
</authors>
<title>Contextual Search and Name Disambiguation in Email using Graphs.</title>
<date>2006</date>
<booktitle>In Proceedings of the International ACM Conference on Research and Development in Information Retrieval (SIGIR),</booktitle>
<pages>35--42</pages>
<publisher>ACM Press,</publisher>
<contexts>
<context position="4160" citStr="Minkov et al., 2006" startWordPosition="604" endWordPosition="607"> light of the relatedness between each of them and the surrounding messages within the same thread, is a more suitable paradigm for this task than a discrete classification-based paradigm. Previous work on recovering conversational structure has relied on simple lexical cohesion 673 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 673–676, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics measures (i.e., cosine similarity), temporal information (Lewis and Knowles, 1997; Wang et al., 2008), and meta-data (Minkov et al., 2006). However, relatively little work has investigated the importance of specifically in-focus connections between initiation-response pairs and utilized them as clues for the task. Consider, for example, the following excerpt discussing whether congress should pass a bill requiring the use of smaller cars to save the environment: a) Regressing to smaller vehicles would discourage business from producing more pollution. b) If CO2 emissions are lowered, wouldn&apos;t tax revenues be lowered as well? Are the democrats going to willingly give up Medicaid and social security? Although segment (b) is a repl</context>
</contexts>
<marker>Minkov, Cohen, Ng, 2006</marker>
<rawString>Einat Minkov, William W. Cohen, Andrew Y. Ng. 2006. Contextual Search and Name Disambiguation in Email using Graphs. In Proceedings of the International ACM Conference on Research and Development in Information Retrieval (SIGIR), pages 35– 42. ACM Press, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter W Foltz</author>
<author>Walter Kintsch</author>
<author>Thomas K Landauer</author>
</authors>
<title>Textual coherence using latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<volume>25</volume>
<pages>285--307</pages>
<contexts>
<context position="12016" citStr="Foltz et al. (1998)" startWordPosition="1921" endWordPosition="1924">ted words (Landauer et al., 1998). It represents word meanings in a concept space with dimensionality k. Before we describe how to compute average similarity given an LSA space, we explain how the LSA space was constructed in our work. First, we construct a term-by-document matrix, where we use the 90,028 message learning set mentioned at the end of Section 2. Next, LSA applies singular value decomposition to the matrix, and reduces the dimensionality of the feature space to a k dimensional concept space. This generated LSA space is used by both lsaavg and lsacart later. For lsaavg, we follow Foltz et al. (1998):  ∑ta ∑ sim(pi,pj)=lsaavg (pi ,pj)=cosVA ,t Epj  pj The meaning of each post is represented as a vector in the LSA space by averaging across the LSA representations for each of its words. The similarity between the two posts is then determined by computing the cosine value of their LSA vectors. This is the typical method for using LSA in text similarity comparisons. However, note that not all words carry equal weight within the vector that results from this averaging process. Words that are closer to the &amp;quot;semantic prototypes&amp;quot; represented by each of the k dimensions of the reduced vector s</context>
</contexts>
<marker>Foltz, Kintsch, Landauer, 1998</marker>
<rawString>Peter W. Foltz, Walter Kintsch, Thomas K. Landauer. 1998. Textual coherence using latent semantic analysis. Discourse Processes, 25, 285–307.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas K Landauer</author>
<author>Peter W Foltz</author>
<author>Darrell Laham</author>
</authors>
<title>Introduction to latent semantic analysis.</title>
<date>1998</date>
<booktitle>Discourse Processes,</booktitle>
<volume>25</volume>
<pages>259--284</pages>
<contexts>
<context position="11430" citStr="Landauer et al., 1998" startWordPosition="1821" endWordPosition="1824">ed its usefulness for the thread identification task. In this case, 1 We cast the problem as a pairwise ranking problem in order to focus specifically on the issue of characterizing how initiation-response links are encoded in language through lexical choice. Note that once trained, pairwise ranking models can be used to rank multiple instances. sim(pi,pj) = cossim(pi,pj) where cossim(pi,pj) computes the cosine of the angle between two posts pi and pj while they are represented as term vectors. LSA Average Similarity (lsaavg). LSA is a wellknown method for grouping semantically related words (Landauer et al., 1998). It represents word meanings in a concept space with dimensionality k. Before we describe how to compute average similarity given an LSA space, we explain how the LSA space was constructed in our work. First, we construct a term-by-document matrix, where we use the 90,028 message learning set mentioned at the end of Section 2. Next, LSA applies singular value decomposition to the matrix, and reduces the dimensionality of the feature space to a k dimensional concept space. This generated LSA space is used by both lsaavg and lsacart later. For lsaavg, we follow Foltz et al. (1998):  ∑ta ∑ sim</context>
</contexts>
<marker>Landauer, Foltz, Laham, 1998</marker>
<rawString>Thomas K. Landauer, Peter W. Foltz, and Darrell Laham. 1998. Introduction to latent semantic analysis. Discourse Processes, 25, 259-284.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Schegloff</author>
</authors>
<title>Sequence Organization in Interaction: A Primer in Conversation Analysis,</title>
<date>2007</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="1693" citStr="Schegloff, 2007" startWordPosition="240" endWordPosition="241">years, research in the analysis of social media (e.g., weblogs, discussion boards, and messengers) has grown in popularity. Unlike expository text, the data produced through use of social media is often conversational, multi-threaded, and more complex because of the involvement of numerous participants who are distributed both across time and across space. Recovering the multithreaded structure is an active area of research. In this paper, we form the foundation for a broader study of this type of data by investigating the basic unit of interaction, referred to as an initiation-response pair (Schegloff, 2007). Initiationresponse pairs are pairs of utterances that are typically contributed by different participants, and where the first pair part sets up an expectation for the second pair part. Types of common initiationresponse pairs include question-answer, assessment-agreement, blame-denial, etc. Note that although sometimes discussion forum interfaces make the thread structure of the interaction explicit, these affordances are not always present. And even in forums that have these affordances, the apparent structure of the discourse as represented through the interface may not capture all of the</context>
</contexts>
<marker>Schegloff, 2007</marker>
<rawString>Schegloff, E. 2007. Sequence Organization in Interaction: A Primer in Conversation Analysis, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Chia Wang</author>
<author>Mahesh Joshi</author>
<author>William W Cohen</author>
<author>Carolyn P Rosé</author>
</authors>
<title>Recovering Implicit Thread Structure in Newsgroup Style Conversations.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2nd International Conference on Weblogs and Social Media (ICWSM II),</booktitle>
<location>Seattle, USA.</location>
<contexts>
<context position="4123" citStr="Wang et al., 2008" startWordPosition="598" endWordPosition="601">a message pair can be considered in light of the relatedness between each of them and the surrounding messages within the same thread, is a more suitable paradigm for this task than a discrete classification-based paradigm. Previous work on recovering conversational structure has relied on simple lexical cohesion 673 Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the ACL, pages 673–676, Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics measures (i.e., cosine similarity), temporal information (Lewis and Knowles, 1997; Wang et al., 2008), and meta-data (Minkov et al., 2006). However, relatively little work has investigated the importance of specifically in-focus connections between initiation-response pairs and utilized them as clues for the task. Consider, for example, the following excerpt discussing whether congress should pass a bill requiring the use of smaller cars to save the environment: a) Regressing to smaller vehicles would discourage business from producing more pollution. b) If CO2 emissions are lowered, wouldn&apos;t tax revenues be lowered as well? Are the democrats going to willingly give up Medicaid and social sec</context>
<context position="10797" citStr="Wang et al., 2008" startWordPosition="1720" endWordPosition="1723">has more evidence of being an initiation-reply link, compared to the other pair. 3.1 Alternative Similarity Functions We introduce and motivate 3 alternative similarity functions, where the first two are considered as baseline approaches and the third one is a novel variation of LSA. We argue that the proposed LSA variation is an appropriate semantic similarity measurement for identifying topic continuation and initiation-reply pairs in online discussions. Cosine Similarity (cossim). We choose an approach that uses only lexical cohesion as our baseline. Previous work (Lewis and Knowles, 1997; Wang et al., 2008) has verified its usefulness for the thread identification task. In this case, 1 We cast the problem as a pairwise ranking problem in order to focus specifically on the issue of characterizing how initiation-response links are encoded in language through lexical choice. Note that once trained, pairwise ranking models can be used to rank multiple instances. sim(pi,pj) = cossim(pi,pj) where cossim(pi,pj) computes the cosine of the angle between two posts pi and pj while they are represented as term vectors. LSA Average Similarity (lsaavg). LSA is a wellknown method for grouping semantically rela</context>
</contexts>
<marker>Wang, Joshi, Cohen, Rosé, 2008</marker>
<rawString>Yi-Chia Wang, Mahesh Joshi, William W. Cohen, Carolyn P. Rosé. 2008. Recovering Implicit Thread Structure in Newsgroup Style Conversations. In Proceedings of the 2nd International Conference on Weblogs and Social Media (ICWSM II), Seattle, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>