<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.014112">
<title confidence="0.9945565">
Superior and Efficient Fully Unsupervised Pattern-based Concept
Acquisition Using an Unsupervised Parser
</title>
<author confidence="0.996901">
Dmitry Davidov1 Roi Reichart1 Ari Rappoport2
</author>
<affiliation confidence="0.9839065">
1ICNC , 2Institute of Computer Science
Hebrew University of Jerusalem
</affiliation>
<email confidence="0.998635">
{dmitry@alice.nc|roiri@cs|arir@cs}.huji.ac.il
</email>
<sectionHeader confidence="0.994801" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999473034482758">
Sets of lexical items sharing a significant
aspect of their meaning (concepts) are fun-
damental for linguistics and NLP. Unsuper-
vised concept acquisition algorithms have
been shown to produce good results, and are
preferable over manual preparation of con-
cept resources, which is labor intensive, er-
ror prone and somewhat arbitrary. Some ex-
isting concept mining methods utilize super-
vised language-specific modules such as POS
taggers and computationally intensive parsers.
In this paper we present an efficient fully
unsupervised concept acquisition algorithm
that uses syntactic information obtained from
a fully unsupervised parser. Our algorithm
incorporates the bracketings induced by the
parser into the meta-patterns used by a sym-
metric patterns and graph-based concept dis-
covery algorithm. We evaluate our algorithm
on very large corpora in English and Russian,
using both human judgments and WordNet-
based evaluation. Using similar settings as
the leading fully unsupervised previous work,
we show a significant improvement in con-
cept quality and in the extraction of multiword
expressions. Our method is the first to use
fully unsupervised parsing for unsupervised
concept discovery, and requires no language-
specific tools or pattern/word seeds.
</bodyText>
<sectionHeader confidence="0.999164" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967714285714">
Comprehensive lexical resources for many domains
and languages are essential for most NLP applica-
tions. One of the most utilized types of such re-
sources is a repository of concepts: sets of lexical
items sharing a significant aspect of their meanings
(e.g., types of food, tool names, etc).
While handcrafted concept databases (e.g., Word-
Net) are extensively used in NLP, manual compila-
tion of such databases is labor intensive, error prone,
and somewhat arbitrary. Hence, for many languages
and domains great efforts have been made for au-
tomated construction of such databases from avail-
able corpora. While language-specific and domain-
specific studies show significant success in develop-
ment of concept discovery frameworks, the majority
of domains and languages remain untreated. Hence
there is a need for a framework that performs well
for many diverse settings and is as unsupervised and
language-independent as possible.
Numerous methods have been proposed for seed-
based concept extraction where a set of concept pat-
terns (or rules), or a small set of seed words for each
concept, is provided as input to the concept acqui-
sition system. However, even simple definitions for
concepts are not always available.
To avoid requiring this type of input, a number of
distributional and pattern-based methods have been
proposed for fully unsupervised seed-less acquisi-
tion of concepts from text. Pattern-based algorithms
were shown to obtain high quality results while be-
ing highly efficient in comparison to distributional
methods. Such fully unsupervised methods do not
incorporate any language-specific parsers or taggers,
so can be successfully applied to diverse languages.
However, unsupervised pattern-based methods
suffer from several weaknesses. Thus they are fre-
quently restricted to single-word terms and are un-
able to discover multiword expressions in efficient
and precise manner. They also usually ignore poten-
tially useful part-of-speech and other syntactic in-
formation. In order to address these weaknesses,
several studies utilize language-specific parsing or
</bodyText>
<page confidence="0.990964">
48
</page>
<note confidence="0.9899125">
Proceedings of the Thirteenth Conference on Computational Natural Language Learning (CoNLL), pages 48–56,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.999750925925926">
tagging systems in concept acquisition. Unfortu-
nately, while improving results, this heavily affects
the language- and domain- independence of such
frameworks, and severely impacts efficiency since
even shallow parsing is computationally demanding.
In this paper we present a method to utilize the in-
formation induced by unsupervised parsers in an un-
supervised pattern-based concept discovery frame-
work. With the recent development of fast fully un-
supervised parsers, it is now possible to add parser-
based information to lexical patterns while keep-
ing the language-independence of the whole frame-
work and still avoiding heavy computational costs.
Specifically, we incorporate the bracketings induced
by the parser into the meta-patterns used by a sym-
metric patterns and graph-based unsupervised con-
cept discovery algorithm.
We performed a thorough evaluation on two En-
glish corpora (the BNC and a 68GB web corpus)
and on a 33GB Russian corpus. Evaluations were
done using both human judgments and WordNet, in
similar settings as that of the leading unsupervised
previous work. Our results show that utilization of
unsupervised parser both improves the assignment
of single-word terms to concepts and allows high-
precision discovery and assignment of of multiword
expressions to concepts.
</bodyText>
<sectionHeader confidence="0.993105" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999729552238806">
Much work has been done on lexical acquisition of
all sorts and the acquisition of concepts in particu-
lar. Concept acquisition methods differ in the type of
corpus annotation and other human input used, and
in their basic algorithmic approach. Some methods
directly aim at concept acquisition, while the direct
goal in some is the construction of hyponym (‘is-a’)
hierarchies. A subtree in such a hierarchy can be
viewed as defining a concept.
A major algorithmic approach is to represent
word contexts as vectors in some space and use dis-
tributional measures and clustering in that space.
Pereira (1993), Curran (2002) and Lin (1998) use
syntactic features in the vector definition. (Pantel
and Lin, 2002) improves on the latter by clustering
by committee. Caraballo (1999) uses conjunction
and appositive annotations in the vector representa-
tion. Several studies avoid requiring any syntactic
annotation. Some methods are based on decompo-
sition of a lexically-defined matrix (by SVD, PCA
etc), e.g. (Sch¨utze, 1998; Deerwester et al., 1990).
While great effort has been made for improv-
ing the computational complexity of distributional
methods (Gorman and Curran, 2006), they still re-
main highly computationally intensive in compari-
son to pattern approaches (see below), and most of
them do not scale well for very large datasets.
The second main approach is to use lexico-
syntactic patterns. Patterns have been shown to pro-
duce more accurate results than feature vectors, at
a lower computational cost on large corpora (Pan-
tel et al., 2004). Since (Hearst, 1992), who used a
manually prepared set of initial lexical patterns, nu-
merous pattern-based methods have been proposed
for the discovery of concepts from seeds. Other
studies develop concept acquisition for on-demand
tasks where concepts are defined by user-provided
seeds. Many of these studies utilize information ob-
tained by language-specific parsing and named en-
tity recognition tools (Dorow et al., 2005). Pantel et
al. (2004) reduce the depth of linguistic data used,
but their method requires POS tagging.
TextRunner (Banko et al., 2007) utilizes a set
of pattern-based seed-less strategies in order to ex-
tract relational tuples from text. However, this sys-
tem contains many language-specific modules, in-
cluding the utilization of a parser in one of the pro-
cessing stages. Thus the majority of the existing
pattern-based concept acquisition systems rely on
pattern/word seeds or supervised language-specific
tools, some of which are very inefficient.
Davidov and Rappoport (2006) developed a
framework which discovers concepts based on high
frequency words and symmetry-based pattern graph
properties. This framework allows a fully unsuper-
vised seed-less discovery of concepts without rely-
ing on language-specific tools. However, it com-
pletely ignores potentially useful syntactic or mor-
phological information.
For example, the pattern ‘X and his Y’ is useful
for acquiring the concept of family member types,
as in “his siblings and his parents’. Without syn-
tactic information, it can capture noise, as in “... in
ireland) and his wife)” (parentheses denote syntac-
tic constituent boundaries). As another example, the
useful symmetric pattern “either X or Y” can appear
in both good examples (“choose either Chihuahua
</bodyText>
<page confidence="0.99891">
49
</page>
<bodyText confidence="0.998839871794872">
or Collie.”) and bad ones (“either Collie or Aus-
tralian Bulldog”). In the latter case, the algorithm
both captures noise (“Australlian” is now consid-
ered as a candidate for the ‘dog type’ concept), and
misses the discovery of a valid multiword candidate
(“Australlian Bulldog”). While symmetry-based fil-
tering greatly reduces such noise, the basic problem
remains. As a result, incorporating at least some
parsing information in a language-independent and
efficient manner could be beneficial.
Unsupervised parsing has been explored for sev-
eral decades (see (Clark, 2001; Klein, 2005) for re-
cent reviews). Recently, unsupervised parsers have
for the first time outperformed the right branch-
ing heuristic baseline for English. These include
CCM (Klein and Manning, 2002), the DMV and
DMV+CCM models (Klein and Manning, 2004),
(U)DOP based models (Bod, 2006a; Bod, 2006b;
Bod, 2007), an exemplar based approach (Den-
nis, 2005), guiding EM using contrastive estimation
(Smith and Eisner, 2006), and the incremental parser
of Seginer (2007) which we use here. These works
learn an unlabeled syntactic structure, dependency
or constituency. In this work we use constituency
trees as our syntactic representation.
Another important factor in concept acquisition
is the source of textual data used. To take advan-
tage of the rapidly expanding web, many of the pro-
posed frameworks utilize web queries rather than
local corpora (Etzioni et al., 2005; Davidov et al.,
2007; Pasca and Van Durme, 2008; Davidov and
Rappoport, 2009). While these methods have a defi-
nite practical advantage of dealing with the most re-
cent and comprehensive data, web-based evaluation
has some methodological drawbacks such as limited
repeatability (Kilgarriff, 2007). In this study we ap-
ply our framework on offline corpora in settings sim-
ilar to that of previous work, in order to be able to
make proper comparisons.
</bodyText>
<sectionHeader confidence="0.982421" genericHeader="method">
3 Efficient Unsupervised Parsing
</sectionHeader>
<bodyText confidence="0.99952875">
Our method utilizes the information induced by un-
supervised parsers. Specifically, we make use of the
bracketings induced by Seginer’s parser1 (Seginer,
2007). This parser has advantages in three major as-
</bodyText>
<footnote confidence="0.9684325">
1The parser is freely available at
http://staff.science.uva.nl/∼yseginer/ccl
</footnote>
<bodyText confidence="0.999665272727273">
pects relevant to this paper.
First, it achieves state of the art unsupervised
parsing performance: its F-score2 is 75.9% for sen-
tences of up to 10 words from the PennTreebank
Wall Street Journal corpus (WSJ) (Marcus, 1993),
and 59% for sentences of the same length from the
German NEGRA (Brants, 1997) corpus. These cor-
pora consists of newspaper texts.
Second, to obtain good results, manually created
POS tags are used as input in all the unsupervised
parsers mentioned above except of Seginer’s, which
uses raw sentences as input. (Headden et al., 2008)
have shown that the performance of algorithms that
require POS tags substantially decreases when using
POS tags induced by unsupervised POS taggers in-
stead of manually created ones. Seginer’s incremen-
tal parser is therefore the only fully unsupervised
parser providing high quality parses.
Third, Seginer’s parser is extremely fast. During
its initial stage, the parser builds a lexicon. Our Pen-
tium 2.8GHB machines with 4GHB RAM can store
in memory the lexicon created by up to 0.2M sen-
tences. We thus divided our corpora to batches of
0.2M sentences and parsed each of them separately.
Note that in this setup parsing quality might be even
better than the quality reported in (Seginer, 2007),
since in the setup reported in that paper the parser
was applied to a few thousand sentences only. On
average, the parsing time of a single batch was 5
minutes (run time did not significantly differ across
batches and corpora).
Parser description. The parser utilizes the novel
common-cover link representation for syntactic
structure. This representation resembles depen-
dency structure but unlike the latter, it can be trans-
lated into a constituency tree, which is the syntactic
representation we use in this work.
The parsing algorithm creates the common-cover
links structure of a sentence in an incremental man-
ner. This means that the parser reads the words of
a sentence one after the other and, as each word is
read, it is only allowed to add links that have one of
their ends at that words (and update existing ones).
Words which have not yet been read are not avail-
</bodyText>
<footnote confidence="0.85542975">
2F = 2·R·P, where R and P are the recall and precision of
R+Pthe parsers’ bracketing compared to manually created bracket-
ing of the same text. This is the accepted measure for parsing
performance (see (Klein, 2005)).
</footnote>
<page confidence="0.993493">
50
</page>
<bodyText confidence="0.999987272727273">
able to the parser at this stage. This restriction is
inspired by psycholinguistics research which sug-
gests that humans process language incrementally.
This results in a significant restriction of the parser’s
search space, which is the reason it is so fast.
During its initial stage the parser builds a lexicon
containing, for each word, statistics helping the deci-
sion of whether to link that word to other words. The
lexicon is updated as any new sentence is read. Lex-
icon updating is also done in an incremental manner
so this stage is also very fast.
</bodyText>
<sectionHeader confidence="0.987085" genericHeader="method">
4 Unsupervised Pattern Discovery
</sectionHeader>
<bodyText confidence="0.999887631578947">
In the first stage of our algorithm, we run the unsu-
pervised parser on the corpus in order to produce a
bracketing structure for each sentence. In the sec-
ond stage, described here, we use these bracketings
in order to discover, in a fully unsupervised manner,
patterns that could be useful for concept mining.
Our algorithm is based on the concept acquisition
method of (Davidov and Rappoport, 2006). We dis-
cover patterns that connect terms belonging to the
same concept in two main stages: discovery of pat-
tern candidates, and identification of the symmetric
patterns among the candidates.
Pattern candidates. A major idea of (Davidov
and Rappoport, 2006) is that a few dozen high fre-
quency words (HFW) such as ‘and’ and ‘is’ con-
nect other, less frequent content terms into relation-
ships. They define meta-patterns, which are short
sequences of H’s and C’s, where H is a slot for
a HFW and C is a slot for a content word (later
to become a word belonging to a discovered con-
cept). Their method was shown to produce good
results. However, the fact that it does not consider
any syntactic information causes problems. Specif-
ically, it does not consider the constituent structure
of the sentence. Meta-patterns that cross constituent
boundaries are likely to generate noise – two content
words (C’s) in a meta-pattern that belong to differ-
ent constituents are likely to belong to different con-
cepts as well. In addition, meta-patterns that do not
occupy a full constituent are likely to ‘cut’ multi-
word expressions (MWEs) into two parts, one part
that gets treated as a valid C word and one part that
is completely ignored.
The main idea in the present paper is to use the
bracketings induced by unsupervised parsers in or-
der to avoid the problems above. We utilize brack-
eting boundaries in our meta-patterns in addition
to HFW and C slots. In other words, their origi-
nal meta-patterns are totally lexical, while ours are
lexico-syntactic meta-patterns. We preserve the at-
tractive properties of meta-patterns, because both
HFWs and bracketings can be found or computed in
a language independent manner and very efficiently.
Concretely, we define a HFW as a word appearing
more than TH times per million words, and a C as
a word or multiword expression containing up to 4
words, appearing less than TC times per million.
We require that our patterns include two slots for
C’s, separated by at least a single HFW or bracket.
We allow separation by a single bracket because the
lowest level in the induced bracketing structure usu-
ally corresponds to lexical items, while higher levels
correspond to actual syntactic constituents.
In order to avoid truncation of multiword expres-
sions, we also require the meta pattern to start and
end by a HFW or bracket. Thus our meta-patterns
match the following regular expression:
</bodyText>
<equation confidence="0.559072">
{HHB}* C1 {HHB}+ C2 {HHB}*
</equation>
<bodyText confidence="0.999834611111111">
where “*” means zero or more times, and “+” means
one or more time and B can be “(”,“)” brackets pro-
duced by the parser (in these patterns we do not
need to guarantee that brackets match properly). Ex-
amples of such patterns include “((C1)in C2))”,
“(C1)(such(as(((C2)”, and “(C1)and(C2)”3. We
dismiss rare patterns that appear less than TP times
per million words.
Symmetric patterns. Many of the pattern candi-
dates discovered in the previous stage are not usable.
In order to find a usable subset, we focus on the sym-
metric patterns. We define a symmetric pattern as a
pattern in which the same pair of terms (C words)
is likely to appear in both left-to-right and right-to-
left orders. In order to identify symmetric patterns,
for each pattern we define a pattern graph G(P), as
proposed by (Widdows and Dorow, 2002). If term
pair (C1, C2) appears in pattern P in some context,
</bodyText>
<footnote confidence="0.99942175">
3This paper does not use any punctuation since the parser
is provided with sentences having all non-alphabetic characters
removed. We assume word separation. C1,2 can be a word or a
multiword expression.
</footnote>
<page confidence="0.99813">
51
</page>
<bodyText confidence="0.999430625">
we add nodes c1, c2 to the graph and a directed edge
EP(c1, c2) between them. In order to select sym-
metric patterns, we create such a pattern graph for
every discovered pattern, and create a symmetric
subgraph SymG(P) in which we take only bidirec-
tional edges from G(P). Then we compute three
measures for each pattern candidate as proposed by
(Davidov and Rappoport, 2006):
</bodyText>
<equation confidence="0.9978235">
M1(P) := |{c1|]c2E |(
(Node)A]c3)|P(c3,c1)}|
M2(P) :=|Nodes(SymG(P))|
|Nodes(G(P))|
M3(P) := |Edges(SymG(P ))|
|Edges(G(P))|
</equation>
<bodyText confidence="0.9621184">
For each measure, we prepare a sorted list of all can-
didate patterns. We remove patterns that are not in
the top ZT (we use 100, see Section 6) in any of the
three lists, and patterns that are in the bottom ZB in
at least one of the lists.
</bodyText>
<sectionHeader confidence="0.977593" genericHeader="method">
5 Concept Discovery
</sectionHeader>
<bodyText confidence="0.998939303571429">
At the end of the previous stage we have a set of
symmetric patterns. We now use them in order to
discover concepts. The concept discovery algorithm
is essentially the same as used by (Davidov and Rap-
poport, 2006) and has some similarity with the one
used by (Widdows and Dorow, 2002). In this section
we outline the algorithm.
The clique-set method. The utilized approach to
concept discovery is based on connectivity struc-
tures in the all-pattern term relationship graph G,
resulting from merging all of the single-pattern
graphs for symmetric patterns selected in the previ-
ous stage. The main observation regarding G is that
highly interconnected words are good candidates to
form a concept. We find all strong n-cliques (sub-
graphs containing n nodes that are all interconnected
in both directions). A clique Q defines a concept that
contains all of the nodes in Q plus all of the nodes
that are (1) at least unidirectionally connected to all
nodes in Q, and (2) bidirectionally connected to at
least one node in Q. Using this definition, we create
a concept for each such clique.
Note that a single term can be assigned to several
concepts. Thus a clique based on a connection of the
word ‘Sun’ to ‘Microsoft’ can lead to a concept of
computer companies, while the connection of ‘Sun’
to ‘Earth’ can lead to a concept of celestial bodies.
Reducing noise: merging and windowing. Since
any given term can participate in many cliques, the
algorithm creates overlapping categories, some of
which redundant. In addition, due to the nature of
language and the imperfection of the corpus some
noise is obviously to be expected. We enhance the
quality of the obtained concepts by merging them
and by windowing on the corpus. We merge two
concepts Q, R, iff there is more than a 50% overlap
between them: (|Q n R |&gt; |Q|/2) ∧ (|Q n R |&gt;
|R|/2). In order to increase concept quality and re-
move concepts that are too context-specific, we use
a simple corpus windowing technique. Instead of
running the algorithm of this section on the whole
corpus, we divide the corpus into windows of equal
size and perform the concept discovery algorithm of
this section (without pattern discovery) on each win-
dow independently. We now have a set of concepts
for each window. For the final set, we select only
those concepts that appear in at least two of the win-
dows. This technique reduces noise at the potential
cost of lowering coverage.
A decrease in the number of windows should pro-
duce more noisy results, while discovering more
concepts and terms. In the next section we show that
while windowing is clearly required for a large cor-
pus, incorporation of parser data increases the qual-
ity of the extracted corpus to the point where win-
dowing can be significantly reduced.
</bodyText>
<sectionHeader confidence="0.999927" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.995281307692308">
In order to estimate the quality of concepts and to
compare it to previous work, we have performed
both automatic and human evaluation. Our basic
comparison was to (Davidov and Rappoport, 2006)
(we have obtained their data and utilized their al-
gorithm), where we can estimate if incorporation of
parser data can solve some fundamental weaknesses
of their framework. In the following description, we
call their algorithm P and our parser-based frame-
work P+. We have also performed an indirect com-
parison to (Widdows and Dorow, 2002).
While there is a significant number of other re-
lated studies4 on concept acquisition (see Section 2),
</bodyText>
<footnote confidence="0.944153">
4Most are supervised and/or use language-specific tools.
</footnote>
<page confidence="0.998789">
52
</page>
<bodyText confidence="0.995729717391305">
direct or even indirect comparison to these works is
problematic due to difference in corpora, problem
definitions and evaluation strategies. Below we de-
scribe the corpora and parameters used in our evalu-
ation and then show and discuss WordNet-based and
Human evaluation settings and results.
Corpora. We performed in-depth evaluation in
two languages, English and Russian, using three
corpora, two for English and one for Russian.
The first English corpus is the BNC, containing
about 100M words. The second English corpus,
DMOZ(Gabrilovich and Markovitch, 2005), is a
web corpus obtained by crawling URLs in the Open
Directory Project (dmoz.org), resulting in 68GB
containing about 8.2G words from 50M web pages.
The Russian corpus (Davidov and Rappoport, 2006)
was assembled from web-based Russian reposito-
ries, to yield 33GB and 4G words. All of these cor-
pora were also used by (Davidov and Rappoport,
2006) and BNC was used in similar settings by
(Widdows and Dorow, 2002).
Algorithm parameters. The thresholds
TH, TC, TP, ZT, ZB, were determined mostly
by practical memory size considerations: we com-
puted thresholds that would give us the maximal
number of terms, while enabling the pattern access
table to reside in main memory. The resulting
numbers are 100, 50, 20,100,100. Corpus window
size was determined by starting from a small
window size, extracting at random a single window,
running the algorithm, and iterating this process
with increased ×2 window sizes until reaching a
desired vocabulary concept participation percentage
(before windowing) (i.e., x% of the different words
in the corpus participate in terms assigned into
concepts. We used 5%.). We also ran the algorithm
without windowing in order to check how well the
provided parsing information can help reduce noise.
Among the patterns discovered are the ubiquitous
ones containing “and”,“or”, e.g. ‘((X) or (a Y))’,
and additional ones such as ‘from (X) to (Y)’.
Influence of parsing data on number of discov-
ered concepts. Table 1 compares the concept ac-
quisition framework with (P+) and without (P) uti-
lization of parsing data.
We can see that the amount of different words
</bodyText>
<table confidence="0.995609">
V W C AS
P P+ P P+ P P+
DMOZ 16 330 504 142 130 12.8 16.0
BNC 0.3 25 42 9.6 8.9 10.2 15.6
Russ. 10 235 406 115 96 11.6 15.1
</table>
<tableCaption confidence="0.99098">
Table 1: Results for concept discovery with (P+) and
</tableCaption>
<figureCaption confidence="0.3487225">
without (P) utilization of parsing data. V is the total num-
ber (millions) of different words in the corpus. W is the
number (thousands) of words belonging to at least one of
the terms for one of the concepts. C is the number (thou-
sands) of concepts (after merging and windowing). AS
is the average(words) category size.
</figureCaption>
<bodyText confidence="0.998915625">
covered by discovered concepts raises nearly 1.5-
fold when we utilize patterns based on parsing data
in comparison to pure HFW patterns used in previ-
ous work. We can also see nearly the same increase
in average concept size. At the same time we ob-
serve about 15% reduction in the total number of
discovered concepts.
There are two opposite factors in P+ which may
influence the number of concepts, their size and cov-
erage in comparison to P. On one hand, utilization of
more restricted patterns that include parsing infor-
mation leads to a reduced number of concept term
instances being discovered. Thus, the P+ pattern “(X
(or (a Y))” will recognize “(TV (or (a movie))” in-
stance and will miss “(lunch) or (a snack))”, while
the P pattern “X or a Y” will capture both. This leads
to a decrease in the number of discovered concepts.
On the other hand, P+ patterns, unlike P ones, al-
low the extraction of multiword expressions5, and
indeed more than third of the discovered terms us-
ing P+ were MWEs. Utilization of MWEs not only
allows to cover a greater amount of different words,
but also increases the number of discovered concepts
since new concepts can be found using cliques of
newly discovered MWEs. From the results, we can
see that for a given concept size and word coverage,
the ability to discover MWEs overcomes the disad-
vantage of ignoring potentially useful concepts.
Human judgment evaluation. Our humanjudge-
ment evaluation closely followed the protocol (Davi-
dov and Rappoport, 2006).
We used 4 subjects for evaluation of the English
</bodyText>
<footnote confidence="0.97147325">
5While P method can potentially be used to extract MWEs,
preliminary experimentation shows that without significant
modification, quality of MWEs obtained by P is very low in
comparison to P+
</footnote>
<page confidence="0.999032">
53
</page>
<bodyText confidence="0.999576914285714">
concepts and 4 subjects for Russian ones. In order
to assess subjects’ reliability, we also included ran-
dom concepts (see below). The goal of the exper-
iment was to examine the differences between the
P+ and P concept acquisition frameworks. Subjects
were given 50 triplets of words and were asked to
rank them using the following scale: (1) the words
definitely share a significant part of their meaning;
(2) the words have a shared meaning but only in
some context; (3) the words have a shared mean-
ing only under a very unusual context/situation; (4)
the words do not share any meaning; (5) I am not
familiar enough with some/all of the words.
The 50 triplets were obtained as follows. We have
randomly selected 40 concept pairs (C+,C): C+ in
P+ and C in P using five following restrictions: (1)
concepts should contain at least 10 words; (2) for
a selected pair, C+ should share at least half of its
single-word terms with C, and C should share at
least half of its words with C+; (3) C+ should con-
tain at least 3 MWEs; (4) C should contain at least 3
words not appearing in C+; (5) C+ should contain at
least 3 single-word terms not appearing in C.
These restrictions allow to select concept pairs
such that C+ is similar to C while they still carry
enough differences which can be examined. We se-
lected the triplets as following: for pairs (C+, C) ten
triplets include terms appearing in both C+ and C
(Both column in Table 2), ten triplets include single-
word terms appearing in C+ but not C (P+ single
column), ten triplets include single-word terms ap-
pearing in C but not C+ (P column), ten triplets in-
clude MWEs appearing in C+ (P+ mwe column) and
ten triplets include random terms obtained from P+
concepts (Rand column).
</bodyText>
<table confidence="0.999697583333333">
P+ P Both Rand
mwe single
% shared
meaning
DMOZ 85 88 68 81 6
BNC 85 90 61 88 0
Russ. 89 95 70 93 11
triplet
score (1-4)
DMOZ 1.7 1.4 2.5 1.7 3.8
BNC 1.6 1.3 2.1 1.5 4.0
Russ. 1.5 1.1 2.0 1.3 3.7
</table>
<tableCaption confidence="0.9925978">
Table 2: Results of evaluation by human judgment of
three data sets. P+ single/mwe: single-word/MWE terms
existing only in P+ concept; P: single-word terms existing
only in P concept; Both: terms existing in both concepts;
Rand: random terms. See text for detailed explanations.
</tableCaption>
<bodyText confidence="0.999907638297873">
The first part of Table 2 gives the average per-
centage of triplets that were given scores of 1 or 2
(that is, ‘significant shared meaning’). The second
part gives the average score of a triplet (1 is best).
In these lines scores of 5 were not counted. Inter-
evaluator Kappa between scores are 0.68/0.75/0.76
for DMOZ, BNC and Russian respectively. We can
see that terms selected by P and skipped by P+
receive low scores, at the same time even single-
word terms selected by P+ and skipped by P show
very high scores. This shows that using parser data,
the proposed framework can successfully avoid se-
lection of erroneous terms, while discovering high-
quality terms missed by P. We can also see that P+
performance on MWEs, while being slightly infe-
rior to the one for single-word terms, still achieves
results comparable to those of single-word terms.
Thus our algorithm can greatly improve the re-
sults not only by discovering of MWEs but also by
improving the set of single word concept terms.
WordNet-based evaluation. The major guideline
in this part of the evaluation was to compare our re-
sults with previous work (Davidov and Rappoport,
2006; Widdows and Dorow, 2002) without the pos-
sible bias of human evaluation. We have followed
their methodology as best as we could, using the
same WordNet (WN) categories and the same cor-
pora. This also allows indirect comparison to several
other studies, thus (Widdows and Dorow, 2002) re-
ports results for an LSA-based clustering algorithm
that are vastly inferior to the pattern-based ones.
The evaluation method is as follows. We took
the exact 10 WN subsets referred to as ‘subjects’ in
(Widdows and Dorow, 2002), and removed all multi-
word items. We then selected at random 10 pairs of
words from each subject. For each pair, we found
the largest of our discovered concepts containing it.
The various morphological forms or clear typos of
the same word were treated as one in the evaluation.
We have improved the evaluation framework for
Russian by using the Russian WordNet (Gelfenbey-
nand et al., 2003) instead of back-translations as
done in (Davidov and Rappoport, 2006). Prelim-
inary examination shows that this has no apparent
effect on the results.
For each found concept C containing N words,
we computed the following: (1) Precision: the num-
</bodyText>
<page confidence="0.993937">
54
</page>
<bodyText confidence="0.950880714285714">
ber of words present in both C and WN divided by
N; (2) Precision*: the number of correct words di-
vided by N. Correct words are either words that
appear in the WN subtree, or words whose entry in
the American Heritage Dictionary or the Britannica
directly defines them as belonging to the given class
(e.g., ‘murder’ is defined as ‘a crime’). This was
done in order to overcome the relative poorness of
WN; (3) Recall: the number of words present in
both C and WN divided by the number of words
in WN; (4) The percentage of correctly discovered
words (according to Precision*) that are not in WN.
Table 3 compares the macro-average of these 10
categories to corresponding related work. We do not
</bodyText>
<table confidence="0.999944909090909">
Prec. Prec.* Rec. %New
DMOZ
P 79.8 86.5 22.7 2.5
P+ 79.5 91.3 28.6 3.7
BNC
P 92.76 95.72 7.22 0.4
P+ 93.0 96.1 14.6 1.7
Widdows 82.0 - - -
Russian
P 82.39 89.64 20.03 2.1
P+ 83.5 92.6 29.6 4.0
</table>
<tableCaption confidence="0.8692448">
Table 3: WordNet evaluation in comparison to P (Davi-
dov and Rappoport, 2006) and to Widdows(Widdows and
Dorow, 2002). Columns show average precision, preci-
sion* (as defined in text), recall, and % of new words
added to corresponding WN subtree.
</tableCaption>
<bodyText confidence="0.999955307692308">
observe apparent rise in precision when comparing
P+ and P, but we can see significant improvement
in both recall and precision* for all of three cor-
pora. In combination with human judgement results,
this suggests that the P+ framework successfully dis-
covers more correct terms not present in WN. This
causes precision to remain constant while precision*
improves significantly. Rise in recall also shows that
the P+ framework can discover significantly more
correct terms from the same data.
Windowing requirement. As discussed in Sec-
tion 5, windowing is required for successful noise
reduction. However, due to the increase in pattern
quality with parser data, it is likely that less noise
will be captured by the discovered patterns. Hence,
windowing could be relaxed allowing to obtain more
data with sufficiently high precision.
In order to test this issue we applied our algo-
rithms on the DMOZ corpus with 3 different win-
dowing settings: (1) choosing window size as de-
scribed above; (2) using ×4 larger window; (3)
avoiding windowing altogether. Each time we ran-
domly sampled a set of 100 concepts and tagged (by
the authors) noisy ones. A concept is considered to
be noisy if it has at least 3 words unrelated to each
other. Table 4 shows results of this test.
</bodyText>
<tableCaption confidence="0.980934">
Table 4: Percentage of noisy concepts as a function of
windowing.
</tableCaption>
<bodyText confidence="0.999839583333333">
We can see that while windowing is still essential
even with available parser data, using this data we
can significantly reduce windowing requirements,
allowing us to discover more concepts from the
same data.
Timing requirements are modest, considering we
parsed such large amounts of data. BNC pars-
ing took 45 minutes, and the total single-machine
processing time for the 68Gb DMOZ corpus was
4 days6. In comparison, a state-of-art supervised
parser (Charniak and Johnson, 2005) would process
the same amount of data in 1.3 years7.
</bodyText>
<sectionHeader confidence="0.999417" genericHeader="conclusions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999994894736842">
We have presented a framework which utilizes an
efficient fully unsupervised parser for unsupervised
pattern-based discovery of concepts. We showed
that utilization of unsupervised parser in pattern ac-
quisition not only allows successful extraction of
MWEs but also improves the quality of obtained
concepts, avoiding noise and adding new terms
missed by the parse-less approach. At the same time,
the framework remains fully unsupervised, allowing
its straightforward application to different languages
as supported by our bilingual evaluation.
This research presents one more step towards the
merging of fully unsupervised techniques for lex-
ical acquisition, allowing to extract semantic data
without strong assumptions on domain or language.
While we have aimed for concept acquisition, the
proposed framework can be also useful for extrac-
tion of different types of lexical relationships, both
among concepts and between concept terms.
</bodyText>
<footnote confidence="0.96347025">
6In fact, we used a PC cluster, and all 3 corpora were parsed
in 15 hours.
7Considering the reported parsing rate of 10 sentences per
second
</footnote>
<figure confidence="0.960087636363637">
Reg. Window
×4 Window
No windowing
P
4
18
33
P+
4
5
21
</figure>
<page confidence="0.993714">
55
</page>
<sectionHeader confidence="0.993195" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999897233009708">
Mishele Banko, Michael J Cafarella , Stephen Soderland,
Matt Broadhead, Oren Etzioni, 2007. Open Informa-
tion Extraction from the Web. IJCAI ’07.
Rens Bod, 2006a. An All-Subtrees Approach to Unsu-
pervised Parsing. ACL ’06.
Rens Bod, 2006b. Unsupervised Parsing with U-DOP.
CoNLL X.
Rens Bod, 2007. Is the End of Supervised Parsing in
Sight? ACL ’07.
Thorsten Brants, 1997. The NEGRA Export Format.
CLAUS Report, Saarland University.
Sharon Caraballo, 1999. Automatic Construction of a
Hypernym-labeled Noun Hierarchy from Text. ACL
’99.
Eugene Charniak and Mark Johnson, 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. ACL ’05.
Alexander Clark, 2001. Unsupervised Language Acqui-
sition: Theory and Practice. Ph.D. thesis, University
of Sussex.
James R. Curran, Marc Moens, 2002. Improvements in
Automatic Thesaurus Extraction SIGLEX 02’, 59–66.
Dmitry Davidov, Ari Rappoport, 2006. Efficient Un-
supervised Discovery of Word Categories using Sym-
metric Patterns and High Frequency Words. COLING-
ACL ’06.
Dmitry Davidov, Ari Rappoport, Moshe Koppel, 2007.
Fully Unsupervised Discovery of Concept-Specific
Relationships by Web Mining. ACL ’07.
Dmitry Davidov, Ari Rappoport, 2009. Translation and
Extension of Concepts Across Languages. EACL ’09.
Scott Deerwester, Susan Dumais, George Furnas,
Thomas Landauer, Richard Harshman, 1990. Index-
ing by Latent Semantic Analysis. J. of the American
Society for Info. Science, 41(6):391–407.
Simon Dennis, 2005. An exemplar-based approach to
unsupervised parsing. Proceedings of the 27th Con-
ference of the Cognitive Science Society.
Beate Dorow, Dominic Widdows, Katarina Ling, Jean-
Pierre Eckmann, Danilo Sergi, Elisha Moses, 2005.
Using curvature and Markov clustering in Graphs for
Lexical Acquisition and Word Sense Discrimination.
MEANING ’05.
Oren Etzioni, Michael Cafarella, Doug Downey, S. Kok,
Ana-Maria Popescu, Tal Shaked, Stephen Soderland,
Daniel Weld, Alexander Yates, 2005. Unsupervised
Named-entity Extraction from the Web: An Experi-
mental Study. Arti�cial Intelligence, 165(1):91134.
Evgeniy Gabrilovich, Shaul Markovitch, 2005. Fea-
ture Generation for Text Categorization Using World
Knowledge. IJCAI ’05.
Ilya Gelfenbeyn, Artem Goncharuk, Vladislav Lehelt,
Anton Lipatov, Victor Shilo, 2003. Automatic Trans-
lation of WordNet Semantic Network to Russian Lan-
guage (in Russian) International Dialog 2003 Work-
shop.
James Gorman, James R. Curran, 2006. Scaling Distri-
butional Similarity to Large Corpora. COLING-ACL
’06.
William P. Headden III, David McClosky and Eugene
Charniak, 2008. Evaluating Unsupervised Part-of-
Speech tagging for Grammar Induction. COLING ’08.
Marti Hearst, 1992. Automatic Acquisition of Hy-
ponyms from Large Text Corpora. COLING ’92.
Adam Kilgarriff, 2007. Googleology is Bad Science.
Computational Linguistics ’08, Vol.33 No. 1,pp147-
151. .
Dan Klein and Christopher Manning, 2002. A genera-
tive constituent-context model for improved grammar
induction. Proc. of the 40th Meeting of the ACL.
Dan Klein and Christopher Manning, 2004. Corpus-
based induction of syntactic structure: Models of de-
pendency and constituency. ACL ’04.
Dan Klein, 2005. The unsupervised learning of natural
language structure. Ph.D. thesis, Stanford University.
Hang Li, Naoki Abe, 1996. Clustering Words with the
MDL Principle. COLING ’96.
Dekang Lin, 1998. Automatic Retrieval and Clustering
of Similar Words. COLING ’98.
Marcus Mitchell P., Beatrice Santorini and Mary Ann
Marcinkiewicz, 1993. Building a large annotated cor-
pus of English: The Penn Treebank. Computational
Linguistics, 19(2):313–330
Marius Pasca, Benjamin Van Durme, 2008. Weakly-
supervised Acquisition of Open-domain Classes and
Class Attributes from Web Documents and Query
Logs. ACL 08.
Patrick Pantel, Dekang Lin, 2002. Discovering Word
Senses from Text. SIGKDD ’02.
Patrick Pantel, Deepak Ravichandran, Eduard Hovy,
2004. Towards Terascale Knowledge Acquisition.
COLING ’04.
Fernando Pereira, Naftali Tishby, Lillian Lee, 1993. Dis-
tributional Clustering of English Words. ACL ’93.
Hinrich Sch¨utze, 1998. Automatic Word Sense Discrim-
ination. Computational Linguistics, 24(1):97–123.
Yoav Seginer, 2007. Fast Unsupervised Incremental
Parsing. ACL ’07.
Noah A. Smith and Jason Eisner, 2006. Annealing Struc-
tural Bias in Multilingual Weighted Grammar Induc-
tion . ACL ’06.
Dominic Widdows, Beate Dorow, 2002. A Graph Model
for Unsupervised Lexical Acquisition. COLING ’02.
</reference>
<page confidence="0.998423">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.981797">
<title confidence="0.997253">Superior and Efficient Fully Unsupervised Pattern-based Acquisition Using an Unsupervised Parser</title>
<author confidence="0.999952">Roi Ari</author>
<affiliation confidence="0.999536">of Computer Hebrew University of Jerusalem</affiliation>
<abstract confidence="0.999590833333333">Sets of lexical items sharing a significant of their meaning are fundamental for linguistics and NLP. Unsupervised concept acquisition algorithms have been shown to produce good results, and are preferable over manual preparation of concept resources, which is labor intensive, error prone and somewhat arbitrary. Some existing concept mining methods utilize supervised language-specific modules such as POS taggers and computationally intensive parsers. In this paper we present an efficient fully unsupervised concept acquisition algorithm that uses syntactic information obtained from a fully unsupervised parser. Our algorithm incorporates the bracketings induced by the parser into the meta-patterns used by a symmetric patterns and graph-based concept discovery algorithm. We evaluate our algorithm on very large corpora in English and Russian, using both human judgments and WordNetbased evaluation. Using similar settings as the leading fully unsupervised previous work, we show a significant improvement in concept quality and in the extraction of multiword expressions. Our method is the first to use fully unsupervised parsing for unsupervised concept discovery, and requires no languagespecific tools or pattern/word seeds.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<date>2007</date>
<booktitle>Open Information Extraction from the Web. IJCAI ’07.</booktitle>
<marker>Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Mishele Banko, Michael J Cafarella , Stephen Soderland, Matt Broadhead, Oren Etzioni, 2007. Open Information Extraction from the Web. IJCAI ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rens Bod</author>
</authors>
<title>An All-Subtrees Approach to Unsupervised Parsing.</title>
<date>2006</date>
<journal>ACL</journal>
<volume>06</volume>
<contexts>
<context position="9251" citStr="Bod, 2006" startWordPosition="1387" endWordPosition="1388">ndidate (“Australlian Bulldog”). While symmetry-based filtering greatly reduces such noise, the basic problem remains. As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al.,</context>
</contexts>
<marker>Bod, 2006</marker>
<rawString>Rens Bod, 2006a. An All-Subtrees Approach to Unsupervised Parsing. ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rens Bod</author>
</authors>
<title>Unsupervised Parsing with U-DOP.</title>
<date>2006</date>
<journal>CoNLL X.</journal>
<contexts>
<context position="9251" citStr="Bod, 2006" startWordPosition="1387" endWordPosition="1388">ndidate (“Australlian Bulldog”). While symmetry-based filtering greatly reduces such noise, the basic problem remains. As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al.,</context>
</contexts>
<marker>Bod, 2006</marker>
<rawString>Rens Bod, 2006b. Unsupervised Parsing with U-DOP. CoNLL X.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rens Bod</author>
</authors>
<title>Is the End of Supervised Parsing in Sight?</title>
<date>2007</date>
<journal>ACL</journal>
<volume>07</volume>
<contexts>
<context position="9276" citStr="Bod, 2007" startWordPosition="1391" endWordPosition="1392">lldog”). While symmetry-based filtering greatly reduces such noise, the basic problem remains. As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durm</context>
</contexts>
<marker>Bod, 2007</marker>
<rawString>Rens Bod, 2007. Is the End of Supervised Parsing in Sight? ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>The NEGRA Export Format.</title>
<date>1997</date>
<tech>CLAUS Report,</tech>
<institution>Saarland University.</institution>
<contexts>
<context position="10898" citStr="Brants, 1997" startWordPosition="1644" endWordPosition="1645">fficient Unsupervised Parsing Our method utilizes the information induced by unsupervised parsers. Specifically, we make use of the bracketings induced by Seginer’s parser1 (Seginer, 2007). This parser has advantages in three major as1The parser is freely available at http://staff.science.uva.nl/∼yseginer/ccl pects relevant to this paper. First, it achieves state of the art unsupervised parsing performance: its F-score2 is 75.9% for sentences of up to 10 words from the PennTreebank Wall Street Journal corpus (WSJ) (Marcus, 1993), and 59% for sentences of the same length from the German NEGRA (Brants, 1997) corpus. These corpora consists of newspaper texts. Second, to obtain good results, manually created POS tags are used as input in all the unsupervised parsers mentioned above except of Seginer’s, which uses raw sentences as input. (Headden et al., 2008) have shown that the performance of algorithms that require POS tags substantially decreases when using POS tags induced by unsupervised POS taggers instead of manually created ones. Seginer’s incremental parser is therefore the only fully unsupervised parser providing high quality parses. Third, Seginer’s parser is extremely fast. During its i</context>
</contexts>
<marker>Brants, 1997</marker>
<rawString>Thorsten Brants, 1997. The NEGRA Export Format. CLAUS Report, Saarland University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharon Caraballo</author>
</authors>
<title>Automatic Construction of a Hypernym-labeled Noun Hierarchy from Text.</title>
<date>1999</date>
<journal>ACL</journal>
<volume>99</volume>
<contexts>
<context position="5883" citStr="Caraballo (1999)" startWordPosition="872" endWordPosition="873">orpus annotation and other human input used, and in their basic algorithmic approach. Some methods directly aim at concept acquisition, while the direct goal in some is the construction of hyponym (‘is-a’) hierarchies. A subtree in such a hierarchy can be viewed as defining a concept. A major algorithmic approach is to represent word contexts as vectors in some space and use distributional measures and clustering in that space. Pereira (1993), Curran (2002) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. Several studies avoid requiring any syntactic annotation. Some methods are based on decomposition of a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al., 1990). While great effort has been made for improving the computational complexity of distributional methods (Gorman and Curran, 2006), they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets. The second main approach is to use lexico</context>
</contexts>
<marker>Caraballo, 1999</marker>
<rawString>Sharon Caraballo, 1999. Automatic Construction of a Hypernym-labeled Noun Hierarchy from Text. ACL ’99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking.</title>
<date>2005</date>
<journal>ACL</journal>
<volume>05</volume>
<contexts>
<context position="33523" citStr="Charniak and Johnson, 2005" startWordPosition="5510" endWordPosition="5513">as at least 3 words unrelated to each other. Table 4 shows results of this test. Table 4: Percentage of noisy concepts as a function of windowing. We can see that while windowing is still essential even with available parser data, using this data we can significantly reduce windowing requirements, allowing us to discover more concepts from the same data. Timing requirements are modest, considering we parsed such large amounts of data. BNC parsing took 45 minutes, and the total single-machine processing time for the 68Gb DMOZ corpus was 4 days6. In comparison, a state-of-art supervised parser (Charniak and Johnson, 2005) would process the same amount of data in 1.3 years7. 7 Discussion We have presented a framework which utilizes an efficient fully unsupervised parser for unsupervised pattern-based discovery of concepts. We showed that utilization of unsupervised parser in pattern acquisition not only allows successful extraction of MWEs but also improves the quality of obtained concepts, avoiding noise and adding new terms missed by the parse-less approach. At the same time, the framework remains fully unsupervised, allowing its straightforward application to different languages as supported by our bilingual</context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson, 2005. Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking. ACL ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Clark</author>
</authors>
<title>Unsupervised Language Acquisition: Theory and Practice.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sussex.</institution>
<contexts>
<context position="8966" citStr="Clark, 2001" startWordPosition="1343" endWordPosition="1344">od examples (“choose either Chihuahua 49 or Collie.”) and bad ones (“either Collie or Australian Bulldog”). In the latter case, the algorithm both captures noise (“Australlian” is now considered as a candidate for the ‘dog type’ concept), and misses the discovery of a valid multiword candidate (“Australlian Bulldog”). While symmetry-based filtering greatly reduces such noise, the basic problem remains. As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency tr</context>
</contexts>
<marker>Clark, 2001</marker>
<rawString>Alexander Clark, 2001. Unsupervised Language Acquisition: Theory and Practice. Ph.D. thesis, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>Marc Moens</author>
</authors>
<date>2002</date>
<booktitle>Improvements in Automatic Thesaurus Extraction SIGLEX 02’,</booktitle>
<pages>59--66</pages>
<marker>Curran, Moens, 2002</marker>
<rawString>James R. Curran, Marc Moens, 2002. Improvements in Automatic Thesaurus Extraction SIGLEX 02’, 59–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Efficient Unsupervised Discovery of Word Categories using Symmetric Patterns and High Frequency Words.</title>
<date>2006</date>
<journal>COLINGACL</journal>
<volume>06</volume>
<contexts>
<context position="7654" citStr="Davidov and Rappoport (2006)" startWordPosition="1142" endWordPosition="1145">named entity recognition tools (Dorow et al., 2005). Pantel et al. (2004) reduce the depth of linguistic data used, but their method requires POS tagging. TextRunner (Banko et al., 2007) utilizes a set of pattern-based seed-less strategies in order to extract relational tuples from text. However, this system contains many language-specific modules, including the utilization of a parser in one of the processing stages. Thus the majority of the existing pattern-based concept acquisition systems rely on pattern/word seeds or supervised language-specific tools, some of which are very inefficient. Davidov and Rappoport (2006) developed a framework which discovers concepts based on high frequency words and symmetry-based pattern graph properties. This framework allows a fully unsupervised seed-less discovery of concepts without relying on language-specific tools. However, it completely ignores potentially useful syntactic or morphological information. For example, the pattern ‘X and his Y’ is useful for acquiring the concept of family member types, as in “his siblings and his parents’. Without syntactic information, it can capture noise, as in “... in ireland) and his wife)” (parentheses denote syntactic constituen</context>
<context position="13929" citStr="Davidov and Rappoport, 2006" startWordPosition="2150" endWordPosition="2153">e decision of whether to link that word to other words. The lexicon is updated as any new sentence is read. Lexicon updating is also done in an incremental manner so this stage is also very fast. 4 Unsupervised Pattern Discovery In the first stage of our algorithm, we run the unsupervised parser on the corpus in order to produce a bracketing structure for each sentence. In the second stage, described here, we use these bracketings in order to discover, in a fully unsupervised manner, patterns that could be useful for concept mining. Our algorithm is based on the concept acquisition method of (Davidov and Rappoport, 2006). We discover patterns that connect terms belonging to the same concept in two main stages: discovery of pattern candidates, and identification of the symmetric patterns among the candidates. Pattern candidates. A major idea of (Davidov and Rappoport, 2006) is that a few dozen high frequency words (HFW) such as ‘and’ and ‘is’ connect other, less frequent content terms into relationships. They define meta-patterns, which are short sequences of H’s and C’s, where H is a slot for a HFW and C is a slot for a content word (later to become a word belonging to a discovered concept). Their method was </context>
<context position="17830" citStr="Davidov and Rappoport, 2006" startWordPosition="2814" endWordPosition="2817"> (C1, C2) appears in pattern P in some context, 3This paper does not use any punctuation since the parser is provided with sentences having all non-alphabetic characters removed. We assume word separation. C1,2 can be a word or a multiword expression. 51 we add nodes c1, c2 to the graph and a directed edge EP(c1, c2) between them. In order to select symmetric patterns, we create such a pattern graph for every discovered pattern, and create a symmetric subgraph SymG(P) in which we take only bidirectional edges from G(P). Then we compute three measures for each pattern candidate as proposed by (Davidov and Rappoport, 2006): M1(P) := |{c1|]c2E |( (Node)A]c3)|P(c3,c1)}| M2(P) :=|Nodes(SymG(P))| |Nodes(G(P))| M3(P) := |Edges(SymG(P ))| |Edges(G(P))| For each measure, we prepare a sorted list of all candidate patterns. We remove patterns that are not in the top ZT (we use 100, see Section 6) in any of the three lists, and patterns that are in the bottom ZB in at least one of the lists. 5 Concept Discovery At the end of the previous stage we have a set of symmetric patterns. We now use them in order to discover concepts. The concept discovery algorithm is essentially the same as used by (Davidov and Rappoport, 2006)</context>
<context position="21177" citStr="Davidov and Rappoport, 2006" startWordPosition="3391" endWordPosition="3394">f the windows. This technique reduces noise at the potential cost of lowering coverage. A decrease in the number of windows should produce more noisy results, while discovering more concepts and terms. In the next section we show that while windowing is clearly required for a large corpus, incorporation of parser data increases the quality of the extracted corpus to the point where windowing can be significantly reduced. 6 Results In order to estimate the quality of concepts and to compare it to previous work, we have performed both automatic and human evaluation. Our basic comparison was to (Davidov and Rappoport, 2006) (we have obtained their data and utilized their algorithm), where we can estimate if incorporation of parser data can solve some fundamental weaknesses of their framework. In the following description, we call their algorithm P and our parser-based framework P+. We have also performed an indirect comparison to (Widdows and Dorow, 2002). While there is a significant number of other related studies4 on concept acquisition (see Section 2), 4Most are supervised and/or use language-specific tools. 52 direct or even indirect comparison to these works is problematic due to difference in corpora, pro</context>
<context position="22442" citStr="Davidov and Rappoport, 2006" startWordPosition="3588" endWordPosition="3591">egies. Below we describe the corpora and parameters used in our evaluation and then show and discuss WordNet-based and Human evaluation settings and results. Corpora. We performed in-depth evaluation in two languages, English and Russian, using three corpora, two for English and one for Russian. The first English corpus is the BNC, containing about 100M words. The second English corpus, DMOZ(Gabrilovich and Markovitch, 2005), is a web corpus obtained by crawling URLs in the Open Directory Project (dmoz.org), resulting in 68GB containing about 8.2G words from 50M web pages. The Russian corpus (Davidov and Rappoport, 2006) was assembled from web-based Russian repositories, to yield 33GB and 4G words. All of these corpora were also used by (Davidov and Rappoport, 2006) and BNC was used in similar settings by (Widdows and Dorow, 2002). Algorithm parameters. The thresholds TH, TC, TP, ZT, ZB, were determined mostly by practical memory size considerations: we computed thresholds that would give us the maximal number of terms, while enabling the pattern access table to reside in main memory. The resulting numbers are 100, 50, 20,100,100. Corpus window size was determined by starting from a small window size, extract</context>
<context position="25828" citStr="Davidov and Rappoport, 2006" startWordPosition="4170" endWordPosition="4174">ke P ones, allow the extraction of multiword expressions5, and indeed more than third of the discovered terms using P+ were MWEs. Utilization of MWEs not only allows to cover a greater amount of different words, but also increases the number of discovered concepts since new concepts can be found using cliques of newly discovered MWEs. From the results, we can see that for a given concept size and word coverage, the ability to discover MWEs overcomes the disadvantage of ignoring potentially useful concepts. Human judgment evaluation. Our humanjudgement evaluation closely followed the protocol (Davidov and Rappoport, 2006). We used 4 subjects for evaluation of the English 5While P method can potentially be used to extract MWEs, preliminary experimentation shows that without significant modification, quality of MWEs obtained by P is very low in comparison to P+ 53 concepts and 4 subjects for Russian ones. In order to assess subjects’ reliability, we also included random concepts (see below). The goal of the experiment was to examine the differences between the P+ and P concept acquisition frameworks. Subjects were given 50 triplets of words and were asked to rank them using the following scale: (1) the words def</context>
<context position="29422" citStr="Davidov and Rappoport, 2006" startWordPosition="4813" endWordPosition="4816">his shows that using parser data, the proposed framework can successfully avoid selection of erroneous terms, while discovering highquality terms missed by P. We can also see that P+ performance on MWEs, while being slightly inferior to the one for single-word terms, still achieves results comparable to those of single-word terms. Thus our algorithm can greatly improve the results not only by discovering of MWEs but also by improving the set of single word concept terms. WordNet-based evaluation. The major guideline in this part of the evaluation was to compare our results with previous work (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) without the possible bias of human evaluation. We have followed their methodology as best as we could, using the same WordNet (WN) categories and the same corpora. This also allows indirect comparison to several other studies, thus (Widdows and Dorow, 2002) reports results for an LSA-based clustering algorithm that are vastly inferior to the pattern-based ones. The evaluation method is as follows. We took the exact 10 WN subsets referred to as ‘subjects’ in (Widdows and Dorow, 2002), and removed all multiword items. We then selected at random 10 pairs of words from e</context>
<context position="31540" citStr="Davidov and Rappoport, 2006" startWordPosition="5184" endWordPosition="5188">me’). This was done in order to overcome the relative poorness of WN; (3) Recall: the number of words present in both C and WN divided by the number of words in WN; (4) The percentage of correctly discovered words (according to Precision*) that are not in WN. Table 3 compares the macro-average of these 10 categories to corresponding related work. We do not Prec. Prec.* Rec. %New DMOZ P 79.8 86.5 22.7 2.5 P+ 79.5 91.3 28.6 3.7 BNC P 92.76 95.72 7.22 0.4 P+ 93.0 96.1 14.6 1.7 Widdows 82.0 - - - Russian P 82.39 89.64 20.03 2.1 P+ 83.5 92.6 29.6 4.0 Table 3: WordNet evaluation in comparison to P (Davidov and Rappoport, 2006) and to Widdows(Widdows and Dorow, 2002). Columns show average precision, precision* (as defined in text), recall, and % of new words added to corresponding WN subtree. observe apparent rise in precision when comparing P+ and P, but we can see significant improvement in both recall and precision* for all of three corpora. In combination with human judgement results, this suggests that the P+ framework successfully discovers more correct terms not present in WN. This causes precision to remain constant while precision* improves significantly. Rise in recall also shows that the P+ framework can </context>
</contexts>
<marker>Davidov, Rappoport, 2006</marker>
<rawString>Dmitry Davidov, Ari Rappoport, 2006. Efficient Unsupervised Discovery of Word Categories using Symmetric Patterns and High Frequency Words. COLINGACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
<author>Moshe Koppel</author>
</authors>
<title>Fully Unsupervised Discovery of Concept-Specific Relationships by Web Mining.</title>
<date>2007</date>
<journal>ACL</journal>
<volume>07</volume>
<contexts>
<context position="9856" citStr="Davidov et al., 2007" startWordPosition="1480" endWordPosition="1483">dels (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durme, 2008; Davidov and Rappoport, 2009). While these methods have a definite practical advantage of dealing with the most recent and comprehensive data, web-based evaluation has some methodological drawbacks such as limited repeatability (Kilgarriff, 2007). In this study we apply our framework on offline corpora in settings similar to that of previous work, in order to be able to make proper comparisons. 3 Efficient Unsupervised Parsing Our method utilizes the information induced by unsupervised parsers. Specifically, we make use of the bracketings induced by Seginer’s parser</context>
</contexts>
<marker>Davidov, Rappoport, Koppel, 2007</marker>
<rawString>Dmitry Davidov, Ari Rappoport, Moshe Koppel, 2007. Fully Unsupervised Discovery of Concept-Specific Relationships by Web Mining. ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Translation and Extension of Concepts Across Languages.</title>
<date>2009</date>
<journal>EACL</journal>
<volume>09</volume>
<contexts>
<context position="9913" citStr="Davidov and Rappoport, 2009" startWordPosition="1489" endWordPosition="1492">plar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durme, 2008; Davidov and Rappoport, 2009). While these methods have a definite practical advantage of dealing with the most recent and comprehensive data, web-based evaluation has some methodological drawbacks such as limited repeatability (Kilgarriff, 2007). In this study we apply our framework on offline corpora in settings similar to that of previous work, in order to be able to make proper comparisons. 3 Efficient Unsupervised Parsing Our method utilizes the information induced by unsupervised parsers. Specifically, we make use of the bracketings induced by Seginer’s parser1 (Seginer, 2007). This parser has advantages in three ma</context>
</contexts>
<marker>Davidov, Rappoport, 2009</marker>
<rawString>Dmitry Davidov, Ari Rappoport, 2009. Translation and Extension of Concepts Across Languages. EACL ’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Deerwester</author>
<author>Susan Dumais</author>
<author>George Furnas</author>
<author>Thomas Landauer</author>
<author>Richard Harshman</author>
</authors>
<title>Indexing by Latent Semantic Analysis.</title>
<date>1990</date>
<journal>J. of the American Society for Info. Science,</journal>
<volume>41</volume>
<issue>6</issue>
<contexts>
<context position="6151" citStr="Deerwester et al., 1990" startWordPosition="909" endWordPosition="912">ed as defining a concept. A major algorithmic approach is to represent word contexts as vectors in some space and use distributional measures and clustering in that space. Pereira (1993), Curran (2002) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. Several studies avoid requiring any syntactic annotation. Some methods are based on decomposition of a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al., 1990). While great effort has been made for improving the computational complexity of distributional methods (Gorman and Curran, 2006), they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets. The second main approach is to use lexicosyntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns, numerous patte</context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Scott Deerwester, Susan Dumais, George Furnas, Thomas Landauer, Richard Harshman, 1990. Indexing by Latent Semantic Analysis. J. of the American Society for Info. Science, 41(6):391–407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Dennis</author>
</authors>
<title>An exemplar-based approach to unsupervised parsing.</title>
<date>2005</date>
<booktitle>Proceedings of the 27th Conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="9319" citStr="Dennis, 2005" startWordPosition="1397" endWordPosition="1399">greatly reduces such noise, the basic problem remains. As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durme, 2008; Davidov and Rappoport, 2009). Whil</context>
</contexts>
<marker>Dennis, 2005</marker>
<rawString>Simon Dennis, 2005. An exemplar-based approach to unsupervised parsing. Proceedings of the 27th Conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beate Dorow</author>
<author>Dominic Widdows</author>
<author>Katarina Ling</author>
<author>JeanPierre Eckmann</author>
<author>Danilo Sergi</author>
<author>Elisha Moses</author>
</authors>
<title>Using curvature and Markov clustering in Graphs for Lexical Acquisition and Word Sense Discrimination.</title>
<date>2005</date>
<journal>MEANING</journal>
<volume>05</volume>
<contexts>
<context position="7077" citStr="Dorow et al., 2005" startWordPosition="1054" endWordPosition="1057">approach is to use lexicosyntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns, numerous pattern-based methods have been proposed for the discovery of concepts from seeds. Other studies develop concept acquisition for on-demand tasks where concepts are defined by user-provided seeds. Many of these studies utilize information obtained by language-specific parsing and named entity recognition tools (Dorow et al., 2005). Pantel et al. (2004) reduce the depth of linguistic data used, but their method requires POS tagging. TextRunner (Banko et al., 2007) utilizes a set of pattern-based seed-less strategies in order to extract relational tuples from text. However, this system contains many language-specific modules, including the utilization of a parser in one of the processing stages. Thus the majority of the existing pattern-based concept acquisition systems rely on pattern/word seeds or supervised language-specific tools, some of which are very inefficient. Davidov and Rappoport (2006) developed a framework </context>
</contexts>
<marker>Dorow, Widdows, Ling, Eckmann, Sergi, Moses, 2005</marker>
<rawString>Beate Dorow, Dominic Widdows, Katarina Ling, JeanPierre Eckmann, Danilo Sergi, Elisha Moses, 2005. Using curvature and Markov clustering in Graphs for Lexical Acquisition and Word Sense Discrimination. MEANING ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Etzioni</author>
<author>Michael Cafarella</author>
<author>Doug Downey</author>
<author>S Kok</author>
</authors>
<title>Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel Weld, Alexander Yates,</title>
<date>2005</date>
<journal>Arti�cial Intelligence,</journal>
<volume>165</volume>
<issue>1</issue>
<contexts>
<context position="9834" citStr="Etzioni et al., 2005" startWordPosition="1476" endWordPosition="1479">2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durme, 2008; Davidov and Rappoport, 2009). While these methods have a definite practical advantage of dealing with the most recent and comprehensive data, web-based evaluation has some methodological drawbacks such as limited repeatability (Kilgarriff, 2007). In this study we apply our framework on offline corpora in settings similar to that of previous work, in order to be able to make proper comparisons. 3 Efficient Unsupervised Parsing Our method utilizes the information induced by unsupervised parsers. Specifically, we make use of the bracketings induc</context>
</contexts>
<marker>Etzioni, Cafarella, Downey, Kok, 2005</marker>
<rawString>Oren Etzioni, Michael Cafarella, Doug Downey, S. Kok, Ana-Maria Popescu, Tal Shaked, Stephen Soderland, Daniel Weld, Alexander Yates, 2005. Unsupervised Named-entity Extraction from the Web: An Experimental Study. Arti�cial Intelligence, 165(1):91134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Feature Generation for Text Categorization Using World Knowledge.</title>
<date>2005</date>
<journal>IJCAI</journal>
<volume>05</volume>
<contexts>
<context position="22242" citStr="Gabrilovich and Markovitch, 2005" startWordPosition="3556" endWordPosition="3559">ction 2), 4Most are supervised and/or use language-specific tools. 52 direct or even indirect comparison to these works is problematic due to difference in corpora, problem definitions and evaluation strategies. Below we describe the corpora and parameters used in our evaluation and then show and discuss WordNet-based and Human evaluation settings and results. Corpora. We performed in-depth evaluation in two languages, English and Russian, using three corpora, two for English and one for Russian. The first English corpus is the BNC, containing about 100M words. The second English corpus, DMOZ(Gabrilovich and Markovitch, 2005), is a web corpus obtained by crawling URLs in the Open Directory Project (dmoz.org), resulting in 68GB containing about 8.2G words from 50M web pages. The Russian corpus (Davidov and Rappoport, 2006) was assembled from web-based Russian repositories, to yield 33GB and 4G words. All of these corpora were also used by (Davidov and Rappoport, 2006) and BNC was used in similar settings by (Widdows and Dorow, 2002). Algorithm parameters. The thresholds TH, TC, TP, ZT, ZB, were determined mostly by practical memory size considerations: we computed thresholds that would give us the maximal number of</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2005</marker>
<rawString>Evgeniy Gabrilovich, Shaul Markovitch, 2005. Feature Generation for Text Categorization Using World Knowledge. IJCAI ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ilya Gelfenbeyn</author>
<author>Artem Goncharuk</author>
<author>Vladislav Lehelt</author>
<author>Anton Lipatov</author>
<author>Victor Shilo</author>
</authors>
<date>2003</date>
<booktitle>Automatic Translation of WordNet Semantic Network to Russian Language (in Russian) International Dialog</booktitle>
<note>Workshop.</note>
<marker>Gelfenbeyn, Goncharuk, Lehelt, Lipatov, Shilo, 2003</marker>
<rawString>Ilya Gelfenbeyn, Artem Goncharuk, Vladislav Lehelt, Anton Lipatov, Victor Shilo, 2003. Automatic Translation of WordNet Semantic Network to Russian Language (in Russian) International Dialog 2003 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Gorman</author>
<author>James R Curran</author>
</authors>
<title>Scaling Distributional Similarity to Large Corpora.</title>
<date>2006</date>
<journal>COLING-ACL</journal>
<volume>06</volume>
<contexts>
<context position="6280" citStr="Gorman and Curran, 2006" startWordPosition="928" endWordPosition="931">nal measures and clustering in that space. Pereira (1993), Curran (2002) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. Several studies avoid requiring any syntactic annotation. Some methods are based on decomposition of a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al., 1990). While great effort has been made for improving the computational complexity of distributional methods (Gorman and Curran, 2006), they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets. The second main approach is to use lexicosyntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns, numerous pattern-based methods have been proposed for the discovery of concepts from seeds. Other studies develop concept acquisition for on-de</context>
</contexts>
<marker>Gorman, Curran, 2006</marker>
<rawString>James Gorman, James R. Curran, 2006. Scaling Distributional Similarity to Large Corpora. COLING-ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William P Headden David McClosky</author>
<author>Eugene Charniak</author>
</authors>
<title>Evaluating Unsupervised Part-ofSpeech tagging for Grammar Induction.</title>
<date>2008</date>
<journal>COLING</journal>
<volume>08</volume>
<marker>McClosky, Charniak, 2008</marker>
<rawString>William P. Headden III, David McClosky and Eugene Charniak, 2008. Evaluating Unsupervised Part-ofSpeech tagging for Grammar Induction. COLING ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti Hearst</author>
</authors>
<title>Automatic Acquisition of Hyponyms from Large Text Corpora.</title>
<date>1992</date>
<journal>COLING</journal>
<volume>92</volume>
<contexts>
<context position="6673" citStr="Hearst, 1992" startWordPosition="996" endWordPosition="997"> lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al., 1990). While great effort has been made for improving the computational complexity of distributional methods (Gorman and Curran, 2006), they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale well for very large datasets. The second main approach is to use lexicosyntactic patterns. Patterns have been shown to produce more accurate results than feature vectors, at a lower computational cost on large corpora (Pantel et al., 2004). Since (Hearst, 1992), who used a manually prepared set of initial lexical patterns, numerous pattern-based methods have been proposed for the discovery of concepts from seeds. Other studies develop concept acquisition for on-demand tasks where concepts are defined by user-provided seeds. Many of these studies utilize information obtained by language-specific parsing and named entity recognition tools (Dorow et al., 2005). Pantel et al. (2004) reduce the depth of linguistic data used, but their method requires POS tagging. TextRunner (Banko et al., 2007) utilizes a set of pattern-based seed-less strategies in orde</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti Hearst, 1992. Automatic Acquisition of Hyponyms from Large Text Corpora. COLING ’92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kilgarriff</author>
</authors>
<title>Googleology is Bad Science.</title>
<date>2007</date>
<journal>Computational Linguistics</journal>
<volume>08</volume>
<pages>1--147</pages>
<contexts>
<context position="10130" citStr="Kilgarriff, 2007" startWordPosition="1522" endWordPosition="1523"> or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durme, 2008; Davidov and Rappoport, 2009). While these methods have a definite practical advantage of dealing with the most recent and comprehensive data, web-based evaluation has some methodological drawbacks such as limited repeatability (Kilgarriff, 2007). In this study we apply our framework on offline corpora in settings similar to that of previous work, in order to be able to make proper comparisons. 3 Efficient Unsupervised Parsing Our method utilizes the information induced by unsupervised parsers. Specifically, we make use of the bracketings induced by Seginer’s parser1 (Seginer, 2007). This parser has advantages in three major as1The parser is freely available at http://staff.science.uva.nl/∼yseginer/ccl pects relevant to this paper. First, it achieves state of the art unsupervised parsing performance: its F-score2 is 75.9% for sentence</context>
</contexts>
<marker>Kilgarriff, 2007</marker>
<rawString>Adam Kilgarriff, 2007. Googleology is Bad Science. Computational Linguistics ’08, Vol.33 No. 1,pp147-151. .</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<title>A generative constituent-context model for improved grammar induction.</title>
<date>2002</date>
<booktitle>Proc. of the 40th Meeting of the ACL.</booktitle>
<contexts>
<context position="9165" citStr="Klein and Manning, 2002" startWordPosition="1371" endWordPosition="1374">nsidered as a candidate for the ‘dog type’ concept), and misses the discovery of a valid multiword candidate (“Australlian Bulldog”). While symmetry-based filtering greatly reduces such noise, the basic problem remains. As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed framework</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Dan Klein and Christopher Manning, 2002. A generative constituent-context model for improved grammar induction. Proc. of the 40th Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher Manning</author>
</authors>
<title>Corpusbased induction of syntactic structure: Models of dependency and constituency.</title>
<date>2004</date>
<journal>ACL</journal>
<volume>04</volume>
<contexts>
<context position="9219" citStr="Klein and Manning, 2004" startWordPosition="1380" endWordPosition="1383">nd misses the discovery of a valid multiword candidate (“Australlian Bulldog”). While symmetry-based filtering greatly reduces such noise, the basic problem remains. As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzio</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Christopher Manning, 2004. Corpusbased induction of syntactic structure: Models of dependency and constituency. ACL ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
</authors>
<title>The unsupervised learning of natural language structure.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="8980" citStr="Klein, 2005" startWordPosition="1345" endWordPosition="1346">“choose either Chihuahua 49 or Collie.”) and bad ones (“either Collie or Australian Bulldog”). In the latter case, the algorithm both captures noise (“Australlian” is now considered as a candidate for the ‘dog type’ concept), and misses the discovery of a valid multiword candidate (“Australlian Bulldog”). While symmetry-based filtering greatly reduces such noise, the basic problem remains. As a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syn</context>
<context position="12935" citStr="Klein, 2005" startWordPosition="1984" endWordPosition="1985">ctic representation we use in this work. The parsing algorithm creates the common-cover links structure of a sentence in an incremental manner. This means that the parser reads the words of a sentence one after the other and, as each word is read, it is only allowed to add links that have one of their ends at that words (and update existing ones). Words which have not yet been read are not avail2F = 2·R·P, where R and P are the recall and precision of R+Pthe parsers’ bracketing compared to manually created bracketing of the same text. This is the accepted measure for parsing performance (see (Klein, 2005)). 50 able to the parser at this stage. This restriction is inspired by psycholinguistics research which suggests that humans process language incrementally. This results in a significant restriction of the parser’s search space, which is the reason it is so fast. During its initial stage the parser builds a lexicon containing, for each word, statistics helping the decision of whether to link that word to other words. The lexicon is updated as any new sentence is read. Lexicon updating is also done in an incremental manner so this stage is also very fast. 4 Unsupervised Pattern Discovery In th</context>
</contexts>
<marker>Klein, 2005</marker>
<rawString>Dan Klein, 2005. The unsupervised learning of natural language structure. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hang Li</author>
<author>Naoki Abe</author>
</authors>
<date>1996</date>
<booktitle>Clustering Words with the MDL Principle. COLING ’96.</booktitle>
<marker>Li, Abe, 1996</marker>
<rawString>Hang Li, Naoki Abe, 1996. Clustering Words with the MDL Principle. COLING ’96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic Retrieval and Clustering of Similar Words.</title>
<date>1998</date>
<journal>COLING</journal>
<volume>98</volume>
<contexts>
<context position="5743" citStr="Lin (1998)" startWordPosition="851" endWordPosition="852">on lexical acquisition of all sorts and the acquisition of concepts in particular. Concept acquisition methods differ in the type of corpus annotation and other human input used, and in their basic algorithmic approach. Some methods directly aim at concept acquisition, while the direct goal in some is the construction of hyponym (‘is-a’) hierarchies. A subtree in such a hierarchy can be viewed as defining a concept. A major algorithmic approach is to represent word contexts as vectors in some space and use distributional measures and clustering in that space. Pereira (1993), Curran (2002) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. Several studies avoid requiring any syntactic annotation. Some methods are based on decomposition of a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al., 1990). While great effort has been made for improving the computational complexity of distributional methods (Gorman and Curran, 2006), they still remain highly computationally intensive in compari</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin, 1998. Automatic Retrieval and Clustering of Similar Words. COLING ’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcus Mitchell P</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<marker>P, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Marcus Mitchell P., Beatrice Santorini and Mary Ann Marcinkiewicz, 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marius Pasca</author>
<author>Benjamin Van Durme</author>
</authors>
<title>Weaklysupervised Acquisition of Open-domain Classes and Class Attributes from Web Documents and Query Logs.</title>
<date>2008</date>
<journal>ACL</journal>
<volume>08</volume>
<marker>Pasca, Van Durme, 2008</marker>
<rawString>Marius Pasca, Benjamin Van Durme, 2008. Weaklysupervised Acquisition of Open-domain Classes and Class Attributes from Web Documents and Query Logs. ACL 08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Dekang Lin</author>
</authors>
<title>Discovering Word Senses from Text.</title>
<date>2002</date>
<journal>SIGKDD</journal>
<volume>02</volume>
<contexts>
<context position="5815" citStr="Pantel and Lin, 2002" startWordPosition="860" endWordPosition="863">ncepts in particular. Concept acquisition methods differ in the type of corpus annotation and other human input used, and in their basic algorithmic approach. Some methods directly aim at concept acquisition, while the direct goal in some is the construction of hyponym (‘is-a’) hierarchies. A subtree in such a hierarchy can be viewed as defining a concept. A major algorithmic approach is to represent word contexts as vectors in some space and use distributional measures and clustering in that space. Pereira (1993), Curran (2002) and Lin (1998) use syntactic features in the vector definition. (Pantel and Lin, 2002) improves on the latter by clustering by committee. Caraballo (1999) uses conjunction and appositive annotations in the vector representation. Several studies avoid requiring any syntactic annotation. Some methods are based on decomposition of a lexically-defined matrix (by SVD, PCA etc), e.g. (Sch¨utze, 1998; Deerwester et al., 1990). While great effort has been made for improving the computational complexity of distributional methods (Gorman and Curran, 2006), they still remain highly computationally intensive in comparison to pattern approaches (see below), and most of them do not scale wel</context>
</contexts>
<marker>Pantel, Lin, 2002</marker>
<rawString>Patrick Pantel, Dekang Lin, 2002. Discovering Word Senses from Text. SIGKDD ’02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
</authors>
<title>Deepak Ravichandran, Eduard Hovy,</title>
<date>2004</date>
<journal>COLING</journal>
<volume>04</volume>
<marker>Pantel, 2004</marker>
<rawString>Patrick Pantel, Deepak Ravichandran, Eduard Hovy, 2004. Towards Terascale Knowledge Acquisition. COLING ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lillian Lee</author>
</authors>
<title>Distributional Clustering of English Words.</title>
<date>1993</date>
<journal>ACL</journal>
<volume>93</volume>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando Pereira, Naftali Tishby, Lillian Lee, 1993. Distributional Clustering of English Words. ACL ’93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic Word Sense Discrimination.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<marker>Sch¨utze, 1998</marker>
<rawString>Hinrich Sch¨utze, 1998. Automatic Word Sense Discrimination. Computational Linguistics, 24(1):97–123.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Seginer</author>
</authors>
<title>Fast Unsupervised Incremental Parsing.</title>
<date>2007</date>
<journal>ACL</journal>
<volume>07</volume>
<contexts>
<context position="9431" citStr="Seginer (2007)" startWordPosition="1414" endWordPosition="1415">tion in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durme, 2008; Davidov and Rappoport, 2009). While these methods have a definite practical advantage of dealing with the most recent and comprehensive data, web-</context>
<context position="11846" citStr="Seginer, 2007" startWordPosition="1798" endWordPosition="1799">ly decreases when using POS tags induced by unsupervised POS taggers instead of manually created ones. Seginer’s incremental parser is therefore the only fully unsupervised parser providing high quality parses. Third, Seginer’s parser is extremely fast. During its initial stage, the parser builds a lexicon. Our Pentium 2.8GHB machines with 4GHB RAM can store in memory the lexicon created by up to 0.2M sentences. We thus divided our corpora to batches of 0.2M sentences and parsed each of them separately. Note that in this setup parsing quality might be even better than the quality reported in (Seginer, 2007), since in the setup reported in that paper the parser was applied to a few thousand sentences only. On average, the parsing time of a single batch was 5 minutes (run time did not significantly differ across batches and corpora). Parser description. The parser utilizes the novel common-cover link representation for syntactic structure. This representation resembles dependency structure but unlike the latter, it can be translated into a constituency tree, which is the syntactic representation we use in this work. The parsing algorithm creates the common-cover links structure of a sentence in an</context>
</contexts>
<marker>Seginer, 2007</marker>
<rawString>Yoav Seginer, 2007. Fast Unsupervised Incremental Parsing. ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noah A Smith</author>
<author>Jason Eisner</author>
</authors>
<title>Annealing Structural Bias in Multilingual Weighted Grammar Induction .</title>
<date>2006</date>
<journal>ACL</journal>
<volume>06</volume>
<contexts>
<context position="9385" citStr="Smith and Eisner, 2006" startWordPosition="1405" endWordPosition="1408">s a result, incorporating at least some parsing information in a language-independent and efficient manner could be beneficial. Unsupervised parsing has been explored for several decades (see (Clark, 2001; Klein, 2005) for recent reviews). Recently, unsupervised parsers have for the first time outperformed the right branching heuristic baseline for English. These include CCM (Klein and Manning, 2002), the DMV and DMV+CCM models (Klein and Manning, 2004), (U)DOP based models (Bod, 2006a; Bod, 2006b; Bod, 2007), an exemplar based approach (Dennis, 2005), guiding EM using contrastive estimation (Smith and Eisner, 2006), and the incremental parser of Seginer (2007) which we use here. These works learn an unlabeled syntactic structure, dependency or constituency. In this work we use constituency trees as our syntactic representation. Another important factor in concept acquisition is the source of textual data used. To take advantage of the rapidly expanding web, many of the proposed frameworks utilize web queries rather than local corpora (Etzioni et al., 2005; Davidov et al., 2007; Pasca and Van Durme, 2008; Davidov and Rappoport, 2009). While these methods have a definite practical advantage of dealing wit</context>
</contexts>
<marker>Smith, Eisner, 2006</marker>
<rawString>Noah A. Smith and Jason Eisner, 2006. Annealing Structural Bias in Multilingual Weighted Grammar Induction . ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominic Widdows</author>
<author>Beate Dorow</author>
</authors>
<title>A Graph Model for Unsupervised Lexical Acquisition.</title>
<date>2002</date>
<journal>COLING</journal>
<volume>02</volume>
<contexts>
<context position="17188" citStr="Widdows and Dorow, 2002" startWordPosition="2704" endWordPosition="2707">ly). Examples of such patterns include “((C1)in C2))”, “(C1)(such(as(((C2)”, and “(C1)and(C2)”3. We dismiss rare patterns that appear less than TP times per million words. Symmetric patterns. Many of the pattern candidates discovered in the previous stage are not usable. In order to find a usable subset, we focus on the symmetric patterns. We define a symmetric pattern as a pattern in which the same pair of terms (C words) is likely to appear in both left-to-right and right-toleft orders. In order to identify symmetric patterns, for each pattern we define a pattern graph G(P), as proposed by (Widdows and Dorow, 2002). If term pair (C1, C2) appears in pattern P in some context, 3This paper does not use any punctuation since the parser is provided with sentences having all non-alphabetic characters removed. We assume word separation. C1,2 can be a word or a multiword expression. 51 we add nodes c1, c2 to the graph and a directed edge EP(c1, c2) between them. In order to select symmetric patterns, we create such a pattern graph for every discovered pattern, and create a symmetric subgraph SymG(P) in which we take only bidirectional edges from G(P). Then we compute three measures for each pattern candidate as</context>
<context position="18501" citStr="Widdows and Dorow, 2002" startWordPosition="2932" endWordPosition="2935">M2(P) :=|Nodes(SymG(P))| |Nodes(G(P))| M3(P) := |Edges(SymG(P ))| |Edges(G(P))| For each measure, we prepare a sorted list of all candidate patterns. We remove patterns that are not in the top ZT (we use 100, see Section 6) in any of the three lists, and patterns that are in the bottom ZB in at least one of the lists. 5 Concept Discovery At the end of the previous stage we have a set of symmetric patterns. We now use them in order to discover concepts. The concept discovery algorithm is essentially the same as used by (Davidov and Rappoport, 2006) and has some similarity with the one used by (Widdows and Dorow, 2002). In this section we outline the algorithm. The clique-set method. The utilized approach to concept discovery is based on connectivity structures in the all-pattern term relationship graph G, resulting from merging all of the single-pattern graphs for symmetric patterns selected in the previous stage. The main observation regarding G is that highly interconnected words are good candidates to form a concept. We find all strong n-cliques (subgraphs containing n nodes that are all interconnected in both directions). A clique Q defines a concept that contains all of the nodes in Q plus all of the </context>
<context position="21515" citStr="Widdows and Dorow, 2002" startWordPosition="3446" endWordPosition="3449">of the extracted corpus to the point where windowing can be significantly reduced. 6 Results In order to estimate the quality of concepts and to compare it to previous work, we have performed both automatic and human evaluation. Our basic comparison was to (Davidov and Rappoport, 2006) (we have obtained their data and utilized their algorithm), where we can estimate if incorporation of parser data can solve some fundamental weaknesses of their framework. In the following description, we call their algorithm P and our parser-based framework P+. We have also performed an indirect comparison to (Widdows and Dorow, 2002). While there is a significant number of other related studies4 on concept acquisition (see Section 2), 4Most are supervised and/or use language-specific tools. 52 direct or even indirect comparison to these works is problematic due to difference in corpora, problem definitions and evaluation strategies. Below we describe the corpora and parameters used in our evaluation and then show and discuss WordNet-based and Human evaluation settings and results. Corpora. We performed in-depth evaluation in two languages, English and Russian, using three corpora, two for English and one for Russian. The </context>
<context position="29448" citStr="Widdows and Dorow, 2002" startWordPosition="4817" endWordPosition="4820">ata, the proposed framework can successfully avoid selection of erroneous terms, while discovering highquality terms missed by P. We can also see that P+ performance on MWEs, while being slightly inferior to the one for single-word terms, still achieves results comparable to those of single-word terms. Thus our algorithm can greatly improve the results not only by discovering of MWEs but also by improving the set of single word concept terms. WordNet-based evaluation. The major guideline in this part of the evaluation was to compare our results with previous work (Davidov and Rappoport, 2006; Widdows and Dorow, 2002) without the possible bias of human evaluation. We have followed their methodology as best as we could, using the same WordNet (WN) categories and the same corpora. This also allows indirect comparison to several other studies, thus (Widdows and Dorow, 2002) reports results for an LSA-based clustering algorithm that are vastly inferior to the pattern-based ones. The evaluation method is as follows. We took the exact 10 WN subsets referred to as ‘subjects’ in (Widdows and Dorow, 2002), and removed all multiword items. We then selected at random 10 pairs of words from each subject. For each pair</context>
<context position="31580" citStr="Widdows and Dorow, 2002" startWordPosition="5191" endWordPosition="5194"> relative poorness of WN; (3) Recall: the number of words present in both C and WN divided by the number of words in WN; (4) The percentage of correctly discovered words (according to Precision*) that are not in WN. Table 3 compares the macro-average of these 10 categories to corresponding related work. We do not Prec. Prec.* Rec. %New DMOZ P 79.8 86.5 22.7 2.5 P+ 79.5 91.3 28.6 3.7 BNC P 92.76 95.72 7.22 0.4 P+ 93.0 96.1 14.6 1.7 Widdows 82.0 - - - Russian P 82.39 89.64 20.03 2.1 P+ 83.5 92.6 29.6 4.0 Table 3: WordNet evaluation in comparison to P (Davidov and Rappoport, 2006) and to Widdows(Widdows and Dorow, 2002). Columns show average precision, precision* (as defined in text), recall, and % of new words added to corresponding WN subtree. observe apparent rise in precision when comparing P+ and P, but we can see significant improvement in both recall and precision* for all of three corpora. In combination with human judgement results, this suggests that the P+ framework successfully discovers more correct terms not present in WN. This causes precision to remain constant while precision* improves significantly. Rise in recall also shows that the P+ framework can discover significantly more correct term</context>
</contexts>
<marker>Widdows, Dorow, 2002</marker>
<rawString>Dominic Widdows, Beate Dorow, 2002. A Graph Model for Unsupervised Lexical Acquisition. COLING ’02.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>