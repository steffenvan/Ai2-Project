<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004590">
<note confidence="0.788928">
Computational Linguistics Volume 26, Number 4
</note>
<title confidence="0.941986">
Architectures and Mechanisms for Language Processing
</title>
<author confidence="0.444667">
Matthew W. Crocker, Martin Pickering, and Charles Clifton, Jr. (editors)
</author>
<affiliation confidence="0.269661">
(University of the Saarland, University of Glasgow, and University of Massachusetts,
</affiliation>
<figure confidence="0.661562833333333">
Amherst)
Cambridge University Press, 2000,
x+365 pp; hardbound ISBN
0-521-63121-1, $64.95
Reviewed by
Amy Weinberg
</figure>
<affiliation confidence="0.508896">
University of Maryland
</affiliation>
<bodyText confidence="0.999696583333333">
The concerns of psycholirtguists will look very familiar to people engaged in CL re-
search. A major area of investigation in psycholinguistics is determining how a listener
uses frequency and other experience-based information during on-line sentence un-
derstanding. This book gives cornputationalists a distinguished guide to the current
issues in the field. It is very clear that psycholinguistics has been influenced by recent
work in CL, and is ripe for further cross-fertilization. Many of the papers recognize
that more rigorous modeling is called for and that these models will require insights
from computational linguistics. I will highlight some of the issues that shape current
debates, with particular emphasis on areas of common interest between psycholin-
guistics and CL.
The major source of data in the theory of human sentence processing comes from
the disambiguation of temporarily ambiguous sentences as in examples (1) and (2):
</bodyText>
<listItem confidence="0.804898666666667">
(1) The man believed the woman {implicitly I was unhappy.}
(2) The girl heard by the window {that John was coming I was speaking
too loudly.}
</listItem>
<bodyText confidence="0.999907">
The boldface material represents two possible continuations of the first part of each
sentence, but the choice of the appropriate continuation depends on how the parser
initially structures the preceding material. In (1), the parser might choose to make the
postverbal noun phrase either the direct object of the matrix verb, compatible with
the first continuation, or the subject of an upcoming complement sentence, compatible
with the second. In (2), the ambiguity centers upon whether heard is taken as an
active main verb or as a passive participle inside a relative clause (the girl who was
heard). Early experiments such as those of Frazier and Rayner (1982) suggested that
speakers had a clear preference for the first continuation in each case, as verified by
an increase in reaction time when the disambiguating word, underlined in examples
above, forced the second continuation. In a case such as (1), the initial preference
seems easy to reanalyze, while in (2), the correct analysis seems unrecoverable and
is commonly referred to as a garden path. These facts were initially explained by a
theory that assumed a serial parser. The choice function guiding the initial analysis
was independently justified either by considerations drawn from linguistics (Gibson
1991, Weinberg 2000) or theories of memory (Frazier and Rayner 1982). Importantly,
these theories assumed that listeners delayed consideration of semantic, pragmatic, or
frequency-based factors until after an initial analysis was constructed.
The present book highlights recent extensions and challenges to these theories.
</bodyText>
<page confidence="0.991484">
648
</page>
<subsectionHeader confidence="0.884172">
Book Reviews
</subsectionHeader>
<bodyText confidence="0.997766326530612">
Chapters by Richard Lewis (based on SOAR [Newell 19901), by Paola Merlo and
Suzanne Stevenson (based on a symbolic connectionist architecture), and by James
Henderson (based on an extension of recurrent networks using Temporal Serial Vari-
able Binding) try to derive initial parsing preferences and to distinguish possible from
impossible reanalyses by means of architectural constraints defined in their underly-
ing (implemented) models. The common idea here is that the distinction between an
easy reanalysis and a garden path should fall out as a side effect of constraints that
need to be imposed on the system in order to allow it to perform analysis on &amp;quot;normal&amp;quot;
unambiguous input in an efficient mariner. These models suggest that restrictions on
how local the initial tnisattachment point is to the point of disambiguation, or how
many constraints need to be specified in order for attachment to occur, determine the
possibility of reanalysis. The fact that these factors characterize models with such dif-
ferent architectural bases suggests that these notions will play an important role in the
design of any parser.
Chapters by Charles Clifton, Jr., by Michael Tarienhaus, Michael Spivey-Knowlton,
and Joy Hanna, by Gerry Altmann, by Steffan Corley and Matthew Crocker, and by
Martin Pickering and Matthew Traxler debate the correctness of the simple statement
of the preference function that chooses initial analyses in terms of a set of noninteract-
ing nonsemantic or pragmatic constraints. Evidence in favor of a radically interactive
constraint-satisfaction model comes from the nonstationarity of preferences during
sentence comprehension. For example, the relative frequency with which a verb ap-
pears as either an active main verb or a passive participle, the compatibility of the
subject noun phrase with interpretation as the agent of a clause (as required by the
verb of a main-clause analysis), and the presence of a post-verbal by phrase (normally
associated with a passive participle), contribute to the availability of the reduced rel-
ative clause, as shown by the ease of interpretation in (3).
(3) The evidence examined by the lawyer turned out to be unreliable.
In (3), evidence is a bad agent, and thus would disfavor the main-verb analysis of ex-
amined. The by phrase, which is associated with the passive-participle reading, also
disfavors the main-clause reading. Trueswell, Tan.enhaus, and Garnsey (1994) found
no significant difference in reading time at the main verb ((urned) when compared
with an unambiguous control (formed by replacing examined with a verb like chosen).
Noninteractive theorists claim that this means that the parser initially tries the wrong
main-clause analysis, on the basis of structural factors, but that this analysis is rapidly
revised. Interactive theorists claim, however, that this result follows simply from al-
lowing factors like &amp;quot;agentivity&amp;quot; and &amp;quot;presence of by&amp;quot; to interact in the choice of the
initial analysis. The chapter by Tanenhaus, Spivey-Knowlton, and Hanna presents a
constraint-satisfaction implementation that allows us to test predictions of the inter-
active theory. They claim that the model can explain a range of hitherto contradictory
findings. For example, they claim that experiments, such as that of Ferreira and Clifton
(1986), using stimuli like (3) but without the by phrase, that were interpreted as demon-
strating a stage where the parser abstracted away from issues of agentivity, could
actually be predicted by an interactive model. This is because Ferreira and Clifton&apos;s
stimuli did not include by phrases that could further bias the model to the relative-
clause reading of the ambiguous verb, because the language as a whole is biased to
treat main-verb/past-particle ambiguities as main verbs, and because the stimuli used
verbs that were equibiased between a relative-clause and main-clause reading. These
factors conspired in their simulation to outweigh any evidence from the nonagentiv-
ity of the subject, which would favor the relative-clause reading. By contrast, since
</bodyText>
<page confidence="0.996982">
649
</page>
<note confidence="0.6444">
Computational Linguistics Volume 26, Number 4
</note>
<bodyText confidence="0.9998415">
the stimuli in Trueswell, Tanenhaus, and Garnsey (1994) contained more factors that
biased in favor of the relative-clause reading, an interactive model would predict that
relative clauses would be easier to understand in these cases.
On the other hand, two major criticisms of constraint-based models are leveled
by Clifton in this volume. The first is that, while there is much evidence that one can
make the dispreferred analysis a more fit competitor, one doesn&apos;t seem to be able to
make the analysis preferred by purely structural constraints unfit (e.g., blocking the
preferred interpretation in cases where it turns out to be correct). This is predicted by
a model that gives particular constraints a first crack at analysis, but is not predicted
by a fully interactive model.
The second criticism is that it is too easy to produce models that can handle any
range of data if there is no limit to the number and type of constraints that can in-
teract. As more sources of constraint are proposed, this becomes a real problem. For
example, Altmann&apos;s and Pickering and Traxler&apos;s chapters emphasize the contribution
of plausibility as a source of constraint. Corley and Crocker try to deal with this second
line of attack. While it is reasonable to believe that the mental lexicon contains entries
for verbs that specify the likelihood of each possible complement type, considerations
of sparse data make it less feasible to suppose that every lexical choice for possi-
ble adjective-noun pairs is stored. Nonetheless, there seems to be a clear difference
between the ease of understanding of cases such as (4) and (5):
</bodyText>
<listItem confidence="0.905915">
(4) The warehouse fires many of its employees every summer.
(5) The corporation fires many of its employees every summer.
</listItem>
<bodyText confidence="0.993894526315789">
MacDonald (1994) suggested that this was due to the greater frequency of warehouse
fires as an adjective-noun pair and the relative rarity of this part-of-speech analysis for
corporation fires.
Corley and Crocker try to show that these data do not force word-by-word bigrarn
conditioning, and propose an alternative where only word to part-of-speech-category
(unigram) and part-of-speech-category to part-of-speech-category (bigram) parameters
are computed when assigning probabilities to ambiguous lexical items. Their model
is inspired by standard part-of-speech taggers. This balancing between enriching the
repertoire of constraints and keeping their number tractable and learnable should also
occupy the field in the near future.
Topics of the rest of the book include expanding the experimental paradigms used
in sentence processing (to ERP work, as discussed in Cohn Brown and Pater Hagoort&apos;s
chapter), expanding the cross-linguistic coverage of the field (in chapters by Barbara
Hemforth, Lars Konieczny, and Christoph Scheepers and by Marica De Vincenzi), and,
in an interesting final section, semantic processing (chapters by Lyn Frazier, by Linda
Moxey and Anthony Sanford, and by Amit Almor).
This book represents the state of the art in sentence processing, with interesting
examples and opportunities for computational modeling. The themes that it presents
are likely to occupy the field for some time.
</bodyText>
<sectionHeader confidence="0.982625" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.991254230769231">
Ferreira, Fernanda and Clifton, Charles Jr.
1986. The independence of syntactic
processing. journal of Memory and Language,
25: 348-368.
Frazier, Lyn and Rayner, Keith. 1982. Making
and correcting errors during sentence
comprehension: Eye movements in the
analysis of structurally ambiguous
sentences. Cognitive Psycho/op, 14:
178-210,
Gibson, Edward. 1991. A computational theory
of human linguistic processing. Unpublished
doctoral thesis, Carnegie Mellon
</reference>
<page confidence="0.990469">
650
</page>
<reference confidence="0.963692833333333">
Book Reviews
University
MacDonald, Maryellen C. 1994. Probabilistic
constraints and syntactic ambiguity
resolution. Language and Cognitive Processes,
9: 157-201.
Newell, Allen. 1990. Unified Theories of
Cognition. Harvard University Press,
Cambridge, MA.
Trueswell, John C., Michael K. Tanenhaus,
and Susan M. Garnsey. 1994. Semantic
influences on parsing: Use of thematic
role information in syntactic ambiguity
resolution. Journal of Memory and Language,
33: 285-318.
Weinberg, Amy. 2000. A minimalist parser.
In Samuel David Epstein and Norbert
Hornstein, editors, Working Minimalism,
The MIT Press, Cambridge, MA.
Amy Weinberg is an Associate Professor in the Department of Linguistics and the Institute for
Advanced Computer Studies at the University of Maryland. She has worked on computational
and experimental models of sentence processing, as well as models for foreign-language tutoring
and machine translation. Weinberg&apos;s address is: LEVIIACS, University of Maryland, College Park,
MD 20742; e-mail: weinberg@untiacs.umd.edu.
</reference>
<page confidence="0.99845">
651
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000090">
<title confidence="0.8133395">Computational Linguistics Volume 26, Number 4 Architectures and Mechanisms for Language Processing</title>
<affiliation confidence="0.999956">University of the Saarland, University of Glasgow, and University of Massachusetts,</affiliation>
<address confidence="0.746815">Amherst) Cambridge University Press, 2000, x+365 pp; hardbound ISBN 0-521-63121-1, $64.95</address>
<note confidence="0.843125">Reviewed by</note>
<author confidence="0.99943">Amy Weinberg</author>
<affiliation confidence="0.995103">University of Maryland</affiliation>
<abstract confidence="0.991358705882353">The concerns of psycholirtguists will look very familiar to people engaged in CL remajor of investigation in psycholinguistics is determining how a listener uses frequency and other experience-based information during on-line sentence understanding. This book gives cornputationalists a distinguished guide to the current issues in the field. It is very clear that psycholinguistics has been influenced by recent work in CL, and is ripe for further cross-fertilization. Many of the papers recognize that more rigorous modeling is called for and that these models will require insights from computational linguistics. I will highlight some of the issues that shape current debates, with particular emphasis on areas of common interest between psycholinguistics and CL. The major source of data in the theory of human sentence processing comes from disambiguation of temporarily ambiguous sentences as in examples (2): The man believed the woman {implicitlyI was The girl heard by the window John was coming I was speaking too loudly.} The boldface material represents two possible continuations of the first part of each sentence, but the choice of the appropriate continuation depends on how the parser initially structures the preceding material. In (1), the parser might choose to make the postverbal noun phrase either the direct object of the matrix verb, compatible with the first continuation, or the subject of an upcoming complement sentence, compatible the second. In (2), the ambiguity centers upon whether taken as an main verb or as a passive participle inside a relative clause girl who was experiments such as those of Frazier and Rayner (1982) suggested that speakers had a clear preference for the first continuation in each case, as verified by an increase in reaction time when the disambiguating word, underlined in examples forced the second continuation. In a case such as initial preference seems easy to reanalyze, while in (2), the correct analysis seems unrecoverable and is commonly referred to as a garden path. These facts were initially explained by a theory that assumed a serial parser. The choice function guiding the initial analysis was independently justified either by considerations drawn from linguistics (Gibson 1991, Weinberg 2000) or theories of memory (Frazier and Rayner 1982). Importantly, these theories assumed that listeners delayed consideration of semantic, pragmatic, or frequency-based factors until after an initial analysis was constructed. The present book highlights recent extensions and challenges to these theories.</abstract>
<note confidence="0.767435333333333">648 Book Reviews Chapters by Richard Lewis (based on SOAR [Newell 19901), by Paola Merlo and</note>
<title confidence="0.800925">Suzanne Stevenson (based on a symbolic connectionist architecture), and by James</title>
<author confidence="0.83088">Henderson</author>
<abstract confidence="0.981700480392157">able Binding) try to derive initial parsing preferences and to distinguish possible from impossible reanalyses by means of architectural constraints defined in their underlying (implemented) models. The common idea here is that the distinction between an easy reanalysis and a garden path should fall out as a side effect of constraints that need to be imposed on the system in order to allow it to perform analysis on &amp;quot;normal&amp;quot; unambiguous input in an efficient mariner. These models suggest that restrictions on how local the initial tnisattachment point is to the point of disambiguation, or how many constraints need to be specified in order for attachment to occur, determine the possibility of reanalysis. The fact that these factors characterize models with such different architectural bases suggests that these notions will play an important role in the design of any parser. Chapters by Charles Clifton, Jr., by Michael Tarienhaus, Michael Spivey-Knowlton, and Joy Hanna, by Gerry Altmann, by Steffan Corley and Matthew Crocker, and by Martin Pickering and Matthew Traxler debate the correctness of the simple statement of the preference function that chooses initial analyses in terms of a set of noninteracting nonsemantic or pragmatic constraints. Evidence in favor of a radically interactive constraint-satisfaction model comes from the nonstationarity of preferences during sentence comprehension. For example, the relative frequency with which a verb appears as either an active main verb or a passive participle, the compatibility of the subject noun phrase with interpretation as the agent of a clause (as required by the of a main-clause analysis), and the presence of a post-verbal (normally associated with a passive participle), contribute to the availability of the reduced relative clause, as shown by the ease of interpretation in (3). The evidence examined by the lawyer turned out to be unreliable. (3), a bad agent, and thus would disfavor the main-verb analysis of exwhich is associated with the passive-participle reading, also disfavors the main-clause reading. Trueswell, Tan.enhaus, and Garnsey (1994) found significant difference in reading time at the main verb compared an unambiguous control (formed by replacing a verb like Noninteractive theorists claim that this means that the parser initially tries the wrong main-clause analysis, on the basis of structural factors, but that this analysis is rapidly revised. Interactive theorists claim, however, that this result follows simply from alfactors like &amp;quot;agentivity&amp;quot; and &amp;quot;presence of by&amp;quot; to interact in the the initial analysis. The chapter by Tanenhaus, Spivey-Knowlton, and Hanna presents a constraint-satisfaction implementation that allows us to test predictions of the interactive theory. They claim that the model can explain a range of hitherto contradictory findings. For example, they claim that experiments, such as that of Ferreira and Clifton using stimuli like (3) but without the that were interpreted as demonstrating a stage where the parser abstracted away from issues of agentivity, could actually be predicted by an interactive model. This is because Ferreira and Clifton&apos;s stimuli did not include by phrases that could further bias the model to the relativeclause reading of the ambiguous verb, because the language as a whole is biased to treat main-verb/past-particle ambiguities as main verbs, and because the stimuli used verbs that were equibiased between a relative-clause and main-clause reading. These factors conspired in their simulation to outweigh any evidence from the nonagentivity of the subject, which would favor the relative-clause reading. By contrast, since 649 Computational Linguistics Volume 26, Number 4 the stimuli in Trueswell, Tanenhaus, and Garnsey (1994) contained more factors that biased in favor of the relative-clause reading, an interactive model would predict that relative clauses would be easier to understand in these cases. On the other hand, two major criticisms of constraint-based models are leveled by Clifton in this volume. The first is that, while there is much evidence that one can make the dispreferred analysis a more fit competitor, one doesn&apos;t seem to be able to make the analysis preferred by purely structural constraints unfit (e.g., blocking the preferred interpretation in cases where it turns out to be correct). This is predicted by a model that gives particular constraints a first crack at analysis, but is not predicted by a fully interactive model. The second criticism is that it is too easy to produce models that can handle any range of data if there is no limit to the number and type of constraints that can interact. As more sources of constraint are proposed, this becomes a real problem. For example, Altmann&apos;s and Pickering and Traxler&apos;s chapters emphasize the contribution of plausibility as a source of constraint. Corley and Crocker try to deal with this second line of attack. While it is reasonable to believe that the mental lexicon contains entries for verbs that specify the likelihood of each possible complement type, considerations of sparse data make it less feasible to suppose that every lexical choice for possible adjective-noun pairs is stored. Nonetheless, there seems to be a clear difference between the ease of understanding of cases such as (4) and (5): (4) The warehouse fires many of its employees every summer. (5) The corporation fires many of its employees every summer. (1994) suggested that this was due to the greater frequency of an adjective-noun pair and the relative rarity of this part-of-speech analysis for corporation fires. and Crocker try to show data do not force word-by-word bigrarn conditioning, and propose an alternative where only word to part-of-speech-category and part-of-speech-category to part-of-speech-category parameters are computed when assigning probabilities to ambiguous lexical items. Their model is inspired by standard part-of-speech taggers. This balancing between enriching the repertoire of constraints and keeping their number tractable and learnable should also occupy the field in the near future. Topics of the rest of the book include expanding the experimental paradigms used in sentence processing (to ERP work, as discussed in Cohn Brown and Pater Hagoort&apos;s chapter), expanding the cross-linguistic coverage of the field (in chapters by Barbara Hemforth, Lars Konieczny, and Christoph Scheepers and by Marica De Vincenzi), and, in an interesting final section, semantic processing (chapters by Lyn Frazier, by Linda Moxey and Anthony Sanford, and by Amit Almor). This book represents the state of the art in sentence processing, with interesting examples and opportunities for computational modeling. The themes that it presents are likely to occupy the field for some time. References Ferreira, Fernanda and Clifton, Charles Jr. 1986. The independence of syntactic of Memory and Language, 25: 348-368. Frazier, Lyn and Rayner, Keith. 1982. Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous 14: 178-210, Edward. 1991. computational theory human linguistic processing.</abstract>
<note confidence="0.4266865">doctoral thesis, Carnegie Mellon 650</note>
<author confidence="0.637659">Book Reviews</author>
<affiliation confidence="0.984054">University</affiliation>
<address confidence="0.847588">MacDonald, Maryellen C. 1994. Probabilistic</address>
<email confidence="0.246764">constraintsandsyntacticambiguity</email>
<affiliation confidence="0.854189">and Cognitive Processes,</affiliation>
<address confidence="0.9227535">9: 157-201. Allen. 1990. Theories of</address>
<affiliation confidence="0.9984">University Press,</affiliation>
<address confidence="0.996711">Cambridge, MA.</address>
<abstract confidence="0.8250436">Trueswell, John C., Michael K. Tanenhaus, and Susan M. Garnsey. 1994. Semantic influences on parsing: Use of thematic role information in syntactic ambiguity of Memory and Language, 33: 285-318. Weinberg, Amy. 2000. A minimalist parser. In Samuel David Epstein and Norbert editors, Minimalism, The MIT Press, Cambridge, MA. Weinberg an Associate Professor in the Department of Linguistics and the Institute for Computer Studies at the University She has worked on computational and experimental models of sentence processing, as well as models for foreign-language tutoring and machine translation. Weinberg&apos;s address is: LEVIIACS, University of Maryland, College Park, MD 20742; e-mail: weinberg@untiacs.umd.edu.</abstract>
<intro confidence="0.696307">651</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Fernanda Ferreira</author>
<author>Charles Jr Clifton</author>
</authors>
<title>The independence of syntactic processing.</title>
<date>1986</date>
<journal>journal of Memory and Language,</journal>
<volume>25</volume>
<pages>348--368</pages>
<contexts>
<context position="6399" citStr="Ferreira and Clifton (1986)" startWordPosition="974" endWordPosition="977">s the wrong main-clause analysis, on the basis of structural factors, but that this analysis is rapidly revised. Interactive theorists claim, however, that this result follows simply from allowing factors like &amp;quot;agentivity&amp;quot; and &amp;quot;presence of by&amp;quot; to interact in the choice of the initial analysis. The chapter by Tanenhaus, Spivey-Knowlton, and Hanna presents a constraint-satisfaction implementation that allows us to test predictions of the interactive theory. They claim that the model can explain a range of hitherto contradictory findings. For example, they claim that experiments, such as that of Ferreira and Clifton (1986), using stimuli like (3) but without the by phrase, that were interpreted as demonstrating a stage where the parser abstracted away from issues of agentivity, could actually be predicted by an interactive model. This is because Ferreira and Clifton&apos;s stimuli did not include by phrases that could further bias the model to the relativeclause reading of the ambiguous verb, because the language as a whole is biased to treat main-verb/past-particle ambiguities as main verbs, and because the stimuli used verbs that were equibiased between a relative-clause and main-clause reading. These factors cons</context>
</contexts>
<marker>Ferreira, Clifton, 1986</marker>
<rawString>Ferreira, Fernanda and Clifton, Charles Jr. 1986. The independence of syntactic processing. journal of Memory and Language, 25: 348-368.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lyn Frazier</author>
<author>Keith Rayner</author>
</authors>
<title>Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences.</title>
<date>1982</date>
<journal>Cognitive Psycho/op,</journal>
<volume>14</volume>
<pages>178--210</pages>
<contexts>
<context position="2145" citStr="Frazier and Rayner (1982)" startWordPosition="324" endWordPosition="327">ssible continuations of the first part of each sentence, but the choice of the appropriate continuation depends on how the parser initially structures the preceding material. In (1), the parser might choose to make the postverbal noun phrase either the direct object of the matrix verb, compatible with the first continuation, or the subject of an upcoming complement sentence, compatible with the second. In (2), the ambiguity centers upon whether heard is taken as an active main verb or as a passive participle inside a relative clause (the girl who was heard). Early experiments such as those of Frazier and Rayner (1982) suggested that speakers had a clear preference for the first continuation in each case, as verified by an increase in reaction time when the disambiguating word, underlined in examples above, forced the second continuation. In a case such as (1), the initial preference seems easy to reanalyze, while in (2), the correct analysis seems unrecoverable and is commonly referred to as a garden path. These facts were initially explained by a theory that assumed a serial parser. The choice function guiding the initial analysis was independently justified either by considerations drawn from linguistics</context>
</contexts>
<marker>Frazier, Rayner, 1982</marker>
<rawString>Frazier, Lyn and Rayner, Keith. 1982. Making and correcting errors during sentence comprehension: Eye movements in the analysis of structurally ambiguous sentences. Cognitive Psycho/op, 14: 178-210,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Gibson</author>
</authors>
<title>A computational theory of human linguistic processing. Unpublished doctoral thesis,</title>
<date>1991</date>
<institution>Carnegie Mellon Book Reviews University</institution>
<contexts>
<context position="2758" citStr="Gibson 1991" startWordPosition="421" endWordPosition="422">uggested that speakers had a clear preference for the first continuation in each case, as verified by an increase in reaction time when the disambiguating word, underlined in examples above, forced the second continuation. In a case such as (1), the initial preference seems easy to reanalyze, while in (2), the correct analysis seems unrecoverable and is commonly referred to as a garden path. These facts were initially explained by a theory that assumed a serial parser. The choice function guiding the initial analysis was independently justified either by considerations drawn from linguistics (Gibson 1991, Weinberg 2000) or theories of memory (Frazier and Rayner 1982). Importantly, these theories assumed that listeners delayed consideration of semantic, pragmatic, or frequency-based factors until after an initial analysis was constructed. The present book highlights recent extensions and challenges to these theories. 648 Book Reviews Chapters by Richard Lewis (based on SOAR [Newell 19901), by Paola Merlo and Suzanne Stevenson (based on a symbolic connectionist architecture), and by James Henderson (based on an extension of recurrent networks using Temporal Serial Variable Binding) try to deriv</context>
</contexts>
<marker>Gibson, 1991</marker>
<rawString>Gibson, Edward. 1991. A computational theory of human linguistic processing. Unpublished doctoral thesis, Carnegie Mellon Book Reviews University</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maryellen C MacDonald</author>
</authors>
<title>Probabilistic constraints and syntactic ambiguity resolution.</title>
<date>1994</date>
<journal>Language and Cognitive Processes,</journal>
<volume>9</volume>
<pages>157--201</pages>
<contexts>
<context position="8963" citStr="MacDonald (1994)" startWordPosition="1389" endWordPosition="1390">rce of constraint. Corley and Crocker try to deal with this second line of attack. While it is reasonable to believe that the mental lexicon contains entries for verbs that specify the likelihood of each possible complement type, considerations of sparse data make it less feasible to suppose that every lexical choice for possible adjective-noun pairs is stored. Nonetheless, there seems to be a clear difference between the ease of understanding of cases such as (4) and (5): (4) The warehouse fires many of its employees every summer. (5) The corporation fires many of its employees every summer. MacDonald (1994) suggested that this was due to the greater frequency of warehouse fires as an adjective-noun pair and the relative rarity of this part-of-speech analysis for corporation fires. Corley and Crocker try to show that these data do not force word-by-word bigrarn conditioning, and propose an alternative where only word to part-of-speech-category (unigram) and part-of-speech-category to part-of-speech-category (bigram) parameters are computed when assigning probabilities to ambiguous lexical items. Their model is inspired by standard part-of-speech taggers. This balancing between enriching the reper</context>
</contexts>
<marker>MacDonald, 1994</marker>
<rawString>MacDonald, Maryellen C. 1994. Probabilistic constraints and syntactic ambiguity resolution. Language and Cognitive Processes, 9: 157-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allen Newell</author>
</authors>
<title>Unified Theories of Cognition.</title>
<date>1990</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="3147" citStr="Newell 1990" startWordPosition="475" endWordPosition="476">path. These facts were initially explained by a theory that assumed a serial parser. The choice function guiding the initial analysis was independently justified either by considerations drawn from linguistics (Gibson 1991, Weinberg 2000) or theories of memory (Frazier and Rayner 1982). Importantly, these theories assumed that listeners delayed consideration of semantic, pragmatic, or frequency-based factors until after an initial analysis was constructed. The present book highlights recent extensions and challenges to these theories. 648 Book Reviews Chapters by Richard Lewis (based on SOAR [Newell 19901), by Paola Merlo and Suzanne Stevenson (based on a symbolic connectionist architecture), and by James Henderson (based on an extension of recurrent networks using Temporal Serial Variable Binding) try to derive initial parsing preferences and to distinguish possible from impossible reanalyses by means of architectural constraints defined in their underlying (implemented) models. The common idea here is that the distinction between an easy reanalysis and a garden path should fall out as a side effect of constraints that need to be imposed on the system in order to allow it to perform analysis</context>
</contexts>
<marker>Newell, 1990</marker>
<rawString>Newell, Allen. 1990. Unified Theories of Cognition. Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John C Trueswell</author>
<author>Michael K Tanenhaus</author>
<author>Susan M Garnsey</author>
</authors>
<title>Semantic influences on parsing: Use of thematic role information in syntactic ambiguity resolution.</title>
<date>1994</date>
<journal>Journal of Memory and Language,</journal>
<volume>33</volume>
<pages>285--318</pages>
<marker>Trueswell, Tanenhaus, Garnsey, 1994</marker>
<rawString>Trueswell, John C., Michael K. Tanenhaus, and Susan M. Garnsey. 1994. Semantic influences on parsing: Use of thematic role information in syntactic ambiguity resolution. Journal of Memory and Language, 33: 285-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Weinberg</author>
</authors>
<title>A minimalist parser.</title>
<date>2000</date>
<editor>In Samuel David Epstein and Norbert Hornstein, editors, Working Minimalism,</editor>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="2774" citStr="Weinberg 2000" startWordPosition="423" endWordPosition="424"> speakers had a clear preference for the first continuation in each case, as verified by an increase in reaction time when the disambiguating word, underlined in examples above, forced the second continuation. In a case such as (1), the initial preference seems easy to reanalyze, while in (2), the correct analysis seems unrecoverable and is commonly referred to as a garden path. These facts were initially explained by a theory that assumed a serial parser. The choice function guiding the initial analysis was independently justified either by considerations drawn from linguistics (Gibson 1991, Weinberg 2000) or theories of memory (Frazier and Rayner 1982). Importantly, these theories assumed that listeners delayed consideration of semantic, pragmatic, or frequency-based factors until after an initial analysis was constructed. The present book highlights recent extensions and challenges to these theories. 648 Book Reviews Chapters by Richard Lewis (based on SOAR [Newell 19901), by Paola Merlo and Suzanne Stevenson (based on a symbolic connectionist architecture), and by James Henderson (based on an extension of recurrent networks using Temporal Serial Variable Binding) try to derive initial parsin</context>
</contexts>
<marker>Weinberg, 2000</marker>
<rawString>Weinberg, Amy. 2000. A minimalist parser. In Samuel David Epstein and Norbert Hornstein, editors, Working Minimalism, The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Amy</author>
</authors>
<title>Weinberg is an Associate Professor in the Department of Linguistics and the Institute for Advanced Computer Studies at the University of Maryland. She has worked on computational and experimental models of sentence processing, as well as models for foreign-language tutoring and machine translation. Weinberg&apos;s address is: LEVIIACS,</title>
<institution>University of Maryland, College Park, MD</institution>
<note>20742; e-mail: weinberg@untiacs.umd.edu.</note>
<marker>Amy, </marker>
<rawString>Amy Weinberg is an Associate Professor in the Department of Linguistics and the Institute for Advanced Computer Studies at the University of Maryland. She has worked on computational and experimental models of sentence processing, as well as models for foreign-language tutoring and machine translation. Weinberg&apos;s address is: LEVIIACS, University of Maryland, College Park, MD 20742; e-mail: weinberg@untiacs.umd.edu.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>