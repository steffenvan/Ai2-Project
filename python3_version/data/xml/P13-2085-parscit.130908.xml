<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001621">
<title confidence="0.960897">
Character-to-Character Sentiment Analysis in Shakespeare’s Plays
</title>
<author confidence="0.998384">
Eric T. Nalisnick Henry S. Baird
</author>
<affiliation confidence="0.839054">
Dept. of Computer Science and Engineering
Lehigh University
Bethlehem, PA 18015, USA
</affiliation>
<email confidence="0.999449">
{etn212,hsb2}@lehigh.edu
</email>
<sectionHeader confidence="0.997397" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998979375">
We present an automatic method for ana-
lyzing sentiment dynamics between char-
acters in plays. This literary format’s
structured dialogue allows us to make as-
sumptions about who is participating in a
conversation. Once we have an idea of
who a character is speaking to, the senti-
ment in his or her speech can be attributed
accordingly, allowing us to generate lists
of a character’s enemies and allies as well
as pinpoint scenes critical to a character’s
emotional development. Results of ex-
periments on Shakespeare’s plays are pre-
sented along with discussion of how this
work can be extended to unstructured texts
(i.e. novels).
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999673745454546">
Insightful analysis of literary fiction often chal-
lenges trained human readers let alone machines.
In fact, some humanists believe literary analysis
is so closely tied to the human condition that it is
impossible for computers to perform. In his book
Reading Machines: Toward an Algorithmic Criti-
cism, Stephen Ramsay (2011) states:
Tools that can adjudicate the hermeneu-
tical parameters of human reading ex-
periences...stretch considerably beyond
the most ambitious fantasies of artificial
intelligence.
Antonio Roque (2012) has challenged Ramsay’s
claim, and certainly there has been successful
work done in the computational analysis and mod-
eling of narratives, as we will review in the next
section. However, we believe that most previous
work (except possibly (Elsner, 2012)) has failed to
directly address the root cause of Ramsay’s skep-
ticism: can computers extract the emotions en-
coded in a narrative? For example, can the love
that Shakespeare’s Juliet feels for Romeo be com-
putationally tracked? Empathizing with characters
along their journeys to emotional highs and lows
is often what makes a narrative compelling for a
reader, and therefore we believe mapping these
journeys is the first step in capturing the human
reading experience.
Unfortunately but unsurprisingly, computa-
tional modeling of the emotional relationships de-
scribed in natural language text remains a daunting
technical challenge. The reason this task is so dif-
ficult is that emotions are indistinct and often sub-
tly conveyed, especially in text with literary merit.
Humans typically achieve no greater than 80% ac-
curacy in sentiment classification experiments in-
volving product reviews (Pang et al., 2002) (Ga-
mon, 2004). Similar experiments on fiction texts
would presumably yield even higher error rates.
In order to attack this open problem and make
further progress towards refuting Ramsay’s claim,
we turn to shallow statistical approaches. Sen-
timent analysis (Pang and Lee, 2008) has been
successfully applied to mine social media data
for emotional responses to events, public figures,
and consumer products just by using emotion
lexicons–lists that map words to polarity values
(+1 for positive sentiment, -1 for negative) or va-
lence values that try to capture degrees of polarity.
In the following paper, we describe our attempts
to use modern sentiment lexicons and dialogue
structure to algorithmically track and model–with
no domain-specific customization–the emotion
dynamics between characters in Shakespeare’s
plays.1
</bodyText>
<subsectionHeader confidence="0.675292">
2 Sentiment Analysis and Related Work
</subsectionHeader>
<bodyText confidence="0.999632333333333">
Sentiment analysis (SA) is now widely used com-
mercially to infer user opinions from product re-
views and social-media messages (Pang and Lee,
</bodyText>
<footnote confidence="0.998769">
1XML versions provided by Jon Bosak:
http://www.ibiblio.org/xml/examples/shakespeare/
</footnote>
<page confidence="0.96466">
479
</page>
<bodyText confidence="0.975953694915254">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 479–483,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
2008). Traditional machine learning techniques on
n-grams, parts of speech, and other bag of words
features can be used when the data is labeled (e.g.
IMDB’s user reviews are labeled with one to ten
stars, which are assumed to correlate with the
text’s polarity) (Pang et al., 2002). But text anno-
tated with its true sentiments is hard to come by so
often labels must be obtained via crowdsourcing.
Knowledge-based methods (which also typi-
cally rely on crowdsourcing) provide an alter-
native to using labeled data (Andreevskaia and
Bergler, 2007). These methods are driven by
sentiment lexicons, fixed lists associating words
with “valences” (signed integers representing pos-
itive and negative feelings) (Kim and Hovy, 2004).
Some lexicons allow for analysis of specific emo-
tions by associating words with degrees of fear,
joy, surprise, anger, anticipation, etc. (Strappar-
ava and Valitutti, 2004) (Mohammad and Turney,
2008). Unsurprisingly, methods which, like these,
lack deep understanding often work more reliably
as the length of the input text increases.
Turning our attention now to automatic seman-
tic analysis of fiction, it seems that narrative mod-
eling and summarization has been the most inten-
sively studied application. Chambers and Jurafsky
(2009) described a system that can learn (without
supervision) the sequence of events described in a
narrative, and Elson and McKeown (2009) created
a platform that can symbolically represent and rea-
son over narratives.
Narrative structure has also been studied by rep-
resenting character interactions as networks. Mut-
ton (2004) adapted methods for extracting social
networks from Internet Relay Chat (IRC) to mine
Shakespeare’s plays for their networks. Extending
this line of work to novels, Elson and McKeown
(2010) developed a reliable method for speech
attribution in unstructured texts, and then used
this method to successfully extract social networks
from Victorian novels (Elson et al., 2010)(Agar-
wal et al., 2012).
While structure is undeniably important, we be-
lieve analyzing a narrative’s emotions is essen-
tial to capturing the ‘reading experience,’ which
is a view others have held. Alm and Sproat
(2005) analyzed Brothers Grimm fairy tales for
their ‘emotional trajectories,’ finding emotion typ-
ically increases as a story progresses. Mohammad
(2011) scaled-up their work by using a crowd-
sourced emotion lexicon to track emotion dynam-
ics over the course of many novels and plays, in-
cluding Shakespeare’s. In the most recent work
we are aware of, Elsner (2012) analyzed emotional
trajectories at the character level, showing how
Miss Elizabeth Bennet’s emotions change over the
course of Pride and Prejudice.
</bodyText>
<sectionHeader confidence="0.90616" genericHeader="method">
3 Character-to-Character Sentiment
Analysis
</sectionHeader>
<figure confidence="0.986378785714286">
Character Hamlet&apos;s Sentiment
Valence Sum
Guildenstern 31
Polonius 25
Gertrude 24
Horatio 12
Ghost 8
Marcellus 7
Osric 7
Bernardo 2
Laertes -1
Ophelia -5
Rosencrantz -12
Claudius -27
</figure>
<figureCaption confidence="0.999878">
Figure 1: The characters in Hamlet are ranked
</figureCaption>
<bodyText confidence="0.962891888888889">
by Hamet’s sentiment towards them. Expectedly,
Claudius draws the most negative emotion.
We attempt to further Elsner’s line of work by
leveraging text structure (as Mutton and Elson did)
and knowlege-based SA to track the emotional tra-
jectories of interpersonal relationships rather than
of a whole text or an isolated character. To ex-
tract these relationships, we mined for character-
to-character sentiment by summing the valence
values (provided by the AFINN sentiment lexicon
(Nielsen, 2011)) over each instance of continuous
speech and then assumed that sentiment was di-
rected towards the character that spoke immedi-
ately before the current speaker. This assumption
doesn’t always hold; it is not uncommon to find a
scene in which two characters are expressing feel-
ings about someone offstage. Yet our initial results
on Shakespeare’s plays show that the instances of
face-to-face dialogue produce a strong enough sig-
nal to generate sentiment rankings that match our
expectations.
For example, Hamlet’s sentiment rankings upon
the conclusion of his play are shown in Figure 1.
Not surprisingly, Claudius draws the most nega-
tive sentiment from Hamlet, receiving a score of
-27. On the other hand, Gertrude is very well liked
by Hamlet (+24), which is unexpected (at least to
</bodyText>
<page confidence="0.990246">
480
</page>
<bodyText confidence="0.8525402">
us) since Hamlet suspects that his mother was in-
volved in murdering King Hamlet.
Figure 2: The above chart tracks how Gertrude’s
and Hamlet’s sentiment towards one another
changes over the course of the play. Hamlet’s sen-
timent for Gertrude is denoted by the black line,
and Gertrude’s for Hamlet is marked by the op-
posite boundary of the dark/light gray area. The
drastic change in Act III Scene IV: The Queen’s
Closet is consistent with the scene’s plot events.
</bodyText>
<subsectionHeader confidence="0.996533">
3.1 Peering into the Queen’s Closet
</subsectionHeader>
<bodyText confidence="0.999829818181818">
To gain more insight into this mother-son rela-
tionship, we examined how their feelings towards
one another change over the course of the play.
Figure 2 shows the results of dynamic character-
to-character sentiment analysis on Gertrude and
Hamlet. The running total of Hamlet’s sentiment
valence toward Gertrude is tracked by the black
line, and Gertrude’s feelings toward her son are
tracked by the opposite boundary of the light/dark
gray area. The line graph shows a dramatic swing
in sentiment around line 2,250, which corresponds
to Act iii, Scene iv.
In this scene, entitled The Queen’s Closet, Ham-
let confronts his mother about her involvement in
King Hamlet’s death. Gertrude is shocked at the
accusation, revealing she never suspected Ham-
let’s father was murdered. King Hamlet’s ghost
even points this out to his son: “But, look, amaze-
ment on thy mother sits” (3.4.109). Hamlet then
comes to the realization that his mother had no
involvement in the murder and probably married
Claudius more so to preserve stability in the state.
As a result, Hamlet’s affection towards his mother
grows, as exhibited in the sentiment jump from
-1 to 22. But this scene has the opposite affect
on Gertrude: she sees her son murder an innocent
man (Polonius) and talk to an invisible presence
(she cannot see King Hamlet’s ghost). Gertrude
is coming to the understanding that Hamlet is
not just depressed but possibly mad and on a re-
venge mission. Because of Gertrude’s realization,
it is only natural that her sentiment undergoes a
sharply negative change (1 to -19).
</bodyText>
<subsectionHeader confidence="0.962219">
3.2 Analyzing Shakespeare’s Most Famous
Couples
</subsectionHeader>
<bodyText confidence="0.9689689">
Figure 3: Othello’s sentiment for Desdemona is
denoted by the black line, and Desdemona’s for
Othello is marked by the opposite boundary of the
dark/light gray area. As expected, the line graph
shows Othello has very strong positive emotion
towards his new wife at the beginning of the play,
but this positivity quickly degrades as Othello falls
deeper and deeper into Iago’s deceit.
After running this automatic analysis on all of
Shakespeare’s plays, not all the results examined
were as enlightening as the Hamlet vs. Gertrude
example. Instead, the majority supported our al-
ready held interpretations. We will now present
what the technique revealed about three of Shake-
speare’s best known relationships. Figure 3 shows
Othello vs. Desdemona sentiment dynamics. We
clearly see Othello’s love for his new bride cli-
maxes in the first third of the play and then rapidly
degrades due to Iago’s deceit while Desdemona’s
feelings for Othello stay positive until the very
end of the play when it is clear Othello’s love for
her has become poisoned. For an example of a
contrasting relationship, Figure 4 shows Romeo
vs. Juliet. As expected, the two exhibit rapidly
increasing positive sentiment for each other that
only tapers when the play takes a tragic course in
the latter half. Lastly, Figure 5 shows Petruchio
vs. Katharina (from The Taming of the Shrew).
The phases of Petruchio’s courtship can be seen:
first he is neutral to her, then ‘tames’ her with a
</bodyText>
<page confidence="0.997417">
481
</page>
<bodyText confidence="0.975037319148936">
period of negative sentiment, and finally she em-
braces him, as shown by the increasingly positive
sentiment exhibited in both directions.
Figure 4: Juliet’s sentiment for Romeo is de-
noted by the black line, and Romeo’s for Juliet
is marked by the opposite boundary of the gray
area. Aligning with our expectations, both charac-
ters exhibit strong positive sentiment towards the
other throughout the play.
Unfortunately, we do not have room in this pa-
per to discuss further examples, but a visualization
of sentiment dynamics between any pair of char-
acters in any of Shakespeare’s plays can be seen at
www.lehigh.edu/∼etn212/ShakespeareExplorer.html.
Figure 5: Petruchio’s sentiment for Katharina is
denoted by the black line, and Katharina’s for
Petruchio is marked by the opposite boundary of
the dark/light gray area. The period from line 1200
to line 1700, during which Petruchio exhibits neg-
ative sentiment, marks where he is ‘taming’ the
‘shrew.’
ten since the Elizabethan Period. The sentiment
lexicon we used, AFINN, is designed for modern
English; thus, it should only provide better anal-
ysis on works written after Shakespeare’s. Fur-
thermore, character-to-character analysis should
be able to be applied to novels (and other un-
structured fiction) if Elson and McKeown’s (2010)
speaker attribution technique is first run on the
work.
Not only can these techniques be extended to
novels but also be made more precise. For in-
stance, the assumption that the current speaker’s
sentiment is directed toward the previous speaker
is rather naive. A speech could be analyzed for
context clues that signal that the character speak-
ing is not talking about someone present but about
someone out of the scene. The sentiment could
then be redirected to the not-present character.
Furthermore, detecting subtle rhetorical features
such as irony and deceit would markedly improve
the accuracy of the analysis on some plays. For ex-
ample, our character-to-character analysis fails to
detect that Iago hates Othello because Iago gives
his commander constant lip service in order to ma-
nipulate him–only revealing his true feelings at the
play’s conclusion.
</bodyText>
<sectionHeader confidence="0.997007" genericHeader="method">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999984647058823">
As demonstrated, shallow, un-customized senti-
ment analysis can be used in conjunction with
text structure to analyze interpersonal relation-
ships described within a play and output an inter-
pretation that matches reader expectations. This
character-to-character sentiment analysis can be
done statically as well as dynamically to possi-
bly pinpoint influential moments in the narrative
(which is how we noticed the importance of Ham-
let’s Act 3, Scene 4 to the Hamlet-Gertrude rela-
tionship). Yet, we believe the most noteworthy as-
pect of this work lies not in the details of our tech-
nique but rather in the demonstration that detailed
emotion dynamics can be extracted with simplis-
tic approaches–which in turn gives promise to the
future work of robust analysis of interpersonal re-
lationships in short stories and novels.
</bodyText>
<sectionHeader confidence="0.999895" genericHeader="conclusions">
4 Future Work
</sectionHeader>
<bodyText confidence="0.988059">
While this paper presents experiments on just
Shakespeare’s plays, note that the described tech-
nique can be extended to any work of fiction writ-
</bodyText>
<sectionHeader confidence="0.999003" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.978211666666667">
A. Agarwal, A. Corvalan, J. Jensen, and O. Rambow.
2012. Social network analysis of alice in wonder-
land. NAACL-HLT 2012, page 88.
</reference>
<page confidence="0.991973">
482
</page>
<reference confidence="0.995674000000001">
Cecilia Ovesdotter Alm and Richard Sproat. 2005.
Emotional sequencing and development in fairy
tales. In Affective Computing and Intelligent Inter-
action, pages 668–674. Springer.
Alina Andreevskaia and Sabine Bergler. 2007. Clac
and clac-nb: knowledge-based and corpus-based ap-
proaches to sentiment tagging. In Proceedings of
the 4th International Workshop on Semantic Evalu-
ations, SemEval ’07, pages 117–120, Stroudsburg,
PA, USA. Association for Computational Linguis-
tics.
Nathanael Chambers and Dan Jurafsky. 2009. Un-
supervised learning of narrative schemas and their
participants. In Proceedings of the Joint Confer-
ence of the 47th Annual Meeting of the ACL and the
4th International Joint Conference on Natural Lan-
guage Processing of the AFNLP: Volume 2-Volume
2, pages 602–610. Association for Computational
Linguistics.
Micha Elsner. 2012. Character-based kernels for nov-
elistic plot structure. In Proceedings of the 13th
Conference of the European Chapter of the Asso-
ciation for Computational Linguistics, EACL ’12,
pages 634–644, Stroudsburg, PA, USA. Association
for Computational Linguistics.
David K Elson and Kathleen R McKeown. 2009. Ex-
tending and evaluating a platform for story under-
standing. In Proceedings of the AAAI 2009 Spring
Symposium on Intelligent Narrative Technologies II.
D.K. Elson and K.R. McKeown. 2010. Automatic at-
tribution of quoted speech in literary narrative. In
Proceedings of AAAI.
D.K. Elson, N. Dames, and K.R. McKeown. 2010. Ex-
tracting social networks from literary fiction. In Pro-
ceedings of the 48th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 138–147.
Association for Computational Linguistics.
Michael Gamon. 2004. Sentiment classification on
customer feedback data: noisy data, large feature
vectors, and the role of linguistic analysis. In Pro-
ceedings of the 20th international conference on
Computational Linguistics, COLING ’04, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Soo-Min Kim and Eduard Hovy. 2004. Determin-
ing the sentiment of opinions. In Proceedings of
the 20th international conference on Computational
Linguistics, COLING ’04, Stroudsburg, PA, USA.
Association for Computational Linguistics.
Saif M Mohammad and Peter D Turney. 2008. Crowd-
sourcing the creation of a word–emotion association
lexicon.
S. Mohammad. 2011. From once upon a time to
happily ever after: Tracking emotions in novels
and fairy tales. In Proceedings of the 5th ACL-
HLT Workshop on Language Technology for Cul-
tural Heritage, Social Sciences, and Humanities,
pages 105–114. Association for Computational Lin-
guistics.
P. Mutton. 2004. Inferring and visualizing social net-
works on internet relay chat. In Information Visuali-
sation, 2004. IV 2004. Proceedings. Eighth Interna-
tional Conference on, pages 35–43. IEEE.
F. ˚A. Nielsen. 2011. Afinn, March.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 conference on Empirical methods in natu-
ral language processing - Volume 10, EMNLP ’02,
pages 79–86, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Stephen Ramsay. 2011. Reading Machines: Toward
an Algorithmic Criticism. University of Illinois
Press.
Antonio Roque. 2012. Towards a computational ap-
proach to literary text analysis. NAACL-HLT 2012,
page 97.
C. Strapparava and A. Valitutti. 2004. Wordnet-affect:
an affective extension of wordnet. In Proceedings of
LREC, volume 4, pages 1083–1086.
</reference>
<page confidence="0.99933">
483
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.856418">
<title confidence="0.999436">Character-to-Character Sentiment Analysis in Shakespeare’s Plays</title>
<author confidence="0.999277">Eric T Nalisnick Henry S</author>
<affiliation confidence="0.9438355">Dept. of Computer Science and Lehigh</affiliation>
<address confidence="0.990654">Bethlehem, PA 18015,</address>
<abstract confidence="0.998264882352941">We present an automatic method for analyzing sentiment dynamics between characters in plays. This literary format’s structured dialogue allows us to make assumptions about who is participating in a conversation. Once we have an idea of who a character is speaking to, the sentiment in his or her speech can be attributed accordingly, allowing us to generate lists of a character’s enemies and allies as well as pinpoint scenes critical to a character’s emotional development. Results of experiments on Shakespeare’s plays are presented along with discussion of how this work can be extended to unstructured texts (i.e. novels).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Agarwal</author>
<author>A Corvalan</author>
<author>J Jensen</author>
<author>O Rambow</author>
</authors>
<title>Social network analysis of alice in wonderland.</title>
<date>2012</date>
<booktitle>NAACL-HLT 2012,</booktitle>
<pages>88</pages>
<contexts>
<context position="5804" citStr="Agarwal et al., 2012" startWordPosition="872" endWordPosition="876">narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by representing character interactions as networks. Mutton (2004) adapted methods for extracting social networks from Internet Relay Chat (IRC) to mine Shakespeare’s plays for their networks. Extending this line of work to novels, Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used this method to successfully extract social networks from Victorian novels (Elson et al., 2010)(Agarwal et al., 2012). While structure is undeniably important, we believe analyzing a narrative’s emotions is essential to capturing the ‘reading experience,’ which is a view others have held. Alm and Sproat (2005) analyzed Brothers Grimm fairy tales for their ‘emotional trajectories,’ finding emotion typically increases as a story progresses. Mohammad (2011) scaled-up their work by using a crowdsourced emotion lexicon to track emotion dynamics over the course of many novels and plays, including Shakespeare’s. In the most recent work we are aware of, Elsner (2012) analyzed emotional trajectories at the character </context>
</contexts>
<marker>Agarwal, Corvalan, Jensen, Rambow, 2012</marker>
<rawString>A. Agarwal, A. Corvalan, J. Jensen, and O. Rambow. 2012. Social network analysis of alice in wonderland. NAACL-HLT 2012, page 88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cecilia Ovesdotter Alm</author>
<author>Richard Sproat</author>
</authors>
<title>Emotional sequencing and development in fairy tales.</title>
<date>2005</date>
<booktitle>In Affective Computing and Intelligent Interaction,</booktitle>
<pages>668--674</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="5998" citStr="Alm and Sproat (2005)" startWordPosition="904" endWordPosition="907">tions as networks. Mutton (2004) adapted methods for extracting social networks from Internet Relay Chat (IRC) to mine Shakespeare’s plays for their networks. Extending this line of work to novels, Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used this method to successfully extract social networks from Victorian novels (Elson et al., 2010)(Agarwal et al., 2012). While structure is undeniably important, we believe analyzing a narrative’s emotions is essential to capturing the ‘reading experience,’ which is a view others have held. Alm and Sproat (2005) analyzed Brothers Grimm fairy tales for their ‘emotional trajectories,’ finding emotion typically increases as a story progresses. Mohammad (2011) scaled-up their work by using a crowdsourced emotion lexicon to track emotion dynamics over the course of many novels and plays, including Shakespeare’s. In the most recent work we are aware of, Elsner (2012) analyzed emotional trajectories at the character level, showing how Miss Elizabeth Bennet’s emotions change over the course of Pride and Prejudice. 3 Character-to-Character Sentiment Analysis Character Hamlet&apos;s Sentiment Valence Sum Guildenste</context>
</contexts>
<marker>Alm, Sproat, 2005</marker>
<rawString>Cecilia Ovesdotter Alm and Richard Sproat. 2005. Emotional sequencing and development in fairy tales. In Affective Computing and Intelligent Interaction, pages 668–674. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alina Andreevskaia</author>
<author>Sabine Bergler</author>
</authors>
<title>Clac and clac-nb: knowledge-based and corpus-based approaches to sentiment tagging.</title>
<date>2007</date>
<booktitle>In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07,</booktitle>
<pages>117--120</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4373" citStr="Andreevskaia and Bergler, 2007" startWordPosition="658" endWordPosition="661">3, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2008). Traditional machine learning techniques on n-grams, parts of speech, and other bag of words features can be used when the data is labeled (e.g. IMDB’s user reviews are labeled with one to ten stars, which are assumed to correlate with the text’s polarity) (Pang et al., 2002). But text annotated with its true sentiments is hard to come by so often labels must be obtained via crowdsourcing. Knowledge-based methods (which also typically rely on crowdsourcing) provide an alternative to using labeled data (Andreevskaia and Bergler, 2007). These methods are driven by sentiment lexicons, fixed lists associating words with “valences” (signed integers representing positive and negative feelings) (Kim and Hovy, 2004). Some lexicons allow for analysis of specific emotions by associating words with degrees of fear, joy, surprise, anger, anticipation, etc. (Strapparava and Valitutti, 2004) (Mohammad and Turney, 2008). Unsurprisingly, methods which, like these, lack deep understanding often work more reliably as the length of the input text increases. Turning our attention now to automatic semantic analysis of fiction, it seems that n</context>
</contexts>
<marker>Andreevskaia, Bergler, 2007</marker>
<rawString>Alina Andreevskaia and Sabine Bergler. 2007. Clac and clac-nb: knowledge-based and corpus-based approaches to sentiment tagging. In Proceedings of the 4th International Workshop on Semantic Evaluations, SemEval ’07, pages 117–120, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised learning of narrative schemas and their participants.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume</booktitle>
<volume>2</volume>
<pages>602--610</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5088" citStr="Chambers and Jurafsky (2009)" startWordPosition="764" endWordPosition="767">alences” (signed integers representing positive and negative feelings) (Kim and Hovy, 2004). Some lexicons allow for analysis of specific emotions by associating words with degrees of fear, joy, surprise, anger, anticipation, etc. (Strapparava and Valitutti, 2004) (Mohammad and Turney, 2008). Unsurprisingly, methods which, like these, lack deep understanding often work more reliably as the length of the input text increases. Turning our attention now to automatic semantic analysis of fiction, it seems that narrative modeling and summarization has been the most intensively studied application. Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by representing character interactions as networks. Mutton (2004) adapted methods for extracting social networks from Internet Relay Chat (IRC) to mine Shakespeare’s plays for their networks. Extending this line of work to novels, Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used </context>
</contexts>
<marker>Chambers, Jurafsky, 2009</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2009. Unsupervised learning of narrative schemas and their participants. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP: Volume 2-Volume 2, pages 602–610. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
</authors>
<title>Character-based kernels for novelistic plot structure.</title>
<date>2012</date>
<booktitle>In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12,</booktitle>
<pages>634--644</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1637" citStr="Elsner, 2012" startWordPosition="246" endWordPosition="247">ied to the human condition that it is impossible for computers to perform. In his book Reading Machines: Toward an Algorithmic Criticism, Stephen Ramsay (2011) states: Tools that can adjudicate the hermeneutical parameters of human reading experiences...stretch considerably beyond the most ambitious fantasies of artificial intelligence. Antonio Roque (2012) has challenged Ramsay’s claim, and certainly there has been successful work done in the computational analysis and modeling of narratives, as we will review in the next section. However, we believe that most previous work (except possibly (Elsner, 2012)) has failed to directly address the root cause of Ramsay’s skepticism: can computers extract the emotions encoded in a narrative? For example, can the love that Shakespeare’s Juliet feels for Romeo be computationally tracked? Empathizing with characters along their journeys to emotional highs and lows is often what makes a narrative compelling for a reader, and therefore we believe mapping these journeys is the first step in capturing the human reading experience. Unfortunately but unsurprisingly, computational modeling of the emotional relationships described in natural language text remains</context>
<context position="6354" citStr="Elsner (2012)" startWordPosition="963" endWordPosition="964">rom Victorian novels (Elson et al., 2010)(Agarwal et al., 2012). While structure is undeniably important, we believe analyzing a narrative’s emotions is essential to capturing the ‘reading experience,’ which is a view others have held. Alm and Sproat (2005) analyzed Brothers Grimm fairy tales for their ‘emotional trajectories,’ finding emotion typically increases as a story progresses. Mohammad (2011) scaled-up their work by using a crowdsourced emotion lexicon to track emotion dynamics over the course of many novels and plays, including Shakespeare’s. In the most recent work we are aware of, Elsner (2012) analyzed emotional trajectories at the character level, showing how Miss Elizabeth Bennet’s emotions change over the course of Pride and Prejudice. 3 Character-to-Character Sentiment Analysis Character Hamlet&apos;s Sentiment Valence Sum Guildenstern 31 Polonius 25 Gertrude 24 Horatio 12 Ghost 8 Marcellus 7 Osric 7 Bernardo 2 Laertes -1 Ophelia -5 Rosencrantz -12 Claudius -27 Figure 1: The characters in Hamlet are ranked by Hamet’s sentiment towards them. Expectedly, Claudius draws the most negative emotion. We attempt to further Elsner’s line of work by leveraging text structure (as Mutton and El</context>
</contexts>
<marker>Elsner, 2012</marker>
<rawString>Micha Elsner. 2012. Character-based kernels for novelistic plot structure. In Proceedings of the 13th Conference of the European Chapter of the Association for Computational Linguistics, EACL ’12, pages 634–644, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David K Elson</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Extending and evaluating a platform for story understanding.</title>
<date>2009</date>
<booktitle>In Proceedings of the AAAI 2009 Spring Symposium on Intelligent Narrative Technologies II.</booktitle>
<contexts>
<context position="5222" citStr="Elson and McKeown (2009)" startWordPosition="785" endWordPosition="788">emotions by associating words with degrees of fear, joy, surprise, anger, anticipation, etc. (Strapparava and Valitutti, 2004) (Mohammad and Turney, 2008). Unsurprisingly, methods which, like these, lack deep understanding often work more reliably as the length of the input text increases. Turning our attention now to automatic semantic analysis of fiction, it seems that narrative modeling and summarization has been the most intensively studied application. Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by representing character interactions as networks. Mutton (2004) adapted methods for extracting social networks from Internet Relay Chat (IRC) to mine Shakespeare’s plays for their networks. Extending this line of work to novels, Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used this method to successfully extract social networks from Victorian novels (Elson et al., 2010)(Agarwal et al., 2012). While structure </context>
</contexts>
<marker>Elson, McKeown, 2009</marker>
<rawString>David K Elson and Kathleen R McKeown. 2009. Extending and evaluating a platform for story understanding. In Proceedings of the AAAI 2009 Spring Symposium on Intelligent Narrative Technologies II.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D K Elson</author>
<author>K R McKeown</author>
</authors>
<title>Automatic attribution of quoted speech in literary narrative.</title>
<date>2010</date>
<booktitle>In Proceedings of AAAI.</booktitle>
<contexts>
<context position="5599" citStr="Elson and McKeown (2010)" startWordPosition="842" endWordPosition="845">rative modeling and summarization has been the most intensively studied application. Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by representing character interactions as networks. Mutton (2004) adapted methods for extracting social networks from Internet Relay Chat (IRC) to mine Shakespeare’s plays for their networks. Extending this line of work to novels, Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used this method to successfully extract social networks from Victorian novels (Elson et al., 2010)(Agarwal et al., 2012). While structure is undeniably important, we believe analyzing a narrative’s emotions is essential to capturing the ‘reading experience,’ which is a view others have held. Alm and Sproat (2005) analyzed Brothers Grimm fairy tales for their ‘emotional trajectories,’ finding emotion typically increases as a story progresses. Mohammad (2011) scaled-up their work by using a crowdsourced emotion </context>
</contexts>
<marker>Elson, McKeown, 2010</marker>
<rawString>D.K. Elson and K.R. McKeown. 2010. Automatic attribution of quoted speech in literary narrative. In Proceedings of AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D K Elson</author>
<author>N Dames</author>
<author>K R McKeown</author>
</authors>
<title>Extracting social networks from literary fiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>138--147</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="5782" citStr="Elson et al., 2010" startWordPosition="869" endWordPosition="872">ents described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by representing character interactions as networks. Mutton (2004) adapted methods for extracting social networks from Internet Relay Chat (IRC) to mine Shakespeare’s plays for their networks. Extending this line of work to novels, Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used this method to successfully extract social networks from Victorian novels (Elson et al., 2010)(Agarwal et al., 2012). While structure is undeniably important, we believe analyzing a narrative’s emotions is essential to capturing the ‘reading experience,’ which is a view others have held. Alm and Sproat (2005) analyzed Brothers Grimm fairy tales for their ‘emotional trajectories,’ finding emotion typically increases as a story progresses. Mohammad (2011) scaled-up their work by using a crowdsourced emotion lexicon to track emotion dynamics over the course of many novels and plays, including Shakespeare’s. In the most recent work we are aware of, Elsner (2012) analyzed emotional trajecto</context>
</contexts>
<marker>Elson, Dames, McKeown, 2010</marker>
<rawString>D.K. Elson, N. Dames, and K.R. McKeown. 2010. Extracting social networks from literary fiction. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 138–147. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Gamon</author>
</authors>
<title>Sentiment classification on customer feedback data: noisy data, large feature vectors, and the role of linguistic analysis.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2559" citStr="Gamon, 2004" startWordPosition="389" endWordPosition="391">en what makes a narrative compelling for a reader, and therefore we believe mapping these journeys is the first step in capturing the human reading experience. Unfortunately but unsurprisingly, computational modeling of the emotional relationships described in natural language text remains a daunting technical challenge. The reason this task is so difficult is that emotions are indistinct and often subtly conveyed, especially in text with literary merit. Humans typically achieve no greater than 80% accuracy in sentiment classification experiments involving product reviews (Pang et al., 2002) (Gamon, 2004). Similar experiments on fiction texts would presumably yield even higher error rates. In order to attack this open problem and make further progress towards refuting Ramsay’s claim, we turn to shallow statistical approaches. Sentiment analysis (Pang and Lee, 2008) has been successfully applied to mine social media data for emotional responses to events, public figures, and consumer products just by using emotion lexicons–lists that map words to polarity values (+1 for positive sentiment, -1 for negative) or valence values that try to capture degrees of polarity. In the following paper, we des</context>
</contexts>
<marker>Gamon, 2004</marker>
<rawString>Michael Gamon. 2004. Sentiment classification on customer feedback data: noisy data, large feature vectors, and the role of linguistic analysis. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Soo-Min Kim</author>
<author>Eduard Hovy</author>
</authors>
<title>Determining the sentiment of opinions.</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4551" citStr="Kim and Hovy, 2004" startWordPosition="683" endWordPosition="686">res can be used when the data is labeled (e.g. IMDB’s user reviews are labeled with one to ten stars, which are assumed to correlate with the text’s polarity) (Pang et al., 2002). But text annotated with its true sentiments is hard to come by so often labels must be obtained via crowdsourcing. Knowledge-based methods (which also typically rely on crowdsourcing) provide an alternative to using labeled data (Andreevskaia and Bergler, 2007). These methods are driven by sentiment lexicons, fixed lists associating words with “valences” (signed integers representing positive and negative feelings) (Kim and Hovy, 2004). Some lexicons allow for analysis of specific emotions by associating words with degrees of fear, joy, surprise, anger, anticipation, etc. (Strapparava and Valitutti, 2004) (Mohammad and Turney, 2008). Unsurprisingly, methods which, like these, lack deep understanding often work more reliably as the length of the input text increases. Turning our attention now to automatic semantic analysis of fiction, it seems that narrative modeling and summarization has been the most intensively studied application. Chambers and Jurafsky (2009) described a system that can learn (without supervision) the se</context>
</contexts>
<marker>Kim, Hovy, 2004</marker>
<rawString>Soo-Min Kim and Eduard Hovy. 2004. Determining the sentiment of opinions. In Proceedings of the 20th international conference on Computational Linguistics, COLING ’04, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Crowdsourcing the creation of a word–emotion association lexicon.</title>
<date>2008</date>
<contexts>
<context position="4752" citStr="Mohammad and Turney, 2008" startWordPosition="713" endWordPosition="716">ated with its true sentiments is hard to come by so often labels must be obtained via crowdsourcing. Knowledge-based methods (which also typically rely on crowdsourcing) provide an alternative to using labeled data (Andreevskaia and Bergler, 2007). These methods are driven by sentiment lexicons, fixed lists associating words with “valences” (signed integers representing positive and negative feelings) (Kim and Hovy, 2004). Some lexicons allow for analysis of specific emotions by associating words with degrees of fear, joy, surprise, anger, anticipation, etc. (Strapparava and Valitutti, 2004) (Mohammad and Turney, 2008). Unsurprisingly, methods which, like these, lack deep understanding often work more reliably as the length of the input text increases. Turning our attention now to automatic semantic analysis of fiction, it seems that narrative modeling and summarization has been the most intensively studied application. Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by repre</context>
</contexts>
<marker>Mohammad, Turney, 2008</marker>
<rawString>Saif M Mohammad and Peter D Turney. 2008. Crowdsourcing the creation of a word–emotion association lexicon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Mohammad</author>
</authors>
<title>From once upon a time to happily ever after: Tracking emotions in novels and fairy tales.</title>
<date>2011</date>
<booktitle>In Proceedings of the 5th ACLHLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities,</booktitle>
<pages>105--114</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="6145" citStr="Mohammad (2011)" startWordPosition="926" endWordPosition="927">orks. Extending this line of work to novels, Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used this method to successfully extract social networks from Victorian novels (Elson et al., 2010)(Agarwal et al., 2012). While structure is undeniably important, we believe analyzing a narrative’s emotions is essential to capturing the ‘reading experience,’ which is a view others have held. Alm and Sproat (2005) analyzed Brothers Grimm fairy tales for their ‘emotional trajectories,’ finding emotion typically increases as a story progresses. Mohammad (2011) scaled-up their work by using a crowdsourced emotion lexicon to track emotion dynamics over the course of many novels and plays, including Shakespeare’s. In the most recent work we are aware of, Elsner (2012) analyzed emotional trajectories at the character level, showing how Miss Elizabeth Bennet’s emotions change over the course of Pride and Prejudice. 3 Character-to-Character Sentiment Analysis Character Hamlet&apos;s Sentiment Valence Sum Guildenstern 31 Polonius 25 Gertrude 24 Horatio 12 Ghost 8 Marcellus 7 Osric 7 Bernardo 2 Laertes -1 Ophelia -5 Rosencrantz -12 Claudius -27 Figure 1: The ch</context>
</contexts>
<marker>Mohammad, 2011</marker>
<rawString>S. Mohammad. 2011. From once upon a time to happily ever after: Tracking emotions in novels and fairy tales. In Proceedings of the 5th ACLHLT Workshop on Language Technology for Cultural Heritage, Social Sciences, and Humanities, pages 105–114. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Mutton</author>
</authors>
<title>Inferring and visualizing social networks on internet relay chat.</title>
<date>2004</date>
<booktitle>In Information Visualisation,</booktitle>
<pages>35--43</pages>
<publisher>IEEE.</publisher>
<contexts>
<context position="5409" citStr="Mutton (2004)" startWordPosition="814" endWordPosition="816"> lack deep understanding often work more reliably as the length of the input text increases. Turning our attention now to automatic semantic analysis of fiction, it seems that narrative modeling and summarization has been the most intensively studied application. Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure has also been studied by representing character interactions as networks. Mutton (2004) adapted methods for extracting social networks from Internet Relay Chat (IRC) to mine Shakespeare’s plays for their networks. Extending this line of work to novels, Elson and McKeown (2010) developed a reliable method for speech attribution in unstructured texts, and then used this method to successfully extract social networks from Victorian novels (Elson et al., 2010)(Agarwal et al., 2012). While structure is undeniably important, we believe analyzing a narrative’s emotions is essential to capturing the ‘reading experience,’ which is a view others have held. Alm and Sproat (2005) analyzed B</context>
</contexts>
<marker>Mutton, 2004</marker>
<rawString>P. Mutton. 2004. Inferring and visualizing social networks on internet relay chat. In Information Visualisation, 2004. IV 2004. Proceedings. Eighth International Conference on, pages 35–43. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F ˚A Nielsen</author>
</authors>
<date>2011</date>
<location>Afinn,</location>
<contexts>
<context position="7269" citStr="Nielsen, 2011" startWordPosition="1100" endWordPosition="1101">s 7 Osric 7 Bernardo 2 Laertes -1 Ophelia -5 Rosencrantz -12 Claudius -27 Figure 1: The characters in Hamlet are ranked by Hamet’s sentiment towards them. Expectedly, Claudius draws the most negative emotion. We attempt to further Elsner’s line of work by leveraging text structure (as Mutton and Elson did) and knowlege-based SA to track the emotional trajectories of interpersonal relationships rather than of a whole text or an isolated character. To extract these relationships, we mined for characterto-character sentiment by summing the valence values (provided by the AFINN sentiment lexicon (Nielsen, 2011)) over each instance of continuous speech and then assumed that sentiment was directed towards the character that spoke immediately before the current speaker. This assumption doesn’t always hold; it is not uncommon to find a scene in which two characters are expressing feelings about someone offstage. Yet our initial results on Shakespeare’s plays show that the instances of face-to-face dialogue produce a strong enough signal to generate sentiment rankings that match our expectations. For example, Hamlet’s sentiment rankings upon the conclusion of his play are shown in Figure 1. Not surprisin</context>
</contexts>
<marker>Nielsen, 2011</marker>
<rawString>F. ˚A. Nielsen. 2011. Afinn, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="2824" citStr="Pang and Lee, 2008" startWordPosition="428" endWordPosition="431">in natural language text remains a daunting technical challenge. The reason this task is so difficult is that emotions are indistinct and often subtly conveyed, especially in text with literary merit. Humans typically achieve no greater than 80% accuracy in sentiment classification experiments involving product reviews (Pang et al., 2002) (Gamon, 2004). Similar experiments on fiction texts would presumably yield even higher error rates. In order to attack this open problem and make further progress towards refuting Ramsay’s claim, we turn to shallow statistical approaches. Sentiment analysis (Pang and Lee, 2008) has been successfully applied to mine social media data for emotional responses to events, public figures, and consumer products just by using emotion lexicons–lists that map words to polarity values (+1 for positive sentiment, -1 for negative) or valence values that try to capture degrees of polarity. In the following paper, we describe our attempts to use modern sentiment lexicons and dialogue structure to algorithmically track and model–with no domain-specific customization–the emotion dynamics between characters in Shakespeare’s plays.1 2 Sentiment Analysis and Related Work Sentiment anal</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10, EMNLP ’02,</booktitle>
<pages>79--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2545" citStr="Pang et al., 2002" startWordPosition="385" endWordPosition="388">ighs and lows is often what makes a narrative compelling for a reader, and therefore we believe mapping these journeys is the first step in capturing the human reading experience. Unfortunately but unsurprisingly, computational modeling of the emotional relationships described in natural language text remains a daunting technical challenge. The reason this task is so difficult is that emotions are indistinct and often subtly conveyed, especially in text with literary merit. Humans typically achieve no greater than 80% accuracy in sentiment classification experiments involving product reviews (Pang et al., 2002) (Gamon, 2004). Similar experiments on fiction texts would presumably yield even higher error rates. In order to attack this open problem and make further progress towards refuting Ramsay’s claim, we turn to shallow statistical approaches. Sentiment analysis (Pang and Lee, 2008) has been successfully applied to mine social media data for emotional responses to events, public figures, and consumer products just by using emotion lexicons–lists that map words to polarity values (+1 for positive sentiment, -1 for negative) or valence values that try to capture degrees of polarity. In the following</context>
<context position="4110" citStr="Pang et al., 2002" startWordPosition="616" endWordPosition="619">m product reviews and social-media messages (Pang and Lee, 1XML versions provided by Jon Bosak: http://www.ibiblio.org/xml/examples/shakespeare/ 479 Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 479–483, Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics 2008). Traditional machine learning techniques on n-grams, parts of speech, and other bag of words features can be used when the data is labeled (e.g. IMDB’s user reviews are labeled with one to ten stars, which are assumed to correlate with the text’s polarity) (Pang et al., 2002). But text annotated with its true sentiments is hard to come by so often labels must be obtained via crowdsourcing. Knowledge-based methods (which also typically rely on crowdsourcing) provide an alternative to using labeled data (Andreevskaia and Bergler, 2007). These methods are driven by sentiment lexicons, fixed lists associating words with “valences” (signed integers representing positive and negative feelings) (Kim and Hovy, 2004). Some lexicons allow for analysis of specific emotions by associating words with degrees of fear, joy, surprise, anger, anticipation, etc. (Strapparava and Va</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: sentiment classification using machine learning techniques. In Proceedings of the ACL-02 conference on Empirical methods in natural language processing - Volume 10, EMNLP ’02, pages 79–86, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Ramsay</author>
</authors>
<title>Reading Machines: Toward an Algorithmic Criticism.</title>
<date>2011</date>
<publisher>University of Illinois Press.</publisher>
<contexts>
<context position="1183" citStr="Ramsay (2011)" startWordPosition="180" endWordPosition="181">rate lists of a character’s enemies and allies as well as pinpoint scenes critical to a character’s emotional development. Results of experiments on Shakespeare’s plays are presented along with discussion of how this work can be extended to unstructured texts (i.e. novels). 1 Introduction Insightful analysis of literary fiction often challenges trained human readers let alone machines. In fact, some humanists believe literary analysis is so closely tied to the human condition that it is impossible for computers to perform. In his book Reading Machines: Toward an Algorithmic Criticism, Stephen Ramsay (2011) states: Tools that can adjudicate the hermeneutical parameters of human reading experiences...stretch considerably beyond the most ambitious fantasies of artificial intelligence. Antonio Roque (2012) has challenged Ramsay’s claim, and certainly there has been successful work done in the computational analysis and modeling of narratives, as we will review in the next section. However, we believe that most previous work (except possibly (Elsner, 2012)) has failed to directly address the root cause of Ramsay’s skepticism: can computers extract the emotions encoded in a narrative? For example, ca</context>
</contexts>
<marker>Ramsay, 2011</marker>
<rawString>Stephen Ramsay. 2011. Reading Machines: Toward an Algorithmic Criticism. University of Illinois Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antonio Roque</author>
</authors>
<title>Towards a computational approach to literary text analysis.</title>
<date>2012</date>
<booktitle>NAACL-HLT 2012,</booktitle>
<pages>97</pages>
<contexts>
<context position="1383" citStr="Roque (2012)" startWordPosition="206" endWordPosition="207">ion of how this work can be extended to unstructured texts (i.e. novels). 1 Introduction Insightful analysis of literary fiction often challenges trained human readers let alone machines. In fact, some humanists believe literary analysis is so closely tied to the human condition that it is impossible for computers to perform. In his book Reading Machines: Toward an Algorithmic Criticism, Stephen Ramsay (2011) states: Tools that can adjudicate the hermeneutical parameters of human reading experiences...stretch considerably beyond the most ambitious fantasies of artificial intelligence. Antonio Roque (2012) has challenged Ramsay’s claim, and certainly there has been successful work done in the computational analysis and modeling of narratives, as we will review in the next section. However, we believe that most previous work (except possibly (Elsner, 2012)) has failed to directly address the root cause of Ramsay’s skepticism: can computers extract the emotions encoded in a narrative? For example, can the love that Shakespeare’s Juliet feels for Romeo be computationally tracked? Empathizing with characters along their journeys to emotional highs and lows is often what makes a narrative compelling</context>
</contexts>
<marker>Roque, 2012</marker>
<rawString>Antonio Roque. 2012. Towards a computational approach to literary text analysis. NAACL-HLT 2012, page 97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Strapparava</author>
<author>A Valitutti</author>
</authors>
<title>Wordnet-affect: an affective extension of wordnet.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<volume>4</volume>
<pages>1083--1086</pages>
<contexts>
<context position="4724" citStr="Strapparava and Valitutti, 2004" startWordPosition="708" endWordPosition="712">Pang et al., 2002). But text annotated with its true sentiments is hard to come by so often labels must be obtained via crowdsourcing. Knowledge-based methods (which also typically rely on crowdsourcing) provide an alternative to using labeled data (Andreevskaia and Bergler, 2007). These methods are driven by sentiment lexicons, fixed lists associating words with “valences” (signed integers representing positive and negative feelings) (Kim and Hovy, 2004). Some lexicons allow for analysis of specific emotions by associating words with degrees of fear, joy, surprise, anger, anticipation, etc. (Strapparava and Valitutti, 2004) (Mohammad and Turney, 2008). Unsurprisingly, methods which, like these, lack deep understanding often work more reliably as the length of the input text increases. Turning our attention now to automatic semantic analysis of fiction, it seems that narrative modeling and summarization has been the most intensively studied application. Chambers and Jurafsky (2009) described a system that can learn (without supervision) the sequence of events described in a narrative, and Elson and McKeown (2009) created a platform that can symbolically represent and reason over narratives. Narrative structure ha</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>C. Strapparava and A. Valitutti. 2004. Wordnet-affect: an affective extension of wordnet. In Proceedings of LREC, volume 4, pages 1083–1086.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>