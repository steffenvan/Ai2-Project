<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000103">
<title confidence="0.995608">
Acquiring the Meaning of Discourse Markers
</title>
<author confidence="0.99664">
Ben Hutchinson
</author>
<affiliation confidence="0.9987735">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.991696">
B.Hutchinson@sms.ed.ac.uk
</email>
<sectionHeader confidence="0.993766" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999828285714286">
This paper applies machine learning techniques to
acquiring aspects of the meaning of discourse mark-
ers. Three subtasks of acquiring the meaning of a
discourse marker are considered: learning its polar-
ity, veridicality, and type (i.e. causal, temporal or
additive). Accuracy of over 90% is achieved for all
three tasks, well above the baselines.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.973543093333333">
This paper is concerned with automatically acquir-
ing the meaning of discourse markers. By con-
sidering the distributions of individual tokens of
discourse markers, we classify discourse markers
along three dimensions upon which there is substan-
tial agreement in the literature: polarity, veridical-
ity and type. This approach of classifying linguistic
types by the distribution of linguistic tokens makes
this research similar in spirit to that of Baldwin and
Bond (2003) and Stevenson and Merlo (1999).
Discourse markers signal relations between dis-
course units. As such, discourse markers play an
important role in the parsing of natural language
discourse (Forbes et al., 2001; Marcu, 2000), and
their correspondence with discourse relations can
be exploited for the unsupervised learning of dis-
course relations (Marcu and Echihabi, 2002). In
addition, generating natural language discourse re-
quires the appropriate selection and placement of
discourse markers (Moser and Moore, 1995; Grote
and Stede, 1998). It follows that a detailed account
of the semantics and pragmatics of discourse mark-
ers would be a useful resource for natural language
processing.
Rather than looking at the finer subtleties in
meaning of particular discourse markers (e.g. Best-
gen et al. (2003)), this paper aims at a broad scale
classification of a subclass of discourse markers:
structural connectives. This breadth of coverage
is of particular importance for discourse parsing,
where a wide range of linguistic realisations must be
catered for. This work can be seen as orthogonal to
that of Di Eugenio et al. (1997), which addresses the
problem of learning if and where discourse markers
should be generated.
Unfortunately, the manual classification of large
numbers of discourse markers has proven to be a
difficult task, and no complete classification yet ex-
ists. For example, Knott (1996) presents a list of
around 350 discourse markers, but his taxonomic
classification, perhaps the largest classification in
the literature, accounts for only around 150 of these.
A general method of automatically classifying dis-
course markers would therefore be of great utility,
both for English and for languages with fewer man-
ually created resources. This paper constitutes a
step in that direction. It attempts to classify dis-
course markers whose classes are already known,
and this allows the classifier to be evaluated empiri-
cally.
The proposed task of learning automatically the
meaning of discourse markers raises several ques-
tions which we hope to answer:
Q1. Difficulty How hard is it to acquire the mean-
ing of discourse markers? Are some aspects of
meaning harder to acquire than others?
Q2. Choice of features What features are useful
for acquiring the meaning of discourse mark-
ers? Does the optimal choice of features de-
pend on the aspect of meaning being learnt?
Q3. Classifiers Which machine learning algo-
rithms work best for this task? Can the right
choice of empirical features make the classifi-
cation problems linearly separable?
Q4. Evidence Can corpus evidence be found for
the existing classifications of discourse mark-
ers? Is there empirical evidence for a separate
class of TEMPORAL markers?
We proceed by first introducing the classes of dis-
course markers that we use in our experiments. Sec-
tion 3 discusses the database of discourse markers
used as our corpus. In Section 4 we describe our ex-
periments, including choice of features. The results
are presented in Section 5. Finally, we conclude and
discuss future work in Section 6.
</bodyText>
<sectionHeader confidence="0.959193" genericHeader="method">
2 Discourse markers
</sectionHeader>
<bodyText confidence="0.999109">
Discourse markers are lexical items (possibly multi-
word) that signal relations between propositions,
events or speech acts. Examples of discourse mark-
ers are given in Tables 1, 2 and 3. In this paper
we will focus on a subclass of discourse markers
known as structural connectives. These markers,
even though they may be multiword expressions,
function syntactically as if they were coordinating
or subordinating conjunctions (Webber et al., 2003).
The literature contains many different classi-
fications of discourse markers, drawing upon a
wide range of evidence including textual co-
hesion (Halliday and Hasan, 1976), hypotactic
conjunctions (Martin, 1992), cognitive plausibil-
ity (Sanders et al., 1992), substitutability (Knott,
1996), and psycholinguistic experiments (Louw-
erse, 2001). Nevertheless there is also considerable
agreement. Three dimensions of classification that
recur, albeit under a variety of names, are polarity,
veridicality and type. We now discuss each of these
in turn.
</bodyText>
<subsectionHeader confidence="0.973572">
2.1 Polarity
</subsectionHeader>
<bodyText confidence="0.9998085">
Many discourse markers signal a concession, a con-
trast or the denial of an expectation. These mark-
ers have been described as having the feature polar-
ity=NEG-POL. An example is given in (1).
</bodyText>
<listItem confidence="0.895402666666667">
(1) Suzy’s part-time, but she does more work
than the rest of us put together. (Taken from
Knott (1996, p. 185))
</listItem>
<bodyText confidence="0.997477">
This sentence is true if and only if Suzy both is part-
time and does more work than the rest of them put
together. In addition, it has the additional effect of
signalling that the fact Suzy does more work is sur-
prising — it denies an expectation. A similar effect
can be obtained by using the connective and and
adding more context, as in (2)
</bodyText>
<listItem confidence="0.956598333333333">
(2) Suzy’s efficiency is astounding. She’s
part-time, and she does more work than the
rest of us put together.
</listItem>
<bodyText confidence="0.9900155">
The difference is that although it is possible for
and to co-occur with a negative polarity discourse
relation, it need not. Discourse markers like and are
said to have the feature polarity=POS-POL. 1 On
</bodyText>
<footnote confidence="0.894158">
1An alternative view is that discourse markers like and are
underspecified with respect to polarity (Knott, 1996). In this
</footnote>
<bodyText confidence="0.998934789473684">
the other hand, a NEG-POL discourse marker like
but always co-occurs with a negative polarity dis-
course relation.
The gold standard classes of POS-POL and NEG-
POL discourse markers used in the learning exper-
iments are shown in Table 1. The gold standards
for all three experiments were compiled by consult-
ing a range of previous classifications (Knott, 1996;
Knott and Dale, 1994; Louwerse, 2001). 2
POS-POL NEG-POL
after, and, as, as soon as, although,
because, before, considering but, even if,
that, ever since, for, given that, even though,
if, in case, in order that, in that, even when,
insofar as, now, now that, on only if, only
the grounds that, once, seeing when, or, or
as, since, so, so that, the in- else, though,
stant, the moment, then, to the unless, until,
extent that, when, whenever whereas, yet
</bodyText>
<tableCaption confidence="0.7485515">
Table 1: Discourse markers used in the polarity ex-
periment
</tableCaption>
<subsectionHeader confidence="0.995064">
2.2 Veridicality
</subsectionHeader>
<bodyText confidence="0.999833428571429">
A discourse relation is veridical if it implies the
truth of both its arguments (Asher and Lascarides,
2003), otherwise it is not. For example, in (3) it is
not necessarily true either that David can stay up or
that he promises, or will promise, to be quiet. For
this reason we will say if has the feature veridical-
ity=NON-VERIDICAL.
</bodyText>
<listItem confidence="0.992285">
(3) David can stay up if he promises to be quiet.
</listItem>
<bodyText confidence="0.9985364">
The disjunctive discourse marker or is also NON-
VERIDICAL, because it does not imply that both
of its arguments are true. On the other hand, and
does imply this, and so has the feature veridical-
ity=VERIDICAL.
The VERIDICAL and NON-VERIDICAL discourse
markers used in the learning experiments are shown
in Table 2. Note that the polarity and veridicality
are independent, for example even if is both NEG-
POL and NON-VERIDICAL.
</bodyText>
<subsectionHeader confidence="0.992371">
2.3 Type
</subsectionHeader>
<bodyText confidence="0.887475391304348">
Discourse markers like because signal a CAUSAL
relation, for example in (4).
account, discourse markers have positive polarity only if they
can never be paraphrased using a discourse marker with nega-
tive polarity. Interpreted in these terms, our experiment aims to
distinguish negative polarity discourse markers from all others.
2An effort was made to exclude discourse markers whose
classification could be contentious, as well as ones which
showed ambiguity across classes. Some level ofjudgement was
therefore exercised by the author.
VERIDICAL NON-
VERIDICAL
after, although, and, as, as soon assuming
as, because, but, considering that, even if,
that, even though, even when, if, if ever, if
ever since, for, given that, in or- only, in case,
der that, in that, insofar as, now, on condition
now that, on the grounds that, that, on the
once, only when, seeing as, assumption
since, so, so that, the instant, that, only if,
the moment, then, though, to or, or else,
the extent that, until, when, supposing
whenever, whereas, while, yet that, unless
</bodyText>
<listItem confidence="0.62321875">
Table 2: Discourse markers used in the veridicality
experiment
(4) The tension in the boardroom rose sharply
because the chairman arrived.
</listItem>
<bodyText confidence="0.916629760869565">
As a result, because has the feature
type=CAUSAL. Other discourse markers that
express a temporal relation, such as after, have
the feature type=TEMPORAL. Just as a POS-POL
discourse marker can occur with a negative polarity
discourse relation, the context can also supply a
causal relation even when a TEMPORAL discourse
marker is used, as in (5).
(5) The tension in the boardroom rose sharply
after the chairman arrived.
If the relation a discourse marker signals is nei-
ther CAUSAL or TEMPORAL it has the feature
type=ADDITIVE.
The need for a distinct class of TEMPORAL dis-
course relations is disputed in the literature. On
the one hand, it has been suggested that TEMPO-
RAL relations are a subclass of ADDITIVE ones on
the grounds that the temporal reference inherent
in the marking of tense and aspect “more or less”
fixes the temporal ordering of events (Sanders et al.,
1992). This contrasts with arguments that resolv-
ing discourse relations and temporal order occur as
distinct but inter-related processes (Lascarides and
Asher, 1993). On the other hand, several of the dis-
course markers we count as TEMPORAL, such as as
soon as, might be described as CAUSAL (Oberlan-
der and Knott, 1995). One of the results of the ex-
periments described below is that corpus evidence
suggests ADDITIVE, TEMPORAL and CAUSAL dis-
course markers have distinct distributions.
The ADDITIVE, TEMPORAL and CAUSAL dis-
course markers used in the learning experiments are
shown in Table 3. These features are independent
of the previous ones, for example even though is
CAUSAL, VERIDICAL and NEG-POL.
ADDITIVE TEMPORAL CAUSAL
and, but, after, as although, because,
whereas soon as, even though, for, given
before, that, if, if ever, in case,
ever on condition that, on
since, the assumption that,
now, now on the grounds that,
that, once, provided that, provid-
until, ing that, so, so that,
when, supposing that, though,
whenever unless
</bodyText>
<tableCaption confidence="0.585773">
Table 3: Discourse markers used in the type exper-
iment
</tableCaption>
<sectionHeader confidence="0.987807" genericHeader="method">
3 Corpus
</sectionHeader>
<bodyText confidence="0.9999925">
The data for the experiments comes from a
database of sentences collected automatically from
the British National Corpus and the world wide
web (Hutchinson, 2004). The database contains ex-
ample sentences for each of 140 discourse structural
connectives.
Many discourse markers have surface forms with
other usages, e.g. before in the phrase before noon.
The following procedure was therefore used to se-
lect sentences for inclusion in the database. First,
sentences containing a string matching the sur-
face form of a structural connective were extracted.
These sentences were then parsed using a statistical
parser (Charniak, 2000). Potential structural con-
nectives were then classified on the basis of their
syntactic context, in particular their proximity to S
nodes. Figure 1 shows example syntactic contexts
which were used to identify discourse markers.
</bodyText>
<equation confidence="0.763984625">
(S ...) (CC and) (S...)
(SBAR (IN after) (S...))
(PP (IN after) (S...))
(PP (VBN given) (SBAR (IN that) (S...)))
(NP (DT the) (NN moment) (SBAR...))
(ADVP (RB as) (RB long)
(SBAR (IN as) (S...)))
(PP (IN in) (SBAR (IN that) (S...)))
</equation>
<figureCaption confidence="0.99883">
Figure 1: Identifying structural connectives
</figureCaption>
<bodyText confidence="0.999875692307692">
It is because structural connectives are easy to
identify in this manner that the experiments use only
this subclass of discourse markers. Due to both
parser errors, and the fact that the syntactic heuris-
tics are not foolproof, the database contains noise.
Manual analysis of a sample of 500 sentences re-
vealed about 12% of sentences do not contain the
discourse marker they are supposed to.
Of the discourse markers used in the experiments,
their frequencies in the database ranged from 270
for the instant to 331,701 for and. The mean num-
ber of instances was 32,770, while the median was
4,948.
</bodyText>
<sectionHeader confidence="0.999693" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999874375">
This section presents three machine learning ex-
periments into automatically classifying discourse
markers according to their polarity, veridicality
and type. We begin in Section 4.1 by describing
the features we extract for each discourse marker
token. Then in Section 4.2 we describe the differ-
ent classifiers we use. The results are presented in
Section 4.3.
</bodyText>
<subsectionHeader confidence="0.974923">
4.1 Features used
</subsectionHeader>
<bodyText confidence="0.999963222222222">
We only used structural connectives in the experi-
ments. This meant that the clauses linked syntacti-
cally were also related at the discourse level (Web-
ber et al., 2003). Two types of features were ex-
tracted from the conjoined clauses. Firstly, we used
lexical co-occurrences with words of various parts
of speech. Secondly, we used a range of linguisti-
cally motivated syntactic, semantic, and discourse
features.
</bodyText>
<subsubsectionHeader confidence="0.426895">
4.1.1 Lexical co-occurrences
</subsubsectionHeader>
<bodyText confidence="0.99983265">
Lexical co-occurrences have previously been shown
to be useful for discourse level learning tasks (La-
pata and Lascarides, 2004; Marcu and Echihabi,
2002). For each discourse marker, the words occur-
ring in their superordinate (main) and subordinate
clauses were recorded,3 along with their parts of
speech. We manually clustered the Penn Treebank
parts of speech together to obtain coarser grained
syntactic categories, as shown in Table 4.
We then lemmatised each word and excluded all
lemmas with a frequency of less than 1000 per mil-
lion in the BNC. Finally, words were attached a pre-
fix of either SUB or SUPER according to whether
they occurred in the sub- or superordinate clause
linked by the marker. This distinguished, for exam-
ple, between occurrences of then in the antecedent
(subordinate) and consequent (main) clauses linked
by if.
We also recorded the presence of other discourse
markers in the two clauses, as these had previously
</bodyText>
<footnote confidence="0.9908455">
3For coordinating conjunctions, the left clause was taken to
be superordinate/main clause, the right, the subordinate clause.
</footnote>
<table confidence="0.999031125">
New label Penn Treebank labels
vb vb vbd vbg vbn vbp vbz
nn nn nns nnp
jj jj jjrjjs
rb rb rbr rbs
aux aux auxg md
prp prp prp$
in in
</table>
<tableCaption confidence="0.999854">
Table 4: Clustering of POS labels
</tableCaption>
<bodyText confidence="0.999728857142857">
been found to be useful on a related classification
task (Hutchinson, 2003). The discourse markers
used for this are based on the list of 350 markers
given by Knott (1996), and include multiword ex-
pressions. Due to the sparser nature of discourse
markers, compared to verbs for example, no fre-
quency cutoffs were used.
</bodyText>
<subsectionHeader confidence="0.55279">
4.1.2 Linguistically motivated features
</subsectionHeader>
<bodyText confidence="0.98599151948052">
These included a range of one and two dimensional
features representing more abstract linguistic infor-
mation, and were extracted through automatic anal-
ysis of the parse trees.
One dimensional features
Two one dimensional features recorded the location
of discourse markers. POSITION indicated whether
a discourse marker occurred between the clauses it
linked, or before both of them. It thus relates to
information structuring. EMBEDDING indicated the
level of embedding, in number of clauses, of the dis-
course marker beneath the sentence’s highest level
clause. We were interested to see if some types of
discourse relations are more often deeply embed-
ded.
The remaining features recorded the presence of
linguistic features that are localised to a particu-
lar clause. Like the lexical co-occurrence features,
these were indexed by the clause they occurred in:
either SUPER or SUB.
We expected negation to correlate with nega-
tive polarity discourse markers, and approximated
negation using four features. NEG-SUBJ and NEG-
VERB indicated the presence of subject negation
(e.g. nothing) or verbal negation (e.g. n’t). We also
recorded the occurrence of a set of negative polar-
ity items (NPI), such as any and ever. The features
NPI-AND-NEG and NPI-WO-NEG indicated whether
an NPI occurred in a clause with or without verbal
or subject negation.
Eventualities can be placed or ordered in time us-
ing not just discourse markers but also temporal ex-
pressions. The feature TEMPEX recorded the num-
ber of temporal expressions in each clause, as re-
turned by a temporal expression tagger (Mani and
Wilson, 2000).
If the main verb was an inflection of to be or to do
we recorded this using the features BE and DO. Our
motivation was to capture any correlation of these
verbs with states and events respectively.
If the final verb was a modal auxiliary, this el-
lipsis was evidence of strong cohesion in the text
(Halliday and Hasan, 1976). We recorded this with
the feature VP-ELLIPSIS. Pronouns also indicate co-
hesion, and have been shown to correlate with sub-
jectivity (Bestgen et al., 2003). A class of features
PRONOUNS represented pronouns, with denot-
ing either 1st person, 2nd person, or 3rd person ani-
mate, inanimate or plural.
The syntactic structure of each clause was cap-
tured using two features, one finer grained and one
coarser grained. STRUCTURAL-SKELETON identi-
fied the major constituents under the S or VP nodes,
e.g. a simple double object construction gives “NP
VB NP NP”. ARGS identified whether the clause
contained an (overt) object, an (overt) subject, or
both, or neither.
The overall size of a clause was represented us-
ing four features. WORDS, NPS and PPS recorded
the numbers of words, NPs and PPs in a clause (not
counting embedded clauses). The feature CLAUSES
counted the number of clauses embedded beneath a
clause.
Two dimensional features
These features all recorded combinations of linguis-
tic features across the two clauses linked by the
discourse marker. For example the MOOD feature
would take the value DECL,IMP for the sentence
John is coming, but don’t tell anyone!
These features were all determined automatically
by analysing the auxiliary verbs and the main verbs’
POS tags. The features and the possible values for
each clause were as follows: MODALITY: one of
FUTURE, ABILITY or NULL; MOOD: one of DECL,
IMP or INTERR; PERFECT: either YES or NO; PRO-
GRESSIVE: either YES or NO; TENSE: either PAST
or PRESENT.
</bodyText>
<subsectionHeader confidence="0.982073">
4.2 Classifier architectures
</subsectionHeader>
<bodyText confidence="0.998526764705882">
Two different classifiers, based on local and global
methods of comparison, were used in the experi-
ments. The first, 1 Nearest Neighbour (1NN), is an
instance based classifier which assigns each marker
to the same class as that of the marker nearest to
it. For this, three different distance metrics were
explored. The first metric was the Euclidean dis-
tance function , shown in (6), applied to proba-
bility distributions.
The second, , is a smoothed variant of
the information theoretic Kullback-Leibner diver-
gence (Lee, 2001, with ). Its definition
is given in (7).
The third metric, , is a-test weighted adap-
tion of the Jaccard coefficient (Curran and Moens,
2002). In it basic form, the Jaccard coefficient is es-
sentially a measure of how much two distributions
overlap. The-test variant weights co-occurrences
by the strength of their collocation, using the fol-
lowing function:
This is then used define the weighted version of
the Jaccard coefficient, as shown in (8). The words
associated with distributions and are indicated
by and , respectively.
and had previously been found to
be the best metrics for other tasks involving lexi-
cal similarity. is included to indicate what can
be achieved using a somewhat naive metric.
The second classifier used, Naive Bayes, takes
the overall distribution of each class into account. It
essentially defines a decision boundary in the form
of a curved hyperplane. The Weka implementa-
tion (Witten and Frank, 2000) was used for the ex-
periments, with 10-fold cross-validation.
</bodyText>
<subsectionHeader confidence="0.64191">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.9871495">
We began by comparing the performance of
the 1NN classifier using the various lexical co-
occurrence features against the gold standards. The
results using all lexical co-occurrences are shown
</bodyText>
<table confidence="0.996029833333333">
Task Baseline All POS Best Best
single POS subset
polarity 67.4 74.4 72.1 74.4 76.7 (rb) 83.7 (rb) 76.7 (rb) 83.7
veridicality 73.5 81.6 85.7 75.5 83.7 (nn) 91.8 (vb) 87.8 (vb) 91.8
type 58.1 74.2 64.5 81.8 74.2 (in) 74.2 (rb) 77.4 (jj) 87.8
Using and either rb or DMs+rb.Using both and vb, and and vb+in.Using and vb+aux+in
</table>
<tableCaption confidence="0.995016">
Table 5: Results using the 1NN classifier on lexical co-occurrences
</tableCaption>
<table confidence="0.806908333333333">
Feature Positively correlated discourse marker co-occurrences
POS-POL though , but , although , assuming that
NEG-POL otherwise , still , in truth , still , after that , in this way , granted that , in
contrast , by then , in the event
VERIDICAL obviously , now , even , indeed , once more , considering that , even after ,
once more , at irst sight
NON-VERIDICAL or , no doubt , in turn , then , by all means , before then
ADDITIVE also , in addition , still , only , at the same time , clearly , naturally ,
now , of course
TEMPORAL back , once more , like , and , once more , which was why ,
CAUSAL again ,altogether ,back ,inally , also , thereby , at once , while ,
clearly ,
</table>
<tableCaption confidence="0.888736">
Table 6: Most informative discourse marker co-occurrences in the super- ( ) and subordinate ( ) clauses
</tableCaption>
<bodyText confidence="0.999494333333333">
in Table 5. The baseline was obtained by assigning
discourse markers to the largest class, i.e. with the
most types. The best results obtained using just a
single POS class are also shown. The results across
the different metrics suggest that adverbs and verbs
are the best single predictors of polarity and veridi-
cality, respectively.
We next applied the 1NN classifier to co-
occurrences with discourse markers. The results are
shown in Table 7. The results show that for each
task 1NN with the weighted Jaccard coefficient per-
forms at least as well as the other three classifiers.
</bodyText>
<table confidence="0.994966">
1NN with metric: Naive
Task Bayes
polarity 74.4 81.4 81.4 81.4
veridicality 83.7 79.6 83.7 73.5
type 74.2 80.1 80.1 58.1
</table>
<tableCaption confidence="0.999806">
Table 7: Results using co-occurrences with DMs
</tableCaption>
<bodyText confidence="0.999455111111111">
We also compared using the following combina-
tions of different parts of speech: vb + aux, vb + in,
vb + rb, nn + prp, vb + nn + prp, vb + aux + rb, vb +
aux + in, vb + aux + nn + prp, nn + prp + in, DMs +
rb, DMs + vb and DMs + rb + vb. The best results
obtained using all combinations tried are shown in
the last column of Table 5. For DMs + rb, DMs + vb
and DMs + rb + vb we also tried weighting the co-
occurrences so that the sums of the co-occurrences
with each of verbs, adverbs and discourse markers
were equal. However this did not lead to any better
results.
One property that distinguishes from the
other metrics is that it weights features the strength
of their collocation. We were therefore interested
to see which co-occurrences were most informa-
tive. Using Weka’s feature selection utility, we
ranked discourse marker co-occurrences by their in-
formation gain when predicting polarity, veridical-
ity and type. The most informative co-occurrences
are listed in Table 6. For example, if also occurs in
the subordinate clause then the discourse marker is
more likely to be ADDITIVE.
The 1NN and Naive Bayes classifiers were then
applied to co-occurrences with just the DMs that
were most informative for each task. The results,
shown in Table 8, indicate that the performance of
</bodyText>
<footnote confidence="0.993611333333333">
1NN drops when we restrict ourselves to this subset.
4 However Naive Bayes outperforms all previous
1NN classifiers.
</footnote>
<table confidence="0.9991816">
Base- 1NN with: Naive
Task line Bayes
polarity 67.4 72.1 69.8 90.7
veridicality 73.5 85.7 77.6 91.8
type 58.1 67.7 58.1 93.5
</table>
<tableCaption confidence="0.997758">
Table 8: Results using most informative DMs
</tableCaption>
<footnote confidence="0.923285">
4The metric is omitted because it essentially already
has its own method of factoring in informativity.
</footnote>
<table confidence="0.999849272727273">
Feature Positively correlated features
POS-POL No significantly informative predictors correlated positively
NEG-POL NEG-VERBAL , NEG-SUBJ , ARGS=NONE , MODALITY= ABILITY,ABILITY
VERIDICAL VERB=BE , WORDS , WORDS , MODALITY= NULL,NULL
NON-VERID TEMPEX , PRONOUN , PRONOUN
ADDITIVE WORDS , WORDS , CLAUSES , MODALITY= ABILITY,FUTURE ,
MODALITY= ABILITY,ABILITY , NPS , MODALITY= FUTURE,FUTURE ,
MOOD= DECLARATIVE,DECLARATIVE
TEMPORAL EMBEDDING=7, PRONOUN , MOOD= INTERROGATIVE,DECLARATIVE
CAUSAL NEG-SUBJ , NEG-VERBAL ,NPI-WO-NEG ,NPI-AND-NEG ,
MODALITY= NULL,FUTURE
</table>
<tableCaption confidence="0.909951">
Table 9: The most informative linguistically motivated predictors for each class. The indices and
indicate that a one dimensional feature belongs to the superordinate or subordinate clause, respectively.
</tableCaption>
<bodyText confidence="0.997234142857143">
Weka’s feature selection utility was also applied
to all the linguistically motivated features described
in Section 4.1.2. The most informative features are
shown in Table 9. Naive Bayes was then applied
using both all the linguistically motivated features,
and just the most informative ones. The results are
shown in Table 10.
</bodyText>
<table confidence="0.9968974">
Task Baseline All Most
features informative
polarity 67.4 74.4 72.1
veridicality 73.5 77.6 79.6
type 58.1 64.5 77.4
</table>
<tableCaption confidence="0.997788">
Table 10: Naive Bayes and linguistic features
</tableCaption>
<sectionHeader confidence="0.997637" genericHeader="method">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999939461538461">
The results demonstrate that discourse markers can
be classified along three different dimensions with
an accuracy of over 90%. The best classifiers
used a global algorithm (Naive Bayes), with co-
occurrences with a subset of discourse markers as
features. The success of Naive Bayes shows that
with the right choice of features the classification
task is highly separable. The high degree of accu-
racy attained on the type task suggests that there is
empirical evidence for a distinct class of TEMPO-
RAL markers.
The results also provide empirical evidence for
the correlation between certain linguistic features
and types of discourse relation. Here we restrict
ourselves to making just five observations. Firstly,
verbs and adverbs are the most informative parts of
speech when classifying discourse markers. This
is presumably because of their close relation to
the main predicate of the clause. Secondly, Ta-
ble 6 shows that the discourse marker DM in the
structure X, but/though/although Y DM Z is more
likely to be signalling a positive polarity discourse
relation between Y and Z than a negative po-
larity one. This suggests that a negative polar-
ity discourse relation is less likely to be embed-
ded directly beneath another negative polarity dis-
course relation. Thirdly, negation correlates with
the main clause of NEG-POL discourse markers,
and it also correlates with subordinate clause of
CAUSAL ones. Fourthly, NON-VERIDICAL corre-
lates with second person pronouns, suggesting that a
writer/speaker is less likely to make assertions about
the reader/listener than about other entities. Lastly,
the best results with knowledge poor features, i.e.
lexical co-occurrences, were better than those with
linguistically sophisticated ones. It may be that the
sophisticated features are predictive of only certain
subclasses of the classes we used, e.g. hypotheticals,
or signallers of contrast.
</bodyText>
<sectionHeader confidence="0.996357" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999990277777778">
We have proposed corpus-based techniques for clas-
sifying discourse markers along three dimensions:
polarity, veridicality and type. For these tasks we
were able to classify with accuracy rates of 90.7%,
91.8% and 93.5% respectively. These equate to er-
ror reduction rates of 71.5%, 69.1% and 84.5% from
the baseline error rates. In addition, we determined
which features were most informative for the differ-
ent classification tasks.
In future work we aim to extend our work in two
directions. Firstly, we will consider finer-grained
classification tasks, such as learning whether a
causal discourse marker introduces a cause or a con-
sequence, e.g. distinguishing because from so. Sec-
ondly, we would like to see how far our results can
be extended to include adverbial discourse markers,
such as instead or for example, by using just fea-
tures of the clauses they occur in.
</bodyText>
<sectionHeader confidence="0.990277" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999573">
I would like to thank Mirella Lapata, Alex Las-
carides, Bonnie Webber, and the three anonymous
reviewers for their comments on drafts of this pa-
per. This research was supported by EPSRC Grant
GR/R40036/01 and a University of Sydney Travel-
ling Scholarship.
</bodyText>
<sectionHeader confidence="0.998474" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999685205607476">
Nicholas Asher and Alex Lascarides. 2003. Logics of
Conversation. Cambridge University Press.
Timothy Baldwin and Francis Bond. 2003. Learning the
countability of English nouns from corpus data. In
Proceedings ofACL 2003, pages 463–470.
Yves Bestgen, Liesbeth Degand, and Wilbert Spooren.
2003. On the use of automatic techniques to deter-
mine the semantics of connectives in large newspaper
corpora: An exploratory study. In Proceedings of the
MAD’03 workshop on Multidisciplinary Approaches
to Discourse, October.
Eugene Charniak. 2000. A maximum-entropy-inspired
parser. In Proceedings of the First Conference of the
North American Chapter of the Association for Com-
putational Linguistics (NAACL-2000), Seattle, Wash-
ington, USA.
James R. Curran and M. Moens. 2002. Improvements in
automatic thesaurus extraction. In Proceedings of the
Workshop on Unsupervised Lexical Acquisition, pages
59–67, Philadelphia, PA, USA.
Barbara Di Eugenio, Johanna D. Moore, and Massimo
Paolucci. 1997. Learning features that predict cue
usage. In Proceedings of the 35th Conference of the
Association for Computational Linguistics (ACL97),
Madrid, Spain, July.
Katherine Forbes, Eleni Miltsakaki, Rashmi Prasad,
Anoop Sarkar, Aravind Joshi, and Bonnie Webber.
2001. D-LTAG system—discourse parsing with a lex-
icalised tree adjoining grammar. In Proceedings of the
ESSLI 2001 Workshop on Information Structure, Dis-
course Structure, and Discourse Semantics, Helsinki,
Finland.
Brigitte Grote and Manfred Stede. 1998. Discourse
marker choice in sentence planning. In Eduard Hovy,
editor, Proceedings of the Ninth International Work-
shop on Natural Language Generation, pages 128–
137. Association for Computational Linguistics, New
Brunswick, New Jersey.
M. Halliday and R. Hasan. 1976. Cohesion in English.
Longman.
Ben Hutchinson. 2003. Automatic classification of dis-
course markers by their co-occurrences. In Proceed-
ings of the ESSLLI2003 workshop on Discourse Par-
ticles: Meaning and Implementation, Vienna, Austria.
Ben Hutchinson. 2004. Mining the web for discourse
markers. In Proceedings of the Fourth International
Conference on Language Resources and Evaluation
(LREC 2004), Lisbon, Portugal.
Alistair Knott and Robert Dale. 1994. Using linguistic
phenomena to motivate a set of coherence relations.
Discourse Processes, 18(1):35–62.
Alistair Knott. 1996. A data-driven methodology for
motivating a set of coherence relations. Ph.D. thesis,
University of Edinburgh.
Mirella Lapata and Alex Lascarides. 2004. Inferring
sentence-internal temporal relations. In In Proceed-
ings of the Human Language Technology Confer-
ence and the North American Chapter of the Associ-
ation for Computational Linguistics Annual Meeting,
Boston, MA.
Alex Lascarides and Nicholas Asher. 1993. Temporal
interpretation, discourse relations and common sense
entailment. Linguistics and Philosophy, 16(5):437–
493.
Lillian Lee. 2001. On the effectiveness of the skew di-
vergence for statistical language analysis. Artificial
Intelligence and Statistics, pages 65–72.
Max M Louwerse. 2001. An analytic and cognitive pa-
rameterization of coherence relations. Cognitive Lin-
guistics, 12(3):291–315.
Inderjeet Mani and George Wilson. 2000. Robust tem-
poral processing of news. In Proceedings of the
38th Annual Meeting of the Association for Compu-
tational Linguistics (ACL 2000), pages 69–76, New
Brunswick, New Jersey.
Daniel Marcu and Abdessamad Echihabi. 2002. An
unsupervised approach to recognizing discourse rela-
tions. In Proceedings of the 40th Annual Meeting of
the Association for Computational Linguistics (ACL-
2002), Philadelphia, PA.
Daniel Marcu. 2000. The Theory and Practice of Dis-
course Parsing and Summarization. The MIT Press.
Jim Martin. 1992. English Text: System and Structure.
Benjamin, Amsterdam.
M. Moser and J. Moore. 1995. Using discourse analy-
sis and automatic text generation to study discourse
cue usage. In Proceedings of the AAAI 1995 Spring
Symposium on Empirical Methods in Discourse Inter-
pretation and Generation, pages 92–98.
Jon Oberlander and Alistair Knott. 1995. Issues in
cue phrase implicature. In Proceedings of the AAAI
Spring Symposium on Empirical Methods in Dis-
course Interpretation and Generation.
Ted J. M. Sanders, W. P. M. Spooren, and L. G. M. No-
ordman. 1992. Towards a taxonomy of coherence re-
lations. Discourse Processes, 15:1–35.
Suzanne Stevenson and Paola Merlo. 1999. Automatic
verb classification using distributions of grammatical
features. In Proceedings of the 9th Conference of the
European Chapter of the ACL, pages 45–52, Bergen,
Norway.
Bonnie Webber, Matthew Stone, Aravind Joshi, and Al-
istair Knott. 2003. Anaphora and discourse structure.
Computational Linguistics, 29(4):545–588.
Ian H. Witten and Eibe Frank. 2000. Data Mining:
Practical machine learning tools with Java implemen-
tations. Morgan Kaufmann, San Francisco.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.986881">
<title confidence="0.999765">Acquiring the Meaning of Discourse Markers</title>
<author confidence="0.999691">Ben Hutchinson</author>
<affiliation confidence="0.999851">School of Informatics University of Edinburgh</affiliation>
<email confidence="0.997064">B.Hutchinson@sms.ed.ac.uk</email>
<abstract confidence="0.998818875">This paper applies machine learning techniques to acquiring aspects of the meaning of discourse markers. Three subtasks of acquiring the meaning of a marker are considered: learning its polarand causal, temporal or additive). Accuracy of over 90% is achieved for all three tasks, well above the baselines.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Logics of Conversation.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="7137" citStr="Asher and Lascarides, 2003" startWordPosition="1136" endWordPosition="1139">e, 1994; Louwerse, 2001). 2 POS-POL NEG-POL after, and, as, as soon as, although, because, before, considering but, even if, that, ever since, for, given that, even though, if, in case, in order that, in that, even when, insofar as, now, now that, on only if, only the grounds that, once, seeing when, or, or as, since, so, so that, the in- else, though, stant, the moment, then, to the unless, until, extent that, when, whenever whereas, yet Table 1: Discourse markers used in the polarity experiment 2.2 Veridicality A discourse relation is veridical if it implies the truth of both its arguments (Asher and Lascarides, 2003), otherwise it is not. For example, in (3) it is not necessarily true either that David can stay up or that he promises, or will promise, to be quiet. For this reason we will say if has the feature veridicality=NON-VERIDICAL. (3) David can stay up if he promises to be quiet. The disjunctive discourse marker or is also NONVERIDICAL, because it does not imply that both of its arguments are true. On the other hand, and does imply this, and so has the feature veridicality=VERIDICAL. The VERIDICAL and NON-VERIDICAL discourse markers used in the learning experiments are shown in Table 2. Note that t</context>
</contexts>
<marker>Asher, Lascarides, 2003</marker>
<rawString>Nicholas Asher and Alex Lascarides. 2003. Logics of Conversation. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
</authors>
<title>Learning the countability of English nouns from corpus data.</title>
<date>2003</date>
<booktitle>In Proceedings ofACL</booktitle>
<pages>463--470</pages>
<contexts>
<context position="969" citStr="Baldwin and Bond (2003)" startWordPosition="139" endWordPosition="142">eridicality, and type (i.e. causal, temporal or additive). Accuracy of over 90% is achieved for all three tasks, well above the baselines. 1 Introduction This paper is concerned with automatically acquiring the meaning of discourse markers. By considering the distributions of individual tokens of discourse markers, we classify discourse markers along three dimensions upon which there is substantial agreement in the literature: polarity, veridicality and type. This approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999). Discourse markers signal relations between discourse units. As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002). In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998). It follows that a detailed account of the semantics and pra</context>
</contexts>
<marker>Baldwin, Bond, 2003</marker>
<rawString>Timothy Baldwin and Francis Bond. 2003. Learning the countability of English nouns from corpus data. In Proceedings ofACL 2003, pages 463–470.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yves Bestgen</author>
<author>Liesbeth Degand</author>
<author>Wilbert Spooren</author>
</authors>
<title>On the use of automatic techniques to determine the semantics of connectives in large newspaper corpora: An exploratory study.</title>
<date>2003</date>
<booktitle>In Proceedings of the MAD’03 workshop on Multidisciplinary Approaches to Discourse,</booktitle>
<contexts>
<context position="1772" citStr="Bestgen et al. (2003)" startWordPosition="260" endWordPosition="264">ourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002). In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998). It follows that a detailed account of the semantics and pragmatics of discourse markers would be a useful resource for natural language processing. Rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. Bestgen et al. (2003)), this paper aims at a broad scale classification of a subclass of discourse markers: structural connectives. This breadth of coverage is of particular importance for discourse parsing, where a wide range of linguistic realisations must be catered for. This work can be seen as orthogonal to that of Di Eugenio et al. (1997), which addresses the problem of learning if and where discourse markers should be generated. Unfortunately, the manual classification of large numbers of discourse markers has proven to be a difficult task, and no complete classification yet exists. For example, Knott (1996</context>
<context position="17255" citStr="Bestgen et al., 2003" startWordPosition="2788" endWordPosition="2791">eature TEMPEX recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger (Mani and Wilson, 2000). If the main verb was an inflection of to be or to do we recorded this using the features BE and DO. Our motivation was to capture any correlation of these verbs with states and events respectively. If the final verb was a modal auxiliary, this ellipsis was evidence of strong cohesion in the text (Halliday and Hasan, 1976). We recorded this with the feature VP-ELLIPSIS. Pronouns also indicate cohesion, and have been shown to correlate with subjectivity (Bestgen et al., 2003). A class of features PRONOUNS represented pronouns, with denoting either 1st person, 2nd person, or 3rd person animate, inanimate or plural. The syntactic structure of each clause was captured using two features, one finer grained and one coarser grained. STRUCTURAL-SKELETON identified the major constituents under the S or VP nodes, e.g. a simple double object construction gives “NP VB NP NP”. ARGS identified whether the clause contained an (overt) object, an (overt) subject, or both, or neither. The overall size of a clause was represented using four features. WORDS, NPS and PPS recorded the</context>
</contexts>
<marker>Bestgen, Degand, Spooren, 2003</marker>
<rawString>Yves Bestgen, Liesbeth Degand, and Wilbert Spooren. 2003. On the use of automatic techniques to determine the semantics of connectives in large newspaper corpora: An exploratory study. In Proceedings of the MAD’03 workshop on Multidisciplinary Approaches to Discourse, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
</authors>
<title>A maximum-entropy-inspired parser.</title>
<date>2000</date>
<booktitle>In Proceedings of the First Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-2000),</booktitle>
<location>Seattle, Washington, USA.</location>
<contexts>
<context position="11643" citStr="Charniak, 2000" startWordPosition="1874" endWordPosition="1875">e experiments comes from a database of sentences collected automatically from the British National Corpus and the world wide web (Hutchinson, 2004). The database contains example sentences for each of 140 discourse structural connectives. Many discourse markers have surface forms with other usages, e.g. before in the phrase before noon. The following procedure was therefore used to select sentences for inclusion in the database. First, sentences containing a string matching the surface form of a structural connective were extracted. These sentences were then parsed using a statistical parser (Charniak, 2000). Potential structural connectives were then classified on the basis of their syntactic context, in particular their proximity to S nodes. Figure 1 shows example syntactic contexts which were used to identify discourse markers. (S ...) (CC and) (S...) (SBAR (IN after) (S...)) (PP (IN after) (S...)) (PP (VBN given) (SBAR (IN that) (S...))) (NP (DT the) (NN moment) (SBAR...)) (ADVP (RB as) (RB long) (SBAR (IN as) (S...))) (PP (IN in) (SBAR (IN that) (S...))) Figure 1: Identifying structural connectives It is because structural connectives are easy to identify in this manner that the experiments </context>
</contexts>
<marker>Charniak, 2000</marker>
<rawString>Eugene Charniak. 2000. A maximum-entropy-inspired parser. In Proceedings of the First Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-2000), Seattle, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James R Curran</author>
<author>M Moens</author>
</authors>
<title>Improvements in automatic thesaurus extraction.</title>
<date>2002</date>
<booktitle>In Proceedings of the Workshop on Unsupervised Lexical Acquisition,</booktitle>
<pages>59--67</pages>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="19309" citStr="Curran and Moens, 2002" startWordPosition="3126" endWordPosition="3129">nd global methods of comparison, were used in the experiments. The first, 1 Nearest Neighbour (1NN), is an instance based classifier which assigns each marker to the same class as that of the marker nearest to it. For this, three different distance metrics were explored. The first metric was the Euclidean distance function , shown in (6), applied to probability distributions. The second, , is a smoothed variant of the information theoretic Kullback-Leibner divergence (Lee, 2001, with ). Its definition is given in (7). The third metric, , is a-test weighted adaption of the Jaccard coefficient (Curran and Moens, 2002). In it basic form, the Jaccard coefficient is essentially a measure of how much two distributions overlap. The-test variant weights co-occurrences by the strength of their collocation, using the following function: This is then used define the weighted version of the Jaccard coefficient, as shown in (8). The words associated with distributions and are indicated by and , respectively. and had previously been found to be the best metrics for other tasks involving lexical similarity. is included to indicate what can be achieved using a somewhat naive metric. The second classifier used, Naive Bay</context>
</contexts>
<marker>Curran, Moens, 2002</marker>
<rawString>James R. Curran and M. Moens. 2002. Improvements in automatic thesaurus extraction. In Proceedings of the Workshop on Unsupervised Lexical Acquisition, pages 59–67, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Di Eugenio</author>
<author>Johanna D Moore</author>
<author>Massimo Paolucci</author>
</authors>
<title>Learning features that predict cue usage.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Conference of the Association for Computational Linguistics (ACL97),</booktitle>
<location>Madrid, Spain,</location>
<marker>Di Eugenio, Moore, Paolucci, 1997</marker>
<rawString>Barbara Di Eugenio, Johanna D. Moore, and Massimo Paolucci. 1997. Learning features that predict cue usage. In Proceedings of the 35th Conference of the Association for Computational Linguistics (ACL97), Madrid, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katherine Forbes</author>
<author>Eleni Miltsakaki</author>
<author>Rashmi Prasad</author>
<author>Anoop Sarkar</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>D-LTAG system—discourse parsing with a lexicalised tree adjoining grammar.</title>
<date>2001</date>
<booktitle>In Proceedings of the ESSLI 2001 Workshop on Information Structure, Discourse Structure, and Discourse Semantics,</booktitle>
<location>Helsinki, Finland.</location>
<contexts>
<context position="1177" citStr="Forbes et al., 2001" startWordPosition="171" endWordPosition="174">eaning of discourse markers. By considering the distributions of individual tokens of discourse markers, we classify discourse markers along three dimensions upon which there is substantial agreement in the literature: polarity, veridicality and type. This approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999). Discourse markers signal relations between discourse units. As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002). In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998). It follows that a detailed account of the semantics and pragmatics of discourse markers would be a useful resource for natural language processing. Rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. Bestgen et al. (2003)), th</context>
</contexts>
<marker>Forbes, Miltsakaki, Prasad, Sarkar, Joshi, Webber, 2001</marker>
<rawString>Katherine Forbes, Eleni Miltsakaki, Rashmi Prasad, Anoop Sarkar, Aravind Joshi, and Bonnie Webber. 2001. D-LTAG system—discourse parsing with a lexicalised tree adjoining grammar. In Proceedings of the ESSLI 2001 Workshop on Information Structure, Discourse Structure, and Discourse Semantics, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Grote</author>
<author>Manfred Stede</author>
</authors>
<title>Discourse marker choice in sentence planning.</title>
<date>1998</date>
<booktitle>Proceedings of the Ninth International Workshop on Natural Language Generation,</booktitle>
<pages>128--137</pages>
<editor>In Eduard Hovy, editor,</editor>
<location>New Brunswick, New Jersey.</location>
<contexts>
<context position="1508" citStr="Grote and Stede, 1998" startWordPosition="218" endWordPosition="221">tic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999). Discourse markers signal relations between discourse units. As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002). In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998). It follows that a detailed account of the semantics and pragmatics of discourse markers would be a useful resource for natural language processing. Rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. Bestgen et al. (2003)), this paper aims at a broad scale classification of a subclass of discourse markers: structural connectives. This breadth of coverage is of particular importance for discourse parsing, where a wide range of linguistic realisations must be catered for. This work can be seen as orthogonal to that of Di Eugenio et al. (1997), which add</context>
</contexts>
<marker>Grote, Stede, 1998</marker>
<rawString>Brigitte Grote and Manfred Stede. 1998. Discourse marker choice in sentence planning. In Eduard Hovy, editor, Proceedings of the Ninth International Workshop on Natural Language Generation, pages 128– 137. Association for Computational Linguistics, New Brunswick, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Halliday</author>
<author>R Hasan</author>
</authors>
<date>1976</date>
<note>Cohesion in English. Longman.</note>
<contexts>
<context position="4665" citStr="Halliday and Hasan, 1976" startWordPosition="722" endWordPosition="725">markers Discourse markers are lexical items (possibly multiword) that signal relations between propositions, events or speech acts. Examples of discourse markers are given in Tables 1, 2 and 3. In this paper we will focus on a subclass of discourse markers known as structural connectives. These markers, even though they may be multiword expressions, function syntactically as if they were coordinating or subordinating conjunctions (Webber et al., 2003). The literature contains many different classifications of discourse markers, drawing upon a wide range of evidence including textual cohesion (Halliday and Hasan, 1976), hypotactic conjunctions (Martin, 1992), cognitive plausibility (Sanders et al., 1992), substitutability (Knott, 1996), and psycholinguistic experiments (Louwerse, 2001). Nevertheless there is also considerable agreement. Three dimensions of classification that recur, albeit under a variety of names, are polarity, veridicality and type. We now discuss each of these in turn. 2.1 Polarity Many discourse markers signal a concession, a contrast or the denial of an expectation. These markers have been described as having the feature polarity=NEG-POL. An example is given in (1). (1) Suzy’s part-tim</context>
<context position="17100" citStr="Halliday and Hasan, 1976" startWordPosition="2763" endWordPosition="2766">ith or without verbal or subject negation. Eventualities can be placed or ordered in time using not just discourse markers but also temporal expressions. The feature TEMPEX recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger (Mani and Wilson, 2000). If the main verb was an inflection of to be or to do we recorded this using the features BE and DO. Our motivation was to capture any correlation of these verbs with states and events respectively. If the final verb was a modal auxiliary, this ellipsis was evidence of strong cohesion in the text (Halliday and Hasan, 1976). We recorded this with the feature VP-ELLIPSIS. Pronouns also indicate cohesion, and have been shown to correlate with subjectivity (Bestgen et al., 2003). A class of features PRONOUNS represented pronouns, with denoting either 1st person, 2nd person, or 3rd person animate, inanimate or plural. The syntactic structure of each clause was captured using two features, one finer grained and one coarser grained. STRUCTURAL-SKELETON identified the major constituents under the S or VP nodes, e.g. a simple double object construction gives “NP VB NP NP”. ARGS identified whether the clause contained an</context>
</contexts>
<marker>Halliday, Hasan, 1976</marker>
<rawString>M. Halliday and R. Hasan. 1976. Cohesion in English. Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hutchinson</author>
</authors>
<title>Automatic classification of discourse markers by their co-occurrences.</title>
<date>2003</date>
<booktitle>In Proceedings of the ESSLLI2003 workshop on Discourse Particles: Meaning and Implementation,</booktitle>
<location>Vienna, Austria.</location>
<contexts>
<context position="14892" citStr="Hutchinson, 2003" startWordPosition="2406" endWordPosition="2407">he marker. This distinguished, for example, between occurrences of then in the antecedent (subordinate) and consequent (main) clauses linked by if. We also recorded the presence of other discourse markers in the two clauses, as these had previously 3For coordinating conjunctions, the left clause was taken to be superordinate/main clause, the right, the subordinate clause. New label Penn Treebank labels vb vb vbd vbg vbn vbp vbz nn nn nns nnp jj jj jjrjjs rb rb rbr rbs aux aux auxg md prp prp prp$ in in Table 4: Clustering of POS labels been found to be useful on a related classification task (Hutchinson, 2003). The discourse markers used for this are based on the list of 350 markers given by Knott (1996), and include multiword expressions. Due to the sparser nature of discourse markers, compared to verbs for example, no frequency cutoffs were used. 4.1.2 Linguistically motivated features These included a range of one and two dimensional features representing more abstract linguistic information, and were extracted through automatic analysis of the parse trees. One dimensional features Two one dimensional features recorded the location of discourse markers. POSITION indicated whether a discourse mar</context>
</contexts>
<marker>Hutchinson, 2003</marker>
<rawString>Ben Hutchinson. 2003. Automatic classification of discourse markers by their co-occurrences. In Proceedings of the ESSLLI2003 workshop on Discourse Particles: Meaning and Implementation, Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Hutchinson</author>
</authors>
<title>Mining the web for discourse markers.</title>
<date>2004</date>
<booktitle>In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="11175" citStr="Hutchinson, 2004" startWordPosition="1803" endWordPosition="1804">r example even though is CAUSAL, VERIDICAL and NEG-POL. ADDITIVE TEMPORAL CAUSAL and, but, after, as although, because, whereas soon as, even though, for, given before, that, if, if ever, in case, ever on condition that, on since, the assumption that, now, now on the grounds that, that, once, provided that, providuntil, ing that, so, so that, when, supposing that, though, whenever unless Table 3: Discourse markers used in the type experiment 3 Corpus The data for the experiments comes from a database of sentences collected automatically from the British National Corpus and the world wide web (Hutchinson, 2004). The database contains example sentences for each of 140 discourse structural connectives. Many discourse markers have surface forms with other usages, e.g. before in the phrase before noon. The following procedure was therefore used to select sentences for inclusion in the database. First, sentences containing a string matching the surface form of a structural connective were extracted. These sentences were then parsed using a statistical parser (Charniak, 2000). Potential structural connectives were then classified on the basis of their syntactic context, in particular their proximity to S </context>
</contexts>
<marker>Hutchinson, 2004</marker>
<rawString>Ben Hutchinson. 2004. Mining the web for discourse markers. In Proceedings of the Fourth International Conference on Language Resources and Evaluation (LREC 2004), Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott</author>
<author>Robert Dale</author>
</authors>
<title>Using linguistic phenomena to motivate a set of coherence relations.</title>
<date>1994</date>
<booktitle>Discourse Processes,</booktitle>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="6517" citStr="Knott and Dale, 1994" startWordPosition="1030" endWordPosition="1033">larity discourse relation, it need not. Discourse markers like and are said to have the feature polarity=POS-POL. 1 On 1An alternative view is that discourse markers like and are underspecified with respect to polarity (Knott, 1996). In this the other hand, a NEG-POL discourse marker like but always co-occurs with a negative polarity discourse relation. The gold standard classes of POS-POL and NEGPOL discourse markers used in the learning experiments are shown in Table 1. The gold standards for all three experiments were compiled by consulting a range of previous classifications (Knott, 1996; Knott and Dale, 1994; Louwerse, 2001). 2 POS-POL NEG-POL after, and, as, as soon as, although, because, before, considering but, even if, that, ever since, for, given that, even though, if, in case, in order that, in that, even when, insofar as, now, now that, on only if, only the grounds that, once, seeing when, or, or as, since, so, so that, the in- else, though, stant, the moment, then, to the unless, until, extent that, when, whenever whereas, yet Table 1: Discourse markers used in the polarity experiment 2.2 Veridicality A discourse relation is veridical if it implies the truth of both its arguments (Asher a</context>
</contexts>
<marker>Knott, Dale, 1994</marker>
<rawString>Alistair Knott and Robert Dale. 1994. Using linguistic phenomena to motivate a set of coherence relations. Discourse Processes, 18(1):35–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alistair Knott</author>
</authors>
<title>A data-driven methodology for motivating a set of coherence relations.</title>
<date>1996</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="2373" citStr="Knott (1996)" startWordPosition="358" endWordPosition="359"> al. (2003)), this paper aims at a broad scale classification of a subclass of discourse markers: structural connectives. This breadth of coverage is of particular importance for discourse parsing, where a wide range of linguistic realisations must be catered for. This work can be seen as orthogonal to that of Di Eugenio et al. (1997), which addresses the problem of learning if and where discourse markers should be generated. Unfortunately, the manual classification of large numbers of discourse markers has proven to be a difficult task, and no complete classification yet exists. For example, Knott (1996) presents a list of around 350 discourse markers, but his taxonomic classification, perhaps the largest classification in the literature, accounts for only around 150 of these. A general method of automatically classifying discourse markers would therefore be of great utility, both for English and for languages with fewer manually created resources. This paper constitutes a step in that direction. It attempts to classify discourse markers whose classes are already known, and this allows the classifier to be evaluated empirically. The proposed task of learning automatically the meaning of disco</context>
<context position="4784" citStr="Knott, 1996" startWordPosition="738" endWordPosition="739">Examples of discourse markers are given in Tables 1, 2 and 3. In this paper we will focus on a subclass of discourse markers known as structural connectives. These markers, even though they may be multiword expressions, function syntactically as if they were coordinating or subordinating conjunctions (Webber et al., 2003). The literature contains many different classifications of discourse markers, drawing upon a wide range of evidence including textual cohesion (Halliday and Hasan, 1976), hypotactic conjunctions (Martin, 1992), cognitive plausibility (Sanders et al., 1992), substitutability (Knott, 1996), and psycholinguistic experiments (Louwerse, 2001). Nevertheless there is also considerable agreement. Three dimensions of classification that recur, albeit under a variety of names, are polarity, veridicality and type. We now discuss each of these in turn. 2.1 Polarity Many discourse markers signal a concession, a contrast or the denial of an expectation. These markers have been described as having the feature polarity=NEG-POL. An example is given in (1). (1) Suzy’s part-time, but she does more work than the rest of us put together. (Taken from Knott (1996, p. 185)) This sentence is true if </context>
<context position="6129" citStr="Knott, 1996" startWordPosition="967" endWordPosition="968"> signalling that the fact Suzy does more work is surprising — it denies an expectation. A similar effect can be obtained by using the connective and and adding more context, as in (2) (2) Suzy’s efficiency is astounding. She’s part-time, and she does more work than the rest of us put together. The difference is that although it is possible for and to co-occur with a negative polarity discourse relation, it need not. Discourse markers like and are said to have the feature polarity=POS-POL. 1 On 1An alternative view is that discourse markers like and are underspecified with respect to polarity (Knott, 1996). In this the other hand, a NEG-POL discourse marker like but always co-occurs with a negative polarity discourse relation. The gold standard classes of POS-POL and NEGPOL discourse markers used in the learning experiments are shown in Table 1. The gold standards for all three experiments were compiled by consulting a range of previous classifications (Knott, 1996; Knott and Dale, 1994; Louwerse, 2001). 2 POS-POL NEG-POL after, and, as, as soon as, although, because, before, considering but, even if, that, ever since, for, given that, even though, if, in case, in order that, in that, even when</context>
<context position="14988" citStr="Knott (1996)" startWordPosition="2424" endWordPosition="2425">e) and consequent (main) clauses linked by if. We also recorded the presence of other discourse markers in the two clauses, as these had previously 3For coordinating conjunctions, the left clause was taken to be superordinate/main clause, the right, the subordinate clause. New label Penn Treebank labels vb vb vbd vbg vbn vbp vbz nn nn nns nnp jj jj jjrjjs rb rb rbr rbs aux aux auxg md prp prp prp$ in in Table 4: Clustering of POS labels been found to be useful on a related classification task (Hutchinson, 2003). The discourse markers used for this are based on the list of 350 markers given by Knott (1996), and include multiword expressions. Due to the sparser nature of discourse markers, compared to verbs for example, no frequency cutoffs were used. 4.1.2 Linguistically motivated features These included a range of one and two dimensional features representing more abstract linguistic information, and were extracted through automatic analysis of the parse trees. One dimensional features Two one dimensional features recorded the location of discourse markers. POSITION indicated whether a discourse marker occurred between the clauses it linked, or before both of them. It thus relates to informati</context>
</contexts>
<marker>Knott, 1996</marker>
<rawString>Alistair Knott. 1996. A data-driven methodology for motivating a set of coherence relations. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mirella Lapata</author>
<author>Alex Lascarides</author>
</authors>
<title>Inferring sentence-internal temporal relations. In</title>
<date>2004</date>
<booktitle>In Proceedings of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics Annual Meeting,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="13706" citStr="Lapata and Lascarides, 2004" startWordPosition="2202" endWordPosition="2206">The results are presented in Section 4.3. 4.1 Features used We only used structural connectives in the experiments. This meant that the clauses linked syntactically were also related at the discourse level (Webber et al., 2003). Two types of features were extracted from the conjoined clauses. Firstly, we used lexical co-occurrences with words of various parts of speech. Secondly, we used a range of linguistically motivated syntactic, semantic, and discourse features. 4.1.1 Lexical co-occurrences Lexical co-occurrences have previously been shown to be useful for discourse level learning tasks (Lapata and Lascarides, 2004; Marcu and Echihabi, 2002). For each discourse marker, the words occurring in their superordinate (main) and subordinate clauses were recorded,3 along with their parts of speech. We manually clustered the Penn Treebank parts of speech together to obtain coarser grained syntactic categories, as shown in Table 4. We then lemmatised each word and excluded all lemmas with a frequency of less than 1000 per million in the BNC. Finally, words were attached a prefix of either SUB or SUPER according to whether they occurred in the sub- or superordinate clause linked by the marker. This distinguished, </context>
</contexts>
<marker>Lapata, Lascarides, 2004</marker>
<rawString>Mirella Lapata and Alex Lascarides. 2004. Inferring sentence-internal temporal relations. In In Proceedings of the Human Language Technology Conference and the North American Chapter of the Association for Computational Linguistics Annual Meeting, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alex Lascarides</author>
<author>Nicholas Asher</author>
</authors>
<title>Temporal interpretation, discourse relations and common sense entailment.</title>
<date>1993</date>
<journal>Linguistics and Philosophy,</journal>
<volume>16</volume>
<issue>5</issue>
<pages>493</pages>
<contexts>
<context position="10077" citStr="Lascarides and Asher, 1993" startWordPosition="1620" endWordPosition="1623"> arrived. If the relation a discourse marker signals is neither CAUSAL or TEMPORAL it has the feature type=ADDITIVE. The need for a distinct class of TEMPORAL discourse relations is disputed in the literature. On the one hand, it has been suggested that TEMPORAL relations are a subclass of ADDITIVE ones on the grounds that the temporal reference inherent in the marking of tense and aspect “more or less” fixes the temporal ordering of events (Sanders et al., 1992). This contrasts with arguments that resolving discourse relations and temporal order occur as distinct but inter-related processes (Lascarides and Asher, 1993). On the other hand, several of the discourse markers we count as TEMPORAL, such as as soon as, might be described as CAUSAL (Oberlander and Knott, 1995). One of the results of the experiments described below is that corpus evidence suggests ADDITIVE, TEMPORAL and CAUSAL discourse markers have distinct distributions. The ADDITIVE, TEMPORAL and CAUSAL discourse markers used in the learning experiments are shown in Table 3. These features are independent of the previous ones, for example even though is CAUSAL, VERIDICAL and NEG-POL. ADDITIVE TEMPORAL CAUSAL and, but, after, as although, because,</context>
</contexts>
<marker>Lascarides, Asher, 1993</marker>
<rawString>Alex Lascarides and Nicholas Asher. 1993. Temporal interpretation, discourse relations and common sense entailment. Linguistics and Philosophy, 16(5):437– 493.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lillian Lee</author>
</authors>
<title>On the effectiveness of the skew divergence for statistical language analysis.</title>
<date>2001</date>
<journal>Artificial Intelligence and Statistics,</journal>
<pages>65--72</pages>
<contexts>
<context position="19168" citStr="Lee, 2001" startWordPosition="3103" endWordPosition="3104">SIVE: either YES or NO; TENSE: either PAST or PRESENT. 4.2 Classifier architectures Two different classifiers, based on local and global methods of comparison, were used in the experiments. The first, 1 Nearest Neighbour (1NN), is an instance based classifier which assigns each marker to the same class as that of the marker nearest to it. For this, three different distance metrics were explored. The first metric was the Euclidean distance function , shown in (6), applied to probability distributions. The second, , is a smoothed variant of the information theoretic Kullback-Leibner divergence (Lee, 2001, with ). Its definition is given in (7). The third metric, , is a-test weighted adaption of the Jaccard coefficient (Curran and Moens, 2002). In it basic form, the Jaccard coefficient is essentially a measure of how much two distributions overlap. The-test variant weights co-occurrences by the strength of their collocation, using the following function: This is then used define the weighted version of the Jaccard coefficient, as shown in (8). The words associated with distributions and are indicated by and , respectively. and had previously been found to be the best metrics for other tasks in</context>
</contexts>
<marker>Lee, 2001</marker>
<rawString>Lillian Lee. 2001. On the effectiveness of the skew divergence for statistical language analysis. Artificial Intelligence and Statistics, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Max M Louwerse</author>
</authors>
<title>An analytic and cognitive parameterization of coherence relations.</title>
<date>2001</date>
<journal>Cognitive Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="4835" citStr="Louwerse, 2001" startWordPosition="743" endWordPosition="745">s 1, 2 and 3. In this paper we will focus on a subclass of discourse markers known as structural connectives. These markers, even though they may be multiword expressions, function syntactically as if they were coordinating or subordinating conjunctions (Webber et al., 2003). The literature contains many different classifications of discourse markers, drawing upon a wide range of evidence including textual cohesion (Halliday and Hasan, 1976), hypotactic conjunctions (Martin, 1992), cognitive plausibility (Sanders et al., 1992), substitutability (Knott, 1996), and psycholinguistic experiments (Louwerse, 2001). Nevertheless there is also considerable agreement. Three dimensions of classification that recur, albeit under a variety of names, are polarity, veridicality and type. We now discuss each of these in turn. 2.1 Polarity Many discourse markers signal a concession, a contrast or the denial of an expectation. These markers have been described as having the feature polarity=NEG-POL. An example is given in (1). (1) Suzy’s part-time, but she does more work than the rest of us put together. (Taken from Knott (1996, p. 185)) This sentence is true if and only if Suzy both is parttime and does more wor</context>
<context position="6534" citStr="Louwerse, 2001" startWordPosition="1034" endWordPosition="1035">ion, it need not. Discourse markers like and are said to have the feature polarity=POS-POL. 1 On 1An alternative view is that discourse markers like and are underspecified with respect to polarity (Knott, 1996). In this the other hand, a NEG-POL discourse marker like but always co-occurs with a negative polarity discourse relation. The gold standard classes of POS-POL and NEGPOL discourse markers used in the learning experiments are shown in Table 1. The gold standards for all three experiments were compiled by consulting a range of previous classifications (Knott, 1996; Knott and Dale, 1994; Louwerse, 2001). 2 POS-POL NEG-POL after, and, as, as soon as, although, because, before, considering but, even if, that, ever since, for, given that, even though, if, in case, in order that, in that, even when, insofar as, now, now that, on only if, only the grounds that, once, seeing when, or, or as, since, so, so that, the in- else, though, stant, the moment, then, to the unless, until, extent that, when, whenever whereas, yet Table 1: Discourse markers used in the polarity experiment 2.2 Veridicality A discourse relation is veridical if it implies the truth of both its arguments (Asher and Lascarides, 20</context>
</contexts>
<marker>Louwerse, 2001</marker>
<rawString>Max M Louwerse. 2001. An analytic and cognitive parameterization of coherence relations. Cognitive Linguistics, 12(3):291–315.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>George Wilson</author>
</authors>
<title>Robust temporal processing of news.</title>
<date>2000</date>
<booktitle>In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL</booktitle>
<pages>69--76</pages>
<location>New Brunswick, New Jersey.</location>
<contexts>
<context position="16775" citStr="Mani and Wilson, 2000" startWordPosition="2703" endWordPosition="2706">gation using four features. NEG-SUBJ and NEGVERB indicated the presence of subject negation (e.g. nothing) or verbal negation (e.g. n’t). We also recorded the occurrence of a set of negative polarity items (NPI), such as any and ever. The features NPI-AND-NEG and NPI-WO-NEG indicated whether an NPI occurred in a clause with or without verbal or subject negation. Eventualities can be placed or ordered in time using not just discourse markers but also temporal expressions. The feature TEMPEX recorded the number of temporal expressions in each clause, as returned by a temporal expression tagger (Mani and Wilson, 2000). If the main verb was an inflection of to be or to do we recorded this using the features BE and DO. Our motivation was to capture any correlation of these verbs with states and events respectively. If the final verb was a modal auxiliary, this ellipsis was evidence of strong cohesion in the text (Halliday and Hasan, 1976). We recorded this with the feature VP-ELLIPSIS. Pronouns also indicate cohesion, and have been shown to correlate with subjectivity (Bestgen et al., 2003). A class of features PRONOUNS represented pronouns, with denoting either 1st person, 2nd person, or 3rd person animate,</context>
</contexts>
<marker>Mani, Wilson, 2000</marker>
<rawString>Inderjeet Mani and George Wilson. 2000. Robust temporal processing of news. In Proceedings of the 38th Annual Meeting of the Association for Computational Linguistics (ACL 2000), pages 69–76, New Brunswick, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>Abdessamad Echihabi</author>
</authors>
<title>An unsupervised approach to recognizing discourse relations.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL2002),</booktitle>
<location>Philadelphia, PA.</location>
<contexts>
<context position="1339" citStr="Marcu and Echihabi, 2002" startWordPosition="194" endWordPosition="197">s upon which there is substantial agreement in the literature: polarity, veridicality and type. This approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999). Discourse markers signal relations between discourse units. As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002). In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998). It follows that a detailed account of the semantics and pragmatics of discourse markers would be a useful resource for natural language processing. Rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. Bestgen et al. (2003)), this paper aims at a broad scale classification of a subclass of discourse markers: structural connectives. This breadth of coverage is of particular importance for</context>
<context position="13733" citStr="Marcu and Echihabi, 2002" startWordPosition="2207" endWordPosition="2210">Section 4.3. 4.1 Features used We only used structural connectives in the experiments. This meant that the clauses linked syntactically were also related at the discourse level (Webber et al., 2003). Two types of features were extracted from the conjoined clauses. Firstly, we used lexical co-occurrences with words of various parts of speech. Secondly, we used a range of linguistically motivated syntactic, semantic, and discourse features. 4.1.1 Lexical co-occurrences Lexical co-occurrences have previously been shown to be useful for discourse level learning tasks (Lapata and Lascarides, 2004; Marcu and Echihabi, 2002). For each discourse marker, the words occurring in their superordinate (main) and subordinate clauses were recorded,3 along with their parts of speech. We manually clustered the Penn Treebank parts of speech together to obtain coarser grained syntactic categories, as shown in Table 4. We then lemmatised each word and excluded all lemmas with a frequency of less than 1000 per million in the BNC. Finally, words were attached a prefix of either SUB or SUPER according to whether they occurred in the sub- or superordinate clause linked by the marker. This distinguished, for example, between occurr</context>
</contexts>
<marker>Marcu, Echihabi, 2002</marker>
<rawString>Daniel Marcu and Abdessamad Echihabi. 2002. An unsupervised approach to recognizing discourse relations. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics (ACL2002), Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
</authors>
<title>The Theory and Practice of Discourse Parsing and Summarization.</title>
<date>2000</date>
<booktitle>English Text: System</booktitle>
<publisher>The MIT Press. Jim</publisher>
<location>Amsterdam.</location>
<contexts>
<context position="1191" citStr="Marcu, 2000" startWordPosition="175" endWordPosition="176">arkers. By considering the distributions of individual tokens of discourse markers, we classify discourse markers along three dimensions upon which there is substantial agreement in the literature: polarity, veridicality and type. This approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999). Discourse markers signal relations between discourse units. As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002). In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998). It follows that a detailed account of the semantics and pragmatics of discourse markers would be a useful resource for natural language processing. Rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. Bestgen et al. (2003)), this paper aims </context>
</contexts>
<marker>Marcu, 2000</marker>
<rawString>Daniel Marcu. 2000. The Theory and Practice of Discourse Parsing and Summarization. The MIT Press. Jim Martin. 1992. English Text: System and Structure. Benjamin, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moser</author>
<author>J Moore</author>
</authors>
<title>Using discourse analysis and automatic text generation to study discourse cue usage.</title>
<date>1995</date>
<booktitle>In Proceedings of the AAAI 1995 Spring Symposium on Empirical Methods in Discourse Interpretation and Generation,</booktitle>
<pages>92--98</pages>
<contexts>
<context position="1484" citStr="Moser and Moore, 1995" startWordPosition="214" endWordPosition="217">distribution of linguistic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999). Discourse markers signal relations between discourse units. As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002). In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998). It follows that a detailed account of the semantics and pragmatics of discourse markers would be a useful resource for natural language processing. Rather than looking at the finer subtleties in meaning of particular discourse markers (e.g. Bestgen et al. (2003)), this paper aims at a broad scale classification of a subclass of discourse markers: structural connectives. This breadth of coverage is of particular importance for discourse parsing, where a wide range of linguistic realisations must be catered for. This work can be seen as orthogonal to that of Di Eugenio </context>
</contexts>
<marker>Moser, Moore, 1995</marker>
<rawString>M. Moser and J. Moore. 1995. Using discourse analysis and automatic text generation to study discourse cue usage. In Proceedings of the AAAI 1995 Spring Symposium on Empirical Methods in Discourse Interpretation and Generation, pages 92–98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Oberlander</author>
<author>Alistair Knott</author>
</authors>
<title>Issues in cue phrase implicature.</title>
<date>1995</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation.</booktitle>
<contexts>
<context position="10230" citStr="Oberlander and Knott, 1995" startWordPosition="1648" endWordPosition="1652">PORAL discourse relations is disputed in the literature. On the one hand, it has been suggested that TEMPORAL relations are a subclass of ADDITIVE ones on the grounds that the temporal reference inherent in the marking of tense and aspect “more or less” fixes the temporal ordering of events (Sanders et al., 1992). This contrasts with arguments that resolving discourse relations and temporal order occur as distinct but inter-related processes (Lascarides and Asher, 1993). On the other hand, several of the discourse markers we count as TEMPORAL, such as as soon as, might be described as CAUSAL (Oberlander and Knott, 1995). One of the results of the experiments described below is that corpus evidence suggests ADDITIVE, TEMPORAL and CAUSAL discourse markers have distinct distributions. The ADDITIVE, TEMPORAL and CAUSAL discourse markers used in the learning experiments are shown in Table 3. These features are independent of the previous ones, for example even though is CAUSAL, VERIDICAL and NEG-POL. ADDITIVE TEMPORAL CAUSAL and, but, after, as although, because, whereas soon as, even though, for, given before, that, if, if ever, in case, ever on condition that, on since, the assumption that, now, now on the grou</context>
</contexts>
<marker>Oberlander, Knott, 1995</marker>
<rawString>Jon Oberlander and Alistair Knott. 1995. Issues in cue phrase implicature. In Proceedings of the AAAI Spring Symposium on Empirical Methods in Discourse Interpretation and Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted J M Sanders</author>
<author>W P M Spooren</author>
<author>L G M Noordman</author>
</authors>
<title>Towards a taxonomy of coherence relations.</title>
<date>1992</date>
<booktitle>Discourse Processes,</booktitle>
<pages>15--1</pages>
<contexts>
<context position="4752" citStr="Sanders et al., 1992" startWordPosition="733" endWordPosition="736">een propositions, events or speech acts. Examples of discourse markers are given in Tables 1, 2 and 3. In this paper we will focus on a subclass of discourse markers known as structural connectives. These markers, even though they may be multiword expressions, function syntactically as if they were coordinating or subordinating conjunctions (Webber et al., 2003). The literature contains many different classifications of discourse markers, drawing upon a wide range of evidence including textual cohesion (Halliday and Hasan, 1976), hypotactic conjunctions (Martin, 1992), cognitive plausibility (Sanders et al., 1992), substitutability (Knott, 1996), and psycholinguistic experiments (Louwerse, 2001). Nevertheless there is also considerable agreement. Three dimensions of classification that recur, albeit under a variety of names, are polarity, veridicality and type. We now discuss each of these in turn. 2.1 Polarity Many discourse markers signal a concession, a contrast or the denial of an expectation. These markers have been described as having the feature polarity=NEG-POL. An example is given in (1). (1) Suzy’s part-time, but she does more work than the rest of us put together. (Taken from Knott (1996, p.</context>
<context position="9917" citStr="Sanders et al., 1992" startWordPosition="1598" endWordPosition="1601">n also supply a causal relation even when a TEMPORAL discourse marker is used, as in (5). (5) The tension in the boardroom rose sharply after the chairman arrived. If the relation a discourse marker signals is neither CAUSAL or TEMPORAL it has the feature type=ADDITIVE. The need for a distinct class of TEMPORAL discourse relations is disputed in the literature. On the one hand, it has been suggested that TEMPORAL relations are a subclass of ADDITIVE ones on the grounds that the temporal reference inherent in the marking of tense and aspect “more or less” fixes the temporal ordering of events (Sanders et al., 1992). This contrasts with arguments that resolving discourse relations and temporal order occur as distinct but inter-related processes (Lascarides and Asher, 1993). On the other hand, several of the discourse markers we count as TEMPORAL, such as as soon as, might be described as CAUSAL (Oberlander and Knott, 1995). One of the results of the experiments described below is that corpus evidence suggests ADDITIVE, TEMPORAL and CAUSAL discourse markers have distinct distributions. The ADDITIVE, TEMPORAL and CAUSAL discourse markers used in the learning experiments are shown in Table 3. These features</context>
</contexts>
<marker>Sanders, Spooren, Noordman, 1992</marker>
<rawString>Ted J. M. Sanders, W. P. M. Spooren, and L. G. M. Noordman. 1992. Towards a taxonomy of coherence relations. Discourse Processes, 15:1–35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Suzanne Stevenson</author>
<author>Paola Merlo</author>
</authors>
<title>Automatic verb classification using distributions of grammatical features.</title>
<date>1999</date>
<booktitle>In Proceedings of the 9th Conference of the European Chapter of the ACL,</booktitle>
<pages>45--52</pages>
<location>Bergen,</location>
<contexts>
<context position="1000" citStr="Stevenson and Merlo (1999)" startWordPosition="144" endWordPosition="147">causal, temporal or additive). Accuracy of over 90% is achieved for all three tasks, well above the baselines. 1 Introduction This paper is concerned with automatically acquiring the meaning of discourse markers. By considering the distributions of individual tokens of discourse markers, we classify discourse markers along three dimensions upon which there is substantial agreement in the literature: polarity, veridicality and type. This approach of classifying linguistic types by the distribution of linguistic tokens makes this research similar in spirit to that of Baldwin and Bond (2003) and Stevenson and Merlo (1999). Discourse markers signal relations between discourse units. As such, discourse markers play an important role in the parsing of natural language discourse (Forbes et al., 2001; Marcu, 2000), and their correspondence with discourse relations can be exploited for the unsupervised learning of discourse relations (Marcu and Echihabi, 2002). In addition, generating natural language discourse requires the appropriate selection and placement of discourse markers (Moser and Moore, 1995; Grote and Stede, 1998). It follows that a detailed account of the semantics and pragmatics of discourse markers wo</context>
</contexts>
<marker>Stevenson, Merlo, 1999</marker>
<rawString>Suzanne Stevenson and Paola Merlo. 1999. Automatic verb classification using distributions of grammatical features. In Proceedings of the 9th Conference of the European Chapter of the ACL, pages 45–52, Bergen, Norway.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bonnie Webber</author>
<author>Matthew Stone</author>
<author>Aravind Joshi</author>
<author>Alistair Knott</author>
</authors>
<title>Anaphora and discourse structure.</title>
<date>2003</date>
<journal>Computational Linguistics,</journal>
<volume>29</volume>
<issue>4</issue>
<contexts>
<context position="4495" citStr="Webber et al., 2003" startWordPosition="697" endWordPosition="700">scribe our experiments, including choice of features. The results are presented in Section 5. Finally, we conclude and discuss future work in Section 6. 2 Discourse markers Discourse markers are lexical items (possibly multiword) that signal relations between propositions, events or speech acts. Examples of discourse markers are given in Tables 1, 2 and 3. In this paper we will focus on a subclass of discourse markers known as structural connectives. These markers, even though they may be multiword expressions, function syntactically as if they were coordinating or subordinating conjunctions (Webber et al., 2003). The literature contains many different classifications of discourse markers, drawing upon a wide range of evidence including textual cohesion (Halliday and Hasan, 1976), hypotactic conjunctions (Martin, 1992), cognitive plausibility (Sanders et al., 1992), substitutability (Knott, 1996), and psycholinguistic experiments (Louwerse, 2001). Nevertheless there is also considerable agreement. Three dimensions of classification that recur, albeit under a variety of names, are polarity, veridicality and type. We now discuss each of these in turn. 2.1 Polarity Many discourse markers signal a concess</context>
<context position="13306" citStr="Webber et al., 2003" startWordPosition="2143" endWordPosition="2147">number of instances was 32,770, while the median was 4,948. 4 Experiments This section presents three machine learning experiments into automatically classifying discourse markers according to their polarity, veridicality and type. We begin in Section 4.1 by describing the features we extract for each discourse marker token. Then in Section 4.2 we describe the different classifiers we use. The results are presented in Section 4.3. 4.1 Features used We only used structural connectives in the experiments. This meant that the clauses linked syntactically were also related at the discourse level (Webber et al., 2003). Two types of features were extracted from the conjoined clauses. Firstly, we used lexical co-occurrences with words of various parts of speech. Secondly, we used a range of linguistically motivated syntactic, semantic, and discourse features. 4.1.1 Lexical co-occurrences Lexical co-occurrences have previously been shown to be useful for discourse level learning tasks (Lapata and Lascarides, 2004; Marcu and Echihabi, 2002). For each discourse marker, the words occurring in their superordinate (main) and subordinate clauses were recorded,3 along with their parts of speech. We manually clustere</context>
</contexts>
<marker>Webber, Stone, Joshi, Knott, 2003</marker>
<rawString>Bonnie Webber, Matthew Stone, Aravind Joshi, and Alistair Knott. 2003. Anaphora and discourse structure. Computational Linguistics, 29(4):545–588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Eibe Frank</author>
</authors>
<title>Data Mining: Practical machine learning tools with Java implementations.</title>
<date>2000</date>
<publisher>Morgan Kaufmann,</publisher>
<location>San Francisco.</location>
<contexts>
<context position="20099" citStr="Witten and Frank, 2000" startWordPosition="3253" endWordPosition="3256">their collocation, using the following function: This is then used define the weighted version of the Jaccard coefficient, as shown in (8). The words associated with distributions and are indicated by and , respectively. and had previously been found to be the best metrics for other tasks involving lexical similarity. is included to indicate what can be achieved using a somewhat naive metric. The second classifier used, Naive Bayes, takes the overall distribution of each class into account. It essentially defines a decision boundary in the form of a curved hyperplane. The Weka implementation (Witten and Frank, 2000) was used for the experiments, with 10-fold cross-validation. 4.3 Results We began by comparing the performance of the 1NN classifier using the various lexical cooccurrence features against the gold standards. The results using all lexical co-occurrences are shown Task Baseline All POS Best Best single POS subset polarity 67.4 74.4 72.1 74.4 76.7 (rb) 83.7 (rb) 76.7 (rb) 83.7 veridicality 73.5 81.6 85.7 75.5 83.7 (nn) 91.8 (vb) 87.8 (vb) 91.8 type 58.1 74.2 64.5 81.8 74.2 (in) 74.2 (rb) 77.4 (jj) 87.8 Using and either rb or DMs+rb.Using both and vb, and and vb+in.Using and vb+aux+in Table 5: R</context>
</contexts>
<marker>Witten, Frank, 2000</marker>
<rawString>Ian H. Witten and Eibe Frank. 2000. Data Mining: Practical machine learning tools with Java implementations. Morgan Kaufmann, San Francisco.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>