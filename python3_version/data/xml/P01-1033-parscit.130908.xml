<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.924576">
Towards Abstract Categorial Grammars
</title>
<note confidence="0.5269255">
Philippe de Groote
LORIA UMR n° 7503 – INRIA
</note>
<address confidence="0.566855">
Campus Scientifique, B.P. 239
54506 Vandcruvre l`es Nancy Cedex – France
</address>
<email confidence="0.993415">
degroote@loria.fr
</email>
<sectionHeader confidence="0.993693" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999151">
We introduce a new categorial formal-
ism based on intuitionistic linear logic.
This formalism, which derives from
current type-logical grammars, is ab-
stract in the sense that both syntax and
semantics are handled by the same set
of primitives. As a consequence, the
formalism is reversible and provides
different computational paradigms that
may be freely composed together.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999777666666667">
Type-logical grammars offer a clear cut between
syntax and semantics. On the one hand, lexical
items are assigned syntactic categories that com-
bine via a categorial logic akin to the Lambek cal-
culus (Lambek, 1958). On the other hand, we
have so-called semantic recipes, which are ex-
pressed as typed A-terms. The syntax-semantics
interface takes advantage of the Curry-Howard
correspondence, which allows semantic readings
to be extracted from categorial deductions (van
Benthem, 1986). These readings rely upon a
homomorphism between the syntactic categories
and the semantic types.
The distinction between syntax and semantics
is of course relevant from a linguistic point of
view. This does not mean, however, that it must
be wired into the computational model. On the
contrary, a computational model based on a small
set of primitives that combine via simple compo-
sition rules will be more flexible in practice and
easier to implement.
In the type-logical approach, the syntactic con-
tents of a lexical entry is outlined by the following
patern:
</bodyText>
<equation confidence="0.731031">
&lt;atom&gt; : &lt;syntactic category&gt;
</equation>
<bodyText confidence="0.82602275">
On the other hand, the semantic contents obeys
the following scheme:
&lt;A-term&gt; : &lt;semantic type&gt;
This asymmetry may be broken by:
</bodyText>
<listItem confidence="0.898798333333333">
1. allowing A-terms on the syntactic side
(atomic expressions being, after all, partic-
ular cases of A-terms),
2. using the same type theory for expressing
both the syntactic categories and the seman-
tic types.
</listItem>
<bodyText confidence="0.9795026">
The first point is a powerfull generalization of
the usual scheme. It allows A-terms to be used
at a syntactic level, which is an approach that
has been advocated by (Oehrle, 1994). The sec-
ond point may be satisfied by dropping the non-
commutative (and non-associative) aspects of cat-
egorial logics. This implies that, contrarily to
the usual categorial approaches, word order con-
straints cannot be expressed at the logical level.
As we will see this apparent loss in expressive
power is compensated by the first point.
2 Definition of a multiplicative kernel
In this section, we define an elementary gram-
matical formalism based on the ideas presented
in the introduction. This elementary formalism is
founded on the multiplicative fragment of linear
logic (Girard, 1987). For this reason, we call it
a multiplicative kernel. Possible extensions based
on other fragments of linear logic are discussed in
Section 5.
</bodyText>
<subsectionHeader confidence="0.892494">
2.1 Types, signature, and A-terms
</subsectionHeader>
<bodyText confidence="0.734461">
We first introduce the mathematical apparatus that
is needed in order to define our notion of an ab-
stract categorial grammar.
3. α E T (A).
The axioms and inference rules are the following:
</bodyText>
<equation confidence="0.797639">
−Σ c : τ(c) (cons)
</equation>
<bodyText confidence="0.984849666666667">
Let A be a set of atomic types. The set T (A)
of linear implicative types built upon A is induc-
tively defined as follows:
</bodyText>
<listItem confidence="0.764297">
1. if a E A, then a E T (A);
2. if α, β E T (A), then (α −o β) E T (A).
</listItem>
<bodyText confidence="0.872149333333333">
We now introduce the notion of a higher-order
linear signature. It consists of a triple Σ =
(A, C, τ), where:
</bodyText>
<listItem confidence="0.995213">
1. A is a finite set of atomic types;
2. C is a finite set of constants;
3. τ : C —* T (A) is a function that assigns to
each constant in C a linear implicative type
in T (A).
</listItem>
<bodyText confidence="0.99660025">
Let X be a infinite countable set of λ-variables.
The set Λ(Σ) of linear λ-terms built upon a
higher-order linear signature Σ = (A, C, τ) is in-
ductively defined as follows:
</bodyText>
<listItem confidence="0.996794166666667">
1. if c E C, then c E Λ(Σ);
2. if x E X, then x E Λ(Σ);
3. if x E X, t E Λ(Σ), and x occurs free in t
exactly once, then (λx. t) E Λ(Σ);
4. if t, u E Λ(Σ), and the sets of free variables
of t and u are disjoint, then (t u) E Λ(Σ).
</listItem>
<bodyText confidence="0.961409875">
Λ(Σ) is provided with the usual notion of cap-
ture avoiding substitution, α-conversion, and β-
reduction (Barendregt, 1984).
Given a higher-order linear signature Σ =
(A, C, τ), each linear λ-term in Λ(Σ) may be as-
signed a linear implicative type in T (A). This
type assignment obeys an inference system whose
judgements are sequents of the following form:
</bodyText>
<equation confidence="0.765855">
Γ −Σ t : α
</equation>
<bodyText confidence="0.570836">
where:
</bodyText>
<listItem confidence="0.9974276">
1. Γ is a finite set of λ-variable typing declara-
tions of the form ‘x : β’ (with x E X and
β E T (A)), such that any λ-variable is de-
clared at most once;
2. t E Λ(Σ);
</listItem>
<equation confidence="0.9943648">
x : α −Σ x : α (var)
Γ, x : α −Σ t : β
(abs)
Γ −Σ (λx. t) : (α −o β)
Γ, Δ −Σ (t u) : β (app)
</equation>
<subsectionHeader confidence="0.4095305">
2.2 Vocabulary, lexicon, grammar, and
language
</subsectionHeader>
<bodyText confidence="0.999362777777778">
We now introduce the abstract notions of a vocab-
ulary and a lexicon, on which the central notion of
an abstract categorial grammar is based.
A vocabulary is simply defined to be a higher-
order linear signature.
Given two vocabularies Σ1 = (A1, C1, τ1) and
Σ2 = (A2,C2,τ2), a lexicon L from Σ1 to Σ2
(in notation, L : Σ1 —* Σ2) is defined to be a
pair L = (F, G) such that:
</bodyText>
<listItem confidence="0.984096777777778">
1. F : A1 —* T (A2) is a function that inter-
prets the atomic types of Σ1 as linear im-
plicative types built upon A2;
2. G : C1 —* Λ(Σ2) is a function that interprets
the constants of Σ1 as linear λ-terms built
upon Σ2;
3. the interpretation functions are compatible
with the typing relation, i.e., for any c E C1,
the following typing judgement is derivable:
</listItem>
<equation confidence="0.478403">
−Σ2 G(c) : Fˆ(τ1(c)),
</equation>
<bodyText confidence="0.999855444444445">
where Fˆ is the unique homomorphic exten-
sion of F.
As stated in Clause 3 of the above defini-
tion, there exists a unique type homomorphism
Fˆ : T (A1) —* T (A2) that extends F. Simi-
larly, there exists a unique λ-term homomorphism
Gˆ : Λ(Σ1) —* Λ(Σ2) that extends G. In the se-
quel, when ‘L ’ will denote a lexicon, it will also
denote the homorphisms Fˆ and Gˆ induced by this
</bodyText>
<equation confidence="0.949702">
Γ −Σ t : (α −o β) Δ −Σ u : α
</equation>
<bodyText confidence="0.995293625">
lexicon. In any case, the intended meaning will
be clear from the context.
Condition 3, in the above definition of a lexi-
con, is necessary and sufficient to ensure that the
homomorphisms induced by a lexicon commute
with the typing relations. In other terms, for any
lexicon L : E1 → E2 and any derivable judge-
ment
</bodyText>
<equation confidence="0.992957">
x0 : α0, ... , xn : αn −Σ1 t : α
the following judgement
x0: L (α0), ... , xn : L (αn) −Σ2 L (t): L (α)
</equation>
<bodyText confidence="0.998441125">
is derivable. This property, which is reminis-
cent of Montague’s homomorphism requirement
(Montague, 1970b), may be seen as an abstract
realization of the compositionality principle.
We are now in a position of giving the defini-
tion of an abstract categorial grammar.
An abstract categorial grammar (ACG) is a
quadruple G = hE1, E2, L , si where:
</bodyText>
<listItem confidence="0.996055666666666">
1. E1 = hA1, C1, τ1i and E2 = hA2, C2, τ2i
are two higher-order linear signatures; E1
is called the abstract vovabulary and E2 is
called the object vovabulary;
2. L : E1 → E2 is a lexicon from the abstract
vovabulary to the object vovabulary;
3. s ∈ T (A1) is a type of the abstract vocabu-
lary; it is called the distinguished type of the
grammar.
</listItem>
<bodyText confidence="0.997994105263158">
Any ACG generates two languages, an abstract
language and an object language. The abstract
language generated by G (A(G )) is defined as
follows:
A(G ) = {t ∈ A(E1)  |−Σ1 t: s is derivable}
In words, the abstract language generated by G
is the set of closed linear λ-terms, built upon the
abstract vocabulary E1, whose type is the distin-
guished type s. On the other hand, the object lan-
guage generated by G (O(G )) is defined to be the
image of the abstract language by the term homo-
morphism induced by the lexicon L :
O(G ) = {t ∈ A(E2)  |∃u ∈ A(G ). t = L (u)}
It may be useful of thinking of the abstract lan-
guage as a set of abstract grammatical structures,
and of the object language as the set of concrete
forms generated from these abstract structures.
Section 4 provides examples of ACGs that illus-
trate this interpretation.
</bodyText>
<subsectionHeader confidence="0.993459">
2.3 Example
</subsectionHeader>
<bodyText confidence="0.99924875">
In order to exemplify the concepts introduced so
far, we demonstrate how to accomodate the PTQ
fragment of Montague (1973). We concentrate on
Montague’s famous sentence:
</bodyText>
<subsectionHeader confidence="0.702952">
John seeks a unicorn (1)
</subsectionHeader>
<bodyText confidence="0.9972555">
For the purpose of the example, we make the two
following assumptions:
</bodyText>
<listItem confidence="0.869358">
1. the formalism provides an atomic type
‘string’ together with a binary associative
operator ‘+’ (that we write as an infix op-
erator for the sake of readability);
2. we have the usual logical connectives and
quantifiers at our disposal.
</listItem>
<bodyText confidence="0.999634">
We will see in Section 4 and 5 that these two as-
sumptions, in fact, are not needed.
In order to handle the syntactic part of the ex-
ample, we define an ACG (G12). The first step
consists in defining the two following vocabular-
ies:
</bodyText>
<equation confidence="0.971480571428571">
E1 = h {n, np, s}, {J, Sre, Sdicto, A, U},
{J 7→ np, Sre 7→ (np −◦ (np −◦ s)),
Sdicto 7→ (np −◦ (np −◦ s)),
A 7→ (n −◦ np), U 7→ n} i
E2 = h {string}, {John, seeks, a, unicorn},
{John 7→ string, seeks 7→ string,
a 7→ string, unicorn 7→ string} i
</equation>
<bodyText confidence="0.993518">
Then, we define a lexicon L12 from the abstract
vocabulary E1 to the object vocabulary E2:
</bodyText>
<equation confidence="0.673256">
L12 = h {n 7→ string, np 7→ string,
s 7→ string},
{J 7→ John,
Sre 7→ λx. λy. x + seeks + y,
Sdicto 7→ λx. λy. x + seeks + y,
A 7→ λx. a + x,
U 7→ unicorn} i
</equation>
<bodyText confidence="0.9882514">
Finally we have G12 = hE1, E2, L12, si.
The semantic part of the example is handled by
another ACG (G13), which shares with G12 the
same abstract language. The object language of
this second ACG is defined as follows:
</bodyText>
<equation confidence="0.755742052631579">
E3 = h {e, t},
{JOHN, TRY-TO, FIND, UNICORN},
{JOHN 7→ e,
TRY-TO 7→ (e −◦ ((e −◦ t) −◦ t)),
FIND 7→ (e −◦ (e −◦ t)),
UNICORN 7→ (e −◦ t)} i
Then, a lexicon from E1 to E3 is defined:
L13 = h {n 7→ (e −◦ t), np 7→ ((e −◦ t) −◦ t),
s 7→ t},
{J 7→ AP. P JOHN,
Sre 7→
AP. AQ. Q (Ax. P
(Ay. TRY-TO y (Az. FIND z x))),
Sdicto 7→
AP. AQ. P
(Ax. TRY-TO x
(Ay. Q (Az. FIND y z))),
A 7→ AP. AQ. ∃x. P x ∧ Q x,
U 7→ Ax. UNICORN x} i
</equation>
<bodyText confidence="0.965318875">
This allows the ACG G13 to be defined as
hE1, E3, L13, si.
The abstract language shared by G12 and G13
contains the two following terms:
Sre J (A U) (2) Sdicto J (A U) (3)
The syntactic lexicon L12 applied to each of these
terms yields the same image. It 0-reduces to the
following object term:
</bodyText>
<equation confidence="0.547662">
John + seeks + a + unicorn
</equation>
<bodyText confidence="0.918561923076923">
On the other hand, the semantic lexicon L13
yields the de re reading when applied to (2):
∃x. UNICORN x ∧ TRY-TO JOHN (Az. FIND z x)
and it yields the de dicto reading when applied to
(3):
TRY-TO JOHN (Ay. ∃x. UNICORN x ∧ FIND y x)
Our handling of the two possible readings
of (1) differs from the type-logical account of
Morrill (1994) and Carpenter (1996). The main
difference is that our abstract vocabulary con-
tains two constants corresponding to seek. Con-
sequently, we have two distinct entries in the se-
mantic lexicon, one for each possible reading.
This is only a matter of choice. We could have
adopt Morrill’s solution (which is closer to Mon-
tague original analysis) by having only one ab-
stract constant S together with the following type
assignment:
S 7→ (np −◦ (((np −◦ s) −◦ s) −◦ s))
Then the types of J and A, and the two lexicons
should be changed accordingly. The semantic lex-
icon of this alternative solution would be simpler.
The syntactic lexicon, however, would be more
involved, with entries such as:
S 7→ Ax. Ay. x + seeks + y (Az. z)
A 7→ Ax. Ay. y (a + x)
</bodyText>
<sectionHeader confidence="0.975643" genericHeader="method">
3 Three computational paradigms
</sectionHeader>
<bodyText confidence="0.999908238095238">
Compositional semantics associates meanings to
utterances by assigning meanings to atomic items,
and by giving rules that allows to compute the
meaning of a compound unit from the meanings
of its parts. In the type logical approach, follow-
ing the Montagovian tradition, meanings are ex-
pressed as typed A-terms and combine via func-
tional application.
Dalrymple et al. (1995) offer an alternative to
this applicative paradigm. They present a deduc-
tive approach in which linear logic is used as a
glue language for assembling meanings. Their
approach is more in the tradition of logic pro-
gramming.
The grammatical framework introduced in the
previous section realizes the compositionality
principle in a abstract way. Indeed, it provides
compositional means to associate the terms of
a given language to the terms of some other
language. Both the applicative and deductive
paradigms are available.
</bodyText>
<subsectionHeader confidence="0.9982">
3.1 Applicative paradigm
</subsectionHeader>
<bodyText confidence="0.999871333333333">
In our framework, the applicative paradigm con-
sists simply in computing, according to the lex-
icon of a given grammar, the object image of
an abstract term. From a computational point of
view it amounts to performing substitution and 0-
reduction.
</bodyText>
<subsectionHeader confidence="0.998686">
3.2 Deductive paradigm
</subsectionHeader>
<bodyText confidence="0.999909666666667">
The deductive paradigm, in our setting, answers
the following problem: does a given term, built
upon the object vocabulary of an ACG, belong
to the object language of this ACG. It amounts
to a kind of proof-search that has been de-
scribed by Merenciano and Morrill (1997) and by
Pogodalla (2000). This proof-search relies on lin-
ear higher-order matching, which is a decidable
problem (de Groote, 2000).
</bodyText>
<subsectionHeader confidence="0.997605">
3.3 Transductive paradigm
</subsectionHeader>
<bodyText confidence="0.999987333333333">
The example developped in Section 2.3 suggests
a third paradigm, which is obtained as the com-
position of the applicative paradigm with the de-
ductive paradigm. We call it the transductive
paradigm because it is reminiscent of the math-
ematical notion of transduction (see Section 4.2).
This paradigm amounts to the transfer from one
object language to another object language, using
a common abstract language as a pivot.
</bodyText>
<sectionHeader confidence="0.9197845" genericHeader="method">
4 Relating ACGs to other grammatical
formalisms
</sectionHeader>
<bodyText confidence="0.99994244">
In this section, we illustrate the expressive power
of ACGs by showing how some other families of
formal grammars may be subsumed. It must be
stressed that we are not only interested in a weak
form of correspondence, where only the gener-
ated languages are equivalent, but in a strong form
of correspondence, where the grammatical struc-
tures are preserved.
First of all, we must explain how ACGs may
manipulate strings of symbols. In other words,
we must show how to encode strings as linear A-
terms. The solution is well known: it suffices
to represent strings of symbols as compositions
of functions. Consider an arbitrary atomic type
*, and define the type ‘string’ to be (* −o *).
Then, a string such as ‘abbac’ may be repre-
sented by the linear A-term Ax. a (b (b (a (c x)))),
where the atomic strings ‘a’, ‘b’, and ‘c’ are
declared to be constants of type (* −o *). In
this setting, the empty word (E) is represented
by the identity function (Ax. x) and concatena-
tion (+) is defined to be functional composition
(Af. Ag. Ax. f (g x)), which is indeed an associa-
tive operator that admits the identity function as a
unit.
</bodyText>
<subsectionHeader confidence="0.987397">
4.1 Context-free grammars
</subsectionHeader>
<bodyText confidence="0.999892777777778">
Let G = (T, N, P, 5) be a context-free grammar,
where T is the set of terminal symbols, N is the
set of non-terminal symbol, P is the set of rules,
and 5 is the start symbol. We write L(G) for the
language generated by G. We show how to con-
struct an ACG WG = (E1, E2, Y, 5) correspond-
ing to G.
The abstract vocabulary E1 = (A1, C1, 7-1) is
defined as follows:
</bodyText>
<listItem confidence="0.995413833333333">
1. The set of atomic types A1 is defined to be
the set of non-terminal symbols N.
2. The set of constants C1 is a set of symbols in
1-1-correspondence with the set of rules P.
3. Let c E C1 and let ‘X —* w’ be the rule cor-
responding to c. 7-1 is defined to be the func-
tion that assigns the type [[w]]X to c, where
[[·]]X obeys the following inductive defini-
tion:
(a) [[E]]X = X;
(b) [[Yw]]X = (Y −o [[w]]X), for Y E N;
(c) [[aw]]X = [[w]]X, for a E T.
</listItem>
<bodyText confidence="0.991961">
The definition of the object vocabulary E2 =
(A2, C2, 7-2) is as follows:
</bodyText>
<listItem confidence="0.968490333333333">
1. A2 is defined to be {*}.
2. The set of constants C2 is defined to be the
set of terminal symbols T.
3. 7-2 is defined to be the function that assigns
the type ‘string’ to each c E C2.
It remains to define the lexicon Y = (F, G):
1. F is defined to be the function that interprets
each atomic type a E A1 as the type ‘string’.
2. Let c E C1 and let ‘X —* w’ be
the rule corresponding to c. G is de-
fined to be the function that interprets c as
Ax1 .... Axn. JwJ, where x1 ... xn is the se-
quence of A-variables occurring in JwJ, and
J · J is inductively defined as follows:
(a) JEJ = Ax. x;
(b) JY wJ = y + JwJ, for Y E N, and where
y is a fresh A-variable;
(c) |aω |= a + |ω|, for a ∈ T.
</listItem>
<bodyText confidence="0.761803">
It is then easy to prove that GG is such that:
</bodyText>
<listItem confidence="0.619817">
1. the abstract language A(GG) is isomorphic
to the set of parse-trees of G.
2. the language generated by G coincides with
the object language of GG, i.e., O(GG) =
L(G).
</listItem>
<bodyText confidence="0.992884">
For instance consider the CFG whose produc-
tion rules are the following:
</bodyText>
<equation confidence="0.7750565">
S → E,
S → aSb,
</equation>
<bodyText confidence="0.999351666666667">
which generates the language anbn. The cor-
responding ACG has the following abstract lan-
guage, object language, and lexicon:
</bodyText>
<equation confidence="0.921193333333333">
E1 = h {S}, {A, B},
{A 7→ S,B 7→ ((S −◦ S)} i
E2 = h {∗}, {a, b},
{a 7→ string, b 7→ string} i
L = h {S 7→ string},
{A 7→ λx. x,B 7→ λx. a + x + b} i
</equation>
<subsectionHeader confidence="0.9587475">
4.2 Regular grammars and rational
transducers
</subsectionHeader>
<bodyText confidence="0.999944277777778">
Regular grammars being particular cases of
context-free grammars, they may be handled by
the same construction. The resulting ACGs
(which we will call “regular ACGs” for the pur-
pose of the discussion) may be seen as finite state
automata. The abstract language of a regular
ACG correspond then to the set of accepting se-
quences of transitions of the corresponding au-
tomaton, and its object language to the accepted
language.
More interestingly, rational transducers may
also be accomodated. Indeed, two regular ACGs
that shares the same abstract language correspond
to a regular language homomorphism composed
with a regular language inverse homomorphism.
Now, after Nivat’s theorem (Nivat, 1968), any ra-
tional transducer may be represented as such a bi-
morphism.
</bodyText>
<subsectionHeader confidence="0.998743">
4.3 Tree adjoining grammars
</subsectionHeader>
<bodyText confidence="0.999706">
The construction that allows to handle the tree
adjoining grammars of Joshi (Joshi and Schabes,
1997) may be seen as a generalization of the con-
struction that we have described for the context-
free grammars. Nevertheless, it is a little bit more
involved. For instance, it is necessary to triplicate
the non-terminal symbols in order to distinguish
the initial trees from the auxiliary trees.
We do not have enough room in this paper for
giving the details of the construction. We will
rather give an example. Consider the TAG with
the following initial tree and auxiliary tree:
</bodyText>
<figure confidence="0.889793833333333">
SNA
S \ \
a S �������
E �������
b S� c
NA
</figure>
<bodyText confidence="0.770525333333333">
It generates the non context-free language
anbncndn. This TAG may be represented by the
ACG, G = hE1, E2, L , Si, where:
</bodyText>
<table confidence="0.24464575">
E1 = h {S, S&apos;, S&apos;&apos;}, {A, B, C},
{A 7→ ((S&apos;&apos; −◦ S&apos;) −◦ S),
B 7→ (S&apos;&apos; −◦ ((S&apos;&apos; −◦ S&apos;) −◦ S&apos;)),
C 7→ (S&apos;&apos; −◦ S&apos;)} i
</table>
<equation confidence="0.944530125">
E2 = h {∗}, {a, b, c, d},
{a 7→ string, b 7→ string,
c 7→ string, d 7→ string} i
L = h {S 7→ string, S&apos; 7→ string,
S&apos;&apos; 7→ string},
{A 7→ λf. f (λx. x),
B 7→ λx. λg. a + g (b + x + c) + d,
C 7→ λx. x} i
</equation>
<bodyText confidence="0.9999684">
One of the keystones in the above translation is
to represent an adjunction node A as a functional
parameter of type A&apos;&apos; −◦ A&apos;. Abrusci et al. (1999)
use a similar idea in their translation of the TAGs
into non-commutative linear logic.
</bodyText>
<sectionHeader confidence="0.905448" genericHeader="method">
5 Beyond the multiplicative fragment
</sectionHeader>
<bodyText confidence="0.99863395">
The linear λ-calculus on which we have based
our definition of an ACG may be seen as a rudi-
mentary functional programming language. The
results in Section 4 indicate that, in theory, this
d
rudimentary language is powerful enough. Never-
theless, in practice, it would be useful to increase
the expressive power of the multiplicative kernel
defined in Section 2 by providing features such
as records, enumerated types, conditional expres-
sions, etc.
From a methodological point of view, there is
a systematic way of considering such extensions.
It consists of enriching the type system of the
formalism with new logical connectives. Indeed,
each new logical connective may be interpreted,
through the Curry-Howard isomorphism, as anew
type constructor. Nonetheless, the possible addi-
tional connectives must satisfy the following re-
quirements:
</bodyText>
<listItem confidence="0.775453">
1. they must be provided with introduction and
elimination rules that satisfy Prawitz’s inver-
sion principle (Prawitz, 1965) and the result-
ing system must be strongly normalizable;
2. the resulting term language (or at least an in-
teresting fragment of it) must have a decid-
able matching problem.
</listItem>
<bodyText confidence="0.999982307692308">
The first requirement ensures that the new types
come with appropriate data constructors and dis-
criminators, and that the associated evaluation
rule terminates. This is mandatory for the applica-
tive paradigm of Section 3. The second require-
ment ensures that the deductive paradigm (and
consequently the transductive paradigm) may be
fully automated.
The other connectives of linear logic are natural
candidates for extending the formalism. In partic-
ular, they all satisfy the first requirement. On the
other hand, the satisfaction of the second require-
ment is, in most of the cases, an open problem.
</bodyText>
<subsectionHeader confidence="0.917463">
5.1 Additives
</subsectionHeader>
<bodyText confidence="0.999937666666667">
The additive connectives of linear logic ‘&amp;’ and
‘®’ corresponds respectively to the cartesian
product and the disjoint union. The cartesian
product allows records to be defined. The dis-
joint union, together with the unit type ‘1’, al-
lows enumerated types and case analysis to be
defined. Consequently, the additive connectives
offer a good theoretical ground to provide ACG
with feature structures.
</bodyText>
<subsectionHeader confidence="0.964468">
5.2 Exponentials
</subsectionHeader>
<bodyText confidence="0.991459333333333">
The exponentials of linear logic are modal oper-
ators that may be used to go beyond linearity. In
particular, the exponential ‘!’ allows the intuition-
istic implication ‘—*’ to be defined, which cor-
responds to the possibility of dealing with non-
linear λ-terms. A need for such non-linear λ-
terms is already present in the example of Sec-
tion 2.3. Indeed, the way of getting rid of the
second assumption we made at the beginning of
section 2.3 is to declare the logical symbols (i.e.,
the existential quantifier and the conjunction that
occurs in the interpretation of A in Lexicon L13)
as constants of the object vocabulary E3. Then,
the interpretation of A would be something like:
λP. λQ. EXISTS (λx. AND (P x) (Q x)).
Now, this expression must be typable, which is
not possible in a purely linear framework. Indeed,
the λ-term to which EXISTS is applied is not linear
(there are two occurrences of the bound variable
x). Consequently, EXISTS must be given ((e —*
t) −o t) as a type.
</bodyText>
<subsectionHeader confidence="0.98604">
5.3 Quantifiers
</subsectionHeader>
<bodyText confidence="0.9992924">
Quantifiers may also play a part. Uses of first-
order quantification, in a type logical setting, are
exemplified by Morrill (1994), Moortgat (1997),
and Ranta (1994). As for second-order quantifi-
cation, it allows for polymorphism.
</bodyText>
<sectionHeader confidence="0.975628" genericHeader="method">
6 Grammars as first-class citizen
</sectionHeader>
<bodyText confidence="0.9999933">
The difference we make between an abstract vo-
cabulary and an object vocabulary is purely con-
ceptual. In fact, it only makes sense relatively to
a given lexicon. Indeed, from a technical point
of view, any vocabulary is simply a higher-order
linear signature. Consequently, one may think of
a lexicon L12 : E1 —* E2 whose object lan-
guage serves as abstract language of another lex-
icon L23 : E2 —* E3. This allows lexicons to be
sequentially composed. Moreover, one may eas-
ily construct a third lexicon L13 : E1 —* E3 that
corresponds to the sequential composition of L23
with L12. From a practical point of view, this
means that the sequential composition of two lex-
icons may be compiled. From a theoretical point
of view, it means that the ACGs form a category
whose objects are vocabularies and whose arrows
are lexicons. This opens the door to a theory
where operations for constructing new grammars
from other grammars could be defined.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999955857142857">
This paper presents the first steps towards the de-
sign of a powerful grammatical framework based
on a small set of computational primitives. The
fact that these primitives are well known from
programming theory renders the framework suit-
able for an implementation. A first prototype is
currently under development.
</bodyText>
<sectionHeader confidence="0.999435" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999884225352113">
M. Abrusci, C. Fouquer´e, and J. Vauzeilles. 1999.
Tree-adjoining grammars in a fragment of the
Lambek calculus. Computational Linguistics,
25(2):209–236.
H.P. Barendregt. 1984. The lambda calculus, its syn-
tax and semantics. North-Holland, revised edition.
J. van Benthem. 1986. Essays in Logical Semantics.
Reidel, Dordrecht.
B. Carpenter. 1996. Type-Logical Semantics. MIT
Press, Cambridge, Massachussetts and London
England.
M. Dalrymple, M. Lamping, F. Pereira, and
V. Saraswat. 1995. Linear logic for meaning as-
sembly. In G. Morrill and D. Oehrle, editors, For-
mal Grammar, pages 75–93. FoLLI.
J.-Y. Girard. 1987. Linear logic. Theoretical Com-
puter Science, 50:1–102.
Ph. de Groote. 2000. Linear higher-order matching
is NP-complete. In L. Bachmair, editor, Rewriting
Techniques and Applications, RTA’00, volume 1833
of Lecture Notes in Computer Science, pages 127–
140. Springer.
A. K. Joshi and Y. Schabes. 1997. Tree-adjoining
grammars. In G. Rozenberg an A. Salomaa, editor,
Handbook of formal languages, volume 3, chap-
ter 2. Springer.
J. Lambek. 1958. The mathematics of sentence struc-
ture. Amer. Math. Monthly, 65:154–170.
J. M. Merenciano and G. Morrill. 1997. Generation as
deduction on labelled proof nets. In C. Retor´e, ed-
itor, Logical Aspects of Computational Linguistics,
LACL’96, volume 1328 of Lecture Notes in Artifi-
cialIntelligence, pages 310–328. Springer Verlag.
R. Montague. 1970a. English as a formal language.
In B. Visentini et al., editor, Linguaggi nella So-
ciet`a e nella Tecnica, Milan. Edizioni di Commu-
nit`a. Reprinted: (Montague, 1974, pages 188–221).
R. Montague. 1970b. Universal grammar. Theoria,
36:373–398. Reprinted: (Montague, 1974, pages
222–246).
R. Montague. 1973. The proper treatment of quan-
tification in ordinary english. In J. Hintikka,
J. Moravcsik, and P. Suppes, editors, Approaches to
natural language: proceedings of the 1970 Stanford
workshop on Grammar and Semantics, Dordrecht.
Reidel. Reprinted: (Montague, 1974, pages 247–
270).
R. Montague. 1974. Formal Philosophy: selected pa-
pers ofRichard Montague, edited and with an intro-
duction by Richmond Thomason. Yale University
Press.
M. Moortgat. 1997. Categorial type logic. In J. van
Benthem and A. ter Meulen, editors, Handbook of
Logic and Language, chapter 2. Elsevier.
G. Morrill. 1994. Type Logical Grammar: Catego-
rial Logic of Signs. Kluwer Academic Publishers,
Dordrecht.
M. Nivat. 1968. Transduction des langages de Chom-
sky. Annales de l’Institut Fourier, 18:339–455.
R. T. Oehrle. 1994. Term-labeled categorial type sys-
tems. Linguistic &amp; Philosophy, 17:633–678.
S. Pogodalla. 2000. Generation, Lambek Calculus,
Montague’s Semantics and Semantic Proof Nets. In
Proceedings of the 18th International Conference
on Computational Linguistics, volume 2, pages
628–634.
D. Prawitz. 1965. Natural Deduction, A Proof-
Theoretical Study. Almqvist &amp; Wiksell, Stock-
holm.
A. Ranta. 1994. Type theoretical grammar. Oxford
University Press.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.951279">
<title confidence="0.999727">Towards Abstract Categorial Grammars</title>
<author confidence="0.994283">Philippe de_Groote</author>
<affiliation confidence="0.99676">UMR – INRIA</affiliation>
<address confidence="0.992718">Campus Scientifique, B.P. 239 54506 Vandcruvre l`es Nancy Cedex – France</address>
<email confidence="0.998534">degroote@loria.fr</email>
<abstract confidence="0.997310727272727">We introduce a new categorial formalism based on intuitionistic linear logic. This formalism, which derives from current type-logical grammars, is abstract in the sense that both syntax and semantics are handled by the same set of primitives. As a consequence, the formalism is reversible and provides different computational paradigms that may be freely composed together.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Abrusci</author>
<author>C Fouquer´e</author>
<author>J Vauzeilles</author>
</authors>
<title>Tree-adjoining grammars in a fragment of the Lambek calculus.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>2</issue>
<marker>Abrusci, Fouquer´e, Vauzeilles, 1999</marker>
<rawString>M. Abrusci, C. Fouquer´e, and J. Vauzeilles. 1999. Tree-adjoining grammars in a fragment of the Lambek calculus. Computational Linguistics, 25(2):209–236.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Barendregt</author>
</authors>
<title>The lambda calculus, its syntax and semantics. North-Holland, revised edition.</title>
<date>1984</date>
<contexts>
<context position="4150" citStr="Barendregt, 1984" startWordPosition="722" endWordPosition="723">T (A) is a function that assigns to each constant in C a linear implicative type in T (A). Let X be a infinite countable set of λ-variables. The set Λ(Σ) of linear λ-terms built upon a higher-order linear signature Σ = (A, C, τ) is inductively defined as follows: 1. if c E C, then c E Λ(Σ); 2. if x E X, then x E Λ(Σ); 3. if x E X, t E Λ(Σ), and x occurs free in t exactly once, then (λx. t) E Λ(Σ); 4. if t, u E Λ(Σ), and the sets of free variables of t and u are disjoint, then (t u) E Λ(Σ). Λ(Σ) is provided with the usual notion of capture avoiding substitution, α-conversion, and β- reduction (Barendregt, 1984). Given a higher-order linear signature Σ = (A, C, τ), each linear λ-term in Λ(Σ) may be assigned a linear implicative type in T (A). This type assignment obeys an inference system whose judgements are sequents of the following form: Γ −Σ t : α where: 1. Γ is a finite set of λ-variable typing declarations of the form ‘x : β’ (with x E X and β E T (A)), such that any λ-variable is declared at most once; 2. t E Λ(Σ); x : α −Σ x : α (var) Γ, x : α −Σ t : β (abs) Γ −Σ (λx. t) : (α −o β) Γ, Δ −Σ (t u) : β (app) 2.2 Vocabulary, lexicon, grammar, and language We now introduce the abstract notions of </context>
</contexts>
<marker>Barendregt, 1984</marker>
<rawString>H.P. Barendregt. 1984. The lambda calculus, its syntax and semantics. North-Holland, revised edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J van Benthem</author>
</authors>
<title>Essays in Logical Semantics.</title>
<date>1986</date>
<location>Reidel, Dordrecht.</location>
<marker>van Benthem, 1986</marker>
<rawString>J. van Benthem. 1986. Essays in Logical Semantics. Reidel, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Carpenter</author>
</authors>
<title>Type-Logical Semantics.</title>
<date>1996</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachussetts and London England.</location>
<contexts>
<context position="10366" citStr="Carpenter (1996)" startWordPosition="1981" endWordPosition="1982">abstract language shared by G12 and G13 contains the two following terms: Sre J (A U) (2) Sdicto J (A U) (3) The syntactic lexicon L12 applied to each of these terms yields the same image. It 0-reduces to the following object term: John + seeks + a + unicorn On the other hand, the semantic lexicon L13 yields the de re reading when applied to (2): ∃x. UNICORN x ∧ TRY-TO JOHN (Az. FIND z x) and it yields the de dicto reading when applied to (3): TRY-TO JOHN (Ay. ∃x. UNICORN x ∧ FIND y x) Our handling of the two possible readings of (1) differs from the type-logical account of Morrill (1994) and Carpenter (1996). The main difference is that our abstract vocabulary contains two constants corresponding to seek. Consequently, we have two distinct entries in the semantic lexicon, one for each possible reading. This is only a matter of choice. We could have adopt Morrill’s solution (which is closer to Montague original analysis) by having only one abstract constant S together with the following type assignment: S 7→ (np −◦ (((np −◦ s) −◦ s) −◦ s)) Then the types of J and A, and the two lexicons should be changed accordingly. The semantic lexicon of this alternative solution would be simpler. The syntactic</context>
</contexts>
<marker>Carpenter, 1996</marker>
<rawString>B. Carpenter. 1996. Type-Logical Semantics. MIT Press, Cambridge, Massachussetts and London England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dalrymple</author>
<author>M Lamping</author>
<author>F Pereira</author>
<author>V Saraswat</author>
</authors>
<title>Linear logic for meaning assembly.</title>
<date>1995</date>
<booktitle>Formal Grammar,</booktitle>
<pages>75--93</pages>
<editor>In G. Morrill and D. Oehrle, editors,</editor>
<publisher>FoLLI.</publisher>
<contexts>
<context position="11494" citStr="Dalrymple et al. (1995)" startWordPosition="2177" endWordPosition="2180"> accordingly. The semantic lexicon of this alternative solution would be simpler. The syntactic lexicon, however, would be more involved, with entries such as: S 7→ Ax. Ay. x + seeks + y (Az. z) A 7→ Ax. Ay. y (a + x) 3 Three computational paradigms Compositional semantics associates meanings to utterances by assigning meanings to atomic items, and by giving rules that allows to compute the meaning of a compound unit from the meanings of its parts. In the type logical approach, following the Montagovian tradition, meanings are expressed as typed A-terms and combine via functional application. Dalrymple et al. (1995) offer an alternative to this applicative paradigm. They present a deductive approach in which linear logic is used as a glue language for assembling meanings. Their approach is more in the tradition of logic programming. The grammatical framework introduced in the previous section realizes the compositionality principle in a abstract way. Indeed, it provides compositional means to associate the terms of a given language to the terms of some other language. Both the applicative and deductive paradigms are available. 3.1 Applicative paradigm In our framework, the applicative paradigm consists s</context>
</contexts>
<marker>Dalrymple, Lamping, Pereira, Saraswat, 1995</marker>
<rawString>M. Dalrymple, M. Lamping, F. Pereira, and V. Saraswat. 1995. Linear logic for meaning assembly. In G. Morrill and D. Oehrle, editors, Formal Grammar, pages 75–93. FoLLI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-Y Girard</author>
</authors>
<title>Linear logic.</title>
<date>1987</date>
<journal>Theoretical Computer Science,</journal>
<pages>50--1</pages>
<contexts>
<context position="2757" citStr="Girard, 1987" startWordPosition="432" endWordPosition="433">cated by (Oehrle, 1994). The second point may be satisfied by dropping the noncommutative (and non-associative) aspects of categorial logics. This implies that, contrarily to the usual categorial approaches, word order constraints cannot be expressed at the logical level. As we will see this apparent loss in expressive power is compensated by the first point. 2 Definition of a multiplicative kernel In this section, we define an elementary grammatical formalism based on the ideas presented in the introduction. This elementary formalism is founded on the multiplicative fragment of linear logic (Girard, 1987). For this reason, we call it a multiplicative kernel. Possible extensions based on other fragments of linear logic are discussed in Section 5. 2.1 Types, signature, and A-terms We first introduce the mathematical apparatus that is needed in order to define our notion of an abstract categorial grammar. 3. α E T (A). The axioms and inference rules are the following: −Σ c : τ(c) (cons) Let A be a set of atomic types. The set T (A) of linear implicative types built upon A is inductively defined as follows: 1. if a E A, then a E T (A); 2. if α, β E T (A), then (α −o β) E T (A). We now introduce th</context>
</contexts>
<marker>Girard, 1987</marker>
<rawString>J.-Y. Girard. 1987. Linear logic. Theoretical Computer Science, 50:1–102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>de Groote</author>
</authors>
<title>Linear higher-order matching is NP-complete.</title>
<date>2000</date>
<booktitle>Rewriting Techniques and Applications, RTA’00,</booktitle>
<volume>1833</volume>
<pages>127--140</pages>
<editor>In L. Bachmair, editor,</editor>
<publisher>Springer.</publisher>
<marker>de Groote, 2000</marker>
<rawString>Ph. de Groote. 2000. Linear higher-order matching is NP-complete. In L. Bachmair, editor, Rewriting Techniques and Applications, RTA’00, volume 1833 of Lecture Notes in Computer Science, pages 127– 140. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>Y Schabes</author>
</authors>
<title>Tree-adjoining grammars.</title>
<date>1997</date>
<booktitle>Handbook of formal languages,</booktitle>
<volume>3</volume>
<editor>In G. Rozenberg an A. Salomaa, editor,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="17448" citStr="Joshi and Schabes, 1997" startWordPosition="3273" endWordPosition="3276">gular ACG correspond then to the set of accepting sequences of transitions of the corresponding automaton, and its object language to the accepted language. More interestingly, rational transducers may also be accomodated. Indeed, two regular ACGs that shares the same abstract language correspond to a regular language homomorphism composed with a regular language inverse homomorphism. Now, after Nivat’s theorem (Nivat, 1968), any rational transducer may be represented as such a bimorphism. 4.3 Tree adjoining grammars The construction that allows to handle the tree adjoining grammars of Joshi (Joshi and Schabes, 1997) may be seen as a generalization of the construction that we have described for the contextfree grammars. Nevertheless, it is a little bit more involved. For instance, it is necessary to triplicate the non-terminal symbols in order to distinguish the initial trees from the auxiliary trees. We do not have enough room in this paper for giving the details of the construction. We will rather give an example. Consider the TAG with the following initial tree and auxiliary tree: SNA S \ \ a S ������� E ������� b S� c NA It generates the non context-free language anbncndn. This TAG may be represented </context>
</contexts>
<marker>Joshi, Schabes, 1997</marker>
<rawString>A. K. Joshi and Y. Schabes. 1997. Tree-adjoining grammars. In G. Rozenberg an A. Salomaa, editor, Handbook of formal languages, volume 3, chapter 2. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lambek</author>
</authors>
<title>The mathematics of sentence structure.</title>
<date>1958</date>
<journal>Amer. Math. Monthly,</journal>
<pages>65--154</pages>
<contexts>
<context position="784" citStr="Lambek, 1958" startWordPosition="118" endWordPosition="119">r Abstract We introduce a new categorial formalism based on intuitionistic linear logic. This formalism, which derives from current type-logical grammars, is abstract in the sense that both syntax and semantics are handled by the same set of primitives. As a consequence, the formalism is reversible and provides different computational paradigms that may be freely composed together. 1 Introduction Type-logical grammars offer a clear cut between syntax and semantics. On the one hand, lexical items are assigned syntactic categories that combine via a categorial logic akin to the Lambek calculus (Lambek, 1958). On the other hand, we have so-called semantic recipes, which are expressed as typed A-terms. The syntax-semantics interface takes advantage of the Curry-Howard correspondence, which allows semantic readings to be extracted from categorial deductions (van Benthem, 1986). These readings rely upon a homomorphism between the syntactic categories and the semantic types. The distinction between syntax and semantics is of course relevant from a linguistic point of view. This does not mean, however, that it must be wired into the computational model. On the contrary, a computational model based on a</context>
</contexts>
<marker>Lambek, 1958</marker>
<rawString>J. Lambek. 1958. The mathematics of sentence structure. Amer. Math. Monthly, 65:154–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Merenciano</author>
<author>G Morrill</author>
</authors>
<title>Generation as deduction on labelled proof nets.</title>
<date>1997</date>
<booktitle>Logical Aspects of Computational Linguistics, LACL’96,</booktitle>
<volume>1328</volume>
<pages>310--328</pages>
<editor>In C. Retor´e, editor,</editor>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="12581" citStr="Merenciano and Morrill (1997)" startWordPosition="2352" endWordPosition="2355">ge. Both the applicative and deductive paradigms are available. 3.1 Applicative paradigm In our framework, the applicative paradigm consists simply in computing, according to the lexicon of a given grammar, the object image of an abstract term. From a computational point of view it amounts to performing substitution and 0- reduction. 3.2 Deductive paradigm The deductive paradigm, in our setting, answers the following problem: does a given term, built upon the object vocabulary of an ACG, belong to the object language of this ACG. It amounts to a kind of proof-search that has been described by Merenciano and Morrill (1997) and by Pogodalla (2000). This proof-search relies on linear higher-order matching, which is a decidable problem (de Groote, 2000). 3.3 Transductive paradigm The example developped in Section 2.3 suggests a third paradigm, which is obtained as the composition of the applicative paradigm with the deductive paradigm. We call it the transductive paradigm because it is reminiscent of the mathematical notion of transduction (see Section 4.2). This paradigm amounts to the transfer from one object language to another object language, using a common abstract language as a pivot. 4 Relating ACGs to oth</context>
</contexts>
<marker>Merenciano, Morrill, 1997</marker>
<rawString>J. M. Merenciano and G. Morrill. 1997. Generation as deduction on labelled proof nets. In C. Retor´e, editor, Logical Aspects of Computational Linguistics, LACL’96, volume 1328 of Lecture Notes in ArtificialIntelligence, pages 310–328. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Montague</author>
</authors>
<title>English as a formal language. In</title>
<date>1970</date>
<booktitle>Linguaggi nella Societ`a e nella Tecnica, Milan. Edizioni di Communit`a.</booktitle>
<pages>188--221</pages>
<editor>B. Visentini et al., editor,</editor>
<location>Reprinted: (Montague,</location>
<contexts>
<context position="6388" citStr="Montague, 1970" startWordPosition="1183" endWordPosition="1184">it will also denote the homorphisms Fˆ and Gˆ induced by this Γ −Σ t : (α −o β) Δ −Σ u : α lexicon. In any case, the intended meaning will be clear from the context. Condition 3, in the above definition of a lexicon, is necessary and sufficient to ensure that the homomorphisms induced by a lexicon commute with the typing relations. In other terms, for any lexicon L : E1 → E2 and any derivable judgement x0 : α0, ... , xn : αn −Σ1 t : α the following judgement x0: L (α0), ... , xn : L (αn) −Σ2 L (t): L (α) is derivable. This property, which is reminiscent of Montague’s homomorphism requirement (Montague, 1970b), may be seen as an abstract realization of the compositionality principle. We are now in a position of giving the definition of an abstract categorial grammar. An abstract categorial grammar (ACG) is a quadruple G = hE1, E2, L , si where: 1. E1 = hA1, C1, τ1i and E2 = hA2, C2, τ2i are two higher-order linear signatures; E1 is called the abstract vovabulary and E2 is called the object vovabulary; 2. L : E1 → E2 is a lexicon from the abstract vovabulary to the object vovabulary; 3. s ∈ T (A1) is a type of the abstract vocabulary; it is called the distinguished type of the grammar. Any ACG gen</context>
</contexts>
<marker>Montague, 1970</marker>
<rawString>R. Montague. 1970a. English as a formal language. In B. Visentini et al., editor, Linguaggi nella Societ`a e nella Tecnica, Milan. Edizioni di Communit`a. Reprinted: (Montague, 1974, pages 188–221).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Montague</author>
</authors>
<date>1970</date>
<tech>Universal grammar. Theoria, 36:373–398.</tech>
<pages>222--246</pages>
<location>Reprinted: (Montague,</location>
<contexts>
<context position="6388" citStr="Montague, 1970" startWordPosition="1183" endWordPosition="1184">it will also denote the homorphisms Fˆ and Gˆ induced by this Γ −Σ t : (α −o β) Δ −Σ u : α lexicon. In any case, the intended meaning will be clear from the context. Condition 3, in the above definition of a lexicon, is necessary and sufficient to ensure that the homomorphisms induced by a lexicon commute with the typing relations. In other terms, for any lexicon L : E1 → E2 and any derivable judgement x0 : α0, ... , xn : αn −Σ1 t : α the following judgement x0: L (α0), ... , xn : L (αn) −Σ2 L (t): L (α) is derivable. This property, which is reminiscent of Montague’s homomorphism requirement (Montague, 1970b), may be seen as an abstract realization of the compositionality principle. We are now in a position of giving the definition of an abstract categorial grammar. An abstract categorial grammar (ACG) is a quadruple G = hE1, E2, L , si where: 1. E1 = hA1, C1, τ1i and E2 = hA2, C2, τ2i are two higher-order linear signatures; E1 is called the abstract vovabulary and E2 is called the object vovabulary; 2. L : E1 → E2 is a lexicon from the abstract vovabulary to the object vovabulary; 3. s ∈ T (A1) is a type of the abstract vocabulary; it is called the distinguished type of the grammar. Any ACG gen</context>
</contexts>
<marker>Montague, 1970</marker>
<rawString>R. Montague. 1970b. Universal grammar. Theoria, 36:373–398. Reprinted: (Montague, 1974, pages 222–246).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Montague</author>
</authors>
<title>The proper treatment of quantification in ordinary english.</title>
<date>1973</date>
<booktitle>Approaches to natural language: proceedings of the 1970 Stanford workshop on Grammar and Semantics,</booktitle>
<pages>247--270</pages>
<editor>In J. Hintikka, J. Moravcsik, and P. Suppes, editors,</editor>
<location>Dordrecht. Reidel. Reprinted: (Montague,</location>
<contexts>
<context position="7942" citStr="Montague (1973)" startWordPosition="1474" endWordPosition="1475">. On the other hand, the object language generated by G (O(G )) is defined to be the image of the abstract language by the term homomorphism induced by the lexicon L : O(G ) = {t ∈ A(E2) |∃u ∈ A(G ). t = L (u)} It may be useful of thinking of the abstract language as a set of abstract grammatical structures, and of the object language as the set of concrete forms generated from these abstract structures. Section 4 provides examples of ACGs that illustrate this interpretation. 2.3 Example In order to exemplify the concepts introduced so far, we demonstrate how to accomodate the PTQ fragment of Montague (1973). We concentrate on Montague’s famous sentence: John seeks a unicorn (1) For the purpose of the example, we make the two following assumptions: 1. the formalism provides an atomic type ‘string’ together with a binary associative operator ‘+’ (that we write as an infix operator for the sake of readability); 2. we have the usual logical connectives and quantifiers at our disposal. We will see in Section 4 and 5 that these two assumptions, in fact, are not needed. In order to handle the syntactic part of the example, we define an ACG (G12). The first step consists in defining the two following vo</context>
</contexts>
<marker>Montague, 1973</marker>
<rawString>R. Montague. 1973. The proper treatment of quantification in ordinary english. In J. Hintikka, J. Moravcsik, and P. Suppes, editors, Approaches to natural language: proceedings of the 1970 Stanford workshop on Grammar and Semantics, Dordrecht. Reidel. Reprinted: (Montague, 1974, pages 247– 270).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Montague</author>
</authors>
<title>Formal Philosophy: selected papers ofRichard Montague, edited and with an introduction by Richmond Thomason.</title>
<date>1974</date>
<publisher>Yale University Press.</publisher>
<marker>Montague, 1974</marker>
<rawString>R. Montague. 1974. Formal Philosophy: selected papers ofRichard Montague, edited and with an introduction by Richmond Thomason. Yale University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Moortgat</author>
</authors>
<title>Categorial type logic.</title>
<date>1997</date>
<booktitle>Handbook of Logic and Language, chapter 2.</booktitle>
<editor>In J. van Benthem and A. ter Meulen, editors,</editor>
<publisher>Elsevier.</publisher>
<contexts>
<context position="21989" citStr="Moortgat (1997)" startWordPosition="4064" endWordPosition="4065">at occurs in the interpretation of A in Lexicon L13) as constants of the object vocabulary E3. Then, the interpretation of A would be something like: λP. λQ. EXISTS (λx. AND (P x) (Q x)). Now, this expression must be typable, which is not possible in a purely linear framework. Indeed, the λ-term to which EXISTS is applied is not linear (there are two occurrences of the bound variable x). Consequently, EXISTS must be given ((e —* t) −o t) as a type. 5.3 Quantifiers Quantifiers may also play a part. Uses of firstorder quantification, in a type logical setting, are exemplified by Morrill (1994), Moortgat (1997), and Ranta (1994). As for second-order quantification, it allows for polymorphism. 6 Grammars as first-class citizen The difference we make between an abstract vocabulary and an object vocabulary is purely conceptual. In fact, it only makes sense relatively to a given lexicon. Indeed, from a technical point of view, any vocabulary is simply a higher-order linear signature. Consequently, one may think of a lexicon L12 : E1 —* E2 whose object language serves as abstract language of another lexicon L23 : E2 —* E3. This allows lexicons to be sequentially composed. Moreover, one may easily constru</context>
</contexts>
<marker>Moortgat, 1997</marker>
<rawString>M. Moortgat. 1997. Categorial type logic. In J. van Benthem and A. ter Meulen, editors, Handbook of Logic and Language, chapter 2. Elsevier.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Morrill</author>
</authors>
<title>Type Logical Grammar: Categorial Logic of Signs.</title>
<date>1994</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="10345" citStr="Morrill (1994)" startWordPosition="1978" endWordPosition="1979">, E3, L13, si. The abstract language shared by G12 and G13 contains the two following terms: Sre J (A U) (2) Sdicto J (A U) (3) The syntactic lexicon L12 applied to each of these terms yields the same image. It 0-reduces to the following object term: John + seeks + a + unicorn On the other hand, the semantic lexicon L13 yields the de re reading when applied to (2): ∃x. UNICORN x ∧ TRY-TO JOHN (Az. FIND z x) and it yields the de dicto reading when applied to (3): TRY-TO JOHN (Ay. ∃x. UNICORN x ∧ FIND y x) Our handling of the two possible readings of (1) differs from the type-logical account of Morrill (1994) and Carpenter (1996). The main difference is that our abstract vocabulary contains two constants corresponding to seek. Consequently, we have two distinct entries in the semantic lexicon, one for each possible reading. This is only a matter of choice. We could have adopt Morrill’s solution (which is closer to Montague original analysis) by having only one abstract constant S together with the following type assignment: S 7→ (np −◦ (((np −◦ s) −◦ s) −◦ s)) Then the types of J and A, and the two lexicons should be changed accordingly. The semantic lexicon of this alternative solution would be s</context>
<context position="21972" citStr="Morrill (1994)" startWordPosition="4062" endWordPosition="4063">e conjunction that occurs in the interpretation of A in Lexicon L13) as constants of the object vocabulary E3. Then, the interpretation of A would be something like: λP. λQ. EXISTS (λx. AND (P x) (Q x)). Now, this expression must be typable, which is not possible in a purely linear framework. Indeed, the λ-term to which EXISTS is applied is not linear (there are two occurrences of the bound variable x). Consequently, EXISTS must be given ((e —* t) −o t) as a type. 5.3 Quantifiers Quantifiers may also play a part. Uses of firstorder quantification, in a type logical setting, are exemplified by Morrill (1994), Moortgat (1997), and Ranta (1994). As for second-order quantification, it allows for polymorphism. 6 Grammars as first-class citizen The difference we make between an abstract vocabulary and an object vocabulary is purely conceptual. In fact, it only makes sense relatively to a given lexicon. Indeed, from a technical point of view, any vocabulary is simply a higher-order linear signature. Consequently, one may think of a lexicon L12 : E1 —* E2 whose object language serves as abstract language of another lexicon L23 : E2 —* E3. This allows lexicons to be sequentially composed. Moreover, one m</context>
</contexts>
<marker>Morrill, 1994</marker>
<rawString>G. Morrill. 1994. Type Logical Grammar: Categorial Logic of Signs. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nivat</author>
</authors>
<title>Transduction des langages de Chomsky. Annales de l’Institut Fourier,</title>
<date>1968</date>
<pages>18--339</pages>
<contexts>
<context position="17252" citStr="Nivat, 1968" startWordPosition="3243" endWordPosition="3244">d by the same construction. The resulting ACGs (which we will call “regular ACGs” for the purpose of the discussion) may be seen as finite state automata. The abstract language of a regular ACG correspond then to the set of accepting sequences of transitions of the corresponding automaton, and its object language to the accepted language. More interestingly, rational transducers may also be accomodated. Indeed, two regular ACGs that shares the same abstract language correspond to a regular language homomorphism composed with a regular language inverse homomorphism. Now, after Nivat’s theorem (Nivat, 1968), any rational transducer may be represented as such a bimorphism. 4.3 Tree adjoining grammars The construction that allows to handle the tree adjoining grammars of Joshi (Joshi and Schabes, 1997) may be seen as a generalization of the construction that we have described for the contextfree grammars. Nevertheless, it is a little bit more involved. For instance, it is necessary to triplicate the non-terminal symbols in order to distinguish the initial trees from the auxiliary trees. We do not have enough room in this paper for giving the details of the construction. We will rather give an examp</context>
</contexts>
<marker>Nivat, 1968</marker>
<rawString>M. Nivat. 1968. Transduction des langages de Chomsky. Annales de l’Institut Fourier, 18:339–455.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R T Oehrle</author>
</authors>
<title>Term-labeled categorial type systems.</title>
<date>1994</date>
<journal>Linguistic &amp; Philosophy,</journal>
<pages>17--633</pages>
<contexts>
<context position="2167" citStr="Oehrle, 1994" startWordPosition="339" endWordPosition="340">contents of a lexical entry is outlined by the following patern: &lt;atom&gt; : &lt;syntactic category&gt; On the other hand, the semantic contents obeys the following scheme: &lt;A-term&gt; : &lt;semantic type&gt; This asymmetry may be broken by: 1. allowing A-terms on the syntactic side (atomic expressions being, after all, particular cases of A-terms), 2. using the same type theory for expressing both the syntactic categories and the semantic types. The first point is a powerfull generalization of the usual scheme. It allows A-terms to be used at a syntactic level, which is an approach that has been advocated by (Oehrle, 1994). The second point may be satisfied by dropping the noncommutative (and non-associative) aspects of categorial logics. This implies that, contrarily to the usual categorial approaches, word order constraints cannot be expressed at the logical level. As we will see this apparent loss in expressive power is compensated by the first point. 2 Definition of a multiplicative kernel In this section, we define an elementary grammatical formalism based on the ideas presented in the introduction. This elementary formalism is founded on the multiplicative fragment of linear logic (Girard, 1987). For this</context>
</contexts>
<marker>Oehrle, 1994</marker>
<rawString>R. T. Oehrle. 1994. Term-labeled categorial type systems. Linguistic &amp; Philosophy, 17:633–678.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Pogodalla</author>
</authors>
<title>Generation, Lambek Calculus, Montague’s Semantics and Semantic Proof Nets.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics,</booktitle>
<volume>2</volume>
<pages>628--634</pages>
<contexts>
<context position="12605" citStr="Pogodalla (2000)" startWordPosition="2358" endWordPosition="2359">e paradigms are available. 3.1 Applicative paradigm In our framework, the applicative paradigm consists simply in computing, according to the lexicon of a given grammar, the object image of an abstract term. From a computational point of view it amounts to performing substitution and 0- reduction. 3.2 Deductive paradigm The deductive paradigm, in our setting, answers the following problem: does a given term, built upon the object vocabulary of an ACG, belong to the object language of this ACG. It amounts to a kind of proof-search that has been described by Merenciano and Morrill (1997) and by Pogodalla (2000). This proof-search relies on linear higher-order matching, which is a decidable problem (de Groote, 2000). 3.3 Transductive paradigm The example developped in Section 2.3 suggests a third paradigm, which is obtained as the composition of the applicative paradigm with the deductive paradigm. We call it the transductive paradigm because it is reminiscent of the mathematical notion of transduction (see Section 4.2). This paradigm amounts to the transfer from one object language to another object language, using a common abstract language as a pivot. 4 Relating ACGs to other grammatical formalism</context>
</contexts>
<marker>Pogodalla, 2000</marker>
<rawString>S. Pogodalla. 2000. Generation, Lambek Calculus, Montague’s Semantics and Semantic Proof Nets. In Proceedings of the 18th International Conference on Computational Linguistics, volume 2, pages 628–634.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Prawitz</author>
</authors>
<title>Natural Deduction, A ProofTheoretical Study. Almqvist &amp; Wiksell,</title>
<date>1965</date>
<location>Stockholm.</location>
<contexts>
<context position="19640" citStr="Prawitz, 1965" startWordPosition="3675" endWordPosition="3676"> Section 2 by providing features such as records, enumerated types, conditional expressions, etc. From a methodological point of view, there is a systematic way of considering such extensions. It consists of enriching the type system of the formalism with new logical connectives. Indeed, each new logical connective may be interpreted, through the Curry-Howard isomorphism, as anew type constructor. Nonetheless, the possible additional connectives must satisfy the following requirements: 1. they must be provided with introduction and elimination rules that satisfy Prawitz’s inversion principle (Prawitz, 1965) and the resulting system must be strongly normalizable; 2. the resulting term language (or at least an interesting fragment of it) must have a decidable matching problem. The first requirement ensures that the new types come with appropriate data constructors and discriminators, and that the associated evaluation rule terminates. This is mandatory for the applicative paradigm of Section 3. The second requirement ensures that the deductive paradigm (and consequently the transductive paradigm) may be fully automated. The other connectives of linear logic are natural candidates for extending the</context>
</contexts>
<marker>Prawitz, 1965</marker>
<rawString>D. Prawitz. 1965. Natural Deduction, A ProofTheoretical Study. Almqvist &amp; Wiksell, Stockholm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ranta</author>
</authors>
<title>Type theoretical grammar.</title>
<date>1994</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="22007" citStr="Ranta (1994)" startWordPosition="4067" endWordPosition="4068">rpretation of A in Lexicon L13) as constants of the object vocabulary E3. Then, the interpretation of A would be something like: λP. λQ. EXISTS (λx. AND (P x) (Q x)). Now, this expression must be typable, which is not possible in a purely linear framework. Indeed, the λ-term to which EXISTS is applied is not linear (there are two occurrences of the bound variable x). Consequently, EXISTS must be given ((e —* t) −o t) as a type. 5.3 Quantifiers Quantifiers may also play a part. Uses of firstorder quantification, in a type logical setting, are exemplified by Morrill (1994), Moortgat (1997), and Ranta (1994). As for second-order quantification, it allows for polymorphism. 6 Grammars as first-class citizen The difference we make between an abstract vocabulary and an object vocabulary is purely conceptual. In fact, it only makes sense relatively to a given lexicon. Indeed, from a technical point of view, any vocabulary is simply a higher-order linear signature. Consequently, one may think of a lexicon L12 : E1 —* E2 whose object language serves as abstract language of another lexicon L23 : E2 —* E3. This allows lexicons to be sequentially composed. Moreover, one may easily construct a third lexicon</context>
</contexts>
<marker>Ranta, 1994</marker>
<rawString>A. Ranta. 1994. Type theoretical grammar. Oxford University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>