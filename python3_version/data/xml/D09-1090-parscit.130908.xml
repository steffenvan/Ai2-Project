<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000086">
<title confidence="0.978715">
Bilingual dictionary generation for low-resourced language pairs
</title>
<author confidence="0.7914">
Varga István
</author>
<affiliation confidence="0.6183155">
Yamagata University,
Graduate School of Science and Engineering
</affiliation>
<email confidence="0.985726">
dyn36150@dip.yz.yamagata-u.ac.jp
</email>
<author confidence="0.731142">
Yokoyama Shoichi
</author>
<affiliation confidence="0.5672265">
Yamagata University,
Graduate School of Science and Engineering
</affiliation>
<email confidence="0.991039">
yokoyama@yz.yamagata-u.ac.jp
</email>
<sectionHeader confidence="0.993712" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99960775">
Bilingual dictionaries are vital resources in
many areas of natural language processing.
Numerous methods of machine translation re-
quire bilingual dictionaries with large cover-
age, but less-frequent language pairs rarely
have any digitalized resources. Since the need
for these resources is increasing, but the hu-
man resources are scarce for less represented
languages, efficient automatized methods are
needed. This paper introduces a fully auto-
mated, robust pivot language based bilingual
dictionary generation method that uses the
WordNet of the pivot language to build a new
bilingual dictionary. We propose the usage of
WordNet in order to increase accuracy; we
also introduce a bidirectional selection method
with a flexible threshold to maximize recall.
Our evaluations showed 79% accuracy and
51% weighted recall, outperforming represen-
tative pivot language based methods. A dic-
tionary generated with this method will still
need manual post-editing, but the improved
recall and precision decrease the work of hu-
man correctors.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99994346">
In recent decades automatic and semi-automatic
machine translation systems gradually managed
to take over costly human tasks. This much wel-
comed change can be attributed not only to major
developments in techniques regarding translation
methods, but also to important translation re-
sources, such as monolingual or bilingual dic-
tionaries and corpora, thesauri, and so on. How-
ever, while widely used language pairs can fully
take advantage of state-of-the-art developments
in machine translation, certain low-frequency, or
less common language pairs lack some or even
most of the above mentioned translation re-
sources. In that case, the key to a highly accurate
machine translation system switches from the
choice and adaptation of the translation method
to the problem of available translation resources
between the chosen languages.
One possible solution is bilingual corpus ac-
quisition for statistical machine translation
(SMT). However, for highly accurate SMT sys-
tems large bilingual corpora are required, which
are rarely available for less represented lan-
guages. Rule or sentence pattern based systems
are an attractive alternative, for these systems the
need for a bilingual dictionary is essential.
Our paper targets bilingual dictionary genera-
tion, a resource which can be used within the
frameworks of a rule or pattern based machine
translation system. Our goal is to provide a low-
cost, robust and accurate dictionary generation
method. Low cost and robustness are essential in
order to be re-implementable with any arbitrary
language pair. We also believe that besides high
precision, high recall is also crucial in order to
facilitate post-editing which has to be performed
by human correctors. For improved precision, we
propose the usage of WordNet, while for good
recall we introduce a bidirectional selection
method with local thresholds.
Our paper is structured as follows: first we
overview the most significant related works, af-
ter which we analyze the problems of current
dictionary generation methods. We present the
details of our proposal, exemplified with the
Japanese-Hungarian language pair. We evaluate
the generated dictionary, performing also a com-
parative evaluation with two other pivot-
language based methods. Finally we present our
conclusions.
</bodyText>
<sectionHeader confidence="0.999738" genericHeader="introduction">
2 Related works
</sectionHeader>
<subsectionHeader confidence="0.998726">
2.1 Bilingual dictionary generation
</subsectionHeader>
<bodyText confidence="0.999752">
Various corpus based, statistical methods with
very good recall and precision were developed
starting from the 1980’s, most notably using the
</bodyText>
<page confidence="0.958613">
862
</page>
<note confidence="0.663861">
Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 862–870,
Singapore, 6-7 August 2009. c�2009 ACL and AFNLP
Dice-coefficient (Kay &amp; Röscheisen, 1993), cor-
respondence-tables (Brown, 1997), or mutual
information (Brown et al., 1998).
</note>
<bodyText confidence="0.999951807692308">
As an answer to the corpus-based method’s
biggest disadvantage, namely the need for a large
bilingual corpus, in the 1990’s Tanaka and
Umemura (1994) presented a new approach. As a
resource, they only use dictionaries to and from a
pivot language to generate a new dictionary.
These so-called pivot language based methods
rely on the idea that the lookup of a word in an
uncommon language through a third, intermedi-
ated language can be automated. Tanaka and
Umemura’s method uses bidirectional source-
pivot and pivot-target dictionaries (harmonized
dictionaries). Correct translation pairs are se-
lected by means of inverse consultation, a
method that relies on counting the number of
pivot language definitions of the source word,
through which the target language definitions can
be identified (Tanaka and Umemura, 1994).
Sjöbergh (2005) also presented an approach to
pivot language based dictionary generation.
When generating his English pivoted Swedish-
Japanese dictionary, each Japanese-to-English
description is compared with each Swedish-to-
English description. Scoring is based on word
overlap, weighted with inverse document fre-
quency; the best matches being selected as trans-
lation pairs.
These two approaches described above are the
best performing ones that are general enough to
be applicable with other language pairs as well.
In our research we used these two methods as
baselines for comparative evaluation.
There are numerous refinements of the above
methods, but for various reasons they cannot be
implemented with any arbitrary language pair.
Shirai and Yamamoto (2001) used English to
design a Korean-Japanese dictionary, but be-
cause the usage of language-specific information,
they conclude that their method ‘can be consid-
ered to be applicable to cases of generating
among languages similar to Japanese or Korean
through English’. In other cases, only a small
portion of the lexical inventory of the language is
chosen to be translated: Paik et al. (2001) pro-
posed a method with multiple pivots (English
and Kanji/Hanzi characters) to translate Sino-
Korean entries. Bond and Ogura describe a Japa-
nese-Malay dictionary that uses a novel tech-
nique in its improved matching through normali-
zation of the pivot language, by means of seman-
tic classes, but only for nouns (2007). Besides
English, they also use Chinese as a second pivot.
</bodyText>
<subsectionHeader confidence="0.999511">
2.2 Lexical database in lexical acquisition
</subsectionHeader>
<bodyText confidence="0.999944209302326">
Large lexical databases are vital for many areas
in natural language processing (NLP), where
large amount of structured linguistic data is
needed. The appearance of WordNet (Miller et
al., 1990) had a big impact in NLP, since not
only did it provide one of the first wide-range
collections of linguistic data in electronic format,
but it also offered a relatively simple structure
that can be implemented with other languages as
well. In the last decades since the first, English
WordNet, numerous languages adopted the
WordNet structure, thus creating a potential large
multilingual network. The Japanese language is
one of the most recent ones added to the Word-
Net family (Isahara et al. 2008), but the Hungar-
ian WordNet is still under development
(Prószéky et al. 2001; Miháltz and Prószéky
2004).
Multilingual projects, such as EuroWordNet
(Vossen 1998; Peters et al. 1998), Balkanet
(Stamou et al. 2002) or Multilingual Central Re-
pository (Agirre et al. 2007) aim to solve numer-
ous problems in natural language processing.
EuroWordNet was specifically designed for
word disambiguation purposes in cross-language
information retrieval (Vossen 1998). The internal
structure of the multilingual WordNets itself can
be a good starting point for bilingual dictionary
generation. In case of EuroWordNet, besides the
internal design of the initial WordNet for each
language, an Inter-Lingual-Index interlinks word
meaning across languages is implemented (Pe-
ters et al. 1998). However, there are two limita-
tions: first of all, the size of each individual lan-
guage database is relatively small (Vossen 1998),
covering only the most frequent words in each
language, thus not being sufficient for creating a
dictionary with a large coverage. Secondly, these
multilingual databases cover only a handful of
languages, with Hungarian or Japanese not being
part of them. Adding a new language would re-
quire the existence of a WordNet of that lan-
guage.
</bodyText>
<sectionHeader confidence="0.9623485" genericHeader="method">
3 Problems of current pivot language
based methods
</sectionHeader>
<subsectionHeader confidence="0.999905">
3.1 Selection method shortcomings
</subsectionHeader>
<bodyText confidence="0.9984874">
Previous pivot language based methods generate
and score a number of translation candidates, and
the candidate’s scores that exceed a certain pre-
defined global threshold are selected as viable
translation pairs. However, the scores highly de-
</bodyText>
<page confidence="0.99787">
863
</page>
<bodyText confidence="0.999892444444444">
pend on the entry itself or the number of transla-
tions in the pivot language, therefore there is a
variance in what that score represents. For this
reason, a large number of good entries are en-
tirely left out from the dictionary, because all of
their translation candidates scored low, while
faulty translation candidates are selected, be-
cause they exceed the global threshold. Due to
this effect the recall value drops significantly.
</bodyText>
<subsectionHeader confidence="0.999765">
3.2 Dictionaries not enough as resource
</subsectionHeader>
<bodyText confidence="0.999926913043478">
Regardless of the language pair, in most cases
the meanings of the corresponding words are not
identical; they only overlap to a certain extent.
Therefore, the pivot language based dictionary
generation problem can be defined as the identi-
fication of the common elements or the extent of
the relevant overlapping in the source-to-pivot
and target-to-pivot definitions.
Current methods perform a strictly lexical
overlap of the source-pivot and target-pivot en-
tries. Even if the meanings of the source and tar-
get head words are transferred to the pivot lan-
guage, this is rarely done with the same set of
words or definitions. Thus, due to the different
word-usage or paraphrases, even semantically
identical or very similar head words can have
different definitions in different dictionaries. As
a result, performing only lexical overlap, current
methods cannot identify the differences between
totally different definitions resulted by unrelated
concepts, and differences in only nuances re-
sulted by lexicographers describing the same
concept, but with different words.
</bodyText>
<sectionHeader confidence="0.998899" genericHeader="method">
4 Proposed method
</sectionHeader>
<subsectionHeader confidence="0.999985">
4.1 Specifics of our proposal
</subsectionHeader>
<bodyText confidence="0.998634517241379">
For higher precision, instead of the familiar lexi-
cal overlap of the current methods we calculate
the semantically expanded lexical overlap of the
source-to-pivot and target-to-pivot translations.
In order to do that, we use semantic information
extracted from the WordNet of the pivot lan-
guage.
To improve recall, we introduce bidirectional
selection. As we stated above, the global thresh-
old eliminates a large number of good translation
pairs, resulting in a low recall. As a solution, we
can group the translations that share the same
source or target entry, and set local thresholds
for each head word. For example, for a source
language head word entry_source there could be
multiple target language candidates: en-
try_target1, ... ,entry_targetn. If the top scoring
entry_targetk candidates are selected, we ensure
that at least one translation will be available for
entry_source, maintaining a high recall. Since we
can group the entries in the source language and
target language as well, we perform this selection
twice, once in each direction. Local thresholds
depend on the top scoring entry_target, being set
to maxscore•c. Constant c varies between 0 and 1,
allowing a small window not only for the maxi-
mum, but high scoring candidates as well. It is
language and selection method dependent (see
§5.1 for details).
</bodyText>
<subsectionHeader confidence="0.997764">
4.2 Translation resources
</subsectionHeader>
<bodyText confidence="0.999969">
As an example of a less-common language pair,
we have chosen Japanese and Hungarian. For
translation candidate generation, we have chosen
two freely available dictionaries with English as
the pivot language. The Japanese-English dic-
tionary had 197282, while the Hungarian-English
contained 189331 1-to-1 entry pairs. The Japa-
nese-English dictionary had part-of-speech
(POS) information as well, but to ensure robust-
ness, our method does not use this information.
To select from the translation candidates, we
mainly use WordNet (Miller et. al., 1990). From
WordNet we consider four types of information:
sense categorization, synonymy, antonymy and
semantic categories provided by the tree struc-
ture of nouns and verbs.
</bodyText>
<subsectionHeader confidence="0.996308">
4.3 Dictionary generation method
</subsectionHeader>
<bodyText confidence="0.9997046">
Our proposed method consists of two steps. In
step 1 we generate a number of translation pair
candidates, while in step 2 we score and select
from them based on semantic information ex-
tracted from WordNet.
</bodyText>
<subsectionHeader confidence="0.742052">
Step 1: translation candidate generation
</subsectionHeader>
<bodyText confidence="0.998799625">
Using the source-pivot and pivot-target diction-
aries, we connect the source and target entries
that share at least one common translation in the
pivot language. We consider each source-target
pair a translation candidate. With our Japanese-
English and English-Hungarian dictionaries we
accumulated 436966 Japanese-Hungarian trans-
lation candidates.
</bodyText>
<subsectionHeader confidence="0.609124">
Step 2: translation pair selection
</subsectionHeader>
<bodyText confidence="0.9999912">
We examine the translation candidates one by
one, looking up the source-pivot and target-pivot
dictionaries, comparing the translations in the
pivot language. There are six types of transla-
tions that we label A-F and explain below. First,
</bodyText>
<page confidence="0.988593">
864
</page>
<bodyText confidence="0.7636745">
we perform a strictly lexical match based only on
the dictionaries. Next, using information ex-
tracted from WordNet we attempt to identify the
correct translation pairs.
</bodyText>
<listItem confidence="0.636362">
(a) Lexically unambiguous translation pairs
</listItem>
<bodyText confidence="0.999607090909091">
Some of the translation candidates have exactly
the same translations into in the pivot language;
we consider these pairs as being correct by de-
fault. Also among the translation candidates we
identified a number of source entries that had
only one target translation; and a number of tar-
get entries that had only one source translation.
Being the sole candidates for the given entries,
we consider these pairs too as being correct.
37391 Japanese-Hungarian translation pairs were
retrieved with this method (type A pairs).
</bodyText>
<listItem confidence="0.481742">
(b) Using sense description
</listItem>
<bodyText confidence="0.9997745">
For most polysemous words WordNet has de-
tailed descriptions with synonyms for each sense.
We use these synonyms of WordNet’s sense de-
scriptions to disambiguate the meanings of the
common translations. For a given source-target
translation candidate (s,t) we look up the source-
pivot and target-pivot translations
(s--+I={sail,...,s--+i„} and
t�I={�����������}). We select the elements
that are common in the two definitions
(I’=(s,l)n(t--+l)) and we look up their respec-
tive senses from WordNet (sns(I)). We identify
the words’ senses comparing each synonym in
the WordNet’s synonym description with each
word from the dictionary definition. As a result,
for each common word we arrive at a certain set
of senses from the source-pivot definitions
(sns((s--+1)) and a certain set of senses from the
target-pivot definitions (sns((t--+1)). We mark
scoreB(s,t) the maximum ratio of the identical
and total number of identified senses (Jaccard
coefficient). The higher the scoreB(s,t) is, the
more probable is candidate (s,t) a valid transla-
tion.
</bodyText>
<equation confidence="0.962738333333333">
sns s i sns t i
( ) ( )
→ ∩
&apos; → &apos;
( )
s t
, = max
i s I t I
&apos; ∈ → ∩ →
( ) ( )sns s i sns t i
( &apos; ) ( &apos;)
→ ∪ →
</equation>
<bodyText confidence="0.978943159090909">
For example, 正解 (seikai: correct, right, cor-
rect interpretation) and helyes (correct, proper,
right, appropriate) have two common transla-
tions (I&apos;={right, correct}), thus scoreB(s,t) can be
performed with these two words. The adjective
right has 13 senses according to WordNet,
among them 4 were identified from the Japanese
to English definition (sns(right)={#1, #3, #5,
#10}, all identified through correct) and 5 from
the Hungarian to English definition
(sns(right)={#1, #3, #5, #6, #10}, through cor-
rect or proper). As a result, 4 senses are com-
mon, and 1 is different. Thus the adjective right’s
score is 0.8 (scoreB(s,t)[right](正解,helyes)). The
adjective correct has 4 senses, all of them are
recognized by both definitions through right,
therefore the score through correct is 1
(scoreB(s,t)[correct]( 正 解 ,helyes)). The maxi-
mum of the above scores is the final score:
scoreB(s,t)(正解,helyes)=1.
All translation candidates are verified based
on all four POS available from WordNet. Since
synonymy information is available for nouns (N),
verbs (V), adjectives (A) and adverbs (R), four
separate scores are calculated for each POS.
Scores that pass a global threshold are consid-
ered correct. 33971 Japanese-Hungarian candi-
dates (type B translations) were selected, with
these two languages the global threshold was set
to 0.1. Even this low value ensures that at least
one of ten meanings is shared by the two entries
of the pair, thus being suitable as translation pair.
(c) Using synonymy, antonymy and semantic
categories
We expand the source-to-pivot and target-to-
pivot definitions with information from WordNet
(synonymy, antonymy and semantic category,
respectively). Thus the similarity of the two ex-
panded pivot language descriptions gives a better
indication on the suitability of the translation
candidate. Using the three relations, the common
versus total number of translations (Jaccard coef-
ficient) will define the appropriateness of the
translation candidate.
</bodyText>
<equation confidence="0.999024">
scoreC,D,E (s,t) =
ext(si) ext(t i)
→ ∪ →
</equation>
<bodyText confidence="0.999710533333333">
Since the same word or concept’s translations
into the pivot language also share the same se-
mantic value, the extension with synonyms
(ext(l--+i)=(lei)∪syn(l--+i), where l={s,t}) the
extended translation should share more common
elements.
In case of antonymy, we expand the initial
definitions with the antonyms of the antonyms
(ext(l--+i)=(lei)∪ant(ant(l--+i)), where l={s,t}).
This extension is different from the synonymy
extension, in most cases the resulting set of
words being considerably larger.
Along with synonymy, antonymy is also avail-
able for nouns, verbs, adjectives and adverbs,
four separate scores are calculated for each POS.
</bodyText>
<equation confidence="0.8756195">
scoreB
(1)
ext(s → i)∩ext(t → i)
(2)
</equation>
<page confidence="0.985569">
865
</page>
<bodyText confidence="0.990212938461539">
Semantic categories are provided by the tree
structure (hypernymy/hyponymy) of nouns and
verbs of WordNet. We transpose each entry from
the pivot translations to its semantic categories
(ext(l--+i)=Esemcat(l--+i), where l={s,t}). We as-
sume that the correct translation pairs share a
high percentage of semantic categories. Accord-
ingly, the translations of semantically similar or
identical entries should share a high number of
common semantic categories.
The scores based on these relations highly de-
pend on the number of pivot language transla-
tions; therefore we use the bidirectional selection
method with local thresholds for each source and
target head word. Local thresholds are set based
on the best scoring candidate for a given entry.
The thresholds were maxscore•0.9 for synonymy
and antonymy; and maxscore•0.8 for the seman-
tic categories (see §5.1 for details).
Using synonymy, 196775 candidate pairs
(type C), with antonymy 99614 pairs (type D);
while with semantic categories 195480 pairs
(type E) were selected.
(d) Combined semantic information
The three separate lists of type C, D and E selec-
tion methods resulted in slightly different results,
proving that they cannot be used as standalone
selection methods (see §5.2 for details).
Because of the multiple POS labelling of nu-
merous words in WordNet, many translation
pairs can be selected up to four times based on
separate POS information (noun, verb, adjective,
adverb), all within one single semantic informa-
tion based methods. Since we use a bidirectional
selection method, experiments showed that trans-
lation pairs that were selected during both direc-
tions, in most cases were the correct translations.
Similarly, translation pairs selected during only
one direction were less accurate. In other words,
translation pairs whose target language transla-
tion was selected as a good translation for the
source language entry; and whose source lan-
guage translation was also selected as a good
translation for the target language entry, should
be awarded with a higher score. In the same way,
entries selected only during one direction should
receive a penalty. For every translation candidate
we select the maximum score from the several
POS (noun, verb, adjective and adverb for syn-
onymy and antonymy relations; noun and verb
for semantic category) based scores, multiplied
by a multiplication factor (mfactor). The multi-
plication factor varies between 0 and 1, awarding
the candidates that were selected both times dur-
ing the double directional selection; and punish-
ing when selection was made only in a single
direction. The product gives the combined score
(scoreF), cli c2 and c3 are constants. In case of
Japanese and Hungarian, these method scored
best with the constants set to 1, 0.5 and 0.8, re-
spectively. The combined score also highly de-
pends on the word entry, therefore local thresh-
olds are used in this selection method as well,
which were empirically set to maxscore•0.85 (see
§5.1 for details).
</bodyText>
<equation confidence="0.984673">
F (s,O =∏rel ((c2
+c�factorrescorerel �(s, t))) (3)
</equation>
<bodyText confidence="0.996428363636364">
As an example, for the Japanese entry 購入
(konyu: buy, purchase) there are 10 possible
Hungarian translations; using the above methods
5 of them (#1, #7, #8, #9, #10) are selected as
correct ones. Among these, only 1 of them (#1)
is a correct translation, the rest have similar or
totally different meanings. However, with the
combined scores the faulty translations were
eliminated and a new, correct, but previously
average scoring translation (#2) was selected
(Table 1).
</bodyText>
<table confidence="0.641038923076923">
score
# translation candidate scoreF score� score� scoreE
N V A R N V A R N V
1 vétel (purchase) 2.012 0.193 0.096 0 0 0 0.500 0 0 0.154 0.500
2 üzlet (business transaction) 1.387 0.026 0.030 0 0 0 0.250 0 0 0.020 0.077
3 hozam (output, yield) 1.348 0.095 0.071 0 0 0 0 0 0 0.231 0.062
4 emel6rúd (lever, purchase) 1.200 0.052 0.079 0 0 0 0 0 0 0.111 0.067
5 el6ny (advantage, virtue) 1.078 0.021 0.020 0 0 0 0 0 0 0.054 0.056
6 támasz (purchase, support) 1.053 0.014 0.015 0 0 0 0 0 0 0.037 0.031
7 vásárlás (shopping) 0.818 0.153 0.285 0 0 0 0 0 0 0.273 0.200
8 szerzemény (attainment) 0.771 0.071 0.285 0 0 0 0 0 0 0.136 0.200
9 könnyítés (facilitation) 0.771 0.064 0.285 0 0 0 0 0 0 0.136 0.200
10 emel6szerkezet (lever) 0.459 0.285 0.285 0 0 0 0 0 0 0.429 0.200
</table>
<tableCaption confidence="0.999352">
Table 1: Translation candidate scoring for 購入: buy, purchase (above thresholds in bold)
</tableCaption>
<page confidence="0.998572">
866
</page>
<bodyText confidence="0.9997626">
161202 translation pairs were retrieved with
this method (type F).
During pre-evaluation type A and type B trans-
lations received a score of above 75%, while type
C, type D and type E scored low (see §5.2 for
details). However, type F translations scored
close to 80%, therefore from the six translation
methods presented above we chose only three
(type A, B and F) to construct the dictionary,
while the remaining three methods (type C, D
and E) are used only indirectly for type F selec-
tion.
With the described selection methods 187761
translation pairs, with 48973 Japanese and 44664
Hungarian unique entries was generated.
</bodyText>
<sectionHeader confidence="0.904828" genericHeader="method">
5 Threshold settings and pre-evaluation
</sectionHeader>
<subsectionHeader confidence="0.982539">
5.1 Local threshold settings
</subsectionHeader>
<bodyText confidence="0.999931730769231">
As development set we considered all translation
candidates whose Hungarian entry starts with
“zs” (IPA: ʒ). We assume that the behaviour of
this subset of words reflects the behaviour of the
entire vocabulary. 133 unique entries totalling
515 translation candidates comprise this devel-
opment set. After this, we manually scored the
515 translation candidates as correct (the transla-
tion conveys the same meaning, or the meanings
are slightly different, but in a certain context the
translation is possible) or wrong (the translation
pair’s two entries convey a different meaning).
The scoring was performed by one of the authors
who is a native Hungarian and fluent in Japanese.
273 entries were marked as correct. Next, we
experimented with a number of thresholds to de-
termine which ones provide with the best F-
scores (Table 2). The F-scores were determined
as follows: for example using synonymy infor-
mation (type C) in case of threshold=0.85%, 343
of the 515 translation pairs were above the
threshold. Among these, 221 were marked as
correct by our manual evaluator, thus the preci-
sion being 221/343.100=64.43 and the recall be-
ing 221/273.100=80.95. F-score is the harmonic
mean of precision and recall (71.75 in this case).
</bodyText>
<table confidence="0.999322142857143">
selection threshold value (%)
type
0.75 0.80 0.85 0.90 0.95
C 70.27 70.86 71.75 72.81 66.95
D 69.92 70.30 70.32 70.69 66.66
E 73.71 74.90 72.52 71.62 65.09
F 78.78 79.07 79.34 78.50 76.94
</table>
<tableCaption confidence="0.990108">
Table 2: Selection type F-scores with varying thresh-
olds (best threshold values in bold)
</tableCaption>
<subsectionHeader confidence="0.997997">
5.2 Selection method evaluation
</subsectionHeader>
<bodyText confidence="0.999563727272727">
As a pre-evaluation of the above selection meth-
ods, we randomly selected 200 1-to-1 source-
target entries resulted by each method. The same
evaluator scored the translation pairs as correct
(the translation conveys the same meaning, or the
meanings are slightly different, but in a certain
context the translation is possible), undecided
(the translation pair’s semantic value is similar,
but a translation based on them would be faulty)
or wrong (the translation pair’s two entries con-
vey a different meaning).
</bodyText>
<table confidence="0.999167">
selection evaluation score (%)
type
correct undecided wrong
A 75.5 6.5 18
B 83 7 10
C 68 5.5 26.5
D 60 9 31
E 71 5.5 23.5
F 79 5 16
</table>
<tableCaption confidence="0.99964">
Table 3: Selection type evaluation
</tableCaption>
<bodyText confidence="0.999554">
The results showed that type A and type B selec-
tions scored higher than all order-based selec-
tions, with type C, type D and type E selections
failing to deliver the desired accuracy (Table 3).
</bodyText>
<sectionHeader confidence="0.996389" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.998851">
We performed three types of evaluation:
</bodyText>
<listItem confidence="0.991196333333333">
(1) frequency-weighted recall evaluation
(2) 1-to-1 entry precision evaluation
(3) 1-to-multiple entry evaluation
</listItem>
<bodyText confidence="0.99976375">
For comparative purposes we also performed
each type of evaluation for two other pivot lan-
guage based methods whose characteristics per-
mit to be implementable with virtually any lan-
guage pair. In order to do so, we constructed two
other Hungarian-Japanese dictionaries using the
methods proposed by Tanaka &amp; Umemura and
Sjöbergh, using the same source dictionaries.
</bodyText>
<subsectionHeader confidence="0.99948">
6.1 Recall evaluation
</subsectionHeader>
<bodyText confidence="0.999965181818182">
It is well known that one of the most challenging
aspects of dictionary generation is word ambigu-
ity. It is relatively easy to automatically generate
the translations of low-frequency keywords, be-
cause they tend to be less ambiguous. On the
contrary, the ambiguity of the high frequency
words is much higher than their low-frequency
counterparts, and as a result conventional meth-
ods fail to translate a considerable number of
them. However, this discrepancy is not reflected
in the traditional recall evaluation, since each
</bodyText>
<page confidence="0.993299">
867
</page>
<bodyText confidence="0.9997375">
word has an equal weight, regardless of its fre-
quency of use. As a result, we performed a fre-
quency weighted recall evaluation. We used a
Japanese frequency dictionary (FD) generated
from the Japanese EDR corpus (Isahara, 2007) to
weight each Japanese entry. Setting the standard
to the frequency dictionary (its recall value being
100), we automatically search for each entry (w)
from the frequency dictionary, looking whether
or not it is included in the bilingual dictionary
(WD). If it is recalled, we weight it with its fre-
quency from the frequency dictionary.
</bodyText>
<figure confidence="0.868706642857143">
frequency
( w)
w W
∈
recall = � D ( ) ⋅1 00 (4)
w frequency
w F
∈ D
method recall
our method 51.68
Sjöbergh method 37.03
Tanaka method 30.76
initial candidates 51.68
Japanese-English(*) 73.23
</figure>
<tableCaption confidence="0.9858655">
Table 4: Recall evaluation results (* marks a manu-
ally created dictionary)
</tableCaption>
<bodyText confidence="0.999859666666667">
The frequency weighted recall value results
show that our method’s dictionary (51.68) out-
scores every other automatically generated
method’s dictionary (37.03, 30.76) with a sig-
nificant advantage. Moreover, it maintains the
score of the initial translation candidates, there-
fore managing to maximize the recall value, ow-
ing to the bidirectional selection method with
local thresholds. However, the recall value of a
manually created Japanese-English dictionary is
higher than any automatically generated diction-
ary’s value (Table 4).
</bodyText>
<subsectionHeader confidence="0.99985">
6.2 1-to-1 precision evaluation
</subsectionHeader>
<bodyText confidence="0.9998158">
With 1-to-1 precision evaluation we determine
the translation accuracy of our method, com-
pared with the two baseline methods. 200 ran-
dom pairs were selected from each of the three
Hungarian-Japanese dictionaries, scoring them
manually the same way as with selection type
evaluation (correct, undecided, wrong) (Table 5).
The manual scoring was performed by one of the
authors, who is a native Hungarian and fluent in
Japanese. Since no independent evaluator was
available for these two languages, after a random
identification code being assigned to each of the
600 selected translation pairs (200 from each
dictionary), they were mixed. Therefore the
evaluator did not know the origin of the transla-
tion pairs, only after manual scoring the total
score for each dictionary was available, after re-
grouping based on the initial identification codes.
The process was repeated 10 times, 2000 pairs
were manually checked from each dictionary.
</bodyText>
<table confidence="0.9998075">
code Japanese Hungarian classification
entry entry
n5d8 k9g6 hír (report, infor- correct
報告 (h�koku: mation, news)
information, re-
port)
j8h0 初 (ubu: innocent, zöld (green, ver- undecided
k1x5 naive) dant)
a5b6 エントリ (entori: bejárat (entry, wrong
n8i3 entry &lt;a contest&gt;) entrance)
</table>
<tableCaption confidence="0.94965">
Table 5: 1-to-1 precision evaluation examples
</tableCaption>
<table confidence="0.9954496">
method evaluation score (%)
correct undecided wrong
our method 79.15% 6.15% 14.70%
Sjöbergh method 54.05% 9.80% 36.15%
Tanaka method 62.50% 7.95% 29.55%
</table>
<tableCaption confidence="0.99847">
Table 6: 1-to-1 precision evaluation results
</tableCaption>
<bodyText confidence="0.999941714285714">
To rank the methods we only consider the cor-
rect translations. Our method performed best
with an average of 79.15%, outscoring Tanaka
method’s 62.50% and Sjöbergh method’s
54.05% (Table 6). The maximum deviance of the
correct translations during the 10 repetitions was
less than 3% from the average.
</bodyText>
<subsectionHeader confidence="0.994242">
6.3 1-to-multiple evaluation
</subsectionHeader>
<bodyText confidence="0.999974916666667">
While with 1-to-1 precision evaluation we esti-
mated the accuracy of the translation pairs, with
1-to-multiple we calculate the true reliability of
the dictionary, with the initial translation candi-
dates set as recall benchmark. When looking up
the meanings or translations of a certain head
word, the user, whether he’s a human or a ma-
chine, expects all translations to be accurate.
Therefore we evaluated 200 randomly selected
Japanese entries from the initial translation can-
didates, together with all of their Hungarian
translations, scoring them as correct (all transla-
tions are correct), acceptable (the good transla-
tions are predominant, but there are up to 2 erro-
neous translations), wrong (the number or wrong
translations exceeds 2) or missing (the translation
is missing) (Table 7).
The same type of mixed, manual evaluation
was performed by the same author on samples of
200 entries from each Japanese-Hungarian dic-
tionary. This evaluation was also repeated 10
times.
To rank the methods, we only consider the
correct translations. Our method scored best with
</bodyText>
<page confidence="0.995084">
868
</page>
<table confidence="0.979728290322581">
71.45%, outperforming Sjöbergh method’s
61.65% and Tanaka method’s 46.95% (Table 8).
code Japanese Hungarian classification
entry translations
m9x r összenyomás (com- correct
5 compr(asshuku: pression, crush,
5 sion, - squeeze: correct)
sion, összeszorítás (com-
squeeze) pression, confinement:
correct)
zsugorítás (shrinkage:
correct)
h9j9l A-19 alap (base, bottom, acceptable
3v1 (teimen: foundation: correct)
base) alapzat (base, bed,
bottom: correct)
lúg (alkali, base: unde-
cided)
támpont (base: correct)
l0k6 ��� bekerít (to encircle, to wrong
m3n (narasu: to enclose, to ring:
7 sound, to wrong)
ring, to beat) cseng (to clang, to
clank, to ring, to tinkle:
correct)
hangzik (to ring, to
sound: correct)
horkan (to snort:
wrong)
üt (to bang, to knock,
to ring: wrong)
</table>
<tableCaption confidence="0.991077">
Table 7: 1-to-multiple entry evaluation examples
</tableCaption>
<table confidence="0.909699666666667">
method evaluation score (%)
correct accept- wrong missing
able
our method 71.45 13.85 14.70 0
Sjöbergh method 61.65 11.30 15.00 12.05
Tanaka method 46.95 3.35 9.10 40.60
</table>
<tableCaption confidence="0.997753">
Table 8: 1-to-many evaluation results
</tableCaption>
<sectionHeader confidence="0.998615" genericHeader="discussions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999963238095238">
Based on the recall evaluations, the traditional
methods showed their major weakness by losing
substantially from the initial recall values, scored
by the initial translation candidates. Our method
maintains the same value with the translation
candidates, but we cannot say that the recall is
perfect. When compared with a manually created
dictionary, our method also lost significantly.
Precision evaluation also showed an im-
provement compared with the traditional meth-
ods, our method outscoring the other two meth-
ods with the 1-to-1 precision evaluation. 1-to-
multiple evaluation was also the highest, proving
that WordNet based methods outperform dic-
tionary based methods. Discussing the weak-
nesses of our system, we have to divide the prob-
lems into two categories: recall problems deal
with the difficulty in connecting the target and
source entries through the pivot language, while
precision problems discuss the reasons why erro-
neous pairs are produced.
</bodyText>
<subsectionHeader confidence="0.996329">
7.1 Recall problems
</subsectionHeader>
<bodyText confidence="0.999984222222222">
We managed to maximize the recall of our initial
translation candidates, but in many cases certain
translation pairs still could not be generated be-
cause the link from the source language to the
target language through the pivot language sim-
ply doesn’t exist. The main reasons are: the entry
is missing from at least one of the dictionaries;
translations in the pivot language are expressions
or explanations; or there is no direct translation
or link between the source and target entries. The
entries that could not be recalled are mostly ex-
pressions, rare entries, words specific to a lan-
guage (ex: tatami: floor-mat, or gulyás: goulash).
Moreover, a number of head words don’t have
any synonym, antonym and/or hy-
pernymy/hyponymy information in WordNet,
and as a result these words could not participate
in the type B, C, D, E and F scoring.
</bodyText>
<subsectionHeader confidence="0.997768">
7.2 Precision problems
</subsectionHeader>
<bodyText confidence="0.999976482758621">
We identified two types of precision problems.
The most obvious reasons for erroneous transla-
tions are the polysemous nature of words and the
meaning-range differences across languages.
With words whose senses are clear and mostly
preserved even through the pivot language, most
of the correct senses were identified and cor-
rectly translated. Nouns, adjectives and adverbs
had a relatively high degree of accuracy. How-
ever, verbs proved to be the most difficult POS
to handle. Because semantically they are more
flexible than other POS categories, and the
meaning range is also highly flexible across lan-
guages, the identification of the correct transla-
tion is increasingly difficult. For this reason, the
number of faulty translations and the number of
meanings that are not translated was relatively
high.
One other source of erroneous translations is
the quality of the initial dictionaries. Even the
unambiguous type A translations fail to produce
the desired accuracy, although they are the
unique candidate for a given word entry. The
main reason for this is the deficiency of the ini-
tial dictionaries, which contain a great number of
irrelevant or low usage translations, shadowing
the main, important senses of some words. In
other cases the resource dictionaries don’t con-
tain translations of all meanings; homonyms are
</bodyText>
<page confidence="0.994179">
869
</page>
<bodyText confidence="0.998737">
present as pivot entries with different meanings,
sometimes creating unique, but faulty links.
</bodyText>
<sectionHeader confidence="0.99894" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999955666666667">
We proposed a new pivot language based
method to create bilingual dictionaries that can
be used as translation resource for machine trans-
lation. In contrast to conventional methods that
use dictionaries only, our method uses WordNet
as a main resource of the pivot language to select
the suitable translation pairs. As a result, we
eliminate most of the weaknesses caused by the
structural differences of dictionaries, while prof-
iting from the semantic relations provided by
WordNet. We believe that because of the nature
of our method it can be re-implemented with
most language pairs.
In addition, owing to features such as the bidi-
rectional selection method with local thresholds
we managed to maximize recall, while maintain-
ing a precision which is better than any other
compared method’s score. During exemplifica-
tion, we generated a mid-large sized Japanese-
Hungarian dictionary with relatively good recall
and promising precision.
The dictionary is freely available online
(http://mj-nlp.homeip.net/mjszotar), being also
downloadable at request.
</bodyText>
<sectionHeader confidence="0.99924" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998786815384616">
Agirre, E., Alegria, I., Rigau, G, Vossen, P. 2007.
MCR for CLIR, Procesamiento del lenguaje natu-
ral 38, pp 3-15.
Bond, F., Ogura, K. 2007. Combining linguistic re-
sources to create a machine-tractable Japanese-
Malay dictionary, Language Resources and
Evaluation, 42(2), pp. 127-136.
Breen, J.W. 1995. Building an Electric Japanese-
English Dictionary, Japanese Studies Association
of Australia Conference, Brisbane, Queensland,
Australia.
Brown, P., Cocke, J., Della Pietra, S., Della Pietra, V.,
Jelinek, F., Mercer, R., Roossin, P. 1998. A Statis-
tical Approach to Language Translation, Proceed-
ings of COLING-88, pp. 71-76.
Brown, R.D. 1997. Automated Dictionary Extraction
for Knowledge-Free Example-Based Translation,
Proceedings of the 7th International Conference on
Theoretical and Methodological Issues in Machine
Translation, pp. 111-118.
Isahara, H., Bond, F., Uchimoto, K., Uchiyama, M.,
Kanzaki, K. 2008. Development of Japanese
WordNet, Proceedings of LREC-2008.
Isahara, H. 2007. EDR Electronic Dictionary – pre-
sent status (EDR 電子化辞書の現状), NICT-EDR
symposium, pp. 1-14. (in Japanese)
Kay, M., Röscheisen, M. 1993. Text-Translation
Alignment, Computational Linguistics, 19(1), pp.
121-142.
Miháltz, M., Prószéky, G. 2004. Results and Evalua-
tion of Hungarian Nominal WordNet v1.0, Pro-
ceedings of the Second Global WordNet Confer-
ence, pp. 175-180.
Miller G.A., Beckwith R., Fellbaum C., Gross D.,
Miller K.J. (1990). Introduction to WordNet: An
Online Lexical Database, Int J Lexicography 3(4),
pp. 235-244.
Paik, K., Bond, F., Shirai, S. 2001. Using Multiple
Pivots to align Korean and Japanese Lexical Re-
sources, NLPRS-2001, pp. 63-70, Tokyo, Japan.
Peters, W., Vossen, P., Díez-Orzas, P., Adriaens, G.
1998. Cross-linguistic Alignment of Wordnets with
an Inter-Lingual-Index, Computers and the Hu-
manities 32, pp. 221–251.
Prószéky, G., Miháltz, M., Nagy, D. 2001. Toward a
Hungarian WordNet, Proceedings of the NAACL
2001 Workshop on WordNet and Other Lexical Re-
sources, Pittsburgh, June 2001.
Sjöbergh, J. 2005. Creating a free Japanese-English
lexicon, Proceedings of PACLING, pp. 296-300.
Shirai, S., Yamamoto, K. 2001. Linking English
words in two bilingual dictionaries to generate an-
other pair dictionary, ICCPOL-2001, pp. 174-179.
Stamou, S., Oflazer, K., Pala, K., Christoudoulakis,
D., Cristea, D., Tufi�, D., Koeva, S., Totkov, G.,
Dutoit, D., Grigoriadou, M. 1997. BalkaNet: A
Multilingual Semantic Network for the Balkan
Languages, In Proceedings of the International
Wordnet Conference, Mysore, India.
Tanaka, K., Umemura, K. 1994. Construction of a
bilingual dictionary intermediated by a third lan-
guage, Proceedings of COLING-94, pp. 297-303.
Vossen, P. 1998. Introduction to EuroWordNet. Com-
puters and the Humanities 32: 73-89 Special Issue
on EuroWordNet.
</reference>
<page confidence="0.997656">
870
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.142549">
<title confidence="0.995942">Bilingual dictionary generation for low-resourced language pairs</title>
<author confidence="0.960133">Varga</author>
<affiliation confidence="0.9106365">Yamagata Graduate School of Science and</affiliation>
<email confidence="0.40864">dyn36150@dip.yz.yamagata-u.ac.jp</email>
<author confidence="0.508141">Yokoyama</author>
<affiliation confidence="0.932124">Yamagata Graduate School of Science and</affiliation>
<email confidence="0.762782">yokoyama@yz.yamagata-u.ac.jp</email>
<abstract confidence="0.99618768">Bilingual dictionaries are vital resources in many areas of natural language processing. Numerous methods of machine translation require bilingual dictionaries with large coverage, but less-frequent language pairs rarely have any digitalized resources. Since the need for these resources is increasing, but the human resources are scarce for less represented languages, efficient automatized methods are needed. This paper introduces a fully automated, robust pivot language based bilingual dictionary generation method that uses the WordNet of the pivot language to build a new bilingual dictionary. We propose the usage of WordNet in order to increase accuracy; we also introduce a bidirectional selection method with a flexible threshold to maximize recall. Our evaluations showed 79% accuracy and 51% weighted recall, outperforming representative pivot language based methods. A dictionary generated with this method will still need manual post-editing, but the improved recall and precision decrease the work of human correctors.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>I Alegria</author>
<author>G Rigau</author>
<author>P Vossen</author>
</authors>
<date>2007</date>
<booktitle>MCR for CLIR, Procesamiento del lenguaje natural 38,</booktitle>
<pages>3--15</pages>
<contexts>
<context position="7452" citStr="Agirre et al. 2007" startWordPosition="1117" endWordPosition="1120">fered a relatively simple structure that can be implemented with other languages as well. In the last decades since the first, English WordNet, numerous languages adopted the WordNet structure, thus creating a potential large multilingual network. The Japanese language is one of the most recent ones added to the WordNet family (Isahara et al. 2008), but the Hungarian WordNet is still under development (Prószéky et al. 2001; Miháltz and Prószéky 2004). Multilingual projects, such as EuroWordNet (Vossen 1998; Peters et al. 1998), Balkanet (Stamou et al. 2002) or Multilingual Central Repository (Agirre et al. 2007) aim to solve numerous problems in natural language processing. EuroWordNet was specifically designed for word disambiguation purposes in cross-language information retrieval (Vossen 1998). The internal structure of the multilingual WordNets itself can be a good starting point for bilingual dictionary generation. In case of EuroWordNet, besides the internal design of the initial WordNet for each language, an Inter-Lingual-Index interlinks word meaning across languages is implemented (Peters et al. 1998). However, there are two limitations: first of all, the size of each individual language dat</context>
</contexts>
<marker>Agirre, Alegria, Rigau, Vossen, 2007</marker>
<rawString>Agirre, E., Alegria, I., Rigau, G, Vossen, P. 2007. MCR for CLIR, Procesamiento del lenguaje natural 38, pp 3-15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bond</author>
<author>K Ogura</author>
</authors>
<title>Combining linguistic resources to create a machine-tractable JapaneseMalay dictionary,</title>
<date>2007</date>
<journal>Language Resources and Evaluation,</journal>
<volume>42</volume>
<issue>2</issue>
<pages>127--136</pages>
<marker>Bond, Ogura, 2007</marker>
<rawString>Bond, F., Ogura, K. 2007. Combining linguistic resources to create a machine-tractable JapaneseMalay dictionary, Language Resources and Evaluation, 42(2), pp. 127-136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Breen</author>
</authors>
<title>Building an Electric JapaneseEnglish Dictionary,</title>
<date>1995</date>
<booktitle>Japanese Studies Association of Australia Conference,</booktitle>
<location>Brisbane, Queensland, Australia.</location>
<marker>Breen, 1995</marker>
<rawString>Breen, J.W. 1995. Building an Electric JapaneseEnglish Dictionary, Japanese Studies Association of Australia Conference, Brisbane, Queensland, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>J Cocke</author>
<author>Della Pietra</author>
<author>Della Pietra S</author>
<author>V Jelinek</author>
<author>F Mercer</author>
<author>R Roossin</author>
<author>P</author>
</authors>
<title>A Statistical Approach to Language Translation,</title>
<date>1998</date>
<booktitle>Proceedings of COLING-88,</booktitle>
<pages>71--76</pages>
<contexts>
<context position="4093" citStr="Brown et al., 1998" startWordPosition="591" endWordPosition="594">the generated dictionary, performing also a comparative evaluation with two other pivotlanguage based methods. Finally we present our conclusions. 2 Related works 2.1 Bilingual dictionary generation Various corpus based, statistical methods with very good recall and precision were developed starting from the 1980’s, most notably using the 862 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 862–870, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP Dice-coefficient (Kay &amp; Röscheisen, 1993), correspondence-tables (Brown, 1997), or mutual information (Brown et al., 1998). As an answer to the corpus-based method’s biggest disadvantage, namely the need for a large bilingual corpus, in the 1990’s Tanaka and Umemura (1994) presented a new approach. As a resource, they only use dictionaries to and from a pivot language to generate a new dictionary. These so-called pivot language based methods rely on the idea that the lookup of a word in an uncommon language through a third, intermediated language can be automated. Tanaka and Umemura’s method uses bidirectional sourcepivot and pivot-target dictionaries (harmonized dictionaries). Correct translation pairs are selec</context>
</contexts>
<marker>Brown, Cocke, Pietra, S, Jelinek, Mercer, Roossin, P, 1998</marker>
<rawString>Brown, P., Cocke, J., Della Pietra, S., Della Pietra, V., Jelinek, F., Mercer, R., Roossin, P. 1998. A Statistical Approach to Language Translation, Proceedings of COLING-88, pp. 71-76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R D Brown</author>
</authors>
<title>Automated Dictionary Extraction for Knowledge-Free Example-Based Translation,</title>
<date>1997</date>
<booktitle>Proceedings of the 7th International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>111--118</pages>
<contexts>
<context position="4049" citStr="Brown, 1997" startWordPosition="586" endWordPosition="587">Hungarian language pair. We evaluate the generated dictionary, performing also a comparative evaluation with two other pivotlanguage based methods. Finally we present our conclusions. 2 Related works 2.1 Bilingual dictionary generation Various corpus based, statistical methods with very good recall and precision were developed starting from the 1980’s, most notably using the 862 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 862–870, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP Dice-coefficient (Kay &amp; Röscheisen, 1993), correspondence-tables (Brown, 1997), or mutual information (Brown et al., 1998). As an answer to the corpus-based method’s biggest disadvantage, namely the need for a large bilingual corpus, in the 1990’s Tanaka and Umemura (1994) presented a new approach. As a resource, they only use dictionaries to and from a pivot language to generate a new dictionary. These so-called pivot language based methods rely on the idea that the lookup of a word in an uncommon language through a third, intermediated language can be automated. Tanaka and Umemura’s method uses bidirectional sourcepivot and pivot-target dictionaries (harmonized dictio</context>
</contexts>
<marker>Brown, 1997</marker>
<rawString>Brown, R.D. 1997. Automated Dictionary Extraction for Knowledge-Free Example-Based Translation, Proceedings of the 7th International Conference on Theoretical and Methodological Issues in Machine Translation, pp. 111-118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Isahara</author>
<author>F Bond</author>
<author>K Uchimoto</author>
<author>M Uchiyama</author>
<author>K Kanzaki</author>
</authors>
<date>2008</date>
<booktitle>Development of Japanese WordNet, Proceedings of LREC-2008.</booktitle>
<contexts>
<context position="7183" citStr="Isahara et al. 2008" startWordPosition="1075" endWordPosition="1078">sing (NLP), where large amount of structured linguistic data is needed. The appearance of WordNet (Miller et al., 1990) had a big impact in NLP, since not only did it provide one of the first wide-range collections of linguistic data in electronic format, but it also offered a relatively simple structure that can be implemented with other languages as well. In the last decades since the first, English WordNet, numerous languages adopted the WordNet structure, thus creating a potential large multilingual network. The Japanese language is one of the most recent ones added to the WordNet family (Isahara et al. 2008), but the Hungarian WordNet is still under development (Prószéky et al. 2001; Miháltz and Prószéky 2004). Multilingual projects, such as EuroWordNet (Vossen 1998; Peters et al. 1998), Balkanet (Stamou et al. 2002) or Multilingual Central Repository (Agirre et al. 2007) aim to solve numerous problems in natural language processing. EuroWordNet was specifically designed for word disambiguation purposes in cross-language information retrieval (Vossen 1998). The internal structure of the multilingual WordNets itself can be a good starting point for bilingual dictionary generation. In case of EuroW</context>
</contexts>
<marker>Isahara, Bond, Uchimoto, Uchiyama, Kanzaki, 2008</marker>
<rawString>Isahara, H., Bond, F., Uchimoto, K., Uchiyama, M., Kanzaki, K. 2008. Development of Japanese WordNet, Proceedings of LREC-2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Isahara</author>
</authors>
<date>2007</date>
<booktitle>EDR Electronic Dictionary – present status (EDR 電子化辞書の現状), NICT-EDR symposium,</booktitle>
<pages>1--14</pages>
<note>(in Japanese)</note>
<contexts>
<context position="26735" citStr="Isahara, 2007" startWordPosition="4201" endWordPosition="4202">enerate the translations of low-frequency keywords, because they tend to be less ambiguous. On the contrary, the ambiguity of the high frequency words is much higher than their low-frequency counterparts, and as a result conventional methods fail to translate a considerable number of them. However, this discrepancy is not reflected in the traditional recall evaluation, since each 867 word has an equal weight, regardless of its frequency of use. As a result, we performed a frequency weighted recall evaluation. We used a Japanese frequency dictionary (FD) generated from the Japanese EDR corpus (Isahara, 2007) to weight each Japanese entry. Setting the standard to the frequency dictionary (its recall value being 100), we automatically search for each entry (w) from the frequency dictionary, looking whether or not it is included in the bilingual dictionary (WD). If it is recalled, we weight it with its frequency from the frequency dictionary. frequency ( w) w W ∈ recall = � D ( ) ⋅1 00 (4) w frequency w F ∈ D method recall our method 51.68 Sjöbergh method 37.03 Tanaka method 30.76 initial candidates 51.68 Japanese-English(*) 73.23 Table 4: Recall evaluation results (* marks a manually created dictio</context>
</contexts>
<marker>Isahara, 2007</marker>
<rawString>Isahara, H. 2007. EDR Electronic Dictionary – present status (EDR 電子化辞書の現状), NICT-EDR symposium, pp. 1-14. (in Japanese)</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
<author>M Röscheisen</author>
</authors>
<title>Text-Translation Alignment,</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>121--142</pages>
<contexts>
<context position="4012" citStr="Kay &amp; Röscheisen, 1993" startWordPosition="580" endWordPosition="583"> of our proposal, exemplified with the Japanese-Hungarian language pair. We evaluate the generated dictionary, performing also a comparative evaluation with two other pivotlanguage based methods. Finally we present our conclusions. 2 Related works 2.1 Bilingual dictionary generation Various corpus based, statistical methods with very good recall and precision were developed starting from the 1980’s, most notably using the 862 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 862–870, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP Dice-coefficient (Kay &amp; Röscheisen, 1993), correspondence-tables (Brown, 1997), or mutual information (Brown et al., 1998). As an answer to the corpus-based method’s biggest disadvantage, namely the need for a large bilingual corpus, in the 1990’s Tanaka and Umemura (1994) presented a new approach. As a resource, they only use dictionaries to and from a pivot language to generate a new dictionary. These so-called pivot language based methods rely on the idea that the lookup of a word in an uncommon language through a third, intermediated language can be automated. Tanaka and Umemura’s method uses bidirectional sourcepivot and pivot-t</context>
</contexts>
<marker>Kay, Röscheisen, 1993</marker>
<rawString>Kay, M., Röscheisen, M. 1993. Text-Translation Alignment, Computational Linguistics, 19(1), pp. 121-142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Miháltz</author>
<author>G Prószéky</author>
</authors>
<title>Results and Evaluation of Hungarian Nominal WordNet</title>
<date>2004</date>
<booktitle>v1.0, Proceedings of the Second Global WordNet Conference,</booktitle>
<pages>175--180</pages>
<contexts>
<context position="7287" citStr="Miháltz and Prószéky 2004" startWordPosition="1092" endWordPosition="1095">(Miller et al., 1990) had a big impact in NLP, since not only did it provide one of the first wide-range collections of linguistic data in electronic format, but it also offered a relatively simple structure that can be implemented with other languages as well. In the last decades since the first, English WordNet, numerous languages adopted the WordNet structure, thus creating a potential large multilingual network. The Japanese language is one of the most recent ones added to the WordNet family (Isahara et al. 2008), but the Hungarian WordNet is still under development (Prószéky et al. 2001; Miháltz and Prószéky 2004). Multilingual projects, such as EuroWordNet (Vossen 1998; Peters et al. 1998), Balkanet (Stamou et al. 2002) or Multilingual Central Repository (Agirre et al. 2007) aim to solve numerous problems in natural language processing. EuroWordNet was specifically designed for word disambiguation purposes in cross-language information retrieval (Vossen 1998). The internal structure of the multilingual WordNets itself can be a good starting point for bilingual dictionary generation. In case of EuroWordNet, besides the internal design of the initial WordNet for each language, an Inter-Lingual-Index int</context>
</contexts>
<marker>Miháltz, Prószéky, 2004</marker>
<rawString>Miháltz, M., Prószéky, G. 2004. Results and Evaluation of Hungarian Nominal WordNet v1.0, Proceedings of the Second Global WordNet Conference, pp. 175-180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K J Miller</author>
</authors>
<title>Introduction to WordNet: An Online Lexical Database,</title>
<date>1990</date>
<journal>Int J Lexicography</journal>
<volume>3</volume>
<issue>4</issue>
<pages>235--244</pages>
<contexts>
<context position="6682" citStr="Miller et al., 1990" startWordPosition="992" endWordPosition="995"> (2001) proposed a method with multiple pivots (English and Kanji/Hanzi characters) to translate SinoKorean entries. Bond and Ogura describe a Japanese-Malay dictionary that uses a novel technique in its improved matching through normalization of the pivot language, by means of semantic classes, but only for nouns (2007). Besides English, they also use Chinese as a second pivot. 2.2 Lexical database in lexical acquisition Large lexical databases are vital for many areas in natural language processing (NLP), where large amount of structured linguistic data is needed. The appearance of WordNet (Miller et al., 1990) had a big impact in NLP, since not only did it provide one of the first wide-range collections of linguistic data in electronic format, but it also offered a relatively simple structure that can be implemented with other languages as well. In the last decades since the first, English WordNet, numerous languages adopted the WordNet structure, thus creating a potential large multilingual network. The Japanese language is one of the most recent ones added to the WordNet family (Isahara et al. 2008), but the Hungarian WordNet is still under development (Prószéky et al. 2001; Miháltz and Prószéky </context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>Miller G.A., Beckwith R., Fellbaum C., Gross D., Miller K.J. (1990). Introduction to WordNet: An Online Lexical Database, Int J Lexicography 3(4), pp. 235-244.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Paik</author>
<author>F Bond</author>
<author>S Shirai</author>
</authors>
<date>2001</date>
<booktitle>Using Multiple Pivots to align Korean and Japanese Lexical Resources, NLPRS-2001,</booktitle>
<pages>63--70</pages>
<location>Tokyo, Japan.</location>
<contexts>
<context position="6069" citStr="Paik et al. (2001)" startWordPosition="894" endWordPosition="897"> used these two methods as baselines for comparative evaluation. There are numerous refinements of the above methods, but for various reasons they cannot be implemented with any arbitrary language pair. Shirai and Yamamoto (2001) used English to design a Korean-Japanese dictionary, but because the usage of language-specific information, they conclude that their method ‘can be considered to be applicable to cases of generating among languages similar to Japanese or Korean through English’. In other cases, only a small portion of the lexical inventory of the language is chosen to be translated: Paik et al. (2001) proposed a method with multiple pivots (English and Kanji/Hanzi characters) to translate SinoKorean entries. Bond and Ogura describe a Japanese-Malay dictionary that uses a novel technique in its improved matching through normalization of the pivot language, by means of semantic classes, but only for nouns (2007). Besides English, they also use Chinese as a second pivot. 2.2 Lexical database in lexical acquisition Large lexical databases are vital for many areas in natural language processing (NLP), where large amount of structured linguistic data is needed. The appearance of WordNet (Miller </context>
</contexts>
<marker>Paik, Bond, Shirai, 2001</marker>
<rawString>Paik, K., Bond, F., Shirai, S. 2001. Using Multiple Pivots to align Korean and Japanese Lexical Resources, NLPRS-2001, pp. 63-70, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Peters</author>
<author>P Vossen</author>
<author>P Díez-Orzas</author>
<author>G Adriaens</author>
</authors>
<date>1998</date>
<booktitle>Cross-linguistic Alignment of Wordnets with an Inter-Lingual-Index, Computers and the Humanities 32,</booktitle>
<pages>221--251</pages>
<contexts>
<context position="7365" citStr="Peters et al. 1998" startWordPosition="1103" endWordPosition="1106">he first wide-range collections of linguistic data in electronic format, but it also offered a relatively simple structure that can be implemented with other languages as well. In the last decades since the first, English WordNet, numerous languages adopted the WordNet structure, thus creating a potential large multilingual network. The Japanese language is one of the most recent ones added to the WordNet family (Isahara et al. 2008), but the Hungarian WordNet is still under development (Prószéky et al. 2001; Miháltz and Prószéky 2004). Multilingual projects, such as EuroWordNet (Vossen 1998; Peters et al. 1998), Balkanet (Stamou et al. 2002) or Multilingual Central Repository (Agirre et al. 2007) aim to solve numerous problems in natural language processing. EuroWordNet was specifically designed for word disambiguation purposes in cross-language information retrieval (Vossen 1998). The internal structure of the multilingual WordNets itself can be a good starting point for bilingual dictionary generation. In case of EuroWordNet, besides the internal design of the initial WordNet for each language, an Inter-Lingual-Index interlinks word meaning across languages is implemented (Peters et al. 1998). How</context>
</contexts>
<marker>Peters, Vossen, Díez-Orzas, Adriaens, 1998</marker>
<rawString>Peters, W., Vossen, P., Díez-Orzas, P., Adriaens, G. 1998. Cross-linguistic Alignment of Wordnets with an Inter-Lingual-Index, Computers and the Humanities 32, pp. 221–251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Prószéky</author>
<author>M Miháltz</author>
<author>D Nagy</author>
</authors>
<title>Toward a Hungarian WordNet,</title>
<date>2001</date>
<booktitle>Proceedings of the NAACL 2001 Workshop on WordNet and Other Lexical Resources,</booktitle>
<location>Pittsburgh,</location>
<contexts>
<context position="7259" citStr="Prószéky et al. 2001" startWordPosition="1088" endWordPosition="1091">appearance of WordNet (Miller et al., 1990) had a big impact in NLP, since not only did it provide one of the first wide-range collections of linguistic data in electronic format, but it also offered a relatively simple structure that can be implemented with other languages as well. In the last decades since the first, English WordNet, numerous languages adopted the WordNet structure, thus creating a potential large multilingual network. The Japanese language is one of the most recent ones added to the WordNet family (Isahara et al. 2008), but the Hungarian WordNet is still under development (Prószéky et al. 2001; Miháltz and Prószéky 2004). Multilingual projects, such as EuroWordNet (Vossen 1998; Peters et al. 1998), Balkanet (Stamou et al. 2002) or Multilingual Central Repository (Agirre et al. 2007) aim to solve numerous problems in natural language processing. EuroWordNet was specifically designed for word disambiguation purposes in cross-language information retrieval (Vossen 1998). The internal structure of the multilingual WordNets itself can be a good starting point for bilingual dictionary generation. In case of EuroWordNet, besides the internal design of the initial WordNet for each language</context>
</contexts>
<marker>Prószéky, Miháltz, Nagy, 2001</marker>
<rawString>Prószéky, G., Miháltz, M., Nagy, D. 2001. Toward a Hungarian WordNet, Proceedings of the NAACL 2001 Workshop on WordNet and Other Lexical Resources, Pittsburgh, June 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sjöbergh</author>
</authors>
<title>Creating a free Japanese-English lexicon,</title>
<date>2005</date>
<booktitle>Proceedings of PACLING,</booktitle>
<pages>296--300</pages>
<contexts>
<context position="4932" citStr="Sjöbergh (2005)" startWordPosition="723" endWordPosition="724">nd from a pivot language to generate a new dictionary. These so-called pivot language based methods rely on the idea that the lookup of a word in an uncommon language through a third, intermediated language can be automated. Tanaka and Umemura’s method uses bidirectional sourcepivot and pivot-target dictionaries (harmonized dictionaries). Correct translation pairs are selected by means of inverse consultation, a method that relies on counting the number of pivot language definitions of the source word, through which the target language definitions can be identified (Tanaka and Umemura, 1994). Sjöbergh (2005) also presented an approach to pivot language based dictionary generation. When generating his English pivoted SwedishJapanese dictionary, each Japanese-to-English description is compared with each Swedish-toEnglish description. Scoring is based on word overlap, weighted with inverse document frequency; the best matches being selected as translation pairs. These two approaches described above are the best performing ones that are general enough to be applicable with other language pairs as well. In our research we used these two methods as baselines for comparative evaluation. There are numero</context>
</contexts>
<marker>Sjöbergh, 2005</marker>
<rawString>Sjöbergh, J. 2005. Creating a free Japanese-English lexicon, Proceedings of PACLING, pp. 296-300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Shirai</author>
<author>K Yamamoto</author>
</authors>
<title>Linking English words in two bilingual dictionaries to generate another pair dictionary, ICCPOL-2001,</title>
<date>2001</date>
<pages>174--179</pages>
<contexts>
<context position="5680" citStr="Shirai and Yamamoto (2001)" startWordPosition="831" endWordPosition="834">nese dictionary, each Japanese-to-English description is compared with each Swedish-toEnglish description. Scoring is based on word overlap, weighted with inverse document frequency; the best matches being selected as translation pairs. These two approaches described above are the best performing ones that are general enough to be applicable with other language pairs as well. In our research we used these two methods as baselines for comparative evaluation. There are numerous refinements of the above methods, but for various reasons they cannot be implemented with any arbitrary language pair. Shirai and Yamamoto (2001) used English to design a Korean-Japanese dictionary, but because the usage of language-specific information, they conclude that their method ‘can be considered to be applicable to cases of generating among languages similar to Japanese or Korean through English’. In other cases, only a small portion of the lexical inventory of the language is chosen to be translated: Paik et al. (2001) proposed a method with multiple pivots (English and Kanji/Hanzi characters) to translate SinoKorean entries. Bond and Ogura describe a Japanese-Malay dictionary that uses a novel technique in its improved match</context>
</contexts>
<marker>Shirai, Yamamoto, 2001</marker>
<rawString>Shirai, S., Yamamoto, K. 2001. Linking English words in two bilingual dictionaries to generate another pair dictionary, ICCPOL-2001, pp. 174-179.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stamou</author>
<author>K Oflazer</author>
<author>K Pala</author>
<author>D Christoudoulakis</author>
<author>D Cristea</author>
<author>D Tufi�</author>
<author>S Koeva</author>
<author>G Totkov</author>
<author>D Dutoit</author>
<author>M Grigoriadou</author>
</authors>
<title>BalkaNet: A Multilingual Semantic Network for the Balkan Languages,</title>
<date>1997</date>
<booktitle>In Proceedings of the International Wordnet Conference, Mysore,</booktitle>
<marker>Stamou, Oflazer, Pala, Christoudoulakis, Cristea, Tufi�, Koeva, Totkov, Dutoit, Grigoriadou, 1997</marker>
<rawString>Stamou, S., Oflazer, K., Pala, K., Christoudoulakis, D., Cristea, D., Tufi�, D., Koeva, S., Totkov, G., Dutoit, D., Grigoriadou, M. 1997. BalkaNet: A Multilingual Semantic Network for the Balkan Languages, In Proceedings of the International Wordnet Conference, Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Tanaka</author>
<author>K Umemura</author>
</authors>
<title>Construction of a bilingual dictionary intermediated by a third language,</title>
<date>1994</date>
<booktitle>Proceedings of COLING-94,</booktitle>
<pages>297--303</pages>
<contexts>
<context position="4244" citStr="Tanaka and Umemura (1994)" startWordPosition="615" endWordPosition="618">. 2 Related works 2.1 Bilingual dictionary generation Various corpus based, statistical methods with very good recall and precision were developed starting from the 1980’s, most notably using the 862 Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 862–870, Singapore, 6-7 August 2009. c�2009 ACL and AFNLP Dice-coefficient (Kay &amp; Röscheisen, 1993), correspondence-tables (Brown, 1997), or mutual information (Brown et al., 1998). As an answer to the corpus-based method’s biggest disadvantage, namely the need for a large bilingual corpus, in the 1990’s Tanaka and Umemura (1994) presented a new approach. As a resource, they only use dictionaries to and from a pivot language to generate a new dictionary. These so-called pivot language based methods rely on the idea that the lookup of a word in an uncommon language through a third, intermediated language can be automated. Tanaka and Umemura’s method uses bidirectional sourcepivot and pivot-target dictionaries (harmonized dictionaries). Correct translation pairs are selected by means of inverse consultation, a method that relies on counting the number of pivot language definitions of the source word, through which the t</context>
</contexts>
<marker>Tanaka, Umemura, 1994</marker>
<rawString>Tanaka, K., Umemura, K. 1994. Construction of a bilingual dictionary intermediated by a third language, Proceedings of COLING-94, pp. 297-303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<title>Introduction to EuroWordNet.</title>
<date>1998</date>
<journal>Computers and the Humanities</journal>
<volume>32</volume>
<pages>73--89</pages>
<note>Special Issue on EuroWordNet.</note>
<contexts>
<context position="7344" citStr="Vossen 1998" startWordPosition="1101" endWordPosition="1102">vide one of the first wide-range collections of linguistic data in electronic format, but it also offered a relatively simple structure that can be implemented with other languages as well. In the last decades since the first, English WordNet, numerous languages adopted the WordNet structure, thus creating a potential large multilingual network. The Japanese language is one of the most recent ones added to the WordNet family (Isahara et al. 2008), but the Hungarian WordNet is still under development (Prószéky et al. 2001; Miháltz and Prószéky 2004). Multilingual projects, such as EuroWordNet (Vossen 1998; Peters et al. 1998), Balkanet (Stamou et al. 2002) or Multilingual Central Repository (Agirre et al. 2007) aim to solve numerous problems in natural language processing. EuroWordNet was specifically designed for word disambiguation purposes in cross-language information retrieval (Vossen 1998). The internal structure of the multilingual WordNets itself can be a good starting point for bilingual dictionary generation. In case of EuroWordNet, besides the internal design of the initial WordNet for each language, an Inter-Lingual-Index interlinks word meaning across languages is implemented (Pet</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Vossen, P. 1998. Introduction to EuroWordNet. Computers and the Humanities 32: 73-89 Special Issue on EuroWordNet.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>