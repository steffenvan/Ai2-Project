<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.023801">
<title confidence="0.976115">
ASAP: Automatic Semantic Alignment for Phrases
</title>
<author confidence="0.99052">
Ana O. Alves
</author>
<affiliation confidence="0.895617333333333">
CISUC - University of Coimbra
and Polytechnic Institute of Coimbra
Portugal
</affiliation>
<email confidence="0.981837">
ana@dei.uc.pt
</email>
<sectionHeader confidence="0.994201" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.980078272727273">
In this paper we describe the ASAP sys-
tem (Automatic Semantic Alignment for
Phrases)1 which participated on the Task
1 at the SemEval-2014 contest (Marelli et
al., 2014a). Our assumption is that STS
(Semantic Text Similarity) follows a func-
tion considering lexical, syntactic, seman-
tic and distributional features. We demon-
strate the learning process of this function
without any deep preprocessing achieving
an acceptable correlation.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999843954545454">
Evaluation of compositional semantic models on
full sentences through semantic relatedness and
textual entailment, title of this task on SemEval,
aims to collect systems and approaches able
to predict the difference of meaning between
phrases and sentences based on their included
words (Baroni and Zamparelli, 2010; Grefenstette
and Sadrzadeh, 2011; Mitchell and Lapata, 2010;
Socher et al., 2012).
Our contribution is in the use of complemen-
tary features in order to learn the function STS,
a part of this challenge. Rather than specifying
rules, constraints and lexicons manually, we advo-
cate a system for automatically acquiring linguis-
tic knowledge using machine learning (ML) meth-
ods. For this we apply some preprocessing tech-
niques over the training set in order to find differ-
ent types of features. Related to the semantic as-
pect, we make use of known semantic relatedness
and similarity measures on WordNet, in this case,
applied to see the relatedness/similarity between
phrases from sentences.
</bodyText>
<footnote confidence="0.969962">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
1This work was supported by the Crowds project-
PTDC/EIA-EIA/115014/2009
</footnote>
<note confidence="0.8671158">
Adriana Ferrugento
Mariana Lourenc¸o
Filipe Rodrigues
CISUC - University of Coimbra
Portugal
</note>
<email confidence="0.8809975">
{aferr,mrlouren}@student.dei.uc.pt
fmpr@dei.uc.pt
</email>
<bodyText confidence="0.999894">
Considering the problem of modeling a text cor-
pus to find short descriptions of documents, we
aim an efficient processing of large collections
while preserving the essential statistical relation-
ships that are useful for, in this case, similarity
judgment. Therefore we also apply topic model-
ing in order to get topic distribution over each sen-
tence set. These features are then used to feed an
ensemble algorithm to learn the STS function.
</bodyText>
<sectionHeader confidence="0.98838" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.943228">
2.1 WordNet
</subsectionHeader>
<bodyText confidence="0.999893464285714">
WordNet (Miller, 1995) is a computational lexicon
of English created and maintained at Princeton
University. It encodes concepts in terms of sets of
synonyms (called synsets). A synset can be seen
as a set of word senses all expressing the same
meaning. Each word sense uniquely identifies
a single synset. For instance, car#n#1 uses
the notation followed by WordNet and subscript
word#p#n where p denotes the part-of-speech
tag and n the word’s sense identifier, respec-
tively. In this case, the corresponding synset
car#n#1, auto#n#1, automobile#n#1,
machine#n#6, motorcar#n#1 is uniquely
determined. As words are not always so ambigu-
ous, a word w#p is said to be monosemous when
it can convey only one meaning. Alternatively,
w#p is polysemous if it can convey more mean-
ings each one represented by a sense number s in
w#p#s. For each synset, WordNet provides the
following information: A gloss, that is, a textual
definition of the synset; Semantic relations, which
connect pairs of synsets. In this context we focus
our attention on the Hypernym/Hyponym relation
which refers to inheritance between nouns, also
known as an is-a, or kind-of relation and their
respective inverses. Y is a hypernym of X if
every X is a (kind of) Y (motor vehicle#n#1 is a
hypernym of car#n#1 and, conversely, car#n#1 is
</bodyText>
<page confidence="0.985271">
104
</page>
<note confidence="0.784841">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 104–108,
Dublin, Ireland, August 23-24, 2014.
</note>
<tableCaption confidence="0.38719">
a hyponym of vehicle#n#1).
</tableCaption>
<subsectionHeader confidence="0.997558">
2.2 Semantic similarity
</subsectionHeader>
<bodyText confidence="0.99998441025641">
There are mainly two approaches to semantic sim-
ilarity. First approach is making use of a large cor-
pus and gathering statistical data from this corpus
to estimate a score of semantic similarity. Second
approach makes use of the relations and the en-
tries of a thesaurus (Lesk, 1986), which is gener-
ally a hand-crafted lexical database such as Word-
Net (Banerjee and Pedersen, 2003). Hybrid ap-
proaches combines both methods (Jiang and Con-
rath, 1997). Semantic similarity can be seen
as a different measure from semantic related-
ness since the former compute the proximity be-
tween concepts in a given concept hierarchy (e.g.
car#n#1 is similar to motorcycle#n); while the
later the common use of both concepts together
(e.g. car#n#1 is related to tire#n).
The Lesk algorithm (Lesk, 1986) uses dictio-
nary definitions (glosses) to disambiguate a poly-
semous word in a sentence context. The major ob-
jective of his idea is to count the number of words
that are shared between two glosses, but, some-
times, dictionary glosses are often quite brief, and
may not include sufficient vocabulary to identify
related sense. In this sense, Banerjee and Peder-
sen (Banerjee and Pedersen, 2003) adapted this al-
gorithm to use WordNet as the dictionary for the
word definitions and extended this metric to use
the rich network of relationships between concepts
present in WordNet.
The Jiang and Conrath similarity measure
(Jiang and Conrath, 1997) computes the informa-
tion shared between two concepts. The shared
information is determined by Information content
of the most specific subsume of the two concepts
in the hierarchy. Furthermore this measure com-
bines the distance between this subsuming concept
and the other two concepts, counting the edge-
based distance from them in the WordNet Hyper-
nym/Hyponym hierarchy.
</bodyText>
<subsectionHeader confidence="0.996633">
2.3 Topic Modeling
</subsectionHeader>
<bodyText confidence="0.999933391304348">
Topic models are based upon the idea that docu-
ments are mixtures of topics, where a topic is a
probability distribution over words. A topic model
is a generative model for documents: it specifies
a simple probabilistic procedure by which docu-
ments can be generated. To make a new document,
one chooses a distribution over topics. Then, for
each word in that document, one chooses a topic at
random according to this distribution, and draws a
word from that topic.
Latent Dirichilet allocation (LDA) is a genera-
tive probabilistic topic model of a corpus (Blei et
al., 2003). The basic idea is that documents are
represented as random mixtures over latent top-
ics, where each topic is characterized by a distri-
bution over words. This process does not make
any assumptions about the order of words as they
appear in documents. The only information rel-
evant to the model is the number of times words
are produced. This is known as the bag-of-words
assumption. The main variables of interest in the
model are the topic-word distributions Φ and the
topic distributions θ for each document.
</bodyText>
<sectionHeader confidence="0.982941" genericHeader="method">
3 Proposed Approach
</sectionHeader>
<bodyText confidence="0.999993">
Our approach to STS is mainly founded on the
idea of learning a regression function that com-
putes that similarity using other variable/features
as components. Before obtaining those features,
sentences are preprocessed trough known state-of-
the-art Natural Language techniques. The result-
ing preprocessed sentences are then lexically, syn-
tactically and semantically decomposed in order to
obtain different partial similarities. These partial
similarities are the features used in the supervised
learning. These specific stages in our system are
explained in detail in the following sections.
</bodyText>
<subsectionHeader confidence="0.998953">
3.1 Natural Language Preprocessing
</subsectionHeader>
<bodyText confidence="0.999950578947369">
Before computing partial similarities considering
different properties of sentences, we need to apply
some known Natural Language techniques. For
this purpose, we chose OpenNLP2 as an open-
source tool suite which contains a variety of Java-
based NLP components. Our focus is here on three
core NLP components: tokenization, POS tagging
and chunking. Besides the fact OpenNLP also of-
fers a stemmer for English we adopted other im-
plementation self-contained in the specific frame-
work for Topic Modeling (detailed in section 3.3).
OpenNLP is a homogeneous package based on
a single machine learning approach, maximum en-
tropy (ME) (Berger et al., 1996). Each OpenNLP
tool requires an ME model that contains statis-
tics about the components default features com-
bining diverse contextual information. OpenNLP
offers the possibility of both create component or
use pre-built models create for different languages.
</bodyText>
<footnote confidence="0.964565">
2http://opennlp.sourceforge.net
</footnote>
<page confidence="0.9978">
105
</page>
<bodyText confidence="0.999722375">
On one side, components can be trained and cus-
tomizable models are built for the language and/or
domain in study. On the other, the availability
of pre-trained models allows the immediate appli-
cation of such tools on a new problem. We fol-
lowed the second approach since the sentences are
of common-sense and not about a specific domain
and are in English3.
</bodyText>
<subsectionHeader confidence="0.999312">
3.2 Feature Engineering
</subsectionHeader>
<bodyText confidence="0.999987066666667">
Features, sometimes called attributes, encode in-
formation from raw data that allows machine
learning algorithms estimate an unknown value.
We focus on, what we call, light features since
they are completely automatic and unsupervised
computed, non-requiring a specific labeled dataset
for this phase. Each feature is computed as a par-
tial similarity metric, which will later feed the pos-
terior regression analysis. This process is fully
automatized, being all features extracted using a
pipeline from OpenNLP and other tools that will
be introduced in the specific stage where they are
used. For convenience and an easier identification
in the later machine learning process, we set for
each feature an id in the form f#n, n E {1..65}.
</bodyText>
<subsectionHeader confidence="0.89249">
3.2.1 Lexical Features
</subsectionHeader>
<bodyText confidence="0.999969571428571">
Some basic similarity metrics are used as features
related exclusively with word forms. In this set
we include: number of negative words4 for each
sentence (f1 and f2 respectively), and the abso-
lute value of the difference of these counts (f3 =
f1 − f2 ); the absolute value of the difference of
overlapping words for each sentence pair (f4..7)5.
</bodyText>
<subsectionHeader confidence="0.587989">
3.2.2 Syntactic Features
</subsectionHeader>
<bodyText confidence="0.998744">
OpenNLP tokenization, POS (Part-of-Speech)
tagging6 and text chunking applied on a pipeline
fashion allows the identification of (NPs) Noun
Phrases, VPs (Verbal Phrases) and (Prepositional
Phrases) in sentences. Heuristically, these NPs are
</bodyText>
<footnote confidence="0.967519928571429">
3OpenNLP offers, for the vast majority of components, at
least one pre-trained model for this language.
4The Snowball stop word list(Porter, 2001) was used and
those words expressing negation were identified (such as:
never, not, neither, no, nobody, aren’t, isn’t, don’t, doesn’t,
hasn’t, hadn’t, haven’t)
5Thanks to the SemEval organizers in making avail-
able the python script which computes baselines com-
pute overlap baseline.py which was applied using different
setting for stop word removal, from 0 to 3.
6As alternative models are available, the Maxent
model with tag dictionary was used on this compo-
nent. Available at http://opennlp.sourceforge.net/models-
1.5/en-pos-maxent.bin
</footnote>
<bodyText confidence="0.999779714285714">
further identified as subjects if they are in the be-
ginning of sentences. This kind of shallow parser
will be useful to identify the syntactic structure of
sentences. Considering only this property, differ-
ent features were computed as the absolute value
of the difference of the number of NPs (f8), VPs
(f9) and PPs(f10) for each sentence pair.
</bodyText>
<subsectionHeader confidence="0.889268">
3.2.3 Semantic Features
</subsectionHeader>
<bodyText confidence="0.999980257142857">
WordNet::Similarity (Pedersen et al., 2004) is a
freely available software package for measuring
the semantic similarity or relatedness between a
pair of concepts (or word senses). At this stage we
have for each sentence the subject identified as the
first NP beginning a sentence.
This NP can be composed of a simple or com-
pound noun, in a root form (lemma) or in a
inflected form (plural) (e.g. electrics or eco-
nomic electric cars). WorNet::Similarity pack-
age also contains a lemmatizer, in the mod-
ule WordNet::QueryData, which compare a in-
flected word form and return all WordNet entries
which can be the root form of this word. This
search is made in all four morphological cate-
gories in WordNet (Adjectives, Adverbs, Nouns
and Verbs), except when indicated the POS in
the end of the queried word, the lemmatizer only
see in that specific category (e.g. flies#n re-
turns flies#n, fly#n, while flies returns more
entries: flies#n, fly#n, fly#v). Therefore, a
lemmatized is successively applied over the Sub-
jects found for each pair of sentences. The com-
pound subjects are reduced from left to right until
a head noun been found as a valid WordNet en-
try (e.g. the subject economicelectriccars is re-
duced until the valid entry electriccar which is
present on WordNet).
After all the subjects been found and a valid
WordNet entry has been matched semantic simi-
larity (f11) (Jiang and Conrath, 1997) and seman-
tic relatedness (f12) (Lesk, 1986) is computed
for each sentence pair. In the case where pair
word#n has multiple senses, the one that maxi-
mizes partial similarity is selected.
</bodyText>
<subsectionHeader confidence="0.996685">
3.3 Distributional Features
</subsectionHeader>
<bodyText confidence="0.999697166666667">
The distribution of topics over documents (in our
case, sentences) may contribute to model Distri-
butional Semantic in texts since in the way that
the model is defined, there is no notion of mu-
tual exclusivity that restricts words to be part of
one topic only. This allows topic models to cap-
</bodyText>
<page confidence="0.996793">
106
</page>
<bodyText confidence="0.999959928571428">
ture polysemy, where the same word has multiple
meanings. In this sense we can see topics as nat-
ural word sense contexts where words appear in
different topics with distinct senses.
Gensim (ˇReh˚uˇrek and Sojka, 2010) is a machine
learning framework for Topic Modeling which
includes several preprocessing techniques such
as stop-word removal and TF-IDF. TF-IDF is a
standard statistical method that combines the fre-
quency of a term in a particular document with its
inverse document frequency in general use (Salton
and Buckley, 1988). This score is high for rare
terms that appear frequently in a document and are
therefore more likely to be significant. In a prag-
matic view, tf-idft,d assigns to term t a weight in
document d that is: highest when t occurs many
times within a small number of documents; lower
when the term occurs fewer times in a document,
or occurs in many documents; lowest when the
term occurs in virtually all documents.
Gensim computes a distribution of 25 topics
over sentences not and using TF-IDF (f13...37
and f38...63). Each feature is the absolute value
of the difference of topici (i.e. topic[i] =
|topic[i]s1 − topic[i]s2|). Euclidean distance over
the difference of topic distribution between sen-
tence pairs in each case (without and with TF-IDF)
was also considered as a feature (f64 and f65).
</bodyText>
<subsectionHeader confidence="0.995035">
3.4 Supervised Learning
</subsectionHeader>
<bodyText confidence="0.9999583">
WEKA(Hall et al., 2009) is a large collection of
state-of-the-art machine learning algorithms writ-
ten in Java. WEKA contains tools for classifica-
tion, regression, classifier ensemble, and others.
Considering the developer version 3.7.117 we used
the following experiment setup considering the 65
features previously computed for both sentence
dataset (train and test) (Marelli et al., 2014b).
One of four approaches is commonly adopted
for building classifier ensembles each one focus-
ing a different level of action. Approach A con-
cerns the different ways of combining the results
from the classifiers, but there is no evidence that
this strategy is better than using different mod-
els (Approach B). At feature level (Approach C)
different feature subsets can be used for the clas-
sifiers, either if they use the same classification
model or not. Finally, the data sets can be modified
so that each classifier in the ensemble is trained on
its own data set (Approach D).
</bodyText>
<footnote confidence="0.719728">
7http://www.cs.waikato.ac.nz/ml/weka/downloading.html
</footnote>
<bodyText confidence="0.99972052">
Different methods for generating and combin-
ing models exist, like Stacking (Seewald, 2002)
(Approach B). These combined models share
sometimes however the disadvantage of being dif-
ficult to analyse, once they can comprise dozens of
individual classifiers. Stacking is used to combine
different types of classifiers and it demands the use
of another learner algorithm to predict which of
the models would be the most reliable for each
case. This combination is done using a meta-
learner, another learner scheme that combines the
output of the base learners. The base learners
are generally called level-0 models, and the meta-
learner is a level-1 model. The predictions of the
base learners are input to the meta-learner.
In WEKA, there is a meta classifier called
”Stacking”.We use this stacking ensemble com-
bining two level-0 models: a K-Nearest Neigh-
bour classifier (K = 1) (Aha et al., 1991); and
a Linear Regression model without any attribute
selection method (−S1) and the ridge parameter
by default (1.0 exp −8). The meta-classifier was
M5P which implements base routines for gener-
ating M5 Model trees and rules (Quinlan, 1992;
Wang and Witten, 1997).
</bodyText>
<sectionHeader confidence="0.998661" genericHeader="conclusions">
4 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999986291666667">
Our contribution is in the use of complementary
features in order to learn the function of STS, a
part of the challenge of building Compositional
Distributional Semantic Models. For this we ap-
plied some preprocessing tasks over the sentence
set in order to find lexical, syntactic, semantic and
distributional features. On the semantic aspect, we
made use of known semantic relatedness and sim-
ilarity measures on WordNet, in this case, applied
to see the relatedness/similarity between phrases
from sentences. We also applied topic modeling
in order to get topic distributions over set of sen-
tences. These features were then used to feed an
ensemble learning algorithm in order to learn the
STS function. This was achieved with a Pearson’s
r of 0.62780. One direction to follow is to find
where the ensemble is failing and try to comple-
ment the feature set with more semantic features.
Indeed, we plan to explore different topic distribu-
tion varying number of topics in order to maximize
the log likelihood. Also we would like to select the
most relevant feature from this set. We are moti-
vated after this first participation in continuing to
improve the system here proposed.
</bodyText>
<page confidence="0.99832">
107
</page>
<sectionHeader confidence="0.990017" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999672173913043">
David W. Aha, Dennis Kibler, and Marc K. Albert.
1991. Instance-based learning algorithms. Mach.
Learn., 6(1):37–66.
Satanjeev Banerjee and Ted Pedersen. 2003. Extended
gloss overlaps as a measure of semantic relatedness.
In Proceedings of the 18th International Joint Con-
ference on Artificial Intelligence (IJCAI’03), pages
805–810, CA, USA.
Marco Baroni and Roberto Zamparelli. 2010. Nouns
are vectors, adjectives are matrices: Represent-
ing adjective-noun constructions in semantic space.
In Proceedings of the 2010 Conference on Em-
pirical Methods in Natural Language Processing
(EMNLP’10), pages 1183–1193, PA, USA.
Adam L. Berger, Vincent J. Della Pietra, and Stephen
A. Della Pietra. 1996. A maximum entropy ap-
proach to natural language processing. Comput.
Linguist., 22(1):39–71.
David M. Blei, Andrew Y. Ng, and Michael I. Jordan.
2003. Latent dirichlet allocation. Journal of Ma-
chine Learning Research, 3:993–1022.
Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011.
Experimental support for a categorical composi-
tional distributional model of meaning. In Proceed-
ings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP ’11), pages
1394–1404, PA, USA.
Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard
Pfahringer, Peter Reutemann, and Ian H. Witten.
2009. The weka data mining software: An update.
SIGKDDExplor. Newsl., 11(1):10–18.
Jay J. Jiang and David W. Conrath. 1997. Semantic
similarity based on corpus statistics and lexical tax-
onomy. In Proc. of the Int’l. Conf. on Research in
Computational Linguistics, pages 19–33.
Michael Lesk. 1986. Automatic sense disambiguation
using machine readable dictionaries: How to tell a
pine cone from an ice cream cone. In Proceedings
of the 5th Annual International Conference on Sys-
tems Documentation (SIGDOC ’86), pages 24–26,
NY, USA.
Marco Marelli, Luisa Bentivogli, Marco Baroni, Raf-
faella Bernardi, Stefano Menini, and Roberto Zam-
parelli. 2014a. Semeval-2014 task 1: Evaluation
of compositional distributional semantic models on
full sentences through semantic relatedness and tex-
tual entailment. SemEval-2014.
Marco Marelli, Stefano Menini, Marco Baroni, Luisa
Bentivogli, Raffaella Bernardi, and Robertomode
Zamparelli. 2014b. A sick cure for the evaluation
of compositional distributional semantic models. In
Proceedings of LREC 2014.
George A. Miller. 1995. Wordnet: A lexical database
for english. COMMUNICATIONS OF THE ACM,
38:39–41.
Jeff Mitchell and Mirella Lapata. 2010. Composition
in distributional models of semantics. Cognitive Sci-
ence, 34(8):1388–1439.
Ted Pedersen, Siddharth Patwardhan, and Jason Miche-
lizzi. 2004. Wordnet::similarity: Measuring the re-
latedness of concepts. In Demonstration Papers at
HLT-NAACL 2004, HLT-NAACL–Demonstrations
’04, pages 38–41, PA, USA.
Martin F. Porter. 2001. Snowball: A language for
stemming algorithms. Published online.
Ross J. Quinlan. 1992. Learning with continuous
classes. In 5th Australian Joint Conference on Ar-
tificial Intelligence, pages 343–348, Singapore.
Radim ˇReh˚uˇrek and Petr Sojka. 2010. Software
Framework for Topic Modelling with Large Cor-
pora. In Proceedings of the Workshop on New Chal-
lenges for NLP Frameworks (LREC 2010), pages
45–50, Valletta, Malta.
Gerard Salton and Christopher Buckley. 1988. Term-
weighting approaches in automatic text retrieval.
Inf. Process. Manage., 24(5):513–523.
Alexander K. Seewald. 2002. How to make stacking
better and faster while also taking care of an un-
known weakness. In C. Sammut and A. Hoffmann,
editors, Nineteenth International Conference on Ma-
chine Learning, pages 554–561.
Richard Socher, Brody Huval, Christopher D. Man-
ning, and Andrew Y. Ng. 2012. Semantic com-
positionality through recursive matrix-vector spaces.
In Proceedings of the 2012 Joint Conference on
Empirical Methods in Natural Language Process-
ing and Computational Natural Language Learning
(EMNLP-CoNLL ’12), pages 1201–1211, PA, USA.
Yong Wang and Ian H. Witten. 1997. Induction of
model trees for predicting continuous classes. In
Poster papers of the 9th European Conference on
Machine Learning.
</reference>
<page confidence="0.998337">
108
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.331919">
<title confidence="0.999805">ASAP: Automatic Semantic Alignment for Phrases</title>
<author confidence="0.990826">O Ana</author>
<affiliation confidence="0.6214155">CISUC - University of and Polytechnic Institute of</affiliation>
<email confidence="0.455884">ana@dei.uc.pt</email>
<abstract confidence="0.99852375">In this paper we describe the ASAP sysfor which participated on the Task 1 at the SemEval-2014 contest (Marelli et al., 2014a). Our assumption is that STS (Semantic Text Similarity) follows a function considering lexical, syntactic, semantic and distributional features. We demonstrate the learning process of this function without any deep preprocessing achieving an acceptable correlation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David W Aha</author>
<author>Dennis Kibler</author>
<author>Marc K Albert</author>
</authors>
<title>Instance-based learning algorithms.</title>
<date>1991</date>
<journal>Mach. Learn.,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="16470" citStr="Aha et al., 1991" startWordPosition="2604" endWordPosition="2607"> combine different types of classifiers and it demands the use of another learner algorithm to predict which of the models would be the most reliable for each case. This combination is done using a metalearner, another learner scheme that combines the output of the base learners. The base learners are generally called level-0 models, and the metalearner is a level-1 model. The predictions of the base learners are input to the meta-learner. In WEKA, there is a meta classifier called ”Stacking”.We use this stacking ensemble combining two level-0 models: a K-Nearest Neighbour classifier (K = 1) (Aha et al., 1991); and a Linear Regression model without any attribute selection method (−S1) and the ridge parameter by default (1.0 exp −8). The meta-classifier was M5P which implements base routines for generating M5 Model trees and rules (Quinlan, 1992; Wang and Witten, 1997). 4 Conclusions and Future Work Our contribution is in the use of complementary features in order to learn the function of STS, a part of the challenge of building Compositional Distributional Semantic Models. For this we applied some preprocessing tasks over the sentence set in order to find lexical, syntactic, semantic and distributi</context>
</contexts>
<marker>Aha, Kibler, Albert, 1991</marker>
<rawString>David W. Aha, Dennis Kibler, and Marc K. Albert. 1991. Instance-based learning algorithms. Mach. Learn., 6(1):37–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Ted Pedersen</author>
</authors>
<title>Extended gloss overlaps as a measure of semantic relatedness.</title>
<date>2003</date>
<booktitle>In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI’03),</booktitle>
<pages>805--810</pages>
<location>CA, USA.</location>
<contexts>
<context position="4382" citStr="Banerjee and Pedersen, 2003" startWordPosition="671" endWordPosition="674">n#1 is a hypernym of car#n#1 and, conversely, car#n#1 is 104 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 104–108, Dublin, Ireland, August 23-24, 2014. a hyponym of vehicle#n#1). 2.2 Semantic similarity There are mainly two approaches to semantic similarity. First approach is making use of a large corpus and gathering statistical data from this corpus to estimate a score of semantic similarity. Second approach makes use of the relations and the entries of a thesaurus (Lesk, 1986), which is generally a hand-crafted lexical database such as WordNet (Banerjee and Pedersen, 2003). Hybrid approaches combines both methods (Jiang and Conrath, 1997). Semantic similarity can be seen as a different measure from semantic relatedness since the former compute the proximity between concepts in a given concept hierarchy (e.g. car#n#1 is similar to motorcycle#n); while the later the common use of both concepts together (e.g. car#n#1 is related to tire#n). The Lesk algorithm (Lesk, 1986) uses dictionary definitions (glosses) to disambiguate a polysemous word in a sentence context. The major objective of his idea is to count the number of words that are shared between two glosses, </context>
</contexts>
<marker>Banerjee, Pedersen, 2003</marker>
<rawString>Satanjeev Banerjee and Ted Pedersen. 2003. Extended gloss overlaps as a measure of semantic relatedness. In Proceedings of the 18th International Joint Conference on Artificial Intelligence (IJCAI’03), pages 805–810, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Baroni</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP’10),</booktitle>
<pages>1183--1193</pages>
<location>PA, USA.</location>
<contexts>
<context position="925" citStr="Baroni and Zamparelli, 2010" startWordPosition="131" endWordPosition="134">contest (Marelli et al., 2014a). Our assumption is that STS (Semantic Text Similarity) follows a function considering lexical, syntactic, semantic and distributional features. We demonstrate the learning process of this function without any deep preprocessing achieving an acceptable correlation. 1 Introduction Evaluation of compositional semantic models on full sentences through semantic relatedness and textual entailment, title of this task on SemEval, aims to collect systems and approaches able to predict the difference of meaning between phrases and sentences based on their included words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Mitchell and Lapata, 2010; Socher et al., 2012). Our contribution is in the use of complementary features in order to learn the function STS, a part of this challenge. Rather than specifying rules, constraints and lexicons manually, we advocate a system for automatically acquiring linguistic knowledge using machine learning (ML) methods. For this we apply some preprocessing techniques over the training set in order to find different types of features. Related to the semantic aspect, we make use of known semantic relatedness and similarity measures on WordNet</context>
</contexts>
<marker>Baroni, Zamparelli, 2010</marker>
<rawString>Marco Baroni and Roberto Zamparelli. 2010. Nouns are vectors, adjectives are matrices: Representing adjective-noun constructions in semantic space. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP’10), pages 1183–1193, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Comput. Linguist.,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="8193" citStr="Berger et al., 1996" startWordPosition="1279" endWordPosition="1282">imilarities considering different properties of sentences, we need to apply some known Natural Language techniques. For this purpose, we chose OpenNLP2 as an opensource tool suite which contains a variety of Javabased NLP components. Our focus is here on three core NLP components: tokenization, POS tagging and chunking. Besides the fact OpenNLP also offers a stemmer for English we adopted other implementation self-contained in the specific framework for Topic Modeling (detailed in section 3.3). OpenNLP is a homogeneous package based on a single machine learning approach, maximum entropy (ME) (Berger et al., 1996). Each OpenNLP tool requires an ME model that contains statistics about the components default features combining diverse contextual information. OpenNLP offers the possibility of both create component or use pre-built models create for different languages. 2http://opennlp.sourceforge.net 105 On one side, components can be trained and customizable models are built for the language and/or domain in study. On the other, the availability of pre-trained models allows the immediate application of such tools on a new problem. We followed the second approach since the sentences are of common-sense an</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Vincent J. Della Pietra, and Stephen A. Della Pietra. 1996. A maximum entropy approach to natural language processing. Comput. Linguist., 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David M Blei</author>
<author>Andrew Y Ng</author>
<author>Michael I Jordan</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>3--993</pages>
<contexts>
<context position="6390" citStr="Blei et al., 2003" startWordPosition="999" endWordPosition="1002">ypernym/Hyponym hierarchy. 2.3 Topic Modeling Topic models are based upon the idea that documents are mixtures of topics, where a topic is a probability distribution over words. A topic model is a generative model for documents: it specifies a simple probabilistic procedure by which documents can be generated. To make a new document, one chooses a distribution over topics. Then, for each word in that document, one chooses a topic at random according to this distribution, and draws a word from that topic. Latent Dirichilet allocation (LDA) is a generative probabilistic topic model of a corpus (Blei et al., 2003). The basic idea is that documents are represented as random mixtures over latent topics, where each topic is characterized by a distribution over words. This process does not make any assumptions about the order of words as they appear in documents. The only information relevant to the model is the number of times words are produced. This is known as the bag-of-words assumption. The main variables of interest in the model are the topic-word distributions Φ and the topic distributions θ for each document. 3 Proposed Approach Our approach to STS is mainly founded on the idea of learning a regre</context>
</contexts>
<marker>Blei, Ng, Jordan, 2003</marker>
<rawString>David M. Blei, Andrew Y. Ng, and Michael I. Jordan. 2003. Latent dirichlet allocation. Journal of Machine Learning Research, 3:993–1022.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Grefenstette</author>
<author>Mehrnoosh Sadrzadeh</author>
</authors>
<title>Experimental support for a categorical compositional distributional model of meaning.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP ’11),</booktitle>
<pages>1394--1404</pages>
<location>PA, USA.</location>
<contexts>
<context position="959" citStr="Grefenstette and Sadrzadeh, 2011" startWordPosition="135" endWordPosition="138">a). Our assumption is that STS (Semantic Text Similarity) follows a function considering lexical, syntactic, semantic and distributional features. We demonstrate the learning process of this function without any deep preprocessing achieving an acceptable correlation. 1 Introduction Evaluation of compositional semantic models on full sentences through semantic relatedness and textual entailment, title of this task on SemEval, aims to collect systems and approaches able to predict the difference of meaning between phrases and sentences based on their included words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Mitchell and Lapata, 2010; Socher et al., 2012). Our contribution is in the use of complementary features in order to learn the function STS, a part of this challenge. Rather than specifying rules, constraints and lexicons manually, we advocate a system for automatically acquiring linguistic knowledge using machine learning (ML) methods. For this we apply some preprocessing techniques over the training set in order to find different types of features. Related to the semantic aspect, we make use of known semantic relatedness and similarity measures on WordNet, in this case, applied to see the</context>
</contexts>
<marker>Grefenstette, Sadrzadeh, 2011</marker>
<rawString>Edward Grefenstette and Mehrnoosh Sadrzadeh. 2011. Experimental support for a categorical compositional distributional model of meaning. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP ’11), pages 1394–1404, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hall</author>
<author>Eibe Frank</author>
<author>Geoffrey Holmes</author>
<author>Bernhard Pfahringer</author>
<author>Peter Reutemann</author>
<author>Ian H Witten</author>
</authors>
<title>The weka data mining software: An update.</title>
<date>2009</date>
<journal>SIGKDDExplor. Newsl.,</journal>
<volume>11</volume>
<issue>1</issue>
<contexts>
<context position="14578" citStr="Hall et al., 2009" startWordPosition="2307" endWordPosition="2310"> many times within a small number of documents; lower when the term occurs fewer times in a document, or occurs in many documents; lowest when the term occurs in virtually all documents. Gensim computes a distribution of 25 topics over sentences not and using TF-IDF (f13...37 and f38...63). Each feature is the absolute value of the difference of topici (i.e. topic[i] = |topic[i]s1 − topic[i]s2|). Euclidean distance over the difference of topic distribution between sentence pairs in each case (without and with TF-IDF) was also considered as a feature (f64 and f65). 3.4 Supervised Learning WEKA(Hall et al., 2009) is a large collection of state-of-the-art machine learning algorithms written in Java. WEKA contains tools for classification, regression, classifier ensemble, and others. Considering the developer version 3.7.117 we used the following experiment setup considering the 65 features previously computed for both sentence dataset (train and test) (Marelli et al., 2014b). One of four approaches is commonly adopted for building classifier ensembles each one focusing a different level of action. Approach A concerns the different ways of combining the results from the classifiers, but there is no evid</context>
</contexts>
<marker>Hall, Frank, Holmes, Pfahringer, Reutemann, Witten, 2009</marker>
<rawString>Mark Hall, Eibe Frank, Geoffrey Holmes, Bernhard Pfahringer, Peter Reutemann, and Ian H. Witten. 2009. The weka data mining software: An update. SIGKDDExplor. Newsl., 11(1):10–18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay J Jiang</author>
<author>David W Conrath</author>
</authors>
<title>Semantic similarity based on corpus statistics and lexical taxonomy.</title>
<date>1997</date>
<booktitle>In Proc. of the Int’l. Conf. on Research in Computational Linguistics,</booktitle>
<pages>pages</pages>
<contexts>
<context position="4449" citStr="Jiang and Conrath, 1997" startWordPosition="681" endWordPosition="685">s of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 104–108, Dublin, Ireland, August 23-24, 2014. a hyponym of vehicle#n#1). 2.2 Semantic similarity There are mainly two approaches to semantic similarity. First approach is making use of a large corpus and gathering statistical data from this corpus to estimate a score of semantic similarity. Second approach makes use of the relations and the entries of a thesaurus (Lesk, 1986), which is generally a hand-crafted lexical database such as WordNet (Banerjee and Pedersen, 2003). Hybrid approaches combines both methods (Jiang and Conrath, 1997). Semantic similarity can be seen as a different measure from semantic relatedness since the former compute the proximity between concepts in a given concept hierarchy (e.g. car#n#1 is similar to motorcycle#n); while the later the common use of both concepts together (e.g. car#n#1 is related to tire#n). The Lesk algorithm (Lesk, 1986) uses dictionary definitions (glosses) to disambiguate a polysemous word in a sentence context. The major objective of his idea is to count the number of words that are shared between two glosses, but, sometimes, dictionary glosses are often quite brief, and may n</context>
<context position="12691" citStr="Jiang and Conrath, 1997" startWordPosition="1993" endWordPosition="1996">the end of the queried word, the lemmatizer only see in that specific category (e.g. flies#n returns flies#n, fly#n, while flies returns more entries: flies#n, fly#n, fly#v). Therefore, a lemmatized is successively applied over the Subjects found for each pair of sentences. The compound subjects are reduced from left to right until a head noun been found as a valid WordNet entry (e.g. the subject economicelectriccars is reduced until the valid entry electriccar which is present on WordNet). After all the subjects been found and a valid WordNet entry has been matched semantic similarity (f11) (Jiang and Conrath, 1997) and semantic relatedness (f12) (Lesk, 1986) is computed for each sentence pair. In the case where pair word#n has multiple senses, the one that maximizes partial similarity is selected. 3.3 Distributional Features The distribution of topics over documents (in our case, sentences) may contribute to model Distributional Semantic in texts since in the way that the model is defined, there is no notion of mutual exclusivity that restricts words to be part of one topic only. This allows topic models to cap106 ture polysemy, where the same word has multiple meanings. In this sense we can see topics </context>
</contexts>
<marker>Jiang, Conrath, 1997</marker>
<rawString>Jay J. Jiang and David W. Conrath. 1997. Semantic similarity based on corpus statistics and lexical taxonomy. In Proc. of the Int’l. Conf. on Research in Computational Linguistics, pages 19–33.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Lesk</author>
</authors>
<title>Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone.</title>
<date>1986</date>
<booktitle>In Proceedings of the 5th Annual International Conference on Systems Documentation (SIGDOC ’86),</booktitle>
<pages>24--26</pages>
<location>NY, USA.</location>
<contexts>
<context position="4284" citStr="Lesk, 1986" startWordPosition="657" endWordPosition="658">ective inverses. Y is a hypernym of X if every X is a (kind of) Y (motor vehicle#n#1 is a hypernym of car#n#1 and, conversely, car#n#1 is 104 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 104–108, Dublin, Ireland, August 23-24, 2014. a hyponym of vehicle#n#1). 2.2 Semantic similarity There are mainly two approaches to semantic similarity. First approach is making use of a large corpus and gathering statistical data from this corpus to estimate a score of semantic similarity. Second approach makes use of the relations and the entries of a thesaurus (Lesk, 1986), which is generally a hand-crafted lexical database such as WordNet (Banerjee and Pedersen, 2003). Hybrid approaches combines both methods (Jiang and Conrath, 1997). Semantic similarity can be seen as a different measure from semantic relatedness since the former compute the proximity between concepts in a given concept hierarchy (e.g. car#n#1 is similar to motorcycle#n); while the later the common use of both concepts together (e.g. car#n#1 is related to tire#n). The Lesk algorithm (Lesk, 1986) uses dictionary definitions (glosses) to disambiguate a polysemous word in a sentence context. The</context>
<context position="12735" citStr="Lesk, 1986" startWordPosition="2002" endWordPosition="2003">hat specific category (e.g. flies#n returns flies#n, fly#n, while flies returns more entries: flies#n, fly#n, fly#v). Therefore, a lemmatized is successively applied over the Subjects found for each pair of sentences. The compound subjects are reduced from left to right until a head noun been found as a valid WordNet entry (e.g. the subject economicelectriccars is reduced until the valid entry electriccar which is present on WordNet). After all the subjects been found and a valid WordNet entry has been matched semantic similarity (f11) (Jiang and Conrath, 1997) and semantic relatedness (f12) (Lesk, 1986) is computed for each sentence pair. In the case where pair word#n has multiple senses, the one that maximizes partial similarity is selected. 3.3 Distributional Features The distribution of topics over documents (in our case, sentences) may contribute to model Distributional Semantic in texts since in the way that the model is defined, there is no notion of mutual exclusivity that restricts words to be part of one topic only. This allows topic models to cap106 ture polysemy, where the same word has multiple meanings. In this sense we can see topics as natural word sense contexts where words a</context>
</contexts>
<marker>Lesk, 1986</marker>
<rawString>Michael Lesk. 1986. Automatic sense disambiguation using machine readable dictionaries: How to tell a pine cone from an ice cream cone. In Proceedings of the 5th Annual International Conference on Systems Documentation (SIGDOC ’86), pages 24–26, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Marelli</author>
<author>Luisa Bentivogli</author>
<author>Marco Baroni</author>
<author>Raffaella Bernardi</author>
<author>Stefano Menini</author>
<author>Roberto Zamparelli</author>
</authors>
<title>Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment.</title>
<date>2014</date>
<tech>SemEval-2014.</tech>
<contexts>
<context position="14944" citStr="Marelli et al., 2014" startWordPosition="2359" endWordPosition="2362">ic[i] = |topic[i]s1 − topic[i]s2|). Euclidean distance over the difference of topic distribution between sentence pairs in each case (without and with TF-IDF) was also considered as a feature (f64 and f65). 3.4 Supervised Learning WEKA(Hall et al., 2009) is a large collection of state-of-the-art machine learning algorithms written in Java. WEKA contains tools for classification, regression, classifier ensemble, and others. Considering the developer version 3.7.117 we used the following experiment setup considering the 65 features previously computed for both sentence dataset (train and test) (Marelli et al., 2014b). One of four approaches is commonly adopted for building classifier ensembles each one focusing a different level of action. Approach A concerns the different ways of combining the results from the classifiers, but there is no evidence that this strategy is better than using different models (Approach B). At feature level (Approach C) different feature subsets can be used for the classifiers, either if they use the same classification model or not. Finally, the data sets can be modified so that each classifier in the ensemble is trained on its own data set (Approach D). 7http://www.cs.waika</context>
</contexts>
<marker>Marelli, Bentivogli, Baroni, Bernardi, Menini, Zamparelli, 2014</marker>
<rawString>Marco Marelli, Luisa Bentivogli, Marco Baroni, Raffaella Bernardi, Stefano Menini, and Roberto Zamparelli. 2014a. Semeval-2014 task 1: Evaluation of compositional distributional semantic models on full sentences through semantic relatedness and textual entailment. SemEval-2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Marelli</author>
<author>Stefano Menini</author>
<author>Marco Baroni</author>
<author>Luisa Bentivogli</author>
<author>Raffaella Bernardi</author>
<author>Robertomode Zamparelli</author>
</authors>
<title>A sick cure for the evaluation of compositional distributional semantic models.</title>
<date>2014</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="14944" citStr="Marelli et al., 2014" startWordPosition="2359" endWordPosition="2362">ic[i] = |topic[i]s1 − topic[i]s2|). Euclidean distance over the difference of topic distribution between sentence pairs in each case (without and with TF-IDF) was also considered as a feature (f64 and f65). 3.4 Supervised Learning WEKA(Hall et al., 2009) is a large collection of state-of-the-art machine learning algorithms written in Java. WEKA contains tools for classification, regression, classifier ensemble, and others. Considering the developer version 3.7.117 we used the following experiment setup considering the 65 features previously computed for both sentence dataset (train and test) (Marelli et al., 2014b). One of four approaches is commonly adopted for building classifier ensembles each one focusing a different level of action. Approach A concerns the different ways of combining the results from the classifiers, but there is no evidence that this strategy is better than using different models (Approach B). At feature level (Approach C) different feature subsets can be used for the classifiers, either if they use the same classification model or not. Finally, the data sets can be modified so that each classifier in the ensemble is trained on its own data set (Approach D). 7http://www.cs.waika</context>
</contexts>
<marker>Marelli, Menini, Baroni, Bentivogli, Bernardi, Zamparelli, 2014</marker>
<rawString>Marco Marelli, Stefano Menini, Marco Baroni, Luisa Bentivogli, Raffaella Bernardi, and Robertomode Zamparelli. 2014b. A sick cure for the evaluation of compositional distributional semantic models. In Proceedings of LREC 2014.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
</authors>
<title>Wordnet: A lexical database for english.</title>
<date>1995</date>
<journal>COMMUNICATIONS OF THE ACM,</journal>
<pages>38--39</pages>
<contexts>
<context position="2528" citStr="Miller, 1995" startWordPosition="372" endWordPosition="373">o Mariana Lourenc¸o Filipe Rodrigues CISUC - University of Coimbra Portugal {aferr,mrlouren}@student.dei.uc.pt fmpr@dei.uc.pt Considering the problem of modeling a text corpus to find short descriptions of documents, we aim an efficient processing of large collections while preserving the essential statistical relationships that are useful for, in this case, similarity judgment. Therefore we also apply topic modeling in order to get topic distribution over each sentence set. These features are then used to feed an ensemble algorithm to learn the STS function. 2 Background 2.1 WordNet WordNet (Miller, 1995) is a computational lexicon of English created and maintained at Princeton University. It encodes concepts in terms of sets of synonyms (called synsets). A synset can be seen as a set of word senses all expressing the same meaning. Each word sense uniquely identifies a single synset. For instance, car#n#1 uses the notation followed by WordNet and subscript word#p#n where p denotes the part-of-speech tag and n the word’s sense identifier, respectively. In this case, the corresponding synset car#n#1, auto#n#1, automobile#n#1, machine#n#6, motorcar#n#1 is uniquely determined. As words are not alw</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>George A. Miller. 1995. Wordnet: A lexical database for english. COMMUNICATIONS OF THE ACM, 38:39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeff Mitchell</author>
<author>Mirella Lapata</author>
</authors>
<title>Composition in distributional models of semantics.</title>
<date>2010</date>
<journal>Cognitive Science,</journal>
<volume>34</volume>
<issue>8</issue>
<contexts>
<context position="986" citStr="Mitchell and Lapata, 2010" startWordPosition="139" endWordPosition="142">mantic Text Similarity) follows a function considering lexical, syntactic, semantic and distributional features. We demonstrate the learning process of this function without any deep preprocessing achieving an acceptable correlation. 1 Introduction Evaluation of compositional semantic models on full sentences through semantic relatedness and textual entailment, title of this task on SemEval, aims to collect systems and approaches able to predict the difference of meaning between phrases and sentences based on their included words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Mitchell and Lapata, 2010; Socher et al., 2012). Our contribution is in the use of complementary features in order to learn the function STS, a part of this challenge. Rather than specifying rules, constraints and lexicons manually, we advocate a system for automatically acquiring linguistic knowledge using machine learning (ML) methods. For this we apply some preprocessing techniques over the training set in order to find different types of features. Related to the semantic aspect, we make use of known semantic relatedness and similarity measures on WordNet, in this case, applied to see the relatedness/similarity bet</context>
</contexts>
<marker>Mitchell, Lapata, 2010</marker>
<rawString>Jeff Mitchell and Mirella Lapata. 2010. Composition in distributional models of semantics. Cognitive Science, 34(8):1388–1439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
<author>Siddharth Patwardhan</author>
<author>Jason Michelizzi</author>
</authors>
<title>Wordnet::similarity: Measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>In Demonstration Papers at HLT-NAACL 2004, HLT-NAACL–Demonstrations ’04,</booktitle>
<pages>38--41</pages>
<location>PA, USA.</location>
<contexts>
<context position="11337" citStr="Pedersen et al., 2004" startWordPosition="1763" endWordPosition="1766">or stop word removal, from 0 to 3. 6As alternative models are available, the Maxent model with tag dictionary was used on this component. Available at http://opennlp.sourceforge.net/models1.5/en-pos-maxent.bin further identified as subjects if they are in the beginning of sentences. This kind of shallow parser will be useful to identify the syntactic structure of sentences. Considering only this property, different features were computed as the absolute value of the difference of the number of NPs (f8), VPs (f9) and PPs(f10) for each sentence pair. 3.2.3 Semantic Features WordNet::Similarity (Pedersen et al., 2004) is a freely available software package for measuring the semantic similarity or relatedness between a pair of concepts (or word senses). At this stage we have for each sentence the subject identified as the first NP beginning a sentence. This NP can be composed of a simple or compound noun, in a root form (lemma) or in a inflected form (plural) (e.g. electrics or economic electric cars). WorNet::Similarity package also contains a lemmatizer, in the module WordNet::QueryData, which compare a inflected word form and return all WordNet entries which can be the root form of this word. This search</context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Ted Pedersen, Siddharth Patwardhan, and Jason Michelizzi. 2004. Wordnet::similarity: Measuring the relatedness of concepts. In Demonstration Papers at HLT-NAACL 2004, HLT-NAACL–Demonstrations ’04, pages 38–41, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin F Porter</author>
</authors>
<title>Snowball: A language for stemming algorithms.</title>
<date>2001</date>
<note>Published online.</note>
<contexts>
<context position="10386" citStr="Porter, 2001" startWordPosition="1622" endWordPosition="1623"> sentence (f1 and f2 respectively), and the absolute value of the difference of these counts (f3 = f1 − f2 ); the absolute value of the difference of overlapping words for each sentence pair (f4..7)5. 3.2.2 Syntactic Features OpenNLP tokenization, POS (Part-of-Speech) tagging6 and text chunking applied on a pipeline fashion allows the identification of (NPs) Noun Phrases, VPs (Verbal Phrases) and (Prepositional Phrases) in sentences. Heuristically, these NPs are 3OpenNLP offers, for the vast majority of components, at least one pre-trained model for this language. 4The Snowball stop word list(Porter, 2001) was used and those words expressing negation were identified (such as: never, not, neither, no, nobody, aren’t, isn’t, don’t, doesn’t, hasn’t, hadn’t, haven’t) 5Thanks to the SemEval organizers in making available the python script which computes baselines compute overlap baseline.py which was applied using different setting for stop word removal, from 0 to 3. 6As alternative models are available, the Maxent model with tag dictionary was used on this component. Available at http://opennlp.sourceforge.net/models1.5/en-pos-maxent.bin further identified as subjects if they are in the beginning o</context>
</contexts>
<marker>Porter, 2001</marker>
<rawString>Martin F. Porter. 2001. Snowball: A language for stemming algorithms. Published online.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ross J Quinlan</author>
</authors>
<title>Learning with continuous classes.</title>
<date>1992</date>
<booktitle>In 5th Australian Joint Conference on Artificial Intelligence,</booktitle>
<pages>343--348</pages>
<contexts>
<context position="16709" citStr="Quinlan, 1992" startWordPosition="2644" endWordPosition="2645">ines the output of the base learners. The base learners are generally called level-0 models, and the metalearner is a level-1 model. The predictions of the base learners are input to the meta-learner. In WEKA, there is a meta classifier called ”Stacking”.We use this stacking ensemble combining two level-0 models: a K-Nearest Neighbour classifier (K = 1) (Aha et al., 1991); and a Linear Regression model without any attribute selection method (−S1) and the ridge parameter by default (1.0 exp −8). The meta-classifier was M5P which implements base routines for generating M5 Model trees and rules (Quinlan, 1992; Wang and Witten, 1997). 4 Conclusions and Future Work Our contribution is in the use of complementary features in order to learn the function of STS, a part of the challenge of building Compositional Distributional Semantic Models. For this we applied some preprocessing tasks over the sentence set in order to find lexical, syntactic, semantic and distributional features. On the semantic aspect, we made use of known semantic relatedness and similarity measures on WordNet, in this case, applied to see the relatedness/similarity between phrases from sentences. We also applied topic modeling in </context>
</contexts>
<marker>Quinlan, 1992</marker>
<rawString>Ross J. Quinlan. 1992. Learning with continuous classes. In 5th Australian Joint Conference on Artificial Intelligence, pages 343–348, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radim ˇReh˚uˇrek</author>
<author>Petr Sojka</author>
</authors>
<title>Software Framework for Topic Modelling with Large Corpora.</title>
<date>2010</date>
<booktitle>In Proceedings of the Workshop on New Challenges for NLP Frameworks (LREC 2010),</booktitle>
<pages>45--50</pages>
<location>Valletta,</location>
<marker>ˇReh˚uˇrek, Sojka, 2010</marker>
<rawString>Radim ˇReh˚uˇrek and Petr Sojka. 2010. Software Framework for Topic Modelling with Large Corpora. In Proceedings of the Workshop on New Challenges for NLP Frameworks (LREC 2010), pages 45–50, Valletta, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerard Salton</author>
<author>Christopher Buckley</author>
</authors>
<title>Termweighting approaches in automatic text retrieval.</title>
<date>1988</date>
<journal>Inf. Process. Manage.,</journal>
<volume>24</volume>
<issue>5</issue>
<contexts>
<context position="13736" citStr="Salton and Buckley, 1988" startWordPosition="2165" endWordPosition="2168">ity that restricts words to be part of one topic only. This allows topic models to cap106 ture polysemy, where the same word has multiple meanings. In this sense we can see topics as natural word sense contexts where words appear in different topics with distinct senses. Gensim (ˇReh˚uˇrek and Sojka, 2010) is a machine learning framework for Topic Modeling which includes several preprocessing techniques such as stop-word removal and TF-IDF. TF-IDF is a standard statistical method that combines the frequency of a term in a particular document with its inverse document frequency in general use (Salton and Buckley, 1988). This score is high for rare terms that appear frequently in a document and are therefore more likely to be significant. In a pragmatic view, tf-idft,d assigns to term t a weight in document d that is: highest when t occurs many times within a small number of documents; lower when the term occurs fewer times in a document, or occurs in many documents; lowest when the term occurs in virtually all documents. Gensim computes a distribution of 25 topics over sentences not and using TF-IDF (f13...37 and f38...63). Each feature is the absolute value of the difference of topici (i.e. topic[i] = |top</context>
</contexts>
<marker>Salton, Buckley, 1988</marker>
<rawString>Gerard Salton and Christopher Buckley. 1988. Termweighting approaches in automatic text retrieval. Inf. Process. Manage., 24(5):513–523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander K Seewald</author>
</authors>
<title>How to make stacking better and faster while also taking care of an unknown weakness.</title>
<date>2002</date>
<booktitle>Nineteenth International Conference on Machine Learning,</booktitle>
<pages>554--561</pages>
<editor>In C. Sammut and A. Hoffmann, editors,</editor>
<contexts>
<context position="15668" citStr="Seewald, 2002" startWordPosition="2474" endWordPosition="2475"> level of action. Approach A concerns the different ways of combining the results from the classifiers, but there is no evidence that this strategy is better than using different models (Approach B). At feature level (Approach C) different feature subsets can be used for the classifiers, either if they use the same classification model or not. Finally, the data sets can be modified so that each classifier in the ensemble is trained on its own data set (Approach D). 7http://www.cs.waikato.ac.nz/ml/weka/downloading.html Different methods for generating and combining models exist, like Stacking (Seewald, 2002) (Approach B). These combined models share sometimes however the disadvantage of being difficult to analyse, once they can comprise dozens of individual classifiers. Stacking is used to combine different types of classifiers and it demands the use of another learner algorithm to predict which of the models would be the most reliable for each case. This combination is done using a metalearner, another learner scheme that combines the output of the base learners. The base learners are generally called level-0 models, and the metalearner is a level-1 model. The predictions of the base learners ar</context>
</contexts>
<marker>Seewald, 2002</marker>
<rawString>Alexander K. Seewald. 2002. How to make stacking better and faster while also taking care of an unknown weakness. In C. Sammut and A. Hoffmann, editors, Nineteenth International Conference on Machine Learning, pages 554–561.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>Brody Huval</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Semantic compositionality through recursive matrix-vector spaces.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL ’12),</booktitle>
<pages>1201--1211</pages>
<location>PA, USA.</location>
<contexts>
<context position="1008" citStr="Socher et al., 2012" startWordPosition="143" endWordPosition="146">lows a function considering lexical, syntactic, semantic and distributional features. We demonstrate the learning process of this function without any deep preprocessing achieving an acceptable correlation. 1 Introduction Evaluation of compositional semantic models on full sentences through semantic relatedness and textual entailment, title of this task on SemEval, aims to collect systems and approaches able to predict the difference of meaning between phrases and sentences based on their included words (Baroni and Zamparelli, 2010; Grefenstette and Sadrzadeh, 2011; Mitchell and Lapata, 2010; Socher et al., 2012). Our contribution is in the use of complementary features in order to learn the function STS, a part of this challenge. Rather than specifying rules, constraints and lexicons manually, we advocate a system for automatically acquiring linguistic knowledge using machine learning (ML) methods. For this we apply some preprocessing techniques over the training set in order to find different types of features. Related to the semantic aspect, we make use of known semantic relatedness and similarity measures on WordNet, in this case, applied to see the relatedness/similarity between phrases from sent</context>
</contexts>
<marker>Socher, Huval, Manning, Ng, 2012</marker>
<rawString>Richard Socher, Brody Huval, Christopher D. Manning, and Andrew Y. Ng. 2012. Semantic compositionality through recursive matrix-vector spaces. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL ’12), pages 1201–1211, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yong Wang</author>
<author>Ian H Witten</author>
</authors>
<title>Induction of model trees for predicting continuous classes.</title>
<date>1997</date>
<booktitle>In Poster papers of the 9th European Conference on Machine Learning.</booktitle>
<contexts>
<context position="16733" citStr="Wang and Witten, 1997" startWordPosition="2646" endWordPosition="2649"> of the base learners. The base learners are generally called level-0 models, and the metalearner is a level-1 model. The predictions of the base learners are input to the meta-learner. In WEKA, there is a meta classifier called ”Stacking”.We use this stacking ensemble combining two level-0 models: a K-Nearest Neighbour classifier (K = 1) (Aha et al., 1991); and a Linear Regression model without any attribute selection method (−S1) and the ridge parameter by default (1.0 exp −8). The meta-classifier was M5P which implements base routines for generating M5 Model trees and rules (Quinlan, 1992; Wang and Witten, 1997). 4 Conclusions and Future Work Our contribution is in the use of complementary features in order to learn the function of STS, a part of the challenge of building Compositional Distributional Semantic Models. For this we applied some preprocessing tasks over the sentence set in order to find lexical, syntactic, semantic and distributional features. On the semantic aspect, we made use of known semantic relatedness and similarity measures on WordNet, in this case, applied to see the relatedness/similarity between phrases from sentences. We also applied topic modeling in order to get topic distr</context>
</contexts>
<marker>Wang, Witten, 1997</marker>
<rawString>Yong Wang and Ian H. Witten. 1997. Induction of model trees for predicting continuous classes. In Poster papers of the 9th European Conference on Machine Learning.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>