<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000580">
<note confidence="0.68772725">
TOWARDS A CORE VOCABULARY FOR A NATURAL LANGUAGE
SYSTEM
llubert I,ehmann
IBM Deutschland GmbH, Scientific Center
Institute for Knowledge Based Systems
Wilckensstr. la
D-6900 I Ieidelberg, Germany
Email: I,E11 at DIIDIIIMI.IIITNFT
</note>
<sectionHeader confidence="0.97102" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999916166666667">
The desire to construct robust and portable na-
tural language systems has led to research on
how a core vocabulary for such systems can be
defined. Statistical methods and semantic criteria
for doing this are discussed and compared. Cur-
rently it does not, seem possible to precisely de-
fine the notion of core vocabulary, but it is
argued that workable criteria can nevertheless be
found. Finally it is emphasized that the imple-
mentation of a core vocabulary must he seen as
a long-range research program rather than as a
short-term goal.
</bodyText>
<sectionHeader confidence="0.556226" genericHeader="keywords">
Motivation
</sectionHeader>
<bodyText confidence="0.987257942857143">
Reaseareh on natural language processing sys-
tems today strives for the construction of robust
and portable systems.&apos; A system is robust, if it
can handle a large variety of user inputs without
giving up or producing unexpected results. A
system is portable in the sense intended here, if
it is not geared to a single subject domain, but
can be ported with a reasonable effort to a vari-
ety of subject domains. It is common under-
standing that there exists a central fragment of a
language %vhich I. is required for dealing with
virtually any subject domain, and 2. is invariant
with respect to meaning and use accross subject
domains. It is of course a non-trivial empirical
question whether such a central fragment really
exists, and if so, to say what it is, but a number
of researchers seem to share the assumption that
it does (cf. e.g. Alshawi et al. (19/N)). Any ro-
bust and portable system would then have to
handle this core fragment.
In this paper I am concerned with a second
— related — assumption, namely that there ex-
ists a core vocabulary which is needed for handl-
ing any subject domain. This assumption is also
shared by many researchers, and it underlies the
production of basic vocabularies for language
learning such as Oehler (1980). lisually the au-
thors claim that their word lists are based on
statistical investigations, but they also emphasize
that, they did not slavishly stick to the statistics
but used additional criteria such as &amp;quot;usage
value&amp;quot;, &amp;quot;availability&amp;quot;, &amp;quot;familiarity&amp;quot;, or
&amp;quot;learnability&amp;quot; without ever saying how these are
est ablished.2
I will address the following questions:
</bodyText>
<listItem confidence="0.992614142857143">
1. I low can the intuitive notion of core vocab-
ulary be properly defined&apos;?
2.. How can statistical methods be employed
to define a core vocabulary and how do they
relate to semantic criteria?
3. What semantic criteria can be found to de-
fine a core vocabulary?
</listItem>
<subsectionHeader confidence="0.995089">
Definitions of a core vocabulary
</subsectionHeader>
<bodyText confidence="0.999320133333333">
There are several ways to define core
vocabulary, I can think of the following three:
U. The core vocabulary consists of the n most
frequent words of a language.
2&apos;. The core vocabulary is that vocabulary
which is common to all native speakers of
a language.
3. The semantic core vocabulary consists of
those words which suffice to define all of the
remaining vocabulary of a language.
The first two definitions call for statistical
methods which shall be discussed in the next
section, and the third one obviously requires a
Semantic approach which shall he discussed in
section &amp;quot;Semantic criteria&amp;quot;.
</bodyText>
<subsectionHeader confidence="0.985349">
Statistical methods
</subsectionHeader>
<bodyText confidence="0.9993752">
Frequency counts have well established the basic
properties of the frequency distribution for text
corpora. Thus in Kucera and Francis (1967) we
get coverage figures like this for their complete
corpus of about I million tokens:
</bodyText>
<figure confidence="0.474314333333333">
10 most frequent words: 24.26 %
100 most frequent words: 47.43 %
1000 most frequent words: 68.86 %
</figure>
<bodyText confidence="0.947576142857143">
The research described here has been conducted in the context of the 1.11,06 project (Ilerzog et at., 1986).
It has profiled front intensive discussions with R. Mayer, Much of the underlying statistical work on text
corpora is due to U. Damian&apos; and (;. Watch from the speech recognition project SPRING (Wothke et
at., 1989).
2 Our investigations arc based on German, but for ease of reference also some English examples are given.
- 303 -
These figures vary only slightly with corpus size,
and also for German similar values are observed.
I lowever, while coverage figures arc rather stable
with respect to the n most frequent words of a
corpus, what are the n most frequent words may
vary widely with corpora or subcorpora. Two
parameters responsible for this variation are ob-
vious:
</bodyText>
<listItem confidence="0.9948145">
1. Subject matter and
2. • Communicative function.
</listItem>
<bodyText confidence="0.997822935483871">
Thus in the &amp;quot;Kultur&amp;quot; section of a newspaper
which we have analyzed we see that words like
Musik, Theater, Regisseur, etc. occur with a
drastically higher frequency than in the other
sections, which of course can be attributed to
subject matter. But personal pronouns, in par-
ticular 1st and 2nd person pronouns, also show
a much higher frequency, and this can hardly be
attributed to subject matter, rather to different
communicative functions of feuilletonistic writ-
ing and say economic news.
All of this relates of course to the much dis-
cussed issue of what constitutes a representatitve
corpus for statistical linguistic analysis. Since
specific subject matters and communicative
functions vary in importance for different speak-
ers of a language, it will be difficult if not im-
possible to eliminate arbitrariness. Rather, a
definition of representative corpus must take into
account the research goals pursued.
For a natural language system which is sup-
posed to analyze and generate texts, to engage in
dialogues with users, and which is to acquire
knowledge from the analysis of definitions and
rules formulated in natural language, one needs
a corpus of texts where all these aspects are suf-
ficiently represented. We Weie able to draw upon
a variety of corpora none of which would show
all the features required, but the combination of
them seems to be quite reasonable.
We compared the following five word lists:
</bodyText>
<listItem confidence="0.918489583333333">
I. Oehler (1980): Grundwortschatz consisting
of 2247 words,
2. Erk (1972): scientific texts from 34 disci-
plines, 1283 words with frequency 20,
3. Pregel/Rickhcit (1987): texts by primary
school children, 593 words with frequency
&gt; 20,
4. SPRING-corpus of newspaper texts, 2733
most frequent words,
5. DUDEN (1989): definitions for words be-
ginning with a, 2693 words with frequency
&gt;4.
</listItem>
<bodyText confidence="0.987586066666667">
From these, word lists 11„ were formed consisting
of those words occurring in at least n of the ori-
ginal word lists (1 &lt; n &lt; 5). The lengths of these
lists are B1: 5409, /32 : 2248, 113: 1215, /14: 565, and
115: 116.
The size of Bs shows that a really common
core of a variety of texts may be extremely small,
the successive losening of restrictions used here
allows for a balanced extension of this very small
core. The list 113 was chosen as the statistical core
vocabulary serving as a base for applying se-
mantic criteria, because the overall core vocabu-
lary was envisaged to have a size of approx. 1500
words. Inspection shows that many intuitively
basic words and very few idiosyncratic words are
contained due to the method of intersecting the
word lists. !knee, /./3 seems quite reasonable.
Semantic criteria
If one takes the n most frequent words of any
frequency count one will no doubt discover that
these words will not exhibit a linguistic closure
in the sense that natural sentences can be formed
with all and only the words in the set. Further
one will see that semantic relations will be in-
complete. Thus one finds in Oehler (1980) which
is based on the old Kaeding count that weiblich
(female) occurs but not its antonym miinnlich
(male). I7or a core vocabulary to be set up for a
natural language system, I think, one must strive
for linguistic closure, since otherwise, one ends
up with words one cannot use. This means that
you cannot base the core vocabulary on fre-
quency counts alone.
Furthermore, one cannot expect that one will
have just the vocabulary needed to formulate
definitions for the words in the list chosen. To
avoid circularity, one will have to accept that
certain words cannot be defined within the vo-
cabulary, but one will also have to accept that
for some words less than complete definitions
can be given. Because of this lack of definability,
a semantic core vocabulary can only be under-
stood as an approxitnative notion geared towards
&amp;quot;the best one can do&amp;quot;. What one can hope to
do, is to define
</bodyText>
<listItem confidence="0.9012248">
I. taxonomic relations,
2. &amp;quot;selectional restrictions&amp;quot; or constraints on
semantic compatibility, and
3. meaning rules of arbitrary complexity (in-
cluding classical definitions).
</listItem>
<bodyText confidence="0.993854523809524">
I propose to formulate all of these types of rules
in natural language for 11 trying to stay within
at least the vocabulary of Il , to add the words
used in the formulations to the original set, and
continue until one cannot think of further rules.
I claim that one can achieve a fixed point from
where on no new words are added to the set, and
that at this moment one has reached a rather
good approximation to a semantic core vocabu-
lary.
There is undoubtedly a relationship between
frequency and semantic relevance: since
taxonomic relations are often exemplified by
anaphoric references, since semantic compatibil-
ity constraints lead to the co-occurrence of ap-
- 304 -
propriate words, and since other more complex
semantic relationships arc bound to be exhibited
in the various threads of discourse, one has all
reason to expect a certain amount of congruence
between frequency counts and the semantic core
vocabulary as defined above.
The work on formulating taxonomic re-
lations, semantic constraints and other meaning
rules is underway, and since it will involve all of
the vocabulary, linguistic closure will be achieved
at the same time.
As an example, take a taxonomic rule for
Arm which is in Bs
Jeder (B3) Arm 1st Tei 1 (84) eines Korpers (83)
(Every arm is part of a body.)
The word Kibperteil (body part) is only avail-
able in /.11 and was therefore not used, or instead
of&apos; Teil one could also have used Glied(I13,
member), but then the rule would not have
covered arms of machines or rivers. This high-
lights a big problem in the natural language for-
mulation of meaning rules: how is ambiguity
dealt with? Space does not permit a full dis-
cussion here, therefore suffice it to say that it is
one of our research goals to formulate meaning
rules which specify criteria for disambiguation.
</bodyText>
<subsectionHeader confidence="0.915756">
Linguistic description
</subsectionHeader>
<bodyText confidence="0.999966129032258">
The preceding discussion has concentrated on
how to establish a core vocabulary. Now a few
brief remarks shall follow on how the words of
the core vocabulary can be linguistically de-
scribed.
The morphology of languages such as
German is well understood and has been coded
for an extended vocabulary in the lexical data-
base of the LEX project (Barnett et al., 1986).
This database also contains detailed syntactic
information, in particular on government pat-
terns.
It is the description of the semantic (and
pragmatic) properties of many words one would
obviously want to include in a core vocabulary
that will confront us with huge unsolved theore-
tical problems. Be it modal verbs or proposi-
tional attitudes, sentence adverbs or &amp;quot;abstract&amp;quot;
nouns of various kinds. Investigations on some
individual words have generated heaps of litera-
ture, for others it seems that people have not
even dared to look at them. Does this make the
enterprise of implementing a core vocabulary a
futile one? I think not. I think the implementa-
tion of a core vocabulary should be seen as a
long-range research goal for both computational
and theoretical linguistics, and furthermore that
natural language systems provide a good envi-
ronment for doing experiments in semantics, be-
cause they encourage an integrated treatment of
linguistic phenomena.
</bodyText>
<sectionHeader confidence="0.564938" genericHeader="conclusions">
Conclusions
</sectionHeader>
<bodyText confidence="0.999968">
Our research on establishing a core vocabulary
for German in the framework of the 1,ILOG
project has revealed that currently no absolute
definition can be given, but ways have been.
shown how to arrive at a working definition with
respect to the objectives of natural language sys-
tems. It has been shown that both statistical
methods and semantic criteria can, and I think,
have to contribute to the establishment of a core
vocabulary.
The linguistic description and thus the im-
plementation of a core vocabulary depends
heavily on progress in theoretical linguistics, in
particular in semantics and pragmatics, but I
want to stress that focussing on a core vocabu-
lary is a fruitful way to direct linguistic research,
which can be supported by the need for inte-
grated treatments in natural language systems.
</bodyText>
<sectionHeader confidence="0.999417" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.98930440625">
Alshawi, II., D. M. Carter, .1. van Eijck, R. C.
Moore, D. B. Moran, F. C. N. Pereira, and A.
G. Smith (1988): &amp;quot;Research Programme in Na-
tural Language Processing — Annual Report&amp;quot;,
Nattie Project Document NA-I6, Cambridge:
SRI International.
Barnett, B., II. I,chmann, M. Zoeppritz
(1986): &amp;quot;A word database for natural language
processing&amp;quot;, Proceedings 1 1 th International Con-
ference on Computational Linguistics COL1NG86
Augttst 2.5th to 29th, 1986, Holm, Federal 1?epub-
lic of Germany. 435-440.
Frk, II. (1972): Zur Lexik wissenschaftlicher
Fachtexte, München: Ilueber.
• I lerzog, 0. et al. (1986): &amp;quot;1.11,06 — Lin-
guistic and I ATic Methods for the Computa-
tional Understanding of German&amp;quot;,
1,11,0G- Report /I), Stuttgart: 113M Deutschland.
Kucera, II., W. N. Francis (1967): Computa-
tional Analysis of Present-Day American English.
Providence, RI: Brown University Press.
Oehler, II. (1980): KLETT Grund- und
Aujbauwortschatz Deutsch. Stuttgart: Klett.
Pregel, D., G. Rickheit (1987): Der
Wortschatz bn Grundschulaher. Ilildeshcim:
Olms.
Wothke, K., U. I3andara, J. Kempf, E.
Keppel, K. Mohr, G. Walch (1989): &amp;quot;The
SPRING Speech Recognition System for
German&amp;quot;, in: Proceedings of Eurospeech &apos;89.
Vol. 2, 9-12.
- 305 -
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.025239">
<title confidence="0.9527065">TOWARDS A CORE VOCABULARY FOR A NATURAL LANGUAGE SYSTEM</title>
<author confidence="0.940178">I llubert</author>
<author confidence="0.940178">ehmann</author>
<affiliation confidence="0.821125">IBM Deutschland GmbH, Scientific Center Institute for Knowledge Based Systems</affiliation>
<address confidence="0.706197">Wilckensstr. la D-6900 I Ieidelberg, Germany</address>
<email confidence="0.950772">I,E11atDIIDIIIMI.IIITNFT</email>
<abstract confidence="0.999001256227758">The desire to construct robust and portable natural language systems has led to research on how a core vocabulary for such systems can be defined. Statistical methods and semantic criteria for doing this are discussed and compared. Currently it does not, seem possible to precisely define the notion of core vocabulary, but it is argued that workable criteria can nevertheless be found. Finally it is emphasized that the implementation of a core vocabulary must he seen as a long-range research program rather than as a short-term goal. Motivation Reaseareh on natural language processing systoday strives for the construction of portable systems.&apos; A is if it can handle a large variety of user inputs without giving up or producing unexpected results. A system is portable in the sense intended here, if it is not geared to a single subject domain, but can be ported with a reasonable effort to a varisubject domains. It is common understanding that there exists a central fragment of a language %vhich I. is required for dealing with virtually any subject domain, and 2. is invariant with respect to meaning and use accross subject domains. It is of course a non-trivial empirical question whether such a central fragment really exists, and if so, to say what it is, but a number of researchers seem to share the assumption that it does (cf. e.g. Alshawi et al. (19/N)). Any robust and portable system would then have to handle this core fragment. In this paper I am concerned with a second related — assumption, namely that exists a core vocabulary which is needed for handlsubject domain. This assumption also many researchers, and it the production of basic vocabularies for language learning such as Oehler (1980). lisually the authors claim that their word lists are based on statistical investigations, but they also emphasize did not slavishly stick to the statistics but used additional criteria such as &amp;quot;usage &amp;quot;availability&amp;quot;, &amp;quot;familiarity&amp;quot;, or &amp;quot;learnability&amp;quot; without ever saying how these are I will address the following questions: low the intuitive notion of vocabbe defined&apos;? statistical methods be employed to define a core vocabulary and how do they relate to semantic criteria? 3. What semantic criteria can be found to define a core vocabulary? Definitions of a core vocabulary are several ways to define I think of the following three: The core vocabulary consists of the frequent words of a language. 2&apos;. The core vocabulary is that vocabulary which is common to all native speakers of a language. 3. The semantic core vocabulary consists of words which suffice to define remaining vocabulary of a language. The first two definitions call for statistical methods which shall be discussed in the next and the third one obviously requires which shall he discussed in section &amp;quot;Semantic criteria&amp;quot;. Statistical methods Frequency counts have well established the basic properties of the frequency distribution for text corpora. Thus in Kucera and Francis (1967) we get coverage figures like this for their complete corpus of about I million tokens: 10 most frequent words: 24.26 % 100 most frequent words: 47.43 % 1000 most frequent words: 68.86 % The research described here has been conducted in the context of the 1.11,06 project (Ilerzog et at., 1986). profiled front intensive discussions with R. Mayer, Much of the underlying statistical work on text corpora is due to U. Damian&apos; and (;. Watch from the speech recognition project SPRING (Wothke et at., 1989). investigations arc based on German, but for ease of reference also some English examples are given. - 303 - These figures vary only slightly with corpus size, and also for German similar values are observed. I lowever, while coverage figures arc rather stable respect to the frequent words of a what are the frequent words may vary widely with corpora or subcorpora. Two parameters responsible for this variation are obvious: 1. Subject matter and 2. • Communicative function. Thus in the &amp;quot;Kultur&amp;quot; section of a newspaper which we have analyzed we see that words like Theater, Regisseur, occur with a drastically higher frequency than in the other sections, which of course can be attributed to subject matter. But personal pronouns, in particular 1st and 2nd person pronouns, also show a much higher frequency, and this can hardly be attributed to subject matter, rather to different communicative functions of feuilletonistic writing and say economic news. All of this relates of course to the much discussed issue of what constitutes a representatitve corpus for statistical linguistic analysis. Since specific subject matters and communicative functions vary in importance for different speakers of a language, it will be difficult if not impossible to eliminate arbitrariness. Rather, a definition of representative corpus must take into account the research goals pursued. For a natural language system which is supposed to analyze and generate texts, to engage in dialogues with users, and which is to acquire from the of definitions and rules formulated in natural language, one needs corpus of texts where all aspects sufrepresented. We to upon a variety of corpora none of which would show all the features required, but the combination of them seems to be quite reasonable. We compared the following five word lists: I. Oehler (1980): Grundwortschatz consisting of 2247 words, Erk (1972): scientific texts from 34 disciplines, 1283 words with frequency 20, 3. Pregel/Rickhcit (1987): texts by primary school children, 593 words with frequency &gt; 20, 4. SPRING-corpus of newspaper texts, 2733 most frequent words, 5. DUDEN (1989): definitions for words bewith with frequency &gt;4. these, word lists formed consisting those words occurring in at least the oriword lists (1 &lt; &lt; 5). lengths of these are 5409, : 2248, 1215, /14: 565, and size of shows that a really common core of a variety of texts may be extremely small, the successive losening of restrictions used here allows for a balanced extension of this very small The list chosen as the statistical core vocabulary serving as a base for applying semantic criteria, because the overall core vocabulary was envisaged to have a size of approx. 1500 words. Inspection shows that many intuitively basic words and very few idiosyncratic words are contained due to the method of intersecting the lists. !knee, seems quite reasonable. Semantic criteria one takes the frequent words of any frequency count one will no doubt discover that these words will not exhibit a linguistic closure in the sense that natural sentences can be formed with all and only the words in the set. Further one will see that semantic relations will be incomplete. Thus one finds in Oehler (1980) which based on the old Kaeding count that but not its antonym a core vocabulary to be set up for a natural language system, I think, one must strive for linguistic closure, since otherwise, one ends up with words one cannot use. This means that you cannot base the core vocabulary on frequency counts alone. Furthermore, one cannot expect that one will have just the vocabulary needed to formulate definitions for the words in the list chosen. To avoid circularity, one will have to accept that certain words cannot be defined within the vobut one will have to accept that for some words less than complete definitions can be given. Because of this lack of definability, core vocabulary only be understood as an approxitnative notion geared towards &amp;quot;the best one can do&amp;quot;. What one can hope to do, is to define I. taxonomic relations, &amp;quot;selectional restrictions&amp;quot; constraints on semantic compatibility, and 3. meaning rules of arbitrary complexity (including classical definitions). I propose to formulate all of these types of rules in natural language for 11 trying to stay within at least the vocabulary of Il , to add the words used in the formulations to the original set, and continue until one cannot think of further rules. I claim that one can achieve a fixed point from where on no new words are added to the set, and that at this moment one has reached a rather good approximation to a semantic core vocabulary. There is undoubtedly a relationship between frequency and semantic relevance: since taxonomic relations are often exemplified by anaphoric references, since semantic compatibilconstraints lead to the co-occurrence of ap- - 304 propriate words, and since other more complex semantic relationships arc bound to be exhibited in the various threads of discourse, one has all reason to expect a certain amount of congruence between frequency counts and the semantic core vocabulary as defined above. The work on formulating taxonomic relations, semantic constraints and other meaning rules is underway, and since it will involve all of the vocabulary, linguistic closure will be achieved at the same time. As an example, take a taxonomic rule for is in Jeder (B3) Arm 1st Tei 1 (84) eines Korpers (83) (Every arm is part of a body.) word (body part) only availin and was therefore not used, or instead could also have used then the rule would not have covered arms of machines or rivers. This highlights a big problem in the natural language formulation of meaning rules: how is ambiguity dealt with? Space does not permit a full discussion here, therefore suffice it to say that it is one of our research goals to formulate meaning rules which specify criteria for disambiguation. Linguistic description The preceding discussion has concentrated on how to establish a core vocabulary. Now a few brief remarks shall follow on how the words of the core vocabulary can be linguistically described. The morphology of languages such as German is well understood and has been coded for an extended vocabulary in the lexical database of the LEX project (Barnett et al., 1986). This database also contains detailed syntactic information, in particular on government patterns. It is the description of the semantic (and pragmatic) properties of many words one would obviously want to include in a core vocabulary that will confront us with huge unsolved theoretical problems. Be it modal verbs or propositional attitudes, sentence adverbs or &amp;quot;abstract&amp;quot; nouns of various kinds. Investigations on some individual words have generated heaps of literature, for others it seems that people have not even dared to look at them. Does this make the enterprise of implementing a core vocabulary a one? not. I think the implementation of a core vocabulary should be seen as a long-range research goal for both computational and theoretical linguistics, and furthermore that natural language systems provide a good environment for doing experiments in semantics, beencourage an integrated treatment of linguistic phenomena. Conclusions Our research on establishing a core vocabulary for German in the framework of the 1,ILOG project has revealed that currently no absolute definition can be given, but ways have been. shown how to arrive at a working definition with respect to the objectives of natural language systems. It has been shown that both statistical methods and semantic criteria can, and I think, have to contribute to the establishment of a core vocabulary. The linguistic description and thus the implementation of a core vocabulary depends heavily on progress in theoretical linguistics, in particular in semantics and pragmatics, but I want to stress that focussing on a core vocabulary is a fruitful way to direct linguistic research, which can be supported by the need for integrated treatments in natural language systems.</abstract>
<note confidence="0.7296705">References M. Carter, .1. van Eijck, R. C. Moore, D. B. Moran, F. C. N. Pereira, and A. G. Smith (1988): &amp;quot;Research Programme in Na-</note>
<affiliation confidence="0.726225333333333">tural Language Processing — Annual Report&amp;quot;, Project Document NA-I6, SRI International.</affiliation>
<address confidence="0.81749">B., II. Zoeppritz</address>
<note confidence="0.967180791666667">(1986): &amp;quot;A word database for natural language 1 1 th International Conference on Computational Linguistics COL1NG86 Augttst 2.5th to 29th, 1986, Holm, Federal 1?epub- Germany. 435-440. (1972): Lexik wissenschaftlicher Ilueber. • I lerzog, 0. et al. (1986): &amp;quot;1.11,06 — Linand I ATic Methods for the Computational Understanding of German&amp;quot;, Report Stuttgart: 113M Deutschland. N. Francis (1967): Computational Analysis of Present-Day American English. Providence, RI: Brown University Press. Grundund Deutsch. Klett. Rickheit (1987): Wortschatz bn Grundschulaher. Ilildeshcim: Olms. Wothke, K., U. I3andara, J. Kempf, E. Keppel, K. Mohr, G. Walch (1989): &amp;quot;The SPRING Speech Recognition System for in: of Eurospeech &apos;89. - 305 -</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R C Moore van Eijck</author>
<author>D B Moran</author>
<author>F C N Pereira</author>
<author>A G Smith</author>
</authors>
<title>Research Programme</title>
<date>1988</date>
<booktitle>in Natural Language Processing — Annual Report&amp;quot;, Nattie Project Document NA-I6,</booktitle>
<publisher>SRI International.</publisher>
<location>Cambridge:</location>
<marker>van Eijck, Moran, Pereira, Smith, 1988</marker>
<rawString>Alshawi, II., D. M. Carter, .1. van Eijck, R. C. Moore, D. B. Moran, F. C. N. Pereira, and A. G. Smith (1988): &amp;quot;Research Programme in Natural Language Processing — Annual Report&amp;quot;, Nattie Project Document NA-I6, Cambridge: SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I chmann</author>
<author>M Zoeppritz</author>
</authors>
<title>A word database for natural language processing&amp;quot;,</title>
<date>1986</date>
<booktitle>Proceedings 1 1 th International Conference on Computational Linguistics COL1NG86 Augttst 2.5th to 29th,</booktitle>
<pages>435--440</pages>
<marker>chmann, Zoeppritz, 1986</marker>
<rawString>Barnett, B., II. I,chmann, M. Zoeppritz (1986): &amp;quot;A word database for natural language processing&amp;quot;, Proceedings 1 1 th International Conference on Computational Linguistics COL1NG86 Augttst 2.5th to 29th, 1986, Holm, Federal 1?epublic of Germany. 435-440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frk</author>
</authors>
<title>Zur Lexik wissenschaftlicher Fachtexte,</title>
<date>1972</date>
<location>München: Ilueber.</location>
<marker>Frk, 1972</marker>
<rawString>Frk, II. (1972): Zur Lexik wissenschaftlicher Fachtexte, München: Ilueber.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I lerzog</author>
</authors>
<title>1.11,06 — Linguistic and I ATic Methods for the Computational Understanding of German&amp;quot;,</title>
<date>1986</date>
<tech>1,11,0G- Report /I), Stuttgart: 113M Deutschland.</tech>
<marker>lerzog, 1986</marker>
<rawString>• I lerzog, 0. et al. (1986): &amp;quot;1.11,06 — Linguistic and I ATic Methods for the Computational Understanding of German&amp;quot;, 1,11,0G- Report /I), Stuttgart: 113M Deutschland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W N Francis Kucera</author>
</authors>
<title>Computational Analysis of Present-Day American English.</title>
<date>1967</date>
<publisher>Brown University Press.</publisher>
<location>Providence, RI:</location>
<marker>Kucera, 1967</marker>
<rawString>Kucera, II., W. N. Francis (1967): Computational Analysis of Present-Day American English. Providence, RI: Brown University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oehler</author>
</authors>
<title>KLETT Grund- und Aujbauwortschatz Deutsch.</title>
<date>1980</date>
<location>Stuttgart: Klett.</location>
<contexts>
<context position="2035" citStr="Oehler (1980)" startWordPosition="341" endWordPosition="342"> is of course a non-trivial empirical question whether such a central fragment really exists, and if so, to say what it is, but a number of researchers seem to share the assumption that it does (cf. e.g. Alshawi et al. (19/N)). Any robust and portable system would then have to handle this core fragment. In this paper I am concerned with a second — related — assumption, namely that there exists a core vocabulary which is needed for handling any subject domain. This assumption is also shared by many researchers, and it underlies the production of basic vocabularies for language learning such as Oehler (1980). lisually the authors claim that their word lists are based on statistical investigations, but they also emphasize that, they did not slavishly stick to the statistics but used additional criteria such as &amp;quot;usage value&amp;quot;, &amp;quot;availability&amp;quot;, &amp;quot;familiarity&amp;quot;, or &amp;quot;learnability&amp;quot; without ever saying how these are est ablished.2 I will address the following questions: 1. I low can the intuitive notion of core vocabulary be properly defined&apos;? 2.. How can statistical methods be employed to define a core vocabulary and how do they relate to semantic criteria? 3. What semantic criteria can be found to define </context>
<context position="5905" citStr="Oehler (1980)" startWordPosition="977" endWordPosition="978">r, a definition of representative corpus must take into account the research goals pursued. For a natural language system which is supposed to analyze and generate texts, to engage in dialogues with users, and which is to acquire knowledge from the analysis of definitions and rules formulated in natural language, one needs a corpus of texts where all these aspects are sufficiently represented. We Weie able to draw upon a variety of corpora none of which would show all the features required, but the combination of them seems to be quite reasonable. We compared the following five word lists: I. Oehler (1980): Grundwortschatz consisting of 2247 words, 2. Erk (1972): scientific texts from 34 disciplines, 1283 words with frequency 20, 3. Pregel/Rickhcit (1987): texts by primary school children, 593 words with frequency &gt; 20, 4. SPRING-corpus of newspaper texts, 2733 most frequent words, 5. DUDEN (1989): definitions for words beginning with a, 2693 words with frequency &gt;4. From these, word lists 11„ were formed consisting of those words occurring in at least n of the original word lists (1 &lt; n &lt; 5). The lengths of these lists are B1: 5409, /32 : 2248, 113: 1215, /14: 565, and 115: 116. The size of Bs</context>
<context position="7420" citStr="Oehler (1980)" startWordPosition="1241" endWordPosition="1242"> the overall core vocabulary was envisaged to have a size of approx. 1500 words. Inspection shows that many intuitively basic words and very few idiosyncratic words are contained due to the method of intersecting the word lists. !knee, /./3 seems quite reasonable. Semantic criteria If one takes the n most frequent words of any frequency count one will no doubt discover that these words will not exhibit a linguistic closure in the sense that natural sentences can be formed with all and only the words in the set. Further one will see that semantic relations will be incomplete. Thus one finds in Oehler (1980) which is based on the old Kaeding count that weiblich (female) occurs but not its antonym miinnlich (male). I7or a core vocabulary to be set up for a natural language system, I think, one must strive for linguistic closure, since otherwise, one ends up with words one cannot use. This means that you cannot base the core vocabulary on frequency counts alone. Furthermore, one cannot expect that one will have just the vocabulary needed to formulate definitions for the words in the list chosen. To avoid circularity, one will have to accept that certain words cannot be defined within the vocabulary</context>
</contexts>
<marker>Oehler, 1980</marker>
<rawString>Oehler, II. (1980): KLETT Grund- und Aujbauwortschatz Deutsch. Stuttgart: Klett.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Pregel</author>
<author>G Rickheit</author>
</authors>
<title>Der Wortschatz bn Grundschulaher. Ilildeshcim: Olms.</title>
<date>1987</date>
<marker>Pregel, Rickheit, 1987</marker>
<rawString>Pregel, D., G. Rickheit (1987): Der Wortschatz bn Grundschulaher. Ilildeshcim: Olms.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Wothke</author>
<author>U I3andara</author>
<author>J Kempf</author>
<author>E Keppel</author>
<author>K Mohr</author>
<author>G Walch</author>
</authors>
<title>The SPRING Speech Recognition System for German&amp;quot;, in:</title>
<date>1989</date>
<booktitle>Proceedings of Eurospeech &apos;89.</booktitle>
<volume>2</volume>
<pages>9--12</pages>
<marker>Wothke, I3andara, Kempf, Keppel, Mohr, Walch, 1989</marker>
<rawString>Wothke, K., U. I3andara, J. Kempf, E. Keppel, K. Mohr, G. Walch (1989): &amp;quot;The SPRING Speech Recognition System for German&amp;quot;, in: Proceedings of Eurospeech &apos;89. Vol. 2, 9-12.</rawString>
</citation>
<citation valid="false">
<pages>305</pages>
<marker></marker>
<rawString>- 305 -</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>