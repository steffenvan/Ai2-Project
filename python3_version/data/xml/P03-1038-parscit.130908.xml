<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000282">
<title confidence="0.996231">
Self-Organizing Markov Models and
Their Application to Part-of-Speech Tagging
</title>
<author confidence="0.982633">
Jin-Dong Kim
</author>
<affiliation confidence="0.9739514">
Dept. of Computer Science
University of Tokyo
Hae-Chang Rim
Dept. of Computer Science
Korea University
</affiliation>
<email confidence="0.947567">
rim@nlp.korea.ac.kr
jdkim@is.s.u-tokyo.ac.jp
</email>
<author confidence="0.986044">
Jun’ich Tsujii
</author>
<affiliation confidence="0.999227">
Dept. of Computer Science
University of Tokyo, and
</affiliation>
<address confidence="0.736969">
CREST, JST
</address>
<email confidence="0.998588">
tsujii@is.s.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.995634" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999902333333333">
This paper presents a method to de-
velop a class of variable memory Markov
models that have higher memory capac-
ity than traditional (uniform memory)
Markov models. The structure of the vari-
able memory models is induced from a
manually annotated corpus through a de-
cision tree learning algorithm. A series of
comparative experiments show the result-
ing models outperform uniform memory
Markov models in a part-of-speech tag-
ging task.
</bodyText>
<sectionHeader confidence="0.998988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999015627906977">
Many major NLP tasks can be regarded as prob-
lems of finding an optimal valuation for random
processes. For example, for a given word se-
quence, part-of-speech (POS) tagging involves find-
ing an optimal sequence of syntactic classes, and NP
chunking involves finding IOB tag sequences (each
of which represents the inside, outside and begin-
ning of noun phrases respectively).
Many machine learning techniques have been de-
veloped to tackle such random process tasks, which
include Hidden Markov Models (HMMs) (Rabiner,
1989), Maximum Entropy Models (MEs) (Rat-
naparkhi, 1996), Support Vector Machines
(SVMs) (Vapnik, 1998), etc. Among them,
SVMs have high memory capacity and show high
performance, especially when the target classifica-
tion requires the consideration of various features.
On the other hand, HMMs have low memory
capacity but they work very well, especially when
the target task involves a series of classifications that
are tightly related to each other and requires global
optimization of them. As for POS tagging, recent
comparisons (Brants, 2000; Schr¨oder, 2001) show
that HMMs work better than other models when
they are combined with good smoothing techniques
and with handling of unknown words.
While global optimization is the strong point of
HMMs, developers often complain that it is difficult
to make HMMs incorporate various features and to
improve them beyond given performances. For ex-
ample, we often find that in some cases a certain
lexical context can improve the performance of an
HMM-based POS tagger, but incorporating such ad-
ditional features is not easy and it may even degrade
the overall performance. Because Markov models
have the structure of tightly coupled states, an ar-
bitrary change without elaborate consideration can
spoil the overall structure.
This paper presents a way of utilizing statistical
decision trees to systematically raise the memory
capacity of Markov models and effectively to make
Markov models be able to accommodate various fea-
tures.
</bodyText>
<sectionHeader confidence="0.996225" genericHeader="method">
2 Underlying Model
</sectionHeader>
<bodyText confidence="0.999921666666667">
The tagging model is probabilistically defined as
finding the most probable tag sequence when a word
sequence is given (equation (1)).
</bodyText>
<equation confidence="0.99988">
T(wi,k) = arg maxP(t1,k|w1,k) (1)
t1,k
=arg max P(t1,k)P(w1,k|t1,k) (2)
t1,k
P(ti|ti−1)P(wi|ti) (3)
</equation>
<bodyText confidence="0.9990575">
By applying Bayes’ formula and eliminating a re-
dundant term not affecting the argument maximiza-
tion, we can obtain equation (2) which is a combi-
nation of two separate models: the tag language
model, P(t1,k) and the tag-to-word translation
model, P(w1,k|t1,k). Because the number of word
sequences, w1,k and tag sequences, t1,k is infinite,
the model of equation (2) is not computationally
tractable. Introduction of Markov assumption re-
duces the complexity of the tag language model and
independent assumption between words makes the
tag-to-word translation model simple, which result
in equation (3) representing the well-known Hidden
Markov Model.
</bodyText>
<sectionHeader confidence="0.889241" genericHeader="method">
3 Effect of Context Classification
</sectionHeader>
<bodyText confidence="0.999936833333333">
Let’s focus on the Markov assumption which is
made to reduce the complexity of the original tag-
ging problem and to make the tagging problem
tractable. We can imagine the following process
through which the Markov assumption can be intro-
duced in terms of context classification:
</bodyText>
<equation confidence="0.998153222222222">
�k7
P(T = t1,k) = 11
i=1
k
 P(ti|-b(t1,i−1)) (5)
i=1
k
 P(ti|ti−1) (6)
i=1
</equation>
<bodyText confidence="0.9895638">
In equation (5), a classification function -b(t1,i−1) is
introduced, which is a mapping of infinite contextual
patterns into a set of finite equivalence classes. By
defining the function as follows we can get equation
(6) which represents a widely-used bi-gram model:
</bodyText>
<equation confidence="0.99237">
-b(t1,i−1)  ti−1 (7)
</equation>
<bodyText confidence="0.9950488">
Equation (7) classifies all the contextual patterns
ending in same tags into the same classes, and is
equivalent to the Markov assumption.
The assumption or the definition of the above
classification function is based on human intuition.
</bodyText>
<figureCaption confidence="0.996995">
Figure 1: Effect of 1’st and 2’nd order context
</figureCaption>
<equation confidence="0.998755666666667">
P(∗  |prep ,&apos; in&apos; )
P (∗  |prep ,&apos; with&apos; )
P(∗  |prep , &apos; out&apos; )
</equation>
<figureCaption confidence="0.910312">
Figure 2: Effect of context with and without lexical
information
</figureCaption>
<bodyText confidence="0.999131">
Although this simple definition works well mostly,
because it is not based on any intensive analysis of
real data, there is room for improvement. Figure 1
and 2 illustrate the effect of context classification on
the compiled distribution of syntactic classes, which
we believe provides the clue to the improvement.
Among the four distributions showed in Figure 1,
the top one illustrates the distribution of syntactic
classes in the Brown corpus that appear after all the
conjunctions. In this case, we can say that we are
considering the first order context (the immediately
preceding words in terms of part-of-speech). The
following three ones illustrates the distributions col-
lected after taking the second order context into con-
sideration. In these cases, we can say that we have
extended the context into second order or we have
classified the first order context classes again into
second order context classes. It shows that distri-
butions like P(|vb,conj) and P(|vbp, conj) are
very different from the first order ones, while distri-
butions like P(|fw, conj) are not.
Figure 2 shows another way of context extension,
so called lexicalization. Here, the initial first order
</bodyText>
<equation confidence="0.9412659375">
P(∗  |Sw, conj )
P (∗  |vb , conj )
P (∗  |vbp , conj )
P(∗  |conj )
vb v
vbpvbp
P(∗|prep)
at a
nn n
 arg max
t1,k
k
i=1
P(ti|t1,i−1) (4)
prep
prep
</equation>
<bodyText confidence="0.9999739">
context class (the top one) is classified again by re-
ferring the lexical information (the following three
ones). We see that the distribution after the prepo-
sition, out is quite different from distribution after
other prepositions.
From the above observations, we can see that by
applying Markov assumptions we may miss much
useful contextual information, or by getting a better
context classification we can build a better context
model.
</bodyText>
<sectionHeader confidence="0.999682" genericHeader="method">
4 Related Works
</sectionHeader>
<bodyText confidence="0.999762057142857">
One of the straightforward ways of context exten-
sion is extending context uniformly. Tri-gram tag-
ging models can be thought of as a result of the
uniform extension of context from bi-gram tagging
models. TnT (Brants, 2000) based on a second or-
der HMM, is an example of this class of models and
is accepted as one of the best part-of-speech taggers
used around.
The uniform extension can be achieved (rela-
tively) easily, but due to the exponential growth of
the model size, it can only be performed in restric-
tive a way.
Another way of context extension is the selective
extension of context. In the case of context exten-
sion from lower context to higher like the examples
in figure 1, the extension involves taking more infor-
mation about the same type of contextual features.
We call this kind of extension homogeneous con-
text extension. (Brants, 1998) presents this type of
context extension method through model merging
and splitting, and also prediction suffix tree learn-
ing (Sch¨utze and Singer, 1994; D. Ron et. al, 1996)
is another well-known method that can perform ho-
mogeneous context extension.
On the other hand, figure 2 illustrates heteroge-
neous context extension, in other words, this type
of extension involves taking more information about
other types of contextual features. (Kim et. al, 1999)
and (Pla and Molina, 2001) present this type of con-
text extension method, so called selective lexicaliza-
tion.
The selective extension can be a good alternative
to the uniform extension, because the growth rate
of the model size is much smaller, and thus various
contextual features can be exploited. In the follow-
</bodyText>
<figureCaption confidence="0.927694">
Figure 3: a Markov model and its equivalent deci-
sion tree
</figureCaption>
<bodyText confidence="0.997333333333333">
ing sections, we describe a novel method of selective
extension of context which performs both homoge-
neous and heterogeneous extension simultaneously.
</bodyText>
<sectionHeader confidence="0.938491" genericHeader="method">
5 Self-Organizing Markov Models
</sectionHeader>
<bodyText confidence="0.999981555555556">
Our approach to the selective context extension is
making use of the statistical decision tree frame-
work. The states of Markov models are represented
in statistical decision trees, and by growing the trees
the context can be extended (or the states can be
split).
We have named the resulting models Self-
Organizing Markov Models to reflect their ability to
automatically organize the structure.
</bodyText>
<subsectionHeader confidence="0.9918275">
5.1 Statistical Decision Tree Representation of
Markov Models
</subsectionHeader>
<bodyText confidence="0.98280052631579">
The decision tree is a well known structure that is
widely used for classification tasks. When there are
several contextual features relating to the classifi-
cation of a target feature, a decision tree organizes
the features as the internal nodes in a manner where
more informative features will take higher levels, so
the most informative feature will be the root node.
Each path from the root node to a leaf node repre-
sents a context class and the classification informa-
tion for the target feature in the context class will be
contained in the leaf node1.
In the case of part-of-speech tagging, a classifi-
cation will be made at each position (or time) of a
word sequence, where the target feature is the syn-
tactic class of the word at current position (or time)
and the contextual features may include the syntactic
&apos;While ordinary decision trees store deterministic classifi-
cation information in their leaves, statistical decision trees store
probabilistic distribution of possible decisions.
</bodyText>
<figure confidence="0.996993833333333">
N C
P V
$
$ C N P V
$ C N P V
P-1
</figure>
<figureCaption confidence="0.9740765">
Figure 4: a selectively lexicalized Markov model
and its equivalent decision tree
Figure 5: a selectively extended Markov model and
its equivalent decision tree
</figureCaption>
<bodyText confidence="0.999189565217392">
classes or the lexical form of preceding words. Fig-
ure 3 shows an example of Markov model for a sim-
ple language having nouns (N), conjunctions (C),
prepositions (P) and verbs (V). The dollar sign ($)
represents sentence initialization. On the left hand
side is the graph representation of the Markov model
and on the right hand side is the decision tree repre-
sentation, where the test for the immediately preced-
ing syntactic class (represented by P-1) is placed on
the root, each branch represents a result of the test
(which is labeled on the arc), and the correspond-
ing leaf node contains the probabilistic distribution
of the syntactic classes for the current position2.
The example shown in figure 4 involves a further
classification of context. On the left hand side, it is
represented in terms of state splitting, while on the
right hand side in terms of context extension (lexi-
calization), where a context class representing con-
textual patterns ending in P (a preposition) is ex-
tended by referring the lexical form and is classi-
fied again into the preposition, out and other prepo-
sitions.
Figure 5 shows another further classification of
</bodyText>
<footnote confidence="0.782374333333333">
2The distribution doesn’t appear in the figure explicitly. Just
imagine each leaf node has the distribution for the target feature
in the corresponding context.
</footnote>
<bodyText confidence="0.9970121">
context. It involves a homogeneous extension of
context while the previous one involves a hetero-
geneous extension. Unlike prediction suffix trees
which grow along an implicitly fixed order, decision
trees don’t presume any implicit order between con-
textual features and thus naturally can accommodate
various features having no underlying order.
In order for a statistical decision tree to be a
Markov model, it must meet the following restric-
tions:
</bodyText>
<listItem confidence="0.9874358">
• There must exist at least one contextual feature
that is homogeneous with the target feature.
• When the target feature at a certain time is clas-
sified, all the requiring context features must be
visible
</listItem>
<bodyText confidence="0.999815333333333">
The first restriction states that in order to be a
Markov model, there must be inter-relations be-
tween the target features at different time. The sec-
ond restriction explicitly states that in order for the
decision tree to be able to classify contextual pat-
terns, all the context features must be visible, and
implicitly states that homogeneous context features
that appear later than the current target feature can-
not be contextual features. Due to the second re-
striction, the Viterbi algorithm can be used with the
self-organizing Markov models to find an optimal
sequence of tags for a given word sequence.
</bodyText>
<subsectionHeader confidence="0.999871">
5.2 Learning Self-Organizing Markov Models
</subsectionHeader>
<bodyText confidence="0.999963117647059">
Self-organizing Markov models can be induced
from manually annotated corpora through the SDTL
algorithm (algorithm 1) we have designed. It is a
variation of ID3 algorithm (Quinlan, 1986). SDTL
is a greedy algorithm where at each time of the node
making phase the most informative feature is se-
lected (line 2), and it is a recursive algorithm in the
sense that the algorithm is called recursively to make
child nodes (line 3),
Though theoretically any statistical decision tree
growing algorithms can be used to train self-
organizing Markov models, there are practical prob-
lems we face when we try to apply the algorithms to
language learning problems. One of the main obsta-
cles is the fact that features used for language learn-
ing often have huge sets of values, which cause in-
tensive fragmentation of the training corpus along
</bodyText>
<figure confidence="0.993029">
N C
,P,*
,t P,out ,P,*
V
, P,out
$
$ C N
$ C N P V
-P-1
W-1
V
N
,P,*
(N)C (V)C (*)C ,t P,out ,P,*
V
, P,out
$
(N(N)C
(V)C
(*)C
$
$ C N P V
P-2
-P-1
N
W-1
V
</figure>
<bodyText confidence="0.999614035714286">
with the growing process and eventually raise the
sparse data problem.
To deal with this problem, the algorithm incor-
porates a value selection mechanism (line 1) where
only meaningful values are selected into a reduced
value set. The meaningful values are statistically
defined as follows: if the distribution of the target
feature varies significantly by referring to the value
v, v is accepted as a meaningful value. We adopted
the x2-test to determine the difference between the
distributions of the target feature before and after re-
ferring to the value v. The use of x2-test enables
us to make a principled decision about the threshold
based on a certain confidence level3.
To evaluate the contribution of contextual features
to the target classification (line 2), we adopted Lopez
distance (L´opez, 1991). While other measures in-
cluding Information Gain or Gain Ratio (Quinlan,
1986) also can be used for this purpose, the Lopez
distance has been reported to yield slightly better re-
sults (L´opez, 1998).
The probabilistic distribution of the target fea-
ture estimated on a node making phase (line 4) is
smoothed by using Jelinek and Mercer’s interpola-
tion method (Jelinek and Mercer, 1980) along the
ancestor nodes. The interpolation parameters are
estimated by deleted interpolation algorithm intro-
duced in (Brants, 2000).
</bodyText>
<sectionHeader confidence="0.999029" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999587133333333">
We performed a series of experiments to compare
the performance of self-organizing Markov models
with traditional Markov models. Wall Street Jour-
nal as contained in Penn Treebank II is used as the
reference material. As the experimental task is part-
of-speech tagging, all other annotations like syntac-
tic bracketing have been removed from the corpus.
Every figure (digit) in the corpus has been changed
into a special symbol.
From the whole corpus, every 10’th sentence from
the first is selected into the test corpus, and the re-
maining ones constitute the training corpus. Table 6
shows some basic statistics of the corpora.
We implemented several tagging models based on
equation (3). For the tag language model, we used
</bodyText>
<footnote confidence="0.995300666666667">
3We used 95% of confidence level to extend context. In
other words, only when there are enough evidences for improve-
ment at 95% of confidence level, a context is extended.
</footnote>
<table confidence="0.809533333333333">
Algorithm 1: SDTL(E, t, F)
Data : E: set of examples,
t: target feature,
F: set of contextual features
Result : Statistical Decision Tree predicting t
initialize a null node;
for each element f in the set F do
sort meaningful value set V for f ;
if |V  |&gt; 1 then
</table>
<bodyText confidence="0.963882666666667">
measure the contribution of f to t;
if f contributes the most then
select f as the best feature b;
</bodyText>
<listItem confidence="0.653799">
end
end
end
</listItem>
<bodyText confidence="0.890503">
if there is b selected then
set the current node to an internal node;
set b as the test feature of the current node;
3 for each v in |V  |for b do
make SDTL(Eb=v, t, F − {b}) as the
subtree for the branch corresponding to
v;
end
end
else
set the current node to a leaf node;
4 store the probability distribution of t over
</bodyText>
<table confidence="0.704779857142857">
E ;
end
return current node;
set # sencences words#
Training 61,731 1,160,101
Test 6,859 129,100
Total 68,590 1,289,201
</table>
<figureCaption confidence="0.907071">
Figure 6: Basic statistics of corpora
</figureCaption>
<equation confidence="0.865170666666667">
1
2
the following 6 approximations:
P(ti|ti−1) (8)
P(ti|ti−2,i−1) (9)
P(ti|-b(ti−2,i−1)) (10)
P(ti|-b(ti−1, wi−1)) (11)
P(ti|-b(ti−2,i−1, wi−1)) (12)
P(ti|-b(ti−2,i−1, wi−2,i−1))(13)
</equation>
<bodyText confidence="0.99837525">
Equation (8) and (9) represent first- and second-
order Markov models respectively. Equation (10)
— (13) represent self-organizing Markov models at
various settings where the classification functions
4b(•) are intended to be induced from the training
corpus.
For the estimation of the tag-to-word translation
model we used the following model:
</bodyText>
<equation confidence="0.99642">
P(wi|ti)
= ki x P(ki|ti) x Pˆ(wi|ti)
+(1 − ki) x P(¬ki|ti) x Pˆ(ei|ti) (14)
</equation>
<bodyText confidence="0.99946741509434">
Equation (14) uses two different models to estimate
the translation model. If the word, wi is a known
word, ki is set to 1 so the second model is ig-
nored. Pˆ means the maximum likelihood probabil-
ity. P(ki|ti) is the probability of knownness gener-
ated from ti and is estimated by using Good-Turing
estimation (Gale and Samson, 1995). If the word, wi
is an unknown word, ki is set to 0 and the first term
is ignored. ei represents suffix of wi and we used the
last two letters for it.
With the 6 tag language models and the 1 tag-to-
word translation model, we construct 6 HMM mod-
els, among them 2 are traditional first- and second-
hidden Markov models, and 4 are self-organizing
hidden Markov models. Additionally, we used T3,
a tri-gram-based POS tagger in ICOPOST release
1.8.3 for comparison.
The overall performances of the resulting models
estimated from the test corpus are listed in figure 7.
From the leftmost column, it shows the model name,
the contextual features, the target features, the per-
formance and the model size of our 6 implementa-
tions of Markov models and additionally the perfor-
mance of T3 is shown.
Our implementation of the second-order hid-
den Markov model (HMM-P2) achieved a slightly
worse performance than T3, which, we are in-
terpreting, is due to the relatively simple imple-
mentation of our unknown word guessing module4.
While HMM-P2 is a uniformly extended model
from HMM-P1, SOHMM-P2 has been selectively
extended using the same contextual feature. It is
encouraging that the self-organizing model suppress
the increase of the model size in half (2,099Kbyte vs
5,630Kbyte) without loss of performance (96.5%).
In a sense, the results of incorporating word
features (SOHMM-P1W1, SOHMM-P2W1 and
SOHMM-P2W2) are disappointing. The improve-
ments of performances are very small compared to
the increase of the model size. Our interpretation
for the results is that because the distribution of
words is huge, no matter how many words the mod-
els incorporate into context modeling, only a few of
them may actually contribute during test phase. We
are planning to use more general features like word
class, suffix, etc.
Another positive observation is that a homo-
geneous context extension (SOHMM-P2) and a
heterogeneous context extension (SOHMM-P1W1)
yielded significant improvements respectively, and
the combination (SOHMM-P2W1) yielded even
more improvement. This is a strong point of using
decision trees rather than prediction suffix trees.
</bodyText>
<sectionHeader confidence="0.998934" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999540142857143">
Through this paper, we have presented a framework
of self-organizing Markov model learning. The
experimental results showed some encouraging as-
pects of the framework and at the same time showed
the direction towards further improvements. Be-
cause all the Markov models are represented as de-
cision trees in the framework, the models are hu-
</bodyText>
<footnote confidence="0.883438">
4T3 uses a suffix trie for unknown word guessing, while our
implementations use just last two letters.
</footnote>
<figure confidence="0.811663">
�k7
P(t1,k) 11
i=1
�
�
�
�
�
k
i=1
k
i=1
k
i=1
k
i=1
k
i=1
</figure>
<table confidence="0.914119">
Model C Features T Precision Model Size
HMM-P1 P-1 T0 95.6 123K
HMM-P2 P-2, P-1 T0 96.5 5,630K
T3 • • 96.6 •
SOHMM-P2 P-2, P-1 T0 96.5 2,099K
SOHMM-P1W1 W-1, P-1 T0 96.3 14,247K
SOHMM-P2W1 P-2, W-1, P-1 T0 96.8 24,628K
SOHMM-P2W2 W-2, P-2, W-1, P-1 T0 96.9 35,494K
</table>
<figureCaption confidence="0.99967">
Figure 7: Estimated Performance of Various Models
</figureCaption>
<bodyText confidence="0.999893333333334">
man readable and we are planning to develop editing
tools for self-organizing Markov models that help
experts to put human knowledge about language into
the models. By adopting x2-test as the criterion for
potential improvement, we can control the degree of
context extension based on the confidence level.
</bodyText>
<sectionHeader confidence="0.977237" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.972629666666667">
The research is partially supported by Information
Mobility Project (CREST, JST, Japan) and Genome
Information Science Project (MEXT, Japan).
</bodyText>
<sectionHeader confidence="0.997114" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99958094">
L. Rabiner. 1989. A tutorial on Hidden Markov Mod-
els and selected applications in speech recognition. in
Proceedings of the IEEE, 77(2):257–285
A. Ratnaparkhi. 1996. A maximum entropy model for
part-of-speech tagging. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language Pro-
cessing (EMNLP).
V. Vapnik. 1998. Statistical Learning Theory. Wiley,
Chichester, UK.
I. Schr¨oder. 2001. ICOPOST - Ingo’s Collection
Of POS Taggers. In http://nats-www.informatik.uni-
hamburg.de/ingo/icopost/.
T. Brants. 1998 Estimating HMM Topologies. In The
Tbilisi Symposium on Logic, Language and Computa-
tion: Selected Papers.
T. Brants. 2000 TnT - A Statistical Part-of-Speech Tag-
ger. In 6’th Applied Natural Language Processing.
H. Sch¨utze and Y. Singer. 1994. Part-of-speech tagging
using a variable memory Markov model. In Proceed-
ings ofthe Annual Meeting ofthe Associationfor Com-
putational Linguistics (ACL).
D. Ron, Y. Singer and N. Tishby. 1996 The Power of
Amnesia: Learning Probabilistic Automata with Vari-
able Memory Length. In Machine Learning, 25(2-
3):117–149.
J.-D. Kim, S.-Z. Lee and H.-C. Rim. 1999 HMM
Specialization with Selective Lexicalization. In
Proceedings of the Joint SIGDAT Conference on
Empirical Methods in NLP and Very Large Cor-
pora(EMNLP/VLC99).
F. Pla and A. Molina. 2001 Part-of-Speech Tagging
with Lexicalized HMM. In Proceedings of the Inter-
national Conference on Recent Advances in Natural
Language Processing(RANLP2001).
R. Quinlan. 1986 Induction of decision trees. In Ma-
chine Learning, 1(1):81–106.
R. L´opez de M´antaras. 1991. A Distance-Based At-
tribute Selection Measure for Decision Tree Induction.
In Machine Learning, 6(1):81–92.
R. L´opez de M´antaras, J. Cerquides and P. Garcia. 1998.
Comparing Information-theoretic Attribute Selection
Measures: A statistical approach. In Artificial Intel-
ligence Communications, 11(2):91–100.
F. Jelinek and R. Mercer. 1980. Interpolated estimation
of Markov source parameters from sparse data. In Pro-
ceedings of the Workshop on Pattern Recognition in
Practice.
W. Gale and G. Sampson. 1995. Good-Turing frequency
estimatin without tears. In Jounal of Quantitative Lin-
guistics, 2:217–237
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.218760">
<title confidence="0.9979935">Self-Organizing Markov Models and Their Application to Part-of-Speech Tagging</title>
<author confidence="0.998687">Jin-Dong Kim</author>
<affiliation confidence="0.999825">Dept. of Computer Science University of Tokyo</affiliation>
<author confidence="0.74835">Hae-Chang Rim</author>
<affiliation confidence="0.9998015">Dept. of Computer Science Korea University</affiliation>
<email confidence="0.802468">rim@nlp.korea.ac.krjdkim@is.s.u-tokyo.ac.jp</email>
<author confidence="0.780397">Jun’ich Tsujii</author>
<affiliation confidence="0.888916333333333">Dept. of Computer Science University of Tokyo, and CREST, JST</affiliation>
<email confidence="0.909699">tsujii@is.s.u-tokyo.ac.jp</email>
<abstract confidence="0.996481769230769">This paper presents a method to develop a class of variable memory Markov models that have higher memory capacity than traditional (uniform memory) Markov models. The structure of the variable memory models is induced from a manually annotated corpus through a decision tree learning algorithm. A series of comparative experiments show the resulting models outperform uniform memory Markov models in a part-of-speech tagging task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Rabiner</author>
</authors>
<title>A tutorial on Hidden Markov Models and selected applications in speech recognition.</title>
<date>1989</date>
<booktitle>in Proceedings of the IEEE,</booktitle>
<pages>77--2</pages>
<contexts>
<context position="1317" citStr="Rabiner, 1989" startWordPosition="194" endWordPosition="195">dels outperform uniform memory Markov models in a part-of-speech tagging task. 1 Introduction Many major NLP tasks can be regarded as problems of finding an optimal valuation for random processes. For example, for a given word sequence, part-of-speech (POS) tagging involves finding an optimal sequence of syntactic classes, and NP chunking involves finding IOB tag sequences (each of which represents the inside, outside and beginning of noun phrases respectively). Many machine learning techniques have been developed to tackle such random process tasks, which include Hidden Markov Models (HMMs) (Rabiner, 1989), Maximum Entropy Models (MEs) (Ratnaparkhi, 1996), Support Vector Machines (SVMs) (Vapnik, 1998), etc. Among them, SVMs have high memory capacity and show high performance, especially when the target classification requires the consideration of various features. On the other hand, HMMs have low memory capacity but they work very well, especially when the target task involves a series of classifications that are tightly related to each other and requires global optimization of them. As for POS tagging, recent comparisons (Brants, 2000; Schr¨oder, 2001) show that HMMs work better than other mod</context>
</contexts>
<marker>Rabiner, 1989</marker>
<rawString>L. Rabiner. 1989. A tutorial on Hidden Markov Models and selected applications in speech recognition. in Proceedings of the IEEE, 77(2):257–285</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ratnaparkhi</author>
</authors>
<title>A maximum entropy model for part-of-speech tagging.</title>
<date>1996</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</booktitle>
<contexts>
<context position="1367" citStr="Ratnaparkhi, 1996" startWordPosition="200" endWordPosition="202">n a part-of-speech tagging task. 1 Introduction Many major NLP tasks can be regarded as problems of finding an optimal valuation for random processes. For example, for a given word sequence, part-of-speech (POS) tagging involves finding an optimal sequence of syntactic classes, and NP chunking involves finding IOB tag sequences (each of which represents the inside, outside and beginning of noun phrases respectively). Many machine learning techniques have been developed to tackle such random process tasks, which include Hidden Markov Models (HMMs) (Rabiner, 1989), Maximum Entropy Models (MEs) (Ratnaparkhi, 1996), Support Vector Machines (SVMs) (Vapnik, 1998), etc. Among them, SVMs have high memory capacity and show high performance, especially when the target classification requires the consideration of various features. On the other hand, HMMs have low memory capacity but they work very well, especially when the target task involves a series of classifications that are tightly related to each other and requires global optimization of them. As for POS tagging, recent comparisons (Brants, 2000; Schr¨oder, 2001) show that HMMs work better than other models when they are combined with good smoothing tec</context>
</contexts>
<marker>Ratnaparkhi, 1996</marker>
<rawString>A. Ratnaparkhi. 1996. A maximum entropy model for part-of-speech tagging. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP).</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Vapnik</author>
</authors>
<title>Statistical Learning Theory.</title>
<date>1998</date>
<publisher>Wiley, Chichester, UK.</publisher>
<contexts>
<context position="1414" citStr="Vapnik, 1998" startWordPosition="207" endWordPosition="208"> major NLP tasks can be regarded as problems of finding an optimal valuation for random processes. For example, for a given word sequence, part-of-speech (POS) tagging involves finding an optimal sequence of syntactic classes, and NP chunking involves finding IOB tag sequences (each of which represents the inside, outside and beginning of noun phrases respectively). Many machine learning techniques have been developed to tackle such random process tasks, which include Hidden Markov Models (HMMs) (Rabiner, 1989), Maximum Entropy Models (MEs) (Ratnaparkhi, 1996), Support Vector Machines (SVMs) (Vapnik, 1998), etc. Among them, SVMs have high memory capacity and show high performance, especially when the target classification requires the consideration of various features. On the other hand, HMMs have low memory capacity but they work very well, especially when the target task involves a series of classifications that are tightly related to each other and requires global optimization of them. As for POS tagging, recent comparisons (Brants, 2000; Schr¨oder, 2001) show that HMMs work better than other models when they are combined with good smoothing techniques and with handling of unknown words. Whi</context>
</contexts>
<marker>Vapnik, 1998</marker>
<rawString>V. Vapnik. 1998. Statistical Learning Theory. Wiley, Chichester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Schr¨oder</author>
</authors>
<title>ICOPOST - Ingo’s Collection Of POS Taggers.</title>
<date>2001</date>
<note>In http://nats-www.informatik.unihamburg.de/ingo/icopost/.</note>
<marker>Schr¨oder, 2001</marker>
<rawString>I. Schr¨oder. 2001. ICOPOST - Ingo’s Collection Of POS Taggers. In http://nats-www.informatik.unihamburg.de/ingo/icopost/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>Estimating HMM Topologies.</title>
<date>1998</date>
<booktitle>In The Tbilisi Symposium on Logic, Language and Computation: Selected Papers.</booktitle>
<contexts>
<context position="7424" citStr="Brants, 1998" startWordPosition="1190" endWordPosition="1191">d order HMM, is an example of this class of models and is accepted as one of the best part-of-speech taggers used around. The uniform extension can be achieved (relatively) easily, but due to the exponential growth of the model size, it can only be performed in restrictive a way. Another way of context extension is the selective extension of context. In the case of context extension from lower context to higher like the examples in figure 1, the extension involves taking more information about the same type of contextual features. We call this kind of extension homogeneous context extension. (Brants, 1998) presents this type of context extension method through model merging and splitting, and also prediction suffix tree learning (Sch¨utze and Singer, 1994; D. Ron et. al, 1996) is another well-known method that can perform homogeneous context extension. On the other hand, figure 2 illustrates heterogeneous context extension, in other words, this type of extension involves taking more information about other types of contextual features. (Kim et. al, 1999) and (Pla and Molina, 2001) present this type of context extension method, so called selective lexicalization. The selective extension can be a</context>
</contexts>
<marker>Brants, 1998</marker>
<rawString>T. Brants. 1998 Estimating HMM Topologies. In The Tbilisi Symposium on Logic, Language and Computation: Selected Papers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
</authors>
<title>TnT - A Statistical Part-of-Speech Tagger.</title>
<date>2000</date>
<booktitle>In 6’th Applied Natural Language Processing.</booktitle>
<contexts>
<context position="1857" citStr="Brants, 2000" startWordPosition="276" endWordPosition="277">process tasks, which include Hidden Markov Models (HMMs) (Rabiner, 1989), Maximum Entropy Models (MEs) (Ratnaparkhi, 1996), Support Vector Machines (SVMs) (Vapnik, 1998), etc. Among them, SVMs have high memory capacity and show high performance, especially when the target classification requires the consideration of various features. On the other hand, HMMs have low memory capacity but they work very well, especially when the target task involves a series of classifications that are tightly related to each other and requires global optimization of them. As for POS tagging, recent comparisons (Brants, 2000; Schr¨oder, 2001) show that HMMs work better than other models when they are combined with good smoothing techniques and with handling of unknown words. While global optimization is the strong point of HMMs, developers often complain that it is difficult to make HMMs incorporate various features and to improve them beyond given performances. For example, we often find that in some cases a certain lexical context can improve the performance of an HMM-based POS tagger, but incorporating such additional features is not easy and it may even degrade the overall performance. Because Markov models h</context>
<context position="6794" citStr="Brants, 2000" startWordPosition="1079" endWordPosition="1080"> lexical information (the following three ones). We see that the distribution after the preposition, out is quite different from distribution after other prepositions. From the above observations, we can see that by applying Markov assumptions we may miss much useful contextual information, or by getting a better context classification we can build a better context model. 4 Related Works One of the straightforward ways of context extension is extending context uniformly. Tri-gram tagging models can be thought of as a result of the uniform extension of context from bi-gram tagging models. TnT (Brants, 2000) based on a second order HMM, is an example of this class of models and is accepted as one of the best part-of-speech taggers used around. The uniform extension can be achieved (relatively) easily, but due to the exponential growth of the model size, it can only be performed in restrictive a way. Another way of context extension is the selective extension of context. In the case of context extension from lower context to higher like the examples in figure 1, the extension involves taking more information about the same type of contextual features. We call this kind of extension homogeneous con</context>
<context position="15007" citStr="Brants, 2000" startWordPosition="2448" endWordPosition="2449">extual features to the target classification (line 2), we adopted Lopez distance (L´opez, 1991). While other measures including Information Gain or Gain Ratio (Quinlan, 1986) also can be used for this purpose, the Lopez distance has been reported to yield slightly better results (L´opez, 1998). The probabilistic distribution of the target feature estimated on a node making phase (line 4) is smoothed by using Jelinek and Mercer’s interpolation method (Jelinek and Mercer, 1980) along the ancestor nodes. The interpolation parameters are estimated by deleted interpolation algorithm introduced in (Brants, 2000). 6 Experiments We performed a series of experiments to compare the performance of self-organizing Markov models with traditional Markov models. Wall Street Journal as contained in Penn Treebank II is used as the reference material. As the experimental task is partof-speech tagging, all other annotations like syntactic bracketing have been removed from the corpus. Every figure (digit) in the corpus has been changed into a special symbol. From the whole corpus, every 10’th sentence from the first is selected into the test corpus, and the remaining ones constitute the training corpus. Table 6 sh</context>
</contexts>
<marker>Brants, 2000</marker>
<rawString>T. Brants. 2000 TnT - A Statistical Part-of-Speech Tagger. In 6’th Applied Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sch¨utze</author>
<author>Y Singer</author>
</authors>
<title>Part-of-speech tagging using a variable memory Markov model.</title>
<date>1994</date>
<booktitle>In Proceedings ofthe Annual Meeting ofthe Associationfor Computational Linguistics (ACL).</booktitle>
<marker>Sch¨utze, Singer, 1994</marker>
<rawString>H. Sch¨utze and Y. Singer. 1994. Part-of-speech tagging using a variable memory Markov model. In Proceedings ofthe Annual Meeting ofthe Associationfor Computational Linguistics (ACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ron</author>
<author>Y Singer</author>
<author>N Tishby</author>
</authors>
<title>The Power of Amnesia: Learning Probabilistic Automata with Variable Memory Length.</title>
<date>1996</date>
<booktitle>In Machine Learning,</booktitle>
<pages>25--2</pages>
<marker>Ron, Singer, Tishby, 1996</marker>
<rawString>D. Ron, Y. Singer and N. Tishby. 1996 The Power of Amnesia: Learning Probabilistic Automata with Variable Memory Length. In Machine Learning, 25(2-3):117–149.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J-D Kim</author>
<author>S-Z Lee</author>
<author>H-C Rim</author>
</authors>
<title>HMM Specialization with Selective Lexicalization.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in NLP and Very Large Corpora(EMNLP/VLC99).</booktitle>
<marker>Kim, Lee, Rim, 1999</marker>
<rawString>J.-D. Kim, S.-Z. Lee and H.-C. Rim. 1999 HMM Specialization with Selective Lexicalization. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in NLP and Very Large Corpora(EMNLP/VLC99).</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pla</author>
<author>A Molina</author>
</authors>
<title>Part-of-Speech Tagging with Lexicalized HMM.</title>
<date>2001</date>
<booktitle>In Proceedings of the International Conference on Recent Advances in Natural Language Processing(RANLP2001).</booktitle>
<contexts>
<context position="7908" citStr="Pla and Molina, 2001" startWordPosition="1264" endWordPosition="1267">more information about the same type of contextual features. We call this kind of extension homogeneous context extension. (Brants, 1998) presents this type of context extension method through model merging and splitting, and also prediction suffix tree learning (Sch¨utze and Singer, 1994; D. Ron et. al, 1996) is another well-known method that can perform homogeneous context extension. On the other hand, figure 2 illustrates heterogeneous context extension, in other words, this type of extension involves taking more information about other types of contextual features. (Kim et. al, 1999) and (Pla and Molina, 2001) present this type of context extension method, so called selective lexicalization. The selective extension can be a good alternative to the uniform extension, because the growth rate of the model size is much smaller, and thus various contextual features can be exploited. In the followFigure 3: a Markov model and its equivalent decision tree ing sections, we describe a novel method of selective extension of context which performs both homogeneous and heterogeneous extension simultaneously. 5 Self-Organizing Markov Models Our approach to the selective context extension is making use of the sta</context>
</contexts>
<marker>Pla, Molina, 2001</marker>
<rawString>F. Pla and A. Molina. 2001 Part-of-Speech Tagging with Lexicalized HMM. In Proceedings of the International Conference on Recent Advances in Natural Language Processing(RANLP2001).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Quinlan</author>
</authors>
<title>Induction of decision trees.</title>
<date>1986</date>
<booktitle>In Machine Learning,</booktitle>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="12882" citStr="Quinlan, 1986" startWordPosition="2079" endWordPosition="2080"> able to classify contextual patterns, all the context features must be visible, and implicitly states that homogeneous context features that appear later than the current target feature cannot be contextual features. Due to the second restriction, the Viterbi algorithm can be used with the self-organizing Markov models to find an optimal sequence of tags for a given word sequence. 5.2 Learning Self-Organizing Markov Models Self-organizing Markov models can be induced from manually annotated corpora through the SDTL algorithm (algorithm 1) we have designed. It is a variation of ID3 algorithm (Quinlan, 1986). SDTL is a greedy algorithm where at each time of the node making phase the most informative feature is selected (line 2), and it is a recursive algorithm in the sense that the algorithm is called recursively to make child nodes (line 3), Though theoretically any statistical decision tree growing algorithms can be used to train selforganizing Markov models, there are practical problems we face when we try to apply the algorithms to language learning problems. One of the main obstacles is the fact that features used for language learning often have huge sets of values, which cause intensive fr</context>
<context position="14568" citStr="Quinlan, 1986" startWordPosition="2379" endWordPosition="2380">ed as follows: if the distribution of the target feature varies significantly by referring to the value v, v is accepted as a meaningful value. We adopted the x2-test to determine the difference between the distributions of the target feature before and after referring to the value v. The use of x2-test enables us to make a principled decision about the threshold based on a certain confidence level3. To evaluate the contribution of contextual features to the target classification (line 2), we adopted Lopez distance (L´opez, 1991). While other measures including Information Gain or Gain Ratio (Quinlan, 1986) also can be used for this purpose, the Lopez distance has been reported to yield slightly better results (L´opez, 1998). The probabilistic distribution of the target feature estimated on a node making phase (line 4) is smoothed by using Jelinek and Mercer’s interpolation method (Jelinek and Mercer, 1980) along the ancestor nodes. The interpolation parameters are estimated by deleted interpolation algorithm introduced in (Brants, 2000). 6 Experiments We performed a series of experiments to compare the performance of self-organizing Markov models with traditional Markov models. Wall Street Jour</context>
</contexts>
<marker>Quinlan, 1986</marker>
<rawString>R. Quinlan. 1986 Induction of decision trees. In Machine Learning, 1(1):81–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L´opez de M´antaras</author>
</authors>
<title>A Distance-Based Attribute Selection Measure for Decision Tree Induction.</title>
<date>1991</date>
<booktitle>In Machine Learning,</booktitle>
<pages>6--1</pages>
<marker>de M´antaras, 1991</marker>
<rawString>R. L´opez de M´antaras. 1991. A Distance-Based Attribute Selection Measure for Decision Tree Induction. In Machine Learning, 6(1):81–92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L´opez de M´antaras</author>
<author>J Cerquides</author>
<author>P Garcia</author>
</authors>
<title>Comparing Information-theoretic Attribute Selection Measures: A statistical approach.</title>
<date>1998</date>
<journal>In Artificial Intelligence Communications,</journal>
<volume>11</volume>
<issue>2</issue>
<marker>de M´antaras, Cerquides, Garcia, 1998</marker>
<rawString>R. L´opez de M´antaras, J. Cerquides and P. Garcia. 1998. Comparing Information-theoretic Attribute Selection Measures: A statistical approach. In Artificial Intelligence Communications, 11(2):91–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
<author>R Mercer</author>
</authors>
<title>Interpolated estimation of Markov source parameters from sparse data.</title>
<date>1980</date>
<booktitle>In Proceedings of the Workshop on Pattern Recognition in Practice.</booktitle>
<contexts>
<context position="14874" citStr="Jelinek and Mercer, 1980" startWordPosition="2428" endWordPosition="2431">f x2-test enables us to make a principled decision about the threshold based on a certain confidence level3. To evaluate the contribution of contextual features to the target classification (line 2), we adopted Lopez distance (L´opez, 1991). While other measures including Information Gain or Gain Ratio (Quinlan, 1986) also can be used for this purpose, the Lopez distance has been reported to yield slightly better results (L´opez, 1998). The probabilistic distribution of the target feature estimated on a node making phase (line 4) is smoothed by using Jelinek and Mercer’s interpolation method (Jelinek and Mercer, 1980) along the ancestor nodes. The interpolation parameters are estimated by deleted interpolation algorithm introduced in (Brants, 2000). 6 Experiments We performed a series of experiments to compare the performance of self-organizing Markov models with traditional Markov models. Wall Street Journal as contained in Penn Treebank II is used as the reference material. As the experimental task is partof-speech tagging, all other annotations like syntactic bracketing have been removed from the corpus. Every figure (digit) in the corpus has been changed into a special symbol. From the whole corpus, ev</context>
</contexts>
<marker>Jelinek, Mercer, 1980</marker>
<rawString>F. Jelinek and R. Mercer. 1980. Interpolated estimation of Markov source parameters from sparse data. In Proceedings of the Workshop on Pattern Recognition in Practice.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>G Sampson</author>
</authors>
<title>Good-Turing frequency estimatin without tears.</title>
<date>1995</date>
<booktitle>In Jounal of Quantitative Linguistics,</booktitle>
<pages>2--217</pages>
<marker>Gale, Sampson, 1995</marker>
<rawString>W. Gale and G. Sampson. 1995. Good-Turing frequency estimatin without tears. In Jounal of Quantitative Linguistics, 2:217–237</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>