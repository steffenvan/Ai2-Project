<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000836">
<title confidence="0.967693">
Learning Syntactic Verb Frames Using Graphical Models
</title>
<author confidence="0.998591">
Thomas Lippincott
</author>
<affiliation confidence="0.975933">
University of Cambridge
Computer Laboratory
</affiliation>
<address confidence="0.795157">
United Kingdom
</address>
<email confidence="0.994386">
tl318@cam.ac.uk
</email>
<author confidence="0.949334">
Diarmuid O´ S´eaghdha
</author>
<affiliation confidence="0.9666255">
University of Cambridge
Computer Laboratory
</affiliation>
<address confidence="0.790857">
United Kingdom
</address>
<email confidence="0.993988">
do242@cam.ac.uk
</email>
<author confidence="0.995818">
Anna Korhonen
</author>
<affiliation confidence="0.9758055">
University of Cambridge
Computer Laboratory
</affiliation>
<address confidence="0.796779">
United Kingdom
</address>
<email confidence="0.997203">
alk23@cam.ac.uk
</email>
<sectionHeader confidence="0.995616" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9994405625">
We present a novel approach for building
verb subcategorization lexicons using a simple
graphical model. In contrast to previous meth-
ods, we show how the model can be trained
without parsed input or a predefined subcate-
gorization frame inventory. Our method out-
performs the state-of-the-art on a verb clus-
tering task, and is easily trained on arbitrary
domains. This quantitative evaluation is com-
plemented by a qualitative discussion of verbs
and their frames. We discuss the advantages of
graphical models for this task, in particular the
ease of integrating semantic information about
verbs and arguments in a principled fashion.
We conclude with future work to augment the
approach.
</bodyText>
<sectionHeader confidence="0.998996" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998955857142857">
Subcategorization frames (SCFs) give a compact de-
scription of a verb’s syntactic preferences. These
two sentences have the same sequence of lexical
syntactic categories (VP-NP-SCOMP), but the first
is a simple transitive (“X understood Y”), while the
second is a ditransitive with a sentential complement
(“X persuaded Y that Z”):
</bodyText>
<listItem confidence="0.9995585">
1. Kim (VP understood (NP the evidence
(SCOMP that Sandy was present)))
2. Kim (VP persuaded (NP the judge) (SCOMP
that Sandy was present))
</listItem>
<bodyText confidence="0.99985344117647">
An SCF lexicon would indicate that “persuade”
is likely to take a direct object and sentential com-
plement (NP-SCOMP), while “understand” is more
likely to take just a direct object (NP). A compre-
hensive lexicon would also include semantic infor-
mation about selectional preferences (or restrictions)
on argument heads of verbs, diathesis alternations
(i.e. semantically-motivated alternations between
pairs of SCFs) and a mapping from surface frames
to the underlying predicate-argument structure. In-
formation about verb subcategorization is useful for
tasks like information extraction (Cohen and Hunter,
2006; Rupp et al., 2010), verb clustering (Korho-
nen et al., 2006b; Merlo and Stevenson, 2001) and
parsing (Carroll et al., 1998). In general, tasks that
depend on predicate-argument structure can benefit
from a high-quality SCF lexicon (Surdeanu et al.,
2003).
Large, manually-constructed SCF lexicons
mostly target general language (Boguraev and
Briscoe, 1987; Grishman et al., 1994). However,
in many domains verbs exhibit different syntactic
behavior (Roland and Jurafsky, 1998; Lippincott
et al., 2010). For example, the verb “develop”
has specific usages in newswire, biomedicine and
engineering that dramatically change its probability
distribution over SCFs. In a few domains like
biomedicine, the need for focused SCF lexicons
has led to manually-built resources (Bodenreider,
2004). Such resources, however, are costly, prone to
human error, and in domains where new lexical and
syntactic constructs are frequently coined, quickly
become obsolete (Cohen and Hunter, 2006). Data-
driven methods for SCF acquisition can alleviate
</bodyText>
<page confidence="0.973173">
420
</page>
<note confidence="0.9857265">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 420–429,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.999966645833333">
these problems by building lexicons tailored to
new domains with less manual effort, and higher
coverage and scalability.
Unfortunately, high quality SCF lexicons are dif-
ficult to build automatically. The argument-adjunct
distinction is challenging even for humans, many
SCFs have no reliable cues in data, and some SCFs
(e.g. those involving control such as type raising)
rely on semantic distinctions. As SCFs follow a Zip-
fian distribution (Korhonen et al., 2000), many gen-
uine frames are also low in frequency. State-of-the-
art methods for building data-driven SCF lexicons
typically rely on parsed input (see section 2). How-
ever, the treebanks necessary for training a high-
accuracy parsing model are expensive to build for
new domains. Moreover, while parsing may aid the
detection of some frames, many experiments have
also reported SCF errors due to noise from parsing
(Korhonen et al., 2006a; Preiss et al., 2007).
Finally, many SCF acquisition methods operate
with predefined SCF inventories. This subscribes to
a single (often language or domain-specific) inter-
pretation of subcategorization a priori, and ignores
the ongoing debate on how this interpretation should
be tailored to new domains and applications, such as
the more prominent role of adjuncts in information
extraction (Cohen and Hunter, 2006).
In this paper, we describe and evaluate a novel
probabilistic data-driven method for SCF acquisi-
tion aimed at addressing some of the problems with
current approaches. In our model, a Bayesian net-
work describes how verbs choose their arguments
in terms of a small number of frames, which are
represented as distributions over syntactic relation-
ships. First, we show that by allowing the infer-
ence process to automatically define a probabilistic
SCF inventory, we outperform systems with hand-
crafted rules and inventories, using identical syntac-
tic features. Second, by replacing the syntactic fea-
tures with an approximation based on POS tags, we
achieve state-of-the-art performance without relying
on error-prone unlexicalized or domain-specific lex-
icalized parsers. Third, we highlight a key advantage
of our method compared to previous approaches: the
ease of integrating and performing joint inference of
additional syntactic and semantic information. We
describe how we plan to exploit this in our future
research.
</bodyText>
<sectionHeader confidence="0.983092" genericHeader="method">
2 Previous work
</sectionHeader>
<bodyText confidence="0.999402652173913">
Many state-of-the-art SCF acquisition systems take
grammatical relations (GRs) as input. GRs ex-
press binary dependencies between lexical items,
and many parsers produce them as output, with
some variation in inventory (Briscoe et al., 2006;
De Marneffe et al., 2006). For example, a subject-
relation like “ncsubj(HEAD, DEPENDENT)” ex-
presses the fact that the lexical item referred to by
HEAD (such as a present-tense verb) has the lexi-
cal item referred to by DEPENDENT as its subject
(such as a singular noun). GR inventories include
direct and indirect objects, complements, conjunc-
tions, among other relations. The dependency rela-
tionships included in GRs correspond closely to the
head-complement structure of SCFs, which is why
they are the natural choice for SCF acquisition.
There are several SCF lexicons for general lan-
guage, such as ANLT (Boguraev and Briscoe, 1987)
and COMLEX (Grishman et al., 1994), that depend
on manual work. VALEX (Preiss et al., 2007) pro-
vides SCF distributions for 6,397 verbs acquired
from a parsed general language corpus via a system
that relies on hand-crafted rules. There are also re-
sources which provide information about both syn-
tactic and semantic properties of verbs: VerbNet
(Kipper et al., 2008) draws on several hand-built
and semi-automatic sources to link the syntax and
semantics of 5,726 verbs. FrameNet (Baker et al.,
1998) provides semantic frames and annotated ex-
ample sentences for 4,186 verbs. PropBank (Palmer
et al., 2005) is a corpus where each verb is annotated
for its arguments and their semantic roles, covering
a total of 4,592 verbs.
There are many language-specific SCF acquisi-
tion systems, e.g. for French (Messiant, 2008),
Italian (Lenci et al., 2008), Turkish (Han et al.,
2008) and Chinese (Han et al., 2008). These typ-
ically rely on language-specific knowledge, either
directly through heuristics, or indirectly through
parsing models trained on treebanks. Furthermore,
some require labeled training instances for super-
vised (Uzun et al., 2008) or semi-supervised (Han
et al., 2008) learning algorithms.
Two state-of-the-art data-driven systems for En-
glish verbs are those that produced VALEX, Preiss et
al. (2007), and the BioLexicon (Venturi et al., 2009).
</bodyText>
<page confidence="0.998022">
421
</page>
<bodyText confidence="0.999985301886793">
The Preiss system extracts a verb instance’s GRs us-
ing the Rasp general-language unlexicalized parser
(Briscoe et al., 2006) as input, and based on hand-
crafted rules, maps verb instances to a predefined
inventory of 168 SCFs. Filtering is then performed
to remove noisy frames, with methods ranging from
a simple single threshold to SCF-specific hypothesis
tests based on external verb classes and SCF inven-
tories. The BioLexicon system extracts each verb in-
stance’s GRs using the lexicalized Enju parser tuned
to the biomedical domain (Miyao, 2005). Each
unique GR-set considered a potential SCF, and an
experimentally-determined threshold is used to fil-
ter low-frequency SCFs.
Note that both methods require extensive man-
ual work: the Preiss system involves the a priori
definition of the SCF inventory, careful construc-
tion of matching rules, and an unlexicalized pars-
ing model. The BioLexicon system induces its SCF
inventory automatically, but requires a lexicalized
parsing model, rendering it more sensitive to domain
variation. Both rely on a filtering stage that depends
on external resources and/or gold standards to select
top-performing thresholds. Our method, by contrast,
does not use a predefined SCF inventory, and can
perform well without parsed input.
Graphical models have been increasingly popu-
lar for a variety of tasks such as distributional se-
mantics (Blei et al., 2003) and unsupervised POS
tagging (Finkel et al., 2007), and sampling methods
allow efficient estimation of full joint distributions
(Neal, 1993). The potential for joint inference of
complementary information, such as syntactic verb
and semantic argument classes, has a clear and in-
terpretable way forward, in contrast to the pipelined
methods described above. This was demonstrated in
Andrew et al. (2004), where a Bayesian model was
used to jointly induce syntactic and semantic classes
for verbs, although that study relied on manually
annotated data and a predefined SCF inventory and
MLE. More recently, Abend and Rappoport (2010)
trained ensemble classifiers to perform argument-
adjunct disambiguation of PP complements, a task
closely related to SCF acquisition. Their study em-
ployed unsupervised POS tagging and parsing, and
measures of selectional preference and argument
structure as complementary features for the classi-
fier.
Finally, our task-based evaluation, verb clustering
with Levin (1993)’s alternation classes as the gold
standard, was previously conducted by Joanis and
Stevenson (2003), Korhonen et al. (2008) and Sun
and Korhonen (2009).
</bodyText>
<sectionHeader confidence="0.997101" genericHeader="method">
3 Methodology
</sectionHeader>
<bodyText confidence="0.998989666666667">
In this section we describe the basic components of
our study: feature sets, graphical model, inference,
and evaluation.
</bodyText>
<subsectionHeader confidence="0.993845">
3.1 Input and feature sets
</subsectionHeader>
<bodyText confidence="0.999678057142857">
We tested several feature sets either based on, or
approximating, the concept of grammatical relation
described in section 2. Our method is agnostic re-
garding the exact definition of GR, and for example
could use the Stanford inventory (De Marneffe et al.,
2006) or even an entirely different lexico-syntactic
formalism like CCG supertags (Curran et al., 2007).
In this paper, we distinguish “true GRs” (tGRs), pro-
duced by a parser, and “pseudo GRs” (pGRs), a
POS-based approximation, and employ subscripts to
further specify the variations described below. Our
input has been parsed into Rasp-style tGRs (Briscoe
et al., 2006), which facilitates comparison with pre-
vious work based on the same data set.
We’ll use a simple example sentence to illustrate
how our feature sets are extracted from CONLL-
formatted data (Nivre et al., 2007). The CONLL
format is a common language for comparing output
from dependency parsers: each lexical item has an
index, lemma, POS tag, tGR in which it is the de-
pendent, and index to the corresponding head. Table
1 shows the relevant fields for the sentence “We run
training programmes in Romania and other coun-
tries”.
We define the feature set for a verb occurrence as
the counts of each GR the verb participates in. Table
2 shows the three variations we tested: the simple
tGR type, with parameterization for the POS tags
of head and dependent, and with closed-class POS
tags (determiners, pronouns and prepositions) lexi-
calized. In addition, we tested the effect of limiting
the features to subject, object and complement tGRs,
indicated by adding the subscript “lim”, for a total of
six tGR-based feature sets.
While ideally tGRs would give full informa-
</bodyText>
<page confidence="0.988532">
422
</page>
<figure confidence="0.984562">
Index Lemma POS Head tGR
1 we PPIS2 2 ncsubj
2 run VV0 0
3 training NN1 4 ncmod
4 programme NN2 2 dobj
5 in II 4 ncmod
6 romania NP1 7 conj
7 and CC 5 dobj
8 other JB 9 ncmod
9 country NN2 7 conj
</figure>
<tableCaption confidence="0.90164775">
Table 1: Simplified CONLL format for example sen-
tence “We run training programmes in Romania and
other countries”. Head=0 indicates the token is the
root.
</tableCaption>
<table confidence="0.96148725">
Name Features
tGR ncsubj dobj
tGRparam ncsubj(VV0,PPIS2) dobj(VV0,NN2)
tGRparam,lex ncsubj(VV0,PPIS2-we) dobj(VV0,NN2)
</table>
<tableCaption confidence="0.859733">
Table 2: True-GR features for example sentence:
</tableCaption>
<bodyText confidence="0.999626666666667">
note there are also WR*,lim versions of each that
only consider subjects, objects and complements
and are not shown.
tion about the verb’s syntactic relationship to other
words, in practice parsers make (possibly prema-
ture) decisions, such as deciding that “in” modifies
“programme”, and not “run” in our example sen-
tence. An unlexicalized parser cannot distinguish
these based just on POS tags, while a lexicalized
parser requires a large treebank. We therefore define
pseudo-GRs (pGRs), which consider each (distance,
POS) pair within a given window of the verb to be
a potential tGR. Table 3 shows the pGR features for
the test sentence using a window of three. As with
tGRs, the closed-class tags can be lexicalized, but
there are no corresponding feature sets for param
(since they are already built from POS tags) or lim
(since there is no similar rule-based approach).
</bodyText>
<table confidence="0.919699333333333">
Name Features
pGR -1(PPIS2) 1(NN1) 2(NN2) 3(II)
pGRlex -1(PPIS2-we) 1(NN1) 2(NN2) 3(II-in)
</table>
<tableCaption confidence="0.9219645">
Table 3: Pseudo-GR features for example sentence
with window=3
</tableCaption>
<bodyText confidence="0.995636888888889">
Whichever feature set is used, an instance is sim-
ply the count of each GR’s occurrences. We extract
instances for the 385 verbs in the union of our two
gold standards from the VALEX lexicon’s data set,
which was used in previous studies (Sun and Korho-
nen, 2009; Preiss et al., 2007) and facilitates com-
parison with that resource. This data set is drawn
from five general-language corpora parsed by Rasp,
and provides, on average, 7,000 instances per verb.
</bodyText>
<subsectionHeader confidence="0.99731">
3.2 SCF extraction
</subsectionHeader>
<bodyText confidence="0.99945975">
Our graphical modeling approach uses the Bayesian
network shown in Figure 1. Its generative story
is as follows: when a verb is instantiated, an SCF
is chosen according to a verb-specific multinomial.
Then, the number and type of syntactic arguments
(GRs) are chosen from two SCF-specific multino-
mials. These three multinomials are modeled with
uniform Dirichlet priors and corresponding hyper-
parameters α, Q and -y. The model is trained via
collapsed Gibbs sampling, where the probability of
assigning a particular SCF s to an instance of verb v
with GRs (gr1 ... grn) is the product
</bodyText>
<equation confidence="0.9947006">
P(s|V erb = v, GRs = gr1 ... grn) =
P(SCF = s|V erb = v)×
P(N = n|SCF = s)×
H P(GR = gri|SCF = s)
i=1:n
</equation>
<bodyText confidence="0.99871825">
The three terms, given the hyper-parameters and
conjugate-prior relationship between Dirichlet and
Multinomial distributions, can be expressed in terms
of current assignments of s to verb v ( csv ), s to
GR-count n ( csn ) and s to GR ( csg ), the corre-
sponding totals ( cv, cs ), the dimensionality of the
distributions ( |SCF |, |N |and |G |) and the hyper-
parameters α, Q and -y:
</bodyText>
<equation confidence="0.999545">
P(SCF = s|V erb = v) = (csv+α)/(cv+|SCF|α)
P(N = n|SCF = s) = (csn + Q)/(cs + |N|Q)
P(GR = gri|SCF = s) = (csgrz +-y)/(cs + |G|-y)
</equation>
<bodyText confidence="0.9997005">
Note that N, the possible GR-count for an in-
stance, is usually constant for pGRs ( 2 × window
), unless the verb is close to the start or end of the
sentence.
</bodyText>
<page confidence="0.995266">
423
</page>
<figure confidence="0.990338733333333">
α = VerbxSCF
��
Verbi
SCFi ��
GRi
V
V
��
��
i E I
Ni
�� SCFxN = Q
SCFxGR
��
7
</figure>
<figureCaption confidence="0.977646">
Figure 1: Our simple graphical model reflecting subcategorization. Double-circles indicate an observed
value, arrows indicate conditional dependency. What constitutes a “GR” depends on the feature set being
used.
</figureCaption>
<bodyText confidence="0.999971454545455">
We chose our hyper-parameters α = Q = ry = .02
to reflect the characteristic sparseness of the phe-
nomena (i.e. verbs tend to take a small number of
SCFs, which in turn are limited to a small number
of realizations). For the pGRs we used a window
of 5 tokens: a verb’s arguments will fall within a
small window in the majority of cases, so there is
diminished return in expanding the window at the
cost of increased noise. Finally, we set our SCF
count to 40, about twice the size of the strictly syn-
tactic general-language gold standard we describe in
section 3.3. This overestimation allows some flex-
ibility for the model to define its inventory based
on the data; any supernumerary frames will act as
“junk frames” that are rarely assigned and hence
will have little influence. We run Gibbs sampling
for 1000 iterations, and average the final 100 sam-
ples to estimate the posteriors P(SCF|V erb) and
P(GR|SCF). Variance between adjacent states’
estimates of P(SCF|V erb) indicates that the sam-
pling typically converges after about 100-200 itera-
tions.1
</bodyText>
<subsectionHeader confidence="0.6463055">
3.3 Evaluation
Quantitative: cluster gold standard
</subsectionHeader>
<bodyText confidence="0.9998265">
Evaluating the output of unsupervised methods is
not straightforward: discrete, expert-defined cate-
gories (like many SCF inventories) are unlikely to
line up perfectly with data-driven, probabilistic out-
put. Even if they do, finding a mapping between
them is a problem of its own (Meila, 2003).
</bodyText>
<footnote confidence="0.9949135">
1Full source code for this work is available at http://cl.
cam.ac.uk/˜tl318/files/subcat.tgz
</footnote>
<bodyText confidence="0.999848535714286">
Our goal is to define a fair quantitative compari-
son between arbitrary SCF lexicons. An SCF lexi-
con makes two claims: first, that it defines a reason-
able SCF inventory. Second, that for each verb, it
has an accurate distribution over that inventory. We
therefore compare the lexicons based on their per-
formance on a task that a good SCF lexicon should
be useful for: clustering verbs into lexical-semantic
classes. Our gold standard is from (Sun and Korho-
nen, 2009), where 200 verbs were assigned to 17
classes based on their alternation patterns (Levin,
1993). Previous work (Schulte im Walde, 2009;
Sun and Korhonen, 2009) has demonstrated that the
quality of an SCF lexicon’s inventory and probabil-
ity estimates corresponds to its predictive power for
membership in such alternation classes.
To compare the performance of our feature sets,
we chose the simple and familiar K-Means cluster-
ing algorithm (Hartigan and Wong, 1979). The in-
stances are the verbs’ SCF distributions, and we se-
lect the number of clusters by the Silhouette vali-
dation technique (Rousseeuw, 1987). The clusters
are then compared to the gold standard clusters with
the purity-based F-Score from Sun and Korhonen
(2009) and the more familiar Adjusted Rand Index
(Hubert and Arabie, 1985). Our main point of com-
parison is the VALEX lexicon of SCF distributions,
whose scores we report alongside ours.
</bodyText>
<sectionHeader confidence="0.384872" genericHeader="method">
Qualitative: manual gold standard
</sectionHeader>
<bodyText confidence="0.997959333333333">
We also want to see how our results line up with
a traditional linguistic view of subcategorization,
but this requires digging into the unsupervised out-
</bodyText>
<page confidence="0.998069">
424
</page>
<bodyText confidence="0.9999330625">
put and associating anonymous probabilistic objects
with established categories. We therefore present
sample output in three ways: first, we show the
clustering output from our top-performing method.
Second, we plot the probability mass over GRs for
two anonymous SCFs that correspond to recogniz-
able traditional SCFs, and one that demonstrates un-
expected behavior. Third, we compared the out-
put for several verbs to a coarsened version of the
manually-annotated gold standard used to evaluate
VALEX (Preiss et al., 2007). We collapsed the orig-
inal inventory of 168 SCFs to 18 purely syntactic
SCFs based on their characteristic GRs and removed
frames that depend on semantic distinctions, leav-
ing the detection of finer-grained and semantically-
based frames for future work.
</bodyText>
<sectionHeader confidence="0.999987" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.998678">
4.1 Verb clustering
</subsectionHeader>
<bodyText confidence="0.9991862">
We evaluated SCF lexicons based on the eight fea-
ture sets described in section 3.1, as well as the
VALEX SCF lexicon described in section 2. Table 4
shows the performance of the lexicons in ascending
order.
</bodyText>
<table confidence="0.9993461">
Method Pur. F-score Adj. Rand
tGR .24 .02
tGRlim .27 .02
pGRlex .32 .09
tGRlim,param .35 .08
pGR .35 .10
VALEX .36 .10
tGRparam,lex .37 .10
tGRparam .39 .12
tGRlim,param,lex .44 .12
</table>
<tableCaption confidence="0.992345">
Table 4: Task-based evaluation of lexicons acquired
</tableCaption>
<bodyText confidence="0.970772733333333">
with each of the eight feature types, and the state-of-
the-art rule-based VALEX lexicon.
These results lead to several conclusions: first,
training our model on tGRs outperforms pGRs and
VALEX. Since the parser that produced them is
known to perform well on general language (Briscoe
et al., 2006), the tGRs are of high quality: it makes
sense that reverting to the pGRs is unnecessary in
this case. The interesting point is the major perfor-
mance gain over VALEX, which uses the same tGR
features along with expert-developed rules and in-
ventory.
Second, we achieve performance comparable to
VALEX using pGRs with a narrow window width.
Since POS tagging is more reliable and robust across
domains than parsing, retraining on new domains
will not suffer the effects of a mismatched parsing
model (Lippincott et al., 2010). It is therefore pos-
sible to use this method to build large-scale lexicons
for any new domain with sufficient data.
Third, lexicalizing the closed-class POS tags in-
troduces semantic information outside the scope
of the alternation-based definition of subcatego-
rization. For example, subdividing the indefinite
pronoun tag “PN1” into “PN1-anyone” and “PN1-
anything” gives information about the animacy of
the verb’s arguments. Our results show this degrades
performance for both pGR and tGR features, unless
the latter are limited to tGRs traditionally thought to
be relevant for the task.
</bodyText>
<subsectionHeader confidence="0.999336">
4.2 Qualitative analysis
</subsectionHeader>
<bodyText confidence="0.999992307692308">
Table 5 shows clusters produced by our top-scoring
method, GRparam,lex,lim. Some clusters are imme-
diately intelligible at the semantic level and corre-
spond closely to the lexical-semantic classes found
in Levin (1993). For example, clusters 1, 6, and 14
include member verbs of Levin’s SAY, PEER and
AMUSE classes, respectively. Some clusters are
based on broader semantic distinctions (e.g. cluster
2 which groups together verbs related to locations)
while others relate semantic classes purely based
on their syntactic similarity (e.g. the verbs in clus-
ter 17 share strong preference for ’to’ preposition).
The syntactic-semantic nature of the clusters reflects
the multimodal nature of verbs and illustrates why a
comprehensive subcategorization lexicon should not
be limited to syntactic frames. This phenomenon is
also encouraging for future work to tease apart and
simultaneously exploit several verbal aspects via ad-
ditional latent structure in the model.
An SCF’s distribution over features can reveal its
place in the traditional definition of subcategoriza-
tion. Figure 2 shows the high-probability (&gt;.02)
tGRs for one SCF: the large mass centered on di-
rect object tGRs indicates this approximates the no-
tion of “transitive”. Looking at the verbs most likely
to take this SCF (“stimulate”, “conserve”) confirms
</bodyText>
<page confidence="0.999423">
425
</page>
<tableCaption confidence="0.5002085">
Table 5: Clusters (of size &gt;2 and &lt;20) produced
using tGRparam,lex,lim
</tableCaption>
<figureCaption confidence="0.996007">
Figure 2: The SCF corresponding to transitive has
most probability centered on dobj (e.g. stimulate,
conserve, deepen, eradicate, broaden)
</figureCaption>
<figure confidence="0.967285">
1
2
3
4
5
6
7
8
9
10
11
12
13
14
15
16
17
</figure>
<bodyText confidence="0.977727983870968">
exclaim, murmur, mutter, reply, retort, say,
sigh, whisper
bang, knock, snoop, swim, teeter
flicker, multiply, overlap, shine
batter, charter, compromise, overwhelm,
regard, sway, treat
abolish, broaden, conserve, deepen, eradi-
cate, remove, sharpen, shorten, stimulate,
strengthen, unify
gaze, glance, look, peer, sneer, squint, stare
coincide, commiserate, concur, flirt, inter-
act
grin, smile, wiggle
confuse, diagnose, march
mate, melt, swirl
frown, jog, stutter
chuckle, mumble, shout
announce, envisage, mention, report, state
frighten, intimidate, scare, shock, upset
bash, falter, snarl, wail, weaken
cooperate, eject, respond, transmit
affiliate, compare, contrast, correlate, for-
ward, mail, ship
this. Figure 3 shows a complement-taking SCF,
which is far rarer than simple transitive but also
clearly induced by our model.
The induced SCF inventory also has some redun-
dancy, such as additional transitive frames beside
figure 2, and frames with poor probability estimates.
Most of these issues can be traced to our simplifying
assumption that each tGR is drawn independently
w.r.t. an instance’s other tGRs. For example, if an
SCF gives any weight to indirect objects, it gives
non-zero probability to an instance with only indi-
rect objects, an impossible case. This can lead to
skewed probability estimates: since some tGRs can
occur multiple times in a given instance (e.g. in-
direct objects and prepositional phrases) the model
may find it reasonable to create an SCF with all
probability focused on that tGR, ignoring all oth-
ers, such as in figure 4. We conclude that our inde-
pendence assumption was too strong, and the model
would benefit from defining more structure within
Figure 3: The SCF corresponding to verbs taking
complements has more probability on xcomp and
ccomp (e.g. believe, state, agree, understand, men-
tion)
instances.
The full tables necessary to compare verb SCF
distributions from our output with the manual gold
standard are prohibited by space, but a few exam-
ples reinforce the analysis above. The verbs “load”
and “fill” show particularly high usage of ditransi-
tive SCFs in the gold standard. In our inventory, this
is reflected in high usage of an SCF with probabil-
ity centered on indirect objects, but due to the inde-
pendence assumptions the frame has a correspond-
ing low probability on subjects and direct objects,
despite the fact that these necessarily occur along
with any indirect object. The verbs “acquire” and
“buy” demonstrate both a strength of our approach
and a weakness of using parsed input: both verbs
</bodyText>
<page confidence="0.99864">
426
</page>
<figureCaption confidence="0.823540333333333">
Figure 4: This SCF is dominated by indirect objects
and complements, catering to verbs that may take
several such tGRs, at the expense of subjects
</figureCaption>
<bodyText confidence="0.999890090909091">
show high probability of simple transitive in our
output and the gold standard. However, the Rasp
parser often conflates indirect objects and preposi-
tional phrases due to its unlexicalized model. While
our system correctly gives high probability to ditran-
sitive for both verbs, it inherits this confusion and
over-estimates “acquire”’s probability mass for the
frame. This is an example of how bad decisions
made by the parser cannot be fixed by the graphi-
cal model, and an area where pGR features have an
advantage.
</bodyText>
<sectionHeader confidence="0.972448" genericHeader="conclusions">
5 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999962646153847">
Our study reached two important conclusions: first,
given the same data as input, an unsupervised prob-
abilistic model can outperform a hand-crafted rule-
based SCF extractor with a predefined inventory.
We achieve better results with far less effort than
previous approaches by allowing the data to gov-
ern the definition of frames while estimating the
verb-specific distributions in a fully Bayesian man-
ner. Second, simply treating POS tags within a
small window of the verb as pseudo-GRs produces
state-of-the-art results without the need for a pars-
ing model. This is particularly encouraging when
building resources for new domains, where com-
plex models fail to generalize. In fact, by integrat-
ing results from unsupervised POS tagging (Teichert
and Daum´e III, 2009) we could render this approach
fully domain- and language-independent.
We did not dwell on issues related to choosing
our hyper-parameters or latent class count. Both of
these can be accomplished with additional sampling
methods: hyper-parameters of Dirichlet priors can
be estimated via slice sampling (Heinrich, 2009),
and their dimensionality via Dirichlet Process priors
(Heinrich, 2011). This could help address the redun-
dancy we find in the induced SCF inventory, with the
potential SCFs growing to accommodate the data.
Our initial attempt at applying graphical models
to subcategorization also suggested several ways to
extend and improve the method. First, the indepen-
dence assumptions between GRs in a given instance
turned out to be too strong. To address this, we could
give instances internal structure to capture condi-
tional probability between generated GRs. Second,
our results showed the conflation of several verbal
aspects, most notably the syntactic and semantic.
In a sense this is encouraging, as it motivates our
most exciting future work: augmenting this simple
model to explicitly capture complementary infor-
mation such as distributional semantics (Blei et al.,
2003), diathesis alternations (McCarthy, 2000) and
selectional preferences ( O´ S´eaghdha, 2010). This
study targeted high-frequency verbs, but the use of
syntactic and semantic classes would also help with
data sparsity down the road. These extensions would
also call for a more comprehensive evaluation, aver-
aging over several tasks, such as clustering by se-
mantics, syntax, alternations and selectional prefer-
ences.
In concrete terms, we plan to introduce latent vari-
ables corresponding to syntactic, semantic and alter-
nation classes, that will determine a verb’s syntac-
tic arguments, their semantic realization (i.e. selec-
tional preferences), and possible predicate-argument
structures. By combining the syntactic classes with
unsupervised POS tagging (Teichert and Daum´e III,
2009) and the selectional preferences with distribu-
tional semantics ( O´ S´eaghdha, 2010), we hope to
produce more accurate results on these complemen-
tary tasks while avoiding the use of any supervised
learning. Finally, a fundamental advantage of a data-
driven, parse-free method is that it can be easily
trained for new domains. We next plan to test our
method on a new domain, such as biomedical text,
where verbs are known to take on distinct syntactic
behavior (Lippincott et al., 2010).
</bodyText>
<page confidence="0.997512">
427
</page>
<sectionHeader confidence="0.998678" genericHeader="acknowledgments">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999911285714286">
The work in this paper was funded by the Royal So-
ciety, (UK), EPSRC (UK) grant EP/G051070/1 and
EU grant 7FP-ITC-248064. We are grateful to Lin
Sun and Laura Rimell for the use of their cluster-
ing and subcategorization gold standards, and the
ACL reviewers for their helpful comments and sug-
gestions.
</bodyText>
<sectionHeader confidence="0.989392" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9994493">
Omri Abend and Ari Rappoport. 2010. Fully unsuper-
vised core-adjunct argument classification. In ACL
’10.
Galen Andrew, Trond Grenager, and Christopher Man-
ning. 2004. Verb sense and subcategorization: us-
ing joint inference to improve performance on com-
plementary tasks. EMNLP ’04.
Collin Baker, Charles Fillmore, and John Lowe. 1998.
The Berkeley FrameNet project. In COLINGACL ’98.
David Blei, Andrew Ng, Michael Jordan, and John Laf-
ferty. 2003. Latent dirichlet allocation. Journal of
Machine Learning Research.
Olivier Bodenreider. 2004. The Unified Medical Lan-
guage System (UMLS): integrating biomedical termi-
nology. Nucleic Acids Research, 32.
Bran Boguraev and Ted Briscoe. 1987. Large lexicons
for natural language processing. Computational Lin-
guistics, 13.
Ted Briscoe, John Carroll, and Rebecca Watson. 2006.
The second release of the RASP system. In Proceed-
ings of the COLING/ACL on Interactive presentation
sessions.
John Carroll, Guido Minnen, and Ted Briscoe. 1998.
Can subcategorisation probabilities help a statistical
parser? In The 6th ACL/SIGDAT Workshop on Very
Large Corpora.
K Bretonnel Cohen and Lawrence Hunter. 2006. A
critical review of PASBio’s argument structures for
biomedical verbs. BMC Bioinformatics, 7.
James Curran, Stephen Clark, and Johan Bos. 2007. Lin-
guistically motivated large-Scale NLP with C&amp;C and
Boxer. In ACL ’07.
Marie-Catherine De Marneffe, Bill Maccartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
LREC ’06.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2007. The infinite tree. In ACL ’07.
Ralph Grishman, Catherine Macleod, and Adam Meyers.
1994. Comlex syntax: building a computational lexi-
con. In COLING ’94.
Xiwu Han, Chengguo Lv, and Tiejun Zhao. 2008.
Weakly supervised SVM for Chinese-English cross-
lingual subcategorization lexicon acquisition. In The
11th Joint Conference on Information Science.
J.A. Hartigan and M.A. Wong. 1979. Algorithm AS 136:
A K-Means clustering algorithm. Journal of the Royal
Statistical Society. Series C (Applied Statistics).
Gregor Heinrich. 2009. Parameter estimation for text
analysis. Technical report, Fraunhofer IGD.
</reference>
<page confidence="0.984169">
428
</page>
<reference confidence="0.99990014">
Gregor Heinrich. 2011. Infinite LDA implementing the
HDP with minimum code complexity. Technical re-
port, arbylon.net.
Lawrence Hubert and Phipps Arabie. 1985. Comparing
partitions. Journal of Classi�cation, 2.
Eric Joanis and Suzanne Stevenson. 2003. A general fea-
ture space for automatic verb classification. In EACL
’03.
Karin Kipper, Anna Korhonen, Neville Ryant, and
Martha Palmer. 2008. A large-scale classification of
English verbs. In LREC ’08.
Anna Korhonen, Genevieve Gorrell, and Diana Mc-
Carthy. 2000. Statistical filtering and subcategoriza-
tion frame acquisition. In Proceedings of the Joint
SIGDAT Conference on Empirical Methods in Natural
Language Processing and Very Large Corpora.
Anna Korhonen, Yuval Krymolowski, and Ted Briscoe.
2006a. A large subcategorization lexicon for natural
language processing applications. In LREC ’06.
Anna Korhonen, Yuval Krymolowski, and Nigel Collier.
2006b. Automatic classification of verbs in biomedi-
cal texts. In ACL ’06.
Anna Korhonen, Yuval Krymolowski, and Nigel Collier.
2008. The choice of features for classification of verbs
in biomedical texts. In COLING ’08.
Ro Lenci, Barbara Mcgillivray, Simonetta Montemagni,
and Vito Pirrelli. 2008. Unsupervised acquisition
of verb subcategorization frames from shallow-parsed
corpora. In LREC ’08.
Beth Levin. 1993. English Verb Classes and Alternation:
A Preliminary Investigation. University of Chicago
Press, Chicago, IL.
Thomas Lippincott, Anna Korhonen, and Diarmuid O´
S´eaghdha. 2010. Exploring subdomain variation in
biomedical language. BMC Bioinformatics.
Diana McCarthy. 2000. Using semantic preferences to
identify verbal participation in role switching alterna-
tions. In NAACL ’00.
Marina Meila. 2003. Comparing clusterings by the Vari-
ation of Information. In COLT.
Paola Merlo and Suzanne Stevenson. 2001. Automatic
verb classification based on statistical distributions of
argument structure. Computational Linguistics.
C´edric Messiant. 2008. A subcategorization acquisition
system for French verbs. In ACL HLT ’08 Student Re-
search Workshop.
Yusuke Miyao. 2005. Probabilistic disambiguation mod-
els for wide-coverage HPSG parsing. In ACL ’05.
Radford M. Neal. 1993. Probabilistic inference using
markov chain Monte Carlo methods. Technical report,
University of Toronto.
Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mc-
donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007. The CoNLL 2007 shared task on de-
pendency parsing. In The CoNLL Shared Task Session
of EMNLP-CoNLL 2007.
Diarmuid O´ S´eaghdha. 2010. Latent variable models of
selectional preference. In ACL ’10.
Martha Palmer, Paul Kingsbury, and Daniel Gildea.
2005. The Proposition Bank: an annotated corpus of
semantic roles. Computational Linguistics.
Judita Preiss, Ted Briscoe, and Anna Korhonen. 2007. A
system for large-scale acquisition of verbal, nominal
and adjectival subcategorization frames from corpora.
In ACL ’07.
Douglas Roland and Daniel Jurafsky. 1998. How verb
subcategorization frequencies are affected by corpus
choice. In ACL ’98.
Peter Rousseeuw. 1987. Silhouettes: a graphical aid
to the interpretation and validation of cluster analysis.
Journal of Computational and Applied Mathematics.
C.J. Rupp, Paul Thompson, William Black, and John Mc-
Naught. 2010. A specialised verb lexicon as the ba-
sis of fact extraction in the biomedical domain. In In-
terdisciplinary Workshop on Verbs: The Identi�cation
and Representation of Verb Features.
Sabine Schulte im Walde. 2009. The induction of verb
frames and verb classes from corpora. In Corpus
Linguistics. An International Handbook. Mouton de
Gruyter.
Lin Sun and Anna Korhonen. 2009. Improving
verb clustering with automatically acquired selectional
preferences. In EMNLP’09.
Mihai Surdeanu, Sanda Harabagiu, John Williams, and
Paul Aarseth. 2003. Using predicate-argument struc-
tures for information extraction. In ACL ’03.
Adam R. Teichert and Hal Daum´e III. 2009. Unsuper-
vised part of speech tagging without a lexicon. In
NIPS Workshop on Grammar Induction, Representa-
tion of Language and Language Learning.
E. Uzun, Y. Klaslan, H.V. Agun, and E. Uar. 2008.
Web-based acquisition of subcategorization frames for
Turkish. In The Eighth International Conference on
Arti�cial Intelligence and Soft Computing.
Giulia Venturi, Simonetta Montemagni, Simone Marchi,
Yutaka Sasaki, Paul Thompson, John McNaught, and
Sophia Ananiadou. 2009. Bootstrapping a verb lex-
icon for biomedical information extraction. In Com-
putational Linguistics and Intelligent Text Processing.
Springer Berlin / Heidelberg.
</reference>
<page confidence="0.999242">
429
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.041278">
<title confidence="0.999957">Learning Syntactic Verb Frames Using Graphical Models</title>
<author confidence="0.989575">Thomas</author>
<affiliation confidence="0.824953">University of Computer United</affiliation>
<email confidence="0.757124">tl318@cam.ac.uk</email>
<affiliation confidence="0.55943575">O´ University of Computer United</affiliation>
<email confidence="0.447697">do242@cam.ac.uk</email>
<author confidence="0.394104">Anna</author>
<affiliation confidence="0.543806">University of Computer United</affiliation>
<email confidence="0.53759">alk23@cam.ac.uk</email>
<abstract confidence="0.995713470588235">We present a novel approach for building verb subcategorization lexicons using a simple graphical model. In contrast to previous methods, we show how the model can be trained without parsed input or a predefined subcategorization frame inventory. Our method outperforms the state-of-the-art on a verb clustering task, and is easily trained on arbitrary domains. This quantitative evaluation is complemented by a qualitative discussion of verbs and their frames. We discuss the advantages of graphical models for this task, in particular the ease of integrating semantic information about verbs and arguments in a principled fashion. We conclude with future work to augment the approach.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Omri Abend</author>
<author>Ari Rappoport</author>
</authors>
<title>Fully unsupervised core-adjunct argument classification.</title>
<date>2010</date>
<booktitle>In ACL ’10.</booktitle>
<contexts>
<context position="9962" citStr="Abend and Rappoport (2010)" startWordPosition="1502" endWordPosition="1505">nsupervised POS tagging (Finkel et al., 2007), and sampling methods allow efficient estimation of full joint distributions (Neal, 1993). The potential for joint inference of complementary information, such as syntactic verb and semantic argument classes, has a clear and interpretable way forward, in contrast to the pipelined methods described above. This was demonstrated in Andrew et al. (2004), where a Bayesian model was used to jointly induce syntactic and semantic classes for verbs, although that study relied on manually annotated data and a predefined SCF inventory and MLE. More recently, Abend and Rappoport (2010) trained ensemble classifiers to perform argumentadjunct disambiguation of PP complements, a task closely related to SCF acquisition. Their study employed unsupervised POS tagging and parsing, and measures of selectional preference and argument structure as complementary features for the classifier. Finally, our task-based evaluation, verb clustering with Levin (1993)’s alternation classes as the gold standard, was previously conducted by Joanis and Stevenson (2003), Korhonen et al. (2008) and Sun and Korhonen (2009). 3 Methodology In this section we describe the basic components of our study:</context>
</contexts>
<marker>Abend, Rappoport, 2010</marker>
<rawString>Omri Abend and Ari Rappoport. 2010. Fully unsupervised core-adjunct argument classification. In ACL ’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Galen Andrew</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Verb sense and subcategorization: using joint inference to improve performance on complementary tasks.</title>
<date>2004</date>
<journal>EMNLP</journal>
<volume>04</volume>
<contexts>
<context position="9733" citStr="Andrew et al. (2004)" startWordPosition="1466" endWordPosition="1469">contrast, does not use a predefined SCF inventory, and can perform well without parsed input. Graphical models have been increasingly popular for a variety of tasks such as distributional semantics (Blei et al., 2003) and unsupervised POS tagging (Finkel et al., 2007), and sampling methods allow efficient estimation of full joint distributions (Neal, 1993). The potential for joint inference of complementary information, such as syntactic verb and semantic argument classes, has a clear and interpretable way forward, in contrast to the pipelined methods described above. This was demonstrated in Andrew et al. (2004), where a Bayesian model was used to jointly induce syntactic and semantic classes for verbs, although that study relied on manually annotated data and a predefined SCF inventory and MLE. More recently, Abend and Rappoport (2010) trained ensemble classifiers to perform argumentadjunct disambiguation of PP complements, a task closely related to SCF acquisition. Their study employed unsupervised POS tagging and parsing, and measures of selectional preference and argument structure as complementary features for the classifier. Finally, our task-based evaluation, verb clustering with Levin (1993)’</context>
</contexts>
<marker>Andrew, Grenager, Manning, 2004</marker>
<rawString>Galen Andrew, Trond Grenager, and Christopher Manning. 2004. Verb sense and subcategorization: using joint inference to improve performance on complementary tasks. EMNLP ’04.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Collin Baker</author>
<author>Charles Fillmore</author>
<author>John Lowe</author>
</authors>
<title>The Berkeley FrameNet project.</title>
<date>1998</date>
<booktitle>In COLINGACL ’98.</booktitle>
<contexts>
<context position="7078" citStr="Baker et al., 1998" startWordPosition="1059" endWordPosition="1062">ice for SCF acquisition. There are several SCF lexicons for general language, such as ANLT (Boguraev and Briscoe, 1987) and COMLEX (Grishman et al., 1994), that depend on manual work. VALEX (Preiss et al., 2007) provides SCF distributions for 6,397 verbs acquired from a parsed general language corpus via a system that relies on hand-crafted rules. There are also resources which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb is annotated for its arguments and their semantic roles, covering a total of 4,592 verbs. There are many language-specific SCF acquisition systems, e.g. for French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Han et al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either directly through heuristics, or indirectly through parsing models trained on treebanks. Furthermore, some require labeled training inst</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin Baker, Charles Fillmore, and John Lowe. 1998. The Berkeley FrameNet project. In COLINGACL ’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Blei</author>
<author>Andrew Ng</author>
<author>Michael Jordan</author>
<author>John Lafferty</author>
</authors>
<title>Latent dirichlet allocation.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="9330" citStr="Blei et al., 2003" startWordPosition="1406" endWordPosition="1409">finition of the SCF inventory, careful construction of matching rules, and an unlexicalized parsing model. The BioLexicon system induces its SCF inventory automatically, but requires a lexicalized parsing model, rendering it more sensitive to domain variation. Both rely on a filtering stage that depends on external resources and/or gold standards to select top-performing thresholds. Our method, by contrast, does not use a predefined SCF inventory, and can perform well without parsed input. Graphical models have been increasingly popular for a variety of tasks such as distributional semantics (Blei et al., 2003) and unsupervised POS tagging (Finkel et al., 2007), and sampling methods allow efficient estimation of full joint distributions (Neal, 1993). The potential for joint inference of complementary information, such as syntactic verb and semantic argument classes, has a clear and interpretable way forward, in contrast to the pipelined methods described above. This was demonstrated in Andrew et al. (2004), where a Bayesian model was used to jointly induce syntactic and semantic classes for verbs, although that study relied on manually annotated data and a predefined SCF inventory and MLE. More rece</context>
<context position="28546" citStr="Blei et al., 2003" startWordPosition="4512" endWordPosition="4515">s to subcategorization also suggested several ways to extend and improve the method. First, the independence assumptions between GRs in a given instance turned out to be too strong. To address this, we could give instances internal structure to capture conditional probability between generated GRs. Second, our results showed the conflation of several verbal aspects, most notably the syntactic and semantic. In a sense this is encouraging, as it motivates our most exciting future work: augmenting this simple model to explicitly capture complementary information such as distributional semantics (Blei et al., 2003), diathesis alternations (McCarthy, 2000) and selectional preferences ( O´ S´eaghdha, 2010). This study targeted high-frequency verbs, but the use of syntactic and semantic classes would also help with data sparsity down the road. These extensions would also call for a more comprehensive evaluation, averaging over several tasks, such as clustering by semantics, syntax, alternations and selectional preferences. In concrete terms, we plan to introduce latent variables corresponding to syntactic, semantic and alternation classes, that will determine a verb’s syntactic arguments, their semantic re</context>
</contexts>
<marker>Blei, Ng, Jordan, Lafferty, 2003</marker>
<rawString>David Blei, Andrew Ng, Michael Jordan, and John Lafferty. 2003. Latent dirichlet allocation. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olivier Bodenreider</author>
</authors>
<title>The Unified Medical Language System (UMLS): integrating biomedical terminology.</title>
<date>2004</date>
<journal>Nucleic Acids Research,</journal>
<volume>32</volume>
<contexts>
<context position="2910" citStr="Bodenreider, 2004" startWordPosition="421" endWordPosition="422">-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs. In a few domains like biomedicine, the need for focused SCF lexicons has led to manually-built resources (Bodenreider, 2004). Such resources, however, are costly, prone to human error, and in domains where new lexical and syntactic constructs are frequently coined, quickly become obsolete (Cohen and Hunter, 2006). Datadriven methods for SCF acquisition can alleviate 420 Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 420–429, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics these problems by building lexicons tailored to new domains with less manual effort, and higher coverage and scalability. Unfortunately, high quality SCF lex</context>
</contexts>
<marker>Bodenreider, 2004</marker>
<rawString>Olivier Bodenreider. 2004. The Unified Medical Language System (UMLS): integrating biomedical terminology. Nucleic Acids Research, 32.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bran Boguraev</author>
<author>Ted Briscoe</author>
</authors>
<title>Large lexicons for natural language processing.</title>
<date>1987</date>
<journal>Computational Linguistics,</journal>
<volume>13</volume>
<contexts>
<context position="2480" citStr="Boguraev and Briscoe, 1987" startWordPosition="358" endWordPosition="361">ternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs. In a few domains like biomedicine, the need for focused SCF lexicons has led to manually-built resources (Bodenreider, 2004). Such resources, however, are costly, prone to human error, and in domains where new lexical and syntactic constructs are frequently coined, quickly become obsolete (Coh</context>
<context position="6578" citStr="Boguraev and Briscoe, 1987" startWordPosition="978" endWordPosition="981">neffe et al., 2006). For example, a subjectrelation like “ncsubj(HEAD, DEPENDENT)” expresses the fact that the lexical item referred to by HEAD (such as a present-tense verb) has the lexical item referred to by DEPENDENT as its subject (such as a singular noun). GR inventories include direct and indirect objects, complements, conjunctions, among other relations. The dependency relationships included in GRs correspond closely to the head-complement structure of SCFs, which is why they are the natural choice for SCF acquisition. There are several SCF lexicons for general language, such as ANLT (Boguraev and Briscoe, 1987) and COMLEX (Grishman et al., 1994), that depend on manual work. VALEX (Preiss et al., 2007) provides SCF distributions for 6,397 verbs acquired from a parsed general language corpus via a system that relies on hand-crafted rules. There are also resources which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., </context>
</contexts>
<marker>Boguraev, Briscoe, 1987</marker>
<rawString>Bran Boguraev and Ted Briscoe. 1987. Large lexicons for natural language processing. Computational Linguistics, 13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
<author>Rebecca Watson</author>
</authors>
<title>The second release of the RASP system.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Interactive presentation sessions.</booktitle>
<contexts>
<context position="5943" citStr="Briscoe et al., 2006" startWordPosition="876" endWordPosition="879">tate-of-the-art performance without relying on error-prone unlexicalized or domain-specific lexicalized parsers. Third, we highlight a key advantage of our method compared to previous approaches: the ease of integrating and performing joint inference of additional syntactic and semantic information. We describe how we plan to exploit this in our future research. 2 Previous work Many state-of-the-art SCF acquisition systems take grammatical relations (GRs) as input. GRs express binary dependencies between lexical items, and many parsers produce them as output, with some variation in inventory (Briscoe et al., 2006; De Marneffe et al., 2006). For example, a subjectrelation like “ncsubj(HEAD, DEPENDENT)” expresses the fact that the lexical item referred to by HEAD (such as a present-tense verb) has the lexical item referred to by DEPENDENT as its subject (such as a singular noun). GR inventories include direct and indirect objects, complements, conjunctions, among other relations. The dependency relationships included in GRs correspond closely to the head-complement structure of SCFs, which is why they are the natural choice for SCF acquisition. There are several SCF lexicons for general language, such a</context>
<context position="8061" citStr="Briscoe et al., 2006" startWordPosition="1209" endWordPosition="1212">al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either directly through heuristics, or indirectly through parsing models trained on treebanks. Furthermore, some require labeled training instances for supervised (Uzun et al., 2008) or semi-supervised (Han et al., 2008) learning algorithms. Two state-of-the-art data-driven systems for English verbs are those that produced VALEX, Preiss et al. (2007), and the BioLexicon (Venturi et al., 2009). 421 The Preiss system extracts a verb instance’s GRs using the Rasp general-language unlexicalized parser (Briscoe et al., 2006) as input, and based on handcrafted rules, maps verb instances to a predefined inventory of 168 SCFs. Filtering is then performed to remove noisy frames, with methods ranging from a simple single threshold to SCF-specific hypothesis tests based on external verb classes and SCF inventories. The BioLexicon system extracts each verb instance’s GRs using the lexicalized Enju parser tuned to the biomedical domain (Miyao, 2005). Each unique GR-set considered a potential SCF, and an experimentally-determined threshold is used to filter low-frequency SCFs. Note that both methods require extensive manu</context>
<context position="11275" citStr="Briscoe et al., 2006" startWordPosition="1700" endWordPosition="1703">ted several feature sets either based on, or approximating, the concept of grammatical relation described in section 2. Our method is agnostic regarding the exact definition of GR, and for example could use the Stanford inventory (De Marneffe et al., 2006) or even an entirely different lexico-syntactic formalism like CCG supertags (Curran et al., 2007). In this paper, we distinguish “true GRs” (tGRs), produced by a parser, and “pseudo GRs” (pGRs), a POS-based approximation, and employ subscripts to further specify the variations described below. Our input has been parsed into Rasp-style tGRs (Briscoe et al., 2006), which facilitates comparison with previous work based on the same data set. We’ll use a simple example sentence to illustrate how our feature sets are extracted from CONLLformatted data (Nivre et al., 2007). The CONLL format is a common language for comparing output from dependency parsers: each lexical item has an index, lemma, POS tag, tGR in which it is the dependent, and index to the corresponding head. Table 1 shows the relevant fields for the sentence “We run training programmes in Romania and other countries”. We define the feature set for a verb occurrence as the counts of each GR th</context>
<context position="20620" citStr="Briscoe et al., 2006" startWordPosition="3275" endWordPosition="3278"> described in section 2. Table 4 shows the performance of the lexicons in ascending order. Method Pur. F-score Adj. Rand tGR .24 .02 tGRlim .27 .02 pGRlex .32 .09 tGRlim,param .35 .08 pGR .35 .10 VALEX .36 .10 tGRparam,lex .37 .10 tGRparam .39 .12 tGRlim,param,lex .44 .12 Table 4: Task-based evaluation of lexicons acquired with each of the eight feature types, and the state-ofthe-art rule-based VALEX lexicon. These results lead to several conclusions: first, training our model on tGRs outperforms pGRs and VALEX. Since the parser that produced them is known to perform well on general language (Briscoe et al., 2006), the tGRs are of high quality: it makes sense that reverting to the pGRs is unnecessary in this case. The interesting point is the major performance gain over VALEX, which uses the same tGR features along with expert-developed rules and inventory. Second, we achieve performance comparable to VALEX using pGRs with a narrow window width. Since POS tagging is more reliable and robust across domains than parsing, retraining on new domains will not suffer the effects of a mismatched parsing model (Lippincott et al., 2010). It is therefore possible to use this method to build large-scale lexicons f</context>
</contexts>
<marker>Briscoe, Carroll, Watson, 2006</marker>
<rawString>Ted Briscoe, John Carroll, and Rebecca Watson. 2006. The second release of the RASP system. In Proceedings of the COLING/ACL on Interactive presentation sessions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Guido Minnen</author>
<author>Ted Briscoe</author>
</authors>
<title>Can subcategorisation probabilities help a statistical parser?</title>
<date>1998</date>
<booktitle>In The 6th ACL/SIGDAT Workshop on Very Large Corpora.</booktitle>
<contexts>
<context position="2248" citStr="Carroll et al., 1998" startWordPosition="327" endWordPosition="330">OMP), while “understand” is more likely to take just a direct object (NP). A comprehensive lexicon would also include semantic information about selectional preferences (or restrictions) on argument heads of verbs, diathesis alternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs. In a few domains like biomedicine, the need for focused SCF le</context>
</contexts>
<marker>Carroll, Minnen, Briscoe, 1998</marker>
<rawString>John Carroll, Guido Minnen, and Ted Briscoe. 1998. Can subcategorisation probabilities help a statistical parser? In The 6th ACL/SIGDAT Workshop on Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Bretonnel Cohen</author>
<author>Lawrence Hunter</author>
</authors>
<title>A critical review of PASBio’s argument structures for biomedical verbs.</title>
<date>2006</date>
<journal>BMC Bioinformatics,</journal>
<volume>7</volume>
<contexts>
<context position="2124" citStr="Cohen and Hunter, 2006" startWordPosition="306" endWordPosition="309">as present)) An SCF lexicon would indicate that “persuade” is likely to take a direct object and sentential complement (NP-SCOMP), while “understand” is more likely to take just a direct object (NP). A comprehensive lexicon would also include semantic information about selectional preferences (or restrictions) on argument heads of verbs, diathesis alternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering tha</context>
<context position="4667" citStr="Cohen and Hunter, 2006" startWordPosition="684" endWordPosition="687">g model are expensive to build for new domains. Moreover, while parsing may aid the detection of some frames, many experiments have also reported SCF errors due to noise from parsing (Korhonen et al., 2006a; Preiss et al., 2007). Finally, many SCF acquisition methods operate with predefined SCF inventories. This subscribes to a single (often language or domain-specific) interpretation of subcategorization a priori, and ignores the ongoing debate on how this interpretation should be tailored to new domains and applications, such as the more prominent role of adjuncts in information extraction (Cohen and Hunter, 2006). In this paper, we describe and evaluate a novel probabilistic data-driven method for SCF acquisition aimed at addressing some of the problems with current approaches. In our model, a Bayesian network describes how verbs choose their arguments in terms of a small number of frames, which are represented as distributions over syntactic relationships. First, we show that by allowing the inference process to automatically define a probabilistic SCF inventory, we outperform systems with handcrafted rules and inventories, using identical syntactic features. Second, by replacing the syntactic featur</context>
</contexts>
<marker>Cohen, Hunter, 2006</marker>
<rawString>K Bretonnel Cohen and Lawrence Hunter. 2006. A critical review of PASBio’s argument structures for biomedical verbs. BMC Bioinformatics, 7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Curran</author>
<author>Stephen Clark</author>
<author>Johan Bos</author>
</authors>
<date>2007</date>
<booktitle>Linguistically motivated large-Scale NLP with C&amp;C and Boxer. In ACL ’07.</booktitle>
<contexts>
<context position="11008" citStr="Curran et al., 2007" startWordPosition="1658" endWordPosition="1661">sly conducted by Joanis and Stevenson (2003), Korhonen et al. (2008) and Sun and Korhonen (2009). 3 Methodology In this section we describe the basic components of our study: feature sets, graphical model, inference, and evaluation. 3.1 Input and feature sets We tested several feature sets either based on, or approximating, the concept of grammatical relation described in section 2. Our method is agnostic regarding the exact definition of GR, and for example could use the Stanford inventory (De Marneffe et al., 2006) or even an entirely different lexico-syntactic formalism like CCG supertags (Curran et al., 2007). In this paper, we distinguish “true GRs” (tGRs), produced by a parser, and “pseudo GRs” (pGRs), a POS-based approximation, and employ subscripts to further specify the variations described below. Our input has been parsed into Rasp-style tGRs (Briscoe et al., 2006), which facilitates comparison with previous work based on the same data set. We’ll use a simple example sentence to illustrate how our feature sets are extracted from CONLLformatted data (Nivre et al., 2007). The CONLL format is a common language for comparing output from dependency parsers: each lexical item has an index, lemma, </context>
</contexts>
<marker>Curran, Clark, Bos, 2007</marker>
<rawString>James Curran, Stephen Clark, and Johan Bos. 2007. Linguistically motivated large-Scale NLP with C&amp;C and Boxer. In ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine De Marneffe</author>
<author>Bill Maccartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In LREC ’06.</booktitle>
<marker>De Marneffe, Maccartney, Manning, 2006</marker>
<rawString>Marie-Catherine De Marneffe, Bill Maccartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In LREC ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>The infinite tree.</title>
<date>2007</date>
<booktitle>In ACL ’07.</booktitle>
<contexts>
<context position="9381" citStr="Finkel et al., 2007" startWordPosition="1414" endWordPosition="1417">on of matching rules, and an unlexicalized parsing model. The BioLexicon system induces its SCF inventory automatically, but requires a lexicalized parsing model, rendering it more sensitive to domain variation. Both rely on a filtering stage that depends on external resources and/or gold standards to select top-performing thresholds. Our method, by contrast, does not use a predefined SCF inventory, and can perform well without parsed input. Graphical models have been increasingly popular for a variety of tasks such as distributional semantics (Blei et al., 2003) and unsupervised POS tagging (Finkel et al., 2007), and sampling methods allow efficient estimation of full joint distributions (Neal, 1993). The potential for joint inference of complementary information, such as syntactic verb and semantic argument classes, has a clear and interpretable way forward, in contrast to the pipelined methods described above. This was demonstrated in Andrew et al. (2004), where a Bayesian model was used to jointly induce syntactic and semantic classes for verbs, although that study relied on manually annotated data and a predefined SCF inventory and MLE. More recently, Abend and Rappoport (2010) trained ensemble c</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2007</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2007. The infinite tree. In ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>Catherine Macleod</author>
<author>Adam Meyers</author>
</authors>
<title>Comlex syntax: building a computational lexicon.</title>
<date>1994</date>
<booktitle>In COLING ’94.</booktitle>
<contexts>
<context position="2504" citStr="Grishman et al., 1994" startWordPosition="362" endWordPosition="365">y-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs. In a few domains like biomedicine, the need for focused SCF lexicons has led to manually-built resources (Bodenreider, 2004). Such resources, however, are costly, prone to human error, and in domains where new lexical and syntactic constructs are frequently coined, quickly become obsolete (Cohen and Hunter, 2006). Da</context>
<context position="6613" citStr="Grishman et al., 1994" startWordPosition="984" endWordPosition="987">ectrelation like “ncsubj(HEAD, DEPENDENT)” expresses the fact that the lexical item referred to by HEAD (such as a present-tense verb) has the lexical item referred to by DEPENDENT as its subject (such as a singular noun). GR inventories include direct and indirect objects, complements, conjunctions, among other relations. The dependency relationships included in GRs correspond closely to the head-complement structure of SCFs, which is why they are the natural choice for SCF acquisition. There are several SCF lexicons for general language, such as ANLT (Boguraev and Briscoe, 1987) and COMLEX (Grishman et al., 1994), that depend on manual work. VALEX (Preiss et al., 2007) provides SCF distributions for 6,397 verbs acquired from a parsed general language corpus via a system that relies on hand-crafted rules. There are also resources which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb i</context>
</contexts>
<marker>Grishman, Macleod, Meyers, 1994</marker>
<rawString>Ralph Grishman, Catherine Macleod, and Adam Meyers. 1994. Comlex syntax: building a computational lexicon. In COLING ’94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiwu Han</author>
<author>Chengguo Lv</author>
<author>Tiejun Zhao</author>
</authors>
<title>Weakly supervised SVM for Chinese-English crosslingual subcategorization lexicon acquisition.</title>
<date>2008</date>
<booktitle>In The 11th Joint Conference on Information Science.</booktitle>
<contexts>
<context position="7450" citStr="Han et al., 2008" startWordPosition="1119" endWordPosition="1122"> which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb is annotated for its arguments and their semantic roles, covering a total of 4,592 verbs. There are many language-specific SCF acquisition systems, e.g. for French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Han et al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either directly through heuristics, or indirectly through parsing models trained on treebanks. Furthermore, some require labeled training instances for supervised (Uzun et al., 2008) or semi-supervised (Han et al., 2008) learning algorithms. Two state-of-the-art data-driven systems for English verbs are those that produced VALEX, Preiss et al. (2007), and the BioLexicon (Venturi et al., 2009). 421 The Preiss system extracts a verb instance’s GRs using the Rasp general-language unlexicalized parser (Briscoe et</context>
</contexts>
<marker>Han, Lv, Zhao, 2008</marker>
<rawString>Xiwu Han, Chengguo Lv, and Tiejun Zhao. 2008. Weakly supervised SVM for Chinese-English crosslingual subcategorization lexicon acquisition. In The 11th Joint Conference on Information Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Hartigan</author>
<author>M A Wong</author>
</authors>
<title>Algorithm AS 136: A K-Means clustering algorithm.</title>
<date>1979</date>
<journal>Journal of the Royal Statistical Society. Series C (Applied Statistics).</journal>
<contexts>
<context position="18443" citStr="Hartigan and Wong, 1979" startWordPosition="2924" endWordPosition="2927">ance on a task that a good SCF lexicon should be useful for: clustering verbs into lexical-semantic classes. Our gold standard is from (Sun and Korhonen, 2009), where 200 verbs were assigned to 17 classes based on their alternation patterns (Levin, 1993). Previous work (Schulte im Walde, 2009; Sun and Korhonen, 2009) has demonstrated that the quality of an SCF lexicon’s inventory and probability estimates corresponds to its predictive power for membership in such alternation classes. To compare the performance of our feature sets, we chose the simple and familiar K-Means clustering algorithm (Hartigan and Wong, 1979). The instances are the verbs’ SCF distributions, and we select the number of clusters by the Silhouette validation technique (Rousseeuw, 1987). The clusters are then compared to the gold standard clusters with the purity-based F-Score from Sun and Korhonen (2009) and the more familiar Adjusted Rand Index (Hubert and Arabie, 1985). Our main point of comparison is the VALEX lexicon of SCF distributions, whose scores we report alongside ours. Qualitative: manual gold standard We also want to see how our results line up with a traditional linguistic view of subcategorization, but this requires di</context>
</contexts>
<marker>Hartigan, Wong, 1979</marker>
<rawString>J.A. Hartigan and M.A. Wong. 1979. Algorithm AS 136: A K-Means clustering algorithm. Journal of the Royal Statistical Society. Series C (Applied Statistics).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregor Heinrich</author>
</authors>
<title>Parameter estimation for text analysis.</title>
<date>2009</date>
<tech>Technical report, Fraunhofer IGD.</tech>
<contexts>
<context position="27673" citStr="Heinrich, 2009" startWordPosition="4381" endWordPosition="4382">b as pseudo-GRs produces state-of-the-art results without the need for a parsing model. This is particularly encouraging when building resources for new domains, where complex models fail to generalize. In fact, by integrating results from unsupervised POS tagging (Teichert and Daum´e III, 2009) we could render this approach fully domain- and language-independent. We did not dwell on issues related to choosing our hyper-parameters or latent class count. Both of these can be accomplished with additional sampling methods: hyper-parameters of Dirichlet priors can be estimated via slice sampling (Heinrich, 2009), and their dimensionality via Dirichlet Process priors (Heinrich, 2011). This could help address the redundancy we find in the induced SCF inventory, with the potential SCFs growing to accommodate the data. Our initial attempt at applying graphical models to subcategorization also suggested several ways to extend and improve the method. First, the independence assumptions between GRs in a given instance turned out to be too strong. To address this, we could give instances internal structure to capture conditional probability between generated GRs. Second, our results showed the conflation of </context>
</contexts>
<marker>Heinrich, 2009</marker>
<rawString>Gregor Heinrich. 2009. Parameter estimation for text analysis. Technical report, Fraunhofer IGD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gregor Heinrich</author>
</authors>
<title>Infinite LDA implementing the HDP with minimum code complexity.</title>
<date>2011</date>
<tech>Technical report, arbylon.net.</tech>
<contexts>
<context position="27745" citStr="Heinrich, 2011" startWordPosition="4390" endWordPosition="4391"> parsing model. This is particularly encouraging when building resources for new domains, where complex models fail to generalize. In fact, by integrating results from unsupervised POS tagging (Teichert and Daum´e III, 2009) we could render this approach fully domain- and language-independent. We did not dwell on issues related to choosing our hyper-parameters or latent class count. Both of these can be accomplished with additional sampling methods: hyper-parameters of Dirichlet priors can be estimated via slice sampling (Heinrich, 2009), and their dimensionality via Dirichlet Process priors (Heinrich, 2011). This could help address the redundancy we find in the induced SCF inventory, with the potential SCFs growing to accommodate the data. Our initial attempt at applying graphical models to subcategorization also suggested several ways to extend and improve the method. First, the independence assumptions between GRs in a given instance turned out to be too strong. To address this, we could give instances internal structure to capture conditional probability between generated GRs. Second, our results showed the conflation of several verbal aspects, most notably the syntactic and semantic. In a se</context>
</contexts>
<marker>Heinrich, 2011</marker>
<rawString>Gregor Heinrich. 2011. Infinite LDA implementing the HDP with minimum code complexity. Technical report, arbylon.net.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Hubert</author>
<author>Phipps Arabie</author>
</authors>
<title>Comparing partitions.</title>
<date>1985</date>
<journal>Journal of Classi�cation,</journal>
<volume>2</volume>
<contexts>
<context position="18775" citStr="Hubert and Arabie, 1985" startWordPosition="2978" endWordPosition="2981">ted that the quality of an SCF lexicon’s inventory and probability estimates corresponds to its predictive power for membership in such alternation classes. To compare the performance of our feature sets, we chose the simple and familiar K-Means clustering algorithm (Hartigan and Wong, 1979). The instances are the verbs’ SCF distributions, and we select the number of clusters by the Silhouette validation technique (Rousseeuw, 1987). The clusters are then compared to the gold standard clusters with the purity-based F-Score from Sun and Korhonen (2009) and the more familiar Adjusted Rand Index (Hubert and Arabie, 1985). Our main point of comparison is the VALEX lexicon of SCF distributions, whose scores we report alongside ours. Qualitative: manual gold standard We also want to see how our results line up with a traditional linguistic view of subcategorization, but this requires digging into the unsupervised out424 put and associating anonymous probabilistic objects with established categories. We therefore present sample output in three ways: first, we show the clustering output from our top-performing method. Second, we plot the probability mass over GRs for two anonymous SCFs that correspond to recogniza</context>
</contexts>
<marker>Hubert, Arabie, 1985</marker>
<rawString>Lawrence Hubert and Phipps Arabie. 1985. Comparing partitions. Journal of Classi�cation, 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Joanis</author>
<author>Suzanne Stevenson</author>
</authors>
<title>A general feature space for automatic verb classification.</title>
<date>2003</date>
<booktitle>In EACL ’03.</booktitle>
<contexts>
<context position="10432" citStr="Joanis and Stevenson (2003)" startWordPosition="1567" endWordPosition="1570">ic classes for verbs, although that study relied on manually annotated data and a predefined SCF inventory and MLE. More recently, Abend and Rappoport (2010) trained ensemble classifiers to perform argumentadjunct disambiguation of PP complements, a task closely related to SCF acquisition. Their study employed unsupervised POS tagging and parsing, and measures of selectional preference and argument structure as complementary features for the classifier. Finally, our task-based evaluation, verb clustering with Levin (1993)’s alternation classes as the gold standard, was previously conducted by Joanis and Stevenson (2003), Korhonen et al. (2008) and Sun and Korhonen (2009). 3 Methodology In this section we describe the basic components of our study: feature sets, graphical model, inference, and evaluation. 3.1 Input and feature sets We tested several feature sets either based on, or approximating, the concept of grammatical relation described in section 2. Our method is agnostic regarding the exact definition of GR, and for example could use the Stanford inventory (De Marneffe et al., 2006) or even an entirely different lexico-syntactic formalism like CCG supertags (Curran et al., 2007). In this paper, we dist</context>
</contexts>
<marker>Joanis, Stevenson, 2003</marker>
<rawString>Eric Joanis and Suzanne Stevenson. 2003. A general feature space for automatic verb classification. In EACL ’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Kipper</author>
<author>Anna Korhonen</author>
<author>Neville Ryant</author>
<author>Martha Palmer</author>
</authors>
<title>A large-scale classification of English verbs.</title>
<date>2008</date>
<booktitle>In LREC ’08.</booktitle>
<contexts>
<context position="6944" citStr="Kipper et al., 2008" startWordPosition="1038" endWordPosition="1041">ndency relationships included in GRs correspond closely to the head-complement structure of SCFs, which is why they are the natural choice for SCF acquisition. There are several SCF lexicons for general language, such as ANLT (Boguraev and Briscoe, 1987) and COMLEX (Grishman et al., 1994), that depend on manual work. VALEX (Preiss et al., 2007) provides SCF distributions for 6,397 verbs acquired from a parsed general language corpus via a system that relies on hand-crafted rules. There are also resources which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb is annotated for its arguments and their semantic roles, covering a total of 4,592 verbs. There are many language-specific SCF acquisition systems, e.g. for French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Han et al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either d</context>
</contexts>
<marker>Kipper, Korhonen, Ryant, Palmer, 2008</marker>
<rawString>Karin Kipper, Anna Korhonen, Neville Ryant, and Martha Palmer. 2008. A large-scale classification of English verbs. In LREC ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Genevieve Gorrell</author>
<author>Diana McCarthy</author>
</authors>
<title>Statistical filtering and subcategorization frame acquisition.</title>
<date>2000</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</booktitle>
<contexts>
<context position="3818" citStr="Korhonen et al., 2000" startWordPosition="553" endWordPosition="556">g of the Association for Computational Linguistics, pages 420–429, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics these problems by building lexicons tailored to new domains with less manual effort, and higher coverage and scalability. Unfortunately, high quality SCF lexicons are difficult to build automatically. The argument-adjunct distinction is challenging even for humans, many SCFs have no reliable cues in data, and some SCFs (e.g. those involving control such as type raising) rely on semantic distinctions. As SCFs follow a Zipfian distribution (Korhonen et al., 2000), many genuine frames are also low in frequency. State-of-theart methods for building data-driven SCF lexicons typically rely on parsed input (see section 2). However, the treebanks necessary for training a highaccuracy parsing model are expensive to build for new domains. Moreover, while parsing may aid the detection of some frames, many experiments have also reported SCF errors due to noise from parsing (Korhonen et al., 2006a; Preiss et al., 2007). Finally, many SCF acquisition methods operate with predefined SCF inventories. This subscribes to a single (often language or domain-specific) i</context>
</contexts>
<marker>Korhonen, Gorrell, McCarthy, 2000</marker>
<rawString>Anna Korhonen, Genevieve Gorrell, and Diana McCarthy. 2000. Statistical filtering and subcategorization frame acquisition. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Ted Briscoe</author>
</authors>
<title>A large subcategorization lexicon for natural language processing applications.</title>
<date>2006</date>
<booktitle>In LREC ’06.</booktitle>
<contexts>
<context position="2184" citStr="Korhonen et al., 2006" startWordPosition="316" endWordPosition="320"> likely to take a direct object and sentential complement (NP-SCOMP), while “understand” is more likely to take just a direct object (NP). A comprehensive lexicon would also include semantic information about selectional preferences (or restrictions) on argument heads of verbs, diathesis alternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs</context>
<context position="4249" citStr="Korhonen et al., 2006" startWordPosition="623" endWordPosition="626"> have no reliable cues in data, and some SCFs (e.g. those involving control such as type raising) rely on semantic distinctions. As SCFs follow a Zipfian distribution (Korhonen et al., 2000), many genuine frames are also low in frequency. State-of-theart methods for building data-driven SCF lexicons typically rely on parsed input (see section 2). However, the treebanks necessary for training a highaccuracy parsing model are expensive to build for new domains. Moreover, while parsing may aid the detection of some frames, many experiments have also reported SCF errors due to noise from parsing (Korhonen et al., 2006a; Preiss et al., 2007). Finally, many SCF acquisition methods operate with predefined SCF inventories. This subscribes to a single (often language or domain-specific) interpretation of subcategorization a priori, and ignores the ongoing debate on how this interpretation should be tailored to new domains and applications, such as the more prominent role of adjuncts in information extraction (Cohen and Hunter, 2006). In this paper, we describe and evaluate a novel probabilistic data-driven method for SCF acquisition aimed at addressing some of the problems with current approaches. In our model,</context>
</contexts>
<marker>Korhonen, Krymolowski, Briscoe, 2006</marker>
<rawString>Anna Korhonen, Yuval Krymolowski, and Ted Briscoe. 2006a. A large subcategorization lexicon for natural language processing applications. In LREC ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Nigel Collier</author>
</authors>
<title>Automatic classification of verbs in biomedical texts.</title>
<date>2006</date>
<booktitle>In ACL ’06.</booktitle>
<contexts>
<context position="2184" citStr="Korhonen et al., 2006" startWordPosition="316" endWordPosition="320"> likely to take a direct object and sentential complement (NP-SCOMP), while “understand” is more likely to take just a direct object (NP). A comprehensive lexicon would also include semantic information about selectional preferences (or restrictions) on argument heads of verbs, diathesis alternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs</context>
<context position="4249" citStr="Korhonen et al., 2006" startWordPosition="623" endWordPosition="626"> have no reliable cues in data, and some SCFs (e.g. those involving control such as type raising) rely on semantic distinctions. As SCFs follow a Zipfian distribution (Korhonen et al., 2000), many genuine frames are also low in frequency. State-of-theart methods for building data-driven SCF lexicons typically rely on parsed input (see section 2). However, the treebanks necessary for training a highaccuracy parsing model are expensive to build for new domains. Moreover, while parsing may aid the detection of some frames, many experiments have also reported SCF errors due to noise from parsing (Korhonen et al., 2006a; Preiss et al., 2007). Finally, many SCF acquisition methods operate with predefined SCF inventories. This subscribes to a single (often language or domain-specific) interpretation of subcategorization a priori, and ignores the ongoing debate on how this interpretation should be tailored to new domains and applications, such as the more prominent role of adjuncts in information extraction (Cohen and Hunter, 2006). In this paper, we describe and evaluate a novel probabilistic data-driven method for SCF acquisition aimed at addressing some of the problems with current approaches. In our model,</context>
</contexts>
<marker>Korhonen, Krymolowski, Collier, 2006</marker>
<rawString>Anna Korhonen, Yuval Krymolowski, and Nigel Collier. 2006b. Automatic classification of verbs in biomedical texts. In ACL ’06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Korhonen</author>
<author>Yuval Krymolowski</author>
<author>Nigel Collier</author>
</authors>
<title>The choice of features for classification of verbs in biomedical texts.</title>
<date>2008</date>
<booktitle>In COLING ’08.</booktitle>
<contexts>
<context position="10456" citStr="Korhonen et al. (2008)" startWordPosition="1571" endWordPosition="1574">h that study relied on manually annotated data and a predefined SCF inventory and MLE. More recently, Abend and Rappoport (2010) trained ensemble classifiers to perform argumentadjunct disambiguation of PP complements, a task closely related to SCF acquisition. Their study employed unsupervised POS tagging and parsing, and measures of selectional preference and argument structure as complementary features for the classifier. Finally, our task-based evaluation, verb clustering with Levin (1993)’s alternation classes as the gold standard, was previously conducted by Joanis and Stevenson (2003), Korhonen et al. (2008) and Sun and Korhonen (2009). 3 Methodology In this section we describe the basic components of our study: feature sets, graphical model, inference, and evaluation. 3.1 Input and feature sets We tested several feature sets either based on, or approximating, the concept of grammatical relation described in section 2. Our method is agnostic regarding the exact definition of GR, and for example could use the Stanford inventory (De Marneffe et al., 2006) or even an entirely different lexico-syntactic formalism like CCG supertags (Curran et al., 2007). In this paper, we distinguish “true GRs” (tGRs</context>
</contexts>
<marker>Korhonen, Krymolowski, Collier, 2008</marker>
<rawString>Anna Korhonen, Yuval Krymolowski, and Nigel Collier. 2008. The choice of features for classification of verbs in biomedical texts. In COLING ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ro Lenci</author>
<author>Barbara Mcgillivray</author>
<author>Simonetta Montemagni</author>
<author>Vito Pirrelli</author>
</authors>
<title>Unsupervised acquisition of verb subcategorization frames from shallow-parsed corpora.</title>
<date>2008</date>
<booktitle>In LREC ’08.</booktitle>
<contexts>
<context position="7422" citStr="Lenci et al., 2008" startWordPosition="1114" endWordPosition="1117">ules. There are also resources which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb is annotated for its arguments and their semantic roles, covering a total of 4,592 verbs. There are many language-specific SCF acquisition systems, e.g. for French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Han et al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either directly through heuristics, or indirectly through parsing models trained on treebanks. Furthermore, some require labeled training instances for supervised (Uzun et al., 2008) or semi-supervised (Han et al., 2008) learning algorithms. Two state-of-the-art data-driven systems for English verbs are those that produced VALEX, Preiss et al. (2007), and the BioLexicon (Venturi et al., 2009). 421 The Preiss system extracts a verb instance’s GRs using the Rasp general-language unle</context>
</contexts>
<marker>Lenci, Mcgillivray, Montemagni, Pirrelli, 2008</marker>
<rawString>Ro Lenci, Barbara Mcgillivray, Simonetta Montemagni, and Vito Pirrelli. 2008. Unsupervised acquisition of verb subcategorization frames from shallow-parsed corpora. In LREC ’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternation: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="10332" citStr="Levin (1993)" startWordPosition="1555" endWordPosition="1556">et al. (2004), where a Bayesian model was used to jointly induce syntactic and semantic classes for verbs, although that study relied on manually annotated data and a predefined SCF inventory and MLE. More recently, Abend and Rappoport (2010) trained ensemble classifiers to perform argumentadjunct disambiguation of PP complements, a task closely related to SCF acquisition. Their study employed unsupervised POS tagging and parsing, and measures of selectional preference and argument structure as complementary features for the classifier. Finally, our task-based evaluation, verb clustering with Levin (1993)’s alternation classes as the gold standard, was previously conducted by Joanis and Stevenson (2003), Korhonen et al. (2008) and Sun and Korhonen (2009). 3 Methodology In this section we describe the basic components of our study: feature sets, graphical model, inference, and evaluation. 3.1 Input and feature sets We tested several feature sets either based on, or approximating, the concept of grammatical relation described in section 2. Our method is agnostic regarding the exact definition of GR, and for example could use the Stanford inventory (De Marneffe et al., 2006) or even an entirely d</context>
<context position="18073" citStr="Levin, 1993" startWordPosition="2869" endWordPosition="2870">ble at http://cl. cam.ac.uk/˜tl318/files/subcat.tgz Our goal is to define a fair quantitative comparison between arbitrary SCF lexicons. An SCF lexicon makes two claims: first, that it defines a reasonable SCF inventory. Second, that for each verb, it has an accurate distribution over that inventory. We therefore compare the lexicons based on their performance on a task that a good SCF lexicon should be useful for: clustering verbs into lexical-semantic classes. Our gold standard is from (Sun and Korhonen, 2009), where 200 verbs were assigned to 17 classes based on their alternation patterns (Levin, 1993). Previous work (Schulte im Walde, 2009; Sun and Korhonen, 2009) has demonstrated that the quality of an SCF lexicon’s inventory and probability estimates corresponds to its predictive power for membership in such alternation classes. To compare the performance of our feature sets, we chose the simple and familiar K-Means clustering algorithm (Hartigan and Wong, 1979). The instances are the verbs’ SCF distributions, and we select the number of clusters by the Silhouette validation technique (Rousseeuw, 1987). The clusters are then compared to the gold standard clusters with the purity-based F-</context>
<context position="21976" citStr="Levin (1993)" startWordPosition="3488" endWordPosition="3489">lternation-based definition of subcategorization. For example, subdividing the indefinite pronoun tag “PN1” into “PN1-anyone” and “PN1- anything” gives information about the animacy of the verb’s arguments. Our results show this degrades performance for both pGR and tGR features, unless the latter are limited to tGRs traditionally thought to be relevant for the task. 4.2 Qualitative analysis Table 5 shows clusters produced by our top-scoring method, GRparam,lex,lim. Some clusters are immediately intelligible at the semantic level and correspond closely to the lexical-semantic classes found in Levin (1993). For example, clusters 1, 6, and 14 include member verbs of Levin’s SAY, PEER and AMUSE classes, respectively. Some clusters are based on broader semantic distinctions (e.g. cluster 2 which groups together verbs related to locations) while others relate semantic classes purely based on their syntactic similarity (e.g. the verbs in cluster 17 share strong preference for ’to’ preposition). The syntactic-semantic nature of the clusters reflects the multimodal nature of verbs and illustrates why a comprehensive subcategorization lexicon should not be limited to syntactic frames. This phenomenon i</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternation: A Preliminary Investigation. University of Chicago Press, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Lippincott</author>
<author>Anna Korhonen</author>
<author>Diarmuid O´ S´eaghdha</author>
</authors>
<title>Exploring subdomain variation in biomedical language.</title>
<date>2010</date>
<journal>BMC Bioinformatics.</journal>
<marker>Lippincott, Korhonen, S´eaghdha, 2010</marker>
<rawString>Thomas Lippincott, Anna Korhonen, and Diarmuid O´ S´eaghdha. 2010. Exploring subdomain variation in biomedical language. BMC Bioinformatics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
</authors>
<title>Using semantic preferences to identify verbal participation in role switching alternations.</title>
<date>2000</date>
<booktitle>In NAACL ’00.</booktitle>
<contexts>
<context position="28587" citStr="McCarthy, 2000" startWordPosition="4518" endWordPosition="4519">l ways to extend and improve the method. First, the independence assumptions between GRs in a given instance turned out to be too strong. To address this, we could give instances internal structure to capture conditional probability between generated GRs. Second, our results showed the conflation of several verbal aspects, most notably the syntactic and semantic. In a sense this is encouraging, as it motivates our most exciting future work: augmenting this simple model to explicitly capture complementary information such as distributional semantics (Blei et al., 2003), diathesis alternations (McCarthy, 2000) and selectional preferences ( O´ S´eaghdha, 2010). This study targeted high-frequency verbs, but the use of syntactic and semantic classes would also help with data sparsity down the road. These extensions would also call for a more comprehensive evaluation, averaging over several tasks, such as clustering by semantics, syntax, alternations and selectional preferences. In concrete terms, we plan to introduce latent variables corresponding to syntactic, semantic and alternation classes, that will determine a verb’s syntactic arguments, their semantic realization (i.e. selectional preferences),</context>
</contexts>
<marker>McCarthy, 2000</marker>
<rawString>Diana McCarthy. 2000. Using semantic preferences to identify verbal participation in role switching alternations. In NAACL ’00.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Meila</author>
</authors>
<title>Comparing clusterings by the Variation of Information.</title>
<date>2003</date>
<booktitle>In COLT.</booktitle>
<contexts>
<context position="17418" citStr="Meila, 2003" startWordPosition="2763" endWordPosition="2764">n Gibbs sampling for 1000 iterations, and average the final 100 samples to estimate the posteriors P(SCF|V erb) and P(GR|SCF). Variance between adjacent states’ estimates of P(SCF|V erb) indicates that the sampling typically converges after about 100-200 iterations.1 3.3 Evaluation Quantitative: cluster gold standard Evaluating the output of unsupervised methods is not straightforward: discrete, expert-defined categories (like many SCF inventories) are unlikely to line up perfectly with data-driven, probabilistic output. Even if they do, finding a mapping between them is a problem of its own (Meila, 2003). 1Full source code for this work is available at http://cl. cam.ac.uk/˜tl318/files/subcat.tgz Our goal is to define a fair quantitative comparison between arbitrary SCF lexicons. An SCF lexicon makes two claims: first, that it defines a reasonable SCF inventory. Second, that for each verb, it has an accurate distribution over that inventory. We therefore compare the lexicons based on their performance on a task that a good SCF lexicon should be useful for: clustering verbs into lexical-semantic classes. Our gold standard is from (Sun and Korhonen, 2009), where 200 verbs were assigned to 17 cl</context>
</contexts>
<marker>Meila, 2003</marker>
<rawString>Marina Meila. 2003. Comparing clusterings by the Variation of Information. In COLT.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paola Merlo</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatic verb classification based on statistical distributions of argument structure.</title>
<date>2001</date>
<journal>Computational Linguistics.</journal>
<contexts>
<context position="2213" citStr="Merlo and Stevenson, 2001" startWordPosition="321" endWordPosition="324"> object and sentential complement (NP-SCOMP), while “understand” is more likely to take just a direct object (NP). A comprehensive lexicon would also include semantic information about selectional preferences (or restrictions) on argument heads of verbs, diathesis alternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs. In a few domains like biome</context>
</contexts>
<marker>Merlo, Stevenson, 2001</marker>
<rawString>Paola Merlo and Suzanne Stevenson. 2001. Automatic verb classification based on statistical distributions of argument structure. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C´edric Messiant</author>
</authors>
<title>A subcategorization acquisition system for French verbs.</title>
<date>2008</date>
<booktitle>In ACL HLT ’08 Student Research Workshop.</booktitle>
<contexts>
<context position="7392" citStr="Messiant, 2008" startWordPosition="1111" endWordPosition="1112">t relies on hand-crafted rules. There are also resources which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb is annotated for its arguments and their semantic roles, covering a total of 4,592 verbs. There are many language-specific SCF acquisition systems, e.g. for French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Han et al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either directly through heuristics, or indirectly through parsing models trained on treebanks. Furthermore, some require labeled training instances for supervised (Uzun et al., 2008) or semi-supervised (Han et al., 2008) learning algorithms. Two state-of-the-art data-driven systems for English verbs are those that produced VALEX, Preiss et al. (2007), and the BioLexicon (Venturi et al., 2009). 421 The Preiss system extracts a verb instance’s GRs using </context>
</contexts>
<marker>Messiant, 2008</marker>
<rawString>C´edric Messiant. 2008. A subcategorization acquisition system for French verbs. In ACL HLT ’08 Student Research Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
</authors>
<title>Probabilistic disambiguation models for wide-coverage HPSG parsing.</title>
<date>2005</date>
<booktitle>In ACL ’05.</booktitle>
<contexts>
<context position="8486" citStr="Miyao, 2005" startWordPosition="1279" endWordPosition="1280"> et al. (2007), and the BioLexicon (Venturi et al., 2009). 421 The Preiss system extracts a verb instance’s GRs using the Rasp general-language unlexicalized parser (Briscoe et al., 2006) as input, and based on handcrafted rules, maps verb instances to a predefined inventory of 168 SCFs. Filtering is then performed to remove noisy frames, with methods ranging from a simple single threshold to SCF-specific hypothesis tests based on external verb classes and SCF inventories. The BioLexicon system extracts each verb instance’s GRs using the lexicalized Enju parser tuned to the biomedical domain (Miyao, 2005). Each unique GR-set considered a potential SCF, and an experimentally-determined threshold is used to filter low-frequency SCFs. Note that both methods require extensive manual work: the Preiss system involves the a priori definition of the SCF inventory, careful construction of matching rules, and an unlexicalized parsing model. The BioLexicon system induces its SCF inventory automatically, but requires a lexicalized parsing model, rendering it more sensitive to domain variation. Both rely on a filtering stage that depends on external resources and/or gold standards to select top-performing </context>
</contexts>
<marker>Miyao, 2005</marker>
<rawString>Yusuke Miyao. 2005. Probabilistic disambiguation models for wide-coverage HPSG parsing. In ACL ’05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radford M Neal</author>
</authors>
<title>Probabilistic inference using markov chain Monte Carlo methods.</title>
<date>1993</date>
<tech>Technical report,</tech>
<institution>University of Toronto.</institution>
<contexts>
<context position="9471" citStr="Neal, 1993" startWordPosition="1428" endWordPosition="1429">entory automatically, but requires a lexicalized parsing model, rendering it more sensitive to domain variation. Both rely on a filtering stage that depends on external resources and/or gold standards to select top-performing thresholds. Our method, by contrast, does not use a predefined SCF inventory, and can perform well without parsed input. Graphical models have been increasingly popular for a variety of tasks such as distributional semantics (Blei et al., 2003) and unsupervised POS tagging (Finkel et al., 2007), and sampling methods allow efficient estimation of full joint distributions (Neal, 1993). The potential for joint inference of complementary information, such as syntactic verb and semantic argument classes, has a clear and interpretable way forward, in contrast to the pipelined methods described above. This was demonstrated in Andrew et al. (2004), where a Bayesian model was used to jointly induce syntactic and semantic classes for verbs, although that study relied on manually annotated data and a predefined SCF inventory and MLE. More recently, Abend and Rappoport (2010) trained ensemble classifiers to perform argumentadjunct disambiguation of PP complements, a task closely rel</context>
</contexts>
<marker>Neal, 1993</marker>
<rawString>Radford M. Neal. 1993. Probabilistic inference using markov chain Monte Carlo methods. Technical report, University of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra K¨ubler</author>
<author>Ryan Mcdonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>The CoNLL</title>
<date>2007</date>
<booktitle>In The CoNLL Shared Task Session of EMNLP-CoNLL</booktitle>
<marker>Nivre, Hall, K¨ubler, Mcdonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra K¨ubler, Ryan Mcdonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007. The CoNLL 2007 shared task on dependency parsing. In The CoNLL Shared Task Session of EMNLP-CoNLL 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
</authors>
<title>Latent variable models of selectional preference.</title>
<date>2010</date>
<booktitle>In ACL ’10.</booktitle>
<marker>S´eaghdha, 2010</marker>
<rawString>Diarmuid O´ S´eaghdha. 2010. Latent variable models of selectional preference. In ACL ’10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Paul Kingsbury</author>
<author>Daniel Gildea</author>
</authors>
<title>The Proposition Bank: an annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics.</journal>
<contexts>
<context position="7183" citStr="Palmer et al., 2005" startWordPosition="1075" endWordPosition="1078"> Briscoe, 1987) and COMLEX (Grishman et al., 1994), that depend on manual work. VALEX (Preiss et al., 2007) provides SCF distributions for 6,397 verbs acquired from a parsed general language corpus via a system that relies on hand-crafted rules. There are also resources which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb is annotated for its arguments and their semantic roles, covering a total of 4,592 verbs. There are many language-specific SCF acquisition systems, e.g. for French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Han et al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either directly through heuristics, or indirectly through parsing models trained on treebanks. Furthermore, some require labeled training instances for supervised (Uzun et al., 2008) or semi-supervised (Han et al., 2008) learning algorithms. Two s</context>
</contexts>
<marker>Palmer, Kingsbury, Gildea, 2005</marker>
<rawString>Martha Palmer, Paul Kingsbury, and Daniel Gildea. 2005. The Proposition Bank: an annotated corpus of semantic roles. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judita Preiss</author>
<author>Ted Briscoe</author>
<author>Anna Korhonen</author>
</authors>
<title>A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora.</title>
<date>2007</date>
<booktitle>In ACL ’07.</booktitle>
<contexts>
<context position="4272" citStr="Preiss et al., 2007" startWordPosition="627" endWordPosition="630">n data, and some SCFs (e.g. those involving control such as type raising) rely on semantic distinctions. As SCFs follow a Zipfian distribution (Korhonen et al., 2000), many genuine frames are also low in frequency. State-of-theart methods for building data-driven SCF lexicons typically rely on parsed input (see section 2). However, the treebanks necessary for training a highaccuracy parsing model are expensive to build for new domains. Moreover, while parsing may aid the detection of some frames, many experiments have also reported SCF errors due to noise from parsing (Korhonen et al., 2006a; Preiss et al., 2007). Finally, many SCF acquisition methods operate with predefined SCF inventories. This subscribes to a single (often language or domain-specific) interpretation of subcategorization a priori, and ignores the ongoing debate on how this interpretation should be tailored to new domains and applications, such as the more prominent role of adjuncts in information extraction (Cohen and Hunter, 2006). In this paper, we describe and evaluate a novel probabilistic data-driven method for SCF acquisition aimed at addressing some of the problems with current approaches. In our model, a Bayesian network des</context>
<context position="6670" citStr="Preiss et al., 2007" startWordPosition="994" endWordPosition="997">ct that the lexical item referred to by HEAD (such as a present-tense verb) has the lexical item referred to by DEPENDENT as its subject (such as a singular noun). GR inventories include direct and indirect objects, complements, conjunctions, among other relations. The dependency relationships included in GRs correspond closely to the head-complement structure of SCFs, which is why they are the natural choice for SCF acquisition. There are several SCF lexicons for general language, such as ANLT (Boguraev and Briscoe, 1987) and COMLEX (Grishman et al., 1994), that depend on manual work. VALEX (Preiss et al., 2007) provides SCF distributions for 6,397 verbs acquired from a parsed general language corpus via a system that relies on hand-crafted rules. There are also resources which provide information about both syntactic and semantic properties of verbs: VerbNet (Kipper et al., 2008) draws on several hand-built and semi-automatic sources to link the syntax and semantics of 5,726 verbs. FrameNet (Baker et al., 1998) provides semantic frames and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb is annotated for its arguments and their semantic roles, c</context>
<context position="14172" citStr="Preiss et al., 2007" startWordPosition="2188" endWordPosition="2191">ass tags can be lexicalized, but there are no corresponding feature sets for param (since they are already built from POS tags) or lim (since there is no similar rule-based approach). Name Features pGR -1(PPIS2) 1(NN1) 2(NN2) 3(II) pGRlex -1(PPIS2-we) 1(NN1) 2(NN2) 3(II-in) Table 3: Pseudo-GR features for example sentence with window=3 Whichever feature set is used, an instance is simply the count of each GR’s occurrences. We extract instances for the 385 verbs in the union of our two gold standards from the VALEX lexicon’s data set, which was used in previous studies (Sun and Korhonen, 2009; Preiss et al., 2007) and facilitates comparison with that resource. This data set is drawn from five general-language corpora parsed by Rasp, and provides, on average, 7,000 instances per verb. 3.2 SCF extraction Our graphical modeling approach uses the Bayesian network shown in Figure 1. Its generative story is as follows: when a verb is instantiated, an SCF is chosen according to a verb-specific multinomial. Then, the number and type of syntactic arguments (GRs) are chosen from two SCF-specific multinomials. These three multinomials are modeled with uniform Dirichlet priors and corresponding hyperparameters α, </context>
<context position="19599" citStr="Preiss et al., 2007" startWordPosition="3106" endWordPosition="3109">ional linguistic view of subcategorization, but this requires digging into the unsupervised out424 put and associating anonymous probabilistic objects with established categories. We therefore present sample output in three ways: first, we show the clustering output from our top-performing method. Second, we plot the probability mass over GRs for two anonymous SCFs that correspond to recognizable traditional SCFs, and one that demonstrates unexpected behavior. Third, we compared the output for several verbs to a coarsened version of the manually-annotated gold standard used to evaluate VALEX (Preiss et al., 2007). We collapsed the original inventory of 168 SCFs to 18 purely syntactic SCFs based on their characteristic GRs and removed frames that depend on semantic distinctions, leaving the detection of finer-grained and semanticallybased frames for future work. 4 Results 4.1 Verb clustering We evaluated SCF lexicons based on the eight feature sets described in section 3.1, as well as the VALEX SCF lexicon described in section 2. Table 4 shows the performance of the lexicons in ascending order. Method Pur. F-score Adj. Rand tGR .24 .02 tGRlim .27 .02 pGRlex .32 .09 tGRlim,param .35 .08 pGR .35 .10 VALE</context>
</contexts>
<marker>Preiss, Briscoe, Korhonen, 2007</marker>
<rawString>Judita Preiss, Ted Briscoe, and Anna Korhonen. 2007. A system for large-scale acquisition of verbal, nominal and adjectival subcategorization frames from corpora. In ACL ’07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Roland</author>
<author>Daniel Jurafsky</author>
</authors>
<title>How verb subcategorization frequencies are affected by corpus choice.</title>
<date>1998</date>
<booktitle>In ACL ’98.</booktitle>
<contexts>
<context position="2600" citStr="Roland and Jurafsky, 1998" startWordPosition="375" endWordPosition="378">rlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs. In a few domains like biomedicine, the need for focused SCF lexicons has led to manually-built resources (Bodenreider, 2004). Such resources, however, are costly, prone to human error, and in domains where new lexical and syntactic constructs are frequently coined, quickly become obsolete (Cohen and Hunter, 2006). Datadriven methods for SCF acquisition can alleviate 420 Proceedings of the 50th Annual Meeting of</context>
</contexts>
<marker>Roland, Jurafsky, 1998</marker>
<rawString>Douglas Roland and Daniel Jurafsky. 1998. How verb subcategorization frequencies are affected by corpus choice. In ACL ’98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Rousseeuw</author>
</authors>
<title>Silhouettes: a graphical aid to the interpretation and validation of cluster analysis.</title>
<date>1987</date>
<journal>Journal of Computational and Applied Mathematics.</journal>
<contexts>
<context position="18586" citStr="Rousseeuw, 1987" startWordPosition="2950" endWordPosition="2951">n, 2009), where 200 verbs were assigned to 17 classes based on their alternation patterns (Levin, 1993). Previous work (Schulte im Walde, 2009; Sun and Korhonen, 2009) has demonstrated that the quality of an SCF lexicon’s inventory and probability estimates corresponds to its predictive power for membership in such alternation classes. To compare the performance of our feature sets, we chose the simple and familiar K-Means clustering algorithm (Hartigan and Wong, 1979). The instances are the verbs’ SCF distributions, and we select the number of clusters by the Silhouette validation technique (Rousseeuw, 1987). The clusters are then compared to the gold standard clusters with the purity-based F-Score from Sun and Korhonen (2009) and the more familiar Adjusted Rand Index (Hubert and Arabie, 1985). Our main point of comparison is the VALEX lexicon of SCF distributions, whose scores we report alongside ours. Qualitative: manual gold standard We also want to see how our results line up with a traditional linguistic view of subcategorization, but this requires digging into the unsupervised out424 put and associating anonymous probabilistic objects with established categories. We therefore present sample</context>
</contexts>
<marker>Rousseeuw, 1987</marker>
<rawString>Peter Rousseeuw. 1987. Silhouettes: a graphical aid to the interpretation and validation of cluster analysis. Journal of Computational and Applied Mathematics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C J Rupp</author>
<author>Paul Thompson</author>
<author>William Black</author>
<author>John McNaught</author>
</authors>
<title>A specialised verb lexicon as the basis of fact extraction in the biomedical domain. In Interdisciplinary Workshop on Verbs: The Identi�cation and Representation of Verb Features.</title>
<date>2010</date>
<contexts>
<context position="2144" citStr="Rupp et al., 2010" startWordPosition="310" endWordPosition="313">con would indicate that “persuade” is likely to take a direct object and sentential complement (NP-SCOMP), while “understand” is more likely to take just a direct object (NP). A comprehensive lexicon would also include semantic information about selectional preferences (or restrictions) on argument heads of verbs, diathesis alternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically chang</context>
</contexts>
<marker>Rupp, Thompson, Black, McNaught, 2010</marker>
<rawString>C.J. Rupp, Paul Thompson, William Black, and John McNaught. 2010. A specialised verb lexicon as the basis of fact extraction in the biomedical domain. In Interdisciplinary Workshop on Verbs: The Identi�cation and Representation of Verb Features.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sabine Schulte im Walde</author>
</authors>
<title>The induction of verb frames and verb classes from corpora.</title>
<date>2009</date>
<booktitle>In Corpus Linguistics. An International Handbook. Mouton de Gruyter.</booktitle>
<contexts>
<context position="18112" citStr="Walde, 2009" startWordPosition="2875" endWordPosition="2876">/subcat.tgz Our goal is to define a fair quantitative comparison between arbitrary SCF lexicons. An SCF lexicon makes two claims: first, that it defines a reasonable SCF inventory. Second, that for each verb, it has an accurate distribution over that inventory. We therefore compare the lexicons based on their performance on a task that a good SCF lexicon should be useful for: clustering verbs into lexical-semantic classes. Our gold standard is from (Sun and Korhonen, 2009), where 200 verbs were assigned to 17 classes based on their alternation patterns (Levin, 1993). Previous work (Schulte im Walde, 2009; Sun and Korhonen, 2009) has demonstrated that the quality of an SCF lexicon’s inventory and probability estimates corresponds to its predictive power for membership in such alternation classes. To compare the performance of our feature sets, we chose the simple and familiar K-Means clustering algorithm (Hartigan and Wong, 1979). The instances are the verbs’ SCF distributions, and we select the number of clusters by the Silhouette validation technique (Rousseeuw, 1987). The clusters are then compared to the gold standard clusters with the purity-based F-Score from Sun and Korhonen (2009) and </context>
</contexts>
<marker>Walde, 2009</marker>
<rawString>Sabine Schulte im Walde. 2009. The induction of verb frames and verb classes from corpora. In Corpus Linguistics. An International Handbook. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lin Sun</author>
<author>Anna Korhonen</author>
</authors>
<title>Improving verb clustering with automatically acquired selectional preferences.</title>
<date>2009</date>
<booktitle>In EMNLP’09.</booktitle>
<contexts>
<context position="10484" citStr="Sun and Korhonen (2009)" startWordPosition="1576" endWordPosition="1579">ally annotated data and a predefined SCF inventory and MLE. More recently, Abend and Rappoport (2010) trained ensemble classifiers to perform argumentadjunct disambiguation of PP complements, a task closely related to SCF acquisition. Their study employed unsupervised POS tagging and parsing, and measures of selectional preference and argument structure as complementary features for the classifier. Finally, our task-based evaluation, verb clustering with Levin (1993)’s alternation classes as the gold standard, was previously conducted by Joanis and Stevenson (2003), Korhonen et al. (2008) and Sun and Korhonen (2009). 3 Methodology In this section we describe the basic components of our study: feature sets, graphical model, inference, and evaluation. 3.1 Input and feature sets We tested several feature sets either based on, or approximating, the concept of grammatical relation described in section 2. Our method is agnostic regarding the exact definition of GR, and for example could use the Stanford inventory (De Marneffe et al., 2006) or even an entirely different lexico-syntactic formalism like CCG supertags (Curran et al., 2007). In this paper, we distinguish “true GRs” (tGRs), produced by a parser, and</context>
<context position="14150" citStr="Sun and Korhonen, 2009" startWordPosition="2183" endWordPosition="2187">with tGRs, the closed-class tags can be lexicalized, but there are no corresponding feature sets for param (since they are already built from POS tags) or lim (since there is no similar rule-based approach). Name Features pGR -1(PPIS2) 1(NN1) 2(NN2) 3(II) pGRlex -1(PPIS2-we) 1(NN1) 2(NN2) 3(II-in) Table 3: Pseudo-GR features for example sentence with window=3 Whichever feature set is used, an instance is simply the count of each GR’s occurrences. We extract instances for the 385 verbs in the union of our two gold standards from the VALEX lexicon’s data set, which was used in previous studies (Sun and Korhonen, 2009; Preiss et al., 2007) and facilitates comparison with that resource. This data set is drawn from five general-language corpora parsed by Rasp, and provides, on average, 7,000 instances per verb. 3.2 SCF extraction Our graphical modeling approach uses the Bayesian network shown in Figure 1. Its generative story is as follows: when a verb is instantiated, an SCF is chosen according to a verb-specific multinomial. Then, the number and type of syntactic arguments (GRs) are chosen from two SCF-specific multinomials. These three multinomials are modeled with uniform Dirichlet priors and correspondi</context>
<context position="17978" citStr="Sun and Korhonen, 2009" startWordPosition="2851" endWordPosition="2855">ng a mapping between them is a problem of its own (Meila, 2003). 1Full source code for this work is available at http://cl. cam.ac.uk/˜tl318/files/subcat.tgz Our goal is to define a fair quantitative comparison between arbitrary SCF lexicons. An SCF lexicon makes two claims: first, that it defines a reasonable SCF inventory. Second, that for each verb, it has an accurate distribution over that inventory. We therefore compare the lexicons based on their performance on a task that a good SCF lexicon should be useful for: clustering verbs into lexical-semantic classes. Our gold standard is from (Sun and Korhonen, 2009), where 200 verbs were assigned to 17 classes based on their alternation patterns (Levin, 1993). Previous work (Schulte im Walde, 2009; Sun and Korhonen, 2009) has demonstrated that the quality of an SCF lexicon’s inventory and probability estimates corresponds to its predictive power for membership in such alternation classes. To compare the performance of our feature sets, we chose the simple and familiar K-Means clustering algorithm (Hartigan and Wong, 1979). The instances are the verbs’ SCF distributions, and we select the number of clusters by the Silhouette validation technique (Rousseeu</context>
</contexts>
<marker>Sun, Korhonen, 2009</marker>
<rawString>Lin Sun and Anna Korhonen. 2009. Improving verb clustering with automatically acquired selectional preferences. In EMNLP’09.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mihai Surdeanu</author>
<author>Sanda Harabagiu</author>
<author>John Williams</author>
<author>Paul Aarseth</author>
</authors>
<title>Using predicate-argument structures for information extraction.</title>
<date>2003</date>
<booktitle>In ACL ’03.</booktitle>
<contexts>
<context position="2379" citStr="Surdeanu et al., 2003" startWordPosition="346" endWordPosition="349">ormation about selectional preferences (or restrictions) on argument heads of verbs, diathesis alternations (i.e. semantically-motivated alternations between pairs of SCFs) and a mapping from surface frames to the underlying predicate-argument structure. Information about verb subcategorization is useful for tasks like information extraction (Cohen and Hunter, 2006; Rupp et al., 2010), verb clustering (Korhonen et al., 2006b; Merlo and Stevenson, 2001) and parsing (Carroll et al., 1998). In general, tasks that depend on predicate-argument structure can benefit from a high-quality SCF lexicon (Surdeanu et al., 2003). Large, manually-constructed SCF lexicons mostly target general language (Boguraev and Briscoe, 1987; Grishman et al., 1994). However, in many domains verbs exhibit different syntactic behavior (Roland and Jurafsky, 1998; Lippincott et al., 2010). For example, the verb “develop” has specific usages in newswire, biomedicine and engineering that dramatically change its probability distribution over SCFs. In a few domains like biomedicine, the need for focused SCF lexicons has led to manually-built resources (Bodenreider, 2004). Such resources, however, are costly, prone to human error, and in d</context>
</contexts>
<marker>Surdeanu, Harabagiu, Williams, Aarseth, 2003</marker>
<rawString>Mihai Surdeanu, Sanda Harabagiu, John Williams, and Paul Aarseth. 2003. Using predicate-argument structures for information extraction. In ACL ’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam R Teichert</author>
<author>Hal Daum´e</author>
</authors>
<title>Unsupervised part of speech tagging without a lexicon.</title>
<date>2009</date>
<booktitle>In NIPS Workshop on Grammar Induction, Representation of Language and Language Learning.</booktitle>
<marker>Teichert, Daum´e, 2009</marker>
<rawString>Adam R. Teichert and Hal Daum´e III. 2009. Unsupervised part of speech tagging without a lexicon. In NIPS Workshop on Grammar Induction, Representation of Language and Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Uzun</author>
<author>Y Klaslan</author>
<author>H V Agun</author>
<author>E Uar</author>
</authors>
<title>Web-based acquisition of subcategorization frames for Turkish.</title>
<date>2008</date>
<booktitle>In The Eighth International Conference on Arti�cial Intelligence and Soft Computing.</booktitle>
<contexts>
<context position="7718" citStr="Uzun et al., 2008" startWordPosition="1157" endWordPosition="1160">mes and annotated example sentences for 4,186 verbs. PropBank (Palmer et al., 2005) is a corpus where each verb is annotated for its arguments and their semantic roles, covering a total of 4,592 verbs. There are many language-specific SCF acquisition systems, e.g. for French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Han et al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either directly through heuristics, or indirectly through parsing models trained on treebanks. Furthermore, some require labeled training instances for supervised (Uzun et al., 2008) or semi-supervised (Han et al., 2008) learning algorithms. Two state-of-the-art data-driven systems for English verbs are those that produced VALEX, Preiss et al. (2007), and the BioLexicon (Venturi et al., 2009). 421 The Preiss system extracts a verb instance’s GRs using the Rasp general-language unlexicalized parser (Briscoe et al., 2006) as input, and based on handcrafted rules, maps verb instances to a predefined inventory of 168 SCFs. Filtering is then performed to remove noisy frames, with methods ranging from a simple single threshold to SCF-specific hypothesis tests based on external </context>
</contexts>
<marker>Uzun, Klaslan, Agun, Uar, 2008</marker>
<rawString>E. Uzun, Y. Klaslan, H.V. Agun, and E. Uar. 2008. Web-based acquisition of subcategorization frames for Turkish. In The Eighth International Conference on Arti�cial Intelligence and Soft Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Giulia Venturi</author>
<author>Simonetta Montemagni</author>
<author>Simone Marchi</author>
<author>Yutaka Sasaki</author>
<author>Paul Thompson</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
</authors>
<title>Bootstrapping a verb lexicon for biomedical information extraction.</title>
<date>2009</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing.</booktitle>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg.</location>
<contexts>
<context position="7931" citStr="Venturi et al., 2009" startWordPosition="1189" endWordPosition="1192">e many language-specific SCF acquisition systems, e.g. for French (Messiant, 2008), Italian (Lenci et al., 2008), Turkish (Han et al., 2008) and Chinese (Han et al., 2008). These typically rely on language-specific knowledge, either directly through heuristics, or indirectly through parsing models trained on treebanks. Furthermore, some require labeled training instances for supervised (Uzun et al., 2008) or semi-supervised (Han et al., 2008) learning algorithms. Two state-of-the-art data-driven systems for English verbs are those that produced VALEX, Preiss et al. (2007), and the BioLexicon (Venturi et al., 2009). 421 The Preiss system extracts a verb instance’s GRs using the Rasp general-language unlexicalized parser (Briscoe et al., 2006) as input, and based on handcrafted rules, maps verb instances to a predefined inventory of 168 SCFs. Filtering is then performed to remove noisy frames, with methods ranging from a simple single threshold to SCF-specific hypothesis tests based on external verb classes and SCF inventories. The BioLexicon system extracts each verb instance’s GRs using the lexicalized Enju parser tuned to the biomedical domain (Miyao, 2005). Each unique GR-set considered a potential S</context>
</contexts>
<marker>Venturi, Montemagni, Marchi, Sasaki, Thompson, McNaught, Ananiadou, 2009</marker>
<rawString>Giulia Venturi, Simonetta Montemagni, Simone Marchi, Yutaka Sasaki, Paul Thompson, John McNaught, and Sophia Ananiadou. 2009. Bootstrapping a verb lexicon for biomedical information extraction. In Computational Linguistics and Intelligent Text Processing. Springer Berlin / Heidelberg.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>