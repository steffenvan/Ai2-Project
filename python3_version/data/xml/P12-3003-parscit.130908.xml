<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000481">
<title confidence="0.969655">
QuickView: NLP-based Tweet Search
</title>
<author confidence="0.997384">
Xiaohua Liu t †, Furu Wei †, Ming Zhou †, Microsoft QuickView Team †
</author>
<affiliation confidence="0.994218666666667">
tSchool of Computer Science and Technology
Harbin Institute of Technology, Harbin, 150001, China
†Microsoft Research Asia
</affiliation>
<address confidence="0.496286">
Beijing, 100190, China
</address>
<email confidence="0.989765">
†{xiaoliu, fuwei, mingzhou,qv}@microsoft.com
</email>
<sectionHeader confidence="0.995635" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999670952380952">
Tweets have become a comprehensive repos-
itory for real-time information. However, it
is often hard for users to quickly get informa-
tion they are interested in from tweets, ow-
ing to the sheer volume of tweets as well as
their noisy and informal nature. We present
QuickView, an NLP-based tweet search plat-
form to tackle this issue. Specifically, it ex-
ploits a series of natural language process-
ing technologies, such as tweet normalization,
named entity recognition, semantic role label-
ing, sentiment analysis, tweet classification, to
extract useful information, i.e., named entities,
events, opinions, etc., from a large volume
of tweets. Then, non-noisy tweets, together
with the mined information, are indexed, on
top of which two brand new scenarios are en-
abled, i.e., categorized browsing and advanced
search, allowing users to effectively access
either the tweets or fine-grained information
they are interested in.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999942888888889">
Tweets represent a comprehensive fresh informa-
tion repository. However, users often have diffi-
culty finding information they are interested in from
tweets, because of the huge number of tweets as well
as their noisy and informal nature. Tweet search,
e.g., Twitter 1, is a kind of service aiming to tackle
this issue. Nevertheless, existing tweet search ser-
vices provide limited functionality. For example, in
Twitter, only a simple keyword-based search is sup-
</bodyText>
<footnote confidence="0.299699">
lhttp://twitter.com/
</footnote>
<page confidence="0.990923">
13
</page>
<bodyText confidence="0.999852176470588">
ported, and the returned list often contains meaning-
less results.
This demonstration introduces QuickView, which
employs a series of NLP technologies to extract
useful information from a large volume of tweets.
Specifically, for each tweet, it first conducts nor-
malization, followed by named entity recognition
(NER). Then it conducts semantic role labeling
(SRL) to get predicate-argument structures, which
are further converted into events, i.e., triples of who
did what. After that, it performs sentiment analysis
(SA), i.e., extracting positive or negative comments
about something/somebody. Next, tweets are clas-
sified into predefined categories. Finally, non-noisy
tweets together with the mined information are in-
dexed.
On top of the index, QuickView enables two brand
new scenarios, allowing users to effectively access
the tweets or fine-grained information mined from
tweets.
Categorized Browsing. As illustrated in Figure
1(a), QuickView shows recent popular tweets, enti-
ties, events, opinions and so on, which are organized
by categories. It also extracts and classifies URL
links in tweets and allows users to check out popular
links in a categorized way.
Advanced Search. As shown in Figure 1(b), Quick-
View provides four advanced search functions: 1)
search results are clustered so that tweets about the
same/similar topic are grouped together, and for
each cluster only the informative tweets are kept;
2) when the query refers to a person or a company,
two bars are presented followed by the words that
strongly suggest opinion polarity. The bar’s width
</bodyText>
<note confidence="0.469915">
Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 13–18,
Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.989585630769231">
is proportional to the number of associated opin-
ions; 3) similarly, the top six most frequent words
that most clearly express event occurrences are pre-
sented; 4) users can search tweets with opinions
or events, e.g., search tweets containing any posi-
tive/negative opinion about “Obama” or any event
involving “Obama”.
The implementation of Quickliew requires adapt-
ing existing NLP components trained on formal
texts, which often performs poorly on tweets. For
example, the average F1 of the Stanford NER
(Finkel et al., 2005) drops from 90.8% (Ratinov
and Roth, 2009) to 45.8% on tweets, while Liu et
al. (2010) report that the F1 score of a state-of-
the-art SRL system (Meza-Ruiz and Riedel, 2009)
falls to 42.5% on tweets as apposed to 75.5% on
news. However, the adaptation of those components
is challenging, owing to the lack of annotated tweets
and the inadequate signals provided by a noisy and
short tweet. Our general strategy is to leverage ex-
isting resources as well as unsupervised or semi-
supervised learning methods to reduce the labeling
efforts, and to aggregate as much evidence as pos-
sible from a broader context to compensate for the
lack of information in a tweet.
This strategy is embodied by various components
we have developed. For example, our NER com-
ponent combines a k-nearest neighbors (KNN) clas-
sifier, which collects global information across re-
cently labeled tweets with a Conditional Random
Fields (CRF) labeler, which exploits information
from a single tweet and the gazetteers. Both the
KNN classifier and the CRF labeler are repeatedly
retrained using the results that they have confidently
labeled. The SRL component caches and clusters
recent labeled tweets, and aggregates information
from the cluster containing the tweet. Similarly, the
classifier considers not only the current tweet but
also its neighbors in a tweet graph, where two tweets
are connected if they are similar in content or have a
tweet/retweet relationship.
Quickliew has been internally deployed, and re-
ceived extremely positive feedback. Experimental
results on a human annotated dataset also indicate
the effectiveness of our adaptation strategy.
Our contributions are summarized as follows.
1. We demonstrate Quickliew, an NLP-based
tweet search. Different from existing methods,
it exploits a series of NLP technologies to ex-
tract useful information from a large volume
of tweets, and enables categorized browsing
and advanced search scenarios, allowing users
to efficiently access information they are inter-
ested in from tweets.
2. We present core components of Quickliew, fo-
cusing on how to leverage existing resources
and technologies as well as how to make up
for the limited information in a short and often
noisy tweet by aggregating information from a
broader context.
The rest of this paper is organized as follows. In
the next section, we introduce related work. In Sec-
tion 3, we describe our system. In Section 4, we
evaluate our system. Finally, Section 5 concludes
and presents future work.
</bodyText>
<sectionHeader confidence="0.999287" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999486666666667">
Information Extraction Systems. Essentially,
Quickliew is an information extraction (IE) system.
However, unlike existing IE systems, such as Evita
(Saur´ı et al., 2005), a robust event recognizer for QA
system, and SRES (Rozenfeld and Feldman, 2008),
a self-supervised relation extractor for the web, it
targets tweets, a new genre of text, which are short
and informal, and its focus is on adapting existing IE
components to tweets.
Tweet Search Services. A couple of tweet search
services exist, including Twitter, Bing social search
2 and Google social search 3. Most of them provide
only keyword-based search interfaces, i.e., return-
ing a list of tweets related to a given word/phrase.
In contrast, our system extracts fine-grained in-
formation from tweets and allows a new end-to-
end search experience beyond keyword search, such
as clustering of search results, and search with
events/opinions.
NLP Components. The NLP technologies adopted
in our system , e.g., NER, SRL and classification,
have been extensively studied on formal text but
rarely on tweets. At the heart of our system is
the re-use of existing resources, methodologies as
</bodyText>
<footnote confidence="0.99989">
2http://www.bing.com/social
3http://www.google.com/realtime
</footnote>
<page confidence="0.994799">
14
</page>
<figure confidence="0.92236">
(a) A screenshot of the categorized browsing scenario.
(b) A screenshot of the advanced search scenario.
</figure>
<figureCaption confidence="0.999944">
Figure 1: Two scenarios of QuickView.
</figureCaption>
<bodyText confidence="0.999801666666666">
well as components, and the the adaptation of them
to tweets. The adaptation process, though varying
across components, consists of three common steps:
1) annotating tweets; 2) defining the decision con-
text that usually involves more than one tweet, such
as a cluster of similar tweets; and 3) re-training mod-
els (often incrementally) with both conventional fea-
tures and features derived from the context defined
in step 2.
</bodyText>
<sectionHeader confidence="0.996908" genericHeader="method">
3 System Description
</sectionHeader>
<bodyText confidence="0.9998465">
We first give an overview of our system, then present
more details about NER and SRL, as two represen-
tative core components, to illustrate the adaptation
process.
</bodyText>
<subsectionHeader confidence="0.9761">
3.1 Overview
</subsectionHeader>
<bodyText confidence="0.999984">
Architecture. QuickView can be divided into four
parts, as illustrated in Figure 2. The first part in-
cludes a crawler and a buffer of raw tweets. The
crawler repeatedly downloads tweets using the Twit-
ter APIs, and then pre-filters noisy tweets using
some heuristic rules, e.g., removing a tweet if it is
too short, say, less than 3 words, or if it contains
any predefined banned word. At the moment, we
focus on English tweets, so non-English tweets are
filtered as well. Finally, the un-filtered are put into
the buffer.
The second part consists of several tweet extrac-
tion pipelines. Each pipeline has the same configura-
tion, constantly fetching a tweet from the raw tweet
buffer, and conducting the following processes se-
</bodyText>
<page confidence="0.986256">
15
</page>
<figureCaption confidence="0.999707">
Figure 2: System architecture of QuickView.
</figureCaption>
<bodyText confidence="0.999031142857143">
quentially: 1) normalization; 2) parsing including
part-of-speech (POS), chunking, and dependency
parsing; 3) NER; 4) SRL; 5) SA and 6) classifica-
tion. The normalization model identifies and cor-
rects ill-formed words. For example, after normal-
ization, “loooove” in “· · · I loooove my icon· · · ”
will be transformed to “love”. A phrase-based trans-
lation system without re-ordering is used to imple-
ment this model. The translation table includes man-
ually compiled ill/good form pairs, and the language
model is a trigram trained on LDC data 4 using
SRILM (Stolcke, 2002). The OpenNLP 5 toolkit
is directly used to implement the parsing model.
In future, the parsing model will be re-trained us-
ing annotated tweets. The SA component is imple-
mented according to Jiang et al. (2011), which incor-
porates target-dependent features and considers re-
lated tweets by utilizing a graph-based optimization.
The classification model is a KNN-based classifier
that caches confidently labeled results to re-train it-
self, which also recognizes and drops noisy tweets.
</bodyText>
<footnote confidence="0.837366666666667">
4http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp ?cata-
logId=LDC2005T12
shttp://sourceforge.net/projects/opennlp/
</footnote>
<bodyText confidence="0.999601486486486">
Each processed tweet, if not identified as noise, is
put into a shared buffer for indexing.
The third part is responsible for indexing and
querying. It constantly takes from the indexing
buffer a processed tweet, which is then indexed with
various entries including words, phrases, metadata
(e.g., source, publish time, and account), named en-
tities, events, and opinions. On top of this, it answers
any search request, and returns a list of matched re-
sults, each of which contains both the original tweet
and the extracted information from that tweet. We
implement an indexing/querying engine similar to
Lucene 6 in C#. This part also maintains a cache of
recent processed tweets, from which the following
information is extracted and indexed: 1) top tweets;
2) top entities/events/opinions in tweets; and 3)
top accounts. Whether a tweet/entity/event/opinion
ranks top depends on their re-tweeted/mentioned
times as well as its publisher, while whether an ac-
count is top relies on the number of his/her followers
and tweets.
The fourth part is a web application that returns
related information to end users according to their
browsing or search request. The implementation of
the web application is organized with the model-
view-control pattern so that other kinds of user in-
terfaces, e.g., a mobile application, can be easily im-
plemented.
Deployment. Quick&lt;iew is deployed into 5 work-
stations 7 including 2 processing pipelines, as illus-
trated in Table 1. The communication between com-
ponents is through TCP/IP. On average, it takes 0.01
seconds to process each tweet, and in total about
10 million tweets are indexed every day. Note that
Quick&lt;iew’s processing capability can be enhanced
in a straightforward manner by deploying additional
pipelines.
</bodyText>
<subsectionHeader confidence="0.999575">
3.2 Core Components
</subsectionHeader>
<bodyText confidence="0.999886666666667">
Because of limited space, we only discuss two core
components of Quick&lt;iew: NER and SRL.
NER. NER is the task of identifying mentions of
rigid designators from text belonging to named-
entity types such as persons, organizations and loca-
tions. Existing solutions fall into three categories: 1)
</bodyText>
<footnote confidence="0.920542">
6http://lucene.apache.org/java/docs/index.html
7Intel® Xeon® 2.33 CPU 5140 @2.33GHz, 4G of RAM,
OS of Windows Server 2003 Enterprise X64 version
</footnote>
<page confidence="0.999147">
16
</page>
<tableCaption confidence="0.999942">
Table 1: Current deployment of QuickView.
</tableCaption>
<figure confidence="0.6611862">
Workstation Hosted components
#1 Crawler,Raw tweet buffer
#2,3 Process pipeline
#4 Indexing Buffer, Indexer/Querier
#5 Web application
</figure>
<bodyText confidence="0.998768692307692">
the rule-based (Krupka and Hausman, 1998); 2) the
machine learning based (Finkel and Manning, 2009;
Singh et al., 2010); and 3) hybrid methods (Jansche
and Abney, 2002). With the availability of annotated
corpora, such as ACE05, Enron and CoNLL03, the
data-driven methods become the dominating meth-
ods. However, because of domain mismatch, cur-
rent systems trained on non-tweets perform poorly
on tweets.
Our NER system takes three steps to address
this problem. Firstly, it defines those recently la-
beled tweets that are similar to the current tweet
as its recognition context, under which a KNN-
based classifier is used to conduct word level clas-
sification. Following the two-stage prediction ag-
gregation methods (Krishnan and Manning, 2006),
such pre-labeled results, together with other con-
ventional features used by the state-of-the-art NER
systems, are fed into a linear CRF models, which
conducts fine-grained tweet level NER. Secondly,
the KNN and CRF model are repeatedly retrained
with an incrementally augmented training set, into
which highly confidently labeled tweets are added.
Finally, following Lev Ratinov and Dan Roth
(2009), 30 gazetteers are used, which cover common
names, countries, locations, temporal expressions,
etc. These gazetteers represent general knowledge
across domains, and help to make up for the lack of
training data.
SRL. Given a sentence, the SRL component identi-
fies every predicate, and for each predicate further
identifies its arguments. This task has been exten-
sively studied on well-written corpora like news, and
a couple of solutions exist. Examples include: 1)
the pipelined approach, i.e., dividing the task into
several successive components such as argument
identification, argument classification, global infer-
ence, etc., and conquering them individually (Xue,
2004; Koomen et al., 2005); 2) sequentially labeling
based approach (M`arquez et al., 2005), i.e., label-
ing the words according to their positions relative
to an argument (i.e., inside, outside, or at the be-
ginning); and 3) Markov Logic Networks (MLN)
based approach (Meza-Ruiz and Riedel, 2009),
i.e., simultaneously resolving all the sub-tasks using
learnt weighted formulas. Unsurprisingly, the per-
formance of the state-of-the-art SRL system (Meza-
Ruiz and Riedel, 2009) drops sharply when applied
to tweets.
The SRL component of Quickliew is based on
CRF, and uses the recently labeled tweets that are
similar to the current tweet as the broader context.
Algorithm 1 outlines its implementation, where:
train denotes a machine learning process to get a
labeler l, which in our work is a linear CRF model;
the cluster function puts the new tweet into a clus-
ter; the label function generates predicate-argument
structures for the input tweet with the help of the
trained model and the cluster; p, s and cf denote a
predicate, a set of argument and role pairs related to
the predicate and the predicted confidence, respec-
tively. To prepare the initial clusters required by the
SRL component as its input, we adopt the predicate-
argument mapping method (Liu et al., 2010) to
get some automatically labeled tweets, which (plus
the manually labeled tweets) are then organized into
groups using a bottom-up clustering procedure.
It is worth noting that: 1) our SRL component
uses the general role schema defined by PropBank,
which includes core roles such as A0, A1 (usually
indicating the agent and patient of the predicate, re-
spectively), and auxiliary roles such as AM-TMP
and AM-LOC (representing the temporal and loca-
tion information of the predicate, respectively); 2)
only verbal predicates are considered, which is con-
sistent with most existing SRL systems; and 3) fol-
lowing M`arquez et al. (2005), it conducts word level
labeling.
</bodyText>
<sectionHeader confidence="0.999621" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.985549333333333">
Overall Performance. We provide a textbox in the
home page of Quickliew to collect feedback. We
have got 165 feedbacks, of which 85.5% are posi-
tive. The main complaint is related to the quality of
the extracted information.
Core Components. We manually labeled the POS,
</bodyText>
<page confidence="0.994706">
17
</page>
<reference confidence="0.395877181818182">
Algorithm 1 SRL of QuickView.
Require: Tweet stream i;clusters cl;output stream o.
1: Initialize l, the CRF labeler: l = train(cl).
2: while Pop a tweet t from i and t ≠ null do
3: Put t to a cluster c: c = cluster(cl, t).
4: Label t with l:(t, {(p, s, cf)}) = label(l, c, t).
5: Update cluster c with labeled results
(t, {(p, s, cf)}).
6: Output labeled results (t, {(p, s, cf)}) to o.
7: end while
8: return o.
</reference>
<bodyText confidence="0.999407846153846">
NER, SRL and SA information for about 10,000
tweets, based on which the NER and SRL com-
ponents are evaluated. Experimental results show
that: 1) our NER component achieves an average
F1 of 80.2%, as opposed to 75.4% of the baseline,
which is a CRF-based system similar to Ratinov and
Roth’s (2009) but re-trained on annotated tweets;
and 2) our SRL component gets an F1 of 59.7%, out-
performing both the state-of-the-art system (Meza-
Ruiz and Riedel, 2009) (42.5%) and the system of
Liu et al. (2010) (42.3%), which is trained on au-
tomatically annotated news tweets (tweets reporting
news).
</bodyText>
<sectionHeader confidence="0.998177" genericHeader="conclusions">
5 Conclusions and Future work
</sectionHeader>
<bodyText confidence="0.9999725">
We have described the motivation, scenarios, archi-
tecture, deployment and implementation of Quick-
View, an NLP-based tweet search. At the heart of
QuickView is the adaptation of existing NLP tech-
nologies, e.g., NER, SRL and SA, to tweets, a new
genre of text, which are short and informal. We
have illustrated our strategy to tackle this challeng-
ing task, i.e., leveraging existing resources and ag-
gregating as much information as possible from a
broader context, using NER and SRL as case stud-
ies. Preliminary positive feedback suggests the use-
fulness of QuickView and its advantages over exist-
ing tweet search services. Experimental results on
a human annotated dataset indicate the effectiveness
of our adaptation strategy.
We are improving the quality of the core compo-
nents of QuickView by labeling more tweets and ex-
ploring alternative models. We are also customizing
QuickView for non-English tweets. As it progresses,
we will release QuickView to the public.
</bodyText>
<sectionHeader confidence="0.996382" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999789666666667">
Jenny Rose Finkel and Christopher D. Manning. 2009.
Nested named entity recognition. In EMNLP, pages
141–150.
Jenny Rose Finkel, Trond Grenager, and Christopher
Manning. 2005. Incorporating non-local information
into information extraction systems by gibbs sampling.
In ACL, pages 363–370.
Martin Jansche and Steven P. Abney. 2002. Informa-
tion extraction from voicemail transcripts. In EMNLP,
pages 320–327.
Long Jiang, Mo Yu, Ming Zhou, and Xiaohua Liu. 2011.
Target-dependent twitter sentiment classification. In
ACL.
Peter Koomen, Vasin Punyakanok, Dan Roth, and Wen-
tau Yih. 2005. Generalized inference with multi-
ple semantic role labeling systems. In CONLL, pages
181–184.
Vijay Krishnan and Christopher D. Manning. 2006. An
effective two-stage model for exploiting non-local de-
pendencies in named entity recognition. In ACL, pages
1121–1128.
George R. Krupka and Kevin Hausman. 1998. Isoquest:
Description of the netowlTM extractor system as used
in muc-7. In MUC-7.
Xiaohua Liu, Kuan Li, Bo Han, Ming Zhou, Long Jiang,
Zhongyang Xiong, and Changning Huang. 2010. Se-
mantic role labeling for news tweets. In Coling, pages
698–706.
Llu´ıs M`arquez, Pere Comas, Jes´us Gim´enez, and Neus
Catal`a. 2005. Semantic role labeling as sequential
tagging. In CONLL, pages 193–196.
Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly
identifying predicates, arguments and senses using
markov logic. In NAACL, pages 155–163.
Lev Ratinov and Dan Roth. 2009. Design challenges
and misconceptions in named entity recognition. In
CoNLL, pages 147–155.
Benjamin Rozenfeld and Ronen Feldman. 2008. Self-
supervised relation extraction from the web. Knowl.
Inf. Syst., 17:17–33, October.
Roser Saur´ı, Robert Knippen, Marc Verhagen, and James
Pustejovsky. 2005. Evita: A robust event recognizer
for qa systems. In EMNLP, pages 700–707.
Sameer Singh, Dustin Hillard, and Chris Leggetter. 2010.
Minimally-supervised extraction of entities from text
advertisements. In HLT-NAACL, pages 73–81.
Andreas Stolcke. 2002. SRILM – an extensible language
modeling toolkit. In ICSLP, volume 2, pages 901–904.
Nianwen Xue. 2004. Calibrating features for seman-
tic role labeling. In In Proceedings of EMNLP 2004,
pages 88–94.
</reference>
<page confidence="0.999291">
18
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.902567">
<title confidence="0.997946">QuickView: NLP-based Tweet Search</title>
<author confidence="0.989583">Liu Furu Wei Ming Zhou Microsoft QuickView Team</author>
<affiliation confidence="0.976689">of Computer Science and Harbin Institute of Technology, Harbin, 150001, Research</affiliation>
<address confidence="0.99577">Beijing, 100190,</address>
<email confidence="0.991588">fuwei,</email>
<abstract confidence="0.999154227272727">Tweets have become a comprehensive repository for real-time information. However, it is often hard for users to quickly get information they are interested in from tweets, owing to the sheer volume of tweets as well as their noisy and informal nature. We present an NLP-based tweet search platform to tackle this issue. Specifically, it exploits a series of natural language processing technologies, such as tweet normalization, named entity recognition, semantic role labeling, sentiment analysis, tweet classification, to extract useful information, i.e., named entities, events, opinions, etc., from a large volume of tweets. Then, non-noisy tweets, together with the mined information, are indexed, on top of which two brand new scenarios are enabled, i.e., categorized browsing and advanced search, allowing users to effectively access either the tweets or fine-grained information they are interested in.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<journal>Algorithm</journal>
<volume>1</volume>
<marker></marker>
<rawString>Algorithm 1 SRL of QuickView.</rawString>
</citation>
<citation valid="false">
<title>Require: Tweet stream i;clusters cl;output stream o. 1: Initialize l, the CRF labeler: l = train(cl). 2: while Pop a tweet t from i and t ≠ null do 3: Put t to a cluster c: c = cluster(cl, t). 4: Label t with l:(t, {(p, s, cf)}) = label(l,</title>
<note>c, t).</note>
<marker></marker>
<rawString>Require: Tweet stream i;clusters cl;output stream o. 1: Initialize l, the CRF labeler: l = train(cl). 2: while Pop a tweet t from i and t ≠ null do 3: Put t to a cluster c: c = cluster(cl, t). 4: Label t with l:(t, {(p, s, cf)}) = label(l, c, t).</rawString>
</citation>
<citation valid="false">
<title>5: Update cluster c with labeled results (t, {(p, s, cf)}). 6: Output labeled results (t, {(p, s, cf)}) to o. 7: end while 8: return o.</title>
<marker></marker>
<rawString>5: Update cluster c with labeled results (t, {(p, s, cf)}). 6: Output labeled results (t, {(p, s, cf)}) to o. 7: end while 8: return o.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Nested named entity recognition.</title>
<date>2009</date>
<booktitle>In EMNLP,</booktitle>
<pages>141--150</pages>
<contexts>
<context position="12914" citStr="Finkel and Manning, 2009" startWordPosition="1992" endWordPosition="1995">R. NER is the task of identifying mentions of rigid designators from text belonging to namedentity types such as persons, organizations and locations. Existing solutions fall into three categories: 1) 6http://lucene.apache.org/java/docs/index.html 7Intel® Xeon® 2.33 CPU 5140 @2.33GHz, 4G of RAM, OS of Windows Server 2003 Enterprise X64 version 16 Table 1: Current deployment of QuickView. Workstation Hosted components #1 Crawler,Raw tweet buffer #2,3 Process pipeline #4 Indexing Buffer, Indexer/Querier #5 Web application the rule-based (Krupka and Hausman, 1998); 2) the machine learning based (Finkel and Manning, 2009; Singh et al., 2010); and 3) hybrid methods (Jansche and Abney, 2002). With the availability of annotated corpora, such as ACE05, Enron and CoNLL03, the data-driven methods become the dominating methods. However, because of domain mismatch, current systems trained on non-tweets perform poorly on tweets. Our NER system takes three steps to address this problem. Firstly, it defines those recently labeled tweets that are similar to the current tweet as its recognition context, under which a KNNbased classifier is used to conduct word level classification. Following the two-stage prediction aggre</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2009. Nested named entity recognition. In EMNLP, pages 141–150.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Trond Grenager</author>
<author>Christopher Manning</author>
</authors>
<title>Incorporating non-local information into information extraction systems by gibbs sampling.</title>
<date>2005</date>
<booktitle>In ACL,</booktitle>
<pages>363--370</pages>
<contexts>
<context position="4011" citStr="Finkel et al., 2005" startWordPosition="602" endWordPosition="605">–18, Jeju, Republic of Korea, 8-14 July 2012. c�2012 Association for Computational Linguistics is proportional to the number of associated opinions; 3) similarly, the top six most frequent words that most clearly express event occurrences are presented; 4) users can search tweets with opinions or events, e.g., search tweets containing any positive/negative opinion about “Obama” or any event involving “Obama”. The implementation of Quickliew requires adapting existing NLP components trained on formal texts, which often performs poorly on tweets. For example, the average F1 of the Stanford NER (Finkel et al., 2005) drops from 90.8% (Ratinov and Roth, 2009) to 45.8% on tweets, while Liu et al. (2010) report that the F1 score of a state-ofthe-art SRL system (Meza-Ruiz and Riedel, 2009) falls to 42.5% on tweets as apposed to 75.5% on news. However, the adaptation of those components is challenging, owing to the lack of annotated tweets and the inadequate signals provided by a noisy and short tweet. Our general strategy is to leverage existing resources as well as unsupervised or semisupervised learning methods to reduce the labeling efforts, and to aggregate as much evidence as possible from a broader cont</context>
</contexts>
<marker>Finkel, Grenager, Manning, 2005</marker>
<rawString>Jenny Rose Finkel, Trond Grenager, and Christopher Manning. 2005. Incorporating non-local information into information extraction systems by gibbs sampling. In ACL, pages 363–370.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Jansche</author>
<author>Steven P Abney</author>
</authors>
<title>Information extraction from voicemail transcripts.</title>
<date>2002</date>
<booktitle>In EMNLP,</booktitle>
<pages>320--327</pages>
<contexts>
<context position="12984" citStr="Jansche and Abney, 2002" startWordPosition="2004" endWordPosition="2007">ext belonging to namedentity types such as persons, organizations and locations. Existing solutions fall into three categories: 1) 6http://lucene.apache.org/java/docs/index.html 7Intel® Xeon® 2.33 CPU 5140 @2.33GHz, 4G of RAM, OS of Windows Server 2003 Enterprise X64 version 16 Table 1: Current deployment of QuickView. Workstation Hosted components #1 Crawler,Raw tweet buffer #2,3 Process pipeline #4 Indexing Buffer, Indexer/Querier #5 Web application the rule-based (Krupka and Hausman, 1998); 2) the machine learning based (Finkel and Manning, 2009; Singh et al., 2010); and 3) hybrid methods (Jansche and Abney, 2002). With the availability of annotated corpora, such as ACE05, Enron and CoNLL03, the data-driven methods become the dominating methods. However, because of domain mismatch, current systems trained on non-tweets perform poorly on tweets. Our NER system takes three steps to address this problem. Firstly, it defines those recently labeled tweets that are similar to the current tweet as its recognition context, under which a KNNbased classifier is used to conduct word level classification. Following the two-stage prediction aggregation methods (Krishnan and Manning, 2006), such pre-labeled results,</context>
</contexts>
<marker>Jansche, Abney, 2002</marker>
<rawString>Martin Jansche and Steven P. Abney. 2002. Information extraction from voicemail transcripts. In EMNLP, pages 320–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Long Jiang</author>
<author>Mo Yu</author>
<author>Ming Zhou</author>
<author>Xiaohua Liu</author>
</authors>
<title>Target-dependent twitter sentiment classification.</title>
<date>2011</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="10036" citStr="Jiang et al. (2011)" startWordPosition="1565" endWordPosition="1568">alization model identifies and corrects ill-formed words. For example, after normalization, “loooove” in “· · · I loooove my icon· · · ” will be transformed to “love”. A phrase-based translation system without re-ordering is used to implement this model. The translation table includes manually compiled ill/good form pairs, and the language model is a trigram trained on LDC data 4 using SRILM (Stolcke, 2002). The OpenNLP 5 toolkit is directly used to implement the parsing model. In future, the parsing model will be re-trained using annotated tweets. The SA component is implemented according to Jiang et al. (2011), which incorporates target-dependent features and considers related tweets by utilizing a graph-based optimization. The classification model is a KNN-based classifier that caches confidently labeled results to re-train itself, which also recognizes and drops noisy tweets. 4http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp ?catalogId=LDC2005T12 shttp://sourceforge.net/projects/opennlp/ Each processed tweet, if not identified as noise, is put into a shared buffer for indexing. The third part is responsible for indexing and querying. It constantly takes from the indexing buffer a processed tweet</context>
</contexts>
<marker>Jiang, Yu, Zhou, Liu, 2011</marker>
<rawString>Long Jiang, Mo Yu, Ming Zhou, and Xiaohua Liu. 2011. Target-dependent twitter sentiment classification. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Koomen</author>
<author>Vasin Punyakanok</author>
<author>Dan Roth</author>
<author>Wentau Yih</author>
</authors>
<title>Generalized inference with multiple semantic role labeling systems.</title>
<date>2005</date>
<booktitle>In CONLL,</booktitle>
<pages>181--184</pages>
<contexts>
<context position="14654" citStr="Koomen et al., 2005" startWordPosition="2254" endWordPosition="2257">poral expressions, etc. These gazetteers represent general knowledge across domains, and help to make up for the lack of training data. SRL. Given a sentence, the SRL component identifies every predicate, and for each predicate further identifies its arguments. This task has been extensively studied on well-written corpora like news, and a couple of solutions exist. Examples include: 1) the pipelined approach, i.e., dividing the task into several successive components such as argument identification, argument classification, global inference, etc., and conquering them individually (Xue, 2004; Koomen et al., 2005); 2) sequentially labeling based approach (M`arquez et al., 2005), i.e., labeling the words according to their positions relative to an argument (i.e., inside, outside, or at the beginning); and 3) Markov Logic Networks (MLN) based approach (Meza-Ruiz and Riedel, 2009), i.e., simultaneously resolving all the sub-tasks using learnt weighted formulas. Unsurprisingly, the performance of the state-of-the-art SRL system (MezaRuiz and Riedel, 2009) drops sharply when applied to tweets. The SRL component of Quickliew is based on CRF, and uses the recently labeled tweets that are similar to the curren</context>
</contexts>
<marker>Koomen, Punyakanok, Roth, Yih, 2005</marker>
<rawString>Peter Koomen, Vasin Punyakanok, Dan Roth, and Wentau Yih. 2005. Generalized inference with multiple semantic role labeling systems. In CONLL, pages 181–184.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vijay Krishnan</author>
<author>Christopher D Manning</author>
</authors>
<title>An effective two-stage model for exploiting non-local dependencies in named entity recognition.</title>
<date>2006</date>
<booktitle>In ACL,</booktitle>
<pages>1121--1128</pages>
<contexts>
<context position="13557" citStr="Krishnan and Manning, 2006" startWordPosition="2093" endWordPosition="2096">2010); and 3) hybrid methods (Jansche and Abney, 2002). With the availability of annotated corpora, such as ACE05, Enron and CoNLL03, the data-driven methods become the dominating methods. However, because of domain mismatch, current systems trained on non-tweets perform poorly on tweets. Our NER system takes three steps to address this problem. Firstly, it defines those recently labeled tweets that are similar to the current tweet as its recognition context, under which a KNNbased classifier is used to conduct word level classification. Following the two-stage prediction aggregation methods (Krishnan and Manning, 2006), such pre-labeled results, together with other conventional features used by the state-of-the-art NER systems, are fed into a linear CRF models, which conducts fine-grained tweet level NER. Secondly, the KNN and CRF model are repeatedly retrained with an incrementally augmented training set, into which highly confidently labeled tweets are added. Finally, following Lev Ratinov and Dan Roth (2009), 30 gazetteers are used, which cover common names, countries, locations, temporal expressions, etc. These gazetteers represent general knowledge across domains, and help to make up for the lack of tr</context>
</contexts>
<marker>Krishnan, Manning, 2006</marker>
<rawString>Vijay Krishnan and Christopher D. Manning. 2006. An effective two-stage model for exploiting non-local dependencies in named entity recognition. In ACL, pages 1121–1128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George R Krupka</author>
<author>Kevin Hausman</author>
</authors>
<title>Isoquest: Description of the netowlTM extractor system as used in muc-7.</title>
<date>1998</date>
<booktitle>In MUC-7.</booktitle>
<contexts>
<context position="12857" citStr="Krupka and Hausman, 1998" startWordPosition="1983" endWordPosition="1986"> discuss two core components of Quick&lt;iew: NER and SRL. NER. NER is the task of identifying mentions of rigid designators from text belonging to namedentity types such as persons, organizations and locations. Existing solutions fall into three categories: 1) 6http://lucene.apache.org/java/docs/index.html 7Intel® Xeon® 2.33 CPU 5140 @2.33GHz, 4G of RAM, OS of Windows Server 2003 Enterprise X64 version 16 Table 1: Current deployment of QuickView. Workstation Hosted components #1 Crawler,Raw tweet buffer #2,3 Process pipeline #4 Indexing Buffer, Indexer/Querier #5 Web application the rule-based (Krupka and Hausman, 1998); 2) the machine learning based (Finkel and Manning, 2009; Singh et al., 2010); and 3) hybrid methods (Jansche and Abney, 2002). With the availability of annotated corpora, such as ACE05, Enron and CoNLL03, the data-driven methods become the dominating methods. However, because of domain mismatch, current systems trained on non-tweets perform poorly on tweets. Our NER system takes three steps to address this problem. Firstly, it defines those recently labeled tweets that are similar to the current tweet as its recognition context, under which a KNNbased classifier is used to conduct word level</context>
</contexts>
<marker>Krupka, Hausman, 1998</marker>
<rawString>George R. Krupka and Kevin Hausman. 1998. Isoquest: Description of the netowlTM extractor system as used in muc-7. In MUC-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Kuan Li</author>
<author>Bo Han</author>
</authors>
<title>Ming Zhou, Long Jiang, Zhongyang Xiong, and Changning Huang.</title>
<date>2010</date>
<pages>698--706</pages>
<contexts>
<context position="4097" citStr="Liu et al. (2010)" startWordPosition="618" endWordPosition="621">stics is proportional to the number of associated opinions; 3) similarly, the top six most frequent words that most clearly express event occurrences are presented; 4) users can search tweets with opinions or events, e.g., search tweets containing any positive/negative opinion about “Obama” or any event involving “Obama”. The implementation of Quickliew requires adapting existing NLP components trained on formal texts, which often performs poorly on tweets. For example, the average F1 of the Stanford NER (Finkel et al., 2005) drops from 90.8% (Ratinov and Roth, 2009) to 45.8% on tweets, while Liu et al. (2010) report that the F1 score of a state-ofthe-art SRL system (Meza-Ruiz and Riedel, 2009) falls to 42.5% on tweets as apposed to 75.5% on news. However, the adaptation of those components is challenging, owing to the lack of annotated tweets and the inadequate signals provided by a noisy and short tweet. Our general strategy is to leverage existing resources as well as unsupervised or semisupervised learning methods to reduce the labeling efforts, and to aggregate as much evidence as possible from a broader context to compensate for the lack of information in a tweet. This strategy is embodied by</context>
<context position="15897" citStr="Liu et al., 2010" startWordPosition="2457" endWordPosition="2460">text. Algorithm 1 outlines its implementation, where: train denotes a machine learning process to get a labeler l, which in our work is a linear CRF model; the cluster function puts the new tweet into a cluster; the label function generates predicate-argument structures for the input tweet with the help of the trained model and the cluster; p, s and cf denote a predicate, a set of argument and role pairs related to the predicate and the predicted confidence, respectively. To prepare the initial clusters required by the SRL component as its input, we adopt the predicateargument mapping method (Liu et al., 2010) to get some automatically labeled tweets, which (plus the manually labeled tweets) are then organized into groups using a bottom-up clustering procedure. It is worth noting that: 1) our SRL component uses the general role schema defined by PropBank, which includes core roles such as A0, A1 (usually indicating the agent and patient of the predicate, respectively), and auxiliary roles such as AM-TMP and AM-LOC (representing the temporal and location information of the predicate, respectively); 2) only verbal predicates are considered, which is consistent with most existing SRL systems; and 3) f</context>
</contexts>
<marker>Liu, Li, Han, 2010</marker>
<rawString>Xiaohua Liu, Kuan Li, Bo Han, Ming Zhou, Long Jiang, Zhongyang Xiong, and Changning Huang. 2010. Semantic role labeling for news tweets. In Coling, pages 698–706.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu´ıs M`arquez</author>
<author>Pere Comas</author>
<author>Jes´us Gim´enez</author>
<author>Neus Catal`a</author>
</authors>
<title>Semantic role labeling as sequential tagging.</title>
<date>2005</date>
<booktitle>In CONLL,</booktitle>
<pages>193--196</pages>
<marker>M`arquez, Comas, Gim´enez, Catal`a, 2005</marker>
<rawString>Llu´ıs M`arquez, Pere Comas, Jes´us Gim´enez, and Neus Catal`a. 2005. Semantic role labeling as sequential tagging. In CONLL, pages 193–196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan Meza-Ruiz</author>
<author>Sebastian Riedel</author>
</authors>
<title>Jointly identifying predicates, arguments and senses using markov logic.</title>
<date>2009</date>
<booktitle>In NAACL,</booktitle>
<pages>155--163</pages>
<contexts>
<context position="4183" citStr="Meza-Ruiz and Riedel, 2009" startWordPosition="633" endWordPosition="636">e top six most frequent words that most clearly express event occurrences are presented; 4) users can search tweets with opinions or events, e.g., search tweets containing any positive/negative opinion about “Obama” or any event involving “Obama”. The implementation of Quickliew requires adapting existing NLP components trained on formal texts, which often performs poorly on tweets. For example, the average F1 of the Stanford NER (Finkel et al., 2005) drops from 90.8% (Ratinov and Roth, 2009) to 45.8% on tweets, while Liu et al. (2010) report that the F1 score of a state-ofthe-art SRL system (Meza-Ruiz and Riedel, 2009) falls to 42.5% on tweets as apposed to 75.5% on news. However, the adaptation of those components is challenging, owing to the lack of annotated tweets and the inadequate signals provided by a noisy and short tweet. Our general strategy is to leverage existing resources as well as unsupervised or semisupervised learning methods to reduce the labeling efforts, and to aggregate as much evidence as possible from a broader context to compensate for the lack of information in a tweet. This strategy is embodied by various components we have developed. For example, our NER component combines a k-nea</context>
<context position="14923" citStr="Meza-Ruiz and Riedel, 2009" startWordPosition="2296" endWordPosition="2299">This task has been extensively studied on well-written corpora like news, and a couple of solutions exist. Examples include: 1) the pipelined approach, i.e., dividing the task into several successive components such as argument identification, argument classification, global inference, etc., and conquering them individually (Xue, 2004; Koomen et al., 2005); 2) sequentially labeling based approach (M`arquez et al., 2005), i.e., labeling the words according to their positions relative to an argument (i.e., inside, outside, or at the beginning); and 3) Markov Logic Networks (MLN) based approach (Meza-Ruiz and Riedel, 2009), i.e., simultaneously resolving all the sub-tasks using learnt weighted formulas. Unsurprisingly, the performance of the state-of-the-art SRL system (MezaRuiz and Riedel, 2009) drops sharply when applied to tweets. The SRL component of Quickliew is based on CRF, and uses the recently labeled tweets that are similar to the current tweet as the broader context. Algorithm 1 outlines its implementation, where: train denotes a machine learning process to get a labeler l, which in our work is a linear CRF model; the cluster function puts the new tweet into a cluster; the label function generates pr</context>
</contexts>
<marker>Meza-Ruiz, Riedel, 2009</marker>
<rawString>Ivan Meza-Ruiz and Sebastian Riedel. 2009. Jointly identifying predicates, arguments and senses using markov logic. In NAACL, pages 155–163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lev Ratinov</author>
<author>Dan Roth</author>
</authors>
<title>Design challenges and misconceptions in named entity recognition.</title>
<date>2009</date>
<booktitle>In CoNLL,</booktitle>
<pages>147--155</pages>
<contexts>
<context position="4053" citStr="Ratinov and Roth, 2009" startWordPosition="609" endWordPosition="612"> 2012. c�2012 Association for Computational Linguistics is proportional to the number of associated opinions; 3) similarly, the top six most frequent words that most clearly express event occurrences are presented; 4) users can search tweets with opinions or events, e.g., search tweets containing any positive/negative opinion about “Obama” or any event involving “Obama”. The implementation of Quickliew requires adapting existing NLP components trained on formal texts, which often performs poorly on tweets. For example, the average F1 of the Stanford NER (Finkel et al., 2005) drops from 90.8% (Ratinov and Roth, 2009) to 45.8% on tweets, while Liu et al. (2010) report that the F1 score of a state-ofthe-art SRL system (Meza-Ruiz and Riedel, 2009) falls to 42.5% on tweets as apposed to 75.5% on news. However, the adaptation of those components is challenging, owing to the lack of annotated tweets and the inadequate signals provided by a noisy and short tweet. Our general strategy is to leverage existing resources as well as unsupervised or semisupervised learning methods to reduce the labeling efforts, and to aggregate as much evidence as possible from a broader context to compensate for the lack of informat</context>
</contexts>
<marker>Ratinov, Roth, 2009</marker>
<rawString>Lev Ratinov and Dan Roth. 2009. Design challenges and misconceptions in named entity recognition. In CoNLL, pages 147–155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Rozenfeld</author>
<author>Ronen Feldman</author>
</authors>
<title>Selfsupervised relation extraction from the web.</title>
<date>2008</date>
<journal>Knowl. Inf. Syst.,</journal>
<pages>17--17</pages>
<contexts>
<context position="6765" citStr="Rozenfeld and Feldman, 2008" startWordPosition="1039" endWordPosition="1042"> well as how to make up for the limited information in a short and often noisy tweet by aggregating information from a broader context. The rest of this paper is organized as follows. In the next section, we introduce related work. In Section 3, we describe our system. In Section 4, we evaluate our system. Finally, Section 5 concludes and presents future work. 2 Related Work Information Extraction Systems. Essentially, Quickliew is an information extraction (IE) system. However, unlike existing IE systems, such as Evita (Saur´ı et al., 2005), a robust event recognizer for QA system, and SRES (Rozenfeld and Feldman, 2008), a self-supervised relation extractor for the web, it targets tweets, a new genre of text, which are short and informal, and its focus is on adapting existing IE components to tweets. Tweet Search Services. A couple of tweet search services exist, including Twitter, Bing social search 2 and Google social search 3. Most of them provide only keyword-based search interfaces, i.e., returning a list of tweets related to a given word/phrase. In contrast, our system extracts fine-grained information from tweets and allows a new end-toend search experience beyond keyword search, such as clustering of</context>
</contexts>
<marker>Rozenfeld, Feldman, 2008</marker>
<rawString>Benjamin Rozenfeld and Ronen Feldman. 2008. Selfsupervised relation extraction from the web. Knowl. Inf. Syst., 17:17–33, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roser Saur´ı</author>
<author>Robert Knippen</author>
<author>Marc Verhagen</author>
<author>James Pustejovsky</author>
</authors>
<title>Evita: A robust event recognizer for qa systems.</title>
<date>2005</date>
<booktitle>In EMNLP,</booktitle>
<pages>700--707</pages>
<marker>Saur´ı, Knippen, Verhagen, Pustejovsky, 2005</marker>
<rawString>Roser Saur´ı, Robert Knippen, Marc Verhagen, and James Pustejovsky. 2005. Evita: A robust event recognizer for qa systems. In EMNLP, pages 700–707.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sameer Singh</author>
<author>Dustin Hillard</author>
<author>Chris Leggetter</author>
</authors>
<title>Minimally-supervised extraction of entities from text advertisements.</title>
<date>2010</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>73--81</pages>
<contexts>
<context position="12935" citStr="Singh et al., 2010" startWordPosition="1996" endWordPosition="1999">tifying mentions of rigid designators from text belonging to namedentity types such as persons, organizations and locations. Existing solutions fall into three categories: 1) 6http://lucene.apache.org/java/docs/index.html 7Intel® Xeon® 2.33 CPU 5140 @2.33GHz, 4G of RAM, OS of Windows Server 2003 Enterprise X64 version 16 Table 1: Current deployment of QuickView. Workstation Hosted components #1 Crawler,Raw tweet buffer #2,3 Process pipeline #4 Indexing Buffer, Indexer/Querier #5 Web application the rule-based (Krupka and Hausman, 1998); 2) the machine learning based (Finkel and Manning, 2009; Singh et al., 2010); and 3) hybrid methods (Jansche and Abney, 2002). With the availability of annotated corpora, such as ACE05, Enron and CoNLL03, the data-driven methods become the dominating methods. However, because of domain mismatch, current systems trained on non-tweets perform poorly on tweets. Our NER system takes three steps to address this problem. Firstly, it defines those recently labeled tweets that are similar to the current tweet as its recognition context, under which a KNNbased classifier is used to conduct word level classification. Following the two-stage prediction aggregation methods (Krish</context>
</contexts>
<marker>Singh, Hillard, Leggetter, 2010</marker>
<rawString>Sameer Singh, Dustin Hillard, and Chris Leggetter. 2010. Minimally-supervised extraction of entities from text advertisements. In HLT-NAACL, pages 73–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In ICSLP,</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<contexts>
<context position="9827" citStr="Stolcke, 2002" startWordPosition="1531" endWordPosition="1532">Figure 2: System architecture of QuickView. quentially: 1) normalization; 2) parsing including part-of-speech (POS), chunking, and dependency parsing; 3) NER; 4) SRL; 5) SA and 6) classification. The normalization model identifies and corrects ill-formed words. For example, after normalization, “loooove” in “· · · I loooove my icon· · · ” will be transformed to “love”. A phrase-based translation system without re-ordering is used to implement this model. The translation table includes manually compiled ill/good form pairs, and the language model is a trigram trained on LDC data 4 using SRILM (Stolcke, 2002). The OpenNLP 5 toolkit is directly used to implement the parsing model. In future, the parsing model will be re-trained using annotated tweets. The SA component is implemented according to Jiang et al. (2011), which incorporates target-dependent features and considers related tweets by utilizing a graph-based optimization. The classification model is a KNN-based classifier that caches confidently labeled results to re-train itself, which also recognizes and drops noisy tweets. 4http://www.ldc.upenn.edu/Catalog/CatalogEntry.jsp ?catalogId=LDC2005T12 shttp://sourceforge.net/projects/opennlp/ Ea</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – an extensible language modeling toolkit. In ICSLP, volume 2, pages 901–904.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Calibrating features for semantic role labeling. In</title>
<date>2004</date>
<booktitle>In Proceedings of EMNLP</booktitle>
<pages>88--94</pages>
<contexts>
<context position="14632" citStr="Xue, 2004" startWordPosition="2252" endWordPosition="2253">ations, temporal expressions, etc. These gazetteers represent general knowledge across domains, and help to make up for the lack of training data. SRL. Given a sentence, the SRL component identifies every predicate, and for each predicate further identifies its arguments. This task has been extensively studied on well-written corpora like news, and a couple of solutions exist. Examples include: 1) the pipelined approach, i.e., dividing the task into several successive components such as argument identification, argument classification, global inference, etc., and conquering them individually (Xue, 2004; Koomen et al., 2005); 2) sequentially labeling based approach (M`arquez et al., 2005), i.e., labeling the words according to their positions relative to an argument (i.e., inside, outside, or at the beginning); and 3) Markov Logic Networks (MLN) based approach (Meza-Ruiz and Riedel, 2009), i.e., simultaneously resolving all the sub-tasks using learnt weighted formulas. Unsurprisingly, the performance of the state-of-the-art SRL system (MezaRuiz and Riedel, 2009) drops sharply when applied to tweets. The SRL component of Quickliew is based on CRF, and uses the recently labeled tweets that are</context>
</contexts>
<marker>Xue, 2004</marker>
<rawString>Nianwen Xue. 2004. Calibrating features for semantic role labeling. In In Proceedings of EMNLP 2004, pages 88–94.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>