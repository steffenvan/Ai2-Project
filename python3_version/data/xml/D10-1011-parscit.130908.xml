<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000365">
<title confidence="0.997296">
Positional Language Models for Clinical Information Retrieval
</title>
<author confidence="0.974896">
Florian Boudin
</author>
<affiliation confidence="0.833374">
DIRO, Universit´e de Montr´eal
</affiliation>
<address confidence="0.84188">
CP. 6128, succ. Centre-ville
H3C 3J7 Montr´eal, Canada
</address>
<email confidence="0.996714">
boudinfl@iro.umontreal.ca
</email>
<author confidence="0.725072">
Jian-Yun Nie
</author>
<affiliation confidence="0.622656">
DIRO, Universit´e de Montr´eal
</affiliation>
<address confidence="0.7439495">
CP. 6128, succ. Centre-ville
H3C 3J7 Montr´eal, Canada
</address>
<email confidence="0.995281">
nie@iro.umontreal.ca
</email>
<author confidence="0.990874">
Martin Dawes
</author>
<affiliation confidence="0.985231">
Department of Family Medicine
</affiliation>
<address confidence="0.8645115">
McGill University, 515 Pine Ave
H2W 1S4 Montr´eal, Canada
</address>
<email confidence="0.998966">
martin.dawes@mcgill.ca
</email>
<sectionHeader confidence="0.993895" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999755526315789">
The PECO framework is a knowledge repre-
sentation for formulating clinical questions.
Queries are decomposed into four aspects,
which are Patient-Problem (P), Exposure (E),
Comparison (C) and Outcome (O). However,
no test collection is available to evaluate such
framework in information retrieval. In this
work, we first present the construction of a
large test collection extracted from system-
atic literature reviews. We then describe an
analysis of the distribution of PECO elements
throughout the relevant documents and pro-
pose a language modeling approach that uses
these distributions as a weighting strategy. In
our experiments carried out on a collection of
1.5 million documents and 423 queries, our
method was found to lead to an improvement
of 28% in MAP and 50% in P@5, as com-
pared to the state-of-the-art method.
</bodyText>
<sectionHeader confidence="0.99899" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999553090909091">
In recent years, the volume of health and biomedi-
cal literature available in electronic form has grown
exponentially. MEDLINE, the authoritative reposi-
tory of citations from the medical and bio-medical
domain, contains more than 18 million citations.
Searching for clinically relevant information within
this large amount of data is a difficult task that med-
ical professionals are often unable to complete in a
timely manner. A better access to clinical evidence
represents a high impact application for physicians.
Evidence-Based Medicine (EBM) is a widely ac-
cepted paradigm for medical practice (Sackett et al.,
1996). EBM is defined as the conscientious, explicit
and judicious use of current best evidence in making
decisions about patient care. Practice EBM means
integrating individual clinical expertise with the best
available external clinical evidence from systematic
research. It involves tracking down the best evi-
dence from randomized trials or meta-analyses with
which to answer clinical questions. Richardson et
al. (1995) identified the following four aspects as the
key elements of a well-built clinical question:
</bodyText>
<listItem confidence="0.954020666666667">
• Patient-problem: what are the patient charac-
teristics (e.g. age range, gender, etc.)? What is
the primary condition or disease?
• Exposure-intervention: what is the main in-
tervention (e.g. drug, treatment, duration, etc.)?
• Comparison: what is the exposure compared
to (e.g. placebo, another drug, etc.)?
• Outcome: what are the clinical outcomes (e.g.
healing, morbidity, side effects, etc.)?
</listItem>
<bodyText confidence="0.999549571428571">
These elements are known as the PECO elements.
Physicians are educated to formulate their clinical
questions in respect to this structure. For example, in
the following question: “In patients of all ages with
Parkinson’s disease, does a Treadmill training com-
pared to no training allows to increase the walking
distance?” one can identify the following elements:
</bodyText>
<listItem confidence="0.99998125">
• P: Patients of all ages with Parkinson’s disease
• E: Treadmill training
• C: No treadmill training
• O: Walking distance
</listItem>
<bodyText confidence="0.983036666666667">
In spite of this well-defined question structure,
physicians still use keyword-based queries when
they search for clinical evidence. An explanation of
</bodyText>
<page confidence="0.980361">
108
</page>
<note confidence="0.8178415">
Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 108–115,
MIT, Massachusetts, USA, 9-11 October 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999964782608696">
that is the almost total absence of PECO search in-
terfaces. PubMed1, the most used search interface,
does not allow users to formulate PECO queries
yet. For the previously mentioned clinical question,
a physician would use the query “Treadmill AND
Parkinson’s disease”. There is intuitively much to
gain by using a PECO structured query in the re-
trieval process. This structure specifies the role of
each concept in the desired documents, which is
a clear advantage over a keyword-based approach.
One can for example differentiate two queries in
which a disease would be a patient condition or a
clinical outcome. This conceptual decomposition of
queries is also particularly useful in a sense that it
can be used to balance the importance of each ele-
ment in the search process.
Another important factor that prevented re-
searchers from testing approaches to clinical infor-
mation retrieval (IR) based on PECO elements is
the lack of a test collection, which contains a set of
documents, a set of queries and the relevance judg-
ments. The construction of such a test collection is
costly in manpower. In this paper, we take advan-
tage of the systematic reviews about clinical ques-
tions from Cochrane. Each Cochrane review ex-
amines in depth a clinical question and survey all
the available relevant publications. The reviews are
written for medical professionals. We transformed
them into a TREC-like test collection, which con-
tains 423 queries and 8926 relevant documents ex-
tracted from MEDLINE. In a second part of this pa-
per, we present a model integrating the PECO frame-
work in a language modeling approach to IR. An in-
tuitive method would try to annotate the concepts
in documents into PECO categories. One can then
match the PECO elements in the query to the ele-
ments detected in documents. However, as previous
studies have shown, it is very difficult to automat-
ically annotate accurately PECO elements in docu-
ments. To by-pass this issue, we propose an alter-
native that relies on the observed positional distri-
bution of these elements in documents. We will see
that different types of element have different distri-
butions. By weighting words according to their posi-
tions, we can indirectly weigh the importance of dif-
ferent types of element in search. As we will show
</bodyText>
<footnote confidence="0.812456">
1www.pubmed.gov
</footnote>
<bodyText confidence="0.998960777777778">
in this paper, this approach turns out to be highly
effective.
This paper is organized as follows. We first briefly
review the previous work, followed by a description
of the test collection we have constructed. Next,
we give the details of the method we propose and
present our experiments and results. Lastly, we con-
clude with a discussion and directions for further
work.
</bodyText>
<sectionHeader confidence="0.99955" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.9996165">
The need to answer clinical questions related to a
patient care using IR systems has been well stud-
ied and documented (Hersh et al., 2000; Niu et al.,
2003; Pluye et al., 2005). There are a limited but
growing number of studies trying to use the PECO
elements in the retrieval process. (Demner-Fushman
and Lin, 2007) is one of the few such studies, in
which a series of knowledge extractors is used to
detect PECO elements in documents. These ele-
ments are later used to re-rank a list of retrieved ci-
tations from PubMed. Results reported indicate that
their method can bring relevant citations into higher-
ranking positions, and from these abstracts gener-
ate responses that answer clinicians’ questions. This
study demonstrates the value of the PECO frame-
work as a method for structuring clinical questions.
However, as the focus has been put on the post-
retrieval step (for question-answering), it is not clear
whether PECO elements are useful at the retrieval
step. Intuitively, the integration of PECO elements
in the retrieval process can also lead to higher re-
trieval effectiveness.
The most obvious scenario for testing this would
be to recognize PECO elements in documents prior
to indexing. When a PECO-structured query is for-
mulated, it is matched against the PECO elements
in the documents (Dawes et al., 2007). Neverthe-
less, the task of automatically identifying PECO el-
ements is a very difficult one. There are two major
reasons for that. First, previous studies have indi-
cated that there is a low to moderate agreement rate
among humans for annotating PECO elements. This
is due to the lack of standard definition for the el-
ement’ boundaries (e.g. can be words, phrases or
sentences) but also to the existence of several lev-
els of annotation. Indeed, there are a high number
</bodyText>
<page confidence="0.998651">
109
</page>
<bodyText confidence="0.999993368421053">
of possible candidates for each element and one has
to choose if it is a main element (i.e. playing a ma-
jor role in the clinical study) or secondary elements.
Second is the lack of sufficient annotated data that
can be used to train automatic tagging tools.
Despite all these difficulties, several efficient
detection methods have been proposed (Demner-
Fushman and Lin, 2007; Chung, 2009). Nearly all
of them are however restricted to a coarse-grain an-
notation level (i.e. tagging entire sentences as de-
scribing one element). This kind of coarser-grain
identification is more robust and more feasible than
the one at concept level, and it could be sufficient in
the context of IR. In fact, for IR purposes, what is
the most important is to correctly weight the words
in documents and queries. From this perspective,
an annotation at the sentence level may be suffi-
cient. Notwithstanding, experiments conducted us-
ing a collection of documents that were annotated at
a sentence-level only showed a small increase in re-
trieval accuracy (Boudin et al., 2010b) compared to
a traditional bag-of-words approach.
More recently, Boudin et al. (2010a) proposed an
alternative to the PECO detection issue that relies
on assigning different weights to words according to
their positions in the document. A location-based
weighting strategy is used to emphasize the most
informative parts of documents. They show that
a large improvement in retrieval effectiveness can
be obtained this way and indicate that the weights
learned automatically are correlated to the observed
distribution of PECO elements in documents. In this
work, we propose to go one step further in this direc-
tion by analyzing the distribution of PECO elements
in a large number of documents and define the posi-
tional probabilities of PECO elements accordingly.
These probabilities will be integrated in the docu-
ment language model.
</bodyText>
<sectionHeader confidence="0.618293" genericHeader="method">
3 Construction of the test collection
</sectionHeader>
<bodyText confidence="0.966251307692308">
Despite the increasing use of search engines by med-
ical professionals, there is no standard test collection
for evaluating clinical IR. Constructing such a re-
source from scratch would require considerable time
and money. One way to overcome this obstacle is
to use already available systematic reviews. Sys-
tematic reviews try to identify, appraise, select and
synthesize all high quality research evidence rele-
vant to a clinical question. The best-known source
of systematic reviews in the healthcare domain is the
Cochrane collaboration2. It consists of a group of
over 15,000 specialists who systematically identify
and review randomized trials of the effects of treat-
ments. In particular, a review contains a reference
section, listing all the relevant studies to the clinical
question. These references can be considered as rel-
evant documents. In our work, we propose to use
these reviews as a way to semi-automatically build a
test collection. As the reviews are made by special-
ists in the area independently from our study, we can
avoid bias in our test collection.
We gathered a subset of Cochrane systematic re-
views and asked a group of annotators, one professor
and four Master students in family medicine, to cre-
ate PECO-structured queries corresponding to the
clinical questions. As clinical questions answered
in these reviews cover various aspects of one topic,
multiple variants of precise PECO queries were gen-
erated for each review. Moreover, in order to be able
to compare a PECO-based search strategy to a real
world scenario, this group have also provided the
keyword-based queries that they would have used
to search with PubMed. Below is an example of
queries generated from the systematic review about
“Aspirin with or without an antiemetic for acute mi-
graine headaches in adults”:
Keyword-based query
[aspirin and migraine]
PECO-structured queries
</bodyText>
<listItem confidence="0.9884782">
1. [adults 18 years or more with migraine]P
[aspirin alone]F-
[placebo]C
[pain free]O
2. [adults 18 years or more with migraine]P
[aspirin plus an antiemetic]F-
[placebo]C
[pain free]O
3. [adults 18 years or more with migraine]P
[aspirin plus metoclopramide]F-
</listItem>
<bodyText confidence="0.7237665">
[active comparator]C
[use of rescue medication]O
</bodyText>
<footnote confidence="0.988575">
2www.cochrane.org
</footnote>
<page confidence="0.996967">
110
</page>
<bodyText confidence="0.998584555555556">
All the citations included in the “References” sec-
tion of the systematic review were extracted and
selected as relevant documents. These citations
were manually mapped to PubMed unique identi-
fiers (PMID). This is a long process that was under-
taken by two different workers to minimize the num-
ber of errors. At this step, only articles published in
journals referenced in PubMed are considered (e.g.
conference proceedings are not included).
</bodyText>
<figure confidence="0.983004142857143">
25
20
15
10
5
0 20 40 60 80 100 120
Number of references in each review
</figure>
<figureCaption confidence="0.994421">
Figure 1: Histogram of the number of queries versus the
number of relevant documents.
</figureCaption>
<bodyText confidence="0.999987785714286">
We selected in sequential order from the set
of new systematic reviews3 and processed 156
Cochrane reviews. There was no restriction about
the topics covered or the number of included refer-
ences. The resulting test collection is composed of
423 queries and 8926 relevant citations (2596 differ-
ent citations). This number reduces to 8138 citations
once we remove the citations without any text in the
abstract (i.e. certain citations, especially old ones,
only contain a title). Figure 1 shows the statistics
derived from the number of relevant documents by
query. In this test collection, the average number of
documents per query is approximately 19 while the
average length of a document is 246 words.
</bodyText>
<sectionHeader confidence="0.949393" genericHeader="method">
4 Distribution of PECO elements
</sectionHeader>
<bodyText confidence="0.999920571428571">
The observation that PECO elements are not evenly
distributed throughout the documents is not new. In
fact, most existing tagging methods used location-
based features. This information turns out to be very
useful because of the standard structure of medical
citations. Actually, many scientific journals explic-
itly recommend authors to write their abstracts in
</bodyText>
<footnote confidence="0.9323155">
3http://mrw.interscience.wiley.com/
cochrane/cochrane clsysrev new fs.html
</footnote>
<bodyText confidence="0.999413395833333">
compliance to the ordered rhetorical structure: In-
troduction, Methods, Results and Discussion. These
rhetorical categories are highly correlated to the dis-
tributions of PECO elements, as some elements are
more likely to occur in certain categories (e.g. clin-
ical outcomes are more likely to appear in the con-
clusion). The position is thus a strong indicator of
whether a text segment contains a PECO element or
not.
To the best of our knowledge, the first analysis
of the distribution of PECO elements in documents
was described in(Boudin et al., 2010a). A small col-
lection of manually annotated abstracts was used to
compute the probability that a PECO element oc-
curs in a specific part of the documents. This study
is however limited by the small number of anno-
tated documents (approximately 50 citations) and
the moderate agreement rate among human annota-
tors. Here we propose to use our test collection to
compute more reliable statistics.
The idea is to use the pairs of PECO-structured
query and relevant document, assuming that if a doc-
ument is relevant then it should contain the same
elements as the query. Of course, this is obvi-
ously not always the case. Errors can be introduced
by synonyms or homonyms and relevant documents
may not contain all of the elements described in the
query. But, with more than 8100 documents, it is
quite safe to say that this method produce fairly reli-
able results. Moreover, a filtering process is applied
to queries removing all non-informative words (e.g.
stopwords, numbers, etc.) from being counted.
There are several ways to look at the distribution
of PECO elements in documents. One can use the
rhetorical structure of abstracts to do that. However,
the high granularity level of such analysis would
make it less precise for IR purposes. Furthermore,
most of the citations available in PubMed are de-
void of explicitly marked sections. It is possible to
automatically detect these sections but only with a
non-negligible error rate (McKnight and Srinivasan,
2003). In our study, we chose to use a fixed num-
ber of partitions by dividing documents into parts of
equal length. This choice is motivated by its repeata-
bility and ease to implement, but also for compari-
son with previous studies.
We divided each relevant document into 10 parts
of equal length on a word level (from P1 to P10). We
</bodyText>
<figure confidence="0.9813975">
Number of systematic reviews
0
</figure>
<page confidence="0.984133">
111
</page>
<bodyText confidence="0.9929548">
pendence, a simple estimate for P(w|Q) can be ob-
tained by computing Maximum Likelihood Estima-
tion (MLE). It is calculated as the number of times
the word w appears in the query Q, divided by its
length:
</bodyText>
<equation confidence="0.995858">
P(w|Q) = |Q|
</equation>
<bodyText confidence="0.979640285714286">
A similar method is employed for estimating
P(w|D). Bayesian smoothing using Dirichlet pri-
ors is however applied to the maximum likelihood
estimator to compensate for data sparseness (i.e.
smoothing probabilities to remove zero estimates).
Given µ the prior parameter and C the collection of
documents, P(w|D) is computed as:
</bodyText>
<equation confidence="0.99978">
count(w, D) + µ · P(w|C)
P(w|D) =
|D |+ µ
</equation>
<subsectionHeader confidence="0.583059">
5.1 Model definition
</subsectionHeader>
<bodyText confidence="0.999874333333333">
In our model, we propose to use the distribution of
PECO elements observed in documents to empha-
size the most informative parts of the documents.
The idea is to get rid of the problem of precisely
detecting PECO elements by using a positional lan-
guage model. To integrate position, we estimate
a series of probabilities that constraints the word
counts to a specific part of the documents instead of
the entire document. Each document D is ranked by
a weighted linear interpolation. Given a document
D divided in 10 parts p E [P1, P2 · · · P101, P(w|D)
in equation 1 is redefined as:
</bodyText>
<equation confidence="0.994331333333333">
P&apos;(w|D) = α · P(w|D) + P · Ptitle(w|D)
+y · � 6e · Pp,(w|D) (2)
p,ED
</equation>
<bodyText confidence="0.99979075">
where the 6e weights for each type of element e
are empirically fixed to the values of the distribution
of PECO elements observed in documents. We then
redefine the scoring function to integrate the PECO
query formulation. The idea is to use the PECO
structure as a way to balance the importance of each
element in the retrieval step. The final scoring func-
tion is defined as:
</bodyText>
<equation confidence="0.986638666666667">
�ScoTefinal(Q, D) = be · ScoTe(Qe, D)
eEPECO
count(w, Q)
</equation>
<bodyText confidence="0.996099333333333">
computed statistics on the number of query words
that occur in each of these parts. For each PECO el-
ement, the distribution of query words among the
parts of the documents is not uniform (Figure 2).
We observe distinctive distributions, especially for
Patient-Problem and Exposure elements, indicating
that first and last parts of the documents have higher
chance to contain these elements. This gives us a
clear and robust indication on which specific parts
should be enhanced when searching for a given el-
ement. Our proposed model will exploit the typical
distributions of PECO elements in documents.
</bodyText>
<figureCaption confidence="0.997146">
Figure 2: Distribution of each PECO element throughout
the different parts of the documents.
</figureCaption>
<sectionHeader confidence="0.995469" genericHeader="method">
5 Retrieval Method
</sectionHeader>
<bodyText confidence="0.999974545454545">
In this work, we use the language modeling ap-
proach to information retrieval. This approach as-
sumes that queries and documents are generated
from some probability distribution of text (Ponte and
Croft, 1998). Under this assumption, ranking a doc-
ument D as relevant to a query Q is seen as estimat-
ing P(Q|D), the probability that Q was generated by
the same distribution as D. A typical way to score
a document D as relevant to a query Q is to com-
pute the Kullback-Leibler divergence between their
respective language models:
</bodyText>
<equation confidence="0.9927975">
�ScoTe(Q, D) = P(w|Q) · log P(w|D) (1)
wEQ
</equation>
<bodyText confidence="0.961914">
Under the traditional bag-of-words assumption,
i.e. assuming that there is no need to model term de-
</bodyText>
<equation confidence="0.919707428571429">
P elements E elements
P1 P2 P3 P4 P5 P6 P] P8 P9 P10
C elements
P1 P2 P3 P4 P5 P6 P] P8 P9 P10
P1 P2 P3 P4 P5 P6 P] P8 P9 P10
O elements
P1 P2 P3 P4 P5 P6 P] P8 P9 P10
</equation>
<figure confidence="0.987688928571429">
Parts of the documents
0.25
Proportion of PECO elements in part
0.20
0.15
0.10
0.05
0.00
0.25
0.20
0.15
0.10
0.05
0.00
</figure>
<page confidence="0.993703">
112
</page>
<bodyText confidence="0.9999282">
In our model, there are a total of 7 weighting pa-
rameters, 4 corresponding to the PECO elements in
queries (6P, 6F, 6C and 6O) and 3 for the document
language models (oc, P and -y). These parameters
will be determined by cross-validation.
</bodyText>
<sectionHeader confidence="0.999722" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.9998465">
In this section, we first describe the details of our
experimental protocol. Then, we present the results
obtained by our model on the constructed test col-
lection.
</bodyText>
<subsectionHeader confidence="0.998945">
6.1 Experimental settings
</subsectionHeader>
<bodyText confidence="0.999364454545455">
As a collection of documents, we gathered 1.5 mil-
lions of citations from PubMed. We used the fol-
lowing constraints: citations with an abstract, hu-
man subjects, and belonging to one of the follow-
ing publication types: randomized control trials, re-
views, clinical trials, letters, editorials and meta-
analyses. The set of queries and relevance judg-
ments described in Section 3 is used to evaluate
our model. Relevant documents were, if not al-
ready included, added to the collection. Because
each query is generated from a systematic literature
review completed at a time t, we placed an addi-
tional restriction on the publication date of the re-
trieved documents: only documents published be-
fore time t are considered. Before indexing, each
citation is pre-processed to extract its title and ab-
stract text and then converted into a TREC-like doc-
ument format. Abstracts are divided into 10 parts of
equal length (the ones containing less than 10 words
are discarded). The following fields are marked in
each document: title, P1, P2 · · · P10. The following
evaluation measures are used:
</bodyText>
<listItem confidence="0.9890805">
• Precision at rank n (P@n): precision computed
on the n topmost retrieved documents.
• Mean Average Precision (MAP): average of
precision measures computed at the point of
each relevant document in the ranked list.
• Number of relevant documents retrieved
</listItem>
<bodyText confidence="0.593527">
All retrieval tasks are performed using an “out-
of-the-shelf” version of the Lemur toolkit4. We use
the embedded tokenization algorithm along with the
</bodyText>
<footnote confidence="0.952797">
4www.lemurproject.org
</footnote>
<bodyText confidence="0.998996">
standard Porter stemmer. The number of retrieved
documents is set to 1000 and the Dirichlet prior
smoothing parameter to µ = 2000. In all our exper-
iments, we use the KL divergence scoring function
(equation 1) as baseline. Statistical significance is
computed using the well-known Student’s t-test. To
determine reasonable weights and avoid overtuning
the parameters, we use a 10-fold cross-validation op-
timizing the MAP values.
</bodyText>
<subsectionHeader confidence="0.995664">
6.2 Experiments
</subsectionHeader>
<bodyText confidence="0.999957135135135">
We first investigated the impact of using PECO-
structured queries on the retrieval performance. As
far as we know, no quantitative evaluation of the
increase or decrease of performance in comparison
with a keyword-based search strategy has been re-
ported. Schardt et al. (2007) presented a compari-
son between PubMed and a PECO search interface
but failed to demonstrate any significant difference
between the two search protocols. The larger num-
ber of words in PECO-structured queries, on aver-
age 18.8 words per query compared to 4.3 words for
keyword queries, should capture more aspects of the
information need. But, it may also be a disadvan-
tage due to the fact that more noise can be brought
in, causing query-drift issues.
We propose two baselines using the keyword-
based queries. The first baseline (named Baseline-
1) uses keyword queries with the traditional lan-
guage modeling approach. This is one of the state-
of-the-art approaches in current IR research. This
retrieval model considers each word in a query as
an equal, independent source of information. In the
second baseline (named Baseline-2), we consider
multiword phrases. In our test collection, queries
are often composed of multiword phrases such as
“low back pain” or “early pregnancy”. It is clear
that finding the exact phrase “heart failure” is a
much stronger indicator of relevance than just find-
ing “heart” and “failure” scattered within a docu-
ment. The Indri operator #1 is used to perform
phrase-based retrieval. Phrases are already indicated
in queries by the conjunction and (e.g. vaccine and
hepatitis B). A simple regular expression is used to
recognize the phrases.
Results are presented in Table 1. As expected,
phrase-based retrieval leads to some increase in re-
trieval precision (P@5). However, the number of
</bodyText>
<page confidence="0.997405">
113
</page>
<bodyText confidence="0.9996292">
relevant documents retrieved is decreased. This is
due to the fact that we use exact phrase matching
that can reduce query coverage. One solution would
be to use unordered window features (Indri operator
#uwn) that would require words to be close together
but not necessarily in an exact sequence order (Met-
zler and Croft, 2005).
The PECO queries use PECO-structured queries
as a bag of words. We observe that PECO queries
do not enhance the average precision but increase
the P@5 significantly. The number of relevant doc-
uments retrieved is also larger. These results indi-
cate that formulating clinical queries according to
the PECO framework enhance the retrieval effec-
tiveness.
</bodyText>
<table confidence="0.99673025">
Model MAP P@5 #rel. ret.
Baseline-1 0.129 0.151 5369
Baseline-2 0.128 0.161∗ 4645
PECO-queries 0.126 0.172∗ 5433
</table>
<tableCaption confidence="0.874513">
Table 1: Comparing the performance measures of
keyword-based and PECO-structured queries in terms of
MAP, precision at 5 and number of relevant documents
retrieved (#rel. ret.). (*: t.test &lt; 0.05)
</tableCaption>
<bodyText confidence="0.999963693877551">
In a second series of experiments, we evaluated
the model we proposed in Section 5 . We compared
two variants of our model. The first variant (named
Model-1) uses a global a, distribution fixed accord-
ing to the average distribution of all PECO elements
(i.e. the observed probability that a PECO element
occurs in a document’ part, no matter which element
it is). The second variant (named Model-2) uses a
differentiated a, distribution for each type of PECO
element. The idea is to see if, given the fact that
PECO elements have different distributions in docu-
ments, using an adapted weight distribution for each
element can improve the retrieval effectiveness.
Previous studies have shown that assigning a dif-
ferent weight to each PECO element in the query
leads to better results (Demner-Fushman and Lin,
2007; Boudin et al., 2010a). In order to compare
our model with a similar method, we defined another
baseline (named Baseline-3) by fixing the parame-
ters P = 0 and -y = 0 in equation 2. We performed
a grid search (from 0 to 1 by step of 0.1) to find
the optimal b weights. Regarding the last three pa-
rameters in our full models, namely oc, P and -y, we
conducted a second grid search to find their optimal
values. Performance measures obtained in 10-fold
cross-validation (optimizing the MAP measure) by
these models are presented in Table 2.
A significant improvement is obtained by
the Baseline-3 over the keyword-based approach
(Baseline-2). The PECO decomposition of queries
is particularly useful to balance the importance of
each element in the scoring function. We observe a
large improvement in retrieval effectiveness for both
models over the two baselines. This strongly indi-
cates that a weighting scheme based on the word po-
sition in documents is effective. These results sup-
port our assumption that the distribution of PECO
elements in documents can be used to weight words
in the document language model.
However, we do not observe meaningful differ-
ences between Model-1 and Model-2. This tend to
suggest that a global distribution is likely more ro-
bust for IR purposes than separate distributions for
each type of element. Another possible reason is that
our direct mapping from positional distribution to
probabilities may not be the most appropriate. One
may think about using a different transformation, or
performing some smoothing. We will leave this for
our future work.
</bodyText>
<sectionHeader confidence="0.998509" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999967117647059">
This paper first presented the construction of a test
collection for evaluating clinical information re-
trieval. From a set of systematic reviews, a group
of annotators were asked to generate structured clin-
ical queries and collect relevance judgments. The
resulting test collection is composed of 423 queries
and 8926 relevant documents. This test collection
provides a basis for researchers to experiment with
PECO-structured queries in clinical IR. The test col-
lection introduced in this paper, along with the man-
ual given to the group of annotators, will be available
for download5.
In a second step, this paper addressed the prob-
lem of using the PECO framework in clinical IR. A
straightforward idea is to identify PECO elements in
documents and use the elements in the retrieval pro-
cess. However, this approach does not work well be-
</bodyText>
<footnote confidence="0.977745">
5http://www-etud.iro.umontreal.ca/-boudinfl/pecodr/
</footnote>
<page confidence="0.993321">
114
</page>
<table confidence="0.999748">
Model MAP % rel. P@5 % rel. #rel. ret.
Baseline-2 0.128 - 0.161 - 4645
Baseline-3 0.144 +12.5%* 0.196 +21.7%† 5780
Model-1 0.164 +28.1%† 0.241 +49.7%† 5768
Model-2 0.163 +27.3%† 0.240 +49.1%† 5770
</table>
<tableCaption confidence="0.986915333333333">
Table 2: 10-fold cross validation scores for the Baseline-2, Baseline-3 and the two variants of our proposed model
(Model-1 and Model-2). Relative increase over the Baseline-2 is given, #rel. ret. is the number of relevant documents
retrieved. (†: t.test &lt; 0.01, *: t.test &lt; 0.05)
</tableCaption>
<bodyText confidence="0.999894578947369">
cause of the difficulty to automatically detect these
elements. Instead, we proposed a less demanding
approach that uses the distribution of PECO ele-
ments in documents to re-weight terms in the doc-
ument model. The observation of variable distribu-
tions in our test collection led us to believe that the
position information can be used as a robust indica-
tor of the presence of a PECO element. This strategy
turns out to be promising. On a data set composed
of 1.5 million citations extracted with PubMed, our
best model obtains an increase of 28% for MAP
and nearly 50% for P@5 over the classical language
modeling approach.
In future work, we intend to expand our analy-
sis of the distribution of PECO elements to a larger
number of citations. One way to do that would
be to automatically extract PubMed citations that
contain structural markers associated to PECO cate-
gories (Chung, 2009).
</bodyText>
<sectionHeader confidence="0.99924" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999789666666667">
Florian Boudin, Jian-Yun Nie, and Martin Dawes. 2010a.
Clinical Information Retrieval using Document and
PICO Structure. In Proceedings of the HLT-NAACL
2010 conference, pages 822–830.
Florian Boudin, Lixin Shi, and Jian-Yun Nie. 2010b. Im-
proving Medical Information Retrieval with PICO El-
ement Detection. In Proceedings of the ECIR 2010
conference, pages 50–61.
Grace Y. Chung. 2009. Sentence retrieval for abstracts
of randomized controlled trials. BMC Medical Infor-
matics and Decision Making, 9(1).
Thomas Owens Sheri Keitz Connie Schardt, Martha
B Adams and Paul Fontelo. 2007. Utilization of the
PICO framework to improve searching PubMed for
clinical questions. BMC Medical Informatics and De-
cision Making, 7(1).
Martin Dawes, Pierre Pluye, Laura Shea, Roland Grad,
Arlene Greenberg, and Jian-Yun Nie. 2007. The iden-
tification of clinically important elements within med-
ical journal abstracts: PatientPopulationProblem, Ex-
posureIntervention, Comparison, Outcome, Duration
and Results (PECODR). Informatics in Primary care,
15(1):9–16.
D. Demner-Fushman and J. Lin. 2007. Answering
clinical questions with knowledge-based and statistical
techniques. Computational Linguistics, 33(1):63–103.
William R. Hersh, Katherine Crabtree, David H. Hickam,
Lynetta Sacherek, Linda Rose, and Charles P. Fried-
man. 2000. Factors associated with successful an-
swering of clinical questions using an information re-
trieval system. Bulletin of the Medical Library Asso-
ciation, 88(4):323–331.
Larry McKnight and Padmini Srinivasan. 2003. Catego-
rization of sentence types in medical abstracts. Pro-
ceedings of the AMIA annual symposium.
Donald Metzler and W. Bruce Croft. 2005. A Markov
random field model for term dependencies. In Pro-
ceedings of the SIGIR conference, pages 472–479.
Yun Niu, Graeme Hirst, Gregory McArthur, and Patricia
Rodriguez-Gianolli. 2003. Answering clinical ques-
tions with role identification. In Proceedings of the
ACL 2003 Workshop on Natural Language Processing
in Biomedicine, pages 73–80.
Pierre Pluye, Roland M. Grad, Lynn G. Dunikowski,
and Randolph Stephenson. 2005. Impact of clinical
information-retrieval technology on physicians: a lit-
erature review of quantitative, qualitative and mixed
methods studies. International Journal of Medical In-
formatics, 74(9):745–768.
Jay M. Ponte and W. Bruce Croft. 1998. A language
modeling approach to information retrieval. In Pro-
ceedings of the SIGIR conference, pages 275–281.
Scott W. Richardson, Mark C. Wilson, Jim Nishikawa,
and Robert S. Hayward. 1995. The well-built clini-
cal question: a key to evidence-based decisions. ACP
Journal Club, 123(3):A12–13.
David L. Sackett, William Rosenberg, J. A. Muir Gray,
Brian Haynes, and W. Scott Richardson. 1996. Ev-
idence based medicine: what it is and what it isn’t.
British medical journal, 312:71–72.
</reference>
<page confidence="0.999025">
115
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.028644">
<title confidence="0.998755">Positional Language Models for Clinical Information Retrieval</title>
<author confidence="0.9553">Florian</author>
<affiliation confidence="0.68955">DIRO, Universit´e de</affiliation>
<address confidence="0.668766">CP. 6128, succ. H3C 3J7 Montr´eal, Canada</address>
<email confidence="0.947921">boudinfl@iro.umontreal.ca</email>
<abstract confidence="0.211476">Jian-Yun DIRO, Universit´e de CP. 6128, succ.</abstract>
<address confidence="0.776735">H3C 3J7 Montr´eal, Canada</address>
<email confidence="0.950224">nie@iro.umontreal.ca</email>
<author confidence="0.922855">Martin</author>
<affiliation confidence="0.8590655">Department of Family McGill University, 515 Pine</affiliation>
<address confidence="0.996846">H2W 1S4 Montr´eal, Canada</address>
<email confidence="0.995863">martin.dawes@mcgill.ca</email>
<abstract confidence="0.985645">The PECO framework is a knowledge representation for formulating clinical questions. Queries are decomposed into four aspects, which are Patient-Problem (P), Exposure (E), Comparison (C) and Outcome (O). However, no test collection is available to evaluate such framework in information retrieval. In this work, we first present the construction of a large test collection extracted from systematic literature reviews. We then describe an analysis of the distribution of PECO elements throughout the relevant documents and propose a language modeling approach that uses these distributions as a weighting strategy. In our experiments carried out on a collection of 1.5 million documents and 423 queries, our method was found to lead to an improvement of 28% in MAP and 50% in P@5, as compared to the state-of-the-art method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Florian Boudin</author>
<author>Jian-Yun Nie</author>
<author>Martin Dawes</author>
</authors>
<title>Clinical Information Retrieval using Document and PICO Structure.</title>
<date>2010</date>
<booktitle>In Proceedings of the HLT-NAACL 2010 conference,</booktitle>
<pages>822--830</pages>
<contexts>
<context position="9167" citStr="Boudin et al., 2010" startWordPosition="1458" endWordPosition="1461"> a coarse-grain annotation level (i.e. tagging entire sentences as describing one element). This kind of coarser-grain identification is more robust and more feasible than the one at concept level, and it could be sufficient in the context of IR. In fact, for IR purposes, what is the most important is to correctly weight the words in documents and queries. From this perspective, an annotation at the sentence level may be sufficient. Notwithstanding, experiments conducted using a collection of documents that were annotated at a sentence-level only showed a small increase in retrieval accuracy (Boudin et al., 2010b) compared to a traditional bag-of-words approach. More recently, Boudin et al. (2010a) proposed an alternative to the PECO detection issue that relies on assigning different weights to words according to their positions in the document. A location-based weighting strategy is used to emphasize the most informative parts of documents. They show that a large improvement in retrieval effectiveness can be obtained this way and indicate that the weights learned automatically are correlated to the observed distribution of PECO elements in documents. In this work, we propose to go one step further i</context>
<context position="14559" citStr="Boudin et al., 2010" startWordPosition="2306" endWordPosition="2309">/mrw.interscience.wiley.com/ cochrane/cochrane clsysrev new fs.html compliance to the ordered rhetorical structure: Introduction, Methods, Results and Discussion. These rhetorical categories are highly correlated to the distributions of PECO elements, as some elements are more likely to occur in certain categories (e.g. clinical outcomes are more likely to appear in the conclusion). The position is thus a strong indicator of whether a text segment contains a PECO element or not. To the best of our knowledge, the first analysis of the distribution of PECO elements in documents was described in(Boudin et al., 2010a). A small collection of manually annotated abstracts was used to compute the probability that a PECO element occurs in a specific part of the documents. This study is however limited by the small number of annotated documents (approximately 50 citations) and the moderate agreement rate among human annotators. Here we propose to use our test collection to compute more reliable statistics. The idea is to use the pairs of PECO-structured query and relevant document, assuming that if a document is relevant then it should contain the same elements as the query. Of course, this is obviously not al</context>
<context position="25760" citStr="Boudin et al., 2010" startWordPosition="4192" endWordPosition="4195">rage distribution of all PECO elements (i.e. the observed probability that a PECO element occurs in a document’ part, no matter which element it is). The second variant (named Model-2) uses a differentiated a, distribution for each type of PECO element. The idea is to see if, given the fact that PECO elements have different distributions in documents, using an adapted weight distribution for each element can improve the retrieval effectiveness. Previous studies have shown that assigning a different weight to each PECO element in the query leads to better results (Demner-Fushman and Lin, 2007; Boudin et al., 2010a). In order to compare our model with a similar method, we defined another baseline (named Baseline-3) by fixing the parameters P = 0 and -y = 0 in equation 2. We performed a grid search (from 0 to 1 by step of 0.1) to find the optimal b weights. Regarding the last three parameters in our full models, namely oc, P and -y, we conducted a second grid search to find their optimal values. Performance measures obtained in 10-fold cross-validation (optimizing the MAP measure) by these models are presented in Table 2. A significant improvement is obtained by the Baseline-3 over the keyword-based app</context>
</contexts>
<marker>Boudin, Nie, Dawes, 2010</marker>
<rawString>Florian Boudin, Jian-Yun Nie, and Martin Dawes. 2010a. Clinical Information Retrieval using Document and PICO Structure. In Proceedings of the HLT-NAACL 2010 conference, pages 822–830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Boudin</author>
<author>Lixin Shi</author>
<author>Jian-Yun Nie</author>
</authors>
<title>Improving Medical Information Retrieval with PICO Element Detection.</title>
<date>2010</date>
<booktitle>In Proceedings of the ECIR 2010 conference,</booktitle>
<pages>50--61</pages>
<contexts>
<context position="9167" citStr="Boudin et al., 2010" startWordPosition="1458" endWordPosition="1461"> a coarse-grain annotation level (i.e. tagging entire sentences as describing one element). This kind of coarser-grain identification is more robust and more feasible than the one at concept level, and it could be sufficient in the context of IR. In fact, for IR purposes, what is the most important is to correctly weight the words in documents and queries. From this perspective, an annotation at the sentence level may be sufficient. Notwithstanding, experiments conducted using a collection of documents that were annotated at a sentence-level only showed a small increase in retrieval accuracy (Boudin et al., 2010b) compared to a traditional bag-of-words approach. More recently, Boudin et al. (2010a) proposed an alternative to the PECO detection issue that relies on assigning different weights to words according to their positions in the document. A location-based weighting strategy is used to emphasize the most informative parts of documents. They show that a large improvement in retrieval effectiveness can be obtained this way and indicate that the weights learned automatically are correlated to the observed distribution of PECO elements in documents. In this work, we propose to go one step further i</context>
<context position="14559" citStr="Boudin et al., 2010" startWordPosition="2306" endWordPosition="2309">/mrw.interscience.wiley.com/ cochrane/cochrane clsysrev new fs.html compliance to the ordered rhetorical structure: Introduction, Methods, Results and Discussion. These rhetorical categories are highly correlated to the distributions of PECO elements, as some elements are more likely to occur in certain categories (e.g. clinical outcomes are more likely to appear in the conclusion). The position is thus a strong indicator of whether a text segment contains a PECO element or not. To the best of our knowledge, the first analysis of the distribution of PECO elements in documents was described in(Boudin et al., 2010a). A small collection of manually annotated abstracts was used to compute the probability that a PECO element occurs in a specific part of the documents. This study is however limited by the small number of annotated documents (approximately 50 citations) and the moderate agreement rate among human annotators. Here we propose to use our test collection to compute more reliable statistics. The idea is to use the pairs of PECO-structured query and relevant document, assuming that if a document is relevant then it should contain the same elements as the query. Of course, this is obviously not al</context>
<context position="25760" citStr="Boudin et al., 2010" startWordPosition="4192" endWordPosition="4195">rage distribution of all PECO elements (i.e. the observed probability that a PECO element occurs in a document’ part, no matter which element it is). The second variant (named Model-2) uses a differentiated a, distribution for each type of PECO element. The idea is to see if, given the fact that PECO elements have different distributions in documents, using an adapted weight distribution for each element can improve the retrieval effectiveness. Previous studies have shown that assigning a different weight to each PECO element in the query leads to better results (Demner-Fushman and Lin, 2007; Boudin et al., 2010a). In order to compare our model with a similar method, we defined another baseline (named Baseline-3) by fixing the parameters P = 0 and -y = 0 in equation 2. We performed a grid search (from 0 to 1 by step of 0.1) to find the optimal b weights. Regarding the last three parameters in our full models, namely oc, P and -y, we conducted a second grid search to find their optimal values. Performance measures obtained in 10-fold cross-validation (optimizing the MAP measure) by these models are presented in Table 2. A significant improvement is obtained by the Baseline-3 over the keyword-based app</context>
</contexts>
<marker>Boudin, Shi, Nie, 2010</marker>
<rawString>Florian Boudin, Lixin Shi, and Jian-Yun Nie. 2010b. Improving Medical Information Retrieval with PICO Element Detection. In Proceedings of the ECIR 2010 conference, pages 50–61.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grace Y Chung</author>
</authors>
<title>Sentence retrieval for abstracts of randomized controlled trials.</title>
<date>2009</date>
<journal>BMC Medical Informatics and Decision Making,</journal>
<volume>9</volume>
<issue>1</issue>
<contexts>
<context position="8502" citStr="Chung, 2009" startWordPosition="1350" endWordPosition="1351">CO elements. This is due to the lack of standard definition for the element’ boundaries (e.g. can be words, phrases or sentences) but also to the existence of several levels of annotation. Indeed, there are a high number 109 of possible candidates for each element and one has to choose if it is a main element (i.e. playing a major role in the clinical study) or secondary elements. Second is the lack of sufficient annotated data that can be used to train automatic tagging tools. Despite all these difficulties, several efficient detection methods have been proposed (DemnerFushman and Lin, 2007; Chung, 2009). Nearly all of them are however restricted to a coarse-grain annotation level (i.e. tagging entire sentences as describing one element). This kind of coarser-grain identification is more robust and more feasible than the one at concept level, and it could be sufficient in the context of IR. In fact, for IR purposes, what is the most important is to correctly weight the words in documents and queries. From this perspective, an annotation at the sentence level may be sufficient. Notwithstanding, experiments conducted using a collection of documents that were annotated at a sentence-level only s</context>
</contexts>
<marker>Chung, 2009</marker>
<rawString>Grace Y. Chung. 2009. Sentence retrieval for abstracts of randomized controlled trials. BMC Medical Informatics and Decision Making, 9(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Owens Sheri Keitz Connie Schardt</author>
<author>Martha B Adams</author>
<author>Paul Fontelo</author>
</authors>
<title>Utilization of the PICO framework to improve searching PubMed for clinical questions.</title>
<date>2007</date>
<journal>BMC Medical Informatics and Decision Making,</journal>
<volume>7</volume>
<issue>1</issue>
<contexts>
<context position="22417" citStr="Schardt et al. (2007)" startWordPosition="3650" endWordPosition="3653">moothing parameter to µ = 2000. In all our experiments, we use the KL divergence scoring function (equation 1) as baseline. Statistical significance is computed using the well-known Student’s t-test. To determine reasonable weights and avoid overtuning the parameters, we use a 10-fold cross-validation optimizing the MAP values. 6.2 Experiments We first investigated the impact of using PECOstructured queries on the retrieval performance. As far as we know, no quantitative evaluation of the increase or decrease of performance in comparison with a keyword-based search strategy has been reported. Schardt et al. (2007) presented a comparison between PubMed and a PECO search interface but failed to demonstrate any significant difference between the two search protocols. The larger number of words in PECO-structured queries, on average 18.8 words per query compared to 4.3 words for keyword queries, should capture more aspects of the information need. But, it may also be a disadvantage due to the fact that more noise can be brought in, causing query-drift issues. We propose two baselines using the keywordbased queries. The first baseline (named Baseline1) uses keyword queries with the traditional language mode</context>
</contexts>
<marker>Schardt, Adams, Fontelo, 2007</marker>
<rawString>Thomas Owens Sheri Keitz Connie Schardt, Martha B Adams and Paul Fontelo. 2007. Utilization of the PICO framework to improve searching PubMed for clinical questions. BMC Medical Informatics and Decision Making, 7(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Dawes</author>
<author>Pierre Pluye</author>
<author>Laura Shea</author>
<author>Roland Grad</author>
<author>Arlene Greenberg</author>
<author>Jian-Yun Nie</author>
</authors>
<title>The identification of clinically important elements within medical journal abstracts:</title>
<date>2007</date>
<booktitle>PatientPopulationProblem, ExposureIntervention, Comparison, Outcome, Duration and Results (PECODR). Informatics in Primary care,</booktitle>
<pages>15--1</pages>
<contexts>
<context position="7643" citStr="Dawes et al., 2007" startWordPosition="1201" endWordPosition="1204">ns. This study demonstrates the value of the PECO framework as a method for structuring clinical questions. However, as the focus has been put on the postretrieval step (for question-answering), it is not clear whether PECO elements are useful at the retrieval step. Intuitively, the integration of PECO elements in the retrieval process can also lead to higher retrieval effectiveness. The most obvious scenario for testing this would be to recognize PECO elements in documents prior to indexing. When a PECO-structured query is formulated, it is matched against the PECO elements in the documents (Dawes et al., 2007). Nevertheless, the task of automatically identifying PECO elements is a very difficult one. There are two major reasons for that. First, previous studies have indicated that there is a low to moderate agreement rate among humans for annotating PECO elements. This is due to the lack of standard definition for the element’ boundaries (e.g. can be words, phrases or sentences) but also to the existence of several levels of annotation. Indeed, there are a high number 109 of possible candidates for each element and one has to choose if it is a main element (i.e. playing a major role in the clinical</context>
</contexts>
<marker>Dawes, Pluye, Shea, Grad, Greenberg, Nie, 2007</marker>
<rawString>Martin Dawes, Pierre Pluye, Laura Shea, Roland Grad, Arlene Greenberg, and Jian-Yun Nie. 2007. The identification of clinically important elements within medical journal abstracts: PatientPopulationProblem, ExposureIntervention, Comparison, Outcome, Duration and Results (PECODR). Informatics in Primary care, 15(1):9–16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Demner-Fushman</author>
<author>J Lin</author>
</authors>
<title>Answering clinical questions with knowledge-based and statistical techniques.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="6641" citStr="Demner-Fushman and Lin, 2007" startWordPosition="1037" endWordPosition="1040">organized as follows. We first briefly review the previous work, followed by a description of the test collection we have constructed. Next, we give the details of the method we propose and present our experiments and results. Lastly, we conclude with a discussion and directions for further work. 2 Related work The need to answer clinical questions related to a patient care using IR systems has been well studied and documented (Hersh et al., 2000; Niu et al., 2003; Pluye et al., 2005). There are a limited but growing number of studies trying to use the PECO elements in the retrieval process. (Demner-Fushman and Lin, 2007) is one of the few such studies, in which a series of knowledge extractors is used to detect PECO elements in documents. These elements are later used to re-rank a list of retrieved citations from PubMed. Results reported indicate that their method can bring relevant citations into higherranking positions, and from these abstracts generate responses that answer clinicians’ questions. This study demonstrates the value of the PECO framework as a method for structuring clinical questions. However, as the focus has been put on the postretrieval step (for question-answering), it is not clear whethe</context>
<context position="25739" citStr="Demner-Fushman and Lin, 2007" startWordPosition="4188" endWordPosition="4191">ion fixed according to the average distribution of all PECO elements (i.e. the observed probability that a PECO element occurs in a document’ part, no matter which element it is). The second variant (named Model-2) uses a differentiated a, distribution for each type of PECO element. The idea is to see if, given the fact that PECO elements have different distributions in documents, using an adapted weight distribution for each element can improve the retrieval effectiveness. Previous studies have shown that assigning a different weight to each PECO element in the query leads to better results (Demner-Fushman and Lin, 2007; Boudin et al., 2010a). In order to compare our model with a similar method, we defined another baseline (named Baseline-3) by fixing the parameters P = 0 and -y = 0 in equation 2. We performed a grid search (from 0 to 1 by step of 0.1) to find the optimal b weights. Regarding the last three parameters in our full models, namely oc, P and -y, we conducted a second grid search to find their optimal values. Performance measures obtained in 10-fold cross-validation (optimizing the MAP measure) by these models are presented in Table 2. A significant improvement is obtained by the Baseline-3 over </context>
</contexts>
<marker>Demner-Fushman, Lin, 2007</marker>
<rawString>D. Demner-Fushman and J. Lin. 2007. Answering clinical questions with knowledge-based and statistical techniques. Computational Linguistics, 33(1):63–103.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William R Hersh</author>
<author>Katherine Crabtree</author>
<author>David H Hickam</author>
<author>Lynetta Sacherek</author>
<author>Linda Rose</author>
<author>Charles P Friedman</author>
</authors>
<title>Factors associated with successful answering of clinical questions using an information retrieval system.</title>
<date>2000</date>
<journal>Bulletin of the Medical Library Association,</journal>
<volume>88</volume>
<issue>4</issue>
<contexts>
<context position="6462" citStr="Hersh et al., 2000" startWordPosition="1006" endWordPosition="1009">gh the importance of different types of element in search. As we will show 1www.pubmed.gov in this paper, this approach turns out to be highly effective. This paper is organized as follows. We first briefly review the previous work, followed by a description of the test collection we have constructed. Next, we give the details of the method we propose and present our experiments and results. Lastly, we conclude with a discussion and directions for further work. 2 Related work The need to answer clinical questions related to a patient care using IR systems has been well studied and documented (Hersh et al., 2000; Niu et al., 2003; Pluye et al., 2005). There are a limited but growing number of studies trying to use the PECO elements in the retrieval process. (Demner-Fushman and Lin, 2007) is one of the few such studies, in which a series of knowledge extractors is used to detect PECO elements in documents. These elements are later used to re-rank a list of retrieved citations from PubMed. Results reported indicate that their method can bring relevant citations into higherranking positions, and from these abstracts generate responses that answer clinicians’ questions. This study demonstrates the value </context>
</contexts>
<marker>Hersh, Crabtree, Hickam, Sacherek, Rose, Friedman, 2000</marker>
<rawString>William R. Hersh, Katherine Crabtree, David H. Hickam, Lynetta Sacherek, Linda Rose, and Charles P. Friedman. 2000. Factors associated with successful answering of clinical questions using an information retrieval system. Bulletin of the Medical Library Association, 88(4):323–331.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Larry McKnight</author>
<author>Padmini Srinivasan</author>
</authors>
<title>Categorization of sentence types in medical abstracts.</title>
<date>2003</date>
<booktitle>Proceedings of the AMIA annual symposium.</booktitle>
<contexts>
<context position="16020" citStr="McKnight and Srinivasan, 2003" startWordPosition="2548" endWordPosition="2551"> fairly reliable results. Moreover, a filtering process is applied to queries removing all non-informative words (e.g. stopwords, numbers, etc.) from being counted. There are several ways to look at the distribution of PECO elements in documents. One can use the rhetorical structure of abstracts to do that. However, the high granularity level of such analysis would make it less precise for IR purposes. Furthermore, most of the citations available in PubMed are devoid of explicitly marked sections. It is possible to automatically detect these sections but only with a non-negligible error rate (McKnight and Srinivasan, 2003). In our study, we chose to use a fixed number of partitions by dividing documents into parts of equal length. This choice is motivated by its repeatability and ease to implement, but also for comparison with previous studies. We divided each relevant document into 10 parts of equal length on a word level (from P1 to P10). We Number of systematic reviews 0 111 pendence, a simple estimate for P(w|Q) can be obtained by computing Maximum Likelihood Estimation (MLE). It is calculated as the number of times the word w appears in the query Q, divided by its length: P(w|Q) = |Q| A similar method is e</context>
</contexts>
<marker>McKnight, Srinivasan, 2003</marker>
<rawString>Larry McKnight and Padmini Srinivasan. 2003. Categorization of sentence types in medical abstracts. Proceedings of the AMIA annual symposium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Metzler</author>
<author>W Bruce Croft</author>
</authors>
<title>A Markov random field model for term dependencies.</title>
<date>2005</date>
<booktitle>In Proceedings of the SIGIR conference,</booktitle>
<pages>472--479</pages>
<contexts>
<context position="24264" citStr="Metzler and Croft, 2005" startWordPosition="3950" endWordPosition="3954">already indicated in queries by the conjunction and (e.g. vaccine and hepatitis B). A simple regular expression is used to recognize the phrases. Results are presented in Table 1. As expected, phrase-based retrieval leads to some increase in retrieval precision (P@5). However, the number of 113 relevant documents retrieved is decreased. This is due to the fact that we use exact phrase matching that can reduce query coverage. One solution would be to use unordered window features (Indri operator #uwn) that would require words to be close together but not necessarily in an exact sequence order (Metzler and Croft, 2005). The PECO queries use PECO-structured queries as a bag of words. We observe that PECO queries do not enhance the average precision but increase the P@5 significantly. The number of relevant documents retrieved is also larger. These results indicate that formulating clinical queries according to the PECO framework enhance the retrieval effectiveness. Model MAP P@5 #rel. ret. Baseline-1 0.129 0.151 5369 Baseline-2 0.128 0.161∗ 4645 PECO-queries 0.126 0.172∗ 5433 Table 1: Comparing the performance measures of keyword-based and PECO-structured queries in terms of MAP, precision at 5 and number of</context>
</contexts>
<marker>Metzler, Croft, 2005</marker>
<rawString>Donald Metzler and W. Bruce Croft. 2005. A Markov random field model for term dependencies. In Proceedings of the SIGIR conference, pages 472–479.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yun Niu</author>
<author>Graeme Hirst</author>
<author>Gregory McArthur</author>
<author>Patricia Rodriguez-Gianolli</author>
</authors>
<title>Answering clinical questions with role identification.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL 2003 Workshop on Natural Language Processing in Biomedicine,</booktitle>
<pages>73--80</pages>
<contexts>
<context position="6480" citStr="Niu et al., 2003" startWordPosition="1010" endWordPosition="1013"> different types of element in search. As we will show 1www.pubmed.gov in this paper, this approach turns out to be highly effective. This paper is organized as follows. We first briefly review the previous work, followed by a description of the test collection we have constructed. Next, we give the details of the method we propose and present our experiments and results. Lastly, we conclude with a discussion and directions for further work. 2 Related work The need to answer clinical questions related to a patient care using IR systems has been well studied and documented (Hersh et al., 2000; Niu et al., 2003; Pluye et al., 2005). There are a limited but growing number of studies trying to use the PECO elements in the retrieval process. (Demner-Fushman and Lin, 2007) is one of the few such studies, in which a series of knowledge extractors is used to detect PECO elements in documents. These elements are later used to re-rank a list of retrieved citations from PubMed. Results reported indicate that their method can bring relevant citations into higherranking positions, and from these abstracts generate responses that answer clinicians’ questions. This study demonstrates the value of the PECO framew</context>
</contexts>
<marker>Niu, Hirst, McArthur, Rodriguez-Gianolli, 2003</marker>
<rawString>Yun Niu, Graeme Hirst, Gregory McArthur, and Patricia Rodriguez-Gianolli. 2003. Answering clinical questions with role identification. In Proceedings of the ACL 2003 Workshop on Natural Language Processing in Biomedicine, pages 73–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Pluye</author>
<author>Roland M Grad</author>
<author>Lynn G Dunikowski</author>
<author>Randolph Stephenson</author>
</authors>
<title>Impact of clinical information-retrieval technology on physicians: a literature review of quantitative, qualitative and mixed methods studies.</title>
<date>2005</date>
<journal>International Journal of Medical Informatics,</journal>
<volume>74</volume>
<issue>9</issue>
<contexts>
<context position="6501" citStr="Pluye et al., 2005" startWordPosition="1014" endWordPosition="1017">f element in search. As we will show 1www.pubmed.gov in this paper, this approach turns out to be highly effective. This paper is organized as follows. We first briefly review the previous work, followed by a description of the test collection we have constructed. Next, we give the details of the method we propose and present our experiments and results. Lastly, we conclude with a discussion and directions for further work. 2 Related work The need to answer clinical questions related to a patient care using IR systems has been well studied and documented (Hersh et al., 2000; Niu et al., 2003; Pluye et al., 2005). There are a limited but growing number of studies trying to use the PECO elements in the retrieval process. (Demner-Fushman and Lin, 2007) is one of the few such studies, in which a series of knowledge extractors is used to detect PECO elements in documents. These elements are later used to re-rank a list of retrieved citations from PubMed. Results reported indicate that their method can bring relevant citations into higherranking positions, and from these abstracts generate responses that answer clinicians’ questions. This study demonstrates the value of the PECO framework as a method for s</context>
</contexts>
<marker>Pluye, Grad, Dunikowski, Stephenson, 2005</marker>
<rawString>Pierre Pluye, Roland M. Grad, Lynn G. Dunikowski, and Randolph Stephenson. 2005. Impact of clinical information-retrieval technology on physicians: a literature review of quantitative, qualitative and mixed methods studies. International Journal of Medical Informatics, 74(9):745–768.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay M Ponte</author>
<author>W Bruce Croft</author>
</authors>
<title>A language modeling approach to information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the SIGIR conference,</booktitle>
<pages>275--281</pages>
<contexts>
<context position="18997" citStr="Ponte and Croft, 1998" startWordPosition="3064" endWordPosition="3067">g that first and last parts of the documents have higher chance to contain these elements. This gives us a clear and robust indication on which specific parts should be enhanced when searching for a given element. Our proposed model will exploit the typical distributions of PECO elements in documents. Figure 2: Distribution of each PECO element throughout the different parts of the documents. 5 Retrieval Method In this work, we use the language modeling approach to information retrieval. This approach assumes that queries and documents are generated from some probability distribution of text (Ponte and Croft, 1998). Under this assumption, ranking a document D as relevant to a query Q is seen as estimating P(Q|D), the probability that Q was generated by the same distribution as D. A typical way to score a document D as relevant to a query Q is to compute the Kullback-Leibler divergence between their respective language models: �ScoTe(Q, D) = P(w|Q) · log P(w|D) (1) wEQ Under the traditional bag-of-words assumption, i.e. assuming that there is no need to model term deP elements E elements P1 P2 P3 P4 P5 P6 P] P8 P9 P10 C elements P1 P2 P3 P4 P5 P6 P] P8 P9 P10 P1 P2 P3 P4 P5 P6 P] P8 P9 P10 O elements P1 </context>
</contexts>
<marker>Ponte, Croft, 1998</marker>
<rawString>Jay M. Ponte and W. Bruce Croft. 1998. A language modeling approach to information retrieval. In Proceedings of the SIGIR conference, pages 275–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott W Richardson</author>
<author>Mark C Wilson</author>
<author>Jim Nishikawa</author>
<author>Robert S Hayward</author>
</authors>
<title>The well-built clinical question: a key to evidence-based decisions.</title>
<date>1995</date>
<journal>ACP Journal Club,</journal>
<volume>123</volume>
<issue>3</issue>
<contexts>
<context position="2319" citStr="Richardson et al. (1995)" startWordPosition="336" endWordPosition="339">mely manner. A better access to clinical evidence represents a high impact application for physicians. Evidence-Based Medicine (EBM) is a widely accepted paradigm for medical practice (Sackett et al., 1996). EBM is defined as the conscientious, explicit and judicious use of current best evidence in making decisions about patient care. Practice EBM means integrating individual clinical expertise with the best available external clinical evidence from systematic research. It involves tracking down the best evidence from randomized trials or meta-analyses with which to answer clinical questions. Richardson et al. (1995) identified the following four aspects as the key elements of a well-built clinical question: • Patient-problem: what are the patient characteristics (e.g. age range, gender, etc.)? What is the primary condition or disease? • Exposure-intervention: what is the main intervention (e.g. drug, treatment, duration, etc.)? • Comparison: what is the exposure compared to (e.g. placebo, another drug, etc.)? • Outcome: what are the clinical outcomes (e.g. healing, morbidity, side effects, etc.)? These elements are known as the PECO elements. Physicians are educated to formulate their clinical questions </context>
</contexts>
<marker>Richardson, Wilson, Nishikawa, Hayward, 1995</marker>
<rawString>Scott W. Richardson, Mark C. Wilson, Jim Nishikawa, and Robert S. Hayward. 1995. The well-built clinical question: a key to evidence-based decisions. ACP Journal Club, 123(3):A12–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David L Sackett</author>
<author>William Rosenberg</author>
<author>J A Muir Gray</author>
<author>Brian Haynes</author>
<author>W Scott Richardson</author>
</authors>
<title>Evidence based medicine: what it is and what it isn’t. British medical journal,</title>
<date>1996</date>
<pages>312--71</pages>
<contexts>
<context position="1901" citStr="Sackett et al., 1996" startWordPosition="276" endWordPosition="279">n In recent years, the volume of health and biomedical literature available in electronic form has grown exponentially. MEDLINE, the authoritative repository of citations from the medical and bio-medical domain, contains more than 18 million citations. Searching for clinically relevant information within this large amount of data is a difficult task that medical professionals are often unable to complete in a timely manner. A better access to clinical evidence represents a high impact application for physicians. Evidence-Based Medicine (EBM) is a widely accepted paradigm for medical practice (Sackett et al., 1996). EBM is defined as the conscientious, explicit and judicious use of current best evidence in making decisions about patient care. Practice EBM means integrating individual clinical expertise with the best available external clinical evidence from systematic research. It involves tracking down the best evidence from randomized trials or meta-analyses with which to answer clinical questions. Richardson et al. (1995) identified the following four aspects as the key elements of a well-built clinical question: • Patient-problem: what are the patient characteristics (e.g. age range, gender, etc.)? </context>
</contexts>
<marker>Sackett, Rosenberg, Gray, Haynes, Richardson, 1996</marker>
<rawString>David L. Sackett, William Rosenberg, J. A. Muir Gray, Brian Haynes, and W. Scott Richardson. 1996. Evidence based medicine: what it is and what it isn’t. British medical journal, 312:71–72.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>