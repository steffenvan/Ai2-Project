<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000020">
<title confidence="0.84086">
Indonesian-Japanese CLIR Using Only Limited Resource
</title>
<author confidence="0.97653">
Ayu Purwarianti Masatoshi Tsuchiya Seiichi Nakagawa
</author>
<affiliation confidence="0.984027">
Department of Information and Computer Science, Toyohashi University of Technology
</affiliation>
<email confidence="0.978866">
ayu@slp.ics.tut.ac.jp tsuchiya@imc.tut.ac.jp nakagawa@slp.ics.tut.ac.jp
</email>
<sectionHeader confidence="0.9972" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999916793103448">
Our research aim here is to build a CLIR
system that works for a language pair
with poor resources where the source
language (e.g. Indonesian) has limited
language resources. Our Indonesian-
Japanese CLIR system employs the
existing Japanese IR system, and we
focus our research on the Indonesian-
Japanese query translation. There are two
problems in our limited resource query
translation: the OOV problem and the
translation ambiguity. The OOV problem
is handled using target language’s
resources (English-Japanese dictionary
and Japanese proper name dictionary).
The translation ambiguity is handled
using a Japanese monolingual corpus in
our translation filtering. We select the
final translation set using the mutual
information score and the TF×IDF score.
The result on NTCIR 3 (NII-NACSIS
Test Collection for IR Systems) Web
Retrieval Task shows that the translation
method achieved a higher IR score than
the transitive machine translation (using
Kataku (Indonesian-English) and
Babelfish/ Excite (English-Japanese)
engine) result. The best result achieved
about 49% of the monolingual retrieval.
</bodyText>
<sectionHeader confidence="0.999162" genericHeader="keywords">
1 Introductions
</sectionHeader>
<bodyText confidence="0.999948081967214">
Due to the various languages used by different
nations in the world, the CLIR has been an
interesting research topic. For language pair with
a rich language resource, the translation in the
CLIR can be done with a bilingual dictionary -
based direct translation, machine translation - or
a parallel corpus - based translation. For a rare
language pair, there is an attempt to use a pivot
language (usually English), known as transitive
translation, because there is no ample bilingual
dictionary or machine translation system
available. Some studies have been done in the
field of transitive translation using bilingual
dictionaries in the CLIR system such as
[Ballesteros 2000; Gollins and Sanderson 2001].
Ballesteros [2000] translated Spanish queries
into French with English as the interlingua.
Ballesteros used Collins Spanish-English and
English-French dictionaries. Gollins and
Sanderson [2001] translated German queries into
English using two pivot languages (Spanish and
Dutch). Gollins used the Euro Wordnet as a data
resource. To our knowledge, no CLIR is
available with transitive translation for a source
language with poor data resources such as
Indonesian.
Translation using a bilingual dictionary
usually provides many translation alternatives
only a few of which are appropriate. A transitive
translation gives more translation alternatives
than a direct translation. In order to select the
most appropriate translation, a monolingual
corpus can be used to select the best translation.
Ballesteros and Croft [1998] used an English
corpus to select some English translation based
on Spanish-English translation and analyzed the
co-occurrence frequencies to disambiguate
phrase translations. The occurrence score is
called the em score. Each set is ranked by em
score, and the highest ranking set is taken as the
final translation. Gao et al. [2001] used a Chinese
corpus to select the best English-Chinese
translation set. It modified the EMMI weighting
measure to calculate the term coherence score.
Qu et al. [2002] selected the best Spanish-
English and Chinese-English translation using an
English corpus. The coherence score calculation
was based on 1) web page count; 2) retrieval
score; and 3) mutual information score. Mirna
[2001] translated Indonesian into English and
used an English monolingual corpus to select the
best translation, employing a term similarity
score based on the Dice similarity coefficient.
Federico and Bertoldi [2002] combined the N-
best translation based on an HMM model of a
query translation pair and relevant document
probability of the input word to rank Italian
documents retrieved by English query. Kishida
and Kando [2004], used all terms to retrieve a
document in order to obtain the best term
combination and chose the most frequent term in
</bodyText>
<page confidence="0.825999">
1
</page>
<note confidence="0.704073">
Proceedings of the Workshop on How Can Computational Linguistics Improve Information Retrieval?, pages 1–8,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.981586375">
each term translation set that appears in the top
ranked document.
In our poor resource language – Japanese
CLIR where we select Indonesian as the source
language with limited resource, we calculate the
mutual information score for each Japanese
translation combination, using a Japanese
monolingual corpus. After that, we select one
translation combination with the highest TF×IDF
score obtained from the Japanese IR engine.
By our experiments on Indonesian-Japanese
CLIR, we would like to show how easy it is to
build a CLIR for a restricted language resource.
By using only an Indonesian (as the source
language) – English dictionary we are able to
retrieve Japanese documents with 41% of the
performance achieved by the monolingual
Japanese IR system.
The rest of the paper is organized as follows:
Section 2 presents an overview of an Indonesian
query sentence; Section 3 discusses the method
used for our Indonesian-Japanese CLIR; Section
4 describes the comparison methods, and Section
5 presents our experimental data and the results.
</bodyText>
<sectionHeader confidence="0.974844" genericHeader="introduction">
2 Indonesian Query Sentence
</sectionHeader>
<bodyText confidence="0.999713679245283">
Indonesian is the official language in Indonesia.
The language is understood by people in
Indonesia, Malaysia, and Brunei. The Indonesian
language family is Malayo-Polynesian
(Austronesian), which extends across the islands
of Southeast Asia and the Pacific [Wikipedia].
Indonesian is not related to either English or
Japanese.
Unlike other languages used in Indonesia
such as Javanese, Sundanese and Balinese that
use their own scripts, Indonesian uses the
familiar Roman script. It uses only 26 letters as
in the English alphabet. A transliteration module
is not needed to translate an Indonesian sentence.
Indonesian language does not have
declensions or conjugations. The basic sentence
order is Subject-Verb-Object. Verbs are not
inflected for person or number. There are no
tenses. Tense is denoted by the time adverb or
some other tense indicators. The time adverb can
be placed at the front or end of the sentence.
A rather complex characteristic of the
Indonesian language is that it is an agglutinave
language. Words in Indonesian, usually verbs,
can be attached by many prefixes or suffixes.
Affixes used in the Indonesian language include
[Kosasih 2003] me(n)-, ber-, di-, ter-, pe(n)-, per-,
se-, ke-, -el-, -em-, -er-, -kan, -i, -nya, -an, me(n)-
kan, di-kan, memper-i, diper-i, ke-an, pe(n)-an,
per-an, ber-an, ber-kan, se-nya. Words with
different affixes might have uniform or different
translation. Examples of different word
translation are “membaca” and “pembaca”,
which are translated into “read” and “reader”,
respectively. Examples of same word translation
are the words “baca” and “bacakan”, which are
both translated into “read” in English. Other
examples are the words “membaca” and “dibaca”,
which are translated into “read” and “being read”,
respectively. By using a stop word elimination,
the translation result of “membaca” and “dibaca”
will give the same English translation, “read”.
An Indonesian dictionary usually contains
words with affixes (that have different
translations) and base words. For example, “se-
nya” affix declares a “most possible” pattern,
such as “sebanyak-banyaknya” (as much as
possible), “sesedikit-sedikitnya” (less possible),
“sehitam-sehitamnya” (as black as possible).
This affix can be attached to many adjectives
with the same meaning pattern. Therefore, words
with “se-nya” affix are usually not included in an
Indonesian dictionary.
</bodyText>
<figure confidence="0.928944333333333">
Query 1
Saya ingin mengetahui siapa yang telah menjadi peraih
Academy Awards beberapa generasi secara berturut-turut
(I want to know who have been the recipients of successive
generations of Academy Awards)
Query 2
Temukan buku-buku yang mengulas tentang novel yang
ditulis oleh Miyabe Miyuki
(Find book reviews of novels written by Miyabe Miyuki)
</figure>
<figureCaption confidence="0.999847">
Figure 1. Indonesian Query Examples
</figureCaption>
<bodyText confidence="0.999910692307692">
Indonesian sentences usually consist of
native (Indonesian) words and borrowed words.
The two query examples in Figure 1 contain
borrowed words. The first query contains
“Academy Awards”, which is borrowed from the
English language. The second query contains
“Miyabe Miyuki”, which is transliterated from
Japanese. To obtain a good translation, the query
translation in our system must be able to translate
those words, the Indonesian (native) words and
the borrowed words. Problems that occur in a
query translation here include OOV words and
translation ambiguity.
</bodyText>
<sectionHeader confidence="0.89366" genericHeader="method">
3 Indonesian - Japanese Query
Translation System
</sectionHeader>
<bodyText confidence="0.993883666666667">
Indonesian-Japanese query translation is a
component of the Indonesian-Japanese CLIR.
The query translation system aims to translate an
</bodyText>
<page confidence="0.988313">
2
</page>
<bodyText confidence="0.999821833333333">
Indonesian query sentence(s) into a Japanese
keyword list. The Japanese keyword list is then
executed in the Japanese IR system to retrieve
the relevant document. The schema of the
Indonesian-Japanese query translation system
can be seen in Figure 2.
</bodyText>
<figure confidence="0.682937">
Candidates for Japanese Translation
Translation Candidate Filtering
Japanese Translation
</figure>
<figureCaption confidence="0.938933">
Figure 2. Indonesian-Japanese Query
Translation Schema
</figureCaption>
<bodyText confidence="0.999789636363636">
The query translation system consists of 2
subsystems: the keyword translation and
translation candidate filtering. The keyword
translation system seeks to obtain Japanese
translation candidates for an Indonesian query
sentence. The translation candidate filtering aims
to select the most appropriate translation among
all Japanese translation alternatives. The filtering
result is used as the input for the Japanese IR
system. The keyword translation and translation
filtering process is described in the next section.
</bodyText>
<subsectionHeader confidence="0.9902545">
3.1 Indonesian – Japanese Key Word
Translation Process
</subsectionHeader>
<bodyText confidence="0.999968125">
The keyword translation system is a process used
to translate Indonesian keywords into Japanese
keywords. In this research, we do transitive
translation using bilingual dictionaries as the
proposed method. Other approaches such as
direct translation or machine translation are
employed for the comparison method. The
schema of our keyword transitive translation
using bilingual dictionaries is shown in Figure 3.
The keyword translation process consists of
native (Indonesian) word translation and
borrowed word translation. The native words are
translated using Indonesian-English and English-
Japanese dictionaries. Because the Indonesian
tag parser is not available, we do the translation
on a single word and consecutive pair of words
that exist as a single term in the Indonesian-
English dictionary. As mentioned in the previous
section dealing with affix combination in
Indonesian language, not all words with the affix
combination are recorded in an Indonesian
dictionary. Therefore, if a search does not reveal
the exact word, it will search for other words that
are the basic term of the query word or have the
same basic term. For example, the Indonesian
word, “munculnya” (come out), has a basic term
“muncul” with the postfix “-nya”. Here, the term
“munculnya” is not available in the dictionary.
Therefore, the searching will take “muncul” as
the matching word with “munculnya” and give
the English translation for “muncul” such as
“come out” as its translation result.
</bodyText>
<figure confidence="0.594982583333333">
Indonesian sentence query
Indonesian words borrowed words
• English – Japanese Bilingual
Dictionary Translation
• Japanese Proper Name
Dictionary Translation
• Hiragana/Katakana
Transliteration
Japanese Keyword List
Japanese Morphological Analyzer (Chasen)
Japanese Stop Word Elimination
Candidates for Japanese Translation
</figure>
<figureCaption confidence="0.99825">
Figure 3. Indonesian-Japanese Keyword
</figureCaption>
<bodyText confidence="0.997438896551724">
Translation Schema
In Indonesian, a noun phrase has the reverse
word position of that in English. For example,
“ozone hole” is translated as “lubang ozon”
(ozone=ozon, hole=lubang) in Indonesian.
Therefore, in English translation, besides word-
by-word translation, we also search for the
reversed English word pair as a single term in an
English-Japanese dictionary. This strategy
reduces the number of translation alternatives.
The borrowed words are translated using an
English-Japanese dictionary. The English-
Japanese dictionary is used because most of the
borrowed words in our query translation system
come from English. Examples of borrowed
words in our query are “Academy Awards”,
“Aurora”, “Tang”, “baseball”, “Plum”, “taping”,
and “Kubrick”.
Even though using an English-Japanese
dictionary may help with accurate translation of
words, but there are some proper names which
can not be translated by this dictionary, such as
“Miyabe Miyuki”, “Miyazaki Hayao”, “Honjo
Manami”, etc. These proper names come from
Japanese words which are romanized. In the
Japanese language, these proper names might be
written in one of the following scripts: kanji
(Chinese character), hiragana, katakana and
romaji (roman alphabet). One alphabet word can
</bodyText>
<figure confidence="0.99581775">
Indonesian sentence query
Indonesian – Japanese
Keyword Translation
Indonesian – English
Bilingual Dictionary
English – Japanese
Bilingual Dictionary
Translation
</figure>
<page confidence="0.983754">
3
</page>
<bodyText confidence="0.999859333333334">
be transliterated into more than one Japanese
words. For example, “Miyabe” can be
transliterated into , , or .
and are written in kanji, is
written in hiragana, and is written in
katakana. For hiragana and katakana script, the
borrowed word is translated by using a pair list
between hiragana or katakana and its roman
alphabet. These systems have a one-to-one
correspondence for pronunciation (syllables or
phonemes), something that can not be done for
kanji. Therefore, to find the Japanese word in
kanji corresponding to borrowed words, we use a
Japanese proper name dictionary. Each term in
the original proper name dictionary usually
consists of two words, the first and last names.
For a wider selection of translation candidates,
we separate each term with two words into two
terms. Even though the input word can not be
found in the original proper name dictionary
(family name and first name), a match may still
be possible with the new proper name dictionary.
Each of the above translation processes also
involves the stop word elimination process,
which aims to delete stop words or words that do
not have significant meaning in the documents
retrieved. The stop word elimination is done at
every language step. First, Indonesian stop word
elimination is applied to a Indonesian query
sentence to obtain Indonesian keywords. Second,
English stop word elimination is applied before
English keywords are translated into Japanese
keywords. Finally, Japanese stop word
elimination is done after the Japanese keywords
are morphologically analyzed by Chasen
(http://chasen.naist.jp/hiki/ChaSen).
The keyword transitive translation is used in
2 systems: 1) transitive translation to translate all
words in the query, and 2) transitive translation
to translate OOV (Indonesian) words from direct
translation using an Indonesian-Japanese
dictionary. We label the first method as the
transitive translation using bilingual dictionary
and the second method as the combined
translation (direct-transitive).
</bodyText>
<subsectionHeader confidence="0.999216">
3.2 Candidate Filtering Process
</subsectionHeader>
<bodyText confidence="0.959032115384615">
The keyword transitive translation results in
many more translation candidates than the direct
translation result. The candidates have a
translation ambiguity problem which will be
handled by our Japanese translation candidate
filtering process, which seeks to select the most
appropriate translation among the Japanese
translation candidates. In order to select the best
Japanese translation, rather than choosing only
the highest TFIIDF score or only the highest
mutual information score among all sets, we
combine both scores. The procedure is as
follows:
1. Calculate the mutual information score for
all term sets. To avoid calculation of all term
sets, we calculate the mutual information
score iteratively. First we calculate it for 2
translation candidate sets. Then we select
100 sets with the highest mutual information
score. These sets are joined with the 3rd
translation candidate sets and the mutual
information score is recalculated. This step is
repeated until all translation candidate sets
are covered.
For a word set, the mutual information score
is shown in Equation 1.
</bodyText>
<equation confidence="0.99004">
n−1 n
I(t1...tn) =∑∑ I(ti;tj)
</equation>
<bodyText confidence="0.779934615384615">
I(t1...tn) means the mutual information for a
set of words t1, t2,...tn. I(ti,tj) means the
mutual information between two words (ti,tj).
Here, for a zero frequency word, it will have
no impact on the mutual information score of
a word set.
2. Select 5 sets with highest mutual information
score and execute them into the IR engine in
order to obtain the TFIIDF scores. The TF
IIDF score used here is the relevance score
between the document and the query
(Equation (2) from Fujii and Ishikawa
[2003]).
</bodyText>
<equation confidence="0.999408727272727">
⎛ ⎞
⎜ ⎟
⎜TF N
t,i ⎟
.log
⎜ DL ⎟
∑ DF
i (2)
⎜ + TF t ⎟
t,i
t ⎝ avglen ⎠
</equation>
<bodyText confidence="0.999664625">
TFt,i denotes the frequency of term t
appearing in document i. DFt denotes the
number of documents containing term t. N
indicates the total number of documents in
the collection. DLi denotes the length of
document i (i.e., the number of characters
contained in i), and avglen the average
length of documents in the collection.
</bodyText>
<listItem confidence="0.876463666666667">
3. Select the term set with the highest mutual
information score among 3 top TF I IDF
scores
</listItem>
<bodyText confidence="0.944606">
Figure 4 shows an example of the keyword
selection process after completion of the
</bodyText>
<equation confidence="0.961444428571429">
i =1 j=i+1
n−1
=∑∑ P
i = = +
1 1log (t ).log (t)
P
j i i j
n lo
(1)
,
)
tj
g (t
P i
</equation>
<page confidence="0.925718">
4
</page>
<bodyText confidence="0.9986413">
keyword translation process. The translation
combination and set rankings are for all words (4
translation sets) in the query. Actually, the
translation combinations and sets for the query
example are also ranked for 2 and 3 translation
sets. All resulting sets (ranked by its mutual
information score) are executed in the IR system
in order to obtain the TF×IDF score. The final
query chosen is the one with the highest TF×
IDF score.
</bodyText>
<figureCaption confidence="0.970556">
Figure 4. Illustration of Translation Filtering
</figureCaption>
<bodyText confidence="0.632272">
Method
</bodyText>
<sectionHeader confidence="0.999805" genericHeader="method">
4 Compared Methods
</sectionHeader>
<bodyText confidence="0.999968833333333">
In the experiment, we compare our proposed
method with other translation methods. Methods
for comparing Indonesian-Japanese query
translation include transitive translation using
MT (machine translation), direct translation
using existing Indonesian-Japanese dictionary,
direct translation using a built-in Indonesian-
Japanese dictionary, transitive translation with
English keyword selection based on mutual
information taken from English corpus, and
transitive translation with Japanese keyword
selection based on mutual information only.
</bodyText>
<subsectionHeader confidence="0.750074">
4.1 Transitive Translation using Machine
Translation
</subsectionHeader>
<bodyText confidence="0.999832666666667">
The first method compared is a transitive
translation using MT (machine translation). The
Indonesian- Japanese transitive translation using
MT has a schema similar to Indonesian-Japanese
transitive translation using a bilingual dictionary.
However, machine transitive translation does not
use Indonesian-English and English-Japanese
dictionaries. Indonesian queries are translated
into English queries using an online Indonesian-
English MT (Kataku engine,
http://www.toggletext.com). The English
translation results are then translated into
Japanese using 2 online MTs (Babelfish engine,
http://www.altavista.com/babelfish and Excite
engine, http://www.excite.co.jp/world).
</bodyText>
<subsectionHeader confidence="0.733215">
4.2 Direct Translation using Existing
</subsectionHeader>
<sectionHeader confidence="0.775697" genericHeader="method">
Indonesian-Japanese Bilingual
Dictionary
</sectionHeader>
<bodyText confidence="0.999861454545455">
The second method compared is a direct
translation using an Indonesian-Japanese
dictionary. This direct translation also has a
schema similar to the transitive translation using
bilingual dictionary (Figure 2). The difference is
that in translation of an Indonesian keyword,
only 1 dictionary is used, rather than using 2
dictionaries; in this case, an Indonesian-Japanese
bilingual dictionary with a fewer words than the
Indonesian-English and English-Japanese
dictionaries.
</bodyText>
<subsectionHeader confidence="0.933632">
4.3 Direct Translation using Built-in
Indonesian-Japanese Dictionary
</subsectionHeader>
<bodyText confidence="0.999948315789474">
We also compare the transitive translation results
with the direct translation using a built-in
Indonesian-Japanese dictionary. The Indonesian-
Japanese dictionary is built from Indonesian-
English, English-Japanese and Japanese-English
dictionaries using “one-time inverse
consultation” such as in Tanaka and Umemura
[1998]. The matching process is similar with that
in query translation. A Japanese translation is
searched for an English translation (from every
Indonesian term in Indonesian-English
dictionary) as a term in the Japanese-English
dictionary. If no match can be found, the English
terms will be normalized by eliminating certain
stop words (“to”, “a”, “an”, “the”, “to be”, “kind
of”). These normalized English terms will be
checked again in the Japanese-English dictionary.
For every Japanese translation, a “one-time
inverse consultation” is calculated. If the score is
</bodyText>
<figure confidence="0.973686222222222">
Query:
Saya ingin mengetahui metode untuk belajar
bagaimana menari salsa (= I wanted to know the
method of studying how to dance the salsa)
Keyword Selection:
Metode (method), belajar (to learn, to study, to take
up), menari (dance), salsa
Japanese Keyword:
Metode: , , ,
Belajar: , , , , , , ,
, , , , , ,
Menari: , , , , ,
,
Salsa:
Translation Combination:
( , , , )
( , , , )
(
, , , ), etc
Rank sets based on Mutual Information Score:
1. ( , , , )
2. ( , , , )
3. ( , , , )
4. ( , , , )
5. ( , , , )
Select query with highest TF IDF score
, , ,
</figure>
<page confidence="0.95721">
5
</page>
<bodyText confidence="0.999843">
more than one (for more than one English term),
then it is accepted as an Indonesian-Japanese pair.
If not, the WordNet is used to find its synonym
and recalculate the “one-time inverse
consultation” score so as to compensate for the
poor quality of Indonesian-English dictionary
(29054 words).
</bodyText>
<sectionHeader confidence="0.999907" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<subsectionHeader confidence="0.997618">
5.1 Experimental Data
</subsectionHeader>
<bodyText confidence="0.996594285714286">
We measure our query translation performance
by the IR score achieved by a CLIR system
because CLIR is a real application and includes
the performance of key word expansion. For this,
we do not use word translation accuracy, as for
the CLIR, since a one-to-one translation rate is
not suitable, given there are so many
semantically equivalent words.
Our CLIR experiments are conducted on
NTCIR-3 Web Retrieval Task data (100 Gb
Japanese documents), in which the Japanese
queries and translated English queries were
prepared. The Indonesian queries (47 queries)
are manually translated from English queries.
The 47 queries contain 528 Indonesian words
(225 are not stop words), 35 English borrowed
words, and 16 transliterated Japanese words
(proper nouns). The IR system (Fujii and
Ishikawa [2003]) is borrowed from Atsushi Fujii
(Tsukuba University). External resources used in
the query translation are listed in Table 1.
</bodyText>
<tableCaption confidence="0.996576">
Table 1. External Resource List
</tableCaption>
<table confidence="0.999189130434783">
Resource Description
KEBI Indonesian-English
dictionary, 29,054 words
Eijirou English-Japanese dictionary,
556,237 words
Kmsmini2000 Indonesian-Japanese
dictionary, 14,823 words
ToggleText Kataku Indonesian-English machine
translation
Excite English-Japanese machine
translation
Babelfish English-Japanese machine
translation
[Fox, 1989] and English stop words (are also
[Zu et al., 2004] translated into Indonesian
stop words)
Chasen Japanese morphological
analyzer
Jinmei Jisho Japanese proper name
dictionary, 61,629 words
Mainichi Shinbun Japanese newspaper corpus
&amp; Online Yomiuri
Shinbun
</table>
<subsectionHeader confidence="0.996051">
5.2 Experimental Result
</subsectionHeader>
<bodyText confidence="0.999935071428572">
In the experiments, we compare the IR score of
each translation method. The IR scores shown in
this section are in Mean Average Precision
(MAP) scores. The evaluation metrics is referred
to [Fujii and Ishikawa 2003b]. Each query group
has 4 MAP scores: RL (highly relevant
document as correct answer with hyperlink
information used), RC (highly relevant document
as correct answer), PL (partially relevant
document as correct answer with hyperlink
information used), and PC (partially relevant
document as correct answer). The documents
hyperlinked from retrieved documents are used
for relevance assessment.
</bodyText>
<figureCaption confidence="0.998942833333333">
Figure 5. Baseline Indonesian-Japanese CLIR
Figure 5 shows the IR scores of queries
translated using basic translation methods such
as the bilingual dictionary or machine translation,
without any enhanced process. The labels used in
Figure 5 are:
</figureCaption>
<listItem confidence="0.9544641">
• jp (monolingual translation), where “jp”
denotes Japanese query
• iej (transitive translation using bilingual
dictionary), where “i”, “e”, “j” denote
Indonesian, English and Japanese, respectively,
• iej-mx (transitive machine translation using
Kataku and Excite engines), where “m”
denotes machine translation,
• iej-mb (transitive machine translation using
Kataku and Babelfish engines),
• ijn (direct translation using the built in
Indonesian-Japanese dictionary),
• ij (direct translation using Indonesian-Japanese
dictionary),
• ij-iej (combination of direct (ij) and transitive
(iej) translation using bilingual dictionary).
The highest CLIR score in the baseline
translation (without the enhancement process)
achieves 30% of the performance achieved by
the monolingual IR (jp).
</listItem>
<bodyText confidence="0.9965896">
IR results in Figure 6 shows that OOV
translation does improve the retrieval result.
Here, our proposed methods (iej and ij-iej)
achieve lower score than the comparison
methods.
</bodyText>
<figure confidence="0.9962882">
0.14
0.12
0.08
0.06
0.04
0.02
0.1
0
jp iej-mx iej-mb ijn ij iej ij-iej
PC PL RC RL
</figure>
<page confidence="0.719196">
6
</page>
<figureCaption confidence="0.91585175">
Figure 6. Indonesian-Japanese CLIR with OOV
Translation
Figure 7. Indonesian-Japanese CLIR with OOV
Translation and Keyword Filtering
Figure 7 shows the MAP score on the
proposed Indonesian-Japanese CLIR. The
keyword selection description of each query
label follows:
</figureCaption>
<listItem confidence="0.994062714285714">
• In (n = 1 .. 5): one query candidate based on
mutual information score; example: I2 means
the 2nd ranked query by its mutual information
score.
• I-n (n = 3,5,10): combination of the n-best
query candidates based on mutual information
score; example: iej-3 (disjuncture of the 3-best
mutual information score candidates).
• IR: the 1-best query candidate based on
combination of mutual information score and
TF × IDF engine score. X in IR-X shows
number of combinations. For example, IR-5
means the highest TF×IDF score among 5
highest mutual information score sets.
</listItem>
<figureCaption confidence="0.864329">
Figure 7 shows that the proposed filtering
</figureCaption>
<bodyText confidence="0.975320181818181">
method yields higher IR score on the transitive
translation. We achieve 41% of the performance
achieved by the monolingual IR. The proposed
transitive translation (iej-IR-10) improves the IR
score of the baseline method of transitive
translation (iej) from 0.0156 to 0.0512. The t-test
shows that iej-IR-10 significantly increases the
baseline method (iej) with a 97% confidence
level, T(68) = 1.91, p&lt;0.03. t-test also shows that,
compared to other baseline systems, the
proposed transitive translation (iej-IR-10) can
significantly increase the IR score at 85% (T(84)
= 1.04, p&lt;0.15), 69% (T(86) = 0.49, p&lt;0.31),
91% (T(83) = 1.35, p&lt;0.09), and 93% (T(70) =
1.49, p&lt;0.07) confidence level for iej-mb, iej-mx,
ij and ij-iej, respectively. Another proposed
method, a combination of direct and transitive
translation (ij-iej), achieved the best IR score
among all the translation methods. The proposed
combination translation method (ijiej-IR-30)
improves the IR score of the baseline
combination translation (ij-iej) from 0.025 to
0.0629. The t-test showed that the proposed
combination translation improves IR score of the
baseline ij-iej with a 98% confidence level, T(69)
= 2.09, p&lt;0.02. Compared to other baseline
systems, t-test shows that the proposed
combination translation method (ijiej-IR-30)
improves the IR score at 95% (T(83) = 1.66,
p&lt;0.05), 86% (T(85) = 1.087, p&lt;0.14), 97%,
(T(82) = 1.91, p&lt;0.03) and 99% (T(67) = 2.38,
p&lt;0.005) confidence level for iej-mb, iej-mx, ij
and iej, respectively.
</bodyText>
<sectionHeader confidence="0.998851" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.955174833333333">
iej-mb-I-3
iej-mb-I-5
We present a translation method on CLIR that
is suitable for language pair with poor resources,
where the source language has a limited data
resource. Compared to other translation methods
</bodyText>
<figure confidence="0.99980038961039">
0.05
0.04
0.03
0.02
0.01
0
iej-mx iej-mb ijn ij iej ij-iej
PC PL RC RL
ij-iej-IR-5
ij-iej-IR-10
ij-iej-IR-20
ij-iej-IR-30
ij-iej-IR-40
ij-iej-IR-50
ij-iej-IR-60
iej-mx-I-3
iej-mx-I-5
ij-iej-I-10
iej-mb-IR
iej-mx-IR
iej-mb-I1
iej-mb-I2
iej-mb-I3
iej-mb-I4
iej-mb-I5
iej-mb-I-
iej-mx-I1
iej-mx-I2
iej-mx-I3
iej-mx-I4
iej-mx-I5
iej-mx-I-
iej-IR-5
iej-IR-10
iej-IR-20
iej-IR-30
ij-iej-I5
ij-iej-I-3
ij-iej-I-5
ij-IR-5
ij-IR-10
ij-IR-20
ij-IR-30
ijn-I-10
iej-I-10
ij-iej-I1
ij-iej-I2
ij-iej-I3
ij-iej-I4
ijn-I-3
ijn-I-5
ij-I-10
iej-I5
iej-I-3
iej-I-5
ijn-IR
ijn-I1
ijn-I2
ijn-I3
ijn-I4
ijn-I5
ij-I5
ij-I-3
ij-I-5
iej-I1
iej-I2
iej-I3
iej-I4
ij-I1
ij-I2
ij-I3
ij-I4
0 0.02 0.04 0.06 0.08
RL
RC
PL
PC
</figure>
<page confidence="0.997587">
7
</page>
<bodyText confidence="0.999977958333333">
such as transitive translation using machine
translation and direct translation using bilingual
dictionary (the source-target dictionary is a poor
bilingual dictionary), our transitive translation
and the combined translation (direct translation
and transitive translation) achieve higher IR
scores. The transitive translation achieves a 41%
performance of the monolingual IR and the
combined translation achieves a 49%
performance of the monolingual IR.
The two important methods in our transitive
translation are the borrowed word translation and
the keyword selection method. The borrowed
word approach can reduce the number of OOV
from 50 words to 5 words using a pivot-target
(English-Japanese) bilingual dictionary and
target (Japanese) proper name dictionary. The
keyword selection using the combination of
mutual information score and TF×IDF score has
improved the baseline transitive translation. The
other important method, the combination method
between transitive and direct translation using
bilingual dictionaries also improves the CLIR
performance.
</bodyText>
<sectionHeader confidence="0.998195" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9909332">
We would like to give our appreciation to Dr.
Atsushi Fujii (Tsukuba University) to allow us to
use the IR Engine in our research. This work was
partially supported by The 21st Century COE
Program “Intelligent Human Sensing”
</bodyText>
<sectionHeader confidence="0.999434" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999666695121951">
Adriani, Mirna. 2000. Using statistical term similarity
for sense disambiguation in cross language
information retrieval. Information Retrieval: 67-78.
Agency for The Assessment and Application of
Technology: KEBI (Kamus Elektronik Bahasa
Indonesia). http://nlp.aia.bppt.go.id/kebi/. Last
access: February 2004.
Babelfish English-Japanese Online Machine
Translation. http://www.altavista.com/babelfish/.
Last access: April 2004.
Ballesteros, Lisa A. and W. Bruce Croft. 1998.
Resolving ambiguity for cross-language retrieval.
ACM Sigir.
Ballesteros, Lisa A. 2000. Cross Language Retrieval
via Transitive Translation. Advances in
Information Retrieval: 203-230. Kluwer Academic
Publisher.
Chasen. http://chasen.naist.jp/hiki/ChaSen/. Last
access: February 2004.
Chen, Kuang-hua, et,al. 2003. Overview of CLIR Task
at the Third NTCIR Workshop. Proceedings of the
Third NTCIR Workshop.
Excite English-Japanese Online Machine Translation.
http://www.excite.co.jp/world/. Last access: April
2004.
Federico, M. and N. Bertoldi. 2002. Statistical cross
language information retrieval using n-best query
translations. Proc. Of 25th International ACM
Sigir.
Fox, Christopher. 1989. A stop list for general text.
ACM Sigir, Vol 24:19-21, Issue 2 Fall 89/Winter
90.
Fujii, Atsushi and Tetsuya Ishikawa. 2003. NTCIR-3
cross-language IR experiments at ULIS. Proc. Of
the Third NTCIR Workshop.
Fujii, Atsushi and Katunobu Itou. 2003. Building a
test collection for speech driven web retrieval.
Proceedings of the 8th European Conference on
Speech Communication and Technology.
Gao, Jianfeng, et, al. 2001. Improving query
translation for cross-language information
retrieval using statistical model. Proc. Sigir.
Gollins, Tim and Mark Sanderson. 2001. Improving
cross language information retrieval with
triangulated translation. Proc. Sigir.
ToggleText, Kataku Automatic Translation System.
http://www.toggletext.com/kataku_trial.php. Last
access: May 2004.
Information Retrieval Resources for Bahasia
Indonesia. Informatics Institute, University of
Amsterdam. http://ilps.science.uva.nl/Resources/.
Last access: Jan 2005.
Kishida, Kazuaki and Noriko Kando. 2004. Two-stage
refinement of query translation in a pivot language
approach to cross-lingual information retrieval:
An experiment at CLEF 2003. CLEF 2003, LNCS
3237: 253-262.
Kosasih, E. 2003. Kompetensi Ketatabahasaan dan
Kesusastraan, Cermat Berbahasa Indonesia.
Yrama Widya.
Mainichi Shinbun CD-Rom data sets 1993-1995,
Nichigai Associates Co., 1994-1996.
Michibata, H., ed.: Eijirou, Alc. Last access:2002.
Qu, Yan and G. Grefenstette, D. A. Evans. 2002.
Resolving translation ambiguity using monolingual
corpora. Advanced in Cross-Language Information
Retrieval, vol. 2785 of LNCS: 223-241. Springer
Verlag.
Sanggar Bahasa Indonesia Proyek: Kmsmini2000.
http://ml.ryu.titech.ac.jp/~indonesia/tokodai/dokum
en/ kamusjpina.pdf. Last access: May 2004.
Tanaka, Kumiko and Kyoji Umemura. Construction
of a bilingual dictionary intermediated by a third
language. COLING 1994, pages 297-303, Kyoto.
Wikipedia on Indonesian Language.
http://en.wikipedia.org/wiki/ Indonesian_language.
Last access: May 2005.
WordNet. http://wordnet.princeton.edu/. Last access:
February 2004.
Zu, Guowei, et, al. 2004. Automatic Text
Classification Techniques. IEEJ Trans EIS, Vol.
124, No. 3.
</reference>
<page confidence="0.998495">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.429149">
<title confidence="0.99639">Indonesian-Japanese CLIR Using Only Limited Resource</title>
<author confidence="0.997911">Ayu Purwarianti Masatoshi Tsuchiya Seiichi Nakagawa</author>
<affiliation confidence="0.999012">Department of Information and Computer Science, Toyohashi University of Technology</affiliation>
<email confidence="0.459277">ayu@slp.ics.tut.ac.jptsuchiya@imc.tut.ac.jpnakagawa@slp.ics.tut.ac.jp</email>
<abstract confidence="0.996909133333333">Our research aim here is to build a CLIR system that works for a language pair with poor resources where the source language (e.g. Indonesian) has limited language resources. Our Indonesian- Japanese CLIR system employs the existing Japanese IR system, and we focus our research on the Indonesian- Japanese query translation. There are two problems in our limited resource query translation: the OOV problem and the translation ambiguity. The OOV problem is handled using target language’s resources (English-Japanese dictionary and Japanese proper name dictionary). The translation ambiguity is handled using a Japanese monolingual corpus in our translation filtering. We select the final translation set using the mutual information score and the TF×IDF score. The result on NTCIR 3 (NII-NACSIS Test Collection for IR Systems) Web Retrieval Task shows that the translation method achieved a higher IR score than the transitive machine translation (using Kataku (Indonesian-English) and Babelfish/ Excite (English-Japanese) engine) result. The best result achieved about 49% of the monolingual retrieval.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Mirna Adriani</author>
</authors>
<title>Using statistical term similarity for sense disambiguation in cross language information retrieval. Information Retrieval:</title>
<date>2000</date>
<pages>67--78</pages>
<marker>Adriani, 2000</marker>
<rawString>Adriani, Mirna. 2000. Using statistical term similarity for sense disambiguation in cross language information retrieval. Information Retrieval: 67-78.</rawString>
</citation>
<citation valid="true">
<title>Agency for The Assessment and Application of Technology: KEBI (Kamus Elektronik Bahasa Indonesia). http://nlp.aia.bppt.go.id/kebi/. Last access:</title>
<date>2004</date>
<contexts>
<context position="4063" citStr="[2004]" startWordPosition="593" endWordPosition="593"> Chinese-English translation using an English corpus. The coherence score calculation was based on 1) web page count; 2) retrieval score; and 3) mutual information score. Mirna [2001] translated Indonesian into English and used an English monolingual corpus to select the best translation, employing a term similarity score based on the Dice similarity coefficient. Federico and Bertoldi [2002] combined the Nbest translation based on an HMM model of a query translation pair and relevant document probability of the input word to rank Italian documents retrieved by English query. Kishida and Kando [2004], used all terms to retrieve a document in order to obtain the best term combination and chose the most frequent term in 1 Proceedings of the Workshop on How Can Computational Linguistics Improve Information Retrieval?, pages 1–8, Sydney, July 2006. c�2006 Association for Computational Linguistics each term translation set that appears in the top ranked document. In our poor resource language – Japanese CLIR where we select Indonesian as the source language with limited resource, we calculate the mutual information score for each Japanese translation combination, using a Japanese monolingual c</context>
</contexts>
<marker>2004</marker>
<rawString>Agency for The Assessment and Application of Technology: KEBI (Kamus Elektronik Bahasa Indonesia). http://nlp.aia.bppt.go.id/kebi/. Last access: February 2004.</rawString>
</citation>
<citation valid="true">
<title>Babelfish English-Japanese Online Machine Translation. http://www.altavista.com/babelfish/. Last access:</title>
<date>2004</date>
<contexts>
<context position="4063" citStr="[2004]" startWordPosition="593" endWordPosition="593"> Chinese-English translation using an English corpus. The coherence score calculation was based on 1) web page count; 2) retrieval score; and 3) mutual information score. Mirna [2001] translated Indonesian into English and used an English monolingual corpus to select the best translation, employing a term similarity score based on the Dice similarity coefficient. Federico and Bertoldi [2002] combined the Nbest translation based on an HMM model of a query translation pair and relevant document probability of the input word to rank Italian documents retrieved by English query. Kishida and Kando [2004], used all terms to retrieve a document in order to obtain the best term combination and chose the most frequent term in 1 Proceedings of the Workshop on How Can Computational Linguistics Improve Information Retrieval?, pages 1–8, Sydney, July 2006. c�2006 Association for Computational Linguistics each term translation set that appears in the top ranked document. In our poor resource language – Japanese CLIR where we select Indonesian as the source language with limited resource, we calculate the mutual information score for each Japanese translation combination, using a Japanese monolingual c</context>
</contexts>
<marker>2004</marker>
<rawString>Babelfish English-Japanese Online Machine Translation. http://www.altavista.com/babelfish/. Last access: April 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa A Ballesteros</author>
<author>W Bruce Croft</author>
</authors>
<title>Resolving ambiguity for cross-language retrieval.</title>
<date>1998</date>
<journal>ACM Sigir.</journal>
<marker>Ballesteros, Croft, 1998</marker>
<rawString>Ballesteros, Lisa A. and W. Bruce Croft. 1998. Resolving ambiguity for cross-language retrieval. ACM Sigir.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa A Ballesteros</author>
</authors>
<title>Cross Language Retrieval via Transitive Translation.</title>
<date>2000</date>
<booktitle>Advances in Information Retrieval:</booktitle>
<pages>203--230</pages>
<publisher>Kluwer Academic Publisher.</publisher>
<contexts>
<context position="2064" citStr="Ballesteros 2000" startWordPosition="295" endWordPosition="296"> world, the CLIR has been an interesting research topic. For language pair with a rich language resource, the translation in the CLIR can be done with a bilingual dictionary - based direct translation, machine translation - or a parallel corpus - based translation. For a rare language pair, there is an attempt to use a pivot language (usually English), known as transitive translation, because there is no ample bilingual dictionary or machine translation system available. Some studies have been done in the field of transitive translation using bilingual dictionaries in the CLIR system such as [Ballesteros 2000; Gollins and Sanderson 2001]. Ballesteros [2000] translated Spanish queries into French with English as the interlingua. Ballesteros used Collins Spanish-English and English-French dictionaries. Gollins and Sanderson [2001] translated German queries into English using two pivot languages (Spanish and Dutch). Gollins used the Euro Wordnet as a data resource. To our knowledge, no CLIR is available with transitive translation for a source language with poor data resources such as Indonesian. Translation using a bilingual dictionary usually provides many translation alternatives only a few of whi</context>
</contexts>
<marker>Ballesteros, 2000</marker>
<rawString>Ballesteros, Lisa A. 2000. Cross Language Retrieval via Transitive Translation. Advances in Information Retrieval: 203-230. Kluwer Academic Publisher.</rawString>
</citation>
<citation valid="true">
<authors>
<author>http chasen naist jphikiChaSen</author>
</authors>
<title>Last access:</title>
<date>2004</date>
<marker>jphikiChaSen, 2004</marker>
<rawString>Chasen. http://chasen.naist.jp/hiki/ChaSen/. Last access: February 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kuang-hua Chen</author>
<author>al et</author>
</authors>
<date>2003</date>
<booktitle>Overview of CLIR Task at the Third NTCIR Workshop. Proceedings of the Third NTCIR Workshop.</booktitle>
<marker>Chen, et, 2003</marker>
<rawString>Chen, Kuang-hua, et,al. 2003. Overview of CLIR Task at the Third NTCIR Workshop. Proceedings of the Third NTCIR Workshop.</rawString>
</citation>
<citation valid="true">
<title>Excite English-Japanese Online Machine Translation. http://www.excite.co.jp/world/. Last access:</title>
<date>2004</date>
<contexts>
<context position="4063" citStr="[2004]" startWordPosition="593" endWordPosition="593"> Chinese-English translation using an English corpus. The coherence score calculation was based on 1) web page count; 2) retrieval score; and 3) mutual information score. Mirna [2001] translated Indonesian into English and used an English monolingual corpus to select the best translation, employing a term similarity score based on the Dice similarity coefficient. Federico and Bertoldi [2002] combined the Nbest translation based on an HMM model of a query translation pair and relevant document probability of the input word to rank Italian documents retrieved by English query. Kishida and Kando [2004], used all terms to retrieve a document in order to obtain the best term combination and chose the most frequent term in 1 Proceedings of the Workshop on How Can Computational Linguistics Improve Information Retrieval?, pages 1–8, Sydney, July 2006. c�2006 Association for Computational Linguistics each term translation set that appears in the top ranked document. In our poor resource language – Japanese CLIR where we select Indonesian as the source language with limited resource, we calculate the mutual information score for each Japanese translation combination, using a Japanese monolingual c</context>
</contexts>
<marker>2004</marker>
<rawString>Excite English-Japanese Online Machine Translation. http://www.excite.co.jp/world/. Last access: April 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Federico</author>
<author>N Bertoldi</author>
</authors>
<title>Statistical cross language information retrieval using n-best query translations.</title>
<date>2002</date>
<booktitle>Proc. Of 25th International ACM Sigir.</booktitle>
<marker>Federico, Bertoldi, 2002</marker>
<rawString>Federico, M. and N. Bertoldi. 2002. Statistical cross language information retrieval using n-best query translations. Proc. Of 25th International ACM Sigir.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Fox</author>
</authors>
<title>A stop list for general text.</title>
<date>1989</date>
<journal>ACM Sigir, Vol 24:19-21, Issue</journal>
<volume>2</volume>
<note>Fall 89/Winter 90.</note>
<contexts>
<context position="22967" citStr="Fox, 1989" startWordPosition="3449" endWordPosition="3450">lish borrowed words, and 16 transliterated Japanese words (proper nouns). The IR system (Fujii and Ishikawa [2003]) is borrowed from Atsushi Fujii (Tsukuba University). External resources used in the query translation are listed in Table 1. Table 1. External Resource List Resource Description KEBI Indonesian-English dictionary, 29,054 words Eijirou English-Japanese dictionary, 556,237 words Kmsmini2000 Indonesian-Japanese dictionary, 14,823 words ToggleText Kataku Indonesian-English machine translation Excite English-Japanese machine translation Babelfish English-Japanese machine translation [Fox, 1989] and English stop words (are also [Zu et al., 2004] translated into Indonesian stop words) Chasen Japanese morphological analyzer Jinmei Jisho Japanese proper name dictionary, 61,629 words Mainichi Shinbun Japanese newspaper corpus &amp; Online Yomiuri Shinbun 5.2 Experimental Result In the experiments, we compare the IR score of each translation method. The IR scores shown in this section are in Mean Average Precision (MAP) scores. The evaluation metrics is referred to [Fujii and Ishikawa 2003b]. Each query group has 4 MAP scores: RL (highly relevant document as correct answer with hyperlink inf</context>
</contexts>
<marker>Fox, 1989</marker>
<rawString>Fox, Christopher. 1989. A stop list for general text. ACM Sigir, Vol 24:19-21, Issue 2 Fall 89/Winter 90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
<author>Tetsuya Ishikawa</author>
</authors>
<date>2003</date>
<booktitle>NTCIR-3 cross-language IR experiments at ULIS. Proc. Of the Third NTCIR Workshop.</booktitle>
<contexts>
<context position="23463" citStr="Fujii and Ishikawa 2003" startWordPosition="3522" endWordPosition="3525">glish machine translation Excite English-Japanese machine translation Babelfish English-Japanese machine translation [Fox, 1989] and English stop words (are also [Zu et al., 2004] translated into Indonesian stop words) Chasen Japanese morphological analyzer Jinmei Jisho Japanese proper name dictionary, 61,629 words Mainichi Shinbun Japanese newspaper corpus &amp; Online Yomiuri Shinbun 5.2 Experimental Result In the experiments, we compare the IR score of each translation method. The IR scores shown in this section are in Mean Average Precision (MAP) scores. The evaluation metrics is referred to [Fujii and Ishikawa 2003b]. Each query group has 4 MAP scores: RL (highly relevant document as correct answer with hyperlink information used), RC (highly relevant document as correct answer), PL (partially relevant document as correct answer with hyperlink information used), and PC (partially relevant document as correct answer). The documents hyperlinked from retrieved documents are used for relevance assessment. Figure 5. Baseline Indonesian-Japanese CLIR Figure 5 shows the IR scores of queries translated using basic translation methods such as the bilingual dictionary or machine translation, without any enhanced </context>
</contexts>
<marker>Fujii, Ishikawa, 2003</marker>
<rawString>Fujii, Atsushi and Tetsuya Ishikawa. 2003. NTCIR-3 cross-language IR experiments at ULIS. Proc. Of the Third NTCIR Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
<author>Katunobu Itou</author>
</authors>
<title>Building a test collection for speech driven web retrieval.</title>
<date>2003</date>
<booktitle>Proceedings of the 8th European Conference on Speech Communication and Technology.</booktitle>
<marker>Fujii, Itou, 2003</marker>
<rawString>Fujii, Atsushi and Katunobu Itou. 2003. Building a test collection for speech driven web retrieval. Proceedings of the 8th European Conference on Speech Communication and Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Gao</author>
<author>al et</author>
</authors>
<title>Improving query translation for cross-language information retrieval using statistical model.</title>
<date>2001</date>
<booktitle>Proc. Sigir.</booktitle>
<marker>Gao, et, 2001</marker>
<rawString>Gao, Jianfeng, et, al. 2001. Improving query translation for cross-language information retrieval using statistical model. Proc. Sigir.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Gollins</author>
<author>Mark Sanderson</author>
</authors>
<title>Improving cross language information retrieval with triangulated translation.</title>
<date>2001</date>
<booktitle>Proc. Sigir.</booktitle>
<contexts>
<context position="2092" citStr="Gollins and Sanderson 2001" startWordPosition="297" endWordPosition="300">as been an interesting research topic. For language pair with a rich language resource, the translation in the CLIR can be done with a bilingual dictionary - based direct translation, machine translation - or a parallel corpus - based translation. For a rare language pair, there is an attempt to use a pivot language (usually English), known as transitive translation, because there is no ample bilingual dictionary or machine translation system available. Some studies have been done in the field of transitive translation using bilingual dictionaries in the CLIR system such as [Ballesteros 2000; Gollins and Sanderson 2001]. Ballesteros [2000] translated Spanish queries into French with English as the interlingua. Ballesteros used Collins Spanish-English and English-French dictionaries. Gollins and Sanderson [2001] translated German queries into English using two pivot languages (Spanish and Dutch). Gollins used the Euro Wordnet as a data resource. To our knowledge, no CLIR is available with transitive translation for a source language with poor data resources such as Indonesian. Translation using a bilingual dictionary usually provides many translation alternatives only a few of which are appropriate. A transi</context>
</contexts>
<marker>Gollins, Sanderson, 2001</marker>
<rawString>Gollins, Tim and Mark Sanderson. 2001. Improving cross language information retrieval with triangulated translation. Proc. Sigir.</rawString>
</citation>
<citation valid="true">
<authors>
<author>ToggleText</author>
</authors>
<title>Kataku Automatic Translation System. http://www.toggletext.com/kataku_trial.php. Last access:</title>
<date>2004</date>
<marker>ToggleText, 2004</marker>
<rawString>ToggleText, Kataku Automatic Translation System. http://www.toggletext.com/kataku_trial.php. Last access: May 2004.</rawString>
</citation>
<citation valid="false">
<date>2005</date>
<institution>Information Retrieval Resources for Bahasia Indonesia. Informatics Institute, University of Amsterdam.</institution>
<note>http://ilps.science.uva.nl/Resources/. Last access:</note>
<marker>2005</marker>
<rawString>Information Retrieval Resources for Bahasia Indonesia. Informatics Institute, University of Amsterdam. http://ilps.science.uva.nl/Resources/. Last access: Jan 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazuaki Kishida</author>
<author>Noriko Kando</author>
</authors>
<title>Two-stage refinement of query translation in a pivot language approach to cross-lingual information retrieval: An experiment at CLEF</title>
<date>2004</date>
<booktitle>CLEF 2003, LNCS</booktitle>
<volume>3237</volume>
<pages>253--262</pages>
<marker>Kishida, Kando, 2004</marker>
<rawString>Kishida, Kazuaki and Noriko Kando. 2004. Two-stage refinement of query translation in a pivot language approach to cross-lingual information retrieval: An experiment at CLEF 2003. CLEF 2003, LNCS 3237: 253-262.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Kosasih</author>
</authors>
<title>Kompetensi Ketatabahasaan dan Kesusastraan, Cermat Berbahasa Indonesia. Yrama Widya.</title>
<date>2003</date>
<contexts>
<context position="6597" citStr="Kosasih 2003" startWordPosition="984" endWordPosition="985">odule is not needed to translate an Indonesian sentence. Indonesian language does not have declensions or conjugations. The basic sentence order is Subject-Verb-Object. Verbs are not inflected for person or number. There are no tenses. Tense is denoted by the time adverb or some other tense indicators. The time adverb can be placed at the front or end of the sentence. A rather complex characteristic of the Indonesian language is that it is an agglutinave language. Words in Indonesian, usually verbs, can be attached by many prefixes or suffixes. Affixes used in the Indonesian language include [Kosasih 2003] me(n)-, ber-, di-, ter-, pe(n)-, per-, se-, ke-, -el-, -em-, -er-, -kan, -i, -nya, -an, me(n)- kan, di-kan, memper-i, diper-i, ke-an, pe(n)-an, per-an, ber-an, ber-kan, se-nya. Words with different affixes might have uniform or different translation. Examples of different word translation are “membaca” and “pembaca”, which are translated into “read” and “reader”, respectively. Examples of same word translation are the words “baca” and “bacakan”, which are both translated into “read” in English. Other examples are the words “membaca” and “dibaca”, which are translated into “read” and “being r</context>
</contexts>
<marker>Kosasih, 2003</marker>
<rawString>Kosasih, E. 2003. Kompetensi Ketatabahasaan dan Kesusastraan, Cermat Berbahasa Indonesia. Yrama Widya.</rawString>
</citation>
<citation valid="true">
<title>Mainichi Shinbun CD-Rom data sets 1993-1995, Nichigai Associates Co.,</title>
<date>1994</date>
<marker>1994</marker>
<rawString>Mainichi Shinbun CD-Rom data sets 1993-1995, Nichigai Associates Co., 1994-1996.</rawString>
</citation>
<citation valid="false">
<editor>Michibata, H., ed.: Eijirou, Alc. Last access:2002.</editor>
<marker></marker>
<rawString>Michibata, H., ed.: Eijirou, Alc. Last access:2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yan Qu</author>
<author>G Grefenstette</author>
<author>D A Evans</author>
</authors>
<title>Resolving translation ambiguity using monolingual corpora.</title>
<date>2002</date>
<booktitle>Advanced in Cross-Language Information Retrieval,</booktitle>
<volume>2785</volume>
<pages>223--241</pages>
<publisher>Springer Verlag.</publisher>
<marker>Qu, Grefenstette, Evans, 2002</marker>
<rawString>Qu, Yan and G. Grefenstette, D. A. Evans. 2002. Resolving translation ambiguity using monolingual corpora. Advanced in Cross-Language Information Retrieval, vol. 2785 of LNCS: 223-241. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<title>Sanggar Bahasa Indonesia Proyek: Kmsmini2000. http://ml.ryu.titech.ac.jp/~indonesia/tokodai/dokum en/ kamusjpina.pdf. Last access:</title>
<date>2004</date>
<contexts>
<context position="4063" citStr="[2004]" startWordPosition="593" endWordPosition="593"> Chinese-English translation using an English corpus. The coherence score calculation was based on 1) web page count; 2) retrieval score; and 3) mutual information score. Mirna [2001] translated Indonesian into English and used an English monolingual corpus to select the best translation, employing a term similarity score based on the Dice similarity coefficient. Federico and Bertoldi [2002] combined the Nbest translation based on an HMM model of a query translation pair and relevant document probability of the input word to rank Italian documents retrieved by English query. Kishida and Kando [2004], used all terms to retrieve a document in order to obtain the best term combination and chose the most frequent term in 1 Proceedings of the Workshop on How Can Computational Linguistics Improve Information Retrieval?, pages 1–8, Sydney, July 2006. c�2006 Association for Computational Linguistics each term translation set that appears in the top ranked document. In our poor resource language – Japanese CLIR where we select Indonesian as the source language with limited resource, we calculate the mutual information score for each Japanese translation combination, using a Japanese monolingual c</context>
</contexts>
<marker>2004</marker>
<rawString>Sanggar Bahasa Indonesia Proyek: Kmsmini2000. http://ml.ryu.titech.ac.jp/~indonesia/tokodai/dokum en/ kamusjpina.pdf. Last access: May 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kumiko Tanaka</author>
<author>Kyoji Umemura</author>
</authors>
<title>Construction of a bilingual dictionary intermediated by a third language. COLING</title>
<date>1994</date>
<pages>297--303</pages>
<location>Kyoto.</location>
<marker>Tanaka, Umemura, 1994</marker>
<rawString>Tanaka, Kumiko and Kyoji Umemura. Construction of a bilingual dictionary intermediated by a third language. COLING 1994, pages 297-303, Kyoto.</rawString>
</citation>
<citation valid="true">
<title>Wikipedia on Indonesian Language. http://en.wikipedia.org/wiki/ Indonesian_language. Last access:</title>
<date>2005</date>
<marker>2005</marker>
<rawString>Wikipedia on Indonesian Language. http://en.wikipedia.org/wiki/ Indonesian_language. Last access: May 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>http wordnet princeton edu</author>
</authors>
<title>Last access:</title>
<date>2004</date>
<marker>edu, 2004</marker>
<rawString>WordNet. http://wordnet.princeton.edu/. Last access: February 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guowei Zu</author>
<author>al et</author>
</authors>
<title>Automatic Text Classification Techniques.</title>
<date>2004</date>
<journal>IEEJ Trans EIS,</journal>
<volume>124</volume>
<marker>Zu, et, 2004</marker>
<rawString>Zu, Guowei, et, al. 2004. Automatic Text Classification Techniques. IEEJ Trans EIS, Vol. 124, No. 3.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>