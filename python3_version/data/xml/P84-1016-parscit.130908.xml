<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<note confidence="0.449362">
QUASI-INDEXICAL REFERENCE IN PROPOSITIONAL SEMANTIC NETWORKS
</note>
<author confidence="0.932338">
William J. Rapaport
</author>
<affiliation confidence="0.992793">
Department of Philosophy. SUNY Fredonia. Fredonia. NY 14063
Department of Computer Science, SUNY Buffalo, Buffalo. NY 14260
</affiliation>
<author confidence="0.817911">
Stuart C. Shapiro
</author>
<affiliation confidence="0.994918">
Department of Computer Science. SUNY Buffalo, Buffalo. NY 14260
</affiliation>
<sectionHeader confidence="0.6799" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.9997868">
We discuss how a deductive question-answering sys-
tem can represent the beliefs or other cognitive
states of users, of other (interacting) systems,
and of itself. In particular. we examine the
representation of first-person beliefs of others
(e.g., the systp.&apos;n representation of a psprfl
belief that he himself is rich). Such beliefs
have asan essential component &amp;quot;quasi-indexical
pronouns&amp;quot; (e.g.. &apos;he himself&apos;). and, hence.
require for their analysis a method of represent-
ing these pronominal constructions and performing
valid inferences with them. The theoretical jus-
tification for the approach to be discussed is the
representation of nested &amp;quot;d1 dicta&amp;quot; beliefs (e.g..
the system&apos;s belief that user-1 believes that
system-2 believes that user-2 is rich). We dis-
cuss a computer implementation of these represen-
tations using the Semantic Network Processing Sys-
tem (SNePS) and an ATN parser-generator with a
question-answering capability.
</bodyText>
<sectionHeader confidence="0.988756" genericHeader="introduction">
1. INTRODUCTION
</sectionHeader>
<bodyText confidence="0.9931446875">
Consider a deductive knowledge-representation
system whose data base contains information about
various people (e.g.. its users), other (perhaps
interacting) systems, or even itself. In order
for the system to learn more about these
entities--to expand its knowledge&amp;quot; base--it
should contain information about the beliefs (or
desires, wants, or other cognitive states) of
these entities, and it should be able to reason
about them (cf. Moore 1977, Creary 1979. Wilks and
Bien 1983, Barnden 1983. and Nilsson 1983: 9).
Such a data base constitutes the &amp;quot;knowledge&amp;quot; (more
accurately, the belirfs) of the system about these
entities and about thaiL beliefs.
Among the interrelated issues in knowledge
representation that can be raised in such a
context are those of multiple reference and the
proper treatment of pronouns. For instance, is the
person named &apos;Lucy&apos; whom John believes to be rich
the same as the person named &apos;Lucy who is
believed by the system to be young? How can the
system (a) represent the person named &apos;Lucy&apos; who
is an object of its am belief without (b) confus-
ing her with the person named &apos;Lucy&apos; who is an
object of Jahn&apos;s_ belief. yet (c) be able to
&amp;quot; &amp;quot;
merge its representations of those two people
if it is later determined that they are the same?
A solution to this problem turns out to be a side
effect of a solution to a subtler problem in pro-
nominal reference, namely, the proper treatment of
pronouns occurring within belief-contexts.
</bodyText>
<sectionHeader confidence="0.866252" genericHeader="method">
Z. OUASI-INDICATORS
</sectionHeader>
<bodyText confidence="0.971816">
Following Castaneda (1967: 85). an indirprnr
is a personal or demonstrative pronoun or adverb
used to make a strictly demonstrative reference.
and a opasi-indicator is an expression within a
&apos;believes-that&apos; context that represents a use of
an indicator by another person. Consider the fol-
lowing statement by person A addressed to person I
at time and place 11: A says. I am going to
kill you here now. Person who overheard this.
calls the police and says. &amp;quot;A said .to A at A at 1
that he* was going to kill him* there* then*: The
starred words are quasi-indicators representing
uses by A of the indicators &apos;I&apos;. &apos;you&apos;. &apos;here&apos;.
and &apos;now&apos;. There are two properties (among many
others) of quasi-indicators that must be taken
into account: (0 They occur only within inten-
tional contexts. and (ii) they cannot be replaced
5alvn veritarp by any co-referential expressions.
The general question is: &amp;quot;How can we attri-
bute indexical references to others?- (Castaneda
1980: 794). The specific cases that we are con-
cerned with are exemplified in the following
scenario. Suppose that John has just been
appointed editor of Utl, but that John does not
yet know this. Further, suppose that, because of
the well-publicized salary accompanying the office
of Ixten editor.
</bodyText>
<listItem confidence="0.934498">
(1) John believes that the editor of $3,itn is rich.
</listItem>
<bodyText confidence="0.843265">
And suppose finally that, because of severe losses
in the stock market.
</bodyText>
<listItem confidence="0.80801">
(2) John believes that he himself is not rich.
</listItem>
<bodyText confidence="0.9894156">
Suppose that the system had information about each
of the following: John&apos;s appointment as editor.
John&apos;s (lack of) knowledge of this appointment.
and John&apos;s belief about the wealth of the editor.
We would not want the system to infer
</bodyText>
<listItem confidence="0.6876575">
(3) John believes that he* is rich
because (2) is consistent with the system&apos;s infor-
</listItem>
<bodyText confidence="0.99914925">
mation. The &apos;he himself&apos; in (2) is a quasi-
indicator. for (2) is the sentence that ne. use to
express the belief that Inhn would express as &apos;I
am&apos; not rich&apos;. Someone pointing to John. saying.
</bodyText>
<page confidence="0.998294">
65
</page>
<listItem confidence="0.5800665">
(4) He [i.e.. that man there] believes that he*
is not rich
</listItem>
<bodyText confidence="0.9881757">
could just as well have said (2). The first &apos;he&apos;
in (4) is not a quasi-indicator: It occurs outside
the believes-that context, and it can be replaced
by &apos;John&apos; or by &apos;the editor of Ufa&apos;. salva ygLi=
tate, But the &apos;he*&apos; in )4) and the &apos;he himself&apos;
in (2) could not be thus replaced by &apos;the editor
of Dvte&apos; - given our scenario - ay= though John
is the editor of Dyte. And if poor John also suf-
fered from amnesia, it could not be replaced by
&apos;John&apos; either.
</bodyText>
<sectionHeader confidence="0.964363" genericHeader="method">
1. REPRESENTATIONS
</sectionHeader>
<bodyText confidence="0.966013154929578">
Entities such as the Lucy who is the object
of John&apos;s belief are intentional (mental), hence
intensional. (Cf. Frege 1892; Meinong 1904; Cas-
taileda 1972; Rapaport 1978. 1981.) Moreover, the
entities represented in the data base are the
objects of the system&apos;s. beliefs, and. so, are also
intentional, hence intensional. We represent sen-
tences by means of propositional semantic net-
works. using the Semantic Network Processing Sys-
tem (SNePS; Shapiro 1979). which treats nodes as
representing intensional concepts (cf. Woods 1975.
Brachman 1977. Maids and Shapiro 1982).
We claim that in the absence of prior
knowledge of co-referentiality. the entities
within belief-contexts should be represented
separately. from entities guTOsip the context that
might be co-referential with them. Suppose the
system&apos;s beliefs include that a person named
&apos;Lucy&apos; is young and that John believes that a
(possibly different) person named &apos;Lucy&apos; is rich.
We represent this with the network of Fig. 1.
Fig. 1. Lucy is young (m3) and John believes that
someone named &apos;Lucy&apos; is rich (m12).
The section of network dominated by nodes m7
and m9 is the system&apos;s da dicto representation of
John&apos;s belief. That is. m9 is the Â§yste1e1
representation al. a belief that aaha might express
by &apos;Lucy is rich&apos;, and it is represented al one of
John&apos;s beliefs. Such nodes are considered as
being in the system&apos;s representation of John&apos;s
7belief space&amp;quot;. Non-dominated nodes, such as m14.
m12, m15, m5. and m3, are the system&apos;s representa-
tion of its wia belief space (i.e.. they can be
thought of as the object of an implicit &apos;I believe
that&apos; case-frame; cf. CastaWeda 1975: 121-22. Kant
1787: 8131).
If it is later determined that the &amp;quot;two&amp;quot;
Lucies are the same, then a node of co-
referentiality would be added (m16. in Fig. 2).
Fig. 2. Lucy is young (m3). John believes that
someone named &apos;Lucy&apos; is rich (m15). and John&apos;s
Lucy is the system&apos;s Lucy (m16).
Now consider the case where the system has no
information about the &amp;quot;content&amp;quot; of John&apos;s belief.
but does have information that John&apos;s belief is
about the =azalea Lucy. Thus. whereas John might
express his belief as. &apos;Linus&apos;s sister is rich&apos;.
the system would express it as. &apos;(Lucy system) is
believed by John to be rich&apos; (where &apos;(Lucy sys-
tem)&apos; is the system&apos;s Lucy). This is a da za
representation of John&apos;s belief, and would be
represented by node m12 of Figure 3.
The strategy of separating entities in dif-
ferent belief spaces is needed in order to satisfy
the two main properties of quasi-indicators.
Consider the possible representations of sen-
tence (3) in Figure 4 (adapted from Maida and
Shapiro 1983: 316). This suffers from three major
problems. First, it is ambiguous: It could be
the representation of (3) or of
(5) John believes that John is rich.
But, as we have seen. (3) and (5) express quite
different propositions; thus, they should be
separate items in the data base.
Second. Figure 4 cannot represent (5). For
then we would have no easy or uniform way to
represent (3) in the case where John does not know
that he is named &apos;John&apos;: Figure 4 says that the
person (m3) who is named &apos;John&apos; and who believes
m6, believes that that person is rich; and this
would be false in the amnesia case.
</bodyText>
<figure confidence="0.897885">
believes young
66
</figure>
<figureCaption confidence="0.99890575">
Fig. 3. The system&apos;s young Lucy is believed by
John to be rich.
Fig. 4. A representation for
&apos;John believes that he* is rich&apos;
</figureCaption>
<bodyText confidence="0.9788778">
Third. Figure 4 cannot represent (3) either.
for it does not adequately represent the quasi-
indexical nature of the &apos;he&apos; in (3); Node m3
represents both &apos;John&apos; and &apos;he&apos;. hence is both
inside and outside the intentional context, con-
trary to both of the properties of quasi-
indicators.
Finally, because of these representational
inadequacies, the system would invalidly &amp;quot;infer&amp;quot;
(6iii) from (6i)-(6ii);
</bodyText>
<listItem confidence="0.986723333333333">
(6) (0 John believes that he is rich.
(ii) he = John
(iii) John believes that John is rich.
</listItem>
<bodyText confidence="0.979012142857143">
simply because premise (61) would be represented
by the same network as conclusion (6iii).
Rather, the general pattern for representing
such sentences is illustrated in Figure 5. The
the*&apos; in the English sentence is represented by
node m2; its quasi-indexical nature is represented
by means of node m10.
</bodyText>
<figureCaption confidence="0.886185">
Fig. 5. John believes that he* is rich
</figureCaption>
<bodyText confidence="0.990346294117647">
(m2 is the system&apos;s representation of John&apos;s
&amp;quot;self-concept expressed by John as &apos;I&apos; and by
the system as &apos;he*&apos;)
That nodes m2 and m5 must be distinct follows
from our separation principle. But, since m2 is
the system&apos;s representation of John&apos;s representa-
tion of himself, it must be within the system&apos;s
representation of John&apos;s belief space; this is
accomplished via nodes m10 and m9. representing
John&apos;s belief that m2 is his self-
representation&amp;quot;. Node m9, with its EGO arc to m2,
represents, roughly. the proposition &apos;m2 is me&apos;.
Our representation of quasi-indexical dg Ag
sentences is thus a special case of the general
schema for dg diggg representations of belief sen-
tences. When a gg gg sentence is interpreted gg
mg. it does not contain quasi-indicators, and can
be handled by the general schema for dg mg
representations. Thus.
(7) John is believed by himself to be rich
would be represented by the network of Figure 4.
A. INFERENCES
Using an ATN parser-generator with a
question-answering capability (based on Shapiro
1982). we are implementing a system that parses
English sentences representing beliefs dg mg or gg
gicto into our semantic-network representations.
and that generates appropriate sentences from such
networks.
It also &amp;quot;recognizes&amp;quot; the invalidity of argu-
ments such as (5) since the premise and conclusion
(when interpreted dg dicto) are no longer
represented by the same network. When given an
appropriate inference rule, however, the system
</bodyText>
<page confidence="0.998709">
67
</page>
<bodyText confidence="0.916498">
will treat as valid such inferences as the follow-
ing:
</bodyText>
<listItem confidence="0.976862">
(8) (i) John believes that the editor of Byte is
rich.
</listItem>
<bodyText confidence="0.842788">
(ii) John believes that he* is the editor of
Byte.
Therefore, (iii) John believes that he* is rich
In this case, an appropriate inference rule would
be:
</bodyText>
<listItem confidence="0.9560005">
(9) (Vx,y,z.F)Ex believes F(y) &amp; x believes z=y
-&gt; x believes F(z)]
</listItem>
<bodyText confidence="0.999587444444444">
In SNePS, inference rules are treated as proposi-
tions represented by nodes in the network. Thus.
the network for (9) would be built by the SNePS
User Language command given in Figure 6 (cf.
Shapiro 1979).
would modify the network of Figure 7 by adding new
beliefs to (John system)&apos;s belief space and to
(Mary John system)&apos;s belief space. but would use
the same nodes to represent John. Mary. and Lucy.
</bodyText>
<figure confidence="0.998395214285714">
(build
avb ($x Sy $z $F)
&amp;ant (build agent *x
verb (build lex believe)
object (build which *y
adj (build lex *F)))
&amp;ant (build agent *x
verb (find lex believe)
object (build equiv *z equiv *y))
cq (build agent *x
verb (find lex believe)
object (build which *z
adj (find lex *F))))
(pelievel&gt;
</figure>
<figureCaption confidence="0.990812">
Fig. 7. John believes that Mary believes that
Lucy is rich.
Fig. 6. SNePSUL command for building rule (9), RIR INFORMATION
</figureCaption>
<bodyText confidence="0.8499585">
for argument (8).
IIKBAnia BELIEF CONTEXTS
Our system can also handle sentences involv-
ing iterated belief contexts. Consider
</bodyText>
<listItem confidence="0.9624635">
(10) John believes that Mary believes that Lucy
is rich.
</listItem>
<bodyText confidence="0.9569175625">
The interpretation of this that we are most
interested in representing treats (10) as the
system&apos;s de. dicto representation of John&apos;s de.
did= representation of Mary&apos;s belief that Lucy is
rich. On this interpretation, we need to
represent the system&apos;i John--(John system)--the
system&apos;s representation of Jahn&apos;l Mary--(Mary John
system)--and the system&apos;s representation of John&apos;s
representation of Mary&apos;s. Lucy--(Lucy Mary John
system). This is done by the network of Figure 7.
Such a network is built recursively as fol-
lows: The parser maintains a stack of &amp;quot;believers&amp;quot;.
Each time a belief-sentence is parsed, it is made
the object of a belief of the previous believer in
the stack. Structure-sharing is used wherever
possible. Thus,
</bodyText>
<listItem confidence="0.991686">
(11) John believes that Mary believes that Lucy
is sweet
</listItem>
<bodyText confidence="0.99799625">
The system is also capable of handling
sequences of new information. For instance, sup-
pose that the system is given the following infor-
mation at three successive times:
</bodyText>
<figureCaption confidence="0.967678">
tl: (12) The system&apos;s Lucy believes that Lucy&apos;s
Lucy is sweet.
t2: (13) The system&apos;s Lucy is sweet.
t3: (14) The system&apos;s Lucy = Lucy&apos;s Lucy.
</figureCaption>
<bodyText confidence="0.998440681818182">
Then it will build the networks of Figures 8-10,
successively. At tl (Fig. 8). node m3 represents
the system&apos;s Lucy and m7 represents Lucy&apos;s Lucy.
At t2 (Fig. 9), m13 is built, representing the
system&apos;s belief that the system&apos;s Lucy (who is not
yet believed to be--and, indeed, might it be--
Lucy&apos;s Lucy) is sweet.[1] At t3 (Fig. 11), m14 is
built, representing the system&apos;s new belief that
there is really only one Lucy. This is a merging
of the two Lucy -nodes. From now on. all proper-
ties of &amp;quot;either. Lucy will be inherited by the
other . by means of an inference rule for the
EQUIV case-frame (roughly, the indiscernibility of
identicals).
fliVie are assuming that the system&apos;s concept of
sweetness (node m8) is also the system&apos;s concept
of (Lucy system)&apos;s concept of sweetness. This as-
sumption seems warranted, since all nodes are in
the system&apos;s belief space. If the system had rea-
son to believe that ill concept of sweetness dif-
fered from Lucy&apos;s, this could--and would have to--
be represented.
</bodyText>
<page confidence="0.995851">
68
</page>
<figure confidence="0.9635436">
071;571717e-g)
Fig. 8. Lucy believes that Lucy is sweet.
V.
(sweet)
(LtâTC-3-)
</figure>
<figureCaption confidence="0.947065">
Fig. 9. Lucy believes that Lucy is sweet.
and Lucy (the believer) is sweet.
</figureCaption>
<sectionHeader confidence="0.980004" genericHeader="method">
1. FUTURE WORK
</sectionHeader>
<bodyText confidence="0.997968916666667">
There are several directions for future
modifications. First, the node-merging mechanism
of the EQUIV case-frame with its associated rule
needs to be generalized: Its current interpreta-
tion is co-referentiality; but if the sequence
(12)-(14) were embedded in someone else&apos;s belief-
space, then co-referentiality might be incorrect.
What is needed is a notion of &apos;co-referentiality-
within-a-belief-space&amp;quot;. The relation of .consoci-
ation&amp;quot; (Castaiieda 1972) seems to be more appropri-
ate.
Second, the system needs to be much more
</bodyText>
<listItem confidence="0.333989666666667">
flexible. Currently. it treats all sentences of
the form
(15) x believes that F(y)
</listItem>
<bodyText confidence="0.9902545">
as canonically gg dicta and all sentences of the
form
</bodyText>
<equation confidence="0.360114">
(16) y is believed by x to be F
</equation>
<bodyText confidence="0.876983333333333">
Fig. 10. Lucy believes that Lucy is sweet. Lucy
is sweet, and the system&apos;s Lucy is Lucy&apos;s Lucy.
as canonically Ag Lg. In ordinary conversation,
however, both sentences can be understood in
either way, depending on context, including prior
beliefs as well as idiosyncracies of particular
predicates. For instance. given (1). above, and
the fact that John is the editor of Axle.. most
people would infer (3). But given
</bodyText>
<listItem confidence="0.88338">
(17) John believes that all identical twins are
conceited.
(18) Unknown to John. he is an identical twin
most people would nat. infer
(19) John believes that he* is conceited.
</listItem>
<bodyText confidence="0.9999974">
Thus, we want to allow the system to make the most
&amp;quot;reasonable&amp;quot; interpretations (d1 LI vs. gg ditto)
of users&apos; belief-reports, based on prior beliefs
and on subject matter, and to modify its initial
representation as more information is received.
</bodyText>
<sectionHeader confidence="0.907349" genericHeader="conclusions">
SUIVARY
</sectionHeader>
<bodyText confidence="0.9997804375">
A deductive knowledge-representation system that
is to be able to reason about the beliefs of cog-
nitive agents must have a scheme for representing
beliefs. This scheme must be able to distinguish
among the &amp;quot;belief spaces&amp;quot; of different agents, as
well as be able to handle &amp;quot;nested belief spaces&amp;quot;,
i.e., second-order beliefs such as the beliefs of
one agent about the beliefs of another. We have
shown how a scheme for representing beliefs as
either Ag Le or Az dicto can distinguish the items
in different belief spaces (including nested
belief spaces). yet merge&amp;quot; the items on the basis
of new information. This general scheme also
enables the system to adequately represent sen-
tences containing quasi-indicators, while not
allowing invalid inferences to be drawn from them.
</bodyText>
<page confidence="0.999043">
69
</page>
<sectionHeader confidence="0.979402" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.997940868852459">
J. A. Barnden, &amp;quot;Intensions as Such: An Outline.&amp;quot;
IJCAI-83 (1983)280-286.
R. J. Brachman, -What&apos;s in a Concept: Structural
Foundations for Semantic Networks,&amp;quot; Interna-
liana], Journal Inn Man-Machine Studies
9(1977)127-52.
Hector-Neri Castaiieda. &amp;quot;Indicators and Quasi-
Indicators, Amaziala rjailaragazajaal Quarterly
4(1967)85-100.
&amp;quot;Thinking and the Structure of the World&amp;quot;
- (1972). PhilosophiR 4(1974)3-40.
&amp;quot;Identity and Sameness,&amp;quot; Philoanphia.
- 5(1975)121-50.
&amp;quot;Reference. Reality and Perceptual Fields.&amp;quot;
- annealing&amp; and. Addresses 2L the. American
Philosophical Afisociation 53(1980)763-823.
L. G. Creary. &amp;quot;Propositional Attitudes: Fregean
Representation and Simulative Reasoning,
IJCAI-79 (1979)176-81.
Gottlob Frege. &amp;quot;On Sense and Reference- (1892). in
Translations lam the. Philosophical Writings a
Gottlob prey.., ed. by P. Geach and M. Black
(Oxford: Basil Blackwell. 1970): 56-78.
Immanuel Kant. critique at EuLl Reason. 2nd ed.
(1787). trans. N. Kemp Smith (New York: St.
Martin&apos;s Press. 1929).
Anthony S. Maids and Stuart C. Shapiro. &amp;quot;Inten-
sional Concepts in Propositional Semantic Net-
works.&amp;quot; CognirivP Science. 6(1982)291-330.
Alexius Meinong. &amp;quot;Ueber Gegenstandstheorie&amp;quot;
(1904). in Alexius Meinong Gesamtausgabe. Vol.
II, ed. R. Haller (Graz. Austria: Akademische
Druck- u. Verlagsanstalt. 1971): 481-535.
English translation in R. Chisholm (ed.). Real-
iam and tha Background at Planamanalagx. (New
York: Free Press. 1960): 76-117.
R. C. Moore. &amp;quot;Reasoning about Knowledge and
Action.&amp;quot; IJCAI-77 (1977)223-27.
Nils J. Nilsson. &amp;quot;Artificial Intelligence Prepares
for 2001. AI Magazinp 4.4(Winter 1983)7-14.
William J. Rapaport. &amp;quot;Meinongian Theories and a
Russellian Paradox.&amp;quot; Soils 12(1978)153-80;
errata. 13(1979)125.
â¢ &amp;quot;How to Make the World Fit Our Language: An
Essay in Meinongian Semantics.&amp;quot; Grazer Philoso-
phische Studien 14(1981)1-21.
Stuart C. Shapiro. The SNePS Semantic Network
Processing System,&amp;quot; in N. V. Findler (ed.).
Associative. Networks (New York: Academic Press,
1979): 179-203.
. -Generalized Augmented Transition Network
Grammars For Generation From Semantic Networks.&amp;quot;
America a Journal at Computational Linguistics
8(1982)12-25.
Yorick Wilks and Janusz Bien. &amp;quot;Beliefs. Points of
View. and Multiple Environments,&amp;quot; Cognirivp Sci-
man&amp; 7(1983)95-119.
William A. Woods. &amp;quot;What&apos;s in a Link: The Semantics
of Semantic Networks.&amp;quot; in D. G. Bobrow and A. M.
Collins (eds.). Ropreaentatinn and Understandinv
(New York: Academic Press, 1975): 35-79.
</reference>
<page confidence="0.998468">
70
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.001378">
<title confidence="0.998893">QUASI-INDEXICAL REFERENCE IN PROPOSITIONAL SEMANTIC NETWORKS</title>
<author confidence="0.999999">William J Rapaport</author>
<affiliation confidence="0.825098">Department of Philosophy. SUNY Fredonia. Fredonia. NY 14063 Department of Computer Science, SUNY Buffalo, Buffalo. NY 14260</affiliation>
<author confidence="0.998148">Stuart C Shapiro</author>
<affiliation confidence="0.929997">Department of Computer Science. SUNY Buffalo, Buffalo. NY 14260</affiliation>
<abstract confidence="0.994384340153452">We discuss how a deductive question-answering system can represent the beliefs or other cognitive states of users, of other (interacting) systems, and of itself. In particular. we examine the representation of first-person beliefs of others the systp.&apos;nrepresentation of a psprfl belief that he himself is rich). Such beliefs have asan essential component &amp;quot;quasi-indexical pronouns&amp;quot; (e.g.. &apos;he himself&apos;). and, hence. require for their analysis a method of representing these pronominal constructions and performing valid inferences with them. The theoretical justification for the approach to be discussed is the of nested&amp;quot;d1 dicta&amp;quot;beliefs (e.g.. the system&apos;s belief that user-1 believes that system-2 believes that user-2 is rich). We discuss a computer implementation of these representations using the Semantic Network Processing System (SNePS) and an ATN parser-generator with a question-answering capability. Consider a deductive knowledge-representation system whose data base contains information about various people (e.g.. its users), other (perhaps interacting) systems, or even itself. In order for the system to learn more about these entities--to expand its knowledge&amp;quot; base--it should contain information about the beliefs (or desires, wants, or other cognitive states) of these entities, and it should be able to reason about them (cf. Moore 1977, Creary 1979. Wilks and Bien 1983, Barnden 1983. and Nilsson 1983: 9). Such a data base constitutes the &amp;quot;knowledge&amp;quot; (more accurately, the belirfs) of the system about these and about Among the interrelated issues in knowledge representation that can be raised in such a context are those of multiple reference and the proper treatment of pronouns. For instance, is the person named &apos;Lucy&apos; whom John believes to be rich the same as the person named &apos;Lucy who is believed by the system to be young? How can the system (a) represent the person named &apos;Lucy&apos; who an object of its without (b) confusing her with the person named &apos;Lucy&apos; who is an of yet (c) be able to &amp;quot; &amp;quot; merge its representations of those two people if it is later determined that they are the same? A solution to this problem turns out to be a side of a solution to a subtler problem in pronominal reference, namely, the proper treatment of pronouns occurring within belief-contexts. Castaneda (1967: 85). an is a personal or demonstrative pronoun or adverb used to make a strictly demonstrative reference. a opasi-indicatoris an expression within a &apos;believes-that&apos; context that represents a use of an indicator by another person. Consider the folstatement by person to person I time and place A I am going to kill you here now. Person who overheard this. the police and says. &amp;quot;A said .to A at that he* was going to kill him* there* then*: The starred words are quasi-indicators representing by the indicators &apos;I&apos;. &apos;you&apos;. &apos;here&apos;. and &apos;now&apos;. There are two properties (among many others) of quasi-indicators that must be taken account: (0 They occur only within tional contexts. and (ii) they cannot be replaced veritarpby any co-referential expressions. The general question is: &amp;quot;How can we attriindexical references to (Castaneda 1980: 794). The specific cases that we are concerned with are exemplified in the following scenario. Suppose that John has just been editor of that John does not yet know this. Further, suppose that, because of the well-publicized salary accompanying the office of Ixten editor. John believes that the editor of $3,itnis rich. And suppose finally that, because of severe losses in the stock market. (2) John believes that he himself is not rich. Suppose that the system had information about each of the following: John&apos;s appointment as editor. John&apos;s (lack of) knowledge of this appointment. and John&apos;s belief about the wealth of the editor. would notwant the system to infer (3) John believes that he* is rich (2) is consistent with the system&apos;s infor- The &apos;he himself&apos; in (2) is a for (2) is the sentence that to express the belief that Inhn would express as &apos;I am&apos; not rich&apos;. Someone pointing to John. saying. 65 (4) He [i.e.. that man there] believes that he* is not rich could just as well have said (2). The first &apos;he&apos; in (4) is not a quasi-indicator: It occurs outside the believes-that context, and it can be replaced &apos;John&apos; or by &apos;the editor of Ufa&apos;. salvaygLi= tate,But the &apos;he*&apos; in )4) and the &apos;he himself&apos; in (2) could not be thus replaced by &apos;the editor Dvte&apos;given our scenario - John the editor of Dyte.And if poor John also suffered from amnesia, it could not be replaced by &apos;John&apos; either. Entities such as the Lucy who is the object of John&apos;s belief are intentional (mental), hence intensional. (Cf. Frege 1892; Meinong 1904; Castaileda 1972; Rapaport 1978. 1981.) Moreover, the entities represented in the data base are the objects of the system&apos;s. beliefs, and. so, are also intentional, hence intensional. We represent sentences by means of propositional semantic networks. using the Semantic Network Processing System (SNePS; Shapiro 1979). which treats nodes as representing intensional concepts (cf. Woods 1975. Brachman 1977. Maids and Shapiro 1982). We claim that in the absence of prior knowledge of co-referentiality. the entities withinbelief-contexts should be represented separately.from entities guTOsipthe context that might be co-referential with them. Suppose the system&apos;s beliefs include that a person named &apos;Lucy&apos; is young and that John believes that a (possibly different) person named &apos;Lucy&apos; is rich. We represent this with the network of Fig. 1. Fig. 1. Lucy is young (m3) and John believes that someone named &apos;Lucy&apos; is rich (m12). The section of network dominated by nodes m7 m9 is the system&apos;s dictorepresentation of John&apos;s belief. That is. m9 is the Â§yste1e1 belief that express &apos;Lucy is rich&apos;, and it is represented of John&apos;s beliefs. Such nodes are considered as in the system&apos;s of John&apos;s 7belief space&amp;quot;. Non-dominated nodes, such as m14. m12, m15, m5. and m3, are the system&apos;s representaof its space (i.e.. they can be thought of as the object of an implicit &apos;I believe that&apos; case-frame; cf. CastaWeda 1975: 121-22. Kant 1787: 8131). If it is later determined that the &amp;quot;two&amp;quot; Lucies are the same, then a node of coreferentiality would be added (m16. in Fig. 2). Fig. 2. Lucy is young (m3). John believes that someone named &apos;Lucy&apos; is rich (m15). and John&apos;s Lucy is the system&apos;s Lucy (m16). Now consider the case where the system has no information about the &amp;quot;content&amp;quot; of John&apos;s belief. but does have information that John&apos;s belief is the Thus. whereas John might express his belief as. &apos;Linus&apos;s sister is rich&apos;. the system would express it as. &apos;(Lucy system) is by John to be rich&apos; (where &apos;(Lucy sysis the system&apos;s Lucy). This is a za representation of John&apos;s belief, and would be represented by node m12 of Figure 3. The strategy of separating entities in different belief spaces is needed in order to satisfy the two main properties of quasi-indicators. Consider the possible representations of sentence (3) in Figure 4 (adapted from Maida and Shapiro 1983: 316). This suffers from three major problems. First, it is ambiguous: It could be the representation of (3) or of (5) John believes that John is rich. But, as we have seen. (3) and (5) express quite different propositions; thus, they should be separate items in the data base. Second. Figure 4 cannot represent (5). For then we would have no easy or uniform way to represent (3) in the case where John does not know that he is named &apos;John&apos;: Figure 4 says that the person (m3) who is named &apos;John&apos; and who believes m6, believes that that person is rich; and this false in the amnesia case. believes young 66 Fig. 3. The system&apos;s young Lucy is believed by John to be rich. Fig. 4. A representation for &apos;John believes that he* is rich&apos; Third. Figure 4 cannot represent (3) either. it does not adequately represent the quasiindexical nature of the &apos;he&apos; in (3); Node m3 represents both &apos;John&apos; and &apos;he&apos;. hence is both inside and outside the intentional context, conto both of the properties quasiindicators. Finally, because of these representational inadequacies, the system would invalidly &amp;quot;infer&amp;quot; (6iii) from (6i)-(6ii); believes that he is rich. (ii) he = John (iii) John believes that John is rich. simply because premise (61) would be represented by the same network as conclusion (6iii). Rather, the general pattern for representing such sentences is illustrated in Figure 5. The the*&apos; in the English sentence is represented by node m2; its quasi-indexical nature is represented by means of node m10. Fig. 5. John believes that he* is rich (m2 is the system&apos;s representation of John&apos;s &amp;quot;self-concept expressed by John as &apos;I&apos; and by the system as &apos;he*&apos;) That nodes m2 and m5 must be distinct follows from our separation principle. But, since m2 is the system&apos;s representation of John&apos;s representation of himself, it must be within the system&apos;s representation of John&apos;s belief space; this is accomplished via nodes m10 and m9. representing belief that m2 is his selfrepresentation&amp;quot;. Node m9, with its EGO arc to m2, represents, roughly. the proposition &apos;m2 is me&apos;. representation of quasi-indexical sentences is thus a special case of the general for diggg of belief sen- When a gg is interpreted does not contain quasi-indicators, and can handled by the general schema for mg representations. Thus. (7) John is believed by himself to be rich would be represented by the network of Figure 4. Using an ATN parser-generator with a question-answering capability (based on Shapiro 1982). we are implementing a system that parses sentences representing beliefs mg gictointo our representations. generates appropriate sentences from such networks. It also &amp;quot;recognizes&amp;quot; the invalidity of arguments such as (5) since the premise and conclusion interpreted dicto)are longer represented by the same network. When given an appropriate inference rule, however, the system 67 willtreat as valid such inferences as the following: (8) (i) John believes that the editor of Byte is rich. believes that he* is the editor of Byte. Therefore, (iii) John believes that he* is rich In this case, an appropriate inference rule would be: (9) (Vx,y,z.F)Ex believes F(y) &amp; x believes z=y -&gt; x believes F(z)] In SNePS, inference rules are treated as propositions represented by nodes in the network. Thus. the network for (9) would be built by the SNePS User Language command given in Figure 6 (cf. Shapiro 1979). would modify the network of Figure 7 by adding new beliefs to (John system)&apos;s belief space and to (Mary John system)&apos;s belief space. but would use same nodes to represent John. Mary. and (build avb ($x Sy $z $F) &amp;ant (build agent *x verb (build lex believe) object (build which *y adj (build lex *F))) &amp;ant (build agent *x verb (find lex believe) object (build equiv *z equiv *y)) cq (build agent *x believe) object (build which *z adj (find lex *F)))) (pelievel&gt; Fig. 7. John believes that Mary believes that Lucy is rich. 6. SNePSUL command for building rule RIR for argument (8). CONTEXTS Our system can also handle sentences involving iterated belief contexts. Consider John believes that Mary believes that is rich. The interpretation of this that we are most interested in representing treats (10) as the dictorepresentation of John&apos;s of Mary&apos;s belief that is rich. On this interpretation, we need to the system&apos;iJohn--(John system)--the representation of John system)--and the system&apos;s representation of John&apos;s of Mary&apos;s.Lucy--(Lucy John system). This is done by the network of Figure 7. Such a network is built recursively as follows: The parser maintains a stack of &amp;quot;believers&amp;quot;. Each time a belief-sentence is parsed, it is made the object of a belief of the previous believer in the stack. Structure-sharing is used wherever possible. Thus, John believes that Mary believes that is sweet The system is also capable of handling sequences of new information. For instance, suppose that the system is given the following information at three successive times: tl: (12) The Lucy that Lucy&apos;s is sweet. t2: (13) The is t3: (14) The = Lucy&apos;s Lucy. Then it will build the networks of Figures 8-10, successively. At tl (Fig. 8). node m3 represents system&apos;s m7 represents Lucy. At t2 (Fig. 9), m13 is built, representing the belief that the system&apos;s is not believed to be--and, indeed, might be-- Lucy) is At t3 (Fig. 11), m14 is built, representing the system&apos;s new belief that is really only one is a merging the two From now on. all properof Lucy will inherited by the . by means of an rule for the EQUIV case-frame (roughly, the indiscernibility of identicals). are assumingthat the system&apos;s concept of sweetness (node m8) is also the system&apos;s concept concept of sweetness. This asseems warranted, since allnodes are in the system&apos;s belief space. If the system had reato believe that ill concept of sweetness diffrom could--and would have to-be represented. 68 8. Lucy that sweet. (sweet) 9. Lucy that sweet. believer) is sweet. WORK There are several directions for future modifications. First, the node-merging mechanism of the EQUIV case-frame with its associated rule needs to be generalized: Its current interpretation is co-referentiality; but if the sequence (12)-(14) were embedded in someone else&apos;s beliefspace, then co-referentiality might be incorrect. What is needed is a notion of &apos;co-referentiality- The relation of (Castaiieda to be more appropriate. Second, the system needs to be much more flexible. Currently. it treats all sentences of the form (15) x believes that F(y) canonically dictaand all sentences of the form y is believed by x to F 10. that Lucy is sweet. Lucy is sweet, and the system&apos;s Lucy is Lucy&apos;s Lucy. canonically Lg. ordinary conversation, both sentences can in either way, depending on context, including prior beliefs as well as idiosyncracies of particular predicates. For instance. given (1). above, and the fact that John is the editor of Axle.. most people would infer (3). But given (17) John believes that all identical twins are conceited. (18) Unknown to John. he is an identical twin people would (19) John believes that he* is conceited. Thus, we want to allow the system to make the most interpretations (d1 ditto) of users&apos; belief-reports, based on prior beliefs and on subject matter, and to modify its initial representation as more information is received. SUIVARY A deductive knowledge-representation system that is to be able to reason about the beliefs of cognitive agents must have a scheme for representing beliefs. This scheme must be able to distinguish among the &amp;quot;belief spaces&amp;quot; of different agents, as well as be able to handle &amp;quot;nested belief spaces&amp;quot;, i.e., second-order beliefs such as the beliefs of one agent about the beliefs of another. We have shown how a scheme for representing beliefs as or dictocan distinguish the items in different belief spaces (including nested belief spaces). yet merge&amp;quot; the items on the basis of new information. This general scheme also enables the system to adequately represent sentences containing quasi-indicators, while not allowing invalid inferences to be drawn from them. 69</abstract>
<title confidence="0.68308">REFERENCES</title>
<author confidence="0.721293">J A Barnden</author>
<author confidence="0.721293">Intensions as Such An Outline</author>
<note confidence="0.929678423076923">IJCAI-83 (1983)280-286. J. Brachman, in a Concept: Structural for Semantic Networks,&amp;quot; Interna- JournalInn Studies 9(1977)127-52. Hector-Neri Castaiieda. &amp;quot;Indicators and Quasi- 4(1967)85-100. &amp;quot;Thinking and the Structure of the World&amp;quot; - (1972). PhilosophiR 4(1974)3-40. and Sameness,&amp;quot; - 5(1975)121-50. &amp;quot;Reference. Reality and Perceptual Fields.&amp;quot; annealing&amp; and. Addresses2L Afisociation53(1980)763-823. L. G. Creary. &amp;quot;Propositional Attitudes: Fregean Representation and Simulative Reasoning, IJCAI-79 (1979)176-81. Frege. &amp;quot;On Sense and (1892). in Translationslam the. Writingsa prey..,ed. by P. Geach and M. Black (Oxford: Basil Blackwell. 1970): 56-78. Kant. critiqueat Reason.2nd ed. (1787). trans. N. Kemp Smith (New York: St. Martin&apos;s Press. 1929). Anthony S. Maids and Stuart C. Shapiro. &amp;quot;Intensional Concepts in Propositional Semantic Net- Science.6(1982)291-330. Alexius Meinong. &amp;quot;Ueber Gegenstandstheorie&amp;quot; in Meinong Gesamtausgabe.Vol. II, ed. R. Haller (Graz. Austria: Akademische Drucku. Verlagsanstalt. 1971): 481-535. translation in R. Chisholm (ed.). Realand tha Backgroundat Planamanalagx. York: Free Press. 1960): 76-117. R. C. Moore. &amp;quot;Reasoning about Knowledge and Action.&amp;quot; IJCAI-77 (1977)223-27. Nils J. Nilsson. &amp;quot;Artificial Intelligence Prepares 2001. Magazinp4.4(Winter 1983)7-14. William J. Rapaport. &amp;quot;Meinongian Theories and a Paradox.&amp;quot; Soils12(1978)153-80; errata. 13(1979)125. â¢ &amp;quot;How to Make the World Fit Our Language: An in Meinongian Semantics.&amp;quot; Philoso- Studien14(1981)1-21. Stuart C. Shapiro. The SNePS Semantic Network Processing System,&amp;quot; in N. V. Findler (ed.). Networks(New York: Academic Press, 1979): 179-203. . Augmented Transition Network Grammars For Generation From Semantic Networks.&amp;quot; Americaa Journalat Computational 8(1982)12-25.</note>
<title confidence="0.7095785">Yorick Wilks and Janusz Bien. &amp;quot;Beliefs. Points of and Multiple Environments,&amp;quot; Sci-</title>
<author confidence="0.850459">What&apos;s in a Link The Semantics</author>
<note confidence="0.64448875">of Semantic Networks.&amp;quot; in D. G. Bobrow and A. M. (eds.). Ropreaentatinn (New York: Academic Press, 1975): 35-79. 70</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J A Barnden</author>
</authors>
<title>Intensions as Such: An Outline.&amp;quot;</title>
<date>1983</date>
<contexts>
<context position="1745" citStr="Barnden 1983" startWordPosition="251" endWordPosition="252">c Network Processing System (SNePS) and an ATN parser-generator with a question-answering capability. 1. INTRODUCTION Consider a deductive knowledge-representation system whose data base contains information about various people (e.g.. its users), other (perhaps interacting) systems, or even itself. In order for the system to learn more about these entities--to expand its knowledge&amp;quot; base--it should contain information about the beliefs (or desires, wants, or other cognitive states) of these entities, and it should be able to reason about them (cf. Moore 1977, Creary 1979. Wilks and Bien 1983, Barnden 1983. and Nilsson 1983: 9). Such a data base constitutes the &amp;quot;knowledge&amp;quot; (more accurately, the belirfs) of the system about these entities and about thaiL beliefs. Among the interrelated issues in knowledge representation that can be raised in such a context are those of multiple reference and the proper treatment of pronouns. For instance, is the person named &apos;Lucy&apos; whom John believes to be rich the same as the person named &apos;Lucy who is believed by the system to be young? How can the system (a) represent the person named &apos;Lucy&apos; who is an object of its am belief without (b) confusing her with the </context>
</contexts>
<marker>Barnden, 1983</marker>
<rawString>J. A. Barnden, &amp;quot;Intensions as Such: An Outline.&amp;quot; IJCAI-83 (1983)280-286.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R J Brachman</author>
</authors>
<title>What&apos;s in a Concept: Structural Foundations for Semantic Networks,&amp;quot;</title>
<journal>Internaliana], Journal Inn Man-Machine Studies</journal>
<pages>9--1977</pages>
<marker>Brachman, </marker>
<rawString>R. J. Brachman, -What&apos;s in a Concept: Structural Foundations for Semantic Networks,&amp;quot; Internaliana], Journal Inn Man-Machine Studies 9(1977)127-52.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Hector-Neri Castaiieda</author>
</authors>
<title>Indicators and QuasiIndicators,</title>
<journal>Amaziala rjailaragazajaal Quarterly</journal>
<pages>4--1967</pages>
<marker>Castaiieda, </marker>
<rawString>Hector-Neri Castaiieda. &amp;quot;Indicators and QuasiIndicators, Amaziala rjailaragazajaal Quarterly 4(1967)85-100.</rawString>
</citation>
<citation valid="true">
<title>Thinking and the Structure of the World&amp;quot; -</title>
<date>1972</date>
<pages>5--1975</pages>
<marker>1972</marker>
<rawString>&amp;quot;Thinking and the Structure of the World&amp;quot; - (1972). PhilosophiR 4(1974)3-40. &amp;quot;Identity and Sameness,&amp;quot; Philoanphia. - 5(1975)121-50.</rawString>
</citation>
<citation valid="false">
<title>Reference. Reality and Perceptual Fields.&amp;quot; - annealing&amp; and. Addresses 2L the.</title>
<journal>American Philosophical Afisociation</journal>
<pages>53--1980</pages>
<marker></marker>
<rawString>&amp;quot;Reference. Reality and Perceptual Fields.&amp;quot; - annealing&amp; and. Addresses 2L the. American Philosophical Afisociation 53(1980)763-823.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L G Creary</author>
</authors>
<title>Propositional Attitudes: Fregean Representation and Simulative Reasoning,</title>
<date>1979</date>
<contexts>
<context position="1710" citStr="Creary 1979" startWordPosition="245" endWordPosition="246"> representations using the Semantic Network Processing System (SNePS) and an ATN parser-generator with a question-answering capability. 1. INTRODUCTION Consider a deductive knowledge-representation system whose data base contains information about various people (e.g.. its users), other (perhaps interacting) systems, or even itself. In order for the system to learn more about these entities--to expand its knowledge&amp;quot; base--it should contain information about the beliefs (or desires, wants, or other cognitive states) of these entities, and it should be able to reason about them (cf. Moore 1977, Creary 1979. Wilks and Bien 1983, Barnden 1983. and Nilsson 1983: 9). Such a data base constitutes the &amp;quot;knowledge&amp;quot; (more accurately, the belirfs) of the system about these entities and about thaiL beliefs. Among the interrelated issues in knowledge representation that can be raised in such a context are those of multiple reference and the proper treatment of pronouns. For instance, is the person named &apos;Lucy&apos; whom John believes to be rich the same as the person named &apos;Lucy who is believed by the system to be young? How can the system (a) represent the person named &apos;Lucy&apos; who is an object of its am belief </context>
</contexts>
<marker>Creary, 1979</marker>
<rawString>L. G. Creary. &amp;quot;Propositional Attitudes: Fregean Representation and Simulative Reasoning, IJCAI-79 (1979)176-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gottlob Frege</author>
</authors>
<title>On Sense and Reference- (1892).</title>
<date>1970</date>
<booktitle>in Translations lam the. Philosophical Writings</booktitle>
<pages>56--78</pages>
<editor>a Gottlob prey.., ed. by P. Geach and M. Black (Oxford:</editor>
<publisher>Basil Blackwell.</publisher>
<marker>Frege, 1970</marker>
<rawString>Gottlob Frege. &amp;quot;On Sense and Reference- (1892). in Translations lam the. Philosophical Writings a Gottlob prey.., ed. by P. Geach and M. Black (Oxford: Basil Blackwell. 1970): 56-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Immanuel Kant</author>
</authors>
<title>critique at EuLl Reason.</title>
<date>1929</date>
<editor>2nd ed. (1787). trans. N. Kemp Smith (New York:</editor>
<publisher>St. Martin&apos;s Press.</publisher>
<marker>Kant, 1929</marker>
<rawString>Immanuel Kant. critique at EuLl Reason. 2nd ed. (1787). trans. N. Kemp Smith (New York: St. Martin&apos;s Press. 1929).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Anthony S Maids</author>
<author>Stuart C Shapiro</author>
</authors>
<title>Intensional Concepts in Propositional Semantic Networks.&amp;quot;</title>
<journal>CognirivP Science.</journal>
<pages>6--1982</pages>
<marker>Maids, Shapiro, </marker>
<rawString>Anthony S. Maids and Stuart C. Shapiro. &amp;quot;Intensional Concepts in Propositional Semantic Networks.&amp;quot; CognirivP Science. 6(1982)291-330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexius Meinong</author>
</authors>
<title>Ueber Gegenstandstheorie&amp;quot;</title>
<date>1904</date>
<journal>English translation</journal>
<booktitle>Akademische Druck- u. Verlagsanstalt.</booktitle>
<pages>481--535</pages>
<editor>Vol. II, ed. R. Haller (Graz. Austria:</editor>
<publisher>Free Press.</publisher>
<location>New York:</location>
<contexts>
<context position="5341" citStr="Meinong 1904" startWordPosition="880" endWordPosition="881">ch could just as well have said (2). The first &apos;he&apos; in (4) is not a quasi-indicator: It occurs outside the believes-that context, and it can be replaced by &apos;John&apos; or by &apos;the editor of Ufa&apos;. salva ygLi= tate, But the &apos;he*&apos; in )4) and the &apos;he himself&apos; in (2) could not be thus replaced by &apos;the editor of Dvte&apos; - given our scenario - ay= though John is the editor of Dyte. And if poor John also suffered from amnesia, it could not be replaced by &apos;John&apos; either. 1. REPRESENTATIONS Entities such as the Lucy who is the object of John&apos;s belief are intentional (mental), hence intensional. (Cf. Frege 1892; Meinong 1904; Castaileda 1972; Rapaport 1978. 1981.) Moreover, the entities represented in the data base are the objects of the system&apos;s. beliefs, and. so, are also intentional, hence intensional. We represent sentences by means of propositional semantic networks. using the Semantic Network Processing System (SNePS; Shapiro 1979). which treats nodes as representing intensional concepts (cf. Woods 1975. Brachman 1977. Maids and Shapiro 1982). We claim that in the absence of prior knowledge of co-referentiality. the entities within belief-contexts should be represented separately. from entities guTOsip the </context>
</contexts>
<marker>Meinong, 1904</marker>
<rawString>Alexius Meinong. &amp;quot;Ueber Gegenstandstheorie&amp;quot; (1904). in Alexius Meinong Gesamtausgabe. Vol. II, ed. R. Haller (Graz. Austria: Akademische Druck- u. Verlagsanstalt. 1971): 481-535. English translation in R. Chisholm (ed.). Realiam and tha Background at Planamanalagx. (New York: Free Press. 1960): 76-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>Reasoning about Knowledge and Action.&amp;quot;</title>
<date>1977</date>
<contexts>
<context position="1697" citStr="Moore 1977" startWordPosition="243" endWordPosition="244">ion of these representations using the Semantic Network Processing System (SNePS) and an ATN parser-generator with a question-answering capability. 1. INTRODUCTION Consider a deductive knowledge-representation system whose data base contains information about various people (e.g.. its users), other (perhaps interacting) systems, or even itself. In order for the system to learn more about these entities--to expand its knowledge&amp;quot; base--it should contain information about the beliefs (or desires, wants, or other cognitive states) of these entities, and it should be able to reason about them (cf. Moore 1977, Creary 1979. Wilks and Bien 1983, Barnden 1983. and Nilsson 1983: 9). Such a data base constitutes the &amp;quot;knowledge&amp;quot; (more accurately, the belirfs) of the system about these entities and about thaiL beliefs. Among the interrelated issues in knowledge representation that can be raised in such a context are those of multiple reference and the proper treatment of pronouns. For instance, is the person named &apos;Lucy&apos; whom John believes to be rich the same as the person named &apos;Lucy who is believed by the system to be young? How can the system (a) represent the person named &apos;Lucy&apos; who is an object of i</context>
</contexts>
<marker>Moore, 1977</marker>
<rawString>R. C. Moore. &amp;quot;Reasoning about Knowledge and Action.&amp;quot; IJCAI-77 (1977)223-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nils J Nilsson</author>
</authors>
<title>Artificial Intelligence Prepares for</title>
<date>2001</date>
<journal>AI Magazinp</journal>
<volume>4</volume>
<pages>1983--7</pages>
<marker>Nilsson, 2001</marker>
<rawString>Nils J. Nilsson. &amp;quot;Artificial Intelligence Prepares for 2001. AI Magazinp 4.4(Winter 1983)7-14.</rawString>
</citation>
<citation valid="false">
<authors>
<author>William J Rapaport</author>
</authors>
<title>Meinongian Theories and a Russellian Paradox.&amp;quot; Soils 12(1978)153-80;</title>
<pages>13--1979</pages>
<marker>Rapaport, </marker>
<rawString>William J. Rapaport. &amp;quot;Meinongian Theories and a Russellian Paradox.&amp;quot; Soils 12(1978)153-80; errata. 13(1979)125.</rawString>
</citation>
<citation valid="false">
<title>How to Make the World Fit Our Language: An Essay in Meinongian Semantics.&amp;quot;</title>
<journal>Grazer Philosophische Studien</journal>
<pages>14--1981</pages>
<marker></marker>
<rawString>â¢ &amp;quot;How to Make the World Fit Our Language: An Essay in Meinongian Semantics.&amp;quot; Grazer Philosophische Studien 14(1981)1-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart C Shapiro</author>
</authors>
<title>The SNePS Semantic Network Processing System,&amp;quot;</title>
<date>1979</date>
<pages>179--203</pages>
<editor>in N. V. Findler (ed.). Associative.</editor>
<publisher>Networks</publisher>
<location>New York:</location>
<contexts>
<context position="5660" citStr="Shapiro 1979" startWordPosition="929" endWordPosition="930">r scenario - ay= though John is the editor of Dyte. And if poor John also suffered from amnesia, it could not be replaced by &apos;John&apos; either. 1. REPRESENTATIONS Entities such as the Lucy who is the object of John&apos;s belief are intentional (mental), hence intensional. (Cf. Frege 1892; Meinong 1904; Castaileda 1972; Rapaport 1978. 1981.) Moreover, the entities represented in the data base are the objects of the system&apos;s. beliefs, and. so, are also intentional, hence intensional. We represent sentences by means of propositional semantic networks. using the Semantic Network Processing System (SNePS; Shapiro 1979). which treats nodes as representing intensional concepts (cf. Woods 1975. Brachman 1977. Maids and Shapiro 1982). We claim that in the absence of prior knowledge of co-referentiality. the entities within belief-contexts should be represented separately. from entities guTOsip the context that might be co-referential with them. Suppose the system&apos;s beliefs include that a person named &apos;Lucy&apos; is young and that John believes that a (possibly different) person named &apos;Lucy&apos; is rich. We represent this with the network of Fig. 1. Fig. 1. Lucy is young (m3) and John believes that someone named &apos;Lucy&apos; i</context>
<context position="11406" citStr="Shapiro 1979" startWordPosition="1905" endWordPosition="1906"> same network. When given an appropriate inference rule, however, the system 67 will treat as valid such inferences as the following: (8) (i) John believes that the editor of Byte is rich. (ii) John believes that he* is the editor of Byte. Therefore, (iii) John believes that he* is rich In this case, an appropriate inference rule would be: (9) (Vx,y,z.F)Ex believes F(y) &amp; x believes z=y -&gt; x believes F(z)] In SNePS, inference rules are treated as propositions represented by nodes in the network. Thus. the network for (9) would be built by the SNePS User Language command given in Figure 6 (cf. Shapiro 1979). would modify the network of Figure 7 by adding new beliefs to (John system)&apos;s belief space and to (Mary John system)&apos;s belief space. but would use the same nodes to represent John. Mary. and Lucy. (build avb ($x Sy $z $F) &amp;ant (build agent *x verb (build lex believe) object (build which *y adj (build lex *F))) &amp;ant (build agent *x verb (find lex believe) object (build equiv *z equiv *y)) cq (build agent *x verb (find lex believe) object (build which *z adj (find lex *F)))) (pelievel&gt; Fig. 7. John believes that Mary believes that Lucy is rich. Fig. 6. SNePSUL command for building rule (9), RI</context>
</contexts>
<marker>Shapiro, 1979</marker>
<rawString>Stuart C. Shapiro. The SNePS Semantic Network Processing System,&amp;quot; in N. V. Findler (ed.). Associative. Networks (New York: Academic Press, 1979): 179-203.</rawString>
</citation>
<citation valid="false">
<authors>
<author>-Generalized</author>
</authors>
<title>Augmented Transition Network Grammars For Generation From Semantic Networks.&amp;quot;</title>
<journal>America a Journal at Computational Linguistics</journal>
<pages>8--1982</pages>
<marker>-Generalized, </marker>
<rawString>. -Generalized Augmented Transition Network Grammars For Generation From Semantic Networks.&amp;quot; America a Journal at Computational Linguistics 8(1982)12-25.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yorick Wilks</author>
<author>Janusz Bien</author>
</authors>
<title>Beliefs. Points of View. and Multiple Environments,&amp;quot;</title>
<journal>Cognirivp Sciman&amp;</journal>
<pages>7--1983</pages>
<marker>Wilks, Bien, </marker>
<rawString>Yorick Wilks and Janusz Bien. &amp;quot;Beliefs. Points of View. and Multiple Environments,&amp;quot; Cognirivp Sciman&amp; 7(1983)95-119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William A Woods</author>
</authors>
<title>What&apos;s in a Link: The Semantics of Semantic Networks.&amp;quot;</title>
<date>1975</date>
<booktitle>Ropreaentatinn and Understandinv</booktitle>
<pages>35--79</pages>
<editor>in D. G. Bobrow and A. M. Collins (eds.).</editor>
<publisher>Academic Press,</publisher>
<location>New York:</location>
<contexts>
<context position="5733" citStr="Woods 1975" startWordPosition="939" endWordPosition="940">ffered from amnesia, it could not be replaced by &apos;John&apos; either. 1. REPRESENTATIONS Entities such as the Lucy who is the object of John&apos;s belief are intentional (mental), hence intensional. (Cf. Frege 1892; Meinong 1904; Castaileda 1972; Rapaport 1978. 1981.) Moreover, the entities represented in the data base are the objects of the system&apos;s. beliefs, and. so, are also intentional, hence intensional. We represent sentences by means of propositional semantic networks. using the Semantic Network Processing System (SNePS; Shapiro 1979). which treats nodes as representing intensional concepts (cf. Woods 1975. Brachman 1977. Maids and Shapiro 1982). We claim that in the absence of prior knowledge of co-referentiality. the entities within belief-contexts should be represented separately. from entities guTOsip the context that might be co-referential with them. Suppose the system&apos;s beliefs include that a person named &apos;Lucy&apos; is young and that John believes that a (possibly different) person named &apos;Lucy&apos; is rich. We represent this with the network of Fig. 1. Fig. 1. Lucy is young (m3) and John believes that someone named &apos;Lucy&apos; is rich (m12). The section of network dominated by nodes m7 and m9 is the </context>
</contexts>
<marker>Woods, 1975</marker>
<rawString>William A. Woods. &amp;quot;What&apos;s in a Link: The Semantics of Semantic Networks.&amp;quot; in D. G. Bobrow and A. M. Collins (eds.). Ropreaentatinn and Understandinv (New York: Academic Press, 1975): 35-79.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>