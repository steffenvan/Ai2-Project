<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019358">
<title confidence="0.983597">
SAP-RI: A Constrained and Supervised Approach for Aspect-Based
Sentiment Analysis
</title>
<author confidence="0.964843">
Nishtha Malhotra1,2∗, Akriti Vij1,2,∗, Naveen Nandan1 and Daniel Dahlmeier1
</author>
<affiliation confidence="0.8386965">
1Research &amp; Innovation, SAP Asia, Singapore
2Nanyang Technological University, Singapore
</affiliation>
<email confidence="0.99863">
{nishtha.malhotra,akriti.vij,naveen.nandan,d.dahlmeier}@sap.com
</email>
<sectionHeader confidence="0.997386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999886444444445">
We describe the submission of the SAP
Research &amp; Innovation team to the Se-
mEval 2014 Task 4: Aspect-Based Senti-
ment Analysis (ABSA). Our system fol-
lows a constrained and supervised ap-
proach for aspect term extraction, catego-
rization and sentiment classification of on-
line reviews and the details are included in
this paper.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999826916666667">
The increasing popularity of the internet as a
source of information, and e-commerce as a way
of life, has led to a major surge in the number of
reviews that can be found online, for a wide range
of products and services. Consequently, more and
more consumers have taken to consulting these on-
line reviews as part of their pre-purchase research
before deciding on availing services from a local
business or investing in a product from a particu-
lar brand. This calls for innovative techniques for
the sentiment analysis of online reviews so as to
generate accurate and relevant recommendations.
Sentiment analysis has been extensively studied
and applied in different domains. Predicting the
sentiment polarity (positive, negative, neutral) of
user opinions by mining user reviews (Hu and Liu,
2004; Liu, 2012; Pang and Lee, 2008; Liu, 2010)
has been of high commercial and research interest.
In these studies, sentiment analysis is often con-
ducted at one of the three levels: document level,
sentence level or attribute level.
Through the SemEval 2014 Task 4 on Aspect
Based Sentiment Analysis (Pontiki et al., 2014),
we explore sentiment analysis at the aspect level.
</bodyText>
<footnote confidence="0.946474">
∗ The work was done during an internship at SAP.
This work is licenced under a Creative Commons Attribution
4.0 International License. Page numbers and proceedings
footer are added by the organizers. License details: http:
//creativecommons.org/licenses/by/4.0/
</footnote>
<bodyText confidence="0.999787771428572">
The task consists of four subtasks: in subtask 1 as-
pect term extraction, participants need to identify
the aspect terms present in a sentence and return
a list containing all distinct aspect terms, in sub-
task 2 aspect term polarity, participants were to
determine the polarity of each aspect term in a sen-
tence, in subtask 3 aspect category detection, par-
ticipants had to identify the aspect categories dis-
cussed in a given sentence, and in subtask 4 aspect
category polarity, participants were to determine
the polarity of each aspect category. The polarity
classification subtasks consider sentiment analysis
to be a three-way classification problem between
positive, negative and neutral sentiment. On the
other hand, the aspect category detection subtask
is a multi-label classification problem where one
sentence can be labelled with more than one as-
pect category.
In this paper, we describe the submission of the
SAP-RI team to the SemEval 2014 Task 4. We
make use of supervised techniques to extract the
aspects of interest (Jakob and Gurevych, 2010),
categorize them (Lu et al., 2011) and predict the
sentiment of customer online reviews on Laptops
and Restaurants. We developed a constrained sys-
tem for aspect-based sentiment analysis of these
online reviews. The system is constrained in the
sense that we only use the training data that was
provided by the challenge organizers and no other
external data sources. Our system performed rea-
sonably well, especially with a F1 score of 75.61%
for the aspect category polarity subtask, 79.04%
F1 score on the aspect category detection task and
66.61% F1 score on the aspect term extraction
task.
</bodyText>
<sectionHeader confidence="0.949283" genericHeader="introduction">
2 Subtask 1: Aspect Term Extraction
</sectionHeader>
<bodyText confidence="0.99970775">
Given a review with annotated entities in the train-
ing set, the task was to extract the aspect terms for
reviews in the test set. For this subtask, training,
development and testing were conducted for both
</bodyText>
<page confidence="0.892147">
517
</page>
<note confidence="0.6723125">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 517–521,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.909342">
the laptop and the restaurant domain.
</bodyText>
<subsectionHeader confidence="0.665345">
2.1 Features
</subsectionHeader>
<bodyText confidence="0.9928965">
Each review was represented as a feature vector
made up of the following features:
</bodyText>
<listItem confidence="0.99973175">
• Word N-grams: all unigrams, bigrams and
trigrams from the review text
• Casing: presence or absence of capital case/
title case words
• POS tags: POS tags of a word and its neigh-
bours
• Parse dependencies and relations: parse
dependency relations of the aspects, i.e.,
presence/absence of adjectives and adverbs in
the dependency parse tree
• Punctuation Marks: presence/absence of
punctuation marks, such as ?, !
</listItem>
<subsectionHeader confidence="0.999029">
2.2 Method
</subsectionHeader>
<bodyText confidence="0.99998292">
We approach the task by casting it as a sequence
tagging task where each token in a candidate sen-
tence is labelled as either Beginning, Inside or
Outside (BIO). We then employ conditional ran-
dom fields (CRF), which is a discriminative, prob-
abilistic model for sequence data with state-of-the-
art performance (Lafferty et al., 2001). A linear-
chain CRF tries to estimate the conditional prob-
ability of a label sequence y given the observed
features x, where each label yt is conditioned on
the previous label yt−1. In our case, we use BIO
CoNLL-style tags (Sang and De Meulder, 2003).
During development, we split the training data
in the ratio of 60:20:20 as training, development
(dev) and testing (dev-test). We train the CRF
model on the training set of the data, perform
feature selection based on the dev set, and test
the resulting model on the dev-test. In all ex-
periments, we use the CRF++1 implementation
of conditional random fields with the parameter
c=4.0. This value was chosen based on manual
observation. We perform a feature ablation study
and the results are reported in Table 1. Features
listed in section 2.1 were those that were retained
for the final run.
</bodyText>
<page confidence="0.462163">
1code.google.com/p/crfpp/
</page>
<sectionHeader confidence="0.9789445" genericHeader="method">
3 Subtask 2: Aspect Term Polarity
Estimation
</sectionHeader>
<bodyText confidence="0.9999805">
For this subtask, the training, development and
testing was done using reviews on laptops and
restaurants. Given the aspect terms in a sentence,
the task was to predict their sentiment polarities.
</bodyText>
<subsectionHeader confidence="0.915748">
3.1 Features
</subsectionHeader>
<bodyText confidence="0.954712">
For each review, we used the following features:
</bodyText>
<listItem confidence="0.999690818181818">
• Word N-grams: all lowercased unigrams,
bigrams and trigrams from the review text
• Polarity of neighbouring adjectives: ex-
tracted word sentiment from SentiWordNet
lexicon (Baccianella et al., 2010)
• Neighbouring POS tags: the POS tags of up
to neighbouring 3 words
• Parse dependencies and relations: parse
dependency relations of the aspects, i.e.,
presence/absence of adjectives and adverbs in
the dependency parse tree
</listItem>
<subsectionHeader confidence="0.99889">
3.2 Method
</subsectionHeader>
<bodyText confidence="0.9999053">
For each aspect term of a sentence, the afore-
mentioned features were extracted. For exam-
ple, for the term Sushi in the sentence Sushi
was delicious., the following feature vector is
constructed, {aspect: ’sushi’, advmod:’null’,
amod:’delicious’, uni sushi: 1, uni was: 1,
uni delicious, uni the: 0, .. }.
We then treat the aspect sentiment polarity es-
timation as a multi-class classification task where
each instance would be labelled as either positive,
negative or neutral. For the classification task, we
experimented with Naive Bayes and Support Vec-
tor Machines (SVM) – both linear and RBF ker-
nels – and it was observed that linear SVM per-
formed best. Hence, we use linear SVM for the
classification task. Table 2 summarizes the results
obtained from our experiments for various feature
combinations. The classifiers used are implemen-
tations from scikit-learn2, which is also used for
the remaining tasks.
</bodyText>
<sectionHeader confidence="0.995102" genericHeader="method">
4 Subtask3: Aspect Category Detection
</sectionHeader>
<bodyText confidence="0.999804">
Given a review with annotated entities or aspect
terms, the task was to predict the aspect categories.
</bodyText>
<footnote confidence="0.376508">
2scikit-learn.org/stable/
</footnote>
<page confidence="0.985484">
518
</page>
<table confidence="0.999919">
Features Precision Recall F1-Score
N-grams, POS tags 0.7655 0.4283 0.5496
N-grams, Parse relations, POS tags 0.8192 0.6641 0.7336
N-Grams, Parse relations, POS tags, casing 0.8101 0.6641 0.7299
N-grams, Parse relations, POS tags, ! 0.8116 0.6641 0.7305
N-grams, Parse relations, POS tags,!, ? 0.8123 0.6672 0.7326
</table>
<tableCaption confidence="0.997323">
Table 1: Training-phase experimental results for Subtask 1 on Restaurant reviews.
</tableCaption>
<table confidence="0.999747">
Features Laptops Restaurants
Neighbouring words, 2,3 POS grams, bigrams, trigrams, Sentiment,1,2 ngram lower 0.4196 0.5997
Parse Relations, 2,3 POS grams, bigrams, trigrams, Sentiment, 1,2 ngram lower 0.5869 0.6375
Parse Relations, Neighbouring words, bigram, trigrams, Sentiment, 1,2 ngram lower 0.5848 0.6380
Parse Relations, 2,3 POS grams, Neighbouring words, Sentiment, 1,2 ngram lower 0.5890 0.6240
Parse Relations, 2,3 POS grams , Neighbouring words, bigram, trigrams, 1,2 ngram lower 0.5626 0.6239
Parse Relations, 2,3 POS grams , Neighbouring words, bigram, trigrams, Sentiment 0.5922 0.6409
</table>
<tableCaption confidence="0.999776">
Table 2: Training-phase experimental results (Accuracy) for Subtask 2.
</tableCaption>
<bodyText confidence="0.997944">
As one sentence in a review could belong to mul-
tiple aspect categories, we model the task as a
multi-label classification problem, i.e., given an
instance, predict all labels that the instance fits to.
</bodyText>
<subsectionHeader confidence="0.910673">
4.1 Features
</subsectionHeader>
<bodyText confidence="0.999992857142857">
We experimented with different features, for ex-
ample unigrams, dependency tree relations, bi-
grams, POS tags and sentiment of the words (Sen-
tiWordNet), but using just the unigrams alone hap-
pened to yield the best result. The feature vector
was merely a bag-of-words vector indicating the
presence or absence of a word in an instance.
</bodyText>
<subsectionHeader confidence="0.996148">
4.2 Method
</subsectionHeader>
<bodyText confidence="0.999748882352941">
The training instances were divided into 5 sets
based on the aspect categories and thereby, we
treated the multi-label classification task as 5 dif-
ferent binary classification tasks. Hence, we used
an ensemble of binary classifiers for the multi-
label classification. An SVM model was trained
using one classifier per class to distinguish it from
all other classes. For the binary classification
tasks, directly estimating a linear separating func-
tion (such as linear SVM) gave better results, as
shown in Table 3. Finally, the results of the 5 bi-
nary classifiers were combined to label the test in-
stance.
The category Miscellaneous was observed to
have the lowest accuracy, probably due to the fact
that miscellaneous captures all those aspects terms
that do not have a clearly defined category.
</bodyText>
<sectionHeader confidence="0.981632" genericHeader="method">
5 Subtask4 Aspect Category Polarity
Detection
</sectionHeader>
<bodyText confidence="0.99977675">
For each review with pre-labelled aspect cate-
gories, the task was to produce a model which
predicts the sentiment polarity of each aspect cat-
egory.
</bodyText>
<subsectionHeader confidence="0.957714">
5.1 Features
</subsectionHeader>
<bodyText confidence="0.9998745">
The training data contains reviews with the po-
larity for the corresponding aspect category. The
models performed best on using just unigram and
bigram features.
</bodyText>
<subsectionHeader confidence="0.999788">
5.2 Method
</subsectionHeader>
<bodyText confidence="0.999968">
The training instances were split into 5 sets based
on the aspect categories. We make use of the sen-
timent polarity classifier, as described in section
3.2, thereby, training one sentiment polarity classi-
fier for each aspect category. Table 4 indicates the
performance of different classifiers for this task,
using features as discussed in section 5.1.
</bodyText>
<sectionHeader confidence="0.999872" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.999894">
Table 5 gives an overview of the performance of
our system in this year’s task based on the offi-
cial scores from the organizers. We see that our
system performs relatively well for subtasks 1, 3
and 4, while for subtask 2 the F1 scores are be-
hind the best system by about 12%. As observed,
a sentence could have more than one aspect and
each of these aspects could have different polar-
ities expressed. Including features that preserve
the context of the aspect could probably improve
the performance in the subtask 2. In most cases,
a simple set of features was enough to result in a
</bodyText>
<page confidence="0.995088">
519
</page>
<table confidence="0.998709166666667">
Restaurants Category Naive Bayes AdaBoost LinearSVC
Food 0.7130 0.8000 0.8470
Service 0.6064 0.9137 0.8997
Miscellaneous 0.6710 0.7490 0.7890
Ambience 0.6770 0.9063 0.8940
Price 0.7608 0.8548 0.9590
</table>
<tableCaption confidence="0.993921">
Table 3: Training-phase experimental results (F1 score) for Subtask 3.
</tableCaption>
<table confidence="0.999540333333333">
Restaurants Category Naive Bayes AdaBoost LinearSVC
Food 0.7136 0.6711 0.7417
Service 0.6733 0.5244 0.6688
Miscellaneous 0.4756 0.3170 0.4756
Ambience 0.6574 0.7232 0.6885
Price 0.7477 0.7752 0.6651
</table>
<tableCaption confidence="0.999852">
Table 4: Training-phase experimental results (F1 score) for Subtask 4.
</tableCaption>
<bodyText confidence="0.98052025">
high F1 score, for example, in subtask 3 a bag-of-
words feature set proved to yield a relatively high
F1 score. In general, for the classification tasks,
we observe that the linear SVM performs best.
</bodyText>
<table confidence="0.998921714285714">
Subtask Dataset Best score Our score Rank
1 Laptops 74.55 66.61 8/27
1 Restaurants 84.01 77.88 12/29
2 Laptops 70.48 58.56 18/32
2 Restaurants 80.95 69.92 22/36
3 Restaurants 88.57 79.04 7/21
4 Restaurants 82.92 75.61 5/25
</table>
<tableCaption confidence="0.975579">
Table 5: Results (F1 score and ranking) for the
Semeval-2014 test set.
</tableCaption>
<sectionHeader confidence="0.99798" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999966666666667">
In this paper, we have described the submission of
the SAP-RI team to the SemEval 2014 Task 4. We
model the classification tasks using linear SVM
and the term extraction task using CRF in order
to develop an aspect-based sentiment analysis sys-
tem that performs reasonably well.
</bodyText>
<sectionHeader confidence="0.957349" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.996047333333333">
The research is partially funded by the Economic
Development Board and the National Research
Foundation of Singapore.
</bodyText>
<sectionHeader confidence="0.999277" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996211636363637">
Stefano Baccianella, Andrea Esuli, and Fabrizio Sebas-
tiani. 2010. SentiWordNet 3.0: An enhanced lexi-
cal resource for sentiment analysis and opinion min-
ing. In Proceedings of the Seventh Conference on
International Language Resources and Evaluation
(LREC’10), volume 10, pages 2200–2204.
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the tenth
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining, pages 168–177.
Niklas Jakob and Iryna Gurevych. 2010. Extracting
opinion targets in a single-and cross-domain setting
with conditional random fields. In Proceedings of
the 2010 Conference on Empirical Methods in Nat-
ural Language Processing, pages 1035–1045.
John Lafferty, Andrew McCallum, and Fernando
Pereira. 2001. Conditional random fields: Prob-
abilistic models for segmenting and labeling se-
quence data. In Proceedings of the Eighteenth In-
ternational Conference on Machine Learning, pages
282–289.
Bing Liu. 2010. Sentiment analysis and subjectiv-
ity. In Handbook of Natural Language Processing,
pages 627–666. Chapman &amp; Hall, 2 edition.
Bing Liu. 2012. Sentiment analysis and opinion min-
ing. Synthesis Lectures on Human Language Tech-
nologies, 5(1):1–167.
Bin Lu, Myle Ott, Claire Cardie, and Benjamin Tsou.
2011. Multi-aspect sentiment analysis with topic
models. In Proceedings of Sentiment Elicitation
from Natural Text for Information Retrieval and Ex-
traction, pages 81–88.
Bo Pang and Lillian Lee. 2008. Opinion mining and
sentiment analysis. Foundations and trends in infor-
mation retrieval, 2(1-2):1–135.
Maria Pontiki, Dimitrios Galanis, John Pavlopou-
los, Haris Papageorgiou, Ion Androutsopoulos, and
Suresh Manandhar. 2014. SemEval-2014 Task 4:
Aspect based sentiment analysis. In Proceedings of
the 8th International Workshop on Semantic Evalu-
ation (SemEval 2014).
Erik Tjong Kim Sang and Fien De Meulder. 2003.
Introduction to the CoNLL-2003 shared task:
Language-independent named entity recognition. In
</reference>
<page confidence="0.990478">
520
</page>
<note confidence="0.9097815">
Proceedings of the Seventh Conference on Natural
Language Learning at HLT-NAACL, pages 142–147.
</note>
<page confidence="0.995464">
521
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.966951">
<title confidence="0.9994935">SAP-RI: A Constrained and Supervised Approach for Sentiment Analysis</title>
<author confidence="0.994135">Akriti Naveen</author>
<affiliation confidence="0.9976415">amp; Innovation, SAP Asia, Technological University,</affiliation>
<abstract confidence="0.9976381">We describe the submission of the SAP Research &amp; Innovation team to the SemEval 2014 Task 4: Aspect-Based Sentiment Analysis (ABSA). Our system follows a constrained and supervised approach for aspect term extraction, categorization and sentiment classification of online reviews and the details are included in this paper.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Stefano Baccianella</author>
<author>Andrea Esuli</author>
<author>Fabrizio Sebastiani</author>
</authors>
<title>SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining.</title>
<date>2010</date>
<booktitle>In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<volume>10</volume>
<pages>2200--2204</pages>
<contexts>
<context position="6390" citStr="Baccianella et al., 2010" startWordPosition="1007" endWordPosition="1010">ted in Table 1. Features listed in section 2.1 were those that were retained for the final run. 1code.google.com/p/crfpp/ 3 Subtask 2: Aspect Term Polarity Estimation For this subtask, the training, development and testing was done using reviews on laptops and restaurants. Given the aspect terms in a sentence, the task was to predict their sentiment polarities. 3.1 Features For each review, we used the following features: • Word N-grams: all lowercased unigrams, bigrams and trigrams from the review text • Polarity of neighbouring adjectives: extracted word sentiment from SentiWordNet lexicon (Baccianella et al., 2010) • Neighbouring POS tags: the POS tags of up to neighbouring 3 words • Parse dependencies and relations: parse dependency relations of the aspects, i.e., presence/absence of adjectives and adverbs in the dependency parse tree 3.2 Method For each aspect term of a sentence, the aforementioned features were extracted. For example, for the term Sushi in the sentence Sushi was delicious., the following feature vector is constructed, {aspect: ’sushi’, advmod:’null’, amod:’delicious’, uni sushi: 1, uni was: 1, uni delicious, uni the: 0, .. }. We then treat the aspect sentiment polarity estimation as </context>
</contexts>
<marker>Baccianella, Esuli, Sebastiani, 2010</marker>
<rawString>Stefano Baccianella, Andrea Esuli, and Fabrizio Sebastiani. 2010. SentiWordNet 3.0: An enhanced lexical resource for sentiment analysis and opinion mining. In Proceedings of the Seventh Conference on International Language Resources and Evaluation (LREC’10), volume 10, pages 2200–2204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining,</booktitle>
<pages>168--177</pages>
<contexts>
<context position="1456" citStr="Hu and Liu, 2004" startWordPosition="212" endWordPosition="215">r a wide range of products and services. Consequently, more and more consumers have taken to consulting these online reviews as part of their pre-purchase research before deciding on availing services from a local business or investing in a product from a particular brand. This calls for innovative techniques for the sentiment analysis of online reviews so as to generate accurate and relevant recommendations. Sentiment analysis has been extensively studied and applied in different domains. Predicting the sentiment polarity (positive, negative, neutral) of user opinions by mining user reviews (Hu and Liu, 2004; Liu, 2012; Pang and Lee, 2008; Liu, 2010) has been of high commercial and research interest. In these studies, sentiment analysis is often conducted at one of the three levels: document level, sentence level or attribute level. Through the SemEval 2014 Task 4 on Aspect Based Sentiment Analysis (Pontiki et al., 2014), we explore sentiment analysis at the aspect level. ∗ The work was done during an internship at SAP. This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //cre</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the tenth ACM SIGKDD International Conference on Knowledge Discovery and Data Mining, pages 168–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Niklas Jakob</author>
<author>Iryna Gurevych</author>
</authors>
<title>Extracting opinion targets in a single-and cross-domain setting with conditional random fields.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1035--1045</pages>
<contexts>
<context position="3147" citStr="Jakob and Gurevych, 2010" startWordPosition="479" endWordPosition="482">, and in subtask 4 aspect category polarity, participants were to determine the polarity of each aspect category. The polarity classification subtasks consider sentiment analysis to be a three-way classification problem between positive, negative and neutral sentiment. On the other hand, the aspect category detection subtask is a multi-label classification problem where one sentence can be labelled with more than one aspect category. In this paper, we describe the submission of the SAP-RI team to the SemEval 2014 Task 4. We make use of supervised techniques to extract the aspects of interest (Jakob and Gurevych, 2010), categorize them (Lu et al., 2011) and predict the sentiment of customer online reviews on Laptops and Restaurants. We developed a constrained system for aspect-based sentiment analysis of these online reviews. The system is constrained in the sense that we only use the training data that was provided by the challenge organizers and no other external data sources. Our system performed reasonably well, especially with a F1 score of 75.61% for the aspect category polarity subtask, 79.04% F1 score on the aspect category detection task and 66.61% F1 score on the aspect term extraction task. 2 Sub</context>
</contexts>
<marker>Jakob, Gurevych, 2010</marker>
<rawString>Niklas Jakob and Iryna Gurevych. 2010. Extracting opinion targets in a single-and cross-domain setting with conditional random fields. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, pages 1035–1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the Eighteenth International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<contexts>
<context position="5016" citStr="Lafferty et al., 2001" startWordPosition="784" endWordPosition="787"> • POS tags: POS tags of a word and its neighbours • Parse dependencies and relations: parse dependency relations of the aspects, i.e., presence/absence of adjectives and adverbs in the dependency parse tree • Punctuation Marks: presence/absence of punctuation marks, such as ?, ! 2.2 Method We approach the task by casting it as a sequence tagging task where each token in a candidate sentence is labelled as either Beginning, Inside or Outside (BIO). We then employ conditional random fields (CRF), which is a discriminative, probabilistic model for sequence data with state-of-theart performance (Lafferty et al., 2001). A linearchain CRF tries to estimate the conditional probability of a label sequence y given the observed features x, where each label yt is conditioned on the previous label yt−1. In our case, we use BIO CoNLL-style tags (Sang and De Meulder, 2003). During development, we split the training data in the ratio of 60:20:20 as training, development (dev) and testing (dev-test). We train the CRF model on the training set of the data, perform feature selection based on the dev set, and test the resulting model on the dev-test. In all experiments, we use the CRF++1 implementation of conditional ran</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the Eighteenth International Conference on Machine Learning, pages 282–289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and subjectivity.</title>
<date>2010</date>
<booktitle>In Handbook of Natural Language Processing,</booktitle>
<volume>2</volume>
<pages>627--666</pages>
<publisher>Chapman &amp; Hall,</publisher>
<contexts>
<context position="1499" citStr="Liu, 2010" startWordPosition="222" endWordPosition="223">ntly, more and more consumers have taken to consulting these online reviews as part of their pre-purchase research before deciding on availing services from a local business or investing in a product from a particular brand. This calls for innovative techniques for the sentiment analysis of online reviews so as to generate accurate and relevant recommendations. Sentiment analysis has been extensively studied and applied in different domains. Predicting the sentiment polarity (positive, negative, neutral) of user opinions by mining user reviews (Hu and Liu, 2004; Liu, 2012; Pang and Lee, 2008; Liu, 2010) has been of high commercial and research interest. In these studies, sentiment analysis is often conducted at one of the three levels: document level, sentence level or attribute level. Through the SemEval 2014 Task 4 on Aspect Based Sentiment Analysis (Pontiki et al., 2014), we explore sentiment analysis at the aspect level. ∗ The work was done during an internship at SAP. This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ The task </context>
</contexts>
<marker>Liu, 2010</marker>
<rawString>Bing Liu. 2010. Sentiment analysis and subjectivity. In Handbook of Natural Language Processing, pages 627–666. Chapman &amp; Hall, 2 edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Sentiment analysis and opinion mining.</title>
<date>2012</date>
<journal>Synthesis Lectures on Human Language Technologies,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="1467" citStr="Liu, 2012" startWordPosition="216" endWordPosition="217">products and services. Consequently, more and more consumers have taken to consulting these online reviews as part of their pre-purchase research before deciding on availing services from a local business or investing in a product from a particular brand. This calls for innovative techniques for the sentiment analysis of online reviews so as to generate accurate and relevant recommendations. Sentiment analysis has been extensively studied and applied in different domains. Predicting the sentiment polarity (positive, negative, neutral) of user opinions by mining user reviews (Hu and Liu, 2004; Liu, 2012; Pang and Lee, 2008; Liu, 2010) has been of high commercial and research interest. In these studies, sentiment analysis is often conducted at one of the three levels: document level, sentence level or attribute level. Through the SemEval 2014 Task 4 on Aspect Based Sentiment Analysis (Pontiki et al., 2014), we explore sentiment analysis at the aspect level. ∗ The work was done during an internship at SAP. This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommon</context>
</contexts>
<marker>Liu, 2012</marker>
<rawString>Bing Liu. 2012. Sentiment analysis and opinion mining. Synthesis Lectures on Human Language Technologies, 5(1):1–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bin Lu</author>
<author>Myle Ott</author>
<author>Claire Cardie</author>
<author>Benjamin Tsou</author>
</authors>
<title>Multi-aspect sentiment analysis with topic models.</title>
<date>2011</date>
<booktitle>In Proceedings of Sentiment Elicitation from Natural Text for Information Retrieval and Extraction,</booktitle>
<pages>81--88</pages>
<contexts>
<context position="3182" citStr="Lu et al., 2011" startWordPosition="485" endWordPosition="488"> participants were to determine the polarity of each aspect category. The polarity classification subtasks consider sentiment analysis to be a three-way classification problem between positive, negative and neutral sentiment. On the other hand, the aspect category detection subtask is a multi-label classification problem where one sentence can be labelled with more than one aspect category. In this paper, we describe the submission of the SAP-RI team to the SemEval 2014 Task 4. We make use of supervised techniques to extract the aspects of interest (Jakob and Gurevych, 2010), categorize them (Lu et al., 2011) and predict the sentiment of customer online reviews on Laptops and Restaurants. We developed a constrained system for aspect-based sentiment analysis of these online reviews. The system is constrained in the sense that we only use the training data that was provided by the challenge organizers and no other external data sources. Our system performed reasonably well, especially with a F1 score of 75.61% for the aspect category polarity subtask, 79.04% F1 score on the aspect category detection task and 66.61% F1 score on the aspect term extraction task. 2 Subtask 1: Aspect Term Extraction Give</context>
</contexts>
<marker>Lu, Ott, Cardie, Tsou, 2011</marker>
<rawString>Bin Lu, Myle Ott, Claire Cardie, and Benjamin Tsou. 2011. Multi-aspect sentiment analysis with topic models. In Proceedings of Sentiment Elicitation from Natural Text for Information Retrieval and Extraction, pages 81–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>Opinion mining and sentiment analysis. Foundations and trends in information retrieval,</title>
<date>2008</date>
<pages>2--1</pages>
<contexts>
<context position="1487" citStr="Pang and Lee, 2008" startWordPosition="218" endWordPosition="221">d services. Consequently, more and more consumers have taken to consulting these online reviews as part of their pre-purchase research before deciding on availing services from a local business or investing in a product from a particular brand. This calls for innovative techniques for the sentiment analysis of online reviews so as to generate accurate and relevant recommendations. Sentiment analysis has been extensively studied and applied in different domains. Predicting the sentiment polarity (positive, negative, neutral) of user opinions by mining user reviews (Hu and Liu, 2004; Liu, 2012; Pang and Lee, 2008; Liu, 2010) has been of high commercial and research interest. In these studies, sentiment analysis is often conducted at one of the three levels: document level, sentence level or attribute level. Through the SemEval 2014 Task 4 on Aspect Based Sentiment Analysis (Pontiki et al., 2014), we explore sentiment analysis at the aspect level. ∗ The work was done during an internship at SAP. This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.</context>
</contexts>
<marker>Pang, Lee, 2008</marker>
<rawString>Bo Pang and Lillian Lee. 2008. Opinion mining and sentiment analysis. Foundations and trends in information retrieval, 2(1-2):1–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Pontiki</author>
<author>Dimitrios Galanis</author>
<author>John Pavlopoulos</author>
<author>Haris Papageorgiou</author>
<author>Ion Androutsopoulos</author>
<author>Suresh Manandhar</author>
</authors>
<title>SemEval-2014 Task 4: Aspect based sentiment analysis.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="1775" citStr="Pontiki et al., 2014" startWordPosition="265" endWordPosition="268"> the sentiment analysis of online reviews so as to generate accurate and relevant recommendations. Sentiment analysis has been extensively studied and applied in different domains. Predicting the sentiment polarity (positive, negative, neutral) of user opinions by mining user reviews (Hu and Liu, 2004; Liu, 2012; Pang and Lee, 2008; Liu, 2010) has been of high commercial and research interest. In these studies, sentiment analysis is often conducted at one of the three levels: document level, sentence level or attribute level. Through the SemEval 2014 Task 4 on Aspect Based Sentiment Analysis (Pontiki et al., 2014), we explore sentiment analysis at the aspect level. ∗ The work was done during an internship at SAP. This work is licenced under a Creative Commons Attribution 4.0 International License. Page numbers and proceedings footer are added by the organizers. License details: http: //creativecommons.org/licenses/by/4.0/ The task consists of four subtasks: in subtask 1 aspect term extraction, participants need to identify the aspect terms present in a sentence and return a list containing all distinct aspect terms, in subtask 2 aspect term polarity, participants were to determine the polarity of each </context>
</contexts>
<marker>Pontiki, Galanis, Pavlopoulos, Papageorgiou, Androutsopoulos, Manandhar, 2014</marker>
<rawString>Maria Pontiki, Dimitrios Galanis, John Pavlopoulos, Haris Papageorgiou, Ion Androutsopoulos, and Suresh Manandhar. 2014. SemEval-2014 Task 4: Aspect based sentiment analysis. In Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014).</rawString>
</citation>
<citation valid="true">
<title>Erik Tjong Kim Sang and Fien De Meulder.</title>
<date>2003</date>
<marker>2003</marker>
<rawString>Erik Tjong Kim Sang and Fien De Meulder. 2003. Introduction to the CoNLL-2003 shared task: Language-independent named entity recognition. In</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>