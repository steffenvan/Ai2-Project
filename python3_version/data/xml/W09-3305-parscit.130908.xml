<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.012387">
<title confidence="0.970937">
Automatic Content-based Categorization of Wikipedia Articles
</title>
<author confidence="0.995191">
Zeno Gantner Lars Schmidt-Thieme
</author>
<affiliation confidence="0.954244">
University of Hildesheim University of Hildesheim
Machine Learning Lab Machine Learning Lab
</affiliation>
<email confidence="0.973917">
gantner@ismll.de schmidt-thieme@ismll.de
</email>
<sectionHeader confidence="0.994182" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999925052631579">
Wikipedia’s article contents and its cate-
gory hierarchy are widely used to produce
semantic resources which improve perfor-
mance on tasks like text classification and
keyword extraction. The reverse – using
text classification methods for predicting
the categories of Wikipedia articles – has
attracted less attention so far. We propose
to “return the favor” and use text classi-
fiers to improve Wikipedia. This could
support the emergence of a virtuous circle
between the wisdom of the crowds and ma-
chine learning/NLP methods.
We define the categorization of Wikipedia
articles as a multi-label classification task,
describe two solutions to the task, and per-
form experiments that show that our ap-
proach is feasible despite the high number
of labels.
</bodyText>
<sectionHeader confidence="0.998783" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.984384657894737">
Wikipedia’s article contents and its category hi-
erarchy are widely used to produce semantic re-
sources which improve performance on tasks like
text classification and keyword extraction (Baner-
jee, 2007; Gabrilovich and Markovitch, 2007;
Minier et al., 2007; Mihalcea and Csomai, 2007;
Wang and Domeniconi, 2008; Medelyan et al.,
2008). The reverse – using text classification
methods to improve Wikipedia’s article-category
mappings – has attracted less attention (Fu et al.,
2007).
A system that automatically suggests categories
for Wikipedia articles will help to improve the en-
cyclopedia for its users and authors, as well as the
semantic resources created from it.
The complexity of Wikipedia’s category sys-
tems1 and sheer number of categories make it
1We use the plural here, as each language version has its
hard for – possibly inexperienced – authors to as-
sign categories to new or existing articles. As of
February 2009, the German Wikipedia has about
886,000 articles, which belong to about 64,000
categories. For the English Wikipedia, those num-
bers are even higher.2
Classical document classification data sets like
Reuters RCV1-V2 (Lewis et al., 2004) have
around 100 different categories. In comparison,
the automatic categorization of Wikipedia articles
is a challenging task, as it involves tens to hun-
dreds of thousand categories. For such large-scale
classification problems, particular attention is nec-
essary to deal with both training and prediction
complexity, as well as imbalanced class distribu-
tions.
In this article, we present the problem of
content-based article categorization in Wikipedia,
and suggest an evaluation protocol as well as two
content-based methods for solving this problem.
</bodyText>
<sectionHeader confidence="0.968061" genericHeader="method">
2 Problem Statement
</sectionHeader>
<bodyText confidence="0.9993994375">
Let X C_ X be the set of all articles and L be
the set of all category labels in one of Wikipedia’s
language versions. Each article x E X is assigned
a set of k(x) category labels {l1,... , lk(x)I C_ L.
In this context, one can think of several pre-
diction problems: Given an article x without cat-
egory information, predict all the article’s cate-
gories. This scenario is typical for newly cre-
ated articles, thus we call it the new article prob-
lem. Another prediction task would be to predict
the missing categories for an article with existing,
but incomplete category information (missing cat-
egories problem). Such a condition can occur e.g.
if a new category is created and the creator of the
new category does not include all existing articles
that should be assigned to that category. In this pa-
</bodyText>
<footnote confidence="0.999171">
own category hierarchy. The categories may be linked across
languages using so-called interlanguage links.
2http://stats.wikimedia.org/
</footnote>
<page confidence="0.989863">
32
</page>
<note confidence="0.990362">
Proceedings of the 2009 Workshop on the People’s Web Meets NLP, ACL-IJCNLP 2009, pages 32–37,
Suntec, Singapore, 7 August 2009. c�2009 ACL and AFNLP
</note>
<table confidence="0.88401475">
fi(x)
1 -1
ˆfi(x) 1 tpi fpi
-1 fni tni
</table>
<tableCaption confidence="0.999535">
Table 1: Confusion matrix for class i.
</tableCaption>
<bodyText confidence="0.987214285714286">
per, we will concentrate on the new article prob-
lem.
Such a problem is a so-called multi-label, or
any-of classification task, as opposed to single-
label (one-of) classification (Manning et al.,
2008). Multi-label classification can be expressed
as a set of binary classification problems:
</bodyText>
<equation confidence="0.991639">
f(x) = {li|fi(x) = 1}, (1)
</equation>
<bodyText confidence="0.9992659375">
where fi : X → {−1,1},1 ≤ i ≤ |L |are indica-
tor functions for class li, i.e. fi(x) = 1 iff. article
x is annotated with the category label li.
The associated learning problem is to find a pre-
diction model fˆ that predicts categories for given
articles as good as possible, according to a given
loss function.
We choose micro- and macro-averaged F1 as
loss functions. Micro-averaged F1 is computed
from the complete confusion matrix, while macro-
averaged F1 is the average F1 computed from
class-wise confusion matrices. Micro-averaged
measures tend to measure the effectiveness of a
classifier on the large categories, while macro-
averaging gives more weight to smaller categories
(Manning et al., 2008).
</bodyText>
<equation confidence="0.990584">
Fmacro 1 |L|� 2 • tpi (2)
i=1
|L |2 - tpi + fpi + fni ,
</equation>
<bodyText confidence="0.999940333333333">
where tpi is the number of true positives, fpi the
number of false positives, and fni the number of
false negatives for class i (see Table 1).
</bodyText>
<equation confidence="0.98786025">
2 · tp
Fmicro
1 := , (3)
2 · tp + fp + fn
</equation>
<bodyText confidence="0.973040869565217">
where tp = �|L|
i=1 tpi is the overall number of
true positives, fp = �|L|
i=1 fpi the overall number
of false positives, and fn = �|L|
i=1 fni the overall
number of false negatives.
F1 is widely used in information retrieval and
supervised learning tasks. While providing a bal-
ance between precision and recall, optimizing for
F1 “forces” the prediction method and the re-
spective learning algorithm to decide which cat-
egory labels to predict and which ones not –
just predicting a ranking of labels is not suffi-
cient. This is motivated by the intended use of the
prediction method in a category suggestion sys-
tem for Wikipedia articles: Such a system can-
not present an arbitrarily high number of (possi-
bly ranked) suggestions to the user, who would be
overwhelmed by the amount of information. On
the other hand, if there is a fixed low number of
suggestions, there would be the danger of correct
category labels being left out.
</bodyText>
<sectionHeader confidence="0.998937" genericHeader="method">
3 Methods
</sectionHeader>
<bodyText confidence="0.999977551724138">
There are many multi-label classification models
in the literature, which are either adaptions of ex-
isting single-label models, or models generated
by transformation of the multi-label problem to
single-label problems, which are then solved using
again existing single-label models. Tsoumakas et
al. (2009) give an overview of multi-label classifi-
cation methods.
Wikipedia articles are hypertext pages. For
classifying hypertext pages, there are two obvious
kinds of features: (i), there are content-based fea-
tures, like words or n-grams contained in the ar-
ticles, and (ii), there are link-based features, such
as in- and outgoing article links, links to external
web pages, and the (estimated or actually known)
categories of the linked articles. Past research on
relational learning and hypertext classification (Lu
and Getoor, 2003) has shown that both kinds of
features are useful, and that the strongest meth-
ods combine both. It makes sense to investigate
content-based features as well as link-based fea-
tures, because improvements in any of the two can
lead to overall improvements. The work presented
here focuses on content-based features.
A naive approach would be to directly take
the binary representation of multi-label classifica-
tion (equation 1), and then to train binary classi-
fier models like support-vector machines (SVM,
Cortes and Vapnik (1995)):
</bodyText>
<equation confidence="0.999703">
ˆfnaive(x) := {li |ˆfi(x) = 1} (4)
</equation>
<bodyText confidence="0.99983475">
As the training of a traditional binary SVM clas-
sifier does not optimize towards the given multi-
label loss function, but for accuracy, we do not ex-
pect the best results from this method.
</bodyText>
<page confidence="0.99518">
33
</page>
<bodyText confidence="0.998886">
If we want better multi-label predictions, chang-
ing the threshold of the binary decision functions
is a straightforward solution. We employed two
well-known thresholding strategies, ranking cut
(RCut) and score cut (SCut, Yang (2001)), to pre-
dict Wikipedia categories.
RCut sorts all labels according to their binary
prediction score ˆf∗i , and selects the t top labels:
</bodyText>
<equation confidence="0.9998615">
frcut(x) := argmax1≤i≤|L |ˆf∗i (x),
t (5)
</equation>
<bodyText confidence="0.978204">
where argmaxta∈A g(a) refers to the t elements of
A with highest value g(a). The value of the hyper-
parameter threshold t can be chosen empirically
on a hold-out set.
SCut uses an individual decision threshold si
for each label:
</bodyText>
<equation confidence="0.999311">
ˆfscut(x) := {li |ˆf∗i (x) &gt; si} (6)
</equation>
<bodyText confidence="0.999910888888889">
Good threshold values si can be determined dur-
ing training. Algorithm 1 shows a category-wise
optimization of the threshold values as described
by Yang (2001). Because it tunes the threshold si
for each category based on the F1 measure over
that category, it optimizes for macro-averaged F1.
If we are able to find optimal thresholds for each
category, then we will achieve optimal macro-F1
performance, as the following lemma says.
</bodyText>
<equation confidence="0.899247">
Lemma 1 Let
si := argmaxs∈S F1(X, Yi, ˆfi), (7)
Then
ˆf),
(9)
ˆf(x) := {li |ˆf∗i (x) &gt; s0i}) (10)
i.e., the component-wise binary F1 optimization
yields the Fma
1-optimal multi-label threshold.
cro
</equation>
<bodyText confidence="0.950241333333333">
Proof: The components of the sum in the defi-
nition of macro-averaged F1 (Equation 2) are ex-
actly the class-wise F1 values. The choice of si
influences only thepart of the sum 2·tpi
2·tpi+fpi+fni be-
longing to i. Thus each si can be optimized inde-
pendently.
Representing each category label as binary pre-
diction problem, as in the work presented here,
requires |L |binary classifiers. There also exist
methods that use |L|2 binary classifiers (Mencia
and F¨urnkranz, 2008), which is not feasible if L is
large.
Algorithm 1 Macro-averaged F1 optimization for
SCut
Input: binary classifiers ( ˆf∗i ), ˆf∗i : X —* S; train-
ing instances X C_ X and labels Y E P(L)|X|
Output: thresholds (si)
</bodyText>
<listItem confidence="0.976006714285714">
1: for i = 1 to |L |do
2: Yi +— binary labels for category i generated
from Y
3: si +— argmaxs∈S F1-measure for ˆf∗i with
threshold s on X, Yi
4: end for
5: return (si)
</listItem>
<sectionHeader confidence="0.998211" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999762">
To demonstrate the general feasibility of the au-
tomatic categorization of Wikipedia articles, we
conducted experiments on a subset of the German
Wikipedia. In this section, we describe the ex-
tracted data sets, the evaluation protocol, and dis-
cuss the results.
</bodyText>
<subsectionHeader confidence="0.992826">
4.1 Category Data
</subsectionHeader>
<bodyText confidence="0.999963652173913">
To generate the data set for the experiment, we
used the official database dumps of the German
Wikipedia, generated December 6, 2008.3 We
then extracted all articles belonging to the cate-
gory Eishockey (“ice-hockey”) or to one of its de-
scendants, and removed all category labels from
outside the chosen category sub-graph, and all cat-
egory labels of categories containing less than 5
articles. We proceeded identically for the category
Philosoph (“philosopher”).
Feature generation was performed as follows:
First, we removed all wiki markup from the article
source code. Second, we used Mallet (McCallum,
2002) to generate bag-of-words representations of
the articles. All tokens were converted to lower
case, and tokens occurring in only one article were
removed. We conducted no stopword removal, nor
stemming. Finally, we normalized the feature vec-
tors to sum up to one.
Table 2 shows some properties of the data. |X|
is the number of instances, |L |the number of dis-
tinct category labels; the fourth column contains
the number of features (words) in the data set.4
</bodyText>
<footnote confidence="0.957374333333333">
3http://download.wikimedia.org
4The data can be downloaded from http://www.
domain/path.
</footnote>
<equation confidence="0.987238166666667">
� 1, if ˆf∗ i (x) &gt;
ˆfi(x) :=
s (8)
−1, otherwise
(s1, ..., s|L|) = argmax(s, 1 (X, Y,
1,...,s, |L|) Fmacro
</equation>
<page confidence="0.996384">
34
</page>
<table confidence="0.995200666666667">
top category |X ||L |# features
Philosoph 2,445 55 68,541
Eishockey 5,037 159 36,473
</table>
<tableCaption confidence="0.997501">
Table 2: Data set properties.
</tableCaption>
<bodyText confidence="0.9996754">
like SCut and RCut, are suitable for the categoriza-
tion of Wikipedia articles: The methods achieve a
good prediction quality, while the number of un-
derlying binary classifiers scales linearly (see Sec-
tion 3).
</bodyText>
<subsectionHeader confidence="0.9455915">
4.2 Evaluation Protocol
Train-Test Split
</subsectionHeader>
<bodyText confidence="0.990560714285714">
For the experiment, we randomly separated the
data sets into 80% of the articles for training, and
20% for testing. To evaluate the new article prob-
lem, we removed all category labels from the arti-
cles in the test sets.
Training
As an experimental baseline, we used a static clas-
sifier (most-frequent) that always predicts the most
frequent categories, regardless of the article.
We implemented the RCut and SCut strate-
gies using linear support-vector machines from the
LIBSVM library (Chang and Lin, 2001) for the
underlying binary classification task. For each
category, we used 5-fold cross-validation to find
a good value for the hyperparameter C (Hsu et
al., 2003). As SVMs perform only binary deci-
sions, but do not yield scores suitable for ranking
the labels, we used LIBSVM’s modified version
of Platt’s method (Platt, 2000) to obtain probabil-
ities, which are used as scores for the RCut rank-
ings and the SCut decisions. As SCut’s threshold
search goes over an infinite set S = [0, 1] (Al-
gorithm 1, line 3), we did an approximate search
over this interval with step size 0.01. For RCut and
most-frequent, we report results for all thresholds
1, . . . ,|L|. In an application setting, we would
have to determine a suitable t using a hold-out data
set.
</bodyText>
<subsectionHeader confidence="0.957403">
4.3 Results and Discussion
</subsectionHeader>
<bodyText confidence="0.99994175">
The results can be seen in Table 3 and Figure
1 and 2. Both methods clearly perform better
than the baseline. For macro-averaged Fi on
Eishockey, SCut performs better than RCut, which
is not surprising, as this method is optimized to-
wards macro-averaged Fl. For Philosoph, RCut
with a rank threshold of t = 3 has a little bit (by
0.005) higher macro-averaged Fi result, but this is
likely not a significant difference.
The experiments show that simple models like
the transformation from multi-label to binary
problems, combined with thresholding strategies
</bodyText>
<sectionHeader confidence="0.959331" genericHeader="conclusions">
5 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999973860465116">
In this article, we view the categorization of
Wikipedia articles as a multi-label classification
problem and report experiments on a subset of the
German Wikipedia. The experiments show that
there are suitable models for the categorization of
Wikipedia articles.
We propose to use machine learning algorithms
in order to improve the category assignments of
Wikipedia articles. While data from Wikipedia
is already widely used to improve text classifica-
tion systems, it may be desirable to “return the fa-
vor” and use text classifiers to improve Wikipedia.
This could support the emergence of a virtuous cir-
cle between the wisdom of the crowds and ma-
chine “intelligence”, i.e. machine learning and
NLP methods.
Wikipedia category data could be used as well
for generating publicly available, large-scale (hier-
archical) multi-label classification benchmark col-
lections with different characteristics. Further-
more, it could provide the basis for multilingual
document classification data sets.
To be able to provide category suggestions for
large Wikipedias like the German, the Spanish or
the English one, we will extend our experiments to
larger subsets, and finally to all of the German and
English Wikipedia. In order to achieve this, we
will also investigate hierarchical multi-label clas-
sification methods (Liu et al., 2005; Cai and Hof-
mann, 2004; Cesa-Bianchi et al., 2006) and faster
training algorithms for linear SVMs and logistic
regression (Fan et al., 2008; Shalev-Shwartz et al.,
2007). Given that we use |L |binary classifiers for
our models, this should be feasible, even for large
numbers of categories. It would also be interest-
ing to compare our methods to the work by Fu et
al. (2007), which concentrates on link-based cate-
gorization of Wikipedia articles.
Other promising research directions are the ex-
amination of Wikipedia-specific features, and the
survey of large-scale multi-label classification al-
gorithms that take into account dependencies be-
tween labels.
</bodyText>
<page confidence="0.997304">
35
</page>
<table confidence="0.999812714285714">
micro- averaged F1 macro -averaged F1
P R P R
method Philosoph
most-frequent (t = 1) 0.489 0.315 0.383 0.009 0.019 0.012
most-frequent (t = 55) 0.028 1.0 0.055 0.028 1.0 0.049
RCut (t = 2) 0.522 0.674 0.589 0.252 0.283 0.244
RCut (t = 3) 0.395 0.764 0.520 0.240 0.379 0.266
SCut 0.341 0.735 0.466 0.225 0.350 0.261
method Eishockey
most-frequent (t = 2) 0.214 0.162 0.185 0.001 0.007 0.003
most-frequent (t = 159) 0.008 1.0 0.016 0.008 1.0 0.017
RCut (t = 1) 0.829 0.628 0.715 0.499 0.472 0.494
RCut (t = 2) 0.526 0.796 0.633 0.406 0.599 0.497
SCut 0.646 0.806 0.717 0.461 0.630 0.554
</table>
<tableCaption confidence="0.998882">
Table 3: Results for data sets Philosoph and Eishockey.
</tableCaption>
<figure confidence="0.999747416666667">
0 50 100 150
t
micro−averaged F1
0.0 0.2 0.4 0.6 0.8
Methods
● ● RCut
● SCut
● most frequent
●
●
●
●
●
●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●●
0 50 100 150
t
macro−averaged F1
0.0 0.2 0.4 0.6 0.8
●
●
Methods
● RCut
SCut
most frequent
</figure>
<figureCaption confidence="0.999313">
Figure 1: Method comparison for F1 on data set Eishockey. SCut does not depend on t.
</figureCaption>
<figure confidence="0.999530318181818">
micro−averaged F1
0.0 0.2 0.4 0.6 0.8
●●●
●
●
●
●
Methods
● RCut
SCut
most frequent
macro−averaged F1
0.0 0.2 0.4 0.6 0.8
0 10 20 30 40 50
t
0 10 20 30 40 50
t
●
Methods
● RCut
SCut
most frequent
</figure>
<figureCaption confidence="0.999074">
Figure 2: Method comparison for F1 on data set Philosoph. SCut does not depend on t.
</figureCaption>
<page confidence="0.996233">
36
</page>
<sectionHeader confidence="0.998173" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999546">
The authors gratefully acknowledge the par-
tial co-funding of their work through the
European Commission FP7 project MyMedia
(www.mymediaproject.org) under the grant agree-
ment no. 215006.
</bodyText>
<sectionHeader confidence="0.996588" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999010901098901">
Somnath Banerjee. 2007. Boosting inductive transfer
for text classification using Wikipedia. In ICMLA
’07: Proceedings of the Sixth International Confer-
ence on Machine Learning and Applications, Wash-
ington, DC, USA. IEEE Computer Society.
Lijuan Cai and Thomas Hofmann. 2004. Hierarchi-
cal document categorization with support vector ma-
chines. In Proceedings of the 13th ACM Interna-
tional Conference on Information and Knowledge
Management (CIKM ’04), November 8-13, 2004,
Washington, D.C., USA. ACM Press, New York, NY,
USA.
Nicol Cesa-Bianchi, Claudio Gentile, and Luca Zani-
boni. 2006. Incremental algorithms for hierarchi-
cal classification. Journal of Machine Learning Re-
search.
Chih-Chung Chang and Chih-Jen Lin, 2001. LIB-
SVM: a library for support vector machines.
Software available at http://www.csie.ntu.
edu.tw/˜cjlin/libsvm.
Corinna Cortes and Vladimir Vapnik. 1995. Support–
vector networks. Machine Learning, 20.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. Liblinear: A
library for large linear classification. Journal of Ma-
chine Learning Research, 9.
Linyun Fu, Haofen Wang, Haiping Zhu, Huajie Zhang,
Yang Wang, and Yong Yu. 2007. Making
more Wikipedians: Facilitating semantics reuse for
wikipedia authoring. In ISWC/ASWC 2007.
Evgeniy Gabrilovich and Shaul Markovitch. 2007.
Harnessing the expertise of 70,000 human editors:
Knowledge-based feature generation for text catego-
rization. Journal of Machine Learning Research.
Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin.
2003. A practical guide to support vector classifi-
cation. Technical report, Department of Computer
Science, National Taiwan University.
David D. Lewis, Yiming Yang, Tony G. Rose, G. Di-
etterich, Fan Li, and Fan Li. 2004. RCV1: A
new benchmark collection for text categorization re-
search. Journal of Machine Learning Research.
Tie-Yan Liu, Yiming Yang, Hao Wan, Hua-Jun Zeng,
Zheng Chen, and Wei-Ying Ma. 2005. Support vec-
tor machines classification with a very large-scale
taxonomy. SIGKDD Explorations, (1).
Qing Lu and Lise Getoor. 2003. Link-based classifi-
cation using labeled and unlabeled data. In ICML
Workshop on ”The Continuum from Labeled to Un-
labeled Data in Machine Learning and Data Min-
ing”.
Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Sch¨utze. 2008. Introduction to Information
Retrieval. Cambridge University Press, New York.
Andrew Kachites McCallum. 2002. Mal-
let: A machine learning for language toolkit.
http://mallet.cs.umass.edu.
Olena Medelyan, Ian H. Witten, and David Milne.
2008. Topic indexing with Wikipedia. In Proceed-
ings of the Wikipedia and AI workshop at AAAI-08.
AAAI.
Eneldo Loza Mencia and Johannes F¨urnkranz. 2008.
Efficient pairwise multilabel classification for large-
scale problems in the legal domain. In Walter Daele-
mans, Bart Goethals, and Katharina Morik, editors,
ECML/PKDD (2), volume 5212 of Lecture Notes in
Computer Science, pages 50–65. Springer.
Rada Mihalcea and Andras Csomai. 2007. Wikify!:
linking documents to encyclopedic knowledge. In
CIKM ’07, New York, NY, USA. ACM.
Zsolt Minier, Zalan Bodo, and Lehel Csato. 2007.
Wikipedia-based kernels for text categorization. In
SYNASC ’07, Washington, DC, USA. IEEE Com-
puter Society.
J. Platt. 2000. Probabilistic outputs for support vector
machines and comparison to regularized likelihood
methods. In Advances in Large Margin Classifiers.
S. Shalev-Shwartz, Y. Singer, and N. Srebro. 2007.
Pegasos: Primal estimated sub–gradient solver for
SVM. In Proceedings of the International Confer-
ence on Machine Learning.
G. Tsoumakas, I. Katakis, and I. Vlahavas. 2009. Min-
ing multi-label data. unpublished book chapter.
Pu Wang and Carlotta Domeniconi. 2008. Build-
ing semantic kernels for text classification using
Wikipedia. In KDD ’08, New York, NY, USA.
ACM.
Yiming Yang. 2001. A study on thresholding strategies
for text categorization. In W. Bruce Croft, David J.
Harper, Donald H. Kraft, and Justin Zobel, editors,
SIGIR 2001, pages 137–145. ACM.
</reference>
<page confidence="0.999611">
37
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.219756">
<title confidence="0.999917">Automatic Content-based Categorization of Wikipedia Articles</title>
<author confidence="0.999842">Zeno Gantner Lars Schmidt-Thieme</author>
<affiliation confidence="0.7944775">University of Hildesheim University of Hildesheim Machine Learning Lab Machine Learning Lab</affiliation>
<abstract confidence="0.974766952380952">gantner@ismll.de schmidt-thieme@ismll.de Abstract Wikipedia’s article contents and its category hierarchy are widely used to produce semantic resources which improve performance on tasks like text classification and keyword extraction. The reverse – using text classification methods for predicting the categories of Wikipedia articles – has attracted less attention so far. We propose to “return the favor” and use text classifiers to improve Wikipedia. This could support the emergence of a virtuous circle the of the crowds machine learning/NLP methods. We define the categorization of Wikipedia articles as a multi-label classification task, describe two solutions to the task, and perform experiments that show that our approach is feasible despite the high number of labels.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Somnath Banerjee</author>
</authors>
<title>Boosting inductive transfer for text classification using Wikipedia. In</title>
<date>2007</date>
<booktitle>ICMLA ’07: Proceedings of the Sixth International Conference on Machine Learning and Applications,</booktitle>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="1201" citStr="Banerjee, 2007" startWordPosition="172" endWordPosition="174">favor” and use text classifiers to improve Wikipedia. This could support the emergence of a virtuous circle between the wisdom of the crowds and machine learning/NLP methods. We define the categorization of Wikipedia articles as a multi-label classification task, describe two solutions to the task, and perform experiments that show that our approach is feasible despite the high number of labels. 1 Introduction Wikipedia’s article contents and its category hierarchy are widely used to produce semantic resources which improve performance on tasks like text classification and keyword extraction (Banerjee, 2007; Gabrilovich and Markovitch, 2007; Minier et al., 2007; Mihalcea and Csomai, 2007; Wang and Domeniconi, 2008; Medelyan et al., 2008). The reverse – using text classification methods to improve Wikipedia’s article-category mappings – has attracted less attention (Fu et al., 2007). A system that automatically suggests categories for Wikipedia articles will help to improve the encyclopedia for its users and authors, as well as the semantic resources created from it. The complexity of Wikipedia’s category systems1 and sheer number of categories make it 1We use the plural here, as each language ve</context>
</contexts>
<marker>Banerjee, 2007</marker>
<rawString>Somnath Banerjee. 2007. Boosting inductive transfer for text classification using Wikipedia. In ICMLA ’07: Proceedings of the Sixth International Conference on Machine Learning and Applications, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lijuan Cai</author>
<author>Thomas Hofmann</author>
</authors>
<title>Hierarchical document categorization with support vector machines.</title>
<date>2004</date>
<booktitle>In Proceedings of the 13th ACM International Conference on Information and Knowledge Management (CIKM ’04),</booktitle>
<publisher>ACM Press,</publisher>
<location>Washington, D.C., USA.</location>
<contexts>
<context position="15004" citStr="Cai and Hofmann, 2004" startWordPosition="2451" endWordPosition="2455"> data could be used as well for generating publicly available, large-scale (hierarchical) multi-label classification benchmark collections with different characteristics. Furthermore, it could provide the basis for multilingual document classification data sets. To be able to provide category suggestions for large Wikipedias like the German, the Spanish or the English one, we will extend our experiments to larger subsets, and finally to all of the German and English Wikipedia. In order to achieve this, we will also investigate hierarchical multi-label classification methods (Liu et al., 2005; Cai and Hofmann, 2004; Cesa-Bianchi et al., 2006) and faster training algorithms for linear SVMs and logistic regression (Fan et al., 2008; Shalev-Shwartz et al., 2007). Given that we use |L |binary classifiers for our models, this should be feasible, even for large numbers of categories. It would also be interesting to compare our methods to the work by Fu et al. (2007), which concentrates on link-based categorization of Wikipedia articles. Other promising research directions are the examination of Wikipedia-specific features, and the survey of large-scale multi-label classification algorithms that take into acco</context>
</contexts>
<marker>Cai, Hofmann, 2004</marker>
<rawString>Lijuan Cai and Thomas Hofmann. 2004. Hierarchical document categorization with support vector machines. In Proceedings of the 13th ACM International Conference on Information and Knowledge Management (CIKM ’04), November 8-13, 2004, Washington, D.C., USA. ACM Press, New York, NY, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicol Cesa-Bianchi</author>
<author>Claudio Gentile</author>
<author>Luca Zaniboni</author>
</authors>
<title>Incremental algorithms for hierarchical classification.</title>
<date>2006</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="15032" citStr="Cesa-Bianchi et al., 2006" startWordPosition="2456" endWordPosition="2459">well for generating publicly available, large-scale (hierarchical) multi-label classification benchmark collections with different characteristics. Furthermore, it could provide the basis for multilingual document classification data sets. To be able to provide category suggestions for large Wikipedias like the German, the Spanish or the English one, we will extend our experiments to larger subsets, and finally to all of the German and English Wikipedia. In order to achieve this, we will also investigate hierarchical multi-label classification methods (Liu et al., 2005; Cai and Hofmann, 2004; Cesa-Bianchi et al., 2006) and faster training algorithms for linear SVMs and logistic regression (Fan et al., 2008; Shalev-Shwartz et al., 2007). Given that we use |L |binary classifiers for our models, this should be feasible, even for large numbers of categories. It would also be interesting to compare our methods to the work by Fu et al. (2007), which concentrates on link-based categorization of Wikipedia articles. Other promising research directions are the examination of Wikipedia-specific features, and the survey of large-scale multi-label classification algorithms that take into account dependencies between lab</context>
</contexts>
<marker>Cesa-Bianchi, Gentile, Zaniboni, 2006</marker>
<rawString>Nicol Cesa-Bianchi, Claudio Gentile, and Luca Zaniboni. 2006. Incremental algorithms for hierarchical classification. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu.</title>
<date>2001</date>
<note>edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="12288" citStr="Chang and Lin, 2001" startWordPosition="2011" endWordPosition="2014">number of underlying binary classifiers scales linearly (see Section 3). 4.2 Evaluation Protocol Train-Test Split For the experiment, we randomly separated the data sets into 80% of the articles for training, and 20% for testing. To evaluate the new article problem, we removed all category labels from the articles in the test sets. Training As an experimental baseline, we used a static classifier (most-frequent) that always predicts the most frequent categories, regardless of the article. We implemented the RCut and SCut strategies using linear support-vector machines from the LIBSVM library (Chang and Lin, 2001) for the underlying binary classification task. For each category, we used 5-fold cross-validation to find a good value for the hyperparameter C (Hsu et al., 2003). As SVMs perform only binary decisions, but do not yield scores suitable for ranking the labels, we used LIBSVM’s modified version of Platt’s method (Platt, 2000) to obtain probabilities, which are used as scores for the RCut rankings and the SCut decisions. As SCut’s threshold search goes over an infinite set S = [0, 1] (Algorithm 1, line 3), we did an approximate search over this interval with step size 0.01. For RCut and most-fre</context>
</contexts>
<marker>Chang, Lin, 2001</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin, 2001. LIBSVM: a library for support vector machines. Software available at http://www.csie.ntu. edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Corinna Cortes</author>
<author>Vladimir Vapnik</author>
</authors>
<title>Support– vector networks.</title>
<date>1995</date>
<booktitle>Machine Learning,</booktitle>
<volume>20</volume>
<contexts>
<context position="7464" citStr="Cortes and Vapnik (1995)" startWordPosition="1204" endWordPosition="1207">rticles. Past research on relational learning and hypertext classification (Lu and Getoor, 2003) has shown that both kinds of features are useful, and that the strongest methods combine both. It makes sense to investigate content-based features as well as link-based features, because improvements in any of the two can lead to overall improvements. The work presented here focuses on content-based features. A naive approach would be to directly take the binary representation of multi-label classification (equation 1), and then to train binary classifier models like support-vector machines (SVM, Cortes and Vapnik (1995)): ˆfnaive(x) := {li |ˆfi(x) = 1} (4) As the training of a traditional binary SVM classifier does not optimize towards the given multilabel loss function, but for accuracy, we do not expect the best results from this method. 33 If we want better multi-label predictions, changing the threshold of the binary decision functions is a straightforward solution. We employed two well-known thresholding strategies, ranking cut (RCut) and score cut (SCut, Yang (2001)), to predict Wikipedia categories. RCut sorts all labels according to their binary prediction score ˆf∗i , and selects the t top labels: f</context>
</contexts>
<marker>Cortes, Vapnik, 1995</marker>
<rawString>Corinna Cortes and Vladimir Vapnik. 1995. Support– vector networks. Machine Learning, 20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>Liblinear: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<volume>9</volume>
<contexts>
<context position="15121" citStr="Fan et al., 2008" startWordPosition="2470" endWordPosition="2473">mark collections with different characteristics. Furthermore, it could provide the basis for multilingual document classification data sets. To be able to provide category suggestions for large Wikipedias like the German, the Spanish or the English one, we will extend our experiments to larger subsets, and finally to all of the German and English Wikipedia. In order to achieve this, we will also investigate hierarchical multi-label classification methods (Liu et al., 2005; Cai and Hofmann, 2004; Cesa-Bianchi et al., 2006) and faster training algorithms for linear SVMs and logistic regression (Fan et al., 2008; Shalev-Shwartz et al., 2007). Given that we use |L |binary classifiers for our models, this should be feasible, even for large numbers of categories. It would also be interesting to compare our methods to the work by Fu et al. (2007), which concentrates on link-based categorization of Wikipedia articles. Other promising research directions are the examination of Wikipedia-specific features, and the survey of large-scale multi-label classification algorithms that take into account dependencies between labels. 35 micro- averaged F1 macro -averaged F1 P R P R method Philosoph most-frequent (t =</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. Liblinear: A library for large linear classification. Journal of Machine Learning Research, 9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Linyun Fu</author>
<author>Haofen Wang</author>
<author>Haiping Zhu</author>
<author>Huajie Zhang</author>
<author>Yang Wang</author>
<author>Yong Yu</author>
</authors>
<title>Making more Wikipedians: Facilitating semantics reuse for wikipedia authoring.</title>
<date>2007</date>
<booktitle>In ISWC/ASWC</booktitle>
<contexts>
<context position="1481" citStr="Fu et al., 2007" startWordPosition="212" endWordPosition="215">olutions to the task, and perform experiments that show that our approach is feasible despite the high number of labels. 1 Introduction Wikipedia’s article contents and its category hierarchy are widely used to produce semantic resources which improve performance on tasks like text classification and keyword extraction (Banerjee, 2007; Gabrilovich and Markovitch, 2007; Minier et al., 2007; Mihalcea and Csomai, 2007; Wang and Domeniconi, 2008; Medelyan et al., 2008). The reverse – using text classification methods to improve Wikipedia’s article-category mappings – has attracted less attention (Fu et al., 2007). A system that automatically suggests categories for Wikipedia articles will help to improve the encyclopedia for its users and authors, as well as the semantic resources created from it. The complexity of Wikipedia’s category systems1 and sheer number of categories make it 1We use the plural here, as each language version has its hard for – possibly inexperienced – authors to assign categories to new or existing articles. As of February 2009, the German Wikipedia has about 886,000 articles, which belong to about 64,000 categories. For the English Wikipedia, those numbers are even higher.2 Cl</context>
<context position="15356" citStr="Fu et al. (2007)" startWordPosition="2512" endWordPosition="2515">r the English one, we will extend our experiments to larger subsets, and finally to all of the German and English Wikipedia. In order to achieve this, we will also investigate hierarchical multi-label classification methods (Liu et al., 2005; Cai and Hofmann, 2004; Cesa-Bianchi et al., 2006) and faster training algorithms for linear SVMs and logistic regression (Fan et al., 2008; Shalev-Shwartz et al., 2007). Given that we use |L |binary classifiers for our models, this should be feasible, even for large numbers of categories. It would also be interesting to compare our methods to the work by Fu et al. (2007), which concentrates on link-based categorization of Wikipedia articles. Other promising research directions are the examination of Wikipedia-specific features, and the survey of large-scale multi-label classification algorithms that take into account dependencies between labels. 35 micro- averaged F1 macro -averaged F1 P R P R method Philosoph most-frequent (t = 1) 0.489 0.315 0.383 0.009 0.019 0.012 most-frequent (t = 55) 0.028 1.0 0.055 0.028 1.0 0.049 RCut (t = 2) 0.522 0.674 0.589 0.252 0.283 0.244 RCut (t = 3) 0.395 0.764 0.520 0.240 0.379 0.266 SCut 0.341 0.735 0.466 0.225 0.350 0.261 m</context>
</contexts>
<marker>Fu, Wang, Zhu, Zhang, Wang, Yu, 2007</marker>
<rawString>Linyun Fu, Haofen Wang, Haiping Zhu, Huajie Zhang, Yang Wang, and Yong Yu. 2007. Making more Wikipedians: Facilitating semantics reuse for wikipedia authoring. In ISWC/ASWC 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evgeniy Gabrilovich</author>
<author>Shaul Markovitch</author>
</authors>
<title>Harnessing the expertise of 70,000 human editors: Knowledge-based feature generation for text categorization.</title>
<date>2007</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="1235" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="175" endWordPosition="178">ext classifiers to improve Wikipedia. This could support the emergence of a virtuous circle between the wisdom of the crowds and machine learning/NLP methods. We define the categorization of Wikipedia articles as a multi-label classification task, describe two solutions to the task, and perform experiments that show that our approach is feasible despite the high number of labels. 1 Introduction Wikipedia’s article contents and its category hierarchy are widely used to produce semantic resources which improve performance on tasks like text classification and keyword extraction (Banerjee, 2007; Gabrilovich and Markovitch, 2007; Minier et al., 2007; Mihalcea and Csomai, 2007; Wang and Domeniconi, 2008; Medelyan et al., 2008). The reverse – using text classification methods to improve Wikipedia’s article-category mappings – has attracted less attention (Fu et al., 2007). A system that automatically suggests categories for Wikipedia articles will help to improve the encyclopedia for its users and authors, as well as the semantic resources created from it. The complexity of Wikipedia’s category systems1 and sheer number of categories make it 1We use the plural here, as each language version has its hard for – possibly </context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Evgeniy Gabrilovich and Shaul Markovitch. 2007. Harnessing the expertise of 70,000 human editors: Knowledge-based feature generation for text categorization. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Wei Hsu</author>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>A practical guide to support vector classification.</title>
<date>2003</date>
<tech>Technical report,</tech>
<institution>Department of Computer Science, National Taiwan University.</institution>
<contexts>
<context position="12451" citStr="Hsu et al., 2003" startWordPosition="2037" endWordPosition="2040">ets into 80% of the articles for training, and 20% for testing. To evaluate the new article problem, we removed all category labels from the articles in the test sets. Training As an experimental baseline, we used a static classifier (most-frequent) that always predicts the most frequent categories, regardless of the article. We implemented the RCut and SCut strategies using linear support-vector machines from the LIBSVM library (Chang and Lin, 2001) for the underlying binary classification task. For each category, we used 5-fold cross-validation to find a good value for the hyperparameter C (Hsu et al., 2003). As SVMs perform only binary decisions, but do not yield scores suitable for ranking the labels, we used LIBSVM’s modified version of Platt’s method (Platt, 2000) to obtain probabilities, which are used as scores for the RCut rankings and the SCut decisions. As SCut’s threshold search goes over an infinite set S = [0, 1] (Algorithm 1, line 3), we did an approximate search over this interval with step size 0.01. For RCut and most-frequent, we report results for all thresholds 1, . . . ,|L|. In an application setting, we would have to determine a suitable t using a hold-out data set. 4.3 Result</context>
</contexts>
<marker>Hsu, Chang, Lin, 2003</marker>
<rawString>Chih-Wei Hsu, Chih-Chung Chang, and Chih-Jen Lin. 2003. A practical guide to support vector classification. Technical report, Department of Computer Science, National Taiwan University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
<author>Yiming Yang</author>
<author>Tony G Rose</author>
<author>G Dietterich</author>
<author>Fan Li</author>
<author>Fan Li</author>
</authors>
<title>RCV1: A new benchmark collection for text categorization research.</title>
<date>2004</date>
<journal>Journal of Machine Learning Research.</journal>
<contexts>
<context position="2164" citStr="Lewis et al., 2004" startWordPosition="322" endWordPosition="325">articles will help to improve the encyclopedia for its users and authors, as well as the semantic resources created from it. The complexity of Wikipedia’s category systems1 and sheer number of categories make it 1We use the plural here, as each language version has its hard for – possibly inexperienced – authors to assign categories to new or existing articles. As of February 2009, the German Wikipedia has about 886,000 articles, which belong to about 64,000 categories. For the English Wikipedia, those numbers are even higher.2 Classical document classification data sets like Reuters RCV1-V2 (Lewis et al., 2004) have around 100 different categories. In comparison, the automatic categorization of Wikipedia articles is a challenging task, as it involves tens to hundreds of thousand categories. For such large-scale classification problems, particular attention is necessary to deal with both training and prediction complexity, as well as imbalanced class distributions. In this article, we present the problem of content-based article categorization in Wikipedia, and suggest an evaluation protocol as well as two content-based methods for solving this problem. 2 Problem Statement Let X C_ X be the set of al</context>
</contexts>
<marker>Lewis, Yang, Rose, Dietterich, Li, Li, 2004</marker>
<rawString>David D. Lewis, Yiming Yang, Tony G. Rose, G. Dietterich, Fan Li, and Fan Li. 2004. RCV1: A new benchmark collection for text categorization research. Journal of Machine Learning Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tie-Yan Liu</author>
<author>Yiming Yang</author>
<author>Hao Wan</author>
<author>Hua-Jun Zeng</author>
<author>Zheng Chen</author>
<author>Wei-Ying Ma</author>
</authors>
<title>Support vector machines classification with a very large-scale taxonomy.</title>
<date>2005</date>
<journal>SIGKDD Explorations,</journal>
<volume>1</volume>
<contexts>
<context position="14981" citStr="Liu et al., 2005" startWordPosition="2447" endWordPosition="2450">Wikipedia category data could be used as well for generating publicly available, large-scale (hierarchical) multi-label classification benchmark collections with different characteristics. Furthermore, it could provide the basis for multilingual document classification data sets. To be able to provide category suggestions for large Wikipedias like the German, the Spanish or the English one, we will extend our experiments to larger subsets, and finally to all of the German and English Wikipedia. In order to achieve this, we will also investigate hierarchical multi-label classification methods (Liu et al., 2005; Cai and Hofmann, 2004; Cesa-Bianchi et al., 2006) and faster training algorithms for linear SVMs and logistic regression (Fan et al., 2008; Shalev-Shwartz et al., 2007). Given that we use |L |binary classifiers for our models, this should be feasible, even for large numbers of categories. It would also be interesting to compare our methods to the work by Fu et al. (2007), which concentrates on link-based categorization of Wikipedia articles. Other promising research directions are the examination of Wikipedia-specific features, and the survey of large-scale multi-label classification algorit</context>
</contexts>
<marker>Liu, Yang, Wan, Zeng, Chen, Ma, 2005</marker>
<rawString>Tie-Yan Liu, Yiming Yang, Hao Wan, Hua-Jun Zeng, Zheng Chen, and Wei-Ying Ma. 2005. Support vector machines classification with a very large-scale taxonomy. SIGKDD Explorations, (1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qing Lu</author>
<author>Lise Getoor</author>
</authors>
<title>Link-based classification using labeled and unlabeled data.</title>
<date>2003</date>
<booktitle>In ICML Workshop on ”The Continuum from Labeled to Unlabeled Data in Machine Learning and Data Mining”.</booktitle>
<contexts>
<context position="6936" citStr="Lu and Getoor, 2003" startWordPosition="1121" endWordPosition="1124">ms, which are then solved using again existing single-label models. Tsoumakas et al. (2009) give an overview of multi-label classification methods. Wikipedia articles are hypertext pages. For classifying hypertext pages, there are two obvious kinds of features: (i), there are content-based features, like words or n-grams contained in the articles, and (ii), there are link-based features, such as in- and outgoing article links, links to external web pages, and the (estimated or actually known) categories of the linked articles. Past research on relational learning and hypertext classification (Lu and Getoor, 2003) has shown that both kinds of features are useful, and that the strongest methods combine both. It makes sense to investigate content-based features as well as link-based features, because improvements in any of the two can lead to overall improvements. The work presented here focuses on content-based features. A naive approach would be to directly take the binary representation of multi-label classification (equation 1), and then to train binary classifier models like support-vector machines (SVM, Cortes and Vapnik (1995)): ˆfnaive(x) := {li |ˆfi(x) = 1} (4) As the training of a traditional b</context>
</contexts>
<marker>Lu, Getoor, 2003</marker>
<rawString>Qing Lu and Lise Getoor. 2003. Link-based classification using labeled and unlabeled data. In ICML Workshop on ”The Continuum from Labeled to Unlabeled Data in Machine Learning and Data Mining”.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press,</publisher>
<location>New York.</location>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to Information Retrieval. Cambridge University Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Kachites McCallum</author>
</authors>
<title>Mallet: A machine learning for language toolkit.</title>
<date>2002</date>
<note>http://mallet.cs.umass.edu.</note>
<contexts>
<context position="10758" citStr="McCallum, 2002" startWordPosition="1761" endWordPosition="1762">ata To generate the data set for the experiment, we used the official database dumps of the German Wikipedia, generated December 6, 2008.3 We then extracted all articles belonging to the category Eishockey (“ice-hockey”) or to one of its descendants, and removed all category labels from outside the chosen category sub-graph, and all category labels of categories containing less than 5 articles. We proceeded identically for the category Philosoph (“philosopher”). Feature generation was performed as follows: First, we removed all wiki markup from the article source code. Second, we used Mallet (McCallum, 2002) to generate bag-of-words representations of the articles. All tokens were converted to lower case, and tokens occurring in only one article were removed. We conducted no stopword removal, nor stemming. Finally, we normalized the feature vectors to sum up to one. Table 2 shows some properties of the data. |X| is the number of instances, |L |the number of distinct category labels; the fourth column contains the number of features (words) in the data set.4 3http://download.wikimedia.org 4The data can be downloaded from http://www. domain/path. � 1, if ˆf∗ i (x) &gt; ˆfi(x) := s (8) −1, otherwise (s</context>
</contexts>
<marker>McCallum, 2002</marker>
<rawString>Andrew Kachites McCallum. 2002. Mallet: A machine learning for language toolkit. http://mallet.cs.umass.edu.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olena Medelyan</author>
<author>Ian H Witten</author>
<author>David Milne</author>
</authors>
<title>Topic indexing with Wikipedia.</title>
<date>2008</date>
<booktitle>In Proceedings of the Wikipedia and AI workshop at AAAI-08.</booktitle>
<publisher>AAAI.</publisher>
<contexts>
<context position="1334" citStr="Medelyan et al., 2008" startWordPosition="191" endWordPosition="194">m of the crowds and machine learning/NLP methods. We define the categorization of Wikipedia articles as a multi-label classification task, describe two solutions to the task, and perform experiments that show that our approach is feasible despite the high number of labels. 1 Introduction Wikipedia’s article contents and its category hierarchy are widely used to produce semantic resources which improve performance on tasks like text classification and keyword extraction (Banerjee, 2007; Gabrilovich and Markovitch, 2007; Minier et al., 2007; Mihalcea and Csomai, 2007; Wang and Domeniconi, 2008; Medelyan et al., 2008). The reverse – using text classification methods to improve Wikipedia’s article-category mappings – has attracted less attention (Fu et al., 2007). A system that automatically suggests categories for Wikipedia articles will help to improve the encyclopedia for its users and authors, as well as the semantic resources created from it. The complexity of Wikipedia’s category systems1 and sheer number of categories make it 1We use the plural here, as each language version has its hard for – possibly inexperienced – authors to assign categories to new or existing articles. As of February 2009, the </context>
</contexts>
<marker>Medelyan, Witten, Milne, 2008</marker>
<rawString>Olena Medelyan, Ian H. Witten, and David Milne. 2008. Topic indexing with Wikipedia. In Proceedings of the Wikipedia and AI workshop at AAAI-08. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneldo Loza Mencia</author>
<author>Johannes F¨urnkranz</author>
</authors>
<title>Efficient pairwise multilabel classification for largescale problems in the legal domain.</title>
<date>2008</date>
<journal>ECML/PKDD</journal>
<booktitle>of Lecture Notes in Computer Science,</booktitle>
<volume>2</volume>
<pages>50--65</pages>
<editor>In Walter Daelemans, Bart Goethals, and Katharina Morik, editors,</editor>
<publisher>Springer.</publisher>
<marker>Mencia, F¨urnkranz, 2008</marker>
<rawString>Eneldo Loza Mencia and Johannes F¨urnkranz. 2008. Efficient pairwise multilabel classification for largescale problems in the legal domain. In Walter Daelemans, Bart Goethals, and Katharina Morik, editors, ECML/PKDD (2), volume 5212 of Lecture Notes in Computer Science, pages 50–65. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Andras Csomai</author>
</authors>
<title>Wikify!: linking documents to encyclopedic knowledge.</title>
<date>2007</date>
<booktitle>In CIKM ’07,</booktitle>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1283" citStr="Mihalcea and Csomai, 2007" startWordPosition="183" endWordPosition="186">t the emergence of a virtuous circle between the wisdom of the crowds and machine learning/NLP methods. We define the categorization of Wikipedia articles as a multi-label classification task, describe two solutions to the task, and perform experiments that show that our approach is feasible despite the high number of labels. 1 Introduction Wikipedia’s article contents and its category hierarchy are widely used to produce semantic resources which improve performance on tasks like text classification and keyword extraction (Banerjee, 2007; Gabrilovich and Markovitch, 2007; Minier et al., 2007; Mihalcea and Csomai, 2007; Wang and Domeniconi, 2008; Medelyan et al., 2008). The reverse – using text classification methods to improve Wikipedia’s article-category mappings – has attracted less attention (Fu et al., 2007). A system that automatically suggests categories for Wikipedia articles will help to improve the encyclopedia for its users and authors, as well as the semantic resources created from it. The complexity of Wikipedia’s category systems1 and sheer number of categories make it 1We use the plural here, as each language version has its hard for – possibly inexperienced – authors to assign categories to </context>
</contexts>
<marker>Mihalcea, Csomai, 2007</marker>
<rawString>Rada Mihalcea and Andras Csomai. 2007. Wikify!: linking documents to encyclopedic knowledge. In CIKM ’07, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zsolt Minier</author>
<author>Zalan Bodo</author>
<author>Lehel Csato</author>
</authors>
<title>Wikipedia-based kernels for text categorization.</title>
<date>2007</date>
<booktitle>In SYNASC ’07,</booktitle>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="1256" citStr="Minier et al., 2007" startWordPosition="179" endWordPosition="182">ia. This could support the emergence of a virtuous circle between the wisdom of the crowds and machine learning/NLP methods. We define the categorization of Wikipedia articles as a multi-label classification task, describe two solutions to the task, and perform experiments that show that our approach is feasible despite the high number of labels. 1 Introduction Wikipedia’s article contents and its category hierarchy are widely used to produce semantic resources which improve performance on tasks like text classification and keyword extraction (Banerjee, 2007; Gabrilovich and Markovitch, 2007; Minier et al., 2007; Mihalcea and Csomai, 2007; Wang and Domeniconi, 2008; Medelyan et al., 2008). The reverse – using text classification methods to improve Wikipedia’s article-category mappings – has attracted less attention (Fu et al., 2007). A system that automatically suggests categories for Wikipedia articles will help to improve the encyclopedia for its users and authors, as well as the semantic resources created from it. The complexity of Wikipedia’s category systems1 and sheer number of categories make it 1We use the plural here, as each language version has its hard for – possibly inexperienced – autho</context>
</contexts>
<marker>Minier, Bodo, Csato, 2007</marker>
<rawString>Zsolt Minier, Zalan Bodo, and Lehel Csato. 2007. Wikipedia-based kernels for text categorization. In SYNASC ’07, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Platt</author>
</authors>
<title>Probabilistic outputs for support vector machines and comparison to regularized likelihood methods.</title>
<date>2000</date>
<booktitle>In Advances in Large Margin Classifiers.</booktitle>
<contexts>
<context position="12614" citStr="Platt, 2000" startWordPosition="2066" endWordPosition="2067">Training As an experimental baseline, we used a static classifier (most-frequent) that always predicts the most frequent categories, regardless of the article. We implemented the RCut and SCut strategies using linear support-vector machines from the LIBSVM library (Chang and Lin, 2001) for the underlying binary classification task. For each category, we used 5-fold cross-validation to find a good value for the hyperparameter C (Hsu et al., 2003). As SVMs perform only binary decisions, but do not yield scores suitable for ranking the labels, we used LIBSVM’s modified version of Platt’s method (Platt, 2000) to obtain probabilities, which are used as scores for the RCut rankings and the SCut decisions. As SCut’s threshold search goes over an infinite set S = [0, 1] (Algorithm 1, line 3), we did an approximate search over this interval with step size 0.01. For RCut and most-frequent, we report results for all thresholds 1, . . . ,|L|. In an application setting, we would have to determine a suitable t using a hold-out data set. 4.3 Results and Discussion The results can be seen in Table 3 and Figure 1 and 2. Both methods clearly perform better than the baseline. For macro-averaged Fi on Eishockey, </context>
</contexts>
<marker>Platt, 2000</marker>
<rawString>J. Platt. 2000. Probabilistic outputs for support vector machines and comparison to regularized likelihood methods. In Advances in Large Margin Classifiers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Shalev-Shwartz</author>
<author>Y Singer</author>
<author>N Srebro</author>
</authors>
<title>Pegasos: Primal estimated sub–gradient solver for SVM.</title>
<date>2007</date>
<booktitle>In Proceedings of the International Conference on Machine Learning.</booktitle>
<contexts>
<context position="15151" citStr="Shalev-Shwartz et al., 2007" startWordPosition="2474" endWordPosition="2477">ith different characteristics. Furthermore, it could provide the basis for multilingual document classification data sets. To be able to provide category suggestions for large Wikipedias like the German, the Spanish or the English one, we will extend our experiments to larger subsets, and finally to all of the German and English Wikipedia. In order to achieve this, we will also investigate hierarchical multi-label classification methods (Liu et al., 2005; Cai and Hofmann, 2004; Cesa-Bianchi et al., 2006) and faster training algorithms for linear SVMs and logistic regression (Fan et al., 2008; Shalev-Shwartz et al., 2007). Given that we use |L |binary classifiers for our models, this should be feasible, even for large numbers of categories. It would also be interesting to compare our methods to the work by Fu et al. (2007), which concentrates on link-based categorization of Wikipedia articles. Other promising research directions are the examination of Wikipedia-specific features, and the survey of large-scale multi-label classification algorithms that take into account dependencies between labels. 35 micro- averaged F1 macro -averaged F1 P R P R method Philosoph most-frequent (t = 1) 0.489 0.315 0.383 0.009 0.</context>
</contexts>
<marker>Shalev-Shwartz, Singer, Srebro, 2007</marker>
<rawString>S. Shalev-Shwartz, Y. Singer, and N. Srebro. 2007. Pegasos: Primal estimated sub–gradient solver for SVM. In Proceedings of the International Conference on Machine Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Tsoumakas</author>
<author>I Katakis</author>
<author>I Vlahavas</author>
</authors>
<date>2009</date>
<note>Mining multi-label data. unpublished book chapter.</note>
<contexts>
<context position="6407" citStr="Tsoumakas et al. (2009)" startWordPosition="1041" endWordPosition="1044">edia articles: Such a system cannot present an arbitrarily high number of (possibly ranked) suggestions to the user, who would be overwhelmed by the amount of information. On the other hand, if there is a fixed low number of suggestions, there would be the danger of correct category labels being left out. 3 Methods There are many multi-label classification models in the literature, which are either adaptions of existing single-label models, or models generated by transformation of the multi-label problem to single-label problems, which are then solved using again existing single-label models. Tsoumakas et al. (2009) give an overview of multi-label classification methods. Wikipedia articles are hypertext pages. For classifying hypertext pages, there are two obvious kinds of features: (i), there are content-based features, like words or n-grams contained in the articles, and (ii), there are link-based features, such as in- and outgoing article links, links to external web pages, and the (estimated or actually known) categories of the linked articles. Past research on relational learning and hypertext classification (Lu and Getoor, 2003) has shown that both kinds of features are useful, and that the stronge</context>
</contexts>
<marker>Tsoumakas, Katakis, Vlahavas, 2009</marker>
<rawString>G. Tsoumakas, I. Katakis, and I. Vlahavas. 2009. Mining multi-label data. unpublished book chapter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pu Wang</author>
<author>Carlotta Domeniconi</author>
</authors>
<title>Building semantic kernels for text classification using Wikipedia.</title>
<date>2008</date>
<booktitle>In KDD ’08,</booktitle>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1310" citStr="Wang and Domeniconi, 2008" startWordPosition="187" endWordPosition="190">us circle between the wisdom of the crowds and machine learning/NLP methods. We define the categorization of Wikipedia articles as a multi-label classification task, describe two solutions to the task, and perform experiments that show that our approach is feasible despite the high number of labels. 1 Introduction Wikipedia’s article contents and its category hierarchy are widely used to produce semantic resources which improve performance on tasks like text classification and keyword extraction (Banerjee, 2007; Gabrilovich and Markovitch, 2007; Minier et al., 2007; Mihalcea and Csomai, 2007; Wang and Domeniconi, 2008; Medelyan et al., 2008). The reverse – using text classification methods to improve Wikipedia’s article-category mappings – has attracted less attention (Fu et al., 2007). A system that automatically suggests categories for Wikipedia articles will help to improve the encyclopedia for its users and authors, as well as the semantic resources created from it. The complexity of Wikipedia’s category systems1 and sheer number of categories make it 1We use the plural here, as each language version has its hard for – possibly inexperienced – authors to assign categories to new or existing articles. A</context>
</contexts>
<marker>Wang, Domeniconi, 2008</marker>
<rawString>Pu Wang and Carlotta Domeniconi. 2008. Building semantic kernels for text classification using Wikipedia. In KDD ’08, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yiming Yang</author>
</authors>
<title>A study on thresholding strategies for text categorization.</title>
<date>2001</date>
<pages>137--145</pages>
<editor>In W. Bruce Croft, David J. Harper, Donald H. Kraft, and Justin Zobel, editors, SIGIR</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="7925" citStr="Yang (2001)" startWordPosition="1282" endWordPosition="1283">ion of multi-label classification (equation 1), and then to train binary classifier models like support-vector machines (SVM, Cortes and Vapnik (1995)): ˆfnaive(x) := {li |ˆfi(x) = 1} (4) As the training of a traditional binary SVM classifier does not optimize towards the given multilabel loss function, but for accuracy, we do not expect the best results from this method. 33 If we want better multi-label predictions, changing the threshold of the binary decision functions is a straightforward solution. We employed two well-known thresholding strategies, ranking cut (RCut) and score cut (SCut, Yang (2001)), to predict Wikipedia categories. RCut sorts all labels according to their binary prediction score ˆf∗i , and selects the t top labels: frcut(x) := argmax1≤i≤|L |ˆf∗i (x), t (5) where argmaxta∈A g(a) refers to the t elements of A with highest value g(a). The value of the hyperparameter threshold t can be chosen empirically on a hold-out set. SCut uses an individual decision threshold si for each label: ˆfscut(x) := {li |ˆf∗i (x) &gt; si} (6) Good threshold values si can be determined during training. Algorithm 1 shows a category-wise optimization of the threshold values as described by Yang (20</context>
</contexts>
<marker>Yang, 2001</marker>
<rawString>Yiming Yang. 2001. A study on thresholding strategies for text categorization. In W. Bruce Croft, David J. Harper, Donald H. Kraft, and Justin Zobel, editors, SIGIR 2001, pages 137–145. ACM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>