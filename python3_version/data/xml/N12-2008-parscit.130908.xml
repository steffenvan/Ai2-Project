<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.008072">
<title confidence="0.999646">
Using Ontology-based Approaches to Representing Speech Transcripts
for Automated Speech Scoring
</title>
<author confidence="0.995998">
Miao Chen
</author>
<affiliation confidence="0.9915745">
School of Information Studies
Syracuse University
</affiliation>
<address confidence="0.708035">
Syracuse, NY 13244, USA
</address>
<email confidence="0.995756">
mchen14@Syr.edu
</email>
<sectionHeader confidence="0.995577" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999892782608696">
This paper presents a thesis proposal on ap-
proaches to automatically scoring non-native
speech from second language tests. Current
speech scoring systems assess speech by pri-
marily using acoustic features such as fluency
and pronunciation; however content features
are barely involved. Motivated by this limita-
tion, the study aims to investigate the use of
content features in speech scoring systems.
For content features, a central question is how
speech content can be represented in appro-
priate means to facilitate automated speech
scoring. The study proposes using ontology-
based representation to perform concept level
representation on speech transcripts, and fur-
thermore the content features computed from
ontology-based representation may facilitate
speech scoring. One baseline and two ontolo-
gy-based representations are compared in ex-
periments. Preliminary results show that
ontology-based representation slightly im-
proves performance of one content feature for
automated scoring over the baseline system.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970024390244">
With increasing number of language learners tak-
ing second language tests, the resulting responses
add a huge burden to testing agencies, and thus
automated scoring has become a necessity for effi-
ciency and objectivity. Speaking, an important as-
pect for assessing second language speakers’
proficiency, is selected as the context of the study.
The general goal is to investigate new approaches
to automatic scoring of second language speech.
When giving a speaking test in computer-
mediated environment, test-takers’ responses are
typically recorded as speech files. These files can
be considered to contain two layers: sound and
text. The sound is about the acoustic side of
speech, whose features have been used to assess
speaking proficiency in existing automated speech-
scoring systems (Dodigovic, 2009; Zechner et al.,
2009). However, the text side, which is about the
content of speech, is by far not well addressed in
scoring systems, mainly due to the imperfect per-
formance of automatic speech recognizer systems.
As content is an integral part of speech, adding
content features to existing scoring systems may
further enhance system performance, and thus this
study aims to examine the use of content features
in speech scoring systems.
In order to acquire speech content, speech files
need to be transcribed to text files, by human or
Automatic Speech Recognition (ASR). The result-
ed text files, namely, speech transcripts, are to be
processed to extract content features. Moreover,
representation of text content (e.g. in vectors) is
important because it is the pre-requisite for compu-
ting content features and building speech scoring
models. Therefore this study focuses on represent-
ing content of speech transcripts to facilitate auto-
matic scoring of speech.
Speech transcripts can be seen as a special type
of text documents, and therefore document repre-
sentation approaches shed light on representation
of speech transcripts, such as Salton et al. (1975),
</bodyText>
<page confidence="0.994003">
41
</page>
<note confidence="0.9805735">
Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47,
Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics
</note>
<bodyText confidence="0.990169023809524">
Deerwester et al. (1990), Lewis (1992), Kaski
(1997), He et al. (2004), Arguello et al. (2008),
Hotho et al. (2003a). On the other hand, written
essays, the output of writing section of second lan-
guage test, share great similarity with speech tran-
scripts, and representation of essays also has
implications on speech transcript representation,
such as Burstein (2003), Attali &amp; Burstein (2006),
and Larkey &amp; Croft (2003).
Existing document representation approaches
are primarily statistical and corpus based, using
words or latent variables mined from corpus as
representation units in the vector. These approach-
es exhibit two challenges: 1) meaningfulness of
representation units. For example, synonymous
words represent similar meaning and thus should
be grouped as one representation unit. 2) unknown
terms. Since words or latent variables in the vector
are from training corpus, if an unknown term oc-
curs in the testing corpus then it is difficult to de-
termine the importance of the term in the training
corpus because there is no prior knowledge of it in
the training corpus.
Ontology concepts, representation units at the
concept level, have been less employed in content
representation. Hotho et al. (2003a) claim that on-
tology concepts can help reveal concepts and se-
mantics in documents, and thus we hypothesize
ontology-based representation may facilitate ob-
taining better content features for speech scoring.
Ontologies can also complement the abovemen-
tioned shortcomings of statistical and corpus based
representations by providing meaningful represen-
tation units and reasoning power between con-
cepts.
The study compares baseline (statistical and
corpus based) and ontology-based approaches. The
criterion is representing the same speech tran-
scripts using these approaches, computing content
features based on the representations, and compar-
ing performance of content features in predicting
speaking proficiency.
</bodyText>
<sectionHeader confidence="0.999804" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999918280701755">
This section reviews work related to representation
of speech transcripts, including document repre-
sentation, essay scoring, and ontology-based repre-
sentation in text processing.
Document representation has been an important
topic in research areas such as natural language
processing, information retrieval, and text mining,
in which a number of representation approaches
have been proposed.
The most common practice of text document
representation is the Bag-Of-Words (BOW) ap-
proach, illustrated in Salton et al. (1975). The basic
idea is that a document can be represented as a
vector of words, with each dimension of the vector
standing for one single word. Besides using explic-
it words from documents, latent variables derived
from document mining can be used for document
representation as well, such as the Latent Semantic
Analysis (LSA) and Latent Dirichlet Allocation
(LDA) approaches. The representation units are
latent concepts or topics and the documents are
projected to the semantic space constructed from
the latent concepts or topics (Deerwester et al.,
1990; Blei, 2012). An important purpose of using
the latent variables is to reduce dimensions in doc-
ument representation and place documents in a
more compact space. Some other dimension reduc-
tion techniques include Subspace-based methods
(Chen et al., 2003) and Self Organizing Map
(Kaski 1997; Kaski, et al. 1998).
In the area of automatic essay scoring, essay
content are represented to facilitate the scoring.
The BOW approach is widely used in essay repre-
sentation as well, including the e-rater system
(Burstein, 2003; Attali &amp; Burstein, 2006) and the
experimental system in Larkey &amp; Croft (2003).
Representation in the BETSY system (Bayesian
Essay Test Scoring System) also involves words,
such as frequency of content words, along with
specific phrases (Dikli, 2006). The exemplar sys-
tem employing LSA representation is the Intelli-
gent Essay Assessor system, which performs LSA
on training essays and then projects essays to the
vector space of latent concepts (Landauer et al.,
2003).
Besides representation approaches, content fea-
ture computing in essay scoring is useful to content
scoring of speech because they share great simi-
larity. Content features can be derived by compu-
ting cosine similarity between essay vectors, such
as in e-rater (Attali &amp; Burstein, 2006) and Intelli-
gent Essay Assessor (Landauer et al., 2003). The e-
rater content feature computing is adopted in this
study to compute content features of speech tran-
scripts.
As mentioned in section 1, ontologies can be
used to complement the challenges of statistical
</bodyText>
<page confidence="0.955312">
42
</page>
<bodyText confidence="0.992109084210526">
representation approaches. Ontology concepts have 3 Methodology
been successfully used in text processing tasks
such as text classification and clustering and can
help resolve the first challenge, meaningfulness of
the representation. Hotho and Bloehdorn along
with other people conducted a series of studies in
using the ontologies (i.e. WordNet) for text catego-
rization and clustering tasks (Bloehdorn &amp; Hotho,
2004; Hotho et al., 2003a; Hotho et al., 2003b).
The goals are to overcome several weaknesses, e.g.
synonyms and generalization issues, of the bag-of-
words representation by using ontology concept
based representation. Basically concepts from on-
tologies are used as units for text representation
and then text processing is performed on top of the
ontology-based representation. Explicit Semantic
Approach (ESA), proposed by Gabrilovich and
Markovitch (2007), is an approach to representing
an arbitrary text snippet in vector of Wikipedia
concepts for the convenience of further natural
language processing. Each Wikipedia concept has
text description, which is used to build an invert
index to associate words with concepts. The invert
index helps represent each word by vector of Wik-
ipedia concepts, and eventually a document can be
represented by weighted Wikipedia concepts by
adding up the Wikipedia concept vectors of the
words that the document contains.
Ontologies can also help resolve the second
challenge of statistical representation, the unknown
term issue. If a term occurs in the testing corpus
but not the training corpus, then the importance of
the term can be inferred from external knowledge
such as ontologies. The semantic relations defined
in ontologies connect relevant concepts and organ-
ize them into a tree (i.e. WordNet) or a graph struc-
ture (i.e. Wikipedia). Since paths usually exist
between two individual concepts, ontologies can
support inferences among concepts by using the
paths and concept nodes between them. Moreover,
semantic similarity between concepts, computed
based on ontology knowledge, can be used to infer
importance of unknown terms.
WordNet (Fellbaum, 1998) and Wikipedia
(Wikipedia, 2012) ontologies are two popular on-
tologies for computing semantic similarity. A
number of similarity approaches have been pro-
posed for similarity calculation according to the
different characteristics of the two ontologies (Lin,
1998; Pedersen et al., 2004; Resnik, 1999; Strube
&amp; Ponzetto, 2006).
43
Experiments are conducted to compare ontology-
based representations (experimental systems) and
common representations (baseline systems). Two
ontology-based methods are employed as the ex-
perimental systems, one is about representing tran-
scripts using ontology concepts (“ONTO”), and the
other is about inferring weights of unknown terms
using ontologies (“OntoReason”). For the baseline,
we identify the BOW representation as a common
text representation and use it in the baseline sys-
tem.
3.1 Data Set
The data set comes from an English proficiency
test for non-native speakers. For the speaking sec-
tion, test takers are asked to provide spontaneous
speech responses to the prompts1 (test tasks). There
are 4 prompts in the data set, all of which are inte-
grated prompts. An integrated prompt is a test task
that first provides test takers some materials to read
or listen and then asks them to provide opinions or
arguments towards the materials. The responses
are then scored holistically by human raters based
on a scoring rubric on a scale of 1 to 4, 4 being the
highest score. For each score level, the scoring ru-
bric contains guidelines of expected performance
on various aspects of speaking ability such as pro-
nunciation, fluency, and content.
The data set contains 1243 speech samples from
327 speakers in total. Manual and automatic meth-
ods are used to obtain transcripts of the speech
samples. For the manual way, each response is
verbatim transcribed by human; and for the auto-
matic way, each response is automatically tran-
scribed by ASR with word error rate of 12.8%.
Therefore two sets of transcripts are derived for the
speech responses, the human transcripts set and the
ASR set.
Since the representation approaches are prompt-
specific in the study, meaning vector representa-
tions are generated for each prompt, the data set is
first split by prompts and then responses are split
into training and testing sets within each prompt.
Table 1 shows size of the data set and subsets:
</bodyText>
<table confidence="0.975396888888889">
1 Prompts are test tasks assigned to test takers to elicit their
speaking responses.
2 The feature is referred to as “cos.w/6” in Attali and Burstein
(2006) because there are usually 6 score levels, while here our
Prompt Training Set Test Set Total
A 143 176 319 (4/79/158/78)
B 140 168 308 (7/86/146/69)
C 139 172 311 (4/74/154/79)
D 137 168 305 (8/75/141/81)
</table>
<tableCaption confidence="0.993871666666667">
Table 1. Size of data set and subsets. The numbers in
parentheses are the number of documents on score lev-
els 1-4.
</tableCaption>
<subsectionHeader confidence="0.96676">
3.2 Representation Approaches of Speech
Transcripts
</subsectionHeader>
<bodyText confidence="0.999979833333333">
One baseline approach and two ontology-based
approaches are briefly introduced here and imple-
mented in experiments. The approaches are used to
generate vectors for computing content features.
We also plan to employ other approaches in the
future, as described in section 5.
</bodyText>
<subsubsectionHeader confidence="0.576408">
3.2.1 Bag-of-words (baseline)
</subsubsectionHeader>
<bodyText confidence="0.999902466666667">
It takes the view that essays can be represented in
vector of words and the value of a word in a vector
refers to its weighting on this dimension. It uses
the representation method in the e-rater as well,
including document-level representation for testing
documents and score-level representation for train-
ing documents (Attali &amp; Burstein, 2006).
Within each prompt, each testing transcript is
converted to a vector (document level representa-
tion); training transcripts are grouped by their
score levels and for each score level a vector is
generated by aggregating all transcripts of this
score level (score level representation). We decide
to use the tfidf weighting schema with stop words
removed after tuning options of the parameters.
</bodyText>
<sectionHeader confidence="0.511157" genericHeader="method">
3.2.2 Ontology-based Representation (experi-
mental)
</sectionHeader>
<bodyText confidence="0.99981212">
ONTO-WordNet approach. Concepts from ontolo-
gy are identified in speech transcripts and then
used to generate concept-level vectors. In practice,
concept mapping in transcripts varies according to
characteristics of ontologies. The WordNet ontolo-
gy, containing mostly single words, is used as one
case in the study. In the future, we plan to try the
Wikipedia ontology, which contains more phrases-
based concepts, for ontology-based representation.
Synsets, groups of synonyms, are concepts in
WordNet and used as ontology concepts here.
Document text is split by whitespace and punctua-
tions to a set of words. Then the words are
matched to WordNet synsets. As a word may have
multiple senses (synsets), it is necessary to decide
which synset to use in WordNet. Therefore we try
two sense selection strategies as in Hotho et al.’s
(2003a) study: 1) simply use the first sense in
WordNet; and 2) do part-of-speech tagging on sen-
tences and find the corresponding sense in Word-
Net. We find the 1st strategy obtains better
performance than the 2nd one and thus decide to
use the 1st one. When constructing ontology-based
vector, we include both concepts and words in the
vector.
</bodyText>
<subsectionHeader confidence="0.526178">
3.2.3 Ontology-based Reasoning (experimental)
</subsectionHeader>
<bodyText confidence="0.99998075">
OntoReason-WordNet approach. This approach is
also implemented by using WordNet. First, tran-
scripts are represented by ontology concepts as in
section 3.2.2. Then given an unknown concept in
test transcripts, we identify its semantically similar
concepts (N=5) in the training transcripts and then
reason the weight of the unknown concept based
on the weights of these similar concepts.
The reasoning makes use of semantic similarity
between WordNet synsets. Concept similarity is
computed using the edge-based path similarity
(Pedersen et al., 2004). We select N=5 concepts
from the training transcripts that are most similar
to the unknown concept, and compute the weight
of the unknown concept in the training transcripts
by averaging the weights of the 5 similar concepts.
</bodyText>
<subsectionHeader confidence="0.999483">
3.3 Content Feature Computation
</subsectionHeader>
<bodyText confidence="0.917118222222222">
The baseline and experimental systems all generate
vector representations for speech transcripts. The
content features are computed based on vector rep-
resentation, and all representation approaches em-
ploy the same method of computing content
features. We choose to use the two content features
of the e-rater system, “max.cos” and “cos.w4”, as
the feature computation method2 (Attali &amp;
Burstein, 2006).
The max.cos feature. This feature identifies
which score level of training documents the testing
document is closest to. It computes and compares
the similarity between the test document and train-
ing documents of each score level in vector space,
and then makes the score level whose training doc-
2 The feature is referred to as “cos.w/6” in Attali and Burstein
(2006) because there are usually 6 score levels, while here our
data has 4 score levels therefore it is written as “cos.w4”.
</bodyText>
<page confidence="0.99879">
44
</page>
<bodyText confidence="0.999957">
uments are most similar to the test document as the
feature value.
The cos.w4 feature. This feature computes con-
tent similarity between the test document and the
highest level training documents in vector space.
Since score 4 is the highest level in our data set of
spoken responses, we compute the cosine similari-
ty between the test vector and the score level 4
vector as the feature value.
Given a speech transcript from the test set, we
first convert it to a vector using one of the repre-
sentation approaches, and then compute the
max.cos and cos.w4 feature values as its content
features.
</bodyText>
<subsectionHeader confidence="0.945968">
3.4 Evaluation
</subsectionHeader>
<bodyText confidence="0.99999575">
Representation approaches are evaluated based on
their performance in predicting speaking proficien-
cy of test takers. More specifically, a representa-
tion approach generates a vector representation
using specific representation units (e.g. words,
concepts); for each test transcript, two content fea-
tures are computed based on the vector representa-
tion; Pearson correlation r is computed between
each content feature and speaking proficiency to
indicate the predictiveness of the content feature
resulting from a specific representation. Higher
correlation indicates higher predictiveness on
speaking proficiency. Lastly, we compare content
feature correlations of different representation ap-
proaches. We consider that the higher the correla-
tion is, the better the representation approach is.
</bodyText>
<sectionHeader confidence="0.984052" genericHeader="evaluation">
4 Experiment Results
</sectionHeader>
<bodyText confidence="0.999961513513513">
In the preliminary stage, the BOW (baseline),
ONTO-WordNet and OntoReason-WordNet (ex-
perimental) approaches are implemented. Mean-
while parameters are optimized to acquire the best
parameter setup for each approach. Since the
speech files are transcribed by both human and
ASR, same experiments are run on both data sets
to compare representation performance on differ-
ent transcriptions. The correlations of the two con-
tent features to speaking proficiency are computed
for each representation. Tables 2 and 3 show corre-
lations of the max.cos and cos.w4 features respec-
tively:
For the max.cos feature, the average correlation
of the ONTO-WordNet approach outperforms the
BOW baseline slightly but the correlation drops
dramatically when using the OntoReason-WordNet
approach, for both the human and ASR transcripts.
For the cos.w4 feature, the average correlation of
the ONTO-WordNet approach outperforms the
BOW, and the OntoReason-WordNet further out-
performs the ONTO-WordNet approach, for both
the human and ASR transcripts. It shows some ev-
idence that ontology-based representation can im-
prove performance of both content features; the
ontology-based reasoning increases performance of
the cos.w4 feature but decreases the max.cos fea-
ture correlation.
Comparing the performance on human vs. ASR
transcripts, the features extracted from the human
transcripts exhibit better average correlations than
the corresponding features from the ASR tran-
scripts. The results also show that the correlation
difference between human and ASR transcripts is
moderate. It may indicate that the representation
approaches can be employed on ASR transcripts to
further automate the speech scoring process.
</bodyText>
<table confidence="0.997601375">
Prompt Hum, Hum, Hum, Onto- ASR, ASR, ASR, Onto-
BOW ONTO- Reason- BOW ONTO- Reason-
WordNet WordNet WordNet WordNet
A 0.320 0.333 0.038 0.293 0.286 0.014
B 0.348 0.352 0.350 0.308 0.338 0.339
C 0.366 0.373 0.074 0.396 0.386 0.106
D 0.343 0.323 0.265 0.309 0.309 0.265
Average 0.344 0.345 0.182 0.327 0.330 0.181
</table>
<tableCaption confidence="0.985559">
Table 2. Correlations between the max.cos feature and speaking proficiency (Hum=using human transcriptions;
ASR=using ASR hypotheses).
</tableCaption>
<page confidence="0.960703">
45
</page>
<table confidence="0.9841035">
Prompt Hum, Hum, Hum, Onto- ASR, ASR, ASR, Onto-
BOW ONTO- Reason- BOW ONTO- Reason-
WordNet WordNet WordNet WordNet
A 0.427 0.429 0.434 0.409 0.416 0.411
B 0.295 0.303 0.327 0.259 0.278 0.292
C 0.352 0.385 0.402 0.338 0.366 0.380
D 0.368 0.385 0.389 0.360 0.379 0.374
Average 0.361 0.376 0.388 0.342 0.360 0.364
</table>
<tableCaption confidence="0.988089">
Table 3. Correlations between the cos.w4 feature and speaking proficiency (Hum=using human transcriptions;
ASR=using ASR hypotheses)
</tableCaption>
<sectionHeader confidence="0.999064" genericHeader="discussions">
5 Future Work
</sectionHeader>
<bodyText confidence="0.999917638297873">
For future work, we will implement one more
baseline (LSA) and two more ontology-based ap-
proaches (ONTO-Wikipedia and OntoReason-
Wikipedia) and analyze their performance.
Latent semantic analysis (LSA). LSA decom-
poses a term-by-document matrix generated from
training transcripts to three sub-matrices. Then
given a test transcript, documents can be projected
to the latent semantic space based on the three sub-
matrices. The rank k parameter needs to be decided
as a parameter for dimensionality reduction pur-
pose by tuning it on the training data.
Using Wikipedia as another case for ontology,
two more experimental approaches will be imple-
mented, one for ontology-based representation and
the other for ontology-based reasoning.
ONTO-Wikipedia. Wikipedia concepts can be
identified in transcripts in two ways: 1) directly
find concepts in text window of 5 words; 2) con-
vert a transcript in vectors of Wikipedia concepts
using the Explicit Semantic Analysis method,
which associates words to Wikipedia concepts and
represents arbitrary text using the word-concept
associations (Gabrilovich and Markovitch, 2007).
OntoReason-Wikpedia. The concept similarity
between Wikipedia concepts is obtained by com-
puting the cosine similarity of the text description
of the concepts. The reasoning method of the un-
known concept follows the one mentioned in the
OntoReason-WordNet approach.
We will compute content features based on the-
se new representations and evaluate the perfor-
mance according to feature correlations. The
current results examine effects of using the Word-
Net ontology on predicting speaking proficiency,
and these new experiments will answer whether
the other type of ontology, Wikipedia, has positive
effect in speaking proficiency prediction. We will
also compare the effects of using different ontolo-
gies for ontology-based representations.
The study has implications on effects of differ-
ent speech transcript representations in predicting
speaking proficiency. Since content features are
less well explored in automatic speech scoring
compared to acoustic features, it also contributes to
the understanding of the use and effects of content
features in speech scoring.
</bodyText>
<sectionHeader confidence="0.998561" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999874666666667">
The author would like to than Drs. Klaus Zech-
ner and Jian Qin for their tremendous help and
support on the dissertation study.
</bodyText>
<sectionHeader confidence="0.998161" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996731888888889">
Arguello, J., Elsas, J. L., Callan, J., &amp; Carbonell, J. G.
(2008). Document representation and query expan-
sion models for blog recommendation. Proceedings
of the Second International Conference on Weblogs
and Social Media (ICWSM 2008).
Attali, Y., &amp; Burstein, J. (2006). Automated essay scor-
ing with e-rater® V. 2. The Journal of Technology,
Learning and Assessment, 4(3).
Blei, D. (2012). Introduction to probabilistic topic mod-
els. Communications of the ACM, 77-84.
Bloehdorn, S., &amp; Hotho, A. (2004). Boosting for text
classification with semantic features. Workshop on
mining for and from the semantic web at the 10th
ACM SIGKDD conference on knowledge discovery
and data mining (KDD 2004).
Burstein, J. (2003). The E-rater® scoring engine: Au-
tomated essay scoring with natural language pro-
cessing. In M. D. Shermis, Burstein, J.C. (Ed.),
Automated essay scoring: A cross-disciplinary per-
spective (pp. 113-121). Mahwah, NJ: Lawrence Erl-
baum Associates, Inc.
Chen, L., Tokuda, N., &amp; Nagai, A. (2003). A new dif-
ferential LSI space-based probabilistic document
classifier. Information Processing Letters, 88(5),
203-212.
Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer,
T. K., &amp; Harshman, R. (1990). Indexing by latent
</reference>
<page confidence="0.99053">
46
</page>
<reference confidence="0.997447763888889">
semantic analysis. Journal of the American Society
for information science, 41(6), 391-407.
Dikli, S. (2006). An overview of automated scoring of
essays. The Journal of Technology, Learning and As-
sessment, 5(1).
Dodigovic, M. (2009). Speech Processing Technology
in Second Language Testing. Proceedings of the
Conference on Language &amp; Technology 2009.
Fellbaum, C. (Ed.). (1998). WordNet: An electronic
lexical database. Cambridge, MA: The MIT press.
Gabrilovich, E., &amp; Markovitch, S. (2007). Computing
semantic relatedness using wikipedia-based explicit
semantic analysis. Proceedings of the 20th Interna-
tional Joint Conference on Artificial Intelligence.
He, X., Cai, D., Liu, H., &amp; Ma, W. Y. (2004). Locality
preserving indexing for document representation.
Proceedings of the 27th Annual International ACM
SIGIR Conference.
Hotho, A., Staab, S., &amp; Stumme, G. (2003a). Ontologies
improve text document clustering. Proceedings of the
Third IEEE International Conference on Data Mining
(ICDM’03).
Hotho, A., Staab, S., &amp; Stumme, G. (2003b). Text clus-
tering based on background knowledge (Technical
report, no.425.): Institute of Applied Informatics and
Formal Description Methods AIFB, University of
Karlsruche.
Kaski, S. (1997). Computationally efficient approxima-
tion of a probabilistic model for document represen-
tation in the WEBSOM full-text analysis method.
Neural processing letters, 5(2), 69-81.
Kaski, S., Honkela, T., Lagus, K., &amp; Kohonen, T.
(1998). WEBSOM-Self-organizing maps of docu-
ment collections1. Neurocomputing, 21(1-3), 101-
117.
Landauer, T. K., Laham, D., &amp; Foltz, P. W. (2003). Au-
tomated scoring and annotation of essays with the In-
telligent Essay Assessor. In M. D. Shermis, Burstein,
J.C. (Ed.), Automated essay scoring: A cross-
disciplinary perspective (pp. 87–112). Mahwah, NJ:
Lawrence Erlbaum Associates, Inc.
Larkey, L. S., &amp; Croft, W. B. (2003). A Text Categori-
zation Approach to Automated Essay Grading. In M.
D. Shermis &amp; J. C. Burstein (Eds.), Automated Essay
Scoring: A Cross-discipline Perspective: Mahwah,
NJ, Lawrence Erlbaum.
Lewis, D. D. (1992). Representation and learning in
information retrieval. (Doctoral dissertation). Uni-
versity of Massachusetts.
Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004).
WordNet:: Similarity: measuring the relatedness of
concepts. Proceedings of the Fifth Annual Meeting of
the North American Chapter of the Association for
Computational Linguistics (NAACL-04).
Resnik, P. (1999). Semantic similarity in a taxonomy:
An information-based measure and its application to
problems of ambiguity in natural language. Journal
of Artificial Intelligence, 11(1999), 95-130.
Salton, G., Wong, A., &amp; Yang, C. S. (1975). A vector
space model for automatic indexing. Communica-
tions of the ACM, 18(11), 613-620.
Strube, M., &amp; Ponzetto, S. P. (2006). WikiRelated!
Computing semantic relatedness using Wikipedia.
Proceedings of the American Association for Artifi-
cial Intelligence 2006, Boston, MA.
Wikipedia: The free encyclopedia. (2012, Apr 1). FL:
Wikimedia Foundation, Inc. Retrieved Apr 1, 2012,
from http://www.wikipedia.org
Zechner, K., Higgins, D., Xi, X., &amp; Williamson, D. M.
(2009). Automatic scoring of non-native spontaneous
speech in tests of spoken English. Speech Communi-
cation, 51(10), 883-895.
</reference>
<page confidence="0.999491">
47
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.341520">
<title confidence="0.999194">Using Ontology-based Approaches to Representing Speech for Automated Speech Scoring</title>
<author confidence="0.994438">Miao</author>
<affiliation confidence="0.848022">School of Information Syracuse</affiliation>
<address confidence="0.599303">Syracuse, NY 13244,</address>
<email confidence="0.996983">mchen14@Syr.edu</email>
<abstract confidence="0.999587541666667">This paper presents a thesis proposal on approaches to automatically scoring non-native speech from second language tests. Current speech scoring systems assess speech by primarily using acoustic features such as fluency and pronunciation; however content features are barely involved. Motivated by this limitation, the study aims to investigate the use of content features in speech scoring systems. For content features, a central question is how speech content can be represented in appropriate means to facilitate automated speech scoring. The study proposes using ontologybased representation to perform concept level representation on speech transcripts, and furthermore the content features computed from ontology-based representation may facilitate speech scoring. One baseline and two ontology-based representations are compared in experiments. Preliminary results show that ontology-based representation slightly improves performance of one content feature for automated scoring over the baseline system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Arguello</author>
<author>J L Elsas</author>
<author>J Callan</author>
<author>J G Carbonell</author>
</authors>
<title>Document representation and query expansion models for blog recommendation.</title>
<date>2008</date>
<booktitle>Proceedings of the Second International Conference on Weblogs and Social Media (ICWSM</booktitle>
<contexts>
<context position="3459" citStr="Arguello et al. (2008)" startWordPosition="512" endWordPosition="515">tent features and building speech scoring models. Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech. Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges: 1) meaningfulness of representation units. For example</context>
</contexts>
<marker>Arguello, Elsas, Callan, Carbonell, 2008</marker>
<rawString>Arguello, J., Elsas, J. L., Callan, J., &amp; Carbonell, J. G. (2008). Document representation and query expansion models for blog recommendation. Proceedings of the Second International Conference on Weblogs and Social Media (ICWSM 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Attali</author>
<author>J Burstein</author>
</authors>
<title>Automated essay scoring with e-rater®</title>
<date>2006</date>
<journal>V. 2. The Journal of Technology, Learning and Assessment,</journal>
<volume>4</volume>
<issue>3</issue>
<contexts>
<context position="12517" citStr="Attali and Burstein (2006)" startWordPosition="1908" endWordPosition="1911">ically transcribed by ASR with word error rate of 12.8%. Therefore two sets of transcripts are derived for the speech responses, the human transcripts set and the ASR set. Since the representation approaches are promptspecific in the study, meaning vector representations are generated for each prompt, the data set is first split by prompts and then responses are split into training and testing sets within each prompt. Table 1 shows size of the data set and subsets: 1 Prompts are test tasks assigned to test takers to elicit their speaking responses. 2 The feature is referred to as “cos.w/6” in Attali and Burstein (2006) because there are usually 6 score levels, while here our Prompt Training Set Test Set Total A 143 176 319 (4/79/158/78) B 140 168 308 (7/86/146/69) C 139 172 311 (4/74/154/79) D 137 168 305 (8/75/141/81) Table 1. Size of data set and subsets. The numbers in parentheses are the number of documents on score levels 1-4. 3.2 Representation Approaches of Speech Transcripts One baseline approach and two ontology-based approaches are briefly introduced here and implemented in experiments. The approaches are used to generate vectors for computing content features. We also plan to employ other approac</context>
<context position="16783" citStr="Attali and Burstein (2006)" startWordPosition="2576" endWordPosition="2579">tor representation, and all representation approaches employ the same method of computing content features. We choose to use the two content features of the e-rater system, “max.cos” and “cos.w4”, as the feature computation method2 (Attali &amp; Burstein, 2006). The max.cos feature. This feature identifies which score level of training documents the testing document is closest to. It computes and compares the similarity between the test document and training documents of each score level in vector space, and then makes the score level whose training doc2 The feature is referred to as “cos.w/6” in Attali and Burstein (2006) because there are usually 6 score levels, while here our data has 4 score levels therefore it is written as “cos.w4”. 44 uments are most similar to the test document as the feature value. The cos.w4 feature. This feature computes content similarity between the test document and the highest level training documents in vector space. Since score 4 is the highest level in our data set of spoken responses, we compute the cosine similarity between the test vector and the score level 4 vector as the feature value. Given a speech transcript from the test set, we first convert it to a vector using one</context>
<context position="3758" citStr="Attali &amp; Burstein (2006)" startWordPosition="558" endWordPosition="561">n representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges: 1) meaningfulness of representation units. For example, synonymous words represent similar meaning and thus should be grouped as one representation unit. 2) unknown terms. Since words or latent variables in the vector are from training corpus, if an unknown term occurs in the testing corpus then it is difficult to determine the importance of the term </context>
<context position="6926" citStr="Attali &amp; Burstein, 2006" startWordPosition="1033" endWordPosition="1036">c space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012). An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006). The exemplar system employing LSA representation is the Intelligent Essay Assessor system, which performs LSA on training essays and then projects essays to the vector space of latent concepts (Landauer et al., 2003). Besides representation approaches, content feature computing in essay scoring is useful to content scoring of speech because they share great similarity. C</context>
<context position="13539" citStr="Attali &amp; Burstein, 2006" startWordPosition="2073" endWordPosition="2076">two ontology-based approaches are briefly introduced here and implemented in experiments. The approaches are used to generate vectors for computing content features. We also plan to employ other approaches in the future, as described in section 5. 3.2.1 Bag-of-words (baseline) It takes the view that essays can be represented in vector of words and the value of a word in a vector refers to its weighting on this dimension. It uses the representation method in the e-rater as well, including document-level representation for testing documents and score-level representation for training documents (Attali &amp; Burstein, 2006). Within each prompt, each testing transcript is converted to a vector (document level representation); training transcripts are grouped by their score levels and for each score level a vector is generated by aggregating all transcripts of this score level (score level representation). We decide to use the tfidf weighting schema with stop words removed after tuning options of the parameters. 3.2.2 Ontology-based Representation (experimental) ONTO-WordNet approach. Concepts from ontology are identified in speech transcripts and then used to generate concept-level vectors. In practice, concept m</context>
<context position="16414" citStr="Attali &amp; Burstein, 2006" startWordPosition="2515" endWordPosition="2518">aining transcripts that are most similar to the unknown concept, and compute the weight of the unknown concept in the training transcripts by averaging the weights of the 5 similar concepts. 3.3 Content Feature Computation The baseline and experimental systems all generate vector representations for speech transcripts. The content features are computed based on vector representation, and all representation approaches employ the same method of computing content features. We choose to use the two content features of the e-rater system, “max.cos” and “cos.w4”, as the feature computation method2 (Attali &amp; Burstein, 2006). The max.cos feature. This feature identifies which score level of training documents the testing document is closest to. It computes and compares the similarity between the test document and training documents of each score level in vector space, and then makes the score level whose training doc2 The feature is referred to as “cos.w/6” in Attali and Burstein (2006) because there are usually 6 score levels, while here our data has 4 score levels therefore it is written as “cos.w4”. 44 uments are most similar to the test document as the feature value. The cos.w4 feature. This feature computes </context>
</contexts>
<marker>Attali, Burstein, 2006</marker>
<rawString>Attali, Y., &amp; Burstein, J. (2006). Automated essay scoring with e-rater® V. 2. The Journal of Technology, Learning and Assessment, 4(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Blei</author>
</authors>
<title>Introduction to probabilistic topic models.</title>
<date>2012</date>
<journal>Communications of the ACM,</journal>
<pages>77--84</pages>
<contexts>
<context position="6394" citStr="Blei, 2012" startWordPosition="951" endWordPosition="952">pproach, illustrated in Salton et al. (1975). The basic idea is that a document can be represented as a vector of words, with each dimension of the vector standing for one single word. Besides using explicit words from documents, latent variables derived from document mining can be used for document representation as well, such as the Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) approaches. The representation units are latent concepts or topics and the documents are projected to the semantic space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012). An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representatio</context>
</contexts>
<marker>Blei, 2012</marker>
<rawString>Blei, D. (2012). Introduction to probabilistic topic models. Communications of the ACM, 77-84.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Bloehdorn</author>
<author>A Hotho</author>
</authors>
<title>Boosting for text classification with semantic features. Workshop on mining for and from the semantic web at the 10th ACM SIGKDD conference on knowledge discovery and data mining (KDD</title>
<date>2004</date>
<contexts>
<context position="8339" citStr="Bloehdorn &amp; Hotho, 2004" startWordPosition="1250" endWordPosition="1253">erater content feature computing is adopted in this study to compute content features of speech transcripts. As mentioned in section 1, ontologies can be used to complement the challenges of statistical 42 representation approaches. Ontology concepts have 3 Methodology been successfully used in text processing tasks such as text classification and clustering and can help resolve the first challenge, meaningfulness of the representation. Hotho and Bloehdorn along with other people conducted a series of studies in using the ontologies (i.e. WordNet) for text categorization and clustering tasks (Bloehdorn &amp; Hotho, 2004; Hotho et al., 2003a; Hotho et al., 2003b). The goals are to overcome several weaknesses, e.g. synonyms and generalization issues, of the bag-ofwords representation by using ontology concept based representation. Basically concepts from ontologies are used as units for text representation and then text processing is performed on top of the ontology-based representation. Explicit Semantic Approach (ESA), proposed by Gabrilovich and Markovitch (2007), is an approach to representing an arbitrary text snippet in vector of Wikipedia concepts for the convenience of further natural language processi</context>
</contexts>
<marker>Bloehdorn, Hotho, 2004</marker>
<rawString>Bloehdorn, S., &amp; Hotho, A. (2004). Boosting for text classification with semantic features. Workshop on mining for and from the semantic web at the 10th ACM SIGKDD conference on knowledge discovery and data mining (KDD 2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Burstein</author>
</authors>
<title>The E-rater® scoring engine: Automated essay scoring with natural language processing. In</title>
<date>2003</date>
<publisher>Inc.</publisher>
<contexts>
<context position="3732" citStr="Burstein (2003)" startWordPosition="556" endWordPosition="557">ches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges: 1) meaningfulness of representation units. For example, synonymous words represent similar meaning and thus should be grouped as one representation unit. 2) unknown terms. Since words or latent variables in the vector are from training corpus, if an unknown term occurs in the testing corpus then it is difficult to determine t</context>
<context position="6900" citStr="Burstein, 2003" startWordPosition="1031" endWordPosition="1032">d to the semantic space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012). An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006). The exemplar system employing LSA representation is the Intelligent Essay Assessor system, which performs LSA on training essays and then projects essays to the vector space of latent concepts (Landauer et al., 2003). Besides representation approaches, content feature computing in essay scoring is useful to content scoring of speech because they</context>
</contexts>
<marker>Burstein, 2003</marker>
<rawString>Burstein, J. (2003). The E-rater® scoring engine: Automated essay scoring with natural language processing. In M. D. Shermis, Burstein, J.C. (Ed.), Automated essay scoring: A cross-disciplinary perspective (pp. 113-121). Mahwah, NJ: Lawrence Erlbaum Associates, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Chen</author>
<author>N Tokuda</author>
<author>A Nagai</author>
</authors>
<title>A new differential LSI space-based probabilistic document classifier.</title>
<date>2003</date>
<journal>Information Processing Letters,</journal>
<volume>88</volume>
<issue>5</issue>
<pages>203--212</pages>
<contexts>
<context position="6635" citStr="Chen et al., 2003" startWordPosition="986" endWordPosition="989">nt variables derived from document mining can be used for document representation as well, such as the Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) approaches. The representation units are latent concepts or topics and the documents are projected to the semantic space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012). An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006). The exemplar system employing LSA representation is the Intelligent Essay Assessor</context>
</contexts>
<marker>Chen, Tokuda, Nagai, 2003</marker>
<rawString>Chen, L., Tokuda, N., &amp; Nagai, A. (2003). A new differential LSI space-based probabilistic document classifier. Information Processing Letters, 88(5), 203-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Deerwester</author>
<author>S T Dumais</author>
<author>G W Furnas</author>
<author>T K Landauer</author>
<author>R Harshman</author>
</authors>
<title>Indexing by latent semantic analysis.</title>
<date>1990</date>
<journal>Journal of the American Society for information science,</journal>
<volume>41</volume>
<issue>6</issue>
<pages>391--407</pages>
<contexts>
<context position="3389" citStr="Deerwester et al. (1990)" startWordPosition="500" endWordPosition="503"> vectors) is important because it is the pre-requisite for computing content features and building speech scoring models. Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech. Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit </context>
<context position="6381" citStr="Deerwester et al., 1990" startWordPosition="947" endWordPosition="950"> the Bag-Of-Words (BOW) approach, illustrated in Salton et al. (1975). The basic idea is that a document can be represented as a vector of words, with each dimension of the vector standing for one single word. Besides using explicit words from documents, latent variables derived from document mining can be used for document representation as well, such as the Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) approaches. The representation units are latent concepts or topics and the documents are projected to the semantic space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012). An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). </context>
</contexts>
<marker>Deerwester, Dumais, Furnas, Landauer, Harshman, 1990</marker>
<rawString>Deerwester, S., Dumais, S. T., Furnas, G. W., Landauer, T. K., &amp; Harshman, R. (1990). Indexing by latent semantic analysis. Journal of the American Society for information science, 41(6), 391-407.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Dikli</author>
</authors>
<title>An overview of automated scoring of essays.</title>
<date>2006</date>
<journal>The Journal of Technology, Learning and Assessment,</journal>
<volume>5</volume>
<issue>1</issue>
<contexts>
<context position="7151" citStr="Dikli, 2006" startWordPosition="1069" endWordPosition="1070">ce. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006). The exemplar system employing LSA representation is the Intelligent Essay Assessor system, which performs LSA on training essays and then projects essays to the vector space of latent concepts (Landauer et al., 2003). Besides representation approaches, content feature computing in essay scoring is useful to content scoring of speech because they share great similarity. Content features can be derived by computing cosine similarity between essay vectors, such as in e-rater (Attali &amp; Burstein, 2006) and Intelligent Essay Assessor (Landauer et al., 2003). The erater content feature computing is</context>
</contexts>
<marker>Dikli, 2006</marker>
<rawString>Dikli, S. (2006). An overview of automated scoring of essays. The Journal of Technology, Learning and Assessment, 5(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dodigovic</author>
</authors>
<date>2009</date>
<booktitle>Speech Processing Technology in Second Language Testing. Proceedings of the Conference on Language &amp; Technology</booktitle>
<contexts>
<context position="2038" citStr="Dodigovic, 2009" startWordPosition="292" endWordPosition="293">or efficiency and objectivity. Speaking, an important aspect for assessing second language speakers’ proficiency, is selected as the context of the study. The general goal is to investigate new approaches to automatic scoring of second language speech. When giving a speaking test in computermediated environment, test-takers’ responses are typically recorded as speech files. These files can be considered to contain two layers: sound and text. The sound is about the acoustic side of speech, whose features have been used to assess speaking proficiency in existing automated speechscoring systems (Dodigovic, 2009; Zechner et al., 2009). However, the text side, which is about the content of speech, is by far not well addressed in scoring systems, mainly due to the imperfect performance of automatic speech recognizer systems. As content is an integral part of speech, adding content features to existing scoring systems may further enhance system performance, and thus this study aims to examine the use of content features in speech scoring systems. In order to acquire speech content, speech files need to be transcribed to text files, by human or Automatic Speech Recognition (ASR). The resulted text files,</context>
</contexts>
<marker>Dodigovic, 2009</marker>
<rawString>Dodigovic, M. (2009). Speech Processing Technology in Second Language Testing. Proceedings of the Conference on Language &amp; Technology 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet: An electronic lexical database.</title>
<date>1998</date>
<publisher>The MIT press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="10040" citStr="Fellbaum, 1998" startWordPosition="1509" endWordPosition="1510"> the testing corpus but not the training corpus, then the importance of the term can be inferred from external knowledge such as ontologies. The semantic relations defined in ontologies connect relevant concepts and organize them into a tree (i.e. WordNet) or a graph structure (i.e. Wikipedia). Since paths usually exist between two individual concepts, ontologies can support inferences among concepts by using the paths and concept nodes between them. Moreover, semantic similarity between concepts, computed based on ontology knowledge, can be used to infer importance of unknown terms. WordNet (Fellbaum, 1998) and Wikipedia (Wikipedia, 2012) ontologies are two popular ontologies for computing semantic similarity. A number of similarity approaches have been proposed for similarity calculation according to the different characteristics of the two ontologies (Lin, 1998; Pedersen et al., 2004; Resnik, 1999; Strube &amp; Ponzetto, 2006). 43 Experiments are conducted to compare ontologybased representations (experimental systems) and common representations (baseline systems). Two ontology-based methods are employed as the experimental systems, one is about representing transcripts using ontology concepts (“O</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. (Ed.). (1998). WordNet: An electronic lexical database. Cambridge, MA: The MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gabrilovich</author>
<author>S Markovitch</author>
</authors>
<title>Computing semantic relatedness using wikipedia-based explicit semantic analysis.</title>
<date>2007</date>
<booktitle>Proceedings of the 20th International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="8792" citStr="Gabrilovich and Markovitch (2007)" startWordPosition="1315" endWordPosition="1318">tho and Bloehdorn along with other people conducted a series of studies in using the ontologies (i.e. WordNet) for text categorization and clustering tasks (Bloehdorn &amp; Hotho, 2004; Hotho et al., 2003a; Hotho et al., 2003b). The goals are to overcome several weaknesses, e.g. synonyms and generalization issues, of the bag-ofwords representation by using ontology concept based representation. Basically concepts from ontologies are used as units for text representation and then text processing is performed on top of the ontology-based representation. Explicit Semantic Approach (ESA), proposed by Gabrilovich and Markovitch (2007), is an approach to representing an arbitrary text snippet in vector of Wikipedia concepts for the convenience of further natural language processing. Each Wikipedia concept has text description, which is used to build an invert index to associate words with concepts. The invert index helps represent each word by vector of Wikipedia concepts, and eventually a document can be represented by weighted Wikipedia concepts by adding up the Wikipedia concept vectors of the words that the document contains. Ontologies can also help resolve the second challenge of statistical representation, the unknow</context>
<context position="22030" citStr="Gabrilovich and Markovitch, 2007" startWordPosition="3367" endWordPosition="3370">r dimensionality reduction purpose by tuning it on the training data. Using Wikipedia as another case for ontology, two more experimental approaches will be implemented, one for ontology-based representation and the other for ontology-based reasoning. ONTO-Wikipedia. Wikipedia concepts can be identified in transcripts in two ways: 1) directly find concepts in text window of 5 words; 2) convert a transcript in vectors of Wikipedia concepts using the Explicit Semantic Analysis method, which associates words to Wikipedia concepts and represents arbitrary text using the word-concept associations (Gabrilovich and Markovitch, 2007). OntoReason-Wikpedia. The concept similarity between Wikipedia concepts is obtained by computing the cosine similarity of the text description of the concepts. The reasoning method of the unknown concept follows the one mentioned in the OntoReason-WordNet approach. We will compute content features based on these new representations and evaluate the performance according to feature correlations. The current results examine effects of using the WordNet ontology on predicting speaking proficiency, and these new experiments will answer whether the other type of ontology, Wikipedia, has positive e</context>
</contexts>
<marker>Gabrilovich, Markovitch, 2007</marker>
<rawString>Gabrilovich, E., &amp; Markovitch, S. (2007). Computing semantic relatedness using wikipedia-based explicit semantic analysis. Proceedings of the 20th International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X He</author>
<author>D Cai</author>
<author>H Liu</author>
<author>W Y Ma</author>
</authors>
<title>Locality preserving indexing for document representation.</title>
<date>2004</date>
<booktitle>Proceedings of the 27th Annual International ACM SIGIR Conference.</booktitle>
<contexts>
<context position="3435" citStr="He et al. (2004)" startWordPosition="508" endWordPosition="511"> for computing content features and building speech scoring models. Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech. Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges: 1) meaningfulness of represent</context>
</contexts>
<marker>He, Cai, Liu, Ma, 2004</marker>
<rawString>He, X., Cai, D., Liu, H., &amp; Ma, W. Y. (2004). Locality preserving indexing for document representation. Proceedings of the 27th Annual International ACM SIGIR Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hotho</author>
<author>S Staab</author>
<author>G Stumme</author>
</authors>
<title>Ontologies improve text document clustering.</title>
<date>2003</date>
<booktitle>Proceedings of the Third IEEE International Conference on Data Mining (ICDM’03).</booktitle>
<contexts>
<context position="3479" citStr="Hotho et al. (2003" startWordPosition="516" endWordPosition="519">ng speech scoring models. Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech. Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges: 1) meaningfulness of representation units. For example, synonymous words r</context>
<context position="8359" citStr="Hotho et al., 2003" startWordPosition="1254" endWordPosition="1257">mputing is adopted in this study to compute content features of speech transcripts. As mentioned in section 1, ontologies can be used to complement the challenges of statistical 42 representation approaches. Ontology concepts have 3 Methodology been successfully used in text processing tasks such as text classification and clustering and can help resolve the first challenge, meaningfulness of the representation. Hotho and Bloehdorn along with other people conducted a series of studies in using the ontologies (i.e. WordNet) for text categorization and clustering tasks (Bloehdorn &amp; Hotho, 2004; Hotho et al., 2003a; Hotho et al., 2003b). The goals are to overcome several weaknesses, e.g. synonyms and generalization issues, of the bag-ofwords representation by using ontology concept based representation. Basically concepts from ontologies are used as units for text representation and then text processing is performed on top of the ontology-based representation. Explicit Semantic Approach (ESA), proposed by Gabrilovich and Markovitch (2007), is an approach to representing an arbitrary text snippet in vector of Wikipedia concepts for the convenience of further natural language processing. Each Wikipedia c</context>
</contexts>
<marker>Hotho, Staab, Stumme, 2003</marker>
<rawString>Hotho, A., Staab, S., &amp; Stumme, G. (2003a). Ontologies improve text document clustering. Proceedings of the Third IEEE International Conference on Data Mining (ICDM’03).</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Hotho</author>
<author>S Staab</author>
<author>G Stumme</author>
</authors>
<title>Text clustering based on background knowledge (Technical report, no.425.): Institute of Applied Informatics and Formal Description Methods AIFB,</title>
<date>2003</date>
<institution>University of Karlsruche.</institution>
<contexts>
<context position="3479" citStr="Hotho et al. (2003" startWordPosition="516" endWordPosition="519">ng speech scoring models. Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech. Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges: 1) meaningfulness of representation units. For example, synonymous words r</context>
<context position="8359" citStr="Hotho et al., 2003" startWordPosition="1254" endWordPosition="1257">mputing is adopted in this study to compute content features of speech transcripts. As mentioned in section 1, ontologies can be used to complement the challenges of statistical 42 representation approaches. Ontology concepts have 3 Methodology been successfully used in text processing tasks such as text classification and clustering and can help resolve the first challenge, meaningfulness of the representation. Hotho and Bloehdorn along with other people conducted a series of studies in using the ontologies (i.e. WordNet) for text categorization and clustering tasks (Bloehdorn &amp; Hotho, 2004; Hotho et al., 2003a; Hotho et al., 2003b). The goals are to overcome several weaknesses, e.g. synonyms and generalization issues, of the bag-ofwords representation by using ontology concept based representation. Basically concepts from ontologies are used as units for text representation and then text processing is performed on top of the ontology-based representation. Explicit Semantic Approach (ESA), proposed by Gabrilovich and Markovitch (2007), is an approach to representing an arbitrary text snippet in vector of Wikipedia concepts for the convenience of further natural language processing. Each Wikipedia c</context>
</contexts>
<marker>Hotho, Staab, Stumme, 2003</marker>
<rawString>Hotho, A., Staab, S., &amp; Stumme, G. (2003b). Text clustering based on background knowledge (Technical report, no.425.): Institute of Applied Informatics and Formal Description Methods AIFB, University of Karlsruche.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kaski</author>
</authors>
<title>Computationally efficient approximation of a probabilistic model for document representation in the WEBSOM full-text analysis method. Neural processing letters,</title>
<date>1997</date>
<volume>5</volume>
<issue>2</issue>
<pages>69--81</pages>
<contexts>
<context position="3417" citStr="Kaski (1997)" startWordPosition="506" endWordPosition="507"> pre-requisite for computing content features and building speech scoring models. Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech. Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges: 1) meaningfu</context>
<context position="6671" citStr="Kaski 1997" startWordPosition="994" endWordPosition="995">n be used for document representation as well, such as the Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) approaches. The representation units are latent concepts or topics and the documents are projected to the semantic space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012). An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006). The exemplar system employing LSA representation is the Intelligent Essay Assessor system, which performs LSA on train</context>
</contexts>
<marker>Kaski, 1997</marker>
<rawString>Kaski, S. (1997). Computationally efficient approximation of a probabilistic model for document representation in the WEBSOM full-text analysis method. Neural processing letters, 5(2), 69-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kaski</author>
<author>T Honkela</author>
<author>K Lagus</author>
<author>T Kohonen</author>
</authors>
<title>WEBSOM-Self-organizing maps of document collections1.</title>
<date>1998</date>
<journal>Neurocomputing,</journal>
<volume>21</volume>
<issue>1</issue>
<pages>101--117</pages>
<contexts>
<context position="6692" citStr="Kaski, et al. 1998" startWordPosition="996" endWordPosition="999">r document representation as well, such as the Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) approaches. The representation units are latent concepts or topics and the documents are projected to the semantic space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012). An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006). The exemplar system employing LSA representation is the Intelligent Essay Assessor system, which performs LSA on training essays and then p</context>
</contexts>
<marker>Kaski, Honkela, Lagus, Kohonen, 1998</marker>
<rawString>Kaski, S., Honkela, T., Lagus, K., &amp; Kohonen, T. (1998). WEBSOM-Self-organizing maps of document collections1. Neurocomputing, 21(1-3), 101-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>D Laham</author>
<author>P W Foltz</author>
</authors>
<title>Automated scoring and annotation of essays with the Intelligent Essay Assessor. In</title>
<date>2003</date>
<publisher>Inc.</publisher>
<contexts>
<context position="7369" citStr="Landauer et al., 2003" startWordPosition="1102" endWordPosition="1105"> are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006). The exemplar system employing LSA representation is the Intelligent Essay Assessor system, which performs LSA on training essays and then projects essays to the vector space of latent concepts (Landauer et al., 2003). Besides representation approaches, content feature computing in essay scoring is useful to content scoring of speech because they share great similarity. Content features can be derived by computing cosine similarity between essay vectors, such as in e-rater (Attali &amp; Burstein, 2006) and Intelligent Essay Assessor (Landauer et al., 2003). The erater content feature computing is adopted in this study to compute content features of speech transcripts. As mentioned in section 1, ontologies can be used to complement the challenges of statistical 42 representation approaches. Ontology concepts ha</context>
</contexts>
<marker>Landauer, Laham, Foltz, 2003</marker>
<rawString>Landauer, T. K., Laham, D., &amp; Foltz, P. W. (2003). Automated scoring and annotation of essays with the Intelligent Essay Assessor. In M. D. Shermis, Burstein, J.C. (Ed.), Automated essay scoring: A crossdisciplinary perspective (pp. 87–112). Mahwah, NJ: Lawrence Erlbaum Associates, Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Larkey</author>
<author>W B Croft</author>
</authors>
<title>A Text Categorization Approach to Automated Essay Grading. In</title>
<date>2003</date>
<contexts>
<context position="3785" citStr="Larkey &amp; Croft (2003)" startWordPosition="563" endWordPosition="566">nscripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges: 1) meaningfulness of representation units. For example, synonymous words represent similar meaning and thus should be grouped as one representation unit. 2) unknown terms. Since words or latent variables in the vector are from training corpus, if an unknown term occurs in the testing corpus then it is difficult to determine the importance of the term in the training corpus beca</context>
<context position="6979" citStr="Larkey &amp; Croft (2003)" startWordPosition="1042" endWordPosition="1045">Deerwester et al., 1990; Blei, 2012). An important purpose of using the latent variables is to reduce dimensions in document representation and place documents in a more compact space. Some other dimension reduction techniques include Subspace-based methods (Chen et al., 2003) and Self Organizing Map (Kaski 1997; Kaski, et al. 1998). In the area of automatic essay scoring, essay content are represented to facilitate the scoring. The BOW approach is widely used in essay representation as well, including the e-rater system (Burstein, 2003; Attali &amp; Burstein, 2006) and the experimental system in Larkey &amp; Croft (2003). Representation in the BETSY system (Bayesian Essay Test Scoring System) also involves words, such as frequency of content words, along with specific phrases (Dikli, 2006). The exemplar system employing LSA representation is the Intelligent Essay Assessor system, which performs LSA on training essays and then projects essays to the vector space of latent concepts (Landauer et al., 2003). Besides representation approaches, content feature computing in essay scoring is useful to content scoring of speech because they share great similarity. Content features can be derived by computing cosine si</context>
</contexts>
<marker>Larkey, Croft, 2003</marker>
<rawString>Larkey, L. S., &amp; Croft, W. B. (2003). A Text Categorization Approach to Automated Essay Grading. In M. D. Shermis &amp; J. C. Burstein (Eds.), Automated Essay Scoring: A Cross-discipline Perspective: Mahwah, NJ, Lawrence Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D D Lewis</author>
</authors>
<title>Representation and learning in information retrieval. (Doctoral dissertation).</title>
<date>1992</date>
<institution>University of Massachusetts.</institution>
<contexts>
<context position="3403" citStr="Lewis (1992)" startWordPosition="504" endWordPosition="505">ause it is the pre-requisite for computing content features and building speech scoring models. Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech. Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing document representation approaches are primarily statistical and corpus based, using words or latent variables mined from corpus as representation units in the vector. These approaches exhibit two challenges</context>
</contexts>
<marker>Lewis, 1992</marker>
<rawString>Lewis, D. D. (1992). Representation and learning in information retrieval. (Doctoral dissertation). University of Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Pedersen</author>
<author>S Patwardhan</author>
<author>J Michelizzi</author>
</authors>
<title>WordNet:: Similarity: measuring the relatedness of concepts.</title>
<date>2004</date>
<booktitle>Proceedings of the Fifth Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-04).</booktitle>
<contexts>
<context position="10324" citStr="Pedersen et al., 2004" startWordPosition="1548" endWordPosition="1551">(i.e. Wikipedia). Since paths usually exist between two individual concepts, ontologies can support inferences among concepts by using the paths and concept nodes between them. Moreover, semantic similarity between concepts, computed based on ontology knowledge, can be used to infer importance of unknown terms. WordNet (Fellbaum, 1998) and Wikipedia (Wikipedia, 2012) ontologies are two popular ontologies for computing semantic similarity. A number of similarity approaches have been proposed for similarity calculation according to the different characteristics of the two ontologies (Lin, 1998; Pedersen et al., 2004; Resnik, 1999; Strube &amp; Ponzetto, 2006). 43 Experiments are conducted to compare ontologybased representations (experimental systems) and common representations (baseline systems). Two ontology-based methods are employed as the experimental systems, one is about representing transcripts using ontology concepts (“ONTO”), and the other is about inferring weights of unknown terms using ontologies (“OntoReason”). For the baseline, we identify the BOW representation as a common text representation and use it in the baseline system. 3.1 Data Set The data set comes from an English proficiency test f</context>
<context position="15754" citStr="Pedersen et al., 2004" startWordPosition="2415" endWordPosition="2418"> and words in the vector. 3.2.3 Ontology-based Reasoning (experimental) OntoReason-WordNet approach. This approach is also implemented by using WordNet. First, transcripts are represented by ontology concepts as in section 3.2.2. Then given an unknown concept in test transcripts, we identify its semantically similar concepts (N=5) in the training transcripts and then reason the weight of the unknown concept based on the weights of these similar concepts. The reasoning makes use of semantic similarity between WordNet synsets. Concept similarity is computed using the edge-based path similarity (Pedersen et al., 2004). We select N=5 concepts from the training transcripts that are most similar to the unknown concept, and compute the weight of the unknown concept in the training transcripts by averaging the weights of the 5 similar concepts. 3.3 Content Feature Computation The baseline and experimental systems all generate vector representations for speech transcripts. The content features are computed based on vector representation, and all representation approaches employ the same method of computing content features. We choose to use the two content features of the e-rater system, “max.cos” and “cos.w4”, </context>
</contexts>
<marker>Pedersen, Patwardhan, Michelizzi, 2004</marker>
<rawString>Pedersen, T., Patwardhan, S., &amp; Michelizzi, J. (2004). WordNet:: Similarity: measuring the relatedness of concepts. Proceedings of the Fifth Annual Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL-04).</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language.</title>
<date>1999</date>
<journal>Journal of Artificial Intelligence,</journal>
<volume>11</volume>
<issue>1999</issue>
<pages>95--130</pages>
<contexts>
<context position="10338" citStr="Resnik, 1999" startWordPosition="1552" endWordPosition="1553"> paths usually exist between two individual concepts, ontologies can support inferences among concepts by using the paths and concept nodes between them. Moreover, semantic similarity between concepts, computed based on ontology knowledge, can be used to infer importance of unknown terms. WordNet (Fellbaum, 1998) and Wikipedia (Wikipedia, 2012) ontologies are two popular ontologies for computing semantic similarity. A number of similarity approaches have been proposed for similarity calculation according to the different characteristics of the two ontologies (Lin, 1998; Pedersen et al., 2004; Resnik, 1999; Strube &amp; Ponzetto, 2006). 43 Experiments are conducted to compare ontologybased representations (experimental systems) and common representations (baseline systems). Two ontology-based methods are employed as the experimental systems, one is about representing transcripts using ontology concepts (“ONTO”), and the other is about inferring weights of unknown terms using ontologies (“OntoReason”). For the baseline, we identify the BOW representation as a common text representation and use it in the baseline system. 3.1 Data Set The data set comes from an English proficiency test for non-native </context>
</contexts>
<marker>Resnik, 1999</marker>
<rawString>Resnik, P. (1999). Semantic similarity in a taxonomy: An information-based measure and its application to problems of ambiguity in natural language. Journal of Artificial Intelligence, 11(1999), 95-130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>A Wong</author>
<author>C S Yang</author>
</authors>
<title>A vector space model for automatic indexing.</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<issue>11</issue>
<pages>613--620</pages>
<contexts>
<context position="3202" citStr="Salton et al. (1975)" startWordPosition="474" endWordPosition="477">matic Speech Recognition (ASR). The resulted text files, namely, speech transcripts, are to be processed to extract content features. Moreover, representation of text content (e.g. in vectors) is important because it is the pre-requisite for computing content features and building speech scoring models. Therefore this study focuses on representing content of speech transcripts to facilitate automatic scoring of speech. Speech transcripts can be seen as a special type of text documents, and therefore document representation approaches shed light on representation of speech transcripts, such as Salton et al. (1975), 41 Proceedings of the NAACL HLT 2012 Student Research Workshop, pages 41–47, Montr´eal, Canada, June 3-8, 2012. c�2012 Association for Computational Linguistics Deerwester et al. (1990), Lewis (1992), Kaski (1997), He et al. (2004), Arguello et al. (2008), Hotho et al. (2003a). On the other hand, written essays, the output of writing section of second language test, share great similarity with speech transcripts, and representation of essays also has implications on speech transcript representation, such as Burstein (2003), Attali &amp; Burstein (2006), and Larkey &amp; Croft (2003). Existing docume</context>
<context position="5827" citStr="Salton et al. (1975)" startWordPosition="859" endWordPosition="862">, and comparing performance of content features in predicting speaking proficiency. 2 Related Work This section reviews work related to representation of speech transcripts, including document representation, essay scoring, and ontology-based representation in text processing. Document representation has been an important topic in research areas such as natural language processing, information retrieval, and text mining, in which a number of representation approaches have been proposed. The most common practice of text document representation is the Bag-Of-Words (BOW) approach, illustrated in Salton et al. (1975). The basic idea is that a document can be represented as a vector of words, with each dimension of the vector standing for one single word. Besides using explicit words from documents, latent variables derived from document mining can be used for document representation as well, such as the Latent Semantic Analysis (LSA) and Latent Dirichlet Allocation (LDA) approaches. The representation units are latent concepts or topics and the documents are projected to the semantic space constructed from the latent concepts or topics (Deerwester et al., 1990; Blei, 2012). An important purpose of using t</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>Salton, G., Wong, A., &amp; Yang, C. S. (1975). A vector space model for automatic indexing. Communications of the ACM, 18(11), 613-620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Strube</author>
<author>S P Ponzetto</author>
</authors>
<title>WikiRelated! Computing semantic relatedness using Wikipedia.</title>
<date>2006</date>
<booktitle>Proceedings of the American Association for Artificial Intelligence</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="10364" citStr="Strube &amp; Ponzetto, 2006" startWordPosition="1554" endWordPosition="1557"> exist between two individual concepts, ontologies can support inferences among concepts by using the paths and concept nodes between them. Moreover, semantic similarity between concepts, computed based on ontology knowledge, can be used to infer importance of unknown terms. WordNet (Fellbaum, 1998) and Wikipedia (Wikipedia, 2012) ontologies are two popular ontologies for computing semantic similarity. A number of similarity approaches have been proposed for similarity calculation according to the different characteristics of the two ontologies (Lin, 1998; Pedersen et al., 2004; Resnik, 1999; Strube &amp; Ponzetto, 2006). 43 Experiments are conducted to compare ontologybased representations (experimental systems) and common representations (baseline systems). Two ontology-based methods are employed as the experimental systems, one is about representing transcripts using ontology concepts (“ONTO”), and the other is about inferring weights of unknown terms using ontologies (“OntoReason”). For the baseline, we identify the BOW representation as a common text representation and use it in the baseline system. 3.1 Data Set The data set comes from an English proficiency test for non-native speakers. For the speaking</context>
</contexts>
<marker>Strube, Ponzetto, 2006</marker>
<rawString>Strube, M., &amp; Ponzetto, S. P. (2006). WikiRelated! Computing semantic relatedness using Wikipedia. Proceedings of the American Association for Artificial Intelligence 2006, Boston, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wikipedia</author>
</authors>
<title>The free encyclopedia.</title>
<date>2012</date>
<journal>Inc. Retrieved Apr</journal>
<volume>1</volume>
<note>from http://www.wikipedia.org</note>
<contexts>
<context position="10072" citStr="Wikipedia, 2012" startWordPosition="1513" endWordPosition="1514"> training corpus, then the importance of the term can be inferred from external knowledge such as ontologies. The semantic relations defined in ontologies connect relevant concepts and organize them into a tree (i.e. WordNet) or a graph structure (i.e. Wikipedia). Since paths usually exist between two individual concepts, ontologies can support inferences among concepts by using the paths and concept nodes between them. Moreover, semantic similarity between concepts, computed based on ontology knowledge, can be used to infer importance of unknown terms. WordNet (Fellbaum, 1998) and Wikipedia (Wikipedia, 2012) ontologies are two popular ontologies for computing semantic similarity. A number of similarity approaches have been proposed for similarity calculation according to the different characteristics of the two ontologies (Lin, 1998; Pedersen et al., 2004; Resnik, 1999; Strube &amp; Ponzetto, 2006). 43 Experiments are conducted to compare ontologybased representations (experimental systems) and common representations (baseline systems). Two ontology-based methods are employed as the experimental systems, one is about representing transcripts using ontology concepts (“ONTO”), and the other is about in</context>
</contexts>
<marker>Wikipedia, 2012</marker>
<rawString>Wikipedia: The free encyclopedia. (2012, Apr 1). FL: Wikimedia Foundation, Inc. Retrieved Apr 1, 2012, from http://www.wikipedia.org</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Zechner</author>
<author>D Higgins</author>
<author>X Xi</author>
<author>D M Williamson</author>
</authors>
<title>Automatic scoring of non-native spontaneous speech in tests of spoken English.</title>
<date>2009</date>
<journal>Speech Communication,</journal>
<volume>51</volume>
<issue>10</issue>
<pages>883--895</pages>
<contexts>
<context position="2061" citStr="Zechner et al., 2009" startWordPosition="294" endWordPosition="297"> objectivity. Speaking, an important aspect for assessing second language speakers’ proficiency, is selected as the context of the study. The general goal is to investigate new approaches to automatic scoring of second language speech. When giving a speaking test in computermediated environment, test-takers’ responses are typically recorded as speech files. These files can be considered to contain two layers: sound and text. The sound is about the acoustic side of speech, whose features have been used to assess speaking proficiency in existing automated speechscoring systems (Dodigovic, 2009; Zechner et al., 2009). However, the text side, which is about the content of speech, is by far not well addressed in scoring systems, mainly due to the imperfect performance of automatic speech recognizer systems. As content is an integral part of speech, adding content features to existing scoring systems may further enhance system performance, and thus this study aims to examine the use of content features in speech scoring systems. In order to acquire speech content, speech files need to be transcribed to text files, by human or Automatic Speech Recognition (ASR). The resulted text files, namely, speech transcr</context>
</contexts>
<marker>Zechner, Higgins, Xi, Williamson, 2009</marker>
<rawString>Zechner, K., Higgins, D., Xi, X., &amp; Williamson, D. M. (2009). Automatic scoring of non-native spontaneous speech in tests of spoken English. Speech Communication, 51(10), 883-895.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>