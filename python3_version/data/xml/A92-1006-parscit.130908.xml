<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000022">
<title confidence="0.975605">
Applied Text Generation*
</title>
<author confidence="0.997664">
Owen Rambow Tanya Korelsky
</author>
<affiliation confidence="0.999634">
University of Pennsylvania CoGenTex, Inc.
</affiliation>
<address confidence="0.970367">
Department.of CIS 105 Lenox Road
Philadelphia, PA 19104 Ithaca, NY 14850
</address>
<email confidence="0.971118">
rambowelinc.cis.upenn.edu tanyaecogentex.com
</email>
<sectionHeader confidence="0.999767" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999988714285714">
This paper presents the Joyce system as an example of a
fully-implemented, application-oriented text generation
system. Joyce covers the whole range of tasks associated
with text generation, from content selection to morpho-
logical processing. It was developped as part of the in-
terface of the software design environment Ulysses. The
following design goals were set for it:
</bodyText>
<listItem confidence="0.9897211">
• The generated text must be of sufficiently high qual-
ity so that the user community of the underlying
application accepts it as part of the documentation
of software designs.
• The generation must be fast enough so that the sys-
tem can be used as a tool during the design process.
• The system must be adaptable to new needs as they
arise during further development of the underlying
system, and it must be portable to completely new
applications.
</listItem>
<bodyText confidence="0.999706388888889">
While we were able to exploit existing research for
many of the design issues, it turned out that we needed
to develop our own approach to text planning (Ra.mbow
1990).
This paper will present the system and attempt to
show how these design objectives led to particular design
decisions. The structure of the paper is as follows. In
Section 2, we will present the underlying application and
give examples of the output of the System. In Section
3, we will discuss the overall structure of Joyce. We
then discuss the three main components in turn: the text
planner in Section 4, the sentence planner in Section 5
and the realizer in Section 6. We will discuss the text
planner in some detail since it represents a new approach
to the problem. Section 7 traces the generation of a short
text. In Section 8, we address the problem of portability,
and wind up by discussing some shortcomings of Joyce
in the conclusion.
</bodyText>
<listItem confidence="0.93577225">
• Research on the original Joyce system (described in this
paper) was supported by the AFSC at Rome Laboratory un-
der grant no. F30602-85-C-0098 to Odyssey Research As-
sociates. A successor system to Joyce has been under de-
velopment at CoGenTex since early 1991. We would like to
thank Richard Kittredge, Robert Rubinoff and two anony-
mous reviewers for helpful comments on earlier versions of
this paper.
</listItem>
<sectionHeader confidence="0.957307" genericHeader="keywords">
2 The Joyce System in the Ulysses
User Interface
</sectionHeader>
<bodyText confidence="0.999102769230769">
The Joyce text generation system was developped
part of the software design environment Ulysses (Ko-
relsky and Ulysses Staff 1988; Rosenthal et al 1988)
Ulysses includes a graphical environment for the de-
sign of secure, distributed software systems. The use]
manipulates icons that symbolize components (boxes)
data ports of components (circles) and data flow be-
tween ports (arrows). Additional information, princi
pally about the security level of the components an
ports, is entered through menus. The design proceed:
hierarchically by top-down structural decomposition.
As a tool in the user interface, Joyce generates twc
different types of texts about software designs:
</bodyText>
<listItem confidence="0.821626076923077">
• It generates annotations of the design which are in
tended to serve as part of the system documentatior
during and after the design process. A short and
long version of these texts are available. The lom
version can be several paragraphs long. The text:
usefully complement the graphical representation:
since the graphical representation can show only ono
level in the structural decomposition, and since tho
additional information that is available about eacl
component (in particular, security level) cannot bi
displayed graphically.
• It is used to explain the result of the application o
a heuristic security design tool, the &amp;quot;flow analyzer&amp;quot;
</listItem>
<bodyText confidence="0.9997828125">
The texts Joyce generates are specifically conceived o
as written texts. The text output is integrated into th
graphical environment in such a way that much of th
same interactive functionality is available either throng]
the text output window or through the graphical inter
face window. For example, if a designer reads the desig]
annotation generated by Joyce and notices that the secu
rity level of a component has been entered wrong, the]
the error can be corrected by clicking at the name of th
component in the text window and accessing the appro
priate menu.
As an example of the output of Joyce, consider the tex
in Figure 2. It is an annotation of the component &amp;quot;Host&amp;quot;
The top level decomposition of this component is show]
in Figure 1. The text annotates the software design b
describing its structure and interpreting it in terms c
</bodyText>
<page confidence="0.991687">
40
</page>
<figure confidence="0.998695777777778">
Ulysses Graphics Interface -- HOST
•••--•
q114:1P Hornet Net Handler
• •
• 5—.11
f•—,—,„ •••---•
Ulysses Graphics Interface -- BLACK BOX
Inputter Merger
P6
111—. •
P34
•
•
Decrementor
Incrementor
•
Forniater
•
</figure>
<figureCaption confidence="0.999995">
Figure 1: The HOST Graphical Representation
</figureCaption>
<bodyText confidence="0.998891076923077">
its security characteristics. The text in Figure 4 is gen-
erated by Joyce in order to report the results of the flow
analyzer; the graphical representation of the underlying
system can be seen in Figure 3. Note that the structures
of the two texts are quite different: while the Host text
is structured according to more abstract categories such
as design structure and functionality, the Black Box text
follows the path of the insecure flow through the compo-
nent.
Joyce has been fully implemented in Common Lisp,
and runs on the Symbolics Lisp Machine and on Sun
workstations. A successor version has been ported to
the Apple MacIntosh.
</bodyText>
<subsectionHeader confidence="0.7878365">
HOST: General Structure and Security Fea-
tures
</subsectionHeader>
<bodyText confidence="0.997646045454545">
The multilevel Host is a complex component of the
Station. It contains a Kernel, a TIP, a Process, a
Net Handler and a group of Managers. The Pro-
cess, the TIP, the Managers and the Net Handler
communicate only through the Kernel. The man-
ifestly secure Process and the Managers perform
auxiliary functions. The Process is low-level. The
TIP serves as interface to a User; the Net Handler
handles communication with a Net. The security
statuses of the TIP, the Managers and the Net Han-
dler have not yet been specified.
The Kernel is a complex component. Its secu-
rity status has not yet been specified. The Ker-
nel contains a Message Switch, an Address Register
and a Locator. The Address Register, the Locator
and the Message Switch communicate directly with
each other. The low-level Address Register and the
multilevel Locator are data-bases. The Message
Switch handles communication with the TIP, the
Process, the Managers and the Net Handler. The
security status of the Message Switch has not yet
been specified.
</bodyText>
<figureCaption confidence="0.988076333333333">
Figure 2: The HOST Text
Figure 3: The BLACK BOX Graphical Representation
BLACK BOX: INSECURE FLOW
</figureCaption>
<bodyText confidence="0.785315444444444">
In the Black Box an insecure flow occurs. Classified
information enters the Black Box through P6. It is
passed through the Inputter to the Merger, which
may upgrade it to top-secret. The Merger passes
it to the Analyzer, which has been assumed secure.
The Analyzer downgrades it to secret. It passes
it through the Incrementor to the Formater, which
downgrades it when a classified corrected reading
leaves through P34.
</bodyText>
<figureCaption confidence="0.995054">
Figure 4: The BLACK BOX Text
</figureCaption>
<sectionHeader confidence="0.930841" genericHeader="method">
3 The Structure of Joyce
</sectionHeader>
<bodyText confidence="0.998017666666667">
Joyce consists of three separate modules, which perform
distinct tasks and access their own knowledge bases (Fig-
ure 5).
</bodyText>
<listItem confidence="0.981380272727273">
1. The text planner accesses the domain representation
and produces a list of propositions, which represents
both the content and the structure of the intended
text. Each proposition is expressed in a language-
independent, conceptual frame-like formalism. It
encodes a minimal amount of information, but can
be realized as an independent sentence if neces-
sary. The text planner draws on domain communi-
cation knowledge expressed in a high-level schema
language (see Section 4).
2. The sentence planner takes the list of propositions
and determines how to express them in natural lan-
guage. This task includes choosing lexicalizations
and a syntactic structure for each proposition, and
assembling these lexico-syntactic structures, called
Deep Syntactic Representation or DSyntR, into
larger sentences. It draws on knowledge captured
in the conceptual/English dictionary.
3. The linguistic realizer takes the syntactic structures
and produces surface sentences. It draws on syntac-
tic and morphological knowledge, expressed in the
English lexicon.
</listItem>
<bodyText confidence="0.9933085">
Usually, the different tasks of text generation are di-
vided among two modules (planning and realization),
</bodyText>
<page confidence="0.998906">
41
</page>
<bodyText confidence="0.981079753424658">
rather than three. However, there is a certain amount
of disagreement about where the line between the two
is to be drawn. For example, McKeown&apos;s TEXT (McK-
eown 1985) performs the tasks that Joyce classifies as
sentence planning as part of the realization process,
whereas Meteer&apos;s SPOKESMAN (Meteer 1989) clas-
sifies them as part of text planning. (See (Meteer
1990, p.23sq) for a useful summary of the terminolog-
ical issues&apos;.) In this paper, &amp;quot;text planning&amp;quot; will always
be used in the narrow sense of &amp;quot;content selection and
organization&amp;quot;. The architecture of Joyce is directly in-
fluenced by that of the SEMSYN system (Rosner 1987;
Wisner 1988). Rosner divides the realization component
into two parts, the &amp;quot;generator kernel&amp;quot; and the &amp;quot;generator
front end&amp;quot;. This distinction is mirrored exactly by the
distinction between sentence planning and realization in
Joyce.
There are two main advantages to such a tripartite ar-
chitecture, one conceptual and the other practical. Con-
ceptually, the advantage is that linguistic planning tasks
are clearly separated from the actual grammar, which
comprises word order and morphological rules. These
rules can be stated independently of the formulation of
purely semantic rules that determine lexical and syn-
tactic choices. This modularity makes the system more
maintainable. The linguistic planning tasks should, how-
ever, be clearly separated from the textual planning
tasks: while the linguistic planning tasks are language-
dependent, the textual planning tasks appear not to be2.
1Note that the tasks Meteer groups together as &amp;quot;Syntax&amp;quot;
- choosing the syntactic structure and linearization - are in-
separable only in certain syntactic representations. In Joyce,
the Deep-Syntactic Representation encodes syntactic struc-
ture but not linear order (see Section 6 for details).
2We are not aware of any example in which different text
plans (as defined here) are needed for different languages.
The fact that functionally similar texts may display different
structures in different cultures should not be confused with
language-specific constraints on text structure.
Thus, if multi-lingual generation is desired, text planning
and sentence planning ought to be performed by distinct
components.
On a more practical level, modularity in design and
implementation can be exploited by parallel process-
ing of independent modules. While the current im-
plementations of Joyce do not allow for parallel exe-
cution, the incremental processing of parallel comput-
ing tasks on a serial machine is also advantageous, as
is argued in the WIP project (Wahlster et al 1991;
Harbusch et al 1991)3. Incrementality reduces the ini-
tial response time of the system (though not the overall
processing time). This can be crucial if multi-paragraph
text is to be generated by an interface tool. In the Joyce
system, the text planner cedes control to the sentence
planner as soon as the text planner has defined a propo-
sition. Once the sentence planner has constructed the
DSyntR of a complete sentence, it sends it to the re-
alizer which generates the English sentence. Thus, the
first sentence is output by Joyce shortly after the text
generator is invoked; text continues to be output approx-
imately at reading speed. The effect is that a user of the
text generator has the impression that he or she never
has to wait for the system to respond, even when it is
generating lengthy texts.
Throughout the system, processing is message-driven
in the sense of (McDonald et al 1987): control lies in the
input, which is used to construct the next level of repre-
sentation. There is no need for backtracking or feedback
from one level of processing to an earlier one. As is
argued by McDonald et al., such an architecture con-
tributes to processing efficiency.
We will now discuss the three modules of Joyce in
more detail.
</bodyText>
<sectionHeader confidence="0.985284" genericHeader="method">
4 The Text Planner
</sectionHeader>
<bodyText confidence="0.999640791666667">
Prior to the design of the text planning component of
Joyce, several existing approaches were studied. Since
the structure of the descriptive text (Figure 2) does
not mirror the structure of the domain, Paris&apos;s &amp;quot;pro-
cedural strategy&amp;quot; (Paris and McKeown 1987) cannot be
used in general. Hovy&apos;s RST-based planner (Hovy 1988)
assumes that content selection has already been per-
formed, contrary to the situation in the Ulysses applica-
tion; furthermore, there are efficiency problems in a pure
STRIPS-like planning paradigm. We therefore found
McKeown&apos;s schema-based approach (McKeown 1985) to
be the most promising. However, it turned out that gen-
eral rhetorical schemas cannot adequately capture the
structure of the intended texts. In (Kittredge et al 1991),
we argue that planning certain types of texts - such as re-
ports and descriptions - requires domain-specific knowl-
edge about how to communicate in that domain. That
knowledge we call &amp;quot;domain communication knowledge&amp;quot;
(DCK). For example, in describing secure system designs
3Incrementality within the realizer has little practical
benefit when the realizer is reasonably fast; its study is
mainly motivated by psycholinguistic considerations. There-
fore, there was no attempt in Joyce to make the realizer
incremental.
</bodyText>
<figure confidence="0.9990306">
Sentence Planner
Deep-Syntactic
Representation
English
Text
</figure>
<figureCaption confidence="0.996121">
Figure 5: The Structure of Joyce
</figureCaption>
<figure confidence="0.7661885">
Domain
Repreaentation
</figure>
<page confidence="0.995778">
42
</page>
<bodyText confidence="0.999968666666667">
you must relate the security level of each component,
but not, say, the number of ports or their security levels.
Furthermore, the connectivity of components should be
stated before their functionality. In the flow analyzer
text, the security levels of the components need not be
communicated at all, but if a component (other than the
final component of the path) downgrades information, it
must be stated whether and why the component is se-
cure. This very precise knowledge about which domain
information needs to communicated and in what order
cannot simply be derived from general principles. We
have also argued that in many existing text planning
systems, such DCK has been encoded implicitly. In the
interest of efficiency, modularity and portability we have
decided to represent DCK explicitly in Joyce.
We have developed a &amp;quot;schema language&amp;quot; for easy rep-
resentation of DCK, called DICKENS (DomaIn Commu-
nication Knowledge ENcoding Schemas). The schemas
are similar in form to those used by McKeown. Basically,
schemas can be seen as a description of text structure.
The system, however, interprets each schema as a list
of instructions. The instructions can be calls to other
schemas, recursive calls to the same schema, or they
can be one of a set of special commands provided by
the schema language. One special command produces a
specific proposition and sends it to the sentence planner.
Other special commands support conditional branching
and iteration. During execution, each schema is associ-
ated with a particular subset of the domain representa-
tion, which is called the focus (in the sense of McKeown&apos;s
&amp;quot;global focus&amp;quot;). In the Ulysses application, the focus
always corresponds to one component. There are spe-
cial commands to shift the focus. In addition to the fo-
cus, which limits the domain representation from which
information can be communicated, a theme can be set
which determines information structure within individ-
ual propositions. The theme corresponds to McKeown&apos;s
&amp;quot;local focus&amp;quot;. As has been widely recognized, thematic
structure affects issues such as grammatical voice at the
linguistic level.
In addition, two further special commands were found
to be necessary in order to perform text planning:
</bodyText>
<listItem confidence="0.539473105263158">
• A portion of the text plan can be edited. To do this,
a schema is called, but any propositions that are cre-
ated (by the schema or by any schema it calls) are
not sent to the sentence planner. They are kept on
a separate list in the order they are created. When
the execution of the schema terminates, an editing
function is applied to the list. The editing function
can delete propositions, change their order, change
their contents or create new ones. The choice of an
editing function depends on the domain and on the
particular requirements of the text. Further study is
needed in order to determine the types of editing op-
erations that can be made and to devise a high-level
language to express them; the goal is to eventually
establish a library of editing operations. Typical
editing operations we have used include juxtapos-
ing similar propositions or juxtaposing propositions
with certain similar slots (typically, the agent slot).
An example is given in Section 7.
</listItem>
<bodyText confidence="0.99954">
This type of revision is different from the revision
discussed in (Gabriel 1988) and (Meteer 1991). In
these systems, the linguistic specification of the tar-
get texts is revised. In Joyce, it is the text plan
itself, i.e. the pre-linguistic representation of text
content and structure, that is subject to revision.
</bodyText>
<listItem confidence="0.991835833333333">
• Schemas can post to a &amp;quot;blackboard&amp;quot;, and check this
blackboard for messages. This allows for additional
control and communication between schemas which
are called at different times during the text planning
process and cannot communicate with each other
directly.
</listItem>
<bodyText confidence="0.97488125">
Instead of being templates that limit the structure of
the text to certain preconceived types, the schemas are
now an explicit and compact representation of domain
communication knowledge.
</bodyText>
<sectionHeader confidence="0.993893" genericHeader="method">
5 The Sentence Planner
</sectionHeader>
<bodyText confidence="0.999733380952381">
The sentence planner combines all those planning tasks
that are specific to the target language. It receives
propositions from the text planner and sends the
DSyntR of complete sentences to the realizer for pro-
cessing. It has two main tasks: first, it chooses lexi-
cal and syntactic realizations by consulting the Concep-
tual/English dictionary; second, it determines sentence
scope by merging the DSyntR of individual propositions.
We will discuss each of these steps in turn.
The Conceptual/English dictionary is implemented as
a set of procedures that operate on the propositions.
Each proposition is mapped into the DSyntR of a clause
(i.e., its root is a verb). Lexicalization can take prag-
matic factors into account. It can also refer to a history
of lexicalizations if lexical variation is desired. After a
DSyntR has been constructed, certain syntactic para-
phrase operations are performed if necessary, for exam-
ple passivization if a grammatical object is the theme of
the sentence, or if the subject is absent.
The second task of the sentence planner is to deter-
mine the scope of sentences. Combining the linguistic
realization of propositions into larger sentences is a cru-
cial issue because it increases the quality of the gener-
ated text. For example, The low-level Address Register
and the multilevel Locator are data-bases (from the Host
text in Figure 2) is significantly better than the four
clauses from which it was formed: The Address Reg-
ister is a data-base. It is low-level. The Locator is a
data-base. It is multilevel. An informal study in which
subjects were asked to revise a (grammatical) text con-
taining only single-proposition sentences supported the
claim that longer sentences are preferred over shorter
ones whenever possible and reasonable.
The first question that arises is at what level proposi-
tions should be combined. To date, the issue of sentence
scoping has always been dealt with at a pre-linguistic,
conceptual level (e.g. (Dale 1988) or (Carcagno and
Iordanskaja 1989)). However, different languages have
different syntactic means of combining clauses; clause
combining must refer to the specific linguistic resources
of the target language. Therefore, in Joyce the task is
performed by the sentence planner rather than the text
</bodyText>
<page confidence="0.999511">
43
</page>
<bodyText confidence="0.999961974358974">
planner&apos;. Joyce performs the following syntactic clause-
combining operations: Relative clause formation, adjec-
tival attachment (the process by which an adjective from
a copula-construction is embedded in an NP), and con-
junction. Conjunction includes multiple conjunctions of
more than one clause, and may lead to elision of repeated
sentence elements (&amp;quot;conjunction reduction&amp;quot;). For exam-
ple, in the example quoted above, the lexeme data base
occurs only once in the conjoined sentence.
The second question that arises is how clause combi-
nation should be restricted. We have identified stylistic
and discourse constraints. The stylistic constraints are
constraints against the sentence becoming too long (an
upper bound on the number of clauses that can be com-
bined into one sentence), and a constraint on recursive
embedding of relative clauses. Discourse constraints are
imposed by the structure of the text: clauses belonging
to conceptually distinct text units should not be com-
bined. The text planner can send a special message,
called conceptual-break, to the sentence planner. It
signals the beginning of a new textual unit. These spe-
cial messages are triggered by appropriate indications in
the DICKENS specifcation of the DCK.
The algorithm is as follows. The sentence planner
maintains a &amp;quot;current&amp;quot; DSyntR. Each incoming propo-
sition is translated into a DSyntR, which the sen-
tence planner then attempts to merge with the current
DSyntR. If none of the clause combination strategies
work, or if stylistic heuristics interfere, or if the incoming
proposition is a conceptual-break, the current DSyntR
is sent to the realizer and the new DSyntR becomes the
current one. The process of clause combination can be
very easily modeled at the DSyntR level: relative clause
formation and conjunction reduce to simple tree compo-
sition operations. (In the case of adjectival attachment
only the adjective node is attached.) Issues such as word
order in relative clauses, the morphological form of the
complementizer, and conjunction reduction can be dealt
with at further stages of processing.
</bodyText>
<sectionHeader confidence="0.986952" genericHeader="method">
6 The Linguistic Realizer
</sectionHeader>
<bodyText confidence="0.9996087">
The linguistic component is based on Meaning-Text The-
ory (MTT) (Mel&apos;euk 1988), and is a reimplementa-
tion (in Lisp) of Polguere&apos;s Prolog implementation of a
Meaning-Text model for English (Iordanskaja et al 1988;
Iordanskaja et al 1991).
MTT defines three successive levels of representation.
With each level of representation is associated a compo-
nent which transforms the representation into the next
higher level. Each component is implemented as a sepa-
rate module in Joyce.
</bodyText>
<listItem confidence="0.707328333333333">
• The Deep-Syntactic Representation (DSyntR) is a
dependency grammar tree representing the syn-
tactic relationships between the meaning-bearing
</listItem>
<tableCaption confidence="0.324238">
&apos;In Section 7, we discuss an example in which two propo-
sitions are merged by the text planner. The crucial point is
that in that example, the two propositions are merged into a
single proposition. Here, we are discussing cases in which two
distinct propositions are linguistically realized in the same
sentence.
</tableCaption>
<figure confidence="0.922792333333333">
Pass present progressive
information Analyzer
indefinite definite
</figure>
<figureCaption confidence="0.952367">
Figure 6: DSyntR of sentence The Merger is passing
information to the Analyzer
</figureCaption>
<bodyText confidence="0.99946175">
words of a sentence. Sister nodes are unordered with
respect to each other. The nodes are labelled with
lexemes which are annotated with features. Numer-
ical arc labels represent the syntactic arguments of
the governing lexeme, while ATTR represents the at-
tributive relation. An example is shown in Figure 6.
Note that the function words the, is, to are not yet
represented.
</bodyText>
<listItem confidence="0.9995409">
• The Surface-Syntactic Representation (SSyntR) is
also a dependency grammar representation, but it
includes all lexemes of the final sentence. The tran-
sition between DSyntR and SSyntR is achieved by
looking up function words in the English lexicon
and by expanding grammatical features such as verb
tenses.
• The Deep Morphological Representation (DMor-
phR) is a linearization of the nodes of the SSyntR.
• The Surface Morphological Representation is in fact
</listItem>
<bodyText confidence="0.551149833333333">
the written form of the English sentence. Morpho-
logical processing is done by a component closely
based on SUTRA-S (Emele and Momma 1985).
While linguistic realizers based on other theories coulc
have been used, this MTT-based approach offers the fol-
lowing advantages:
</bodyText>
<listItem confidence="0.989017076923077">
• The approach is based on an independently moti
vated linguistic theory. Much linguistic work hal
already been done in the MTT framework (for ex
ample (Mel&apos;Zuk and Pertsov 1987)).
• The modularization of different types of linguisti■
knowledge makes the grammar easier to maintain
Parallelism in computation could be exploited.
• The dependency grammar used to express the twc
syntactic levels of representation permits the sepa
ration of the semantically relevant issue of grammat
ical relations (e.g., subjecthood) from pragmaticaTh
relevant issues of surface word order (e.g., topical
ization).
</listItem>
<sectionHeader confidence="0.942684" genericHeader="method">
7 An Example
</sectionHeader>
<bodyText confidence="0.999954428571429">
As an example, consider the sample text in Figure 4. I
describes the occurrence of an insecure flow in compo
nent Black Box. The texts that explain insecure flow
are generated by a set of eight schemas, one of which i
shown in Figure 7. It is the first that is invoked.
Special commands are preceded by a colon; command
not starting with a colon are calls to other schema.s
</bodyText>
<figure confidence="0.509623">
Merger
definite
</figure>
<page confidence="0.910589">
44
</page>
<table confidence="0.982585090909091">
(def schema flow-analysis-error focus)))
:title &amp;quot;Insecure flow&amp;quot;
:theme &amp;quot;information&amp;quot;
:make-proposition (insecure-flow :location focus)
:make-proposition (enter :agent (get-information)
:object focus
:location (entry-port focus))
:make-proposition (id-security :agent (get-information)
:value (get-level (entry-port
conceptual-break
:shift-focus-and-edit (next-component initial-follow-path N&apos;merge-send-data))
</table>
<figureCaption confidence="0.999675">
Figure 7: The FLOW ANALYZER schema
</figureCaption>
<bodyText confidence="0.999968041666667">
The arguments to special commands immediately fol-
low the command. The :title special command gen-
erates a title. Command :theme sets the initial theme
of the paragraph, influencing issues such as passiviza-
tion. Then follow three :make-propos it ion commands,
which each produce one proposition. The first argu-
ment to :make-proposition is the class of the propo-
sition. The slots are typically filled with pointers into
the domain representation of the application program.
focus is a pointer maintained by the text planner which
refers to the global focus (currently the component Black
Box, represented by pointer #&lt;COMPONENT Black Box&gt;),
while get-information and entry-port are functions
provided by the underlying application program. Not all
arguments must be filled by a :make-proposition com-
mand; the sentence planner will choose lexical and syn-
tactic realizations accordingly. The text planner sends
an insecure-flow proposition to the sentence planner,
which translates it into a DSyntR tree (which repre-
sents the clause In the Black Box an insecure flow oc-
curs) and returns control to the text planner. The text
planner then proceeds to the next :make-proposition
command, and sends the proposition shown in Figure 8
to the sentence planner. When the sentence planner re-
</bodyText>
<sectionHeader confidence="0.9671115" genericHeader="method">
ENTER
AGENT #&lt;information&gt;
OBJECT INCOMPONENT Black Box&gt;
LOCATION #&lt;PORT P9&gt;
</sectionHeader>
<figureCaption confidence="0.998783">
Figure 8: The ENTER proposition
</figureCaption>
<bodyText confidence="0.999554166666667">
ceives the enter proposition, it translates it into the
DSyntR tree shown in Figure 9, which could be ex-
pressed as the clause information enters the Black Box
through P6. Note that the choice of enter as verb is due
to the fact that information is currently the theme; if
Black Box were the theme, the choice would have been
receives. The sentence planner then tries to combine
the new DSyntR with the current one (which was de-
rived from the previous proposition). This fails (since
the two clauses have different verbs and different ac-
tants), so the current DSyntR is sent to the realizer,
which prints out the first sentence. The new DSyntR
</bodyText>
<figure confidence="0.9496614">
enterpre.mt
ATTR
Black Box information through
definite indefmite prepl2
P6
</figure>
<figureCaption confidence="0.9853545">
Figure 9: DSyntR of sentence information enters the
Black Box through P6
</figureCaption>
<bodyText confidence="0.99859">
becomes the current one. Control is returned to the text
planner, which processes the third :make-propos it ion
command and sends the appropriate proposition to the
sentence planner. The sentence planner generates the
clausal DSyntR tree shown in Figure 10 (the informa-
tion is classified). It then attempts to combine the new
</bodyText>
<figure confidence="0.510759">
be present
2
information classified
defmite adjective
</figure>
<figureCaption confidence="0.5716705">
Figure 10: DSyntR of sentence The information is clas-
sified
</figureCaption>
<bodyText confidence="0.9998954">
clause with the &amp;quot;current DSyntR&amp;quot;, first using the adjec-
tival attachment strategy. This succeeds, yielding the
tree shown in Figure 11. It then returns control to the
text planner, since another clause could be merged with
the current DSyntR. The text planner then calls schema
conceptual-break. The only effect of this schema is to
send a conceptual-break message to the sentence plan-
ner, which thereupon sends its current DSyntR to the re-
alizer. The realizer prints out the surface sentence Clas-
sified information enters the Black Box through P6.
The last command of the schema first shifts the
(global) focus to next-component, which is the next
component traversed by the insecure flow. The sec-
ond argument of the : shift-focus-and-edit command
designates the next schema to be called. This com-
</bodyText>
<page confidence="0.99712">
45
</page>
<figure confidence="0.9846528">
Black Box information
definite indefinite
ATM
classified
adjective
ATTR
through
PreP
2
P6
</figure>
<figureCaption confidence="0.9598675">
Figure 11: DSyntR of sentence Classified information
enters the Black Box through P6
</figureCaption>
<bodyText confidence="0.999939235294118">
mand also initiates the editing process. All proposi-
tions that are generated as a result of this command
are kept on a list rather than sent to the sentence plan-
ner. When the command has been executed, the list
is edited by the function given as the third argument,
# &apos;merge-send-data. The effect of this function is to
combine two successive send propositions into a single,
new one, so that two clauses such as the Analyzer sends
the information to the Incrementor and the Incrementor
sends the information to the Formater yield the Ana-
lyzer sends the information to the Formater through the
Incrementor. Note that this combination is not a lin-
guistic one but a conceptual one, since it relies on facts
about sending data in this domain, rather than on the
syntax or lexical semantics about the verb send. It must
therefore be performed by the text planner, and not the
sentence planner.
</bodyText>
<sectionHeader confidence="0.900016" genericHeader="method">
8 Porting the System
</sectionHeader>
<bodyText confidence="0.976007829268292">
Porting is an important way to evaluate complete applied
text generation systems, since there is no canonical set
of tasks that such a system must be able to perform and
on which it can be tested. (Realization components, on
the other hand, can be tested for their syntactic and
perhaps lexical coverage.) Joyce was originally designed
to generate only component descriptions (as in Figure 2).
The &amp;quot;flow analyzer&amp;quot; heuristic tool was added later to
the system, and the completely different type of text it
required was a first successful test of Joyce and its text
planner in particular.
The modular design of Joyce proved beneficial dur-
ing the porting to the new application. The following
conceptually well-defined tasks were required during the
development of the &amp;quot;flow analyzer&amp;quot; application:
1. Since the flow analyzer is a new type of tool, no
corpus of texts was available for study. Instead,
sample texts were written by hand and critiqued by
domain experts. The texts were then revised and
resubmitted to the experts. The &amp;quot;ideal text&amp;quot; that
emerged was then analyzed and the DCK needed
to generate it expressed in terms of schemas. We
interpret the cycle of writing, critiquing and revising
as a process of DCK acquisition.
2. New classes of proposition were defined. These in-
clude enter, upgrade and downgrade. Some of the
proposition classes from the earlier descriptive ap-
plication could be reused, such as send.
3. The Conceptual/English dictionary was extended to
account for the new proposition classes.
4. Several new lexical items were entered into the
English lexicon. For example, the English lex-
eme downgrade subcategorizes for two nouns and
a propositional phrase obligatorily headed by to.
Note that those parts of Joyce that deal with facts of
English (including clause combination) needed no atten-
tion (other than updating the lexicon).
We are currently working on porting a successor of
Joyce to several new applications, including the genera-
tion of project management reports. Initial results, in-
cluding a prototype, are encouraging.
</bodyText>
<sectionHeader confidence="0.99391" genericHeader="conclusions">
9 Conclusion
</sectionHeader>
<bodyText confidence="0.999416">
We are aware of several shortcomings of Joyce, which we
will address in future versions of the system.
</bodyText>
<listItem confidence="0.5634595">
• While we have argued in (Kittredge et al 1991)
that rhetoric cannot be the central guiding princi-
</listItem>
<bodyText confidence="0.9901205">
ple in text planning, it appears to play an impor-
tant role as a constraint on possible text structures.
Furthermore, it helps determine the use of connec-
tives between rhetorically related clauses. Finally,
it may determine when conceptual breaks occur in
text structure which affect sentence scoping (Scott
and de Souza 1990). We are currently investigating
the option of augmenting the DCK schemas with
rhetorical annotations.
• The current form of the Conceptual/English dictio-
nary is not satisfactory, since the dictionary writer is
too free in writing dictionary entries. For example,
the dictionary could be used as a back door for the
introduction of new content which the text planner
was (for whatever reasons) unable to plan. Meteer
discusses the same problem in McKeown&apos;s original
TEXT system (Meteer 1990, p.35). An interface to
the dictionary that is more restrictive is needed.
• While it is possible to set a theme in the text
plan, thematic structure has not received suffi-
cient attention. Rules of thematic progression (as
implemented, for instance, in McKeown&apos;s TEXT)
are not taken into consideration. Furthermore
clause combination is also sensitive to thematic
structure (Kuno 1976; Derr and McKeown 1986
Iordanskaja 1989), which is currently not taken intc
account.
Despite these shortcomings, Joyce has proven to be a
successful and useful tool in the Ulysses user interface. II
has met the design objectives of speed and quality, and
our experience in porting the text generator to new task:
and to new applications indicates that Joyce is a flexibl(
system that can adapt to a variety of text generatior
tasks.
</bodyText>
<page confidence="0.999144">
46
</page>
<sectionHeader confidence="0.901862" genericHeader="references">
Bibliography
</sectionHeader>
<reference confidence="0.999684990196078">
Carcagno, Denis and Iordanskaja, Lidija, 1989. Con-
tent Determination and Text Structuring in Gossip.
In Proceedings of the Second European Workshop on
Text Generation. Edinburgh.
Dale, Robert, 1988. Generating Referring Expressions
in a Domain of Objects and Processes. PhD thesis,
University of Edinburgh.
Derr, Marcia A. and McKeown, Kathleen R., 1986. Us-
ing Focus to Generate Complex and Simple Sentences.
In 24th Meeting of The Association for Computational
Linguistics (ACL&apos;86), ACL, pages 319-326.
Emele, Martin and Momma, Stefan, 1985. SUTRA-
S: Erweiterungen eines Generator-Front-End fir das
SEMSYN-Projekt. Technical Report, Universitat
Stuttgart.
Gabriel, Richard P., 1988. Deliberate Writing. In Mc-
Donald, David D. and Bolc, Leonard (editors), Natural
Language Generation Systems, pages 1-46. Springer
Verlag.
Harbusch, Karin; Finkler, Wolfgang; and Schauder,
Anne, 1991. Incremental Syntax Generation with
Tree Adjoining Grammars. In Proceedings 4.Int. GI-
Kongress Wissensbasierte Systeme, GWAI. Munchen.
Hovy, Eduard H., 1988. Planning coherent multisenten-
tial text. In Proceedings of the 26th Annual Meeting,
ACL, pages 163-169. Buffalo.
Iordanskaja, Lidija, 1989. Communicative Structure
and Its Use During Text Generation. Technical Re-
port TR 15-10, Odyssey Research Associates, Ithaca,
NY/Montreal, PQ.
Iordanskaja, Lidija; Kittredge, Richard; and Polguere,
Alain, 1988. Implementing the Meaning-Text Model
for Language Generation. Paper presented at
COLING-88.
Iordanskaja, Lidija; Kittredge, Richard; and Polguere,
Alain, 1991. Lexical Selection and Paraphrase in a
Meaning-Text Generation Model. In Paris, Cecile;
Swartout, William; and Mann, William (editors), Nat-
ural Language Generation in Artifical Intelligence and
Computational Linguistics, pages 293-312. Kluwer
Academic Publishers.
Kittredge, Richard; Korelsky, Tanya; and Rambow,
Owen, 1991. On the Need for Domain Communica-
tion Knowledge. Computational Intelligence 7(4).
Kuno, S., 1976. Subject, theme and the speaker&apos;s empa-
thy - a reexamination of relativization phenomena. In
Li, Charles N. (editor), Subject and Topic, pages 417-
444. Academic Press.
McDonald, David D.; Meteer (Vaughan), Marie W.; and
Pustejovsky, James D., 1987. Factors contributing to
efficiency in Natural Language Generation. In Kem-
pen, Gerard (editor), Natural Language Generation,
pages 159-181. Martinus Nijhoff Publishers.
McKeown, Kathleen, 1985. Text Generation. Cam-
bridge University Press, Cambridge.
Mereuk, Igor A., 1988. Dependency Syntax: Theory and
Practice. State University of New York Press, New
York.
Mel&apos;euk, Igor A. and Pertsov, Nikolaj V., 1987. Sur-
face Syntax of English. John Benjamins, Amster-
dam/Philadelphia.
Meteer, Marie W., 1989. The SPOKESMAN Natural
Language Generation System. Technical Report, BBN
Systems and Technologies Corporation.
Meteer, Marie W., 1990. The &apos;Generation Gap&apos;: The
Problem of Expressibility in Text Planning. Technical
Report 7347, BBN Systems and Technologies Corpo-
ration.
Meteer, Marie W., 1991. The Implication of Revisions
for Natural Language Generation. In Paris, Cecile;
Swartout, William; and Mann, William (editors), Nat-
ural Language Generation in Artifical Intelligence and
Computational Linguistics, pages 155-177. Kluwer
Academic Publishers.
Paris, Cecile L. and McKeown, Kathleen It., 1987. Dis-
course Strategies for Describing Complex Physical Ob-
jects. In Kempen, Gerard (editor), Natural Language
Generation, pages 97-115. Martinus Nijhoff Publish-
ers.
Rambow, Owen, 1990. Domain Communication Knowl-
edge. In Proceedings of the Fifth International Work-
shop on Natural Language Generation. Dawson, PA.
Wisner, Dietmar, 1987. The Automated News Agency
SEMTEX - a Text Generator for German. In Kem-
pen, G. (editor), Natural Language Generation: New
Results in Artificial Intelligence, Psychology and Lin-
guistics, pages 138-148. Kluwer Academic Publishers,
Boston.
Rosner, Dietmar, 1988. The SEMSYN Generation Sys-
tem: Ingredients, Applications, Prospects. In Pro-
ceedings of the Second Conference on Applied Natural
Language Processing, ACL. Austin.
Scott, Donia It. and de Souza, Clarisse Sieckenius, 1990.
Getting the message across in RST-based Text Gen-
eration. In Dale, Robert; Mellish, Chris; and Zock,
Michael (editors), Current Research in Natural Lan-
gugae Generation. Academic Press, London.
Wahlster, Wolfgang; Andre, Elisabeth; Graf, Winfried;
and Rist, Thomas, 1991. WIP: The Coordinated Gen-
eration of Multimodal Presentations from a Common
Representation. In Proceedings of the 5th Conference
of the European Chapter, ACL. Berlin.
</reference>
<page confidence="0.999488">
47
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.909229">
<title confidence="0.998819">Applied Text Generation*</title>
<author confidence="0.999408">Owen Rambow Tanya Korelsky</author>
<affiliation confidence="0.999976">University of Pennsylvania CoGenTex, Inc.</affiliation>
<address confidence="0.990023">Department.of CIS 105 Lenox Road Philadelphia, PA 19104 Ithaca, NY 14850</address>
<email confidence="0.927729">rambowelinc.cis.upenn.edutanyaecogentex.com</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Denis Carcagno</author>
<author>Lidija Iordanskaja</author>
</authors>
<title>Content Determination and Text Structuring in Gossip.</title>
<date>1989</date>
<booktitle>In Proceedings of the Second European Workshop on Text Generation.</booktitle>
<location>Edinburgh.</location>
<contexts>
<context position="19616" citStr="Carcagno and Iordanskaja 1989" startWordPosition="3152" endWordPosition="3155">cantly better than the four clauses from which it was formed: The Address Register is a data-base. It is low-level. The Locator is a data-base. It is multilevel. An informal study in which subjects were asked to revise a (grammatical) text containing only single-proposition sentences supported the claim that longer sentences are preferred over shorter ones whenever possible and reasonable. The first question that arises is at what level propositions should be combined. To date, the issue of sentence scoping has always been dealt with at a pre-linguistic, conceptual level (e.g. (Dale 1988) or (Carcagno and Iordanskaja 1989)). However, different languages have different syntactic means of combining clauses; clause combining must refer to the specific linguistic resources of the target language. Therefore, in Joyce the task is performed by the sentence planner rather than the text 43 planner&apos;. Joyce performs the following syntactic clausecombining operations: Relative clause formation, adjectival attachment (the process by which an adjective from a copula-construction is embedded in an NP), and conjunction. Conjunction includes multiple conjunctions of more than one clause, and may lead to elision of repeated sent</context>
</contexts>
<marker>Carcagno, Iordanskaja, 1989</marker>
<rawString>Carcagno, Denis and Iordanskaja, Lidija, 1989. Content Determination and Text Structuring in Gossip. In Proceedings of the Second European Workshop on Text Generation. Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
</authors>
<title>Generating Referring Expressions in a Domain of Objects and Processes.</title>
<date>1988</date>
<tech>PhD thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="19581" citStr="Dale 1988" startWordPosition="3149" endWordPosition="3150">e 2) is significantly better than the four clauses from which it was formed: The Address Register is a data-base. It is low-level. The Locator is a data-base. It is multilevel. An informal study in which subjects were asked to revise a (grammatical) text containing only single-proposition sentences supported the claim that longer sentences are preferred over shorter ones whenever possible and reasonable. The first question that arises is at what level propositions should be combined. To date, the issue of sentence scoping has always been dealt with at a pre-linguistic, conceptual level (e.g. (Dale 1988) or (Carcagno and Iordanskaja 1989)). However, different languages have different syntactic means of combining clauses; clause combining must refer to the specific linguistic resources of the target language. Therefore, in Joyce the task is performed by the sentence planner rather than the text 43 planner&apos;. Joyce performs the following syntactic clausecombining operations: Relative clause formation, adjectival attachment (the process by which an adjective from a copula-construction is embedded in an NP), and conjunction. Conjunction includes multiple conjunctions of more than one clause, and m</context>
</contexts>
<marker>Dale, 1988</marker>
<rawString>Dale, Robert, 1988. Generating Referring Expressions in a Domain of Objects and Processes. PhD thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marcia A Derr</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Using Focus to Generate Complex and Simple Sentences.</title>
<date>1986</date>
<booktitle>In 24th Meeting of The Association for Computational Linguistics (ACL&apos;86), ACL,</booktitle>
<pages>319--326</pages>
<marker>Derr, McKeown, 1986</marker>
<rawString>Derr, Marcia A. and McKeown, Kathleen R., 1986. Using Focus to Generate Complex and Simple Sentences. In 24th Meeting of The Association for Computational Linguistics (ACL&apos;86), ACL, pages 319-326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Emele</author>
<author>Stefan Momma</author>
</authors>
<title>SUTRAS: Erweiterungen eines Generator-Front-End fir das SEMSYN-Projekt.</title>
<date>1985</date>
<tech>Technical Report,</tech>
<institution>Universitat Stuttgart.</institution>
<contexts>
<context position="24042" citStr="Emele and Momma 1985" startWordPosition="3838" endWordPosition="3841">are not yet represented. • The Surface-Syntactic Representation (SSyntR) is also a dependency grammar representation, but it includes all lexemes of the final sentence. The transition between DSyntR and SSyntR is achieved by looking up function words in the English lexicon and by expanding grammatical features such as verb tenses. • The Deep Morphological Representation (DMorphR) is a linearization of the nodes of the SSyntR. • The Surface Morphological Representation is in fact the written form of the English sentence. Morphological processing is done by a component closely based on SUTRA-S (Emele and Momma 1985). While linguistic realizers based on other theories coulc have been used, this MTT-based approach offers the following advantages: • The approach is based on an independently moti vated linguistic theory. Much linguistic work hal already been done in the MTT framework (for ex ample (Mel&apos;Zuk and Pertsov 1987)). • The modularization of different types of linguisti■ knowledge makes the grammar easier to maintain Parallelism in computation could be exploited. • The dependency grammar used to express the twc syntactic levels of representation permits the sepa ration of the semantically relevant is</context>
</contexts>
<marker>Emele, Momma, 1985</marker>
<rawString>Emele, Martin and Momma, Stefan, 1985. SUTRAS: Erweiterungen eines Generator-Front-End fir das SEMSYN-Projekt. Technical Report, Universitat Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard P Gabriel</author>
</authors>
<title>Deliberate Writing.</title>
<date>1988</date>
<booktitle>Natural Language Generation Systems,</booktitle>
<pages>1--46</pages>
<editor>In McDonald, David D. and Bolc, Leonard (editors),</editor>
<publisher>Springer Verlag.</publisher>
<contexts>
<context position="16896" citStr="Gabriel 1988" startWordPosition="2721" endWordPosition="2722">te new ones. The choice of an editing function depends on the domain and on the particular requirements of the text. Further study is needed in order to determine the types of editing operations that can be made and to devise a high-level language to express them; the goal is to eventually establish a library of editing operations. Typical editing operations we have used include juxtaposing similar propositions or juxtaposing propositions with certain similar slots (typically, the agent slot). An example is given in Section 7. This type of revision is different from the revision discussed in (Gabriel 1988) and (Meteer 1991). In these systems, the linguistic specification of the target texts is revised. In Joyce, it is the text plan itself, i.e. the pre-linguistic representation of text content and structure, that is subject to revision. • Schemas can post to a &amp;quot;blackboard&amp;quot;, and check this blackboard for messages. This allows for additional control and communication between schemas which are called at different times during the text planning process and cannot communicate with each other directly. Instead of being templates that limit the structure of the text to certain preconceived types, the </context>
</contexts>
<marker>Gabriel, 1988</marker>
<rawString>Gabriel, Richard P., 1988. Deliberate Writing. In McDonald, David D. and Bolc, Leonard (editors), Natural Language Generation Systems, pages 1-46. Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karin Harbusch</author>
<author>Wolfgang Finkler</author>
<author>Anne Schauder</author>
</authors>
<title>Incremental Syntax Generation with Tree Adjoining Grammars.</title>
<date>1991</date>
<booktitle>In Proceedings 4.Int. GIKongress Wissensbasierte Systeme, GWAI. Munchen.</booktitle>
<contexts>
<context position="10993" citStr="Harbusch et al 1991" startWordPosition="1760" endWordPosition="1763">structures in different cultures should not be confused with language-specific constraints on text structure. Thus, if multi-lingual generation is desired, text planning and sentence planning ought to be performed by distinct components. On a more practical level, modularity in design and implementation can be exploited by parallel processing of independent modules. While the current implementations of Joyce do not allow for parallel execution, the incremental processing of parallel computing tasks on a serial machine is also advantageous, as is argued in the WIP project (Wahlster et al 1991; Harbusch et al 1991)3. Incrementality reduces the initial response time of the system (though not the overall processing time). This can be crucial if multi-paragraph text is to be generated by an interface tool. In the Joyce system, the text planner cedes control to the sentence planner as soon as the text planner has defined a proposition. Once the sentence planner has constructed the DSyntR of a complete sentence, it sends it to the realizer which generates the English sentence. Thus, the first sentence is output by Joyce shortly after the text generator is invoked; text continues to be output approximately at</context>
</contexts>
<marker>Harbusch, Finkler, Schauder, 1991</marker>
<rawString>Harbusch, Karin; Finkler, Wolfgang; and Schauder, Anne, 1991. Incremental Syntax Generation with Tree Adjoining Grammars. In Proceedings 4.Int. GIKongress Wissensbasierte Systeme, GWAI. Munchen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard H Hovy</author>
</authors>
<title>Planning coherent multisentential text.</title>
<date>1988</date>
<booktitle>In Proceedings of the 26th Annual Meeting, ACL,</booktitle>
<pages>163--169</pages>
<location>Buffalo.</location>
<contexts>
<context position="12546" citStr="Hovy 1988" startWordPosition="2028" endWordPosition="2029">l of representation. There is no need for backtracking or feedback from one level of processing to an earlier one. As is argued by McDonald et al., such an architecture contributes to processing efficiency. We will now discuss the three modules of Joyce in more detail. 4 The Text Planner Prior to the design of the text planning component of Joyce, several existing approaches were studied. Since the structure of the descriptive text (Figure 2) does not mirror the structure of the domain, Paris&apos;s &amp;quot;procedural strategy&amp;quot; (Paris and McKeown 1987) cannot be used in general. Hovy&apos;s RST-based planner (Hovy 1988) assumes that content selection has already been performed, contrary to the situation in the Ulysses application; furthermore, there are efficiency problems in a pure STRIPS-like planning paradigm. We therefore found McKeown&apos;s schema-based approach (McKeown 1985) to be the most promising. However, it turned out that general rhetorical schemas cannot adequately capture the structure of the intended texts. In (Kittredge et al 1991), we argue that planning certain types of texts - such as reports and descriptions - requires domain-specific knowledge about how to communicate in that domain. That k</context>
</contexts>
<marker>Hovy, 1988</marker>
<rawString>Hovy, Eduard H., 1988. Planning coherent multisentential text. In Proceedings of the 26th Annual Meeting, ACL, pages 163-169. Buffalo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lidija Iordanskaja</author>
</authors>
<title>Communicative Structure and Its Use During Text Generation.</title>
<date>1989</date>
<tech>Technical Report TR 15-10,</tech>
<institution>Odyssey Research Associates,</institution>
<location>Ithaca, NY/Montreal, PQ.</location>
<contexts>
<context position="19616" citStr="Iordanskaja 1989" startWordPosition="3154" endWordPosition="3155"> than the four clauses from which it was formed: The Address Register is a data-base. It is low-level. The Locator is a data-base. It is multilevel. An informal study in which subjects were asked to revise a (grammatical) text containing only single-proposition sentences supported the claim that longer sentences are preferred over shorter ones whenever possible and reasonable. The first question that arises is at what level propositions should be combined. To date, the issue of sentence scoping has always been dealt with at a pre-linguistic, conceptual level (e.g. (Dale 1988) or (Carcagno and Iordanskaja 1989)). However, different languages have different syntactic means of combining clauses; clause combining must refer to the specific linguistic resources of the target language. Therefore, in Joyce the task is performed by the sentence planner rather than the text 43 planner&apos;. Joyce performs the following syntactic clausecombining operations: Relative clause formation, adjectival attachment (the process by which an adjective from a copula-construction is embedded in an NP), and conjunction. Conjunction includes multiple conjunctions of more than one clause, and may lead to elision of repeated sent</context>
</contexts>
<marker>Iordanskaja, 1989</marker>
<rawString>Iordanskaja, Lidija, 1989. Communicative Structure and Its Use During Text Generation. Technical Report TR 15-10, Odyssey Research Associates, Ithaca, NY/Montreal, PQ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lidija Iordanskaja</author>
<author>Richard Kittredge</author>
<author>Alain Polguere</author>
</authors>
<title>Implementing the Meaning-Text Model for Language Generation. Paper presented at COLING-88.</title>
<date>1988</date>
<contexts>
<context position="22205" citStr="Iordanskaja et al 1988" startWordPosition="3551" endWordPosition="3554">ion can be very easily modeled at the DSyntR level: relative clause formation and conjunction reduce to simple tree composition operations. (In the case of adjectival attachment only the adjective node is attached.) Issues such as word order in relative clauses, the morphological form of the complementizer, and conjunction reduction can be dealt with at further stages of processing. 6 The Linguistic Realizer The linguistic component is based on Meaning-Text Theory (MTT) (Mel&apos;euk 1988), and is a reimplementation (in Lisp) of Polguere&apos;s Prolog implementation of a Meaning-Text model for English (Iordanskaja et al 1988; Iordanskaja et al 1991). MTT defines three successive levels of representation. With each level of representation is associated a component which transforms the representation into the next higher level. Each component is implemented as a separate module in Joyce. • The Deep-Syntactic Representation (DSyntR) is a dependency grammar tree representing the syntactic relationships between the meaning-bearing &apos;In Section 7, we discuss an example in which two propositions are merged by the text planner. The crucial point is that in that example, the two propositions are merged into a single propos</context>
</contexts>
<marker>Iordanskaja, Kittredge, Polguere, 1988</marker>
<rawString>Iordanskaja, Lidija; Kittredge, Richard; and Polguere, Alain, 1988. Implementing the Meaning-Text Model for Language Generation. Paper presented at COLING-88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lidija Iordanskaja</author>
<author>Richard Kittredge</author>
<author>Alain Polguere</author>
</authors>
<title>Lexical Selection and Paraphrase in a Meaning-Text Generation Model.</title>
<date>1991</date>
<booktitle>Natural Language Generation in Artifical Intelligence and Computational Linguistics,</booktitle>
<pages>293--312</pages>
<editor>In Paris, Cecile; Swartout, William; and Mann, William (editors),</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="22230" citStr="Iordanskaja et al 1991" startWordPosition="3555" endWordPosition="3558">odeled at the DSyntR level: relative clause formation and conjunction reduce to simple tree composition operations. (In the case of adjectival attachment only the adjective node is attached.) Issues such as word order in relative clauses, the morphological form of the complementizer, and conjunction reduction can be dealt with at further stages of processing. 6 The Linguistic Realizer The linguistic component is based on Meaning-Text Theory (MTT) (Mel&apos;euk 1988), and is a reimplementation (in Lisp) of Polguere&apos;s Prolog implementation of a Meaning-Text model for English (Iordanskaja et al 1988; Iordanskaja et al 1991). MTT defines three successive levels of representation. With each level of representation is associated a component which transforms the representation into the next higher level. Each component is implemented as a separate module in Joyce. • The Deep-Syntactic Representation (DSyntR) is a dependency grammar tree representing the syntactic relationships between the meaning-bearing &apos;In Section 7, we discuss an example in which two propositions are merged by the text planner. The crucial point is that in that example, the two propositions are merged into a single proposition. Here, we are discu</context>
</contexts>
<marker>Iordanskaja, Kittredge, Polguere, 1991</marker>
<rawString>Iordanskaja, Lidija; Kittredge, Richard; and Polguere, Alain, 1991. Lexical Selection and Paraphrase in a Meaning-Text Generation Model. In Paris, Cecile; Swartout, William; and Mann, William (editors), Natural Language Generation in Artifical Intelligence and Computational Linguistics, pages 293-312. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Kittredge</author>
<author>Tanya Korelsky</author>
<author>Owen Rambow</author>
</authors>
<title>On the Need for Domain Communication Knowledge.</title>
<date>1991</date>
<journal>Computational Intelligence</journal>
<volume>7</volume>
<issue>4</issue>
<contexts>
<context position="12979" citStr="Kittredge et al 1991" startWordPosition="2091" endWordPosition="2094">criptive text (Figure 2) does not mirror the structure of the domain, Paris&apos;s &amp;quot;procedural strategy&amp;quot; (Paris and McKeown 1987) cannot be used in general. Hovy&apos;s RST-based planner (Hovy 1988) assumes that content selection has already been performed, contrary to the situation in the Ulysses application; furthermore, there are efficiency problems in a pure STRIPS-like planning paradigm. We therefore found McKeown&apos;s schema-based approach (McKeown 1985) to be the most promising. However, it turned out that general rhetorical schemas cannot adequately capture the structure of the intended texts. In (Kittredge et al 1991), we argue that planning certain types of texts - such as reports and descriptions - requires domain-specific knowledge about how to communicate in that domain. That knowledge we call &amp;quot;domain communication knowledge&amp;quot; (DCK). For example, in describing secure system designs 3Incrementality within the realizer has little practical benefit when the realizer is reasonably fast; its study is mainly motivated by psycholinguistic considerations. Therefore, there was no attempt in Joyce to make the realizer incremental. Sentence Planner Deep-Syntactic Representation English Text Figure 5: The Structure</context>
<context position="32350" citStr="Kittredge et al 1991" startWordPosition="5160" endWordPosition="5163"> English lexeme downgrade subcategorizes for two nouns and a propositional phrase obligatorily headed by to. Note that those parts of Joyce that deal with facts of English (including clause combination) needed no attention (other than updating the lexicon). We are currently working on porting a successor of Joyce to several new applications, including the generation of project management reports. Initial results, including a prototype, are encouraging. 9 Conclusion We are aware of several shortcomings of Joyce, which we will address in future versions of the system. • While we have argued in (Kittredge et al 1991) that rhetoric cannot be the central guiding principle in text planning, it appears to play an important role as a constraint on possible text structures. Furthermore, it helps determine the use of connectives between rhetorically related clauses. Finally, it may determine when conceptual breaks occur in text structure which affect sentence scoping (Scott and de Souza 1990). We are currently investigating the option of augmenting the DCK schemas with rhetorical annotations. • The current form of the Conceptual/English dictionary is not satisfactory, since the dictionary writer is too free in w</context>
</contexts>
<marker>Kittredge, Korelsky, Rambow, 1991</marker>
<rawString>Kittredge, Richard; Korelsky, Tanya; and Rambow, Owen, 1991. On the Need for Domain Communication Knowledge. Computational Intelligence 7(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kuno</author>
</authors>
<title>Subject, theme and the speaker&apos;s empathy - a reexamination of relativization phenomena.</title>
<date>1976</date>
<booktitle>Subject and Topic,</booktitle>
<pages>417--444</pages>
<editor>In Li, Charles N. (editor),</editor>
<publisher>Academic Press.</publisher>
<marker>Kuno, 1976</marker>
<rawString>Kuno, S., 1976. Subject, theme and the speaker&apos;s empathy - a reexamination of relativization phenomena. In Li, Charles N. (editor), Subject and Topic, pages 417-444. Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Marie</author>
<author>James D Pustejovsky</author>
</authors>
<title>Factors contributing to efficiency in Natural Language Generation.</title>
<date>1987</date>
<booktitle>Natural Language Generation,</booktitle>
<pages>159--181</pages>
<editor>In Kempen, Gerard (editor),</editor>
<publisher>Martinus Nijhoff Publishers.</publisher>
<marker>Marie, Pustejovsky, 1987</marker>
<rawString>McDonald, David D.; Meteer (Vaughan), Marie W.; and Pustejovsky, James D., 1987. Factors contributing to efficiency in Natural Language Generation. In Kempen, Gerard (editor), Natural Language Generation, pages 159-181. Martinus Nijhoff Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen McKeown</author>
</authors>
<title>Text Generation.</title>
<date>1985</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="8548" citStr="McKeown 1985" startWordPosition="1387" endWordPosition="1389">o-syntactic structures, called Deep Syntactic Representation or DSyntR, into larger sentences. It draws on knowledge captured in the conceptual/English dictionary. 3. The linguistic realizer takes the syntactic structures and produces surface sentences. It draws on syntactic and morphological knowledge, expressed in the English lexicon. Usually, the different tasks of text generation are divided among two modules (planning and realization), 41 rather than three. However, there is a certain amount of disagreement about where the line between the two is to be drawn. For example, McKeown&apos;s TEXT (McKeown 1985) performs the tasks that Joyce classifies as sentence planning as part of the realization process, whereas Meteer&apos;s SPOKESMAN (Meteer 1989) classifies them as part of text planning. (See (Meteer 1990, p.23sq) for a useful summary of the terminological issues&apos;.) In this paper, &amp;quot;text planning&amp;quot; will always be used in the narrow sense of &amp;quot;content selection and organization&amp;quot;. The architecture of Joyce is directly influenced by that of the SEMSYN system (Rosner 1987; Wisner 1988). Rosner divides the realization component into two parts, the &amp;quot;generator kernel&amp;quot; and the &amp;quot;generator front end&amp;quot;. This dist</context>
<context position="12809" citStr="McKeown 1985" startWordPosition="2065" endWordPosition="2066">e detail. 4 The Text Planner Prior to the design of the text planning component of Joyce, several existing approaches were studied. Since the structure of the descriptive text (Figure 2) does not mirror the structure of the domain, Paris&apos;s &amp;quot;procedural strategy&amp;quot; (Paris and McKeown 1987) cannot be used in general. Hovy&apos;s RST-based planner (Hovy 1988) assumes that content selection has already been performed, contrary to the situation in the Ulysses application; furthermore, there are efficiency problems in a pure STRIPS-like planning paradigm. We therefore found McKeown&apos;s schema-based approach (McKeown 1985) to be the most promising. However, it turned out that general rhetorical schemas cannot adequately capture the structure of the intended texts. In (Kittredge et al 1991), we argue that planning certain types of texts - such as reports and descriptions - requires domain-specific knowledge about how to communicate in that domain. That knowledge we call &amp;quot;domain communication knowledge&amp;quot; (DCK). For example, in describing secure system designs 3Incrementality within the realizer has little practical benefit when the realizer is reasonably fast; its study is mainly motivated by psycholinguistic cons</context>
</contexts>
<marker>McKeown, 1985</marker>
<rawString>McKeown, Kathleen, 1985. Text Generation. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Mereuk</author>
</authors>
<title>Dependency Syntax: Theory and Practice.</title>
<date>1988</date>
<publisher>State University of New York Press,</publisher>
<location>New York.</location>
<marker>Mereuk, 1988</marker>
<rawString>Mereuk, Igor A., 1988. Dependency Syntax: Theory and Practice. State University of New York Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Igor A Mel&apos;euk</author>
<author>Nikolaj V Pertsov</author>
</authors>
<date>1987</date>
<journal>Surface Syntax of English. John Benjamins, Amsterdam/Philadelphia.</journal>
<marker>Mel&apos;euk, Pertsov, 1987</marker>
<rawString>Mel&apos;euk, Igor A. and Pertsov, Nikolaj V., 1987. Surface Syntax of English. John Benjamins, Amsterdam/Philadelphia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie W Meteer</author>
</authors>
<title>The SPOKESMAN Natural Language Generation System.</title>
<date>1989</date>
<booktitle>BBN Systems and Technologies Corporation.</booktitle>
<tech>Technical Report,</tech>
<contexts>
<context position="8687" citStr="Meteer 1989" startWordPosition="1408" endWordPosition="1409">ual/English dictionary. 3. The linguistic realizer takes the syntactic structures and produces surface sentences. It draws on syntactic and morphological knowledge, expressed in the English lexicon. Usually, the different tasks of text generation are divided among two modules (planning and realization), 41 rather than three. However, there is a certain amount of disagreement about where the line between the two is to be drawn. For example, McKeown&apos;s TEXT (McKeown 1985) performs the tasks that Joyce classifies as sentence planning as part of the realization process, whereas Meteer&apos;s SPOKESMAN (Meteer 1989) classifies them as part of text planning. (See (Meteer 1990, p.23sq) for a useful summary of the terminological issues&apos;.) In this paper, &amp;quot;text planning&amp;quot; will always be used in the narrow sense of &amp;quot;content selection and organization&amp;quot;. The architecture of Joyce is directly influenced by that of the SEMSYN system (Rosner 1987; Wisner 1988). Rosner divides the realization component into two parts, the &amp;quot;generator kernel&amp;quot; and the &amp;quot;generator front end&amp;quot;. This distinction is mirrored exactly by the distinction between sentence planning and realization in Joyce. There are two main advantages to such a </context>
</contexts>
<marker>Meteer, 1989</marker>
<rawString>Meteer, Marie W., 1989. The SPOKESMAN Natural Language Generation System. Technical Report, BBN Systems and Technologies Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie W Meteer</author>
</authors>
<title>The &apos;Generation Gap&apos;: The Problem of Expressibility in Text Planning.</title>
<date>1990</date>
<booktitle>BBN Systems and Technologies Corporation.</booktitle>
<tech>Technical Report 7347,</tech>
<contexts>
<context position="8747" citStr="Meteer 1990" startWordPosition="1419" endWordPosition="1420">syntactic structures and produces surface sentences. It draws on syntactic and morphological knowledge, expressed in the English lexicon. Usually, the different tasks of text generation are divided among two modules (planning and realization), 41 rather than three. However, there is a certain amount of disagreement about where the line between the two is to be drawn. For example, McKeown&apos;s TEXT (McKeown 1985) performs the tasks that Joyce classifies as sentence planning as part of the realization process, whereas Meteer&apos;s SPOKESMAN (Meteer 1989) classifies them as part of text planning. (See (Meteer 1990, p.23sq) for a useful summary of the terminological issues&apos;.) In this paper, &amp;quot;text planning&amp;quot; will always be used in the narrow sense of &amp;quot;content selection and organization&amp;quot;. The architecture of Joyce is directly influenced by that of the SEMSYN system (Rosner 1987; Wisner 1988). Rosner divides the realization component into two parts, the &amp;quot;generator kernel&amp;quot; and the &amp;quot;generator front end&amp;quot;. This distinction is mirrored exactly by the distinction between sentence planning and realization in Joyce. There are two main advantages to such a tripartite architecture, one conceptual and the other practi</context>
<context position="33216" citStr="Meteer 1990" startWordPosition="5299" endWordPosition="5300">, it may determine when conceptual breaks occur in text structure which affect sentence scoping (Scott and de Souza 1990). We are currently investigating the option of augmenting the DCK schemas with rhetorical annotations. • The current form of the Conceptual/English dictionary is not satisfactory, since the dictionary writer is too free in writing dictionary entries. For example, the dictionary could be used as a back door for the introduction of new content which the text planner was (for whatever reasons) unable to plan. Meteer discusses the same problem in McKeown&apos;s original TEXT system (Meteer 1990, p.35). An interface to the dictionary that is more restrictive is needed. • While it is possible to set a theme in the text plan, thematic structure has not received sufficient attention. Rules of thematic progression (as implemented, for instance, in McKeown&apos;s TEXT) are not taken into consideration. Furthermore clause combination is also sensitive to thematic structure (Kuno 1976; Derr and McKeown 1986 Iordanskaja 1989), which is currently not taken intc account. Despite these shortcomings, Joyce has proven to be a successful and useful tool in the Ulysses user interface. II has met the des</context>
</contexts>
<marker>Meteer, 1990</marker>
<rawString>Meteer, Marie W., 1990. The &apos;Generation Gap&apos;: The Problem of Expressibility in Text Planning. Technical Report 7347, BBN Systems and Technologies Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie W Meteer</author>
</authors>
<title>The Implication of Revisions for Natural Language Generation. In</title>
<date>1991</date>
<booktitle>Natural Language Generation in Artifical Intelligence and Computational Linguistics,</booktitle>
<pages>155--177</pages>
<editor>Paris, Cecile; Swartout, William; and Mann, William (editors),</editor>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="16914" citStr="Meteer 1991" startWordPosition="2724" endWordPosition="2725">oice of an editing function depends on the domain and on the particular requirements of the text. Further study is needed in order to determine the types of editing operations that can be made and to devise a high-level language to express them; the goal is to eventually establish a library of editing operations. Typical editing operations we have used include juxtaposing similar propositions or juxtaposing propositions with certain similar slots (typically, the agent slot). An example is given in Section 7. This type of revision is different from the revision discussed in (Gabriel 1988) and (Meteer 1991). In these systems, the linguistic specification of the target texts is revised. In Joyce, it is the text plan itself, i.e. the pre-linguistic representation of text content and structure, that is subject to revision. • Schemas can post to a &amp;quot;blackboard&amp;quot;, and check this blackboard for messages. This allows for additional control and communication between schemas which are called at different times during the text planning process and cannot communicate with each other directly. Instead of being templates that limit the structure of the text to certain preconceived types, the schemas are now an</context>
</contexts>
<marker>Meteer, 1991</marker>
<rawString>Meteer, Marie W., 1991. The Implication of Revisions for Natural Language Generation. In Paris, Cecile; Swartout, William; and Mann, William (editors), Natural Language Generation in Artifical Intelligence and Computational Linguistics, pages 155-177. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cecile L Paris</author>
<author>Kathleen It McKeown</author>
</authors>
<title>Discourse Strategies for Describing Complex Physical Objects. In</title>
<date>1987</date>
<booktitle>Natural Language Generation,</booktitle>
<pages>97--115</pages>
<editor>Kempen, Gerard (editor),</editor>
<publisher>Martinus Nijhoff Publishers.</publisher>
<contexts>
<context position="12482" citStr="Paris and McKeown 1987" startWordPosition="2016" endWordPosition="2019">al 1987): control lies in the input, which is used to construct the next level of representation. There is no need for backtracking or feedback from one level of processing to an earlier one. As is argued by McDonald et al., such an architecture contributes to processing efficiency. We will now discuss the three modules of Joyce in more detail. 4 The Text Planner Prior to the design of the text planning component of Joyce, several existing approaches were studied. Since the structure of the descriptive text (Figure 2) does not mirror the structure of the domain, Paris&apos;s &amp;quot;procedural strategy&amp;quot; (Paris and McKeown 1987) cannot be used in general. Hovy&apos;s RST-based planner (Hovy 1988) assumes that content selection has already been performed, contrary to the situation in the Ulysses application; furthermore, there are efficiency problems in a pure STRIPS-like planning paradigm. We therefore found McKeown&apos;s schema-based approach (McKeown 1985) to be the most promising. However, it turned out that general rhetorical schemas cannot adequately capture the structure of the intended texts. In (Kittredge et al 1991), we argue that planning certain types of texts - such as reports and descriptions - requires domain-sp</context>
</contexts>
<marker>Paris, McKeown, 1987</marker>
<rawString>Paris, Cecile L. and McKeown, Kathleen It., 1987. Discourse Strategies for Describing Complex Physical Objects. In Kempen, Gerard (editor), Natural Language Generation, pages 97-115. Martinus Nijhoff Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
</authors>
<title>Domain Communication Knowledge.</title>
<date>1990</date>
<booktitle>In Proceedings of the Fifth International Workshop on Natural Language Generation.</booktitle>
<location>Dawson, PA.</location>
<marker>Rambow, 1990</marker>
<rawString>Rambow, Owen, 1990. Domain Communication Knowledge. In Proceedings of the Fifth International Workshop on Natural Language Generation. Dawson, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dietmar Wisner</author>
</authors>
<title>The Automated News Agency SEMTEX - a Text Generator for German. In</title>
<date>1987</date>
<booktitle>Natural Language Generation: New Results in Artificial Intelligence, Psychology and Linguistics,</booktitle>
<pages>138--148</pages>
<editor>Kempen, G. (editor),</editor>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Boston.</location>
<marker>Wisner, 1987</marker>
<rawString>Wisner, Dietmar, 1987. The Automated News Agency SEMTEX - a Text Generator for German. In Kempen, G. (editor), Natural Language Generation: New Results in Artificial Intelligence, Psychology and Linguistics, pages 138-148. Kluwer Academic Publishers, Boston.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dietmar Rosner</author>
</authors>
<title>The SEMSYN Generation System: Ingredients, Applications, Prospects.</title>
<date>1988</date>
<booktitle>In Proceedings of the Second Conference on Applied Natural Language Processing, ACL.</booktitle>
<publisher>Austin.</publisher>
<marker>Rosner, 1988</marker>
<rawString>Rosner, Dietmar, 1988. The SEMSYN Generation System: Ingredients, Applications, Prospects. In Proceedings of the Second Conference on Applied Natural Language Processing, ACL. Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>de Souza</author>
</authors>
<title>Clarisse Sieckenius,</title>
<date>1990</date>
<booktitle>Current Research in Natural Langugae Generation.</booktitle>
<editor>In Dale, Robert; Mellish, Chris; and Zock, Michael (editors),</editor>
<publisher>Academic Press,</publisher>
<location>London.</location>
<marker>de Souza, 1990</marker>
<rawString>Scott, Donia It. and de Souza, Clarisse Sieckenius, 1990. Getting the message across in RST-based Text Generation. In Dale, Robert; Mellish, Chris; and Zock, Michael (editors), Current Research in Natural Langugae Generation. Academic Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
<author>Elisabeth Andre</author>
<author>Winfried Graf</author>
<author>Thomas Rist</author>
</authors>
<title>WIP: The Coordinated Generation of Multimodal Presentations from a Common Representation.</title>
<date>1991</date>
<booktitle>In Proceedings of the 5th Conference of the European Chapter, ACL.</booktitle>
<location>Berlin.</location>
<contexts>
<context position="10971" citStr="Wahlster et al 1991" startWordPosition="1756" endWordPosition="1759">ay display different structures in different cultures should not be confused with language-specific constraints on text structure. Thus, if multi-lingual generation is desired, text planning and sentence planning ought to be performed by distinct components. On a more practical level, modularity in design and implementation can be exploited by parallel processing of independent modules. While the current implementations of Joyce do not allow for parallel execution, the incremental processing of parallel computing tasks on a serial machine is also advantageous, as is argued in the WIP project (Wahlster et al 1991; Harbusch et al 1991)3. Incrementality reduces the initial response time of the system (though not the overall processing time). This can be crucial if multi-paragraph text is to be generated by an interface tool. In the Joyce system, the text planner cedes control to the sentence planner as soon as the text planner has defined a proposition. Once the sentence planner has constructed the DSyntR of a complete sentence, it sends it to the realizer which generates the English sentence. Thus, the first sentence is output by Joyce shortly after the text generator is invoked; text continues to be o</context>
</contexts>
<marker>Wahlster, Andre, Graf, Rist, 1991</marker>
<rawString>Wahlster, Wolfgang; Andre, Elisabeth; Graf, Winfried; and Rist, Thomas, 1991. WIP: The Coordinated Generation of Multimodal Presentations from a Common Representation. In Proceedings of the 5th Conference of the European Chapter, ACL. Berlin.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>