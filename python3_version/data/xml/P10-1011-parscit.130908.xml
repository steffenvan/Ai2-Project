<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001745">
<title confidence="0.992319">
Bilingual Lexicon Generation Using Non-Aligned Signatures
</title>
<author confidence="0.996872">
Daphna Shezaf
</author>
<affiliation confidence="0.9991065">
Institute of Computer Science
Hebrew University of Jerusalem
</affiliation>
<email confidence="0.975747">
daphna.shezaf@mail.huji.ac.il
</email>
<author confidence="0.992677">
Ari Rappoport
</author>
<affiliation confidence="0.9990615">
Institute of Computer Science
Hebrew University of Jerusalem
</affiliation>
<email confidence="0.988429">
arir@cs.huji.ac.il
</email>
<sectionHeader confidence="0.993703" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999168909090909">
Bilingual lexicons are fundamental re-
sources. Modern automated lexicon gen-
eration methods usually require parallel
corpora, which are not available for most
language pairs. Lexicons can be gener-
ated using non-parallel corpora or a pivot
language, but such lexicons are noisy.
We present an algorithm for generating
a high quality lexicon from a noisy one,
which only requires an independent cor-
pus for each language. Our algorithm in-
troduces non-aligned signatures (NAS), a
cross-lingual word context similarity score
that avoids the over-constrained and inef-
ficient nature of alignment-based methods.
We use NAS to eliminate incorrect transla-
tions from the generated lexicon. We eval-
uate our method by improving the quality
of noisy Spanish-Hebrew lexicons gener-
ated from two pivot English lexicons. Our
algorithm substantially outperforms other
lexicon generation methods.
</bodyText>
<sectionHeader confidence="0.998999" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975370370371">
Bilingual lexicons are useful for both end users
and computerized language processing tasks.
They provide, for each source language word or
phrase, a set of translations in the target language,
and thus they are a basic component of dictio-
naries, which also include syntactic information,
sense division, usage examples, semantic fields,
usage guidelines, etc.
Traditionally, when bilingual lexicons are not
compiled manually, they are extracted from par-
allel corpora. However, for most language pairs
parallel bilingual corpora either do not exist or are
at best small and unrepresentative of the general
language.
Bilingual lexicons can be generated using non-
parallel corpora or pivot language lexicons (see
Section 2). However, such lexicons are noisy. In
this paper we present a method for generating a
high quality lexicon given such a noisy one. Our
evaluation focuses on the pivot language case.
Pivot language approaches deal with the
scarcity of bilingual data for most language pairs
by relying on the availability of bilingual data for
each of the languages in question with a third,
pivot, language. In practice, this third language
is often English.
A naive method for pivot-based lexicon genera-
tion goes as follows. For each source headword&apos;,
take its translations to the pivot language using the
source-to-pivot lexicon, then for each such transla-
tion take its translations to the target language us-
ing the pivot-to-target lexicon. This method yields
highly noisy (‘divergent’) lexicons, because lexi-
cons are generally intransitive. This intransitivity
stems from polysemy in the pivot language that
does not exist in the source language. For ex-
ample, take French-English-Spanish. The English
word spring is the translation of the French word
printemps, but only in the season of year sense.
Further translating spring into Spanish yields both
the correct translation primavera and an incorrect
one, resorte (the elastic object).
To cope with the issue of divergence due to lex-
ical intransitivity, we present an algorithm for as-
sessing the correctness of candidate translations.
The algorithm is quite simple to understand and
to implement and is computationally efficient. In
spite of its simplicity, we are not aware of previous
work applying it to our problem.
The algorithm utilizes two monolingual cor-
pora, comparable in their domain but otherwise
unrelated, in the source and target languages. It
does not need a pivot language corpus. The al-
gorithm comprises two stages: signature genera-
</bodyText>
<footnote confidence="0.988680666666667">
&apos;In this paper we focus on single word head entries.
Multi-word expressions form a major topic in NLP and their
handling is deferred to future work.
</footnote>
<page confidence="0.732261">
98
</page>
<note confidence="0.9503495">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 98–107,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.99991565">
tion and signature ranking. The signature of word
w is the set of words that co-occur with w most
strongly. While co-occurrence scores are used
to compute signatures, signatures, unlike context
vectors, do not contain the score values. For
each given source headword we compute its sig-
nature and the signatures of all of its candidate
translations. We present the non-aligned signa-
tures (NAS) similarity score for signature and use
it to rank these translations. NAS is based on the
number of headword signature words that may be
translated using the input noisy lexicon into words
in the signature of a candidate translation.
We evaluate our algorithm by generating a
bilingual lexicon for Hebrew and Spanish using
pivot Hebrew-English and English-Spanish lexi-
cons compiled by a professional publishing house.
We show that the algorithm outperforms exist-
ing algorithms for handling divergence induced by
lexical intransitivity.
</bodyText>
<sectionHeader confidence="0.99283" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<subsectionHeader confidence="0.988591">
2.1 Parallel Corpora
</subsectionHeader>
<bodyText confidence="0.999960166666667">
Parallel corpora are often used to infer word-
oriented machine-readable bilingual lexicons. The
texts are aligned to each other, at chunk- and/or
word-level. Alignment is generally evaluated by
consistency (source words should be translated to
a small number of target words over the entire cor-
pus) and minimal shifting (in each occurrence, the
source should be aligned to a translation nearby).
For a review of such methods see (Lopez, 2008).
The limited availability of parallel corpora of suffi-
cient size for most language pairs restricts the use-
fulness of these methods.
</bodyText>
<subsectionHeader confidence="0.9973165">
2.2 Pivot Language Without Corpora
2.2.1 Inverse Consultation
</subsectionHeader>
<bodyText confidence="0.999957692307692">
Tanaka and Umemura (1994) generated a bilin-
gual lexicon using a pivot language. They ap-
proached lexical intransitivity divergence using
Inverse Consultation (IC). IC examines the inter-
section of two pivot language sets: the set of pivot
translations of a source-language word w, and the
set of pivot translations of each target-language
word that is a candidate for being a translation
to w. IC generally requires that the intersection
set contains at least two words, which are syn-
onyms. For example, the intersection of the En-
glish translations of French printemps and Spanish
resorte contains only a single word, spring. The
intersection for a correct translation pair printemps
and primavera may include two synonym words,
spring and springtime. Variations of this method
were proposed by (Kaji and Aizono, 1996; Bond
et al., 2001; Paik et al., 2004; Ahn and Frampton,
2006).
One weakness of IC is that it relies on pivot lan-
guage synonyms to identify correct translations.
In the above example, if the relatively rare spring-
time had not existed or was missing from the input
lexicons, IC would not have been able to discern
that primavera is a correct translation. This may
result in low recall.
</bodyText>
<subsectionHeader confidence="0.969237">
2.2.2 Multiple Pivot Languages
</subsectionHeader>
<bodyText confidence="0.999966304347826">
Mausam et al. (2009) used many input bilingual
lexicons to create bilingual lexicons for new lan-
guage pairs. They represent the multiple input
lexicons in a single undirected graph, with words
from all the lexicons as nodes. The input lexi-
cons translation pairs define the edges in the graph.
New translation pairs are inferred based on cycles
in the graph, that is, the existence of multiple paths
between two words in different languages.
In a sense, this is a generalization of the pivot
language idea, where multiple pivots are used. In
the example above, if both English and German
are used as pivots, printemps and primavera would
be accepted as correct because they are linked by
both English spring and German Fruehling, while
printemps and resorte are not linked by any Ger-
man pivot. This multiple-pivot idea is similar to
Inverse Consultation in that multiple pivots are re-
quired, but using multiple pivot languages frees it
from the dependency on rich input lexicons that
contain a variety of synonyms. This is replaced,
however, with the problem of coming up with mul-
tiple suitable input lexicons.
</bodyText>
<subsectionHeader confidence="0.998555">
2.2.3 Micro-Structure of Dictionary Entries
</subsectionHeader>
<bodyText confidence="0.999612333333333">
Dictionaries published by a single publishing
house tend to partition the semantic fields of head-
words in the same way. Thus the first translation
of some English headword in the English-Spanish
and in the English-Hebrew dictionaries would cor-
respond to the same sense of the headword, and
would therefore constitute translations of each
other. The applicability of this method is lim-
ited by the availability of machine-readable dic-
tionaries produced by the same publishing house.
Not surprisingly, this method has been proposed
by lexicographers working in such companies (Sk-
</bodyText>
<page confidence="0.996834">
99
</page>
<bodyText confidence="0.544987">
oumalova, 2001).
</bodyText>
<subsectionHeader confidence="0.996474">
2.3 Cross-lingual Co-occurrences in Lexicon
Construction
</subsectionHeader>
<bodyText confidence="0.999972346153847">
Rapp (1999) and Fung (1998) discussed seman-
tic similarity estimation using cross-lingual con-
text vector alignment. Both works rely on a
pre-existing large (16-20K entries), correct, one-
to-one lexicon between the source and target
languages, which is used to align context vec-
tors between languages. The context vector
data was extracted from comparable (monolingual
but domain-related) corpora. Koehn and Knight
(2002) were able to do without the initial large lex-
icon by limiting themselves to related languages
that share a writing system, and using identically-
spelled words as context words. Garera et al.
(2009) and Pekar et al. (2006) suggested different
methods for improving the context vectors data in
each language before aligning them. Garera et al.
(2009) replaced the traditional window-based co-
occurrence counting with dependency-tree based
counting, while Pekar et al. (2006) predicted miss-
ing co-occurrence values based on similar words
in the same language. In the latter work, the one-
to-one lexicon assumption was not made: when
a context word had multiple equivalents, it was
mapped into all of them, with the original prob-
ability equally distributed between them.
Pivot Language. Using cross-lingual co-
occurrences to improve a lexicon generated using
a pivot language was suggested by Tanaka and
Iwasaki (1996). Schafer and Yarowsky (2002)
created lexicons between English and a target
local language (e.g. Gujarati) using a related
language (e.g. Hindi) as pivot. An English pivot
lexicon was used in conjunction with pivot-target
cognates. Cross-lingual co-occurrences were used
to remove errors, together with other cues such as
edit distance and Inverse Document Frequencies
(IDF) scores. It appears that this work assumed a
single alignment was possible from English to the
target language.
Kaji et al. (2008) used a pivot English lexicon
to generate initial Japanese-Chinese and Chinese-
Japanese lexicons, then used co-occurrences in-
formation, aligned using the initial lexicon, to
identify correct translations. Unlike other works,
which require alignments of pairs (i.e., two co-
occurring words in one language translatable into
two co-occurring words in the other), this method
relies on alignments of 3-word cliques in each
language, every pair of which frequently co-
occurring. This is a relatively rare occurrence,
which may explain the low recall rates of their re-
sults.
</bodyText>
<sectionHeader confidence="0.993668" genericHeader="method">
3 Algorithm
</sectionHeader>
<bodyText confidence="0.999984869565218">
Our algorithm transforms a noisy lexicon into a
high quality one. As explained above, in this paper
we focus on noisy lexicons generated using pivot
language lexicons. Other methods for obtaining
an initial noisy lexicon could be used as well; their
evaluation is deferred to future work.
In the setting evaluated in this paper, we first
generate an initial noisy lexicon ilex possibly
containing many translation candidates for each
source headword. ilex is computed from two
pivot-language lexicons, and is the only place in
which the algorithm utilizes the pivot language.
Afterwards, for each source headword, we com-
pute its signature and the signatures of each of its
translation candidates. Signature computation uti-
lizes a monolingual corpus to discover the words
that are most strongly related to the word. We now
rank the candidates according to the non-aligned
signatures (NAS) similarity score, which assesses
the similarity between each candidate’s signature
and that of the headword. For each headword,
we select the t translations with the highest NAS
scores as correct translations.
</bodyText>
<subsectionHeader confidence="0.996542">
3.1 Input Resources
</subsectionHeader>
<bodyText confidence="0.999960461538462">
The resources required by our algorithm as evalu-
ated in this paper are: (a) two bilingual lexicons,
one from the source to the pivot language and the
other from the pivot to the target language. In
principle, these two pivot lexicons can be noisy,
although in our evaluation we use manually com-
piled lexicons; (b) two monolingual corpora, one
for each of the source and target languages. We
have tested the method with corpora of compa-
rable domains, but not covering the same well-
defined subjects (the corpora contain news from
different countries and over non-identical time pe-
riods).
</bodyText>
<subsectionHeader confidence="0.997927">
3.2 Initial Lexicon Construction
</subsectionHeader>
<bodyText confidence="0.9998945">
We create an initial lexicon from the source to the
target language using the pivot language: we look
up each source language word s in the source-
pivot lexicon, and obtain the set P3 of its pivot
</bodyText>
<page confidence="0.956663">
100
</page>
<bodyText confidence="0.999968888888889">
translations. We then look up each of the mem-
bers of Ps in the pivot-target lexicon, and obtain
a set Ts of candidate target translations. iLex is
therefore a mapping from the set of source head-
words to the set of candidate target translations.
Note that it is possible that not all target lexicon
words appear as translation candidates. To create
a target to source lexicon, we repeat the process
with the directions reversed.
</bodyText>
<subsectionHeader confidence="0.997417">
3.3 Signatures
</subsectionHeader>
<bodyText confidence="0.999784666666667">
The signature of a word w in a language is the
set of N words most strongly related to w. There
are various possible ways to formalize this notion.
We use a common and simple one, the words hav-
ing the highest tendency to co-occur with w in a
corpus. We count co-occurrences using a sliding
fixed-length window of size k. We compute, for
each pair of words, their Pointwise Mutual Infor-
mation (PMI), that is:
</bodyText>
<equation confidence="0.999639666666667">
PMI(w1,w2) = log
Pr(w1)Pr(w2)
Pr(w1, w2)
</equation>
<bodyText confidence="0.999979307692307">
where Pr(w1, w2) is the co-occurrence count, and
Pr(wi) is the total number of appearance of wi
in the corpus (Church and Hanks, 1990). We de-
fine the signature G(w)N,k of w to be the set of N
words with the highest PMI with w.
Note that a word’s signature includes words in
the same language. Therefore, two signatures of
words in different languages cannot be directly
compared; we compare them using a lexicon L as
explained below.
Signature is a function of w parameterized by
N and k. We discuss the selection of these param-
eters in section 4.1.5.
</bodyText>
<subsectionHeader confidence="0.9853475">
3.4 Non-aligned Signatures (NAS) Similarity
Scoring
</subsectionHeader>
<bodyText confidence="0.999986625">
The core strength of our method lies in the way
in which we evaluate similarity between words in
the source and target languages. For a lexicon L,
a source word s and a target word t, NA5L(s, t)
is defined as the number of words in the signature
G(s)N,k of s that may be translated, using L, to
words in the signature G(t)N,k of t, normalized by
dividing it by N. Formally,
</bodyText>
<equation confidence="0.987202666666667">
NA5L(s, t) =
j{wEG(s)jL(w)nG(t)=j40}j
N
</equation>
<bodyText confidence="0.8109035">
Where L(x) is the set of candidate translations
of x under the lexicon L. Since we use a single
</bodyText>
<table confidence="0.978412">
Language Sites Tokens
Hebrew haartz.co.il, ynet.co.il, 510M
nrg.co.il
Spanish elpais.com, 560M
elmundo.com, abc.es
</table>
<tableCaption confidence="0.999522">
Table 1: Hebrew corpus data.
</tableCaption>
<bodyText confidence="0.7832445">
lexicon, iLex, throughout this work, we usually
omit the L subscript when referring to NAS.
</bodyText>
<sectionHeader confidence="0.987095" genericHeader="method">
4 Lexicon Generation Experiments
</sectionHeader>
<bodyText confidence="0.999649555555556">
We tested our algorithm by generating bilingual
lexicons for Hebrew and Spanish, using English
as a pivot language. We chose a language pair for
which basically no parallel corpora exist2, and that
do not share ancestry or writing system in a way
that can provide cues for alignment.
We conducted the test twice: once creating
a Hebrew-Spanish lexicon, and once creating a
Spanish-Hebrew one.
</bodyText>
<subsectionHeader confidence="0.821219">
4.1 Experimental Setup
4.1.1 Corpora
</subsectionHeader>
<bodyText confidence="0.99996704">
The Hebrew and Spanish corpora were extracted
from Israeli and Spanish newspaper websites re-
spectively (see table 1 for details). Crawling a
small number of sites allowed us to use special-
tailored software to extract the textual data from
the web pages, thus improving the quality of the
extracted texts. Our two corpora are comparable
in their domains, news and news commentary.
No kind of preprocessing was used for the Span-
ish corpus. For Hebrew, closed-class words that
are attached to the succeeding word (e.g., ‘the’,
‘and’, ‘in’) were segmented using a simple un-
supervised method (Dinur et al., 2009). This
method compares the corpus frequencies of the
non-prefixed form x and the prefixed form wx. If x
is frequent enough, it is assumed to be the correct
form, and all the occurrences of wx are segmented
into two tokens, w x. This method was chosen for
being simple and effective. However, the segmen-
tation it produces is not perfect. It is context insen-
sitive, segmenting all appearances of a token in the
same way, while many wx forms are actually am-
biguous. Even unambiguous token segmentations
may fail when the non-segmented form is very fre-
quent in the domain.
</bodyText>
<footnote confidence="0.8503875">
2Old testament corpora are for biblical Hebrew, which is
very different from modern Hebrew.
</footnote>
<page confidence="0.978344">
101
</page>
<table confidence="0.999886285714286">
Lexicon # headwords BF
Eng-Spa 55057 2.4
Spa-Eng 44349 2.9
Eng-Heb 48857 2.5
Heb-Eng 33439 3.7
Spa-Heb 34077 12.6
Heb-Spa 27591 14.8
</table>
<tableCaption confidence="0.972458">
Table 2: Number of words in lexicons, and branch-
ing factors (BF).
</tableCaption>
<bodyText confidence="0.988937666666667">
Hebrew orthography presents additional diffi-
culties: there are relatively many homographs, and
spelling is not quite standardized. These consid-
erations lead us to believe that our choice of lan-
guage pair is more challenging than, for example,
a pair of European languages.
</bodyText>
<subsectionHeader confidence="0.589278">
4.1.2 Lexicons
</subsectionHeader>
<bodyText confidence="0.999409695652174">
The source of the Hebrew-English lexicon was the
Babylon on-line dictionary3. For Spanish-English,
we used the union of Babylon with the Oxford
English-Spanish lexicon. Since the corpus was
segmented to words using spaces, lexicon entries
containing spaces were discarded.
Lexicon directionality was ignored. All trans-
lation pairs extracted for Hebrew-Spanish via En-
glish, were also reversed and added to the Spanish-
Hebrew lexicon, and vice-versa. Therefore, every
L1-L2 lexicon we mention is identical to the cor-
responding L2-L1 lexicon in the set of translation
pairs it contains. Our lexicon is thus the ‘noisi-
est’ that can be generated using a pivot language
and two source-pivot-target lexicons, but it also
provides the most complete candidate set possible.
Ignoring directionality is also in accordance with
the reversibility principle of the lexicographic lit-
erature (Tomaszczyk, 1998).
Table 2 details the sizes and branching factors
(BF) (the average number of translations for head-
word) of the input lexicons, as well as those of the
generated initial noisy lexicon.
</bodyText>
<sectionHeader confidence="0.521183" genericHeader="method">
4.1.3 Baseline
</sectionHeader>
<bodyText confidence="0.9999096">
The performance of our method was compared to
three baselines: Inverse Consultation (IC), average
cosine distance, and average city block distance.
The first is a completely different algorithm, and
the last two are a version of our algorithm in which
</bodyText>
<footnote confidence="0.701828">
3www.babylon.com.
</footnote>
<bodyText confidence="0.998880166666667">
the NAS score is replaced by other scores.
IC (see section 2.2.1) is a corpus-less method.
It ranks t1, t2, ..., the candidate translations of a
source word s, by the size of the intersections of
the sets of pivot translations of ti and s. Note that
IC ranking is a partial order, as the intersection
size may be the same for many candidate transla-
tions. IC is a baseline for our algorithm as a whole.
Cosine and city block distances are widely
used methods for calculating distances of vectors
within the same vector space. They are defined
here as4
</bodyText>
<equation confidence="0.9774245">
� viui
Cosine(v, u) = 1 − √� vi � ui
CityBlock(v, u) = − � |vi − ui|
i
</equation>
<bodyText confidence="0.999838375">
In the case of context vectors, the vector in-
dices, or keys, are words, and their values are co-
occurrence based scores. We used the words in
our signatures as context vector keys, and PMI
scores as values. In this way, the two scores are
‘plugged’ into our method and serve as baselines
for our NAS similarity score.
Since the context vectors are in different lan-
guages, we had to translate, or align, the baseline
context vectors for the source and target words.
Our initial lexicon is a many-to-many relation, so
multiple alignments were possible; in fact, the
number of possible alignments tends to be very
large5. We therefore generated M random possible
alignments, and used the average distance metric
across these alignments.
</bodyText>
<subsectionHeader confidence="0.992767">
4.1.4 Test Sets and Gold Standard
</subsectionHeader>
<bodyText confidence="0.999922333333333">
Following other works (e.g. (Rapp, 1999)), and to
simplify the experimental setup, we focused in our
experiments on nouns.
A p-q frequency range in a corpus is the set of
tokens in the places between p and q in the list of
corpus tokens, sorted by frequency from high to
low. Two types of test sets were used. The first
(R1) includes all the singular, correctly segmented
(in Hebrew) nouns among the 500 words in the
1001-1500 frequency range. The 1000 highest-
frequency tokens were discarded, as a large num-
ber of these are utilized as auxiliary syntactic
</bodyText>
<footnote confidence="0.999965333333333">
4We modified the standard cosine and city block metrics
so that for all measures higher values would be better.
5This is another advantage of our NAS score.
</footnote>
<page confidence="0.993521">
102
</page>
<table confidence="0.998927833333333">
R1 R2
Precision Recall Precision Recall
NAS 82.1% 100% 56% 100%
Cosine 60.7% 100% 28% 100%
City block 56.3% 100% 32% 100%
IC 55.2% 85.7% 52% 88%
</table>
<tableCaption confidence="0.986747">
Table 3: Hebrew-Spanish lexicon generation:
highest-ranking translation.
</tableCaption>
<table confidence="0.999599">
R1 R2
Precision Recall Precision Recall
NAS 87.6% 100% 80% 100%
Cosine 68% 100% 44% 100%
City block 69.8% 100% 36% 100%
IC 76.4% 100% 48% 92%
</table>
<tableCaption confidence="0.9597215">
Table 4: Spanish-Hebrew Lexicon Generation:
highest-ranking translation.
</tableCaption>
<bodyText confidence="0.999667526315789">
words. This yielded a test set of 112 Hebrew
nouns and 169 Spanish nouns. The second (R2),
contains 25 words for each of the two languages,
obtained by randomly selecting 5 singular cor-
rectly segmented nouns from each of the 5 fre-
quency ranges 1-1000 to 4001-5000.
For each of the test words, the correct transla-
tions were extracted from a modern professional
concise printed Hebrew-Spanish-Hebrew dictio-
nary (Prolog, 2003). This dictionary almost al-
ways provides a single Spanish translation for He-
brew headwords. Spanish headwords had 1.98 He-
brew translations on the average. In both cases
this is a small number of correct translation com-
paring to what we might expect with other evalu-
ation methods; therefore this evaluation amounts
to a relatively high standard of correctness. Our
score comparison experiments (section 5) extend
the evaluation beyond this gold standard.
</bodyText>
<subsectionHeader confidence="0.72495">
4.1.5 Parameters
</subsectionHeader>
<bodyText confidence="0.999984375">
The following parameter values were used. The
window size for co-occurrence counting, k, was 4.
This value was chosen in a small pre-test. Signa-
ture size N was 200 (see Section 6.1). The number
of alignments M for the baseline scores was 100.
The number of translations selected for each head-
word, t, was set to 1 for ease of testing, but see
further notes under results.
</bodyText>
<sectionHeader confidence="0.525779" genericHeader="method">
4.2 Results
</sectionHeader>
<bodyText confidence="0.99982316">
Tables 3 and 4 summarize the results of the
Hebrew-Spanish and Spanish-Hebrew lexicon
generation respectively, for both the R1 and R2
test sets.
In the three co-occurrence based methods, NAS
similarity, cosine distance and and city block dis-
tance, the highest ranking translation was selected.
Recall is always 100% as a translation from the
candidate set is always selected, and all of this set
is valid. Precision is computed as the number of
test words whose selected translation was one of
the translations in the gold standard.
IC translations ranking is a partial order, as usu-
ally many translations are scored equally. When
all translations have the same score, IC is effec-
tively undecided. We calculate recall as the per-
centage of cases in which there was more than one
score rank. A result was counted as precise if any
of the highest-ranking translations was in the gold-
standard, even if other translations were equally
ranked, creating a bias in favor of IC.
In both of the Hebrew-Spanish and the Spanish-
Hebrew cases, our method significantly outper-
formed all baselines in generating a precise lexi-
con on the highest-ranking translations.
All methods performed better in R1 than in
R2, which included also lower-frequency words,
and this was more noticeable with the corpus-
based methods (Hebrew-Spanish) than with IC.
This suggests, not surprisingly, that the perfor-
mance of corpus-based methods is related to the
amount of information in the corpus.
That the results for the Spanish-Hebrew lexi-
con are higher may arise from the difference in the
gold standard. As mentioned, Hebrew words only
had one “correct” Spanish translation, while Span-
ish had 1.98 correct translations on the average.
If we had used a more comprehensive resource to
test against, the precision of the method would be
higher than shown here.
In translation pairs generation, the results be-
yond the top-ranking pair are also of importance.
Tables 5 and 6 present the accuracy of the first
three translation suggestions, for the three co-
occurrence based scores, calculated for the R1 test
set. IC results are not included, as they are incom-
parable to those of the other methods: IC tends to
score many candidate translations identically, and
in practice, the three highest-scoring sets of trans-
lation candidates contained on average 77% of all
</bodyText>
<page confidence="0.998163">
103
</page>
<table confidence="0.999571">
1st 2nd 3rd total
NAS 82.1% 6.3% 1.8% 90.2%
Cosine 60.7% 9.8% 2.7% 73.2%
City block 56.3% 4.5% 10.7% 71.4%
</table>
<tableCaption confidence="0.983426">
Table 5: Hebrew-Spanish lexicon generation: ac-
</tableCaption>
<bodyText confidence="0.767738">
curacy of 3 best translations for the R1 condition.
The table shows how many of the 2nd and 3rd
translations are correct. Note that NAS is always
a better solution, even though its numbers for 2nd
and 3rd are smaller, because its accumulative per-
centage, shown in the last column, is higher.
</bodyText>
<table confidence="0.99824825">
1st 2nd 3rd total
NAS 87.6% 77.5% 16% 163.9%
Cosine 68% 66.3% 10.1% 144.4%
City block 69.8% 64.5% 7.7% 142%
</table>
<tableCaption confidence="0.974091">
Table 6: Spanish-Hebrew lexicon generation: ac-
</tableCaption>
<bodyText confidence="0.995148166666667">
curacy of 3 best translations for the R1 condition.
The total exceeds 100% because Spanish words
had more than one correct translation. See also
the caption of Table 5.
the candidates, thus necessarily yielding mostly
incorrect translations. Recall was omitted from the
tables as it is always 100%.
For all methods, many of the correct translations
that do not rank first, rank as second or third. For
both languages, NAS ranks highest for total ac-
curacy of the three translations, with considerable
advantage.
</bodyText>
<sectionHeader confidence="0.977914" genericHeader="method">
5 Score Comparison Experiments
</sectionHeader>
<bodyText confidence="0.990361666666667">
Lexicon generation, as defined in our experiment,
is a relatively high standard for cross-linguistic se-
mantic distance evaluation. This is especially cor-
</bodyText>
<table confidence="0.9307904">
Heb-Spa Spa-Heb
SCE1 SCE2 SCE1 SCE2
NAS 93.8% 76.2% 94.1% 83.7%
Cosine 74.1% 57.1% 70.7% 63.2%
City block 74.1% 68.3% 78,1% 75.2%
</table>
<tableCaption confidence="0.994636">
Table 7: Precision of score comparison experi-
</tableCaption>
<bodyText confidence="0.998685763636364">
ments. The percentage of cases in which each
of the scoring methods was able to successfully
distinguish the correct (SCE1) or possible correct
(SCE2) translation from the random translation.
rect since our gold standard gives only a small set
of translations. The set of possible translations in
iLex tends to include, besides the “correct” transla-
tion of the gold standard, other translations that are
suitable in certain contexts or are semantically re-
lated. For example, for one Hebrew word, kvuza,
the gold standard translation was grupo (group),
while our method chose equipo (team), which was
at least as plausible given the amount of sports
news in the corpus.
Thus to better compare the capability of NAS to
distinguish correct and incorrect translations with
that of other scores, we performed two more ex-
periments. In the first score comparison experi-
ment (SCE1), we used the two R1 test sets, He-
brew and Spanish, from the lexicon generation test
(section 4.1.4). For each word in the test set, we
used our method to select between one of two
translations: a correct translation, from the gold
standard, and a random translation, chosen ran-
domly among all the nouns similar in frequency
to the correct translation.
The second score comparison experiment
(SCE2) was designed to test the score with a more
extensive test set. For each of the two languages,
we randomly selected 1000 nouns, and used our
method to select between a possibly correct trans-
lation, chosen randomly among the translations
suggested in iLex, and a random translation, cho-
sen randomly among nouns similar in frequency
to the possibly correct translation. This test, while
using a more extensive test set, is less accurate
because it is not guaranteed that any of the input
translations is correct.
In both SCE1 and SCE2, cosine and city block
distance were used as baselines. Inverse Consul-
tation is irrelevant here because it can only score
translation pairs that appear in iLex.
Table 7 presents the results of the two score
comparison experiments, each of them for each of
the translation directions. Recall is by definition
100% and is omitted.
Again, NAS performs better than the baselines
in all cases. With all scores, precision values in
SCE1 are higher than in the lexicon generation
experiment. This is consistent with the expecta-
tion that selection between a correct and a ran-
dom, probably incorrect, translation is easier than
selecting among the translations in iLex. The pre-
cision in SCE2 is lower than that in SCE1. This
may be a result of both translations in SCE2 being
</bodyText>
<page confidence="0.997802">
104
</page>
<figureCaption confidence="0.962293666666667">
Figure 1: NAS values (not algorithm precision) for
various N sizes. NAS is not sensitive to the value
of N (see text).
</figureCaption>
<bodyText confidence="0.909435">
in some cases incorrect. Yet this may also reflect a
weakness of all three scores with lower-frequency
words, which are represented in the 1000-word
samples but not in the ones used in SCE1.
</bodyText>
<sectionHeader confidence="0.995182" genericHeader="method">
6 NAS Score Properties
</sectionHeader>
<subsectionHeader confidence="0.996356">
6.1 Signature Size
</subsectionHeader>
<bodyText confidence="0.999894961538461">
NAS values are in the range [0, 1]. The values de-
pend on N, the size of the signature used. With an
extremely small N, NAS values would usually be
0, and would tend to be noisy, due to accidental
inclusion of high-frequency or highly ambiguous
words in the signature. As N approaches the size
of the lexicon used for alignment, NAS values ap-
proach 1 for all word pairs.
This suggests that choosing a suitable value of
N is critical for effectively using NAS. Yet an em-
pirical test has shown that NAS may be useful for
a wide range of N values: we computed NAS val-
ues for the correct and random translations used
in the Hebrew-Spanish SCE1 experiment (section
5), using N values between 50 and 2000.
Figure 1 shows the average score values (note
that these are not precision values) for the correct
and random translations across that N range. The
scores for the correct translations are consistently
higher than those of the random translations, even
while there is a discernible decline in the differ-
ence between them. In fact, the precision of the se-
lection between the correct and random translation
is persistent throughout the range. This suggests
that while extreme N values should be avoided, the
selection of N is not a major issue.
</bodyText>
<subsectionHeader confidence="0.995737">
6.2 Dependency on Alignment Lexicon
</subsectionHeader>
<bodyText confidence="0.999948777777778">
NA5L values depend on L, the lexicon in use.
Clearly again, in the extremes, an almost empty
lexicon or a lexicon containing every possible pair
of words (a Cartesian product), this score would
not be useful. In the first case, it would yield 0
for every pair, and in the second, 1. However as
our experiments show, it performed well with real-
world examples of a noisy lexicon, with branching
factors of 12.6 and 14.8 (see table 2).
</bodyText>
<subsectionHeader confidence="0.993262">
6.3 Lemmatization
</subsectionHeader>
<bodyText confidence="0.999971">
Lemmatization is the process of extracting the
lemmas of words in the corpus. Our experiments
show that good results can be achieved without
lemmatization, at least for nouns in the pair of lan-
guages tested (aside from the simple prefix seg-
mentation we used for Hebrew, see section 4.1.1).
For other language pairs lemmatization may be
needed. In general, correct lemmatization should
improve results, since the signatures would con-
sist of more meaningful information. If automatic
lemmatization introduces noise, it may reduce the
results’ quality.
</bodyText>
<subsectionHeader confidence="0.951339">
6.4 Alternative Models for Relatedness
</subsectionHeader>
<bodyText confidence="0.999970615384615">
Cosine and city block, as well as other related dis-
tance metrics, rely on context vectors. The context
vector of a word w collects words and maps them
to some score of their “relatedness” to w; in this
case, we used PMI. NAS, in contrast, relies on the
signature, the set of N words most related to w.
That is, it requires a Boolean relatedness indica-
tion, rather than a numeric relatedness score. We
used PMI to generate this Boolean indication, and
naturally, other similar measures could be used as
well. More significantly, it may be possible to use
it with corpus-less sources of “relatedness”, such
as WordNet or search result snippets.
</bodyText>
<sectionHeader confidence="0.998485" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999863666666667">
We presented a method to create a high quality
bilingual lexicon given a noisy one. We focused
on the case in which the noisy lexicon is created
using two pivot language lexicons. Our algorithm
uses two unrelated monolingual corpora. At the
heart of our method is the non-aligned signatures
(NAS) context similarity score, used for remov-
ing incorrect translations using cross-lingual co-
occurrences.
</bodyText>
<page confidence="0.997619">
105
</page>
<bodyText confidence="0.999987666666667">
Words in one language tend to have multiple
translations in another. The common method for
context similarity scoring utilizes some algebraic
distance between context vectors, and requires a
single alignment of context vectors in one lan-
guage into the other. Finding a single correct
alignment is unrealistic even when a perfectly cor-
rect lexicon is available. For example, alignment
forces us to choose one correct translation for each
context word, while in practice a few possible
terms may be used interchangeably in the other
language. In our task, moreover, the lexicon used
for alignment was automatically generated from
pivot language lexicons and was expected to con-
tain errors.
NAS does not depend on finding a single correct
alignment. While it measures how well the sets of
words that tend to co-occur with these two words
align to each other, its strength may lie in bypass-
ing the question of which word in one language
should be aligned to a certain context word in the
other language. Therefore, unlike other scoring
methods, it is not effected by incorrect alignments.
We have shown that NAS outperforms the more
traditional distance metrics, which we adapted to
the many-to-many scenario by amortizing across
multiple alignments. Our results confirm that
alignment is problematic in using co-occurrence
methods across languages, at least in our settings.
NAS constitutes a way to avoid this problem.
While the purpose of this work was to discern
correct translations from incorrect one, it is worth
noting that our method actually ranks translation
correctness. This is a stronger property, which
may render it useful in a wider range of scenarios.
In fact, NAS can be viewed as a general mea-
sure for word similarity between languages. It
would be interesting to further investigate this ob-
servation with other sources of lexicons (e.g., ob-
tained from parallel or comparable corpora) and
for other tasks, such as cross-lingual word sense
disambiguation and information retrieval.
</bodyText>
<sectionHeader confidence="0.999474" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999813482758621">
Kisuh Ahn and Matthew Frampton. 2006. Automatic
generation of translation dictionaries using interme-
diary languages. In EACL 2006 Workshop on Cross-
Language Knowledge Induction.
Francis Bond, Ruhaida Binti Sulong, Takefumi Ya-
mazaki, and Kentaro Ogura. 2001. Design and con-
struction of a machine-tractable japanese-malay dic-
tionary. In MT Summit VIII: Machine Translation in
the Information Age, Proceedings, pages 53–58.
Kenneth W. Church and Patrick Hanks. 1990. Word
association norms, mutual information, and lexicog-
raphy. Computational Linguistics, 16:22–29.
Elad Dinur, Dmitry Davidov, and Ari Rappoport. 2009.
Unsupervised concept discovery in hebrew using
simple unsupervised word prefix segmentation for
hebrew and arabic. In EACL 2009 Workshop on
Computational Approaches to Semitic Languages.
Pascale Fung. 1998. A statistical view on bilin-
gual lexicon extraction:from parallel corpora to non-
parallel corpora. In The Third Conference of the As-
sociation for Machine Translation in the Americas.
Nikesh Garera, Chris Callison-Burch, and David
Yarowsky. 2009. Improving translation lexi-
con induction from monolingual corpora via depen-
dency contexts and part-of-speech equivalences. In
CoNLL.
Hiroyuki Kaji and Toshiko Aizono. 1996. Extracting
word correspondences from bilingual corpora based
on word co-occurrence information. In COLING.
Hiroyuki Kaji, Shin’ichi Tamamura, and Dashtseren
Erdenebat. 2008. Automatic construction of a
japanese-chinese dictionary via english. In LREC.
Philipp Koehn and Kevin Knight. 2002. Learn-
ing a translation lexicon from monolingual corpora.
In Proceedings of ACL Workshop on Unsupervised
Lexical Acquisition.
Adam Lopez. 2008. Statistical machine translation.
ACM Computing Surveys, 40(3):1–49.
Mausam, Stephen Soderland, Oren Etzioni, Daniel S.
Weld, Michael Skinner, and Jeff Bilmes. 2009.
Compiling a massive, multilingual dictionary via
probabilistic inference. In Proceedings of the 47th
Annual Meeting of the Association for Computa-
tional Linguistics and 4th International Joint Con-
ference on Natural Language Processing.
Kyonghee Paik, Satoshi Shirai, and Hiromi Nakaiwa.
2004. Automatic construction of a transfer dictio-
nary considering directionality. In COLING, Multi-
lingual Linguistic Resources Workshop.
Viktor Pekar, Ruslan Mitkov, Dimitar Blagoev, and An-
drea Mulloni. 2006. Finding translations for low-
frequency words in comparable corpora. Machine
Translation, 20:247 – 266.
Prolog. 2003. Practical Bilingual Dictionary:
Spanish-Hebew/Hebrew-Spanish. Israel.
Reinhard Rapp. 1999. Automatic identification of
word translations from unrelated english and german
corpora. In ACL.
</reference>
<page confidence="0.934783">
106
</page>
<reference confidence="0.9997138">
Charles Schafer and David Yarowsky. 2002. Inducing
translation lexicons via diverse similarity measures
and bridge languages. In CoNLL.
Hana Skoumalova. 2001. Bridge dictionaries as
bridges between languages. International Journal
of Corpus Linguistics, 6:95–105.
Kumiko Tanaka and Hideya Iwasaki. 1996. Extraction
of lexical translations from non-aligned corpora. In
Conference on Computational linguistics.
Kumiko Tanaka and Kyoji Umemura. 1994. Construc-
tion of a bilingual dictionary intermediated by a third
language. In Conference on Computational Linguis-
tics.
Jerzy Tomaszczyk. 1998. The bilingual dictionary un-
der review. In ZuriLEX’86.
</reference>
<page confidence="0.998703">
107
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.976337">
<title confidence="0.999484">Bilingual Lexicon Generation Using Non-Aligned Signatures</title>
<author confidence="0.999749">Daphna Shezaf</author>
<affiliation confidence="0.9995175">Institute of Computer Science Hebrew University of Jerusalem</affiliation>
<email confidence="0.995481">daphna.shezaf@mail.huji.ac.il</email>
<author confidence="0.996661">Ari Rappoport</author>
<affiliation confidence="0.999829">Institute of Computer Science Hebrew University of Jerusalem</affiliation>
<email confidence="0.995011">arir@cs.huji.ac.il</email>
<abstract confidence="0.999607478260869">Bilingual lexicons are fundamental resources. Modern automated lexicon generation methods usually require parallel corpora, which are not available for most language pairs. Lexicons can be generated using non-parallel corpora or a pivot language, but such lexicons are noisy. We present an algorithm for generating a high quality lexicon from a noisy one, which only requires an independent corpus for each language. Our algorithm insignatures a cross-lingual word context similarity score that avoids the over-constrained and inefficient nature of alignment-based methods. We use NAS to eliminate incorrect translations from the generated lexicon. We evaluate our method by improving the quality of noisy Spanish-Hebrew lexicons generated from two pivot English lexicons. Our algorithm substantially outperforms other lexicon generation methods.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kisuh Ahn</author>
<author>Matthew Frampton</author>
</authors>
<title>Automatic generation of translation dictionaries using intermediary languages.</title>
<date>2006</date>
<booktitle>In EACL 2006 Workshop on CrossLanguage Knowledge Induction.</booktitle>
<contexts>
<context position="6483" citStr="Ahn and Frampton, 2006" startWordPosition="988" endWordPosition="991">source-language word w, and the set of pivot translations of each target-language word that is a candidate for being a translation to w. IC generally requires that the intersection set contains at least two words, which are synonyms. For example, the intersection of the English translations of French printemps and Spanish resorte contains only a single word, spring. The intersection for a correct translation pair printemps and primavera may include two synonym words, spring and springtime. Variations of this method were proposed by (Kaji and Aizono, 1996; Bond et al., 2001; Paik et al., 2004; Ahn and Frampton, 2006). One weakness of IC is that it relies on pivot language synonyms to identify correct translations. In the above example, if the relatively rare springtime had not existed or was missing from the input lexicons, IC would not have been able to discern that primavera is a correct translation. This may result in low recall. 2.2.2 Multiple Pivot Languages Mausam et al. (2009) used many input bilingual lexicons to create bilingual lexicons for new language pairs. They represent the multiple input lexicons in a single undirected graph, with words from all the lexicons as nodes. The input lexicons tr</context>
</contexts>
<marker>Ahn, Frampton, 2006</marker>
<rawString>Kisuh Ahn and Matthew Frampton. 2006. Automatic generation of translation dictionaries using intermediary languages. In EACL 2006 Workshop on CrossLanguage Knowledge Induction.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Francis Bond</author>
</authors>
<title>Ruhaida Binti Sulong, Takefumi Yamazaki, and Kentaro Ogura.</title>
<date>2001</date>
<booktitle>In MT Summit VIII: Machine Translation in the Information Age, Proceedings,</booktitle>
<pages>53--58</pages>
<marker>Bond, 2001</marker>
<rawString>Francis Bond, Ruhaida Binti Sulong, Takefumi Yamazaki, and Kentaro Ogura. 2001. Design and construction of a machine-tractable japanese-malay dictionary. In MT Summit VIII: Machine Translation in the Information Age, Proceedings, pages 53–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth W Church</author>
<author>Patrick Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--22</pages>
<contexts>
<context position="14019" citStr="Church and Hanks, 1990" startWordPosition="2202" endWordPosition="2205">the directions reversed. 3.3 Signatures The signature of a word w in a language is the set of N words most strongly related to w. There are various possible ways to formalize this notion. We use a common and simple one, the words having the highest tendency to co-occur with w in a corpus. We count co-occurrences using a sliding fixed-length window of size k. We compute, for each pair of words, their Pointwise Mutual Information (PMI), that is: PMI(w1,w2) = log Pr(w1)Pr(w2) Pr(w1, w2) where Pr(w1, w2) is the co-occurrence count, and Pr(wi) is the total number of appearance of wi in the corpus (Church and Hanks, 1990). We define the signature G(w)N,k of w to be the set of N words with the highest PMI with w. Note that a word’s signature includes words in the same language. Therefore, two signatures of words in different languages cannot be directly compared; we compare them using a lexicon L as explained below. Signature is a function of w parameterized by N and k. We discuss the selection of these parameters in section 4.1.5. 3.4 Non-aligned Signatures (NAS) Similarity Scoring The core strength of our method lies in the way in which we evaluate similarity between words in the source and target languages. </context>
</contexts>
<marker>Church, Hanks, 1990</marker>
<rawString>Kenneth W. Church and Patrick Hanks. 1990. Word association norms, mutual information, and lexicography. Computational Linguistics, 16:22–29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elad Dinur</author>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic.</title>
<date>2009</date>
<booktitle>In EACL 2009 Workshop on Computational Approaches to Semitic Languages.</booktitle>
<contexts>
<context position="16305" citStr="Dinur et al., 2009" startWordPosition="2586" endWordPosition="2589">1.1 Corpora The Hebrew and Spanish corpora were extracted from Israeli and Spanish newspaper websites respectively (see table 1 for details). Crawling a small number of sites allowed us to use specialtailored software to extract the textual data from the web pages, thus improving the quality of the extracted texts. Our two corpora are comparable in their domains, news and news commentary. No kind of preprocessing was used for the Spanish corpus. For Hebrew, closed-class words that are attached to the succeeding word (e.g., ‘the’, ‘and’, ‘in’) were segmented using a simple unsupervised method (Dinur et al., 2009). This method compares the corpus frequencies of the non-prefixed form x and the prefixed form wx. If x is frequent enough, it is assumed to be the correct form, and all the occurrences of wx are segmented into two tokens, w x. This method was chosen for being simple and effective. However, the segmentation it produces is not perfect. It is context insensitive, segmenting all appearances of a token in the same way, while many wx forms are actually ambiguous. Even unambiguous token segmentations may fail when the non-segmented form is very frequent in the domain. 2Old testament corpora are for </context>
</contexts>
<marker>Dinur, Davidov, Rappoport, 2009</marker>
<rawString>Elad Dinur, Dmitry Davidov, and Ari Rappoport. 2009. Unsupervised concept discovery in hebrew using simple unsupervised word prefix segmentation for hebrew and arabic. In EACL 2009 Workshop on Computational Approaches to Semitic Languages.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pascale Fung</author>
</authors>
<title>A statistical view on bilingual lexicon extraction:from parallel corpora to nonparallel corpora.</title>
<date>1998</date>
<booktitle>In The Third Conference of the Association for Machine Translation in the Americas.</booktitle>
<contexts>
<context position="8671" citStr="Fung (1998)" startWordPosition="1344" endWordPosition="1345"> the semantic fields of headwords in the same way. Thus the first translation of some English headword in the English-Spanish and in the English-Hebrew dictionaries would correspond to the same sense of the headword, and would therefore constitute translations of each other. The applicability of this method is limited by the availability of machine-readable dictionaries produced by the same publishing house. Not surprisingly, this method has been proposed by lexicographers working in such companies (Sk99 oumalova, 2001). 2.3 Cross-lingual Co-occurrences in Lexicon Construction Rapp (1999) and Fung (1998) discussed semantic similarity estimation using cross-lingual context vector alignment. Both works rely on a pre-existing large (16-20K entries), correct, oneto-one lexicon between the source and target languages, which is used to align context vectors between languages. The context vector data was extracted from comparable (monolingual but domain-related) corpora. Koehn and Knight (2002) were able to do without the initial large lexicon by limiting themselves to related languages that share a writing system, and using identicallyspelled words as context words. Garera et al. (2009) and Pekar e</context>
</contexts>
<marker>Fung, 1998</marker>
<rawString>Pascale Fung. 1998. A statistical view on bilingual lexicon extraction:from parallel corpora to nonparallel corpora. In The Third Conference of the Association for Machine Translation in the Americas.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nikesh Garera</author>
<author>Chris Callison-Burch</author>
<author>David Yarowsky</author>
</authors>
<title>Improving translation lexicon induction from monolingual corpora via dependency contexts and part-of-speech equivalences.</title>
<date>2009</date>
<booktitle>In CoNLL.</booktitle>
<contexts>
<context position="9259" citStr="Garera et al. (2009)" startWordPosition="1431" endWordPosition="1434">tion Rapp (1999) and Fung (1998) discussed semantic similarity estimation using cross-lingual context vector alignment. Both works rely on a pre-existing large (16-20K entries), correct, oneto-one lexicon between the source and target languages, which is used to align context vectors between languages. The context vector data was extracted from comparable (monolingual but domain-related) corpora. Koehn and Knight (2002) were able to do without the initial large lexicon by limiting themselves to related languages that share a writing system, and using identicallyspelled words as context words. Garera et al. (2009) and Pekar et al. (2006) suggested different methods for improving the context vectors data in each language before aligning them. Garera et al. (2009) replaced the traditional window-based cooccurrence counting with dependency-tree based counting, while Pekar et al. (2006) predicted missing co-occurrence values based on similar words in the same language. In the latter work, the oneto-one lexicon assumption was not made: when a context word had multiple equivalents, it was mapped into all of them, with the original probability equally distributed between them. Pivot Language. Using cross-ling</context>
</contexts>
<marker>Garera, Callison-Burch, Yarowsky, 2009</marker>
<rawString>Nikesh Garera, Chris Callison-Burch, and David Yarowsky. 2009. Improving translation lexicon induction from monolingual corpora via dependency contexts and part-of-speech equivalences. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Kaji</author>
<author>Toshiko Aizono</author>
</authors>
<title>Extracting word correspondences from bilingual corpora based on word co-occurrence information.</title>
<date>1996</date>
<booktitle>In COLING.</booktitle>
<contexts>
<context position="6420" citStr="Kaji and Aizono, 1996" startWordPosition="976" endWordPosition="979"> two pivot language sets: the set of pivot translations of a source-language word w, and the set of pivot translations of each target-language word that is a candidate for being a translation to w. IC generally requires that the intersection set contains at least two words, which are synonyms. For example, the intersection of the English translations of French printemps and Spanish resorte contains only a single word, spring. The intersection for a correct translation pair printemps and primavera may include two synonym words, spring and springtime. Variations of this method were proposed by (Kaji and Aizono, 1996; Bond et al., 2001; Paik et al., 2004; Ahn and Frampton, 2006). One weakness of IC is that it relies on pivot language synonyms to identify correct translations. In the above example, if the relatively rare springtime had not existed or was missing from the input lexicons, IC would not have been able to discern that primavera is a correct translation. This may result in low recall. 2.2.2 Multiple Pivot Languages Mausam et al. (2009) used many input bilingual lexicons to create bilingual lexicons for new language pairs. They represent the multiple input lexicons in a single undirected graph, w</context>
</contexts>
<marker>Kaji, Aizono, 1996</marker>
<rawString>Hiroyuki Kaji and Toshiko Aizono. 1996. Extracting word correspondences from bilingual corpora based on word co-occurrence information. In COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroyuki Kaji</author>
<author>Shin’ichi Tamamura</author>
<author>Dashtseren Erdenebat</author>
</authors>
<title>Automatic construction of a japanese-chinese dictionary via english. In LREC.</title>
<date>2008</date>
<contexts>
<context position="10477" citStr="Kaji et al. (2008)" startWordPosition="1617" endWordPosition="1620">ual cooccurrences to improve a lexicon generated using a pivot language was suggested by Tanaka and Iwasaki (1996). Schafer and Yarowsky (2002) created lexicons between English and a target local language (e.g. Gujarati) using a related language (e.g. Hindi) as pivot. An English pivot lexicon was used in conjunction with pivot-target cognates. Cross-lingual co-occurrences were used to remove errors, together with other cues such as edit distance and Inverse Document Frequencies (IDF) scores. It appears that this work assumed a single alignment was possible from English to the target language. Kaji et al. (2008) used a pivot English lexicon to generate initial Japanese-Chinese and ChineseJapanese lexicons, then used co-occurrences information, aligned using the initial lexicon, to identify correct translations. Unlike other works, which require alignments of pairs (i.e., two cooccurring words in one language translatable into two co-occurring words in the other), this method relies on alignments of 3-word cliques in each language, every pair of which frequently cooccurring. This is a relatively rare occurrence, which may explain the low recall rates of their results. 3 Algorithm Our algorithm transfo</context>
</contexts>
<marker>Kaji, Tamamura, Erdenebat, 2008</marker>
<rawString>Hiroyuki Kaji, Shin’ichi Tamamura, and Dashtseren Erdenebat. 2008. Automatic construction of a japanese-chinese dictionary via english. In LREC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philipp Koehn</author>
<author>Kevin Knight</author>
</authors>
<title>Learning a translation lexicon from monolingual corpora.</title>
<date>2002</date>
<booktitle>In Proceedings of ACL Workshop on Unsupervised Lexical Acquisition.</booktitle>
<contexts>
<context position="9062" citStr="Koehn and Knight (2002)" startWordPosition="1398" endWordPosition="1401">ed by the same publishing house. Not surprisingly, this method has been proposed by lexicographers working in such companies (Sk99 oumalova, 2001). 2.3 Cross-lingual Co-occurrences in Lexicon Construction Rapp (1999) and Fung (1998) discussed semantic similarity estimation using cross-lingual context vector alignment. Both works rely on a pre-existing large (16-20K entries), correct, oneto-one lexicon between the source and target languages, which is used to align context vectors between languages. The context vector data was extracted from comparable (monolingual but domain-related) corpora. Koehn and Knight (2002) were able to do without the initial large lexicon by limiting themselves to related languages that share a writing system, and using identicallyspelled words as context words. Garera et al. (2009) and Pekar et al. (2006) suggested different methods for improving the context vectors data in each language before aligning them. Garera et al. (2009) replaced the traditional window-based cooccurrence counting with dependency-tree based counting, while Pekar et al. (2006) predicted missing co-occurrence values based on similar words in the same language. In the latter work, the oneto-one lexicon as</context>
</contexts>
<marker>Koehn, Knight, 2002</marker>
<rawString>Philipp Koehn and Kevin Knight. 2002. Learning a translation lexicon from monolingual corpora. In Proceedings of ACL Workshop on Unsupervised Lexical Acquisition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Lopez</author>
</authors>
<title>Statistical machine translation.</title>
<date>2008</date>
<journal>ACM Computing Surveys,</journal>
<volume>40</volume>
<issue>3</issue>
<contexts>
<context position="5410" citStr="Lopez, 2008" startWordPosition="820" endWordPosition="821">blishing house. We show that the algorithm outperforms existing algorithms for handling divergence induced by lexical intransitivity. 2 Previous Work 2.1 Parallel Corpora Parallel corpora are often used to infer wordoriented machine-readable bilingual lexicons. The texts are aligned to each other, at chunk- and/or word-level. Alignment is generally evaluated by consistency (source words should be translated to a small number of target words over the entire corpus) and minimal shifting (in each occurrence, the source should be aligned to a translation nearby). For a review of such methods see (Lopez, 2008). The limited availability of parallel corpora of sufficient size for most language pairs restricts the usefulness of these methods. 2.2 Pivot Language Without Corpora 2.2.1 Inverse Consultation Tanaka and Umemura (1994) generated a bilingual lexicon using a pivot language. They approached lexical intransitivity divergence using Inverse Consultation (IC). IC examines the intersection of two pivot language sets: the set of pivot translations of a source-language word w, and the set of pivot translations of each target-language word that is a candidate for being a translation to w. IC generally </context>
</contexts>
<marker>Lopez, 2008</marker>
<rawString>Adam Lopez. 2008. Statistical machine translation. ACM Computing Surveys, 40(3):1–49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Soderland Mausam</author>
<author>Oren Etzioni</author>
<author>Daniel S Weld</author>
<author>Michael Skinner</author>
<author>Jeff Bilmes</author>
</authors>
<title>Compiling a massive, multilingual dictionary via probabilistic inference.</title>
<date>2009</date>
<booktitle>In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and 4th International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="6857" citStr="Mausam et al. (2009)" startWordPosition="1053" endWordPosition="1056">rsection for a correct translation pair printemps and primavera may include two synonym words, spring and springtime. Variations of this method were proposed by (Kaji and Aizono, 1996; Bond et al., 2001; Paik et al., 2004; Ahn and Frampton, 2006). One weakness of IC is that it relies on pivot language synonyms to identify correct translations. In the above example, if the relatively rare springtime had not existed or was missing from the input lexicons, IC would not have been able to discern that primavera is a correct translation. This may result in low recall. 2.2.2 Multiple Pivot Languages Mausam et al. (2009) used many input bilingual lexicons to create bilingual lexicons for new language pairs. They represent the multiple input lexicons in a single undirected graph, with words from all the lexicons as nodes. The input lexicons translation pairs define the edges in the graph. New translation pairs are inferred based on cycles in the graph, that is, the existence of multiple paths between two words in different languages. In a sense, this is a generalization of the pivot language idea, where multiple pivots are used. In the example above, if both English and German are used as pivots, printemps and</context>
</contexts>
<marker>Mausam, Etzioni, Weld, Skinner, Bilmes, 2009</marker>
<rawString>Mausam, Stephen Soderland, Oren Etzioni, Daniel S. Weld, Michael Skinner, and Jeff Bilmes. 2009. Compiling a massive, multilingual dictionary via probabilistic inference. In Proceedings of the 47th Annual Meeting of the Association for Computational Linguistics and 4th International Joint Conference on Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kyonghee Paik</author>
<author>Satoshi Shirai</author>
<author>Hiromi Nakaiwa</author>
</authors>
<title>Automatic construction of a transfer dictionary considering directionality.</title>
<date>2004</date>
<booktitle>In COLING, Multilingual Linguistic Resources Workshop.</booktitle>
<contexts>
<context position="6458" citStr="Paik et al., 2004" startWordPosition="984" endWordPosition="987"> translations of a source-language word w, and the set of pivot translations of each target-language word that is a candidate for being a translation to w. IC generally requires that the intersection set contains at least two words, which are synonyms. For example, the intersection of the English translations of French printemps and Spanish resorte contains only a single word, spring. The intersection for a correct translation pair printemps and primavera may include two synonym words, spring and springtime. Variations of this method were proposed by (Kaji and Aizono, 1996; Bond et al., 2001; Paik et al., 2004; Ahn and Frampton, 2006). One weakness of IC is that it relies on pivot language synonyms to identify correct translations. In the above example, if the relatively rare springtime had not existed or was missing from the input lexicons, IC would not have been able to discern that primavera is a correct translation. This may result in low recall. 2.2.2 Multiple Pivot Languages Mausam et al. (2009) used many input bilingual lexicons to create bilingual lexicons for new language pairs. They represent the multiple input lexicons in a single undirected graph, with words from all the lexicons as nod</context>
</contexts>
<marker>Paik, Shirai, Nakaiwa, 2004</marker>
<rawString>Kyonghee Paik, Satoshi Shirai, and Hiromi Nakaiwa. 2004. Automatic construction of a transfer dictionary considering directionality. In COLING, Multilingual Linguistic Resources Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viktor Pekar</author>
<author>Ruslan Mitkov</author>
<author>Dimitar Blagoev</author>
<author>Andrea Mulloni</author>
</authors>
<title>Finding translations for lowfrequency words in comparable corpora.</title>
<date>2006</date>
<booktitle>Machine Translation,</booktitle>
<pages>20--247</pages>
<contexts>
<context position="9283" citStr="Pekar et al. (2006)" startWordPosition="1436" endWordPosition="1439"> (1998) discussed semantic similarity estimation using cross-lingual context vector alignment. Both works rely on a pre-existing large (16-20K entries), correct, oneto-one lexicon between the source and target languages, which is used to align context vectors between languages. The context vector data was extracted from comparable (monolingual but domain-related) corpora. Koehn and Knight (2002) were able to do without the initial large lexicon by limiting themselves to related languages that share a writing system, and using identicallyspelled words as context words. Garera et al. (2009) and Pekar et al. (2006) suggested different methods for improving the context vectors data in each language before aligning them. Garera et al. (2009) replaced the traditional window-based cooccurrence counting with dependency-tree based counting, while Pekar et al. (2006) predicted missing co-occurrence values based on similar words in the same language. In the latter work, the oneto-one lexicon assumption was not made: when a context word had multiple equivalents, it was mapped into all of them, with the original probability equally distributed between them. Pivot Language. Using cross-lingual cooccurrences to imp</context>
</contexts>
<marker>Pekar, Mitkov, Blagoev, Mulloni, 2006</marker>
<rawString>Viktor Pekar, Ruslan Mitkov, Dimitar Blagoev, and Andrea Mulloni. 2006. Finding translations for lowfrequency words in comparable corpora. Machine Translation, 20:247 – 266.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prolog</author>
</authors>
<title>Practical Bilingual Dictionary:</title>
<date>2003</date>
<publisher>Spanish-Hebew/Hebrew-Spanish. Israel.</publisher>
<contexts>
<context position="21782" citStr="Prolog, 2003" startWordPosition="3501" endWordPosition="3502">ecision Recall NAS 87.6% 100% 80% 100% Cosine 68% 100% 44% 100% City block 69.8% 100% 36% 100% IC 76.4% 100% 48% 92% Table 4: Spanish-Hebrew Lexicon Generation: highest-ranking translation. words. This yielded a test set of 112 Hebrew nouns and 169 Spanish nouns. The second (R2), contains 25 words for each of the two languages, obtained by randomly selecting 5 singular correctly segmented nouns from each of the 5 frequency ranges 1-1000 to 4001-5000. For each of the test words, the correct translations were extracted from a modern professional concise printed Hebrew-Spanish-Hebrew dictionary (Prolog, 2003). This dictionary almost always provides a single Spanish translation for Hebrew headwords. Spanish headwords had 1.98 Hebrew translations on the average. In both cases this is a small number of correct translation comparing to what we might expect with other evaluation methods; therefore this evaluation amounts to a relatively high standard of correctness. Our score comparison experiments (section 5) extend the evaluation beyond this gold standard. 4.1.5 Parameters The following parameter values were used. The window size for co-occurrence counting, k, was 4. This value was chosen in a small </context>
</contexts>
<marker>Prolog, 2003</marker>
<rawString>Prolog. 2003. Practical Bilingual Dictionary: Spanish-Hebew/Hebrew-Spanish. Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Reinhard Rapp</author>
</authors>
<title>Automatic identification of word translations from unrelated english and german corpora.</title>
<date>1999</date>
<booktitle>In ACL.</booktitle>
<contexts>
<context position="8655" citStr="Rapp (1999)" startWordPosition="1341" endWordPosition="1342">end to partition the semantic fields of headwords in the same way. Thus the first translation of some English headword in the English-Spanish and in the English-Hebrew dictionaries would correspond to the same sense of the headword, and would therefore constitute translations of each other. The applicability of this method is limited by the availability of machine-readable dictionaries produced by the same publishing house. Not surprisingly, this method has been proposed by lexicographers working in such companies (Sk99 oumalova, 2001). 2.3 Cross-lingual Co-occurrences in Lexicon Construction Rapp (1999) and Fung (1998) discussed semantic similarity estimation using cross-lingual context vector alignment. Both works rely on a pre-existing large (16-20K entries), correct, oneto-one lexicon between the source and target languages, which is used to align context vectors between languages. The context vector data was extracted from comparable (monolingual but domain-related) corpora. Koehn and Knight (2002) were able to do without the initial large lexicon by limiting themselves to related languages that share a writing system, and using identicallyspelled words as context words. Garera et al. (2</context>
<context position="20249" citStr="Rapp, 1999" startWordPosition="3243" endWordPosition="3244">s values. In this way, the two scores are ‘plugged’ into our method and serve as baselines for our NAS similarity score. Since the context vectors are in different languages, we had to translate, or align, the baseline context vectors for the source and target words. Our initial lexicon is a many-to-many relation, so multiple alignments were possible; in fact, the number of possible alignments tends to be very large5. We therefore generated M random possible alignments, and used the average distance metric across these alignments. 4.1.4 Test Sets and Gold Standard Following other works (e.g. (Rapp, 1999)), and to simplify the experimental setup, we focused in our experiments on nouns. A p-q frequency range in a corpus is the set of tokens in the places between p and q in the list of corpus tokens, sorted by frequency from high to low. Two types of test sets were used. The first (R1) includes all the singular, correctly segmented (in Hebrew) nouns among the 500 words in the 1001-1500 frequency range. The 1000 highestfrequency tokens were discarded, as a large number of these are utilized as auxiliary syntactic 4We modified the standard cosine and city block metrics so that for all measures hig</context>
</contexts>
<marker>Rapp, 1999</marker>
<rawString>Reinhard Rapp. 1999. Automatic identification of word translations from unrelated english and german corpora. In ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Schafer</author>
<author>David Yarowsky</author>
</authors>
<title>Inducing translation lexicons via diverse similarity measures and bridge languages. In CoNLL.</title>
<date>2002</date>
<contexts>
<context position="10002" citStr="Schafer and Yarowsky (2002)" startWordPosition="1545" endWordPosition="1548">aligning them. Garera et al. (2009) replaced the traditional window-based cooccurrence counting with dependency-tree based counting, while Pekar et al. (2006) predicted missing co-occurrence values based on similar words in the same language. In the latter work, the oneto-one lexicon assumption was not made: when a context word had multiple equivalents, it was mapped into all of them, with the original probability equally distributed between them. Pivot Language. Using cross-lingual cooccurrences to improve a lexicon generated using a pivot language was suggested by Tanaka and Iwasaki (1996). Schafer and Yarowsky (2002) created lexicons between English and a target local language (e.g. Gujarati) using a related language (e.g. Hindi) as pivot. An English pivot lexicon was used in conjunction with pivot-target cognates. Cross-lingual co-occurrences were used to remove errors, together with other cues such as edit distance and Inverse Document Frequencies (IDF) scores. It appears that this work assumed a single alignment was possible from English to the target language. Kaji et al. (2008) used a pivot English lexicon to generate initial Japanese-Chinese and ChineseJapanese lexicons, then used co-occurrences inf</context>
</contexts>
<marker>Schafer, Yarowsky, 2002</marker>
<rawString>Charles Schafer and David Yarowsky. 2002. Inducing translation lexicons via diverse similarity measures and bridge languages. In CoNLL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hana Skoumalova</author>
</authors>
<title>Bridge dictionaries as bridges between languages.</title>
<date>2001</date>
<journal>International Journal of Corpus Linguistics,</journal>
<pages>6--95</pages>
<marker>Skoumalova, 2001</marker>
<rawString>Hana Skoumalova. 2001. Bridge dictionaries as bridges between languages. International Journal of Corpus Linguistics, 6:95–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kumiko Tanaka</author>
<author>Hideya Iwasaki</author>
</authors>
<title>Extraction of lexical translations from non-aligned corpora.</title>
<date>1996</date>
<booktitle>In Conference on Computational linguistics.</booktitle>
<contexts>
<context position="9973" citStr="Tanaka and Iwasaki (1996)" startWordPosition="1541" endWordPosition="1544">ta in each language before aligning them. Garera et al. (2009) replaced the traditional window-based cooccurrence counting with dependency-tree based counting, while Pekar et al. (2006) predicted missing co-occurrence values based on similar words in the same language. In the latter work, the oneto-one lexicon assumption was not made: when a context word had multiple equivalents, it was mapped into all of them, with the original probability equally distributed between them. Pivot Language. Using cross-lingual cooccurrences to improve a lexicon generated using a pivot language was suggested by Tanaka and Iwasaki (1996). Schafer and Yarowsky (2002) created lexicons between English and a target local language (e.g. Gujarati) using a related language (e.g. Hindi) as pivot. An English pivot lexicon was used in conjunction with pivot-target cognates. Cross-lingual co-occurrences were used to remove errors, together with other cues such as edit distance and Inverse Document Frequencies (IDF) scores. It appears that this work assumed a single alignment was possible from English to the target language. Kaji et al. (2008) used a pivot English lexicon to generate initial Japanese-Chinese and ChineseJapanese lexicons,</context>
</contexts>
<marker>Tanaka, Iwasaki, 1996</marker>
<rawString>Kumiko Tanaka and Hideya Iwasaki. 1996. Extraction of lexical translations from non-aligned corpora. In Conference on Computational linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kumiko Tanaka</author>
<author>Kyoji Umemura</author>
</authors>
<title>Construction of a bilingual dictionary intermediated by a third language.</title>
<date>1994</date>
<booktitle>In Conference on Computational Linguistics.</booktitle>
<contexts>
<context position="5630" citStr="Tanaka and Umemura (1994)" startWordPosition="851" endWordPosition="854">nfer wordoriented machine-readable bilingual lexicons. The texts are aligned to each other, at chunk- and/or word-level. Alignment is generally evaluated by consistency (source words should be translated to a small number of target words over the entire corpus) and minimal shifting (in each occurrence, the source should be aligned to a translation nearby). For a review of such methods see (Lopez, 2008). The limited availability of parallel corpora of sufficient size for most language pairs restricts the usefulness of these methods. 2.2 Pivot Language Without Corpora 2.2.1 Inverse Consultation Tanaka and Umemura (1994) generated a bilingual lexicon using a pivot language. They approached lexical intransitivity divergence using Inverse Consultation (IC). IC examines the intersection of two pivot language sets: the set of pivot translations of a source-language word w, and the set of pivot translations of each target-language word that is a candidate for being a translation to w. IC generally requires that the intersection set contains at least two words, which are synonyms. For example, the intersection of the English translations of French printemps and Spanish resorte contains only a single word, spring. T</context>
</contexts>
<marker>Tanaka, Umemura, 1994</marker>
<rawString>Kumiko Tanaka and Kyoji Umemura. 1994. Construction of a bilingual dictionary intermediated by a third language. In Conference on Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerzy Tomaszczyk</author>
</authors>
<title>The bilingual dictionary under review.</title>
<date>1998</date>
<booktitle>In ZuriLEX’86.</booktitle>
<contexts>
<context position="18350" citStr="Tomaszczyk, 1998" startWordPosition="2914" endWordPosition="2915">icon directionality was ignored. All translation pairs extracted for Hebrew-Spanish via English, were also reversed and added to the SpanishHebrew lexicon, and vice-versa. Therefore, every L1-L2 lexicon we mention is identical to the corresponding L2-L1 lexicon in the set of translation pairs it contains. Our lexicon is thus the ‘noisiest’ that can be generated using a pivot language and two source-pivot-target lexicons, but it also provides the most complete candidate set possible. Ignoring directionality is also in accordance with the reversibility principle of the lexicographic literature (Tomaszczyk, 1998). Table 2 details the sizes and branching factors (BF) (the average number of translations for headword) of the input lexicons, as well as those of the generated initial noisy lexicon. 4.1.3 Baseline The performance of our method was compared to three baselines: Inverse Consultation (IC), average cosine distance, and average city block distance. The first is a completely different algorithm, and the last two are a version of our algorithm in which 3www.babylon.com. the NAS score is replaced by other scores. IC (see section 2.2.1) is a corpus-less method. It ranks t1, t2, ..., the candidate tra</context>
</contexts>
<marker>Tomaszczyk, 1998</marker>
<rawString>Jerzy Tomaszczyk. 1998. The bilingual dictionary under review. In ZuriLEX’86.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>