<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000133">
<title confidence="0.979795">
Combining multiple information types in Bayesian word segmentation
</title>
<author confidence="0.996195">
Gabriel Doyle and Roger Levy
</author>
<affiliation confidence="0.9986495">
Department of Linguistics
University of California, San Diego
</affiliation>
<address confidence="0.946911">
La Jolla, CA 92093, USA
</address>
<email confidence="0.999751">
{gdoyle,rlevy}@ucsd.edu
</email>
<sectionHeader confidence="0.998606" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999893952380952">
Humans identify word boundaries in continu-
ous speech by combining multiple cues; exist-
ing state-of-the-art models, though, look at a
single cue. We extend the generative model of
Goldwater et al (2006) to segment using sylla-
ble stress as well as phonemic form. Our new
model treats identification of word boundaries
and prevalent stress patterns in the language as
a joint inference task. We show that this model
improves segmentation accuracy over purely
segmental input representations, and recov-
ers the dominant stress pattern of the data.
Additionally, our model retains high perfor-
mance even without single-word utterances.
We also demonstrate a discrepancy in the per-
formance of our model and human infants on
an artificial-language task in which stress cues
and transition-probability information are pit-
ted against one another. We argue that this dis-
crepancy indicates a bound on rationality in
the mechanisms of human segmentation.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999908296296296">
For an adult speaker of a language, word segmen-
tation from fluid speech may seem so easy that
it barely needed to be learned. However, pauses
in speech and word boundaries are not well cor-
related (Cole &amp; Jakimik, 1980), word boundaries
are marked by a conspiracy of partially-informative
cues (Johnson &amp; Jusczyk, 2001), and different lan-
guages mark their boundaries differently (Cutler &amp;
Carter, 1987). This makes the problem of unsuper-
vised word segmentation acquisition, whether by a
computational model or an infant, a daunting task.
Effective segmentation relies on the flexible in-
tegration of multiple types of segmentation cues,
among them statistical regularities in phonemes and
prosody, coarticulation, and allophonic variation. In-
fants begin using multiple segmentation cues within
their first year of life (Johnson &amp; Jusczyk, 2001).
Despite this, many state-of-the-art models look at
only one type of information: phonemes.
In this study, we expand an existing model to
incorporate multiple cues, leading to an improve-
ment in segmentation performance and opening new
ways of investigating human segmentation acquisi-
tion. On the latter point, we show that rational learn-
ers can learn to segment without encountering words
in isolation, and that human learners deviate from ra-
tionality in certain segmentation tasks.
</bodyText>
<sectionHeader confidence="0.998534" genericHeader="method">
2 Previous work
</sectionHeader>
<bodyText confidence="0.9997291">
The prevailing unsupervised word segmentation sys-
tems (e.g., Brent, 1999; Goldwater, Griffiths, &amp;
Johnson, 2006; Blanchard &amp; Heinz, 2008) use only
phonemic information to segment speech. However,
human segmenters use additional information types,
notably stress information, in their segmentation.
We present an overview of these phonemic mod-
els here before discussing the prosodic model ex-
pansion. A more complete review is available in
Goldwater (2007).
</bodyText>
<subsectionHeader confidence="0.806695">
2.1 Goldwater et al (2006)
</subsectionHeader>
<bodyText confidence="0.97848825">
The Goldwater et al model is related to Brent
(1999)’s model, both of which use strictly phone-
mic information to segment. The model assumes that
the corpus is generated by a Dirichlet process over
</bodyText>
<page confidence="0.971148">
117
</page>
<note confidence="0.483154">
Proceedings of NAACL-HLT 2013, pages 117–126,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.948949666666667">
word bigrams.1 We present a basic overview here,
based on Sect. 5.5 of Goldwater, 2007. To generate
the word wi given the preceding word wi−1:
</bodyText>
<listItem confidence="0.813852">
1. Decide if bigram bi = (wi−1, wi) is novel
2. If bi non-novel, draw bi from bigram lexicon
3. If bi novel, decide whether wi is novel
a. If wi non-novel, draw wi from word lexicon
b. If wi novel, draw wi from word-generating
distribution P0.
</listItem>
<bodyText confidence="0.995010625">
The Dirichlet process first decides whether to
draw a non-novel (“nn”) bigram, with probability
proportional to the number of times the previous
word has appeared in the corpus:
where nhx,yi is the token count for bigram (x, y).
If the bigram is non-novel, word wi is drawn in
proportion to the number of times it has appeared
after wi−1 in the corpus:
</bodyText>
<equation confidence="0.983732">
p(wi = x|(wi−1, wi) nn) = nhwi−1,xi (2)
nhwi−1,·i
</equation>
<bodyText confidence="0.9994825">
If the bigram is novel, this could either be due to
wi being a novel word or due to wi being an existing
word that had not appeared with wi−1 before. The
probability of wi being a non-novel word x is
</bodyText>
<equation confidence="0.921991">
(b(·,·i + α0)
</equation>
<bodyText confidence="0.929124428571429">
where bh.,.i is the count of word bigram types.
Finally, if wi is a new word, its phonemic form is
generated from a distribution P0. In the Goldwater
et al model, this distribution is simply the product of
the unigram probabilities of the phonemes, P(σj),
times the probability of a word boundary, p#, to end
the word:
</bodyText>
<equation confidence="0.99012">
p(wi = σ1 ··· σM |wi
</equation>
<bodyText confidence="0.929513636363636">
novel ) = p#(1 − p#)M−1 H P(σ3-)
1We will only discuss the bigram model here because it is
more appropriate from both a cognitive perspective (it posits la-
tent hierarchical structure) and engineering perspective (it seg-
ments more accurately) than the unigram model.
To segment an observed corpus, the model Gibbs
samples over the possible word boundaries (utter-
ance boundaries are assumed to be word bound-
aries).2 The exchangability of draws from a Dirichlet
process allows for Gibbs sampling of each possible
boundary given all the others.
</bodyText>
<subsectionHeader confidence="0.999848">
2.2 A cognitively-plausible variant
</subsectionHeader>
<bodyText confidence="0.999982125">
Phillips and Pearl (2012) make these Bayesian seg-
mentation models more cognitively plausible in two
ways. The first is to move from phonemes to syl-
lables as the base representational unit from which
words are constructed, as infants learn to categorize
syllables before phonemes (Eimas, 1999). The sec-
ond is to add memory and processing constraints on
the learner. They find that syllable-based segmen-
tation is better than phoneme-based segmentation
in the bigram model (though worse in the unigram
model), and that, counter-intuitively, the constrained
learner outperforms the unconstrained learner. This
improvement appears to be driven by better perfor-
mance in segmenting more common words. In this
work, we adopt the syllabified representation but re-
tain the unconstrained rational learner assumption.
</bodyText>
<subsectionHeader confidence="0.999481">
2.3 Other multiple-cue models
</subsectionHeader>
<bodyText confidence="0.999963333333334">
Some previous models have incorporated multiple
cues, specifically the phonemic and stress infor-
mation that our model will use. Two prominent
examples are Christiansen, Allen, and Seidenberg
(1998)’s connectionist model and Gambell and Yang
(2006)’s algebraic model. The connectionist model
places word boundaries where the combination of
phonemic and stress information predict likely ut-
terance boundaries, but does not include an explicit
sense of “word”, and performs only modestly on
the segmentation task (boundary F-scores of .40-
.45). The algebraic model also underperforms the
Bayesian model (Phillips &amp; Pearl, 2012) unless it
includes the heuristic that there is a word bound-
ary between any two stressed syllables. Our model
presents a more general and completely unsuper-
vised approach to segmentation with multiple cue-
types.
</bodyText>
<footnote confidence="0.552727666666667">
2The model assumes that utterance boundaries are generated
just like other words, and includes an adjustable parameter p$
to account for their frequency.
</footnote>
<equation confidence="0.9944245">
nhwi−1,·i
p((wi−1, wi) nn|wi−1) =
, (1)
nhwi−1,·i + α1
p(wi = x, wi nn |(wi−1, wi) ) =bh·,wii
novel &apos;
</equation>
<page confidence="0.991521">
118
</page>
<bodyText confidence="0.9986771">
In general, joint inference is becoming more com-
mon in language acquisition problems and has been
shown to improve performance over single-feature
inference. Examples include joint inference of a
lexicon and phonetic categories (Feldman, Grif-
fiths, &amp; Morgan, 2009), joint inference of syntactic
word order and word reference (Maurits, Perfors, &amp;
Navarro, 2009), and joint inference of word mean-
ings and speaker intentions in child-directed speech
(Frank, Goodman, &amp; Tenenbaum, 2009).
</bodyText>
<sectionHeader confidence="0.951049" genericHeader="method">
3 Model design
</sectionHeader>
<bodyText confidence="0.999372454545454">
Our model changes P0 from a single-cue distribu-
tion, generating only phonemes, to a multiple-cue
distribution that generates a stress form as well. This
can improve segmentation performance and allows
the investigation of rational segmentation behavior
in a multiple-cue world.
In the original model, P0(wi = σ1 · · · σM) a
Hj P(σj), where P(σj) is the frequency of the
phoneme σj. In the multiple-cue model, we first
generate a phonemic form wi, then assign a stress
pattern si to it.
</bodyText>
<equation confidence="0.97719525">
P0(wi,si) = PW(wi)PS(siJM)
M
= p#(1 − p#)M−1 P(σj)PS(siJM) (5)
j
</equation>
<bodyText confidence="0.999951235294118">
The phonemic form wi has the same product-of-
segments probability as the Goldwater et al model,
but σj are now syllables instead of phonemes. We
discuss the rationale behind this change in the next
section.
The phonemic form is generated first, and the
stress form is then drawn as a multinomial over all
possible stress patterns with the same number of syl-
lables as wi. The stress distribution PS is a multino-
mial distribution over word-length stress templates.
PS can be learned by the model based on a Dirich-
let prior, but for simplicity in the present implemen-
tation, we estimate PS as the plus-one-smoothed
frequency of the stress patterns in the current seg-
mentation. There are two stress levels (stressed or
unstressed), and 2M possible stress templates for a
word of length M.3
</bodyText>
<footnote confidence="0.627051">
3We do not assume that each word has one and only one
</footnote>
<bodyText confidence="0.998696142857143">
Unlike phonemic forms, stress patterns are drawn
as a whole word. This allows the model to capture
a wide range of stress biases, although it prevents
the model from generalizing biases across different
word lengths. A potential future change to PS that
would allow for better generalization is discussed in
Section 6.
</bodyText>
<subsectionHeader confidence="0.999785">
3.1 On syllabification and stress
</subsectionHeader>
<bodyText confidence="0.987723179487179">
We change from segmenting on phonemes to seg-
menting on syllables in order to more easily imple-
ment stress information, which is a supersegmental
feature most appropriately located on syllables. Syl-
labified data has been used in some previous mod-
els of segmentation, especially those using stress
information or syllable-level transition probabilities
(Christiansen et al., 1998; Swingley, 2005; Gambell
&amp; Yang, 2006; Phillips &amp; Pearl, 2012).
For studying human word segmentation, Phillips
and Pearl argue syllabified speech may be a
more cognitively plausible testing ground. 3-month-
old infants appear to have categorical representa-
tions of syllables (Eimas, 1999), three months be-
fore word segmentation appears (Borfeld, Morgan,
Golinkoff, &amp; Rathbun, 2005), and seven months
before phoneme categorization (Werker &amp; Tees,
1984). In addition, syllabification is assumed in
much work on human word segmentation, especially
in artificial-language studies (e.g., Thiessen &amp; Saf-
fran, 2003), which calculate statistical cues at the
syllable level.
The assumption that syllable boundaries are
known affects the baseline performance of the
model, as it reduces the number of possible word
boundary locations (since a word boundary is nec-
essarily a syllable boundary). As such performance
over syllabified data cannot be directly compared to
performance on non-syllabified data.
It may seem that syllabification is so closely tied
to word segmentation that including the former in a
model of the latter leaves little to the model. How-
ever, the determinants of syllable boundaries are not
the same as those for word boundaries. The prob-
stressed syllable, which would reduce the number of possible
stress templates to M, for two reasons. First, in the current cor-
pus, some words have citation forms with multiple stressed syl-
lables. Second, in actual speech this assumption will not hold
(e.g., many function words go unstressed).
</bodyText>
<page confidence="0.995351">
119
</page>
<bodyText confidence="0.999944583333333">
lem of assigning syllable boundaries is a question of
deciding where a boundary goes between two syl-
lable nuclei, with the assumption that there must be
a boundary there. The problem of assigning word
boundaries is a question of deciding whether there
is a boundary between two syllable nuclei, and if so,
where it is. Knowing the syllable boundaries reduces
the set of possible word boundaries, but does not di-
rectly address the question of how likely a boundary
is. The difference in these tasks is supported by the
three-month gap between syllable and word identifi-
cation in infants.
</bodyText>
<sectionHeader confidence="0.996864" genericHeader="method">
4 Data
</sectionHeader>
<bodyText confidence="0.999995608695652">
We use the Korman (1984) training corpus, as com-
piled by Christiansen et al. (1998), in this study. This
is a 24493-word corpus of English spoken by adults
to infants aged 6–16 weeks.4 Phonemes, stresses,
and syllable boundaries are the same as those used
by Christiansen et al, which were based on citation
forms in the MRC Psycholinguistic Database. All
monosyllabic words were coded as stressed. Only
utterances for which all words had citation forms
were included.
This corpus is largely monosyllabic (87.3% of all
word tokens), and heavily biased toward initial stress
(89.2% of all multisyllable word tokens). No word
is longer than three syllables, and most words have
only one stressed syllable. A breakdown of the cor-
pus by stress pattern is given in Table 1. This mono-
syllabic bias is an inherent property of English, not
idiosyncratic to this corpus. The Bernstein-Ratner
child-directed corpus is also over 80% monosyl-
labic. We expect that the results of segmentation on
child-directed data will extend to adult speech, as
the adult-directed corpus used by Gambell and Yang
(2006) has an average word length of 1.17 syllables.
</bodyText>
<sectionHeader confidence="0.999279" genericHeader="method">
5 Experiments
</sectionHeader>
<bodyText confidence="0.9999874">
We test the model on three problems. First, we show
that the addition of stress information improves seg-
mentation performance compared to a stress-less
model. Next, we apply the model to a question in
human segmentation acquisition. Finally, we look at
</bodyText>
<footnote confidence="0.736945">
4Approximately 150 word tokens from the original corpus
were omitted in our version of the corpus due to a disparity
between recorded number of syllables and number of stresses.
</footnote>
<table confidence="0.999136666666667">
Types Tokens
Stress pattern Count Stress pattern Count
S 21402 S 523
SW 2231 SW 208
SS 389 WS 40
WS 284 SWW 24
SWW 182 SS 7
WSW 33 WSW 7
Other 5 Other 2
</table>
<tableCaption confidence="0.992278">
Table 1: Corpus stress patterns by types and tokens,
showing an initial-stress bias in all lengths.
</tableCaption>
<bodyText confidence="0.9655245">
a task where the rational model deviates from human
performance.
</bodyText>
<subsectionHeader confidence="0.986173">
5.1 Parameter setting
</subsectionHeader>
<bodyText confidence="0.99994325">
The model has four free parameters: α0 and α1,
which affect the likelihood of new words and bi-
grams, respectively, and p# and p$, which affect the
expected likelihood of word and utterance bound-
aries. Following Goldwater, Griffiths, and Johnson
(2009), we set α0 = 20, α1 = 100, p# = 0.8 and
p$ = 0.5 in all experiments.5
In all cases, the model performed five indepen-
dent runs of 20000 iterations of Gibbs sampling the
boundaries for the full corpus. Simulated annealing
was performed during the burn-in period to improve
convergence. All performance measures are reported
as the mean of these five runs.
Performance is measured as word, boundary, and
lexicon precision, recall, and F-scores. A word is
matched iff both of its true boundaries are marked
as boundaries and no internal boundaries are marked
as word boundaries. Boundary counts omit utterance
boundaries, which are assumed to be word bound-
aries. Lexical counts are based on word type counts.
</bodyText>
<subsectionHeader confidence="0.998444">
5.2 Stress improves performance
</subsectionHeader>
<bodyText confidence="0.9997155">
We begin by showing that including a second
cue type improves segmentation performance. We
compare segmentation on a corpus with the at-
tested stress patterns to that of a corpus with-
out stress. With stress information included in
the model, word/boundary/lexicon F-scores are
</bodyText>
<footnote confidence="0.9920465">
5Performance was similar for a range of settings between 1
and 100 for α0 and between 10 and 200 for α1.
</footnote>
<page confidence="0.913991">
120
</page>
<table confidence="0.9999192">
With stress Without stress
Word Bnd Lex Word Bnd Lex
Prec .76 .99 .75 .76 .99 .72
Rec .61 .70 .87 .60 .69 .84
F .68 .82 .80 .67 .82 .77
</table>
<tableCaption confidence="0.977675">
Table 2: Precision, recall, and F-score over corpora with
and without stress information available. Stress informa-
tion especially improves lexical performance.
</tableCaption>
<bodyText confidence="0.978982042253521">
.68/.82/.80. Without stress, performance drops to
.67/.82/.77.6 Full results are given in Table 2.
Stress information primarily improves lexicon
performance, along with a small improvement in
token segmentation. Accounting for stress reduces
both false positives and negatives in the lexicon; the
fact that the lexical improvement is greater than that
for words or boundaries suggests that much of the
improvement rests is on rare words.
These effects are small but significant. For word
token performance, we performed a paired t-test
on utterance token F-scores between the with- and
without-stress models. This difference was signif-
icant (t = 11.28, df = 8125,p &lt; .001). We
performed a similar utterance-by-utterance test on
boundaries; again a small singificant improvement
was found (t = 8.92, df = 6084, p &lt; .001). To
assess lexicon performance, we calculated for each
word type in the gold-standard lexicon the propor-
tion of the five trials in which that word appeared
in the learned lexicon for the two models. We then
examined the words where the proportions differed
between the models. 89 true words appeared more
often in the with-stress lexicons; 40 appeared more
often in the without-stress lexicons. (683 appeared
equally often in both.) By a sign test, this is signif-
icant at p &lt; .001. We also tested lexicon perfor-
mance with a binomial test on the two models’ lexi-
con accuracy; this result was marginal (p = .06).
The explicit tracking of stress information also
improves the model’s acquisition of the stress bias of
the language. Acquisition of the stress bias is poten-
tially useful for generalization; stress patterns can be
used for an initial segmentation if few or none of the
words are familiar. In practice, we see children use
6Recall that due to the syllabified data, these results are not
directly comparable to unsyllabified results in previous work.
their stress biases to segment new words from En-
glish speech (Jusczyk, Houston, &amp; Newsome, 1999)
as well as artificial languages (Thiessen &amp; Saffran,
2003).
We assess the learned stress bias by dividing up
the corpus as the model has segmented it, and count
the number of tokens with SW versus WS stress pat-
terns.7 With stress representation, the learned stress
bias is 6.77:1, and without stress representation, the
stress bias is lower, at 6.33:1. Although these are
both underestimates of the corpus’s true stress bias
(7.86:1), the stressed model is stronger and a better
estimate of the true value.
The model’s performance can be compared to
various baselines, but perhaps the strongest is one
with every syllable boundary being a word bound-
ary. This baseline represents a shift from boundary
precision being at ceiling (as in the model) to bound-
ary recall being at ceiling. In fact, due to the pre-
ponderance of monosyllabic words in English child-
directed speech, this baseline outperforms the model
on word and boundary F-scores (.68 and .82 in the
model, .82 and .91 in the baseline). However, the
baseline’s lexicon is much worse than the model’s
(F=.80 in the with-stress model, F=.64 in the base-
line), and the baseline fails to learn anything about
the language’s stress biases. In addition, the base-
line oversegments, whereas both the model and in-
fant segmenters undersegment (Peters, 1983). This
raises an important question about what the model
should seek to optimize: though the baseline is more
accurate by token, no structure is learned; type per-
formance is more important if we want to learn the
underlying structure.
</bodyText>
<subsectionHeader confidence="0.998059">
5.3 Are isolated words necessary?
</subsectionHeader>
<bodyText confidence="0.999984">
We next use this model to test the necessity of iso-
lated words in rational word segmentation. It is not
immediately obvious how human learners begin to
segment words from fluid speech. Stress biases and
other phonological cues are dominant in all but the
earliest of infant word segmentation (Johnson &amp;
Jusczyk, 2001). This raises a chicken-and-egg prob-
lem; if the cues infants favor to segment words, such
as stress biases, are dependent on the words of the
</bodyText>
<footnote confidence="0.977907">
7Note this defines a stress bias for the stressless model as
well.
</footnote>
<page confidence="0.99774">
121
</page>
<bodyText confidence="0.99998165625">
language, how do they learn enough words to deter-
mine the cues’ biases?
One existing proposal is that human learners de-
velop their stress biases based on words frequently
heard in isolation (Jusczyk et al., 1999). In En-
glish, these include names and common diminutives
(e.g., mommy, kitty) that generally have initial stress.
These single-word utterances could offer the seg-
menter an initial guess of the stress bias, by suppos-
ing that short utterances are single words and record-
ing their stress patterns. The most common stress
patterns in short utterances could then be used as
an initial guess at the stress bias to bootstrap other
words and thereby improve the learned stress bias.
We test the rational learner’s need for such ex-
plicit bootstrapping by learning to segment a corpus
with all single-word utterances removed. The corpus
is produced by excising all single-word utterances
from the Korman corpus. This results in a 22081-
word corpus, 10% fewer tokens than in the original.
However, it does not substantially change the lexi-
con; the number of distinct word types only drops
from 811 to 806.
We compare performance only on ambiguous
boundaries and lexicon, as these are comparable
between the corpora, and find that the model per-
forms almost equally well. Without single-word ut-
terances, boundary and lexical F-scores are .81 and
.80, compared to .82 and .80 with single-word utter-
ances. This shows that rational learners are able to
segment even without the possibility of bootstrap-
ping stress patterns from single-word utterances.
</bodyText>
<subsectionHeader confidence="0.9371055">
5.4 Bounded rationality in human
segmentation
</subsectionHeader>
<bodyText confidence="0.999501846153846">
Lastly, we use this model to examine rational per-
formance in a multiple-cue segmentation task. We
show that humans’ segmentation does not adhere to
these predictions, suggesting a bound on human ra-
tionality in word segmentation.
We consider an artificial language study by
Thiessen and Saffran (2003). In this study, infants
are exposed to an artificial language consisting of
four bisyllabic word types uttered repeatedly with-
out pauses. Each syllable appears in only one word
type, so within-word transition probabilities are al-
ways 1, while across-word transition probabilities
are less than 0.5. Segmentation strategies that hy-
</bodyText>
<table confidence="0.999245166666667">
Against bias, with TP
AB CD CD AB
WS WS WS WS
With bias, against TP
A BC DC DA B
W SW SW SW S
</table>
<tableCaption confidence="0.981260428571428">
Table 3: Examples of segmenting an artificial language
according to transition probabilities (top) or stress bias
(bottom), when the true words have weak-strong stress.
Vertical lines represent word boundaries. The top seg-
mentation produces a smaller lexicon, but the bottom seg-
mentation produces primarily words with the preferred
stress pattern.
</tableCaption>
<bodyText confidence="0.999960424242424">
pothesize word boundaries at low transition proba-
bilities or that seek to minimize the lexicon size will
segment out the four word types as expected.
Segmentation in the experiment is complicated by
the presence of stress in the artificial language. De-
pending on the condition, the words are either all
strong-weak or all weak-strong. In the first condi-
tion, segmenting according to transition probabili-
ties, lexicon size, or English stress bias favors the
same segmentation. In the second condition, though,
segmenting by the English stress bias to yield a lex-
icon of strong-weak words requires boundaries in
the middle of the words. The segmenter must decide
whether transition probabilities or preferred stress
patterns are more important in segmentation. This
situation is illustrated in Table 3, with a corpus con-
sisting of two word types, AB and CD, each with
weak-strong stress.
Thiessen and Saffran found that seven-month-
old English-learning infants consistently segmented
according to the transition probabilities, regardless
of stress. However, nine-month-olds segmented ac-
cording to the English stress bias, even if this meant
going against the transition probabilities.
Intuitively, this could be rational behavior accord-
ing to our model. A child’s increasing age means
more exposure to data, potentially leading the child
to develop more confidence in the stress bias. As
confidence in the stress bias increases, the cost of
segmenting against it increases as well. A suffi-
ciently strong stress preference could lead the seg-
menter to accept a large lexicon, all of whose words
have the preferred stress pattern, over a small lexi-
</bodyText>
<page confidence="0.994784">
122
</page>
<bodyText confidence="0.996207428571429">
con, all of whose words have the dispreferred stress
pattern.
To judge by the Korman corpus, English has a
stress bias of approximately 7:1 in favor of SW bi-
syllabic stress over WS.8 If human segmentation be-
havior follows the rational model, the model should
predict segmentation to favor strong-weak words
over the transition probabilities when the stress bias
is approximately this strong.
We test this rationality hypothesis with a smaller
version of the Thiessen and Saffran artificial lan-
guage, consisting of 48 tokens.9 In one version,
all tokens have the preferred SW pattern, and in
the other all tokens have the dispreferred WS pat-
tern. We then adjust the PS distribution such that
PS(SW|M = 2) = b * PS(WS|M = 2), where
b is the bias ratio. We run the model otherwise the
same as in the previous experiments, except with 10
runs instead of 5.
Contrary to this hypothesis, the model’s segmen-
tation with b = 7 was the same whether the true
words were strong-weak or weak-strong. In all ten
runs, transition probabilities dictated the segmenta-
tion. To switch to stress-based segmentation, the bias
must be orders of magnitude greater than the English
bias. Figure 1 shows the proportions of runs in the
weak-strong condition that show segmentation ac-
cording to the stress bias, as the bias increases by
factors of 10. When b = 10000, three of the ten runs
segmented according to the stress bias; below that,
the stress bias did not affect the rational model’s seg-
mentation.
Why is this? In the Bayesian model, the stress bias
of a language affects only the PS(si|M) term in the
P0 distribution, so non-novel words are not penal-
ized for their stress pattern. The model pays only
once to create a word; once the word is generated,
no matter how a priori implausible the word was,
it may be cheaply drawn again as a non-novel word.
This effect can be illustrated with a brief calculation.
Consider a corpus built from four bisyllabic word
types (AB, CD, EF, GH), each appearing N times. If
</bodyText>
<footnote confidence="0.985594833333333">
8The specific bias varies from corpus to corpus, but this ap-
pears to be a representative value.
9The 48 tokens come from four word types, with two types
appearing 16 times and the other two appearing 8 times, mim-
icking the relative frequencies of Thiessen and Saffran’s lan-
guages. Their test language had 270 tokens.
</footnote>
<figure confidence="0.970630666666667">
100
80
60
40
20
0
</figure>
<figureCaption confidence="0.99860475">
Figure 1: Percentage of runs segmented with the stress
bias, against transition probabilities, as bias varies. At
English-level biases, the rational model still overrules the
stress bias when segmenting.
</figureCaption>
<bodyText confidence="0.9978805">
the corpus is segmented against the transition proba-
bilities, the resulting lexicon will have 16 bisyllabic
word types (BA, BC, BE, BG, DA, etc.), each occur-
ring approximately N4 times.
The probability of the against-bias corpus (CWS)
is proportional to the probability of generating the
four word types, and then drawing them non-novelly
from the lexicon.10 (To simplify the calculations,
we use the unigram version of the Goldwater et al
model.)
</bodyText>
<equation confidence="0.9951535">
p(CWS) a P4WPS(WS)4(N!)41
4N! (6)
</equation>
<bodyText confidence="0.959346285714286">
The first two terms are the probability of gen-
erating the four word types (Eqn. 5);11 the second
two terms are the Dirichlet process draws from
the existing lexicon N times each (Eqn. 2). By
comparison, the probability of the with-bias corpus
CSW depends on generating the 16 word types, and
drawing each non-novelly N4 times.
</bodyText>
<equation confidence="0.855834">
(N �
p(CSW) a PW 16 PS(SW)16 4 !
</equation>
<bodyText confidence="0.9676815">
Given an SW bias b and a uniform distribution
over syllables (so PW=164), we find:
</bodyText>
<equation confidence="0.966801">
(N!)4
(N 4 !)16 (8)
</equation>
<footnote confidence="0.9966634">
10It is also possible to generate this corpus by re-drawing the
words novelly, but this is much less likely than non-novel draws.
11Because all syllables have equal unigram probabilities, the
probability of all words’ phonemic forms are equal, and will be
written as Pw.
</footnote>
<figure confidence="0.949471142857143">
Percent SW segmention
100 101 102 103 104 105 106
bias
4N! (7)
16 1
p(CWS) = 6412(b + 1)12
p(CSW ) b16
</figure>
<page confidence="0.99727">
123
</page>
<bodyText confidence="0.99998484">
This equation shows that the rational model is
heavily biased toward the segmentation that fits the
transition probabilities. Increasing the stress bias b
or decreasing the number of observed word tokens
makes the rational model more likely to segment
with the stress bias (against transition probabilities),
but as we see in the experimental results, the stress
bias must be very strong to overcome the efficient
lexicon that the transition probability segmentation
provides.
Since humans do not show this same inherent
bias (or quickly lose it as they acquire the stress
bias), we can ask how humans deviate from ratio-
nality. One possibility is that humans simply do not
segment in this Bayesian manner. However, previ-
ous work (Frank, Goldwater, Griffiths, &amp; Tenen-
baum, 2010) has shown that human word segmen-
tation shows similar behavior to a resource-limited
Bayesian model. Equation 8 suggests that human
segmentation could deviate from rationality by hav-
ing an effectively stronger bias than English would
suggest (reducing the first fraction)12 or, as with
Phillips and Pearl’s constrained learners, by having
effectively less input than the model assumes (reduc-
ing the second fraction).
</bodyText>
<sectionHeader confidence="0.999887" genericHeader="method">
6 Future work
</sectionHeader>
<bodyText confidence="0.99994847826087">
Introducing stress into the Bayesian segmentation
model suggests a few additional expansions. One
possibility is to add other cues into the genera-
tive model via Po. Any cue that is based on the
word itself can be added in this way, with little
change to the general model structure. Phonotactics
can be added using an n-gram distribution for Po
(Blanchard &amp; Heinz, 2008). Coarticulation between
adjacent phonemes is also used in human segmen-
tation (Johnson &amp; Jusczyk, 2001), so the Po distri-
bution could predict higher within-word coarticula-
tion. Integrating additional cues used by human seg-
menters extends the investigation of the bounds on
rationality in human segmentation and in balancing
multiple conflicting cues.
12A potential source of an inflated bias is infants’ preference
for strong-weak patterns. Jusczyk, Cutler, and Redanz (1993)
found English-hearing infants listened longer to strong-weak
patterns than weak-strong. This could lead to overestimation of
the stress bias by making possible strong-weak segmentations
more prominent in the segmenter’s mind.
A more complex view of the stress system of a
language may also be useful. One possibility is to
place a Dirichlet prior over the stress templates and
allow Ps to be learned as a latent variable in the
model. Another possibility is to treat the stress tem-
plates more generally; in the present implementa-
tion, knowledge of the preferred stress patterns for
word of one length tells the segmenter nothing about
preferred stress patterns in another length. Cross-
linguistically common stress rules (e.g., those that
place stress a certain number of syllables from the
left or right edge of a word) can be coded into Ps to
improve generalization. Each rule dictates a specific
stress pattern for each word length. When a word
is generated in the Dirichlet process, the generative
model would decide whether to assign stress accord-
ing to one of these rules or to assign lexical stress
from a default multinomial distribution. (This “de-
fault” distribution would handle idiosyncratic stress
assignments, as one might see with names or mor-
phologically complex words, like Spanish reflexive
verbs.) A sparse prior over these rules, asymmetri-
cally weighted against the default category, will en-
courage the model to explain as much of the ob-
served stress patterns as possible with a few domi-
nant rules, improving the phonological structure that
the segmenter learns.
Improving the realism of the data is also impor-
tant. The corpora used in much of segmentation re-
search are idealized representations of the true data,
and the dictionary-based phoneme and stress pat-
terns used in this study are no exception. This ideal
setting may paint a skewed picture of the segmen-
tation problem, by providing a more consistent and
learnable data source than humans actually receive.
Elsner, Goldwater, and Eisenstein (2012)’s model
unifying lexical and phonetic acquisition takes a sig-
nificant step in showing that a rational segmenter
can handle noisy input by recognizing phonetic vari-
ants of a base form. In terms of stress representa-
tions, dictionary-based stress has been standard in
previous work (Christiansen et al., 1998; Gambell &amp;
Yang, 2006; Rytting, Brew, &amp; Fosler-Lussier, 2010),
but it is important to confirm such results against a
(currently nonexistent) corpus with stresses based on
the actual utterances. Effective use of stress in a less
idealized setting may require a more complex repre-
sentation of stress in the model.
</bodyText>
<page confidence="0.997775">
124
</page>
<sectionHeader confidence="0.999104" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999943428571428">
Effective word segmentation combines multiple fac-
tors to make predictions about word boundaries. We
extended an existing Bayesian segmentation model
to account for two factors, phonemes and stress,
when segmenting. This improves segmentation per-
formance and opens up new possibilities for compar-
ing rational segmentation and human segmentation.
</bodyText>
<sectionHeader confidence="0.998091" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9997628">
This research was partially supported by an Alfred P.
Sloan Fellowship to RL and by NSF award 0830535.
We also appreciate the feedback of the reviewers
and the members of the UCSD Computational Psy-
cholinguistics Lab.
</bodyText>
<sectionHeader confidence="0.999623" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997616805194805">
Blanchard, D., &amp; Heinz, J. (2008). Improving
word segmentation by simultaneously learn-
ing phonotactics. In Proceedings of CoNLL
(pp. 65–72).
Borfeld, H., Morgan, J., Golinkoff, R., &amp; Rath-
bun, K. (2005). Mommy and me: familiar
names help launch babies into speech-stream
segmentation. Psychological Science, 16(4),
298–304.
Brent, M. R. (1999). An efficient, probabilistically
sound algorithm for segmentation and word
discovery. Machine Learning, 34, 71–105.
Christiansen, M. H., Allen, J., &amp; Seidenberg, M. S.
(1998). Learning to segment speech using
multiple cues: A connectionist model. Lan-
guage and Cognitive Processes, 13, 221–268.
Cole, R., &amp; Jakimik, J. (1980). A model of speech
perception. In Perception and production of
fluent speech (pp. 136–163). Hillsdale, NJ:
Erlbaum.
Cutler, A., &amp; Carter, D. (1987). The predominance
of strong initial syllables in the English vocab-
ulary. Comp. Speech Lang., 2, 133–142.
Eimas, P. (1999). Segmental and syllabic representa-
tions in the perception of speech by young in-
fants. Journal of the Acoustic Society ofAmer-
ica, 105, 1901–1911.
Elsner, M., Goldwater, S., &amp; Eisenstein, J. (2012).
Bootstrapping a unified model of lexical and
phonetic acquisition. In Proceedings of the
50th annual meeting of the ACL.
Feldman, N., Griffiths, T., &amp; Morgan, J. (2009).
Learning phonetic categories by learning a
lexicon. In Proceedings of the 31st annual
conference on cognitive science.
Frank, M., Goldwater, S., Griffiths, T., &amp; Tenen-
baum, J. (2010). Modeling human perfor-
mance in statistical word segmentation. Cog-
nition.
Frank, M., Goodman, N., &amp; Tenenbaum, J. (2009).
Using speakers’ referential intentions to
model early cross-situational word learning.
Psychological Science, 20, 579–585.
Gambell, T., &amp; Yang, C. (2006). Word segmen-
tation: Quick but not dirty. (Unpublished
manuscript)
Goldwater, S. (2007). Nonparametric Bayesian
models of lexical acquisition. Unpublished
doctoral dissertation, Brown Univ.
Goldwater, S., Griffiths, T., &amp; Johnson, M. (2006).
Contextual dependencies in unsupervised
word segmentation. In Proceedings of Col-
ing/ACL.
Goldwater, S., Griffiths, T. L., &amp; Johnson, M.
(2009). A Bayesian framework for word seg-
mentation: Exploring the effects of context.
Cognition, 112, 21–54.
Johnson, E., &amp; Jusczyk, P. (2001). Word segmen-
tation by 8-month-olds: When speech cues
count more than statistics. J. of Memory and
Language, 44, 548–567.
Jusczyk, P., Cutler, A., &amp; Redanz, N. (1993). Pref-
erence for predominant stress patterns of En-
glish words. Child Development, 64, 675–
687.
Jusczyk, P., Houston, D., &amp; Newsome, M. (1999).
The beginnings of word segmentation in
English-learning infants. Cognitive Psychol-
ogy, 39, 159–207.
Korman, M. (1984). Adaptive aspects of mater-
nal vocalizations in differing contexts at ten
weeks. First language, 5, 44–45.
Maurits, L., Perfors, A., &amp; Navarro, D. (2009). Joint
acquisition of word order and word reference.
In Proceedings of 31st annual conference of
the Cognitive Science Society.
Peters, A. (1983). The units of language acqui-
</reference>
<page confidence="0.983966">
125
</page>
<reference confidence="0.884800130434783">
sition: Monographs in applied psycholinguis-
tics. Cambridge Univ. Press.
Phillips, L., &amp; Pearl, L. (2012). “less is more”
in Bayesian word segmentation: When cogni-
tively plausible learners outperform the ideal.
In Proceedings of the 34th annual conference
of the cognitive science society.
Rytting, C. A., Brew, C., &amp; Fosler-Lussier, E.
(2010). Segmenting words from natural
speech: subsegmental variation in segmental
cues. Journal of Child Language, 37, 513–
543.
Swingley, D. (2005). Statistical clustering and the
contents of the infant vocabulary. Cognitive
Psychology, 50, 86–132.
Thiessen, E. D., &amp; Saffran, J. R. (2003). When cues
collide: Use of stress and statistical cues to
word boundaries by 7- to 9-month-old infants.
Developmental Psychology, 39(4), 706–716.
Werker, J., &amp; Tees, R. (1984). Cross-language
speech perception: Evidence for perceptual
reorganization during the first year of life. In-
fant Behavior and Development, 7, 49–63.
</reference>
<page confidence="0.998292">
126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.984823">
<title confidence="0.999868">Combining multiple information types in Bayesian word segmentation</title>
<author confidence="0.997279">Doyle</author>
<affiliation confidence="0.999374">Department of University of California, San</affiliation>
<address confidence="0.99835">La Jolla, CA 92093,</address>
<abstract confidence="0.999529272727273">Humans identify word boundaries in continuous speech by combining multiple cues; existing state-of-the-art models, though, look at a single cue. We extend the generative model of Goldwater et al (2006) to segment using syllable stress as well as phonemic form. Our new model treats identification of word boundaries and prevalent stress patterns in the language as a joint inference task. We show that this model improves segmentation accuracy over purely segmental input representations, and recovers the dominant stress pattern of the data. Additionally, our model retains high performance even without single-word utterances. We also demonstrate a discrepancy in the performance of our model and human infants on an artificial-language task in which stress cues and transition-probability information are pitted against one another. We argue that this discrepancy indicates a bound on rationality in the mechanisms of human segmentation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Blanchard</author>
<author>J Heinz</author>
</authors>
<title>Improving word segmentation by simultaneously learning phonotactics.</title>
<date>2008</date>
<booktitle>In Proceedings of CoNLL</booktitle>
<pages>65--72</pages>
<contexts>
<context position="2650" citStr="Blanchard &amp; Heinz, 2008" startWordPosition="398" endWordPosition="401">s, many state-of-the-art models look at only one type of information: phonemes. In this study, we expand an existing model to incorporate multiple cues, leading to an improvement in segmentation performance and opening new ways of investigating human segmentation acquisition. On the latter point, we show that rational learners can learn to segment without encountering words in isolation, and that human learners deviate from rationality in certain segmentation tasks. 2 Previous work The prevailing unsupervised word segmentation systems (e.g., Brent, 1999; Goldwater, Griffiths, &amp; Johnson, 2006; Blanchard &amp; Heinz, 2008) use only phonemic information to segment speech. However, human segmenters use additional information types, notably stress information, in their segmentation. We present an overview of these phonemic models here before discussing the prosodic model expansion. A more complete review is available in Goldwater (2007). 2.1 Goldwater et al (2006) The Goldwater et al model is related to Brent (1999)’s model, both of which use strictly phonemic information to segment. The model assumes that the corpus is generated by a Dirichlet process over 117 Proceedings of NAACL-HLT 2013, pages 117–126, Atlanta</context>
<context position="29360" citStr="Blanchard &amp; Heinz, 2008" startWordPosition="4781" endWordPosition="4784">y having an effectively stronger bias than English would suggest (reducing the first fraction)12 or, as with Phillips and Pearl’s constrained learners, by having effectively less input than the model assumes (reducing the second fraction). 6 Future work Introducing stress into the Bayesian segmentation model suggests a few additional expansions. One possibility is to add other cues into the generative model via Po. Any cue that is based on the word itself can be added in this way, with little change to the general model structure. Phonotactics can be added using an n-gram distribution for Po (Blanchard &amp; Heinz, 2008). Coarticulation between adjacent phonemes is also used in human segmentation (Johnson &amp; Jusczyk, 2001), so the Po distribution could predict higher within-word coarticulation. Integrating additional cues used by human segmenters extends the investigation of the bounds on rationality in human segmentation and in balancing multiple conflicting cues. 12A potential source of an inflated bias is infants’ preference for strong-weak patterns. Jusczyk, Cutler, and Redanz (1993) found English-hearing infants listened longer to strong-weak patterns than weak-strong. This could lead to overestimation of</context>
</contexts>
<marker>Blanchard, Heinz, 2008</marker>
<rawString>Blanchard, D., &amp; Heinz, J. (2008). Improving word segmentation by simultaneously learning phonotactics. In Proceedings of CoNLL (pp. 65–72).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Borfeld</author>
<author>J Morgan</author>
<author>R Golinkoff</author>
<author>K Rathbun</author>
</authors>
<title>Mommy and me: familiar names help launch babies into speech-stream segmentation.</title>
<date>2005</date>
<journal>Psychological Science,</journal>
<volume>16</volume>
<issue>4</issue>
<pages>298--304</pages>
<contexts>
<context position="10177" citStr="Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005" startWordPosition="1615" endWordPosition="1620">tion, which is a supersegmental feature most appropriately located on syllables. Syllabified data has been used in some previous models of segmentation, especially those using stress information or syllable-level transition probabilities (Christiansen et al., 1998; Swingley, 2005; Gambell &amp; Yang, 2006; Phillips &amp; Pearl, 2012). For studying human word segmentation, Phillips and Pearl argue syllabified speech may be a more cognitively plausible testing ground. 3-monthold infants appear to have categorical representations of syllables (Eimas, 1999), three months before word segmentation appears (Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005), and seven months before phoneme categorization (Werker &amp; Tees, 1984). In addition, syllabification is assumed in much work on human word segmentation, especially in artificial-language studies (e.g., Thiessen &amp; Saffran, 2003), which calculate statistical cues at the syllable level. The assumption that syllable boundaries are known affects the baseline performance of the model, as it reduces the number of possible word boundary locations (since a word boundary is necessarily a syllable boundary). As such performance over syllabified data cannot be directly compared to performance on non-syll</context>
</contexts>
<marker>Borfeld, Morgan, Golinkoff, Rathbun, 2005</marker>
<rawString>Borfeld, H., Morgan, J., Golinkoff, R., &amp; Rathbun, K. (2005). Mommy and me: familiar names help launch babies into speech-stream segmentation. Psychological Science, 16(4), 298–304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Brent</author>
</authors>
<title>An efficient, probabilistically sound algorithm for segmentation and word discovery.</title>
<date>1999</date>
<booktitle>Machine Learning,</booktitle>
<volume>34</volume>
<pages>71--105</pages>
<contexts>
<context position="2585" citStr="Brent, 1999" startWordPosition="391" endWordPosition="392"> year of life (Johnson &amp; Jusczyk, 2001). Despite this, many state-of-the-art models look at only one type of information: phonemes. In this study, we expand an existing model to incorporate multiple cues, leading to an improvement in segmentation performance and opening new ways of investigating human segmentation acquisition. On the latter point, we show that rational learners can learn to segment without encountering words in isolation, and that human learners deviate from rationality in certain segmentation tasks. 2 Previous work The prevailing unsupervised word segmentation systems (e.g., Brent, 1999; Goldwater, Griffiths, &amp; Johnson, 2006; Blanchard &amp; Heinz, 2008) use only phonemic information to segment speech. However, human segmenters use additional information types, notably stress information, in their segmentation. We present an overview of these phonemic models here before discussing the prosodic model expansion. A more complete review is available in Goldwater (2007). 2.1 Goldwater et al (2006) The Goldwater et al model is related to Brent (1999)’s model, both of which use strictly phonemic information to segment. The model assumes that the corpus is generated by a Dirichlet proce</context>
</contexts>
<marker>Brent, 1999</marker>
<rawString>Brent, M. R. (1999). An efficient, probabilistically sound algorithm for segmentation and word discovery. Machine Learning, 34, 71–105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M H Christiansen</author>
<author>J Allen</author>
<author>M S Seidenberg</author>
</authors>
<title>Learning to segment speech using multiple cues: A connectionist model.</title>
<date>1998</date>
<journal>Language and Cognitive Processes,</journal>
<volume>13</volume>
<pages>221--268</pages>
<contexts>
<context position="9798" citStr="Christiansen et al., 1998" startWordPosition="1562" endWordPosition="1565"> range of stress biases, although it prevents the model from generalizing biases across different word lengths. A potential future change to PS that would allow for better generalization is discussed in Section 6. 3.1 On syllabification and stress We change from segmenting on phonemes to segmenting on syllables in order to more easily implement stress information, which is a supersegmental feature most appropriately located on syllables. Syllabified data has been used in some previous models of segmentation, especially those using stress information or syllable-level transition probabilities (Christiansen et al., 1998; Swingley, 2005; Gambell &amp; Yang, 2006; Phillips &amp; Pearl, 2012). For studying human word segmentation, Phillips and Pearl argue syllabified speech may be a more cognitively plausible testing ground. 3-monthold infants appear to have categorical representations of syllables (Eimas, 1999), three months before word segmentation appears (Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005), and seven months before phoneme categorization (Werker &amp; Tees, 1984). In addition, syllabification is assumed in much work on human word segmentation, especially in artificial-language studies (e.g., Thiessen &amp; Saffran</context>
<context position="12022" citStr="Christiansen et al. (1998)" startWordPosition="1915" endWordPosition="1918">of deciding where a boundary goes between two syllable nuclei, with the assumption that there must be a boundary there. The problem of assigning word boundaries is a question of deciding whether there is a boundary between two syllable nuclei, and if so, where it is. Knowing the syllable boundaries reduces the set of possible word boundaries, but does not directly address the question of how likely a boundary is. The difference in these tasks is supported by the three-month gap between syllable and word identification in infants. 4 Data We use the Korman (1984) training corpus, as compiled by Christiansen et al. (1998), in this study. This is a 24493-word corpus of English spoken by adults to infants aged 6–16 weeks.4 Phonemes, stresses, and syllable boundaries are the same as those used by Christiansen et al, which were based on citation forms in the MRC Psycholinguistic Database. All monosyllabic words were coded as stressed. Only utterances for which all words had citation forms were included. This corpus is largely monosyllabic (87.3% of all word tokens), and heavily biased toward initial stress (89.2% of all multisyllable word tokens). No word is longer than three syllables, and most words have only on</context>
<context position="32166" citStr="Christiansen et al., 1998" startWordPosition="5224" endWordPosition="5227">ntations of the true data, and the dictionary-based phoneme and stress patterns used in this study are no exception. This ideal setting may paint a skewed picture of the segmentation problem, by providing a more consistent and learnable data source than humans actually receive. Elsner, Goldwater, and Eisenstein (2012)’s model unifying lexical and phonetic acquisition takes a significant step in showing that a rational segmenter can handle noisy input by recognizing phonetic variants of a base form. In terms of stress representations, dictionary-based stress has been standard in previous work (Christiansen et al., 1998; Gambell &amp; Yang, 2006; Rytting, Brew, &amp; Fosler-Lussier, 2010), but it is important to confirm such results against a (currently nonexistent) corpus with stresses based on the actual utterances. Effective use of stress in a less idealized setting may require a more complex representation of stress in the model. 124 7 Conclusion Effective word segmentation combines multiple factors to make predictions about word boundaries. We extended an existing Bayesian segmentation model to account for two factors, phonemes and stress, when segmenting. This improves segmentation performance and opens up new</context>
</contexts>
<marker>Christiansen, Allen, Seidenberg, 1998</marker>
<rawString>Christiansen, M. H., Allen, J., &amp; Seidenberg, M. S. (1998). Learning to segment speech using multiple cues: A connectionist model. Language and Cognitive Processes, 13, 221–268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cole</author>
<author>J Jakimik</author>
</authors>
<title>A model of speech perception. In Perception and production of fluent speech</title>
<date>1980</date>
<pages>136--163</pages>
<publisher>Erlbaum.</publisher>
<location>Hillsdale, NJ:</location>
<contexts>
<context position="1389" citStr="Cole &amp; Jakimik, 1980" startWordPosition="212" endWordPosition="215">ly, our model retains high performance even without single-word utterances. We also demonstrate a discrepancy in the performance of our model and human infants on an artificial-language task in which stress cues and transition-probability information are pitted against one another. We argue that this discrepancy indicates a bound on rationality in the mechanisms of human segmentation. 1 Introduction For an adult speaker of a language, word segmentation from fluid speech may seem so easy that it barely needed to be learned. However, pauses in speech and word boundaries are not well correlated (Cole &amp; Jakimik, 1980), word boundaries are marked by a conspiracy of partially-informative cues (Johnson &amp; Jusczyk, 2001), and different languages mark their boundaries differently (Cutler &amp; Carter, 1987). This makes the problem of unsupervised word segmentation acquisition, whether by a computational model or an infant, a daunting task. Effective segmentation relies on the flexible integration of multiple types of segmentation cues, among them statistical regularities in phonemes and prosody, coarticulation, and allophonic variation. Infants begin using multiple segmentation cues within their first year of life (</context>
</contexts>
<marker>Cole, Jakimik, 1980</marker>
<rawString>Cole, R., &amp; Jakimik, J. (1980). A model of speech perception. In Perception and production of fluent speech (pp. 136–163). Hillsdale, NJ: Erlbaum.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cutler</author>
<author>D Carter</author>
</authors>
<title>The predominance of strong initial syllables in the English vocabulary.</title>
<date>1987</date>
<journal>Comp. Speech Lang.,</journal>
<volume>2</volume>
<pages>133--142</pages>
<contexts>
<context position="1572" citStr="Cutler &amp; Carter, 1987" startWordPosition="238" endWordPosition="241">age task in which stress cues and transition-probability information are pitted against one another. We argue that this discrepancy indicates a bound on rationality in the mechanisms of human segmentation. 1 Introduction For an adult speaker of a language, word segmentation from fluid speech may seem so easy that it barely needed to be learned. However, pauses in speech and word boundaries are not well correlated (Cole &amp; Jakimik, 1980), word boundaries are marked by a conspiracy of partially-informative cues (Johnson &amp; Jusczyk, 2001), and different languages mark their boundaries differently (Cutler &amp; Carter, 1987). This makes the problem of unsupervised word segmentation acquisition, whether by a computational model or an infant, a daunting task. Effective segmentation relies on the flexible integration of multiple types of segmentation cues, among them statistical regularities in phonemes and prosody, coarticulation, and allophonic variation. Infants begin using multiple segmentation cues within their first year of life (Johnson &amp; Jusczyk, 2001). Despite this, many state-of-the-art models look at only one type of information: phonemes. In this study, we expand an existing model to incorporate multiple</context>
</contexts>
<marker>Cutler, Carter, 1987</marker>
<rawString>Cutler, A., &amp; Carter, D. (1987). The predominance of strong initial syllables in the English vocabulary. Comp. Speech Lang., 2, 133–142.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Eimas</author>
</authors>
<title>Segmental and syllabic representations in the perception of speech by young infants.</title>
<date>1999</date>
<journal>Journal of the Acoustic Society ofAmerica,</journal>
<volume>105</volume>
<pages>1901--1911</pages>
<contexts>
<context position="5539" citStr="Eimas, 1999" startWordPosition="890" endWordPosition="891">m model. To segment an observed corpus, the model Gibbs samples over the possible word boundaries (utterance boundaries are assumed to be word boundaries).2 The exchangability of draws from a Dirichlet process allows for Gibbs sampling of each possible boundary given all the others. 2.2 A cognitively-plausible variant Phillips and Pearl (2012) make these Bayesian segmentation models more cognitively plausible in two ways. The first is to move from phonemes to syllables as the base representational unit from which words are constructed, as infants learn to categorize syllables before phonemes (Eimas, 1999). The second is to add memory and processing constraints on the learner. They find that syllable-based segmentation is better than phoneme-based segmentation in the bigram model (though worse in the unigram model), and that, counter-intuitively, the constrained learner outperforms the unconstrained learner. This improvement appears to be driven by better performance in segmenting more common words. In this work, we adopt the syllabified representation but retain the unconstrained rational learner assumption. 2.3 Other multiple-cue models Some previous models have incorporated multiple cues, sp</context>
<context position="10085" citStr="Eimas, 1999" startWordPosition="1606" endWordPosition="1607">on syllables in order to more easily implement stress information, which is a supersegmental feature most appropriately located on syllables. Syllabified data has been used in some previous models of segmentation, especially those using stress information or syllable-level transition probabilities (Christiansen et al., 1998; Swingley, 2005; Gambell &amp; Yang, 2006; Phillips &amp; Pearl, 2012). For studying human word segmentation, Phillips and Pearl argue syllabified speech may be a more cognitively plausible testing ground. 3-monthold infants appear to have categorical representations of syllables (Eimas, 1999), three months before word segmentation appears (Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005), and seven months before phoneme categorization (Werker &amp; Tees, 1984). In addition, syllabification is assumed in much work on human word segmentation, especially in artificial-language studies (e.g., Thiessen &amp; Saffran, 2003), which calculate statistical cues at the syllable level. The assumption that syllable boundaries are known affects the baseline performance of the model, as it reduces the number of possible word boundary locations (since a word boundary is necessarily a syllable boundary). As s</context>
</contexts>
<marker>Eimas, 1999</marker>
<rawString>Eimas, P. (1999). Segmental and syllabic representations in the perception of speech by young infants. Journal of the Acoustic Society ofAmerica, 105, 1901–1911.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Elsner</author>
<author>S Goldwater</author>
<author>J Eisenstein</author>
</authors>
<title>Bootstrapping a unified model of lexical and phonetic acquisition.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th annual meeting of the ACL.</booktitle>
<marker>Elsner, Goldwater, Eisenstein, 2012</marker>
<rawString>Elsner, M., Goldwater, S., &amp; Eisenstein, J. (2012). Bootstrapping a unified model of lexical and phonetic acquisition. In Proceedings of the 50th annual meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Feldman</author>
<author>T Griffiths</author>
<author>J Morgan</author>
</authors>
<title>Learning phonetic categories by learning a lexicon.</title>
<date>2009</date>
<booktitle>In Proceedings of the 31st annual conference on cognitive science.</booktitle>
<contexts>
<context position="7442" citStr="Feldman, Griffiths, &amp; Morgan, 2009" startWordPosition="1173" endWordPosition="1178">Our model presents a more general and completely unsupervised approach to segmentation with multiple cuetypes. 2The model assumes that utterance boundaries are generated just like other words, and includes an adjustable parameter p$ to account for their frequency. nhwi−1,·i p((wi−1, wi) nn|wi−1) = , (1) nhwi−1,·i + α1 p(wi = x, wi nn |(wi−1, wi) ) =bh·,wii novel &apos; 118 In general, joint inference is becoming more common in language acquisition problems and has been shown to improve performance over single-feature inference. Examples include joint inference of a lexicon and phonetic categories (Feldman, Griffiths, &amp; Morgan, 2009), joint inference of syntactic word order and word reference (Maurits, Perfors, &amp; Navarro, 2009), and joint inference of word meanings and speaker intentions in child-directed speech (Frank, Goodman, &amp; Tenenbaum, 2009). 3 Model design Our model changes P0 from a single-cue distribution, generating only phonemes, to a multiple-cue distribution that generates a stress form as well. This can improve segmentation performance and allows the investigation of rational segmentation behavior in a multiple-cue world. In the original model, P0(wi = σ1 · · · σM) a Hj P(σj), where P(σj) is the frequency o</context>
</contexts>
<marker>Feldman, Griffiths, Morgan, 2009</marker>
<rawString>Feldman, N., Griffiths, T., &amp; Morgan, J. (2009). Learning phonetic categories by learning a lexicon. In Proceedings of the 31st annual conference on cognitive science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Frank</author>
<author>S Goldwater</author>
<author>T Griffiths</author>
<author>J Tenenbaum</author>
</authors>
<title>Modeling human performance in statistical word segmentation.</title>
<date>2010</date>
<journal>Cognition.</journal>
<contexts>
<context position="28558" citStr="Frank, Goldwater, Griffiths, &amp; Tenenbaum, 2010" startWordPosition="4650" endWordPosition="4656">easing the stress bias b or decreasing the number of observed word tokens makes the rational model more likely to segment with the stress bias (against transition probabilities), but as we see in the experimental results, the stress bias must be very strong to overcome the efficient lexicon that the transition probability segmentation provides. Since humans do not show this same inherent bias (or quickly lose it as they acquire the stress bias), we can ask how humans deviate from rationality. One possibility is that humans simply do not segment in this Bayesian manner. However, previous work (Frank, Goldwater, Griffiths, &amp; Tenenbaum, 2010) has shown that human word segmentation shows similar behavior to a resource-limited Bayesian model. Equation 8 suggests that human segmentation could deviate from rationality by having an effectively stronger bias than English would suggest (reducing the first fraction)12 or, as with Phillips and Pearl’s constrained learners, by having effectively less input than the model assumes (reducing the second fraction). 6 Future work Introducing stress into the Bayesian segmentation model suggests a few additional expansions. One possibility is to add other cues into the generative model via Po. Any</context>
</contexts>
<marker>Frank, Goldwater, Griffiths, Tenenbaum, 2010</marker>
<rawString>Frank, M., Goldwater, S., Griffiths, T., &amp; Tenenbaum, J. (2010). Modeling human performance in statistical word segmentation. Cognition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Frank</author>
<author>N Goodman</author>
<author>J Tenenbaum</author>
</authors>
<title>Using speakers’ referential intentions to model early cross-situational word learning.</title>
<date>2009</date>
<journal>Psychological Science,</journal>
<volume>20</volume>
<pages>579--585</pages>
<contexts>
<context position="7660" citStr="Frank, Goodman, &amp; Tenenbaum, 2009" startWordPosition="1206" endWordPosition="1210"> parameter p$ to account for their frequency. nhwi−1,·i p((wi−1, wi) nn|wi−1) = , (1) nhwi−1,·i + α1 p(wi = x, wi nn |(wi−1, wi) ) =bh·,wii novel &apos; 118 In general, joint inference is becoming more common in language acquisition problems and has been shown to improve performance over single-feature inference. Examples include joint inference of a lexicon and phonetic categories (Feldman, Griffiths, &amp; Morgan, 2009), joint inference of syntactic word order and word reference (Maurits, Perfors, &amp; Navarro, 2009), and joint inference of word meanings and speaker intentions in child-directed speech (Frank, Goodman, &amp; Tenenbaum, 2009). 3 Model design Our model changes P0 from a single-cue distribution, generating only phonemes, to a multiple-cue distribution that generates a stress form as well. This can improve segmentation performance and allows the investigation of rational segmentation behavior in a multiple-cue world. In the original model, P0(wi = σ1 · · · σM) a Hj P(σj), where P(σj) is the frequency of the phoneme σj. In the multiple-cue model, we first generate a phonemic form wi, then assign a stress pattern si to it. P0(wi,si) = PW(wi)PS(siJM) M = p#(1 − p#)M−1 P(σj)PS(siJM) (5) j The phonemic form wi has the sa</context>
</contexts>
<marker>Frank, Goodman, Tenenbaum, 2009</marker>
<rawString>Frank, M., Goodman, N., &amp; Tenenbaum, J. (2009). Using speakers’ referential intentions to model early cross-situational word learning. Psychological Science, 20, 579–585.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Gambell</author>
<author>C Yang</author>
</authors>
<title>Word segmentation: Quick but not dirty.</title>
<date>2006</date>
<note>(Unpublished manuscript)</note>
<contexts>
<context position="6330" citStr="Gambell and Yang (2006)" startWordPosition="1002" endWordPosition="1005">ram model (though worse in the unigram model), and that, counter-intuitively, the constrained learner outperforms the unconstrained learner. This improvement appears to be driven by better performance in segmenting more common words. In this work, we adopt the syllabified representation but retain the unconstrained rational learner assumption. 2.3 Other multiple-cue models Some previous models have incorporated multiple cues, specifically the phonemic and stress information that our model will use. Two prominent examples are Christiansen, Allen, and Seidenberg (1998)’s connectionist model and Gambell and Yang (2006)’s algebraic model. The connectionist model places word boundaries where the combination of phonemic and stress information predict likely utterance boundaries, but does not include an explicit sense of “word”, and performs only modestly on the segmentation task (boundary F-scores of .40- .45). The algebraic model also underperforms the Bayesian model (Phillips &amp; Pearl, 2012) unless it includes the heuristic that there is a word boundary between any two stressed syllables. Our model presents a more general and completely unsupervised approach to segmentation with multiple cuetypes. 2The model </context>
<context position="13030" citStr="Gambell and Yang (2006)" startWordPosition="2078" endWordPosition="2081"> This corpus is largely monosyllabic (87.3% of all word tokens), and heavily biased toward initial stress (89.2% of all multisyllable word tokens). No word is longer than three syllables, and most words have only one stressed syllable. A breakdown of the corpus by stress pattern is given in Table 1. This monosyllabic bias is an inherent property of English, not idiosyncratic to this corpus. The Bernstein-Ratner child-directed corpus is also over 80% monosyllabic. We expect that the results of segmentation on child-directed data will extend to adult speech, as the adult-directed corpus used by Gambell and Yang (2006) has an average word length of 1.17 syllables. 5 Experiments We test the model on three problems. First, we show that the addition of stress information improves segmentation performance compared to a stress-less model. Next, we apply the model to a question in human segmentation acquisition. Finally, we look at 4Approximately 150 word tokens from the original corpus were omitted in our version of the corpus due to a disparity between recorded number of syllables and number of stresses. Types Tokens Stress pattern Count Stress pattern Count S 21402 S 523 SW 2231 SW 208 SS 389 WS 40 WS 284 SWW </context>
<context position="9836" citStr="Gambell &amp; Yang, 2006" startWordPosition="1568" endWordPosition="1571">ts the model from generalizing biases across different word lengths. A potential future change to PS that would allow for better generalization is discussed in Section 6. 3.1 On syllabification and stress We change from segmenting on phonemes to segmenting on syllables in order to more easily implement stress information, which is a supersegmental feature most appropriately located on syllables. Syllabified data has been used in some previous models of segmentation, especially those using stress information or syllable-level transition probabilities (Christiansen et al., 1998; Swingley, 2005; Gambell &amp; Yang, 2006; Phillips &amp; Pearl, 2012). For studying human word segmentation, Phillips and Pearl argue syllabified speech may be a more cognitively plausible testing ground. 3-monthold infants appear to have categorical representations of syllables (Eimas, 1999), three months before word segmentation appears (Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005), and seven months before phoneme categorization (Werker &amp; Tees, 1984). In addition, syllabification is assumed in much work on human word segmentation, especially in artificial-language studies (e.g., Thiessen &amp; Saffran, 2003), which calculate statistical c</context>
<context position="32188" citStr="Gambell &amp; Yang, 2006" startWordPosition="5228" endWordPosition="5231">and the dictionary-based phoneme and stress patterns used in this study are no exception. This ideal setting may paint a skewed picture of the segmentation problem, by providing a more consistent and learnable data source than humans actually receive. Elsner, Goldwater, and Eisenstein (2012)’s model unifying lexical and phonetic acquisition takes a significant step in showing that a rational segmenter can handle noisy input by recognizing phonetic variants of a base form. In terms of stress representations, dictionary-based stress has been standard in previous work (Christiansen et al., 1998; Gambell &amp; Yang, 2006; Rytting, Brew, &amp; Fosler-Lussier, 2010), but it is important to confirm such results against a (currently nonexistent) corpus with stresses based on the actual utterances. Effective use of stress in a less idealized setting may require a more complex representation of stress in the model. 124 7 Conclusion Effective word segmentation combines multiple factors to make predictions about word boundaries. We extended an existing Bayesian segmentation model to account for two factors, phonemes and stress, when segmenting. This improves segmentation performance and opens up new possibilities for com</context>
</contexts>
<marker>Gambell, Yang, 2006</marker>
<rawString>Gambell, T., &amp; Yang, C. (2006). Word segmentation: Quick but not dirty. (Unpublished manuscript)</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
</authors>
<title>Nonparametric Bayesian models of lexical acquisition.</title>
<date>2007</date>
<institution>Brown Univ.</institution>
<note>Unpublished doctoral dissertation,</note>
<contexts>
<context position="2967" citStr="Goldwater (2007)" startWordPosition="446" endWordPosition="447">ers can learn to segment without encountering words in isolation, and that human learners deviate from rationality in certain segmentation tasks. 2 Previous work The prevailing unsupervised word segmentation systems (e.g., Brent, 1999; Goldwater, Griffiths, &amp; Johnson, 2006; Blanchard &amp; Heinz, 2008) use only phonemic information to segment speech. However, human segmenters use additional information types, notably stress information, in their segmentation. We present an overview of these phonemic models here before discussing the prosodic model expansion. A more complete review is available in Goldwater (2007). 2.1 Goldwater et al (2006) The Goldwater et al model is related to Brent (1999)’s model, both of which use strictly phonemic information to segment. The model assumes that the corpus is generated by a Dirichlet process over 117 Proceedings of NAACL-HLT 2013, pages 117–126, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics word bigrams.1 We present a basic overview here, based on Sect. 5.5 of Goldwater, 2007. To generate the word wi given the preceding word wi−1: 1. Decide if bigram bi = (wi−1, wi) is novel 2. If bi non-novel, draw bi from bigram lexicon 3. If</context>
</contexts>
<marker>Goldwater, 2007</marker>
<rawString>Goldwater, S. (2007). Nonparametric Bayesian models of lexical acquisition. Unpublished doctoral dissertation, Brown Univ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>T Griffiths</author>
<author>M Johnson</author>
</authors>
<title>Contextual dependencies in unsupervised word segmentation.</title>
<date>2006</date>
<booktitle>In Proceedings of Coling/ACL.</booktitle>
<contexts>
<context position="2624" citStr="Goldwater, Griffiths, &amp; Johnson, 2006" startWordPosition="393" endWordPosition="397"> (Johnson &amp; Jusczyk, 2001). Despite this, many state-of-the-art models look at only one type of information: phonemes. In this study, we expand an existing model to incorporate multiple cues, leading to an improvement in segmentation performance and opening new ways of investigating human segmentation acquisition. On the latter point, we show that rational learners can learn to segment without encountering words in isolation, and that human learners deviate from rationality in certain segmentation tasks. 2 Previous work The prevailing unsupervised word segmentation systems (e.g., Brent, 1999; Goldwater, Griffiths, &amp; Johnson, 2006; Blanchard &amp; Heinz, 2008) use only phonemic information to segment speech. However, human segmenters use additional information types, notably stress information, in their segmentation. We present an overview of these phonemic models here before discussing the prosodic model expansion. A more complete review is available in Goldwater (2007). 2.1 Goldwater et al (2006) The Goldwater et al model is related to Brent (1999)’s model, both of which use strictly phonemic information to segment. The model assumes that the corpus is generated by a Dirichlet process over 117 Proceedings of NAACL-HLT 20</context>
<context position="2995" citStr="Goldwater et al (2006)" startWordPosition="449" endWordPosition="452">nt without encountering words in isolation, and that human learners deviate from rationality in certain segmentation tasks. 2 Previous work The prevailing unsupervised word segmentation systems (e.g., Brent, 1999; Goldwater, Griffiths, &amp; Johnson, 2006; Blanchard &amp; Heinz, 2008) use only phonemic information to segment speech. However, human segmenters use additional information types, notably stress information, in their segmentation. We present an overview of these phonemic models here before discussing the prosodic model expansion. A more complete review is available in Goldwater (2007). 2.1 Goldwater et al (2006) The Goldwater et al model is related to Brent (1999)’s model, both of which use strictly phonemic information to segment. The model assumes that the corpus is generated by a Dirichlet process over 117 Proceedings of NAACL-HLT 2013, pages 117–126, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics word bigrams.1 We present a basic overview here, based on Sect. 5.5 of Goldwater, 2007. To generate the word wi given the preceding word wi−1: 1. Decide if bigram bi = (wi−1, wi) is novel 2. If bi non-novel, draw bi from bigram lexicon 3. If bi novel, decide whether wi</context>
</contexts>
<marker>Goldwater, Griffiths, Johnson, 2006</marker>
<rawString>Goldwater, S., Griffiths, T., &amp; Johnson, M. (2006). Contextual dependencies in unsupervised word segmentation. In Proceedings of Coling/ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Goldwater</author>
<author>T L Griffiths</author>
<author>M Johnson</author>
</authors>
<title>A Bayesian framework for word segmentation: Exploring the effects of context.</title>
<date>2009</date>
<journal>Cognition,</journal>
<volume>112</volume>
<pages>21--54</pages>
<marker>Goldwater, Griffiths, Johnson, 2009</marker>
<rawString>Goldwater, S., Griffiths, T. L., &amp; Johnson, M. (2009). A Bayesian framework for word segmentation: Exploring the effects of context. Cognition, 112, 21–54.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Johnson</author>
<author>P Jusczyk</author>
</authors>
<title>Word segmentation by 8-month-olds: When speech cues count more than statistics.</title>
<date>2001</date>
<journal>J. of Memory and Language,</journal>
<volume>44</volume>
<pages>548--567</pages>
<contexts>
<context position="1489" citStr="Johnson &amp; Jusczyk, 2001" startWordPosition="226" endWordPosition="229"> discrepancy in the performance of our model and human infants on an artificial-language task in which stress cues and transition-probability information are pitted against one another. We argue that this discrepancy indicates a bound on rationality in the mechanisms of human segmentation. 1 Introduction For an adult speaker of a language, word segmentation from fluid speech may seem so easy that it barely needed to be learned. However, pauses in speech and word boundaries are not well correlated (Cole &amp; Jakimik, 1980), word boundaries are marked by a conspiracy of partially-informative cues (Johnson &amp; Jusczyk, 2001), and different languages mark their boundaries differently (Cutler &amp; Carter, 1987). This makes the problem of unsupervised word segmentation acquisition, whether by a computational model or an infant, a daunting task. Effective segmentation relies on the flexible integration of multiple types of segmentation cues, among them statistical regularities in phonemes and prosody, coarticulation, and allophonic variation. Infants begin using multiple segmentation cues within their first year of life (Johnson &amp; Jusczyk, 2001). Despite this, many state-of-the-art models look at only one type of inform</context>
<context position="19399" citStr="Johnson &amp; Jusczyk, 2001" startWordPosition="3138" endWordPosition="3141">segmenters undersegment (Peters, 1983). This raises an important question about what the model should seek to optimize: though the baseline is more accurate by token, no structure is learned; type performance is more important if we want to learn the underlying structure. 5.3 Are isolated words necessary? We next use this model to test the necessity of isolated words in rational word segmentation. It is not immediately obvious how human learners begin to segment words from fluid speech. Stress biases and other phonological cues are dominant in all but the earliest of infant word segmentation (Johnson &amp; Jusczyk, 2001). This raises a chicken-and-egg problem; if the cues infants favor to segment words, such as stress biases, are dependent on the words of the 7Note this defines a stress bias for the stressless model as well. 121 language, how do they learn enough words to determine the cues’ biases? One existing proposal is that human learners develop their stress biases based on words frequently heard in isolation (Jusczyk et al., 1999). In English, these include names and common diminutives (e.g., mommy, kitty) that generally have initial stress. These single-word utterances could offer the segmenter an ini</context>
<context position="29463" citStr="Johnson &amp; Jusczyk, 2001" startWordPosition="4796" endWordPosition="4799"> with Phillips and Pearl’s constrained learners, by having effectively less input than the model assumes (reducing the second fraction). 6 Future work Introducing stress into the Bayesian segmentation model suggests a few additional expansions. One possibility is to add other cues into the generative model via Po. Any cue that is based on the word itself can be added in this way, with little change to the general model structure. Phonotactics can be added using an n-gram distribution for Po (Blanchard &amp; Heinz, 2008). Coarticulation between adjacent phonemes is also used in human segmentation (Johnson &amp; Jusczyk, 2001), so the Po distribution could predict higher within-word coarticulation. Integrating additional cues used by human segmenters extends the investigation of the bounds on rationality in human segmentation and in balancing multiple conflicting cues. 12A potential source of an inflated bias is infants’ preference for strong-weak patterns. Jusczyk, Cutler, and Redanz (1993) found English-hearing infants listened longer to strong-weak patterns than weak-strong. This could lead to overestimation of the stress bias by making possible strong-weak segmentations more prominent in the segmenter’s mind. A</context>
</contexts>
<marker>Johnson, Jusczyk, 2001</marker>
<rawString>Johnson, E., &amp; Jusczyk, P. (2001). Word segmentation by 8-month-olds: When speech cues count more than statistics. J. of Memory and Language, 44, 548–567.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Jusczyk</author>
<author>A Cutler</author>
<author>N Redanz</author>
</authors>
<title>Preference for predominant stress patterns of English words.</title>
<date>1993</date>
<journal>Child Development,</journal>
<volume>64</volume>
<pages>675--687</pages>
<marker>Jusczyk, Cutler, Redanz, 1993</marker>
<rawString>Jusczyk, P., Cutler, A., &amp; Redanz, N. (1993). Preference for predominant stress patterns of English words. Child Development, 64, 675– 687.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Jusczyk</author>
<author>D Houston</author>
<author>M Newsome</author>
</authors>
<title>The beginnings of word segmentation in English-learning infants.</title>
<date>1999</date>
<journal>Cognitive Psychology,</journal>
<volume>39</volume>
<pages>159--207</pages>
<contexts>
<context position="17507" citStr="Jusczyk, Houston, &amp; Newsome, 1999" startWordPosition="2824" endWordPosition="2828">a binomial test on the two models’ lexicon accuracy; this result was marginal (p = .06). The explicit tracking of stress information also improves the model’s acquisition of the stress bias of the language. Acquisition of the stress bias is potentially useful for generalization; stress patterns can be used for an initial segmentation if few or none of the words are familiar. In practice, we see children use 6Recall that due to the syllabified data, these results are not directly comparable to unsyllabified results in previous work. their stress biases to segment new words from English speech (Jusczyk, Houston, &amp; Newsome, 1999) as well as artificial languages (Thiessen &amp; Saffran, 2003). We assess the learned stress bias by dividing up the corpus as the model has segmented it, and count the number of tokens with SW versus WS stress patterns.7 With stress representation, the learned stress bias is 6.77:1, and without stress representation, the stress bias is lower, at 6.33:1. Although these are both underestimates of the corpus’s true stress bias (7.86:1), the stressed model is stronger and a better estimate of the true value. The model’s performance can be compared to various baselines, but perhaps the strongest is </context>
<context position="19824" citStr="Jusczyk et al., 1999" startWordPosition="3212" endWordPosition="3215">us how human learners begin to segment words from fluid speech. Stress biases and other phonological cues are dominant in all but the earliest of infant word segmentation (Johnson &amp; Jusczyk, 2001). This raises a chicken-and-egg problem; if the cues infants favor to segment words, such as stress biases, are dependent on the words of the 7Note this defines a stress bias for the stressless model as well. 121 language, how do they learn enough words to determine the cues’ biases? One existing proposal is that human learners develop their stress biases based on words frequently heard in isolation (Jusczyk et al., 1999). In English, these include names and common diminutives (e.g., mommy, kitty) that generally have initial stress. These single-word utterances could offer the segmenter an initial guess of the stress bias, by supposing that short utterances are single words and recording their stress patterns. The most common stress patterns in short utterances could then be used as an initial guess at the stress bias to bootstrap other words and thereby improve the learned stress bias. We test the rational learner’s need for such explicit bootstrapping by learning to segment a corpus with all single-word utte</context>
</contexts>
<marker>Jusczyk, Houston, Newsome, 1999</marker>
<rawString>Jusczyk, P., Houston, D., &amp; Newsome, M. (1999). The beginnings of word segmentation in English-learning infants. Cognitive Psychology, 39, 159–207.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Korman</author>
</authors>
<title>Adaptive aspects of maternal vocalizations in differing contexts at ten weeks.</title>
<date>1984</date>
<journal>First language,</journal>
<volume>5</volume>
<pages>44--45</pages>
<contexts>
<context position="11963" citStr="Korman (1984)" startWordPosition="1907" endWordPosition="1908">f assigning syllable boundaries is a question of deciding where a boundary goes between two syllable nuclei, with the assumption that there must be a boundary there. The problem of assigning word boundaries is a question of deciding whether there is a boundary between two syllable nuclei, and if so, where it is. Knowing the syllable boundaries reduces the set of possible word boundaries, but does not directly address the question of how likely a boundary is. The difference in these tasks is supported by the three-month gap between syllable and word identification in infants. 4 Data We use the Korman (1984) training corpus, as compiled by Christiansen et al. (1998), in this study. This is a 24493-word corpus of English spoken by adults to infants aged 6–16 weeks.4 Phonemes, stresses, and syllable boundaries are the same as those used by Christiansen et al, which were based on citation forms in the MRC Psycholinguistic Database. All monosyllabic words were coded as stressed. Only utterances for which all words had citation forms were included. This corpus is largely monosyllabic (87.3% of all word tokens), and heavily biased toward initial stress (89.2% of all multisyllable word tokens). No word </context>
</contexts>
<marker>Korman, 1984</marker>
<rawString>Korman, M. (1984). Adaptive aspects of maternal vocalizations in differing contexts at ten weeks. First language, 5, 44–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Maurits</author>
<author>A Perfors</author>
<author>D Navarro</author>
</authors>
<title>Joint acquisition of word order and word reference.</title>
<date>2009</date>
<booktitle>In Proceedings of 31st annual conference of the Cognitive Science Society.</booktitle>
<contexts>
<context position="7538" citStr="Maurits, Perfors, &amp; Navarro, 2009" startWordPosition="1188" endWordPosition="1192">ple cuetypes. 2The model assumes that utterance boundaries are generated just like other words, and includes an adjustable parameter p$ to account for their frequency. nhwi−1,·i p((wi−1, wi) nn|wi−1) = , (1) nhwi−1,·i + α1 p(wi = x, wi nn |(wi−1, wi) ) =bh·,wii novel &apos; 118 In general, joint inference is becoming more common in language acquisition problems and has been shown to improve performance over single-feature inference. Examples include joint inference of a lexicon and phonetic categories (Feldman, Griffiths, &amp; Morgan, 2009), joint inference of syntactic word order and word reference (Maurits, Perfors, &amp; Navarro, 2009), and joint inference of word meanings and speaker intentions in child-directed speech (Frank, Goodman, &amp; Tenenbaum, 2009). 3 Model design Our model changes P0 from a single-cue distribution, generating only phonemes, to a multiple-cue distribution that generates a stress form as well. This can improve segmentation performance and allows the investigation of rational segmentation behavior in a multiple-cue world. In the original model, P0(wi = σ1 · · · σM) a Hj P(σj), where P(σj) is the frequency of the phoneme σj. In the multiple-cue model, we first generate a phonemic form wi, then assign a</context>
</contexts>
<marker>Maurits, Perfors, Navarro, 2009</marker>
<rawString>Maurits, L., Perfors, A., &amp; Navarro, D. (2009). Joint acquisition of word order and word reference. In Proceedings of 31st annual conference of the Cognitive Science Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Peters</author>
</authors>
<title>The units of language acquisition: Monographs in applied psycholinguistics.</title>
<date>1983</date>
<publisher>Cambridge Univ. Press.</publisher>
<contexts>
<context position="18813" citStr="Peters, 1983" startWordPosition="3043" endWordPosition="3044"> boundary precision being at ceiling (as in the model) to boundary recall being at ceiling. In fact, due to the preponderance of monosyllabic words in English childdirected speech, this baseline outperforms the model on word and boundary F-scores (.68 and .82 in the model, .82 and .91 in the baseline). However, the baseline’s lexicon is much worse than the model’s (F=.80 in the with-stress model, F=.64 in the baseline), and the baseline fails to learn anything about the language’s stress biases. In addition, the baseline oversegments, whereas both the model and infant segmenters undersegment (Peters, 1983). This raises an important question about what the model should seek to optimize: though the baseline is more accurate by token, no structure is learned; type performance is more important if we want to learn the underlying structure. 5.3 Are isolated words necessary? We next use this model to test the necessity of isolated words in rational word segmentation. It is not immediately obvious how human learners begin to segment words from fluid speech. Stress biases and other phonological cues are dominant in all but the earliest of infant word segmentation (Johnson &amp; Jusczyk, 2001). This raises </context>
</contexts>
<marker>Peters, 1983</marker>
<rawString>Peters, A. (1983). The units of language acquisition: Monographs in applied psycholinguistics. Cambridge Univ. Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Phillips</author>
<author>L Pearl</author>
</authors>
<title>less is more” in Bayesian word segmentation: When cognitively plausible learners outperform the ideal.</title>
<date>2012</date>
<booktitle>In Proceedings of the 34th annual conference of the cognitive science society.</booktitle>
<contexts>
<context position="5272" citStr="Phillips and Pearl (2012)" startWordPosition="846" endWordPosition="849">: p(wi = σ1 ··· σM |wi novel ) = p#(1 − p#)M−1 H P(σ3-) 1We will only discuss the bigram model here because it is more appropriate from both a cognitive perspective (it posits latent hierarchical structure) and engineering perspective (it segments more accurately) than the unigram model. To segment an observed corpus, the model Gibbs samples over the possible word boundaries (utterance boundaries are assumed to be word boundaries).2 The exchangability of draws from a Dirichlet process allows for Gibbs sampling of each possible boundary given all the others. 2.2 A cognitively-plausible variant Phillips and Pearl (2012) make these Bayesian segmentation models more cognitively plausible in two ways. The first is to move from phonemes to syllables as the base representational unit from which words are constructed, as infants learn to categorize syllables before phonemes (Eimas, 1999). The second is to add memory and processing constraints on the learner. They find that syllable-based segmentation is better than phoneme-based segmentation in the bigram model (though worse in the unigram model), and that, counter-intuitively, the constrained learner outperforms the unconstrained learner. This improvement appears</context>
<context position="6708" citStr="Phillips &amp; Pearl, 2012" startWordPosition="1057" endWordPosition="1060">me previous models have incorporated multiple cues, specifically the phonemic and stress information that our model will use. Two prominent examples are Christiansen, Allen, and Seidenberg (1998)’s connectionist model and Gambell and Yang (2006)’s algebraic model. The connectionist model places word boundaries where the combination of phonemic and stress information predict likely utterance boundaries, but does not include an explicit sense of “word”, and performs only modestly on the segmentation task (boundary F-scores of .40- .45). The algebraic model also underperforms the Bayesian model (Phillips &amp; Pearl, 2012) unless it includes the heuristic that there is a word boundary between any two stressed syllables. Our model presents a more general and completely unsupervised approach to segmentation with multiple cuetypes. 2The model assumes that utterance boundaries are generated just like other words, and includes an adjustable parameter p$ to account for their frequency. nhwi−1,·i p((wi−1, wi) nn|wi−1) = , (1) nhwi−1,·i + α1 p(wi = x, wi nn |(wi−1, wi) ) =bh·,wii novel &apos; 118 In general, joint inference is becoming more common in language acquisition problems and has been shown to improve performance ov</context>
<context position="9861" citStr="Phillips &amp; Pearl, 2012" startWordPosition="1572" endWordPosition="1575">ralizing biases across different word lengths. A potential future change to PS that would allow for better generalization is discussed in Section 6. 3.1 On syllabification and stress We change from segmenting on phonemes to segmenting on syllables in order to more easily implement stress information, which is a supersegmental feature most appropriately located on syllables. Syllabified data has been used in some previous models of segmentation, especially those using stress information or syllable-level transition probabilities (Christiansen et al., 1998; Swingley, 2005; Gambell &amp; Yang, 2006; Phillips &amp; Pearl, 2012). For studying human word segmentation, Phillips and Pearl argue syllabified speech may be a more cognitively plausible testing ground. 3-monthold infants appear to have categorical representations of syllables (Eimas, 1999), three months before word segmentation appears (Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005), and seven months before phoneme categorization (Werker &amp; Tees, 1984). In addition, syllabification is assumed in much work on human word segmentation, especially in artificial-language studies (e.g., Thiessen &amp; Saffran, 2003), which calculate statistical cues at the syllable level</context>
</contexts>
<marker>Phillips, Pearl, 2012</marker>
<rawString>Phillips, L., &amp; Pearl, L. (2012). “less is more” in Bayesian word segmentation: When cognitively plausible learners outperform the ideal. In Proceedings of the 34th annual conference of the cognitive science society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C A Rytting</author>
<author>C Brew</author>
<author>E Fosler-Lussier</author>
</authors>
<title>Segmenting words from natural speech: subsegmental variation in segmental cues.</title>
<date>2010</date>
<journal>Journal of Child Language,</journal>
<volume>37</volume>
<pages>513--543</pages>
<contexts>
<context position="32227" citStr="Rytting, Brew, &amp; Fosler-Lussier, 2010" startWordPosition="5232" endWordPosition="5236">ed phoneme and stress patterns used in this study are no exception. This ideal setting may paint a skewed picture of the segmentation problem, by providing a more consistent and learnable data source than humans actually receive. Elsner, Goldwater, and Eisenstein (2012)’s model unifying lexical and phonetic acquisition takes a significant step in showing that a rational segmenter can handle noisy input by recognizing phonetic variants of a base form. In terms of stress representations, dictionary-based stress has been standard in previous work (Christiansen et al., 1998; Gambell &amp; Yang, 2006; Rytting, Brew, &amp; Fosler-Lussier, 2010), but it is important to confirm such results against a (currently nonexistent) corpus with stresses based on the actual utterances. Effective use of stress in a less idealized setting may require a more complex representation of stress in the model. 124 7 Conclusion Effective word segmentation combines multiple factors to make predictions about word boundaries. We extended an existing Bayesian segmentation model to account for two factors, phonemes and stress, when segmenting. This improves segmentation performance and opens up new possibilities for comparing rational segmentation and human </context>
</contexts>
<marker>Rytting, Brew, Fosler-Lussier, 2010</marker>
<rawString>Rytting, C. A., Brew, C., &amp; Fosler-Lussier, E. (2010). Segmenting words from natural speech: subsegmental variation in segmental cues. Journal of Child Language, 37, 513– 543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Swingley</author>
</authors>
<title>Statistical clustering and the contents of the infant vocabulary.</title>
<date>2005</date>
<journal>Cognitive Psychology,</journal>
<volume>50</volume>
<pages>86--132</pages>
<contexts>
<context position="9814" citStr="Swingley, 2005" startWordPosition="1566" endWordPosition="1567">though it prevents the model from generalizing biases across different word lengths. A potential future change to PS that would allow for better generalization is discussed in Section 6. 3.1 On syllabification and stress We change from segmenting on phonemes to segmenting on syllables in order to more easily implement stress information, which is a supersegmental feature most appropriately located on syllables. Syllabified data has been used in some previous models of segmentation, especially those using stress information or syllable-level transition probabilities (Christiansen et al., 1998; Swingley, 2005; Gambell &amp; Yang, 2006; Phillips &amp; Pearl, 2012). For studying human word segmentation, Phillips and Pearl argue syllabified speech may be a more cognitively plausible testing ground. 3-monthold infants appear to have categorical representations of syllables (Eimas, 1999), three months before word segmentation appears (Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005), and seven months before phoneme categorization (Werker &amp; Tees, 1984). In addition, syllabification is assumed in much work on human word segmentation, especially in artificial-language studies (e.g., Thiessen &amp; Saffran, 2003), which c</context>
</contexts>
<marker>Swingley, 2005</marker>
<rawString>Swingley, D. (2005). Statistical clustering and the contents of the infant vocabulary. Cognitive Psychology, 50, 86–132.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E D Thiessen</author>
<author>J R Saffran</author>
</authors>
<title>When cues collide: Use of stress and statistical cues to word boundaries by 7- to 9-month-old infants.</title>
<date>2003</date>
<journal>Developmental Psychology,</journal>
<volume>39</volume>
<issue>4</issue>
<pages>706--716</pages>
<contexts>
<context position="21507" citStr="Thiessen and Saffran (2003)" startWordPosition="3481" endWordPosition="3484">ll. Without single-word utterances, boundary and lexical F-scores are .81 and .80, compared to .82 and .80 with single-word utterances. This shows that rational learners are able to segment even without the possibility of bootstrapping stress patterns from single-word utterances. 5.4 Bounded rationality in human segmentation Lastly, we use this model to examine rational performance in a multiple-cue segmentation task. We show that humans’ segmentation does not adhere to these predictions, suggesting a bound on human rationality in word segmentation. We consider an artificial language study by Thiessen and Saffran (2003). In this study, infants are exposed to an artificial language consisting of four bisyllabic word types uttered repeatedly without pauses. Each syllable appears in only one word type, so within-word transition probabilities are always 1, while across-word transition probabilities are less than 0.5. Segmentation strategies that hyAgainst bias, with TP AB CD CD AB WS WS WS WS With bias, against TP A BC DC DA B W SW SW SW S Table 3: Examples of segmenting an artificial language according to transition probabilities (top) or stress bias (bottom), when the true words have weak-strong stress. Vertic</context>
<context position="10405" citStr="Thiessen &amp; Saffran, 2003" startWordPosition="1648" endWordPosition="1652">ansen et al., 1998; Swingley, 2005; Gambell &amp; Yang, 2006; Phillips &amp; Pearl, 2012). For studying human word segmentation, Phillips and Pearl argue syllabified speech may be a more cognitively plausible testing ground. 3-monthold infants appear to have categorical representations of syllables (Eimas, 1999), three months before word segmentation appears (Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005), and seven months before phoneme categorization (Werker &amp; Tees, 1984). In addition, syllabification is assumed in much work on human word segmentation, especially in artificial-language studies (e.g., Thiessen &amp; Saffran, 2003), which calculate statistical cues at the syllable level. The assumption that syllable boundaries are known affects the baseline performance of the model, as it reduces the number of possible word boundary locations (since a word boundary is necessarily a syllable boundary). As such performance over syllabified data cannot be directly compared to performance on non-syllabified data. It may seem that syllabification is so closely tied to word segmentation that including the former in a model of the latter leaves little to the model. However, the determinants of syllable boundaries are not the s</context>
<context position="17567" citStr="Thiessen &amp; Saffran, 2003" startWordPosition="2834" endWordPosition="2837"> marginal (p = .06). The explicit tracking of stress information also improves the model’s acquisition of the stress bias of the language. Acquisition of the stress bias is potentially useful for generalization; stress patterns can be used for an initial segmentation if few or none of the words are familiar. In practice, we see children use 6Recall that due to the syllabified data, these results are not directly comparable to unsyllabified results in previous work. their stress biases to segment new words from English speech (Jusczyk, Houston, &amp; Newsome, 1999) as well as artificial languages (Thiessen &amp; Saffran, 2003). We assess the learned stress bias by dividing up the corpus as the model has segmented it, and count the number of tokens with SW versus WS stress patterns.7 With stress representation, the learned stress bias is 6.77:1, and without stress representation, the stress bias is lower, at 6.33:1. Although these are both underestimates of the corpus’s true stress bias (7.86:1), the stressed model is stronger and a better estimate of the true value. The model’s performance can be compared to various baselines, but perhaps the strongest is one with every syllable boundary being a word boundary. This</context>
</contexts>
<marker>Thiessen, Saffran, 2003</marker>
<rawString>Thiessen, E. D., &amp; Saffran, J. R. (2003). When cues collide: Use of stress and statistical cues to word boundaries by 7- to 9-month-old infants. Developmental Psychology, 39(4), 706–716.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Werker</author>
<author>R Tees</author>
</authors>
<title>Cross-language speech perception: Evidence for perceptual reorganization during the first year of life.</title>
<date>1984</date>
<journal>Infant Behavior and Development,</journal>
<volume>7</volume>
<pages>49--63</pages>
<contexts>
<context position="10248" citStr="Werker &amp; Tees, 1984" startWordPosition="1627" endWordPosition="1630">ata has been used in some previous models of segmentation, especially those using stress information or syllable-level transition probabilities (Christiansen et al., 1998; Swingley, 2005; Gambell &amp; Yang, 2006; Phillips &amp; Pearl, 2012). For studying human word segmentation, Phillips and Pearl argue syllabified speech may be a more cognitively plausible testing ground. 3-monthold infants appear to have categorical representations of syllables (Eimas, 1999), three months before word segmentation appears (Borfeld, Morgan, Golinkoff, &amp; Rathbun, 2005), and seven months before phoneme categorization (Werker &amp; Tees, 1984). In addition, syllabification is assumed in much work on human word segmentation, especially in artificial-language studies (e.g., Thiessen &amp; Saffran, 2003), which calculate statistical cues at the syllable level. The assumption that syllable boundaries are known affects the baseline performance of the model, as it reduces the number of possible word boundary locations (since a word boundary is necessarily a syllable boundary). As such performance over syllabified data cannot be directly compared to performance on non-syllabified data. It may seem that syllabification is so closely tied to wo</context>
</contexts>
<marker>Werker, Tees, 1984</marker>
<rawString>Werker, J., &amp; Tees, R. (1984). Cross-language speech perception: Evidence for perceptual reorganization during the first year of life. Infant Behavior and Development, 7, 49–63.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>