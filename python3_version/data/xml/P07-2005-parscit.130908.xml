<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011410">
<title confidence="0.970328">
System Demonstration of On-Demand Information Extraction
</title>
<author confidence="0.902852">
Satoshi Sekine
</author>
<affiliation confidence="0.780292">
New York University
</affiliation>
<address confidence="0.984383">
715 Broadway, 7th floor
New York, NY 10003 USA
</address>
<email confidence="0.999816">
sekine@cs.nyu.edu
</email>
<sectionHeader confidence="0.993924" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999391">
In this paper, we will describe ODIE, the
On-Demand Information Extraction system.
Given a user’s query, the system will pro-
duce tables of the salient information about
the topic in structured form. It produces the
tables in less than one minute without any
knowledge engineering by hand, i.e. pat-
tern creation or paraphrase knowledge
creation, which was the largest obstacle in
traditional IE. This demonstration is based
on the idea and technologies reported in
(Sekine 06). A substantial speed-up over
the previous system (which required about
15 minutes to analyze one year of newspa-
per) was achieved through a new approach
to handling pattern candidates; now less
than one minute is required when using 11
years of newspaper corpus. In addition,
functionality was added to facilitate inves-
tigation of the extracted information.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999956363636364">
The goal of information extraction (IE) is to extract
information about events in structured form from
unstructured texts. In traditional IE, a great deal of
knowledge for the systems must be coded by hand
in advance. For example, in the later MUC evalua-
tions, system developers spent one month for the
knowledge engineering to customize the system to
the given test topic. Improving portability is neces-
sary to make Information Extraction technology
useful for real users and, we believe, lead to a
breakthrough for the application of the technology.
</bodyText>
<footnote confidence="0.997701">
1) This work was conducted when the first author was a
junior research scientist at New York University.
</footnote>
<page confidence="0.993857">
17
</page>
<author confidence="0.70775">
Akira Oda 1)
</author>
<affiliation confidence="0.978076">
Toyohashi University of Technology
</affiliation>
<address confidence="0.5137975">
1-1 Hibarigaoka, Tenpaku-cho,
Toyohashi, Aichi 441-3580 Japan
</address>
<email confidence="0.975487">
oda@ss.ics.tut.ac.jp
</email>
<bodyText confidence="0.999904846153846">
Sekine (Sekine 06) proposed ‘On-demand in-
formation extraction (ODIE)’: a system which
automatically identifies the most salient structures
and extracts the information on the topic the user
demands. This new IE paradigm becomes feasible
due to recent developments in machine learning for
NLP, in particular unsupervised learning methods,
and is created on top of a range of basic language
analysis tools, including POS taggers, dependency
analyzers, and extended Named Entity taggers.
This paper describes the demonstration system of
the new IE paradigm, which incorporates some
new ideas to make the system practical.
</bodyText>
<sectionHeader confidence="0.940213" genericHeader="method">
2 Algorithm Overview
</sectionHeader>
<bodyText confidence="0.999967636363636">
We will present an overview of the algorithm in
this section. The details can be found in (Sekine
06).
The basic functionality of the system is the fol-
lowing. The user types a query / topic description
in keywords (for example, “merge, acquire, pur-
chase”). Then tables will be created automatically
while the user is waiting, rather than in a month of
human labor. These tables are expected to show
information about the salient relations for the topic.
There are six major components in the system.
</bodyText>
<listItem confidence="0.919031714285714">
1) IR system: Based on the query given by the
user, it retrieves relevant documents from the
document database. We used a simple TF/IDF
IR system we developed.
2) Pattern discovery: The texts are analyzed using
a POS tagger, a dependency analyzer and an
Extended Named Entity (ENE) tagger, which
</listItem>
<bodyText confidence="0.952623655172414">
will be explained in (5). Then sub-trees of de-
pendency trees which are relatively frequent in
the retrieved documents compared to the entire
corpus are identified. The sub-trees to be used
must satisfy some restrictions, including having
Proceedings of the ACL 2007 Demo and Poster Sessions, pages 17–20,
Prague, June 2007. c�2007 Association for Computational Linguistics
between 2 and 6 nodes, having a predicate or
nominalization as the head of the sub-tree, and
having at least one NE. We introduced upper
and lower frequency bounds for the sub-trees to
be used, as we found the medium frequency
sub-trees to be the most useful and least noisy.
We compute a score for each pattern based on
its frequency in the retrieved documents and in
the entire collection. The top scoring sub-trees
will be called patterns, which are expected to
indicate salient relationships of the topic and
which will be used in the later components. We
pre-compute such information as much as pos-
sible in order to enable usably prompt response
to queries.
3) Paraphrase discovery: In order to find semantic
relationships between patterns, i.e. to find pat-
terns which should be used to build the same
table, we use lexical knowledge such as Word-
Net and paraphrase discovery techniques. The
paraphrase discovery was conducted off-line
and created a paraphrase knowledge base.
</bodyText>
<listItem confidence="0.983581409090909">
4) Table construction: In this component, the pat-
terns created in (2) are linked based on the
paraphrase knowledge base created by (3), pro-
ducing sets of patterns which are semantically
equivalent. Once the sets of patterns are created,
these patterns are applied to the documents re-
trieved by the IR system (1). The matched pat-
terns pull out the entity instances from the sen-
tences and these entities are aligned to build the
final tables.
5) Extended NE tagger: Most of the participants in
events are likely to be Named Entities. How-
ever, the traditional NE categories are not suffi-
cient to cover most participants of various
events. For example, the standard MUC’s 7 NE
categories (i.e. person, location, organization,
percent, money, time and date) miss product
names (e.g. Windows XP, Boeing 747), event
names (Olympics, World War II), numerical
expressions other than monetary expressions,
etc. We used the Extended NE with 140 catego-
ries and a tagger developed for these categories.
</listItem>
<sectionHeader confidence="0.990189" genericHeader="method">
3 Speed-enhancing technology
</sectionHeader>
<bodyText confidence="0.999538853658536">
The largest computational load in this system is the
extraction and scoring of the topic-relevant sub-
trees. In the previous system, 1,000 top-scoring
sub-trees are extracted from all possible (on the
order of hundreds of thousands) sub-trees in the
top 200 relevant articles. This computation took
about 14 minutes out of the total 15 minutes of the
entire process. The difficulty is that the set of top
articles is not predictable, as the input is arbitrary
and hence the list of sub-trees is not predictable,
too. Although a state-of-the-art tree mining algo-
rithm (Abe et al. 02) was used, the computation is
still impracticable for a real system.
The solution we propose in this paper is to pre-
compute all possibly useful sub-trees in order to
reduce runtime. We enumerate all possible sub-
trees in the entire corpus and store them in a data-
base with frequency and location information. To
reduce the size of the database, we filter the pat-
terns, keeping only those satisfying the constraints
on frequency and existence of predicate and named
entities. However, it is still a big challenge, be-
cause in this system, we use 11 years of newspaper
(AQUAINT corpus, with duplicate articles re-
moved) instead of the one year of newspaper (New
York Times 95) used in the previous system. With
this idea, the response time of the demonstration
system is reduced significantly.
The statistics of the corpus and sub-trees are as
follows. The entire corpus includes 1,031,124 arti-
cles and 24,953,026 sentences. The frequency
thresholds for sub-trees to be used is set to more
than 10 and less than 10,000; i.e. sub-trees of those
frequencies in the corpus are expected to contain
most of the salient relationships with minimum
noise. The sub-trees with frequency less than 11
account for a very large portion of the data; 97.5%
of types and 66.3% of instances, as shown in Table
1. The sub-trees of frequency of 10,001 or more
are relatively small; only 76 kinds and only 2.5%
of the instances.
</bodyText>
<table confidence="0.970549833333333">
Frequency 10,001 or 10,000-11 10 or less
more
# of type 76 975,269 38,158,887
~0.0% 2.5% 97.5%
# of instance 2,313,347 29,257,437 62,097,271
2.5% 31.2% 66.3%
</table>
<tableCaption confidence="0.999698">
Table 1. Frequency of sub-trees
</tableCaption>
<bodyText confidence="0.7838975">
We assign ID numbers to all 1 million sub-trees
and 25 million sentences and those are mutually
linked in a database. Also, 60 million NE occur-
rences in the sub-trees are identified and linked to
</bodyText>
<page confidence="0.998181">
18
</page>
<bodyText confidence="0.999748">
the sub-tree and sentence IDs. In the process, the
sentences found by the IR component are identi-
fied. Then the sub-trees linked to those sentences
are gathered and the scores are calculated. Those
processes can be done by manipulation of the data-
base in a very short time. The top sub-trees are
used to create the output tables using NE occur-
rence IDs linked to the sub-trees and sentences.
</bodyText>
<sectionHeader confidence="0.989204" genericHeader="method">
4 A Demonstration
</sectionHeader>
<bodyText confidence="0.9998386875">
In this section, a simple demonstration scenario is
presented with an example. Figure 1 shows the
initial page. The user types in any keywords in the
query box. This can be anything, but as a tradi-
tional IR system is used for the search, the key-
words have to include expressions which are nor-
mally used in relevant documents. Examples of
such keywords are “merge, acquisition, purchase”,
“meet, meeting, summit” and “elect, election”,
which were derived from ACE event types.
Then, normally within one minute, the system
produces tables, such as those shown in Figure 2.
All extracted tables are listed. Each table contains
sentence ID, document ID and information ex-
tracted from the sentence. Some cells are empty if
the information can’t be extracted.
</bodyText>
<figureCaption confidence="0.996302">
Figure 1. Screenshot of the initial page
</figureCaption>
<sectionHeader confidence="0.994675" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999951090909091">
The evaluation was conducted using scenarios
based on 20 of the ACE event types. The accuracy
of the extracted information was evaluated by
judges for 100 rows selected at random. Of these
rows, 66 were judged to be on target and correct.
Another 10 were judged to be correct and related
to the topic, but did not include the essential in-
formation of the topic. The remaining 24 included
NE errors and totally irrelevant information (in
some cases due to word sense ambiguity; e.g.
“fine” weather vs.“fine” as a financial penalty).
</bodyText>
<figureCaption confidence="0.997413">
Figure 2. Screenshot of produced tables
</figureCaption>
<page confidence="0.997919">
19
</page>
<sectionHeader confidence="0.986703" genericHeader="method">
6 Other Functionality
</sectionHeader>
<bodyText confidence="0.9998041">
Functionality is provided to facilitate the user’s
access to the extracted information. Figure 3 shows
a screenshot of the document from which the in-
formation was extracted. Also the patterns used to
create each table can be found by clicking the tab
“patterns” (shown in Figure 4). This could help the
user to understand the nature of the table. The in-
formation includes the frequency of the pattern in
the retrieved documents and in the entire corpus,
and the pattern’s score.
</bodyText>
<figureCaption confidence="0.939742">
Figure 4. Screenshot of pattern information
</figureCaption>
<sectionHeader confidence="0.999329" genericHeader="discussions">
7 Future Work
</sectionHeader>
<bodyText confidence="0.999996592592593">
We demonstrated the On-Demand Information Ex-
traction system, which provides usable response
time for a large corpus. We still have several im-
provements to be made in the future. One is to in-
clude more advanced and accurate natural lan-
guage technologies to improve the accuracy and
coverage. For example, we did not use a corefer-
ence analyzer, and hence information which was
expressed using pronouns or other anaphoric ex-
pressions can not be extracted. Also, more seman-
tic knowledge including synonym, paraphrase or
inference knowledge should be included. The out-
put table has to be more clearly organized. In par-
ticular, we can’t display role information as col-
umn headings. The keyword input requirement is
very inconvenient. For good performance, the cur-
rent system requires several keywords occurring in
relevant documents; this is an obvious limitation.
On the other hand, there are systems which don’t
need any user input to create the structured infor-
mation (Banko et al. 07) (Shinyama and Sekine 06).
The latter system tries to identify all possible struc-
tural relations from a large set of unstructured
documents. However, the user’s information needs
are not predictable and the question of whether we
can create structured information for all possible
needs is still a big challenge.
</bodyText>
<sectionHeader confidence="0.997347" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.772155833333333">
This research was supported in part by the Defense Ad-
vanced Research Projects Agency as part of the
Translingual Information Detection, Extraction and
Summarization (TIDES) program, under Grant N66001-
001-1-8917 from the Space and Naval Warfare Systems
Center, San Diego, and by the National Science Founda-
tion under Grant IIS-00325657. This paper does not
necessarily reflect the position of the U.S. Government.
We would like to thank our colleagues at New York
University, who provided useful suggestions and dis-
cussions, including, Prof. Ralph Grishman and Mr. Yu-
suke Shinyama.
</bodyText>
<sectionHeader confidence="0.997187" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998291416666667">
Kenji Abe, Shinji Kawasone, Tatsuya Asai, Hiroki Ari-
mura and Setsuo Arikawa. 2002. “Optimized Sub-
structure Discovery for Semi-structured Data”.
PKDD-02.
Michele Banko, Michael J Cafarella, Stephen Soderland,
Matt Broadhead and Oren Etzioni. 2007. “Open In-
formation Extraction from Web”. IJCAI-07.
Satoshi Sekine. 2006. “On-Demand Information Extrac-
tion”. COLING-ACL-06.
Yusuke Shinyama and Satoshi Sekine, 2006. “Preemp-
tive Information Extraction using Unrestricted Rela-
tion Discovery”. HLT-NAACL-2006.
</reference>
<figureCaption confidence="0.998307">
Figure 3. Screenshot of document view
</figureCaption>
<page confidence="0.962808">
20
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.929625">
<title confidence="0.999903">System Demonstration of On-Demand Information Extraction</title>
<author confidence="0.974821">Satoshi Sekine</author>
<affiliation confidence="0.99892">New York University</affiliation>
<address confidence="0.993667">Broadway, floor New York, NY 10003 USA</address>
<email confidence="0.999828">sekine@cs.nyu.edu</email>
<abstract confidence="0.998345952380952">In this paper, we will describe ODIE, the On-Demand Information Extraction system. Given a user’s query, the system will produce tables of the salient information about the topic in structured form. It produces the tables in less than one minute without any knowledge engineering by hand, i.e. pattern creation or paraphrase knowledge creation, which was the largest obstacle in traditional IE. This demonstration is based on the idea and technologies reported in (Sekine 06). A substantial speed-up over the previous system (which required about 15 minutes to analyze one year of newspaper) was achieved through a new approach to handling pattern candidates; now less than one minute is required when using 11 years of newspaper corpus. In addition, functionality was added to facilitate investigation of the extracted information.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Kenji Abe</author>
</authors>
<title>Shinji Kawasone, Tatsuya Asai, Hiroki Arimura and Setsuo Arikawa.</title>
<date>2002</date>
<note>Optimized Substructure Discovery for Semi-structured Data”. PKDD-02.</note>
<marker>Abe, 2002</marker>
<rawString>Kenji Abe, Shinji Kawasone, Tatsuya Asai, Hiroki Arimura and Setsuo Arikawa. 2002. “Optimized Substructure Discovery for Semi-structured Data”. PKDD-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Banko</author>
<author>Michael J Cafarella</author>
<author>Stephen Soderland</author>
<author>Matt Broadhead</author>
<author>Oren Etzioni</author>
</authors>
<date>2007</date>
<booktitle>Open Information Extraction from Web”. IJCAI-07.</booktitle>
<marker>Banko, Cafarella, Soderland, Broadhead, Etzioni, 2007</marker>
<rawString>Michele Banko, Michael J Cafarella, Stephen Soderland, Matt Broadhead and Oren Etzioni. 2007. “Open Information Extraction from Web”. IJCAI-07.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoshi Sekine</author>
</authors>
<title>On-Demand Information Extraction”.</title>
<date>2006</date>
<tech>COLING-ACL-06.</tech>
<marker>Sekine, 2006</marker>
<rawString>Satoshi Sekine. 2006. “On-Demand Information Extraction”. COLING-ACL-06.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Shinyama</author>
<author>Satoshi Sekine</author>
</authors>
<title>Preemptive Information Extraction using Unrestricted Relation Discovery”.</title>
<date>2006</date>
<pages>2006</pages>
<marker>Shinyama, Sekine, 2006</marker>
<rawString>Yusuke Shinyama and Satoshi Sekine, 2006. “Preemptive Information Extraction using Unrestricted Relation Discovery”. HLT-NAACL-2006.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>