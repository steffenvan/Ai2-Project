<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000185">
<title confidence="0.999354">
Towards a Framework for
Abstractive Summarization of Multimodal Documents
</title>
<author confidence="0.98313">
Charles F. Greenbacker
</author>
<affiliation confidence="0.994888">
Dept. of Computer &amp; Information Sciences
University of Delaware
</affiliation>
<address confidence="0.825286">
Newark, Delaware, USA
</address>
<email confidence="0.999291">
charlieg@cis.udel.edu
</email>
<sectionHeader confidence="0.995648" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998405">
We propose a framework for generating an ab-
stractive summary from a semantic model of a
multimodal document. We discuss the type of
model required, the means by which it can be
constructed, how the content of the model is
rated and selected, and the method of realizing
novel sentences for the summary. To this end,
we introduce a metric called information den-
sity used for gauging the importance of con-
tent obtained from text and graphical sources.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.990801268292683">
The automatic summarization of text is a promi-
nent task in the field of natural language processing
(NLP). While significant achievements have been
made using statistical analysis and sentence extrac-
tion, “true abstractive summarization remains a re-
searcher’s dream” (Radev et al., 2002). Although
existing systems produce high-quality summaries of
relatively simple articles, there are limitations as to
the types of documents these systems can handle.
One such limitation is the summarization of mul-
timodal documents: no existing system is able to in-
corporate the non-text portions of a document (e.g.,
information graphics, images) into the overall sum-
mary. Carberry et al. (2006) showed that the con-
tent of information graphics is often not repeated
in the article’s text, meaning important information
may be overlooked if the graphical content is not in-
cluded in the summary. Systems that perform statis-
tical analysis of text and extract sentences from the
original article to assemble a summary cannot access
the information contained in non-text components,
75
let alone seamlessly combine that information with
the extracted text. The problem is that information
from the text and graphical components can only be
integrated at the conceptual level, necessitating a se-
mantic understanding of the underlying concepts.
Our proposed framework enables the genera-
tion of abstractive summaries from unified semantic
models, regardless of the original format of the in-
formation sources. We contend that this framework
is more akin to the human process of conceptual in-
tegration and regeneration in writing an abstract, as
compared to the traditional NLP techniques of rat-
ing and extracting sentences to form a summary.
Furthermore, this approach enables us to generate
summary sentences about the information collected
from graphical formats, for which there are no sen-
tences available for extraction, and helps avoid the
issues of coherence and ambiguity that tend to affect
extraction-based summaries (Nenkova, 2006).
</bodyText>
<sectionHeader confidence="0.999836" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.997391692307692">
Summarization is generally seen as a two-phase pro-
cess: identifying the important elements of the doc-
ument, and then using those elements to construct
a summary. Most work in this area has focused on
extractive summarization, assembling the summary
from sentences representing the information in a
document (Kupiec et al., 1995). Statistical methods
are often employed to find key words and phrases
(Witbrock and Mittal, 1999). Discourse structure
(Marcu, 1997) also helps indicate the most impor-
tant sentences. Various machine learning techniques
have been applied (Aone et al., 1999; Lin, 1999), as
well as approaches combining surface, content, rel-
</bodyText>
<subsectionHeader confidence="0.377007">
Proceedings of the ACL-HLT 2011 Student Session, pages 75–80,
</subsectionHeader>
<bodyText confidence="0.990467873015873">
Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics
evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these
However, a few efforts have been directed to- resources automatically.
wards abstractive summaries, including the modifi- Although our framework is general enough to
cation (i.e., editing and rewriting) of extracted sen- cover any image type, as well as other modalities
tences (Jing and McKeown, 1999) and the genera- (e.g., audio, video), since image understanding re-
tion of novel sentences based on a deeper under- search has not yet developed tools capable of ex-
standing of the concepts being described. Lexical tracting semantic content from every possible im-
chains, which capture relationships between related age, we must restrict our focus to a limited class of
terms in a document, have shown promise as an in- images for the prototype implementation. Informa-
termediate representation for producing summaries tion graphics, such as bar charts and line graphs, are
(Barzilay and Elhadad, 1997). Our work shares sim- commonly found in popular media (e.g., magazines,
ilarities with the knowledge-based text condensation newspapers) accompanying article text. To integrate
model of Reimer and Hahn (1988), as well as with this graphical content, we use the SIGHT system
Rau et al. (1989), who developed an information ex- (Demir et al., 2010b) which identifies the intended
traction approach for conceptual information sum- message of a bar chart or line graph along with other
marization. While we also build a conceptual model, salient propositions conveyed by the graphic. Ex-
we believe our method of construction will produce tending the prototype to incorporate other modalities
a richer representation. Moreover, Reimer and Hahn would not entail a significant change to the frame-
did not actually produce a natural language sum- work. However, it would require adding a module
mary, but rather a condensed text graph. capable of mapping the particular modality to its un-
Efforts towards the summarization of multimodal derlying message-level semantic content.
documents have included naive approaches relying The next sections provide detail regarding the
on image captions and direct references to the im- steps of our method, which will be illustrated on
age in the text (Bhatia et al., 2009), while content- a short article from the May 29, 2006 edition of
based image analysis and NLP techniques are being Businessweek magazine entitled, “Will Medtronic’s
combined for multimodal document indexing and Pulse Quicken?”2 This particular article was chosen
retrieval in the medical domain (N´ev´eol et al., 2009). due to good coverage in the existing Sparser gram-
mar for the business news domain, and because it ap-
pears in the corpus of multimodal documents made
available by the SIGHT project.
3.1 Semantic Modeling
Figure 1 shows a high-level (low-detail) overview
of the type of semantic model we can build using
Sparser and SIGHT. This particular example mod-
els the article text (including title) and line graph
from the Medtronic article. Each box represents
an individual concept recognized in the document.
Lines connecting boxes correspond to relationships
between concepts. In the interest of space, the in-
dividual attributes of the model entries have been
omitted from this diagram, but are available in Fig-
ure 2, which zooms into a fragment of the model
showing the concepts that are eventually rated most
salient (Section 3.2) and selected for inclusion in
3 Method
Our method consists of the following steps: building
the semantic model, rating the informational con-
tent, and generating a summary. We construct the
semantic model in a knowledge representation based
on typed, structured objects organized under a foun-
dational ontology (McDonald, 2000). To analyze the
text, we use Sparser,1 a linguistically-sound, phrase
structure-based chart parser with an extensive and
extendible semantic grammar (McDonald, 1992).
For the purposes of this proposal, we assume a rela-
tively complete semantic grammar exists for the do-
main of documents to be summarized. In the proto-
type implementation (currently in progress), we are
manually extending an existing grammar on an as-
needed basis, with plans for large-scale learning of
new rules and ontology definitions as future work.
Projects like the Never-Ending Language Learner
</bodyText>
<figure confidence="0.986203396825397">
2Available at http://www.businessweek.com/
magazine/content/06_22/b3986120.htm.
1https://github.com/charlieg/Sparser
76
Comparison3
AmountPerShare2
AmountPerShare1
RevenuePct1
RevenuePct1
Group3
AmountPerShare5
AmountPerShare7
AmountPerShare6
Prediction2
Market2
Company4
MarketFluctuations1
EmployedAt1
MakeAnnouncement1
Person2
StockPriceChange1
Prediction4
StockPriceChange2
Volatile1
StockOwnership1
HistoricLow1
Prediction3
ChangeTrend1
LineGraph1
StockPriceChange3
StockRating2
GainMarketShare1
EarningsGrowth1
EarningsForecast1
Company1
Protected1
EarningsReport1
Group2
WhQuestion1
Idiom1
Comparison2
Company3
BeatForecast1
SalesForecast1
EarningsForecast2
EarningsForecast3
AmountPerShare2
AmountPerShare3
AmountPerShare4
TargetStockPrice1
SalesForecast2
SalesForecast3
StockRating1
Market1
Prediction1
MissForecast1
CounterArgument1
GrowthSlowed1
EmployedAt1
Group1
Person1
Company2
Comparison1
</figure>
<figureCaption confidence="0.99999">
Figure 1: High-level overview of semantic model for Medtronic article.
</figureCaption>
<bodyText confidence="0.999787785714286">
the summary (Section 3.3). The top portion of each
box in Figure 2 indicates the name of the conceptual
category (with a number to distinguish between in-
stances), the middle portion shows various attributes
of the concept with their values, and the bottom por-
tion contains some of the original phrasings from
the text that were used to express these concepts
(formally stored as a synchronous TAG) (McDon-
ald and Greenbacker, 2010)). Attribute values in an-
gle brackets (&lt;&gt;) are references to other concepts,
hash symbols (#) refer to a concept or category that
has not been instantiated in the current model, and
each expression is preceded by a sentence tag (e.g.,
“P1S4” stands for “paragraph 1, sentence 4”).
</bodyText>
<figureCaption confidence="0.972383">
Figure 2: Detail of Figure 1 showing concepts rated most
important and selected for inclusion in the summary.
</figureCaption>
<bodyText confidence="0.999927833333333">
As illustrated in this example, concepts conveyed
by the graphics in the document can also be included
in the semantic model. The overall intended mes-
sage (ChangeTrend1) and additional propositions
(Volatile1, StockPriceChange3, etc.) that SIGHT
extracts from the line graph and deems important
are added to the model produced by Sparser by sim-
ply inserting new concepts, filling slots for existing
concepts, and creating new connections. This way,
information gathered from both text and graphical
sources can be integrated at the conceptual level re-
gardless of the format of the source.
</bodyText>
<subsectionHeader confidence="0.998445">
3.2 Rating Content
</subsectionHeader>
<bodyText confidence="0.9998531">
Once document analysis is complete and the seman-
tic model has been built, we must determine which
concepts conveyed by the document and captured
in the model are most salient. Intuitively, the con-
cepts containing the most information and having
the most connections to other important concepts in
the model are those we’d like to convey in the sum-
mary. We propose the use of an information den-
sity metric (ID) which rates a concept’s importance
based on a number of factors:3
</bodyText>
<listItem confidence="0.9970745">
• Completeness of attributes: the concept’s
filled-in slots (f) vs. its total slots (s) [“satura-
tion level”], and the importance of the concepts
(ci) filling these slots [a recursive value]:
</listItem>
<footnote confidence="0.605876285714286">
* log(s) * �fi�1 ID(ci)
3The first three factors are similar to the dominant slot
fillers, connectivity patterns, and frequency criteria described
by Reimer and Hahn (1988).
P1S1: &amp;quot;medical device
giant Medtronic&amp;quot;
P1S5: &amp;quot;Medtronic&amp;quot;
</footnote>
<figure confidence="0.838968045454545">
P1S4: &amp;quot;a 12-month
target of 62&amp;quot;
P1S4: &amp;quot;Investment firm
Harris Nesbitt&apos;s
Joanne Wuensch&amp;quot;
P1S7: &amp;quot;Wuensch&amp;quot;
Person1
FirstName: &amp;quot;Joanne&amp;quot;
LastName: &amp;quot;Wuensch&amp;quot;
Company1
TargetStockPrice1
Name: &amp;quot;Medtronic&amp;quot;
Stock: &amp;quot;MDT&amp;quot;
Industry: (#pacemakers,
#defibrillators,
#medical devices)
Person: &lt;Person 1&gt;
Company: &lt;Company 1&gt;
Price: $62.00
Horizon: #12_months
f
s
</figure>
<page confidence="0.879985">
77
</page>
<listItem confidence="0.819133857142857">
• Number of connections/relationships (n) with After computing the ID of each concept, we will
other concepts (cj), and the importance of these apply Demir’s (2010a) graph-based ranking algo-
connected concepts [a recursive value]: rithm to select items for the summary. This algo-
E 1 ID(cj) rithm is based on PageRank (Page et al., 1999), but
• Number of expressions (e) realizing the con- with several changes. Beyond centrality assessment
cept in the current document based on relationships between concepts, it also in-
• Prominence based on document and rhetorical corporates apriori importance nodes that enable us
</listItem>
<bodyText confidence="0.990754051282051">
structure (WD &amp; WR), and salience assessed to capture concept completeness, number of expres-
by the graph understanding system (WG) sions, and document and rhetorical structure. More
Saturation refers to the level of completeness with importantly from a generation perspective, Demir’s
which the knowledge base entry for a given concept algorithm iteratively selects concepts one at a time,
is “filled-out” by information obtained from the doc- re-ranking the remaining items by increasing the
ument. As information is collected about a concept, weight of related concepts and discounting redun-
the corresponding slots in its concept model entry dant ones. Thus, we favor concepts that ought to be
are assigned values. The more slots that are filled, conveyed together while avoiding redundancy.
the more we know about a given instance of a con- 3.3 Generating a Summary
cept. When all slots are filled, the model entry for After we determine which concepts are most im-
that concept is “complete,” at least as far as the on- portant as scored by ID, the next step is to de-
tological definition of the concept category is con- cide what to say about them and express these el-
cerned. As saturation level is sensitive to the amount ements as sentences. Following the generation tech-
of detail in the ontology definition, this factor must nique of McDonald and Greenbacker (2010), the ex-
be normalized by the number of attribute slots in its pressions observed by the parser and stored in the
definition, thus log(s) above. model are used as the “raw material” for express-
In Figure 3 we can see an example of relative ing the concepts and relationships. The two most
saturation level by comparing the attribute slots for important concepts as rated in the semantic model
Company2 with that of Company1 in Figure 2. built from the Medtronic article would be Company1
Since the “Stock” slot is filled for Medtronic and (“Medtronic”) and Person1 (“Joanne Wuensch,” a
remains empty for Harris Nesbitt, we say that the stock analyst). To generate a single summary sen-
concept for Company1 is more saturated (i.e., more tence for this document, we should try to find some
complete) than that of Company2. way of expressing these concepts together using the
available phrasings. Since there is no direct link
between these two concepts in the model (see Fig-
ure 1), none of the collected phrasings can express
both concepts at the same time. Instead, we need to
find a third concept that provides a semantic link be-
tween Company1 and Person1. If multiple options
are available, deciding which linking concept to use
becomes a microplanning problem, with the choice
depending on linguistic constraints and the relative
importance of the applicable linking concepts.
In this example, a reasonable selection would be
TargetStockPrice1 (see Figure 1). Combining orig-
inal phrasings from all three concepts (via substi-
tution and adjunction operations on the underlying
TAG trees), along with a “built-in” realization inher-
ited by the TargetStockPrice category (a subtype of
</bodyText>
<table confidence="0.675738">
Expectation – not shown in the figure), produces a
Company2
Name: &amp;quot;Harris Nesbitt&amp;quot;
Stock:
Industry: (#investments)
P1S4: &amp;quot;Investment firm
Harris Nesbitt&amp;quot;
</table>
<figureCaption confidence="0.9251455">
Figure 3: Detail of Figure 1 showing example concept
with unfilled attribute slot.
</figureCaption>
<bodyText confidence="0.960890666666667">
Document and rhetorical structure (WD and WR)
take into account the location of a concept within
a document (e.g., mentioned in the title) and the
use of devices highlighting particular concepts (e.g.,
juxtaposition) in computing the overall ID score.
For the intended message and informational proposi-
tions conveyed by the graphics, the weights assigned
by SIGHT are incorporated into ID as WG.
78
construction resulting in this final surface form:
Wuensch expects a 12-month target of 62
for medical device giant Medtronic.
Thus, we generate novel sentences, albeit with some
“recycled” expressions, to form an abstractive sum-
mary of the original document.
Studies have shown that nearly 80% of human-
written summary sentences are produced by a cut-
and-paste technique of reusing original sentences
and editing them together in novel ways (Jing and
McKeown, 1999). By reusing selected short phrases
(“cutting”) coupled together with generalized con-
structions (“pasting”), we can generate abstracts
similar to human-written summaries.
The set of available expressions is augmented
with numerous built-in schemas for realizing com-
mon relationships such as “is-a” and “has-a,” as
well as realizations inherited from other concep-
tual categories in the hierarchy. If the knowledge
base persists between documents, storing the ob-
served expressions and making them available for
later use when realizing concepts in the same cat-
egory, the variety of utterances we can generate is
increased. With a sufficiently rich set of expres-
sions, the reliance on straightforward “recycling” is
reduced while the amount of paraphrasing and trans-
formation is increased, resulting in greater novelty
of production. By using ongoing parser observations
to support the generation process, the more the sys-
tem “reads,” the better it “writes.”
</bodyText>
<sectionHeader confidence="0.996727" genericHeader="background">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.99999409375">
As an intermediate evaluation, we will rate the con-
cepts stored in a model built only from text and use
this rating to select sentences containing these con-
cepts from the original document. These sentences
will be compared to another set chosen by traditional
extraction methods. Human judges will be asked
to determine which set of sentences best captures
the most important concepts in the document. This
“checkpoint” will allow us to assess how well our
system identifies the most salient concepts in a text.
The summaries ultimately generated as final out-
put by our prototype system will be evaluated
against summaries written by human authors, as
well as summaries created by extraction-based sys-
tems and a baseline of selecting the first few sen-
tences. For each comparison, participants will be
asked to indicate a preference for one summary
over another. We propose to use preference-strength
judgment experiments testing multiple dimensions
of preference (e.g., accuracy, clarity, completeness).
Compared to traditional rating scales, this alterna-
tive paradigm has been shown to result in better
evaluator self-consistency and high inter-evaluator
agreement (Belz and Kow, 2010). This allows a
larger proportion of observed variations to be ac-
counted for by the characteristics of systems under-
going evaluation, and can result in a greater number
of significant differences being discovered.
Automatic evaluation, though desirable, is likely
unfeasible. As human-written summaries have only
about 60% agreement (Radev et al., 2002), there is
no “gold standard” to compare our output against.
</bodyText>
<sectionHeader confidence="0.998899" genericHeader="discussions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999942">
The work proposed herein aims to advance the state-
of-the-art in automatic summarization by offering a
means of generating abstractive summaries from a
semantic model built from the original article. By
incorporating concepts obtained from non-text com-
ponents (e.g., information graphics) into the seman-
tic model, we can produce unified summaries of
multimodal documents, resulting in an abstract cov-
ering the entire document, rather than one that ig-
nores potentially important graphical content.
</bodyText>
<sectionHeader confidence="0.997639" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.9999124">
This work was funded in part by the National Insti-
tute on Disability and Rehabilitation Research (grant
#H133G080047). The author also wishes to thank
Kathleen McCoy, Sandra Carberry, and David Mc-
Donald for their collaborative support.
</bodyText>
<sectionHeader confidence="0.99897" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.964666875">
Chinatsu Aone, Mary E. Okurowski, James Gorlinsky,
and Bjornar Larsen. 1999. A Trainable Summarizer
with Knowledge Acquired from Robust NLP Tech-
niques. In Inderjeet Mani and Mark T. Maybury, edi-
tors, Advances in Automated Text Summarization. MIT
Press.
Regina Barzilay and Michael Elhadad. 1997. Using lex-
ical chains for text summarization. In In Proceedings
</reference>
<page confidence="0.991852">
79
</page>
<reference confidence="0.999534240740741">
of the ACL Workshop on Intelligent Scalable Text Sum-
marization, pages 10–17, Madrid, July. ACL.
Anja Belz and Eric Kow. 2010. Comparing rating
scales and preference judgements in language evalu-
ation. In Proceedings of the 6th International Natural
Language Generation Conference, INLG 2010, pages
7–16, Trim, Ireland, July. ACL.
Sumit Bhatia, Shibamouli Lahiri, and Prasenjit Mitra.
2009. Generating synopses for document-element
search. In Proceeding of the 18th ACM Conference
on Information and Knowledge Management, CIKM
’09, pages 2003–2006, Hong Kong, November. ACM.
Sandra Carberry, Stephanie Elzer, and Seniz Demir.
2006. Information graphics: an untapped resource for
digital libraries. In Proceedings of the 29th Annual
International ACM SIGIR Conference on Research
and Development in Information Retrieval, SIGIR ’06,
pages 581–588, Seattle, August. ACM.
Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr
Settles, Estevam R. Hruschka Jr., and Tom M.
Mitchell. 2010. Toward an architecture for never-
ending language learning. In Proceedings of the 24th
Conference on Artificial Intelligence (AAAI 2010),
pages 1306–1313, Atlanta, July. AAAI.
Seniz Demir, Sandra Carberry, and Kathleen F. Mc-
Coy. 2010a. A discourse-aware graph-based content-
selection framework. In Proceedings of the 6th In-
ternational Natural Language Generation Conference,
INLG 2010, pages 17–26, Trim, Ireland, July. ACL.
Seniz Demir, David Oliver, Edward Schwartz, Stephanie
Elzer, Sandra Carberry, and Kathleen F. McCoy.
2010b. Interactive SIGHT into information graphics.
In Proceedings of the 2010 International Cross Dis-
ciplinary Conference on Web Accessibility, W4A ’10,
pages 16:1–16:10, Raleigh, NC, April. ACM.
Hongyan Jing and Kathleen R. McKeown. 1999. The
decomposition of human-written summary sentences.
In Proceedings of the 22nd Annual International ACM
SIGIR Conference on Research and Development in
Information Retrieval, SIGIR ’99, pages 129–136,
Berkeley, August. ACM.
Julian Kupiec, Jan Pedersen, and Francine Chen. 1995.
A trainable document summarizer. In Proceedings
of the 18th Annual International ACM SIGIR Confer-
ence on Research and Development in Information Re-
trieval, SIGIR ’95, pages 68–73, Seattle, July. ACM.
Chin-Yew Lin. 1999. Training a selection function for
extraction. In Proceedings of the 8th International
Conference on Information and Knowledge Manage-
ment, CIKM ’99, pages 55–62, Kansas City, Novem-
ber. ACM.
Daniel C. Marcu. 1997. The Rhetorical Parsing, Summa-
rization, and Generation of Natural Language Texts.
Ph.D. thesis, University of Toronto, December.
David D. McDonald and Charles F. Greenbacker. 2010.
‘If you’ve heard it, you can say it’ - towards an ac-
count of expressibility. In Proceedings of the 6th In-
ternational Natural Language Generation Conference,
INLG 2010, pages 185–190, Trim, Ireland, July. ACL.
David D. McDonald. 1992. An efficient chart-based
algorithm for partial-parsing of unrestricted texts. In
Proceedings of the 3rd Conference on Applied Natural
Language Processing, pages 193–200, Trento, March.
ACL.
David D. McDonald. 2000. Issues in the repre-
sentation of real texts: the design of KRISP. In
Lucja M. Iwa´nska and Stuart C. Shapiro, editors, Nat-
ural Language Processing and Knowledge Represen-
tation, pages 77–110. MIT Press, Cambridge, MA.
Ani Nenkova. 2006. Understanding the process of multi-
document summarization: content selection, rewrite
and evaluation. Ph.D. thesis, Columbia University,
January.
Aur´elie N´ev´eol, Thomas M. Deserno, St´efan J. Darmoni,
Mark Oliver G¨uld, and Alan R. Aronson. 2009. Nat-
ural language processing versus content-based image
analysis for medical document retrieval. Journal of the
American Society for Information Science and Tech-
nology, 60(1):123–134.
Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry
Winograd. 1999. The pagerank citation ranking:
Bringing order to the web. Technical Report 1999-
66, Stanford InfoLab, November. Previous number:
SIDL-WP-1999-0120.
Dragomir R. Radev, Eduard Hovy, and Kathleen McKe-
own. 2002. Introduction to the special issue on sum-
marization. Computational Linguistics, 28(4):399–
408.
Lisa F. Rau, Paul S. Jacobs, and Uri Zernik. 1989. In-
formation extraction and text summarization using lin-
guistic knowledge acquisition. Information Process-
ing &amp; Management, 25(4):419 – 428.
Ulrich Reimer and Udo Hahn. 1988. Text condensation
as knowledge base abstraction. In Proceedings of the
4th Conference on Artificial Intelligence Applications,
CAIA ’88, pages 338–344, San Diego, March. IEEE.
Michael J. Witbrock and Vibhu O. Mittal. 1999. Ultra-
summarization: a statistical approach to generating
highly condensed non-extractive summaries. In Pro-
ceedings of the 22nd Annual International ACM SIGIR
Conference on Research and Development in Informa-
tion Retrieval, SIGIR ’99, pages 315–316, Berkeley,
August. ACM.
Kam-Fai Wong, Mingli Wu, and Wenjie Li. 2008.
Extractive summarization using supervised and semi-
supervised learning. In Proceedings of the 22nd Int’l
Conference on Computational Linguistics, COLING
’08, pages 985–992, Manchester, August. ACL.
</reference>
<page confidence="0.998248">
80
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.538819">
<title confidence="0.9993875">Towards a Framework for Abstractive Summarization of Multimodal Documents</title>
<author confidence="0.990491">F Charles</author>
<affiliation confidence="0.854733666666667">Dept. of Computer &amp; Information University of Newark, Delaware,</affiliation>
<email confidence="0.999888">charlieg@cis.udel.edu</email>
<abstract confidence="0.996503545454546">We propose a framework for generating an abstractive summary from a semantic model of a multimodal document. We discuss the type of model required, the means by which it can be constructed, how the content of the model is rated and selected, and the method of realizing novel sentences for the summary. To this end, introduce a metric called denfor gauging the importance of content obtained from text and graphical sources.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Chinatsu Aone</author>
<author>Mary E Okurowski</author>
<author>James Gorlinsky</author>
<author>Bjornar Larsen</author>
</authors>
<date>1999</date>
<booktitle>A Trainable Summarizer with Knowledge Acquired from Robust NLP Techniques. In Inderjeet Mani and</booktitle>
<editor>Mark T. Maybury, editors,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3300" citStr="Aone et al., 1999" startWordPosition="502" endWordPosition="505"> (Nenkova, 2006). 2 Related Work Summarization is generally seen as a two-phase process: identifying the important elements of the document, and then using those elements to construct a summary. Most work in this area has focused on extractive summarization, assembling the summary from sentences representing the information in a document (Kupiec et al., 1995). Statistical methods are often employed to find key words and phrases (Witbrock and Mittal, 1999). Discourse structure (Marcu, 1997) also helps indicate the most important sentences. Various machine learning techniques have been applied (Aone et al., 1999; Lin, 1999), as well as approaches combining surface, content, relProceedings of the ACL-HLT 2011 Student Session, pages 75–80, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these However, a few efforts have been directed to- resources automatically. wards abstractive summaries, including the modifi- Although our framework is general enough to cation (i.e., editing and rewriting) of extracted sen- cover any image type, as well as other modalities tences (Jing and</context>
</contexts>
<marker>Aone, Okurowski, Gorlinsky, Larsen, 1999</marker>
<rawString>Chinatsu Aone, Mary E. Okurowski, James Gorlinsky, and Bjornar Larsen. 1999. A Trainable Summarizer with Knowledge Acquired from Robust NLP Techniques. In Inderjeet Mani and Mark T. Maybury, editors, Advances in Automated Text Summarization. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Michael Elhadad</author>
</authors>
<title>Using lexical chains for text summarization. In</title>
<date>1997</date>
<booktitle>In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization,</booktitle>
<pages>10--17</pages>
<publisher>ACL.</publisher>
<location>Madrid,</location>
<contexts>
<context position="4514" citStr="Barzilay and Elhadad, 1997" startWordPosition="689" endWordPosition="692">ces (Jing and McKeown, 1999) and the genera- (e.g., audio, video), since image understanding retion of novel sentences based on a deeper under- search has not yet developed tools capable of exstanding of the concepts being described. Lexical tracting semantic content from every possible imchains, which capture relationships between related age, we must restrict our focus to a limited class of terms in a document, have shown promise as an in- images for the prototype implementation. Informatermediate representation for producing summaries tion graphics, such as bar charts and line graphs, are (Barzilay and Elhadad, 1997). Our work shares sim- commonly found in popular media (e.g., magazines, ilarities with the knowledge-based text condensation newspapers) accompanying article text. To integrate model of Reimer and Hahn (1988), as well as with this graphical content, we use the SIGHT system Rau et al. (1989), who developed an information ex- (Demir et al., 2010b) which identifies the intended traction approach for conceptual information sum- message of a bar chart or line graph along with other marization. While we also build a conceptual model, salient propositions conveyed by the graphic. Exwe believe our me</context>
</contexts>
<marker>Barzilay, Elhadad, 1997</marker>
<rawString>Regina Barzilay and Michael Elhadad. 1997. Using lexical chains for text summarization. In In Proceedings of the ACL Workshop on Intelligent Scalable Text Summarization, pages 10–17, Madrid, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anja Belz</author>
<author>Eric Kow</author>
</authors>
<title>Comparing rating scales and preference judgements in language evaluation.</title>
<date>2010</date>
<booktitle>In Proceedings of the 6th International Natural Language Generation Conference, INLG 2010,</booktitle>
<pages>7--16</pages>
<publisher>ACL.</publisher>
<location>Trim, Ireland,</location>
<contexts>
<context position="18428" citStr="Belz and Kow, 2010" startWordPosition="2794" endWordPosition="2797">ur prototype system will be evaluated against summaries written by human authors, as well as summaries created by extraction-based systems and a baseline of selecting the first few sentences. For each comparison, participants will be asked to indicate a preference for one summary over another. We propose to use preference-strength judgment experiments testing multiple dimensions of preference (e.g., accuracy, clarity, completeness). Compared to traditional rating scales, this alternative paradigm has been shown to result in better evaluator self-consistency and high inter-evaluator agreement (Belz and Kow, 2010). This allows a larger proportion of observed variations to be accounted for by the characteristics of systems undergoing evaluation, and can result in a greater number of significant differences being discovered. Automatic evaluation, though desirable, is likely unfeasible. As human-written summaries have only about 60% agreement (Radev et al., 2002), there is no “gold standard” to compare our output against. 5 Discussion The work proposed herein aims to advance the stateof-the-art in automatic summarization by offering a means of generating abstractive summaries from a semantic model built f</context>
</contexts>
<marker>Belz, Kow, 2010</marker>
<rawString>Anja Belz and Eric Kow. 2010. Comparing rating scales and preference judgements in language evaluation. In Proceedings of the 6th International Natural Language Generation Conference, INLG 2010, pages 7–16, Trim, Ireland, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sumit Bhatia</author>
<author>Shibamouli Lahiri</author>
<author>Prasenjit Mitra</author>
</authors>
<title>Generating synopses for document-element search.</title>
<date>2009</date>
<booktitle>In Proceeding of the 18th ACM Conference on Information and Knowledge Management, CIKM ’09,</booktitle>
<pages>2003--2006</pages>
<publisher>ACM.</publisher>
<location>Hong Kong,</location>
<contexts>
<context position="5816" citStr="Bhatia et al., 2009" startWordPosition="891" endWordPosition="894">ities a richer representation. Moreover, Reimer and Hahn would not entail a significant change to the framedid not actually produce a natural language sum- work. However, it would require adding a module mary, but rather a condensed text graph. capable of mapping the particular modality to its unEfforts towards the summarization of multimodal derlying message-level semantic content. documents have included naive approaches relying The next sections provide detail regarding the on image captions and direct references to the im- steps of our method, which will be illustrated on age in the text (Bhatia et al., 2009), while content- a short article from the May 29, 2006 edition of based image analysis and NLP techniques are being Businessweek magazine entitled, “Will Medtronic’s combined for multimodal document indexing and Pulse Quicken?”2 This particular article was chosen retrieval in the medical domain (N´ev´eol et al., 2009). due to good coverage in the existing Sparser grammar for the business news domain, and because it appears in the corpus of multimodal documents made available by the SIGHT project. 3.1 Semantic Modeling Figure 1 shows a high-level (low-detail) overview of the type of semantic mo</context>
</contexts>
<marker>Bhatia, Lahiri, Mitra, 2009</marker>
<rawString>Sumit Bhatia, Shibamouli Lahiri, and Prasenjit Mitra. 2009. Generating synopses for document-element search. In Proceeding of the 18th ACM Conference on Information and Knowledge Management, CIKM ’09, pages 2003–2006, Hong Kong, November. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Carberry</author>
<author>Stephanie Elzer</author>
<author>Seniz Demir</author>
</authors>
<title>Information graphics: an untapped resource for digital libraries.</title>
<date>2006</date>
<booktitle>In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’06,</booktitle>
<pages>581--588</pages>
<publisher>ACM.</publisher>
<location>Seattle,</location>
<contexts>
<context position="1362" citStr="Carberry et al. (2006)" startWordPosition="205" endWordPosition="208">e field of natural language processing (NLP). While significant achievements have been made using statistical analysis and sentence extraction, “true abstractive summarization remains a researcher’s dream” (Radev et al., 2002). Although existing systems produce high-quality summaries of relatively simple articles, there are limitations as to the types of documents these systems can handle. One such limitation is the summarization of multimodal documents: no existing system is able to incorporate the non-text portions of a document (e.g., information graphics, images) into the overall summary. Carberry et al. (2006) showed that the content of information graphics is often not repeated in the article’s text, meaning important information may be overlooked if the graphical content is not included in the summary. Systems that perform statistical analysis of text and extract sentences from the original article to assemble a summary cannot access the information contained in non-text components, 75 let alone seamlessly combine that information with the extracted text. The problem is that information from the text and graphical components can only be integrated at the conceptual level, necessitating a semantic</context>
</contexts>
<marker>Carberry, Elzer, Demir, 2006</marker>
<rawString>Sandra Carberry, Stephanie Elzer, and Seniz Demir. 2006. Information graphics: an untapped resource for digital libraries. In Proceedings of the 29th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’06, pages 581–588, Seattle, August. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Carlson</author>
<author>Justin Betteridge</author>
<author>Bryan Kisiel</author>
<author>Burr Settles</author>
<author>Estevam R Hruschka Jr</author>
<author>Tom M Mitchell</author>
</authors>
<title>Toward an architecture for neverending language learning.</title>
<date>2010</date>
<booktitle>In Proceedings of the 24th Conference on Artificial Intelligence (AAAI</booktitle>
<pages>1306--1313</pages>
<publisher>AAAI.</publisher>
<location>Atlanta,</location>
<contexts>
<context position="3582" citStr="Carlson et al., 2010" startWordPosition="544" endWordPosition="547">ary from sentences representing the information in a document (Kupiec et al., 1995). Statistical methods are often employed to find key words and phrases (Witbrock and Mittal, 1999). Discourse structure (Marcu, 1997) also helps indicate the most important sentences. Various machine learning techniques have been applied (Aone et al., 1999; Lin, 1999), as well as approaches combining surface, content, relProceedings of the ACL-HLT 2011 Student Session, pages 75–80, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these However, a few efforts have been directed to- resources automatically. wards abstractive summaries, including the modifi- Although our framework is general enough to cation (i.e., editing and rewriting) of extracted sen- cover any image type, as well as other modalities tences (Jing and McKeown, 1999) and the genera- (e.g., audio, video), since image understanding retion of novel sentences based on a deeper under- search has not yet developed tools capable of exstanding of the concepts being described. Lexical tracting semantic content from every possible imchain</context>
</contexts>
<marker>Carlson, Betteridge, Kisiel, Settles, Jr, Mitchell, 2010</marker>
<rawString>Andrew Carlson, Justin Betteridge, Bryan Kisiel, Burr Settles, Estevam R. Hruschka Jr., and Tom M. Mitchell. 2010. Toward an architecture for neverending language learning. In Proceedings of the 24th Conference on Artificial Intelligence (AAAI 2010), pages 1306–1313, Atlanta, July. AAAI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seniz Demir</author>
<author>Sandra Carberry</author>
<author>Kathleen F McCoy</author>
</authors>
<title>A discourse-aware graph-based contentselection framework.</title>
<date>2010</date>
<booktitle>In Proceedings of the 6th International Natural Language Generation Conference, INLG 2010,</booktitle>
<pages>17--26</pages>
<publisher>ACL.</publisher>
<location>Trim, Ireland,</location>
<contexts>
<context position="4860" citStr="Demir et al., 2010" startWordPosition="743" endWordPosition="746">restrict our focus to a limited class of terms in a document, have shown promise as an in- images for the prototype implementation. Informatermediate representation for producing summaries tion graphics, such as bar charts and line graphs, are (Barzilay and Elhadad, 1997). Our work shares sim- commonly found in popular media (e.g., magazines, ilarities with the knowledge-based text condensation newspapers) accompanying article text. To integrate model of Reimer and Hahn (1988), as well as with this graphical content, we use the SIGHT system Rau et al. (1989), who developed an information ex- (Demir et al., 2010b) which identifies the intended traction approach for conceptual information sum- message of a bar chart or line graph along with other marization. While we also build a conceptual model, salient propositions conveyed by the graphic. Exwe believe our method of construction will produce tending the prototype to incorporate other modalities a richer representation. Moreover, Reimer and Hahn would not entail a significant change to the framedid not actually produce a natural language sum- work. However, it would require adding a module mary, but rather a condensed text graph. capable of mapping </context>
</contexts>
<marker>Demir, Carberry, McCoy, 2010</marker>
<rawString>Seniz Demir, Sandra Carberry, and Kathleen F. McCoy. 2010a. A discourse-aware graph-based contentselection framework. In Proceedings of the 6th International Natural Language Generation Conference, INLG 2010, pages 17–26, Trim, Ireland, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seniz Demir</author>
<author>David Oliver</author>
<author>Edward Schwartz</author>
<author>Stephanie Elzer</author>
<author>Sandra Carberry</author>
<author>Kathleen F McCoy</author>
</authors>
<title>Interactive SIGHT into information graphics.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 International Cross Disciplinary Conference on Web Accessibility, W4A ’10,</booktitle>
<pages>16--1</pages>
<publisher>ACM.</publisher>
<location>Raleigh, NC,</location>
<contexts>
<context position="4860" citStr="Demir et al., 2010" startWordPosition="743" endWordPosition="746">restrict our focus to a limited class of terms in a document, have shown promise as an in- images for the prototype implementation. Informatermediate representation for producing summaries tion graphics, such as bar charts and line graphs, are (Barzilay and Elhadad, 1997). Our work shares sim- commonly found in popular media (e.g., magazines, ilarities with the knowledge-based text condensation newspapers) accompanying article text. To integrate model of Reimer and Hahn (1988), as well as with this graphical content, we use the SIGHT system Rau et al. (1989), who developed an information ex- (Demir et al., 2010b) which identifies the intended traction approach for conceptual information sum- message of a bar chart or line graph along with other marization. While we also build a conceptual model, salient propositions conveyed by the graphic. Exwe believe our method of construction will produce tending the prototype to incorporate other modalities a richer representation. Moreover, Reimer and Hahn would not entail a significant change to the framedid not actually produce a natural language sum- work. However, it would require adding a module mary, but rather a condensed text graph. capable of mapping </context>
</contexts>
<marker>Demir, Oliver, Schwartz, Elzer, Carberry, McCoy, 2010</marker>
<rawString>Seniz Demir, David Oliver, Edward Schwartz, Stephanie Elzer, Sandra Carberry, and Kathleen F. McCoy. 2010b. Interactive SIGHT into information graphics. In Proceedings of the 2010 International Cross Disciplinary Conference on Web Accessibility, W4A ’10, pages 16:1–16:10, Raleigh, NC, April. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongyan Jing</author>
<author>Kathleen R McKeown</author>
</authors>
<title>The decomposition of human-written summary sentences.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’99,</booktitle>
<pages>129--136</pages>
<publisher>ACM.</publisher>
<location>Berkeley,</location>
<contexts>
<context position="3915" citStr="Jing and McKeown, 1999" startWordPosition="595" endWordPosition="598">l., 1999; Lin, 1999), as well as approaches combining surface, content, relProceedings of the ACL-HLT 2011 Student Session, pages 75–80, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these However, a few efforts have been directed to- resources automatically. wards abstractive summaries, including the modifi- Although our framework is general enough to cation (i.e., editing and rewriting) of extracted sen- cover any image type, as well as other modalities tences (Jing and McKeown, 1999) and the genera- (e.g., audio, video), since image understanding retion of novel sentences based on a deeper under- search has not yet developed tools capable of exstanding of the concepts being described. Lexical tracting semantic content from every possible imchains, which capture relationships between related age, we must restrict our focus to a limited class of terms in a document, have shown promise as an in- images for the prototype implementation. Informatermediate representation for producing summaries tion graphics, such as bar charts and line graphs, are (Barzilay and Elhadad, 1997).</context>
<context position="16273" citStr="Jing and McKeown, 1999" startWordPosition="2467" endWordPosition="2470">l ID score. For the intended message and informational propositions conveyed by the graphics, the weights assigned by SIGHT are incorporated into ID as WG. 78 construction resulting in this final surface form: Wuensch expects a 12-month target of 62 for medical device giant Medtronic. Thus, we generate novel sentences, albeit with some “recycled” expressions, to form an abstractive summary of the original document. Studies have shown that nearly 80% of humanwritten summary sentences are produced by a cutand-paste technique of reusing original sentences and editing them together in novel ways (Jing and McKeown, 1999). By reusing selected short phrases (“cutting”) coupled together with generalized constructions (“pasting”), we can generate abstracts similar to human-written summaries. The set of available expressions is augmented with numerous built-in schemas for realizing common relationships such as “is-a” and “has-a,” as well as realizations inherited from other conceptual categories in the hierarchy. If the knowledge base persists between documents, storing the observed expressions and making them available for later use when realizing concepts in the same category, the variety of utterances we can ge</context>
</contexts>
<marker>Jing, McKeown, 1999</marker>
<rawString>Hongyan Jing and Kathleen R. McKeown. 1999. The decomposition of human-written summary sentences. In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’99, pages 129–136, Berkeley, August. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julian Kupiec</author>
<author>Jan Pedersen</author>
<author>Francine Chen</author>
</authors>
<title>A trainable document summarizer.</title>
<date>1995</date>
<booktitle>In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’95,</booktitle>
<pages>68--73</pages>
<publisher>ACM.</publisher>
<location>Seattle,</location>
<contexts>
<context position="3044" citStr="Kupiec et al., 1995" startWordPosition="464" endWordPosition="467">ch enables us to generate summary sentences about the information collected from graphical formats, for which there are no sentences available for extraction, and helps avoid the issues of coherence and ambiguity that tend to affect extraction-based summaries (Nenkova, 2006). 2 Related Work Summarization is generally seen as a two-phase process: identifying the important elements of the document, and then using those elements to construct a summary. Most work in this area has focused on extractive summarization, assembling the summary from sentences representing the information in a document (Kupiec et al., 1995). Statistical methods are often employed to find key words and phrases (Witbrock and Mittal, 1999). Discourse structure (Marcu, 1997) also helps indicate the most important sentences. Various machine learning techniques have been applied (Aone et al., 1999; Lin, 1999), as well as approaches combining surface, content, relProceedings of the ACL-HLT 2011 Student Session, pages 75–80, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these However, a few efforts have bee</context>
</contexts>
<marker>Kupiec, Pedersen, Chen, 1995</marker>
<rawString>Julian Kupiec, Jan Pedersen, and Francine Chen. 1995. A trainable document summarizer. In Proceedings of the 18th Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’95, pages 68–73, Seattle, July. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
</authors>
<title>Training a selection function for extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the 8th International Conference on Information and Knowledge Management, CIKM ’99,</booktitle>
<pages>55--62</pages>
<publisher>ACM.</publisher>
<location>Kansas City,</location>
<contexts>
<context position="3312" citStr="Lin, 1999" startWordPosition="506" endWordPosition="507"> Related Work Summarization is generally seen as a two-phase process: identifying the important elements of the document, and then using those elements to construct a summary. Most work in this area has focused on extractive summarization, assembling the summary from sentences representing the information in a document (Kupiec et al., 1995). Statistical methods are often employed to find key words and phrases (Witbrock and Mittal, 1999). Discourse structure (Marcu, 1997) also helps indicate the most important sentences. Various machine learning techniques have been applied (Aone et al., 1999; Lin, 1999), as well as approaches combining surface, content, relProceedings of the ACL-HLT 2011 Student Session, pages 75–80, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these However, a few efforts have been directed to- resources automatically. wards abstractive summaries, including the modifi- Although our framework is general enough to cation (i.e., editing and rewriting) of extracted sen- cover any image type, as well as other modalities tences (Jing and McKeown, 19</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Chin-Yew Lin. 1999. Training a selection function for extraction. In Proceedings of the 8th International Conference on Information and Knowledge Management, CIKM ’99, pages 55–62, Kansas City, November. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel C Marcu</author>
</authors>
<title>The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Toronto,</institution>
<contexts>
<context position="3177" citStr="Marcu, 1997" startWordPosition="485" endWordPosition="486">e for extraction, and helps avoid the issues of coherence and ambiguity that tend to affect extraction-based summaries (Nenkova, 2006). 2 Related Work Summarization is generally seen as a two-phase process: identifying the important elements of the document, and then using those elements to construct a summary. Most work in this area has focused on extractive summarization, assembling the summary from sentences representing the information in a document (Kupiec et al., 1995). Statistical methods are often employed to find key words and phrases (Witbrock and Mittal, 1999). Discourse structure (Marcu, 1997) also helps indicate the most important sentences. Various machine learning techniques have been applied (Aone et al., 1999; Lin, 1999), as well as approaches combining surface, content, relProceedings of the ACL-HLT 2011 Student Session, pages 75–80, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these However, a few efforts have been directed to- resources automatically. wards abstractive summaries, including the modifi- Although our framework is general enough t</context>
</contexts>
<marker>Marcu, 1997</marker>
<rawString>Daniel C. Marcu. 1997. The Rhetorical Parsing, Summarization, and Generation of Natural Language Texts. Ph.D. thesis, University of Toronto, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D McDonald</author>
<author>Charles F Greenbacker</author>
</authors>
<title>If you’ve heard it, you can say it’ - towards an account of expressibility.</title>
<date>2010</date>
<booktitle>In Proceedings of the 6th International Natural Language Generation Conference, INLG 2010,</booktitle>
<pages>185--190</pages>
<publisher>ACL.</publisher>
<location>Trim, Ireland,</location>
<contexts>
<context position="9261" citStr="McDonald and Greenbacker, 2010" startWordPosition="1354" endWordPosition="1358">st3 StockRating1 Market1 Prediction1 MissForecast1 CounterArgument1 GrowthSlowed1 EmployedAt1 Group1 Person1 Company2 Comparison1 Figure 1: High-level overview of semantic model for Medtronic article. the summary (Section 3.3). The top portion of each box in Figure 2 indicates the name of the conceptual category (with a number to distinguish between instances), the middle portion shows various attributes of the concept with their values, and the bottom portion contains some of the original phrasings from the text that were used to express these concepts (formally stored as a synchronous TAG) (McDonald and Greenbacker, 2010)). Attribute values in angle brackets (&lt;&gt;) are references to other concepts, hash symbols (#) refer to a concept or category that has not been instantiated in the current model, and each expression is preceded by a sentence tag (e.g., “P1S4” stands for “paragraph 1, sentence 4”). Figure 2: Detail of Figure 1 showing concepts rated most important and selected for inclusion in the summary. As illustrated in this example, concepts conveyed by the graphics in the document can also be included in the semantic model. The overall intended message (ChangeTrend1) and additional propositions (Volatile1,</context>
<context position="13494" citStr="McDonald and Greenbacker (2010)" startWordPosition="2025" endWordPosition="2028">e filled, conveyed together while avoiding redundancy. the more we know about a given instance of a con- 3.3 Generating a Summary cept. When all slots are filled, the model entry for After we determine which concepts are most imthat concept is “complete,” at least as far as the on- portant as scored by ID, the next step is to detological definition of the concept category is con- cide what to say about them and express these elcerned. As saturation level is sensitive to the amount ements as sentences. Following the generation techof detail in the ontology definition, this factor must nique of McDonald and Greenbacker (2010), the exbe normalized by the number of attribute slots in its pressions observed by the parser and stored in the definition, thus log(s) above. model are used as the “raw material” for expressIn Figure 3 we can see an example of relative ing the concepts and relationships. The two most saturation level by comparing the attribute slots for important concepts as rated in the semantic model Company2 with that of Company1 in Figure 2. built from the Medtronic article would be Company1 Since the “Stock” slot is filled for Medtronic and (“Medtronic”) and Person1 (“Joanne Wuensch,” a remains empty fo</context>
</contexts>
<marker>McDonald, Greenbacker, 2010</marker>
<rawString>David D. McDonald and Charles F. Greenbacker. 2010. ‘If you’ve heard it, you can say it’ - towards an account of expressibility. In Proceedings of the 6th International Natural Language Generation Conference, INLG 2010, pages 185–190, Trim, Ireland, July. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D McDonald</author>
</authors>
<title>An efficient chart-based algorithm for partial-parsing of unrestricted texts.</title>
<date>1992</date>
<booktitle>In Proceedings of the 3rd Conference on Applied Natural Language Processing,</booktitle>
<pages>193--200</pages>
<publisher>ACL.</publisher>
<location>Trento,</location>
<contexts>
<context position="7453" citStr="McDonald, 1992" startWordPosition="1146" endWordPosition="1147">igure 2, which zooms into a fragment of the model showing the concepts that are eventually rated most salient (Section 3.2) and selected for inclusion in 3 Method Our method consists of the following steps: building the semantic model, rating the informational content, and generating a summary. We construct the semantic model in a knowledge representation based on typed, structured objects organized under a foundational ontology (McDonald, 2000). To analyze the text, we use Sparser,1 a linguistically-sound, phrase structure-based chart parser with an extensive and extendible semantic grammar (McDonald, 1992). For the purposes of this proposal, we assume a relatively complete semantic grammar exists for the domain of documents to be summarized. In the prototype implementation (currently in progress), we are manually extending an existing grammar on an asneeded basis, with plans for large-scale learning of new rules and ontology definitions as future work. Projects like the Never-Ending Language Learner 2Available at http://www.businessweek.com/ magazine/content/06_22/b3986120.htm. 1https://github.com/charlieg/Sparser 76 Comparison3 AmountPerShare2 AmountPerShare1 RevenuePct1 RevenuePct1 Group3 Amo</context>
</contexts>
<marker>McDonald, 1992</marker>
<rawString>David D. McDonald. 1992. An efficient chart-based algorithm for partial-parsing of unrestricted texts. In Proceedings of the 3rd Conference on Applied Natural Language Processing, pages 193–200, Trento, March. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D McDonald</author>
</authors>
<title>Issues in the representation of real texts: the design of KRISP.</title>
<date>2000</date>
<booktitle>Natural Language Processing and Knowledge Representation,</booktitle>
<pages>77--110</pages>
<editor>In Lucja M. Iwa´nska and Stuart C. Shapiro, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="7287" citStr="McDonald, 2000" startWordPosition="1124" endWordPosition="1125">o relationships between concepts. In the interest of space, the individual attributes of the model entries have been omitted from this diagram, but are available in Figure 2, which zooms into a fragment of the model showing the concepts that are eventually rated most salient (Section 3.2) and selected for inclusion in 3 Method Our method consists of the following steps: building the semantic model, rating the informational content, and generating a summary. We construct the semantic model in a knowledge representation based on typed, structured objects organized under a foundational ontology (McDonald, 2000). To analyze the text, we use Sparser,1 a linguistically-sound, phrase structure-based chart parser with an extensive and extendible semantic grammar (McDonald, 1992). For the purposes of this proposal, we assume a relatively complete semantic grammar exists for the domain of documents to be summarized. In the prototype implementation (currently in progress), we are manually extending an existing grammar on an asneeded basis, with plans for large-scale learning of new rules and ontology definitions as future work. Projects like the Never-Ending Language Learner 2Available at http://www.busines</context>
</contexts>
<marker>McDonald, 2000</marker>
<rawString>David D. McDonald. 2000. Issues in the representation of real texts: the design of KRISP. In Lucja M. Iwa´nska and Stuart C. Shapiro, editors, Natural Language Processing and Knowledge Representation, pages 77–110. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ani Nenkova</author>
</authors>
<title>Understanding the process of multidocument summarization: content selection, rewrite and evaluation.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>Columbia University,</institution>
<contexts>
<context position="2699" citStr="Nenkova, 2006" startWordPosition="412" endWordPosition="413">ied semantic models, regardless of the original format of the information sources. We contend that this framework is more akin to the human process of conceptual integration and regeneration in writing an abstract, as compared to the traditional NLP techniques of rating and extracting sentences to form a summary. Furthermore, this approach enables us to generate summary sentences about the information collected from graphical formats, for which there are no sentences available for extraction, and helps avoid the issues of coherence and ambiguity that tend to affect extraction-based summaries (Nenkova, 2006). 2 Related Work Summarization is generally seen as a two-phase process: identifying the important elements of the document, and then using those elements to construct a summary. Most work in this area has focused on extractive summarization, assembling the summary from sentences representing the information in a document (Kupiec et al., 1995). Statistical methods are often employed to find key words and phrases (Witbrock and Mittal, 1999). Discourse structure (Marcu, 1997) also helps indicate the most important sentences. Various machine learning techniques have been applied (Aone et al., 199</context>
</contexts>
<marker>Nenkova, 2006</marker>
<rawString>Ani Nenkova. 2006. Understanding the process of multidocument summarization: content selection, rewrite and evaluation. Ph.D. thesis, Columbia University, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aur´elie N´ev´eol</author>
<author>Thomas M Deserno</author>
<author>St´efan J Darmoni</author>
<author>Mark Oliver G¨uld</author>
<author>Alan R Aronson</author>
</authors>
<title>Natural language processing versus content-based image analysis for medical document retrieval.</title>
<date>2009</date>
<journal>Journal of the American Society for Information Science and Technology,</journal>
<volume>60</volume>
<issue>1</issue>
<marker>N´ev´eol, Deserno, Darmoni, G¨uld, Aronson, 2009</marker>
<rawString>Aur´elie N´ev´eol, Thomas M. Deserno, St´efan J. Darmoni, Mark Oliver G¨uld, and Alan R. Aronson. 2009. Natural language processing versus content-based image analysis for medical document retrieval. Journal of the American Society for Information Science and Technology, 60(1):123–134.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lawrence Page</author>
<author>Sergey Brin</author>
<author>Rajeev Motwani</author>
<author>Terry Winograd</author>
</authors>
<title>The pagerank citation ranking: Bringing order to the web.</title>
<date>1999</date>
<tech>Technical Report 1999-66,</tech>
<pages>1999--0120</pages>
<publisher>Previous</publisher>
<institution>Stanford InfoLab,</institution>
<contexts>
<context position="11843" citStr="Page et al., 1999" startWordPosition="1759" endWordPosition="1762">tt&apos;s Joanne Wuensch&amp;quot; P1S7: &amp;quot;Wuensch&amp;quot; Person1 FirstName: &amp;quot;Joanne&amp;quot; LastName: &amp;quot;Wuensch&amp;quot; Company1 TargetStockPrice1 Name: &amp;quot;Medtronic&amp;quot; Stock: &amp;quot;MDT&amp;quot; Industry: (#pacemakers, #defibrillators, #medical devices) Person: &lt;Person 1&gt; Company: &lt;Company 1&gt; Price: $62.00 Horizon: #12_months f s 77 • Number of connections/relationships (n) with After computing the ID of each concept, we will other concepts (cj), and the importance of these apply Demir’s (2010a) graph-based ranking algoconnected concepts [a recursive value]: rithm to select items for the summary. This algoE 1 ID(cj) rithm is based on PageRank (Page et al., 1999), but • Number of expressions (e) realizing the con- with several changes. Beyond centrality assessment cept in the current document based on relationships between concepts, it also in• Prominence based on document and rhetorical corporates apriori importance nodes that enable us structure (WD &amp; WR), and salience assessed to capture concept completeness, number of expresby the graph understanding system (WG) sions, and document and rhetorical structure. More Saturation refers to the level of completeness with importantly from a generation perspective, Demir’s which the knowledge base entry for</context>
</contexts>
<marker>Page, Brin, Motwani, Winograd, 1999</marker>
<rawString>Lawrence Page, Sergey Brin, Rajeev Motwani, and Terry Winograd. 1999. The pagerank citation ranking: Bringing order to the web. Technical Report 1999-66, Stanford InfoLab, November. Previous number: SIDL-WP-1999-0120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dragomir R Radev</author>
<author>Eduard Hovy</author>
<author>Kathleen McKeown</author>
</authors>
<title>Introduction to the special issue on summarization.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>4</issue>
<pages>408</pages>
<contexts>
<context position="966" citStr="Radev et al., 2002" startWordPosition="145" endWordPosition="148">odel required, the means by which it can be constructed, how the content of the model is rated and selected, and the method of realizing novel sentences for the summary. To this end, we introduce a metric called information density used for gauging the importance of content obtained from text and graphical sources. 1 Introduction The automatic summarization of text is a prominent task in the field of natural language processing (NLP). While significant achievements have been made using statistical analysis and sentence extraction, “true abstractive summarization remains a researcher’s dream” (Radev et al., 2002). Although existing systems produce high-quality summaries of relatively simple articles, there are limitations as to the types of documents these systems can handle. One such limitation is the summarization of multimodal documents: no existing system is able to incorporate the non-text portions of a document (e.g., information graphics, images) into the overall summary. Carberry et al. (2006) showed that the content of information graphics is often not repeated in the article’s text, meaning important information may be overlooked if the graphical content is not included in the summary. Syste</context>
<context position="18781" citStr="Radev et al., 2002" startWordPosition="2846" endWordPosition="2849"> testing multiple dimensions of preference (e.g., accuracy, clarity, completeness). Compared to traditional rating scales, this alternative paradigm has been shown to result in better evaluator self-consistency and high inter-evaluator agreement (Belz and Kow, 2010). This allows a larger proportion of observed variations to be accounted for by the characteristics of systems undergoing evaluation, and can result in a greater number of significant differences being discovered. Automatic evaluation, though desirable, is likely unfeasible. As human-written summaries have only about 60% agreement (Radev et al., 2002), there is no “gold standard” to compare our output against. 5 Discussion The work proposed herein aims to advance the stateof-the-art in automatic summarization by offering a means of generating abstractive summaries from a semantic model built from the original article. By incorporating concepts obtained from non-text components (e.g., information graphics) into the semantic model, we can produce unified summaries of multimodal documents, resulting in an abstract covering the entire document, rather than one that ignores potentially important graphical content. Acknowledgments This work was </context>
</contexts>
<marker>Radev, Hovy, McKeown, 2002</marker>
<rawString>Dragomir R. Radev, Eduard Hovy, and Kathleen McKeown. 2002. Introduction to the special issue on summarization. Computational Linguistics, 28(4):399– 408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lisa F Rau</author>
<author>Paul S Jacobs</author>
<author>Uri Zernik</author>
</authors>
<title>Information extraction and text summarization using linguistic knowledge acquisition.</title>
<date>1989</date>
<journal>Information Processing &amp; Management,</journal>
<volume>25</volume>
<issue>4</issue>
<pages>428</pages>
<contexts>
<context position="4806" citStr="Rau et al. (1989)" startWordPosition="734" endWordPosition="737">h capture relationships between related age, we must restrict our focus to a limited class of terms in a document, have shown promise as an in- images for the prototype implementation. Informatermediate representation for producing summaries tion graphics, such as bar charts and line graphs, are (Barzilay and Elhadad, 1997). Our work shares sim- commonly found in popular media (e.g., magazines, ilarities with the knowledge-based text condensation newspapers) accompanying article text. To integrate model of Reimer and Hahn (1988), as well as with this graphical content, we use the SIGHT system Rau et al. (1989), who developed an information ex- (Demir et al., 2010b) which identifies the intended traction approach for conceptual information sum- message of a bar chart or line graph along with other marization. While we also build a conceptual model, salient propositions conveyed by the graphic. Exwe believe our method of construction will produce tending the prototype to incorporate other modalities a richer representation. Moreover, Reimer and Hahn would not entail a significant change to the framedid not actually produce a natural language sum- work. However, it would require adding a module mary, </context>
</contexts>
<marker>Rau, Jacobs, Zernik, 1989</marker>
<rawString>Lisa F. Rau, Paul S. Jacobs, and Uri Zernik. 1989. Information extraction and text summarization using linguistic knowledge acquisition. Information Processing &amp; Management, 25(4):419 – 428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulrich Reimer</author>
<author>Udo Hahn</author>
</authors>
<title>Text condensation as knowledge base abstraction.</title>
<date>1988</date>
<booktitle>In Proceedings of the 4th Conference on Artificial Intelligence Applications, CAIA ’88,</booktitle>
<pages>338--344</pages>
<publisher>IEEE.</publisher>
<location>San Diego, March.</location>
<contexts>
<context position="4723" citStr="Reimer and Hahn (1988)" startWordPosition="718" endWordPosition="721">ts being described. Lexical tracting semantic content from every possible imchains, which capture relationships between related age, we must restrict our focus to a limited class of terms in a document, have shown promise as an in- images for the prototype implementation. Informatermediate representation for producing summaries tion graphics, such as bar charts and line graphs, are (Barzilay and Elhadad, 1997). Our work shares sim- commonly found in popular media (e.g., magazines, ilarities with the knowledge-based text condensation newspapers) accompanying article text. To integrate model of Reimer and Hahn (1988), as well as with this graphical content, we use the SIGHT system Rau et al. (1989), who developed an information ex- (Demir et al., 2010b) which identifies the intended traction approach for conceptual information sum- message of a bar chart or line graph along with other marization. While we also build a conceptual model, salient propositions conveyed by the graphic. Exwe believe our method of construction will produce tending the prototype to incorporate other modalities a richer representation. Moreover, Reimer and Hahn would not entail a significant change to the framedid not actually pro</context>
<context position="11099" citStr="Reimer and Hahn (1988)" startWordPosition="1653" endWordPosition="1656">most information and having the most connections to other important concepts in the model are those we’d like to convey in the summary. We propose the use of an information density metric (ID) which rates a concept’s importance based on a number of factors:3 • Completeness of attributes: the concept’s filled-in slots (f) vs. its total slots (s) [“saturation level”], and the importance of the concepts (ci) filling these slots [a recursive value]: * log(s) * �fi�1 ID(ci) 3The first three factors are similar to the dominant slot fillers, connectivity patterns, and frequency criteria described by Reimer and Hahn (1988). P1S1: &amp;quot;medical device giant Medtronic&amp;quot; P1S5: &amp;quot;Medtronic&amp;quot; P1S4: &amp;quot;a 12-month target of 62&amp;quot; P1S4: &amp;quot;Investment firm Harris Nesbitt&apos;s Joanne Wuensch&amp;quot; P1S7: &amp;quot;Wuensch&amp;quot; Person1 FirstName: &amp;quot;Joanne&amp;quot; LastName: &amp;quot;Wuensch&amp;quot; Company1 TargetStockPrice1 Name: &amp;quot;Medtronic&amp;quot; Stock: &amp;quot;MDT&amp;quot; Industry: (#pacemakers, #defibrillators, #medical devices) Person: &lt;Person 1&gt; Company: &lt;Company 1&gt; Price: $62.00 Horizon: #12_months f s 77 • Number of connections/relationships (n) with After computing the ID of each concept, we will other concepts (cj), and the importance of these apply Demir’s (2010a) graph-based ranking algoc</context>
</contexts>
<marker>Reimer, Hahn, 1988</marker>
<rawString>Ulrich Reimer and Udo Hahn. 1988. Text condensation as knowledge base abstraction. In Proceedings of the 4th Conference on Artificial Intelligence Applications, CAIA ’88, pages 338–344, San Diego, March. IEEE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael J Witbrock</author>
<author>Vibhu O Mittal</author>
</authors>
<title>Ultrasummarization: a statistical approach to generating highly condensed non-extractive summaries.</title>
<date>1999</date>
<booktitle>In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’99,</booktitle>
<pages>315--316</pages>
<publisher>ACM.</publisher>
<location>Berkeley,</location>
<contexts>
<context position="3142" citStr="Witbrock and Mittal, 1999" startWordPosition="479" endWordPosition="482">ormats, for which there are no sentences available for extraction, and helps avoid the issues of coherence and ambiguity that tend to affect extraction-based summaries (Nenkova, 2006). 2 Related Work Summarization is generally seen as a two-phase process: identifying the important elements of the document, and then using those elements to construct a summary. Most work in this area has focused on extractive summarization, assembling the summary from sentences representing the information in a document (Kupiec et al., 1995). Statistical methods are often employed to find key words and phrases (Witbrock and Mittal, 1999). Discourse structure (Marcu, 1997) also helps indicate the most important sentences. Various machine learning techniques have been applied (Aone et al., 1999; Lin, 1999), as well as approaches combining surface, content, relProceedings of the ACL-HLT 2011 Student Session, pages 75–80, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these However, a few efforts have been directed to- resources automatically. wards abstractive summaries, including the modifi- Althoug</context>
</contexts>
<marker>Witbrock, Mittal, 1999</marker>
<rawString>Michael J. Witbrock and Vibhu O. Mittal. 1999. Ultrasummarization: a statistical approach to generating highly condensed non-extractive summaries. In Proceedings of the 22nd Annual International ACM SIGIR Conference on Research and Development in Information Retrieval, SIGIR ’99, pages 315–316, Berkeley, August. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kam-Fai Wong</author>
<author>Mingli Wu</author>
<author>Wenjie Li</author>
</authors>
<title>Extractive summarization using supervised and semisupervised learning.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd Int’l Conference on Computational Linguistics, COLING ’08,</booktitle>
<pages>985--992</pages>
<publisher>ACL.</publisher>
<location>Manchester,</location>
<contexts>
<context position="3558" citStr="Wong et al., 2008" startWordPosition="540" endWordPosition="543">, assembling the summary from sentences representing the information in a document (Kupiec et al., 1995). Statistical methods are often employed to find key words and phrases (Witbrock and Mittal, 1999). Discourse structure (Marcu, 1997) also helps indicate the most important sentences. Various machine learning techniques have been applied (Aone et al., 1999; Lin, 1999), as well as approaches combining surface, content, relProceedings of the ACL-HLT 2011 Student Session, pages 75–80, Portland, OR, USA 19-24 June 2011. c�2011 Association for Computational Linguistics evance and event features (Wong et al., 2008). (Carlson et al., 2010) may enable us to induce these However, a few efforts have been directed to- resources automatically. wards abstractive summaries, including the modifi- Although our framework is general enough to cation (i.e., editing and rewriting) of extracted sen- cover any image type, as well as other modalities tences (Jing and McKeown, 1999) and the genera- (e.g., audio, video), since image understanding retion of novel sentences based on a deeper under- search has not yet developed tools capable of exstanding of the concepts being described. Lexical tracting semantic content fro</context>
</contexts>
<marker>Wong, Wu, Li, 2008</marker>
<rawString>Kam-Fai Wong, Mingli Wu, and Wenjie Li. 2008. Extractive summarization using supervised and semisupervised learning. In Proceedings of the 22nd Int’l Conference on Computational Linguistics, COLING ’08, pages 985–992, Manchester, August. ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>