<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.72688">
American Journal of Computational Linguistics Micro
</note>
<title confidence="0.714221">
A GOAL-ORIENTED MODEL or HUMAN DIALOGUE
</title>
<author confidence="0.624514">
James A. Moore
James A. Levin
William C. Mann
</author>
<sectionHeader confidence="0.683792" genericHeader="method">
USC/Information Sciences Institute
4676 Admiralty Way
Marina del Rey, California 90291
</sectionHeader>
<bodyText confidence="0.812256">
The re arch reported herein was supported 4fy the Florsonn( I rvi Tr ainirIE Pcc.or
Programs of the Office of Naval Research, Contract N00014-75 (; 0710, uriricr Af+A
Order Number 2930 from the Cybernttics Tethnol gy Office of the Advanced Pr ty.e3r, h
&apos;Projects Agency.
A ,4 I 4,44 ,gI ( 1JL, if 4f )f. )7&apos;64 )
</bodyText>
<note confidence="0.769139">
A Model of Dialogue 2
</note>
<sectionHeader confidence="0.800345" genericHeader="method">
SUMMARY
</sectionHeader>
<bodyText confidence="0.999527454545455">
Within a view of language users as problem solvers, speakers are seen as creating
utterances in pursuit of their own goals. Dialogue &amp;quot;works&amp;quot; because this activity tends to
serve goals of both participants. Hence, for the model of dialogue comprehension
presented here, recognition of these goals of the speaker is central to the comprehension
of dialogue.
We have found that dialogues are composed of structured interactions represented
by collections of knowledge which describe the interrelated goals of the participants.
We call these knowledge structures &amp;quot;Dialogue-games&amp;quot; (DG). This paper describes DGs
in general, a particular one (the Helping-DG) in some detail, how DGs are used by our
Dialogue-game Model (DGM), and the benefits of this model.
A DG consists of three parts: the Parameters (the two roles filled by the
participants, and the topic), the Parameter Specifications (a set of predicates on the
Parameters), and the Components (a sequence of goals held by the participants in the
course of the dialogue).
For example, in the Helping-DG, the Parameters are HELPER, HELPEE (the roles)
and TASK (the topic). The Specifications are: 1) The HELPEE wants to perform the
TASK: 2) the HELPEE wants to be able to do it but 3) the HELPEE is not able to. 4) The
HELPER wants to enable the HELPEE to do the TASK and 5) the HELPER is able to
provide this help. The Components specify that 1) the HELPEE wants to establish a
context by describing a collection of unexceptional events (a partial performance of the
TASK): 2) he also wants to describe some sort of unoesirable surprise: then 3) the.
HELPER wants to erplain the violation of expectation so that the HELPEE can avoid it ahd
get on with the TASK.
The DGM makes use of DGs in five stages of processing: Nomination, Recognition,
Instantiation, Conduct and Termination.
The DGM models each participant&apos;s knowledge, goal and attention states. A
mechanism adds to the attention state, concepts &amp;quot;suggested&amp;quot; by those already in attention.
When a hearer sees himself or his partner as potentially filling a role in a DG (by fulfilling
one or more demands of the DG&apos;s Specifications) then that DG is brought into attention
(Nominated).
DGs can be nominated by weak evidence: Recognition is the step of verifying that
these DGs are plausibly consistent with the current state of the model. Those which are
not are eliminated from attention.
</bodyText>
<note confidence="0.587406">
A Model of Dialogue 3
</note>
<bodyText confidence="0.992819416666667">
OGs which survive the Recognition stago are Instantiated by asserting (as
assumptions) all the Specifications not yet represented as holding. For example, when a
person says &amp;quot;Do you have a match?&amp;quot;, Instantiation, by the hearer (of the Action-seek DG)
derives assertions that the speaker does not have a match and wants the hearer to give
him one,
The Conduct of the DO is modeled by tracking the pursuit and fulfillment of the
participants&apos; goals as represented in the Components.
When the DGM detects that one participant no longer regards a Specification as
holding, this creates an expectation of the Termination of this phase of the
dialogue--there is no longer a possibility that it wall serve both participants&apos; goals.
The appendix contains a detailed hand-simulation of the DGM assimilating a
segment of a dialogue.
</bodyText>
<note confidence="0.7085865">
A Model of Dialogue 4
CONTENTS
</note>
<listItem confidence="0.764965833333333">
1, Summary 2
2. Statement of the Problem 6
3. Past Research on Language Comprehension 8
4. The Shape of the Theory 10
5. The Dialogue-game Model 11
5.1 What&apos;s in a Game? 13
</listItem>
<subsubsectionHeader confidence="0.889031">
5.1.1 Parameters 13
5.1.2 Parameter Specifications 13
5.1.3 Components 14
5.1.4 ridding and Accepting 14
</subsubsectionHeader>
<subsectionHeader confidence="0.300093">
5.2 The Helping-game, an Example 15
5.3 Dialogue-games in the Comprehension. of Dialcdtie 17
</subsectionHeader>
<subsubsectionHeader confidence="0.5635055">
5.3.1 Processing Environment 18
5.3.2 Nomination 19
5.3.3 Recognition 20
5.3.4 Instantiation 21
</subsubsectionHeader>
<figure confidence="0.90211525">
A Model of Dialogue 5
5.3.5 Conduct 21
5.3.6 Termination 22
5.4 The Dialogue-game Processes 22
5.4.1 Long-term Memory (LTM) 23
5.4.2 Workspace (WS) 25
5.4..3 Parser 26
5.4.4 Proteus 26
5.4.5 Match 26
5.4.6 Deduce 28
5.4.7 Dialogue-game Manager 28
5.4.8 Pronoun Processes 29
</figure>
<listItem confidence="0.66116375">
6. Deficiencies in Current Man-machine Communication 31
7. Conclusions 33
8. References
Appendix -- Simulation of the Dialogue-game Model
</listItem>
<note confidence="0.483025">
A Model of Dialogue 6
</note>
<sectionHeader confidence="0.912058" genericHeader="method">
STATEMENT OF THE PROBLEM
</sectionHeader>
<bodyText confidence="0.9876195">
The broadest goal of our research has been to improve the sorry state of interactive
man-machine communication, including its appearance of comple)dty, rigidity, lack of
continuity and the difficulty it poses for many people to acquire useful levels of
competence. In our pursuit of this goal, we have adopted.the following two assumptions:
</bodyText>
<figureCaption confidence="0.69804275">
Assumption 1: When people communicate with machines, they do so by
using their already well-developed ability to communicate with other people.
Assumption 2: The effectiveness of this communication is diminished by any
adaptation required of the human.
</figureCaption>
<bodyText confidence="0.952762714285714">
A scientific understanding of how people c-ommunicate thus relevant to the design
of man-machine communication schemes, but such knowledge is seldom used in the design
process. Since human communication skills have not been characterized at a level of
detail appropriate for guiding design, interface designers have not been able to take into
account some major determinants of their success.
Thd operative goal of our research was therefore to create a mode/ of human
communication at an appropriate level of detail to benefit man-machine communication
design. Any form of communication must be based on knowledge shared by the
individuals engaged in that communication. However, the nature of this shared
knoWledge and how is it used in the communicative process have not been well
understood. We have developed a Working hypothesis which has deeply affected the
research:
Hypothesis: People know that certain kinds of goals may be pursued by
communication, and they know which kinds of communication acts correspond
to which goals. The use of this knowledge is essential to comprehending
dialogue.
In particular, a person generates an utterance to advance one or more of his own goals.
Thus, to assimilate a particular utterance, it is necessary to identify why the person said
it.
Working with this hypothesis, we have conducted three related investigations:
A Model of Dialogue. 7
</bodyText>
<listItem confidence="0.984512">
1. A study of naturally occurring language to discover regularities of usage
and to determine what these regularities mean to the users of the language.
2. The representation of these regularities as knowledge structures and
processes in a dialogue model.
</listItem>
<bodyText confidence="0.617744333333333">
3. The establishment of standards by which the model&apos;s performance can
be compared with that of humans on closely related tasks.
We have adopted two additional, tactical constraints on the task:
</bodyText>
<listItem confidence="0.9810982">
1. We have modeled only the receptive aspects of communication.
2. We.have examined only dialogue communication, interaction in real-time,
by exactly two people. These dialogues were conducted over a restricted
medium so that there was no visual or intonational communication not captured
in the tr,nscript.
</listItem>
<note confidence="0.611243">
A Model of Diillogue 8
PAST RESEARCH ON LANGUAGE COMPREHENSION
</note>
<bodyText confidence="0.9984076875">
Most of the research jnto language comprehension has focused on the
comprehension of single sentences or fragments of sentences. However some research
has indicated the importance of the context created by surrounding sentences on the
comprehension of an individual sentence. One specific model for the form of this
multi-sentential knowledge is the &amp;quot;story schema&amp;quot;, organized within a story grammar
(Rumelhart, 1975). This model has been supported by the results of story recalls
(Rumelhart, 1975; Thorndyke, 1977). Other similar kinds of theoretical constructs for
organizing multiple sentences of stories have been proposed called: &amp;quot;frames&amp;quot; (Minsky,
1975; Charniak, 1975), &amp;quot;scripts&amp;quot; (Schank &amp; Abelson, 1975), and &amp;quot;commonsense
algorithms&amp;quot; (Rieger, 1975).
To account for the conduct and comprehension of dialogues, multi-sentential
knowledge units have also been proposed by linguists and sociolinguists to explain
certain kinds of regularities observed in naturally occurring dialogues. These
regularities have been called &amp;quot;rules&amp;quot; by Labov &amp; Fanshel (1974) and &amp;quot;sequences&amp;quot; by
Sacks, Schegloff, &amp; Jefferson (1974).
Once these multi-sentential knowledge units are evoked, they serve as a basis for
comprehending the&apos; successive inputs. This is achieved by generating expectations and
by providing a framework for integrating the comprehension of an utterance with that of
its predecessors. Recently, we have proposed (Levin &amp; Moore, 1976; 1977, Mann,
Moore &amp; Levin, 1977) multi-sentential knowledge units that are specified primarily by
the speaker&apos;s and hearer&apos;s goals. These goal-oriented units, which we call
Dialogue-games[1], specify the kinds of language interactions in which people engage,
rather than the specific content of these interactions. People use language primarily to
communicate with other people to achieve their own goals. The Dialogue-game
multi-sentential structures were developed to represent this knowledge about language
and how it can be used to achieve goals.
[1J The term &amp;quot;Dialogue-71;3W was adopted by analogy from Wittgenstein&apos;s term
&amp;quot;Janguap,e game&amp;quot; (Wittgenstein, 198).. However, Dialogue-games represent knowledge
people ha&apos;ve dbout language as Used to pursue goals, rather than Wittgenstein&apos;s more
general. notion. Although other &amp;quot;games&amp;quot; are similar, the properties of .Dial.ogue-Tame
are only those described here. For example, they are not necessarily competitive,
con ciou ly pursued, or zero-sum.
</bodyText>
<subsectionHeader confidence="0.917234">
A Model of Dialogue 9
</subsectionHeader>
<bodyText confidence="0.997728909090909">
An important problem for researchers of language comprehension is posed by
sentences with which the speaker performs what philosophers of language have called
&amp;quot;indirect speech acts&amp;quot; (Searle, 1969). The direct comprehension of these sentences
fails to derive the main communicative effect. For example, declarative sentences can be
used to seek information (&amp;quot;I need to know your Social Security number.&amp;quot;); questions can be
used to convey information (&amp;quot;Did you know that John and Harriet got married?&amp;quot;) or to
request an action (&amp;quot;Could you pass the salt?&amp;quot;). These kinds of utterances, which have
been extensively analyzed by philosophers of language (Austin, 1962; Searle, 1969,
1975; Grice, 1975), are not handled satisfactorily by any of the current theories of the
direct comprehension of language. However, these indirect language usages are
widespread in naturally occurring language--even two-year-old children can
comprehend indirect requesis for action almost as well as direct requests (Shatz, 1975).
One theory proposed to account for these indirect uses of language is based on the
concept of &amp;quot;conversational postulates&amp;quot; (Grice, 1975; Gordon &amp; Lakoff, 1971). If the
direct comprehension of an utterance is implausible, then the indirect meaning is derived
using these postulates. Clark &amp; Lucy (1975) formalized and tested this model, and found
that people&apos;s response times tend to support a three-stage model (deriving the literal
meaning, check its &apos;plausibility and, if implausible, deriving the &amp;quot;intended&amp;quot; meaning&amp;quot; from
conversational rules).
In general, this approach to indirect speech acts is infetence-based, depending on
the application of conversational rules to infer the indirect meaning from the direct
meaning and the context. A different approach has been proposed by Labovii Fanst)el
(1974) and by Levin &amp; Moore (1976; 1977). Multi-sentential knowledge, organizing a
segment of language interaction, can form the basis for deriving the indirect effect of
utteronce within the segment. For example, a multi-sentential structure for an
information-seeking interaction can supply the appropriate context for interpreting the
subsequent utterances to seek and then supply information. The inference-based
approach requires one set of conversational rules for information requests, a different set
of rules for answers to these requests, and a way to tie these two rule sets together. The
Dialogue-game model postulates a single knowledge structure for this kind of interaction,
with cooperating processes for: (1) recognizing when this kind of interaction is proposed,
(2) using this knowledge to comprehend utterances within its scope, and (3) identifying
when the interaction is to be terminated.
</bodyText>
<note confidence="0.667071">
A Model of Dialogue 10
THE SHAPE OF THE THEORY
</note>
<bodyText confidence="0.997935514285714">
Our theory of human language use has been strongly influenced by work in human
problem solving (Newell &amp; Simon, 1972) in which the behavior of a human is modeled as
an information. processing system, having goals to pursue and selecting actions which
tend to achieve these goals. We view humans as engaging in linguistic behavior in order
to advance the state of certain of their goals. They decide to use language, they select
(or accept) the other participant for a dialogue, they choose the details of linguistic
expression — all with the expectation that some of their desired state specifications can
thereby be realized.
In this theory of language, a participant in a linguistic exchange views the other as
an independent information-processing system, with separate knowledge, goals, abilities
and access to the world. A speaker has a range of potential changes he can effect in his
listener, a corresponding collection of linguistic actions which may result in each such
change, and some notion of the consequences of performing each of these. The speaker
may view the hearer as a resource for information, a potential actor, or as an object to be
molded into some desired state.
A dialogue involves two speakers, who alternate as hearers. In choosing to initiate
or continue the exchange, a participant attempts to satisfy his own goals; in interpreting
an utterance of his partner, each participant attempts to find the way in which that
utterance serves the goals of his partner. Thus a dialogue continues because the
participants continue to see it as furthering their own goals. Likewise, when the dialogue
no longer serves the goals of one of the participants, it is redirected to new goals or
to
this mechanism of joint interaction, via exchange of utterances, in pursuit of desired
Liles, is useful for achieving certain related pairs &amp;quot;of participants&apos; goals (e.g.,
learning/teaching, buying/selling, getting help/giving help, ...). Many of these paired sets
of goals correspond to highly structured collections of knowledge, shared by the
mcmbers of the languor° community. These collections specify such things as: 1) what
characteristics an individual must have to engage in a dialogue of this sort, 2) how this
dialogue is initiated, pursued and terminated, 3) what range .of information can be
communicated implicitly, and 4) under what eircumstances the dialogue will &amp;quot;succeed&amp;quot;
(serve the function for which it was initiated) and how this Will be exhibited in the
participants&apos; behavior.
We have attempted to represent the.se collections _of knowledge and the way in
which they are iried to facilitate the comprehension of a dialogue, in the Dialogue game
Model.
</bodyText>
<note confidence="0.415977">
A Model of Dialogue 11
</note>
<sectionHeader confidence="0.757836" genericHeader="method">
THE DIALOGUE-GAME MODEL
</sectionHeader>
<bodyText confidence="0.947285818181818">
This section describes our Dialogue-game Model at its current state of
development. It starts with a brief overview of dialogue and how it is structured, then
describes the dominant knowledge structures which guide the model, and finally
describes a set of processes which apply theGe knowledge structures to text to
comprehend it,.
Within the mb.cid, each participant in a dialogue is simply pursuing his own goals of
the moment. The two participants interact smoothly because the conventions of
communication coordinate their goals and give them continuing reasons to speak and
listen. These goals have a number of attributes which are not necessarily consequences
of either human activity in general, or communication in particule, but which are
nonetheless characteristic of human communication in the form of dialogue:
</bodyText>
<listItem confidence="0.994017461538462">
1. Goals are cooperatively established. Bidding and acceptance
activities serve to intfoduce goals.
2. Goals,are mutually knokyn. Each party assumes or comes to
know goals of the other, and each interprets the entire dialogue relative to
currently known goals.
3. Goals are conf 4Yu&apos;red by convention. Sets of goals for use in
dialogue (and other Ivguage use as well) are tacitly&apos;known and employed by
all competent speaters oithe language.
4. Goals are bilateral. Each dialogue partkipant assumes goals
complementary to those of his partner.
5. Goals are ubiquitous. A hearer views the speaker as always
having goals he is pursuing by speaking. Furthermore, the hearer recognizes
and uses these goals as part of his understanding of the utterance.
</listItem>
<bodyText confidence="0.7077786">
An uninterrupted dialogue goes through three phases:
establishing goals,
pursuing goals,
decommitting from goals.
A Model of Dialogue 12
</bodyText>
<subsectionHeader confidence="0.765877">
Typically this sequence is repeated several times over the course of a few minutes.
</subsectionHeader>
<bodyText confidence="0.985024833333333">
We have created knowledge structures to represent these conventions, and
processes to apply the conventions to actual dialogues to comprehend them.. Since the
knowledge structures dominate all of the activity, they are described first. The
assimilation of an utterance in the dialogue is represented in this model by a sequence of
modifications of a &amp;quot;Workspace&amp;quot;[2] which represents the attention or awareness of the
listening party. The modifications are roughly cyclic:
</bodyText>
<listItem confidence="0.9687012">
1. A new item of text T is brought into attention through the
&amp;quot;Parser.&amp;quot;[2]
2. Interpretive consequences‘ of T are developed in the Workspace by
a variety of processes.
3. An expressi-on E appears in the Workspace which specifies the
</listItem>
<subsectionHeader confidence="0.605305">
relation between T and the imputed goals of the speaker of T.
</subsectionHeader>
<bodyText confidence="0.998406875">
This final expression is of course a formal expression in the knowledge
representation of the model, E represents the proposition (held by the hearer) that in
uttering T, the speaker was performing an act in pursuit of G, a spbaker&apos;s goal known to
the hearer. Successful comprehension is equated with relating text to satisfaction of
speaker&apos;s goals.
To make an explicit account of dialogue in this way, we now describe the knowledge
structures that represent those conventions which supply the goals for the participants to
pursue. In particular, we will answer the following three questions:
</bodyText>
<listItem confidence="0.89848975">
1. What is the knowledge we are representing within the definition of a
particular Dialogue-game?
2. How is this knowledge used to model the receptive acts of dialogue
participant.s-?&apos;
</listItem>
<bodyText confidence="0.923371">
..... 0 Ohl eft! OOP 11.1, P. owe 4. *as ava. saw op. or, 1W am ad ma am am
</bodyText>
<footnote confidence="0.9467125">
[2rThe Parser and the Work cc are parts of the process model and are described in a
later ecti-on.
</footnote>
<figure confidence="0.46362125">
A Model of Dialogue 13
What sortof processes does it take to support this model?
s rn 3 Game?
A Dialogue-game consists of three parts: a set of Parameters, a collection of
</figure>
<bodyText confidence="0.952515">
Specifications that apply to these Parameters throughout the conduct of the game,
and a partially ordered set of Components characterizing the dynamic aspects of the
r,amo. For the balance of this section, we will elaborate on these three parts and
exemplify these with an example of the Helping-game.
</bodyText>
<subsectionHeader confidence="0.953246">
Parameters
</subsectionHeader>
<bodyText confidence="0.857816125">
Dialogue-games capture a certain collection of inforMation, common across many
dialogues. However, the individual participants involved and the content subjet Of the
dialogue may yary freely over dialogues described by the same Dialogue-game. To
represent this, each Dialogue-game has a set of Parameters which assume specific values
for each particular dialogue.
The dialogue types wc have represented so far as Dialague-gtmes have each
required only three Parameters: the two participants involved (called &amp;quot;Roles&amp;quot;), and the
subject of the dialogue (called &amp;quot;Topic&amp;quot;).
</bodyText>
<subsectionHeader confidence="0.997582">
Paramedter Specifications
</subsectionHeader>
<bodyText confidence="0.975809571428571">
One of the major aspects distinguishing various types of dialogues is the set of goals
held by the participants. Another such aspect is the set of knowledge states of the
participants. We have found that each type of dialogue has a characteristic set of goal
and knowledge states of the participants, vis-a-vis each other and the subject. Within
the formalism of the Dialogue-game, these are called the Parameter Specifications, and
are represented by a collection of predicates on the Parameters.
Thes.e Specifications are known to the participants of the dialogue, and the
requirement that they be satisfied during the conduct of a game is used by thp participants
to signal what Dialogue-games they wish to conduct, to recognize what game is being bid,
to decide how to respond to a bid, to conduct the game once the bid it accepted, and to
terminate the game, when appropriate. These Specifications also provide the means with
which- to explain the implicit, but clearly successful, communication which accompanies
A Model of Dialogue 14
any natural dialogtie. Examples and discussions of these Specifications will accompany
the following description of the Helping-game.
Components
While the Parameter Specifications represent those aspects of a dialogue type that
remain constant throughout the course of a dialogue of that type, we have also found that
certain aspects change in systematic ways. These are represented in Dialogue-games at
Components. In the Dialogue-games we have developed so far, the Components are
represented as a set of participants&apos; subgoals, partially ordered in time.
</bodyText>
<subsectionHeader confidence="0.655196">
Bidding and Accepting
</subsectionHeader>
<bodyText confidence="0.7315995">
Bidding and Acceptance arc entry operations which people use to enter
Dialogue-games. Bidding
</bodyText>
<listItem confidence="0.995972">
1. identifies the gate,
2. indicates the bidder s interest in pursuing the game,
3. identifies the Parameter configuration intended.
</listItem>
<bodyText confidence="0.7856894">
Bidding is performed many different ways, often very briefly. It is typical[y the
source of a great deal of implicit communication, since a brief bid can communicate all of
the Parameters and their Specifications for The Dialogue-game being bid.
Acceptance is one of the typical responses to a Bid, and leads to pursuit of the game.
Acceptance exhibits
</bodyText>
<listItem confidence="0.996366">
1. acknowledgment that a bid has been made,
2. recognition of the particular Dialogue-game and Parameters bid,
3. agreement to pursue the game,
4. assumption of the Acceptor&apos;s role in the Dialogue game,
</listItem>
<bodyText confidence="0.949982434782609">
Acceptance is often implicit, e pecially in telotfvely informal dialogue. 41 can be
indicated by statements of agreement or approval, or by beginning to pursue the Ome-
(ix., attempts to satisfy the goals). Alter&apos;nalives to acceptance include rejecting,
negotiating and ignoring.
Bidding and acceptance appear to be part&amp;quot; of game .entry for all of the
Dialogue-games of ordinary adult dialoNe. They are also involved in game termination.
In the case of termination, three alternatives are posi_able: interruption and spontaneous
termination by either goal satisfaction or unconditional goal failure,
A Model of Dialogue 15
Once a game has been bid and accepted, the two participants each pursue the
subgoals specified for their role by the Components of this game. These subgoals are
mutually complementary, each set facilitating the other. Furthermore, by the time the
termination stage has been reached, pursuit of the Component-sibecified subgoals will
have assured satisfaction of the higher, initial goals of the participants, for which the
game was initiated in the first place.
T he Helping- ,,,ametan Example
In this section, we exhibit a specific Dialogue-game: the He/ping - /70/120. This
game is presented in an informal representation, in order to emphasize the informational
content, rather than the representational power of our formalism. Later in this report we
will present the formal analogue of this same game. In what follows, the bold face
indicates the information contained in the representation of this particular Dialogue-game,
the text in regular type is explanatory commentary.
The (annotated) Helping-game
</bodyText>
<subsubsectionHeader confidence="0.746747">
Parameters: HELPEE,HELPER,and TASK.
</subsubsectionHeader>
<bodyText confidence="0.80267">
The HELPEE wants help from the HELPEE. The TASK is
some sort of a problem, otherwise unspecified.
</bodyText>
<construct confidence="0.973744666666667">
Parameter S_pecifications..
HELPEE: wants to performT ASK.
HE LPEE: wants to be able to performT ASK.
ELPEE: not able to performT ASK.
HELPEE: permitted to perform TASK.
LPEE: a person.
</construct>
<bodyText confidence="0.928868473684211">
A Model of Dialogue 16
These Specifications not only constrain who would qualify
as filling the role of HELPEE, but also provide reliable information
about the HELPEE, given that this individual is believed to be
engaged in the Helping-game. This prohibits someone from
asking for help on a problem he did not want solved. Similarly, if
one receives what he judges to be a sincere request for help to do
some task, the helper normally as lumes that the requester has the
necessary authority to do the task, if only he knew how.
HELPER: wants to help HELPEE performT ASK.
HELPER: able to provide help.
HELPER: a person.
So, in order to be a HELPER, an individual must be willing and
able to provide the needed assistance. Since this Dialogue-game
represents shared knowledge, the HELPER knows these
Specifications, and therefore will not bid the Helping-game to
someone who is not likely to meet them. And similarly, no one
who. fails to meet these Specifications (and knows he fails) will
accept a bid for the Helping-game with hims-elf as HELPER.
</bodyText>
<subsectionHeader confidence="0.626161">
Components of the He/ping- game..
</subsectionHeader>
<bodyText confidence="0.976561">
There are three components: the first two constitute the
&amp;quot;Diagnosis&amp;quot; phase to communicate what the problem is.
</bodyText>
<sectionHeader confidence="0.348863" genericHeader="method">
I. HELPEE wants HELPER to know about a set of unexceptional, actual
events.
</sectionHeader>
<bodyText confidence="0.99821">
The HELPEE sets up a context by describing a situation
where everything, so far, is going well. Since the HELPEE
assumes that the TASK is understood by the HELPER, he also
assumes that the HELPER shares his expectations for subsequent
activity.
</bodyText>
<figure confidence="0.9097264">
A Model of Dialogue 17
2. HELPEE wants HELPER to know about:
I) a set of exceptional events which occurred
or
2) a set of expected, unexceptional events whic1,7 dio&apos; not occur.
</figure>
<bodyText confidence="0.9880284">
This pattern of a Helping-game is sufficiently well known to
the participants, that the HELPEE almost never needs to actually
ask a question at this point. By simply exhibiting a failure of
expectation, the HELPEE has communicated that this acts as a
block to his successfully pursuing the TASK. The HELPER is
expected to explain why the failurd occurred and how HELPEE can
avoid it or otherwise continue in the TASK.
The third component specifies the &apos;Treatment&amp;quot; phase where
the HELPER communicates an explanation for the perceived
failure.
</bodyText>
<listItem confidence="0.532265">
3. HELPER wants HELPEE to know about an action which will avoid the
undesired event or cause the desired one.
</listItem>
<bodyText confidence="0.925703181818182">
The context description enables the HELPEE to identify a
collection of activities which he understands, and in which the
HELPEE is attempting to participate. The
violation-of-expectation description points out just where the
HELPEE&apos;s image of the activities differs from the correct image. It
is from this area of difference that the HELPER selects an action
for the HELPEE.
A Model of Dialogue 18
Dialogue - games in the Comprehension of Dialogue
In this section we describe the five stages of dialogue assimilation and detail the
involvement of Dialogue-games with each stage:
</bodyText>
<listItem confidence="0.9903316">
1) nomination,
2) recognition,
3) instantiation,
4) conduct,
5) termination.
</listItem>
<subsectionHeader confidence="0.76787">
Processing Environment
</subsectionHeader>
<bodyText confidence="0.983256142857143">
Our description of the model should be viewed as representing the changing
cognitive state of one of the participants, throughout the course of the dialogue. That is,
two models are involved, one for each participant. Since the same processing
occurs for both, we will describe only one.
The Dialogue-Game Model consists of a Long-Term Memory (LTM), a Workspace
(WS), and a sot of processes that modify the contents of WS, contingent upon the contents
of LTM and WS. LTM contains a representation of the knowledge that the particular
dialogue participant bl ings to the dialogue before it starts. This includes knowledge
about the world, relevant objects, processes, concepts, the cognitive state of his partner
in diaJogue, rules of inference and evidence, as well as linguistic knowledge (words and
their semantic representation, case frames for verbs and predicates and the multi-turn
language structures, the Dialogue-games).
WS is the volatile short-term memory of the model, containing all the partial and
temporary results of processing. The contents of WS at any moment represent the
model&apos;s state of comprehension and focus at that point. The processes are autonomous
specialists, operating independently and in parallel, to modify the, entities in WS (called
&amp;quot;activations&amp;quot;). These processes are also influenced by the contents of WS, as well as by
the knowledge in LTM. Thus, WS is the place in which these concurrently operating
processes interact with each other. This anarchistic control structure resembles that
the HEARSAY system (Erman, Fennel, Lesser &amp; Reddy, 1973)
A Model of Dialogue 19
</bodyText>
<subsectionHeader confidence="0.711179">
Nomination
</subsectionHeader>
<bodyText confidence="0.951245736842105">
When dialogue participants propose a new type of interaction, they do not
consistently use any single word or phrase to introduce the interaction. Thus we cannot
determine which Dialogue-games represent the dialogue type through a simple
invocation by name or any other pre-known collection of words or phrases. Instead the
dialogue type is communicated by attempts to establish various entities as the values of
the Pal meters of the desired Dialogue-game. Thus, an utterance which is
comprehended as associating an entity (a, person or a concept) with a Parameter of a
Dialogue-game suggests that Dialogue-game as a possibility for initiation.
The Dialogue-Game Model has two ways in which these nominations of new
Dialogue-games occur. One of the processes of the model is a &amp;quot;spreading activation&amp;quot;
process caltei&apos;d Proteus (Levin, 1976). Proteus generates new activations in WS on the
basis of Eclations in LTM, from concepts (nodes in the semantic network) that are already
in WS. Proteus brings into focus concepts somehow related to those already there. A
collection of concepts in WS leads to focusing on some aspect of a particular
Dialogue-game, in this sense &amp;quot;nominating&amp;quot; it as a possible new Dialogue-game.
MATCH and DEDUCE are two of the model s processes which operate in conjunction
to generate new activations from existing ones, by means of finding and ap.07110rule-like
transformations, They operate through partial match and plausible inference-techniclues,
and if they activate Parameters, then the Dialogue-game that contains those Parameters
becomes nominated as. a candidate Dialogue-game. Match and Deduce operate together
as a kind of production system (Newell, 1973).
For example, from the input utterance:
&amp;quot;I tried to send a message to &lt;person&gt; at &lt;computer-site&gt; and it didn&apos;t go.&amp;quot;
the following two sequences of associations and inferences result:
(la) I tried to X.
(2a) I wanted to X.
(3a) I. want to X.
(4a) HELPEE wants to do TASK.
(lb) It didn&apos;t go.
(2b)What I tried to do dirin&apos;t work.
(3b) X didn&apos;t work.
(4b) I can&apos;t X.
(5b) I don&apos;t know 115 to X.
(GE) HELPEEldp6sn&apos;t know how to do TASK.
A Model of Dialogue 20
(Where: I = HELPEE and X = do TASK = send a message to &lt;person&gt; at &lt;computer-site&gt;.)
At this point, (4a) and (6b), since they are both Parameter Specifications for the
Helping-game, cause the model to focus on this Dialogue-game, in effect nominating it as
an organizing structure for the dialogue being initiated.
Recognition
The processes described so far are reasonably unselective and may activate a
number of possible Dialogue-games, some of which may be mutually incompatible or
otherwise inappropriate. The Dialogue-game Manager investigates each of the
nominated Dialogue-games, verifying inferences based on the Parameter Specifications,
and eliminating t those Dialogue-games for which one or more Specifications are
contradicted.
A second mechanism (part of Proteus) identifies those activations which are
incompatible and sets about accumulating evidence in support of a decision to accept one
and delete the rest from the WS.
Fdr example, suppose the question
&amp;quot;How do I get RUNOFF to work?&amp;quot;
leads to the nomination of two games:
Info-seek-game (person asking question wants to know answer)
and
Info-probe-game (person asking question wants to know if other knows answer)
These two Dialogue -games have a lot, in common hut differ in one crucial aspect: In the
Info-seek-game, the questioner does not know the answer to the question, while in the
Info-probe-game he does. These two predicates are represented in the Parameter
Specifications of the two Dialogue-games, and upon their joint nomination are discovered
to be contradictory. Proteus represents this discovery with a structure which has the
effect of eliminating the conflicting Dialogue-game with the least supporting evidence.
Such support might be, for example, either the knowledge that the speaker is the hearer&apos;s
teacher or that he is a novice programmer (which would lend support for the choice of the
Info-probe-game or Info-seek-game, respectively).
A Model oh Dialogue 21
Through these processes, the number of candidate Dialogue-games is reduced until
those remaining are compatible with each other and with the knowledge currently in WS
and in LTM.
Instantiation
Once a proposed Dialogue-game has successfully survived the filtering procestses
described above, it is then instantiated by the Dialogue-game Manager. Those
Parameter Specifications not previously known (represented in the WS) are established
as newly inferred knowledge about the Parameters. A large part of the implicit
communication bttween dialogue participants is modeled through Instantiation.
To illustrate this, suppose that the following come to be represented in WS (i.e.,
known) in the course of assimilating an utterance:
SPEAKER does not know how to do a TASK.
SPEAKER wants to know how to do that TASK.
SPEAKER wants to do the TASK.
These are adequate to nominate the Helping-game. In the process of instantiating this
Dialogue-game, the following predicates are added to WS:
SPEAKER believes HEARER knows how to do TASK.
SPEAKER believes HEARER is able to tell him how to do TASK.
SPEAKER believes HEARER is willing to tell him how to do TASK.
SPEAKER wants HEARER to tell him how to do TASK.
SPEAKER expects HEARER to tell him how to do TASK.
The model predicts that ithe.e predicates will be implicitly communicated by an
utterance which succeeds in instantiating the Helping-game. This corresponds to a
dialogue in which can&apos;t get this thing to work&amp;quot; is taken to communicate that. the speaker
wants to &amp;quot;get this thing to work&amp;quot; (even ,though, on the surface, it is only a simple
declarative of the speaker&apos;s ability).
Conduct
Once a Dialogue-game is instantiated, the Dialogue-game Manager is guided by the
Components in comprehending the ret of the dialogue. These Components are goals for
A Model of Dialogue 22
the dialogue participants. For the speaker, these goals guide what he is next to say; for
the hearer, these provide expectations for the functions to be served by the speaker s
subsequent utterances.
These &amp;quot;tactical&amp;quot; goals are central to our theory crf language; an utterance is not
deemed to be comprehended until some direct consequence of it is seen as serving a goal
imputed to the speaker Furthermore, although the goals of the Components are active
only within the conduct of a particular game, their pursuit leads to the satisfaction of the
goals described in the Parameter Specifidations, which were held by the participants
prior to the evocation of the Dialogue-game.
In the case of the Helping-game, the goals in the &amp;quot;diagnostic&amp;quot; phase are that the
HELPEE describe a sequence of related, unexceptional events leading up to a failure of his
expectations. These goals model the state al thC HELPER as he assimilates this initial
part of the dialogue, both in that he knows how the HD:PEE is attempting to describe his
problem, and also that the HELPER knows when this phase is past, and the time has come
(the &amp;quot;treatment&amp;quot; phase) for him to provide the help which has been implicitly requested.
Termination
The processes described above perform the identification and pursuit of
Dialogue-games. How, then, are DGs terminated? The Parameter Specifications
represent those aspects of dialogues that are constant over that particular type of
dialogue. The Dialogue-Game Model pushes this a step further in specifying that the
Dialogue-,game continues only as long as the Parameter Specifications continue to hold.
Whenever any predicate in the Specification ceases to hold, then the model predicts the
impending termination of this Dialogue-game.
For example, if the lif:LPES no longer wants to perform the TASK (either by
occomplishing it or by abandoning that goal), ho indicates this with an utterAnco which
bids for termination. The Wiping game then tPrrnmates; this corresponds to thc,
simultaneous termination of the helping interaction. If the HELPER becomes unwilling to
give help, or discovers that he is unable, then the Helping-game also terminates. Again,
we .have one simple rule tht covcrs di4crsity of cases--a rule for termination that
captures the variety of way, that the•dialogues we have studied end.
A Model of Dialogue 23
The Dialogue- game Processes
In this section we describe the major process elements of the Dialogue-Game
Model. All the major parts and their connectivity are shown in Figure 1. These parts
(two memories and six Processes) will each be described separately. The appendix
contains an extensive, detailed trace of the model as it analyzes (via hand simulation) a
naturally occurring dialogue fragment. Finally, we will summarize our experience with
the model to date.
</bodyText>
<subsectionHeader confidence="0.563273">
Long-term Memory (LTM)
</subsectionHeader>
<bodyText confidence="0.961111153846154">
The Long-Term Memory is the model&apos;s representation of a participant&apos;s knowledge
of the external World. It contains the initial knowledge states of the participants: the
grammatical case frames, the semantic structures for word-senses, the knowledge of the
subject matter of the dialogue, the various ways in which dialogues are structured, etc.
LTM is a semantic network, containing a set of nodes (also called concepts) and the
relations that hold between them at the lowest level. This information is stored in the
form of triples:
&lt;node-1 relation node-2&gt;
We have this machinery encoded and working--a full complement of read and write
primitives for this representation. However, it has proven awkward for us to specify
knowledge at this level, so we have implemented further machinery (named SIM) to
translate n-ary predicates into these triples. Thus, far a predicate, P, having arguments
Al, A2, and A3, SIM can be given the input:
</bodyText>
<subsectionHeader confidence="0.676565">
Pl: (Alpha P Beta Gamma)
</subsectionHeader>
<bodyText confidence="0.996784666666667">
[mearling that P1 is defined to be an instance of P (the predicate always goes insec-ond
position) with arguments Alpha for Al, Beta for A2 and Gamma-or A3.} The resulting
triples are created:
</bodyText>
<sectionHeader confidence="0.499762" genericHeader="method">
&lt;P1 PRED P&gt;
</sectionHeader>
<footnote confidence="0.94799875">
&lt;P1 Al ALPHA›
&lt;P1 A2 BETA&gt;
&lt;P1 A3 GAMMA&gt;
Let&apos;s examine a more concrete example; suppose we want to include in the LTM
</footnote>
<figureCaption confidence="0.725792">
that:
Figure 1. The Dialogue-game Model
</figureCaption>
<figure confidence="0.8366152">
Dialogue
text
A Model of Dialogue 24
A Model of Dialogue 25
Mary hit John with a rock.
</figure>
<bodyText confidence="0.910337">
The predicate &amp;quot;HIT&amp;quot; has two mandatory arguments (subject, object) and an optional one
(instrument). The SIM representation of this.assertion (which we shall. name Q1) is
</bodyText>
<sectionHeader confidence="0.940729" genericHeader="method">
Q1:(MARY HIT JOHN ROCK)
</sectionHeader>
<bodyText confidence="0.799171">
which translates into the following triples:
</bodyText>
<sectionHeader confidence="0.99926725" genericHeader="method">
&lt;Q1 PRED HIT&gt;
&lt;Q1 SUBJ MARY&gt;
&lt;Q1 OBJ JOHN&gt;
&lt;Q1 INST ROCK&gt;
</sectionHeader>
<subsectionHeader confidence="0.586283">
Workspace (WS)
</subsectionHeader>
<bodyText confidence="0.99699175">
The Workspace is the model&apos;s representation for that information which the
participant is actively using. This memory corresponds roughly to a model of the
participant&apos;s focus of attention.
While the LTM is static during the operation of the model (we are not attempting to
simulate levning), the WS is extremely volatile, with elements (activations) coming into
and out of focus continuously. All incoming sensations (i.e., utterances) appear in the WS,
as do all augmentations of the participant&apos;s knowledge and goal state. The
representational format of the WS is the satire as in LTM. Each node in the WS is &apos;a token
(copy) of some node in LTM. Whenever some process determines that the model&apos;s
attenlion (WS) should include a token of a specific node (C) from LTM, a new node (A) is
created by copying C and this new node is added to the WS. A is referred to as an
-aivActbtation_01)is.s1or
</bodyText>
<sectionHeader confidence="0.789045" genericHeader="method">
&lt;A IAO C&gt;
</sectionHeader>
<bodyText confidence="0.891542181818182">
This representation provides the associative links between an object in attention, and the
body of knowledge assOciated with it, but not yet brough.t into attention.
A Model of Dialogue 26
Parser
This module produces activations representing each successive utterance to be
processed. These representations are generated from the surface string using a
standard ATN Grammar similar to those developed by Woods (19701 and Norman,
Rumelhart, &amp; the LNR Research Group (1975). We use a case graMmar representation,
with each utterance specified as a main predicate with a set of parameters. Because this
module is a conventional parser whose implementation is well understood, we have so far
produced hand parses of the input utterances, following an ATN grammar.
</bodyText>
<subsectionHeader confidence="0.331138">
Proteus
</subsectionHeader>
<bodyText confidence="0.972989142857143">
This is a spreading activation mechanism, which modifies the activation of concepts
specified as related in LTM whenever a given concept becomes active. This mechanism
provides a way to integrate top-down and bottom-up processing within a uniform
framework (Levin, 1976). The Dialogue-Game i4odel uses Proteus to activate a
concept, given tha a number of closely related concepts (Components, features,
instances, etc.) are active.
Proteus operates on all currozt activations to modify their &amp;quot;salience&amp;quot;, a number
associated with each activation that generally represents the importance or relevance of
the concept. Two kinds of influence relations can exist between concepts: excite or
inhibit. If an excite relation exists, then Proteus increases the salience of the
activation of that concept in proportion to the salience of the influencing concept. The
higher the salience of an activation, the larger its influence on directly related- concepts.
If an inhibit relation is specified, then Process decreases the salience of the activation
of the neighboring concept.
Match
This Process identifies concepts in LTM that are congruent to existing activations.
The Dialogue-Game Model contains a number of equivalence-like relations, which Match
U5CG to identify a concept in LTM as representing the same thing as an activation of some
seemingly different concept. Once this equivalent concept is found, it is activated.
Depending on how this concept is defined in LTM, its activation may have effects on other
processes (for example, if the concept is part of a rule, Deduce may be invoked).
</bodyText>
<subsectionHeader confidence="0.281232">
Match can be viewed as an attempt to find an activation (A) in WS and a Concept (C)
</subsectionHeader>
<bodyText confidence="0.771508">
in LTM which correspond, according. to some -et of criter The basic tactic is to attempt
</bodyText>
<subsectionHeader confidence="0.407407">
A Model of Dialogue 27
</subsectionHeader>
<bodyText confidence="0.95363725">
to find a form 0 equivalence relationship between A and C, without delving into their
structure at alt. Only if this f ails are their respective substructures examined. In this
second case, the same match which was atlempted, at the top level is tried between
corresponding subparts of A and C. Match proceeds in five steps:
</bodyText>
<listItem confidence="0.98407575">
1. Is it already known that A is an activation of C? If so, the mateh terminates
with a positive conclusion.
2. Is there any other activation (A&apos;). and/or concept (C&apos;) such that A&apos;is known
to be a yiew of A, C is known to be a kind of C&apos;, and A&apos; is known (by step 1) to
</listItem>
<bodyText confidence="0.90652475">
be an activation of C&apos;? The relations is a view of ...) and (... is a kind of ...)
represent stored relations between pairs of activations and concepts,
respectively. One concept &amp;quot;is a kind of&amp;quot; another concept rep, a
soperclass inclusion, true&apos; for all time and &apos;contexts. (Whatever else he migh4
be, John is a kind&apos;of human being.) On the other hand, one activation may be &amp;quot;a
vievv of&amp;quot; another only under certain circumstances--a conditional, or tactical
relationship. Under differentconditions, it is appropriate to view John as a
Husband, Father, Child., Help-seeker, Advice,.giver, etc,
</bodyText>
<listItem confidence="0.9594928">
3. A list of matched pairs of activations and concepts represent
correspondences found elsewhere, with which match must be consistent.
(N.B.: this Match, as we Will see later, may be in service of another Match
called&apos; on structures containing the current A and C.) If the pair [A,C] is a
matched pair, then these tvyo have been previously found to maichrso we may
here conctude, the same thing and Match exits.
4. On the other hand, if there is either an X or a Y such that [AIX] (or [Y,C]) is
a matched pair, then replace this match with an attempt to match C and X (or A
and Y).
5. Finally, if the match•has neither succeeded nor failed by this point, then
Match is called recursivdy on all corresponding subparts of A a&apos;nd C,
pairwise. That is, e.g., if A and C have only three subparts in common (say,
SUBJ, 0I3J and PRED) thori Match((SUBJ of A),(SUBJ of C)), Match((0E3JA.of
A),(OBJ of C)) and Match((PRED of A),(MED of C)) arc attempted. Only if all of
these subordinate matches succeed is the top-level Match void to succeed.
</listItem>
<bodyText confidence="0.977295333333333">
Clearly, for structures of significant compleXity, Match may eventually call itself
recursively, to an arbitrary depth. However, since each subordinate call is on a strictly
smaller unit, this process must coriverge.
</bodyText>
<subsectionHeader confidence="0.471726">
A Model of Dialogue 28
</subsectionHeader>
<bodyText confidence="0.998005">
Our experience has shown us that this type of mechanism plus a collection of
rewrite rules enable us to eventually map a wide variety of input parsing structures to
pre-stored, abstract knowledge structures, in a way that a significant aspect of their
intended meaning has been assimilated in the process.
</bodyText>
<subsectionHeader confidence="0.514303">
Deduce
</subsectionHeader>
<bodyText confidence="0.958404133333333">
This operates to carry out a rule when that rule has become active. Rules are of
the form (Condition)-&gt;(Action), and Deduce senses the activity of a rule and applies the
rule by activating the concept for the action. Whatever corresponoences were evolved
in the course.of creating the activation of the condition (left) half of The rule are carried
over into the activation of the action (right) half. The combination of Match and Deduce
gives us the capability of a production system.
The operation of Deduce is relatively simple. It is called only when a rule is active
in the WS. Deduce attempts to match the left half of this rule with some other actNati on
in the WS. (This has typically already been done by match.) Assuming this is
accomplished, Deduce creates an activation of the right half of the rule, substituting in the
activation for all subparts for which there are correspondences with the left half.
Dialogue-game Manager
Once a Dialogue-game has been activated (by Proteus) as possibly the
communication form being bid for a dialogue, the Dialogue-game Manager uses it to guide
the assimilation of successive utteraices of the dialogue, through four stages:
</bodyText>
<listItem confidence="0.988015833333333">
1. establish the Parameter values and verify that no Specification is
contradicted,
2. establish otherwise unsupported Specifications as assumptions,
3. establish the Components as goals of the participanG,
4. detect the circumstances which indicate that the Ualop,ue-game is
terminating and represent the consequences of this.
</listItem>
<bodyText confidence="0.988580294117647">
The first two of these phases happen in parallel. When the Manager accesses
each of the Parameters, they are found either to have activations in the WS or not. If
they do, the correspondences between activation, and Parameter are established in the
WS. This corresponds to assigning a value to the Parameter for this particular evocation
of the Dialogue-game. Any Parameter that ha no activation is put on a list which is
A Model of Dialogue 29
periodically checked in the hope that later activity by the Manager will lead to the
creation of appropriate activations.
For each of the Specifications, a check is made to determine if it already has an
activation in WS. (In most cases, the activation of some of these Specifications will have
led to the activity of the Dialogue-game itself.) The Specifications having activations need
no further attention.
For all remaining Specifications, activations are created substituting for the
Parameters as determined above. At this stage, the Dialogue-game Manager calls
Prottus to determine the stability of these new activations. Any new activation which
contradicts existing activations will have its level of activity sharply reduced by Proteus.
If this happens, the Dialogue-game Manager concludes that some of the necessary
preconditions for the game do not hold (are in conflict with current understanding) and
that this particular game should be abandoned. Otherwise, the new activaticns stand as
new knowledge, following from the hypothesis that the chosen game is appropriate.
The Dialogue-game has now been successfully entered; the Manager sets up the
third phase, creating activations of the Dialogue-game&apos;s Components, with appropriate
substitutions. (By this time, any unresolved Parameters may well have -activations,
permitting their resolution.) This sets up all of the game-specific knowledge and goals for
both participants.
Finally, the Manager detects that one of the Specifications no longer appears to
hold. This signals the impending termination of the Dialogue-game. In fact, the
utterance whilch contains this information is a bid to terminate. At this point, if the
participants&apos; initial goals are satisfied (thus contradicting the Specification which Calls for
the presence of those goals) the interaction ends &amp;quot;successfully&amp;quot;. Otherwise, the
Dialogue-game is terminated for some other reason (e.g., one participant&apos;s unwillingness
or inability to continue) and would generally be regarded as a &amp;quot;failure&amp;quot;. These
consequences are inferred by the Manager and added to the WS. When a Dialogue-game
has terminated, its salience goes to zero and it is removed from the WS.
</bodyText>
<subsectionHeader confidence="0.934998">
Pronoun Processes
</subsectionHeader>
<bodyText confidence="0.911940222222222">
The Dialogue-Game Model contains a set of Pronoun Processes, including an
I-Process, a You-Process, and an It-Process. Each of these is invoked whenever the
associated surface word appears in an input utterance, and operates to identify some
preexisting activation that can be seen as a view of the same object.
A Model of Dialogue 30
Each of these Processes search th&apos;e current context, as represented by the current
set of activations in the WS, using the features specified there to identify a set of possible
co-refol.ential expressions. When there is more than one possibility, the one with a
higher salience is selected.
</bodyText>
<note confidence="0.571919">
A Model of Dialogue 31
</note>
<sectionHeader confidence="0.913205" genericHeader="method">
DEFICIENCIES IN CURRENT MAN-MACHINE COMMUNICATION
</sectionHeader>
<bodyText confidence="0.980055375">
With the understanding we new have of the multi-sentential aspects of human
communication, it is easy to see why man-machine communicttion appears so alien, highly
restrictive, uncomprehending and awkward. This is because major regulation and
inter prettdion structures are missing.
In Table 1, we compare human dialogue and typical man-machine communication
with respect to some of these features. The table designates a &amp;quot;sender and a &amp;quot;receiver&amp;quot;
which should be identified with the person and the computer, respectively, in the
man-machine communication case.
</bodyText>
<sectionHeader confidence="0.991243" genericHeader="method">
ASPECTS OF NATURAL COMMUNICATION HUMAN MAN-
ADDRESSED BY DIALOGUE-GAME THEORY . DIALOGUE MACHINE
SENDER&apos;S GOALS KNOWN TO RECIPIENT YES NO
PARTICIPANTS CAN DECLARE THEIR GOALS YES NO
GOALS PERSIST OVER SEVERAL MESSAGES YES NO
GOALS IDENTIFIED WITH EACH MESSAGE YES NO
COMMUNICATION PLANS USED YES LITTLE
IMPLICIT COMMUNICATION TAKES PLACE YES LITTLE
</sectionHeader>
<tableCaption confidence="0.998754">
Table 1: omparison of man-man and man-machine communication
</tableCaption>
<bodyText confidence="0.8258592">
Conventional man-machine communication frequently gives the user a sense that
the computer is operating &amp;quot;out of context&amp;quot;, since he must continually respecify what is
relevant to the ongoing dialogue. In human communication it is the shared awareness of
each other&apos;s goal structures which permits them to retain and focus,on what is relevant.
Man-machine communication seems aimless and undirected because no analogous body of -
knowledge is being used to facilitate and interpret the communication.
A Model of Dialogue 32
The ideal interface, and the sort toward which this research is direcied, would be
continuously asking itself: &amp;quot;Why did he say that?&amp;quot;. From answers to this, the interface
would infer just what the human was expecting as a response. This would constitute a
major step toward the enabling the. interface to serve the actual (rather than the poorly
expressed) needs of the user. Finally, such an interface would require much less
adaptation on the part of the user, and so, by our original hypothesis, would significantly
enhance the effectiveness of the man-machine partnership.
A Model of Dialogue 33
</bodyText>
<sectionHeader confidence="0.914636" genericHeader="conclusions">
CONCLUSIONS
</sectionHeader>
<bodyText confidence="0.999941833333333">
This paper has described a research effort into the modeling of human dialogue.
The purpose of this research has been to uncover and describe in process models,
regularities that occur in dialogu-e. It is hoped that the enhanced understanding of human
communication which results, will facilitate the development of more natural (and thus
more effective) man-machine interfates.
The principal regularity We have discovered is a collection of knowledge and goal
structures, called Dialogue-games, which seem to be crucial in understanding the
structure of naturally-occurring dialogues. According to the theory we have proposed,
one or more of these Dialogue-games serve as the major organizing influence on every
human dialogue.
Each Dialogue-game specifies what knowledge each person must have to ehgage in
such a dialogue, and what goals of the participants might be served by that interchange.
A Dialogue-game also specifies, as a sequence of &amp;quot;tactical&amp;quot; goals, the manner in which the
dialogue is conducted.
The Dialogue-game Model is a collection of cooperative processes which
continuously updated a representation of each participant&apos;s attention state in a
Workspace. The model recognizes when a particular Dialogue-game is being bid,
accepted, pursued and terminated, and represents these states appropriately in the
Workspace. A particular Dialogue-game, the Helping-game, was described in some
detail. A simulation of the evocation and use of the Helping-game on a segment of natural
dialogue is contained in the Appendix.
Our experience so far with the Dialogue-game Model has reinforced our
hypotheses that an understanding of the goal-serving aspects of dialogue is a powerftil
tool in understanding the individual dialogues.
</bodyText>
<note confidence="0.690451">
A Model of Dialogue 34
</note>
<sectionHeader confidence="0.897859" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.919866620689655">
Austin, J. L. How to do things with words. Cambridge, MA: Harvard University
Press, 1962.
Bales, R. F. Interactive process ana/ysis Cambridge, MA: Addison-Wesley,
1952.
Charniak, E. Organization and inference in a frame-like system of common sense
knowledge. In R. Schank &amp; B. L. Nash-Webber (Eds.), Theoretical issues in
natural language processing. Cambridge, MA: Bolt, Beranek and Newman, Inc.,
1975.
Clark, H. H., &amp; Lucy, P. Understanding what is meant from what is said: A study in
conversationally conveyed requests. Journal of Verbal Learning and Verbal
Behavior, 1975,14, 56-72.
Erman, L. D, Fennell, R. D., Lesser, V. R., -&amp; Reddy, D. R. System organizations for
speech understanding. Proceedings of the Third International Joint
Conference on Artificial Intelligence. Palo Alto, CA: Stanford University,
1973.
Gordon, D., &amp; Lakoff, G. Conversational postulates. Papers from the Seventh
Regional Meeting, Chicago Linguistic Society, 1971.
Grice, H. P. Logic and conversation. In P. Cole &amp; J. L. Morgan (Eds.), Syntax and
semantics. New York: Academic Press, 1975.
Labov, W., &amp; Fanshel, D. Therapeutic discourse. Psychotherapy as
conversation. Draft copy, 1974.
Levin, J. A. Proteus: An activation framework for cognitive process models.
Unpublished doctoral dissertation, San Diego, CA: Univ. of Calif, San Diego, 1976.
Levin. J. A., &amp; Moore, J. A. Dialogue-games: A process model of natural language
interaction. Proceedings of the A/S8 Summer Conference. Edinburgh,
Scotland, July 1976.
Levin, J. A., &amp; Moore, J. A. Dialogue Games: Meta-communication Structures for
Natural Language Interaction (ISI/RR-77-53). Marina del Rey, CA: Information
Sciences Institute, 1977. Also in press, Cognitive Sciences, 1977,1 ( 4 )
</reference>
<note confidence="0.848991">
A Model of Dialogue 35
Mann, W. C. Why things are so bad for the computer-naive user (ISI/RR-75-32).
Marina del Rey, CA: Information Sciences Institute, 1975.
</note>
<reference confidence="0.673744">
Mann, W. C., Moore, J. A., &amp; Levin, J. A. A comprehension model for human
dialogue. Proceedings of the Fifth International Join&apos;t Conference on
Artificial Intelli gence. Cambridge, MA:.MIT, 1977, forthcoming.
Minsky, M. A framework for representing knowledge. In P. H. Winston (Ed.), The
psychology of computer vision. New York: McGraw-Hill, 1975.
Newell, A. Production systems: Models of control structures. In W. G. Chase (Ed.),
Visual information processing. New York: Academic Press, 1973.
Newell, A., &amp; Simon, H. A. Human problem solvtiig. Englewood Cliffs, NJ:
Prentice-Hall, 1972.
Norman, D. A., Rumelhart, D E. &amp; the LNR Research Group. Explorations in
cognition. San Francisco: W. H. Freeman, 1975.
Rieger, C. The commonsense algorithm as a basis for computer models of human
memory, inference, belief and contextual language comprehension. In R. Schank
B. L. Nash-Webber (Eds.), Theoretical issues in natural language
processing. Cambridge, MA: Bolt, Beranek and Newman, Inc., 1975.
Rumelhart, D. E. Notes on a schema for stories. In D. G. Bobrow &amp; A. Collins
(Eds.), Representation and understanding: Studies in cognitive science.
New York: Academic Press, 1975.
Sacks, H., Schegloff, E. A., &amp; Jefferson, G. A simplest systematics for the organization
of turn-taking for conversation. Language, 1974, 50, 696-735.
Schank, R. C., &amp; Abelson, R. P. Scripts, plans and knowledge. Paper presented at
the Fourth International Joint Conference on Artificial Intelligence, Tbilisi, USSR,
August 1975.
</reference>
<note confidence="0.885966714285714">
Searle, J. R. Speech acts: An essay in the philosophy of langdage. Cambridge,
England: Cambridge University Press, 1969.
Searle, J. R. Indirect speech acts. In P. Cole &amp; J. L. Morgan (Eds.), Syntax and
semantics. New York: Academic Press, 1975.
A Model of Dialogue 36
Shatz, M. How young children respond to language: Procedures for answering.
Papers and Reports on Child language Development, Palo Alto, CA: Stanford
</note>
<tableCaption confidence="0.498443">
University, 1975.
Thorndyke, P. W. Cognitive structures in comprehension and memory of &apos;narrative
discourse. Cognitive P.tychology, 1977, .9,77-110.
Wittgenstein, L. Philosophical inve.tigaf ions (3rd ed.). New York: Macmillan,
1958.
</tableCaption>
<note confidence="0.422689">
Woods, W. A. Transition network grammars for natural language analysis.
</note>
<title confidence="0.371976">
Communications of the ACM, 1970,13,-591,-606.
A Model of Dialogue
</title>
<sectionHeader confidence="0.751672" genericHeader="references">
APPENDIX -- SIMULATION OF THE DIALOGUE-GAMES MODEL
</sectionHeader>
<subsectionHeader confidence="0.980186">
Example of theDialogue Model in Action
</subsectionHeader>
<bodyText confidence="0.9975249375">
In this appendix we describe an extensive simulation of the current state of the
Dialogue-game Model. We make use of a particular version of the Helpin-game and alsc
explore another structure, an Execution Scene, which describes the customary events
surrounding the successful execution of a particular program (Runoff).
We start by describing this more detailed version of the Helping-game, introducing
names for the various aspects, to be used later. Next we show a short, naturally
occurring dialogue between a computer operator and a user. Then we describe the
operation of the Dialogue-game Model as it assimilates this dialogue, up to the point at
which it concludes that the Herping-game is an appropriate structure through which to
understand the subsequent utterances.
Once this hypothesis for the form of the dialogue has been chosen, we continue the
simulation to examine how othe model decides that a particular Execution Scene is
appropriate for assimilating the content of the dialogue. Next, we see how this choice of
scenes enhances the set of goals imputed to the speaker, thus facilitating the
comprehension of what he is saying. Finally, we summarize our experience with the
Dialogue-game Model so far.
</bodyText>
<subsectionHeader confidence="0.456415">
A Detailed&apos; Structure far the He/ping - game
</subsectionHeader>
<bodyText confidence="0.9984164">
What follows is the substance of the communication structure we have named the
Helping-game. In the interests of clarity of presentation, the formal structures of the
definition have been expressed in prose. However, the elements of the following
description correspond one-to-one to those in the actual Helping-game used in &apos;the
simulation.
</bodyText>
<note confidence="0.600358166666667">
HELPING-GAME
Parameters:
The parameters are two roles (HELPER and HELPEE) and a topic (TASK/HG).
A Model of Dialogue 38
Parameter specifications:
The HELPER and HELPEE are each a kind of person.
</note>
<tableCaption confidence="0.726986121212121">
HI = A goal of the HELPEE is that he perform TASK/HG.
H2 = It is not true that HELPEE is able to perform this TASK/HG.
H5 = The HELPEE wants to be able to perform the TASK/HG.
(being able to perform the task is a subgoal of
performing the task)
H6 = The HELPER is able to enable the HELPEE to perform the TASK/HG.
H8 = The HELPER is willing (= is able to want to ...) to enable the
HELPEE to perform the TASK/HG.
H10 = The HELPEE is permitted to perform the TASK/HG.
HII = The HELPEE wants the HELPER to enable him to perform the TASK/HG.
(being enabled to perform the taskis&apos;a subgoal of
performing the task)
Game components:
HGX1 = The HELPEE knows of a particular execution scene, XS/HE.
[note: an execution scene is a flowchart-like description
of the use of a particular process; more details below]
HGX2 = The HELPEE knows that his perceiving the terminal state of XS/HE
would satisfy his wanting to perform TASK/HG.
HGX2C= (Thus) The HELPEE wants to perceive XS/HE in this terminal
state.
(this perception is a subgoal of performing the TASK/HG)
ACTION/GOOD = an ACTION of XS/HE which was realized in the past.
HGX3 = The HELPEE knows he has perceived this ACTION/GOOD.
HGX4 = The HELPEE knows he had expected to perceive it.
HGX5 = The HELPEE knows he wants to perceive this ACTION/GOOD.
(perceiving the ACTION/GOOD is a subgoal of perceiving the
rdesiredlterminal state of the XS/HE)
ACTION/BAD = an ACTION of XS/HE which was not realized in the past.
HGX6 = The HELPEE knows that he did not perceive ACTION/BAD.
1-1GX7 = The HELPEE knows that he had expected to perceive it.
HGX8 = The HELPE wants to perceive ACTION/BAD.
(perceiving the ACTION/BAD is a subgoal to perceiving the
terminal state of XS/HE.)
</tableCaption>
<footnote confidence="0.8676938">
HGX9 The HELPEE wants to describe what happened which was both
expected and wanted, the ACTION[s]/GOOD.
(describing these ACTION[s]/GOOD is a subgoal of having
the HELPER enable the HELPEE to perform the TASK/HG.)
HGX10= The HELPEE wants to describe what did not happen that he
</footnote>
<note confidence="0.841906">
A Model of Dialogue 39
</note>
<bodyText confidence="0.98898825">
expected, and wanted, the ACTION[s]/BAD.
(describing these ACTION[s]/BAD is a subgoal of having
the HELPER enable the HELPEE to perform the TASK/FIG.)
The Dialogue to be Modeled
What follows is a transcript of a naturally occurring dialogue between a computer
operator (identified as &amp;quot;0&amp;quot;) and a user (&amp;quot;L&amp;quot;) who has &amp;quot;linked&amp;quot; to the operator, in an
attempt to solve a problem.
There has been virtually no &amp;quot;cleanup&amp;quot; of this transcript, except to remove
extraneous typing that had appeared on the operator&apos;s console listing as a result of the
operating system printing routine status messages. The choice of words, and even
spelling, are exactly as typed by the participants. (We have segmented the text by
interposing carriage-returns as we deemed appropriate.)
</bodyText>
<table confidence="0.561773333333333">
Dialogue 0C117
LINK FROM [Li, TTY 42
L: How do I get runoff to work,
I keep xeqtn it
but it just grabs my input file
and then says done
but gives me no output?
GA
0: The output comes out on the line printer
Throw it away
but can I get it to go to a file?
GA
0: Confirm your commands with a comma
and you&apos;ll be queried for files, etc.
GA
A Model of Dialogue 40
L: Thanx mucho
BREAK
</table>
<bodyText confidence="0.933829553846154">
The subsequent simulation is of the model processing the first five segments, the
entire first utterance. Each utterance is ingested one at a time, by the Parser, and the
assimilation proceeds until a quiescent state is reached (much more detail, below)
whereupon the next segment is parsed and input for processing.
The identification of the Helping-game
How does the model know to evoke the Helping-game? To exhibit answers to this
and subsequent questions, we lead the reader through a simulation of the mod&amp; as it
processes the beginning of dialogue 0C117. We indulge in the same use of prose for
formalism as aboi/e, again with the same assurances of correspondences with the actual
simulati on.
The simulation proceeds in cycles; in each cycle, we exhibit the operation of a
single processor, performing one iteration of its function. We do not address here the
is
sues of how the model would select which processor to call next. ln fact, our design
calls for these processors to be maximally autonomous and parallel in their operation,
operating whenever circumstances are ripe for their function and dormant otherwise.
The format of this simulation is as follows: The cycle number is first, in the form:
segment number)---cycle number in this segment?. Next is the name of the processor
operating in this cycle. After that is a description of the nature of the processing done
choirs. that cycle. Finally, there is a list of the results for this cycle, that is, ll the
important changes in WS.
Initially, the description is at a very detailed level. But after a while, the
operations beconle extremely repetitive so the description becomes less debited,
focusing only on the unique aspects of the current operation. In this example, each
processor is called at least once in the processing of each segment; Match, Deduce and
Proteus bear the major burden, having several invocations each peer segment.
A Model of Dialogue 41
Cycle 1-1 — Parse.
The parser reads one utterance/segment of input and translates it into the formalism
for activations in the workspace. No claim is made that this translation retains all the
content of the original text, only that it is adequately faithful to the level of detail we are
simulating.
Results: Case/9 (= (0 perceives that L asks (how do I get Runoff working?))) is activated.
Cycle 1-2 — 1-processor
Certain words (e.g. pronouns, determiners) are taken to be signals that a reference
is being made to concepts introduced elsewhere. The presence of a concept in the
workspace corresponding to one of these words leads to the calling of the.
process-specialist which attempts to resolve the implied reference. Thus, the presence
of &amp;quot;I&amp;quot; in the text leads to the calling of the I-process, whose sole function is to determine
the referent of the &amp;quot;I&amp;quot; and modify the stored concept to reflect this. This process judges
that if L is asking a question which contains &amp;quot;I&amp;quot; as its subject, then this constitutes
adequate evidence to hypothesize that &amp;quot;I&amp;quot; is being used to refer to L.
Results: 0 perceives that L asks (how does L get Runoff working?)
Cycle 1-3 — Match
Match is always on the lookout for pairs of nodes, one in the WS and the other in the
LTM, such that the activation (node in WS) matches the concept (node in LTM). This is
taken to be evidence that the activation is also to be taken as an activation of the matched
concept. It should be understood that we are-examining only some of the succeswful
matches which occurred.
Starting in this cycle, we see a pattern which recurs regularly, and which accounts
fcr a significant piece of the action, as the model assimilates the dialogue. Match
determines that a particular activation matches the left half (condition side, if part, etc.) of
a production-like rule stored in LTM. This successful match leads to the identification of
the correspondences between the aspects of the activation and those of the left- half of
the rule, as well as creating an activation of the rule itself. The activation of a rule leads
to calling the Deduce processor in the-next cycle, which applies the activated rule to the
node in the WS responsible for the rule&apos;s activation. This application of a rule (which
also results in the removal of the rule&apos;s activation from the WS) creates a new activation
structure in the WS.
A Model of Dialogue 42
In other words, the introduction of a piece of knowledge suggests that a certain
transformation (e.g.,°&amp;quot;Whenever you know X, you can conclude Y.&amp;quot;) is appropriate. This
transformation is applied to the stimulus knowledge to generate a conclusion: a new piece
of knowledge.
In this particular case, the above result structure is found to match the left half of
</bodyText>
<equation confidence="0.20406875">
Rule0 = If ()perceives a proposition,
then 0 knows that proposition.
with the correspondences
Case/I (= (L asks (How do I get Runoff working?))) is activated.
</equation>
<bodyText confidence="0.69140775">
corresponds to the proposition.
(This rule represents the approximation that what is perceived is accepted at face value.)
Since Case/5 is now seen to be an activation of the Left-half of Rule°, an activation
for the rule itself is created in the WS.
Results: Case/9 is an activation of Left half of Ruie0.
Case/corresponds to the proposition in Rule°.
An activation of Rule() is entered into WS.
Cycle 1-4--Deduce
Since a rule is active in WS, Deduce is called in an attempt to apply the rule. The
Match has guaranteed that the necessary correspondences exists between the left half of
the rule and the node which is its activation. To apply the rule, Deduce cretes an
activation of the right-half, with the corresponding sub-parts substituted.
</bodyText>
<table confidence="0.85866675">
Results: RO-1 = 0 knows Case/1
Activation of Rule0 deleted from WS.
Cycle 1-5 — Match
Match finds that RO-1 matches the left half of:
</table>
<note confidence="0.7374176">
Rule1 = If 0 knows (L asks about a proposition),
then 0 knows (L does not know about that proposition).
A Model of Dialogue 43
Results: RO-1 is an activation of the left half of Rule1.
Case/1 corresponds to (L asks about a proposition)
</note>
<table confidence="0.832420363636364">
Case/2 = (How does L get Runoff working) corresponds to the
proposition.
An activation of Rule1 is created in the WS.
Cycle 1-6 -- Deduce
Deduce applies Rule 1 to RO-1, substituting according to the discovered
correspondences.
Results: R1-1 (= 0 knows (L does not know Case/2), is activated.)
Activation of Rule 1 deleted from WS.
Cycle 1-7 -- Match
Match R1-1 with left half of
Rule3 = If 0 knows that a person does not know how to perform a
task,
then 0 knows that that person is not able to perform
the task.
Results: R1-1 is an activation of the left half of Rule3.
L corresponds to the person mentioned.
Get corresponds to Perform.
The state of Runoff working corresponds to the task.
An activation of Rule3 is created in the WS.
Cycle 1-8 Deduce
Deduce applies Rule3 to R1-1..
Results: R3-1 (= 0 knows that R3-11 = (L is not able to perform
(getting Runoff working)) is activated).
Activation of Rule 3 deleted from WS.
Cycle 1-9 -- Match
A Model of Dialogue 44
Match R3-11 with H2 = He&apos;pee is not able to perform the task.
Results: R3-11 is an activation of H2.
(getting Runoff working) corresponds to the task.
L corresponds to the Helpee
Cycle 1-10 -- Match
Match RO-1 with left 1/2 of:
Rule2 = if 0 knows (L asks about a proposition),
</table>
<bodyText confidence="0.686163363636364">
then 0 knows (L wants to know about that proposition).
Results: RO-1 is an activation of the left half of Rule2.
Case/1 corresponds to (L asks ...), in Rule 2.
Case/2 corresponds to the proposition.
An activation of Rule 2 is created in the WS.
Cycle 1-11--Deduce
Deduce applies RuIe2 to RO-1.
Results: R2-1 (= 0 knows (L wants to know about Case/2) is activated).
Activation of Rule 2 deleted from WS.
Cycle 1-12-- Match
Match R2-1 with left half of
</bodyText>
<equation confidence="0.431041">
Rule4 = If 0 knows (a person wants to know how
</equation>
<bodyText confidence="0.903894166666667">
to perform a task),
then 0 knows (that person wants to perform that task).
Results: R2-1 is an activation if the left half of Rule4.
L corresponds to the person.
(getting Runoff to work) corresponds to the task.
An activation of Rule 4 is created in the WS.
</bodyText>
<table confidence="0.910359538461538">
Cycle 1-13 -- Deduce
A Model of Dialogue 45
Deduce applies Rule4 to R2-1.
Results: R4-1 (= 0 knows (L wants to perform (getting Runoff working)) is activated),
Activation of Rule 4 deleted from WS.
Cycle 1-14--Match
Match R4-11 with H1 = Helpee wants to perform a task.
Results: R4-11 is an activation of H2.
L corresponds to the Help=
(Getting Runoff working) corresponds to the task.
Cycle 1-15-- Match
Match RO-1 with left half of
RuleVa = If 0 knows (a person says
</table>
<bodyText confidence="0.945038111111111">
(he executes a process with an instrument)),
then 0 knows (that person is saying
(he performs (the execution of the process)
with the instrument).
Results: RO-1 is an activation of the left half of RuleVa,
L corresponds to the person.
(getting Runoff working) corresponds to (... executes a process
How corresponds to the instrument (i.e., the means).
An activation of Rule Va is created in the WS.
</bodyText>
<reference confidence="0.887221931034483">
Cycle 1-16-- Deduce
Deduce applies RuleVa to RO-1.
Results: RVa-1 (= 0 knows ( L asks (how do I perform (getting Runoff working)?)) is
activated)..
Activation of Rule Va deleted from WS.
Cycle 1-17--Match
A Model of Dialogue 46
Match RVa-1 with Left half of
Rule2a = If 0 knows (a person asks how to perform a task),
then 0 knows (that person wants 0 to enable him
to perform that task).
Results: RVa-1 is an activation of the left half of Rule2a.
L corresponds to that person.
(L getting Runoff to work) corresponds to the task.
An activation of Rule 2a is created in the WS.
Cycle 1-18 — Deduce
Deduce applies Rule2a to RVa-1
Results: R2-1 (= 0 knows (L wants 0 to enable him (L) to get Runoff working) is activated).
Activation of Rule 2a deleted from WS.
Cycle 1-19 Match
Match R2a-1 with H11 = Helpee wants Helper to enable him tato a task.
Results: 0 corresporids to Helper.
L corresponds to Helpee.
(L getting Runoff to work) corresponds to the task.
Cycle 1-20 Proteus
H1, H2 gz H11 provide Proteus with enough evidence to create an activation of the
Helping-Game.
Results: An activation of the Helping-game is created in the WS.
Cycle 1-21 -- Dialogue-game Manager
</reference>
<bodyText confidence="0.98647675">
The- presence of an activation of a Dialogue-game in the WS leads to the calling of
the processor specialized in this_category of knowledge. The Dialogue-game Manager
(DGM) makes use of a set of correspondences that have already been established by the
matches which led to the activations of HI, H2, and H11:
</bodyText>
<figure confidence="0.8205385">
A Model of Dialogue 47
Previous Results: L corresponds to He(pee
0 corresponds to Helper
Case/3 (= (Runoff working)) corresponds to the task.
</figure>
<bodyText confidence="0.96136575">
Once an activation of a game has led to the calling of the DGM, the Manager accesses
the entire collection of information about the game from the LTM representation Of it.
The items of knowledge in the game, with the particular parameters of this situation
substituted apprcipriately, fall into one of three categories:
</bodyText>
<listItem confidence="0.489355333333333">
1. Already known to hearer (e.g. H1, H2 &amp; H11). Items in this category are
simply ignored, since it serves no purpose to re-assert them.
2. Contradict knowledge already held by the hearer (e.g., if 0 already knew,
</listItem>
<bodyText confidence="0.848004111111111">
for sure, that L knew all about Runoff). If any item falls into this category, the
hypothesis that this game is active is simply abandoned as inaccurate.
3. Items neither previously known or contradicted (the majority of the
content of the typical case). In this case, the DGM creates activations of
these items to represent the collection of implidit knowledge that follows from
a recognition of the proposed game.
Results: Activations are created for all of the following:
H5 = L wants to be able to get (Runoff working) himself.
(being able to get (Runoff working) is a subgoal
to performing (Runoff working).)
H6 = 0 is able to enable L to get (Runoff working).
H8 = 0 is able to want to enable [i.e. is willing to enable]
L to get (Runoff working).
H10=1 is permitted to get (Runoff working).
The game also contains a collection of knowledge having to do with The conduct of
the game, rather than what the participants need to successfully evoke it. These items of
knowled&amp; and goals are also established as activations by the DGM at this time:
Resufts: Activations are created or all of the following:
HGX1 = L knows of an execution scene (XS/HE).
HGX2 = L knows that if he perceives a particular
terminal state of this scene, this will
satisfy his wanting to perform the task.
HGX2C= (Thus) L wants to perceive this terminal state
A Model of Dialogue 48
of XS/HE.
An ACTION/GOOD,is an-ACTION within the specification of
XS/HE which occurred in the past.
</bodyText>
<equation confidence="0.63184">
HGX3 = L knows that he has perceive the ACTION/GOOD.
HGX4 = L knows he expected to perceive it.
HGX5 = L wanted to perceive it.
</equation>
<bodyText confidence="0.942081095238095">
An ACTION/BAD is an ACTION within the specification of
XS/HE which has not occurred in the past.
HGX6 L knows he has not perceived the ACTION/BAD.
HGX7 = L knows he expected to perceive it.
HGX8 = L knows he wanted to perceive it.
(perceiving the ACTION/BAD is a subgoal to perceiving
the desired terminal state of XS/HE.)
HGX9 = L wants to describe the ACTION[s]/GOOD [to 0].
(this describing is a subgoal to (0 enables L to
perform the task)
HGX10= L wants to describe the ACTION[s]/BAD [to 0].
(this describing is a subgoal to (0 enables L to
perform the task)
Processes, procedures, ceremonies, and the like, may have an associated execution
scene, which is in effect an abstract description of a complete performance of the object
described. The execution scene resembles a flowchart, with the boxes being actions of
one of the active agents involved.
In this cote, the execution scene is for Runoff, a program which reads a file
specified by the user, formats the contents of the file, and outputs this formated material
onto either the line printer or another file. The execution scene of Runoff, as stored in
our model, is similar to figure A-1.
</bodyText>
<figure confidence="0.98281203030303">
A Model of Dialogue 49
START
1
. User initiates Runoff
XSA-2 . Runoff requests a file name.
1
XSA-3 . User types a file name.
1
XSA-4 Runoff requests a confirmation.
1
1
[one of the following two paths is taken:)
1
1
XSA-11 = user types comma. XSA-21 = user types carriage return.
1
1
XSA-12 . Runoff reads (grabs) XSA-22 = Runoff reads (grabs)
input file. input file.
1 1
XSA-13 .Runoff requests output XSA-23 = Runoff produces (gives)
file name. output on line printer.
1 1
1
XSA-14 User types output file name. XSA-24 = Runoff tgpes DONE.
1 1
1
FINISH
XSA-15 Runoff produces (gives)
output on output file.
1
XSA-16 . Runoff types DONE.
FINISH
</figure>
<figureCaption confidence="0.993072">
Figure A-1. XS/RO, THE RUNOFF EXECUTION SCENE.
</figureCaption>
<figure confidence="0.1879555">
A Model of Dialogue 50
Cycle 1-22 -- Proteus
</figure>
<bodyText confidence="0.999806592592593">
As a result of the numerous references to Runoff and XS/HE, the activations for
these two concepts are &amp;quot;highly active&amp;quot;. Consequently, when Proteus is called, the
concept XS/R0 (the execution scene of the Runoff process) becomes active and, duo to its
similarity to XS/HE, is taken to be equivalent to it, Since XS/R0 is more detailed (contains
more information) than XS/HE, XS/R0 is used in place if XS/HE in all of the expressions
introduced in Cycle 1-21.
Something we passed over in the earlier examples was the issue of vyhen the model
is willing to stop processing a given piece of text and go on to the next one. It seems
inappropriate to demand that the model wring all possible information and deductions out
of each utterance. Yet there must be some demands made on the assimilation. An
alternate form of the question is: what needs of his own does the hearer see the incoming
text as potentially satisfying? We have taken the position that a hearer (tentatively)
understands an utterance, when he successfully views it as serving some goal imputed to
the speaker. That is, to a first approximation, the hearer has assimilated an utterance if
he figures out why the speaker said it.
The model has already established (HCX9 and HGX10, above) that L wants to
describe kimplicitly, to 0) certain actions in XS/R0 that L expected to perceive, and in
some cases, did. Thus, in the following utterances, we see the model matching the
parsed &apos;input structure with one of these two goals, thus it is seen as being in service of a
goal of the speaker, and need be examined no further (for the time being).
In the subsequent example, we use two new rules: RS (Satisfaction) and RQ
(Quiescence). RS determines when an utterance is seen to satisfy a speaker&apos;s goal and
RQ reacts to this detected satisfaction by marking the utterance quiescent.
(Operationally, this means that in the next cycle, the Parser is called to input the next
segment of text.)
We resume the example at the point where the first segment has been marked
quiescent, and the Parser is called.
</bodyText>
<reference confidence="0.651975666666667">
Cycle 2-1 -- Parser
Results: Case9a t: 0 perceives that L. declares (I executed it).
Cycle 2-2 -- I-processor
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.7263915">Journal of Computational Linguistics GOAL-ORIENTED MODEL DIALOGUE</title>
<author confidence="0.991787333333333">James A James A William C Mann</author>
<affiliation confidence="0.999927">USC/Information Sciences Institute</affiliation>
<address confidence="0.985647">4676 Admiralty Way Marina del Rey, California 90291</address>
<note confidence="0.8630664">The re arch reported herein was supported 4fy the Florsonn( I rvi Tr ainirIE Pcc.or Programs of the Office of Naval Research, Contract N00014-75 (; 0710, uriricr Af+A Number 2930 from the Cybernttics Tethnol gy Office of the Advanced ty.e3r, h &apos;Projects Agency. if )</note>
<abstract confidence="0.956944375">Model of Dialogue SUMMARY Within a view of language users as problem solvers, speakers are seen as creating in pursuit of their own goals. Dialogue &amp;quot;works&amp;quot; because this activity tends goals both participants. Hence, for the model of dialogue comprehension here, recognition of goals the speaker is central to the comprehension of dialogue. We have found that dialogues are composed of structured interactions represented by collections of knowledge which describe the interrelated goals of the participants. We call these knowledge structures &amp;quot;Dialogue-games&amp;quot; (DG). This paper describes DGs in general, a particular one (the Helping-DG) in some detail, how DGs are used by our Dialogue-game Model (DGM), and the benefits of this model. consists of three parts: the Parameters (the two roles filled by the participants, and the topic), the Parameter Specifications (a set of predicates on the Parameters), and the Components (a sequence of goals held by the participants in the course of the dialogue). For example, in the Helping-DG, the Parameters are HELPER, HELPEE (the roles) TASK (the topic). The Specifications are: 1) The HELPEE wants to 2) the HELPEE wants to be do it but 3) the HELPEE is to. 4) The wants to HELPEE to do the TASK and 5) the HELPER is provide this help. The Components specify that 1) the HELPEE wants to establish a context by describing a collection of unexceptional events (a partial performance of the TASK): 2) he also wants to describe some sort of unoesirable surprise: then 3) the. HELPER wants to erplain the violation of expectation so that the HELPEE can avoid it ahd get on with the TASK. DGM of DGs in five stages of processing: Nomination, Recognition, Instantiation, Conduct and Termination. The DGM models each participant&apos;s knowledge, goal and attention states. A mechanism adds to the attention state, concepts &amp;quot;suggested&amp;quot; by those already in attention. When a hearer sees himself or his partner as potentially filling a role in a DG (by fulfilling one or more demands of the DG&apos;s Specifications) then that DG is brought into attention (Nominated). DGs can be nominated by weak evidence: Recognition is the step of verifying that these DGs are plausibly consistent with the current state of the model. Those which are not are eliminated from attention. A Model of Dialogue 3 OGs which survive the Recognition stago are Instantiated by asserting (as assumptions) all the Specifications not yet represented as holding. For example, when a person says &amp;quot;Do you have a match?&amp;quot;, Instantiation, by the hearer (of the Action-seek DG) assertions that the speaker does not have a match and wants hearer to him one, The Conduct of the DO is modeled by tracking the pursuit and fulfillment of the participants&apos; goals as represented in the Components. When the DGM detects that one participant no longer regards a Specification as holding, this creates an expectation of the Termination of this phase of the dialogue--there is no longer a possibility that it wall serve both participants&apos; goals. appendix contains a hand-simulation of the DGM assimilating a segment of a dialogue.</abstract>
<note confidence="0.687207342857143">A Model of Dialogue 4 CONTENTS 1, Summary 2 2. Statement of the Problem 6 3. Past Research on Language Comprehension 8 4. The Shape of the Theory 10 5. The Dialogue-game Model 11 5.1 What&apos;s in a Game? 13 5.1.1 Parameters 13 5.1.2 Parameter Specifications 13 5.1.3 Components 14 5.1.4 ridding and Accepting 14 5.2 The Helping-game, an Example 15 5.3 Dialogue-games in the Comprehension. of Dialcdtie 17 5.3.1 Processing Environment 18 5.3.2 Nomination 19 5.3.3 Recognition 20 5.3.4 Instantiation 21 A Model of Dialogue 5 5.3.5 Conduct 21 5.3.6 Termination 22 5.4 The Dialogue-game Processes 22 5.4.1 Long-term Memory (LTM) 23 5.4.2 Workspace (WS) 25 5.4..3 Parser 26 5.4.4 Proteus 26 5.4.5 Match 26 5.4.6 Deduce 28 5.4.7 Dialogue-game Manager 28 5.4.8 Pronoun Processes 29 6. Deficiencies in Current Man-machine Communication 31 7. Conclusions 33 8. References Appendix -- Simulation of the Dialogue-game Model A Model of Dialogue 6</note>
<abstract confidence="0.983279509831461">STATEMENT OF THE PROBLEM The broadest goal of our research has been to improve the sorry state of interactive man-machine communication, including its appearance of comple)dty, rigidity, lack of continuity and the difficulty it poses for many people to acquire useful levels of competence. In our pursuit of this goal, we have adopted.the following two assumptions: Assumption 1: When people communicate with machines, they do so using their already well-developed ability to communicate with other people. Assumption 2: The effectiveness of this communication is diminished by any adaptation required of the human. scientific understanding of how people thus relevant to the design of man-machine communication schemes, but such knowledge is seldom used in the design process. Since human communication skills have not been characterized at a level of detail appropriate for guiding design, interface designers have not been able to take into account some major determinants of their success. operative goal of our research was therefore to a mode/ of human an appropriate level of detail to benefit man-machine communication design. Any form of communication must be based on knowledge shared by the individuals engaged in that communication. However, the nature of this shared knoWledge and how is it used in the communicative process have not been well understood. We have developed a Working hypothesis which has deeply affected the research: Hypothesis: People know that certain kinds of goals may be pursued by communication, and they know which kinds of communication acts correspond to which goals. The use of this knowledge is essential to comprehending dialogue. In particular, a person generates an utterance to advance one or more of his own goals. Thus, to assimilate a particular utterance, it is necessary to identify why the person said it. Working with this hypothesis, we have conducted three related investigations: A Model of Dialogue. 7 1. A study of naturally occurring language to discover regularities of usage and to determine what these regularities mean to the users of the language. 2. The representation of these regularities as knowledge structures and processes in a dialogue model. 3. The establishment of standards by which the model&apos;s performance can be compared with that of humans on closely related tasks. We have adopted two additional, tactical constraints on the task: 1. We have modeled only the receptive aspects of communication. 2. We.have examined only dialogue communication, interaction in real-time, by exactly two people. These dialogues were conducted over a restricted medium so that there was no visual or intonational communication not captured the A Model of Diillogue 8 PAST RESEARCH ON LANGUAGE COMPREHENSION Most of the research jnto language comprehension has focused on the comprehension of single sentences or fragments of sentences. However some research has indicated the importance of the context created by surrounding sentences on the comprehension of an individual sentence. One specific model for the form of this multi-sentential knowledge is the &amp;quot;story schema&amp;quot;, organized within a story grammar (Rumelhart, 1975). This model has been supported by the results of story recalls (Rumelhart, 1975; Thorndyke, 1977). Other similar kinds of theoretical constructs for organizing multiple sentences of stories have been proposed called: &amp;quot;frames&amp;quot; (Minsky, 1975; Charniak, 1975), &amp;quot;scripts&amp;quot; (Schank &amp; Abelson, 1975), and &amp;quot;commonsense algorithms&amp;quot; (Rieger, 1975). To account for the conduct and comprehension of dialogues, multi-sentential knowledge units have also been proposed by linguists and sociolinguists to explain certain kinds of regularities observed in naturally occurring dialogues. These regularities have been called &amp;quot;rules&amp;quot; by Labov &amp; Fanshel (1974) and &amp;quot;sequences&amp;quot; by Sacks, Schegloff, &amp; Jefferson (1974). Once these multi-sentential knowledge units are evoked, they serve as a basis for comprehending the&apos; successive inputs. This is achieved by generating expectations and providing for integrating the comprehension of an utterance with that of its predecessors. Recently, we have proposed (Levin &amp; Moore, 1976; 1977, Mann, Moore &amp; Levin, 1977) multi-sentential knowledge units that are specified primarily by the speaker&apos;s and hearer&apos;s goals. These goal-oriented units, which we call Dialogue-games[1], specify the kinds of language interactions in which people engage, rather than the specific content of these interactions. People use language primarily to communicate with other people to achieve their own goals. The Dialogue-game multi-sentential structures were developed to represent this knowledge about language and how it can be used to achieve goals. [1J The term &amp;quot;Dialogue-71;3W was adopted by analogy from Wittgenstein&apos;s term &amp;quot;Janguap,e game&amp;quot; (Wittgenstein, 198).. However, Dialogue-games represent knowledge people ha&apos;ve dbout language as Used to pursue goals, rather than Wittgenstein&apos;s more notion. Although other are similar, the properties of are only those described here. For example, they are not necessarily competitive, ly pursued, or zero-sum. A Model of Dialogue 9 An important problem for researchers of language comprehension is posed by sentences with which the speaker performs what philosophers of language have called &amp;quot;indirect speech acts&amp;quot; (Searle, 1969). The direct comprehension of these sentences fails to derive the main communicative effect. For example, declarative sentences can be used to seek information (&amp;quot;I need to know your Social Security number.&amp;quot;); questions can be used to convey information (&amp;quot;Did you know that John and Harriet got married?&amp;quot;) or to request an action (&amp;quot;Could you pass the salt?&amp;quot;). These kinds of utterances, which have been extensively analyzed by philosophers of language (Austin, 1962; Searle, 1969, 1975; Grice, 1975), are not handled satisfactorily by any of the current theories of the direct comprehension of language. However, these indirect language usages are widespread in naturally occurring language--even two-year-old children can comprehend indirect requesis for action almost as well as direct requests (Shatz, 1975). One theory proposed to account for these indirect uses of language is based on the concept of &amp;quot;conversational postulates&amp;quot; (Grice, 1975; Gordon &amp; Lakoff, 1971). If the comprehension of an utterance is implausible, then the indirect meaning is using these postulates. Clark &amp; Lucy (1975) formalized and tested this model, and found that people&apos;s response times tend to support a three-stage model (deriving the literal check its &apos;plausibility and, if implausible, deriving &amp;quot;intended&amp;quot; meaning&amp;quot; from conversational rules). In general, this approach to indirect speech acts is infetence-based, depending on the application of conversational rules to infer the indirect meaning from the direct meaning and the context. A different approach has been proposed by Labovii Fanst)el (1974) and by Levin &amp; Moore (1976; 1977). Multi-sentential knowledge, organizing a segment of language interaction, can form the basis for deriving the indirect effect of utteronce within the segment. For example, a multi-sentential structure for an information-seeking interaction can supply the appropriate context for interpreting the utterances to and then supply information. The inference-based approach requires one set of conversational rules for information requests, a different set rules answers to requests, and a way to tie these two rule sets together. The model postulates a single knowledge for kind of interaction, processes for: (1) recognizing when this kind of interaction is proposed, (2) using this knowledge to comprehend utterances within its scope, and (3) identifying when the interaction is to be terminated. A Model of Dialogue 10 THE SHAPE OF THE THEORY Our theory of human language use has been strongly influenced by work in human problem solving (Newell &amp; Simon, 1972) in which the behavior of a human is modeled as an information. processing system, having goals to pursue and selecting actions which to these goals. We view humans as in linguistic behavior in order advance state of certain of their goals. They decide to use language, they select the other participant for a dialogue, they choose the details of linguistic expression — all with the expectation that some of their desired state specifications can thereby be realized. In this theory of language, a participant in a linguistic exchange views the other as information-processing system, with separate knowledge, goals, abilities and access to the world. A speaker has a range of potential changes he can effect in his a corresponding collection of actions which may result in each and some notion of the consequences of each of these. The speaker view the hearer as a resource information, a potential actor, or as an object to be some desired state. A dialogue involves two speakers, who alternate as hearers. In choosing to initiate or continue the exchange, a participant attempts to satisfy his own goals; in interpreting an utterance of his partner, each participant attempts to find the way in which that utterance serves the goals of his partner. Thus a dialogue continues because the continue to as furthering their own goals. Likewise, when the dialogue longer serves the goals of one of the participants, it is redirected new goals or to this mechanism of joint interaction, via exchange of utterances, in pursuit of desired Liles, is useful for achieving certain related pairs &amp;quot;of participants&apos; goals (e.g., buying/selling, getting help/giving help, ...). these paired sets of goals correspond to highly structured collections of knowledge, shared by the mcmbers of the languor° community. These collections specify such things as: 1) what characteristics an individual must have to engage in a dialogue of this sort, 2) how this dialogue is initiated, pursued and terminated, 3) what range .of information can be communicated implicitly, and 4) under what eircumstances the dialogue will &amp;quot;succeed&amp;quot; the function for it was initiated) and how this Will be exhibited in the participants&apos; behavior. attempted the.se _of knowledge and the way in which they are iried to facilitate the comprehension of a dialogue, in the Dialogue game Model. Model of Dialogue THE DIALOGUE-GAME MODEL This section describes our Dialogue-game Model at its current state of development. It starts with a brief overview of dialogue and how it is structured, then describes the dominant knowledge structures which guide the model, and finally describes a set of processes which apply theGe knowledge structures to text to comprehend it,. Within the mb.cid, each participant in a dialogue is simply pursuing his own goals of the moment. The two participants interact smoothly because the conventions of communication coordinate their goals and give them continuing reasons to speak and listen. These goals have a number of attributes which are not necessarily consequences of either human activity in general, or communication in particule, but which are nonetheless characteristic of human communication in the form of dialogue: Goals are cooperatively established. and acceptance activities serve to intfoduce goals. Goals,are mutually knokyn. party assumes or comes to know goals of the other, and each interprets the entire dialogue relative to currently known goals. Goals are conf 4Yu&apos;red by convention. of goals for use in dialogue (and other Ivguage use as well) are tacitly&apos;known and employed by all competent speaters oithe language. Goals are bilateral. dialogue partkipant assumes goals complementary to those of his partner. Goals are ubiquitous. the speaker as always having goals he is pursuing by speaking. Furthermore, the hearer recognizes and uses these goals as part of his understanding of the utterance. An uninterrupted dialogue goes through three phases: establishing goals, pursuing goals, decommitting from goals. Model of Dialogue Typically this sequence is repeated several times over the course of a few minutes. We have created knowledge structures to represent these conventions, and to apply the conventions to actual dialogues to comprehend Since the knowledge structures dominate all of the activity, they are described first. The assimilation of an utterance in the dialogue is represented in this model by a sequence of modifications of a &amp;quot;Workspace&amp;quot;[2] which represents the attention or awareness of the listening party. The modifications are roughly cyclic: 1. A new item of text T is brought into attention through the &amp;quot;Parser.&amp;quot;[2] 2. Interpretive consequences‘ of T are developed in the Workspace by a variety of processes. 3. An expressi-on E appears in the Workspace which specifies the relation between T and the imputed goals of the speaker of T. This final expression is of course a formal expression in the knowledge of the model, E represents the proposition (held by the hearer) uttering T, the speaker was performing an act in pursuit of G, a spbaker&apos;s goal known to hearer. Successful comprehension with relating text to satisfaction of speaker&apos;s goals. To make an explicit account of dialogue in this way, we now describe the knowledge structures that represent those conventions which supply the goals for the participants to pursue. In particular, we will answer the following three questions: 1. What is the knowledge we are representing within the definition of a particular Dialogue-game? 2. How is this knowledge used to model the receptive acts of dialogue Ohl eft! OOP 11.1, P. ava. saw op. or, ad am am Parser and the Work cc are parts of the process model and are in a later ecti-on. A Model of Dialogue 13 What sortof processes does it take to support this model? 3 consists of three parts: set of collection of apply to these Parameters throughout the conduct of the game, partially ordered set of the dynamic aspects of the r,amo. For the balance of this section, we will elaborate on these three parts and exemplify these with an example of the Helping-game. Parameters capture a certain collection of inforMation, common across dialogues. However, the individual participants involved and the content subjet Of the dialogue may yary freely over dialogues described by the same Dialogue-game. To represent this, each Dialogue-game has a set of Parameters which assume specific values for each particular dialogue. The dialogue types wc have represented so far as Dialague-gtmes have each required only three Parameters: the two participants involved (called &amp;quot;Roles&amp;quot;), and the subject of the dialogue (called &amp;quot;Topic&amp;quot;). Paramedter Specifications One of the major aspects distinguishing various types of dialogues is the set of goals held by the participants. Another such aspect is the set of knowledge states of the have found each type of a set of goal and knowledge states of the participants, vis-a-vis each other and the subject. Within the formalism of the Dialogue-game, these are called the Parameter Specifications, and by a collection of predicates on the Parameters. Thes.e Specifications are known to the participants of the dialogue, and the requirement that they be satisfied during the conduct of a game is used by thp participants to signal what Dialogue-games they wish to conduct, to recognize what game is being bid, to decide how to respond to a bid, to conduct the game once the bid it accepted, and to the when appropriate. These Specifications also provide the means with whichto explain the implicit, but clearly successful, communication which accompanies A Model of Dialogue 14 any natural dialogtie. Examples and discussions of these Specifications will accompany the following description of the Helping-game. Components While the Parameter Specifications represent those aspects of a dialogue type that remain constant throughout the course of a dialogue of that type, we have also found that certain aspects change in systematic ways. These are represented in Dialogue-games at Components. In the Dialogue-games we have developed so far, the Components are represented as a set of participants&apos; subgoals, partially ordered in time. Bidding and Accepting and Acceptance arc entry operations which people enter Dialogue-games. Bidding 1. identifies the gate, 2. indicates the bidder s interest in pursuing the game, 3. identifies the Parameter configuration intended. Bidding is performed many different ways, often very briefly. It is typical[y the source of a great deal of implicit communication, since a brief bid can communicate all of the Parameters and their Specifications for The Dialogue-game being bid. Acceptance is one of the typical responses to a Bid, and leads to pursuit of the game. Acceptance exhibits acknowledgment that has been made, recognition of particular Dialogue-game and Parameters bid, 3. agreement to pursue the game, 4. assumption of the Acceptor&apos;s role in the Dialogue game, is often implicit, e pecially in telotfvely informal dialogue. be by of agreement or approval, or by beginning to pursue the Ometo satisfy goals). Alter&apos;nalives to acceptance include rejecting, negotiating and ignoring. and acceptance appear to be part&amp;quot; of game .entry for all of ordinary adult dialoNe. They are also involved in game termination. In the case of termination, three alternatives are posi_able: interruption and spontaneous termination by either goal satisfaction or unconditional goal failure, Model of Dialogue Once a game has been bid and accepted, the two participants each pursue the subgoals specified for their role by the Components of this game. These subgoals are mutually complementary, each set facilitating the other. Furthermore, by the time the termination stage has been reached, pursuit of the Component-sibecified subgoals will have assured satisfaction of the higher, initial goals of the participants, for which the game was initiated in the first place. he Helping- Example this section, we exhibit a specific Dialogue-game: the is presented an informal representation, in order to emphasize the informational content, rather than the representational power of our formalism. Later in this report we will present the formal analogue of this same game. In what follows, the bold face indicates the information contained in the representation of this particular Dialogue-game, the text in regular type is explanatory commentary. The (annotated) Helping-game Parameters: HELPEE,HELPER,and TASK. HELPEE wants help from the The TASK is some sort of a problem, otherwise unspecified. Parameter S_pecifications.. HELPEE: wants to performT ASK. HE LPEE: wants to be able to performT ASK. ELPEE: not able to performT ASK. HELPEE: permitted to perform TASK. LPEE: a person. A Model of Dialogue 16 These Specifications not only constrain who would qualify as filling the role of HELPEE, but also provide reliable information about the HELPEE, given that this individual is believed to be engaged in the Helping-game. This prohibits someone from asking for help on a problem he did not want solved. Similarly, if one receives what he judges to be a sincere request for help to do some task, the helper normally as lumes that the requester has the necessary authority to do the task, if only he knew how. HELPER: wants to help HELPEE performT ASK. HELPER: able to provide help. HELPER: a person. So, in order to be a HELPER, an individual must be willing and able to provide the needed assistance. Since this Dialogue-game represents shared knowledge, the HELPER knows these Specifications, and therefore will not bid the Helping-game to someone who is not likely to meet them. And similarly, no one who. fails to meet these Specifications (and knows he fails) will for the Helping-game with as HELPER. Components of the He/pinggame.. There are three components: the first two constitute the &amp;quot;Diagnosis&amp;quot; phase to communicate what the problem is. wants HELPER to know about a set of unexceptional, actual events. The HELPEE sets up a context by describing a situation everything, so far, is going well. the HELPEE assumes that the TASK is understood by the HELPER, he also that the HELPER shares his expectations subsequent activity. A Model of Dialogue 17 2. HELPEE wants HELPER to know about: I) a set of exceptional events which occurred or 2) a set of expected, unexceptional events whic1,7 dio&apos; not occur. This pattern of a Helping-game is sufficiently well known to the participants, that the HELPEE almost never needs to actually ask a question at this point. By simply exhibiting a failure of expectation, the HELPEE has communicated that this acts as a block to his successfully pursuing the TASK. The HELPER is to explain why the failurd occurred and how HELPEE avoid it or otherwise continue in the TASK. The third component specifies the &apos;Treatment&amp;quot; phase where the HELPER communicates an explanation for the perceived failure. 3. HELPER wants HELPEE to know about an action which will avoid the undesired event or cause the desired one. The context description enables the HELPEE to identify a collection of activities which he understands, and in which the HELPEE is attempting to participate. violation-of-expectation description points out just where the HELPEE&apos;s image of the activities differs from the correct image. It from this area of difference that the HELPER selects an for the HELPEE. A Model of Dialogue 18 Dialogue games in the Comprehension of Dialogue In this section we describe the five stages of dialogue assimilation and detail the involvement of Dialogue-games with each stage: 1) nomination, 2) recognition, 3) instantiation, 4) conduct, 5) termination. Processing Environment Our description of the model should be viewed as representing the changing state of the participants, throughout the course of the dialogue. That is, are involved, one for each participant. Since the same processing occurs for both, we will describe only one. The Dialogue-Game Model consists of a Long-Term Memory (LTM), a Workspace (WS), and a sot of processes that modify the contents of WS, contingent upon the contents LTM and WS. LTM contains of the knowledge that the particular dialogue participant bl ings to the dialogue before it starts. This includes knowledge about the world, relevant objects, processes, concepts, the cognitive state of his partner in diaJogue, rules of inference and evidence, as well as linguistic knowledge (words and their semantic representation, case frames for verbs and predicates and the multi-turn language structures, the Dialogue-games). the volatile short-term memory of the model, containing all the partial and temporary results of processing. The contents of WS at any moment represent the state and focus that point. The processes are autonomous specialists, operating independently and in parallel, to modify the, entities in WS (called These are also influenced by the contents of WS, as as by knowledge in LTM. Thus, WS is the in which these concurrently operating interact each other. This anarchistic control structure resembles that the HEARSAY system (Erman, Fennel, Lesser &amp; Reddy, 1973) A Model of Dialogue 19 Nomination When dialogue participants propose a new type of interaction, they do not consistently use any single word or phrase to introduce the interaction. Thus we cannot determine which Dialogue-games represent the dialogue type through a simple invocation by name or any other pre-known collection of words or phrases. Instead the dialogue type is communicated by attempts to establish various entities as the values of the Pal meters of the desired Dialogue-game. Thus, an utterance which is as associating an entity person or a concept) with of a Dialogue-game suggests that Dialogue-game as a possibility for initiation. The Dialogue-Game Model has two ways in which these nominations of new Dialogue-games occur. One of the processes of the model is a &amp;quot;spreading activation&amp;quot; caltei&apos;d Proteus (Levin, 1976). Proteus generates new in WS on the basis of Eclations in LTM, from concepts (nodes in the semantic network) that are already in WS. Proteus brings into focus concepts somehow related to those already there. A collection of concepts in WS leads to focusing on some aspect of a particular Dialogue-game, in this sense &amp;quot;nominating&amp;quot; it as a possible new Dialogue-game. MATCH and DEDUCE are two of the model s processes which operate in conjunction to generate new activations from existing ones, by means of finding and ap.07110rule-like They operate through partial match and plausible and if they activate Parameters, then the Dialogue-game that contains those Parameters nominated a candidate Dialogue-game. Match and Deduce operate together as a kind of production system (Newell, 1973). For example, from the input utterance: &amp;quot;I tried to send a message to &lt;person&gt; at &lt;computer-site&gt; and it didn&apos;t go.&amp;quot; the following two sequences of associations and inferences result: (la) I tried to X. (2a) I wanted to X. want to X. (4a) HELPEE wants to do TASK. go. (2b)What I tried to do dirin&apos;t work. (3b) X didn&apos;t work. (4b) I can&apos;t X. (5b) I don&apos;t know 115 to X. (GE) HELPEEldp6sn&apos;t know how to do TASK. A Model of Dialogue 20 (Where: I = HELPEE and X = do TASK = send a message to &lt;person&gt; at &lt;computer-site&gt;.) At this point, (4a) and (6b), since they are both Parameter Specifications for the Helping-game, cause the model to focus on this Dialogue-game, in effect nominating it as an organizing structure for the dialogue being initiated. Recognition The processes described so far are reasonably unselective and may activate a number of possible Dialogue-games, some of which may be mutually incompatible or otherwise inappropriate. The Dialogue-game Manager investigates each of the nominated Dialogue-games, verifying inferences based on the Parameter Specifications, and eliminating t those Dialogue-games for which one or more Specifications are contradicted. A second mechanism (part of Proteus) identifies those activations which are and accumulating evidence in support of a decision to accept one and delete the rest from the WS. example, suppose question &amp;quot;How do I get RUNOFF to work?&amp;quot; leads to the nomination of two games: Info-seek-game (person asking question wants to know answer) and Info-probe-game (person asking question wants to know if other knows answer) These two Dialogue -games have a lot, in common hut differ in one crucial aspect: In the the questioner does know the the question, while in the he These two predicates represented in the Parameter of the two Dialogue-games, and their joint nomination are discovered contradictory. Proteus represents this discovery a structure which has the of eliminating the conflicting Dialogue-game with the least supporting Such support might be, for example, either the knowledge that the speaker is the hearer&apos;s or that he is (which would lend support for the choice of the Info-probe-game or Info-seek-game, respectively). Model oh Dialogue Through these processes, the number of candidate Dialogue-games is reduced until those remaining are compatible with each other and with the knowledge currently in WS and in LTM. Instantiation Dialogue-game has successfully survived the filtering procestses described above, it is then instantiated by the Dialogue-game Manager. Those Parameter Specifications not previously known (represented in the WS) are established as newly inferred knowledge about the Parameters. A large part of the implicit communication bttween dialogue participants is modeled through Instantiation. To illustrate this, suppose that the following come to be represented in WS (i.e., known) in the course of assimilating an utterance: SPEAKER does not know how to do a TASK. SPEAKER wants to know how to do that TASK. SPEAKER wants to do the TASK. These are adequate to nominate the Helping-game. In the process of instantiating this Dialogue-game, the following predicates are added to WS: SPEAKER believes HEARER knows how to do TASK. SPEAKER believes HEARER is able to tell him how to do TASK. SPEAKER believes HEARER is willing to tell him how to do TASK. SPEAKER wants HEARER to tell him how to do TASK. SPEAKER expects HEARER to tell him how to do TASK. model predicts that predicates will be implicitly communicated by an utterance which succeeds in instantiating the Helping-game. This corresponds to a in which can&apos;t get this thing to work&amp;quot; is taken to the &amp;quot;get this thing to work&amp;quot; (even ,though, on the surface, it only simple declarative of the speaker&apos;s ability). Conduct a Dialogue-game is instantiated, the Dialogue-game Manager is guided by Components in comprehending the ret of the dialogue. These Components are goals for A Model of Dialogue 22 the dialogue participants. For the speaker, these goals guide what he is next to say; for the hearer, these provide expectations for the functions to be served by the speaker s subsequent utterances. These &amp;quot;tactical&amp;quot; goals are central to our theory crf language; an utterance is not deemed to be comprehended until some direct consequence of it is seen as serving a goal imputed to the speaker Furthermore, although the goals of the Components are active only within the conduct of a particular game, their pursuit leads to the satisfaction of the goals described in the Parameter Specifidations, which were held by the participants prior to the evocation of the Dialogue-game. In the case of the Helping-game, the goals in the &amp;quot;diagnostic&amp;quot; phase are that the HELPEE describe a sequence of related, unexceptional events leading up to a failure of his expectations. These goals model the state al thC HELPER as he assimilates this initial part of the dialogue, both in that he knows how the HD:PEE is attempting to describe his problem, and also that the HELPER knows when this phase is past, and the time has come (the &amp;quot;treatment&amp;quot; phase) for him to provide the help which has been implicitly requested. Termination The processes described above perform the identification and pursuit of Dialogue-games. How, then, are DGs terminated? The Parameter Specifications represent those aspects of dialogues that are constant over that particular type of dialogue. The Dialogue-Game Model pushes this a step further in specifying that the continues only as long as the Parameter Specifications continue to Whenever any predicate in the Specification ceases to hold, then the model predicts the impending termination of this Dialogue-game. example, if the lif:LPES longer wants to perform the TASK (either by it abandoning that goal), indicates this with utterAnco for termination. The Wiping game then tPrrnmates; this to termination of the helping interaction. If HELPER becomes unwilling to help, discovers that he is unable, then the Helping-game also terminates. Again, .have one simple rule tht covcrs di4crsity for termination the of that the•dialogues we studied end. A Model of Dialogue 23 The Dialoguegame Processes In this section we describe the major process elements of the Dialogue-Game Model. All the major parts and their connectivity are shown in Figure 1. These parts (two memories and six Processes) will each be described separately. The appendix contains an extensive, detailed trace of the model as it analyzes (via hand simulation) a naturally occurring dialogue fragment. Finally, we will summarize our experience with the model to date. Long-term Memory (LTM) The Long-Term Memory is the model&apos;s representation of a participant&apos;s knowledge of the external World. It contains the initial knowledge states of the participants: the grammatical case frames, the semantic structures for word-senses, the knowledge of the subject matter of the dialogue, the various ways in which dialogues are structured, etc. LTM is a semantic network, containing a set of nodes (also called concepts) and the relations that hold between them at the lowest level. This information is stored in the form of triples: &lt;node-1 relation node-2&gt; have machinery encoded and working--a full complement of read and write for this representation. However, it proven awkward for us specify at this level, so we have further machinery (named SIM) to translate n-ary predicates into these triples. Thus, far a predicate, P, having arguments Al, A2, and A3, SIM can be given the input: Beta Gamma) [mearling that P1 is defined to be an instance of P (the predicate always goes insec-ond with arguments Alpha for Beta for A2 and Gamma-or A3.} resulting triples are created: &lt;P1 PRED P&gt; Al &lt;P1 A2 BETA&gt; &lt;P1 A3 GAMMA&gt; examine a more example; suppose want to include in the LTM that: Figure 1. The Dialogue-game Model Dialogue text A Model of Dialogue 24 A Model of Dialogue 25 Mary hit John with a rock. The predicate &amp;quot;HIT&amp;quot; has two mandatory arguments (subject, object) and an optional one (instrument). The SIM representation of this.assertion (which we shall. name Q1) is Q1:(MARY HIT JOHN ROCK) which translates into the following triples: &lt;Q1 PRED HIT&gt; &lt;Q1 SUBJ MARY&gt; &lt;Q1 OBJ JOHN&gt; &lt;Q1 INST ROCK&gt; Workspace (WS) The Workspace is the model&apos;s representation for that information which the participant is actively using. This memory corresponds roughly to a model of the participant&apos;s focus of attention. the LTM is static during the operation of the model (we are to simulate levning), the WS is extremely volatile, with elements (activations) coming into and out of focus continuously. All incoming sensations (i.e., utterances) appear in the WS, as do all augmentations of the participant&apos;s knowledge and goal state. The representational format of the WS is the satire as in LTM. Each node in the WS is &apos;a token (copy) of some node in LTM. Whenever some process determines that the model&apos;s attenlion (WS) should include a token of a specific node (C) from LTM, a new node (A) is by copying C and this new node is added to the WS. A is referred to as -aivActbtation_01)is.s1or &lt;A IAO C&gt; This representation provides the associative links between an object in attention, and the body of knowledge assOciated with it, but not yet brough.t into attention. A Model of Dialogue 26 Parser This module produces activations representing each successive utterance to be processed. These representations are generated from the surface string using a standard ATN Grammar similar to those developed by Woods (19701 and Norman, Rumelhart, &amp; the LNR Research Group (1975). We use a case graMmar representation, with each utterance specified as a main predicate with a set of parameters. Because this module is a conventional parser whose implementation is well understood, we have so far produced hand parses of the input utterances, following an ATN grammar. Proteus This is a spreading activation mechanism, which modifies the activation of concepts specified as related in LTM whenever a given concept becomes active. This mechanism provides a way to integrate top-down and bottom-up processing within a uniform framework (Levin, 1976). The Dialogue-Game i4odel uses Proteus to activate a concept, given tha a number of closely related concepts (Components, features, instances, etc.) are active. Proteus operates on all currozt activations to modify their &amp;quot;salience&amp;quot;, a number associated with each activation that generally represents the importance or relevance of concept. Two kinds of influence relations can exist between concepts: an exists, then Proteus increases the salience of activation of that concept in proportion to the salience of the influencing concept. The the salience of an activation, the larger its influence on directly concepts. an is specified, then Process decreases the salience of the activation of the neighboring concept. Match This Process identifies concepts in LTM that are congruent to existing activations. The Dialogue-Game Model contains a number of equivalence-like relations, which Match identify a concept in LTM as representing the same thing as an activation of some Once concept is found, it is on how this concept is in LTM, its may have effects on other processes (for example, if the concept is part of a rule, Deduce may be invoked). viewed as an attempt to find an activation (A) in WS and a Concept (C) in LTM which correspond, according. to some -et of criter The basic tactic is to attempt A Model of Dialogue 27 to find a form 0 equivalence relationship between A and C, without delving into their structure at alt. Only if this f ails are their respective substructures examined. In this second case, the same match which was atlempted, at the top level is tried between corresponding subparts of A and C. Match proceeds in five steps: 1. Is it already known that A is an activation of C? If so, the mateh terminates with a positive conclusion. 2. Is there any other activation (A&apos;). and/or concept (C&apos;) such that A&apos;is known be a yiew of A, C is known to be a kind of C&apos;, and A&apos; is known (by step be an activation of C&apos;? The relations is a view of ...) and (... is a kind of represent stored relations between pairs of activations and concepts, respectively. One concept &amp;quot;is a kind of&amp;quot; another concept rep, soperclass inclusion, true&apos; for all time and &apos;contexts. (Whatever else he migh4 be, John is a kind&apos;of human being.) On the other hand, one activation may be &amp;quot;a vievv of&amp;quot; another only under certain circumstances--a conditional, or tactical relationship. Under differentconditions, it is appropriate to view John as a Father, Help-seeker, Advice,.giver, etc, A list of matched pairs of activations represent correspondences found elsewhere, with which match must be consistent. (N.B.: this Match, as we Will see later, may be in service of another Match called&apos; on structures containing the current A and C.) If the pair [A,C] is a pair, then these tvyo have been previously found to we may here conctude, the same thing and Match exits. On the other hand, if there is either an X or a Y such that (or [Y,C]) is a matched pair, then replace this match with an attempt to match C and X (or A and Y). Finally, if the match•has succeeded nor failed by this point, then is called recursivdy on all corresponding subparts of a&apos;nd C, That is, e.g., if A and have only three subparts in (say, 0I3J and PRED) thori Match((SUBJ of A),(SUBJ of C)), A),(OBJ of C)) and Match((PRED of A),(MED of C)) arc attempted. Only if all of these subordinate matches succeed is the top-level Match void to succeed. Clearly, for structures of significant compleXity, Match may eventually call itself recursively, to an arbitrary depth. However, since each subordinate call is on a strictly smaller unit, this process must coriverge. A Model of Dialogue 28 Our experience has shown us that this type of mechanism plus a collection of rewrite rules enable us to eventually map a wide variety of input parsing structures to pre-stored, abstract knowledge structures, in a way that a significant aspect of their intended meaning has been assimilated in the process. Deduce This operates to carry out a rule when that rule has become active. Rules are of the form (Condition)-&gt;(Action), and Deduce senses the activity of a rule and applies the rule by activating the concept for the action. Whatever corresponoences were evolved in the course.of creating the activation of the condition (left) half of The rule are carried over into the activation of the action (right) half. The combination of Match and Deduce gives us the capability of a production system. The operation of Deduce is relatively simple. It is called only when a rule is active in the WS. Deduce attempts to match the left half of this rule with some other actNati on in the WS. (This has typically already been done by match.) Assuming this is accomplished, Deduce creates an activation of the right half of the rule, substituting in the activation for all subparts for which there are correspondences with the left half. Dialogue-game Manager been activated (by Proteus) as possibly the communication form being bid for a dialogue, the Dialogue-game Manager uses it to guide the assimilation of successive utteraices of the dialogue, through four stages: 1. establish the Parameter values and verify that no Specification is contradicted, 2. establish otherwise unsupported Specifications as assumptions, establish the Components as goals of the detect circumstances which indicate that the Ualop,ue-game is terminating and represent the consequences of this. The first two of these phases happen in parallel. When the Manager accesses each of the Parameters, they are found either to have activations in the WS or not. If they do, the correspondences between activation, and Parameter are established in the WS. This corresponds to assigning a value to the Parameter for this particular evocation of the Dialogue-game. Any Parameter that ha no activation is put on a list which is A Model of Dialogue 29 checked in the hope that later activity Manager will lead to the creation of appropriate activations. For each of the Specifications, a check is made to determine if it already has an activation in WS. (In most cases, the activation of some of these Specifications will have led to the activity of the Dialogue-game itself.) The Specifications having activations need no further attention. all remaining Specifications, activations are created for the as determined above. At this stage, the Manager calls determine the stability of these new activations. Any new activation which contradicts existing activations will have its level of activity sharply reduced by Proteus. If this happens, the Dialogue-game Manager concludes that some of the necessary preconditions for the game do not hold (are in conflict with current understanding) and that this particular game should be abandoned. Otherwise, the new activaticns stand as new knowledge, following from the hypothesis that the chosen game is appropriate. The Dialogue-game has now been successfully entered; the Manager sets up the third phase, creating activations of the Dialogue-game&apos;s Components, with appropriate (By this time, any unresolved Parameters may well have permitting their resolution.) This sets up all of the game-specific knowledge and goals for both participants. Finally, the Manager detects that one of the Specifications no longer appears to hold. This signals the impending termination of the Dialogue-game. In fact, the contains this information is a bid to terminate. At this point, if the participants&apos; initial goals are satisfied (thus contradicting the Specification which Calls for the presence of those goals) the interaction ends &amp;quot;successfully&amp;quot;. Otherwise, the Dialogue-game is terminated for some other reason (e.g., one participant&apos;s unwillingness inability to continue) and would generally be regarded as These consequences are inferred by the Manager and added to the WS. When a Dialogue-game has terminated, its salience goes to zero and it is removed from the WS. Pronoun Processes The Dialogue-Game Model contains a set of Pronoun Processes, including an I-Process, a You-Process, and an It-Process. Each of these is invoked whenever the associated surface word appears in an input utterance, and operates to identify some activation that can as a view of the same object. of Dialogue 30 Each of these Processes search th&apos;e current context, as represented by the current set of activations in the WS, using the features specified there to identify a set of possible expressions. When is than one possibility, the one with a higher salience is selected. A Model of Dialogue 31 DEFICIENCIES IN CURRENT MAN-MACHINE COMMUNICATION With the understanding we new have of the multi-sentential aspects of human communication, it is easy to see why man-machine communicttion appears so alien, highly uncomprehending and awkward. This is because regulation and inter prettdion structures are missing. In Table 1, we compare human dialogue and typical man-machine communication with respect to some of these features. The table designates a &amp;quot;sender and a &amp;quot;receiver&amp;quot; which should be identified with the person and the computer, respectively, in the man-machine communication case.</abstract>
<affiliation confidence="0.63935725">OF NATURAL COMMUNICATION HUMAN MAN- ADDRESSED BY DIALOGUE-GAME THEORY . DIALOGUE MACHINE SENDER&apos;S GOALS KNOWN TO RECIPIENT YES NO PARTICIPANTS CAN DECLARE THEIR GOALS YES NO GOALS PERSIST OVER SEVERAL MESSAGES YES NO GOALS IDENTIFIED WITH EACH MESSAGE YES NO COMMUNICATION PLANS USED YES LITTLE IMPLICIT COMMUNICATION TAKES PLACE YES LITTLE</affiliation>
<abstract confidence="0.995721146341464">Table 1: omparison of man-man and man-machine communication Conventional man-machine communication frequently gives the user a sense that the computer is operating &amp;quot;out of context&amp;quot;, since he must continually respecify what is relevant to the ongoing dialogue. In human communication it is the shared awareness of each other&apos;s goal structures which permits them to retain and focus,on what is relevant. Man-machine communication seems aimless and undirected because no analogous body of knowledge is being used to facilitate and interpret the communication. A Model of Dialogue 32 The ideal interface, and the sort toward which this research is direcied, would be continuously asking itself: &amp;quot;Why did he say that?&amp;quot;. From answers to this, the interface would infer just what the human was expecting as a response. This would constitute a major step toward the enabling the. interface to serve the actual (rather than the poorly expressed) needs of the user. Finally, such an interface would require much less adaptation on the part of the user, and so, by our original hypothesis, would significantly enhance the effectiveness of the man-machine partnership. A Model of Dialogue 33 CONCLUSIONS This paper has described a research effort into the modeling of human dialogue. The purpose of this research has been to uncover and describe in process models, that occur in It is hoped that the enhanced understanding of human communication which results, will facilitate the development of more natural (and thus more effective) man-machine interfates. The principal regularity We have discovered is a collection of knowledge and goal structures, called Dialogue-games, which seem to be crucial in understanding the structure of naturally-occurring dialogues. According to the theory we have proposed, one or more of these Dialogue-games serve as the major organizing influence on every human dialogue. Each Dialogue-game specifies what knowledge each person must have to ehgage in such a dialogue, and what goals of the participants might be served by that interchange. A Dialogue-game also specifies, as a sequence of &amp;quot;tactical&amp;quot; goals, the manner in which the dialogue is conducted. The Dialogue-game Model is a collection of cooperative processes which continuously updated a representation of each participant&apos;s attention state in a Workspace. The model recognizes when a particular Dialogue-game is being bid, accepted, pursued and terminated, and represents these states appropriately in the Workspace. A particular Dialogue-game, the Helping-game, was described in some detail. A simulation of the evocation and use of the Helping-game on a segment of natural dialogue is contained in the Appendix. Our experience so far with the Dialogue-game Model has reinforced our hypotheses that an understanding of the goal-serving aspects of dialogue is a powerftil tool in understanding the individual dialogues.</abstract>
<note confidence="0.909804647058823">A Model of Dialogue 34 REFERENCES J. L. do things with words. MA: Harvard University Press, 1962. R. F. process ana/ysis MA: Addison-Wesley, 1952. Charniak, E. Organization and inference in a frame-like system of common sense In R. Schank &amp; B. L. Nash-Webber (Eds.), issues in language processing. MA: Bolt, Beranek and Inc., 1975. Clark, H. H., &amp; Lucy, P. Understanding what is meant from what is said: A study in conveyed requests. of Verbal Learning and Verbal Erman, L. D, Fennell, R. D., Lesser, V. R., -&amp; Reddy, D. R. System organizations for understanding. of the Third International Joint on Artificial Intelligence. Alto, CA: Stanford University, 1973. D., &amp; Lakoff, G. Conversational postulates. from the Seventh Meeting, Linguistic Society, 1971. H. P. Logic and conversation. In P. Cole &amp; J. L. Morgan (Eds.), and York: Academic Press, 1975. W., &amp; Fanshel, D. discourse. Psychotherapy as copy, 1974. Levin, J. A. Proteus: An activation framework for cognitive process models. Unpublished doctoral dissertation, San Diego, CA: Univ. of Calif, San Diego, 1976. J. A., &amp; Moore, J. A. A model of natural of the A/S8 Summer Conference. Scotland, July 1976. J. A., &amp; Moore, J. A. Dialogue Meta-communication Structures for Natural Language Interaction (ISI/RR-77-53). Marina del Rey, CA: Information Institute, 1977. Also in press, Sciences, 4 ) A Model of Dialogue 35 Mann, W. C. Why things are so bad for the computer-naive user (ISI/RR-75-32). Marina del Rey, CA: Information Sciences Institute, 1975. Mann, W. C., Moore, J. A., &amp; Levin, J. A. A comprehension model for human of the Fifth International Join&apos;t Conference on Intelli gence. MA:.MIT, 1977, forthcoming. M. A framework for representing knowledge. In P. H. Winston (Ed.), of computer vision. York: McGraw-Hill, 1975. Newell, A. Production systems: Models of control structures. In W. G. Chase (Ed.), information processing. York: Academic Press, 1973. A., &amp; Simon, H. A. problem solvtiig. Cliffs, NJ: Prentice-Hall, 1972. D. A., Rumelhart, D E. &amp; the LNR Research Group. in Francisco: W. H. Freeman, 1975. Rieger, C. The commonsense algorithm as a basis for computer models of human memory, inference, belief and contextual language comprehension. In R. Schank L. Nash-Webber (Eds.), issues in natural language MA: Bolt, Beranek and Newman, Inc., 1975. Rumelhart, D. E. Notes on a schema for stories. In D. G. Bobrow &amp; A. Collins and understanding: Studies in cognitive science. New York: Academic Press, 1975. Sacks, H., Schegloff, E. A., &amp; Jefferson, G. A simplest systematics for the organization turn-taking for conversation. Schank, R. C., &amp; Abelson, R. P. Scripts, plans and knowledge. Paper presented at Fourth International Joint Artificial Intelligence, Tbilisi, USSR, August 1975. J. R. acts: An essay in the philosophy of langdage. England: Cambridge University Press, 1969. J. R. Indirect speech acts. In P. Cole &amp; J. L. Morgan (Eds.), and York: Academic Press, 1975. A Model of Dialogue 36 Shatz, M. How young children respond to language: Procedures for answering. and Reports on Child language Development, Alto, CA: Stanford University, 1975. Thorndyke, P. W. Cognitive structures in comprehension and memory of &apos;narrative P.tychology, .9,77-110. L. inve.tigaf ions ed.). New York: Macmillan, 1958.</note>
<abstract confidence="0.961716708074534">Woods, W. A. Transition network grammars for natural language analysis. of the ACM, A Model of Dialogue APPENDIX -- SIMULATION OF THE DIALOGUE-GAMES MODEL Example of theDialogue Model in Action In this appendix we describe an extensive simulation of the current state of the Dialogue-game Model. We make use of a particular version of the Helpin-game and alsc explore another structure, an Execution Scene, which describes the customary events surrounding the successful execution of a particular program (Runoff). We start by describing this more detailed version of the Helping-game, introducing names for the various aspects, to be used later. Next we show a short, naturally occurring dialogue between a computer operator and a user. Then we describe the operation of the Dialogue-game Model as it assimilates this dialogue, up to the point at which it concludes that the Herping-game is an appropriate structure through which to understand the subsequent utterances. Once this hypothesis for the form of the dialogue has been chosen, we continue the simulation to examine how othe model decides that a particular Execution Scene is appropriate for assimilating the content of the dialogue. Next, we see how this choice of scenes enhances the set of goals imputed to the speaker, thus facilitating the comprehension of what he is saying. Finally, we summarize our experience with the Dialogue-game Model so far. A Detailed&apos; Structure far the He/ping game What follows is the substance of the communication structure we have named the Helping-game. In the interests of clarity of presentation, the formal structures of the definition have been expressed in prose. However, the elements of the following correspond one-to-one to those in the actual Helping-game in &apos;the simulation. HELPING-GAME Parameters: The parameters are two roles (HELPER and HELPEE) and a topic (TASK/HG). A Model of Dialogue 38 Parameter specifications: The HELPER and HELPEE are each a kind of person. HI = A goal of the HELPEE is that he perform TASK/HG. H2 = It is not true that HELPEE is able to perform this TASK/HG. H5 = The HELPEE wants to be able to perform the TASK/HG. (being able to perform the task is a subgoal of performing the task) = The able to enable the HELPEE to perform the TASK/HG. H8 = The HELPER is willing (= is able to want to ...) to enable the HELPEE to perform the TASK/HG. H10 = The HELPEE is permitted to perform the TASK/HG. HII = The HELPEE wants the HELPER to enable him to perform the TASK/HG. (being enabled to perform the taskis&apos;a subgoal of performing the task) Game components: HGX1 = The HELPEE knows of a particular execution scene, XS/HE. [note: an execution scene is a flowchart-like description of the use of a particular process; more details below] HGX2 = The HELPEE knows that his perceiving the terminal state of XS/HE would satisfy his wanting to perform TASK/HG. HGX2C= (Thus) The HELPEE wants to perceive XS/HE in this terminal state. (this perception is a subgoal of performing the TASK/HG) ACTION/GOOD = an ACTION of XS/HE which was realized in the past. HGX3 = The HELPEE knows he has perceived this ACTION/GOOD. HGX4 = The HELPEE knows he had expected to perceive it. HGX5 = The HELPEE knows he wants to perceive this ACTION/GOOD. (perceiving the ACTION/GOOD is a subgoal of perceiving the rdesiredlterminal state of the XS/HE) = an ACTION of XS/HE which was not realized in the HGX6 = The HELPEE knows that he did not perceive ACTION/BAD. 1-1GX7 = The HELPEE knows that he had expected to perceive it. HGX8 = The HELPE wants to perceive ACTION/BAD. (perceiving the ACTION/BAD is a subgoal to perceiving the terminal state of XS/HE.) HGX9 The HELPEE wants to describe what happened which was expected and wanted, the ACTION[s]/GOOD. (describing these ACTION[s]/GOOD is a subgoal of having the HELPER enable the HELPEE to perform the TASK/HG.) HGX10= The HELPEE wants to describe what did not happen that he A Model of Dialogue 39 expected, and wanted, the ACTION[s]/BAD. (describing these ACTION[s]/BAD is a subgoal of having the HELPER enable the HELPEE to perform the TASK/FIG.) The Dialogue to be Modeled What follows is a transcript of a naturally occurring dialogue between a computer operator (identified as &amp;quot;0&amp;quot;) and a user (&amp;quot;L&amp;quot;) who has &amp;quot;linked&amp;quot; to the operator, in an attempt to solve a problem. There has been virtually no &amp;quot;cleanup&amp;quot; of this transcript, except to remove extraneous typing that had appeared on the operator&apos;s console listing as a result of the operating system printing routine status messages. The choice of words, and even spelling, are exactly as typed by the participants. (We have segmented the text by interposing carriage-returns as we deemed appropriate.) Dialogue 0C117 FROM 42 L: How do I get runoff to work, I keep xeqtn it but it just grabs my input file and then says done but gives me no output? GA 0: The output comes out on the line printer Throw it away but can I get it to go to a file? GA 0: Confirm your commands with a comma and you&apos;ll be queried for files, etc. GA A Model of Dialogue 40 L: Thanx mucho BREAK The subsequent simulation is of the model processing the first five segments, the first Each utterance is ingested one a by the Parser, and the assimilation proceeds until a quiescent state is reached (much more detail, below) segment is parsed and input for processing. The identification of the Helping-game How does the model know to evoke the Helping-game? To exhibit answers to this and subsequent questions, we lead the reader through a simulation of the mod&amp; as it processes the beginning of dialogue 0C117. We indulge in the same use of prose for formalism as aboi/e, again with the same assurances of correspondences with the actual simulati on. proceeds in cycles; in each cycle, we exhibit the operation of a single processor, performing one iteration of its function. We do not address here the is how the model would select which processor to call ln fact, our design calls for these processors to be maximally autonomous and parallel in their operation, whenever circumstances are ripe for their function and dormant The format of this simulation is as follows: The cycle number is first, in the form: segment number)---cycle number in this segment?. Next is the name of the processor operating in this cycle. After that is a description of the nature of the processing done cycle. there is a list of the results for this cycle, that is, ll important changes in WS. Initially, the description is at a very detailed level. But after a while, the beconle repetitive description less only on the unique aspects of the current In this each processor is called at least once in the processing of each segment; Match, Deduce and bear the major burden, having several invocations each of Dialogue 41 Cycle 1-1 — Parse. The parser reads one utterance/segment of input and translates it into the formalism for activations in the workspace. No claim is made that this translation retains all the content of the original text, only that it is adequately faithful to the level of detail we are simulating. Case/9 (= (0 perceives that L asks (how get Runoff working?))) is activated. Cycle 1-2 — 1-processor Certain words (e.g. pronouns, determiners) are taken to be signals that a reference is being made to concepts introduced elsewhere. The presence of a concept in the workspace corresponding to one of these words leads to the calling of the. process-specialist which attempts to resolve the implied reference. Thus, the presence of &amp;quot;I&amp;quot; in the text leads to the calling of the I-process, whose sole function is to determine the referent of the &amp;quot;I&amp;quot; and modify the stored concept to reflect this. This process judges that if L is asking a question which contains &amp;quot;I&amp;quot; as its subject, then this constitutes evidence to hypothesize that being used to refer to L. Results: 0 perceives that L asks (how does L get Runoff working?) Cycle 1-3 — Match always on the lookout for pairs of nodes, one in the WS and the other in the LTM, such that the activation (node in WS) matches the concept (node in LTM). This is taken to be evidence that the activation is also to be taken as an activation of the matched concept. It should be understood that we are-examining only some of the succeswful matches which occurred. Starting in this cycle, we see a pattern which recurs regularly, and which accounts fcr a significant piece of the action, as the model assimilates the dialogue. Match determines that a particular activation matches the left half (condition side, if part, etc.) of a production-like rule stored in LTM. This successful match leads to the identification of the correspondences between the aspects of the activation and those of the lefthalf of the rule, as well as creating an activation of the rule itself. The activation of a rule leads to calling the Deduce processor in the-next cycle, which applies the activated rule to the node in the WS responsible for the rule&apos;s activation. This application of a rule (which also results in the removal of the rule&apos;s activation from the WS) creates a new activation structure in the WS.</abstract>
<intro confidence="0.553352">A Model of Dialogue 42</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J L Austin</author>
</authors>
<title>How to do things with words.</title>
<date>1962</date>
<publisher>Harvard University Press,</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="10687" citStr="Austin, 1962" startWordPosition="1664" endWordPosition="1665"> comprehension is posed by sentences with which the speaker performs what philosophers of language have called &amp;quot;indirect speech acts&amp;quot; (Searle, 1969). The direct comprehension of these sentences fails to derive the main communicative effect. For example, declarative sentences can be used to seek information (&amp;quot;I need to know your Social Security number.&amp;quot;); questions can be used to convey information (&amp;quot;Did you know that John and Harriet got married?&amp;quot;) or to request an action (&amp;quot;Could you pass the salt?&amp;quot;). These kinds of utterances, which have been extensively analyzed by philosophers of language (Austin, 1962; Searle, 1969, 1975; Grice, 1975), are not handled satisfactorily by any of the current theories of the direct comprehension of language. However, these indirect language usages are widespread in naturally occurring language--even two-year-old children can comprehend indirect requesis for action almost as well as direct requests (Shatz, 1975). One theory proposed to account for these indirect uses of language is based on the concept of &amp;quot;conversational postulates&amp;quot; (Grice, 1975; Gordon &amp; Lakoff, 1971). If the direct comprehension of an utterance is implausible, then the indirect meaning is deri</context>
</contexts>
<marker>Austin, 1962</marker>
<rawString>Austin, J. L. How to do things with words. Cambridge, MA: Harvard University Press, 1962.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R F Bales</author>
</authors>
<title>Interactive process ana/ysis</title>
<date>1952</date>
<publisher>Addison-Wesley,</publisher>
<location>Cambridge, MA:</location>
<marker>Bales, 1952</marker>
<rawString>Bales, R. F. Interactive process ana/ysis Cambridge, MA: Addison-Wesley, 1952.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
</authors>
<title>Organization and inference in a frame-like system of common sense knowledge. In</title>
<date>1975</date>
<location>Cambridge, MA:</location>
<contexts>
<context position="8241" citStr="Charniak, 1975" startWordPosition="1311" endWordPosition="1312">ed on the comprehension of single sentences or fragments of sentences. However some research has indicated the importance of the context created by surrounding sentences on the comprehension of an individual sentence. One specific model for the form of this multi-sentential knowledge is the &amp;quot;story schema&amp;quot;, organized within a story grammar (Rumelhart, 1975). This model has been supported by the results of story recalls (Rumelhart, 1975; Thorndyke, 1977). Other similar kinds of theoretical constructs for organizing multiple sentences of stories have been proposed called: &amp;quot;frames&amp;quot; (Minsky, 1975; Charniak, 1975), &amp;quot;scripts&amp;quot; (Schank &amp; Abelson, 1975), and &amp;quot;commonsense algorithms&amp;quot; (Rieger, 1975). To account for the conduct and comprehension of dialogues, multi-sentential knowledge units have also been proposed by linguists and sociolinguists to explain certain kinds of regularities observed in naturally occurring dialogues. These regularities have been called &amp;quot;rules&amp;quot; by Labov &amp; Fanshel (1974) and &amp;quot;sequences&amp;quot; by Sacks, Schegloff, &amp; Jefferson (1974). Once these multi-sentential knowledge units are evoked, they serve as a basis for comprehending the&apos; successive inputs. This is achieved by generating expecta</context>
</contexts>
<marker>Charniak, 1975</marker>
<rawString>Charniak, E. Organization and inference in a frame-like system of common sense knowledge. In R. Schank &amp; B. L. Nash-Webber (Eds.), Theoretical issues in natural language processing. Cambridge, MA: Bolt, Beranek and Newman, Inc., 1975.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H H Clark</author>
<author>P Lucy</author>
</authors>
<title>Understanding what is meant from what is said: A study in conversationally conveyed requests.</title>
<journal>Journal of Verbal Learning and Verbal Behavior,</journal>
<volume>1975</volume>
<pages>56--72</pages>
<marker>Clark, Lucy, </marker>
<rawString>Clark, H. H., &amp; Lucy, P. Understanding what is meant from what is said: A study in conversationally conveyed requests. Journal of Verbal Learning and Verbal Behavior, 1975,14, 56-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L D Erman</author>
<author>R D Fennell</author>
<author>V R Lesser</author>
<author>-&amp; Reddy</author>
<author>D R</author>
</authors>
<title>System organizations for speech understanding.</title>
<date>1973</date>
<booktitle>Proceedings of the Third International Joint Conference on Artificial Intelligence.</booktitle>
<institution>Stanford University,</institution>
<location>Palo Alto, CA:</location>
<marker>Erman, Fennell, Lesser, Reddy, R, 1973</marker>
<rawString>Erman, L. D, Fennell, R. D., Lesser, V. R., -&amp; Reddy, D. R. System organizations for speech understanding. Proceedings of the Third International Joint Conference on Artificial Intelligence. Palo Alto, CA: Stanford University, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Gordon</author>
<author>G Lakoff</author>
</authors>
<title>Conversational postulates. Papers from the Seventh Regional Meeting, Chicago Linguistic Society,</title>
<date>1971</date>
<contexts>
<context position="11192" citStr="Gordon &amp; Lakoff, 1971" startWordPosition="1735" endWordPosition="1738">he salt?&amp;quot;). These kinds of utterances, which have been extensively analyzed by philosophers of language (Austin, 1962; Searle, 1969, 1975; Grice, 1975), are not handled satisfactorily by any of the current theories of the direct comprehension of language. However, these indirect language usages are widespread in naturally occurring language--even two-year-old children can comprehend indirect requesis for action almost as well as direct requests (Shatz, 1975). One theory proposed to account for these indirect uses of language is based on the concept of &amp;quot;conversational postulates&amp;quot; (Grice, 1975; Gordon &amp; Lakoff, 1971). If the direct comprehension of an utterance is implausible, then the indirect meaning is derived using these postulates. Clark &amp; Lucy (1975) formalized and tested this model, and found that people&apos;s response times tend to support a three-stage model (deriving the literal meaning, check its &apos;plausibility and, if implausible, deriving the &amp;quot;intended&amp;quot; meaning&amp;quot; from conversational rules). In general, this approach to indirect speech acts is infetence-based, depending on the application of conversational rules to infer the indirect meaning from the direct meaning and the context. A different appro</context>
</contexts>
<marker>Gordon, Lakoff, 1971</marker>
<rawString>Gordon, D., &amp; Lakoff, G. Conversational postulates. Papers from the Seventh Regional Meeting, Chicago Linguistic Society, 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>In P Cole</author>
<author>J L Morgan</author>
</authors>
<title>Syntax and semantics.</title>
<date>1975</date>
<publisher>Academic Press,</publisher>
<location>New York:</location>
<marker>Cole, Morgan, 1975</marker>
<rawString>Grice, H. P. Logic and conversation. In P. Cole &amp; J. L. Morgan (Eds.), Syntax and semantics. New York: Academic Press, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Labov</author>
<author>D Fanshel</author>
</authors>
<title>Therapeutic discourse. Psychotherapy as conversation. Draft copy,</title>
<date>1974</date>
<contexts>
<context position="8625" citStr="Labov &amp; Fanshel (1974)" startWordPosition="1361" endWordPosition="1364">en supported by the results of story recalls (Rumelhart, 1975; Thorndyke, 1977). Other similar kinds of theoretical constructs for organizing multiple sentences of stories have been proposed called: &amp;quot;frames&amp;quot; (Minsky, 1975; Charniak, 1975), &amp;quot;scripts&amp;quot; (Schank &amp; Abelson, 1975), and &amp;quot;commonsense algorithms&amp;quot; (Rieger, 1975). To account for the conduct and comprehension of dialogues, multi-sentential knowledge units have also been proposed by linguists and sociolinguists to explain certain kinds of regularities observed in naturally occurring dialogues. These regularities have been called &amp;quot;rules&amp;quot; by Labov &amp; Fanshel (1974) and &amp;quot;sequences&amp;quot; by Sacks, Schegloff, &amp; Jefferson (1974). Once these multi-sentential knowledge units are evoked, they serve as a basis for comprehending the&apos; successive inputs. This is achieved by generating expectations and by providing a framework for integrating the comprehension of an utterance with that of its predecessors. Recently, we have proposed (Levin &amp; Moore, 1976; 1977, Mann, Moore &amp; Levin, 1977) multi-sentential knowledge units that are specified primarily by the speaker&apos;s and hearer&apos;s goals. These goal-oriented units, which we call Dialogue-games[1], specify the kinds of langua</context>
</contexts>
<marker>Labov, Fanshel, 1974</marker>
<rawString>Labov, W., &amp; Fanshel, D. Therapeutic discourse. Psychotherapy as conversation. Draft copy, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Levin</author>
</authors>
<title>Proteus: An activation framework for cognitive process models. Unpublished doctoral dissertation,</title>
<date>1976</date>
<institution>Univ. of Calif,</institution>
<location>San Diego, CA:</location>
<contexts>
<context position="29952" citStr="Levin, 1976" startWordPosition="4694" endWordPosition="4695">h a simple invocation by name or any other pre-known collection of words or phrases. Instead the dialogue type is communicated by attempts to establish various entities as the values of the Pal meters of the desired Dialogue-game. Thus, an utterance which is comprehended as associating an entity (a, person or a concept) with a Parameter of a Dialogue-game suggests that Dialogue-game as a possibility for initiation. The Dialogue-Game Model has two ways in which these nominations of new Dialogue-games occur. One of the processes of the model is a &amp;quot;spreading activation&amp;quot; process caltei&apos;d Proteus (Levin, 1976). Proteus generates new activations in WS on the basis of Eclations in LTM, from concepts (nodes in the semantic network) that are already in WS. Proteus brings into focus concepts somehow related to those already there. A collection of concepts in WS leads to focusing on some aspect of a particular Dialogue-game, in this sense &amp;quot;nominating&amp;quot; it as a possible new Dialogue-game. MATCH and DEDUCE are two of the model s processes which operate in conjunction to generate new activations from existing ones, by means of finding and ap.07110rule-like transformations, They operate through partial match </context>
<context position="41548" citStr="Levin, 1976" startWordPosition="6554" endWordPosition="6555">n, Rumelhart, &amp; the LNR Research Group (1975). We use a case graMmar representation, with each utterance specified as a main predicate with a set of parameters. Because this module is a conventional parser whose implementation is well understood, we have so far produced hand parses of the input utterances, following an ATN grammar. Proteus This is a spreading activation mechanism, which modifies the activation of concepts specified as related in LTM whenever a given concept becomes active. This mechanism provides a way to integrate top-down and bottom-up processing within a uniform framework (Levin, 1976). The Dialogue-Game i4odel uses Proteus to activate a concept, given tha a number of closely related concepts (Components, features, instances, etc.) are active. Proteus operates on all currozt activations to modify their &amp;quot;salience&amp;quot;, a number associated with each activation that generally represents the importance or relevance of the concept. Two kinds of influence relations can exist between concepts: excite or inhibit. If an excite relation exists, then Proteus increases the salience of the activation of that concept in proportion to the salience of the influencing concept. The higher the sa</context>
</contexts>
<marker>Levin, 1976</marker>
<rawString>Levin, J. A. Proteus: An activation framework for cognitive process models. Unpublished doctoral dissertation, San Diego, CA: Univ. of Calif, San Diego, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A</author>
<author>J A Moore</author>
</authors>
<title>Dialogue-games: A process model of natural language interaction.</title>
<date>1976</date>
<booktitle>Proceedings of the A/S8 Summer Conference.</booktitle>
<location>Edinburgh, Scotland,</location>
<marker>A, Moore, 1976</marker>
<rawString>Levin. J. A., &amp; Moore, J. A. Dialogue-games: A process model of natural language interaction. Proceedings of the A/S8 Summer Conference. Edinburgh, Scotland, July 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Levin</author>
<author>J A Moore</author>
</authors>
<title>Dialogue Games: Meta-communication Structures for Natural Language Interaction (ISI/RR-77-53). Marina del Rey, CA: Information Sciences Institute,</title>
<date>1977</date>
<journal>Cognitive Sciences,</journal>
<volume>1977</volume>
<note>Also in press,</note>
<marker>Levin, Moore, 1977</marker>
<rawString>Levin, J. A., &amp; Moore, J. A. Dialogue Games: Meta-communication Structures for Natural Language Interaction (ISI/RR-77-53). Marina del Rey, CA: Information Sciences Institute, 1977. Also in press, Cognitive Sciences, 1977,1 ( 4 )</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>J A Moore</author>
<author>J A Levin</author>
</authors>
<title>A comprehension model for human dialogue.</title>
<date>1977</date>
<booktitle>Proceedings of the Fifth International Join&apos;t Conference on Artificial Intelli gence.</booktitle>
<pages>forthcoming.</pages>
<location>Cambridge, MA:.MIT,</location>
<marker>Mann, Moore, Levin, 1977</marker>
<rawString>Mann, W. C., Moore, J. A., &amp; Levin, J. A. A comprehension model for human dialogue. Proceedings of the Fifth International Join&apos;t Conference on Artificial Intelli gence. Cambridge, MA:.MIT, 1977, forthcoming.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Minsky</author>
</authors>
<title>A framework for representing knowledge. In</title>
<date>1975</date>
<publisher>McGraw-Hill,</publisher>
<location>New York:</location>
<contexts>
<context position="8224" citStr="Minsky, 1975" startWordPosition="1309" endWordPosition="1310">sion has focused on the comprehension of single sentences or fragments of sentences. However some research has indicated the importance of the context created by surrounding sentences on the comprehension of an individual sentence. One specific model for the form of this multi-sentential knowledge is the &amp;quot;story schema&amp;quot;, organized within a story grammar (Rumelhart, 1975). This model has been supported by the results of story recalls (Rumelhart, 1975; Thorndyke, 1977). Other similar kinds of theoretical constructs for organizing multiple sentences of stories have been proposed called: &amp;quot;frames&amp;quot; (Minsky, 1975; Charniak, 1975), &amp;quot;scripts&amp;quot; (Schank &amp; Abelson, 1975), and &amp;quot;commonsense algorithms&amp;quot; (Rieger, 1975). To account for the conduct and comprehension of dialogues, multi-sentential knowledge units have also been proposed by linguists and sociolinguists to explain certain kinds of regularities observed in naturally occurring dialogues. These regularities have been called &amp;quot;rules&amp;quot; by Labov &amp; Fanshel (1974) and &amp;quot;sequences&amp;quot; by Sacks, Schegloff, &amp; Jefferson (1974). Once these multi-sentential knowledge units are evoked, they serve as a basis for comprehending the&apos; successive inputs. This is achieved by g</context>
</contexts>
<marker>Minsky, 1975</marker>
<rawString>Minsky, M. A framework for representing knowledge. In P. H. Winston (Ed.), The psychology of computer vision. New York: McGraw-Hill, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Newell</author>
</authors>
<title>Production systems: Models of control structures. In</title>
<date>1973</date>
<publisher>Academic Press,</publisher>
<location>New York:</location>
<contexts>
<context position="30804" citStr="Newell, 1973" startWordPosition="4823" endWordPosition="4824">ncepts in WS leads to focusing on some aspect of a particular Dialogue-game, in this sense &amp;quot;nominating&amp;quot; it as a possible new Dialogue-game. MATCH and DEDUCE are two of the model s processes which operate in conjunction to generate new activations from existing ones, by means of finding and ap.07110rule-like transformations, They operate through partial match and plausible inference-techniclues, and if they activate Parameters, then the Dialogue-game that contains those Parameters becomes nominated as. a candidate Dialogue-game. Match and Deduce operate together as a kind of production system (Newell, 1973). For example, from the input utterance: &amp;quot;I tried to send a message to &lt;person&gt; at &lt;computer-site&gt; and it didn&apos;t go.&amp;quot; the following two sequences of associations and inferences result: (la) I tried to X. (2a) I wanted to X. (3a) I. want to X. (4a) HELPEE wants to do TASK. (lb) It didn&apos;t go. (2b)What I tried to do dirin&apos;t work. (3b) X didn&apos;t work. (4b) I can&apos;t X. (5b) I don&apos;t know 115 to X. (GE) HELPEEldp6sn&apos;t know how to do TASK. A Model of Dialogue 20 (Where: I = HELPEE and X = do TASK = send a message to &lt;person&gt; at &lt;computer-site&gt;.) At this point, (4a) and (6b), since they are both Paramete</context>
</contexts>
<marker>Newell, 1973</marker>
<rawString>Newell, A. Production systems: Models of control structures. In W. G. Chase (Ed.), Visual information processing. New York: Academic Press, 1973.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Newell</author>
<author>H A Simon</author>
</authors>
<title>Human problem solvtiig. Englewood Cliffs,</title>
<date>1972</date>
<publisher>Prentice-Hall,</publisher>
<location>NJ:</location>
<contexts>
<context position="12909" citStr="Newell &amp; Simon, 1972" startWordPosition="1992" endWordPosition="1995">tional rules for information requests, a different set of rules for answers to these requests, and a way to tie these two rule sets together. The Dialogue-game model postulates a single knowledge structure for this kind of interaction, with cooperating processes for: (1) recognizing when this kind of interaction is proposed, (2) using this knowledge to comprehend utterances within its scope, and (3) identifying when the interaction is to be terminated. A Model of Dialogue 10 THE SHAPE OF THE THEORY Our theory of human language use has been strongly influenced by work in human problem solving (Newell &amp; Simon, 1972) in which the behavior of a human is modeled as an information. processing system, having goals to pursue and selecting actions which tend to achieve these goals. We view humans as engaging in linguistic behavior in order to advance the state of certain of their goals. They decide to use language, they select (or accept) the other participant for a dialogue, they choose the details of linguistic expression — all with the expectation that some of their desired state specifications can thereby be realized. In this theory of language, a participant in a linguistic exchange views the other as an i</context>
</contexts>
<marker>Newell, Simon, 1972</marker>
<rawString>Newell, A., &amp; Simon, H. A. Human problem solvtiig. Englewood Cliffs, NJ: Prentice-Hall, 1972.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Norman</author>
<author>D E Rumelhart</author>
</authors>
<title>the LNR Research Group. Explorations in cognition.</title>
<date>1975</date>
<location>San Francisco:</location>
<marker>Norman, Rumelhart, 1975</marker>
<rawString>Norman, D. A., Rumelhart, D E. &amp; the LNR Research Group. Explorations in cognition. San Francisco: W. H. Freeman, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Rieger</author>
</authors>
<title>The commonsense algorithm as a basis for computer models of human memory, inference, belief and contextual language comprehension. In</title>
<date>1975</date>
<location>Cambridge, MA:</location>
<contexts>
<context position="8322" citStr="Rieger, 1975" startWordPosition="1321" endWordPosition="1322"> research has indicated the importance of the context created by surrounding sentences on the comprehension of an individual sentence. One specific model for the form of this multi-sentential knowledge is the &amp;quot;story schema&amp;quot;, organized within a story grammar (Rumelhart, 1975). This model has been supported by the results of story recalls (Rumelhart, 1975; Thorndyke, 1977). Other similar kinds of theoretical constructs for organizing multiple sentences of stories have been proposed called: &amp;quot;frames&amp;quot; (Minsky, 1975; Charniak, 1975), &amp;quot;scripts&amp;quot; (Schank &amp; Abelson, 1975), and &amp;quot;commonsense algorithms&amp;quot; (Rieger, 1975). To account for the conduct and comprehension of dialogues, multi-sentential knowledge units have also been proposed by linguists and sociolinguists to explain certain kinds of regularities observed in naturally occurring dialogues. These regularities have been called &amp;quot;rules&amp;quot; by Labov &amp; Fanshel (1974) and &amp;quot;sequences&amp;quot; by Sacks, Schegloff, &amp; Jefferson (1974). Once these multi-sentential knowledge units are evoked, they serve as a basis for comprehending the&apos; successive inputs. This is achieved by generating expectations and by providing a framework for integrating the comprehension of an uttera</context>
</contexts>
<marker>Rieger, 1975</marker>
<rawString>Rieger, C. The commonsense algorithm as a basis for computer models of human memory, inference, belief and contextual language comprehension. In R. Schank B. L. Nash-Webber (Eds.), Theoretical issues in natural language processing. Cambridge, MA: Bolt, Beranek and Newman, Inc., 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D E Rumelhart</author>
</authors>
<title>Notes on a schema for stories. In</title>
<date>1975</date>
<publisher>Academic Press,</publisher>
<location>New York:</location>
<contexts>
<context position="7984" citStr="Rumelhart, 1975" startWordPosition="1275" endWordPosition="1276">logues were conducted over a restricted medium so that there was no visual or intonational communication not captured in the tr,nscript. A Model of Diillogue 8 PAST RESEARCH ON LANGUAGE COMPREHENSION Most of the research jnto language comprehension has focused on the comprehension of single sentences or fragments of sentences. However some research has indicated the importance of the context created by surrounding sentences on the comprehension of an individual sentence. One specific model for the form of this multi-sentential knowledge is the &amp;quot;story schema&amp;quot;, organized within a story grammar (Rumelhart, 1975). This model has been supported by the results of story recalls (Rumelhart, 1975; Thorndyke, 1977). Other similar kinds of theoretical constructs for organizing multiple sentences of stories have been proposed called: &amp;quot;frames&amp;quot; (Minsky, 1975; Charniak, 1975), &amp;quot;scripts&amp;quot; (Schank &amp; Abelson, 1975), and &amp;quot;commonsense algorithms&amp;quot; (Rieger, 1975). To account for the conduct and comprehension of dialogues, multi-sentential knowledge units have also been proposed by linguists and sociolinguists to explain certain kinds of regularities observed in naturally occurring dialogues. These regularities have been</context>
</contexts>
<marker>Rumelhart, 1975</marker>
<rawString>Rumelhart, D. E. Notes on a schema for stories. In D. G. Bobrow &amp; A. Collins (Eds.), Representation and understanding: Studies in cognitive science. New York: Academic Press, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sacks</author>
<author>E A Schegloff</author>
<author>G Jefferson</author>
</authors>
<title>A simplest systematics for the organization of turn-taking for conversation. Language,</title>
<date>1974</date>
<volume>50</volume>
<pages>696--735</pages>
<marker>Sacks, Schegloff, Jefferson, 1974</marker>
<rawString>Sacks, H., Schegloff, E. A., &amp; Jefferson, G. A simplest systematics for the organization of turn-taking for conversation. Language, 1974, 50, 696-735.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Schank</author>
<author>R P Scripts Abelson</author>
</authors>
<title>plans and knowledge. Paper presented at the</title>
<date>1975</date>
<booktitle>Fourth International Joint Conference on Artificial Intelligence,</booktitle>
<location>Tbilisi, USSR,</location>
<contexts>
<context position="8277" citStr="Schank &amp; Abelson, 1975" startWordPosition="1314" endWordPosition="1317">ingle sentences or fragments of sentences. However some research has indicated the importance of the context created by surrounding sentences on the comprehension of an individual sentence. One specific model for the form of this multi-sentential knowledge is the &amp;quot;story schema&amp;quot;, organized within a story grammar (Rumelhart, 1975). This model has been supported by the results of story recalls (Rumelhart, 1975; Thorndyke, 1977). Other similar kinds of theoretical constructs for organizing multiple sentences of stories have been proposed called: &amp;quot;frames&amp;quot; (Minsky, 1975; Charniak, 1975), &amp;quot;scripts&amp;quot; (Schank &amp; Abelson, 1975), and &amp;quot;commonsense algorithms&amp;quot; (Rieger, 1975). To account for the conduct and comprehension of dialogues, multi-sentential knowledge units have also been proposed by linguists and sociolinguists to explain certain kinds of regularities observed in naturally occurring dialogues. These regularities have been called &amp;quot;rules&amp;quot; by Labov &amp; Fanshel (1974) and &amp;quot;sequences&amp;quot; by Sacks, Schegloff, &amp; Jefferson (1974). Once these multi-sentential knowledge units are evoked, they serve as a basis for comprehending the&apos; successive inputs. This is achieved by generating expectations and by providing a framework f</context>
</contexts>
<marker>Schank, Abelson, 1975</marker>
<rawString>Schank, R. C., &amp; Abelson, R. P. Scripts, plans and knowledge. Paper presented at the Fourth International Joint Conference on Artificial Intelligence, Tbilisi, USSR, August 1975.</rawString>
</citation>
<citation valid="false">
<title>Cycle 1-16-- Deduce Deduce applies RuleVa to RO-1.</title>
<marker></marker>
<rawString>Cycle 1-16-- Deduce Deduce applies RuleVa to RO-1.</rawString>
</citation>
<citation valid="false">
<title>Results: RVa-1 (= 0 knows ( L asks (how do I perform (getting Runoff working)?)) is activated).. Activation of Rule Va deleted from WS.</title>
<journal>Cycle</journal>
<pages>1--17</pages>
<marker></marker>
<rawString>Results: RVa-1 (= 0 knows ( L asks (how do I perform (getting Runoff working)?)) is activated).. Activation of Rule Va deleted from WS. Cycle 1-17--Match</rawString>
</citation>
<citation valid="false">
<title>A Model of Dialogue 46 Match RVa-1 with Left half of Rule2a = If 0 knows (a person asks how to perform a task), then 0 knows (that person wants 0 to enable him to perform that task). Results: RVa-1 is an activation of the left half of Rule2a. L corresponds to that person. (L getting Runoff to work) corresponds to the task. An activation of Rule 2a is created in the WS.</title>
<booktitle>Cycle 1-18 — Deduce Deduce applies Rule2a to RVa-1</booktitle>
<marker></marker>
<rawString>A Model of Dialogue 46 Match RVa-1 with Left half of Rule2a = If 0 knows (a person asks how to perform a task), then 0 knows (that person wants 0 to enable him to perform that task). Results: RVa-1 is an activation of the left half of Rule2a. L corresponds to that person. (L getting Runoff to work) corresponds to the task. An activation of Rule 2a is created in the WS. Cycle 1-18 — Deduce Deduce applies Rule2a to RVa-1</rawString>
</citation>
<citation valid="false">
<title>Results: R2-1 (= 0 knows (L wants 0 to enable him (L) to get Runoff working) is activated).</title>
<booktitle>Activation of Rule 2a deleted from WS. Cycle 1-19 Match Match R2a-1 with H11 = Helpee</booktitle>
<marker></marker>
<rawString>Results: R2-1 (= 0 knows (L wants 0 to enable him (L) to get Runoff working) is activated). Activation of Rule 2a deleted from WS. Cycle 1-19 Match Match R2a-1 with H11 = Helpee wants Helper to enable him tato a task.</rawString>
</citation>
<citation valid="false">
<title>Results: 0 corresporids to Helper. L corresponds to Helpee. (L getting Runoff to work) corresponds to the task.</title>
<booktitle>Cycle 1-20 Proteus H1, H2 gz H11 provide Proteus with</booktitle>
<marker></marker>
<rawString>Results: 0 corresporids to Helper. L corresponds to Helpee. (L getting Runoff to work) corresponds to the task. Cycle 1-20 Proteus H1, H2 gz H11 provide Proteus with enough evidence to create an activation of the Helping-Game.</rawString>
</citation>
<citation valid="false">
<title>Results: An activation of the Helping-game is created in the WS. Cycle 1-21 -- Dialogue-game Manager Cycle 2-1 -- Parser Results: Case9a t: 0 perceives that L. declares (I executed it). Cycle 2-2 -- I-processor</title>
<marker></marker>
<rawString>Results: An activation of the Helping-game is created in the WS. Cycle 1-21 -- Dialogue-game Manager Cycle 2-1 -- Parser Results: Case9a t: 0 perceives that L. declares (I executed it). Cycle 2-2 -- I-processor</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>