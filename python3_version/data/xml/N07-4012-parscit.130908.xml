<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.168079">
<title confidence="0.998106">
A Conversational In-car Dialog System
</title>
<author confidence="0.994528">
Baoshi Yan1 Fuliang Weng1 Zhe Feng1 Florin Ratiu2 Madhuri Raya1 Yao Meng1
Sebastian Varges2 Matthew Purver2 Annie Lien1 Tobias Scheideck1 Badri Raghunathan1
Feng Lin1 Rohit Mishra4 Brian Lathrop4 Zhaoxia Zhang4 Harry Bratt3 Stanley Peters2
</author>
<affiliation confidence="0.9492875">
Research and Technology Center, Robert Bosch LLC, Palo Alto, California1
Center for the Study of Language and Information, Stanford University, Stanford, California2
Speech Technology and Research Lab, SRI International, Menlo Park, California3
Electronics Research Lab, Volkswagen of America, Palo Alto, California4
</affiliation>
<sectionHeader confidence="0.97469" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999489">
In this demonstration we present a con-
versational dialog system for automobile
drivers. The system provides a voice-
based interface to playing music, finding
restaurants, and navigating while driving.
The design of the system as well as the
new technologies developed will be pre-
sented. Our evaluation showed that the
system is promising, achieving high task
completion rate and good user satisfation.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977689655172">
As a constant stream of electronic gadgets such as
navigation systems and digital music players en-
ters cars, it threatens driving safety by increasing
driver distraction. According to a 2005 report by
the National Highway Traffic Safety Administration
(NHTSA) (NHTSA, 2005), driver distraction and
inattention from all sources contributed to 20-25%
of police reported crashes. It is therefore impor-
tant to design user interfaces to devices that mini-
mize driver distraction, to which voice-based inter-
faces have been a promising approach as they keep
a driver’s hands on the wheel and eyes on the road.
In this demonstration we present a conversational
dialog system, CHAT, that supports music selection,
restaurant selection, and driving navigation (Weng
et al., 2006). The system is a joint research effort
from Bosch RTC, VW ERL, Stanford CSLI, and SRI
STAR Lab funded by NIST ATP. It has reached a
promising level, achieving a task completion rate of
98%, 94%, 97% on playing music, finding restau-
rants, and driving navigation respectively.
Specifically, we plan to present a number of fea-
tures in the CHAT system, including end-pointing
with prosodic cues, robust natural language under-
standing, error identification and recovery strate-
gies, content optimization, full-fledged reponse gen-
eration, flexible multi-threaded, multi-device dialog
management, and support for random events, dy-
namic information, and domain switching.
</bodyText>
<sectionHeader confidence="0.975256" genericHeader="method">
2 System Descriptions
</sectionHeader>
<bodyText confidence="0.99977724">
The spoken dialog system consists of a number of
components (see the figure on the next page). In-
stead of the hub architecture employed by Commu-
nicator projects (Seneff et al., 1998), it is devel-
oped in Java and uses flexible event-based, message-
oriented middleware. This allows for dynamic regis-
tration of new components. Among the component
modules in the figure, we use the Nuance speech
recognition engine with class-based n-grams and
dynamic grammars, and the Nuance Vocalizer as the
TTS engine. The Speech Enhancer removes noises
and echo. The Prosody module will provide addi-
tional features to the Natural Language Understand-
ing (NLU) and Dialog Manager (DM) modules to
improve their performance.
The NLU module takes a sequence of recognized
words and tags, performs a deep linguistic analysis
with probabilistic models, and produces an XML-
based semantic feature structure representation. Par-
allel to the deep analysis, a topic classifier assigns
n-best topics to the utterance, which are used in the
cases where the dialog manager cannot make any
sense of the parsed structure. The NLU module also
supports dynamic updates of the knowledge base.
The DM module mediates and manages interac-
</bodyText>
<page confidence="0.968159">
23
</page>
<author confidence="0.233267">
NAACL HLT Demonstration Program, pages 23–24,
</author>
<affiliation confidence="0.729534">
Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics
</affiliation>
<bodyText confidence="0.999946441860465">
tion. It uses an information-state-update approach to
maintain dialog context, which is then used to inter-
pret incoming utterances (including fragments and
revisions), resolve NPs, construct salient responses,
track issues, etc. Dialog states can also be used to
bias SR expectation and improve SR performance,
as has been performed in previous applications of
the DM. Detailed descriptions of the DM can be
found in (Lemon et al., 2002) (Mirkovic and Cave-
don, 2005).
The Knowledge Manager (KM) controls access
to knowledge base sources (such as domain knowl-
edge and device information) and their updates. Do-
main knowledge is structured according to domain-
dependent ontologies. The current KM makes use of
OWL, a W3C standard, to represent the ontological
relationships between domain entities.
The Content Optimization module acts as an in-
termediary between the dialog management module
and the knowledge management module and con-
trols the amount of content and provides recommen-
dations to user. It receives queries in the form of se-
mantic frames from the DM, resolves possible ambi-
guities, and queries the KM. Depending on the items
in the query result as well as configurable properties,
the module selects and performs an appropriate op-
timization strategy (Pon-Barry et al., 2006).
The Response Generation module takes query re-
sults from the KM or Content Optimizer and gener-
ates natural language sentences as system responses
to user utterances. The query results are converted
into natural language sentences via a bottom-up ap-
proach using a production system. An alignment-
based ranking algorithm is used to select the best
generated sentence.
The system supports random events and dy-
namic external information, for example, the system
prompts users for the next turn when they drive close
to an intersection and dialogs can be carried out in
terms of the current dynamic situation. The user can
also switch among the three different applications
easily by explicitly instructing the system which do-
main to operate in.
</bodyText>
<sectionHeader confidence="0.987813" genericHeader="method">
3 Acknowledgement
</sectionHeader>
<bodyText confidence="0.970871">
This work is partially supported by the NIST Ad-
vanced Technology Program.
</bodyText>
<sectionHeader confidence="0.998351" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999707638888889">
Oliver Lemon, Alex Gruenstein, and Stanley Peters.
2002. Collaborative activities and multi-tasking in
dialogue systems. In Traitement Automatique des
Langues (TAL), page 43(2).
Danilo Mirkovic and Lawrence Cavedon. 2005. Prac-
tical Plug-and-Play Dialogue Management. In Pro-
ceedings of the 6th Meeting of the Pacific Associa-
tion for Computational Linguistics (PACLING), page
43(2), Tokyo, Japan.
National Highway Traffic Safety Administration
NHTSA. 2005. NHTSA Vehicle Safety Rulemaking
and Supporting Research Priorities: Calendar Years
2005-2009. January.
Heather Pon-Barry, Fuliang Weng, and Sebastian Varges.
2006. Evaluation of content presentation strategies
for an in-car spoken dialogue system. In Proceedings
of the 9th International Conference on Spoken Lan-
guage Processing (Interspeech/ICSLP), pages 1930–
1933, Pittsburgh, PA, September.
Stephanie Seneff, Ed Hurley, Raymond Lau, Chris-
tine Pao, Philipp Schmid, and Victor Zue. 1998.
GALAXY-II: A Reference Architecture for Conversa-
tional System Development. In International Confer-
ence on Spoken Language Processing (ICSLP), page
43(2), Sydney, Australia, December.
Fuliang Weng, Sebastian Varges, Badri Raghunathan,
Florin Ratiu, Heather Pon-Barry, Brian Lathrop,
Qi Zhang, Tobias Scheideck, Harry Bratt, Kui Xu,
Matthew Purver, Rohit Mishra, Annie Lien, Mad-
huri Raya, Stanley Peters, Yao Meng, Jeff Russel,
Lawrence Cavedon, Liz Shriberg, and Hauke Schmidt.
2006. CHAT: A conversational helper for automo-
tive tasks. In Proceedings of the 9th International
Conference on Spoken Language Processing (Inter-
speech/ICSLP), pages 1061–1064, Pittsburgh, PA,
September.
</reference>
<page confidence="0.999177">
24
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.215763">
<title confidence="0.999869">A Conversational In-car Dialog System</title>
<author confidence="0.852903666666667">Fuliang Zhe Florin Madhuri Yao Matthew Annie Tobias Badri Rohit Brian Zhaoxia Harry Stanley</author>
<affiliation confidence="0.919770666666667">and Technology Center, Robert Bosch LLC, Palo Alto, for the Study of Language and Information, Stanford University, Stanford, Technology and Research Lab, SRI International, Menlo Park,</affiliation>
<address confidence="0.438667">Research Lab, Volkswagen of America, Palo Alto,</address>
<abstract confidence="0.998439636363636">In this demonstration we present a conversational dialog system for automobile drivers. The system provides a voicebased interface to playing music, finding restaurants, and navigating while driving. The design of the system as well as the new technologies developed will be presented. Our evaluation showed that the system is promising, achieving high task completion rate and good user satisfation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Alex Gruenstein</author>
<author>Stanley Peters</author>
</authors>
<title>Collaborative activities and multi-tasking in dialogue systems.</title>
<date>2002</date>
<booktitle>In Traitement Automatique des Langues (TAL),</booktitle>
<pages>43--2</pages>
<contexts>
<context position="4244" citStr="Lemon et al., 2002" startWordPosition="639" endWordPosition="642">se. The DM module mediates and manages interac23 NAACL HLT Demonstration Program, pages 23–24, Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics tion. It uses an information-state-update approach to maintain dialog context, which is then used to interpret incoming utterances (including fragments and revisions), resolve NPs, construct salient responses, track issues, etc. Dialog states can also be used to bias SR expectation and improve SR performance, as has been performed in previous applications of the DM. Detailed descriptions of the DM can be found in (Lemon et al., 2002) (Mirkovic and Cavedon, 2005). The Knowledge Manager (KM) controls access to knowledge base sources (such as domain knowledge and device information) and their updates. Domain knowledge is structured according to domaindependent ontologies. The current KM makes use of OWL, a W3C standard, to represent the ontological relationships between domain entities. The Content Optimization module acts as an intermediary between the dialog management module and the knowledge management module and controls the amount of content and provides recommendations to user. It receives queries in the form of seman</context>
</contexts>
<marker>Lemon, Gruenstein, Peters, 2002</marker>
<rawString>Oliver Lemon, Alex Gruenstein, and Stanley Peters. 2002. Collaborative activities and multi-tasking in dialogue systems. In Traitement Automatique des Langues (TAL), page 43(2).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Danilo Mirkovic</author>
<author>Lawrence Cavedon</author>
</authors>
<title>Practical Plug-and-Play Dialogue Management.</title>
<date>2005</date>
<booktitle>In Proceedings of the 6th Meeting of the Pacific Association for Computational Linguistics (PACLING),</booktitle>
<pages>43--2</pages>
<location>Tokyo, Japan.</location>
<contexts>
<context position="4273" citStr="Mirkovic and Cavedon, 2005" startWordPosition="643" endWordPosition="647">iates and manages interac23 NAACL HLT Demonstration Program, pages 23–24, Rochester, New York, USA, April 2007. c�2007 Association for Computational Linguistics tion. It uses an information-state-update approach to maintain dialog context, which is then used to interpret incoming utterances (including fragments and revisions), resolve NPs, construct salient responses, track issues, etc. Dialog states can also be used to bias SR expectation and improve SR performance, as has been performed in previous applications of the DM. Detailed descriptions of the DM can be found in (Lemon et al., 2002) (Mirkovic and Cavedon, 2005). The Knowledge Manager (KM) controls access to knowledge base sources (such as domain knowledge and device information) and their updates. Domain knowledge is structured according to domaindependent ontologies. The current KM makes use of OWL, a W3C standard, to represent the ontological relationships between domain entities. The Content Optimization module acts as an intermediary between the dialog management module and the knowledge management module and controls the amount of content and provides recommendations to user. It receives queries in the form of semantic frames from the DM, resol</context>
</contexts>
<marker>Mirkovic, Cavedon, 2005</marker>
<rawString>Danilo Mirkovic and Lawrence Cavedon. 2005. Practical Plug-and-Play Dialogue Management. In Proceedings of the 6th Meeting of the Pacific Association for Computational Linguistics (PACLING), page 43(2), Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<title>Traffic Safety Administration NHTSA.</title>
<date>2005</date>
<institution>National Highway</institution>
<marker>2005</marker>
<rawString>National Highway Traffic Safety Administration NHTSA. 2005. NHTSA Vehicle Safety Rulemaking and Supporting Research Priorities: Calendar Years 2005-2009. January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heather Pon-Barry</author>
<author>Fuliang Weng</author>
<author>Sebastian Varges</author>
</authors>
<title>Evaluation of content presentation strategies for an in-car spoken dialogue system.</title>
<date>2006</date>
<booktitle>In Proceedings of the 9th International Conference on Spoken Language Processing (Interspeech/ICSLP),</booktitle>
<pages>pages</pages>
<location>Pittsburgh, PA,</location>
<contexts>
<context position="5091" citStr="Pon-Barry et al., 2006" startWordPosition="773" endWordPosition="776">dent ontologies. The current KM makes use of OWL, a W3C standard, to represent the ontological relationships between domain entities. The Content Optimization module acts as an intermediary between the dialog management module and the knowledge management module and controls the amount of content and provides recommendations to user. It receives queries in the form of semantic frames from the DM, resolves possible ambiguities, and queries the KM. Depending on the items in the query result as well as configurable properties, the module selects and performs an appropriate optimization strategy (Pon-Barry et al., 2006). The Response Generation module takes query results from the KM or Content Optimizer and generates natural language sentences as system responses to user utterances. The query results are converted into natural language sentences via a bottom-up approach using a production system. An alignmentbased ranking algorithm is used to select the best generated sentence. The system supports random events and dynamic external information, for example, the system prompts users for the next turn when they drive close to an intersection and dialogs can be carried out in terms of the current dynamic situat</context>
</contexts>
<marker>Pon-Barry, Weng, Varges, 2006</marker>
<rawString>Heather Pon-Barry, Fuliang Weng, and Sebastian Varges. 2006. Evaluation of content presentation strategies for an in-car spoken dialogue system. In Proceedings of the 9th International Conference on Spoken Language Processing (Interspeech/ICSLP), pages 1930– 1933, Pittsburgh, PA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Seneff</author>
<author>Ed Hurley</author>
<author>Raymond Lau</author>
<author>Christine Pao</author>
<author>Philipp Schmid</author>
<author>Victor Zue</author>
</authors>
<title>GALAXY-II: A Reference Architecture for Conversational System Development.</title>
<date>1998</date>
<booktitle>In International Conference on Spoken Language Processing (ICSLP), page 43(2),</booktitle>
<location>Sydney, Australia,</location>
<contexts>
<context position="2656" citStr="Seneff et al., 1998" startWordPosition="393" endWordPosition="396">ng navigation respectively. Specifically, we plan to present a number of features in the CHAT system, including end-pointing with prosodic cues, robust natural language understanding, error identification and recovery strategies, content optimization, full-fledged reponse generation, flexible multi-threaded, multi-device dialog management, and support for random events, dynamic information, and domain switching. 2 System Descriptions The spoken dialog system consists of a number of components (see the figure on the next page). Instead of the hub architecture employed by Communicator projects (Seneff et al., 1998), it is developed in Java and uses flexible event-based, messageoriented middleware. This allows for dynamic registration of new components. Among the component modules in the figure, we use the Nuance speech recognition engine with class-based n-grams and dynamic grammars, and the Nuance Vocalizer as the TTS engine. The Speech Enhancer removes noises and echo. The Prosody module will provide additional features to the Natural Language Understanding (NLU) and Dialog Manager (DM) modules to improve their performance. The NLU module takes a sequence of recognized words and tags, performs a deep </context>
</contexts>
<marker>Seneff, Hurley, Lau, Pao, Schmid, Zue, 1998</marker>
<rawString>Stephanie Seneff, Ed Hurley, Raymond Lau, Christine Pao, Philipp Schmid, and Victor Zue. 1998. GALAXY-II: A Reference Architecture for Conversational System Development. In International Conference on Spoken Language Processing (ICSLP), page 43(2), Sydney, Australia, December.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fuliang Weng</author>
<author>Sebastian Varges</author>
<author>Badri Raghunathan</author>
<author>Florin Ratiu</author>
<author>Heather Pon-Barry</author>
<author>Brian Lathrop</author>
<author>Qi Zhang</author>
<author>Tobias Scheideck</author>
<author>Harry Bratt</author>
<author>Kui Xu</author>
<author>Matthew Purver</author>
</authors>
<title>CHAT: A conversational helper for automotive tasks.</title>
<date>2006</date>
<booktitle>In Proceedings of the 9th International Conference on Spoken Language Processing (Interspeech/ICSLP),</booktitle>
<pages>1061--1064</pages>
<location>Rohit Mishra, Annie Lien, Madhuri Raya, Stanley Peters, Yao Meng, Jeff Russel, Lawrence Cavedon, Liz Shriberg, and</location>
<contexts>
<context position="1788" citStr="Weng et al., 2006" startWordPosition="259" endWordPosition="262"> driver distraction. According to a 2005 report by the National Highway Traffic Safety Administration (NHTSA) (NHTSA, 2005), driver distraction and inattention from all sources contributed to 20-25% of police reported crashes. It is therefore important to design user interfaces to devices that minimize driver distraction, to which voice-based interfaces have been a promising approach as they keep a driver’s hands on the wheel and eyes on the road. In this demonstration we present a conversational dialog system, CHAT, that supports music selection, restaurant selection, and driving navigation (Weng et al., 2006). The system is a joint research effort from Bosch RTC, VW ERL, Stanford CSLI, and SRI STAR Lab funded by NIST ATP. It has reached a promising level, achieving a task completion rate of 98%, 94%, 97% on playing music, finding restaurants, and driving navigation respectively. Specifically, we plan to present a number of features in the CHAT system, including end-pointing with prosodic cues, robust natural language understanding, error identification and recovery strategies, content optimization, full-fledged reponse generation, flexible multi-threaded, multi-device dialog management, and suppor</context>
</contexts>
<marker>Weng, Varges, Raghunathan, Ratiu, Pon-Barry, Lathrop, Zhang, Scheideck, Bratt, Xu, Purver, 2006</marker>
<rawString>Fuliang Weng, Sebastian Varges, Badri Raghunathan, Florin Ratiu, Heather Pon-Barry, Brian Lathrop, Qi Zhang, Tobias Scheideck, Harry Bratt, Kui Xu, Matthew Purver, Rohit Mishra, Annie Lien, Madhuri Raya, Stanley Peters, Yao Meng, Jeff Russel, Lawrence Cavedon, Liz Shriberg, and Hauke Schmidt. 2006. CHAT: A conversational helper for automotive tasks. In Proceedings of the 9th International Conference on Spoken Language Processing (Interspeech/ICSLP), pages 1061–1064, Pittsburgh, PA, September.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>