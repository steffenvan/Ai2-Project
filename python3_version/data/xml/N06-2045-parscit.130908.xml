<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.045372">
<title confidence="0.977809">
Lycos Retriever: An Information Fusion Engine
</title>
<author confidence="0.994273">
Brian Ulicny
</author>
<affiliation confidence="0.986577">
Versatile Information Systems, Inc.
</affiliation>
<address confidence="0.601095">
5 Mountainview Drive
Framingham, MA 01701 USA
</address>
<email confidence="0.997826">
bulicny@vistology.com
</email>
<sectionHeader confidence="0.993863" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999939">
This paper describes the Lycos Retriever
system, a deployed system for automati-
cally generating coherent topical summa-
ries of popular web query topics.
</bodyText>
<sectionHeader confidence="0.998687" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998452642857143">
Lycos Retriever1 is something new on the Web: a
patent-pending information fusion engine. That is,
unlike a search engine, rather than returning ranked
documents links in response to a query, Lycos Re-
triever categorizes and disambiguates topics, col-
lects documents on the Web relevant to the
disambiguated sense of that topic, extracts para-
graphs and images from these documents and ar-
ranges these into a coherent summary report or
background briefing on the topic at something like
the level of the first draft of a Wikipedia2 article.
These topical pages are then arranged into a
browsable hierarchy that allows users to find re-
lated topics by browsing as well as searching.
</bodyText>
<sectionHeader confidence="0.994004" genericHeader="introduction">
2 Motivations
</sectionHeader>
<bodyText confidence="0.999422">
The presentation of search results as ranked lists of
document links has become so ingrained that it is
hard now to imagine alternatives to it. Other inter-
faces, such as graphical maps or visualizations,
have not been widely adopted. Question-answering
interfaces on the Web have not had a high adoption
</bodyText>
<footnote confidence="0.951210333333333">
1 http://www.lycos.com/retriever.html. Work on Retriever
was done while author was employed at Lycos.
2 http://www.wikipedia.org
</footnote>
<bodyText confidence="0.999478789473684">
rate, either: it is hard to get users to venture beyond
the 2.5 word queries they are accustomed to, and if
question-answering results are not reliably better
than keyword search, users quickly return to key-
word queries. Many user queries specify nothing
more than a topic anyway.
But why treat common queries exactly like
unique queries? For common queries we know
that incentives for ranking highly have led to tech-
niques for artificially inflating a site’s ranking at
the expense of useful information. So the user has
many useless results to sift through. Furthermore,
users are responsive to filtered information, as the
upsurge in popularity of Wikipedia and An-
swers.com demonstrate.
Retriever responds to these motivations by
automatically generating a narrative summary that
answers, “What do I need to know about this
topic?” for the most popular topics on the Web.3
</bodyText>
<sectionHeader confidence="0.881108" genericHeader="method">
3 Lycos Retriever pages
</sectionHeader>
<bodyText confidence="0.9987939">
Figure 1 shows a sample Retriever page for the
topic “Mario Lemieux”.4 The topic is indicated at
the upper left. Below it is a category assigned to
the topic, in this case Sports &gt; Hockey &gt; Ice
Hockey &gt; National Hockey League &gt; Lemieux,
Mario. The main body of the page is a set of para-
graphs beginning with a biographical paragraph
complete with Lemieux’s birth date, height, weight
and position extracted from Nationmaster.com,
followed by paragraphs outlining his career from
</bodyText>
<footnote confidence="0.949896125">
3 See (Liu, 2003) for a similarly motivated system.
4 For other categories, see e.g. King Kong (1933):
http://www.lycos.com/info/king-kong-1933.html,
Zoloft: http://www.lycos.com/info/zoloft.html,
Public-Key Cryptography: http://www.lycos.com/info/public-
key-cryptography.html ,
Lyme Disease: http://www.lycos.com/info/lyme-disease.html,
Reggaeton: http://www.lycos.com/info/reggaeton.html
</footnote>
<page confidence="0.807019">
177
</page>
<note confidence="0.8222005">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 177–180,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999309416666667">
other sources. The source for each extract is indi-
cated in shortened form in the left margin of the
page; mousing over the shortened URL reveals the
full title and URL. Associated images are thumb-
nailed alongside the extracted paragraphs.
Running down the right side of the page under
More About is a set of subtopics. Each subtopic is
a link to a page (or pages) with paragraphs about
the topic (Lemieux) with respect to such subtopics
as Games, Seasons, Pittsburgh Penguins, Wayne
Gretzky, and others, including the unpromising
subtopic ice.
</bodyText>
<sectionHeader confidence="0.988616" genericHeader="method">
4 Topic Selection
</sectionHeader>
<bodyText confidence="0.999338461538462">
After a topic was input to the system, the Retriever
system assigned it a category using a naïve Bayes
classifier built on a spidered DMOZ5 hierarchy.
Various heuristics were implemented to make the
returned set of categories uniform in length and
depth, up-to-date, and readable.
Once the categorizer assigned a set of cate-
gories to a topic, a disambiguator module deter-
mined whether the assigned categories could be
assigned to a single thing using a set of disambigu-
ating features learned from the DMOZ data itself.
For example, for the topic ‘Saturn’, the assigned
categories included ‘Science/Astronomy’, ‘Recrea-
</bodyText>
<figureCaption confidence="0.971874">
Figure 1 Retriever Topic Page &amp;quot;Mario Lemieux&amp;quot;
</figureCaption>
<bodyText confidence="0.999752">
An initial run of about 60K topics was initiated in
December, 2005; this run yielded approximately
30K Retriever topic pages, each of which can have
multiple display pages. Retriever topics that had
fewer than three paragraphs or which were catego-
rized as pornographic were automatically deleted.
The biggest source of topic candidates was Lycos’s
own query logs. A diverse set of topics was chosen
in order to see which types of topics generated the
best Retriever pages.
</bodyText>
<sectionHeader confidence="0.984422" genericHeader="method">
5 Topic Categorization &amp; Disambiguation
</sectionHeader>
<bodyText confidence="0.999886">
tion/Autos’ and ‘Computers/Video Games’ (Sega
Saturn). The disambiguator detected the presence
of feature pairs in these that indicated more than
one topic. Therefore, it clustered the assigned
categories into groups for the car-, astronomy- and
video-game-senses of the topic and assigned each
group a discriminative term which was used to dis-
ambiguate the topic: Saturn (Auto), Saturn (Solar
System), Saturn (Video Game). Retriever returned
pages only for topics that were believed to be dis-
ambiguated according to DMOZ. If no categories
</bodyText>
<footnote confidence="0.928087">
5 http://www.dmoz.com
</footnote>
<page confidence="0.992439">
178
</page>
<bodyText confidence="0.999956">
were identified via DMOZ, a default Other cate-
gory was assigned unless the system guessed that
the topic was a personal name, based on its com-
ponents.
The live system assigns non-default categories
with 86.5% precision; a revised algorithm achieved
93.0% precision, both based on an evaluation of
982 topics. However, our precision on identifying
unambiguous topics with DMOZ was only 83%.
Still, this compares well with the 75% precision
achieved on by the best-performing system on a
similar task in the 2005 KDD Cup (Shen 2005).
</bodyText>
<sectionHeader confidence="0.988777" genericHeader="method">
6 Document Retrieval
</sectionHeader>
<bodyText confidence="0.999973777777778">
After a topic was categorized and disambiguated,
the disambiguated topic was used to identify up to
1000 documents from Lycos’ search provider. For
ambiguous topics various terms were added as op-
tional ‘boost’ terms, while terms from other senses
of the ambiguous topic categories were prohibited.
Other query optimization techniques were used to
get the most focused document set, with non-
English and obscene pages filtered out
</bodyText>
<sectionHeader confidence="0.981483" genericHeader="method">
7 Passage Extraction
</sectionHeader>
<bodyText confidence="0.999950826086957">
Each URL for the topic was then fetched. An
HTML parser converted the document into a se-
quence of contiguous text blocks. At this point,
contiguous text passages were identified as being
potentially interesting if they contained an expres-
sion of the topic in the first sentence.
When a passage was identified as being
potentially interesting, it was then fully parsed to
see if an expression denoting the topic was the
Discourse Topic of the passage. Discourse Topic
is an under-theorized notion in linguistic theory:
not all linguists agree that the notion of Discourse
Topic is required in discourse analysis at all (cf.
Asher, 2004). For our purposes, however, we for-
mulated a set of patterns for identifying Discourse
Topics on the basis of the output of the CMU Link
Parser6 the system uses.
Paradigmatically, we counted ordinary
subjects of the first sentence of a passage as ex-
pressive of the Discourse Topic. So, if we found
an expression of the topic there, either in full or
reduced form, we took that as an instance of the
topic appearing as Discourse Topic in that passage
</bodyText>
<footnote confidence="0.611884">
6 http://www.link.cs.cmu.edu/link/
</footnote>
<bodyText confidence="0.999846516129032">
and ranked that passage highly. Of course, not all
Discourse Topics are expressed as subjects, and the
system recognized this.
A crucial aspect of this functionality is to
identify how different sorts of topics can be ex-
pressed in a sentence. To give a simple illustra-
tion, if the system believes that a topic has been
categorized as a personal name, then it accepted
reduced forms of the name as expressions of the
topic (e.g. “Lindsay” and “Lohan” can both be ex-
pressions of the topic “Lindsay Lohan” in certain
contexts); but it does not accept reduced forms in
all cases.
Paragraphs were verified to contain a se-
quence of sentences by parsing the rest of the con-
tiguous text. The verb associated with the
Discourse Topic of the paragraph was recorded for
future use in assembling the topic report. Various
filters for length, keyword density, exophoric ex-
pressions, spam and obscenity were employed. A
score of the intrinsic informativeness of the para-
graph was then assigned, making use of such met-
rics as the length of the paragraph, the number of
unique NPs, the type of verb associated with the
Discourse Topic, and other factors.
Images were thumbnailed and associated with
the extracted paragraph on the basis of matching
text in the image filename, alt-text or description
elements of the tag as well as the size and prox-
imity of the image to the paragraph at hand. We
did not analyze the image itself.
</bodyText>
<sectionHeader confidence="0.516487" genericHeader="method">
8 Subtopic Selection and Report Assembly
</sectionHeader>
<bodyText confidence="0.99994605882353">
Once the system had an array of extracted para-
graphs, ranked by their intrinsic properties, we be-
gan constructing the topic report by populating an
initial ‘overview’ portion of the report with some
of the best-scoring paragraphs overall.
First, Retriever eliminated duplicate and
near-duplicate paragraphs using a spread-activation
algorithm.
Next the system applied question-
answering methodology to order the remaining
paragraphs into a useful overview of the topic:
first, we found the best two paragraphs that say
what the topic is, by finding the best paragraphs
where the topic is the Discourse Topic of the para-
graph and the associated verb is a copula or cop-
ula-like (e.g. be known as). Then, in a similar way,
we found the best few paragraphs that said what
</bodyText>
<page confidence="0.99733">
179
</page>
<bodyText confidence="0.99995475862069">
attributes the topic has. Then, a few paragraphs
that said what the topic does, followed by a few
paragraphs that said what happens to the topic
(how it is used, things it has undergone, and so on).
The remaining paragraphs were then clus-
tered into subtopics by looking at the most frequent
NPs they contain, with two exceptions. First, su-
perstrings of the topic were favored as subtopics in
order to discover complex nominals in which the
topic appears. Secondly, non-reduced forms of
personal names were required as subtopics, even if
a reduced form was more frequent.
Similar heuristics were used to order para-
graphs within the subtopic sections of the topic
report as in the overview section.
Additional constraints were applied to stay
within the boundaries of fair use of potentially
copyrighted material, limiting the amount of con-
tiguous text from any one source.
Topic reports were set to be refreshed by the
system five days after they were generated in order
to reflect any new developments.
In an evaluation of 642 paragraphs, 88.8% were
relevant to the topic; 83.4% relevant to the topic as
categorized. For images, 85.5% of 83 images were
relevant, using a revised algorithm, not the live
system. Of 1861 subtopic paragraphs, 88.5% of
paragraphs were relevant to the assigned topic and
subtopic.
</bodyText>
<sectionHeader confidence="0.998941" genericHeader="discussions">
9 Discussion
</sectionHeader>
<bodyText confidence="0.999988944444445">
Of the over 30K topical reports generated by Re-
triever thus far, some of the reports generated
turned out surprisingly well, while many turned out
poorly. In general, since we paid no attention to
temporal ordering of paragraphs, topics that were
highly temporal did poorly, since we would typi-
cally arrange paragraphs with no regard for event
precedence.
There are many things that remained to be
done with Retriever, including extracting para-
graphs from non-HTML documents, auto-
hyperlinking topics within Retriever pages (as in
Wikipedia), finding more up-to-date sources for
categorization, and verticalizing Retriever page
generation for different types of topics (e.g. treat-
ing movies differently than people and both differ-
ently than diseases). Unfortunately, the project
was essentially discontinued in February, 2006.
</bodyText>
<sectionHeader confidence="0.999652" genericHeader="acknowledgments">
10 Related Work
</sectionHeader>
<bodyText confidence="0.999983533333333">
Although there have been previous systems that
learned to identify and summarize web documents
on a particular topic (Allen et al, 1996) without
attempting to fuse them into a narrative structure,
we are not aware of any project that attempts to
generate coherent, narrative topical summaries by
paragraph extraction and ordering. Much recent
work focuses on multi-article summarization of
news by sentence extraction and ordering (see for
example, Columbia’s well-known Newsblaster
project and Michigan’s NewsInEssence project).
The latest DUC competition similarly emphasized
sentence-level fusion of multi-document summa-
ries from news text (DUC, 2005). One exception is
the ArteQuaKt project (Kim et al, 2002), a proto-
type system for generating artist biographies from
extracted passages and facts found on the Web
aimed at different levels of readers (e.g. grade
school versus university students). The Artequakt
system was to use extracted text both as found and
as generated from facts in a logical representation.
It is not clear how far the ArteQuaKt project pro-
gressed.
Less legitimately, more and more “spam
blogs” repackage snippets from search results or in
other ways appropriate text from original sources
into pages they populate with pay-per-click adver-
tising. Retriever differs from such schemes in fil-
tering out low value content and by making
obscure sources visible.
</bodyText>
<sectionHeader confidence="0.999248" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99972025">
Allen, Brad et al. 1996. WebCompass: an agent-based meta-
search and metadata discovery tool for the Web. SIGIR ’96.
Asher,Nicholas. 2004. Discourse Topic, Theoretical Linguis-
tics. 30:2-3
DUC. 2005 DUC Workshop. Vancouver, BC
Kim, Sanghee et al. 2002. Artequakt: Generating Talored Bi-
ographies from Automatically Annotated Fragments from
the Web. In Proceedings of Workshop on Semantic Author-
ing, Annotation &amp; Knowledge Markup (SAAKM’02).
pp. 1-6, Lyon, France.
Liu, Bing, et al. 2003. Mining Topic-Specific Concepts and
Definitions on the Web. Proceedings of the Twelfth Inter-
national World Wide Web Conference (WWW-2003),
Shen, Dou et al, Q2C@UST: Our Winning Solution to Query
Classification in KDDCUP 2005. ACM KDD Explora-
tions. Vol 7, no. 2. December 2005.
</reference>
<page confidence="0.997762">
180
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.710013">
<title confidence="0.999474">Lycos Retriever: An Information Fusion Engine</title>
<author confidence="0.999878">Brian Ulicny</author>
<affiliation confidence="0.997059">Versatile Information Systems,</affiliation>
<address confidence="0.861895">5 Mountainview Framingham, MA 01701</address>
<email confidence="0.999843">bulicny@vistology.com</email>
<abstract confidence="0.9965976">This paper describes the Lycos Retriever system, a deployed system for automatically generating coherent topical summaries of popular web query topics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Brad Allen</author>
</authors>
<title>WebCompass: an agent-based metasearch and metadata discovery tool for the Web.</title>
<date>1996</date>
<journal>SIGIR</journal>
<volume>96</volume>
<marker>Allen, 1996</marker>
<rawString>Allen, Brad et al. 1996. WebCompass: an agent-based metasearch and metadata discovery tool for the Web. SIGIR ’96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
</authors>
<title>Discourse Topic, Theoretical Linguistics.</title>
<date>2004</date>
<pages>30--2</pages>
<contexts>
<context position="7360" citStr="Asher, 2004" startWordPosition="1136" endWordPosition="1137">was then fetched. An HTML parser converted the document into a sequence of contiguous text blocks. At this point, contiguous text passages were identified as being potentially interesting if they contained an expression of the topic in the first sentence. When a passage was identified as being potentially interesting, it was then fully parsed to see if an expression denoting the topic was the Discourse Topic of the passage. Discourse Topic is an under-theorized notion in linguistic theory: not all linguists agree that the notion of Discourse Topic is required in discourse analysis at all (cf. Asher, 2004). For our purposes, however, we formulated a set of patterns for identifying Discourse Topics on the basis of the output of the CMU Link Parser6 the system uses. Paradigmatically, we counted ordinary subjects of the first sentence of a passage as expressive of the Discourse Topic. So, if we found an expression of the topic there, either in full or reduced form, we took that as an instance of the topic appearing as Discourse Topic in that passage 6 http://www.link.cs.cmu.edu/link/ and ranked that passage highly. Of course, not all Discourse Topics are expressed as subjects, and the system recog</context>
</contexts>
<marker>Asher, 2004</marker>
<rawString>Asher,Nicholas. 2004. Discourse Topic, Theoretical Linguistics. 30:2-3</rawString>
</citation>
<citation valid="true">
<authors>
<author>DUC</author>
</authors>
<title>DUC Workshop.</title>
<date>2005</date>
<location>Vancouver, BC</location>
<contexts>
<context position="12890" citStr="DUC, 2005" startWordPosition="2034" endWordPosition="2035">at learned to identify and summarize web documents on a particular topic (Allen et al, 1996) without attempting to fuse them into a narrative structure, we are not aware of any project that attempts to generate coherent, narrative topical summaries by paragraph extraction and ordering. Much recent work focuses on multi-article summarization of news by sentence extraction and ordering (see for example, Columbia’s well-known Newsblaster project and Michigan’s NewsInEssence project). The latest DUC competition similarly emphasized sentence-level fusion of multi-document summaries from news text (DUC, 2005). One exception is the ArteQuaKt project (Kim et al, 2002), a prototype system for generating artist biographies from extracted passages and facts found on the Web aimed at different levels of readers (e.g. grade school versus university students). The Artequakt system was to use extracted text both as found and as generated from facts in a logical representation. It is not clear how far the ArteQuaKt project progressed. Less legitimately, more and more “spam blogs” repackage snippets from search results or in other ways appropriate text from original sources into pages they populate with pay-</context>
</contexts>
<marker>DUC, 2005</marker>
<rawString>DUC. 2005 DUC Workshop. Vancouver, BC</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sanghee Kim</author>
</authors>
<title>Artequakt: Generating Talored Biographies from Automatically Annotated Fragments from the Web. In</title>
<date>2002</date>
<booktitle>Proceedings of Workshop on Semantic Authoring, Annotation &amp; Knowledge Markup (SAAKM’02).</booktitle>
<pages>1--6</pages>
<location>Lyon, France.</location>
<marker>Kim, 2002</marker>
<rawString>Kim, Sanghee et al. 2002. Artequakt: Generating Talored Biographies from Automatically Annotated Fragments from the Web. In Proceedings of Workshop on Semantic Authoring, Annotation &amp; Knowledge Markup (SAAKM’02). pp. 1-6, Lyon, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Liu</author>
</authors>
<title>Mining Topic-Specific Concepts and Definitions on the Web.</title>
<date>2003</date>
<booktitle>Proceedings of the Twelfth International World Wide Web Conference (WWW-2003),</booktitle>
<contexts>
<context position="2859" citStr="Liu, 2003" startWordPosition="452" endWordPosition="453">wers, “What do I need to know about this topic?” for the most popular topics on the Web.3 3 Lycos Retriever pages Figure 1 shows a sample Retriever page for the topic “Mario Lemieux”.4 The topic is indicated at the upper left. Below it is a category assigned to the topic, in this case Sports &gt; Hockey &gt; Ice Hockey &gt; National Hockey League &gt; Lemieux, Mario. The main body of the page is a set of paragraphs beginning with a biographical paragraph complete with Lemieux’s birth date, height, weight and position extracted from Nationmaster.com, followed by paragraphs outlining his career from 3 See (Liu, 2003) for a similarly motivated system. 4 For other categories, see e.g. King Kong (1933): http://www.lycos.com/info/king-kong-1933.html, Zoloft: http://www.lycos.com/info/zoloft.html, Public-Key Cryptography: http://www.lycos.com/info/publickey-cryptography.html , Lyme Disease: http://www.lycos.com/info/lyme-disease.html, Reggaeton: http://www.lycos.com/info/reggaeton.html 177 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 177–180, New York, June 2006. c�2006 Association for Computational Linguistics other sources. The source for each extrac</context>
</contexts>
<marker>Liu, 2003</marker>
<rawString>Liu, Bing, et al. 2003. Mining Topic-Specific Concepts and Definitions on the Web. Proceedings of the Twelfth International World Wide Web Conference (WWW-2003),</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dou Shen</author>
</authors>
<title>Q2C@UST: Our Winning Solution to Query Classification in KDDCUP</title>
<date>2005</date>
<journal>ACM KDD Explorations.</journal>
<volume>7</volume>
<contexts>
<context position="6252" citStr="Shen 2005" startWordPosition="958" endWordPosition="959"> be disambiguated according to DMOZ. If no categories 5 http://www.dmoz.com 178 were identified via DMOZ, a default Other category was assigned unless the system guessed that the topic was a personal name, based on its components. The live system assigns non-default categories with 86.5% precision; a revised algorithm achieved 93.0% precision, both based on an evaluation of 982 topics. However, our precision on identifying unambiguous topics with DMOZ was only 83%. Still, this compares well with the 75% precision achieved on by the best-performing system on a similar task in the 2005 KDD Cup (Shen 2005). 6 Document Retrieval After a topic was categorized and disambiguated, the disambiguated topic was used to identify up to 1000 documents from Lycos’ search provider. For ambiguous topics various terms were added as optional ‘boost’ terms, while terms from other senses of the ambiguous topic categories were prohibited. Other query optimization techniques were used to get the most focused document set, with nonEnglish and obscene pages filtered out 7 Passage Extraction Each URL for the topic was then fetched. An HTML parser converted the document into a sequence of contiguous text blocks. At th</context>
</contexts>
<marker>Shen, 2005</marker>
<rawString>Shen, Dou et al, Q2C@UST: Our Winning Solution to Query Classification in KDDCUP 2005. ACM KDD Explorations. Vol 7, no. 2. December 2005.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>