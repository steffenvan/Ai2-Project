<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.989406">
Rebanking CCGbank for improved NP interpretation
</title>
<author confidence="0.997653">
Matthew Honnibal and James R. Curran
</author>
<affiliation confidence="0.995536">
School of Information Technologies
University of Sydney
</affiliation>
<address confidence="0.436253">
NSW 2006, Australia
</address>
<email confidence="0.995328">
{mhonn,james}@it.usyd.edu.au
</email>
<note confidence="0.550471">
Johan Bos
University of Groningen
The Netherlands
</note>
<email confidence="0.806797">
bos@meaningfactory.com
</email>
<sectionHeader confidence="0.995215" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999615176470588">
Once released, treebanks tend to remain
unchanged despite any shortcomings in
their depth of linguistic analysis or cover-
age of specific phenomena. Instead, sepa-
rate resources are created to address such
problems. In this paper we show how to
improve the quality of a treebank, by in-
tegrating resources and implementing im-
proved analyses for specific constructions.
We demonstrate this rebanking process
by creating an updated version of CCG-
bank that includes the predicate-argument
structure of both verbs and nouns, base-
NP brackets, verb-particle constructions,
and restrictive and non-restrictive nominal
modifiers; and evaluate the impact of these
changes on a statistical parser.
</bodyText>
<sectionHeader confidence="0.999516" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99971811627907">
Progress in natural language processing relies on
direct comparison on shared data, discouraging
improvements to the evaluation data. This means
that we often spend years competing to reproduce
partially incorrect annotations. It also encourages
us to approach related problems as discrete tasks,
when a new data set that adds deeper information
establishes a new incompatible evaluation.
Direct comparison has been central to progress
in statistical parsing, but it has also caused prob-
lems. Treebanking is a difficult engineering task:
coverage, cost, consistency and granularity are all
competing concerns that must be balanced against
each other when the annotation scheme is devel-
oped. The difficulty of the task means that we
ought to view treebanking as an ongoing process
akin to grammar development, such as the many
years of work on the ERG (Flickinger, 2000).
This paper demonstrates how a treebank can be
rebanked to incorporate novel analyses and infor-
mation from existing resources. We chose to work
on CCGbank (Hockenmaier and Steedman, 2007),
a Combinatory Categorial Grammar (Steedman,
2000) treebank acquired from the Penn Treebank
(Marcus et al., 1993). This work is equally ap-
plicable to the corpora described by Miyao et al.
(2004), Shen et al. (2008) or Cahill et al. (2008).
Our first changes integrate four previously sug-
gested improvements to CCGbank. We then de-
scribe a novel CCG analysis of NP predicate-
argument structure, which we implement using
NomBank (Meyers et al., 2004). Our analysis al-
lows the distinction between core and peripheral
arguments to be represented for predicate nouns.
With this distinction, an entailment recognition
system could recognise that Google’s acquisition
of YouTube entailed Google acquired YouTube, be-
cause equivalent predicate-argument structures are
built for both. Our analysis also recovers non-
local dependencies mediated by nominal predi-
cates; for instance, Google is the agent of acquire
in Google’s decision to acquire YouTube.
The rebanked corpus extends CCGbank with:
</bodyText>
<listItem confidence="0.998285714285714">
1. NP brackets from Vadas and Curran (2008);
2. Restored and normalised punctuation;
3. Propbank-derived verb subcategorisation;
4. Verb particle structure drawn from Propbank;
5. Restrictive and non-restrictive adnominals;
6. Reanalyses to promote better head-finding;
7. Nombank-derived noun subcategorisation.
</listItem>
<bodyText confidence="0.999815571428571">
Together, these changes modify 30% of the la-
belled dependencies in CCGbank, demonstrating
how multiple resources can be brought together in
a single, richly annotated corpus. We then train
and evaluate a parser for these changes, to investi-
gate their impact on the accuracy of a state-of-the-
art statistical CCG parser.
</bodyText>
<page confidence="0.968642">
207
</page>
<note confidence="0.969331">
Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 207–215,
Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.884389" genericHeader="introduction">
2 Background and motivation
</sectionHeader>
<bodyText confidence="0.99995408">
Formalisms like HPSG (Pollard and Sag, 1994),
LFG (Kaplan and Bresnan, 1982), and CCG (Steed-
man, 2000) are linguistically motivated in the
sense that they attempt to explain and predict
the limited variation found in the grammars of
natural languages. They also attempt to spec-
ify how grammars construct semantic representa-
tions from surface strings, which is why they are
sometimes referred to as deep grammars. Anal-
yses produced by these formalisms can be more
detailed than those produced by skeletal phrase-
structure parsers, because they produce fully spec-
ified predicate-argument structures.
Unfortunately, statistical parsers do not take ad-
vantage of this potential detail. Statistical parsers
induce their grammars from corpora, and the
corpora for linguistically motivated formalisms
currently do not contain high quality predicate-
argument annotation, because they were derived
from the Penn Treebank (PTB Marcus et al., 1993).
Manually written grammars for these formalisms,
such as the ERG HPSG grammar (Flickinger, 2000)
and the XLE LFG grammar (Butt et al., 2006)
produce far more detailed and linguistically cor-
rect analyses than any English statistical parser,
due to the comparatively coarse-grained annota-
tion schemes of the corpora statistical parsers are
trained on. While rule-based parsers use gram-
mars that are carefully engineered (e.g. Oepen
et al., 2004), and can be updated to reflect the best
linguistic analyses, statistical parsers have so far
had to take what they are given.
What we suggest in this paper is that a tree-
bank’s grammar need not last its lifetime. For a
start, there have been many annotations of the PTB
that add much of the extra information needed to
produce very high quality analyses for a linguis-
tically motivated grammar. There are also other
transformations which can be made with no addi-
tional information. That is, sometimes the existing
trees allow transformation rules to be written that
improve the quality of the grammar.
Linguistic theories are constantly changing,
which means that there is a substantial lag between
what we (think we) understand of grammar and
the annotations in our corpora. The grammar en-
gineering process we describe, which we dub re-
banking, is intended to reduce this gap, tightening
the feedback loop between formal and computa-
tional linguistics.
</bodyText>
<subsectionHeader confidence="0.976554">
2.1 Combinatory Categorial Grammar
</subsectionHeader>
<bodyText confidence="0.999925590909091">
Combinatory Categorial Grammar (CCG; Steed-
man, 2000) is a lexicalised grammar, which means
that all grammatical dependencies are specified
in the lexical entries and that the production of
derivations is governed by a small set of rules.
Lexical categories are either atomic (S, NP,
PP, N), or a functor consisting of a result, direc-
tional slash, and argument. For instance, in might
head a PP-typed constituent with one NP-typed
argument, written as PP/NP.
A category can have a functor as its result, so
that a word can have a complex valency structure.
For instance, a verb phrase is represented by the
category S\NP: it is a function from a leftward
NP (a subject) to a sentence. A transitive verb
requires an object to become a verb phrase, pro-
ducing the category (S\NP)/NP.
A CCG grammar consists of a small number of
schematic rules, called combinators. CCG extends
the basic application rules of pure categorial gram-
mar with (generalised) composition rules and type
raising. The most common rules are:
</bodyText>
<equation confidence="0.9912632">
X/Y Y X (&gt;)
Y X\Y X (&lt;)
X/Y Y /Z X/Z (&gt;B)
Y \Z X\Y X\Z (&lt;B)
Y /Z X\Y X/Z (&lt;B,)
</equation>
<bodyText confidence="0.999811714285714">
CCGbank (Hockenmaier and Steedman, 2007)
extends this compact set of combinatory rules with
a set of type-changing rules, designed to strike a
better balance between sparsity in the category set
and ambiguity in the grammar. We mark type-
changing rules TC in our derivations.
In wide-coverage descriptions, categories are
generally modelled as typed-feature structures
(Shieber, 1986), rather than atomic symbols. This
allows the grammar to include a notion of headed-
ness, and to unify under-specified features.
We occasionally must refer to these additional
details, for which we employ the following no-
tation. Features are annotated in square-brackets,
e.g. S[dcl]. Head-finding indices are annotated on
categories in subscripts, e.g. (NPy\NPy)/NP..
The index of the word the category is assigned to
is left implicit. We will sometimes also annotate
derivations with the heads of categories as they are
being built, to help the reader keep track of what
lexemes have been bound to which categories.
</bodyText>
<page confidence="0.998756">
208
</page>
<sectionHeader confidence="0.980803" genericHeader="method">
3 Combining CCGbank corrections
</sectionHeader>
<bodyText confidence="0.999981">
There have been a few papers describing correc-
tions to CCGbank. We bring these corrections to-
gether for the first time, before building on them
with our further changes.
</bodyText>
<subsectionHeader confidence="0.999522">
3.1 Compound noun brackets
</subsectionHeader>
<bodyText confidence="0.9982105">
Compound noun phrases can nest inside each
other, creating bracketing ambiguities:
</bodyText>
<listItem confidence="0.817114">
(1) (crude oil) prices
</listItem>
<subsectionHeader confidence="0.999318">
3.3 Verb predicate-argument corrections
</subsectionHeader>
<bodyText confidence="0.999264571428571">
Semantic role descriptions generally recognise a
distinction between core arguments, whose role
comes from a set specific to the predicate, and pe-
ripheral arguments, who have a role drawn from a
small, generic set. This distinction is represented
in the surface syntax in CCG, because the category
of a verb must specify its argument structure. In
</bodyText>
<listItem confidence="0.9979115">
(3) as a director is annotated as a complement; in
(4) it is an adjunct:
(3) He joined as a director
(2) crude (oil prices) NP (S\NP)/PP PP
</listItem>
<bodyText confidence="0.999876173913044">
The structure of such compound noun phrases
is left underspecified in the Penn Treebank (PTB),
because the annotation procedure involved stitch-
ing together partial parses produced by the Fid-
ditch parser (Hindle, 1983), which produced flat
brackets for these constructions. The bracketing
decision was also a source of annotator disagree-
ment (Bies et al., 1995).
When Hockenmaier and Steedman (2002) went
to acquire a CCG treebank from the PTB, this posed
a problem. There is no equivalent way to leave
these structures under-specified in CCG, because
derivations must be binary branching. They there-
fore employed a simple heuristic: assume all such
structures branch to the right. Under this analysis,
crude oil is not a constituent, producing an incor-
rect analysis as in (1).
Vadas and Curran (2007) addressed this by
manually annotating all of the ambiguous noun
phrases in the PTB, and went on to use this infor-
mation to correct 20,409 dependencies (1.95%) in
CCGbank (Vadas and Curran, 2008). Our changes
build on this corrected corpus.
</bodyText>
<subsectionHeader confidence="0.999899">
3.2 Punctuation corrections
</subsectionHeader>
<bodyText confidence="0.996725615384615">
The syntactic analysis of punctuation is noto-
riously difficult, and punctuation is not always
treated consistently in the Penn Treebank (Bies
et al., 1995). Hockenmaier (2003) determined
that quotation marks were particularly problem-
atic, and therefore removed them from CCGbank
altogether. We use the process described by Tse
and Curran (2008) to restore the quotation marks
and shift commas so that they always attach to the
constituent to their left. This allows a grammar
rule to be removed, preventing a great deal of spu-
rious ambiguity and improving the speed of the
C&amp;C parser (Clark and Curran, 2007) by 37%.
</bodyText>
<listItem confidence="0.9935795">
(4) He joined as a director
NP S\NP (S\NP)\(S\NP)
</listItem>
<bodyText confidence="0.994357571428571">
CCGbank contains noisy complement and ad-
junct distinctions, because they were drawn from
PTB function labels which imperfectly represent
the distinction. In our previous work we used
Propbank (Palmer et al., 2005) to convert 1,543
complements to adjuncts and 13,256 adjuncts to
complements (Honnibal and Curran, 2007). If a
constituent such as as a director received an ad-
junct category, but was labelled as a core argu-
ment in Propbank, we changed it to a comple-
ment, using its head’s part-of-speech tag to infer
its constituent type. We performed the equivalent
transformation to ensure all peripheral arguments
of verbs were analysed as adjuncts.
</bodyText>
<subsectionHeader confidence="0.97668">
3.4 Verb-particle constructions
</subsectionHeader>
<bodyText confidence="0.98908975">
Propbank also offers reliable annotation of verb-
particle constructions. This was not available in
the PTB, so Hockenmaier and Steedman (2007)
annotated all intransitive prepositions as adjuncts:
</bodyText>
<listItem confidence="0.7408605">
(5) He woke up
NP S\NP (S\NP)\(S\NP)
</listItem>
<bodyText confidence="0.870701">
We follow Constable and Curran (2009) in ex-
ploiting the Propbank annotations to add verb-
particle distinctions to CCGbank, by introducing a
new atomic category PT for particles, and chang-
ing their status from adjuncts to complements:
</bodyText>
<listItem confidence="0.989651">
(6) He woke up
NP (S\NP)/PT PT
</listItem>
<bodyText confidence="0.999545">
This analysis could be improved by adding extra
head-finding logic to the verbal category, to recog-
nise the multi-word expression as the head.
</bodyText>
<page confidence="0.989537">
209
</page>
<figure confidence="0.950399555555556">
Rome &apos;s gift of peace to Europe
NP (NP/(N/PP))\NP (N/PP)/PP)/PP PP/NP NP PP/NP NP
&lt; &gt; &gt;
N/(N/PP) PP PP
&gt;
(N/PP)/PP &gt;
&gt;
N/PP
NP
</figure>
<figureCaption confidence="0.998849">
Figure 1: Deverbal noun predicate with agent, patient and beneficiary arguments.
</figureCaption>
<sectionHeader confidence="0.959058" genericHeader="method">
4 Noun predicate-argument structure
</sectionHeader>
<bodyText confidence="0.999733857142857">
Many common nouns in English can receive
optional complements and adjuncts, realised by
prepositional phrases, genitive determiners, com-
pound nouns, relative clauses, and for some nouns,
complementised clauses. For example, deverbal
nouns generally have argument structures similar
to the verbs they are derived from:
</bodyText>
<listItem confidence="0.9959975">
(7) Rome’s destruction of Carthage
(8) Rome destroyed Carthage
</listItem>
<bodyText confidence="0.9981055">
The semantic roles of Rome and Carthage are the
same in (7) and (8), but the noun cannot case-
mark them directly, so of and the genitive clitic
are pressed into service. The semantic role de-
pends on both the predicate and subcategorisation
frame:
</bodyText>
<listItem confidence="0.999637">
(9) Carthage’sp destructionPred.
(10) Rome’sa destructionPred. of Carthagep
(11) Rome’sa giftPred.
(12) Rome’sa giftPred. of peacep to Europeb
</listItem>
<bodyText confidence="0.999186571428571">
In (9), the genitive introduces the patient, but
when the patient is supplied by the PP, it instead
introduces the agent. The mapping differs for gift,
where the genitive introduces the agent.
Peripheral arguments, which supply generically
available modifiers of time, place, cause, quality
etc, can be realised by pre- and post-modifiers:
</bodyText>
<listItem confidence="0.935535333333333">
(13) The portrait in the Louvre
(14) The fine portrait
(15) The Louvre’s portraits
</listItem>
<bodyText confidence="0.999912111111111">
These are distinct from core arguments because
their interpretation does not depend on the pred-
icate. The ambiguity can be seen in an NP such as
The nobleman’s portrait, where the genitive could
mark possession (peripheral), or it could introduce
the patient (core). The distinction between core
and peripheral arguments is particularly difficult
for compound nouns, as pre-modification is very
productive in English.
</bodyText>
<subsectionHeader confidence="0.999593">
4.1 CCG analysis
</subsectionHeader>
<bodyText confidence="0.942433857142857">
We designed our analysis for transparency be-
tween the syntax and the predicate-argument
structure, by stipulating that all and only the core
arguments should be syntactic arguments of the
predicate’s category. This is fairly straightforward
for arguments introduced by prepositions:
destruction of Carthage
</bodyText>
<equation confidence="0.924843">
N/PPy PPy/NPy NP
&gt;
&gt;
</equation>
<bodyText confidence="0.922945421052632">
In our analysis, the head of of Carthage is
Carthage, as of is assumed to be a semantically
transparent case-marker. We apply this analysis
to prepositional phrases that provide arguments to
verbs as well — a departure from CCGbank.
Prepositional phrases that introduce peripheral
arguments are analysed as syntactic adjuncts:
The war in 149 B.C.
NPy/Ny N (Ny\Ny)/NPz NP
&gt;
&lt;
NPwar
Adjunct prepositional phrases remain headed by
the preposition, as it is the preposition’s semantics
that determines whether they function as temporal,
causal, spatial etc. arguments. We follow Hocken-
maier and Steedman (2007) in our analysis of gen-
itives which realise peripheral arguments, such as
the literal possessive:
</bodyText>
<equation confidence="0.739684666666667">
Rome is aqueducts
NP (NPy/Ny)\NPz N
&lt;
</equation>
<bodyText confidence="0.968845142857143">
NPaqueducts
Arguments introduced by possessives are a lit-
tle trickier, because the genitive also functions as
a determiner. We achieve this by having the noun
subcategorise for the argument, which we type
PP, and having the possessive subcategorise for
the unsaturated noun to ultimately produce an NP:
</bodyText>
<figure confidence="0.971767">
PPCarthage
Ndestruction
(Ny\Ny)in
Nwar
&gt;
(NPy/Ny)&apos;s
&gt;
210
Google &apos;s decision to buy YouTube
NP (NPy/(Ny/PPz)y)\NPz (N/PPy)/(S[to]z\NPy)z (S[to]y\NPz)y/(S[b]y\NPz)y (S[b]\NPy)/NPz NP
&lt;
NPy/(Ny/PPGoogle)y S[b]\NPy
&gt;B &gt;
NPdecision/(S[to]y\NPGoogle)y S[to]buy\NPy
&gt;
NP
</figure>
<figureCaption confidence="0.996301">
Figure 2: The coindexing on decision’s category allows the hard-to-reach agent of buy to be recovered. A non-normal form
derivation is shown so that instantiated variables can be seen.
</figureCaption>
<figure confidence="0.53877325">
&gt;
Carthage is destruction
NP (NPy/(Ny/PPz)y)\NPz N/PPy
&lt;
</figure>
<bodyText confidence="0.991443630434783">
NPdestruction
In this analysis, we regard the genitive clitic as a
case-marker that performs a movement operation
roughly analogous to WH-extraction. Its category
is therefore similar to the one used in object ex-
traction, (N\N)/(S/NP). Figure 1 shows an ex-
ample with multiple core arguments.
This analysis allows recovery of verbal argu-
ments of nominalised raising and control verbs, a
construction which both Gildea and Hockenmaier
(2003) and Boxwell and White (2008) identify as a
problem case when aligning Propbank and CCG-
bank. Our analysis accommodates this construc-
tion effortlessly, as shown in Figure 2. The cate-
gory assigned to decision can coindex the missing
NP argument of buy with its own PP argument.
When that argument is supplied by the genitive,
it is also supplied to the verb, buy, filling its de-
pendency with its agent, Google. This argument
would be quite difficult to recover using a shallow
syntactic analysis, as the path would be quite long.
There are 494 such verb arguments mediated by
nominal predicates in Sections 02-21.
These analyses allow us to draw comple-
ment/adjunct distinctions for nominal predicates,
so that the surface syntax takes us very close to
a full predicate-argument analysis. The only in-
formation we are not specifying in the syntac-
tic analysis are the role labels assigned to each
of the syntactic arguments. We could go further
and express these labels in the syntax, produc-
ing categories like (N/PP{0}y)/PP{1 }z and
(N/PP{1 }y)/PP{0}z, but we expect that this
would cause sparse data problems given the lim-
ited size of the corpus. This experiment would be
an interesting subject of future work.
The only local core arguments that we do not
annotate as syntactic complements are compound
nouns, such as decision makers. We avoided these
arguments because of the productivity of noun-
noun compounding in English, which makes these
argument structures very difficult to recover.
We currently do not have an analysis that allows
support verbs to supply noun arguments, so we
do not recover any of the long-range dependency
structures described by Meyers et al. (2004).
</bodyText>
<subsectionHeader confidence="0.964421">
4.2 Implementation and statistics
</subsectionHeader>
<bodyText confidence="0.999971171428572">
Our analysis requires semantic role labels for each
argument of the nominal predicates in the Penn
Treebank — precisely what NomBank (Meyers
et al., 2004) provides. We can therefore draw our
distinctions using the process described in our pre-
vious work, Honnibal and Curran (2007).
NomBank follows the same format as Prop-
bank, so the procedure is exactly the same. First,
we align CCGbank and the Penn Treebank, and
produce a version of NomBank that refers to CCG-
bank nodes. We then assume that any preposi-
tional phrase or genitive determiner annotated as
a core argument in NomBank should be analysed
as a complement, while peripheral arguments and
adnominals that receive no semantic role label at
all are analysed as adjuncts.
We converted 34,345 adnominal prepositional
phrases to complements, leaving 18,919 as ad-
juncts. The most common preposition converted
was of, which was labelled as a core argument
99.1% of the 19,283 times it occurred as an ad-
nominal. The most common adjunct preposition
was in, which realised a peripheral argument in
59.1% of its 7,725 occurrences.
The frequent prepositions were more skewed to-
wards core arguments. 73% of the occurrences of
the 5 most frequent prepositions (of, in, for, on and
to) realised peripheral arguments, compared with
53% for other prepositions.
Core arguments were also more common than
peripheral arguments for possessives. There are
20,250 possessives in the corpus, of which 75%
were converted to complements. The percentage
was similar for both personal pronouns (such as
his) and genitive phrases (such as the boy’s).
</bodyText>
<figure confidence="0.5747465">
(NPy/(Ny/PPCarthage)y)&apos;s
&gt;
</figure>
<page confidence="0.995536">
211
</page>
<sectionHeader confidence="0.964225" genericHeader="method">
5 Adding restrictivity distinctions
</sectionHeader>
<bodyText confidence="0.996739727272727">
Adnominals can have either a restrictive or a non-
restrictive (appositional) interpretation, determin-
ing the potential reference of the noun phrase
it modifies. This ambiguity manifests itself in
whether prepositional phrases, relative clauses and
other adnominals are analysed as modifiers of
either N or NP, yielding a restrictive or non-
restrictive interpretation respectively.
In CCGbank, all adnominals attach to NPs,
producing non-restrictive interpretations. We
therefore move restrictive adnominals to N nodes:
</bodyText>
<figure confidence="0.625449125">
All staff on casual contracts
NP/N N (N\N)/NP N/N N
�
TC
NP
�
�
NP
</figure>
<bodyText confidence="0.9976025">
This corrects the previous interpretation, which
stated that there were no permanent staff.
</bodyText>
<subsectionHeader confidence="0.988072">
5.1 Implementation and statistics
</subsectionHeader>
<bodyText confidence="0.999908826086956">
The Wall Street Journal’s style guide mandates
that this attachment ambiguity be managed by
bracketing non-restrictive relatives with commas
(Martin, 2002, p. 82), as in casual staff, who have
no health insurance, support it. We thus use punc-
tuation to make the attachment decision.
All NP\NP modifiers that are not preceded by
punctuation were moved to the lowest N node
possible and relabelled N\N. We select the low-
est (i.e. closest to leaf) N node because some ad-
jectives, such as present or former, require scope
over the qualified noun, making it safer to attach
the adnominal first.
Some adnominals in CCGbank are created by
the S\NP —* NP\NP unary type-changing rule,
which transforms reduced relative clauses. We in-
troduce a S\NP —* N\N in its place, and add a
binary rule cued by punctuation to handle the rela-
tively rare non-restrictive reduced relative clauses.
The rebanked corpus contains 34,134 N\N re-
strictive modifiers, and 9,784 non-restrictive mod-
ifiers. Most (61%) of the non-restrictive modifiers
were relative clauses.
</bodyText>
<sectionHeader confidence="0.902161" genericHeader="method">
6 Reanalysing partitive constructions
</sectionHeader>
<bodyText confidence="0.99867075">
True partitive constructions consist of a quantifier
(16), a cardinal (17) or demonstrative (18) applied
to an NP via of. There are similar constructions
headed by common nouns, as in (19):
</bodyText>
<listItem confidence="0.9997795">
(16) Some of us
(17) Four of our members
(18) Those of us who smoke
(19) A glass of wine
</listItem>
<bodyText confidence="0.995401666666667">
We regard the common noun partitives as headed
by the initial noun, such as glass, because this
noun usually controls the number agreement. We
therefore analyse these cases as nouns with prepo-
sitional arguments. In (19), glass would be as-
signed the category N/PP.
True partitive constructions are different, how-
ever: they are always headed by the head of the NP
supplied by of. The construction is quite common,
because it provides a way to quantify or apply two
different determiners.
Partitive constructions are not given special
treatment in the PTB, and were analysed as noun
phrases with a PP modifier in CCGbank:
Four of our members
</bodyText>
<equation confidence="0.664365333333333">
NP (NPy\NPy)/NPz NPy/Ny N
�
�
</equation>
<bodyText confidence="0.958980375">
NPFour
This analysis does not yield the correct seman-
tics, and may even hurt parser performance, be-
cause the head of the phrase is incorrectly as-
signed. We correct this with the following anal-
ysis, which takes the head from the NP argument
of the PP:
Four of our members
</bodyText>
<equation confidence="0.725198666666667">
NPy/PPy PPy/NPy NPy/Ny N
�
�
</equation>
<bodyText confidence="0.937468">
NPmembers
The cardinal is given the category NP/PP,
in analogy with the standard determiner category
which is a function from a noun to a noun phrase
(NP/N).
</bodyText>
<figure confidence="0.9889973">
N
N\N
N
�
NPmembers
(NPy\NPy)of
�
NPmembers
PPmembers
�
</figure>
<page confidence="0.992439">
212
</page>
<table confidence="0.999184875">
Corpus L. DEPS U. DEPS CATS
+NP brackets 97.2 97.7 98.5
+Quotes 97.2 97.7 98.5
+Propbank 93.0 94.9 96.7
+Particles 92.5 94.8 96.2
+Restrictivity 79.5 94.4 90.6
+Part. Gen. 76.1 90.1 90.4
+NP Pred-Arg 70.6 83.3 84.8
</table>
<tableCaption confidence="0.9632485">
Table 1: Effect of the changes on CCGbank, by percentage
of dependencies and categories left unchanged in Section 00.
</tableCaption>
<subsectionHeader confidence="0.999404">
6.1 Implementation and Statistics
</subsectionHeader>
<bodyText confidence="0.9989654">
We detect this construction by identifying NPs
post-modified by an of PP. The NP’s head must
either have the POS tag CD, or be one of the follow-
ing words, determined through manual inspection
of Sections 02-21:
</bodyText>
<construct confidence="0.58036225">
all, another, average, both, each, another, any,
anything, both, certain, each, either, enough, few,
little, most, much, neither, nothing, other, part,
plenty, several, some, something, that, those.
</construct>
<bodyText confidence="0.9984305">
Having identified the construction, we simply rela-
bel the NP to NP/PP, and the NP\NP adnom-
inal to PP. We identified and reanalysed 3,010
partitive genitives in CCGbank.
</bodyText>
<sectionHeader confidence="0.8751" genericHeader="method">
7 Similarity to CCGbank
</sectionHeader>
<bodyText confidence="0.999967045454546">
Table 1 shows the percentage of labelled depen-
dencies (L. Deps), unlabelled dependencies (U.
Deps) and lexical categories (Cats) that remained
the same after each set of changes.
A labelled dependency is a 4-tuple consisting of
the head, the argument, the lexical category of the
head, and the argument slot that the dependency
fills. For instance, the subject fills slot 1 and the
object fills slot 2 on the transitive verb category
(S\NP)/NP. There are more changes to labelled
dependencies than lexical categories because one
lexical category change alters all of the dependen-
cies headed by a predicate, as they all depend on
its lexical category. Unlabelled dependencies con-
sist of only the head and argument.
The biggest changes were those described in
Sections 4 and 5. After the addition of nominal
predicate-argument structure, over 50% of the la-
belled dependencies were changed. Many of these
changes involved changing an adjunct to a com-
plement, which affects the unlabelled dependen-
cies because the head and argument are inverted.
</bodyText>
<sectionHeader confidence="0.919588" genericHeader="method">
8 Lexicon statistics
</sectionHeader>
<bodyText confidence="0.998333333333333">
Our changes make the grammar sensitive to new
distinctions, which increases the number of lexi-
cal categories required. Table 2 shows the number
</bodyText>
<table confidence="0.998775111111111">
Corpus CATS Cats &gt; 10 CATS/WORD
CCGbank 1286 425 8.6
+NP brackets 1298 429 8.9
+Quotes 1300 431 8.8
+Propbank 1342 433 8.9
+Particles 1405 458 9.1
+Restrictivity 1447 471 9.3
+Part. Gen. 1455 474 9.5
+NP Pred-Arg 1574 511 10.1
</table>
<tableCaption confidence="0.999689">
Table 2: Effect of the changes on the size of the lexicon.
</tableCaption>
<bodyText confidence="0.99994548">
of lexical categories (Cats), the number of lexical
categories that occur at least 10 times in Sections
02-21 (Cats &gt; 10), and the average number of cat-
egories available for assignment to each token in
Section 00 (Cats/Word). We followed Clark and
Curran’s (2007) process to determine the set of
categories a word could receive, which includes
a part-of-speech back-off for infrequent words.
The lexicon steadily grew with each set of
changes, because each added information to the
corpus. The addition of quotes only added two cat-
egories (LQU and RQU), and the addition of the
quote tokens slightly decreased the average cate-
gories per word. The Propbank and verb-particle
changes both introduced rare categories for com-
plicated, infrequent argument structures.
The NP predicate-argument structure modifica-
tions added the most information. Head nouns
were previously guaranteed the category N in
CCGbank; possessive clitics always received the
category (NPIN)\NP; and possessive personal
pronouns were always NP/N. Our changes in-
troduce new categories for these frequent tokens,
which meant a substantial increase in the number
of possible categories per word.
</bodyText>
<sectionHeader confidence="0.625235" genericHeader="method">
9 Parsing Evaluation
</sectionHeader>
<bodyText confidence="0.999874066666667">
Some of the changes we have made correct prob-
lems that have caused the performance of a sta-
tistical CCG parser to be over-estimated. Other
changes introduce new distinctions, which a parser
may or may not find difficult to reproduce. To in-
vestigate these issues, we trained and evaluated the
C&amp;C CCG parser on our rebanked corpora.
The experiments were set up as follows. We
used the highest scoring configuration described
by Clark and Curran (2007), the hybrid depen-
dency model, using gold-standard POS tags. We
followed Clark and Curran in excluding sentences
that could not be parsed from the evaluation. All
models obtained similar coverage, between 99.0
and 99.3%. The parser was evaluated using depen-
</bodyText>
<page confidence="0.997417">
213
</page>
<table confidence="0.999746625">
Corpus LF WSJ 00 CAT LF WSJ 23 CAT
OF OF
CCGbank 87.2 92.9 94.1 87.7 93.0 94.4
+NP brackets 86.9 92.8 93.8 87.3 92.8 93.9
+Quotes 86.8 92.7 93.9 87.1 92.6 94.0
+Propbank 86.7 92.6 94.0 87.0 92.6 94.0
+Particles 86.4 92.5 93.8 86.8 92.6 93.8
All Rebanking 84.2 91.2 91.9 84.7 91.3 92.2
</table>
<tableCaption confidence="0.994005">
Table 3: Parser evaluation on the rebanked corpora.
</tableCaption>
<table confidence="0.999724">
Corpus Rebanked CCGbank
LF OF LF OF
+NP brackets 86.45 92.36 86.52 92.35
+Quotes 86.57 92.40 86.52 92.35
+Propbank 87.76 92.96 87.74 92.99
+Particles 87.50 92.77 87.67 92.93
All Rebanking 87.23 92.71 88.02 93.51
</table>
<tableCaption confidence="0.982341">
Table 4: Comparison of parsers trained on CCGbank and
the rebanked corpora, using dependencies that occur in both.
</tableCaption>
<bodyText confidence="0.998765">
dencies generated from the gold-standard deriva-
tions (Boxwell, p.c., 2010).
Table 3 shows the accuracy of the parser on Sec-
tions 00 and 23. The parser scored slightly lower
as the NP brackets, Quotes, Propbank and Parti-
cles corrections were added. This apparent decline
in performance is at least partially an artefact of
the evaluation. CCGbank contains some depen-
dencies that are trivial to recover, because Hock-
enmaier and Steedman (2007) was forced to adopt
a strictly right-branching analysis for NP brackets.
There was a larger drop in accuracy on the
fully rebanked corpus, which included our anal-
yses of restrictivity, partitive constructions and
noun predicate-argument structure. This might
also be explained by the evaluation, as the re-
banked corpus includes much more fine-grained
distinctions. The labelled dependencies evaluation
is particularly sensitive to this, as a single category
change affects multiple dependencies. This can be
seen in the smaller gap in category accuracy.
We investigated whether the differences in per-
formance were due to the different evaluation data
by comparing the parsers’ performance against the
original parser on the dependencies they agreed
upon, to allow direct comparison. To do this, we
extracted the CCGbank intersection of each cor-
pus’s Section 00 dependencies.
Table 4 compares the labelled and unlabelled re-
call of the rebanked parsers we trained against the
CCGbank parser on these intersections. Note that
each row refers to a different intersection, so re-
sults are not comparable between rows. This com-
parison shows that the declines in accuracy seen in
Table 3 were largely confined to the corrected de-
pendencies. The parser’s performance remained
fairly stable on the dependencies left unchanged.
The rebanked parser performed 0.8% worse
than the CCGbank parser on the intersection de-
pendencies, suggesting that the fine-grained dis-
tinctions we introduced did cause some sparse data
problems. However, we did not change any of
the parser’s maximum entropy features or hyper-
parameters, which are tuned for CCGbank.
</bodyText>
<sectionHeader confidence="0.993745" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.999890102564103">
Research in natural language understanding is
driven by the datasets that we have available. The
most cited computational linguistics work to date
is the Penn Treebank (Marcus et al., 1993)1. Prop-
bank (Palmer et al., 2005) has also been very
influential since its release, and NomBank has
been used for semantic dependency parsing in the
CoNLL 2008 and 2009 shared tasks.
This paper has described how these resources
can be jointly exploited using a linguistically moti-
vated theory of syntax and semantics. The seman-
tic annotations provided by Propbank and Nom-
Bank allowed us to build a corpus that takes much
greater advantage of the semantic transparency
of a deep grammar, using careful analyses and
phenomenon-specific conversion rules.
The major areas of CCGbank’s grammar left to
be improved are the analysis of comparatives, and
the analysis of named entities. English compar-
atives are diverse and difficult to analyse. Even
the XTAG grammar (Doran et al., 1994), which
deals with the major constructions of English in
enviable detail, does not offer a full analysis of
these phenomena. Named entities are also difficult
to analyse, as many entity types obey their own
specific grammars. This is another example of a
phenomenon that could be analysed much better
in CCGbank using an existing resource, the BBN
named entity corpus.
Our rebanking has substantially improved
CCGbank, by increasing the granularity and lin-
guistic fidelity of its analyses. We achieved this
by exploiting existing resources and crafting novel
analyses. The process we have demonstrated can
be used to train a parser that returns dependencies
that abstract away as much surface syntactic vari-
ation as possible — including, now, even whether
the predicate and arguments are expressed in a
noun phrase or a full clause.
</bodyText>
<footnote confidence="0.988511">
1http://clair.si.umich.edu/clair/anthology/rankings.cgi
</footnote>
<page confidence="0.997877">
214
</page>
<sectionHeader confidence="0.998352" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.917081272727273">
James Curran was supported by Australian Re-
search Council Discovery grant DP1097291 and
the Capital Markets Cooperative Research Centre.
The parsing evaluation for this paper would
have been much more difficult without the assis-
tance of Stephen Boxwell, who helped generate
the gold-standard dependencies with his software.
We are also grateful to the members of the CCG
technicians mailing list for their help crafting the
analyses, particularly Michael White, Mark Steed-
man and Dennis Mehay.
</bodyText>
<sectionHeader confidence="0.999423" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999880495412844">
Ann Bies, Mark Ferguson, Karen Katz, and Robert MacIn-
tyre. 1995. Bracketing guidelines for Treebank II style
Penn Treebank project. Technical report, MS-CIS-95-06,
University of Pennsylvania, Philadelphia, PA, USA.
Stephen Boxwell and Michael White. 2008. Projecting prop-
bank roles onto the CCGbank. In Proceedings of the
Sixth International Language Resources and Evaluation
(LREC’08), pages 3112–3117. European Language Re-
sources Association (ELRA), Marrakech, Morocco.
Miriam Butt, Mary Dalrymple, and Tracy H. King, editors.
2006. Lexical Semantics in LFG. CSLI Publications, Stan-
ford, CA.
Aoife Cahill, Michael Burke, Ruth O’Donovan, Stefan Rie-
zler, Josef van Genabith, and Andy Way. 2008. Wide-
coverage deep statistical parsing using automatic depen-
dency structure annotation. Computational Linguistics,
34(1):81–124.
Stephen Clark and James R. Curran. 2007. Wide-coverage ef-
ficient statistical parsing with CCG and log-linear models.
Computational Linguistics, 33(4):493–552.
James Constable and James Curran. 2009. Integrating verb-
particle constructions into CCG parsing. In Proceedings of
the Australasian Language Technology Association Work-
shop 2009, pages 114–118. Sydney, Australia.
Christy Doran, Dania Egedi, Beth Ann Hockey, B. Srinivas,
and Martin Zaidel. 1994. Xtag system: a wide coverage
grammar for english. In Proceedings of the 15th confer-
ence on Computational linguistics, pages 922–928. ACL,
Morristown, NJ, USA.
Dan Flickinger. 2000. On building a more efficient gram-
mar by exploiting types. Natural Language Engineering,
6(1):15–28.
Daniel Gildea and Julia Hockenmaier. 2003. Identifying se-
mantic roles using combinatory categorial grammar. In
Proceedings of the 2003 conference on Empirical meth-
ods in natural language processing, pages 57–64. ACL,
Morristown, NJ, USA.
Donald Hindle. 1983. User manual for fidditch, a determin-
istic parser. Technical Memorandum 7590-142, Naval Re-
search Laboratory.
Julia Hockenmaier. 2003. Data and Models for Statistical
Parsing with Combinatory Categorial Grammar. Ph.D.
thesis, University of Edinburgh, Edinburgh, UK.
Julia Hockenmaier and Mark Steedman. 2002. Acquiring
compact lexicalized grammars from a cleaner treebank.
In Proceedings of the Third Conference on Language Re-
sources and Evaluation Conference, pages 1974–1981.
Las Palmas, Spain.
Julia Hockenmaier and Mark Steedman. 2007. CCGbank: a
corpus of CCG derivations and dependency structures ex-
tracted from the Penn Treebank. Computational Linguis-
tics, 33(3):355–396.
Matthew Honnibal and James R. Curran. 2007. Improving the
complement/adjunct distinction in CCGBank. In Proceed-
ings of the Conference of the Pacific Association for Com-
putational Linguistics, pages 210–217. Melbourne, Aus-
tralia.
Ronald M. Kaplan and Joan Bresnan. 1982. Lexical-
Functional Grammar: A formal system for grammatical
representation. In Joan Bresnan, editor, The mental repre-
sentation of grammatical relations, pages 173–281. MIT
Press, Cambridge, MA, USA.
Mitchell Marcus, Beatrice Santorini, and Mary
Marcinkiewicz. 1993. Building a large annotated
corpus of English: The Penn Treebank. Computational
Linguistics, 19(2):313–330.
Paul Martin. 2002. The Wall Street Journal Guide to Business
Style and Usage. Free Press, New York.
Adam Meyers, Ruth Reeves, Catherine Macleod, Rachel
Szekely, Veronika Zielinska, Brian Young, and Ralph Gr-
ishman. 2004. The NomBank project: An interim report.
In Frontiers in Corpus Annotation: Proceedings of the
Workshop, pages 24–31. Boston, MA, USA.
Yusuke Miyao, Takashi Ninomiya, and Jun’ichi Tsujii. 2004.
Corpus-oriented grammar development for acquiring a
head-driven phrase structure grammar from the Penn Tree-
bank. In Proceedings of the First International Joint Con-
ference on Natural Language Processing (IJCNLP-04),
pages 684–693. Hainan Island, China.
Stepan Oepen, Daniel Flickenger, Kristina Toutanova, and
Christopher D. Manning. 2004. LinGO Redwoods. a rich
and dynamic treebank for HPSG. Research on Language
and Computation, 2(4):575–596.
Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005.
The proposition bank: An annotated corpus of semantic
roles. Computational Linguistics, 31(1):71–106.
Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase Struc-
ture Grammar. The University of Chicago Press, Chicago.
Libin Shen, Lucas Champollion, and Aravind K. Joshi. 2008.
LTAG-spinal and the treebank: A new resource for incre-
mental, dependency and semantic parsing. Language Re-
sources and Evaluation, 42(1):1–19.
Stuart M. Shieber. 1986. An Introduction to Unification-
Based Approaches to Grammar, volume 4 of CSLI Lecture
Notes. CSLI Publications, Stanford, CA.
Mark Steedman. 2000. The Syntactic Process. The MIT
Press, Cambridge, MA, USA.
Daniel Tse and James R. Curran. 2008. Punctuation normali-
sation for cleaner treebanks and parsers. In Proceedings of
the Australian Language Technology Workshop, volume 6,
pages 151–159. ALTW, Hobart, Australia.
David Vadas and James Curran. 2007. Adding noun phrase
structure to the Penn Treebank. In Proceedings of the 45th
Annual Meeting of the Association of Computational Lin-
guistics, pages 240–247. ACL, Prague, Czech Republic.
David Vadas and James R. Curran. 2008. Parsing noun phrase
structure with CCG. In Proceedings of the 46th Annual
Meeting of the Association for Computational Linguistics,
pages 335–343. ACL, Columbus, Ohio, USA.
</reference>
<page confidence="0.999144">
215
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.943542">
<title confidence="0.999675">Rebanking CCGbank for improved NP interpretation</title>
<author confidence="0.999998">Matthew Honnibal</author>
<author confidence="0.999998">James R Curran</author>
<affiliation confidence="0.999721">School of Information Technologies University of Sydney</affiliation>
<address confidence="0.988063">NSW 2006, Australia</address>
<author confidence="0.998873">Johan Bos</author>
<affiliation confidence="0.999895">University of Groningen</affiliation>
<address confidence="0.966598">The Netherlands</address>
<email confidence="0.99992">bos@meaningfactory.com</email>
<abstract confidence="0.999439111111111">Once released, treebanks tend to remain unchanged despite any shortcomings in their depth of linguistic analysis or coverage of specific phenomena. Instead, separate resources are created to address such problems. In this paper we show how to improve the quality of a treebank, by integrating resources and implementing improved analyses for specific constructions. demonstrate this by creating an updated version of CCGbank that includes the predicate-argument structure of both verbs and nouns, base- NP brackets, verb-particle constructions, and restrictive and non-restrictive nominal modifiers; and evaluate the impact of these changes on a statistical parser.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ann Bies</author>
<author>Mark Ferguson</author>
<author>Karen Katz</author>
<author>Robert MacIntyre</author>
</authors>
<title>Bracketing guidelines for Treebank II style Penn Treebank project.</title>
<date>1995</date>
<tech>Technical report, MS-CIS-95-06,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA, USA.</location>
<contexts>
<context position="9545" citStr="Bies et al., 1995" startWordPosition="1473" endWordPosition="1476">n is represented in the surface syntax in CCG, because the category of a verb must specify its argument structure. In (3) as a director is annotated as a complement; in (4) it is an adjunct: (3) He joined as a director (2) crude (oil prices) NP (S\NP)/PP PP The structure of such compound noun phrases is left underspecified in the Penn Treebank (PTB), because the annotation procedure involved stitching together partial parses produced by the Fidditch parser (Hindle, 1983), which produced flat brackets for these constructions. The bracketing decision was also a source of annotator disagreement (Bies et al., 1995). When Hockenmaier and Steedman (2002) went to acquire a CCG treebank from the PTB, this posed a problem. There is no equivalent way to leave these structures under-specified in CCG, because derivations must be binary branching. They therefore employed a simple heuristic: assume all such structures branch to the right. Under this analysis, crude oil is not a constituent, producing an incorrect analysis as in (1). Vadas and Curran (2007) addressed this by manually annotating all of the ambiguous noun phrases in the PTB, and went on to use this information to correct 20,409 dependencies (1.95%) </context>
</contexts>
<marker>Bies, Ferguson, Katz, MacIntyre, 1995</marker>
<rawString>Ann Bies, Mark Ferguson, Karen Katz, and Robert MacIntyre. 1995. Bracketing guidelines for Treebank II style Penn Treebank project. Technical report, MS-CIS-95-06, University of Pennsylvania, Philadelphia, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Boxwell</author>
<author>Michael White</author>
</authors>
<title>Projecting propbank roles onto the CCGbank.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08),</booktitle>
<pages>3112--3117</pages>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="16465" citStr="Boxwell and White (2008)" startWordPosition="2542" endWordPosition="2545">to be recovered. A non-normal form derivation is shown so that instantiated variables can be seen. &gt; Carthage is destruction NP (NPy/(Ny/PPz)y)\NPz N/PPy &lt; NPdestruction In this analysis, we regard the genitive clitic as a case-marker that performs a movement operation roughly analogous to WH-extraction. Its category is therefore similar to the one used in object extraction, (N\N)/(S/NP). Figure 1 shows an example with multiple core arguments. This analysis allows recovery of verbal arguments of nominalised raising and control verbs, a construction which both Gildea and Hockenmaier (2003) and Boxwell and White (2008) identify as a problem case when aligning Propbank and CCGbank. Our analysis accommodates this construction effortlessly, as shown in Figure 2. The category assigned to decision can coindex the missing NP argument of buy with its own PP argument. When that argument is supplied by the genitive, it is also supplied to the verb, buy, filling its dependency with its agent, Google. This argument would be quite difficult to recover using a shallow syntactic analysis, as the path would be quite long. There are 494 such verb arguments mediated by nominal predicates in Sections 02-21. These analyses al</context>
</contexts>
<marker>Boxwell, White, 2008</marker>
<rawString>Stephen Boxwell and Michael White. 2008. Projecting propbank roles onto the CCGbank. In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08), pages 3112–3117. European Language Resources Association (ELRA), Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Mary Dalrymple</author>
<author>H Tracy</author>
</authors>
<date>2006</date>
<booktitle>Lexical Semantics in LFG.</booktitle>
<editor>King, editors.</editor>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="4939" citStr="Butt et al., 2006" startWordPosition="726" endWordPosition="729"> more detailed than those produced by skeletal phrasestructure parsers, because they produce fully specified predicate-argument structures. Unfortunately, statistical parsers do not take advantage of this potential detail. Statistical parsers induce their grammars from corpora, and the corpora for linguistically motivated formalisms currently do not contain high quality predicateargument annotation, because they were derived from the Penn Treebank (PTB Marcus et al., 1993). Manually written grammars for these formalisms, such as the ERG HPSG grammar (Flickinger, 2000) and the XLE LFG grammar (Butt et al., 2006) produce far more detailed and linguistically correct analyses than any English statistical parser, due to the comparatively coarse-grained annotation schemes of the corpora statistical parsers are trained on. While rule-based parsers use grammars that are carefully engineered (e.g. Oepen et al., 2004), and can be updated to reflect the best linguistic analyses, statistical parsers have so far had to take what they are given. What we suggest in this paper is that a treebank’s grammar need not last its lifetime. For a start, there have been many annotations of the PTB that add much of the extra</context>
</contexts>
<marker>Butt, Dalrymple, Tracy, 2006</marker>
<rawString>Miriam Butt, Mary Dalrymple, and Tracy H. King, editors. 2006. Lexical Semantics in LFG. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Aoife Cahill</author>
<author>Michael Burke</author>
<author>Ruth O’Donovan</author>
<author>Stefan Riezler</author>
<author>Josef van Genabith</author>
<author>Andy Way</author>
</authors>
<title>Widecoverage deep statistical parsing using automatic dependency structure annotation.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>1</issue>
<marker>Cahill, Burke, O’Donovan, Riezler, van Genabith, Way, 2008</marker>
<rawString>Aoife Cahill, Michael Burke, Ruth O’Donovan, Stefan Riezler, Josef van Genabith, and Andy Way. 2008. Widecoverage deep statistical parsing using automatic dependency structure annotation. Computational Linguistics, 34(1):81–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Wide-coverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="10862" citStr="Clark and Curran, 2007" startWordPosition="1686" endWordPosition="1689">on corrections The syntactic analysis of punctuation is notoriously difficult, and punctuation is not always treated consistently in the Penn Treebank (Bies et al., 1995). Hockenmaier (2003) determined that quotation marks were particularly problematic, and therefore removed them from CCGbank altogether. We use the process described by Tse and Curran (2008) to restore the quotation marks and shift commas so that they always attach to the constituent to their left. This allows a grammar rule to be removed, preventing a great deal of spurious ambiguity and improving the speed of the C&amp;C parser (Clark and Curran, 2007) by 37%. (4) He joined as a director NP S\NP (S\NP)\(S\NP) CCGbank contains noisy complement and adjunct distinctions, because they were drawn from PTB function labels which imperfectly represent the distinction. In our previous work we used Propbank (Palmer et al., 2005) to convert 1,543 complements to adjuncts and 13,256 adjuncts to complements (Honnibal and Curran, 2007). If a constituent such as as a director received an adjunct category, but was labelled as a core argument in Propbank, we changed it to a complement, using its head’s part-of-speech tag to infer its constituent type. We per</context>
<context position="27148" citStr="Clark and Curran (2007)" startWordPosition="4274" endWordPosition="4277">NP/N. Our changes introduce new categories for these frequent tokens, which meant a substantial increase in the number of possible categories per word. 9 Parsing Evaluation Some of the changes we have made correct problems that have caused the performance of a statistical CCG parser to be over-estimated. Other changes introduce new distinctions, which a parser may or may not find difficult to reproduce. To investigate these issues, we trained and evaluated the C&amp;C CCG parser on our rebanked corpora. The experiments were set up as follows. We used the highest scoring configuration described by Clark and Curran (2007), the hybrid dependency model, using gold-standard POS tags. We followed Clark and Curran in excluding sentences that could not be parsed from the evaluation. All models obtained similar coverage, between 99.0 and 99.3%. The parser was evaluated using depen213 Corpus LF WSJ 00 CAT LF WSJ 23 CAT OF OF CCGbank 87.2 92.9 94.1 87.7 93.0 94.4 +NP brackets 86.9 92.8 93.8 87.3 92.8 93.9 +Quotes 86.8 92.7 93.9 87.1 92.6 94.0 +Propbank 86.7 92.6 94.0 87.0 92.6 94.0 +Particles 86.4 92.5 93.8 86.8 92.6 93.8 All Rebanking 84.2 91.2 91.9 84.7 91.3 92.2 Table 3: Parser evaluation on the rebanked corpora. Co</context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>Stephen Clark and James R. Curran. 2007. Wide-coverage efficient statistical parsing with CCG and log-linear models. Computational Linguistics, 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Constable</author>
<author>James Curran</author>
</authors>
<title>Integrating verbparticle constructions into CCG parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the Australasian Language Technology Association Workshop</booktitle>
<pages>114--118</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="11871" citStr="Constable and Curran (2009)" startWordPosition="1843" endWordPosition="1846"> constituent such as as a director received an adjunct category, but was labelled as a core argument in Propbank, we changed it to a complement, using its head’s part-of-speech tag to infer its constituent type. We performed the equivalent transformation to ensure all peripheral arguments of verbs were analysed as adjuncts. 3.4 Verb-particle constructions Propbank also offers reliable annotation of verbparticle constructions. This was not available in the PTB, so Hockenmaier and Steedman (2007) annotated all intransitive prepositions as adjuncts: (5) He woke up NP S\NP (S\NP)\(S\NP) We follow Constable and Curran (2009) in exploiting the Propbank annotations to add verbparticle distinctions to CCGbank, by introducing a new atomic category PT for particles, and changing their status from adjuncts to complements: (6) He woke up NP (S\NP)/PT PT This analysis could be improved by adding extra head-finding logic to the verbal category, to recognise the multi-word expression as the head. 209 Rome &apos;s gift of peace to Europe NP (NP/(N/PP))\NP (N/PP)/PP)/PP PP/NP NP PP/NP NP &lt; &gt; &gt; N/(N/PP) PP PP &gt; (N/PP)/PP &gt; &gt; N/PP NP Figure 1: Deverbal noun predicate with agent, patient and beneficiary arguments. 4 Noun predicate-a</context>
</contexts>
<marker>Constable, Curran, 2009</marker>
<rawString>James Constable and James Curran. 2009. Integrating verbparticle constructions into CCG parsing. In Proceedings of the Australasian Language Technology Association Workshop 2009, pages 114–118. Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christy Doran</author>
<author>Dania Egedi</author>
<author>Beth Ann Hockey</author>
<author>B Srinivas</author>
<author>Martin Zaidel</author>
</authors>
<title>Xtag system: a wide coverage grammar for english.</title>
<date>1994</date>
<booktitle>In Proceedings of the 15th conference on Computational linguistics,</booktitle>
<pages>922--928</pages>
<publisher>ACL,</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="31132" citStr="Doran et al., 1994" startWordPosition="4910" endWordPosition="4913">nd 2009 shared tasks. This paper has described how these resources can be jointly exploited using a linguistically motivated theory of syntax and semantics. The semantic annotations provided by Propbank and NomBank allowed us to build a corpus that takes much greater advantage of the semantic transparency of a deep grammar, using careful analyses and phenomenon-specific conversion rules. The major areas of CCGbank’s grammar left to be improved are the analysis of comparatives, and the analysis of named entities. English comparatives are diverse and difficult to analyse. Even the XTAG grammar (Doran et al., 1994), which deals with the major constructions of English in enviable detail, does not offer a full analysis of these phenomena. Named entities are also difficult to analyse, as many entity types obey their own specific grammars. This is another example of a phenomenon that could be analysed much better in CCGbank using an existing resource, the BBN named entity corpus. Our rebanking has substantially improved CCGbank, by increasing the granularity and linguistic fidelity of its analyses. We achieved this by exploiting existing resources and crafting novel analyses. The process we have demonstrate</context>
</contexts>
<marker>Doran, Egedi, Hockey, Srinivas, Zaidel, 1994</marker>
<rawString>Christy Doran, Dania Egedi, Beth Ann Hockey, B. Srinivas, and Martin Zaidel. 1994. Xtag system: a wide coverage grammar for english. In Proceedings of the 15th conference on Computational linguistics, pages 922–928. ACL, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Flickinger</author>
</authors>
<title>On building a more efficient grammar by exploiting types.</title>
<date>2000</date>
<journal>Natural Language Engineering,</journal>
<volume>6</volume>
<issue>1</issue>
<contexts>
<context position="1842" citStr="Flickinger, 2000" startWordPosition="268" endWordPosition="269">approach related problems as discrete tasks, when a new data set that adds deeper information establishes a new incompatible evaluation. Direct comparison has been central to progress in statistical parsing, but it has also caused problems. Treebanking is a difficult engineering task: coverage, cost, consistency and granularity are all competing concerns that must be balanced against each other when the annotation scheme is developed. The difficulty of the task means that we ought to view treebanking as an ongoing process akin to grammar development, such as the many years of work on the ERG (Flickinger, 2000). This paper demonstrates how a treebank can be rebanked to incorporate novel analyses and information from existing resources. We chose to work on CCGbank (Hockenmaier and Steedman, 2007), a Combinatory Categorial Grammar (Steedman, 2000) treebank acquired from the Penn Treebank (Marcus et al., 1993). This work is equally applicable to the corpora described by Miyao et al. (2004), Shen et al. (2008) or Cahill et al. (2008). Our first changes integrate four previously suggested improvements to CCGbank. We then describe a novel CCG analysis of NP predicateargument structure, which we implement </context>
<context position="4895" citStr="Flickinger, 2000" startWordPosition="719" endWordPosition="720">nalyses produced by these formalisms can be more detailed than those produced by skeletal phrasestructure parsers, because they produce fully specified predicate-argument structures. Unfortunately, statistical parsers do not take advantage of this potential detail. Statistical parsers induce their grammars from corpora, and the corpora for linguistically motivated formalisms currently do not contain high quality predicateargument annotation, because they were derived from the Penn Treebank (PTB Marcus et al., 1993). Manually written grammars for these formalisms, such as the ERG HPSG grammar (Flickinger, 2000) and the XLE LFG grammar (Butt et al., 2006) produce far more detailed and linguistically correct analyses than any English statistical parser, due to the comparatively coarse-grained annotation schemes of the corpora statistical parsers are trained on. While rule-based parsers use grammars that are carefully engineered (e.g. Oepen et al., 2004), and can be updated to reflect the best linguistic analyses, statistical parsers have so far had to take what they are given. What we suggest in this paper is that a treebank’s grammar need not last its lifetime. For a start, there have been many annot</context>
</contexts>
<marker>Flickinger, 2000</marker>
<rawString>Dan Flickinger. 2000. On building a more efficient grammar by exploiting types. Natural Language Engineering, 6(1):15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Identifying semantic roles using combinatory categorial grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 conference on Empirical methods in natural language processing,</booktitle>
<pages>57--64</pages>
<publisher>ACL,</publisher>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="16436" citStr="Gildea and Hockenmaier (2003)" startWordPosition="2537" endWordPosition="2540">ws the hard-to-reach agent of buy to be recovered. A non-normal form derivation is shown so that instantiated variables can be seen. &gt; Carthage is destruction NP (NPy/(Ny/PPz)y)\NPz N/PPy &lt; NPdestruction In this analysis, we regard the genitive clitic as a case-marker that performs a movement operation roughly analogous to WH-extraction. Its category is therefore similar to the one used in object extraction, (N\N)/(S/NP). Figure 1 shows an example with multiple core arguments. This analysis allows recovery of verbal arguments of nominalised raising and control verbs, a construction which both Gildea and Hockenmaier (2003) and Boxwell and White (2008) identify as a problem case when aligning Propbank and CCGbank. Our analysis accommodates this construction effortlessly, as shown in Figure 2. The category assigned to decision can coindex the missing NP argument of buy with its own PP argument. When that argument is supplied by the genitive, it is also supplied to the verb, buy, filling its dependency with its agent, Google. This argument would be quite difficult to recover using a shallow syntactic analysis, as the path would be quite long. There are 494 such verb arguments mediated by nominal predicates in Sect</context>
</contexts>
<marker>Gildea, Hockenmaier, 2003</marker>
<rawString>Daniel Gildea and Julia Hockenmaier. 2003. Identifying semantic roles using combinatory categorial grammar. In Proceedings of the 2003 conference on Empirical methods in natural language processing, pages 57–64. ACL, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donald Hindle</author>
</authors>
<title>User manual for fidditch, a deterministic parser.</title>
<date>1983</date>
<tech>Technical Memorandum 7590-142,</tech>
<institution>Naval Research Laboratory.</institution>
<contexts>
<context position="9402" citStr="Hindle, 1983" startWordPosition="1453" endWordPosition="1454">ole comes from a set specific to the predicate, and peripheral arguments, who have a role drawn from a small, generic set. This distinction is represented in the surface syntax in CCG, because the category of a verb must specify its argument structure. In (3) as a director is annotated as a complement; in (4) it is an adjunct: (3) He joined as a director (2) crude (oil prices) NP (S\NP)/PP PP The structure of such compound noun phrases is left underspecified in the Penn Treebank (PTB), because the annotation procedure involved stitching together partial parses produced by the Fidditch parser (Hindle, 1983), which produced flat brackets for these constructions. The bracketing decision was also a source of annotator disagreement (Bies et al., 1995). When Hockenmaier and Steedman (2002) went to acquire a CCG treebank from the PTB, this posed a problem. There is no equivalent way to leave these structures under-specified in CCG, because derivations must be binary branching. They therefore employed a simple heuristic: assume all such structures branch to the right. Under this analysis, crude oil is not a constituent, producing an incorrect analysis as in (1). Vadas and Curran (2007) addressed this b</context>
</contexts>
<marker>Hindle, 1983</marker>
<rawString>Donald Hindle. 1983. User manual for fidditch, a deterministic parser. Technical Memorandum 7590-142, Naval Research Laboratory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
</authors>
<title>Data and Models for Statistical Parsing with Combinatory Categorial Grammar.</title>
<date>2003</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh,</institution>
<location>Edinburgh, UK.</location>
<contexts>
<context position="10429" citStr="Hockenmaier (2003)" startWordPosition="1616" endWordPosition="1617">istic: assume all such structures branch to the right. Under this analysis, crude oil is not a constituent, producing an incorrect analysis as in (1). Vadas and Curran (2007) addressed this by manually annotating all of the ambiguous noun phrases in the PTB, and went on to use this information to correct 20,409 dependencies (1.95%) in CCGbank (Vadas and Curran, 2008). Our changes build on this corrected corpus. 3.2 Punctuation corrections The syntactic analysis of punctuation is notoriously difficult, and punctuation is not always treated consistently in the Penn Treebank (Bies et al., 1995). Hockenmaier (2003) determined that quotation marks were particularly problematic, and therefore removed them from CCGbank altogether. We use the process described by Tse and Curran (2008) to restore the quotation marks and shift commas so that they always attach to the constituent to their left. This allows a grammar rule to be removed, preventing a great deal of spurious ambiguity and improving the speed of the C&amp;C parser (Clark and Curran, 2007) by 37%. (4) He joined as a director NP S\NP (S\NP)\(S\NP) CCGbank contains noisy complement and adjunct distinctions, because they were drawn from PTB function labels</context>
<context position="16436" citStr="Hockenmaier (2003)" startWordPosition="2539" endWordPosition="2540">-to-reach agent of buy to be recovered. A non-normal form derivation is shown so that instantiated variables can be seen. &gt; Carthage is destruction NP (NPy/(Ny/PPz)y)\NPz N/PPy &lt; NPdestruction In this analysis, we regard the genitive clitic as a case-marker that performs a movement operation roughly analogous to WH-extraction. Its category is therefore similar to the one used in object extraction, (N\N)/(S/NP). Figure 1 shows an example with multiple core arguments. This analysis allows recovery of verbal arguments of nominalised raising and control verbs, a construction which both Gildea and Hockenmaier (2003) and Boxwell and White (2008) identify as a problem case when aligning Propbank and CCGbank. Our analysis accommodates this construction effortlessly, as shown in Figure 2. The category assigned to decision can coindex the missing NP argument of buy with its own PP argument. When that argument is supplied by the genitive, it is also supplied to the verb, buy, filling its dependency with its agent, Google. This argument would be quite difficult to recover using a shallow syntactic analysis, as the path would be quite long. There are 494 such verb arguments mediated by nominal predicates in Sect</context>
</contexts>
<marker>Hockenmaier, 2003</marker>
<rawString>Julia Hockenmaier. 2003. Data and Models for Statistical Parsing with Combinatory Categorial Grammar. Ph.D. thesis, University of Edinburgh, Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>Acquiring compact lexicalized grammars from a cleaner treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third Conference on Language Resources and Evaluation Conference,</booktitle>
<pages>1974--1981</pages>
<location>Las Palmas,</location>
<contexts>
<context position="9583" citStr="Hockenmaier and Steedman (2002)" startWordPosition="1478" endWordPosition="1481">urface syntax in CCG, because the category of a verb must specify its argument structure. In (3) as a director is annotated as a complement; in (4) it is an adjunct: (3) He joined as a director (2) crude (oil prices) NP (S\NP)/PP PP The structure of such compound noun phrases is left underspecified in the Penn Treebank (PTB), because the annotation procedure involved stitching together partial parses produced by the Fidditch parser (Hindle, 1983), which produced flat brackets for these constructions. The bracketing decision was also a source of annotator disagreement (Bies et al., 1995). When Hockenmaier and Steedman (2002) went to acquire a CCG treebank from the PTB, this posed a problem. There is no equivalent way to leave these structures under-specified in CCG, because derivations must be binary branching. They therefore employed a simple heuristic: assume all such structures branch to the right. Under this analysis, crude oil is not a constituent, producing an incorrect analysis as in (1). Vadas and Curran (2007) addressed this by manually annotating all of the ambiguous noun phrases in the PTB, and went on to use this information to correct 20,409 dependencies (1.95%) in CCGbank (Vadas and Curran, 2008). O</context>
</contexts>
<marker>Hockenmaier, Steedman, 2002</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2002. Acquiring compact lexicalized grammars from a cleaner treebank. In Proceedings of the Third Conference on Language Resources and Evaluation Conference, pages 1974–1981. Las Palmas, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Julia Hockenmaier</author>
<author>Mark Steedman</author>
</authors>
<title>CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="2030" citStr="Hockenmaier and Steedman, 2007" startWordPosition="295" endWordPosition="298"> progress in statistical parsing, but it has also caused problems. Treebanking is a difficult engineering task: coverage, cost, consistency and granularity are all competing concerns that must be balanced against each other when the annotation scheme is developed. The difficulty of the task means that we ought to view treebanking as an ongoing process akin to grammar development, such as the many years of work on the ERG (Flickinger, 2000). This paper demonstrates how a treebank can be rebanked to incorporate novel analyses and information from existing resources. We chose to work on CCGbank (Hockenmaier and Steedman, 2007), a Combinatory Categorial Grammar (Steedman, 2000) treebank acquired from the Penn Treebank (Marcus et al., 1993). This work is equally applicable to the corpora described by Miyao et al. (2004), Shen et al. (2008) or Cahill et al. (2008). Our first changes integrate four previously suggested improvements to CCGbank. We then describe a novel CCG analysis of NP predicateargument structure, which we implement using NomBank (Meyers et al., 2004). Our analysis allows the distinction between core and peripheral arguments to be represented for predicate nouns. With this distinction, an entailment r</context>
<context position="7358" citStr="Hockenmaier and Steedman, 2007" startWordPosition="1129" endWordPosition="1132">ult, so that a word can have a complex valency structure. For instance, a verb phrase is represented by the category S\NP: it is a function from a leftward NP (a subject) to a sentence. A transitive verb requires an object to become a verb phrase, producing the category (S\NP)/NP. A CCG grammar consists of a small number of schematic rules, called combinators. CCG extends the basic application rules of pure categorial grammar with (generalised) composition rules and type raising. The most common rules are: X/Y Y X (&gt;) Y X\Y X (&lt;) X/Y Y /Z X/Z (&gt;B) Y \Z X\Y X\Z (&lt;B) Y /Z X\Y X/Z (&lt;B,) CCGbank (Hockenmaier and Steedman, 2007) extends this compact set of combinatory rules with a set of type-changing rules, designed to strike a better balance between sparsity in the category set and ambiguity in the grammar. We mark typechanging rules TC in our derivations. In wide-coverage descriptions, categories are generally modelled as typed-feature structures (Shieber, 1986), rather than atomic symbols. This allows the grammar to include a notion of headedness, and to unify under-specified features. We occasionally must refer to these additional details, for which we employ the following notation. Features are annotated in squ</context>
<context position="11743" citStr="Hockenmaier and Steedman (2007)" startWordPosition="1824" endWordPosition="1827"> (Palmer et al., 2005) to convert 1,543 complements to adjuncts and 13,256 adjuncts to complements (Honnibal and Curran, 2007). If a constituent such as as a director received an adjunct category, but was labelled as a core argument in Propbank, we changed it to a complement, using its head’s part-of-speech tag to infer its constituent type. We performed the equivalent transformation to ensure all peripheral arguments of verbs were analysed as adjuncts. 3.4 Verb-particle constructions Propbank also offers reliable annotation of verbparticle constructions. This was not available in the PTB, so Hockenmaier and Steedman (2007) annotated all intransitive prepositions as adjuncts: (5) He woke up NP S\NP (S\NP)\(S\NP) We follow Constable and Curran (2009) in exploiting the Propbank annotations to add verbparticle distinctions to CCGbank, by introducing a new atomic category PT for particles, and changing their status from adjuncts to complements: (6) He woke up NP (S\NP)/PT PT This analysis could be improved by adding extra head-finding logic to the verbal category, to recognise the multi-word expression as the head. 209 Rome &apos;s gift of peace to Europe NP (NP/(N/PP))\NP (N/PP)/PP)/PP PP/NP NP PP/NP NP &lt; &gt; &gt; N/(N/PP) P</context>
<context position="15051" citStr="Hockenmaier and Steedman (2007)" startWordPosition="2334" endWordPosition="2338">age N/PPy PPy/NPy NP &gt; &gt; In our analysis, the head of of Carthage is Carthage, as of is assumed to be a semantically transparent case-marker. We apply this analysis to prepositional phrases that provide arguments to verbs as well — a departure from CCGbank. Prepositional phrases that introduce peripheral arguments are analysed as syntactic adjuncts: The war in 149 B.C. NPy/Ny N (Ny\Ny)/NPz NP &gt; &lt; NPwar Adjunct prepositional phrases remain headed by the preposition, as it is the preposition’s semantics that determines whether they function as temporal, causal, spatial etc. arguments. We follow Hockenmaier and Steedman (2007) in our analysis of genitives which realise peripheral arguments, such as the literal possessive: Rome is aqueducts NP (NPy/Ny)\NPz N &lt; NPaqueducts Arguments introduced by possessives are a little trickier, because the genitive also functions as a determiner. We achieve this by having the noun subcategorise for the argument, which we type PP, and having the possessive subcategorise for the unsaturated noun to ultimately produce an NP: PPCarthage Ndestruction (Ny\Ny)in Nwar &gt; (NPy/Ny)&apos;s &gt; 210 Google &apos;s decision to buy YouTube NP (NPy/(Ny/PPz)y)\NPz (N/PPy)/(S[to]z\NPy)z (S[to]y\NPz)y/(S[b]y\NPz</context>
<context position="28514" citStr="Hockenmaier and Steedman (2007)" startWordPosition="4500" endWordPosition="4504">9 +Particles 87.50 92.77 87.67 92.93 All Rebanking 87.23 92.71 88.02 93.51 Table 4: Comparison of parsers trained on CCGbank and the rebanked corpora, using dependencies that occur in both. dencies generated from the gold-standard derivations (Boxwell, p.c., 2010). Table 3 shows the accuracy of the parser on Sections 00 and 23. The parser scored slightly lower as the NP brackets, Quotes, Propbank and Particles corrections were added. This apparent decline in performance is at least partially an artefact of the evaluation. CCGbank contains some dependencies that are trivial to recover, because Hockenmaier and Steedman (2007) was forced to adopt a strictly right-branching analysis for NP brackets. There was a larger drop in accuracy on the fully rebanked corpus, which included our analyses of restrictivity, partitive constructions and noun predicate-argument structure. This might also be explained by the evaluation, as the rebanked corpus includes much more fine-grained distinctions. The labelled dependencies evaluation is particularly sensitive to this, as a single category change affects multiple dependencies. This can be seen in the smaller gap in category accuracy. We investigated whether the differences in pe</context>
</contexts>
<marker>Hockenmaier, Steedman, 2007</marker>
<rawString>Julia Hockenmaier and Mark Steedman. 2007. CCGbank: a corpus of CCG derivations and dependency structures extracted from the Penn Treebank. Computational Linguistics, 33(3):355–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Honnibal</author>
<author>James R Curran</author>
</authors>
<title>Improving the complement/adjunct distinction in CCGBank.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference of the Pacific Association for Computational Linguistics,</booktitle>
<pages>210--217</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="11238" citStr="Honnibal and Curran, 2007" startWordPosition="1744" endWordPosition="1747">e quotation marks and shift commas so that they always attach to the constituent to their left. This allows a grammar rule to be removed, preventing a great deal of spurious ambiguity and improving the speed of the C&amp;C parser (Clark and Curran, 2007) by 37%. (4) He joined as a director NP S\NP (S\NP)\(S\NP) CCGbank contains noisy complement and adjunct distinctions, because they were drawn from PTB function labels which imperfectly represent the distinction. In our previous work we used Propbank (Palmer et al., 2005) to convert 1,543 complements to adjuncts and 13,256 adjuncts to complements (Honnibal and Curran, 2007). If a constituent such as as a director received an adjunct category, but was labelled as a core argument in Propbank, we changed it to a complement, using its head’s part-of-speech tag to infer its constituent type. We performed the equivalent transformation to ensure all peripheral arguments of verbs were analysed as adjuncts. 3.4 Verb-particle constructions Propbank also offers reliable annotation of verbparticle constructions. This was not available in the PTB, so Hockenmaier and Steedman (2007) annotated all intransitive prepositions as adjuncts: (5) He woke up NP S\NP (S\NP)\(S\NP) We f</context>
<context position="18427" citStr="Honnibal and Curran (2007)" startWordPosition="2863" endWordPosition="2866">e of the productivity of nounnoun compounding in English, which makes these argument structures very difficult to recover. We currently do not have an analysis that allows support verbs to supply noun arguments, so we do not recover any of the long-range dependency structures described by Meyers et al. (2004). 4.2 Implementation and statistics Our analysis requires semantic role labels for each argument of the nominal predicates in the Penn Treebank — precisely what NomBank (Meyers et al., 2004) provides. We can therefore draw our distinctions using the process described in our previous work, Honnibal and Curran (2007). NomBank follows the same format as Propbank, so the procedure is exactly the same. First, we align CCGbank and the Penn Treebank, and produce a version of NomBank that refers to CCGbank nodes. We then assume that any prepositional phrase or genitive determiner annotated as a core argument in NomBank should be analysed as a complement, while peripheral arguments and adnominals that receive no semantic role label at all are analysed as adjuncts. We converted 34,345 adnominal prepositional phrases to complements, leaving 18,919 as adjuncts. The most common preposition converted was of, which wa</context>
</contexts>
<marker>Honnibal, Curran, 2007</marker>
<rawString>Matthew Honnibal and James R. Curran. 2007. Improving the complement/adjunct distinction in CCGBank. In Proceedings of the Conference of the Pacific Association for Computational Linguistics, pages 210–217. Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronald M Kaplan</author>
<author>Joan Bresnan</author>
</authors>
<title>LexicalFunctional Grammar: A formal system for grammatical representation.</title>
<date>1982</date>
<booktitle>The mental representation of grammatical relations,</booktitle>
<pages>173--281</pages>
<editor>In Joan Bresnan, editor,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="3940" citStr="Kaplan and Bresnan, 1982" startWordPosition="575" endWordPosition="578">orisation. Together, these changes modify 30% of the labelled dependencies in CCGbank, demonstrating how multiple resources can be brought together in a single, richly annotated corpus. We then train and evaluate a parser for these changes, to investigate their impact on the accuracy of a state-of-theart statistical CCG parser. 207 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 207–215, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics 2 Background and motivation Formalisms like HPSG (Pollard and Sag, 1994), LFG (Kaplan and Bresnan, 1982), and CCG (Steedman, 2000) are linguistically motivated in the sense that they attempt to explain and predict the limited variation found in the grammars of natural languages. They also attempt to specify how grammars construct semantic representations from surface strings, which is why they are sometimes referred to as deep grammars. Analyses produced by these formalisms can be more detailed than those produced by skeletal phrasestructure parsers, because they produce fully specified predicate-argument structures. Unfortunately, statistical parsers do not take advantage of this potential deta</context>
</contexts>
<marker>Kaplan, Bresnan, 1982</marker>
<rawString>Ronald M. Kaplan and Joan Bresnan. 1982. LexicalFunctional Grammar: A formal system for grammatical representation. In Joan Bresnan, editor, The mental representation of grammatical relations, pages 173–281. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics,</title>
<date>1993</date>
<contexts>
<context position="2144" citStr="Marcus et al., 1993" startWordPosition="311" endWordPosition="314">t, consistency and granularity are all competing concerns that must be balanced against each other when the annotation scheme is developed. The difficulty of the task means that we ought to view treebanking as an ongoing process akin to grammar development, such as the many years of work on the ERG (Flickinger, 2000). This paper demonstrates how a treebank can be rebanked to incorporate novel analyses and information from existing resources. We chose to work on CCGbank (Hockenmaier and Steedman, 2007), a Combinatory Categorial Grammar (Steedman, 2000) treebank acquired from the Penn Treebank (Marcus et al., 1993). This work is equally applicable to the corpora described by Miyao et al. (2004), Shen et al. (2008) or Cahill et al. (2008). Our first changes integrate four previously suggested improvements to CCGbank. We then describe a novel CCG analysis of NP predicateargument structure, which we implement using NomBank (Meyers et al., 2004). Our analysis allows the distinction between core and peripheral arguments to be represented for predicate nouns. With this distinction, an entailment recognition system could recognise that Google’s acquisition of YouTube entailed Google acquired YouTube, because e</context>
<context position="4798" citStr="Marcus et al., 1993" startWordPosition="703" endWordPosition="706">epresentations from surface strings, which is why they are sometimes referred to as deep grammars. Analyses produced by these formalisms can be more detailed than those produced by skeletal phrasestructure parsers, because they produce fully specified predicate-argument structures. Unfortunately, statistical parsers do not take advantage of this potential detail. Statistical parsers induce their grammars from corpora, and the corpora for linguistically motivated formalisms currently do not contain high quality predicateargument annotation, because they were derived from the Penn Treebank (PTB Marcus et al., 1993). Manually written grammars for these formalisms, such as the ERG HPSG grammar (Flickinger, 2000) and the XLE LFG grammar (Butt et al., 2006) produce far more detailed and linguistically correct analyses than any English statistical parser, due to the comparatively coarse-grained annotation schemes of the corpora statistical parsers are trained on. While rule-based parsers use grammars that are carefully engineered (e.g. Oepen et al., 2004), and can be updated to reflect the best linguistic analyses, statistical parsers have so far had to take what they are given. What we suggest in this paper</context>
<context position="30352" citStr="Marcus et al., 1993" startWordPosition="4784" endWordPosition="4787">d dependencies. The parser’s performance remained fairly stable on the dependencies left unchanged. The rebanked parser performed 0.8% worse than the CCGbank parser on the intersection dependencies, suggesting that the fine-grained distinctions we introduced did cause some sparse data problems. However, we did not change any of the parser’s maximum entropy features or hyperparameters, which are tuned for CCGbank. 10 Conclusion Research in natural language understanding is driven by the datasets that we have available. The most cited computational linguistics work to date is the Penn Treebank (Marcus et al., 1993)1. Propbank (Palmer et al., 2005) has also been very influential since its release, and NomBank has been used for semantic dependency parsing in the CoNLL 2008 and 2009 shared tasks. This paper has described how these resources can be jointly exploited using a linguistically motivated theory of syntax and semantics. The semantic annotations provided by Propbank and NomBank allowed us to build a corpus that takes much greater advantage of the semantic transparency of a deep grammar, using careful analyses and phenomenon-specific conversion rules. The major areas of CCGbank’s grammar left to be </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell Marcus, Beatrice Santorini, and Mary Marcinkiewicz. 1993. Building a large annotated corpus of English: The Penn Treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Martin</author>
</authors>
<title>The Wall Street Journal Guide to Business Style and Usage.</title>
<date>2002</date>
<publisher>Free Press,</publisher>
<location>New York.</location>
<contexts>
<context position="20661" citStr="Martin, 2002" startWordPosition="3207" endWordPosition="3208"> adnominals are analysed as modifiers of either N or NP, yielding a restrictive or nonrestrictive interpretation respectively. In CCGbank, all adnominals attach to NPs, producing non-restrictive interpretations. We therefore move restrictive adnominals to N nodes: All staff on casual contracts NP/N N (N\N)/NP N/N N � TC NP � � NP This corrects the previous interpretation, which stated that there were no permanent staff. 5.1 Implementation and statistics The Wall Street Journal’s style guide mandates that this attachment ambiguity be managed by bracketing non-restrictive relatives with commas (Martin, 2002, p. 82), as in casual staff, who have no health insurance, support it. We thus use punctuation to make the attachment decision. All NP\NP modifiers that are not preceded by punctuation were moved to the lowest N node possible and relabelled N\N. We select the lowest (i.e. closest to leaf) N node because some adjectives, such as present or former, require scope over the qualified noun, making it safer to attach the adnominal first. Some adnominals in CCGbank are created by the S\NP —* NP\NP unary type-changing rule, which transforms reduced relative clauses. We introduce a S\NP —* N\N in its p</context>
</contexts>
<marker>Martin, 2002</marker>
<rawString>Paul Martin. 2002. The Wall Street Journal Guide to Business Style and Usage. Free Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Meyers</author>
<author>Ruth Reeves</author>
<author>Catherine Macleod</author>
<author>Rachel Szekely</author>
<author>Veronika Zielinska</author>
<author>Brian Young</author>
<author>Ralph Grishman</author>
</authors>
<title>The NomBank project: An interim report.</title>
<date>2004</date>
<booktitle>In Frontiers in Corpus Annotation: Proceedings of the Workshop,</booktitle>
<pages>24--31</pages>
<location>Boston, MA, USA.</location>
<contexts>
<context position="2477" citStr="Meyers et al., 2004" startWordPosition="368" endWordPosition="371">monstrates how a treebank can be rebanked to incorporate novel analyses and information from existing resources. We chose to work on CCGbank (Hockenmaier and Steedman, 2007), a Combinatory Categorial Grammar (Steedman, 2000) treebank acquired from the Penn Treebank (Marcus et al., 1993). This work is equally applicable to the corpora described by Miyao et al. (2004), Shen et al. (2008) or Cahill et al. (2008). Our first changes integrate four previously suggested improvements to CCGbank. We then describe a novel CCG analysis of NP predicateargument structure, which we implement using NomBank (Meyers et al., 2004). Our analysis allows the distinction between core and peripheral arguments to be represented for predicate nouns. With this distinction, an entailment recognition system could recognise that Google’s acquisition of YouTube entailed Google acquired YouTube, because equivalent predicate-argument structures are built for both. Our analysis also recovers nonlocal dependencies mediated by nominal predicates; for instance, Google is the agent of acquire in Google’s decision to acquire YouTube. The rebanked corpus extends CCGbank with: 1. NP brackets from Vadas and Curran (2008); 2. Restored and nor</context>
<context position="18111" citStr="Meyers et al. (2004)" startWordPosition="2814" endWordPosition="2817"> expect that this would cause sparse data problems given the limited size of the corpus. This experiment would be an interesting subject of future work. The only local core arguments that we do not annotate as syntactic complements are compound nouns, such as decision makers. We avoided these arguments because of the productivity of nounnoun compounding in English, which makes these argument structures very difficult to recover. We currently do not have an analysis that allows support verbs to supply noun arguments, so we do not recover any of the long-range dependency structures described by Meyers et al. (2004). 4.2 Implementation and statistics Our analysis requires semantic role labels for each argument of the nominal predicates in the Penn Treebank — precisely what NomBank (Meyers et al., 2004) provides. We can therefore draw our distinctions using the process described in our previous work, Honnibal and Curran (2007). NomBank follows the same format as Propbank, so the procedure is exactly the same. First, we align CCGbank and the Penn Treebank, and produce a version of NomBank that refers to CCGbank nodes. We then assume that any prepositional phrase or genitive determiner annotated as a core a</context>
</contexts>
<marker>Meyers, Reeves, Macleod, Szekely, Zielinska, Young, Grishman, 2004</marker>
<rawString>Adam Meyers, Ruth Reeves, Catherine Macleod, Rachel Szekely, Veronika Zielinska, Brian Young, and Ralph Grishman. 2004. The NomBank project: An interim report. In Frontiers in Corpus Annotation: Proceedings of the Workshop, pages 24–31. Boston, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Takashi Ninomiya</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Corpus-oriented grammar development for acquiring a head-driven phrase structure grammar from the Penn Treebank.</title>
<date>2004</date>
<booktitle>In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04),</booktitle>
<pages>684--693</pages>
<location>Hainan Island, China.</location>
<contexts>
<context position="2225" citStr="Miyao et al. (2004)" startWordPosition="326" endWordPosition="329">ainst each other when the annotation scheme is developed. The difficulty of the task means that we ought to view treebanking as an ongoing process akin to grammar development, such as the many years of work on the ERG (Flickinger, 2000). This paper demonstrates how a treebank can be rebanked to incorporate novel analyses and information from existing resources. We chose to work on CCGbank (Hockenmaier and Steedman, 2007), a Combinatory Categorial Grammar (Steedman, 2000) treebank acquired from the Penn Treebank (Marcus et al., 1993). This work is equally applicable to the corpora described by Miyao et al. (2004), Shen et al. (2008) or Cahill et al. (2008). Our first changes integrate four previously suggested improvements to CCGbank. We then describe a novel CCG analysis of NP predicateargument structure, which we implement using NomBank (Meyers et al., 2004). Our analysis allows the distinction between core and peripheral arguments to be represented for predicate nouns. With this distinction, an entailment recognition system could recognise that Google’s acquisition of YouTube entailed Google acquired YouTube, because equivalent predicate-argument structures are built for both. Our analysis also rec</context>
</contexts>
<marker>Miyao, Ninomiya, Tsujii, 2004</marker>
<rawString>Yusuke Miyao, Takashi Ninomiya, and Jun’ichi Tsujii. 2004. Corpus-oriented grammar development for acquiring a head-driven phrase structure grammar from the Penn Treebank. In Proceedings of the First International Joint Conference on Natural Language Processing (IJCNLP-04), pages 684–693. Hainan Island, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stepan Oepen</author>
<author>Daniel Flickenger</author>
<author>Kristina Toutanova</author>
<author>Christopher D Manning</author>
</authors>
<title>LinGO Redwoods. a rich and dynamic treebank for HPSG.</title>
<date>2004</date>
<journal>Research on Language and Computation,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="5242" citStr="Oepen et al., 2004" startWordPosition="771" endWordPosition="774">guistically motivated formalisms currently do not contain high quality predicateargument annotation, because they were derived from the Penn Treebank (PTB Marcus et al., 1993). Manually written grammars for these formalisms, such as the ERG HPSG grammar (Flickinger, 2000) and the XLE LFG grammar (Butt et al., 2006) produce far more detailed and linguistically correct analyses than any English statistical parser, due to the comparatively coarse-grained annotation schemes of the corpora statistical parsers are trained on. While rule-based parsers use grammars that are carefully engineered (e.g. Oepen et al., 2004), and can be updated to reflect the best linguistic analyses, statistical parsers have so far had to take what they are given. What we suggest in this paper is that a treebank’s grammar need not last its lifetime. For a start, there have been many annotations of the PTB that add much of the extra information needed to produce very high quality analyses for a linguistically motivated grammar. There are also other transformations which can be made with no additional information. That is, sometimes the existing trees allow transformation rules to be written that improve the quality of the grammar</context>
</contexts>
<marker>Oepen, Flickenger, Toutanova, Manning, 2004</marker>
<rawString>Stepan Oepen, Daniel Flickenger, Kristina Toutanova, and Christopher D. Manning. 2004. LinGO Redwoods. a rich and dynamic treebank for HPSG. Research on Language and Computation, 2(4):575–596.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Daniel Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The proposition bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="11134" citStr="Palmer et al., 2005" startWordPosition="1729" endWordPosition="1732"> them from CCGbank altogether. We use the process described by Tse and Curran (2008) to restore the quotation marks and shift commas so that they always attach to the constituent to their left. This allows a grammar rule to be removed, preventing a great deal of spurious ambiguity and improving the speed of the C&amp;C parser (Clark and Curran, 2007) by 37%. (4) He joined as a director NP S\NP (S\NP)\(S\NP) CCGbank contains noisy complement and adjunct distinctions, because they were drawn from PTB function labels which imperfectly represent the distinction. In our previous work we used Propbank (Palmer et al., 2005) to convert 1,543 complements to adjuncts and 13,256 adjuncts to complements (Honnibal and Curran, 2007). If a constituent such as as a director received an adjunct category, but was labelled as a core argument in Propbank, we changed it to a complement, using its head’s part-of-speech tag to infer its constituent type. We performed the equivalent transformation to ensure all peripheral arguments of verbs were analysed as adjuncts. 3.4 Verb-particle constructions Propbank also offers reliable annotation of verbparticle constructions. This was not available in the PTB, so Hockenmaier and Steedm</context>
<context position="30385" citStr="Palmer et al., 2005" startWordPosition="4790" endWordPosition="4793">ormance remained fairly stable on the dependencies left unchanged. The rebanked parser performed 0.8% worse than the CCGbank parser on the intersection dependencies, suggesting that the fine-grained distinctions we introduced did cause some sparse data problems. However, we did not change any of the parser’s maximum entropy features or hyperparameters, which are tuned for CCGbank. 10 Conclusion Research in natural language understanding is driven by the datasets that we have available. The most cited computational linguistics work to date is the Penn Treebank (Marcus et al., 1993)1. Propbank (Palmer et al., 2005) has also been very influential since its release, and NomBank has been used for semantic dependency parsing in the CoNLL 2008 and 2009 shared tasks. This paper has described how these resources can be jointly exploited using a linguistically motivated theory of syntax and semantics. The semantic annotations provided by Propbank and NomBank allowed us to build a corpus that takes much greater advantage of the semantic transparency of a deep grammar, using careful analyses and phenomenon-specific conversion rules. The major areas of CCGbank’s grammar left to be improved are the analysis of comp</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Daniel Gildea, and Paul Kingsbury. 2005. The proposition bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl Pollard</author>
<author>Ivan Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>The University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="3908" citStr="Pollard and Sag, 1994" startWordPosition="570" endWordPosition="573">Nombank-derived noun subcategorisation. Together, these changes modify 30% of the labelled dependencies in CCGbank, demonstrating how multiple resources can be brought together in a single, richly annotated corpus. We then train and evaluate a parser for these changes, to investigate their impact on the accuracy of a state-of-theart statistical CCG parser. 207 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 207–215, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics 2 Background and motivation Formalisms like HPSG (Pollard and Sag, 1994), LFG (Kaplan and Bresnan, 1982), and CCG (Steedman, 2000) are linguistically motivated in the sense that they attempt to explain and predict the limited variation found in the grammars of natural languages. They also attempt to specify how grammars construct semantic representations from surface strings, which is why they are sometimes referred to as deep grammars. Analyses produced by these formalisms can be more detailed than those produced by skeletal phrasestructure parsers, because they produce fully specified predicate-argument structures. Unfortunately, statistical parsers do not take </context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Carl Pollard and Ivan Sag. 1994. Head-Driven Phrase Structure Grammar. The University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Libin Shen</author>
<author>Lucas Champollion</author>
<author>Aravind K Joshi</author>
</authors>
<title>LTAG-spinal and the treebank: A new resource for incremental, dependency and semantic parsing.</title>
<date>2008</date>
<journal>Language Resources and Evaluation,</journal>
<volume>42</volume>
<issue>1</issue>
<contexts>
<context position="2245" citStr="Shen et al. (2008)" startWordPosition="330" endWordPosition="333"> the annotation scheme is developed. The difficulty of the task means that we ought to view treebanking as an ongoing process akin to grammar development, such as the many years of work on the ERG (Flickinger, 2000). This paper demonstrates how a treebank can be rebanked to incorporate novel analyses and information from existing resources. We chose to work on CCGbank (Hockenmaier and Steedman, 2007), a Combinatory Categorial Grammar (Steedman, 2000) treebank acquired from the Penn Treebank (Marcus et al., 1993). This work is equally applicable to the corpora described by Miyao et al. (2004), Shen et al. (2008) or Cahill et al. (2008). Our first changes integrate four previously suggested improvements to CCGbank. We then describe a novel CCG analysis of NP predicateargument structure, which we implement using NomBank (Meyers et al., 2004). Our analysis allows the distinction between core and peripheral arguments to be represented for predicate nouns. With this distinction, an entailment recognition system could recognise that Google’s acquisition of YouTube entailed Google acquired YouTube, because equivalent predicate-argument structures are built for both. Our analysis also recovers nonlocal depen</context>
</contexts>
<marker>Shen, Champollion, Joshi, 2008</marker>
<rawString>Libin Shen, Lucas Champollion, and Aravind K. Joshi. 2008. LTAG-spinal and the treebank: A new resource for incremental, dependency and semantic parsing. Language Resources and Evaluation, 42(1):1–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stuart M Shieber</author>
</authors>
<title>An Introduction to UnificationBased Approaches to Grammar,</title>
<date>1986</date>
<volume>4</volume>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<contexts>
<context position="7701" citStr="Shieber, 1986" startWordPosition="1182" endWordPosition="1183">s. CCG extends the basic application rules of pure categorial grammar with (generalised) composition rules and type raising. The most common rules are: X/Y Y X (&gt;) Y X\Y X (&lt;) X/Y Y /Z X/Z (&gt;B) Y \Z X\Y X\Z (&lt;B) Y /Z X\Y X/Z (&lt;B,) CCGbank (Hockenmaier and Steedman, 2007) extends this compact set of combinatory rules with a set of type-changing rules, designed to strike a better balance between sparsity in the category set and ambiguity in the grammar. We mark typechanging rules TC in our derivations. In wide-coverage descriptions, categories are generally modelled as typed-feature structures (Shieber, 1986), rather than atomic symbols. This allows the grammar to include a notion of headedness, and to unify under-specified features. We occasionally must refer to these additional details, for which we employ the following notation. Features are annotated in square-brackets, e.g. S[dcl]. Head-finding indices are annotated on categories in subscripts, e.g. (NPy\NPy)/NP.. The index of the word the category is assigned to is left implicit. We will sometimes also annotate derivations with the heads of categories as they are being built, to help the reader keep track of what lexemes have been bound to w</context>
</contexts>
<marker>Shieber, 1986</marker>
<rawString>Stuart M. Shieber. 1986. An Introduction to UnificationBased Approaches to Grammar, volume 4 of CSLI Lecture Notes. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="2081" citStr="Steedman, 2000" startWordPosition="303" endWordPosition="304">Treebanking is a difficult engineering task: coverage, cost, consistency and granularity are all competing concerns that must be balanced against each other when the annotation scheme is developed. The difficulty of the task means that we ought to view treebanking as an ongoing process akin to grammar development, such as the many years of work on the ERG (Flickinger, 2000). This paper demonstrates how a treebank can be rebanked to incorporate novel analyses and information from existing resources. We chose to work on CCGbank (Hockenmaier and Steedman, 2007), a Combinatory Categorial Grammar (Steedman, 2000) treebank acquired from the Penn Treebank (Marcus et al., 1993). This work is equally applicable to the corpora described by Miyao et al. (2004), Shen et al. (2008) or Cahill et al. (2008). Our first changes integrate four previously suggested improvements to CCGbank. We then describe a novel CCG analysis of NP predicateargument structure, which we implement using NomBank (Meyers et al., 2004). Our analysis allows the distinction between core and peripheral arguments to be represented for predicate nouns. With this distinction, an entailment recognition system could recognise that Google’s acq</context>
<context position="3966" citStr="Steedman, 2000" startWordPosition="581" endWordPosition="583">odify 30% of the labelled dependencies in CCGbank, demonstrating how multiple resources can be brought together in a single, richly annotated corpus. We then train and evaluate a parser for these changes, to investigate their impact on the accuracy of a state-of-theart statistical CCG parser. 207 Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 207–215, Uppsala, Sweden, 11-16 July 2010. c�2010 Association for Computational Linguistics 2 Background and motivation Formalisms like HPSG (Pollard and Sag, 1994), LFG (Kaplan and Bresnan, 1982), and CCG (Steedman, 2000) are linguistically motivated in the sense that they attempt to explain and predict the limited variation found in the grammars of natural languages. They also attempt to specify how grammars construct semantic representations from surface strings, which is why they are sometimes referred to as deep grammars. Analyses produced by these formalisms can be more detailed than those produced by skeletal phrasestructure parsers, because they produce fully specified predicate-argument structures. Unfortunately, statistical parsers do not take advantage of this potential detail. Statistical parsers in</context>
<context position="6281" citStr="Steedman, 2000" startWordPosition="941" endWordPosition="943">mations which can be made with no additional information. That is, sometimes the existing trees allow transformation rules to be written that improve the quality of the grammar. Linguistic theories are constantly changing, which means that there is a substantial lag between what we (think we) understand of grammar and the annotations in our corpora. The grammar engineering process we describe, which we dub rebanking, is intended to reduce this gap, tightening the feedback loop between formal and computational linguistics. 2.1 Combinatory Categorial Grammar Combinatory Categorial Grammar (CCG; Steedman, 2000) is a lexicalised grammar, which means that all grammatical dependencies are specified in the lexical entries and that the production of derivations is governed by a small set of rules. Lexical categories are either atomic (S, NP, PP, N), or a functor consisting of a result, directional slash, and argument. For instance, in might head a PP-typed constituent with one NP-typed argument, written as PP/NP. A category can have a functor as its result, so that a word can have a complex valency structure. For instance, a verb phrase is represented by the category S\NP: it is a function from a leftwar</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The Syntactic Process. The MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Tse</author>
<author>James R Curran</author>
</authors>
<title>Punctuation normalisation for cleaner treebanks and parsers.</title>
<date>2008</date>
<booktitle>In Proceedings of the Australian Language Technology Workshop,</booktitle>
<volume>6</volume>
<pages>151--159</pages>
<publisher>ALTW, Hobart, Australia.</publisher>
<contexts>
<context position="10598" citStr="Tse and Curran (2008)" startWordPosition="1639" endWordPosition="1642">n (2007) addressed this by manually annotating all of the ambiguous noun phrases in the PTB, and went on to use this information to correct 20,409 dependencies (1.95%) in CCGbank (Vadas and Curran, 2008). Our changes build on this corrected corpus. 3.2 Punctuation corrections The syntactic analysis of punctuation is notoriously difficult, and punctuation is not always treated consistently in the Penn Treebank (Bies et al., 1995). Hockenmaier (2003) determined that quotation marks were particularly problematic, and therefore removed them from CCGbank altogether. We use the process described by Tse and Curran (2008) to restore the quotation marks and shift commas so that they always attach to the constituent to their left. This allows a grammar rule to be removed, preventing a great deal of spurious ambiguity and improving the speed of the C&amp;C parser (Clark and Curran, 2007) by 37%. (4) He joined as a director NP S\NP (S\NP)\(S\NP) CCGbank contains noisy complement and adjunct distinctions, because they were drawn from PTB function labels which imperfectly represent the distinction. In our previous work we used Propbank (Palmer et al., 2005) to convert 1,543 complements to adjuncts and 13,256 adjuncts to</context>
</contexts>
<marker>Tse, Curran, 2008</marker>
<rawString>Daniel Tse and James R. Curran. 2008. Punctuation normalisation for cleaner treebanks and parsers. In Proceedings of the Australian Language Technology Workshop, volume 6, pages 151–159. ALTW, Hobart, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vadas</author>
<author>James Curran</author>
</authors>
<title>Adding noun phrase structure to the Penn Treebank.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>240--247</pages>
<publisher>ACL,</publisher>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="9985" citStr="Vadas and Curran (2007)" startWordPosition="1545" endWordPosition="1548">ed by the Fidditch parser (Hindle, 1983), which produced flat brackets for these constructions. The bracketing decision was also a source of annotator disagreement (Bies et al., 1995). When Hockenmaier and Steedman (2002) went to acquire a CCG treebank from the PTB, this posed a problem. There is no equivalent way to leave these structures under-specified in CCG, because derivations must be binary branching. They therefore employed a simple heuristic: assume all such structures branch to the right. Under this analysis, crude oil is not a constituent, producing an incorrect analysis as in (1). Vadas and Curran (2007) addressed this by manually annotating all of the ambiguous noun phrases in the PTB, and went on to use this information to correct 20,409 dependencies (1.95%) in CCGbank (Vadas and Curran, 2008). Our changes build on this corrected corpus. 3.2 Punctuation corrections The syntactic analysis of punctuation is notoriously difficult, and punctuation is not always treated consistently in the Penn Treebank (Bies et al., 1995). Hockenmaier (2003) determined that quotation marks were particularly problematic, and therefore removed them from CCGbank altogether. We use the process described by Tse and </context>
</contexts>
<marker>Vadas, Curran, 2007</marker>
<rawString>David Vadas and James Curran. 2007. Adding noun phrase structure to the Penn Treebank. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 240–247. ACL, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Vadas</author>
<author>James R Curran</author>
</authors>
<title>Parsing noun phrase structure with CCG.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>335--343</pages>
<publisher>ACL,</publisher>
<location>Columbus, Ohio, USA.</location>
<contexts>
<context position="3056" citStr="Vadas and Curran (2008)" startWordPosition="452" endWordPosition="455">mplement using NomBank (Meyers et al., 2004). Our analysis allows the distinction between core and peripheral arguments to be represented for predicate nouns. With this distinction, an entailment recognition system could recognise that Google’s acquisition of YouTube entailed Google acquired YouTube, because equivalent predicate-argument structures are built for both. Our analysis also recovers nonlocal dependencies mediated by nominal predicates; for instance, Google is the agent of acquire in Google’s decision to acquire YouTube. The rebanked corpus extends CCGbank with: 1. NP brackets from Vadas and Curran (2008); 2. Restored and normalised punctuation; 3. Propbank-derived verb subcategorisation; 4. Verb particle structure drawn from Propbank; 5. Restrictive and non-restrictive adnominals; 6. Reanalyses to promote better head-finding; 7. Nombank-derived noun subcategorisation. Together, these changes modify 30% of the labelled dependencies in CCGbank, demonstrating how multiple resources can be brought together in a single, richly annotated corpus. We then train and evaluate a parser for these changes, to investigate their impact on the accuracy of a state-of-theart statistical CCG parser. 207 Proceed</context>
<context position="10180" citStr="Vadas and Curran, 2008" startWordPosition="1578" endWordPosition="1581">nmaier and Steedman (2002) went to acquire a CCG treebank from the PTB, this posed a problem. There is no equivalent way to leave these structures under-specified in CCG, because derivations must be binary branching. They therefore employed a simple heuristic: assume all such structures branch to the right. Under this analysis, crude oil is not a constituent, producing an incorrect analysis as in (1). Vadas and Curran (2007) addressed this by manually annotating all of the ambiguous noun phrases in the PTB, and went on to use this information to correct 20,409 dependencies (1.95%) in CCGbank (Vadas and Curran, 2008). Our changes build on this corrected corpus. 3.2 Punctuation corrections The syntactic analysis of punctuation is notoriously difficult, and punctuation is not always treated consistently in the Penn Treebank (Bies et al., 1995). Hockenmaier (2003) determined that quotation marks were particularly problematic, and therefore removed them from CCGbank altogether. We use the process described by Tse and Curran (2008) to restore the quotation marks and shift commas so that they always attach to the constituent to their left. This allows a grammar rule to be removed, preventing a great deal of spu</context>
</contexts>
<marker>Vadas, Curran, 2008</marker>
<rawString>David Vadas and James R. Curran. 2008. Parsing noun phrase structure with CCG. In Proceedings of the 46th Annual Meeting of the Association for Computational Linguistics, pages 335–343. ACL, Columbus, Ohio, USA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>