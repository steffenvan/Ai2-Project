<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000023">
<title confidence="0.917297">
Predicting Thread Discourse Structure over Technical Web Forums
</title>
<note confidence="0.685048">
Li Wang,&apos;° Marco Lui,&apos;° Su Nam Kim,&apos;° Joakim Nivre* and Timothy Baldwin&apos;°
♠ Dept. of Computer Science and Software Engineering, University of Melbourne
♥ NICTA Victoria Research Laboratory
♦ Dept. of Linguistics and Philology, Uppsala University
</note>
<email confidence="0.9763955">
li.wang.d@gmail.com, saffsd@gmail.com,
sunamkim@gmail.com, joakim.nivre@lingfil.uu.se, tb@ldwin.net
</email>
<sectionHeader confidence="0.995621" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999591125">
Online discussion forums are a valuable
means for users to resolve specific information
needs, both interactively for the participants
and statically for users who search/browse
over historical thread data. However, the com-
plex structure of forum threads can make it
difficult for users to extract relevant informa-
tion. The discourse structure of web forum
threads, in the form of labelled dependency re-
lationships between posts, has the potential to
greatly improve information access over web
forum archives. In this paper, we present the
task of parsing user forum threads to deter-
mine the labelled dependencies between posts.
Three methods, including a dependency pars-
ing approach, are proposed to jointly clas-
sify the links (relationships) between posts
and the dialogue act (type) of each link. The
proposed methods significantly surpass an in-
formed baseline. We also experiment with “in
situ” classification of evolving threads, and es-
tablish that our best methods are able to per-
form equivalently well over partial threads as
complete threads.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999945976744186">
Web user forums (or simply “forums”) are online
platforms for people to discuss information and ob-
tain information via a text-based threaded discourse,
generally in a pre-determined domain (e.g. IT sup-
port or DSLR cameras). With the advent of Web
2.0, there has been an explosion of web authorship in
this area, and forums are now widely used in various
areas such as customer support, community devel-
opment, interactive reporting and online eduction.
In addition to providing the means to interactively
participate in discussions or obtain/provide answers
to questions, the vast volumes of data contained in
forums make them a valuable resource for “support
sharing”, i.e. looking over records of past user inter-
actions to potentially find an immediately applica-
ble solution to a current problem. On the one hand,
more and more answers to questions over a wide
range of domains are becoming available on forums;
on the other hand, it is becoming harder and harder
to extract and access relevant information due to the
sheer scale and diversity of the data.
This research aims at enhancing information ac-
cess and support sharing, by mining the discourse
structure of troubleshooting-oriented web user fo-
rum threads. Previous research has shown that sim-
ple thread structure information (e.g. reply-to struc-
ture) can enhance tasks such as forum information
retrieval (Seo et al., 2009) and post quality assess-
ment (Lui and Baldwin, 2009). We aim to move be-
yond simple threading, to predict not only the links
between posts, but also show the manner of each
link, in the form of the discourse structure of the
thread. In doing so, we hope to be able to perform
richer visualisation of thread structure (e.g. high-
lighting the key posts which appear to have led to
a successful resolution to a problem), and more fine-
grained weighting of posts in threads for search pur-
poses.
To illustrate the task, we use an example thread,
made up of 5 posts from 4 distinct participants, from
the CNET forum dataset of Kim et al. (2010b), as
shown in Figure 1. The discourse structure of the
thread is modelled as a rooted directed acyclic graph
</bodyText>
<page confidence="0.992134">
13
</page>
<note confidence="0.9816555">
Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 13–25,
Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics
</note>
<figureCaption confidence="0.999813">
Figure 1: A snippeted and annotated CNET thread
</figureCaption>
<bodyText confidence="0.999924625">
(DAG) with a dialogue act label associated with each
edge of the graph. In this example, UserA initiates
the thread with a question (dialogue act = Question-
Question) in the first post, by asking how to create
an interactive input box on a webpage. In response,
UserB and UserC provide independent answers (di-
alogue act = Answer-Answer). UserA responds to
UserC to confirm the details of the solution (dia-
logue act = Answer-Confirmation), and at the same
time, adds extra information to his/her original ques-
tion (dialogue act = Question-Add); i.e., this one
post has two distinct dependency links associated
with it. Finally, UserD proposes a different solution
again to the original question.
To predict thread discourse structure of this type,
we jointly classify the links and dialogue acts be-
tween posts, experimenting with a variety of su-
pervised classification methods, namely dependency
parsing and linear-chain conditional random fields.
In this, we build on the earlier work of Kim et al.
(2010b) who first proposed the task of thread dis-
course analysis, but only carried out experiments on
post linking and post dialogue act classification as
separate tasks. In addition to achieving state-of-the-
art accuracy over the task, we carry out in-depth
analysis of classification effectiveness at different
thread depths, and establish that the accuracy of our
method over partial threads is equivalent to that over
full threads, indicating that the method is applica-
ble to in-situ thread classification. Finally, we in-
vestigate the role of user-level features in discourse
structure analysis.
</bodyText>
<sectionHeader confidence="0.999298" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.998177048780488">
This work builds directly on earlier work of a subset
of the authors (Kim et al., 2010b), whereby a novel
post-level dialogue act set was proposed, and used
as the basis for annotation of a set of threads taken
from CNET. In the original work, we proposed a set
of novel features, which we applied to the separate
tasks of post link classification and dialogue act clas-
sification. We later applied the same basic method-
ology to dialogue act classification over one-on-one
live chat data with provided message dependencies
(Kim et al., 2010a), demonstrating the generalisabil-
ity of the original method. In both cases, however,
we tackled only a single task, either link classifica-
tion (optionally given dialogue act tags) or dialogue
act classification, but never the two together. In this
paper, we take the obvious step of exploring joint
classification of post link and dialogue act tags, to
generate full thread discourse structures.
Discourse disentanglement (i.e. link classifica-
tion) and dialogue act tagging have been studied
largely as independent tasks. Discourse disentangle-
ment is the task of dividing a conversation thread
(Elsner and Charniak, 2008; Lemon et al., 2002)
or document thread (Wolf and Gibson, 2005) into
a set of distinct sub-discourses. The disentangled
discourse is sometimes assumed to take the form of
a tree structure (Grosz and Sidner, 1986; Lemon et
al., 2002; Seo et al., 2009), an acyclic graph struc-
ture (Ros´e et al., 1995; Schuth et al., 2007; Elsner
and Charniak, 2008; Wang et al., 2008; Lin et al.,
2009), or a more general cyclic chain graph struc-
ture (Wolf and Gibson, 2005). Dialogue acts are
used to describe the function or role of an utterance
in a discourse, and have been applied to the anal-
ysis of mediums of communication including con-
versational speech (Stolcke et al., 2000; Shriberg et
al., 2004; Murray et al., 2006), email (Cohen et al.,
2004; Carvalho and Cohen, 2005; Lampert et al.,
2008), instant messaging (Ivanovic, 2008; Kim et
al., 2010a), edited documents (Soricut and Marcu,
2003; Sagae, 2009) and online forums (Xi et al.,
</bodyText>
<figure confidence="0.996145272727273">
1+Answer-Confirmation
4+Answer-Answer
User C
Post 3
asp.net c\# video
I’ve prepared for you video.link click ...
Ø
0+Question-Question
HTML Input Code
...Please can someone tell me how to create an input
box that asks the user to enter their ID, and then allows
them to press go. It will then redirect to the page ...
2+Answer-Answer
User A
Post 1
1+Answer-Answer
User B
Post 2
Re: html input code
Part 1: create a form with a text field. See ... Part
2: give it a Javascript action
3+Question-Add
Thank You!
Thanks a lot for that ... I have Microsoft Visual
Studio 6, what program should I do this in? Lastly,
how do I actually include this in my site? ...
User A
Post 4
User D
Post 5
A little more help
... You would simply do it this way: ... You could
also just ... An example of this is ...
</figure>
<page confidence="0.996817">
14
</page>
<bodyText confidence="0.999773051282052">
2004; Weinberger and Fischer, 2006; Wang et al.,
2007; Fortuna et al., 2007; Kim et al., 2010b). For a
more complete review of models for discourse dis-
entanglement and dialogue act tagging, see Kim et
al. (2010b).
Joint classification has been applied in a number
of different contexts, based on the intuition that it
should be possible to harness interactions between
different sub-tasks to the mutual benefit of both.
Warnke et al. (1997) jointly performed segmenta-
tion and dialogue act classification over a German
spontaneous speech corpus. In their approach, the
predictions of a multi-layer perceptron classifier on
dialogue act boundaries were fed into an n-gram
language model, which was used for the joint seg-
mentation and classification of dialogue acts. Sut-
ton and McCallum (2005) performed joint parsing
and semantic role labelling (SRL), using the results
of a probabilistic SRL system to improve the accu-
racy of a probabilistic parser. Finkel and Manning
(2009) built a joint, discriminative model for pars-
ing and named entity recognition (NER), address-
ing the problem of inconsistent annotations across
the two tasks, and demonstrating that NER bene-
fited considerably from the interaction with parsing.
Dahlmeier et al. (2009) proposed a joint probabilis-
tic model for word sense disambiguation (WSD) of
prepositions and SRL of prepositional phrases (PPs),
and achieved state-of-the-art results over both tasks.
There has been a recent growth in user-level
research over forums. Lui and Baldwin (2009)
explored a range of user-level features, including
replies-to and co-participation graph analysis, for
post quality classification. Lui and Baldwin (2010)
introduced a novel user classification task where
each user is classified against four attributes: clar-
ity, proficiency, positivity and effort. User commu-
nication roles in web forums have also been studied
(Chan and Hayes, 2010; Chan et al., 2010).
Threading information has been shown to en-
hance retrieval effectiveness for post-level retrieval
(Xi et al., 2004; Seo et al., 2009), thread-level
retrieval (Seo et al., 2009; Elsas and Carbonell,
2009), sentence-level shallow information extrac-
tion (Sondhi et al., 2010), and near-duplicate thread
detection (Muthmann et al., 2009). These results
suggest that the thread structural representation used
in this research, which includes both linking struc-
ture and the dialogue act associated with each link,
could potentially provide even greater leverage in
these retrieval tasks.
Another related research area is post-level classi-
fication, such as general post quality classification
(Weimer et al., 2007; Weimer and Gurevych, 2007;
Wanas et al., 2008; Lui and Baldwin, 2009), and
post descriptiveness in particular domains (e.g. med-
ical forums: Leaman et al. (2010)). It has been
demonstrated (Wanas et al., 2008; Lui and Bald-
win, 2009) that thread discourse structure can signif-
icantly improve the classification accuracy for post-
level tasks.
Initiation–response pairs (e.g. question–answer,
assessment–agreement, and blame–denial) from on-
line forums have the potential to enhance thread
summarisation or automatically generate knowledge
bases for Community Question Answering (cQA)
services such as Yahoo! Answers. While initiation–
response pair identification has been explored as a
pairwise ranking problem (Wang and Ros´e, 2010),
question–answer pair identification has been ap-
proached via the two separate sub-tasks of ques-
tion classification and answer detection (Cong et al.,
2008; Ding et al., 2008; Cao et al., 2009). Our
thread discourse structure prediction task includes
joint classification of post roles (i.e. dialogue acts)
and links, and could potentially be performed at the
sub-post sentence level to extract initiation–response
pairs.
</bodyText>
<sectionHeader confidence="0.899233" genericHeader="method">
3 Task Description and Data Set
</sectionHeader>
<bodyText confidence="0.999922">
The main task performed in this research is joint
classification of inter-post links (Link) and dialogue
acts (DA) within forum threads. In this, we assume
that a post can only link to an earlier post (or a vir-
tual root node), and that dialogue acts are labels on
edges. It is possible for there to be multiple edges
from a given post, e.g. if a post both confirms the va-
lidity of an answer and adds extra information to the
original question (as happens in Post4 in Figure 1).
We experiment with two different approaches to
joint classification: (1) a linear-chain CRF over
combined Link/DA post labels; and (2) a depen-
dency parser. The joint classification task is a nat-
ural fit for dependency parsing, in that the task is
intrinsically one of inferring labelled dependencies
</bodyText>
<page confidence="0.996004">
15
</page>
<bodyText confidence="0.997817864197531">
between posts, but it has a number of special prop-
erties that distinguish it from standard dependency
parsing:
strict reverse-chronological directionality: the
head always precedes the dependent, in terms
of the chronological sequencing of posts.
non-projective dependencies: threads can contain
non-projective dependencies, e.g. in a 4-post
thread, posts 2 and 3 may be dependent on
post 1, and post 4 dependent on post 2; around
2% of the threads in our dataset contain non-
projective dependencies.
multi-headedness: it is possible for a given post to
have multiple heads, including the possibility
of multiple dependency links to the same post
(e.g. adding extra information to a question
[Question-Add] as well as retracting infor-
mation from the original question [Question-
Correction]); around 6% of the threads in our
dataset contain multi-headed dependencies.
disconnected sub-graphs: it is possible for there to
be disconnected sub-graphs, e.g. in instances
where a user hijacks a thread to ask their
own unrelated question, or submit an unrelated
spam post; around 2% of the threads in our
dataset contain disconnected sub-graphs.
The first constraint potentially simplifies depen-
dency parsing, and non-projective dependencies are
relatively well understood in the dependency parsing
community (Tapanainen and Jarvinen, 1997; Mc-
Donald et al., 2005). Multi-headedness and dis-
connected sub-graphs pose greater challenges to de-
pendency parsing, although there has been research
done on both (McDonald and Pereira, 2006; Sagae
and Tsujii, 2008; Eisner and Smith, 2005). The
combination of non-projectivity, multi-headedness
and disconnected sub-graphs in a single dataset,
however, poses a challenge for dependency parsing.
In addition to performing evaluation in batch
mode over complete threads, we consider the task of
“in situ thread classification”, whereby we predict
the discourse structure of a thread after each post.
This is intended to simulate the more realistic set-
ting of incrementally crawling/updating thread data,
but needing to predict discourse structure for partial
threads. We are interested in determining the rela-
tive degradation in accuracy for in situ classification
vs. batch classification.
As our dataset, we use the CNET forum dataset
of Kim et al. (2010b),1 which contains 1332 an-
notated posts spanning 315 threads, collected from
the Operating System, Software, Hardware and Web
Development sub-forums of cnet.2 Each post is la-
belled with one or more links (including the possi-
bility of null-links, where the post doesn’t link to
any other post), and each link is labelled with a di-
alogue act. The dialogue act set is made up of 5
super-categories: Question, Answer, Resolution
(confirmation of the question being resolved), Re-
production (external confirmation of a proposed so-
lution working) and Other. The Question category
contains 4 sub-classes: Question, Add, Confirma-
tion and Correction. Similarly, the Answer cate-
gory contains 5 sub-classes: Answer, Add, Confir-
mation, Correction and Objection. For example,
the label Question-Add signifies the Question su-
perclass and Add subclass, i.e. addition of extra in-
formation to a question. For full details of the dia-
logue act tagset, see Kim et al. (2010b).
Dependency links are represented by their relative
position in the chronologically-sorted list of posts,
e.g. 1 indicates a link back to the preceding post,
and 2 indicates a link back two posts.
Unless otherwise noted, evaluation is over the
combined link and dialogue act tag, including the
combination of superclass and subclass for the
Question and Answer dialogue acts. For ex-
ample, 1+Answer-Answer indicates a dependency
link back one post, which is an answer to a question.
The most common label in the dataset is 1+Answer-
answer (28.4%).
</bodyText>
<sectionHeader confidence="0.937313" genericHeader="method">
4 Learners and Features
</sectionHeader>
<subsectionHeader confidence="0.989241">
4.1 Learners
</subsectionHeader>
<bodyText confidence="0.9999948">
To predict thread discourse structure, we use a struc-
tured classification approach — based on the find-
ings of Kim et al. (2010b) and Kim et al. (2010a)
— and a dependency parser. The structured clas-
sification approach we experiment with is a linear-
</bodyText>
<footnote confidence="0.999969">
1Available from http://www.csse.unimelb.edu.
au/research/lt/resources/conll2010-thread/
2http://forums.cnet.com/
</footnote>
<page confidence="0.998018">
16
</page>
<bodyText confidence="0.999989357142858">
chain conditional random field learner (CRF: Laf-
ferty et al. (2001)), within which we explore two
simple approaches to joint classification, as is ex-
plained in Section 5.1. Dependency parsing (K¨ubler
et al., 2009) is the task of automatically predicting
the dependency structure of a token sequence, in
the form of binary asymmetric dependency relations
with dependency types.
Standardly, CRFs have been applied to tasks such
as part-of-speech tagging, named entity recognition,
semantic role labelling and supertagging, where the
individual tokens are single words. Similarly, de-
pendency parsing is conventionally applied to sen-
tences, with single-word tokens. In our case, our
tokens are thread posts, with much greater scope for
feature engineering than single words, and techni-
cal challenges in scaling the underlying implemen-
tations to handle potentially much larger feature sets.
As our learners, we deployed CRFSGD (Bot-
tou, 2011) to learn the CRF, and MaltParser (Nivre
et al., 2007) as our dependency parser. CRFSGD
uses stochastic gradient descent to efficiently solve
the convex optimisation problem, and scales well to
large feature sets. We used the default parameter set-
tings for CRFSGD, with feature templates includ-
ing all unigram features of the current token as well
as bigram features combining the previous output to-
ken with the current token.
MaltParser implements transition-based parsing,
where no formal grammar is considered, and a tran-
sition system, or state machine, is learned to map a
sentence onto its dependency graph. One feature of
MaltParser that makes it well suited to our task is
that it is possible to define feature models of arbi-
trary complexity for each token. In presenting the
thread data to MaltParser, we represent the null-
link from the initial post of each thread, as well as
any disconnected posts, as the root.
To the best of our knowledge, there is no past
work on using dependency parsing to learn thread
discourse structure. Based on extensive experimen-
tation, we determined that the MaltParser configu-
ration that obtains the best results for our task is the
Nivre algorithm in arc-standard mode (Nivre, 2003;
Nivre, 2004), using LIBSVM (Chang and Lin, 2011)
with a linear kernel as the learner, and a feature
model with exhaustive combinations of features re-
lating to the features and predictions of the first/top
three tokens from both “Input” and “Stack”.3 As
such, MaltParser is actually unable to predict any
non-projective structures, as experiments with algo-
rithms supporting non-projective structures invari-
ably led to lower results. In our choice of parsing al-
gorithm, we are also unable to detect posts with mul-
tiple heads, but can potentially detect disconnected
sub-graphs.
</bodyText>
<subsectionHeader confidence="0.871428">
4.2 Features
</subsectionHeader>
<bodyText confidence="0.931094428571429">
The features used in our classifiers are as follows:
Structural Features:
Initiator a binary feature indicating whether the
current post’s author is the thread initiator.
Position the relative position of the current post,
as a ratio over the total number of posts in the
thread.
</bodyText>
<subsectionHeader confidence="0.824714">
Semantic Features:
</subsectionHeader>
<bodyText confidence="0.999718636363636">
TitSim the relative location of the post which has
the most similar title (based on unweighted co-
sine similarity) to the current post.
PostSim the relative location of the post which
has the most similar content (based on un-
weighted cosine similarity) to the current post.
Punct the number of question marks (QuCount),
exclamation marks (ExCount) and URLs
(UrlCount) in the current post.
UserProf the class distribution (in the training
thread) of the author of the current post.
These features are drawn largely from the work
of Kim et al. (2010b), with two major differences:
(1) we do not use post context features because our
learners (i.e. CRFSGD and MaltParser) inherently
capture Markov chains; and (2) our UserProf fea-
tures are customised to the class set associated with
the task at hand, e.g. the UserProf features for the
standalone linking task take the form of the link la-
bels (and not dialogue act labels) of the posts by the
relevant author in the training data. Table 1 shows
the feature representation of the third post in a thread
</bodyText>
<page confidence="0.982895">
17
</page>
<figure confidence="0.374278">
Feature Value
Initiator 1.0
ExCount 4.0
QuCount 0.0
UrlCount 0.0
Position 0.25
PostSim 2.0
TitSim 2.0
UserProf x�
Explanation
post from the initiator
4 exclamation marks
0 question marks
0 URLs
i−1
n
</figure>
<bodyText confidence="0.9894398">
most similar to post 1
most similar to post 1
counts for posts of each
class from the same author
in the training data
</bodyText>
<tableCaption confidence="0.9927825">
Table 1: The feature presentation of the third post in a
thread of length 8
</tableCaption>
<bodyText confidence="0.999403181818182">
of length 8. The values of each feature are scaled to
the range [0, 1] before being fed into the learners.
We also experimented with other features,
including raw bag-of-words lexical features,
dimensionality-reduced lexical features (using
principal components analysis), and different post
similarity measures such as longest common subse-
quence (LCS) match. While we were able to obtain
gains in isolation, when combined with the other
features, these features had no impact, and are thus
not included in the results presented in this paper.
</bodyText>
<sectionHeader confidence="0.995249" genericHeader="method">
5 Classification Methodology
</sectionHeader>
<bodyText confidence="0.999963333333333">
All our experiments were carried out based on strati-
fied 10-fold cross-validation, stratifying at the thread
level to ensure that all posts from a given thread
occur in a single fold. The results are primarily
evaluated using post-level micro-averaged F-score
(Fµ: R = 1), and additionally with thread-level F-
score/classification accuracy (i.e. the proportion of
threads where all posts have been correctly classi-
fied4), where space allows. Statistical significance
is tested using randomised estimation (Yeh, 2000)
with p &lt; 0.05. Initial experiments showed it is
hard for learners to discover which posts have multi-
ple links, largely due to the sparsity of multi-headed
posts (which account for less than 5% of the total
posts). Therefore, only the the most recent link for
</bodyText>
<footnote confidence="0.98958325">
3http://maltparser.org/userguide.html#
parsingalg
4Classification accuracy = F-score at the thread-level, as
each thread is assigned a single label of correct or incorrect.
</footnote>
<bodyText confidence="0.994602">
each multi-headed post was included in training, but
evaluation still considers all links.
</bodyText>
<subsectionHeader confidence="0.985784">
5.1 Joint classification
</subsectionHeader>
<bodyText confidence="0.9999235">
In our experiments, we test two basic approaches to
joint classification for the CRF: (1) classifying the
Link and DA separately, and composing the predic-
tions to form the joint classification (Composition);
and (2) combining the Link and DA labels into a sin-
gle class, and applying the learner over the posts
with the combined class (Combine). Note that
Composition has the potential for mismatches in
the number of Link and DA predictions it gener-
ates, causing complications in the class composition.
Even if the same number of labels is predicted for
both Link and DA, if multiple tags are predicted in
both cases, we are left with the problem of determin-
ing which link label to combine with which dialogue
act label. As such, we have our reservations about
Composition, but as the CRF performs strict 1-of-
n labelling, these are not issues in the experiments
reported herein.
MaltParser natively handles the combination of
Link and DA in its dependency parsing formulation.
</bodyText>
<subsectionHeader confidence="0.978031">
5.2 In Situ Thread Classification
</subsectionHeader>
<bodyText confidence="0.999991105263158">
One of the biggest challenges in classifying the dis-
course structure of a forum thread is that threads
evolve over time, as new posts are posted. In or-
der to capture this phenomenon, and compare the
accuracy of different models when applied to partial
thread data (artificially cutting off a thread at post
N) vs. complete threads.5 This is done in the fol-
lowing way: classification over the first two posts
only ([1, 2]), the first four posts ([1, 4]), the first six
posts ([1, 6]), the first eight posts ([1, 8]), and all
posts ([all]). In each case, we limit the test data
only, meaning that the only variable in play is the
extent of thread context used to learn the thread dis-
course structure for the given set of posts. We break
down the results in each case into the indicated sub-
threads, e.g. we take the predictions for [all], and
break them down into the results for [1, 2], [1, 4],
[1, 6], [1, 8] and [all], for direct comparison with the
predictions over the respective sub-thread data.
</bodyText>
<footnote confidence="0.836185666666667">
5In practice, completeness is defined at a given point in time,
when the crawl was done, and it is highly likely that some of the
“complete” threads had extra posts after the crawl.
</footnote>
<page confidence="0.742563666666667">
3−1
8
18
</page>
<table confidence="0.998005666666667">
Method Link DA
Kim et al. (2010b) .863 / .676 .751 / .543
CRFSGD .891 / .727 .795 / .609
</table>
<tableCaption confidence="0.970414">
Table 2: Post/thread-level component-wise classification
F-scores for Link and DA classes
</tableCaption>
<sectionHeader confidence="0.989619" genericHeader="method">
6 Experiments and Analysis
</sectionHeader>
<subsectionHeader confidence="0.99277">
6.1 Joint classification
</subsectionHeader>
<bodyText confidence="0.99998852631579">
As our baseline for the task, we first use a sim-
ple majority class classifier in the form of the sin-
gle joint class of 1+Answer-Answer for all posts,
which has a post-level F-score of 0.284. A stronger
baseline is to classify all first posts as 0+Question-
Question and all subsequent posts as 1+Answer-
answer, which achieves a post-level F-score of
0.515 (labelled as Heuristic).
As described in Section 5.1, one approach to joint
classification with CRFSGD is to firstly conduct
component-wise classification over Link and DA
separately, and compose the predictions. The results
for the separate Link and DA classification tasks are
presented in Table 2, along with the best results for
Link and DA classification from Kim et al. (2010b).
At the component-wise tasks, our method is superior
to Kim et al. (2010b), based on a different learner
and slightly different feature set.
Next, we compose the component-wise clas-
sifications for the CRF into joint classifications
(Composition). We contrast this with the com-
bined class approach for CRFSGD and MaltParser
(jointly presented as Joint in Table 3). With the
combined class results, we additionally ablate each
of the feature types from Section 4.2, and also
present results for a dummy model, where no fea-
tures are provided and the prediction is based simply
on sequential priors (Dummy). The results are pre-
sented in Table 3, along with the Heuristic baseline
result.
Several interesting things can be observed from
the post-level F-score results in Table 3. First, with
no features (Dummy), while CRFSGD performs
slightly worse than the Heuristic baseline, Malt-
Parser significantly surpasses the baseline. This is
due to the richer sequential context model of Malt-
Parser. Second, the single feature with the greatest
impact on results is UserProf, i.e. user profile fea-
</bodyText>
<note confidence="0.716068">
Method CRFSGD MaltParser
</note>
<tableCaption confidence="0.918224666666667">
Table 3: Post/thread-level Link-DA joint classification F-
scores (“∗” signifies a significantly worse result than that
for the same learner with ALL features)
</tableCaption>
<bodyText confidence="0.99984803030303">
tures extracted from the training data; CRFSGD in
particular benefits from this feature. We return to ex-
plore this effect in Section 6.4. Third, although the
Initiator feature does not have much effect on CRF-
SGD, it affects the performance of MaltParser sig-
nificantly. Further experiments shown that the com-
bination of Initiator and UserProf is sufficient to
achieve a competitive result (i.e. 0.731). It therefore
seems that MaltParser is more robust than CRF-
SGD, whose performance relies crucially on user-
level features which must be learned from the train-
ing data (i.e. UserProf).
Looking to the thread-level F-scores, we observe
some interesting divergences from the post-level F-
score results. First, with no features (Dummy),
CRFSGD significantly outperforms both the base-
line and MaltParser. This appears to be because
CRFSGD performs particularly well over short
threads (e.g. of length 3 and 4), but worse over
longer threads. Second, the best thread-level F-
scores from CRFSGD (i.e. 0.587) and MaltParser
(i.e. 0.578) are not significantly different, despite the
discrepancy in post-level F-score (where CRFSGD
is markedly superior in this case). With the extra
features, the performance of MaltParser on short
threads appears to pick up noticeably, and the differ-
ence in post-level predictions is over longer threads.
If we evaluate the two models over DA super-
classes only (ignoring mismatches at the subclass
level for Question and Answer), the post-level F-
scores for joint classification with ALL features for
CRFSGD and MaltParser are 0.803 and 0.787, re-
spectively.
</bodyText>
<table confidence="0.976049266666667">
Heuristic .515*/ .311*
Dummy .508*/ .394* .533*/ .356*
Composition .728*/ .553* —
Joint +ALL .756 / .578 .738 / .578
−Initiator .745 / .569 .708*/ .534*
−Position .750 / .565 .736 / .568
−PostSim .753 / .578 .737 / .568
−TitSim .760 / .587 .734 / .571
−Punct .745 / .571 .735 / .578
−UserProf .672*/ .527* .701*/ .536*
19
Approaches Link DA
Component-wise .891 / .727* .795 / .609
CRFSGD decomp .893 / .749 .785 / .603
MaltParser decomp .870*/ .730* .766*/ .571*
</table>
<tableCaption confidence="0.996105">
Table 4: Post/thread-level Link and DA F-scores from
</tableCaption>
<bodyText confidence="0.952972875">
component-wise classification, and from Link-DA clas-
sification decomposition (“∗” signifies a significantly
worse result than the best result in that column)
Looking at the performance of CRFSGD (in
Combine mode) and MaltParser on disconnected
sub-graphs, while both models did predict a small
number of non-initial posts with null-links (includ-
ing MaltParser predicting 5 out of 6 posts in a sin-
gle thread as having null-links), none were correct,
and neither model was able to correctly predict any
of the 6 actual non-initial instances of null-links in
the dataset.
Finally, we took the joint classification results
from CRFSGD and MaltParser using ALL fea-
tures, and decomposed the predictions into Link and
DA. The results are presented in Table 4, along with
the results for component-wise classification from
Table 2. Somewhat surprisingly, the decomposed
predictions are mostly slightly worse than the re-
sults for the component-wise classification, despite
achieving higher F-score for the joint classification
task. This is simply due to the combined method
tending to get both labels correct or both labels
wrong, for a given post.
</bodyText>
<subsectionHeader confidence="0.999446">
6.2 Post Position-based Result Breakdown
</subsectionHeader>
<bodyText confidence="0.9999886">
One question in thread discourse structure classifica-
tion is how accurate the predictions are at different
depths in a thread (e.g. the first two posts vs. the sec-
ond two posts). A breakdown of results across posts
at different positions is presented in Figure 2.
The overall trend for both CRFSGD and Malt-
Parser is that it becomes increasingly hard to clas-
sify posts as we continue through a thread, due to
greater variability in discourse structure and greater
sparsity in the data. However, it is interesting to note
that the results for CRFSGD actually improve from
posts 7 and 8 ([7,8]) to posts 9 and onwards ([9, ]).
To further investigate this effect, we performed class
decomposition over the joint classification predic-
tions, and performed a similar breakdown of posts
</bodyText>
<figure confidence="0.580751">
Posts
</figure>
<figureCaption confidence="0.9462965">
Figure 2: Breakdown of post-level Link-DA results for
CRFSGD and MaltParser based on post position
</figureCaption>
<figure confidence="0.990871">
Decomposed Link
Posts
</figure>
<figureCaption confidence="0.882726">
Figure 3: Breakdown of post-level Link and DA F-score
based on the decomposition of CRFSGD and Malt-
Parser classifications
</figureCaption>
<bodyText confidence="0.9994916">
for Link and DA; the results are presented in Fig-
ure 3. It is clear that the anomaly for CRFSGD
comes from the DA component, due to there being
greater predictability in the dialogue for final posts
in a thread (users tend to confirm a successful reso-
lution of the problem, or report on successful exter-
nal reproduction of the solution). MaltParser seems
less adept at identifying that a post is at the end
of a thread, and predicting the dialogue act accord-
ingly. This observation is congruous with the find-
ings of McDonald and Nivre (2007) that errors prop-
agate, due to MaltParser’s greedy inference strat-
egy. The higher results for Link are to be expected,
as throughout the thread, most posts tend to link lo-
cally.
</bodyText>
<figure confidence="0.999250548387097">
1
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
[1,2] [3,4] [5,6] [7,8] [9,] All
CRFSGD
MaltParser
CRFSGD
MaltParser
[1,2] [3,4] [5,6] [7,8] [9,] All
Decomposed DA
CRFSGD
MaltParser
[1,2] [3,4] [5,6] [7,8] [9,] All
1
F
0.5
0
Posts
1
F
0.5
0
F
</figure>
<page confidence="0.91451">
20
</page>
<table confidence="0.99945825">
B/down [1, 2] [1, 4] [1, 6] [1, 8] [All]
❳❳❳❳❳❳❳❳❳
Test
[1, 2] .947/.947 — — — —
[1, 4] .946/.947 .836/.841 — —
[1, 6] .946/.947 .840/.841 .800/.794 — —
[1, 8] .946/.947 .840/.841 .800/.794 .780/.769 —
[All] .946/.946 .840/.838 .800/.791 .776/.767 .756/.738
</table>
<tableCaption confidence="0.9984895">
Table 5: Post-level Link-DA F-score for CRFSGD/MaltParser, based on in situ classification over sub-threads of
different lengths (indicated in the rows), broken down over different post extents (indicated in the columns)
</tableCaption>
<subsectionHeader confidence="0.9912">
6.3 In Situ Structure Prediction
</subsectionHeader>
<bodyText confidence="0.999982785714286">
As described in Section 5.2, we simulate in situ
thread discourse structure prediction by removing
differing numbers of posts from the tail of the thread,
and applying the trained model over the resultant
sub-threads. The results for in situ classification are
presented in Table 5, with the rows indicating the
size of the test sub-thread, and the columns being a
breakdown of results over different portions of the
classified thread. The reason that we do not pro-
vide numbers for all cells in the table is that the size
of the test sub-thread determines the post extents we
can breakdown the results into, e.g. we cannot return
results for posts 1–4 ([1, 4]) when the size of the test
thread was only two posts ([1, 2]).
From the results, we can see that both CRFSGD
and MaltParser are very robust when applied to par-
tial threads, to the extent that we actually achieve
higher results over shortened versions of the thread
than over the complete thread in some instances, al-
though the only difference that is statistically signif-
icant is over [1, 8] for CRFSGD, where the predic-
tion over the partial thread is actually superior to that
over the complete thread. From this, we can con-
clude that it is possible to apply our method to partial
threads without any reduction in effectiveness rela-
tive to classification over complete threads. As such,
our method is shown to be robust when applied to
real-time analysis of dynamically evolving threads.
</bodyText>
<subsectionHeader confidence="0.997724">
6.4 User profile feature analysis
</subsectionHeader>
<bodyText confidence="0.999624333333333">
In our experiments, we noticed that the user profile
feature (UserProf) is the most effective feature for
both CRFSGD and MaltParser. To gain a deeper
insight into the behaviour of the feature, we binned
the posts according to the number of times the author
had posted in the training data, evaluated based on a
</bodyText>
<table confidence="0.999650166666667">
Bin uscore Posts Total Total
per user users posts
High 224.6 251 1 251
Medium 1∼41.7 4∼48 45 395
Low 0 2∼4 157 377
Very Low 0 1 309 309
</table>
<tableCaption confidence="0.884129">
Table 6: Statistics for the 4 groups of users
</tableCaption>
<equation confidence="0.8299556">
user score (uscore) for each user:
�ni
j=1 spi,j
uscorei =
ni
</equation>
<bodyText confidence="0.99997852">
where ni is the number of posts by user i, and spi,j is
the number of posts by user i that occur as training
instances for other posts by the same author. uscore
reflects the average training–test post ratio per user
in cross-validation. Note that as we include all posts
from a given thread in a single partition during cross-
validation, it is possible for an author to have posted
4 times, but have a uscore of 0 due to those posts all
occurring in the same thread.
We ranked the users in the dataset in descending
order of uscore, sub-ranking on ni in cases of a tie
in uscore. The users were binned into 4 groups
of roughly equal post size. The detailed statistics
are shown in Table 6, noting that the high-frequency
bin (“High”) contains posts from a single user. We
present the post-level micro-averaged F-score for
posts in each bin based on CRFSGD, with and with-
out user profile features, in Figure 4.
Contrary to expectation, the UserProf features
have the greatest impact for users with fewer posts.
In fact, a statistically significant difference was ob-
served only for users with no posts in the training
data (uscore = 0), where the F-score jumped over
10% in absolute terms for both the Low and Very
Low bins. Our explanation for this effect is that the
</bodyText>
<page confidence="0.997712">
21
</page>
<figure confidence="0.737033">
User Group
</figure>
<figureCaption confidence="0.849762333333333">
Figure 4: Post-level joint classification results for users
binned by uscore, based on CRFSGD with and without
UserProf features)
</figureCaption>
<bodyText confidence="0.999109">
fit users with no posts in the training data, rather than
prolific users. We wish to explore this effect further,
including incorporating unsupervised user-level fea-
tures into our classifiers.
</bodyText>
<sectionHeader confidence="0.951124" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9987805">
The authors wish to acknowledge the development
efforts of Johan Hall in configuring MaltParser to
handle numeric features, and be able to parse thread
structures. NICTA is funded by the Australian gov-
ernment as represented by Department of Broad-
band, Communication and Digital Economy, and the
Australian Research Council through the ICT Centre
of Excellence programme.
</bodyText>
<figure confidence="0.9926272">
High Median Low Very Low
0.9
0.8
0.7
0.6
0.5
0.4
0.3
0.2
0.1
0
1
With UserProf
Without UserProf
F
</figure>
<bodyText confidence="0.988293">
lack of user profile information is predictive of the
sort of posts we can expect from a user (i.e. they
tend to be newbie users, asking questions).
</bodyText>
<sectionHeader confidence="0.989722" genericHeader="conclusions">
7 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.999946037037037">
In this research, we explored the joint classification
of web user forum thread discourse structure, in the
form of a rooted directed acyclic graph over posts,
with edges labelled with dialogue acts. Three classi-
fication approaches were proposed: separately pre-
dicting Link and DA labels, and composing them
into a joint class; predicting a combined Link-DA
class using a structured classifier; and applying de-
pendency parsing to the problem. We found the
combined approach based on CRFSGD to perform
best over the task, closely followed by dependency
parsing with MaltParser.
We also examined the task of in situ classification
of dialogue structure, in the form of predicting the
discourse structure of partial threads, as contrasted
with classifying only complete threads. We found
that there was no drop in F-score over different sub-
extents of the thread in classifying partial threads,
despite the relative lack of thread context.
In future work, we plan to delve further into de-
pendency parsing, looking specifically at the impli-
cations of multi-headedness and disconnected sub-
graphs on dependency parsing. We also intend to
carry out meta-classification, combining the predic-
tions of CRFSGD and MaltParser.
Our user profile features were found to be the
pick of our features, but counter-intuitively, to bene-
</bodyText>
<sectionHeader confidence="0.998945" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.993373588235294">
L´eon Bottou. 2011. CRFSGD software. http://
leon.bottou.org/projects/sgd.
Xin Cao, Gao Cong, Bin Cui, Christian S. Jensen, and
Ce Zhang. 2009. The use of categorization infor-
mation in language models for question retrieval. In
Proceedings of the 18th ACM Conference on Informa-
tion and Knowledge Management (CIKM 2009), pages
265–274, Hong Kong, China.
Vitor R. Carvalho and William W. Cohen. 2005. On
the collective classification of email ”speech acts”. In
Proceedings of 28th International ACM-SIGIR Con-
ference on Research and Development in Information
Retrieval (SIGIR 2005), pages 345–352.
Jeffrey Chan and Conor Hayes. 2010. Decomposing dis-
cussion forums using user roles. In Proceedings of the
WebSci10: Extending the Frontiers of Society On-Line
(WebSci10), pages 1–8, Raleigh, USA.
Jeffrey Chan, Conor Hayes, and Elizabeth M. Daly.
2010. Decomposing discussion forums using user
roles. In Proceedings of the Fourth International AAAI
Conference on Weblogs and Social Media (ICWSM
2010), pages 215–8, Washington, USA.
Chih-Chung Chang and Chih-Jen Lin. 2011. LIB-
SVM: A library for support vector machines. ACM
Transactions on Intelligent Systems and Technology,
2(3):27:1–27:27. Software available at http://
www.csie.ntu.edu.tw/˜cjlin/libsvm.
William W. Cohen, Vitor R. Carvalho, and Tom M.
Mitchell. 2004. Learning to classify email into
“speech acts”. In Proceedings of the 2004 Conference
on Empirical Methods in Natural Language Process-
ing (EMNLP 2004), pages 309–316, Barcelona, Spain.
Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song,
and Yueheng Sun. 2008. Finding question-answer
</reference>
<page confidence="0.990363">
22
</page>
<reference confidence="0.997299504672897">
pairs from online forums. In Proceedings of 31st Inter-
national ACM-SIGIR Conference on Research and De-
velopment in Information Retrieval (SIGIR’08), pages
467–474, Singapore.
Daniel Dahlmeier, Hwee Tou Ng, and Tanja Schultz.
2009. Joint learning of preposition senses and seman-
tic roles of prepositional phrases. In Proceedings of
the 2009 Conference on Empirical Methods in Natural
Language Processing (EMNLP 2009), pages 450–458,
Singapore. Association for Computational Linguistics.
Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan Zhu.
2008. Using conditional random fields to extract con-
text and answers of questions from online forums. In
Proceedings of the 46th Annual Meeting of the ACL:
HLT (ACL 2008), pages 710–718, Columbus, USA.
Jason Eisner and Noah A. Smith. 2005. Parsing with soft
and hard constraints on dependency length. In Pro-
ceedings of the Ninth International Workshop on Pars-
ing Technology, pages 30–41, Vancouver, Canada.
Jonathan L. Elsas and Jaime G. Carbonell. 2009. It
pays to be picky: An evaluation of thread retrieval
in online forums. In Proceedings of 32nd Interna-
tional ACM-SIGIR Conference on Research and De-
velopment in Information Retrieval (SIGIR’09), pages
714–715, Boston, USA.
Micha Elsner and Eugene Charniak. 2008. You talk-
ing to me? a corpus and algorithm for conversation
disentanglement. In Proceedings of the 46th Annual
Meeting of the ACL: HLT (ACL 2008), pages 834–842,
Columbus, USA.
Jenny Rose Finkel and Christopher D. Manning. 2009.
Joint parsing and named entity recognition. In Pro-
ceedings of Human Language Technologies: The 2009
Annual Conference of the North American Chap-
ter of the Association for Computational Linguistics
(NAACL HLT 2009), pages 326–334, Boulder, Col-
orado. Association for Computational Linguistics.
Blaz Fortuna, Eduarda Mendes Rodrigues, and Natasa
Milic-Frayling. 2007. Improving the classification of
newsgroup messages through social network analysis.
In Proceedings of the 16th ACM Conference on In-
formation and Knowledge Management (CIKM 2007),
pages 877–880, Lisbon, Portugal.
Barbara J. Grosz and Candace L. Sidner. 1986. Atten-
tion, intention and the structure of discourse. Compu-
tational Linguistics, 12(3):175–204.
Edward Ivanovic. 2008. Automatic instant messaging
dialogue using statistical models and dialogue acts.
Master’s thesis, University of Melbourne.
Su Nam Kim, Lawrence Cavedon, and Timothy Bald-
win. 2010a. Classifying dialogue acts in one-on-one
live chats. In Proceedings of the 2010 Conference on
Empirical Methods in Natural Language Processing
(EMNLP 2010), pages 862–871, Boston, USA.
Su Nam Kim, Li Wang, and Timothy Baldwin. 2010b.
Tagging and linking web forum posts. In Proceedings
of the 14th Conference on Computational Natural Lan-
guage Learning (CoNLL-2010), pages 192–202, Upp-
sala, Sweden.
Sandra K¨ubler, Ryan McDonald, and Joakim Nivre.
2009. Dependency parsing. Synthesis Lectures on Hu-
man Language Technologies, 2(1):1–127.
John Lafferty, Andrew McCallum, and Fernando Pereira.
2001. Conditional random fields: Probabilistic mod-
els for segmenting and labeling sequence data. In Pro-
ceedings of the 18th International Conference on Ma-
chine Learning, pages 282–289, Williamstown, USA.
Andrew Lampert, Robert Dale, and C´ecile Paris. 2008.
The nature of requests and commitments in email mes-
sages. In Proceedings of the AAAI 2008 Workshop on
Enhanced Messaging, pages 42–47, Chicago, USA.
Robert Leaman, Laura Wojtulewicz, Ryan Sullivan, An-
nie Skariah, Jian Yang, and Graciela Gonzalez. 2010.
Towards internet-age pharmacovigilance: Extracting
adverse drug reactions from user posts in health-
related social networks. In Proceedings of the 2010
Workshop on Biomedical Natural Language Process-
ing (ACL 2010), pages 117–125, Uppsala, Sweden.
Oliver Lemon, Alex Gruenstein, and Stanley Peters.
2002. Collaborative activities and multi-tasking in di-
alogue systems. Traitement Automatique des Langues
(TAL), Special Issue on Dialogue, 43(2):131–154.
Chen Lin, Jiang-Ming Yang, Rui Cai, Xin-Jing Wang,
Wei Wang, and Lei Zhang. 2009. Modeling semantics
and structure of discussion threads. In Proceedings of
the 18th International Conference on the World Wide
Web (WWW 2009), pages 1103–1104, Madrid, Spain.
Marco Lui and Timothy Baldwin. 2009. You are what
you post: User-level features in threaded discourse. In
Proceedings of the 14th Australasian Document Com-
puting Symposium (ADCS 2009), Sydney, Australia.
Marco Lui and Timothy Baldwin. 2010. Classifying
user forum participants: Separating the gurus from the
hacks, and other tales of the internet. In Proceedings
of the 2010 Australasian Language Technology Work-
shop (ALTW 2010), pages 49–57, Melbourne, Aus-
tralia.
Ryan McDonald and Joakim Nivre. 2007. Charac-
terizing the errors of data-driven dependency parsing
models. In Proceedings of the 2007 Joint Confer-
ence on Empirical Methods in Natural Language Pro-
cessing and Computational Natural Language Learn-
ing (EMNLP-CoNLL 2007), pages 122–131, Prague,
Czech Republic.
Ryan McDonald and Fernando Pereira. 2006. On-
line learning of approximate dependency parsing al-
gorithms. In Proceedings of the 11th Conference of
</reference>
<page confidence="0.988977">
23
</page>
<reference confidence="0.998622407407407">
the European Chapter of the Association for Computa-
tional Linguistics (EACL 2006), pages 81–88, Trento,
Italy.
Ryan McDonald, Fernando Pereira, Kiril Ribarov, and
Jan Hajic. 2005. Non-projective dependency pars-
ing using spanning tree algorithms. In Proceedings of
Human Language Technology Conference and Confer-
ence on Empirical Methods in Natural Language Pro-
cessing, pages 523–530, Vancouver, Canada.
Gabriel Murray, Steve Renals, Jean Carletta, and Johanna
Moore. 2006. Incorporating speaker and discourse
features into speech summarization. In Proceedings
of the Main Conference on Human Language Technol-
ogy Conference of the North American Chapter of the
Association of Computational Linguistics, pages 367–
374.
Klemens Muthmann, Wojciech M. Barczy´nski, Falk
Brauer, and Alexander L¨oser. 2009. Near-duplicate
detection for web-forums. In Proceedings of the 2009
International Database Engineering &amp; Applications
Symposium (IDEAS 2009), pages 142–151, Cetraro,
Italy.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev,
G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov,
and Erwin Marsi. 2007. MaltParser: A language-
independent system for data-driven dependency pars-
ing. Natural Language Engineering, 13(02):95–135.
Joakim Nivre. 2003. An efficient algorithm for projec-
tive dependency parsing. In Proceedings of the 8th In-
ternational Workshop on Parsing Technologies (IWPT
03), pages 149–160, Nancy, France.
Joakim Nivre. 2004. Incrementality in determinis-
tic dependency parsing. In Proceedings of the ACL
Workshop Incremental Parsing: Bringing Engineer-
ing and Cognition Together (ACL-2004), pages 50–57,
Barcelona, Spain.
Carolyn Penstein Ros´e, Barbara Di Eugenio, Lori S.
Levin, and Carol Van Ess-Dykema. 1995. Discourse
processing of dialogues with multiple threads. In Pro-
ceedings of the 33rd Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 31–38,
Cambridge, USA.
Kenji Sagae and Jun’ichi Tsujii. 2008. Shift-reduce
dependency DAG parsing. In Proceedings of the
22nd International Conference on Computational Lin-
guistics (COLING 2008), pages 753–760, Manchester,
UK.
Kenji Sagae. 2009. Analysis of discourse structure with
syntactic dependencies and data-driven shift-reduce
parsing. In Proceedings of the 11th International Con-
ference on Parsing Technologies (IWPT-09), pages 81–
84, Paris, France.
Anne Schuth, Maarten Marx, and Maarten de Rijke.
2007. Extracting the discussion structure in comments
on news-articles. In Proceedings of the 9th Annual
ACM International Workshop on Web Information and
Data Management, pages 97–104, Lisboa, Portugal.
Jangwon Seo, W. Bruce Croft, and David A. Smith.
2009. Online community search using thread struc-
ture. In Proceedings of the 18th ACM Conference
on Information and Knowledge Management (CIKM
2009), pages 1907–1910, Hong Kong, China.
Elinzabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy
Ang, and Hannah Carvey. 2004. The ICSI meeting
recorder dialog act (MRDA) corpus. In Proceedings of
the 5th SIGdial Workshop on Discourse and Dialogue,
pages 97–100, Cambridge, USA.
Parikshit Sondhi, Manish Gupta, ChengXiang Zhai, and
Julia Hockenmaier. 2010. Shallow information ex-
traction from medical forum data. In Proceedings of
the 23rd International Conference on Computational
Linguistics (COLING 2010), Posters Volume, pages
1158–1166, Beijing, China.
Radu Soricut and Daniel Marcu. 2003. Sentence level
discourse parsing using syntactic and lexical infor-
mation. In Proceedings of the 2003 Human Lan-
guage Technology Conference of the North American
Chapter of the Association for Computational Linguis-
tics (HLT-NAACL 2003), pages 149–156, Edmonton,
Canada.
Andreas Stolcke, Klaus Ries, Noah Coccaro, Eliza-
beth Shriberg, Rebecca Bates, Daniel Jurafsky, Pail
Taylor, Rachel Martin, Carol Van Ess-Dykema, and
Marie Meteer. 2000. Dialogue act modeling for
automatic tagging and recognition of conversational
speech. Computational Linguistics, 26(3):339–373.
Charles Sutton and Andrew McCallum. 2005. Joint
parsing and semantic role labeling. In Proceedings of
the Ninth Conference on Computational Natural Lan-
guage Learning (CoNLL-2005), pages 225–228, Ann
Arbor, Michigan. Association for Computational Lin-
guistics.
Pasi Tapanainen and Timo Jarvinen. 1997. A non-
projective dependency parser. In Proceedings of the
Fifth Conference on Applied Natural Language Pro-
cessing, pages 64–71, Washington, USA.
Nayer Wanas, Motaz El-Saban, Heba Ashour, and
Waleed Ammar. 2008. Automatic scoring of online
discussion posts. In Proceeding of the 2nd ACM work-
shop on Information credibility on the web (WICOW
’08), pages 19–26, Napa Valley, USA.
Yi-Chia Wang and Carolyn P. Ros´e. 2010. Mak-
ing conversational structure explicit: identification of
initiation-response pairs within online discussions. In
Human Language Technologies: The 2010 Annual
Conference of the North American Chapter of the As-
sociation for Computational Linguistics (NAACL HLT
2010), pages 673–676.
</reference>
<page confidence="0.974877">
24
</page>
<reference confidence="0.999201782608696">
Yi-Chia Wang, Mahesh Joshi, and Carolyn Ros´e. 2007.
A feature based approach to leveraging context for
classifying newsgroup style discussion segments. In
Proceedings of the 45th Annual Meeting of the As-
sociation for Computational Linguistics Companion
Volume Proceedings of the Demo and Poster Sessions
(ACL 2007), pages 73–76, Prague, Czech Republic.
Yi-Chia Wang, Mahesh Joshi, William W. Cohen, and
Carolyn Ros´e. 2008. Recovering implicit thread
structure in newsgroup style conversations. In Pro-
ceedings of the Second International Conference on
Weblogs and Social Media (ICWSM 2008), pages 152–
160, Seattle, USA.
V. Warnke, R. Kompe, H. Niemann, and E. N¨oth. 1997.
Integrated dialog act segmentation and classification
using prosodic features and language models. In Proc.
Eurospeech, volume 1, pages 207–210.
Markus Weimer and Iryna Gurevych. 2007. Predicting
the perceived quality of web forum posts. In Proceed-
ings of the 2007 International Conference on Recent
Advances in Natural Language Processing (RANLP
2007), pages 643–648, Borovets, Bulgaria.
Markus Weimer, Iryna Gurevych, and Max M¨uhlh¨auser.
2007. Automatically assessing the post quality in on-
line discussions on software. In Proceedings of the
45th Annual Meeting of the ACL: Interactive Poster
and Demonstration Sessions, pages 125–128, Prague,
Czech Republic.
Armin Weinberger and Frank Fischer. 2006. A
framework to analyze argumentative knowledge con-
struction in computer-supported collaborative learn-
ing. Computers &amp; Education, 46:71–95, January.
Florian Wolf and Edward Gibson. 2005. Representing
discourse coherence: A corpus-based study. Compu-
tational Linguistics, 31(2):249–287.
Wensi Xi, Jesper Lind, and Eric Brill. 2004. Learning
effective ranking functions for newsgroup search. In
Proceedings of 27th International ACM-SIGIR Con-
ference on Research and Development in Informa-
tion Retrieval (SIGIR 2004), pages 394–401. Sheffield,
UK.
Alexander Yeh. 2000. More accurate tests for the sta-
tistical significance of result differences. In Proceed-
ings of the 18th International Conference on Compu-
tational Linguistics (COLING 2000), pages 947–953,
Saarbr¨ucken, Germany.
</reference>
<page confidence="0.998731">
25
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.669713">
<title confidence="0.999935">Predicting Thread Discourse Structure over Technical Web Forums</title>
<author confidence="0.999959">Marco Su Nam Joakim</author>
<affiliation confidence="0.890629">of Computer Science and Software Engineering, University of Victoria Research Laboratory ♦ Dept. of Linguistics and Philology, Uppsala</affiliation>
<abstract confidence="0.99969512">Online discussion forums are a valuable means for users to resolve specific information needs, both interactively for the participants and statically for users who search/browse over historical thread data. However, the complex structure of forum threads can make it difficult for users to extract relevant information. The discourse structure of web forum threads, in the form of labelled dependency relationships between posts, has the potential to greatly improve information access over web forum archives. In this paper, we present the task of parsing user forum threads to determine the labelled dependencies between posts. Three methods, including a dependency parsing approach, are proposed to jointly classify the links (relationships) between posts and the dialogue act (type) of each link. The proposed methods significantly surpass an informed baseline. We also experiment with “in situ” classification of evolving threads, and establish that our best methods are able to perform equivalently well over partial threads as complete threads.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L´eon Bottou</author>
</authors>
<date>2011</date>
<note>CRFSGD software. http:// leon.bottou.org/projects/sgd.</note>
<contexts>
<context position="18077" citStr="Bottou, 2011" startWordPosition="2841" endWordPosition="2843">symmetric dependency relations with dependency types. Standardly, CRFs have been applied to tasks such as part-of-speech tagging, named entity recognition, semantic role labelling and supertagging, where the individual tokens are single words. Similarly, dependency parsing is conventionally applied to sentences, with single-word tokens. In our case, our tokens are thread posts, with much greater scope for feature engineering than single words, and technical challenges in scaling the underlying implementations to handle potentially much larger feature sets. As our learners, we deployed CRFSGD (Bottou, 2011) to learn the CRF, and MaltParser (Nivre et al., 2007) as our dependency parser. CRFSGD uses stochastic gradient descent to efficiently solve the convex optimisation problem, and scales well to large feature sets. We used the default parameter settings for CRFSGD, with feature templates including all unigram features of the current token as well as bigram features combining the previous output token with the current token. MaltParser implements transition-based parsing, where no formal grammar is considered, and a transition system, or state machine, is learned to map a sentence onto its depen</context>
</contexts>
<marker>Bottou, 2011</marker>
<rawString>L´eon Bottou. 2011. CRFSGD software. http:// leon.bottou.org/projects/sgd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xin Cao</author>
<author>Gao Cong</author>
<author>Bin Cui</author>
<author>Christian S Jensen</author>
<author>Ce Zhang</author>
</authors>
<title>The use of categorization information in language models for question retrieval.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM</booktitle>
<pages>265--274</pages>
<location>Hong Kong, China.</location>
<contexts>
<context position="11909" citStr="Cao et al., 2009" startWordPosition="1889" endWordPosition="1892">ion accuracy for postlevel tasks. Initiation–response pairs (e.g. question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge bases for Community Question Answering (cQA) services such as Yahoo! Answers. While initiation– response pair identification has been explored as a pairwise ranking problem (Wang and Ros´e, 2010), question–answer pair identification has been approached via the two separate sub-tasks of question classification and answer detection (Cong et al., 2008; Ding et al., 2008; Cao et al., 2009). Our thread discourse structure prediction task includes joint classification of post roles (i.e. dialogue acts) and links, and could potentially be performed at the sub-post sentence level to extract initiation–response pairs. 3 Task Description and Data Set The main task performed in this research is joint classification of inter-post links (Link) and dialogue acts (DA) within forum threads. In this, we assume that a post can only link to an earlier post (or a virtual root node), and that dialogue acts are labels on edges. It is possible for there to be multiple edges from a given post, e.g</context>
</contexts>
<marker>Cao, Cong, Cui, Jensen, Zhang, 2009</marker>
<rawString>Xin Cao, Gao Cong, Bin Cui, Christian S. Jensen, and Ce Zhang. 2009. The use of categorization information in language models for question retrieval. In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM 2009), pages 265–274, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vitor R Carvalho</author>
<author>William W Cohen</author>
</authors>
<title>On the collective classification of email ”speech acts”.</title>
<date>2005</date>
<booktitle>In Proceedings of 28th International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR</booktitle>
<pages>345--352</pages>
<contexts>
<context position="7395" citStr="Carvalho and Cohen, 2005" startWordPosition="1178" endWordPosition="1181">mes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text fi</context>
</contexts>
<marker>Carvalho, Cohen, 2005</marker>
<rawString>Vitor R. Carvalho and William W. Cohen. 2005. On the collective classification of email ”speech acts”. In Proceedings of 28th International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2005), pages 345–352.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Chan</author>
<author>Conor Hayes</author>
</authors>
<title>Decomposing discussion forums using user roles.</title>
<date>2010</date>
<booktitle>In Proceedings of the WebSci10: Extending the Frontiers of Society On-Line (WebSci10),</booktitle>
<pages>1--8</pages>
<location>Raleigh, USA.</location>
<contexts>
<context position="10258" citStr="Chan and Hayes, 2010" startWordPosition="1648" endWordPosition="1651"> for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval task</context>
</contexts>
<marker>Chan, Hayes, 2010</marker>
<rawString>Jeffrey Chan and Conor Hayes. 2010. Decomposing discussion forums using user roles. In Proceedings of the WebSci10: Extending the Frontiers of Society On-Line (WebSci10), pages 1–8, Raleigh, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Chan</author>
<author>Conor Hayes</author>
<author>Elizabeth M Daly</author>
</authors>
<title>Decomposing discussion forums using user roles.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media (ICWSM 2010),</booktitle>
<pages>215--8</pages>
<location>Washington, USA.</location>
<contexts>
<context position="10278" citStr="Chan et al., 2010" startWordPosition="1652" endWordPosition="1655">iguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related r</context>
</contexts>
<marker>Chan, Hayes, Daly, 2010</marker>
<rawString>Jeffrey Chan, Conor Hayes, and Elizabeth M. Daly. 2010. Decomposing discussion forums using user roles. In Proceedings of the Fourth International AAAI Conference on Weblogs and Social Media (ICWSM 2010), pages 215–8, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chih-Chung Chang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBSVM: A library for support vector machines.</title>
<date>2011</date>
<journal>ACM Transactions on Intelligent Systems and Technology,</journal>
<volume>2</volume>
<issue>3</issue>
<note>Software available at http:// www.csie.ntu.edu.tw/˜cjlin/libsvm.</note>
<contexts>
<context position="19349" citStr="Chang and Lin, 2011" startWordPosition="3050" endWordPosition="3053"> well suited to our task is that it is possible to define feature models of arbitrary complexity for each token. In presenting the thread data to MaltParser, we represent the nulllink from the initial post of each thread, as well as any disconnected posts, as the root. To the best of our knowledge, there is no past work on using dependency parsing to learn thread discourse structure. Based on extensive experimentation, we determined that the MaltParser configuration that obtains the best results for our task is the Nivre algorithm in arc-standard mode (Nivre, 2003; Nivre, 2004), using LIBSVM (Chang and Lin, 2011) with a linear kernel as the learner, and a feature model with exhaustive combinations of features relating to the features and predictions of the first/top three tokens from both “Input” and “Stack”.3 As such, MaltParser is actually unable to predict any non-projective structures, as experiments with algorithms supporting non-projective structures invariably led to lower results. In our choice of parsing algorithm, we are also unable to detect posts with multiple heads, but can potentially detect disconnected sub-graphs. 4.2 Features The features used in our classifiers are as follows: Struct</context>
</contexts>
<marker>Chang, Lin, 2011</marker>
<rawString>Chih-Chung Chang and Chih-Jen Lin. 2011. LIBSVM: A library for support vector machines. ACM Transactions on Intelligent Systems and Technology, 2(3):27:1–27:27. Software available at http:// www.csie.ntu.edu.tw/˜cjlin/libsvm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William W Cohen</author>
<author>Vitor R Carvalho</author>
<author>Tom M Mitchell</author>
</authors>
<title>Learning to classify email into “speech acts”.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP 2004),</booktitle>
<pages>309--316</pages>
<location>Barcelona,</location>
<contexts>
<context position="7369" citStr="Cohen et al., 2004" startWordPosition="1174" endWordPosition="1177"> discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: cr</context>
</contexts>
<marker>Cohen, Carvalho, Mitchell, 2004</marker>
<rawString>William W. Cohen, Vitor R. Carvalho, and Tom M. Mitchell. 2004. Learning to classify email into “speech acts”. In Proceedings of the 2004 Conference on Empirical Methods in Natural Language Processing (EMNLP 2004), pages 309–316, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gao Cong</author>
<author>Long Wang</author>
<author>Chin-Yew Lin</author>
<author>Young-In Song</author>
<author>Yueheng Sun</author>
</authors>
<title>Finding question-answer pairs from online forums.</title>
<date>2008</date>
<booktitle>In Proceedings of 31st International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’08),</booktitle>
<pages>467--474</pages>
<contexts>
<context position="11871" citStr="Cong et al., 2008" startWordPosition="1881" endWordPosition="1884"> significantly improve the classification accuracy for postlevel tasks. Initiation–response pairs (e.g. question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge bases for Community Question Answering (cQA) services such as Yahoo! Answers. While initiation– response pair identification has been explored as a pairwise ranking problem (Wang and Ros´e, 2010), question–answer pair identification has been approached via the two separate sub-tasks of question classification and answer detection (Cong et al., 2008; Ding et al., 2008; Cao et al., 2009). Our thread discourse structure prediction task includes joint classification of post roles (i.e. dialogue acts) and links, and could potentially be performed at the sub-post sentence level to extract initiation–response pairs. 3 Task Description and Data Set The main task performed in this research is joint classification of inter-post links (Link) and dialogue acts (DA) within forum threads. In this, we assume that a post can only link to an earlier post (or a virtual root node), and that dialogue acts are labels on edges. It is possible for there to be</context>
</contexts>
<marker>Cong, Wang, Lin, Song, Sun, 2008</marker>
<rawString>Gao Cong, Long Wang, Chin-Yew Lin, Young-In Song, and Yueheng Sun. 2008. Finding question-answer pairs from online forums. In Proceedings of 31st International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’08), pages 467–474, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Dahlmeier</author>
<author>Hwee Tou Ng</author>
<author>Tanja Schultz</author>
</authors>
<title>Joint learning of preposition senses and semantic roles of prepositional phrases.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP</booktitle>
<pages>450--458</pages>
<institution>Singapore. Association for Computational Linguistics.</institution>
<contexts>
<context position="9601" citStr="Dahlmeier et al. (2009)" startWordPosition="1552" endWordPosition="1555"> on dialogue act boundaries were fed into an n-gram language model, which was used for the joint segmentation and classification of dialogue acts. Sutton and McCallum (2005) performed joint parsing and semantic role labelling (SRL), using the results of a probabilistic SRL system to improve the accuracy of a probabilistic parser. Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles i</context>
</contexts>
<marker>Dahlmeier, Ng, Schultz, 2009</marker>
<rawString>Daniel Dahlmeier, Hwee Tou Ng, and Tanja Schultz. 2009. Joint learning of preposition senses and semantic roles of prepositional phrases. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing (EMNLP 2009), pages 450–458, Singapore. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shilin Ding</author>
<author>Gao Cong</author>
<author>Chin-Yew Lin</author>
<author>Xiaoyan Zhu</author>
</authors>
<title>Using conditional random fields to extract context and answers of questions from online forums.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the ACL: HLT (ACL</booktitle>
<pages>710--718</pages>
<location>Columbus, USA.</location>
<contexts>
<context position="11890" citStr="Ding et al., 2008" startWordPosition="1885" endWordPosition="1888">ove the classification accuracy for postlevel tasks. Initiation–response pairs (e.g. question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge bases for Community Question Answering (cQA) services such as Yahoo! Answers. While initiation– response pair identification has been explored as a pairwise ranking problem (Wang and Ros´e, 2010), question–answer pair identification has been approached via the two separate sub-tasks of question classification and answer detection (Cong et al., 2008; Ding et al., 2008; Cao et al., 2009). Our thread discourse structure prediction task includes joint classification of post roles (i.e. dialogue acts) and links, and could potentially be performed at the sub-post sentence level to extract initiation–response pairs. 3 Task Description and Data Set The main task performed in this research is joint classification of inter-post links (Link) and dialogue acts (DA) within forum threads. In this, we assume that a post can only link to an earlier post (or a virtual root node), and that dialogue acts are labels on edges. It is possible for there to be multiple edges fro</context>
</contexts>
<marker>Ding, Cong, Lin, Zhu, 2008</marker>
<rawString>Shilin Ding, Gao Cong, Chin-Yew Lin, and Xiaoyan Zhu. 2008. Using conditional random fields to extract context and answers of questions from online forums. In Proceedings of the 46th Annual Meeting of the ACL: HLT (ACL 2008), pages 710–718, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
<author>Noah A Smith</author>
</authors>
<title>Parsing with soft and hard constraints on dependency length.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth International Workshop on Parsing Technology,</booktitle>
<pages>30--41</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="14522" citStr="Eisner and Smith, 2005" startWordPosition="2297" endWordPosition="2300">g. in instances where a user hijacks a thread to ask their own unrelated question, or submit an unrelated spam post; around 2% of the threads in our dataset contain disconnected sub-graphs. The first constraint potentially simplifies dependency parsing, and non-projective dependencies are relatively well understood in the dependency parsing community (Tapanainen and Jarvinen, 1997; McDonald et al., 2005). Multi-headedness and disconnected sub-graphs pose greater challenges to dependency parsing, although there has been research done on both (McDonald and Pereira, 2006; Sagae and Tsujii, 2008; Eisner and Smith, 2005). The combination of non-projectivity, multi-headedness and disconnected sub-graphs in a single dataset, however, poses a challenge for dependency parsing. In addition to performing evaluation in batch mode over complete threads, we consider the task of “in situ thread classification”, whereby we predict the discourse structure of a thread after each post. This is intended to simulate the more realistic setting of incrementally crawling/updating thread data, but needing to predict discourse structure for partial threads. We are interested in determining the relative degradation in accuracy for</context>
</contexts>
<marker>Eisner, Smith, 2005</marker>
<rawString>Jason Eisner and Noah A. Smith. 2005. Parsing with soft and hard constraints on dependency length. In Proceedings of the Ninth International Workshop on Parsing Technology, pages 30–41, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan L Elsas</author>
<author>Jaime G Carbonell</author>
</authors>
<title>It pays to be picky: An evaluation of thread retrieval in online forums.</title>
<date>2009</date>
<booktitle>In Proceedings of 32nd International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’09),</booktitle>
<pages>714--715</pages>
<location>Boston, USA.</location>
<contexts>
<context position="10482" citStr="Elsas and Carbonell, 2009" startWordPosition="1683" endWordPosition="1686"> and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer and Gurevych, 2007; Wanas et al., 2008; Lui and Baldwin, 2009), and post descriptiveness</context>
</contexts>
<marker>Elsas, Carbonell, 2009</marker>
<rawString>Jonathan L. Elsas and Jaime G. Carbonell. 2009. It pays to be picky: An evaluation of thread retrieval in online forums. In Proceedings of 32nd International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR’09), pages 714–715, Boston, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Micha Elsner</author>
<author>Eugene Charniak</author>
</authors>
<title>You talking to me? a corpus and algorithm for conversation disentanglement.</title>
<date>2008</date>
<booktitle>In Proceedings of the 46th Annual Meeting of the ACL: HLT (ACL</booktitle>
<pages>834--842</pages>
<location>Columbus, USA.</location>
<contexts>
<context position="6631" citStr="Elsner and Charniak, 2008" startWordPosition="1044" endWordPosition="1047">010a), demonstrating the generalisability of the original method. In both cases, however, we tackled only a single task, either link classification (optionally given dialogue act tags) or dialogue act classification, but never the two together. In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of c</context>
</contexts>
<marker>Elsner, Charniak, 2008</marker>
<rawString>Micha Elsner and Eugene Charniak. 2008. You talking to me? a corpus and algorithm for conversation disentanglement. In Proceedings of the 46th Annual Meeting of the ACL: HLT (ACL 2008), pages 834–842, Columbus, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jenny Rose Finkel</author>
<author>Christopher D Manning</author>
</authors>
<title>Joint parsing and named entity recognition.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT</booktitle>
<pages>326--334</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado.</location>
<contexts>
<context position="9335" citStr="Finkel and Manning (2009)" startWordPosition="1512" endWordPosition="1515">teractions between different sub-tasks to the mutual benefit of both. Warnke et al. (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. In their approach, the predictions of a multi-layer perceptron classifier on dialogue act boundaries were fed into an n-gram language model, which was used for the joint segmentation and classification of dialogue acts. Sutton and McCallum (2005) performed joint parsing and semantic role labelling (SRL), using the results of a probabilistic SRL system to improve the accuracy of a probabilistic parser. Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-</context>
</contexts>
<marker>Finkel, Manning, 2009</marker>
<rawString>Jenny Rose Finkel and Christopher D. Manning. 2009. Joint parsing and named entity recognition. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2009), pages 326–334, Boulder, Colorado. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Blaz Fortuna</author>
<author>Eduarda Mendes Rodrigues</author>
<author>Natasa Milic-Frayling</author>
</authors>
<title>Improving the classification of newsgroup messages through social network analysis.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th ACM Conference on Information and Knowledge Management (CIKM</booktitle>
<pages>877--880</pages>
<location>Lisbon, Portugal.</location>
<contexts>
<context position="8435" citStr="Fortuna et al., 2007" startWordPosition="1370" endWordPosition="1373"> allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text field. See ... Part 2: give it a Javascript action 3+Question-Add Thank You! Thanks a lot for that ... I have Microsoft Visual Studio 6, what program should I do this in? Lastly, how do I actually include this in my site? ... User A Post 4 User D Post 5 A little more help ... You would simply do it this way: ... You could also just ... An example of this is ... 14 2004; Weinberger and Fischer, 2006; Wang et al., 2007; Fortuna et al., 2007; Kim et al., 2010b). For a more complete review of models for discourse disentanglement and dialogue act tagging, see Kim et al. (2010b). Joint classification has been applied in a number of different contexts, based on the intuition that it should be possible to harness interactions between different sub-tasks to the mutual benefit of both. Warnke et al. (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. In their approach, the predictions of a multi-layer perceptron classifier on dialogue act boundaries were fed into an n-gram langu</context>
</contexts>
<marker>Fortuna, Rodrigues, Milic-Frayling, 2007</marker>
<rawString>Blaz Fortuna, Eduarda Mendes Rodrigues, and Natasa Milic-Frayling. 2007. Improving the classification of newsgroup messages through social network analysis. In Proceedings of the 16th ACM Conference on Information and Knowledge Management (CIKM 2007), pages 877–880, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
<author>Candace L Sidner</author>
</authors>
<title>Attention, intention and the structure of discourse.</title>
<date>1986</date>
<journal>Computational Linguistics,</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="6843" citStr="Grosz and Sidner, 1986" startWordPosition="1079" endWordPosition="1082">, but never the two together. In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivan</context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>Barbara J. Grosz and Candace L. Sidner. 1986. Attention, intention and the structure of discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Ivanovic</author>
</authors>
<title>Automatic instant messaging dialogue using statistical models and dialogue acts. Master’s thesis,</title>
<date>2008</date>
<institution>University of Melbourne.</institution>
<contexts>
<context position="7453" citStr="Ivanovic, 2008" startWordPosition="1188" endWordPosition="1189">1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text field. See ... Part 2: give it a Javascript action 3+Questio</context>
</contexts>
<marker>Ivanovic, 2008</marker>
<rawString>Edward Ivanovic. 2008. Automatic instant messaging dialogue using statistical models and dialogue acts. Master’s thesis, University of Melbourne.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Lawrence Cavedon</author>
<author>Timothy Baldwin</author>
</authors>
<title>Classifying dialogue acts in one-on-one live chats.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP 2010),</booktitle>
<pages>862--871</pages>
<location>Boston, USA.</location>
<contexts>
<context position="3503" citStr="Kim et al. (2010" startWordPosition="550" endWordPosition="553">assessment (Lui and Baldwin, 2009). We aim to move beyond simple threading, to predict not only the links between posts, but also show the manner of each link, in the form of the discourse structure of the thread. In doing so, we hope to be able to perform richer visualisation of thread structure (e.g. highlighting the key posts which appear to have led to a successful resolution to a problem), and more finegrained weighting of posts in threads for search purposes. To illustrate the task, we use an example thread, made up of 5 posts from 4 distinct participants, from the CNET forum dataset of Kim et al. (2010b), as shown in Figure 1. The discourse structure of the thread is modelled as a rooted directed acyclic graph 13 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 13–25, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics Figure 1: A snippeted and annotated CNET thread (DAG) with a dialogue act label associated with each edge of the graph. In this example, UserA initiates the thread with a question (dialogue act = QuestionQuestion) in the first post, by asking how to create an interactive input box on a webpag</context>
<context position="4861" citStr="Kim et al. (2010" startWordPosition="765" endWordPosition="768">the solution (dialogue act = Answer-Confirmation), and at the same time, adds extra information to his/her original question (dialogue act = Question-Add); i.e., this one post has two distinct dependency links associated with it. Finally, UserD proposes a different solution again to the original question. To predict thread discourse structure of this type, we jointly classify the links and dialogue acts between posts, experimenting with a variety of supervised classification methods, namely dependency parsing and linear-chain conditional random fields. In this, we build on the earlier work of Kim et al. (2010b) who first proposed the task of thread discourse analysis, but only carried out experiments on post linking and post dialogue act classification as separate tasks. In addition to achieving state-of-theart accuracy over the task, we carry out in-depth analysis of classification effectiveness at different thread depths, and establish that the accuracy of our method over partial threads is equivalent to that over full threads, indicating that the method is applicable to in-situ thread classification. Finally, we investigate the role of user-level features in discourse structure analysis. 2 Rela</context>
<context position="7471" citStr="Kim et al., 2010" startWordPosition="1190" endWordPosition="1193">l., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text field. See ... Part 2: give it a Javascript action 3+Question-Add Thank You! T</context>
<context position="15237" citStr="Kim et al. (2010" startWordPosition="2404" endWordPosition="2407">aset, however, poses a challenge for dependency parsing. In addition to performing evaluation in batch mode over complete threads, we consider the task of “in situ thread classification”, whereby we predict the discourse structure of a thread after each post. This is intended to simulate the more realistic setting of incrementally crawling/updating thread data, but needing to predict discourse structure for partial threads. We are interested in determining the relative degradation in accuracy for in situ classification vs. batch classification. As our dataset, we use the CNET forum dataset of Kim et al. (2010b),1 which contains 1332 annotated posts spanning 315 threads, collected from the Operating System, Software, Hardware and Web Development sub-forums of cnet.2 Each post is labelled with one or more links (including the possibility of null-links, where the post doesn’t link to any other post), and each link is labelled with a dialogue act. The dialogue act set is made up of 5 super-categories: Question, Answer, Resolution (confirmation of the question being resolved), Reproduction (external confirmation of a proposed solution working) and Other. The Question category contains 4 sub-classes: Qu</context>
<context position="16902" citStr="Kim et al. (2010" startWordPosition="2672" endWordPosition="2675">st of posts, e.g. 1 indicates a link back to the preceding post, and 2 indicates a link back two posts. Unless otherwise noted, evaluation is over the combined link and dialogue act tag, including the combination of superclass and subclass for the Question and Answer dialogue acts. For example, 1+Answer-Answer indicates a dependency link back one post, which is an answer to a question. The most common label in the dataset is 1+Answeranswer (28.4%). 4 Learners and Features 4.1 Learners To predict thread discourse structure, we use a structured classification approach — based on the findings of Kim et al. (2010b) and Kim et al. (2010a) — and a dependency parser. The structured classification approach we experiment with is a linear1Available from http://www.csse.unimelb.edu. au/research/lt/resources/conll2010-thread/ 2http://forums.cnet.com/ 16 chain conditional random field learner (CRF: Lafferty et al. (2001)), within which we explore two simple approaches to joint classification, as is explained in Section 5.1. Dependency parsing (K¨ubler et al., 2009) is the task of automatically predicting the dependency structure of a token sequence, in the form of binary asymmetric dependency relations with de</context>
<context position="20735" citStr="Kim et al. (2010" startWordPosition="3272" endWordPosition="3275">atio over the total number of posts in the thread. Semantic Features: TitSim the relative location of the post which has the most similar title (based on unweighted cosine similarity) to the current post. PostSim the relative location of the post which has the most similar content (based on unweighted cosine similarity) to the current post. Punct the number of question marks (QuCount), exclamation marks (ExCount) and URLs (UrlCount) in the current post. UserProf the class distribution (in the training thread) of the author of the current post. These features are drawn largely from the work of Kim et al. (2010b), with two major differences: (1) we do not use post context features because our learners (i.e. CRFSGD and MaltParser) inherently capture Markov chains; and (2) our UserProf features are customised to the class set associated with the task at hand, e.g. the UserProf features for the standalone linking task take the form of the link labels (and not dialogue act labels) of the posts by the relevant author in the training data. Table 1 shows the feature representation of the third post in a thread 17 Feature Value Initiator 1.0 ExCount 4.0 QuCount 0.0 UrlCount 0.0 Position 0.25 PostSim 2.0 Tit</context>
<context position="25505" citStr="Kim et al. (2010" startWordPosition="4070" endWordPosition="4073">ariable in play is the extent of thread context used to learn the thread discourse structure for the given set of posts. We break down the results in each case into the indicated subthreads, e.g. we take the predictions for [all], and break them down into the results for [1, 2], [1, 4], [1, 6], [1, 8] and [all], for direct comparison with the predictions over the respective sub-thread data. 5In practice, completeness is defined at a given point in time, when the crawl was done, and it is highly likely that some of the “complete” threads had extra posts after the crawl. 3−1 8 18 Method Link DA Kim et al. (2010b) .863 / .676 .751 / .543 CRFSGD .891 / .727 .795 / .609 Table 2: Post/thread-level component-wise classification F-scores for Link and DA classes 6 Experiments and Analysis 6.1 Joint classification As our baseline for the task, we first use a simple majority class classifier in the form of the single joint class of 1+Answer-Answer for all posts, which has a post-level F-score of 0.284. A stronger baseline is to classify all first posts as 0+QuestionQuestion and all subsequent posts as 1+Answeranswer, which achieves a post-level F-score of 0.515 (labelled as Heuristic). As described in Sectio</context>
</contexts>
<marker>Kim, Cavedon, Baldwin, 2010</marker>
<rawString>Su Nam Kim, Lawrence Cavedon, and Timothy Baldwin. 2010a. Classifying dialogue acts in one-on-one live chats. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing (EMNLP 2010), pages 862–871, Boston, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Li Wang</author>
<author>Timothy Baldwin</author>
</authors>
<title>Tagging and linking web forum posts.</title>
<date>2010</date>
<booktitle>In Proceedings of the 14th Conference on Computational Natural Language Learning (CoNLL-2010),</booktitle>
<pages>192--202</pages>
<location>Uppsala,</location>
<contexts>
<context position="3503" citStr="Kim et al. (2010" startWordPosition="550" endWordPosition="553">assessment (Lui and Baldwin, 2009). We aim to move beyond simple threading, to predict not only the links between posts, but also show the manner of each link, in the form of the discourse structure of the thread. In doing so, we hope to be able to perform richer visualisation of thread structure (e.g. highlighting the key posts which appear to have led to a successful resolution to a problem), and more finegrained weighting of posts in threads for search purposes. To illustrate the task, we use an example thread, made up of 5 posts from 4 distinct participants, from the CNET forum dataset of Kim et al. (2010b), as shown in Figure 1. The discourse structure of the thread is modelled as a rooted directed acyclic graph 13 Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 13–25, Edinburgh, Scotland, UK, July 27–31, 2011. c�2011 Association for Computational Linguistics Figure 1: A snippeted and annotated CNET thread (DAG) with a dialogue act label associated with each edge of the graph. In this example, UserA initiates the thread with a question (dialogue act = QuestionQuestion) in the first post, by asking how to create an interactive input box on a webpag</context>
<context position="4861" citStr="Kim et al. (2010" startWordPosition="765" endWordPosition="768">the solution (dialogue act = Answer-Confirmation), and at the same time, adds extra information to his/her original question (dialogue act = Question-Add); i.e., this one post has two distinct dependency links associated with it. Finally, UserD proposes a different solution again to the original question. To predict thread discourse structure of this type, we jointly classify the links and dialogue acts between posts, experimenting with a variety of supervised classification methods, namely dependency parsing and linear-chain conditional random fields. In this, we build on the earlier work of Kim et al. (2010b) who first proposed the task of thread discourse analysis, but only carried out experiments on post linking and post dialogue act classification as separate tasks. In addition to achieving state-of-theart accuracy over the task, we carry out in-depth analysis of classification effectiveness at different thread depths, and establish that the accuracy of our method over partial threads is equivalent to that over full threads, indicating that the method is applicable to in-situ thread classification. Finally, we investigate the role of user-level features in discourse structure analysis. 2 Rela</context>
<context position="7471" citStr="Kim et al., 2010" startWordPosition="1190" endWordPosition="1193">l., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text field. See ... Part 2: give it a Javascript action 3+Question-Add Thank You! T</context>
<context position="15237" citStr="Kim et al. (2010" startWordPosition="2404" endWordPosition="2407">aset, however, poses a challenge for dependency parsing. In addition to performing evaluation in batch mode over complete threads, we consider the task of “in situ thread classification”, whereby we predict the discourse structure of a thread after each post. This is intended to simulate the more realistic setting of incrementally crawling/updating thread data, but needing to predict discourse structure for partial threads. We are interested in determining the relative degradation in accuracy for in situ classification vs. batch classification. As our dataset, we use the CNET forum dataset of Kim et al. (2010b),1 which contains 1332 annotated posts spanning 315 threads, collected from the Operating System, Software, Hardware and Web Development sub-forums of cnet.2 Each post is labelled with one or more links (including the possibility of null-links, where the post doesn’t link to any other post), and each link is labelled with a dialogue act. The dialogue act set is made up of 5 super-categories: Question, Answer, Resolution (confirmation of the question being resolved), Reproduction (external confirmation of a proposed solution working) and Other. The Question category contains 4 sub-classes: Qu</context>
<context position="16902" citStr="Kim et al. (2010" startWordPosition="2672" endWordPosition="2675">st of posts, e.g. 1 indicates a link back to the preceding post, and 2 indicates a link back two posts. Unless otherwise noted, evaluation is over the combined link and dialogue act tag, including the combination of superclass and subclass for the Question and Answer dialogue acts. For example, 1+Answer-Answer indicates a dependency link back one post, which is an answer to a question. The most common label in the dataset is 1+Answeranswer (28.4%). 4 Learners and Features 4.1 Learners To predict thread discourse structure, we use a structured classification approach — based on the findings of Kim et al. (2010b) and Kim et al. (2010a) — and a dependency parser. The structured classification approach we experiment with is a linear1Available from http://www.csse.unimelb.edu. au/research/lt/resources/conll2010-thread/ 2http://forums.cnet.com/ 16 chain conditional random field learner (CRF: Lafferty et al. (2001)), within which we explore two simple approaches to joint classification, as is explained in Section 5.1. Dependency parsing (K¨ubler et al., 2009) is the task of automatically predicting the dependency structure of a token sequence, in the form of binary asymmetric dependency relations with de</context>
<context position="20735" citStr="Kim et al. (2010" startWordPosition="3272" endWordPosition="3275">atio over the total number of posts in the thread. Semantic Features: TitSim the relative location of the post which has the most similar title (based on unweighted cosine similarity) to the current post. PostSim the relative location of the post which has the most similar content (based on unweighted cosine similarity) to the current post. Punct the number of question marks (QuCount), exclamation marks (ExCount) and URLs (UrlCount) in the current post. UserProf the class distribution (in the training thread) of the author of the current post. These features are drawn largely from the work of Kim et al. (2010b), with two major differences: (1) we do not use post context features because our learners (i.e. CRFSGD and MaltParser) inherently capture Markov chains; and (2) our UserProf features are customised to the class set associated with the task at hand, e.g. the UserProf features for the standalone linking task take the form of the link labels (and not dialogue act labels) of the posts by the relevant author in the training data. Table 1 shows the feature representation of the third post in a thread 17 Feature Value Initiator 1.0 ExCount 4.0 QuCount 0.0 UrlCount 0.0 Position 0.25 PostSim 2.0 Tit</context>
<context position="25505" citStr="Kim et al. (2010" startWordPosition="4070" endWordPosition="4073">ariable in play is the extent of thread context used to learn the thread discourse structure for the given set of posts. We break down the results in each case into the indicated subthreads, e.g. we take the predictions for [all], and break them down into the results for [1, 2], [1, 4], [1, 6], [1, 8] and [all], for direct comparison with the predictions over the respective sub-thread data. 5In practice, completeness is defined at a given point in time, when the crawl was done, and it is highly likely that some of the “complete” threads had extra posts after the crawl. 3−1 8 18 Method Link DA Kim et al. (2010b) .863 / .676 .751 / .543 CRFSGD .891 / .727 .795 / .609 Table 2: Post/thread-level component-wise classification F-scores for Link and DA classes 6 Experiments and Analysis 6.1 Joint classification As our baseline for the task, we first use a simple majority class classifier in the form of the single joint class of 1+Answer-Answer for all posts, which has a post-level F-score of 0.284. A stronger baseline is to classify all first posts as 0+QuestionQuestion and all subsequent posts as 1+Answeranswer, which achieves a post-level F-score of 0.515 (labelled as Heuristic). As described in Sectio</context>
</contexts>
<marker>Kim, Wang, Baldwin, 2010</marker>
<rawString>Su Nam Kim, Li Wang, and Timothy Baldwin. 2010b. Tagging and linking web forum posts. In Proceedings of the 14th Conference on Computational Natural Language Learning (CoNLL-2010), pages 192–202, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra K¨ubler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<date>2009</date>
<booktitle>Dependency parsing. Synthesis Lectures on Human Language Technologies,</booktitle>
<pages>2--1</pages>
<marker>K¨ubler, McDonald, Nivre, 2009</marker>
<rawString>Sandra K¨ubler, Ryan McDonald, and Joakim Nivre. 2009. Dependency parsing. Synthesis Lectures on Human Language Technologies, 2(1):1–127.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Lafferty</author>
<author>Andrew McCallum</author>
<author>Fernando Pereira</author>
</authors>
<title>Conditional random fields: Probabilistic models for segmenting and labeling sequence data.</title>
<date>2001</date>
<booktitle>In Proceedings of the 18th International Conference on Machine Learning,</booktitle>
<pages>282--289</pages>
<location>Williamstown, USA.</location>
<contexts>
<context position="17207" citStr="Lafferty et al. (2001)" startWordPosition="2709" endWordPosition="2713">nswer-Answer indicates a dependency link back one post, which is an answer to a question. The most common label in the dataset is 1+Answeranswer (28.4%). 4 Learners and Features 4.1 Learners To predict thread discourse structure, we use a structured classification approach — based on the findings of Kim et al. (2010b) and Kim et al. (2010a) — and a dependency parser. The structured classification approach we experiment with is a linear1Available from http://www.csse.unimelb.edu. au/research/lt/resources/conll2010-thread/ 2http://forums.cnet.com/ 16 chain conditional random field learner (CRF: Lafferty et al. (2001)), within which we explore two simple approaches to joint classification, as is explained in Section 5.1. Dependency parsing (K¨ubler et al., 2009) is the task of automatically predicting the dependency structure of a token sequence, in the form of binary asymmetric dependency relations with dependency types. Standardly, CRFs have been applied to tasks such as part-of-speech tagging, named entity recognition, semantic role labelling and supertagging, where the individual tokens are single words. Similarly, dependency parsing is conventionally applied to sentences, with single-word tokens. In o</context>
</contexts>
<marker>Lafferty, McCallum, Pereira, 2001</marker>
<rawString>John Lafferty, Andrew McCallum, and Fernando Pereira. 2001. Conditional random fields: Probabilistic models for segmenting and labeling sequence data. In Proceedings of the 18th International Conference on Machine Learning, pages 282–289, Williamstown, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Lampert</author>
<author>Robert Dale</author>
<author>C´ecile Paris</author>
</authors>
<title>The nature of requests and commitments in email messages.</title>
<date>2008</date>
<booktitle>In Proceedings of the AAAI 2008 Workshop on Enhanced Messaging,</booktitle>
<pages>42--47</pages>
<location>Chicago, USA.</location>
<contexts>
<context position="7418" citStr="Lampert et al., 2008" startWordPosition="1182" endWordPosition="1185">rm of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text field. See ... Part 2: gi</context>
</contexts>
<marker>Lampert, Dale, Paris, 2008</marker>
<rawString>Andrew Lampert, Robert Dale, and C´ecile Paris. 2008. The nature of requests and commitments in email messages. In Proceedings of the AAAI 2008 Workshop on Enhanced Messaging, pages 42–47, Chicago, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Leaman</author>
<author>Laura Wojtulewicz</author>
<author>Ryan Sullivan</author>
<author>Annie Skariah</author>
<author>Jian Yang</author>
<author>Graciela Gonzalez</author>
</authors>
<title>Towards internet-age pharmacovigilance: Extracting adverse drug reactions from user posts in healthrelated social networks.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Workshop on Biomedical Natural Language Processing (ACL 2010),</booktitle>
<pages>117--125</pages>
<location>Uppsala,</location>
<contexts>
<context position="11147" citStr="Leaman et al. (2010)" startWordPosition="1780" endWordPosition="1783">on (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer and Gurevych, 2007; Wanas et al., 2008; Lui and Baldwin, 2009), and post descriptiveness in particular domains (e.g. medical forums: Leaman et al. (2010)). It has been demonstrated (Wanas et al., 2008; Lui and Baldwin, 2009) that thread discourse structure can significantly improve the classification accuracy for postlevel tasks. Initiation–response pairs (e.g. question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge bases for Community Question Answering (cQA) services such as Yahoo! Answers. While initiation– response pair identification has been explored as a pairwise ranking problem (Wang and Ros´e, 2010), question–answer pair identifi</context>
</contexts>
<marker>Leaman, Wojtulewicz, Sullivan, Skariah, Yang, Gonzalez, 2010</marker>
<rawString>Robert Leaman, Laura Wojtulewicz, Ryan Sullivan, Annie Skariah, Jian Yang, and Graciela Gonzalez. 2010. Towards internet-age pharmacovigilance: Extracting adverse drug reactions from user posts in healthrelated social networks. In Proceedings of the 2010 Workshop on Biomedical Natural Language Processing (ACL 2010), pages 117–125, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Alex Gruenstein</author>
<author>Stanley Peters</author>
</authors>
<title>Collaborative activities and multi-tasking in dialogue systems.</title>
<date>2002</date>
<journal>Traitement Automatique des Langues (TAL), Special Issue on Dialogue,</journal>
<volume>43</volume>
<issue>2</issue>
<contexts>
<context position="6652" citStr="Lemon et al., 2002" startWordPosition="1048" endWordPosition="1051">neralisability of the original method. In both cases, however, we tackled only a single task, either link classification (optionally given dialogue act tags) or dialogue act classification, but never the two together. In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication includin</context>
</contexts>
<marker>Lemon, Gruenstein, Peters, 2002</marker>
<rawString>Oliver Lemon, Alex Gruenstein, and Stanley Peters. 2002. Collaborative activities and multi-tasking in dialogue systems. Traitement Automatique des Langues (TAL), Special Issue on Dialogue, 43(2):131–154.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Lin</author>
<author>Jiang-Ming Yang</author>
<author>Rui Cai</author>
<author>Xin-Jing Wang</author>
<author>Wei Wang</author>
<author>Lei Zhang</author>
</authors>
<title>Modeling semantics and structure of discussion threads.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th International Conference on the World Wide Web (WWW</booktitle>
<pages>1103--1104</pages>
<location>Madrid,</location>
<contexts>
<context position="7016" citStr="Lin et al., 2009" startWordPosition="1112" endWordPosition="1115">ctures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp</context>
</contexts>
<marker>Lin, Yang, Cai, Wang, Wang, Zhang, 2009</marker>
<rawString>Chen Lin, Jiang-Ming Yang, Rui Cai, Xin-Jing Wang, Wei Wang, and Lei Zhang. 2009. Modeling semantics and structure of discussion threads. In Proceedings of the 18th International Conference on the World Wide Web (WWW 2009), pages 1103–1104, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Timothy Baldwin</author>
</authors>
<title>You are what you post: User-level features in threaded discourse.</title>
<date>2009</date>
<booktitle>In Proceedings of the 14th Australasian Document Computing Symposium (ADCS 2009),</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="2921" citStr="Lui and Baldwin, 2009" startWordPosition="442" endWordPosition="445">, more and more answers to questions over a wide range of domains are becoming available on forums; on the other hand, it is becoming harder and harder to extract and access relevant information due to the sheer scale and diversity of the data. This research aims at enhancing information access and support sharing, by mining the discourse structure of troubleshooting-oriented web user forum threads. Previous research has shown that simple thread structure information (e.g. reply-to structure) can enhance tasks such as forum information retrieval (Seo et al., 2009) and post quality assessment (Lui and Baldwin, 2009). We aim to move beyond simple threading, to predict not only the links between posts, but also show the manner of each link, in the form of the discourse structure of the thread. In doing so, we hope to be able to perform richer visualisation of thread structure (e.g. highlighting the key posts which appear to have led to a successful resolution to a problem), and more finegrained weighting of posts in threads for search purposes. To illustrate the task, we use an example thread, made up of 5 posts from 4 distinct participants, from the CNET forum dataset of Kim et al. (2010b), as shown in Fi</context>
<context position="9875" citStr="Lui and Baldwin (2009)" startWordPosition="1593" endWordPosition="1596">ystem to improve the accuracy of a probabilistic parser. Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell</context>
<context position="11218" citStr="Lui and Baldwin, 2009" startWordPosition="1792" endWordPosition="1796">nn et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer and Gurevych, 2007; Wanas et al., 2008; Lui and Baldwin, 2009), and post descriptiveness in particular domains (e.g. medical forums: Leaman et al. (2010)). It has been demonstrated (Wanas et al., 2008; Lui and Baldwin, 2009) that thread discourse structure can significantly improve the classification accuracy for postlevel tasks. Initiation–response pairs (e.g. question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge bases for Community Question Answering (cQA) services such as Yahoo! Answers. While initiation– response pair identification has been explored as a pairwise ranking problem (Wang and Ros´e, 2010), question–answer pair identification has been approached via the two separate sub-tasks of question c</context>
</contexts>
<marker>Lui, Baldwin, 2009</marker>
<rawString>Marco Lui and Timothy Baldwin. 2009. You are what you post: User-level features in threaded discourse. In Proceedings of the 14th Australasian Document Computing Symposium (ADCS 2009), Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Lui</author>
<author>Timothy Baldwin</author>
</authors>
<title>Classifying user forum participants: Separating the gurus from the hacks, and other tales of the internet.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Australasian Language Technology Workshop (ALTW 2010),</booktitle>
<pages>49--57</pages>
<location>Melbourne, Australia.</location>
<contexts>
<context position="10030" citStr="Lui and Baldwin (2010)" startWordPosition="1613" endWordPosition="1616">tion (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-of-the-art results over both tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results su</context>
</contexts>
<marker>Lui, Baldwin, 2010</marker>
<rawString>Marco Lui and Timothy Baldwin. 2010. Classifying user forum participants: Separating the gurus from the hacks, and other tales of the internet. In Proceedings of the 2010 Australasian Language Technology Workshop (ALTW 2010), pages 49–57, Melbourne, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Characterizing the errors of data-driven dependency parsing models.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning</booktitle>
<pages>122--131</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="32557" citStr="McDonald and Nivre (2007)" startWordPosition="5208" endWordPosition="5211"> and DA F-score based on the decomposition of CRFSGD and MaltParser classifications for Link and DA; the results are presented in Figure 3. It is clear that the anomaly for CRFSGD comes from the DA component, due to there being greater predictability in the dialogue for final posts in a thread (users tend to confirm a successful resolution of the problem, or report on successful external reproduction of the solution). MaltParser seems less adept at identifying that a post is at the end of a thread, and predicting the dialogue act accordingly. This observation is congruous with the findings of McDonald and Nivre (2007) that errors propagate, due to MaltParser’s greedy inference strategy. The higher results for Link are to be expected, as throughout the thread, most posts tend to link locally. 1 0.9 0.8 0.7 0.6 0.5 0.4 0.3 0.2 0.1 0 [1,2] [3,4] [5,6] [7,8] [9,] All CRFSGD MaltParser CRFSGD MaltParser [1,2] [3,4] [5,6] [7,8] [9,] All Decomposed DA CRFSGD MaltParser [1,2] [3,4] [5,6] [7,8] [9,] All 1 F 0.5 0 Posts 1 F 0.5 0 F 20 B/down [1, 2] [1, 4] [1, 6] [1, 8] [All] ❳❳❳❳❳❳❳❳❳ Test [1, 2] .947/.947 — — — — [1, 4] .946/.947 .836/.841 — — [1, 6] .946/.947 .840/.841 .800/.794 — — [1, 8] .946/.947 .840/.841 .800</context>
</contexts>
<marker>McDonald, Nivre, 2007</marker>
<rawString>Ryan McDonald and Joakim Nivre. 2007. Characterizing the errors of data-driven dependency parsing models. In Proceedings of the 2007 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning (EMNLP-CoNLL 2007), pages 122–131, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL</booktitle>
<pages>81--88</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="14473" citStr="McDonald and Pereira, 2006" startWordPosition="2289" endWordPosition="2292">possible for there to be disconnected sub-graphs, e.g. in instances where a user hijacks a thread to ask their own unrelated question, or submit an unrelated spam post; around 2% of the threads in our dataset contain disconnected sub-graphs. The first constraint potentially simplifies dependency parsing, and non-projective dependencies are relatively well understood in the dependency parsing community (Tapanainen and Jarvinen, 1997; McDonald et al., 2005). Multi-headedness and disconnected sub-graphs pose greater challenges to dependency parsing, although there has been research done on both (McDonald and Pereira, 2006; Sagae and Tsujii, 2008; Eisner and Smith, 2005). The combination of non-projectivity, multi-headedness and disconnected sub-graphs in a single dataset, however, poses a challenge for dependency parsing. In addition to performing evaluation in batch mode over complete threads, we consider the task of “in situ thread classification”, whereby we predict the discourse structure of a thread after each post. This is intended to simulate the more realistic setting of incrementally crawling/updating thread data, but needing to predict discourse structure for partial threads. We are interested in det</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>Ryan McDonald and Fernando Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics (EACL 2006), pages 81–88, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Fernando Pereira</author>
<author>Kiril Ribarov</author>
<author>Jan Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>523--530</pages>
<location>Vancouver, Canada.</location>
<contexts>
<context position="14306" citStr="McDonald et al., 2005" startWordPosition="2264" endWordPosition="2268">mation from the original question [QuestionCorrection]); around 6% of the threads in our dataset contain multi-headed dependencies. disconnected sub-graphs: it is possible for there to be disconnected sub-graphs, e.g. in instances where a user hijacks a thread to ask their own unrelated question, or submit an unrelated spam post; around 2% of the threads in our dataset contain disconnected sub-graphs. The first constraint potentially simplifies dependency parsing, and non-projective dependencies are relatively well understood in the dependency parsing community (Tapanainen and Jarvinen, 1997; McDonald et al., 2005). Multi-headedness and disconnected sub-graphs pose greater challenges to dependency parsing, although there has been research done on both (McDonald and Pereira, 2006; Sagae and Tsujii, 2008; Eisner and Smith, 2005). The combination of non-projectivity, multi-headedness and disconnected sub-graphs in a single dataset, however, poses a challenge for dependency parsing. In addition to performing evaluation in batch mode over complete threads, we consider the task of “in situ thread classification”, whereby we predict the discourse structure of a thread after each post. This is intended to simul</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>Ryan McDonald, Fernando Pereira, Kiril Ribarov, and Jan Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. In Proceedings of Human Language Technology Conference and Conference on Empirical Methods in Natural Language Processing, pages 523–530, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Murray</author>
<author>Steve Renals</author>
<author>Jean Carletta</author>
<author>Johanna Moore</author>
</authors>
<title>Incorporating speaker and discourse features into speech summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>367--374</pages>
<contexts>
<context position="7342" citStr="Murray et al., 2006" startWordPosition="1169" endWordPosition="1172">-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re:</context>
</contexts>
<marker>Murray, Renals, Carletta, Moore, 2006</marker>
<rawString>Gabriel Murray, Steve Renals, Jean Carletta, and Johanna Moore. 2006. Incorporating speaker and discourse features into speech summarization. In Proceedings of the Main Conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 367– 374.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klemens Muthmann</author>
<author>Wojciech M Barczy´nski</author>
<author>Falk Brauer</author>
<author>Alexander L¨oser</author>
</authors>
<title>Near-duplicate detection for web-forums.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 International Database Engineering &amp; Applications Symposium (IDEAS</booktitle>
<pages>142--151</pages>
<location>Cetraro, Italy.</location>
<marker>Muthmann, Barczy´nski, Brauer, L¨oser, 2009</marker>
<rawString>Klemens Muthmann, Wojciech M. Barczy´nski, Falk Brauer, and Alexander L¨oser. 2009. Near-duplicate detection for web-forums. In Proceedings of the 2009 International Database Engineering &amp; Applications Symposium (IDEAS 2009), pages 142–151, Cetraro, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>02</issue>
<contexts>
<context position="18131" citStr="Nivre et al., 2007" startWordPosition="2850" endWordPosition="2853">ypes. Standardly, CRFs have been applied to tasks such as part-of-speech tagging, named entity recognition, semantic role labelling and supertagging, where the individual tokens are single words. Similarly, dependency parsing is conventionally applied to sentences, with single-word tokens. In our case, our tokens are thread posts, with much greater scope for feature engineering than single words, and technical challenges in scaling the underlying implementations to handle potentially much larger feature sets. As our learners, we deployed CRFSGD (Bottou, 2011) to learn the CRF, and MaltParser (Nivre et al., 2007) as our dependency parser. CRFSGD uses stochastic gradient descent to efficiently solve the convex optimisation problem, and scales well to large feature sets. We used the default parameter settings for CRFSGD, with feature templates including all unigram features of the current token as well as bigram features combining the previous output token with the current token. MaltParser implements transition-based parsing, where no formal grammar is considered, and a transition system, or state machine, is learned to map a sentence onto its dependency graph. One feature of MaltParser that makes it w</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, G¨ulsen Eryigit, Sandra K¨ubler, Svetoslav Marinov, and Erwin Marsi. 2007. MaltParser: A languageindependent system for data-driven dependency parsing. Natural Language Engineering, 13(02):95–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>An efficient algorithm for projective dependency parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT 03),</booktitle>
<pages>149--160</pages>
<location>Nancy, France.</location>
<contexts>
<context position="19299" citStr="Nivre, 2003" startWordPosition="3044" endWordPosition="3045">. One feature of MaltParser that makes it well suited to our task is that it is possible to define feature models of arbitrary complexity for each token. In presenting the thread data to MaltParser, we represent the nulllink from the initial post of each thread, as well as any disconnected posts, as the root. To the best of our knowledge, there is no past work on using dependency parsing to learn thread discourse structure. Based on extensive experimentation, we determined that the MaltParser configuration that obtains the best results for our task is the Nivre algorithm in arc-standard mode (Nivre, 2003; Nivre, 2004), using LIBSVM (Chang and Lin, 2011) with a linear kernel as the learner, and a feature model with exhaustive combinations of features relating to the features and predictions of the first/top three tokens from both “Input” and “Stack”.3 As such, MaltParser is actually unable to predict any non-projective structures, as experiments with algorithms supporting non-projective structures invariably led to lower results. In our choice of parsing algorithm, we are also unable to detect posts with multiple heads, but can potentially detect disconnected sub-graphs. 4.2 Features The featu</context>
</contexts>
<marker>Nivre, 2003</marker>
<rawString>Joakim Nivre. 2003. An efficient algorithm for projective dependency parsing. In Proceedings of the 8th International Workshop on Parsing Technologies (IWPT 03), pages 149–160, Nancy, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Incrementality in deterministic dependency parsing.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL Workshop Incremental Parsing: Bringing Engineering and Cognition Together (ACL-2004),</booktitle>
<pages>50--57</pages>
<location>Barcelona,</location>
<contexts>
<context position="19313" citStr="Nivre, 2004" startWordPosition="3046" endWordPosition="3047"> of MaltParser that makes it well suited to our task is that it is possible to define feature models of arbitrary complexity for each token. In presenting the thread data to MaltParser, we represent the nulllink from the initial post of each thread, as well as any disconnected posts, as the root. To the best of our knowledge, there is no past work on using dependency parsing to learn thread discourse structure. Based on extensive experimentation, we determined that the MaltParser configuration that obtains the best results for our task is the Nivre algorithm in arc-standard mode (Nivre, 2003; Nivre, 2004), using LIBSVM (Chang and Lin, 2011) with a linear kernel as the learner, and a feature model with exhaustive combinations of features relating to the features and predictions of the first/top three tokens from both “Input” and “Stack”.3 As such, MaltParser is actually unable to predict any non-projective structures, as experiments with algorithms supporting non-projective structures invariably led to lower results. In our choice of parsing algorithm, we are also unable to detect posts with multiple heads, but can potentially detect disconnected sub-graphs. 4.2 Features The features used in ou</context>
</contexts>
<marker>Nivre, 2004</marker>
<rawString>Joakim Nivre. 2004. Incrementality in deterministic dependency parsing. In Proceedings of the ACL Workshop Incremental Parsing: Bringing Engineering and Cognition Together (ACL-2004), pages 50–57, Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolyn Penstein Ros´e</author>
<author>Barbara Di Eugenio</author>
<author>Lori S Levin</author>
<author>Carol Van Ess-Dykema</author>
</authors>
<title>Discourse processing of dialogues with multiple threads.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>31--38</pages>
<location>Cambridge, USA.</location>
<marker>Ros´e, Di Eugenio, Levin, Van Ess-Dykema, 1995</marker>
<rawString>Carolyn Penstein Ros´e, Barbara Di Eugenio, Lori S. Levin, and Carol Van Ess-Dykema. 1995. Discourse processing of dialogues with multiple threads. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics, pages 31–38, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Shift-reduce dependency DAG parsing.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (COLING</booktitle>
<pages>753--760</pages>
<location>Manchester, UK.</location>
<contexts>
<context position="14497" citStr="Sagae and Tsujii, 2008" startWordPosition="2293" endWordPosition="2296">connected sub-graphs, e.g. in instances where a user hijacks a thread to ask their own unrelated question, or submit an unrelated spam post; around 2% of the threads in our dataset contain disconnected sub-graphs. The first constraint potentially simplifies dependency parsing, and non-projective dependencies are relatively well understood in the dependency parsing community (Tapanainen and Jarvinen, 1997; McDonald et al., 2005). Multi-headedness and disconnected sub-graphs pose greater challenges to dependency parsing, although there has been research done on both (McDonald and Pereira, 2006; Sagae and Tsujii, 2008; Eisner and Smith, 2005). The combination of non-projectivity, multi-headedness and disconnected sub-graphs in a single dataset, however, poses a challenge for dependency parsing. In addition to performing evaluation in batch mode over complete threads, we consider the task of “in situ thread classification”, whereby we predict the discourse structure of a thread after each post. This is intended to simulate the more realistic setting of incrementally crawling/updating thread data, but needing to predict discourse structure for partial threads. We are interested in determining the relative de</context>
</contexts>
<marker>Sagae, Tsujii, 2008</marker>
<rawString>Kenji Sagae and Jun’ichi Tsujii. 2008. Shift-reduce dependency DAG parsing. In Proceedings of the 22nd International Conference on Computational Linguistics (COLING 2008), pages 753–760, Manchester, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
</authors>
<title>Analysis of discourse structure with syntactic dependencies and data-driven shift-reduce parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT-09),</booktitle>
<pages>81--84</pages>
<location>Paris, France.</location>
<contexts>
<context position="7530" citStr="Sagae, 2009" startWordPosition="1200" endWordPosition="1201">et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text field. See ... Part 2: give it a Javascript action 3+Question-Add Thank You! Thanks a lot for that ... I have Microsoft Visual Studio 6, </context>
</contexts>
<marker>Sagae, 2009</marker>
<rawString>Kenji Sagae. 2009. Analysis of discourse structure with syntactic dependencies and data-driven shift-reduce parsing. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT-09), pages 81– 84, Paris, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anne Schuth</author>
<author>Maarten Marx</author>
<author>Maarten de Rijke</author>
</authors>
<title>Extracting the discussion structure in comments on news-articles.</title>
<date>2007</date>
<booktitle>In Proceedings of the 9th Annual ACM International Workshop on Web Information and Data Management,</booktitle>
<pages>97--104</pages>
<location>Lisboa, Portugal.</location>
<marker>Schuth, Marx, de Rijke, 2007</marker>
<rawString>Anne Schuth, Maarten Marx, and Maarten de Rijke. 2007. Extracting the discussion structure in comments on news-articles. In Proceedings of the 9th Annual ACM International Workshop on Web Information and Data Management, pages 97–104, Lisboa, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jangwon Seo</author>
<author>W Bruce Croft</author>
<author>David A Smith</author>
</authors>
<title>Online community search using thread structure.</title>
<date>2009</date>
<booktitle>In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM</booktitle>
<pages>1907--1910</pages>
<location>Hong Kong, China.</location>
<contexts>
<context position="2869" citStr="Seo et al., 2009" startWordPosition="433" endWordPosition="436"> solution to a current problem. On the one hand, more and more answers to questions over a wide range of domains are becoming available on forums; on the other hand, it is becoming harder and harder to extract and access relevant information due to the sheer scale and diversity of the data. This research aims at enhancing information access and support sharing, by mining the discourse structure of troubleshooting-oriented web user forum threads. Previous research has shown that simple thread structure information (e.g. reply-to structure) can enhance tasks such as forum information retrieval (Seo et al., 2009) and post quality assessment (Lui and Baldwin, 2009). We aim to move beyond simple threading, to predict not only the links between posts, but also show the manner of each link, in the form of the discourse structure of the thread. In doing so, we hope to be able to perform richer visualisation of thread structure (e.g. highlighting the key posts which appear to have led to a successful resolution to a problem), and more finegrained weighting of posts in threads for search purposes. To illustrate the task, we use an example thread, made up of 5 posts from 4 distinct participants, from the CNET</context>
<context position="6882" citStr="Seo et al., 2009" startWordPosition="1087" endWordPosition="1090"> we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited </context>
<context position="10412" citStr="Seo et al., 2009" startWordPosition="1673" endWordPosition="1676"> been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer and Gurevych, 2007</context>
</contexts>
<marker>Seo, Croft, Smith, 2009</marker>
<rawString>Jangwon Seo, W. Bruce Croft, and David A. Smith. 2009. Online community search using thread structure. In Proceedings of the 18th ACM Conference on Information and Knowledge Management (CIKM 2009), pages 1907–1910, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elinzabeth Shriberg</author>
<author>Raj Dhillon</author>
<author>Sonali Bhagat</author>
<author>Jeremy Ang</author>
<author>Hannah Carvey</author>
</authors>
<title>The ICSI meeting recorder dialog act (MRDA) corpus.</title>
<date>2004</date>
<booktitle>In Proceedings of the 5th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>97--100</pages>
<location>Cambridge, USA.</location>
<contexts>
<context position="7320" citStr="Shriberg et al., 2004" startWordPosition="1165" endWordPosition="1168">o a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-An</context>
</contexts>
<marker>Shriberg, Dhillon, Bhagat, Ang, Carvey, 2004</marker>
<rawString>Elinzabeth Shriberg, Raj Dhillon, Sonali Bhagat, Jeremy Ang, and Hannah Carvey. 2004. The ICSI meeting recorder dialog act (MRDA) corpus. In Proceedings of the 5th SIGdial Workshop on Discourse and Dialogue, pages 97–100, Cambridge, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Parikshit Sondhi</author>
<author>Manish Gupta</author>
<author>ChengXiang Zhai</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Shallow information extraction from medical forum data.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), Posters Volume,</booktitle>
<pages>1158--1166</pages>
<location>Beijing, China.</location>
<contexts>
<context position="10551" citStr="Sondhi et al., 2010" startWordPosition="1692" endWordPosition="1695">ies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer and Gurevych, 2007; Wanas et al., 2008; Lui and Baldwin, 2009), and post descriptiveness in particular domains (e.g. medical forums: Leaman et al. (2010)). I</context>
</contexts>
<marker>Sondhi, Gupta, Zhai, Hockenmaier, 2010</marker>
<rawString>Parikshit Sondhi, Manish Gupta, ChengXiang Zhai, and Julia Hockenmaier. 2010. Shallow information extraction from medical forum data. In Proceedings of the 23rd International Conference on Computational Linguistics (COLING 2010), Posters Volume, pages 1158–1166, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL</booktitle>
<pages>149--156</pages>
<location>Edmonton, Canada.</location>
<contexts>
<context position="7516" citStr="Soricut and Marcu, 2003" startWordPosition="1196" endWordPosition="1199">c graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 2000; Shriberg et al., 2004; Murray et al., 2006), email (Cohen et al., 2004; Carvalho and Cohen, 2005; Lampert et al., 2008), instant messaging (Ivanovic, 2008; Kim et al., 2010a), edited documents (Soricut and Marcu, 2003; Sagae, 2009) and online forums (Xi et al., 1+Answer-Confirmation 4+Answer-Answer User C Post 3 asp.net c\# video I’ve prepared for you video.link click ... Ø 0+Question-Question HTML Input Code ...Please can someone tell me how to create an input box that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text field. See ... Part 2: give it a Javascript action 3+Question-Add Thank You! Thanks a lot for that ... I have Microsoft Vis</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>Radu Soricut and Daniel Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of the 2003 Human Language Technology Conference of the North American Chapter of the Association for Computational Linguistics (HLT-NAACL 2003), pages 149–156, Edmonton, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Klaus Ries</author>
<author>Noah Coccaro</author>
<author>Elizabeth Shriberg</author>
<author>Rebecca Bates</author>
<author>Daniel Jurafsky</author>
<author>Pail Taylor</author>
<author>Rachel Martin</author>
<author>Carol Van Ess-Dykema</author>
<author>Marie Meteer</author>
</authors>
<title>Dialogue act modeling for automatic tagging and recognition of conversational speech.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>3</issue>
<marker>Stolcke, Ries, Coccaro, Shriberg, Bates, Jurafsky, Taylor, Martin, Van Ess-Dykema, Meteer, 2000</marker>
<rawString>Andreas Stolcke, Klaus Ries, Noah Coccaro, Elizabeth Shriberg, Rebecca Bates, Daniel Jurafsky, Pail Taylor, Rachel Martin, Carol Van Ess-Dykema, and Marie Meteer. 2000. Dialogue act modeling for automatic tagging and recognition of conversational speech. Computational Linguistics, 26(3):339–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles Sutton</author>
<author>Andrew McCallum</author>
</authors>
<title>Joint parsing and semantic role labeling.</title>
<date>2005</date>
<booktitle>In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005),</booktitle>
<pages>225--228</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="9151" citStr="Sutton and McCallum (2005)" startWordPosition="1482" endWordPosition="1486">nd dialogue act tagging, see Kim et al. (2010b). Joint classification has been applied in a number of different contexts, based on the intuition that it should be possible to harness interactions between different sub-tasks to the mutual benefit of both. Warnke et al. (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. In their approach, the predictions of a multi-layer perceptron classifier on dialogue act boundaries were fed into an n-gram language model, which was used for the joint segmentation and classification of dialogue acts. Sutton and McCallum (2005) performed joint parsing and semantic role labelling (SRL), using the results of a probabilistic SRL system to improve the accuracy of a probabilistic parser. Finkel and Manning (2009) built a joint, discriminative model for parsing and named entity recognition (NER), addressing the problem of inconsistent annotations across the two tasks, and demonstrating that NER benefited considerably from the interaction with parsing. Dahlmeier et al. (2009) proposed a joint probabilistic model for word sense disambiguation (WSD) of prepositions and SRL of prepositional phrases (PPs), and achieved state-o</context>
</contexts>
<marker>Sutton, McCallum, 2005</marker>
<rawString>Charles Sutton and Andrew McCallum. 2005. Joint parsing and semantic role labeling. In Proceedings of the Ninth Conference on Computational Natural Language Learning (CoNLL-2005), pages 225–228, Ann Arbor, Michigan. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pasi Tapanainen</author>
<author>Timo Jarvinen</author>
</authors>
<title>A nonprojective dependency parser.</title>
<date>1997</date>
<booktitle>In Proceedings of the Fifth Conference on Applied Natural Language Processing,</booktitle>
<pages>64--71</pages>
<location>Washington, USA.</location>
<contexts>
<context position="14282" citStr="Tapanainen and Jarvinen, 1997" startWordPosition="2260" endWordPosition="2263">dd] as well as retracting information from the original question [QuestionCorrection]); around 6% of the threads in our dataset contain multi-headed dependencies. disconnected sub-graphs: it is possible for there to be disconnected sub-graphs, e.g. in instances where a user hijacks a thread to ask their own unrelated question, or submit an unrelated spam post; around 2% of the threads in our dataset contain disconnected sub-graphs. The first constraint potentially simplifies dependency parsing, and non-projective dependencies are relatively well understood in the dependency parsing community (Tapanainen and Jarvinen, 1997; McDonald et al., 2005). Multi-headedness and disconnected sub-graphs pose greater challenges to dependency parsing, although there has been research done on both (McDonald and Pereira, 2006; Sagae and Tsujii, 2008; Eisner and Smith, 2005). The combination of non-projectivity, multi-headedness and disconnected sub-graphs in a single dataset, however, poses a challenge for dependency parsing. In addition to performing evaluation in batch mode over complete threads, we consider the task of “in situ thread classification”, whereby we predict the discourse structure of a thread after each post. T</context>
</contexts>
<marker>Tapanainen, Jarvinen, 1997</marker>
<rawString>Pasi Tapanainen and Timo Jarvinen. 1997. A nonprojective dependency parser. In Proceedings of the Fifth Conference on Applied Natural Language Processing, pages 64–71, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nayer Wanas</author>
<author>Motaz El-Saban</author>
<author>Heba Ashour</author>
<author>Waleed Ammar</author>
</authors>
<title>Automatic scoring of online discussion posts.</title>
<date>2008</date>
<booktitle>In Proceeding of the 2nd ACM workshop on Information credibility on the web (WICOW ’08),</booktitle>
<pages>19--26</pages>
<location>Napa Valley, USA.</location>
<contexts>
<context position="11032" citStr="Wanas et al., 2008" startWordPosition="1762" endWordPosition="1765">thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer and Gurevych, 2007; Wanas et al., 2008; Lui and Baldwin, 2009), and post descriptiveness in particular domains (e.g. medical forums: Leaman et al. (2010)). It has been demonstrated (Wanas et al., 2008; Lui and Baldwin, 2009) that thread discourse structure can significantly improve the classification accuracy for postlevel tasks. Initiation–response pairs (e.g. question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge bases for Community Question Answering (cQA) services such as Yahoo! Answers. While initiation– response pair i</context>
</contexts>
<marker>Wanas, El-Saban, Ashour, Ammar, 2008</marker>
<rawString>Nayer Wanas, Motaz El-Saban, Heba Ashour, and Waleed Ammar. 2008. Automatic scoring of online discussion posts. In Proceeding of the 2nd ACM workshop on Information credibility on the web (WICOW ’08), pages 19–26, Napa Valley, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Chia Wang</author>
<author>Carolyn P Ros´e</author>
</authors>
<title>Making conversational structure explicit: identification of initiation-response pairs within online discussions.</title>
<date>2010</date>
<booktitle>In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT</booktitle>
<pages>673--676</pages>
<marker>Wang, Ros´e, 2010</marker>
<rawString>Yi-Chia Wang and Carolyn P. Ros´e. 2010. Making conversational structure explicit: identification of initiation-response pairs within online discussions. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL HLT 2010), pages 673–676.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Chia Wang</author>
<author>Mahesh Joshi</author>
<author>Carolyn Ros´e</author>
</authors>
<title>A feature based approach to leveraging context for classifying newsgroup style discussion segments.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions (ACL</booktitle>
<pages>73--76</pages>
<location>Prague, Czech Republic.</location>
<marker>Wang, Joshi, Ros´e, 2007</marker>
<rawString>Yi-Chia Wang, Mahesh Joshi, and Carolyn Ros´e. 2007. A feature based approach to leveraging context for classifying newsgroup style discussion segments. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions (ACL 2007), pages 73–76, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi-Chia Wang</author>
<author>Mahesh Joshi</author>
<author>William W Cohen</author>
<author>Carolyn Ros´e</author>
</authors>
<title>Recovering implicit thread structure in newsgroup style conversations.</title>
<date>2008</date>
<booktitle>In Proceedings of the Second International Conference on Weblogs and Social Media (ICWSM</booktitle>
<pages>152--160</pages>
<location>Seattle, USA.</location>
<marker>Wang, Joshi, Cohen, Ros´e, 2008</marker>
<rawString>Yi-Chia Wang, Mahesh Joshi, William W. Cohen, and Carolyn Ros´e. 2008. Recovering implicit thread structure in newsgroup style conversations. In Proceedings of the Second International Conference on Weblogs and Social Media (ICWSM 2008), pages 152– 160, Seattle, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Warnke</author>
<author>R Kompe</author>
<author>H Niemann</author>
<author>E N¨oth</author>
</authors>
<title>Integrated dialog act segmentation and classification using prosodic features and language models.</title>
<date>1997</date>
<booktitle>In Proc. Eurospeech,</booktitle>
<volume>1</volume>
<pages>207--210</pages>
<marker>Warnke, Kompe, Niemann, N¨oth, 1997</marker>
<rawString>V. Warnke, R. Kompe, H. Niemann, and E. N¨oth. 1997. Integrated dialog act segmentation and classification using prosodic features and language models. In Proc. Eurospeech, volume 1, pages 207–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Weimer</author>
<author>Iryna Gurevych</author>
</authors>
<title>Predicting the perceived quality of web forum posts.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 International Conference on Recent Advances in Natural Language Processing (RANLP</booktitle>
<pages>643--648</pages>
<location>Borovets, Bulgaria.</location>
<contexts>
<context position="11012" citStr="Weimer and Gurevych, 2007" startWordPosition="1758" endWordPosition="1761">, 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer and Gurevych, 2007; Wanas et al., 2008; Lui and Baldwin, 2009), and post descriptiveness in particular domains (e.g. medical forums: Leaman et al. (2010)). It has been demonstrated (Wanas et al., 2008; Lui and Baldwin, 2009) that thread discourse structure can significantly improve the classification accuracy for postlevel tasks. Initiation–response pairs (e.g. question–answer, assessment–agreement, and blame–denial) from online forums have the potential to enhance thread summarisation or automatically generate knowledge bases for Community Question Answering (cQA) services such as Yahoo! Answers. While initiat</context>
</contexts>
<marker>Weimer, Gurevych, 2007</marker>
<rawString>Markus Weimer and Iryna Gurevych. 2007. Predicting the perceived quality of web forum posts. In Proceedings of the 2007 International Conference on Recent Advances in Natural Language Processing (RANLP 2007), pages 643–648, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Markus Weimer</author>
<author>Iryna Gurevych</author>
<author>Max M¨uhlh¨auser</author>
</authors>
<title>Automatically assessing the post quality in online discussions on software.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the ACL: Interactive Poster and Demonstration Sessions,</booktitle>
<pages>125--128</pages>
<location>Prague, Czech Republic.</location>
<marker>Weimer, Gurevych, M¨uhlh¨auser, 2007</marker>
<rawString>Markus Weimer, Iryna Gurevych, and Max M¨uhlh¨auser. 2007. Automatically assessing the post quality in online discussions on software. In Proceedings of the 45th Annual Meeting of the ACL: Interactive Poster and Demonstration Sessions, pages 125–128, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Armin Weinberger</author>
<author>Frank Fischer</author>
</authors>
<title>A framework to analyze argumentative knowledge construction in computer-supported collaborative learning.</title>
<date>2006</date>
<journal>Computers &amp; Education,</journal>
<pages>46--71</pages>
<contexts>
<context position="8394" citStr="Weinberger and Fischer, 2006" startWordPosition="1362" endWordPosition="1365">ox that asks the user to enter their ID, and then allows them to press go. It will then redirect to the page ... 2+Answer-Answer User A Post 1 1+Answer-Answer User B Post 2 Re: html input code Part 1: create a form with a text field. See ... Part 2: give it a Javascript action 3+Question-Add Thank You! Thanks a lot for that ... I have Microsoft Visual Studio 6, what program should I do this in? Lastly, how do I actually include this in my site? ... User A Post 4 User D Post 5 A little more help ... You would simply do it this way: ... You could also just ... An example of this is ... 14 2004; Weinberger and Fischer, 2006; Wang et al., 2007; Fortuna et al., 2007; Kim et al., 2010b). For a more complete review of models for discourse disentanglement and dialogue act tagging, see Kim et al. (2010b). Joint classification has been applied in a number of different contexts, based on the intuition that it should be possible to harness interactions between different sub-tasks to the mutual benefit of both. Warnke et al. (1997) jointly performed segmentation and dialogue act classification over a German spontaneous speech corpus. In their approach, the predictions of a multi-layer perceptron classifier on dialogue act</context>
</contexts>
<marker>Weinberger, Fischer, 2006</marker>
<rawString>Armin Weinberger and Frank Fischer. 2006. A framework to analyze argumentative knowledge construction in computer-supported collaborative learning. Computers &amp; Education, 46:71–95, January.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Florian Wolf</author>
<author>Edward Gibson</author>
</authors>
<title>Representing discourse coherence: A corpus-based study.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>2</issue>
<contexts>
<context position="6695" citStr="Wolf and Gibson, 2005" startWordPosition="1055" endWordPosition="1058">n both cases, however, we tackled only a single task, either link classification (optionally given dialogue act tags) or dialogue act classification, but never the two together. In this paper, we take the obvious step of exploring joint classification of post link and dialogue act tags, to generate full thread discourse structures. Discourse disentanglement (i.e. link classification) and dialogue act tagging have been studied largely as independent tasks. Discourse disentanglement is the task of dividing a conversation thread (Elsner and Charniak, 2008; Lemon et al., 2002) or document thread (Wolf and Gibson, 2005) into a set of distinct sub-discourses. The disentangled discourse is sometimes assumed to take the form of a tree structure (Grosz and Sidner, 1986; Lemon et al., 2002; Seo et al., 2009), an acyclic graph structure (Ros´e et al., 1995; Schuth et al., 2007; Elsner and Charniak, 2008; Wang et al., 2008; Lin et al., 2009), or a more general cyclic chain graph structure (Wolf and Gibson, 2005). Dialogue acts are used to describe the function or role of an utterance in a discourse, and have been applied to the analysis of mediums of communication including conversational speech (Stolcke et al., 20</context>
</contexts>
<marker>Wolf, Gibson, 2005</marker>
<rawString>Florian Wolf and Edward Gibson. 2005. Representing discourse coherence: A corpus-based study. Computational Linguistics, 31(2):249–287.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wensi Xi</author>
<author>Jesper Lind</author>
<author>Eric Brill</author>
</authors>
<title>Learning effective ranking functions for newsgroup search.</title>
<date>2004</date>
<booktitle>In Proceedings of 27th International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2004),</booktitle>
<pages>394--401</pages>
<publisher>Sheffield, UK.</publisher>
<contexts>
<context position="10393" citStr="Xi et al., 2004" startWordPosition="1669" endWordPosition="1672"> tasks. There has been a recent growth in user-level research over forums. Lui and Baldwin (2009) explored a range of user-level features, including replies-to and co-participation graph analysis, for post quality classification. Lui and Baldwin (2010) introduced a novel user classification task where each user is classified against four attributes: clarity, proficiency, positivity and effort. User communication roles in web forums have also been studied (Chan and Hayes, 2010; Chan et al., 2010). Threading information has been shown to enhance retrieval effectiveness for post-level retrieval (Xi et al., 2004; Seo et al., 2009), thread-level retrieval (Seo et al., 2009; Elsas and Carbonell, 2009), sentence-level shallow information extraction (Sondhi et al., 2010), and near-duplicate thread detection (Muthmann et al., 2009). These results suggest that the thread structural representation used in this research, which includes both linking structure and the dialogue act associated with each link, could potentially provide even greater leverage in these retrieval tasks. Another related research area is post-level classification, such as general post quality classification (Weimer et al., 2007; Weimer</context>
</contexts>
<marker>Xi, Lind, Brill, 2004</marker>
<rawString>Wensi Xi, Jesper Lind, and Eric Brill. 2004. Learning effective ranking functions for newsgroup search. In Proceedings of 27th International ACM-SIGIR Conference on Research and Development in Information Retrieval (SIGIR 2004), pages 394–401. Sheffield, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Yeh</author>
</authors>
<title>More accurate tests for the statistical significance of result differences.</title>
<date>2000</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING</booktitle>
<pages>947--953</pages>
<location>Saarbr¨ucken, Germany.</location>
<contexts>
<context position="22724" citStr="Yeh, 2000" startWordPosition="3597" endWordPosition="3598">and are thus not included in the results presented in this paper. 5 Classification Methodology All our experiments were carried out based on stratified 10-fold cross-validation, stratifying at the thread level to ensure that all posts from a given thread occur in a single fold. The results are primarily evaluated using post-level micro-averaged F-score (Fµ: R = 1), and additionally with thread-level Fscore/classification accuracy (i.e. the proportion of threads where all posts have been correctly classified4), where space allows. Statistical significance is tested using randomised estimation (Yeh, 2000) with p &lt; 0.05. Initial experiments showed it is hard for learners to discover which posts have multiple links, largely due to the sparsity of multi-headed posts (which account for less than 5% of the total posts). Therefore, only the the most recent link for 3http://maltparser.org/userguide.html# parsingalg 4Classification accuracy = F-score at the thread-level, as each thread is assigned a single label of correct or incorrect. each multi-headed post was included in training, but evaluation still considers all links. 5.1 Joint classification In our experiments, we test two basic approaches to</context>
</contexts>
<marker>Yeh, 2000</marker>
<rawString>Alexander Yeh. 2000. More accurate tests for the statistical significance of result differences. In Proceedings of the 18th International Conference on Computational Linguistics (COLING 2000), pages 947–953, Saarbr¨ucken, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>