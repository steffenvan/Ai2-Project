<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004000">
<title confidence="0.980269">
Temporal Classification of Text and Automatic Document Dating
</title>
<author confidence="0.996807">
Angelo Dalli
</author>
<affiliation confidence="0.999306">
University of Sheffield
</affiliation>
<address confidence="0.8649465">
211, Portobello Street
Sheffield, S1 4DP, UK
</address>
<email confidence="0.996887">
angelo@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.998587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99992625">
Temporal information is presently under-
utilised for document and text processing
purposes. This work presents an unsuper-
vised method of extracting periodicity in-
formation from text, enabling time series
creation and filtering to be used in the
creation of sophisticated language models
that can discern between repetitive trends
and non-repetitive writing pat-terns. The
algorithm performs in O(n log n) time for
input of length n. The temporal language
model is used to create rules based on
temporal-word associations inferred from
the time series. The rules are used to
automatically guess at likely document
creation dates, based on the assumption
that natural languages have unique signa-
tures of changing word distributions over
time. Experimental results on news items
spanning a nine year period show that the
proposed method and algorithms are ac-
curate in discovering periodicity patterns
and in dating documents automatically
solely from their content.
</bodyText>
<sectionHeader confidence="0.99963" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999754125">
Various features have been used to classify and
predict the characteristics of text and related text
documents, ranging from simple word count mod-
els to sophisticated clustering and Bayesian models
that can handle both linear and non-linear classes.
The general goal of most classification research is
to assign objects from a pre-defined domain (such
as words or entire documents) to two or more
classes/categories. Current and past research has
largely focused on solving problems like tagging,
sense disambiguation, sentiment classification,
author and language identification and topic classi-
fication. We introduce an unsupervised method
that classifies text and documents according to
their predicted time of writing/creation. The
method uses a sophisticated temporal language
model to predict likely creation dates for a docu-
ment, hence dating it automatically. This short pa-
per presents some background information about
existing techniques and the implemented system,
followed by a brief explanation of the classifica-
tion and dating method, and finally concluding
with results and evaluation performed on the LDC
GigaWord English Corpus (LDC, 2003).
</bodyText>
<sectionHeader confidence="0.987271" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.998849571428572">
Temporal information is presently under-utilised
for document and text processing purposes. Past
and ongoing research work has largely focused on
the identification and tagging of temporal expres-
sions, with the creation of tagging methodologies
such as TimeML/TIMEX (Gaizauskas and Setzer,
2002; Pustejovsky et al., 2003; Ferro et al., 2004),
TDRL (Aramburu and Berlanga, 1998) and associ-
ated evaluations such as the ACE TERN competi-
tion (Sundheim et al. 2004).
Temporal analysis has also been applied in
Question-Answering systems (Pustejovsky et al.,
2004; Schilder and Habel, 2003; Prager et al.,
2003), email classification (Kiritchenko et al.
</bodyText>
<page confidence="0.992529">
29
</page>
<note confidence="0.932485">
Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 29–32,
New York, June 2006. c�2006 Association for Computational Linguistics
</note>
<figure confidence="0.974108302631579">
500
400
300
200
600
10000
100
9000
8000
5000
4000
3000
2000
7000
6000
1000
0
237
46
24
12
17
10
19
307
22
3
16
18
13
35
33
31
14
17
5
6
0
1 164 327 490 653 816 979 1142 1305 1468 1631 1794 1957
600
500
400
300
200
100
0
237
46
24
12
17
10
19
307
22
3
16
18
13
35
33
31
14
17
5
6
4000
3500
3000
2500
2000
1500
1000
500
0
1 161 321 481 641 801 961 1121 1281 1441 1601 1761 1921 2081
</figure>
<figureCaption confidence="0.947312333333333">
Figure 1 Effects of applying the temporal periodical algorithm on time series for &amp;quot;January&amp;quot; (top) and &amp;quot;the&amp;quot; (bottom)
with original series on the left and the remaining time series component after filtering on the right. Y-axis shows
frequency count and X-axis shows the day number (time).
</figureCaption>
<bodyText confidence="0.9998995">
2004), aiding the precision of Information Re-
trieval results (Berlanga et al., 2001), document
summarisation (Mani and Wilson, 2000), time
stamping of event clauses (Filatova and Hovy,
2001), temporal ordering of events (Mani et al.,
2003) and temporal reasoning from text (Boguraev
and Ando, 2005; Moldovan et al., 2005). There is
also a large body of work on time series analysis
and temporal logic in Physics, Economics and
Mathematics, providing important techniques and
general background information. In particular, this
work uses techniques adapted from Seasonal Auto-
Regressive Integrated Moving Average models
(SARIMA). SARIMA models are a class of sea-
sonal, non-stationary temporal models based on the
ARIMA process (defined as a non-stationary ex-
tension of the stationary ARMA model). Non-
stationary ARIMA processes are defined by:
</bodyText>
<equation confidence="0.545478">
( ) ( ) , ( ) ,
1−B dO B X =B B Z (1)
</equation>
<bodyText confidence="0.999664909090909">
where d is non-negative integer, and O(X )
B(X ) polynomials of degrees p and q respec-
tively. The exact parameters for each process (one
process per word) are determined automatically by
the system. A discussion of the general SARIMA
model is beyond the scope of this paper (details
can be found in Mathematics &amp; Physics publica-
tions). The NLP application of temporal classifica-
tion and prediction to guess at likely document and
text creation dates is a novel application that has
not been considered much before, if at all.
</bodyText>
<sectionHeader confidence="0.994427" genericHeader="method">
3 Temporal Periodicity Analysis
</sectionHeader>
<bodyText confidence="0.9996583125">
We have created a high-performance system that
decomposes time series into two parts: a periodic
component that repeats itself in a predictable man-
ner, and a non-periodic component that is left after
the periodic component has been filtered out from
the original time series. Figure 1 shows an example
of the filtering results on time-series of the words
“January” and “the”. The time series are based on
training documents selected at random from the
GigaWord English corpus. 10% of all the docu-
ments in the corpus were used as training docu-
ments, with the rest being available for evaluation
and testing. A total of 395,944 time series spanning
9 years were calculated from the GigaWord cor-
pus. Figure 2 presents pseudo-code for the time
series decomposition algorithm:
</bodyText>
<page confidence="0.991469">
30
</page>
<listItem confidence="0.898407578947368">
1. Find min/max/mean and standard devia-
tion of time series
2. Start with a pre-defined maximum win-
dow size (presently set to 366 days)
3. While window size bigger than 1 repeat
steps a. to d. below:
a. Look at current value in time
series (starting first value)
b. Do values at positions current,
current + window size, current +
2 x window size, etc. vary by
less than 1/2 standard deviation?
c. If yes, mark current
value/window size pair as being
possible decomposition match
d. Look at next value in time se-
ries until the end is reached
e. Decrease window size by one
4. Select the minimum number of decompo-
</listItem>
<bodyText confidence="0.5457575">
sition matches that cover the entire
time series using a greedy algorithm
</bodyText>
<figureCaption confidence="0.981229">
Figure 2 Time Series Decomposition Algorithm
</figureCaption>
<bodyText confidence="0.999990739130435">
The time series decomposition algorithm was
applied to the 395,944 time series, taking an aver-
age of 419ms per series. The algorithm runs in O(n
log n) time for a time series of length n.
The periodic component of the time series is
then analysed to extract temporal association rules
between words and different “seasons”, including
Day of Week, Week Number, Month Number,
Quarter, and Year. The procedure of determining if
a word, for example, is predominantly peaking on
a weekly basis, is to apply a sliding window of size
7 (in the case of weekly periods) and determining
if the periodic time series always spikes within this
window. Figure 3 shows the frequency distribution
of the periodic time series component of the days
of week names (“Monday”, “Tuesday”, etc.) Note
that the frequency counts peak exactly on that par-
ticular day of the week. For example, the word
“Monday” is automatically associated with Day 1,
and “April” associated with Month 4. The creation
of temporal association rules generalises inferences
obtained from the periodic data. Each association
rule has the following information:
</bodyText>
<listItem confidence="0.999919">
• Word ID
• Period Type (Week, Month, etc.)
• Period Number and Score Matrix
</listItem>
<bodyText confidence="0.99982775">
The period number and score matrix represent a
probability density function that shows the likeli-
hood of a word appearing on a particular period
number. For example, the score matrix for “Janu-
ary” will have a high score for period 1 (and period
type set to Monthly). Figure 4 shows some exam-
ples of extracted association rules. The PDF scores
are shown in Figure 4 as they are stored internally
(as multiples of the standard deviation of that time
series) and are automatically normalised during the
classification process at runtime. Rule generalisa-
tion is not possible in such a straightforward man-
ner for the non-periodic data. The use of non-
periodic data to optimise the results of the temporal
classification and automatic dating system is not
covered in this paper.
</bodyText>
<sectionHeader confidence="0.924329" genericHeader="method">
4 Temporal Classification and Dating
</sectionHeader>
<bodyText confidence="0.993978461538462">
The periodic temporal association rules are utilised
to automatically guess at the creation date of
documents automatically. Documents are input
into the system and the probability density func-
tions for each word are weighted and added up.
Each PDF is weighted according to the inverse
document frequency (IDF) of each associated
word. Periods that obtain high score are then
ranked for each type of period and two guesses per
period type are obtained for each document. Ten
guesses in total are thus obtained for Day of Week,
Week Number, Month Number, Quarter, and Year
(5 period types x 2 guesses each).
</bodyText>
<figure confidence="0.9709055">
Su M T W Th F S
0 22660 10540 7557 772 2130 3264 11672
1 12461 37522 10335 6599 1649 3222 3414
2 3394 18289 38320 9352 7300 2543 2261
3 2668 4119 18120 36933 10427 5762 2147
4 2052 2602 3910 17492 36094 9098 5667
5 5742 1889 2481 2568 17002 32597 7849
6 7994 7072 1924 1428 3050 14087 21468
8138 11719 11806 10734 11093 10081 7782
7357 12711 12974 12933 12308 10746 6930
</figure>
<figureCaption confidence="0.93441">
Figure 3 Days of Week Temporal Frequency Distribu-
tion for extracted Periodic Component
displayed in a Weekly Period Type format
</figureCaption>
<table confidence="0.9866469">
January
Week 1 2 3 4 5
Score 1.48 2.20 3.60 3.43 3.52
Month 1 Score 2.95
Quarter 1 Score 1.50
Christmas
Week 2 5 36 42 44
Score 1.32 0.73 1.60 0.83 1.32
Av
St
</table>
<page confidence="0.723959">
31
</page>
<table confidence="0.814376">
Week 47 49 50 51 52
Score 1.32 2.20 2.52 2.13 1.16
Month 1 9 10 11 12
Score 1.10 0.75 1.63 1.73 1.98
Quarter 4 Score 1.07
Figure 4 Temporal Classification Rules for Periodic
Components of &amp;quot;January&amp;quot; and &amp;quot;Christmas&amp;quot;
</table>
<sectionHeader confidence="0.95239" genericHeader="conclusions">
5 Evaluation, Results and Conclusion
</sectionHeader>
<bodyText confidence="0.985464833333333">
The system was trained using 67,000 news items
selected randomly from the GigaWord corpus. The
evaluation took place on 678,924 news items ex-
tracted from items marked as being of type “story”
or “multi”. Table 1 presents a summary of results.
Processing took around 2.33ms per item.
</bodyText>
<table confidence="0.999701785714286">
Type Correct Incorrect Avg.
Error
DOW 218,899 460,025 1.89
(32.24%) (67.75%) days
Week 24,660 654,264 14.37
(3.53%) (96.36%) wks
Month 122,777 556,147 2.57
(18.08%) (81.91%) mths
Quarter 337,384 341,540 1.48
(49.69%) (50.30%) qts
Year 596,009 82,915 1.74
(87.78%) (12.21%) yrs
Combined 422,358 256,566 210
(62.21%) (37.79%) days
</table>
<tableCaption confidence="0.999612">
Table 1 Evaluation Results Summary
</tableCaption>
<bodyText confidence="0.999963260869565">
The actual date was extracted from each news item
in the GigaWord corpus and the day of week
(DOW), week number and quarter calculated from
the actual date. Average errors for each type of
classifier were calculated automatically. For results
to be considered correct, the system had to have
the predicted value ranked in the first position
equal to the actual value (of the type of period).
The system results show that reasonable accurate
dates can be guessed at the quarterly and yearly
levels. The weekly classifier had the worst per-
formance of all classifiers. The combined classifier
uses a simple weighted formula to guess the final
document date using input from all classifiers. The
weights for the combined classifier have been set
on the basis of this evaluation. The temporal classi-
fication and analysis system presented in this paper
can handle any Indo-European language in its pre-
sent form. Further work is being carried out to ex-
tend the system to Chinese and Arabic. Current
research is aiming at improving the accuracy of the
classifier by using the non-periodic components
and improving the combined classification method.
</bodyText>
<sectionHeader confidence="0.998478" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999577875">
Aramburu, M. Berlanga, R. 1998. A Retrieval Language
for Historical Documents. LNCS, 1460, pp. 216-225.
Berlanga, R. Perez, J. Aramburu, M. Llido, D. 2001.
Techniques and Tools for the Temporal Analysis of
Retrieved Information. LNCS, 2113, pp. 72-81.
Boguraev, B. Ando, R.K. 2005. TimeML-Compliant
Text Analysis for Temporal Reasoning. IJCAI-2005.
Ferro, L. Gerber, L. Mani, I. Sundheim, B. Wilson, G.
2004. TIDES Standard for the Annotation of Tempo-
ral Expressions. The MITRE Corporation.
Filatova, E. Hovy, E. 2001. Assigning time-stamps to
event-clauses. Proc. EACL 2001, Toulouse, France.
Gaizauskas, R. Setzer, A. 2002. Annotation Standards
for Temporal Information in NL. Proc. LREC 2002.
Kiritchenko, S. Matwin, S. Abu-Hakima, S. 2004. Email
Classification with Temporal Features. Proc. IIPWM
2004, Zakopane, Poland. pp. 523-534.
Linguistic Data Consortium (LDC). 2003. English Gi-
gaword Corpus. David Graff, ed. LDC2003T05.
Mani, I. Wilson, G. 2000. Robust temporal processing
of news. Proc. ACL 2000, Hong Kong.
Mani, I. Schiffman, B. Zhang, J. 2003. Inferring tempo-
ral ordering of events in news. HLT-NAACL 2003.
Moldovan, D. Clark, C. Harabagiu, S. 2005. Temporal
Context Representation and Reasoning. IJCAI-2005.
Prager, J. Chu-Carroll, J. Brown, E. Czuba, C. 2003.
Question Answering using predictive annotation.
Pustejovsky, J. Castano, R. Ingria, R. Sauri, R. Gai-
zauskas, R. Setzer, A. Katz, G. 2003. TimeML: Ro-
bust Specification of event and temporal expressions
in text. IWCS-5.
Pustejovsky, J. Sauri, R. Castano, J. Radev, D. Gai-
zauskas, R. Setzer, A. Sundheim, B. Katz, G. 2004.
“Representing Temporal and Event Knowledge for
QA Systems”. New Directions in QA, MIT Press.
Schilder, F. Habel, C. 2003. Temporal Information Ex-
traction for Temporal QA. AAAI NDQA, pp. 35-44.
Sundheim, B. Gerber, L. Ferro, L. Mani, I. Wilson, G.
2004. Time Expression Recognition and Normaliza-
tion (TERN). http://timex2.mitre.org.
</reference>
<page confidence="0.999291">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.962004">
<title confidence="0.999864">Temporal Classification of Text and Automatic Document Dating</title>
<author confidence="0.999803">Angelo Dalli</author>
<affiliation confidence="0.999991">University of Sheffield</affiliation>
<address confidence="0.9992105">211, Portobello Street Sheffield, S1 4DP, UK</address>
<email confidence="0.99571">angelo@dcs.shef.ac.uk</email>
<abstract confidence="0.99865496">Temporal information is presently underutilised for document and text processing purposes. This work presents an unsupervised method of extracting periodicity information from text, enabling time series creation and filtering to be used in the creation of sophisticated language models that can discern between repetitive trends and non-repetitive writing pat-terns. The algorithm performs in O(n log n) time for input of length n. The temporal language model is used to create rules based on temporal-word associations inferred from the time series. The rules are used to automatically guess at likely document creation dates, based on the assumption that natural languages have unique signatures of changing word distributions over time. Experimental results on news items spanning a nine year period show that the proposed method and algorithms are accurate in discovering periodicity patterns and in dating documents automatically solely from their content.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Berlanga Aramburu</author>
<author>R</author>
</authors>
<title>A Retrieval Language for Historical Documents.</title>
<date>1998</date>
<volume>1460</volume>
<pages>216--225</pages>
<marker>Aramburu, R, 1998</marker>
<rawString>Aramburu, M. Berlanga, R. 1998. A Retrieval Language for Historical Documents. LNCS, 1460, pp. 216-225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Perez Berlanga</author>
<author>J Aramburu</author>
<author>M Llido</author>
<author>D</author>
</authors>
<title>Techniques and Tools for the Temporal Analysis of Retrieved Information.</title>
<date>2001</date>
<volume>2113</volume>
<pages>72--81</pages>
<contexts>
<context position="3909" citStr="Berlanga et al., 2001" startWordPosition="618" endWordPosition="621">5 6 0 1 164 327 490 653 816 979 1142 1305 1468 1631 1794 1957 600 500 400 300 200 100 0 237 46 24 12 17 10 19 307 22 3 16 18 13 35 33 31 14 17 5 6 4000 3500 3000 2500 2000 1500 1000 500 0 1 161 321 481 641 801 961 1121 1281 1441 1601 1761 1921 2081 Figure 1 Effects of applying the temporal periodical algorithm on time series for &amp;quot;January&amp;quot; (top) and &amp;quot;the&amp;quot; (bottom) with original series on the left and the remaining time series component after filtering on the right. Y-axis shows frequency count and X-axis shows the day number (time). 2004), aiding the precision of Information Retrieval results (Berlanga et al., 2001), document summarisation (Mani and Wilson, 2000), time stamping of event clauses (Filatova and Hovy, 2001), temporal ordering of events (Mani et al., 2003) and temporal reasoning from text (Boguraev and Ando, 2005; Moldovan et al., 2005). There is also a large body of work on time series analysis and temporal logic in Physics, Economics and Mathematics, providing important techniques and general background information. In particular, this work uses techniques adapted from Seasonal AutoRegressive Integrated Moving Average models (SARIMA). SARIMA models are a class of seasonal, non-stationary te</context>
</contexts>
<marker>Berlanga, Aramburu, Llido, D, 2001</marker>
<rawString>Berlanga, R. Perez, J. Aramburu, M. Llido, D. 2001. Techniques and Tools for the Temporal Analysis of Retrieved Information. LNCS, 2113, pp. 72-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Ando Boguraev</author>
<author>R K</author>
</authors>
<title>TimeML-Compliant Text Analysis for Temporal Reasoning.</title>
<date>2005</date>
<marker>Boguraev, K, 2005</marker>
<rawString>Boguraev, B. Ando, R.K. 2005. TimeML-Compliant Text Analysis for Temporal Reasoning. IJCAI-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Gerber Ferro</author>
<author>L Mani</author>
<author>I Sundheim</author>
<author>B Wilson</author>
<author>G</author>
</authors>
<title>TIDES Standard for the Annotation of Temporal Expressions.</title>
<date>2004</date>
<publisher>The MITRE Corporation.</publisher>
<contexts>
<context position="2664" citStr="Ferro et al., 2004" startWordPosition="385" endWordPosition="388"> some background information about existing techniques and the implemented system, followed by a brief explanation of the classification and dating method, and finally concluding with results and evaluation performed on the LDC GigaWord English Corpus (LDC, 2003). 2 Background Temporal information is presently under-utilised for document and text processing purposes. Past and ongoing research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as TimeML/TIMEX (Gaizauskas and Setzer, 2002; Pustejovsky et al., 2003; Ferro et al., 2004), TDRL (Aramburu and Berlanga, 1998) and associated evaluations such as the ACE TERN competition (Sundheim et al. 2004). Temporal analysis has also been applied in Question-Answering systems (Pustejovsky et al., 2004; Schilder and Habel, 2003; Prager et al., 2003), email classification (Kiritchenko et al. 29 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 29–32, New York, June 2006. c�2006 Association for Computational Linguistics 500 400 300 200 600 10000 100 9000 8000 5000 4000 3000 2000 7000 6000 1000 0 237 46 24 12 17 10 19 307 22 3 1</context>
</contexts>
<marker>Ferro, Mani, Sundheim, Wilson, G, 2004</marker>
<rawString>Ferro, L. Gerber, L. Mani, I. Sundheim, B. Wilson, G. 2004. TIDES Standard for the Annotation of Temporal Expressions. The MITRE Corporation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy Filatova</author>
<author>E</author>
</authors>
<title>Assigning time-stamps to event-clauses.</title>
<date>2001</date>
<booktitle>Proc. EACL 2001,</booktitle>
<location>Toulouse, France.</location>
<marker>Filatova, E, 2001</marker>
<rawString>Filatova, E. Hovy, E. 2001. Assigning time-stamps to event-clauses. Proc. EACL 2001, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Setzer Gaizauskas</author>
<author>A</author>
</authors>
<title>Annotation Standards for Temporal Information in NL.</title>
<date>2002</date>
<booktitle>Proc. LREC</booktitle>
<marker>Gaizauskas, A, 2002</marker>
<rawString>Gaizauskas, R. Setzer, A. 2002. Annotation Standards for Temporal Information in NL. Proc. LREC 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Matwin Kiritchenko</author>
<author>S Abu-Hakima</author>
<author>S</author>
</authors>
<title>Email Classification with Temporal Features.</title>
<date>2004</date>
<booktitle>Proc. IIPWM 2004,</booktitle>
<pages>523--534</pages>
<location>Zakopane,</location>
<marker>Kiritchenko, Abu-Hakima, S, 2004</marker>
<rawString>Kiritchenko, S. Matwin, S. Abu-Hakima, S. 2004. Email Classification with Temporal Features. Proc. IIPWM 2004, Zakopane, Poland. pp. 523-534.</rawString>
</citation>
<citation valid="false">
<booktitle>Linguistic Data Consortium (LDC). 2003. English Gigaword</booktitle>
<pages>2003--05</pages>
<editor>Corpus. David Graff, ed.</editor>
<marker></marker>
<rawString>Linguistic Data Consortium (LDC). 2003. English Gigaword Corpus. David Graff, ed. LDC2003T05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Wilson Mani</author>
<author>G</author>
</authors>
<title>Robust temporal processing of news.</title>
<date>2000</date>
<booktitle>Proc. ACL</booktitle>
<location>Hong Kong.</location>
<marker>Mani, G, 2000</marker>
<rawString>Mani, I. Wilson, G. 2000. Robust temporal processing of news. Proc. ACL 2000, Hong Kong.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Schiffman Mani</author>
<author>B Zhang</author>
<author>J</author>
</authors>
<title>Inferring temporal ordering of events in news. HLT-NAACL</title>
<date>2003</date>
<contexts>
<context position="4064" citStr="Mani et al., 2003" startWordPosition="641" endWordPosition="644">00 2500 2000 1500 1000 500 0 1 161 321 481 641 801 961 1121 1281 1441 1601 1761 1921 2081 Figure 1 Effects of applying the temporal periodical algorithm on time series for &amp;quot;January&amp;quot; (top) and &amp;quot;the&amp;quot; (bottom) with original series on the left and the remaining time series component after filtering on the right. Y-axis shows frequency count and X-axis shows the day number (time). 2004), aiding the precision of Information Retrieval results (Berlanga et al., 2001), document summarisation (Mani and Wilson, 2000), time stamping of event clauses (Filatova and Hovy, 2001), temporal ordering of events (Mani et al., 2003) and temporal reasoning from text (Boguraev and Ando, 2005; Moldovan et al., 2005). There is also a large body of work on time series analysis and temporal logic in Physics, Economics and Mathematics, providing important techniques and general background information. In particular, this work uses techniques adapted from Seasonal AutoRegressive Integrated Moving Average models (SARIMA). SARIMA models are a class of seasonal, non-stationary temporal models based on the ARIMA process (defined as a non-stationary extension of the stationary ARMA model). Nonstationary ARIMA processes are defined by</context>
</contexts>
<marker>Mani, Zhang, J, 2003</marker>
<rawString>Mani, I. Schiffman, B. Zhang, J. 2003. Inferring temporal ordering of events in news. HLT-NAACL 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Clark Moldovan</author>
<author>C Harabagiu</author>
<author>S</author>
</authors>
<title>Temporal Context Representation and Reasoning.</title>
<date>2005</date>
<contexts>
<context position="4146" citStr="Moldovan et al., 2005" startWordPosition="654" endWordPosition="657">1 1921 2081 Figure 1 Effects of applying the temporal periodical algorithm on time series for &amp;quot;January&amp;quot; (top) and &amp;quot;the&amp;quot; (bottom) with original series on the left and the remaining time series component after filtering on the right. Y-axis shows frequency count and X-axis shows the day number (time). 2004), aiding the precision of Information Retrieval results (Berlanga et al., 2001), document summarisation (Mani and Wilson, 2000), time stamping of event clauses (Filatova and Hovy, 2001), temporal ordering of events (Mani et al., 2003) and temporal reasoning from text (Boguraev and Ando, 2005; Moldovan et al., 2005). There is also a large body of work on time series analysis and temporal logic in Physics, Economics and Mathematics, providing important techniques and general background information. In particular, this work uses techniques adapted from Seasonal AutoRegressive Integrated Moving Average models (SARIMA). SARIMA models are a class of seasonal, non-stationary temporal models based on the ARIMA process (defined as a non-stationary extension of the stationary ARMA model). Nonstationary ARIMA processes are defined by: ( ) ( ) , ( ) , 1−B dO B X =B B Z (1) where d is non-negative integer, and O(X )</context>
</contexts>
<marker>Moldovan, Harabagiu, S, 2005</marker>
<rawString>Moldovan, D. Clark, C. Harabagiu, S. 2005. Temporal Context Representation and Reasoning. IJCAI-2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Chu-Carroll Prager</author>
<author>J Brown</author>
<author>E Czuba</author>
<author>C</author>
</authors>
<title>Question Answering using predictive annotation.</title>
<date>2003</date>
<contexts>
<context position="2928" citStr="Prager et al., 2003" startWordPosition="426" endWordPosition="429">. 2 Background Temporal information is presently under-utilised for document and text processing purposes. Past and ongoing research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as TimeML/TIMEX (Gaizauskas and Setzer, 2002; Pustejovsky et al., 2003; Ferro et al., 2004), TDRL (Aramburu and Berlanga, 1998) and associated evaluations such as the ACE TERN competition (Sundheim et al. 2004). Temporal analysis has also been applied in Question-Answering systems (Pustejovsky et al., 2004; Schilder and Habel, 2003; Prager et al., 2003), email classification (Kiritchenko et al. 29 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 29–32, New York, June 2006. c�2006 Association for Computational Linguistics 500 400 300 200 600 10000 100 9000 8000 5000 4000 3000 2000 7000 6000 1000 0 237 46 24 12 17 10 19 307 22 3 16 18 13 35 33 31 14 17 5 6 0 1 164 327 490 653 816 979 1142 1305 1468 1631 1794 1957 600 500 400 300 200 100 0 237 46 24 12 17 10 19 307 22 3 16 18 13 35 33 31 14 17 5 6 4000 3500 3000 2500 2000 1500 1000 500 0 1 161 321 481 641 801 961 1121 1281 1441 1601 1761 19</context>
</contexts>
<marker>Prager, Brown, Czuba, C, 2003</marker>
<rawString>Prager, J. Chu-Carroll, J. Brown, E. Czuba, C. 2003. Question Answering using predictive annotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Castano Pustejovsky</author>
<author>R Ingria</author>
<author>R Sauri</author>
<author>R Gaizauskas</author>
<author>R Setzer</author>
<author>A Katz</author>
<author>G</author>
</authors>
<title>TimeML: Robust Specification of event and temporal expressions in text.</title>
<date>2003</date>
<pages>5</pages>
<contexts>
<context position="2643" citStr="Pustejovsky et al., 2003" startWordPosition="381" endWordPosition="384"> This short paper presents some background information about existing techniques and the implemented system, followed by a brief explanation of the classification and dating method, and finally concluding with results and evaluation performed on the LDC GigaWord English Corpus (LDC, 2003). 2 Background Temporal information is presently under-utilised for document and text processing purposes. Past and ongoing research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as TimeML/TIMEX (Gaizauskas and Setzer, 2002; Pustejovsky et al., 2003; Ferro et al., 2004), TDRL (Aramburu and Berlanga, 1998) and associated evaluations such as the ACE TERN competition (Sundheim et al. 2004). Temporal analysis has also been applied in Question-Answering systems (Pustejovsky et al., 2004; Schilder and Habel, 2003; Prager et al., 2003), email classification (Kiritchenko et al. 29 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 29–32, New York, June 2006. c�2006 Association for Computational Linguistics 500 400 300 200 600 10000 100 9000 8000 5000 4000 3000 2000 7000 6000 1000 0 237 46 24 1</context>
</contexts>
<marker>Pustejovsky, Ingria, Sauri, Gaizauskas, Setzer, Katz, G, 2003</marker>
<rawString>Pustejovsky, J. Castano, R. Ingria, R. Sauri, R. Gaizauskas, R. Setzer, A. Katz, G. 2003. TimeML: Robust Specification of event and temporal expressions in text. IWCS-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Sauri Pustejovsky</author>
<author>R Castano</author>
<author>J Radev</author>
<author>D Gaizauskas</author>
<author>R Setzer</author>
<author>A Sundheim</author>
<author>B Katz</author>
<author>G</author>
</authors>
<title>Representing Temporal and Event Knowledge for QA Systems”. New Directions in QA,</title>
<date>2004</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2880" citStr="Pustejovsky et al., 2004" startWordPosition="418" endWordPosition="421">ormed on the LDC GigaWord English Corpus (LDC, 2003). 2 Background Temporal information is presently under-utilised for document and text processing purposes. Past and ongoing research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as TimeML/TIMEX (Gaizauskas and Setzer, 2002; Pustejovsky et al., 2003; Ferro et al., 2004), TDRL (Aramburu and Berlanga, 1998) and associated evaluations such as the ACE TERN competition (Sundheim et al. 2004). Temporal analysis has also been applied in Question-Answering systems (Pustejovsky et al., 2004; Schilder and Habel, 2003; Prager et al., 2003), email classification (Kiritchenko et al. 29 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 29–32, New York, June 2006. c�2006 Association for Computational Linguistics 500 400 300 200 600 10000 100 9000 8000 5000 4000 3000 2000 7000 6000 1000 0 237 46 24 12 17 10 19 307 22 3 16 18 13 35 33 31 14 17 5 6 0 1 164 327 490 653 816 979 1142 1305 1468 1631 1794 1957 600 500 400 300 200 100 0 237 46 24 12 17 10 19 307 22 3 16 18 13 35 33 31 14 17 5 6 4000 3500 3000 2500 2000 1500 1000 500 0 1 161</context>
</contexts>
<marker>Pustejovsky, Castano, Radev, Gaizauskas, Setzer, Sundheim, Katz, G, 2004</marker>
<rawString>Pustejovsky, J. Sauri, R. Castano, J. Radev, D. Gaizauskas, R. Setzer, A. Sundheim, B. Katz, G. 2004. “Representing Temporal and Event Knowledge for QA Systems”. New Directions in QA, MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Habel Schilder</author>
<author>C</author>
</authors>
<title>Temporal Information Extraction for Temporal QA. AAAI NDQA,</title>
<date>2003</date>
<pages>35--44</pages>
<marker>Schilder, C, 2003</marker>
<rawString>Schilder, F. Habel, C. 2003. Temporal Information Extraction for Temporal QA. AAAI NDQA, pp. 35-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Gerber Sundheim</author>
<author>L Ferro</author>
<author>L Mani</author>
<author>I Wilson</author>
<author>G</author>
</authors>
<title>Time Expression Recognition and Normalization</title>
<date>2004</date>
<contexts>
<context position="2783" citStr="Sundheim et al. 2004" startWordPosition="405" endWordPosition="408"> the classification and dating method, and finally concluding with results and evaluation performed on the LDC GigaWord English Corpus (LDC, 2003). 2 Background Temporal information is presently under-utilised for document and text processing purposes. Past and ongoing research work has largely focused on the identification and tagging of temporal expressions, with the creation of tagging methodologies such as TimeML/TIMEX (Gaizauskas and Setzer, 2002; Pustejovsky et al., 2003; Ferro et al., 2004), TDRL (Aramburu and Berlanga, 1998) and associated evaluations such as the ACE TERN competition (Sundheim et al. 2004). Temporal analysis has also been applied in Question-Answering systems (Pustejovsky et al., 2004; Schilder and Habel, 2003; Prager et al., 2003), email classification (Kiritchenko et al. 29 Proceedings of the Human Language Technology Conference of the North American Chapter of the ACL, pages 29–32, New York, June 2006. c�2006 Association for Computational Linguistics 500 400 300 200 600 10000 100 9000 8000 5000 4000 3000 2000 7000 6000 1000 0 237 46 24 12 17 10 19 307 22 3 16 18 13 35 33 31 14 17 5 6 0 1 164 327 490 653 816 979 1142 1305 1468 1631 1794 1957 600 500 400 300 200 100 0 237 46 2</context>
</contexts>
<marker>Sundheim, Ferro, Mani, Wilson, G, 2004</marker>
<rawString>Sundheim, B. Gerber, L. Ferro, L. Mani, I. Wilson, G. 2004. Time Expression Recognition and Normalization (TERN). http://timex2.mitre.org.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>