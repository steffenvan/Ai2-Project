<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000184">
<title confidence="0.9979305">
Are These Documents Written from Different Perspectives? A Test of
Different Perspectives Based On Statistical Distribution Divergence
</title>
<author confidence="0.994858">
Wei-Hao Lin
</author>
<affiliation confidence="0.91524725">
Language Technologies Institute
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213 U.S.A.
</affiliation>
<email confidence="0.997495">
whlin@cs.cmu.edu
</email>
<author confidence="0.995881">
Alexander Hauptmann
</author>
<affiliation confidence="0.9155305">
Language Technologies Institute
School of Computer Science
Carnegie Mellon University
Pittsburgh, PA 15213 U.S.A.
</affiliation>
<email confidence="0.998675">
alex@cs.cmu.edu
</email>
<sectionHeader confidence="0.993921" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999548153846154">
In this paper we investigate how to auto-
matically determine if two document col-
lections are written from different per-
spectives. By perspectives we mean a
point of view, for example, from the per-
spective of Democrats or Republicans. We
propose a test of different perspectives
based on distribution divergence between
the statistical models of two collections.
Experimental results show that the test can
successfully distinguish document collec-
tions of different perspectives from other
types of collections.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999769285714286">
Conflicts arise when two groups of people take
very different perspectives on political, socio-
economical, or cultural issues. For example, here
are the answers that two presidential candidates,
John Kerry and George Bush, gave during the third
presidential debate in 2004 in response to a ques-
tion on abortion:
</bodyText>
<listItem confidence="0.987606666666667">
(1) Kerry: What is an article of faith for me is
not something that I can legislate on some-
body who doesn’t share that article of faith. I
believe that choice is a woman’s choice. It’s
between a woman, God and her doctor. And
that’s why I support that.
(2) Bush: I believe the ideal world is one in
which every child is protected in law and wel-
comed to life. I understand there’s great dif-
</listItem>
<bodyText confidence="0.899252615384615">
ferences on this issue of abortion, but I be-
lieve reasonable people can come together
and put good law in place that will help re-
duce the number of abortions.
After reading the above transcripts some readers
may conclude that one takes a “pro-choice” per-
spective while the other takes a “pro-life” perspec-
tive, the two dominant perspectives in the abortion
controversy.
Perspectives, however, are not always mani-
fested when two pieces of text together are put to-
gether. For example, the following two sentences
are from Reuters newswire:
</bodyText>
<listItem confidence="0.821384777777778">
(3) Gold output in the northeast China province
of Heilongjiang rose 22.7 pct in 1986 from
1985’s level, the New China News Agency
said.
(4) Exco Chairman Richard Lacy told Reuters
the acquisition was being made from Bank
of New York Co Inc, which currently holds
a 50.1 pct, and from RMJ partners who hold
the remainder.
</listItem>
<bodyText confidence="0.999889466666667">
A reader would not from this pair of examples per-
ceive as strongly contrasting perspectives as the
Kerry-Bush answers. Instead, as the Reuters an-
notators did, one would label Example 3 as “gold”
and Example 4 as “acquisition”, that is, as two top-
ics instead of two perspectives.
Why does the contrast between Example 1 and
Example 2 convey different perspectives, but the
contrast between Example 3 and Example 4 result
in different topics? How can we define the impal-
pable “different perspectives” anyway? The defi-
nition of “perspective” in the dictionary is “subjec-
tive evaluation of relative significance,”1 but can
we have a computable definition to test the exis-
tence of different perspectives?
</bodyText>
<footnote confidence="0.992078">
1The American Heritage Dictionary of the English Lan-
guage, 4th ed. We are interested in identifying “ideologi-
cal perspectives” (Verdonk, 2002), not first-person or second-
person “perspective” in narrative.
</footnote>
<page confidence="0.981804">
1057
</page>
<bodyText confidence="0.998433636363636">
Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1057–1064,
Sydney, July 2006. c�2006 Association for Computational Linguistics
The research question about the definition of
different perspectives is not only scientifically in-
triguing, it also enables us to develop important
natural language processing applications. Such
a computational definition can be used to detect
the emergence of contrasting perspectives. Me-
dia and political analysts regularly monitor broad-
cast news, magazines, newspapers, and blogs to
see if there are public opinion splitting. The huge
number of documents, however, make the task ex-
tremely daunting. Therefore an automated test of
different perspectives will be very valuable to in-
formation analysts.
We first review the relevant work in Section 2.
We take a model-based approach to develop a
computational definition of different perspectives.
We first develop statistical models for the two doc-
ument collections, A and B, and then measure the
degree of contrast by calculating the “distance”
between A and B. How document collections are
statistically modeled and how distribution differ-
ence is estimated are described in Section 3. The
document corpora are described in Section 4. In
Section 5, we evaluate how effective the proposed
test of difference perspectives based on statistical
distribution. The experimental results show that
the distribution divergence can successfully sepa-
rate document collections of different perspectives
from other kinds of collection pairs. We also in-
vestigate if the pattern of distribution difference is
due to personal writing or speaking styles.
</bodyText>
<sectionHeader confidence="0.999694" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.99992415">
There has been interest in understanding how be-
liefs and ideologies can be represented in comput-
ers since mid-sixties of the last century (Abelson
and Carroll, 1965; Schank and Abelson, 1977).
The Ideology Machine (Abelson, 1973) can simu-
late a right-wing ideologue, and POLITICS (Car-
bonell, 1978) can interpret a text from conserva-
tive or liberal ideologies. In this paper we take
a statistics-based approach, which is very differ-
ent from previous work that rely very much on
manually-constructed knowledge base.
Note that what we are interested in is to deter-
mine if two document collections are written from
different perspectives, not to model individual per-
spectives. We aim to capture the characteristics,
specifically the statistical regularities of any pairs
of document collections with opposing perspec-
tives. Given a pair of document collections A and
B, our goal is not to construct classifiers that can
predict if a document was written from the per-
spective of A or B (Lin et al., 2006), but to deter-
mine if the document collection pair (A, B) con-
vey opposing perspectives.
There has been growing interest in subjectivity
and sentiment analysis. There are studies on learn-
ing subjective language (Wiebe et al., 2004), iden-
tifying opinionated documents (Yu and Hatzivas-
siloglou, 2003) and sentences (Riloff et al., 2003;
Riloff and Wiebe, 2003), and discriminating be-
tween positive and negative language (Turney and
Littman, 2003; Pang et al., 2002; Dave et al.,
2003; Nasukawa and Yi, 2003; Morinaga et al.,
2002). There are also research work on automati-
cally classifying movie or product reviews as pos-
itive or negative (Nasukawa and Yi, 2003; Mullen
and Collier, 2004; Beineke et al., 2004; Pang and
Lee, 2004; Hu and Liu, 2004).
Although we expect by its very nature much of
the language used when expressing a perspective
to be subjective and opinionated, the task of la-
beling a document or a sentence as subjective is
orthogonal to the test of different perspectives. A
subjectivity classifier may successfully identify all
subjective sentences in the document collection
pair A and B, but knowing the number of sub-
jective sentences in A and B does not necessarily
tell us if they convey opposing perspectives. We
utilize the subjectivity patterns automatically ex-
tracted from foreign news documents (Riloff and
Wiebe, 2003), and find that the percentages of
the subjective sentences in the bitterlemons corpus
(see Section 4) are similar (65.6% in the Pales-
tinian documents and 66.2% in the Israeli docu-
ments). The high but almost equivalent number of
subjective sentences in two perspectives suggests
that perspective is largely expressed in subjective
language but subjectivity ratio is not enough to tell
if two document collections are written from the
same (Palestinian v.s. Palestinian) or different per-
spectives (Palestinian v.s. Israeli)2.
</bodyText>
<sectionHeader confidence="0.992125" genericHeader="method">
3 Statistical Distribution Divergence
</sectionHeader>
<bodyText confidence="0.999061875">
We take a model-based approach to measure to
what degree, if any, two document collections are
different. A document is represented as a point
2However, the close subjectivity ratio doesn’t mean that
subjectivity can never help identify document collections of
opposing perspectives. For example, the accuracy of the test
of different perspectives may be improved by focusing on
only subjective sentences.
</bodyText>
<page confidence="0.973275">
1058
</page>
<bodyText confidence="0.996228785714286">
in a V-dimensional space, where V is vocabulary
size. Each coordinate is the frequency of a word
in a document, i.e., term frequency. Although vec-
tor representation, commonly known as a bag of
words, is oversimplified and ignores rich syntactic
and semantic structures, more sophisticated rep-
resentation requires more data to obtain reliable
models. Practically, bag-of-word representation
has been very effective in many tasks, including
text categorization (Sebastiani, 2002) and infor-
mation retrieval (Lewis, 1998).
We assume that a collection of N documents,
y1, y2, ... , yN are sampled from the following
process,
</bodyText>
<equation confidence="0.9994745">
θ — Dirichlet(α)
yi — Multinomial(ni, θ).
</equation>
<bodyText confidence="0.999982">
We first sample a V-dimensional vector θ from a
Dirichlet prior distribution with a hyperparameter
α, and then sample a document yi repeatedly from
a Multinomial distribution conditioned on the pa-
rameter θ, where ni is the document length of the
ith document in the collection and assumed to be
known and fixed.
We are interested in comparing the parameter θ
after observing document collections A and 13:
</bodyText>
<equation confidence="0.98589275">
p(θ|A) = p(A|θ)p(θ)
p(A)
= Dirichlet(θ|α + 1] yi).
yzEA
</equation>
<bodyText confidence="0.999935222222222">
The posterior distribution p(θ|·) is a Dirichlet dis-
tribution since a Dirichlet distribution is a conju-
gate prior for a Multinomial distribution.
How should we measure the difference between
two posterior distributions p(θ|A) and p(θ|13)?
One common way to measure the difference be-
tween two distributions is Kullback-Leibler (KL)
divergence (Kullback and Leibler, 1951), defined
as follows,
</bodyText>
<equation confidence="0.745629333333333">
D(p(θ|A)||p(θ|13))
f p(θ|A) log p(θ|A)
= p(θ|13) dθ. (5)
</equation>
<listItem confidence="0.845932375">
Directly calculating KL divergence according to
(5) involves a difficult high-dimensional integral.
As an alternative, we approximate KL divergence
using Monte Carlo methods as follows,
1. Sample θ1, θ2, ... , θM from Dirichlet(θ|α +
EyzEA yi).
2. Return D = M �M1 log P(Bz||A) as a Monte
Carlo estimate of D(p(θ|A)||p(θ|13)).
</listItem>
<bodyText confidence="0.97545">
Algorithms of sampling from Dirichlet distribu-
tion can be found in (Ripley, 1987). As M —* oo,
the Monte Carlo estimate will converge to true KL
divergence by the Law of Large Numbers.
</bodyText>
<sectionHeader confidence="0.995869" genericHeader="method">
4 Corpora
</sectionHeader>
<bodyText confidence="0.997592166666667">
To evaluate how well KL divergence between pos-
terior distributions can discern a document collec-
tion pair of different perspectives, we collect two
corpora of documents that were written or spoken
from different perspectives and one newswire cor-
pus that covers various topics, as summarized in
</bodyText>
<tableCaption confidence="0.5499855">
Table 1. No stemming algorithms is performed;
no stopwords are removed.
</tableCaption>
<table confidence="0.999922227272727">
Corpus Subset 11)1 Idl V
bitterlemons Palestinian 290 748.7 10309
Israeli 303 822.4 11668
Pal. Editor 144 636.2 6294
Pal. Guest 146 859.6 8661
Isr. Editor 152 819.4 8512
Isr. Guest 151 825.5 8812
2004 Kerry 178 124.7 2554
Presiden- Bush 176 107.8 2393
tial 1st Kerry 33 216.3 1274
Debate 1st Bush 41 155.3 1195
2nd Kerry 73 103.8 1472
2nd Bush 75 89.0 1333
3rd Kerry 72 104.0 1408
3rd Bush 60 98.8 1281
Reuters- ACQ 2448 124.7 14293
21578 CRUDE 634 214.7 9009
EARN 3987 81.0 12430
GRAIN 628 183.0 8236
INTEREST 513 176.3 6056
MONEY-FX 801 197.9 8162
TRADE 551 255.3 8175
</table>
<tableCaption confidence="0.997931">
Table 1: The number of documents |D|, average
</tableCaption>
<bodyText confidence="0.976868666666667">
document length �|d |, and vocabulary size V of
the three corpora.
The first perspective corpus consists of arti-
cles published on the bitterlemons website3 from
late 2001 to early 2005. The website is set up
to “contribute to mutual understanding [between
Palestinians and Israelis] through the open ex-
change of ideas”4. Every week an issue about the
Israeli-Palestinian conflict is selected for discus-
sion (e.g., “Disengagement: unilateral or coordi-
nated?”), and a Palestinian editor and an Israeli
editor each contribute one article addressing the
</bodyText>
<footnote confidence="0.994928">
3http://www.bitterlemons.org/
4http://www.bitterlemons.org/about/
about.html
</footnote>
<page confidence="0.995991">
1059
</page>
<bodyText confidence="0.999777884615385">
issue. In addition, the Israeli and Palestinian ed-
itors interview a guest to express their views on
the issue, resulting in a total of four articles in a
weekly edition. The perspective from which each
article is written is labeled as either Palestinian or
Israeli by the editors.
The second perspective corpus consists of the
transcripts of the three Bush-Kerry presidential de-
bates in 2004. The transcripts are from the website
of the Commission on Presidential Debates5. Each
spoken document is roughly an answer to a ques-
tion or a rebuttal. The transcript are segmented
by the speaker tags already in the transcripts. All
words from moderators are discarded.
The topical corpus contains newswire from
Reuters in 1987. Reuters-215786 is one of the
most common testbeds for text categorization.
Each document belongs to none, one, or more of
the 135 categories (e.g., “Mergers” and “U.S. Dol-
lars”.) The number of documents in each category
is not evenly distributed (median 9.0, mean 105.9).
To estimate statistics reliably, we only consider
categories with more than 500 documents, result-
ing in a total of seven categories (ACQ, CRUDE,
EARN, GRAIN, INTEREST, MONEY-FX, and
TRADE).
</bodyText>
<sectionHeader confidence="0.999519" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.998965529411765">
A test of different perspectives is acute when it
can draw distinctions between document collec-
tion pairs of different perspectives and document
collection pairs of the same perspective and others.
We thus evaluate the proposed test of different per-
spectives in the following four types of document
collection pairs (A, B):
Different Perspectives (DP) A and B are writ-
ten from different perspectives. For example,
A is written from the Palestinian perspective
and B is written from the Israeli perspective
in the bitterlemons corpus.
Same Perspective (SP) A and B are written from
the same perspective. For example, A and B
consist of the words spoken by Kerry.
Different Topics (DT) A and B are written on
different topics. For example, A is about
</bodyText>
<footnote confidence="0.9969305">
5http://www.debates.org/pages/
debtrans.html
6http://www.ics.uci.edu/-kdd/
databases/reuters21578/reuters21578.html
</footnote>
<bodyText confidence="0.999547866666667">
acquisition (ACQ) and B is about crude oil
(CRUDE).
Same Topic (ST) A and B are written on the
same topic. For example, A and B are both
about earnings (EARN).
The effectiveness of the proposed test of differ-
ent perspectives can thus be measured by how the
distribution divergence of DP document collection
pairs is separated from the distribution divergence
of SP, DT, and ST document collection pairs. The
little the overlap of the range of distribution di-
vergence, the sharper the test of different perspec-
tives.
To account for large variation in the number of
words and vocabulary size across corpora, we nor-
malize the total number of words in a document
collection to be the same K, and consider only the
top C% frequent words in the document collection
pair. We vary the values of K and C, and find that
K changes the absolute scale of KL divergence
but does not change the rankings of four condi-
tions. Rankings among four conditions is consis-
tent when C is small. We only report results of
K = 1000, C = 10 in the paper due to space limit.
There are two kinds of variances in the estima-
tion of divergence between two posterior distribu-
tion and should be carefully checked. The first
kind of variance is due to Monte Carlo methods.
We assess the Monte Carlo variance by calculat-
ing a 100α percent confidence interval as follows,
</bodyText>
<equation confidence="0.912663">
Dˆ + Φ−1(1 − α 2 )
</equation>
<bodyText confidence="0.999849">
where ˆσ2 is the sample variance of θ1, θ2, ... , θM,
and Φ(·)−1 is the inverse of the standard normal
cumulative density function. The second kind of
variance is due to the intrinsic uncertainties of data
generating processes. We assess the second kind
of variance by collecting 1000 bootstrapped sam-
ples, that is, sampling with replacement, from each
document collection pair.
</bodyText>
<subsectionHeader confidence="0.999316">
5.1 Quality of Monte Carlo Estimates
</subsectionHeader>
<bodyText confidence="0.995927714285714">
The Monte Carlo estimates of the KL divergence
from several document collection pair are listed in
Table 2. A complete list of the results is omit-
ted due to the space limit. We can see that the
95% confidence interval captures well the Monte
Carlo estimates of KL divergence. Note that KL
divergence is not symmetric. The KL divergence
</bodyText>
<figure confidence="0.5632138">
[Dˆ − Φ−1(α2 )
σˆ
I/M ,
σˆ
I/M ]
</figure>
<page confidence="0.900844">
1060
</page>
<table confidence="0.998139428571429">
A B D 95% CI
ACQ ACQ 2.76 [2.62, 2.89]
Palestinian Palestinian 3.00 [3.54, 3.85]
Palestinian Israeli 27.11 [26.64, 27.58]
Israeli Palestinian 28.44 [27.97, 28.91]
Kerry Bush 58.93 [58.22, 59.64]
ACQ EARN 615.75 [610.85, 620.65]
</table>
<tableCaption confidence="0.984925">
Table 2: The Monte Carlo estimate D and 95%
confidence interval (CI) of the Kullback-Leibler
divergence of several document collection pairs
</tableCaption>
<equation confidence="0.9833845">
(A, B) with the number of Monte Carlo samples
M = 1000.
</equation>
<bodyText confidence="0.9998092">
of the pair (Israeli, Palestinian) is not necessarily
the same as (Palestinian, Israeli). KL divergence is
greater than zero (Cover and Thomas, 1991) and
equal to zero only when document collections A
and B are exactly the same. Here (ACQ, ACQ) is
close to but not exactly zero because they are dif-
ferent samples of documents in the ACQ category.
Since the CIs of Monte Carlo estimates are reason-
ably tight, we assume them to be exact and ignore
the errors from Monte Carlo methods.
</bodyText>
<subsectionHeader confidence="0.9999">
5.2 Test of Different Perspectives
</subsectionHeader>
<bodyText confidence="0.999973052631579">
We now present the main result of the paper.
We calculate the KL divergence between poste-
rior distributions of document collection pairs in
four conditions using Monte Carlo methods, and
plot the results in Figure 1. The test of different
perspectives based on statistical distribution diver-
gence is shown to be very acute. The KL diver-
gence of the document collection pairs in the DP
condition fall mostly in the middle range, and is
well separated from the high KL divergence of the
pairs in DT condition and from the low KL diver-
gence of the pairs in SP and ST conditions. There-
fore, by simply calculating the KL divergence of
a document collection pair, we can reliably pre-
dict that they are written from different perspec-
tives if the value of KL divergence falls in the
middle range, from different topics if the value is
very large, from the same topic or perspective if
the value is very small.
</bodyText>
<subsectionHeader confidence="0.999329">
5.3 Personal Writing Styles or Perspectives?
</subsectionHeader>
<bodyText confidence="0.999524909090909">
One may suspect that the mid-range distribution
divergence is attributed to personal speaking or
writing styles and has nothing to do with differ-
ent perspectives. The doubt is expected because
half of the bitterlemons corpus are written by one
Palestinian editor and one Israeli editor (see Ta-
ble 1), and the debate transcripts come from only
two candidates.
We test the hypothesis by computing the dis-
tribution divergence of the document collection
pair (Israeli Guest, Palestinian Guest), that is, a
Different Perspectives (DP) pair. There are more
than 200 different authors in the Israeli Guest and
Palestinian Guest collection. If the distribution di-
vergence of the pair with diverse authors falls out
of the middle range, it will support that mid-range
divergence is due to writing styles. On the other
hand, if the distribution divergence still fall in the
middle range, we are more confident the effect
is attributed to different perspectives. We com-
pare the distribution divergence of the pair (Israeli
Guest, Palestinian Guest) with others in Figure 2.
</bodyText>
<table confidence="0.732446666666667">
KL Divergence
1 2 5 10 20 50 200 500
ST SP DP Guest DT
</table>
<figureCaption confidence="0.5898714">
Figure 2: The average KL divergence of document
collection pairs in the bitterlemons Guest subset
(Israeli Guest vs. Palestinian Guest), ST ,SP, DP,
DT conditions. The horizontal lines are the same
as those in Figure 1.
</figureCaption>
<bodyText confidence="0.999989">
The results show that the distribution diver-
gence of the (Israeli Guest, Palestinian Guest) pair,
as other pairs in the DP condition, still falls in the
middle range, and is well separated from SP and
ST in the low range and DT in the high range. The
decrease in KL divergence due to writing or speak-
ing styles is noticeable, and the overall effect due
to different perspectives is strong enough to make
the test robust. We thus conclude that the test of
different perspectives based on distribution diver-
gence indeed captures different perspectives, not
personal writing or speaking styles.
</bodyText>
<subsectionHeader confidence="0.996699">
5.4 Origins of Differences
</subsectionHeader>
<bodyText confidence="0.9486105">
While the effectiveness of the test of different per-
spectives is demonstrated in Figure 1, one may
</bodyText>
<page confidence="0.967966">
1061
</page>
<figure confidence="0.99506025">
Density
SP
ST
DP
DT
0.00 0.05 0.10 0.15
2 5 10 20 50 100 200 500 1000
KL Divergence
</figure>
<figureCaption confidence="0.8806526">
Figure 1: The KL divergence of the document collection pairs in four conditions: Different Perspectives
(DP), Same Perspective (SP), Different Topics (DT), and Same Topic (ST). Note that the x axis is in log
scale. The Monte Carlo estimates D� of the pairs in DP condition are plotted as rugs. D� of the pairs in
other conditions are omitted to avoid clutter and summarized in one-dimensional density using Kernel
Density Estimation. The vertical lines are drawn at the points with equivalent densities.
</figureCaption>
<bodyText confidence="0.999905833333333">
wonder why the distribution divergence of the
document collection pair with different perspec-
tives falls in the middle range and what causes the
large and small divergence of the document collec-
tion pairs with different topics (DT) and the same
topic (ST) or perspective (SP), respectively. In
other words where do the differences result from?
We answer the question by taking a closer look
at the causes of the distribution divergence in our
model. We compare the expected marginal dif-
ference of θ between two posterior distributions
p(θ|A) and p(θ|B). The marginal distribution of
the i-th coordinate of θ, that is, the i-th word in the
vocabulary, is a Beta distribution, and thus the ex-
pected value can be easily calculated. We plot the
Aθ = E[θZ|A] − E[θZ|B] against E[θZ|A] for each
condition in Figure 3.
How Aθ is deviated from zero partially explains
different patterns of distribution divergence in Fig-
ure 1. In Figure 3d we see that the Aθ increases
as θ increases, and the deviance from zero is much
greater than those in the Same Perspective (Fig-
ure 3b) and Same Topic (Figure 3a) conditions.
The large Aθ not only accounts for large distribu-
tion divergence of the document pairs in DT con-
ditions, but also shows that words in different top-
ics that is frequent in one topic are less likely to be
frequent in the other topic. At the other extreme,
document collection pairs of the Same Perspective
(SP) or Same Topic (ST) show very little differ-
ence in θ, which matches our intuition that docu-
ments of the same perspective or the same topic
use the same vocabulary in a very similar way.
The manner in which Aθ is varied with the
value of θ in the Different Perspective (DP) con-
dition is very unique. The Aθ in Figure 3c is not
as small as those in the SP and ST conditions,
but at the same time not as large as those in DT
conditions, resulting in mid-range distribution di-
vergence in Figure 1. Why do document collec-
tions of different perspectives distribute this way?
Partly because articles from different perspectives
focus on the closely related issues (the Palestinian-
Israeli conflict in the bitterlemons corpus, or the
political and economical issues in the debate cor-
pus), the authors of different perspectives write or
speak in a similar vocabulary, but with emphasis
on different words.
</bodyText>
<sectionHeader confidence="0.99967" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99612875">
In this paper we develop a computational test of
different perspectives based on statistical distri-
bution divergence between the statistical models
of document collections. We show that the pro-
</bodyText>
<page confidence="0.975026">
1062
</page>
<figure confidence="0.704967">
(d) Two examples of Different Topics (DT)
</figure>
<figureCaption confidence="0.783235">
Figure 3: Cont’d
</figureCaption>
<figure confidence="0.997483181818182">
0.00 0.01 0.02 0.03 0.04 0.05 0.06
−0.04 −0.02 0.00 0.02 0.04
(a) Same Topic (ST)
0.00 0.01 0.02 0.03 0.04 0.05 0.06
−0.04 −0.02 0.00 0.02 0.04
0.00 0.01 0.02 0.03 0.04 0.05 0.06
−0.04 −0.02 0.00 0.02 0.04
0.00 0.01 0.02 0.03 0.04 0.05 0.06
−0.04 −0.02 0.00 0.02 0.04
(b) Same Topic (SP)
(c) Two examples of Different Perspective (DP)
</figure>
<figureCaption confidence="0.802086333333333">
Figure 3: The AO vs. 0 plots of the typical docu-
ment collection pairs in four conditions. The hori-
zontal line is AO = 0.
</figureCaption>
<bodyText confidence="0.999525">
posed test can successfully separate document col-
lections of different perspectives from other types
of document collection pairs. The distribution di-
vergence falling in the middle range can not sim-
ply be attributed to personal writing or speaking
styles. From the plot of multinomial parameter
difference we offer insights into where the differ-
ent patterns of distribution divergence come from.
Although we validate the test of different per-
spectives by comparing the DP condition with DT,
SP, and ST conditions, the comparisons are by
no means exhaustive, and the distribution diver-
gence of some document collection pairs may also
fall in the middle range. We plan to investigate
more types of document collections pairs, e.g., the
document collections from different text genres
(Kessler et al., 1997).
</bodyText>
<sectionHeader confidence="0.959259" genericHeader="acknowledgments">
Acknowledgment
</sectionHeader>
<bodyText confidence="0.9941876">
We would like thank the anonymous reviewers for
useful comments and suggestions. This material
is based on work supported by the Advanced Re-
search and Development Activity (ARDA) under
contract number NBCHC040037.
</bodyText>
<table confidence="0.87205025">
0.00 0.01 0.02 0.03 0.04 0.05 0.06
0.00 0.01 0.02 0.03 0.04 0.05 0.06
−0.04 −0.02 0.00 0.02 0.04
−0.04 −0.02 0.00 0.02 0.04
</table>
<page confidence="0.707554">
1063
</page>
<sectionHeader confidence="0.98183" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999753701030928">
Robert P. Abelson and J. Douglas Carroll. 1965. Com-
puter simulation of individual belief systems. The
American Behavioral Scientist, 8:24–30, May.
Robert P. Abelson, 1973. Computer Models of Thought
and Language, chapter The Structure of Belief Sys-
tems, pages 287–339. W. H. Freeman and Company.
Philip Beineke, Trevor Hastie, and Shivakumar
Vaithyanathan. 2004. The sentimental factor: Im-
proving review classification via human-provided
information. In Proceedings of the Association for
Computational Linguistics (ACL-2004).
Jaime G. Carbonell. 1978. POLITICS: Automated
ideological reasoning. Cognitive Science, 2(1):27–
51.
Thomas M. Cover and Joy A. Thomas. 1991. Elements
ofInformation Theory. Wiley-Interscience.
Kushal Dave, Steve Lawrence, and David M. Pennock.
2003. Mining the peanut gallery: Opinion extraction
and semantic classification of product reviews. In
Proceedings of the 12th International World Wide
Web Conference (WWW2003).
Minqing Hu and Bing Liu. 2004. Mining and summa-
rizing customer reviews. In Proceedings of the 2004
ACM SIGKDD International Conference on Knowl-
edge Discovery and Data Mining.
Brett Kessler, Geoffrey Nunberg, and Hinrich Sch¨utze.
1997. Automatic detection of text genre. In Pro-
ceedings of the 35th Conference on Association for
Computational Linguistics, pages 32–38.
S. Kullback and R. A. Leibler. 1951. On information
and sufficiency. The Annals ofMathematical Statis-
tics, 22(1):79–86, March.
David D. Lewis. 1998. Naive (Bayes) at forty: The in-
dependence assumption in information retrieval. In
Proceedings of the 9th European Conference on Ma-
chine Learning (ECML).
Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and
Alexander Hauptmann. 2006. Which side are you
on? identifying perspectives at the document and
sentence levels. In Proceedings of Tenth Conference
on Natural Language Learning (CoNLL).
S. Morinaga, K. Yamanishi, K. Tateishi, and
T. Fukushima. 2002. Mining product reputations on
the web. In Proceedings of the 2002 ACM SIGKDD
International Conference on Knowledge Discovery
and Data Mining.
Tony Mullen and Nigel Collier. 2004. Sentiment anal-
ysis using support vector machines with diverse in-
formation sources. In Proceedings of the Confer-
ence on Empirical Methods in Natural Language
Processing (EMNLP-2004).
T. Nasukawa and J. Yi. 2003. Sentiment analysis:
Capturing favorability using natural language pro-
cessing. In Proceedings of the 2nd International
Conference on Knowledge Capture (K-CAP 2003).
Bo Pang and Lillian Lee. 2004. A sentimental edu-
cation: Sentiment analysis using subjectivity sum-
marization based on minimum cuts. In Proceed-
ings of the Association for Computational Linguis-
tics (ACL-2004).
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up? Sentiment classification using
machine learning techniques. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing (EMNLP-2002).
Ellen Riloff and Janyce Wiebe. 2003. Learning ex-
traction patterns for subjective expressions. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing (EMNLP-2003).
Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003.
Learning subjective nouns using extraction pattern
bootstrapping. In Proceedings of the 7th Conference
on Natural Language Learning (CoNLL-2003).
B. D. Ripley. 1987. Stochastic Simulation. Wiley.
Roger C. Schank and Robert P. Abelson. 1977. Scripts,
plans, goals, and understanding: an inquiry into hu-
man knowledge structures. Lawrene Erlbaum Asso-
ciates.
Fabrizio Sebastiani. 2002. Machine learning in au-
tomated text categorization. ACM Computing Sur-
veys, 34(1):1–47, March.
Peter Turney and Michael L. Littman. 2003. Mea-
suring praise and criticism: Inference of semantic
orientation from association. ACM Transactions on
Information Systems (TOIS), 21(4):315–346.
Peter Verdonk. 2002. Stylistics. Oxford University
Press.
Janyce Wiebe, Theresa Wilson, Rebecca Bruce,
Matthew Bell, and Melanie Martin. 2004. Learn-
ing subjective language. Computational Linguistics,
30(3).
Hong Yu and Vasileios Hatzivassiloglou. 2003. To-
wards answering opinion questions: Separating facts
from opinions and identifying the polarity of opin-
ion sentences. In Proceedings of the Conference on
Empirical Methods in Natural Language Processing
(EMNLP-2003).
</reference>
<page confidence="0.983514">
1064
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.335275">
<title confidence="0.992472">Are These Documents Written from Different Perspectives? A Test of Different Perspectives Based On Statistical Distribution Divergence</title>
<author confidence="0.997828">Wei-Hao Lin</author>
<affiliation confidence="0.978104333333333">Language Technologies Institute School of Computer Science Carnegie Mellon University</affiliation>
<address confidence="0.59169">Pittsburgh, PA 15213 U.S.A.</address>
<email confidence="0.999682">whlin@cs.cmu.edu</email>
<author confidence="0.999931">Alexander Hauptmann</author>
<affiliation confidence="0.999159333333333">Language Technologies Institute School of Computer Science Carnegie Mellon University</affiliation>
<address confidence="0.621536">Pittsburgh, PA 15213 U.S.A.</address>
<email confidence="0.999633">alex@cs.cmu.edu</email>
<abstract confidence="0.999599214285714">In this paper we investigate how to automatically determine if two document colare written from different per- By perspectives we mean a point of view, for example, from the perspective of Democrats or Republicans. We propose a test of different perspectives based on distribution divergence between the statistical models of two collections. Experimental results show that the test can successfully distinguish document collections of different perspectives from other types of collections.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Robert P Abelson</author>
<author>J Douglas Carroll</author>
</authors>
<title>Computer simulation of individual belief systems.</title>
<date>1965</date>
<journal>The American Behavioral Scientist,</journal>
<volume>8</volume>
<contexts>
<context position="5299" citStr="Abelson and Carroll, 1965" startWordPosition="822" endWordPosition="825">cument corpora are described in Section 4. In Section 5, we evaluate how effective the proposed test of difference perspectives based on statistical distribution. The experimental results show that the distribution divergence can successfully separate document collections of different perspectives from other kinds of collection pairs. We also investigate if the pattern of distribution difference is due to personal writing or speaking styles. 2 Related Work There has been interest in understanding how beliefs and ideologies can be represented in computers since mid-sixties of the last century (Abelson and Carroll, 1965; Schank and Abelson, 1977). The Ideology Machine (Abelson, 1973) can simulate a right-wing ideologue, and POLITICS (Carbonell, 1978) can interpret a text from conservative or liberal ideologies. In this paper we take a statistics-based approach, which is very different from previous work that rely very much on manually-constructed knowledge base. Note that what we are interested in is to determine if two document collections are written from different perspectives, not to model individual perspectives. We aim to capture the characteristics, specifically the statistical regularities of any pai</context>
</contexts>
<marker>Abelson, Carroll, 1965</marker>
<rawString>Robert P. Abelson and J. Douglas Carroll. 1965. Computer simulation of individual belief systems. The American Behavioral Scientist, 8:24–30, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert P Abelson</author>
</authors>
<title>Computer Models of Thought and Language, chapter The Structure of Belief Systems,</title>
<date>1973</date>
<pages>287--339</pages>
<contexts>
<context position="5364" citStr="Abelson, 1973" startWordPosition="833" endWordPosition="834">ective the proposed test of difference perspectives based on statistical distribution. The experimental results show that the distribution divergence can successfully separate document collections of different perspectives from other kinds of collection pairs. We also investigate if the pattern of distribution difference is due to personal writing or speaking styles. 2 Related Work There has been interest in understanding how beliefs and ideologies can be represented in computers since mid-sixties of the last century (Abelson and Carroll, 1965; Schank and Abelson, 1977). The Ideology Machine (Abelson, 1973) can simulate a right-wing ideologue, and POLITICS (Carbonell, 1978) can interpret a text from conservative or liberal ideologies. In this paper we take a statistics-based approach, which is very different from previous work that rely very much on manually-constructed knowledge base. Note that what we are interested in is to determine if two document collections are written from different perspectives, not to model individual perspectives. We aim to capture the characteristics, specifically the statistical regularities of any pairs of document collections with opposing perspectives. Given a pa</context>
</contexts>
<marker>Abelson, 1973</marker>
<rawString>Robert P. Abelson, 1973. Computer Models of Thought and Language, chapter The Structure of Belief Systems, pages 287–339. W. H. Freeman and Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Beineke</author>
<author>Trevor Hastie</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>The sentimental factor: Improving review classification via human-provided information.</title>
<date>2004</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL-2004).</booktitle>
<contexts>
<context position="6839" citStr="Beineke et al., 2004" startWordPosition="1072" endWordPosition="1075">. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify all subjective sentences in the document collection pair A and B, but knowing the number of subjective sentences in A and B does not necessarily tell us if they convey opposing perspectives. We utilize the subjectivity patterns automatically extracted from foreign n</context>
</contexts>
<marker>Beineke, Hastie, Vaithyanathan, 2004</marker>
<rawString>Philip Beineke, Trevor Hastie, and Shivakumar Vaithyanathan. 2004. The sentimental factor: Improving review classification via human-provided information. In Proceedings of the Association for Computational Linguistics (ACL-2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaime G Carbonell</author>
</authors>
<title>POLITICS: Automated ideological reasoning.</title>
<date>1978</date>
<journal>Cognitive Science,</journal>
<volume>2</volume>
<issue>1</issue>
<pages>51</pages>
<contexts>
<context position="5432" citStr="Carbonell, 1978" startWordPosition="843" endWordPosition="845">stical distribution. The experimental results show that the distribution divergence can successfully separate document collections of different perspectives from other kinds of collection pairs. We also investigate if the pattern of distribution difference is due to personal writing or speaking styles. 2 Related Work There has been interest in understanding how beliefs and ideologies can be represented in computers since mid-sixties of the last century (Abelson and Carroll, 1965; Schank and Abelson, 1977). The Ideology Machine (Abelson, 1973) can simulate a right-wing ideologue, and POLITICS (Carbonell, 1978) can interpret a text from conservative or liberal ideologies. In this paper we take a statistics-based approach, which is very different from previous work that rely very much on manually-constructed knowledge base. Note that what we are interested in is to determine if two document collections are written from different perspectives, not to model individual perspectives. We aim to capture the characteristics, specifically the statistical regularities of any pairs of document collections with opposing perspectives. Given a pair of document collections A and B, our goal is not to construct cla</context>
</contexts>
<marker>Carbonell, 1978</marker>
<rawString>Jaime G. Carbonell. 1978. POLITICS: Automated ideological reasoning. Cognitive Science, 2(1):27– 51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas M Cover</author>
<author>Joy A Thomas</author>
</authors>
<title>Elements ofInformation Theory.</title>
<date>1991</date>
<publisher>Wiley-Interscience.</publisher>
<contexts>
<context position="16942" citStr="Cover and Thomas, 1991" startWordPosition="2710" endWordPosition="2713">divergence [Dˆ − Φ−1(α2 ) σˆ I/M , σˆ I/M ] 1060 A B D 95% CI ACQ ACQ 2.76 [2.62, 2.89] Palestinian Palestinian 3.00 [3.54, 3.85] Palestinian Israeli 27.11 [26.64, 27.58] Israeli Palestinian 28.44 [27.97, 28.91] Kerry Bush 58.93 [58.22, 59.64] ACQ EARN 615.75 [610.85, 620.65] Table 2: The Monte Carlo estimate D and 95% confidence interval (CI) of the Kullback-Leibler divergence of several document collection pairs (A, B) with the number of Monte Carlo samples M = 1000. of the pair (Israeli, Palestinian) is not necessarily the same as (Palestinian, Israeli). KL divergence is greater than zero (Cover and Thomas, 1991) and equal to zero only when document collections A and B are exactly the same. Here (ACQ, ACQ) is close to but not exactly zero because they are different samples of documents in the ACQ category. Since the CIs of Monte Carlo estimates are reasonably tight, we assume them to be exact and ignore the errors from Monte Carlo methods. 5.2 Test of Different Perspectives We now present the main result of the paper. We calculate the KL divergence between posterior distributions of document collection pairs in four conditions using Monte Carlo methods, and plot the results in Figure 1. The test of di</context>
</contexts>
<marker>Cover, Thomas, 1991</marker>
<rawString>Thomas M. Cover and Joy A. Thomas. 1991. Elements ofInformation Theory. Wiley-Interscience.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kushal Dave</author>
<author>Steve Lawrence</author>
<author>David M Pennock</author>
</authors>
<title>Mining the peanut gallery: Opinion extraction and semantic classification of product reviews.</title>
<date>2003</date>
<booktitle>In Proceedings of the 12th International World Wide Web Conference (WWW2003).</booktitle>
<contexts>
<context position="6613" citStr="Dave et al., 2003" startWordPosition="1034" endWordPosition="1037"> B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify all subjective sentences in the document</context>
</contexts>
<marker>Dave, Lawrence, Pennock, 2003</marker>
<rawString>Kushal Dave, Steve Lawrence, and David M. Pennock. 2003. Mining the peanut gallery: Opinion extraction and semantic classification of product reviews. In Proceedings of the 12th International World Wide Web Conference (WWW2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Minqing Hu</author>
<author>Bing Liu</author>
</authors>
<title>Mining and summarizing customer reviews.</title>
<date>2004</date>
<booktitle>In Proceedings of the 2004 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="6878" citStr="Hu and Liu, 2004" startWordPosition="1080" endWordPosition="1083">ctivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify all subjective sentences in the document collection pair A and B, but knowing the number of subjective sentences in A and B does not necessarily tell us if they convey opposing perspectives. We utilize the subjectivity patterns automatically extracted from foreign news documents (Riloff and Wiebe, 2003),</context>
</contexts>
<marker>Hu, Liu, 2004</marker>
<rawString>Minqing Hu and Bing Liu. 2004. Mining and summarizing customer reviews. In Proceedings of the 2004 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brett Kessler</author>
<author>Geoffrey Nunberg</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Automatic detection of text genre.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Conference on Association for Computational Linguistics,</booktitle>
<pages>32--38</pages>
<marker>Kessler, Nunberg, Sch¨utze, 1997</marker>
<rawString>Brett Kessler, Geoffrey Nunberg, and Hinrich Sch¨utze. 1997. Automatic detection of text genre. In Proceedings of the 35th Conference on Association for Computational Linguistics, pages 32–38.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kullback</author>
<author>R A Leibler</author>
</authors>
<title>On information and sufficiency.</title>
<date>1951</date>
<journal>The Annals ofMathematical Statistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="9945" citStr="Kullback and Leibler, 1951" startWordPosition="1554" endWordPosition="1557">, where ni is the document length of the ith document in the collection and assumed to be known and fixed. We are interested in comparing the parameter θ after observing document collections A and 13: p(θ|A) = p(A|θ)p(θ) p(A) = Dirichlet(θ|α + 1] yi). yzEA The posterior distribution p(θ|·) is a Dirichlet distribution since a Dirichlet distribution is a conjugate prior for a Multinomial distribution. How should we measure the difference between two posterior distributions p(θ|A) and p(θ|13)? One common way to measure the difference between two distributions is Kullback-Leibler (KL) divergence (Kullback and Leibler, 1951), defined as follows, D(p(θ|A)||p(θ|13)) f p(θ|A) log p(θ|A) = p(θ|13) dθ. (5) Directly calculating KL divergence according to (5) involves a difficult high-dimensional integral. As an alternative, we approximate KL divergence using Monte Carlo methods as follows, 1. Sample θ1, θ2, ... , θM from Dirichlet(θ|α + EyzEA yi). 2. Return D = M �M1 log P(Bz||A) as a Monte Carlo estimate of D(p(θ|A)||p(θ|13)). Algorithms of sampling from Dirichlet distribution can be found in (Ripley, 1987). As M —* oo, the Monte Carlo estimate will converge to true KL divergence by the Law of Large Numbers. 4 Corpora</context>
</contexts>
<marker>Kullback, Leibler, 1951</marker>
<rawString>S. Kullback and R. A. Leibler. 1951. On information and sufficiency. The Annals ofMathematical Statistics, 22(1):79–86, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
</authors>
<title>Naive (Bayes) at forty: The independence assumption in information retrieval.</title>
<date>1998</date>
<booktitle>In Proceedings of the 9th European Conference on Machine Learning (ECML).</booktitle>
<contexts>
<context position="8968" citStr="Lewis, 1998" startWordPosition="1398" endWordPosition="1399"> test of different perspectives may be improved by focusing on only subjective sentences. 1058 in a V-dimensional space, where V is vocabulary size. Each coordinate is the frequency of a word in a document, i.e., term frequency. Although vector representation, commonly known as a bag of words, is oversimplified and ignores rich syntactic and semantic structures, more sophisticated representation requires more data to obtain reliable models. Practically, bag-of-word representation has been very effective in many tasks, including text categorization (Sebastiani, 2002) and information retrieval (Lewis, 1998). We assume that a collection of N documents, y1, y2, ... , yN are sampled from the following process, θ — Dirichlet(α) yi — Multinomial(ni, θ). We first sample a V-dimensional vector θ from a Dirichlet prior distribution with a hyperparameter α, and then sample a document yi repeatedly from a Multinomial distribution conditioned on the parameter θ, where ni is the document length of the ith document in the collection and assumed to be known and fixed. We are interested in comparing the parameter θ after observing document collections A and 13: p(θ|A) = p(A|θ)p(θ) p(A) = Dirichlet(θ|α + 1] yi)</context>
</contexts>
<marker>Lewis, 1998</marker>
<rawString>David D. Lewis. 1998. Naive (Bayes) at forty: The independence assumption in information retrieval. In Proceedings of the 9th European Conference on Machine Learning (ECML).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei-Hao Lin</author>
<author>Theresa Wilson</author>
<author>Janyce Wiebe</author>
<author>Alexander Hauptmann</author>
</authors>
<title>Which side are you on? identifying perspectives at the document and sentence levels.</title>
<date>2006</date>
<booktitle>In Proceedings of Tenth Conference on Natural Language Learning (CoNLL).</booktitle>
<contexts>
<context position="6133" citStr="Lin et al., 2006" startWordPosition="958" endWordPosition="961"> a statistics-based approach, which is very different from previous work that rely very much on manually-constructed knowledge base. Note that what we are interested in is to determine if two document collections are written from different perspectives, not to model individual perspectives. We aim to capture the characteristics, specifically the statistical regularities of any pairs of document collections with opposing perspectives. Given a pair of document collections A and B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or prod</context>
</contexts>
<marker>Lin, Wilson, Wiebe, Hauptmann, 2006</marker>
<rawString>Wei-Hao Lin, Theresa Wilson, Janyce Wiebe, and Alexander Hauptmann. 2006. Which side are you on? identifying perspectives at the document and sentence levels. In Proceedings of Tenth Conference on Natural Language Learning (CoNLL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Morinaga</author>
<author>K Yamanishi</author>
<author>K Tateishi</author>
<author>T Fukushima</author>
</authors>
<title>Mining product reputations on the web.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</booktitle>
<contexts>
<context position="6660" citStr="Morinaga et al., 2002" startWordPosition="1042" endWordPosition="1045">rs that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify all subjective sentences in the document collection pair A and B, but knowing the numbe</context>
</contexts>
<marker>Morinaga, Yamanishi, Tateishi, Fukushima, 2002</marker>
<rawString>S. Morinaga, K. Yamanishi, K. Tateishi, and T. Fukushima. 2002. Mining product reputations on the web. In Proceedings of the 2002 ACM SIGKDD International Conference on Knowledge Discovery and Data Mining.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tony Mullen</author>
<author>Nigel Collier</author>
</authors>
<title>Sentiment analysis using support vector machines with diverse information sources.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2004).</booktitle>
<contexts>
<context position="6817" citStr="Mullen and Collier, 2004" startWordPosition="1068" endWordPosition="1071">nvey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify all subjective sentences in the document collection pair A and B, but knowing the number of subjective sentences in A and B does not necessarily tell us if they convey opposing perspectives. We utilize the subjectivity patterns automatically ex</context>
</contexts>
<marker>Mullen, Collier, 2004</marker>
<rawString>Tony Mullen and Nigel Collier. 2004. Sentiment analysis using support vector machines with diverse information sources. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Nasukawa</author>
<author>J Yi</author>
</authors>
<title>Sentiment analysis: Capturing favorability using natural language processing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2nd International Conference on Knowledge Capture (K-CAP</booktitle>
<contexts>
<context position="6636" citStr="Nasukawa and Yi, 2003" startWordPosition="1038" endWordPosition="1041"> to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify all subjective sentences in the document collection pair A and </context>
</contexts>
<marker>Nasukawa, Yi, 2003</marker>
<rawString>T. Nasukawa and J. Yi. 2003. Sentiment analysis: Capturing favorability using natural language processing. In Proceedings of the 2nd International Conference on Knowledge Capture (K-CAP 2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
</authors>
<title>A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Association for Computational Linguistics (ACL-2004).</booktitle>
<contexts>
<context position="6859" citStr="Pang and Lee, 2004" startWordPosition="1076" endWordPosition="1079">ng interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify all subjective sentences in the document collection pair A and B, but knowing the number of subjective sentences in A and B does not necessarily tell us if they convey opposing perspectives. We utilize the subjectivity patterns automatically extracted from foreign news documents (Rilof</context>
</contexts>
<marker>Pang, Lee, 2004</marker>
<rawString>Bo Pang and Lillian Lee. 2004. A sentimental education: Sentiment analysis using subjectivity summarization based on minimum cuts. In Proceedings of the Association for Computational Linguistics (ACL-2004).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up? Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2002).</booktitle>
<contexts>
<context position="6594" citStr="Pang et al., 2002" startWordPosition="1030" endWordPosition="1033">t collections A and B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify all subjective senten</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up? Sentiment classification using machine learning techniques. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2002).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
</authors>
<title>Learning extraction patterns for subjective expressions.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</booktitle>
<contexts>
<context position="6490" citStr="Riloff and Wiebe, 2003" startWordPosition="1014" endWordPosition="1017">tistical regularities of any pairs of document collections with opposing perspectives. Given a pair of document collections A and B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the t</context>
</contexts>
<marker>Riloff, Wiebe, 2003</marker>
<rawString>Ellen Riloff and Janyce Wiebe. 2003. Learning extraction patterns for subjective expressions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
</authors>
<title>Learning subjective nouns using extraction pattern bootstrapping.</title>
<date>2003</date>
<booktitle>In Proceedings of the 7th Conference on Natural Language Learning (CoNLL-2003).</booktitle>
<contexts>
<context position="6465" citStr="Riloff et al., 2003" startWordPosition="1010" endWordPosition="1013"> specifically the statistical regularities of any pairs of document collections with opposing perspectives. Given a pair of document collections A and B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjecti</context>
</contexts>
<marker>Riloff, Wiebe, Wilson, 2003</marker>
<rawString>Ellen Riloff, Janyce Wiebe, and Theresa Wilson. 2003. Learning subjective nouns using extraction pattern bootstrapping. In Proceedings of the 7th Conference on Natural Language Learning (CoNLL-2003).</rawString>
</citation>
<citation valid="true">
<authors>
<author>B D Ripley</author>
</authors>
<title>Stochastic Simulation.</title>
<date>1987</date>
<publisher>Wiley.</publisher>
<contexts>
<context position="10432" citStr="Ripley, 1987" startWordPosition="1633" endWordPosition="1634">ommon way to measure the difference between two distributions is Kullback-Leibler (KL) divergence (Kullback and Leibler, 1951), defined as follows, D(p(θ|A)||p(θ|13)) f p(θ|A) log p(θ|A) = p(θ|13) dθ. (5) Directly calculating KL divergence according to (5) involves a difficult high-dimensional integral. As an alternative, we approximate KL divergence using Monte Carlo methods as follows, 1. Sample θ1, θ2, ... , θM from Dirichlet(θ|α + EyzEA yi). 2. Return D = M �M1 log P(Bz||A) as a Monte Carlo estimate of D(p(θ|A)||p(θ|13)). Algorithms of sampling from Dirichlet distribution can be found in (Ripley, 1987). As M —* oo, the Monte Carlo estimate will converge to true KL divergence by the Law of Large Numbers. 4 Corpora To evaluate how well KL divergence between posterior distributions can discern a document collection pair of different perspectives, we collect two corpora of documents that were written or spoken from different perspectives and one newswire corpus that covers various topics, as summarized in Table 1. No stemming algorithms is performed; no stopwords are removed. Corpus Subset 11)1 Idl V bitterlemons Palestinian 290 748.7 10309 Israeli 303 822.4 11668 Pal. Editor 144 636.2 6294 Pal</context>
</contexts>
<marker>Ripley, 1987</marker>
<rawString>B. D. Ripley. 1987. Stochastic Simulation. Wiley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger C Schank</author>
<author>Robert P Abelson</author>
</authors>
<title>Scripts, plans, goals, and understanding: an inquiry into human knowledge structures. Lawrene Erlbaum Associates.</title>
<date>1977</date>
<contexts>
<context position="5326" citStr="Schank and Abelson, 1977" startWordPosition="826" endWordPosition="829">d in Section 4. In Section 5, we evaluate how effective the proposed test of difference perspectives based on statistical distribution. The experimental results show that the distribution divergence can successfully separate document collections of different perspectives from other kinds of collection pairs. We also investigate if the pattern of distribution difference is due to personal writing or speaking styles. 2 Related Work There has been interest in understanding how beliefs and ideologies can be represented in computers since mid-sixties of the last century (Abelson and Carroll, 1965; Schank and Abelson, 1977). The Ideology Machine (Abelson, 1973) can simulate a right-wing ideologue, and POLITICS (Carbonell, 1978) can interpret a text from conservative or liberal ideologies. In this paper we take a statistics-based approach, which is very different from previous work that rely very much on manually-constructed knowledge base. Note that what we are interested in is to determine if two document collections are written from different perspectives, not to model individual perspectives. We aim to capture the characteristics, specifically the statistical regularities of any pairs of document collections </context>
</contexts>
<marker>Schank, Abelson, 1977</marker>
<rawString>Roger C. Schank and Robert P. Abelson. 1977. Scripts, plans, goals, and understanding: an inquiry into human knowledge structures. Lawrene Erlbaum Associates.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Machine learning in automated text categorization.</title>
<date>2002</date>
<journal>ACM Computing Surveys,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="8928" citStr="Sebastiani, 2002" startWordPosition="1392" endWordPosition="1393">erspectives. For example, the accuracy of the test of different perspectives may be improved by focusing on only subjective sentences. 1058 in a V-dimensional space, where V is vocabulary size. Each coordinate is the frequency of a word in a document, i.e., term frequency. Although vector representation, commonly known as a bag of words, is oversimplified and ignores rich syntactic and semantic structures, more sophisticated representation requires more data to obtain reliable models. Practically, bag-of-word representation has been very effective in many tasks, including text categorization (Sebastiani, 2002) and information retrieval (Lewis, 1998). We assume that a collection of N documents, y1, y2, ... , yN are sampled from the following process, θ — Dirichlet(α) yi — Multinomial(ni, θ). We first sample a V-dimensional vector θ from a Dirichlet prior distribution with a hyperparameter α, and then sample a document yi repeatedly from a Multinomial distribution conditioned on the parameter θ, where ni is the document length of the ith document in the collection and assumed to be known and fixed. We are interested in comparing the parameter θ after observing document collections A and 13: p(θ|A) = </context>
</contexts>
<marker>Sebastiani, 2002</marker>
<rawString>Fabrizio Sebastiani. 2002. Machine learning in automated text categorization. ACM Computing Surveys, 34(1):1–47, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Measuring praise and criticism: Inference of semantic orientation from association.</title>
<date>2003</date>
<journal>ACM Transactions on Information Systems (TOIS),</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="6575" citStr="Turney and Littman, 2003" startWordPosition="1026" endWordPosition="1029">s. Given a pair of document collections A and B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a document or a sentence as subjective is orthogonal to the test of different perspectives. A subjectivity classifier may successfully identify al</context>
</contexts>
<marker>Turney, Littman, 2003</marker>
<rawString>Peter Turney and Michael L. Littman. 2003. Measuring praise and criticism: Inference of semantic orientation from association. ACM Transactions on Information Systems (TOIS), 21(4):315–346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter Verdonk</author>
</authors>
<date>2002</date>
<publisher>Stylistics. Oxford University Press.</publisher>
<contexts>
<context position="3364" citStr="Verdonk, 2002" startWordPosition="535" endWordPosition="536">hat is, as two topics instead of two perspectives. Why does the contrast between Example 1 and Example 2 convey different perspectives, but the contrast between Example 3 and Example 4 result in different topics? How can we define the impalpable “different perspectives” anyway? The definition of “perspective” in the dictionary is “subjective evaluation of relative significance,”1 but can we have a computable definition to test the existence of different perspectives? 1The American Heritage Dictionary of the English Language, 4th ed. We are interested in identifying “ideological perspectives” (Verdonk, 2002), not first-person or secondperson “perspective” in narrative. 1057 Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the ACL, pages 1057–1064, Sydney, July 2006. c�2006 Association for Computational Linguistics The research question about the definition of different perspectives is not only scientifically intriguing, it also enables us to develop important natural language processing applications. Such a computational definition can be used to detect the emergence of contrasting perspectives. Media and political analysts regularly monitor</context>
</contexts>
<marker>Verdonk, 2002</marker>
<rawString>Peter Verdonk. 2002. Stylistics. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Janyce Wiebe</author>
<author>Theresa Wilson</author>
<author>Rebecca Bruce</author>
<author>Matthew Bell</author>
<author>Melanie Martin</author>
</authors>
<title>Learning subjective language.</title>
<date>2004</date>
<journal>Computational Linguistics,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="6363" citStr="Wiebe et al., 2004" startWordPosition="995" endWordPosition="998">m different perspectives, not to model individual perspectives. We aim to capture the characteristics, specifically the statistical regularities of any pairs of document collections with opposing perspectives. Given a pair of document collections A and B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a p</context>
</contexts>
<marker>Wiebe, Wilson, Bruce, Bell, Martin, 2004</marker>
<rawString>Janyce Wiebe, Theresa Wilson, Rebecca Bruce, Matthew Bell, and Melanie Martin. 2004. Learning subjective language. Computational Linguistics, 30(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hong Yu</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences.</title>
<date>2003</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</booktitle>
<contexts>
<context position="6430" citStr="Yu and Hatzivassiloglou, 2003" startWordPosition="1003" endWordPosition="1007">ctives. We aim to capture the characteristics, specifically the statistical regularities of any pairs of document collections with opposing perspectives. Given a pair of document collections A and B, our goal is not to construct classifiers that can predict if a document was written from the perspective of A or B (Lin et al., 2006), but to determine if the document collection pair (A, B) convey opposing perspectives. There has been growing interest in subjectivity and sentiment analysis. There are studies on learning subjective language (Wiebe et al., 2004), identifying opinionated documents (Yu and Hatzivassiloglou, 2003) and sentences (Riloff et al., 2003; Riloff and Wiebe, 2003), and discriminating between positive and negative language (Turney and Littman, 2003; Pang et al., 2002; Dave et al., 2003; Nasukawa and Yi, 2003; Morinaga et al., 2002). There are also research work on automatically classifying movie or product reviews as positive or negative (Nasukawa and Yi, 2003; Mullen and Collier, 2004; Beineke et al., 2004; Pang and Lee, 2004; Hu and Liu, 2004). Although we expect by its very nature much of the language used when expressing a perspective to be subjective and opinionated, the task of labeling a</context>
</contexts>
<marker>Yu, Hatzivassiloglou, 2003</marker>
<rawString>Hong Yu and Vasileios Hatzivassiloglou. 2003. Towards answering opinion questions: Separating facts from opinions and identifying the polarity of opinion sentences. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2003).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>