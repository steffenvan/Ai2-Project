<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000317">
<title confidence="0.772921">
Theoretical Evaluation of Estimation Methods for Data-Oriented Parsing
</title>
<author confidence="0.877916">
Willem Zuidema
</author>
<affiliation confidence="0.876742">
Institute for Logic, Language and Computation
University of Amsterdam
</affiliation>
<address confidence="0.741495">
Plantage Muidergracht 24, 1018 TV, Amsterdam, the Netherlands.
</address>
<email confidence="0.996734">
jzuidema@science.uva.nl
</email>
<sectionHeader confidence="0.996626" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999933">
We analyze estimation methods for Data-
Oriented Parsing, as well as the theoret-
ical criteria used to evaluate them. We
show that all current estimation methods
are inconsistent in the “weight-distribution
test”, and argue that these results force us
to rethink both the methods proposed and
the criteria used.
</bodyText>
<sectionHeader confidence="0.99832" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.973281088888889">
Stochastic Tree Substitution Grammars (hence-
forth, STSGs) are a simple generalization of Prob-
abilistic Context Free Grammars, where the pro-
ductive elements are not rewrite rules but elemen-
tary trees of arbitrary size. The increased flexibil-
ity allows STSGs to model a variety of syntactic
and statistical dependencies, using relatively com-
plex primitives but just a single and extremely sim-
ple global rule: substitution. STSGs can be seen as
Stochastic Tree Adjoining Grammars without the
adjunction operation.
STSGs are the underlying formalism of most in-
stantiations of an approach to statistical parsing
known as “Data-Oriented Parsing” (Scha, 1990;
Bod, 1998). In this approach the subtrees of the
trees in a tree bank are used as elementary trees of
the grammar. In most DOP models the grammar
used is an STSG with, in principle, all subtrees1 of
the trees in the tree bank as elementary trees. For
disambiguation, the best parse tree is taken to be
the most probable parse according to the weights
of the grammar.
Several methods have been proposed to decide
on the weights based on observed tree frequencies
1A subtree t&apos; of a parse tree t is a tree such that every node
i&apos; in t&apos; equals a node i in t, and i&apos; either has no daughters or
the same daughter nodes as i.
in a tree bank. The first such method is now known
as “DOP1” (Bod, 1993). In combination with
some heuristic constraints on the allowed subtrees,
it has been remarkably successful on small tree
banks. Despite this empirical success, (Johnson,
2002) argued that it is inadequate because it is bi-
ased and inconsistent. His criticism spearheaded
a number of other methods, including (Bonnema
et al., 1999; Bod, 2003; Sima’an and Buratto,
2003; Zollmann and Sima’an, 2005), and will be
the starting point of our analysis. As it turns out,
the DOP1 method really is biased and inconsis-
tent, but not for the reasons Johnson gives, and it
really is inadequate, but not because it is biased
and inconsistent. In this note, we further show that
alternative methods that have been proposed, only
partly remedy the problems with DOP1, leaving
weight estimation as an important open problem.
</bodyText>
<sectionHeader confidence="0.999135" genericHeader="method">
2 Estimation Methods
</sectionHeader>
<bodyText confidence="0.996627">
The DOP model and STSG formalism are de-
scribed in detail elsewhere, for instance in (Bod,
1998). The main difference with PCFGs is that
multiple derivations, using elementary trees with
a variety of sizes, can yield the same parse tree.
The probability of a parse p is therefore given by:
P(p) = Ed: ˆd=p P(d), where dˆ is the tree derived
by derivation d, P(d) = Ht∈d w(t) and w(t) gives
the weights of elementary trees t, which are com-
bined in the derivation d (here treated as a multi-
set).
</bodyText>
<subsectionHeader confidence="0.99059">
2.1 DOP1
</subsectionHeader>
<bodyText confidence="0.9997672">
In Bod’s original DOP implementation (Bod,
1993; Bod, 1998), henceforth DOP1, the weights
of an elementary tree t is defined as its relative
frequency (relative to other subtrees with the same
root label) in the tree bank. That is, the weight
</bodyText>
<page confidence="0.959946">
183
</page>
<equation confidence="0.991088666666667">
wi = w(ti) of an elementary tree ti is given by:
fi (1)
wi = Ej:r(tj)=r(ti)( fj),
</equation>
<bodyText confidence="0.999795642857143">
where fi = f(ti) gives the frequency of subtree ti
in a corpus, and r(ti) is the root label of ti.
In his critique of this method, (Johnson, 2002)
considers a situation where there is an STSG G
(the target grammar) with a specific set of sub-
trees (t1 ... tN) and specific values of the weights
(w1 ... wN) . He evaluates an estimation proce-
dure which produces a grammar G0 (the estimated
grammar), by looking at the difference between
the weights of G and the expected weights of G0.
Johnson’s test for consistency is thus based on
comparing the weight-distributions between target
grammar and estimated grammar2. I will therefore
refer to this test as the “weight-distribution test”.
</bodyText>
<figure confidence="0.72037">
t5 =S
A
</figure>
<figureCaption confidence="0.999922">
Figure 1: The example of (Johnson, 2002)
</figureCaption>
<bodyText confidence="0.99926825">
(Johnson, 2002) looks at an example grammar
G E STSG with the subtrees as in figure 1. John-
son considers the case where the weights of all
trees of the target grammar G are 0, except for
w7, which is necessarily 1, and w4 and w6 which
are w4 = p and w6 = 1 − p. He finds that the
expected values of the weights w4 and w6 of the
estimated grammar G0 are:
</bodyText>
<equation confidence="0.99997625">
E[w04] = p
2 + 2p, (2)
1 − p
E[w06] = 2 + 2p, (3)
</equation>
<bodyText confidence="0.995169041666667">
which are not equal to their target values for all
values of p where 0 &lt; p &lt; 1. This analysis
thus shows that DOP1 is unable to recover the true
weights of the given STSG, and hence the incon-
sistency of the estimator with respect to the class
of STSGs.
Although usually cited as showing the inad-
equacy of DOP1, Johnson’s example is in fact
2More precisely, it is based on evaluating the estimator’s
behavior for any weight-distribution possible in the STSG
model. (Prescher et al., 2003) give a more formal treatment
of bias and consistency in the context of DOP.
not suitable to distinguish DOP1 from alternative
methods, because no possible estimation proce-
dure can recover the true weights in the case con-
sidered. In the example there are only two com-
plete trees that can be observed in the training
data, corresponding to the trees t1 and t5. It is
easy to see that when generating examples with
the grammar in figure 1, the relative frequencies3
f1 ... f4 of the subtrees t1 ... t4 must all be the
same, and equal to the frequency of the complete
tree t1 which can be composed in the following
ways from the subtrees in the original grammar:
</bodyText>
<equation confidence="0.958092">
t1=t20t7=t30t7=t40t70t7. (4)
</equation>
<bodyText confidence="0.988183">
It follows that the expected frequencies of each of
these subtrees are:
</bodyText>
<equation confidence="0.948771">
E[f1] = E[f2] = E[f3] = E[f4] (5)
= w1 + w2w7 + w3w7 + w4w7w7
Similarly, the other frequencies are given by:
E[f5] = E[f6] = w5 + w6w7 (6)
E[f7] = 2 (w1 + w2w7 + w3w7
+w4w7w7) + w5 + w6w7
= 2E[f1] + E[f5]. (7)
</equation>
<bodyText confidence="0.9994408">
From these equations it is immediately clear
that, regardless of the amount of training data,
the problem is simply underdetermined. The val-
ues of 6 weights w1 ... w6 (w7 = 1) given only
2 frequencies f1 and f5 (and the constraint that
</bodyText>
<equation confidence="0.565804">
E6 fi
6 ( ) = 1) are not uniquely defined, and no
</equation>
<bodyText confidence="0.999573230769231">
possible estimation method will be able to reliably
recover the true weights.
The relevant test is whether for all possible
STSGs and in the limit of infinite data, the ex-
pected relative frequencies of trees given the es-
timated grammar, equal the observed relative fre-
quencies. I will refer to this test as the “frequency-
distribution test”. As it turns out, the DOP1
method also fails this more lenient test. The easi-
est way to show this, using again figure 1, is as fol-
lows. The weights w01 ... w07 of grammar G0 will –
by definition – be set to the relative frequencies of
the corresponding subtrees:
</bodyText>
<equation confidence="0.983436833333333">
� &apos;
/ = � .
sfi for i = 1... 6
wi _1 f7 �
(8)
1 for i = 7.
</equation>
<footnote confidence="0.679917">
3Throughout this paper I take frequencies fi to be relative
to the size of the corpus.
</footnote>
<figure confidence="0.999914722222222">
a
a
a
a
a
t7 =A
ts =S
A
a
t4 =S
A A
t1 = S
A
A
t2 =S
A
t3 =S
A A A
</figure>
<page confidence="0.983274">
184
</page>
<bodyText confidence="0.900099">
The grammar G0 will thus produce the complete
trees t1 and t5 with expected frequencies:
</bodyText>
<equation confidence="0.9965918">
E[f01] = w0 1 + w0 2w0 7 + w0 3w0 7 + w0 4w0 7w0 7
= 4 f1 (9)
Ej=1 fj
E[f05] = w05 + w0 6w7 = 2 6 5
Ej=1 fj
</equation>
<bodyText confidence="0.947934">
Now consider the two possible complete trees
t1 and t5, and the fraction of their frequencies
f1/f5. In the estimated grammar G0 this fraction
</bodyText>
<figure confidence="0.429723">
becomes:
</figure>
<figureCaption confidence="0.8210655">
Figure 2: Counter-example to the correction-
factor approaches
</figureCaption>
<figure confidence="0.996633717948718">
a
b
b
a
A
A
A
A
t1 = S
A
t4 = S
A
t3 = S
A
t2 = S
A
t9 =S
A A
t10 =A
a
t11 =A
b
b
a
a
a
b
b
a
b
t5 =S
A
t6 =S
A A A
t7 =S
A
t8 =S
A A A
. (10)
</figure>
<bodyText confidence="0.997351">
That is, in the limit of infinite data, the estima-
tion procedure not only –understandably– fails to
find the target grammar amongst the many gram-
mars that could have produced the observed fre-
quencies, it in fact chooses a grammar that could
never have produced these observed frequencies
at all. This example shows the DOP1 method is
biased and inconsistent for the STSG class in the
frequency-distribution test4.
</bodyText>
<subsectionHeader confidence="0.987765">
2.2 Correction-factor approaches
</subsectionHeader>
<bodyText confidence="0.997596833333333">
Based on similar observation, (Bonnema et al.,
1999; Bod, 2003) propose alternative estimation
methods, which involve a correction factor to
move probability mass from larger subtrees to
smaller ones. For instance, Bonnema et al. replace
equation (1) with:
</bodyText>
<equation confidence="0.881543">
fi
wi = 2−N(ti) , (12)
(fj)
</equation>
<bodyText confidence="0.9257695">
where N(ti) gives the number of internal nodes
in ti (such that 2−N(ti) is inversely proportional
to the number of possible derivations of ti). Sim-
ilarly, (Bod, 2003) changes the way frequencies
fi are counted, with a similar effect. This ap-
proach solves the specific problem shown in equa-
tion (11). However, the following example shows
that the correction-factor approaches cannot solve
the more general problem.
4Note that there are settings of the weights w1 ... w7 that
generate a frequency-distribution that could also have been
generated with a PCFG. The example given applies to such
distribution as well, and therefore also shows the inconsis-
tency of the DOP1 method for PCFG distributions.
Consider the STSG in figure 2. The expected
frequencies f1 ... f4 are here given by:
</bodyText>
<equation confidence="0.99865">
E[f1] = w1 + w5w11 + w6w10 + w9w10w11
E[f2] = w2 + w7w10 + w8w11 + w9w11w10
E[f3] = w3 + w5w10 + w8w10 + w9w10w10
E[f4] = w4 + w6w11 + w7w11 + w9w11w11
(13)
</equation>
<bodyText confidence="0.999366636363636">
Frequencies f5 ... f11 are again simple com-
binations of the frequencies f1 ... f4. Observa-
tions of these frequencies therefore do not add
any extra information, and the problem of find-
ing the weights of the target grammar is in general
again underdetermined. But consider the situation
where f3 = f4 = 0 and f1 &gt; 0 and f2 &gt; 0.
This constrains the possible solutions enormously.
If we solve the following equations for w3 ... w11
with the constraint that probabilities with the same
root label add up to 1: (i.e. E9i=1(wi) = 1,
</bodyText>
<equation confidence="0.991074285714286">
w10 + w11 = 1):
w3 + w5w10 + w8w10 + w9w10w10 = 0
w4 + w6w11 + w7w11 + w9w11w11 = 0,
we find, in addition to the obvious w3 = w4 = 0,
the following solutions: w10 = w6 = w7 = w9 =
0 ∨ w11 = w5 = w8 = w9 = 0 ∨ w5 =
w6 = w7 = w8 = w9 = 0. That is, if we ob-
</equation>
<bodyText confidence="0.998046363636364">
serve no occurrences of trees t3 and t4 in the train-
ing sample, we know that at least one subtree in
each derivation of these strings must have weight
zero. However, any estimation method that uses
the (relative) frequencies of subtrees and a (non-
zero) correction factor that is based on the size of
the subtrees, will give non-zero probabilities to all
weights w5 ... w11 if f1 &gt; 0 and f2 &gt; 0, as we
assumed. In other words, these weight estimation
methods for STSGs are also biased and inconsis-
tent in the frequency-distribution test.
</bodyText>
<figure confidence="0.69442975">
E[f01] 4n s 1 2f1 .(11)
E[f05] Pj=1 fj f5
2n s5
Pj=1 fj
</figure>
<page confidence="0.978619">
185
</page>
<subsectionHeader confidence="0.984653">
2.3 Shortest derivation estimators
</subsectionHeader>
<bodyText confidence="0.9719235">
Because the STSG formalism allows elementary
trees of arbitrary size, every parse tree in a tree
bank could in principle be incorporated in an
STSG grammar. That is, we can define a trivial
estimator with the following weights:
� fi if ti is an observed parse tree
</bodyText>
<equation confidence="0.780045">
wi =
0 otherwise
(14)
</equation>
<bodyText confidence="0.999916941176471">
Such an estimator is not particularly interesting,
because it does not generalize beyond the training
data. It is a point to note, however, that this esti-
mator is unbiased and consistent in the frequency-
distribution test. (Prescher et al., 2003) prove that
any unbiased estimator that uses the “all subtrees”
representation has the same property, and con-
clude that lack of bias is not a desired property.
(Zollmann and Sima’an, 2005) propose an esti-
mator based on held-out estimation. The training
corpus is split into an estimation corpus EC and a
held out corpus HC. The HC corpus is parsed
by searching for the shortest derivation of each
sentence, using only fragments from EC. The
elementary trees of the estimated STSG are as-
signed weights according to their usage frequen-
cies u1, ... , uN in these shortest derivations:
This approach solves the problem with bias de-
scribed above, while still allowing for consistency,
as Zollmann &amp; Sima’an prove. However, their
proof only concerns consistency in the frequency-
distribution test. As the corpus EC grows to be
infinitely large, every parse tree in HC will also
be found in EC, and the shortest derivation will
therefore in the limit only involve a single ele-
mentary tree: the parse tree itself. Target STSGs
with non-zero weights on smaller elementary trees
will thus not be identified correctly, even with an
infinitely large training set. In other words, the
Zollmann &amp; Sima’an method, and other methods
that converge to the “complete parse tree” solution
such as LS-DOP (Bod, 2003) and BackOff-DOP
(Sima’an and Buratto, 2003), are inconsistent in
the weight-distribution test.
</bodyText>
<sectionHeader confidence="0.997525" genericHeader="method">
3 Discussion &amp; Conclusions
</sectionHeader>
<bodyText confidence="0.9998962">
A desideratum for parameter estimation methods
is that they converge to the correct parameters with
infinitely many data – that is, we like an estima-
tor to be consistent. The STSG formalism, how-
ever, allows for many different derivations of the
same parse tree, and for many different grammars
to generate the same frequency-distribution. Con-
sistency in the weight-distribution test is there-
fore too stringent a criterion. We have shown that
DOP1 and methods based on correction factors
also fail the weaker frequency-distribution test.
However, the only current estimation methods
that are consistent in the frequency-distribution
test, have the linguistically undesirable property
of converging to a distribution with all probabil-
ity mass in complete parse trees. Although these
method fail the weight-distribution test for the
whole class of STSGs, we argued earlier that this
test is not the appropriate test either. Both estima-
tion methods for STSGs and the criteria for eval-
uating them, thus require thorough rethinking. In
forthcoming work we therefore study yet another
estimator, and the linguistically motivated evalua-
tion criterion of convergence to a maximally gen-
eral STSG consistent with the training data5.
</bodyText>
<sectionHeader confidence="0.999455" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995811846153846">
Rens Bod. 1993. Using an annotated corpus as a stochastic
grammar. In Proceedings EACL’93, pp. 37–44.
Rens Bod. 1998. Beyond Grammar: An experience-based
theory of language. CSLI, Stanford, CA.
Rens Bod. 2003. An efficient implementation of a new DOP
model. In Proceedings EACL’03.
Remko Bonnema, Paul Buying, and Remko Scha. 1999.
A new probability model for data oriented parsing. In
Paul Dekker, editor, Proceedings of the Twelfth Amster-
dam Colloquium. ILLC, University of Amsterdam.
Mark Johnson. 2002. The DOP estimation method is biased
and inconsistent. Computational Linguistics, 28(1):71–
76.
D. Prescher, R. Scha, K. Sima’an, and A. Zollmann. 2003.
On the statistical consistency of DOP estimators. In Pro-
ceedings CLIN’03, Antwerp, Belgium.
Remko Scha. 1990. Taaltheorie en taaltechnologie; compe-
tence en performance. In R. de Kort and G.L.J. Leerdam,
eds, Computertoepassingen in de Neerlandistiek, pages 7–
22. LVVN, Almere.http://iaaa.nl/rs/LeerdamE.html.
Khalil Sima’an and Luciano Buratto (2003). Backoff pa-
rameter estimation for the DOP model. In Proceedings
ECML’03, pp. 373–384. Berlin: Springer Verlag.
Andreas Zollmann and Khalil Sima’an. 2005. A consistent
and efficient estimator for data-oriented parsing. Journal
of Automata, Languages and Combinatorics. In press.
</reference>
<footnote confidence="0.866474666666667">
5The author is funded by NWO, project nr. 612.066.405,
and would like to thank the anonymous reviewers and several
colleagues for comments.
</footnote>
<equation confidence="0.847871">
(15)
Ej:r(tj)=r(ti) uj
wi =
ui
</equation>
<page confidence="0.992987">
186
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.846583">
<title confidence="0.999786">Theoretical Evaluation of Estimation Methods for Data-Oriented Parsing</title>
<author confidence="0.999788">Willem Zuidema</author>
<affiliation confidence="0.9993445">Institute for Logic, Language and Computation University of Amsterdam</affiliation>
<address confidence="0.891999">Plantage Muidergracht 24, 1018 TV, Amsterdam, the Netherlands.</address>
<email confidence="0.998266">jzuidema@science.uva.nl</email>
<abstract confidence="0.994303777777778">We analyze estimation methods for Data- Oriented Parsing, as well as the theoretical criteria used to evaluate them. We show that all current estimation methods are inconsistent in the “weight-distribution test”, and argue that these results force us to rethink both the methods proposed and the criteria used.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Rens Bod</author>
</authors>
<title>Using an annotated corpus as a stochastic grammar.</title>
<date>1993</date>
<booktitle>In Proceedings EACL’93,</booktitle>
<pages>37--44</pages>
<contexts>
<context position="1921" citStr="Bod, 1993" startWordPosition="311" endWordPosition="312">elementary trees of the grammar. In most DOP models the grammar used is an STSG with, in principle, all subtrees1 of the trees in the tree bank as elementary trees. For disambiguation, the best parse tree is taken to be the most probable parse according to the weights of the grammar. Several methods have been proposed to decide on the weights based on observed tree frequencies 1A subtree t&apos; of a parse tree t is a tree such that every node i&apos; in t&apos; equals a node i in t, and i&apos; either has no daughters or the same daughter nodes as i. in a tree bank. The first such method is now known as “DOP1” (Bod, 1993). In combination with some heuristic constraints on the allowed subtrees, it has been remarkably successful on small tree banks. Despite this empirical success, (Johnson, 2002) argued that it is inadequate because it is biased and inconsistent. His criticism spearheaded a number of other methods, including (Bonnema et al., 1999; Bod, 2003; Sima’an and Buratto, 2003; Zollmann and Sima’an, 2005), and will be the starting point of our analysis. As it turns out, the DOP1 method really is biased and inconsistent, but not for the reasons Johnson gives, and it really is inadequate, but not because it</context>
<context position="3299" citStr="Bod, 1993" startWordPosition="544" endWordPosition="545">timation as an important open problem. 2 Estimation Methods The DOP model and STSG formalism are described in detail elsewhere, for instance in (Bod, 1998). The main difference with PCFGs is that multiple derivations, using elementary trees with a variety of sizes, can yield the same parse tree. The probability of a parse p is therefore given by: P(p) = Ed: ˆd=p P(d), where dˆ is the tree derived by derivation d, P(d) = Ht∈d w(t) and w(t) gives the weights of elementary trees t, which are combined in the derivation d (here treated as a multiset). 2.1 DOP1 In Bod’s original DOP implementation (Bod, 1993; Bod, 1998), henceforth DOP1, the weights of an elementary tree t is defined as its relative frequency (relative to other subtrees with the same root label) in the tree bank. That is, the weight 183 wi = w(ti) of an elementary tree ti is given by: fi (1) wi = Ej:r(tj)=r(ti)( fj), where fi = f(ti) gives the frequency of subtree ti in a corpus, and r(ti) is the root label of ti. In his critique of this method, (Johnson, 2002) considers a situation where there is an STSG G (the target grammar) with a specific set of subtrees (t1 ... tN) and specific values of the weights (w1 ... wN) . He evaluat</context>
</contexts>
<marker>Bod, 1993</marker>
<rawString>Rens Bod. 1993. Using an annotated corpus as a stochastic grammar. In Proceedings EACL’93, pp. 37–44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rens Bod</author>
</authors>
<title>Beyond Grammar: An experience-based theory of language. CSLI,</title>
<date>1998</date>
<location>Stanford, CA.</location>
<contexts>
<context position="1239" citStr="Bod, 1998" startWordPosition="178" endWordPosition="179">SGs) are a simple generalization of Probabilistic Context Free Grammars, where the productive elements are not rewrite rules but elementary trees of arbitrary size. The increased flexibility allows STSGs to model a variety of syntactic and statistical dependencies, using relatively complex primitives but just a single and extremely simple global rule: substitution. STSGs can be seen as Stochastic Tree Adjoining Grammars without the adjunction operation. STSGs are the underlying formalism of most instantiations of an approach to statistical parsing known as “Data-Oriented Parsing” (Scha, 1990; Bod, 1998). In this approach the subtrees of the trees in a tree bank are used as elementary trees of the grammar. In most DOP models the grammar used is an STSG with, in principle, all subtrees1 of the trees in the tree bank as elementary trees. For disambiguation, the best parse tree is taken to be the most probable parse according to the weights of the grammar. Several methods have been proposed to decide on the weights based on observed tree frequencies 1A subtree t&apos; of a parse tree t is a tree such that every node i&apos; in t&apos; equals a node i in t, and i&apos; either has no daughters or the same daughter no</context>
<context position="2845" citStr="Bod, 1998" startWordPosition="461" endWordPosition="462">ma et al., 1999; Bod, 2003; Sima’an and Buratto, 2003; Zollmann and Sima’an, 2005), and will be the starting point of our analysis. As it turns out, the DOP1 method really is biased and inconsistent, but not for the reasons Johnson gives, and it really is inadequate, but not because it is biased and inconsistent. In this note, we further show that alternative methods that have been proposed, only partly remedy the problems with DOP1, leaving weight estimation as an important open problem. 2 Estimation Methods The DOP model and STSG formalism are described in detail elsewhere, for instance in (Bod, 1998). The main difference with PCFGs is that multiple derivations, using elementary trees with a variety of sizes, can yield the same parse tree. The probability of a parse p is therefore given by: P(p) = Ed: ˆd=p P(d), where dˆ is the tree derived by derivation d, P(d) = Ht∈d w(t) and w(t) gives the weights of elementary trees t, which are combined in the derivation d (here treated as a multiset). 2.1 DOP1 In Bod’s original DOP implementation (Bod, 1993; Bod, 1998), henceforth DOP1, the weights of an elementary tree t is defined as its relative frequency (relative to other subtrees with the same </context>
</contexts>
<marker>Bod, 1998</marker>
<rawString>Rens Bod. 1998. Beyond Grammar: An experience-based theory of language. CSLI, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rens Bod</author>
</authors>
<title>An efficient implementation of a new DOP model.</title>
<date>2003</date>
<booktitle>In Proceedings EACL’03.</booktitle>
<contexts>
<context position="2261" citStr="Bod, 2003" startWordPosition="363" endWordPosition="364">hts based on observed tree frequencies 1A subtree t&apos; of a parse tree t is a tree such that every node i&apos; in t&apos; equals a node i in t, and i&apos; either has no daughters or the same daughter nodes as i. in a tree bank. The first such method is now known as “DOP1” (Bod, 1993). In combination with some heuristic constraints on the allowed subtrees, it has been remarkably successful on small tree banks. Despite this empirical success, (Johnson, 2002) argued that it is inadequate because it is biased and inconsistent. His criticism spearheaded a number of other methods, including (Bonnema et al., 1999; Bod, 2003; Sima’an and Buratto, 2003; Zollmann and Sima’an, 2005), and will be the starting point of our analysis. As it turns out, the DOP1 method really is biased and inconsistent, but not for the reasons Johnson gives, and it really is inadequate, but not because it is biased and inconsistent. In this note, we further show that alternative methods that have been proposed, only partly remedy the problems with DOP1, leaving weight estimation as an important open problem. 2 Estimation Methods The DOP model and STSG formalism are described in detail elsewhere, for instance in (Bod, 1998). The main diffe</context>
<context position="8346" citStr="Bod, 2003" startWordPosition="1542" endWordPosition="1543">t2 = S A t9 =S A A t10 =A a t11 =A b b a a a b b a b t5 =S A t6 =S A A A t7 =S A t8 =S A A A . (10) That is, in the limit of infinite data, the estimation procedure not only –understandably– fails to find the target grammar amongst the many grammars that could have produced the observed frequencies, it in fact chooses a grammar that could never have produced these observed frequencies at all. This example shows the DOP1 method is biased and inconsistent for the STSG class in the frequency-distribution test4. 2.2 Correction-factor approaches Based on similar observation, (Bonnema et al., 1999; Bod, 2003) propose alternative estimation methods, which involve a correction factor to move probability mass from larger subtrees to smaller ones. For instance, Bonnema et al. replace equation (1) with: fi wi = 2−N(ti) , (12) (fj) where N(ti) gives the number of internal nodes in ti (such that 2−N(ti) is inversely proportional to the number of possible derivations of ti). Similarly, (Bod, 2003) changes the way frequencies fi are counted, with a similar effect. This approach solves the specific problem shown in equation (11). However, the following example shows that the correction-factor approaches can</context>
<context position="12748" citStr="Bod, 2003" startWordPosition="2336" endWordPosition="2337">ollmann &amp; Sima’an prove. However, their proof only concerns consistency in the frequencydistribution test. As the corpus EC grows to be infinitely large, every parse tree in HC will also be found in EC, and the shortest derivation will therefore in the limit only involve a single elementary tree: the parse tree itself. Target STSGs with non-zero weights on smaller elementary trees will thus not be identified correctly, even with an infinitely large training set. In other words, the Zollmann &amp; Sima’an method, and other methods that converge to the “complete parse tree” solution such as LS-DOP (Bod, 2003) and BackOff-DOP (Sima’an and Buratto, 2003), are inconsistent in the weight-distribution test. 3 Discussion &amp; Conclusions A desideratum for parameter estimation methods is that they converge to the correct parameters with infinitely many data – that is, we like an estimator to be consistent. The STSG formalism, however, allows for many different derivations of the same parse tree, and for many different grammars to generate the same frequency-distribution. Consistency in the weight-distribution test is therefore too stringent a criterion. We have shown that DOP1 and methods based on correctio</context>
</contexts>
<marker>Bod, 2003</marker>
<rawString>Rens Bod. 2003. An efficient implementation of a new DOP model. In Proceedings EACL’03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remko Bonnema</author>
<author>Paul Buying</author>
<author>Remko Scha</author>
</authors>
<title>A new probability model for data oriented parsing.</title>
<date>1999</date>
<booktitle>Proceedings of the Twelfth Amsterdam Colloquium. ILLC,</booktitle>
<editor>In Paul Dekker, editor,</editor>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="2250" citStr="Bonnema et al., 1999" startWordPosition="359" endWordPosition="362"> to decide on the weights based on observed tree frequencies 1A subtree t&apos; of a parse tree t is a tree such that every node i&apos; in t&apos; equals a node i in t, and i&apos; either has no daughters or the same daughter nodes as i. in a tree bank. The first such method is now known as “DOP1” (Bod, 1993). In combination with some heuristic constraints on the allowed subtrees, it has been remarkably successful on small tree banks. Despite this empirical success, (Johnson, 2002) argued that it is inadequate because it is biased and inconsistent. His criticism spearheaded a number of other methods, including (Bonnema et al., 1999; Bod, 2003; Sima’an and Buratto, 2003; Zollmann and Sima’an, 2005), and will be the starting point of our analysis. As it turns out, the DOP1 method really is biased and inconsistent, but not for the reasons Johnson gives, and it really is inadequate, but not because it is biased and inconsistent. In this note, we further show that alternative methods that have been proposed, only partly remedy the problems with DOP1, leaving weight estimation as an important open problem. 2 Estimation Methods The DOP model and STSG formalism are described in detail elsewhere, for instance in (Bod, 1998). The</context>
<context position="8334" citStr="Bonnema et al., 1999" startWordPosition="1538" endWordPosition="1541">S A t4 = S A t3 = S A t2 = S A t9 =S A A t10 =A a t11 =A b b a a a b b a b t5 =S A t6 =S A A A t7 =S A t8 =S A A A . (10) That is, in the limit of infinite data, the estimation procedure not only –understandably– fails to find the target grammar amongst the many grammars that could have produced the observed frequencies, it in fact chooses a grammar that could never have produced these observed frequencies at all. This example shows the DOP1 method is biased and inconsistent for the STSG class in the frequency-distribution test4. 2.2 Correction-factor approaches Based on similar observation, (Bonnema et al., 1999; Bod, 2003) propose alternative estimation methods, which involve a correction factor to move probability mass from larger subtrees to smaller ones. For instance, Bonnema et al. replace equation (1) with: fi wi = 2−N(ti) , (12) (fj) where N(ti) gives the number of internal nodes in ti (such that 2−N(ti) is inversely proportional to the number of possible derivations of ti). Similarly, (Bod, 2003) changes the way frequencies fi are counted, with a similar effect. This approach solves the specific problem shown in equation (11). However, the following example shows that the correction-factor ap</context>
</contexts>
<marker>Bonnema, Buying, Scha, 1999</marker>
<rawString>Remko Bonnema, Paul Buying, and Remko Scha. 1999. A new probability model for data oriented parsing. In Paul Dekker, editor, Proceedings of the Twelfth Amsterdam Colloquium. ILLC, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Johnson</author>
</authors>
<title>The DOP estimation method is biased and inconsistent.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>1</issue>
<pages>76</pages>
<contexts>
<context position="2097" citStr="Johnson, 2002" startWordPosition="336" endWordPosition="337">ambiguation, the best parse tree is taken to be the most probable parse according to the weights of the grammar. Several methods have been proposed to decide on the weights based on observed tree frequencies 1A subtree t&apos; of a parse tree t is a tree such that every node i&apos; in t&apos; equals a node i in t, and i&apos; either has no daughters or the same daughter nodes as i. in a tree bank. The first such method is now known as “DOP1” (Bod, 1993). In combination with some heuristic constraints on the allowed subtrees, it has been remarkably successful on small tree banks. Despite this empirical success, (Johnson, 2002) argued that it is inadequate because it is biased and inconsistent. His criticism spearheaded a number of other methods, including (Bonnema et al., 1999; Bod, 2003; Sima’an and Buratto, 2003; Zollmann and Sima’an, 2005), and will be the starting point of our analysis. As it turns out, the DOP1 method really is biased and inconsistent, but not for the reasons Johnson gives, and it really is inadequate, but not because it is biased and inconsistent. In this note, we further show that alternative methods that have been proposed, only partly remedy the problems with DOP1, leaving weight estimatio</context>
<context position="3727" citStr="Johnson, 2002" startWordPosition="625" endWordPosition="626"> Ht∈d w(t) and w(t) gives the weights of elementary trees t, which are combined in the derivation d (here treated as a multiset). 2.1 DOP1 In Bod’s original DOP implementation (Bod, 1993; Bod, 1998), henceforth DOP1, the weights of an elementary tree t is defined as its relative frequency (relative to other subtrees with the same root label) in the tree bank. That is, the weight 183 wi = w(ti) of an elementary tree ti is given by: fi (1) wi = Ej:r(tj)=r(ti)( fj), where fi = f(ti) gives the frequency of subtree ti in a corpus, and r(ti) is the root label of ti. In his critique of this method, (Johnson, 2002) considers a situation where there is an STSG G (the target grammar) with a specific set of subtrees (t1 ... tN) and specific values of the weights (w1 ... wN) . He evaluates an estimation procedure which produces a grammar G0 (the estimated grammar), by looking at the difference between the weights of G and the expected weights of G0. Johnson’s test for consistency is thus based on comparing the weight-distributions between target grammar and estimated grammar2. I will therefore refer to this test as the “weight-distribution test”. t5 =S A Figure 1: The example of (Johnson, 2002) (Johnson, 20</context>
</contexts>
<marker>Johnson, 2002</marker>
<rawString>Mark Johnson. 2002. The DOP estimation method is biased and inconsistent. Computational Linguistics, 28(1):71– 76.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Prescher</author>
<author>R Scha</author>
<author>K Sima’an</author>
<author>A Zollmann</author>
</authors>
<title>On the statistical consistency of DOP estimators.</title>
<date>2003</date>
<booktitle>In Proceedings CLIN’03,</booktitle>
<location>Antwerp, Belgium.</location>
<marker>Prescher, Scha, Sima’an, Zollmann, 2003</marker>
<rawString>D. Prescher, R. Scha, K. Sima’an, and A. Zollmann. 2003. On the statistical consistency of DOP estimators. In Proceedings CLIN’03, Antwerp, Belgium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Remko Scha</author>
</authors>
<title>Taaltheorie en taaltechnologie; competence en performance. In</title>
<date>1990</date>
<note>eds, Computertoepassingen in de Neerlandistiek, pages 7– 22. LVVN, Almere.http://iaaa.nl/rs/LeerdamE.html.</note>
<contexts>
<context position="1227" citStr="Scha, 1990" startWordPosition="176" endWordPosition="177">nceforth, STSGs) are a simple generalization of Probabilistic Context Free Grammars, where the productive elements are not rewrite rules but elementary trees of arbitrary size. The increased flexibility allows STSGs to model a variety of syntactic and statistical dependencies, using relatively complex primitives but just a single and extremely simple global rule: substitution. STSGs can be seen as Stochastic Tree Adjoining Grammars without the adjunction operation. STSGs are the underlying formalism of most instantiations of an approach to statistical parsing known as “Data-Oriented Parsing” (Scha, 1990; Bod, 1998). In this approach the subtrees of the trees in a tree bank are used as elementary trees of the grammar. In most DOP models the grammar used is an STSG with, in principle, all subtrees1 of the trees in the tree bank as elementary trees. For disambiguation, the best parse tree is taken to be the most probable parse according to the weights of the grammar. Several methods have been proposed to decide on the weights based on observed tree frequencies 1A subtree t&apos; of a parse tree t is a tree such that every node i&apos; in t&apos; equals a node i in t, and i&apos; either has no daughters or the same</context>
</contexts>
<marker>Scha, 1990</marker>
<rawString>Remko Scha. 1990. Taaltheorie en taaltechnologie; competence en performance. In R. de Kort and G.L.J. Leerdam, eds, Computertoepassingen in de Neerlandistiek, pages 7– 22. LVVN, Almere.http://iaaa.nl/rs/LeerdamE.html.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Khalil Sima’an</author>
<author>Luciano Buratto</author>
</authors>
<title>Backoff parameter estimation for the DOP model.</title>
<date>2003</date>
<booktitle>In Proceedings ECML’03,</booktitle>
<pages>373--384</pages>
<publisher>Springer Verlag.</publisher>
<location>Berlin:</location>
<marker>Sima’an, Buratto, 2003</marker>
<rawString>Khalil Sima’an and Luciano Buratto (2003). Backoff parameter estimation for the DOP model. In Proceedings ECML’03, pp. 373–384. Berlin: Springer Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Zollmann</author>
<author>Khalil Sima’an</author>
</authors>
<title>A consistent and efficient estimator for data-oriented parsing.</title>
<date>2005</date>
<journal>Journal of Automata, Languages and Combinatorics.</journal>
<note>In press.</note>
<marker>Zollmann, Sima’an, 2005</marker>
<rawString>Andreas Zollmann and Khalil Sima’an. 2005. A consistent and efficient estimator for data-oriented parsing. Journal of Automata, Languages and Combinatorics. In press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>