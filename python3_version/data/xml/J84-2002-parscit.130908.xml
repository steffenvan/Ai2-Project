<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.685609">
The Pragmatics of Referring and
the Modality of Communication&apos;
Philip R. Cohen
Laboratory for Artificial Intelligence Research
Fairchild Camera and Instrument Corporation
</title>
<author confidence="0.605915">
Palo Alto, CA
</author>
<bodyText confidence="0.997461333333333">
This paper presents empirical results comparing spoken and keyboard communication. It is
shown that speakers attempt to achieve more detailed goals in giving instructions than do users
of keyboards. One specific kind of fine-grained communicative act, a request that the hearer
identify the referent of a noun phrase, is shown to dominate spoken instruction-giving
discourse, but is nearly absent from keyboard discourse. Most important, these requests are
only achieved &amp;quot;indirectly&amp;quot;. — through utterances whose surface forms do not explicitly convey
the speakers&apos; intent. A plan-based theory of communication is shown to uncover the speakers&apos;
intentions underlying many cases of indirect identification requests found in the corpus, once an
action for referent identification has been posited. In so doing, the theory demonstrates how
intent (or plan) recognition can be applied in reasoning about the use of a description. As a
consequence of this approach, it is shown that the conditions on the planning of successful
identification requests account for Searle&apos;s conditions on the act of referring. It is concluded
that intent recognition will need to be a central focus for pragmatics/discourse components of
future speech understanding systems, and that computational linguistics needs to develop
formalisms for reasoning about speakers&apos; use of descriptions.
</bodyText>
<sectionHeader confidence="0.99868" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999158583333333">
As natural language interaction with computers becomes
more widespread, systems&apos; abilities to engage users in
discourse will become increasingly important. These
capabilities will be especially in demand when users can
speak naturally to their machines. Although it is widely
suspected that spoken language is different from written
language, the question of precisely what the differences
are has only recently become a topic of computational
linguistic research. Previous investigations have concen-
trated on syntactic differences between spoken and writ-
ten language (Hindle 1983, Kroch and Hindle 1982,
Thompson 1980), with the goal of adapting parsing tech-
niques to handle the syntax of spoken language. Howev-
er, even if this goal were achieved, a system needs to be
prepared to handle any unique properties of the discourse
structure of spoken interaction if it is to be successful in
conducting a dialogue.
Of course, there has been much work on discourse
processing within computational linguistics (e.g., Grosz
1977, Sidner 1979, Webber 1978), and any future
systems will undoubtedly incorporate previously success-
ful techniques. However, one suspects that the coverage
This research was supported primarily by the National Institute of
Education under contract US-N1E-C-400-76-0116 to the Center for
the Study of Reading of the University of Illinois and Bolt Beranek and
Newman Inc., and in part by the Oregon State University. The paper
was written at the Fairchild Camera and Instrument Corporation, and
revised at SRI International. The revisions of this paper have been
made possible by a gift from the System Development Foundation to
SRI as part of a coordinated research effort with the Center for the
Study of Language and Information, Stanford University. Author&apos;s
current address: Artificial Intelligence Center, SRI International, Menlo
Park, CA 94035.
Copyright 1984 by the Association for Computational Linguistics, Permission to copy without fee all or part of this material is granted provided that
the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To copy
otherwise, or to republish, requires a fee and/or specific permission.
</bodyText>
<footnote confidence="0.415143">
0362-613X/84 / 020097-50$03.00
</footnote>
<note confidence="0.504333">
Computational Linguistics Volume 10, Number 2, April-June 1984 97
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<bodyText confidence="0.995084181818182">
of discourse processing algorithms may depend on the
corpora from which they were developed, and many of
those reflect keyboard-mediated dialogue. Thus, to
determine whether and how current techniques need to
be adapted to the way people speak, research is needed
to compare the discourse structure of spoken and
keyboard interaction.
This paper presents an empirical study and theoretical
analysis of utterance form and function as determined by
the communication modality. The two initial objectives
are:
</bodyText>
<listItem confidence="0.821223833333333">
1. To develop an empirical methodology for analyzing
discourse pragmatics.
2. To use that methodology to identify both the goals
that speakers attempt to achieve in spoken and
keyboard modalities, and the discourse and sentence
structures they use in achieving those goals.
</listItem>
<bodyText confidence="0.977437825396826">
These objectives are investigated in a study of instruc-
tion-giving discourse, a communication task that inti-
mately ties utterance function to a nonlinguistic task
being accomplished by the conversants. In addition to
depending on the communication task, the goals people
achieve with language are a function, in part, of the
communication situation — i.e., of how the speaker(s),
hearer(s), object(s) under discussion, and discourse itself
are situated in the world. For example, the utterance
&amp;quot;On the table is a little yellow piece of rubber,&amp;quot; would be
interpreted quite differently in a narrative than in a set of
instructions for assembling an object. The communi-
cation situation helps to determine the pragmatics of
reference — what speakers intend hearers to do with refer-
ring expressions. Thus, a third goal of this paper, a
subsidiary to objective 2 is to consider
3. How the speakers&apos; goals for the interpretation of
referring expressions are expressed and achieved in
different modalities.
Results indicate that speakers attempt to achieve more
detailed referential goals in giving instructions than do
users of keyboards. That is, speakers explicitly request
hearers to identify the referents of noun phrases (NPs),
but users of keyboards do not. Instead, the referential
goals achieved by these requests are subsumed by other
requested actions. Most importantly, these identification
requests are only achieved &amp;quot;indirectly&amp;quot; — through utter-
ances whose surface forms do not explicitly convey the
speakers&apos; intent.
Current theories propose that the speaker&apos;s intentions
underlying the use of indirect speech acts can be recog-
nized as a by-product of a more general, independently
motivated process of inferring a speaker&apos;s plans (Bruce
1983, Cohen and Perrault 1979, Cohen and Levesque
1980, Perrault and Allen 1980, Schmidt 1975, Sidner and
Israel 1981). Essentially, illocutionary acts, which
communicate the speaker&apos;s intentions, are regarded as
steps in a speaker&apos;s plan, just as physical acts are.
Furthermore, just as observing an agent&apos;s behavior may
lead one to infer what the agent is trying to do, so too
can the observation/understanding of a speaker&apos;s utter-
ance lead an observer to infer the speaker&apos;s intentions.
This approach has led to formal and computational
models of discourse processing (Allen 1979; Allen and
Perrault 1980; Brachman et al. 1979; Cohen and
Levesque, in preparation; Sidner et al. 1981). Although
these provide a more comprehensive account of indirect
speech act interpretation than previous linguistic or philo-
sophical approaches, they have not been tested against a
corpus other than the ones that supported their creation
(e.g., Horrigan 1977). Therefore, as an adequacy test,
the fourth objective for this paper is:
4. To evaluate how well a plan-based theory of
communication can uncover the intentions underly-
ing the use of many surface forms in the transcripts.
The theory is shown to account for approximately
70% of the indirect requests for referent identification
found in the transcripts, once an action for referent iden-
tification has been posited. An important aspect of the
account is the demonstration that speakers and hearers
can reason about referent identification much as they
reason about other actions and plans. Hence, the last
goal for this paper is to
</bodyText>
<listItem confidence="0.714280666666667">
5. Contrast the plan-based analysis of referring, and
the flexibility it allows, with Searle&apos;s account of
reference as a speech act.
</listItem>
<bodyText confidence="0.995771285714286">
I show that Searle&apos;s analysis cannot account for many
of the examples treated here, and that those examples it
does cover can also be handled by the present analysis.
The conclusions I draw are specific to the conversa-
tional task of giving instructions about objects physically
present to the hearer. This task was chosen for four
reasons:
</bodyText>
<listItem confidence="0.99735155">
• First, it was expected that speakers would frequently
issue requests. Because requests dominate interactions
with many question-answering systems, and with most
conceivable interactive applications of natural
language processing, they have been extensively
studied in computational linguistics.
• Second, because the task is simple and constrained, it
provides an excellent adequacy test for proposed theo-
ries and computational techniques; any theory of
communication that cannot handle the phenomena of
this study can hardly be called general. However,
since the domain is functionally similar to those of
various keyboard-based systems (Brachman et al.
1979, Robinson et al. 1980, Winograd 1972), the data
and results of the study may suggest directions for
extending those systems.
• Third, the domain is similar to those analyzed by other
researchers (Chapanis et al. 1972, Chapanis et al.
1977, Grosz 1977), and thus the dialogues could serve
to confirm or refute their results.
</listItem>
<note confidence="0.7058865">
98 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<listItem confidence="0.587306333333333">
• Finally, instructions play a crucially important role in
people&apos;s everyday lives — success in industrial, academ-
ic, and bureaucratic tasks, for example, requires the
</listItem>
<bodyText confidence="0.99983859375">
following of instructions. Children are initially
instructed face-to-face, but they eventually learn to
follow written instructions. The present study, though
not this paper, should ultimately provide a window on
how the language of written instructions differs from
that of instructional dialogue.
In summary, this paper applies an empirical methodol-
ogy for analyzing discourse pragmatics to compare
spoken and keyboard language for an instruction-giving
task. The primary differentiating phenomenon, the use
of explicit identification requests, is used as an adequacy
test for a plan-based theory of communication.
Conversely, the theory is used to explicate how such
communicative actions might be analyzed. Finally, the
theory gives rise to a pragmatic analysis of referring that
subsumes Searle&apos;s (1969).
The remainder of this paper is organized as follows:
Section 2 discusses previous- research in a number of
related areas. Section 3 isolates the phenomena of inter-
est — referent identification. Section 4 describes the
study and the method of discourse analysis, and Section 5
presents and discusses the empirical results. Section 6
sketches the plan-based theory of communication and
applies the theory to key examples. Section 7 counters
possible alternative explanations that would purport to
explain the data without recourse to an analysis of speak-
er intent. Section 8 compares the analysis with Searle&apos;s,
and suggests generalizations based on independently
motivated principles. Finally, the appendices contain the
materials, transcripts, and codings on which these
analyses are based. A full set of coded transcripts may
be obtained on request.
</bodyText>
<sectionHeader confidence="0.837138" genericHeader="method">
2 Previous Research
</sectionHeader>
<bodyText confidence="0.999966878787879">
Four traditions of research bear on the problems at hand:
empirical work on differences between spoken and writ-
ten language, discourse analysis, psychological studies of
referential communication, and computational linguistics
studies of discourse that have been based on observation
of actual communicative interaction.
The subject of oral/written language comparisons has
received much attention from researchers: Anthropolo-
gists have traditionally studied characteristics of &amp;quot;oral&amp;quot;
and &amp;quot;literate&amp;quot; cultures; human-factors researchers have
investigated the opportunities that particular modalities
afford for effective communication; and educational
psychologists, using empirical and anthropological meth-
ods, have sought answers to children&apos;s reading and writ-
ing problems in the study of oral/written language
differences.
Rubin (1980) discusses methodological weaknesses in
many oral/written studies — weaknesses that stem from a
simplistic division of language experiences into &amp;quot;oral&amp;quot;
and &amp;quot;written&amp;quot;. Instead, she classifies language experi-
ences in terms of their characteristic values on several
dimensions such as: the use of voice or print, the ability
of &amp;quot;speaker&amp;quot; and &amp;quot;hearer&amp;quot; to interact, their spatial
and/or temporal commonality, their mutual involvement
in the discourse, and the concreteness of the referents.
Face-to-face conversations about physically present
objects are seen to lie at one extreme within this
&amp;quot;communication space&amp;quot; (with &amp;quot;positive&amp;quot; values on the
above dimensions), whereas written text is at the oppo-
site. Other language experiences that differ along these
dimensions include communication by telephone,
keyboard, audiotape, picturephone, writing, etc.2 Rubin
reports that many studies comparing language experi-
ences present conclusions about oral/written language
differences even though the language experiences differ
from one another along multiple dimensions. In such
cases it is not clear if the observed differences result, for
example, from the presence of voice, the ability to inter-
act, or both.
There is evidence that at least some quantitative
linguistic and efficacy results are primarily determined by
the presence of voice in the communication modality. A
series of studies by Chapanis and colleagues (Chapanis et
al. 1972, Chapanis et al. 1977) compared problem-solv-
ing effectiveness among teams communicating in face-to-
face, voice only, written, keyboard, and other
communication modalities. Dependent measures
included problem solution time, number of words,
sentences, utterances, etc. Results indicate that problems
are solved twice as fast in vocal modalities as they are in
written ones, even though communicators use twice as
many words when speaking.3 Although motivating the
development of speech-understanding systems, these
results unfortunately tell us little about how the process-
ing of spoken utterances differs from the processing of
written ones.
Other research has compared the syntax of spoken and
written discourse. The primary findings are: Written
language is syntactically more integrated than spoken,
employing nominalizations, participles, complements,
relative clauses, etc. (Chafe 1982); and spoken language
exhibits regular patterns of false starts and hesitations
(Hindle 1983, Kroch and Hindle 1982). The former
results can help a system designer to determine which
syntactic constructs to emphasize in a grammar for pars-
ing. The latter results are more useful to computational
</bodyText>
<footnote confidence="0.69201575">
2 This approach essentially characterizes language situations as multidi-
mensional vectors whose components, describing the above dimensions,
are binary values (e.g., +/- voice). Thus, it is assumed that neighboring
modalities afford equal communicative possibilities in all dimensions in
which they are the same. This is obviously untrue for the dimension of
interaction.
3 Thompson (1980) has confirmed Chapanis et al.&apos;s results for face-to-
face and keyboard modalities.
</footnote>
<note confidence="0.5618475">
Computational Linguistics Volume 10, Number 3-4, July-December 1984 99
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<bodyText confidence="0.990783945945947">
linguistics. Not only are regularities in nongrammatical
speech identified, but a class of &amp;quot;editing&amp;quot; rules is
provided that can make such utterances parsable.
Current work on relaxing grammar rules and on parsing
ill-formed input (Hayes and Mouradian 1981, Kwasny
and Sondheimer 1981, Weischedel and Black 1980) is in
much the same spirit.
The purposes at hand require analyses of the pragmat-
ic and discourse structure of actual dialogues. Grosz
(1977) and Bruce (1981) (among others) have shown
how such discourse analyses can have direct implications
for algorithm design. In their work, transcripts of
dialogues were collected and analyzed, leading to the
development of algorithms for speech-understanding
systems (Walker 1978, Woods et al. 1976).4 Grosz&apos;
analyses indicate that anaphoric reference in task-orient-
ed dialogues is constrained by the hierarchical structure
of the physical task. A parallel structuring of &amp;quot;focus
spaces&amp;quot; was proposed as a mechanism to constrain the
search for co-referents, and became the mainstay of the
discourse component of two systems (Robinson et al.
1980, Walker 1978). Although this research did not
directly address the problem of discovering cross-modal
similarities and differences, the major finding of explicitly
&amp;quot;stacked&amp;quot; topics serving to constrain co-reference was
validated independently in a domain of casual, f ace-to-
f ace conversation (Reichman 1981).
Bruce&apos;s pragmatics component for the HWIM system
was based on transcripts of human keyboard-mediated
dialogues simulating interactions with a travel budget
manager. Users were seen to be interacting in various
&amp;quot;modes&amp;quot; (e.g., editing-a-trip mode, creating-a-trip mode,
etc.). The system attempted to track the user&apos;s progress
through these modes, using an ATN-based represen-
tation, and thereby to create expectations of his/her
future utterances. Discourse analysis revealed that users
did not follow the strict embedding of subdialogues
required by the ATN model. Consequently, the pragmat-
ics component was reorganized as a &amp;quot;demand&amp;quot; model in
which the system was seen as responding to one of a set
of pending goals. Although this research did not directly
address issues of cross-modal similarities and differences,
it did point out the promise of a goal-oriented view of
language processing.
Many researchers in the field of discourse analysis
have tried to identify goals or intentions in dialogue. For
example, Labov and Fanshel (1977) analyzed transcripts
of therapy sessions by employing the vocabulary of
linguistics and speech act theory. Their analyses
presented rules for interpreting the intentions behind
utterances of various syntactic forms — e.g., rules for
when a hearer will interpret utterances as indirect
requests for physical action or verbal confirmation.
However, these rules were stipulated as regularities of
discourse rather than as derived from underlying proc-
esses. Their findings should serve as data to be explained,
rather than as a satisfying account of discourse.
In research more relevant to computational linguistics,
Mann et al. (Mann, Moore, and Levin 1977; Mann,
Carlisle, Moore, and Levin 1977) applied traditional
empirical methods to the identification of speaker inten-
tion and utterance function in dialogue.5 Their goal was
to build systems to replicate observers&apos; scorings of tran-
scripts. The observers, and ultimately the systems, were
to identify repeated reference, requests, expressions of
comprehension, topic structure, etc., in keyboard
dialogues between a user and a computer operator, and
in radio dialogues between Apollo astronauts and ground
control. Much care was taken to develop a scoring
scheme, train dialogue observers, and attain reliability
Mann, Carlisle, Moore, and Levin 1977). A separate
computer program was to have been built for processing
each transcript. By merging the common features of
these systems, an empirically-based theory and computa-
tional model were to have been developed. This work
resulted in a goal-directed, &amp;quot;dialogue games&amp;quot; model of
conversational interaction (Levin and Moore 1977),
though it is not clear whether the model&apos;s formulation
resulted from the merging of implementations.
Finally, there is a huge literature of psychological
studies of referential communication. I will not survey it
here (but see Dickson 1981 for recent papers and Asher
1979 for an extensive review), but mention only two
themes of relevance to this study. First, such work has
shown that, in spoken interaction, noun phrase length
tends to decrease as subsequent references to an object
are made. However, in non-interactive spoken modalities
(Krauss &amp; Weinheimer 1966), the decrease for subse-
quent references is lessened. These results indicate that
efficiency in referential communication is a function of
user feedback.
The development of the component skills involved in
referring is a second theme in this literature. In order to
test Piaget&apos;s &amp;quot;egocentrism&amp;quot; hypotheses, a typical question
asked is whether children take their listener&apos;s
&amp;quot;perspective&amp;quot; into account when planning their referring
expressions.6 Another question raised is whether children
of certain ages can adequately make comparisons of the
properties of referents and non-referents in order to
formulate an adequate referring expression. This line of
&apos;However, neither corpus incorporated true spoken interaction. The SRI
dialogues that were analyzed in depth were taken from a mixed commu-
nication mode in which one, an &amp;quot;expert&amp;quot;, typed instructions to a third
party, who spoke them to an &amp;quot;apprentice&amp;quot;, and typed the apprentice&apos;s
spoken replies to the expert. The BBN &amp;quot;incremental simulation&amp;quot;
dialogues involved only keyboard communication.
&apos;Similar approaches include those of Dore et al. (1978), and Sinclair
and Coulthard (1975).
Shatz and Gelman (1973) showed they can do so (though not neces-
sarily accurately (Asher 1979)) at a much earlier age than had been
supposed.
</bodyText>
<page confidence="0.50247">
100 Computational Linguistics Volume 10, Number 3-4, July-December 1984
</page>
<note confidence="0.666311">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<bodyText confidence="0.8914178">
work is more relevant to the present concerns of charac-
terizing the act of identification, but the subskills exam-
ined are still too coarse for our needs.
Previous research has thus provided many lessons,
among them:
</bodyText>
<listItem confidence="0.957579875">
• the need to compare (at least initially) modalities that
are minimally different,
• the need for repeatable methods for characterizing
linguistic behavior at the pragmatics and discourse
structure level,
• the need to assess the adequacy of our theories, and
• the need for couching explanations in computational
terms.
</listItem>
<bodyText confidence="0.648027">
The present study addresses each of these needs.
</bodyText>
<sectionHeader confidence="0.980177" genericHeader="method">
3 The Phenomena of Interest: Referent Identifi-
cation
</sectionHeader>
<bodyText confidence="0.999955609375">
One referential goal that is essential to the present
communication task is to get the hearer to identify the
object the speaker has in mind. I shall be using the term
&amp;quot;identify&amp;quot; in a very narrow, though important and basic,
sense — one that intimately involves perception. Thus,
the analysis is not intended to be general; it applies only
when the referents are perceptually accessible to the
hearer, and when the hearer is intended to use perceptual
means to pick them out. For the time being, I shall
explicitly not be concerned with a hearer&apos;s mentally
&amp;quot;identifying&amp;quot; some entity satisfying a description, or
discovering a co-referring description, although these
operations are certainly important aspects of processing
many referring expressions. In the remainder of this
section, properties of the referent identification act are
examined, in part by contrasting it with other concepts
that have previously entered into computational linguistic
analyses of reference.
Referent identification requires an agent and a
description. The essence of the act is that the agent pick
out the thing or things satisfying the description. The
agent need not be the speaker of the description, and
indeed, the description need not be communicated
linguistically, or even communicated at all. A crucial
component of referent identification is the act of percep-
tually searching for something that satisfies the
description. To determine which method(s) should be
used in identifying the referent, the agent first requires
some representation of the description per se. The
description is decomposed by the hearer into a plan of
action for identifying the referent. The intended and
expected physical, sensory, and cognitive actions to be
included in that plan may be signalled by the speaker&apos;s
choice of predicates. For example, a speaker who utters,
&amp;quot;the magnetic screwdriver, please&amp;quot;, may expect and
intend for the hearer to place various screwdrivers
against some piece of iron to determine which is magnet-
ic. Similarly, a speaker uttering the description &amp;quot;the
three two-inch long salted green noodles&amp;quot; may expect
and intend the hearer to count, look at, measure, and
perhaps taste various objects. For their part, hearers
decompose the noun phrase/description to discover that
&amp;quot;green&amp;quot; is determinable by vision, &amp;quot;inch&amp;quot; by measuring,
&amp;quot;salted&amp;quot; primarily by taste, &amp;quot;noodle&amp;quot; primarily by vision,
and &amp;quot;three&amp;quot; by counting. Speakers know this is what
hearers can do, and thus, using a model of the hearer&apos;s
capabilities and the causal connections among people,
their senses, and physical objects, design the referring
expression D to suggest the actions needed to identify the
referent.
Speakers often not only plan for hearers to identify the
referents of descriptions, but also communicate, in the
Gricean way (1957), their intention that the hearers do
so. This intention may not be explicitly signalled in the
utterance, but rather have to be recognized by the hear-
er. To respond appropriately, a hearer decides when
identification is the intended act to perform in response
to a description, what part this act will play in the speak-
er&apos;s and hearer&apos;s plans, and when to perform the act. If
perceptually identifying a referent is represented as an
action in the speaker&apos;s plan, hearers could reason about it
just as they do about any other act, thereby becoming
able to infer the speaker&apos;s intentions behind, for example,
indirect identification requests.
</bodyText>
<subsectionHeader confidence="0.9973385">
3.1 A sketch of a definition of perceptual refer-
ent identification
</subsectionHeader>
<bodyText confidence="0.992918333333333">
Figure 1 presents a sketchy definition of the referent
identification action, in which the description is formed
from &amp;quot;a/the y such that D(y)&amp;quot;.7
</bodyText>
<sectionHeader confidence="0.817279666666667" genericHeader="method">
VD Agt
3 X [PERCE1PTUALLY-
ACCESSIBLE(X, Agt) &amp;
D(X) &amp;
IDENTIFIABLE(Agt,D)]
3 X [RESULT(Agt,
IDENTIFY-REFERENT(D),
IDENTIFIED-REFERENT
(Agt, D, X)]
</sectionHeader>
<figureCaption confidence="0.998312">
Figure 1. The act of referent identification.
</figureCaption>
<footnote confidence="0.9918068">
&apos; This definition is not particularly illuminating, but it is not any vaguer
than others in the literature, including Searle&apos;s (1969). The point of
giving it is that if a definition can be given in this form (i.e., as an action
characterizable in a dynamic logic), a plan-based analysis (see section
7.5) applies.
</footnote>
<note confidence="0.585384">
Computational Linguistics Volume 10, Number 3-4, July-December 1984 101
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<bodyText confidence="0.999518064935065">
The formula follows the usual axiomatization of
actions in a dynamic logic: P D [Act](); that is, if P is
true, after doing Act, Q holds. Following Moore&apos;s
(1980) possible worlds semantics for action, the modal
operator RESULT is taken to be true of an agent, an
action, and a formula, iff in all world states resulting
from the agent&apos;s performing that action, the formula is
true.8
The antecedent says there exists some (perhaps more
than one) object satisfying three conditions. The first is
a &amp;quot;perceptual accessibility&amp;quot; condition to guarantee that
the IDENTITY-REFERENT action is applicable. This
should guarantee that, for example, a speaker does not
intend someone to pick out the referent of &amp;quot;3&amp;quot;,
&amp;quot;democracy&amp;quot;, or &amp;quot;the first man to land on Mars&amp;quot;. The
condition is satisfied in the experimental task because it
rapidly becomes mutual knowledge that the task requires
communication about the objects in front of the hearer.
The second condition states that X fulfills the
description D. Here, I am ignoring cases in which the
description is not literally true of the intended referent,
including metonymy, irony, and the like (but see Perrault
and Cohen 1981). Finally, D should be a description
that is identifiable to this particular Agt. It should use
descriptors whose extension the agent already knows or
can discover by action. I am assuming that we can know
that a combination of descriptors is identifiable without
having formed a plan for identifying the referent.
If the antecedent is true, then the agent picks out
something (not necessarily the object satisfying the ante-
cedent) as the referent of D. His picking out the &amp;quot;right&amp;quot;
(i.e., the intended) object is handled by a separate char-
acterization of the speaker&apos;s intention with respect to this
action (see section 7.5). Here, I will merely give a name
to the state of knowledge the agent is in after having
identified the referent of D — (IDENTIFIED-REFERENT
Agt D X). That is, Agt has identified the referent of D to
be X. Of course, what has been notoriously difficult to
specify is just what Agt has to know about X to say he
has identified it as the referent of D. Clearly, &amp;quot;knowing
who the D is&amp;quot; (Hintikka 1969, Moore 1980) is no substi-
tute for having identified a referent. After having picked
out the referent of a description, we may still not not
know who the D is. On the other hand, we may know
who or what the description denotes, for example, by
knowing some &amp;quot;standard name&amp;quot; for it, and yet be unable
to use that knowledge to pick out the object. For exam-
ple, if we ask &amp;quot;Which is the Seattle train?&amp;quot; and receive
the reply &amp;quot;It&apos;s train number 11689&amp;quot;, we may still not be
able to pick out and board the train if its serial number is
not plainly in view. Clearly, the notion of identification
needs to be made relative to a purpose, which perhaps
could be derived from the bodily actions that Agt is
intended to perform upon the intended referent.9
Finally, although not stated in this definition, the
means by which the act is performed is some function
mapping D to some plan or procedure that, when
executed by Agt, enables Agt to discover the X that is the
referent of D.
Even with this imprecise understanding of referent
identification, it is apparent that not all noun phrases
used in task-oriented conversations (even with the
perceptual access conditions satisfied) are uttered with
the intention that their referents be identified. For exam-
ple, in dialogues with an information booth clerk in a
train station (Allen 1979, Horrigan 1977), patrons utter-
ing &amp;quot;the 3:15 to Montreal?&amp;quot; are not intending the clerk
to pick out the train. Instead, as part of their plan for
boarding a train, patrons are intending the clerk to supply
them with a co-referring noun phrase that will allow them
to identify the train. The attributive use of definite noun
phrases (Donnellan 1960) is another case in which the
speaker has no intention that the hearer identify a refer-
ent. Other non-anaphoric uses of noun phrases include
labeling an object, correcting a referential miscommuni-
cation, getting the speaker to wait while the speaker
identifies the referent, etc.1°
</bodyText>
<subsectionHeader confidence="0.999899">
3.2 Comparisons with computational linguistics
approaches to reference
</subsectionHeader>
<bodyText confidence="0.999324222222222">
Computational linguistics research has usually been
concerned with co-reference — the relationship of words
and symbols to other words and symbols. Typically,
referents of descriptions are determined by intersecting
the extensions of the predicates in the description,
subject to the quantificational constraints imposed by the
determiner. Although perhaps adequate for interfacing
with databases, this approach presupposes that the exten-
sions can be computed from information currently in the
database. However, in interpreting and generating
discourse about some physical task, the system may have
to form a plan that it or its user perform physical actions
to determine the extensions of the predicates.
Five approaches are most closely related to ours. First,
Winograd&apos;s SHRDLU (1972) attempted to simulate true
reference with co-reference.11 SHRDLU had a PLANNER
function, THFIND, that could find objects in the database
satisfying THGOAL statements as a simulation of finding
</bodyText>
<footnote confidence="0.97188425">
s Actually, Moore characterizes RESULT as taking an event and a
formula as arguments. In his framework, an agent&apos;s doing an action
denotes an event. However, this difference is not critical for what
follows.
9 The connection with the contextually relevant actions is a matter of
inference (see section 6).
1° For other discussion of speakers&apos; goals in uttering noun phrases (see
Sidner (1983) and Wilkes-Gibbs, unpublished ms).
&amp;quot; On the other hand, one might argue that SHRDLU engaged in true
reference because the discourse was about non-existing blocks
&amp;quot;contained&amp;quot; within the system. To pursue the truth of the matter would
take us too far afield.
</footnote>
<page confidence="0.5355415">
102 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</page>
<bodyText confidence="0.999977523809524">
blocks in the real world. THFIND was included in the
semantic representation of definite NPs, and in the repre-
sentation of indefinite NPs when those NPs were embed-
ded in an action verb. However, THFIND is not
attributed as a user goal, nor is it reasoned about (other
than to maintain a distinction between definite and indef-
inite NPs). Furthermore, it is not treated in the same way
as acts such as PICKUP, whose execution is marked
specially so that the system can later answer &amp;quot;why&amp;quot; ques-
tions.
Second, Allen&apos;s (1979) system used an IDENTIFY
state in the control part of the plan-recognition mech-
anism. Again, for this system, identification meant to
find something in the database satisfying the requisite
predicates. However, the IDENTIFY action itself was not
part of the plan being recognized. The system did not
reason about when IDENTIFY should be done (it always
tried to IDENTIFY referents), nor did it attribute
IDENTIFY to be part of its user&apos;s plan.
The TDUS system (Robinson et al. 1980) engaged in a
dialogue about the assembly of an air compressor that, it
was understood, was being assembled by an apprentice.
Thus, the referents of the system&apos;s noun phrases were
perceptually accessible to the hearer. The system was
primarily oriented towards utterance interpretation, but it
did generate responses to questions. In doing so, the
system was in the same circumstances as the experts in
the present study. However, because it was assumed that
the extensions of all of the system&apos;s descriptors were
already known to the hearer, the system did not reason
that it should choose particular referring expressions so
that the hearer could pick out their referents. Instead,
the choice of referring expressions was constrained by
uniqueness and focus (Grosz 1977), constraints that are
not considered here but are clearly necessary. Although
TDUS employed the concept of locating an object in its
representation of successful task performance, this
concept did not play a role in choosing referring
expressions unless the system was asked a question about
an object&apos;s location.
Appelt&apos;s KAMP system (1981) generalized TDUS to
plan referring actions as part of the planning of illocu-
tionary acts. However, KAMP would only include
descriptors in a referring expression for which it was
already mutually believed that the hearer knew the refer-
ent. Thus, it could not generate referring expressions to
new objects for the hearer to pick out. Furthermore, as
argued earlier, the concept of &amp;quot;knowing what the refer-
ent is&amp;quot;, which was central to KAMP&apos;s planning of refer-
ring phrases, is too strong to be an accurate
representation of referent identification.
Finally, the HAM-ANS question-answering system
(Hoeppner, Monk, and Marburger 1984) generates
descriptions of objects in a hotel room from visually
derived information, assuming the user&apos;s visual search
processes are identical with its own. In another applica-
tion, the system answers questions about traffic flow
based on visual data. In its tying reference to perception,
the HAM-ANS system has some of the flexibility that I
am advocating. However, as with the others, it does not
reason about identification as an action that the speaker
intends it to do. In this paper, I argue why such reason-
ing is needed.
</bodyText>
<subsectionHeader confidence="0.99979">
3.3 Summary
</subsectionHeader>
<bodyText confidence="0.999986">
In summary, I am suggesting that referent identification
be an action that the hearer infers to be part of the
speaker&apos;s plan, and that speakers plan for hearers to
perform. To ensure that hearers can do so, speakers
employ their knowledge of the hearer&apos;s perceptual abili-
ties, and choose descriptions that will make use of those
abilities. The ability to reason about the referent identifi-
cation act will allow the hearer to infer the intentions
behind many utterances that secure reference separately
from predication, and do so indirectly. With this concept
in mind, we can proceed to examine its use in discourse.
</bodyText>
<sectionHeader confidence="0.789015" genericHeader="method">
4 The Study
</sectionHeader>
<bodyText confidence="0.999653548387097">
Twenty-five subjects (&amp;quot;experts&amp;quot;) each instructed a
randomly chosen &amp;quot;apprentice&amp;quot; in assembling a toy water
pump, following Grosz&apos;s (1977) and Chapanis et al.&apos;s
(1972) task-oriented dialogue paradigm.12
Subjects were paid volunteer students from the
University of Illinois, all of whom were familiar with CRT
terminals. Five &amp;quot;dialogues&amp;quot; took place in each of the
following modalities: face-to-face, by telephone,
keyboard (&amp;quot;linked&amp;quot; CRTs), (noninteractive) audiotape,
and (non-interactive) written. In all modes, the appren-
tices were videotaped as they followed the experts&apos;
instructions.
Face-to-face and written modalities are the ones usual-
ly compared in oral/written discussions. However, they
differ along many dimensions (Rubin 1980). Pairwise
comparisons of the modalities in this study can determine
the effects of mutual vision, interaction, and the use of
voice or print. Telephone and keyboard dialogues are
analyzed first because our conclusions would indicate the
effects of having a voice channel, and moreover would
have implications for the design of speech understanding
and production systems. These modalities take on inter-
mediate values in Rubin&apos;s dimensional space: the conver-
sants share the same time frame, can interact, cannot see
each other, and are conversing about objects mutually
known to be physically present to one of them.
Each expert participated in the experiment on two
consecutive days, the first for training and the second for
instructing an apprentice. Subjects playing the expert
role were trained by following a set of assembly
directions consisting entirely of imperatives, assembling
</bodyText>
<footnote confidence="0.520394666666667">
12 An exploded parts diagram of the pump can be found in Appendix A.
Computational Linguistics Volume 10, Number 2, April-June 1984 103
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</footnote>
<bodyText confidence="0.9999009375">
the pump as often as desired, and then instructing a
research assistant. This practice session took place face
to face. Experts knew that the research assistant already
knew how to assemble the pump. Experts were given an
initial statement of the purpose of the experiment, which
indicated that communication would take place in one of
a number of different modes. Experts were not informed
of the modality in which they would communicate until
the next day.13
Apprentices were told the purpose of the experiment
was to analyze the communicating of a set of instructions
in different modalities. They were not initially informed
that they were engaged in an assembly task.
In both modes, experts and apprentices were located in
different rooms. Experts had a set of pump parts that,
they were told, were not to be assembled but could be
manipulated. In Telephone mode, experts communicated
through a standard telephone and apprentices communi-
cated through a speaker-phone. This device did not need
to be held and allowed simultaneous two-way communi-
cation. Distortion of the expert&apos;s voice was apparent, but
not measured.
Subjects in &amp;quot;keyboard&amp;quot; mode typed their communi-
cation on Elite Datamedia 1500 CRT terminals connected
by the Telenet computer network to a computer at Bolt
Beranek and Newman Inc. The terminals were &amp;quot;linked&amp;quot;
so that whatever was typed on one would appear on the
other. Simultaneous typing was possible and did occur.
Subjects were informed that their typing would not
appear simultaneously on either terminal. Response
times averaged 1 to 2 seconds, with occasionally longer
delays due to system load.
</bodyText>
<subsectionHeader confidence="0.999902">
4.1 Sample transcripts
</subsectionHeader>
<bodyText confidence="0.9998395">
The following are representative samples of transcripts in
the two modalities.
</bodyText>
<sectionHeader confidence="0.683473" genericHeader="method">
A TELEPHONE DIALOGUE FRAGMENT
</sectionHeader>
<bodyText confidence="0.795164">
S: &amp;quot;OK. Take that. Now there&apos;s a thing called a plun-
ger. It has a red handle on it, a green bottom, and
it&apos;s got a blue lid.
</bodyText>
<listItem confidence="0.841667">
J: OK
S: OK now, the small blue cap we talked about
before?
J: Yeah
S: Put that over the hole on the side of that tube —
J: Yeah
</listItem>
<bodyText confidence="0.98003425">
The instructions given to the expert about the experiment and the
assembly task are given in Appendix A. Burke (1982) reports that the
order of the instructions, and the descriptions of the pieces, influenced
the order and vocabulary of the expert&apos;s subsequent instructions.
</bodyText>
<figure confidence="0.843873826086957">
S: — that is nearest to the top, or nearest to the red
handle.
J: OK
S: OK. Now. now, the smallest of the red pieces?
J: OK&amp;quot;
A KEYBOARD DIALOGUE FRAGMENT
B: &amp;quot;fit the blue cap over the tub end
N: done
B: put the little black ring into the large blue cap with
the hole in it...
N: ok
B: right Put the 1/4 inch long &apos;post&apos; into the loosely
fitting hole...
N: i don&apos;t understand what you mean
B: the red piece, with the four tiny projections?
N: OK
B: place it loosely into the hole on the side of the large
tube...
N: done
B: very good. See the clear elbow tube?
N: yes
B: place the large end over that same place.
N: ready
</figure>
<bodyText confidence="0.8100845">
B: take the clear dome and attach it to the end of the
elbow joint...&amp;quot;
</bodyText>
<subsectionHeader confidence="0.999994">
4.2 Method of analysis
</subsectionHeader>
<bodyText confidence="0.998904769230769">
Discourses are analyzed for many reasons, with a corre-
sponding variety of methods. Some analyses of discourse
strive to explain what the text itself meant. Recent work
on discourse pragmatics emphasizes the need to explain
what the speaker meant in producing the utterances, i.e.,
what were the speaker&apos;s intentions? To build dialogue
systems, we need to devise first theories and then algo-
rithms for deriving what the speaker meant as a function
of what was said and of contextual factors. The logical
first step toward such a formalization is to establish reli-
able methods for isolating the words, context, and speak-
er intent. Each of these aspects of the discourse is
considered below.
</bodyText>
<page confidence="0.6027905">
104 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</page>
<bodyText confidence="0.999695860465116">
First, the typewritten transcript of a verbal interaction
provides reasonably accurate data on what was said,
provided one&apos;s goal is not to study prosody. Second,
contextual factors can be modelled in a setting in which
the objects, communication task, and modality have been
selected by the experimenter. The conversants&apos; know-
ledge of the domain is somewhat constrained by the
experimental setup and the initial instructions. This
semi-controlled environment can enable the experimenter
to model the participants&apos; initial experiment-induced
beliefs, intentions, and expectations, which constitute our
model of the cognitive effects of context.
Finally, as the conversation progresses, one needs
interpretations of what each speaker meant, stated in
terms of further attributions of beliefs and intentions.
Standard empirical methods should be used to minimize
experimenter bias in making such attributions. In partic-
ular, the theorist must be careful not to be the source of
belief/intent attributions, for if given the leeway, he will
undoubtedly find what he is looking for. To avoid this
problem, I trained two people to employ a vocabulary for
describing intentions in discourse, the so-called
&amp;quot;illocutionary acts&amp;quot; (or, loosely, &amp;quot;speech acts&amp;quot;) (Austin
1962, Searle 1969). That is, the discourse analysts
&amp;quot;code&amp;quot; the speaker&apos;s intentions in making an utterance
by assigning illocutionary act labels to utterances (or
groups of them). Fortunately, the illocutionary act
vocabulary is the natural one in our common-sense
psychology for making such attributions. However,
unlike most theories of illocutionary acts, I do not claim
that the conversants themselves attempt to determine
what illocutionary acts were performed, although they
might be able to do so if requested.14 The illocutionary
act interpretations are therefore our interpretations, as
coders and as theorists.
The data that need to be compared and explained are
these illocutionary act codings. As mentioned earlier, a
number of researchers have attempted similar analyses,
but are content with solely identifying regularities in their
discourses. A preferable analysis would derive regulari-
ties from more basic principles. The method employed
here for formulating such derivations includes the follow-
ing components:
</bodyText>
<listItem confidence="0.974023727272727">
• A logic of beliefs, mutual beliefs, and goals.
• A specification of the goals achieved by utterances of
various forms (e.g., a yes/no question is an attempt to
get the hearer to inform the speaker whether or not
the proposition in question is true).
• A formal theory of rational, intentional action that
specifies how an agent&apos;s actions are determined by
both his goals and his knowledge of the effects of,
14 See Cohen and Levesque (1980, in preparation) for a plan-based
theory of communication that does not require the recognition of illocu-
tionary acts.
</listItem>
<bodyText confidence="0.9945994">
preconditions for, and means of accomplishing various
action types.
The aim of a competence theory of communication
based on plans is to specify the set of possible plans
underlying the appropriate use of various illocutionary
acts. In applying such a theory to the analysis of
discourse, plans are used to connect an utterance&apos;s form
and content with the observers&apos; illocutionary act coding,
which is our best approximation to the speaker&apos;s intent.
It is important to remember that these intentions may not
be identical to those conveyed by the literal utterance.
The plans make use of a formalization of the exper-
imental task, the modality and the prior discourse,
expressed in terms of the participants&apos; mutual beliefs,
goals, expectations, and possibilities for action. Thus, the
theory captures, albeit in an indirect way, the depend-
ence of the discourse structure on the experimental task
and communication modality.
In addition, a performance model would include algo-
rithms for forming and recognizing plans of action to
derive the observer&apos;s intent codings. Although such
models have been built (Allen 1979, Brachman et al.
1979), I do not discuss them further here.
In summary, the discourse analysis methodology is as
follows:
</bodyText>
<listItem confidence="0.984552777777778">
• Train coders to identify various illocutionary acts
(IAs).
• Compare the distribution of IAs across modalities.
• Independently, characterize those IA types in terms of
plans.
• Formally derive the IA codings as a rational strategy of
action, given attributions of the participants&apos; beliefs,
goals, and expectations at the point in the discourse in
which the IAs occurred.
</listItem>
<bodyText confidence="0.994363666666667">
When our work is complete, we will have analyses of the
differences in achievement of the same overarching set of
goals (the assembly task) as a function of modality.
</bodyText>
<subsectionHeader confidence="0.994746">
4.2.1 Coding the transcripts
</subsectionHeader>
<bodyText confidence="0.961004652173913">
The first stage of discourse analysis involves the coding
of the communicator&apos;s intent in making various utter-
ances. Following the experiences of Sinclair and Coul-
thard (1975), Dore et al. (1978), and Mann, Carlisle,
Moore, and Levin (1977), a coding scheme was devel-
oped and two people were trained in its use. The coders
relied on written transcripts, audiotapes, and on vide-
otapes.
The scheme, which was tested and revised on pilot
data until reliability was attained, included a set of
approximately eight illocutionary act categories that were
used to label intent, and a set of &amp;quot;operators&amp;quot; and prop-
ositions that were used to describe the assembly task, as
in Sacerdoti (1975). Appendix B lists the propositions
and operators for the physical actions. For example,
putting two hollow, pipe-like pieces together was termed
Computational Linguistics Volume 10, Number 2, April-June 1984 105
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
CONNECTing; putting a part with a protrusion into a part
with a hole was termed MESHing. The operators for
physical actions often served as the propositional content
of the communicative acts.
The following illocutionary act categories were coded:
</bodyText>
<subsectionHeader confidence="0.845406">
Communicative Act
</subsectionHeader>
<bodyText confidence="0.449043">
Example
</bodyText>
<equation confidence="0.828504894736842">
Request(Assembly Action)
&amp;quot;put that on the hole&amp;quot;
Request(Orientation Action)
&amp;quot;the other way around&amp;quot;
&amp;quot;the top is the bottom&amp;quot;
Request(Pick-up)
&amp;quot;take the blue base&amp;quot;
Request(Identify-Referent)
&amp;quot;there is a little yellow piece of rubber&amp;quot;
Requestanformif ([relationD)
&amp;quot;and you&apos;ve got the base on it?&amp;quot;
Request(Informif (Identified-referent))
&amp;quot;got it?&amp;quot;
&amp;quot;the little red plug?&amp;quot;
Request(Achieve([relation]))
&amp;quot;and the purpose of that is to cover up that hole....
[relation] = (Cover V2 Hole(TB)))]
Label
&amp;quot;that&apos;s a plunger&amp;quot;
</equation>
<bodyText confidence="0.9999532">
As discussed earlier, the action of referent identifica-
tion is labelled IDENTIFY-REFERENT, and the state of
affairs resulting from it is termed IDENTIFIED-
REFERENT. Communicating that the speaker wants the
hearer to do something is termed REQUESTing. Yes/no
questions are REQUESTs to get a hearer to perform an
INFORMIF action, i.e., to tell the speaker whether or not
some proposition holds. One subcase of this is to tell the
hearer whether or not a referent for a description has
been identified. Finally, speakers often request that
hearers make a relation true, without specifying an action
that would do so. This is capiured by the REQUEST to
ACHIEVE [relation] coding.
Regarding referent identification, the coders were
asked to state which utterances, or groups of utterances,
constituted either an explicit request by the speaker that
the hearer identify the referent of a noun phrase or a
question about whether or not the hearer had done so.
The coders were instructed not to consider whether or
not an utterance was an indirect request to pick some-
thing up (but see section 6.4.1). Furthermore, they were
told not to consider noun phrases in assembly requests as
identification requests unless identification was somehow
&amp;quot;explicitly marked&amp;quot;.15 Because agreement about the
intent behind utterance parts was not obtainable, I
cannot assert, on the basis of empirical evidence alone,
that noun phrases embedded in imperatives are requests
to identify the referents. Instead, the speaker&apos;s intent
behind whole utterances (though not necessarily
complete sentences) was coded:16
</bodyText>
<subsectionHeader confidence="0.992154">
4.2.2 Mechanics of coding
</subsectionHeader>
<bodyText confidence="0.999983371428571">
Of course, a coding scheme must not only capture the
domain of discourse, it must be tailored to the nature of
discourse per se. Many theorists have observed that a
speaker can use a number of utterances to achieve a goal,
and can use one utterance to achieve a number of goals.
Correspondingly, the coders could consider utterances as
jointly achieving one intention (by &amp;quot;bracketing&amp;quot; them),
could place an utterance in multiple categories, and could
attribute more than one intention to the same utterance
or utterance part. The coders were instructed to ignore
false starts, even though a false start may communicate
information.
Although our goals did not include a precise analysis
of how prosody reflects speaker-intent and meaning,
some decisions about how to translate prosody into
orthographic form, which undoubtedly influence subse-
quent discourse analyses, were made by the transcriber
of the audiotapes. To minimize inconsistencies in tran-
scription, all transcriptions were checked by a second
party. Moreover, it was discovered that the physical
layout of a transcript, particularly the location of line
breaks, affected which utterances were coded. To ensure
uniformity, each coder first divided each transcript into
utterances that he or she would code. These joint
&amp;quot;bracketings&amp;quot; were compared to yield a base set of coda-
ble utterance parts. The coders could later bracket utter-
ances differently if necessary.
For one third of the transcripts, interrater reliabilities
were calculated within each mode, for each category.
The measure consisted of twice the number of agree-
ments divided by the number of times that category was
coded (cf. Mann, Carlisle, Moore, and Levin 1977).
Reliabilities were high (above 88%). Because each disa-
greement counted twice (against both categories that
were coded), agreements also counted twice.
</bodyText>
<subsectionHeader confidence="0.998033">
4.2.3 Coding the sample dialogue fragments
</subsectionHeader>
<bodyText confidence="0.9657345">
The previous fragments are coded below to indicate some
of the complexities of the data as well as the scoring
scheme. A number of shortcuts have been taken for
expository purposes. First, if an act is stated as
</bodyText>
<footnote confidence="0.9894505">
&apos;5 The above Telephone dialogue fragment contains one such intona-
tionally marked noun phrase.
16 For a formal analysis that does make such a claim, see section 8.4 and
Cohen (1984).
&apos; The action-effect relation holding between the various propositions
and assembly actions can be readily inferred from Appendix B.
</footnote>
<page confidence="0.4964245">
106 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</page>
<bodyText confidence="0.999992563636364">
COMPLETE, then the proposition stated as the effect of
that act holds.17 Second, some of the arguments to the
embedded propositions have not been presented when
those arguments are not problematic. Third, as argued
above, the second argument of IDENTIFY-REFERENT
should be a description in some appropriate logical form
representing the meaning of the speaker&apos;s noun phrase.
However, because it was too difficult to get coders to
determine logical forms for the noun phrases, they
instead coded only the canonical names of the referents
as arguments. Finally, the elapsed time between utter-
ances is not shown here, but is available from the vide-
otapes.
The codings of S&apos;s first turn indicate an attempt to
achieve more than one intention in one utterance.
Specifically, the form &amp;quot;there&apos;s a ...&amp;quot;, is a typical way to
perform a request to identify something satisfying the
description (the &amp;quot;...&amp;quot;). In this case, the speaker said
&amp;quot;thing&amp;quot;, and labelled that thing a plunger. Whereas the
labelling act may be finished, the request for referent
identification apparently is not, and is continued over a
number of utterances.
The other &amp;quot;bracketed&amp;quot; turn is an example of a speak-
er&apos;s prosodically achieving multiple goals at once. Here,
the use of rising intonation in the middle of an imperative
is used to check whether the hearer knows what the
speaker is talking about. The pragmatics of this
discourse situation led to the coding of &amp;quot;knowing what
the speaker is talking about&amp;quot; as a request to physically
identify a referent. Finally, notice the subsequent use of
a questioned noun phrase fragment to perform the same
act. The use of fragments will be discussed further
below.
The coding of the Keyboard utterances is more
straightforward. There are three strategies of instruction
here. First, direct requests for assembly actions, in the
form of imperatives, as in line (1). Second, there are
conjoined direct requests, for picking up followed by an
assembly action, as in (12). Finally, B performs separate
identification requests, as in (7) and (8).
What is important to notice here is that B shifts his
strategy (in a fashion that resembles driving a three-
speed car). Before this fragment, the conversation had
proceeded smoothly, in &amp;quot;high gear&amp;quot;, with B initially
&amp;quot;upshifting&amp;quot; from first a &amp;quot;take and assemble&amp;quot; request to
six consecutive assembly requests (one of them indirect),
the last of which is utterance (1) of this fragment.
In (5)-(7), we observe clarification dialogue about a
noun phrase. Immediately after an apparent breakdown
at (3), B &amp;quot;downshifts&amp;quot; to questioning the achievement of
his first subgoal, identifying the red piece. Once that is
corrected, B stays in &amp;quot;low gear&amp;quot;, explicitly ensuring
success of his reference, in (8), before requesting an
assembly action in (9). After that success, he &amp;quot;upshifts&amp;quot;
to &amp;quot;second gear&amp;quot; — with requests to pick-up and assemble
</bodyText>
<subsectionHeader confidence="0.887167">
Computational Linguistics Volume 10, Number 2, April-June 1984
</subsectionHeader>
<bodyText confidence="0.999991318181818">
in (13). After being successful yet again, B &amp;quot;upshifts&amp;quot; to
&amp;quot;high gear&amp;quot;, using direct assembly requests, for the rest
of the dialogue (seven more requests).
What could explain this conversation pattern? A
common sense analysis of the plan for assembling would
indicate that to install a piece, one must be holding it; to
hold it, one must pick it up; to perform any action on an
object, one must have identified that object. By request-
ing an assembly action (&amp;quot;high gear&amp;quot;), one requires the
listener to infer the rest of the plan. By requesting the
sequence take-and-assemble (&amp;quot;second gear&amp;quot;), the speak-
er makes one of the inferences himself, but requires the
listener to realize that identification of the speaker&apos;s part
description is needed. Finally, &amp;quot;low gear&amp;quot; involves the
speaker&apos;s checking the success of the component
subgoals, which involves identifying the referents of the
speaker&apos;s descriptions. In summary, the strategy shift to
&amp;quot;low gear&amp;quot; occurs after a referential miscommunication
because it affords a more precise monitoring of the
listener&apos;s achievement of the speaker&apos;s goals. The ques-
tion to be asked is how, if at all, the use of identification
requests differs across modes of communication.
</bodyText>
<sectionHeader confidence="0.999712" genericHeader="method">
5 Results
</sectionHeader>
<subsectionHeader confidence="0.999767">
5.1 Analysis 1: Distribution of requests
</subsectionHeader>
<bodyText confidence="0.994972517241379">
Because most of each dialogue consists of the making of
requests, the first analysis examined the frequency of the
various kinds of requests in the corpus of five transcripts
for each modality. Table 1 displays the findings.
Identification requests, which include questions about
whether a referent has been identified, are much more
frequent in Telephone dialogues than in Keyboard
conversations. In fact, they constitute the largest catego-
ry of requests in the former. Because orientation
requests, pick-up requests, and other requests are often
issued to clarify or follow up on a previous request, it is
not surprising that they would increase in number
(though not as a percentage) with the increase in the use
of identification requests. Furthermore, it is sensible that
there are about the same number of requests for assem-
bly actions (and hence half the percentage) in each mode
because the same &amp;quot;assembly work&amp;quot; is accomplished.
Therefore, identification requests seem to be the primary
request differentiating the two modalities.18 Notice also
that Chapanis et al.&apos;s finding of twice as many words
used in spoken over written modes holds true when we
consider the number of requests rather than just words.
18 The only cases of unreliable coding resulted from attempts to code
identification requests when they were not obviously separate utter-
ances. Most of these unreliable cases were found in the Keyboard
dialogues, but were included in the totals for that modality. Thus, using
a strict criterion of counting only reliable examples of identification
requests, the differences between the two modes are even stronger than
shown in the table.
</bodyText>
<page confidence="0.955358">
107
</page>
<figure confidence="0.996247266666667">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
CODING
REQUEST(PICK-UP)
,I--
LABEL(PLUNGER)
REQUEST(IDENTIFY-REFERENT(PLUNGER))
INFORM(COMPLETE
(IDENTIFY-REFERENT(PLUNGER)))
REQUEST(INFORMIF
(IDENTIFIED-REFERENT
(TUBE-CAP)))
INFORM(COMPLETE
(IDENTIFY-REFERENT(TUBE-CAP)))
REQUEST(COVER)
REQUEST(INFORMIF
(IDENTIFIED-REFERENT OUTLET1))
INFORM(COMPLETE
(IDENTIFY-REFERENT (MAIN-TUBE)))
INFORM(COMPLETE (COVER))
REQUEST(INFORMIF
(IDENTIFIED-REFERENT (PLUG)))
INFORM(COMPLETE
(IDENTIFY-REFERENT(PLUG)))
UTTERANCE
S: &amp;quot;OK. Take that.
Now there&apos;s a thing
called a plunger.
It has a red handle on it,
a greenbottom, and it&apos;s got a blue lid.
J: OK
•
S: OK now, the small blue cap we talked
about before?
J: Yeah
S: Put that over the hole on
the side of that tube —
J: Yeah
S: — that is nearest to the top, or nearest
to the red handle.
J: OK
•
•
S: OK. now. now, the smallest of the red
pieces?
J: OK
</figure>
<figureCaption confidence="0.999991">
Figure 2. The telephone fragment coded.
</figureCaption>
<subsectionHeader confidence="0.999919">
5.2 Analysis 2: First-time identifications
</subsectionHeader>
<bodyText confidence="0.999962810810811">
Although frequency data are important for computational
linguistics, they supply only a coarse description of
discourse phenomena and the dialogue itself. For assess-
ing the importance of a phenomenon, it is important to
discover the context in which it occurs. In our case, the
question arises whether the frequent use of identification
requests is a function of the modality itself or a function
of the dynamics of the discourse (or both). For example,
identification requests might arise primarily after referen-
tial miscommunication, as in the above Keyboard
dialogue. If they did, one might argue that people would
speak more carefully to machines than they do to people,
leading to less miscommunication and therefore a smaller
frequency of identification requests than we found.
Consequently, the argument that identification requests
are important for computational linguistics research
would be weakened. However, Fertig (unpublished)
found no significant differences in the frequency of
miscommunication across modes. The observed modality
differences in the use of identification requests are there-
fore due to other causes.
To determine if the frequent use of identification
requests holds across subjects within modes, a second
analysis of the utterance codings was undertaken that
was limited to &amp;quot;first-time&amp;quot; identifications — that is, how
objects were first introduced to hearers. Each time a
novice first identified a piece in response to a communi-
cative act, that act was noted. Furthermore, that act was
counted only if it was not preceded by another mention-
ing the same part prior to the novice&apos;s identification
attempt. This analysis therefore examines only requests
used to make first effective reference to an object. Table
2 indicates the results for each subject in Telephone and
Keyboard modes.
Subjects were classified as habitual users of a commu-
nicative act if, out of 12 pieces, the subject &amp;quot;introduced&amp;quot;
at least 9 of the pieces with that act. In Telephone mode,
</bodyText>
<page confidence="0.733431">
108 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<figure confidence="0.450951888888889">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
UTTERANCE CODING
(1)B: &amp;quot;fit the blue cap over the tub end REQUEST(COVER(TUBE-CAP MAIN-TUBE))
(2)N: done INFORM ( COMPLETE(COVER) )
(3)B: put the little black ring into the REQUEST(PUT-INTO
large blue cap with the hole in it... (0-RING TUBE-BASE))
(4)N: ok INFORM(COMPLETE(PUT-INTO))
• REQUEST(MESH (VALVE3 OUTLET2))
(5)B: right
</figure>
<bodyText confidence="0.845753125">
put the 1/4 inch long &apos;post&apos; into
the loosely fitting hole...
(6)N: I don&apos;t understand what you mean
(7)B: the red piece, with the four tiny REQUEST(INFORMIF
projections? (IDENTIFIED-REFERENT (VALVE3)))
.
(8)B: very good.
See the clear elbow tube? REQUEST(INFORMIF
</bodyText>
<listItem confidence="0.8302072">
(IDENTIFIED-REFERENT (SPOUT)))
(9)N: Yes INFORM(IDENTIFIED-REFERENT (SPOUT))
(10)B: Place the large end over REQUEST(CONNECT
that same place. (SPOUT OUTLET2))
(11)N: ready INFORM(COMPLETE
</listItem>
<bodyText confidence="0.630194333333333">
(CONNECT SPOUT OUTLET2))
(12)B: take the clear dome and attach it REQUEST(PICK-UP(AIR-CH))
to the end of the elbow joint... REQUEST(CONNECT(AIR-CH SPOUT))
</bodyText>
<figureCaption confidence="0.995758">
Figure 3. The keyboard dialogue fragment coded.
</figureCaption>
<bodyText confidence="0.99997946875">
four of five experts were habitual users of identification
requests to get the apprentice to find a piece. The
remaining subject used the strategy of first requesting the
apprentice to pick up a part, and then requesting that it
be attached to the pump. In Keyboard mode, no experts
were habitual users of identification requests. However,
three experts were habitual users of assembly requests in
getting apprentices to identify objects.
To show a &amp;quot;modality effect&amp;quot; in the making of first
effective reference, the number of habitual users of each
request type in each mode was subjected to Fischer&apos;s
exact probability test. This calculates the probability that
differences in the number of habitual and nonusers of a
particular reference strategy in different modes could
have happened by chance. Even with five subjects per
mode, differences in the use of identification requests
across modes were significant (p = 0.023), indicating
that Telephone conversation per se differs from
Keyboard conversation in the ways in which a speaker
will first get a hearer to identify an object.
In summary, it has been shown that Telephone and
Keyboard modes differ primarily in the use of explicit
identification requests. These requests do not simply
occur after referential miscommunication (as they do in
Keyboard), but are used to first introduce objects. The
experts then often question the apprentices about
successful completion of the identification act (just as
they do assembly acts). Experts using keyboards do not
attempt to achieve referential goals explicitly. Instead,
referential goals are subsumed in assembly requests.
Voice communication is thus &amp;quot;finer-grained&amp;quot; than
keyboard communication.
</bodyText>
<subsectionHeader confidence="0.999931">
5.3 Comparison with other studies
</subsectionHeader>
<bodyText confidence="0.999004428571428">
These results are similar to observations by Ochs and
colleagues (Ochs 1979; Ochs, Schieffelin, and Pratt
1979). Using evidence from transcripts, they point out
that caretaker-child and child-child discourse often
consists of &amp;quot;sequential&amp;quot; constructions — with separate
utterances for securing reference and for predicating.
Ochs et al. suggest that the presence of sequential
</bodyText>
<table confidence="0.5148645">
Computational Linguistics Volume 10, Number 2, April-June 1984 109
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</table>
<tableCaption confidence="0.995109">
Table 1. Distribution of requests (percent).
</tableCaption>
<table confidence="0.998874166666667">
Type of Request Telephone (n=288) Keyboard (n=134)
Assembly 25 51
Orient 9 8
Other 15 13
Pick-up 16 17
Identification 35 10
</table>
<bodyText confidence="0.999702172413793">
constructions is tied to the possibility for preplanning an
utterance. Relatively unplanned discourse, it is claimed,
relies on the pragmatic context to express propositions,
where planned discourse would use syntactic means.
Unplanned discourse results when speakers are concen-
trating on a task or when the expression of a concept is
particularly difficult. The present study upholds Och et
al.&apos;s claim for Telephone and Keyboard communication,
but does not do so for the Written condition, in which
many identification requests occur as separate steps
(Tierney et al. 1983). Furthermore, Ochs et al.&apos;s claim
does not account for the use of identification requests in
Keyboard modality after prior referential miscommuni-
cation (see section 4.1 for a sample conversation), indi-
cating that sequential constructions can result from (what
they term) planned as well as unplanned discourse.
Clark and Wilkes-Gibbs (unpublished) analyze refer-
ential communication data similar to ours. Their concern
is to show that referring is a collaborative process, one
that proceeds by a speaker&apos;s proposing a referring
expression, and a hearer&apos;s accepting or rejecting it as
adequate for identifying the referent. Among the speak-
er&apos;s strategies for securing reference, they note elabo-
rations (which I called &amp;quot;supplements&amp;quot;), trial proposals
(Question-requests for identification), partial proposals,
and others. Unlike what has occasionally been assumed
in the referential communication literature, speakers are
not regarded as trying to produce, in one turn, an effec-
tive referring expression that is minimally long. Instead,
they claim speakers attempt to minimize the collaborative
effort of both parties. The discourses they analyzed
overlap significantly in structure with those found here.
The present account differs in that I give a formal analy-
sis of the act of referring as an illocutionary act — an
account that allows for indirect performance.
It is difficult to compare the present results with those
of other studies. Chapanis et al.&apos;s (1977) observation
that voice modes are faster and wordier than keyword
modes certainly holds here. However, their transcripts
cannot easily be used to verify the present findings
because, for the equipment assembly problem, their
subjects were given a set of instructions that could be,
and often were, read to the listener. Thus, utterance
function would often be predetermined. Our subjects
had to remember the task and compose the instructions
afresh.
Stoll et. al.&apos;s (1976) lexical analysis of the Chapanis
data indicates that in verbal modalities subjects produce
many more pronouns and (what they term) &amp;quot;function
words&amp;quot;, which include articles, prepositions, modals,
existential &amp;quot;there&amp;quot;, etc. In the present study, there were
at least two requests used for each assembly step in Tele-
phone mode. Each pair of requests (identification
requests followed by assembly requests, or requests to
pick up followed by assembly requests) involved at least
one common object being manipulated. In the assembly
request, the speakers frequently referred to that object
with a pronoun. Thus, because of the pragmatically fine-
grained nature of Telephone mode, there are many more
pronouns to to resolve. I suspect the same kind of analy-
sis can be applied to Stoll et. al.&apos;s &amp;quot;function word&amp;quot; cate-
gory, although that category is so diverse that
generalizations may be harder to find. However, it is
clear that in the present data, the use of &amp;quot;existential
there&amp;quot; sentences, by far the largest class of identification
requests, is only a Telephone strategy.
Modality differences in Grosz&apos; (1977) study cannot be
directly compared for the identification phenomena
because the core dialogues that were analyzed in depth
each employed both spoken and keyboard modalities.
However, the present results would predict that indirect
identification requests would not appear because the
expert, who did most of the communicating, used a
keyboard.
Finally, Thompson&apos;s (1980) extensive tabulation of
utterance forms in a multiple modality comparison over-
laps the analysis in this paper at the level of syntax. Both
Thompson&apos;s and the present study are primarily
concerned with extending the usability of current systems
by identifying phenomena that people use, but that
would be problematic for computers. However, the two
studies proceeded along different lines. Thompson&apos;s was
more concerned with utterance forms and less with prag-
matic function, whereas for this study, the concerns are
reversed in priority. This study&apos;s concern stems from the
observation that differences in utterance function will
influence the processing of utterances with the same
</bodyText>
<page confidence="0.85808">
110 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.403272">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<tableCaption confidence="0.7835675">
Table 2. Communicative Acts Making First Effective
Reference to Each of 12 Pump Pieces.
</tableCaption>
<table confidence="0.967214428571429">
TELEPHONE REQUESTS KEYBOARD REQUESTS
SUBJECT IDENT PICK-UP ASSEMBLY IDENT PICK-UP ASSEMBLY
1 9 2 1 1 2 9
2 1 10 1 0 2 9
3 11 1 0 1 2 9
4 9 1 0 0 6 3
5 10 0 0 2 6 4
</table>
<bodyText confidence="0.9956785">
form. The remainder of this paper explores issues of
inferring utterance function partly from utterance form.
</bodyText>
<subsectionHeader confidence="0.613322">
6 Analysis of Utterance Forms: Identification
Requests
</subsectionHeader>
<bodyText confidence="0.999979451612904">
Thus far, explicit identification requests have been shown
to be pervasive in Telephone mode. One might expect
that, in analogous circumstances (i.e., with analogous
goals and perceptual capabilities), a robot might be
confronted with many of these acts. Computational
linguistics research then must discover algorithms for
determining an appropriate analysis and response, in part
as a function of utterance form. To see just which forms
are used for the task, utterances classified as identifica-
tion requests in Telephone mode were tabulated. The
full listing of identification requests can be found in
Appendix C.
Table 3 presents a classification of these utterances,
along with an example of each class. The utterance
forms are divided into four major groups, based on their
similarities in either syntactic or logical form. The first
group consists of utterances whose logical form is an
existential proposition (usually determined by the pres-
ence of an indefinite noun phrase). The second category
includes those utterances that mention perceptual actions
(e.g., &amp;quot;look&amp;quot;) and perceptual effects (such as &amp;quot;see&amp;quot;), but
are not syntactically imperatives. The third class contains
identification requests performed with utterance frag-
ments, usually noun or prepositional phrases (PPs). The
concept of fragment is not solely a syntactic classification
— hearers can be requested prosodically to respond to
NPs and PPs that are embedded in full sentences. Other
categories of utterance forms for identification requests
include what are &amp;quot;nearly direct&amp;quot; requests (i.e., imper-
atives and utterances that explicitly mention searching for
an object) and what are termed &amp;quot;Let&apos;s requests&amp;quot;, which
explicitly change the focus of attention to an object satis-
fying the description. Finally, one class of utterances,
accounting for 11% of identification requests and called
&amp;quot;supplemental NP&amp;quot; (e.g., &amp;quot;Put that on the opening in the
other large tube, with the round top&amp;quot;), was unreliably
coded and not considered for the analyses below. Cate-
gory labels followed by &amp;quot;(?)&amp;quot; indicate that the utterances
comprising those categories might also have been issued
with rising intonation. Typically, such utterances were
coded as questions and also as requests for identification.
The important thing to notice in Table 3 is that in
Telephone mode identification requests were almost never
performed directly. No speaker used direct forms, e.g.,
&amp;quot;Find the rubber ring shaped like an 0&amp;quot;, which occurred
frequently in the Written modality (Tierney et al. 1983).
However, the use of indirection is selective — Telephone
experts frequently use direct imperatives to perform
assembly requests. Moreover, many speakers adopted a
consistent style. For example, all the &amp;quot;nearly direct
requests&amp;quot; came from one speaker, and another almost
uniformly used the &amp;quot;there&apos;s a NP&amp;quot; strategy.
Because explicit identification requests come in many
syntactic forms, each of which has a literal interpretation
that is not an identification request, the hearer needs
some method for deciding what the speaker&apos;s intention(s)
are. Ideally, such reasoning should be an application of
more general reasoning about nonlinguistic actions. Of
course, a suitable &amp;quot;compiling&amp;quot; strategy can specialize the
general case for this task (cf. Brachman et al. 1979).
Below, I sketch such a theory and apply it to the exam-
ples in Table 3.
</bodyText>
<subsectionHeader confidence="0.99613">
6.1 A sketch of a plan-based theory of communi-
cation
</subsectionHeader>
<bodyText confidence="0.998779909090909">
The unifying theme of much current pragmatics research
is that the coherence of dialogue is to be found in the
interaction of the conversants&apos; plans. That is, a speaker
is regarded as planning his utterances to achieve his
goals, which may involve influencing a hearer. On
receiving an utterance, the hearer attempts to infer the
speaker&apos;s goal(s), and to understand how the, utterance
furthers them. The hearer then adopts new goals (e.g., to
respond to a request, to clarify the previous speaker&apos;s
utterance or goal), and plans his own utterances to
achieve those. A conversation ensues.
</bodyText>
<table confidence="0.4855855">
Computational Linguistics Volume 10, Number 2, April-June 1984 111
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</table>
<tableCaption confidence="0.942876">
Table 3. Identification requests in telephone mode.
</tableCaption>
<figure confidence="0.955801272727273">
Group Category [Example] Per Cent of Request(Ident.)
A. EXISTENTIAL PROPOSITIONS
I. THERE&apos;S A NP(?) 25%
[&amp;quot;there&apos;s a black o-ring (?)&amp;quot;]
2.OBJ HAS PART(?) 14%
[&amp;quot;It&apos;s got a peg in it&amp;quot;
3. LISTENER HAS OBJ? 10%
[&amp;quot;Now you have two devices that are clear plastic&amp;quot;]
4. DESCRIPTION1 = DESCRIPTION2 9%
[&amp;quot;The other one is a bubbled piece with a blue base on it with one spout&amp;quot;]
B. PERCEPTION-BASED
</figure>
<listItem confidence="0.902297333333333">
1. INFORM(IF ACT THEN EFFECT) 2%
[&amp;quot;If you look at the bottom you will see a project&amp;quot;]
2. QUESTION(EFFECT) 5%
[&amp;quot;If you look at the bottom you will see a projection&amp;quot;]
3. INFORM(EFFECT) 2%
[&amp;quot; you will see two blue tubes&amp;quot;]
C. FRAGMENTS
1. NP AND PP FRAGMENTS (?) 12%
[&amp;quot;The smallest of the red pieces?&amp;quot;]
2. PREPOSED OR INTERIOR PP (?) 6%
rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;]
D. NEARLY DIRECT REQUESTS
</listItem>
<bodyText confidence="0.930940171428571">
[&amp;quot;Look at the bottom of the tube&amp;quot;] 1%
[&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1%
E. LET&apos;S REQUESTS
[&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5%
Recent work of this type (Allen 1979, Appelt 1981,
Bruce 1983, Bruce and Newman 1978, Bruce and
Schmidt, Cohen 1978, Cohen and Levesque 1980,
Cohen and Perrault 1979, Perrault and Allen 1980,
Schmidt 1975, Sidner and Israel 1981) has resulted in
formal and computational models of communication that
have been applied in analyzing dialogues about tasks and
stories. The general features of the models include: a
simple theory of action, definitions of various physical
and communicative actions, a set of inference rules for
formulating and recognizing plans of action, a formaliza-
tion of agents&apos; beliefs, goals, and expectations, and a
mapping of utterance forms to the &amp;quot;surface speech
actions&amp;quot; speakers are performing in making those utter-
ances.
For the purposes of this paper, planning is simplis-
tically viewed as the process of finding an action (or a
sequence of them) that will achieve the agent&apos;s goal(s)
given what he believes to be the state of the world.
Roughly speaking, to recognize an agent&apos;s plan in
performing an action, observers deploy a theory of plan-
ning &amp;quot;in reverse&amp;quot; to connect the observed action with a
chain of inferences of the form &amp;quot;agent did X in order to
achieve Y, which would enable him to do Z&amp;quot;, terminating
in (what they take to be) a likely or expected goal of the
agent (Allen 1979; Genesereth 1978; Schmidt, Sridhar-
an, and Goodson 1979; Wilensky 1978). Such reasoning
employs beliefs about the agent&apos;s beliefs, conditions that
are likely to be true at the end of an action, other actions
that are enabled by those conditions, and expected plans
and goals of that agent.
</bodyText>
<page confidence="0.793254">
112 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.345604">
Philip R. Cohen The Pragmatics of Referring and the M, odality of Communication
</note>
<subsectionHeader confidence="0.999457">
6.2 Analyzing indirect identification requests
</subsectionHeader>
<bodyText confidence="0.8929275">
Perrault and Allen (1980) have proposed the following
plan-recognition inferences:
</bodyText>
<listItem confidence="0.957676875">
• Action-effect: If the observer thinks the agent wants to
do an action, the observer can posit that the agent
wants that action done in order to achieve its typical
effect.
• Precondition-action: If the agent is thought to want
some proposition P to be true, and P is the precondi-
tion of an action known to the agent, consider that the
agent&apos;s goal is to perform that action.
• Body-action: If the agent is thought to have a goal that
is the means by which a &amp;quot;higher level&amp;quot; action is
performed, then consider that the agent is attempting
to perform that action.19
• Knowif: If the agent is thought to want to know
whether or not some proposition P holds, then consid-
er that the agent wants P to hold (or wants P to be
false).
</listItem>
<bodyText confidence="0.999965">
The plan-recognition process first classifies utterances
by their mood into so-called &amp;quot;surface speech acts&amp;quot;:
declaratives become instances of the S-INFORM act type,
imperatives become S-REQUESTS, and questions become
S-REQUESTS to INFORMIF or INFORMREF (for Yes/No
and Wh questions, respectively). These surface acts are
the prototypical ways to perform the corresponding illo-
cutionary acts REQUEST, INFORM, and REQUEST to
INFORMIF.2°
Grice (1957) has argued that a simple plan-recognition
process, which an unseen observer might perform, cannot
be the basis for communication. Rather, the hearer must
infer and act on what the speaker wants him to think she
wants. A plan-based theory proposes that such reason-
ing is invoked by applying the independently motivated
plan-recognition process to the observed communicative
actions. Hearers are, in effect, asking themselves &amp;quot;Why
did the speaker say that?&amp;quot; Subsequent reasoning, termed
here intended plan recognition, derives other goals that the
hearer thinks she or he was supposed to infer. The proc-
ess of attributing goals to an agent is terminated when an
inference path merges with a mutually expected goal of
that agent.
This plan-based approach has led to a first explanation
of a large class of &amp;quot;indirect speech acts&amp;quot; — utterances
whose surface form indicates one speaker intention, but
for which additional intentions should be recognized.
For example, although &amp;quot;Can you reach the hammer?&amp;quot; is
literally a yes/no question, the speaker may have another
goal — to get the hearer to pass the hammer to the speak-
er. The essential insight of the theory is that indirect
speech act recognition is a by-product of the general
process of recognizing someone&apos;s plans. If illocutionary
act identification occurs immediately after the expansion
of a surface act, then a literal interpretation has been
found. If there are intervening intended plan-recognition
inferences, then an indirect interpretation has been
inferred.
</bodyText>
<subsectionHeader confidence="0.998209">
6.3 Example
</subsectionHeader>
<bodyText confidence="0.998772111111111">
The following example is intended to give a brief intro-
duction to the reasoning underlying indirection. Details
of this process can be found in (Allen and Perrault 1980,
Perrault and Allen 1980). The utterance to be interpret-
ed is, &amp;quot;Can you reach the hammer?&amp;quot; The inferred prop-
ositions are indicated in boldface; commentary on the
inference process is indented.
After parsing and semantic interpretation, the utter-
ance is represented as a surface speech act:
</bodyText>
<sectionHeader confidence="0.781233" genericHeader="method">
HBSW (S-REQUEST(S,H,INFORMIF(H,S,
</sectionHeader>
<subsectionHeader confidence="0.429883">
CANDO(H,REACH(H,HAMMER)))))
</subsectionHeader>
<bodyText confidence="0.97987364516129">
That is, the Hearer Believes the Speaker Wanted
to perform (what appears to be) a yes-no ques-
tion about his ability to reach the hammer.
The effect of an S-REQUESTS to do action ACT
is simply that the hearer believes the speaker
wants the hearer to do ACT. Thus, applying the
action-effect inference to the S-REQUESTS act,
yields:
HBSW(HBSW(KNOWIF(S,
CANDO(H,REACH(H,HAMMER)))))
The first level of &amp;quot;HBSW&amp;quot; comes from assuming
the speaker&apos;s action was intentional. The second
level is derived from the effect of the surface
speech act. Now, intended plan recognition
involves deriving new formulas of the form
HBSW(HBSW(G)), i.e., the Hearer Believes the
Speaker Wants him to think the speaker&apos;s goal is
G. Any goals G&apos; derived with the prefix
HBSW(HBSW) are taken to have been communi-
cated (in the Gricean sense). The truth of the
preconditions to the actions that are inserted into
the (intended) plan being recognized are evalu-
ated with respect to the mutual beliefs of speaker
and hearer.
The two outer levels of &amp;quot;HBSW&amp;quot; are assumed to
embed all the following formulas. In particular,
applying the knowif inference at this level of
embedding, the hearer realizes the speaker wants
to knowif P (i.e., to know whether or not H can
reach the hammer) because he wants him to be
able to reach the hammer, yielding
</bodyText>
<footnote confidence="0.950165666666667">
19 Note that this inference can adversely affect the combinatorics of the
plan-recognition process.
&amp;quot; Levesque and I (in preparation) demonstrate how the intentions
underlying these indirect speech act analyses can be derived using the
surface speech acts and plan-recognition inferences, but not Perrault
and Allen&apos;s illocutionary acts.
</footnote>
<table confidence="0.400477333333333">
Computational Linguistics Volume 10, Number 2, April-June 1984 113
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
CANDO(H,REACH(H,HAMMER))
</table>
<bodyText confidence="0.96526575">
CANDO(H,ACT) is true when the preconditions
of ACT are true, and the speaker wants the prec-
onditions to be true because he wants the act
done:
</bodyText>
<figure confidence="0.975868">
REACH(H,HAMMER)
S wants the act done for its effect:
HAVE(H,HAMMER)
S wants the effect because it enables another
act:
PASS(H,S,HAMMER)
</figure>
<bodyText confidence="0.821312">
Finally, because the embedded HBSW(PASS...) is
a way of performing a request to pass the
hammer, the body-action inference yields:
</bodyText>
<sectionHeader confidence="0.843511" genericHeader="method">
HBSW (REQUEST(S,H,(PASS(H,S,HAMMER))))
</sectionHeader>
<bodyText confidence="0.981244458333333">
Of course, the procedure could also have derived
a request to reach the hammer. It does not do so
because of the &amp;quot;level-of-inference&amp;quot; heuristic that
pursues inference paths at the HBSW(HBSW)
level of embedding before those with just the
HBSW level of embedding. Applying the action-
effect inference to the REQUEST action, and
collapsing a few uninteresting inferences, H
infers:
HBSW(PASS(H,S,HAMMER))
Then, H arrives at:
HBSW(HAVE(S,HAMMER))
Because the speaker&apos;s having the hammer was
(assumed to be) an expected goal, the inference
process stops.
To summarize, the plan-based theory views speech
actions as planned actions that can be reasoned about in
the same ways as physical actions. Indirect speech act
interpretation involves linking the surface speech act
characterizing each utterance with some expected goal
through a chain of means-ends reasoning. When applied
to a discourse, the plan-based theory attempts to mediate
between utterance form and a (potentially changing) set
of beliefs, goals, and expectations.
</bodyText>
<subsectionHeader confidence="0.999288">
6.4 Applying the theory
</subsectionHeader>
<bodyText confidence="0.999845714285714">
Assume that syntactic and semantic components have
already analyzed the utterances, resulting in a logical
form for each sentence or complete constituent. Further-
more, assume that the apprentice has inferred the follow-
ing expectations about the expert&apos;s goals: &amp;quot;For each
piece making up the pump: The expert gets the appren-
tice to: identify the piece, pick it up, and perform some
assembly action on it.&amp;quot; Such expected goals can be used
to terminate the process of plan recognition. Now, many
of the utterance forms can be analyzed as requests for
identification once an act for physically searching for the
referent of a description has been posited. For conven-
ience, the definition of IDENTIFY-REFERENT, from
section 3.1, is repeated below:
</bodyText>
<sectionHeader confidence="0.946825" genericHeader="method">
V D Agt
3 X [PERCEPTUALLY-
ACCESSIBLE(X, Agt) &amp;
</sectionHeader>
<figure confidence="0.964637666666667">
D(X) &amp;
IDENTIFIABLE(Agt,D)]
3 X [RESULT(Agt,
IDENTIFY-REFERENT(D),
IDENTIFIED-REFERENT
(Agt, D, X)]
</figure>
<figureCaption confidence="0.999814">
Figure 4. The act of referent identification.
</figureCaption>
<subsectionHeader confidence="0.901154">
6.4.1 Existential propositions
</subsectionHeader>
<bodyText confidence="0.999979842105263">
The utterances in Class A can then be analyzed as
requests for IDENTIFY-REFERENT by applying plan
recognition to the definition of the surface speech acts.
Class A includes all declarative utterances whose logical
form is an existential proposition (3 X P(X)), which
includes utterances of the form &amp;quot;there is a ....&amp;quot;, &amp;quot;you
have a ....&amp;quot;, and &amp;quot;[object] has a .... [part]&amp;quot;. These utter-
ances would appear literally to be informative. However,
they can be interpreted as requests that the hearer
IDENTIFY-REFERENT of the description &amp;quot;the P&amp;quot; by
reasoning that a speaker&apos;s wanting a hearer to believe
that a precondition to an action (IDENTIFY-REFERENT)
is true can communicate (in the Gricean way) that the
speaker wants that action to be performed, provided the
act&apos;s effect is mutually known to be an expected goal of
the speaker&apos;s.
For example, &amp;quot;it&apos;s got a peg in it&amp;quot; is represented as 3 x
[INSIDE(x, PLUNGER) &amp; PEG(x)]. Informing a hearer of
this proposition yields sufficient conditions for inferring
</bodyText>
<sectionHeader confidence="0.889747" genericHeader="method">
IDENTIFY-REFERENT (APPRENTICE, [INSIDE(x,
</sectionHeader>
<bodyText confidence="0.999837642857143">
PLUNGER) &amp; PEG(x)1), whose effect unifies with a
mutually expected goal. Thus, the existing indirection
machinery can handle these cases.21
Yes/no questions can be recognized as requests for
identification by the means of the same plan-recognition
process. There are two cases. In one case, the hearer is
modelled as inferring that the speaker wants the proposi-
tion in question to be true because it enables some action
(i.e., IDENTIFY-REFERENT) to be performed that will
yield a desired effect (IDENTIFIED-REFERENT). The
inference takes hold because it is mutually believed that
the speaker already knows the answer to his question.
For example, in saying, &amp;quot;There&apos;s a little blue cap?&amp;quot; it is
shared knowledge that the speaker already knows such a
</bodyText>
<page confidence="0.81488">
114 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.392011">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<bodyText confidence="0.972730375">
cap is in front of the hearer. Therefore, finding out
whether there is such a cap could not be the speaker&apos;s
goal.22 In the second case, the hearer wants to know
whether some proposition is true because he wants it to
be true (or false), and wants the hearer to make it true
(or false). In this way, questioning IDENTIFIED-
REFERENT can be taken as a request for
IDENTIFY-REFERENT.23,24
</bodyText>
<subsectionHeader confidence="0.547154">
6.4.2 Perception-based utterances
</subsectionHeader>
<bodyText confidence="0.994187456140351">
Plan recognition can also suggest how Class B utterances
all convey requests for referent identification. In this
class, ACT = LOOK-AT, EFFECT = AGENT SEE X.
Because LOOK-AT is one of the constituent acts of
IDENTIFY-REFERENT, Perrault and Allen&apos;s &amp;quot;body-
action&amp;quot; inference, given a formalization of perceptual
actions and their relation to searching, should make the
necessary connection — the speaker wanted the hearer to
LOOK-AT something as part of his IDENTIFY-
REFERENT act. Specifically, Case 1 [&amp;quot;If you look, you
will see...&amp;quot; (If you don&apos;t, you won&apos;t)] again appears to be
an informative utterance about a conditional. The speak-
er&apos;s intent that the hearer actually look for something is
derived by an inference saying that if a speaker commu-
nicates that an act will yield some desired effect, then one
can infer that the speaker wants that act performed to
achieve that effect. Case 2 (&amp;quot;Do you see X&amp;quot;) is again
indirect because the hearer can truthfully answer &amp;quot;No&amp;quot; if
he is looking out the window. Again the appropriate
21 The formalism also predicts that, in this task, an indirect request to
identify an object would also be an indirect request to pick up that
object, because the line of inference is unambiguous and its end goal is
mutually believed to be desired. If it were mutually believed that a
possible end goal of the inference path (e.g., that the apprentice be
holding the piece) was not desired (because, for instance, the piece was
known to be hot), then the hearer would not infer he was supposed to
pick up the piece. Although the coders were not asked to make this
distinction, further analysis indicates the modality differences are stron-
ger when pick-up requests are considered together with identification
requests in Analysis 2. In Telephone mode, all 5 subjects were habitual
users of either identification or pick-up requests, whereas no subjects
were habitual users of either of those request types in Keyboard mode.
Differences across modes are significant (p = 0.004).
&amp;quot; &amp;quot;Do you have homework to do?&amp;quot; is similarly identified as a request
that you do your homework.
23 A similar inference occurs in recognizing &amp;quot;Is the garbage out?&amp;quot; as a
request to take out the garbage.
&apos; Occasionally, speakers appear to ask &amp;quot;real&amp;quot; questions. For example,
after requesting the hearer to identify a part, a speaker asked, &amp;quot;Do you
see that?&amp;quot; I would have coded this as a true question, and not as an
identification request, because the goal of an identification request (the
speaker&apos;s communicating his intent that the hearer identify the piece)
has already been achieved. The interrogative, then, is truly a question
about whether the part has been identified. The coders, however, were
not asked to make this distinction. The formalism makes predictions
concerning which utterances were identification requests and which
were only questions; since the codings did not reflect this difference, we
have considered all questions to be identification requests. The number
of cases of suspected true questions is small enough that the quantita-
tive results are still valid.
intention — that the hearer look for X — can be inferred
by noticing that the speaker&apos;s questioning whether the
desired effect of an act holds conveys the sense that the
act itself is desired (e.g., &amp;quot;Is the garbage out?&amp;quot;). Case 3
(&amp;quot;You will see X&amp;quot;) is similar to Case 1, except that the
relationship between the desired effect and the action
yielding that effect is presumed.
</bodyText>
<subsectionHeader confidence="0.917446">
6.4.3 Fragments
</subsectionHeader>
<bodyText confidence="0.986064918918919">
Group C utterances constitute the class of fragments
classified as requests for identification. Case 1 includes
NP fragments, often with rising intonation. The action to
be performed is not explicitly stated, but must be
supplied on the basis of shared knowledge about the
discourse situation — who can do what, who can see
what, what each participant thinks the other believes,
what is expected, etc.
Allen and Perrault&apos;s (1980) method of handling frag-
ments involves unifying (in the technical sense of the
term) the effects of the possible surface speech acts
corresponding to the fragment with expected goals of the
speaker. The result is a more fully specified goal that can,
perhaps, be acted on. For questioned singular definite
noun phrases (NP), their model proposes two possible
incomplete surface speech acts:
S-REQUEST(S,H,INFORMIF(H,S, 4, (ixNPx))), and
S-REQUEST(S,H,INFORMREF(H,S, iy[ 4, (ixNPx) = y])).
For example, on hearing &amp;quot;The Windsor train?&amp;quot; the
system would initially take the speaker either to be &apos;asking
a yes/no question about some property 4, of the referent
of &amp;quot;the Windsor train&amp;quot;, or to be asking to know that the
referent of the value of applying some function ip to the
referent of &amp;quot;the Windsor train&amp;quot;. The respective effects
of these surface acts would involve the hearer&apos;s thinking
the speaker&apos;s goal is to know whether or not that predi-
cate 4, holds, or to know the identity of the referent of iy[
tp (ixNPx) = y])). The appropriate predicates (0) and
functions (4,) need to be supplied from domain-depen-
dent expectations. In the former case, the predicate 4
might be (LAMBDA y (LEAVES-AT(y,4:40))), whereas in
the latter case, the function 4, might be (LAMBDA y (
GATE(y))).
Consider a questioned noun phrase, and just the
yes/no question interpretation. The next step, according
to the theory, is to infer that (it is shared knowledge) that
the speaker wants (the hearer to think) that the speaker&apos;s
goal is that 0 (iyNPy) be true. The properties 0 needed
to &amp;quot;fill in&amp;quot; such fragments come from mutually expected
goals of the expert. The expected goal in question for
this domain, which is (somehow) derived from the nature
of the task as one of manual assembly, is
(IDENTIFIED-REFERENT APPRENTICE D X), where D
becomes bound to iyNPy, X names the referent, and 0 is
IDENTIFIED-REFERENT.
Computational Linguistics Volume 10, Number 2, April-June 1984 115
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
From this, the apprentice infers that he should make
(IDENTIFY-REFERENT APPRENTICE iyNPy X) true. In
the same way that questioning the completion of an
action can convey a request for action, questioning
IDENTIFIED-REFERENT conveys a request for
IDENTIFY-REFERENT (see Case 2, Group B, above).
Thus, by my positing an IDENTIFY-REFERENT act, and
by my assuming that the effect of this act is expected, the
inferential machinery can derive the appropriate inten-
tion behind the use of a noun phrase fragment.
Notice that &amp;quot;fragment&amp;quot; is not a simple syntactic classi-
fication. In Case 2 (&amp;quot;In the green thing at the bottom
[pause]&amp;quot; &amp;quot;Mmhm&amp;quot;), the speaker paralinguistically &amp;quot;calls
for&amp;quot; a hearer response in the course of some linguistically
complete utterance. Because of the nature of the task,
Case 2 is coded as an identification request. A simple
syntactic classification of fragments would not consider
this request as fragmentary.25
This treatment of fragments is different from the usual
one in computational linguistics, in which the fragment is
matched into prior syntactic forms. Such an approach
cannot work for fragments spoken without prior linguis-
tic context, nor for fragmented adverbials whose coher-
ence depends on a prior system action. Allen and
Perrault&apos;s approach is an attempt to access the user&apos;s goal
without reconstructing either a full syntactic or semantic
analysis.
</bodyText>
<subsectionHeader confidence="0.640737">
6.4.4 Nearly direct requests
</subsectionHeader>
<bodyText confidence="0.999810583333333">
Group D utterance forms are the closest forms to direct
requests for identification that appeared, though strictly
speaking, they are not direct requests. Case 1 (&amp;quot;Look at
the bottom of the tube&amp;quot;) mentions &amp;quot;Look at&amp;quot;, but does
not indicate a search explicitly. The interpretation of this
utterance in Perrault and Allen&apos;s scheme would require
an additional &amp;quot;body-action&amp;quot; inference to yield a request
for identification. Case 2 (&amp;quot;The next thing you&apos;re gonna
look for is...&amp;quot;) is literally an informative utterance,
though a request could be derived in one step. It is
important that the frequency of these &amp;quot;nearest
neighbors&amp;quot; is minimal (2%).
</bodyText>
<subsectionHeader confidence="0.711202">
6.4.5 &amp;quot;Let&apos;s&amp;quot; requests
</subsectionHeader>
<bodyText confidence="0.999777333333333">
One speaker used &amp;quot;Let&apos;s&amp;quot; requests explicitly to shift the
topic of conversation to one previously &amp;quot;closed&amp;quot; (Grosz
1977), and in the process to get the hearer to re-identify
an object. Whereas other identification requests shift the
topic as a by-product, this request seems literally to be a
topic shift, with identification as a by-product.
</bodyText>
<subsectionHeader confidence="0.992415">
6.5 Summary
</subsectionHeader>
<bodyText confidence="0.99987255">
The act of explicitly requesting referent identification is
nearly always performed indirectly in Telephone mode.
This being the case, inferential mechanisms are needed
for uncovering the speaker&apos;s intentions from the variety
of forms with which this act is performed. A plan-based
theory of communication accounts for 69% of the iden-
tification requests in the corpus [class A (56%), class Cl
(12%), and class D2 (1%)]. Furthermore, plan recogni-
tion can infer the LOOK-AT action from the perception-
based utterances [class B (9%)], but cannot yet connect
LOOK-AT to IDENTIFY-REFERENT, because the means
for performing IDENTIFY-REFERENT remains unspeci-
fied. Class C2 (preposed or interior prepositional phras-
es) requires a prosodic analysis to determine that a
hearer response is called for and precisely what constitu-
ent is in question. With such an analysis, Perrault and
Allen&apos;s fragment analysis can employ expectations to
respond appropriately. Finally, Class E (&amp;quot;Let&apos;s&amp;quot;
requests) is problematic for this theory (but see Grosz
1977).
</bodyText>
<sectionHeader confidence="0.866967" genericHeader="method">
7. Alternative Explanations Countered
</sectionHeader>
<bodyText confidence="0.884763527777778">
I have argued that to interpret indirect identification
requests, the apprentice needs to reason about the
expert&apos;s intent. Alternative explanations could be envi-
sioned that would place the burden of noun phrase inter-
pretation entirely on the hearer. According to such
accounts, the hearer would act on a noun phrase as he
pleased, independent of the speaker&apos;s intended use of
that noun phrase. A succession of such explanations is
countered below.
1. The hearer will identify the referent of every noun
phrase. Clearly, for both definite and indefinite noun
phrases, this explanation is inadequate. Noun phras-
es such as &amp;quot;See the tapered red piece with the hole?
That&apos;s the nozzle&amp;quot;, and &amp;quot;We need a valve for that
hole. It&apos;s the little yellow piece of rubber&amp;quot;, supply
functional descriptions or labels that cannot be iden-
tified at the time of utterance.26 Rather, the speaker
informs the hearer about some future function of that
piece.
2. The hearer identifies every description he can. For
example, perhaps a hearer will identify all things
described with color or shape terms, or all noun
phrases with existential presuppositions. However,
this is again too simplistic. A hearer will undoubt-
edly not react to &amp;quot;there is a red cobra under that
basket&amp;quot;, by trying to identify the cobra because, in
short, he doesn&apos;t want to.
3. The hearer identifies every description he can identify
and wants to identify. That is, the hearer would
25 Such examples of parallel achievement of communicative actions
cannot be accounted for by any linguistic theory or computational
linguistic mechanism of which I am aware. These cases have been
included here because I believe that the theory should be extended to
handle them by reasoning about parallel actions.
The IDENTIFIABLE precondition was posited to prevent such noun
phrases from being identified.
</bodyText>
<page confidence="0.812512">
116 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.393716">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<bodyText confidence="0.999775675675675">
ignore what the speaker intends, and act on what he
thinks is both feasible and desirable. To see that this
cannot be the hearer&apos;s sole strategy, consider the
following Telephone dialogue (and recall that the
expert had a set of pieces in front of him, though the
apprentice did not know this):
Expert: Now, take the big blue stopper that&apos;s
laying around and take the black ring...&amp;quot;
Apprentice: [Searches and repeats more slowly]
&amp;quot;the big blue stopper&amp;quot;
Expert:&amp;quot;Yeah, the big blue stopper [short pause] and
black ring.&amp;quot;
Although the apprentice could be said to be follow-
ing the purported reference strategy in response to
the expert&apos;s definite noun phrase, the same could not
be said of the expert in responding to the same NP.27
The expert is obviously not intended by the appren-
tice to identify the piece even though he could,
because he has just requested the apprentice to do
so, and because the expert&apos;s having a set of pieces
was not mutually believed. The expert responds to
(what he believes to be) the apprentice&apos;s purpose in
repeating the NP, and not solely to his own desires
and capabilities.
According to the above argument, the hearer cannot
be completely egocentric in his interpretation of noun
phrases, but considers the speaker&apos;s intentions with
respect to that noun phrase.28 One might still argue,
however, that such consideration is quite simple; that a
conversational &amp;quot;script&amp;quot; (Schank and Abelson 1977),
involving the specification of the part the expert desires
the apprentice to pick up and the assembly action to be
performed on it, could handle the data. I argue that
because the script notion of role already incorporates the
expected goals of the parties who are playing each role, a
script argument supports the position that noun phrase
interpretation requires analysis of speaker intent.
</bodyText>
<subsubsectionHeader confidence="0.570092">
4. The apprentice fits the noun phrase into the script for
</subsubsectionHeader>
<bodyText confidence="0.97976218">
his role in the experiment. Scripts (Schank and Abel-
son 1977) contain expected sequences of actions,
related in some &amp;quot;causal chain&amp;quot;, in some stereotyped
situation. According to Schank and Abelson, typical
scripted situations might include birthday parties,
restaurants, classrooms, etc. Scripts are parameter-
ized by &amp;quot;slots&amp;quot; that define &amp;quot;roles&amp;quot; in the various
actions and events. Essentially, a script&apos;s partic-
ipants perform the specified actions, which, having
been a successful pattern of interaction in the past,
are already structured to achieve the goal(s) of the
script. &amp;quot;Dialogue Games&amp;quot; Levin and Moore (1977)
can be seen as scripts once utterances are viewed as
communicative acts.
I claim that a script analysis of the discourses in
the present experiment, if sufficiently detailed,
supports the positions that (1) noun phrase interpre-
tation requires an analysis of speaker intent, and (2)
the speaker&apos;s intent is that the hearer perform an
action of referent identification. The argument has
three prongs: the contents of the purported script,
the apprentice&apos;s inferring of that script, and the
relationship of the script to the utterances.
First, as Schank and Abelson have pointed out,
scripts are frozen plans. When two parties agree
(perhaps tacitly) to play roles in a script, they have
adopted their (respective) expected actions as part of
their (respective) plans. This observation supports
both of the above points. The contents of the script
become expected goals, and the script contains
actions that each participant is supposed to play.
Any specification of the actions in the purported
experimental script will contain the apprentice&apos;s
performing IDENTIFY-REFERENT actions as a goal
of the expert.
Second, the script needs to be inferred. The stan-
dard, well-worn, mundane activities (such as eating
at a restaurant) that are claimed to be captured in
scripts may not apply here. Apprentices may never
have been in similar circumstances before (such as
being in an experiment, or being instructed over a
telephone), and thus may not have had a preexisting
script. Furthermore, the apprentices were not told
the script in the instructions nor by the expert
(generally speaking, although there were a few
exceptions). Thus, to the extent that a script is avail-
able to the participants, it would have been
inferred.29 Because scripts are frozen plans, to infer a
script, apprentices would have engaged in a process
of plan recognition in advance of engaging in the
experimental task, or while the task was being
achieved.
This process of inferring a script yields a set of
expected actions. The plan-based theory of commu-
nication would require that the elements of a script
be mutually expected and intended — i.e., that they
would represent mutual beliefs about intended future
actions. Such mutual expectations about each others&apos;
goals can terminate the process of plan recognition
&amp;quot; It is apparent that the two NP&apos;s are spoken with different intonation
and timing. Prosodic aspects of an utterance are often regarded as
signalling the speaker&apos;s attitude or intent toward what is being said.
Thus, perhaps the speaker is prosodically signalling the &amp;quot;wait while I
identify&amp;quot; intent. This conclusion supports the argument that speaker
intent plays a role in processing descriptions.
&amp;quot; The &amp;quot;referential communication&amp;quot; literature considers the converse
position — whether speakers are egocentric in producing noun phrases
for a hearer (Asher 1979).
&amp;quot; No mechanisms have been proposed in the literature that can derive
such expectations of the expert&apos;s goals from more basic information
about the task, modality, genre, etc. At most, what has been proposed is
the ability to use such expectations, independently of how they are
derived.
Computational Linguistics Volume 10, Number 2, April-June 1984 117
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
applied to utterance interpretation. Thus, the infer-
ring of a script that contains the expert&apos;s intent that
the hearer identify the referents of descriptions is
consistent with my proposal.
Although much of the determination of speaker intent
has been precomputed, the utterance itself cannot be
ignored. The results of this study show that speakers in
the Telephone condition do not achieve their referential
goals with direct requests, as they do in the Written
condition (Tierney et al. 1983). The analysis of indi-
rection used here (and similarly advocated by most
speech act theorists) requires that speaker intent be
recognized as a function, in part, of utterance form.
Possible specifications of illocutionary force are derived
from features of the utterance. Indirect speech acts are
recognized through a chain of intended plan-recognition
inferences (based on mutual beliefs) deriving subsequent
intended inferences that, if confirmed by mutually
expected goals, communicate speaker intent.
One might still argue that the reasoning involved in
processing these indirect speech acts has become short-
circuited into a convention of language usage. According
to such an account, &amp;quot;conscious&amp;quot; inference is unnecessary
for utterances with conventional forms, such as &amp;quot;Can you
do X?&amp;quot; For such utterances, the argument goes, people
simply &amp;quot;know&amp;quot; such utterances are conventional
requests. In contrast, the plan-based theory would
appear to propose a Baroque way of uncovering the
speaker&apos;s intention.
Apart from the lack of evidence that, for example, the
&amp;quot;there&apos;s a&amp;quot; construction has become conventionalized,
accounts of indirect speech acts based solely on conven-
tion are inadequate. A conventional account cannot
handle the many creative uses of indirection (e.g., &amp;quot;It&apos;s
cold in here&amp;quot;), nor the case of intended literal interpreta-
tions of conventionally indirect speech acts (such as
asking a companion on a lifeboat, &amp;quot;Can you swim to
shore?&amp;quot;). The plan-based theory is suited to such cases.
On the other hand, the indirect speech acts that are
usually regarded as conventional can be handled within
the plan-based theory in a comparably efficient way,
because inference paths can be precomputed from
surface speech acts characterizing utterance forms (rath-
er than always being derived from first principles, as vari-
ous critiques assume). &amp;quot;Bottom-up&amp;quot; derived rules can be
used in concert with the more general-purpose rules,
much as lemmas are used in a proof (Cohen and
Levesque 1980).3° Such an &amp;quot;ability is needed to account
for examples such as &amp;quot;Can you reach the hammer&amp;quot;, that
cannot be handled by conventional methods alone (which
would only be able to derive a request to reach the
hammer, rather than as a request to pass it).
Scripts are often viewed as short-cuts for more general
processing. The plan-based position advocated here
conforms to the intuition that scripted situations should
give rise to simple processing. By combining strong top-
down expectations with bottom-up derived rules based
on utterance form, utterances can be interpreted with
minimal inference. However, because the plan-based
approach incorporates both short-cuts and general mech-
anisms for reasoning about speaker intent, the theory
applies equally well in nonscripted situations.
In summary, a script analysis, if appropriately detailed
and formalized, supports the position that speaker intent
plays a role in noun phrase interpretation, and that refer-
ent identification needs to be reasoned about in the same
way as other acts. Essentially, the argument states that
scripts are frozen plans, that apprentices inferred these
plans, and that the plans indicated that the apprentice
should perform actions of referent identification.
The next section shows that the data in this exper-
iment cause difficulty for Searle&apos;s analysis of referring.
Furthermore, it shows that the present analysis can be
extended to cover those cases of referring for which
Searle&apos;s is applicable.
</bodyText>
<sectionHeader confidence="0.647235" genericHeader="method">
8 Referring as Requesting
</sectionHeader>
<bodyText confidence="0.996710129032258">
Searle (1969) has argued forcefully that referring is a
speech act; that people refer, not just expressions. This
section considers what kind of speech act referring might
be. I propose a generalization of Searle&apos;s &amp;quot;propositional&amp;quot;
act of referring that treats it as an illocutionary act, a
request, and I argue that a special level of propositional
acts for referring is unnecessary.
The essence of the argument is as follows: First, I
consider Searle&apos;s definition of the propositional act of
referring (which I term the PAA, for Propositional Act
Account). This definition is found to be inadequate to
deal with various utterances in discourse used for the sole
purpose of referring. Although the relevance of such
utterances to the propositional act has been defined away
by Searle, it is clear that any comprehensive account of
referring should treat them. I show that the act of
requesting referent identification, which I term the illocu-
tionary act analysis (IAA) satisfies Searle&apos;s conditions for
referring, yet also captures utterances that the PAA
cannot. The converse position is then examined: Can
the IAA capture the same uses of referring expressions as
the PAA? If one extends the perceptually based notion
of referent identification to include Searle&apos;s concept of
identification, then by associating a complex proposi-
tional attitude to one use of the definite determiner, a
request can be derived. The IAA thus handles the refer-
ring use of definite noun phrases with independently
motivated rules. Referring becomes a kind of requesting.
Hence, the propositional act of referring is unnecessary.
&amp;quot; These derived rules are akin to Morgan&apos;s (1978) &amp;quot;short-circuited
implicatures&amp;quot;.
</bodyText>
<page confidence="0.871604">
118 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.50722">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<subsectionHeader confidence="0.995804">
8.1 Referring as a propositional speech act
</subsectionHeader>
<bodyText confidence="0.999904916666667">
Revising Austin&apos;s (1962) locutionary/illocutionary
dichotomy, Searle distinguishes between illocutionary
acts (IAs) and propositional acts (PAs) of referring and
predicating. Both kinds of acts are performed in making
an utterance, but propositional acts can only be
performed in the course of performing some illocutionary
act.
Let us consider Searle&apos;s rules for referring, the PAA.
A speaker, S, &amp;quot;successfully and non-defectively performs
the speech act of singular identifying reference&amp;quot; in utter-
ing a referring expression, R, in the presence of hearer,
H, in a context, C, if and only if:
</bodyText>
<listItem confidence="0.991161611111111">
1. Normal input and output conditions obtain.
2. The utterance of R occurs as part of the utterance of
some sentence (or similar stretch of discourse) T.
3. The utterance of T is the (purported) performance of
an illocutionary act.
4. There exists some object X such that either R
contains an identifying description of X or S is able
to supplement R with an identifying description of X.
5. S intends that the utterance of R will pick out or
identify X to H.
6. S intends that the utterance of R will identify X to H
by means of H&apos;s recognition of S&apos;s intention to iden-
tify X, and he intends this recognition to be achieved
by means of H&apos;s knowledge of the rules governing R
and his awareness of C.
7. The semantical rules governing R are such that it is
correctly uttered in T in C if and only if conditions
1-6 obtain.&amp;quot; (Searle 1969, pp. 94-95.)
</listItem>
<bodyText confidence="0.997411086956522">
Conditions 2 and 3 are justified as follows:
Propositional acts cannot occur alone; that is one
cannot just [emphasis in original — PRC] refer and
predicate without making an assertion or
asking a question or performing some other
illocutionary act.... One only refers as part of
the performance of an illocutionary act, and
the grammatical clothing of an illocutionary
act is the complete sentence. An utterance of
a referring expression only counts as referring
if one says something. (Mid, p. 25.)
The essence of Conditions 4 and 5 is that the speaker
needs to utter an &amp;quot;identifying description&amp;quot;, For Searle,
&amp;quot;identification&amp;quot; means &amp;quot;.... there should no longer be any
doubt what exactly is being talked about&amp;quot;. (Ibid. p. 85.)
Furthermore, not only should the description be an iden-
tifying one (one that would pick out an object), but the
speaker should intend it to do so uniquely (Condition 5).
Moreover, the speaker&apos;s intention is supposed to be
recognized by the hearer (Condition 6). This last Grice-
an condition is needed to distinguish having the hearer
pick out an object by referring to it from, for example,
hitting him in the back with it.
</bodyText>
<subsectionHeader confidence="0.982608">
8.2 Problems for the propositional act account
</subsectionHeader>
<bodyText confidence="0.999993125">
I have shown that in giving instructions over a telephone,
speakers, but not users of keyboards, often make sepa-
rate utterances for reference and for predication.
Frequently, these &amp;quot;referential utterances&amp;quot; take the form
of existential sentences, such as &amp;quot;Now, there&apos;s a black
0-ring&amp;quot;, Occasionally, speakers use questioned noun
phrases — &amp;quot;OK, now, the smallest of the red pieces?&amp;quot; The
data present two problems for the PAA.
</bodyText>
<subsectionHeader confidence="0.742373">
8.2.1 Referring as a sentential phenomenon
</subsectionHeader>
<bodyText confidence="0.999828090909091">
Conditions 2 and 3 require the referring expression to be
embedded in a sentence or &amp;quot;similar stretch of discourse&amp;quot;
that predicates something of the referent as part of the
performance of some illocutionary act. However, it is
obvious that speakers can refer by issuing isolated noun
phrases or prepositional phrases. Because speakers
performed illocutionary acts in making these utterances,
then, according to Conditions 2 and 3, there should be an
act of predication, either in the sentence or the &amp;quot;similar
stretch of discourse&amp;quot;. For example, consider the follow-
ing dialogue fragment:
</bodyText>
<listItem confidence="0.999601">
1. &amp;quot;Now, the small blue cap we talked about before?&amp;quot;
2. &amp;quot;Uh-huh&amp;quot;
3. &amp;quot;Put that over the hole on the side of that tube....&amp;quot;
</listItem>
<bodyText confidence="0.9557758">
The illocutionary act performed by uttering phrase (1)
is finished and responded to in phrase (2) before the illo-
cutionary act performed in phrase (3) containing the
predication &amp;quot;put&amp;quot; is performed. The appeal to a sentence
or stretch of discourse in which to find the illocutionary
act containing the propositional act in (1) is therefore
unconvincing. The cause of this inadequacy is that,
according to Searle, to perform an illocutionary act, an
act of predicating is required, and the predicate must be
uttered (Searle, op. cit., pp. 126-127). Hence, there is no
appeal to context to supply obvious predications. Like-
wise, there is no room for context to supply an obvious
focus of attention. Unfortunately, we can easily imagine
cases in which an object is mutually, but nonlinguis-
tically, focused on (e.g., when Holmes, having come
upon a body on the ground, listens for a heartbeat, and
says to Watson: &amp;quot;Dead&amp;quot;). In such a case, we need only
predicate. Thus, the requirement that the act of refer-
ence be jointly located with some predication in a
sentence or illocutionary act is too restrictive — the goals
involved with reference and predication can be satisfied
separately and contextually. The point of this paper is to
bring such goals to the fore.
Computational Linguistics Volume 10, Number 2, April-June 1984 119
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</bodyText>
<subsectionHeader confidence="0.753855">
8.2.2 Referring without a propositional act
</subsectionHeader>
<bodyText confidence="0.999973461538461">
The second problem is that many of the separate utter-
ances issued to secure reference were declarative
sentences whose logical form was 3 x P(x). Consider, for
example, &amp;quot;There is a little yellow piece of rubber&amp;quot;, and,
&amp;quot;it&apos;s got a plug in it&amp;quot;. However, Searle claims that these
utterances contain no act of referring (to x). (Searle, op.
cit., p. 29.) How then can speakers use them to refer?
The answer involves our analysis of indirect speech
acts. Although such declarative utterances can be issued
just to be informative, they are also issued as requests
that the hearer identify the referent. The analysis of
these utterances as requests depends on our positing an
action of referent identification.
</bodyText>
<subsectionHeader confidence="0.971226">
8.3 Accounting for Searle&apos;s conditions on refer-
ring
</subsectionHeader>
<bodyText confidence="0.999945962962963">
Assume Searle&apos;s Condition 1, the &amp;quot;normal I/O condi-
tions.&amp;quot; For the reasons outlined above, do not assume
Conditions 2 and 3. Now, clearly, a speaker&apos;s planning
of a request that the hearer identify the referent of some
description should comply with the rules for requesting;
the speaker is trying to achieve one of the effects of the
requested action (i.e., IDENTIFIED-REFERENT) by way
of communicating (in the Gricean sense) his intent that
the hearer perform the action, provided that it is shared
knowledge that the hearer can do the action. The last
condition is true if it is shared knowledge that the
precondition to the action holds, which includes Searle&apos;s
existential Condition 4. Searle&apos;s Condition 5 states that
the speaker intends to identify the referent to the hearer.
This condition is captured in the IAA by the hearer&apos;s
recognizing that the speaker intends to achieve the effect
of the referent identification act,
IDENTIFIED-REFERENT. Finally, Searle&apos;s Gricean
intent recognition, Condition 6, takes hold in the same
way that it does for other illocutionary acts, namely by
virtue of a &amp;quot;feature&amp;quot; of the utterance (e.g., utterance
mood) that is correlated with a complex propositional
attitude. This attitude becomes the basis for subsequent
reasoning about the speaker&apos;s plans. In summary,
Searle&apos;s conditions can be accounted for by simply posit-
ing an action that the speaker requests and that the hear-
er reasons about and performs.
</bodyText>
<subsectionHeader confidence="0.99936">
8.4 Extending the analysis
</subsectionHeader>
<bodyText confidence="0.999991294117647">
So far, the IAA and PAA are complementary. They each
account for different aspects of referring. The IAA char-
acterizes utterances whose sole purpose is to secure
referent identification, and the PAA characterizes the use
of referring phrases within an illocutionary act. I now
proceed to show how the IAA can subsume the PAA.
Searle argues that one use of the definite article in
uttering an NP is to indicate the speaker&apos;s intention to
refer uniquely. Moreover, from Condition 5, this inten-
tion is supposed to be recognized by the hearer. We can
get this effect by correlating the expression in Figure 5
with the definite determiner, where (DONE Agt Act P) is
true if the Agt has done Act, thereby producing the state
of affairs P. Think of this entire expression as being a
pragmatic &amp;quot;feature&amp;quot; of a syntactic constituent, as in
current linguistic formalisms. When this expression is
applied to a descriptor (supplied from the semantics of
the NP), we have a complete formula that becomes the
seed for deriving a request. Namely, if the hearer
believes that the uttering of the determiner was inten-
tional (which, of course, he does), then the hearer
believes that the speaker wants him to think there is a
unique object that speaker wants him to pick out. If it is
mutually believed, the hearer can do it (i.e., the precon-
ditions to the referent identification act hold, and the
hearer knows how to do it by decomposing the
description into a plan of action), the hearer believes that
the speaker&apos;s goal is that he believe of some object that
the speaker&apos;s goal is that he have picked it out. Hence, a
request can be derived.31 Thus, for the perceptual case,
the IAA subsumes the PAA.
Assume that instead of just considering the act of
identification in its perceptual sense, we adopt Searle&apos;s
concept — namely that &amp;quot;.... there should no longer be any
doubt what exactly is being talked about.&amp;quot; Identification
in this sense is primarily a process of establishing a co-re-
ferential link between the description in question and
some other whose referent is in some way known to the
hearer. However, we again regard identification as an
act that the hearer performs, not something the speaker
does to/for a hearer. If an analysis of this extended
notion can be made similar in form to the analysis of the
perceptual identification act, then the IAA completely
subsumes the PAA. Because both accounts are equally
vague on what constitutes identification (as are, for that
matter, all other accounts of which I am aware), the
choice between them must rest on other grounds. The
grounds favoring the identification request analysis
include the use of separate utterances and illocutionary
acts for its analysis of referring, and the independently
motivated satisfaction of Searle&apos;s conditions on referring.
</bodyText>
<subsectionHeader confidence="0.999256">
8.5 Searle vs. Russell
</subsectionHeader>
<bodyText confidence="0.998655916666667">
Using the propositional act of referring, Searle argues
against Russell&apos;s (1905) theory of descriptions, which
holds that the uttering of an expression &amp;quot;the 0&amp;quot; is equiv-
The analysis of referring in Cohen (1984) makes use of a theory of
communication of Cohen and Levesque (1980, in preparation) that
does not require the recognition of illocutionary acts. Instead, IA&apos;s are
derived as theorems about the speaker&apos;s goals. The analysis of request-
ing in this theory would state that the request theorem is applicable
when Searle claims that an act of referring is performed, and, as we
have seen, at other times as well. Thus, the hearer does not have to
recognize each referring act as a request; each referring act merely has
to be characterizable as one.
</bodyText>
<figure confidence="0.948466272727273">
120 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
X D (BEL Hearer
(WANT Speaker
(BEL Hearer
3 ! X (WANT Speaker
(DONE Hearer
IDENTIFY-REFERENT
(Hearer, D),
IDENTIFIED-REFERENT
(Hearer, D, X))))))]
</figure>
<figureCaption confidence="0.999779">
Figure 5. Pragmatic feature correlated with a definite determiner.
</figureCaption>
<bodyText confidence="0.999543529411765">
alent to the assertion of a uniquely existential proposi-
tion, &amp;quot;There is a unique ci5&amp;quot;. Thus, when reference fails,
it is because the uniquely existential proposition is not
true. Searle claims instead that the existence of the refer-
ent is a precondition to the action of referring. In refer-
ring to X, we do not assert that X exists any more than
we do in hitting X (Searle, op. cit., p. 160.) However,
the precondition is necessary for successful performance.
Searle&apos;s argument against this theory essentially comes
down to:
.... It [Russell&apos;s theory] presents the propositional
act of definite reference, when performed with
definite descriptions ... as equivalent to the illocu-
tionary act of asserting a uniquely existential
proposition, and there is no coherent way to inte-
grate such a theory into a theory of illocutionary
acts. Under no condition is a propositional act
identical with the illocutionary act of assertion, for
a propositional act can only occur as part of some
illocutionary act, never simply by itself.
(Searle, op. cit., p. 15.)
There are two difficulties with this argument. First,
the requirement that acts of referring be part of an illocu-
tionary act was shown to be unnecessarily restrictive.
Second, there is a way to assimilate the assertion of an
existential proposition — an act that Searle claims does
not contain a referring act — into an analysis of illocu-
tionary acts, namely as an indirect request for referent
identification. However, because an assertion of a
uniquely existential proposition may fail to convey an
indirect request for referent identification (just as utter-
ing, &amp;quot;It&apos;s cold in here&amp;quot;, may fail to convey an indirect
request), Searle&apos;s argument, though weakened, still
stands.
</bodyText>
<subsectionHeader confidence="0.948323">
8.6 Summary
</subsectionHeader>
<bodyText confidence="0.999987214285714">
There are a number of advantages for treating referent
identification as an action that speakers request, and thus
for treating the speech act of referring as a request. The
analysis not only accounts for data that Searle&apos;s analysis
cannot, but also predicts each of Searle&apos;s conditions for
performing the act of singular identifying reference, while
allowing for appropriate extension into a planning proc-
ess. If we extend the perceptual use of referent identifi-
cation to Searle&apos;s more general concept of identification,
and we correlate a certain (Gricean) propositional atti-
tude with the use of definite determiners in a noun
phrase, then Searle&apos;s analysis is subsumed by the act of
requesting referent identification. The propositional act
of referring is therefore unnecessary.
</bodyText>
<sectionHeader confidence="0.961944" genericHeader="method">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.9999683">
This paper has had five objectives: to develop a method-
ology for analyzing discourse pragmatics; to apply it in
comparing spoken and keyboard discourse; to explore
the differences in utterance function across modes
(particularly in the pragmatics of reference); to evaluate
the adequacy of a plan-based theory of communication
for analyzing discourse; and to compare the resulting
analysis with Searle&apos;s. I shall first summarize the empir-
ical findings and the theory&apos;s adequacy, and then discuss
implications for computational linguistics.
</bodyText>
<subsectionHeader confidence="0.999751">
9.1 Summary of findings
</subsectionHeader>
<bodyText confidence="0.991789088235294">
Spoken and keyboard-based instructional discourse, even
used for the same ends, differ in structure and in form.
Telephone conversation about object assembly is domi-
nated by explicit requests to identify objects satisfying
descriptions. This paper makes no attempt to explain
why it is that speakers break up the referring and predi-
cating functions, but users of keyboards do not. Many
intuitive explanations come to mind — channel band-
width, memory limitations on the speaker or on the hear-
er, etc. Rather than attempt more detailed investigation
of the causes of the phenomena, I concentrate instead on
applying a plan-based theory to derive the coders&apos;
analyses of the speakers&apos; intentions.
Only rarely are identification requests performed
directly. The plan-based theory was shown to capture
many of the indirect requests (69%). However, it needs
to be extended in many ways. In particular, the theory
does not yet account for the inferring of expected goals
from analyses of the communication task, the physical
setting, and the modality constraints. It cannot relate
perceptual actions to the act of searching for something,
and it cannot capture the parallelism evident in speakers&apos;
Computational Linguistics Volume 10, Number 2, April-June 1984 121
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
prosodically questioning referent identification in the
course of issuing an imperative utterance.
I have argued that the need to process indirect identifi-
cation requests requires hearers to reason about the
speaker&apos;s intention that the hearer perceptually identify
the referents of various descriptions. This reasoning
process involves determining how (the hearer&apos;s perform-
ing) an action of referent identification might fit into the
speaker&apos;s plans. The treatment of referent identification
as an action that speakers request not only accounts for
the data, but also predicts each of Searle&apos;s conditions for
performing the act of singular identifying reference while
it allowing for appropriate extension into a planning
process.
The promissory note introduced by this approach is to
show how the same kind of plan-based reasoning used in
analyzing indirect speech acts can take hold when a hear-
er realizes he cannot, and was not intended to, identify
the referent of a description. That is, plan-based reason-
ing should explain how a hearer might decide that the
speaker&apos;s intention cannot be what it appears to be
(based on the intent correlated with the use of a definite
determiner), leading him, for example, to decide to treat
a description attributively (Donnellan 1960). Moreover,
such reasoning should be useful in determining intended
referents, as Ortony (1978) has argued.
To cash in this promissory note, one needs to be
specific about speaker intentions for other uses of noun
phrases. This will be no easy task. One difficulty will be
to capture the distinction between achieving effects on a
hearer, and doing so communicatively (i.e., in the Grice-
an way). Thus, for example, a hearer cannot comply
with the illocutionary act, &amp;quot;Quick, don&apos;t think of an
elephant&amp;quot;, because there seems to be an &amp;quot;automatic&amp;quot;
process of &amp;quot;concept activation&amp;quot; (Appelt 1981). Achiev-
ing effects noncommunicatively, without the recognition
of intent, may be central to some kinds of reference. In
such cases, speakers would be able to identify referents
for a hearer. If this held for singular identifying refer-
ence, then there could be grounds for a propositional act.
However, we might have to give up the Gricean Condi-
tion 5, which I suspect Searle would not want to do.
Although it has been demonstrated that the action of
perceptual identification differs from other treatments of
reference in computational linguistics, perceptual identifi-
cation has not yet been formalized in a precise way. A
formalism should indicate when identification is neces-
sary, how it relates to the performance of physical action,
and how the perceptual actions that comprise it are
related to the structure of the descriptions. Nonetheless,
I hope to have demonstrated the importance of formaliz-
ing this action.
The methodology of attempting to explain the
discourse analyses of two observers is clearly good
theoretical hygiene, but is difficult to implement in prac-
tice. Care must be taken to assure that coders are not
asked to make too many judgments at once (they get
confused), or to make subtle judgments. For example,
coders were not able to differentiate questions from
requests for confirmation reliably, even though they were
provided with formal definitions for the communicative
actions and the intuitive distinctions were clear. In fact,
my providing the coders with formal definitions may have
been counterproductive because the definitions did not
necessarily mirror people&apos;s commonsense distinctions.
One lesson to be learned from the difficult experience
of getting others to &amp;quot;code&amp;quot; the illocutionary acts in a
dialogue is that because it is so difficult, perhaps it is not
done by the participants. It is certainly possible that
conversants engage in dialogue without being able to
specify precisely, using illocutionary verbs, just which illo-
cutionary acts were performed. Because elsewhere
(Cohen and Levesque 1980, in preparation) we have
developed formalisms for communication that do not
require the identification of illocutionary acts, it may be
unnecessary to require the hearer to do so. Therefore,
empirical support is needed for the often presupposed
position that hearers must identify illocutionary acts.
</bodyText>
<subsectionHeader confidence="0.998518">
9.2 Implications for computational linguistics
</subsectionHeader>
<bodyText confidence="0.999905966666667">
The simple communication task analyzed here involved
primarily the performing of requests. As such, it should
fall within the scope of computational linguistic tech-
niques. However, no natural language system that I
know can handle the discourse structure of the Tele-
phone data. Of course, one might be able to develop a
system that could handle just the data found here. But,
we would value more a system (or theory, for that
matter) that handles such data because of general princi-
ples it embodies. It is for this reason that I have applied
a general purpose plan-based theory.
An extrapolation of the empirical results results
suggests that if robots are to be instructed with spoken
natural language, they are likely to encounter indirect
identification requests. If their language processing is
based on inferring and responding to the speaker&apos;s intent,
then intent recognition will have to be applied to the act
of identifying a referent. However, given sufficient
restrictions on the domain of discourse and the robot&apos;s
capabilities, an implementation of the plan-recognition
process might simplify the general case. I have suggested
that derived inference rules coupled with expectations
can serve adequately. A formal foundation for such
derived rules for intent interpretation can be found in
Cohen and Levesque (1980, in preparation), and a
prototype implementation that uses both general and
derived rules for interpreting speaker intent is described
in Brachman et al. (1979).
Additional problem areas suggested by this research
include developing formal and computational models of
</bodyText>
<page confidence="0.736628">
122 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.513589">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<bodyText confidence="0.999938203703704">
the generation of useful descriptions, and getting
machines to plan reference and predication separately.32
However, if given more resources, systems should be able
to &amp;quot;optimize&amp;quot; referring and predicating plans into single
utterances. Conversely, systems ought to be able to
reason about the speakers&apos; uses of descriptions — for
identification, correcting previous misidentifications,
attribution, etc.
The empirical findings of this study must be interpret-
ed with three cautionary notes. First, the category of
identification requests is specific to discourse situations in
which the topics of conversation include objects phys-
ically present to the hearer. If the conversation is not
about manipulating concrete objects, different pragmatic
inferences could be made, even though the same surface
forms might be used. Second, not all natural language
communication between person and machine are accu-
rately captured by the Telephone and Keyboard condi-
tions. For example, conversations about the contents of
the system&apos;s display scope (Brachman et al. 1979, Wino-
grad 1972) might share some aspects of the Face-to-Face
condition (especially the experts&apos; use of sentence frag-
ments to correct the apprentices&apos; mistakes). Thus, the
generality of these findings will only be established when
conversations in other discourse situations are analyzed.
Third, it should be realized that the indirection results
may occur only in conversations between humans. It is
possible that people do not wish to verbally instruct
others with fine-grained imperatives for fear of sounding
condescending. Print may remove such inhibitions, as
may talking to a machine. The question of how people
will speak to machines probably cannot be settled until
good speech-understanding systems have been devel-
oped. Nevertheless, in building future speech-under-
standing systems, it may be unwise to underestimate the
frequency of indirect speech acts in spoken discourse.
Finally, I observe again that when computational
linguistic techniques have been developed based on a
corpus of dialogues, most often those dialogues have
been conducted through keyboard interaction. However,
it is clear from the results of this study that keyboard
communication is distinctly different from other modali-
ties. In addition to differences from telephone communi-
cation, a cursory examination of the handwritten
transcripts reveals that keyboard communication is mark-
edly different in structure from written communication.
Whereas experts in keyboard mode rarely use identifica-
tion requests, writers use them frequently, in both direct
and indirect forms. Furthermore, writers often
performed all identification requests first, and labeled
each of the objects for future reference (much as authors
of published assembly instructions do). Keyboard inter-
action, in its emphasis on optimal packing of information
into the smallest linguistic &amp;quot;space&amp;quot;, appears to be a mode
</bodyText>
<page confidence="0.607618">
32 See Appelt (1981) for a system that operates along these lines.
</page>
<bodyText confidence="0.9998215">
of communication that alters the normal organization of
discourse. We should thus be wary of our theories&apos; and
techniques&apos; coverage if they are to extended to other
modalities of communication.
</bodyText>
<sectionHeader confidence="0.646289" genericHeader="method">
10 Acknowledgements
</sectionHeader>
<bodyText confidence="0.702202357142857">
This work would not have been possible without the help
of Scott Fertig and Kathleen Starr, who spent countless
hours coding the transcripts. Many thanks also to Rob
Tierney for collaboration in organizing and conducting
the experiments. I would like to thank Zoltan Uzhelyi for
videotaping, Debbie Winograd, Larry Shirey, and Julie
Burke for helping to conduct the experiments, and
Marion Hazen, Elsie Chappell, Joan Hirschkorn, Cindy
Hunt, Mike Nivens, Ken Olum, and Norma Peterson for
text and transcript preparation. Thanks also go to Mari-
lyn Adams, Doug Appelt, Ron Brachman, Chip Bruce,
Julie Burke, Martin Kay, Hector Levesque, Sharon
Oviatt, Ray Perrault, Andee Rubin, Candy Sidner, Ed
Smith, and Rob Tierney for valuable discussions.
</bodyText>
<sectionHeader confidence="0.734523" genericHeader="method">
References
</sectionHeader>
<reference confidence="0.983303790055248">
Allen, J.F. 1979 (January) A Plan-based Approach to Speech Act
Recognition. Technical Report 131, Department of Computer
Science, University of Toronto.
Allen, J.F. and Perrault, C.R. 1980 Analyzing Intention in Dialogues.
Artificial Intelligence 15(3): 143-178.
Appelt, D. 1981 (December) Planning Natural Language Utterances
to Satisfy Multiple Goals. Ph.D. Thesis, Stanford University, Stan-
ford, California.
Asher, S.R. 1979 Referential Communication. In Whitehurst, G.J.
and Zimmerman, B.Z., Eds., The Functions of Language and Cogni-
tion. Academic Press, New York, New York.
Austin, J.L. 1962 How to Do Things with Words. Oxford University
Press, London.
Brachman, R.; Bobrow, R.; Cohen, P.; Klovstad, J.; Webber, B.L.; and
Woods, W.A. 1979 (August) Research in Natural Language
Understanding. Technical Report 4274, Bolt Beranek and Newman
Inc.
Bruce, B.C. 1981 Natural Communication Between Person and
Computer. In Lehnert, W. and Ringle, M., Eds., Strategies for
Natural Language Processing, Lawrence Erlbaum Associates, Hills-
dale, New Jersey.
Bruce, B.C. 1983 Belief Systems and Language Understanding. In
Trends in Linguistics, Studies and Monographs 19: Computers in
Language Research 2. Walter de Gruyter and Co., New York, New
York.
Bruce, B.C. and Newman, D. 1978 Interacting Plans. Cognitive
Science 2(3): 195-233.
Bruce, B., and Schmidt, C.F. Episode Understanding and Belief Guided
Parsing. Presented at the Association for Computational Linguistics
Meeting at Amherst, Massachusetts.
Burke, J.A. 1982 An Analysis of Intelligibility in a Practical Activity:
The Role and Relationship of Discourse and Context. Ph.D. Thesis,
Dept. of Speech Communication, University of Illinois.
Chafe, W.L. 1982 Integration and Involvement in Speaking, Writing,
and Oral Literature. In Tannen, D., Ed., Spoken and Written
Language: Exploring Orality and Literacy. Ablex Publishing Corpo-
ration, Norwood, New Jersey.
Chapanis, A.; Ochsman, RB.; Parrish, R.N.; and Weeks, G.D. 1972
Studies in Interactive Communication: I. The Effects of Four
Communication Modes on the Behavior of Teams during Cooper-
ative Problem Solving. Human Factors 14: 487-509.
Computational Linguistics Volume 10, Number 2, April-June 1984 123
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
Chapanis, A.; Parrish, R.N.; Ochsman, R.B.; and Weeks, G.D. 1977
Studies in Interactive Communication: II. The Effects of Four
Communication Modes on the Linguistic Performance of Teams
during Cooperative Problem Solving. Human Factors 19(2):
101-125.
Clark, H.H. and Wilkes-Gibbs, D. Referring as a Collaborative Proc-
ess. Unpublished ms.
Cohen, P.R. On Knowing What to Say: Planning Speech Acts. Ph.D.
Thesis and Technical Report No. 118, Department of Computer
Science, University of Toronto, Toronto.
Cohen, P.R. 1984 Referring as Requesting. Proceedings of
COLING84, Stanford, California, 207-211.
Cohen, P.R. and Levesque, H.J. 1980 (May) Speech Acts and the
Recognition of Shared Plans. Proceedings of the Third Biennial
Conference, Canadian Society for Computational Studies of Intelli-
gence, Victoria, B. C., 263-271.
Cohen, P.R. and Levesque, H.J. (in preparation) Speech Acts as
Summaries of Shared Plans.
Cohen, P.R. and Perrault, C.R. 1979 Elements of a Plan-based Theo-
ry of Speech Acts. Cognitive Science 3(3): 177-212.
Dickson, W.P. 1981 Childrens&apos;s Oral Communication Skills. Academic
Press, New York, New York.
Donnellan, K. 1960 Reference and definite description. The Philo-
sophical Review 75: 281-304.
Dore, J.; Gearhart, M.; and Newman, D. 1978 The Structure of Nurs-
ery School Conversation. In Nelson, K., Ed., Children&apos;s Language.
Vol I. Gardner Press, New York, New York, 337-396.
Evans, D. 1981 (December) Situations and Speech Acts: Toward a
Formal Semantics of Discourse. Ph.D. Thesis, Department of
Linguistics, Stanford University.
Fertig, S. Miscommunication in Discourse. Unpublished B.A. Thesis,
Hampshire College, Amherst, Massachuseets.
Genesereth, M.R. 1978 (September) Automated Consultation for
Complex Computer Systems. Ph.D. Thesis, Department of
Computer Science, Division of Applied Sciences, Harvard Universi-
ty.
Grice, H.P. 1957 Meaning. Philosophical Review 66: 377-388.
Grosz, B.J. 1977 (July) The Representation and Use of Focus in
Dialogue Understanding. Technical Report 151, Artificial Intelli-
gence Center, SRI International.
Hayes, P.J. and Mouradian, G.V. 1981 Flexible Parsing. American
Journal of Computational Linguistics 7(4): 232-242.
Hindle, D. 1983 Deterministic Parsing of Syntactic Non-fluencies.
Proceedings of the 21st Annual Meeting of the Association for Compu-
tational Linguistics, Cambridge, Massachusetts, 123-128.
Hintikka, J. 1969 Semantics for Propositional Attitudes. In Davis,
J.W. et al., Eds., Philosophical Logic. D. Reidel Publishing Co.,
Dordrecht, Holland.
Hoeppner, W.; Monk, K.; and Marburger, H. 1984 (May) Talking It
Over: The Natural Language Dialog System HAM-ANS. Technical
report ANS-26, Research Unit for Information Science and Artifi-
cial Intelligence, University of Hamburg.
Horrigan, M.K. 1977 Modelling simple dialogues. Technical Report
108, Department of Computer Science, University of Toronto.
Krauss, R.M. and Weinheimer, S. 1966 Concurrent Feedback, Confir-
mation, and the Encoding of Referents in Verbal Communication.
Journal of Personality and Social Psychology 4: 343--346.
Kroch, A.S. and Hindle, D. 1982 On the Linguistic Character of
Non-standard Input. Proceedings of the 20th Annual Meeting of the
Association for Computational Linguistics, Toronto, Canada,
161-163.
Kwasny, S.C. and Sondheimer, N.K. 1981 Relaxation Techniques for
Parsing Ill-formed Input. American Journal of Computational
Linguistics 7(2): 99-108.
Labov, W. and Fanshel, D. 1977 Therapeutic Discourse. Academic
Press, New York, 1977.
Levin, J.A. and Moore, J.A. 1977 Dialogue Games: Metacommunica-
tion Structures for Natural Language Interaction. Cognitive Science
1(4): 395-420.
Mann, W.C.; Carlisle, J.H.; Moore, J.A.; and Levin, J.A. 1977 (Janu-
ary) An Assessment of Reliability of Dialogue-annotation
Instructions. Technical Report ISI/RR-77-54, Information Sciences
Institute.
Mann, W.; Moore, J.; and Levin, J. 1977 A Comprehension Model for
Human Dialogue. Proceedings of the Fifth International Joint Confer-
ence on Artificial Intelligence, Cambridge, Massachusetts.
Moore, R.C. 1980 (October) Reasoning about Knowledge and
Action. Technical Note 191, Artificial Intelligence Center, SRI
International.
Morgan, J.L. 1978 Two Types of Convention in Indirect Speech Acts.
In Cole, P., Ed., Syntax and Semantics, Volume 9: Pragmatics,
Academic Press, New York, New York, 261-280.
Ochs, E. 1979 Planned and unplanned discourse. In Givon, T., Ed.,
Syntax and Semantics, Volume 12: Discourse and Syntax, Academic
Press, New York, New York, 51-80.
Ochs, E.; Schieffelin, B.B.; and Pratt, M.L. 1979 Propositions Across
Utterances and Speakers. In Ochs, E., and Schieffelin, B. B., Eds.,
Developmental Pragmatics, Academic Press, New York, New York.
Ortony, A. 1978 Some Psycholinguistic Constraints on the
Construction and Interpretation of Definite Descriptions.
Proceedings of the Second Conference on Theoretical Issues in Natural
Language Processing, Urbana, Illinois, 73-78.
Perrault, C.R. and Allen, J.F. 1980 A Plan-based Analysis of Indirect
Speech Acts. American Journal of Computational Linguistics 6(3):
167-182.
Perrault, C.R. and Cohen, P.R. 1981 It&apos;s for Your Own Good: A Note
on Inaccurate Reference. In Joshi, A.; Sag, I.; and Webber, B., Eds.,
Elements of Discourse Understanding. Cambridge University Press,
Cambridge, Massachusetts.
Reichman, R. 1981 Plain-speaking: A Theory and Grammar of Spon-
taneous Discourse. Ph.D. Thesis, Department of Computer Science,
Harvard University, Cambridge, Massachusetts.
Robinson, A.E.; Appelt, D.E.; Grosz, B.J.; Hendrix, G.G.; and Robin-
son, J.J. 1980 (March) Interpreting Natural-language Utterances
in Dialogs about Tasks. Technical Note 210, Artificial Intelligence
Center, SRI International.
Rubin, A.D. 1980 A Theoretical Taxonomy of the Differences
Between Oral and Written Language. In Spiro, R.; Bruce, B.; and
Brewer, W., Eds., Theoretical Issues in Reading Comprehension,
Lawrence Erlbaum Assocs., Hillsdale, New Jersey.
Russell, B. 1905 On denoting. Mind 14: 479-492.
Sacerdoti, E.D. 1975 (August) A Structure for Plans and Behavior.
Technical Note 109, Artificial Intelligence Center, SRI Interna-
tional.
Schank, R. and Abelson, R. 1977 Scripts, Plans, Goals, and Understand-
ing. Lawrence Erlbaum Associates, Hillsdale, New Jersey.
Schmidt, C.F. 1975 Understanding Human Action. Proceedings of
Conference on Theoretical Issues in Natural Language Processing,
Cambridge, Massachusetts.
Schmidt, D.F.; Sridharan, N.S.; and Goodson, J.L. 1979 The Plan
Recognition Problem: An Intersection of Artificial Intelligence and
Psychology. Artificial Intelligence 10: 45-83.
Searle, J.R. 1969 Speech Acts: An Essay in the Philosophy of Language.
Cambridge University Press, Cambridge.
Shatz, M. and Gelman, R. 1973 The Development of Communication
Skills: Modifications in the Speech of Young Children as a
Function of Listener. Monographs of the Society for Research in
Child Development.
Sidner, C.L. 1979 (June) Towards a Computational Theory of Defi-
nite Anaphora Comprehension in English Discourse. Technical
Report 537, Artificial Intelligence Laboratory, Massachusetts Insti-
tute of Technology.
Sidner, C.L. 1983 The Pragmatics of Non-anaphoric Noun Phrases.
In Research in Knowledge Representation for Natural Language
Understanding: Annual Report, 9/1/82-8/31/83, Bolt Beranek
and Newman Inc., Cambridge, Massachusetts.
Sidner, CL., Bates, M.; Bobrow, R.J.; Brachman, R.J.; Cohen, P.R.;
Israel, D.J.; Webber, B.L.; and Woods, W.A. 1981 (November)
</reference>
<page confidence="0.874092">
124 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.598648">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<reference confidence="0.841881555555556">
Research in Knowledge Representation for Natural Language
Understanding. Annual Report 4785, Bolt, Beranek and Newman
Inc.
Sidner, C. and Israel, D. 1981 Recognizing Intended Meaning and
Speaker &apos;s Plans. Proceedings of the Seventh International Joint
Conference on Artificial Intelligence, Vancouver, B. C.
Sinclair, J.McH. and Coulthard, R.M. 1975 Towards an Analysis of
Discourse: The English Used by Teachers and Pupils. Oxford Univer-
sity Press, London.
Stoll, F.C.; Hoecker, D.G.; Krueger, G.P.; and Chapanis, A. 1976
The Effects of Four Communication Modes on the Structure of
Language Used During Cooperative Problem Solving. The Journal
of Psychology 94(1): 13-26.
Thompson, B. 1980 Linguistic Analysis of Natural Language Commu-
nication with Computers. Proceedings of COLING-80, Tokyo, 190-
201.
Tierney, R.J.; LaZansky, J.; Raphael, T.; and Cohen, P.R. 1983
Author&apos;s Intentions and Readers&apos; Interpretations. In Tierney, R.J.;
Anders, P.; and Mitchell, J.N.; Eds.; Understanding Readers&apos; Under-
standings. Lawrence Erlbaum Assoc., Hillsdale, N. J., 1983.
Walker, D., Ed. 1978 Understanding Spoken Language. Elsevier North-
Holland, New York New York.
Webber, B.L. 1978 (May) A Formal Approach to Discourse Anapho-
ra. BBN Report 3761, Bolt Beranek and Newman Inc.
Weischedel, R.M. and Black, J.E. 1980 Responding Intelligently to
Unparsable Inputs. American Journal of Computational Linguistics
6(3): 97-109.
</reference>
<table confidence="0.920562076923077">
Wilensky, R. 1978 Understanding Goal-based Stories. Research
Report 140, Department of Computer Science, Yale University,
New Haven, Connecticut.
Wilkes-Gibbs, D. How to Do Things with Reference: The Function of
Goals in Determining Referential Choice. Unpublished ms.
Winograd, T. 1972 Understanding Natural Language. Academic Press,
New York, New York.
Woods, W.; Bates, M.; Brown, G.; Bruce, B.; Cook, C.; Klovstad, J.;
Makhoul, J.; Nash-Webber, B.; Schwartz, R.; Wolf, J.; and Zue, V.
1976 Speech Understanding Systems — Final Technical Progress
Report. Technical Report 3438, Bolt Beranek and Newman Inc.
Computational Linguistics Volume 10, Number 2, April-June 1984 125
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</table>
<sectionHeader confidence="0.681144" genericHeader="method">
Appendix A
</sectionHeader>
<subsectionHeader confidence="0.979243">
Instructions for the Expert
</subsectionHeader>
<bodyText confidence="0.999912805555555">
We are studying communication between individuals.
We want to examine how an individual effectively
communicates a set of instructions to another. The
purpose of this experiment is to observe and document
the variety and similarities among different communica-
tive styles.
If you decide to participate, you will be randomly
assigned to another individual taking part in the exper-
iment, and to communication modality. Each pair is to
cooperate in building a water cannon pump. You will
have been previously trained to build the pump, but will
not be allowed to touch any of the parts during the
experiment. Your partner will do the actual building.
You should be aware that your partner will know very
little about the task. You must be sure to explain what
the task is, make sure they build the pump, and check to
see that the pump functions correctly.
The schedule for your role in the experiment is as
follows. Today you will read the instructions for building
the water pump and then practice building it. After
about 20 minutes, we will ask you to instruct one of us.
If there are no problems with this practice run, then you
are free to leave and tomorrow you will come in and
instruct your partner. If you do have difficulty or have
any doubts about your ability to remember till tomorrow
how to assemble the pump, then we want you to stay and
practice for at least another ten minutes.
The communication will take place in one of the
following modes: face-to-face, telephone, teletype,
audiotape, or written. You will learn the specifics of
your mode in the next session. Depending on the mode
of communication, you may be recorded on video or
audio tape. These tapes will be used for the collection of
data and not for any other purpose.
All fellow subjects Will be adult university students.
If you agree to these conditions, please sign below.
</bodyText>
<subsectionHeader confidence="0.5964635">
Instructions for Building a Water Cannon
Building a Water.Cannon:
</subsectionHeader>
<listItem confidence="0.994359392857143">
1. Plug the hole in the bottom of the plunger with the
plunger plug.
2. Insert the plunger into the main tube. The red
handle of the plunger should extend from the non-
threaded end of the main tube.
3. Press the blue tube cap down onto the main tube so
it fits firmly.
4. Drop the 0-ring into the tube base.
5. Fit the pink base valve onto the top of the tube base.
The valve should cover the hole in the base.
6. Fit the feed tube onto the bottom of the base.
7. Screw the tube base onto the main tube.
8. Put the tube cap over the upper outlet of the main
tube.
9. Fit the slide valve loosely into the lower outlet of the
main tube.
Using the Water Cannon:
1. Place the pump into a tray of water. The pump
should be supported by the feed tube.
2. Move the plunger up and down by alternately push-
ing and pulling on the red handle.
3. Water will be forced out the lower outlet of the main
tube, through the spout, through the air chamber,
and out through the nozzle.
4. Water will continue to be forced out the nozzle as
long as you keep moving the plunger up and down.
5. If nothing happens, check to see that all parts fit
tightly and that the valves are properly sealed.
</listItem>
<subsectionHeader confidence="0.937466">
Telephone
</subsectionHeader>
<bodyText confidence="0.99994875">
Talk to your partner as you would during a normal phone
conversation. Your partner will have his/her hands free
during the entire conversation and will be able to
construct the pump without interruptions.
Your partner will have all the necessary pieces and a
tray of water. Again, the task is to assemble the pump
and ensure that it works. Your partner does not know
anything about the task.
</bodyText>
<subsectionHeader confidence="0.971761">
Teletype
</subsectionHeader>
<bodyText confidence="0.999941769230769">
Just type as you would on a typewriter. The print will
not appear as soon as it is typed in; there will be a small
delay. If you experience any long delays in seeing the
characters you typed it is probably due to heavy use of
the computer. Please bear with it.
Finally, it is possible the computer will stop working
during the experiment. Everything before a stopage will
be saved and we will attempt to continue the experiment
as soon as possible.
Your partner will have all the necessary pieces and a
tray of water. Again, the task is to assemble the pump
and ensure that it works. Your partner does not know
anything about the task.
</bodyText>
<page confidence="0.850175">
126 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.659903">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<subsectionHeader confidence="0.955975">
Instructions for the Novice
</subsectionHeader>
<bodyText confidence="0.998096357142857">
We are studying communication between individuals.
We want to examine how an individual effectively
communicates a set of instructions to another. The
purpose of this experiment is to observe and document
the variety and similarities among different communica-
tive styles.
The communication will taRe place in one of the
following modes: face-to-face, telephone, teletype,
audiotape, or written. You will learn the specifics of
your mode on the next page. Depending on the mode of
communication, you may be recorded on video or audio
tape. These tapes will be used for the collection of data
and not for any other purpose.
If you agree to these conditions, please sign below.
</bodyText>
<subsectionHeader confidence="0.498592">
Exploded Parts Diagram of the Water Pump
</subsectionHeader>
<figure confidence="0.99005546875">
MIINIIABX
CONTENTS OF
outlet tube
(green)
bass valve isiumper
(pink) Plug
CS)
tube cap
(blue)
ace
c.v., valve
(red)
bottle cap
Plunger valve
(yellow)
cannon bottle
bottle holder
Hydraulic Pump Kit
and portable Wafer Cannon
cannon
tubing
Note: on extra set of valves hal been supplied.
SPOIJ
plunger with sap
rubber 0.4&amp;quot;ing
be base
air &amp;iambs&apos;
norzie
main tub.
hod tube
Computational Linguistics Volume 10, Number 2, April-June 1984 127
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</figure>
<subsectionHeader confidence="0.64611">
Appendix B: Coding Categories
</subsectionHeader>
<bodyText confidence="0.9994485">
The following is the list of parts and their respective
codes. Subparts are indented on a new line after the
main part. To avoid confusion, subpart names are used
where needed.
</bodyText>
<subsectionHeader confidence="0.726471">
Part Code
</subsectionHeader>
<table confidence="0.957781947368421">
Main Tube MT
Outlett (Main Tube) 01
Outlet2 02
Plunger [green end] PL
Plug PLUG
Rod ROD
Handle HANDLE
Top-cap T-CAP
Outletl cap 0-CAP
Tube Base TB
Valve2 [pink valve] V2
0-ring 0-RING
Valve3 [red slide valve] V3
Spout [elbow joint] SPOUT
Air-chamber AIR-CH
Nozzle NOZ
Stand STAND
Pump [as built so far] PUMP
Tray TRAY
</table>
<tableCaption confidence="0.587428">
Table TAB
Expert EXP
Apprentice APP
</tableCaption>
<subsectionHeader confidence="0.982089">
Subassemblies
</subsectionHeader>
<bodyText confidence="0.998051833333333">
Occasionally, subjects mention a grouping of parts to be
regarded as subassemblies, which are then connected
together to form the pump. The following are typical
ones — what a particular expert groups into one subas-
sembly is up to him/her, so we were not strict on what
are the constituents of a subassembly.
</bodyText>
<figure confidence="0.984992285714286">
• Base-assembly
BASSM = ITB,V2,STAND,ORING1
• Spout-assembly
SPASSM = {SPOUT, V3, 02}
• Main-tube-assembly
MTASSM = {MT,PASS,PLUG,T-CAP}
• Air-chamber-assembly
</figure>
<sectionHeader confidence="0.492235" genericHeader="method">
ARCHMASSM = {SPOUT,NOZ,AIR-C1-11
</sectionHeader>
<subsectionHeader confidence="0.884659">
Functions
</subsectionHeader>
<bodyText confidence="0.99991425">
The following functions can be applied to (the right)
parts and yield the appropriate aspects of those parts.
So, &amp;quot;Bump&amp;quot; can be applied to the tube base TB to yield
the set of 2 bumps protruding from it.
</bodyText>
<listItem confidence="0.999318">
• Bump
• Hole
• Threaded-end
• Nonthreaded-end
• Thin-end
• Fat-end
</listItem>
<subsectionHeader confidence="0.578884">
Actions
</subsectionHeader>
<bodyText confidence="0.999246">
The following are the set of actions that are generally
used in building the pump.
</bodyText>
<listItem confidence="0.999546615384615">
• PICK-UP(part)
• PUT-DOWN(part)
• PUT-INTO(inserted-part receiving-part)
• PUSH-INTO(inserted-part receiving-part)
• COVER(covering-part covered-part)
• SCREW-TOGETHER(female-part male-part)
• MESH(hole-part bump-part)
• CONNECT(enclosing-part enclosed-part)
• ORIENT(part towards/away-from(part))
• STOP [action]
• UNDO(most-recent-action+2nd-mr-action+...+ last-
action-to-undo)
• PUMP [handle]
</listItem>
<bodyText confidence="0.999107">
The next action makes the pump or subassembly from
the set of pieces. It was only coded when the expert gave
an overview of a number of steps before instructing how
to do the substeps.
</bodyText>
<listItem confidence="0.999347">
• ASSEMBLE (PUMP or sub-assembly)
• ACHIEVE (person relation)
</listItem>
<bodyText confidence="0.991652666666667">
ACHIEVE stands for &amp;quot;make [relation] true.&amp;quot; ACHIEVE
was coded when [relation] was on our list below, but the
action that would achieve A was not mentioned.
</bodyText>
<subsectionHeader confidence="0.543989">
Relations
</subsectionHeader>
<bodyText confidence="0.99978725">
The following relations were coded as the content of the
categories INFORM and ACHIEVE. Appropriately filled-
in with the right parts, a collection of these relations form
the goal state of the assembled pump.
</bodyText>
<listItem confidence="0.999715375">
• (ACCESSIBLE part)
• (HOLDING part)
• (SUPPORTED part 1 part2)
• (INSIDE inserted-part receiving-part)
• (COVERS covering-part covered-part)
• (SCREWED-TOGETHER female-part male-part)
• (MESHES hole-part bump-part)
• (CONNECTS enclosing-part enclosed-part)
• (ORIENTED part)
• (IDENTIFIED part)
• (READY EXP/APP)
• (TIGHT part1 part2) partl should be tightly
connected to part2
• (LOOSE part 1 part2) part2 should be loosely
connected to part2
• (SEES person object)
</listItem>
<page confidence="0.592947">
128 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.255242">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<listItem confidence="0.982119">
• (DOUBTFUL person) All relations could be negated. This was expressed as
• (WORKING pump) &amp;quot;(NOTtrelation1)&amp;quot;. E.g., (NOT-COMPLETED PICKUP
• (COMPLETED action) implies the proposition stated (MT))
as the final state of the action holds.
</listItem>
<table confidence="0.913375166666667">
Computational Linguistics Volume 10, Number 2, April-June 1984 129
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
Appendix C: Identification Requests in Telephone Modality
The utterances coded as identification requests are
presented in italics.
Class A: Exisential Propositions
</table>
<listItem confidence="0.935286913043478">
1: And then— there should be a tray of water with you?
1: Okay. Now, if you&apos;ll look around in front of you,
there&apos;s a little tiny red piece that is like a uh—looks like
a fat thumb tack.
1: and there&apos;s this little tiny like pink plastic thing.
2: Yeah.
1: Now. There&apos;s another funny little looking red thing, a
little teeny red thing that&apos;s some— should be somewhere
on the desk, that has um—there&apos;s like teeth on one end?
2: Okay.
1: What&apos;s next? All right. See that little— there&apos;s a little
L-shaped clear plastic.
2: Yeah.
1: All right. Now. There is a skinny urn— there&apos;s a
funny blue —blue tube— it&apos;s a skinny blue tube.
2: Mm-hm.
1: There is one red cap.
2: Mm-hm.
1: And a funny like cylinder?
2: Yeah.
1: All right Now there&apos;s a blue cap that has two little
teeth sticking out of the bottom [of it.]
2: [Mm-hm.]
</listItem>
<bodyText confidence="0.853949666666667">
J: Huh. Okay, first thing, there&apos;s a long cylinder that has
a slightly purplish cast to it.
T: With the two side hoods, yep.
J: Okay. Uh now there&apos;s a little plastic blue cap.
T: Yep.
J: Uh, the next thing is there is a blue— looks like a
screw cap.
T: Mm-hm.
J: There&apos;s two little prongs sticking up.
T: Yeah.
J: Okay, now there&apos;s a black 0-ring.
T: Got it.
J: Okay. In the green thing at the bottom, there&apos;s a
hole.
T: Right.
Put the little red [plug—]
J: [unintelligible] There&apos;s a little red thing you gotta stuff
up in there.
</bodyText>
<figure confidence="0.473833125">
T: Okay. Got it.
J: Okay. Next step.
T: Mm-hm.
J: There&apos;s a little red thing with um prong-like things
hangin&apos; out from it.
T: With what-like things?
J: Okay. Now there&apos;s a clear 90-degree angle piece of
plastic.
</figure>
<figureCaption confidence="0.7650414">
T: Right. That—[which fits—]
J: Okay. Now, the next thing is there&apos;s a uh a blue
thing with a plastic dome, looks something like some-
thin&apos; you&apos;d put on uh a to evacuate. I&apos;m talking
about— it&apos;s the only big piece left really.
</figureCaption>
<bodyText confidence="0.880010533333333">
T: Mm-hm.
J: Okay. Onto that there is a little red nozzle, and that
fits on the side hole coming out of that dome.
T: Okay.
J: Okay. Take the whole mechanism and stand it up
into the uh— I think there&apos;s a photographic tray there
full of water.
T: Mm-hm.
S: Now there&apos;s a thing called a plunger. It has a red
handle on it, a green bottom, and it&apos;s got a blue lid.
J: Okay.
A: Okay. Now there&apos;s a little blue cap?
J: Yes.
A: Uh-huh. Now, there&apos;s a—a red plastic piece that has
four gizmos on it.
</bodyText>
<listItem confidence="0.708244071428571">
J: Yes.
1: Pick that up, and it has two projecting blue prongs on
it.
2: Uh-huh.
1: And it has two holes in it.
2: Uh-huh.
1: It&apos;s a funny-loo—hollow, hollow projection on one end
and then teeth on the other.
2: Uh-huh.
1: And if you&apos;ll look carefully, one toward the blue end
has two holes in it,
1: and the other —toward the red end has no holes in it.
2: Mm-hm.
1: All right. We have another hole.
</listItem>
<page confidence="0.678443">
130 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<note confidence="0.526507">
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</note>
<reference confidence="0.8726819">
2: Mm-hm.
1: All right. Has a—uh, I mean, [unintelligible] has a
funny projection at the other end, it&apos;s like notched.
2: Mm-hm.
1: -and this um cylinder-like thing, if you look at the
bottom has a hole in it-
2: Mm-hm.
1: Then, if you&apos;ll pick up the tube— it&apos;s kind of a purple
color?
2: Yes.
</reference>
<figure confidence="0.880858229508197">
A: Okay. Now take the littlest red plastic piece— it&apos;s a
little urn—
J: Looks like a plug?
A: stopper
J: and also pick up what looks like a plunger. It has [a
red end and green—]
T: [With the red end and a blue—]
J: bottom.
T: Right.
S: Okay? Now you have two blue caps.
S: One very small that&apos;s just a push-on cap,
S: and the other one is a larger one with threads on it.
J: Okay.
S: Okay? Now you have two devices that are clear plas-
tic.
J: Okay.
S: One of them has two openings on the outside with
threads on the end, and it&apos;s about five inches long.
Do you see that?
S: Okay, the other one is a bubbled piece with a blue base
on it with one spout. Do you see it?
S: It just round with a little point.
J: Yeah
S: Okay, now you&apos;ve got a bottom hole still to be filled,
correct?
J: Yeah.
S: Okay. You have one red piece remaining?
J: Yeah.
S: Okay. Take that red piece. It&apos;s got four little feet on
it?
J: Yeah.
S: —and on the bottom of that is a hole, right?
J: Yeah.
S: Okay? Now, do you have a—a uh little spout that has
a 90 degree turn in it?
J: Yeah.
A: Okay. Uh let&apos;s see. Got the plunger? That thing with
the metal part and uh—
J: Right.
A: —and the red, blue, and green.
J: Got it.
Okay. Now, insert that entire thing— the red part of
the plunger is your handle.
A: Now take the plunger and the— the main tube— that&apos;s
the biggest plastic tube, and it&apos;s got a threaded end
and an unthreaded end?
J: Right.
A: Okay, now you got a little pink seal with two holes in
it?
J: Yes.
A: Okay. Now you&apos;ve got that uh cone-shaped—that sort
of mouth-shaped red plastic thing?
J: Right.
A: Okay, now all you&apos;ve got left is that little blue plastic
thing.
J: Right.
A: Okay, on the bottom of the main tube you&apos;ve got the
big blue cap.
J: Yes.
A: And it&apos;s got a—it&apos;s got a uh peg in the bottom of it.
J: Right.
</figure>
<bodyText confidence="0.961518">
A: The main tube, yeah. The main tube has a blue cap
on the bottom, and also
</bodyText>
<sectionHeader confidence="0.10735" genericHeader="method">
J: Yes
</sectionHeader>
<reference confidence="0.6776278125">
A: —a blue cap on the top.
J: Yes, right.
A: Okay, you&apos;ve got this blue cap on the bottom. It&apos;s
got a peg in it.
J: Right. Small red peg with four little red things
comin&apos; off it.
Class B: Perception-Based
S: Okay. First I want you to uh— do you see small—three
small red pieces?
J: Y-yes.
S: Do you see a little ring, a little black rubber ring?
J: Yeah.
S: Now. Do you see a little pink plastic piece?
J: Yeah, yeah.
Computational Linguistics Volume 10, Number 2, April-June 1984 131
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
S: And stick it on the en— onto the uh spout coming out
the side. You see that?
J: Yeah,
1: You see a hole?
2: Uh-huh.
1: Um, you will see in front of you a bunch of um pieces
of plastic.
1: All right. And then you&apos;ll see the blue cap begins to
come down over the tube.
1: If you&apos;ll look at the bottom, you will see a projection
in that cap.
2: Yeah.
1: and you see the two projections?
2: Mm-hmm
2: You&apos;ll see three very small red pieces of plastic.
Class C: Fragments
</reference>
<listItem confidence="0.457954">
1: And—if you&apos;re still holding the top— uh the blue—the
blue —that looks like the medicine cap with the peak on
it?
2: Mm-hm.
</listItem>
<bodyText confidence="0.896764333333333">
1:—and this um cylinder-like thing, if you look at the
bottom,
has a hole in it-
</bodyText>
<listItem confidence="0.785736333333333">
2: Mm-hm.
1: All right, this very — this very blue um like narrow
little funnel
</listItem>
<bodyText confidence="0.799038181818182">
A: Oh, let&apos;s see. Four little things coming off it? Now
that was supposed to be—that was supposed to be in
the—
J: top.
A: —in the side. The little red—the red thing with four
little things coming off it.
J: Hey, I think we&apos;re there.
S: —pick it up, and in the bottom of the blue cap on the
main tube—
J: Uh-huh.
S: —is another hole.
</bodyText>
<listItem confidence="0.851355333333333">
2: And take a small blue cap and plug the top hole.
1: The top hole?
2: On the side.
1: Okay.
2: Now. In the cap that you plug the bottom of it with-
1: Mm-hm.
</listItem>
<bodyText confidence="0.873319611111111">
J: Okay. In the green thing at the bottom, there&apos;s a hole.
T: Right. Put the little red [plug—] &amp;line
S: Okay. Now, the small blue cap we talked about
before?
J: Yeah.
S: Put that over the hole on the side of that tube—
J: Yeah.
S: —that is nearest to the top, or nearest to the red
handle.
J: Okay.
S: Okay. Now. Now, the smallest of the red pieces?
J: Okay.
S: Okay. Now where the little red valve is I want you to
flip that 90 degree spout over that.
J: Okay.
S: Okay. Now. I want you to take the other tube that
now has a little red spout sticking on it—
J: Yeah.
S: —pick it up, and in the bottom of the blue cap on the
main tube—
J: Uh-huh.
S: —is another hole.
A: Okay, the—the big part goes in the bottom, and the
little part, that&apos;s what you use— uh you should fit into
the— the main tube, the bottom.
J: (laughs)
A: Yeah, take the red thing off. That was the wrong
instruction.
J: And put the . . .
A: That water chamber with the blue bottom and the globe
top?
J: Yeah.
J: Hm. (laughs) Where does it go?
A: Uh, that—that—that—that uh opening in the side?
J: Yeah.
J: On the red thing?
</bodyText>
<figure confidence="0.599656384615385">
A: Urn no, just—just in the bottom of the— you know the
big blue cap?
J: Yeah.
A: In the bottom of the main tube.
J: Big blue cap
A: Yeah
A: Okay, now stick the elbow joint back on.
J: I got it.
A: Okay, now on the very bottom— the very bottom of the
main tube—
J: I got it, too.
132 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
</figure>
<subsectionHeader confidence="0.601318">
Class D: Nearly Direct Requests
</subsectionHeader>
<bodyText confidence="0.9570642">
1: the next thing you&apos;re gonna look for is a uh blue
piece— it&apos;s—it&apos;s uh a fairly large blue piece, and it looks
like the cap to a medicine bottle.
1: and look at the bottom of the tube that you should be
holding
</bodyText>
<subsectionHeader confidence="0.666249">
Class E: &amp;quot;Let&apos;s&amp;quot; Requests
</subsectionHeader>
<listItem confidence="0.97303375">
1: Okay. Uh keep the [?] Let&apos;s start with a piece that
has— it&apos;s a metal rod.
2: Mm-hm.
1: And it has a green thing on one end-
2: Yes.
1: —and a blue and a red
1: Okay, now (laughs) let&apos;s go back to the original parts
that we put together.
1: Let&apos;s go to the little tiny blue cap.
2: Okay.
1: All right. Now, let&apos;s go back to that funny little red
projection with teeth on the other end.
2: Okay
1: Okay. Now, let&apos;s go back to that little L-shaped piece
of plas—clear plastic that&apos;s sticking up-
2: Mm-hm.
</listItem>
<subsectionHeader confidence="0.980086">
Supplemental NPs
</subsectionHeader>
<bodyText confidence="0.995001">
S: Okay, the other one is a bubbled piece with a blue
base on it with one spout. Do you see it? About two
inches long. Both of these are tubular.
</bodyText>
<figure confidence="0.92321162962963">
J: Okay. Not the bent one.
S: Okay, I want you to take the largest tube, or actually
it&apos;s the largest piece of anything, that has two
openings on the side —
J: yeah
S: Take the spout— the little one that looks like the end
of an oil can—
J: Okay.
S: —and put that on the opening in the other large tube.
With the round top
A: Now take the plunger and the— the main tube— that&apos;s
the biggest plastic tube and it&apos;s got a threaded end and
an unthreaded end?
J: Right.
A: Okay. Now, take the big blue stopper that&apos;s laying
around and take the black ring—
J: The big blue stopper.
A: Yeah, the big blue stopper (short pause) and the black
ring.
J: Yes.
A: Okay, the—the big part goes in the bottom, and the
little part, that&apos;s what you use— uh you should fit into
the— the main tube, the bottom.
J: (laughs)
S: Okay. Now, take the larger blue cap, which is the
only cap remaining—
J: Yeah,
</figure>
<figureCaption confidence="0.211278">
2: And then the elbow goes over that. The big end of
the elbow.
</figureCaption>
<table confidence="0.992643936363637">
Computational Linguistics Volume 10, Number 2, April-June 1984 133
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
Appendix D: Sample Dialogues
Sample Telephone Dialogue
Request Inform
Request Request Infif Complete
Label Action Ident Ident Ident
J: Okay,
we can start now.
S: Okay, John,
you have all the
pieces in front of you?
J: I guess so.
All of &apos;em.
S: Okay.
First I want you to uh— PLUG, V3,
do you see small—three small NOZ
red pieces?
J: Y-yes. PLUG, V3,
NOZ
S: Okay.
Why don&apos;t you take PICK-UP(PLUG, V3, NOZ)
those and separate those out.
Put those three together. PUT-DOWN(PLUG, V3, NOZ)
J: Okay.
S: Okay?
Now you have two blue caps. 0-CAP, TB
One very small that&apos;s 0-CAP
just a push-on cap, TB
and the
other one is a larger one with
threads on it.
J: Okay. 0-CAP, TB
S: You see those? 0-CAP, TB
J: Yes. 0-CAP, TB
S: Put those together and PICK-UP(O-CAP,TB)
separate. PUT-DOWN(0-CAP, TB)
J: Okay.
S: Okay?
Now you have two devices MT,AIR-CH
that are clear plastic.
J: Okay. MT,AIR-CH
S: One of them has two MT
openings on the outside with
threads on the end, and it&apos;s
about five inches long.
Do you see that? MT
J: Yeah. MT
134 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen Label The Pragmatics of Referring and the Modality of Communication Inform
S: Okay, Request Request Request Complete
the other one is a Action Ident Infif Ident
bubbled piece with a blue base AIR-CH Ident
on it with one spout.
Do you see it? AIR-CH
About two inches long.
Both of these are tubular. MT,AIR-CH
J: Okay.
Not the bent one.
S: No,
not the bent one.
J: Okay.
S: That&apos;s a spout, SPOUT
okay?
Okay,
I want you to take the largest PICK-UP(MT) MT
tube,
or actually it&apos;s the
largest piece of anything,
that has two openings on the
side—
J: Yeah. MT
S: —and threads on the bottom.
J: Yeah. MT
S: Do you see it? MT
J: Yeah. MT
S: Okay.
Take that. PICK-UP(MT)
Now there&apos;s PASS PASS
a thing called a plunger.
It has a red handle on it, a
green bottom, and it&apos;s got a
blue lid.
J: Okay. PASS
S: Take that, PICK-UP(PASS)
and starting— PUT-INTO(PL MT)
insert the green end into the
top of that large piece that
you have in your hand—
J: Okay.
S: —and push the green thing PUSH-INTO(PL MT)
down until it comes to the
threaded end.
J: Mm.
It&apos;s pretty tight.
Computational Linguistics Volume 10, Number 2, April-June 1984 135
Philip R. Cohen Label The Pragmatics of Referring and the Modality of Communication Inform
S: Tight fit. Request Request Request Complete
J: Okay. Action Ident Infif Ident
S: Is that in? COVER(T-CAP MT) Ident
J: Yeah.
S: Now,
put that—
snap that blue
cap over the top.
J: (pause) Okay.
S: Have that?
J: Yeah.
S: Okay.
Now, 0-CAP 0-CAP
</table>
<figureCaption confidence="0.905059387096774">
the small blue cap
we talked about before?
J: Yeah. 0-CAP
S: Put that over the hole on the COVER(O-CAP 01) MT
side of that tube—
J: Yeah.
S: —that is nearest to the top,
or nearest to the red handle.
J: Okay.
S: You got that on the hole?
J: Yeah.
S: Okay.
Now.
Now, PLUG PLUG
the smallest of the red pieces?
J: Okay. PLUG
S: You see that? PLUG
J: Yeah.
S: It&apos;s just round with a little PLUG
point.
J: Yeah. PLUG
S: Take that and stick that in MESH(PL PLUG)
the end of the green part of
the plunger.
In the bottom of
the green part of the plunger.
J: Okay.
S: You see it? Hole(PL)
J: Yeah. Hole(PL)
S: You got it in?
J: Yeah.
</figureCaption>
<page confidence="0.388099">
136 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<table confidence="0.808982739130435">
Philip R. Cohen Label The Pragmatics of Referring and the Modality of Communication Inform
Request Request Request Complete
Action Ident Infif Ident
Ident
S: Okay.
Now, PICK-UP(TB) TB
take the larger blue cap,
which is the only cap remaining—
J: Yeah.
S: Do you see a little ring, 0-RING
a little black rubber ring?
Jr Yeah. 0-RING
S: Slip that down into that cap. PUT-INTO(O-RING TB)
Jr Okay.
Sr Got it?
Jr Yeah.
Sr Now.
Do you see a little pink V2
plastic piece?
Jr Yeah, yeah. V2
Sr With two holes? V2
Jr Yeah. V2
Sr Okay.
</table>
<bodyText confidence="0.851339153846154">
You have your blue cap
in front of you?
Jr Yeah.
S:Setting down with the two
little prongs sticking up.
Jr Yeah.
Sr Okay, PICK-UP(V2)
take that little pink MESH(V2 TB)
plastic piece,
and the two
holes in the plastic piece—
Jr Mm-hm.
Sr —go over the two little
notches.
Jr Does it matter whether the
shiny side or the dull side of
the pink thing&apos;s up?
Sr Pardon me?
Jr Well, one side of the pink
thing is shiny, one side is—
S: No, it doesn&apos;t matter.
Jr Okay.
Sr And put it so that it&apos;s ACHIEVE(COVERS(V2 Hole
covering the hole in the
bottom of that little cap.
(TB)))
</bodyText>
<figure confidence="0.890219176470588">
Computational Linguistics Volume 10, Number 2, April-June 1984 137
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
Request
Action
Request
Ident
Request
Infif
Ident
Inform
Complete
Ident
(pause) Kinda fits hard,
doesn&apos;t it?
J: Little bit tight, yeah.
Okay.
S: Okay,
</figure>
<figureCaption confidence="0.442434">
now it&apos;s covering the
hole in the cap.
J: Yeah.
S: Okay.
Now,
</figureCaption>
<bodyText confidence="0.902183230769231">
I want you to
screw that cap onto that big
air tube that had the threads
on it—
J: Okay.
S: —that you put the plunger in.
J: Okay.
S: Now,
you have the large tube,
you have the plunger in the tube,
you have the little red
thing in the bottom of the
plunger.
</bodyText>
<reference confidence="0.81612">
J: Mm-hm.
S: You have the blue cap on the
upper hole.
J: Mm-hm.
S: And you have the big blue cap
with the ring and the little
plastic thing screwed onto the
bottom.
J: Yeah.
S: Okay.
Now.
Urn I want you to
take the urn—
okay,
take uh the
—now you have two red pieces
remaining, right?
J: Yeah.
S: Take the spout—
the little one
that looks like the end of an
oil can—
</reference>
<figure confidence="0.648860666666667">
SCREW-TOGETHER(MT TB)
PICK-UP(NOZ)
NOZ
Label
138 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen Label The Pragmatics of Referring and the Modality of Communication Inform
Request Request Request Complete
Action Ident Infif Ident
Ident
</figure>
<figureCaption confidence="0.164787113636364">
J: Okay. NOZ
S:—and put that on the opening CONNECT(NOZ AIR-CH)
in the other large tube.
With the round top—
J: Oh,
the other large tube.
Okay.
S: The other large—
yeah.
Put the tube with the plunger PUT-DOWN(MT)
aside.
J: Okay.
S: And stick it on the en— CONNECT(NOZ AIR-CH)
onto the uh spout coming out the
side.
You see that? 03
J: Yeah, 03
okay.
S: You got that on,
okay.
J: Yeah.
S: Um now.
Now we&apos;re getting a
little more difficult.
J: (laughs)
S: Pick out the large air tube PICK-UP(MT)
that has the plunger in it.
J: Okay.
S: And set it on its base, PUT-DOWN(TB)
which is blue now,
right?
J: Yeah.
S: Base is blue.
Okay,
now
you&apos;ve got a bottom hole still
to be filled,
correct?
J: Yeah.
S: Okay.
You have one red piece
remaining?
J: Yeah.
S: Okay.
</figureCaption>
<figure confidence="0.968560142857143">
Computational Linguistics Volume 10, Number 2, April-June 1984 139
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
Request
Ident
Request
Infif
Ident
Inform
Complete
Ident
V3
V3
SPOUT
SPOUT
</figure>
<bodyText confidence="0.97038075">
Take that red piece.
It&apos;s got four little feet on
it?
J: Yeah.
S: And put the small end into
that hole on the air tube—
on the big tube.
J: On the very bottom.
S: On the bottom,
yes.
J: Okay.
S: Okay?
Now,
do you have a—a
uh little spout that has a 90 degree
turn in it?
J: Yeah.
S: Okay.
Stick that directly
over—
Now wait.
We put the
little red piece in the bottom
hole,
correct?
J: Yeah,
on the—
you mean the
bottom hole in the side or the
—there was a bottom hole in
the blue cap.
S: On the side,
yes.
J: On the side,
okay.
S: Yes,
okay?
One&apos;s got a blue
cap on it,
and the other one&apos;s
got the little red thing in it
now.
J: Yeah.
S: Okay.
</bodyText>
<figure confidence="0.949462818181818">
Request
Action
PICK-UP(V3)
CONNECT(SPOUT AIR-CH)
CONNECT(SPOUT---)
Label
140 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen Label The Pragmatics of Referring and the Modality of Communication Inform
Request Request Request Complete
Action Ident Infif Ident
Ident
</figure>
<figureCaption confidence="0.756460822222222">
Now where the little CONNECT(SPOUT MT) 01
red valve is
I want you to
flip that 90 degree spout over that.
J: Okay.
Which way should I
point the spout?
S: The—the spout should point
upward.
J: Upward,
okay.
S: Which is toward the red handle
of the plunger.
J: Yeah.
S: Got that?
J: Yeah.
S: Okay.
Now the little—the
little red thing fits in there
okay.
J: Yeah.
S: Okay.
Now.
I want you to PICK-UP(AIR-CH)
take the other tube that now
has a little red spout
sticking on it—
J: Yeah. AIR-CH
S: —and on the bottom of that is Hole
a hole, (AIR-CH)
right?
J: Yeah.
S: I want you to fit that over CONNECT(SPOUT AIR-CH)
the top of that 90 degree turn.
J: Okay.
S: Okay?
J: Yeah.
S: Got that?
J: Mm-hm.
S: Now,
what piece do you have
remaining?
Only the one long STAND
bluish colored piece?
J: Yeah. STAND
</figureCaption>
<figure confidence="0.2099834">
Computational Linguistics Volume 10, Number 2, April-June 1984 141
Philip R. Cohen Label The Pragmatics of Referring and the Modality of Communication Inform
Request Request Request Complete
Action Ident Infif Ident
Ident
</figure>
<figureCaption confidence="0.958578622222222">
S: Okay.
Take the entire apparatus, PICK-UP(PUMP)
which should all be
together now—
J: Yeah.
S: —pick it up, Hole(TB)
and in the
bottom of the blue cap on the
main tube—
J: Uh-huh. Hole(TB)
S: —is another hole.
I want you CONNECT(STAND TB)
to stick that remaining
piece—
J: In there?
S: —in that hole—
J: Okay.
S: —with the long piece going
in.
J: Yeah.
Okay.
S: Okay.
Now.
You have the
plunger in and all the holes
should be filled.
J: Uhh.
S: Are there any remaining
pieces?
J: No.
S: No.
Okay.
Now, HANDLE PUT-INTO (PUMP TRAY)
insert that entire thing—
the red part of
the plunger is your handle.
Insert the base of the—of the
apparatus into the water—
J: Mm-hm.
S: —and start pumping that PUMP[HANDLE]
handle.
Draw up some water,
like a hypodermic needle.
J: Okay.
S: Now,
</figureCaption>
<figure confidence="0.920990594594595">
142 Computational Linguistics Volume 10, Number 2, April-June 1984
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
Request Inform
Request Request Infif Complete
Label Action Ident Ident Ident
push it down.
Does it indeed squirt out the red
spout?
J: Yeah.
S: Okay.
I think we&apos;re finished.
(END OF TAPE)
Computational Linguistics Volume 10, Number 2, April-June 1984 143
Philip R. Cohen The Pragmatics of Referring and the Modality of Communicatiori-
Sample Keyboard Dialogue
Request
Action
Request
Ident
Request
Infif
Ident
Inform
Complete
Ident
anyone there?
hello
hi
all right?
ready
ok
N: [what]
B: to [whom am i] speaking
N: nicolette
B: shall we begin?
N: i&apos;m ready when you are
B: ok,
</figure>
<bodyText confidence="0.988283875">
here goes...
1) take the plunger...
and [2)]
N: [ok]
B: insert it into the non-threaded
end of the big tube...
N: ready
B: fit the blue cap over the tube
end
N: done
B: put the little black ring
into the large blue cap with
the hole in it...
N: ok
B: put the pink valve on the two
pegs in that blue cap...
N: ok
B: now,
put the little blue cap over
the hole in the large tube near
the plunger handle...
N: ready
B: forgot one thing...
use the red thing that looks like
a nail to plug the plunger
so it will work...
N: [you mean] the green part
B: [capeesh]
you got it, kid...
N: great
B: anyway,
put the red piece with the strange
</bodyText>
<figure confidence="0.996276125">
Pick-up(PASS)
Put-into(PL MT)
Cover(T-CAP MT)
Put-into(0-RING TB)
Mesh(V2 TB)
Cover(0-CAP 01)
PASS
Label
</figure>
<page confidence="0.423339">
144 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
<bodyText confidence="0.78316236">
Philip R. Cohen Label The Pragmatics of Referring and the Modality of Communication Inform
projections LOOSELY into the Request Request Request Complete
bottom hole on the main tube. Action Ident Infif Ident
Mesh(V3 MT) &amp; Ident
Achieve (LOOSE V3 MT)
Ok?
N: which hole
the bottom one on the side?
B: right.
put the 1/4 inch long
&apos;post&apos; into the loosely fitting hole... Mesh (V3 MT)
N: i don&apos;t understand what you
mean
B: the red piece, with the four tiny V3
projections?
N: ok V3
B: just place it loosely
[into the] Mesh (V3 MT) &amp;
Achieve (LOOSE V3 MT)
N: [done]
B: yes?
N: yes
B: place it loosely into the hole on
the side of the large tube...
N: done
B: very good.
See the clear elbow tube? SPOUT
N: yes
B: place the large end over that Connect (SPOUT MT)
same place.
N: ready
B: take the clear dome Pick-up (AIR-CH)
and attach it to the Connect (AIR-CH SPOUT)
end of the elbow joint...
N: using the blue attachment part?
B: right.
it&apos;s already attached, so I
didn&apos;t mention it.
Now, Connect (NOZZ AIR-CH)
put the red nozzle over the hole
in the dome.
N: ok
B: Almost done now.
Screw the blue cap that has the Screw-together (TB MTASSM)
pink valve on it onto the bottom
of the main cylinder.
N: ready
B: stick the translucent blue stand Connect (STAND PUMP)
onto that very cap Achieve (SUPPORTED TAB
so that the pump will stand up. PUMP)
</bodyText>
<figure confidence="0.831559523809524">
Computational Linguistics Volume 10, Number 2, April-June 1984 145
Philip R. Cohen The Pragmatics of Referring and the Modality of Communication
Request
Action
Request
Ident
Request
Inf if
Ident
Inform
Complete
Ident
N: ok,
but it won&apos;t stand
B: then hold onto it...
N: ok
B: i think that that&apos;s all!.
Test it!
N: here goes
B: well???
N: it works beautifully
</figure>
<bodyText confidence="0.9547818">
B: thank you, no applause, just
money...
sure thing
anything else?
nope, that&apos;s all
</bodyText>
<sectionHeader confidence="0.937371" genericHeader="method">
Achieve (HOLDING PUMP)
Achieve (WORKING PUMP)
</sectionHeader>
<bodyText confidence="0.520499">
Label
</bodyText>
<page confidence="0.805887">
146 Computational Linguistics Volume 10, Number 2, April-June 1984
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.403787">
<title confidence="0.996575">The Pragmatics of Referring the Modality of Communication&apos;</title>
<author confidence="0.99998">Philip R Cohen</author>
<affiliation confidence="0.881773">Laboratory for Artificial Intelligence Fairchild Camera and Instrument</affiliation>
<address confidence="0.942184">Palo Alto, CA</address>
<abstract confidence="0.966596533333334">This paper presents empirical results comparing spoken and keyboard communication. It is shown that speakers attempt to achieve more detailed goals in giving instructions than do users of keyboards. One specific kind of fine-grained communicative act, a request that the hearer identify the referent of a noun phrase, is shown to dominate spoken instruction-giving discourse, but is nearly absent from keyboard discourse. Most important, these requests are only achieved &amp;quot;indirectly&amp;quot;. — through utterances whose surface forms do not explicitly convey the speakers&apos; intent. A plan-based theory of communication is shown to uncover the speakers&apos; intentions underlying many cases of indirect identification requests found in the corpus, once an action for referent identification has been posited. In so doing, the theory demonstrates how intent (or plan) recognition can be applied in reasoning about the use of a description. As a consequence of this approach, it is shown that the conditions on the planning of successful identification requests account for Searle&apos;s conditions on the act of referring. It is concluded that intent recognition will need to be a central focus for pragmatics/discourse components of future speech understanding systems, and that computational linguistics needs to develop formalisms for reasoning about speakers&apos; use of descriptions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J F Allen</author>
</authors>
<title>A Plan-based Approach to Speech Act Recognition.</title>
<date>1979</date>
<tech>Technical Report 131,</tech>
<institution>Department of Computer Science, University of Toronto.</institution>
<contexts>
<context position="7084" citStr="Allen 1979" startWordPosition="1067" endWordPosition="1068">ng a speaker&apos;s plans (Bruce 1983, Cohen and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in preparation; Sidner et al. 1981). Although these provide a more comprehensive account of indirect speech act interpretation than previous linguistic or philosophical approaches, they have not been tested against a corpus other than the ones that supported their creation (e.g., Horrigan 1977). Therefore, as an adequacy test, the fourth objective for this paper is: 4. To evaluate how well a plan-based theory of communication can uncover the intentions underlying the use of many surface forms in the transcripts. The theory is</context>
<context position="30144" citStr="Allen 1979" startWordPosition="4601" endWordPosition="4602">upon the intended referent.9 Finally, although not stated in this definition, the means by which the act is performed is some function mapping D to some plan or procedure that, when executed by Agt, enables Agt to discover the X that is the referent of D. Even with this imprecise understanding of referent identification, it is apparent that not all noun phrases used in task-oriented conversations (even with the perceptual access conditions satisfied) are uttered with the intention that their referents be identified. For example, in dialogues with an information booth clerk in a train station (Allen 1979, Horrigan 1977), patrons uttering &amp;quot;the 3:15 to Montreal?&amp;quot; are not intending the clerk to pick out the train. Instead, as part of their plan for boarding a train, patrons are intending the clerk to supply them with a co-referring noun phrase that will allow them to identify the train. The attributive use of definite noun phrases (Donnellan 1960) is another case in which the speaker has no intention that the hearer identify a referent. Other non-anaphoric uses of noun phrases include labeling an object, correcting a referential miscommunication, getting the speaker to wait while the speaker ide</context>
<context position="46169" citStr="Allen 1979" startWordPosition="7157" endWordPosition="7158">not be identical to those conveyed by the literal utterance. The plans make use of a formalization of the experimental task, the modality and the prior discourse, expressed in terms of the participants&apos; mutual beliefs, goals, expectations, and possibilities for action. Thus, the theory captures, albeit in an indirect way, the dependence of the discourse structure on the experimental task and communication modality. In addition, a performance model would include algorithms for forming and recognizing plans of action to derive the observer&apos;s intent codings. Although such models have been built (Allen 1979, Brachman et al. 1979), I do not discuss them further here. In summary, the discourse analysis methodology is as follows: • Train coders to identify various illocutionary acts (IAs). • Compare the distribution of IAs across modalities. • Independently, characterize those IA types in terms of plans. • Formally derive the IA codings as a rational strategy of action, given attributions of the participants&apos; beliefs, goals, and expectations at the point in the discourse in which the IAs occurred. When our work is complete, we will have analyses of the differences in achievement of the same overarc</context>
<context position="75648" citStr="Allen 1979" startWordPosition="11743" endWordPosition="11744">ACT THEN EFFECT) 2% [&amp;quot;If you look at the bottom you will see a project&amp;quot;] 2. QUESTION(EFFECT) 5% [&amp;quot;If you look at the bottom you will see a projection&amp;quot;] 3. INFORM(EFFECT) 2% [&amp;quot; you will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a</context>
<context position="76927" citStr="Allen 1979" startWordPosition="11958" endWordPosition="11959">are performing in making those utterances. For the purposes of this paper, planning is simplistically viewed as the process of finding an action (or a sequence of them) that will achieve the agent&apos;s goal(s) given what he believes to be the state of the world. Roughly speaking, to recognize an agent&apos;s plan in performing an action, observers deploy a theory of planning &amp;quot;in reverse&amp;quot; to connect the observed action with a chain of inferences of the form &amp;quot;agent did X in order to achieve Y, which would enable him to do Z&amp;quot;, terminating in (what they take to be) a likely or expected goal of the agent (Allen 1979; Genesereth 1978; Schmidt, Sridharan, and Goodson 1979; Wilensky 1978). Such reasoning employs beliefs about the agent&apos;s beliefs, conditions that are likely to be true at the end of an action, other actions that are enabled by those conditions, and expected plans and goals of that agent. 112 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the M, odality of Communication 6.2 Analyzing indirect identification requests Perrault and Allen (1980) have proposed the following plan-recognition inferences: • Action-effect: If the observer </context>
</contexts>
<marker>Allen, 1979</marker>
<rawString>Allen, J.F. 1979 (January) A Plan-based Approach to Speech Act Recognition. Technical Report 131, Department of Computer Science, University of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J F Allen</author>
<author>C R Perrault</author>
</authors>
<title>Analyzing Intention in Dialogues.</title>
<date>1980</date>
<journal>Artificial Intelligence</journal>
<volume>15</volume>
<issue>3</issue>
<pages>143--178</pages>
<contexts>
<context position="7109" citStr="Allen and Perrault 1980" startWordPosition="1069" endWordPosition="1072">&apos;s plans (Bruce 1983, Cohen and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in preparation; Sidner et al. 1981). Although these provide a more comprehensive account of indirect speech act interpretation than previous linguistic or philosophical approaches, they have not been tested against a corpus other than the ones that supported their creation (e.g., Horrigan 1977). Therefore, as an adequacy test, the fourth objective for this paper is: 4. To evaluate how well a plan-based theory of communication can uncover the intentions underlying the use of many surface forms in the transcripts. The theory is shown to account for app</context>
<context position="80369" citStr="Allen and Perrault 1980" startWordPosition="12506" endWordPosition="12509"> hearer to pass the hammer to the speaker. The essential insight of the theory is that indirect speech act recognition is a by-product of the general process of recognizing someone&apos;s plans. If illocutionary act identification occurs immediately after the expansion of a surface act, then a literal interpretation has been found. If there are intervening intended plan-recognition inferences, then an indirect interpretation has been inferred. 6.3 Example The following example is intended to give a brief introduction to the reasoning underlying indirection. Details of this process can be found in (Allen and Perrault 1980, Perrault and Allen 1980). The utterance to be interpreted is, &amp;quot;Can you reach the hammer?&amp;quot; The inferred propositions are indicated in boldface; commentary on the inference process is indented. After parsing and semantic interpretation, the utterance is represented as a surface speech act: HBSW (S-REQUEST(S,H,INFORMIF(H,S, CANDO(H,REACH(H,HAMMER))))) That is, the Hearer Believes the Speaker Wanted to perform (what appears to be) a yes-no question about his ability to reach the hammer. The effect of an S-REQUESTS to do action ACT is simply that the hearer believes the speaker wants the hearer t</context>
</contexts>
<marker>Allen, Perrault, 1980</marker>
<rawString>Allen, J.F. and Perrault, C.R. 1980 Analyzing Intention in Dialogues. Artificial Intelligence 15(3): 143-178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Appelt</author>
</authors>
<title>Planning Natural Language Utterances to Satisfy Multiple Goals.</title>
<date>1981</date>
<tech>Ph.D. Thesis,</tech>
<institution>Stanford University,</institution>
<location>Stanford, California.</location>
<contexts>
<context position="75661" citStr="Appelt 1981" startWordPosition="11745" endWordPosition="11746">ECT) 2% [&amp;quot;If you look at the bottom you will see a project&amp;quot;] 2. QUESTION(EFFECT) 5% [&amp;quot;If you look at the bottom you will see a projection&amp;quot;] 3. INFORM(EFFECT) 2% [&amp;quot; you will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a mapping of u</context>
<context position="128177" citStr="Appelt 1981" startWordPosition="20132" endWordPosition="20133">tively (Donnellan 1960). Moreover, such reasoning should be useful in determining intended referents, as Ortony (1978) has argued. To cash in this promissory note, one needs to be specific about speaker intentions for other uses of noun phrases. This will be no easy task. One difficulty will be to capture the distinction between achieving effects on a hearer, and doing so communicatively (i.e., in the Gricean way). Thus, for example, a hearer cannot comply with the illocutionary act, &amp;quot;Quick, don&apos;t think of an elephant&amp;quot;, because there seems to be an &amp;quot;automatic&amp;quot; process of &amp;quot;concept activation&amp;quot; (Appelt 1981). Achieving effects noncommunicatively, without the recognition of intent, may be central to some kinds of reference. In such cases, speakers would be able to identify referents for a hearer. If this held for singular identifying reference, then there could be grounds for a propositional act. However, we might have to give up the Gricean Condition 5, which I suspect Searle would not want to do. Although it has been demonstrated that the action of perceptual identification differs from other treatments of reference in computational linguistics, perceptual identification has not yet been formali</context>
<context position="135252" citStr="Appelt (1981)" startWordPosition="21199" endWordPosition="21200">sory examination of the handwritten transcripts reveals that keyboard communication is markedly different in structure from written communication. Whereas experts in keyboard mode rarely use identification requests, writers use them frequently, in both direct and indirect forms. Furthermore, writers often performed all identification requests first, and labeled each of the objects for future reference (much as authors of published assembly instructions do). Keyboard interaction, in its emphasis on optimal packing of information into the smallest linguistic &amp;quot;space&amp;quot;, appears to be a mode 32 See Appelt (1981) for a system that operates along these lines. of communication that alters the normal organization of discourse. We should thus be wary of our theories&apos; and techniques&apos; coverage if they are to extended to other modalities of communication. 10 Acknowledgements This work would not have been possible without the help of Scott Fertig and Kathleen Starr, who spent countless hours coding the transcripts. Many thanks also to Rob Tierney for collaboration in organizing and conducting the experiments. I would like to thank Zoltan Uzhelyi for videotaping, Debbie Winograd, Larry Shirey, and Julie Burke </context>
</contexts>
<marker>Appelt, 1981</marker>
<rawString>Appelt, D. 1981 (December) Planning Natural Language Utterances to Satisfy Multiple Goals. Ph.D. Thesis, Stanford University, Stanford, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Asher</author>
</authors>
<title>Referential Communication. In</title>
<date>1979</date>
<publisher>Academic Press,</publisher>
<location>New York, New York.</location>
<contexts>
<context position="19959" citStr="Asher 1979" startWordPosition="2961" endWordPosition="2962">n 1977). A separate computer program was to have been built for processing each transcript. By merging the common features of these systems, an empirically-based theory and computational model were to have been developed. This work resulted in a goal-directed, &amp;quot;dialogue games&amp;quot; model of conversational interaction (Levin and Moore 1977), though it is not clear whether the model&apos;s formulation resulted from the merging of implementations. Finally, there is a huge literature of psychological studies of referential communication. I will not survey it here (but see Dickson 1981 for recent papers and Asher 1979 for an extensive review), but mention only two themes of relevance to this study. First, such work has shown that, in spoken interaction, noun phrase length tends to decrease as subsequent references to an object are made. However, in non-interactive spoken modalities (Krauss &amp; Weinheimer 1966), the decrease for subsequent references is lessened. These results indicate that efficiency in referential communication is a function of user feedback. The development of the component skills involved in referring is a second theme in this literature. In order to test Piaget&apos;s &amp;quot;egocentrism&amp;quot; hypotheses</context>
<context position="21483" citStr="Asher 1979" startWordPosition="3189" endWordPosition="3190">e referring expression. This line of &apos;However, neither corpus incorporated true spoken interaction. The SRI dialogues that were analyzed in depth were taken from a mixed communication mode in which one, an &amp;quot;expert&amp;quot;, typed instructions to a third party, who spoke them to an &amp;quot;apprentice&amp;quot;, and typed the apprentice&apos;s spoken replies to the expert. The BBN &amp;quot;incremental simulation&amp;quot; dialogues involved only keyboard communication. &apos;Similar approaches include those of Dore et al. (1978), and Sinclair and Coulthard (1975). Shatz and Gelman (1973) showed they can do so (though not necessarily accurately (Asher 1979)) at a much earlier age than had been supposed. 100 Computational Linguistics Volume 10, Number 3-4, July-December 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication work is more relevant to the present concerns of characterizing the act of identification, but the subskills examined are still too coarse for our needs. Previous research has thus provided many lessons, among them: • the need to compare (at least initially) modalities that are minimally different, • the need for repeatable methods for characterizing linguistic behavior at the pragmatics and discour</context>
<context position="104131" citStr="Asher 1979" startWordPosition="16286" endWordPosition="16287">oals can terminate the process of plan recognition &amp;quot; It is apparent that the two NP&apos;s are spoken with different intonation and timing. Prosodic aspects of an utterance are often regarded as signalling the speaker&apos;s attitude or intent toward what is being said. Thus, perhaps the speaker is prosodically signalling the &amp;quot;wait while I identify&amp;quot; intent. This conclusion supports the argument that speaker intent plays a role in processing descriptions. &amp;quot; The &amp;quot;referential communication&amp;quot; literature considers the converse position — whether speakers are egocentric in producing noun phrases for a hearer (Asher 1979). &amp;quot; No mechanisms have been proposed in the literature that can derive such expectations of the expert&apos;s goals from more basic information about the task, modality, genre, etc. At most, what has been proposed is the ability to use such expectations, independently of how they are derived. Computational Linguistics Volume 10, Number 2, April-June 1984 117 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication applied to utterance interpretation. Thus, the inferring of a script that contains the expert&apos;s intent that the hearer identify the referents of descriptions is consi</context>
</contexts>
<marker>Asher, 1979</marker>
<rawString>Asher, S.R. 1979 Referential Communication. In Whitehurst, G.J. and Zimmerman, B.Z., Eds., The Functions of Language and Cognition. Academic Press, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Austin</author>
</authors>
<title>How to Do Things with Words.</title>
<date>1962</date>
<publisher>Oxford University Press,</publisher>
<location>London.</location>
<contexts>
<context position="43470" citStr="Austin 1962" startWordPosition="6738" endWordPosition="6739">ly, as the conversation progresses, one needs interpretations of what each speaker meant, stated in terms of further attributions of beliefs and intentions. Standard empirical methods should be used to minimize experimenter bias in making such attributions. In particular, the theorist must be careful not to be the source of belief/intent attributions, for if given the leeway, he will undoubtedly find what he is looking for. To avoid this problem, I trained two people to employ a vocabulary for describing intentions in discourse, the so-called &amp;quot;illocutionary acts&amp;quot; (or, loosely, &amp;quot;speech acts&amp;quot;) (Austin 1962, Searle 1969). That is, the discourse analysts &amp;quot;code&amp;quot; the speaker&apos;s intentions in making an utterance by assigning illocutionary act labels to utterances (or groups of them). Fortunately, the illocutionary act vocabulary is the natural one in our common-sense psychology for making such attributions. However, unlike most theories of illocutionary acts, I do not claim that the conversants themselves attempt to determine what illocutionary acts were performed, although they might be able to do so if requested.14 The illocutionary act interpretations are therefore our interpretations, as coders a</context>
</contexts>
<marker>Austin, 1962</marker>
<rawString>Austin, J.L. 1962 How to Do Things with Words. Oxford University Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Brachman</author>
<author>R Bobrow</author>
<author>P Cohen</author>
<author>J Klovstad</author>
<author>B L Webber</author>
<author>W A Woods</author>
</authors>
<title>Research in Natural Language Understanding.</title>
<date>1979</date>
<tech>Technical Report 4274,</tech>
<institution>Bolt Beranek and Newman Inc.</institution>
<contexts>
<context position="7131" citStr="Brachman et al. 1979" startWordPosition="1073" endWordPosition="1076">en and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in preparation; Sidner et al. 1981). Although these provide a more comprehensive account of indirect speech act interpretation than previous linguistic or philosophical approaches, they have not been tested against a corpus other than the ones that supported their creation (e.g., Horrigan 1977). Therefore, as an adequacy test, the fourth objective for this paper is: 4. To evaluate how well a plan-based theory of communication can uncover the intentions underlying the use of many surface forms in the transcripts. The theory is shown to account for approximately 70% of the </context>
<context position="9214" citStr="Brachman et al. 1979" startWordPosition="1394" endWordPosition="1397">uld frequently issue requests. Because requests dominate interactions with many question-answering systems, and with most conceivable interactive applications of natural language processing, they have been extensively studied in computational linguistics. • Second, because the task is simple and constrained, it provides an excellent adequacy test for proposed theories and computational techniques; any theory of communication that cannot handle the phenomena of this study can hardly be called general. However, since the domain is functionally similar to those of various keyboard-based systems (Brachman et al. 1979, Robinson et al. 1980, Winograd 1972), the data and results of the study may suggest directions for extending those systems. • Third, the domain is similar to those analyzed by other researchers (Chapanis et al. 1972, Chapanis et al. 1977, Grosz 1977), and thus the dialogues could serve to confirm or refute their results. 98 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication • Finally, instructions play a crucially important role in people&apos;s everyday lives — success in industrial, academic, and bureaucra</context>
<context position="46192" citStr="Brachman et al. 1979" startWordPosition="7159" endWordPosition="7162">ical to those conveyed by the literal utterance. The plans make use of a formalization of the experimental task, the modality and the prior discourse, expressed in terms of the participants&apos; mutual beliefs, goals, expectations, and possibilities for action. Thus, the theory captures, albeit in an indirect way, the dependence of the discourse structure on the experimental task and communication modality. In addition, a performance model would include algorithms for forming and recognizing plans of action to derive the observer&apos;s intent codings. Although such models have been built (Allen 1979, Brachman et al. 1979), I do not discuss them further here. In summary, the discourse analysis methodology is as follows: • Train coders to identify various illocutionary acts (IAs). • Compare the distribution of IAs across modalities. • Independently, characterize those IA types in terms of plans. • Formally derive the IA codings as a rational strategy of action, given attributions of the participants&apos; beliefs, goals, and expectations at the point in the discourse in which the IAs occurred. When our work is complete, we will have analyses of the differences in achievement of the same overarching set of goals (the </context>
<context position="73725" citStr="Brachman et al. 1979" startWordPosition="11404" endWordPosition="11407"> speakers adopted a consistent style. For example, all the &amp;quot;nearly direct requests&amp;quot; came from one speaker, and another almost uniformly used the &amp;quot;there&apos;s a NP&amp;quot; strategy. Because explicit identification requests come in many syntactic forms, each of which has a literal interpretation that is not an identification request, the hearer needs some method for deciding what the speaker&apos;s intention(s) are. Ideally, such reasoning should be an application of more general reasoning about nonlinguistic actions. Of course, a suitable &amp;quot;compiling&amp;quot; strategy can specialize the general case for this task (cf. Brachman et al. 1979). Below, I sketch such a theory and apply it to the examples in Table 3. 6.1 A sketch of a plan-based theory of communication The unifying theme of much current pragmatics research is that the coherence of dialogue is to be found in the interaction of the conversants&apos; plans. That is, a speaker is regarded as planning his utterances to achieve his goals, which may involve influencing a hearer. On receiving an utterance, the hearer attempts to infer the speaker&apos;s goal(s), and to understand how the, utterance furthers them. The hearer then adopts new goals (e.g., to respond to a request, to clari</context>
<context position="132056" citStr="Brachman et al. (1979)" startWordPosition="20731" endWordPosition="20734">tent recognition will have to be applied to the act of identifying a referent. However, given sufficient restrictions on the domain of discourse and the robot&apos;s capabilities, an implementation of the plan-recognition process might simplify the general case. I have suggested that derived inference rules coupled with expectations can serve adequately. A formal foundation for such derived rules for intent interpretation can be found in Cohen and Levesque (1980, in preparation), and a prototype implementation that uses both general and derived rules for interpreting speaker intent is described in Brachman et al. (1979). Additional problem areas suggested by this research include developing formal and computational models of 122 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication the generation of useful descriptions, and getting machines to plan reference and predication separately.32 However, if given more resources, systems should be able to &amp;quot;optimize&amp;quot; referring and predicating plans into single utterances. Conversely, systems ought to be able to reason about the speakers&apos; uses of descriptions — for identification, co</context>
<context position="133364" citStr="Brachman et al. 1979" startWordPosition="20919" endWordPosition="20922">tudy must be interpreted with three cautionary notes. First, the category of identification requests is specific to discourse situations in which the topics of conversation include objects physically present to the hearer. If the conversation is not about manipulating concrete objects, different pragmatic inferences could be made, even though the same surface forms might be used. Second, not all natural language communication between person and machine are accurately captured by the Telephone and Keyboard conditions. For example, conversations about the contents of the system&apos;s display scope (Brachman et al. 1979, Winograd 1972) might share some aspects of the Face-to-Face condition (especially the experts&apos; use of sentence fragments to correct the apprentices&apos; mistakes). Thus, the generality of these findings will only be established when conversations in other discourse situations are analyzed. Third, it should be realized that the indirection results may occur only in conversations between humans. It is possible that people do not wish to verbally instruct others with fine-grained imperatives for fear of sounding condescending. Print may remove such inhibitions, as may talking to a machine. The ques</context>
</contexts>
<marker>Brachman, Bobrow, Cohen, Klovstad, Webber, Woods, 1979</marker>
<rawString>Brachman, R.; Bobrow, R.; Cohen, P.; Klovstad, J.; Webber, B.L.; and Woods, W.A. 1979 (August) Research in Natural Language Understanding. Technical Report 4274, Bolt Beranek and Newman Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B C Bruce</author>
</authors>
<title>Strategies for Natural Language Processing, Lawrence Erlbaum Associates,</title>
<date>1981</date>
<journal>Natural Communication Between Person</journal>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="16077" citStr="Bruce (1981)" startWordPosition="2387" endWordPosition="2388">ational Linguistics Volume 10, Number 3-4, July-December 1984 99 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication linguistics. Not only are regularities in nongrammatical speech identified, but a class of &amp;quot;editing&amp;quot; rules is provided that can make such utterances parsable. Current work on relaxing grammar rules and on parsing ill-formed input (Hayes and Mouradian 1981, Kwasny and Sondheimer 1981, Weischedel and Black 1980) is in much the same spirit. The purposes at hand require analyses of the pragmatic and discourse structure of actual dialogues. Grosz (1977) and Bruce (1981) (among others) have shown how such discourse analyses can have direct implications for algorithm design. In their work, transcripts of dialogues were collected and analyzed, leading to the development of algorithms for speech-understanding systems (Walker 1978, Woods et al. 1976).4 Grosz&apos; analyses indicate that anaphoric reference in task-oriented dialogues is constrained by the hierarchical structure of the physical task. A parallel structuring of &amp;quot;focus spaces&amp;quot; was proposed as a mechanism to constrain the search for co-referents, and became the mainstay of the discourse component of two sys</context>
</contexts>
<marker>Bruce, 1981</marker>
<rawString>Bruce, B.C. 1981 Natural Communication Between Person and Computer. In Lehnert, W. and Ringle, M., Eds., Strategies for Natural Language Processing, Lawrence Erlbaum Associates, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B C Bruce</author>
</authors>
<title>Belief Systems and Language Understanding.</title>
<date>1983</date>
<booktitle>In Trends in Linguistics, Studies and Monographs 19: Computers in Language Research 2. Walter de Gruyter and Co.,</booktitle>
<location>New York, New York.</location>
<contexts>
<context position="6506" citStr="Bruce 1983" startWordPosition="977" endWordPosition="978">s, speakers explicitly request hearers to identify the referents of noun phrases (NPs), but users of keyboards do not. Instead, the referential goals achieved by these requests are subsumed by other requested actions. Most importantly, these identification requests are only achieved &amp;quot;indirectly&amp;quot; — through utterances whose surface forms do not explicitly convey the speakers&apos; intent. Current theories propose that the speaker&apos;s intentions underlying the use of indirect speech acts can be recognized as a by-product of a more general, independently motivated process of inferring a speaker&apos;s plans (Bruce 1983, Cohen and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1</context>
<context position="75673" citStr="Bruce 1983" startWordPosition="11747" endWordPosition="11748">you look at the bottom you will see a project&amp;quot;] 2. QUESTION(EFFECT) 5% [&amp;quot;If you look at the bottom you will see a projection&amp;quot;] 3. INFORM(EFFECT) 2% [&amp;quot; you will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a mapping of utterance for</context>
</contexts>
<marker>Bruce, 1983</marker>
<rawString>Bruce, B.C. 1983 Belief Systems and Language Understanding. In Trends in Linguistics, Studies and Monographs 19: Computers in Language Research 2. Walter de Gruyter and Co., New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B C Bruce</author>
<author>D Newman</author>
</authors>
<title>Interacting Plans.</title>
<date>1978</date>
<journal>Cognitive Science</journal>
<volume>2</volume>
<issue>3</issue>
<pages>195--233</pages>
<contexts>
<context position="75696" citStr="Bruce and Newman 1978" startWordPosition="11749" endWordPosition="11752">the bottom you will see a project&amp;quot;] 2. QUESTION(EFFECT) 5% [&amp;quot;If you look at the bottom you will see a projection&amp;quot;] 3. INFORM(EFFECT) 2% [&amp;quot; you will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a mapping of utterance forms to the &amp;quot;surface spee</context>
</contexts>
<marker>Bruce, Newman, 1978</marker>
<rawString>Bruce, B.C. and Newman, D. 1978 Interacting Plans. Cognitive Science 2(3): 195-233.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B Bruce</author>
<author>C F Schmidt</author>
</authors>
<title>Episode Understanding and Belief Guided Parsing. Presented at the Association for Computational Linguistics Meeting at</title>
<location>Amherst, Massachusetts.</location>
<marker>Bruce, Schmidt, </marker>
<rawString>Bruce, B., and Schmidt, C.F. Episode Understanding and Belief Guided Parsing. Presented at the Association for Computational Linguistics Meeting at Amherst, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Burke</author>
</authors>
<title>An Analysis of Intelligibility in a Practical Activity: The Role and Relationship of Discourse and Context.</title>
<date>1982</date>
<tech>Ph.D. Thesis,</tech>
<institution>Dept. of Speech Communication, University of Illinois.</institution>
<contexts>
<context position="40502" citStr="Burke (1982)" startWordPosition="6247" endWordPosition="6248">either terminal. Response times averaged 1 to 2 seconds, with occasionally longer delays due to system load. 4.1 Sample transcripts The following are representative samples of transcripts in the two modalities. A TELEPHONE DIALOGUE FRAGMENT S: &amp;quot;OK. Take that. Now there&apos;s a thing called a plunger. It has a red handle on it, a green bottom, and it&apos;s got a blue lid. J: OK S: OK now, the small blue cap we talked about before? J: Yeah S: Put that over the hole on the side of that tube — J: Yeah The instructions given to the expert about the experiment and the assembly task are given in Appendix A. Burke (1982) reports that the order of the instructions, and the descriptions of the pieces, influenced the order and vocabulary of the expert&apos;s subsequent instructions. S: — that is nearest to the top, or nearest to the red handle. J: OK S: OK. Now. now, the smallest of the red pieces? J: OK&amp;quot; A KEYBOARD DIALOGUE FRAGMENT B: &amp;quot;fit the blue cap over the tub end N: done B: put the little black ring into the large blue cap with the hole in it... N: ok B: right Put the 1/4 inch long &apos;post&apos; into the loosely fitting hole... N: i don&apos;t understand what you mean B: the red piece, with the four tiny projections? N: </context>
</contexts>
<marker>Burke, 1982</marker>
<rawString>Burke, J.A. 1982 An Analysis of Intelligibility in a Practical Activity: The Role and Relationship of Discourse and Context. Ph.D. Thesis, Dept. of Speech Communication, University of Illinois.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W L Chafe</author>
</authors>
<title>Integration and Involvement in Speaking, Writing, and Oral Literature. In</title>
<date>1982</date>
<location>Norwood, New Jersey.</location>
<contexts>
<context position="14693" citStr="Chafe 1982" startWordPosition="2180" endWordPosition="2181">cate that problems are solved twice as fast in vocal modalities as they are in written ones, even though communicators use twice as many words when speaking.3 Although motivating the development of speech-understanding systems, these results unfortunately tell us little about how the processing of spoken utterances differs from the processing of written ones. Other research has compared the syntax of spoken and written discourse. The primary findings are: Written language is syntactically more integrated than spoken, employing nominalizations, participles, complements, relative clauses, etc. (Chafe 1982); and spoken language exhibits regular patterns of false starts and hesitations (Hindle 1983, Kroch and Hindle 1982). The former results can help a system designer to determine which syntactic constructs to emphasize in a grammar for parsing. The latter results are more useful to computational 2 This approach essentially characterizes language situations as multidimensional vectors whose components, describing the above dimensions, are binary values (e.g., +/- voice). Thus, it is assumed that neighboring modalities afford equal communicative possibilities in all dimensions in which they are th</context>
</contexts>
<marker>Chafe, 1982</marker>
<rawString>Chafe, W.L. 1982 Integration and Involvement in Speaking, Writing, and Oral Literature. In Tannen, D., Ed., Spoken and Written Language: Exploring Orality and Literacy. Ablex Publishing Corporation, Norwood, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Chapanis</author>
<author>RB Ochsman</author>
<author>R N Parrish</author>
<author>G D Weeks</author>
</authors>
<title>Studies in Interactive Communication: I. The Effects of Four Communication Modes on the Behavior of Teams during Cooperative Problem Solving.</title>
<date>1972</date>
<journal>Human Factors</journal>
<volume>14</volume>
<pages>487--509</pages>
<contexts>
<context position="9431" citStr="Chapanis et al. 1972" startWordPosition="1430" endWordPosition="1433"> studied in computational linguistics. • Second, because the task is simple and constrained, it provides an excellent adequacy test for proposed theories and computational techniques; any theory of communication that cannot handle the phenomena of this study can hardly be called general. However, since the domain is functionally similar to those of various keyboard-based systems (Brachman et al. 1979, Robinson et al. 1980, Winograd 1972), the data and results of the study may suggest directions for extending those systems. • Third, the domain is similar to those analyzed by other researchers (Chapanis et al. 1972, Chapanis et al. 1977, Grosz 1977), and thus the dialogues could serve to confirm or refute their results. 98 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication • Finally, instructions play a crucially important role in people&apos;s everyday lives — success in industrial, academic, and bureaucratic tasks, for example, requires the following of instructions. Children are initially instructed face-to-face, but they eventually learn to follow written instructions. The present study, though not this paper, shoul</context>
<context position="13802" citStr="Chapanis et al. 1972" startWordPosition="2056" endWordPosition="2059">iotape, picturephone, writing, etc.2 Rubin reports that many studies comparing language experiences present conclusions about oral/written language differences even though the language experiences differ from one another along multiple dimensions. In such cases it is not clear if the observed differences result, for example, from the presence of voice, the ability to interact, or both. There is evidence that at least some quantitative linguistic and efficacy results are primarily determined by the presence of voice in the communication modality. A series of studies by Chapanis and colleagues (Chapanis et al. 1972, Chapanis et al. 1977) compared problem-solving effectiveness among teams communicating in face-toface, voice only, written, keyboard, and other communication modalities. Dependent measures included problem solution time, number of words, sentences, utterances, etc. Results indicate that problems are solved twice as fast in vocal modalities as they are in written ones, even though communicators use twice as many words when speaking.3 Although motivating the development of speech-understanding systems, these results unfortunately tell us little about how the processing of spoken utterances dif</context>
</contexts>
<marker>Chapanis, Ochsman, Parrish, Weeks, 1972</marker>
<rawString>Chapanis, A.; Ochsman, RB.; Parrish, R.N.; and Weeks, G.D. 1972 Studies in Interactive Communication: I. The Effects of Four Communication Modes on the Behavior of Teams during Cooperative Problem Solving. Human Factors 14: 487-509.</rawString>
</citation>
<citation valid="false">
<booktitle>Computational Linguistics Volume 10, Number 2, April-June 1984 123 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication</booktitle>
<marker></marker>
<rawString>Computational Linguistics Volume 10, Number 2, April-June 1984 123 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Chapanis</author>
<author>R N Parrish</author>
<author>R B Ochsman</author>
<author>G D Weeks</author>
</authors>
<title>Studies in Interactive Communication: II. The Effects of Four Communication Modes on the Linguistic Performance of Teams during Cooperative Problem Solving. Human Factors</title>
<date>1977</date>
<volume>19</volume>
<issue>2</issue>
<pages>101--125</pages>
<contexts>
<context position="9453" citStr="Chapanis et al. 1977" startWordPosition="1434" endWordPosition="1437">nal linguistics. • Second, because the task is simple and constrained, it provides an excellent adequacy test for proposed theories and computational techniques; any theory of communication that cannot handle the phenomena of this study can hardly be called general. However, since the domain is functionally similar to those of various keyboard-based systems (Brachman et al. 1979, Robinson et al. 1980, Winograd 1972), the data and results of the study may suggest directions for extending those systems. • Third, the domain is similar to those analyzed by other researchers (Chapanis et al. 1972, Chapanis et al. 1977, Grosz 1977), and thus the dialogues could serve to confirm or refute their results. 98 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication • Finally, instructions play a crucially important role in people&apos;s everyday lives — success in industrial, academic, and bureaucratic tasks, for example, requires the following of instructions. Children are initially instructed face-to-face, but they eventually learn to follow written instructions. The present study, though not this paper, should ultimately provide a</context>
<context position="13825" citStr="Chapanis et al. 1977" startWordPosition="2060" endWordPosition="2063">writing, etc.2 Rubin reports that many studies comparing language experiences present conclusions about oral/written language differences even though the language experiences differ from one another along multiple dimensions. In such cases it is not clear if the observed differences result, for example, from the presence of voice, the ability to interact, or both. There is evidence that at least some quantitative linguistic and efficacy results are primarily determined by the presence of voice in the communication modality. A series of studies by Chapanis and colleagues (Chapanis et al. 1972, Chapanis et al. 1977) compared problem-solving effectiveness among teams communicating in face-toface, voice only, written, keyboard, and other communication modalities. Dependent measures included problem solution time, number of words, sentences, utterances, etc. Results indicate that problems are solved twice as fast in vocal modalities as they are in written ones, even though communicators use twice as many words when speaking.3 Although motivating the development of speech-understanding systems, these results unfortunately tell us little about how the processing of spoken utterances differs from the processin</context>
</contexts>
<marker>Chapanis, Parrish, Ochsman, Weeks, 1977</marker>
<rawString>Chapanis, A.; Parrish, R.N.; Ochsman, R.B.; and Weeks, G.D. 1977 Studies in Interactive Communication: II. The Effects of Four Communication Modes on the Linguistic Performance of Teams during Cooperative Problem Solving. Human Factors 19(2): 101-125.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H H Clark</author>
<author>D Wilkes-Gibbs</author>
</authors>
<title>Referring as a Collaborative Process. Unpublished ms.</title>
<marker>Clark, Wilkes-Gibbs, </marker>
<rawString>Clark, H.H. and Wilkes-Gibbs, D. Referring as a Collaborative Process. Unpublished ms.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P R Cohen</author>
</authors>
<title>On Knowing What to Say: Planning Speech Acts.</title>
<tech>Ph.D. Thesis and Technical Report No. 118,</tech>
<institution>Department of Computer Science, University of Toronto,</institution>
<location>Toronto.</location>
<marker>Cohen, </marker>
<rawString>Cohen, P.R. On Knowing What to Say: Planning Speech Acts. Ph.D. Thesis and Technical Report No. 118, Department of Computer Science, University of Toronto, Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Cohen</author>
</authors>
<title>Referring as Requesting.</title>
<date>1984</date>
<booktitle>Proceedings of COLING84,</booktitle>
<pages>207--211</pages>
<location>Stanford, California,</location>
<contexts>
<context position="52507" citStr="Cohen (1984)" startWordPosition="8146" endWordPosition="8147">, Moore, and Levin 1977). Reliabilities were high (above 88%). Because each disagreement counted twice (against both categories that were coded), agreements also counted twice. 4.2.3 Coding the sample dialogue fragments The previous fragments are coded below to indicate some of the complexities of the data as well as the scoring scheme. A number of shortcuts have been taken for expository purposes. First, if an act is stated as &apos;5 The above Telephone dialogue fragment contains one such intonationally marked noun phrase. 16 For a formal analysis that does make such a claim, see section 8.4 and Cohen (1984). &apos; The action-effect relation holding between the various propositions and assembly actions can be readily inferred from Appendix B. 106 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication COMPLETE, then the proposition stated as the effect of that act holds.17 Second, some of the arguments to the embedded propositions have not been presented when those arguments are not problematic. Third, as argued above, the second argument of IDENTIFY-REFERENT should be a description in some appropriate logical form r</context>
<context position="120969" citStr="Cohen (1984)" startWordPosition="19000" endWordPosition="19001">t constitutes identification (as are, for that matter, all other accounts of which I am aware), the choice between them must rest on other grounds. The grounds favoring the identification request analysis include the use of separate utterances and illocutionary acts for its analysis of referring, and the independently motivated satisfaction of Searle&apos;s conditions on referring. 8.5 Searle vs. Russell Using the propositional act of referring, Searle argues against Russell&apos;s (1905) theory of descriptions, which holds that the uttering of an expression &amp;quot;the 0&amp;quot; is equivThe analysis of referring in Cohen (1984) makes use of a theory of communication of Cohen and Levesque (1980, in preparation) that does not require the recognition of illocutionary acts. Instead, IA&apos;s are derived as theorems about the speaker&apos;s goals. The analysis of requesting in this theory would state that the request theorem is applicable when Searle claims that an act of referring is performed, and, as we have seen, at other times as well. Thus, the hearer does not have to recognize each referring act as a request; each referring act merely has to be characterizable as one. 120 Computational Linguistics Volume 10, Number 2, Apri</context>
</contexts>
<marker>Cohen, 1984</marker>
<rawString>Cohen, P.R. 1984 Referring as Requesting. Proceedings of COLING84, Stanford, California, 207-211.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Cohen</author>
<author>H J Levesque</author>
</authors>
<title>Speech Acts and the Recognition of Shared Plans.</title>
<date>1980</date>
<booktitle>Proceedings of the Third Biennial Conference, Canadian Society for Computational Studies of Intelligence,</booktitle>
<pages>263--271</pages>
<location>Victoria, B. C.,</location>
<contexts>
<context position="6556" citStr="Cohen and Levesque 1980" startWordPosition="983" endWordPosition="986">s to identify the referents of noun phrases (NPs), but users of keyboards do not. Instead, the referential goals achieved by these requests are subsumed by other requested actions. Most importantly, these identification requests are only achieved &amp;quot;indirectly&amp;quot; — through utterances whose surface forms do not explicitly convey the speakers&apos; intent. Current theories propose that the speaker&apos;s intentions underlying the use of indirect speech acts can be recognized as a by-product of a more general, independently motivated process of inferring a speaker&apos;s plans (Bruce 1983, Cohen and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in </context>
<context position="44935" citStr="Cohen and Levesque (1980" startWordPosition="6962" endWordPosition="6965">r discourses. A preferable analysis would derive regularities from more basic principles. The method employed here for formulating such derivations includes the following components: • A logic of beliefs, mutual beliefs, and goals. • A specification of the goals achieved by utterances of various forms (e.g., a yes/no question is an attempt to get the hearer to inform the speaker whether or not the proposition in question is true). • A formal theory of rational, intentional action that specifies how an agent&apos;s actions are determined by both his goals and his knowledge of the effects of, 14 See Cohen and Levesque (1980, in preparation) for a plan-based theory of communication that does not require the recognition of illocutionary acts. preconditions for, and means of accomplishing various action types. The aim of a competence theory of communication based on plans is to specify the set of possible plans underlying the appropriate use of various illocutionary acts. In applying such a theory to the analysis of discourse, plans are used to connect an utterance&apos;s form and content with the observers&apos; illocutionary act coding, which is our best approximation to the speaker&apos;s intent. It is important to remember th</context>
<context position="75752" citStr="Cohen and Levesque 1980" startWordPosition="11758" endWordPosition="11761">) 5% [&amp;quot;If you look at the bottom you will see a projection&amp;quot;] 3. INFORM(EFFECT) 2% [&amp;quot; you will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a mapping of utterance forms to the &amp;quot;surface speech actions&amp;quot; speakers are performing in making those utte</context>
<context position="107053" citStr="Cohen and Levesque 1980" startWordPosition="16732" endWordPosition="16735">t speech acts (such as asking a companion on a lifeboat, &amp;quot;Can you swim to shore?&amp;quot;). The plan-based theory is suited to such cases. On the other hand, the indirect speech acts that are usually regarded as conventional can be handled within the plan-based theory in a comparably efficient way, because inference paths can be precomputed from surface speech acts characterizing utterance forms (rather than always being derived from first principles, as various critiques assume). &amp;quot;Bottom-up&amp;quot; derived rules can be used in concert with the more general-purpose rules, much as lemmas are used in a proof (Cohen and Levesque 1980).3° Such an &amp;quot;ability is needed to account for examples such as &amp;quot;Can you reach the hammer&amp;quot;, that cannot be handled by conventional methods alone (which would only be able to derive a request to reach the hammer, rather than as a request to pass it). Scripts are often viewed as short-cuts for more general processing. The plan-based position advocated here conforms to the intuition that scripted situations should give rise to simple processing. By combining strong topdown expectations with bottom-up derived rules based on utterance form, utterances can be interpreted with minimal inference. Howev</context>
<context position="121036" citStr="Cohen and Levesque (1980" startWordPosition="19010" endWordPosition="19013">all other accounts of which I am aware), the choice between them must rest on other grounds. The grounds favoring the identification request analysis include the use of separate utterances and illocutionary acts for its analysis of referring, and the independently motivated satisfaction of Searle&apos;s conditions on referring. 8.5 Searle vs. Russell Using the propositional act of referring, Searle argues against Russell&apos;s (1905) theory of descriptions, which holds that the uttering of an expression &amp;quot;the 0&amp;quot; is equivThe analysis of referring in Cohen (1984) makes use of a theory of communication of Cohen and Levesque (1980, in preparation) that does not require the recognition of illocutionary acts. Instead, IA&apos;s are derived as theorems about the speaker&apos;s goals. The analysis of requesting in this theory would state that the request theorem is applicable when Searle claims that an act of referring is performed, and, as we have seen, at other times as well. Thus, the hearer does not have to recognize each referring act as a request; each referring act merely has to be characterizable as one. 120 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Mod</context>
<context position="130220" citStr="Cohen and Levesque 1980" startWordPosition="20449" endWordPosition="20452">itive distinctions were clear. In fact, my providing the coders with formal definitions may have been counterproductive because the definitions did not necessarily mirror people&apos;s commonsense distinctions. One lesson to be learned from the difficult experience of getting others to &amp;quot;code&amp;quot; the illocutionary acts in a dialogue is that because it is so difficult, perhaps it is not done by the participants. It is certainly possible that conversants engage in dialogue without being able to specify precisely, using illocutionary verbs, just which illocutionary acts were performed. Because elsewhere (Cohen and Levesque 1980, in preparation) we have developed formalisms for communication that do not require the identification of illocutionary acts, it may be unnecessary to require the hearer to do so. Therefore, empirical support is needed for the often presupposed position that hearers must identify illocutionary acts. 9.2 Implications for computational linguistics The simple communication task analyzed here involved primarily the performing of requests. As such, it should fall within the scope of computational linguistic techniques. However, no natural language system that I know can handle the discourse struct</context>
<context position="131895" citStr="Cohen and Levesque (1980" startWordPosition="20707" endWordPosition="20710">, they are likely to encounter indirect identification requests. If their language processing is based on inferring and responding to the speaker&apos;s intent, then intent recognition will have to be applied to the act of identifying a referent. However, given sufficient restrictions on the domain of discourse and the robot&apos;s capabilities, an implementation of the plan-recognition process might simplify the general case. I have suggested that derived inference rules coupled with expectations can serve adequately. A formal foundation for such derived rules for intent interpretation can be found in Cohen and Levesque (1980, in preparation), and a prototype implementation that uses both general and derived rules for interpreting speaker intent is described in Brachman et al. (1979). Additional problem areas suggested by this research include developing formal and computational models of 122 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication the generation of useful descriptions, and getting machines to plan reference and predication separately.32 However, if given more resources, systems should be able to &amp;quot;optimize&amp;quot; referri</context>
</contexts>
<marker>Cohen, Levesque, 1980</marker>
<rawString>Cohen, P.R. and Levesque, H.J. 1980 (May) Speech Acts and the Recognition of Shared Plans. Proceedings of the Third Biennial Conference, Canadian Society for Computational Studies of Intelligence, Victoria, B. C., 263-271.</rawString>
</citation>
<citation valid="false">
<authors>
<author>P R Cohen</author>
<author>H J Levesque</author>
</authors>
<title>(in preparation) Speech Acts as Summaries of Shared Plans.</title>
<marker>Cohen, Levesque, </marker>
<rawString>Cohen, P.R. and Levesque, H.J. (in preparation) Speech Acts as Summaries of Shared Plans.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P R Cohen</author>
<author>C R Perrault</author>
</authors>
<title>Elements of a Plan-based Theory of Speech Acts.</title>
<date>1979</date>
<journal>Cognitive Science</journal>
<volume>3</volume>
<issue>3</issue>
<pages>177--212</pages>
<contexts>
<context position="6531" citStr="Cohen and Perrault 1979" startWordPosition="979" endWordPosition="982">explicitly request hearers to identify the referents of noun phrases (NPs), but users of keyboards do not. Instead, the referential goals achieved by these requests are subsumed by other requested actions. Most importantly, these identification requests are only achieved &amp;quot;indirectly&amp;quot; — through utterances whose surface forms do not explicitly convey the speakers&apos; intent. Current theories propose that the speaker&apos;s intentions underlying the use of indirect speech acts can be recognized as a by-product of a more general, independently motivated process of inferring a speaker&apos;s plans (Bruce 1983, Cohen and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979</context>
<context position="75777" citStr="Cohen and Perrault 1979" startWordPosition="11762" endWordPosition="11765"> bottom you will see a projection&amp;quot;] 3. INFORM(EFFECT) 2% [&amp;quot; you will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a mapping of utterance forms to the &amp;quot;surface speech actions&amp;quot; speakers are performing in making those utterances. For the purposes </context>
</contexts>
<marker>Cohen, Perrault, 1979</marker>
<rawString>Cohen, P.R. and Perrault, C.R. 1979 Elements of a Plan-based Theory of Speech Acts. Cognitive Science 3(3): 177-212.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W P Dickson</author>
</authors>
<title>Childrens&apos;s Oral Communication Skills.</title>
<date>1981</date>
<publisher>Academic Press,</publisher>
<location>New York, New York.</location>
<contexts>
<context position="19926" citStr="Dickson 1981" startWordPosition="2955" endWordPosition="2956">ity Mann, Carlisle, Moore, and Levin 1977). A separate computer program was to have been built for processing each transcript. By merging the common features of these systems, an empirically-based theory and computational model were to have been developed. This work resulted in a goal-directed, &amp;quot;dialogue games&amp;quot; model of conversational interaction (Levin and Moore 1977), though it is not clear whether the model&apos;s formulation resulted from the merging of implementations. Finally, there is a huge literature of psychological studies of referential communication. I will not survey it here (but see Dickson 1981 for recent papers and Asher 1979 for an extensive review), but mention only two themes of relevance to this study. First, such work has shown that, in spoken interaction, noun phrase length tends to decrease as subsequent references to an object are made. However, in non-interactive spoken modalities (Krauss &amp; Weinheimer 1966), the decrease for subsequent references is lessened. These results indicate that efficiency in referential communication is a function of user feedback. The development of the component skills involved in referring is a second theme in this literature. In order to test </context>
</contexts>
<marker>Dickson, 1981</marker>
<rawString>Dickson, W.P. 1981 Childrens&apos;s Oral Communication Skills. Academic Press, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Donnellan</author>
</authors>
<title>Reference and definite description.</title>
<date>1960</date>
<journal>The Philosophical Review</journal>
<volume>75</volume>
<pages>281--304</pages>
<contexts>
<context position="30491" citStr="Donnellan 1960" startWordPosition="4660" endWordPosition="4661"> not all noun phrases used in task-oriented conversations (even with the perceptual access conditions satisfied) are uttered with the intention that their referents be identified. For example, in dialogues with an information booth clerk in a train station (Allen 1979, Horrigan 1977), patrons uttering &amp;quot;the 3:15 to Montreal?&amp;quot; are not intending the clerk to pick out the train. Instead, as part of their plan for boarding a train, patrons are intending the clerk to supply them with a co-referring noun phrase that will allow them to identify the train. The attributive use of definite noun phrases (Donnellan 1960) is another case in which the speaker has no intention that the hearer identify a referent. Other non-anaphoric uses of noun phrases include labeling an object, correcting a referential miscommunication, getting the speaker to wait while the speaker identifies the referent, etc.1° 3.2 Comparisons with computational linguistics approaches to reference Computational linguistics research has usually been concerned with co-reference — the relationship of words and symbols to other words and symbols. Typically, referents of descriptions are determined by intersecting the extensions of the predicate</context>
<context position="127588" citStr="Donnellan 1960" startWordPosition="20037" endWordPosition="20038">while it allowing for appropriate extension into a planning process. The promissory note introduced by this approach is to show how the same kind of plan-based reasoning used in analyzing indirect speech acts can take hold when a hearer realizes he cannot, and was not intended to, identify the referent of a description. That is, plan-based reasoning should explain how a hearer might decide that the speaker&apos;s intention cannot be what it appears to be (based on the intent correlated with the use of a definite determiner), leading him, for example, to decide to treat a description attributively (Donnellan 1960). Moreover, such reasoning should be useful in determining intended referents, as Ortony (1978) has argued. To cash in this promissory note, one needs to be specific about speaker intentions for other uses of noun phrases. This will be no easy task. One difficulty will be to capture the distinction between achieving effects on a hearer, and doing so communicatively (i.e., in the Gricean way). Thus, for example, a hearer cannot comply with the illocutionary act, &amp;quot;Quick, don&apos;t think of an elephant&amp;quot;, because there seems to be an &amp;quot;automatic&amp;quot; process of &amp;quot;concept activation&amp;quot; (Appelt 1981). Achieving</context>
</contexts>
<marker>Donnellan, 1960</marker>
<rawString>Donnellan, K. 1960 Reference and definite description. The Philosophical Review 75: 281-304.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Dore</author>
<author>M Gearhart</author>
<author>D Newman</author>
</authors>
<title>The Structure of Nursery School Conversation. In</title>
<date>1978</date>
<pages>337--396</pages>
<publisher>Gardner Press,</publisher>
<location>New York, New York,</location>
<contexts>
<context position="21353" citStr="Dore et al. (1978)" startWordPosition="3166" endWordPosition="3169">hildren of certain ages can adequately make comparisons of the properties of referents and non-referents in order to formulate an adequate referring expression. This line of &apos;However, neither corpus incorporated true spoken interaction. The SRI dialogues that were analyzed in depth were taken from a mixed communication mode in which one, an &amp;quot;expert&amp;quot;, typed instructions to a third party, who spoke them to an &amp;quot;apprentice&amp;quot;, and typed the apprentice&apos;s spoken replies to the expert. The BBN &amp;quot;incremental simulation&amp;quot; dialogues involved only keyboard communication. &apos;Similar approaches include those of Dore et al. (1978), and Sinclair and Coulthard (1975). Shatz and Gelman (1973) showed they can do so (though not necessarily accurately (Asher 1979)) at a much earlier age than had been supposed. 100 Computational Linguistics Volume 10, Number 3-4, July-December 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication work is more relevant to the present concerns of characterizing the act of identification, but the subskills examined are still too coarse for our needs. Previous research has thus provided many lessons, among them: • the need to compare (at least initially) modalities th</context>
<context position="47058" citStr="Dore et al. (1978)" startWordPosition="7298" endWordPosition="7301">e IA types in terms of plans. • Formally derive the IA codings as a rational strategy of action, given attributions of the participants&apos; beliefs, goals, and expectations at the point in the discourse in which the IAs occurred. When our work is complete, we will have analyses of the differences in achievement of the same overarching set of goals (the assembly task) as a function of modality. 4.2.1 Coding the transcripts The first stage of discourse analysis involves the coding of the communicator&apos;s intent in making various utterances. Following the experiences of Sinclair and Coulthard (1975), Dore et al. (1978), and Mann, Carlisle, Moore, and Levin (1977), a coding scheme was developed and two people were trained in its use. The coders relied on written transcripts, audiotapes, and on videotapes. The scheme, which was tested and revised on pilot data until reliability was attained, included a set of approximately eight illocutionary act categories that were used to label intent, and a set of &amp;quot;operators&amp;quot; and propositions that were used to describe the assembly task, as in Sacerdoti (1975). Appendix B lists the propositions and operators for the physical actions. For example, putting two hollow, pipe-</context>
</contexts>
<marker>Dore, Gearhart, Newman, 1978</marker>
<rawString>Dore, J.; Gearhart, M.; and Newman, D. 1978 The Structure of Nursery School Conversation. In Nelson, K., Ed., Children&apos;s Language. Vol I. Gardner Press, New York, New York, 337-396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Evans</author>
</authors>
<title>Situations and Speech Acts: Toward a Formal Semantics of Discourse.</title>
<date>1981</date>
<tech>Ph.D. Thesis,</tech>
<institution>Department of Linguistics, Stanford University.</institution>
<marker>Evans, 1981</marker>
<rawString>Evans, D. 1981 (December) Situations and Speech Acts: Toward a Formal Semantics of Discourse. Ph.D. Thesis, Department of Linguistics, Stanford University.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Fertig</author>
</authors>
<title>Miscommunication in Discourse. Unpublished B.A. Thesis,</title>
<location>Hampshire College, Amherst, Massachuseets.</location>
<marker>Fertig, </marker>
<rawString>Fertig, S. Miscommunication in Discourse. Unpublished B.A. Thesis, Hampshire College, Amherst, Massachuseets.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Genesereth</author>
</authors>
<title>Automated Consultation for Complex Computer Systems.</title>
<date>1978</date>
<tech>Ph.D. Thesis,</tech>
<institution>Department of Computer Science, Division of Applied Sciences, Harvard University.</institution>
<contexts>
<context position="76944" citStr="Genesereth 1978" startWordPosition="11960" endWordPosition="11961">ng in making those utterances. For the purposes of this paper, planning is simplistically viewed as the process of finding an action (or a sequence of them) that will achieve the agent&apos;s goal(s) given what he believes to be the state of the world. Roughly speaking, to recognize an agent&apos;s plan in performing an action, observers deploy a theory of planning &amp;quot;in reverse&amp;quot; to connect the observed action with a chain of inferences of the form &amp;quot;agent did X in order to achieve Y, which would enable him to do Z&amp;quot;, terminating in (what they take to be) a likely or expected goal of the agent (Allen 1979; Genesereth 1978; Schmidt, Sridharan, and Goodson 1979; Wilensky 1978). Such reasoning employs beliefs about the agent&apos;s beliefs, conditions that are likely to be true at the end of an action, other actions that are enabled by those conditions, and expected plans and goals of that agent. 112 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the M, odality of Communication 6.2 Analyzing indirect identification requests Perrault and Allen (1980) have proposed the following plan-recognition inferences: • Action-effect: If the observer thinks the agent </context>
</contexts>
<marker>Genesereth, 1978</marker>
<rawString>Genesereth, M.R. 1978 (September) Automated Consultation for Complex Computer Systems. Ph.D. Thesis, Department of Computer Science, Division of Applied Sciences, Harvard University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Grice</author>
</authors>
<date>1957</date>
<journal>Meaning. Philosophical Review</journal>
<volume>66</volume>
<pages>377--388</pages>
<contexts>
<context position="78668" citStr="Grice (1957)" startWordPosition="12240" endWordPosition="12241">19 • Knowif: If the agent is thought to want to know whether or not some proposition P holds, then consider that the agent wants P to hold (or wants P to be false). The plan-recognition process first classifies utterances by their mood into so-called &amp;quot;surface speech acts&amp;quot;: declaratives become instances of the S-INFORM act type, imperatives become S-REQUESTS, and questions become S-REQUESTS to INFORMIF or INFORMREF (for Yes/No and Wh questions, respectively). These surface acts are the prototypical ways to perform the corresponding illocutionary acts REQUEST, INFORM, and REQUEST to INFORMIF.2° Grice (1957) has argued that a simple plan-recognition process, which an unseen observer might perform, cannot be the basis for communication. Rather, the hearer must infer and act on what the speaker wants him to think she wants. A plan-based theory proposes that such reasoning is invoked by applying the independently motivated plan-recognition process to the observed communicative actions. Hearers are, in effect, asking themselves &amp;quot;Why did the speaker say that?&amp;quot; Subsequent reasoning, termed here intended plan recognition, derives other goals that the hearer thinks she or he was supposed to infer. The pr</context>
</contexts>
<marker>Grice, 1957</marker>
<rawString>Grice, H.P. 1957 Meaning. Philosophical Review 66: 377-388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
</authors>
<title>The Representation and Use of Focus in Dialogue Understanding.</title>
<date>1977</date>
<tech>Technical Report 151,</tech>
<institution>Artificial Intelligence Center, SRI International.</institution>
<contexts>
<context position="2587" citStr="Grosz 1977" startWordPosition="381" endWordPosition="382">become a topic of computational linguistic research. Previous investigations have concentrated on syntactic differences between spoken and written language (Hindle 1983, Kroch and Hindle 1982, Thompson 1980), with the goal of adapting parsing techniques to handle the syntax of spoken language. However, even if this goal were achieved, a system needs to be prepared to handle any unique properties of the discourse structure of spoken interaction if it is to be successful in conducting a dialogue. Of course, there has been much work on discourse processing within computational linguistics (e.g., Grosz 1977, Sidner 1979, Webber 1978), and any future systems will undoubtedly incorporate previously successful techniques. However, one suspects that the coverage This research was supported primarily by the National Institute of Education under contract US-N1E-C-400-76-0116 to the Center for the Study of Reading of the University of Illinois and Bolt Beranek and Newman Inc., and in part by the Oregon State University. The paper was written at the Fairchild Camera and Instrument Corporation, and revised at SRI International. The revisions of this paper have been made possible by a gift from the System</context>
<context position="9466" citStr="Grosz 1977" startWordPosition="1438" endWordPosition="1439">ond, because the task is simple and constrained, it provides an excellent adequacy test for proposed theories and computational techniques; any theory of communication that cannot handle the phenomena of this study can hardly be called general. However, since the domain is functionally similar to those of various keyboard-based systems (Brachman et al. 1979, Robinson et al. 1980, Winograd 1972), the data and results of the study may suggest directions for extending those systems. • Third, the domain is similar to those analyzed by other researchers (Chapanis et al. 1972, Chapanis et al. 1977, Grosz 1977), and thus the dialogues could serve to confirm or refute their results. 98 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication • Finally, instructions play a crucially important role in people&apos;s everyday lives — success in industrial, academic, and bureaucratic tasks, for example, requires the following of instructions. Children are initially instructed face-to-face, but they eventually learn to follow written instructions. The present study, though not this paper, should ultimately provide a window on ho</context>
<context position="16060" citStr="Grosz (1977)" startWordPosition="2384" endWordPosition="2385">odalities. Computational Linguistics Volume 10, Number 3-4, July-December 1984 99 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication linguistics. Not only are regularities in nongrammatical speech identified, but a class of &amp;quot;editing&amp;quot; rules is provided that can make such utterances parsable. Current work on relaxing grammar rules and on parsing ill-formed input (Hayes and Mouradian 1981, Kwasny and Sondheimer 1981, Weischedel and Black 1980) is in much the same spirit. The purposes at hand require analyses of the pragmatic and discourse structure of actual dialogues. Grosz (1977) and Bruce (1981) (among others) have shown how such discourse analyses can have direct implications for algorithm design. In their work, transcripts of dialogues were collected and analyzed, leading to the development of algorithms for speech-understanding systems (Walker 1978, Woods et al. 1976).4 Grosz&apos; analyses indicate that anaphoric reference in task-oriented dialogues is constrained by the hierarchical structure of the physical task. A parallel structuring of &amp;quot;focus spaces&amp;quot; was proposed as a mechanism to constrain the search for co-referents, and became the mainstay of the discourse com</context>
<context position="34394" citStr="Grosz 1977" startWordPosition="5273" endWordPosition="5274"> noun phrases were perceptually accessible to the hearer. The system was primarily oriented towards utterance interpretation, but it did generate responses to questions. In doing so, the system was in the same circumstances as the experts in the present study. However, because it was assumed that the extensions of all of the system&apos;s descriptors were already known to the hearer, the system did not reason that it should choose particular referring expressions so that the hearer could pick out their referents. Instead, the choice of referring expressions was constrained by uniqueness and focus (Grosz 1977), constraints that are not considered here but are clearly necessary. Although TDUS employed the concept of locating an object in its representation of successful task performance, this concept did not play a role in choosing referring expressions unless the system was asked a question about an object&apos;s location. Appelt&apos;s KAMP system (1981) generalized TDUS to plan referring actions as part of the planning of illocutionary acts. However, KAMP would only include descriptors in a referring expression for which it was already mutually believed that the hearer knew the referent. Thus, it could not</context>
<context position="95495" citStr="Grosz 1977" startWordPosition="14916" endWordPosition="14917"> the bottom of the tube&amp;quot;) mentions &amp;quot;Look at&amp;quot;, but does not indicate a search explicitly. The interpretation of this utterance in Perrault and Allen&apos;s scheme would require an additional &amp;quot;body-action&amp;quot; inference to yield a request for identification. Case 2 (&amp;quot;The next thing you&apos;re gonna look for is...&amp;quot;) is literally an informative utterance, though a request could be derived in one step. It is important that the frequency of these &amp;quot;nearest neighbors&amp;quot; is minimal (2%). 6.4.5 &amp;quot;Let&apos;s&amp;quot; requests One speaker used &amp;quot;Let&apos;s&amp;quot; requests explicitly to shift the topic of conversation to one previously &amp;quot;closed&amp;quot; (Grosz 1977), and in the process to get the hearer to re-identify an object. Whereas other identification requests shift the topic as a by-product, this request seems literally to be a topic shift, with identification as a by-product. 6.5 Summary The act of explicitly requesting referent identification is nearly always performed indirectly in Telephone mode. This being the case, inferential mechanisms are needed for uncovering the speaker&apos;s intentions from the variety of forms with which this act is performed. A plan-based theory of communication accounts for 69% of the identification requests in the corp</context>
<context position="96765" citStr="Grosz 1977" startWordPosition="15110" endWordPosition="15111">hermore, plan recognition can infer the LOOK-AT action from the perceptionbased utterances [class B (9%)], but cannot yet connect LOOK-AT to IDENTIFY-REFERENT, because the means for performing IDENTIFY-REFERENT remains unspecified. Class C2 (preposed or interior prepositional phrases) requires a prosodic analysis to determine that a hearer response is called for and precisely what constituent is in question. With such an analysis, Perrault and Allen&apos;s fragment analysis can employ expectations to respond appropriately. Finally, Class E (&amp;quot;Let&apos;s&amp;quot; requests) is problematic for this theory (but see Grosz 1977). 7. Alternative Explanations Countered I have argued that to interpret indirect identification requests, the apprentice needs to reason about the expert&apos;s intent. Alternative explanations could be envisioned that would place the burden of noun phrase interpretation entirely on the hearer. According to such accounts, the hearer would act on a noun phrase as he pleased, independent of the speaker&apos;s intended use of that noun phrase. A succession of such explanations is countered below. 1. The hearer will identify the referent of every noun phrase. Clearly, for both definite and indefinite noun p</context>
</contexts>
<marker>Grosz, 1977</marker>
<rawString>Grosz, B.J. 1977 (July) The Representation and Use of Focus in Dialogue Understanding. Technical Report 151, Artificial Intelligence Center, SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Hayes</author>
<author>G V Mouradian</author>
</authors>
<title>Flexible Parsing.</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics</journal>
<volume>7</volume>
<issue>4</issue>
<pages>232--242</pages>
<contexts>
<context position="15863" citStr="Hayes and Mouradian 1981" startWordPosition="2350" endWordPosition="2353">e possibilities in all dimensions in which they are the same. This is obviously untrue for the dimension of interaction. 3 Thompson (1980) has confirmed Chapanis et al.&apos;s results for face-toface and keyboard modalities. Computational Linguistics Volume 10, Number 3-4, July-December 1984 99 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication linguistics. Not only are regularities in nongrammatical speech identified, but a class of &amp;quot;editing&amp;quot; rules is provided that can make such utterances parsable. Current work on relaxing grammar rules and on parsing ill-formed input (Hayes and Mouradian 1981, Kwasny and Sondheimer 1981, Weischedel and Black 1980) is in much the same spirit. The purposes at hand require analyses of the pragmatic and discourse structure of actual dialogues. Grosz (1977) and Bruce (1981) (among others) have shown how such discourse analyses can have direct implications for algorithm design. In their work, transcripts of dialogues were collected and analyzed, leading to the development of algorithms for speech-understanding systems (Walker 1978, Woods et al. 1976).4 Grosz&apos; analyses indicate that anaphoric reference in task-oriented dialogues is constrained by the hie</context>
</contexts>
<marker>Hayes, Mouradian, 1981</marker>
<rawString>Hayes, P.J. and Mouradian, G.V. 1981 Flexible Parsing. American Journal of Computational Linguistics 7(4): 232-242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Hindle</author>
</authors>
<title>Deterministic Parsing of Syntactic Non-fluencies.</title>
<date>1983</date>
<booktitle>Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>123--128</pages>
<location>Cambridge, Massachusetts,</location>
<contexts>
<context position="2145" citStr="Hindle 1983" startWordPosition="308" endWordPosition="309">f descriptions. 1 Introduction As natural language interaction with computers becomes more widespread, systems&apos; abilities to engage users in discourse will become increasingly important. These capabilities will be especially in demand when users can speak naturally to their machines. Although it is widely suspected that spoken language is different from written language, the question of precisely what the differences are has only recently become a topic of computational linguistic research. Previous investigations have concentrated on syntactic differences between spoken and written language (Hindle 1983, Kroch and Hindle 1982, Thompson 1980), with the goal of adapting parsing techniques to handle the syntax of spoken language. However, even if this goal were achieved, a system needs to be prepared to handle any unique properties of the discourse structure of spoken interaction if it is to be successful in conducting a dialogue. Of course, there has been much work on discourse processing within computational linguistics (e.g., Grosz 1977, Sidner 1979, Webber 1978), and any future systems will undoubtedly incorporate previously successful techniques. However, one suspects that the coverage Thi</context>
<context position="14785" citStr="Hindle 1983" startWordPosition="2193" endWordPosition="2194"> even though communicators use twice as many words when speaking.3 Although motivating the development of speech-understanding systems, these results unfortunately tell us little about how the processing of spoken utterances differs from the processing of written ones. Other research has compared the syntax of spoken and written discourse. The primary findings are: Written language is syntactically more integrated than spoken, employing nominalizations, participles, complements, relative clauses, etc. (Chafe 1982); and spoken language exhibits regular patterns of false starts and hesitations (Hindle 1983, Kroch and Hindle 1982). The former results can help a system designer to determine which syntactic constructs to emphasize in a grammar for parsing. The latter results are more useful to computational 2 This approach essentially characterizes language situations as multidimensional vectors whose components, describing the above dimensions, are binary values (e.g., +/- voice). Thus, it is assumed that neighboring modalities afford equal communicative possibilities in all dimensions in which they are the same. This is obviously untrue for the dimension of interaction. 3 Thompson (1980) has con</context>
</contexts>
<marker>Hindle, 1983</marker>
<rawString>Hindle, D. 1983 Deterministic Parsing of Syntactic Non-fluencies. Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics, Cambridge, Massachusetts, 123-128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hintikka</author>
</authors>
<title>Semantics for Propositional Attitudes. In</title>
<date>1969</date>
<booktitle>Davis, J.W. et al., Eds., Philosophical Logic. D. Reidel Publishing Co.,</booktitle>
<location>Dordrecht, Holland.</location>
<contexts>
<context position="28820" citStr="Hintikka 1969" startWordPosition="4368" endWordPosition="4369">isfying the antecedent) as the referent of D. His picking out the &amp;quot;right&amp;quot; (i.e., the intended) object is handled by a separate characterization of the speaker&apos;s intention with respect to this action (see section 7.5). Here, I will merely give a name to the state of knowledge the agent is in after having identified the referent of D — (IDENTIFIED-REFERENT Agt D X). That is, Agt has identified the referent of D to be X. Of course, what has been notoriously difficult to specify is just what Agt has to know about X to say he has identified it as the referent of D. Clearly, &amp;quot;knowing who the D is&amp;quot; (Hintikka 1969, Moore 1980) is no substitute for having identified a referent. After having picked out the referent of a description, we may still not not know who the D is. On the other hand, we may know who or what the description denotes, for example, by knowing some &amp;quot;standard name&amp;quot; for it, and yet be unable to use that knowledge to pick out the object. For example, if we ask &amp;quot;Which is the Seattle train?&amp;quot; and receive the reply &amp;quot;It&apos;s train number 11689&amp;quot;, we may still not be able to pick out and board the train if its serial number is not plainly in view. Clearly, the notion of identification needs to be m</context>
</contexts>
<marker>Hintikka, 1969</marker>
<rawString>Hintikka, J. 1969 Semantics for Propositional Attitudes. In Davis, J.W. et al., Eds., Philosophical Logic. D. Reidel Publishing Co., Dordrecht, Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Hoeppner</author>
<author>K Monk</author>
<author>H Marburger</author>
</authors>
<title>Talking It Over: The Natural Language Dialog System HAM-ANS.</title>
<date>1984</date>
<tech>Technical report ANS-26,</tech>
<institution>Research Unit for Information Science and Artificial Intelligence, University of Hamburg.</institution>
<marker>Hoeppner, Monk, Marburger, 1984</marker>
<rawString>Hoeppner, W.; Monk, K.; and Marburger, H. 1984 (May) Talking It Over: The Natural Language Dialog System HAM-ANS. Technical report ANS-26, Research Unit for Information Science and Artificial Intelligence, University of Hamburg.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M K Horrigan</author>
</authors>
<title>Modelling simple dialogues.</title>
<date>1977</date>
<tech>Technical Report 108,</tech>
<institution>Department of Computer Science, University of Toronto.</institution>
<contexts>
<context position="7448" citStr="Horrigan 1977" startWordPosition="1122" endWordPosition="1123">o infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in preparation; Sidner et al. 1981). Although these provide a more comprehensive account of indirect speech act interpretation than previous linguistic or philosophical approaches, they have not been tested against a corpus other than the ones that supported their creation (e.g., Horrigan 1977). Therefore, as an adequacy test, the fourth objective for this paper is: 4. To evaluate how well a plan-based theory of communication can uncover the intentions underlying the use of many surface forms in the transcripts. The theory is shown to account for approximately 70% of the indirect requests for referent identification found in the transcripts, once an action for referent identification has been posited. An important aspect of the account is the demonstration that speakers and hearers can reason about referent identification much as they reason about other actions and plans. Hence, the</context>
<context position="30160" citStr="Horrigan 1977" startWordPosition="4603" endWordPosition="4604">ended referent.9 Finally, although not stated in this definition, the means by which the act is performed is some function mapping D to some plan or procedure that, when executed by Agt, enables Agt to discover the X that is the referent of D. Even with this imprecise understanding of referent identification, it is apparent that not all noun phrases used in task-oriented conversations (even with the perceptual access conditions satisfied) are uttered with the intention that their referents be identified. For example, in dialogues with an information booth clerk in a train station (Allen 1979, Horrigan 1977), patrons uttering &amp;quot;the 3:15 to Montreal?&amp;quot; are not intending the clerk to pick out the train. Instead, as part of their plan for boarding a train, patrons are intending the clerk to supply them with a co-referring noun phrase that will allow them to identify the train. The attributive use of definite noun phrases (Donnellan 1960) is another case in which the speaker has no intention that the hearer identify a referent. Other non-anaphoric uses of noun phrases include labeling an object, correcting a referential miscommunication, getting the speaker to wait while the speaker identifies the refe</context>
</contexts>
<marker>Horrigan, 1977</marker>
<rawString>Horrigan, M.K. 1977 Modelling simple dialogues. Technical Report 108, Department of Computer Science, University of Toronto.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Krauss</author>
<author>S Weinheimer</author>
</authors>
<title>Concurrent Feedback, Confirmation, and the Encoding of Referents in Verbal Communication.</title>
<date>1966</date>
<journal>Journal of Personality and Social Psychology</journal>
<volume>4</volume>
<pages>343--346</pages>
<contexts>
<context position="20255" citStr="Krauss &amp; Weinheimer 1966" startWordPosition="3005" endWordPosition="3008">el of conversational interaction (Levin and Moore 1977), though it is not clear whether the model&apos;s formulation resulted from the merging of implementations. Finally, there is a huge literature of psychological studies of referential communication. I will not survey it here (but see Dickson 1981 for recent papers and Asher 1979 for an extensive review), but mention only two themes of relevance to this study. First, such work has shown that, in spoken interaction, noun phrase length tends to decrease as subsequent references to an object are made. However, in non-interactive spoken modalities (Krauss &amp; Weinheimer 1966), the decrease for subsequent references is lessened. These results indicate that efficiency in referential communication is a function of user feedback. The development of the component skills involved in referring is a second theme in this literature. In order to test Piaget&apos;s &amp;quot;egocentrism&amp;quot; hypotheses, a typical question asked is whether children take their listener&apos;s &amp;quot;perspective&amp;quot; into account when planning their referring expressions.6 Another question raised is whether children of certain ages can adequately make comparisons of the properties of referents and non-referents in order to for</context>
</contexts>
<marker>Krauss, Weinheimer, 1966</marker>
<rawString>Krauss, R.M. and Weinheimer, S. 1966 Concurrent Feedback, Confirmation, and the Encoding of Referents in Verbal Communication. Journal of Personality and Social Psychology 4: 343--346.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A S Kroch</author>
<author>D Hindle</author>
</authors>
<title>On the Linguistic Character of Non-standard Input.</title>
<date>1982</date>
<booktitle>Proceedings of the 20th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>161--163</pages>
<location>Toronto, Canada,</location>
<contexts>
<context position="2168" citStr="Kroch and Hindle 1982" startWordPosition="310" endWordPosition="313">s. 1 Introduction As natural language interaction with computers becomes more widespread, systems&apos; abilities to engage users in discourse will become increasingly important. These capabilities will be especially in demand when users can speak naturally to their machines. Although it is widely suspected that spoken language is different from written language, the question of precisely what the differences are has only recently become a topic of computational linguistic research. Previous investigations have concentrated on syntactic differences between spoken and written language (Hindle 1983, Kroch and Hindle 1982, Thompson 1980), with the goal of adapting parsing techniques to handle the syntax of spoken language. However, even if this goal were achieved, a system needs to be prepared to handle any unique properties of the discourse structure of spoken interaction if it is to be successful in conducting a dialogue. Of course, there has been much work on discourse processing within computational linguistics (e.g., Grosz 1977, Sidner 1979, Webber 1978), and any future systems will undoubtedly incorporate previously successful techniques. However, one suspects that the coverage This research was supporte</context>
<context position="14809" citStr="Kroch and Hindle 1982" startWordPosition="2195" endWordPosition="2198">communicators use twice as many words when speaking.3 Although motivating the development of speech-understanding systems, these results unfortunately tell us little about how the processing of spoken utterances differs from the processing of written ones. Other research has compared the syntax of spoken and written discourse. The primary findings are: Written language is syntactically more integrated than spoken, employing nominalizations, participles, complements, relative clauses, etc. (Chafe 1982); and spoken language exhibits regular patterns of false starts and hesitations (Hindle 1983, Kroch and Hindle 1982). The former results can help a system designer to determine which syntactic constructs to emphasize in a grammar for parsing. The latter results are more useful to computational 2 This approach essentially characterizes language situations as multidimensional vectors whose components, describing the above dimensions, are binary values (e.g., +/- voice). Thus, it is assumed that neighboring modalities afford equal communicative possibilities in all dimensions in which they are the same. This is obviously untrue for the dimension of interaction. 3 Thompson (1980) has confirmed Chapanis et al.&apos;s</context>
</contexts>
<marker>Kroch, Hindle, 1982</marker>
<rawString>Kroch, A.S. and Hindle, D. 1982 On the Linguistic Character of Non-standard Input. Proceedings of the 20th Annual Meeting of the Association for Computational Linguistics, Toronto, Canada, 161-163.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Kwasny</author>
<author>N K Sondheimer</author>
</authors>
<title>Relaxation Techniques for Parsing Ill-formed Input.</title>
<date>1981</date>
<journal>American Journal of Computational Linguistics</journal>
<volume>7</volume>
<issue>2</issue>
<pages>99--108</pages>
<contexts>
<context position="15891" citStr="Kwasny and Sondheimer 1981" startWordPosition="2354" endWordPosition="2357">ensions in which they are the same. This is obviously untrue for the dimension of interaction. 3 Thompson (1980) has confirmed Chapanis et al.&apos;s results for face-toface and keyboard modalities. Computational Linguistics Volume 10, Number 3-4, July-December 1984 99 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication linguistics. Not only are regularities in nongrammatical speech identified, but a class of &amp;quot;editing&amp;quot; rules is provided that can make such utterances parsable. Current work on relaxing grammar rules and on parsing ill-formed input (Hayes and Mouradian 1981, Kwasny and Sondheimer 1981, Weischedel and Black 1980) is in much the same spirit. The purposes at hand require analyses of the pragmatic and discourse structure of actual dialogues. Grosz (1977) and Bruce (1981) (among others) have shown how such discourse analyses can have direct implications for algorithm design. In their work, transcripts of dialogues were collected and analyzed, leading to the development of algorithms for speech-understanding systems (Walker 1978, Woods et al. 1976).4 Grosz&apos; analyses indicate that anaphoric reference in task-oriented dialogues is constrained by the hierarchical structure of the p</context>
</contexts>
<marker>Kwasny, Sondheimer, 1981</marker>
<rawString>Kwasny, S.C. and Sondheimer, N.K. 1981 Relaxation Techniques for Parsing Ill-formed Input. American Journal of Computational Linguistics 7(2): 99-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Labov</author>
<author>D Fanshel</author>
</authors>
<title>Therapeutic Discourse.</title>
<date>1977</date>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<contexts>
<context position="18052" citStr="Labov and Fanshel (1977)" startWordPosition="2676" endWordPosition="2679">s of his/her future utterances. Discourse analysis revealed that users did not follow the strict embedding of subdialogues required by the ATN model. Consequently, the pragmatics component was reorganized as a &amp;quot;demand&amp;quot; model in which the system was seen as responding to one of a set of pending goals. Although this research did not directly address issues of cross-modal similarities and differences, it did point out the promise of a goal-oriented view of language processing. Many researchers in the field of discourse analysis have tried to identify goals or intentions in dialogue. For example, Labov and Fanshel (1977) analyzed transcripts of therapy sessions by employing the vocabulary of linguistics and speech act theory. Their analyses presented rules for interpreting the intentions behind utterances of various syntactic forms — e.g., rules for when a hearer will interpret utterances as indirect requests for physical action or verbal confirmation. However, these rules were stipulated as regularities of discourse rather than as derived from underlying processes. Their findings should serve as data to be explained, rather than as a satisfying account of discourse. In research more relevant to computational</context>
</contexts>
<marker>Labov, Fanshel, 1977</marker>
<rawString>Labov, W. and Fanshel, D. 1977 Therapeutic Discourse. Academic Press, New York, 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Levin</author>
<author>J A Moore</author>
</authors>
<title>Dialogue Games: Metacommunication Structures for Natural Language Interaction.</title>
<date>1977</date>
<journal>Cognitive Science</journal>
<volume>1</volume>
<issue>4</issue>
<pages>395--420</pages>
<contexts>
<context position="19685" citStr="Levin and Moore 1977" startWordPosition="2916" endWordPosition="2919">, topic structure, etc., in keyboard dialogues between a user and a computer operator, and in radio dialogues between Apollo astronauts and ground control. Much care was taken to develop a scoring scheme, train dialogue observers, and attain reliability Mann, Carlisle, Moore, and Levin 1977). A separate computer program was to have been built for processing each transcript. By merging the common features of these systems, an empirically-based theory and computational model were to have been developed. This work resulted in a goal-directed, &amp;quot;dialogue games&amp;quot; model of conversational interaction (Levin and Moore 1977), though it is not clear whether the model&apos;s formulation resulted from the merging of implementations. Finally, there is a huge literature of psychological studies of referential communication. I will not survey it here (but see Dickson 1981 for recent papers and Asher 1979 for an extensive review), but mention only two themes of relevance to this study. First, such work has shown that, in spoken interaction, noun phrase length tends to decrease as subsequent references to an object are made. However, in non-interactive spoken modalities (Krauss &amp; Weinheimer 1966), the decrease for subsequent </context>
<context position="101283" citStr="Levin and Moore (1977)" startWordPosition="15834" endWordPosition="15837">pt for his role in the experiment. Scripts (Schank and Abelson 1977) contain expected sequences of actions, related in some &amp;quot;causal chain&amp;quot;, in some stereotyped situation. According to Schank and Abelson, typical scripted situations might include birthday parties, restaurants, classrooms, etc. Scripts are parameterized by &amp;quot;slots&amp;quot; that define &amp;quot;roles&amp;quot; in the various actions and events. Essentially, a script&apos;s participants perform the specified actions, which, having been a successful pattern of interaction in the past, are already structured to achieve the goal(s) of the script. &amp;quot;Dialogue Games&amp;quot; Levin and Moore (1977) can be seen as scripts once utterances are viewed as communicative acts. I claim that a script analysis of the discourses in the present experiment, if sufficiently detailed, supports the positions that (1) noun phrase interpretation requires an analysis of speaker intent, and (2) the speaker&apos;s intent is that the hearer perform an action of referent identification. The argument has three prongs: the contents of the purported script, the apprentice&apos;s inferring of that script, and the relationship of the script to the utterances. First, as Schank and Abelson have pointed out, scripts are frozen</context>
</contexts>
<marker>Levin, Moore, 1977</marker>
<rawString>Levin, J.A. and Moore, J.A. 1977 Dialogue Games: Metacommunication Structures for Natural Language Interaction. Cognitive Science 1(4): 395-420.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>J H Carlisle</author>
<author>J A Moore</author>
<author>J A Levin</author>
</authors>
<title>An Assessment of Reliability of Dialogue-annotation Instructions.</title>
<date>1977</date>
<tech>Technical Report ISI/RR-77-54,</tech>
<institution>Information Sciences Institute.</institution>
<marker>Mann, Carlisle, Moore, Levin, 1977</marker>
<rawString>Mann, W.C.; Carlisle, J.H.; Moore, J.A.; and Levin, J.A. 1977 (January) An Assessment of Reliability of Dialogue-annotation Instructions. Technical Report ISI/RR-77-54, Information Sciences Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Mann</author>
<author>J Moore</author>
<author>J Levin</author>
</authors>
<title>A Comprehension Model for Human Dialogue.</title>
<date>1977</date>
<booktitle>Proceedings of the Fifth International Joint Conference on Artificial Intelligence,</booktitle>
<location>Cambridge, Massachusetts.</location>
<marker>Mann, Moore, Levin, 1977</marker>
<rawString>Mann, W.; Moore, J.; and Levin, J. 1977 A Comprehension Model for Human Dialogue. Proceedings of the Fifth International Joint Conference on Artificial Intelligence, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R C Moore</author>
</authors>
<title>Reasoning about Knowledge and Action.</title>
<date>1980</date>
<booktitle>Technical Note 191, Artificial Intelligence Center, SRI International.</booktitle>
<contexts>
<context position="28833" citStr="Moore 1980" startWordPosition="4370" endWordPosition="4371">ecedent) as the referent of D. His picking out the &amp;quot;right&amp;quot; (i.e., the intended) object is handled by a separate characterization of the speaker&apos;s intention with respect to this action (see section 7.5). Here, I will merely give a name to the state of knowledge the agent is in after having identified the referent of D — (IDENTIFIED-REFERENT Agt D X). That is, Agt has identified the referent of D to be X. Of course, what has been notoriously difficult to specify is just what Agt has to know about X to say he has identified it as the referent of D. Clearly, &amp;quot;knowing who the D is&amp;quot; (Hintikka 1969, Moore 1980) is no substitute for having identified a referent. After having picked out the referent of a description, we may still not not know who the D is. On the other hand, we may know who or what the description denotes, for example, by knowing some &amp;quot;standard name&amp;quot; for it, and yet be unable to use that knowledge to pick out the object. For example, if we ask &amp;quot;Which is the Seattle train?&amp;quot; and receive the reply &amp;quot;It&apos;s train number 11689&amp;quot;, we may still not be able to pick out and board the train if its serial number is not plainly in view. Clearly, the notion of identification needs to be made relative </context>
</contexts>
<marker>Moore, 1980</marker>
<rawString>Moore, R.C. 1980 (October) Reasoning about Knowledge and Action. Technical Note 191, Artificial Intelligence Center, SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Morgan</author>
</authors>
<title>Two Types of Convention in Indirect Speech Acts.</title>
<date>1978</date>
<booktitle>In Cole, P., Ed., Syntax and Semantics, Volume 9: Pragmatics,</booktitle>
<pages>261--280</pages>
<publisher>Academic Press,</publisher>
<location>New York, New York,</location>
<marker>Morgan, 1978</marker>
<rawString>Morgan, J.L. 1978 Two Types of Convention in Indirect Speech Acts. In Cole, P., Ed., Syntax and Semantics, Volume 9: Pragmatics, Academic Press, New York, New York, 261-280.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ochs</author>
</authors>
<title>Planned and unplanned discourse.</title>
<date>1979</date>
<booktitle>In Givon, T., Ed., Syntax and Semantics, Volume 12: Discourse and Syntax,</booktitle>
<pages>51--80</pages>
<publisher>Academic Press,</publisher>
<location>New York, New York,</location>
<contexts>
<context position="64581" citStr="Ochs 1979" startWordPosition="10006" endWordPosition="10007">on requests. These requests do not simply occur after referential miscommunication (as they do in Keyboard), but are used to first introduce objects. The experts then often question the apprentices about successful completion of the identification act (just as they do assembly acts). Experts using keyboards do not attempt to achieve referential goals explicitly. Instead, referential goals are subsumed in assembly requests. Voice communication is thus &amp;quot;finer-grained&amp;quot; than keyboard communication. 5.3 Comparison with other studies These results are similar to observations by Ochs and colleagues (Ochs 1979; Ochs, Schieffelin, and Pratt 1979). Using evidence from transcripts, they point out that caretaker-child and child-child discourse often consists of &amp;quot;sequential&amp;quot; constructions — with separate utterances for securing reference and for predicating. Ochs et al. suggest that the presence of sequential Computational Linguistics Volume 10, Number 2, April-June 1984 109 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication Table 1. Distribution of requests (percent). Type of Request Telephone (n=288) Keyboard (n=134) Assembly 25 51 Orient 9 8 Other 15 13 Pick-up 16 17 Identi</context>
</contexts>
<marker>Ochs, 1979</marker>
<rawString>Ochs, E. 1979 Planned and unplanned discourse. In Givon, T., Ed., Syntax and Semantics, Volume 12: Discourse and Syntax, Academic Press, New York, New York, 51-80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Ochs</author>
<author>B B Schieffelin</author>
<author>M L Pratt</author>
</authors>
<title>Propositions Across Utterances and Speakers.</title>
<date>1979</date>
<booktitle>In Ochs, E., and Schieffelin, B. B., Eds., Developmental Pragmatics,</booktitle>
<publisher>Academic Press,</publisher>
<location>New York, New York.</location>
<marker>Ochs, Schieffelin, Pratt, 1979</marker>
<rawString>Ochs, E.; Schieffelin, B.B.; and Pratt, M.L. 1979 Propositions Across Utterances and Speakers. In Ochs, E., and Schieffelin, B. B., Eds., Developmental Pragmatics, Academic Press, New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Ortony</author>
</authors>
<title>Some Psycholinguistic Constraints on the Construction and Interpretation of Definite Descriptions.</title>
<date>1978</date>
<booktitle>Proceedings of the Second Conference on Theoretical Issues in Natural Language Processing,</booktitle>
<pages>73--78</pages>
<location>Urbana, Illinois,</location>
<contexts>
<context position="127683" citStr="Ortony (1978)" startWordPosition="20050" endWordPosition="20051">ed by this approach is to show how the same kind of plan-based reasoning used in analyzing indirect speech acts can take hold when a hearer realizes he cannot, and was not intended to, identify the referent of a description. That is, plan-based reasoning should explain how a hearer might decide that the speaker&apos;s intention cannot be what it appears to be (based on the intent correlated with the use of a definite determiner), leading him, for example, to decide to treat a description attributively (Donnellan 1960). Moreover, such reasoning should be useful in determining intended referents, as Ortony (1978) has argued. To cash in this promissory note, one needs to be specific about speaker intentions for other uses of noun phrases. This will be no easy task. One difficulty will be to capture the distinction between achieving effects on a hearer, and doing so communicatively (i.e., in the Gricean way). Thus, for example, a hearer cannot comply with the illocutionary act, &amp;quot;Quick, don&apos;t think of an elephant&amp;quot;, because there seems to be an &amp;quot;automatic&amp;quot; process of &amp;quot;concept activation&amp;quot; (Appelt 1981). Achieving effects noncommunicatively, without the recognition of intent, may be central to some kinds of</context>
</contexts>
<marker>Ortony, 1978</marker>
<rawString>Ortony, A. 1978 Some Psycholinguistic Constraints on the Construction and Interpretation of Definite Descriptions. Proceedings of the Second Conference on Theoretical Issues in Natural Language Processing, Urbana, Illinois, 73-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Perrault</author>
<author>J F Allen</author>
</authors>
<title>A Plan-based Analysis of Indirect Speech Acts.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics</journal>
<volume>6</volume>
<issue>3</issue>
<pages>167--182</pages>
<contexts>
<context position="6581" citStr="Perrault and Allen 1980" startWordPosition="987" endWordPosition="990">ts of noun phrases (NPs), but users of keyboards do not. Instead, the referential goals achieved by these requests are subsumed by other requested actions. Most importantly, these identification requests are only achieved &amp;quot;indirectly&amp;quot; — through utterances whose surface forms do not explicitly convey the speakers&apos; intent. Current theories propose that the speaker&apos;s intentions underlying the use of indirect speech acts can be recognized as a by-product of a more general, independently motivated process of inferring a speaker&apos;s plans (Bruce 1983, Cohen and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in preparation; Sidner et al</context>
<context position="75802" citStr="Perrault and Allen 1980" startWordPosition="11766" endWordPosition="11769">ojection&amp;quot;] 3. INFORM(EFFECT) 2% [&amp;quot; you will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a mapping of utterance forms to the &amp;quot;surface speech actions&amp;quot; speakers are performing in making those utterances. For the purposes of this paper, planning i</context>
<context position="77436" citStr="Perrault and Allen (1980)" startWordPosition="12034" endWordPosition="12037"> would enable him to do Z&amp;quot;, terminating in (what they take to be) a likely or expected goal of the agent (Allen 1979; Genesereth 1978; Schmidt, Sridharan, and Goodson 1979; Wilensky 1978). Such reasoning employs beliefs about the agent&apos;s beliefs, conditions that are likely to be true at the end of an action, other actions that are enabled by those conditions, and expected plans and goals of that agent. 112 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the M, odality of Communication 6.2 Analyzing indirect identification requests Perrault and Allen (1980) have proposed the following plan-recognition inferences: • Action-effect: If the observer thinks the agent wants to do an action, the observer can posit that the agent wants that action done in order to achieve its typical effect. • Precondition-action: If the agent is thought to want some proposition P to be true, and P is the precondition of an action known to the agent, consider that the agent&apos;s goal is to perform that action. • Body-action: If the agent is thought to have a goal that is the means by which a &amp;quot;higher level&amp;quot; action is performed, then consider that the agent is attempting to </context>
<context position="80395" citStr="Perrault and Allen 1980" startWordPosition="12510" endWordPosition="12513">r to the speaker. The essential insight of the theory is that indirect speech act recognition is a by-product of the general process of recognizing someone&apos;s plans. If illocutionary act identification occurs immediately after the expansion of a surface act, then a literal interpretation has been found. If there are intervening intended plan-recognition inferences, then an indirect interpretation has been inferred. 6.3 Example The following example is intended to give a brief introduction to the reasoning underlying indirection. Details of this process can be found in (Allen and Perrault 1980, Perrault and Allen 1980). The utterance to be interpreted is, &amp;quot;Can you reach the hammer?&amp;quot; The inferred propositions are indicated in boldface; commentary on the inference process is indented. After parsing and semantic interpretation, the utterance is represented as a surface speech act: HBSW (S-REQUEST(S,H,INFORMIF(H,S, CANDO(H,REACH(H,HAMMER))))) That is, the Hearer Believes the Speaker Wanted to perform (what appears to be) a yes-no question about his ability to reach the hammer. The effect of an S-REQUESTS to do action ACT is simply that the hearer believes the speaker wants the hearer to do ACT. Thus, applying t</context>
</contexts>
<marker>Perrault, Allen, 1980</marker>
<rawString>Perrault, C.R. and Allen, J.F. 1980 A Plan-based Analysis of Indirect Speech Acts. American Journal of Computational Linguistics 6(3): 167-182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C R Perrault</author>
<author>P R Cohen</author>
</authors>
<title>It&apos;s for Your Own Good: A Note on Inaccurate Reference. In</title>
<date>1981</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="27799" citStr="Perrault and Cohen 1981" startWordPosition="4186" endWordPosition="4189">arantee that the IDENTITY-REFERENT action is applicable. This should guarantee that, for example, a speaker does not intend someone to pick out the referent of &amp;quot;3&amp;quot;, &amp;quot;democracy&amp;quot;, or &amp;quot;the first man to land on Mars&amp;quot;. The condition is satisfied in the experimental task because it rapidly becomes mutual knowledge that the task requires communication about the objects in front of the hearer. The second condition states that X fulfills the description D. Here, I am ignoring cases in which the description is not literally true of the intended referent, including metonymy, irony, and the like (but see Perrault and Cohen 1981). Finally, D should be a description that is identifiable to this particular Agt. It should use descriptors whose extension the agent already knows or can discover by action. I am assuming that we can know that a combination of descriptors is identifiable without having formed a plan for identifying the referent. If the antecedent is true, then the agent picks out something (not necessarily the object satisfying the antecedent) as the referent of D. His picking out the &amp;quot;right&amp;quot; (i.e., the intended) object is handled by a separate characterization of the speaker&apos;s intention with respect to this </context>
</contexts>
<marker>Perrault, Cohen, 1981</marker>
<rawString>Perrault, C.R. and Cohen, P.R. 1981 It&apos;s for Your Own Good: A Note on Inaccurate Reference. In Joshi, A.; Sag, I.; and Webber, B., Eds., Elements of Discourse Understanding. Cambridge University Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Reichman</author>
</authors>
<title>Plain-speaking: A Theory and Grammar of Spontaneous Discourse.</title>
<date>1981</date>
<tech>Ph.D. Thesis,</tech>
<institution>Department of Computer Science, Harvard University,</institution>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="17012" citStr="Reichman 1981" startWordPosition="2522" endWordPosition="2523">ic reference in task-oriented dialogues is constrained by the hierarchical structure of the physical task. A parallel structuring of &amp;quot;focus spaces&amp;quot; was proposed as a mechanism to constrain the search for co-referents, and became the mainstay of the discourse component of two systems (Robinson et al. 1980, Walker 1978). Although this research did not directly address the problem of discovering cross-modal similarities and differences, the major finding of explicitly &amp;quot;stacked&amp;quot; topics serving to constrain co-reference was validated independently in a domain of casual, f ace-tof ace conversation (Reichman 1981). Bruce&apos;s pragmatics component for the HWIM system was based on transcripts of human keyboard-mediated dialogues simulating interactions with a travel budget manager. Users were seen to be interacting in various &amp;quot;modes&amp;quot; (e.g., editing-a-trip mode, creating-a-trip mode, etc.). The system attempted to track the user&apos;s progress through these modes, using an ATN-based representation, and thereby to create expectations of his/her future utterances. Discourse analysis revealed that users did not follow the strict embedding of subdialogues required by the ATN model. Consequently, the pragmatics compo</context>
</contexts>
<marker>Reichman, 1981</marker>
<rawString>Reichman, R. 1981 Plain-speaking: A Theory and Grammar of Spontaneous Discourse. Ph.D. Thesis, Department of Computer Science, Harvard University, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A E Robinson</author>
<author>D E Appelt</author>
<author>B J Grosz</author>
<author>G G Hendrix</author>
<author>J J Robinson</author>
</authors>
<date>1980</date>
<booktitle>Interpreting Natural-language Utterances in Dialogs about Tasks. Technical Note 210, Artificial Intelligence Center, SRI International.</booktitle>
<contexts>
<context position="9236" citStr="Robinson et al. 1980" startWordPosition="1398" endWordPosition="1401">equests. Because requests dominate interactions with many question-answering systems, and with most conceivable interactive applications of natural language processing, they have been extensively studied in computational linguistics. • Second, because the task is simple and constrained, it provides an excellent adequacy test for proposed theories and computational techniques; any theory of communication that cannot handle the phenomena of this study can hardly be called general. However, since the domain is functionally similar to those of various keyboard-based systems (Brachman et al. 1979, Robinson et al. 1980, Winograd 1972), the data and results of the study may suggest directions for extending those systems. • Third, the domain is similar to those analyzed by other researchers (Chapanis et al. 1972, Chapanis et al. 1977, Grosz 1977), and thus the dialogues could serve to confirm or refute their results. 98 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication • Finally, instructions play a crucially important role in people&apos;s everyday lives — success in industrial, academic, and bureaucratic tasks, for example</context>
<context position="16703" citStr="Robinson et al. 1980" startWordPosition="2477" endWordPosition="2480">g others) have shown how such discourse analyses can have direct implications for algorithm design. In their work, transcripts of dialogues were collected and analyzed, leading to the development of algorithms for speech-understanding systems (Walker 1978, Woods et al. 1976).4 Grosz&apos; analyses indicate that anaphoric reference in task-oriented dialogues is constrained by the hierarchical structure of the physical task. A parallel structuring of &amp;quot;focus spaces&amp;quot; was proposed as a mechanism to constrain the search for co-referents, and became the mainstay of the discourse component of two systems (Robinson et al. 1980, Walker 1978). Although this research did not directly address the problem of discovering cross-modal similarities and differences, the major finding of explicitly &amp;quot;stacked&amp;quot; topics serving to constrain co-reference was validated independently in a domain of casual, f ace-tof ace conversation (Reichman 1981). Bruce&apos;s pragmatics component for the HWIM system was based on transcripts of human keyboard-mediated dialogues simulating interactions with a travel budget manager. Users were seen to be interacting in various &amp;quot;modes&amp;quot; (e.g., editing-a-trip mode, creating-a-trip mode, etc.). The system att</context>
<context position="33622" citStr="Robinson et al. 1980" startWordPosition="5149" endWordPosition="5152">way as acts such as PICKUP, whose execution is marked specially so that the system can later answer &amp;quot;why&amp;quot; questions. Second, Allen&apos;s (1979) system used an IDENTIFY state in the control part of the plan-recognition mechanism. Again, for this system, identification meant to find something in the database satisfying the requisite predicates. However, the IDENTIFY action itself was not part of the plan being recognized. The system did not reason about when IDENTIFY should be done (it always tried to IDENTIFY referents), nor did it attribute IDENTIFY to be part of its user&apos;s plan. The TDUS system (Robinson et al. 1980) engaged in a dialogue about the assembly of an air compressor that, it was understood, was being assembled by an apprentice. Thus, the referents of the system&apos;s noun phrases were perceptually accessible to the hearer. The system was primarily oriented towards utterance interpretation, but it did generate responses to questions. In doing so, the system was in the same circumstances as the experts in the present study. However, because it was assumed that the extensions of all of the system&apos;s descriptors were already known to the hearer, the system did not reason that it should choose particula</context>
</contexts>
<marker>Robinson, Appelt, Grosz, Hendrix, Robinson, 1980</marker>
<rawString>Robinson, A.E.; Appelt, D.E.; Grosz, B.J.; Hendrix, G.G.; and Robinson, J.J. 1980 (March) Interpreting Natural-language Utterances in Dialogs about Tasks. Technical Note 210, Artificial Intelligence Center, SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A D Rubin</author>
</authors>
<title>A Theoretical Taxonomy of the Differences Between Oral and Written Language. In</title>
<date>1980</date>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="12369" citStr="Rubin (1980)" startWordPosition="1850" endWordPosition="1851">s studies of discourse that have been based on observation of actual communicative interaction. The subject of oral/written language comparisons has received much attention from researchers: Anthropologists have traditionally studied characteristics of &amp;quot;oral&amp;quot; and &amp;quot;literate&amp;quot; cultures; human-factors researchers have investigated the opportunities that particular modalities afford for effective communication; and educational psychologists, using empirical and anthropological methods, have sought answers to children&apos;s reading and writing problems in the study of oral/written language differences. Rubin (1980) discusses methodological weaknesses in many oral/written studies — weaknesses that stem from a simplistic division of language experiences into &amp;quot;oral&amp;quot; and &amp;quot;written&amp;quot;. Instead, she classifies language experiences in terms of their characteristic values on several dimensions such as: the use of voice or print, the ability of &amp;quot;speaker&amp;quot; and &amp;quot;hearer&amp;quot; to interact, their spatial and/or temporal commonality, their mutual involvement in the discourse, and the concreteness of the referents. Face-to-face conversations about physically present objects are seen to lie at one extreme within this &amp;quot;communicat</context>
<context position="37272" citStr="Rubin 1980" startWordPosition="5719" endWordPosition="5720">sz&apos;s (1977) and Chapanis et al.&apos;s (1972) task-oriented dialogue paradigm.12 Subjects were paid volunteer students from the University of Illinois, all of whom were familiar with CRT terminals. Five &amp;quot;dialogues&amp;quot; took place in each of the following modalities: face-to-face, by telephone, keyboard (&amp;quot;linked&amp;quot; CRTs), (noninteractive) audiotape, and (non-interactive) written. In all modes, the apprentices were videotaped as they followed the experts&apos; instructions. Face-to-face and written modalities are the ones usually compared in oral/written discussions. However, they differ along many dimensions (Rubin 1980). Pairwise comparisons of the modalities in this study can determine the effects of mutual vision, interaction, and the use of voice or print. Telephone and keyboard dialogues are analyzed first because our conclusions would indicate the effects of having a voice channel, and moreover would have implications for the design of speech understanding and production systems. These modalities take on intermediate values in Rubin&apos;s dimensional space: the conversants share the same time frame, can interact, cannot see each other, and are conversing about objects mutually known to be physically present</context>
</contexts>
<marker>Rubin, 1980</marker>
<rawString>Rubin, A.D. 1980 A Theoretical Taxonomy of the Differences Between Oral and Written Language. In Spiro, R.; Bruce, B.; and Brewer, W., Eds., Theoretical Issues in Reading Comprehension, Lawrence Erlbaum Assocs., Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Russell</author>
</authors>
<title>On denoting.</title>
<date>1905</date>
<journal>Mind</journal>
<volume>14</volume>
<pages>479--492</pages>
<marker>Russell, 1905</marker>
<rawString>Russell, B. 1905 On denoting. Mind 14: 479-492.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E D Sacerdoti</author>
</authors>
<title>A Structure for Plans and Behavior.</title>
<date>1975</date>
<booktitle>Technical Note 109, Artificial Intelligence Center, SRI International.</booktitle>
<contexts>
<context position="47544" citStr="Sacerdoti (1975)" startWordPosition="7381" endWordPosition="7382">communicator&apos;s intent in making various utterances. Following the experiences of Sinclair and Coulthard (1975), Dore et al. (1978), and Mann, Carlisle, Moore, and Levin (1977), a coding scheme was developed and two people were trained in its use. The coders relied on written transcripts, audiotapes, and on videotapes. The scheme, which was tested and revised on pilot data until reliability was attained, included a set of approximately eight illocutionary act categories that were used to label intent, and a set of &amp;quot;operators&amp;quot; and propositions that were used to describe the assembly task, as in Sacerdoti (1975). Appendix B lists the propositions and operators for the physical actions. For example, putting two hollow, pipe-like pieces together was termed Computational Linguistics Volume 10, Number 2, April-June 1984 105 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication CONNECTing; putting a part with a protrusion into a part with a hole was termed MESHing. The operators for physical actions often served as the propositional content of the communicative acts. The following illocutionary act categories were coded: Communicative Act Example Request(Assembly Action) &amp;quot;put that </context>
</contexts>
<marker>Sacerdoti, 1975</marker>
<rawString>Sacerdoti, E.D. 1975 (August) A Structure for Plans and Behavior. Technical Note 109, Artificial Intelligence Center, SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Schank</author>
<author>R Abelson</author>
</authors>
<title>Scripts, Plans, Goals, and Understanding. Lawrence Erlbaum Associates,</title>
<date>1977</date>
<location>Hillsdale, New Jersey.</location>
<contexts>
<context position="100214" citStr="Schank and Abelson 1977" startWordPosition="15668" endWordPosition="15671"> piece even though he could, because he has just requested the apprentice to do so, and because the expert&apos;s having a set of pieces was not mutually believed. The expert responds to (what he believes to be) the apprentice&apos;s purpose in repeating the NP, and not solely to his own desires and capabilities. According to the above argument, the hearer cannot be completely egocentric in his interpretation of noun phrases, but considers the speaker&apos;s intentions with respect to that noun phrase.28 One might still argue, however, that such consideration is quite simple; that a conversational &amp;quot;script&amp;quot; (Schank and Abelson 1977), involving the specification of the part the expert desires the apprentice to pick up and the assembly action to be performed on it, could handle the data. I argue that because the script notion of role already incorporates the expected goals of the parties who are playing each role, a script argument supports the position that noun phrase interpretation requires analysis of speaker intent. 4. The apprentice fits the noun phrase into the script for his role in the experiment. Scripts (Schank and Abelson 1977) contain expected sequences of actions, related in some &amp;quot;causal chain&amp;quot;, in some stere</context>
</contexts>
<marker>Schank, Abelson, 1977</marker>
<rawString>Schank, R. and Abelson, R. 1977 Scripts, Plans, Goals, and Understanding. Lawrence Erlbaum Associates, Hillsdale, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C F Schmidt</author>
</authors>
<title>Understanding Human Action.</title>
<date>1975</date>
<booktitle>Proceedings of Conference on Theoretical Issues in Natural Language Processing,</booktitle>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="6595" citStr="Schmidt 1975" startWordPosition="991" endWordPosition="992"> but users of keyboards do not. Instead, the referential goals achieved by these requests are subsumed by other requested actions. Most importantly, these identification requests are only achieved &amp;quot;indirectly&amp;quot; — through utterances whose surface forms do not explicitly convey the speakers&apos; intent. Current theories propose that the speaker&apos;s intentions underlying the use of indirect speech acts can be recognized as a by-product of a more general, independently motivated process of inferring a speaker&apos;s plans (Bruce 1983, Cohen and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in preparation; Sidner et al. 1981). Altho</context>
<context position="75816" citStr="Schmidt 1975" startWordPosition="11770" endWordPosition="11771">CT) 2% [&amp;quot; you will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a mapping of utterance forms to the &amp;quot;surface speech actions&amp;quot; speakers are performing in making those utterances. For the purposes of this paper, planning is simplistical</context>
</contexts>
<marker>Schmidt, 1975</marker>
<rawString>Schmidt, C.F. 1975 Understanding Human Action. Proceedings of Conference on Theoretical Issues in Natural Language Processing, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D F Schmidt</author>
<author>N S Sridharan</author>
<author>J L Goodson</author>
</authors>
<title>The Plan Recognition Problem:</title>
<date>1979</date>
<journal>An Intersection of Artificial Intelligence and Psychology. Artificial Intelligence</journal>
<volume>10</volume>
<pages>45--83</pages>
<marker>Schmidt, Sridharan, Goodson, 1979</marker>
<rawString>Schmidt, D.F.; Sridharan, N.S.; and Goodson, J.L. 1979 The Plan Recognition Problem: An Intersection of Artificial Intelligence and Psychology. Artificial Intelligence 10: 45-83.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Searle</author>
</authors>
<title>Speech Acts: An Essay in the Philosophy of Language.</title>
<date>1969</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="43484" citStr="Searle 1969" startWordPosition="6740" endWordPosition="6741">nversation progresses, one needs interpretations of what each speaker meant, stated in terms of further attributions of beliefs and intentions. Standard empirical methods should be used to minimize experimenter bias in making such attributions. In particular, the theorist must be careful not to be the source of belief/intent attributions, for if given the leeway, he will undoubtedly find what he is looking for. To avoid this problem, I trained two people to employ a vocabulary for describing intentions in discourse, the so-called &amp;quot;illocutionary acts&amp;quot; (or, loosely, &amp;quot;speech acts&amp;quot;) (Austin 1962, Searle 1969). That is, the discourse analysts &amp;quot;code&amp;quot; the speaker&apos;s intentions in making an utterance by assigning illocutionary act labels to utterances (or groups of them). Fortunately, the illocutionary act vocabulary is the natural one in our common-sense psychology for making such attributions. However, unlike most theories of illocutionary acts, I do not claim that the conversants themselves attempt to determine what illocutionary acts were performed, although they might be able to do so if requested.14 The illocutionary act interpretations are therefore our interpretations, as coders and as theorist</context>
<context position="108569" citStr="Searle (1969)" startWordPosition="16966" endWordPosition="16967"> a role in noun phrase interpretation, and that referent identification needs to be reasoned about in the same way as other acts. Essentially, the argument states that scripts are frozen plans, that apprentices inferred these plans, and that the plans indicated that the apprentice should perform actions of referent identification. The next section shows that the data in this experiment cause difficulty for Searle&apos;s analysis of referring. Furthermore, it shows that the present analysis can be extended to cover those cases of referring for which Searle&apos;s is applicable. 8 Referring as Requesting Searle (1969) has argued forcefully that referring is a speech act; that people refer, not just expressions. This section considers what kind of speech act referring might be. I propose a generalization of Searle&apos;s &amp;quot;propositional&amp;quot; act of referring that treats it as an illocutionary act, a request, and I argue that a special level of propositional acts for referring is unnecessary. The essence of the argument is as follows: First, I consider Searle&apos;s definition of the propositional act of referring (which I term the PAA, for Propositional Act Account). This definition is found to be inadequate to deal with </context>
<context position="111865" citStr="Searle 1969" startWordPosition="17504" endWordPosition="17505">ry act. 4. There exists some object X such that either R contains an identifying description of X or S is able to supplement R with an identifying description of X. 5. S intends that the utterance of R will pick out or identify X to H. 6. S intends that the utterance of R will identify X to H by means of H&apos;s recognition of S&apos;s intention to identify X, and he intends this recognition to be achieved by means of H&apos;s knowledge of the rules governing R and his awareness of C. 7. The semantical rules governing R are such that it is correctly uttered in T in C if and only if conditions 1-6 obtain.&amp;quot; (Searle 1969, pp. 94-95.) Conditions 2 and 3 are justified as follows: Propositional acts cannot occur alone; that is one cannot just [emphasis in original — PRC] refer and predicate without making an assertion or asking a question or performing some other illocutionary act.... One only refers as part of the performance of an illocutionary act, and the grammatical clothing of an illocutionary act is the complete sentence. An utterance of a referring expression only counts as referring if one says something. (Mid, p. 25.) The essence of Conditions 4 and 5 is that the speaker needs to utter an &amp;quot;identifying </context>
</contexts>
<marker>Searle, 1969</marker>
<rawString>Searle, J.R. 1969 Speech Acts: An Essay in the Philosophy of Language. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Shatz</author>
<author>R Gelman</author>
</authors>
<title>The Development of Communication Skills: Modifications in the Speech of Young Children as a Function of Listener. Monographs of the Society for Research in Child Development.</title>
<date>1973</date>
<contexts>
<context position="21413" citStr="Shatz and Gelman (1973)" startWordPosition="3175" endWordPosition="3178"> of the properties of referents and non-referents in order to formulate an adequate referring expression. This line of &apos;However, neither corpus incorporated true spoken interaction. The SRI dialogues that were analyzed in depth were taken from a mixed communication mode in which one, an &amp;quot;expert&amp;quot;, typed instructions to a third party, who spoke them to an &amp;quot;apprentice&amp;quot;, and typed the apprentice&apos;s spoken replies to the expert. The BBN &amp;quot;incremental simulation&amp;quot; dialogues involved only keyboard communication. &apos;Similar approaches include those of Dore et al. (1978), and Sinclair and Coulthard (1975). Shatz and Gelman (1973) showed they can do so (though not necessarily accurately (Asher 1979)) at a much earlier age than had been supposed. 100 Computational Linguistics Volume 10, Number 3-4, July-December 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication work is more relevant to the present concerns of characterizing the act of identification, but the subskills examined are still too coarse for our needs. Previous research has thus provided many lessons, among them: • the need to compare (at least initially) modalities that are minimally different, • the need for repeatable method</context>
</contexts>
<marker>Shatz, Gelman, 1973</marker>
<rawString>Shatz, M. and Gelman, R. 1973 The Development of Communication Skills: Modifications in the Speech of Young Children as a Function of Listener. Monographs of the Society for Research in Child Development.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse.</title>
<date>1979</date>
<tech>Technical Report 537,</tech>
<institution>Artificial Intelligence Laboratory, Massachusetts Institute of Technology.</institution>
<contexts>
<context position="2600" citStr="Sidner 1979" startWordPosition="383" endWordPosition="384">ic of computational linguistic research. Previous investigations have concentrated on syntactic differences between spoken and written language (Hindle 1983, Kroch and Hindle 1982, Thompson 1980), with the goal of adapting parsing techniques to handle the syntax of spoken language. However, even if this goal were achieved, a system needs to be prepared to handle any unique properties of the discourse structure of spoken interaction if it is to be successful in conducting a dialogue. Of course, there has been much work on discourse processing within computational linguistics (e.g., Grosz 1977, Sidner 1979, Webber 1978), and any future systems will undoubtedly incorporate previously successful techniques. However, one suspects that the coverage This research was supported primarily by the National Institute of Education under contract US-N1E-C-400-76-0116 to the Center for the Study of Reading of the University of Illinois and Bolt Beranek and Newman Inc., and in part by the Oregon State University. The paper was written at the Fairchild Camera and Instrument Corporation, and revised at SRI International. The revisions of this paper have been made possible by a gift from the System Development </context>
</contexts>
<marker>Sidner, 1979</marker>
<rawString>Sidner, C.L. 1979 (June) Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. Technical Report 537, Artificial Intelligence Laboratory, Massachusetts Institute of Technology.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C L Sidner</author>
</authors>
<title>The Pragmatics of Non-anaphoric Noun Phrases. In Research in Knowledge Representation for Natural Language Understanding:</title>
<date>1983</date>
<tech>Annual Report, 9/1/82-8/31/83,</tech>
<institution>Bolt Beranek and Newman Inc.,</institution>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="32218" citStr="Sidner (1983)" startWordPosition="4918" endWordPosition="4919">t, Winograd&apos;s SHRDLU (1972) attempted to simulate true reference with co-reference.11 SHRDLU had a PLANNER function, THFIND, that could find objects in the database satisfying THGOAL statements as a simulation of finding s Actually, Moore characterizes RESULT as taking an event and a formula as arguments. In his framework, an agent&apos;s doing an action denotes an event. However, this difference is not critical for what follows. 9 The connection with the contextually relevant actions is a matter of inference (see section 6). 1° For other discussion of speakers&apos; goals in uttering noun phrases (see Sidner (1983) and Wilkes-Gibbs, unpublished ms). &amp;quot; On the other hand, one might argue that SHRDLU engaged in true reference because the discourse was about non-existing blocks &amp;quot;contained&amp;quot; within the system. To pursue the truth of the matter would take us too far afield. 102 Computational Linguistics Volume 10, Number 2, April-June 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication blocks in the real world. THFIND was included in the semantic representation of definite NPs, and in the representation of indefinite NPs when those NPs were embedded in an action verb. However, TH</context>
</contexts>
<marker>Sidner, 1983</marker>
<rawString>Sidner, C.L. 1983 The Pragmatics of Non-anaphoric Noun Phrases. In Research in Knowledge Representation for Natural Language Understanding: Annual Report, 9/1/82-8/31/83, Bolt Beranek and Newman Inc., Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>CL Sidner</author>
<author>M Bates</author>
<author>R J Bobrow</author>
<author>R J Brachman</author>
<author>P R Cohen</author>
<author>D J Israel</author>
<author>B L Webber</author>
<author>W A Woods</author>
</authors>
<title>Research in Knowledge Representation for Natural Language Understanding.</title>
<date>1981</date>
<tech>Annual Report 4785,</tech>
<institution>Bolt, Beranek and Newman Inc.</institution>
<contexts>
<context position="7188" citStr="Sidner et al. 1981" startWordPosition="1082" endWordPosition="1085">d Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in preparation; Sidner et al. 1981). Although these provide a more comprehensive account of indirect speech act interpretation than previous linguistic or philosophical approaches, they have not been tested against a corpus other than the ones that supported their creation (e.g., Horrigan 1977). Therefore, as an adequacy test, the fourth objective for this paper is: 4. To evaluate how well a plan-based theory of communication can uncover the intentions underlying the use of many surface forms in the transcripts. The theory is shown to account for approximately 70% of the indirect requests for referent identification found in th</context>
</contexts>
<marker>Sidner, Bates, Bobrow, Brachman, Cohen, Israel, Webber, Woods, 1981</marker>
<rawString>Sidner, CL., Bates, M.; Bobrow, R.J.; Brachman, R.J.; Cohen, P.R.; Israel, D.J.; Webber, B.L.; and Woods, W.A. 1981 (November) Research in Knowledge Representation for Natural Language Understanding. Annual Report 4785, Bolt, Beranek and Newman Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Sidner</author>
<author>D Israel</author>
</authors>
<title>Recognizing Intended Meaning and Speaker &apos;s Plans.</title>
<date>1981</date>
<booktitle>Proceedings of the Seventh International Joint Conference on Artificial Intelligence,</booktitle>
<location>Vancouver, B. C.</location>
<contexts>
<context position="6620" citStr="Sidner and Israel 1981" startWordPosition="993" endWordPosition="996">keyboards do not. Instead, the referential goals achieved by these requests are subsumed by other requested actions. Most importantly, these identification requests are only achieved &amp;quot;indirectly&amp;quot; — through utterances whose surface forms do not explicitly convey the speakers&apos; intent. Current theories propose that the speaker&apos;s intentions underlying the use of indirect speech acts can be recognized as a by-product of a more general, independently motivated process of inferring a speaker&apos;s plans (Bruce 1983, Cohen and Perrault 1979, Cohen and Levesque 1980, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981). Essentially, illocutionary acts, which communicate the speaker&apos;s intentions, are regarded as steps in a speaker&apos;s plan, just as physical acts are. Furthermore, just as observing an agent&apos;s behavior may lead one to infer what the agent is trying to do, so too can the observation/understanding of a speaker&apos;s utterance lead an observer to infer the speaker&apos;s intentions. This approach has led to formal and computational models of discourse processing (Allen 1979; Allen and Perrault 1980; Brachman et al. 1979; Cohen and Levesque, in preparation; Sidner et al. 1981). Although these provide a more </context>
<context position="75841" citStr="Sidner and Israel 1981" startWordPosition="11772" endWordPosition="11775">will see two blue tubes&amp;quot;] C. FRAGMENTS 1. NP AND PP FRAGMENTS (?) 12% [&amp;quot;The smallest of the red pieces?&amp;quot;] 2. PREPOSED OR INTERIOR PP (?) 6% rand in the bottom of the blue cap on the main tube (pause) there is a hole&amp;quot;] D. NEARLY DIRECT REQUESTS [&amp;quot;Look at the bottom of the tube&amp;quot;] 1% [&amp;quot;The next thing you&apos;re gonna look for is....&amp;quot; 1% E. LET&apos;S REQUESTS [&amp;quot;Let&apos;s go to the little tiny blue cap&amp;quot;] 5% Recent work of this type (Allen 1979, Appelt 1981, Bruce 1983, Bruce and Newman 1978, Bruce and Schmidt, Cohen 1978, Cohen and Levesque 1980, Cohen and Perrault 1979, Perrault and Allen 1980, Schmidt 1975, Sidner and Israel 1981) has resulted in formal and computational models of communication that have been applied in analyzing dialogues about tasks and stories. The general features of the models include: a simple theory of action, definitions of various physical and communicative actions, a set of inference rules for formulating and recognizing plans of action, a formalization of agents&apos; beliefs, goals, and expectations, and a mapping of utterance forms to the &amp;quot;surface speech actions&amp;quot; speakers are performing in making those utterances. For the purposes of this paper, planning is simplistically viewed as the process </context>
</contexts>
<marker>Sidner, Israel, 1981</marker>
<rawString>Sidner, C. and Israel, D. 1981 Recognizing Intended Meaning and Speaker &apos;s Plans. Proceedings of the Seventh International Joint Conference on Artificial Intelligence, Vancouver, B. C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Coulthard</author>
</authors>
<title>Towards an Analysis of Discourse: The English Used by Teachers and Pupils.</title>
<date>1975</date>
<publisher>Oxford University Press,</publisher>
<location>London.</location>
<contexts>
<context position="21388" citStr="Coulthard (1975)" startWordPosition="3173" endWordPosition="3174">y make comparisons of the properties of referents and non-referents in order to formulate an adequate referring expression. This line of &apos;However, neither corpus incorporated true spoken interaction. The SRI dialogues that were analyzed in depth were taken from a mixed communication mode in which one, an &amp;quot;expert&amp;quot;, typed instructions to a third party, who spoke them to an &amp;quot;apprentice&amp;quot;, and typed the apprentice&apos;s spoken replies to the expert. The BBN &amp;quot;incremental simulation&amp;quot; dialogues involved only keyboard communication. &apos;Similar approaches include those of Dore et al. (1978), and Sinclair and Coulthard (1975). Shatz and Gelman (1973) showed they can do so (though not necessarily accurately (Asher 1979)) at a much earlier age than had been supposed. 100 Computational Linguistics Volume 10, Number 3-4, July-December 1984 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication work is more relevant to the present concerns of characterizing the act of identification, but the subskills examined are still too coarse for our needs. Previous research has thus provided many lessons, among them: • the need to compare (at least initially) modalities that are minimally different, • the n</context>
<context position="47038" citStr="Coulthard (1975)" startWordPosition="7295" endWordPosition="7297"> characterize those IA types in terms of plans. • Formally derive the IA codings as a rational strategy of action, given attributions of the participants&apos; beliefs, goals, and expectations at the point in the discourse in which the IAs occurred. When our work is complete, we will have analyses of the differences in achievement of the same overarching set of goals (the assembly task) as a function of modality. 4.2.1 Coding the transcripts The first stage of discourse analysis involves the coding of the communicator&apos;s intent in making various utterances. Following the experiences of Sinclair and Coulthard (1975), Dore et al. (1978), and Mann, Carlisle, Moore, and Levin (1977), a coding scheme was developed and two people were trained in its use. The coders relied on written transcripts, audiotapes, and on videotapes. The scheme, which was tested and revised on pilot data until reliability was attained, included a set of approximately eight illocutionary act categories that were used to label intent, and a set of &amp;quot;operators&amp;quot; and propositions that were used to describe the assembly task, as in Sacerdoti (1975). Appendix B lists the propositions and operators for the physical actions. For example, putti</context>
</contexts>
<marker>Coulthard, 1975</marker>
<rawString>Sinclair, J.McH. and Coulthard, R.M. 1975 Towards an Analysis of Discourse: The English Used by Teachers and Pupils. Oxford University Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F C Stoll</author>
<author>D G Hoecker</author>
<author>G P Krueger</author>
<author>A Chapanis</author>
</authors>
<title>The Effects of Four Communication Modes on the Structure of Language Used During Cooperative Problem Solving.</title>
<date>1976</date>
<journal>The Journal of Psychology</journal>
<volume>94</volume>
<issue>1</issue>
<pages>13--26</pages>
<marker>Stoll, Hoecker, Krueger, Chapanis, 1976</marker>
<rawString>Stoll, F.C.; Hoecker, D.G.; Krueger, G.P.; and Chapanis, A. 1976 The Effects of Four Communication Modes on the Structure of Language Used During Cooperative Problem Solving. The Journal of Psychology 94(1): 13-26.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Thompson</author>
</authors>
<title>Linguistic Analysis of Natural Language Communication with Computers.</title>
<date>1980</date>
<booktitle>Proceedings of COLING-80,</booktitle>
<location>Tokyo,</location>
<contexts>
<context position="2184" citStr="Thompson 1980" startWordPosition="314" endWordPosition="315">tural language interaction with computers becomes more widespread, systems&apos; abilities to engage users in discourse will become increasingly important. These capabilities will be especially in demand when users can speak naturally to their machines. Although it is widely suspected that spoken language is different from written language, the question of precisely what the differences are has only recently become a topic of computational linguistic research. Previous investigations have concentrated on syntactic differences between spoken and written language (Hindle 1983, Kroch and Hindle 1982, Thompson 1980), with the goal of adapting parsing techniques to handle the syntax of spoken language. However, even if this goal were achieved, a system needs to be prepared to handle any unique properties of the discourse structure of spoken interaction if it is to be successful in conducting a dialogue. Of course, there has been much work on discourse processing within computational linguistics (e.g., Grosz 1977, Sidner 1979, Webber 1978), and any future systems will undoubtedly incorporate previously successful techniques. However, one suspects that the coverage This research was supported primarily by t</context>
<context position="15377" citStr="Thompson (1980)" startWordPosition="2281" endWordPosition="2282">esitations (Hindle 1983, Kroch and Hindle 1982). The former results can help a system designer to determine which syntactic constructs to emphasize in a grammar for parsing. The latter results are more useful to computational 2 This approach essentially characterizes language situations as multidimensional vectors whose components, describing the above dimensions, are binary values (e.g., +/- voice). Thus, it is assumed that neighboring modalities afford equal communicative possibilities in all dimensions in which they are the same. This is obviously untrue for the dimension of interaction. 3 Thompson (1980) has confirmed Chapanis et al.&apos;s results for face-toface and keyboard modalities. Computational Linguistics Volume 10, Number 3-4, July-December 1984 99 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication linguistics. Not only are regularities in nongrammatical speech identified, but a class of &amp;quot;editing&amp;quot; rules is provided that can make such utterances parsable. Current work on relaxing grammar rules and on parsing ill-formed input (Hayes and Mouradian 1981, Kwasny and Sondheimer 1981, Weischedel and Black 1980) is in much the same spirit. The purposes at hand require </context>
</contexts>
<marker>Thompson, 1980</marker>
<rawString>Thompson, B. 1980 Linguistic Analysis of Natural Language Communication with Computers. Proceedings of COLING-80, Tokyo, 190-201.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R J Tierney</author>
<author>J LaZansky</author>
<author>T Raphael</author>
<author>P R Cohen</author>
</authors>
<title>Author&apos;s Intentions and Readers&apos; Interpretations. In</title>
<date>1983</date>
<location>Hillsdale, N. J.,</location>
<contexts>
<context position="65771" citStr="Tierney et al. 1983" startWordPosition="10181" endWordPosition="10184">her 15 13 Pick-up 16 17 Identification 35 10 constructions is tied to the possibility for preplanning an utterance. Relatively unplanned discourse, it is claimed, relies on the pragmatic context to express propositions, where planned discourse would use syntactic means. Unplanned discourse results when speakers are concentrating on a task or when the expression of a concept is particularly difficult. The present study upholds Och et al.&apos;s claim for Telephone and Keyboard communication, but does not do so for the Written condition, in which many identification requests occur as separate steps (Tierney et al. 1983). Furthermore, Ochs et al.&apos;s claim does not account for the use of identification requests in Keyboard modality after prior referential miscommunication (see section 4.1 for a sample conversation), indicating that sequential constructions can result from (what they term) planned as well as unplanned discourse. Clark and Wilkes-Gibbs (unpublished) analyze referential communication data similar to ours. Their concern is to show that referring is a collaborative process, one that proceeds by a speaker&apos;s proposing a referring expression, and a hearer&apos;s accepting or rejecting it as adequate for ide</context>
<context position="72959" citStr="Tierney et al. 1983" startWordPosition="11291" endWordPosition="11294">the other large tube, with the round top&amp;quot;), was unreliably coded and not considered for the analyses below. Category labels followed by &amp;quot;(?)&amp;quot; indicate that the utterances comprising those categories might also have been issued with rising intonation. Typically, such utterances were coded as questions and also as requests for identification. The important thing to notice in Table 3 is that in Telephone mode identification requests were almost never performed directly. No speaker used direct forms, e.g., &amp;quot;Find the rubber ring shaped like an 0&amp;quot;, which occurred frequently in the Written modality (Tierney et al. 1983). However, the use of indirection is selective — Telephone experts frequently use direct imperatives to perform assembly requests. Moreover, many speakers adopted a consistent style. For example, all the &amp;quot;nearly direct requests&amp;quot; came from one speaker, and another almost uniformly used the &amp;quot;there&apos;s a NP&amp;quot; strategy. Because explicit identification requests come in many syntactic forms, each of which has a literal interpretation that is not an identification request, the hearer needs some method for deciding what the speaker&apos;s intention(s) are. Ideally, such reasoning should be an application of m</context>
<context position="105060" citStr="Tierney et al. 1983" startWordPosition="16430" endWordPosition="16433">stics Volume 10, Number 2, April-June 1984 117 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication applied to utterance interpretation. Thus, the inferring of a script that contains the expert&apos;s intent that the hearer identify the referents of descriptions is consistent with my proposal. Although much of the determination of speaker intent has been precomputed, the utterance itself cannot be ignored. The results of this study show that speakers in the Telephone condition do not achieve their referential goals with direct requests, as they do in the Written condition (Tierney et al. 1983). The analysis of indirection used here (and similarly advocated by most speech act theorists) requires that speaker intent be recognized as a function, in part, of utterance form. Possible specifications of illocutionary force are derived from features of the utterance. Indirect speech acts are recognized through a chain of intended plan-recognition inferences (based on mutual beliefs) deriving subsequent intended inferences that, if confirmed by mutually expected goals, communicate speaker intent. One might still argue that the reasoning involved in processing these indirect speech acts has </context>
</contexts>
<marker>Tierney, LaZansky, Raphael, Cohen, 1983</marker>
<rawString>Tierney, R.J.; LaZansky, J.; Raphael, T.; and Cohen, P.R. 1983 Author&apos;s Intentions and Readers&apos; Interpretations. In Tierney, R.J.; Anders, P.; and Mitchell, J.N.; Eds.; Understanding Readers&apos; Understandings. Lawrence Erlbaum Assoc., Hillsdale, N. J., 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Walker</author>
<author>Ed</author>
</authors>
<title>Understanding Spoken Language.</title>
<date>1978</date>
<publisher>Elsevier NorthHolland,</publisher>
<location>New York New York.</location>
<marker>Walker, Ed, 1978</marker>
<rawString>Walker, D., Ed. 1978 Understanding Spoken Language. Elsevier NorthHolland, New York New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B L Webber</author>
</authors>
<title>A Formal Approach to Discourse Anaphora.</title>
<date>1978</date>
<tech>BBN Report 3761,</tech>
<institution>Bolt Beranek and Newman Inc.</institution>
<contexts>
<context position="2614" citStr="Webber 1978" startWordPosition="385" endWordPosition="386">tional linguistic research. Previous investigations have concentrated on syntactic differences between spoken and written language (Hindle 1983, Kroch and Hindle 1982, Thompson 1980), with the goal of adapting parsing techniques to handle the syntax of spoken language. However, even if this goal were achieved, a system needs to be prepared to handle any unique properties of the discourse structure of spoken interaction if it is to be successful in conducting a dialogue. Of course, there has been much work on discourse processing within computational linguistics (e.g., Grosz 1977, Sidner 1979, Webber 1978), and any future systems will undoubtedly incorporate previously successful techniques. However, one suspects that the coverage This research was supported primarily by the National Institute of Education under contract US-N1E-C-400-76-0116 to the Center for the Study of Reading of the University of Illinois and Bolt Beranek and Newman Inc., and in part by the Oregon State University. The paper was written at the Fairchild Camera and Instrument Corporation, and revised at SRI International. The revisions of this paper have been made possible by a gift from the System Development Foundation to </context>
</contexts>
<marker>Webber, 1978</marker>
<rawString>Webber, B.L. 1978 (May) A Formal Approach to Discourse Anaphora. BBN Report 3761, Bolt Beranek and Newman Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Weischedel</author>
<author>J E Black</author>
</authors>
<title>Responding Intelligently to Unparsable Inputs.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics</journal>
<volume>6</volume>
<issue>3</issue>
<pages>97--109</pages>
<contexts>
<context position="15919" citStr="Weischedel and Black 1980" startWordPosition="2358" endWordPosition="2361">e same. This is obviously untrue for the dimension of interaction. 3 Thompson (1980) has confirmed Chapanis et al.&apos;s results for face-toface and keyboard modalities. Computational Linguistics Volume 10, Number 3-4, July-December 1984 99 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication linguistics. Not only are regularities in nongrammatical speech identified, but a class of &amp;quot;editing&amp;quot; rules is provided that can make such utterances parsable. Current work on relaxing grammar rules and on parsing ill-formed input (Hayes and Mouradian 1981, Kwasny and Sondheimer 1981, Weischedel and Black 1980) is in much the same spirit. The purposes at hand require analyses of the pragmatic and discourse structure of actual dialogues. Grosz (1977) and Bruce (1981) (among others) have shown how such discourse analyses can have direct implications for algorithm design. In their work, transcripts of dialogues were collected and analyzed, leading to the development of algorithms for speech-understanding systems (Walker 1978, Woods et al. 1976).4 Grosz&apos; analyses indicate that anaphoric reference in task-oriented dialogues is constrained by the hierarchical structure of the physical task. A parallel str</context>
</contexts>
<marker>Weischedel, Black, 1980</marker>
<rawString>Weischedel, R.M. and Black, J.E. 1980 Responding Intelligently to Unparsable Inputs. American Journal of Computational Linguistics 6(3): 97-109. 2: Mm-hm.</rawString>
</citation>
<citation valid="false">
<title>1: All right. Has a—uh, I mean, [unintelligible] has a funny projection at the other end, it&apos;s like notched.</title>
<tech>2: Mm-hm.</tech>
<marker></marker>
<rawString>1: All right. Has a—uh, I mean, [unintelligible] has a funny projection at the other end, it&apos;s like notched. 2: Mm-hm.</rawString>
</citation>
<citation valid="false">
<title>1: -and this um cylinder-like thing, if you look at the bottom has a hole in it2:</title>
<publisher>Mm-hm.</publisher>
<marker></marker>
<rawString>1: -and this um cylinder-like thing, if you look at the bottom has a hole in it2: Mm-hm.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Then</author>
</authors>
<title>if you&apos;ll pick up the tube— it&apos;s kind of a purple color? 2: Yes. A: —a blue cap on the top.</title>
<location>J: Yes, right.</location>
<marker>Then, </marker>
<rawString>1: Then, if you&apos;ll pick up the tube— it&apos;s kind of a purple color? 2: Yes. A: —a blue cap on the top. J: Yes, right.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Okay</author>
</authors>
<title>you&apos;ve got this blue cap on the bottom. It&apos;s got a peg in it. J: Right. Small red peg with four little red things comin&apos; off it.</title>
<marker>Okay, </marker>
<rawString>A: Okay, you&apos;ve got this blue cap on the bottom. It&apos;s got a peg in it. J: Right. Small red peg with four little red things comin&apos; off it.</rawString>
</citation>
<citation valid="false">
<authors>
<author>B Class</author>
</authors>
<title>Perception-Based S: Okay. First I want you to uh— do you see small—three small red pieces?</title>
<journal>J: Y-yes.</journal>
<marker>Class, </marker>
<rawString>Class B: Perception-Based S: Okay. First I want you to uh— do you see small—three small red pieces? J: Y-yes.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Do</author>
</authors>
<title>you see a little ring, a little black rubber ring?</title>
<location>J: Yeah.</location>
<marker>Do, </marker>
<rawString>S: Do you see a little ring, a little black rubber ring? J: Yeah.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S Now</author>
</authors>
<title>Do you see a little pink plastic piece?</title>
<location>J: Yeah, yeah.</location>
<marker>Now, </marker>
<rawString>S: Now. Do you see a little pink plastic piece? J: Yeah, yeah.</rawString>
</citation>
<citation valid="false">
<booktitle>Computational Linguistics Volume 10, Number 2, April-June 1984 131 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication</booktitle>
<marker></marker>
<rawString>Computational Linguistics Volume 10, Number 2, April-June 1984 131 Philip R. Cohen The Pragmatics of Referring and the Modality of Communication</rawString>
</citation>
<citation valid="false">
<authors>
<author>S</author>
</authors>
<title>stick it on the en— onto the uh spout coming out the side. You see that?</title>
<marker>S, </marker>
<rawString>S: And stick it on the en— onto the uh spout coming out the side. You see that?</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Yeah</author>
</authors>
<title>1: You see a hole? 2: Uh-huh.</title>
<marker>Yeah, </marker>
<rawString>J: Yeah, 1: You see a hole? 2: Uh-huh.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Um</author>
</authors>
<title>you will see in front of you a bunch of um pieces of plastic.</title>
<marker>Um, </marker>
<rawString>1: Um, you will see in front of you a bunch of um pieces of plastic.</rawString>
</citation>
<citation valid="false">
<title>1: All right. And then you&apos;ll see the blue cap begins to come down over the tube.</title>
<marker></marker>
<rawString>1: All right. And then you&apos;ll see the blue cap begins to come down over the tube.</rawString>
</citation>
<citation valid="false">
<title>1: If you&apos;ll look at the bottom, you will see a projection in that cap. 2: Yeah. 1: and you see the two projections? 2: Mm-hmm 2: You&apos;ll see three very small red pieces of plastic.</title>
<marker></marker>
<rawString>1: If you&apos;ll look at the bottom, you will see a projection in that cap. 2: Yeah. 1: and you see the two projections? 2: Mm-hmm 2: You&apos;ll see three very small red pieces of plastic.</rawString>
</citation>
<citation valid="false">
<authors>
<author>S</author>
</authors>
<title>You have the blue cap on the upper hole.</title>
<marker>S, </marker>
<rawString>Class C: Fragments J: Mm-hm. S: You have the blue cap on the upper hole.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Mm-hm</author>
</authors>
<title>S: And you have the big blue cap with the ring and the little plastic thing screwed onto the bottom.</title>
<marker>Mm-hm, </marker>
<rawString>J: Mm-hm. S: And you have the big blue cap with the ring and the little plastic thing screwed onto the bottom.</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Yeah</author>
</authors>
<publisher>S: Okay. Now.</publisher>
<marker>Yeah, </marker>
<rawString>J: Yeah. S: Okay. Now.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I Urn</author>
</authors>
<title>want you to take the urn— okay, take uh the —now you have two red pieces remaining,</title>
<pages>right?</pages>
<marker>Urn, </marker>
<rawString>Urn I want you to take the urn— okay, take uh the —now you have two red pieces remaining, right?</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Yeah</author>
</authors>
<title>S: Take the spout— the little one that looks like the end of an oil can—</title>
<marker>Yeah, </marker>
<rawString>J: Yeah. S: Take the spout— the little one that looks like the end of an oil can—</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>