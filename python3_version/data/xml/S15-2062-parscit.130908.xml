<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.063786">
<title confidence="0.9943555">
SUDOKU: Treating Word Sense Disambiguation &amp; Entity Linking as a
Deterministic Problem – via an Unsupervised &amp; Iterative Approach
</title>
<author confidence="0.997594">
Steve L. Manion
</author>
<affiliation confidence="0.999954">
University of Canterbury, Christchurch, New Zealand
</affiliation>
<email confidence="0.990314">
steve.manion @pg.canterbury.ac.nz
</email>
<sectionHeader confidence="0.99554" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.996970826086957">
SUDOKU’s submissions to SemEval Task 13
treats Word Sense Disambiguation and Entity
Linking as a deterministic problem that ex-
ploits two key attributes of open-class words
as constraints – their degree of polysemy and
their part of speech. This is an extension and
further validation of the results achieved by
Manion and Sainudiin (2014). SUDOKU’s
three submissions are incremental in the use
of the two aforementioned constraints. Run1
has no constraints and disambiguates all lem-
mas in one pass. Run2 disambiguates lemmas
at increasing degrees of polysemy, leaving the
most polysemous until last. Run3 is identical
to Run2, with the additional constraint of dis-
ambiguating all named entities and nouns first
before other types of open-class words (verbs,
adjectives, and adverbs). Over all-domains,
for English Run2 and Run3 were placed sec-
ond and third. For Spanish Run2, Run3, and
Run1 were placed first, second, and third re-
spectively. For Italian Run1 was placed first
with Run2 and Run3 placed second equal.
</bodyText>
<sectionHeader confidence="0.996088" genericHeader="introduction">
1 Introduction &amp; Related Work
</sectionHeader>
<bodyText confidence="0.999931947368421">
Almost a decade ago, Agirre and Edmonds (2007)
suggested the promising potential for WSD that
could exploit the interdependencies between senses
in an interactive manner. In other words, this would
be a WSD system which allows the disambiguation
of word a to directly influence the consecutive dis-
ambiguation of word b. This is analogous to treating
WSD as a deterministic problem, much like the Su-
doku puzzle in which the final solution is reached by
adhering to a set of pre-determined constraints. Con-
ventional approaches to WSD often overlook the po-
tential to exploit sense interdependencies, and sim-
ply disambiguate all senses in one pass based on a
context window (e.g. a sentence or document). For
this task the author proposes an iterative approach
which makes several passes based on a set of con-
straints. For a more formal distinction between the
conventional and iterative approach to WSD, please
refer to this paper (Manion and Sainudiin, 2014).
</bodyText>
<table confidence="0.9848458">
Yr %NE %N %V %R %A F ΔF
’04 - 37.7 34.0 12.6 15.6 27.1 +16.8
’10 - 73.8 26.2 - - 26.8 +11.1
’13 17.1 82.9 - - - 58.3 +6.1
’15 6.0 44.9 28.9 6.5 13.7 55.8 +5.8
</table>
<tableCaption confidence="0.991326">
Table 1: Parts of Speech disambiguated (as percent-
</tableCaption>
<bodyText confidence="0.972059266666667">
ages) for each SemEval Task (denoted by its year).
In-Degree Centrality as implemented in (Manion
and Sainudiin, 2014) observes F-Score improvement
(F + ΔF) by applying the iterative approach.
The author found in the investigations of his
thesis (Manion, 2014) that the iterative approach
performed best on the SemEval 2013 Multilingual
WSD Task (Navigli et al., 2013), as opposed to ear-
lier tasks such as SensEval 2004 English All Words
WSD Task (Snyder and Palmer, 2004) and the Se-
mEval 2010 All Words WSD task on a Specific Do-
main (Agirre et al., 2010). While these earlier tasks
also experienced improvement, F-Scores remained
lower overall. Table 1 above and Figures 1(a) to (i)
help highlight what changed between these tasks.
</bodyText>
<page confidence="0.996711">
365
</page>
<note confidence="0.537714">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 365–369,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
</note>
<figure confidence="0.999874275362319">
(g) Biomedical (IT)
(i) Social Issues (IT)
Degree of Polysemy
0.2
✓ Run2 (+6.5)
✓ Run3 (+8.8)
0.1
0
10 20 30
(a) Biomedical (EN)
X Run2 (-1.9)
X Run3 (-0.1)
0.2
0.1
0
10 20 30
(d) Biomedical (ES)
0.2
0.1
X Run3 (-3.7)
X Run2 (-6.3)
0
10 20 30
0.2
0.1
0
0.2
0.1
0
0.2
0.1
0
✓ Run2 (+10.2)
✓ Run3 (+6.4)
10 20 30
(b) Math &amp; Comp (EN)
✓ Run2 (+5.5)
✓ Run3 (+4.2)
10 20 30
(e) Math &amp; Comp (ES)
✓ Run2 (+3.7)
✓ Run3 (+0.7)
10 20 30
(h) Math &amp; Comp (IT)
Adverbs
Adjectives
Verbs
Nouns
Named Entities
X Run2 (-0.8)
X Run3 (-5.3)
10 20 30
(c) Social Issues (EN)
✓ Run2 (+2.8)
X Run3 (-0.9)
10 20 30
(f) Social Issues (ES)
X Run2 (-3.1)
X Run3 (-5.2)
10 20 30
0.2
0.1
0
0.2
0.1
0
0.2
0.1
0
</figure>
<figureCaption confidence="0.999749">
Figure 1: Depicted above are distributions for each domain and language, detailing the probability (y-axis)
</figureCaption>
<bodyText confidence="0.9491266">
of specific parts of speech at increasing degrees of polysemy (x-axis). These distributions were produced
from the gold keys (or synsets) of the test documents by querying BabelNet for the polysemy of each word.
Each distribution was normalised with one sense per discourse assumed, therefore duplicate synsets were
ignored. Lastly the difference in F-Score between the conventional Run1 and the iterative Run2 and Run3
is listed beside each distribution.
</bodyText>
<page confidence="0.98832">
366
</page>
<bodyText confidence="0.999789333333333">
Firstly WSD tasks before 2013 generally relied on
only a lexicon, such as WordNet (Fellbaum, 1998)
or an alternative equivalent, whereas SemEval 2013
Task 12 WSD and this task (Moro and Navigli,
2015) included Entity Linking (EL) using the en-
cyclopaedia Wikipedia via BabelNet (Navigli and
Ponzetto, 2012). Secondly, as shown by Manion and
Sainudiin (2014) with a simple linear regression, the
iterative approach increases WSD performance for
documents that have a higher degree of document
monosemy - the percentage of unique monosemous
lemmas in a document. As seen in Figures 1(a) to
(i) on the previous page, named entities (or unique
rather than common nouns) are more monosemous
compared to other parts of speech, especially for
more technical domains. Lastly, the SemEval 2013
WSD task differs in that only nouns and named en-
tities required disambiguation. This simplifies the
WSD task, as shown in the experiments on local
context by Yarowsky (1993), nouns are best disam-
biguated by directly adjacent nouns (or modifying
adjectives). Based on these observations, the author
hypothesized the following implementations of the
iterative approach should perform well.
</bodyText>
<sectionHeader confidence="0.88384" genericHeader="method">
2 System Description &amp; Implementation
</sectionHeader>
<bodyText confidence="0.996694698113208">
Run1 (SUDOKU-1) is the conventional approach –
no constraints are applied. Formalised in (Manion
and Sainudiin, 2014), this run can act as a baseline
to gauge any improvement for Run2 and Run3 that
apply the iterative approach. Run2 (SUDOKU-2)
has the constraint of words being disambiguated in
order of increasing polysemy, leaving the most pol-
ysemous to last. Run3 (SUDOKU-3) is an untested
and unpublished version of the iterative approach. It
includes Run2’s constraint plus a second constraint
– that all nouns and named entities must be disam-
biguated before other parts of speech.
For each run, a semantic subgraph is constructed
from BabelNet (version 2.5.1). Then for disam-
biguation the graph centrality measure PageRank
(Brin and Page, 1998) is used in conjunction with
a surfing vector that biases probability mass to cer-
tain sense nodes in the semantic subgraph. This
idea is taken from Personalised PageRank (PPR)
(Agirre and Soroa, 2009), which applies the method
put forward by Haveliwala (2003) to the field of
WSD. In the previous SemEval WSD task (Nav-
igli et al., 2013) team UMCC DLSI (Gutierrez et
al., 2013) implemented this method and achieved
the best performance by biasing probability mass
based on SemCor (Miller et al., 1993) sense fre-
quencies. As the winning method for this task, PPR
was selected to test the iterative approach on. For
SUDOKU’s implementation to be unsupervised, all
runs biased probability mass towards senses from
monosemous lemmas. Additionally for Run2 and
Run3, once a lemma is disambiguated it is consid-
ered to be monosemous. Therefore with each it-
eration of Run2 and Run3, probability mass is re-
distributed across the surfing vector to acknowledge
these newly appointed monosemous lemmas.
All system runs are applied at the document level,
across all languages and domains, for all named en-
tities, nouns, verbs, adverbs, and adjectives. Se-
mantic subgraphs are constructed from BabelNet via
a Depth First Search (DFS) up to 2 hops in path
length. PageRank’s damping factor is set to 0.85,
with a maximum of 30 iterations1. In order to avoid
masking the effect of using the iterative approach, a
back-off strategy (see (McCarthy et al., 2004)) was
not used. Multiword units were found by finding
lemma sequences that contained at least one noun
and at the same time could return a result from
BabelNet. Lemma sequences beginning with defi-
nite/indefinite articles (e.g. the, a, il, la, and el) were
removed as they induced too much noise, given they
almost always returned a result from BabelNet (such
as a book or movie title).
</bodyText>
<sectionHeader confidence="0.99826" genericHeader="method">
3 Results, Discussions, &amp; Conclusions
</sectionHeader>
<bodyText confidence="0.9997339">
As seen in Figures 1(a) to (i) on the previous page,
the Biomedical and Math &amp; Computers domains in-
clude a substantial degree of monosemy, no doubt
increased by the monosemous technical terms and
named entities present. Given the importance of
document monosemy for the iterative approach, it
is of no surprise that Run2 and Run3 in most cases
performed much better than Run1 for these technical
domains. Equally so, Run2 and Run3 were outper-
formed by Run1 for the less technical Social Issues
</bodyText>
<footnote confidence="0.952015666666667">
1PageRank iterations remain at the atomic level, i.e. they
do not influence the construction of the semantic subgraph, see
(Manion and Sainudiin, 2014) Section 3.1 for more details.
</footnote>
<page confidence="0.990169">
367
</page>
<table confidence="0.999541285714286">
Part of All Domains Biology Math &amp; Comp Social Issues
Speech (1) 0(2-1) 0(3-1) (1) 0(2-1) 0(3-1) (1) 0(2-1) 0(3-1) (1) 0(2-1) 0(3-1)
Named Ents 16.8 +70.2 +70.2 4.1 +94.8 +94.8 0.0 +56.3 +56.3 60.9 +20.6 +20.6
Nouns 53.4 +9.1 +9.3 62.8 +9.1 +13.0 28.5 +22.9 +20.4 56.4 -3.6 -8.2
Verbs 52.2 -2.6 -6.2 52.5 -5.2 -1.9 51.4 -2.3 -9.1 52.9 +3.9 -12.0
Adverbs 48.9 +21.5 +22.8 50.7 +27.2 +24.6 52.0 +4.6 +12.2 36.4 +39.5 +39.5
Adjectives 74.4 -2.7 -6.3 82.3 +1.0 -4.5 75.0 -7.5 -17.5 63.6 -4.3 -0.6
</table>
<tableCaption confidence="0.999862">
Table 2: The difference in F-Scores over each Domain and Part of Speech for English SUDOKU Runs.
</tableCaption>
<bodyText confidence="0.999671777777778">
domain in which many of the named entities are pol-
ysemous rather than monosemous.
While the iterative approach achieved reasonably
competitive results in English, this success did not
translate as well to Spanish and Italian. The Ital-
ian Biomedical domain had the highest document
monosemy, observable in Figure 1 (g), yet this did
not help the iterative Run2 and Run3. Yet it is worth
noting the results of the task paper (Moro and Nav-
igli, 2015) report that SUDOKU Run2 and Run3
achieved very low F-Scores for named entity disam-
biguation (&lt;28.6) in Spanish and Italian. Given that
more than half of the named entities were monose-
mous in Figure 1(d) and (g), the WSD system either
did not capture them in text or filtered them out dur-
ing subgraph construction (see BabelNet API). This
underscores the importance of named entities being
included in disambiguation tasks. To further support
this evidence, while the iterative approach is suited
to domain based WSD, recall that the 2010 domain
based WSD task in Table 1 also had no tagged
named entities (and thus scores were lower than for
successive named entity inclusive WSD tasks).
As seen in Table 2, the iterative approach has a
varied effect on different parts of speech. Always
improved is the disambiguation of named entities
and adverbs. This is also the case for nouns in tech-
nical domains (e.g. Biomedical as opposed to Social
Issues). On the other hand the disambiguation of
verbs and adjectives suffers under the iterative ap-
proach. In hindsight, the iterative approach could
be restricted to the parts of speech it is known to
improve, while remaining with the conventional ap-
proach on others. To the right in Table 3 the author’s
SUDOKU runs are compared against the team with
the most competitive results – LIMSI. The author
could not improve on their superior results achieved
in English, however for Spanish and Italian the Ba-
belNet First Sense (BFS) baseline was much lower
since it often resorted to lexicographic sorting in the
absence of WordNet synsets – see (Navigli et al.,
2013). The author’s baseline-independent submis-
sions were unaffected by this, which on reviewing
results in (Moro and Navigli, 2015) appears to have
helped SUDOKU do best for these languages.
</bodyText>
<equation confidence="0.9161008">
LIMSI
SUDOKU-2
SUDOKU-3
SUDOKU-1
BFS 67.5
SUDOKU-2
SUDOKU-3
SUDOKU-1
LIMSI
BFS 37.5
SUDOKU-1
SUDOKU-3
SUDOKU-2
LIMSI
BFS 40.2
</equation>
<tableCaption confidence="0.8448445">
Table 3: F1 scores for each domain/language for
SUDOKU and LIMSI.
</tableCaption>
<bodyText confidence="0.99978975">
In summary, the inclusion of named entities in
disambiguation tasks certainly improves results, as
well as the effectiveness of the iterative approach.
Furthermore in Table 3 above, the iterative Run3
for the English Biomedical domain is 0.1 short of
achieving the best result of 71.3. Investigating ex-
actly which factors contributed to the success of this
unsupervised result is a top priority for future work.
</bodyText>
<figure confidence="0.90938865625">
Team Run All
(EN)
(ES)
(IT)
65.8
61.6
60.7
55.8
57.1
56.8
56.0
45.0
59.9
56.9
56.9
48.4
Bio Mat Soc
71.3 54.1 67.2
68.9 53.2 55.6
71.2 49.4 51.1
62.4 43.0 56.4
72.2 55.3 70.8
60.8 49.7 57.0
62.6 48.4 53.3
62.7 44.2 54.2
51.0 34.8 43.1
43.7 28.7 34.0
65.1 48.4 61.0
64.1 49.1 55.8
58.8 52.1 57.9
53.1 44.6 42.9
44.3 36.7 35.7
</figure>
<page confidence="0.985625">
368
</page>
<sectionHeader confidence="0.8761" genericHeader="conclusions">
Resources
</sectionHeader>
<bodyText confidence="0.9821215">
Codebase and resources are at the author’s home-
page: http://www.stevemanion.com.
</bodyText>
<sectionHeader confidence="0.995491" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99526375">
This submission is an extension of the author’s
PhD thesis completed under the supervision of Dr
Raazesh Sainudiin and with the help of the Korean
Foundation Graduate Studies Fellowship.
</bodyText>
<sectionHeader confidence="0.998361" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999515306666667">
Eneko Agirre and Philip Edmonds 2007. Chapter 1: In-
troduction. Word Sense Disambiguation Algorithms
and Applications, pages 1-28. Springer, New York.
Eneko Agirre, Oier Lopez De Lacalle, Christiane Fell-
baum, Shu-Kai Hsieh, Maurizio Tesconi, Monica
Monachini, Piek Vossen, and Roxanne Segers. 2010.
SemEval-2010 Task 17: All-words Word Sense Dis-
ambiguation on a Specific Domain. In Proceedings of
the 5th International Workshop on Semantic Evalua-
tion (SemEval-2010), pages 75-80. Uppsala, Sweden.
Eneko Agirre and Aitor Soroa. 2009. Personaliz-
ing PageRank for Word Sense Disambiguation. In
Proceedings of the 12th Conference of the European
Chapter of the Association for Computational Linguis-
tics (EACL’09), pages 33-41. Athens, Greece.
Sergey Brin and Lawrence Page. 1998. The Anatomy of
a Large-scale Hypertextual Web Search Engine. Com-
puter Networks and ISDN Systems, 30:107-117.
Christiane Fellbaum. 1998, ed. WordNet: An Electronic
Lexical Database., Cambridge, MA: MIT Press.
Yoan Gutirrez, Antonio Fernndez Orqun, Franc Camara,
Yenier Castaeda, Andy Gonzlez, Andrs Montoyo,
Rafael Muoz, Rainel Estrada, Dennys D. Piug, Jose
I. Abreu, and Roger Prez. 2013. UMCC DLSI: Rein-
forcing a Ranking Algorithm with Sense Frequencies
and Multidimensional Semantic Resources to solve
Multilingual Word Sense Disambiguation. Proceed-
ings of the 7th International Workshop on Semantic
Evaluation (SemEval-2013), pages 241-249. Atlanta,
Georgia.
Taher H. Haveliwala. 2003. A Context-Sensetive Rank-
ing Algorithm for Web Search. IEEE Transactions on
Knowledge and Data Engineering, 15(4):784–796.
Steve L. Manion and Raazesh Sainudiin. 2014. An Itera-
tive Sudoku Style Approach to Subgraph-based Word
Sense Disambiguation. In Proceedings of the 3rd Joint
Conference on Lexical and Computational Semantics
(*SEM’14), pages 40-50. Dublin, Ireland.
Steve L. Manion. 2014. Unsupervised Knowledge-based
Word Sense Disambiguation: Exploration &amp; Evalua-
tion of Semantic Subgraphs. Doctoral Thesis. Univer-
sity of Canterbury.
Diana McCarthy, Rob Koeling, Julie Weeds, and John
Carroll. 2004. Finding Predominant Word Senses in
Untagged Text. In Proceedings of the 42nd Annual
Meeting for the Association for Computational Lin-
guistics (ACL’04), pages 280-287. Barcelona, Spain.
George A. Miller, Claudia Leacock, Randee Tengi, and
Ross T. Bunker. 1993. A Semantic Concordance.
In Proceedings of the Workshop on Human Language
Technology (HLT93), pages 303-308. Princeton, New
Jersey.
Andrea Moro and Roberto Navigli. 2015. SemEval-
2015 Task 13: Multilingual All-Words Sense Disam-
biguation and Entity Linking. In Proceedings of the
9th International Workshop on Semantic Evaluation
(SemEval-2015). Denver, Colorado.
Roberto Navigli, David Jurgens, and Daniele Van-
nella. 2013. SemEval-2013 Task 12: Multilingual-
Word Sense Disambiguation. In Proceedings of the
7th International Workshop on Semantic Evaluation
(SemEval-2013), pages 222-231. Atlanta, Georgia.
Roberto Navigli and Simone Paolo Ponzetto. 2012. Ba-
belNet: The automatic construction, evaluation and
application of a wide-coverage multilingual semantic
network. Artificial Intelligence, 193:217–250.
Benjamin Snyder and Martha Palmer. 2004. The English
All-Words Task. In Proceedings of the 3rd Interna-
tional Workshop on the Evaluation of Systems for the
Semantic Analysis of Text (SENSEVAL-3), pages 41-
43. Barcelona, Spain.
David Yarowsky. 1993. One Sense Per Collocation. In
Proceedings of the ARPA Workshop on Human Lan-
guage Technology (HLT’93), pages 266-271. Morris-
town, New Jersey.
</reference>
<page confidence="0.999161">
369
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.366773">
<title confidence="0.997136">SUDOKU: Treating Word Sense Disambiguation &amp; Entity Linking as Deterministic Problem – via an Unsupervised &amp; Iterative Approach</title>
<author confidence="0.999914">Steve L Manion</author>
<affiliation confidence="0.986865">University of Canterbury, Christchurch, New</affiliation>
<email confidence="0.412828">steve.manion@pg.canterbury.ac.nz</email>
<abstract confidence="0.99179275">SUDOKU’s submissions to SemEval Task 13 treats Word Sense Disambiguation and Entity Linking as a deterministic problem that exploits two key attributes of open-class words constraints – their of polysemy of This is an extension and further validation of the results achieved by Manion and Sainudiin (2014). SUDOKU’s three submissions are incremental in the use of the two aforementioned constraints. Run1 has no constraints and disambiguates all lemmas in one pass. Run2 disambiguates lemmas at increasing degrees of polysemy, leaving the most polysemous until last. Run3 is identical to Run2, with the additional constraint of disambiguating all named entities and nouns first before other types of open-class words (verbs, adjectives, and adverbs). Over all-domains, for English Run2 and Run3 were placed second and third. For Spanish Run2, Run3, and Run1 were placed first, second, and third respectively. For Italian Run1 was placed first with Run2 and Run3 placed second equal.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Philip Edmonds</author>
</authors>
<title>Chapter 1: Introduction. Word Sense Disambiguation Algorithms and Applications,</title>
<date>2007</date>
<pages>1--28</pages>
<publisher>Springer,</publisher>
<location>New York.</location>
<contexts>
<context position="1333" citStr="Agirre and Edmonds (2007)" startWordPosition="201" endWordPosition="204">iguates all lemmas in one pass. Run2 disambiguates lemmas at increasing degrees of polysemy, leaving the most polysemous until last. Run3 is identical to Run2, with the additional constraint of disambiguating all named entities and nouns first before other types of open-class words (verbs, adjectives, and adverbs). Over all-domains, for English Run2 and Run3 were placed second and third. For Spanish Run2, Run3, and Run1 were placed first, second, and third respectively. For Italian Run1 was placed first with Run2 and Run3 placed second equal. 1 Introduction &amp; Related Work Almost a decade ago, Agirre and Edmonds (2007) suggested the promising potential for WSD that could exploit the interdependencies between senses in an interactive manner. In other words, this would be a WSD system which allows the disambiguation of word a to directly influence the consecutive disambiguation of word b. This is analogous to treating WSD as a deterministic problem, much like the Sudoku puzzle in which the final solution is reached by adhering to a set of pre-determined constraints. Conventional approaches to WSD often overlook the potential to exploit sense interdependencies, and simply disambiguate all senses in one pass ba</context>
</contexts>
<marker>Agirre, Edmonds, 2007</marker>
<rawString>Eneko Agirre and Philip Edmonds 2007. Chapter 1: Introduction. Word Sense Disambiguation Algorithms and Applications, pages 1-28. Springer, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Oier Lopez De Lacalle</author>
<author>Christiane Fellbaum</author>
<author>Shu-Kai Hsieh</author>
<author>Maurizio Tesconi</author>
<author>Monica Monachini</author>
<author>Piek Vossen</author>
<author>Roxanne Segers</author>
</authors>
<title>SemEval-2010 Task 17: All-words Word Sense Disambiguation on a Specific Domain.</title>
<date>2010</date>
<booktitle>In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval-2010),</booktitle>
<pages>75--80</pages>
<location>Uppsala,</location>
<marker>Agirre, De Lacalle, Fellbaum, Hsieh, Tesconi, Monachini, Vossen, Segers, 2010</marker>
<rawString>Eneko Agirre, Oier Lopez De Lacalle, Christiane Fellbaum, Shu-Kai Hsieh, Maurizio Tesconi, Monica Monachini, Piek Vossen, and Roxanne Segers. 2010. SemEval-2010 Task 17: All-words Word Sense Disambiguation on a Specific Domain. In Proceedings of the 5th International Workshop on Semantic Evaluation (SemEval-2010), pages 75-80. Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>Aitor Soroa</author>
</authors>
<title>Personalizing PageRank for Word Sense Disambiguation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL’09),</booktitle>
<pages>33--41</pages>
<location>Athens, Greece.</location>
<contexts>
<context position="6783" citStr="Agirre and Soroa, 2009" startWordPosition="1119" endWordPosition="1122">aving the most polysemous to last. Run3 (SUDOKU-3) is an untested and unpublished version of the iterative approach. It includes Run2’s constraint plus a second constraint – that all nouns and named entities must be disambiguated before other parts of speech. For each run, a semantic subgraph is constructed from BabelNet (version 2.5.1). Then for disambiguation the graph centrality measure PageRank (Brin and Page, 1998) is used in conjunction with a surfing vector that biases probability mass to certain sense nodes in the semantic subgraph. This idea is taken from Personalised PageRank (PPR) (Agirre and Soroa, 2009), which applies the method put forward by Haveliwala (2003) to the field of WSD. In the previous SemEval WSD task (Navigli et al., 2013) team UMCC DLSI (Gutierrez et al., 2013) implemented this method and achieved the best performance by biasing probability mass based on SemCor (Miller et al., 1993) sense frequencies. As the winning method for this task, PPR was selected to test the iterative approach on. For SUDOKU’s implementation to be unsupervised, all runs biased probability mass towards senses from monosemous lemmas. Additionally for Run2 and Run3, once a lemma is disambiguated it is con</context>
</contexts>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Eneko Agirre and Aitor Soroa. 2009. Personalizing PageRank for Word Sense Disambiguation. In Proceedings of the 12th Conference of the European Chapter of the Association for Computational Linguistics (EACL’09), pages 33-41. Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The Anatomy of a Large-scale Hypertextual Web Search Engine.</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems,</journal>
<pages>30--107</pages>
<contexts>
<context position="6583" citStr="Brin and Page, 1998" startWordPosition="1086" endWordPosition="1089">n act as a baseline to gauge any improvement for Run2 and Run3 that apply the iterative approach. Run2 (SUDOKU-2) has the constraint of words being disambiguated in order of increasing polysemy, leaving the most polysemous to last. Run3 (SUDOKU-3) is an untested and unpublished version of the iterative approach. It includes Run2’s constraint plus a second constraint – that all nouns and named entities must be disambiguated before other parts of speech. For each run, a semantic subgraph is constructed from BabelNet (version 2.5.1). Then for disambiguation the graph centrality measure PageRank (Brin and Page, 1998) is used in conjunction with a surfing vector that biases probability mass to certain sense nodes in the semantic subgraph. This idea is taken from Personalised PageRank (PPR) (Agirre and Soroa, 2009), which applies the method put forward by Haveliwala (2003) to the field of WSD. In the previous SemEval WSD task (Navigli et al., 2013) team UMCC DLSI (Gutierrez et al., 2013) implemented this method and achieved the best performance by biasing probability mass based on SemCor (Miller et al., 1993) sense frequencies. As the winning method for this task, PPR was selected to test the iterative appr</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The Anatomy of a Large-scale Hypertextual Web Search Engine. Computer Networks and ISDN Systems, 30:107-117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<date>1998</date>
<booktitle>WordNet: An Electronic Lexical Database.,</booktitle>
<editor>ed.</editor>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="4721" citStr="Fellbaum, 1998" startWordPosition="798" endWordPosition="799"> domain and language, detailing the probability (y-axis) of specific parts of speech at increasing degrees of polysemy (x-axis). These distributions were produced from the gold keys (or synsets) of the test documents by querying BabelNet for the polysemy of each word. Each distribution was normalised with one sense per discourse assumed, therefore duplicate synsets were ignored. Lastly the difference in F-Score between the conventional Run1 and the iterative Run2 and Run3 is listed beside each distribution. 366 Firstly WSD tasks before 2013 generally relied on only a lexicon, such as WordNet (Fellbaum, 1998) or an alternative equivalent, whereas SemEval 2013 Task 12 WSD and this task (Moro and Navigli, 2015) included Entity Linking (EL) using the encyclopaedia Wikipedia via BabelNet (Navigli and Ponzetto, 2012). Secondly, as shown by Manion and Sainudiin (2014) with a simple linear regression, the iterative approach increases WSD performance for documents that have a higher degree of document monosemy - the percentage of unique monosemous lemmas in a document. As seen in Figures 1(a) to (i) on the previous page, named entities (or unique rather than common nouns) are more monosemous compared to o</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Christiane Fellbaum. 1998, ed. WordNet: An Electronic Lexical Database., Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yoan Gutirrez</author>
<author>Antonio Fernndez Orqun</author>
<author>Franc Camara</author>
<author>Yenier Castaeda</author>
<author>Andy Gonzlez</author>
<author>Andrs Montoyo</author>
<author>Rafael Muoz</author>
<author>Rainel Estrada</author>
<author>Dennys D Piug</author>
<author>Jose I Abreu</author>
<author>Roger Prez</author>
</authors>
<title>UMCC DLSI: Reinforcing a Ranking Algorithm with Sense Frequencies and Multidimensional Semantic Resources to solve Multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval-2013),</booktitle>
<pages>241--249</pages>
<location>Atlanta,</location>
<marker>Gutirrez, Orqun, Camara, Castaeda, Gonzlez, Montoyo, Muoz, Estrada, Piug, Abreu, Prez, 2013</marker>
<rawString>Yoan Gutirrez, Antonio Fernndez Orqun, Franc Camara, Yenier Castaeda, Andy Gonzlez, Andrs Montoyo, Rafael Muoz, Rainel Estrada, Dennys D. Piug, Jose I. Abreu, and Roger Prez. 2013. UMCC DLSI: Reinforcing a Ranking Algorithm with Sense Frequencies and Multidimensional Semantic Resources to solve Multilingual Word Sense Disambiguation. Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval-2013), pages 241-249. Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taher H Haveliwala</author>
</authors>
<title>A Context-Sensetive Ranking Algorithm for Web Search.</title>
<date>2003</date>
<journal>IEEE Transactions on Knowledge and Data Engineering,</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="6842" citStr="Haveliwala (2003)" startWordPosition="1130" endWordPosition="1131"> and unpublished version of the iterative approach. It includes Run2’s constraint plus a second constraint – that all nouns and named entities must be disambiguated before other parts of speech. For each run, a semantic subgraph is constructed from BabelNet (version 2.5.1). Then for disambiguation the graph centrality measure PageRank (Brin and Page, 1998) is used in conjunction with a surfing vector that biases probability mass to certain sense nodes in the semantic subgraph. This idea is taken from Personalised PageRank (PPR) (Agirre and Soroa, 2009), which applies the method put forward by Haveliwala (2003) to the field of WSD. In the previous SemEval WSD task (Navigli et al., 2013) team UMCC DLSI (Gutierrez et al., 2013) implemented this method and achieved the best performance by biasing probability mass based on SemCor (Miller et al., 1993) sense frequencies. As the winning method for this task, PPR was selected to test the iterative approach on. For SUDOKU’s implementation to be unsupervised, all runs biased probability mass towards senses from monosemous lemmas. Additionally for Run2 and Run3, once a lemma is disambiguated it is considered to be monosemous. Therefore with each iteration of </context>
</contexts>
<marker>Haveliwala, 2003</marker>
<rawString>Taher H. Haveliwala. 2003. A Context-Sensetive Ranking Algorithm for Web Search. IEEE Transactions on Knowledge and Data Engineering, 15(4):784–796.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve L Manion</author>
<author>Raazesh Sainudiin</author>
</authors>
<title>An Iterative Sudoku Style Approach to Subgraph-based Word Sense Disambiguation.</title>
<date>2014</date>
<booktitle>In Proceedings of the 3rd Joint Conference on Lexical and Computational Semantics (*SEM’14),</booktitle>
<pages>40--50</pages>
<location>Dublin, Ireland.</location>
<contexts>
<context position="2243" citStr="Manion and Sainudiin, 2014" startWordPosition="350" endWordPosition="353">nalogous to treating WSD as a deterministic problem, much like the Sudoku puzzle in which the final solution is reached by adhering to a set of pre-determined constraints. Conventional approaches to WSD often overlook the potential to exploit sense interdependencies, and simply disambiguate all senses in one pass based on a context window (e.g. a sentence or document). For this task the author proposes an iterative approach which makes several passes based on a set of constraints. For a more formal distinction between the conventional and iterative approach to WSD, please refer to this paper (Manion and Sainudiin, 2014). Yr %NE %N %V %R %A F ΔF ’04 - 37.7 34.0 12.6 15.6 27.1 +16.8 ’10 - 73.8 26.2 - - 26.8 +11.1 ’13 17.1 82.9 - - - 58.3 +6.1 ’15 6.0 44.9 28.9 6.5 13.7 55.8 +5.8 Table 1: Parts of Speech disambiguated (as percentages) for each SemEval Task (denoted by its year). In-Degree Centrality as implemented in (Manion and Sainudiin, 2014) observes F-Score improvement (F + ΔF) by applying the iterative approach. The author found in the investigations of his thesis (Manion, 2014) that the iterative approach performed best on the SemEval 2013 Multilingual WSD Task (Navigli et al., 2013), as opposed to earli</context>
<context position="4979" citStr="Manion and Sainudiin (2014)" startWordPosition="836" endWordPosition="839">polysemy of each word. Each distribution was normalised with one sense per discourse assumed, therefore duplicate synsets were ignored. Lastly the difference in F-Score between the conventional Run1 and the iterative Run2 and Run3 is listed beside each distribution. 366 Firstly WSD tasks before 2013 generally relied on only a lexicon, such as WordNet (Fellbaum, 1998) or an alternative equivalent, whereas SemEval 2013 Task 12 WSD and this task (Moro and Navigli, 2015) included Entity Linking (EL) using the encyclopaedia Wikipedia via BabelNet (Navigli and Ponzetto, 2012). Secondly, as shown by Manion and Sainudiin (2014) with a simple linear regression, the iterative approach increases WSD performance for documents that have a higher degree of document monosemy - the percentage of unique monosemous lemmas in a document. As seen in Figures 1(a) to (i) on the previous page, named entities (or unique rather than common nouns) are more monosemous compared to other parts of speech, especially for more technical domains. Lastly, the SemEval 2013 WSD task differs in that only nouns and named entities required disambiguation. This simplifies the WSD task, as shown in the experiments on local context by Yarowsky (1993</context>
<context position="9093" citStr="Manion and Sainudiin, 2014" startWordPosition="1502" endWordPosition="1505"> 1(a) to (i) on the previous page, the Biomedical and Math &amp; Computers domains include a substantial degree of monosemy, no doubt increased by the monosemous technical terms and named entities present. Given the importance of document monosemy for the iterative approach, it is of no surprise that Run2 and Run3 in most cases performed much better than Run1 for these technical domains. Equally so, Run2 and Run3 were outperformed by Run1 for the less technical Social Issues 1PageRank iterations remain at the atomic level, i.e. they do not influence the construction of the semantic subgraph, see (Manion and Sainudiin, 2014) Section 3.1 for more details. 367 Part of All Domains Biology Math &amp; Comp Social Issues Speech (1) 0(2-1) 0(3-1) (1) 0(2-1) 0(3-1) (1) 0(2-1) 0(3-1) (1) 0(2-1) 0(3-1) Named Ents 16.8 +70.2 +70.2 4.1 +94.8 +94.8 0.0 +56.3 +56.3 60.9 +20.6 +20.6 Nouns 53.4 +9.1 +9.3 62.8 +9.1 +13.0 28.5 +22.9 +20.4 56.4 -3.6 -8.2 Verbs 52.2 -2.6 -6.2 52.5 -5.2 -1.9 51.4 -2.3 -9.1 52.9 +3.9 -12.0 Adverbs 48.9 +21.5 +22.8 50.7 +27.2 +24.6 52.0 +4.6 +12.2 36.4 +39.5 +39.5 Adjectives 74.4 -2.7 -6.3 82.3 +1.0 -4.5 75.0 -7.5 -17.5 63.6 -4.3 -0.6 Table 2: The difference in F-Scores over each Domain and Part of Speech </context>
</contexts>
<marker>Manion, Sainudiin, 2014</marker>
<rawString>Steve L. Manion and Raazesh Sainudiin. 2014. An Iterative Sudoku Style Approach to Subgraph-based Word Sense Disambiguation. In Proceedings of the 3rd Joint Conference on Lexical and Computational Semantics (*SEM’14), pages 40-50. Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steve L Manion</author>
</authors>
<title>Unsupervised Knowledge-based Word Sense Disambiguation: Exploration &amp; Evaluation of Semantic Subgraphs. Doctoral Thesis.</title>
<date>2014</date>
<institution>University of Canterbury.</institution>
<contexts>
<context position="2714" citStr="Manion, 2014" startWordPosition="440" endWordPosition="441"> For a more formal distinction between the conventional and iterative approach to WSD, please refer to this paper (Manion and Sainudiin, 2014). Yr %NE %N %V %R %A F ΔF ’04 - 37.7 34.0 12.6 15.6 27.1 +16.8 ’10 - 73.8 26.2 - - 26.8 +11.1 ’13 17.1 82.9 - - - 58.3 +6.1 ’15 6.0 44.9 28.9 6.5 13.7 55.8 +5.8 Table 1: Parts of Speech disambiguated (as percentages) for each SemEval Task (denoted by its year). In-Degree Centrality as implemented in (Manion and Sainudiin, 2014) observes F-Score improvement (F + ΔF) by applying the iterative approach. The author found in the investigations of his thesis (Manion, 2014) that the iterative approach performed best on the SemEval 2013 Multilingual WSD Task (Navigli et al., 2013), as opposed to earlier tasks such as SensEval 2004 English All Words WSD Task (Snyder and Palmer, 2004) and the SemEval 2010 All Words WSD task on a Specific Domain (Agirre et al., 2010). While these earlier tasks also experienced improvement, F-Scores remained lower overall. Table 1 above and Figures 1(a) to (i) help highlight what changed between these tasks. 365 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 365–369, Denver, Colorado, June </context>
</contexts>
<marker>Manion, 2014</marker>
<rawString>Steve L. Manion. 2014. Unsupervised Knowledge-based Word Sense Disambiguation: Exploration &amp; Evaluation of Semantic Subgraphs. Doctoral Thesis. University of Canterbury.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Rob Koeling</author>
<author>Julie Weeds</author>
<author>John Carroll</author>
</authors>
<title>Finding Predominant Word Senses in Untagged Text.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Annual Meeting for the Association for Computational Linguistics (ACL’04),</booktitle>
<pages>280--287</pages>
<location>Barcelona,</location>
<contexts>
<context position="8024" citStr="McCarthy et al., 2004" startWordPosition="1324" endWordPosition="1327">emous. Therefore with each iteration of Run2 and Run3, probability mass is redistributed across the surfing vector to acknowledge these newly appointed monosemous lemmas. All system runs are applied at the document level, across all languages and domains, for all named entities, nouns, verbs, adverbs, and adjectives. Semantic subgraphs are constructed from BabelNet via a Depth First Search (DFS) up to 2 hops in path length. PageRank’s damping factor is set to 0.85, with a maximum of 30 iterations1. In order to avoid masking the effect of using the iterative approach, a back-off strategy (see (McCarthy et al., 2004)) was not used. Multiword units were found by finding lemma sequences that contained at least one noun and at the same time could return a result from BabelNet. Lemma sequences beginning with definite/indefinite articles (e.g. the, a, il, la, and el) were removed as they induced too much noise, given they almost always returned a result from BabelNet (such as a book or movie title). 3 Results, Discussions, &amp; Conclusions As seen in Figures 1(a) to (i) on the previous page, the Biomedical and Math &amp; Computers domains include a substantial degree of monosemy, no doubt increased by the monosemous </context>
</contexts>
<marker>McCarthy, Koeling, Weeds, Carroll, 2004</marker>
<rawString>Diana McCarthy, Rob Koeling, Julie Weeds, and John Carroll. 2004. Finding Predominant Word Senses in Untagged Text. In Proceedings of the 42nd Annual Meeting for the Association for Computational Linguistics (ACL’04), pages 280-287. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Claudia Leacock</author>
<author>Randee Tengi</author>
<author>Ross T Bunker</author>
</authors>
<title>A Semantic Concordance.</title>
<date>1993</date>
<booktitle>In Proceedings of the Workshop on Human Language Technology (HLT93),</booktitle>
<pages>303--308</pages>
<location>Princeton, New Jersey.</location>
<contexts>
<context position="7083" citStr="Miller et al., 1993" startWordPosition="1170" endWordPosition="1173">ucted from BabelNet (version 2.5.1). Then for disambiguation the graph centrality measure PageRank (Brin and Page, 1998) is used in conjunction with a surfing vector that biases probability mass to certain sense nodes in the semantic subgraph. This idea is taken from Personalised PageRank (PPR) (Agirre and Soroa, 2009), which applies the method put forward by Haveliwala (2003) to the field of WSD. In the previous SemEval WSD task (Navigli et al., 2013) team UMCC DLSI (Gutierrez et al., 2013) implemented this method and achieved the best performance by biasing probability mass based on SemCor (Miller et al., 1993) sense frequencies. As the winning method for this task, PPR was selected to test the iterative approach on. For SUDOKU’s implementation to be unsupervised, all runs biased probability mass towards senses from monosemous lemmas. Additionally for Run2 and Run3, once a lemma is disambiguated it is considered to be monosemous. Therefore with each iteration of Run2 and Run3, probability mass is redistributed across the surfing vector to acknowledge these newly appointed monosemous lemmas. All system runs are applied at the document level, across all languages and domains, for all named entities, n</context>
</contexts>
<marker>Miller, Leacock, Tengi, Bunker, 1993</marker>
<rawString>George A. Miller, Claudia Leacock, Randee Tengi, and Ross T. Bunker. 1993. A Semantic Concordance. In Proceedings of the Workshop on Human Language Technology (HLT93), pages 303-308. Princeton, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Moro</author>
<author>Roberto Navigli</author>
</authors>
<title>SemEval2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking.</title>
<date>2015</date>
<booktitle>In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval-2015).</booktitle>
<location>Denver, Colorado.</location>
<contexts>
<context position="4823" citStr="Moro and Navigli, 2015" startWordPosition="813" endWordPosition="816">sing degrees of polysemy (x-axis). These distributions were produced from the gold keys (or synsets) of the test documents by querying BabelNet for the polysemy of each word. Each distribution was normalised with one sense per discourse assumed, therefore duplicate synsets were ignored. Lastly the difference in F-Score between the conventional Run1 and the iterative Run2 and Run3 is listed beside each distribution. 366 Firstly WSD tasks before 2013 generally relied on only a lexicon, such as WordNet (Fellbaum, 1998) or an alternative equivalent, whereas SemEval 2013 Task 12 WSD and this task (Moro and Navigli, 2015) included Entity Linking (EL) using the encyclopaedia Wikipedia via BabelNet (Navigli and Ponzetto, 2012). Secondly, as shown by Manion and Sainudiin (2014) with a simple linear regression, the iterative approach increases WSD performance for documents that have a higher degree of document monosemy - the percentage of unique monosemous lemmas in a document. As seen in Figures 1(a) to (i) on the previous page, named entities (or unique rather than common nouns) are more monosemous compared to other parts of speech, especially for more technical domains. Lastly, the SemEval 2013 WSD task differs</context>
<context position="10165" citStr="Moro and Navigli, 2015" startWordPosition="1689" endWordPosition="1693"> +39.5 Adjectives 74.4 -2.7 -6.3 82.3 +1.0 -4.5 75.0 -7.5 -17.5 63.6 -4.3 -0.6 Table 2: The difference in F-Scores over each Domain and Part of Speech for English SUDOKU Runs. domain in which many of the named entities are polysemous rather than monosemous. While the iterative approach achieved reasonably competitive results in English, this success did not translate as well to Spanish and Italian. The Italian Biomedical domain had the highest document monosemy, observable in Figure 1 (g), yet this did not help the iterative Run2 and Run3. Yet it is worth noting the results of the task paper (Moro and Navigli, 2015) report that SUDOKU Run2 and Run3 achieved very low F-Scores for named entity disambiguation (&lt;28.6) in Spanish and Italian. Given that more than half of the named entities were monosemous in Figure 1(d) and (g), the WSD system either did not capture them in text or filtered them out during subgraph construction (see BabelNet API). This underscores the importance of named entities being included in disambiguation tasks. To further support this evidence, while the iterative approach is suited to domain based WSD, recall that the 2010 domain based WSD task in Table 1 also had no tagged named ent</context>
<context position="11900" citStr="Moro and Navigli, 2015" startWordPosition="1979" endWordPosition="1982">e parts of speech it is known to improve, while remaining with the conventional approach on others. To the right in Table 3 the author’s SUDOKU runs are compared against the team with the most competitive results – LIMSI. The author could not improve on their superior results achieved in English, however for Spanish and Italian the BabelNet First Sense (BFS) baseline was much lower since it often resorted to lexicographic sorting in the absence of WordNet synsets – see (Navigli et al., 2013). The author’s baseline-independent submissions were unaffected by this, which on reviewing results in (Moro and Navigli, 2015) appears to have helped SUDOKU do best for these languages. LIMSI SUDOKU-2 SUDOKU-3 SUDOKU-1 BFS 67.5 SUDOKU-2 SUDOKU-3 SUDOKU-1 LIMSI BFS 37.5 SUDOKU-1 SUDOKU-3 SUDOKU-2 LIMSI BFS 40.2 Table 3: F1 scores for each domain/language for SUDOKU and LIMSI. In summary, the inclusion of named entities in disambiguation tasks certainly improves results, as well as the effectiveness of the iterative approach. Furthermore in Table 3 above, the iterative Run3 for the English Biomedical domain is 0.1 short of achieving the best result of 71.3. Investigating exactly which factors contributed to the success</context>
</contexts>
<marker>Moro, Navigli, 2015</marker>
<rawString>Andrea Moro and Roberto Navigli. 2015. SemEval2015 Task 13: Multilingual All-Words Sense Disambiguation and Entity Linking. In Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval-2015). Denver, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>David Jurgens</author>
<author>Daniele Vannella</author>
</authors>
<title>SemEval-2013 Task 12: MultilingualWord Sense Disambiguation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval-2013),</booktitle>
<pages>222--231</pages>
<location>Atlanta,</location>
<contexts>
<context position="2822" citStr="Navigli et al., 2013" startWordPosition="455" endWordPosition="458">to this paper (Manion and Sainudiin, 2014). Yr %NE %N %V %R %A F ΔF ’04 - 37.7 34.0 12.6 15.6 27.1 +16.8 ’10 - 73.8 26.2 - - 26.8 +11.1 ’13 17.1 82.9 - - - 58.3 +6.1 ’15 6.0 44.9 28.9 6.5 13.7 55.8 +5.8 Table 1: Parts of Speech disambiguated (as percentages) for each SemEval Task (denoted by its year). In-Degree Centrality as implemented in (Manion and Sainudiin, 2014) observes F-Score improvement (F + ΔF) by applying the iterative approach. The author found in the investigations of his thesis (Manion, 2014) that the iterative approach performed best on the SemEval 2013 Multilingual WSD Task (Navigli et al., 2013), as opposed to earlier tasks such as SensEval 2004 English All Words WSD Task (Snyder and Palmer, 2004) and the SemEval 2010 All Words WSD task on a Specific Domain (Agirre et al., 2010). While these earlier tasks also experienced improvement, F-Scores remained lower overall. Table 1 above and Figures 1(a) to (i) help highlight what changed between these tasks. 365 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 365–369, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics (g) Biomedical (IT) (i) Social Issues (IT) Degre</context>
<context position="6919" citStr="Navigli et al., 2013" startWordPosition="1143" endWordPosition="1147">nstraint plus a second constraint – that all nouns and named entities must be disambiguated before other parts of speech. For each run, a semantic subgraph is constructed from BabelNet (version 2.5.1). Then for disambiguation the graph centrality measure PageRank (Brin and Page, 1998) is used in conjunction with a surfing vector that biases probability mass to certain sense nodes in the semantic subgraph. This idea is taken from Personalised PageRank (PPR) (Agirre and Soroa, 2009), which applies the method put forward by Haveliwala (2003) to the field of WSD. In the previous SemEval WSD task (Navigli et al., 2013) team UMCC DLSI (Gutierrez et al., 2013) implemented this method and achieved the best performance by biasing probability mass based on SemCor (Miller et al., 1993) sense frequencies. As the winning method for this task, PPR was selected to test the iterative approach on. For SUDOKU’s implementation to be unsupervised, all runs biased probability mass towards senses from monosemous lemmas. Additionally for Run2 and Run3, once a lemma is disambiguated it is considered to be monosemous. Therefore with each iteration of Run2 and Run3, probability mass is redistributed across the surfing vector to</context>
<context position="11773" citStr="Navigli et al., 2013" startWordPosition="1961" endWordPosition="1964"> of verbs and adjectives suffers under the iterative approach. In hindsight, the iterative approach could be restricted to the parts of speech it is known to improve, while remaining with the conventional approach on others. To the right in Table 3 the author’s SUDOKU runs are compared against the team with the most competitive results – LIMSI. The author could not improve on their superior results achieved in English, however for Spanish and Italian the BabelNet First Sense (BFS) baseline was much lower since it often resorted to lexicographic sorting in the absence of WordNet synsets – see (Navigli et al., 2013). The author’s baseline-independent submissions were unaffected by this, which on reviewing results in (Moro and Navigli, 2015) appears to have helped SUDOKU do best for these languages. LIMSI SUDOKU-2 SUDOKU-3 SUDOKU-1 BFS 67.5 SUDOKU-2 SUDOKU-3 SUDOKU-1 LIMSI BFS 37.5 SUDOKU-1 SUDOKU-3 SUDOKU-2 LIMSI BFS 40.2 Table 3: F1 scores for each domain/language for SUDOKU and LIMSI. In summary, the inclusion of named entities in disambiguation tasks certainly improves results, as well as the effectiveness of the iterative approach. Furthermore in Table 3 above, the iterative Run3 for the English Biom</context>
</contexts>
<marker>Navigli, Jurgens, Vannella, 2013</marker>
<rawString>Roberto Navigli, David Jurgens, and Daniele Vannella. 2013. SemEval-2013 Task 12: MultilingualWord Sense Disambiguation. In Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval-2013), pages 222-231. Atlanta, Georgia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roberto Navigli</author>
<author>Simone Paolo Ponzetto</author>
</authors>
<title>BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network.</title>
<date>2012</date>
<journal>Artificial Intelligence,</journal>
<pages>193--217</pages>
<contexts>
<context position="4928" citStr="Navigli and Ponzetto, 2012" startWordPosition="828" endWordPosition="831">of the test documents by querying BabelNet for the polysemy of each word. Each distribution was normalised with one sense per discourse assumed, therefore duplicate synsets were ignored. Lastly the difference in F-Score between the conventional Run1 and the iterative Run2 and Run3 is listed beside each distribution. 366 Firstly WSD tasks before 2013 generally relied on only a lexicon, such as WordNet (Fellbaum, 1998) or an alternative equivalent, whereas SemEval 2013 Task 12 WSD and this task (Moro and Navigli, 2015) included Entity Linking (EL) using the encyclopaedia Wikipedia via BabelNet (Navigli and Ponzetto, 2012). Secondly, as shown by Manion and Sainudiin (2014) with a simple linear regression, the iterative approach increases WSD performance for documents that have a higher degree of document monosemy - the percentage of unique monosemous lemmas in a document. As seen in Figures 1(a) to (i) on the previous page, named entities (or unique rather than common nouns) are more monosemous compared to other parts of speech, especially for more technical domains. Lastly, the SemEval 2013 WSD task differs in that only nouns and named entities required disambiguation. This simplifies the WSD task, as shown in</context>
</contexts>
<marker>Navigli, Ponzetto, 2012</marker>
<rawString>Roberto Navigli and Simone Paolo Ponzetto. 2012. BabelNet: The automatic construction, evaluation and application of a wide-coverage multilingual semantic network. Artificial Intelligence, 193:217–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Snyder</author>
<author>Martha Palmer</author>
</authors>
<title>The English All-Words Task.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3),</booktitle>
<pages>41--43</pages>
<location>Barcelona,</location>
<contexts>
<context position="2926" citStr="Snyder and Palmer, 2004" startWordPosition="474" endWordPosition="477">6.8 ’10 - 73.8 26.2 - - 26.8 +11.1 ’13 17.1 82.9 - - - 58.3 +6.1 ’15 6.0 44.9 28.9 6.5 13.7 55.8 +5.8 Table 1: Parts of Speech disambiguated (as percentages) for each SemEval Task (denoted by its year). In-Degree Centrality as implemented in (Manion and Sainudiin, 2014) observes F-Score improvement (F + ΔF) by applying the iterative approach. The author found in the investigations of his thesis (Manion, 2014) that the iterative approach performed best on the SemEval 2013 Multilingual WSD Task (Navigli et al., 2013), as opposed to earlier tasks such as SensEval 2004 English All Words WSD Task (Snyder and Palmer, 2004) and the SemEval 2010 All Words WSD task on a Specific Domain (Agirre et al., 2010). While these earlier tasks also experienced improvement, F-Scores remained lower overall. Table 1 above and Figures 1(a) to (i) help highlight what changed between these tasks. 365 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 365–369, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics (g) Biomedical (IT) (i) Social Issues (IT) Degree of Polysemy 0.2 ✓ Run2 (+6.5) ✓ Run3 (+8.8) 0.1 0 10 20 30 (a) Biomedical (EN) X Run2 (-1.9) X Run3 (-</context>
</contexts>
<marker>Snyder, Palmer, 2004</marker>
<rawString>Benjamin Snyder and Martha Palmer. 2004. The English All-Words Task. In Proceedings of the 3rd International Workshop on the Evaluation of Systems for the Semantic Analysis of Text (SENSEVAL-3), pages 41-43. Barcelona, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>One Sense Per Collocation.</title>
<date>1993</date>
<booktitle>In Proceedings of the ARPA Workshop on Human Language Technology (HLT’93),</booktitle>
<pages>266--271</pages>
<location>Morristown, New Jersey.</location>
<contexts>
<context position="5580" citStr="Yarowsky (1993)" startWordPosition="935" endWordPosition="936">inudiin (2014) with a simple linear regression, the iterative approach increases WSD performance for documents that have a higher degree of document monosemy - the percentage of unique monosemous lemmas in a document. As seen in Figures 1(a) to (i) on the previous page, named entities (or unique rather than common nouns) are more monosemous compared to other parts of speech, especially for more technical domains. Lastly, the SemEval 2013 WSD task differs in that only nouns and named entities required disambiguation. This simplifies the WSD task, as shown in the experiments on local context by Yarowsky (1993), nouns are best disambiguated by directly adjacent nouns (or modifying adjectives). Based on these observations, the author hypothesized the following implementations of the iterative approach should perform well. 2 System Description &amp; Implementation Run1 (SUDOKU-1) is the conventional approach – no constraints are applied. Formalised in (Manion and Sainudiin, 2014), this run can act as a baseline to gauge any improvement for Run2 and Run3 that apply the iterative approach. Run2 (SUDOKU-2) has the constraint of words being disambiguated in order of increasing polysemy, leaving the most polys</context>
</contexts>
<marker>Yarowsky, 1993</marker>
<rawString>David Yarowsky. 1993. One Sense Per Collocation. In Proceedings of the ARPA Workshop on Human Language Technology (HLT’93), pages 266-271. Morristown, New Jersey.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>