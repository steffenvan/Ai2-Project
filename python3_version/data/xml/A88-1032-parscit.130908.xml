<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<note confidence="0.72991825">
Localizing Expression of Ambiguity
John Bear and Terry R. Hobbs
Artificial Intelligence Center
SRI International
</note>
<sectionHeader confidence="0.978024" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.987714555555556">
In this paper we describe an implemented program for
localizing the expression of many types of syntactic am-
biguity, in the logical forms of sentences, in a manner
convenient for subsequent inferential processing. Among
the types of ambiguities handled are prepositional phrases,
very compound nominals, adverbials, relative clauses, and
preposed prepositional phrases. The algorithm we use is
presented, and several possible shortcomings and exten-
sions of our method are discussed.
</bodyText>
<sectionHeader confidence="0.999648" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999891666666666">
Ambiguity is a problem in any natural language processing
system. Large grammars tend to produce large numbers
of alternative analyses for even relatively simple sentences.
Furthermore, as is well known, syntactic information may
be insufficient for selecting a best reading. It may take se-
mantic knowledge of arbitrary complexity to decide which
alternative to choose.
In the TACITUS project [Hobbs, 1986; Hobbs and
Martin, 1987] we are developing a pragmatics component
which, given the logical form of a sentence, uses world
knowledge to solve various interpretation problems, the
rzzolut:un of syntactic ambiguity among them. Sentences
are translated into logical form by the DIALOGIC system
for syntactic and semantic analysis [Grosz et al., 1982].
In this paper we describe how information about alter-
native parses is passed concisely from DIALOGIC to the
pragmatics component, and more generally, we discuss a
method of localizing the representation of syntactic ambi-
guity in the logical form of a sentence.
One possible approach to the ambiguity problem would
be to produce a set of logical forms for a sentence, one for
each parse tree, and to send them one at a time to the
pragmatics component. This involves considerable dupli-
cation of effort if the logical forms are largely the same
and differ only with respect to attachment. A more effi-
cient approach is to try to localize the information about
the alternate possibilities.
Instead of feeding two logical forms, which differ only
with respect to an attachment site, to a pragmatics com-
ponent, it is worthwhile trying to condense the information
of the two logical forms together into one expression with a
disjunction inside it representing the attachment ambigu-
ity. That one expression may then be given to a pragmat-
ics component with the effect that parts of the sentence
that would have been processed twice are now processed
only once. The savings can be considerably more dramatic
when a set of five or ten or twenty logical forms can be re-
duced to one, as is often the case.
In effect, this approach translates the syntactic ambigu-
ity problem into a highly constrained coreference problem.
It is as though we translated the sentence in (1) into the
two sentences in (2)
</bodyText>
<listItem confidence="0.9980015">
(1) John drove down the street in a car.
(2) John drove down the street. It was in a car.
</listItem>
<bodyText confidence="0.9997840625">
where we knew &amp;quot;it&amp;quot; had to refer either to the street or
to the driving. Since coreference is one of the phenomena
the pragmatics component is designed to cope with [Hobbs
and Martin, 1987], such a translation represents progress
toward a solution.
The rest of this paper describes the procedures we use
to produce a reduced set of logical forms from a larger
set. The basic strategy hinges on the idea of a neu-
tral representation (Hobbs, 19821. This is similar to the
idea behind Church&apos;s Pseudo-attachment [Church, 1980].
Pereira&apos;s Rightmost Normal Form [Pereira, 1083], and
what Rich et al. refer to as the Procrastination Approach
to parsing [Rich, Barnett, Wittenburg, and Whittemore.
1086]. However, by expressing the ambiguity as a disjunc-
tion in logical form, we put it into the form most convenient
for subsequent inferential processing.
</bodyText>
<sectionHeader confidence="0.970917" genericHeader="method">
2 Range of Phenomena
</sectionHeader>
<subsectionHeader confidence="0.999158">
2.1 Attachment Possibilities
</subsectionHeader>
<bodyText confidence="0.996680714285714">
There are three representative classes of attachment ambi-
guities, and we have implemented our approach to each of
these. For each class, we give representative examples and
show the relevant logical form fragments that encode the
set of possible attachments.
In the first class are those constituents that may attach
to either nouns or verbs.
</bodyText>
<listItem confidence="0.975303">
(3) John saw the man with the telescope.
</listItem>
<page confidence="0.997735">
235
</page>
<bodyText confidence="0.952002675675676">
The prepositional phrase (PP) -with the telescope&amp;quot; can be
attached either to -the man&amp;quot; or to &amp;quot;saw&amp;quot;. If In stands for
the man, t for the telescope, and e for the seeing event, the
neutral logical form for the sentence includes
... A with(y,t) A [y=mVy=e] A ...
That is, something y is with the telescope, and it is either
the man or the seeing event.
Gerund modifiers may also modify nouns and verbs, re-
sulting in ambiguities like that in the sentence
I saw the Grand Canyon, flying to New York.
Their treatment is identical to that of PPs. If g is the
Grand Canyon, n is New York, and e is the seeing event,
the neutral logical form will include
... A f/y(y,n) A [y =gV y=elA...
That is, something y is flying to New York, and it is either
the Grand Canyon or the seeing event.
In the second class are those constituents that can only
attach to verbs, such as adverbials.
George said Sam left his wife yesterday.
Here &amp;quot;yesterday&amp;quot; can modify the saying or the leaving but
not &amp;quot;his wife&amp;quot;. Suppose we take yesterday to be a predi-
cate that applies to events and specifies something about
their times of occurrence, and suppose el is the leaving
event and e2 the saying event. Then the neutral logical
form will include
... A yesterday(y) A [y = el V y = e2] A ...
That is, something y was yesterday and it is either the
leaving event or the saying event.
Related to this is the case of a relative clause where
the preposed constituent is a PP, which could have been
extracted from any of several embedded clauses. In
That was the week during which George thought
Sam told his wife he was leaving,
the thinking, the telling, or the leaving could have been
during the week. Let to be the week, el the thinking, ez
the telling, and e3 the leaving. Then the neutral logical
form will include
</bodyText>
<equation confidence="0.763852">
... A during(y,w) A = ei V y = e2
V y = e3J A ...
</equation>
<bodyText confidence="0.9874525">
That is, something y was during the week, and y is either
the thinking, the telling, or the leaving.
The third class contains those constituents that may
only attach to nouns, e.g., relative clauses.
This component recycles the oil that flows
through the compressor that is still good.
The second relative clause, &amp;quot;that is still good,&amp;quot; can attach
to &amp;quot;compressor&amp;quot;, or &amp;quot;oil&amp;quot;, but not to &amp;quot;flows&amp;quot; or &amp;quot;recycles&amp;quot;.
Let o be the oil and c the compressor. Then, ignoring
&amp;quot;still&amp;quot;, the neutral logical form will include
... A good(y) A [y=cVy=o1 A...
That is, something y is still good, and y is either the com-
pressor or the oil.
Similar to this are the compound nominal ambiguities,
as in
He inspected the oil filter element.
&amp;quot;Oil&amp;quot; could modify either &amp;quot;filter&amp;quot; or &amp;quot;element&amp;quot;. Let o be
the oil, f the filter, e the element, and nn the implicit
relation that is encoded by the nominal compound con-
struction. Then the neutral logical form will include
... A nn( f, e) A nn(o, y) A [y=fVy= e] A ...
That is, there is some implicit relation nn between the filter
and the element, and there is another implicit relation nn
between the oil and something y, where y is either the filter
or the element.
Our treatment of all of these types of ambiguity has been
implemented.
In fact, the distinction we base the attachment possi-
bilities on is not that between nouns and verbs, but that
between event variables and entity variables in the logical
form. This means that we would generate logical forms
encoding the attachment of adverbials to event nominal-
izations in those cases where the event nouns are translated
with event variables. Thus in
I read about Judith&apos;s promotion last year.
&amp;quot;last year&amp;quot; would be taken as modifying either the promo-
tion or the reading, if &amp;quot;promotion&amp;quot; were represented by an
event variable in the logical form.
</bodyText>
<subsectionHeader confidence="0.999945">
2.2 Single or Multiple Parse Trees
</subsectionHeader>
<bodyText confidence="0.999943666666667">
In addition to classifying attachment phenomena in terms
of which kind of constituent something may attach to,
there is another dimension along which we need to clas-
sify the phenomena: does the DIALOGIC parser produce
all possible parses, or only one? For some regular struc-
tural ambiguities, such as very compound nominals, and
the &amp;quot;during which&amp;quot; examples, only a single parse is pro-
duced. In this case it is straightforward to produce from
the parse a neutral representation encoding all the possi-
bilities. In the other cases, however, such as (nonpreposed)
PPs, adverbials, and relative clauses, DIALOGIC produces
an exhaustive (and sometimes exhausting) list of the dif-
ferent possible structures. This distinction is an artifact
of our working in the DIALOGIC system. It would be
preferable if there were only one tree constructed which
</bodyText>
<page confidence="0.987944">
236
</page>
<bodyText confidence="0.9997473">
was somehow neutral with respect to attachment. How-
ever, the DIALOGIC grammar is large and complex, and
it would have been difficult to implement such an approach.
Thus, in these cases, one of the parses, the one correspond-
ing to right association [Kimball, 19731, is selected, and the
neutral representation is generated from that. This makes
it necessary to suppress redundant readings, as described
below. (In fact, limited heuristics for suppressing multi-
ple parse trees have recently been implemented in DIA-
LOGIC.)
</bodyText>
<subsectionHeader confidence="0.998589">
2.3 Thematic Role Ambiguities
</subsectionHeader>
<bodyText confidence="0.949856">
Neutral representations are constructed for one other kind
of ambiguity in the TACITUS systemâ€”ambiguities in the
thematic role or case of the arguments. In the sentence
It broke the window.
we don&apos;t know whether &amp;quot;it&amp;quot; is the agent or the instru-
ment. Suppose the predicate break takes three arguments,
an agent, a patient, and an instrument, and suppose x is
whatever is referred to by &amp;quot;it&amp;quot; and w is the window. Then
the neutral logical form will include
... A break(yi, w, Y2) A [yl = x V y2 = x] A ...
That is, something yl breaks the window with something
else 112, and either yi or 112 is whatever is referred to by
4,ic .1
</bodyText>
<subsectionHeader confidence="0.972895">
2.4 Ambiguities Not Handled
</subsectionHeader>
<bodyText confidence="0.998924260869566">
There are other types of structural ambiguity about which
we have little to say. In
They will win one day in Hawaii,
one of the obvious readings is that &amp;quot;one day in Hawaii&amp;quot;
is an adverbial phrase. However, another perfectly rea-
sonable reading is that &amp;quot;one day in Hawaii&amp;quot; is the direct
object of the verb &amp;quot;win&amp;quot;. This is due to the verb having
more than one subcategorization frame that could be filled
by the surrounding constituents. It is the existence of this
kind of ambiguity that led to the approach of not having
DIALOGIC try to build a single neutral representation
in all cases. A neutral representation for such sentences,
though possible, would be very complicated.
Similarly, we do not attempt to produce neutral repre-
sentations for fortuitous or unsystematic ambiguities such
as those exhibited in sentences like
They are flying planes.
Time flies like an arrow.
Becky saw her duck.
&apos;The treatment of thematic role ambiguities has been implemented
by Paul Martin as part of the interface between DIALOGIC and the
pragmatic processes of TACITUS that translates the logical forms of
the sentences into a canonical representation.
</bodyText>
<subsectionHeader confidence="0.993711">
2.5 Resolving Ambiguities
</subsectionHeader>
<bodyText confidence="0.996381857142857">
It is beyond the scope of this paper to describe the prag-
matics processing that is intended to resolve the ambigu-
ities (see Hobbs and Martin, 1987). Nevertheless, we dis-
cuss one nontrivial example, just to give the reader a feel
for the kind of processing it is. Consider the sentence
We retained the filter element for future analysis.
Let r be the retaining event, f the filter element, and a
the analysis. Then the logical form for the sentence will
include
... A for(y, a) A [y =f V y=d A ...
The predicate for, let us say, requires the relation
enable(y, a) to obtain between its arguments. That is, if y
is for a, then either y or something coercible from y must
somehow enable a or something coercible from a. The
TACITUS knowledge base contains axioms encoding the
fact that having something is a prerequisite for analyzing
it and the fact that a retaining is a having. y can thus be
equal to r, which is consistent with the constraints on y.
On the other hand, any inference that the filter element
enables the analysis will be much less direct, and conse-
quently will not be chosen.
</bodyText>
<sectionHeader confidence="0.998697" genericHeader="method">
3 The Algorithm
</sectionHeader>
<subsectionHeader confidence="0.999946">
3.1 Finding Attachment Sites
</subsectionHeader>
<bodyText confidence="0.998000285714286">
The logical forms (LFs) that are produced from each of
the parse trees are given to an attachment-finding program
which adds, or makes explicit, information about possible
attachment sites. Where this makes some LFs redundant,
as in the prepositional phrase case, the redundant LFs are
then eliminated.
For instance, for the sentence in (4),
</bodyText>
<listItem confidence="0.697458">
(4) John saw the man in the park with the telescope.
</listItem>
<bodyText confidence="0.9856185">
DIALOGIC produces five parse trees, and five correspond-
ing logical forms. When the attachment-finding routine is
run on an LF, it annotates the LF with information about
a set of variables that might be the subject (i.e., the at-
tachment site) of each PP.
The example below shows the LFs for one of the five
readings before and after the attachment-finding routine is
run on it. They are somewhat simplified for the purposes
of exposition. In this notation, a proposition is a predi-
cate followed by one or more arguments. An argument is
a variable or a complex term. A complex term is a vari-
able followed by a &amp;quot;such that&amp;quot; symbol &amp;quot;I&amp;quot;, followed by a
conjunction of one or more propositions.&apos; Complex terms
=This notation can be translated into a Russellian notation, with
the consequent loss of information about grammatical subordination,
by repeated application of the transformation p(x p(x) A Q.
</bodyText>
<page confidence="0.984095">
237
</page>
<bodyText confidence="0.99971525">
are enclosed in square brackets for readability. Events are
represented by event variables, as in [Hobbs, 1985], so that
see&apos; (el, xi, x2) means el is a seeing event by x1 of 53.
One of sentence (4)&apos;s LFs before attachment-finding is
</bodyText>
<equation confidence="0.98890675">
pastaei
[SiJohn(si)],
[x2 I man(x2) A
in(x27
jx3I park(x3) A
with(x3,
[54 I telescope(x4)1)])])1)
The same LF after attachment-finding is
past([ei I see&apos; (ei,
[SiI John(zi)],
[Si I man(s2) A
inaYi Iyi = X2 V y= et],
[x3 I park(x3) A
with([Y2 I y2=x3 V y2=52 V
Y2=e11,
(X4 I teleSCOpe(X4)1)1)1)1)
</equation>
<bodyText confidence="0.999859222222222">
A paraphrase of the latter LF in English would be some-
thing like this: There is an event ei that happened in the
past; it is a seeing event by xi who is John, of 52 who is
the man; something yl is in the park, and that something
is either the man or the seeing event; something y2 is with
a telescope, and that something is the park, the man, or
the seeing event.
The procedure for finding possible attachment sites in
order to modify a logical form is as follows. The program
recursively descends an LF, and keeps lists of the event
and entity variables that initiate complex terms. Event
variables associated with tenses are omitted. When the
program arrives at some part of the LF that can have mul-
tiple attachment sites, it replaces the explicit argument by
an existentially quantified variable y, determines whether
it can be an event variable, an entity variable, or either,
and then encodes the list of possibilities for what y could
equal.
</bodyText>
<subsectionHeader confidence="0.985591">
3.2 Eliminating Redundant Logical
Forms
</subsectionHeader>
<bodyText confidence="0.986252620689655">
In those cases where more than one parse tree, and hence
more than one logical form, is produced by DIALOGIC,
it is necessary to eliminate redundant readings. In order
to do this, once the attachment possibilities are registered,
the LFs are flattened (thus losing temporarily the gram-
matical subordination information), and some simplifying
preprocessing is done. Each of the flattened LFs is com-
pared with the others. Any LF that is subsumed by an-
other is discarded as redundant. One LF subsumes another
if the two LFs are the same except that the first has a list
of possible attachment sites that includes the correspond-
ing list in the second. For example, one LF for sentence
(3) says that &amp;quot;with the telescope&amp;quot; can modify either &amp;quot;saw&amp;quot;
or &amp;quot;the man&amp;quot;, and one says that it modifies &amp;quot;saw&amp;quot;. The
first LF subsumes the second, and the second is discarded
and not compared with any other LFs. Thus, although the
LFs are compared pairwise, if all of the ambiguity is due
to only one attachment indeterminacy, each LF is looked
at only once.
Frequently, only some of the alternatives may be thrown
out. For
Andy said he lost yesterday
after attachment-finding, one logical form allows &amp;quot;yester-
day&amp;quot; to be attached to either the saying or the losing, while
another attaches it only to the saying. The second is sub-
sumed by the first, and thus discarded. However, there is
a third reading in which &amp;quot;yesterday&amp;quot; is the direct object of
&amp;quot;lost&amp;quot; and this neither subsumes nor is subsumed by the
others and is retained.
</bodyText>
<sectionHeader confidence="0.99444" genericHeader="method">
4 Lost Information
</sectionHeader>
<subsectionHeader confidence="0.993558">
4.1 Crossing Dependencies
</subsectionHeader>
<bodyText confidence="0.9953865">
Our attachment-finding routine constructs a logical form
that describes all of the standard readings of a sentence,
but it also describes some nonstandard readings, namely
those corresponding to parse trees with crossing branches,
or crossing dependencies. An example would be a reading
of (4) in which the seeing was in the park and the man was
with the telescope.
For small numbers of possible attachment sites, this is
an acceptable result. If a sentence is two-ways ambiguous
(due just to attachment), we get no wrong readings. If it is
five-ways ambiguous on the standard analysis, we get six
readings. However, in a sentence with a sequence of four
PPs, the standard analysis (and the DIALOGIC parser)
get 42 readings, whereas our single disjune.lve LF stands
for 120 different readings.
Two things can be said about what to do in these cases
where the two approaches diverge widely. We could argue
that sentences with such crossing dependencies do exist in
English. There are some plausible sounding examples.
Specify the length, in bytes, of the word.
Kate saw a man on Sunday with a wooden leg.
In the first, the phrase &amp;quot;in bytes&amp;quot; modifies &amp;quot;specify&amp;quot;, and
&amp;quot;of the word&amp;quot; modifies &amp;quot;the length&amp;quot;. In the second, &amp;quot;on
Sunday&amp;quot; modifies &amp;quot;saw&amp;quot; and &amp;quot;with a wooden leg&amp;quot; modifies
&amp;quot;a man&amp;quot;. Stucky [1987] argues that such examples are
acceptable and quite frequent.
On the other hand, if one feels that these putative ex-
amples of crossing dependencies can be explained away
</bodyText>
<page confidence="0.994419">
238
</page>
<bodyText confidence="0.999938225806452">
and should be ruled out. there is a way to do it within
our framework. One can encode in the LFs a crossing-
dependencies constraint, and consult that constraint when
doing the pragmatic processing.
To handle the crossing-dependencies constraint (which
we have not yet implemented), the program would need
to keep the list of the logical variables it constructs. This
list would contain three kinds of variables, event variables,
entity variables, and the special variables (the y&apos;s in the
LFs above) representing attachment ambiguities. The list
would keep track of the order in which variables were en-
countered in descending the LF. A separate list of just the
special y variables also needs to be kept. The strategy
would be that in trying to resolve referents, whenever one
tries to instantiate a y variable to something, the other y
variables need to be checked, in accordance with the fol-
lowing constraint:
There cannot be yj, 112 in the list of y&apos;s such that
B(y1) &lt; B(112) &lt; yj &lt; y2, where B(y) is the
proposed variable to which yi will be bound
or with which it will be coreferential, and the
&lt; operator means &amp;quot;precedes in the list of vari-
ables&amp;quot;.
This constraint handles a single phrase that has attach-
ment ambiguities. It also works in the case where there is
a string of PPs in the subject NP, and then a string of PPs
in the object NP, as in
The man with the telescope in the park lounged
on the bank of a river in the sun.
With the appropriate crossing-dependency constraints, the
logical form for this would be&apos;
</bodyText>
<equation confidence="0.973147058823529">
past(ki I oung e&apos;(ei,
[x1 man(xi) A
wit haYi = Si V yj = ei],
(52 I telescope(x2) A
inay21Y2=x2V y2=xi V
Y2 =e1],
[531 park(x3)1)])]) A
on(ei,
[54 I bank(s4) A
01(1Y3 1 Y3 = V y3 = ed,
[55 I river(x6) A
in([Y4 IY4=x5 V Y4=x4 V Y4=ed,
[56 I sun(x6)D1)1) A
crossing-in fo(&lt;ei , xi, y, x2, 112, x3&gt;,
{Y142}) A
crossing-in f o(&lt;ei, x4, y3, 55, y4, 56&gt;,
{y3, N})])
</equation>
<bodyText confidence="0.48911">
3We are assuming &amp;quot;with the telescope&amp;quot; and &amp;quot;in the park&amp;quot; can mod-
ify the lounging, which they certainly can if we place commas before
and after them.
</bodyText>
<subsectionHeader confidence="0.946198">
4.2 Noncoreference Constraints
</subsectionHeader>
<bodyText confidence="0.98551855">
One kind of information that is provided by the DIA-
LOGIC system is information about coreference and non-
coreference insofar as it can be determined from syntactic
structure. Thus, the logical form for
John saw him.
includes the information that &amp;quot;John&amp;quot; and &amp;quot;him&amp;quot; cannot
be coreferential. This interacts with our localization of
attachment ambiguity. Consider the sentence,
John returned Bill&apos;s gift to him.
If we attach &amp;quot;to him&amp;quot; to &amp;quot;gift&amp;quot;, &amp;quot;him&amp;quot; can be coreferential
with &amp;quot;John&amp;quot; but it cannot be coreferential with &amp;quot;Bill&amp;quot;. If
we attach it to &amp;quot;returned&amp;quot;, &amp;quot;him&amp;quot; can be coreferential with
&amp;quot;Bill&amp;quot; but not with &amp;quot;John&amp;quot;. It is therefore not enough to
say that the &amp;quot;subject&amp;quot; of &amp;quot;to&amp;quot; is either the gift or the re-
turning. Each alternative carries its own noncoreference
constraints with it. We do not have an elegant solution to
this problem. We mention it because, to our knowledge,
this interaction of noncoreference constraints and PP at-
tachment has not been noticed by other researchers taking
similar approaches.
</bodyText>
<sectionHeader confidence="0.916258" genericHeader="method">
5 A Note on Literal Meaning
</sectionHeader>
<bodyText confidence="0.999964652173913">
There is an objection one could make to our whole ap-
proach. If our logical forms are taken to be a represen-
tation of the &amp;quot;literal meaning&amp;quot; of the sentence, then we
would seem to be making the claim that the literal mean-
ing of sentence (2) is &amp;quot;Using a telescope, John saw a man,
or John saw a man who had a telescope,&amp;quot; whereas the real
situation is that either the literal meaning is &amp;quot;Using a tele-
scope, John saw a man,&amp;quot; or the literal meaning is &amp;quot;John
saw a man who had a telescope.&amp;quot; The disjunction occurs
in the metalanguage, whereas we may seem to be claiming
it is in the language.
The misunderstanding behind this objection is that the
logical form is not intended to represent &amp;quot;literal meaning&amp;quot;.
There is no general agreement on precisely what consti-
tutes &amp;quot;literal meaning&amp;quot;, or even whether it is a coherent
notion. In any case, few would argue that the meaning of
a sentence could be determined on the basis of syntactic
information alone. The logical forms produced by the DI-
ALOGIC system are simply intended to encode all of the
information that syntactic processing can extract about
the sentence. Sometimes the best we can come up with
in this phase of the processing is disjunctive information
about attachment sites, and that is what the LF records.
</bodyText>
<page confidence="0.998115">
239
</page>
<sectionHeader confidence="0.990524" genericHeader="method">
6 Future Extensions
</sectionHeader>
<subsectionHeader confidence="0.999965">
6.1 Extending the Range of Phenomena
</subsectionHeader>
<bodyText confidence="0.981077892857143">
The work that has been done demonstrates the feasibility
of localizing in logical form information about attachment
ambiguities. There is some mundane programming to do
to handle the cases similar to those described here, e.g.,
other forms of postnominal modification. There is also the
crossing-dependency constraint to implement.
The principal area in which we intend to extend our
approach is various kinds of conjunction ambiguities. Our
approach to some of these cases is quite similar to what
we have presented already. In the sentence,
(5) Mary told us John was offended and George left
the party early.
it is possible for George&apos;s leaving to be conjoined with ei-
ther John&apos;s being offended or Mary&apos;s telling. Following
Hobbs [1985], conjunction is represented in logical form by
the predicate and&apos; taking a self argument and two event
variables as its arguments. In (5) suppose ei stands for the
telling, ex for the being offended, e3 for the leaving, and eo
for the conjunction. Then the neutral representation for
(5) would include
and(eo, yo, e3) A telP(ei, M,
A ((Yo = ei A y = e2) V (yo = ex A y eo))
That is, there is a conjunction eo of yo and the leaving e3;
there is a telling el by Mary of yi; and either yo is the
telling el and yi is the being offended e2, or yo is the being
offended e2 and yi is the conjunction eo.
A different kind of ambiguity occurs in noun phrase con-
junction. In
</bodyText>
<listItem confidence="0.943917">
(6) Where are the British and American ships?
</listItem>
<bodyText confidence="0.643308">
there is a set of British ships and a disjoint set of American
ships, whereas in
</bodyText>
<listItem confidence="0.845155">
(7) Where are the tall and handsome men?
</listItem>
<bodyText confidence="0.99593575">
the natural interpretation is that a single set of men is
desired, consisting of men who are both tall and handsome.
In TACITUS, noun phrase conjunction is encoded with
the predicate andn, taking three sets as its arguments.
The expression andn(s1,8203) means that the set 85 is
the union of sets 32 and 33.4 Following Hobbs [1983], the
representation of plurals involves a set and a typical ele-
ment of the set, or a reified universally quantified variable
ranging over the elements of the set. Properties like cardi-
nality are properties of the set itself, while properties that
hold for each of the elements are properties of the typical
element. An axiom schema specifies that any properties of
</bodyText>
<footnote confidence="0.8464185">
4 If either st or 33 is not a set, the singleton set consisting of just
that element is used instead.
</footnote>
<bodyText confidence="0.999228333333333">
the typical element are inherited by the individual, actual
elements.&apos; Thus, the phrase &amp;quot;British and American ships&amp;quot;
is translated into the set si such that
</bodyText>
<equation confidence="0.450938333333333">
andn(si, s2, s3) A typelt(x , si) A ship(xi)
A typelt(x2, s2) A British(x2)
A typelt(s3, s3) A American(x3)
</equation>
<bodyText confidence="0.999282833333333">
That is, the typical element xi of the set 31 is a ship, and
S1 is the union of the sets 52 and 33, where the typical
element 52 of 32 is British, and the typical element x3 of
33 is American.
The phrase &amp;quot;tall and handsome men&amp;quot; can be represented
in the same way.
</bodyText>
<construct confidence="0.498136333333333">
andn(si, 32, s3) A typelt(xi, si) A man(s1)
A typelt(x2, s2) A tall(x2)
A typelt(x3, 33) A handsome(x3)
</construct>
<bodyText confidence="0.99519575">
Then it is a matter for pragmatic processing to discover
that the set 82 of tall men and the set 33 of handsome men
are in fact identical.
In this representational framework, the treatment given
to the kind of ambiguity illustrated in
I like intelligent men and women.
resembles the treatment given to attachment ambiguities.
The neutral logical form would include
</bodyText>
<figure confidence="0.82514225">
... A andn(si, s2, s3) A typelt(x , si)
A typelt(x2, 32) A man(x2)
A typelt(x3, s3) A woman(s3)
A intelligent(y) A [y = xi V y = 52]
</figure>
<bodyText confidence="0.999312736842105">
That is, there is a set si, with typical element xi, which is
the union of sets S2 and 33, where the typical element S2
of S2 is a man and the typical element 53 of s3 is a woman,
and something y is intelligent, where y is either the typical
element xi of si (the typical person) or the typical element
52 of 32 (the typical man).
Ambiguities in conjoined compound nominals can be
represented similarly. The representation for
oil pump and filter
would include
... A andn(s, p, f) A typelt(x , s) A pump(p)
A filter( f) A oil(o) A nn(o, y)
A [y .pV y=s1
That is, there is a set s, with typical element x, composed
of the elements p and f, where p is a pump and f is a filter,
and there is some implicit relation nn between some oil o
and y, where y is either the pump p or the typical element
x or s. (In the latter case, the axiom in the TACITUS
system&apos;s knowledge base,
</bodyText>
<footnote confidence="0.89315">
5The reader may with some justification feel that the term &amp;quot;typical
element&amp;quot; is ill-chosen. He or she is invited to suggest a better term.
</footnote>
<page confidence="0.98293">
240
</page>
<bodyText confidence="0.6832486">
(V tv, x, y, s)nn(w, x) A typelt(x , s)
A andn(s, y,
nn(w, , y) A n72(w, z)
allows the nn relation to be distributed to the two con-
juncts.)
</bodyText>
<subsectionHeader confidence="0.998878">
6.2 Ordering Heuristics
</subsectionHeader>
<bodyText confidence="0.992592769230769">
So far we have only been concerned with specifying the
set of possible attachment sites. However, it is true, em-
pirically, that certain attachment sites can be favored over
others, strictly on the basis of syntactic (and simple se-
mantic) information alone.&apos;
For example, for the prepositional phrase attachment
problem, an informal study of several hundred examples
suggests that a very good heuristic is obtained by using
the following three principles: (1) favor right association;
(2) override right association if (a) the PP is temporal and
the second nearest attachment site is a verb or event nom-
inalization, or (b) if the preposition typically signals an
argument of the second nearest attachment site (verb or
relational noun) and not of the nearest attachment site;
(3) override right association if a comma (or comma into-
nation) separates the PP from the nearest attachment site.
The preposition&amp;quot;of&amp;quot; should be treated specially; for &amp;quot;of&amp;quot;
PPs, right association is correct over 98% of the time.
There are two roles such a heuristic ordering of possibil-
ities can play. In a system without sophisticated seman-
tic or pragmatic processing, the favored attachment could
simply be selected. On the other hand, in a system such
as TACITUS in which complex inference procedures access
world knowledge in interpreting a text, the heuristic order-
ing can influence an allocation of computational resources
to the various possibilities.
</bodyText>
<sectionHeader confidence="0.996903" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998978">
The authors have profited from discussions with Stu
Shieber about this work. The research was funded by the
Defense Advanced Research Projects Agency under Office
of Naval Research contract N00014-85-C-0013.
</bodyText>
<sectionHeader confidence="0.999054" genericHeader="conclusions">
References
</sectionHeader>
<reference confidence="0.994408673469388">
[1] Dowty, David, Lauri Karttunen, and Arnold Zwicky
(1985) Natural Language Parsing, Cambridge University
Press.
[2] Church, Kenneth (1980) &amp;quot;On Memory Limitations in
Natural Language Processing&amp;quot;, Technical Note, MIT
Computer Science Lab, MIT.
6There is a vast literature on this topic. For a good introduction,
see Dowty, Karttunen, and Zwicky (1985].
[3] Church, Kenneth, and Ramesh Patil (1982) &amp;quot;Coping
with Syntactic Ambiguity or How to Put the Block in
the Box on the Table&amp;quot;, AJCL, Vol S. No 3-4.
[4] Grosz, Barbara, Norman Haas, Gary Hendrix, Jerry
Hobbs, Paul Martin, Robert Moore, Jane Robin-
son, Stanley Rosenschein (1982) &amp;quot;DIALOGIC: A Core
Natural-Language Processing System&amp;quot;, Technical Note
270, Artificial Intelligence Center, SRI International.
[5] Hirst, Graeme (1986) &amp;quot;Semantic Interpretation and
Ambiguity&amp;quot;, to appear in Artificial Intelligence.
[6] Hobbs, Jerry (1982) &amp;quot;Representing Ambiguity&amp;quot;, Pro-
ceedings of the First West Coast Conference on For-
mal Linguistics, Stanford University Linguistics Depart-
ment, pp. 15-28.
[7] Hobbs, Jerry (1983) &amp;quot;An Improper Approach to Quan-
tification in Ordinary English&amp;quot;, Proceedings of the 21st
Annual Meeting of the Association for Computational
Linguistics, Cambridge, Massachusetts, pp. 57-63.
[8] Hobbs, Jerry (1985) &amp;quot;Ontological Promiscuity&amp;quot;, Pro-
ceedings of the 23rd Annual Meeting of the Association
for Computational Linguistics, Chicago, Illinois, pp. 61-
69.
[9] Hobbs, Jerry (1986) &amp;quot;Overview of the TACITUS
Project&amp;quot;, CL, Vol. 12, No. 3.
[10] Hobbs, Jerry, and Paul Martin (1987) &amp;quot;Local Prag-
matics&amp;quot;, Proceedings of the Tenth International Joint
Conference on Artificial Intelligence, Milano, Italy, pp.
520-523.
[11] Kimball, John (1973) &amp;quot;Seven Principles of Surface
Structure Parsing&amp;quot;, Cognition, Vol. 2, No. 1, pp. 15-47.
[12] Pereira, Fernando (1983) &amp;quot;Logic for Natural Language
Analysis&amp;quot;, Technical Note 275, Artificial Intelligence
Center, SRI International.
[13] Rich, Elaine, Jim Barnett, Kent Wittenburg, and
Greg Whittemore (1986) &amp;quot;Ambiguity and Procrastina-
tion in NL Interfaces&amp;quot;, Technical Note HI-073-86, MCC.
[14] Stucky, Susan (1987) &amp;quot;Configurational Variation in
English: A Study of Extraposition and Related Mat-
ters&amp;quot;, in Syntax and Semantics: Discontinuous Con-
stituency, Vol. 20, edited by G. Huck and A. Ojeda,
Academic Press.
</reference>
<page confidence="0.998212">
241
</page>
<sectionHeader confidence="0.815947" genericHeader="references">
Appendix
</sectionHeader>
<bodyText confidence="0.642585">
John saw the man with the telescope.
Logical Form before Attachment-Finding:
</bodyText>
<figure confidence="0.8665091875">
((PAST
(SELF Ell)
(SUBJECT
(E3
(SEE
(SELF E3)
(SUBJECT (X1 (JOHN (SELF E2) (SUBJECT X1))))
(OBJECT (X4 (MAN (SELF ES) (SUBJECT X4))
(WITH (SELF E6)
(PP-SUBJECT X4) ; &lt;-- [with] modifies [man]
(OBJECT (X7 (TELESCOPE (SELF E8) (SUBJECT X7))
(THE (SELF E9) (SUBJECT X7))
(NOT= (NP X7) (ANTES (X4))))))
(THE (SELF E10) (SUBJECT X4))
(NOT= (NP X4) (ANTES (X1))))))))))
Logical Form after Attachment-Finding:
((PAST
(SELF Ell)
(SUBJECT
(E3
(SEE
(SELF E3)
(SUBJECT (X1 (JOHN (SELF E2) (SUBJECT X1))))
(OBJECT (X4 (MAN (SELF ES) (SUBJECT X4))
(WITH (SELF E6)
(SUBJECT (Y14 (?= (NP Y14) ; &lt;-- [with] modifies [man] or [saw]
(ANTES (X4 E3)))))
(OBJECT (X7 (TELESCOPE (SELF E8) (SUBJECT X7))
(THE (SELF E9) (SUBJECT X7))
(NOT= (NP X7) (ANTES (X4))))))
(THE (SELF E10) (SUBJECT X4))
(NOT= (NP X4) (ANTES (X1))))))))))
</figure>
<page confidence="0.975388">
242
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.985692">
<title confidence="0.999593">Localizing Expression of Ambiguity</title>
<author confidence="0.99975">John Bear</author>
<author confidence="0.99975">Terry R Hobbs</author>
<affiliation confidence="0.9992785">Artificial Intelligence Center SRI International</affiliation>
<abstract confidence="0.998735">In this paper we describe an implemented program for localizing the expression of many types of syntactic ambiguity, in the logical forms of sentences, in a manner convenient for subsequent inferential processing. Among the types of ambiguities handled are prepositional phrases, very compound nominals, adverbials, relative clauses, and preposed prepositional phrases. The algorithm we use is presented, and several possible shortcomings and extensions of our method are discussed.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Dowty</author>
<author>Lauri Karttunen</author>
<author>Arnold Zwicky</author>
</authors>
<title>Natural Language Parsing,</title>
<date>1985</date>
<publisher>Cambridge University Press.</publisher>
<marker>[1]</marker>
<rawString>Dowty, David, Lauri Karttunen, and Arnold Zwicky (1985) Natural Language Parsing, Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
</authors>
<title>On Memory Limitations in Natural Language Processing&amp;quot;,</title>
<date>1980</date>
<tech>Technical Note,</tech>
<institution>MIT Computer Science Lab, MIT.</institution>
<marker>[2]</marker>
<rawString>Church, Kenneth (1980) &amp;quot;On Memory Limitations in Natural Language Processing&amp;quot;, Technical Note, MIT Computer Science Lab, MIT. 6There is a vast literature on this topic. For a good introduction, see Dowty, Karttunen, and Zwicky (1985].</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>Ramesh Patil</author>
</authors>
<title>Coping with Syntactic Ambiguity or How to Put the Block in the Box on the Table&amp;quot;,</title>
<date>1982</date>
<journal>AJCL, Vol S. No</journal>
<pages>3--4</pages>
<marker>[3]</marker>
<rawString>Church, Kenneth, and Ramesh Patil (1982) &amp;quot;Coping with Syntactic Ambiguity or How to Put the Block in the Box on the Table&amp;quot;, AJCL, Vol S. No 3-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Grosz</author>
<author>Norman Haas</author>
<author>Gary Hendrix</author>
<author>Jerry Hobbs</author>
<author>Paul Martin</author>
</authors>
<title>DIALOGIC: A Core Natural-Language Processing System&amp;quot;, Technical Note 270, Artificial Intelligence Center,</title>
<date>1982</date>
<publisher>SRI International.</publisher>
<location>Robert Moore, Jane Robinson, Stanley Rosenschein</location>
<marker>[4]</marker>
<rawString>Grosz, Barbara, Norman Haas, Gary Hendrix, Jerry Hobbs, Paul Martin, Robert Moore, Jane Robinson, Stanley Rosenschein (1982) &amp;quot;DIALOGIC: A Core Natural-Language Processing System&amp;quot;, Technical Note 270, Artificial Intelligence Center, SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
</authors>
<title>Semantic Interpretation and Ambiguity&amp;quot;, to appear in</title>
<date>1986</date>
<journal>Artificial Intelligence.</journal>
<marker>[5]</marker>
<rawString>Hirst, Graeme (1986) &amp;quot;Semantic Interpretation and Ambiguity&amp;quot;, to appear in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>Representing Ambiguity&amp;quot;,</title>
<date>1982</date>
<booktitle>Proceedings of the First West Coast Conference on Formal Linguistics,</booktitle>
<pages>15--28</pages>
<institution>Stanford University Linguistics Department,</institution>
<marker>[6]</marker>
<rawString>Hobbs, Jerry (1982) &amp;quot;Representing Ambiguity&amp;quot;, Proceedings of the First West Coast Conference on Formal Linguistics, Stanford University Linguistics Department, pp. 15-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>An Improper Approach to Quantification in Ordinary English&amp;quot;,</title>
<date>1983</date>
<booktitle>Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>57--63</pages>
<location>Cambridge, Massachusetts,</location>
<marker>[7]</marker>
<rawString>Hobbs, Jerry (1983) &amp;quot;An Improper Approach to Quantification in Ordinary English&amp;quot;, Proceedings of the 21st Annual Meeting of the Association for Computational Linguistics, Cambridge, Massachusetts, pp. 57-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>Ontological Promiscuity&amp;quot;,</title>
<date>1985</date>
<booktitle>Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>61--69</pages>
<location>Chicago, Illinois,</location>
<marker>[8]</marker>
<rawString>Hobbs, Jerry (1985) &amp;quot;Ontological Promiscuity&amp;quot;, Proceedings of the 23rd Annual Meeting of the Association for Computational Linguistics, Chicago, Illinois, pp. 61-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
</authors>
<title>Overview of the TACITUS Project&amp;quot;,</title>
<date>1986</date>
<journal>CL,</journal>
<volume>12</volume>
<marker>[9]</marker>
<rawString>Hobbs, Jerry (1986) &amp;quot;Overview of the TACITUS Project&amp;quot;, CL, Vol. 12, No. 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerry Hobbs</author>
<author>Paul Martin</author>
</authors>
<title>Local Pragmatics&amp;quot;,</title>
<date>1987</date>
<booktitle>Proceedings of the Tenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>520--523</pages>
<location>Milano, Italy,</location>
<marker>[10]</marker>
<rawString>Hobbs, Jerry, and Paul Martin (1987) &amp;quot;Local Pragmatics&amp;quot;, Proceedings of the Tenth International Joint Conference on Artificial Intelligence, Milano, Italy, pp. 520-523.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Kimball</author>
</authors>
<title>Seven Principles of Surface Structure Parsing&amp;quot;,</title>
<date>1973</date>
<journal>Cognition,</journal>
<volume>2</volume>
<pages>15--47</pages>
<marker>[11]</marker>
<rawString>Kimball, John (1973) &amp;quot;Seven Principles of Surface Structure Parsing&amp;quot;, Cognition, Vol. 2, No. 1, pp. 15-47.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
</authors>
<title>Logic for Natural Language Analysis&amp;quot;,</title>
<date>1983</date>
<journal>Technical Note 275, Artificial Intelligence Center, SRI International.</journal>
<marker>[12]</marker>
<rawString>Pereira, Fernando (1983) &amp;quot;Logic for Natural Language Analysis&amp;quot;, Technical Note 275, Artificial Intelligence Center, SRI International.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elaine Rich</author>
<author>Jim Barnett</author>
<author>Kent Wittenburg</author>
<author>Greg Whittemore</author>
</authors>
<title>Ambiguity and Procrastination in NL Interfaces&amp;quot;,</title>
<date>1986</date>
<tech>Technical Note HI-073-86, MCC.</tech>
<marker>[13]</marker>
<rawString>Rich, Elaine, Jim Barnett, Kent Wittenburg, and Greg Whittemore (1986) &amp;quot;Ambiguity and Procrastination in NL Interfaces&amp;quot;, Technical Note HI-073-86, MCC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Stucky</author>
</authors>
<title>Configurational Variation in English: A Study of Extraposition and Related Matters&amp;quot;,</title>
<date>1987</date>
<booktitle>in Syntax and Semantics: Discontinuous Constituency,</booktitle>
<volume>20</volume>
<publisher>Academic Press.</publisher>
<note>edited by</note>
<marker>[14]</marker>
<rawString>Stucky, Susan (1987) &amp;quot;Configurational Variation in English: A Study of Extraposition and Related Matters&amp;quot;, in Syntax and Semantics: Discontinuous Constituency, Vol. 20, edited by G. Huck and A. Ojeda, Academic Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>