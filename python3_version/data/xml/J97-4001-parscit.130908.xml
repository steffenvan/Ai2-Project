<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99781975">
Algorithms for Grapheme-Phoneme
Translation for English and French:
Applications for Database Searches and
Speech Synthesis
</title>
<author confidence="0.999261">
Michel Diyay* Anthony J. Vital&amp;
</author>
<affiliation confidence="0.740831">
Universite de Rennes Digital Equipment Corporation
</affiliation>
<bodyText confidence="0.997653333333333">
Letter-to-sound rules, also known as grapheme-to-phoneme rules, are important computational
tools and have been used for a variety of purposes including word or name lookups for database
searches and speech synthesis.
These rules are especially useful when integrated into database searches on names and ad-
dresses, since they can complement orthographic search algorithms that make use of permutation,
deletion, and insertion by allowing for a comparison with the phonetic equivalent. In databases,
phonetics can help retrieve a word or a proper name without the user needing to know the correct
spelling. A phonetic index is built with the vocabulary of the application. This could be an entire
dictionary, or a list of proper names. The searched word is then converted into phonetics and
retrieved with its information, ff the word is in the phonetic index. This phonetic lookup can be
used to retrieve a misspelled word in a dictionary or a database, or in a text editor to suggest
corrections.
Such rules are also necessary to formalize grapheme-phoneme correspondences in speech
synthesis architecture. In text-to-speech systems, these rules are typically used to create phonemes
from computer text. These phonemic symbols, in turn, are used to feed lower-level phonetic
modules (such as timing, intonation, vowel formant trajectories, etc.) which, in turn, feed a vocal
tract model and finally output a waveform and, via a digital-analogue converter, synthesized
speech. Such rules are a necessary and integral part of a text-to-speech system since a database
lookup (dictionary search) is not sufficient to handle derived forms, new words, nonce forms,
proper nouns, low-frequency technical jargon, and the like; such forms typically are not included
in the database. And while the use of a dictionary is more important now that denser and faster
memory is available to smaller systems, letter-to-sound still plays a crucial and central role in
speech synthesis technology.
Grapheme-to-phoneme technology is also useful in speech recognition, as a way of generating
pronunciations for new words that may be available in grapheme form, or for naive users to add
new words more easily. In that case, the system must generate the multiple variations of the word.
While there are different problems in languages that use non-alphabetic writing systems
(syllabaries, as in Japanese, or logographic systems, as in Chinese) (DeFrancis 1984), all alphabetic
systems have a structured set of correspondences. These range from the trivial in languages like
Spanish or Swahili, to extremely complex in languages such as English and French. This paper
</bodyText>
<affiliation confidence="0.405311666666667">
* Universite de Rennes, Institut Universitaire de Technologie, B.P. 150, 22302 Lannion, France. E-mail:
divay@iut-lannion.fr
t Digital Equipment Corporation, 200 Forest St. (MR01-1/L31), Marlborough, MA 01752-3011. E-mail:
</affiliation>
<email confidence="0.817272">
yitale@dectlk.enet.dec.com
</email>
<note confidence="0.9605645">
C) 1997 Association for Computational Linguistics
Computational Linguistics Volume 23, Number 4
</note>
<bodyText confidence="0.673614">
will outline some of the previous attempts to construct such rule sets and will describe new and
successful approaches to the construction of letter-to-sound rules for English and French.
</bodyText>
<sectionHeader confidence="0.83291" genericHeader="abstract">
1. Introduction and Historical Background
</sectionHeader>
<bodyText confidence="0.999779673913044">
The interest in letter-to-sound rules goes back centuries and can be found (in relatively
unsystematic descriptions) in many of the older descriptive grammars of languages
such as English and French. The paucity of literature in grapheme-to-phoneme transla-
tion is partially due to the fact that the field of linguistics, and in particular, descriptive
linguistics, has traditionally shied away from the writing system (except as a study in
its own right) since the phonological system was considered of primary importance.
Papers on the subject are rarely found in linguistics journals. Nevertheless, there have
been some important studies done on grapheme-phoneme correspondences in past
years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly
(1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980),
Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky
(1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964);
for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach
and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte
(1988), Prouts (1980), Yvon (1996).
Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in
nature and represented a solid base of data from which a rule set could be built. These
works consisted of tables of correspondences and examples of words containing these
correspondences. These studies made use of phonetic, phonemic, or even morpho-
phonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alter-
nation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies
included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985).
More recent studies have attempted to use learning algorithms to incorporate pro-
nunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist
approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991;
Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an in-
duction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman
1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hid-
den Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding
1991). Some have even developed a bidirectional approach of letter-to-sound as well
as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven ap-
proaches and is also useful for automatic speech recognition. This paper will focus on
a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b,
1991, 1994), and others, all of which are essentially knowledge-rich expert systems.
The various attempts at rule formulation were related to differences in the phone-
mic inventory, the number of rules, the type and format of rules, and even the direction
of parse of the rules (whether they were scanned from left to right or from right to left).
Different approaches were also taken in the size of the dictionary, the algorithm used
to scan or rescan the dictionary (if one was used), the methods for determining lexical
stress placement, the amount of morphological analysis used, and the difficulties in
the prediction of the correct phonemic form of homographs.
Part of the educational process for a child is learning to read, and educational
literature is filled with disparate pedagogical approaches to this problem. Developing
a letter-to-sound rule set in software is essentially teaching the computer how to read
(pronounce) a language. The difficulty in developing an accurate algorithm to perform
this task is directly proportional to the fit between graphemes and corresponding
</bodyText>
<page confidence="0.997123">
496
</page>
<note confidence="0.485398">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<bodyText confidence="0.855357">
phonemes as well as the allophonic complexity of the language in question.
</bodyText>
<sectionHeader confidence="0.856315" genericHeader="method">
2. Dictionary versus Letter-to-Sound Rules
</sectionHeader>
<bodyText confidence="0.999975820512821">
Any procedure to convert text into phonemes would necessarily make use of a lexical
database or dictionary to provide for lookup of words prior to letter-to-sound conver-
sion. Such a database typically consists of words that exhibit unusual stress patterns
(for languages such as English), and of unassimilated or partially assimilated loan-
words including place names and personal names that do not fit into the canonical
phonological or phonotactic form of the language.
Memory is increasingly less expensive and we now have the capability to store in
memory a large number of words (along with their phonetic equivalent, grammatical
class, and meaning). Why not then store all words (or certainly all of the words that
would be commonly encountered in text) in memory? First, if we include derived
forms and technical jargon, there are well over three-quarters of a million words in
the English or French language. It would be an extremely difficult task to create such
a list. More importantly, new words come into the language every day and from
these are generated many derived forms. Lastly, when we factor in items that may
not even be found in a dictionary, such as proper nouns (first names, surnames, place
names, names of corporations, etc.), the necessity of a rule-governed approach quickly
becomes apparent. For example, there are roughly 1.5 million different surnames in
the US alone (Spiegel 1985; Spiegel and Machi 1990; Vitale 1991); moreover, one-third
of these surnames are unique in that they are singletons. In fact, at this stage in the
technology, it is still the rule set and not the dictionary that is the more dominant,
although this is beginning to change, primarily due to the need for more complex
lexical entry containing information on syntax, semantics, and even pragmatics for
more natural prosodics in text-to-speech tasks.
It is difficult and time consuming to place all derived forms in the dictionary,
including singular and plural forms and all verb affixes, especially for a language
like French where a verb can expand, depending on the conjugation, into about fifty
strings consisting of the root plus suffixes. Code could, of course, be added in the
dictionary modules providing information on how to form the plurals or conjugations.
The lookup procedure could then strip some of the affixes to retrieve the root in the
dictionary.
There do exist letter-to-sound systems based on very large dictionaries (for French,
see Laporte [19881) but they require a great deal of memory, especially if the lexical
entries contain graphemic, phonetic, syntactic, and semantic information. The main
advantage is that this dictionary can then be used to drive a sentence tagger and
parser necessary for improving intonation and naturalness for speech synthesis. This
universal electronic dictionary could also be used for speech recognition and machine
translation. Today, most speech synthesizers do not include such a large dictionary,
which, in any case, must be complemented by a set of rules just in case the word or
the proper name is not in the dictionary.
</bodyText>
<sectionHeader confidence="0.661536" genericHeader="method">
3. Grapheme-to-Phoneme Conversion Problems for Both English and French
</sectionHeader>
<bodyText confidence="0.947183666666667">
In this section, we describe the problems encountered when converting from graphemes
to phonemes for English and French. Some problems are similar in both languages,
others are specific to one language or the other.
</bodyText>
<page confidence="0.994878">
497
</page>
<note confidence="0.886658">
Computational Linguistics Volume 23, Number 4
</note>
<subsectionHeader confidence="0.7359635">
3.1 History Results in an Incoherent Letter-to-Sound System for Both English and
French
</subsectionHeader>
<bodyText confidence="0.999801547619048">
English and French are difficult languages to construct letter-to-sound rules for.
Grapheme-phoneme correspondences in English are complex, primarily due to non-
linguistic factors related to the aftermath of the Norman invasion (1066 A.D.) as well
as various waves of immigration into anglophone countries such as the UK and the
US. The sound system has undergone many shifts, including the addition of the /f /-
/v/ phonemic distinction under the influence of massive borrowing from French, the
Great Vowel Shift (1400-1500 A.D.) (Wells 1982), and others. It has been estimated that
external borrowing has been so extensive that English has retained only about 25% of
its original Germanic lexicon (Ben Crane 1981). A quick scan of a text in Old English
is enough to convince the reader of this. Since the late Middle Ages, due to the avail-
ability of printed materials, dictionaries and grammars, the orthographic system has
remained virtually unchanged.
Letter-to-sound transcription for French is complex because a gap has slowly ap-
peared between the orthographic and phonetic forms at the inception of what we
would call French (about the 12th Century), and the orthographic and phonetic forms
at the current time. Prior to the Roman invasion in 51 B.C., inhabitants of northern
France (called at that time Gallia) spoke a Celtic language. The Roman occupation
(which lasted until 476 A.D.) resulted in well-educated people speaking Latin; for oth-
ers, a language derived from Latin. After the Roman pullback, the language continued
to evolve in different ways, especially since few people knew how to read. The first
written texts in the new language, called Roman ([romal), appear only in the 9th Cen-
tury. Then official papers written in Latin began to be written in Roman. Up until the
17th Century, standardization in spelling had been vague until dictionaries, schools,
and laws enforced a standard spelling (Burney 1955; Catach 1978; Thimonnier 1978).
Spelling reform is currently an extremely controversial subject in France, which can
cause social and business problems when it is under discussion. Only minor correc-
tions have recently been approved. Consequently, computational applications have to
deal with this problem in the same way as do young students or foreigners learning
the language.&apos;
There are many classic examples of the problem in English. Among those often
cited are the different phonetic realizations of the grapheme sequence ough as in rough
[AI], through [III], bough ja231, thought [D1], dough [aL3], cough [Df], and hiccough [Apt&apos;
A single grapheme or sequence of graphemes in various orthographic pairs may
show considerable phonetic difference even within nearly identical environments: the
a in swan-swam [swon—swm] or the wh in whorl-who [1/%73:1—hied. When morpheme
boundaries enter the equation, we find a similar situation, uni in uniformed-uninformed,
th in pothole-matthew, ph in flophouse-sphere, and so on. Finally, lexical (external) bor-
rowing results in exceptions to normal Germanic letter-to-sound rules such that many
additional rules (or an exception table) are needed. For example, words like cello and
concerto keep their Italian [tf] phoneme for the letter c followed by e. Similar prob-
lems are encountered with other partially assimilated loan-words from a variety of
other languages, e.g., entente (one of the few forms: entrée, entourage, and a few oth-
</bodyText>
<footnote confidence="0.998583666666667">
1 Many of the more sophisticated language pedagogical approaches now used to teach a conversational
form of a language such as French or English will intentionally not expose the student to the
orthographic system in the first lessons, since to do so causes interference with the phonetic form.
2 Conversely, one phoneme may have a number of orthographic manifestations: the phone [iI] may be
realized as ey (key), ee (lee), ei (receive), ie (achieve), i (machine), e (she), ea (peace), eo (people), oe (amoeba), ay
(quay), ae (aegis), and y (lovely).
</footnote>
<page confidence="0.99401">
498
</page>
<note confidence="0.488209">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<bodyText confidence="0.999836421052632">
ers, in which orthographic e is realized phonetically as [DP; and finally bourgeois, hors
d&apos;oeuvres, Arkansas, Illinois, and a variety of personal names that come from a disparate
group of language families. When borrowed into English, these words are pronounced
neither according to the rules of general English nor according to the rules of the source
language.
In French, there are also different phonetic realizations of a single grapheme se-
quence: x is pronounced [ks] in axiome, [gz] in exemple, [s] in soixante, [z] in sixieme,
and [ I (not pronounced) in auxquels.3 There is sometimes a linking phoneme added
between two words. A latent e is deleted in certain cases (elision).4 For some phonemes
(mostly vowels and semivowels), variations are sometimes acceptable and depend on
the area, the speaker, or even the speech rate. Some words have a different pronuncia-
tion depending on the grammatical category of the word (when the form is a member
of a pair of homographs).
Spelling and pronunciation are for both languages the result of history. With the
Great Vowel Shift for English, pronunciation has changed, but not spelling (face for
instance was pronounced with an [a]). In French, oi, as in roi has been pronounced
successively [3i], [ue], [we], [wa]. French has a lot of words that have kept their original
pronunciation: Celtic words like dolmen, menhir; Latin words like posteriori, in fine. The
spelling is, for many words, still dependent on their Latin or Greek origin.
</bodyText>
<subsectionHeader confidence="0.999795">
3.2 Normalization
</subsectionHeader>
<bodyText confidence="0.991103857142857">
Normalization consists for both English and French in replacing graphemes by other
graphemes or phonemes to expand numbers (12, 12.57, 12E+02), dates (12-03-97, 12-
Mar-97), fractions (1/3, 1/4), telephone numbers, abbreviations (kg, km), acronyms
(spelled, such as U.F.O. in English, S.N.C.F. in French, or pronounced as a word such
as NATO in English, OTAN in French), and the like. For instance, 24 is replaced by
twenty-four for English, and vingt quatre for French.
For French, the replacement is sometime context-dependent as in:
</bodyText>
<listItem confidence="0.992443166666667">
• 1 enfant &apos;1 child&apos; replaced by un enfant where there is a linking: a
phoneme [n] added between un and enfant,
• or in 3 enfants &apos;3 children&apos; where a phoneme [z] is added between trois
and enfants.
• 1 flue &apos;1 girl&apos; has to be replaced by une fille and not un fille due to the
feminine gender of fine.
</listItem>
<bodyText confidence="0.8212305">
If the pronunciation of the word to normalize is not context-dependent, the word
can be replaced by the equivalent phoneme string rather than another grapheme string.
</bodyText>
<subsectionHeader confidence="0.999608">
3.3 Morphology
</subsectionHeader>
<bodyText confidence="0.999908">
In some cases, depending on the language, words have to be decomposed into mor-
phemes for letter-to-sound purposes. In English, hothead, hothouse are the concatenation
of two morphemes, which keep their own pronunciation. The th in these words ([t+h]
where + is a morpheme boundary) is different from the th in this [6] or thin [0]. Simi-
larly, for French, forms like tournesol, entresol, telesiege are formed from two morphemes,
</bodyText>
<footnote confidence="0.97329625">
3 As in English, one phoneme may have a number of orthographic manifestations: the phone [s] may be
produced from s, ss, c, c&apos;, and so on as in son, brosse, cet, c&apos;est; [fl is produced from f or ph as in feu,
flamme, amphibie, alpha.
4 Called an e muet &apos;mute e&apos; in French linguistics.
</footnote>
<page confidence="0.991548">
499
</page>
<note confidence="0.44843">
Computational Linguistics Volume 23, Number 4
</note>
<bodyText confidence="0.999895727272727">
each of which retains its pronunciation. Usually, in French, s between two vowels is
pronounced [z], otherwise [s]. The s in tournesol, entresol, telesiege, vraisemblable, con-
tresens, antisocial must be considered the beginning of a morpheme, and although it
occurs between two vowels, is pronounced [s]. This morpheme decomposition is dif-
ficult and is sometimes based on a large dictionary of morphs. Some implementations
have had as many as 12,000 for English (Allen et al., 1979). For English, and French,
the number of words having this problem is relatively small, and can be dealt with
by a dictionary or rules. In the English implementation, for example, many such mor-
phemes can be incorporated directly into the letter-to-sound rule set itself. For certain
other languages, such as German, where word compounding is quite common, mor-
pheme decomposition algorithms tend to be much more complex.
</bodyText>
<subsectionHeader confidence="0.994102">
3.4 Homographs
</subsectionHeader>
<bodyText confidence="0.999828">
Homographs are pairs of words that are orthographically identical but phonetically
different. In English, this difference is often simply a difference in stress depending
on the grammatical category of the word: permit ([1p31mIt] noun vs. [po&apos; mIt] verb),
baton al bxton] noun vs. [bol ton] verb), arithmetic ([ol rIemotIk] noun vs. ExrI0I metIk]
adjective) and so on. However, it can also be a difference of one or more segments:
deliberate ([dI&apos; lIborIt] adjective vs. [di&apos; lIboreIt] verb), use ([juis] noun vs. [julz] verb)
differ in terms of only one segment. Further, it is not always possible to resolve the
ambiguity from part of speech: in I read books, the pronunciation of read ([6:d] or [red])
is ambiguous. A less-frequently examined category, but one that is crucial to more
natural speech synthesis, is what we will refer to as functor homographs. These are
more subtle variations found in pairs such as can, which could be a verb ([kwn]) or a
model auxiliary ON] or [kin] — [kxn]); just, which could be an adjective ([dyst]) or
an adverb ([d3ist] [d3Ast]), etc., where there is partial overlapping in careful speech.
See Yarowsky (1994) on homograph disambiguation.
In French, the situation is similar. The same spelling can produce different phone-
mic forms: fi/s ([fis] &apos;son&apos; vs. [fil] &apos;thread&apos;); president aprezida] &apos;president&apos; vs. [prezid]
&apos;they preside&apos;), etc. The pronunciation typically depends on the grammatical category
of the word: fier (&apos;proud&apos; or &apos;to trust&apos;), est (&apos;is&apos; or &apos;East&apos;), couvent (&apos;convent&apos; or &apos;they
brood&apos;), notions (&apos;we were noting&apos; or &apos;the notions&apos;), as (&apos;an ace&apos; or &apos;you have&apos;), are
all ambiguous in terms of their pronunciation. The word six can be pronounced [sis]
(j&apos;en veux six), [siz] (six enfants), [si] (six fl/les). First-order context can sometimes solve
the problem (nous notions vs. des notions; un as vs. tu as), but, generally, a parsing of
the entire sentence is required. The ambiguity is often between a conjugated verb
and another grammatical category. The entire sentence can be ambiguous as in &amp;quot;les
fils sont jolis&amp;quot; where fi/s is pronounced differently depending on the meaning (sons or
threads).
</bodyText>
<subsectionHeader confidence="0.993852">
3.5 Stress
</subsectionHeader>
<bodyText confidence="0.9999058">
For English, due to the interaction of stress and vowel reduction, knowing the stressed
syllable is often crucial in determining the correct phoneme sequence (Halle and
Keyser 1971). For instance, a word like aggravation has three tokens of the vowel
grapheme a, but all are phonetically different. The vowel nucleus of the first sylla-
ble is []; the stressed syllable va is manifested by Eel]; and vowel nucleus of the
unstressed syllable gra (in this case) undergoes automatic vowel reduction and is real-
ized as [o]. The stress pattern for English is difficult to predict and has to be learned.
Nevertheless, some basic rules exist. We have seen the verb/noun homographs in the
previous section. In words of two syllables, the verb has stress on the second syllable,
the noun on the first.
</bodyText>
<page confidence="0.976982">
500
</page>
<note confidence="0.479125">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<bodyText confidence="0.999678476190476">
Adding one of a set of suffixes, S„ to a word can keep the stress on the origi-
nal syllable, such as for -Jul in beautiful, -less in defenceless, -able in changeable, -ness in
shallowness. A different set, Si, modifies the stressed syllable. For instance, -ity moves
the stress to the syllable preceding -ity, as in fatal [t feltl] fatality [fol tlItl]; probable
[t pripbabl] probability [probol MTH]; -ation moves the stress to the penultimate sylla-
ble of words ending in -ation: aggravation [,xgralvell@n].
Another difficulty for English concerns the stress in noun compounds such as
coffee cup, Thermos bottle, tape recorder, etc., which exhibit a stress pattern of [1 2] or [1 0]
due to the semantic unity of the two words in spite of the white space between them.
Because of this white space, a program without special rules would assign primary
stress to both words: [t kulfI# &apos;1(A.p] instead of [ 103fI# ,kAp] and 03:mos# Ihotl] instead
of [t 03:mas# ,britl]. This problem has been known some time (Liberman and Prince
1977).
Phonemes for French, on the other hand, are stress independent, since while lexical
stress is nonfunctional except in a small number of ambiguous words and phrases, it
plays a subordinate role to phrasal stress, which is invariant and phrase-final. Even
for function words where the stress of the word is reduced in terms of duration and
intonation, the phonemes stay the same.&apos; The stress could be different in belle fille
[Ibel#fij] vs. belle-fille [bel#1 fij], grand pere gra#per] vs. grand-pere [gra# &apos;per], stressing
belle or grand if it is not a compound word. Even a word like pomme de terre could have
two meanings: &apos;potato&apos;, or (the unlikely) &apos;apple made of earth&apos;.
</bodyText>
<subsectionHeader confidence="0.999058">
3.6 Morphophonemics
</subsectionHeader>
<bodyText confidence="0.99999">
The conversion can also depend on the preceding and following words. For English,
when the precedes a word beginning with a vowel it is pronounced differently from
when it precedes a word beginning with a consonant: the [NA apple versus the [15@1
boy. For English, except for grammatical category considerations, the conversion can
be done simply by examining the phonetic status of the first segment of the following
word.
In French, there are many cases where a phoneme is added at the beginning of a
word depending on the last grapheme of the preceding word. This link between words
is always between a word ending with a consonant (d, t, n, s, z), usually latent, and a
word beginning with a vowel or an aspirated h. There are linkings that are mandatory,
and others that are speaker or style dependent. These links occur between words in
the same syntactic group: a personal pronoun and a verb (nous avons [nuzav5]), an
article and a noun (un enfant Kenaral), an adjective and a noun (trois enfants [trwazafa],
grand homme [gratom]). In natural speech, these words are pronounced together, within
the same breath group and without a pause between them. In these cases, a word-
by-word conversion, or a dictionary lookup is insufficient to convert graphemes into
their correct phonemic equivalents. Instead, the preceding word needs to be analyzed.
For a few words, such as nord-ouest &apos;North-West&apos;, the link is done with the r of nord,
not with the final consonant d. In words like bon enfant, non aligne, the link is done
with n, but the preceding vowel of bon or non is also modified from [5] to N.
</bodyText>
<subsectionHeader confidence="0.999426">
3.7 Elision or Epenthesis of Schwa (Mute el
</subsectionHeader>
<bodyText confidence="0.947487666666667">
Cases of elision are specific to French. For example, the grapheme e is sometimes
realized phonetically as [ ] (the empty phoneme, meaning e is eliminated). This occurs
in words ending in e, like poule &apos;hen&apos;, genre &apos;kind&apos;, except for monosyllabic forms,
</bodyText>
<footnote confidence="0.959854">
5 This is in marked contrast to vowel reduction in English, where most unstressed vowels become [a].
</footnote>
<page confidence="0.97746">
501
</page>
<note confidence="0.443636">
Computational Linguistics Volume 23, Number 4
</note>
<bodyText confidence="0.999946722222222">
such as le &apos;the&apos; and de &apos;of&apos;. If the last syllable is a consonant cluster ending in e, and
the next word begins with a consonant, a short [a] is heard as in les chevres de [lE
fevracl@] &apos;the goats of&apos;; otherwise, more than two consonants would be in the same
consonant cluster, and this presents articulatory difficulty in French and violates the
constraints on syllable structure. Elision can be done in the first syllable of a word,
but is considered familiar (vs. normal) style: petit [pti] &apos;small&apos;, recommencer [rkomase]
&apos;to begin again&apos;.
In the middle of a word, elision is done for words such as tellement [tElma] &apos;so
much&apos; but not for justement [3ystamd] &apos;precisely&apos;, which is additional support for the
three-consonant cluster (CCC) constraint.&apos; This elision sometimes does not occur, as
in poetry reading, for example.
The rule does not provide for words like batelier [latalje] &apos;boatman&apos;, or bachelier
[baf alje] &apos;bachelor&apos; where elision is not done. The semivowel [j] can be considered a
consonant, and the three-consonant cluster constraint applies.
Sometimes, an [0] phoneme is added between two words. For instance, in the
newspaper name Ouest-France [west#fras], an epenthetic [a] vowel is often inserted
[west@ #fras]. This happens between two words, in the context CC#C, and is again
the result of the difficulty of pronouncing more than two consecutive consonants.
</bodyText>
<subsectionHeader confidence="0.999952">
3.8 Segmental Phonology and Speech Rate
</subsectionHeader>
<bodyText confidence="0.999966941176471">
These rules are generic rules and sometimes may not apply in unusual cases, such
as in very slow speech where each word is pronounced or in poetry (which often
has its own set of rules different from normal speech). Thus far, in the area of speech
synthesis, at least, not much has been done to modify segmental phonology according
to speech rate.
In English, when the speech rate exceeds a certain threshold, in natural speech,
pauses disappear and segmental durations become shortened. In the future, in text-to-
speech systems, some segments and even syllables will disappear entirely and certain
functors will be greatly attenuated. See Dirksen and Coleman (1994) for more on
speech rate.
In French, in words containing a semivowel followed by a vowel, if the speech
rate is slow enough (or sometimes in poetic contexts), a semivowel could be produced
as a vowel: /ui &apos;him&apos; ([4] vs. [lyi]), nuage &apos;cloud&apos; Untia3] vs. [nyag, her &apos;to bind&apos;
([1je] vs. [lie]). A common phrase such as parce que &apos;because&apos;, which is typically two
syllables in normal speech ([parska]) becomes three syllables in very slow or emphatic
speech ((parsokal). In fast speech, the phrase je te he dirai [3atalodirc] &apos;I will tell you&apos;
is pronounced je t&apos;le dirai [3atladire] or j&apos;tel dirai [3taldire] eliding one or two N.
</bodyText>
<subsectionHeader confidence="0.999403">
3.9 Proper Names
</subsectionHeader>
<bodyText confidence="0.999990666666667">
For proper names, the correspondence between written names and their pronunciation
is even more difficult to specify due to their disparate origins. In English (whether
British or American), there are many different ethnic groups represented in a telephone
book or database of names. In a typical American telephone book, for example, are
names that originate from hundreds of languages. In France, when a person is asked
to provide a proper name, he or she is also often asked to spell it. For cities like Caen
([kã]), Rennes (fret*, Reims ([rs]), etc., the pronunciation differs substantially from
the spelling. In proper names like Lesage, Des pres, Bourgneuf, Mont rouge, Lesventes, it is
important to recognize the morphemes Le, Des, Bourg, Mont to correctly transcribe. In
</bodyText>
<page confidence="0.736596">
6 In French, la regle des 3 consonnes.
502
</page>
<note confidence="0.496068">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<bodyText confidence="0.999938105263158">
both anglophone and francophone countries, these patterns of immigration have been
sufficient to make this a serious problem for any automatic phoneticization algorithm.
The rules for proper names can generally be derived from the rules for words.
Nevertheless, a large superset of rules has to be added to obtain very high accuracy
since the phonotactics change from language to language. Moreover, to compound the
problem, the pronunciation of proper names outside of the foreign speech community
is often different from their original pronunciation. For example, in the US, e ending
Italian names (pronounced [e] in Italian) is typically pronounced [ill or even [ 1 (not
pronounced). The proper name Falcone is pronounced in anglophone countries as either
[fx1103rtil] or even [flIcon], Bach as either [bax] or [bald. In French, we observe a
similar situation where the name Smith is pronounced [smis] and Thatcher as [satf or]
as French does not have a [0] phoneme.
There have been successful attempts to automatically detect the ethnic group of
a proper name for use in anglophone countries like the United States, and to apply
a different set of rules depending on that group (Church 1985, Vitale 1991). Trigram
frequencies are computed from a large set of proper names whose ethnic group is
known, and used to classify a new proper name in terms of some language, language
group, or language family (the linguistic etymology of the name). Depending on that
classification, different subsets of language-specific rules can be activated.
</bodyText>
<sectionHeader confidence="0.839336" genericHeader="method">
4. Expert Systems
</sectionHeader>
<bodyText confidence="0.999977785714286">
Expert systems are used to facilitate the transfer of the knowledge of a specific domain
from an expert to a computer. They traditionally distinguish between the system,
which is as independent as possible from the application, and the expert rules, which
are application dependent. The system requires a computer specialist, the rules require
an expert in the domain to be processed, in this case, a linguist. Everybody is an
&amp;quot;expert&amp;quot; in reading his or her own language, and the average educated individual
does not hesitate in front of a word like monsieur or second in French, or hiccough or
Edinburgh in English, even though the pronunciation may be quite different from the
spelling. In any case, we apply, albeit unconsciously, rules to read text aloud.
Considering the complexity of the problems presented above, it was quickly un-
derstood that letter-to-sound rules had to be treated like an expert system with a rule
set developed by an expert (a linguist) and an interpreter to interpret the rules. This is
a pragmatic approach based on failures of systems that use hard-coded rules that the
linguist would be forced to program or the programmer would be forced to articulate.
</bodyText>
<sectionHeader confidence="0.956824" genericHeader="method">
5. The English Rule Set
</sectionHeader>
<subsectionHeader confidence="0.999298">
5.1 The Rule Formalism for English
</subsectionHeader>
<bodyText confidence="0.9908325">
Essentially, a letter-to-sound rule can be viewed as similar to a phonological rule in
classical phonology except that it converts a grapheme string to a phoneme string.
These rules may be context-sensitive or context-free. A lexical entry in a dictionary
(without syntactic and semantic information) is, in essence, a context-free letter-to-
sound rule.
An efficient rule set had to be developed. This rule set had to be:
</bodyText>
<listItem confidence="0.993952333333333">
• rigorous (have a minimum of ordering constraints, such that new rules
could be added at random with a minimum of liability);
• complete, with a large number of rules covering large sequences
</listItem>
<page confidence="0.988865">
503
</page>
<note confidence="0.428348">
Computational Linguistics Volume 23, Number 4
</note>
<bodyText confidence="0.960593">
including morphs both free and bound;
</bodyText>
<listItem confidence="0.909617">
• optimally parsed in order to make use of morphological information
relevant to allophonic variation as well as to stress.
</listItem>
<bodyText confidence="0.985454571428572">
Using these criteria as a working basis, we developed a set of highly accurate letter-
to-sound rules.
In English, the scan is done right to left to strip the suffixes of a word in sequence
as shown in Example 4 below. The input is a string of graphemes, the output a string
of phonemes (and occasionally the allophones themselves). There is only one scan.
The rules themselves are stated in terms a linguist would be familiar with such as the
following:
</bodyText>
<equation confidence="0.998218333333333">
X [y); (context-free)
or
X [A /W — Z; (context-sensitive)
</equation>
<bodyText confidence="0.999108">
where X, W, and Z are grapheme sequences and [y] is a phoneme (or phone) sequence.
A two-tiered architecture (compiler and interpreter) has been designed to easily
define and modify the rule set in our implementation of grapheme-to-phoneme rules.
The rule compiler transforms the external form of the rules into an internal form
that can be easily used by the rule interpreter. The grapheme pattern is encoded
as a simple text string. The left and right context patterns are encoded as strings
of operators and parameters for a pattern-matching procedure, and the replacement
phoneme string is encoded using the system&apos;s internal phoneme codes.&apos; The grapheme
pattern and the left context pattern are reversed by the rule compiler (that is, stored in
right-to-left order) so that they are stored in the direction that they are actually used.
The rule compiler does not perform any sophisticated checking of the rules; it does
not check that the rule set is complete, nor does it check that long rules are always
presented before short rules.
The rule interpreter begins processing a word by setting its current position to the
rightmost grapheme. It then searches linearly through the rules, in the order they were
written, until it finds a rule that matches at that current position. A rule matches if the
grapheme string matches, the left context pattern matches (if present), and the right
context string matches (if present). The grapheme string is matched using a simple
right-to-left text compare, and the context strings are matched by a recursive procedure
that interprets the pattern string built by the rule compiler. The phonemes for the rule
are then placed in the output, the current position is advanced over the matched
graphemes, and the process is repeated until a rule consumes the leftmost grapheme.
Since the rule set contains an unconstrained rule for each grapheme, the matcher
will always find a rule, and will always make progress. Matched graphemes are not
deleted; the word is left intact, since &amp;quot;consumed&amp;quot; graphemes could be part of the right-
hand context of some future rule. The phoneme string generated by the letter-to-sound
rule interpreter is represented as a double linked list. This representation was chosen
7 The right-to-left match has already been described. It should be pointed out that the use of &amp;quot;text&amp;quot; in
&amp;quot;text string&amp;quot; was not ASCII, but an encoded alphabet in which some grapheme pairs, like qu, gu and
certain others were encoded as single letters, because doing so made it unnecessary to have a large
number of (unnecessary) blocking rules in the rules for the grapheme u.
</bodyText>
<page confidence="0.97134">
504
</page>
<note confidence="0.488179">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<bodyText confidence="0.999264166666667">
because subsequent processing (syllable marking, stress analysis, and final allophone
adjustment) needs to be able to scan the phoneme string in both directions, and needs
to be able to add and delete phonemes at arbitrary places.8
It would be, of course, possible to use more elaborate string-matching techniques
to increase the speed of rule selection, but this was not done in our system because
letter-to-sound processing never uses a significant fraction of the total processing time.
</bodyText>
<subsectionHeader confidence="0.748821">
5.2 Examples of Rules for English
Example 1
</subsectionHeader>
<bodyText confidence="0.999856">
The following is an example of a set of two letter-to-sound rules for the letter c in
English. The first is context-sensitive and the second context-free:
</bodyText>
<equation confidence="0.951108">
[lc] / — {a, o};
[s];
</equation>
<bodyText confidence="0.9823438125">
This set reads as follows: The grapheme c is realized phonemically as [k] if occurring
immediately before the grapheme a or o as in cab, cake, decaf; it is realized as [s]
elsewhere: cease, cigar.&apos;
Example 2
Such rules, of course, handle only those forms that constitute the set of assimilated or
partially assimilated loanwords. In the case of the English rules above, words such as
call, cell, cilia, cool would be handled, as well as cure, cute, (assuming that palatalization
issues are handled by another rule). It does not account for words such as cello trel@U]
or concerto [ken&apos;tfe3t325], because these are unassimilated borrowings that still show
the original Italian palatalization rule of:
When we have a rule that handles n words, where n is between 1 and some small
number, say fewer than 7, we generally put these forms in a dictionary instead of
using up computation to process such a small number of words. Similarly, even if a
rule to convert e to [D] (to handle words such as entrée [&amp;quot;untreI], entente, or entourage)
could be written, it would be much easier and more efficient to put the words it affects
in a dictionary, because there are so few of them.
</bodyText>
<equation confidence="0.7706765">
Example 3
ation [1][eI] = [0][r][3][n] / — +;
</equation>
<bodyText confidence="0.944718">
indicates that the string ation at the end of the word (morpheme boundary) is replaced
by the phoneme string:
</bodyText>
<listItem confidence="0.9997885">
• [eIfan]
• plus a mark [1] of primary stress for [el],
</listItem>
<footnote confidence="0.8345098">
8 Syllabification, stress, and final allophone adjustment are done after the first output of a phoneme
string.
9 We used square brackets for the segmental output of the rules. We have adopted this convention
because the output could be either phonemic or phonetic. That is, if allophonic rules can be done in
one pass here, we include them along with rules that output phonemes.
</footnote>
<page confidence="0.978841">
505
</page>
<note confidence="0.276186">
Computational Linguistics Volume 23, Number 4
</note>
<listItem confidence="0.995360666666667">
• a syllable boundary =,
• and a mark [0] of unstressed syllable for [r@n], as, for instance, in
aggravation.
</listItem>
<subsectionHeader confidence="0.856377">
Example 4
</subsectionHeader>
<bodyText confidence="0.999985142857143">
This example shows the decomposition of words into their constituents morphs in
such a way as to &amp;quot;undo&amp;quot; the mutations caused by suffixes. In some cases, the input
string is modified to add a morpheme boundary, or replace the suffix. With the word
finishing, a context-sensitive rule in ing would, for instance, produce the phonemes
for ing plus a mark [0] indicating that the syllable is unstressed, add a morpheme
boundary mark (±) in the input string, which is then finish+ing, and continue the
conversion from right to left starting on h of finish.
</bodyText>
<equation confidence="0.588435">
it-1g &gt; ± --- [0] [I] [DI / — +;
</equation>
<bodyText confidence="0.983338625">
With the word riding, a context-sensitive rule in ing would produce the phonemes for
ing plus a mark indicating that the syllable is unstressed, replace the suffix ing by e+
in the input string, which is then ride+, and continue the conversion from right to left
starting on e.
ing &gt; e+ —4 • • • / -+;
With the word relationship, the rule decomposes the word into relation + ship:
ship &gt; + —+ ... / —+;
scandalousness is decomposed into scandal + ous + ness by the following rules:
</bodyText>
<equation confidence="0.9759724">
ness &gt; + —&gt;
ous &gt;+ —&gt;
This suffix stripping is the main reason for a right-to-left scan for English (Allen 1976).
Example 5
o —&gt; [u o5] / micr —;
</equation>
<bodyText confidence="0.9926045">
means o will be translated as ED] if the syllable is stressed (micrometer), and as
otherwise (microgram). (See Section 5.7 for stress assignment)
</bodyText>
<subsectionHeader confidence="0.981926">
5.3 Normalization for English
</subsectionHeader>
<bodyText confidence="0.998133777777778">
Text normalization, i.e., replacing numbers, abbreviations and acronyms, by their full
text equivalents is done in a preprocessing section. In English, the choice between ex-
pansion to the full graphemic equivalence or expansion to a full phonetic equivalence
was made in favor of the latter.
English contains a separate preprocessing section for numbers (24 in twenty-four),
acronyms (IBM, FBI), or abbreviations (Pr. for Professor, $ for dollar(s)). Some of these
examples can become quite complex: $50 is retranscribed (or phoneticized) as fifty
dollars; $50.60 as fifty dollars and sixty cents; $50 million as fifty million dollars; $50.2 million
as fifty point two million dollars; and so on.
</bodyText>
<page confidence="0.987646">
506
</page>
<note confidence="0.687759">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<bodyText confidence="0.9992934">
Some characters may or may not be pronounced depending on the application
(punctuation spelling for instance): 1 kg is a singular one kilogram but 5 kg is plural five
kilograms. Similarly, Dr. may be doctor or drive and St. may be street or saint, depending
upon the context. We disambiguate and expand all such abbreviations in a separate
module that by-passes letter-to-sound. There are switches that can be set, for example
to turn all punctuation off, to turn it all on, or to normal pronunciation, where very
few punctuation marks need to be pronounced. Any of these approaches works. The
advantage of a separate text preprocessing module is that it does not clutter up the
letter-to-sound rules. It can be optional, removed or replaced as necessary depending
on the application.
</bodyText>
<subsectionHeader confidence="0.977999">
5.4 Homographs for English
</subsectionHeader>
<bodyText confidence="0.998848333333333">
In English, homographs represent a common problem that cannot be solved entirely
by letter-to-sound rules. There has traditionally been an avoidance of the problem by
defaulting to one member of the pair based on blind form class selection (default to
the noun), which, of course, is less than adequate. For example, in grapheme strings
such as refuse and produce, the default to noun would be to refjuis] and pradjuIsl,
which, in unrestricted text, are less frequent than the verb forms.
Later solutions in our system involved a default to the member with the higher
frequency of occurrence. For example, using the same words, the default would be to
[rItfjulz] and [pro&apos; djuls] rather than to [1 refjuis] and [1 prodjuls].
</bodyText>
<subsectionHeader confidence="0.99408">
5.5 Morphophonemics
</subsectionHeader>
<bodyText confidence="0.959326666666667">
There are several rules for phonemic tuning, especially to account for morphonemic
alternations, which are extremely important. For example, there are a number of es-
sential morphonemic rules in English that perform various tasks, such as plural and
past tense formation. These rules are very well known among linguists and need to
be formalized in the same way as were the grapheme-to-phoneme rules. This time,
however, we are always going from a morphophonemic to a phonetic realization as
in:
{x} [y] / [w] - [z];
where {x} is an archiphoneme or abstract morphophoneme, [y] is some phonetic
sequence, and [w] and [z] are some environment E, where E is either phonemic or
phonetic. For example, the following are two well-known rules that implement the
phonetic realizations for [plural] and [past]:1°
After conversion, we have for roses, the following phoneme string: [r][0T5][z]+[z]
{z} ---+ [i][z] / [+Cons, +Sib] + —#;
applies for the second [z], which is preceded by + (morpheme boundary), and by a
sibilant consonant ([z]).
After conversion, we have for cats, the following phoneme string: [k][x][t]+[z]
{z} —&gt; [s] / [+Cons, —Voice] + — #;
</bodyText>
<page confidence="0.8680835">
10 {z} and {d} are abstract base forms that are replaced by appropriate phones.
507
</page>
<note confidence="0.526961">
Computational Linguistics Volume 23, Number 4
</note>
<bodyText confidence="0.900709857142857">
applies for [z], which is preceded by + and an unvoiced consonant (RD.
After conversion, we have for spotted, the following phoneme string: [s][p][to][t][t]+[d]
{d} [i] [d] / { [t], [d] } + — #;
applies for [d], which is preceded by + and by [t].
After conversion, we have for walked, the following phoneme string: [w][DI][kl+[d]
{d} [t] / [+Cons, —Voice] + — #;
applies for [d], which is preceded by + and by an unvoiced consonant.
</bodyText>
<subsectionHeader confidence="0.992918">
5.6 Syllabification
</subsectionHeader>
<bodyText confidence="0.969024933333334">
A phone scanning, from right to left, marks the positions of the syllables according to
consonant clusters, vowels, and morph boundaries.
For instance, scandalousness, which has been processed by the previous steps as:
[s][k][][n][d] [a] [1] -F [a] [s] + [n] [i] [s]
is decomposed into syllables as follows:
[s] [k] [x] [n] — [d] [01 [1] + [o] [s] + [n] [i] [s]
chevron would result in: Li] [e] [v] [r] [a] [n]
and would be decomposed as:
[1] [e] [v] — [r] [a] [n]
Although there are several different theories of syllabification, any standard linguistics
book will have a reference to these valid clusters and an accurate definition of the
syllable for a language L (Clemens and Keyser 1983). It is beyond the scope of this
paper to discuss the merits of one theory of the English syllable over another. Whatever
theory is chosen, syllabification should serve as an accurate input into the module that
handles stress.&amp;quot;
</bodyText>
<subsectionHeader confidence="0.996821">
5.7 Stress
</subsectionHeader>
<bodyText confidence="0.9765395">
The letter-to-sound rule set described above sets lexical stress in a wide variety of cases,
especially where the word is monosyllabic or the suffixal information is sufficient to
place primary or secondary stress.
These routines contain special rules, which contain a number of different options:
</bodyText>
<listItem confidence="0.952667666666667">
(a) assign primary stress,
(b) place primary stress n syllables to the left or right,
(c) place secondary stress,
</listItem>
<footnote confidence="0.571158333333333">
11 Syllabification can be applied in the user interface as a useful addition to spell mode (i.e., &amp;quot;say letter&amp;quot;),
and word mode (&amp;quot;speak word by word&amp;quot;). Such an interface can then be used in applications ranging
from language pedagogy to the teaching of reading to individuals with learning disabilities.
</footnote>
<page confidence="0.972505">
508
</page>
<listItem confidence="0.7362092">
Divay and Vitale Grapheme-Phoneme Translation
(d) place secondary stress n syllables to the left or right,
(e) assign [-stress] (not stressed) to a syllable,
(f) refuse stress.
Example of letter-to-sound (morph) rules that would have already assigned primary
stress:
ation --4 [1] [el] = [0][J1[il [n] / — +;
• Eel] has primary stressed (marked [1]) as in transformation;
• [f][i][n] is unstressed (marked [01)
• = is a syllable boundary.
</listItem>
<bodyText confidence="0.949416">
Example of letter-to-sound rule that would have assigned primary stress one syllable
on the left:
graphy &gt;+ --4 [S1left] [g][r][@]=[0][f][I] / - +;
geo --4 [d3][i][01@] / - +;
The primary stress is one syllable [S1left] to the left of graphy, so [DM is stressed and
the phoneme is [&amp;quot; o]
There are certain affixes in English that refuse to be assigned stress. For example
the prefix in- normally does not take [1 stress] except under contrastive stress, e.g., I
said include, not preclude. A word is scanned left to right and on syllables that fall
under the category of stress-refusers, a flag is set. It is possible that more that one
contiguous syllable will refuse to take stress.
Generic stress rules in this module assign primary stress if and only if [1 stress]
has not yet been assigned. In this block, the word is scanned left to right, the number
of syllables is counted, and pointers are stored in syllable-initial position in an array
A. The number of syllables in the root form is counted and the syllable that forces the
primary stress is marked as [1 stress].
Primary stress ([1 stress]) is a requisite for all words except certain words already
marked otherwise in the dictionary and noun compounds. If at the end of these rules,
[1 stress] still has not been placed on a word, a set of generic rules applies. First the
number of syllables in the root is noted and a flag is set on that syllable with the most
likely default for the placement of [1 stress].
Examples of default rules are as follows where $ is a syllable:
</bodyText>
<equation confidence="0.975004">
$ —4 $
[1 stress]
For instance: smart
$$ —+ $ $
[1 stress] [0 stress]
</equation>
<bodyText confidence="0.404935">
For instance: baby (stressed on the first syllable ba)
</bodyText>
<page confidence="0.97791">
509
</page>
<note confidence="0.591167">
Computational Linguistics Volume 23, Number 4
</note>
<subsectionHeader confidence="0.980251">
5.8 Allophonics
</subsectionHeader>
<bodyText confidence="0.998777142857143">
The allophonic pass performs some allophonic rules well known to those familiar with
phonemic variation.
The phoneme string is scanned left to right, performing such tasks as vowel re-
ductions. This is done in a prepass, to ensure that each [@] or [i] (reduced) vowel is
accurately adjusted before the main body of the allophonic rules are run.
The following are examples (a small subset) of (ordered) rules of the final allo-
phonic pass:
</bodyText>
<equation confidence="0.714435">
{[k], [g]};
pancake, previously transcribed It pxnkeIld, becomes rp.nkeild.
[s][s] [Y] / — [u:1+;
</equation>
<bodyText confidence="0.947782571428571">
issue, previously transcribed rissua becomes [lifte].
Finally, one member of geminate pairs is deleted. There are some special pairs like
[1] and [L] (syllabic [I]) that get deleted even if there is a morpheme boundary between
them. Nevertheless, often these rules are blocked if they cross a morpheme boundary.
[d] [d] —&gt; [d];
This rule applies for adder, which is add+er but does not apply for midday, which is
mid+day
</bodyText>
<sectionHeader confidence="0.944628" genericHeader="method">
6. The French Rule Set
</sectionHeader>
<bodyText confidence="0.99976525">
For French, an ad hoc programming language has been designed to easily define and
modify the rule set. Text normalization, i.e., replacing numbers, abbreviations, and
acronyms, by their full text equivalents, and grapheme-to-phoneme transcription can
be achieved using this formalism.
</bodyText>
<subsectionHeader confidence="0.999591">
6.1 The Rule Formalism for French
</subsectionHeader>
<bodyText confidence="0.925276333333333">
6.1.1 Input and Output Characters. The external codes of the units to be processed
must be declared, i.e., the grapheme codes (upper and lower case letters, numbers,
punctuation, diacritics) and the phoneme codes. These codes may be composed of one
or more characters. In this way, users can define their own code, and the formalism
can be used for different languages. These basic input and output units, or elements,
are expressed as ei, where i is some number.
6.1.2 Strings and Classes. A string consists of the concatenation of the predeclared
external characters: ele2e3 is a string. A class is a set of strings having a common
property. &apos;Cl&apos; and &apos;C2&apos; are classes.
</bodyText>
<equation confidence="0.937467">
&apos;Cr : el, e2, e3/
&apos;C2&apos; : ele2, e5e1, e2e3i
</equation>
<footnote confidence="0.88168">
6.1.3 Blocks of Rules. The set of rules consists of one or several blocks of rules. Each
block describes a process, taking the input text, processing it, and replacing it by the
</footnote>
<page confidence="0.987025">
510
</page>
<figure confidence="0.975188285714286">
Divay and Vitale Grapheme-Phoneme Translation
result of the processing. The different blocks can be activated sequentially, or directly
(execute block 5 for example).
begin {Block
rule 1
rule n
end
</figure>
<figureCaption confidence="0.9091905">
6.1.4 Rules. The syntax of a rule is:
(number) : (Is) --&gt; (rs)/(lc) — (rc);
</figureCaption>
<bodyText confidence="0.996250076923077">
where number is the rule label; Is (left string) is the string to be replaced; rs (right
string) is the string replacing Is; lc (left context) represents the strings to be found on
the left side of Is; rc (right context) represents the strings to be found on the right
of is. lc and rc are formed with operands (characters, strings, classes) and operators
(concatenation, logical or, negation).
6.1.5 Using One or Two Buffers. If the contexts match, the rs string replaces the Is
string. This process can be achieved using either one or two buffers. With one buffer,
the rs string replaces the is string, so the left context of a rule must be written according
to the rules previously used. With two buffers, the writing of the left context of a rule
is easier because the input string is only modified at the end of the block of rules. In
effect, three contexts are usable: the left context and right context in the input buffer,
and the left context in the output buffer. This left output context is written between
angled brackets.
</bodyText>
<subsectionHeader confidence="0.687273">
6.1.6 Formal Examples of Rules.
</subsectionHeader>
<equation confidence="0.808752666666667">
E = A, B, C, D, E, F, G, H/; input and output characters
&apos;Cr, &apos;C2&apos;, &apos;C3&apos; classes formed with strings of E.
&apos;Cl&apos; : AB, CD/
&apos;C2&apos; : CFG, DE, AAH/
&apos;C3&apos; : CCC, CBA/
1 : EF H /E.&apos;C2&apos;—;
EF is replaced by H if, on the left side of EF, an element of the class &apos;C2&apos; is found
preceded by another E.
2 : AB, CD —+ FC / &apos;Cl&apos;.H - `C2&apos;.G, &apos;C3&apos;;
</equation>
<bodyText confidence="0.380106">
The string AB or CD is replaced by FC, in the following contexts:
</bodyText>
<listItem confidence="0.959406">
• on the left of AB or CD, a H preceded by an element of the class &apos;Cr,
</listItem>
<page confidence="0.984422">
511
</page>
<note confidence="0.511102">
Computational Linguistics Volume 23, Number 4
</note>
<listItem confidence="0.650395">
• on the right of AB or CD,
</listItem>
<bodyText confidence="0.814994">
either an element of &apos;C2&apos; followed by a G,
or an element of &apos;C3&apos;.
</bodyText>
<listItem confidence="0.970385571428571">
3 : HH ---+ A /Non(C, E, H) -;
HH is replaced by A if the left context is not a C, an E, or an H.
4: CA -&gt; GE /(G.&apos;C3&apos;)H-;
CA is replaced by GE if:
• the left context of the output buffer (between angle brackets) is an
element of &apos;C3&apos; preceded by G,
• and the left context of the input buffer is H.
</listItem>
<bodyText confidence="0.9532645">
6.1.7 Interpreting the Rules. The rule having the longest match between the set of
all the is strings of the block, and the string beginning with the next character to be
processed in the input text, is searched first. If both contexts are true, the rule applies,
otherwise another rule is searched for, first any other rule with the same Is, and then
in decreasing length of is matches.
Let us consider the following rules:
</bodyText>
<equation confidence="0.982385">
begin
50 : AB -&gt;
51 : A
52 : ABC
53 : AB -4
54 : BC --*
55 : ABCG -&gt;
end
</equation>
<bodyText confidence="0.999879076923077">
and the input string, &amp;quot;ABCE&amp;quot; to be processed.
The longest match between the left string (Is) of the rules in the block, and the
input string to be processed is searched. In this case the longest match is &amp;quot;ABC&amp;quot;. So,
rule 52 is tested. If the contexts are true, the rule is applied, and the next character
to process is &amp;quot;E&amp;quot; in the input string. If the context is false, the rules are tested in
decreasing order of the longest match. Rules with &amp;quot;AB&amp;quot; as is are tested in the order in
which they are written (50, 53). Then if no rule has yet been applied, rule 51 is tested.
If no rule is true, the first character A to process is copied into the output buffer, and
the procedure starts again with the next character B. The order in which rules are tried
is: 52, 50, 53, 51. The order in which the rules are written is significant only for those
having the same is.
Using the formalism of the expert system, the expert is in charge of defining a set
of rules to simulate his or her expertise.
</bodyText>
<subsectionHeader confidence="0.999924">
6.2 Examples of Rules for French
</subsectionHeader>
<bodyText confidence="0.999561666666667">
As this paper is in English dealing with the French language, and in the event that the
reader might be not familiar with the idiosyncrasies of French, only a few examples
will be given to explain the mechanism of the letter-to-sound rules for French.
</bodyText>
<page confidence="0.989781">
512
</page>
<note confidence="0.592121">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<footnote confidence="0.252555">
Example 6
</footnote>
<bodyText confidence="0.962117142857143">
o is pronounced [o] in moto, /oto, solo.
oi is pronounced [wl[a] in moi, pois, fois.
on is pronounced [5] in bon, but not in abandonner, bonheur, or bonne,
where the rule for o applies.
oin is pronounced [w][] in loin, poing but not in avoine where the rule
for oi applies.
The rules could be written as shown below.
</bodyText>
<listItem confidence="0.557934166666667">
&apos;CexceptN&apos;: B, C, ... grapheme consonants except N /
5 : oin —+ [w] [e] , _ &apos;CexceptN&apos;, _;
oin gives [w][8] if oin is followed by an element of &apos;CexceptN&apos; or a space.
Otherwise,
6: oi --+ [w] [a]; context-free rule
7: on —+ [3] / — &apos;CexceptN&apos;, _;
</listItem>
<bodyText confidence="0.9715795">
on gives the phoneme [5] if on is followed by a consonant except N, or a space.
Otherwise,
</bodyText>
<equation confidence="0.468707">
8 : o —*[o];
</equation>
<bodyText confidence="0.998968">
Independently of the order of the rules, the rules having the longest match will be
first tested. Here, the order of the rules is irrelevant.
</bodyText>
<subsectionHeader confidence="0.884662">
Example 7
</subsectionHeader>
<bodyText confidence="0.924768428571428">
er at the end of words is pronounced [e] as in chanter, danser but [el.] in super, joker,
fer, or hier.
The rules could be formulated as:
&apos;Wer&apos;: sup, jok, f, hi/
9: er —4 [E] [r] /_.&apos;Wer&apos; — _;
er is pronounced [][r] if er if preceded by an element of &apos;Wer&apos; (words ending in er)
preceded by a space and followed by a space.
</bodyText>
<equation confidence="0.777762">
10 : er —*[e];
Otherwise er is rewritten as [e].
Example 8
</equation>
<bodyText confidence="0.993765">
The ai string in French words like bienfaisant, contrefaisait, faisait, faisan, satisfaisant, etc.,
is pronounced [a] but not in faisceau, chauffais where the corresponding phoneme is
an [E].
</bodyText>
<page confidence="0.996288">
513
</page>
<figure confidence="0.932129454545454">
Computational Linguistics Volume 23, Number 4
The rule can be written as:
&apos;Vowels&apos;: a, e, i, o, u, y/
11 : fais [f][a][z] / — &apos;Vowels&apos;;
fais is pronounced [fez] if fais is followed by an element of the class &apos;Vowels&apos;.
Example 9
In order to eliminate geminates, one possibility is to analyze the last character sent to
the output buffer.
12 : b / ([b]) — ;
b is eliminated if the left context in the output buffer is already a phoneme [la]. (See
Section 6.1.5 on using one or two buffers.)
</figure>
<subsectionHeader confidence="0.978487">
6.3 Normalization for French: from Graphemes to Graphemes
</subsectionHeader>
<bodyText confidence="0.998733166666667">
The first step, done by a block of rules, is to normalize the text, replacing numbers,
abbreviations, and acronyms by their full text equivalents. Both input and output are
graphemes. Normalization is handled in the letter-to-sound rule set and in a prepro-
cessing module. By rules, the contexts indicate if the replacement is required.
Numbers. 123 is rewritten as cent vingt trois by a set of rules checking the left and right
context for each digit.
</bodyText>
<equation confidence="0.7995278">
&apos;Digit&apos; : 0,1,2,3, ...,9/ is the class for digits
13 : 1 —&gt; cent_ / — &apos;Digit&apos;.&apos;Digit&apos;._;
14 : 2 vingt_ / — &apos;Digit&apos;._;
15 : 3 —&gt; trois /—_;
1 is rewritten cent_ if followed (right context) by two digits and a space, etc.
Abbreviations. kg for kilo, Dr for Docteur, Pr for Professeur, bd for Boulevard, etc.
16 : kg kilos /, &apos;Digit&apos; — _;
kg is replaced by kilos in 5kg or trois kg.
Acronyms. Similar rules are used to spell acronyms (I.B.M. gives [&apos;been]):
17 : B. —&gt; be /_,.—;
</equation>
<bodyText confidence="0.98759375">
B followed by a point is replaced by bE (spelled) if B is preceded by another point or
a space. In I.B.M., or vitamine B., B is spelled correctly.
Preprocessing procedures are also used in cases like $50, which gives: cinquante
dollars and where you have to permute $ and 50.
</bodyText>
<page confidence="0.995173">
514
</page>
<note confidence="0.659789">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<subsectionHeader confidence="0.99429">
6.4 Morphology
</subsectionHeader>
<bodyText confidence="0.997191">
The problem mentioned in Section 3.3 is solved most of the time using rules for French.
For words like those in Section 3.3 (homosexuel, heterosexuel, telesiege, entresol, tournesol),
a class is defined with the prefixes ending with a vowel.
</bodyText>
<equation confidence="0.793398833333333">
For instance,
Prefix: homo, hetero, tele, entre, tourne /
18: s -- [s] / &apos;Prefix&apos; -
s is pronounced [s] if preceded by an element of &apos;Prefix&apos;, and followed by an element
of &apos;V&apos; (a vowel) as in telesiege.
19 : s —&gt; [z];
</equation>
<bodyText confidence="0.964619">
as in base, bise, anglaise, opposition
</bodyText>
<subsectionHeader confidence="0.996717">
6.5 Homograph Problem
</subsectionHeader>
<bodyText confidence="0.999910888888889">
A limited parsing has been done using the same formalism as letter-to-sound. A dictio-
nary lookup gives one or several grammatical categories for the most common words.
By examining the left and right words, it is possible in most of the cases to get an idea
of the grammatical categories of the unmarked words or to reduce (to one if possible)
the set of potential grammatical categories for each word of a sentence. The same
formalism allows the processing of grammatical categories (verb, adverb, preposition,
etc.) instead of characters for transcription. A class is a set of grammatical categories
(Divay 1984, 1985).
If the grammatical category is known (where V = Verb), it can be used in the rules:
</bodyText>
<equation confidence="0.823413">
20 : ent(V) --- / — 4
</equation>
<bodyText confidence="0.95032">
ent is eliminated at the end of a word (right context is a space) if the word is a verb
(us chantent).
</bodyText>
<subsectionHeader confidence="0.999495">
6.6 Linking
</subsectionHeader>
<bodyText confidence="0.989415333333333">
In some cases, a new phoneme is added between two words of a same-breath group.
For instance, a [z] phoneme is added between the two words of les enfants. The second
word has to begin with a vowel or aspirated h, and the first one to end with n, s, d, t,
x, or z. It depends also on the grammatical category of both words. This problem also
is solved by rules, such as the following:
21: _ —+ _[z] /Jes, _des, _ses, _nous — &apos;Vowels&apos;;
The space between two words is replaced by a space and a phoneme [z] if the space
is preceded by les or des, etc., and followed by a vowel, as in les enfants.
If the left context is very large, a new class can be created, and used as left context.
</bodyText>
<subsectionHeader confidence="0.971551">
6.7 Elision: From Phonemes to Phonemes
</subsectionHeader>
<bodyText confidence="0.919809">
Some rules, mostly rules dealing with mute e and semivowels, can be more easily
expressed on the phonemes strings. This is a new block of rules run after the grapheme-
phoneme conversion.
</bodyText>
<page confidence="0.994283">
515
</page>
<subsectionHeader confidence="0.486588">
Computational Linguistics Volume 23, Number 4
</subsectionHeader>
<bodyText confidence="0.9637664">
The following is an example of elision with mute e:
&apos;VP&apos;: [a], [i], ... / the vowel phonemes
&apos;CP&apos;: [13], [d], ... / the consonant phonemes
22: [@] —4 PVP&apos; — &apos;CP&apos;.&apos;VP&apos;;
Mute e is eliminated before a vowel phoneme and after a consonant phoneme followed
by a vowel phoneme as in emploiera [aplwa@ra], which becomes [aplwara].
Elision often occurs at the end of words (petite), or in the middle of words (em-
ploiera, tellement). It can be done in the first syllable (pesanteur, retard, teneur) except if
there are two consonants as in premier. It is never done if suppressing [9] would result
in three or more consecutive consonants.
</bodyText>
<sectionHeader confidence="0.737948" genericHeader="method">
7. Testing
</sectionHeader>
<bodyText confidence="0.986566">
No standardized tests exist for evaluating letter-to-sound systems, although some re-
searchers are beginning to look at the problem in order to determine whether one
approach has merit over another (Golding and Rosenbloom 1993). For example, the
Oregon Graduate Institute is currently investigating letter-to-sound rules done in more
traditional ways and comparing them to neural network learning.
Tests can be done:
</bodyText>
<listItem confidence="0.998228363636364">
1. with or without an exception dictionary lookup running before the rules,
2. on text extracted from papers, books, magazines. In that case, the same
words is counted as many times as it appears in the text. This is
especially true for linking words (one, a, the, is, etc.), which are then
counted many times. A more systematic test can be carried out using an
electronic dictionary, having for each entry (grapheme string) the
corresponding phoneme string. In that case, every word is tested and
counted one time, even though its occurrence frequency might be very
low,
3. in terms of percentage of phonemes or of words correctly transcribed.
Percentage of phonemes is obviously higher than percentage of words.
</listItem>
<subsectionHeader confidence="0.998638">
7.1 English Analysis
</subsectionHeader>
<bodyText confidence="0.998988692307692">
The rule set for English consists of about 1,500 rules containing morphs as well as
nonsemantic grapheme strings. An exception dictionary has been defined for words
not correctly translated by these rules. These consist mostly of functors, abbreviations,
homographs, and unassimilated loanwords such as adobe, bayou, cello, coyote, and the
like. In addition, the lexical entry need not contain phonetics, especially if the entry
in question is adequately handled by rule. It may, however, still be used to convey
both syntactic and semantic information that would then serve as input to a parser
for more accurate prosodic rules.
In this study, we took two different corpora: (1) a 1,676-word corpus originally
used by Bill Huggins (BB&amp;N) and eventually by Dennis Klatt (MIT). This corpus was
chosen because it consists of complex polysyllabic forms; (2) a sample taken from the
Brown corpus (19,837 words), which we felt to be sizable enough and representative
enough to use to examine letter-to-sound accuracy.
</bodyText>
<page confidence="0.993522">
516
</page>
<note confidence="0.801587">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<bodyText confidence="0.999645466666667">
On the Huggins corpus, without the use of the exceptions dictionary, our rule set
scored 94.9% of words. The 5.1% errors consisted mainly of incorrect morphological
analysis and consequent inaccuracies in lexical stress placement.
On the Brown corpus, we had a large number of dictionary hits, which was not
unexpected since the corpus contains many high-frequency forms. Out of a total word
count of 19,837 words, the dictionary hit count was 7,337 (36.99%); the rules matched
5,432 words (27.38%) for a total word match of 12,769 or 64.37%. Of the words missed,
3,905 (19.69%) missed by only one segmental phoneme or phone and 3,636 (18.33%)
had incorrect stress placement. We consider incorrect stress placement to be a more
serious error than one incorrect segmental phoneme.
The latest version is used in different products, from text-to-speech synthesizers
both hardware and software, assistive devices, and games, and will soon be used in
proper name retrieval, both on computer systems and over the telephone. Using the
same formalism, a different set of rules has been defined for proper names found in
a typical telephone book in the US and could be extended to other languages.
</bodyText>
<subsectionHeader confidence="0.976943">
7.2 French Analysis
</subsectionHeader>
<bodyText confidence="0.985909848484849">
The set of rules for French consists of about 600 rules and 100 classes. Some of these
classes contain 100 or more elements. The French letter-to-sound rule set was tested on
the 55,000 unique word Le Petit Robert dictionary, and the 100,000 word Le Grand Robert
de la Langue Francaise dictionary. An exception dictionary is automatically defined for
words not correctly translated by these 600 rules.
The execution of the set of rules on the 55,000 unique word dictionary gives
4.4% of words whose pronunciation is different from the dictionary Le Petit Robert
but is acceptable from the authors&apos; point of view. These differences are only due to a
mismatch between open or closed phonemes for phonemes [a], [e] and [o].
The distinction between the open [a] and closed [a] has almost disappeared in
France in favor of the open [a]. The proposed pronunciation varies even from one
dictionary to another. Words like accablant, phase, cable, vase, and trois have different
pronunciations depending on the dictionary used. Sometimes, both are mentioned.
They are even differences between Le Petit Robert and Le Grand Robert dictionaries.
Both open [o] and closed [o] are also acceptable in many words e.g., automobile,
aerodrome, augmenter, autonome, austral, ozone. Nevertheless for some words, the distinc-
tion has to be made (bol [bol] vs. rose [roz]). The closed phoneme is used for instance
before a phoneme [s]: pose, chose, oser or at the end of a word: abricot, escargot.
The closed [e] and open [E] are also very much interchangeable in many words
(les, baisser, adolescent, essai, agressif, blessant, interessant, aigri, biennal, accession).
Of the 55,000 words, 2.8% are incorrectly processed (1,500 out of 55,000), and
have to be added to an exception dictionary. Some words have several acceptable
pronunciations (aoat [aut, ut], ananas [anana, ananas], dompter cl5teD, bat,
babil, blet, chenil, exact, but, as, but only one is stored in the electronic dictionary. Some
problems result also from a different but acceptable elision of mute e, as in chemin de
fer, briqueterie, petit-neveu, amenuiser, point de vue, porte-bebe, redevenir. But, most of the
errors come from foreign words such as: accelerando, adagio, allegro, artefact, posteriori,
mea culpa, beluga, placebo, torero, baby, girl, shirt, blue-jeans, base-ball, steward, business,
building, copyright, bonsai&apos;.
The number of applications of each of the 600 rules has been calculated on the
55,000 words to give an indication of its weight.
This program is currently in use in different laboratories in France, Canada
(O&apos;Shaugnessy et al. 1981) and the United States (DEC) as the first level in speech
</bodyText>
<page confidence="0.985452">
517
</page>
<note confidence="0.734486">
Computational Linguistics Volume 23, Number 4
</note>
<bodyText confidence="0.997346266666667">
synthesis for French. It has been used by various companies producing electronic
board speech synthesizers for French.
This transcription program has also been used to create a phonetic index and
retrieve a word without knowing how to write it. The word is converted to phonetics
and searched for in the phonetic dictionary index (used in both CD-ROM dictionaries
Le Grand Robert and Le Petit Robert) (Rey et al. 1989). For information retrieval, open
and closed phonemes are always considered identical. The same mechanism (using
phonetics) is used to retrieve a proper name (without knowing how to spell it) through
the 30,000 proper names of the phone book of the city of Dakar (Senegal). The system
is also used in the Taurus multimedia database software (from DCI: Data Concept
Informatique) to create an index on one field of a structure defined by the user of
the database, and to retrieve the corresponding information even if it is misspelled.
Other similar uses are under investigation for the pronunciation of names from on-line
telephone books in particular and telecommunications applications in general (Alcatel
TITN Answare).
</bodyText>
<sectionHeader confidence="0.468598" genericHeader="method">
8. Final Remarks
</sectionHeader>
<bodyText confidence="0.9999285">
It is beyond the scope of this paper to discuss letter-to-sound procedures in languages
other than English and French. However, the disparate nature of different languages
argues for a brief mention of our experience in developing letter-to-sound rule sets in
other languages.&apos;
</bodyText>
<subsectionHeader confidence="0.999942">
8.1 Simple Systems
</subsectionHeader>
<bodyText confidence="0.999958133333333">
In certain languages, as diverse as Spanish and Swahili, letter-to-sound rule sets are
extremely easy to produce, due to the extremely close fit between orthography and
its phonemic /phonetic equivalent. First, there are many languages that developed a
writing system only recently. Swahili, for example, was written in Arabic script until
1850 when Krapf, a German missionary, introduced the Roman alphabet to the Bantu-
speaking peoples of the East African coast. Consequently, in the time span of less that
150 years, the phonological and phonetic systems of the language have not had time
to change to any significant extent. Secondly, many languages have undergone some
spelling reform. Czech, for example, underwent spelling reform fairly recently and
the orthographic system was brought into line with the phonological and phonetic
system. Third, there are some languages in which the orthography had a close fit with
the phonemic system. Spanish, for example, is a simple system in that there is an
almost iconic relationship between graphemes and their phonemic equivalent. In fact,
even lexical stress is marked in many forms and, where it is not, it is almost always
predictable.
</bodyText>
<subsectionHeader confidence="0.999686">
8.2 Mid-Level Systems
</subsectionHeader>
<bodyText confidence="0.99962">
Many languages are somewhat more complex and fit into a second category of lan-
guages of mid-level difficulty. German, for example, has a large morphological system
yet it is surprisingly simple in terms of letter-to-sound rules. If one lists a large number
of common morphemes, it becomes a simple task to state an accurate set of letter-to-
</bodyText>
<footnote confidence="0.984418166666667">
12 All languages of the world are of an equal degree of complexity. Primitive languages are a myth
perpetrated by early anthropologists, missionaries, and adventurers. However, when we compare
different subsytems of any two languages, it quickly becomes clear that subsystems are vastly different
in complexity. This is true of the phonological, phonetic, morphological, syntactic, semantic and
letter-to-sound subsystems of two different languages; some are an order of magnitude more complex
than others.
</footnote>
<page confidence="0.978627">
518
</page>
<note confidence="0.801577">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<bodyText confidence="0.7728295">
sound rules. Many languages with a high synthetic index (Greenberg 1990) fall into
this category.°
</bodyText>
<subsectionHeader confidence="0.999656">
8.3 Complex Systems
</subsectionHeader>
<bodyText confidence="0.999977">
Certain languages, such as English and French, are among the most complex lan-
guages to construct letter-to-sound rules for. These are not the only languages in this
last category. Any language with an old writing system that has not undergone a mod-
icum of spelling reform but has undergone dramatic phonological, morphonemic, and
morphological changes will probably fall into this category.
</bodyText>
<sectionHeader confidence="0.846273" genericHeader="conclusions">
9. Conclusions
</sectionHeader>
<bodyText confidence="0.999986222222222">
We have presented the difficulties of grapheme-to-phoneme conversion for English
and French. Both languages have evolved from different origins, and are the results
of the historical influence of other languages from which words have been borrowed
and assimilated, sometimes only partially. English and French have interacted and
continue to interact with each other. For both languages, the spelling has been enforced
by dictionaries and laws, but the pronunciation has continued to evolve, widening the
gap between the written and spoken components of the language.
Both the English and French translation systems presented in this paper are based
on rewriting rules. Nevertheless, some differences exist in the syntax and the interpre-
tation of these rules. For a more theoretical approach to rewriting rules, see Kaplan
and Kay (1994).
English is scanned once from right to left to better take into account the suffixes of
the word, which in certain cases determine the stressed syllable. The rule transforms
the grapheme into phonemes and stress marks used by the stress module. In some
cases, the input string is modified to add a morpheme boundary, or to replace the suffix
by another suffix to continue the conversion. Syllabification, stress, and allophonic
rules are achieved by programs.
French uses the concept of a class that allows for the grouping of strings having
a common property, thus reducing the number of rules. Several blocks of rules can
be defined corresponding to different scans from left to right of the string (the output
string replacing the input text at the end of a block of rules). The input string is not
modified. Rules can check the left and right contexts of the input string, and the left
context of the output string. French is not a stressed language, so there is no need for
a syllabification module or a stress module.
Many problems persist for phonemicization. In English, suffix stripping, com-
pound decomposition, and primary stressed syllable are very important to get the
proper phoneme string, and are carried out mostly by rules without an explicit morph
dictionary, contrary to as in Allen (1976), who uses a morph dictionary with 12,000
morphs, or Coker (1985), whose dictionary has 43,000 morphs. In French, the word-by-
word conversion is probably simpler due to the absence of stressed syllables. Affixes
do not alter the pronunciation of the root; compare, for instance, photo, photograph,
and photography in English with photo, photographe and photographie in French. But in
French, there are more interactions between words due to the linking problem (nous
avons) and mute e (chemin defer). These interactions are also dependent on speech rate.
Sometimes the homograph problem can be solved by looking at the left and right
context of the word, but the general case requires a better understanding of the overall
</bodyText>
<page confidence="0.8808205">
13 The synthetic index is Is = w ± m, where w is a word and m is a morpheme.
519
</page>
<note confidence="0.712033">
Computational Linguistics Volume 23, Number 4
</note>
<bodyText confidence="0.99907775">
structure of the sentence. This is also required to get a more natural prosodics in text-
to-speech synthesizers.
The same formalism could be used for both English and French with a slight
modification, for instance, of the French formalism. Blocks of rules should indicate if
the scan is to be done from left to right or from right to left. In the right-to-left scan,
the right context of the output buffer would be usable (instead of the left context if
the scan is done from left to right). The word scandalousness could be decomposed by
the following rules:
</bodyText>
<figure confidence="0.41911125">
begin RL RL for Right to Left
10 : ness +ness / ous - _ ;
20: ous +ous / al + in the output buffer
end
</figure>
<bodyText confidence="0.9996375">
resulting in scandal+ous+ness. Translating the root scandal could be done either from
left to right or from right to left in one or more blocks of rules.
The required output phoneme string depends on the application. For speech syn-
thesis, one output string is needed for a word. If several pronunciations are possible,
the software has to produce only one for the synthesizer.
Speech recognition algorithms must know all the phonetic variations of the words
in the vocabulary to be recognized, so the output should be a set of phonetic strings
corresponding to the input word. Some rules must be declared optional, and the
interpreter modified to take them into account.
For database searches, a set of equivalences can be devised where two (or more)
phonemes or allophones could be considered correct. For example, in many cases [0]
and [i] can be considered equivalents. Similarly, [0][1] and [L] (syllabic [1]) can also
be considered equivalents. For French open [a] and close [a] could be equivalent, as
would be [o] and [o], or [e] and [s]. The search could even be done only on phoneme
consonants (for proper name searches, for instance).
To our knowledge, learning algorithms, although promising, have not (yet) reached
the level of rule sets developed by humans. The automatic discovery of the underlying
structure of a language is not easy, nor is the developing of a universal rewriting rule
formalism for the different languages.
Dictionaries and sets of rules will have to continue to coexist either as a dictionary
of exceptions and a large set of rules, or as a large dictionary and a set of rules to deal
with exceptions.
</bodyText>
<sectionHeader confidence="0.989104" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997861151515151">
Ainsworth, W. A. 1973. A system for
converting English text into speech. In
IEEE Transactions of Audio and
Elect roacoustics, pages 288-290.
Allen, J. 1976. Synthesis of speech from
unrestricted text. In IEEE 64 (4), April.
Allen, J., R. Carlson, B. GranstrOm,
S. Hunnicutt, D. H. Klatt, and
D. B. Pisoni. 1979. Conversion of
unrestricted text-to-speech. Unpublished
Monograph, Massachusetts Institute of
Technology, Cambridge, MA.
Auberge, V. 1991. La synthese de la parole:
&amp;quot;des regles au lexique&amp;quot;. These, Universite
Stendhal, Grenoble.
Bakiri, G., and T. G. Dietterich. 1991.
Converting English Text to Speech: A Machine
Learning Approach. Ph.D. thesis.
Rep. No. 91-30-1. Department of
Computer Science, Oregon State
University.
Bechet F., T. Spriet, and M. El-Beze. 1996.
Traitement specifique des noms propres
dans un systerne de transcription
grapheme-phoneme. JST Avignon.
Ben Crane, L., E. Yeager, and R. Whitman.
1981. An Introduction to Linguistics,
Chapter 4: History of English. Little,
Brown and Company.
Bernstein, J. and L. Nessly. 1981.
Performance comparison of component
algorithms for the phonemicization of
orthography. In Proceedings of the 19th
</reference>
<page confidence="0.995245">
520
</page>
<note confidence="0.745916">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<reference confidence="0.996913459016393">
Annual Meeting, Stanford University.
Association for Computational
Linguistics.
Burney, P. 1955. Que sais-je? L&apos;orthographe.
Collections.
Catach, N. 1978. Que sais-je? L&apos;orthographe.
Collections.
Catach, N. 1989. Informatique: Traitement
automatique du Langage. Bulletin
Liaisons-Heso, September.
Catach, N. and L. Catach 1992. Presentation
du logiciel VOISINETTE, &amp;quot;Un correcteur
a entree phonetique&amp;quot;. CNRS-INFOS.
Church, K. W. 1985. Stress assignment in
letter to sound rules for speech synthesis.
In Proceedings of the 23rd Annual Meeting,
pages 246-253, University of Chicago.
Association for Computional Linguistics.
Clemens, G. N. and S. J. Keyser. 1983. CV
Phonology: A Generative Theory of the
Syllable. Linguistic Inquiry Monograph
Nine. MIT Press, Cambridge, MA.
Coker, C. H. 1985. A dictionary-intensive
letter-to-sound program. Journal of the
Acoustical Society of America Supplement 1,
Vol. 78, S7.
Cotto, D. 1992. Traitement automatique des
textes en vue de la syn these vocale. These,
Universite Paul Sabatier, Toulouse III.
Dedina, M. J. and H. C. Nusbaum. 1991.
PRONOUNCE: A program for
pronunciation by analogy. Computer
Speech and Language 5:55-64.
DeFrancis, J. 1984. The Chinese Language: Fact
and Fantasy. University of Hawaii Press.
Dirksen, A. and Coleman, J. 1994.
All-Prosodic speech synthesis. Second
ESCA/IEEE Workshop on Speech
Synthesis.
Divay, M. 1984. De l&apos;ecrit vers l&apos;oral ou
contribution a l&apos;etude des traitements des
textes ecrits en vue de leur prononciation sur
synthetiseur de parole. These d&apos;Etat,
Universite de Rennes, France.
Divay, M. 1985. A text-processing expert
system. 5eme Congres Reconnaissance
des formes et Intelligence Artificielle,
Novembre 1985, Grenoble, France.
Divay, M. 1990a. Traitement du langage
naturel: la phonetisation ou comment
apprendre a l&apos;ordinateur a lire un texte
Francais. MICRO-SY STEMES, March.
Divay, M. 1990b. A written processing
expert system for text to phoneme
conversion. In Proceedings of the
International Conference on Spoken Language
(ICSLP 90), Kobe, Japan.
Divay, M. 1991. CD-ROM Electronic
Dictionary, November.
Divay, M. 1994. Indexation phonetique et
recherche documentaire. In Proceedings of
the 9eme Congres AFCET, Paris, Volume 2:
Intelligence Artificielle.
Elovitz, H. S., R. W. Johnson, A. McHugh,
and J. E. Shore. 1976. Automatic
translation of English text to phonetics by
means of letter-to-sound rules. NRL
Report 7948, Naval Research Laboratory,
Washington, D.C.
Golding, A. R. 1991. Pronouncing Names by a
Combination of Case-based and Rule-based
Reasoning. Ph.D. Thesis, Stanford
University.
Golding, A. R. and P. S. Rosenbloom. 1993.
A comparison of anapron with seven
other name-pronunciation systems.
Journal of the American Voice Input/Output
Society 14:1-21.
Gonzalez, S. and J. P. Tubach. 1982. Reseaux
connexionistes pour la traduction
orthographique phonetique: Applications
a l&apos;Espagnol et au Francais. 136me
Journees d&apos;Etudes sur la Parole, Montreal,
Canada.
Greenberg, J. 1990. A quantitative approach
to the morphological typology of
language. In K. Denning and S. Kemmer,
editors, On Language: Selected Writings of
Joseph H. Greenberg. Stanford University
Press, Stanford.
Halle, M. and S. J. Keyser. 1971. English
Stress: Its Form, its Growth and its Role in
Verse. Harper and Row, New York.
Hertz, S. R. 1979. Appropriateness of
different rule types in speech synthesis. In
J. J. Wolf and D. H. Klatt, editors, Speech
Communication Papers, No. 50,
pages 511-514. Acoustical Society of
America.
Hertz, S. R. 1981. SRS text-to-phoneme
rules: A three-level rule strategy. In
Proceedings of the IEEE International
Conference on Acoustics, Speech, and Signal
Processing (ICASSP), pages 102-105.
Hertz, S. R. 1982. From text to speech with
SRS. Journal of the Acoustical Society of
America 72: 1155-1170.
Hertz, S. R. 1983. The &amp;quot;morphology&amp;quot; of
English spelling: A look at the SRS
text-modification rules for English.
Working Papers of the Cornell Phonetics
Laboratory 1: 17-28.
Hertz, S. R. 1985. A versatile dictionary for
speech synthesis by rule. Journal of the
Acoustical Society of America, Supplement
1:77, S11.
Hochberg, J., S. M. Mniszewski, T. Calleja,
and G. J. Papcun. 1990. What&apos;s in a
name?: Last names as a computational
problem. Unpublished manuscript, Los
Alamos National Laboratory, Los Alamos,
NM.
</reference>
<page confidence="0.944408">
521
</page>
<note confidence="0.359961">
Computational Linguistics Volume 23, Number 4
</note>
<reference confidence="0.9999245">
Hochberg, J., S. M. Mniszewski, T. Calleja,
and G. J. Papcun. 1991. A default
hierarchy for pronouncing English. IEEE
Transactions on Pattern Matching and
Machine Intelligence 13(9): 957-964.
Hunnicut, S. 1976. Phonological rules for a
text-to-speech system. American Journal of
Computational Linguistics, Microfiche 57.
Hunnicut, S. 1980. Grapheme to Phoneme
Rules: A Review. STL-QPSR 2-3.
Kaplan, R. M. and M. Kay. 1994. Regular
models of phonological rule systems.
Computational Linguistics 20(3).
Klatt, D. H. 1987. Review of text to speech
conversion for English. Journal of the
Acoustical Society of America 82(3): 737-793.
Klatt, D. H. and D. W. Shipman. 1982.
Letter-to-phoneme rules: A
semi-automatic discovery procedure.
Journal of the Acoustical Society of America
82: 737-793.
Laporte, E. 1988. Methodes algorithmiques
et lexicales de phonetisation de textes.
These, Universite Paris 7, May.
Levin, H. 1963. A basic research program on
reading. Final Report, Cooperative
Research Project No. 639, Cornell
University.
Liberman, M. Y. and A. Prince. 1977. On
stress and linguistic rhythm. Linguistic
Inquiry 8(2): 249-336.
Lucas, S. M. and R. I. Damper. 1992.
Syntactic neural networks for
bi-directional text-phonetics translation.
In G. Bailly and C. Benoit, editors, Talking
Machines, Theories, Models and Designs.
North-Holland Publishers.
Lucassen, J. M. and R. L. Mercer. 1984. An
information theoretic approach to the
automatic determination of phonemic
baseforms. In Proceedings of ICASSP-84,
pages 42.5.1-42.5.3, San Diego.
McCormick, S. and S. R. Hertz. 1989. A new
approach to English text-to-phoneme
conversion using delta, Version 2. 117th
Meeting. Journal of the Acoustical Society of
America, Supplement 1, Vol. 85, S124.
McIlroy, M. D. 1974. Synthetic English
speech by rules. Bell Telephone
Laboratories Memo.
Meng, H. M. 1995. Phonological Parsing for
Bi-Directional Letter-to-Sound and
Sound-to-Letter Generation. Ph.D. Thesis,
MIT, Cambridge, MA.
O&apos;Malley, M. H. 1990. Text-to-speech
conversion technology. Computer IEEE,
page 17.
O&apos;Shaughnessy, D., M. Lennig,
P. Mermelstein, and M. Divay. 1981.
Simulation d&apos;un lecteur automatique du
Francais. 12emes Journees d&apos;Etudes sur la
Parole, Montreal, Canada.
Parfitt, S. and R. Sharman. 1991. A
bi-directional model of English
pronunciation. In Proceedings of Eurospeech,
volume 2, pages 801-804.
Prouts, B. 1980. Contribution a la synthese de la
parole a partir de texte; transcription
graphe&apos;mo-phonetique en temps reel sur
microprocesseur. These de
Docteur-Ingenieur, Universite de Paris
Sud, Orsay.
Rey, A., A. Duval, B. Vienne, B. Struyf,
M. Divay, T. Lootens and S. Zimmermann.
1989. Le Robert Elect ronique. Ensemble
d&apos;Outils d&apos;Aide a la Redaction de Textes
Francais sur Disque Optique Compact
(CD-ROM), November.
Sejnowski, T. J. and C. R. Rosenberg. 1987.
NETtalk: Parallel networks that learn to
pronounce English text. Complex Systems
1:145-168.
Spiegel, M. F. 1985. Pronouncing surnames
automatically. In Proceedings of AVIOS.
Spiegel, M. F. and M. J. Machi. 1990.
Synthesis of names by a
demi-syllable-based speech synthesizer
(Orator). Journal of the American Voice
Input/Output Society 7:1-10.
Thimonnier, R. 1978. Code Orthographique et
Grammatical. Collections Marabout.
Venezky, R. L. 1962. A Computer Program for
Deriving Spelling to Sound Correlations. MA
thesis, Cornell University. Published in
part in A Basic Research Program on
Reading. See Levin 1963.
Venezky, R. L. 1966. Automatic
spelling-to-sound conversion. Computation
in Linguistics: A Case Book. Indiana
University Press, Bloomington, IN.
Venezky, R. L. 1967a. English orthography:
Its graphical structure and its relation to
sound. Reading Research Quarterly, II.
Venezky, R. L. 196713, Reading:
Grapheme-phoneme relationships.
Education 87: 519-524.
Venezky, R. L. 1967c, The basis of English
orthography. Acta Linguistica 10: 145-159.
Venezky, R. L. 1970. The Structure of English
Orthography. Mouton, The Hague.
Venezky, R. L. and R. Weir. 1966. A study of
selected spelling-to-sound correspondence
patterns. Final Report, Cooperative
Research project No. 3090, Stanford
University.
Vitale, A. J. 1991. An algorithm for high
accuracy name pronunciation by
parametric speech synthesizer.
Computational Linguistics 17(3).
Yarowsky, D. 1994. Homograph
disambiguation in text-to-speech
synthesis. Second ESCA/IEEE Workshop
</reference>
<page confidence="0.984353">
522
</page>
<note confidence="0.486775">
Divay and Vitale Grapheme-Phoneme Translation
</note>
<reference confidence="0.998572384615385">
on Speech Synthesis.
Yvon, F. 1996. Prononcer par analogie:
motivation, formalisation et evaluation. These,
Ecole nationale des Telecommunications,
Paris.
Weir, R. 1964. Formulation of
grapheme-phoneme correspondence rules
to aid the teaching of reading. Final
Report, Cooperative Research project
No. S-039 Stanford University.
Wells, J. C. 1982. Accents of English, An
Introduction, Chapter 3. Cambridge
University Press.
</reference>
<page confidence="0.99892">
523
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.239442">
<title confidence="0.998638">Algorithms for Grapheme-Phoneme Translation for English and French: Applications for Database Searches and Speech Synthesis</title>
<author confidence="0.999948">Michel Diyay Anthony J Vital&amp;</author>
<affiliation confidence="0.998694">Universite de Rennes Digital Equipment Corporation</affiliation>
<abstract confidence="0.934027696969697">Letter-to-sound rules, also known as grapheme-to-phoneme rules, are important computational tools and have been used for a variety of purposes including word or name lookups for database searches and speech synthesis. These rules are especially useful when integrated into database searches on names and addresses, since they can complement orthographic search algorithms that make use of permutation, deletion, and insertion by allowing for a comparison with the phonetic equivalent. In databases, phonetics can help retrieve a word or a proper name without the user needing to know the correct spelling. A phonetic index is built with the vocabulary of the application. This could be an entire dictionary, or a list of proper names. The searched word is then converted into phonetics and retrieved with its information, ff the word is in the phonetic index. This phonetic lookup can be used to retrieve a misspelled word in a dictionary or a database, or in a text editor to suggest corrections. Such rules are also necessary to formalize grapheme-phoneme correspondences in speech synthesis architecture. In text-to-speech systems, these rules are typically used to create phonemes from computer text. These phonemic symbols, in turn, are used to feed lower-level phonetic modules (such as timing, intonation, vowel formant trajectories, etc.) which, in turn, feed a vocal tract model and finally output a waveform and, via a digital-analogue converter, synthesized speech. Such rules are a necessary and integral part of a text-to-speech system since a database lookup (dictionary search) is not sufficient to handle derived forms, new words, nonce forms, proper nouns, low-frequency technical jargon, and the like; such forms typically are not included in the database. And while the use of a dictionary is more important now that denser and faster memory is available to smaller systems, letter-to-sound still plays a crucial and central role in speech synthesis technology. Grapheme-to-phoneme technology is also useful in speech recognition, as a way of generating pronunciations for new words that may be available in grapheme form, or for naive users to add new words more easily. In that case, the system must generate the multiple variations of the word. While there are different problems in languages that use non-alphabetic writing systems (syllabaries, as in Japanese, or logographic systems, as in Chinese) (DeFrancis 1984), all alphabetic systems have a structured set of correspondences. These range from the trivial in languages like Spanish or Swahili, to extremely complex in languages such as English and French. This paper * Universite de Rennes, Institut Universitaire de Technologie, B.P. 150, 22302 Lannion, France. E-mail: divay@iut-lannion.fr t Digital Equipment Corporation, 200 Forest St. (MR01-1/L31), Marlborough, MA 01752-3011. E-mail:</abstract>
<email confidence="0.980436">yitale@dectlk.enet.dec.com</email>
<note confidence="0.97561775">C) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 4 will outline some of the previous attempts to construct such rule sets and will describe new and successful approaches to the construction of letter-to-sound rules for English and French.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>W A Ainsworth</author>
</authors>
<title>A system for converting English text into speech.</title>
<date>1973</date>
<booktitle>In IEEE Transactions of Audio and Elect roacoustics,</booktitle>
<pages>288--290</pages>
<contexts>
<context position="4155" citStr="Ainsworth (1973)" startWordPosition="614" endWordPosition="615">ptions) in many of the older descriptive grammars of languages such as English and French. The paucity of literature in grapheme-to-phoneme translation is partially due to the fact that the field of linguistics, and in particular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptiv</context>
</contexts>
<marker>Ainsworth, 1973</marker>
<rawString>Ainsworth, W. A. 1973. A system for converting English text into speech. In IEEE Transactions of Audio and Elect roacoustics, pages 288-290.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Allen</author>
</authors>
<title>Synthesis of speech from unrestricted text.</title>
<date>1976</date>
<booktitle>In IEEE</booktitle>
<volume>64</volume>
<issue>4</issue>
<contexts>
<context position="40200" citStr="Allen 1976" startWordPosition="6497" endWordPosition="6498">] [I] [DI / — +; With the word riding, a context-sensitive rule in ing would produce the phonemes for ing plus a mark indicating that the syllable is unstressed, replace the suffix ing by e+ in the input string, which is then ride+, and continue the conversion from right to left starting on e. ing &gt; e+ —4 • • • / -+; With the word relationship, the rule decomposes the word into relation + ship: ship &gt; + —+ ... / —+; scandalousness is decomposed into scandal + ous + ness by the following rules: ness &gt; + —&gt; ous &gt;+ —&gt; This suffix stripping is the main reason for a right-to-left scan for English (Allen 1976). Example 5 o —&gt; [u o5] / micr —; means o will be translated as ED] if the syllable is stressed (micrometer), and as otherwise (microgram). (See Section 5.7 for stress assignment) 5.3 Normalization for English Text normalization, i.e., replacing numbers, abbreviations and acronyms, by their full text equivalents is done in a preprocessing section. In English, the choice between expansion to the full graphemic equivalence or expansion to a full phonetic equivalence was made in favor of the latter. English contains a separate preprocessing section for numbers (24 in twenty-four), acronyms (IBM, </context>
<context position="73092" citStr="Allen (1976)" startWordPosition="12086" endWordPosition="12087">ring (the output string replacing the input text at the end of a block of rules). The input string is not modified. Rules can check the left and right contexts of the input string, and the left context of the output string. French is not a stressed language, so there is no need for a syllabification module or a stress module. Many problems persist for phonemicization. In English, suffix stripping, compound decomposition, and primary stressed syllable are very important to get the proper phoneme string, and are carried out mostly by rules without an explicit morph dictionary, contrary to as in Allen (1976), who uses a morph dictionary with 12,000 morphs, or Coker (1985), whose dictionary has 43,000 morphs. In French, the word-byword conversion is probably simpler due to the absence of stressed syllables. Affixes do not alter the pronunciation of the root; compare, for instance, photo, photograph, and photography in English with photo, photographe and photographie in French. But in French, there are more interactions between words due to the linking problem (nous avons) and mute e (chemin defer). These interactions are also dependent on speech rate. Sometimes the homograph problem can be solved </context>
</contexts>
<marker>Allen, 1976</marker>
<rawString>Allen, J. 1976. Synthesis of speech from unrestricted text. In IEEE 64 (4), April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Allen</author>
<author>R Carlson</author>
<author>B GranstrOm</author>
<author>S Hunnicutt</author>
<author>D H Klatt</author>
<author>D B Pisoni</author>
</authors>
<date>1979</date>
<institution>Monograph, Massachusetts Institute of Technology,</institution>
<location>Cambridge, MA.</location>
<note>Conversion of unrestricted text-to-speech. Unpublished</note>
<contexts>
<context position="18738" citStr="Allen et al., 1979" startWordPosition="2924" endWordPosition="2927">as in feu, flamme, amphibie, alpha. 4 Called an e muet &apos;mute e&apos; in French linguistics. 499 Computational Linguistics Volume 23, Number 4 each of which retains its pronunciation. Usually, in French, s between two vowels is pronounced [z], otherwise [s]. The s in tournesol, entresol, telesiege, vraisemblable, contresens, antisocial must be considered the beginning of a morpheme, and although it occurs between two vowels, is pronounced [s]. This morpheme decomposition is difficult and is sometimes based on a large dictionary of morphs. Some implementations have had as many as 12,000 for English (Allen et al., 1979). For English, and French, the number of words having this problem is relatively small, and can be dealt with by a dictionary or rules. In the English implementation, for example, many such morphemes can be incorporated directly into the letter-to-sound rule set itself. For certain other languages, such as German, where word compounding is quite common, morpheme decomposition algorithms tend to be much more complex. 3.4 Homographs Homographs are pairs of words that are orthographically identical but phonetically different. In English, this difference is often simply a difference in stress depe</context>
</contexts>
<marker>Allen, Carlson, GranstrOm, Hunnicutt, Klatt, Pisoni, 1979</marker>
<rawString>Allen, J., R. Carlson, B. GranstrOm, S. Hunnicutt, D. H. Klatt, and D. B. Pisoni. 1979. Conversion of unrestricted text-to-speech. Unpublished Monograph, Massachusetts Institute of Technology, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Auberge</author>
</authors>
<title>La synthese de la parole: &amp;quot;des regles au lexique&amp;quot;. These, Universite Stendhal,</title>
<date>1991</date>
<location>Grenoble.</location>
<contexts>
<context position="4498" citStr="Auberge (1991)" startWordPosition="663" endWordPosition="664"> since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternati</context>
</contexts>
<marker>Auberge, 1991</marker>
<rawString>Auberge, V. 1991. La synthese de la parole: &amp;quot;des regles au lexique&amp;quot;. These, Universite Stendhal, Grenoble.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Bakiri</author>
<author>T G Dietterich</author>
</authors>
<title>Converting English Text to Speech: A Machine Learning Approach.</title>
<date>1991</date>
<tech>Ph.D. thesis.</tech>
<contexts>
<context position="4185" citStr="Bakiri and Dietterich (1991)" startWordPosition="616" endWordPosition="619"> the older descriptive grammars of languages such as English and French. The paucity of literature in grapheme-to-phoneme translation is partially due to the fact that the field of linguistics, and in particular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a </context>
<context position="5506" citStr="Bakiri and Dietterich 1991" startWordPosition="809" endWordPosition="812">respondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approa</context>
</contexts>
<marker>Bakiri, Dietterich, 1991</marker>
<rawString>Bakiri, G., and T. G. Dietterich. 1991. Converting English Text to Speech: A Machine Learning Approach. Ph.D. thesis.</rawString>
</citation>
<citation valid="false">
<authors>
<author>No</author>
</authors>
<tech>91-30-1.</tech>
<institution>Department of Computer Science, Oregon State University.</institution>
<marker>No, </marker>
<rawString>Rep. No. 91-30-1. Department of Computer Science, Oregon State University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Bechet</author>
<author>T Spriet</author>
<author>M El-Beze</author>
</authors>
<title>Traitement specifique des noms propres dans un systerne de transcription grapheme-phoneme.</title>
<date>1996</date>
<publisher>JST Avignon.</publisher>
<marker>Bechet, Spriet, El-Beze, 1996</marker>
<rawString>Bechet F., T. Spriet, and M. El-Beze. 1996. Traitement specifique des noms propres dans un systerne de transcription grapheme-phoneme. JST Avignon.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Crane</author>
<author>E Yeager L</author>
<author>R Whitman</author>
</authors>
<title>An Introduction to Linguistics, Chapter 4:</title>
<date>1981</date>
<journal>History of English. Little, Brown and Company.</journal>
<marker>Crane, L, Whitman, 1981</marker>
<rawString>Ben Crane, L., E. Yeager, and R. Whitman. 1981. An Introduction to Linguistics, Chapter 4: History of English. Little, Brown and Company.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Bernstein</author>
<author>L Nessly</author>
</authors>
<title>Performance comparison of component algorithms for the phonemicization of orthography.</title>
<date>1981</date>
<booktitle>In Proceedings of the 19th</booktitle>
<contexts>
<context position="4214" citStr="Bernstein and Nessly (1981)" startWordPosition="620" endWordPosition="623">s of languages such as English and French. The paucity of literature in grapheme-to-phoneme translation is partially due to the fact that the field of linguistics, and in particular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which</context>
</contexts>
<marker>Bernstein, Nessly, 1981</marker>
<rawString>Bernstein, J. and L. Nessly. 1981. Performance comparison of component algorithms for the phonemicization of orthography. In Proceedings of the 19th</rawString>
</citation>
<citation valid="false">
<institution>Annual Meeting, Stanford University. Association for Computational Linguistics.</institution>
<marker></marker>
<rawString>Annual Meeting, Stanford University. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Burney</author>
</authors>
<title>Que sais-je?</title>
<date>1955</date>
<journal>L&apos;orthographe. Collections.</journal>
<contexts>
<context position="12880" citStr="Burney 1955" startWordPosition="1978" endWordPosition="1979">) spoke a Celtic language. The Roman occupation (which lasted until 476 A.D.) resulted in well-educated people speaking Latin; for others, a language derived from Latin. After the Roman pullback, the language continued to evolve in different ways, especially since few people knew how to read. The first written texts in the new language, called Roman ([romal), appear only in the 9th Century. Then official papers written in Latin began to be written in Roman. Up until the 17th Century, standardization in spelling had been vague until dictionaries, schools, and laws enforced a standard spelling (Burney 1955; Catach 1978; Thimonnier 1978). Spelling reform is currently an extremely controversial subject in France, which can cause social and business problems when it is under discussion. Only minor corrections have recently been approved. Consequently, computational applications have to deal with this problem in the same way as do young students or foreigners learning the language.&apos; There are many classic examples of the problem in English. Among those often cited are the different phonetic realizations of the grapheme sequence ough as in rough [AI], through [III], bough ja231, thought [D1], dough </context>
</contexts>
<marker>Burney, 1955</marker>
<rawString>Burney, P. 1955. Que sais-je? L&apos;orthographe. Collections.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Catach</author>
</authors>
<title>Que sais-je?</title>
<date>1978</date>
<journal>L&apos;orthographe. Collections.</journal>
<contexts>
<context position="12893" citStr="Catach 1978" startWordPosition="1980" endWordPosition="1981">tic language. The Roman occupation (which lasted until 476 A.D.) resulted in well-educated people speaking Latin; for others, a language derived from Latin. After the Roman pullback, the language continued to evolve in different ways, especially since few people knew how to read. The first written texts in the new language, called Roman ([romal), appear only in the 9th Century. Then official papers written in Latin began to be written in Roman. Up until the 17th Century, standardization in spelling had been vague until dictionaries, schools, and laws enforced a standard spelling (Burney 1955; Catach 1978; Thimonnier 1978). Spelling reform is currently an extremely controversial subject in France, which can cause social and business problems when it is under discussion. Only minor corrections have recently been approved. Consequently, computational applications have to deal with this problem in the same way as do young students or foreigners learning the language.&apos; There are many classic examples of the problem in English. Among those often cited are the different phonetic realizations of the grapheme sequence ough as in rough [AI], through [III], bough ja231, thought [D1], dough [aL3], cough </context>
</contexts>
<marker>Catach, 1978</marker>
<rawString>Catach, N. 1978. Que sais-je? L&apos;orthographe. Collections.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Catach</author>
</authors>
<title>Informatique: Traitement automatique du Langage. Bulletin Liaisons-Heso,</title>
<date>1989</date>
<contexts>
<context position="4549" citStr="Catach (1989)" startWordPosition="670" endWordPosition="671">mary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (si</context>
</contexts>
<marker>Catach, 1989</marker>
<rawString>Catach, N. 1989. Informatique: Traitement automatique du Langage. Bulletin Liaisons-Heso, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Catach</author>
<author>L Catach</author>
</authors>
<title>Presentation du logiciel VOISINETTE, &amp;quot;Un correcteur a entree phonetique&amp;quot;.</title>
<date>1992</date>
<publisher>CNRS-INFOS.</publisher>
<contexts>
<context position="4575" citStr="Catach and Catach (1992)" startWordPosition="672" endWordPosition="675">. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other st</context>
</contexts>
<marker>Catach, Catach, 1992</marker>
<rawString>Catach, N. and L. Catach 1992. Presentation du logiciel VOISINETTE, &amp;quot;Un correcteur a entree phonetique&amp;quot;. CNRS-INFOS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K W Church</author>
</authors>
<title>Stress assignment in letter to sound rules for speech synthesis.</title>
<date>1985</date>
<booktitle>In Proceedings of the 23rd Annual Meeting,</booktitle>
<pages>246--253</pages>
<institution>University of Chicago. Association for Computional Linguistics.</institution>
<contexts>
<context position="30758" citStr="Church 1985" startWordPosition="4902" endWordPosition="4903">ng Italian names (pronounced [e] in Italian) is typically pronounced [ill or even [ 1 (not pronounced). The proper name Falcone is pronounced in anglophone countries as either [fx1103rtil] or even [flIcon], Bach as either [bax] or [bald. In French, we observe a similar situation where the name Smith is pronounced [smis] and Thatcher as [satf or] as French does not have a [0] phoneme. There have been successful attempts to automatically detect the ethnic group of a proper name for use in anglophone countries like the United States, and to apply a different set of rules depending on that group (Church 1985, Vitale 1991). Trigram frequencies are computed from a large set of proper names whose ethnic group is known, and used to classify a new proper name in terms of some language, language group, or language family (the linguistic etymology of the name). Depending on that classification, different subsets of language-specific rules can be activated. 4. Expert Systems Expert systems are used to facilitate the transfer of the knowledge of a specific domain from an expert to a computer. They traditionally distinguish between the system, which is as independent as possible from the application, and t</context>
</contexts>
<marker>Church, 1985</marker>
<rawString>Church, K. W. 1985. Stress assignment in letter to sound rules for speech synthesis. In Proceedings of the 23rd Annual Meeting, pages 246-253, University of Chicago. Association for Computional Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G N Clemens</author>
<author>S J Keyser</author>
</authors>
<title>CV Phonology: A Generative Theory of the Syllable. Linguistic Inquiry Monograph Nine.</title>
<date>1983</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="45136" citStr="Clemens and Keyser 1983" startWordPosition="7309" endWordPosition="7312">lables according to consonant clusters, vowels, and morph boundaries. For instance, scandalousness, which has been processed by the previous steps as: [s][k][][n][d] [a] [1] -F [a] [s] + [n] [i] [s] is decomposed into syllables as follows: [s] [k] [x] [n] — [d] [01 [1] + [o] [s] + [n] [i] [s] chevron would result in: Li] [e] [v] [r] [a] [n] and would be decomposed as: [1] [e] [v] — [r] [a] [n] Although there are several different theories of syllabification, any standard linguistics book will have a reference to these valid clusters and an accurate definition of the syllable for a language L (Clemens and Keyser 1983). It is beyond the scope of this paper to discuss the merits of one theory of the English syllable over another. Whatever theory is chosen, syllabification should serve as an accurate input into the module that handles stress.&amp;quot; 5.7 Stress The letter-to-sound rule set described above sets lexical stress in a wide variety of cases, especially where the word is monosyllabic or the suffixal information is sufficient to place primary or secondary stress. These routines contain special rules, which contain a number of different options: (a) assign primary stress, (b) place primary stress n syllables</context>
</contexts>
<marker>Clemens, Keyser, 1983</marker>
<rawString>Clemens, G. N. and S. J. Keyser. 1983. CV Phonology: A Generative Theory of the Syllable. Linguistic Inquiry Monograph Nine. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C H Coker</author>
</authors>
<title>A dictionary-intensive letter-to-sound program.</title>
<date>1985</date>
<journal>Journal of the Acoustical Society of America Supplement</journal>
<volume>1</volume>
<pages>7</pages>
<contexts>
<context position="73157" citStr="Coker (1985)" startWordPosition="12097" endWordPosition="12098">block of rules). The input string is not modified. Rules can check the left and right contexts of the input string, and the left context of the output string. French is not a stressed language, so there is no need for a syllabification module or a stress module. Many problems persist for phonemicization. In English, suffix stripping, compound decomposition, and primary stressed syllable are very important to get the proper phoneme string, and are carried out mostly by rules without an explicit morph dictionary, contrary to as in Allen (1976), who uses a morph dictionary with 12,000 morphs, or Coker (1985), whose dictionary has 43,000 morphs. In French, the word-byword conversion is probably simpler due to the absence of stressed syllables. Affixes do not alter the pronunciation of the root; compare, for instance, photo, photograph, and photography in English with photo, photographe and photographie in French. But in French, there are more interactions between words due to the linking problem (nous avons) and mute e (chemin defer). These interactions are also dependent on speech rate. Sometimes the homograph problem can be solved by looking at the left and right context of the word, but the gen</context>
</contexts>
<marker>Coker, 1985</marker>
<rawString>Coker, C. H. 1985. A dictionary-intensive letter-to-sound program. Journal of the Acoustical Society of America Supplement 1, Vol. 78, S7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Cotto</author>
</authors>
<title>Traitement automatique des textes en vue de la syn these vocale. These, Universite Paul Sabatier,</title>
<date>1992</date>
<location>Toulouse III.</location>
<contexts>
<context position="4589" citStr="Cotto (1992)" startWordPosition="676" endWordPosition="677">e rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included</context>
</contexts>
<marker>Cotto, 1992</marker>
<rawString>Cotto, D. 1992. Traitement automatique des textes en vue de la syn these vocale. These, Universite Paul Sabatier, Toulouse III.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Dedina</author>
<author>H C Nusbaum</author>
</authors>
<title>PRONOUNCE: A program for pronunciation by analogy.</title>
<date>1991</date>
<journal>Computer Speech and Language</journal>
<pages>5--55</pages>
<contexts>
<context position="5389" citStr="Dedina and Nusbaum 1991" startWordPosition="792" endWordPosition="795">e and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rul</context>
</contexts>
<marker>Dedina, Nusbaum, 1991</marker>
<rawString>Dedina, M. J. and H. C. Nusbaum. 1991. PRONOUNCE: A program for pronunciation by analogy. Computer Speech and Language 5:55-64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J DeFrancis</author>
</authors>
<title>The Chinese Language: Fact and Fantasy.</title>
<date>1984</date>
<publisher>University of Hawaii Press.</publisher>
<contexts>
<context position="2647" citStr="DeFrancis 1984" startWordPosition="401" endWordPosition="402">t now that denser and faster memory is available to smaller systems, letter-to-sound still plays a crucial and central role in speech synthesis technology. Grapheme-to-phoneme technology is also useful in speech recognition, as a way of generating pronunciations for new words that may be available in grapheme form, or for naive users to add new words more easily. In that case, the system must generate the multiple variations of the word. While there are different problems in languages that use non-alphabetic writing systems (syllabaries, as in Japanese, or logographic systems, as in Chinese) (DeFrancis 1984), all alphabetic systems have a structured set of correspondences. These range from the trivial in languages like Spanish or Swahili, to extremely complex in languages such as English and French. This paper * Universite de Rennes, Institut Universitaire de Technologie, B.P. 150, 22302 Lannion, France. E-mail: divay@iut-lannion.fr t Digital Equipment Corporation, 200 Forest St. (MR01-1/L31), Marlborough, MA 01752-3011. E-mail: yitale@dectlk.enet.dec.com C) 1997 Association for Computational Linguistics Computational Linguistics Volume 23, Number 4 will outline some of the previous attempts to c</context>
</contexts>
<marker>DeFrancis, 1984</marker>
<rawString>DeFrancis, J. 1984. The Chinese Language: Fact and Fantasy. University of Hawaii Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Dirksen</author>
<author>J Coleman</author>
</authors>
<title>All-Prosodic speech synthesis.</title>
<date>1994</date>
<booktitle>Second ESCA/IEEE Workshop on Speech Synthesis.</booktitle>
<contexts>
<context position="28049" citStr="Dirksen and Coleman (1994)" startWordPosition="4459" endWordPosition="4462">imes may not apply in unusual cases, such as in very slow speech where each word is pronounced or in poetry (which often has its own set of rules different from normal speech). Thus far, in the area of speech synthesis, at least, not much has been done to modify segmental phonology according to speech rate. In English, when the speech rate exceeds a certain threshold, in natural speech, pauses disappear and segmental durations become shortened. In the future, in text-tospeech systems, some segments and even syllables will disappear entirely and certain functors will be greatly attenuated. See Dirksen and Coleman (1994) for more on speech rate. In French, in words containing a semivowel followed by a vowel, if the speech rate is slow enough (or sometimes in poetic contexts), a semivowel could be produced as a vowel: /ui &apos;him&apos; ([4] vs. [lyi]), nuage &apos;cloud&apos; Untia3] vs. [nyag, her &apos;to bind&apos; ([1je] vs. [lie]). A common phrase such as parce que &apos;because&apos;, which is typically two syllables in normal speech ([parska]) becomes three syllables in very slow or emphatic speech ((parsokal). In fast speech, the phrase je te he dirai [3atalodirc] &apos;I will tell you&apos; is pronounced je t&apos;le dirai [3atladire] or j&apos;tel dirai [3t</context>
</contexts>
<marker>Dirksen, Coleman, 1994</marker>
<rawString>Dirksen, A. and Coleman, J. 1994. All-Prosodic speech synthesis. Second ESCA/IEEE Workshop on Speech Synthesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Divay</author>
</authors>
<title>De l&apos;ecrit vers l&apos;oral ou contribution a l&apos;etude des traitements des textes ecrits en vue de leur prononciation sur synthetiseur de parole. These d&apos;Etat, Universite de</title>
<date>1984</date>
<location>Rennes, France.</location>
<contexts>
<context position="4602" citStr="Divay (1984" startWordPosition="678" endWordPosition="679"> in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlr</context>
<context position="6153" citStr="Divay (1984" startWordPosition="910" endWordPosition="911">d Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b, 1991, 1994), and others, all of which are essentially knowledge-rich expert systems. The various attempts at rule formulation were related to differences in the phonemic inventory, the number of rules, the type and format of rules, and even the direction of parse of the rules (whether they were scanned from left to right or from right to left). Different approaches were also taken in the size of the dictionary, the algorithm used to scan or rescan the dictionary (if one was used), the methods for determining lexical stress placement, the amount of morphological analysis u</context>
<context position="58887" citStr="Divay 1984" startWordPosition="9784" endWordPosition="9785">imited parsing has been done using the same formalism as letter-to-sound. A dictionary lookup gives one or several grammatical categories for the most common words. By examining the left and right words, it is possible in most of the cases to get an idea of the grammatical categories of the unmarked words or to reduce (to one if possible) the set of potential grammatical categories for each word of a sentence. The same formalism allows the processing of grammatical categories (verb, adverb, preposition, etc.) instead of characters for transcription. A class is a set of grammatical categories (Divay 1984, 1985). If the grammatical category is known (where V = Verb), it can be used in the rules: 20 : ent(V) --- / — 4 ent is eliminated at the end of a word (right context is a space) if the word is a verb (us chantent). 6.6 Linking In some cases, a new phoneme is added between two words of a same-breath group. For instance, a [z] phoneme is added between the two words of les enfants. The second word has to begin with a vowel or aspirated h, and the first one to end with n, s, d, t, x, or z. It depends also on the grammatical category of both words. This problem also is solved by rules, such as t</context>
</contexts>
<marker>Divay, 1984</marker>
<rawString>Divay, M. 1984. De l&apos;ecrit vers l&apos;oral ou contribution a l&apos;etude des traitements des textes ecrits en vue de leur prononciation sur synthetiseur de parole. These d&apos;Etat, Universite de Rennes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Divay</author>
</authors>
<title>A text-processing expert system. 5eme Congres Reconnaissance des formes et Intelligence Artificielle,</title>
<date>1985</date>
<location>Novembre</location>
<marker>Divay, 1985</marker>
<rawString>Divay, M. 1985. A text-processing expert system. 5eme Congres Reconnaissance des formes et Intelligence Artificielle, Novembre 1985, Grenoble, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Divay</author>
</authors>
<title>Traitement du langage naturel: la phonetisation ou comment apprendre a l&apos;ordinateur a lire un texte Francais. MICRO-SY STEMES,</title>
<date>1990</date>
<marker>Divay, 1990</marker>
<rawString>Divay, M. 1990a. Traitement du langage naturel: la phonetisation ou comment apprendre a l&apos;ordinateur a lire un texte Francais. MICRO-SY STEMES, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Divay</author>
</authors>
<title>A written processing expert system for text to phoneme conversion.</title>
<date>1990</date>
<booktitle>In Proceedings of the International Conference on Spoken Language (ICSLP 90),</booktitle>
<location>Kobe, Japan.</location>
<marker>Divay, 1990</marker>
<rawString>Divay, M. 1990b. A written processing expert system for text to phoneme conversion. In Proceedings of the International Conference on Spoken Language (ICSLP 90), Kobe, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Divay</author>
</authors>
<date>1991</date>
<booktitle>CD-ROM Electronic Dictionary,</booktitle>
<marker>Divay, 1991</marker>
<rawString>Divay, M. 1991. CD-ROM Electronic Dictionary, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Divay</author>
</authors>
<title>Indexation phonetique et recherche documentaire.</title>
<date>1994</date>
<booktitle>In Proceedings of the 9eme Congres AFCET, Paris, Volume 2: Intelligence Artificielle.</booktitle>
<marker>Divay, 1994</marker>
<rawString>Divay, M. 1994. Indexation phonetique et recherche documentaire. In Proceedings of the 9eme Congres AFCET, Paris, Volume 2: Intelligence Artificielle.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H S Elovitz</author>
<author>R W Johnson</author>
<author>A McHugh</author>
<author>J E Shore</author>
</authors>
<title>Automatic translation of English text to phonetics by means of letter-to-sound rules.</title>
<date>1976</date>
<tech>NRL Report 7948,</tech>
<institution>Naval Research Laboratory,</institution>
<location>Washington, D.C.</location>
<contexts>
<context position="4237" citStr="Elovitz et al. (1976)" startWordPosition="624" endWordPosition="627">h and French. The paucity of literature in grapheme-to-phoneme translation is partially due to the fact that the field of linguistics, and in particular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be bu</context>
</contexts>
<marker>Elovitz, Johnson, McHugh, Shore, 1976</marker>
<rawString>Elovitz, H. S., R. W. Johnson, A. McHugh, and J. E. Shore. 1976. Automatic translation of English text to phonetics by means of letter-to-sound rules. NRL Report 7948, Naval Research Laboratory, Washington, D.C.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Golding</author>
</authors>
<title>Pronouncing Names by a Combination of Case-based and Rule-based Reasoning.</title>
<date>1991</date>
<tech>Ph.D. Thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="5839" citStr="Golding 1991" startWordPosition="861" endWordPosition="862">tic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b, 1991, 1994), and others, all of which are essentially knowledge-rich expert systems. The various attempts at rule formulation were related to differences in the phonemic inventory, the number of rules, the type and format of rules, and even the direction of parse </context>
</contexts>
<marker>Golding, 1991</marker>
<rawString>Golding, A. R. 1991. Pronouncing Names by a Combination of Case-based and Rule-based Reasoning. Ph.D. Thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A R Golding</author>
<author>P S Rosenbloom</author>
</authors>
<title>A comparison of anapron with seven other name-pronunciation systems.</title>
<date>1993</date>
<journal>Journal of the American Voice Input/Output Society</journal>
<pages>14--1</pages>
<contexts>
<context position="60940" citStr="Golding and Rosenbloom 1993" startWordPosition="10159" endWordPosition="10162">eme followed by a vowel phoneme as in emploiera [aplwa@ra], which becomes [aplwara]. Elision often occurs at the end of words (petite), or in the middle of words (emploiera, tellement). It can be done in the first syllable (pesanteur, retard, teneur) except if there are two consonants as in premier. It is never done if suppressing [9] would result in three or more consecutive consonants. 7. Testing No standardized tests exist for evaluating letter-to-sound systems, although some researchers are beginning to look at the problem in order to determine whether one approach has merit over another (Golding and Rosenbloom 1993). For example, the Oregon Graduate Institute is currently investigating letter-to-sound rules done in more traditional ways and comparing them to neural network learning. Tests can be done: 1. with or without an exception dictionary lookup running before the rules, 2. on text extracted from papers, books, magazines. In that case, the same words is counted as many times as it appears in the text. This is especially true for linking words (one, a, the, is, etc.), which are then counted many times. A more systematic test can be carried out using an electronic dictionary, having for each entry (gr</context>
</contexts>
<marker>Golding, Rosenbloom, 1993</marker>
<rawString>Golding, A. R. and P. S. Rosenbloom. 1993. A comparison of anapron with seven other name-pronunciation systems. Journal of the American Voice Input/Output Society 14:1-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Gonzalez</author>
<author>J P Tubach</author>
</authors>
<title>Reseaux connexionistes pour la traduction orthographique phonetique: Applications a l&apos;Espagnol et au Francais. 136me Journees d&apos;Etudes sur la Parole,</title>
<date>1982</date>
<location>Montreal, Canada.</location>
<contexts>
<context position="5532" citStr="Gonzalez and Tubach 1982" startWordPosition="813" endWordPosition="816"> words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Alle</context>
</contexts>
<marker>Gonzalez, Tubach, 1982</marker>
<rawString>Gonzalez, S. and J. P. Tubach. 1982. Reseaux connexionistes pour la traduction orthographique phonetique: Applications a l&apos;Espagnol et au Francais. 136me Journees d&apos;Etudes sur la Parole, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Greenberg</author>
</authors>
<title>A quantitative approach to the morphological typology of language. In</title>
<date>1990</date>
<booktitle>On Language: Selected Writings of</booktitle>
<editor>K. Denning and S. Kemmer, editors,</editor>
<publisher>Stanford University Press, Stanford.</publisher>
<contexts>
<context position="70493" citStr="Greenberg 1990" startWordPosition="11669" endWordPosition="11670">es of the world are of an equal degree of complexity. Primitive languages are a myth perpetrated by early anthropologists, missionaries, and adventurers. However, when we compare different subsytems of any two languages, it quickly becomes clear that subsystems are vastly different in complexity. This is true of the phonological, phonetic, morphological, syntactic, semantic and letter-to-sound subsystems of two different languages; some are an order of magnitude more complex than others. 518 Divay and Vitale Grapheme-Phoneme Translation sound rules. Many languages with a high synthetic index (Greenberg 1990) fall into this category.° 8.3 Complex Systems Certain languages, such as English and French, are among the most complex languages to construct letter-to-sound rules for. These are not the only languages in this last category. Any language with an old writing system that has not undergone a modicum of spelling reform but has undergone dramatic phonological, morphonemic, and morphological changes will probably fall into this category. 9. Conclusions We have presented the difficulties of grapheme-to-phoneme conversion for English and French. Both languages have evolved from different origins, an</context>
</contexts>
<marker>Greenberg, 1990</marker>
<rawString>Greenberg, J. 1990. A quantitative approach to the morphological typology of language. In K. Denning and S. Kemmer, editors, On Language: Selected Writings of Joseph H. Greenberg. Stanford University Press, Stanford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Halle</author>
<author>S J Keyser</author>
</authors>
<title>English Stress: Its Form, its Growth and its Role in Verse. Harper and Row,</title>
<date>1971</date>
<location>New York.</location>
<contexts>
<context position="21522" citStr="Halle and Keyser 1971" startWordPosition="3370" endWordPosition="3373">iz] (six enfants), [si] (six fl/les). First-order context can sometimes solve the problem (nous notions vs. des notions; un as vs. tu as), but, generally, a parsing of the entire sentence is required. The ambiguity is often between a conjugated verb and another grammatical category. The entire sentence can be ambiguous as in &amp;quot;les fils sont jolis&amp;quot; where fi/s is pronounced differently depending on the meaning (sons or threads). 3.5 Stress For English, due to the interaction of stress and vowel reduction, knowing the stressed syllable is often crucial in determining the correct phoneme sequence (Halle and Keyser 1971). For instance, a word like aggravation has three tokens of the vowel grapheme a, but all are phonetically different. The vowel nucleus of the first syllable is []; the stressed syllable va is manifested by Eel]; and vowel nucleus of the unstressed syllable gra (in this case) undergoes automatic vowel reduction and is realized as [o]. The stress pattern for English is difficult to predict and has to be learned. Nevertheless, some basic rules exist. We have seen the verb/noun homographs in the previous section. In words of two syllables, the verb has stress on the second syllable, the noun on t</context>
</contexts>
<marker>Halle, Keyser, 1971</marker>
<rawString>Halle, M. and S. J. Keyser. 1971. English Stress: Its Form, its Growth and its Role in Verse. Harper and Row, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Hertz</author>
</authors>
<title>Appropriateness of different rule types in speech synthesis. In</title>
<date>1979</date>
<journal>Speech Communication Papers,</journal>
<volume>50</volume>
<editor>J. J. Wolf and D. H. Klatt, editors,</editor>
<contexts>
<context position="4250" citStr="Hertz (1979" startWordPosition="628" endWordPosition="629">ty of literature in grapheme-to-phoneme translation is partially due to the fact that the field of linguistics, and in particular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These wo</context>
</contexts>
<marker>Hertz, 1979</marker>
<rawString>Hertz, S. R. 1979. Appropriateness of different rule types in speech synthesis. In J. J. Wolf and D. H. Klatt, editors, Speech Communication Papers, No. 50,</rawString>
</citation>
<citation valid="false">
<pages>511--514</pages>
<publisher>Acoustical Society of America.</publisher>
<marker></marker>
<rawString>pages 511-514. Acoustical Society of America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Hertz</author>
</authors>
<title>SRS text-to-phoneme rules: A three-level rule strategy.</title>
<date>1981</date>
<booktitle>In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP),</booktitle>
<pages>102--105</pages>
<marker>Hertz, 1981</marker>
<rawString>Hertz, S. R. 1981. SRS text-to-phoneme rules: A three-level rule strategy. In Proceedings of the IEEE International Conference on Acoustics, Speech, and Signal Processing (ICASSP), pages 102-105.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Hertz</author>
</authors>
<title>From text to speech with SRS.</title>
<date>1982</date>
<journal>Journal of the Acoustical Society of America</journal>
<volume>72</volume>
<pages>1155--1170</pages>
<marker>Hertz, 1982</marker>
<rawString>Hertz, S. R. 1982. From text to speech with SRS. Journal of the Acoustical Society of America 72: 1155-1170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Hertz</author>
</authors>
<title>The &amp;quot;morphology&amp;quot; of English spelling: A look at the SRS text-modification rules for English. Working Papers of the</title>
<date>1983</date>
<journal>Cornell Phonetics Laboratory</journal>
<volume>1</volume>
<pages>17--28</pages>
<marker>Hertz, 1983</marker>
<rawString>Hertz, S. R. 1983. The &amp;quot;morphology&amp;quot; of English spelling: A look at the SRS text-modification rules for English. Working Papers of the Cornell Phonetics Laboratory 1: 17-28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S R Hertz</author>
</authors>
<title>A versatile dictionary for speech synthesis by rule.</title>
<date>1985</date>
<journal>Journal of the Acoustical Society of America, Supplement</journal>
<volume>1</volume>
<pages>11</pages>
<marker>Hertz, 1985</marker>
<rawString>Hertz, S. R. 1985. A versatile dictionary for speech synthesis by rule. Journal of the Acoustical Society of America, Supplement 1:77, S11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hochberg</author>
<author>S M Mniszewski</author>
<author>T Calleja</author>
<author>G J Papcun</author>
</authors>
<title>What&apos;s in a name?: Last names as a computational problem.</title>
<date>1990</date>
<institution>Los Alamos National Laboratory,</institution>
<location>Los Alamos, NM.</location>
<note>Unpublished manuscript,</note>
<marker>Hochberg, Mniszewski, Calleja, Papcun, 1990</marker>
<rawString>Hochberg, J., S. M. Mniszewski, T. Calleja, and G. J. Papcun. 1990. What&apos;s in a name?: Last names as a computational problem. Unpublished manuscript, Los Alamos National Laboratory, Los Alamos, NM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hochberg</author>
<author>S M Mniszewski</author>
<author>T Calleja</author>
<author>G J Papcun</author>
</authors>
<title>A default hierarchy for pronouncing English.</title>
<date>1991</date>
<journal>IEEE Transactions on Pattern Matching and Machine Intelligence</journal>
<volume>13</volume>
<issue>9</issue>
<pages>957--964</pages>
<contexts>
<context position="5623" citStr="Hochberg et al. 1991" startWordPosition="828" endWordPosition="831"> morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b, 1991, 1994), and others, all of which are essent</context>
</contexts>
<marker>Hochberg, Mniszewski, Calleja, Papcun, 1991</marker>
<rawString>Hochberg, J., S. M. Mniszewski, T. Calleja, and G. J. Papcun. 1991. A default hierarchy for pronouncing English. IEEE Transactions on Pattern Matching and Machine Intelligence 13(9): 957-964.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hunnicut</author>
</authors>
<title>Phonological rules for a text-to-speech system.</title>
<date>1976</date>
<journal>American Journal of Computational Linguistics, Microfiche</journal>
<volume>57</volume>
<marker>Hunnicut, 1976</marker>
<rawString>Hunnicut, S. 1976. Phonological rules for a text-to-speech system. American Journal of Computational Linguistics, Microfiche 57.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Hunnicut</author>
</authors>
<title>Grapheme to Phoneme Rules: A Review.</title>
<date>1980</date>
<journal>STL-QPSR</journal>
<pages>2--3</pages>
<marker>Hunnicut, 1980</marker>
<rawString>Hunnicut, S. 1980. Grapheme to Phoneme Rules: A Review. STL-QPSR 2-3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R M Kaplan</author>
<author>M Kay</author>
</authors>
<title>Regular models of phonological rule systems.</title>
<date>1994</date>
<journal>Computational Linguistics</journal>
<volume>20</volume>
<issue>3</issue>
<contexts>
<context position="71783" citStr="Kaplan and Kay (1994)" startWordPosition="11864" endWordPosition="11867"> which words have been borrowed and assimilated, sometimes only partially. English and French have interacted and continue to interact with each other. For both languages, the spelling has been enforced by dictionaries and laws, but the pronunciation has continued to evolve, widening the gap between the written and spoken components of the language. Both the English and French translation systems presented in this paper are based on rewriting rules. Nevertheless, some differences exist in the syntax and the interpretation of these rules. For a more theoretical approach to rewriting rules, see Kaplan and Kay (1994). English is scanned once from right to left to better take into account the suffixes of the word, which in certain cases determine the stressed syllable. The rule transforms the grapheme into phonemes and stress marks used by the stress module. In some cases, the input string is modified to add a morpheme boundary, or to replace the suffix by another suffix to continue the conversion. Syllabification, stress, and allophonic rules are achieved by programs. French uses the concept of a class that allows for the grouping of strings having a common property, thus reducing the number of rules. Sev</context>
</contexts>
<marker>Kaplan, Kay, 1994</marker>
<rawString>Kaplan, R. M. and M. Kay. 1994. Regular models of phonological rule systems. Computational Linguistics 20(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Klatt</author>
</authors>
<title>Review of text to speech conversion for English.</title>
<date>1987</date>
<journal>Journal of the Acoustical Society of America</journal>
<volume>82</volume>
<issue>3</issue>
<pages>737--793</pages>
<contexts>
<context position="5686" citStr="Klatt 1987" startWordPosition="839" endWordPosition="840">orphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b, 1991, 1994), and others, all of which are essentially knowledge-rich expert systems. The various attempts at ru</context>
</contexts>
<marker>Klatt, 1987</marker>
<rawString>Klatt, D. H. 1987. Review of text to speech conversion for English. Journal of the Acoustical Society of America 82(3): 737-793.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D H Klatt</author>
<author>D W Shipman</author>
</authors>
<title>Letter-to-phoneme rules: A semi-automatic discovery procedure.</title>
<date>1982</date>
<journal>Journal of the Acoustical Society of America</journal>
<volume>82</volume>
<pages>737--793</pages>
<contexts>
<context position="5673" citStr="Klatt and Shipman 1982" startWordPosition="835" endWordPosition="838">ulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b, 1991, 1994), and others, all of which are essentially knowledge-rich expert systems. The various a</context>
</contexts>
<marker>Klatt, Shipman, 1982</marker>
<rawString>Klatt, D. H. and D. W. Shipman. 1982. Letter-to-phoneme rules: A semi-automatic discovery procedure. Journal of the Acoustical Society of America 82: 737-793.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Laporte</author>
</authors>
<title>Methodes algorithmiques et lexicales de phonetisation de textes.</title>
<date>1988</date>
<tech>These,</tech>
<institution>Universite Paris</institution>
<contexts>
<context position="4651" citStr="Laporte (1988)" startWordPosition="685" endWordPosition="686">have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 19</context>
</contexts>
<marker>Laporte, 1988</marker>
<rawString>Laporte, E. 1988. Methodes algorithmiques et lexicales de phonetisation de textes. These, Universite Paris 7, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Levin</author>
</authors>
<title>A basic research program on reading.</title>
<date>1963</date>
<tech>Final Report, Cooperative Research Project No. 639,</tech>
<institution>Cornell University.</institution>
<contexts>
<context position="4313" citStr="Levin (1963)" startWordPosition="637" endWordPosition="638">ly due to the fact that the field of linguistics, and in particular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of word</context>
</contexts>
<marker>Levin, 1963</marker>
<rawString>Levin, H. 1963. A basic research program on reading. Final Report, Cooperative Research Project No. 639, Cornell University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Y Liberman</author>
<author>A Prince</author>
</authors>
<title>On stress and linguistic rhythm.</title>
<date>1977</date>
<journal>Linguistic Inquiry</journal>
<volume>8</volume>
<issue>2</issue>
<pages>249--336</pages>
<contexts>
<context position="23212" citStr="Liberman and Prince 1977" startWordPosition="3656" endWordPosition="3659">on moves the stress to the penultimate syllable of words ending in -ation: aggravation [,xgralvell@n]. Another difficulty for English concerns the stress in noun compounds such as coffee cup, Thermos bottle, tape recorder, etc., which exhibit a stress pattern of [1 2] or [1 0] due to the semantic unity of the two words in spite of the white space between them. Because of this white space, a program without special rules would assign primary stress to both words: [t kulfI# &apos;1(A.p] instead of [ 103fI# ,kAp] and 03:mos# Ihotl] instead of [t 03:mas# ,britl]. This problem has been known some time (Liberman and Prince 1977). Phonemes for French, on the other hand, are stress independent, since while lexical stress is nonfunctional except in a small number of ambiguous words and phrases, it plays a subordinate role to phrasal stress, which is invariant and phrase-final. Even for function words where the stress of the word is reduced in terms of duration and intonation, the phonemes stay the same.&apos; The stress could be different in belle fille [Ibel#fij] vs. belle-fille [bel#1 fij], grand pere gra#per] vs. grand-pere [gra# &apos;per], stressing belle or grand if it is not a compound word. Even a word like pomme de terre</context>
</contexts>
<marker>Liberman, Prince, 1977</marker>
<rawString>Liberman, M. Y. and A. Prince. 1977. On stress and linguistic rhythm. Linguistic Inquiry 8(2): 249-336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Lucas</author>
<author>R I Damper</author>
</authors>
<title>Syntactic neural networks for bi-directional text-phonetics translation.</title>
<date>1992</date>
<editor>In G. Bailly and C. Benoit, editors,</editor>
<publisher>North-Holland Publishers.</publisher>
<contexts>
<context position="5556" citStr="Lucas and Damper 1992" startWordPosition="817" endWordPosition="820">rrespondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1</context>
</contexts>
<marker>Lucas, Damper, 1992</marker>
<rawString>Lucas, S. M. and R. I. Damper. 1992. Syntactic neural networks for bi-directional text-phonetics translation. In G. Bailly and C. Benoit, editors, Talking Machines, Theories, Models and Designs. North-Holland Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Lucassen</author>
<author>R L Mercer</author>
</authors>
<title>An information theoretic approach to the automatic determination of phonemic baseforms.</title>
<date>1984</date>
<booktitle>In Proceedings of ICASSP-84,</booktitle>
<pages>42--5</pages>
<location>San Diego.</location>
<contexts>
<context position="5748" citStr="Lucassen and Mercer 1984" startWordPosition="845" endWordPosition="848">c) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b, 1991, 1994), and others, all of which are essentially knowledge-rich expert systems. The various attempts at rule formulation were related to differences in the phonemic inv</context>
</contexts>
<marker>Lucassen, Mercer, 1984</marker>
<rawString>Lucassen, J. M. and R. L. Mercer. 1984. An information theoretic approach to the automatic determination of phonemic baseforms. In Proceedings of ICASSP-84, pages 42.5.1-42.5.3, San Diego.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McCormick</author>
<author>S R Hertz</author>
</authors>
<title>A new approach to English text-to-phoneme conversion using delta, Version 2. 117th Meeting.</title>
<date>1989</date>
<journal>Journal of the Acoustical Society of America, Supplement</journal>
<volume>1</volume>
<pages>124</pages>
<contexts>
<context position="4341" citStr="McCormick and Hertz (1989)" startWordPosition="639" endWordPosition="642">fact that the field of linguistics, and in particular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspon</context>
</contexts>
<marker>McCormick, Hertz, 1989</marker>
<rawString>McCormick, S. and S. R. Hertz. 1989. A new approach to English text-to-phoneme conversion using delta, Version 2. 117th Meeting. Journal of the Acoustical Society of America, Supplement 1, Vol. 85, S124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M D McIlroy</author>
</authors>
<title>Synthetic English speech by rules.</title>
<date>1974</date>
<institution>Bell Telephone Laboratories Memo.</institution>
<contexts>
<context position="4357" citStr="McIlroy (1974)" startWordPosition="643" endWordPosition="644">istics, and in particular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These st</context>
</contexts>
<marker>McIlroy, 1974</marker>
<rawString>McIlroy, M. D. 1974. Synthetic English speech by rules. Bell Telephone Laboratories Memo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H M Meng</author>
</authors>
<title>Phonological Parsing for Bi-Directional Letter-to-Sound and Sound-to-Letter Generation.</title>
<date>1995</date>
<tech>Ph.D. Thesis,</tech>
<location>MIT, Cambridge, MA.</location>
<contexts>
<context position="5948" citStr="Meng 1995" startWordPosition="876" endWordPosition="877"> pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b, 1991, 1994), and others, all of which are essentially knowledge-rich expert systems. The various attempts at rule formulation were related to differences in the phonemic inventory, the number of rules, the type and format of rules, and even the direction of parse of the rules (whether they were scanned from left to right or from right to left). Different approaches were </context>
</contexts>
<marker>Meng, 1995</marker>
<rawString>Meng, H. M. 1995. Phonological Parsing for Bi-Directional Letter-to-Sound and Sound-to-Letter Generation. Ph.D. Thesis, MIT, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M H O&apos;Malley</author>
</authors>
<title>Text-to-speech conversion technology.</title>
<date>1990</date>
<booktitle>Computer IEEE,</booktitle>
<pages>17</pages>
<contexts>
<context position="4374" citStr="O&apos;Malley (1990)" startWordPosition="645" endWordPosition="646">articular, descriptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of</context>
</contexts>
<marker>O&apos;Malley, 1990</marker>
<rawString>O&apos;Malley, M. H. 1990. Text-to-speech conversion technology. Computer IEEE, page 17.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D O&apos;Shaughnessy</author>
<author>M Lennig</author>
<author>P Mermelstein</author>
<author>M Divay</author>
</authors>
<title>Simulation d&apos;un lecteur automatique du Francais. 12emes Journees d&apos;Etudes sur la Parole,</title>
<date>1981</date>
<location>Montreal, Canada.</location>
<marker>O&apos;Shaughnessy, Lennig, Mermelstein, Divay, 1981</marker>
<rawString>O&apos;Shaughnessy, D., M. Lennig, P. Mermelstein, and M. Divay. 1981. Simulation d&apos;un lecteur automatique du Francais. 12emes Journees d&apos;Etudes sur la Parole, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Parfitt</author>
<author>R Sharman</author>
</authors>
<title>A bi-directional model of English pronunciation.</title>
<date>1991</date>
<booktitle>In Proceedings of Eurospeech,</booktitle>
<volume>2</volume>
<pages>801--804</pages>
<contexts>
<context position="5797" citStr="Parfitt and Sharman 1991" startWordPosition="853" endWordPosition="856"> studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to incorporate pronunciation by analogy (Dedina and Nusbaum 1991), a neural network or connectionist approach to the problem (Sejnowski and Rosenberg 1986; Bakiri and Dietterich 1991; Gonzalez and Tubach 1982; Lucas and Damper 1992), automatic alignment by an induction method (Hochberg et al. 1991); a computational approach (Klatt and Shipman 1982; Klatt 1987), an information theoretic approach (Lucassen and Mercer 1984), hidden Markov models (Parfitt and Sharman 1991), and a case-based approach (Golding 1991). Some have even developed a bidirectional approach of letter-to-sound as well as sound-to-letter (Meng 1995), which is a hybrid of data-based and rule-driven approaches and is also useful for automatic speech recognition. This paper will focus on a rule-based approach, as for example in Allen (1979). Divay (1984, 1985, 1990a, 1990b, 1991, 1994), and others, all of which are essentially knowledge-rich expert systems. The various attempts at rule formulation were related to differences in the phonemic inventory, the number of rules, the type and format </context>
</contexts>
<marker>Parfitt, Sharman, 1991</marker>
<rawString>Parfitt, S. and R. Sharman. 1991. A bi-directional model of English pronunciation. In Proceedings of Eurospeech, volume 2, pages 801-804.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Prouts</author>
</authors>
<title>Contribution a la synthese de la parole a partir de texte; transcription graphe&apos;mo-phonetique en temps reel sur microprocesseur. These de Docteur-Ingenieur, Universite de</title>
<date>1980</date>
<location>Paris Sud, Orsay.</location>
<contexts>
<context position="4666" citStr="Prouts (1980)" startWordPosition="687" endWordPosition="688">mportant studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More</context>
</contexts>
<marker>Prouts, 1980</marker>
<rawString>Prouts, B. 1980. Contribution a la synthese de la parole a partir de texte; transcription graphe&apos;mo-phonetique en temps reel sur microprocesseur. These de Docteur-Ingenieur, Universite de Paris Sud, Orsay.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Rey</author>
<author>A Duval</author>
<author>B Vienne</author>
<author>B Struyf</author>
<author>M Divay</author>
<author>T Lootens</author>
<author>S Zimmermann</author>
</authors>
<title>Le Robert Elect ronique. Ensemble d&apos;Outils d&apos;Aide a la Redaction de Textes Francais sur Disque Optique Compact (CD-ROM),</title>
<date>1989</date>
<contexts>
<context position="67276" citStr="Rey et al. 1989" startWordPosition="11169" endWordPosition="11172">is currently in use in different laboratories in France, Canada (O&apos;Shaugnessy et al. 1981) and the United States (DEC) as the first level in speech 517 Computational Linguistics Volume 23, Number 4 synthesis for French. It has been used by various companies producing electronic board speech synthesizers for French. This transcription program has also been used to create a phonetic index and retrieve a word without knowing how to write it. The word is converted to phonetics and searched for in the phonetic dictionary index (used in both CD-ROM dictionaries Le Grand Robert and Le Petit Robert) (Rey et al. 1989). For information retrieval, open and closed phonemes are always considered identical. The same mechanism (using phonetics) is used to retrieve a proper name (without knowing how to spell it) through the 30,000 proper names of the phone book of the city of Dakar (Senegal). The system is also used in the Taurus multimedia database software (from DCI: Data Concept Informatique) to create an index on one field of a structure defined by the user of the database, and to retrieve the corresponding information even if it is misspelled. Other similar uses are under investigation for the pronunciation </context>
</contexts>
<marker>Rey, Duval, Vienne, Struyf, Divay, Lootens, Zimmermann, 1989</marker>
<rawString>Rey, A., A. Duval, B. Vienne, B. Struyf, M. Divay, T. Lootens and S. Zimmermann. 1989. Le Robert Elect ronique. Ensemble d&apos;Outils d&apos;Aide a la Redaction de Textes Francais sur Disque Optique Compact (CD-ROM), November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T J Sejnowski</author>
<author>C R Rosenberg</author>
</authors>
<title>NETtalk: Parallel networks that learn to pronounce English text.</title>
<date>1987</date>
<journal>Complex Systems</journal>
<pages>1--145</pages>
<marker>Sejnowski, Rosenberg, 1987</marker>
<rawString>Sejnowski, T. J. and C. R. Rosenberg. 1987. NETtalk: Parallel networks that learn to pronounce English text. Complex Systems 1:145-168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Spiegel</author>
</authors>
<title>Pronouncing surnames automatically.</title>
<date>1985</date>
<booktitle>In Proceedings of AVIOS.</booktitle>
<contexts>
<context position="8845" citStr="Spiegel 1985" startWordPosition="1337" endWordPosition="1338">orms and technical jargon, there are well over three-quarters of a million words in the English or French language. It would be an extremely difficult task to create such a list. More importantly, new words come into the language every day and from these are generated many derived forms. Lastly, when we factor in items that may not even be found in a dictionary, such as proper nouns (first names, surnames, place names, names of corporations, etc.), the necessity of a rule-governed approach quickly becomes apparent. For example, there are roughly 1.5 million different surnames in the US alone (Spiegel 1985; Spiegel and Machi 1990; Vitale 1991); moreover, one-third of these surnames are unique in that they are singletons. In fact, at this stage in the technology, it is still the rule set and not the dictionary that is the more dominant, although this is beginning to change, primarily due to the need for more complex lexical entry containing information on syntax, semantics, and even pragmatics for more natural prosodics in text-to-speech tasks. It is difficult and time consuming to place all derived forms in the dictionary, including singular and plural forms and all verb affixes, especially for</context>
</contexts>
<marker>Spiegel, 1985</marker>
<rawString>Spiegel, M. F. 1985. Pronouncing surnames automatically. In Proceedings of AVIOS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M F Spiegel</author>
<author>M J Machi</author>
</authors>
<title>Synthesis of names by a demi-syllable-based speech synthesizer (Orator).</title>
<date>1990</date>
<journal>Journal of the American Voice Input/Output Society</journal>
<pages>7--1</pages>
<contexts>
<context position="8869" citStr="Spiegel and Machi 1990" startWordPosition="1339" endWordPosition="1342">ical jargon, there are well over three-quarters of a million words in the English or French language. It would be an extremely difficult task to create such a list. More importantly, new words come into the language every day and from these are generated many derived forms. Lastly, when we factor in items that may not even be found in a dictionary, such as proper nouns (first names, surnames, place names, names of corporations, etc.), the necessity of a rule-governed approach quickly becomes apparent. For example, there are roughly 1.5 million different surnames in the US alone (Spiegel 1985; Spiegel and Machi 1990; Vitale 1991); moreover, one-third of these surnames are unique in that they are singletons. In fact, at this stage in the technology, it is still the rule set and not the dictionary that is the more dominant, although this is beginning to change, primarily due to the need for more complex lexical entry containing information on syntax, semantics, and even pragmatics for more natural prosodics in text-to-speech tasks. It is difficult and time consuming to place all derived forms in the dictionary, including singular and plural forms and all verb affixes, especially for a language like French </context>
</contexts>
<marker>Spiegel, Machi, 1990</marker>
<rawString>Spiegel, M. F. and M. J. Machi. 1990. Synthesis of names by a demi-syllable-based speech synthesizer (Orator). Journal of the American Voice Input/Output Society 7:1-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Thimonnier</author>
</authors>
<date>1978</date>
<journal>Code Orthographique et Grammatical. Collections Marabout.</journal>
<contexts>
<context position="12911" citStr="Thimonnier 1978" startWordPosition="1982" endWordPosition="1983"> The Roman occupation (which lasted until 476 A.D.) resulted in well-educated people speaking Latin; for others, a language derived from Latin. After the Roman pullback, the language continued to evolve in different ways, especially since few people knew how to read. The first written texts in the new language, called Roman ([romal), appear only in the 9th Century. Then official papers written in Latin began to be written in Roman. Up until the 17th Century, standardization in spelling had been vague until dictionaries, schools, and laws enforced a standard spelling (Burney 1955; Catach 1978; Thimonnier 1978). Spelling reform is currently an extremely controversial subject in France, which can cause social and business problems when it is under discussion. Only minor corrections have recently been approved. Consequently, computational applications have to deal with this problem in the same way as do young students or foreigners learning the language.&apos; There are many classic examples of the problem in English. Among those often cited are the different phonetic realizations of the grapheme sequence ough as in rough [AI], through [III], bough ja231, thought [D1], dough [aL3], cough [Df], and hiccough</context>
</contexts>
<marker>Thimonnier, 1978</marker>
<rawString>Thimonnier, R. 1978. Code Orthographique et Grammatical. Collections Marabout.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Venezky</author>
</authors>
<title>A Computer Program for Deriving Spelling to Sound Correlations. MA thesis,</title>
<date>1962</date>
<booktitle>A Basic Research Program on Reading. See</booktitle>
<institution>Cornell University.</institution>
<location>Levin</location>
<note>Published in part in</note>
<contexts>
<context position="4389" citStr="Venezky (1962" startWordPosition="647" endWordPosition="648">ptive linguistics, has traditionally shied away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phon</context>
</contexts>
<marker>Venezky, 1962</marker>
<rawString>Venezky, R. L. 1962. A Computer Program for Deriving Spelling to Sound Correlations. MA thesis, Cornell University. Published in part in A Basic Research Program on Reading. See Levin 1963.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Venezky</author>
</authors>
<title>Automatic spelling-to-sound conversion. Computation in Linguistics: A Case Book.</title>
<date>1966</date>
<publisher>Indiana University Press,</publisher>
<location>Bloomington, IN.</location>
<contexts>
<context position="4727" citStr="Venezky 1966" startWordPosition="697" endWordPosition="698">ast years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studies have attempted to use learning algorithms to </context>
</contexts>
<marker>Venezky, 1966</marker>
<rawString>Venezky, R. L. 1966. Automatic spelling-to-sound conversion. Computation in Linguistics: A Case Book. Indiana University Press, Bloomington, IN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Venezky</author>
</authors>
<title>English orthography: Its graphical structure and its relation to sound. Reading Research Quarterly,</title>
<date>1967</date>
<journal>Education</journal>
<volume>87</volume>
<pages>519--524</pages>
<marker>Venezky, 1967</marker>
<rawString>Venezky, R. L. 1967a. English orthography: Its graphical structure and its relation to sound. Reading Research Quarterly, II. Venezky, R. L. 196713, Reading: Grapheme-phoneme relationships. Education 87: 519-524.</rawString>
</citation>
<citation valid="false">
<authors>
<author>R L Venezky</author>
</authors>
<title>1967c, The basis of English orthography.</title>
<journal>Acta Linguistica</journal>
<volume>10</volume>
<pages>145--159</pages>
<marker>Venezky, </marker>
<rawString>Venezky, R. L. 1967c, The basis of English orthography. Acta Linguistica 10: 145-159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Venezky</author>
</authors>
<title>The Structure of English Orthography.</title>
<date>1970</date>
<publisher>Mouton, The Hague.</publisher>
<marker>Venezky, 1970</marker>
<rawString>Venezky, R. L. 1970. The Structure of English Orthography. Mouton, The Hague.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Venezky</author>
<author>R Weir</author>
</authors>
<title>A study of selected spelling-to-sound correspondence patterns. Final Report, Cooperative Research project No. 3090,</title>
<date>1966</date>
<institution>Stanford University.</institution>
<contexts>
<context position="4442" citStr="Venezky and Weir (1966)" startWordPosition="653" endWordPosition="656">away from the writing system (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalizat</context>
</contexts>
<marker>Venezky, Weir, 1966</marker>
<rawString>Venezky, R. L. and R. Weir. 1966. A study of selected spelling-to-sound correspondence patterns. Final Report, Cooperative Research project No. 3090, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A J Vitale</author>
</authors>
<title>An algorithm for high accuracy name pronunciation by parametric speech synthesizer.</title>
<date>1991</date>
<journal>Computational Linguistics</journal>
<volume>17</volume>
<issue>3</issue>
<contexts>
<context position="4457" citStr="Vitale (1991)" startWordPosition="657" endWordPosition="658">tem (except as a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity,</context>
<context position="8883" citStr="Vitale 1991" startWordPosition="1343" endWordPosition="1344">ell over three-quarters of a million words in the English or French language. It would be an extremely difficult task to create such a list. More importantly, new words come into the language every day and from these are generated many derived forms. Lastly, when we factor in items that may not even be found in a dictionary, such as proper nouns (first names, surnames, place names, names of corporations, etc.), the necessity of a rule-governed approach quickly becomes apparent. For example, there are roughly 1.5 million different surnames in the US alone (Spiegel 1985; Spiegel and Machi 1990; Vitale 1991); moreover, one-third of these surnames are unique in that they are singletons. In fact, at this stage in the technology, it is still the rule set and not the dictionary that is the more dominant, although this is beginning to change, primarily due to the need for more complex lexical entry containing information on syntax, semantics, and even pragmatics for more natural prosodics in text-to-speech tasks. It is difficult and time consuming to place all derived forms in the dictionary, including singular and plural forms and all verb affixes, especially for a language like French where a verb c</context>
<context position="30772" citStr="Vitale 1991" startWordPosition="4904" endWordPosition="4905">mes (pronounced [e] in Italian) is typically pronounced [ill or even [ 1 (not pronounced). The proper name Falcone is pronounced in anglophone countries as either [fx1103rtil] or even [flIcon], Bach as either [bax] or [bald. In French, we observe a similar situation where the name Smith is pronounced [smis] and Thatcher as [satf or] as French does not have a [0] phoneme. There have been successful attempts to automatically detect the ethnic group of a proper name for use in anglophone countries like the United States, and to apply a different set of rules depending on that group (Church 1985, Vitale 1991). Trigram frequencies are computed from a large set of proper names whose ethnic group is known, and used to classify a new proper name in terms of some language, language group, or language family (the linguistic etymology of the name). Depending on that classification, different subsets of language-specific rules can be activated. 4. Expert Systems Expert systems are used to facilitate the transfer of the knowledge of a specific domain from an expert to a computer. They traditionally distinguish between the system, which is as independent as possible from the application, and the expert rule</context>
</contexts>
<marker>Vitale, 1991</marker>
<rawString>Vitale, A. J. 1991. An algorithm for high accuracy name pronunciation by parametric speech synthesizer. Computational Linguistics 17(3).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Homograph disambiguation in text-to-speech synthesis.</title>
<date>1994</date>
<booktitle>Second ESCA/IEEE Workshop on Speech Synthesis.</booktitle>
<contexts>
<context position="20324" citStr="Yarowsky (1994)" startWordPosition="3185" endWordPosition="3186"> terms of only one segment. Further, it is not always possible to resolve the ambiguity from part of speech: in I read books, the pronunciation of read ([6:d] or [red]) is ambiguous. A less-frequently examined category, but one that is crucial to more natural speech synthesis, is what we will refer to as functor homographs. These are more subtle variations found in pairs such as can, which could be a verb ([kwn]) or a model auxiliary ON] or [kin] — [kxn]); just, which could be an adjective ([dyst]) or an adverb ([d3ist] [d3Ast]), etc., where there is partial overlapping in careful speech. See Yarowsky (1994) on homograph disambiguation. In French, the situation is similar. The same spelling can produce different phonemic forms: fi/s ([fis] &apos;son&apos; vs. [fil] &apos;thread&apos;); president aprezida] &apos;president&apos; vs. [prezid] &apos;they preside&apos;), etc. The pronunciation typically depends on the grammatical category of the word: fier (&apos;proud&apos; or &apos;to trust&apos;), est (&apos;is&apos; or &apos;East&apos;), couvent (&apos;convent&apos; or &apos;they brood&apos;), notions (&apos;we were noting&apos; or &apos;the notions&apos;), as (&apos;an ace&apos; or &apos;you have&apos;), are all ambiguous in terms of their pronunciation. The word six can be pronounced [sis] (j&apos;en veux six), [siz] (six enfants), [si] </context>
</contexts>
<marker>Yarowsky, 1994</marker>
<rawString>Yarowsky, D. 1994. Homograph disambiguation in text-to-speech synthesis. Second ESCA/IEEE Workshop on Speech Synthesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Yvon</author>
</authors>
<title>Prononcer par analogie: motivation, formalisation et evaluation. These, Ecole nationale des Telecommunications,</title>
<date>1996</date>
<location>Paris.</location>
<contexts>
<context position="4679" citStr="Yvon (1996)" startWordPosition="689" endWordPosition="690">s done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc.), morphophonemic alternation (symmetry vs. symmetric) and even morphology (singer vs. finger). Other studies included pause (McIlroy 1974) and even syntactic information (Divay 1984, 1985). More recent studi</context>
</contexts>
<marker>Yvon, 1996</marker>
<rawString>Yvon, F. 1996. Prononcer par analogie: motivation, formalisation et evaluation. These, Ecole nationale des Telecommunications, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Weir</author>
</authors>
<title>Formulation of grapheme-phoneme correspondence rules to aid the teaching of reading. Final Report, Cooperative Research project No. S-039</title>
<date>1964</date>
<institution>Stanford University.</institution>
<contexts>
<context position="4470" citStr="Weir (1964)" startWordPosition="659" endWordPosition="660">a study in its own right) since the phonological system was considered of primary importance. Papers on the subject are rarely found in linguistics journals. Nevertheless, there have been some important studies done on grapheme-phoneme correspondences in past years; for English: Ainsworth (1973), Bakiri and Dietterich (1991), Bernstein and Nessly (1981), Elovitz et al. (1976), Hertz (1979, 1981, 1982, 1983, 1985), Hunnicutt (1976, 1980), Levin (1963), McCormick and Hertz (1989), McIlroy (1974), O&apos;Malley (1990), Venezky (1962, 1967a, 1967b, 1967c, 1970), Venezky and Weir (1966), Vitale (1991), Weir (1964); for French: Auberge (1991), Bechet, Spriet, and El-Beze (1996), Catach (1989), Catach and Catach (1992), Cotto (1992), Divay (1984, 1985, 1990a, 1990b, 1991, 1994), Laporte (1988), Prouts (1980), Yvon (1996). Some of these studies (Weir 1964; Venezky 1966, 1970) were more descriptive in nature and represented a solid base of data from which a rule set could be built. These works consisted of tables of correspondences and examples of words containing these correspondences. These studies made use of phonetic, phonemic, or even morphophonemic form such as palatalization (credulity, cuticle, etc</context>
</contexts>
<marker>Weir, 1964</marker>
<rawString>Weir, R. 1964. Formulation of grapheme-phoneme correspondence rules to aid the teaching of reading. Final Report, Cooperative Research project No. S-039 Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Wells</author>
</authors>
<title>Accents of English, An Introduction, Chapter 3.</title>
<date>1982</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="11495" citStr="Wells 1982" startWordPosition="1753" endWordPosition="1754"> in an Incoherent Letter-to-Sound System for Both English and French English and French are difficult languages to construct letter-to-sound rules for. Grapheme-phoneme correspondences in English are complex, primarily due to nonlinguistic factors related to the aftermath of the Norman invasion (1066 A.D.) as well as various waves of immigration into anglophone countries such as the UK and the US. The sound system has undergone many shifts, including the addition of the /f /- /v/ phonemic distinction under the influence of massive borrowing from French, the Great Vowel Shift (1400-1500 A.D.) (Wells 1982), and others. It has been estimated that external borrowing has been so extensive that English has retained only about 25% of its original Germanic lexicon (Ben Crane 1981). A quick scan of a text in Old English is enough to convince the reader of this. Since the late Middle Ages, due to the availability of printed materials, dictionaries and grammars, the orthographic system has remained virtually unchanged. Letter-to-sound transcription for French is complex because a gap has slowly appeared between the orthographic and phonetic forms at the inception of what we would call French (about the </context>
</contexts>
<marker>Wells, 1982</marker>
<rawString>Wells, J. C. 1982. Accents of English, An Introduction, Chapter 3. Cambridge University Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>