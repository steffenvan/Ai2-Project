<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.334668">
<title confidence="0.985988">
Creating a Multilingual Collocation Dictionary from Large Text Corpora
</title>
<author confidence="0.997663">
Luka Nerima, Violeta Seretan, Eric Wehrli
</author>
<affiliation confidence="0.998585">
Language Technology Laboratory (LATL), Dept. of Linguistics
University of Geneva
</affiliation>
<address confidence="0.84626">
CH-1211 Geneva 4, Switzerland
</address>
<email confidence="0.995814">
fLuka.Nerima, Violeta.Seretan, Eric.Wehrlil@lettres.unige.ch
</email>
<sectionHeader confidence="0.997353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999897545454545">
This paper describes a system of termino-
logical extraction capable of handling
multi-word expressions, using a powerful
syntactic parser. The system includes a
concordancing tool enabling the user to
display the context of the collocation, i.e.
the sentence or the whole document where
the collocation occurs. Since the corpora
are multilingual, the system also offers an
alignment mechanism for the correspond-
ing translated documents.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999883166666667">
Cross-linguistic communication frequently raises
the problem of the proper understanding of idio-
matic expressions, i.e. multi-word expressions
whose meaning differs from the composition of the
individual meaning of their parts. The importance
of multi-word expressions is widely recognized in
the domains of translation and terminology. These
expressions can usually not be translated literally,
and one must find adequate correspondences in the
target language.
This paper describes a system of terminological
extraction capable of handling multi-word expres-
sions, based on a detailed linguistic analysis. The
originality of our approach comes from the fact
that collocations are not extracted from raw texts,
but rather from syntactically parsed texts. The lin-
guistic analysis selects potential pairs of words, as
only the words occurring in a specific syntactic
configuration will be taken into account for further
statistical processing. Such a chain of processes
significantly increases the quality and the rele-
vance of the extracted collocations.
This system will be applied to textual corpora
from the World Trade Organisation (WTO), which
consist in parallel documents in three languages:
English, French and Spanish. All the examples
given in this paper are taken from these corpora.
Ultimately, the system will enrich the workbench
of translators and terminologists of this organiza-
tion.
</bodyText>
<sectionHeader confidence="0.987188" genericHeader="introduction">
2 Collocations
</sectionHeader>
<bodyText confidence="0.99993384">
The notion of &amp;quot;collocation&amp;quot; is difficult to define in
a very precise way. Commonly used to refer to an
arbitrary and recurrent word combination (Be n-
son, 1990), it is also often taken as a conventional
combination of two or more words, with a more or
less transparent meaning. &amp;quot;Conventional combina-
tions&amp;quot; means that native speakers recognize such
combinations as the &amp;quot;correct&amp;quot; way of expressing a
particular concept. For instance, substituting one
term of a collocation with a synonym or a near-
synonym is usually felt by native-speakers as being
&amp;quot;not quite right&amp;quot;, although perfectly understand-
able, e.g. firing ambition vs. burning ambition or in
French exercer une profession vs. pratiquer une
profession (to practice a profession). For further
discussion on collocations, see (Gross 1996; Man-
ning and Schiitze, 1999; Wehrli, 2000).
In spite of the lack of agreement over what ex-
actly counts as collocation, computational linguists
agree that collocations and more generally multi-
word expressions play a very important role in
many NLP applications such as terminology ex-
traction, translation, information retrieval, and
multilingual text alignment. This, along with the
ever-increasing availability of very large text cor-
</bodyText>
<page confidence="0.997409">
131
</page>
<bodyText confidence="0.9910375">
pora, has triggered an important need for tools to
extract collocations.
</bodyText>
<sectionHeader confidence="0.955879" genericHeader="method">
3 Collocation Extraction
</sectionHeader>
<bodyText confidence="0.999977666666667">
The problem of extracting collocations from texts
has been much addressed in the literature, in par-
ticular since the work of Church at al. (1991), and
several statistical packages have been designed for
this purpose (see for instance, the X tract system of
Smadja (1993)). Although very effective, those
systems suffer from the fundamental weakness that
the measure of relatedness they use is essentially
the linear proximity of two or more words. As
pointed out above, grammatical dependencies pro-
vide a more appropriate criterion of relatedness
than simple linear proximity
</bodyText>
<subsectionHeader confidence="0.998393">
3.1 Cooccurrence Extraction with Fips
</subsectionHeader>
<bodyText confidence="0.9969684">
Collocations are extracted from syntactically ana-
lysed corpora. The analysis is performed by Fips, a
large-scale parser based on an adaptation of
Chomksy&apos;s &amp;quot;Principles and Parameters&amp;quot; theory
(Laenzlinger and Wehrli, 1991). Thanks to the syn-
tactic representation, it is not necessary to take into
account any pair of reasonably closed lexical units,
but rather the relevant pairs bound by syntactic
configurations. We consider eight types of con-
figurations: N-Adj, Adj-N, N-N, N-Prep-N, N-V,
V-N, V-Prep-N.
Another argument in favour of a full syntactical
analysis is that it solves the problem of all cases of
extraposed elements, such as passives, topicalisa-
tion, and dislocation. To illustrate some of these
points, consider a few examples of the collocations
prendre - mesure (take - measure) and accepter -
amendement (accept - amendment):
&amp;quot;Regular&amp;quot; phrase: Le Conseil prendra les me-
sures qui pourront etre con venues
Passive phrase:... a moms que des mesures ne
soient prises pour s&apos;assurer
The two terms of the following collocation are
separated by no less than 39 words!: Les amen-
dements qui auront uniquement pour objet
l&apos;adaptation a des niveaux plus eleves de pro-
tection des droits de propriete intellectuelle
etablis et applicables conformement a d&apos;autres
accords multilateraux et qui auront ete accep-
t&amp; dans le cadre de ces accords ...
</bodyText>
<subsectionHeader confidence="0.998775">
3.2 Scoring for Collocation Discovery
</subsectionHeader>
<bodyText confidence="0.999927833333333">
In order to identify collocations among the cooc-
currences, the system achieves an independence
hypothesis testing using the Log-Likelihood-ratio
(see for instance (Dunning, 1993)).
Based on the contingency table below for the
two lexical items w1 and w2 that co-occur,
</bodyText>
<equation confidence="0.655914666666667">
w2
w1 a
c
</equation>
<tableCaption confidence="0.992783">
Table 1. Contingency table for cooccurrences.
</tableCaption>
<bodyText confidence="0.9703055">
the system computes the cooccurrence score as
follow:
</bodyText>
<equation confidence="0.99993175">
logX = 2 (a log a + b log b + clog c + d log d —
(a + b) log (a + b) — (a + c) log (a + c) — (b + d)
log (b+d)—(c+d)log(c+d)+(a+b+c+d)
log (a + b+ c+ d)).
</equation>
<bodyText confidence="0.999174">
The cooccurrences with a high score are good
candidates for collocations. It is however difficult
to determine a critical value above which a cooc-
currence is a collocation and below which it is not.
</bodyText>
<subsectionHeader confidence="0.998988">
3.3 Preliminary Results
</subsectionHeader>
<bodyText confidence="0.999855875">
Our first experiments concerned the WTO corpus
on the Uruguay Round trade negotiation of about
10 millions words for each language. About
380,000 cooccurrences were identified. The cooc-
currences were classified in eight classes corre-
sponding to specific syntactic configurations. The
table below gives the 12 first cooccurrences of type
V-N ranked by the Log-Likelihood ratio.
</bodyText>
<table confidence="0.999384230769231">
WI W2 logX a
faire objet 2599.73 370
atteindre objectif 1366.59 200
jouer role 1361.40 136
obtenir resultat 1315.26 249
priver revenu 983.20 74
appeler attention 951.49 112
presenter proposition 833.02 253
tenir reunion 791.69 183
importer marchandise 790.36 87
adopter ordre du jour 745.84 104
avoir intention 742.48 123
prendre decision 712.44 188
</table>
<tableCaption confidence="0.999933">
Table 2. The 12 best collocations of type V-N obtained.
</tableCaption>
<bodyText confidence="0.9995646">
The results clearly show that the combination of
an accurate parsing and the use of Log-Likelihood
ratio leads to a promising approach. When unable
to create a complete analysis of a sentence, the
Fips parser returns chunks of partial analyses. If
</bodyText>
<page confidence="0.991102">
132
</page>
<bodyText confidence="0.999969666666667">
the collocation is contained in a chunk, it will be
correctly identified by the extraction system. Oth-
erwise, if the two terms do not belong to the same
chunk, it will be missed. We did not assess yet the
number of missed cooccurrences, but we estimate
it at about 10%, i.e. less than the number of cooc-
currences missed by the mobile window methods.
Actually, it appears that the terms of the colloca-
tions of type N-V (subject - verb), V-N (verb - di-
rect object) and V-Prep-N (verb - prep - object) are
separated by more than 5 words in about 20% of
cases, justifying our approach.
</bodyText>
<sectionHeader confidence="0.984848" genericHeader="method">
4 Collocation Dictionary
</sectionHeader>
<bodyText confidence="0.999992333333334">
We used the collocations extracted from the
French and English corpora for creating a database
of knowledge that integrates collocations and in-
stances of their actual use in language. Corpus evi-
dence for each entry in the collocation dictionary is
provided, that can be consulted by the user. We
display the context of a collocation for all its oc-
currences in the analysed corpus, and we offer the
user the option to consult the entire document, if
interested in a larger context.
The collocation context is represented by the
sentence in which the collocation occurs (both col-
location&apos;s keys occur on the same sentence, as they
are in a syntactical relation).
When parallel corpora are available, also the
translation equivalents of the collocation context
are displayed, thus allowing the user to see how a
given collocation was translated in different lan-
guages, and in different contexts. This is done us-
ing a shallow alignment method, without need to
parse the documents in the target languages.
</bodyText>
<subsectionHeader confidence="0.993414">
4.1 Contexts Alignment Method
</subsectionHeader>
<bodyText confidence="0.999841961538462">
The alignment method is aimed at finding, for a
given collocation, the translation of its context in
the other document&apos;s versions. The granularity of
text alignment is the sentence level; we are not
concerned with a finer, word-level alignment of
text that would, for example, put in correspon-
dence the collocations with their translation
equivalent (which can be a collocation or not). We
focus on sentence alignment since the aim of the
dictionary is to provide instances of collocation&apos;s
actual use in language, that is, coherent text spans
found in the corpora resources. At the same time,
we intend to provide a quite precise and delimited
context, that&apos;s why we do not consider a larger
context (such as the whole paragraph).
The specificity of our method consists in the fact
that the alignment is local and partial. No complete
mapping between sentences is done, but only the
mapping for the sentence of the currently visual-
ised instance of collocation. It means that the
alignment is done &amp;quot;on the fly&amp;quot;, for the source sen-
tence that is actually visualised by the user. This is
motivated by the big size of the collocation dic-
tionary and corpora.
The sentence alignment method consists of two
parts:
</bodyText>
<listItem confidence="0.997359">
1. the alignment of paragraphs;
2. the alignment of sentences inside the
aligned paragraphs.
</listItem>
<bodyText confidence="0.99986675">
While the second part is limited for now to a
simple linear and 1:1 correspondence between sen-
tences, the paragraph alignment method is more
complex; it is length-based and integrates a shal-
low content analysis. It begins by individuating a
paragraph in the target text which is a first candi-
date as target paragraph, and which we call
&amp;quot;pivot&amp;quot;. The identification of the pivot is based on
the documents size proportion. Once the pivot
found, we look in its neighbourhood for the opti-
mal candidate as target paragraph.
We perform two kinds of tests on the paragraphs
in this span: a test of paragraph content, and a test
of paragraphs relative size matching. The first test
compares the paragraphs&apos; numbering (if present).
The second one determines the paragraph that best
matches the rapports of sizes in a context (a se-
quence of surrounding paragraphs).
Concluding, our approach to sentence alignment
follows a length correlation strategy, as most of the
existing works do, e.g. (Gale and Church, 1991;
Brown et al., 1991). Individuating the pivot is a
function of the documents sizes, and selecting the
most likely target paragraph is a function of the
relative sizes of paragraphs in the neighbourhood
of the pivot. Similarly to (Simard et al., 1992), we
exploit the text content in order to find word an-
chors (the paragraph numbering in our case). Like
in (Romary and Bonhomme, 2000) and (Catizone
et al., 1989), first the macro (paragraph-level)
structure of documents is examined, possibly using
mark-up from text encoding.
</bodyText>
<page confidence="0.99753">
133
</page>
<subsectionHeader confidence="0.998672">
4.2 Method Evaluation
</subsectionHeader>
<bodyText confidence="0.999725090909091">
The preliminary results we obtained show that the
alignment method outlined above is quite reliable.
We performed the test on a sample of 800 ran-
domly chosen collocation instances, half of which
extracted from the English corpus, and half from
the French corpus. These subsets were further di-
vided in two parts, corresponding to the two target
languages. A human judge verified the correctness
of alignment in each case. The tables below show
the accuracy rating of the alignment method for
each test subset. The avera e precision is 90.87%.
</bodyText>
<table confidence="0.9644575">
source French
taraet
English 92.5%
Spanish 93.5%
</table>
<tableCaption confidence="0.997736">
Table 3. Preliminary results of contexts alignment.
</tableCaption>
<sectionHeader confidence="0.992532" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999795357142857">
We presented a system that integrates the extrac-
tion of collocations from a large collection of
documents with an extensive use of existing trans-
lations for creating a tri-lingual collocation dic-
tionary, with samples of actual use in language.
Using past translations as reference for the transla-
tor&apos;s further work was an idea first proposed by
Melby (1982). Many concordance tools, such as
(Isabelle et al., 1993), allow the user to consult the
translations archives. The specificity of our ap-
proach lies, on one hand, in using the translations
to extract collocations and visualise their context in
all the document&apos;s versions, and, on the other hand,
in relying on syntactically parsed text.
</bodyText>
<sectionHeader confidence="0.953033" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9998298">
This work is supported by Geneva International
Academic Network (GIAN), research project &amp;quot;Lin-
guistic Analysis and Collocation Extraction&amp;quot;, ap-
proved in 2001. Thanks to Olivier Pasteur for the
invaluable help in this research.
</bodyText>
<sectionHeader confidence="0.998958" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999728365384616">
Benson, M. (1990). Collocations and general-purpose
dictionaries. International Journal of Lexicography,
3(1), 23-35.
Brown P., Lai J., and Mercer R. (1991). Aligning Sen-
tences in Parallel Corpora. In Proceedings of the 29th
Annual Meeting of the Association for Computational
Linguistics, Berkeley, Canada, pp. 169-176.
Catizone R., Russell G., and Warwick S. (1989). Deriv-
ing Translation Data from Bilingual Texts. In Pro-
ceedings of the First International Lexical
Acquisition Workshop, Detroit.
Church, K., Gale, W., Hanks, P., and Hindle, D. (1991).
Using Statistics in Lexical Analysis. In Zernick, U.
(ed.), Lexical Acquisition: Exploiting On-Line Re-
sources to Build a Lexicon, Lawrence Erlbaum Asso-
ciates, pp. 115-164.
Dunning, T. (1993). Accurate methods for the statistics
of surprise and coincidence. Computational Linguis-
tics, 19(1):61-74.
Gale W. and Church K. (1991). A program for aligning
sentences in bilingual corpora Computational Lin-
guistics, 19(1):75-102.
Gross, G. (1996). Les expressions figees en francais.
OPHRYS, Paris.
Isabelle P., Dymetman M., Foster G., Jutras J-M.,
Macldovitch E., Perrault F., Ren X., and Simard M.
(1993). Translation Analysis and Translation Auto-
mation. In Proceedings of the Fifth International
Conference on Theoretical and Methodological Is-
sues in Machine Translation, Kyoto, pp. 1133-1147.
Laenzlinger, C. and Wehrli, E. (1991). Fips, un analy-
seur interactif pour le franyais. TA informations,
32(2): 35-49.
Manning, C. and Schiitze, H. (1999). Foundations of
Statistical Natural Language Processing. MIT Press,
Cambridge.
Melby A. (1982). A Bilingual Concordance System and
its Use in Linguistic Studies. In Proceedings of the
Eighth LACUS Forum, Columbia, SC, pp. 541-549.
Romary L. and Bonhomme P. (2000). Parallel align-
ment of structured documents. Veronis J. (Ed.). Par-
allel Text Processing. Dordrecht: Kluwer.
Simard M., Foster G., and Isabelle P. (1992). Using
Cognates to Align Sentences in Parallel Corpora. In
Proceedings of the Fourth International Conference
on Theoretical and Methodological Issues in Ma-
chine Translation, Montreal, Canada, pp. 67-81.
Smadja, F. (1993). Retrieving collocations form text: X-
tract. Computational Linguistics, 19(1):143 -177.
Wehrli, E. (2000). Parsing and Collocations, in Christo-
doulakis, D. (ed.), Natural Language Processing.
Springer Verlag, pp. 272-282.
</reference>
<figure confidence="0.9818075">
source English
tarRet
French 88.0%
Spanish 89.5%
</figure>
<page confidence="0.967283">
134
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.942440">
<title confidence="0.999514">Creating a Multilingual Collocation Dictionary from Large Text Corpora</title>
<author confidence="0.99977">Luka Nerima</author>
<author confidence="0.99977">Violeta Seretan</author>
<author confidence="0.99977">Eric Wehrli</author>
<affiliation confidence="0.999689">Language Technology Laboratory (LATL), Dept. of Linguistics University of Geneva</affiliation>
<address confidence="0.997137">CH-1211 Geneva 4, Switzerland</address>
<email confidence="0.969552">fLuka.Nerima,Violeta.Seretan,Eric.Wehrlil@lettres.unige.ch</email>
<abstract confidence="0.997980916666667">This paper describes a system of terminological extraction capable of handling multi-word expressions, using a powerful syntactic parser. The system includes a concordancing tool enabling the user to display the context of the collocation, i.e. the sentence or the whole document where the collocation occurs. Since the corpora are multilingual, the system also offers an alignment mechanism for the corresponding translated documents.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Benson</author>
</authors>
<title>Collocations and general-purpose dictionaries.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<volume>3</volume>
<issue>1</issue>
<pages>23--35</pages>
<marker>Benson, 1990</marker>
<rawString>Benson, M. (1990). Collocations and general-purpose dictionaries. International Journal of Lexicography, 3(1), 23-35.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>J Lai</author>
<author>R Mercer</author>
</authors>
<title>Aligning Sentences in Parallel Corpora.</title>
<date>1991</date>
<booktitle>In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>169--176</pages>
<location>Berkeley, Canada,</location>
<contexts>
<context position="11239" citStr="Brown et al., 1991" startWordPosition="1787" endWordPosition="1790">ize proportion. Once the pivot found, we look in its neighbourhood for the optimal candidate as target paragraph. We perform two kinds of tests on the paragraphs in this span: a test of paragraph content, and a test of paragraphs relative size matching. The first test compares the paragraphs&apos; numbering (if present). The second one determines the paragraph that best matches the rapports of sizes in a context (a sequence of surrounding paragraphs). Concluding, our approach to sentence alignment follows a length correlation strategy, as most of the existing works do, e.g. (Gale and Church, 1991; Brown et al., 1991). Individuating the pivot is a function of the documents sizes, and selecting the most likely target paragraph is a function of the relative sizes of paragraphs in the neighbourhood of the pivot. Similarly to (Simard et al., 1992), we exploit the text content in order to find word anchors (the paragraph numbering in our case). Like in (Romary and Bonhomme, 2000) and (Catizone et al., 1989), first the macro (paragraph-level) structure of documents is examined, possibly using mark-up from text encoding. 133 4.2 Method Evaluation The preliminary results we obtained show that the alignment method </context>
</contexts>
<marker>Brown, Lai, Mercer, 1991</marker>
<rawString>Brown P., Lai J., and Mercer R. (1991). Aligning Sentences in Parallel Corpora. In Proceedings of the 29th Annual Meeting of the Association for Computational Linguistics, Berkeley, Canada, pp. 169-176.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Catizone</author>
<author>G Russell</author>
<author>S Warwick</author>
</authors>
<title>Deriving Translation Data from Bilingual Texts.</title>
<date>1989</date>
<booktitle>In Proceedings of the First International Lexical Acquisition Workshop,</booktitle>
<location>Detroit.</location>
<contexts>
<context position="11631" citStr="Catizone et al., 1989" startWordPosition="1854" endWordPosition="1857">of sizes in a context (a sequence of surrounding paragraphs). Concluding, our approach to sentence alignment follows a length correlation strategy, as most of the existing works do, e.g. (Gale and Church, 1991; Brown et al., 1991). Individuating the pivot is a function of the documents sizes, and selecting the most likely target paragraph is a function of the relative sizes of paragraphs in the neighbourhood of the pivot. Similarly to (Simard et al., 1992), we exploit the text content in order to find word anchors (the paragraph numbering in our case). Like in (Romary and Bonhomme, 2000) and (Catizone et al., 1989), first the macro (paragraph-level) structure of documents is examined, possibly using mark-up from text encoding. 133 4.2 Method Evaluation The preliminary results we obtained show that the alignment method outlined above is quite reliable. We performed the test on a sample of 800 randomly chosen collocation instances, half of which extracted from the English corpus, and half from the French corpus. These subsets were further divided in two parts, corresponding to the two target languages. A human judge verified the correctness of alignment in each case. The tables below show the accuracy rat</context>
</contexts>
<marker>Catizone, Russell, Warwick, 1989</marker>
<rawString>Catizone R., Russell G., and Warwick S. (1989). Deriving Translation Data from Bilingual Texts. In Proceedings of the First International Lexical Acquisition Workshop, Detroit.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>W Gale</author>
<author>P Hanks</author>
<author>D Hindle</author>
</authors>
<title>Using Statistics in Lexical Analysis.</title>
<date>1991</date>
<booktitle>Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, Lawrence Erlbaum Associates,</booktitle>
<pages>115--164</pages>
<editor>In Zernick, U. (ed.),</editor>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>Church, K., Gale, W., Hanks, P., and Hindle, D. (1991). Using Statistics in Lexical Analysis. In Zernick, U. (ed.), Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, Lawrence Erlbaum Associates, pp. 115-164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--1</pages>
<contexts>
<context position="5663" citStr="Dunning, 1993" startWordPosition="843" endWordPosition="844"> des mesures ne soient prises pour s&apos;assurer The two terms of the following collocation are separated by no less than 39 words!: Les amendements qui auront uniquement pour objet l&apos;adaptation a des niveaux plus eleves de protection des droits de propriete intellectuelle etablis et applicables conformement a d&apos;autres accords multilateraux et qui auront ete accept&amp; dans le cadre de ces accords ... 3.2 Scoring for Collocation Discovery In order to identify collocations among the cooccurrences, the system achieves an independence hypothesis testing using the Log-Likelihood-ratio (see for instance (Dunning, 1993)). Based on the contingency table below for the two lexical items w1 and w2 that co-occur, w2 w1 a c Table 1. Contingency table for cooccurrences. the system computes the cooccurrence score as follow: logX = 2 (a log a + b log b + clog c + d log d — (a + b) log (a + b) — (a + c) log (a + c) — (b + d) log (b+d)—(c+d)log(c+d)+(a+b+c+d) log (a + b+ c+ d)). The cooccurrences with a high score are good candidates for collocations. It is however difficult to determine a critical value above which a cooccurrence is a collocation and below which it is not. 3.3 Preliminary Results Our first experiments</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, T. (1993). Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61-74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora Computational Linguistics,</title>
<date>1991</date>
<pages>19--1</pages>
<contexts>
<context position="11218" citStr="Gale and Church, 1991" startWordPosition="1783" endWordPosition="1786">ased on the documents size proportion. Once the pivot found, we look in its neighbourhood for the optimal candidate as target paragraph. We perform two kinds of tests on the paragraphs in this span: a test of paragraph content, and a test of paragraphs relative size matching. The first test compares the paragraphs&apos; numbering (if present). The second one determines the paragraph that best matches the rapports of sizes in a context (a sequence of surrounding paragraphs). Concluding, our approach to sentence alignment follows a length correlation strategy, as most of the existing works do, e.g. (Gale and Church, 1991; Brown et al., 1991). Individuating the pivot is a function of the documents sizes, and selecting the most likely target paragraph is a function of the relative sizes of paragraphs in the neighbourhood of the pivot. Similarly to (Simard et al., 1992), we exploit the text content in order to find word anchors (the paragraph numbering in our case). Like in (Romary and Bonhomme, 2000) and (Catizone et al., 1989), first the macro (paragraph-level) structure of documents is examined, possibly using mark-up from text encoding. 133 4.2 Method Evaluation The preliminary results we obtained show that </context>
</contexts>
<marker>Gale, Church, 1991</marker>
<rawString>Gale W. and Church K. (1991). A program for aligning sentences in bilingual corpora Computational Linguistics, 19(1):75-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gross</author>
</authors>
<title>Les expressions figees en francais. OPHRYS,</title>
<date>1996</date>
<location>Paris.</location>
<contexts>
<context position="2948" citStr="Gross 1996" startWordPosition="428" endWordPosition="429">ken as a conventional combination of two or more words, with a more or less transparent meaning. &amp;quot;Conventional combinations&amp;quot; means that native speakers recognize such combinations as the &amp;quot;correct&amp;quot; way of expressing a particular concept. For instance, substituting one term of a collocation with a synonym or a nearsynonym is usually felt by native-speakers as being &amp;quot;not quite right&amp;quot;, although perfectly understandable, e.g. firing ambition vs. burning ambition or in French exercer une profession vs. pratiquer une profession (to practice a profession). For further discussion on collocations, see (Gross 1996; Manning and Schiitze, 1999; Wehrli, 2000). In spite of the lack of agreement over what exactly counts as collocation, computational linguists agree that collocations and more generally multiword expressions play a very important role in many NLP applications such as terminology extraction, translation, information retrieval, and multilingual text alignment. This, along with the ever-increasing availability of very large text cor131 pora, has triggered an important need for tools to extract collocations. 3 Collocation Extraction The problem of extracting collocations from texts has been much </context>
</contexts>
<marker>Gross, 1996</marker>
<rawString>Gross, G. (1996). Les expressions figees en francais. OPHRYS, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Isabelle</author>
<author>M Dymetman</author>
<author>G Foster</author>
<author>J-M Jutras</author>
<author>E Macldovitch</author>
<author>F Perrault</author>
<author>X Ren</author>
<author>M Simard</author>
</authors>
<title>Translation Analysis and Translation Automation.</title>
<date>1993</date>
<booktitle>In Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation, Kyoto,</booktitle>
<pages>1133--1147</pages>
<marker>Isabelle, Dymetman, Foster, Jutras, Macldovitch, Perrault, Ren, Simard, 1993</marker>
<rawString>Isabelle P., Dymetman M., Foster G., Jutras J-M., Macldovitch E., Perrault F., Ren X., and Simard M. (1993). Translation Analysis and Translation Automation. In Proceedings of the Fifth International Conference on Theoretical and Methodological Issues in Machine Translation, Kyoto, pp. 1133-1147.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Laenzlinger</author>
<author>E Wehrli</author>
</authors>
<title>Fips, un analyseur interactif pour le franyais.</title>
<date>1991</date>
<journal>TA informations,</journal>
<volume>32</volume>
<issue>2</issue>
<pages>35--49</pages>
<contexts>
<context position="4319" citStr="Laenzlinger and Wehrli, 1991" startWordPosition="631" endWordPosition="634">s purpose (see for instance, the X tract system of Smadja (1993)). Although very effective, those systems suffer from the fundamental weakness that the measure of relatedness they use is essentially the linear proximity of two or more words. As pointed out above, grammatical dependencies provide a more appropriate criterion of relatedness than simple linear proximity 3.1 Cooccurrence Extraction with Fips Collocations are extracted from syntactically analysed corpora. The analysis is performed by Fips, a large-scale parser based on an adaptation of Chomksy&apos;s &amp;quot;Principles and Parameters&amp;quot; theory (Laenzlinger and Wehrli, 1991). Thanks to the syntactic representation, it is not necessary to take into account any pair of reasonably closed lexical units, but rather the relevant pairs bound by syntactic configurations. We consider eight types of configurations: N-Adj, Adj-N, N-N, N-Prep-N, N-V, V-N, V-Prep-N. Another argument in favour of a full syntactical analysis is that it solves the problem of all cases of extraposed elements, such as passives, topicalisation, and dislocation. To illustrate some of these points, consider a few examples of the collocations prendre - mesure (take - measure) and accepter - amendement</context>
</contexts>
<marker>Laenzlinger, Wehrli, 1991</marker>
<rawString>Laenzlinger, C. and Wehrli, E. (1991). Fips, un analyseur interactif pour le franyais. TA informations, 32(2): 35-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Manning</author>
<author>H Schiitze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="2976" citStr="Manning and Schiitze, 1999" startWordPosition="430" endWordPosition="434">ventional combination of two or more words, with a more or less transparent meaning. &amp;quot;Conventional combinations&amp;quot; means that native speakers recognize such combinations as the &amp;quot;correct&amp;quot; way of expressing a particular concept. For instance, substituting one term of a collocation with a synonym or a nearsynonym is usually felt by native-speakers as being &amp;quot;not quite right&amp;quot;, although perfectly understandable, e.g. firing ambition vs. burning ambition or in French exercer une profession vs. pratiquer une profession (to practice a profession). For further discussion on collocations, see (Gross 1996; Manning and Schiitze, 1999; Wehrli, 2000). In spite of the lack of agreement over what exactly counts as collocation, computational linguists agree that collocations and more generally multiword expressions play a very important role in many NLP applications such as terminology extraction, translation, information retrieval, and multilingual text alignment. This, along with the ever-increasing availability of very large text cor131 pora, has triggered an important need for tools to extract collocations. 3 Collocation Extraction The problem of extracting collocations from texts has been much addressed in the literature,</context>
</contexts>
<marker>Manning, Schiitze, 1999</marker>
<rawString>Manning, C. and Schiitze, H. (1999). Foundations of Statistical Natural Language Processing. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Melby</author>
</authors>
<title>A Bilingual Concordance System and its Use in Linguistic Studies.</title>
<date>1982</date>
<booktitle>In Proceedings of the Eighth LACUS Forum,</booktitle>
<pages>541--549</pages>
<location>Columbia, SC,</location>
<marker>Melby, 1982</marker>
<rawString>Melby A. (1982). A Bilingual Concordance System and its Use in Linguistic Studies. In Proceedings of the Eighth LACUS Forum, Columbia, SC, pp. 541-549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Romary</author>
<author>P Bonhomme</author>
</authors>
<title>Parallel alignment of structured documents.</title>
<date>2000</date>
<journal>Veronis</journal>
<publisher>Kluwer.</publisher>
<location>Dordrecht:</location>
<contexts>
<context position="11603" citStr="Romary and Bonhomme, 2000" startWordPosition="1849" endWordPosition="1852"> that best matches the rapports of sizes in a context (a sequence of surrounding paragraphs). Concluding, our approach to sentence alignment follows a length correlation strategy, as most of the existing works do, e.g. (Gale and Church, 1991; Brown et al., 1991). Individuating the pivot is a function of the documents sizes, and selecting the most likely target paragraph is a function of the relative sizes of paragraphs in the neighbourhood of the pivot. Similarly to (Simard et al., 1992), we exploit the text content in order to find word anchors (the paragraph numbering in our case). Like in (Romary and Bonhomme, 2000) and (Catizone et al., 1989), first the macro (paragraph-level) structure of documents is examined, possibly using mark-up from text encoding. 133 4.2 Method Evaluation The preliminary results we obtained show that the alignment method outlined above is quite reliable. We performed the test on a sample of 800 randomly chosen collocation instances, half of which extracted from the English corpus, and half from the French corpus. These subsets were further divided in two parts, corresponding to the two target languages. A human judge verified the correctness of alignment in each case. The tables</context>
</contexts>
<marker>Romary, Bonhomme, 2000</marker>
<rawString>Romary L. and Bonhomme P. (2000). Parallel alignment of structured documents. Veronis J. (Ed.). Parallel Text Processing. Dordrecht: Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Simard</author>
<author>G Foster</author>
<author>P Isabelle</author>
</authors>
<title>Using Cognates to Align Sentences in Parallel Corpora.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>67--81</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="11469" citStr="Simard et al., 1992" startWordPosition="1825" endWordPosition="1828"> relative size matching. The first test compares the paragraphs&apos; numbering (if present). The second one determines the paragraph that best matches the rapports of sizes in a context (a sequence of surrounding paragraphs). Concluding, our approach to sentence alignment follows a length correlation strategy, as most of the existing works do, e.g. (Gale and Church, 1991; Brown et al., 1991). Individuating the pivot is a function of the documents sizes, and selecting the most likely target paragraph is a function of the relative sizes of paragraphs in the neighbourhood of the pivot. Similarly to (Simard et al., 1992), we exploit the text content in order to find word anchors (the paragraph numbering in our case). Like in (Romary and Bonhomme, 2000) and (Catizone et al., 1989), first the macro (paragraph-level) structure of documents is examined, possibly using mark-up from text encoding. 133 4.2 Method Evaluation The preliminary results we obtained show that the alignment method outlined above is quite reliable. We performed the test on a sample of 800 randomly chosen collocation instances, half of which extracted from the English corpus, and half from the French corpus. These subsets were further divided</context>
</contexts>
<marker>Simard, Foster, Isabelle, 1992</marker>
<rawString>Simard M., Foster G., and Isabelle P. (1992). Using Cognates to Align Sentences in Parallel Corpora. In Proceedings of the Fourth International Conference on Theoretical and Methodological Issues in Machine Translation, Montreal, Canada, pp. 67-81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Smadja</author>
</authors>
<title>Retrieving collocations form text:</title>
<date>1993</date>
<journal>Xtract. Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<pages>177</pages>
<contexts>
<context position="3754" citStr="Smadja (1993)" startWordPosition="552" endWordPosition="553">ord expressions play a very important role in many NLP applications such as terminology extraction, translation, information retrieval, and multilingual text alignment. This, along with the ever-increasing availability of very large text cor131 pora, has triggered an important need for tools to extract collocations. 3 Collocation Extraction The problem of extracting collocations from texts has been much addressed in the literature, in particular since the work of Church at al. (1991), and several statistical packages have been designed for this purpose (see for instance, the X tract system of Smadja (1993)). Although very effective, those systems suffer from the fundamental weakness that the measure of relatedness they use is essentially the linear proximity of two or more words. As pointed out above, grammatical dependencies provide a more appropriate criterion of relatedness than simple linear proximity 3.1 Cooccurrence Extraction with Fips Collocations are extracted from syntactically analysed corpora. The analysis is performed by Fips, a large-scale parser based on an adaptation of Chomksy&apos;s &amp;quot;Principles and Parameters&amp;quot; theory (Laenzlinger and Wehrli, 1991). Thanks to the syntactic represent</context>
</contexts>
<marker>Smadja, 1993</marker>
<rawString>Smadja, F. (1993). Retrieving collocations form text: Xtract. Computational Linguistics, 19(1):143 -177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Wehrli</author>
</authors>
<title>Parsing and Collocations,</title>
<date>2000</date>
<booktitle>Natural Language Processing.</booktitle>
<pages>272--282</pages>
<editor>in Christodoulakis, D. (ed.),</editor>
<publisher>Springer Verlag,</publisher>
<contexts>
<context position="2991" citStr="Wehrli, 2000" startWordPosition="435" endWordPosition="436"> or more words, with a more or less transparent meaning. &amp;quot;Conventional combinations&amp;quot; means that native speakers recognize such combinations as the &amp;quot;correct&amp;quot; way of expressing a particular concept. For instance, substituting one term of a collocation with a synonym or a nearsynonym is usually felt by native-speakers as being &amp;quot;not quite right&amp;quot;, although perfectly understandable, e.g. firing ambition vs. burning ambition or in French exercer une profession vs. pratiquer une profession (to practice a profession). For further discussion on collocations, see (Gross 1996; Manning and Schiitze, 1999; Wehrli, 2000). In spite of the lack of agreement over what exactly counts as collocation, computational linguists agree that collocations and more generally multiword expressions play a very important role in many NLP applications such as terminology extraction, translation, information retrieval, and multilingual text alignment. This, along with the ever-increasing availability of very large text cor131 pora, has triggered an important need for tools to extract collocations. 3 Collocation Extraction The problem of extracting collocations from texts has been much addressed in the literature, in particular </context>
</contexts>
<marker>Wehrli, 2000</marker>
<rawString>Wehrli, E. (2000). Parsing and Collocations, in Christodoulakis, D. (ed.), Natural Language Processing. Springer Verlag, pp. 272-282.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>