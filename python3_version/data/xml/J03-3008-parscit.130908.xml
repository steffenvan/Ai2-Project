<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002094">
<sectionHeader confidence="0.18394" genericHeader="method">
Briefly Noted
</sectionHeader>
<bodyText confidence="0.425958">
Une grammaire ´electronique du fran¸cais
</bodyText>
<subsectionHeader confidence="0.450749">
Anne Abeill´e
</subsectionHeader>
<bodyText confidence="0.993333976190476">
(Universit´e Denis Diderot (Paris VII))
Paris: CNRS ´Editions (Collection sciences
du langage, edited by Christian Hudelot),
2002, 396 pp; paperbound, ISBN
2-271-05824-4, ––C38.00
This recent publication by CNRS Publica-
tions is a reworked version of Abeill´e’s 1991
doctoral dissertation. It presents, in consid-
erable detail, the tree adjunction grammar
(TAG) formalism used, and the details of the
French grammar written in that formalism.
This book is worthy of notice because of its
thoroughness in presenting a complete gram-
mar of French for computational use, though,
of course, the content is accessible only to
readers of French.
Chapter 1 is an overview of the TAG
framework used throughout the book. Chap-
ter 2 discusses the basic properties of French
and justifies the fact that the analyses do use
a VP. Chapter 3 is an overview of elementary
trees and lexical categories. Chapter 4 dis-
cusses further categories of elementary trees.
Chapter 5 addresses long-distance depen-
dencies and extraction phenomena. Chapter
6 discusses noncompositional expressions.
Chapter 7 covers implementation issues and
some testing results. The book ends with a
conclusion and two appendices, one on the
formal properties of TAG and one on French
TAG grammar.
The overview of the TAG formalism is
very well done. It is pedagogically sound,
and French speakers would find it a good
overview of pertinent work and of the as-
pects of a TAG relevant for a grammar writer.
Although a novice in the TAG framework, I
found myself well prepared to understand
the specifics of the following chapters de-
voted to French constructions.
The sections on French-specific issues
(auxiliaries, clitics, past-participle agreement)
and the presentation of the elementary trees
are both clear and illustrate well how the
framework can be used to generate the right
results. The details are complex and will re-
quire an advanced understanding of the lin-
guistic issues of French syntax. One naturally
makes allowances for the fact that the work
covers all of the syntax of French, no small
task.
The impression that emerges from read-
ing this book is that creating a grammar in
TAG would require a lot of effort—for the
trees as well as for the complex lexical items.
This seems to be borne out by the relatively
small lexicon (7,500 items) that the system
uses (p. 289), even though the development
time spans over 10 years. Size, performance,
and coverage, though briefly documented,
also seem to be of lesser importance, as this is
a theoretical implementation as much as, or
more than, a usable computational grammar.
A detail that I find unconvincing from a
linguistic perspective is the account of island
constraints. The island nature of a comple-
ment clause is accounted for (p. 239) by stat-
ing that it results from a substitution oper-
ation rather than attachment to a foot node
(nczud pied). Since no reference to previous
work appears here, one is led to believe this
is a new explanation, and one that struck me
as mechanical and unconvincing.
From a practical point of view, I cannot
agree with the insistence, led by theoreti-
cal concerns, that the grammar be generative
(i.e., able to reject ungrammatical input). My
work on grammar in industrial contexts has
convinced me that “real” corpora are flawed
in form and rarely conform to the theoreti-
cal assumptions of grammar writers. I would
have welcomed some estimation of how this
grammar might apply in real contexts.—Jessie
Pinkham, Microsoft Research
</bodyText>
<sectionHeader confidence="0.481495666666667" genericHeader="method">
Natural Language Processing for On-
line Applications: Text Retrieval, Extrac-
tion, and Categorization
</sectionHeader>
<subsectionHeader confidence="0.631547">
Peter Jackson and Isabelle Moulinier
</subsectionHeader>
<bodyText confidence="0.967724066666667">
(Thomson Legal &amp; Regulatory)
Amsterdam: John Benjamins Publishing
Company (Natural language processing
series, edited by Ruslan Mitkov, volume 5),
2002, x+225 pp; hardbound, ISBN
90-272-4988-1 and 1-58811-249-7, $68.00,
––C75.00; paperbound, ISBN 90-272-4989-X
and 1-58811-250-0, $29.95, ––C33.00
Jackson and Moulinier’s book introduces ap-
plied natural language processing to an au-
dience that need not have any prior knowl-
edge of the field or of linguistic issues. But it
is not NLP for Dummies; it respects the intel-
ligence of its readers (apart from a few too-
glib jokes in the first chapter) and doesn’t
</bodyText>
<page confidence="0.988135">
510
</page>
<bodyText confidence="0.994998027027027">
Briefly Noted
shy away from serious mathematics where
the treatment warrants it.
The introductory chapter covers the goals
of NLP and fundamental tools such as to-
kenizers, part-of-speech taggers, and simple
name recognizers. The four main chapters of
the book then cover document retrieval from
collections and from the Web, information
extraction, text categorization, named-entity
and coreference recognition, and automatic
summarization.
Thus, unlike the standard large and com-
prehensive computational linguistics text-
books (Jurafsky and Martin 2000; Manning
and Sch¨utze 1999) and handbooks (Dale,
Moisl, and Somers 2000; Mitkov 2003), Jack-
son and Moulinier’s book is concise and fo-
cused on the goal of building applications.
The book is therefore a useful resource for
those who want to find out quickly about
NLP without learning everything there is to
know about computational linguistics and
NLP. A reader who completes the book will
be well-equipped then to learn more by read-
ing selectively from the textbooks and hand-
books.
Readers of this journal who work in in-
dustry will want to recommend the book
to coworkers, such as project managers and
software engineers, whose experience is in
other fields; those who work in universities
will want to recommend it as prereading to
keen undergraduates. And any reader of this
journal will find it a helpful consolidation of
up-to-date material that is presently scattered
around conference proceedings and journal
</bodyText>
<affiliation confidence="0.550809">
articles.—Graeme Hirst, University of Toronto
</affiliation>
<sectionHeader confidence="0.994254" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.923368">
Dale, Robert, Hermann Moisl, and Harold
Somers, editors. 2000. Handbook of Natural
Language Processing. Marcel Dekker, New
York.
Jurafsky, Daniel and James Martin. 2000.
Speech and Language Processing.
Prentice-Hall, Englewood Cliffs, NJ.
Manning, Christopher and Hinrich Sch¨utze.
1999. Foundations of Statistical Natural
Language Processing. MIT Press, Cambridge.
Mitkov, Ruslan, editor. 2003. The Oxford
Handbook of Computational Linguistics.
Oxford University Press, Oxford.
Defining Language: A Local Grammar
of Definition Sentences
</reference>
<subsectionHeader confidence="0.917187">
Geoff Barnbrook
</subsectionHeader>
<bodyText confidence="0.994856837837838">
(University of Birmingham)
Amsterdam: John Benjamins (Studies in
corpus linguistics, edited by Elena
Tognini-Bonelli, volume 11), 2002,
xv+280 pp; hardbound, ISBN 90-272-2281-9
and 1-58811-298-5, $79.00, ––C88.00.
“This book describes the analysis of the main
features of the language used in English defi-
nition sentences, using as a corpus the defini-
tions contained in the Collins Cobuild Student’s
Dictionary. It examines the usefulness of the
information provided by dictionaries in natu-
ral language processing work and the nature
of the language used in dictionary definitions
in general and in the Cobuild range in par-
ticular. It provides a general survey of mono-
lingual English dictionaries, including a brief
history of their development, and a detailed
investigation of the nature of learners’ dictio-
naries and their special features. The concept
of sublanguages is examined, together with
the justification for regarding definition sen-
tences as a sublanguage and for the appli-
cation to them of a local grammar of defini-
tion. Grammars and parsers are considered
in general terms, and in their relevance to
the creation of a model for the language of
definitions.
“The methodology adopted for the devel-
opment of the language model is described,
together with a detailed account of the tax-
onomy, local grammar, and associated parser
developed for definition sentences. The im-
plications of the results of the analysis and
future possible applications of the taxon-
omy, grammar, and parser are described and
assessed.”—From the pr´ecis of the book
</bodyText>
<page confidence="0.996105">
511
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000124">
<title confidence="0.841724">Briefly Noted grammaire ´electronique du</title>
<author confidence="0.727599">Anne Abeill´e</author>
<affiliation confidence="0.439455">Universit´e Denis Diderot (Paris VII)) Paris: CNRS ´Editions (Collection sciences du langage, edited by Christian Hudelot),</affiliation>
<address confidence="0.810668">2002, 396 pp; paperbound, ISBN</address>
<note confidence="0.4856915">This recent publication by CNRS Publications is a reworked version of Abeill´e’s 1991</note>
<abstract confidence="0.999348868421053">doctoral dissertation. It presents, in considerable detail, the tree adjunction grammar (TAG) formalism used, and the details of the French grammar written in that formalism. This book is worthy of notice because of its thoroughness in presenting a complete grammar of French for computational use, though, of course, the content is accessible only to readers of French. Chapter 1 is an overview of the TAG framework used throughout the book. Chapter 2 discusses the basic properties of French and justifies the fact that the analyses do use a VP. Chapter 3 is an overview of elementary trees and lexical categories. Chapter 4 discusses further categories of elementary trees. Chapter 5 addresses long-distance dependencies and extraction phenomena. Chapter 6 discusses noncompositional expressions. Chapter 7 covers implementation issues and some testing results. The book ends with a conclusion and two appendices, one on the formal properties of TAG and one on French TAG grammar. The overview of the TAG formalism is very well done. It is pedagogically sound, and French speakers would find it a good overview of pertinent work and of the aspects of a TAG relevant for a grammar writer. Although a novice in the TAG framework, I found myself well prepared to understand the specifics of the following chapters devoted to French constructions. The sections on French-specific issues (auxiliaries, clitics, past-participle agreement) and the presentation of the elementary trees are both clear and illustrate well how the framework can be used to generate the right results. The details are complex and will require an advanced understanding of the linguistic issues of French syntax. One naturally makes allowances for the fact that the work covers all of the syntax of French, no small task. The impression that emerges from reading this book is that creating a grammar in TAG would require a lot of effort—for the trees as well as for the complex lexical items. This seems to be borne out by the relatively small lexicon (7,500 items) that the system uses (p. 289), even though the development time spans over 10 years. Size, performance, and coverage, though briefly documented, also seem to be of lesser importance, as this is a theoretical implementation as much as, or more than, a usable computational grammar. A detail that I find unconvincing from a linguistic perspective is the account of island constraints. The island nature of a complement clause is accounted for (p. 239) by stating that it results from a substitution operation rather than attachment to a foot node Since no reference to previous work appears here, one is led to believe this is a new explanation, and one that struck me as mechanical and unconvincing. From a practical point of view, I cannot agree with the insistence, led by theoretical concerns, that the grammar be generative (i.e., able to reject ungrammatical input). My work on grammar in industrial contexts has convinced me that “real” corpora are flawed in form and rarely conform to the theoretical assumptions of grammar writers. I would have welcomed some estimation of how this might apply in real</abstract>
<title confidence="0.71621975">Pinkham, Microsoft Research Natural Language Processing for Online Applications: Text Retrieval, Extraction, and Categorization</title>
<author confidence="0.990523">Peter Jackson</author>
<author confidence="0.990523">Isabelle Moulinier</author>
<affiliation confidence="0.938093">(Thomson Legal &amp; Regulatory)</affiliation>
<address confidence="0.740807">Amsterdam: John Benjamins Publishing</address>
<abstract confidence="0.933060403846154">Company (Natural language processing series, edited by Ruslan Mitkov, volume 5), 2002, x+225 pp; hardbound, ISBN 90-272-4988-1 and 1-58811-249-7, $68.00, paperbound, ISBN 90-272-4989-X 1-58811-250-0, $29.95, Jackson and Moulinier’s book introduces applied natural language processing to an audience that need not have any prior knowledge of the field or of linguistic issues. But it not for it respects the intelligence of its readers (apart from a few tooglib jokes in the first chapter) and doesn’t 510 Briefly Noted shy away from serious mathematics where the treatment warrants it. The introductory chapter covers the goals of NLP and fundamental tools such as tokenizers, part-of-speech taggers, and simple name recognizers. The four main chapters of the book then cover document retrieval from collections and from the Web, information extraction, text categorization, named-entity and coreference recognition, and automatic summarization. Thus, unlike the standard large and comprehensive computational linguistics textbooks (Jurafsky and Martin 2000; Manning and Sch¨utze 1999) and handbooks (Dale, Moisl, and Somers 2000; Mitkov 2003), Jackson and Moulinier’s book is concise and focused on the goal of building applications. The book is therefore a useful resource for those who want to find out quickly about NLP without learning everything there is to know about computational linguistics and NLP. A reader who completes the book will be well-equipped then to learn more by reading selectively from the textbooks and handbooks. Readers of this journal who work in industry will want to recommend the book to coworkers, such as project managers and software engineers, whose experience is in other fields; those who work in universities will want to recommend it as prereading to keen undergraduates. And any reader of this journal will find it a helpful consolidation of up-to-date material that is presently scattered around conference proceedings and journal Hirst, University of Toronto</abstract>
<note confidence="0.4504905">References Dale, Robert, Hermann Moisl, and Harold editors. 2000. of Natural Marcel Dekker, New York. Jurafsky, Daniel and James Martin. 2000.</note>
<title confidence="0.678271">and Language Prentice-Hall, Englewood Cliffs, NJ.</title>
<author confidence="0.762398">Christopher Manning</author>
<author confidence="0.762398">Hinrich Sch¨utze</author>
<affiliation confidence="0.826725">of Statistical Natural MIT Press, Cambridge.</affiliation>
<address confidence="0.808449">Ruslan, editor. 2003. Oxford</address>
<affiliation confidence="0.910696">of Computational Oxford University Press, Oxford.</affiliation>
<title confidence="0.9627515">Defining Language: A Local Grammar of Definition Sentences</title>
<author confidence="0.998835">Geoff Barnbrook</author>
<affiliation confidence="0.99589">(University of Birmingham)</affiliation>
<address confidence="0.476267">Amsterdam: John Benjamins (Studies in</address>
<abstract confidence="0.944893828571429">corpus linguistics, edited by Elena Tognini-Bonelli, volume 11), 2002, xv+280 pp; hardbound, ISBN 90-272-2281-9 1-58811-298-5, $79.00, “This book describes the analysis of the main features of the language used in English definition sentences, using as a corpus the definicontained in the Cobuild Student’s It examines the usefulness of the information provided by dictionaries in natural language processing work and the nature of the language used in dictionary definitions in general and in the Cobuild range in particular. It provides a general survey of monolingual English dictionaries, including a brief history of their development, and a detailed investigation of the nature of learners’ dictionaries and their special features. The concept of sublanguages is examined, together with the justification for regarding definition sentences as a sublanguage and for the application to them of a local grammar of definition. Grammars and parsers are considered in general terms, and in their relevance to the creation of a model for the language of definitions. “The methodology adopted for the development of the language model is described, together with a detailed account of the taxonomy, local grammar, and associated parser developed for definition sentences. The implications of the results of the analysis and future possible applications of the taxonomy, grammar, and parser are described and the pr´ecis of the book</abstract>
<intro confidence="0.537564">511</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>2000</date>
<booktitle>Handbook of Natural Language Processing.</booktitle>
<editor>Dale, Robert, Hermann Moisl, and Harold Somers, editors.</editor>
<publisher>Marcel Dekker,</publisher>
<location>New York.</location>
<marker>2000</marker>
<rawString>Dale, Robert, Hermann Moisl, and Harold Somers, editors. 2000. Handbook of Natural Language Processing. Marcel Dekker, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>James Martin</author>
</authors>
<title>Speech and Language Processing. Prentice-Hall,</title>
<date>2000</date>
<location>Englewood Cliffs, NJ.</location>
<contexts>
<context position="4850" citStr="Jurafsky and Martin 2000" startWordPosition="764" endWordPosition="767">s (apart from a few tooglib jokes in the first chapter) and doesn’t 510 Briefly Noted shy away from serious mathematics where the treatment warrants it. The introductory chapter covers the goals of NLP and fundamental tools such as tokenizers, part-of-speech taggers, and simple name recognizers. The four main chapters of the book then cover document retrieval from collections and from the Web, information extraction, text categorization, named-entity and coreference recognition, and automatic summarization. Thus, unlike the standard large and comprehensive computational linguistics textbooks (Jurafsky and Martin 2000; Manning and Sch¨utze 1999) and handbooks (Dale, Moisl, and Somers 2000; Mitkov 2003), Jackson and Moulinier’s book is concise and focused on the goal of building applications. The book is therefore a useful resource for those who want to find out quickly about NLP without learning everything there is to know about computational linguistics and NLP. A reader who completes the book will be well-equipped then to learn more by reading selectively from the textbooks and handbooks. Readers of this journal who work in industry will want to recommend the book to coworkers, such as project managers a</context>
</contexts>
<marker>Jurafsky, Martin, 2000</marker>
<rawString>Jurafsky, Daniel and James Martin. 2000. Speech and Language Processing. Prentice-Hall, Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Manning</author>
<author>Hinrich Sch¨utze</author>
</authors>
<date>1999</date>
<booktitle>Foundations of Statistical Natural Language Processing.</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge.</location>
<marker>Manning, Sch¨utze, 1999</marker>
<rawString>Manning, Christopher and Hinrich Sch¨utze. 1999. Foundations of Statistical Natural Language Processing. MIT Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<title>The Oxford Handbook of Computational Linguistics.</title>
<date>2003</date>
<editor>Mitkov, Ruslan, editor.</editor>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<marker>2003</marker>
<rawString>Mitkov, Ruslan, editor. 2003. The Oxford Handbook of Computational Linguistics. Oxford University Press, Oxford. Defining Language: A Local Grammar of Definition Sentences</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>