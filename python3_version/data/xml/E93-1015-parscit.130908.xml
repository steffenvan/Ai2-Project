<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.993549">
Automating the Acquisition of Bilingual Terminology
</title>
<author confidence="0.922346">
Pim van der Eijk
</author>
<affiliation confidence="0.887379">
Digital Equipment Corporation
</affiliation>
<address confidence="0.794168">
Kabelweg 21
1014 BA Amsterdam
The Netherlands
</address>
<email confidence="0.706356">
eijkacecehv.enet.dec.com
</email>
<sectionHeader confidence="0.991255" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9316048">
As the acquisition problem of bilingual lists
of terminological expressions is formidable,
it is worthwhile to investigate methods to
compile such lists as automatically as pos-
sible. In this paper we discuss experimen-
tal results for a number of methods, which
operate on corpora of previously translated
texts.
Keywords: parallel corpora, tagging, ter-
minology acquisition.
</bodyText>
<sectionHeader confidence="0.999236" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.900777620689656">
In the past several years, many researchers have
started looking at bilingual corpora, as they im-
plicitly contain much information needed for vari-
ous purposes that would otherwise have to be com-
piled manually. Some applications using information
extracted from bilingual corpora are statistical MT
([Brown et al., 199*, bilingual lexicography ([Cati-
zone et al., 1989]), word sense disambiguation ([Gale
et al., 1992]), and multilingual information retrieval
([Landauer and Littmann, 1990]).
The goal of the research discussed in this paper is
to automate as much as possible the generation of
bilingual term lists from previously translated texts.
These lists are used by terminologists and transla-
tors, e.g. in documentation departments. Manual
compilation of bilingual term lists is an expensive
and laborious effort, hence the relative rarity of spe-
cialized, up-to-date, and manageable terminological
data collections. However, organizations interested
in terminology and translation are likely to have
archives of previously translated documents, which
represent a considerable investment. Automatic or
semi-automatic extraction of the information con-
tained in these documents would then be an attrac-
tive perspective.
A bilingual term list is a list associating source
language terms with a ranked list of target language
terms. The methods to extract bilingual terminol-
ogy from parallel texts were developed and evaluated
experimentally using a bilingual, Dutch-English cor-
pus. There are two phases in the process:
1. Process the texts to extract terms. The defini-
tion of the notion &apos;term&apos; will be an important
issue of this paper, as it is necessary to adopt a
definition that facilitates comparison of terms in
the source and target language. Section 4 will
show some flaws of methods that define terms as
words or nouns. Terminologists commonly use
full noun phrases&apos; as terms to express (domain-
specific) concepts. The NP level is shown to be
a better level to compare Dutch and English in
sections 5.1 and 5.2.
This phase acts as a linguistic front end to the
second phase. The various techniques used to
process the corpus are described in section 2.
2. Apply statistic techniques to determine corres-
pondences between source and target language.
In section 3 we will introduce a simple algorithm
to select and order potential translations for a
given term. This method will subsequently be
compared to two other methods discussed in the
literature.
The usual benefits of modularity apply because the
two phases are highly independent.
&apos;To some extent, a particular domain will also have
textual elements specific to the domain that are not NPs.
We will ignore these, but essentially the same methods
could be used to create bilingual lists of e.g. verbs.
</bodyText>
<page confidence="0.998622">
113
</page>
<bodyText confidence="0.998341416666667">
This paper is structured as follows. Section 2 in-
troduces the operations carried out on the evaluation
corpus. Section 3 describes the translation selection
method used. Section 4 discusses initial experiments
which use words, resp. only nouns, as terms. Section
5 contains an evaluation of a larger experiment in
which NPs are used as terms. Related research is dis-
cussed in [Gaussier et al., 1992], [Gale and Church,
1991a] and [Landauer and Littmann, 1990]. Section
6 compares our method with these approaches. Sec-
tion 7 summarizes the paper, and compares our ap-
proach to related research.
</bodyText>
<sectionHeader confidence="0.872051" genericHeader="method">
2 Text preprocessing
</sectionHeader>
<bodyText confidence="0.9845746">
A number of experiments were carried out on a sam-
ple bilingual corpus, viz. Dutch and English ver-
sions of the official announcement of the ESPRIT pro-
gramme by the European Commission, the Dutch
version of which contains some 25,000 words. The
texts have been preprocessed in several ways.
Lexical Analysis Word and sentence boundaries
were marked up in SGML. This involved taking into
account issues like abbreviations, numerical expres-
sions, character normalization. No morphological
analysis (stemming or lemmatization) was applied.
Alignment The experiments were carried out on
parallel texts aligned at the sentence level, i.e. the
texts have been converted to corresponding segments
of one, or a few, sentences. Reliable sentence align-
ment algorithms are discussed in [Brown et al., 1991]
and [Gale and Church, 1991b1. For our experiments
we used the Gale-Church method, which is imple-
mented by Amy Winarske, ISSCO, Geneva. Figure
1 is a display of two aligned segments.
</bodyText>
<figureCaption confidence="0.999732">
Figure 1: Aligned text segments
</figureCaption>
<bodyText confidence="0.991197631578947">
Een hardneklcige weerzin A persisting aversion to
tegen vroegtijdige stan- early
daardisatie verhindert standardisation prevents
een wisselwerldng tussen an inter-working of prod-
produkten ucts
Tagging In order to investigate the role of syn-
tactic information, the texts have been tagged. A
tagged version of the English text was supplied by
Umist, Manchester. The Dutch version was tagged
automatically using a tagger inspired on the En-
glish tagger described in [Church, 1988]. This tag-
ger uses as contextual information a trigram model
constructed using a previously tagged corpus, viz.
the &amp;quot;Eindhovense corpus&amp;quot;. The system furthermore
uses as lexical information a dictionary derived from
a subset of the Celex lexical database, which con-
tains information about the possible categories and
relative frequencies of about 50,000 inflected Dutch
word forms.
</bodyText>
<figureCaption confidence="0.9942125">
Figure 2 shows the tagged aligned segments.
Figure 2: Tagged aligned text segments
</figureCaption>
<bodyText confidence="0.6093545">
Eend hardnekkige. 4-+ Ad persistinga aversion.
weerzin tegenp to,
vroegtijdige0 standaar- early standardisationn
disatie verhindert,, eend prevents0 and inter-
wisselwerking tussenp working. ofp products.
produkten.
</bodyText>
<listItem confidence="0.637075375">
â€¢ Parsing On the basis of previous tagging, the texts
are superficially parsed by simple pattern matching,
where the objective is to extract a list of term noun
phrases. The following grammer rule, where &amp;quot;w&amp;quot; is
a marked up word, expresses that English term NPs
consist of zero or more words tagged as adjectives
followed by a one or more words tagged as nouns.
np --+ w: w;/,&amp;quot;
</listItem>
<bodyText confidence="0.995229875">
The grammar rule doesn&apos;t take postnominal com-
plements and modifiers into account, because the lex-
icon lacks information to disambiguate PP attach-
ment. We will later see (section 5.3) that this causes
problems in relating Dutch and English NPs. Figure
3 shows the result of parsing, with recognized NPs in
bold face. Texts can be parsed in linear time using
finite state techniques.
</bodyText>
<figureCaption confidence="0.996734">
Figure 3: Parsed aligned text segments
</figureCaption>
<bodyText confidence="0.954212666666667">
Een hardnekkige 4-+ A persisting aversion
weerzin tegen vroeg- to early
tijdige standaardisa- standardisation pre-
tie verhin- vents an inter-working
dert een wisselwerking of products
tussen produkten
</bodyText>
<sectionHeader confidence="0.976017" genericHeader="method">
3 Translation selection
</sectionHeader>
<bodyText confidence="0.998871058823529">
A number of variants of bilingual term acquisition
algorithms have been implemented that operate on
parallel texts. These methods use the output of
the operations in section 2, then build a database
of &amp;quot;translational co-occurrences&amp;quot;, determine and or-
der target language terms for each source language
term, (optionally) apply filtering using threshold val-
ues, and write a report.
The selection and ordering technique used is simi-
lar to another well-known ranking method, viz, mu-
tual information. We will compare experimental re-
sults based on our method and on mutual informa-
tion in section 6.1.
Co-occurrence In conducting our experiments, a
simple statistic measure was used to rank the prob-
ability that a target language term is the translation
of a source language item. This measure is based on
</bodyText>
<page confidence="0.993496">
114
</page>
<bodyText confidence="0.999795875">
the intuition that the translation of a term is likely
to be more frequent in the subset of target2 text seg-
ments aligned to source text segments containing the
source language term than in the entire target lan-
guage text.
The method consists in building a &amp;quot;global&amp;quot; fre-
quency table for all target language terms. Further-
more, for each source language term, a &amp;quot;sub-corpus&amp;quot;
of target text segments aligned to source language
segments containing that source language term is
created. A separate, &amp;quot;local&amp;quot; frequency table of tar-
get language terms is built for each source language
term. Candidate translation terms 11 for a source lan-
guage term s/ are ranked by dividing the &amp;quot;local&amp;quot; fre-
quency by their &amp;quot;global&amp;quot; frequency, and select those
pairs for which the result &gt; 1.
</bodyText>
<equation confidence="0.56324">
freq/ocal (a1s1)
freqgiobat (a)
</equation>
<bodyText confidence="0.999326333333333">
Threshold An important drawback of this defini-
tion is that very low-frequent target language terms,
which just happen to occur in an aligned segment will
get unrealistically high scores. To eliminate these, we
imposed a threshold by removing from the list those
target language terms whose local frequency was be-
low a certain threshold. The threshold is defined in
terms of the global frequency of the source language
term.
</bodyText>
<construct confidence="0.5679625">
&gt; threshold
freqgzobal (sl) â€”
</construct>
<bodyText confidence="0.955530333333333">
The default threshold used was 50%. However,
this restriction does not improve results for those
source language terms that are infrequent them-
selves. The effects of variation of this threshold
on precision and recall are discussed in section 5.2,
where it will be shown that the threshold, as a pa-
rameter of the program, can be modified by the user
to give a higher priority to precision or to recall.
Similar filters could be established by defining a
threshold in terms of the global frequency of the tar-
get language term. One could also require minimal
absolute values&apos;.
Position-sensitivity An option to the selection
method is to calculate the &amp;quot;expected&amp;quot; position of
the translation of a term (using the size4 of source
and target fragments and the position of the source
term in the source segment). For the target language
terms, the score is decreased proportionally to the
21t should be noted that we are comparing two trans-
lationally related texts; there need not be an actual di-
rectional source target relation between the texts.
3For example, [Gaussier et al., 1992] selected source
language terms co-occurring more than six times with
target language terms.
</bodyText>
<listItem confidence="0.634392">
4 Size and distance are measured in terms of the num-
ber. of words (or nouns, NPs) in the segments.
</listItem>
<bodyText confidence="0.974172">
distance from the expected position, normalized by
the size of the target segment5.
</bodyText>
<sectionHeader confidence="0.85096" genericHeader="method">
4 Word and noun-based methods
</sectionHeader>
<subsectionHeader confidence="0.983603">
4.1 Experiment
</subsectionHeader>
<bodyText confidence="0.999886333333333">
In the word and noun-based methods, a test suite
of 100 Dutch words which were tagged as a noun
was selected at random. In the word-based method,
the frequencies being compared are the frequencies
of the word forms. In the noun-based method, only
frequencies of nouns are compared. Figure 4 shows
the result of some experiments. The quality of the
methods can be measured in recall -whether or not
a translation of a term is found- and precision. We
define precision as the ability of the program to as-
sign the translation, given that this translation has
been found, the highest relevance score.
</bodyText>
<figureCaption confidence="0.993982">
Figure 4: Word and noun-based methods
</figureCaption>
<subsectionHeader confidence="0.906378">
Term Position Recall Precision
</subsectionHeader>
<bodyText confidence="0.964914823529412">
word no 52% 33%
word yes 52%- 77%
noun no 48% 49%
noun yes 43% 77%
The experiments demonstrate that position-
sensitivity results in a major improvement of pre-
cision. The size of the segments of the aligned pro-
gram is still fairly large (on average, over 24 words
per segment in the test corpus), therefore there will
in general be a lot of candidate translations for a
given term. Especially in the case of a small corpus
such as ours, this results in a tendency to return a
number of terms as ex aequo highest scoring items.
Apparently, there is little distortion in the order of
terms in the corpus.
Another conclusion that can be drawn from the
examples is that use of categorial information alone
does not improve precision, even though the num-
ber of candidate translations is greatly reduced.
Position-sensitivity is a much more effective way to
achieve improved precision. One factor explaining
this lack of succes is the error rate introduced by
text tagging, which the word-based method does not
suffer from. As expected, there is an inherent reduc-
tion in recall because nouns do not always translate
to nouns.
Figure 5 shows an example of the output of the
position-sensitive, word-based system. The word in-
dustry occurs 88 times globally (fourth output col-
umn) in the corpus, twice locally, in segments aligned
5This option introduces a complication in that local
scores are no longer simple co-occurrence counts, whereas
global scores still are. This is partly responsible for lower
recall in figures 4 and 9.
</bodyText>
<equation confidence="0.595111">
freDocal (tIls1)
</equation>
<page confidence="0.985742">
115
</page>
<bodyText confidence="0.856558333333333">
to segments containing industrietak. This local fre-
quency is adapted to 1.8315.. (the third output col-
umn), because of position-sensitivity.
</bodyText>
<figureCaption confidence="0.976421">
Figure 5: Example output
</figureCaption>
<table confidence="0.9715785">
Found 2 matches for industrietak in 912 segments
13.073232323232324 industry 1.8315151515151515 88
3.5176684881602913 is 1.376969696969697 244
2.331223628691983 in 1.7727272727272727 474
</table>
<subsectionHeader confidence="0.883065">
4.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999985294117647">
The real concern raised by the results of the four
methods discussed is the very low recall. There are
various categories of errors common to all methods,
which will be discussed in more detail in the evalua-
tion of a much larger experiment in section 5.3.
However, a more fundamental problem specific to
the word and noun-based methods is the inability
to extract translational information between higher-
level units such as noun phrases or compounds. The
English compound programme management is re-
lated to a single Dutch word, viz. programmabeheer,
and even more complex sequences such as high speed
data processing capability are translations of snelle
gegevensverwerkingscapaciteit, where high speed is
mapped to the adjective snel and data processing ca-
pability to gegevensverwerkingscapaciteit. The com-
pound problem alone represents 65% of the errors,
and is a general problem which comes up in com-
paring languages like German or Dutch to languages
like French or English.
Although the compound problem can also be ad-
dressed by morphological decomposition of com-
pounds, there are two other advantages to com-
pare the languages at the phrasal rather than at the
(tagged) lexical level.
Sometimes, an ambiguous noun is disambiguated
by an adjective, e.g. financial statement, where the
adjective imposes a particular reading on the head
noun. A phrasal method is then based on less am-
biguous terms, and will therefore yield more refined
translations.
Furthermore, the method implicitly lexicalizes
translation of collocational effects between adjectives
and head nouns.
</bodyText>
<sectionHeader confidence="0.999991" genericHeader="method">
5 Phrase-based methods
</sectionHeader>
<subsectionHeader confidence="0.999498">
5.1 Evaluation of phase-based methods
</subsectionHeader>
<bodyText confidence="0.964193625">
Initial experiments with a phrase-based method
showed a small quality increase. However, in order to
evaluate the performance of the phrase-based meth-
ods in more detail, a much larger and representative
collection of NPs was selected. This collection con-
sisted of 1100 Dutch NPs, which is 17% of the total
number of NPs in the Dutch text.
A list associating these terms to their correct
translations was compiled semi-automatically, by us-
ing some of the methods described in this paper and
checking and correcting the results manually. 61 NPs
were removed from the collection because the trans-
lation of some occurrences of these terms turned out
to be incorrect, very indirect, simply missing from
the text, or because they suffered from low-level for-
matting errors or typing errors. Also, a program to
automate the evaluation process was implemented.
The remaining set was divided in two groups.
1. One group contained 706 pairs of NPs which
the extraction algorithms should be able extract
from the text, because they occur in correctly
aligned segments, and are tagged and parsed
correctly.
2. The other group consists of 334 NPs which it
would not be able to extract because of one or a
combination of errors in one of the preprocessing
steps. Section 5.3 contains a detailed analysis of
these errors.
It is important to note that due to these errors,
the extraction algorithms will not be able to achieve
recall beyond 68%. Nevertheless, the acquisition al-
gorithms, when operating on NPs instead of words
or nouns, perform markedly better, cf. figure 6. The
recall of both methods is 64%, which is much better
than word and noun-based methods. When only tak-
ing into account the group of 706 items which didn&apos;t
have any preprocessing errors, recall is even 94%. Fi-
nally, precision again improves considerably by ap-
plying position-sensitivity. Section 5.4 discusses at-
tempts to further improve precision.
</bodyText>
<figureCaption confidence="0.997766">
Figure 6: Phrase-based methods
</figureCaption>
<subsectionHeader confidence="0.994608">
5.2 Tunability
</subsectionHeader>
<bodyText confidence="0.998591714285714">
The threshold is defined in terms of the source lan-
guage term frequency. As can be expected, a high
threshold results in relatively higher precision and
relatively lower recall. Figure 7 shows some fig-
ures of varying thresholds with the position-sensitive
method. As in figure 6, the score in parentheses is
the recall score when attention is restricted to the set
of 706 NPs. The 50% threshold is the default for the
experiments discussed in this paper, cf. the second
row of table 6.
The threshold value of our method is a parameter
that can be changed, so that an appropriate thresh-
old can be selected, depending on the desired priority
of precision and recall.
</bodyText>
<figure confidence="0.986414125">
Position
Recall
Precision
64% (94%) 35%
64% (94%)
no
Yes
68%
</figure>
<page confidence="0.885807">
116
</page>
<figureCaption confidence="0.999111">
Figure 7: Effects of variation of threshold value
</figureCaption>
<table confidence="0.99877875">
Threshold Recall Precision
100% 15% (23%) 100 %
95% 31% (45%) 96%
90% 42% (62%) 88%
75% 54% (79%) 76%
50% 64% (94%) 68%
25% 66% (97%) 64%
10%-- 66% (97%) 59%
</table>
<subsectionHeader confidence="0.990598">
5.3 Analysis of errors affecting recall
</subsectionHeader>
<bodyText confidence="0.999469">
The errors can be classified and quantified as follows.
There are four classes of technical problems caused
by the various preprocessing phases, and two classes
of fundamental counter-examples. These are the four
classes of errors due to preprocessing.
</bodyText>
<listItem confidence="0.757422333333333">
1. Incorrect alignment of text segments accounts
for 6% of the errors.
2. In 15% of the errors part of a term is tagged
</listItem>
<bodyText confidence="0.914645958333333">
incorrectly. This is often due to lexicon errors.
An incompatibility between lexical classification
schemes accounts for another 7% of the errors.
The Dutch tagger also has no facility to deal
with occasional use of English in Dutch text
(4%).
3. The tagger (and its dictionary) currently doesn&apos;t
recognize multi word units, hence e.g. with res-
pect to wrongly yields the term respect (6%).
4. In many cases the syntactic structures of the
terms in the two languages do not match. This
is the main source of errors (47%). The pattern
matcher ignores postnominal PP arguments and
modifiers in both languages. However, a Dutch
postnominal PP argument often maps to the
first part of an English noun-noun compound,
as in the following example, where markt maps
to market and versplintering to fragmentation.
versplintering van, markets
ded markt,&apos; fragmentationn
The majority of errors (85%) is therefore due to er-
rors in text preprocessing, where there are still many
possible improvements. The remaining two classes
are fundamental counter-examples.
</bodyText>
<listItem confidence="0.651392666666667">
1. In a number of cases (15%), NPs do not trans-
late to NPs, e.g. the following Dutch sentence
contains the equivalent of careful management.
</listItem>
<bodyText confidence="0.875115052631579">
snelle mare needsâ€ž
zorgvuldigea leidingn ton, be,, rapida but
vraagtv carefullysdv
managed.
2. In two cases (1%), the solution of a genuine
. ambiguity by the tagger did not correspond to
the interpretation imposed by the translation.
In the following example, the deverbal mean-
ing of vervaardiging imposes the interpretation
of manufacturing as a gerund.
hoofdaccentn op, ded 4-4 main, emphasis on,
vervaardigingn van, manufacturing/,,,
elementenn elementsn
However, these two classes affect only 5% of all
terms. The theoretically maximal recall, assuming
that the alignment program, tagger and NP parser
all perform fully correctly, is 95%. Since the parser is
currently extremely simplistic, we expect that major
improvements can be readily achieved&apos;.
</bodyText>
<subsectionHeader confidence="0.99939">
5.4 Improving precision
</subsectionHeader>
<bodyText confidence="0.999984923076923">
The results in figure 6 and 7 show an important im-
provement in recall. One factor impeding better pre-
cision is the small size of the corpus. In our corpus,
71% of the Dutch NPs is unique in the corpus, and
precision suffers from sparsity of data. Still, it is
useful to investigate ways to improve precision.
One obvious option we explored was to exploit
compositionality in translation. The Dutch terms in
figure 8 all contain the `subterm&apos; schakelingen, the
English terms the subterm circuits. This evident
regularity is not exploited by any of the discussed
methods. We experimented with an approach where
co-occurrence tables are built of terms as well as of
heads of terms&apos; and where this information is used in
the selection and ordering of translations. Surpris-
ingly, this improved results for non-positional meth-
ods, but not for positional methods. We do expect
these regularities to emerge with much larger cor-
pora.
There are some other possibilities which could be
explored. The terms could lemmatized, so that infor-
mation about inflectional variants can be combined.
There may also be a correlation in length of terms
and their translations. Finally, the alignment pro-
gram provides a measure of the quality of alignment,
which is not yet used by the program.
</bodyText>
<sectionHeader confidence="0.996222" genericHeader="method">
6 Related Research
</sectionHeader>
<bodyText confidence="0.999701333333333">
In this section we compare our work with two other
methods reported on in the literature. In section 6.1
we compare our work to work discussed in [Gaussier
et al., 1992], which is based on mutual informa-
tion. Section 6.2 discusses [Gale and Church, 1991a),
which is based on the 02 statistic.
</bodyText>
<footnote confidence="0.999158625">
6It is conceivable to partly automate the acquisition of
the necessary lexical knowledge, viz, determining which
nouns are likely to take PP complements, but our corpus
is too small for this type of knowledge acquisition.
7In fact, it turned out to be better to use final sub-
strings (e.g. six or seven characters) of the head noun of
the NP instead of the head itself to avoid the compound
problem discussed in section 4.2.
</footnote>
<page confidence="0.992248">
117
</page>
<figureCaption confidence="0.995154">
Figure 8: Terms containing circuits
</figureCaption>
<figure confidence="0.948920454545454">
geintegreerde opto-
electronische schakelin-
gen
snelle logische schake-
lingen
geintegreerde
schakelingen
integrated optoelectric
circuits
4-â–  high speed logic circuits
4-4 integrated circuits
</figure>
<bodyText confidence="0.93349725">
In both cases, the threshold results in a huge im-
provement of precision, at the expense of recall. The
position-sensitive result is comparable to the 90%
row in table 7.
</bodyText>
<figureCaption confidence="0.8943665">
Figure 9: Phrase-based methods using mutual infor-
mation
</figureCaption>
<subsectionHeader confidence="0.966808">
Position Filter Recall Precision
</subsectionHeader>
<bodyText confidence="0.999943615384615">
A third method to extract bilingual terminology
is the use of latent semantic indexing, cf. [Landauer
and Littmann, 1990]. Latent semantic indexing is
a vector model, where a term-document matrix is
transformed to a space of much less dimensions using
a technique called singular value decomposition. In
the resulting matrix, distributionally similar terms,
such as synonyms, are represented by similar vec-
tors. When applied to a collection of documents and
their translations, terms will be represented by vec-
tors similar to the representations of their transla-
tions. We have not yet compared our method to this
approach.
</bodyText>
<subsectionHeader confidence="0.999693">
6.1 Mutual information
</subsectionHeader>
<bodyText confidence="0.999932857142857">
The selection and ranking method is not based on
the concept of mutual information (cf. [Church and
Hanks, 19891), though the technique is quite similar.
The mutual information score compares the prob-
ability of observing two items together (in aligned
segments) to the product of their individual proba-
bilities.
</bodyText>
<equation confidence="0.997074333333333">
P(sl,t1)
I(sl,t1)----- log2
P(s1)P(t1)
</equation>
<bodyText confidence="0.855594153846154">
The difference is that in our method the global
frequency of the source language term is only used
in the threshold, and is not used for computing
the translational relevance score. Mutual informa-
tion is used for translation selection and ranking in
[Gaussier et al., 1992]. For comparison, the evalu-
ation was repeated using mutual information as se-
lection and ordering criterium. The first two rows in
figure 9 show mutual information achieves improved
recall when compared to figure 6, but at the expense
of reduced precisions.
In [Gaussier ei al., 1992] a filter is used which elim-
inates all candidate target language terms that do
not provide more information on any other source
language term. The last two rows in figure 9 show
results from our implementation of that technique.
81t is possible to select only pairs with a mutual infor-
mation score greater than some minimum value, which
reduces recall and improves precision. However, reduc-
ing recall to the level in figure 6 still leaves precision at
a level much below the precision level given there.
no no 66% 25%
y es no r8%i 58%
66% 98%
no y es 55% 82% 38%
yes yes 40% (59%) 89%
</bodyText>
<subsectionHeader confidence="0.994156">
6.2 The 4)2 method
</subsectionHeader>
<bodyText confidence="0.999816285714286">
In [Gale and Church, 1991a], another association
measure is used, viz. 02, a x2-like statistic. In the
following formula, assume a is the co-occurrence fre-
quency of a source language term s/ and a target
language term ii, b the frequency of s/ minus a, c the
frequency of ti minus a, and d the number of regions
containing neither sl, nor LI.
</bodyText>
<equation confidence="0.667997666666667">
= (ad â€” bc)2
e
(a b) (a + c)(b + d)(c + d)
</equation>
<bodyText confidence="0.9987304">
As in the other methods, the co-occurrence fre-
quency can be modified to reflect position-sensitivity.
We incorporated this measure into our system and
evaluated the performance. This result is similar to
the 25% threshold in figure 7.
</bodyText>
<figureCaption confidence="0.617246">
Figure 10: Results using 02-statistic
</figureCaption>
<sectionHeader confidence="0.999278" genericHeader="discussions">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999405642857143">
In this paper a number of methods to extract bilin-
gual terminology from aligned corpora were dis-
cussed. The methods consist of a linguistic term
extraction phase and a statistic translation selection
phase.
The best term extraction method (in terms of re-
call) turned out to be a method that defines terms
as NPs. NPs are extracted from text using part of
speech tagging and pattern matching. Both tagging
and NP-extraction can still be improved consider-
ably. Precision is improved by preferring terms at
&apos;similar&apos; positions in target language segments.
The translation selection method selects and or-
ders translations of a term by comparing global and
</bodyText>
<figure confidence="0.99276775">
Position
Recall
Precision
66% (97%) 37%
66% (97%)
no
yes
64%
</figure>
<page confidence="0.989668">
118
</page>
<bodyText confidence="0.999950157894737">
local frequencies of the target language terms, sub-
ject to a threshold condition defined in terms of the
frequency of the source language term. The thresh-
old is a parameter which can be used to give priority
to precision or recall.
The re-implementation of the algorithms discussed
in [Gaussier et al., 1992] and [Gale and Church,
1991a] results in precision/recall figures comparable
to our method. It should be noted that these studies
establish correspondences between words rather than
phrases. We have shown a phrasal approach yields
improved recall in the Dutch-English language pair.
These studies dealt with an English-French corpus.
To some extent, the mismatch due to compounding
may be less problematic for this language pair, but
the example of the translation of the English expres-
sion House of Commons to Chambre des Communes9
shows this language pair would also benefit from a
phrasal approach. These are lexicalized phrases and
are described as such in dictionaries10.
Another difference is that position-sensitivity in
ranking potential translations is not taken advantage
of in the earlier proposals. Tables 9 and 10 show
these methods also benefit from this extension. Both
proposals also have no direct analog to our threshold
parameter, which allows for prioritizing precision or
recall (cf. section 5.2).
One aspect not covered at all in our proposal is
the technical problem of memory requirements which
will emerge when using very large corpora. This is-
sue is discussed in [Gale and Church, 1991a]. Future
experiments should definitely concentrate on experi-
ments with much larger corpora, because these would
allow us to carry out realistic experiments with tech-
niques such as mentioned in section 5.4. We also ex-
pect precision to improve in larger corpora, because
most NPs are unique in the small corpus we used so
far.
</bodyText>
<sectionHeader confidence="0.991332" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.996813363636364">
The research reported was supported by the Euro-
pean Commission, through the Eurotra project and
carried out at the Research Institute for Language
and Speech, Utrecht University. Some experiments
and revisions were carried out at Digital Equipment&apos;s
CEC in Amsterdam. I thank Danny Jones at Umist,
Manchester, for the tagged version of the English
corpus; Amy Winarske at ISSCO Geneva, for the
alignment program mentioned in section 2; and Jean-
Marc Lange and Bill Gale for help in preparing sec-
tion 6.
</bodyText>
<footnote confidence="0.439566">
9 Discussed in [Landauer and Littmann, 1990, page 34]
and [Gale and Church, 1991a, page 154].
&amp;quot;This example again pinpoints the need for improved
NP-recognition, because the PP of Commons would not
be attached to the NP by the NP rule in section 2.
</footnote>
<sectionHeader confidence="0.96262" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.967262608695652">
[Brown et al., 1990] P.F. Brown, J. Cocke, S.A. Del-
laPietra, V.J. DellaPietra, F. Jelinek, J.D. Laf-
ferty, R.L. Mercer, and P.S. Roossin. A statistical
approach to machine translation. Computational
Linguistics, 16:85-97, 1990.
[Brown et al., 1991] P. Brown, J. Lai, and R. Mer-
cer. Aligning sentences in parallel corpora. In 29th
Annual Meeting of the Association for Computa-
tional Linguistics, pages 169-176, 1991.
[Catizone et al., 1989] R. Catizone, G. Russel, and
S. Warwick. Deriving translation data from bilin-
gual texts. In Uri Zernik, editor, Proc. of the First
Int. Lexical Acquisition Workshop, Detroit, 1989.
[Church and Hanks, 1989] K. Church and P. Hanks.
Word association norms, mutual information, and
lexicography. In 27th Annual Meeting of the As-
sociation for Computational Linguistics, pages 76-
83, 1989.
[Church, 1988] K. Church. A stochastic parts pro-
gram and noun phrase parser for unrestricted text.
In 2nd Conference on Applied Natural Language
Processing (ACL), 1988.
[Gale and Church, 1991a] W. Gale and K. Church.
Identifying word correspondences in parallel texts.
In 4th Darpa Workshop on Speech and Natural
Language, pages 152-157, 1991.
[Gale and Church, 1991b] W. Gale and K. Church.
A program for aligning sentences in bilingual cor-
pora. In 29th Annual Meeting of the Associa-
tion for Computational Linguistics, pages 177-
184, 1991.
[Gale et al., 1992] W. Gale, K. Church, and
D. Yarowsky. Using bilingual materials to develop
word sense disambiguation methods. In Fourth In-
ternational Conference on theoretical and method-
ological issues in machine translation, pages 101-
112, Montreal, 1992.
[Gaussier et al., 1992] E. Gaussier, J-M Lange, and
F. Meunier. Toward bilingual terminology. In
Joint A LLC/ACH Conference, Oxford, 1992.
[Landauer and Littmann, 1990] T. Landauer and
M. Littmann. Fully automatic cross-language doc-
ument retrieval using latent semantic indexing. In
Proceedings of the 6th Conference of the UW Cen-
tre for the New Oxford English Dictionary and
Text Research, pages 31-38, 1990.
</reference>
<page confidence="0.998952">
119
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.612104">
<title confidence="0.999838">Automating the Acquisition of Bilingual Terminology</title>
<author confidence="0.998545">Pim van_der_Eijk</author>
<affiliation confidence="0.99878">Digital Equipment Corporation</affiliation>
<address confidence="0.988214666666667">Kabelweg 21 1014 BA Amsterdam The Netherlands</address>
<email confidence="0.999943">eijkacecehv.enet.dec.com</email>
<abstract confidence="0.999668333333333">As the acquisition problem of bilingual lists of terminological expressions is formidable, it is worthwhile to investigate methods to compile such lists as automatically as possible. In this paper we discuss experimental results for a number of methods, which operate on corpora of previously translated texts.</abstract>
<keyword confidence="0.812851">Keywords: parallel corpora, tagging, terminology acquisition.</keyword>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P F Brown</author>
<author>J Cocke</author>
<author>S A DellaPietra</author>
<author>V J DellaPietra</author>
<author>F Jelinek</author>
<author>J D Lafferty</author>
<author>R L Mercer</author>
<author>P S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>Computational Linguistics,</journal>
<pages>16--85</pages>
<marker>[Brown et al., 1990]</marker>
<rawString>P.F. Brown, J. Cocke, S.A. DellaPietra, V.J. DellaPietra, F. Jelinek, J.D. Lafferty, R.L. Mercer, and P.S. Roossin. A statistical approach to machine translation. Computational Linguistics, 16:85-97, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Brown</author>
<author>J Lai</author>
<author>R Mercer</author>
</authors>
<title>Aligning sentences in parallel corpora.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>169--176</pages>
<marker>[Brown et al., 1991]</marker>
<rawString>P. Brown, J. Lai, and R. Mercer. Aligning sentences in parallel corpora. In 29th Annual Meeting of the Association for Computational Linguistics, pages 169-176, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Catizone</author>
<author>G Russel</author>
<author>S Warwick</author>
</authors>
<title>Deriving translation data from bilingual texts.</title>
<date>1989</date>
<booktitle>In Uri Zernik, editor, Proc. of the First Int. Lexical Acquisition Workshop,</booktitle>
<location>Detroit,</location>
<marker>[Catizone et al., 1989]</marker>
<rawString>R. Catizone, G. Russel, and S. Warwick. Deriving translation data from bilingual texts. In Uri Zernik, editor, Proc. of the First Int. Lexical Acquisition Workshop, Detroit, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>P Hanks</author>
</authors>
<title>Word association norms, mutual information, and lexicography.</title>
<date>1989</date>
<booktitle>In 27th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>76--83</pages>
<marker>[Church and Hanks, 1989]</marker>
<rawString>K. Church and P. Hanks. Word association norms, mutual information, and lexicography. In 27th Annual Meeting of the Association for Computational Linguistics, pages 76-83, 1989.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>A stochastic parts program and noun phrase parser for unrestricted text.</title>
<date>1988</date>
<booktitle>In 2nd Conference on Applied Natural Language Processing (ACL),</booktitle>
<marker>[Church, 1988]</marker>
<rawString>K. Church. A stochastic parts program and noun phrase parser for unrestricted text. In 2nd Conference on Applied Natural Language Processing (ACL), 1988.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
</authors>
<title>Identifying word correspondences in parallel texts.</title>
<date>1991</date>
<booktitle>In 4th Darpa Workshop on Speech and Natural Language,</booktitle>
<pages>152--157</pages>
<marker>[Gale and Church, 1991a]</marker>
<rawString>W. Gale and K. Church. Identifying word correspondences in parallel texts. In 4th Darpa Workshop on Speech and Natural Language, pages 152-157, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
</authors>
<title>A program for aligning sentences in bilingual corpora.</title>
<date>1991</date>
<booktitle>In 29th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>177--184</pages>
<marker>[Gale and Church, 1991b]</marker>
<rawString>W. Gale and K. Church. A program for aligning sentences in bilingual corpora. In 29th Annual Meeting of the Association for Computational Linguistics, pages 177-184, 1991.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
<author>D Yarowsky</author>
</authors>
<title>Using bilingual materials to develop word sense disambiguation methods.</title>
<date>1992</date>
<booktitle>In Fourth International Conference on theoretical and methodological issues in machine translation,</booktitle>
<pages>101--112</pages>
<location>Montreal,</location>
<marker>[Gale et al., 1992]</marker>
<rawString>W. Gale, K. Church, and D. Yarowsky. Using bilingual materials to develop word sense disambiguation methods. In Fourth International Conference on theoretical and methodological issues in machine translation, pages 101-112, Montreal, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Gaussier</author>
<author>J-M Lange</author>
<author>F Meunier</author>
</authors>
<title>Toward bilingual terminology.</title>
<date>1992</date>
<booktitle>In Joint A LLC/ACH Conference,</booktitle>
<location>Oxford,</location>
<marker>[Gaussier et al., 1992]</marker>
<rawString>E. Gaussier, J-M Lange, and F. Meunier. Toward bilingual terminology. In Joint A LLC/ACH Conference, Oxford, 1992.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Landauer</author>
<author>M Littmann</author>
</authors>
<title>Fully automatic cross-language document retrieval using latent semantic indexing.</title>
<date>1990</date>
<booktitle>In Proceedings of the 6th Conference of the UW Centre for the New Oxford English Dictionary and Text Research,</booktitle>
<pages>31--38</pages>
<marker>[Landauer and Littmann, 1990]</marker>
<rawString>T. Landauer and M. Littmann. Fully automatic cross-language document retrieval using latent semantic indexing. In Proceedings of the 6th Conference of the UW Centre for the New Oxford English Dictionary and Text Research, pages 31-38, 1990.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>