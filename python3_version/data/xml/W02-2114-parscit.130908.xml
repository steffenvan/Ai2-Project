<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.027377">
<title confidence="0.988512">
Aggregation with Strong Regularities and Alternatives
</title>
<author confidence="0.793649">
Helmut Horacek
</author>
<affiliation confidence="0.643938">
Universität des Saarlandes
</affiliation>
<address confidence="0.304485">
FB 6.2 Informatik
</address>
<email confidence="0.994079">
horacek@cs.uni-sb.de
</email>
<sectionHeader confidence="0.993786" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997088">
Aggregation is typically treated in NLG as
a local optimization measure, and methods
exist only for building conjoined expres-
sions with &apos;and&apos;. In contrast to that, solu-
tions to logical problems are characterized
by regularly occurring commonalities, in-
cluding complete subsets of possible value
combinations and alternatives. In order to
address constellations of this kind, we
extend current aggregation techniques,
envisioning high degrees of condensation.
In particular, we define novel constructs
that can express sets of propositions with
highly regular variations on slot values
concisely, including special forms of dis-
junctions. Our methods enable the gener-
ation of expressions with semantically
complex operators, such as &apos;vice-versa&apos; and
&apos;each&apos;, and they support various aspects in
interpreting solutions produced by formal
systems, such as highlighting commonal-
ities among and differences across solution
parts, supporting the inspection of depen-
dencies and variations, and the discovery
of flaws in problem specifications.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99998075">
Aggregation is a central concept in NLG that is
relevant for practically all applications. It is typi-
cally treated as an opportunistic optimization
measure addressing locally occurring commonal-
ities. In contrast to that, solutions to logical
problems are characterized by regularly occurring
commonalities, including complete subsets of
value combinations and alternatives.
In order to address constellations of this kind, we
extend current aggregation techniques, envisioning
high degrees of condensation. In particular, we
define novel constructs that can express sets of
propositions with highly regular variations on slot
values concisely, including special forms of dis-
junctions. Among others, this method enables the
generation of expressions with semantically com-
plex operators and disambiguation markers, such
as &apos;vice-versa&apos;, &apos;each&apos;, &apos;remaining&apos;, and &apos;distinct&apos;.
The paper is organized as follows. First we
review aggregation techniques. Then we define
new aggregation constructs. We describe a proce-
dure for building compositions of these constructs,
including syntactic realization. Finally, we discuss
the application potential of our approach.
</bodyText>
<sectionHeader confidence="0.982421" genericHeader="method">
2 Previous Approaches
</sectionHeader>
<bodyText confidence="0.999966842105263">
The term aggregation was first used in (Mann and
Moore, 1980). It is relevant in all processing
phases of NLG (Reape and Mellish, 1999). Its
most common form, structural aggregation, con-
cerns compositions of several logical assertions
that share information into a single natural langu-
age utterance with coordinated or omitted parts,
yielding conjunction reduction (“Foxes and wolves
are animals”) and ellipsis or gapping (“Foxes are
larger than birds and _ smaller than wolves”).
Aggregation techniques have been incorporated
in early systems, such as KDS (Mann and Moore,
1981). Aggregation manifests itself in optimi-
zations carried out at the discourse level (Horacek,
1992) and domain specific orderings of propo-
sitions prior to condensation (Dalianis, 1999; Dali-
anis and Hovy, 1996). Coordination and lexical
aggregation take place in sentence planning,
emphasizing stylistic preference rules (Scott and de
</bodyText>
<equation confidence="0.998651">
be(Pete,boxer,&lt;2,4,5,7,9-11,13-16&gt;) be(Steve,actor,&lt;3,5,13&gt;) be(Thelma,actor,&lt;4,8-10,15&gt;)
be(Pete,guard,&lt;1,3,6,8,12,15,16&gt;) be(Steve,boxer,&lt;8,12&gt;) be(Thelma,boxer,&lt;1,3,6&gt;)
be(Pete,operator,&lt;1-14&gt;) be(Steve,guard,&lt;9,14&gt;) be(Thelma,chef,&lt;1-16&gt;)
be(Roberta,actor,&lt;1,2,6,7,11,12,14,16&gt;) be(Steve,nurse,&lt;1-16&gt;) be(Thelma,guard,&lt;2,5,7&gt;)
be(Roberta,guard,&lt;4,10,11,13&gt;) be(Steve,officer,&lt;6,7,10,11&gt;) be(Thelma,teacher,&lt;11-14,16&gt;)
be(Roberta,officer,&lt;1-5,8,9,12-16&gt;) be(Steve,operator,&lt;15,16&gt;)
be(Roberta,teacher,&lt;3,5-10,15&gt;) be(Steve,teacher,&lt;1,2,4&gt;)
</equation>
<figureCaption confidence="0.983742">
Figure 1. Solutions to the puzzle – alternatives in assigning persons to jobs
</figureCaption>
<bodyText confidence="0.967252888888889">
Souza, 1990) and hypotactic aggregation with
detailed lexical decisions (Robin, 1995). However,
all these approaches operate on some local level.
The only systematic approach, which has also
inspired our method, is Shaw&apos;s staged process
(1998a; 1998b), which separates heuristic order-
ings followed by recurrence markings from lingu-
istically justified sentence boundary decisions and
reduction operations.
</bodyText>
<sectionHeader confidence="0.990886" genericHeader="method">
3 The Running Example
</sectionHeader>
<bodyText confidence="0.999987947368421">
We present solutions to a puzzle: “There are four
people: Roberta, Thelma, Steve, and Pete. Among
them they hold eight different jobs, each exactly
two. The jobs are: chef, guard, nurse, telephone
operator, police officer, teacher, actor, and boxer.
The job of the nurse is held by a male. The hus-
band of the chef is the telephone operator. Roberta
is not a boxer. Pete has no education past the ninth
grade. Roberta, the chef, and the police officer
went golfing together. Who holds which jobs?”
This is a fully regular assignment problem. 16
solution variants consist of eight assignments each,
which amounts to 128 propositions if unaggregat-
ed. In Figure 1, the solution variants are referred to
by numbers, as an extra slot. All propositions with
the same value of this slot must be true at the same
time, those with different values holding alter-
natively. To save space, variant numbers for the
same fact are enclosed between &apos;&lt;&apos; and &apos;&gt;&apos;.
</bodyText>
<sectionHeader confidence="0.984052" genericHeader="method">
4 New Aggregation Constructs
</sectionHeader>
<bodyText confidence="0.9966549375">
The solutions to this puzzle consist of highly
regular assignments, which is typical for machine-
generated solutions to these kind of problems
(consider, for example, solutions produced by the
model generator KIMBA (Konrad and Wolfram,
1999), presented in (Horacek and Konrad, 1999)).
For expressing these constellations concisely and
elegantly in natural language, semantically com-
plex operators, such as &apos;each&apos; and &apos;vice-versa&apos; prove
useful. For generating these expressions, we define
novel “2-dimensional” coordinations. Normally,
coordination is done in a pairwise fashion. For the
new constructs, aggregation is done by building the
cross product of the values of two slots, including
special forms of disjunctions for commonalities
across variants (Choice, Except, and Assign):
</bodyText>
<listItem confidence="0.840696">
• The Permut construct
</listItem>
<bodyText confidence="0.818028714285714">
It expresses a set of predications in which the
values of two slots comprise all combinations
out of the two sets of slot fillers, within the
same variant. An example sentence is “Each
of Pete, Steve, and Thelma can be boxer and
guard,” expressing six of the facts in Figure 1,
when abstracting from the variant slot.
</bodyText>
<listItem confidence="0.919258">
• The Choice and the Except constructs
</listItem>
<bodyText confidence="0.99952575">
It expresses an assignment of one individual
to several others, each in a different variant.
An example sentence is “Thelma holds one of
the jobs actor, guard, and teacher,” compris-
ing job assignments of Thelma other than that
to chef in variants 7, 10, and 11 (see Figure
1). An Except construct comprises the com-
plementing assignments for each variant of
the Choice construct, for another individual.
An example sentence is “and Roberta holds
the remaining positions,” complementing the
above job assignments of Thelma.
</bodyText>
<listItem confidence="0.993802666666667">
(1) base(P,a1,...,an) ::= P(a1,...,an)
(2) λxi,xj. base(...,xi,...,xj,...) (ai) (aj) ::= base(...,ai,...,aj,...)
(3) &lt;Ain&gt; ::= &lt;ai1,...,ain&gt;
(4) Coord(base(...,&lt;Ain&gt;,...,&lt;Ajn&gt;,...)) ::= ∀k(1≤ k≤n): λxi,xj. base(...,xi,...,xj,...) (aik) (ajk)
(5) Permut(base(...,&lt;Ain[/aid]&gt;,...,&lt;Ajm[/aje]&gt;,...,ac)) ::=
∀k,l(1≤k≤n,1≤l≤ m; (k,l)≠(d,e)): λxi,xj. base(...,xi,...,xj,...,ac) (aik) (ajl)
(6) Choice(base(...,a,...,&lt;Ain&gt;,...,&lt;Ajn&gt;)) ::= ∀l(1≤ k≤n): λxi,xj. base(...,a,...,xi,...,xj) (aik) (ajl)
(7) Except(base(...,a,...,&lt;Ain&gt;,...,&lt;Ajn&gt;)) ::= ∀k,l(1≤k,l≤n,k≠l): λxi,xj. base(...,a,...,xi,...,xj) (aik) (ajl)
(8) Assign(base(...,&lt;Ain[/aid]&gt;,...,&lt;Ajn[/aje]&gt;,...,&lt;Akn&gt;)) ::=
</listItem>
<bodyText confidence="0.7869735">
∀l,m(1≤l,m≤n; (l,m)≠(d,e)) ∀p(1≤p≤n!): Choice(base(...,&lt;Ail&gt;,...,&lt;Ajm&gt;,...,&lt;Akp&gt;))
where jm = f(il,kp) with f(x,z) ≠ f(y,z) (mutually exclusive)
</bodyText>
<figureCaption confidence="0.731675">
Figure 2. Formal definitions of aggregation constructs
</figureCaption>
<listItem confidence="0.910319">
• The Assign construct
</listItem>
<bodyText confidence="0.999709886363636">
It comprises a special set of Choice constructs
which express the set of all bijective functions
between two sets of individuals, each in one
variant, without repetitions. An example is
“Roberta, Steve, and Thelma each hold one
distinct job out of the set actor, guard, and
teacher,” expressing their job assignments in
variants 2, 4, 5, 9, 13, and 14 (see Figure 1).
In order to define these constructs, we apply λ-
expressions with some special notations (see
Figure 2). Assertions can be reexpressed with the
predicate as an additional slot (1), to allow the
building of λ-expressions (2), that is, the extraction
of variables bound by λ, for which constants can
be substituted. Moreover, slots can be filled by
lists, expressed by capital letters. The first index
indicates the slot position, and the second the
number of elements in the list (3). Moreover,
square brackets indicate optionality, and a dash
marks an element as an exception. Based on that,
operators are used to express the way composition
is done in each case, defined by implicitly con-
joined λ-expressions. The Coord operator handles
pairwise coordination where the substitutions run
over the same index, defined for two slots in (4).
The Permut operator is similar, but both indexes
are varied separately, within one variant ac (5). In
addition, one specific combination can be excluded
optionally (the pair aid and aje). The Choice
operator is identical to Coord, but for the fact that
the variant slot is aggregated (6); for Choice, how-
ever, aggregated assertions hold alternatively and
not simultaneously. The complementing Except
operator (7) is defined analoguously. The Assign
operator is defined as a specific composition of
Choice operators, with one assignment optionally
excluded (8). The variant numbers expressing
alternatives are included as an extra slot in the pro-
minent last position, in order to keep the aggre-
gation procedures uniform. Examples for these
constructs are given in Figure 3.
In order for these constructs to be meaning-
fully applicable, three conditions about the corres-
ponding lexical expressions must hold in addition
</bodyText>
<listItem confidence="0.9977482">
(9) Coord(be(&lt;Steve,Thelma&gt;,&lt;nurse,chef&gt;,all))
(10) Permut(be(&lt;Pete,Steve,Thelma&gt;,&lt;boxer,guard&gt;)) (abstracting from variants)
(11) Choice(be(Thelma,&lt;actor,guard,teacher&gt;,&lt;10,7,11&gt;))
(12) Except(be(Roberta,&lt;actor,guard,teacher&gt;,&lt;10,7,11&gt;))
(13) Assign(be(&lt;Roberta,Steve,Thelma&gt;,&lt;actor,guard,teacher&gt;,&lt;2,4,5,9,13,14&gt;))
</listItem>
<figureCaption confidence="0.99893">
Figure 3. Aggregation constructs built from the running example
</figureCaption>
<bodyText confidence="0.999906882352941">
to the proper constellation of regularities (for
Coord constructs, the second condition is suffi-
cient): (1) slot values aggregated in a cross product
fashion must be expressed by NPs, (2) the sentence
predicate must not allow collective readings, and
(3) the sentence pattern must make reference to the
object&apos;s category (e.g, “holding a position”), to
anchor disambiguation markers (e.g., “distinct”).
These requirements are special forms of express-
ibility conditions, and they are tested by advance
lexicon look-ups. Note that these expressions are
underspecified in terms of scoping. This represen-
tation is justified by the fact that all scopings
conform with the above conditions are semanti-
cally equivalent due to the explicit enumeration of
slot fillers and the restriction to distributive reading
(only the variant slot has a specific semantic).
</bodyText>
<sectionHeader confidence="0.993361" genericHeader="method">
5 A Procedure for Aggregation
</sectionHeader>
<bodyText confidence="0.999992315789474">
In order to achieve maximal condensation, which
is the intuitively most plausible optimization criter-
ion, investigating a considerable search effort
would be required. The results are very sensitive to
the ordering imposed on the facts to be aggregated.
Therefore, all possible orderings need to be tested
to find the maximally condensed text, with reord-
ering applied to aggregated structures for obtaining
further condensation. To achieve a balance betw-
een optimality and efficiency, we confine ourselves
to a linear procedure. Hence, aggregation is per-
formed in a staged process with internal recursions:
(5.1) Intermediate structures with single coordi-
nations are built. (5.2) For disjunctions, all variants
are expressed compactly and unambiguously, if
possible, otherwise (5.3) the set of variants is split,
repeating step (5.2) for each subset. (5.4) Multiple
coordinations are built out of intermediate struct-
ures. (5.5) Linguistic realization is carried out.
</bodyText>
<subsectionHeader confidence="0.998092">
5.1 Coordination with a Single Difference
</subsectionHeader>
<bodyText confidence="0.999890210526316">
First, propositions are ordered by the following
heuristics: (1) The variant slot is the last slot sorted,
to support efficient aggregation across variants. (2)
The remaining slots are sorted by starting from the
element with the least number of distinct values,
which tends to keep together “regular” substruc-
tures, contrasting to the heuristic applied by Shaw.
Coord constructs are built across propositions that
differ in a single slot value (one-slot distinct). This
is done by testing the first two propositions for
identity in all but one of their slots, building a
Coord construct with a list for the slot with non-
equal values. This is repeated incrementally for the
next pair of adjacent propositions, or with the
Coord construct just built and the proposition
following. If a set contains all individuals in the
given context, it is replaced by &apos;all&apos;. In the puzzle,
condensation is done across variants, yielding the
propositions in Figure 1 within Coord operators.
</bodyText>
<subsectionHeader confidence="0.997917">
5.2 Condensing Disjunctions
</subsectionHeader>
<bodyText confidence="0.99997675">
In order to express a set of facts holding in
several variants concisely, coordination constructs
must be built that convey all dependencies among
these variants unambiguously. This means that a
subset of the propositions must be condensed into
one construct expressing disjunctions, with the
remaining propositions being independent of the
set of variants considered – otherwise, the set of
variants is split and condensation attempts are
made for each subset separately. In order to test
whether this is possible, Choice constructs are built
by condensing adjacent propositions that differ by
their variant slot only. Three constellations are
possible (examples appear under variant subsets in
which the set of propositions is partitioned and
marked as cases in Figure 4):
</bodyText>
<listItem confidence="0.973072588235294">
• There are two Choice constructs, Choice(x,
&lt;a1,a2&gt;,&lt;i1,i2&gt;) and Choice(y,&lt;a2,a1&gt;, &lt;i1,i2&gt;).
They are condensed into an Assign construct of
the form Assign(&lt;x,y&gt;,&lt;a1,a2&gt;,&lt;i1,i2&gt;). In the
puzzle, this step applies to assigning &apos;Roberta&apos;
and &apos;Thelma&apos; and &apos;actor&apos; and &apos;teacher&apos;, variants
15 and 16 (case 1).
• There is one Choice construct, Choice(x,&lt;An&gt;,
&lt;In&gt;). If no further propositions are left, or
there are n Coord constructs Coord(y,ai,&lt;Im&gt;),
where Im is equal to In with ii missing, then
these Coord constructs are condensed into an
Except construct Except(y,&lt;An&gt;,&lt;In&gt;). In the
puzzle, this measure applies to assigning &apos;Thel-
ma&apos; to &apos;actor&apos;, &apos;guard&apos;, and &apos;teacher&apos; in variants
7, 10, and 11, and &apos;Roberta&apos; to the remaining
positions in each variant (case 2.1.2).
</listItem>
<figure confidence="0.9568831875">
Coord(be(&lt;Steve,Thelma&gt;,&lt;chef,nurse&gt;))
case 1 (variants are &lt;15,16&gt;): be(Steve,operator)
Coord(be(&lt;Pete,Pete,Roberta&gt;,&lt;boxer,guard,officer&gt;))
Assign(be(&lt;Roberta,Thelma&gt;,&lt;actor,teacher&gt;))
case 2 (variants are &lt;1-14&gt;): be(Pete,operator)
case 2.1 (variants are &lt;6,7,10,11&gt;): be(Steve,officer)
case 2.1.1 (variant is 6): be(Thelma,boxer)
Coord(be(&lt;Pete,Roberta,Roberta&gt;, &lt;guard,teacher,actor&gt;))
case 2.1.2 (variants are &lt;7,10,11&gt;): be(Pete,boxer):
Choice(be(Thelma,&lt;actor,guard,teacher&gt;))
Except(be(Roberta,&lt;actor,guard,teacher&gt;))
case 2.2 (variants are &lt;1-5,8,9,12-14&gt;): be(Roberta,officer)
case 2.2.1 (variants are &lt;1,3,8,12&gt;): be(Pete,guard)
Assign(be(&lt;actor,boxer,teacher/boxer&gt;,&lt;Roberta,Steve,Thelma/Roberta&gt;))
case 2.2.2 (variants are &lt;2,4,5,9,13,14&gt;):be(Pete,boxer)
Assign(be(&lt;actor,guard,teacher&gt;,&lt;Roberta,Steve,Thelma&gt;))
</figure>
<figureCaption confidence="0.999469">
Figure 4. Aggregation constructs for the puzzle (with variants slots omitted, corresponding to cases)
</figureCaption>
<listItem confidence="0.967892321428571">
• There is no Choice construct. In this case, a
specific set of Coord constructs must be pre-
sent so that they can be condensed into an
Assign construct. This is an effective way to
compose an Assign construct, whereas the one
in Figure 2 is more convenient for defining it.
To start with, there must be exactly n! or n!-(n-
1)! variants for some n, and exactly n indi-
viduals in the slots varied (without the variant
slot) in n2 or n2-1 Coord constructs. With
indexing over individuals, checking the
conditions is cheap. Only in case of success,
expensive conditions for building an Assign
construct must be checked. For each i of n (or
n-1) Coord constructs Coord(x,ai,&lt;Im&gt;), the
sets of variants must be pairwise disjoint,
which means that each x is assigned to exactly
one individual in each variant. Similarly, in
each i of the n (or n-1) Coord constructs
Coord(xi,a,&lt;Im&gt;), the sets of variants must be
pairwise disjoint, too, so that each xi is
assigned differently in each variant. If all this
is fulfilled, an Assign construct comprising all
these individuals is built. If the number of
intermediate Coord constructs is n!-(n-1)! and
not n!, the missing fact must be incorporated
in the Assign construct as an exception. In the
puzzle, such a constellation occurs twice. In
</listItem>
<bodyText confidence="0.999453125">
variants 1, 3, 8, and 12 (4 = 3!-2! variants), all
combinations assigning &apos;Roberta&apos;, &apos;Steve&apos;, and
&apos;Thelma&apos; to &apos;actor&apos;, &apos;boxer&apos;, and &apos;teacher&apos; occur,
except that &apos;Thelma&apos; is not assigned to &apos;boxer&apos;
(case 2.2.1). Similarly, variants 2, 4, 5, 9, 13,
and 14 (6 = 3! variants) contain all combi-
nations assigning &apos;Roberta&apos;, &apos;Steve&apos;, and &apos;Thel-
ma&apos; to &apos;actor&apos;, &apos;guard&apos;, and &apos;teacher&apos; (case 2.2.2).
</bodyText>
<subsectionHeader confidence="0.998973">
5.3 Splitting Sets of Variants
</subsectionHeader>
<bodyText confidence="0.98836745">
After Coord constructs that hold across all variants
are extracted, splitting is done along a set of predi-
cations that are two-slot distinct from one another
and appear in each variant exactly once. Due to the
ordering imposed, finding such a set can be done
locally. If there is none, no splitting is attempted,
since it might appear unmotivated and computati-
onally expensive – each variant is then presented
separately. In case of several candidates, the selec-
tion is oriented on economy criteria, preferring
smaller sets of facts, and fewer splits of facts
aggregated over variants. Moreover, uneven distri-
butions of variants are favored, since smaller parts
are more likely to contain regular substructures.
In the puzzle, the propositions holding in all
variants are extracted first, yielding the “fixed”
jobs &apos;chef&apos; and &apos;nurse&apos;. For the first splitting into
Assign (general form) &lt;MARK(POSITION)&gt; &lt;LIST(SLOT1)&gt; &amp;quot;each&amp;quot; &lt;P-CAT(CAT)&gt; &amp;quot;one distinct&amp;quot;
&lt;N-CAT (CAT)&gt; &amp;quot;out of the set of&amp;quot; &lt;LIST(SLOT2)&gt; [&lt;EXCEPTION(TOP)&gt;]
Assign (for list length 2) &lt;COORD (TOP)&gt; &amp;quot;or vice-versa&amp;quot;
</bodyText>
<figureCaption confidence="0.951818">
Figure 5: Example TG/2 patterns, two variants of expressing Assign constructs
</figureCaption>
<bodyText confidence="0.999634">
cases 1 and 2, &apos;operator&apos; and &apos;officer&apos; yield binary
partitions, &apos;operator&apos; causing a more uneven parti-
tioning. Case 2 is split again, according to the
assignment variants for &apos;officer&apos;. Its first partition,
case 2.1, needs to be split further. All candidate
jobs except &apos;guard&apos; yield binary splits, and &apos;boxer&apos; is
chosen because this requires only two aggregated
facts to be split instead of three for &apos;actor&apos; and
&apos;teacher&apos;. The other partition resulting after the
second split, case 2.2, is split again, the only binary
choice being the jobs taken by Pete.
</bodyText>
<subsectionHeader confidence="0.999514">
5.4 Coordination with Two Distinct Slots
</subsectionHeader>
<bodyText confidence="0.999914586206896">
Within subsets of variants, it is attempted to
compose facts that hold across all of these variants
into larger structures, preferably Permut constructs
or at least Coord constructs with two-slot distinct
facts. Building Permut constructs is done by
composing Coord constructs that have identical
lists &lt;Ain&gt; in position i, non-equal atomic values ajk
in position j (k indexing m Coord constructs), and
identical atomic values in other positions, to yield
Permut(base(...,&lt;Ain&gt;,...,&lt;Ajm&gt;,...)). At most once,
one value ax from &lt;Ain&gt; may be missing yielding
Permut(base(...,&lt;Ain[/ax]&gt;,...,&lt;Ajm[/ay]&gt;, ...)) for a
Coord construct with ay in position j. For the
remaining facts and one-slot distinct Coord con-
structs, condensation into two-slot distinct Coord
constructs is attempted. This is done similarly to
the building of one-slot distinct Coord constructs,
and lists are built in the positions of two slots with
distinct values. If a one-slot distinct Coord con-
struct is incorporated, the atomic value in the other
slot is copied as many times as the list in the slot
with distinct values has elements. Repetitions in
one of the slots lead to mixed coordinations in the
linguistic realization, where coordinated conjunc-
tions are combined with predicate gapping. This
advance over previous approaches is due to our
staged coordination procedure. However, the dis-
advantage is the restriction to two-slot distinct
coordinations (Shaw handles multiple distinctions).
</bodyText>
<subsectionHeader confidence="0.995488">
5.5 Linguistic Realization
</subsectionHeader>
<bodyText confidence="0.996786403846154">
In order to express the aggregation constructs by
natural language text, these specifications are pro-
cessed by the linguistic realization component
TG/2 (Busemann, 1996). TG/2 is a pragmatically
motivated system that has been used for several
kinds of applications, including multi-lingual re-
ports of air pollution data (Busemann and Horacek,
1996). Its most unique feature is its capability to
process specifications from several levels of lingu-
istic elaboration, integrating canned text, template
techniques and context-free grammars into a single
formalism. This enables a user of TG/2 to express
specifications only as detailed as needed to handle
the distinctions required for the application at hand.
This feature allows us to model linguistically com-
plex coordination phenomena by defining simpli-
fied grammar rules for schematic sentence patterns
(unlike Shaw&apos;s repertoire of linguistic constructs).
The proper application of TG/2 is preceeded
by a conversion procedure that reexpresses the
position-based encodings in terms of predicate-
argument structures. In addition, specifications
with case splits are reorganized. Blocks with predi-
cates of one category or propositions within cases
that result from splitting are headed by an intro-
ductory statement about their commonality, and
markers expressing, for example, positions in
enumerations, are added. Moreover, nested case
structures are converted into lists where each case
is labeled explicitly with its distinctive feature,
except subcases of minimal size (one sentence).
Subsequently, TG/2 maps aggregation con-
structs via rules onto sentence patterns, such as
those listed in Figure 5. For the first variant of the
Assign construct, the pattern accesses substructures
of that construct (POSITION, SLOT1, CAT,
Thelma is the chef and Steve the nurse.
Then we have three cases to consider.
Case 1: Steve is the operator.
Then Pete is the boxer and the guard, and Roberta the officer.
Moreover, Roberta is the actor and Thelma the teacher, or vice-versa.
Case 2: Pete is the operator and Steve the officer.
One alternative here is that Thelma is the boxer.
Then Roberta is the teacher and the actor, and Peter the guard.
The other alternative is that Pete is the boxer.
Then Thelma takes one of the positions teacher, guard, and actor, and Roberta the remaining positions.
Case 3: Pete is the operator and Roberta the officer.
One alternative here is that Pete is the guard.
Then Roberta, Thelma, and Steve each take one distinct position out of the set teacher, actor, and
boxer, but Roberta is not the boxer.
The other alternative is that Pete is the boxer.
Then Roberta, Thelma, and Steve each take one distinct position out of the set guard, teacher, and actor.
</bodyText>
<figureCaption confidence="0.944961">
Figure 6: Natural language text for the puzzle
</figureCaption>
<bodyText confidence="0.999910375">
SLOT2), and the whole structure (TOP), and it has
further references to rules for a discourse marker
(MARK), lists (LIST), a function verb for the
predicate (P-CAT), the associated noun (N-CAT),
and an optional exception (EXCEPTION). The se-
cond variant, which is treated as a Coord construct
followed by a canned text portion, is only applic-
able to lists of length 2 without an exception. There
are two variants for expressing Except constructs,
one using “remaining” when following a suitable
Choice construct (see Figure 6, Case 2, fourth
sentence). &apos;Mixed&apos; coordinations may require local
reordering, to group together sublists (see Figure 6,
Case 1, first sentence). When applied to the
subject, the predicate must be repeated when plural
changes to singular or vice-versa.
</bodyText>
<sectionHeader confidence="0.996768" genericHeader="conclusions">
6 Conclusion and Discussion
</sectionHeader>
<bodyText confidence="0.999989276923077">
In this paper, we have developed extensions to
existing aggregation techniques that address con-
stellations with regularly occurring commonalities,
as typically found in problem solutions produced
by formal systems. We have defined novel con-
structs that can express sets of propositions with
highly regular variations on slot values concisely,
including special forms of disjunctions. Moreover,
we have described a systematic process in which
compositions of these constructs are built.
Our methods are particularly useful for pre-
senting results produced by formal systems, where
the problem definitions justify expectations about
highly regular structures in the associated results.
Moreover, predications typically have few slots
only, to support efficient reasoning. In such set-
tings, our methods are essential and effective, and
they enable the generation of expressions with
semantically complex operators, such as &apos;vice-
versa&apos; and &apos;each&apos;, and coordinated conjunctions
combined with predicate gapping. Apart from mere
conciseness, the presentations obtained highlight
commonalities among and differences across parts
of problem solutions in a much better way than
previous approaches do, thereby supporting the
inspection of dependencies and variations, and the
discovery of flaws in problem specifications, as
shown in (Horacek and Konrad, 1999). For constel-
lations with less regular value combinations and
more predicate slots (including, e.g., temporal and
local information), the procedure proposed by
Shaw is more appropriate. It is procedurally
simpler and has a richer repertoire in expressing
linguistic phenomena. In principle, our operators
could also be applied beneficially for ordinary text
generation, especially those operators expressing
alternatives compactly. The major problem, how-
ever, would be their effective integration into the
overall generation process, since testing their
applicability conditions might be expensive and
not easy to manage.
Finally, we have limited the use of the new
operators to simple cases, without interference with
other constructs. For example, our procedures are
set up in such a way that a Choice operator is built
only if all its assignments are distinct from one
another. However, there may be constellations
where a distinction between alternatives is made
elsewhere, and the use of a Choice operator would
still be possible and effective, as in “Thelma takes
one of the positions teacher, guard, and actor, and
Roberta is the teacher or the actor if Thelma is the
guard”. This constellation comprises four alter-
natives, with Thelma being the guard in two of
them. Despite the extra condition involved, we
believe that the aggregated form above conveys the
underlying situation in a more natural and better
understandable way than a mere enumeration.
In the future, we intend to investigate practical
demands for extended uses of the new operators.
Moreover, we will examine the adequacy of the
pattern-based approach for expressing these oper-
ators in lexical terms by considering non-European
languages, such as Arabic. Finally, we extend the
use of these operators to formulas (Horacek, 2002).
</bodyText>
<sectionHeader confidence="0.999273" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999829719298245">
Busemann, S. 1996. Best-First Generation. In Proc. of
the 8th International Workshop on Natural Langu-
age Generation, pp. 101-110, Hearstmonceaux, UK.
Busemann, S. and Horacek, H. 1998. A Flexible
Shallow Approach to Text Geneartion. In Proc. of
the 9th International Workshop on Natural Langu-
age Generation, pp. 238-247, Niagara-on-the-Lake,
Canada.
Dalianis, H. 1999. Aggregation in Natural Language
Generation. Computational Intelligence 15(4).
Dalianis, H.; and Hovy, E. 1996. Aggregation in
Natural Language Generation. In G. Adorni, M.
Zock (eds.), Trends in Natural Language Gener-
ation – An Artificial Intelligence Perspective, pp.
88-105, Springer.
Horacek, H. 1992. An Integrated View of Text
Planning. In R. Dale, E. Hovy, D. Rösner, O. Stock
(eds.), Aspects of Automated Natural Language
Generation, pp. 29-44, Springer.
Horacek, H. 2002. Presenting Sets of Problem Solutions
Concisely. Submitted.
Horacek, H.; and Konrad, K. 1999. Presenting Herbrand
Models with Linguistically Motivated Techniques.
In Proc. of CIMCA-99, Vienna, Austria.
Konrad, K.; and Wolfram, D. 1999. System Descrip-
tion: Kimba, A Model Generator for Many-Valued
First-Order Logics. In Proc. of the 16th Internati-
onal Conference on Automated Deduction (CADE-
16), pp. 282-286 Trento, Italy.
Mann, B.; and Moore, J. 1980. Computer as Author –
Results and Prospects. Research Report ISI/ RR-79-
82, University of Southern California, Information
Sciences Institute, Marina del Rey.
Mann, B.; and Moore, J. 1981. Computer Generation of
Multiparagraph English Text. American Journal of
Computational Linguistics 8(2), pp. 17-29.
Reape, M.; and Mellish, C. 1999. What is Aggregation
Anyhow? In Proc. of 7th European Workshop on
Natural Language Generation, pp. 20-29,
Toulouse, France.
Robin, J. 1995. Revision-Based Generation of Natural
Language Summaries Providing Historical Back-
ground. PhD thesis, Columbia University.
Scott, D.; and de Souza C. 1990. Getting the Message
Across in RST-Based Text Generation. In R. Dale,
C. Mellish, M. Zock (eds.), Current Research in
Natural Language Generation, pp. 47-73, Academic
Press, New York.
Shaw, J. 1998a. Segregatory Coordination and Ellipsis
in Text Generation. In Proc. of the 36th Association
for Computational Linguistics and the 17th Interna-
tional Conference on Computational Linguistics,
pp. 1220-1226, Montreal, Canada.
Shaw, J. 1998b. Clause Aggregation Using Linguistic
Knowledge. In Proc. of the 9th International Work-
shop on Natural Language Generation, pp. 18-147,
Niagara-on-the-lake, Canada.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.368559">
<title confidence="0.997396">Aggregation with Strong Regularities and Alternatives</title>
<author confidence="0.446539">Helmut</author>
<affiliation confidence="0.572706">Universität des</affiliation>
<address confidence="0.547197">FB 6.2</address>
<email confidence="0.962996">horacek@cs.uni-sb.de</email>
<abstract confidence="0.999407038461538">Aggregation is typically treated in NLG as a local optimization measure, and methods exist only for building conjoined expressions with &apos;and&apos;. In contrast to that, solutions to logical problems are characterized by regularly occurring commonalities, including complete subsets of possible value combinations and alternatives. In order to address constellations of this kind, we extend current aggregation techniques, envisioning high degrees of condensation. In particular, we define novel constructs that can express sets of propositions with highly regular variations on slot values concisely, including special forms of disjunctions. Our methods enable the generation of expressions with semantically complex operators, such as &apos;vice-versa&apos; and &apos;each&apos;, and they support various aspects in interpreting solutions produced by formal systems, such as highlighting commonalities among and differences across solution parts, supporting the inspection of dependencies and variations, and the discovery of flaws in problem specifications.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Busemann</author>
</authors>
<title>Best-First Generation.</title>
<date>1996</date>
<booktitle>In Proc. of the 8th International Workshop on Natural Language Generation,</booktitle>
<pages>101--110</pages>
<location>Hearstmonceaux, UK.</location>
<contexts>
<context position="20867" citStr="Busemann, 1996" startWordPosition="2976" endWordPosition="2977">as the list in the slot with distinct values has elements. Repetitions in one of the slots lead to mixed coordinations in the linguistic realization, where coordinated conjunctions are combined with predicate gapping. This advance over previous approaches is due to our staged coordination procedure. However, the disadvantage is the restriction to two-slot distinct coordinations (Shaw handles multiple distinctions). 5.5 Linguistic Realization In order to express the aggregation constructs by natural language text, these specifications are processed by the linguistic realization component TG/2 (Busemann, 1996). TG/2 is a pragmatically motivated system that has been used for several kinds of applications, including multi-lingual reports of air pollution data (Busemann and Horacek, 1996). Its most unique feature is its capability to process specifications from several levels of linguistic elaboration, integrating canned text, template techniques and context-free grammars into a single formalism. This enables a user of TG/2 to express specifications only as detailed as needed to handle the distinctions required for the application at hand. This feature allows us to model linguistically complex coordin</context>
</contexts>
<marker>Busemann, 1996</marker>
<rawString>Busemann, S. 1996. Best-First Generation. In Proc. of the 8th International Workshop on Natural Language Generation, pp. 101-110, Hearstmonceaux, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Busemann</author>
<author>H Horacek</author>
</authors>
<title>A Flexible Shallow Approach to Text Geneartion.</title>
<date>1998</date>
<booktitle>In Proc. of the 9th International Workshop on Natural Language Generation,</booktitle>
<pages>238--247</pages>
<location>Niagara-on-the-Lake, Canada.</location>
<marker>Busemann, Horacek, 1998</marker>
<rawString>Busemann, S. and Horacek, H. 1998. A Flexible Shallow Approach to Text Geneartion. In Proc. of the 9th International Workshop on Natural Language Generation, pp. 238-247, Niagara-on-the-Lake, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dalianis</author>
</authors>
<date>1999</date>
<journal>Aggregation in Natural Language Generation. Computational Intelligence</journal>
<volume>15</volume>
<issue>4</issue>
<contexts>
<context position="3134" citStr="Dalianis, 1999" startWordPosition="440" endWordPosition="441">ommon form, structural aggregation, concerns compositions of several logical assertions that share information into a single natural language utterance with coordinated or omitted parts, yielding conjunction reduction (“Foxes and wolves are animals”) and ellipsis or gapping (“Foxes are larger than birds and _ smaller than wolves”). Aggregation techniques have been incorporated in early systems, such as KDS (Mann and Moore, 1981). Aggregation manifests itself in optimizations carried out at the discourse level (Horacek, 1992) and domain specific orderings of propositions prior to condensation (Dalianis, 1999; Dalianis and Hovy, 1996). Coordination and lexical aggregation take place in sentence planning, emphasizing stylistic preference rules (Scott and de be(Pete,boxer,&lt;2,4,5,7,9-11,13-16&gt;) be(Steve,actor,&lt;3,5,13&gt;) be(Thelma,actor,&lt;4,8-10,15&gt;) be(Pete,guard,&lt;1,3,6,8,12,15,16&gt;) be(Steve,boxer,&lt;8,12&gt;) be(Thelma,boxer,&lt;1,3,6&gt;) be(Pete,operator,&lt;1-14&gt;) be(Steve,guard,&lt;9,14&gt;) be(Thelma,chef,&lt;1-16&gt;) be(Roberta,actor,&lt;1,2,6,7,11,12,14,16&gt;) be(Steve,nurse,&lt;1-16&gt;) be(Thelma,guard,&lt;2,5,7&gt;) be(Roberta,guard,&lt;4,10,11,13&gt;) be(Steve,officer,&lt;6,7,10,11&gt;) be(Thelma,teacher,&lt;11-14,16&gt;) be(Roberta,officer,&lt;1-5,8,9</context>
</contexts>
<marker>Dalianis, 1999</marker>
<rawString>Dalianis, H. 1999. Aggregation in Natural Language Generation. Computational Intelligence 15(4).</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Dalianis</author>
<author>E Hovy</author>
</authors>
<title>Aggregation in Natural Language Generation.</title>
<date>1996</date>
<booktitle>Trends in Natural Language Generation – An Artificial Intelligence Perspective,</booktitle>
<pages>88--105</pages>
<editor>In G. Adorni, M. Zock (eds.),</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="3160" citStr="Dalianis and Hovy, 1996" startWordPosition="442" endWordPosition="446">ctural aggregation, concerns compositions of several logical assertions that share information into a single natural language utterance with coordinated or omitted parts, yielding conjunction reduction (“Foxes and wolves are animals”) and ellipsis or gapping (“Foxes are larger than birds and _ smaller than wolves”). Aggregation techniques have been incorporated in early systems, such as KDS (Mann and Moore, 1981). Aggregation manifests itself in optimizations carried out at the discourse level (Horacek, 1992) and domain specific orderings of propositions prior to condensation (Dalianis, 1999; Dalianis and Hovy, 1996). Coordination and lexical aggregation take place in sentence planning, emphasizing stylistic preference rules (Scott and de be(Pete,boxer,&lt;2,4,5,7,9-11,13-16&gt;) be(Steve,actor,&lt;3,5,13&gt;) be(Thelma,actor,&lt;4,8-10,15&gt;) be(Pete,guard,&lt;1,3,6,8,12,15,16&gt;) be(Steve,boxer,&lt;8,12&gt;) be(Thelma,boxer,&lt;1,3,6&gt;) be(Pete,operator,&lt;1-14&gt;) be(Steve,guard,&lt;9,14&gt;) be(Thelma,chef,&lt;1-16&gt;) be(Roberta,actor,&lt;1,2,6,7,11,12,14,16&gt;) be(Steve,nurse,&lt;1-16&gt;) be(Thelma,guard,&lt;2,5,7&gt;) be(Roberta,guard,&lt;4,10,11,13&gt;) be(Steve,officer,&lt;6,7,10,11&gt;) be(Thelma,teacher,&lt;11-14,16&gt;) be(Roberta,officer,&lt;1-5,8,9,12-16&gt;) be(Steve,operator</context>
</contexts>
<marker>Dalianis, Hovy, 1996</marker>
<rawString>Dalianis, H.; and Hovy, E. 1996. Aggregation in Natural Language Generation. In G. Adorni, M. Zock (eds.), Trends in Natural Language Generation – An Artificial Intelligence Perspective, pp. 88-105, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
</authors>
<title>An Integrated View of Text Planning. In</title>
<date>1992</date>
<booktitle>Aspects of Automated Natural Language Generation,</booktitle>
<pages>29--44</pages>
<editor>R. Dale, E. Hovy, D. Rösner, O. Stock (eds.),</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="3050" citStr="Horacek, 1992" startWordPosition="428" endWordPosition="429">It is relevant in all processing phases of NLG (Reape and Mellish, 1999). Its most common form, structural aggregation, concerns compositions of several logical assertions that share information into a single natural language utterance with coordinated or omitted parts, yielding conjunction reduction (“Foxes and wolves are animals”) and ellipsis or gapping (“Foxes are larger than birds and _ smaller than wolves”). Aggregation techniques have been incorporated in early systems, such as KDS (Mann and Moore, 1981). Aggregation manifests itself in optimizations carried out at the discourse level (Horacek, 1992) and domain specific orderings of propositions prior to condensation (Dalianis, 1999; Dalianis and Hovy, 1996). Coordination and lexical aggregation take place in sentence planning, emphasizing stylistic preference rules (Scott and de be(Pete,boxer,&lt;2,4,5,7,9-11,13-16&gt;) be(Steve,actor,&lt;3,5,13&gt;) be(Thelma,actor,&lt;4,8-10,15&gt;) be(Pete,guard,&lt;1,3,6,8,12,15,16&gt;) be(Steve,boxer,&lt;8,12&gt;) be(Thelma,boxer,&lt;1,3,6&gt;) be(Pete,operator,&lt;1-14&gt;) be(Steve,guard,&lt;9,14&gt;) be(Thelma,chef,&lt;1-16&gt;) be(Roberta,actor,&lt;1,2,6,7,11,12,14,16&gt;) be(Steve,nurse,&lt;1-16&gt;) be(Thelma,guard,&lt;2,5,7&gt;) be(Roberta,guard,&lt;4,10,11,13&gt;) be(</context>
</contexts>
<marker>Horacek, 1992</marker>
<rawString>Horacek, H. 1992. An Integrated View of Text Planning. In R. Dale, E. Hovy, D. Rösner, O. Stock (eds.), Aspects of Automated Natural Language Generation, pp. 29-44, Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
</authors>
<title>Presenting Sets of Problem Solutions Concisely.</title>
<date>2002</date>
<note>Submitted.</note>
<marker>Horacek, 2002</marker>
<rawString>Horacek, H. 2002. Presenting Sets of Problem Solutions Concisely. Submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Horacek</author>
<author>K Konrad</author>
</authors>
<title>Presenting Herbrand Models with Linguistically Motivated Techniques.</title>
<date>1999</date>
<booktitle>In Proc. of CIMCA-99,</booktitle>
<location>Vienna, Austria.</location>
<contexts>
<context position="5587" citStr="Horacek and Konrad, 1999" startWordPosition="758" endWordPosition="761">s if unaggregated. In Figure 1, the solution variants are referred to by numbers, as an extra slot. All propositions with the same value of this slot must be true at the same time, those with different values holding alternatively. To save space, variant numbers for the same fact are enclosed between &apos;&lt;&apos; and &apos;&gt;&apos;. 4 New Aggregation Constructs The solutions to this puzzle consist of highly regular assignments, which is typical for machinegenerated solutions to these kind of problems (consider, for example, solutions produced by the model generator KIMBA (Konrad and Wolfram, 1999), presented in (Horacek and Konrad, 1999)). For expressing these constellations concisely and elegantly in natural language, semantically complex operators, such as &apos;each&apos; and &apos;vice-versa&apos; prove useful. For generating these expressions, we define novel “2-dimensional” coordinations. Normally, coordination is done in a pairwise fashion. For the new constructs, aggregation is done by building the cross product of the values of two slots, including special forms of disjunctions for commonalities across variants (Choice, Except, and Assign): • The Permut construct It expresses a set of predications in which the values of two slots compri</context>
<context position="25627" citStr="Horacek and Konrad, 1999" startWordPosition="3702" endWordPosition="3705"> slots only, to support efficient reasoning. In such settings, our methods are essential and effective, and they enable the generation of expressions with semantically complex operators, such as &apos;viceversa&apos; and &apos;each&apos;, and coordinated conjunctions combined with predicate gapping. Apart from mere conciseness, the presentations obtained highlight commonalities among and differences across parts of problem solutions in a much better way than previous approaches do, thereby supporting the inspection of dependencies and variations, and the discovery of flaws in problem specifications, as shown in (Horacek and Konrad, 1999). For constellations with less regular value combinations and more predicate slots (including, e.g., temporal and local information), the procedure proposed by Shaw is more appropriate. It is procedurally simpler and has a richer repertoire in expressing linguistic phenomena. In principle, our operators could also be applied beneficially for ordinary text generation, especially those operators expressing alternatives compactly. The major problem, however, would be their effective integration into the overall generation process, since testing their applicability conditions might be expensive an</context>
</contexts>
<marker>Horacek, Konrad, 1999</marker>
<rawString>Horacek, H.; and Konrad, K. 1999. Presenting Herbrand Models with Linguistically Motivated Techniques. In Proc. of CIMCA-99, Vienna, Austria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Konrad</author>
<author>D Wolfram</author>
</authors>
<title>System Description: Kimba, A Model Generator for Many-Valued First-Order Logics.</title>
<date>1999</date>
<booktitle>In Proc. of the 16th International Conference on Automated Deduction (CADE16),</booktitle>
<pages>282--286</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="5546" citStr="Konrad and Wolfram, 1999" startWordPosition="752" endWordPosition="755">ts each, which amounts to 128 propositions if unaggregated. In Figure 1, the solution variants are referred to by numbers, as an extra slot. All propositions with the same value of this slot must be true at the same time, those with different values holding alternatively. To save space, variant numbers for the same fact are enclosed between &apos;&lt;&apos; and &apos;&gt;&apos;. 4 New Aggregation Constructs The solutions to this puzzle consist of highly regular assignments, which is typical for machinegenerated solutions to these kind of problems (consider, for example, solutions produced by the model generator KIMBA (Konrad and Wolfram, 1999), presented in (Horacek and Konrad, 1999)). For expressing these constellations concisely and elegantly in natural language, semantically complex operators, such as &apos;each&apos; and &apos;vice-versa&apos; prove useful. For generating these expressions, we define novel “2-dimensional” coordinations. Normally, coordination is done in a pairwise fashion. For the new constructs, aggregation is done by building the cross product of the values of two slots, including special forms of disjunctions for commonalities across variants (Choice, Except, and Assign): • The Permut construct It expresses a set of predication</context>
</contexts>
<marker>Konrad, Wolfram, 1999</marker>
<rawString>Konrad, K.; and Wolfram, D. 1999. System Description: Kimba, A Model Generator for Many-Valued First-Order Logics. In Proc. of the 16th International Conference on Automated Deduction (CADE16), pp. 282-286 Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Mann</author>
<author>J Moore</author>
</authors>
<title>Computer as Author – Results and Prospects.</title>
<date>1980</date>
<tech>Research Report ISI/ RR-79-82,</tech>
<institution>University of Southern California, Information Sciences Institute, Marina del Rey.</institution>
<contexts>
<context position="2434" citStr="Mann and Moore, 1980" startWordPosition="334" endWordPosition="337">n slot values concisely, including special forms of disjunctions. Among others, this method enables the generation of expressions with semantically complex operators and disambiguation markers, such as &apos;vice-versa&apos;, &apos;each&apos;, &apos;remaining&apos;, and &apos;distinct&apos;. The paper is organized as follows. First we review aggregation techniques. Then we define new aggregation constructs. We describe a procedure for building compositions of these constructs, including syntactic realization. Finally, we discuss the application potential of our approach. 2 Previous Approaches The term aggregation was first used in (Mann and Moore, 1980). It is relevant in all processing phases of NLG (Reape and Mellish, 1999). Its most common form, structural aggregation, concerns compositions of several logical assertions that share information into a single natural language utterance with coordinated or omitted parts, yielding conjunction reduction (“Foxes and wolves are animals”) and ellipsis or gapping (“Foxes are larger than birds and _ smaller than wolves”). Aggregation techniques have been incorporated in early systems, such as KDS (Mann and Moore, 1981). Aggregation manifests itself in optimizations carried out at the discourse level</context>
</contexts>
<marker>Mann, Moore, 1980</marker>
<rawString>Mann, B.; and Moore, J. 1980. Computer as Author – Results and Prospects. Research Report ISI/ RR-79-82, University of Southern California, Information Sciences Institute, Marina del Rey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Mann</author>
<author>J Moore</author>
</authors>
<date>1981</date>
<journal>Computer Generation of Multiparagraph English Text. American Journal of Computational Linguistics</journal>
<volume>8</volume>
<issue>2</issue>
<pages>17--29</pages>
<contexts>
<context position="2952" citStr="Mann and Moore, 1981" startWordPosition="412" endWordPosition="415">al of our approach. 2 Previous Approaches The term aggregation was first used in (Mann and Moore, 1980). It is relevant in all processing phases of NLG (Reape and Mellish, 1999). Its most common form, structural aggregation, concerns compositions of several logical assertions that share information into a single natural language utterance with coordinated or omitted parts, yielding conjunction reduction (“Foxes and wolves are animals”) and ellipsis or gapping (“Foxes are larger than birds and _ smaller than wolves”). Aggregation techniques have been incorporated in early systems, such as KDS (Mann and Moore, 1981). Aggregation manifests itself in optimizations carried out at the discourse level (Horacek, 1992) and domain specific orderings of propositions prior to condensation (Dalianis, 1999; Dalianis and Hovy, 1996). Coordination and lexical aggregation take place in sentence planning, emphasizing stylistic preference rules (Scott and de be(Pete,boxer,&lt;2,4,5,7,9-11,13-16&gt;) be(Steve,actor,&lt;3,5,13&gt;) be(Thelma,actor,&lt;4,8-10,15&gt;) be(Pete,guard,&lt;1,3,6,8,12,15,16&gt;) be(Steve,boxer,&lt;8,12&gt;) be(Thelma,boxer,&lt;1,3,6&gt;) be(Pete,operator,&lt;1-14&gt;) be(Steve,guard,&lt;9,14&gt;) be(Thelma,chef,&lt;1-16&gt;) be(Roberta,actor,&lt;1,2,6,</context>
</contexts>
<marker>Mann, Moore, 1981</marker>
<rawString>Mann, B.; and Moore, J. 1981. Computer Generation of Multiparagraph English Text. American Journal of Computational Linguistics 8(2), pp. 17-29.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Reape</author>
<author>C Mellish</author>
</authors>
<title>What is Aggregation Anyhow?</title>
<date>1999</date>
<booktitle>In Proc. of 7th European Workshop on Natural Language Generation,</booktitle>
<pages>20--29</pages>
<location>Toulouse, France.</location>
<contexts>
<context position="2508" citStr="Reape and Mellish, 1999" startWordPosition="347" endWordPosition="350"> others, this method enables the generation of expressions with semantically complex operators and disambiguation markers, such as &apos;vice-versa&apos;, &apos;each&apos;, &apos;remaining&apos;, and &apos;distinct&apos;. The paper is organized as follows. First we review aggregation techniques. Then we define new aggregation constructs. We describe a procedure for building compositions of these constructs, including syntactic realization. Finally, we discuss the application potential of our approach. 2 Previous Approaches The term aggregation was first used in (Mann and Moore, 1980). It is relevant in all processing phases of NLG (Reape and Mellish, 1999). Its most common form, structural aggregation, concerns compositions of several logical assertions that share information into a single natural language utterance with coordinated or omitted parts, yielding conjunction reduction (“Foxes and wolves are animals”) and ellipsis or gapping (“Foxes are larger than birds and _ smaller than wolves”). Aggregation techniques have been incorporated in early systems, such as KDS (Mann and Moore, 1981). Aggregation manifests itself in optimizations carried out at the discourse level (Horacek, 1992) and domain specific orderings of propositions prior to co</context>
</contexts>
<marker>Reape, Mellish, 1999</marker>
<rawString>Reape, M.; and Mellish, C. 1999. What is Aggregation Anyhow? In Proc. of 7th European Workshop on Natural Language Generation, pp. 20-29, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Robin</author>
</authors>
<title>Revision-Based Generation of Natural Language Summaries Providing Historical Background. PhD thesis,</title>
<date>1995</date>
<institution>Columbia University.</institution>
<contexts>
<context position="3991" citStr="Robin, 1995" startWordPosition="504" endWordPosition="505">ete,guard,&lt;1,3,6,8,12,15,16&gt;) be(Steve,boxer,&lt;8,12&gt;) be(Thelma,boxer,&lt;1,3,6&gt;) be(Pete,operator,&lt;1-14&gt;) be(Steve,guard,&lt;9,14&gt;) be(Thelma,chef,&lt;1-16&gt;) be(Roberta,actor,&lt;1,2,6,7,11,12,14,16&gt;) be(Steve,nurse,&lt;1-16&gt;) be(Thelma,guard,&lt;2,5,7&gt;) be(Roberta,guard,&lt;4,10,11,13&gt;) be(Steve,officer,&lt;6,7,10,11&gt;) be(Thelma,teacher,&lt;11-14,16&gt;) be(Roberta,officer,&lt;1-5,8,9,12-16&gt;) be(Steve,operator,&lt;15,16&gt;) be(Roberta,teacher,&lt;3,5-10,15&gt;) be(Steve,teacher,&lt;1,2,4&gt;) Figure 1. Solutions to the puzzle – alternatives in assigning persons to jobs Souza, 1990) and hypotactic aggregation with detailed lexical decisions (Robin, 1995). However, all these approaches operate on some local level. The only systematic approach, which has also inspired our method, is Shaw&apos;s staged process (1998a; 1998b), which separates heuristic orderings followed by recurrence markings from linguistically justified sentence boundary decisions and reduction operations. 3 The Running Example We present solutions to a puzzle: “There are four people: Roberta, Thelma, Steve, and Pete. Among them they hold eight different jobs, each exactly two. The jobs are: chef, guard, nurse, telephone operator, police officer, teacher, actor, and boxer. The job </context>
</contexts>
<marker>Robin, 1995</marker>
<rawString>Robin, J. 1995. Revision-Based Generation of Natural Language Summaries Providing Historical Background. PhD thesis, Columbia University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Scott</author>
<author>C de Souza</author>
</authors>
<title>Getting the Message Across in RST-Based Text Generation. In</title>
<date>1990</date>
<booktitle>Current Research in Natural Language Generation,</booktitle>
<pages>47--73</pages>
<editor>R. Dale, C. Mellish, M. Zock (eds.),</editor>
<publisher>Academic Press,</publisher>
<location>New York.</location>
<marker>Scott, de Souza, 1990</marker>
<rawString>Scott, D.; and de Souza C. 1990. Getting the Message Across in RST-Based Text Generation. In R. Dale, C. Mellish, M. Zock (eds.), Current Research in Natural Language Generation, pp. 47-73, Academic Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Shaw</author>
</authors>
<title>Segregatory Coordination and Ellipsis in Text Generation.</title>
<date>1998</date>
<booktitle>In Proc. of the 36th Association for Computational Linguistics and the 17th International Conference on Computational Linguistics,</booktitle>
<pages>1220--1226</pages>
<location>Montreal, Canada.</location>
<marker>Shaw, 1998</marker>
<rawString>Shaw, J. 1998a. Segregatory Coordination and Ellipsis in Text Generation. In Proc. of the 36th Association for Computational Linguistics and the 17th International Conference on Computational Linguistics, pp. 1220-1226, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Shaw</author>
</authors>
<title>Clause Aggregation Using Linguistic Knowledge.</title>
<date>1998</date>
<booktitle>In Proc. of the 9th International Workshop on Natural Language Generation,</booktitle>
<pages>18--147</pages>
<location>Niagara-on-the-lake, Canada.</location>
<marker>Shaw, 1998</marker>
<rawString>Shaw, J. 1998b. Clause Aggregation Using Linguistic Knowledge. In Proc. of the 9th International Workshop on Natural Language Generation, pp. 18-147, Niagara-on-the-lake, Canada.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>