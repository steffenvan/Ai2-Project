<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.051877">
<title confidence="0.975622">
Morphological Analysis and Disambiguation for Dialectal Arabic
</title>
<author confidence="0.999227">
Nizar Habash, Ryan Roth, Owen Rambow, Ramy Eskander, and Nadi Tomeh
</author>
<affiliation confidence="0.9976095">
Center for Computational Learning Systems
Columbia University
</affiliation>
<email confidence="0.998873">
{habash,ryanr,rambow,reskander,nadi}@ccls.columbia.edu
</email>
<sectionHeader confidence="0.993905" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999658">
The many differences between Dialectal Ara-
bic and Modern Standard Arabic (MSA) pose
a challenge to the majority of Arabic natural
language processing tools, which are designed
for MSA. In this paper, we retarget an exist-
ing state-of-the-art MSA morphological tag-
ger to Egyptian Arabic (ARZ). Our evalua-
tion demonstrates that our ARZ morphology
tagger outperforms its MSA variant on ARZ
input in terms of accuracy in part-of-speech
tagging, diacritization, lemmatization and to-
kenization; and in terms of utility for ARZ-to-
English statistical machine translation.
</bodyText>
<sectionHeader confidence="0.998795" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999948607142857">
Dialectal Arabic (DA) refers to the day-to-day na-
tive vernaculars spoken in the Arab World. DA
is used side by side with Modern Standard Arabic
(MSA), the official language of the media and edu-
cation (Holes, 2004). Although DAs are historically
related to MSA, there are many phonological, mor-
phological and lexical differences between them.
Unlike MSA, DAs have no standard orthographies
or language academies. Furthermore, different DAs,
such as Egyptian Arabic (henceforth, ARZ), Levan-
tine Arabic or Moroccan Arabic have important dif-
ferences among them, similar to those seen among
Romance languages (Holes, 2004; Abdel-Massih et
al., 1979). Most tools and resources developed for
natural language processing (NLP) of Arabic are de-
signed for MSA. Such resources are quite limited
when it comes to processing DA, e.g., a state-of-
the-art MSA morphological analyzer only has 60%
coverage of Levantine Arabic verb forms (Habash
and Rambow, 2006).
In this paper, we describe the process of retar-
geting an existing state-of-the-art tool for model-
ing MSA morphology disambiguation to ARZ, the
most commonly spoken DA. The MSA tool we
extend is MADA – Morphological Analysis and
Disambiguation of Arabic (Habash and Rambow,
2005). The approach used in MADA, which was
inspired by earlier work by Hajiˇc (2000), disam-
biguates in context for every aspect of Arabic mor-
phology, thus solving all tasks in “one fell swoop”.
The disadvantage of the MADA approach is its de-
pendence on two complex resources: a morpholog-
ical analyzer for the language and a large collection
of manually annotated words for all morphological
features in the same representation used by the an-
alyzer. For ARZ, such resources have recently be-
come available, with the development of the CAL-
IMA ARZ morphological analyzer (Habash et al.,
2012b) and the release by the Linguistic Data Con-
sortium (LDC) of a large ARZ corpus annotated
morphologically in a manner compatible with CAL-
IMA (Maamouri et al., 2012a). In the work pre-
sented here, we utilize these new resources within
the paradigm of MADA, transforming MADA into
MADA-ARZ. The elegance of the MADA solution
makes this conceptually a simple extension.
Our evaluation demonstrates that our Egyptian
DA version of MADA, henceforth MADA-ARZ,
outperforms MADA for MSA on ARZ morpholog-
ical tagging and improves the quality of ARZ to En-
glish statistical machine translation (MT).
The rest of this paper is structured as follows:
Section 2 discusses related work. Section 3 presents
the challenges of processing Arabic dialects. Sec-
tion 4 outlines our approach. And Section 5 presents
and discusses our evaluation results.
</bodyText>
<page confidence="0.987148">
426
</page>
<note confidence="0.512004">
Proceedings of NAACL-HLT 2013, pages 426–432,
Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.999237" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9999">
There has been a considerable amount of work on
MSA morphological analysis, disambiguation, part-
of-speech (POS) tagging, tokenization, lemmatiza-
tion and diacritization; for an overview, see (Habash,
2010). Most solutions target specific problems, such
as diacritization (Zitouni et al., 2006), tokenization
or POS tagging (Diab et al., 2007). In contrast,
MADA provides a solution to all of these problems
together (Habash and Rambow, 2005).
Previous work on DA morphological tagging fo-
cused on creating resources, using noisy or in-
complete annotations, and using unsupervised/semi-
supervised methods. Duh and Kirchhoff (2005)
adopt a minimally supervised approach that only re-
quires raw text data from several DAs, as well as a
MSA morphological analyzer. They report a POS
accuracy of 70.9% on a rather coarse-grained POS
tagset (17 tags).
Al-Sabbagh and Girju (2012) describe a super-
vised tagger for Egyptian Arabic social networking
corpora trained using transformation-based learning
(Brill, 1995). They report 94.5% F-measure on to-
kenization and 87.6% on POS tagging. Their tok-
enization and POS tagsets are comparable to the set
used by the Arabic Treebank (ATB). We do not com-
pare to them since their data sets are not public.
Stallard et al. (2012) show that unsupervised
methods for learning DA tokenization can outper-
form MSA tokenizers on MT from Levantine Ara-
bic to English. We do not compare to them directly
since our work is on ARZ. However, we carry a sim-
ilar MT experiment in Section 5.
Mohamed et al. (2012) annotated a small corpus
of Egyptian Arabic for morphological segmentation
and learned segmentation models using memory-
based learning (Daelemans and van den Bosch,
2005). Their best system achieves a 91.90% accu-
racy on the task of morpheme-segmentation. We
compare to their work and report on their test set
in Section 5.
There are some other morphological analyzers for
DA. Kilany et al. (2002) worked on ARZ, but the
analyzer has very limited coverage. Their lexicon
was used as part of the development of CALIMA
(Habash et al., 2012b). Other efforts are not about
ARZ (Habash and Rambow, 2006; Salloum and
Habash, 2011).
Given the similarity between MSA and DA, there
has been some work on mapping DA to MSA to
exploit rich MSA resources (Chiang et al., 2006;
Abo Bakr et al., 2008; Salloum and Habash, 2011;
Salloum and Habash, 2013). Other researchers have
studied the value of simply combining DA and
MSA data, such as Zbib et al. (2012) for DA to En-
glish MT. In our approach, we target DA directly,
and we evaluate the use of additional MSA anno-
tated resources to our training in Section 5.
</bodyText>
<sectionHeader confidence="0.99624" genericHeader="method">
3 Arabic Dialect Challenges
</sectionHeader>
<bodyText confidence="0.94346903125">
General Arabic Challenges Arabic, as MSA or
DA, poses many challenges for NLP. Arabic is a
morphologically complex language which includes
rich inflectional morphology and a number of cli-
tics. For example, the MSA word Aî:ñJ.:ºJ�ƒð wsyk-
tbwnhA (wa+sa+ya-ktub-uwna+hA)1 ‘and they will
write it [lit. and+will+they-write-they+it]’ has two
proclitics, one circumfix and one pronominal en-
clitic. Additionally, Arabic has a high degree of
ambiguity resulting from its diacritic-optional writ-
ing system and common deviation from spelling
standards (e.g., Alif and Ya variants) (Buckwalter,
2007). The Standard Arabic Morphological Ana-
lyzer for (SAMA) (Graff et al., 2009) produces 12
analyses per MSA word on average.
Differences between ARZ and MSA As men-
tioned above, most tools developed for MSA cannot
be expected to perform well on ARZ. This is due
to the numerous differences between the two vari-
ants. Lexically, the number of differences is quite
significant. For example, ARZ S �uQ£ Trbyzh ‘table’
corresponds to MSA aËðA£ TAwlh. Phonologically,
there are many important differences which relate
to orthography in DA, e.g., the MSA consonant H~
/B/ is pronounced as /t/ in ARZ (or /s/ in more re-
cent borrowings from MSA); for a fuller discussion,
see (Habash, 2010; Habash et al., 2012a). Examples
of morphological differences include changes in the
1Arabic transliteration is presented in the Habash-Soudi-
Buckwalter scheme (Habash et al., 2007): (in alphabetical or-
der) Abt0jHxdðrzsšSDT ˇDS-yfqklmnhwy and the additional sym-
bols: ’ Z, Â 1, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø.
</bodyText>
<page confidence="0.994246">
427
</page>
<bodyText confidence="0.998753045454545">
morpheme form, e.g., the MSA future proclitic +v
sa+ appears in ARZ as +A ha+. There are some
morphemes in ARZ that do not exist in MSA such
as the negation circum-clitic v:+ ... +La mA+ ... +š.
And there are MSA features that are absent from
ARZ, most notably case and mood.
Since there are no orthographic standards, ARZ
words may be written in a variety of ways reflect-
ing different writing rules, e.g., phonologically or
etymologically. A conventional orthography for Di-
alectal Arabic (CODA) has been proposed and used
for writing ARZ in the context of NLP applications
(Habash et al., 2012a; Al-Sabbagh and Girju, 2012;
Eskander et al., 2013). Finally, MSA and ARZ co-
exist and are often used interchangeably, especially
in more formal settings. The CALIMA morpholog-
ical analyzer we use addresses several of these issues
by modeling both ARZ and MSA together, includ-
ing a limited set of inter-dialect morphology phe-
nomena, and by mapping ARZ words into CODA
orthography internally while accepting a wide range
of spelling variants.
</bodyText>
<sectionHeader confidence="0.999081" genericHeader="method">
4 Approach
</sectionHeader>
<subsectionHeader confidence="0.997986">
4.1 The MADA Approach
</subsectionHeader>
<bodyText confidence="0.999986117647059">
MADA is a method for Arabic morphological anal-
ysis and disambiguation (Habash and Rambow,
2005; Roth et al., 2008). MADA uses a morpholog-
ical analyzer to produce, for each input word, a list
of analyses specifying every possible morphological
interpretation of that word, covering all morphologi-
cal features of the word (diacritization, POS, lemma,
and 13 inflectional and clitic features). MADA then
applies a set of models (support vector machines
and N-gram language models) to produce a predic-
tion, per word in-context, for different morpholog-
ical features, such as POS, lemma, gender, number
or person. A ranking component scores the analy-
ses produced by the morphological analyzer using a
tuned weighted sum of matches with the predicted
features. The top-scoring analysis is chosen as the
predicted interpretation for that word in context.
</bodyText>
<subsectionHeader confidence="0.958544">
4.2 Extending MADA into MADA-ARZ
</subsectionHeader>
<bodyText confidence="0.999924945945946">
Adjusting MADA to handle DA requires a number
of modifications. The most significant change is re-
placing the MSA analyzer SAMA with the ARZ
analyzer CALIMA to address the differences out-
lined in Section 3. In addition, new feature predic-
tion models are needed; these are trained using ARZ
data sets annotated by the LDC (Maamouri et al.,
2006; Maamouri et al., 2012b). The data sets were
not usable as released due to numerous annotation
inconsistencies and differences from CALIMA, as
well due to gaps in CALIMA. We synchronized the
annotations with the latest version of CALIMA fol-
lowing a technique described by Habash and Ram-
bow (2005). The result of this synchronization step
is the data we use in this study (for training, de-
velopment and testing). Our synchronized annota-
tions fully match the LDC annotations in 90% of the
words (in full morphological tag). We performed a
manual analysis on randomly chosen 100 words that
did not fully match. The choice we made is cor-
rect or acceptable in 55% of the cases of mismatch
with the LDC annotation, which means that the our
choice is accurate in over 95% of all cases.
Some of the original MADA features (which
were needed for MSA) are not used in ARZ and
so are dropped in MADA-ARZ; these features are
case, mood, the question-marking proclitic, state
and voice. Additional ARZ feature values have been
added, e.g., to handle the progressive particle and
future marker, among others. These are provided
by CALIMA and are classified and selected by
MADA-ARZ. In our current implementation, ARZ
features that are not present in MSA, such as the
negation and indirect-object enclitics, are not classi-
fied by MADA-ARZ classifiers, but since they are
provided by CALIMA they can be selected by the
whole MADA-ARZ system.
</bodyText>
<sectionHeader confidence="0.998651" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999903333333333">
We evaluate MADA-ARZ intrinsically — in terms
of performance on morphological disambiguation
— and extrinsically in the context of MT.
</bodyText>
<sectionHeader confidence="0.898705" genericHeader="method">
5.1 POS Tagging, Diacritization,
Lemmatization and Segmentation
</sectionHeader>
<bodyText confidence="0.978488">
Experimental Settings We use two sets of anno-
tated data from the LDC: ATB-123, which includes
parts 1, 2 and 3 of the MSA Penn Arabic Treebank
</bodyText>
<page confidence="0.988273">
428
</page>
<table confidence="0.9998308">
Train Data MADA Development MADA Test
MSA MADA-ARZ MSA MADA-ARZ
ARZ ALL ARZ ALL
Morph Tag 35.8 84.0 77.3 35.7 84.5 75.5
Penn POS 77.5 89.6 90.2 79.0 90.0 90.1
MADA POS 80.7 90.8 91.3 82.1 91.1 91.4
Diacritic 31.3 82.6 72.9 32.2 83.2 72.2
Lemma 64.0 85.2 81.6 67.1 86.3 82.8
Full 26.2 74.3 65.4 27.0 75.4 64.7
ATB Segmentation 90.6 97.4 97.6 90.5 97.4 97.5
</table>
<tableCaption confidence="0.995290333333333">
Table 1: Evaluation metrics on the ATB-ARZ development and test sets. The best results are bolded. We compare
MADA and MADA-ARZ with different training data conditions. Definitions of metrics are in Section 5.1. MSA
training data is ATB-123. ARZ training data is ATB-ARZ. ALL training data is ATB-123 plus ATB-ARZ.
</tableCaption>
<bodyText confidence="0.998199433333334">
(Maamouri et al., 2004); and ATB-ARZ, the Egyp-
tian Arabic Treebank (parts 1-5) (Maamouri et al.,
2012a). For ATB-123 training, we use all of parts 1
and 2 plus the training portion of ATB-3 (as defined
by Zitouni et al. (2006)); for development and test,
we split Zitouni et al. (2006)’s devtest set into two.
We sub-divide ATB-ARZ into development, train-
ing, and test sets (roughly a 10/80/10 split). The
ATB-ARZ training data has 134K words, and the
ATB-123 training data has 711K words.
We evaluate two systems. We used the latest re-
lease of MADA for MSA (v3.2), trained on ATB-
123 (MSA), as our baseline. For MADA-ARZ,
we compare two training settings: using ATB-ARZ
(ARZ) and combining ATB-ARZ with ATB-123
(ALL). We present our results on the ATB-ARZ
development and blind test sets (21.1K words and
20.4K words). Tuning for MADA-ARZ was done
using a random 10% of the ATB-ARZ training data,
which was later integrated back into the training set.
Metrics We use several evaluation metrics to mea-
sure the effectiveness of MADA-ARZ. Morph Tag
refers to the accuracy of correctly predicting the full
CALIMA morphological tag (i.e., not the diacritics
or the lemma). Penn POS and MADA POS are also
tag accuracy metrics. Penn POS, also known as the
Reduced Tag Set, is a tag set reduction of the full
Arabic morphological tag set, which was proposed
for MSA (Kulick et al., 2006; Diab, 2007; Habash,
2010); since it retains no MSA-specific morpholog-
ical features, it also makes sense for ARZ. MADA
POS is the small POS tag set (36 tags) MADA uses
internally. Diacritic and Lemma are the accura-
cies of the choice of diacritized form and Lemma,
respectively. Full is the harshest metric, requiring
that every morphological feature of the chosen anal-
ysis be correct. Finally, ATB Segmentation is the
percentage of words with correct ATB segmentation
(splitting off all clitics except for the determiner +JI
Al+).
Results The results are shown in Table 1.
MADA-ARZ performs much better than the
MADA baselines in all evaluation metrics. Compar-
ing the two MADA-ARZ systems, it is evident that
adding MSA data (ATB123) results in slightly better
performance only for the Penn POS, MADA POS,
and ATB Segmentation metrics. Including the MSA
data results in accuracy reductions for the other met-
rics, but the resulting system still outperforms the
MADA MSA baseline in all cases. The results are
consistent for development and blind test.
The CMUQ-ECA Test Set Mohamed et al.
(2012) reported on the task of ARZ raw orthogra-
phy morph segmentation (determining the morphs
in the raw word). The CMUQ-ECA test data
comprised 36 ARZ political comments and jokes
from the Egyptian web site www.masrawy.com.
The set contains 2,445 words including punctua-
tion. Their best system gets a 91.9% word-level ac-
curacy. Since MADA-ARZ modifies the spelling
</bodyText>
<table confidence="0.999571">
Tokenization OOV BLEU METEOR TER
Punct 9.2 22.1 27.2 63.2
MADA ATB 5.8 24.4 29.6 60.5
MADA-ARZ ATB 4.9 25.2 29.9 59.4
</table>
<tableCaption confidence="0.999083">
Table 2: Machine translation results on the test set. “Punct” refers to the baseline which only tokenizes at punctuation.
</tableCaption>
<bodyText confidence="0.9853572">
of the word when it maps into CODA, we needed
a manual analysis where no exact match with the
gold occurs (11.8% of the time). We determined
MADA-ARZ’s accuracy on their test set for morph-
segmentation to be 93.2%.
</bodyText>
<subsectionHeader confidence="0.984782">
5.2 Egyptian Arabic to English MT
</subsectionHeader>
<bodyText confidence="0.99961856">
MT Experimental Settings We use the open-
source Moses toolkit (Koehn et al., 2007) to build
a phrase-based SMT system. We use MGIZA++
for word alignment (Gao and Vogel, 2008). Phrase
translations of up to 8 words are extracted in the
phrase table. We use SRILM (Stolcke, 2002) with
modified Kneser-Ney smoothing to build two 4-
gram language models. The first model is trained
on the English side of the bitext, while the other
is trained on the English Gigaword data. Feature
weights are tuned to maximize BLEU (Papineni et
al., 2002) on a development set using Minimum Er-
ror Rate Training (Och, 2003). We perform case-
insensitive evaluation in terms of BLEU, METEOR
(Banerjee and Lavie, 2005) and TER (Snover et al.,
2006) metrics.
Data We trained on DA-English parallel data
(Egyptian and Levantine) obtained from several
LDC corpora. The training data amounts to 3.8M
untokenized words on the Arabic side. The dev set,
used for tuning the parameters of the MT system,
has 15,585 untokenized Arabic words. The test set
has 12,116 untokenized Arabic words. Both dev and
test data contain two sets of reference translations.
The English data is lower-cased and tokenized using
simple punctuation-based rules.
Systems We build three translation systems which
vary in tokenization of the Arabic text. The first
system applies only simple punctuation-based rules.
The second and third systems use MADA and
MADA-ARZ, respectively, to tokenize the Arabic
text in the ATB tokenization scheme (Habash and
Sadat, 2006). The Arabic text is also Alif/Ya nor-
malized.
Results The MT results are in Table 2, which also
shows the percentage of out-of-vocabulary (OOV)
words – test words not in the training data. MADA-
ARZ delivers the best translation performance ac-
cording to all metrics. All MADA-ARZ improve-
ments over MADA are statistically significant at
the .01 level (except in the case of METEOR). All
improvements over Punct by MADA and MADA-
ARZ are also statistically significant. For BLEU
scores, we observe 3.1% absolute improvement to
Punct (14% relative), and 0.8% absolute improve-
ment to MADA (3.3% relative). In addition to bet-
ter morphological disambiguation, MADA-ARZ
reduces the OOV ratio (16% relative to MADA),
which we suspect contributes to the observed im-
provements in MT quality.
</bodyText>
<sectionHeader confidence="0.983915" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.9999125">
We have presented MADA-ARZ, a system for
morphological tagging of ARZ. We have shown
that it outperforms an state-of-the-art MSA tagger
(MADA) on ARZ text, and that it helps ARZ-to-
English machine translation more than MADA.
In the future, we intend to perform further feature
engineering to improve the results of MADA-ARZ,
and extend the system to handle other DAs.
</bodyText>
<sectionHeader confidence="0.989779" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.997848142857143">
This paper is based upon work supported by
the Defense Advanced Research Projects Agency
(DARPA) under Contract No. HR0011-12-C-0014.
Any opinions, findings and conclusions or recom-
mendations expressed in this paper are those of the
authors and do not necessarily reflect the views of
DARPA.
</bodyText>
<page confidence="0.997679">
430
</page>
<sectionHeader confidence="0.913056" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.973164179245283">
Ernest T. Abdel-Massih, Zaki N. Abdel-Malek, and El-
Said M. Badawi. 1979. A Reference Grammar of
Egyptian Arabic. Georgetown University Press.
Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan.
2008. A Hybrid Approach for Converting Written
Egyptian Colloquial Dialect into Diacritized Arabic.
In The 6th International Conference on Informatics
and Systems, INFOS2008. Cairo University.
Rania Al-Sabbagh and Roxana Girju. 2012. A super-
vised POS tagger for written Arabic social network-
ing corpora. In Jeremy Jancsary, editor, Proceedings
of KONVENS 2012, pages 39–52. ÖGAI, September.
Main track: oral presentations.
Satanjeev Banerjee and Alon Lavie. 2005. METEOR:
An Automatic Metric for MT Evaluation with Im-
proved Correlation with Human Judgments. In Pro-
ceedings of the ACL Workshop on Intrinsic and Ex-
trinsic Evaluation Measures for Machine Transla-
tion and/or Summarization, pages 65–72, Ann Arbor,
Michigan.
Eric Brill. 1995. Transformation-Based Error-Driven
Learning and Natural Language Processing: A Case
Study in Part-of-Speech Tagging. Computational Lin-
guistics, 21(4):543–565.
Tim Buckwalter. 2007. Issues in Arabic Morphologi-
cal Analysis. In A. van den Bosch and A. Soudi, edi-
tors, Arabic Computational Morphology: Knowledge-
based and Empirical Methods. Springer.
David Chiang, Mona Diab, Nizar Habash, Owen Ram-
bow, and Safiullah Shareef. 2006. Parsing Arabic
Dialects. In Proceedings of the European Chapter of
ACL (EACL).
Walter Daelemans and Antal van den Bosch. 2005.
Memory-Based Language Processing. Studies in
Natural Language Processing. Cambridge University
Press, Cambridge, UK.
Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2007.
Automated methods for processing arabic text: From
tokenization to base phrase chunking. In Antal
van den Bosch and Abdelhadi Soudi, editors, Arabic
Computational Morphology: Knowledge-based and
Empirical Methods. Kluwer/Springer.
Mona Diab. 2007. Improved Arabic Base Phrase Chunk-
ing with a New Enriched POS Tag Set. In Proceedings
of the 2007 Workshop on Computational Approaches
to Semitic Languages: Common Issues and Resources,
pages 89–96, Prague, Czech Republic, June.
Kevin Duh and Katrin Kirchhoff. 2005. POS tagging of
dialectal Arabic: a minimally supervised approach. In
Proceedings of the ACL Workshop on Computational
Approaches to Semitic Languages, Semitic ’05, pages
55–62, Ann Arbor, Michigan.
Ramy Eskander, Nizar Habash, Owen Rambow, and Nadi
Tomeh. 2013. Processing Spontaneous Orthogra-
phy. In Proceedings of the 2013 Conference of the
North American Chapter of the Association for Com-
putational Linguistics: Human Language Technolo-
gies (NAACL-HLT), Atlanta, GA.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, SETQA-NLP ’08, pages 49–57,
Stroudsburg, PA, USA. Association for Computational
Linguistics.
David Graff, Mohamed Maamouri, Basma Bouziri,
Sondos Krouna, Seth Kulick, and Tim Buckwal-
ter. 2009. Standard Arabic Morphological Analyzer
(SAMA) Version 3.1. Linguistic Data Consortium
LDC2009E73.
Nizar Habash and Owen Rambow. 2005. Arabic Tok-
enization, Part-of-Speech Tagging and Morphological
Disambiguation in One Fell Swoop. In Proceedings of
the 43rd Annual Meeting of the Association for Com-
putational Linguistics (ACL’05), pages 573–580, Ann
Arbor, Michigan.
Nizar Habash and Owen Rambow. 2006. MAGEAD:
A Morphological Analyzer and Generator for the Ara-
bic Dialects. In Proceedings of the 21st International
Conference on Computational Linguistics and 44th
Annual Meeting of the Association for Computational
Linguistics, pages 681–688, Sydney, Australia.
Nizar Habash and Fatiha Sadat. 2006. Arabic Prepro-
cessing Schemes for Statistical Machine Translation.
In Proceedings of the 7th Meeting of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics/Human Language Technologies Conference
(HLT-NAACL06), pages 49–52, New York, NY.
Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter.
2007. On Arabic Transliteration. In A. van den Bosch
and A. Soudi, editors, Arabic Computational Mor-
phology: Knowledge-based and Empirical Methods.
Springer.
Nizar Habash, Mona Diab, and Owen Rabmow. 2012a.
Conventional Orthography for Dialectal Arabic. In
Proceedings of the Language Resources and Evalua-
tion Conference (LREC), Istanbul.
Nizar Habash, Ramy Eskander, and Abdelati Hawwari.
2012b. A Morphological Analyzer for Egyptian
Arabic. In NAACL-HLT 2012 Workshop on Com-
putational Morphology and Phonology (SIGMOR-
PHON2012), pages 1–9.
Nizar Habash. 2010. Introduction to Arabic Natural
Language Processing. Morgan &amp; Claypool Publish-
ers.
Jan Hajiˇc. 2000. Morphological tagging: Data vs. dic-
tionaries. In Proceedings of the 1st Meeting of the
</reference>
<page confidence="0.993829">
431
</page>
<reference confidence="0.998664794392523">
North American Chapter of the Association for Com-
putational Linguistics (NAACL’00), Seattle, WA.
Clive Holes. 2004. Modern Arabic: Structures, Func-
tions, and Varieties. Georgetown Classics in Ara-
bic Language and Linguistics. Georgetown University
Press.
H. Kilany, H. Gadalla, H. Arram, A. Yacoub, A. El-
Habashi, and C. McLemore. 2002. Egyptian
Colloquial Arabic Lexicon. LDC catalog number
LDC99L22.
Philipp Koehn, Hieu Hoang, Alexandra Birch, Christo-
pher Callison-Burch, Marcello Federico, Nicola
Bertoldi, Brooke Cowan, Wade Shen, Christine
Moran, Richard Zens, Christopher Dyer, Ondrej Bo-
jar, Alexandra Constantin, and Evan Herbst. 2007.
Moses: open source toolkit for statistical machine
translation. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguistics
Companion Volume Proceedings of the Demo and
Poster Sessions, pages 177–180, Prague, Czech Re-
public.
Seth Kulick, Ryan Gabbard, and Mitch Marcus. 2006.
Parsing the Arabic Treebank: Analysis and Improve-
ments. In Proceedings of the Treebanks and Linguis-
tic Theories Conference, pages 31–42, Prague, Czech
Republic.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, and
Wigdan Mekki. 2004. The Penn Arabic Treebank :
Building a Large-Scale Annotated Arabic Corpus. In
NEMLAR Conference on Arabic Language Resources
and Tools, pages 102–109, Cairo, Egypt.
Mohamed Maamouri, Ann Bies, Tim Buckwalter, Mona
Diab, Nizar Habash, Owen Rambow, and Dalila
Tabessi. 2006. Developing and Using a Pilot Dialec-
tal Arabic Treebank. In The fifth international confer-
ence on Language Resources and Evaluation (LREC),
pages 443–448, Genoa, Italy.
Mohamed Maamouri, Ann Bies, Seth Kulick, Dalila
Tabessi, and Sondos Krouna. 2012a. Egyptian Ara-
bic Treebank Pilot.
Mohamed Maamouri, Sondos Krouna, Dalila Tabessi,
Nadia Hamrouni, and Nizar Habash. 2012b. Egyptian
Arabic Morphological Annotation Guidelines.
Emad Mohamed, Behrang Mohit, and Kemal Oflazer.
2012. Annotating and Learning Morphological Seg-
mentation of Egyptian Colloquial Arabic. In Proceed-
ings of the Language Resources and Evaluation Con-
ference (LREC), Istanbul.
Franz Josef Och. 2003. Minimum Error Rate Training
for Statistical Machine Translation. In Proceedings
of the 41st Annual Conference of the Association for
Computational Linguistics, pages 160–167, Sapporo,
Japan.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a Method for Automatic Eval-
uation of Machine Translation. In Proceedings of the
40th Annual Meeting of the Association for Computa-
tional Linguistics, pages 311–318, Philadelphia, PA.
Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab,
and Cynthia Rudin. 2008. Arabic morphological tag-
ging, diacritization, and lemmatization using lexeme
models and feature ranking. In ACL 2008: The Con-
ference of the Association for Computational Linguis-
tics; Companion Volume, Short Papers, Columbus,
Ohio.
Wael Salloum and Nizar Habash. 2011. Dialectal
to Standard Arabic Paraphrasing to Improve Arabic-
English Statistical Machine Translation. In Proceed-
ings of the First Workshop on Algorithms and Re-
sources for Modelling of Dialects and Language Va-
rieties, pages 10–21, Edinburgh, Scotland.
Wael Salloum and Nizar Habash. 2013. Dialectal Ara-
bic to English Machine Translation: Pivoting through
Modern Standard Arabic. In Proceedings of the 2013
Conference of the North American Chapter of the As-
sociation for Computational Linguistics: Human Lan-
guage Technologies (NAACL-HLT), Atlanta, GA.
Matt Snover, Bonnie J. Dorr, Richard Schwartz, Lin-
nea Micciulla, and John Makhoul. 2006. A Study
of Translation Error Rate with Targeted Human An-
notation. In Proceedings of the Association for Ma-
chine Transaltion in the Americas (AMTA 2006), Cam-
bridge, Massachusetts.
David Stallard, Jacob Devlin, Michael Kayser,
Yoong Keok Lee, and Regina Barzilay. 2012.
Unsupervised Morphology Rivals Supervised Mor-
phology for Arabic MT. In Proceedings of the 50th
Annual Meeting of the Association for Computational
Linguistics, pages 322–327, Jeju Island, Korea.
Andreas Stolcke. 2002. SRILM - an Extensible Lan-
guage Modeling Toolkit. In Proceedings of the Inter-
national Conference on Spoken Language Processing
(ICSLP), volume 2, pages 901–904, Denver, CO.
Rabih Zbib, Erika Malchiodi, Jacob Devlin, David
Stallard, Spyros Matsoukas, Richard Schwartz, John
Makhoul, Omar F. Zaidan, and Chris Callison-Burch.
2012. Machine translation of arabic dialects. In Pro-
ceedings of the 2012 Conference of the North Ameri-
can Chapter of the Association for Computational Lin-
guistics: Human Language Technologies, pages 49–
59, Montréal, Canada.
Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya.
2006. Maximum entropy based restoration of ara-
bic diacritics. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Computa-
tional Linguistics, pages 577–584, Sydney, Australia.
</reference>
<page confidence="0.998538">
432
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.536222">
<title confidence="0.988392">Morphological Analysis and Disambiguation for Dialectal Arabic</title>
<author confidence="0.942767">Nizar Habash</author>
<author confidence="0.942767">Ryan Roth</author>
<author confidence="0.942767">Owen Rambow</author>
<author confidence="0.942767">Ramy Eskander</author>
<author confidence="0.942767">Nadi</author>
<affiliation confidence="0.8126685">Center for Computational Learning Columbia</affiliation>
<email confidence="0.999833">habash@ccls.columbia.edu</email>
<email confidence="0.999833">ryanr@ccls.columbia.edu</email>
<email confidence="0.999833">rambow@ccls.columbia.edu</email>
<email confidence="0.999833">reskander@ccls.columbia.edu</email>
<email confidence="0.999833">nadi@ccls.columbia.edu</email>
<abstract confidence="0.993304928571428">The many differences between Dialectal Arabic and Modern Standard Arabic (MSA) pose a challenge to the majority of Arabic natural language processing tools, which are designed for MSA. In this paper, we retarget an existing state-of-the-art MSA morphological tagger to Egyptian Arabic (ARZ). Our evaluation demonstrates that our ARZ morphology tagger outperforms its MSA variant on ARZ input in terms of accuracy in part-of-speech tagging, diacritization, lemmatization and tokenization; and in terms of utility for ARZ-to- English statistical machine translation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ernest T Abdel-Massih</author>
<author>Zaki N Abdel-Malek</author>
<author>ElSaid M Badawi</author>
</authors>
<title>A Reference Grammar of Egyptian Arabic.</title>
<date>1979</date>
<publisher>Georgetown University Press.</publisher>
<contexts>
<context position="1479" citStr="Abdel-Massih et al., 1979" startWordPosition="209" endWordPosition="212">DA) refers to the day-to-day native vernaculars spoken in the Arab World. DA is used side by side with Modern Standard Arabic (MSA), the official language of the media and education (Holes, 2004). Although DAs are historically related to MSA, there are many phonological, morphological and lexical differences between them. Unlike MSA, DAs have no standard orthographies or language academies. Furthermore, different DAs, such as Egyptian Arabic (henceforth, ARZ), Levantine Arabic or Moroccan Arabic have important differences among them, similar to those seen among Romance languages (Holes, 2004; Abdel-Massih et al., 1979). Most tools and resources developed for natural language processing (NLP) of Arabic are designed for MSA. Such resources are quite limited when it comes to processing DA, e.g., a state-ofthe-art MSA morphological analyzer only has 60% coverage of Levantine Arabic verb forms (Habash and Rambow, 2006). In this paper, we describe the process of retargeting an existing state-of-the-art tool for modeling MSA morphology disambiguation to ARZ, the most commonly spoken DA. The MSA tool we extend is MADA – Morphological Analysis and Disambiguation of Arabic (Habash and Rambow, 2005). The approach used</context>
</contexts>
<marker>Abdel-Massih, Abdel-Malek, Badawi, 1979</marker>
<rawString>Ernest T. Abdel-Massih, Zaki N. Abdel-Malek, and ElSaid M. Badawi. 1979. A Reference Grammar of Egyptian Arabic. Georgetown University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hitham Abo Bakr</author>
<author>Khaled Shaalan</author>
<author>Ibrahim Ziedan</author>
</authors>
<title>A Hybrid Approach for Converting Written Egyptian Colloquial Dialect into Diacritized Arabic.</title>
<date>2008</date>
<booktitle>In The 6th International Conference on Informatics and Systems, INFOS2008.</booktitle>
<institution>Cairo University.</institution>
<contexts>
<context position="5931" citStr="Bakr et al., 2008" startWordPosition="929" endWordPosition="932">5). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA directly, and we evaluate the use of additional MSA annotated resources to our training in Section 5. 3 Arabic Dialect Challenges General Arabic Challenges Arabic, as MSA or DA, poses many challenges for NLP. Arabic is a morphologically complex language which includes rich inflectional morphology and a number of clitics. For example, the MSA word Aî:ñJ.:ºJ�ƒð wsyktbwnhA (wa+sa+ya-ktub-</context>
</contexts>
<marker>Bakr, Shaalan, Ziedan, 2008</marker>
<rawString>Hitham Abo Bakr, Khaled Shaalan, and Ibrahim Ziedan. 2008. A Hybrid Approach for Converting Written Egyptian Colloquial Dialect into Diacritized Arabic. In The 6th International Conference on Informatics and Systems, INFOS2008. Cairo University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rania Al-Sabbagh</author>
<author>Roxana Girju</author>
</authors>
<title>A supervised POS tagger for written Arabic social networking corpora.</title>
<date>2012</date>
<booktitle>Proceedings of KONVENS 2012,</booktitle>
<pages>39--52</pages>
<editor>In Jeremy Jancsary, editor,</editor>
<contexts>
<context position="4490" citStr="Al-Sabbagh and Girju (2012)" startWordPosition="683" endWordPosition="686">lems, such as diacritization (Zitouni et al., 2006), tokenization or POS tagging (Diab et al., 2007). In contrast, MADA provides a solution to all of these problems together (Habash and Rambow, 2005). Previous work on DA morphological tagging focused on creating resources, using noisy or incomplete annotations, and using unsupervised/semisupervised methods. Duh and Kirchhoff (2005) adopt a minimally supervised approach that only requires raw text data from several DAs, as well as a MSA morphological analyzer. They report a POS accuracy of 70.9% on a rather coarse-grained POS tagset (17 tags). Al-Sabbagh and Girju (2012) describe a supervised tagger for Egyptian Arabic social networking corpora trained using transformation-based learning (Brill, 1995). They report 94.5% F-measure on tokenization and 87.6% on POS tagging. Their tokenization and POS tagsets are comparable to the set used by the Arabic Treebank (ATB). We do not compare to them since their data sets are not public. Stallard et al. (2012) show that unsupervised methods for learning DA tokenization can outperform MSA tokenizers on MT from Levantine Arabic to English. We do not compare to them directly since our work is on ARZ. However, we carry a s</context>
<context position="8478" citStr="Al-Sabbagh and Girju, 2012" startWordPosition="1348" endWordPosition="1351">27 morpheme form, e.g., the MSA future proclitic +v sa+ appears in ARZ as +A ha+. There are some morphemes in ARZ that do not exist in MSA such as the negation circum-clitic v:+ ... +La mA+ ... +š. And there are MSA features that are absent from ARZ, most notably case and mood. Since there are no orthographic standards, ARZ words may be written in a variety of ways reflecting different writing rules, e.g., phonologically or etymologically. A conventional orthography for Dialectal Arabic (CODA) has been proposed and used for writing ARZ in the context of NLP applications (Habash et al., 2012a; Al-Sabbagh and Girju, 2012; Eskander et al., 2013). Finally, MSA and ARZ coexist and are often used interchangeably, especially in more formal settings. The CALIMA morphological analyzer we use addresses several of these issues by modeling both ARZ and MSA together, including a limited set of inter-dialect morphology phenomena, and by mapping ARZ words into CODA orthography internally while accepting a wide range of spelling variants. 4 Approach 4.1 The MADA Approach MADA is a method for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Roth et al., 2008). MADA uses a morphological analyzer to </context>
</contexts>
<marker>Al-Sabbagh, Girju, 2012</marker>
<rawString>Rania Al-Sabbagh and Roxana Girju. 2012. A supervised POS tagger for written Arabic social networking corpora. In Jeremy Jancsary, editor, Proceedings of KONVENS 2012, pages 39–52. ÖGAI, September. Main track: oral presentations.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satanjeev Banerjee</author>
<author>Alon Lavie</author>
</authors>
<title>METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization,</booktitle>
<pages>65--72</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="16617" citStr="Banerjee and Lavie, 2005" startWordPosition="2708" endWordPosition="2711"> et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4- gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using Minimum Error Rate Training (Och, 2003). We perform caseinsensitive evaluation in terms of BLEU, METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006) metrics. Data We trained on DA-English parallel data (Egyptian and Levantine) obtained from several LDC corpora. The training data amounts to 3.8M untokenized words on the Arabic side. The dev set, used for tuning the parameters of the MT system, has 15,585 untokenized Arabic words. The test set has 12,116 untokenized Arabic words. Both dev and test data contain two sets of reference translations. The English data is lower-cased and tokenized using simple punctuation-based rules. Systems We build three translation systems which vary in tokenization of the Arabic </context>
</contexts>
<marker>Banerjee, Lavie, 2005</marker>
<rawString>Satanjeev Banerjee and Alon Lavie. 2005. METEOR: An Automatic Metric for MT Evaluation with Improved Correlation with Human Judgments. In Proceedings of the ACL Workshop on Intrinsic and Extrinsic Evaluation Measures for Machine Translation and/or Summarization, pages 65–72, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
</authors>
<title>Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>4</issue>
<contexts>
<context position="4623" citStr="Brill, 1995" startWordPosition="702" endWordPosition="703">f these problems together (Habash and Rambow, 2005). Previous work on DA morphological tagging focused on creating resources, using noisy or incomplete annotations, and using unsupervised/semisupervised methods. Duh and Kirchhoff (2005) adopt a minimally supervised approach that only requires raw text data from several DAs, as well as a MSA morphological analyzer. They report a POS accuracy of 70.9% on a rather coarse-grained POS tagset (17 tags). Al-Sabbagh and Girju (2012) describe a supervised tagger for Egyptian Arabic social networking corpora trained using transformation-based learning (Brill, 1995). They report 94.5% F-measure on tokenization and 87.6% on POS tagging. Their tokenization and POS tagsets are comparable to the set used by the Arabic Treebank (ATB). We do not compare to them since their data sets are not public. Stallard et al. (2012) show that unsupervised methods for learning DA tokenization can outperform MSA tokenizers on MT from Levantine Arabic to English. We do not compare to them directly since our work is on ARZ. However, we carry a similar MT experiment in Section 5. Mohamed et al. (2012) annotated a small corpus of Egyptian Arabic for morphological segmentation a</context>
</contexts>
<marker>Brill, 1995</marker>
<rawString>Eric Brill. 1995. Transformation-Based Error-Driven Learning and Natural Language Processing: A Case Study in Part-of-Speech Tagging. Computational Linguistics, 21(4):543–565.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Buckwalter</author>
</authors>
<title>Issues in Arabic Morphological Analysis.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledgebased and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="6861" citStr="Buckwalter, 2007" startWordPosition="1076" endWordPosition="1077"> 3 Arabic Dialect Challenges General Arabic Challenges Arabic, as MSA or DA, poses many challenges for NLP. Arabic is a morphologically complex language which includes rich inflectional morphology and a number of clitics. For example, the MSA word Aî:ñJ.:ºJ�ƒð wsyktbwnhA (wa+sa+ya-ktub-uwna+hA)1 ‘and they will write it [lit. and+will+they-write-they+it]’ has two proclitics, one circumfix and one pronominal enclitic. Additionally, Arabic has a high degree of ambiguity resulting from its diacritic-optional writing system and common deviation from spelling standards (e.g., Alif and Ya variants) (Buckwalter, 2007). The Standard Arabic Morphological Analyzer for (SAMA) (Graff et al., 2009) produces 12 analyses per MSA word on average. Differences between ARZ and MSA As mentioned above, most tools developed for MSA cannot be expected to perform well on ARZ. This is due to the numerous differences between the two variants. Lexically, the number of differences is quite significant. For example, ARZ S �uQ£ Trbyzh ‘table’ corresponds to MSA aËðA£ TAwlh. Phonologically, there are many important differences which relate to orthography in DA, e.g., the MSA consonant H~ /B/ is pronounced as /t/ in ARZ (or /s/ in</context>
</contexts>
<marker>Buckwalter, 2007</marker>
<rawString>Tim Buckwalter. 2007. Issues in Arabic Morphological Analysis. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledgebased and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Mona Diab</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Safiullah Shareef</author>
</authors>
<title>Parsing Arabic Dialects.</title>
<date>2006</date>
<booktitle>In Proceedings of the European Chapter of ACL (EACL).</booktitle>
<contexts>
<context position="5908" citStr="Chiang et al., 2006" startWordPosition="924" endWordPosition="927">ns and van den Bosch, 2005). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA directly, and we evaluate the use of additional MSA annotated resources to our training in Section 5. 3 Arabic Dialect Challenges General Arabic Challenges Arabic, as MSA or DA, poses many challenges for NLP. Arabic is a morphologically complex language which includes rich inflectional morphology and a number of clitics. For example, the MSA word Aî:ñJ.:ºJ�ƒð wsy</context>
</contexts>
<marker>Chiang, Diab, Habash, Rambow, Shareef, 2006</marker>
<rawString>David Chiang, Mona Diab, Nizar Habash, Owen Rambow, and Safiullah Shareef. 2006. Parsing Arabic Dialects. In Proceedings of the European Chapter of ACL (EACL).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
</authors>
<date>2005</date>
<booktitle>Memory-Based Language Processing. Studies in Natural Language Processing.</booktitle>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge, UK.</location>
<marker>Daelemans, van den Bosch, 2005</marker>
<rawString>Walter Daelemans and Antal van den Bosch. 2005. Memory-Based Language Processing. Studies in Natural Language Processing. Cambridge University Press, Cambridge, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
<author>Kadri Hacioglu</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automated methods for processing arabic text: From tokenization to base phrase chunking.</title>
<date>2007</date>
<booktitle>In Antal van den Bosch and Abdelhadi Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<publisher>Kluwer/Springer.</publisher>
<contexts>
<context position="3963" citStr="Diab et al., 2007" startWordPosition="600" endWordPosition="603">ges of processing Arabic dialects. Section 4 outlines our approach. And Section 5 presents and discusses our evaluation results. 426 Proceedings of NAACL-HLT 2013, pages 426–432, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Related Work There has been a considerable amount of work on MSA morphological analysis, disambiguation, partof-speech (POS) tagging, tokenization, lemmatization and diacritization; for an overview, see (Habash, 2010). Most solutions target specific problems, such as diacritization (Zitouni et al., 2006), tokenization or POS tagging (Diab et al., 2007). In contrast, MADA provides a solution to all of these problems together (Habash and Rambow, 2005). Previous work on DA morphological tagging focused on creating resources, using noisy or incomplete annotations, and using unsupervised/semisupervised methods. Duh and Kirchhoff (2005) adopt a minimally supervised approach that only requires raw text data from several DAs, as well as a MSA morphological analyzer. They report a POS accuracy of 70.9% on a rather coarse-grained POS tagset (17 tags). Al-Sabbagh and Girju (2012) describe a supervised tagger for Egyptian Arabic social networking corpo</context>
</contexts>
<marker>Diab, Hacioglu, Jurafsky, 2007</marker>
<rawString>Mona Diab, Kadri Hacioglu, and Daniel Jurafsky. 2007. Automated methods for processing arabic text: From tokenization to base phrase chunking. In Antal van den Bosch and Abdelhadi Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Kluwer/Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mona Diab</author>
</authors>
<title>Improved Arabic Base Phrase Chunking with a New Enriched POS Tag Set.</title>
<date>2007</date>
<booktitle>In Proceedings of the 2007 Workshop on Computational Approaches to Semitic Languages: Common Issues and Resources,</booktitle>
<pages>89--96</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="13994" citStr="Diab, 2007" startWordPosition="2272" endWordPosition="2273">st sets (21.1K words and 20.4K words). Tuning for MADA-ARZ was done using a random 10% of the ATB-ARZ training data, which was later integrated back into the training set. Metrics We use several evaluation metrics to measure the effectiveness of MADA-ARZ. Morph Tag refers to the accuracy of correctly predicting the full CALIMA morphological tag (i.e., not the diacritics or the lemma). Penn POS and MADA POS are also tag accuracy metrics. Penn POS, also known as the Reduced Tag Set, is a tag set reduction of the full Arabic morphological tag set, which was proposed for MSA (Kulick et al., 2006; Diab, 2007; Habash, 2010); since it retains no MSA-specific morphological features, it also makes sense for ARZ. MADA POS is the small POS tag set (36 tags) MADA uses internally. Diacritic and Lemma are the accuracies of the choice of diacritized form and Lemma, respectively. Full is the harshest metric, requiring that every morphological feature of the chosen analysis be correct. Finally, ATB Segmentation is the percentage of words with correct ATB segmentation (splitting off all clitics except for the determiner +JI Al+). Results The results are shown in Table 1. MADA-ARZ performs much better than the</context>
</contexts>
<marker>Diab, 2007</marker>
<rawString>Mona Diab. 2007. Improved Arabic Base Phrase Chunking with a New Enriched POS Tag Set. In Proceedings of the 2007 Workshop on Computational Approaches to Semitic Languages: Common Issues and Resources, pages 89–96, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Duh</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>POS tagging of dialectal Arabic: a minimally supervised approach.</title>
<date>2005</date>
<booktitle>In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, Semitic ’05,</booktitle>
<pages>55--62</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="4247" citStr="Duh and Kirchhoff (2005)" startWordPosition="642" endWordPosition="645">here has been a considerable amount of work on MSA morphological analysis, disambiguation, partof-speech (POS) tagging, tokenization, lemmatization and diacritization; for an overview, see (Habash, 2010). Most solutions target specific problems, such as diacritization (Zitouni et al., 2006), tokenization or POS tagging (Diab et al., 2007). In contrast, MADA provides a solution to all of these problems together (Habash and Rambow, 2005). Previous work on DA morphological tagging focused on creating resources, using noisy or incomplete annotations, and using unsupervised/semisupervised methods. Duh and Kirchhoff (2005) adopt a minimally supervised approach that only requires raw text data from several DAs, as well as a MSA morphological analyzer. They report a POS accuracy of 70.9% on a rather coarse-grained POS tagset (17 tags). Al-Sabbagh and Girju (2012) describe a supervised tagger for Egyptian Arabic social networking corpora trained using transformation-based learning (Brill, 1995). They report 94.5% F-measure on tokenization and 87.6% on POS tagging. Their tokenization and POS tagsets are comparable to the set used by the Arabic Treebank (ATB). We do not compare to them since their data sets are not </context>
</contexts>
<marker>Duh, Kirchhoff, 2005</marker>
<rawString>Kevin Duh and Katrin Kirchhoff. 2005. POS tagging of dialectal Arabic: a minimally supervised approach. In Proceedings of the ACL Workshop on Computational Approaches to Semitic Languages, Semitic ’05, pages 55–62, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ramy Eskander</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Nadi Tomeh</author>
</authors>
<title>Processing Spontaneous Orthography.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="8502" citStr="Eskander et al., 2013" startWordPosition="1352" endWordPosition="1355">MSA future proclitic +v sa+ appears in ARZ as +A ha+. There are some morphemes in ARZ that do not exist in MSA such as the negation circum-clitic v:+ ... +La mA+ ... +š. And there are MSA features that are absent from ARZ, most notably case and mood. Since there are no orthographic standards, ARZ words may be written in a variety of ways reflecting different writing rules, e.g., phonologically or etymologically. A conventional orthography for Dialectal Arabic (CODA) has been proposed and used for writing ARZ in the context of NLP applications (Habash et al., 2012a; Al-Sabbagh and Girju, 2012; Eskander et al., 2013). Finally, MSA and ARZ coexist and are often used interchangeably, especially in more formal settings. The CALIMA morphological analyzer we use addresses several of these issues by modeling both ARZ and MSA together, including a limited set of inter-dialect morphology phenomena, and by mapping ARZ words into CODA orthography internally while accepting a wide range of spelling variants. 4 Approach 4.1 The MADA Approach MADA is a method for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Roth et al., 2008). MADA uses a morphological analyzer to produce, for each input </context>
</contexts>
<marker>Eskander, Habash, Rambow, Tomeh, 2013</marker>
<rawString>Ramy Eskander, Nizar Habash, Owen Rambow, and Nadi Tomeh. 2013. Processing Spontaneous Orthography. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, SETQA-NLP ’08,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="16098" citStr="Gao and Vogel, 2008" startWordPosition="2620" endWordPosition="2623">2 22.1 27.2 63.2 MADA ATB 5.8 24.4 29.6 60.5 MADA-ARZ ATB 4.9 25.2 29.9 59.4 Table 2: Machine translation results on the test set. “Punct” refers to the baseline which only tokenizes at punctuation. of the word when it maps into CODA, we needed a manual analysis where no exact match with the gold occurs (11.8% of the time). We determined MADA-ARZ’s accuracy on their test set for morphsegmentation to be 93.2%. 5.2 Egyptian Arabic to English MT MT Experimental Settings We use the opensource Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4- gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using Minimum Error Rate Training (Och, 2003). We perform caseinsensitive evaluation in terms of BLEU, METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006) metrics. Data We trained on DA-English parallel da</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, SETQA-NLP ’08, pages 49–57, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Graff</author>
<author>Mohamed Maamouri</author>
<author>Basma Bouziri</author>
<author>Sondos Krouna</author>
<author>Seth Kulick</author>
<author>Tim Buckwalter</author>
</authors>
<date>2009</date>
<booktitle>Standard Arabic Morphological Analyzer (SAMA) Version 3.1. Linguistic Data Consortium LDC2009E73.</booktitle>
<contexts>
<context position="6937" citStr="Graff et al., 2009" startWordPosition="1086" endWordPosition="1089">A, poses many challenges for NLP. Arabic is a morphologically complex language which includes rich inflectional morphology and a number of clitics. For example, the MSA word Aî:ñJ.:ºJ�ƒð wsyktbwnhA (wa+sa+ya-ktub-uwna+hA)1 ‘and they will write it [lit. and+will+they-write-they+it]’ has two proclitics, one circumfix and one pronominal enclitic. Additionally, Arabic has a high degree of ambiguity resulting from its diacritic-optional writing system and common deviation from spelling standards (e.g., Alif and Ya variants) (Buckwalter, 2007). The Standard Arabic Morphological Analyzer for (SAMA) (Graff et al., 2009) produces 12 analyses per MSA word on average. Differences between ARZ and MSA As mentioned above, most tools developed for MSA cannot be expected to perform well on ARZ. This is due to the numerous differences between the two variants. Lexically, the number of differences is quite significant. For example, ARZ S �uQ£ Trbyzh ‘table’ corresponds to MSA aËðA£ TAwlh. Phonologically, there are many important differences which relate to orthography in DA, e.g., the MSA consonant H~ /B/ is pronounced as /t/ in ARZ (or /s/ in more recent borrowings from MSA); for a fuller discussion, see (Habash, 201</context>
</contexts>
<marker>Graff, Maamouri, Bouziri, Krouna, Kulick, Buckwalter, 2009</marker>
<rawString>David Graff, Mohamed Maamouri, Basma Bouziri, Sondos Krouna, Seth Kulick, and Tim Buckwalter. 2009. Standard Arabic Morphological Analyzer (SAMA) Version 3.1. Linguistic Data Consortium LDC2009E73.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>573--580</pages>
<location>Ann Arbor, Michigan.</location>
<contexts>
<context position="2060" citStr="Habash and Rambow, 2005" startWordPosition="302" endWordPosition="305">es (Holes, 2004; Abdel-Massih et al., 1979). Most tools and resources developed for natural language processing (NLP) of Arabic are designed for MSA. Such resources are quite limited when it comes to processing DA, e.g., a state-ofthe-art MSA morphological analyzer only has 60% coverage of Levantine Arabic verb forms (Habash and Rambow, 2006). In this paper, we describe the process of retargeting an existing state-of-the-art tool for modeling MSA morphology disambiguation to ARZ, the most commonly spoken DA. The MSA tool we extend is MADA – Morphological Analysis and Disambiguation of Arabic (Habash and Rambow, 2005). The approach used in MADA, which was inspired by earlier work by Hajiˇc (2000), disambiguates in context for every aspect of Arabic morphology, thus solving all tasks in “one fell swoop”. The disadvantage of the MADA approach is its dependence on two complex resources: a morphological analyzer for the language and a large collection of manually annotated words for all morphological features in the same representation used by the analyzer. For ARZ, such resources have recently become available, with the development of the CALIMA ARZ morphological analyzer (Habash et al., 2012b) and the releas</context>
<context position="4062" citStr="Habash and Rambow, 2005" startWordPosition="616" endWordPosition="619">d discusses our evaluation results. 426 Proceedings of NAACL-HLT 2013, pages 426–432, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Related Work There has been a considerable amount of work on MSA morphological analysis, disambiguation, partof-speech (POS) tagging, tokenization, lemmatization and diacritization; for an overview, see (Habash, 2010). Most solutions target specific problems, such as diacritization (Zitouni et al., 2006), tokenization or POS tagging (Diab et al., 2007). In contrast, MADA provides a solution to all of these problems together (Habash and Rambow, 2005). Previous work on DA morphological tagging focused on creating resources, using noisy or incomplete annotations, and using unsupervised/semisupervised methods. Duh and Kirchhoff (2005) adopt a minimally supervised approach that only requires raw text data from several DAs, as well as a MSA morphological analyzer. They report a POS accuracy of 70.9% on a rather coarse-grained POS tagset (17 tags). Al-Sabbagh and Girju (2012) describe a supervised tagger for Egyptian Arabic social networking corpora trained using transformation-based learning (Brill, 1995). They report 94.5% F-measure on tokeni</context>
<context position="9018" citStr="Habash and Rambow, 2005" startWordPosition="1435" endWordPosition="1438">n the context of NLP applications (Habash et al., 2012a; Al-Sabbagh and Girju, 2012; Eskander et al., 2013). Finally, MSA and ARZ coexist and are often used interchangeably, especially in more formal settings. The CALIMA morphological analyzer we use addresses several of these issues by modeling both ARZ and MSA together, including a limited set of inter-dialect morphology phenomena, and by mapping ARZ words into CODA orthography internally while accepting a wide range of spelling variants. 4 Approach 4.1 The MADA Approach MADA is a method for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Roth et al., 2008). MADA uses a morphological analyzer to produce, for each input word, a list of analyses specifying every possible morphological interpretation of that word, covering all morphological features of the word (diacritization, POS, lemma, and 13 inflectional and clitic features). MADA then applies a set of models (support vector machines and N-gram language models) to produce a prediction, per word in-context, for different morphological features, such as POS, lemma, gender, number or person. A ranking component scores the analyses produced by the morphological analyzer using a</context>
<context position="10443" citStr="Habash and Rambow (2005)" startWordPosition="1664" endWordPosition="1668">to handle DA requires a number of modifications. The most significant change is replacing the MSA analyzer SAMA with the ARZ analyzer CALIMA to address the differences outlined in Section 3. In addition, new feature prediction models are needed; these are trained using ARZ data sets annotated by the LDC (Maamouri et al., 2006; Maamouri et al., 2012b). The data sets were not usable as released due to numerous annotation inconsistencies and differences from CALIMA, as well due to gaps in CALIMA. We synchronized the annotations with the latest version of CALIMA following a technique described by Habash and Rambow (2005). The result of this synchronization step is the data we use in this study (for training, development and testing). Our synchronized annotations fully match the LDC annotations in 90% of the words (in full morphological tag). We performed a manual analysis on randomly chosen 100 words that did not fully match. The choice we made is correct or acceptable in 55% of the cases of mismatch with the LDC annotation, which means that the our choice is accurate in over 95% of all cases. Some of the original MADA features (which were needed for MSA) are not used in ARZ and so are dropped in MADA-ARZ; th</context>
</contexts>
<marker>Habash, Rambow, 2005</marker>
<rawString>Nizar Habash and Owen Rambow. 2005. Arabic Tokenization, Part-of-Speech Tagging and Morphological Disambiguation in One Fell Swoop. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 573–580, Ann Arbor, Michigan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
</authors>
<title>MAGEAD: A Morphological Analyzer and Generator for the Arabic Dialects.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>681--688</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="1780" citStr="Habash and Rambow, 2006" startWordPosition="257" endWordPosition="260">rences between them. Unlike MSA, DAs have no standard orthographies or language academies. Furthermore, different DAs, such as Egyptian Arabic (henceforth, ARZ), Levantine Arabic or Moroccan Arabic have important differences among them, similar to those seen among Romance languages (Holes, 2004; Abdel-Massih et al., 1979). Most tools and resources developed for natural language processing (NLP) of Arabic are designed for MSA. Such resources are quite limited when it comes to processing DA, e.g., a state-ofthe-art MSA morphological analyzer only has 60% coverage of Levantine Arabic verb forms (Habash and Rambow, 2006). In this paper, we describe the process of retargeting an existing state-of-the-art tool for modeling MSA morphology disambiguation to ARZ, the most commonly spoken DA. The MSA tool we extend is MADA – Morphological Analysis and Disambiguation of Arabic (Habash and Rambow, 2005). The approach used in MADA, which was inspired by earlier work by Hajiˇc (2000), disambiguates in context for every aspect of Arabic morphology, thus solving all tasks in “one fell swoop”. The disadvantage of the MADA approach is its dependence on two complex resources: a morphological analyzer for the language and a </context>
<context position="5742" citStr="Habash and Rambow, 2006" startWordPosition="894" endWordPosition="897">on 5. Mohamed et al. (2012) annotated a small corpus of Egyptian Arabic for morphological segmentation and learned segmentation models using memorybased learning (Daelemans and van den Bosch, 2005). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA directly, and we evaluate the use of additional MSA annotated resources to our training in Section 5. 3 Arabic Dialect Challenges General Arabic Challenges Arabic, as MSA or DA, poses many challenges</context>
</contexts>
<marker>Habash, Rambow, 2006</marker>
<rawString>Nizar Habash and Owen Rambow. 2006. MAGEAD: A Morphological Analyzer and Generator for the Arabic Dialects. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 681–688, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Fatiha Sadat</author>
</authors>
<title>Arabic Preprocessing Schemes for Statistical Machine Translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL06),</booktitle>
<pages>49--52</pages>
<location>New York, NY.</location>
<contexts>
<context position="17434" citStr="Habash and Sadat, 2006" startWordPosition="2835" endWordPosition="2838">s on the Arabic side. The dev set, used for tuning the parameters of the MT system, has 15,585 untokenized Arabic words. The test set has 12,116 untokenized Arabic words. Both dev and test data contain two sets of reference translations. The English data is lower-cased and tokenized using simple punctuation-based rules. Systems We build three translation systems which vary in tokenization of the Arabic text. The first system applies only simple punctuation-based rules. The second and third systems use MADA and MADA-ARZ, respectively, to tokenize the Arabic text in the ATB tokenization scheme (Habash and Sadat, 2006). The Arabic text is also Alif/Ya normalized. Results The MT results are in Table 2, which also shows the percentage of out-of-vocabulary (OOV) words – test words not in the training data. MADAARZ delivers the best translation performance according to all metrics. All MADA-ARZ improvements over MADA are statistically significant at the .01 level (except in the case of METEOR). All improvements over Punct by MADA and MADAARZ are also statistically significant. For BLEU scores, we observe 3.1% absolute improvement to Punct (14% relative), and 0.8% absolute improvement to MADA (3.3% relative). In</context>
</contexts>
<marker>Habash, Sadat, 2006</marker>
<rawString>Nizar Habash and Fatiha Sadat. 2006. Arabic Preprocessing Schemes for Statistical Machine Translation. In Proceedings of the 7th Meeting of the North American Chapter of the Association for Computational Linguistics/Human Language Technologies Conference (HLT-NAACL06), pages 49–52, New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Abdelhadi Soudi</author>
<author>Tim Buckwalter</author>
</authors>
<title>On Arabic Transliteration.</title>
<date>2007</date>
<booktitle>Arabic Computational Morphology: Knowledge-based and Empirical Methods.</booktitle>
<editor>In A. van den Bosch and A. Soudi, editors,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="7719" citStr="Habash et al., 2007" startWordPosition="1213" endWordPosition="1216"> on ARZ. This is due to the numerous differences between the two variants. Lexically, the number of differences is quite significant. For example, ARZ S �uQ£ Trbyzh ‘table’ corresponds to MSA aËðA£ TAwlh. Phonologically, there are many important differences which relate to orthography in DA, e.g., the MSA consonant H~ /B/ is pronounced as /t/ in ARZ (or /s/ in more recent borrowings from MSA); for a fuller discussion, see (Habash, 2010; Habash et al., 2012a). Examples of morphological differences include changes in the 1Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical order) Abt0jHxdðrzsšSDT ˇDS-yfqklmnhwy and the additional symbols: ’ Z, Â 1, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø. 427 morpheme form, e.g., the MSA future proclitic +v sa+ appears in ARZ as +A ha+. There are some morphemes in ARZ that do not exist in MSA such as the negation circum-clitic v:+ ... +La mA+ ... +š. And there are MSA features that are absent from ARZ, most notably case and mood. Since there are no orthographic standards, ARZ words may be written in a variety of ways reflecting different writing rules, e.g., phonologically or etymologically. A conventional orthogra</context>
</contexts>
<marker>Habash, Soudi, Buckwalter, 2007</marker>
<rawString>Nizar Habash, Abdelhadi Soudi, and Tim Buckwalter. 2007. On Arabic Transliteration. In A. van den Bosch and A. Soudi, editors, Arabic Computational Morphology: Knowledge-based and Empirical Methods. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Owen Rabmow</author>
</authors>
<title>Conventional Orthography for Dialectal Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC),</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="2643" citStr="Habash et al., 2012" startWordPosition="400" endWordPosition="403"> of Arabic (Habash and Rambow, 2005). The approach used in MADA, which was inspired by earlier work by Hajiˇc (2000), disambiguates in context for every aspect of Arabic morphology, thus solving all tasks in “one fell swoop”. The disadvantage of the MADA approach is its dependence on two complex resources: a morphological analyzer for the language and a large collection of manually annotated words for all morphological features in the same representation used by the analyzer. For ARZ, such resources have recently become available, with the development of the CALIMA ARZ morphological analyzer (Habash et al., 2012b) and the release by the Linguistic Data Consortium (LDC) of a large ARZ corpus annotated morphologically in a manner compatible with CALIMA (Maamouri et al., 2012a). In the work presented here, we utilize these new resources within the paradigm of MADA, transforming MADA into MADA-ARZ. The elegance of the MADA solution makes this conceptually a simple extension. Our evaluation demonstrates that our Egyptian DA version of MADA, henceforth MADA-ARZ, outperforms MADA for MSA on ARZ morphological tagging and improves the quality of ARZ to English statistical machine translation (MT). The rest of</context>
<context position="5682" citStr="Habash et al., 2012" startWordPosition="884" endWordPosition="887"> ARZ. However, we carry a similar MT experiment in Section 5. Mohamed et al. (2012) annotated a small corpus of Egyptian Arabic for morphological segmentation and learned segmentation models using memorybased learning (Daelemans and van den Bosch, 2005). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA directly, and we evaluate the use of additional MSA annotated resources to our training in Section 5. 3 Arabic Dialect Challenges General A</context>
<context position="7559" citStr="Habash et al., 2012" startWordPosition="1192" endWordPosition="1195">oduces 12 analyses per MSA word on average. Differences between ARZ and MSA As mentioned above, most tools developed for MSA cannot be expected to perform well on ARZ. This is due to the numerous differences between the two variants. Lexically, the number of differences is quite significant. For example, ARZ S �uQ£ Trbyzh ‘table’ corresponds to MSA aËðA£ TAwlh. Phonologically, there are many important differences which relate to orthography in DA, e.g., the MSA consonant H~ /B/ is pronounced as /t/ in ARZ (or /s/ in more recent borrowings from MSA); for a fuller discussion, see (Habash, 2010; Habash et al., 2012a). Examples of morphological differences include changes in the 1Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical order) Abt0jHxdðrzsšSDT ˇDS-yfqklmnhwy and the additional symbols: ’ Z, Â 1, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø. 427 morpheme form, e.g., the MSA future proclitic +v sa+ appears in ARZ as +A ha+. There are some morphemes in ARZ that do not exist in MSA such as the negation circum-clitic v:+ ... +La mA+ ... +š. And there are MSA features that are absent from ARZ, most notably case and mood. Since there are no orthograp</context>
</contexts>
<marker>Habash, Diab, Rabmow, 2012</marker>
<rawString>Nizar Habash, Mona Diab, and Owen Rabmow. 2012a. Conventional Orthography for Dialectal Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
<author>Ramy Eskander</author>
<author>Abdelati Hawwari</author>
</authors>
<title>A Morphological Analyzer for Egyptian Arabic.</title>
<date>2012</date>
<booktitle>In NAACL-HLT 2012 Workshop on Computational Morphology and Phonology (SIGMORPHON2012),</booktitle>
<pages>1--9</pages>
<contexts>
<context position="2643" citStr="Habash et al., 2012" startWordPosition="400" endWordPosition="403"> of Arabic (Habash and Rambow, 2005). The approach used in MADA, which was inspired by earlier work by Hajiˇc (2000), disambiguates in context for every aspect of Arabic morphology, thus solving all tasks in “one fell swoop”. The disadvantage of the MADA approach is its dependence on two complex resources: a morphological analyzer for the language and a large collection of manually annotated words for all morphological features in the same representation used by the analyzer. For ARZ, such resources have recently become available, with the development of the CALIMA ARZ morphological analyzer (Habash et al., 2012b) and the release by the Linguistic Data Consortium (LDC) of a large ARZ corpus annotated morphologically in a manner compatible with CALIMA (Maamouri et al., 2012a). In the work presented here, we utilize these new resources within the paradigm of MADA, transforming MADA into MADA-ARZ. The elegance of the MADA solution makes this conceptually a simple extension. Our evaluation demonstrates that our Egyptian DA version of MADA, henceforth MADA-ARZ, outperforms MADA for MSA on ARZ morphological tagging and improves the quality of ARZ to English statistical machine translation (MT). The rest of</context>
<context position="5682" citStr="Habash et al., 2012" startWordPosition="884" endWordPosition="887"> ARZ. However, we carry a similar MT experiment in Section 5. Mohamed et al. (2012) annotated a small corpus of Egyptian Arabic for morphological segmentation and learned segmentation models using memorybased learning (Daelemans and van den Bosch, 2005). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA directly, and we evaluate the use of additional MSA annotated resources to our training in Section 5. 3 Arabic Dialect Challenges General A</context>
<context position="7559" citStr="Habash et al., 2012" startWordPosition="1192" endWordPosition="1195">oduces 12 analyses per MSA word on average. Differences between ARZ and MSA As mentioned above, most tools developed for MSA cannot be expected to perform well on ARZ. This is due to the numerous differences between the two variants. Lexically, the number of differences is quite significant. For example, ARZ S �uQ£ Trbyzh ‘table’ corresponds to MSA aËðA£ TAwlh. Phonologically, there are many important differences which relate to orthography in DA, e.g., the MSA consonant H~ /B/ is pronounced as /t/ in ARZ (or /s/ in more recent borrowings from MSA); for a fuller discussion, see (Habash, 2010; Habash et al., 2012a). Examples of morphological differences include changes in the 1Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical order) Abt0jHxdðrzsšSDT ˇDS-yfqklmnhwy and the additional symbols: ’ Z, Â 1, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø. 427 morpheme form, e.g., the MSA future proclitic +v sa+ appears in ARZ as +A ha+. There are some morphemes in ARZ that do not exist in MSA such as the negation circum-clitic v:+ ... +La mA+ ... +š. And there are MSA features that are absent from ARZ, most notably case and mood. Since there are no orthograp</context>
</contexts>
<marker>Habash, Eskander, Hawwari, 2012</marker>
<rawString>Nizar Habash, Ramy Eskander, and Abdelati Hawwari. 2012b. A Morphological Analyzer for Egyptian Arabic. In NAACL-HLT 2012 Workshop on Computational Morphology and Phonology (SIGMORPHON2012), pages 1–9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nizar Habash</author>
</authors>
<title>Introduction to Arabic Natural Language Processing.</title>
<date>2010</date>
<publisher>Morgan &amp; Claypool Publishers.</publisher>
<contexts>
<context position="3826" citStr="Habash, 2010" startWordPosition="582" endWordPosition="583"> translation (MT). The rest of this paper is structured as follows: Section 2 discusses related work. Section 3 presents the challenges of processing Arabic dialects. Section 4 outlines our approach. And Section 5 presents and discusses our evaluation results. 426 Proceedings of NAACL-HLT 2013, pages 426–432, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Related Work There has been a considerable amount of work on MSA morphological analysis, disambiguation, partof-speech (POS) tagging, tokenization, lemmatization and diacritization; for an overview, see (Habash, 2010). Most solutions target specific problems, such as diacritization (Zitouni et al., 2006), tokenization or POS tagging (Diab et al., 2007). In contrast, MADA provides a solution to all of these problems together (Habash and Rambow, 2005). Previous work on DA morphological tagging focused on creating resources, using noisy or incomplete annotations, and using unsupervised/semisupervised methods. Duh and Kirchhoff (2005) adopt a minimally supervised approach that only requires raw text data from several DAs, as well as a MSA morphological analyzer. They report a POS accuracy of 70.9% on a rather </context>
<context position="7538" citStr="Habash, 2010" startWordPosition="1190" endWordPosition="1191"> al., 2009) produces 12 analyses per MSA word on average. Differences between ARZ and MSA As mentioned above, most tools developed for MSA cannot be expected to perform well on ARZ. This is due to the numerous differences between the two variants. Lexically, the number of differences is quite significant. For example, ARZ S �uQ£ Trbyzh ‘table’ corresponds to MSA aËðA£ TAwlh. Phonologically, there are many important differences which relate to orthography in DA, e.g., the MSA consonant H~ /B/ is pronounced as /t/ in ARZ (or /s/ in more recent borrowings from MSA); for a fuller discussion, see (Habash, 2010; Habash et al., 2012a). Examples of morphological differences include changes in the 1Arabic transliteration is presented in the Habash-SoudiBuckwalter scheme (Habash et al., 2007): (in alphabetical order) Abt0jHxdðrzsšSDT ˇDS-yfqklmnhwy and the additional symbols: ’ Z, Â 1, Aˇ@�, A¯�@, wˆ j , yˆZø , h a, ý ø. 427 morpheme form, e.g., the MSA future proclitic +v sa+ appears in ARZ as +A ha+. There are some morphemes in ARZ that do not exist in MSA such as the negation circum-clitic v:+ ... +La mA+ ... +š. And there are MSA features that are absent from ARZ, most notably case and mood. Since t</context>
<context position="14009" citStr="Habash, 2010" startWordPosition="2274" endWordPosition="2275">1K words and 20.4K words). Tuning for MADA-ARZ was done using a random 10% of the ATB-ARZ training data, which was later integrated back into the training set. Metrics We use several evaluation metrics to measure the effectiveness of MADA-ARZ. Morph Tag refers to the accuracy of correctly predicting the full CALIMA morphological tag (i.e., not the diacritics or the lemma). Penn POS and MADA POS are also tag accuracy metrics. Penn POS, also known as the Reduced Tag Set, is a tag set reduction of the full Arabic morphological tag set, which was proposed for MSA (Kulick et al., 2006; Diab, 2007; Habash, 2010); since it retains no MSA-specific morphological features, it also makes sense for ARZ. MADA POS is the small POS tag set (36 tags) MADA uses internally. Diacritic and Lemma are the accuracies of the choice of diacritized form and Lemma, respectively. Full is the harshest metric, requiring that every morphological feature of the chosen analysis be correct. Finally, ATB Segmentation is the percentage of words with correct ATB segmentation (splitting off all clitics except for the determiner +JI Al+). Results The results are shown in Table 1. MADA-ARZ performs much better than the MADA baselines</context>
</contexts>
<marker>Habash, 2010</marker>
<rawString>Nizar Habash. 2010. Introduction to Arabic Natural Language Processing. Morgan &amp; Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajiˇc</author>
</authors>
<title>Morphological tagging: Data vs. dictionaries.</title>
<date>2000</date>
<booktitle>In Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL’00),</booktitle>
<location>Seattle, WA.</location>
<marker>Hajiˇc, 2000</marker>
<rawString>Jan Hajiˇc. 2000. Morphological tagging: Data vs. dictionaries. In Proceedings of the 1st Meeting of the North American Chapter of the Association for Computational Linguistics (NAACL’00), Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clive Holes</author>
</authors>
<title>Modern Arabic: Structures, Functions, and Varieties. Georgetown Classics in Arabic Language and Linguistics.</title>
<date>2004</date>
<publisher>Georgetown University Press.</publisher>
<contexts>
<context position="1048" citStr="Holes, 2004" startWordPosition="149" endWordPosition="150"> MSA. In this paper, we retarget an existing state-of-the-art MSA morphological tagger to Egyptian Arabic (ARZ). Our evaluation demonstrates that our ARZ morphology tagger outperforms its MSA variant on ARZ input in terms of accuracy in part-of-speech tagging, diacritization, lemmatization and tokenization; and in terms of utility for ARZ-toEnglish statistical machine translation. 1 Introduction Dialectal Arabic (DA) refers to the day-to-day native vernaculars spoken in the Arab World. DA is used side by side with Modern Standard Arabic (MSA), the official language of the media and education (Holes, 2004). Although DAs are historically related to MSA, there are many phonological, morphological and lexical differences between them. Unlike MSA, DAs have no standard orthographies or language academies. Furthermore, different DAs, such as Egyptian Arabic (henceforth, ARZ), Levantine Arabic or Moroccan Arabic have important differences among them, similar to those seen among Romance languages (Holes, 2004; Abdel-Massih et al., 1979). Most tools and resources developed for natural language processing (NLP) of Arabic are designed for MSA. Such resources are quite limited when it comes to processing D</context>
</contexts>
<marker>Holes, 2004</marker>
<rawString>Clive Holes. 2004. Modern Arabic: Structures, Functions, and Varieties. Georgetown Classics in Arabic Language and Linguistics. Georgetown University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kilany</author>
<author>H Gadalla</author>
<author>H Arram</author>
<author>A Yacoub</author>
<author>A ElHabashi</author>
<author>C McLemore</author>
</authors>
<date>2002</date>
<booktitle>Egyptian Colloquial Arabic Lexicon. LDC catalog number LDC99L22.</booktitle>
<contexts>
<context position="5542" citStr="Kilany et al. (2002)" startWordPosition="859" endWordPosition="862">DA tokenization can outperform MSA tokenizers on MT from Levantine Arabic to English. We do not compare to them directly since our work is on ARZ. However, we carry a similar MT experiment in Section 5. Mohamed et al. (2012) annotated a small corpus of Egyptian Arabic for morphological segmentation and learned segmentation models using memorybased learning (Daelemans and van den Bosch, 2005). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA</context>
</contexts>
<marker>Kilany, Gadalla, Arram, Yacoub, ElHabashi, McLemore, 2002</marker>
<rawString>H. Kilany, H. Gadalla, H. Arram, A. Yacoub, A. ElHabashi, and C. McLemore. 2002. Egyptian Colloquial Arabic Lexicon. LDC catalog number LDC99L22.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Christopher Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Richard Zens</author>
<author>Christopher Dyer</author>
<author>Ondrej Bojar</author>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>177--180</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="16006" citStr="Koehn et al., 2007" startWordPosition="2604" endWordPosition="2607">el accuracy. Since MADA-ARZ modifies the spelling Tokenization OOV BLEU METEOR TER Punct 9.2 22.1 27.2 63.2 MADA ATB 5.8 24.4 29.6 60.5 MADA-ARZ ATB 4.9 25.2 29.9 59.4 Table 2: Machine translation results on the test set. “Punct” refers to the baseline which only tokenizes at punctuation. of the word when it maps into CODA, we needed a manual analysis where no exact match with the gold occurs (11.8% of the time). We determined MADA-ARZ’s accuracy on their test set for morphsegmentation to be 93.2%. 5.2 Egyptian Arabic to English MT MT Experimental Settings We use the opensource Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4- gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using Minimum Error Rate Training (Och, 2003). We perform caseinsensitive evaluation in terms of BLEU, METEOR (Banerjee and L</context>
</contexts>
<marker>Koehn, Hoang, Birch, Callison-Burch, Federico, Bertoldi, Cowan, Shen, Moran, Zens, Dyer, Bojar, Constantin, Herbst, 2007</marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Christopher Dyer, Ondrej Bojar, Alexandra Constantin, and Evan Herbst. 2007. Moses: open source toolkit for statistical machine translation. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 177–180, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Seth Kulick</author>
<author>Ryan Gabbard</author>
<author>Mitch Marcus</author>
</authors>
<title>Parsing the Arabic Treebank: Analysis and Improvements.</title>
<date>2006</date>
<booktitle>In Proceedings of the Treebanks and Linguistic Theories Conference,</booktitle>
<pages>31--42</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="13982" citStr="Kulick et al., 2006" startWordPosition="2268" endWordPosition="2271">elopment and blind test sets (21.1K words and 20.4K words). Tuning for MADA-ARZ was done using a random 10% of the ATB-ARZ training data, which was later integrated back into the training set. Metrics We use several evaluation metrics to measure the effectiveness of MADA-ARZ. Morph Tag refers to the accuracy of correctly predicting the full CALIMA morphological tag (i.e., not the diacritics or the lemma). Penn POS and MADA POS are also tag accuracy metrics. Penn POS, also known as the Reduced Tag Set, is a tag set reduction of the full Arabic morphological tag set, which was proposed for MSA (Kulick et al., 2006; Diab, 2007; Habash, 2010); since it retains no MSA-specific morphological features, it also makes sense for ARZ. MADA POS is the small POS tag set (36 tags) MADA uses internally. Diacritic and Lemma are the accuracies of the choice of diacritized form and Lemma, respectively. Full is the harshest metric, requiring that every morphological feature of the chosen analysis be correct. Finally, ATB Segmentation is the percentage of words with correct ATB segmentation (splitting off all clitics except for the determiner +JI Al+). Results The results are shown in Table 1. MADA-ARZ performs much bet</context>
</contexts>
<marker>Kulick, Gabbard, Marcus, 2006</marker>
<rawString>Seth Kulick, Ryan Gabbard, and Mitch Marcus. 2006. Parsing the Arabic Treebank: Analysis and Improvements. In Proceedings of the Treebanks and Linguistic Theories Conference, pages 31–42, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Wigdan Mekki</author>
</authors>
<title>The Penn Arabic Treebank : Building a Large-Scale Annotated Arabic Corpus.</title>
<date>2004</date>
<booktitle>In NEMLAR Conference on Arabic Language Resources and Tools,</booktitle>
<pages>102--109</pages>
<location>Cairo, Egypt.</location>
<contexts>
<context position="12627" citStr="Maamouri et al., 2004" startWordPosition="2035" endWordPosition="2038">ARZ ALL Morph Tag 35.8 84.0 77.3 35.7 84.5 75.5 Penn POS 77.5 89.6 90.2 79.0 90.0 90.1 MADA POS 80.7 90.8 91.3 82.1 91.1 91.4 Diacritic 31.3 82.6 72.9 32.2 83.2 72.2 Lemma 64.0 85.2 81.6 67.1 86.3 82.8 Full 26.2 74.3 65.4 27.0 75.4 64.7 ATB Segmentation 90.6 97.4 97.6 90.5 97.4 97.5 Table 1: Evaluation metrics on the ATB-ARZ development and test sets. The best results are bolded. We compare MADA and MADA-ARZ with different training data conditions. Definitions of metrics are in Section 5.1. MSA training data is ATB-123. ARZ training data is ATB-ARZ. ALL training data is ATB-123 plus ATB-ARZ. (Maamouri et al., 2004); and ATB-ARZ, the Egyptian Arabic Treebank (parts 1-5) (Maamouri et al., 2012a). For ATB-123 training, we use all of parts 1 and 2 plus the training portion of ATB-3 (as defined by Zitouni et al. (2006)); for development and test, we split Zitouni et al. (2006)’s devtest set into two. We sub-divide ATB-ARZ into development, training, and test sets (roughly a 10/80/10 split). The ATB-ARZ training data has 134K words, and the ATB-123 training data has 711K words. We evaluate two systems. We used the latest release of MADA for MSA (v3.2), trained on ATB123 (MSA), as our baseline. For MADA-ARZ, w</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Mekki, 2004</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, and Wigdan Mekki. 2004. The Penn Arabic Treebank : Building a Large-Scale Annotated Arabic Corpus. In NEMLAR Conference on Arabic Language Resources and Tools, pages 102–109, Cairo, Egypt.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Tim Buckwalter</author>
<author>Mona Diab</author>
<author>Nizar Habash</author>
<author>Owen Rambow</author>
<author>Dalila Tabessi</author>
</authors>
<title>Developing and Using a Pilot Dialectal Arabic Treebank.</title>
<date>2006</date>
<booktitle>In The fifth international conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>443--448</pages>
<location>Genoa, Italy.</location>
<contexts>
<context position="10146" citStr="Maamouri et al., 2006" startWordPosition="1616" endWordPosition="1619">erson. A ranking component scores the analyses produced by the morphological analyzer using a tuned weighted sum of matches with the predicted features. The top-scoring analysis is chosen as the predicted interpretation for that word in context. 4.2 Extending MADA into MADA-ARZ Adjusting MADA to handle DA requires a number of modifications. The most significant change is replacing the MSA analyzer SAMA with the ARZ analyzer CALIMA to address the differences outlined in Section 3. In addition, new feature prediction models are needed; these are trained using ARZ data sets annotated by the LDC (Maamouri et al., 2006; Maamouri et al., 2012b). The data sets were not usable as released due to numerous annotation inconsistencies and differences from CALIMA, as well due to gaps in CALIMA. We synchronized the annotations with the latest version of CALIMA following a technique described by Habash and Rambow (2005). The result of this synchronization step is the data we use in this study (for training, development and testing). Our synchronized annotations fully match the LDC annotations in 90% of the words (in full morphological tag). We performed a manual analysis on randomly chosen 100 words that did not full</context>
</contexts>
<marker>Maamouri, Bies, Buckwalter, Diab, Habash, Rambow, Tabessi, 2006</marker>
<rawString>Mohamed Maamouri, Ann Bies, Tim Buckwalter, Mona Diab, Nizar Habash, Owen Rambow, and Dalila Tabessi. 2006. Developing and Using a Pilot Dialectal Arabic Treebank. In The fifth international conference on Language Resources and Evaluation (LREC), pages 443–448, Genoa, Italy.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mohamed Maamouri</author>
<author>Ann Bies</author>
<author>Seth Kulick</author>
</authors>
<title>Dalila Tabessi, and Sondos Krouna. 2012a. Egyptian Arabic Treebank Pilot.</title>
<marker>Maamouri, Bies, Kulick, </marker>
<rawString>Mohamed Maamouri, Ann Bies, Seth Kulick, Dalila Tabessi, and Sondos Krouna. 2012a. Egyptian Arabic Treebank Pilot.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mohamed Maamouri</author>
<author>Sondos Krouna</author>
<author>Dalila Tabessi</author>
<author>Nadia Hamrouni</author>
<author>Nizar Habash</author>
</authors>
<title>Egyptian Arabic Morphological Annotation Guidelines.</title>
<date>2012</date>
<contexts>
<context position="2807" citStr="Maamouri et al., 2012" startWordPosition="428" endWordPosition="431"> Arabic morphology, thus solving all tasks in “one fell swoop”. The disadvantage of the MADA approach is its dependence on two complex resources: a morphological analyzer for the language and a large collection of manually annotated words for all morphological features in the same representation used by the analyzer. For ARZ, such resources have recently become available, with the development of the CALIMA ARZ morphological analyzer (Habash et al., 2012b) and the release by the Linguistic Data Consortium (LDC) of a large ARZ corpus annotated morphologically in a manner compatible with CALIMA (Maamouri et al., 2012a). In the work presented here, we utilize these new resources within the paradigm of MADA, transforming MADA into MADA-ARZ. The elegance of the MADA solution makes this conceptually a simple extension. Our evaluation demonstrates that our Egyptian DA version of MADA, henceforth MADA-ARZ, outperforms MADA for MSA on ARZ morphological tagging and improves the quality of ARZ to English statistical machine translation (MT). The rest of this paper is structured as follows: Section 2 discusses related work. Section 3 presents the challenges of processing Arabic dialects. Section 4 outlines our appr</context>
<context position="10169" citStr="Maamouri et al., 2012" startWordPosition="1620" endWordPosition="1623">ent scores the analyses produced by the morphological analyzer using a tuned weighted sum of matches with the predicted features. The top-scoring analysis is chosen as the predicted interpretation for that word in context. 4.2 Extending MADA into MADA-ARZ Adjusting MADA to handle DA requires a number of modifications. The most significant change is replacing the MSA analyzer SAMA with the ARZ analyzer CALIMA to address the differences outlined in Section 3. In addition, new feature prediction models are needed; these are trained using ARZ data sets annotated by the LDC (Maamouri et al., 2006; Maamouri et al., 2012b). The data sets were not usable as released due to numerous annotation inconsistencies and differences from CALIMA, as well due to gaps in CALIMA. We synchronized the annotations with the latest version of CALIMA following a technique described by Habash and Rambow (2005). The result of this synchronization step is the data we use in this study (for training, development and testing). Our synchronized annotations fully match the LDC annotations in 90% of the words (in full morphological tag). We performed a manual analysis on randomly chosen 100 words that did not fully match. The choice we </context>
<context position="12705" citStr="Maamouri et al., 2012" startWordPosition="2048" endWordPosition="2051">.0 90.1 MADA POS 80.7 90.8 91.3 82.1 91.1 91.4 Diacritic 31.3 82.6 72.9 32.2 83.2 72.2 Lemma 64.0 85.2 81.6 67.1 86.3 82.8 Full 26.2 74.3 65.4 27.0 75.4 64.7 ATB Segmentation 90.6 97.4 97.6 90.5 97.4 97.5 Table 1: Evaluation metrics on the ATB-ARZ development and test sets. The best results are bolded. We compare MADA and MADA-ARZ with different training data conditions. Definitions of metrics are in Section 5.1. MSA training data is ATB-123. ARZ training data is ATB-ARZ. ALL training data is ATB-123 plus ATB-ARZ. (Maamouri et al., 2004); and ATB-ARZ, the Egyptian Arabic Treebank (parts 1-5) (Maamouri et al., 2012a). For ATB-123 training, we use all of parts 1 and 2 plus the training portion of ATB-3 (as defined by Zitouni et al. (2006)); for development and test, we split Zitouni et al. (2006)’s devtest set into two. We sub-divide ATB-ARZ into development, training, and test sets (roughly a 10/80/10 split). The ATB-ARZ training data has 134K words, and the ATB-123 training data has 711K words. We evaluate two systems. We used the latest release of MADA for MSA (v3.2), trained on ATB123 (MSA), as our baseline. For MADA-ARZ, we compare two training settings: using ATB-ARZ (ARZ) and combining ATB-ARZ wit</context>
</contexts>
<marker>Maamouri, Krouna, Tabessi, Hamrouni, Habash, 2012</marker>
<rawString>Mohamed Maamouri, Sondos Krouna, Dalila Tabessi, Nadia Hamrouni, and Nizar Habash. 2012b. Egyptian Arabic Morphological Annotation Guidelines.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emad Mohamed</author>
<author>Behrang Mohit</author>
<author>Kemal Oflazer</author>
</authors>
<title>Annotating and Learning Morphological Segmentation of Egyptian Colloquial Arabic.</title>
<date>2012</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC),</booktitle>
<location>Istanbul.</location>
<contexts>
<context position="5146" citStr="Mohamed et al. (2012)" startWordPosition="796" endWordPosition="799">gyptian Arabic social networking corpora trained using transformation-based learning (Brill, 1995). They report 94.5% F-measure on tokenization and 87.6% on POS tagging. Their tokenization and POS tagsets are comparable to the set used by the Arabic Treebank (ATB). We do not compare to them since their data sets are not public. Stallard et al. (2012) show that unsupervised methods for learning DA tokenization can outperform MSA tokenizers on MT from Levantine Arabic to English. We do not compare to them directly since our work is on ARZ. However, we carry a similar MT experiment in Section 5. Mohamed et al. (2012) annotated a small corpus of Egyptian Arabic for morphological segmentation and learned segmentation models using memorybased learning (Daelemans and van den Bosch, 2005). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Sa</context>
<context position="15077" citStr="Mohamed et al. (2012)" startWordPosition="2447" endWordPosition="2450">tting off all clitics except for the determiner +JI Al+). Results The results are shown in Table 1. MADA-ARZ performs much better than the MADA baselines in all evaluation metrics. Comparing the two MADA-ARZ systems, it is evident that adding MSA data (ATB123) results in slightly better performance only for the Penn POS, MADA POS, and ATB Segmentation metrics. Including the MSA data results in accuracy reductions for the other metrics, but the resulting system still outperforms the MADA MSA baseline in all cases. The results are consistent for development and blind test. The CMUQ-ECA Test Set Mohamed et al. (2012) reported on the task of ARZ raw orthography morph segmentation (determining the morphs in the raw word). The CMUQ-ECA test data comprised 36 ARZ political comments and jokes from the Egyptian web site www.masrawy.com. The set contains 2,445 words including punctuation. Their best system gets a 91.9% word-level accuracy. Since MADA-ARZ modifies the spelling Tokenization OOV BLEU METEOR TER Punct 9.2 22.1 27.2 63.2 MADA ATB 5.8 24.4 29.6 60.5 MADA-ARZ ATB 4.9 25.2 29.9 59.4 Table 2: Machine translation results on the test set. “Punct” refers to the baseline which only tokenizes at punctuation. </context>
</contexts>
<marker>Mohamed, Mohit, Oflazer, 2012</marker>
<rawString>Emad Mohamed, Behrang Mohit, and Kemal Oflazer. 2012. Annotating and Learning Morphological Segmentation of Egyptian Colloquial Arabic. In Proceedings of the Language Resources and Evaluation Conference (LREC), Istanbul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum Error Rate Training for Statistical Machine Translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Conference of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<location>Sapporo, Japan.</location>
<contexts>
<context position="16526" citStr="Och, 2003" startWordPosition="2696" endWordPosition="2697">glish MT MT Experimental Settings We use the opensource Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4- gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using Minimum Error Rate Training (Och, 2003). We perform caseinsensitive evaluation in terms of BLEU, METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006) metrics. Data We trained on DA-English parallel data (Egyptian and Levantine) obtained from several LDC corpora. The training data amounts to 3.8M untokenized words on the Arabic side. The dev set, used for tuning the parameters of the MT system, has 15,585 untokenized Arabic words. The test set has 12,116 untokenized Arabic words. Both dev and test data contain two sets of reference translations. The English data is lower-cased and tokenized using simple punctuation-based </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum Error Rate Training for Statistical Machine Translation. In Proceedings of the 41st Annual Conference of the Association for Computational Linguistics, pages 160–167, Sapporo, Japan.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>Wei-</author>
</authors>
<marker>Papineni, Roukos, Ward, Wei-, </marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and Wei-</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jing Zhu</author>
</authors>
<title>BLEU: a Method for Automatic Evaluation of Machine Translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<location>Philadelphia, PA.</location>
<marker>Zhu, 2002</marker>
<rawString>Jing Zhu. 2002. BLEU: a Method for Automatic Evaluation of Machine Translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan Roth</author>
<author>Owen Rambow</author>
<author>Nizar Habash</author>
<author>Mona Diab</author>
<author>Cynthia Rudin</author>
</authors>
<title>Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking.</title>
<date>2008</date>
<booktitle>In ACL 2008: The Conference of the Association for Computational Linguistics; Companion Volume, Short Papers,</booktitle>
<location>Columbus, Ohio.</location>
<contexts>
<context position="9038" citStr="Roth et al., 2008" startWordPosition="1439" endWordPosition="1442">ications (Habash et al., 2012a; Al-Sabbagh and Girju, 2012; Eskander et al., 2013). Finally, MSA and ARZ coexist and are often used interchangeably, especially in more formal settings. The CALIMA morphological analyzer we use addresses several of these issues by modeling both ARZ and MSA together, including a limited set of inter-dialect morphology phenomena, and by mapping ARZ words into CODA orthography internally while accepting a wide range of spelling variants. 4 Approach 4.1 The MADA Approach MADA is a method for Arabic morphological analysis and disambiguation (Habash and Rambow, 2005; Roth et al., 2008). MADA uses a morphological analyzer to produce, for each input word, a list of analyses specifying every possible morphological interpretation of that word, covering all morphological features of the word (diacritization, POS, lemma, and 13 inflectional and clitic features). MADA then applies a set of models (support vector machines and N-gram language models) to produce a prediction, per word in-context, for different morphological features, such as POS, lemma, gender, number or person. A ranking component scores the analyses produced by the morphological analyzer using a tuned weighted sum </context>
</contexts>
<marker>Roth, Rambow, Habash, Diab, Rudin, 2008</marker>
<rawString>Ryan Roth, Owen Rambow, Nizar Habash, Mona Diab, and Cynthia Rudin. 2008. Arabic morphological tagging, diacritization, and lemmatization using lexeme models and feature ranking. In ACL 2008: The Conference of the Association for Computational Linguistics; Companion Volume, Short Papers, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties,</booktitle>
<pages>10--21</pages>
<location>Edinburgh, Scotland.</location>
<contexts>
<context position="5769" citStr="Salloum and Habash, 2011" startWordPosition="898" endWordPosition="901">2) annotated a small corpus of Egyptian Arabic for morphological segmentation and learned segmentation models using memorybased learning (Daelemans and van den Bosch, 2005). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA directly, and we evaluate the use of additional MSA annotated resources to our training in Section 5. 3 Arabic Dialect Challenges General Arabic Challenges Arabic, as MSA or DA, poses many challenges for NLP. Arabic is a morph</context>
</contexts>
<marker>Salloum, Habash, 2011</marker>
<rawString>Wael Salloum and Nizar Habash. 2011. Dialectal to Standard Arabic Paraphrasing to Improve ArabicEnglish Statistical Machine Translation. In Proceedings of the First Workshop on Algorithms and Resources for Modelling of Dialects and Language Varieties, pages 10–21, Edinburgh, Scotland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wael Salloum</author>
<author>Nizar Habash</author>
</authors>
<title>Dialectal Arabic to English Machine Translation: Pivoting through Modern Standard Arabic.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT),</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="5984" citStr="Salloum and Habash, 2013" startWordPosition="937" endWordPosition="940">acy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA directly, and we evaluate the use of additional MSA annotated resources to our training in Section 5. 3 Arabic Dialect Challenges General Arabic Challenges Arabic, as MSA or DA, poses many challenges for NLP. Arabic is a morphologically complex language which includes rich inflectional morphology and a number of clitics. For example, the MSA word Aî:ñJ.:ºJ�ƒð wsyktbwnhA (wa+sa+ya-ktub-uwna+hA)1 ‘and they will write it [lit. and+will+they</context>
</contexts>
<marker>Salloum, Habash, 2013</marker>
<rawString>Wael Salloum and Nizar Habash. 2013. Dialectal Arabic to English Machine Translation: Pivoting through Modern Standard Arabic. In Proceedings of the 2013 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies (NAACL-HLT), Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Snover</author>
<author>Bonnie J Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciulla</author>
<author>John Makhoul</author>
</authors>
<title>A Study of Translation Error Rate with Targeted Human Annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the Association for Machine Transaltion in the Americas (AMTA</booktitle>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="16647" citStr="Snover et al., 2006" startWordPosition="2714" endWordPosition="2717">sed SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4- gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using Minimum Error Rate Training (Och, 2003). We perform caseinsensitive evaluation in terms of BLEU, METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006) metrics. Data We trained on DA-English parallel data (Egyptian and Levantine) obtained from several LDC corpora. The training data amounts to 3.8M untokenized words on the Arabic side. The dev set, used for tuning the parameters of the MT system, has 15,585 untokenized Arabic words. The test set has 12,116 untokenized Arabic words. Both dev and test data contain two sets of reference translations. The English data is lower-cased and tokenized using simple punctuation-based rules. Systems We build three translation systems which vary in tokenization of the Arabic text. The first system applies</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciulla, Makhoul, 2006</marker>
<rawString>Matt Snover, Bonnie J. Dorr, Richard Schwartz, Linnea Micciulla, and John Makhoul. 2006. A Study of Translation Error Rate with Targeted Human Annotation. In Proceedings of the Association for Machine Transaltion in the Americas (AMTA 2006), Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Stallard</author>
<author>Jacob Devlin</author>
<author>Michael Kayser</author>
<author>Yoong Keok Lee</author>
<author>Regina Barzilay</author>
</authors>
<title>Unsupervised Morphology Rivals Supervised Morphology for Arabic MT.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>322--327</pages>
<location>Jeju Island,</location>
<contexts>
<context position="4877" citStr="Stallard et al. (2012)" startWordPosition="747" endWordPosition="750"> minimally supervised approach that only requires raw text data from several DAs, as well as a MSA morphological analyzer. They report a POS accuracy of 70.9% on a rather coarse-grained POS tagset (17 tags). Al-Sabbagh and Girju (2012) describe a supervised tagger for Egyptian Arabic social networking corpora trained using transformation-based learning (Brill, 1995). They report 94.5% F-measure on tokenization and 87.6% on POS tagging. Their tokenization and POS tagsets are comparable to the set used by the Arabic Treebank (ATB). We do not compare to them since their data sets are not public. Stallard et al. (2012) show that unsupervised methods for learning DA tokenization can outperform MSA tokenizers on MT from Levantine Arabic to English. We do not compare to them directly since our work is on ARZ. However, we carry a similar MT experiment in Section 5. Mohamed et al. (2012) annotated a small corpus of Egyptian Arabic for morphological segmentation and learned segmentation models using memorybased learning (Daelemans and van den Bosch, 2005). Their best system achieves a 91.90% accuracy on the task of morpheme-segmentation. We compare to their work and report on their test set in Section 5. There ar</context>
</contexts>
<marker>Stallard, Devlin, Kayser, Lee, Barzilay, 2012</marker>
<rawString>David Stallard, Jacob Devlin, Michael Kayser, Yoong Keok Lee, and Regina Barzilay. 2012. Unsupervised Morphology Rivals Supervised Morphology for Arabic MT. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics, pages 322–327, Jeju Island, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM - an Extensible Language Modeling Toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the International Conference on Spoken Language Processing (ICSLP),</booktitle>
<volume>2</volume>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="16200" citStr="Stolcke, 2002" startWordPosition="2640" endWordPosition="2641">sults on the test set. “Punct” refers to the baseline which only tokenizes at punctuation. of the word when it maps into CODA, we needed a manual analysis where no exact match with the gold occurs (11.8% of the time). We determined MADA-ARZ’s accuracy on their test set for morphsegmentation to be 93.2%. 5.2 Egyptian Arabic to English MT MT Experimental Settings We use the opensource Moses toolkit (Koehn et al., 2007) to build a phrase-based SMT system. We use MGIZA++ for word alignment (Gao and Vogel, 2008). Phrase translations of up to 8 words are extracted in the phrase table. We use SRILM (Stolcke, 2002) with modified Kneser-Ney smoothing to build two 4- gram language models. The first model is trained on the English side of the bitext, while the other is trained on the English Gigaword data. Feature weights are tuned to maximize BLEU (Papineni et al., 2002) on a development set using Minimum Error Rate Training (Och, 2003). We perform caseinsensitive evaluation in terms of BLEU, METEOR (Banerjee and Lavie, 2005) and TER (Snover et al., 2006) metrics. Data We trained on DA-English parallel data (Egyptian and Levantine) obtained from several LDC corpora. The training data amounts to 3.8M untok</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM - an Extensible Language Modeling Toolkit. In Proceedings of the International Conference on Spoken Language Processing (ICSLP), volume 2, pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rabih Zbib</author>
<author>Erika Malchiodi</author>
<author>Jacob Devlin</author>
<author>David Stallard</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
<author>John Makhoul</author>
<author>Omar F Zaidan</author>
<author>Chris Callison-Burch</author>
</authors>
<title>Machine translation of arabic dialects.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>49--59</pages>
<location>Montréal, Canada.</location>
<contexts>
<context position="6090" citStr="Zbib et al. (2012)" startWordPosition="956" endWordPosition="959">re are some other morphological analyzers for DA. Kilany et al. (2002) worked on ARZ, but the analyzer has very limited coverage. Their lexicon was used as part of the development of CALIMA (Habash et al., 2012b). Other efforts are not about ARZ (Habash and Rambow, 2006; Salloum and Habash, 2011). Given the similarity between MSA and DA, there has been some work on mapping DA to MSA to exploit rich MSA resources (Chiang et al., 2006; Abo Bakr et al., 2008; Salloum and Habash, 2011; Salloum and Habash, 2013). Other researchers have studied the value of simply combining DA and MSA data, such as Zbib et al. (2012) for DA to English MT. In our approach, we target DA directly, and we evaluate the use of additional MSA annotated resources to our training in Section 5. 3 Arabic Dialect Challenges General Arabic Challenges Arabic, as MSA or DA, poses many challenges for NLP. Arabic is a morphologically complex language which includes rich inflectional morphology and a number of clitics. For example, the MSA word Aî:ñJ.:ºJ�ƒð wsyktbwnhA (wa+sa+ya-ktub-uwna+hA)1 ‘and they will write it [lit. and+will+they-write-they+it]’ has two proclitics, one circumfix and one pronominal enclitic. Additionally, Arabic has a</context>
</contexts>
<marker>Zbib, Malchiodi, Devlin, Stallard, Matsoukas, Schwartz, Makhoul, Zaidan, Callison-Burch, 2012</marker>
<rawString>Rabih Zbib, Erika Malchiodi, Jacob Devlin, David Stallard, Spyros Matsoukas, Richard Schwartz, John Makhoul, Omar F. Zaidan, and Chris Callison-Burch. 2012. Machine translation of arabic dialects. In Proceedings of the 2012 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, pages 49– 59, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Imed Zitouni</author>
<author>Jeffrey S Sorensen</author>
<author>Ruhi Sarikaya</author>
</authors>
<title>Maximum entropy based restoration of arabic diacritics.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>577--584</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="3914" citStr="Zitouni et al., 2006" startWordPosition="592" endWordPosition="595">scusses related work. Section 3 presents the challenges of processing Arabic dialects. Section 4 outlines our approach. And Section 5 presents and discusses our evaluation results. 426 Proceedings of NAACL-HLT 2013, pages 426–432, Atlanta, Georgia, 9–14 June 2013. c�2013 Association for Computational Linguistics 2 Related Work There has been a considerable amount of work on MSA morphological analysis, disambiguation, partof-speech (POS) tagging, tokenization, lemmatization and diacritization; for an overview, see (Habash, 2010). Most solutions target specific problems, such as diacritization (Zitouni et al., 2006), tokenization or POS tagging (Diab et al., 2007). In contrast, MADA provides a solution to all of these problems together (Habash and Rambow, 2005). Previous work on DA morphological tagging focused on creating resources, using noisy or incomplete annotations, and using unsupervised/semisupervised methods. Duh and Kirchhoff (2005) adopt a minimally supervised approach that only requires raw text data from several DAs, as well as a MSA morphological analyzer. They report a POS accuracy of 70.9% on a rather coarse-grained POS tagset (17 tags). Al-Sabbagh and Girju (2012) describe a supervised t</context>
<context position="12830" citStr="Zitouni et al. (2006)" startWordPosition="2072" endWordPosition="2075">ll 26.2 74.3 65.4 27.0 75.4 64.7 ATB Segmentation 90.6 97.4 97.6 90.5 97.4 97.5 Table 1: Evaluation metrics on the ATB-ARZ development and test sets. The best results are bolded. We compare MADA and MADA-ARZ with different training data conditions. Definitions of metrics are in Section 5.1. MSA training data is ATB-123. ARZ training data is ATB-ARZ. ALL training data is ATB-123 plus ATB-ARZ. (Maamouri et al., 2004); and ATB-ARZ, the Egyptian Arabic Treebank (parts 1-5) (Maamouri et al., 2012a). For ATB-123 training, we use all of parts 1 and 2 plus the training portion of ATB-3 (as defined by Zitouni et al. (2006)); for development and test, we split Zitouni et al. (2006)’s devtest set into two. We sub-divide ATB-ARZ into development, training, and test sets (roughly a 10/80/10 split). The ATB-ARZ training data has 134K words, and the ATB-123 training data has 711K words. We evaluate two systems. We used the latest release of MADA for MSA (v3.2), trained on ATB123 (MSA), as our baseline. For MADA-ARZ, we compare two training settings: using ATB-ARZ (ARZ) and combining ATB-ARZ with ATB-123 (ALL). We present our results on the ATB-ARZ development and blind test sets (21.1K words and 20.4K words). Tuning </context>
</contexts>
<marker>Zitouni, Sorensen, Sarikaya, 2006</marker>
<rawString>Imed Zitouni, Jeffrey S. Sorensen, and Ruhi Sarikaya. 2006. Maximum entropy based restoration of arabic diacritics. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 577–584, Sydney, Australia.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>