<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.235372">
<title confidence="0.853587">
Commentary on Daelemans, Gillis, and Durieux
</title>
<author confidence="0.810715">
Prahlad Gupta&apos;
</author>
<affiliation confidence="0.64495">
(Carnegie Mellon University)
</affiliation>
<bodyText confidence="0.999930666666667">
The article by Daelemans et al. bears on an important question about the adequacy of
the &amp;quot;Principles and Parameters&amp;quot; frame work as the basis of a process account of language
learning (exemplified, for instance, by the work of Dresher and Kaye 1990). As Gupta
and Touretzky (1991, 1994) have pointed out, a learning system based on a particular
linguistic description (of metrical phenomena, for example) can at best learn whatever
is describable within that linguistic formalism; however, important aspects of real-
world stress data do not appear amenable to parameter-based description, and are
therefore unlearnable for a parameter-based system.
In the present work, the authors make a careful examination of main stress as-
signment in Dutch, showing that the consensus (parameterized) linguistic analysis for
Dutch yields correct stress for only 81.1% of the words in a representative corpus. The
problem is that when words are represented only by their syllable weights (as required
by metrical theory), they can be ambiguous with respect to stress assignment.
A parameter-based procedure therefore can at best learn only the &amp;quot;regular&amp;quot; 81.1%
of the data. By assuming certain lexically specified exception markings, the framework
can be extended to allow characterization of a further 16% of the data; however,
the analysis then loses its principled, parameterized form. Furthermore, it offers no
account of how these &amp;quot;irregular&amp;quot; data could be learned, except by rote.
The authors contrast this with results they obtained using instance-based learning
(IBL); their system was trained on 90% of the corpus and tested on the other 10%.
With an input representation encoding only syllable weight, IBL performed at 81.26%
correct, which consisted of all the regulars but none of the irregulars, mirroring the
descriptive adequacy of the linguistic formalism based on the same representation.
When the input representation encoded phonemic information (instead of syllable
weight), IBL performed at 88% correct, which included most of the regulars and a
substantial proportion of the irregulars. Rote learning would have to be invoked for
the remaining 12% of the data. However, this is probably about the best that can be
done given the idiosyncracies of Dutch stress, and it is substantially less than the
20% rote learning required in the linguistic scheme. The difference lies in the use of
phonemic information.
Choosing between these schemes is largely a matter of preference, and the authors&apos;
results do not rule out the linguistic alternative. Rather, the importance of their work
lies, first, in highlighting the inadequacy of a parameter-based framework for characterizing
and learning Dutch stress assignment, and second, in its demonstration of the utility
of phonemic information in learning about stress. Both these results deserve to be taken
seriously by metrical phonologists.
</bodyText>
<sectionHeader confidence="0.81116" genericHeader="abstract">
References Annual Conference of the Cognitive Science
</sectionHeader>
<reference confidence="0.546181142857143">
Dresher, B. E., and Kaye, J. D. (1990). &amp;quot;A Society, 334-339. Lawrence Erlbaum.
computational learning model for metrical Gupta, P., and Touretzky, D. S. (1994).
phonology.&amp;quot; Cognition, 34,137-195. &amp;quot;Connectionist models and linguistic
Gupta, P., and Touretzky, D. S. (1991). &amp;quot;What theory: Investigations of stress systems in
a perceptron reveals about metrical language.&amp;quot; Cognitive Science, 18(1), 1-50.
phonology.&amp;quot; In Proceedings, 13th
1 Department of Psychology, Carnegie Mellon University, Pittsburgh, PA 15213.
</reference>
<page confidence="0.99769">
452
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.575092">
<title confidence="0.999132">Commentary on Daelemans, Gillis, and Durieux</title>
<author confidence="0.99173">Prahlad Gupta&apos;</author>
<affiliation confidence="0.998495">(Carnegie Mellon University)</affiliation>
<abstract confidence="0.989231277777778">The article by Daelemans et al. bears on an important question about the adequacy of &amp;quot;Principles and Parameters&amp;quot; frame work as the basis of a account language learning (exemplified, for instance, by the work of Dresher and Kaye 1990). As Gupta and Touretzky (1991, 1994) have pointed out, a learning system based on a particular linguistic description (of metrical phenomena, for example) can at best learn whatever is describable within that linguistic formalism; however, important aspects of realworld stress data do not appear amenable to parameter-based description, and are therefore unlearnable for a parameter-based system. In the present work, the authors make a careful examination of main stress assignment in Dutch, showing that the consensus (parameterized) linguistic analysis for Dutch yields correct stress for only 81.1% of the words in a representative corpus. The problem is that when words are represented only by their syllable weights (as required by metrical theory), they can be ambiguous with respect to stress assignment. A parameter-based procedure therefore can at best learn only the &amp;quot;regular&amp;quot; 81.1% of the data. By assuming certain lexically specified exception markings, the framework can be extended to allow characterization of a further 16% of the data; however, the analysis then loses its principled, parameterized form. Furthermore, it offers no account of how these &amp;quot;irregular&amp;quot; data could be learned, except by rote. authors contrast this with results they obtained using learning (IBL); their system was trained on 90% of the corpus and tested on the other 10%. With an input representation encoding only syllable weight, IBL performed at 81.26% correct, which consisted of all the regulars but none of the irregulars, mirroring the descriptive adequacy of the linguistic formalism based on the same representation. When the input representation encoded phonemic information (instead of syllable weight), IBL performed at 88% correct, which included most of the regulars and a substantial proportion of the irregulars. Rote learning would have to be invoked for the remaining 12% of the data. However, this is probably about the best that can be done given the idiosyncracies of Dutch stress, and it is substantially less than the 20% rote learning required in the linguistic scheme. The difference lies in the use of phonemic information. Choosing between these schemes is largely a matter of preference, and the authors&apos; results do not rule out the linguistic alternative. Rather, the importance of their work first, in highlighting the of a parameter-based framework characterizing learning Dutch stress assignment, and second, in its demonstration of the phonemic information learning about stress. Both these results deserve to be taken seriously by metrical phonologists.</abstract>
<note confidence="0.9666768">References Annual Conference of the Cognitive Science Lawrence Erlbaum. Dresher, B. E., and Kaye, J. D. (1990). &amp;quot;A computational learning model for metrical Gupta, P., and Touretzky, D. S. (1994). &amp;quot;Connectionist models and linguistic theory: Investigations of stress systems in Science, 1-50. Gupta, P., and Touretzky, D. S. (1991). &amp;quot;What a perceptron reveals about metrical In 13th 1 Department of Psychology, Carnegie Mellon University, Pittsburgh, PA 15213. 452</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>B E Dresher</author>
<author>J D Kaye</author>
</authors>
<title>A Society, 334-339. Lawrence Erlbaum. computational learning model for metrical</title>
<date>1990</date>
<journal>Cognitive Science,</journal>
<booktitle>In Proceedings, 13th</booktitle>
<volume>18</volume>
<issue>1</issue>
<pages>1--50</pages>
<marker>Dresher, Kaye, 1990</marker>
<rawString> Dresher, B. E., and Kaye, J. D. (1990). &amp;quot;A Society, 334-339. Lawrence Erlbaum. computational learning model for metrical Gupta, P., and Touretzky, D. S. (1994). phonology.&amp;quot; Cognition, 34,137-195. &amp;quot;Connectionist models and linguistic Gupta, P., and Touretzky, D. S. (1991). &amp;quot;What theory: Investigations of stress systems in a perceptron reveals about metrical language.&amp;quot; Cognitive Science, 18(1), 1-50. phonology.&amp;quot; In Proceedings, 13th</rawString>
</citation>
<citation valid="false">
<pages>15213</pages>
<institution>Department of Psychology, Carnegie Mellon University,</institution>
<location>Pittsburgh, PA</location>
<marker>1</marker>
<rawString>Department of Psychology, Carnegie Mellon University, Pittsburgh, PA 15213.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>