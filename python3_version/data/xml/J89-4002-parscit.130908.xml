<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.660031">
NATURAL LANGUAGE GENERATION FROM PLANS
</title>
<author confidence="0.918238">
Chris Mellish, and Roger Evans
</author>
<affiliation confidence="0.737306666666667">
School of Cognitive and Computing Sciences
University of Sussex
Falmer
</affiliation>
<address confidence="0.352012">
Brighton BN1 9QN
United Kingdom
</address>
<bodyText confidence="0.998181125">
This paper addresses the problem of designing a system that accepts a plan structure of the sort
generated by AI planning programs and produces natural language text explaining how to execute the
plan. We describe a system that generates text from plans produced by the NONLIN planner (Tate
1976).
The results of our system are promising, but the texts still lack much of the smoothness of
human-generated text. This is partly because, although the domain of plans seems a priori to provide
rich structure that a natural language generator can use, in practice a plan that is generated without the
production of explanations in mind rarely contains the kinds of information that would yield an
interesting natural language account. For instance, the hierarchical organization assigned to a plan is
liable to reflect more a programmer&apos;s approach to generating a class of plans efficiently than the way
that a human would naturally &amp;quot;chunk&amp;quot; the relevant actions. Such problems are, of course, similar to
those that Swartout (1983) encountered with expert systems. In addition, AI planners have a restricted
view of the world that is hard to match up with the normal semantics of natural language expressions.
Thus constructs that are primitive to the planner may be only clumsily or misleadingly expressed in
natural language, and the range of possible natural language constructs may be artificially limited by the
shallowness of the planner&apos;s representations.
</bodyText>
<sectionHeader confidence="0.999442" genericHeader="abstract">
1 INTRODUCTION
</sectionHeader>
<bodyText confidence="0.9966734">
Planning is a central concept in Artificial Intelligence,
and the state of the art in planning systems allows quite
complex plans to be produced with very little human
guidance. If these plans are to be for human consump-
tion, they must be explained in a way that is compre-
hensible to a human being. There is thus a practical
reason for considering ways of generating natural lan-
guage from plans. There are also theoretical reasons
why plans are a good domain for studying natural
language generation. Although there may be a great deal
of material in a given plan, there is a kind of consensus
among planning researchers on what sort of information
a plan is likely to contain. Thus it is possible that
interesting general principles about producing explana-
tions of plans can be formulated, independently of the
domains in which the plans are produced. This prop-
erty, of providing a relatively formally defined and yet
domain-independent input, makes plans very attractive
from a natural language generation point of view.
This paper discusses a system that accepts a plan
structure of the sort generated by Al planning programs
and produces natural language text explaining how to
execute the plan. Our objective in building this system
has been to develop a clear model of a possible archi-
tecture for a language generation system that makes use
of simple, well-understood, and restricted computa-
tional techniques. We feel that too much of the work in
this area has been characterized by the use of arbitrary
procedures, which often do not provide a clear basis for
future work. We believe that by providing a simple yet
nontrivial account of language generation, we can con-
tribute at least by providing a &amp;quot;straw man&amp;quot; with known
limitations, with respect to which other work can be
compared.
Describing plans represents in many ways an obvious
</bodyText>
<footnote confidence="0.8309976">
Copyright 1989 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted provided
that the copies are not made for direct commercial advantage and the CL reference and this copyright notice are included on the first page. To
copy otherwise, or to republish, requires a fee and/or specific permission.
0362-613X/ 89 /010233-249—$03.00
Computational Linguistics Volume 15, Number 4, December 1989 233
</footnote>
<note confidence="0.884661">
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<figureCaption confidence="0.997751">
Figure 1 Action Graph of a Nonlinear Plan.
</figureCaption>
<bodyText confidence="0.99971395">
application of natural language generation, and our
approach has been to tackle this problem in a fairly
straightforward way, informed by the state of the art as
we perceive it. The results from our system are prom-
ising, but our texts lack much of the smoothness of
human-generated explanations. An analysis of the rea-
sons behind some of the system&apos;s failures points to a
number of deep problems concerning the connection
between Al plans and natural language explanations.
In the next section we briefly introduce the inputs
and structure of the language generation system. We
then run through the parts of the system by showing a
worked example. The core of this paper concerns the
mapping from plans to messages, which can be thought
of as abstract descriptions of natural language dis-
courses. We describe our repertoire of messages, how
plan structures are mapped onto messages, and how
messages are simplified. Finally we look at further
examples of the system&apos;s output and analyze some of its
failures and successes.
</bodyText>
<sectionHeader confidence="0.98296" genericHeader="method">
2 SYSTEM OVERVIEW
</sectionHeader>
<subsectionHeader confidence="0.947159">
2.1 PLANS AND PLANNERS
</subsectionHeader>
<bodyText confidence="0.999533780487805">
For this project, we have adopted a traditional Al view
of planning and plans. According to this view, the task
of planning to achieve a goal is that of finding a set of
(instantaneous) actions which, when performed, will
transform the world as it is (the &amp;quot;initial state&amp;quot;) to a new
world (the &amp;quot;final state&amp;quot;), which is similar to the present
world, but where in addition the goal is true.
We assume that the plans produced by our planner
are nonlinear (almost standard with Al planners since
NOAH; Sacerdoti 1975); that is, they only partially
specify the order in which the actions are to be per-
formed. Furthermore we assume that the time con-
straints involved in a plan can be displayed in an action
graph, where an action is represented by a point and a
line going rightward from one action to another indi-
cates that the first action must take place before the
second (this is true of most, but not all, Al plans—see
for instance Tsang 1986). Figure 1 shows an action
graph for a nonlinear plan for building a house.
We further assume that plans are in general hierar-
chical. By this we mean that the planner operates in a
hierarchical manner (almost standard in Al planners
since ABSTRIPS; Sacerdoti 1973), first producing a
plan specified at a very abstract level, and then succes-
sively refining it until the required level of detail is
obtained. At each stage a process of criticism may
impose new orderings between actions whose relative
ordering seemed to be unconstrained at the previous
levels of abstraction. For us, the history of this hierar-
chical expansion must be present in the final plan, since
we assume no explicit interaction with the planner itself
while it is operating. (We shall return in Section 5 to the
question of whether the hierarchical plan structure is in
fact a sufficient description of the planner&apos;s processing.)
For concreteness, we have based our system on the
output of a single Al planning program, even though
there are a number of planning systems that could
produce a similar style of output. The input to our
natural language generator, then, is the translation into
Prolog of the set of datastructures created by Tate&apos;s
(1976) NONLIN planner.
</bodyText>
<subsectionHeader confidence="0.47628">
.2.2 SYSTEM STRUCTURE AND PARAMETRIZATION
</subsectionHeader>
<bodyText confidence="0.99988280952381">
We have set ourselves the goal of generating from a
NON LIN plan a single natural language text that ex-
plains the actions to be performed and why things have
to be done this way. To a large extent the explanatory
power of such an account depends on what information
is represented in the plan in the first place. Although a
system that produces a single monolog from a plan is
more restricted than, say, an interactive system that can
be asked to explain parts of the plan selectively, a
number of possible applications do suggest themselves
(for instance, the automatic generation of instruction
manuals), and the monolog task does provide us with an
excellent way of studying the problems of automatically
generating large texts.
We have attempted to factor out domain-dependence
as much as possible in the generation system by having
it rely heavily on knowledge expressed in a declarative
fashion. Given a particular target natural language, a
specific lexicon then needs to be provided for the
domain in which the plans are to be generated (we have
considered cookery, house building, car maintenance,
</bodyText>
<page confidence="0.736405">
234 Computational Linguistics Volume 15, Number 4, December 1989
</page>
<note confidence="0.826579">
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<bodyText confidence="0.9999528125">
central heating installation, and the &amp;quot;blocks world&amp;quot;).
This provides linguistic representations corresponding
to the objects, states, and actions that will arise in
generated plans. These lexical representations are sup-
plemented by domain-dependent rewrite rules that can
be used to reveal hidden additional structure in the
planner&apos;s representation of the domain. Even with the
target natural language fixed and a particular domain
given, there are still in general many possible plans from
which natural language could potentially be generated
(indeed, many man-years of Al research were devoted
to developing plans simply in the &amp;quot;blocks world&amp;quot;).
Our natural language generation system can be
thought of as consisting of four processing stages,
centering on the construction and manipulation of an
expression of our special message language, as follows:
</bodyText>
<sectionHeader confidence="0.5063845" genericHeader="method">
Message Planning
Message Simplification
Compositional Structure Building
Linearization and Output
</sectionHeader>
<bodyText confidence="0.999841632653061">
Message Planning is the interface between the genera-
tor and the outside world. At this stage, the generator
must decide &amp;quot;what to say,&amp;quot; i.e., which objects and
relationships in the world are to be expressed in lan-
guage and in roughly what order. The output of the
message planner is an expression in the message lan-
guage which, following McDonald, we will call the
message. The idea is that message planning may be a
relatively simple process and that the resulting message
is then &amp;quot;cleaned up&amp;quot; and simplified by localized rewrite
operations on the expression (&amp;quot;Message Simplifica-
tion&amp;quot;).
The message is a nonlinguistic object, and the task of
structure building is to build a first description (a
functional description much as in Functional Grammar;
Kay 1979) of a linguistic object that will realize the
intended message. We assume here that a &amp;quot;linguistical-
ly motivated&amp;quot; intermediate representation of the text is
of value (this is argued for, for instance, by McDonald
1983). Our structure builder is purely compositional,
and so the amount of information that it can take into
account is limited. We treat structure-building as a
recursive descent traversal of the message, using rules
about how to build linguistic structures that correspond
to local patterns in the message. During this, a simple
grammatical constraint satisfaction system is used, to
enforce grammaticality and propagate the consequences
of syntactic decisions. The recursive descent terminates
when it reaches elements of the message for which there
are entries in the system&apos;s lexicon.
Once a structural description of a text has been
produced, it is necessary to produce a linear sequence
of words. Our structural descriptions contain only dom-
inance information and no ordering information, and so
a separate set of rules is used to produce a linearization.
This is akin to the ID/LP distinction used in GPSG
(Gazdar et al. 1985).
The resulting system is similar to McDonald&apos;s (1983)
model, in that it is basically a direct production system
that utilizes an intermediate syntactic representation.
The system is also similar to McDonald&apos;s in its empha-
sis on local processing, although there is no attempt to
produce a psychological model in our work. Our con-
straint satisfaction system is implemented efficiently by
unification, however, so that the effects of local deci-
sions can propagate globally without the need for ex-
plicit global variables. This is used, for instance, to
enforce a simple model of pronominalization (based on
that of Dale 1986).
</bodyText>
<sectionHeader confidence="0.990777" genericHeader="method">
3 A WORKED EXAMPLE
</sectionHeader>
<bodyText confidence="0.994790131578947">
As an illustration of the various mechanisms contained
within the system, we present in this section an example
of the system in operation. The example is taken from a
demonstration application, showing how the language
generator might be attached to an expert system. The
scenario is as follows: we have an expert system whose
function is to diagnose car-starting faults. The expert
system asks questions to which the user can either give
an answer or type &amp;quot;how,&amp;quot; meaning &amp;quot;how can I find out
the answer?&amp;quot; In this latter case, the expert system
invokes a planner to work out what the user has to do,
and passes the resultant plan to the language generator,
which produces text giving instructions to the user. The
expert system then asks its original question again.
In our demonstration system, the expert system is in
fact just a binary decision tree. At each internal node
there is a yes-no question and a planner goal, to be used
if the user responds with &amp;quot;how.&amp;quot; At each leaf node
there is a recommendation and a planner goal—here
&amp;quot;how&amp;quot; is interpreted as &amp;quot;how do I carry out your
recommendation?&amp;quot; To make the demonstration more
varied, the system keeps track of what it has already
told the user to do, so that, for example, accessing the
carburetor jet will be described differently depending on
whether the air filter (which is on top of the carburetor)
has already been checked.
We pick up the example at a point where it has been
ascertained that the battery is OK, but that there is no
spark on the spark plugs. The next step is to test for a
spark at the distributor. The system asks:
Is there a spark at the distributor?
and we respond with &amp;quot;how.&amp;quot; The NONLIN plan goal
associated with the above question is
{tested dist_spark}
that is, &amp;quot;make a plan to achieve the state in which we
have tested the distributor spark.&amp;quot; The planner assumes
that we have done nothing already and are standing at
the front of the car, looking at the engine.
</bodyText>
<subsectionHeader confidence="0.997608">
3.1 THE PLAN
</subsectionHeader>
<bodyText confidence="0.972022">
The plan produced by NONLIN for this example case is
a totally ordered sequence of six actions as follows:
</bodyText>
<figure confidence="0.7876267">
Computational Linguistics Volume 15, Number 4, December 1989 235
Chris Mellish and Roger Evans Natural Language Generation from Plans
{act {detached dirLcover engine}} detach the dirt cover from the engine
{act {detached coiLlead dist_cap}} detach the coil lead from the distributor
cap
fact {located mech cab}} go to the cab
{act {started engine}} start the engine
{act {located mech frontofcar}} go to the front of the car
fact {observed spark coiLleacl}} observe whether there is a spark on the
coil lead
</figure>
<bodyText confidence="0.999941142857143">
However, although this is the plan at its lowest level,
the plan structure returned by NONLIN also includes
the hierarchical expansion history of the plan. The plan
started out as just the original goal itself, and was
successively expanded to greater levels of detail until
the primitive actions given above were obtained. The
expansion hierarchy for this plan is shown in Figure 2.2
As well as this hierarchical structure (and the order-
ing information not shown in this diagram), NONLIN
returns information about preconditions in the plan—
where they are needed and where they are established.
So, for example, the condition {goal {located mech cab}}
is required by node 14 and made true by node 13 (and
made false again by node 15).
</bodyText>
<subsectionHeader confidence="0.999669">
3.2 THE TEXT
</subsectionHeader>
<bodyText confidence="0.9984679">
All this information is extracted from NONLIN&apos;s data
structures, converted into Prolog clauses, and passed to
the language generator. The generator looks for ways to
break up and organize the information in the plan to
produce comprehensible text. This process is described
in more detail in Section 4, but to see what it does in this
case, we shall concentrate on just one fragment of the
above plan, namely nodes 3, 5, 6, 7, and 8. These nodes
represent the expansion of the following NONLIN
operator:
</bodyText>
<equation confidence="0.439590578947368">
actschema testecL4
pattern {act {tested dist_spark}}
expansion
goal {goal {detached coiLlead dist_cap}}
goal {goal {started engine}}
goal {goal {located mech frontofcar}}
goal {goal {observed spark coiLlead}}
orderings
2 —&gt; 4
3 —&gt; 4
conditions
unsupervised {goal {accessible dist}} at self
supervised {goal {detached coiLlead
dist_cap}} at 4 from 1
supervised {goal {located mech frontofcar}}
at 4 from 3
supervised {goal {started engine}} at 4 from
2
end;
</equation>
<bodyText confidence="0.999257181818182">
This operator expands the high level action &amp;quot;do some-
thing that causes the distributor spark to have been
tested&amp;quot; (that is, &amp;quot;test the distributor spark&amp;quot;) into four
subgoals (not actions, since if they are already in effect,
nothing further needs to be done), the first three of
which must preceed the last. Thus the plan here is to
ensure that the coil lead is detached from the distributor
cap, the engine is started, and the mechanic is at the
front of the car, and then to observe whether there is a
spark on the coil lead.
The subplan gives rise to the following piece of text:
</bodyText>
<sectionHeader confidence="0.693114" genericHeader="method">
TESTING THE DISTRIBUTOR SPARK
</sectionHeader>
<bodyText confidence="0.9747345">
Testing the distributor spark involves detaching the coil
lead from the distributor cap, starting the engine, going
</bodyText>
<listItem confidence="0.98968975">
1: (goal (tested clist_sparic))
2: (goal (accessible dist))
3: (act (tested dist_spark) )
4: (act (accessible dist))
5: (goal (detached coil_lead dist_cap))
6: (goal (started engine)}
7: (goal (located mech frontofcar}}
8: (goal (observed spark coil_lead))
9: (goal (detached dirt_cover engine))
10: (goal (located mech cab))
11: (act (detached dirt_cover engine))
12: (act (detached coil_lead clist_cap)}
13: (act (located mech cab) )
14: (act (started engine))
15: (act (located mech frontofcar))
16: (act (observed spark coil_lead))
</listItem>
<figureCaption confidence="0.972221">
Figure 2 Expansion Hierarchy.
</figureCaption>
<page confidence="0.801329">
236 Computational Linguistics Volume 15, Number 4, December 1989
</page>
<note confidence="0.502972">
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<construct confidence="0.8674676">
to the front of the car and then observing whether the
coil lead sparks.
If you go to the front of the car now you will not be
at the wheel afterwards. However in order to start the
engine you must be at it. Therefore before going to the
front of the car you must start the engine.
If you start the engine now you will not be at the front
of the car afterwards. However in order to detach the
coil lead from the distributor cap you must be at the
front of the car. Therefore before starting it you must
detach the coil lead from the distributor cap.
Detach the coil lead from the distributor cap. After
this start the engine. After this go to the front of the car.
After this observe whether the coil lead sparks.
You have now finished testing the distributor spark.
</construct>
<bodyText confidence="0.999823444444444">
Notice that this text is not just a description of the
actions as specified by the plan operator. Nor is it the
fully detailed plan of everything to be done. It is a
description of the plan operator in the context of the
current plan, embellished with additional useful infor-
mation from that context. It includes references to
actions at several different levels of abstraction, as well
as information about ordering constraints present in the
plan but not present in the basic plan operator.
</bodyText>
<subsectionHeader confidence="0.996662">
3.3 THE MESSAGE
</subsectionHeader>
<bodyText confidence="0.9999312">
The first step in the generation of this text is to convert
the plan data into an expression in the generator&apos;s
intermediate message language. The message language
and the strategies for carrying out this conversion are
discussed more fully in Section 4; here we concentrate
on those aspects particularly relevant to this text.
The overall strategy applied to our subplan is to
construct an embedding: an introduction-body-conclu-
sion structure in which the introduction explains how
the action is expanded, the body explains how to
execute the expansion, and the conclusion makes the
point that by executing the expansion, the higher level
action is acheived. This strategy is appropriate because
the body of the expansion is relatively simple. For more
complex examples, where it is not practical to attempt
to describe the expansion merely as an introductory
sentence of a paragraph, an alternative strategy would
be employed.
This strategy decision gives us the general shape of
the text, and the components of the embedding are
straightforwardly constructed, by reference to the local
&amp;quot;shape&amp;quot; of the plan fragment. Here the actions are
linearly ordered, which suggests presenting them in the
order of execution. At the same time the message is
embellished with the justifications for the action order-
ing. In the above plan operator, the first three actions
were unordered, but lower level considerations (con-
cerning where the mechanic is at a given time) impose
an ordering on them in the actual plan returned. Mes-
sage elements are added to explain these ordering
requirements, and in this case these necessarily appeal
to the lower level actions of moving about.
The resulting message expression is too large for
easy display, so we shall concentrate on a small part of
it, the part corresponding to the three sentences:
</bodyText>
<construct confidence="0.81293625">
If you go to the front of the car now you will not be
at the cab afterwards. However in order to start the
engine you must be at it. Therefore before going to the
front of the car you must start the engine.
</construct>
<figure confidence="0.50832">
The initial message expression for this text is:
implies (
contra_seq (
hypo_result (
user,
achieve (goal (located (mech, front ofcar))),
not (goal (located (mech, cab)))),
prereqs (
user,
then (wait ([ ]), achieve (goal (started
(engine)))),
goal (located (mech, cab)))),
neccbefore ( user,
then (wait ([ ]), achieve (goal (started
(engine)))),
achieve (goal (located (mech, frontofcar)))))
</figure>
<bodyText confidence="0.99979">
where expressions like goa1(located(mech,frontofca,r))
and goal(started(engine)) are straight NONLIN ex-
pressions, translated literally into Prolog. This expres-
sion can be read approximately as &amp;quot;the hypothetical
result of going to the front of the car is that you will not
be in the cab, and this contrasts with the prerequisite of
being in the cab to start the engine. This combination
implies you should start the engine before you go to the
front of the car.&amp;quot; And of course, that is more or less
what the produced text says.
</bodyText>
<subsectionHeader confidence="0.822334">
3.4 SIMPLIFYING THE MESSAGE
</subsectionHeader>
<bodyText confidence="0.999928272727273">
The above message contains a number of redundancies,
which will lead to inelegant text if it is used for gener-
ation. First of all, it contains various occurrences of
wait(H) (the action of waiting for nothing). These are
inserted because in general at certain points of the
subplan being explained, one is forced to wait for the
conclusion of actions being performed in other sub-
plans; this time, however, there are no such critical
actions in other parts of the plan. Second, the NONLIN
expressions have been inserted verbatim, without any
consideration of whether they could be expressed more
elegantly in the message language. Message simplifica-
tion concerns rewriting the message expression gener-
ated by message planning into one that is &amp;quot;simpler&amp;quot; in
some sense. This is achieved by applying rewrite rules
to components of the whole message. Two kinds of
rewrite rules are used: the first kind perform domain-
independent structural simplifications to message ex-
pressions, and the second domain- or language-depen-
dent alterations. For example, the following two rules
together dispose of the redundant wait([ ]) terms of the
above message ([ ] denotes the empty action here):
</bodyText>
<equation confidence="0.9928825">
wait([ ]) —&gt; [ ].
then(H,X) —&gt; X.
</equation>
<bodyText confidence="0.968374321428571">
Computational Linguistics Volume 15, Number 4, December 1989 237
Chris Mellish and Roger Evans Natural Language Generation from Plans
These are to be read as rewrite rules, with the expres-
sions on the left of the &amp;quot;--&gt;&amp;quot; being rewritten to the
expressions on the right. Variables are denoted by
names beginning with capital letters. The operation of
these rules is entirely domain-independent. One of the
domain-dependent rules rewrites mech (the mechanic)
as user, to indicate that the mechanic is the same as the
person to whom the instructions are being given. An-
other set of rules rewrites states into a form where the
affected person or object is explicit (this representation
allows the system to collapse together multiple states
involving the same person):
goal (located (X,Y)) —&gt; state (X, located (Y)).
More substantial examples include the following rules
for talking about moving around:
achieve (state (user, located (Y))) go_to (user,Y).
result (go_to (X,Y),state (user, located (Y))) —&gt;
do (go_to (X,Y)).
The first causes a phrase such as &amp;quot;get to be at the front
of the car&amp;quot; to be rewritten as &amp;quot;go to the front of the
car.&amp;quot; The second removes redundancy in a sentence
like &amp;quot;Go to the front of the car and you will be at the
front of the car,&amp;quot; rewriting it as simply &amp;quot;Go to the front
of the car.&amp;quot;
Once all the rewrite rules have been applied, our
simplified example message looks like this:
</bodyText>
<equation confidence="0.842167692307692">
implies (
contra_seq (
hypo_result (
user,
go_to (user, function (front, car)),
state (user, not (located (cab)))),
prereqs (
user,
start (engine),
state (user, located (cab)))),
neccbefore (user,
start (engine),
go_to (user, function (front, car))))
</equation>
<subsectionHeader confidence="0.972764">
3.5 COMPOSITIONAL STRUCTURE BUILDING
</subsectionHeader>
<bodyText confidence="0.999659411764706">
The next stage is to build a linguistic structure from this
message expression. The structure-building component
uses an ordered set of rules for mapping from local
message patterns to linguistic structures. It is similar to
the system described in Chester (1976) in the local
nature of its operation, but Chester builds sentences
directly, rather than via structural representations.
Mann et al. (1982) would call our system a &amp;quot;direct
translation&amp;quot; system. A system built in this fashion has
the advantage of a very simple control structure and has
the potential of having its principles expressed in mod-
ular, independent rules.
Our linguistic structural descriptions are similar to
the functional descriptions used in Functional Grammar
(Kay 1979; Kay 1984). For example, the following is a
slightly simplified version of the rule used to realize the
hypo_result construct above:
</bodyText>
<equation confidence="0.971141428571429">
hypo_result (Agent, Act, State) —&gt;
[sa.mesentence,
conin = [root = &apos;if],
first =
[s,
agent = [$Agent],
pred = [active,
morph = pres,
$Act,
adv =+ [ap, adv_word=[root=now]]]],
rest =
[s,
pred =
[VP,
aux = [root = will],
pred =
[vP,
$State,
morph = in!,
adv =+ [ap,
adv_word=[root=afterwards]]]]]].
</equation>
<bodyText confidence="0.969871552631579">
In this rule, the left hand side of the —&gt; is a Prolog
pattern to be matched with part of the message (symbols
beginning with uppercase letters represent variables,
which are to match subexpressions of the message). The
righthand side is a functional description, describing the
English phrase that is to render that part. In these
functional descriptions, expressions preceded by dollar
signs represent the places where further information
will be contributed by the expansion of subparts of the
message. Thus the &amp;quot;agent&amp;quot; value is obtained by recur-
sively matching the value of the variable Agent (that is,
the first argument in the hypo_result term) against the
structure rules.
This rule is responsible for sentences like:
If you start the engine now you will not be at the front
of the car afterwards.
The rule provides the basic template for the sentence: it
is a combination of two sentences using the conjunction
&amp;quot;if.&amp;quot; The first sentence is present tense active, with
agent specified by the Agent argument and predicate by
the Act argument, and has an adverbial modifer &amp;quot;now.&amp;quot;
The second sentence is a future tense expression of the
State given as argument, with adverbial modifier &amp;quot;af-
terwards.&amp;quot; The presence of samesentencer ensures
that the whole is a single sentence and that the two
subclauses have the same focus.
The recursive structure building process &amp;quot;bottoms
out&amp;quot; when a message element is reached for which a
linguistic realization appears in the domain-dependent
lexicon. Domain states and properties (Section 4.1) are
provided with lexical entries that describe how to
realize them as VPs. Such entries could be written as
structure building rules in the same format as the above
hypo_result rule, but in practice it is convenient to use
a more compact notation:
lx (accessible, be, [attr: @ accessible]).
lx (answer, answer, [obj: @ the question&apos;]).
lx (start (Z), start, [obj: Z]).
</bodyText>
<page confidence="0.756918">
238 Computational Linguistics Volume 15, Number 4, December 1989
</page>
<note confidence="0.43693">
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<bodyText confidence="0.999881578313253">
These entries indicate how each of accessible (a prop-
erty), answer, and start(Z) (actions) can be realized in
English, by providing a verb and a specification for the
complements to follow it. In the first two, the comple-
ment phrases are specified directly as constant strings
(indicated by the `@&apos; sign). In the last one, the filler of
the obj role (the direct object) will be whatever phrase
is used to realize the object Z being started. Additional
rules provide possible fixed phrases to realize such
domain objects:
referent (engine, @engine).
When a domain object like engine comes to be realized,
either the fixed phrase provided (prefixed by &apos;the&apos;) will
be used, or a pronoun with the appropriate gender and
number will be chosen. It is clearly a limitation of our
system that no other possibilities are currently allowed,
but in some sense this reflects the fact that plans come
with a great deal of information about the actions to be
performed but very little information about the objects
involved in them.
Structure building rules are ordered, so rules for
more specific patterns can be placed before rules for
less specific ones, without the latter having to explicitly
provide negative conditions. In addition, rule applica-
tion is deterministic, in that, once the left hand side of a
rule has matched a piece of message and the right hand
side structure (minus the parts that require recursive
rule matching) has been successfully built, no other rule
will ever be tried for that portion of the message.
As well as the usual specifications of features and
values (for example, conjn and first used above),
functional descriptions can also contain specifications
of properties, such as s and samesentence, that the
relevant construction must have. Some of these prop-
erties (such as s) are intrinsic—essentially just features
without values. Others are &amp;quot;macros&amp;quot; for bundles of
simpler feature-value and property specifications. For
example, samesentence is defined as being shorthand
for a bundle of feature-value pairs that limit the possi-
bilities for focus movement in and around the structure
described. A collection of such macros enables us to
implement what is essentially Dale&apos;s (1986) model of
how discourse structure constrains pronominalization,
which was inspired by the work of Grosz (1977) and
Sidner (1979). The use of a macro like samesentence
(keyed off particular structures in the message) sets up
an environment that will allow certain pronominalize-
tions but exclude others. The choice of whether to
pronominalize or not is then made on a local basis. It is
interesting to compare this scheme to that of McKeown
(1982), which also makes focus decisions on a local
basis. McKeown&apos;s approach, almost the opposite to
ours, is to take certain focus priorities as primary and
then to attempt to select material in accordance with
these. Our approach, which involves considering focus
only after the material has already been organized,
regards pronominalization more as a last-minute lexical
optimization than as something that is planned in ad-
vance. We have considered incorporating some means
of focus annotation in the message, but it is not always
clear at this level what the focus should be. We have
thus preferred to allow message planning simply to
place general constraints on focus movement.
As the message is traversed by the structure building
rules, more and more information accumulates about
the output functional description and its components.
As is usual in unification grammar, in the written form
structural descriptions are sideways open, that is, an
object satisfying the description is required to have the
features listed, but may have any other features in
addition. Thus our structure building rules only provide
the framework of the final functional description. The
rest is filled in by a simple grammatical constraint
satisfaction system. This enforces grammaticality and
handles the propagation of feature values that are
shared between different phrases (for instance, number
agreement). The constraint satisfaction system is based
on the use of a declarative &amp;quot;grammar specification&amp;quot; of
the types of legal descriptions and the constraints they
must satisfy. This specification is compiled into a rep-
resentation that essentially treats every property and
feature as a macro for a bundle of conclusions that
follow from its being involved in a description.
</bodyText>
<subsectionHeader confidence="0.970395">
3.6 CONSTITUENT ORDERING
</subsectionHeader>
<bodyText confidence="0.967976375">
The final task once the linguistic structure has been built
is to determine the order in which the constituents are to
be produced, and to locate the actual words to be used.
Substructure ordering is determined by ordering rules.
The ordering rules are applied to a structural description
in much the same way that structure-building rules are
applied to the message; that is, recursively and compo-
sitionally. The left hand side of an ordering rule is a
pattern that is matched against the structural descrip-
tion. The right hand side of the first rule whose pattern
matches is then taken as a template determining which
parts of the description are to be realized as phrases and
in what order. For example, here is a rule for VP
ordering:
[vp, mainverb = V, adv = A, compls = C] —&gt; [V,C,A].
This rule ensures that a verb is realized before its
complements, which are realized before any adverbial
modifiers, producing VPs like:
go to the front of the car now
Each application of an ordering rule returns an ordered
list of functional descriptions. These are then recur-
sively subjected to ordering rules, to determine their
relevant subphrases and the order these should be
realized in. The recursion &amp;quot;bottoms out&amp;quot; when a func-
tional description of type word is reached. The end
result is a list of word descriptions each containing
features detailing aspects of the morphology. These are
passed to the morphology component (currently ex-
Computational Linguistics Volume 15, Number 4, December 1989 239
Chris Mellish and Roger Evans Natural Language Generation from Plans
pressed as raw Prolog code), which will then output the
appropriately inflected word.
</bodyText>
<sectionHeader confidence="0.779796" genericHeader="method">
4 PLANS AND MESSAGES
4.1 THE MESSAGE LANGUAGE
</sectionHeader>
<bodyText confidence="0.99996825">
In some ways, a natural language generation system is
like an optimizing compiler. Producing some sort of
natural language from a symbolic input is not a task of
great difficulty, but producing text that is smooth and
readable is a challenge (and in general quite beyond the
state of the art). With both tasks one has the option of
planning the text and simplifying its form either in a
single pass or in multiple passes. In language genera-
tion, McDonald&apos;s MUMBLE (McDonald 1983) pro-
duces and simplifies linguistic structures within a single
pass of the input. Although the modeling of human
language production may require a theory of this kind in
the end, the result is a system where it can be hard to
separate out the different principles of structure build-
ing and simplification, because these have all been
conflated for reasons of efficiency. We have thus opted
for a multi-pass system. Multi-pass optimizing compil-
ers need to have specialized internal languages (virtual
machine codes) more abstract than the output machine
codes and in terms of which optimizations can be
stated. The analog in a natural language generation
system would be a message language that could ex-
press at a level more abstract than linguistic structure
the goals and intended content of a piece of language to
be generated. We can see elements of such a language in
the &amp;quot;realization specifications&amp;quot; of McDonald and Con-
klin (1982) and in the &amp;quot;protosentences&amp;quot; of Mann and
Moore (1981). A crucial part of our own system is the
use of a message language specialized for the explana-
tion of plans.
Our message language is a language specifically de-
vised for expressing the objects that arise in plans and
the kinds of things one might wish to say about them.
The main types of statements (&amp;quot;utterances&amp;quot;) that can
be made at present as part of our generated text are
shown in Figure 3. These &amp;quot;utterances&amp;quot; mention actions
and states, which could be domain actions and states (as
appearing in the plan) or complex actions and states,
formed according to the rules in Figure 4. The message
language provides for the description of actions being
carried out involving different agents and objects (both
represented as &amp;quot;objects&amp;quot;—Figure 5), although NON-
LIN provides no indication about who is responsible for
any given part of a plan. Thus the agent of an action
defaults to user for an action that is properly part of the
current subplan and someone for an action that has
been included in the description but is properly part of
another subplan. In this way, each part of the plan is
explained from the point of view of the person executing
it, with no assumption that the same person will be
executing other parts of the plan. A message consists of
a number of &amp;quot;utterances&amp;quot; linked together by various
</bodyText>
<sectionHeader confidence="0.33558" genericHeader="method">
UTTERANCE ::=
</sectionHeader>
<bodyText confidence="0.99098745">
neccbefore(OBJECT,ACTION,ACITON)
one action must take place before another
do(ACTION)
--- instruction to perform an action
result(ACTION,STATE)
--- as &apos;do&apos;, but also mentioning an effect of the action
hypo_result(OBJECT,ACTION,STATE)
--- if the agent carried out the action, the state would hold
expansion(ACTION,ACTION)
--- describing the expansion of an action into subactions
prereqs(OBJECT,ACTION,STATE)
--- describing the prerequisites of an action, with the
--- assumption that a given agent will perform it
needed(OBJECT,ACTION,STATE)
--- describing the reason why a STATE is needed, so that
--- OBJECT can perform ACTION
causes(STATE,STATE)
--- once the first state holds, so does the second
now(STATE)
--- indicating that some state now holds
</bodyText>
<figureCaption confidence="0.728003">
Figure 3 Types of Basic Utterance.
</figureCaption>
<bodyText confidence="0.999802">
organizational devices. These indicate various kinds of
sequencing and embedding (Figure 6). Most are simply
ways to string together two &amp;quot;utterances,&amp;quot; with an
appropriate conjunction being suggested, according to
what kind of link there is between the two. The embed
construction is used to indicate a discourse segment
which has an introductory section, a body and a con-
cluding section. Hence it has three parts. The idea is
that the explicit marking of such structures in the
message language will enable linguistic decisions (for
instance concerning pronominalization) to be made
more intelligently. In general, the domain-dependent
lexicon need only supply a single linguistic representa-
tion for the simplest form of a domain action or prop-
erty. The linguistic forms of the more complex forms
allowed by the message language are then dealt with
automatically by the system (Figure 7).
</bodyText>
<subsectionHeader confidence="0.973311">
4.2 FROM PLAN TO MESSAGE
</subsectionHeader>
<bodyText confidence="0.998784142857143">
A plan with 30 or so actions contains a great deal of
material, spelling out the necessary partial ordering
between the actions and their preconditions and effects.
A crucial task in message planning is cutting this
material down into small enough pieces that can be
rendered as independent pieces of text. In a domain-
independent system for plan explanation, the only
structure that such a &amp;quot;chunking&amp;quot; can make use of is the
abstraction hierarchy and the local &amp;quot;shape&amp;quot; of the
action graph. Even this is unfortunately limited by the
fact that the abstraction hierarchy may represent a view
of the domain that is convenient to the plan generator,
but not the plan executer.
The abstraction hierarchy tells us how certain actions
</bodyText>
<page confidence="0.73548">
240 Computational Linguistics Volume 15, Number 4, December 1989
</page>
<note confidence="0.789755">
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<sectionHeader confidence="0.866473" genericHeader="method">
ACTION ::=
</sectionHeader>
<bodyText confidence="0.973611285714286">
then(ACTION,ACTION)
--- two actions in sequence
achieve(STATE)
--- the action to achieve a state
wait(STATE)
--- waiting until a state holds
complete(ACTION)
--- finishing doing a prolonged action
repeat(ACTION,STATE)
--- doing the action until the state holds
delegate(OBJECT,ACTION)
--- have someone else do an action
parallel(ACTION,ACTION)
--- doing two actions in parallel
</bodyText>
<figure confidence="0.5296801">
DOMA1N_ACTION
STATE
and(STATE,STATE)
--- both states hold
state(OBJECT,PROPERTY)
--- an agent has a property
not(state(OBJECT,PROPERTY))
--- an agent does not have a property
PROPERTY ::=
andp(PROPERTY,PROPERTY)
</figure>
<bodyText confidence="0.953728875">
--- conjunction of properties
enabled(ACTION)
--- able to perform an action
done(ACTION)
--- having done an action
doing(ACTION)
--- doing an action
DOMA1N_PROPERTY
</bodyText>
<figureCaption confidence="0.869055">
Figure 4 Actions, States, and Properties.
</figureCaption>
<bodyText confidence="0.9928733">
at a particular level of the plan arise from the expansion
of a single action at a more abstract level. Such a group
of actions is an obvious candidate for explaining as a
single chunk. Thus our basic strategy is to first of all talk
about the plan at the most abstract level, then discuss
the expansion of the actions at that level, then discuss
the expansion of the actions involved in that, and so on.
In general, then, at any time we are concerned with
1) selecting out the portion of the plan that corresponds
to the expansion of a single abstract action and
</bodyText>
<figure confidence="0.7020812">
OBJECT
user
someone
function(FWORD,OBJECT)
DOMAIN_OBJECT
</figure>
<figureCaption confidence="0.842252">
Figure 5 Objects.
</figureCaption>
<figure confidence="0.3683775">
MESSAGE :=--
title(ACTION,MESSAGE)
--- labels a piece of text with a title (based on an action)
embed(MESSAGE,MESSAGE,MESSAGE)
</figure>
<bodyText confidence="0.9771578">
--- introduction-body-conclusion type structure
neutral_seq(MESSAGE,MESSAGE)
--- two bits produced in sequence, but with no implied relationship
time_then(MESSAGE,MESSAGE)
--- two bits produced in sequence, this indicating time order
linked(MESSAGE,MESSAGE)
--- two bits produced in sequence, with some unspecified relatinship
time_parallel(MESSAGE,MESSAGE)
--- two bits produced in sequence, indicating parallelism in time
contra_seq(MESSAGE,MESSAGE)
--- two bits produced in sequence, where the second contradicts an
--- expectation created by the first
implies(MESSAGE,MESSAGE)
--- one dplan statement is true and hence so is another
UTTERANCE
</bodyText>
<figureCaption confidence="0.746806">
Figure 6 Linking Devices for Utterances.
</figureCaption>
<bodyText confidence="0.988353388888889">
2) describing this, given that whole subsets of the
actions in it are to be treated as single actions.
The first of these is not trivial because, as the result of
successive criticisms, the set of actions in the expansion
of a more abstract action may no longer be a simple
connected piece of the plan. As an example of this,
Figure 8 is the action graph for a house-building plan,
with the actions that are in the expansion of &amp;quot;installing
the services&amp;quot; blocked out.
To describe this set of actions and their timing in the
plan, it is necessary to describe other actions whose
timing is closely coupled to them. The actions to be
included in the explanation of the expansion are ob-
tained by a &amp;quot;closure&amp;quot; operation—a process of tracing
through all possible paths going forward in time be-
tween actions in the expansion. Any other actions
encountered on these paths are deemed necessary to be
included in the description. We call these actions &amp;quot;in-
truders.&amp;quot; Thus the actions described form the minimal
convex graph that includes the desired actions (Figure
9).
Once the lowest-level plan actions corresponding to a
single abstract action have been isolated, the &amp;quot;shape&amp;quot;
of this part of the plan at the current level of abstraction
needs to be determined. The current point in the ab-
straction hierarchy specifies the set of actions that can
be mentioned in this part of the text. If one of these is an
abstract action, in general there will be a whole class of
lowest-level actions that need to be described simply as
parts of this action, whose internal structure will be
described later. The lowest-level actions are thus
grouped into subsets, and what is to be explained are
relationships between these subsets, rather than rela-
tionships between primitive actions. Technically, the
&amp;quot;chunking&amp;quot; imposed by the current layer of the ab-
straction hierarchy defines an equivalence relation, and
</bodyText>
<note confidence="0.3014435">
Computational Linguistics Volume 15, Number 4, December 1989 241
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<construct confidence="0.821237">
do(examine(filter_bolts)).
do(complete(examine(filler_bolts))).
do(delegate(someone,examine(filter_bolts))).
now(state(user,enabled(examine(filter_bolts)))).
now(state(someone,done(examine(filter_bolts)))).
now(state(user,doing(examine(filter_bolts)))).
now(state(plug_leads,positioned)).
do(achieve(state(plug_leads,positioned))).
do(waigstate(plug_leads,positioned))).
causes(state(user,done(achieve(state(plug_leads,positioned)))),
state(user,enabled(examine(filter_bolts)))).
</construct>
<bodyText confidence="0.993912">
Examine the filter bolts.
Finish examining the filter bolts.
Have someone examine the filter bolts.
You can now examine the filter bolts.
The filter bolts have now been examined.
You are now examining the filter bolts.
The plug leads are now in position.
Get the plug leads to be in position.
Wait until the plug leads are in position.
Once the plug leads are in position you can
examine the filter bolts.
</bodyText>
<figureCaption confidence="0.997996">
Figure 7 Expressions Generated Using Two Lexical Entries.
</figureCaption>
<bodyText confidence="0.999309">
we are interested in the quotient plan with respect to
this relation. We can define the usual plan relationships
between the relevant subsets of actions in a natural
way. For instance, we say that one subset comes before
another if and only if each element of the first comes
before each element of the second. Because such a
demanding criterion will apply quite rarely, in general
there will be a great deal of parallelism in subplans
whose actions are not at the most detailed level.
Once a piece of the whole plan has been extracted
and its &amp;quot;shape&amp;quot; (relative to some given equivalence
relation) established, rhetorical strategies are applied to
decide how particular parts are to be presented. The
message created depends directly on the structure of the
justified plan. Thus, for instance, the expansion of a
complex action gives rise to a section of text repre-
sented by a message of the form:
</bodyText>
<table confidence="0.5231934">
title ( Action,
embed ( Intro,
Body,
now (state (user, done (complete
(Action)))))))
</table>
<bodyText confidence="0.999096111111111">
where Action is the action described, Intro is an
introductory message, which describes the prerequi-
sites of the main action and the set of actions in its
expansion (unless there are too many of them) and Body
describes the action graph expanding the main action.
The main strategies for describing action graphs are the
lump strategy, forwards description, and backwards
description (Figure 10). The lump strategy applies if a
piece of the action graph is a self-contained &amp;quot;lump&amp;quot;
</bodyText>
<figureCaption confidence="0.991519">
Figure 8 Distribution of Expression of an Abstract Action.
</figureCaption>
<page confidence="0.947773">
242
</page>
<bodyText confidence="0.999939428571429">
between two actions A and B, with no links between
any actions inside the &amp;quot;lump&amp;quot; and any actions outside.
If the subgraph between the actions is sufficiently
complex (has more structure than two simple actions in
parallel), the strategy suggests that its explanation
should be postponed to a separate &amp;quot;section.&amp;quot; Mean-
while the whole subgraph is incorporated into the
current explanation as if it were a simple action (this is,
of course, the same strategy that is applied for an action
that is above the primitive level in the abstraction
hierarchy). Forward description is deemed appropriate
when the action graph is a right-branching structure; in
this case the actions are generally dealt with in time
order, giving a message of one of the forms:
</bodyText>
<table confidence="0.575018">
time_then (result (Act, State), ...)
neutraLseq (
result (Act, State),
embed (causes (State,
state (user, enabled (Acts))),
</table>
<listItem confidence="0.685433">
• • • , [ ])
</listItem>
<bodyText confidence="0.999786">
where Act is the first action, State a state that it makes
true., and &amp;quot;. .&amp;quot; is the message derived from the
subsequent actions. When the action graph is a left
branching structure, however, the strategy of back-
wards description is suggested. This gives rise to mes-
sages of the form:
</bodyText>
<figure confidence="0.76056575">
embed (prereqs(user,Act,Pres),
now (state(user,
enabled (
0 0 0
</figure>
<figureCaption confidence="0.996059">
Figure 9 Closure of Expansion.
</figureCaption>
<figure confidence="0.9271754">
Computational Linguistics Volume 15, Number 4, December 1989
Chris Mellish and Roger Evans Natural Language Generation from Plans
Lump:
•
Forwards:
</figure>
<figureCaption confidence="0.937079">
Figure 10 Rhetorical Strategies.
</figureCaption>
<figure confidence="0.40556">
parallel (Act,
achieve (State)))))
</figure>
<bodyText confidence="0.999808611111111">
where Act is the first action, with preconditions Pres
and effects State, and &amp;quot;. . .&amp;quot; is the message derived
from the subsequent actions.
All of these kinds of messages require the insertion of
preconditions and effects of actions. It is necessary for
the system to compute those preconditions and effects
that are actually relevent for the current plan, rather
than simply the total sets of preconditions and effects.
This amounts to determining the justifications for the
action ordering chosen. The justification for action A
coming before action B can be of one of two types.
Either A is needed to create a state where a precondi-
tion of B is true, or A comes before B because otherwise
B would create a state where a precondition of A was
not true. The two different possibilities give rise to
different modes of presentation, but if the justification is
redundant or not available from the plan, it is simply
missed out.
</bodyText>
<subsectionHeader confidence="0.97384">
4.3 IMPROVING THE MESSAGE
</subsectionHeader>
<bodyText confidence="0.999077527777778">
As the last section suggests, the initial version of the
message is put together in a very direct way from the
structure of the plan. As a result, it is often unneces-
sarily cumbersome. Message simplification concerns
rewriting the message expression generated by message
planning into one that is &amp;quot;simpler&amp;quot; in some sense. Since
the amount of material we wish to deal with could be
large, we have avoided considering expensive global
simplification techniques in favor of emphasizing local
simplification techniques analogous to &amp;quot;peephole&amp;quot; op-
timizing techniques in compiling. Of course, a crucial
difference between language generation and compila-
tion is that in the former there is no clear notion of what
&amp;quot;optimality&amp;quot; is. In the absence of a formal and detailed
psychological theory of discourse comprehension, re-
searchers in natural language generation are reduced
more or less to using their intuitions about whether one
way of phrasing something is &amp;quot;easier to understand&amp;quot;
than another. We have regretfully had to follow the
same course in designing and evaluating our own sys-
tem.
The domain-independent simplification rules used by
our message simplification system are treated equally,
but conceptually they seem to be of four main types.
Members of the first type tidy up special cases that
could as easily be detected when the expression is
constructed. Here is an example of such a rule ([
denotes the empty utterance):
Thus any utterance expression of type neutraLseq will
be rewritten by this rule if its second component is
empty. Such an expression is rewritten simply to its first
component. Incorporating such rules into the simplifi-
cation stage means that the message-planning compo-
nent can be simpler and more perspicuous.
The second kind of rule expresses knowledge about
planning and plan execution. Here are two such rules:
</bodyText>
<listItem confidence="0.9744205">
(2) achieve (state (user, done (Act))) —&gt; Act.
(3) parallel (X, wait (Y)) —&gt; then (X, wait (Y)).
</listItem>
<bodyText confidence="0.972183689655173">
Rule (2) expresses the fact that the only way to create a
state where you have done an action is to do the action.
Rule (3) expresses the fact that waiting is an action that
is always postponed until there is nothing else to do.
Both of these principles are useful in finding the best
way to express a given action.
A third kind of rule really reflects the linguistic
coverage of the system in an indirect manner. If there is
a special way available for saying a particular kind of
thing, then that should be preferred to using a more
general technique. Here is such a rule:
(4) prereqs (user, X, state (user, done (Y))) —&gt;
n.eccbefore (user, Y, X).
This rule is about a special case of the prereqs structure
arising in the message. When one is calling attention to
the prerequisite(s) of an action X, a special case arises
when the only prerequisite is the achievement of an-
other action Y. In this case, the prerequisites statement
amounts to saying simply that Y must happen before X.
In general, one would expect that expressing the state-
ment in this second way would result in a simpler piece
of text than using a general-purpose strategy for ex-
pressing prereqs statements. It is arguable that such
rules should really exist as special-case structure build-
ing rules. Such an approach would, however, preclude
the use of simplification rules that made further use of
the output of such rules.
Finally, there are rules that are motivated by notions
of simplicity of structure. For instance, the rule:
</bodyText>
<figure confidence="0.56715">
(5) time_para1lel (do (X), do (Y)) —&gt; do (parallel (X,
Y)).
When you have done A
you can do B and C
Before you can do A
you must do B and C
(1) neutraLseq (X,[ ]) —&gt; X.
Computational Linguistics Volume 15, Number 4, December 1989 243
Chris Mellish and Roger Evans Natural Language Generation from Plans
</figure>
<bodyText confidence="0.82868755">
results in an expression with one fewer &amp;quot;connectives.&amp;quot;
Such rules should really be backed up by a (perhaps
psychological) theory of the complexity of messages.
Here is an example of how a message language
expression can be simplified using these rules.
neutraLseq (
prereqs (user,
achieve (state (user, done (al))),
state (user,
done (parallel (a2, wait (s))))),
])
is simplified by rule (1) to:
prereqs (user,
achieve (state (user, done (al))),
state (user,
done (parallel (a2, wait(s)))))
which is simplified by rule (2) to:
prereqs (user,
al,
state (user, done (parallel (a2, wait(s)))))
which is simplified by rule (3) to:
prereqs (user,
al,
state (user, done (then (a2, wait(s)))))
which is simplified by rule (4) to:
neccbefore (user, then (a2, wait(s)), al)
Here the simplification would result in the difference
between a text like:
In order to get you to have washed the baby you must
have undressed the baby and waited until the bath is
full.
and one like the following:
You must undress the baby and then wait until the bath
is full before you can wash the baby
The rewrite rules we have discussed so far in this
section are independent of the domain in which the plan
is made. Our system also allows for domain-dependent
rules to be provided for a given planning domain. This
provides a way of automatically rewriting every occur-
rence of a given expression coming from the planner
into another given expression. One purpose of this kind
of rule is to provide a translation for states, which may
be primitive objects to the planner but are required to be
somewhat more complex by the generator. For exam-
ple, in the car domain, there is a rule that rewrites the
planner primitive positioned (X) to be the complex
term state (X, positioned). Domain-dependent rewrite
rules can also be used to show correspondances be-
tween action and state names that seem independent but
are in fact strongly connected. For instance, in the
house-building plan, there is an action lay_basement_
floor and a domain state basement_floor1aid (not a
legal message state). Not surprisingly, the second is an
effect of the first and can only come about by the first
having been done. Given that we can deal with complex
states and actions, we would do well to replace the
second by a formula involving the first, in fact state
(user, done (lay_basement_floor)). In this way we can
simplify certain expressions in the message. For in-
stance, the expression:
</bodyText>
<equation confidence="0.2828258">
do (achieve (basement_floor_laid))
is equivalent to:
do (achieve (state (user, done (lay_basement_floor)))
which simplifies to:
do (lay_basement_floor)
</equation>
<bodyText confidence="0.999619894736842">
by simplification rule (2) above. Given this domain-
dependent rule and the simplifications thus enabled, the
expression do (achieve (basement_floor_laid)) would
be realized as something like &amp;quot;lay the basement floor,&amp;quot;
rather than &amp;quot;get the basement floor to be laid,&amp;quot; which
would arise from a more straightforward encoding of the
state basement_floorlaid in terms of verbs and cases.
Domain-dependent rewrite rules allow us, in princi-
ple, infinitely to enrich the semantics of actions and
states represented in the plan. They thus provide one
way of compensating for the shallowness of the plan-
ner&apos;s representation. The basic framework on which the
plan actions and states hang is, however, fixed by the
planner and cannot be changed by the generator. Thus
not all deficiencies of the planner can be rectified by this
method. The extensive use of domain-dependent re-
write rules is in any case unattractive, as it takes away
from the domain-independence of the system. We will
return to this topic later.
</bodyText>
<subsectionHeader confidence="0.997684">
4.4 KNOWLEDGE SOURCES IN MESSAGE CONSTRUCTION
</subsectionHeader>
<bodyText confidence="0.999876739130435">
Before we leave our discussion of how messages are
constructed, it is useful to summarize the different
knowledge sources that have an effect on the text
generated from a plan. The gross organization of the
message is determined by rhetorical strategies that look
for patterns in the plan structure. Such strategies are
specific only to the kind of plan that we are taking as
input (i.e., hierarchical, nonlinear plans). Message sim-
plification is usually responsible for the finer-grain
structure of the message, as its rewrite rules operate
strictly locally in the message. The domain-independent
rewrite rules exploit the redundancy in the message
language and express heuristics about how a given
proposition might be expressed most simply. Such rules
embody simple knowledge about planning and the facil-
ities of the message language. Finally, domain-depen-
dent rewrite rules enable some of the hidden structure in
the planner&apos;s representation to be revealed.
Once a final message has been decided on, its real-
ization as text makes use of structure building rules that
depend on the natural language being used. At this point
most of the significant decisions have already been
made. The structure-building rules are able to make a
</bodyText>
<page confidence="0.850786">
244 Computational Linguistics Volume 15, Number 4, December 1989
</page>
<note confidence="0.884453">
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<figureCaption confidence="0.994109">
Figure 11 Installing the Services.
</figureCaption>
<bodyText confidence="0.996922090909091">
limited choice among possible syntactic structures and
are able to introduce pronominalization where it seems
appropriate, but their scope is heavily constrained by
the message. During structure building, a domain-de-
pendent lexicon makes available a verb entry for each
domain state and action, as well as a fixed NP that can
be used to denote each domain object. Although it is
useful to assess the effectiveness of the system by
considering the text output, many of the more interest-
ing problems with the system are really already visible
at the message stage.
</bodyText>
<sectionHeader confidence="0.99807" genericHeader="method">
5. DISCUSSION
</sectionHeader>
<subsectionHeader confidence="0.99963">
5.1 FURTHER EXAMPLES
</subsectionHeader>
<bodyText confidence="0.9999856">
The system has been tested using a number of different
domains with rather different characteristics, and the
results have been correspondingly varied. One domain
that seems to work fairly well is that of cookery recipes
such as the following:
</bodyText>
<subsubsectionHeader confidence="0.663174">
MAKING PAPRIKA POTATOES AND SMOKED SAUSAGES
</subsubsectionHeader>
<bodyText confidence="0.999785307692308">
Melt the fat, fry the onion in it, add the flour to it and
add the paprika to it. After this, stir the sauce until it
boils. Meanwhile peel the potatoes and cut them into
pieces. After this, add them to the sauce, cover the pan
and make the sauce boil, stirring the sauce occasion-
ally. Meanwhile cook the sausages. After this, add them
to the sauce.
This text was actually produced from a &amp;quot;mockup&amp;quot; of
plausible planner output, rather than a real plan, and did
not include enough information (about preconditions,
effects, etc.) to warrant the system adding justifications
about ordering. This does not seem to matter too much,
probably because cookery recipes are traditionally pre-
sented as instructions to be followed more or less
blindly.
For an example where our techniques produce a less
pleasing result, consider the &amp;quot;installing the services&amp;quot;
extract from the house-building plan (discussed above)
shown in Figure 11. In this action graph (which shows
no preconditions or effects), we have indicated the
actions with abbreviated names. Those actions in low-
ercase are not actually part of installing the services (but
are &amp;quot;intruder&amp;quot; actions that are nevertheless crucial to
this part of the plan); they will be described elsewhere in
the text. Here is the English produced for this plan
fragment:
</bodyText>
<sectionHeader confidence="0.473494" genericHeader="method">
INSTALLING THE SERVICES
</sectionHeader>
<bodyText confidence="0.9793938125">
Installing the services involves finishing the electrical
work and laying the storm drains.
You must paint the house before finishing the electrical
work.
In order to paint the house you must have installed the
finished plumbing and installed the kitchen equipment.
You must lay the finished flooring before installing the
finished plumbing and installing the kitchen equipment.
You must fasten the plaster and plaster board before
laying the finished flooring. In order to fasten the
plaster and plaster board you must have installed the
air conditioning and installed the rough plumbing and
installed the rough wiring.
Install the drains and then install the air conditioning,
installing the rough plumbing.
Meanwhile install the rough wiring,
You can now fasten the plaster and plaster board.
You can now lay the finished flooring.
You can now install the finished plumbing and install
the kitchen equipment.
You can now paint the house.
You can now finish the electrical work.
Meanwhile lay the storm drains.
You have now finished installing the services.
This account is basically comprehensible, but is repet-
itive and quite hard to follow. One reason for the
repetition is that the subject matter is really very boring
and uninformative, and it would be quite a challenging
task for a human being to produce interesting and
readable text from the same information. We discuss
below some other reasons why this text is less than
optimal.
</bodyText>
<subsectionHeader confidence="0.995413">
5.2 DEFICIENCIES IN PLANS
</subsectionHeader>
<bodyText confidence="0.999992888888889">
Although generating explanations from the output of an
Al planner appears to be a promising application of
natural language generation research, there are a num-
ber of special problems that we have encountered with
this task. Indeed, we can explain some of the defi-
ciences in the text we have been able to generate purely
in terms of deficiencies of the planner and/or its plans.
Some problems stem from the use of plan operators not
designed with text generation in mind, and can be
solved within the scope of the planning system. More
serious are problems that arise because of deficiencies
in the planner methodology itself. In the development of
our system we have encountered a number of these,
ranging from trivial to quite fundamental. Some of these
are properties of NONLIN in particular; others apply
more generally to most Al planning systems. It is not
appropriate to discuss the full details of these problems
here, but we shall mention some of the main points.
</bodyText>
<sectionHeader confidence="0.741451" genericHeader="method">
GRANULARITY
</sectionHeader>
<bodyText confidence="0.970932788732394">
One might ask why, unlike in the cookery recipe, there
is no pronominalization in the text for installing the
services. The coherence of the text would be improved
Computational Linguistics Volume 15, Number 4, December 1989 245
Chris Mellish and Roger Evans Natural Language Generation from Plans
considerably by the judicious use of pronouns. Unfor-
tunately, whereas in the cookery domain (which we
encoded by hand) a particular action of &apos;frying&apos; is
treated as an instance of a general action that can
potentially be applied to different objects; in the house-
building domain the objects acted on by an action are
fundamentally built into that action. The difference can
be seen from example lexical entries from the two
domains:
lx (fry (Food, In), fry, [obj: Food, in: In]).
lx (install rougb_wiring, install,
[obj : @ the rough wiring&apos;]).
To use pronominalization, one needs to be able to
determine that the same domain object is being men-
tioned several times, but only the first type of represen-
tation here actually supports the representation of do-
main objects. What has happened here is that, from the
point of view of making a house-building plan, the
planner cannot make use of properties of a general
action like &apos;install,&apos; and so its representation of actions
is at a coarser level of granularity than that required to
produce good text.
In common with most plans in traditional Al work,
NONLIN plans only encode very weak information
about causality and temporal relationships. For in-
stance, when there is an action that achieves an effect,
there is no way to tell from the plan whether we are
dealing with an instantaneous action, an extended ac-
tion that terminates as soon as the effect is achieved, or
an extended action where the effect is achieved some-
time during the execution. A natural language like
English provides ways of distinguishing between these
cases:
Turn on the switch and the light will be on.
Pour in the water until the bucket is full.
Prepare a chicken curry so that the chicken scraps are
used up.
Because there is no way to distinguish between these in
the NONLIN representation of effects, our generator is
forced to try to find a neutral way to express all of them.
As a result, there is a homogeneity in the text that is not
necessarily reflected in the actual plan execution. Again
the problem can be thought of as a mismatch between
the granularity of the representation used for planning
and that needed to exploit the facilities of the natural
language.
The effect of the granularity problem can be lessened
by allowing the plan generator to provide deeper infor-
mation about the internal structure of actions and states
through domain-dependent rewrite rules. Our message
language allows us to talk about repeated actions, for
instance, and so we can specify that certain domain
actions are really shorthand for more complex expres-
sions:
filLbucket --&gt; repeat (pour (water, bucket),
state (bucket, full)).
Messages containing these complex actions can then be
simplified by domain-independent rules like:
result (repeat (Act, State), State) --&gt;
do (repeat (Act, State)).
Similarly we can use domain-dependent rewrite rules to
introduce tokens standing for domain objects and hence
give us a basis for pronominalization. The more one
relies on domain-dependent rewrite rules for good text,
however, the less one can claim to have a domain-
independent basis for generating text from plans.
</bodyText>
<sectionHeader confidence="0.979059" genericHeader="method">
CONCEPTUAL FRAMEWORK
</sectionHeader>
<bodyText confidence="0.991331619047619">
Domain-dependent rewrite rules can be regarded as a
way of embellishing the planner&apos;s output to match up
!Defter with the requirements for generation. The basic
framework of the plan is, however, something that
cannot be changed unless the generator itself is to start
doing some of the planning. Assuming that there is some
point in distinguishing the planner from the generator,
the generator is therefore sometimes faced with a mis-
match between self-evident concepts in the planner&apos;s
conceptual framework and those concepts that can be
expressed simply in natural language. Consider, for
instance, the notion of (primitive) actions that are
unordered in the plan. If two actions have no ordering
relation between them, then this indicates that the
actions can be performed in any order relative to one
another. To express correctly the plan&apos;s semantics, one
should therefore make use of expressions like:
Install the drains and install the rough wiring, in any
order.
In practice, however, we have chosen to map such a
piece of plan into a message like:
do (parallel (install_drains, install rough_wiring)).
which then gives rise to a text such as:
Install the drains. Meanwhile install the rough wiring,
Treating unordered actions as parallel actions may
indeed both produce good text and even capture the
reality of plan execution, as in:
Make the sauce boil, stirring the sauce occasionally.
but this will only be so if at least one of the actions takes
place over a period of time and the actions can be and
are recommended to be executed concurrently. There
is, of course, no way to determine from the planner&apos;s
representation whether this is so. Indeed, since the
planner regards all primitive actions as essentially in-
stantaneous, in all cases it is in some sense incorrect to
express the planner&apos;s recommendations in this way. If
the correct execution of the plan were critical, for
instance, then it could be very dangerous to hide the
limited way in which the planner views the world as we
have done. It might thus be suggested that a generator
working from plans could and should always strive to
convey the plan semantics accurately, even if this
</bodyText>
<page confidence="0.816705">
246 Computational Linguistics Volume 15, Number 4, December 1989
</page>
<note confidence="0.762762">
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<bodyText confidence="0.9999124">
involves long-winded and unnatural prose. But in the
end one is faced with an incompatibility between the
planner&apos;s conceptual framework and the limits of what
our language can express. For instance, it unclear how
the action of &amp;quot;installing the rough wiring&amp;quot; can be
expressed in English in such a way that the action can
only be interpreted as an instantaneous action, which is
the way the planner sees it.
sumably because otherwise it is hard to make the pipes
line up) would be very large, and it would be well
beyond the state of the art for such a plan to be
produced automatically. Moreover, such a plan would
undoubtably contain a lot of information that was
blindingly obvious to a human reader and hence of no
interest whatsoever.
</bodyText>
<sectionHeader confidence="0.9794485" genericHeader="method">
ARBITRARY PLANNER RESTRICTIONS
EXPLANATORY POWER
</sectionHeader>
<bodyText confidence="0.999889194444445">
The texts that we have generated from plans are in-
tended to do more than simply tell the reader how to
execute a series of actions. We always hoped that the
justification structure built by the planner would also
help us to explain why the given actions, with the
ordering described, are the right ones to achieve the
plan&apos;s goal. In practice, however, our texts have failed
to be explanatory for a number of reasons. One problem
is that, unlike instructions generated by human beings,
our texts only tell you what to do, and not what not to
do. It is often just as important for a person to be
warned about the unpleasant consequences of doing the
wrong thing as it is to be told what the right thing is.
Unfortunately, the notion of &amp;quot;plan&amp;quot; we have adopted
only makes reference to the successful actions, even
though the plan generator may have spent a lot of time
exploring other possibilities that did not work out. It
might therefore be appropriate, in future work, to
consider natural language generation based on the trace
of a planning system, rather than on the final result.
Similarly, in many of the texts produced by our
system the reader is told what to do but is given no
illumination as to why things have to be done in this
way. Unfortunately, although in principle every plan is
justified by earlier actions achieving the preconditions
of later actions, many plans do not contain this infor-
mation in a useful form—in the housebuilding plan, for
instance, the only preconditions that are required for an
action in this plan to be performed are the successful
completion of previous actions. That is, the person who
has encoded the operators in terms of which the plan is
constructed has &amp;quot;compiled in&amp;quot; certain ordering con-
straints without using the language of preconditions and
effects effectively to explain them. One is reminded
here of the problems that Swartout (1983) encountered
in producing explanations from expert systems. The
problem was that just because a set of rules was
sufficient to produce expert behavior did not mean that
those rules contained anything illuminating to put into
explanations. Similarly in the planning area, there is no
reason why a set of operators that are effective for
producing useful plans need contain anything very
interesting that can be put into a natural language
account. Unfortunately, one cannot necessarily expect
machine-generated plans to come at the right level of
detail to be really useful to a human being. For instance,
a house-building plan that enabled one to see why the
rough plumbing must be installed after the drains (pre-
As is typical with application programs, most planners
have particular features that represent non-standard or
novel approaches to certain situations. This fact means
that any natural language generator using plans as input
must customize itself somewhat to the peculiarities of
the particular planner it is working with. One problem
peculiar to NONLIN&apos;s representation language con-
cerns the manner in which preconditions are specified.
In NONLIN an operator specifies how a goal is ex-
panded to a network of subgoals. As was observed in
the earliest Al planners, the most common case is that
a goal has preconditions, goals that must be true before
the given goal can be achieved. In NONLIN, one has to
use an expansion to represent this, with the conse-
quence that one wants the original goal itself to occur in
the expansion (that is Goal expands to Pre&apos;, . . PreN,
Goal). NONLIN will not allow this, so there have to be
two distinct representations of the goal. So in the car
example, we have {goal ...} for the high level goal and
{act ...} for the low level version (although this scheme
might not work in every domain). By this means we can
make NONLIN behave, but give ourselves a linguistic
problem—every action occurs twice. For example, we
might get:
</bodyText>
<sectionHeader confidence="0.767618" genericHeader="method">
STARTING THE ENGINE
</sectionHeader>
<bodyText confidence="0.998048625">
Go to the cab and then start the engine and you will
have finished starting it.
Roughly speaking, the distinction is between &apos;starting
the engine&apos; (the whole task) and &apos;actually starting the
engine&apos; (the specific operation). To some extent we can
avoid the problem by using different phrases (e.g., &apos;turn
on the engine&apos;), but it does not make the generation task
easier.
</bodyText>
<subsectionHeader confidence="0.951785">
5.3 DEFICIENCIES IN OUR APPROACH
</subsectionHeader>
<bodyText confidence="0.999942857142857">
The problems with our natural language accounts are, of
course, not entirely due to deficiencies in the plans we
are working on. We have deliberately held closely to
some basic guiding principles to evaluate their applica-
bility. So it is important to pinpoint their failings in our
current system and mention possible alternative ap-
proaches.
</bodyText>
<sectionHeader confidence="0.973693" genericHeader="method">
RELYING ON PLAN STRUCTURE
</sectionHeader>
<bodyText confidence="0.9814585">
To build a domain-independent system to generate text
from plans, we have deliberately tried to use only
information that the planner itself understands; i.e.,
information about the structure of the plan. One of the
Computational Linguistics Volume 15, Number 4, December 1989 247
Chris Mellish and Roger Evans Natural Language Generation from Plans
fundamental tenets of our approach was thus that the
plan abstraction hierarchy would be a useful source of
information about how the text should be organized.
But our experience suggests that it may not be as useful
as one might think. As well as the kind of problems
described above (which might be corrected in a different
planning system), there seem to be more general dis-
crepancies between the kind of abstraction useful to a
planner and the kind useful to a text generator.
For example, our car domain and many of the
blocksworld plans that have been studied in Al tend to
have a deeper abstraction hierarchy than one might
expect from the apparent simplicity of the tasks. A
generator that tries to exploit them all ends up produc-
ing too much structure in its text. Thus the example
used in Section 3 also has a &apos;section&apos;:
</bodyText>
<sectionHeader confidence="0.458849" genericHeader="method">
GAINING ACCESS TO THE DISTRIBUTOR
</sectionHeader>
<bodyText confidence="0.99970515">
Detach the dirt cover from the engine and you will have
finished gaining access to the distributor.
Here there is a level of abstraction that is useful to the
planner, but not to the human reader: it would probably
have been better to insert this section &amp;quot;in-line&amp;quot; in the
higher level description. On the other hand, the single
&amp;quot;section&amp;quot; devoted to installing the services in the
house-building plan would have gained from being bro-
ken up in some way. There may be a linguistic solution
to the problem of whether a piece of information
deserves a full &amp;quot;section,&amp;quot; perhaps in terms of a domain-
dependent model of what is and is not worth saying, or
the problem may point to a fundamental difference
between the ways the planner and a human perceives
the planning task. Either way, what is clear is that the
planner&apos;s abstraction hierachy alone is not fully ade-
quate for text generation. Whether we can devise gen-
eral principles for producing alternative decompositions
of plans more suitable for text generation remains an
open research area.
</bodyText>
<sectionHeader confidence="0.97195" genericHeader="evaluation">
REPETITION
</sectionHeader>
<bodyText confidence="0.999094821428572">
We have commented above on reasons why the raw
material we can gain from plans is liable to lead to
repetitiveness in the text. Even if we managed to enrich
the plan representations suitably, however, the genera-
tor would still be deficient when the input really is
uniform. In particular, the uniformity of the text output
often leads to unwanted ambiguities, simply because of
the lack of variation in the stylistic devices used. For
instance, in the following excerpt it is unclear whether
the potato peeling is supposed to be &amp;quot;in parallel with&amp;quot;
melting the fat, or just with stirring the sauce:
Melt the fat, . . .
After this, stir the sauce until it boils.
Meanwhile peel the potatoes and cut them into pieces.
We originally hoped to overcome the problem of repe-
tition by providing several structure-building rules for
each type of message language construction, which
would be sensitive to the form of the objects involved in
the construction. To some extent we succeeded in
producing such rules, but the effect on the text was riot
great. The problem here is that, even with these extra
rules, our structure-building is based solely on local
patterns in the message, whereas the problem of repe-
tition can only be solved by a global planning of the
text. It might be possible to gain some improvement in
our system by having the choice of structure-building
rules be determined partially by some random factor,
butt a proper solution requires a more radical redesign.
</bodyText>
<sectionHeader confidence="0.927738" genericHeader="conclusions">
LINGUISTIC SIMPLIFICATIONS
</sectionHeader>
<bodyText confidence="0.99999336">
There are a number of stylistic issues that the system
cannot easily accommodate. For instance, operations
such as &amp;quot;heavy NP shift,&amp;quot; segmentation into sentences,
coordination, and ellipsis all require detailed stylistic
control and evaluation. The message language is delib-
erately nonlinguistic and so can only approximately
represent the kinds of language-dependent stylistic in-
formation such processing needs. For instance, rewrite
rules can decide how to group information on the basis
of the complexity of the message, but this only indi-
rectly reflects the complexity of the text that will be
generated. The effective use of different stylistic de-
vices depends in the end on simplifications that are
justified on linguistic, rather than conceptual, grounds,
and this suggests that our architecture should really
incorporate a style module capable of reasoning at this
level. Such a style module would necessarily have to
take a more global view, looking at the overall linguistic
effect of the localized basic text generation processes. It
might be possible to introduce linguistic simplifications
at structure-building time, relaxing the requirement of
compositionality (indeed, this is how McDonald 1983
operates). We believe, however, that it would be pref-
erable to attempt to treat it at least conceptually as a
subsequent processing stage.
</bodyText>
<subsectionHeader confidence="0.890831">
5.4 WAYS FORWARD
</subsectionHeader>
<bodyText confidence="0.999691473684211">
In this paper we have described a system for generating
natural language from automatically generated plans.
Our main aim in developing the system was to produce
a model of a complete system using state-of-the-art
methodology and techniques, partly to evaluate the
current state of knowledge, and partly to provide a basis
for comparison for future work. Logically, then, there
are two strands to further work based on this research:
building on the evaluation to learn lessons about the
design of generation systems and the systems they
interact with, and building on the system itself to
produce better generation-from-plans systems.
One of the key evaluative lessons concerns the plan
structures a system like this depends on. We found the
plans produced by NONLIN unsatisfactory and we
have begun to understand why. We must now specify
what we would like a plan to look like and contain,
within the general constraint that a planning system
could reasonably produce it. Our present approach to
</bodyText>
<page confidence="0.809998">
248 Computational Linguistics Volume 15, Number 4, December 1989
</page>
<note confidence="0.488216">
Chris Mellish and Roger Evans Natural Language Generation from Plans
</note>
<bodyText confidence="0.999919666666667">
this topic is to take a very formal view of plans as
algebraic expressions over states (rather than actions or
goals) with a well-defined formal semantics, allowing us
to be clear about the semantic effect of plan transfor-
mations.
The system itself falls broadly into two parts, build-
ing and simplifying the message, and turning the mes-
sage into text. Of these the latter is the more modular,
more declarative, and probably more successful at
present. To a certain extent it can serve as a piece of
enabling technology for research on the message com-
ponent. Its major deficiency as discussed above is
global stylistic control. Its handling of morphology is
currently rather unprincipled, but the utilization of a
morphological representation language such as Datr
(Evans and Gazdar 1989 a,b) would rectify this.
The biggest outstanding task, however, is the mes-
sage planner itself. The mechanism described above
employs some quite powerful techniques in a fairly
effective way, but it is not very perspicuous or exten-
sible. We have begun work on a new message planner
module that applies transformation rules to plans of the
algebraic type mentioned above, gradually transforming
the plan into an optimized message structure. This will
provide us with a rule-based semideclarative framework
in which to explore further the issues of message
planning.
</bodyText>
<sectionHeader confidence="0.997371" genericHeader="acknowledgments">
ACKNOWLEDGMENTS
</sectionHeader>
<bodyText confidence="0.977483333333333">
The work reported here was made possible by SERC grant GR/D/
08876. Both authors are currently supported by SERC Advanced
Fellowships.
</bodyText>
<sectionHeader confidence="0.992378" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.993880343283582">
Chester, Daniel 1976 The Translation of Formal Proofs into English.
Artificial Intelligence, Vol 7, 261.
Conklin, E. Jeffrey and McDonald, David D. 1982 Salience: The Key
to the Selection Problem in Natural Language Generation. In:
Proceedings of the 20th Meeting of the Association for Computa-
tional Linguistics, Toronto, Canada.
Dale, Robert 1986 The Pronominalization Decision in Language
Generation. Dissertation Abstracts International Report 276, Uni-
versity of Edinburgh, Edinburgh, U.K.
Evans, Roger and Gazdar, Gerald 1989 Inference in Datr. In: Pro-
ceedings of the 1989 European Association for Computational
Linguistics, UMIST.
Evans, Roger and Gazdar, Gerald 1989 The Semantics of Datr. In:
Proceedings of the 1989 Artificial Intelligence Society of Great
Britain, University of Sussex.
Gazdar, Gerald; Klein, Ewan; Pullum, Geoffrey; and Sag, Ivan 1985
Generalised Phrase Structure Grammar. Blackwell.
Grosz, Barbara J. 1977 The Representation and Use of Focus in
Dialogue Understanding. SRI Technical Report 151.
Kay, Martin 1979 Functional Grammar. In: Proceedings of the 5th
Annual Meeting of the Berkeley Linguistics Society. Berkeley,
CA.
Kay, Martin 1984 Functional Unification Grammar: A Formalism for
Machine Translation. In: Proceedings of COLING-84. Stanford,
CA.
Mann, William C. and Moore, James A. 1981 Computer Generation of
Multiparagraph English Text. American Journal of Computational
Linguistics, Vol 7, No I.
Mann, William; Bates, Madeleine; Grosz, Barbara; McDonald, Dav-
id; McKeown, Kathleen; and Swartout, William 1982 Text Gen-
eration. American Journal of Computational Linguistics. Vol 8,
No 2.
McDonald, David D. 1983 Natural Language Generation as a Com-
putational Problem: An Introduction. In: Brady, Michael and
Berwick, Robert (Eds.), Computational Models of Discourse,
MIT Press, Cambridge, MA.
McKeown, Kathleen R. 1982 Generating Natural Language Text in
Response to Questions about Database Structure. Ph.D. thesis,
University of Pennsylvania, Philadelphia, PA.
Sacerdoti, Earl D. 1973 Planning in a Hierarchy of Abstraction
Spaces. In: Proceedings of the Eighth International Joint Confer-
ence on Artificial Intelligence-83. Palo Alto, CA.
Sacerdoti, Earl D. 1975 The Non-Linear Nature of Plans. In: Pro-
ceedings of the Fourth International Joint Conference on Artificial
Intelligence, Tbilisi, USSR.
Sidner, Candace L. 1979 Towards a Computational Theory of Definite
Anaphora Comprehension in English Discourse. Technical Report
537, MIT Artificial Intelligence Laboratory, Cambridge, MA.
Swartout, William R. 1983 XPLAIN: A System for Creating and
Explaining Expert Consulting Programs. Artificial Intelligence,
Vol 21.
Tate, Austin 1976 Project Planning using a Hierarchical Non-linear
Planner. Dissertation Abstracts International Report 25, Univer-
sity of Edinburgh, Edinburgh, U.K.
Tsang, Edward 1986 Plan Generation in a Temporal Frame. In:
Proceedings of the 7th European Conference on Artificial Intelli-
gence, Brighton, U.K.
NOTES
I. Current address: Department of Artificial Intelligence, University
of Edinburgh, 80 South Bridge, EDINBURGH EH1 1HN, United
Kingdom.
2. In the node descriptions we distinguish explicitly between goals and
actions that achieve goals. The reason for this is discussed in Section
5 below.
3. It is possible, however, to specify that, for a given domain, there
will only ever be one agent.
Computational Linguistics Volume 15, Number 4, December 1989 249
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.327698">
<title confidence="0.997785">NATURAL LANGUAGE GENERATION FROM PLANS</title>
<author confidence="0.999407">Roger Evans</author>
<affiliation confidence="0.99949">School of Cognitive and Computing University of Sussex</affiliation>
<address confidence="0.898171">Falmer Brighton BN1</address>
<abstract confidence="0.956595">United Kingdom This paper addresses the problem of designing a system that accepts a plan structure of the sort generated by AI planning programs and produces natural language text explaining how to execute the plan. We describe a system that generates text from plans produced by the NONLIN planner (Tate 1976). The results of our system are promising, but the texts still lack much of the smoothness of text. This is partly because, although the domain of plans seems a provide rich structure that a natural language generator can use, in practice a plan that is generated without the production of explanations in mind rarely contains the kinds of information that would yield an interesting natural language account. For instance, the hierarchical organization assigned to a plan is liable to reflect more a programmer&apos;s approach to generating a class of plans efficiently than the way that a human would naturally &amp;quot;chunk&amp;quot; the relevant actions. Such problems are, of course, similar to those that Swartout (1983) encountered with expert systems. In addition, AI planners have a restricted view of the world that is hard to match up with the normal semantics of natural language expressions. Thus constructs that are primitive to the planner may be only clumsily or misleadingly expressed in natural language, and the range of possible natural language constructs may be artificially limited by the shallowness of the planner&apos;s representations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Daniel Chester</author>
</authors>
<title>The Translation of Formal Proofs into English.</title>
<date>1976</date>
<journal>Artificial Intelligence,</journal>
<volume>7</volume>
<pages>261</pages>
<contexts>
<context position="25234" citStr="Chester (1976)" startWordPosition="4152" endWordPosition="4153"> been applied, our simplified example message looks like this: implies ( contra_seq ( hypo_result ( user, go_to (user, function (front, car)), state (user, not (located (cab)))), prereqs ( user, start (engine), state (user, located (cab)))), neccbefore (user, start (engine), go_to (user, function (front, car)))) 3.5 COMPOSITIONAL STRUCTURE BUILDING The next stage is to build a linguistic structure from this message expression. The structure-building component uses an ordered set of rules for mapping from local message patterns to linguistic structures. It is similar to the system described in Chester (1976) in the local nature of its operation, but Chester builds sentences directly, rather than via structural representations. Mann et al. (1982) would call our system a &amp;quot;direct translation&amp;quot; system. A system built in this fashion has the advantage of a very simple control structure and has the potential of having its principles expressed in modular, independent rules. Our linguistic structural descriptions are similar to the functional descriptions used in Functional Grammar (Kay 1979; Kay 1984). For example, the following is a slightly simplified version of the rule used to realize the hypo_result</context>
</contexts>
<marker>Chester, 1976</marker>
<rawString>Chester, Daniel 1976 The Translation of Formal Proofs into English. Artificial Intelligence, Vol 7, 261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Jeffrey Conklin</author>
<author>David D McDonald</author>
</authors>
<title>Salience: The Key to the Selection Problem in Natural Language Generation. In:</title>
<date>1982</date>
<booktitle>Proceedings of the 20th Meeting of the Association for Computational Linguistics,</booktitle>
<location>Toronto, Canada.</location>
<marker>Conklin, McDonald, 1982</marker>
<rawString>Conklin, E. Jeffrey and McDonald, David D. 1982 Salience: The Key to the Selection Problem in Natural Language Generation. In: Proceedings of the 20th Meeting of the Association for Computational Linguistics, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Dale</author>
</authors>
<title>The Pronominalization Decision in Language Generation. Dissertation Abstracts International Report 276,</title>
<date>1986</date>
<institution>University of Edinburgh,</institution>
<location>Edinburgh, U.K.</location>
<contexts>
<context position="12078" citStr="Dale 1986" startWordPosition="1957" endWordPosition="1958">ing system is similar to McDonald&apos;s (1983) model, in that it is basically a direct production system that utilizes an intermediate syntactic representation. The system is also similar to McDonald&apos;s in its emphasis on local processing, although there is no attempt to produce a psychological model in our work. Our constraint satisfaction system is implemented efficiently by unification, however, so that the effects of local decisions can propagate globally without the need for explicit global variables. This is used, for instance, to enforce a simple model of pronominalization (based on that of Dale 1986). 3 A WORKED EXAMPLE As an illustration of the various mechanisms contained within the system, we present in this section an example of the system in operation. The example is taken from a demonstration application, showing how the language generator might be attached to an expert system. The scenario is as follows: we have an expert system whose function is to diagnose car-starting faults. The expert system asks questions to which the user can either give an answer or type &amp;quot;how,&amp;quot; meaning &amp;quot;how can I find out the answer?&amp;quot; In this latter case, the expert system invokes a planner to work out what</context>
</contexts>
<marker>Dale, 1986</marker>
<rawString>Dale, Robert 1986 The Pronominalization Decision in Language Generation. Dissertation Abstracts International Report 276, University of Edinburgh, Edinburgh, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Evans</author>
<author>Gerald Gazdar</author>
</authors>
<title>Inference in Datr. In:</title>
<date>1989</date>
<booktitle>Proceedings of the 1989 European Association for Computational Linguistics, UMIST.</booktitle>
<contexts>
<context position="80552" citStr="Evans and Gazdar 1989" startWordPosition="13137" endWordPosition="13140">us to be clear about the semantic effect of plan transformations. The system itself falls broadly into two parts, building and simplifying the message, and turning the message into text. Of these the latter is the more modular, more declarative, and probably more successful at present. To a certain extent it can serve as a piece of enabling technology for research on the message component. Its major deficiency as discussed above is global stylistic control. Its handling of morphology is currently rather unprincipled, but the utilization of a morphological representation language such as Datr (Evans and Gazdar 1989 a,b) would rectify this. The biggest outstanding task, however, is the message planner itself. The mechanism described above employs some quite powerful techniques in a fairly effective way, but it is not very perspicuous or extensible. We have begun work on a new message planner module that applies transformation rules to plans of the algebraic type mentioned above, gradually transforming the plan into an optimized message structure. This will provide us with a rule-based semideclarative framework in which to explore further the issues of message planning. ACKNOWLEDGMENTS The work reported h</context>
</contexts>
<marker>Evans, Gazdar, 1989</marker>
<rawString>Evans, Roger and Gazdar, Gerald 1989 Inference in Datr. In: Proceedings of the 1989 European Association for Computational Linguistics, UMIST.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roger Evans</author>
<author>Gerald Gazdar</author>
</authors>
<title>The Semantics of Datr. In:</title>
<date>1989</date>
<booktitle>Proceedings of the 1989 Artificial Intelligence Society of</booktitle>
<institution>Great Britain, University of Sussex.</institution>
<contexts>
<context position="80552" citStr="Evans and Gazdar 1989" startWordPosition="13137" endWordPosition="13140">us to be clear about the semantic effect of plan transformations. The system itself falls broadly into two parts, building and simplifying the message, and turning the message into text. Of these the latter is the more modular, more declarative, and probably more successful at present. To a certain extent it can serve as a piece of enabling technology for research on the message component. Its major deficiency as discussed above is global stylistic control. Its handling of morphology is currently rather unprincipled, but the utilization of a morphological representation language such as Datr (Evans and Gazdar 1989 a,b) would rectify this. The biggest outstanding task, however, is the message planner itself. The mechanism described above employs some quite powerful techniques in a fairly effective way, but it is not very perspicuous or extensible. We have begun work on a new message planner module that applies transformation rules to plans of the algebraic type mentioned above, gradually transforming the plan into an optimized message structure. This will provide us with a rule-based semideclarative framework in which to explore further the issues of message planning. ACKNOWLEDGMENTS The work reported h</context>
</contexts>
<marker>Evans, Gazdar, 1989</marker>
<rawString>Evans, Roger and Gazdar, Gerald 1989 The Semantics of Datr. In: Proceedings of the 1989 Artificial Intelligence Society of Great Britain, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Gazdar</author>
<author>Ewan Klein</author>
<author>Geoffrey Pullum</author>
<author>Ivan Sag</author>
</authors>
<title>Generalised Phrase Structure Grammar.</title>
<date>1985</date>
<publisher>Blackwell.</publisher>
<contexts>
<context position="11456" citStr="Gazdar et al. 1985" startWordPosition="1856" endWordPosition="1859"> this, a simple grammatical constraint satisfaction system is used, to enforce grammaticality and propagate the consequences of syntactic decisions. The recursive descent terminates when it reaches elements of the message for which there are entries in the system&apos;s lexicon. Once a structural description of a text has been produced, it is necessary to produce a linear sequence of words. Our structural descriptions contain only dominance information and no ordering information, and so a separate set of rules is used to produce a linearization. This is akin to the ID/LP distinction used in GPSG (Gazdar et al. 1985). The resulting system is similar to McDonald&apos;s (1983) model, in that it is basically a direct production system that utilizes an intermediate syntactic representation. The system is also similar to McDonald&apos;s in its emphasis on local processing, although there is no attempt to produce a psychological model in our work. Our constraint satisfaction system is implemented efficiently by unification, however, so that the effects of local decisions can propagate globally without the need for explicit global variables. This is used, for instance, to enforce a simple model of pronominalization (based</context>
</contexts>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, Gerald; Klein, Ewan; Pullum, Geoffrey; and Sag, Ivan 1985 Generalised Phrase Structure Grammar. Blackwell.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara J Grosz</author>
</authors>
<title>The Representation and Use of Focus in Dialogue Understanding.</title>
<date>1977</date>
<tech>SRI Technical Report 151.</tech>
<contexts>
<context position="30501" citStr="Grosz (1977)" startWordPosition="5000" endWordPosition="5001">nd samesentence, that the relevant construction must have. Some of these properties (such as s) are intrinsic—essentially just features without values. Others are &amp;quot;macros&amp;quot; for bundles of simpler feature-value and property specifications. For example, samesentence is defined as being shorthand for a bundle of feature-value pairs that limit the possibilities for focus movement in and around the structure described. A collection of such macros enables us to implement what is essentially Dale&apos;s (1986) model of how discourse structure constrains pronominalization, which was inspired by the work of Grosz (1977) and Sidner (1979). The use of a macro like samesentence (keyed off particular structures in the message) sets up an environment that will allow certain pronominalizetions but exclude others. The choice of whether to pronominalize or not is then made on a local basis. It is interesting to compare this scheme to that of McKeown (1982), which also makes focus decisions on a local basis. McKeown&apos;s approach, almost the opposite to ours, is to take certain focus priorities as primary and then to attempt to select material in accordance with these. Our approach, which involves considering focus only</context>
</contexts>
<marker>Grosz, 1977</marker>
<rawString>Grosz, Barbara J. 1977 The Representation and Use of Focus in Dialogue Understanding. SRI Technical Report 151.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional Grammar. In:</title>
<date>1979</date>
<booktitle>Proceedings of the 5th Annual Meeting of the Berkeley Linguistics Society.</booktitle>
<location>Berkeley, CA.</location>
<contexts>
<context position="10310" citStr="Kay 1979" startWordPosition="1677" endWordPosition="1678">ects and relationships in the world are to be expressed in language and in roughly what order. The output of the message planner is an expression in the message language which, following McDonald, we will call the message. The idea is that message planning may be a relatively simple process and that the resulting message is then &amp;quot;cleaned up&amp;quot; and simplified by localized rewrite operations on the expression (&amp;quot;Message Simplification&amp;quot;). The message is a nonlinguistic object, and the task of structure building is to build a first description (a functional description much as in Functional Grammar; Kay 1979) of a linguistic object that will realize the intended message. We assume here that a &amp;quot;linguistically motivated&amp;quot; intermediate representation of the text is of value (this is argued for, for instance, by McDonald 1983). Our structure builder is purely compositional, and so the amount of information that it can take into account is limited. We treat structure-building as a recursive descent traversal of the message, using rules about how to build linguistic structures that correspond to local patterns in the message. During this, a simple grammatical constraint satisfaction system is used, to en</context>
<context position="25718" citStr="Kay 1979" startWordPosition="4226" endWordPosition="4227">es for mapping from local message patterns to linguistic structures. It is similar to the system described in Chester (1976) in the local nature of its operation, but Chester builds sentences directly, rather than via structural representations. Mann et al. (1982) would call our system a &amp;quot;direct translation&amp;quot; system. A system built in this fashion has the advantage of a very simple control structure and has the potential of having its principles expressed in modular, independent rules. Our linguistic structural descriptions are similar to the functional descriptions used in Functional Grammar (Kay 1979; Kay 1984). For example, the following is a slightly simplified version of the rule used to realize the hypo_result construct above: hypo_result (Agent, Act, State) —&gt; [sa.mesentence, conin = [root = &apos;if], first = [s, agent = [$Agent], pred = [active, morph = pres, $Act, adv =+ [ap, adv_word=[root=now]]]], rest = [s, pred = [VP, aux = [root = will], pred = [vP, $State, morph = in!, adv =+ [ap, adv_word=[root=afterwards]]]]]]. In this rule, the left hand side of the —&gt; is a Prolog pattern to be matched with part of the message (symbols beginning with uppercase letters represent variables, whic</context>
</contexts>
<marker>Kay, 1979</marker>
<rawString>Kay, Martin 1979 Functional Grammar. In: Proceedings of the 5th Annual Meeting of the Berkeley Linguistics Society. Berkeley, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>Functional Unification Grammar: A Formalism for Machine Translation. In:</title>
<date>1984</date>
<booktitle>Proceedings of COLING-84.</booktitle>
<location>Stanford, CA.</location>
<contexts>
<context position="25729" citStr="Kay 1984" startWordPosition="4228" endWordPosition="4229">ping from local message patterns to linguistic structures. It is similar to the system described in Chester (1976) in the local nature of its operation, but Chester builds sentences directly, rather than via structural representations. Mann et al. (1982) would call our system a &amp;quot;direct translation&amp;quot; system. A system built in this fashion has the advantage of a very simple control structure and has the potential of having its principles expressed in modular, independent rules. Our linguistic structural descriptions are similar to the functional descriptions used in Functional Grammar (Kay 1979; Kay 1984). For example, the following is a slightly simplified version of the rule used to realize the hypo_result construct above: hypo_result (Agent, Act, State) —&gt; [sa.mesentence, conin = [root = &apos;if], first = [s, agent = [$Agent], pred = [active, morph = pres, $Act, adv =+ [ap, adv_word=[root=now]]]], rest = [s, pred = [VP, aux = [root = will], pred = [vP, $State, morph = in!, adv =+ [ap, adv_word=[root=afterwards]]]]]]. In this rule, the left hand side of the —&gt; is a Prolog pattern to be matched with part of the message (symbols beginning with uppercase letters represent variables, which are to ma</context>
</contexts>
<marker>Kay, 1984</marker>
<rawString>Kay, Martin 1984 Functional Unification Grammar: A Formalism for Machine Translation. In: Proceedings of COLING-84. Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>James A Moore</author>
</authors>
<date>1981</date>
<journal>Computer Generation of Multiparagraph English Text. American Journal of Computational Linguistics,</journal>
<volume>Vol</volume>
<note>7, No I.</note>
<contexts>
<context position="35792" citStr="Mann and Moore (1981)" startWordPosition="5861" endWordPosition="5864">cy. We have thus opted for a multi-pass system. Multi-pass optimizing compilers need to have specialized internal languages (virtual machine codes) more abstract than the output machine codes and in terms of which optimizations can be stated. The analog in a natural language generation system would be a message language that could express at a level more abstract than linguistic structure the goals and intended content of a piece of language to be generated. We can see elements of such a language in the &amp;quot;realization specifications&amp;quot; of McDonald and Conklin (1982) and in the &amp;quot;protosentences&amp;quot; of Mann and Moore (1981). A crucial part of our own system is the use of a message language specialized for the explanation of plans. Our message language is a language specifically devised for expressing the objects that arise in plans and the kinds of things one might wish to say about them. The main types of statements (&amp;quot;utterances&amp;quot;) that can be made at present as part of our generated text are shown in Figure 3. These &amp;quot;utterances&amp;quot; mention actions and states, which could be domain actions and states (as appearing in the plan) or complex actions and states, formed according to the rules in Figure 4. The message lan</context>
</contexts>
<marker>Mann, Moore, 1981</marker>
<rawString>Mann, William C. and Moore, James A. 1981 Computer Generation of Multiparagraph English Text. American Journal of Computational Linguistics, Vol 7, No I.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William Mann</author>
<author>Madeleine Bates</author>
<author>Barbara Grosz</author>
<author>David McDonald</author>
<author>Kathleen McKeown</author>
<author>Swartout</author>
</authors>
<title>Text Generation.</title>
<date>1982</date>
<journal>American Journal of Computational Linguistics.</journal>
<volume>8</volume>
<location>William</location>
<contexts>
<context position="25374" citStr="Mann et al. (1982)" startWordPosition="4171" endWordPosition="4174">car)), state (user, not (located (cab)))), prereqs ( user, start (engine), state (user, located (cab)))), neccbefore (user, start (engine), go_to (user, function (front, car)))) 3.5 COMPOSITIONAL STRUCTURE BUILDING The next stage is to build a linguistic structure from this message expression. The structure-building component uses an ordered set of rules for mapping from local message patterns to linguistic structures. It is similar to the system described in Chester (1976) in the local nature of its operation, but Chester builds sentences directly, rather than via structural representations. Mann et al. (1982) would call our system a &amp;quot;direct translation&amp;quot; system. A system built in this fashion has the advantage of a very simple control structure and has the potential of having its principles expressed in modular, independent rules. Our linguistic structural descriptions are similar to the functional descriptions used in Functional Grammar (Kay 1979; Kay 1984). For example, the following is a slightly simplified version of the rule used to realize the hypo_result construct above: hypo_result (Agent, Act, State) —&gt; [sa.mesentence, conin = [root = &apos;if], first = [s, agent = [$Agent], pred = [active, mor</context>
</contexts>
<marker>Mann, Bates, Grosz, McDonald, McKeown, Swartout, 1982</marker>
<rawString>Mann, William; Bates, Madeleine; Grosz, Barbara; McDonald, David; McKeown, Kathleen; and Swartout, William 1982 Text Generation. American Journal of Computational Linguistics. Vol 8, No 2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D McDonald</author>
</authors>
<title>Natural Language Generation as a Computational Problem: An Introduction. In: Brady, Michael and Berwick, Robert (Eds.), Computational Models of Discourse,</title>
<date>1983</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="10527" citStr="McDonald 1983" startWordPosition="1712" endWordPosition="1713">e message. The idea is that message planning may be a relatively simple process and that the resulting message is then &amp;quot;cleaned up&amp;quot; and simplified by localized rewrite operations on the expression (&amp;quot;Message Simplification&amp;quot;). The message is a nonlinguistic object, and the task of structure building is to build a first description (a functional description much as in Functional Grammar; Kay 1979) of a linguistic object that will realize the intended message. We assume here that a &amp;quot;linguistically motivated&amp;quot; intermediate representation of the text is of value (this is argued for, for instance, by McDonald 1983). Our structure builder is purely compositional, and so the amount of information that it can take into account is limited. We treat structure-building as a recursive descent traversal of the message, using rules about how to build linguistic structures that correspond to local patterns in the message. During this, a simple grammatical constraint satisfaction system is used, to enforce grammaticality and propagate the consequences of syntactic decisions. The recursive descent terminates when it reaches elements of the message for which there are entries in the system&apos;s lexicon. Once a structur</context>
<context position="34804" citStr="McDonald 1983" startWordPosition="5699" endWordPosition="5700">ns pressed as raw Prolog code), which will then output the appropriately inflected word. 4 PLANS AND MESSAGES 4.1 THE MESSAGE LANGUAGE In some ways, a natural language generation system is like an optimizing compiler. Producing some sort of natural language from a symbolic input is not a task of great difficulty, but producing text that is smooth and readable is a challenge (and in general quite beyond the state of the art). With both tasks one has the option of planning the text and simplifying its form either in a single pass or in multiple passes. In language generation, McDonald&apos;s MUMBLE (McDonald 1983) produces and simplifies linguistic structures within a single pass of the input. Although the modeling of human language production may require a theory of this kind in the end, the result is a system where it can be hard to separate out the different principles of structure building and simplification, because these have all been conflated for reasons of efficiency. We have thus opted for a multi-pass system. Multi-pass optimizing compilers need to have specialized internal languages (virtual machine codes) more abstract than the output machine codes and in terms of which optimizations can b</context>
<context position="78477" citStr="McDonald 1983" startWordPosition="12804" endWordPosition="12805"> generated. The effective use of different stylistic devices depends in the end on simplifications that are justified on linguistic, rather than conceptual, grounds, and this suggests that our architecture should really incorporate a style module capable of reasoning at this level. Such a style module would necessarily have to take a more global view, looking at the overall linguistic effect of the localized basic text generation processes. It might be possible to introduce linguistic simplifications at structure-building time, relaxing the requirement of compositionality (indeed, this is how McDonald 1983 operates). We believe, however, that it would be preferable to attempt to treat it at least conceptually as a subsequent processing stage. 5.4 WAYS FORWARD In this paper we have described a system for generating natural language from automatically generated plans. Our main aim in developing the system was to produce a model of a complete system using state-of-the-art methodology and techniques, partly to evaluate the current state of knowledge, and partly to provide a basis for comparison for future work. Logically, then, there are two strands to further work based on this research: building </context>
</contexts>
<marker>McDonald, 1983</marker>
<rawString>McDonald, David D. 1983 Natural Language Generation as a Computational Problem: An Introduction. In: Brady, Michael and Berwick, Robert (Eds.), Computational Models of Discourse, MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kathleen R McKeown</author>
</authors>
<title>Generating Natural Language Text in Response to Questions about Database Structure.</title>
<date>1982</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<contexts>
<context position="30836" citStr="McKeown (1982)" startWordPosition="5057" endWordPosition="5058">t limit the possibilities for focus movement in and around the structure described. A collection of such macros enables us to implement what is essentially Dale&apos;s (1986) model of how discourse structure constrains pronominalization, which was inspired by the work of Grosz (1977) and Sidner (1979). The use of a macro like samesentence (keyed off particular structures in the message) sets up an environment that will allow certain pronominalizetions but exclude others. The choice of whether to pronominalize or not is then made on a local basis. It is interesting to compare this scheme to that of McKeown (1982), which also makes focus decisions on a local basis. McKeown&apos;s approach, almost the opposite to ours, is to take certain focus priorities as primary and then to attempt to select material in accordance with these. Our approach, which involves considering focus only after the material has already been organized, regards pronominalization more as a last-minute lexical optimization than as something that is planned in advance. We have considered incorporating some means of focus annotation in the message, but it is not always clear at this level what the focus should be. We have thus preferred to</context>
</contexts>
<marker>McKeown, 1982</marker>
<rawString>McKeown, Kathleen R. 1982 Generating Natural Language Text in Response to Questions about Database Structure. Ph.D. thesis, University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Earl D Sacerdoti</author>
</authors>
<title>Planning in a Hierarchy of Abstraction Spaces. In:</title>
<date>1973</date>
<booktitle>Proceedings of the Eighth International Joint Conference on Artificial Intelligence-83.</booktitle>
<location>Palo Alto, CA.</location>
<contexts>
<context position="6336" citStr="Sacerdoti 1973" startWordPosition="1045" endWordPosition="1046"> performed. Furthermore we assume that the time constraints involved in a plan can be displayed in an action graph, where an action is represented by a point and a line going rightward from one action to another indicates that the first action must take place before the second (this is true of most, but not all, Al plans—see for instance Tsang 1986). Figure 1 shows an action graph for a nonlinear plan for building a house. We further assume that plans are in general hierarchical. By this we mean that the planner operates in a hierarchical manner (almost standard in Al planners since ABSTRIPS; Sacerdoti 1973), first producing a plan specified at a very abstract level, and then successively refining it until the required level of detail is obtained. At each stage a process of criticism may impose new orderings between actions whose relative ordering seemed to be unconstrained at the previous levels of abstraction. For us, the history of this hierarchical expansion must be present in the final plan, since we assume no explicit interaction with the planner itself while it is operating. (We shall return in Section 5 to the question of whether the hierarchical plan structure is in fact a sufficient des</context>
</contexts>
<marker>Sacerdoti, 1973</marker>
<rawString>Sacerdoti, Earl D. 1973 Planning in a Hierarchy of Abstraction Spaces. In: Proceedings of the Eighth International Joint Conference on Artificial Intelligence-83. Palo Alto, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Earl D Sacerdoti</author>
</authors>
<title>The Non-Linear Nature of Plans. In:</title>
<date>1975</date>
<booktitle>Proceedings of the Fourth International Joint Conference on Artificial Intelligence,</booktitle>
<location>Tbilisi, USSR.</location>
<contexts>
<context position="5642" citStr="Sacerdoti 1975" startWordPosition="920" endWordPosition="921">stem&apos;s output and analyze some of its failures and successes. 2 SYSTEM OVERVIEW 2.1 PLANS AND PLANNERS For this project, we have adopted a traditional Al view of planning and plans. According to this view, the task of planning to achieve a goal is that of finding a set of (instantaneous) actions which, when performed, will transform the world as it is (the &amp;quot;initial state&amp;quot;) to a new world (the &amp;quot;final state&amp;quot;), which is similar to the present world, but where in addition the goal is true. We assume that the plans produced by our planner are nonlinear (almost standard with Al planners since NOAH; Sacerdoti 1975); that is, they only partially specify the order in which the actions are to be performed. Furthermore we assume that the time constraints involved in a plan can be displayed in an action graph, where an action is represented by a point and a line going rightward from one action to another indicates that the first action must take place before the second (this is true of most, but not all, Al plans—see for instance Tsang 1986). Figure 1 shows an action graph for a nonlinear plan for building a house. We further assume that plans are in general hierarchical. By this we mean that the planner ope</context>
</contexts>
<marker>Sacerdoti, 1975</marker>
<rawString>Sacerdoti, Earl D. 1975 The Non-Linear Nature of Plans. In: Proceedings of the Fourth International Joint Conference on Artificial Intelligence, Tbilisi, USSR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Candace L Sidner</author>
</authors>
<title>Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse.</title>
<date>1979</date>
<tech>Technical Report 537,</tech>
<institution>MIT Artificial Intelligence Laboratory,</institution>
<location>Cambridge, MA.</location>
<contexts>
<context position="30519" citStr="Sidner (1979)" startWordPosition="5003" endWordPosition="5004">that the relevant construction must have. Some of these properties (such as s) are intrinsic—essentially just features without values. Others are &amp;quot;macros&amp;quot; for bundles of simpler feature-value and property specifications. For example, samesentence is defined as being shorthand for a bundle of feature-value pairs that limit the possibilities for focus movement in and around the structure described. A collection of such macros enables us to implement what is essentially Dale&apos;s (1986) model of how discourse structure constrains pronominalization, which was inspired by the work of Grosz (1977) and Sidner (1979). The use of a macro like samesentence (keyed off particular structures in the message) sets up an environment that will allow certain pronominalizetions but exclude others. The choice of whether to pronominalize or not is then made on a local basis. It is interesting to compare this scheme to that of McKeown (1982), which also makes focus decisions on a local basis. McKeown&apos;s approach, almost the opposite to ours, is to take certain focus priorities as primary and then to attempt to select material in accordance with these. Our approach, which involves considering focus only after the materia</context>
</contexts>
<marker>Sidner, 1979</marker>
<rawString>Sidner, Candace L. 1979 Towards a Computational Theory of Definite Anaphora Comprehension in English Discourse. Technical Report 537, MIT Artificial Intelligence Laboratory, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William R Swartout</author>
</authors>
<title>XPLAIN: A System for Creating and Explaining Expert Consulting Programs.</title>
<date>1983</date>
<journal>Artificial Intelligence, Vol</journal>
<volume>21</volume>
<contexts>
<context position="1200" citStr="Swartout (1983)" startWordPosition="189" endWordPosition="190">This is partly because, although the domain of plans seems a priori to provide rich structure that a natural language generator can use, in practice a plan that is generated without the production of explanations in mind rarely contains the kinds of information that would yield an interesting natural language account. For instance, the hierarchical organization assigned to a plan is liable to reflect more a programmer&apos;s approach to generating a class of plans efficiently than the way that a human would naturally &amp;quot;chunk&amp;quot; the relevant actions. Such problems are, of course, similar to those that Swartout (1983) encountered with expert systems. In addition, AI planners have a restricted view of the world that is hard to match up with the normal semantics of natural language expressions. Thus constructs that are primitive to the planner may be only clumsily or misleadingly expressed in natural language, and the range of possible natural language constructs may be artificially limited by the shallowness of the planner&apos;s representations. 1 INTRODUCTION Planning is a central concept in Artificial Intelligence, and the state of the art in planning systems allows quite complex plans to be produced with ver</context>
<context position="70737" citStr="Swartout (1983)" startWordPosition="11527" endWordPosition="11528">rinciple every plan is justified by earlier actions achieving the preconditions of later actions, many plans do not contain this information in a useful form—in the housebuilding plan, for instance, the only preconditions that are required for an action in this plan to be performed are the successful completion of previous actions. That is, the person who has encoded the operators in terms of which the plan is constructed has &amp;quot;compiled in&amp;quot; certain ordering constraints without using the language of preconditions and effects effectively to explain them. One is reminded here of the problems that Swartout (1983) encountered in producing explanations from expert systems. The problem was that just because a set of rules was sufficient to produce expert behavior did not mean that those rules contained anything illuminating to put into explanations. Similarly in the planning area, there is no reason why a set of operators that are effective for producing useful plans need contain anything very interesting that can be put into a natural language account. Unfortunately, one cannot necessarily expect machine-generated plans to come at the right level of detail to be really useful to a human being. For insta</context>
</contexts>
<marker>Swartout, 1983</marker>
<rawString>Swartout, William R. 1983 XPLAIN: A System for Creating and Explaining Expert Consulting Programs. Artificial Intelligence, Vol 21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tate</author>
</authors>
<title>Project Planning using a Hierarchical Non-linear Planner. Dissertation Abstracts International Report 25,</title>
<date>1976</date>
<institution>University of Edinburgh,</institution>
<location>Austin</location>
<marker>Tate, 1976</marker>
<rawString>Tate, Austin 1976 Project Planning using a Hierarchical Non-linear Planner. Dissertation Abstracts International Report 25, University of Edinburgh, Edinburgh, U.K.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Tsang</author>
</authors>
<title>Plan Generation in a Temporal Frame. In:</title>
<date>1986</date>
<booktitle>Proceedings of the 7th European Conference on Artificial Intelligence,</booktitle>
<location>Brighton, U.K.</location>
<contexts>
<context position="6072" citStr="Tsang 1986" startWordPosition="1000" endWordPosition="1001">e present world, but where in addition the goal is true. We assume that the plans produced by our planner are nonlinear (almost standard with Al planners since NOAH; Sacerdoti 1975); that is, they only partially specify the order in which the actions are to be performed. Furthermore we assume that the time constraints involved in a plan can be displayed in an action graph, where an action is represented by a point and a line going rightward from one action to another indicates that the first action must take place before the second (this is true of most, but not all, Al plans—see for instance Tsang 1986). Figure 1 shows an action graph for a nonlinear plan for building a house. We further assume that plans are in general hierarchical. By this we mean that the planner operates in a hierarchical manner (almost standard in Al planners since ABSTRIPS; Sacerdoti 1973), first producing a plan specified at a very abstract level, and then successively refining it until the required level of detail is obtained. At each stage a process of criticism may impose new orderings between actions whose relative ordering seemed to be unconstrained at the previous levels of abstraction. For us, the history of th</context>
</contexts>
<marker>Tsang, 1986</marker>
<rawString>Tsang, Edward 1986 Plan Generation in a Temporal Frame. In: Proceedings of the 7th European Conference on Artificial Intelligence, Brighton, U.K.</rawString>
</citation>
<citation valid="false">
<authors>
<author>I NOTES</author>
</authors>
<title>Current address: Department of Artificial Intelligence,</title>
<journal>University of Edinburgh,</journal>
<booktitle>South Bridge, EDINBURGH EH1 1HN,</booktitle>
<volume>80</volume>
<location>United Kingdom.</location>
<marker>NOTES, </marker>
<rawString>NOTES I. Current address: Department of Artificial Intelligence, University of Edinburgh, 80 South Bridge, EDINBURGH EH1 1HN, United Kingdom.</rawString>
</citation>
<citation valid="false">
<title>In the node descriptions we distinguish explicitly between goals and actions that achieve goals. The reason for this is discussed in</title>
<journal>Section</journal>
<volume>5</volume>
<pages>below.</pages>
<marker></marker>
<rawString>2. In the node descriptions we distinguish explicitly between goals and actions that achieve goals. The reason for this is discussed in Section 5 below.</rawString>
</citation>
<citation valid="false">
<title>It is possible, however, to specify that, for a given domain, there will only ever be one agent.</title>
<marker></marker>
<rawString>3. It is possible, however, to specify that, for a given domain, there will only ever be one agent.</rawString>
</citation>
<citation valid="true">
<date>1989</date>
<journal>Computational Linguistics</journal>
<volume>15</volume>
<pages>249</pages>
<marker>1989</marker>
<rawString>Computational Linguistics Volume 15, Number 4, December 1989 249</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>