<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000555">
<title confidence="0.993128">
Effective Phrase Translation Extraction from Alignment Models
</title>
<author confidence="0.764796">
Ashish Venugopal
</author>
<affiliation confidence="0.799176">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.635792">
Pittsburgh, PA 15213
</address>
<email confidence="0.998227">
ashishv@cs.cmu.edu
</email>
<author confidence="0.976918">
Stephan Vogel
</author>
<affiliation confidence="0.8840105">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.646835">
Pittsburgh, PA 15213
</address>
<email confidence="0.99818">
vogel+@cs.cmu.edu
</email>
<author confidence="0.977553">
Alex Waibel
</author>
<affiliation confidence="0.8846765">
Language Technologies Institute
Carnegie Mellon University
</affiliation>
<address confidence="0.64724">
Pittsburgh, PA 15213
</address>
<email confidence="0.998912">
ahw@cs.cmu.edu
</email>
<sectionHeader confidence="0.995642" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998669">
Phrase level translation models are ef-
fective in improving translation qual-
ity by addressing the problem of local
re-ordering across language boundaries.
Methods that attempt to fundamentally
modify the traditional IBM translation
model to incorporate phrases typically do
so at a prohibitive computational cost. We
present a technique that begins with im-
proved IBM models to create phrase level
knowledge sources that effectively repre-
sent local as well as global phrasal con-
text. Our method is robust to noisy align-
ments at both the sentence and corpus
level, delivering high quality phrase level
translation pairs that contribute to signif-
icant improvements in translation quality
(as measured by the BLEU metric) over
word based lexica as well as a competing
alignment based method.
</bodyText>
<sectionHeader confidence="0.999331" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999554590909091">
Statistical Machine Translation defines the task
of translating a source language sentence
into a target language sentence
. The traditional framework presented in
(Brown et al., 1993) assumes a generative process
where the source sentence is passed through a noisy
stochastic process to produce the target sentence.
The task can be formally stated as finding the
s.t = where the search compo-
nent is commonly referred to as the decoding step
(Wang and Waibel, 1998). Within the generative
model, the Bayes reformulation is used to estimate
where is considered the lan-
guage model, and is the translation model;
the IBM (Brown et al., 1993) models being the de
facto standard. Direct translation approaches (Fos-
ter, 2000) consider estimating directly, and
work by (Och and Ney, 2002) show that similar
or improved results are achieved by replacing
in the optimization with , at the cost of devi-
ating from the Bayesian framework. Regardless of
the approach, the question of accurately estimating
a model of translation from a large parallel or com-
parable corpus is one of the defining components
within statistical machine translation.
Re-ordering effects across languages have been
modeled in several ways, including word-based
(Brown et al., 1993), template-based (Och et al.,
1999) and syntax-based (Yamada, Knight, 2001).
Analyzing these models from a generative mind-
set, they all assume that the atomic unit of lexi-
cal content is the word, and re-ordering effects are
applied above that level. (Marcu, Wong, 2002) il-
lustrate the effects of assuming that lexical corre-
spondence can only be modeled at the word level,
and motivate a joint probability model that explic-
itly generates phrase level lexical content across
both languages. (Wu, 1995) presents a bracketing
method that models re-ordering at the sentence level.
Both (Marcu, Wong, 2002; Wu, 1995) model the re-
ordering phenomenon effectively, but at significant
computational expense, and tend to be difficult to
scale to long sentences. Reasons to introduce phrase
level translation knowledge sources have been ade-
quately shown and confirmed by (Och, Ney, 2000),
and we focus on methods to build these sources from
existing, mature components within the translation
process.
This paper presents a method of phrase extraction
from alignment data generated by IBM Models. By
working directly from alignment data with appro-
priate measures taken to extract accurate translation
pairs, we try to avoid the computational complex-
ity that can result from methods that try to create
globally consistent alignment model phrase segmen-
tations.
We first describe the information available within
alignment data, and go on to describe a method
for extracting high quality phrase translation pairs
from such data. We then discuss the implications of
adding phrasal translation pairs to the decoding pro-
cess, and present evaluation results that show sig-
nificant improvements when applying the described
extraction technique. We end with a discussion of
strengths and weaknesses of this method and the po-
tential for future work.
</bodyText>
<sectionHeader confidence="0.976028" genericHeader="introduction">
2 Motivation
</sectionHeader>
<bodyText confidence="0.999287739130435">
Alignment models associate words and their transla-
tions at the sentence level creating a translation lexi-
con across the language pair. For each sentence pair,
the model also presents the maximally likely associ-
ation between each source and target word across the
sentence pair, forming an alignment map for each
sentence pair in the training corpus. The most likely
alignment pattern between a source and target sen-
tence under the trained alignment model will be re-
ferred to as the maximum approximation, which un-
der HMM alignment (Vogel et al., 1996) model cor-
responds to the Viterbi path. A set of words in the
source sentence associated with a set of words in
the target sentence is considered a phrasal pair and
forms a partition within the alignment map. Fig-
ure . shows a source and target sentence pair with
points indicating alignment points.
A phrasal translation pair within a sentence
pair can be represented as the 4-tuple hypothesis
representing an index and length
within the source and the target sentence pair
, respectively. The phrasal extraction task involves
selecting phrasal hypotheses based on the alignment
</bodyText>
<figureCaption confidence="0.927755333333333">
Figure 1: Sample source and target aligment
map. Partitions/Potential translations for source
phrase s2s3 are shown by rounded boxes.
</figureCaption>
<bodyText confidence="0.99974705">
model (both the translation lexicon as well as the
maximal approximation). The maximal approxima-
tion captures context at the sentence level, while
the lexicon provides a corpus level translation esti-
mate, motivating the alignment model as a starting
point for phrasal extraction. The extraction tech-
nique must be able to handle alignments that are
only partially correct, as well as cases where the sen-
tence pairs have been incorrectly matched as parallel
translations within the corpus. Accommodating for
the noisy corpus is an increasingly important com-
ponent of the translation process, especially when
considering languages where no manually aligned
parallel corpus is available.
Building a phrasal lexicon involves Generation,
Scoring, and Pruning steps, corresponding to gen-
erating a set of candidate translation pairs, scoring
them based on the translation model, and pruning
them to account for noise within the data as well as
the extraction process.
</bodyText>
<sectionHeader confidence="0.997895" genericHeader="method">
3 Generation
</sectionHeader>
<bodyText confidence="0.997265647058824">
The generation step refers to the process of identify-
ing source phrases that require translations and then
extracting translations from the alignment model
data. We begin by identifying all source language n-
grams upto some within the training corpus. When
the test sentences that require translation are known,
we can simply extract those n-grams that appear in
the test sentences. For each of these n-grams, we
create a set of candidate translations extracted from
the corpus. The primary motivation to restrict the
identification step to the test sentence n-grams is
savings in computational expense, and the result is
a phrasal translation source that extracts translation
pairs limited to the test sentences. For each source
language n-gram within the pool, we have to find a
set of candidate translations. The generation task is
formally defined as finding in Equation (1)
</bodyText>
<equation confidence="0.740878">
(1)
.
</equation>
<bodyText confidence="0.999983925925926">
We extract these candidates from the alignment
map by examining each sentence pair where the
source n-gram occurs, and extracting all possible tar-
get phrase translations using a sliding window ap-
proach. We extract candidate translations of phrase
length to , starting at offset to . Figure 1.
shows circular boxes indicating each potential parti-
tion region. One particular partition is indicated by
the shading.
Over all occurrences of the n-gram within the sen-
tences as well as across sentences, a sizeable can-
didate pool is generated that attempts the cover the
translated usage of the source n-gram within the
corpus. This set is large, and contains several spuri-
ous translations, and does not consider other source
side n-grams within each sentence. The deliberate
choice to avoid creating a consistent partitioning of
the sentence pairs across n-grams reflects the abil-
ity to model partially correct alignments within sen-
tences. This sliding window can be restricted to ex-
clude word-word translations, ie ,if
other sources are available that are known to be more
accurate. Now that the candidate pool has been gen-
erated, it needs to be scored and pruned to reflect rel-
ative confidence between candidate translations and
to remove spurious translations due to the sliding
window approach.
</bodyText>
<sectionHeader confidence="0.994711" genericHeader="method">
4 Scoring
</sectionHeader>
<bodyText confidence="0.980909411764706">
The candidate translations for the source n-gram
now need to be scored and ranked according to some
measure of confidence. Each candidate translation
pair defines a partition within the sentence map,
and this partitioning can be scored for confidence
in translation quality. We estimate translation con-
fidence by measures from three models; the estima-
tion from the maximum approximation (alignment
map), estimation from the word based translation
lexicon, and language specific measures. Each of
the scoring methods discussed below contributes to
the final score under (2)
(2)
where = and refers to a translation hy-
pothesis for a given source n-gram . From now on
we will refer to a with regard to a particular
implicitly.
</bodyText>
<subsectionHeader confidence="0.998606">
4.1 Alignment Map
</subsectionHeader>
<bodyText confidence="0.99968525">
We define two kinds of scores, within sentence con-
sistency and across sentence consistency from the
alignment map, in order to represent local and global
context effects.
</bodyText>
<subsectionHeader confidence="0.9965">
4.2 Within Sentence
</subsectionHeader>
<bodyText confidence="0.995518352941177">
The partition defined by each candidate translation
pair imposes constraints over the maximum approx-
imation hypothesis for sentences in which it occurs.
We evaluate the partition by examining its consis-
tency with the maximum approximation hypothe-
sis by considering the alignment hypothesis points
within the sentence. An alignment point
(source, target) is said to be consistent if it occurs
within the partition defined by
is considered inconsistent in two cases.
and or
in ( + defines
) determines a set of consistent and inconsistent
points. Figure 1. shows inconsistent points with re-
spect to the shaded partition by drawing an X over
the alignment point. The within sentence consis-
tency scoring metric is defined in Equation (5).
</bodyText>
<figure confidence="0.645887666666667">
(5)
and or
(4)
</figure>
<bodyText confidence="0.998473125">
where is the source n-gram for which we are ex-
tracting translations, is the set of all partitions,
and refers to the word at position in the source
sentence . is then the set of all translations
for source n-gram , and is a specific translation
hypothesis within this set. When considering only
those hypothesis translation extracted from a partic-
ular sentence pair , we use
</bodyText>
<equation confidence="0.828298333333333">
.
(3)
Each
</equation>
<bodyText confidence="0.998026">
This measure represents consistency of
within the maximal approxima-
tion alignment for sentence pair .
</bodyText>
<subsectionHeader confidence="0.999125">
4.3 Across Sentence
</subsectionHeader>
<bodyText confidence="0.998643638888889">
Several hypothesis within are similar or iden-
tical to those in where . We want to
score hypothesis that are consistent across sentences
higher than those that occur rarely, as the former are
assumed to be the correct translations in context. We
want to account for different contexts across sen-
tences; therefore we want to highlight similar trans-
lations, not simply exact matches. We use a word
level Levenstein distance to compare the target side
hypotheses within . Each element within
(the complete candidate translation list for ) is as-
signed the average Levenstein distance with all other
elements as its across sentence consistence score; ef-
fectively performing a single pass average link clus-
tering to identify the correct translations.
The translation lexicon provides a conditional
probability estimate for each (
refers to the word at position in sentence ) within
the maximum approximation. Depending on the
direction in which the traditional IBM models are
trained, we can either condition on the source or tar-
get side, while joint probability models can give us a
bidirectional estimate. These translation probability
estimates are used to weight the within the
methods described above. Instead of simply count-
ing the number of consistent/inconsistent
,
we sum the probability estimates for each
. So far we have only considered the points
within the partition where alignment points are pre-
dicted by the maximal approximation. The transla-
tion lexicon provides estimates at the word level, so
we can construct a scoring measure for the complete
region within that models the com-
plete probability of the partition. The lexical scoring
equation below models this effect.
</bodyText>
<equation confidence="0.585298">
(6)
</equation>
<bodyText confidence="0.9994876">
where calculates the Levenshein distance be-
tween the target phrases within two hypothesis and
, is the number of elements in .
The higher the , the more likely the hy-
pothesis pair is a correct translation. The clustering
approach accounts for noise due to incorrect sen-
tence alignment, as well as the different contexts
in which a particular source n-gram can be used.
As predicted by the formulation of this method,
preference is given towards shorter target transla-
tions. This effect can be countered by introducing a
phrase length model to approximate the difference in
phrases lengths across the language boundary. This
will be discussed further as a language specific scor-
ing method.
</bodyText>
<subsectionHeader confidence="0.99779">
4.4 Alignment Lexicon
</subsectionHeader>
<bodyText confidence="0.999645214285715">
The methods presented above used the maximum
approximation to score candidate translation hy-
potheses. The translation lexicon generated by the
IBM models provides translation estimates at the
word level built on the complete training corpus.
These corpus level estimates can be integrated into
our scoring paradigm to balance the sentence level
estimates from the alignment map methods.
(7)
This method prefers longer target side phrases due
to the sum over the target words within the parti-
tion. Although it would also prefer short source side
phrases, we are only concerned with comparing hy-
pothesis partitions for a given source n-gram .
</bodyText>
<subsectionHeader confidence="0.998609">
4.5 Language Specific
</subsectionHeader>
<bodyText confidence="0.997590205128205">
The nature of the phrasal association between lan-
guages varies depending on the level of inflexion,
morphology as well as other factors. The predomi-
nant language specific correction to the scoring tech-
niques discussed above models differences in phrase
lengths across languages. For example, when com-
paring English and Chinese translations, we see that
on average, the English sentence is approximately
1.3 times longer (under our current segmentation
in the small data track). To model these language
specific effects, we introduce a phrase length scor-
ing component that is based on the ratio of sen-
tence length between languages. We build a sen-
tence length model based on the DiffRatio statis-
tic defined as where I is the
source sentence length and J is the target sentence
length. Let be the average over
the sentences in the corpus, and be the vari-
ance; thereby defining a normal distribution over the
DiffRatio statistic. Using the standard Z normaliza-
tion technique under a normal distribution param-
eterized by , we can estimate the proba-
bility that a new DiffRatio calculated on the phrasal
pair can be generated by the model, giving us the
scoring estimate below.
(8)
To improve the model we might consider exam-
ining known phrase translation pairs if this data is
available. We explore the language specific differ-
ence further by noting that English phrases contain
several function words that typically align to the
empty Chinese word. We accounted for this effect
within the scoring process by treating all target lan-
guage (English) phrases that only differed by the
function words on the phrase boundary as the same
translation. The burden of selecting the appropriate
hypothesis within the decoding process is moved to-
wards the language model under this corrective strat-
egy.
</bodyText>
<sectionHeader confidence="0.993244" genericHeader="method">
5 Pruning
</sectionHeader>
<bodyText confidence="0.999833642857143">
The list of candidate translations for each source n-
gram is large, and must be pruned to select the
most likely set of translations. This pruning is re-
quired to ensure that the decoding process remains
computationally tractable. Simple threshold meth-
ods that rank hypotheses by their final score and
only save the top hypotheses will not work here,
since phrases differ in the number ofpossible correct
translations they could have when used in different
contexts. Given the score ordered set of candidate
phrases , we would like to label some subset as
incorrect translations and remove them from the set.
We approach this task as a density estimation prob-
lem where we need to separate the distribution of
the incorrectly translated hypothesis from the dis-
tribution of the likely translations. Instead of using
the maximum likelihood criteria, we use the maxi-
mal separation criteria ie. selecting a splitting point
within the scores to maximize the difference of the
mean score between distributions as shown below.
where is the mean score of those hypothesis
with a score less than , and is the mean score
of those hypothesis with a greater than or equal to
. Once pruning is completed, we convert the scores
into a probability measure conditioned on the source
n-gram and assign the probability estimate as the
translation probability for the hypothesis as shown
below.
</bodyText>
<equation confidence="0.698274">
(10)
</equation>
<bodyText confidence="0.9256195">
(10) calculates direct translation probabilities, ie
. As mentioned earlier, (Och and Ney, 2002),
show that using direction translation estimates in
the decoding process as compared with calculating
as prescribed by the Bayesian framework does
not reduce translation quality. Our results corrob-
orate these findings and we use (10) as the phrase
level translation model estimate within our decoder.
</bodyText>
<sectionHeader confidence="0.99812" genericHeader="method">
6 Integration
</sectionHeader>
<bodyText confidence="0.999975652173913">
Phrase translation pairs that are generated by the
method described in this paper are finally scored
with estimates of translation probability, which can
be conditioned on the target language if necessary.
These estimates fit cleanly into the decoding pro-
cess, except for the issue of phrase length. Tra-
ditional word lexicons propose translations for one
source word, while with phrase translations, a single
hypothesis pair can span several words in the source
or target language. Comparing between a path that
uses a phrase compared to one that uses multiple
words (even if the constituent words are the same)
is difficult. The word level pathway involves the
product of several probabilities, whereas the phrasal
path is represented by one probability score. Po-
tential solutions are to introduce translation length
models or to learn scaling factors for phrases of dif-
ferent lengths. Results in this paper have been gener-
ated by empirically determining a scaling factor that
was inversely proportional to the lenth of the phrase,
causing each translation to have a score compara-
ble to the product of the word to word translations
within the phrase.
</bodyText>
<sectionHeader confidence="0.921842" genericHeader="method">
7 HMM Phrase Extraction
</sectionHeader>
<bodyText confidence="0.951727">
In order to compare our method to a well under-
(9) stood phrase baseline, we present a method that ex-
</bodyText>
<table confidence="0.793934666666667">
Small 3540 90K 115K
Large 77558 2.46M 2.69M
Testing 993 27K NA
</table>
<tableCaption confidence="0.888641">
Table 1: Corpus figures indicating no. of sentence
pairs, no. of Chinese and English words
</tableCaption>
<bodyText confidence="0.9992976875">
tracts phrases by harvesting the Viterbi path from an
HMM alignment model (Vogel et al., 1996). The
HMM alignment model is computationally feasible
even for very long sentences, and the phrase ex-
traction method does not have limits on the length
of extracted target side phrase. For each source
phrase ranging from positions to the target
phrase is given by and
, where and
refers to an index in the target sentence pair. We cal-
culate phrase translation probabilities (the scores for
each extracted phrase) based on a statistical lexicon
for the constituent words in the phrase. As the IBM1
alignment model gives the global optimum for the
lexical probabilities, this is the natural choice. This
leads to the phrase translation probability
</bodyText>
<equation confidence="0.678442">
(11)
</equation>
<bodyText confidence="0.999614142857143">
where and denotes the length of the target
phrase , source phrase , and the word probabil-
ities are estimated using the IBM1 word
alignment model. The phrases extracted from this
method can be used directly within our in-house
decoder without the significant changes that other
phrase based methods could require.
</bodyText>
<sectionHeader confidence="0.9926" genericHeader="evaluation">
8 Experimentation
</sectionHeader>
<bodyText confidence="0.999540949152543">
IBM alignment models were trained up to model
4 using GIZA (Al Onaizan et al., 1999) from Chi-
nese to English and Chinese to English on two
tracks of data. Figures describing the characteris-
tics of each track as well as the test sentences are
shown in Table (1). All the data were extracted
from a newswire source. We applied our in house
segmentation toolkit on the Chinese data and per-
formed basic preprocessing which included; lower-
casing, tagging dates, times and numbers on both
languages. Translation quality is evaluated by two
metrics, (MTEval, 2002) and BLEU (Papeneni et
al., 2001), both of which measure n-gram matches
between the translated text and the reference trans-
lations. NIST is more sensitive to unigram precision
due to its emphasis toward high perplexity words.
Four reference translations were available for each
test sentence. We first compare against a system
built using word level lexica only to reiterate the im-
pact of phrase translation, and then show gains by
our method over a system that utilizes phrase ex-
tracted from the HMM method. The word level sys-
tem consisted of a hand crafted (Linguistics Data
Consortium) bilingual dictionary and a statistical
lexicon derived from training IBM model 1. In our
experiments we found that although training higher
order IBM models does yield lower alignment error
rates when measured against manually aligned sen-
tences, the highest translation quality is achieved by
using a lexicon extracted from the Model 1 align-
ment. Experiments were run with a language model
(LM) built on a 20 million word news source corpus
using our in house decoder which performs a mono-
tone decoding without reordering. To implement our
phrase extraction technique, the maximum approx-
imation alignments were combined with the union
operation as described in (Och et al., 1999), result-
ing in a dense but inaccurate alignment map as mea-
sured against a human aligned gold standard. Since
bi-directional translation models are available, scor-
ing was performed in both directions, using IBM
Model 1 lexica for the within sentence scoring. The
final phrase level scores computed in each direction
were combined by a weighted average before the
pruning step. Source side phrases were restricted
to be of length 2 or higher since word lexica were
available. Weights for each scoring metric were de-
termined empirically against a validation set (align-
ment map scores were assigned the highest weight-
ing). Table (2) shows results on the small data
track, while Table (3) shows results on the large data
track. The technique described in this paper is la-
belled in the tables. The results show that
the phrase extraction method described in this paper
contribute to statistically significant improvements
over the baseline word and phrase level(HMM) sys-
tems. When compared against the HMM phrases,
our technique show statistically significant improve-
ments. Statistical significance is evaluated by con-
</bodyText>
<table confidence="0.99752425">
Baseline-Word 0.135 6.19
Baseline-Word+Phrases 0.167 6.71
Baseline-HMM 0.166 6.49
Baseline-HMM+Phrases 0.174 6.71
</table>
<tableCaption confidence="0.700267">
Table 2: Small track results
</tableCaption>
<table confidence="0.99903975">
Baseline-Word 0.147 6.62
Baseline-Word+Phrases 0.190 7.48
Baseline-HMM 0.187 7.42
Baseline-HMM+Phrases 0.197 7.60
</table>
<tableCaption confidence="0.999639">
Table 3: Large track results
</tableCaption>
<bodyText confidence="0.999792555555556">
sidering deviations in sentence level NIST scores
over the 993 sentence test set with a NIST improve-
ment of 0.05 being statistically significant at the 0.01
alpha level. In combination with the HMM method,
our technique delivers further gains, providing evi-
dence that different kinds of phrases have been learnt
by each method. The improvements caused by our
methods is more apparent in the NIST score rather
than the BLEU score. We predict that this effect is
due to the language specific correction that treats tar-
get phrases with function words at the boundaries as
the same phrase. This correction cause the burden
to be placed on the language model to select the cor-
rect phrase instance from several possible transla-
tions. Correctly translating function words dramati-
cally boosts the NIST measure as it places emphasis
on high perplexity words ie. those with diverse con-
texts.
</bodyText>
<sectionHeader confidence="0.997388" genericHeader="conclusions">
9 Conclusions
</sectionHeader>
<bodyText confidence="0.999926612903226">
We have presented a method to efficiently ex-
tract phrase relationships from IBM word alignment
models by leveraging the maximum approximation
as well as the word lexicon. Our method is signifi-
cantly less computationally expensive than methods
that attempt to explicitly model phrase level inter-
actions within alignment models, and recovers well
from noisy alignments at the sentence and corpus
level. The significant improvements above the base-
line carry through when this method is combined
with other phrasal and word level methods. Further
experimentation is required to fully appreciate the
robustness of this technique, especially when con-
sidering a comparable, but not parallel, corpus. The
language specific scoring methods have a significant
impact on translation quality, and further work to ex-
tend these methods to represent specific characteris-
tics of each language, promises to deliver further im-
provements. Although the method performs well, it
lacks an explanatory framework through the extrac-
tion process; instead it leverages the well understood
fundamentals of the traditional IBM models.
Combining phrase level knowledge sources
within a decoder in an effective manner is currently
our primary research interest, specifically integrat-
ing knowledge sources of varying reliability. Our
method has shown to be an effective contributing
component within the translation framework and we
expect to continue to improve the state of the art
within machine translation by improving phrasal ex-
traction and integration.
</bodyText>
<sectionHeader confidence="0.999069" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999431264150943">
Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della
Pietra, and Robert L. Mercer 1993. The Mathematics
of Statistical Machine Translation: Parameter Estima-
tion, Computational Linguisics vol 19(2) 1993
George Foster 2000. A Maximum Entropy Minimum Di-
vergence Translation Model, Proc. of the 38th Annual
Meeting of the Association for Computational Lin-
guistics
Daniel Marcu and William Wong 2002. A Phrase-Based,
Joint Probability Modelfor Statistical Machine Trans-
lation, Proc. of the Conference on Empirical Methods
in Natural Language Processing , Philadelphia, PA
NIST 2002. MT Evaluation Kit Version 9,
www.nist.gov/speech/tests/mt/
Franz Josef Och, Hermann Ney 2002. Discriminative
Training and Maximum Entropy Models for Statistical
Machine Translation, Proc. North American Associa-
tion for Computational Linguistics
Franz Josef Och and Hermann Ney 200. A Comparison
of Alignment Models for Statistical Machine Transla-
tion, Proc. of the 18th International Conference on
Computational Linguistics. Saarbrucken, Germany
Franz Josef Och, Christoph Tillmann, Hermann Ney
1999. Improved Alignment Models for Statistical Ma-
chine Translation, Proc. of the Joint Conference of
Empirical Methods in Natural Language Processing,
p20-28, MD.
Al’ Onaizan, Jan Curin, Michael Jahr, Kevin Knight,
John Lafferty, Dan Melamed, Franz-Josef Och, David
Purdy, Noah H. Smith and David Yarowsky 1999.
Statistical Machine Translation, Final Report, JHU
Summer Workshop
Kishore Papeneni, Salim Roukos, Todd Ward 2001.
BLEU: A Method for Automatic Evaluation of Ma-
chine Translation, IBM Research Report, RC22176
Stephan Vogel, Hermann Ney, and Christoph Tillmann
1996. HMM-based Word Alignment in Statistical
Translation, Proc. of COLING ’96: The 16th Interna-
tional Conference on Computational Linguistics, pp.
836-841. Copenhagen, Denmark
Yeyi Wang, Alex Waibel 1998. Fast Decodingfor Statis-
tical Machine Translation, Proc. of the International
Conference in Spoken Language Processing
Dekai Wu 1995. Stochastic Inversion Transduction
Grammars, with Application to Segmentation, Brack-
eting, and Alignment of Parallel Corpora, Proceed-
ings of the 14th International Joint Conference on Ar-
tificial Intelligence (IJCAI-95), pp. 1328-1335. Mon-
treal
Kenji Yamada and Kevin Knight 2001. A syntax-based
statistical translation model, Proc. of the 39th An-
nual Meeting of the Association for Computational
Linguistics, France
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.928138">
<title confidence="0.998871">Effective Phrase Translation Extraction from Alignment Models</title>
<author confidence="0.971809">Ashish Venugopal</author>
<affiliation confidence="0.993118">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.999821">Pittsburgh, PA 15213</address>
<email confidence="0.998246">ashishv@cs.cmu.edu</email>
<author confidence="0.999926">Stephan Vogel</author>
<affiliation confidence="0.9984295">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.999783">Pittsburgh, PA 15213</address>
<email confidence="0.983473">vogel+@cs.cmu.edu</email>
<author confidence="0.999879">Alex Waibel</author>
<affiliation confidence="0.9985765">Language Technologies Institute Carnegie Mellon University</affiliation>
<address confidence="0.999821">Pittsburgh, PA 15213</address>
<email confidence="0.997054">ahw@cs.cmu.edu</email>
<abstract confidence="0.99950880952381">Phrase level translation models are effective in improving translation quality by addressing the problem of local re-ordering across language boundaries. Methods that attempt to fundamentally modify the traditional IBM translation model to incorporate phrases typically do so at a prohibitive computational cost. We present a technique that begins with improved IBM models to create phrase level knowledge sources that effectively represent local as well as global phrasal context. Our method is robust to noisy alignments at both the sentence and corpus level, delivering high quality phrase level translation pairs that contribute to significant improvements in translation quality (as measured by the BLEU metric) over word based lexica as well as a competing alignment based method.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<date>1993</date>
<journal>The Mathematics of Statistical Machine Translation: Parameter Estimation, Computational Linguisics</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1392" citStr="Brown et al., 1993" startWordPosition="191" endWordPosition="194">odels to create phrase level knowledge sources that effectively represent local as well as global phrasal context. Our method is robust to noisy alignments at both the sentence and corpus level, delivering high quality phrase level translation pairs that contribute to significant improvements in translation quality (as measured by the BLEU metric) over word based lexica as well as a competing alignment based method. 1 Introduction Statistical Machine Translation defines the task of translating a source language sentence into a target language sentence . The traditional framework presented in (Brown et al., 1993) assumes a generative process where the source sentence is passed through a noisy stochastic process to produce the target sentence. The task can be formally stated as finding the s.t = where the search component is commonly referred to as the decoding step (Wang and Waibel, 1998). Within the generative model, the Bayes reformulation is used to estimate where is considered the language model, and is the translation model; the IBM (Brown et al., 1993) models being the de facto standard. Direct translation approaches (Foster, 2000) consider estimating directly, and work by (Och and Ney, 2002) sh</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent J. Della Pietra, and Robert L. Mercer 1993. The Mathematics of Statistical Machine Translation: Parameter Estimation, Computational Linguisics vol 19(2) 1993</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
</authors>
<title>A Maximum Entropy Minimum Divergence Translation Model,</title>
<date>2000</date>
<booktitle>Proc. of the 38th Annual Meeting of the Association for Computational Linguistics</booktitle>
<contexts>
<context position="1927" citStr="Foster, 2000" startWordPosition="281" endWordPosition="283">anguage sentence . The traditional framework presented in (Brown et al., 1993) assumes a generative process where the source sentence is passed through a noisy stochastic process to produce the target sentence. The task can be formally stated as finding the s.t = where the search component is commonly referred to as the decoding step (Wang and Waibel, 1998). Within the generative model, the Bayes reformulation is used to estimate where is considered the language model, and is the translation model; the IBM (Brown et al., 1993) models being the de facto standard. Direct translation approaches (Foster, 2000) consider estimating directly, and work by (Och and Ney, 2002) show that similar or improved results are achieved by replacing in the optimization with , at the cost of deviating from the Bayesian framework. Regardless of the approach, the question of accurately estimating a model of translation from a large parallel or comparable corpus is one of the defining components within statistical machine translation. Re-ordering effects across languages have been modeled in several ways, including word-based (Brown et al., 1993), template-based (Och et al., 1999) and syntax-based (Yamada, Knight, 200</context>
</contexts>
<marker>Foster, 2000</marker>
<rawString>George Foster 2000. A Maximum Entropy Minimum Divergence Translation Model, Proc. of the 38th Annual Meeting of the Association for Computational Linguistics</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Marcu</author>
<author>William Wong</author>
</authors>
<title>A Phrase-Based, Joint Probability Modelfor Statistical Machine Translation,</title>
<date>2002</date>
<booktitle>Proc. of the Conference on Empirical Methods in Natural Language Processing ,</booktitle>
<location>Philadelphia, PA</location>
<marker>Marcu, Wong, 2002</marker>
<rawString>Daniel Marcu and William Wong 2002. A Phrase-Based, Joint Probability Modelfor Statistical Machine Translation, Proc. of the Conference on Empirical Methods in Natural Language Processing , Philadelphia, PA</rawString>
</citation>
<citation valid="true">
<authors>
<author>NIST</author>
</authors>
<date>2002</date>
<journal>MT Evaluation Kit Version 9, www.nist.gov/speech/tests/mt/</journal>
<marker>NIST, 2002</marker>
<rawString>NIST 2002. MT Evaluation Kit Version 9, www.nist.gov/speech/tests/mt/</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative Training and Maximum Entropy Models for Statistical Machine Translation,</title>
<date>2002</date>
<booktitle>Proc. North American Association for Computational Linguistics</booktitle>
<contexts>
<context position="1989" citStr="Och and Ney, 2002" startWordPosition="290" endWordPosition="293"> (Brown et al., 1993) assumes a generative process where the source sentence is passed through a noisy stochastic process to produce the target sentence. The task can be formally stated as finding the s.t = where the search component is commonly referred to as the decoding step (Wang and Waibel, 1998). Within the generative model, the Bayes reformulation is used to estimate where is considered the language model, and is the translation model; the IBM (Brown et al., 1993) models being the de facto standard. Direct translation approaches (Foster, 2000) consider estimating directly, and work by (Och and Ney, 2002) show that similar or improved results are achieved by replacing in the optimization with , at the cost of deviating from the Bayesian framework. Regardless of the approach, the question of accurately estimating a model of translation from a large parallel or comparable corpus is one of the defining components within statistical machine translation. Re-ordering effects across languages have been modeled in several ways, including word-based (Brown et al., 1993), template-based (Och et al., 1999) and syntax-based (Yamada, Knight, 2001). Analyzing these models from a generative mindset, they all</context>
<context position="17238" citStr="Och and Ney, 2002" startWordPosition="2738" endWordPosition="2741">maximal separation criteria ie. selecting a splitting point within the scores to maximize the difference of the mean score between distributions as shown below. where is the mean score of those hypothesis with a score less than , and is the mean score of those hypothesis with a greater than or equal to . Once pruning is completed, we convert the scores into a probability measure conditioned on the source n-gram and assign the probability estimate as the translation probability for the hypothesis as shown below. (10) (10) calculates direct translation probabilities, ie . As mentioned earlier, (Och and Ney, 2002), show that using direction translation estimates in the decoding process as compared with calculating as prescribed by the Bayesian framework does not reduce translation quality. Our results corroborate these findings and we use (10) as the phrase level translation model estimate within our decoder. 6 Integration Phrase translation pairs that are generated by the method described in this paper are finally scored with estimates of translation probability, which can be conditioned on the target language if necessary. These estimates fit cleanly into the decoding process, except for the issue of</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz Josef Och, Hermann Ney 2002. Discriminative Training and Maximum Entropy Models for Statistical Machine Translation, Proc. North American Association for Computational Linguistics</rawString>
</citation>
<citation valid="false">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A Comparison of Alignment Models for Statistical Machine Translation,</title>
<booktitle>Proc. of the 18th International Conference on Computational Linguistics. Saarbrucken,</booktitle>
<location>Germany</location>
<marker>Och, Ney, </marker>
<rawString>Franz Josef Och and Hermann Ney 200. A Comparison of Alignment Models for Statistical Machine Translation, Proc. of the 18th International Conference on Computational Linguistics. Saarbrucken, Germany</rawString>
</citation>
<citation valid="false">
<authors>
<author>Franz Josef Och</author>
<author>Christoph Tillmann</author>
</authors>
<title>Hermann Ney 1999. Improved Alignment Models for Statistical Machine Translation,</title>
<booktitle>Proc. of the Joint Conference of Empirical Methods in Natural Language Processing,</booktitle>
<pages>20--28</pages>
<marker>Och, Tillmann, </marker>
<rawString>Franz Josef Och, Christoph Tillmann, Hermann Ney 1999. Improved Alignment Models for Statistical Machine Translation, Proc. of the Joint Conference of Empirical Methods in Natural Language Processing, p20-28, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Al’ Onaizan</author>
<author>Jan Curin</author>
<author>Michael Jahr</author>
<author>Kevin Knight</author>
<author>John Lafferty</author>
<author>Dan Melamed</author>
<author>Franz-Josef Och</author>
<author>David Purdy</author>
<author>Noah H Smith</author>
<author>David Yarowsky</author>
</authors>
<date>1999</date>
<booktitle>Statistical Machine Translation, Final Report, JHU Summer Workshop</booktitle>
<contexts>
<context position="20144" citStr="Onaizan et al., 1999" startWordPosition="3213" endWordPosition="3216">or the constituent words in the phrase. As the IBM1 alignment model gives the global optimum for the lexical probabilities, this is the natural choice. This leads to the phrase translation probability (11) where and denotes the length of the target phrase , source phrase , and the word probabilities are estimated using the IBM1 word alignment model. The phrases extracted from this method can be used directly within our in-house decoder without the significant changes that other phrase based methods could require. 8 Experimentation IBM alignment models were trained up to model 4 using GIZA (Al Onaizan et al., 1999) from Chinese to English and Chinese to English on two tracks of data. Figures describing the characteristics of each track as well as the test sentences are shown in Table (1). All the data were extracted from a newswire source. We applied our in house segmentation toolkit on the Chinese data and performed basic preprocessing which included; lowercasing, tagging dates, times and numbers on both languages. Translation quality is evaluated by two metrics, (MTEval, 2002) and BLEU (Papeneni et al., 2001), both of which measure n-gram matches between the translated text and the reference translati</context>
</contexts>
<marker>Onaizan, Curin, Jahr, Knight, Lafferty, Melamed, Och, Purdy, Smith, Yarowsky, 1999</marker>
<rawString>Al’ Onaizan, Jan Curin, Michael Jahr, Kevin Knight, John Lafferty, Dan Melamed, Franz-Josef Och, David Purdy, Noah H. Smith and David Yarowsky 1999. Statistical Machine Translation, Final Report, JHU Summer Workshop</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papeneni</author>
</authors>
<title>Salim Roukos, Todd Ward</title>
<date>2001</date>
<journal>IBM Research Report,</journal>
<volume>22176</volume>
<marker>Papeneni, 2001</marker>
<rawString>Kishore Papeneni, Salim Roukos, Todd Ward 2001. BLEU: A Method for Automatic Evaluation of Machine Translation, IBM Research Report, RC22176</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Vogel</author>
<author>Hermann Ney</author>
<author>Christoph Tillmann</author>
</authors>
<title>HMM-based Word Alignment in Statistical Translation,</title>
<date>1996</date>
<booktitle>Proc. of COLING ’96: The 16th International Conference on Computational Linguistics,</booktitle>
<pages>836--841</pages>
<location>Copenhagen, Denmark</location>
<contexts>
<context position="4844" citStr="Vogel et al., 1996" startWordPosition="739" endWordPosition="742">sses of this method and the potential for future work. 2 Motivation Alignment models associate words and their translations at the sentence level creating a translation lexicon across the language pair. For each sentence pair, the model also presents the maximally likely association between each source and target word across the sentence pair, forming an alignment map for each sentence pair in the training corpus. The most likely alignment pattern between a source and target sentence under the trained alignment model will be referred to as the maximum approximation, which under HMM alignment (Vogel et al., 1996) model corresponds to the Viterbi path. A set of words in the source sentence associated with a set of words in the target sentence is considered a phrasal pair and forms a partition within the alignment map. Figure . shows a source and target sentence pair with points indicating alignment points. A phrasal translation pair within a sentence pair can be represented as the 4-tuple hypothesis representing an index and length within the source and the target sentence pair , respectively. The phrasal extraction task involves selecting phrasal hypotheses based on the alignment Figure 1: Sample sour</context>
<context position="19078" citStr="Vogel et al., 1996" startWordPosition="3037" endWordPosition="3040">per have been generated by empirically determining a scaling factor that was inversely proportional to the lenth of the phrase, causing each translation to have a score comparable to the product of the word to word translations within the phrase. 7 HMM Phrase Extraction In order to compare our method to a well under(9) stood phrase baseline, we present a method that exSmall 3540 90K 115K Large 77558 2.46M 2.69M Testing 993 27K NA Table 1: Corpus figures indicating no. of sentence pairs, no. of Chinese and English words tracts phrases by harvesting the Viterbi path from an HMM alignment model (Vogel et al., 1996). The HMM alignment model is computationally feasible even for very long sentences, and the phrase extraction method does not have limits on the length of extracted target side phrase. For each source phrase ranging from positions to the target phrase is given by and , where and refers to an index in the target sentence pair. We calculate phrase translation probabilities (the scores for each extracted phrase) based on a statistical lexicon for the constituent words in the phrase. As the IBM1 alignment model gives the global optimum for the lexical probabilities, this is the natural choice. Thi</context>
</contexts>
<marker>Vogel, Ney, Tillmann, 1996</marker>
<rawString>Stephan Vogel, Hermann Ney, and Christoph Tillmann 1996. HMM-based Word Alignment in Statistical Translation, Proc. of COLING ’96: The 16th International Conference on Computational Linguistics, pp. 836-841. Copenhagen, Denmark</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yeyi Wang</author>
</authors>
<title>Alex Waibel</title>
<date>1998</date>
<booktitle>Proc. of the International Conference in Spoken Language Processing</booktitle>
<marker>Wang, 1998</marker>
<rawString>Yeyi Wang, Alex Waibel 1998. Fast Decodingfor Statistical Machine Translation, Proc. of the International Conference in Spoken Language Processing</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic Inversion Transduction Grammars, with Application to Segmentation, Bracketing, and Alignment of Parallel Corpora,</title>
<date>1995</date>
<booktitle>Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI-95),</booktitle>
<pages>1328--1335</pages>
<location>Montreal</location>
<contexts>
<context position="2953" citStr="Wu, 1995" startWordPosition="444" endWordPosition="445">ordering effects across languages have been modeled in several ways, including word-based (Brown et al., 1993), template-based (Och et al., 1999) and syntax-based (Yamada, Knight, 2001). Analyzing these models from a generative mindset, they all assume that the atomic unit of lexical content is the word, and re-ordering effects are applied above that level. (Marcu, Wong, 2002) illustrate the effects of assuming that lexical correspondence can only be modeled at the word level, and motivate a joint probability model that explicitly generates phrase level lexical content across both languages. (Wu, 1995) presents a bracketing method that models re-ordering at the sentence level. Both (Marcu, Wong, 2002; Wu, 1995) model the reordering phenomenon effectively, but at significant computational expense, and tend to be difficult to scale to long sentences. Reasons to introduce phrase level translation knowledge sources have been adequately shown and confirmed by (Och, Ney, 2000), and we focus on methods to build these sources from existing, mature components within the translation process. This paper presents a method of phrase extraction from alignment data generated by IBM Models. By working dire</context>
</contexts>
<marker>Wu, 1995</marker>
<rawString>Dekai Wu 1995. Stochastic Inversion Transduction Grammars, with Application to Segmentation, Bracketing, and Alignment of Parallel Corpora, Proceedings of the 14th International Joint Conference on Artificial Intelligence (IJCAI-95), pp. 1328-1335. Montreal</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntax-based statistical translation model,</title>
<date>2001</date>
<booktitle>Proc. of the 39th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<location>France</location>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight 2001. A syntax-based statistical translation model, Proc. of the 39th Annual Meeting of the Association for Computational Linguistics, France</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>