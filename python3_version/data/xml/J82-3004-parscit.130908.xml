<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.705426">
Coping with Syntactic Ambiguity
or
How to Put the Block in the Box on the Table&apos;
</title>
<author confidence="0.9460825">
Kenneth Church
Ramesh Patil
</author>
<affiliation confidence="0.9211725">
Laboratory for Computer Science
Massachusetts Institute of Technology
</affiliation>
<sectionHeader confidence="0.386894" genericHeader="method">
Cambridge, MA 02139
</sectionHeader>
<bodyText confidence="0.997700413793103">
Sentences are far more ambiguous than one might have thought. There may be
hundreds, perhaps thousands, of syntactic parse trees for certain very natural sentences of
English. This fact has been a major problem confronting natural language processing,
especially when a large percentage of the syntactic parse trees are enumerated during
semantic/pragmatic processing. In this paper we propose some methods for dealing with
syntactic ambiguity in ways that exploit certain regularities among alternative parse trees.
These regularities will be expressed as linear combinations of ATN networks, and also as
sums and products of formal power series. We believe that such encoding of ambiguity will
enhance processing, whether syntactic and semantic constraints are processed separately in
sequence or interleaved together.
Most parsers find the set of parse trees by starting
with the empty set and adding to it each time they find
a new possibility. We make the observation that in
certain situations it would be much more efficient to
work in the other direction, starting from the universal
set (i.e, the set of all binary trees) and ruling trees out
when the parser decides that they cannot be parses.
Ruling-out is easier when the set of parse trees is clos-
er to the universal set and ruling-in is easier when the
set of parse trees is closer to the empty set. Ruling-
out is particularly suited for &amp;quot;every way ambiguous&amp;quot;
constructions such as prepositional phrases that have
just as many parse trees as there are binary trees over
the terminal elements. Since every tree is a parse, the
parser doesn&apos;t have to rule any of them out.
In some sense, this is a formalization of an idea
that has been in the literature for some time. That is,
it has been noticed for a long time that these sorts of
very ambiguous constructions are very difficult for
</bodyText>
<footnote confidence="0.516234">
1 This research was supported (in part) by the National Insti-
</footnote>
<affiliation confidence="0.60381625">
tutes of Health Grant No. 1 P01 LM 03374-02 from the National
Library of Medicine, and by the Defense Advanced Research Pro-
jects Agency (DOD) monitored by the Office of Naval Research
under Contract No. N00014-75-C-0661.
</affiliation>
<bodyText confidence="0.999778545454545">
most parsing algorithms, but (apparently) not for peo-
ple. This observation has led some researchers to
hypothesize additional parsing mechanisms, such as
pseudo-attachment (Church 1980, pp. 65-71)2 and
permanent predictable ambiguity (Sager 1973), so that
the parser could &amp;quot;attach all ways&amp;quot; in a single step.
However, these mechanisms have always lacked a pre-
cise interpretation; we will present a much more for-
mal way of coping with &amp;quot;every way ambiguous&amp;quot; gram-
mars, defined in terms of Catalan numbers (Knuth
1975, pp. 388-389, 531-533).
</bodyText>
<footnote confidence="0.23864">
1. Ambiguity is a Practical Problem
</footnote>
<bodyText confidence="0.950254538461539">
Sentences are far more ambiguous than one might
have thought. Our experience with the EQSP parser
(Martin, Church, and Patil 1981) indicates that there
may be hundreds, perhaps thousands, of syntactic
parse trees for certain very natural sentences of Eng-
lish. For example, consider the following sentence
with two prepositional phrases:
2 The idea of pseudo-attachment was first proposed by Mar-
cus (private communication), though Marcus does not accept the
formulation in Church 1980.
Copyright 1982 by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted
provided that the copies are not made for direct commercial advantage and the Journal reference and this copyright notice are included on
the first page. To copy otherwise, or to republish, requires a fee and/or specific permission.
</bodyText>
<page confidence="0.415816">
0362-613X/82/030139-11$03.00
</page>
<note confidence="0.7286785">
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 139
Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity
</note>
<listItem confidence="0.93009575">
(1) Put the block in the box on the table.
which has two interpretations:
(2a) Put the block[in the box on the table]
(2b) Put [the block in the box] on the table.
</listItem>
<bodyText confidence="0.999937">
These syntactic ambiguities grow &amp;quot;combinatorially&amp;quot;
with the number of prepositional phrases. For exam-
ple, when a third PP is added to the sentence above,
there are five interpretations:
</bodyText>
<listItem confidence="0.9831126">
(3a) Put the block [[in the box on the table] in the
kitchen].
(3b) Put the block [in the box [on the table in the
kitchen]].
(3c) Put [[the block in the box] on the table] in the
kitchen.
(3d) Put [the block [in the box on the table]] in the
kitchen.
(3e) Put [the block in the box] [on the table in the
kitchen].
</listItem>
<bodyText confidence="0.9968626">
When a fourth PP is added, there are fourteen trees,
and so on. This sort of combinatoric ambiguity has
been a major problem confronting natural language
processing. In this paper we propose some methods
for dealing with syntactic ambiguity in ways that take
advantage of regularities among the alternative parse
trees.
In particular, we observe that enumerating the
parse trees as above fails to capture the important
generalization that prepositional phrases are &amp;quot;every
way ambiguous,&amp;quot; or more precisely, the set of parse
trees over i PPs is the same as the set of binary trees
that can be constructed over i terminal elements. No-
tice, for example, that there are two possible binary
trees over three elements,
</bodyText>
<listItem confidence="0.972273">
(4a) [ ... block ... [ ... box ... table ... ]]
(4b) [[ ... block ... box ...] ... table ... ]
</listItem>
<bodyText confidence="0.9996643125">
corresponding to (2a) and (2b), respectively, and that
there are five binary trees over four elements corre-
sponding to (3a)â€”(3c), respectively.
PPs, adjuncts, conjuncts, noun-noun modification,
stack relative clauses, and other &amp;quot;every way
ambiguous&amp;quot; constructions will be treated as primitive
objects. They can be combined in various ways to
produce composite constructions, such as lexical ambi-
guity, which may also be very ambiguous but not nec-
essarily &amp;quot;every way ambiguous.&amp;quot; Lexical ambiguity,
for example, will be analyzed as the sum of its senses,
or in flow graph terminology (Oppenheim and Schafer
1975) as a parallel connection of its senses. Structural
ambiguity, on the other hand, will be analyzed as the
product of its components, or in flow graph terminolo-
gy as a series connection.
</bodyText>
<sectionHeader confidence="0.919183" genericHeader="method">
2. Formal Power Series
</sectionHeader>
<bodyText confidence="0.999667333333333">
This section will make the linear systems analogy
more precise by relating context-free grammars to
formal power series (polynominals). Formal power
series are a well-known device in the formal language
literature (e.g., Salomaa 1973) for developing the alge-
braic properties of context-free grammars. We intro-
duce them here to establish a formal basis for our
upcoming discussion of processing issues.
The power series for grammar (5a) is (5b).
</bodyText>
<listItem confidence="0.999289333333333">
(5a) NP -.John I NP and NP
(5b) NP = John + John and John
+ 2John and John and John
+ 5John and John and John and John
+ 14John and John and John and John
and John + ...
</listItem>
<bodyText confidence="0.8120425">
Each term consists of a sentence generated by the
grammar and an ambiguity coefficient3 which counts
how many ways the sentence can be generated. For
example, the sentence &amp;quot;John&amp;quot; has one parse tree
</bodyText>
<listItem confidence="0.9926666">
(6a) [John] I tree
because the zero-th coefficient of the power series is
one. Similarly, the sentence &amp;quot;John and John&amp;quot; also has
one tree because its coefficient is one,
(6b) [John and John] I tree
and &amp;quot;John and John and John&amp;quot; has two because its
coefficient is two,
(6c) [[John and John] and John], 2 trees
[John and [John and John]]
and &amp;quot;John and John and John and John&amp;quot; has five,
(6d) [John and [[John and John] and John]], 5 trees
[John and [John and [John and John]]],
[[[John and John], and John] and John],
[[John and [John and John]] and John],
Wolin and John] and [John and John]]
</listItem>
<bodyText confidence="0.9165590625">
and so on. The reader can verify for himself that
&amp;quot;John and John and John and John and John&amp;quot; has
fourteen trees.
Note that the power series encapsulates the ambi-
guity response of the system (grammar) to all possible
input sentences. In this way, the power series is ana-
logous to the impulse response in electrical engineer-
ing, which encapsulates the response of the system
(circuit) to all possible input frequencies. (Ambiguity
coefficients bear a strong resemblance to frequency
coefficients in Fourier analysis.) All of these trans-
formed representation systems (e.g., power series,
impulse response, and Fourier series) provide a com-
plete description of the system with no loss of
information4 (and no heuristic approximations, for
example, search strategies (Kaplan 1972)). Trans-
</bodyText>
<footnote confidence="0.964429">
3 The formal language literature (Harrison 1978, Salomaa
1973) uses the term support instead of ambiguity coefficient.
</footnote>
<page confidence="0.687779">
140 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982
</page>
<note confidence="0.494595">
Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity
</note>
<bodyText confidence="0.9997746">
forms are often very useful because they provide a
different point of view. Certain observations are more
easily seen in the transform space than in the original
space, and vice versa.
This paper will discuss several ways to generate the
power series. Initially let us consider successive ap-
proximation. Of all the techniques to be presented
here, successive approximations most closely resembles
the approach taken by most current chart parsers in-
cluding EQSP (Martin, Church, and Patil 1981). The
alternative approaches take advantage of certain regu-
larities in the power series in order to produce the
same results more efficiently.
Successive approximation works as follows. First
we translate grammar (5a) into the equation:
</bodyText>
<listItem confidence="0.477398">
(7) NP = John + NP. and. NP
</listItem>
<bodyText confidence="0.9995825">
where &amp;quot;+&amp;quot; connects two ways of generating an NP
and &amp;quot;.&amp;quot; concatenates two parts of an NP. In some
sense, we want to &amp;quot;solve&amp;quot; this equation for NP. This
can be accomplished by refining successive approxima-
tions. An initial approximation NP0 is formed by tak-
ing NP to be the empty language,
</bodyText>
<equation confidence="0.978403">
(8a) NP0 = 0
</equation>
<bodyText confidence="0.9993802">
Then we form the next approximation by substituting
the previous approximation into equation (7), and
simplifying according to the usual rules of algebra
(e.g., assuming distributivity, associativity,5 identity
element, and zero element).
</bodyText>
<listItem confidence="0.9462935">
(8b) NPi = John + NP0 â€¢ and. NP0
= John + 0. and. 0 = John
We continue refining the approximation in this way.
(8c) NP2 = John + NP1. and â€¢ NPi
= John + John and John
(8d) NP3 = John + NP2 and NP2
= John + (John + John and John) . and.
(John + John and John)
= John + John and John
+ John and John and John
+ John and John and John
+ John and John and John and John
</listItem>
<bodyText confidence="0.560854266666667">
4 This needs a qualification. It is true that the power series
provides a complete description of the ambiguity response to any
input sentence. However, the power series representation may be
losing some information that would be useful for parsing. In partic-
ular, there might be some cases where it is impossible to recover the
parse trees exactly, as we will see, though this may not be too
serious a problem for many practical applications. That is, it is
often possible to recover most (if not all) of the structure, which
may be adequate for many applications.
5 The careful reader may correctly object to this assumption.
We include it here for expository convenience, as it greatly simpli-
fies the derivations though it should be noted that many of the
results could be derived without the assumption. Furthermore, this
assumption is valid for counting ambiguity. That is, IA â€¢ BI *
ICI = IAI * I8 â€¢ CI, where A, B, and C are sets of trees and
</bodyText>
<listItem confidence="0.552513">
I A I denotes the number of members of A, and * is integer multi-
plication.
= John + John and John
+ 2 John and John and John
+ John and John and John and John
</listItem>
<bodyText confidence="0.9103656">
Eventually, we have NP expressed as an infinitely long
polynominal (5b) above. This expression can be sim-
plified by introducing a notation for exponentiation.
Let x&apos; be an abbreviation for multiplying x x â€¢ ... â€¢ x,
i times.
</bodyText>
<listItem confidence="0.95653">
(9) NP = John + John and John
+ 2 John (and John)2
+ 5 John (and John)3
+ 14 John (and John)4
+
</listItem>
<bodyText confidence="0.9991008">
Note that parentheses are interpreted differently in
algebraic equations than in context-free rules. In
context-free rules, parentheses denote optionality,
where in equations they denote precedence relations
among algebraic operations.
</bodyText>
<sectionHeader confidence="0.689281" genericHeader="method">
3. Catalan Numbers
</sectionHeader>
<bodyText confidence="0.995770733333333">
Ambiguity coefficients take on an important practi-
cal significance when we can model them directly
without resorting to successive approximation as
above. This can result in substantial time and space
savings in certain special cases where there are much
more efficient ways to compute the coefficients than
successive approximation (chart parsing). Equation
(9) is such a special case; the coefficients follow a
well-known combinatoric series called the Catalan
Numbers (Knuth 1975, pp. 388-389, 531-533).6 This
section will describe Catalan numbers and their rela-
tion to parsing.
The first few Catalan numbers are 1, 1, 2, 5, 14,
42, 132, 469, 1430, 4862. They are generated by the
closed form expression:7
</bodyText>
<equation confidence="0.860437">
2n
(10) Cat, =
n (n2-111)
</equation>
<bodyText confidence="0.889155181818182">
This formula can be explained in terms of parenthes-
ized expressions, which are equivalent to trees. Cat,
is the number of ways to parenthesize a formula of
length n. There are two conditions on parenthesiza-
tion: (a) there must be the same number of open and
close parentheses, and (b) they must be properly nest-
ed so that an open parenthesis precedes its matching
close parenthesis. The first term counts the number of
6 This fact was first pointed out to us by V. Pratt. We sus-
pect that it is a generally well-known result in the formal language
community, though its origin is unclear.
</bodyText>
<page confidence="0.804323">
7 (g) is known as a binominal coefficient. It is equivalent to
a!/[b!(a-b)!jl,
</page>
<bodyText confidence="0.981166866666667">
where a! is equal to the product of all integers between 1 and a.
Binomial coefficients are very common in combinatorics where they
are interpreted as the number of ways to pick b objects out of a set
of a objects.
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 141
Kenneth Church and Ramesh Path Coping with Syntactic Ambiguity
sequences of 2n parentheses, such that there are the
same number of opens and closes. The second term
subtracts cases violating condition (b). This explana-
tion is elaborated in Knuth 1975, p. 531.
It is very useful to know that the ambiguity coeffi-
cients are Catalan numbers because this observation
enables us to replace equation (9) with (11), where
Cat i denotes the ith Catalan number. (All summations
range from 0 to 00 unless noted otherwise.)
</bodyText>
<listItem confidence="0.719973">
(11) NP = E Cat. John (and John)i
</listItem>
<bodyText confidence="0.998011666666667">
The ith Catalan number is the number of binary trees
that can be constructed over i phrases. This theoreti-
cal model correctly predicts our practical experience
with EQSP. EQSP found exactly the Catalan number
of parse trees for each sentence in the following se-
quence.
</bodyText>
<listItem confidence="0.7667512">
1 It was the number.
1 It was the number of products.
2 It was the number of products of products.
5 It was the number of products of products
of products.
</listItem>
<bodyText confidence="0.96809">
14 It was the number of products of products
of products of products.
These predictions continue to hold with as many as
nine prepositional phrases (4862 parse trees).
</bodyText>
<sectionHeader confidence="0.682134" genericHeader="method">
4. Table Lookup
</sectionHeader>
<bodyText confidence="0.992888857142857">
We could improve EQSP&apos;s performance on PPs if
we could find a more efficient way to compute Cata-
lan numbers than chart parsing, the method currently
employed by EQSP. Let us propose two alternatives:
table lookup and evaluating expression (10) directly.
Both are very efficient over practical ranges of n, say
no more than 20 phrases or so.8 In both cases, the
ambiguity of a sentence in grammar (5a) can be deter-
mined by counting the number of occurrences of &amp;quot;and
John&amp;quot; and then retrieving the Catalan of that number.
These approaches both take linear time (over practical
ranges of n),9 whereas chart parsing requires cubic
time to parse sentences in these grammars, a signifi-
cant improvement.
So far we have shown how to compute in linear
time the number of ambiguous interpretations of a
sentence in an &amp;quot;every way ambiguous&amp;quot; grammar.
However, we are really interested in finding parse
trees, not just the number of ambiguous interpreta-
tions. We could extend the table lookup algorithm to
find trees rather than ambiguity coefficients, by modif-
ying the table to store trees instead of numbers. For
parsing purposes, Cati can be thought of as a pointer
to the ith entry of the table. So, for a sentence in
grammar (5a), for example, the machine could count
the number of occurrences of &amp;quot;and John&amp;quot; and then
retrieve the table entry for that number.
index trees
</bodyText>
<listItem confidence="0.957694666666667">
0 {[John]}
1 {[John and John]}
2 {[[John and John] and John],
</listItem>
<bodyText confidence="0.7792416">
[John and [John and John]]]
The table would be more general if it did not specify
the lexical items at the leaves. Let us replace the table
above with
index trees
</bodyText>
<equation confidence="0.9827">
0 {[x]}
1 {[x x]}
2 {[[x x] x], [x [x x]]]
</equation>
<bodyText confidence="0.9345844">
and assume the machine can bind the x&apos;s to the appro-
priate lexical items.
There is a real problem with this table lookup ma-
chine. The parse trees may not be exactly correct
because the power series computation assumed that
multiplication was associative, which is an appropriate
assumption for computing ambiguity, but inappropriate
for constructing trees. For example, we observed that
prepositional phrases and conjunction are both &amp;quot;every
way ambiguous&amp;quot; grammars because their ambiguity
coefficients are Catalan numbers. However, it is not
the case that they generate exactly the same parse
trees.
Nevertheless we present the table lookup pseudo-
parser here because it seems to be a speculative new
approach with considerable promise. It is often more
efficient than a real parser, and the trees that it finds
may be just as useful as the correct one for many
practical purposes. For example, many speech recog-
nition projects employ a parser to filter out syntacti-
cally inappropriate hypotheses. However, a full parser
is not really necessary for this task; a recognizer such
as this table lookup pseudo-parser may be perfectly
adequate for this task. Furthermore, it is often possi-
ble to recover the correct trees from the output of the
pseudo-parser. In particular, the difference between
prepositional phrases and conjunction could be ac-
counted for by modifying the interpretation of the PP
category label, so that the trees would be interpreted
correctly even though they are not exactly correct.
8 The table lookup scheme ought to have a way to handle the
theoretical possibility that there are an unlimited number of prepo-
sitional phrases. The table lookup routine will employ a more
traditional parsing algorithm (e.g., Earley&apos;s algorithm) when the
number of phrases in the input sentence is not stored in the table.
</bodyText>
<footnote confidence="0.92666825">
9 The linear time result depends on the assumption that table
lookup (or closed form computation) can be performed in constant
time. This may be a fair assumption over practical ranges of n, but
it is not true in general.
</footnote>
<note confidence="0.730169">
142 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982
Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity
</note>
<bodyText confidence="0.99940025">
The table lookup approach works for primitive
grammars. The next two sections show how to de-
compose composite grammars into series and parallel
combinations of primitive grammars.
</bodyText>
<equation confidence="0.5623815">
(12a) G = G1. G2 series
(12b) G = G1 + G2 parallel
</equation>
<sectionHeader confidence="0.76684" genericHeader="method">
5. Parallel Decomposition
</sectionHeader>
<bodyText confidence="0.99548">
Parallel decomposition can be very useful for deal-
ing with lexical ambiguity, as in
</bodyText>
<listItem confidence="0.60382">
(13) ...to total with products near profits...
</listItem>
<bodyText confidence="0.997456095238095">
where &amp;quot;total&amp;quot; can be taken as a noun or as a verb, as
in:
(14a) The accountant brought the daily sales to total
with products near profits organized according
to the new law. noun
(14b) The daily sales were ready for the accountant
to total with products near profits organized
according to the new law. verb
The analysis of these sentences makes use of the
additivity property of linear systems. That is, each
case, (14a) and (14b), is treated separately, and then
the results are added together. Assuming &amp;quot;total&amp;quot; is a
noun, there are three prepositional phrases contribut-
ing Cat3 bracketings, and assuming it is a verb, there
are two prepositional phrases for Cat2 ambiguities.
Combining the two cases produces Cat3 + Cat2 = 5 +
2 = 7 parses. Adding another prepositional phrase
yields Cat4 + Cat3 = 14 + 5 = 19 parses. (EOSP
behaved as predicted in both cases.)
This behavior is generalized by the following power
series:
</bodyText>
<equation confidence="0.94806825">
P N â€¢
(15) E (Cati+ + Cati)(P N)&apos;
to V i
which is the sum of the two cases:
(16a) E Cati(P N)i = P N E Cat1+1. .(P N)i noun
i
i&gt;0
(16b) to V E Cati(P N)i verb
</equation>
<bodyText confidence="0.999691">
This observation can be incorporated into the table
lookup pseudo-parser outlined above. Recall that Cat,
is interpreted as the ith index in a table containing all
binary trees dominating i leaves. Similarly, Cati +
Cati+ I will be interpreted as an instruction to
&amp;quot;append&amp;quot; the ith entry and i+ 1 th entry of the table.10
</bodyText>
<equation confidence="0.987428">
(17) (ADD-TREES
(CAT-TABLE i)
(CAT-TABLE(+ i 1)))
</equation>
<bodyText confidence="0.999947962962963">
Let us consider a system where syntactic processing
strictly precedes semantic and pragmatic processing.
In such a system, how could we incorporate semantic
and pragmatic heuristics once we have already parsed
the input sentence and found that it was the sum of
two Catalans? The parser can simply subtract the
inappropriate interpretations. If the oracle says that
&amp;quot;total&amp;quot; is a verb, then (16a) would be subtracted from
the combined sum, and if the oracle says that &amp;quot;total&amp;quot;
is a noun, then (16b) would be subtracted.
On the other hand, our analysis is also useful in a
system that interleaves syntactic processing with se-
mantic and pragmatic processing. Suppose that we
had a semantic routine that could disambiguate
&amp;quot;total,&amp;quot; but only at a very high cost in execution time.
We need a way to estimate the usefulness of executing
the semantic routine so that we don&apos;t spend the time if
it is not likely to pay off. The analysis above provides
a very simple way to estimate the benefit of disambig-
uating &amp;quot;total.&amp;quot; If it turns out to be a verb, then (16a)
trees have been ruled out, and if it turns out to be a
noun, then (16b) trees have been ruled out. We pref-
er our declarative algebraic approach over procedural
heuristic search strategies (e.g., Kaplan 1972) because
we do not have to specify the order of evaluation. We
can delay the binding of decisions until the most op-
portune moment.
</bodyText>
<sectionHeader confidence="0.933989" genericHeader="method">
6. Series Decomposition
</sectionHeader>
<bodyText confidence="0.999967">
Suppose we have a non-terminal S that is a series
combination of two other non-terminals, NP and VP.
By inspection, the power series of S is:
</bodyText>
<equation confidence="0.446468">
(18) S = NP â€¢ VP
</equation>
<bodyText confidence="0.9974688">
This result is easily verified when there is an unmistak-
able dividing point between the subject and the predi-
cate. For example, the verb &amp;quot;is&amp;quot; separates the PPs in
the subject from those in the predicate in (19a), but
not in (19b).
</bodyText>
<listItem confidence="0.74895675">
(19a) The number of products over sales of ... is near
the number of sales under ... clearly divided
(19b) Is the number of products over sales of ... near
the number of sales under ...? not clearly divided
</listItem>
<bodyText confidence="0.9997">
In (19a), the total number of parse trees is the product
of the number of ways of parsing the subject times the
number of ways of parsing the predicate. Both the
subject and the predicate produce a Catalan number of
parses, and hence the result is the product of two Ca-
talan numbers, which was verified by EQSP (Martin,
Church, and Patil 1981, p. 53). This result can be
formalized in terms of the power series:
</bodyText>
<listItem confidence="0.77288075">
(20) (N E Cat.(P NO (is E Cati(P
i
which is formed by taking the product of the two sub-
cases:
</listItem>
<footnote confidence="0.46181">
(21a) N E Cati(P N)i
(21b) is E Cat:(P N)j
subject
predicate
</footnote>
<page confidence="0.991534">
143
</page>
<bodyText confidence="0.863237">
10 This can be implemented efficiently, given an appropriate
representation of sets of trees.
</bodyText>
<subsectionHeader confidence="0.903532">
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982
</subsectionHeader>
<bodyText confidence="0.966497857142857">
Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity
The power series says that the ambiguity of a par-
ticular sentence is the product of Cati and Cat, where
i is the number of PPs before &amp;quot;is&amp;quot; and j is the number
after &amp;quot;is.&amp;quot; This could be incorporated in the table
lookup parser as an instruction to &amp;quot;multiply&amp;quot; the ith
entry in the table by the jth entry. Multiplication is a
cross-product operation; L x R generates the set of
binary trees whose left sub-tree l is from L and whose
right sub-tree r is from R.
(22) L x R = {(1, r) 11 cL &amp; râ‚¬R}
This is a formal definition. For practical purposes, it
may be more useful for the parser to output the list in
the factored form:
</bodyText>
<equation confidence="0.966216333333333">
(23) (MULTIPLY-TREES
(CAT-TABLE i)
(CAT-TABLE j))
</equation>
<bodyText confidence="0.999965448275862">
which is much more concise than a list of trees. It is
possible, for example, that semantic processing can
take advantage of factoring, capturing a semantic gen-
eralization that holds across all subjects or all predi-
cates. Imagine, for example, that there is a semantic
agreement constraint between predicates and argu-
ments. For example, subjects and predicates might
have to agree on the feature +human. Suppose that
we were given sentences where this constraint was
violated by all ambiguous interpretations of the sen-
tence. In this case, it would be more efficient to em-
ploy a feature vector scheme (Dostert and Thompson
1971) which propagates the features in factored form.
That is, it computes a feature vector for the union of
all possible subjects, and a vector for the union of all
possible VPs, and then compares (intersects) these
vectors to check if there are any interpretations that
meet the constraint. A system such as this, which
keeps the parses in factored form, is much more effi-
cient than one that multiplies them out. Even if se-
mantics cannot take advantage of the factoring, there
is no harm in keeping the representation in factored
form, because it is straightforward to expand (23) into
a list of trees (though it may be somewhat slow).
This example is relatively simple because &amp;quot;is&amp;quot; helps
the parser determine the value of i and j. Now let us
return to example (19b) where &amp;quot;is&amp;quot; does not separate
the two strings of PPs. Again, we determine the pow-
er series by multiplying the two subcases:
</bodyText>
<equation confidence="0.6642214">
(24) is (N E Cati(P Cat
(E â€¢(P N) )
i
= is N E E Cat Cat(P N)1+J
J j
</equation>
<bodyText confidence="0.999986636363636">
However, this form is not so useful for parsing
because the parser cannot easily determine i and j, the
number of prepositional phrases in the subject and the
number in the predicate. It appears the parser will
have to compute the product of two Catalans for each
way of picking i and j, which is somewhat expensive.11
Fortunately, the Catalan function has some special
properties so that it is possible algebraically to remove
the references to i and j. In the next section we show
how this expression can be reformulated in terms of n,
the total number of PPs.
</bodyText>
<subsectionHeader confidence="0.999991">
6.1 Auto-Convolution of Catalan Grammars
</subsectionHeader>
<bodyText confidence="0.947967777777778">
Some readers may have noticed that expression
(24) is in convolution form. We will make use of this
in the reformulation. Notice that the Catalan series is
a fixed point under auto-convolution (except for a
shift); that is, multiplying a Catalan power series (i.e.,
1 + x + 2x2 + 5x3 + 14x4 + Catix1 ...) with itself
produces another polynomial with Catalan coeffi-
cients.12 The multiplication is worked out for the first
few terms.
</bodyText>
<equation confidence="0.999816375">
1 + x + 2x2 + 5x3 +
x 1 + x + 2x2 + 5x3 +
5x3 +
2x3+ 5x4+
2x3+ 4x4+
5x3+ 5x4+
14x4 +
1 + 2x + 5x2 + 14x3 + 42x4 +
</equation>
<bodyText confidence="0.989079333333333">
This property can be summarized as:
(25) E Cat, xi E Cat x&apos;1i xi = E Catn+ X
where n equals i+j.
Intuitively, this equation says that if we have two
&amp;quot;every way ambiguous&amp;quot; (Catalan) constructions, and
we combine them in every possible way (convolution),
the result is an &amp;quot;every way ambiguous&amp;quot; (Catalan)
construction. With this observation, equation (24)
reduces to:
</bodyText>
<equation confidence="0.7176">
(26) is (N E Cati(P N)i) (E Catâ€¢(P N)i)
= is N E Cat
n+1 (P NN)&apos;1n
</equation>
<bodyText confidence="0.9781401">
Hence the number of parses in the auxiliary-inverted
case is the Catalan of one more than in the non-
inverted cases. As predicted, EQSP found the follow-
ing inverted sentences to be more ambiguous than
their non-inverted counterparts (previously discussed
on page 142) by one Catalan number.
11 Earley&apos;s algorithm and most other context-free parsing
algorithms actually work this way.
12 The proof immediately follows from the z-transform of the
Catalan series (Knuth 1975, p. 388): zB(z) = B(z) â€” 1.
</bodyText>
<figure confidence="0.974628">
2x2 +
x2 +
2x2 +
14x4 +
14x4 +
14x4 +
</figure>
<page confidence="0.657188">
144 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982
</page>
<note confidence="0.612884">
Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity
</note>
<footnote confidence="0.617884909090909">
1 Was the number?
2 Was the number of products?
5 Was the number of products of products?
14 Was the number of products of products
of products?
42 Was the number of products of products
of products of products?
1 It was the number.
1 It was the number of products.
2 It was the number of products of products.
5 It was the number of products of products
</footnote>
<bodyText confidence="0.913511105263158">
of products.
14 It was the number of products of products
of products of products.
How could this result be incorporated into the table
lookup pseudo-parser? Recall that the pseudo-parser
implements Catalan grammars by returning an index
into the Catalan table. For example, if there were i
PPs, the parser would return: (CAT-TABLE i). We
now extend the indexing scheme so that the parser
implements a series connection of two Catalan gram-
mars by returning one higher index than it would for a
simple Catalan grammar. That is, if there were n PPs,
the parser would return (CAT-TABLE (-4- n 1)).
Series connections of Catalan grammars are very
common in every day natural language, as illustrated
by the following two sentences, which have received
considerable attention in the literature because the
parser cannot separate the direct object from the pre-
positional complement.
</bodyText>
<listItem confidence="0.538387">
(27a) I saw the man on the hill with a telescope ...
(27b) Put the block in the box on the table in the
kitchen ...
</listItem>
<bodyText confidence="0.9336921">
Both examples have a Catalan number of ambiguities
because the auto-convolution of a Catalan series yields
another Catalan series.13 This result can improve
parsing performance because it suggests ways to re-
organize (compile) the grammar so that there will be
fewer references to quantities that are not readily
available. This re-organization will reap benefits that
chart parsers (e.g., Earley&apos;s algorithm) do not current-
ly achieve because the re-organization is taking advan-
tage of a number of combinatoric regularities, espe-
cially convolution, that are not easily encoded into a
chart. Section 9 presents an example of the re-
organization.
13 There is a difference between these two sentences because
&amp;quot;put&amp;quot; subcategorizes for two objects unlike &amp;quot;see.&amp;quot; Suppose we
analyze &amp;quot;see&amp;quot; as lexically ambiguous between two senses, one that
selects for exactly two objects like &amp;quot;put&amp;quot; and one that selects for
exactly one object as in &amp;quot;I saw it.&amp;quot; The first sense contributes the
same number of parses as &amp;quot;put&amp;quot; and the second sense contributes
an additional Catalan factor.
</bodyText>
<subsectionHeader confidence="0.999874">
6.2 Chart Parsing
</subsectionHeader>
<bodyText confidence="0.999008">
Perhaps it is worthwhile to reformulate chart pars-
ing in our terms in order to show which of the above
results can be captured by such an approach and
which cannot. Traditionally, chart parsers maintain a
chart (or matrix) M, whose entries M1 contain the set
of category labels that span from position i to position
j in the input sentence. This is accomplished by find-
ing a position k between i and j such that there is a
phrase from i to k that can combine with another
phrase from k to j. An implementation of the inner
loop looks something like:
</bodyText>
<listItem confidence="0.340563333333333">
(28) Mii
loop for k from i to j do
:= Mji U Mjk * Mkj
</listItem>
<bodyText confidence="0.73265">
Essentially, then, a chart parser is maintaining the
invariant
</bodyText>
<listItem confidence="0.7453485">
(29) Mi. = E M.
k I
</listItem>
<bodyText confidence="0.999438333333333">
where addition and multiplication of matrix elements is
related to parallel and series combination. Thus chart
parsers are able to process very ambiguous sentences
in polynomial time, as opposed to exponential (or
Catalan) time.
However, the examples above illustrate cases where
chart parsers are not as efficient as they might be. In
particular, chart parsers implement convolution the
&amp;quot;long way,&amp;quot; by picking each possible dividing point k,
and parsing from i to k and from k to j; they do not
reduce the convolution of two Catalans as we did
above. Similarly, chart parsers do not make use of the
&amp;quot;every way ambiguous&amp;quot; generalization; given a Cata-
lan grammar, chart parsers will eventually enumerate
all possible values of i, j, and k.
</bodyText>
<subsectionHeader confidence="0.936975">
7. Computing the Power Series Directly from the
Grammar
</subsectionHeader>
<bodyText confidence="0.999874428571429">
Thus far, most of our derivations have been justi-
fied in terms of successive approximation. It is also
possible to derive some interesting (and well-known)
results directly from the grammar itself. Suppose, for
the sake of discussion, that we choose to analyze ad-
juncts with a right branching grammar.14 (By conven-
tion, terminal symbols appear in lower case.)
</bodyText>
<listItem confidence="0.523098">
(30) ADJS adj ADJS I A
</listItem>
<bodyText confidence="0.982154875">
First we translate the grammar into an equation in the
usual way. That is, ADJS is modeled as a parallel
combination of two subgrammars, adj ADJS and A.
(A, the empty string, is modeled as 1 because it is the
14 A similar analysis of adjuncts is adopted in Kaplan and
Bresnan 1981. This analysis can also be defended on performance
grounds as an efficiency approximation. (This approximation is in
the spirit of pseudo-attachment (Church 1980).)
</bodyText>
<listItem confidence="0.820458428571429">
â€¢ Mkj
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 145
Kenneth Church and Ramesh Path l Coping with Syntactic Ambiguity
identity element under series combination, i.e., multi-
plication.)
(31a) ADJS adj ADJS I A
(31b) ADJS = adj â€¢ ADJS + 1
</listItem>
<bodyText confidence="0.9999315">
We can simplify (31b) so the right hand side is ex-
pressed in terminal symbols alone, with no references
to non-terminals. This is very useful for processing
because it is much easier for the parser to determine
the presence or absence of terminals than of non-
terminals. That is, it is easier for the parser to deter-
mine, for example, whether a word is an adj, than it is
to decide whether a substring is an ADJS phrase. The
simplification moves all references to ADJS to the left
hand side, by subtracting from both sides,
</bodyText>
<listItem confidence="0.842742166666667">
(31c) ADJS â€” adj â€¢ ADJS = 1
factoring the left hand side,
(31d) (1 â€” adDADJS = 1
and dividing from both sides,
(31e) ADJS = (1 â€” adj)-1
(31f) 1 1 adj
</listItem>
<equation confidence="0.980876">
1 + adj adj+ 2
1â€”adj 1â€”adj 1â€”adj
adj
.3
= 1 adj + adj.2 â€” = E adjn
1â€”adj
</equation>
<bodyText confidence="0.959667416666667">
Grammars like ADJS will sometimes be referred to as a
step, by analogy to a unit step function in electrical
engineering.
8. Computing the Power Series from the ATN
This section will re-derive the power series for the
unit step grammar directly from the ATN representa-
tion by treating the networks as flow graphs
(Oppenheim 1975). The graph transformations pres-
ented here are directly analogous to the algebraic sim-
plifications employed in the previous section.
First we translate the grammar into an ATN in the
usual way (Woods 1970).
</bodyText>
<listItem confidence="0.994348">
(32) ADJS adj ADJS I A
(33) ADJS: 0Cat adj Push ADJ Pop
</listItem>
<subsectionHeader confidence="0.552278">
Jump
</subsectionHeader>
<bodyText confidence="0.9125402">
This graph can be simplified by performing a compiler
optimization call tail recursion (Church and Kaplan
1981 and references therein). This transformation
replaces the final push arc with a jump:
Jump
</bodyText>
<subsectionHeader confidence="0.400447">
Jump
</subsectionHeader>
<bodyText confidence="0.998079875">
Tail recursion corresponds directly to the algebraic
operations of moving the ADJS term to the left hand
side, factoring out the ADJS, and dividing from both
sides.
Then we remove the top jump arc by series reduc-
tion. This step corresponds to multiplying by 1 since a
jump arc is the ATN representation for the identity
element under series combination.
</bodyText>
<figure confidence="0.4728676">
Pop
9&gt;
Jump
The loop can be treated as an infinite series:
(36) 1 + adj + adj2 + adj3 +
</figure>
<bodyText confidence="0.9322327">
where the zero-th term corresponds to zero iterations
around the loop, the first term corresponds to a single
iteration, the second term to two iterations, and so on.
Recall that (36) is equivalent to:
(37) 1
1â€”adj
With this observation, it is possible to open the loop:
(38) ADJS:01/(1-adj) Jump Pop
After one final series reduction, the ATN is equivalent
to expression (31e) above.
</bodyText>
<equation confidence="0.349466">
(38g) ADJS:
</equation>
<bodyText confidence="0.996649285714286">
Intuitively, an ATN loop (or step grammar) is a divi-
sion operator. We now have composition operators
for parallel composition (addition), series composition
(multiplication), and loops (division).
An ATN loop can be implemented in terms of the
table lookup scheme discussed above. First we refor-
mulate the loop as an infinite sum:
</bodyText>
<figure confidence="0.8843833">
ADJS:
ADJS:
By performing the long division, we observe that (31) (35)
has unit coefficients.
Cat adj
Pop
146 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982
Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity
(39) 1 â€” E adji
1â€”adj
</figure>
<bodyText confidence="0.9969305">
Then we construct a table so that the ith entry in the
table tells the parser how to parse i occurrences of adj.
</bodyText>
<sectionHeader confidence="0.507847" genericHeader="method">
9. An Example
</sectionHeader>
<bodyText confidence="0.988454">
Suppose for example that we were given the fol-
lowing grammar:
</bodyText>
<listItem confidence="0.9807625">
(40a) S NP VP ADJS
(40b) S V NP (PP) ADJS ADJS
(40c) VP -0. V NP (PP) ADJS
(40d) PP P NP
(40e) NP NI NP PP
(40f) ADJS adj ADJS I A
</listItem>
<bodyText confidence="0.9938515">
(In this example we will assume no lexical ambiguity
among N, V, P, and adj.)
By inspection, we notice that NP and PP are Cata-
lan grammars and that ADJS is a Step grammar.
</bodyText>
<listItem confidence="0.8880555">
(41a) PP = E Cati(P N)i
i&gt;0
(41b) NP = N Cati(P N)i
(41c) ADJS = adj1
</listItem>
<bodyText confidence="0.938039133333333">
With these observations, the parser can process PPs,
NPs, and ADJSs by counting the number of occurrenc-
es of terminal symbols and looking up those numbers
in the appropriate tables. We now substitute (41a-c)
into (40c).
(42) VP = V NP (1 + PP)ADJS
= V (N E Cati(P N)&apos;)(E Cati(P (E adji)
and simplify the convolution of the two Catalan func-
tions
(43) VP = V (N E Cati+i(P N)i)(E adj&apos;)
so that the parser can also find VPs by just counting
coccurrences of terminal symbols. Now we simplify
(40a-b) so that S phrases can also be parsed by just
counting occurrences of terminal symbols. First,
translate (40a-b) into the equation:
</bodyText>
<listItem confidence="0.821145">
(44) S = NP VP ADJS + V NP (1+PP) ADJS ADJS
and then expand VP using (42)
(45) S = NP (V NP (1+PP) ADJS) ADJS
+ V NP (1+PP) ADJS ADJS
</listItem>
<figure confidence="0.799076870967742">
and factor
(46) S = (NP + 1) V NP (1+PP) ADJS2
That can be simplified considerably because
(47) NP (1 + PP) = N E Cati(P N)i E Cati(P N)i
= N E Cati+i(P N)i
and
(48) ADJS2 = E adj&apos; E adj&apos; = (i + 1)adji
so that
(49) S = (N E Cati(P N)i + 1)
V N E Cat. i(P N)i
14-
E (i + 1)adjI
which has the following ATN realization:
Jump
Jump
Cat (P
â€¢ â€¢ â€¢ â€¢ â€¢
at 1
. (1, (i + 1) adji
1+
(50)
&gt;CD
The entire example grammar has now been compiled
into a form that is easier for parsing. This formula
says that sentences are all of the form:
(51) S (N (P N)*) V N (P N)* adj*
which could be recognized by the following finite state
machine:
(52) S: â€ºc)
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 147
Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity
</figure>
<bodyText confidence="0.9982786875">
Furthermore, the number of parse trees for a given
input sentence can be found by multiplying three num-
bers: (a) the Catalan of the number of P N&apos;s before
the verb, (b) the Catalan of one more than the num-
ber of P N&apos;s after the verb, and (c) the ramp of the
number of adj&apos;s. For example, the sentence
(53) The man on the hill saw the boy with a tele-
scope yesterday in the morning.
has Cat * Cat2 * 3 = 6 parses. That is, there is one
way to parse &amp;quot;the man on the hill,&amp;quot; two ways to parse
&amp;quot;saw the boy with a telescope&amp;quot; (&amp;quot;telescope&amp;quot; is either
a complement of &amp;quot;see&amp;quot; as in (54a-c) or is attached to
&amp;quot;boy&amp;quot; as in (54d-f)), and three ways to parse the
adjuncts (they could both attach to the S (54a,d), or
they could both attach to the VP (54b,e), or they
could split (54c,f)).
</bodyText>
<listItem confidence="0.884399166666667">
(54a) [The man on the hill [saw the boy with a tele-
scope] [yesterday in the morning.]]
(54b) The man on the hill [[saw the boy with a tele-
scope] [yesterday in the morning.]]
(54c) The man on the hill [[saw the boy with a tele-
scope] yesterday] in the morning.
(54d) [The man on the hill saw [the boy with a tele-
scope] [yesterday in the morning.]]
(54e) The man on the hill [saw [the boy with a tele-
scope] [yesterday in the morning.]]
(54f) The man on the hill [saw [the boy with a tele-
scope] yesterday] in the morning.
</listItem>
<bodyText confidence="0.9247935">
All and only these possibilities are permitted by the
grammar.
</bodyText>
<sectionHeader confidence="0.755754" genericHeader="conclusions">
10. Conclusion
</sectionHeader>
<bodyText confidence="0.998626228571429">
We began our discussion with the observation that
certain grammars are &amp;quot;every way ambiguous&amp;quot; and
suggested that this observation could lead to improved
parsing performance. Catalan grammars were then
introduced to remedy the situation so that the proc-
essor can delay attachment decisions until it discovers
some more useful constraints. Until such time, the
processor can do little more than note that the input
sentence is &amp;quot;every way ambiguous.&amp;quot; We suggested
that a table lookup scheme might be an effective me-
thod to implement such a processor.
We then introduced rules for combining primitive
grammars, such as Catalan grammars, into composite
grammars. This linear systems view &amp;quot;bundles up&amp;quot; all
the parse trees into a single concise description capa-
ble of telling us everything we might want to know
about the parses (including how much it might cost to
ask a particular question). This abstract view of ambi-
guity enables us to ask questions in the most conven-
ient order, and to delay asking until it is clear that the
pay-off will exceed the cost. This abstraction was
very strongly influenced by the notion of delayed
binding.
We have presented combination rules in three dif-
ferent representation systems: power series, ATNs, and
context-free grammars, each of which contributed its
own insights. Power series are convenient for defining
the algebraic operations, ATNs are most suited for
discussing implementation issues, and context-free
grammars enable the shortest derivations. Perhaps the
following quotation best summarizes our motivation
for alternating among these three representation sys-
tems:
A thing or idea seems meaningful only when we have several
different ways to represent it â€” different perspectives and differ-
ent associations. Then you can turn it around in your mind, so to
speak; however, it seems at the moment you can see it another
way; you never come to a full stop. (Minsky 1981, p. 19)
In each of these representation schemes, we have
introduced five primitive grammars: Catalan, Unit
Step, 1, and 0, and terminals; and four composition
rules: addition, subtraction, multiplication, and divi-
sion. We have seen that it is often possible to employ
these analytic tools in order to re-organize (compile)
the grammar into a form more suitable for processing
efficiently. We have identified certain situations
where the ambiguity is combinatoric, and have
sketched a few modifications to the grammar that ena-
ble processing to proceed in a more efficient manner.
In particular, we have observed it to be important for
the grammar to avoid referencing quantities that are
not easily determined, such as the dividing point be-
tween a noun phrase and a prepositional phrase as in
(55) Put the block in the box on the table in the
kitchen ...
We have seen that the desired re-organization can be
achieved by taking advantage of the fact that the auto-
convolution of a Catalan series produces another Ca-
talan series. This reduced processing time from 0(n3)
to almost linear time. Similar analyses have been dis-
cussed for a number of lexically and structurally ambi-
guous constructions, culminating with the example in
section 9, where we transformed a grammar into a
form that could be parsed by a single left-to-right pass
over the terminal elements. Currently, these grammar
reformulations have to be performed by hand. It
ought to be possible to automate this process so that
the reformulations could be performed by a grammar
compiler. We leave this project open for future re-
search.
</bodyText>
<sectionHeader confidence="0.848727" genericHeader="acknowledgments">
11. Acknowledgments
</sectionHeader>
<bodyText confidence="0.90253825">
We would like to thank Jon Allen, Sarah Ferguson,
Lowell Hawkinson, Kris Halvorsen, Bill Long, Mitch
Marcus, Rohit Parikh, and Peter Szolovits for their
very useful comments on earlier drafts. We would
</bodyText>
<page confidence="0.837678">
148 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982
</page>
<bodyText confidence="0.995254">
especially like to thank Bill Martin for initiating the
project.
</bodyText>
<sectionHeader confidence="0.98294" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995003461538462">
Church, K. 1980 On Memory Limitations in Natural Language
Processing. MIT/LCS/TR-245, and IULC.
Church, K. and Kaplan, R. 1981 Removing Recursion from Natural
Language Processors Based on Phrase-Structure Grammars. Paper
presented at Conference on Modeling Human Parsing Strate-
gies, University of Texas at Austin.
Dostert, B. and Thompson, F. 1971. How Features Resolve Syn-
tactic Ambiguity. In Ivlinker, J. and Rosenfeld, S., eds., Pro-
ceedings of the Symposium on Information Storage and Retrieval.
Earley, J. 1970 An Efficient Context-Free Parsing Algorithm,
CACM 13:2.
Harrison, M. 1978 Introduction to Formal Language Theory. Addi-
son Wesley.
Kaplan, R. 1972 Augmented Transition Networks as Psychological
Models of Sentence Comprehension, Artificial Intelligence,
3:77-100.
Kaplan, R. and Bresnan, J. 1981 Lexical-Functional Grammar: A
Formal System for Grammatical Representation. In Bresnan, J.,
ed., The Mental Representation of Grammatical Relations. MIT
Press.
Knuth, D. 1975 The Art of Computer Programming. Vol. I: Funda-
mental Algorithms. Addison Wesley.
Liu, C. and Liu, J. 1975 Linear Systems Analysis. McGraw Hill.
Malhotra, A. 1975 Design Criteria for a Knowledge-Based English
Language System for Management: An Experimental Analysis.
MIT/LCS /TR-146.
Martin, W., Church, K., and Patil, R. 1981 Preliminary Analysis of
a Breadth-First Parsing Algorithm: Theoretical and Experimental
Results. MIT /LCS/TR-261.
Minsky, M. 1981 Music, Mind, and Meaning. MIT A.I. Memo No.
616.
Oppenheim, A. and Schafer, R. 1975. Digital Signal Processing.
Prentice Hall.
Sager, N. 1973 The String Parser for Scientific Literature. In
Rustin, R., ed., Natural Language Processing. Algorithmic Press.
Salomaa, A. 1973 Formal Languages. Academic Press
Woods, W. 1970 Transition Network Grammars for Natural Lan-
guage Analysis, CACM 13:10.
American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 149
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.992643">Coping with Syntactic Ambiguity or How to Put the Block in the Box on the Table&apos;</title>
<author confidence="0.871907">Kenneth Ramesh Patil</author>
<affiliation confidence="0.995222">Laboratory for Computer Massachusetts Institute of</affiliation>
<address confidence="0.999762">Cambridge, MA 02139</address>
<abstract confidence="0.972864352459016">Sentences are far more ambiguous than one might have thought. There may be hundreds, perhaps thousands, of syntactic parse trees for certain very natural sentences of English. This fact has been a major problem confronting natural language processing, especially when a large percentage of the syntactic parse trees are enumerated during semantic/pragmatic processing. In this paper we propose some methods for dealing with syntactic ambiguity in ways that exploit certain regularities among alternative parse trees. regularities will be expressed as combinations and also as sums and products of formal power series. We believe that such encoding of ambiguity will enhance processing, whether syntactic and semantic constraints are processed separately in sequence or interleaved together. Most parsers find the set of parse trees by starting with the empty set and adding to it each time they find a new possibility. We make the observation that in certain situations it would be much more efficient to work in the other direction, starting from the universal set (i.e, the set of all binary trees) and ruling trees out when the parser decides that they cannot be parses. Ruling-out is easier when the set of parse trees is closer to the universal set and ruling-in is easier when the set of parse trees is closer to the empty set. Rulingis particularly suited for way ambiguous&amp;quot; constructions such as prepositional phrases that have just as many parse trees as there are binary trees over the terminal elements. Since every tree is a parse, the parser doesn&apos;t have to rule any of them out. In some sense, this is a formalization of an idea that has been in the literature for some time. That is, it has been noticed for a long time that these sorts of very ambiguous constructions are very difficult for 1This research was supported (in part) by the National Institutes of Health Grant No. 1 P01 LM 03374-02 from the National Library of Medicine, and by the Defense Advanced Research Projects Agency (DOD) monitored by the Office of Naval Research under Contract No. N00014-75-C-0661. most parsing algorithms, but (apparently) not for people. This observation has led some researchers to hypothesize additional parsing mechanisms, such as (Church 1980, pp. and permanent predictable ambiguity (Sager 1973), so that the parser could &amp;quot;attach all ways&amp;quot; in a single step. However, these mechanisms have always lacked a precise interpretation; we will present a much more formal way of coping with &amp;quot;every way ambiguous&amp;quot; gramdefined in terms of numbers 1975, pp. 388-389, 531-533). 1. Ambiguity is a Practical Problem Sentences are far more ambiguous than one might thought. Our experience with the (Martin, Church, and Patil 1981) indicates that there may be hundreds, perhaps thousands, of syntactic parse trees for certain very natural sentences of English. For example, consider the following sentence with two prepositional phrases: 2The idea of pseudo-attachment was first proposed by Marcus (private communication), though Marcus does not accept the formulation in Church 1980. by the Association for Computational Linguistics. Permission to copy without fee all or part of this material is granted that the copies are not made for direct commercial advantage and the and this copyright notice are included on the first page. To copy otherwise, or to republish, requires a fee and/or specific permission. 0362-613X/82/030139-11$03.00 Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity (1) Put the block in the box on the table. which has two interpretations: (2a) Put the block[in the box on the table] (2b) Put [the block in the box] on the table. These syntactic ambiguities grow &amp;quot;combinatorially&amp;quot; with the number of prepositional phrases. For example, when a third PP is added to the sentence above, there are five interpretations: (3a) Put the block [[in the box on the table] in the kitchen]. (3b) Put the block [in the box [on the table in the kitchen]]. (3c) Put [[the block in the box] on the table] in the kitchen. (3d) Put [the block [in the box on the table]] in the kitchen. (3e) Put [the block in the box] [on the table in the kitchen]. a fourth added, there are fourteen trees, and so on. This sort of combinatoric ambiguity has been a major problem confronting natural language processing. In this paper we propose some methods for dealing with syntactic ambiguity in ways that take advantage of regularities among the alternative parse trees. In particular, we observe that enumerating the parse trees as above fails to capture the important generalization that prepositional phrases are &amp;quot;every way ambiguous,&amp;quot; or more precisely, the set of parse over is the same as the set of binary trees can be constructed over elements. Notice, for example, that there are two possible binary trees over three elements, (4a) [ ... block ... [ ... box ... table ... ]] (4b) [[ ... block ... box ...] ... table ... ] corresponding to (2a) and (2b), respectively, and that there are five binary trees over four elements correto (3a)â€”(3c), PPs, adjuncts, conjuncts, noun-noun modification, stack relative clauses, and other &amp;quot;every way ambiguous&amp;quot; constructions will be treated as primitive objects. They can be combined in various ways to produce composite constructions, such as lexical ambiguity, which may also be very ambiguous but not necessarily &amp;quot;every way ambiguous.&amp;quot; Lexical ambiguity, for example, will be analyzed as the sum of its senses, or in flow graph terminology (Oppenheim and Schafer 1975) as a parallel connection of its senses. Structural ambiguity, on the other hand, will be analyzed as the product of its components, or in flow graph terminology as a series connection. 2. Formal Power Series This section will make the linear systems analogy more precise by relating context-free grammars to formal power series (polynominals). Formal power series are a well-known device in the formal language literature (e.g., Salomaa 1973) for developing the algebraic properties of context-free grammars. We introduce them here to establish a formal basis for our upcoming discussion of processing issues.</abstract>
<note confidence="0.940496833333333">The power series for grammar (5a) is (5b). (5a) NP -.John I NP and NP (5b) NP = John + John and John + 2John and John and John + 5John and John and John and John + 14John and John and John and John</note>
<abstract confidence="0.991163">and John + ... term consists of a by the and an which counts how many ways the sentence can be generated. For example, the sentence &amp;quot;John&amp;quot; has one parse tree [John] tree because the zero-th coefficient of the power series is one. Similarly, the sentence &amp;quot;John and John&amp;quot; also has one tree because its coefficient is one, [John and John] tree and &amp;quot;John and John and John&amp;quot; has two because its coefficient is two,</abstract>
<affiliation confidence="0.323926">John and John] and John], [John and [John and John]] and &amp;quot;John and John and John and John&amp;quot; has five,</affiliation>
<address confidence="0.266635">John and [[Johnand John] John]], 5</address>
<affiliation confidence="0.63538875">John and [John and [John and John]]], [[[John and John], and John] and John], [[John and [John and John]] and John], Wolin and John] and [John and John</affiliation>
<abstract confidence="0.931761527272727">and so on. The reader can verify for himself that &amp;quot;John and John and John and John and John&amp;quot; has fourteen trees. Note that the power series encapsulates the ambiguity response of the system (grammar) to all possible input sentences. In this way, the power series is analogous to the impulse response in electrical engineering, which encapsulates the response of the system (circuit) to all possible input frequencies. (Ambiguity coefficients bear a strong resemblance to frequency coefficients in Fourier analysis.) All of these transformed representation systems (e.g., power series, impulse response, and Fourier series) provide a complete description of the system with no loss of (and no heuristic approximations, for search strategies (Kaplan 1972)). Trans- 3The formal language literature (Harrison 1978, Salomaa uses the term of ambiguity coefficient. Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity forms are often very useful because they provide a different point of view. Certain observations are more easily seen in the transform space than in the original space, and vice versa. This paper will discuss several ways to generate the power series. Initially let us consider successive approximation. Of all the techniques to be presented here, successive approximations most closely resembles the approach taken by most current chart parsers in- Church, and Patil 1981). The alternative approaches take advantage of certain regularities in the power series in order to produce the same results more efficiently. Successive approximation works as follows. First we translate grammar (5a) into the equation: (7) NP = John + NP. and. NP &amp;quot;+&amp;quot; connects two ways of generating an &amp;quot;.&amp;quot; concatenates two parts of an some we want to &amp;quot;solve&amp;quot; this equation for can be accomplished by refining successive approxima- An initial approximation is formed by takbe the empty language, (8a) = 0 Then we form the next approximation by substituting the previous approximation into equation (7), and simplifying according to the usual rules of algebra assuming distributivity, identity element, and zero element). (8b) = + â€¢ = John + 0. and. 0 = John We continue refining the approximation in this way. (8c) = John + and â€¢ = John + John and John (8d) = John + and = John + (John + John and John) . and.</abstract>
<affiliation confidence="0.3657828">(John + John and John) = John + John and John + John and John and John + John and John and John + John and John and John and John</affiliation>
<abstract confidence="0.980720985714286">4This needs a qualification. It is true that the power series provides a complete description of the ambiguity response to any input sentence. However, the power series representation may be losing some information that would be useful for parsing. In particular, there might be some cases where it is impossible to recover the parse trees exactly, as we will see, though this may not be too serious a problem for many practical applications. That is, it is often possible to recover most (if not all) of the structure, which may be adequate for many applications. 5The careful reader may correctly object to this assumption. We include it here for expository convenience, as it greatly simplifies the derivations though it should be noted that many of the results could be derived without the assumption. Furthermore, this assumption is valid for counting ambiguity. That is, IA â€¢ BI * ICI = IAI * I8 â€¢ CI, where A, B, and C are sets of trees and I denotes the number of members of A, and * is integer multiplication. = John + John and John + 2 John and John and John + John and John and John and John we have as an infinitely long polynominal (5b) above. This expression can be simplified by introducing a notation for exponentiation. Let x&apos; be an abbreviation for multiplying x x â€¢ ... â€¢ x, i times. (9) NP = John + John and John 2 John (and 5 John (and 14 John (and + Note that parentheses are interpreted differently in algebraic equations than in context-free rules. In context-free rules, parentheses denote optionality, where in equations they denote precedence relations among algebraic operations. 3. Catalan Numbers Ambiguity coefficients take on an important practical significance when we can model them directly without resorting to successive approximation as above. This can result in substantial time and space savings in certain special cases where there are much more efficient ways to compute the coefficients than successive approximation (chart parsing). Equation (9) is such a special case; the coefficients follow a combinatoric series called the 1975, pp. 388-389, This section will describe Catalan numbers and their relation to parsing. The first few Catalan numbers are 1, 1, 2, 5, 14, 42, 132, 469, 1430, 4862. They are generated by the form 2n (10) Cat, = This formula can be explained in terms of parenthesized expressions, which are equivalent to trees. Cat, is the number of ways to parenthesize a formula of are two conditions on parenthesization: (a) there must be the same number of open and close parentheses, and (b) they must be properly nested so that an open parenthesis precedes its matching close parenthesis. The first term counts the number of 6This fact was first pointed out to us by V. Pratt. We suspect that it is a generally well-known result in the formal language community, though its origin is unclear. 7(g) known as a coefficient. is equivalent a!/[b!(a-b)!jl, a! is equal to the product of all integers between a. Binomial coefficients are very common in combinatorics where they are interpreted as the number of ways to pick b objects out of a set of a objects.</abstract>
<note confidence="0.74561">Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 141</note>
<author confidence="0.64131">Kenneth Church</author>
<author confidence="0.64131">Ramesh Path Coping with Syntactic Ambiguity</author>
<abstract confidence="0.990835818181818">of such that there are the same number of opens and closes. The second term subtracts cases violating condition (b). This explanation is elaborated in Knuth 1975, p. 531. It is very useful to know that the ambiguity coefficients are Catalan numbers because this observation enables us to replace equation (9) with (11), where idenotes the Catalan number. (All summations range from 0 to 00 unless noted otherwise.) NP = E Cat. John (and Catalan number is the number of binary trees can be constructed over This theoretical model correctly predicts our practical experience EQSP exactly the Catalan number of parse trees for each sentence in the following sequence. 1 It was the number. 1 It was the number of products. the number of products of products. the number of products of products of products. 14 It was the number of products of products of products of products. These predictions continue to hold with as many as nine prepositional phrases (4862 parse trees). Lookup could improve performance on PPs if we could find a more efficient way to compute Catathan chart parsing, the method currently employed by EQSP. Let us propose two alternatives: table lookup and evaluating expression (10) directly. are very efficient over practical ranges of more than 20 phrases or In both cases, the ambiguity of a sentence in grammar (5a) can be determined by counting the number of occurrences of &amp;quot;and John&amp;quot; and then retrieving the Catalan of that number. These approaches both take linear time (over practical of whereas chart parsing requires cubic time to parse sentences in these grammars, a significant improvement. So far we have shown how to compute in linear time the number of ambiguous interpretations of a sentence in an &amp;quot;every way ambiguous&amp;quot; grammar. However, we are really interested in finding parse trees, not just the number of ambiguous interpretations. We could extend the table lookup algorithm to find trees rather than ambiguity coefficients, by modifying the table to store trees instead of numbers. For purposes, can be thought of as a pointer the entry of the table. So, for a sentence in grammar (5a), for example, the machine could count the number of occurrences of &amp;quot;and John&amp;quot; and then retrieve the table entry for that number. index trees 0 {[John</abstract>
<address confidence="0.658298">1 {[John and John</address>
<affiliation confidence="0.4758065">2 {[[John and John] and John], [John and [John and John</affiliation>
<abstract confidence="0.990804403314917">The table would be more general if it did not specify the lexical items at the leaves. Let us replace the table above with index trees 0 {[x]} 1 {[x x]} 2 {[[x x] x], [x [x x]]] and assume the machine can bind the x&apos;s to the appropriate lexical items. There is a real problem with this table lookup machine. The parse trees may not be exactly correct because the power series computation assumed that multiplication was associative, which is an appropriate assumption for computing ambiguity, but inappropriate for constructing trees. For example, we observed that prepositional phrases and conjunction are both &amp;quot;every way ambiguous&amp;quot; grammars because their ambiguity coefficients are Catalan numbers. However, it is not the case that they generate exactly the same parse trees. Nevertheless we present the table lookup pseudoparser here because it seems to be a speculative new approach with considerable promise. It is often more efficient than a real parser, and the trees that it finds may be just as useful as the correct one for many practical purposes. For example, many speech recognition projects employ a parser to filter out syntactically inappropriate hypotheses. However, a full parser is not really necessary for this task; a recognizer such as this table lookup pseudo-parser may be perfectly adequate for this task. Furthermore, it is often possible to recover the correct trees from the output of the pseudo-parser. In particular, the difference between prepositional phrases and conjunction could be acfor by modifying the interpretation of the category label, so that the trees would be interpreted correctly even though they are not exactly correct. 8The table lookup scheme ought to have a way to handle the theoretical possibility that there are an unlimited number of prepositional phrases. The table lookup routine will employ a more traditional parsing algorithm (e.g., Earley&apos;s algorithm) when the number of phrases in the input sentence is not stored in the table. 9The linear time result depends on the assumption that table lookup (or closed form computation) can be performed in constant This may be a fair assumption over practical ranges of it is not true in general. Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity The table lookup approach works for primitive grammars. The next two sections show how to decompose composite grammars into series and parallel combinations of primitive grammars. G = series G = + parallel 5. Parallel Decomposition Parallel decomposition can be very useful for dealing with lexical ambiguity, as in (13) ...to total with products near profits... where &amp;quot;total&amp;quot; can be taken as a noun or as a verb, as in: (14a) The accountant brought the daily sales to total with products near profits organized according the new law. (14b) The daily sales were ready for the accountant to total with products near profits organized to the new law. The analysis of these sentences makes use of the additivity property of linear systems. That is, each case, (14a) and (14b), is treated separately, and then the results are added together. Assuming &amp;quot;total&amp;quot; is a noun, there are three prepositional phrases contributbracketings, and assuming it is a verb, there two prepositional phrases for ambiguities. the two cases produces + = 5 + 2 = 7 parses. Adding another prepositional phrase + = 14 + 5 = 19 parses. (EOSP behaved as predicted in both cases.) This behavior is generalized by the following power series: P N â€¢ + N)&apos; V i which is the sum of the two cases: E = P N E noun i i&gt;0 to V E verb This observation can be incorporated into the table lookup pseudo-parser outlined above. Recall that Cat, interpreted as the index in a table containing all trees dominating i leaves. Similarly, + Iwill be interpreted as an instruction to the entry and i+ 1 thentry of the (17) (ADD-TREES (CAT-TABLE i) (CAT-TABLE(+ i 1))) Let us consider a system where syntactic processing strictly precedes semantic and pragmatic processing. In such a system, how could we incorporate semantic and pragmatic heuristics once we have already parsed the input sentence and found that it was the sum of two Catalans? The parser can simply subtract the inappropriate interpretations. If the oracle says that &amp;quot;total&amp;quot; is a verb, then (16a) would be subtracted from the combined sum, and if the oracle says that &amp;quot;total&amp;quot; is a noun, then (16b) would be subtracted. On the other hand, our analysis is also useful in a system that interleaves syntactic processing with semantic and pragmatic processing. Suppose that we had a semantic routine that could disambiguate &amp;quot;total,&amp;quot; but only at a very high cost in execution time. We need a way to estimate the usefulness of executing the semantic routine so that we don&apos;t spend the time if it is not likely to pay off. The analysis above provides a very simple way to estimate the benefit of disambiguating &amp;quot;total.&amp;quot; If it turns out to be a verb, then (16a) trees have been ruled out, and if it turns out to be a noun, then (16b) trees have been ruled out. We prefer our declarative algebraic approach over procedural heuristic search strategies (e.g., Kaplan 1972) because we do not have to specify the order of evaluation. We can delay the binding of decisions until the most opportune moment. 6. Series Decomposition we have a non-terminal is a series of two other non-terminals, VP. inspection, the power series of (18) S = NP â€¢ VP This result is easily verified when there is an unmistakable dividing point between the subject and the predi- For example, the verb &amp;quot;is&amp;quot; separates the in the subject from those in the predicate in (19a), but not in (19b). The number of products over sales of ... number of sales under ... divided Is number of products over sales of ... near number of sales under ...? clearly divided In (19a), the total number of parse trees is the product of the number of ways of parsing the subject times the number of ways of parsing the predicate. Both the subject and the predicate produce a Catalan number of parses, and hence the result is the product of two Canumbers, which was verified by (Martin, Church, and Patil 1981, p. 53). This result can be formalized in terms of the power series: (N E Cat.(P NO (is E i which is formed by taking the product of the two subcases: N E is E subject predicate 143 10This can be implemented efficiently, given an appropriate representation of sets of trees. American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity The power series says that the ambiguity of a parsentence is the product of and Cat, where the number of PPs before &amp;quot;is&amp;quot; and the number after &amp;quot;is.&amp;quot; This could be incorporated in the table parser as an instruction to &amp;quot;multiply&amp;quot; the in the table by the entry. Multiplication is a operation; L generates the set of trees whose left sub-tree l is from whose right sub-tree r is from R. (22) L x R = {(1, r) 11 cL &amp; râ‚¬R} This is a formal definition. For practical purposes, it may be more useful for the parser to output the list in the factored form: (23) (MULTIPLY-TREES (CAT-TABLE i) (CAT-TABLE j)) which is much more concise than a list of trees. It is possible, for example, that semantic processing can take advantage of factoring, capturing a semantic generalization that holds across all subjects or all predicates. Imagine, for example, that there is a semantic agreement constraint between predicates and arguments. For example, subjects and predicates might have to agree on the feature +human. Suppose that we were given sentences where this constraint was violated by all ambiguous interpretations of the sentence. In this case, it would be more efficient to employ a feature vector scheme (Dostert and Thompson 1971) which propagates the features in factored form. That is, it computes a feature vector for the union of all possible subjects, and a vector for the union of all then compares (intersects) these vectors to check if there are any interpretations that meet the constraint. A system such as this, which keeps the parses in factored form, is much more efficient than one that multiplies them out. Even if semantics cannot take advantage of the factoring, there is no harm in keeping the representation in factored form, because it is straightforward to expand (23) into a list of trees (though it may be somewhat slow). This example is relatively simple because &amp;quot;is&amp;quot; helps parser determine the value of let us return to example (19b) where &amp;quot;is&amp;quot; does not separate two strings of Again, we determine the powby multiplying the two subcases: (24) is (N E Cati(P Cat (E â€¢(P N) ) i is N E E Cat Cat(P J j However, this form is not so useful for parsing the parser cannot easily determine number of prepositional phrases in the subject and the number in the predicate. It appears the parser will have to compute the product of two Catalans for each of picking is somewhat Fortunately, the Catalan function has some special properties so that it is possible algebraically to remove references to the next section we show this expression can be reformulated in terms of total number of of Catalan Grammars Some readers may have noticed that expression is in We will make use of this in the reformulation. Notice that the Catalan series is fixed point under for a shift); that is, multiplying a Catalan power series (i.e., + x + + + + ...) with produces another polynomial with Catalan coeffi- The multiplication is worked out for the first few terms. + x + + + 1 + x + + + + + + 2x + + + + This property can be summarized as: E Cat, E Cat = E where n equals i+j. Intuitively, this equation says that if we have two &amp;quot;every way ambiguous&amp;quot; (Catalan) constructions, and we combine them in every possible way (convolution), the result is an &amp;quot;every way ambiguous&amp;quot; (Catalan) construction. With this observation, equation (24) reduces to: is (N E (E Catâ€¢(P = is N E Cat Hence the number of parses in the auxiliary-inverted case is the Catalan of one more than in the noncases. As predicted, the following inverted sentences to be more ambiguous than their non-inverted counterparts (previously discussed on page 142) by one Catalan number. 11Earley&apos;s algorithm and most other context-free parsing algorithms actually work this way. 12The proof immediately follows from the z-transform of the Catalan series (Knuth 1975, p. 388): zB(z) = B(z) â€” 1. + + + + + Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity 1 Was the number? 2 Was the number of products? 5 Was the number of products of products? 14 Was the number of products of products of products? 42 Was the number of products of products of products of products? 1 It was the number. 1 It was the number of products. 2 It was the number of products of products. 5 It was the number of products of products of products. 14 It was the number of products of products of products of products. How could this result be incorporated into the table lookup pseudo-parser? Recall that the pseudo-parser implements Catalan grammars by returning an index into the Catalan table. For example, if there were i the parser would return: i). We now extend the indexing scheme so that the parser implements a series connection of two Catalan grammars by returning one higher index than it would for a Catalan grammar. That is, if there were n parser would return n Series connections of Catalan grammars are very common in every day natural language, as illustrated by the following two sentences, which have received considerable attention in the literature because the parser cannot separate the direct object from the prepositional complement. (27a) I saw the man on the hill with a telescope ... (27b) Put the block in the box on the table in the kitchen ... Both examples have a Catalan number of ambiguities because the auto-convolution of a Catalan series yields Catalan This result can improve parsing performance because it suggests ways to reorganize (compile) the grammar so that there will be fewer references to quantities that are not readily available. This re-organization will reap benefits that chart parsers (e.g., Earley&apos;s algorithm) do not currently achieve because the re-organization is taking advantage of a number of combinatoric regularities, espeare not easily encoded into a chart. Section 9 presents an example of the reorganization. 13There is a difference between these two sentences because &amp;quot;put&amp;quot; subcategorizes for two objects unlike &amp;quot;see.&amp;quot; Suppose we analyze &amp;quot;see&amp;quot; as lexically ambiguous between two senses, one that selects for exactly two objects like &amp;quot;put&amp;quot; and one that selects for exactly one object as in &amp;quot;I saw it.&amp;quot; The first sense contributes the same number of parses as &amp;quot;put&amp;quot; and the second sense contributes an additional Catalan factor. 6.2 Chart Parsing Perhaps it is worthwhile to reformulate chart parsing in our terms in order to show which of the above results can be captured by such an approach and which cannot. Traditionally, chart parsers maintain a (or matrix) M, whose entries contain the set of category labels that span from position i to position j in the input sentence. This is accomplished by finding a position k between i and j such that there is a phrase from i to k that can combine with another phrase from k to j. An implementation of the inner loop looks something like: (28) loop for k from i to j do U * Essentially, then, a chart parser is maintaining the invariant (29) = M. I where addition and multiplication of matrix elements is related to parallel and series combination. Thus chart parsers are able to process very ambiguous sentences in polynomial time, as opposed to exponential (or Catalan) time. However, the examples above illustrate cases where chart parsers are not as efficient as they might be. In particular, chart parsers implement convolution the &amp;quot;long way,&amp;quot; by picking each possible dividing point k, and parsing from i to k and from k to j; they do not reduce the convolution of two Catalans as we did above. Similarly, chart parsers do not make use of the &amp;quot;every way ambiguous&amp;quot; generalization; given a Catalan grammar, chart parsers will eventually enumerate all possible values of i, j, and k. 7. Computing the Power Series Directly from the Grammar Thus far, most of our derivations have been justified in terms of successive approximation. It is also possible to derive some interesting (and well-known) results directly from the grammar itself. Suppose, for the sake of discussion, that we choose to analyze adwith a right branching (By convention, terminal symbols appear in lower case.) (30) ADJS adj ADJS I A First we translate the grammar into an equation in the way. That is, modeled as a parallel of two subgrammars, ADJS A.</abstract>
<note confidence="0.732563714285714">A, the empty string, is modeled as 1 because it is the 14A similar analysis of adjuncts is adopted in Kaplan and Bresnan 1981. This analysis can also be defended on performance grounds as an efficiency approximation. (This approximation is in the spirit of pseudo-attachment (Church 1980).) â€¢ Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982</note>
<author confidence="0.432111">Kenneth Church</author>
<author confidence="0.432111">Ramesh Path l Coping with Syntactic Ambiguity</author>
<abstract confidence="0.9916616125">identity element under series combination, i.e., multiplication.) (31a) ADJS adj ADJS I A (31b) ADJS = adj â€¢ ADJS + 1 We can simplify (31b) so the right hand side is expressed in terminal symbols alone, with no references to non-terminals. This is very useful for processing because it is much easier for the parser to determine the presence or absence of terminals than of nonterminals. That is, it is easier for the parser to deterfor example, whether a is an it is decide whether a an ADJS phrase. The simplification moves all references to ADJS to the left hand side, by subtracting from both sides, (31c) ADJS â€” adj â€¢ ADJS = 1 factoring the left hand side, (31d) (1 â€” adDADJS = 1 and dividing from both sides, ADJS = (1 â€” 1 1adj + adj 2 1â€”adj 1â€”adj 1â€”adj adj .3 1 + = 1â€”adj like will be referred to as a analogy to a unit step function in electrical engineering. the Power Series from the This section will re-derive the power series for the unit step grammar directly from the ATN representaby treating the networks as graphs (Oppenheim 1975). The graph transformations presented here are directly analogous to the algebraic simplifications employed in the previous section. First we translate the grammar into an ATN in the usual way (Woods 1970). ADJS adj ADJS I ADJS: adj Push ADJ Pop Jump This graph can be simplified by performing a compiler call recursion and Kaplan 1981 and references therein). This transformation replaces the final push arc with a jump: Jump Jump corresponds directly to the algebraic of moving the to the left hand side, factoring out the ADJS, and dividing from both sides. Then we remove the top jump arc by series reduction. This step corresponds to multiplying by 1 since a jump arc is the ATN representation for the identity element under series combination. Pop Jump The loop can be treated as an infinite series: 1 + adj + + + where the zero-th term corresponds to zero iterations around the loop, the first term corresponds to a single iteration, the second term to two iterations, and so on. Recall that (36) is equivalent to: (37) With this observation, it is possible to open the loop: (38) Jump Pop final series reduction, the ATN is equivalent to expression (31e) above. (38g) ADJS: an ATN loop (or step grammar) is a division operator. We now have composition operators for parallel composition (addition), series composition (multiplication), and loops (division). An ATN loop can be implemented in terms of the table lookup scheme discussed above. First we reformulate the loop as an infinite sum: ADJS: ADJS: performing the long division, we observe that (31) has unit coefficients.</abstract>
<note confidence="0.7544255">Cat adj Pop Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity 1 â€” E 1â€”adj</note>
<abstract confidence="0.96131896">we construct a table so that the entry in the tells the parser how to parse i occurrences of 9. An Example Suppose for example that we were given the following grammar: (40a) S NP VP ADJS (40b) S V NP (PP) ADJS ADJS (40c) VP -0. V NP (PP) ADJS (40d) PP P NP (40e) NP NI NP PP ADJS adj ADJS I (In this example we will assume no lexical ambiguity V, P, inspection, we notice that NP are Catalan grammars and that ADJS is a Step grammar. PP = E i&gt;0 NP = N ADJS = With these observations, the parser can process PPs, and by counting the number of occurrencof terminal symbols and looking up numbers in the appropriate tables. We now substitute (41a-c) into (40c). (42) VP = V NP (1 + PP)ADJS V (N E N)&apos;)(E (E and simplify the convolution of the two Catalan functions VP = V (N E adj&apos;) so that the parser can also find VPs by just counting coccurrences of terminal symbols. Now we simplify so that can also be parsed by just counting occurrences of terminal symbols. translate (40a-b) into the equation: (44) S = NP VP ADJS + V NP (1+PP) ADJS ADJS and then expand VP using (42) (45) S = NP (V NP (1+PP) ADJS) ADJS + V NP (1+PP) ADJS ADJS and factor S = (NP + 1) V NP (1+PP) That can be simplified considerably because NP (1 + PP) = N E E N E and (48) = E adj&apos; E adj&apos; = (i + so that S = (N E + 1) N E Cat. 14- (i + has the following Jump Jump â€¢ â€¢ â€¢ â€¢ â€¢ (1, (i + 1+ (50) The entire example grammar has now been compiled into a form that is easier for parsing. This formula says that sentences are all of the form: (51) S (N (P N)*) V N (P N)* adj* which could be recognized by the following finite state machine: (52) â€ºc) Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity Furthermore, the number of parse trees for a given input sentence can be found by multiplying three numbers: (a) the Catalan of the number of P N&apos;s before the verb, (b) the Catalan of one more than the number of P N&apos;s after the verb, and (c) the ramp of the number of adj&apos;s. For example, the sentence (53) The man on the hill saw the boy with a telescope yesterday in the morning. Cat * * 3 = 6 parses. That is, there is one way to parse &amp;quot;the man on the hill,&amp;quot; two ways to parse &amp;quot;saw the boy with a telescope&amp;quot; (&amp;quot;telescope&amp;quot; is either a complement of &amp;quot;see&amp;quot; as in (54a-c) or is attached to &amp;quot;boy&amp;quot; as in (54d-f)), and three ways to parse the adjuncts (they could both attach to the S (54a,d), or they could both attach to the VP (54b,e), or they could split (54c,f)). (54a) [The man on the hill [saw the boy with a telescope] [yesterday in the morning.]] (54b) The man on the hill [[saw the boy with a telescope] [yesterday in the morning.]] (54c) The man on the hill [[saw the boy with a telescope] yesterday] in the morning. (54d) [The man on the hill saw [the boy with a telescope] [yesterday in the morning.]] (54e) The man on the hill [saw [the boy with a telescope] [yesterday in the morning.]] (54f) The man on the hill [saw [the boy with a telescope] yesterday] in the morning. All and only these possibilities are permitted by the grammar. 10. Conclusion We began our discussion with the observation that certain grammars are &amp;quot;every way ambiguous&amp;quot; and suggested that this observation could lead to improved parsing performance. Catalan grammars were then introduced to remedy the situation so that the processor can delay attachment decisions until it discovers some more useful constraints. Until such time, the processor can do little more than note that the input sentence is &amp;quot;every way ambiguous.&amp;quot; We suggested that a table lookup scheme might be an effective method to implement such a processor. We then introduced rules for combining primitive grammars, such as Catalan grammars, into composite grammars. This linear systems view &amp;quot;bundles up&amp;quot; all the parse trees into a single concise description capable of telling us everything we might want to know about the parses (including how much it might cost to ask a particular question). This abstract view of ambiguity enables us to ask questions in the most convenient order, and to delay asking until it is clear that the pay-off will exceed the cost. This abstraction was strongly influenced by the notion of binding. We have presented combination rules in three different representation systems: power series, ATNs, and context-free grammars, each of which contributed its own insights. Power series are convenient for defining the algebraic operations, ATNs are most suited for discussing implementation issues, and context-free grammars enable the shortest derivations. Perhaps the following quotation best summarizes our motivation for alternating among these three representation systems: thing or idea seems meaningful only when we have different ways to represent it â€” different perspectives and different associations. Then you can turn it around in your mind, so to speak; however, it seems at the moment you can see it another way; you never come to a full stop. (Minsky 1981, p. 19) In each of these representation schemes, we have introduced five primitive grammars: Catalan, Unit Step, 1, and 0, and terminals; and four composition rules: addition, subtraction, multiplication, and division. We have seen that it is often possible to employ these analytic tools in order to re-organize (compile) the grammar into a form more suitable for processing efficiently. We have identified certain where the ambiguity is combinatoric, and have sketched a few modifications to the grammar that enable processing to proceed in a more efficient manner. In particular, we have observed it to be important for the grammar to avoid referencing quantities that are not easily determined, such as the dividing point between a noun phrase and a prepositional phrase as in (55) Put the block in the box on the table in the kitchen ... We have seen that the desired re-organization can be achieved by taking advantage of the fact that the autoconvolution of a Catalan series produces another Caseries. This reduced processing time from to almost linear time. Similar analyses have been discussed for a number of lexically and structurally ambiguous constructions, culminating with the example in section 9, where we transformed a grammar into a form that could be parsed by a single left-to-right pass over the terminal elements. Currently, these grammar reformulations have to be performed by hand. It ought to be possible to automate this process so that the reformulations could be performed by a grammar compiler. We leave this project open for future research. 11. Acknowledgments We would like to thank Jon Allen, Sarah Ferguson, Lowell Hawkinson, Kris Halvorsen, Bill Long, Mitch Marcus, Rohit Parikh, and Peter Szolovits for their very useful comments on earlier drafts. We would Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 especially like to thank Bill Martin for initiating the project.</abstract>
<note confidence="0.942342307692308">References K. 1980 Memory Limitations in Natural Language and IULC. K. and Kaplan, R. 1981 Recursion from Natural Processors Based on Phrase-Structure Grammars. presented at Conference on Modeling Human Parsing Strategies, University of Texas at Austin. Dostert, B. and Thompson, F. 1971. How Features Resolve Syn- Ambiguity. In Ivlinker, J. and Rosenfeld, S., eds., Proceedings of the Symposium on Information Storage and Retrieval. Earley, J. 1970 An Efficient Context-Free Parsing Algorithm, M. 1978 to Formal Language Theory. Addison Wesley. Kaplan, R. 1972 Augmented Transition Networks as Psychological of Sentence Comprehension, Intelligence, 3:77-100. Kaplan, R. and Bresnan, J. 1981 Lexical-Functional Grammar: A Formal System for Grammatical Representation. In Bresnan, J., Mental Representation of Grammatical Relations. Press. D. 1975 Art of Computer Programming. Vol. I: Funda- Algorithms. Wesley. C. and Liu, J. 1975 Systems Analysis. Hill. A. 1975 Criteria for a Knowledge-Based English Language System for Management: An Experimental Analysis. MIT/LCS /TR-146. W., Church, K., and Patil, R. 1981 Analysis of a Breadth-First Parsing Algorithm: Theoretical and Experimental /LCS/TR-261. M. 1981 Mind, and Meaning. A.I. Memo No. 616. A. and Schafer, R. 1975. Signal Processing. Prentice Hall. Sager, N. 1973 The String Parser for Scientific Literature. In R., ed., Language Processing. Press. A. 1973 Languages. Press Woods, W. 1970 Transition Network Grammars for Natural Lan- Analysis, Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<date>1980</date>
<booktitle>On Memory Limitations in Natural Language Processing. MIT/LCS/TR-245, and IULC.</booktitle>
<contexts>
<context position="2513" citStr="Church 1980" startWordPosition="408" endWordPosition="409">e literature for some time. That is, it has been noticed for a long time that these sorts of very ambiguous constructions are very difficult for 1 This research was supported (in part) by the National Institutes of Health Grant No. 1 P01 LM 03374-02 from the National Library of Medicine, and by the Defense Advanced Research Projects Agency (DOD) monitored by the Office of Naval Research under Contract No. N00014-75-C-0661. most parsing algorithms, but (apparently) not for people. This observation has led some researchers to hypothesize additional parsing mechanisms, such as pseudo-attachment (Church 1980, pp. 65-71)2 and permanent predictable ambiguity (Sager 1973), so that the parser could &amp;quot;attach all ways&amp;quot; in a single step. However, these mechanisms have always lacked a precise interpretation; we will present a much more formal way of coping with &amp;quot;every way ambiguous&amp;quot; grammars, defined in terms of Catalan numbers (Knuth 1975, pp. 388-389, 531-533). 1. Ambiguity is a Practical Problem Sentences are far more ambiguous than one might have thought. Our experience with the EQSP parser (Martin, Church, and Patil 1981) indicates that there may be hundreds, perhaps thousands, of syntactic parse tre</context>
<context position="32680" citStr="Church 1980" startWordPosition="5621" endWordPosition="5622"> sake of discussion, that we choose to analyze adjuncts with a right branching grammar.14 (By convention, terminal symbols appear in lower case.) (30) ADJS adj ADJS I A First we translate the grammar into an equation in the usual way. That is, ADJS is modeled as a parallel combination of two subgrammars, adj ADJS and A. (A, the empty string, is modeled as 1 because it is the 14 A similar analysis of adjuncts is adopted in Kaplan and Bresnan 1981. This analysis can also be defended on performance grounds as an efficiency approximation. (This approximation is in the spirit of pseudo-attachment (Church 1980).) â€¢ Mkj American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 145 Kenneth Church and Ramesh Path l Coping with Syntactic Ambiguity identity element under series combination, i.e., multiplication.) (31a) ADJS adj ADJS I A (31b) ADJS = adj â€¢ ADJS + 1 We can simplify (31b) so the right hand side is expressed in terminal symbols alone, with no references to non-terminals. This is very useful for processing because it is much easier for the parser to determine the presence or absence of terminals than of nonterminals. That is, it is easier for the parser to determ</context>
</contexts>
<marker>Church, 1980</marker>
<rawString>Church, K. 1980 On Memory Limitations in Natural Language Processing. MIT/LCS/TR-245, and IULC.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
<author>R Kaplan</author>
</authors>
<title>Removing Recursion from Natural Language Processors Based on Phrase-Structure Grammars. Paper presented at Conference on Modeling Human Parsing Strategies,</title>
<date>1981</date>
<institution>University of Texas at Austin.</institution>
<contexts>
<context position="34417" citStr="Church and Kaplan 1981" startWordPosition="5934" endWordPosition="5937"> function in electrical engineering. 8. Computing the Power Series from the ATN This section will re-derive the power series for the unit step grammar directly from the ATN representation by treating the networks as flow graphs (Oppenheim 1975). The graph transformations presented here are directly analogous to the algebraic simplifications employed in the previous section. First we translate the grammar into an ATN in the usual way (Woods 1970). (32) ADJS adj ADJS I A (33) ADJS: 0Cat adj Push ADJ Pop Jump This graph can be simplified by performing a compiler optimization call tail recursion (Church and Kaplan 1981 and references therein). This transformation replaces the final push arc with a jump: Jump Jump Tail recursion corresponds directly to the algebraic operations of moving the ADJS term to the left hand side, factoring out the ADJS, and dividing from both sides. Then we remove the top jump arc by series reduction. This step corresponds to multiplying by 1 since a jump arc is the ATN representation for the identity element under series combination. Pop 9&gt; Jump The loop can be treated as an infinite series: (36) 1 + adj + adj2 + adj3 + where the zero-th term corresponds to zero iterations around </context>
</contexts>
<marker>Church, Kaplan, 1981</marker>
<rawString>Church, K. and Kaplan, R. 1981 Removing Recursion from Natural Language Processors Based on Phrase-Structure Grammars. Paper presented at Conference on Modeling Human Parsing Strategies, University of Texas at Austin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dostert</author>
<author>F Thompson</author>
</authors>
<title>How Features Resolve Syntactic Ambiguity.</title>
<date>1971</date>
<booktitle>Proceedings of the Symposium on Information Storage and Retrieval.</booktitle>
<editor>In Ivlinker, J. and Rosenfeld, S., eds.,</editor>
<contexts>
<context position="24712" citStr="Dostert and Thompson 1971" startWordPosition="4219" endWordPosition="4222">ich is much more concise than a list of trees. It is possible, for example, that semantic processing can take advantage of factoring, capturing a semantic generalization that holds across all subjects or all predicates. Imagine, for example, that there is a semantic agreement constraint between predicates and arguments. For example, subjects and predicates might have to agree on the feature +human. Suppose that we were given sentences where this constraint was violated by all ambiguous interpretations of the sentence. In this case, it would be more efficient to employ a feature vector scheme (Dostert and Thompson 1971) which propagates the features in factored form. That is, it computes a feature vector for the union of all possible subjects, and a vector for the union of all possible VPs, and then compares (intersects) these vectors to check if there are any interpretations that meet the constraint. A system such as this, which keeps the parses in factored form, is much more efficient than one that multiplies them out. Even if semantics cannot take advantage of the factoring, there is no harm in keeping the representation in factored form, because it is straightforward to expand (23) into a list of trees (</context>
</contexts>
<marker>Dostert, Thompson, 1971</marker>
<rawString>Dostert, B. and Thompson, F. 1971. How Features Resolve Syntactic Ambiguity. In Ivlinker, J. and Rosenfeld, S., eds., Proceedings of the Symposium on Information Storage and Retrieval.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An Efficient Context-Free Parsing Algorithm,</title>
<date>1970</date>
<journal>CACM</journal>
<pages>13--2</pages>
<marker>Earley, 1970</marker>
<rawString>Earley, J. 1970 An Efficient Context-Free Parsing Algorithm, CACM 13:2.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Harrison</author>
</authors>
<title>Introduction to Formal Language Theory.</title>
<date>1978</date>
<publisher>Addison Wesley.</publisher>
<contexts>
<context position="8466" citStr="Harrison 1978" startWordPosition="1400" endWordPosition="1401">nput sentences. In this way, the power series is analogous to the impulse response in electrical engineering, which encapsulates the response of the system (circuit) to all possible input frequencies. (Ambiguity coefficients bear a strong resemblance to frequency coefficients in Fourier analysis.) All of these transformed representation systems (e.g., power series, impulse response, and Fourier series) provide a complete description of the system with no loss of information4 (and no heuristic approximations, for example, search strategies (Kaplan 1972)). Trans3 The formal language literature (Harrison 1978, Salomaa 1973) uses the term support instead of ambiguity coefficient. 140 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity forms are often very useful because they provide a different point of view. Certain observations are more easily seen in the transform space than in the original space, and vice versa. This paper will discuss several ways to generate the power series. Initially let us consider successive approximation. Of all the techniques to be presented here, successive approximation</context>
</contexts>
<marker>Harrison, 1978</marker>
<rawString>Harrison, M. 1978 Introduction to Formal Language Theory. Addison Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kaplan</author>
</authors>
<title>Augmented Transition Networks as Psychological Models of Sentence Comprehension,</title>
<date>1972</date>
<journal>Artificial Intelligence,</journal>
<pages>3--77</pages>
<contexts>
<context position="8411" citStr="Kaplan 1972" startWordPosition="1392" endWordPosition="1393">ity response of the system (grammar) to all possible input sentences. In this way, the power series is analogous to the impulse response in electrical engineering, which encapsulates the response of the system (circuit) to all possible input frequencies. (Ambiguity coefficients bear a strong resemblance to frequency coefficients in Fourier analysis.) All of these transformed representation systems (e.g., power series, impulse response, and Fourier series) provide a complete description of the system with no loss of information4 (and no heuristic approximations, for example, search strategies (Kaplan 1972)). Trans3 The formal language literature (Harrison 1978, Salomaa 1973) uses the term support instead of ambiguity coefficient. 140 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity forms are often very useful because they provide a different point of view. Certain observations are more easily seen in the transform space than in the original space, and vice versa. This paper will discuss several ways to generate the power series. Initially let us consider successive approximation. Of all the te</context>
<context position="21843" citStr="Kaplan 1972" startWordPosition="3705" endWordPosition="3706">essing. Suppose that we had a semantic routine that could disambiguate &amp;quot;total,&amp;quot; but only at a very high cost in execution time. We need a way to estimate the usefulness of executing the semantic routine so that we don&apos;t spend the time if it is not likely to pay off. The analysis above provides a very simple way to estimate the benefit of disambiguating &amp;quot;total.&amp;quot; If it turns out to be a verb, then (16a) trees have been ruled out, and if it turns out to be a noun, then (16b) trees have been ruled out. We prefer our declarative algebraic approach over procedural heuristic search strategies (e.g., Kaplan 1972) because we do not have to specify the order of evaluation. We can delay the binding of decisions until the most opportune moment. 6. Series Decomposition Suppose we have a non-terminal S that is a series combination of two other non-terminals, NP and VP. By inspection, the power series of S is: (18) S = NP â€¢ VP This result is easily verified when there is an unmistakable dividing point between the subject and the predicate. For example, the verb &amp;quot;is&amp;quot; separates the PPs in the subject from those in the predicate in (19a), but not in (19b). (19a) The number of products over sales of ... is near </context>
</contexts>
<marker>Kaplan, 1972</marker>
<rawString>Kaplan, R. 1972 Augmented Transition Networks as Psychological Models of Sentence Comprehension, Artificial Intelligence, 3:77-100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>Lexical-Functional Grammar: A Formal System for Grammatical Representation.</title>
<date>1981</date>
<editor>In Bresnan, J., ed.,</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="32517" citStr="Kaplan and Bresnan 1981" startWordPosition="5596" endWordPosition="5599">een justified in terms of successive approximation. It is also possible to derive some interesting (and well-known) results directly from the grammar itself. Suppose, for the sake of discussion, that we choose to analyze adjuncts with a right branching grammar.14 (By convention, terminal symbols appear in lower case.) (30) ADJS adj ADJS I A First we translate the grammar into an equation in the usual way. That is, ADJS is modeled as a parallel combination of two subgrammars, adj ADJS and A. (A, the empty string, is modeled as 1 because it is the 14 A similar analysis of adjuncts is adopted in Kaplan and Bresnan 1981. This analysis can also be defended on performance grounds as an efficiency approximation. (This approximation is in the spirit of pseudo-attachment (Church 1980).) â€¢ Mkj American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 145 Kenneth Church and Ramesh Path l Coping with Syntactic Ambiguity identity element under series combination, i.e., multiplication.) (31a) ADJS adj ADJS I A (31b) ADJS = adj â€¢ ADJS + 1 We can simplify (31b) so the right hand side is expressed in terminal symbols alone, with no references to non-terminals. This is very useful for process</context>
</contexts>
<marker>Kaplan, Bresnan, 1981</marker>
<rawString>Kaplan, R. and Bresnan, J. 1981 Lexical-Functional Grammar: A Formal System for Grammatical Representation. In Bresnan, J., ed., The Mental Representation of Grammatical Relations. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Knuth</author>
</authors>
<title>The Art of Computer Programming. Vol. I: Fundamental Algorithms.</title>
<date>1975</date>
<publisher>Addison Wesley.</publisher>
<contexts>
<context position="2842" citStr="Knuth 1975" startWordPosition="463" endWordPosition="464">ects Agency (DOD) monitored by the Office of Naval Research under Contract No. N00014-75-C-0661. most parsing algorithms, but (apparently) not for people. This observation has led some researchers to hypothesize additional parsing mechanisms, such as pseudo-attachment (Church 1980, pp. 65-71)2 and permanent predictable ambiguity (Sager 1973), so that the parser could &amp;quot;attach all ways&amp;quot; in a single step. However, these mechanisms have always lacked a precise interpretation; we will present a much more formal way of coping with &amp;quot;every way ambiguous&amp;quot; grammars, defined in terms of Catalan numbers (Knuth 1975, pp. 388-389, 531-533). 1. Ambiguity is a Practical Problem Sentences are far more ambiguous than one might have thought. Our experience with the EQSP parser (Martin, Church, and Patil 1981) indicates that there may be hundreds, perhaps thousands, of syntactic parse trees for certain very natural sentences of English. For example, consider the following sentence with two prepositional phrases: 2 The idea of pseudo-attachment was first proposed by Marcus (private communication), though Marcus does not accept the formulation in Church 1980. Copyright 1982 by the Association for Computational Li</context>
<context position="12524" citStr="Knuth 1975" startWordPosition="2100" endWordPosition="2101">entheses denote optionality, where in equations they denote precedence relations among algebraic operations. 3. Catalan Numbers Ambiguity coefficients take on an important practical significance when we can model them directly without resorting to successive approximation as above. This can result in substantial time and space savings in certain special cases where there are much more efficient ways to compute the coefficients than successive approximation (chart parsing). Equation (9) is such a special case; the coefficients follow a well-known combinatoric series called the Catalan Numbers (Knuth 1975, pp. 388-389, 531-533).6 This section will describe Catalan numbers and their relation to parsing. The first few Catalan numbers are 1, 1, 2, 5, 14, 42, 132, 469, 1430, 4862. They are generated by the closed form expression:7 2n (10) Cat, = n (n2-111) This formula can be explained in terms of parenthesized expressions, which are equivalent to trees. Cat, is the number of ways to parenthesize a formula of length n. There are two conditions on parenthesization: (a) there must be the same number of open and close parentheses, and (b) they must be properly nested so that an open parenthesis prece</context>
<context position="14001" citStr="Knuth 1975" startWordPosition="2356" endWordPosition="2357">nal coefficient. It is equivalent to a!/[b!(a-b)!jl, where a! is equal to the product of all integers between 1 and a. Binomial coefficients are very common in combinatorics where they are interpreted as the number of ways to pick b objects out of a set of a objects. American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 141 Kenneth Church and Ramesh Path Coping with Syntactic Ambiguity sequences of 2n parentheses, such that there are the same number of opens and closes. The second term subtracts cases violating condition (b). This explanation is elaborated in Knuth 1975, p. 531. It is very useful to know that the ambiguity coefficients are Catalan numbers because this observation enables us to replace equation (9) with (11), where Cat i denotes the ith Catalan number. (All summations range from 0 to 00 unless noted otherwise.) (11) NP = E Cat. John (and John)i The ith Catalan number is the number of binary trees that can be constructed over i phrases. This theoretical model correctly predicts our practical experience with EQSP. EQSP found exactly the Catalan number of parse trees for each sentence in the following sequence. 1 It was the number. 1 It was the </context>
<context position="27720" citStr="Knuth 1975" startWordPosition="4767" endWordPosition="4768">(Catalan) construction. With this observation, equation (24) reduces to: (26) is (N E Cati(P N)i) (E Catâ€¢(P N)i) = is N E Cat n+1 (P NN)&apos;1n Hence the number of parses in the auxiliary-inverted case is the Catalan of one more than in the noninverted cases. As predicted, EQSP found the following inverted sentences to be more ambiguous than their non-inverted counterparts (previously discussed on page 142) by one Catalan number. 11 Earley&apos;s algorithm and most other context-free parsing algorithms actually work this way. 12 The proof immediately follows from the z-transform of the Catalan series (Knuth 1975, p. 388): zB(z) = B(z) â€” 1. 2x2 + x2 + 2x2 + 14x4 + 14x4 + 14x4 + 144 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity 1 Was the number? 2 Was the number of products? 5 Was the number of products of products? 14 Was the number of products of products of products? 42 Was the number of products of products of products of products? 1 It was the number. 1 It was the number of products. 2 It was the number of products of products. 5 It was the number of products of products of products. 14 It was</context>
</contexts>
<marker>Knuth, 1975</marker>
<rawString>Knuth, D. 1975 The Art of Computer Programming. Vol. I: Fundamental Algorithms. Addison Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Liu</author>
<author>J Liu</author>
</authors>
<title>Linear Systems Analysis.</title>
<date>1975</date>
<publisher>McGraw Hill.</publisher>
<marker>Liu, Liu, 1975</marker>
<rawString>Liu, C. and Liu, J. 1975 Linear Systems Analysis. McGraw Hill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Malhotra</author>
</authors>
<title>Design Criteria for a Knowledge-Based English Language System for Management: An Experimental Analysis.</title>
<date>1975</date>
<booktitle>MIT/LCS /TR-146.</booktitle>
<marker>Malhotra, 1975</marker>
<rawString>Malhotra, A. 1975 Design Criteria for a Knowledge-Based English Language System for Management: An Experimental Analysis. MIT/LCS /TR-146.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Martin</author>
<author>K Church</author>
<author>R Patil</author>
</authors>
<title>Preliminary Analysis of a Breadth-First Parsing Algorithm: Theoretical and Experimental Results.</title>
<date>1981</date>
<booktitle>MIT /LCS/TR-261.</booktitle>
<marker>Martin, Church, Patil, 1981</marker>
<rawString>Martin, W., Church, K., and Patil, R. 1981 Preliminary Analysis of a Breadth-First Parsing Algorithm: Theoretical and Experimental Results. MIT /LCS/TR-261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Minsky</author>
</authors>
<date>1981</date>
<pages>616</pages>
<contexts>
<context position="41359" citStr="Minsky 1981" startWordPosition="7204" endWordPosition="7205">ts. Power series are convenient for defining the algebraic operations, ATNs are most suited for discussing implementation issues, and context-free grammars enable the shortest derivations. Perhaps the following quotation best summarizes our motivation for alternating among these three representation systems: A thing or idea seems meaningful only when we have several different ways to represent it â€” different perspectives and different associations. Then you can turn it around in your mind, so to speak; however, it seems at the moment you can see it another way; you never come to a full stop. (Minsky 1981, p. 19) In each of these representation schemes, we have introduced five primitive grammars: Catalan, Unit Step, 1, and 0, and terminals; and four composition rules: addition, subtraction, multiplication, and division. We have seen that it is often possible to employ these analytic tools in order to re-organize (compile) the grammar into a form more suitable for processing efficiently. We have identified certain situations where the ambiguity is combinatoric, and have sketched a few modifications to the grammar that enable processing to proceed in a more efficient manner. In particular, we ha</context>
</contexts>
<marker>Minsky, 1981</marker>
<rawString>Minsky, M. 1981 Music, Mind, and Meaning. MIT A.I. Memo No. 616.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Oppenheim</author>
<author>R Schafer</author>
</authors>
<date>1975</date>
<booktitle>Digital Signal Processing.</booktitle>
<publisher>Prentice Hall.</publisher>
<contexts>
<context position="6025" citStr="Oppenheim and Schafer 1975" startWordPosition="982" endWordPosition="985"> ... table ... ] corresponding to (2a) and (2b), respectively, and that there are five binary trees over four elements corresponding to (3a)â€”(3c), respectively. PPs, adjuncts, conjuncts, noun-noun modification, stack relative clauses, and other &amp;quot;every way ambiguous&amp;quot; constructions will be treated as primitive objects. They can be combined in various ways to produce composite constructions, such as lexical ambiguity, which may also be very ambiguous but not necessarily &amp;quot;every way ambiguous.&amp;quot; Lexical ambiguity, for example, will be analyzed as the sum of its senses, or in flow graph terminology (Oppenheim and Schafer 1975) as a parallel connection of its senses. Structural ambiguity, on the other hand, will be analyzed as the product of its components, or in flow graph terminology as a series connection. 2. Formal Power Series This section will make the linear systems analogy more precise by relating context-free grammars to formal power series (polynominals). Formal power series are a well-known device in the formal language literature (e.g., Salomaa 1973) for developing the algebraic properties of context-free grammars. We introduce them here to establish a formal basis for our upcoming discussion of processi</context>
</contexts>
<marker>Oppenheim, Schafer, 1975</marker>
<rawString>Oppenheim, A. and Schafer, R. 1975. Digital Signal Processing. Prentice Hall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Sager</author>
</authors>
<title>The String Parser for Scientific Literature.</title>
<date>1973</date>
<booktitle>Natural Language Processing.</booktitle>
<editor>In Rustin, R., ed.,</editor>
<publisher>Algorithmic Press.</publisher>
<contexts>
<context position="2575" citStr="Sager 1973" startWordPosition="416" endWordPosition="417"> long time that these sorts of very ambiguous constructions are very difficult for 1 This research was supported (in part) by the National Institutes of Health Grant No. 1 P01 LM 03374-02 from the National Library of Medicine, and by the Defense Advanced Research Projects Agency (DOD) monitored by the Office of Naval Research under Contract No. N00014-75-C-0661. most parsing algorithms, but (apparently) not for people. This observation has led some researchers to hypothesize additional parsing mechanisms, such as pseudo-attachment (Church 1980, pp. 65-71)2 and permanent predictable ambiguity (Sager 1973), so that the parser could &amp;quot;attach all ways&amp;quot; in a single step. However, these mechanisms have always lacked a precise interpretation; we will present a much more formal way of coping with &amp;quot;every way ambiguous&amp;quot; grammars, defined in terms of Catalan numbers (Knuth 1975, pp. 388-389, 531-533). 1. Ambiguity is a Practical Problem Sentences are far more ambiguous than one might have thought. Our experience with the EQSP parser (Martin, Church, and Patil 1981) indicates that there may be hundreds, perhaps thousands, of syntactic parse trees for certain very natural sentences of English. For example,</context>
</contexts>
<marker>Sager, 1973</marker>
<rawString>Sager, N. 1973 The String Parser for Scientific Literature. In Rustin, R., ed., Natural Language Processing. Algorithmic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Salomaa</author>
</authors>
<title>Formal Languages.</title>
<date>1973</date>
<publisher>Academic Press</publisher>
<contexts>
<context position="6468" citStr="Salomaa 1973" startWordPosition="1054" endWordPosition="1055">ot necessarily &amp;quot;every way ambiguous.&amp;quot; Lexical ambiguity, for example, will be analyzed as the sum of its senses, or in flow graph terminology (Oppenheim and Schafer 1975) as a parallel connection of its senses. Structural ambiguity, on the other hand, will be analyzed as the product of its components, or in flow graph terminology as a series connection. 2. Formal Power Series This section will make the linear systems analogy more precise by relating context-free grammars to formal power series (polynominals). Formal power series are a well-known device in the formal language literature (e.g., Salomaa 1973) for developing the algebraic properties of context-free grammars. We introduce them here to establish a formal basis for our upcoming discussion of processing issues. The power series for grammar (5a) is (5b). (5a) NP -.John I NP and NP (5b) NP = John + John and John + 2John and John and John + 5John and John and John and John + 14John and John and John and John and John + ... Each term consists of a sentence generated by the grammar and an ambiguity coefficient3 which counts how many ways the sentence can be generated. For example, the sentence &amp;quot;John&amp;quot; has one parse tree (6a) [John] I tree be</context>
<context position="8481" citStr="Salomaa 1973" startWordPosition="1402" endWordPosition="1403"> In this way, the power series is analogous to the impulse response in electrical engineering, which encapsulates the response of the system (circuit) to all possible input frequencies. (Ambiguity coefficients bear a strong resemblance to frequency coefficients in Fourier analysis.) All of these transformed representation systems (e.g., power series, impulse response, and Fourier series) provide a complete description of the system with no loss of information4 (and no heuristic approximations, for example, search strategies (Kaplan 1972)). Trans3 The formal language literature (Harrison 1978, Salomaa 1973) uses the term support instead of ambiguity coefficient. 140 American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 Kenneth Church and Ramesh Patil Coping with Syntactic Ambiguity forms are often very useful because they provide a different point of view. Certain observations are more easily seen in the transform space than in the original space, and vice versa. This paper will discuss several ways to generate the power series. Initially let us consider successive approximation. Of all the techniques to be presented here, successive approximations most closely </context>
</contexts>
<marker>Salomaa, 1973</marker>
<rawString>Salomaa, A. 1973 Formal Languages. Academic Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis,</title>
<date>1970</date>
<journal>CACM</journal>
<pages>13--10</pages>
<contexts>
<context position="34244" citStr="Woods 1970" startWordPosition="5905" endWordPosition="5906">adj 1 + adj adj+ 2 1â€”adj 1â€”adj 1â€”adj adj .3 = 1 adj + adj.2 â€” = E adjn 1â€”adj Grammars like ADJS will sometimes be referred to as a step, by analogy to a unit step function in electrical engineering. 8. Computing the Power Series from the ATN This section will re-derive the power series for the unit step grammar directly from the ATN representation by treating the networks as flow graphs (Oppenheim 1975). The graph transformations presented here are directly analogous to the algebraic simplifications employed in the previous section. First we translate the grammar into an ATN in the usual way (Woods 1970). (32) ADJS adj ADJS I A (33) ADJS: 0Cat adj Push ADJ Pop Jump This graph can be simplified by performing a compiler optimization call tail recursion (Church and Kaplan 1981 and references therein). This transformation replaces the final push arc with a jump: Jump Jump Tail recursion corresponds directly to the algebraic operations of moving the ADJS term to the left hand side, factoring out the ADJS, and dividing from both sides. Then we remove the top jump arc by series reduction. This step corresponds to multiplying by 1 since a jump arc is the ATN representation for the identity element un</context>
</contexts>
<marker>Woods, 1970</marker>
<rawString>Woods, W. 1970 Transition Network Grammars for Natural Language Analysis, CACM 13:10.</rawString>
</citation>
<citation valid="true">
<date>1982</date>
<journal>American Journal of Computational Linguistics,</journal>
<volume>8</volume>
<pages>3--4</pages>
<marker>1982</marker>
<rawString>American Journal of Computational Linguistics, Volume 8, Number 3-4, July-December 1982 149</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>