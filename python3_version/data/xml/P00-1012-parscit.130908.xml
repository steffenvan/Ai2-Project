<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004053">
<title confidence="0.9956175">
The order of prenominal adjectives
in natural language generation
</title>
<author confidence="0.968974">
Robert Malouf
</author>
<affiliation confidence="0.6949425">
Alfa Informatica
Rijksuniversiteit Groningen
</affiliation>
<address confidence="0.848924">
Postbus 716
9700 AS Groningen
The Netherlands
</address>
<email confidence="0.997003">
malouf@let.rug.nl
</email>
<sectionHeader confidence="0.99736" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999328">
The order of prenominal adjectival
modifiers in English is governed by
complex and difficult to describe con-
straints which straddle the boundary
between competence and performance.
This paper describes and compares
a number of statistical and machine
learning techniques for ordering se-
quences of adjectives in the context of
a natural language generation system.
</bodyText>
<sectionHeader confidence="0.965994" genericHeader="method">
1 The problem
</sectionHeader>
<bodyText confidence="0.999940260869566">
The question of robustness is a perennial prob-
lem for parsing systems. In order to be useful,
a parser must be able to accept a wide range of
input types, and must be able to gracefully deal
with dysfluencies, false starts, and other ungram-
matical input. In natural language generation, on
the other hand, robustness is not an issue in the
same way. While a tactical generator must be able
to deal with a wide range of semantic inputs, it
only needs to produce grammatical strings, and
the grammar writer can select in advance which
construction types will be considered grammati-
cal. However, it is important that a generator not
produce strings which are strictly speaking gram-
matical but for some reason unusual. This is a
particular problem for dialog systems which use
the same grammar for both parsing and genera-
tion. The looseness required for robust parsing
is in direct opposition to the tightness needed for
high quality generation.
One area where this tension shows itself clearly
is in the order of prenominal modifiers in English.
In principle, prenominal adjectives can, depend-
ing on context, occur in almost any order:
the large red American car
??the American red large car
*car American red the large
Some orders are more marked than others, but
none are strictly speaking ungrammatical. So, the
grammar should not put any strong constraints on
adjective order. For a generation system, how-
ever, it is important that sequences of adjectives
be produced in the ‘correct’ order. Any other or-
der will at best sound odd and at worst convey an
unintended meaning.
Unfortunately, while there are rules of thumb
for ordering adjectives, none lend themselves to a
computational implementation. For example, ad-
jectives denoting size do tend to precede adjec-
tives denoting color. However, these rules under-
specify the relative order for many pairs of adjec-
tives and are often difficult to apply in practice.
In this paper, we will discuss a number of statisti-
cal and machine learning approaches to automati-
cally extracting from large corpora the constraints
on the order of prenominal adjectives in English.
</bodyText>
<sectionHeader confidence="0.987721" genericHeader="method">
2 Word bigram model
</sectionHeader>
<bodyText confidence="0.96922835">
The problem of generating ordered sequences of
adjectives is an instance of the more general prob-
lem of selecting among a number of possible
outputs from a natural language generation sys-
tem. One approach to this more general problem,
taken by the ‘Nitrogen’ generator (Langkilde and
Knight, 1998a; Langkilde and Knight, 1998b),
takes advantage of standard statistical techniques
by generating a lattice of all possible strings given
a semantic representation as input and selecting
the most likely output using a bigram language
model.
Langkilde and Knight report that this strategy
yields good results for problems like generating
verb/object collocations and for selecting the cor-
rect morphological form of a word. It also should
be straightforwardly applicable to the more spe-
cific problem we are addressing here. To deter-
mine the correct order for a sequence of prenom-
inal adjectives, we can simply generate all possi-
ble orderings and choose the one with the high-
est probability. This has the advantage of reduc-
ing the problem of adjective ordering to the prob-
lem of estimating n-gram probabilities, some-
thing which is relatively well understood.
To test the effectiveness of this strategy, we
took as a dataset the first one million sentences
of the written portion of the British National Cor-
pus (Burnard, 1995).1 We held out a randomly se-
lected 10% of this dataset and constructed a back-
off bigram model from the remaining 90% using
the CMU-Cambridge statistical language model-
ing toolkit (Clarkson and Rosenfeld, 1997). We
then evaluated the model by extracting all se-
quences of two or more adjectives followed by
a noun from the held-out test data and counted
the number of such sequences for which the most
likely order was the actually observed order. Note
that while the model was constructed using the
entire training set, it was evaluated based on only
sequences of adjectives.
The results of this experiment were some-
what disappointing. Of 5,113 adjective sequences
found in the test data, the order was correctly pre-
dicted for only 3,864 for an overall prediction ac-
curacy of 75.57%. The apparent reason that this
method performs as poorly as it does for this par-
ticular problem is that sequences of adjectives are
relatively rare in written English. This is evi-
denced by the fact that in the test data only one se-
quence of adjectives was found for every twenty
sentences. With adjective sequences so rare, the
chances of finding information about any particu-
lar sequence of adjectives is extremely small. The
data is simply too sparse for this to be a reliable
method.
&apos;The relevant files were identified by the absence of the
&lt;settDesc&gt; (spoken text “setting description”) SGML tag
in the file header. Thanks to John Carroll for help in prepar-
ing the corpus.
</bodyText>
<sectionHeader confidence="0.978473" genericHeader="method">
3 The experiments
</sectionHeader>
<bodyText confidence="0.9997401">
Since Langkilde and Knight’s general approach
does not seem to be very effective in this particu-
lar case, we instead chose to pursue more focused
solutions to the problem of generating correctly
ordered sequences of prenominal adjectives. In
addition, at least one generation algorithm (Car-
roll et al., 1999) inserts adjectival modifiers in a
post-processing step. This makes it easy to in-
tegrate a distinct adjective-ordering module with
the rest of the generation system.
</bodyText>
<subsectionHeader confidence="0.999645">
3.1 The data
</subsectionHeader>
<bodyText confidence="0.99999175">
To evaluate various methods for ordering
prenominal adjectives, we first constructed a
dataset by taking all sequences of two or more
adjectives followed by a common noun in the 100
million tokens of written English in the British
National Corpus. From 247,032 sequences, we
produced 262,838 individual pairs of adjectives.
Among these pairs, there were 127,016 different
pair types, and 23,941 different adjective types.
For test purposes, we then randomly held out
10% of the pairs, and used the remaining 90% as
the training sample.
Before we look at the different methods for
predicting the order of adjective pairs, there are
two properties of this dataset which bear noting.
First, it is quite sparse. More than 76% of the
adjective pair types occur only once, and 49%
of the adjective types only occur once. Second,
we get no useful information about the syntag-
matic context in which a pair appears. The left-
hand context is almost always a determiner, and
including information about the modified head
noun would only make the data even sparser. This
lack of context makes this problem different from
other problems, such as part-of-speech tagging
and grapheme-to-phoneme conversion, for which
statistical and machine learning solutions have
been proposed.
</bodyText>
<subsectionHeader confidence="0.99955">
3.2 Direct evidence
</subsectionHeader>
<bodyText confidence="0.998143764705882">
The simplest strategy for ordering adjectives is
what Shaw and Hatzivassiloglou (1999) call the
direct evidence method. To order the pair {a,b},
count how many times the ordered sequences
(a,b) and (b,a) appear in the training data and
output the pair in the order which occurred more
often.
This method has the advantage of being con-
ceptually very simple, easy to implement, and
highly accurate for pairs of adjectives which ac-
tually appear in the training data. Applying this
method to the adjectives sequences taken from
the BNC yields better than 98% accuracy for
pairs that occurred in the training data. However,
since as we have seen, the majority of pairs occur
only once, the overall accuracy of this method is
59.72%, only slightly better than random guess-
ing. Fortunately, another strength of this method
is that it is easy to identify those pairs for which
it is likely to give the right result. This means
that one can fall back on another less accurate but
more general method for pairs which did not oc-
cur in the training data. In particular, if we ran-
domly assign an order to unseen pairs, we can cut
the error rate in half and raise the overall accuracy
to 78.28%.
It should be noted that the direct evidence
method as employed here is slightly different
from Shaw and Hatzivassiloglou’s: we simply
compare raw token counts and take the larger
value, while they applied a significance test to es-
timate the probability that a difference between
counts arose strictly by chance. Like one finds in
a trade-off between precision and recall, the use
of a significance test slightly improved the accu-
racy of the method for those pairs which it had
an opinion about, but also increased the number
of pairs which had to be randomly assigned an
order. As a result, the net impact of using a sig-
nificance test for the BNC data was a very slight
decrease in the overall prediction accuracy.
The direct evidence method is straightforward
to implement and gives impressive results for ap-
plications that involve a small number of frequent
adjectives which occur in all relevant combina-
tions in the training data. However, as a general
approach to ordering adjectives, it leaves quite
a bit to be desired. In order to overcome the
sparseness inherent to this kind of data, we need
a method which can generalize from the pairs
which occur in the training data to unseen pairs.
</bodyText>
<subsectionHeader confidence="0.985355">
3.3 Transitivity
</subsectionHeader>
<bodyText confidence="0.999656536585366">
One way to think of the direct evidence method is
to see that it defines a relation � on the set of En-
glish adjectives. Given two adjectives, if the or-
dered pair (a,b) appears in the training data more
often then the pair (b,a), then a � b. If the re-
verse is true, and (b,a) is found more often than
(a,b), then b � a. If neither order appears in the
training data, then neither a � b nor b � a and an
order must be randomly assigned.
Shaw and Hatzivassiloglou (1999) propose to
generalize the direct evidence method so that it
can apply to unseen pairs of adjectives by com-
puting the transitive closure of the ordering re-
lation �. That is, if a � c and c � b, we can
conclude that a � b. To take an example from
the BNC, the adjectives large and green never oc-
cur together in the training data, and so would
be assigned a random order by the direct evi-
dence method. However, the pairs (large,new)
and (new,green) occur fairly frequently. There-
fore, in the face of this evidence we can assign
this pair the order (large,green), which not coin-
cidently is the correct English word order.
The difficulty with applying the transitive clo-
sure method to any large dataset is that there of-
ten will be evidence for both orders of any given
pair. For instance, alongside the evidence sup-
porting the order (large,green), we also find the
pairs (green,byzantine), (byzantine,decorative),
and (decorative,new), which suggest the order
(green,large).
Intuitively, the evidence for the first order is
quite a bit stronger than the evidence for the sec-
ond. The first ordered pairs are more frequent, as
are the individual adjectives involved. To quan-
tify the relative strengths of these transitive in-
ferences, Shaw and Hatzivassiloglou (1999) pro-
pose to assign a weight to each link. Say the order
(a,b) occurs m times and the pair {a,b} occurs n
times in total. Then the weight of the pair a —* b
is:
</bodyText>
<equation confidence="0.963744">
n 1
n n
∑ k 2
k=m
</equation>
<bodyText confidence="0.999961333333334">
This weight decreases as the probability that the
observed order did not occur strictly by chance
increases. This way, the problem of finding the
order best supported by the evidence can be stated
as a general shortest path problem: to find the pre-
ferred order for {a,b}, find the sum of the weights
of the pairs in the lowest-weighted path from a to
b and from b to a and choose whichever is lower.
Using this method, Shaw and Hatzivassiloglou
report predictions ranging from 81% to 95% ac-
curacy on small, domain specific samples. How-
ever, they note that the results are very domain-
</bodyText>
<equation confidence="0.8396425">
1−
−log
</equation>
<bodyText confidence="0.999664307692308">
specific. Applying a graph trained on one domain
to a text from another another generally gives
very poor results, ranging from 54% to 58% accu-
racy. Applying this method to the BNC data gives
83.91% accuracy, in line with Shaw and Hatzivas-
siloglou’s results and considerably better than the
direct evidence method. However, applying the
method is computationally a bit expensive. Like
the direct evidence method, it requires storing ev-
ery pair of adjectives found in the training data
along with its frequency. In addition, it also re-
quires solving the all-pairs shortest path problem,
for which common algorithms run in O(n3) time.
</bodyText>
<subsectionHeader confidence="0.952764">
3.4 Adjective bigrams
</subsectionHeader>
<bodyText confidence="0.98865268">
Another way to look at the direct evidence
method is as a comparison between two proba-
bilities. Given an adjective pair {a,b}, we com-
pare the number of times we observed the order
(a,b) to the number of times we observed the or-
der (b,a). Dividing each of these counts by the
total number of times {a,b} occurred gives us the
maximum likelihood estimate of the probabilities
P((a,b)|{a,b}) and P((b,a)|{a,b}).
Looking at it this way, it should be clear why
the direct evidence method does not work well, as
maximum likelihood estimation of bigram proba-
bilities is well known to fail in the face of sparse
data. It should also be clear how we might im-
prove the direct evidence method. Using the same
strategy as described in section 2, we constructed
a back-off bigram model of adjective pairs, again
using the CMU-Cambridge toolkit. Since this
model was constructed using only data specifi-
cally about adjective sequences, the relative in-
frequency of such sequences does not degrade its
performance. Therefore, while the word bigram
model gave an accuracy of only 75.57%, the ad-
jective bigram model yields an overall prediction
accuracy of 88.02% for the BNC data.
</bodyText>
<subsectionHeader confidence="0.638949">
3.5 Memory-based learning
</subsectionHeader>
<bodyText confidence="0.999781352380952">
An important property of the direct evidence
method for ordering adjectives is that it requires
storing all of the adjective pairs observed in the
training data. In this respect, the direct evidence
method can be thought of as a kind of memory-
based learning.
Memory-based (also known as lazy, near-
est neighbor, instance-based, or case-based) ap-
proaches to classification work by storing all of
the instances in the training data, along with their
classes. To classify a new instance, the store of
previously seen instances is searched to find those
instances which most resemble the new instance
with respect to some similarity metric. The new
instance is then assigned a class based on the ma-
jority class of its nearest neighbors in the space of
previously seen instances.
To make the comparison between the direct
evidence method and memory-based learning
clearer, we can frame the problem of adjective or-
dering as a classification problem. Given an un-
ordered pair {a,b}, we can assign it some canon-
ical order to get an instance ab. Then, if a pre-
cedes b more often than b precedes a in the train-
ing data, we assign the instance ab to the class
a � b. Otherwise, we assign it to the class b � a.
Seen as a solution to a classification problem,
the direct evidence method then is an application
of memory-based learning where the chosen sim-
ilarity metric is strict identity. As with the inter-
pretation of the direct evidence method explored
in the previous section, this view both reveals a
reason why the method is not very effective and
also indicates a direction which can be taken to
improve it. By requiring the new instance to be
identical to a previously seen instance in order to
classify it, the direct evidence method is unable to
generalize from seen pairs to unseen pairs. There-
fore, to improve the method, we need a more ap-
propriate similarity metric that allows the classi-
fier to get information from previously seen pairs
which are relevant to but not identical to new un-
seen pairs.
Following the conventional linguistic wisdom
(Quirk et al., 1985, e.g.), this similarity metric
should pick out adjectives which belong to the
same semantic class. Unfortunately, for many
adjectives this information is difficult or impos-
sible to come by. Machine readable dictionar-
ies and lexical databases such as WordNet (Fell-
baum, 1998) do provide some information about
semantic classes. However, the semantic classifi-
cation in a lexical database may not make exactly
the distinctions required for predicting adjective
order. More seriously, available lexical databases
are by necessity limited to a relatively small num-
ber of words, of which a relatively small fraction
are adjectives. In practice, the available sources
of semantic information only provide semantic
classifications for fairly common adjectives, and
these are precisely the adjectives which are found
frequently in the training data and so for which
semantic information is least necessary.
While we do not reliably have access to the
meaning of an adjective, we do always have ac-
cess to its form. And, fortunately, for many of
the cases in which the direct evidence method
fails, finding a previously seen pair of adjec-
tives with a similar form has the effect of find-
ing a pair with a similar meaning. For ex-
ample, suppose we want to order the adjective
pair {21-year-old,Armenian}. If this pair ap-
pears in the training data, then the previous oc-
currences of this pair will be used to predict
the order and the method reduces to direct ev-
idence. If, on the other hand, that particu-
lar pair did not appear in the training data, we
can base the classification on previously seen
pairs with a similar form. In this way, we
may find pairs like {73-year-old,Colombian} and
{44-year-old,Norwegian}, which have more or
less the same distribution as the target pair.
To test the effectiveness of a form-based sim-
ilarity metric, we encoded each adjective pair ab
as a vector of 16 features (the last 8 characters
of a and the last 8 characters of b) and a class
a ≺ b or b ≺ a. Constructing the instance base
and testing the classification was performed using
the TiMBL 3.0 (Daelemans et al., 2000) memory-
based learning system. Instances to be classified
were compared to previously seen instances by
counting the number of feature values that the two
instances had in common.
In computing the similarity score, features
were weighted by their information gain, an in-
formation theoretic measure of the relevance of a
feature for determining the correct classification
(Quinlan, 1986; Daelemans and van den Bosch,
1992). This weighting reduces the sensitivity of
memory based learning to the presence of irrele-
vant features.
Given the probability pi of finding each class
i in the instance base D, we can compute the en-
tropy H(D), a measure of the amount of uncer-
tainty in D:
</bodyText>
<equation confidence="0.8778075">
H(D) = −∑ pi log2 pi
pi
</equation>
<bodyText confidence="0.999585">
In the case of the adjective ordering data, there
are two classes a ≺ b and b ≺ a, each of which
occurs with a probability of roughly 0.5, so the
entropy of the instance base is close to 1 bit. We
can also compute the entropy of a feature f which
takes values V as the weighted sum of the entropy
of each of the values V:
</bodyText>
<equation confidence="0.97323">
H(Df) = ∑
vi∈V H(Df=vi)|Df =vi|
|D|
</equation>
<bodyText confidence="0.9977068">
Here H(Df=vi) is the entropy of subset of the in-
stance base which has value vi for feature f. The
information gain of a feature then is simply the
difference between the total entropy of the in-
stance base and the entropy of a single feature:
</bodyText>
<equation confidence="0.638865">
G(D, f) = H(D) −H(Df)
</equation>
<bodyText confidence="0.9999834">
The information gain G(D, f) is the reduction in
uncertainty in D we expect to achieve by learning
the value of the feature f. In other words, know-
ing the value of a feature with a higher G gets us
closer on average to knowing the class of an in-
stance than knowing the value of a feature with a
lower G does.
The similarity Abetween two instances then is
the number of feature values they have in com-
mon, weighted by the information gain:
</bodyText>
<equation confidence="0.987094333333333">
n
A(X,Y) = ∑ G(D,i)S(xi,yi)
i=1
</equation>
<bodyText confidence="0.884006428571429">
where:
� 1 if xi = yi
S(xi,yi) = 0 otherwise
Classification was based on the five training in-
stances most similar to the instance to be classi-
fied, and produced an overall prediction accuracy
of 89.34% for the BNC data.
</bodyText>
<subsectionHeader confidence="0.998465">
3.6 Positional probabilities
</subsectionHeader>
<bodyText confidence="0.999786074074074">
One difficulty faced by each of the methods de-
scribed so far is that they all to one degree or an-
other depend on finding particular pairs of adjec-
tives. For example, in order for the direct evi-
dence method to assign an order to a pair of ad-
jectives like {blue, large}, this specific pair must
have appeared in the training data. If not, an or-
der will have to be assigned randomly, even if
the individual adjectives blue and large appear
quite frequently in combination with a wide vari-
ety of other adjectives. Both the adjective bigram
method and the memory-based learning method
reduce this dependency on pairs to a certain ex-
tent, but these methods still suffer from the fact
that even for common adjectives one is much less
likely to find a specific pair in the training data
than to find some pair of which a specific adjec-
tive is a member.
Recall that the adjective bigram method
depended on estimating the probabilities
P((a,b)J{a,b}) and P((b,a)J{a,b}). Suppose we
now assume that the probability of a particular
adjective appearing first in a sequence depends
only on that adjective, and not the the other ad-
jectives in the sequence. We can easily estimate
the probability that if an adjective pair includes
some given adjective a, then that adjective occurs
first (let us call that P((a,x)J{a,x})) by looking
at each pair in the training data that includes
that adjective a. Then, given the assumption of
independence, the probability P((a,b)J{a,b})
is simply the product of P((a,x)J{a,x}) and
P((x,b)J{b,x}). Taking the most likely order
for a pair of adjectives using this alternative
method for estimating P((a,b)J{a,b}) and
P((a,b)J{a,b}) gives quite good results: a
prediction accuracy of 89.73% for the BNC data.
At first glance, the effectiveness of this method
may be surprising since it is based on an indepen-
dence assumption which common sense indicates
must not be true. However, to order a pair of ad-
jectives, this method brings to bear information
from all the previously seen pairs which include
either of adjectives in the pair in question. Since
it makes much more effective use of the train-
ing data, it can nevertheless achieve high accu-
racy. This method also has the advantage of be-
ing computationally quite simple. Applying this
method requires only one easy-to-calculate value
be stored for each possible adjective. Compared
to the other methods, which require at a mini-
mum that all of the training data be available dur-
ing classification, this represents a considerable
resource savings.
</bodyText>
<subsectionHeader confidence="0.987945">
3.7 Combined method
</subsectionHeader>
<bodyText confidence="0.999979095238095">
The two highest scoring methods, using memory-
based learning and positional probability, perform
similarly, and from the point of view of accuracy
there is little to recommend one method over the
other. However, it is interesting to note that the er-
rors made by the two methods do not completely
overlap: while either of the methods gives the
right answer for about 89% of the test data, one
of the two is right 95.00% of the time. This in-
dicates that a method which combined the infor-
mation used by the memory-based learning and
positional probability methods ought to be able
to perform better than either one individually.
To test this possibility, we added two new fea-
tures to the representation described in section
3.5. Besides information about the morphological
form of the adjectives in the pair, we also included
the positional probabilities P((a,x)J{a,x}) and
P((b,x)J{b,x}) as real-valued features. For nu-
meric features, the similarity metric Δ is com-
puted using the scaled difference between the val-
</bodyText>
<equation confidence="0.562096333333333">
ues:
xi −yi
δ(xi,yi) =maxi − mini
</equation>
<bodyText confidence="0.9982228">
Repeating the MBL experiment with these two
additional features yields 91.85% accuracy for
the BNC data, a 24% reduction in error rate over
purely morphological MBL with only a modest
increase in resource requirements.
</bodyText>
<sectionHeader confidence="0.998326" genericHeader="method">
4 Future directions
</sectionHeader>
<bodyText confidence="0.999887740740741">
To get an idea of what the upper bound on ac-
curacy is for this task, we tried applying the di-
rect evidence method trained on both the train-
ing data and the held-out test data. This gave
an accuracy of approximately 99%, which means
that 1% of the pairs in the corpus are in the
‘wrong’ order. For an even larger percentage of
pairs either order is acceptable, so an evaluation
procedure which assumes that the observed or-
der is the only correct order will underestimate
the classification accuracy. Native speaker intu-
itions about infrequently-occurring adjectives are
not very strong, so it is difficult to estimate what
fraction of adjective pairs in the corpus are ac-
tually unordered. However, it should be clear
that even a perfect method for ordering adjectives
would score well below 100% given the experi-
mental set-up described here.
While the combined MBL method achieves
reasonably good results even given the limitations
of the evaluation method, there is still clearly
room for improvement. Future work will pur-
sue at least two directions for improving the re-
sults. First, while semantic information is not
available for all adjectives, it is clearly available
for some. Furthermore, any realistic dialog sys-
tem would make use of some limited vocabulary
</bodyText>
<table confidence="0.9998688">
Direct evidence 78.28%
Adjective bigrams 88.02%
MBL (morphological) 89.34% (*)
Positional probabilities 89.73% (*)
MBL (combined) 91.85%
</table>
<tableCaption confidence="0.784778666666667">
Table 1: Summary of results. With the exception
of the starred values, all differences are statisti-
cally significant (p &lt; 0.005)
</tableCaption>
<bodyText confidence="0.99983780952381">
for which semantic information would be avail-
able. More generally, distributional clustering
techniques (Sch¨utze, 1992; Pereira et al., 1993)
could be applied to extract semantic classes from
the corpus itself. Since the constraints on adjec-
tive ordering in English depend largely on seman-
tic classes, the addition of semantic information
to the model ought to improve the results.
The second area where the methods described
here could be improved is in the way that multi-
ple information sources are integrated. The tech-
nique method described in section 3.7 is a fairly
crude method for combining frequency informa-
tion with symbolic data. It would be worthwhile
to investigate applying some of the more sophis-
ticated ensemble learning techniques which have
been proposed in the literature (Dietterich, 1997).
In particular, boosting (Schapire, 1999; Abney et
al., 1999) offers the possibility of achieving high
accuracy from a collection of classifiers which in-
dividually perform quite poorly.
</bodyText>
<sectionHeader confidence="0.999301" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.99997852">
In this paper, we have presented the results of ap-
plying a number of statistical and machine learn-
ing techniques to the problem of predicting the
order of prenominal adjectives in English. The
scores for each of the methods are summarized in
table 1. The best methods yield around 90% ac-
curacy, better than the best previously published
methods when applied to the broad domain data
of the British National Corpus. Note that Mc-
Nemar’s test (Dietterich, 1998) confirms the sig-
nificance of all of the differences reflected here
(with p &lt; 0.005) with the exception of the differ-
ence between purely morphological MBL and the
method based on positional probabilities.
From this investigation, we can draw some ad-
ditional conclusions. First, a solution specific
to adjective ordering works better than a gen-
eral probabilistic filter. Second, machine learn-
ing techniques can be applied to a different kind
of linguistic problem with some success, even in
the absence of syntagmatic context, and can be
used to augment a hand-built competence gram-
mar. Third, in some cases statistical and memory
based learning techniques can be combined in a
way that performs better than either individually.
</bodyText>
<sectionHeader confidence="0.999633" genericHeader="acknowledgments">
6 Acknowledgments
</sectionHeader>
<bodyText confidence="0.987014875">
I am indebted to Carol Bleyle, John Carroll, Ann
Copestake, Guido Minnen, Miles Osborne, au-
diences at the University of Groningen and the
University of Sussex, and three anonymous re-
viewers for their comments and suggestions. The
work described here was supported by the School
of Behavioral and Cognitive Neurosciences at the
University of Groningen.
</bodyText>
<sectionHeader confidence="0.998961" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999929583333334">
Steven Abney, Robert E. Schapire, and Yoram Singer.
1999. Boosting applied to tagging and PP attach-
ment. In Proceedings of the Joint SIGDAT Confer-
ence on Empirical Methods in Natural Language
Processing and Very Large Corpora.
Lou Burnard. 1995. Users reference guide for the
British National Corpus, version 1.0. Technical re-
port, Oxford University Computing Services.
John Carroll, Ann Copestake, Dan Flickinger, and
Victor Poznanski. 1999. An efficient chart gen-
erator for (semi-)lexicalist grammars. In Proceed-
ings of the 7th European Workshop on Natural
Language Generation (EWNLG’99), pages 86–95,
Toulouse.
Philip R. Clarkson and Ronald Rosenfeld. 1997.
Statistical language modeling using the CMU-
Cambridge Toolkit. In G. Kokkinakis, N. Fako-
takis, and E. Dermatas, editors, Eurospeech ’97
Proceedings, pages 2707–2710.
Walter Daelemans and Antal van den Bosch. 1992.
Generalization performance of backpropagation
learning on a syllabification task. In M.F.J.
Drossaers and A. Nijholt, editors, Proceedings of
TWLT3: Connectionism and Natural Language
Processing, Enschede. University of Twente.
Walter Daelemans, Jakub Zavrel, Ko van der Sloot,
and Antal van den Bosch. 2000. TiMBL:
Tilburg memory based learner, version 3.0, refer-
ence guide. ILK Technical Report 00-01, Tilburg
University. Available from http://ilk.kub.nl/
~ilk/papers/ilk0001.ps.gz.
Thomas G. Dietterich. 1997. Machine learning
research: four current directions. AI Magazine,
18:97–136.
Thomas G. Dietterich. 1998. Approximate statistical
tests for comparing supervised classification learn-
ing algorithms. Neural Computation, 10(7):1895–
1924.
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press, Cambridge,
MA.
Irene Langkilde and Kevin Knight. 1998a. Gener-
ation that exploits corpus-based statistical knowl-
edge. In Proceedings of 36th Annual Meeting of
the Association for Computational Linguistics and
17th International Conference on Computational
Linguistics, pages 704–710, Montreal.
Irene Langkilde and Kevin Knight. 1998b. The practi-
cal value of n-grams in generation. In Proceedings
of the International Natural Language Generation
Workshop, Niagara-on-the-Lake, Ontario.
Fernando Pereira, Naftali Tishby, and Lilian Lee.
1993. Distributional clustering of English words.
In Proceedings of the 30th annual meeting of the
Association for Computational Linguistics, pages
183–190.
J. Ross Quinlan. 1986. Induction of decision trees.
Machine Learning, 1:81–106.
Randolf Quirk, Sidney Greenbaum, Geoffrey Leech,
and Jan Svartvik. 1985. A Comprehensive Gram-
mar of the English Language. Longman, London.
Robert E. Schapire. 1999. A brief introduction to
boosting. In Proceedings of the Sixteenth Interna-
tional Joint Conference on Artificial Intelligence.
Hinrich Sch¨utze. 1992. Dimensions of meaning.
In Proceedings of Supercomputing, pages 787–796,
Minneapolis.
James Shaw and Vasileios Hatzivassiloglou. 1999.
Ordering among premodifiers. In Proceedings of
the 37th Annual Meeting of the Association for
Computational Linguistics, pages 135–143, Col-
lege Park, Maryland.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000103">
<title confidence="0.9970565">The order of prenominal adjectives in natural language generation</title>
<author confidence="0.999872">Robert Malouf</author>
<affiliation confidence="0.932471">Alfa Informatica Rijksuniversiteit Groningen</affiliation>
<address confidence="0.977846666666667">Postbus 716 9700 AS Groningen The Netherlands</address>
<email confidence="0.995984">malouf@let.rug.nl</email>
<abstract confidence="0.999601869636966">The order of prenominal adjectival modifiers in English is governed by complex and difficult to describe constraints which straddle the boundary between competence and performance. This paper describes and compares a number of statistical and machine learning techniques for ordering sequences of adjectives in the context of a natural language generation system. 1 The problem The question of robustness is a perennial problem for parsing systems. In order to be useful, a parser must be able to accept a wide range of input types, and must be able to gracefully deal with dysfluencies, false starts, and other ungrammatical input. In natural language generation, on the other hand, robustness is not an issue in the same way. While a tactical generator must be able to deal with a wide range of semantic inputs, it only needs to produce grammatical strings, and the grammar writer can select in advance which construction types will be considered grammatical. However, it is important that a generator not produce strings which are strictly speaking grammatical but for some reason unusual. This is a particular problem for dialog systems which use the same grammar for both parsing and generation. The looseness required for robust parsing is in direct opposition to the tightness needed for high quality generation. One area where this tension shows itself clearly is in the order of prenominal modifiers in English. In principle, prenominal adjectives can, depending on context, occur in almost any order: the large red American car ??the American red large car *car American red the large Some orders are more marked than others, but none are strictly speaking ungrammatical. So, the grammar should not put any strong constraints on adjective order. For a generation system, however, it is important that sequences of adjectives be produced in the ‘correct’ order. Any other order will at best sound odd and at worst convey an unintended meaning. Unfortunately, while there are rules of thumb for ordering adjectives, none lend themselves to a computational implementation. For example, adjectives denoting size do tend to precede adjectives denoting color. However, these rules underspecify the relative order for many pairs of adjectives and are often difficult to apply in practice. In this paper, we will discuss a number of statistical and machine learning approaches to automatically extracting from large corpora the constraints on the order of prenominal adjectives in English. 2 Word bigram model The problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system. One approach to this more general problem, taken by the ‘Nitrogen’ generator (Langkilde and Knight, 1998a; Langkilde and Knight, 1998b), takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model. Langkilde and Knight report that this strategy yields good results for problems like generating verb/object collocations and for selecting the correct morphological form of a word. It also should be straightforwardly applicable to the more specific problem we are addressing here. To determine the correct order for a sequence of prenominal adjectives, we can simply generate all possible orderings and choose the one with the highest probability. This has the advantage of reducing the problem of adjective ordering to the probof estimating probabilities, something which is relatively well understood. To test the effectiveness of this strategy, we took as a dataset the first one million sentences of the written portion of the British National Cor- (Burnard, We held out a randomly selected 10% of this dataset and constructed a backoff bigram model from the remaining 90% using the CMU-Cambridge statistical language modeling toolkit (Clarkson and Rosenfeld, 1997). We then evaluated the model by extracting all sequences of two or more adjectives followed by a noun from the held-out test data and counted the number of such sequences for which the most likely order was the actually observed order. Note that while the model was constructed using the entire training set, it was evaluated based on only sequences of adjectives. The results of this experiment were somewhat disappointing. Of 5,113 adjective sequences found in the test data, the order was correctly predicted for only 3,864 for an overall prediction acof The apparent reason that this method performs as poorly as it does for this particular problem is that sequences of adjectives are relatively rare in written English. This is evidenced by the fact that in the test data only one sequence of adjectives was found for every twenty sentences. With adjective sequences so rare, the of finding information about any particuof adjectives is extremely small. The data is simply too sparse for this to be a reliable method. relevant files were identified by the absence of the text “setting description”) SGML tag in the file header. Thanks to John Carroll for help in preparing the corpus. 3 The experiments Since Langkilde and Knight’s general approach does not seem to be very effective in this particular case, we instead chose to pursue more focused solutions to the problem of generating correctly ordered sequences of prenominal adjectives. In addition, at least one generation algorithm (Carroll et al., 1999) inserts adjectival modifiers in a post-processing step. This makes it easy to integrate a distinct adjective-ordering module with the rest of the generation system. 3.1 The data To evaluate various methods for ordering prenominal adjectives, we first constructed a dataset by taking all sequences of two or more adjectives followed by a common noun in the 100 million tokens of written English in the British Corpus. From sequences, we individual pairs of adjectives. these pairs, there were different types, and different adjective types. For test purposes, we then randomly held out 10% of the pairs, and used the remaining 90% as the training sample. Before we look at the different methods for predicting the order of adjective pairs, there are two properties of this dataset which bear noting. First, it is quite sparse. More than 76% of the adjective pair types occur only once, and 49% of the adjective types only occur once. Second, we get no useful information about the syntagmatic context in which a pair appears. The lefthand context is almost always a determiner, and including information about the modified head noun would only make the data even sparser. This lack of context makes this problem different from other problems, such as part-of-speech tagging and grapheme-to-phoneme conversion, for which statistical and machine learning solutions have been proposed. 3.2 Direct evidence The simplest strategy for ordering adjectives is what Shaw and Hatzivassiloglou (1999) call the evidence To order the pair count how many times the ordered sequences in the training data and output the pair in the order which occurred more often. This method has the advantage of being conceptually very simple, easy to implement, and highly accurate for pairs of adjectives which actually appear in the training data. Applying this method to the adjectives sequences taken from the BNC yields better than 98% accuracy for pairs that occurred in the training data. However, since as we have seen, the majority of pairs occur only once, the overall accuracy of this method is only slightly better than random guessing. Fortunately, another strength of this method is that it is easy to identify those pairs for which it is likely to give the right result. This means that one can fall back on another less accurate but more general method for pairs which did not occur in the training data. In particular, if we randomly assign an order to unseen pairs, we can cut the error rate in half and raise the overall accuracy It should be noted that the direct evidence method as employed here is slightly different from Shaw and Hatzivassiloglou’s: we simply compare raw token counts and take the larger value, while they applied a significance test to estimate the probability that a difference between counts arose strictly by chance. Like one finds in a trade-off between precision and recall, the use of a significance test slightly improved the accuracy of the method for those pairs which it had an opinion about, but also increased the number of pairs which had to be randomly assigned an order. As a result, the net impact of using a significance test for the BNC data was a very slight decrease in the overall prediction accuracy. The direct evidence method is straightforward to implement and gives impressive results for applications that involve a small number of frequent adjectives which occur in all relevant combinations in the training data. However, as a general approach to ordering adjectives, it leaves quite a bit to be desired. In order to overcome the sparseness inherent to this kind of data, we need a method which can generalize from the pairs which occur in the training data to unseen pairs. 3.3 Transitivity One way to think of the direct evidence method is see that it defines a relation the set of English adjectives. Given two adjectives, if the orpair in the training data more then the pair then If the reis true, and found more often than then If neither order appears in the data, then neither an order must be randomly assigned. Shaw and Hatzivassiloglou (1999) propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by comthe closure the ordering re- That is, if we can that To take an example from BNC, the adjectives occur together in the training data, and so would be assigned a random order by the direct evimethod. However, the pairs fairly frequently. Therefore, in the face of this evidence we can assign pair the order which not coincidently is the correct English word order. The difficulty with applying the transitive closure method to any large dataset is that there often will be evidence for both orders of any given pair. For instance, alongside the evidence supthe order we also find the which suggest the order Intuitively, the evidence for the first order is quite a bit stronger than the evidence for the second. The first ordered pairs are more frequent, as are the individual adjectives involved. To quantify the relative strengths of these transitive inferences, Shaw and Hatzivassiloglou (1999) propose to assign a weight to each link. Say the order and the pair in total. Then the weight of the pair is: n n This weight decreases as the probability that the observed order did not occur strictly by chance increases. This way, the problem of finding the order best supported by the evidence can be stated as a general shortest path problem: to find the preorder for find the sum of the weights the pairs in the lowest-weighted path from from choose whichever is lower. Using this method, Shaw and Hatzivassiloglou report predictions ranging from 81% to 95% accuracy on small, domain specific samples. Howthey note that the results are very domainspecific. Applying a graph trained on one domain to a text from another another generally gives very poor results, ranging from 54% to 58% accuracy. Applying this method to the BNC data gives accuracy, in line with Shaw and Hatzivassiloglou’s results and considerably better than the direct evidence method. However, applying the method is computationally a bit expensive. Like the direct evidence method, it requires storing every pair of adjectives found in the training data along with its frequency. In addition, it also requires solving the all-pairs shortest path problem, which common algorithms run in 3.4 Adjective bigrams Another way to look at the direct evidence method is as a comparison between two proba- Given an adjective pair we compare the number of times we observed the order the number of times we observed the or- Dividing each of these counts by the number of times gives us the maximum likelihood estimate of the probabilities Looking at it this way, it should be clear why the direct evidence method does not work well, as maximum likelihood estimation of bigram probabilities is well known to fail in the face of sparse data. It should also be clear how we might improve the direct evidence method. Using the same strategy as described in section 2, we constructed a back-off bigram model of adjective pairs, again using the CMU-Cambridge toolkit. Since this model was constructed using only data specifically about adjective sequences, the relative infrequency of such sequences does not degrade its performance. Therefore, while the word bigram gave an accuracy of only the adjective bigram model yields an overall prediction of for the BNC data. 3.5 Memory-based learning An important property of the direct evidence method for ordering adjectives is that it requires storing all of the adjective pairs observed in the training data. In this respect, the direct evidence method can be thought of as a kind of memorybased learning. Memory-based (also known as lazy, nearest neighbor, instance-based, or case-based) approaches to classification work by storing all of the instances in the training data, along with their classes. To classify a new instance, the store of previously seen instances is searched to find those instances which most resemble the new instance with respect to some similarity metric. The new instance is then assigned a class based on the majority class of its nearest neighbors in the space of previously seen instances. To make the comparison between the direct evidence method and memory-based learning clearer, we can frame the problem of adjective ordering as a classification problem. Given an unpair we can assign it some canonorder to get an instance Then, if preoften than the traindata, we assign the instance the class Otherwise, we assign it to the class Seen as a solution to a classification problem, the direct evidence method then is an application of memory-based learning where the chosen similarity metric is strict identity. As with the interpretation of the direct evidence method explored in the previous section, this view both reveals a reason why the method is not very effective and also indicates a direction which can be taken to improve it. By requiring the new instance to be identical to a previously seen instance in order to classify it, the direct evidence method is unable to generalize from seen pairs to unseen pairs. Therefore, to improve the method, we need a more appropriate similarity metric that allows the classifier to get information from previously seen pairs which are relevant to but not identical to new unseen pairs. Following the conventional linguistic wisdom (Quirk et al., 1985, e.g.), this similarity metric should pick out adjectives which belong to the same semantic class. Unfortunately, for many adjectives this information is difficult or impossible to come by. Machine readable dictionaries and lexical databases such as WordNet (Fellbaum, 1998) do provide some information about semantic classes. However, the semantic classification in a lexical database may not make exactly the distinctions required for predicting adjective order. More seriously, available lexical databases are by necessity limited to a relatively small number of words, of which a relatively small fraction are adjectives. In practice, the available sources of semantic information only provide semantic classifications for fairly common adjectives, and these are precisely the adjectives which are found frequently in the training data and so for which semantic information is least necessary. While we do not reliably have access to the meaning of an adjective, we do always have access to its form. And, fortunately, for many of the cases in which the direct evidence method fails, finding a previously seen pair of adjectives with a similar form has the effect of finding a pair with a similar meaning. For example, suppose we want to order the adjective If this pair appears in the training data, then the previous occurrences of this pair will be used to predict the order and the method reduces to direct evidence. If, on the other hand, that particular pair did not appear in the training data, we can base the classification on previously seen pairs with a similar form. In this way, we find pairs like which have more or less the same distribution as the target pair. To test the effectiveness of a form-based simmetric, we encoded each adjective pair as a vector of 16 features (the last 8 characters the last 8 characters of and a class Constructing the instance base and testing the classification was performed using TiMBL (Daelemans et al., 2000) memorybased learning system. Instances to be classified were compared to previously seen instances by counting the number of feature values that the two instances had in common. In computing the similarity score, features were weighted by their information gain, an information theoretic measure of the relevance of a feature for determining the correct classification (Quinlan, 1986; Daelemans and van den Bosch, 1992). This weighting reduces the sensitivity of memory based learning to the presence of irrelevant features. the probability finding each class the instance base we can compute the ena measure of the amount of uncerin = In the case of the adjective ordering data, there two classes each of which with a probability of roughly so the entropy of the instance base is close to 1 bit. We also compute the entropy of a feature values the weighted sum of the entropy each of the values = is the entropy of subset of the inbase which has value feature The information gain of a feature then is simply the difference between the total entropy of the instance base and the entropy of a single feature: = information gain the reduction in in expect to achieve by learning value of the feature In other words, knowthe value of a feature with a higher us closer on average to knowing the class of an instance than knowing the value of a feature with a similarity two instances then is the number of feature values they have in common, weighted by the information gain: n = where: if = otherwise Classification was based on the five training instances most similar to the instance to be classified, and produced an overall prediction accuracy for the BNC data. 3.6 Positional probabilities One difficulty faced by each of the methods described so far is that they all to one degree or another depend on finding particular pairs of adjectives. For example, in order for the direct evidence method to assign an order to a pair of adlike this specific pair must have appeared in the training data. If not, an order will have to be assigned randomly, even if individual adjectives quite frequently in combination with a wide variety of other adjectives. Both the adjective bigram method and the memory-based learning method reduce this dependency on pairs to a certain extent, but these methods still suffer from the fact that even for common adjectives one is much less likely to find a specific pair in the training data than to find some pair of which a specific adjective is a member. Recall that the adjective bigram method depended on estimating the probabilities Suppose we now assume that the probability of a particular adjective appearing first in a sequence depends only on that adjective, and not the the other adjectives in the sequence. We can easily estimate the probability that if an adjective pair includes given adjective then that adjective occurs (let us call that by looking at each pair in the training data that includes adjective Then, given the assumption of the probability simply the product of Taking the most likely order for a pair of adjectives using this alternative for estimating quite good results: a accuracy of for the BNC data. At first glance, the effectiveness of this method may be surprising since it is based on an independence assumption which common sense indicates must not be true. However, to order a pair of adjectives, this method brings to bear information from all the previously seen pairs which include either of adjectives in the pair in question. Since it makes much more effective use of the training data, it can nevertheless achieve high accuracy. This method also has the advantage of being computationally quite simple. Applying this method requires only one easy-to-calculate value be stored for each possible adjective. Compared to the other methods, which require at a minimum that all of the training data be available during classification, this represents a considerable resource savings. 3.7 Combined method The two highest scoring methods, using memorybased learning and positional probability, perform similarly, and from the point of view of accuracy there is little to recommend one method over the other. However, it is interesting to note that the errors made by the two methods do not completely overlap: while either of the methods gives the right answer for about 89% of the test data, one the two is right of the time. This indicates that a method which combined the information used by the memory-based learning and positional probability methods ought to be able to perform better than either one individually. To test this possibility, we added two new features to the representation described in section 3.5. Besides information about the morphological form of the adjectives in the pair, we also included positional probabilities real-valued features. For nufeatures, the similarity metric comusing the scaled difference between the values: Repeating the MBL experiment with these two features yields accuracy for the BNC data, a 24% reduction in error rate over purely morphological MBL with only a modest increase in resource requirements. 4 Future directions To get an idea of what the upper bound on accuracy is for this task, we tried applying the direct evidence method trained on both the training data and the held-out test data. This gave an accuracy of approximately 99%, which means that 1% of the pairs in the corpus are in the ‘wrong’ order. For an even larger percentage of pairs either order is acceptable, so an evaluation procedure which assumes that the observed order is the only correct order will underestimate the classification accuracy. Native speaker intuitions about infrequently-occurring adjectives are not very strong, so it is difficult to estimate what fraction of adjective pairs in the corpus are actually unordered. However, it should be clear that even a perfect method for ordering adjectives would score well below 100% given the experimental set-up described here. While the combined MBL method achieves reasonably good results even given the limitations of the evaluation method, there is still clearly room for improvement. Future work will pursue at least two directions for improving the results. First, while semantic information is not available for all adjectives, it is clearly available for some. Furthermore, any realistic dialog system would make use of some limited vocabulary Direct evidence Adjective bigrams MBL (morphological) (*) Positional probabilities (*) MBL (combined) Table 1: Summary of results. With the exception of the starred values, all differences are statistisignificant for which semantic information would be available. More generally, distributional clustering techniques (Sch¨utze, 1992; Pereira et al., 1993) could be applied to extract semantic classes from the corpus itself. Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results. The second area where the methods described here could be improved is in the way that multiple information sources are integrated. The technique method described in section 3.7 is a fairly crude method for combining frequency information with symbolic data. It would be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature (Dietterich, 1997). In particular, boosting (Schapire, 1999; Abney et al., 1999) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly. 5 Conclusion In this paper, we have presented the results of applying a number of statistical and machine learning techniques to the problem of predicting the order of prenominal adjectives in English. The scores for each of the methods are summarized in table 1. The best methods yield around 90% accuracy, better than the best previously published methods when applied to the broad domain data of the British National Corpus. Note that Mc- Nemar’s test (Dietterich, 1998) confirms the significance of all of the differences reflected here with the exception of the difference between purely morphological MBL and the method based on positional probabilities. From this investigation, we can draw some additional conclusions. First, a solution specific to adjective ordering works better than a general probabilistic filter. Second, machine learning techniques can be applied to a different kind of linguistic problem with some success, even in the absence of syntagmatic context, and can be used to augment a hand-built competence grammar. Third, in some cases statistical and memory based learning techniques can be combined in a way that performs better than either individually.</abstract>
<note confidence="0.8881915">6 Acknowledgments I am indebted to Carol Bleyle, John Carroll, Ann Copestake, Guido Minnen, Miles Osborne, audiences at the University of Groningen and the</note>
<affiliation confidence="0.367491">University of Sussex, and three anonymous reviewers for their comments and suggestions. The</affiliation>
<author confidence="0.25699">work described here was supported by the School</author>
<affiliation confidence="0.685679">of Behavioral and Cognitive Neurosciences at the University of Groningen.</affiliation>
<title confidence="0.850194">References</title>
<author confidence="0.872903">Steven Abney</author>
<author confidence="0.872903">Robert E Schapire</author>
<author confidence="0.872903">Yoram Singer</author>
<affiliation confidence="0.5358075">1999. Boosting applied to tagging and PP attach- In of the Joint SIGDAT Confer-</affiliation>
<title confidence="0.896894">ence on Empirical Methods in Natural Language and Very Large</title>
<author confidence="0.881252">Users reference guide for the</author>
<note confidence="0.72088448">British National Corpus, version 1.0. Technical report, Oxford University Computing Services. John Carroll, Ann Copestake, Dan Flickinger, and Victor Poznanski. 1999. An efficient chart genfor (semi-)lexicalist grammars. In Proceedings of the 7th European Workshop on Natural Generation pages 86–95, Toulouse. Philip R. Clarkson and Ronald Rosenfeld. 1997. Statistical language modeling using the CMU- Cambridge Toolkit. In G. Kokkinakis, N. Fakoand E. Dermatas, editors, ’97 pages 2707–2710. Walter Daelemans and Antal van den Bosch. 1992. Generalization performance of backpropagation learning on a syllabification task. In M.F.J. and A. Nijholt, editors, of TWLT3: Connectionism and Natural Language Enschede. University of Twente. Walter Daelemans, Jakub Zavrel, Ko van der Sloot, and Antal van den Bosch. 2000. TiMBL: Tilburg memory based learner, version 3.0, reference guide. ILK Technical Report 00-01, Tilburg Available from Thomas G. Dietterich. 1997. Machine learning</note>
<abstract confidence="0.817155115384615">four current directions. 18:97–136. Thomas G. Dietterich. 1998. Approximate statistical tests for comparing supervised classification learnalgorithms. 10(7):1895– 1924. Fellbaum, editor. 1998. An Elec- Lexical MIT Press, Cambridge, MA. Irene Langkilde and Kevin Knight. 1998a. Generation that exploits corpus-based statistical knowl- In of 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational pages 704–710, Montreal. Irene Langkilde and Kevin Knight. 1998b. The practivalue of in generation. In of the International Natural Language Generation Niagara-on-the-Lake, Ontario. Fernando Pereira, Naftali Tishby, and Lilian Lee. 1993. Distributional clustering of English words. of the 30th annual meeting of the for Computational pages 183–190. J. Ross Quinlan. 1986. Induction of decision trees. 1:81–106.</abstract>
<author confidence="0.933772">Comprehensive Gram-</author>
<affiliation confidence="0.358876">of the English Longman, London.</affiliation>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Abney</author>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>Boosting applied to tagging and PP attachment.</title>
<date>1999</date>
<booktitle>In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</booktitle>
<contexts>
<context position="26440" citStr="Abney et al., 1999" startWordPosition="4464" endWordPosition="4467">ing in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results. The second area where the methods described here could be improved is in the way that multiple information sources are integrated. The technique method described in section 3.7 is a fairly crude method for combining frequency information with symbolic data. It would be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature (Dietterich, 1997). In particular, boosting (Schapire, 1999; Abney et al., 1999) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly. 5 Conclusion In this paper, we have presented the results of applying a number of statistical and machine learning techniques to the problem of predicting the order of prenominal adjectives in English. The scores for each of the methods are summarized in table 1. The best methods yield around 90% accuracy, better than the best previously published methods when applied to the broad domain data of the British National Corpus. Note that McNemar’s test (Dietterich, 1998) con</context>
</contexts>
<marker>Abney, Schapire, Singer, 1999</marker>
<rawString>Steven Abney, Robert E. Schapire, and Yoram Singer. 1999. Boosting applied to tagging and PP attachment. In Proceedings of the Joint SIGDAT Conference on Empirical Methods in Natural Language Processing and Very Large Corpora.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lou Burnard</author>
</authors>
<title>Users reference guide for the British National Corpus, version 1.0.</title>
<date>1995</date>
<tech>Technical report,</tech>
<institution>Oxford University Computing Services.</institution>
<contexts>
<context position="4028" citStr="Burnard, 1995" startWordPosition="646" endWordPosition="647">rm of a word. It also should be straightforwardly applicable to the more specific problem we are addressing here. To determine the correct order for a sequence of prenominal adjectives, we can simply generate all possible orderings and choose the one with the highest probability. This has the advantage of reducing the problem of adjective ordering to the problem of estimating n-gram probabilities, something which is relatively well understood. To test the effectiveness of this strategy, we took as a dataset the first one million sentences of the written portion of the British National Corpus (Burnard, 1995).1 We held out a randomly selected 10% of this dataset and constructed a backoff bigram model from the remaining 90% using the CMU-Cambridge statistical language modeling toolkit (Clarkson and Rosenfeld, 1997). We then evaluated the model by extracting all sequences of two or more adjectives followed by a noun from the held-out test data and counted the number of such sequences for which the most likely order was the actually observed order. Note that while the model was constructed using the entire training set, it was evaluated based on only sequences of adjectives. The results of this exper</context>
</contexts>
<marker>Burnard, 1995</marker>
<rawString>Lou Burnard. 1995. Users reference guide for the British National Corpus, version 1.0. Technical report, Oxford University Computing Services.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Carroll</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
<author>Victor Poznanski</author>
</authors>
<title>An efficient chart generator for (semi-)lexicalist grammars.</title>
<date>1999</date>
<booktitle>In Proceedings of the 7th European Workshop on Natural Language Generation (EWNLG’99),</booktitle>
<pages>86--95</pages>
<location>Toulouse.</location>
<contexts>
<context position="5814" citStr="Carroll et al., 1999" startWordPosition="944" endWordPosition="948">uence of adjectives is extremely small. The data is simply too sparse for this to be a reliable method. &apos;The relevant files were identified by the absence of the &lt;settDesc&gt; (spoken text “setting description”) SGML tag in the file header. Thanks to John Carroll for help in preparing the corpus. 3 The experiments Since Langkilde and Knight’s general approach does not seem to be very effective in this particular case, we instead chose to pursue more focused solutions to the problem of generating correctly ordered sequences of prenominal adjectives. In addition, at least one generation algorithm (Carroll et al., 1999) inserts adjectival modifiers in a post-processing step. This makes it easy to integrate a distinct adjective-ordering module with the rest of the generation system. 3.1 The data To evaluate various methods for ordering prenominal adjectives, we first constructed a dataset by taking all sequences of two or more adjectives followed by a common noun in the 100 million tokens of written English in the British National Corpus. From 247,032 sequences, we produced 262,838 individual pairs of adjectives. Among these pairs, there were 127,016 different pair types, and 23,941 different adjective types.</context>
</contexts>
<marker>Carroll, Copestake, Flickinger, Poznanski, 1999</marker>
<rawString>John Carroll, Ann Copestake, Dan Flickinger, and Victor Poznanski. 1999. An efficient chart generator for (semi-)lexicalist grammars. In Proceedings of the 7th European Workshop on Natural Language Generation (EWNLG’99), pages 86–95, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip R Clarkson</author>
<author>Ronald Rosenfeld</author>
</authors>
<title>Statistical language modeling using the CMUCambridge Toolkit. In</title>
<date>1997</date>
<booktitle>Eurospeech ’97 Proceedings,</booktitle>
<pages>2707--2710</pages>
<editor>G. Kokkinakis, N. Fakotakis, and E. Dermatas, editors,</editor>
<contexts>
<context position="4237" citStr="Clarkson and Rosenfeld, 1997" startWordPosition="678" endWordPosition="681">imply generate all possible orderings and choose the one with the highest probability. This has the advantage of reducing the problem of adjective ordering to the problem of estimating n-gram probabilities, something which is relatively well understood. To test the effectiveness of this strategy, we took as a dataset the first one million sentences of the written portion of the British National Corpus (Burnard, 1995).1 We held out a randomly selected 10% of this dataset and constructed a backoff bigram model from the remaining 90% using the CMU-Cambridge statistical language modeling toolkit (Clarkson and Rosenfeld, 1997). We then evaluated the model by extracting all sequences of two or more adjectives followed by a noun from the held-out test data and counted the number of such sequences for which the most likely order was the actually observed order. Note that while the model was constructed using the entire training set, it was evaluated based on only sequences of adjectives. The results of this experiment were somewhat disappointing. Of 5,113 adjective sequences found in the test data, the order was correctly predicted for only 3,864 for an overall prediction accuracy of 75.57%. The apparent reason that t</context>
</contexts>
<marker>Clarkson, Rosenfeld, 1997</marker>
<rawString>Philip R. Clarkson and Ronald Rosenfeld. 1997. Statistical language modeling using the CMUCambridge Toolkit. In G. Kokkinakis, N. Fakotakis, and E. Dermatas, editors, Eurospeech ’97 Proceedings, pages 2707–2710.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Antal van den Bosch</author>
</authors>
<title>Generalization performance of backpropagation learning on a syllabification task.</title>
<date>1992</date>
<booktitle>Proceedings of TWLT3: Connectionism and Natural Language Processing,</booktitle>
<editor>In M.F.J. Drossaers and A. Nijholt, editors,</editor>
<institution>Enschede. University of Twente.</institution>
<marker>Daelemans, van den Bosch, 1992</marker>
<rawString>Walter Daelemans and Antal van den Bosch. 1992. Generalization performance of backpropagation learning on a syllabification task. In M.F.J. Drossaers and A. Nijholt, editors, Proceedings of TWLT3: Connectionism and Natural Language Processing, Enschede. University of Twente.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walter Daelemans</author>
<author>Jakub Zavrel</author>
<author>Ko van der Sloot</author>
<author>Antal van den Bosch</author>
</authors>
<title>TiMBL: Tilburg memory based learner, version 3.0, reference guide.</title>
<date>2000</date>
<tech>ILK Technical Report 00-01,</tech>
<institution>Tilburg University.</institution>
<note>Available from http://ilk.kub.nl/ ~ilk/papers/ilk0001.ps.gz.</note>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 2000</marker>
<rawString>Walter Daelemans, Jakub Zavrel, Ko van der Sloot, and Antal van den Bosch. 2000. TiMBL: Tilburg memory based learner, version 3.0, reference guide. ILK Technical Report 00-01, Tilburg University. Available from http://ilk.kub.nl/ ~ilk/papers/ilk0001.ps.gz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>Machine learning research: four current directions.</title>
<date>1997</date>
<journal>AI Magazine,</journal>
<pages>18--97</pages>
<contexts>
<context position="26378" citStr="Dietterich, 1997" startWordPosition="4457" endWordPosition="4458"> the corpus itself. Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results. The second area where the methods described here could be improved is in the way that multiple information sources are integrated. The technique method described in section 3.7 is a fairly crude method for combining frequency information with symbolic data. It would be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature (Dietterich, 1997). In particular, boosting (Schapire, 1999; Abney et al., 1999) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly. 5 Conclusion In this paper, we have presented the results of applying a number of statistical and machine learning techniques to the problem of predicting the order of prenominal adjectives in English. The scores for each of the methods are summarized in table 1. The best methods yield around 90% accuracy, better than the best previously published methods when applied to the broad domain data of the British Na</context>
</contexts>
<marker>Dietterich, 1997</marker>
<rawString>Thomas G. Dietterich. 1997. Machine learning research: four current directions. AI Magazine, 18:97–136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas G Dietterich</author>
</authors>
<title>Approximate statistical tests for comparing supervised classification learning algorithms.</title>
<date>1998</date>
<journal>Neural Computation,</journal>
<volume>10</volume>
<issue>7</issue>
<contexts>
<context position="27036" citStr="Dietterich, 1998" startWordPosition="4564" endWordPosition="4565">; Abney et al., 1999) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly. 5 Conclusion In this paper, we have presented the results of applying a number of statistical and machine learning techniques to the problem of predicting the order of prenominal adjectives in English. The scores for each of the methods are summarized in table 1. The best methods yield around 90% accuracy, better than the best previously published methods when applied to the broad domain data of the British National Corpus. Note that McNemar’s test (Dietterich, 1998) confirms the significance of all of the differences reflected here (with p &lt; 0.005) with the exception of the difference between purely morphological MBL and the method based on positional probabilities. From this investigation, we can draw some additional conclusions. First, a solution specific to adjective ordering works better than a general probabilistic filter. Second, machine learning techniques can be applied to a different kind of linguistic problem with some success, even in the absence of syntagmatic context, and can be used to augment a hand-built competence grammar. Third, in some</context>
</contexts>
<marker>Dietterich, 1998</marker>
<rawString>Thomas G. Dietterich. 1998. Approximate statistical tests for comparing supervised classification learning algorithms. Neural Computation, 10(7):1895– 1924.</rawString>
</citation>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<booktitle>In Proceedings of 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics,</booktitle>
<pages>704--710</pages>
<location>Montreal.</location>
<contexts>
<context position="3006" citStr="Langkilde and Knight, 1998" startWordPosition="480" endWordPosition="483">es underspecify the relative order for many pairs of adjectives and are often difficult to apply in practice. In this paper, we will discuss a number of statistical and machine learning approaches to automatically extracting from large corpora the constraints on the order of prenominal adjectives in English. 2 Word bigram model The problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system. One approach to this more general problem, taken by the ‘Nitrogen’ generator (Langkilde and Knight, 1998a; Langkilde and Knight, 1998b), takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model. Langkilde and Knight report that this strategy yields good results for problems like generating verb/object collocations and for selecting the correct morphological form of a word. It also should be straightforwardly applicable to the more specific problem we are addressing here. To determine the correct order for a sequence of prenominal adjectives, we can</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998a. Generation that exploits corpus-based statistical knowledge. In Proceedings of 36th Annual Meeting of the Association for Computational Linguistics and 17th International Conference on Computational Linguistics, pages 704–710, Montreal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>The practical value of n-grams in generation.</title>
<date>1998</date>
<booktitle>In Proceedings of the International Natural Language Generation Workshop,</booktitle>
<location>Niagara-on-the-Lake, Ontario.</location>
<contexts>
<context position="3006" citStr="Langkilde and Knight, 1998" startWordPosition="480" endWordPosition="483">es underspecify the relative order for many pairs of adjectives and are often difficult to apply in practice. In this paper, we will discuss a number of statistical and machine learning approaches to automatically extracting from large corpora the constraints on the order of prenominal adjectives in English. 2 Word bigram model The problem of generating ordered sequences of adjectives is an instance of the more general problem of selecting among a number of possible outputs from a natural language generation system. One approach to this more general problem, taken by the ‘Nitrogen’ generator (Langkilde and Knight, 1998a; Langkilde and Knight, 1998b), takes advantage of standard statistical techniques by generating a lattice of all possible strings given a semantic representation as input and selecting the most likely output using a bigram language model. Langkilde and Knight report that this strategy yields good results for problems like generating verb/object collocations and for selecting the correct morphological form of a word. It also should be straightforwardly applicable to the more specific problem we are addressing here. To determine the correct order for a sequence of prenominal adjectives, we can</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998b. The practical value of n-grams in generation. In Proceedings of the International Natural Language Generation Workshop, Niagara-on-the-Lake, Ontario.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fernando Pereira</author>
<author>Naftali Tishby</author>
<author>Lilian Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In Proceedings of the 30th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>183--190</pages>
<contexts>
<context position="25711" citStr="Pereira et al., 1993" startWordPosition="4348" endWordPosition="4351">r improving the results. First, while semantic information is not available for all adjectives, it is clearly available for some. Furthermore, any realistic dialog system would make use of some limited vocabulary Direct evidence 78.28% Adjective bigrams 88.02% MBL (morphological) 89.34% (*) Positional probabilities 89.73% (*) MBL (combined) 91.85% Table 1: Summary of results. With the exception of the starred values, all differences are statistically significant (p &lt; 0.005) for which semantic information would be available. More generally, distributional clustering techniques (Sch¨utze, 1992; Pereira et al., 1993) could be applied to extract semantic classes from the corpus itself. Since the constraints on adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results. The second area where the methods described here could be improved is in the way that multiple information sources are integrated. The technique method described in section 3.7 is a fairly crude method for combining frequency information with symbolic data. It would be worthwhile to investigate applying some of the more sophisticated ensemble learning techn</context>
</contexts>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Fernando Pereira, Naftali Tishby, and Lilian Lee. 1993. Distributional clustering of English words. In Proceedings of the 30th annual meeting of the Association for Computational Linguistics, pages 183–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Ross Quinlan</author>
</authors>
<title>Induction of decision trees.</title>
<date>1986</date>
<booktitle>Machine Learning,</booktitle>
<pages>1--81</pages>
<contexts>
<context position="18557" citStr="Quinlan, 1986" startWordPosition="3126" endWordPosition="3127">ector of 16 features (the last 8 characters of a and the last 8 characters of b) and a class a ≺ b or b ≺ a. Constructing the instance base and testing the classification was performed using the TiMBL 3.0 (Daelemans et al., 2000) memorybased learning system. Instances to be classified were compared to previously seen instances by counting the number of feature values that the two instances had in common. In computing the similarity score, features were weighted by their information gain, an information theoretic measure of the relevance of a feature for determining the correct classification (Quinlan, 1986; Daelemans and van den Bosch, 1992). This weighting reduces the sensitivity of memory based learning to the presence of irrelevant features. Given the probability pi of finding each class i in the instance base D, we can compute the entropy H(D), a measure of the amount of uncertainty in D: H(D) = −∑ pi log2 pi pi In the case of the adjective ordering data, there are two classes a ≺ b and b ≺ a, each of which occurs with a probability of roughly 0.5, so the entropy of the instance base is close to 1 bit. We can also compute the entropy of a feature f which takes values V as the weighted sum o</context>
</contexts>
<marker>Quinlan, 1986</marker>
<rawString>J. Ross Quinlan. 1986. Induction of decision trees. Machine Learning, 1:81–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Randolf Quirk</author>
<author>Sidney Greenbaum</author>
<author>Geoffrey Leech</author>
<author>Jan Svartvik</author>
</authors>
<title>A Comprehensive Grammar of the English Language.</title>
<date>1985</date>
<location>Longman, London.</location>
<contexts>
<context position="16075" citStr="Quirk et al., 1985" startWordPosition="2714" endWordPosition="2717">the previous section, this view both reveals a reason why the method is not very effective and also indicates a direction which can be taken to improve it. By requiring the new instance to be identical to a previously seen instance in order to classify it, the direct evidence method is unable to generalize from seen pairs to unseen pairs. Therefore, to improve the method, we need a more appropriate similarity metric that allows the classifier to get information from previously seen pairs which are relevant to but not identical to new unseen pairs. Following the conventional linguistic wisdom (Quirk et al., 1985, e.g.), this similarity metric should pick out adjectives which belong to the same semantic class. Unfortunately, for many adjectives this information is difficult or impossible to come by. Machine readable dictionaries and lexical databases such as WordNet (Fellbaum, 1998) do provide some information about semantic classes. However, the semantic classification in a lexical database may not make exactly the distinctions required for predicting adjective order. More seriously, available lexical databases are by necessity limited to a relatively small number of words, of which a relatively smal</context>
</contexts>
<marker>Quirk, Greenbaum, Leech, Svartvik, 1985</marker>
<rawString>Randolf Quirk, Sidney Greenbaum, Geoffrey Leech, and Jan Svartvik. 1985. A Comprehensive Grammar of the English Language. Longman, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert E Schapire</author>
</authors>
<title>A brief introduction to boosting.</title>
<date>1999</date>
<booktitle>In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="26419" citStr="Schapire, 1999" startWordPosition="4462" endWordPosition="4463"> adjective ordering in English depend largely on semantic classes, the addition of semantic information to the model ought to improve the results. The second area where the methods described here could be improved is in the way that multiple information sources are integrated. The technique method described in section 3.7 is a fairly crude method for combining frequency information with symbolic data. It would be worthwhile to investigate applying some of the more sophisticated ensemble learning techniques which have been proposed in the literature (Dietterich, 1997). In particular, boosting (Schapire, 1999; Abney et al., 1999) offers the possibility of achieving high accuracy from a collection of classifiers which individually perform quite poorly. 5 Conclusion In this paper, we have presented the results of applying a number of statistical and machine learning techniques to the problem of predicting the order of prenominal adjectives in English. The scores for each of the methods are summarized in table 1. The best methods yield around 90% accuracy, better than the best previously published methods when applied to the broad domain data of the British National Corpus. Note that McNemar’s test (</context>
</contexts>
<marker>Schapire, 1999</marker>
<rawString>Robert E. Schapire. 1999. A brief introduction to boosting. In Proceedings of the Sixteenth International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Dimensions of meaning.</title>
<date>1992</date>
<booktitle>In Proceedings of Supercomputing,</booktitle>
<pages>787--796</pages>
<location>Minneapolis.</location>
<marker>Sch¨utze, 1992</marker>
<rawString>Hinrich Sch¨utze. 1992. Dimensions of meaning. In Proceedings of Supercomputing, pages 787–796, Minneapolis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Shaw</author>
<author>Vasileios Hatzivassiloglou</author>
</authors>
<title>Ordering among premodifiers.</title>
<date>1999</date>
<booktitle>In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>135--143</pages>
<location>College Park, Maryland.</location>
<contexts>
<context position="7363" citStr="Shaw and Hatzivassiloglou (1999)" startWordPosition="1190" endWordPosition="1193"> pair types occur only once, and 49% of the adjective types only occur once. Second, we get no useful information about the syntagmatic context in which a pair appears. The lefthand context is almost always a determiner, and including information about the modified head noun would only make the data even sparser. This lack of context makes this problem different from other problems, such as part-of-speech tagging and grapheme-to-phoneme conversion, for which statistical and machine learning solutions have been proposed. 3.2 Direct evidence The simplest strategy for ordering adjectives is what Shaw and Hatzivassiloglou (1999) call the direct evidence method. To order the pair {a,b}, count how many times the ordered sequences (a,b) and (b,a) appear in the training data and output the pair in the order which occurred more often. This method has the advantage of being conceptually very simple, easy to implement, and highly accurate for pairs of adjectives which actually appear in the training data. Applying this method to the adjectives sequences taken from the BNC yields better than 98% accuracy for pairs that occurred in the training data. However, since as we have seen, the majority of pairs occur only once, the o</context>
<context position="10139" citStr="Shaw and Hatzivassiloglou (1999)" startWordPosition="1687" endWordPosition="1690">he sparseness inherent to this kind of data, we need a method which can generalize from the pairs which occur in the training data to unseen pairs. 3.3 Transitivity One way to think of the direct evidence method is to see that it defines a relation � on the set of English adjectives. Given two adjectives, if the ordered pair (a,b) appears in the training data more often then the pair (b,a), then a � b. If the reverse is true, and (b,a) is found more often than (a,b), then b � a. If neither order appears in the training data, then neither a � b nor b � a and an order must be randomly assigned. Shaw and Hatzivassiloglou (1999) propose to generalize the direct evidence method so that it can apply to unseen pairs of adjectives by computing the transitive closure of the ordering relation �. That is, if a � c and c � b, we can conclude that a � b. To take an example from the BNC, the adjectives large and green never occur together in the training data, and so would be assigned a random order by the direct evidence method. However, the pairs (large,new) and (new,green) occur fairly frequently. Therefore, in the face of this evidence we can assign this pair the order (large,green), which not coincidently is the correct E</context>
<context position="11399" citStr="Shaw and Hatzivassiloglou (1999)" startWordPosition="1901" endWordPosition="1904">culty with applying the transitive closure method to any large dataset is that there often will be evidence for both orders of any given pair. For instance, alongside the evidence supporting the order (large,green), we also find the pairs (green,byzantine), (byzantine,decorative), and (decorative,new), which suggest the order (green,large). Intuitively, the evidence for the first order is quite a bit stronger than the evidence for the second. The first ordered pairs are more frequent, as are the individual adjectives involved. To quantify the relative strengths of these transitive inferences, Shaw and Hatzivassiloglou (1999) propose to assign a weight to each link. Say the order (a,b) occurs m times and the pair {a,b} occurs n times in total. Then the weight of the pair a —* b is: n 1 n n ∑ k 2 k=m This weight decreases as the probability that the observed order did not occur strictly by chance increases. This way, the problem of finding the order best supported by the evidence can be stated as a general shortest path problem: to find the preferred order for {a,b}, find the sum of the weights of the pairs in the lowest-weighted path from a to b and from b to a and choose whichever is lower. Using this method, Sha</context>
</contexts>
<marker>Shaw, Hatzivassiloglou, 1999</marker>
<rawString>James Shaw and Vasileios Hatzivassiloglou. 1999. Ordering among premodifiers. In Proceedings of the 37th Annual Meeting of the Association for Computational Linguistics, pages 135–143, College Park, Maryland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>