<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.114947">
<title confidence="0.99687">
Detecting Compositionality in Multi-Word Expressions
</title>
<author confidence="0.978104">
Ioannis Korkontzelos
</author>
<affiliation confidence="0.9358485">
Department of Computer Science
The University of York
</affiliation>
<address confidence="0.805187">
Heslington, York, YO10 5NG, UK
</address>
<email confidence="0.995821">
johnkork@cs.york.ac.uk
</email>
<author confidence="0.979531">
Suresh Manandhar
</author>
<affiliation confidence="0.9966985">
Department of Computer Science
The University of York
</affiliation>
<address confidence="0.892261">
Heslington, York, YO10 5NG, UK
</address>
<email confidence="0.995803">
suresh@cs.york.ac.uk
</email>
<sectionHeader confidence="0.997373" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999726066666667">
Identifying whether a multi-word expres-
sion (MWE) is compositional or not is im-
portant for numerous NLP applications.
Sense induction can partition the context
of MWEs into semantic uses and there-
fore aid in deciding compositionality. We
propose an unsupervised system to ex-
plore this hypothesis on compound nom-
inals, proper names and adjective-noun
constructions, and evaluate the contribu-
tion of sense induction. The evaluation
set is derived from WordNet in a semi-
supervised way. Graph connectivity mea-
sures are employed for unsupervised pa-
rameter tuning.
</bodyText>
<sectionHeader confidence="0.983392" genericHeader="categories and subject descriptors">
1 Introduction and related work
</sectionHeader>
<bodyText confidence="0.99979402173913">
Multi-word expressions (MWEs) are sequences of
words that tend to cooccur more frequently than
chance and are either idiosyncratic or decompos-
able into multiple simple words (Baldwin, 2006).
Deciding idiomaticity of MWEs is highly impor-
tant for machine translation, information retrieval,
question answering, lexical acquisition, parsing
and language generation.
Compositionality refers to the degree to which
the meaning of a MWE can be predicted by com-
bining the meanings of its components. Unlike
syntactic compositionality (e.g. by and large), se-
mantic compositionality is continuous (Baldwin,
2006).
In this paper, we propose a novel unsupervised
approach that compares the major senses of a
MWE and its semantic head using distributional
similarity measures to test the compositionality of
the MWE. These senses are induced by a graph
based sense induction system, whose parameters
are estimated in an unsupervised manner exploit-
ing a number of graph connectivity measures (Ko-
rkontzelos et al., 2009). Our method partitions the
context space and only uses the major senses, fil-
tering out minor senses. In our approach the only
language dependent components are a PoS tagger
and a parser.
There are several studies relevant to detecting
compositionality of noun-noun MWEs (Baldwin et
al., 2003) verb-particle constructions (Bannard et
al., 2003; McCarthy et al., 2003) and verb-noun
pairs (Katz and Giesbrecht, 2006). Datasets with
human compositionality judgements are available
for these MWE categories (Cook et al., 2008).
Here, we focus on compound nominals, proper
names and adjective-noun constructions.
Our contributions are three-fold: firstly, we ex-
perimentally show that sense induction can as-
sist in identifying compositional MWEs. Sec-
ondly, we show that unsupervised parameter tun-
ing (Korkontzelos et al., 2009) results in accuracy
that is comparable to the best manually selected
combination of parameters. Thirdly, we propose
a semi-supervised approach for extracting non-
compositional MWEs from WordNet, to decrease
annotation cost.
</bodyText>
<sectionHeader confidence="0.906387" genericHeader="method">
2 Proposed approach
</sectionHeader>
<bodyText confidence="0.982264">
Let us consider the non-compositional MWE “red
carpet”. It mainly refers to a strip of red carpeting
laid down for dignitaries to walk on. However, it
is possible to encounter instances of “red carpet”
referring to any carpet of red colour. Our method
first applies sense induction to identify the major
semantic uses (senses) of a MWE (“red carpet”)
and its semantic head (“carpet”). Then, it com-
pares these uses to decide MWE compositionality.
The more diverse these uses are, the more possi-
bly the MWE is non-compositional. Our algorithm
consists of 4 steps:
A. Corpora collection and preprocessing. Our
approach receives as input a MWE (e.g. “red car-
pet”). The dependency output of Stanford Parser
(Klein and Manning, 2003) is used to locate the
</bodyText>
<page confidence="0.996529">
65
</page>
<note confidence="0.976007">
Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 65–68,
Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP
</note>
<figureCaption confidence="0.999943">
Figure 1: “red carpet”, sense induction example
</figureCaption>
<bodyText confidence="0.974954530864197">
MWE semantic head. Two different corpora are
collected (for the MWE and its semantic head).
Each consists of webtext snippets of length 15 to
200 tokens in which the MWE/semantic head ap-
pears. Given a MWE, a set of queries is created:
All synonyms of the MWE extracted from Word-
Net are collected1. The MWE is paired with each
synonym to create a set of queries. For each query,
snippets are collected by parsing the web-pages re-
turned by Yahoo!. The union of all snippets pro-
duces the MWE corpus. The corpus for a semantic
head is created equivalently.
To keep the computational time reasonable,
only the longest 3, 000 snippets are kept from each
corpus. Both corpora are PoS tagged (GENIA tag-
ger). In common with Agirre et al. (2006), only
nouns are kept and lemmatized, since they are
more discriminative than other PoS.
B. Sense Induction methods can be broadly di-
vided into vector-space models and graph based
models. Sense induction methods are evaluated
under the SemEval-2007 framework (Agirre and
Soroa, 2007). We employ the collocational graph-
based sense induction of Klapaftis and Manand-
har (2008) in this work (henceforth referred to as
KM). The method consists of 3 stages:
Corpus preprocessing aims to capture nouns
that are contextually related to the target
MWE/head. Log-likelihood ratio (G2) (Dunning,
1993) with respect to a large reference corpus, Web
1T 5-gram Corpus (Brants and Franz, 2006), is
used to capture the contextually relevant nouns.
P1 is the G2 threshold below which nouns are re-
moved from corpora.
Graph creation. A collocation is defined as a
pair of nouns cooccuring within a snippet. Each
1Thus, for “red carpet”, corpora will be collected for “red
carpet” and “carpet”. The synonyms of “red carpet” are
“rug”, “carpet” and “carpeting”
noun within a snippet is combined with every
other, generating (2) collocations. Each collo-
cation is represented as a weighted vertex. P2
thresholds collocation frequencies and P3 colloca-
tion weights. Weighted edges are drawn based on
cooccurrence of the corresponding vertices in one
or more snippets (e.g. w8 and w7,9, fig. 1). In con-
trast to KM, frequencies for weighting vertices and
edges are obtained from Yahoo! web-page counts
to deal with data sparsity.
Graph clustering uses Chinese Whispers2 (Bie-
mann, 2006) to cluster the graph. Each cluster now
represents a sense of the target word.
KM produces larger number of clusters (uses)
than expected. To reduce it we exploit the one
sense per collocation property (Yarowsky, 1995).
Given a cluster li, we compute the set Si of snip-
pets that contain at least one collocation of li. Any
clusters la and lb are merged if Sa ⊆ Sb.
C. Comparing the induced senses. We used
two techniques to measure the distributional simi-
larity of major uses of the MWE and its semantic
head, both based on Jaccard coefficient (J). “Ma-
jor use” denotes the cluster of collocations which
tags the most snippets. Lee (1999) shows that
J performs better than other symmetric similarity
measures such as cosine, Jensen-Shannon diver-
gence, etc. The first is Jc = J(A, B) = |A∩B|
|A∪B|,
where A, B are sets of collocations. The second,
Jsn, is based on the snippets that are tagged by
the induced uses. Let Ki be the set of snippets in
which at least one collocation of the use i occurs.
Jsn = J(Kj, Kk), where j, k are the major uses
of the MWE and its semantic head, respectively.
D. Determining compositionality. Given the
major uses of a MWE and its semantic head,
the MWE is considered as compositional, when
the corresponding distributional similarity mea-
sure (Jc or Jsn) value is above a parameter thresh-
old, sim. Otherwise, it is considered as non-
compositional.
</bodyText>
<sectionHeader confidence="0.920923" genericHeader="method">
3 Test set of MWEs
</sectionHeader>
<bodyText confidence="0.9979635">
To the best of our knowledge there are no noun
compound datasets accompanied with composi-
tionality judgements available. Thus, we devel-
oped an algorithm to aid human annotation. For
each of the 52, 217 MWEs of WordNet 3.0 (Miller,
1995) we collected:
</bodyText>
<footnote confidence="0.9981375">
2Chinese Whispers is not guaranteed to converge, thus
200 was adopted as the maximum number of iterations.
</footnote>
<page confidence="0.994195">
66
</page>
<bodyText confidence="0.996253769230769">
Non-compositional MWEs
agony aunt, black maria, dead end, dutch oven,
fish finger, fool’s paradise, goat’s rue, green light,
high jump, joint chiefs, lip service, living rock,
monkey puzzle, motor pool, prince Albert,
stocking stuffer, sweet bay, teddy boy, think tank
Compositional MWEs
box white oak, cartridge brass, common iguana,
closed chain, eastern pipistrel, field mushroom,
hard candy, king snake, labor camp, lemon tree,
life form, parenthesis-free notation, parking brake,
petitjuror, relational adjective, taxonomic category,
telephone service, tea table, upland cotton
</bodyText>
<tableCaption confidence="0.978561666666667">
Table 1: Test set with compositionality annotation.
MWEs whose compositionality was successfully
detected by: (a) 1c1word baseline are in bold font,
</tableCaption>
<listItem confidence="0.950453142857143">
(b) manual parameter selection are underlined and
(c) average cluster coefficient are in italics.
1. all synonyms of the MWE
2. all hypernyms of the MWE
3. sister-synsets of the MWE, within distance3 3
4. synsets that are in holonymy or meronymy re-
lation to the MWE, within distance 3
</listItem>
<bodyText confidence="0.999835333333333">
If the semantic head of the MWE is also in the
above collection then the MWE is likely to be com-
positional, otherwise it is likely that the MWE is
non-compositional.
6,287 MWEs were judged as potentially non-
compositional. We randomly chose 19 and
checked them manually. Those that were compo-
sitional were replaced by other randomly chosen
ones. The process was repeated until we ended up
with 19 non-compositional examples. Similarly,
19 negative examples that were judged as compo-
sitional were collected (Table 1).
</bodyText>
<sectionHeader confidence="0.927859" genericHeader="method">
4 Evaluation setting and results
</sectionHeader>
<bodyText confidence="0.999900153846154">
The sense induction component of our algorithm
depends upon 3 parameters: P1 is the G2 threshold
below which noun are removed from corpora. P2
thresholds collocation frequencies and P3 colloca-
tion weights. We chose P1 ∈ {5,10,15}, P2 ∈
{102, 103, 104, 105} and P3 ∈ {0.2, 0.3, 0.4}. For
reference, P1 values of 3.84, 6.63, 10.83 and
15.13 correspond to G2 values for confidence lev-
els of 95%, 99%, 99.9% and 99.99%, respectively.
To assess the performance of the proposed al-
gorithm we compute accuracy, the percentage of
MWEs whose compositionality was correctly de-
termined against the gold standard.
</bodyText>
<footnote confidence="0.9298115">
3Locating sister synsets at distance D implies ascending
D steps and then descending D steps.
</footnote>
<figureCaption confidence="0.999991">
Figure 2: Proposed system and 1c1word accuracy.
Figure 3: Unweighted graph con/vity measures.
</figureCaption>
<bodyText confidence="0.999967434782609">
We compared the system’s performance against
a baseline, 1c1word, that assigns the whole graph
to a single cluster and no graph clustering is
performed. 1c1word corresponds to a relevant
SemEval-2007 baseline (Agirre and Soroa, 2007)
and helps in showing whether sense induction can
assist determining compositionality.
Our method was evaluated for each hP1, P2, P3i
combination and similarity measures J, and J3,,,,
separately. We used our development set to deter-
mine if there are parameter values that verify our
hypothesis. Given a sim value (see section 2, last
paragraph), we chose the best performing parame-
ter combination manually.
The best results for manual parameter selection
were obtained for sim = 95% giving an accu-
racy of 68.42% for detecting non-compositional
MWEs. In all experiments, J3,,, outperforms J,.
With manually selected parameters, our system’s
accuracy is higher than 1c1word for all sim values
(5% points) (fig. 2, table 1). The initial hypothesis
holds; sense induction improves MWE composi-
tionality detection.
</bodyText>
<sectionHeader confidence="0.875484" genericHeader="method">
5 Unsupervised parameter tuning
</sectionHeader>
<bodyText confidence="0.9996693">
We followed Korkontzelos et al. (2009) to select
the “best” parameters hP1, P2, P3i for the collo-
cational graph of each MWE or head word. We
applied 8 graph connectivity measures (weighted
and unweighted versions of average degree, clus-
ter coefficient, graph entropy and edge density)
separately on each of the clusters (resulting from
the application of the chinese whispers algorithm).
Each graph connectivity measure assigns a
score to each cluster. We averaged the scores over
</bodyText>
<page confidence="0.999176">
67
</page>
<figureCaption confidence="0.999375">
Figure 4: Weighted graph connectivity measures.
</figureCaption>
<bodyText confidence="0.998172857142857">
the clusters from the same graph. For each con-
nectivity measure, we chose the parameter combi-
nation (P1, P2, P3) that gave the highest score.
While manual parameter tuning chooses a sin-
gle globally best set of parameters (see section 4),
the graph connectivity measures generate different
values of (P1, P2, P3) for each graph.
</bodyText>
<subsectionHeader confidence="0.981581">
5.1 Evaluation results
</subsectionHeader>
<bodyText confidence="0.999852588235294">
The best performing distributional similarity mea-
sure is J3,,,. Unweighted versions of graph con-
nectivity measures perform better than weighted
ones. Figures 3 and 4 present a comparison be-
tween the unweighted and weighted versions of
all graph connectivity measures, respectively, for
all sim values. Average cluster coefficient per-
forms better or equally well to the other graph
connectivity measures for all sim values (except
for sim E [90%,100%]). The accuracy of aver-
age cluster coefficient is equal (68.42%) to that
of manual parameter selection (section 4, table
1). The second best performing unweighted graph
connectivity measures is average graph entropy.
For weighted graph connectivity measures, aver-
age graph entropy performs best, followed by av-
erage weighted clustering coefficient.
</bodyText>
<sectionHeader confidence="0.998258" genericHeader="conclusions">
6 Conclusion and Future Work
</sectionHeader>
<bodyText confidence="0.999988">
We hypothesized that sense induction can assist in
identifying compositional MWEs. We introduced
an unsupervised system to experimentally explore
the hypothesis, and showed that it holds. We
proposed a semi-supervised way to extract non-
compositional MWEs from WordNet. We showed
that graph connectivity measures can be success-
fully employed to perform unsupervised parame-
ter tuning of our system. It would be interesting
to explore ways to substitute querying Yahoo! so
as to make the system quicker. Experimentation
with more sophisticated graph connectivity mea-
sures could possibly improve accuracy.
</bodyText>
<sectionHeader confidence="0.996105" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99986337254902">
E. Agirre and A. Soroa. 2007. Semeval-2007, task
02: Evaluating WSI and discrimination systems. In
proceedings of SemEval-2007. ACL.
E. Agirre, D. Martinez, O. de Lacalle, and A. Soroa.
2006. Two graph-based algorithms for state-of-the-
art WSD. In proceedings of EMNLP-2006. ACL.
T. Baldwin, C. Bannard, T. Tanaka, and D. Widdows.
2003. An empirical model of MWE decomposabil-
ity. In proceedings of the MWE workshop. ACL.
T. Baldwin. 2006. Compositionality and MWEs: Six
of one, half a dozen of the other? In proceedings of
the MWE workshop. ACL.
C. Bannard, T. Baldwin, and A. Lascarides. 2003.
A statistical approach to the semantics of verb-
particles. In proceedings of the MWE workshop.
ACL.
C. Biemann. 2006. Chinese whispers - an efficient
graph clustering algorithm and its application to
NLP problems. In proceedings of TextGraphs. ACL.
T. Brants and A. Franz. 2006. Web 1t 5-gram corpus,
version 1. Technical report, Google Research.
P. Cook, A. Fazly, and S. Stevenson. 2008. The VNC-
Tokens Dataset. In proceedings of the MWE work-
shop. ACL.
T. Dunning. 1993. Accurate methods for the statistics
of surprise and coincidence. Computational Lin-
guistics, 19(1):61–74.
G. Katz and E. Giesbrecht. 2006. Automatic identifi-
cation of non-compositional MWEs using latent se-
mantic analysis. In proceedings of the MWE work-
shop. ACL.
I. P. Klapaftis and S. Manandhar. 2008. WSI using
graphs of collocations. In proceedings of ECAI-
2008.
D. Klein and C. Manning. 2003. Fast exact inference
with a factored model for natural language parsing.
In proceedings of NIPS 15. MIT Press.
I. Korkontzelos, I. Klapaftis, and S. Manandhar. 2009.
Graph connectivity measures for unsupervised pa-
rameter tuning of graph-based sense induction sys-
tems. In proceedings of the UMSLLS Workshop,
NAACL HLT 2009.
L. Lee. 1999. Measures of distributional similarity. In
proceedings of ACL.
D. McCarthy, B. Keller, and J. Carroll. 2003. De-
tecting a continuum of compositionality in phrasal
verbs. In proceedings of the MWE workshop. ACL.
G. A. Miller. 1995. WordNet: a lexical database for
English. ACM, 38(11):39–41.
D. Yarowsky. 1995. Unsupervised WSD rivaling su-
pervised methods. In proceedings of ACL.
</reference>
<page confidence="0.999445">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.884249">
<title confidence="0.999912">Detecting Compositionality in Multi-Word Expressions</title>
<author confidence="0.966911">Ioannis Korkontzelos</author>
<affiliation confidence="0.999531">Department of Computer Science The University of York</affiliation>
<address confidence="0.99991">Heslington, York, YO10 5NG, UK</address>
<email confidence="0.995145">johnkork@cs.york.ac.uk</email>
<author confidence="0.941049">Suresh Manandhar</author>
<affiliation confidence="0.999443">Department of Computer Science The University of York</affiliation>
<address confidence="0.999865">Heslington, York, YO10 5NG, UK</address>
<email confidence="0.997918">suresh@cs.york.ac.uk</email>
<abstract confidence="0.998763875">Identifying whether a multi-word expresis compositional or not is imfor numerous Sense induction can partition the context semantic uses and therefore aid in deciding compositionality. We propose an unsupervised system to exthis hypothesis on nomnames and evaluate the contribution of sense induction. The evaluation is derived from a semisupervised way. Graph connectivity measures are employed for unsupervised parameter tuning.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>A Soroa</author>
</authors>
<title>Semeval-2007, task 02: Evaluating WSI and discrimination systems.</title>
<date>2007</date>
<booktitle>In proceedings of SemEval-2007. ACL.</booktitle>
<contexts>
<context position="4924" citStr="Agirre and Soroa, 2007" startWordPosition="757" endWordPosition="760">ected by parsing the web-pages returned by Yahoo!. The union of all snippets produces the MWE corpus. The corpus for a semantic head is created equivalently. To keep the computational time reasonable, only the longest 3, 000 snippets are kept from each corpus. Both corpora are PoS tagged (GENIA tagger). In common with Agirre et al. (2006), only nouns are kept and lemmatized, since they are more discriminative than other PoS. B. Sense Induction methods can be broadly divided into vector-space models and graph based models. Sense induction methods are evaluated under the SemEval-2007 framework (Agirre and Soroa, 2007). We employ the collocational graphbased sense induction of Klapaftis and Manandhar (2008) in this work (henceforth referred to as KM). The method consists of 3 stages: Corpus preprocessing aims to capture nouns that are contextually related to the target MWE/head. Log-likelihood ratio (G2) (Dunning, 1993) with respect to a large reference corpus, Web 1T 5-gram Corpus (Brants and Franz, 2006), is used to capture the contextually relevant nouns. P1 is the G2 threshold below which nouns are removed from corpora. Graph creation. A collocation is defined as a pair of nouns cooccuring within a snip</context>
<context position="10547" citStr="Agirre and Soroa, 2007" startWordPosition="1674" endWordPosition="1677">9.9% and 99.99%, respectively. To assess the performance of the proposed algorithm we compute accuracy, the percentage of MWEs whose compositionality was correctly determined against the gold standard. 3Locating sister synsets at distance D implies ascending D steps and then descending D steps. Figure 2: Proposed system and 1c1word accuracy. Figure 3: Unweighted graph con/vity measures. We compared the system’s performance against a baseline, 1c1word, that assigns the whole graph to a single cluster and no graph clustering is performed. 1c1word corresponds to a relevant SemEval-2007 baseline (Agirre and Soroa, 2007) and helps in showing whether sense induction can assist determining compositionality. Our method was evaluated for each hP1, P2, P3i combination and similarity measures J, and J3,,,, separately. We used our development set to determine if there are parameter values that verify our hypothesis. Given a sim value (see section 2, last paragraph), we chose the best performing parameter combination manually. The best results for manual parameter selection were obtained for sim = 95% giving an accuracy of 68.42% for detecting non-compositional MWEs. In all experiments, J3,,, outperforms J,. With man</context>
</contexts>
<marker>Agirre, Soroa, 2007</marker>
<rawString>E. Agirre and A. Soroa. 2007. Semeval-2007, task 02: Evaluating WSI and discrimination systems. In proceedings of SemEval-2007. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Martinez</author>
<author>O de Lacalle</author>
<author>A Soroa</author>
</authors>
<title>Two graph-based algorithms for state-of-theart WSD.</title>
<date>2006</date>
<booktitle>In proceedings of EMNLP-2006.</booktitle>
<publisher>ACL.</publisher>
<marker>Agirre, Martinez, de Lacalle, Soroa, 2006</marker>
<rawString>E. Agirre, D. Martinez, O. de Lacalle, and A. Soroa. 2006. Two graph-based algorithms for state-of-theart WSD. In proceedings of EMNLP-2006. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>C Bannard</author>
<author>T Tanaka</author>
<author>D Widdows</author>
</authors>
<title>An empirical model of MWE decomposability.</title>
<date>2003</date>
<booktitle>In proceedings of the MWE workshop. ACL.</booktitle>
<contexts>
<context position="2204" citStr="Baldwin et al., 2003" startWordPosition="322" endWordPosition="325"> major senses of a MWE and its semantic head using distributional similarity measures to test the compositionality of the MWE. These senses are induced by a graph based sense induction system, whose parameters are estimated in an unsupervised manner exploiting a number of graph connectivity measures (Korkontzelos et al., 2009). Our method partitions the context space and only uses the major senses, filtering out minor senses. In our approach the only language dependent components are a PoS tagger and a parser. There are several studies relevant to detecting compositionality of noun-noun MWEs (Baldwin et al., 2003) verb-particle constructions (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs (Katz and Giesbrecht, 2006). Datasets with human compositionality judgements are available for these MWE categories (Cook et al., 2008). Here, we focus on compound nominals, proper names and adjective-noun constructions. Our contributions are three-fold: firstly, we experimentally show that sense induction can assist in identifying compositional MWEs. Secondly, we show that unsupervised parameter tuning (Korkontzelos et al., 2009) results in accuracy that is comparable to the best manually selected c</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>T. Baldwin, C. Bannard, T. Tanaka, and D. Widdows. 2003. An empirical model of MWE decomposability. In proceedings of the MWE workshop. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Baldwin</author>
</authors>
<title>Compositionality and MWEs: Six of one, half a dozen of the other?</title>
<date>2006</date>
<booktitle>In proceedings of the MWE workshop. ACL.</booktitle>
<contexts>
<context position="1094" citStr="Baldwin, 2006" startWordPosition="155" endWordPosition="156">s into semantic uses and therefore aid in deciding compositionality. We propose an unsupervised system to explore this hypothesis on compound nominals, proper names and adjective-noun constructions, and evaluate the contribution of sense induction. The evaluation set is derived from WordNet in a semisupervised way. Graph connectivity measures are employed for unsupervised parameter tuning. 1 Introduction and related work Multi-word expressions (MWEs) are sequences of words that tend to cooccur more frequently than chance and are either idiosyncratic or decomposable into multiple simple words (Baldwin, 2006). Deciding idiomaticity of MWEs is highly important for machine translation, information retrieval, question answering, lexical acquisition, parsing and language generation. Compositionality refers to the degree to which the meaning of a MWE can be predicted by combining the meanings of its components. Unlike syntactic compositionality (e.g. by and large), semantic compositionality is continuous (Baldwin, 2006). In this paper, we propose a novel unsupervised approach that compares the major senses of a MWE and its semantic head using distributional similarity measures to test the compositional</context>
</contexts>
<marker>Baldwin, 2006</marker>
<rawString>T. Baldwin. 2006. Compositionality and MWEs: Six of one, half a dozen of the other? In proceedings of the MWE workshop. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bannard</author>
<author>T Baldwin</author>
<author>A Lascarides</author>
</authors>
<title>A statistical approach to the semantics of verbparticles.</title>
<date>2003</date>
<booktitle>In proceedings of the MWE workshop. ACL.</booktitle>
<contexts>
<context position="2254" citStr="Bannard et al., 2003" startWordPosition="328" endWordPosition="331">distributional similarity measures to test the compositionality of the MWE. These senses are induced by a graph based sense induction system, whose parameters are estimated in an unsupervised manner exploiting a number of graph connectivity measures (Korkontzelos et al., 2009). Our method partitions the context space and only uses the major senses, filtering out minor senses. In our approach the only language dependent components are a PoS tagger and a parser. There are several studies relevant to detecting compositionality of noun-noun MWEs (Baldwin et al., 2003) verb-particle constructions (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs (Katz and Giesbrecht, 2006). Datasets with human compositionality judgements are available for these MWE categories (Cook et al., 2008). Here, we focus on compound nominals, proper names and adjective-noun constructions. Our contributions are three-fold: firstly, we experimentally show that sense induction can assist in identifying compositional MWEs. Secondly, we show that unsupervised parameter tuning (Korkontzelos et al., 2009) results in accuracy that is comparable to the best manually selected combination of parameters. Thirdly, we propose a se</context>
</contexts>
<marker>Bannard, Baldwin, Lascarides, 2003</marker>
<rawString>C. Bannard, T. Baldwin, and A. Lascarides. 2003. A statistical approach to the semantics of verbparticles. In proceedings of the MWE workshop. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Biemann</author>
</authors>
<title>Chinese whispers - an efficient graph clustering algorithm and its application to NLP problems.</title>
<date>2006</date>
<booktitle>In proceedings of TextGraphs. ACL.</booktitle>
<contexts>
<context position="6199" citStr="Biemann, 2006" startWordPosition="962" endWordPosition="964">for “red carpet” and “carpet”. The synonyms of “red carpet” are “rug”, “carpet” and “carpeting” noun within a snippet is combined with every other, generating (2) collocations. Each collocation is represented as a weighted vertex. P2 thresholds collocation frequencies and P3 collocation weights. Weighted edges are drawn based on cooccurrence of the corresponding vertices in one or more snippets (e.g. w8 and w7,9, fig. 1). In contrast to KM, frequencies for weighting vertices and edges are obtained from Yahoo! web-page counts to deal with data sparsity. Graph clustering uses Chinese Whispers2 (Biemann, 2006) to cluster the graph. Each cluster now represents a sense of the target word. KM produces larger number of clusters (uses) than expected. To reduce it we exploit the one sense per collocation property (Yarowsky, 1995). Given a cluster li, we compute the set Si of snippets that contain at least one collocation of li. Any clusters la and lb are merged if Sa ⊆ Sb. C. Comparing the induced senses. We used two techniques to measure the distributional similarity of major uses of the MWE and its semantic head, both based on Jaccard coefficient (J). “Major use” denotes the cluster of collocations whi</context>
</contexts>
<marker>Biemann, 2006</marker>
<rawString>C. Biemann. 2006. Chinese whispers - an efficient graph clustering algorithm and its application to NLP problems. In proceedings of TextGraphs. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Brants</author>
<author>A Franz</author>
</authors>
<title>Web 1t 5-gram corpus, version 1.</title>
<date>2006</date>
<tech>Technical report, Google Research.</tech>
<contexts>
<context position="5319" citStr="Brants and Franz, 2006" startWordPosition="819" endWordPosition="822">re discriminative than other PoS. B. Sense Induction methods can be broadly divided into vector-space models and graph based models. Sense induction methods are evaluated under the SemEval-2007 framework (Agirre and Soroa, 2007). We employ the collocational graphbased sense induction of Klapaftis and Manandhar (2008) in this work (henceforth referred to as KM). The method consists of 3 stages: Corpus preprocessing aims to capture nouns that are contextually related to the target MWE/head. Log-likelihood ratio (G2) (Dunning, 1993) with respect to a large reference corpus, Web 1T 5-gram Corpus (Brants and Franz, 2006), is used to capture the contextually relevant nouns. P1 is the G2 threshold below which nouns are removed from corpora. Graph creation. A collocation is defined as a pair of nouns cooccuring within a snippet. Each 1Thus, for “red carpet”, corpora will be collected for “red carpet” and “carpet”. The synonyms of “red carpet” are “rug”, “carpet” and “carpeting” noun within a snippet is combined with every other, generating (2) collocations. Each collocation is represented as a weighted vertex. P2 thresholds collocation frequencies and P3 collocation weights. Weighted edges are drawn based on coo</context>
</contexts>
<marker>Brants, Franz, 2006</marker>
<rawString>T. Brants and A. Franz. 2006. Web 1t 5-gram corpus, version 1. Technical report, Google Research.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Cook</author>
<author>A Fazly</author>
<author>S Stevenson</author>
</authors>
<title>The VNCTokens Dataset.</title>
<date>2008</date>
<booktitle>In proceedings of the MWE workshop. ACL.</booktitle>
<contexts>
<context position="2434" citStr="Cook et al., 2008" startWordPosition="354" endWordPosition="357">upervised manner exploiting a number of graph connectivity measures (Korkontzelos et al., 2009). Our method partitions the context space and only uses the major senses, filtering out minor senses. In our approach the only language dependent components are a PoS tagger and a parser. There are several studies relevant to detecting compositionality of noun-noun MWEs (Baldwin et al., 2003) verb-particle constructions (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs (Katz and Giesbrecht, 2006). Datasets with human compositionality judgements are available for these MWE categories (Cook et al., 2008). Here, we focus on compound nominals, proper names and adjective-noun constructions. Our contributions are three-fold: firstly, we experimentally show that sense induction can assist in identifying compositional MWEs. Secondly, we show that unsupervised parameter tuning (Korkontzelos et al., 2009) results in accuracy that is comparable to the best manually selected combination of parameters. Thirdly, we propose a semi-supervised approach for extracting noncompositional MWEs from WordNet, to decrease annotation cost. 2 Proposed approach Let us consider the non-compositional MWE “red carpet”. I</context>
</contexts>
<marker>Cook, Fazly, Stevenson, 2008</marker>
<rawString>P. Cook, A. Fazly, and S. Stevenson. 2008. The VNCTokens Dataset. In proceedings of the MWE workshop. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="5231" citStr="Dunning, 1993" startWordPosition="806" endWordPosition="807">ith Agirre et al. (2006), only nouns are kept and lemmatized, since they are more discriminative than other PoS. B. Sense Induction methods can be broadly divided into vector-space models and graph based models. Sense induction methods are evaluated under the SemEval-2007 framework (Agirre and Soroa, 2007). We employ the collocational graphbased sense induction of Klapaftis and Manandhar (2008) in this work (henceforth referred to as KM). The method consists of 3 stages: Corpus preprocessing aims to capture nouns that are contextually related to the target MWE/head. Log-likelihood ratio (G2) (Dunning, 1993) with respect to a large reference corpus, Web 1T 5-gram Corpus (Brants and Franz, 2006), is used to capture the contextually relevant nouns. P1 is the G2 threshold below which nouns are removed from corpora. Graph creation. A collocation is defined as a pair of nouns cooccuring within a snippet. Each 1Thus, for “red carpet”, corpora will be collected for “red carpet” and “carpet”. The synonyms of “red carpet” are “rug”, “carpet” and “carpeting” noun within a snippet is combined with every other, generating (2) collocations. Each collocation is represented as a weighted vertex. P2 thresholds c</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>T. Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Katz</author>
<author>E Giesbrecht</author>
</authors>
<title>Automatic identification of non-compositional MWEs using latent semantic analysis.</title>
<date>2006</date>
<booktitle>In proceedings of the MWE workshop. ACL.</booktitle>
<contexts>
<context position="2326" citStr="Katz and Giesbrecht, 2006" startWordPosition="339" endWordPosition="342"> the MWE. These senses are induced by a graph based sense induction system, whose parameters are estimated in an unsupervised manner exploiting a number of graph connectivity measures (Korkontzelos et al., 2009). Our method partitions the context space and only uses the major senses, filtering out minor senses. In our approach the only language dependent components are a PoS tagger and a parser. There are several studies relevant to detecting compositionality of noun-noun MWEs (Baldwin et al., 2003) verb-particle constructions (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs (Katz and Giesbrecht, 2006). Datasets with human compositionality judgements are available for these MWE categories (Cook et al., 2008). Here, we focus on compound nominals, proper names and adjective-noun constructions. Our contributions are three-fold: firstly, we experimentally show that sense induction can assist in identifying compositional MWEs. Secondly, we show that unsupervised parameter tuning (Korkontzelos et al., 2009) results in accuracy that is comparable to the best manually selected combination of parameters. Thirdly, we propose a semi-supervised approach for extracting noncompositional MWEs from WordNet</context>
</contexts>
<marker>Katz, Giesbrecht, 2006</marker>
<rawString>G. Katz and E. Giesbrecht. 2006. Automatic identification of non-compositional MWEs using latent semantic analysis. In proceedings of the MWE workshop. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I P Klapaftis</author>
<author>S Manandhar</author>
</authors>
<title>WSI using graphs of collocations.</title>
<date>2008</date>
<booktitle>In proceedings of ECAI2008.</booktitle>
<contexts>
<context position="5014" citStr="Klapaftis and Manandhar (2008)" startWordPosition="770" endWordPosition="774">es the MWE corpus. The corpus for a semantic head is created equivalently. To keep the computational time reasonable, only the longest 3, 000 snippets are kept from each corpus. Both corpora are PoS tagged (GENIA tagger). In common with Agirre et al. (2006), only nouns are kept and lemmatized, since they are more discriminative than other PoS. B. Sense Induction methods can be broadly divided into vector-space models and graph based models. Sense induction methods are evaluated under the SemEval-2007 framework (Agirre and Soroa, 2007). We employ the collocational graphbased sense induction of Klapaftis and Manandhar (2008) in this work (henceforth referred to as KM). The method consists of 3 stages: Corpus preprocessing aims to capture nouns that are contextually related to the target MWE/head. Log-likelihood ratio (G2) (Dunning, 1993) with respect to a large reference corpus, Web 1T 5-gram Corpus (Brants and Franz, 2006), is used to capture the contextually relevant nouns. P1 is the G2 threshold below which nouns are removed from corpora. Graph creation. A collocation is defined as a pair of nouns cooccuring within a snippet. Each 1Thus, for “red carpet”, corpora will be collected for “red carpet” and “carpet”</context>
</contexts>
<marker>Klapaftis, Manandhar, 2008</marker>
<rawString>I. P. Klapaftis and S. Manandhar. 2008. WSI using graphs of collocations. In proceedings of ECAI2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klein</author>
<author>C Manning</author>
</authors>
<title>Fast exact inference with a factored model for natural language parsing.</title>
<date>2003</date>
<booktitle>In proceedings of NIPS 15.</booktitle>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3704" citStr="Klein and Manning, 2003" startWordPosition="551" endWordPosition="554">id down for dignitaries to walk on. However, it is possible to encounter instances of “red carpet” referring to any carpet of red colour. Our method first applies sense induction to identify the major semantic uses (senses) of a MWE (“red carpet”) and its semantic head (“carpet”). Then, it compares these uses to decide MWE compositionality. The more diverse these uses are, the more possibly the MWE is non-compositional. Our algorithm consists of 4 steps: A. Corpora collection and preprocessing. Our approach receives as input a MWE (e.g. “red carpet”). The dependency output of Stanford Parser (Klein and Manning, 2003) is used to locate the 65 Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 65–68, Suntec, Singapore, 4 August 2009. c�2009 ACL and AFNLP Figure 1: “red carpet”, sense induction example MWE semantic head. Two different corpora are collected (for the MWE and its semantic head). Each consists of webtext snippets of length 15 to 200 tokens in which the MWE/semantic head appears. Given a MWE, a set of queries is created: All synonyms of the MWE extracted from WordNet are collected1. The MWE is paired with each synonym to create a set of queries. For each query, snippets are collect</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>D. Klein and C. Manning. 2003. Fast exact inference with a factored model for natural language parsing. In proceedings of NIPS 15. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Korkontzelos</author>
<author>I Klapaftis</author>
<author>S Manandhar</author>
</authors>
<title>Graph connectivity measures for unsupervised parameter tuning of graph-based sense induction systems.</title>
<date>2009</date>
<booktitle>In proceedings of the UMSLLS Workshop, NAACL HLT</booktitle>
<contexts>
<context position="1911" citStr="Korkontzelos et al., 2009" startWordPosition="274" endWordPosition="278">refers to the degree to which the meaning of a MWE can be predicted by combining the meanings of its components. Unlike syntactic compositionality (e.g. by and large), semantic compositionality is continuous (Baldwin, 2006). In this paper, we propose a novel unsupervised approach that compares the major senses of a MWE and its semantic head using distributional similarity measures to test the compositionality of the MWE. These senses are induced by a graph based sense induction system, whose parameters are estimated in an unsupervised manner exploiting a number of graph connectivity measures (Korkontzelos et al., 2009). Our method partitions the context space and only uses the major senses, filtering out minor senses. In our approach the only language dependent components are a PoS tagger and a parser. There are several studies relevant to detecting compositionality of noun-noun MWEs (Baldwin et al., 2003) verb-particle constructions (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs (Katz and Giesbrecht, 2006). Datasets with human compositionality judgements are available for these MWE categories (Cook et al., 2008). Here, we focus on compound nominals, proper names and adjective-noun constr</context>
<context position="11426" citStr="Korkontzelos et al. (2009)" startWordPosition="1808" endWordPosition="1811">ameter values that verify our hypothesis. Given a sim value (see section 2, last paragraph), we chose the best performing parameter combination manually. The best results for manual parameter selection were obtained for sim = 95% giving an accuracy of 68.42% for detecting non-compositional MWEs. In all experiments, J3,,, outperforms J,. With manually selected parameters, our system’s accuracy is higher than 1c1word for all sim values (5% points) (fig. 2, table 1). The initial hypothesis holds; sense induction improves MWE compositionality detection. 5 Unsupervised parameter tuning We followed Korkontzelos et al. (2009) to select the “best” parameters hP1, P2, P3i for the collocational graph of each MWE or head word. We applied 8 graph connectivity measures (weighted and unweighted versions of average degree, cluster coefficient, graph entropy and edge density) separately on each of the clusters (resulting from the application of the chinese whispers algorithm). Each graph connectivity measure assigns a score to each cluster. We averaged the scores over 67 Figure 4: Weighted graph connectivity measures. the clusters from the same graph. For each connectivity measure, we chose the parameter combination (P1, P</context>
</contexts>
<marker>Korkontzelos, Klapaftis, Manandhar, 2009</marker>
<rawString>I. Korkontzelos, I. Klapaftis, and S. Manandhar. 2009. Graph connectivity measures for unsupervised parameter tuning of graph-based sense induction systems. In proceedings of the UMSLLS Workshop, NAACL HLT 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lee</author>
</authors>
<title>Measures of distributional similarity.</title>
<date>1999</date>
<booktitle>In proceedings of ACL.</booktitle>
<contexts>
<context position="6836" citStr="Lee (1999)" startWordPosition="1076" endWordPosition="1077"> cluster now represents a sense of the target word. KM produces larger number of clusters (uses) than expected. To reduce it we exploit the one sense per collocation property (Yarowsky, 1995). Given a cluster li, we compute the set Si of snippets that contain at least one collocation of li. Any clusters la and lb are merged if Sa ⊆ Sb. C. Comparing the induced senses. We used two techniques to measure the distributional similarity of major uses of the MWE and its semantic head, both based on Jaccard coefficient (J). “Major use” denotes the cluster of collocations which tags the most snippets. Lee (1999) shows that J performs better than other symmetric similarity measures such as cosine, Jensen-Shannon divergence, etc. The first is Jc = J(A, B) = |A∩B| |A∪B|, where A, B are sets of collocations. The second, Jsn, is based on the snippets that are tagged by the induced uses. Let Ki be the set of snippets in which at least one collocation of the use i occurs. Jsn = J(Kj, Kk), where j, k are the major uses of the MWE and its semantic head, respectively. D. Determining compositionality. Given the major uses of a MWE and its semantic head, the MWE is considered as compositional, when the correspon</context>
</contexts>
<marker>Lee, 1999</marker>
<rawString>L. Lee. 1999. Measures of distributional similarity. In proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>B Keller</author>
<author>J Carroll</author>
</authors>
<title>Detecting a continuum of compositionality in phrasal verbs.</title>
<date>2003</date>
<booktitle>In proceedings of the MWE workshop. ACL.</booktitle>
<contexts>
<context position="2278" citStr="McCarthy et al., 2003" startWordPosition="332" endWordPosition="335">ity measures to test the compositionality of the MWE. These senses are induced by a graph based sense induction system, whose parameters are estimated in an unsupervised manner exploiting a number of graph connectivity measures (Korkontzelos et al., 2009). Our method partitions the context space and only uses the major senses, filtering out minor senses. In our approach the only language dependent components are a PoS tagger and a parser. There are several studies relevant to detecting compositionality of noun-noun MWEs (Baldwin et al., 2003) verb-particle constructions (Bannard et al., 2003; McCarthy et al., 2003) and verb-noun pairs (Katz and Giesbrecht, 2006). Datasets with human compositionality judgements are available for these MWE categories (Cook et al., 2008). Here, we focus on compound nominals, proper names and adjective-noun constructions. Our contributions are three-fold: firstly, we experimentally show that sense induction can assist in identifying compositional MWEs. Secondly, we show that unsupervised parameter tuning (Korkontzelos et al., 2009) results in accuracy that is comparable to the best manually selected combination of parameters. Thirdly, we propose a semi-supervised approach f</context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>D. McCarthy, B. Keller, and J. Carroll. 2003. Detecting a continuum of compositionality in phrasal verbs. In proceedings of the MWE workshop. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
</authors>
<title>WordNet: a lexical database for English.</title>
<date>1995</date>
<pages>38--11</pages>
<publisher>ACM,</publisher>
<contexts>
<context position="7834" citStr="Miller, 1995" startWordPosition="1252" endWordPosition="1253">, k are the major uses of the MWE and its semantic head, respectively. D. Determining compositionality. Given the major uses of a MWE and its semantic head, the MWE is considered as compositional, when the corresponding distributional similarity measure (Jc or Jsn) value is above a parameter threshold, sim. Otherwise, it is considered as noncompositional. 3 Test set of MWEs To the best of our knowledge there are no noun compound datasets accompanied with compositionality judgements available. Thus, we developed an algorithm to aid human annotation. For each of the 52, 217 MWEs of WordNet 3.0 (Miller, 1995) we collected: 2Chinese Whispers is not guaranteed to converge, thus 200 was adopted as the maximum number of iterations. 66 Non-compositional MWEs agony aunt, black maria, dead end, dutch oven, fish finger, fool’s paradise, goat’s rue, green light, high jump, joint chiefs, lip service, living rock, monkey puzzle, motor pool, prince Albert, stocking stuffer, sweet bay, teddy boy, think tank Compositional MWEs box white oak, cartridge brass, common iguana, closed chain, eastern pipistrel, field mushroom, hard candy, king snake, labor camp, lemon tree, life form, parenthesis-free notation, parki</context>
</contexts>
<marker>Miller, 1995</marker>
<rawString>G. A. Miller. 1995. WordNet: a lexical database for English. ACM, 38(11):39–41.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised WSD rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In proceedings of ACL.</booktitle>
<contexts>
<context position="6417" citStr="Yarowsky, 1995" startWordPosition="999" endWordPosition="1000">ghted vertex. P2 thresholds collocation frequencies and P3 collocation weights. Weighted edges are drawn based on cooccurrence of the corresponding vertices in one or more snippets (e.g. w8 and w7,9, fig. 1). In contrast to KM, frequencies for weighting vertices and edges are obtained from Yahoo! web-page counts to deal with data sparsity. Graph clustering uses Chinese Whispers2 (Biemann, 2006) to cluster the graph. Each cluster now represents a sense of the target word. KM produces larger number of clusters (uses) than expected. To reduce it we exploit the one sense per collocation property (Yarowsky, 1995). Given a cluster li, we compute the set Si of snippets that contain at least one collocation of li. Any clusters la and lb are merged if Sa ⊆ Sb. C. Comparing the induced senses. We used two techniques to measure the distributional similarity of major uses of the MWE and its semantic head, both based on Jaccard coefficient (J). “Major use” denotes the cluster of collocations which tags the most snippets. Lee (1999) shows that J performs better than other symmetric similarity measures such as cosine, Jensen-Shannon divergence, etc. The first is Jc = J(A, B) = |A∩B| |A∪B|, where A, B are sets o</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised WSD rivaling supervised methods. In proceedings of ACL.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>