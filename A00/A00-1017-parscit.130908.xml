<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001315">
<title confidence="0.99889">
A Representation for Complex and Evolving Data Dependencies
in Generation
</title>
<author confidence="0.996895">
C Mellisht, R Evanst, L Cahi11, C Dorant; D Paivat, M ReapeI, D Scottt, N Tippert
</author>
<affiliation confidence="0.9958885">
tInformation Technology Research Institute, University of Brighton, Lewes Rd, Brighton, UK
IDivision of Informatics, University of Edinburgh, 80 South Bridge, Edinburgh, UK
</affiliation>
<email confidence="0.781421">
rags@itri.brighton.ac.uk
http:/www.itri.brighton.ac.uk/projects/rags
</email>
<sectionHeader confidence="0.950867" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999985066666667">
This paper introduces an approach to represent-
ing the kinds of information that components
in a natural language generation (NLG) sys-
tem will need to communicate to one another.
This information may be partial, may involve
more than one level of analysis and may need
to include information about the history of a
derivation. We present a general representation
scheme capable of handling these cases. In ad-
dition, we make a proposal for organising inter-
module communication in an NLG system by
having a central server for this information. We
have validated the approach by a reanalysis of
an existing NLG system and through a full im-
plementation of a runnable specification.
</bodyText>
<sectionHeader confidence="0.996303" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.997761629629629">
One of the distinctive properties of natural lan-
guage generation when compared with other
language engineering applications is that it has
to take seriously the full range of linguistic rep-
resentation, from concepts to morphology, or
even phonetics. Any processing system is only
as sophisticated as its input allows, so while a
natural language understanding system might
be judged primarily by its syntactic prowess,
even if its attention to semantics, pragmatics
and underlying conceptual analysis is minimal,
a generation system is only as good as its deep-
est linguistic representations. Moreover, any at-
tempt to abstract away from individual gener-
ation systems to a more generic architectural
specification faces an even greater challenge:
not only are complex linguistic representations
required, able to support the dynamic evolu-
tionary development of data during the gener-
* Now at the MITRE Corporation, Bedford, MA, USA,
cdoranOmitre.org.
ation process, but they must do so in a generic
and flexible fashion.
This paper describes a representation devel-
oped to meet these requirements. It offers a
formally well-defined declarative representation
language, which provides a framework for ex-
pressing the complex and dynamic data require-
ments of NLG systems. The approach supports
different levels of representation, mixed repre-
sentations that cut across levels, partial and
shared structures and &apos;canned&apos; representations,
as well as dynamic relationships between data
at different stages in processing. We are using
the approach to develop a high level data model
for NLG systems as part of a generic generation
architecture called RAGS1.
The framework has been implemented in the
form of a database server for modular genera-
tion systems. As proof of concept of the frame-
work, we have reimplemented an existing NLG
system. The system we chose was the Caption
Generation System (CGS) (Mittal et al., 1995;
Mittal et al., 1998). The reimplementation in-
volved defining the interfaces to the modules of
CGS in terms of the RAGS representations and
then implementing modules that had the requi-
site input and output representations.
Generation systems, especially end-to-end,
applied generation systems, have, unsurpris-
ingly, many things in common. Reiter (1994)
proposed an analysis of such systems in terms
of a simple three stage pipeline. More recently,
the RAGS project attempted to repeat the anal-
</bodyText>
<footnote confidence="0.974403285714286">
iThis work is supported by ESPRC grants
GR/L77041 (Edinburgh) and GR/L77102 (Brighton),
RAGS: Reference Architecture for Generation Systems.
We would also like to acknowledge the contribution of
Jo Calder to the ideas and formalisation described in
this paper. In particular, parts of this paper are based
on (Calder et al., 1999).
</footnote>
<page confidence="0.998351">
119
</page>
<bodyText confidence="0.999279013888889">
ysis (Cahill et al., 1999a), but found that while
most systems did implement a pipeline, they
did not implement the same pipeline - different
functionalities occurred in different places and
different orders in different systems. In order
to accommodate this result, we sought to de-
velop an architecture that is more general than
a simple pipeline, and thus supports the range
of pipelines observed, as well as other more com-
plex control regimes (see (Cahill et al., 1999a;
Cahill et al., 1999b)). In this paper, we argue
that supporting such an architecture requires
careful consideration of the way data represen-
tations interact and develop. Any formal frame-
work for expressing the architecture must take
account of this.
2 The representational requirements
of generation systems
We noted in the introduction that generation
systems have to deal with a range of linguis-
tic information. It is natural, especially in the
context of a generic architecture proposal, to
model this breadth in terms of discrete layers
of representation: (1999a) introduce layers such
as conceptual, semantic, rhetorical, syntactic
and document structure, but the precise demar-
cation is not as important here as the princi-
ple. The different kinds of information are typi-
cally represented differently, and built up sepa-
rately. However the layers are far from indepen-
dent: objects at one layer are directly related to
those at others, forming chains of dependency
from conceptual through rhetorical and seman-
tic structure to final syntactic and document re-
alisation. This means that data resources, such
as grammars and lexicons, and processing mod-
ules in the system, are often defined in terms of
mixed data: structures that include informa-
tion in more than one representation layer. So
the ability to represent such mixed structures
in a single formal framework is an important
property of a generic data proposal.
In addition, it is largely standard in gener-
ation as elsewhere in language applications, to
make extensive use of partial representations,
often using a type system to capture grades of
underspecification. An immediate corollary of
providing support for partial structures is the
notion that they may become further specified
over time, that data structures evolve. If the
framework seeks to avoid over-commitment to
particular processing strategies it needs to pro-
vide a way of representing such evolution ex-
plicitly if required, rather than relying on de-
structive modification of a structure. Related
to this, it should provide explicit support for
representing alternative specifications at any
point. Finally, to fully support efficient pro-
cessing across the range of applications, from
the simple to the most complex, the represen-
tation must allow for compact sharing of infor-
mation in tangled structures (two structures
which share components).
In addition to these direct requirements of the
generation task itself, additional requirements
arise from more general methodological consid-
erations: we desire a representation that is for-
mally well defined, allows for theoretical rea-
soning about the data and performance of sys-
tems, and supports control regimes from simple
deterministic pipelines to complex parallel ar-
chitectures.
</bodyText>
<sectionHeader confidence="0.979338" genericHeader="method">
3 The Representation Scheme
</sectionHeader>
<bodyText confidence="0.999618375">
In this section, we present our proposal for a
general representation scheme capable of cover-
ing the above requirements. Our formulation is
layered: the foundation is a simple, flexible, rig-
orously defined graph representation formalism,
on top of which we introduce notions of com-
plex types and larger data structures and rela-
tionships between them. This much is sufficient
to capture the requirements just discussed. We
suppose a yet higher level of specification could
capture a more constraining data model but
make no specific proposals about this here, how-
ever the following sections use examples that do
conform to such a higher level data model.
The lowest level of the representation scheme
is:
</bodyText>
<listItem confidence="0.995996142857143">
• relational: the basic data entity is x y,
an arrow representing a relation from ob-
ject x to object y;
• typed: objects and arrows have an asso-
ciated type system, so it is possible to de-
fine classes and subclasses of objects and
arrows.
</listItem>
<bodyText confidence="0.780829333333333">
At the most fundamental level, this is more or
less the whole definition. There is no commit-
ment to what object or arrow types there are or
</bodyText>
<page confidence="0.991736">
120
</page>
<bodyText confidence="0.9999505">
how they relate to each other. So a representa-
tion allowed by the scheme consists of:
</bodyText>
<listItem confidence="0.9636045">
• a set of objects, organised into types;
• a set of binary relations, organised into
types;
• a set of arrows, each indicating that a rela-
tion holds between one object and another
object.
</listItem>
<subsectionHeader confidence="0.58062">
Sets, sequences and functions
</subsectionHeader>
<bodyText confidence="0.968689176470588">
For the next level, we introduce more struc-
ture in the type system to support sets, se-
quences and functions. Objects are always
atomic (though they can be of type set, se-
quence or function) — it is not possible to make
an object which actually is a set of two other
objects (as you might with data structures in a
computer program). To create a set, we intro-
duce a set type for the object, and a set mem-
bership arrow type (el), that links the set&apos;s el-
ements to the set. Similarly, for a sequence, we
introduce a sequence type and sequence mem-
ber arrow types (1-el, 2-el, 3-el, ...), and for a
function, we have a complex type which spec-
ifies the types of the arrows that make up the
domain and the range of the function.
SemRep
</bodyText>
<figureCaption confidence="0.680070666666667">
Figure 1: The partial semantic representation
of &amp;quot;The second chart shows the number of days
on the market&amp;quot;
</figureCaption>
<bodyText confidence="0.9977238125">
As an example, consider Figure 1, which
shows a semantic representation (Sem Rep) from
the CGS reimplementation. Here, the tree
nodes correspond to objects, each labelled with
its type. The root node is of type Sem Rep, and
although it is not an explicit sequence type, we
can see that it is a triple, as it has three sequence
member arrows (with types 1-el, 2-el and 3-el).
Its first arrow&apos;s target is an object of type DR
(Discourse Referent). Its second represents a set
of Sem Pred (Semantic Predicate) objects, and in
this case there&apos;s just one, of type show. Its third
element is a (partial) function, from Role arrow
types (agent and affected are both subtypes of
Role) to SemReps. (In this case, the SemReps
have not yet been fully specified.)
</bodyText>
<subsectionHeader confidence="0.606053">
Local and non-local arrows
</subsectionHeader>
<bodyText confidence="0.999961488888889">
The second extension to the basic representa-
tion scheme is to distinguish two different ab-
stract kinds of arrows — local and non-local.
Fundamentally we are representing just a homo-
geneous network of objects and relationships. In
the example above we saw a network of arrows
that we might want to view as a single data
structure, and other major data types might
similarly appear as networks. Additionally, we
want to be able to express relationships between
these larger &apos;structures&apos; — between structures
of the same type (alternative solutions, or re-
vised versions) or of different types (semantic
and syntactic for example). To capture these
distinctions among arrows, we classify our ar-
row types as local or non-local (we could do
this in the type system itself, or leave it as an
informal distinction). Local arrows are used to
build up networks that we think of as single
data structures. Non-local arrows express rela-
tionships between such data structures.
All the arrow types we saw above were local.
Examples of non-local arrows might include:
realises These arroWs link something more ab-
stract to something less abstract that re-
alises it. Chains of realises arrows might
lead from the original conceptual input to
the generator through rhetorical, seman-
tic and syntactic structures to the actual
words that express the input.
revises These arrows link a structure to an-
other one of the same type, which is con-
sidered to be a &apos;better&apos; solution — perhaps
because it is more instantiated. It is impor-
tant to note that parts of larger structures
can be revised without revising the entire
structure.
coreference These arrows link structures
which are somehow &amp;quot;parallel&amp;quot; and which
perhaps share some substructure, i.e., tan-
gled structures. For instance, document
representations may be linked to rhetorical
representations, either as whole isomorphic
structures or at the level of individual con-
stituents.
</bodyText>
<figure confidence="0.991078875">
3-d
set(SemPred)
agent
fun(Role,SemRep)
affected
DR
el
show SemRep SemRep
</figure>
<page confidence="0.980549">
121
</page>
<bodyText confidence="0.998617347826087">
Notice that the representation scheme does
not enforce any kind of well-formedness with
respect to local and non-local arrows. In fact,
although it is natural to think of a &apos;structure&apos; as
being a maximal network of local arrows with
a single root object, there&apos;s no reason why this
should be so - networks with multiple roots rep-
resent tangled structures (structures that share
content), networks that include non-local links
might be mixed representations, containing in-
formation of more than one sort. Such tech-
niques might be useful for improving generator
efficiency, or representing canned text or tem-
plates, cf. (Calder et al., 1999).
Partial and Opaque structures
Partial structures are essential when a module
needs to produce a skeleton of a representa-
tion that it does not have the competence to
completely fill out. For instance, lexical choice
brings with it certain syntactic commitments,
but in most NLG systems lexical choice occurs
some time before a grammar is consulted to
flesh out syntactic structure in detail.
</bodyText>
<figureCaption confidence="0.999191">
Figure 2: A partial structure
</figureCaption>
<bodyText confidence="0.999983518518518">
By simply leaving out local arrows, we can
represent a range of partial structures. Con-
sider Fig. 2, where the triangles represent local
structure, representing a sentence object and its
component verb phrase. There is a link to a sub-
ject noun phrase object, but none of the local
arrows of the actual noun phrase are present. In
subsequent processing this local structure might
be filled in. This is possible as long as the noun
phrase object has been declared to be of the
right type.
An opaque structure is one which has an in-
complete derivational history - for example part
of a syntactic structure without any correspond-
ing semantic structure. Three possible reasons
for having such structures are (a) to allow struc-
ture to be introduced that the generator is not
capable of producing directly, (b) to prevent the
generator from interfering with the structure
thus built (for example, by trying to modify an
idiom in an inappropriate way), or (c) to im-
prove generator efficiency by hiding detail that
may lead to wasteful processing. An opaque
structure is represented simply by the failure
to include a realises arrow to that structure.
Such structures provide the basis for a gener-
alised approach to &amp;quot;canning&amp;quot;.
</bodyText>
<sectionHeader confidence="0.999023" genericHeader="method">
4 Implementation
</sectionHeader>
<bodyText confidence="0.999272777777778">
There are many ways that modules in an
NLG system could communicate information
using the representation scheme just outlined.
Here we describe a particularly general model
of inter-module communication, based around
modules communicating with a single cen-
tralised repository of data called the whiteboard
(Calder et al., 1999). A whiteboard is a cumu-
lative typed relational blackboard:
</bodyText>
<listItem confidence="0.992867666666667">
• typed and relational: because it is based
on using the above representation scheme;
• a blackboard: a control architec-
ture and data store shared between
processing modules; typically, modules
add/change/remove objects in the data
store, examine its contents, and/or ask to
be notified of changes;
• cumulative: unlike standard blackboards,
once data is added, it can&apos;t be changed or
removed. So a structure is built incremen-
tally by making successive copies of it (or of
constituents of it) linked by revises links
(although actually, there&apos;s no constraint on
the order in which they are built).
</listItem>
<bodyText confidence="0.987917538461539">
A whiteboard allows modules to add ar-
rows (typically forming networks through ar-
rows sharing source or target objects), to in-
spect the set of arrows looking for particular
configurations of types, or to be informed when
a particular type of arrow (or group of arrows)
is added.
The whiteboard is an active database server.
This means that it runs as an independent pro-
cess that other modules connect to by appropri-
ate means. There are essentially three kinds of
interaction that a module might have with the
whiteboard server:
</bodyText>
<listItem confidence="0.987476">
• publish - add an arrow or arrows to the
whiteboard;
</listItem>
<equation confidence="0.385573">
NP-comp VP-comp
</equation>
<page confidence="0.951231">
122
</page>
<listItem confidence="0.9781405">
• query - look for an arrow or arrows in the
whiteboard;
• wait - register interest in an arrow or ar-
rows appearing in the whiteboard.
</listItem>
<bodyText confidence="0.999742975609756">
In both query and wait, arrows are specified
by type, and with a hierarchical type system on
objects and relations, this amounts to a pattern
that matches arrows of subtypes as well. The
wait function allows the whiteboard to take the
initiative in processing - if a module waits on a
query then the whiteboard waits until the query
is satisfied, and then tells the module about it.
So the module does not have to continuously
scan the whiteboard for work to do, but can
let the whiteboard tell it as soon as anything
interesting happens.
Typically a module will start up and regis-
ter interest in the kind of arrow that represents
the module&apos;s input data. It will then wait for
the whiteboard to notify it of instances of that
data (produced by other modules), and when-
ever anything turns up, it processes it, adding
its own results to the whiteboard. All the mod-
ules do this asynchronously, and processing con-
tinues until no module has any more work to
do. This may sound like a recipe for confusion,
but more standard pipelined behaviour is not
much different. In fact, pipelining is exactly a
data-based constraint - the second module in a
pipeline does not start until the first one pro-
duces its output.
However, to be a strict pipeline, the first mod-
ule must produce all of its output before the sec-
ond one starts. This can be achieved simply by
making the first module produce all its output
at once, but sometimes that is not ideal - for ex-
ample if the module is recursive and wishes to
react to its own output. Alternative strategies
include the use of markers in the whiteboard,
so that modules can tell each other that they&apos;ve
finished processing (by adding a marker), or
extending the whiteboard architecture itself so
that modules can tell the whiteboard that they
have finished processing, and other modules can
wait for that to occur.
</bodyText>
<sectionHeader confidence="0.877039" genericHeader="method">
5 Reconstruction of the Caption
Generation System
</sectionHeader>
<bodyText confidence="0.999811615384615">
In order to prove this representation scheme
in practice, we have implemented the white-
board in Sicstus Prolog and used it to support
data communications between modules in a re-
construction of the Caption Generation System
(Mittal et al., 1995). CGS is a system developed
at the University of Pittsburgh, which takes in-
put from the SAGE graphics presentation sys-
tem (Roth et al., 1994) and generates captions
for the graphics SAGE produces. We selected it
for this effort because it appeared to be a fairly
simple pipelined system, with modules perform-
ing clearly defined linguistic tasks. As such, we
thought it would be a good test case for our
whiteboard specification.
Although the CGS is organised as a pipeline,
shown in Figure 3, the representations commu-
nicated between the modules do not correspond
to complete, separate instances of RAGS data-
type representations. Instead, the representa-
tions at the various levels accumulate along the
pipeline or are revised in a way that does not
correspond exactly to module boundaries. Fig-
ure 3 gives a simple picture of how the different
levels of representation build up. The labels for
the RAGS representations refer to the following:
</bodyText>
<listItem confidence="0.9999284">
• I = conceptual;
• II = semantic;
• III = rhetorical;
• IV = document;
• V = syntactic.
</listItem>
<bodyText confidence="0.999814882352941">
For instance, some semantic (II) information is
produced by the Text Planning module, and
more work is done on this by Aggregation, but
the semantic level of representation is not com-
plete and final until the Referring Expression
module has run. Also, for instance, at the
point where the Ordering module has run, there
are partially finished versions of three different
types of representation. It is clear from this that
the interfaces between the modules are more
complex than could be accounted for by just re-
ferring to the individual levels of representation
of RAGS. The ability to express combinations of
structures and partial structures was fundamen-
tal to the reimplementation of CGS. We high-
light below a few of the interesting places where
these features were used.
</bodyText>
<page confidence="0.995635">
123
</page>
<figure confidence="0.998686444444444">
!-el
AbsSemRep
3-el SemRep
3-el
I-el
-s.et(KI3Pred) _ _
DR
fun(Role,set(KBId))
affected
agent
set(SemPred)
dom-1822
fun(Role,set(SemRep))
present sel(KBId) _ ___
affected
_
el
chart1 chart2
</figure>
<figureCaption confidence="0.999757333333333">
Figure 4: Combined Abstract Semantic Representation and Concrete Semantic Representation for
the output: &amp;quot;These two charts present information about house sales from data-set ts-1740&amp;quot;
Figure 3: A RAGS view of the CGS system
</figureCaption>
<subsectionHeader confidence="0.994057">
5.1 Referring Expression Generation
</subsectionHeader>
<bodyText confidence="0.999016857142857">
In many NLG systems, (nominal) referring ex-
pression generation is an operation that is in-
voked at a relatively late stage, after the struc-
ture of individual sentences is fairly well speci-
fied (at least semantically). However, referring
expression generation needs to go right back to
the original world model/knowledge base to se-
lect appropriate semantic content to realise a
particular conceptual item as an NP (whereas
all other content has been determined much ear-
lier). In fact, there seems to be no place to
put referring expression generation in a pipeline
without there being some resulting awkward-
ness.
</bodyText>
<subsectionHeader confidence="0.936911">
present SemRep SemRep
</subsectionHeader>
<bodyText confidence="0.999982666666667">
In RAGS, pointers to conceptual items can
be included inside the first, &amp;quot;abstract&amp;quot;, level of
semantic representation (AbsSem Rep), which is
intended to correspond to an initial bundling of
conceptual material under semantic predicates.
On the other hand, the final, &amp;quot;concrete&amp;quot;, level
of semantic representation (Sem Rep) is more
like a fully-fledged logical form and it is no
longer appropriate for conceptual material to
be included there. In the CGS reimplementa-
tion, it is necessary for the Aggregation mod-
ule to reason about the final high-level semantic
representation of sentences, which means that
this module must have access to &amp;quot;concrete&amp;quot; se-
mantic representations. The Referring Expres-
sion generation module does not run until later,
which means that these representations cannot
be complete.
Our way around this was to ensure that the
initial computation of concrete semantics from
abstract semantics (done as part of Aggrega-
tion here) left a record of the relationship by
including realises arrows between correspond-
ing structures. That computation could not be
completed whenever it reached conceptual ma-
terial - at that point it left a &amp;quot;hole&amp;quot; (an ob-
ject with no further specification) in the con-
crete semantic representation linked back to the
conceptual material. When referring expression
was later invoked, by following the arrows in the
</bodyText>
<figure confidence="0.993979714285714">
Lexical
Choice
Module
FUF
RAGS representations
I II III IV V
_J
</figure>
<page confidence="0.99529">
124
</page>
<bodyText confidence="0.999940714285714">
resulting mixed structure, it could tell exactly
which conceptual entity needed to be referred
to and where in the semantic structure the re-
sulting semantic expression should be placed.
Figure 4 shows the resulting arrangement for
one example CGS sentence. The dashed lines
indicate realises, i.e. non-local, arrows.
</bodyText>
<subsectionHeader confidence="0.99957">
5.2 Handling Centering Information
</subsectionHeader>
<bodyText confidence="0.999909731707317">
The CGS Centering module reasons about the
entities that will be referred to in each sentence
and produces a representation which records the
forward and backward-looking centers (Grosz et
al., 1995). This representation is later used by
the Referring Expression generation module in
making pronominalisation decisions. This in-
formation could potentially also be used in the
Realisation module.
Since Centering is not directly producing re-
ferring expressions, its results have to sit around
until they can actually be used. This posed
a possible problem for us, because the RAGS
framework does not provide a specific level of
representation for Centering information and
therefore seems on first sight unable to account
for this information being communicated be-
tween modules. The solution to the problem
came when we realised that Centering informa-
tion is in fact a kind of abstract syntactic in-
formation. Although one might not expect ab-
stract syntactic structure to be determined until
the Realisation module (or perhaps slightly ear-
lier), the CGS system starts this computation in
the Centering module.
Thus in the reimplementation, the Centering
module computes (very partial) abstract syn-
tactic representations for the entities that will
eventually be realised as NPs. These represen-
tations basically just indicate the relevant Cen-
tering statuses using syntactic features. Figure
5 shows an example of the semantics for a typi-
cal output sentence and the two partial abstract
syntactic representations computed by the Cen-
tering module for what will be the two NPs in
that sentence2. As before, dashed lines indicate
realises arrows. Of course, given the discussion
of the last section, the semantic representation
objects that are the source of these arrows are in
fact themselves linked back to conceptual enti-
ties by being the destination of realises arrows
</bodyText>
<footnote confidence="0.490452">
2FVM = Feature Value Matrix.
</footnote>
<bodyText confidence="0.99627275">
from them.
When the Referring Expression generation
module runs, it can recover the Centering infor-
mation by inspecting the partial syntactic rep-
resentations for the phrases it is supposed to
generate. These partial representations are then
further instantiated by, e.g., Lexical Choice at
later stages of the pipeline.
</bodyText>
<sectionHeader confidence="0.999189" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999976853658537">
The representation scheme we have proposed
here is designed specifically to support the re-
quirements of the current state-of-the-art NLG
systems, and our pilot implementation demon-
strates the practical applicability of the pro-
posal. Tangled, partial and mixed structures
are of obvious utility to any system with a flex-
ible control strategy and we have shown here
how the proposed representation scheme sup-
ports them. By recording the derivational his-
tory of computations, it also supports decisions
which partly depend on earlier stages of the
generation process (e.g., possibly, lexical choice)
and revision-based architectures which typically
make use of such information. We have shown
how the representation scheme might be the ba-
sis for an inter-module communication model,
the whiteboard, which supports a wide range of
processing strategies that require the represen-
tation of complex and evolving data dependen-
cies. The fact that the whiteboard is cumula-
tive, or monotonic in a logical sense, means that
the whiteboard also supports reasoning about
the behaviour of NLG systems implemented in
terms of it. This is something that we would
like to exploit directly in the future.
The reimplementation of the CGS system
in the RAGS framework was a challenge to
the framework because it was a system that
had already been developed completely inde-
pendently. Even though we did not always un-
derstand the detailed motivation for the struc-
ture of CGS being as it was, within a short time
we reconstructed a working system with mod-
ules that corresponded closely to the original
CGS modules. The representation scheme we
have proposed here was a key ingredient in giv-
ing us the flexibility to achieve the particular
processing scheme used by CGS whilst remain-
ing faithful to the (relatively simple) RAGS
data model.
</bodyText>
<page confidence="0.989962">
125
</page>
<figure confidence="0.689809">
SemRep
</figure>
<figureCaption confidence="0.998643">
Figure 5: Arrangement of centering information for the output sentence above
</figureCaption>
<figure confidence="0.99629770967742">
2
1-el
el
present
3-el
set(SemPred)
agent
SemRep
Lex
Args
FVM
AbsSynRep
fun(Role,set(SemRep))
ecred
%SemRep
s.
AbsSynRep &apos;40
I-el
Lex • Args
2-el 3-el
4-el
Adjs
AdjS
forward-looking-center
fun(Funs,ArgSpec)
forward-looking-center
backward-looking-center
fun(Funs,ArgSpec)
backward-looking-center
I-el
DR
</figure>
<bodyText confidence="0.999846875">
The representation scheme is useful in situa-
tions where modules need to be defined and im-
plemented to work with other modules, possibly
developed by different people. In such cases, the
representation scheme we propose permits pre-
cise definition of the interfaces of the modules,
even where they are not restricted to a single
&apos;level&apos; of representation. Even though the con-
trol structure of CGS is quite simple, we found
that the use of a centralised whiteboard was use-
ful in helping us to agree on interfaces and on
the exact contribution that each module should
be making. Ultimately, it is hoped that the use
of a scheme of this type will permit much more
widespread &apos;plug-and-play&apos; among members of
the NLG community.
</bodyText>
<sectionHeader confidence="0.999527" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999632704545455">
Lynne Cahill, Christy Doran, Roger Evans, Chris
Mellish, Daniel Paiva, Mike Reape, Donia Scott,
and Neil Tipper. 1999a. In Search of a Reference
Architecture for NLG Systems. In Proceedings of
the 7th European Workshop on Natural Language
Generation, pages 77-85, Toulouse.
Lynne Cahill, Christy Doran, Roger Evans, Chris
Mellish, Daniel Paiva, Mike Reape, Donia Scott,
and Neil Tipper. 1999b. Towards a Reference
Architecture for Natural Language Genera-
tion Systems. Technical Report ITRI-99-14,
Information Technology Research Institute
(ITRI), University of Brighton. Available at
http://www.itri.brighton.ac.uk/projects/rags.
Jo Calder, Roger Evans, Chris Mellish, and Mike
Reape. 1999. &amp;quot;Free choice&amp;quot; and templates: how
to get both at the same time. In &amp;quot;May I speak
freely?&amp;quot; Between templates and free choice in nat-
ural language generation, number D-99-01, pages
19-24. Saarbriicken.
B.J. Grosz, A.K. Joshi, and S. Weinstein. 1995.
Centering: a framework for modelling the local co-
herence of discourse. Computational Linguistics,
21(2) :203-226.
V. 0. Mittal, S. Roth, J. D. Moore, J. Mattis, and
G. Carenini. 1995. Generating explanatory cap-
tions for information graphics. In Proceedings of
the 15th International Joint Conference on Ar-
tificial Intelligence (IJCAI&apos;95), pages 1276-1283,
Montreal, Canada, August.
V. 0. Mittal, J. D. Moore, G. Carenini, and S. Roth.
1998. Describing complex charts in natural lan-
guage: A caption generation system. Computa-
tional Linguistics, 24(3):431-468.
Ehud Reiter. 1994. Has a consensus NL generation
architecture appeared and is it psycholinguisti-
cally plausible? In Proceedings of the Seventh In-
ternational Workshop on Natural Language Gen-
eration, pages 163-170, Kennebunkport, Maine.
Steven F. Roth, John Kolojejchick, Joe Mattis, and
Jade Goldstein. 1994. Interactive graphic design
using automatic presentation knowledge. In Pro-
ceedings of CHI&apos;94: Human Factors in Computing
Systems, Boston, MA.
</reference>
<page confidence="0.998528">
126
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.593241">
<title confidence="0.998746">A Representation for Complex and Evolving Data Dependencies in Generation</title>
<author confidence="0.731662">R L D M D N</author>
<affiliation confidence="0.714211">Technology Research Institute, University of Brighton, Lewes Rd, Brighton, UK</affiliation>
<address confidence="0.962306">of Informatics, University of Edinburgh, 80 South Bridge, Edinburgh, UK</address>
<email confidence="0.99838">rags@itri.brighton.ac.uk</email>
<web confidence="0.996883">http:/www.itri.brighton.ac.uk/projects/rags</web>
<abstract confidence="0.9964548125">This paper introduces an approach to representing the kinds of information that components in a natural language generation (NLG) system will need to communicate to one another. This information may be partial, may involve more than one level of analysis and may need to include information about the history of a derivation. We present a general representation scheme capable of handling these cases. In addition, we make a proposal for organising intermodule communication in an NLG system by having a central server for this information. We have validated the approach by a reanalysis of an existing NLG system and through a full implementation of a runnable specification.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Lynne Cahill</author>
<author>Christy Doran</author>
<author>Roger Evans</author>
<author>Chris Mellish</author>
<author>Daniel Paiva</author>
<author>Mike Reape</author>
<author>Donia Scott</author>
<author>Neil Tipper</author>
</authors>
<title>In Search of a Reference Architecture for NLG Systems.</title>
<date>1999</date>
<booktitle>In Proceedings of the 7th European Workshop on Natural Language Generation,</booktitle>
<pages>77--85</pages>
<location>Toulouse.</location>
<contexts>
<context position="3864" citStr="Cahill et al., 1999" startWordPosition="588" endWordPosition="591">ystems, especially end-to-end, applied generation systems, have, unsurprisingly, many things in common. Reiter (1994) proposed an analysis of such systems in terms of a simple three stage pipeline. More recently, the RAGS project attempted to repeat the analiThis work is supported by ESPRC grants GR/L77041 (Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Architecture for Generation Systems. We would also like to acknowledge the contribution of Jo Calder to the ideas and formalisation described in this paper. In particular, parts of this paper are based on (Calder et al., 1999). 119 ysis (Cahill et al., 1999a), but found that while most systems did implement a pipeline, they did not implement the same pipeline - different functionalities occurred in different places and different orders in different systems. In order to accommodate this result, we sought to develop an architecture that is more general than a simple pipeline, and thus supports the range of pipelines observed, as well as other more complex control regimes (see (Cahill et al., 1999a; Cahill et al., 1999b)). In this paper, we argue that supporting such an architecture requires careful consideration of the way data representations int</context>
</contexts>
<marker>Cahill, Doran, Evans, Mellish, Paiva, Reape, Scott, Tipper, 1999</marker>
<rawString>Lynne Cahill, Christy Doran, Roger Evans, Chris Mellish, Daniel Paiva, Mike Reape, Donia Scott, and Neil Tipper. 1999a. In Search of a Reference Architecture for NLG Systems. In Proceedings of the 7th European Workshop on Natural Language Generation, pages 77-85, Toulouse.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lynne Cahill</author>
<author>Christy Doran</author>
<author>Roger Evans</author>
<author>Chris Mellish</author>
<author>Daniel Paiva</author>
<author>Mike Reape</author>
<author>Donia Scott</author>
<author>Neil Tipper</author>
</authors>
<title>Towards a Reference Architecture for Natural Language Generation Systems.</title>
<date>1999</date>
<tech>Technical Report ITRI-99-14,</tech>
<institution>Information Technology Research Institute (ITRI), University of Brighton.</institution>
<note>Available at http://www.itri.brighton.ac.uk/projects/rags.</note>
<contexts>
<context position="3864" citStr="Cahill et al., 1999" startWordPosition="588" endWordPosition="591">ystems, especially end-to-end, applied generation systems, have, unsurprisingly, many things in common. Reiter (1994) proposed an analysis of such systems in terms of a simple three stage pipeline. More recently, the RAGS project attempted to repeat the analiThis work is supported by ESPRC grants GR/L77041 (Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Architecture for Generation Systems. We would also like to acknowledge the contribution of Jo Calder to the ideas and formalisation described in this paper. In particular, parts of this paper are based on (Calder et al., 1999). 119 ysis (Cahill et al., 1999a), but found that while most systems did implement a pipeline, they did not implement the same pipeline - different functionalities occurred in different places and different orders in different systems. In order to accommodate this result, we sought to develop an architecture that is more general than a simple pipeline, and thus supports the range of pipelines observed, as well as other more complex control regimes (see (Cahill et al., 1999a; Cahill et al., 1999b)). In this paper, we argue that supporting such an architecture requires careful consideration of the way data representations int</context>
</contexts>
<marker>Cahill, Doran, Evans, Mellish, Paiva, Reape, Scott, Tipper, 1999</marker>
<rawString>Lynne Cahill, Christy Doran, Roger Evans, Chris Mellish, Daniel Paiva, Mike Reape, Donia Scott, and Neil Tipper. 1999b. Towards a Reference Architecture for Natural Language Generation Systems. Technical Report ITRI-99-14, Information Technology Research Institute (ITRI), University of Brighton. Available at http://www.itri.brighton.ac.uk/projects/rags.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo Calder</author>
<author>Roger Evans</author>
<author>Chris Mellish</author>
<author>Mike Reape</author>
</authors>
<title>Free choice&amp;quot; and templates: how to get both at the same time. In &amp;quot;May I speak freely?&amp;quot; Between templates and free choice in natural language generation, number</title>
<date>1999</date>
<pages>99--01</pages>
<publisher>Saarbriicken.</publisher>
<contexts>
<context position="3833" citStr="Calder et al., 1999" startWordPosition="582" endWordPosition="585">ut representations. Generation systems, especially end-to-end, applied generation systems, have, unsurprisingly, many things in common. Reiter (1994) proposed an analysis of such systems in terms of a simple three stage pipeline. More recently, the RAGS project attempted to repeat the analiThis work is supported by ESPRC grants GR/L77041 (Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Architecture for Generation Systems. We would also like to acknowledge the contribution of Jo Calder to the ideas and formalisation described in this paper. In particular, parts of this paper are based on (Calder et al., 1999). 119 ysis (Cahill et al., 1999a), but found that while most systems did implement a pipeline, they did not implement the same pipeline - different functionalities occurred in different places and different orders in different systems. In order to accommodate this result, we sought to develop an architecture that is more general than a simple pipeline, and thus supports the range of pipelines observed, as well as other more complex control regimes (see (Cahill et al., 1999a; Cahill et al., 1999b)). In this paper, we argue that supporting such an architecture requires careful consideration of t</context>
<context position="12730" citStr="Calder et al., 1999" startWordPosition="2050" endWordPosition="2053">resentation scheme does not enforce any kind of well-formedness with respect to local and non-local arrows. In fact, although it is natural to think of a &apos;structure&apos; as being a maximal network of local arrows with a single root object, there&apos;s no reason why this should be so - networks with multiple roots represent tangled structures (structures that share content), networks that include non-local links might be mixed representations, containing information of more than one sort. Such techniques might be useful for improving generator efficiency, or representing canned text or templates, cf. (Calder et al., 1999). Partial and Opaque structures Partial structures are essential when a module needs to produce a skeleton of a representation that it does not have the competence to completely fill out. For instance, lexical choice brings with it certain syntactic commitments, but in most NLG systems lexical choice occurs some time before a grammar is consulted to flesh out syntactic structure in detail. Figure 2: A partial structure By simply leaving out local arrows, we can represent a range of partial structures. Consider Fig. 2, where the triangles represent local structure, representing a sentence objec</context>
<context position="14715" citStr="Calder et al., 1999" startWordPosition="2374" endWordPosition="2377">), or (c) to improve generator efficiency by hiding detail that may lead to wasteful processing. An opaque structure is represented simply by the failure to include a realises arrow to that structure. Such structures provide the basis for a generalised approach to &amp;quot;canning&amp;quot;. 4 Implementation There are many ways that modules in an NLG system could communicate information using the representation scheme just outlined. Here we describe a particularly general model of inter-module communication, based around modules communicating with a single centralised repository of data called the whiteboard (Calder et al., 1999). A whiteboard is a cumulative typed relational blackboard: • typed and relational: because it is based on using the above representation scheme; • a blackboard: a control architecture and data store shared between processing modules; typically, modules add/change/remove objects in the data store, examine its contents, and/or ask to be notified of changes; • cumulative: unlike standard blackboards, once data is added, it can&apos;t be changed or removed. So a structure is built incrementally by making successive copies of it (or of constituents of it) linked by revises links (although actually, the</context>
</contexts>
<marker>Calder, Evans, Mellish, Reape, 1999</marker>
<rawString>Jo Calder, Roger Evans, Chris Mellish, and Mike Reape. 1999. &amp;quot;Free choice&amp;quot; and templates: how to get both at the same time. In &amp;quot;May I speak freely?&amp;quot; Between templates and free choice in natural language generation, number D-99-01, pages 19-24. Saarbriicken.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Grosz</author>
<author>A K Joshi</author>
<author>S Weinstein</author>
</authors>
<title>Centering: a framework for modelling the local coherence of discourse.</title>
<date>1995</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<issue>2</issue>
<pages>203--226</pages>
<contexts>
<context position="23120" citStr="Grosz et al., 1995" startWordPosition="3760" endWordPosition="3763">Lexical Choice Module FUF RAGS representations I II III IV V _J 124 resulting mixed structure, it could tell exactly which conceptual entity needed to be referred to and where in the semantic structure the resulting semantic expression should be placed. Figure 4 shows the resulting arrangement for one example CGS sentence. The dashed lines indicate realises, i.e. non-local, arrows. 5.2 Handling Centering Information The CGS Centering module reasons about the entities that will be referred to in each sentence and produces a representation which records the forward and backward-looking centers (Grosz et al., 1995). This representation is later used by the Referring Expression generation module in making pronominalisation decisions. This information could potentially also be used in the Realisation module. Since Centering is not directly producing referring expressions, its results have to sit around until they can actually be used. This posed a possible problem for us, because the RAGS framework does not provide a specific level of representation for Centering information and therefore seems on first sight unable to account for this information being communicated between modules. The solution to the pr</context>
</contexts>
<marker>Grosz, Joshi, Weinstein, 1995</marker>
<rawString>B.J. Grosz, A.K. Joshi, and S. Weinstein. 1995. Centering: a framework for modelling the local coherence of discourse. Computational Linguistics, 21(2) :203-226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Roth Mittal</author>
<author>J D Moore</author>
<author>J Mattis</author>
<author>G Carenini</author>
</authors>
<title>Generating explanatory captions for information graphics.</title>
<date>1995</date>
<booktitle>In Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI&apos;95),</booktitle>
<pages>1276--1283</pages>
<location>Montreal, Canada,</location>
<contexts>
<context position="3009" citStr="Mittal et al., 1995" startWordPosition="456" endWordPosition="459">erent levels of representation, mixed representations that cut across levels, partial and shared structures and &apos;canned&apos; representations, as well as dynamic relationships between data at different stages in processing. We are using the approach to develop a high level data model for NLG systems as part of a generic generation architecture called RAGS1. The framework has been implemented in the form of a database server for modular generation systems. As proof of concept of the framework, we have reimplemented an existing NLG system. The system we chose was the Caption Generation System (CGS) (Mittal et al., 1995; Mittal et al., 1998). The reimplementation involved defining the interfaces to the modules of CGS in terms of the RAGS representations and then implementing modules that had the requisite input and output representations. Generation systems, especially end-to-end, applied generation systems, have, unsurprisingly, many things in common. Reiter (1994) proposed an analysis of such systems in terms of a simple three stage pipeline. More recently, the RAGS project attempted to repeat the analiThis work is supported by ESPRC grants GR/L77041 (Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Ar</context>
<context position="18252" citStr="Mittal et al., 1995" startWordPosition="2985" endWordPosition="2988">rnative strategies include the use of markers in the whiteboard, so that modules can tell each other that they&apos;ve finished processing (by adding a marker), or extending the whiteboard architecture itself so that modules can tell the whiteboard that they have finished processing, and other modules can wait for that to occur. 5 Reconstruction of the Caption Generation System In order to prove this representation scheme in practice, we have implemented the whiteboard in Sicstus Prolog and used it to support data communications between modules in a reconstruction of the Caption Generation System (Mittal et al., 1995). CGS is a system developed at the University of Pittsburgh, which takes input from the SAGE graphics presentation system (Roth et al., 1994) and generates captions for the graphics SAGE produces. We selected it for this effort because it appeared to be a fairly simple pipelined system, with modules performing clearly defined linguistic tasks. As such, we thought it would be a good test case for our whiteboard specification. Although the CGS is organised as a pipeline, shown in Figure 3, the representations communicated between the modules do not correspond to complete, separate instances of R</context>
</contexts>
<marker>Mittal, Moore, Mattis, Carenini, 1995</marker>
<rawString>V. 0. Mittal, S. Roth, J. D. Moore, J. Mattis, and G. Carenini. 1995. Generating explanatory captions for information graphics. In Proceedings of the 15th International Joint Conference on Artificial Intelligence (IJCAI&apos;95), pages 1276-1283, Montreal, Canada, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D Moore Mittal</author>
<author>G Carenini</author>
<author>S Roth</author>
</authors>
<title>Describing complex charts in natural language: A caption generation system.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<pages>24--3</pages>
<contexts>
<context position="3031" citStr="Mittal et al., 1998" startWordPosition="460" endWordPosition="463">sentation, mixed representations that cut across levels, partial and shared structures and &apos;canned&apos; representations, as well as dynamic relationships between data at different stages in processing. We are using the approach to develop a high level data model for NLG systems as part of a generic generation architecture called RAGS1. The framework has been implemented in the form of a database server for modular generation systems. As proof of concept of the framework, we have reimplemented an existing NLG system. The system we chose was the Caption Generation System (CGS) (Mittal et al., 1995; Mittal et al., 1998). The reimplementation involved defining the interfaces to the modules of CGS in terms of the RAGS representations and then implementing modules that had the requisite input and output representations. Generation systems, especially end-to-end, applied generation systems, have, unsurprisingly, many things in common. Reiter (1994) proposed an analysis of such systems in terms of a simple three stage pipeline. More recently, the RAGS project attempted to repeat the analiThis work is supported by ESPRC grants GR/L77041 (Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Architecture for Generat</context>
</contexts>
<marker>Mittal, Carenini, Roth, 1998</marker>
<rawString>V. 0. Mittal, J. D. Moore, G. Carenini, and S. Roth. 1998. Describing complex charts in natural language: A caption generation system. Computational Linguistics, 24(3):431-468.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
</authors>
<title>Has a consensus NL generation architecture appeared and is it psycholinguistically plausible?</title>
<date>1994</date>
<booktitle>In Proceedings of the Seventh International Workshop on Natural Language Generation,</booktitle>
<pages>163--170</pages>
<location>Kennebunkport, Maine.</location>
<contexts>
<context position="3362" citStr="Reiter (1994)" startWordPosition="509" endWordPosition="510">framework has been implemented in the form of a database server for modular generation systems. As proof of concept of the framework, we have reimplemented an existing NLG system. The system we chose was the Caption Generation System (CGS) (Mittal et al., 1995; Mittal et al., 1998). The reimplementation involved defining the interfaces to the modules of CGS in terms of the RAGS representations and then implementing modules that had the requisite input and output representations. Generation systems, especially end-to-end, applied generation systems, have, unsurprisingly, many things in common. Reiter (1994) proposed an analysis of such systems in terms of a simple three stage pipeline. More recently, the RAGS project attempted to repeat the analiThis work is supported by ESPRC grants GR/L77041 (Edinburgh) and GR/L77102 (Brighton), RAGS: Reference Architecture for Generation Systems. We would also like to acknowledge the contribution of Jo Calder to the ideas and formalisation described in this paper. In particular, parts of this paper are based on (Calder et al., 1999). 119 ysis (Cahill et al., 1999a), but found that while most systems did implement a pipeline, they did not implement the same pi</context>
</contexts>
<marker>Reiter, 1994</marker>
<rawString>Ehud Reiter. 1994. Has a consensus NL generation architecture appeared and is it psycholinguistically plausible? In Proceedings of the Seventh International Workshop on Natural Language Generation, pages 163-170, Kennebunkport, Maine.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven F Roth</author>
<author>John Kolojejchick</author>
<author>Joe Mattis</author>
<author>Jade Goldstein</author>
</authors>
<title>Interactive graphic design using automatic presentation knowledge.</title>
<date>1994</date>
<booktitle>In Proceedings of CHI&apos;94: Human Factors in Computing Systems,</booktitle>
<location>Boston, MA.</location>
<contexts>
<context position="18393" citStr="Roth et al., 1994" startWordPosition="3010" endWordPosition="3013">g a marker), or extending the whiteboard architecture itself so that modules can tell the whiteboard that they have finished processing, and other modules can wait for that to occur. 5 Reconstruction of the Caption Generation System In order to prove this representation scheme in practice, we have implemented the whiteboard in Sicstus Prolog and used it to support data communications between modules in a reconstruction of the Caption Generation System (Mittal et al., 1995). CGS is a system developed at the University of Pittsburgh, which takes input from the SAGE graphics presentation system (Roth et al., 1994) and generates captions for the graphics SAGE produces. We selected it for this effort because it appeared to be a fairly simple pipelined system, with modules performing clearly defined linguistic tasks. As such, we thought it would be a good test case for our whiteboard specification. Although the CGS is organised as a pipeline, shown in Figure 3, the representations communicated between the modules do not correspond to complete, separate instances of RAGS datatype representations. Instead, the representations at the various levels accumulate along the pipeline or are revised in a way that d</context>
</contexts>
<marker>Roth, Kolojejchick, Mattis, Goldstein, 1994</marker>
<rawString>Steven F. Roth, John Kolojejchick, Joe Mattis, and Jade Goldstein. 1994. Interactive graphic design using automatic presentation knowledge. In Proceedings of CHI&apos;94: Human Factors in Computing Systems, Boston, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>