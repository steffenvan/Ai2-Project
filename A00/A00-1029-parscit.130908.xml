<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.942294">
A Tool for Automated Revision of Grammars for NLP Systems
</title>
<note confidence="0.819084">
Nanda Kambhatla and Wlodek Zadrozny
IBM T.J. Watson Research Center
30 Saw Mill River Road,
Hawthorne, NY, 10532
</note>
<email confidence="0.981201">
fnanda,wlodzI @us.ibm.com
</email>
<sectionHeader confidence="0.971251" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999921842105263">
We present an algorithm and a tool for
automatically revising grammars for natural
language processing (NLP) systems to
disallow specifically identified sentences or
sets of sentences. We also outline an
approach for automatically revising attribute
value grammars using counter-examples.
Developing grammars for NLP systems that
are both general enough to accept most
sentences about a domain, but constrained
enough to disallow other sentences is very
tedious. Our approach of revising grammars
automatically using counter-examples
greatly simplifies the development and
revision of tightly constrained grammars.
We have successfully used our tool to
constrain over-generalizing grammars of
speech understanding systems and obtained
higher recognition accuracy.
</bodyText>
<sectionHeader confidence="0.99554" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998832170731707">
Natural language processing systems often
constrain the set of &amp;quot;utterances&amp;quot; from a user
(spoken, typed in, etc.) to narrow down the
possible syntactic and semantic resolutions of
the utterance and reduce the number of
misrecognitions and/or misunderstandings by
the system. Such constraints on the allowed
syntax and the inferred semantics are often
expressed in the form of a &amp;quot;grammar&amp;quot;1, a set of
1 Throughout this document, by using the word
&amp;quot;grammar&amp;quot;, we refer to a Context-Free Grammar that
consists of a finite set of non-terminals, a finite set of
terminals, a unique non-terminal called the start
symbol, and a set of production rules of the form A-.&gt;
a, where A is a non-terminal and a is a string of
terminal or non-terminal symbols. The language&apos;
rules specifying the set of allowed utterances
and possibly also specifying the semantics
associated with these utterances. For instance,
grammars are commonly used in speech
understanding systems to specify both the set of
allowed sentences and to specify &amp;quot;tags&amp;quot; to
extract semantic entities (e.g. the &amp;quot;amount&amp;quot; of
money).
Constraining the number of sentences accepted
by a grammar is essential for reducing
misinterpretations of user queries by an NLP
system. For instance, for speech understanding
systems, if the grammar accepts a large number
of sentences, then the likelihood of recognizing
uttered sentences as random, irrelevant, or
undesirable sentences is increased. For
transaction processing systems, misrecognized
words can lead to unintended transactions being
processed. An effective constraining grammar
can reduce transactional errors by limiting the
number of sentence level errors. The problem of
over-generalization of speech grammars and
related issues is well discussed by Seneff (1992).
Thus, speech grammars must often balance the
conflicting requirements of
</bodyText>
<listItem confidence="0.9917268">
• accepting a wide variety of sentences to
increase flexibility, and
• accepting a small number of sentences
to increase system accuracy and
robustness.
</listItem>
<bodyText confidence="0.676124625">
Developing tight grammars which trade-off
these conflicting constraints is a tedious and
accepted by a grammar is the set of all terminal
strings that can be generated from the start symbol by
successive application of the production rules. The
grammar may optionally have semantic interpretation
rules associated with each production rule (e.g. see
(Allen 95)).
</bodyText>
<page confidence="0.997434">
210
</page>
<bodyText confidence="0.998144181818182">
difficult process. Typically, grammars
overgeneralize and accept too many sentences
that are irrelevant or undesirable for a given
application. We call such sentences &amp;quot;counter-
examples&amp;quot;. The problem is usually handled by
revising the grammar manually to disallow such
counter-examples. For instance, the sentence
&amp;quot;give me my last eighteen transactions&amp;quot; may
need to be excluded from a grammar for a
speech understanding system, since the words
&amp;quot;eighteen&amp;quot; and &amp;quot;ATM&amp;quot; are easily confused by
the speech recogniser. However, &amp;quot;five&amp;quot; and
&amp;quot;ten&amp;quot; should remain as possible modifiers of
&amp;quot;transactions&amp;quot;. Counter-examples can also be
sets of sentences that need to be excluded from a
grammar (specified by allowing the inclusion of
non-terminals in counter-examples). For
example, for a banking application that
disallows money transfers to online accounts, we
might wish to exclude the set of sentences
&amp;quot;transfer &lt;AMOUNT&gt; dollars to my online
account&amp;quot; from the grammar, where
&lt;AMOUNT&gt; is a non-terminal in the grammar
that maps to all possible ways of specifying
amounts.
In this paper, we are proposing techniques for
automatically revising grammars using counter-
examples. The grammar developer identifies
counter-examples from among sentences (or sets
of sentences) mis-recognized by the speech
recognizer or from sentences randomly
generated by a sentence generator using the
original grammar. The grammar reviser modifies
</bodyText>
<figureCaption confidence="0.846511">
Figure 1
</figureCaption>
<figure confidence="0.744172285714286">
Grammar Reviser
Parser counter-
examples
parse
tree
initial
grammar
</figure>
<bodyText confidence="0.998023066666667">
iterated several times until the resulting
grammar is deemed satisfactory.
In the next sections, we first describe our
algorithm for revising grammars to disallow
counter-examples. We also discuss algorithms to
make the revised grammar compact using
minimum description length (MDL) based
grammar compaction techniques and extensions
to our basic algorithm to handle grammars with
recursion. We then present some results of
applying our grammar reviser tool to constrain
speech grammars of speech understanding
systems. Finally, we present an approach for
revising attribute value grammars using our
technique and present our conclusions.
</bodyText>
<sectionHeader confidence="0.930292" genericHeader="method">
2 Automated Grammar Revision by rule
</sectionHeader>
<subsectionHeader confidence="0.864641">
modification
</subsectionHeader>
<bodyText confidence="0.997769733333333">
In this section, we describe an algorithm (see
Figure 1) for revising grammars that directly
modifies the rules of the grammar to disallow
counter-examples. For each counter-example2,
we generate the parse tree (representation of all
the grammar rules needed to generate the
sentence or set of sentences) and the grammar
modifier modifies the production rules of the
grammar to invalidate the counter-example. This
process is repeated for each counter-example
using the revised grammar from the previous
iteration for generating the parse tree for the
current counter-example. If a counter-example
generates multiple parse trees, the above
algorithm is repeated for each parse tree in turn.
</bodyText>
<subsectionHeader confidence="0.998298">
2.1 Grammar modification algorithm
</subsectionHeader>
<bodyText confidence="0.93875545">
We present the grammar modification algorithm
below. For, we assume that the parse-tree(s) of
the counter-example contain no recursion (i.e.
the same production rule does not occur twice in
any of the parse trees). In section 2.4, we present
an approach for using the algorithm even when
the parse-trees contain recursion. Thus, the
algorithm is applicable for any context-free
grammar. The grammar modification algorithm
Grammar
Modi f ier
revised grammar
the original grammar to invalidate the counter-
examples. The revised grammar can be fed back
to the grammar reviser and whole process can be
2 Note that a counter-example can be a sentence such
as &amp;quot;move to operator&amp;quot; or a set of sentences such as
&amp;quot;transfer &lt;AMOUNT&gt; to online account&amp;quot;. The latter
is specified using non-terminals interspersed with
words.
</bodyText>
<page confidence="0.990945">
211
</page>
<bodyText confidence="0.9993445">
for modifying the rules of a grammar to disallow
a counter-example c (identified by a grammar
developer) using a parse-tree for c proceeds as
follows:
</bodyText>
<listItem confidence="0.894637777777778">
1. For each non-terminal &lt;N&gt; in the parse
tree, except the &lt;&lt;START&gt;&gt; symbol,
a. Add a rule to define a new non-
terminal &lt;N&apos;&gt; such that &lt;N&apos;&gt;
generates all phrases that &lt;N&gt;
generates except for the phrase
in the counter-example that &lt;N&gt;
generates.
b. Add a rule to define a new non-
terminal &lt;No&gt; such that &lt;No&gt;
generates only the phrase(s) in
the counter-example that &lt;N&gt;
generates.
2. Modify the rule that contains the
&lt;&lt;START&gt;&gt; symbol in the parse tree,
such that the &lt;&lt;START&gt;&gt; symbol no
longer generates the given counter-
example.
</listItem>
<figureCaption confidence="0.710732">
Figure 2
</figureCaption>
<figure confidence="0.8909985">
(a) Original grammar:
&lt;&lt;START&gt;&gt; ::= &lt;V&gt; &lt;N&gt; &lt;PP&gt; I
&lt;V&gt; &lt;pp&gt;
&lt;PP&gt; ::= &amp;quot;to&amp;quot; &lt;N&gt; .
&lt;V&gt; ::= &amp;quot;move&amp;quot; 1 &amp;quot;transfer&amp;quot;
&lt;N&gt; ::= &amp;quot;checking&amp;quot; 1 &amp;quot;savings&apos;
&amp;quot;money&amp;quot; 1 &amp;quot;operator&amp;quot; .
(b) Parse Tree for &amp;quot;move to operator&amp;quot;
:2= &lt;V&gt; &lt;PP&gt; .
&amp;quot;move&amp;quot; .
</figure>
<bodyText confidence="0.979220347826087">
::= &amp;quot;to&amp;quot; &lt;N&gt; .
&amp;quot;operator&amp;quot;.
We illustrate the algorithm with an example.
Figure 2(a) shows a simple grammar. Suppose
the sentence &amp;quot;move to operator&amp;quot; is a counter-
example for an application. Figure 2(b) shows
the parse-tree for &amp;quot;move to operator&amp;quot;. Since the
parse tree contains the rule: &lt;V&gt; ::= &amp;quot;move&amp;quot;,
new rules are added to define non-terminals
&lt;V&apos;&gt; and &lt;Vo&gt;, where &lt;VI&gt; does not generate
&amp;quot;move&amp;quot; and &lt;Vo&gt; generates only &amp;quot;move&amp;quot;.
Similarly, since the parse tree contains the rule:
&lt;N&gt;::= &amp;quot;operator&amp;quot;, the new rules: &lt;N&gt;::=
&amp;quot;checking&amp;quot; I &amp;quot;savings&amp;quot; I &amp;quot;money&amp;quot;; and &lt;No&gt;::=
&amp;quot;operator&amp;quot;, are added. For the non-terminal
&lt;PP&gt;, the new rules: &lt;PP&apos;&gt;::= &amp;quot;to&amp;quot; &lt;N&apos;&gt;; and
&lt;PPo&gt;::= &amp;quot;to&amp;quot; &lt;No&gt;, are added. Note that since
&lt;No&gt; only generates the phrase &amp;quot;operator&amp;quot;
which is part of the counter-example, &lt;PPo&gt;
only generates the phrase &amp;quot;to operator&amp;quot; which is
part of the counter-example. Also, &lt;PP&apos;&gt;
generates all phrases that &lt;PP&gt; generates except
for the phrase &amp;quot;to operator&amp;quot;. Finally, the rule:
&lt;&lt;START&gt;&gt;::= &lt;V&gt; &lt;PP&gt; is modified using
the newly created non-terminals &lt;V&apos;&gt;, &lt;Vo&gt;,
&lt;PP5 and &lt;PPo&gt; such that the only sentences
which are accepted by the grammar and begin
with the phrase &amp;quot;move&amp;quot; do not end with the
phrase &amp;quot;to operator&amp;quot;, and also, the only
sentences which are accepted by the grammar
and end with the phrase &amp;quot;to operator&amp;quot; do not
begin with the phrase &amp;quot;move&amp;quot;. Figure 3 shows
the final modified grammar that accepts all the
sentences that the grammar in Figure 2(a)
accepts except for the sentence &amp;quot;move to
Figure 3
operator&amp;quot;. In Figure 3, all the grammar rules that
are new or modified are shown in bold and
italics.
The above algorithm for grammar modification
has a time complexity of 0(m*2k) rule creation
(or modification) steps for removing a counter-
example, where m is the number of production
rules in the parse tree of the counter-example
and k is the largest number of non-terminals on
the right hand side of any of these production
</bodyText>
<figure confidence="0.99673537037037">
&lt;&lt;START&gt;&gt;
&lt;PP&gt;
&lt;PP&apos;&gt; ::=
&lt;PPo&gt;
&lt;V&gt;
&lt;VI&gt;
&lt;N&gt; ::=
&lt;MO&gt; ::=
&lt;V&gt; &lt;N&gt; &lt;PP&gt;
&lt;Tp&gt; &lt;PPO&gt; I
&lt;VO&gt; &lt;PP&apos;&gt; I
&lt;11,&gt; &lt;PP&apos;&gt; .
&amp;quot;to&amp;quot; &lt;N&gt; .
&amp;quot;to&amp;quot; &lt;N&apos;&gt; .
&amp;quot;to&amp;quot; &lt;NO&gt; .
&amp;quot;move&amp;quot; 1 &amp;quot;transfer&amp;quot; .
&amp;quot;transfer&amp;quot; .
&amp;quot;move&amp;quot; .
&amp;quot;checking&amp;quot; 1 &amp;quot;savings&amp;quot; I
&amp;quot;money&amp;quot; 1 &amp;quot;operator&amp;quot; .
&amp;quot;checking&amp;quot; I &amp;quot;savings&amp;quot; I
&amp;quot;money&amp;quot; .
&amp;quot;operator&amp;quot; .
&lt;&lt;START»
&lt;V&gt;
&lt;PP&gt;
&lt;N&gt;
</figure>
<page confidence="0.994497">
212
</page>
<bodyText confidence="0.99993425">
rules. Since grammars used for real applications
rarely have more than a handful of non-terminals
on the right hand side of production rules, this
complexity is quite manageable.
</bodyText>
<subsectionHeader confidence="0.9925825">
2.2 Automated grammar compaction using
MDL based grammar induction
</subsectionHeader>
<bodyText confidence="0.933116708333333">
As seen in the example described above, the size
of the grammar (number of production rules) can
increase greatly by applying our algorithm
successively for a number of counter-examples.
However, we can remedy this by applying
grammar induction algorithms based on
minimum description length (MDL) (e.g.
Grunwald (1996) and Zadrozny (1997)) to
combine rules and create a compact grammar
that accepts the same language.
The MDL principle (Rissanen (1982)) selects
that description (theory) of data, which
minimizes the sum of the length, in bits, of the
description of the theory, and the length, in bits,
of data when encoded using the theory. In our
case, the data is the set of possible word
combinations and the theory is the grammar that
specifies it. We are primarily interested in using
the MDL principle to obtain (select) a compact
grammar (the theory) from among a set of
equivalent grammars. Since the set of possible
word combinations (data) is the same for all
grammars in consideration, we focus on the
description length of the grammars itself, which
we approximate by using a set of heuristics
described in step 1 below.
We use the following modified version of
Zadrozny&apos;s (1997) algorithm to generate a more
compact grammar from the revised grammar
using the MDL principle:
1. Compute the description length of the
grammar, i.e. the total number of
symbols needed to specify the grammar,
where each non-terminal, &amp;quot;::=&amp;quot;, and&amp;quot; &amp;quot;
are counted as one symbol.
2. Modify the current grammar by
concatenating all possible pairs of non-
terminals, and compute the description
length of each such resultant grammar.
For concatenating &lt;N1&gt; and &lt;N2&gt;,
introduce the rule &lt;N3&gt;::= &lt;N1&gt; &lt;N2&gt;,
search all other rules for consecutive
occurrences of &lt;N1&gt; and &lt;N2&gt;, and
replace such occurrences with &lt;N3›.
Note that this change results in an
equivalent grammar (that accepts the
same set of sentences as the original
grammar).
</bodyText>
<listItem confidence="0.938097">
3. Modify the current grammar by merging
all possible pairs of non-terminals, and
</listItem>
<bodyText confidence="0.972319538461538">
compute the description length of each
such resultant grammar. For merging
&lt;N4&gt; and &lt;N5&gt;, introduce the rule:
&lt;N6&gt;::= &lt;N4&gt; I &lt;N5&gt;, search for pairs
of rules which differ only in one
position such that for one of the rules,
&lt;N4&gt; occurs in that position and the
other rule, the &lt;N5&gt; occurs in the same
position. Replace the pair of rules with a
new rule that is exactly the same as
either of the pairs of rules, except for the
use of &lt;N6&gt; instead of &lt;N3&gt; or &lt;N4&gt;.
Note that this change results in an
equivalent grammar (that accepts the
same set of sentences as the original
grammar).
4. Compute a table of description lengths
of the grammars obtained by
concatenating or merging all possible
pairs of non- terminals of the initial
grammar, as described above. Select the
pair of non-terminals (if any) together
with the action (concatenate or merge)
that results in the least description
length and execute the corresponding
action.
</bodyText>
<listItem confidence="0.520163">
5. Iterate steps 2, 3, and 4 until the
description length does not decrease.
No further modification is performed if
the base description length of the
grammar is lower than that resulting
from merging or concatenating any pair
of non- terminals.
</listItem>
<bodyText confidence="0.998994714285714">
In variations of this algorithm, the selection of
the pairs of non-terminals to concatenate or
merge, can be based on; the syntactic categories
of the corresponding terminals, the semantic
categories of the corresponding terminals, and
the frequency of occurrence of the non-
terminals.
</bodyText>
<page confidence="0.998056">
213
</page>
<bodyText confidence="0.9996925">
Using the algorithm described above in
conjunction with the algorithm in section 2.1, we
can obtain a compact grammar that is guaranteed
to disallow the counter-examples.
</bodyText>
<subsectionHeader confidence="0.9743125">
2.3 Results for grammar revision for speech
understanding systems
</subsectionHeader>
<bodyText confidence="0.999989333333333">
We have built a graphical tool for revising
grammars for NLP systems based on the
algorithm described in sections 2.1 and 2.2
above. The tool takes as input an existing
grammar and can randomly generate sentences
accepted by the grammar including non-terminal
strings and strings containing terminals and non-
terminals (e.g. both &amp;quot;move to operator&amp;quot; and
&amp;quot;transfer &lt;AMOUNT&gt; to online account&amp;quot; would
be generated if they were accepted by the
grammar). A grammar developer (a human)
interacts with the tool and either inputs counter-
examples selected from speech recognition error
logs or selects counter-examples like the ones
listed above. The grammar developer can then
revise the grammar to disallow the counter-
examples by pressing a button and then reduce
the size of the resulting grammar using the
algorithm in section 2.2 by pressing another
button to obtain a compact grammar that does
not accept any of the identified counter-
examples. Typically, the grammar developer
repeats the above cycle several times to obtain a
tightly constrained grammar.
We have successfully used the tool described
above to greatly constrain overgeneralizing
grammars for speech understanding systems that
we built for telephony banking, stock trading
and directory assistance (Zadrozny et al, 1998).
The speech recognition grammars for these
systems accepted around fifty million sentences
each. We successfully used the reviser tool to
constrain these grammars by eliminating
thousands of sentences and obtained around 20-
30% improvement in sentence recognition
accuracy. We conducted two user studies of our
telephony banking system at different stages of
development. The user studies were conducted
eight months apart. During these eight months,
we used a multi-pronged strategy of constraining
grammars using the grammar revision
algorithms described in this paper, improving
the pronunciation models of some words and
redesigning the prompts of the system to enable
fast and easy error recovery by users. The
combination of all these techniques resulted in
improving the &apos;successful transaction in first
try&apos;3 from 43% to 71%, an improvement of 65%.
The average number of wrong tries (turns of
conversation) to get a successful answer was
reduced from 2.1 to 0.5 tries. We did not
conduct experiments to isolate the contribution
of each factor towards this improvement in
system performance.
It is important to note here that we would
probably have obtained this improvement in
recognition accuracy even with a manual
revision of the grammars. However, the main
advantage in using our tool is the tremendous
simplification of the whole process of revision
for a grammar developer who now selects
counter-examples with an interactive tool
instead of manually revising the grammars.
</bodyText>
<subsectionHeader confidence="0.99996">
2.4 Handling recursion in grammars
</subsectionHeader>
<bodyText confidence="0.999819444444445">
We now describe an extension of the algorithm
in section 2.1 that can modify grammars with
recursion to disallow a finite set of counter-
examples. The example grammars shown above
are regular grammars (i.e. equivalent finite state
automatons exist). For regular grammars (and
only for regular grammars), an alternative
approach for eliminating counter-examples
using standard automata theory is:
</bodyText>
<listItem confidence="0.892680181818182">
• Compute the finite state automaton
(FSA) G corresponding to the original
grammar.
• Compute the FSA C corresponding to
the set of counter-examples.
• Compute C&apos;, the complement of C with
respect to the given alphabet.
• Compute G&apos;, the intersection of G and
C&apos;. The FSA G&apos; is equivalent to a revised
grammar which disallows the counter-
examples.
</listItem>
<footnote confidence="0.9972565">
3 We measured the number of times the user&apos;s
transactional intent (e.g. checking balance, last five
transactions etc.) was recognized and acted upon
correctly by the system in the first try, even when the
actual utterance may not have been recognized
correctly word for word.
</footnote>
<page confidence="0.998155">
214
</page>
<bodyText confidence="0.997439714285714">
The time complexity of the algorithm is 0(n*m),
where n and m are the number of states in the
finite state automatons G and C respectively.
This is comparable to the quadratic time
complexity of our grammar revision algorithm
presented in Section 3.1.
However, the above algorithm for eliminating
counter-examples only works for regular
grammars. This is because context-free
grammars are not closed under complementation
and intersection. However we can use our
algorithm for grammar modification (section
2.1) to handle any context-free grammar as
follows:
</bodyText>
<listItem confidence="0.941444565217391">
1) As before, generate parse tree p for
counter-example c for an initial
grammar G.
2) If p contains a recursion (two or
more repetitions of any production
rule in the same parse tree), rewrite
the initial grammar G as the
equivalent grammar G&apos;, where the
recursion is &amp;quot;unrolled&amp;quot; sufficiently
many times (at least one more time
than the number of repetitions of the
recursive production rule in the
parse tree). We explain the unrolling
of recursion in greater detail below.
If p does not contain any recursion,
go to step 4.
3) Generate parse tree p&apos; for the
counter-example c for the rewritten
grammar G&apos;. Note that p&apos; will no
longer contain a recursive
application of any production rules,
though G&apos; itself will still have
recursion.
</listItem>
<bodyText confidence="0.963046789473684">
4) Use the algorithm described in
section 2.1 to modify the grammar
G&apos; to eliminate the counter-example
c using the parse tree p&apos;.
We illustrate the above algorithm with an
example. Figure 4(a) shows a context free
grammar which accepts all strings of the form
ab a , for any n greater than 0. Note that this is
not a regular language. Suppose we wish to
eliminate the counter-example aaabbb from the
initial grammar. The parse tree p for the counter-
example aaabbb is shown in Figure 4(b). The
grammar in 4(a) can be rewritten as the
equivalent grammar 4(c), where the recursion of
(S-&gt;aSb) is unrolled three times. The parse tree
p&apos; for the counter-example aaabbb with respect
to grammar in 4(c) is shown in Figure 4(d). Note
that p&apos; does not contain any recursion, though
the rewritten grammar does. We revised the
</bodyText>
<figure confidence="0.984884714285714">
FIGURE 4
(a) ORIGINAL GRAMMAR G
&amp;quot;a&amp;quot; &lt;S&gt; &amp;quot;b&amp;quot; I &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; .
(b) PARSE TREE p
&lt;s&gt; : := &amp;quot;a&amp;quot; &lt;S&gt; &amp;quot;b&amp;quot; .
&lt;s&gt; : := &amp;quot;a&amp;quot; 45&gt; &amp;quot;b&amp;quot; .
&lt;S&gt; : := &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; .
(c) REWRITTEN GRAMMAR G&apos;
&lt;s&gt; ::= &amp;quot;a&amp;quot; &lt;S1&gt; &amp;quot;b&amp;quot; 1 &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;
&lt;S1&gt; ::= &amp;quot;a&amp;quot; &lt;52&gt; &amp;quot;b&amp;quot; 1 &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;
&lt;S2&gt; ::= &amp;quot;a&amp;quot; &lt;S3&gt; &amp;quot;b&amp;quot; 1 &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;
&lt;S3&gt; ::= &amp;quot;a&amp;quot; &lt;S3&gt; &amp;quot;b&amp;quot; 1 &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;
(d) PARSE TREE p&apos;
&lt;S&gt; : := &amp;quot;a&amp;quot; &lt;SI.&gt; &amp;quot;b&amp;quot; .
&lt;S1&gt; ::= &amp;quot;a&amp;quot; &lt;S2&gt; &amp;quot;b&amp;quot; .
&lt;$2&gt; ::= &amp;quot;a&amp;quot; &amp;quot;b&amp;quot; .
(e) REVISED GRAMMAR Cr
&amp;quot;a&amp;quot; &lt;S1&gt; &amp;quot;b&amp;quot; I &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;
&lt;S1&gt; ::= &amp;quot;a&amp;quot; &lt;S2&gt; &amp;quot;b&amp;quot; 1 &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;
&lt;52&gt; ::= &amp;quot;a&amp;quot; &lt;S3&gt; &amp;quot;b&amp;quot; .
&lt;53&gt; ::= &amp;quot;a&amp;quot; &lt;S3&gt; &amp;quot;b&amp;quot; I &amp;quot;a&amp;quot; &amp;quot;b&amp;quot;
</figure>
<bodyText confidence="0.987468">
grammar in 4(c) to eliminate the counter-
example aaabbb using the parse tree in Figure
4(d). The revised grammar is shown in Figure
4(e). Note that here we are assuming that a
mechanism exists for rewriting the rules of a
grammar with recursion to unroll the recursion
(if it exists) a finite number of times. Such an
unrolling is readily accomplished by introducing
a set of new non-terminars, one for each iteration
of unrolling as shown in Figure 4(c).
</bodyText>
<sectionHeader confidence="0.9659875" genericHeader="method">
3 Automated revision of attribute-value
grammars
</sectionHeader>
<bodyText confidence="0.993810545454546">
In this section, we delineate an approach for
automatically modifying attribute value
grammars using counter-examples. We first
convert an attribute value grammar into an
equivalent non-attributed grammar by creating
new non-terminals and encoding the attributes in
the names of the new non-terminals (see
Manaster Ramer and Zadrozny (1990) and
Pollard and Sag (1994)).
For example, suppose the grammar in Figure
2(a) is an attribute value grammar with an
</bodyText>
<page confidence="0.997928">
215
</page>
<figureCaption confidence="0.644046">
Figure 5
</figureCaption>
<figure confidence="0.750589363636364">
«START&gt;&gt; &lt;v&gt; &lt;N&gt; &lt;PP&gt; I
&lt;v&gt; &lt;PP&gt; .
&lt;PP&gt; ::= &amp;quot;to&amp;quot; &lt;N&gt; .
&lt;V&gt; ::= &amp;quot;move&amp;quot; 1 &amp;quot;transfer&amp;quot; .
&lt;N&gt; &lt;N_account_checking&gt; 1
&lt;N_account_savings&gt; 1
&lt;N account_unspecified&gt;
sccount_checking&gt; ::= &amp;quot;checking&amp;quot; .
&lt;N_account_savings&gt; ::= &amp;quot;savings&amp;quot;.
&lt;N_aceount_unspecified&gt; ::= &amp;quot;money&amp;quot; 1
&amp;quot;operator&amp;quot; .
</figure>
<bodyText confidence="0.9988351">
attribute &apos;account&apos;, which encodes information
about the type of account specified, e.g.
&apos;account&apos; might have the values, SAVINGS,
CHECKING and UNSPECIFIED. Figure 5
shows an equivalent non-attributed grammar,
where the value of the attribute &apos;account&apos; has
been encoded in the names of the non-terminals.
Note that such an encoding can potentially
create a very large number of non-terminals.
Also, the specific coding used needs to be such
</bodyText>
<figure confidence="0.843818">
«START&gt;&gt; &lt;V&gt; &lt;N&gt; &lt;PP&gt; 1 &lt;17.&gt; &lt;PPo&gt; I
</figure>
<figureCaption confidence="0.67346">
Figure 6 &lt;PP&gt; ::= &amp;quot;to&amp;quot; &lt;N&gt; .
</figureCaption>
<figure confidence="0.982624052631579">
&lt;vo&gt; &lt;pp.&gt; I &lt;V.&gt; &lt;PP.&gt; .
.to. &lt;N.&gt; .
&lt;PPo&gt; ::= .to&amp;quot; &lt;No&gt; .
&amp;quot;move&amp;quot; 1 &amp;quot;transfer&amp;quot;
:= &amp;quot;transfer. .
No&gt; ,i= .move. .
&lt;N&gt; ::= &lt;N account checking&gt; 1
&lt;N_account_savings&gt; I
&lt;N account unspecified&gt; .
&lt;1■Laccount_checking&gt; I
&lt;N_account_savings&gt; I
&lt;11._account unspecified&gt; .
&lt;No&gt; ::= &lt;NO account_unspecified&gt; .
&lt;N account_checking&gt; ::= &amp;quot;Checking&amp;quot; .
&lt;N_account_savings&gt; ::= &amp;quot;savings&amp;quot;.
&lt;N account unspecified&gt; ::= &amp;quot;money&amp;quot; 1
&amp;quot;operator&amp;quot; .
&lt;N.._account unspecified&gt; ::= &amp;quot;money. .
&lt;NO account unspecified&gt; ::= &amp;quot;operator. .
</figure>
<bodyText confidence="0.998553375">
that the attributes can be easily recovered from
the non-terminal names later on.
We can now use our modification algorithms
(Section 2.1 and 2.2) to eliminate counter-
examples from the non-attributed grammar. For
instance, suppose we wish to eliminate &apos;move to
operator&apos; from the attributed grammar based on
Figure 2(a), as discussed above. We apply our
algorithm (Section 2.1) to the grammar in Figure
5 and obtain the grammar shown in Figure 6.
Note that we name any new non-terminals
created during the grammar modification in such
a way as to leave the encoding of the attribute
values in the non-terminal names intact.
After applying the grammar revision algorithm,
we can extract the attribute values from the
encoding in the non-terminal names. For
instance, in the example outlined above, we
might systematically check for suffixes of a
certain type and recover the attributes and their
values. Also, as described earlier, we can use the
algorithm described in section 2.2 to make the
resulting grammar compact again by using MDL
based grammar induction algorithms.
</bodyText>
<sectionHeader confidence="0.999125" genericHeader="conclusions">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.99994003030303">
We have presented a set of algorithms and an
interactive tool for automatically revising
grammars of NLP systems to disallow identified
counter-examples (sentences or sets of sentences
accepted by the current grammar but deemed to
be irrelevant for a given application). We have
successfully used the tool to constrain
overgeneralizing grammars of speech
understanding systems and obtained 20-30%
higher recognition accuracy. However, we
believe the primary benefit of using our tool is
the tremendously reduced effort for the grammar
developer. Our technique relieves the grammar
developer from the burden of going through the
tedious and time consuming task of revising
grammars by manually modifying production
rules one at a time. Instead, the grammar
developer simply identifies counter-examples to
an interactive tool that revises the grammar to
invalidate the identified sentences.
We also discussed an MDL based algorithm for
grammar compaction to reduce the size of the
revised grammar. Thus, using a combination of
the algorithms presented in this paper, one can
obtain a compact grammar that is guaranteed to
disallow the counter-examples.
Although our discussion here was focussed on
speech understanding applications, the
algorithms and the tool described here are
applicable for any domain where grammars are
used. We are currently implementing an
extension of the grammar modifier to handle
attribute-value grammars. We outlined an
</bodyText>
<page confidence="0.9993205">
216
217
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.978107">
<title confidence="0.999941">A Tool for Automated Revision of Grammars for NLP Systems</title>
<author confidence="0.998867">Nanda Kambhatla</author>
<author confidence="0.998867">Wlodek Zadrozny</author>
<affiliation confidence="0.999927">IBM T.J. Watson Research Center</affiliation>
<address confidence="0.994778">30 Saw Mill River Road, Hawthorne, NY, 10532</address>
<abstract confidence="0.9994781">We present an algorithm and a tool for automatically revising grammars for natural language processing (NLP) systems to disallow specifically identified sentences or sets of sentences. We also outline an approach for automatically revising attribute value grammars using counter-examples. Developing grammars for NLP systems that are both general enough to accept most sentences about a domain, but constrained enough to disallow other sentences is very tedious. Our approach of revising grammars automatically using counter-examples greatly simplifies the development and revision of tightly constrained grammars. We have successfully used our tool to constrain over-generalizing grammars of speech understanding systems and obtained higher recognition accuracy.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
</citationList>
</algorithm>
</algorithms>