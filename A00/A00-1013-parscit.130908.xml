<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<title confidence="0.856701666666667">
DP: A Detector for Presuppositions in survey questions
Katj a WIEMER-HASTINGS
Psychology Department / Institute for Intelligent
</title>
<author confidence="0.697468">
Systems
</author>
<affiliation confidence="0.974866">
University of Memphis
</affiliation>
<address confidence="0.715694">
Memphis, TN 38152
</address>
<email confidence="0.973906">
kwiemer@latte.memphis.edu
</email>
<author confidence="0.798784">
Peter WIEMER-HASTINGS
</author>
<affiliation confidence="0.9901915">
Human Communication Research Centre
University of Edinburgh
</affiliation>
<address confidence="0.781437">
2 Buccleuch Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.981647">
peterwh@cogsci.ed.ac.uk
</email>
<author confidence="0.896227">
Sonya RAJAN, Art GRAESSER, Roger KREUZ, &amp; Ashish KARNAVAT
</author>
<affiliation confidence="0.964035">
Institute for Intelligent Systems, University of Memphis, Memphis, TN 38152
</affiliation>
<email confidence="0.902944">
sonyaraj an @hotmail.com, graesser @memphis.edu, rkreuz@memphis.edu, akarnavat@hotmail.com
</email>
<sectionHeader confidence="0.980373" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999714727272727">
This paper describes and evaluates a detector
of presuppositions (DP) for survey questions.
Incorrect presuppositions can make it
difficult to answer a question correctly.
Since they can be difficult to detect, DP is a
useful tool for questionnaire designer. DP
performs well using local characteristics of
presuppositions. It reports the presupposition
to the survey methodologist who can
determine whether the presupposition is
valid.
</bodyText>
<sectionHeader confidence="0.834571" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999924648148148">
Presuppositions are propositions that take some
information as given, or as &amp;quot;the logical
assumptions underlying utterances&amp;quot; (Dijkstra &amp;
de Smedt , 1996, p. 255; for a general overview,
see McCawley, 1981). Presupposed information
includes state of affairs, such as being married;
events, such as a graduation; possessions, such as
a house, children, knowledge about something;
and others. For example, the question, &amp;quot;when did
you graduate from college&amp;quot;, presupposes the
event that the respondent did in fact graduate
from college. The answer options may be ranges
of years, such as &amp;quot;between 1970 and 1980&amp;quot;.
Someone who has never attended college can
either not respond at all, or give a random (and
false) reply. Thus, incorrect presuppositions
cause two problems. First, the question is
difficult to answer. Second, assuming that people
feel obliged to answer them anyway, their
answers present false information. This biases
survey statistics, or, in an extreme case, makes
them useless.
The detector for presuppositions (DP) is part of the
computer tool QUAD (Graesser, Wiemer-
Hastings, Kreuz, Wiemer-Hastings &amp; Marquis, in
press), which helps survey methodologists design
questions that are easy to process. DP detects a
presupposition and reports it to the survey
methodologist, who can examine if the
presupposition is correct. QUAID is a
computerized QUEST questionnaire evaluation
aid. It is based on QUEST (Graesser &amp; Franklin,
1990), a computational model of the cognitive
processes underlying human question answering.
QUAD critiques questions with respect to
unfamiliar technical terms, vague terms, working
memory overload, complex syntax, incorrect
presuppositions, and unclear question purpose or
category. These problems are a subset of potential
problems that have been identified by Graesser,
Bommareddy, Swamer, and Golding (1996; see
also Graesser, Kennedy, Wiemer-Hastings &amp;
Ottati, 1999).
QUAD performs reliably on the first five problem
categories. In comparison to these five problems,
presupposition detection is even more challenging.
For unfamiliar technical terms, for example,
QUAD reports words with frequencies below a
certain threshold. Such an elegant solution is
impossible for presuppositions. Their forms vary
widely across presupposition types. Therefore,
their detection requires a complex set of rules,
carefully tuned to identify a variety of
presupposition problems. DP prints out the
</bodyText>
<page confidence="0.996442">
90
</page>
<bodyText confidence="0.999755666666667">
presuppositions of a question, and relies on the
survey methodologist to make the final decision
whether the presuppositions are valid.
</bodyText>
<subsectionHeader confidence="0.563563">
1 How to detect presuppositions
</subsectionHeader>
<bodyText confidence="0.999856631578948">
We conducted a content analysis of questions
with presupposition problems to construct a list
of indicators for presuppositions. 22 questions
containing problematic presuppositions were
selected from a corpus of 550 questions, taken
from questionnaires provided by the U.S. Census
Bureau. The 22 questions were identified based
on ratings by three human expert raters. It may
seem that this problem is infrequent, but then,
these questions are part of commonly used
questionnaires that have been designed and
revised very thoughtfully.
Additionally, we randomly selected a contrast
question sample of 22 questions rated
unproblematic with regard to incorrect
presuppositions by all three raters. Examples (1)
and (2) are questions rated as problematic by at
least two raters; examples (3) and (4) present
questions that do not contain presuppositions.
</bodyText>
<listItem confidence="0.998237727272727">
(1) Is that the same place you USUALLY go
when you need routine or preventive care, such as
a physical examination or check up?
(2) How much do your parents or parent know
about your close friends&apos; parents?
(3) From date to December 31, did you take one
or more trips or outings in the United States, of at
least one mile, for the PRIMARY purpose of
observing, photographing, or feeding wildlife?
(4) Are you now on full-time active duty with the
armed forces?
</listItem>
<bodyText confidence="0.9995514">
Example (1) presupposes the habit of making
use of routine / preventive care; (2)
presupposes that the respondent has close
friends.
As stated above, incorrect presuppositions are
infrequent in well-designed questionnaires. For
example, questions about details of somebody&apos;s
marriage are usually preceded by a question
establishing the person&apos;s marital status.
In spite of this, providing feedback about
presuppositions to the survey methodologist is
useful. Importantly, QUAD is designed to aid in
the design process. Consider a survey on health-
related issues. In the context of this topic, a
survey methodologist may be interested in how
many days of work a person missed because of
illness, but not think about whether the person
actually has a job. Upon entering the question
&amp;quot;how many days of work did you miss last year
because of illness&amp;quot; into the QUAD) tool, DP
would report that the question presupposes
employment. The survey methodologist could
then insert a question about employment.
Second, there are subtle presuppositions that may
go undetected even by a skilled survey designer.
These are presuppositions about things that are
likely (but not necessarily) true. For example, a
question may inquire about a person&apos;s close
friends (presupposing close friends) or someone&apos;s
standard place for preventive care (presupposing
the habit of making use of preventive care). DP
does not know which presuppositions are likely to
be valid or invalid, and is therefore more likely to
detect such subtle incorrect presuppositions than a
human expert.
</bodyText>
<subsectionHeader confidence="0.999548">
1.1 The presupposition detector (DP)
</subsectionHeader>
<bodyText confidence="0.99998625">
We constructed a set of presupposition detection
rules based on the content analysis. The rules use
a wide range of linguistic information about the
input sentences, including particular words (such
as &amp;quot;why&amp;quot;), part of speech categories (e.g., wh-
pronoun), and complex syntactic subtrees (such as
a quantification clause, followed by a noun
phrase).
</bodyText>
<subsubsectionHeader confidence="0.994474">
1.1.1 The syntactic analysis component
</subsubsectionHeader>
<bodyText confidence="0.999985555555555">
We used Eric Brill&apos;s rule-based word tagger (1992,
1994a, 1994b), the de facto state of the art tagging
system, to break the questions down into part-of-
speech categories. Brill&apos;s tagger produces a single
lexical category for each word in a sentence by
first assigning tags based on the frequency of
occurrence of the word in that category, and then
applying a set of context-based re-tagging rules.
The tagged text was then passed on to Abney&apos;s
SCOL/CASS system (1996a, 1996b), an extreme
bottom-up parser. It is designed to avoid
ambiguity problems by applying grammar rules on
a level-by-level basis. Each level contains rules
that will only fire if they are correct with high
probability. Once the parse moves on to a higher
level, it will not attempt to apply lower-level rules.
In this way, the parser identifies chunks of
information, which it can be reasonably certain are
</bodyText>
<page confidence="0.995846">
91
</page>
<tableCaption confidence="0.50029425">
connected, even when it cannot create a complete
parse of a sentence.
Table 1: Indicators of absence or presence of
presuppositions
</tableCaption>
<subsubsectionHeader confidence="0.976523">
1.1.2 The presupposition indicators
</subsubsectionHeader>
<bodyText confidence="0.99958975">
The indicators for presuppositions were tested
against questions rated as &amp;quot;unproblematic&amp;quot; to
eliminate items that failed to discriminate
questions with versus without presuppositions.
We constructed a second list of indicators that
detect questions containing no presuppositions.
All indicators are listed in Table 1. These lists
are certainly far from complete, but they present a
good basis for evaluating of how well
presuppositions can be detected by an NLP
system. These rules were integrated into a
decision tree structure, as illustrated in Figure 1.
</bodyText>
<figure confidence="0.772161142857143">
Presupposition
First word(s) When VP
What time
Who VP
Why
How much
How many
How often etc.
How VP
Where V NP
Keywords usually
Possessives:
mine, yours,
NP&apos;s
while
Indexicals:
this, these, such
Specific V infinitive
constructions when NP
No presupposition
Initial or following
comma:
- is there
- are there
Does! do NP have ...
Will NP have ...
Has / Have NP
Is / are NP
ever
any
anybody
anything
whether
if
could, would
</figure>
<table confidence="0.892024625">
Are indicators present that question
does not contain presuppositon?
I I/ \\FES1 no problem!,
Are indicators present that question
contains a presupposition?
&amp;quot;probably no problem&amp;quot;
Is indicator reliable?
YES / \10
</table>
<bodyText confidence="0.829276333333333">
It looks like you are presupposing [...J. Make
sure that the presupposition it correct by
consultinig the previous questions.
</bodyText>
<figureCaption confidence="0.998179">
Figure
Figure 1 : The DP decision structure tree
</figureCaption>
<figure confidence="0.483114">
&amp;quot;probably a problem&amp;quot;
</figure>
<page confidence="0.776841">
92
</page>
<subsectionHeader confidence="0.997317">
1.2 Classifying presuppositions
</subsectionHeader>
<bodyText confidence="0.999301125">
Different types of presuppositions can be
distinguished based on particular indicators.
Examples for presupposition types, such as
events or possessions, were mentioned above.
Table 2 presents an exhaustive overview of
presupposition types identified in our analysis.
Note that some indicators can point to more than
one type of presupposition.
</bodyText>
<tableCaption confidence="0.614649258064516">
Table 2: Classification of presupposition based on
indicators. In the right column, expressions in
parentheses identify the presupposed unit.
Presupposition type: The
question presupposes...
&amp;quot;how often&amp;quot; ...VP an action (V)
&amp;quot;how&amp;quot; aux NP VP
&amp;quot;while&amp;quot; ... VP
&amp;quot;where&amp;quot; ... VP
&amp;quot;why&amp;quot; ... VP
&amp;quot;usually&amp;quot; ... VP a habit (V)
&amp;quot;how often&amp;quot;,
&amp;quot;frequently&amp;quot;, etc.
&amp;quot;how many&amp;quot; NP an entity: object, state, or
&amp;quot;where is&amp;quot; NP person (NP)
Indexicals: a shared referent or common
&amp;quot;this&amp;quot; / &amp;quot;that&amp;quot; NP ground (NP)
&amp;quot;these&amp;quot; / &amp;quot;those&amp;quot; NP
&amp;quot;such a(n)&amp;quot; NP
&amp;quot;how much&amp;quot; NP a possession (NP);
&amp;quot;how much does&amp;quot; NP exception list: NP&apos;s that can be
&amp;quot;know&amp;quot; presupposed (name, age, etc.)
&amp;quot;how many&amp;quot; NP
Possessive pronouns
Apostrophe &apos;5&apos;: NP&apos;s
&amp;quot;why&amp;quot; S a state of affairs, fact, or
assertion (5)
an intention / a goal (infinitive /
NP VP)
an agent (A person who VP)
an event (VP)
</tableCaption>
<bodyText confidence="0.999729466666667">
DP reports when a presupposition is present, and
it also indicates the type of presupposition that is
made (e.g., a common ground presupposition or
the presupposition of a habit) in order to point the
question designer to the potential presupposition
error. DP uses the expressions in the right
column in Table 2, selected in accordance with
the indicators, and fills them into the brackets in
its output (see Figure 1). For example, given the
question &amp;quot;How old is your child?&amp;quot;, DP would
detect the possessive pronoun &amp;quot;your&amp;quot;, and
accordingly respond: &amp;quot;It looks like you are
presupposing a possession (child). Make sure that
the presupposition is correct by consulting the
previous questions.&amp;quot;
</bodyText>
<sectionHeader confidence="0.937305" genericHeader="background">
2 Evaluation
</sectionHeader>
<bodyText confidence="0.99972925">
In this section, we report summary statistics for
the human ratings of our test questions and the
measures we computed based on these ratings to
evaluate DP&apos;s performance.
</bodyText>
<subsectionHeader confidence="0.999518">
2.1 Human ratings
</subsectionHeader>
<bodyText confidence="0.99999725">
We used human ratings as the standard against
which to evaluate the performance of DP. Three
raters rated about 90 questions from 12
questionnaires provided by the Census Bureau.
DP currently does not use context. To have a fair
test of its performance, the questions were
presented to the human raters out of context, and
they were instructed to rate them as isolated
questions. Ratings were made on a four-point
scale, indicating whether the question contained
no presupposition (1), probably contained no
presupposition (2), probably contained a
presupposition (3), or definitely contained a
presupposition (4). We transformed the ratings
into Boolean ratings by combining ratings of 1 and
2 (&amp;quot;no problem&amp;quot;) versus ratings of 3 and 4
(&amp;quot;problem&amp;quot;). We obtained very similar results for
analyses of the ratings based on the four-point and
the Boolean scale. For simplicity, we just report
the results for the Boolean scale.
</bodyText>
<subsectionHeader confidence="0.999804">
2.2 Agreement among the raters
</subsectionHeader>
<bodyText confidence="0.999979333333333">
We evaluated the agreement among the raters with
three measures: correlations, Cohen&apos;s kappa, and
percent agreement. Correlations were significant
only between two raters (r = 0. 41); the
correlations of these two with the third rater
produced non-significant correlations, indicating
that the third rater may have used a different
strategy. The kappa scores, similarly, were
significant only for two raters (Lc = 0.36). In terms
of percent agreement, the raters with correlated
ratings agreed in 67% of the cases. The
percentages of agreement with rater 3 were 57%
and 56%, respectively.
DP ratings were significantly correlated with the
ratings provided by the two human raters who
</bodyText>
<figure confidence="0.846781166666667">
Indicator
VP infinitive
&amp;quot;why&amp;quot; VP NP
&amp;quot;who&amp;quot; VP
&amp;quot;When&amp;quot; VP
...&amp;quot;when&amp;quot; NP VP
</figure>
<page confidence="0.995488">
93
</page>
<bodyText confidence="0.999721181818182">
agreed well (r = 0.32 and 0.31), resulting in
agreement of ratings in 63% and 66% of the
questions. In other words, the agreement of
ratings provided by the system and by two human
raters is comparable to the highest agreement rate
achieved between the human raters.
Some of the human ratings diverged
substantially. Therefore, we computed two
restrictive measures based on the ratings to
evaluate the performance of DP. Both scores are
Boolean. The first score is &amp;quot;lenient&amp;quot;; it reports a
presupposition only if at least two raters report a
presupposition for the question (rating of 3 or 4).
We call this measure PE*, a majority-based
presupposition count. The second score is strict.
It reports a presupposition only if all three raters
report a presupposition. This measure is called
Pcomp, a presupposition count based on complete
agreement. It results in fewer detected
presuppositions overall: Pcomp reports
presuppositions for 29 of the questions (33%),
whereas Pâ€ž,ai reports 57 (64%).
</bodyText>
<subsectionHeader confidence="0.999698">
2.3 Evaluation of the DP
</subsectionHeader>
<bodyText confidence="0.999605666666667">
DP ratings were significantly correlated only with
Pcomp (0.35). DP and Pconv ratings were in
agreement for 67% of the questions. Table 3 lists
hit and false alarm rates for DP, separately for Pniai
and Pc.inp. The hit rate indicates how many of the
presuppositions identified by the human ratings
were detected by DP. The false alarm rate
indicates how often DP reported a presupposition
when the human raters did not. The measures look
better with respect to the complete agreement
criterion, Pcomp.
Table 3 further lists recall and precision scores.
The recall rate indicates how many
presuppositions DP detects out of the
presuppositions reported by the human rating
criterion (computed as hits, divided by the sum of
hits and misses). The precision score (computed
as hits, divided by the sum of hits and false
alarms) measures how many presuppositions
reported by DP are actually present, as reported by
the human ratings.
</bodyText>
<tableCaption confidence="0.997496">
Table 3: Performance measures for DP with respect to hits, false alarms, and misses.
</tableCaption>
<table confidence="0.898720666666667">
Hit rate False alarm rate Recall Precision d&apos;
0.54 0.34 0.66 0.74 0.50
0.72 0.35 0.72 0.50 0.95
</table>
<bodyText confidence="0.915199222222222">
flaj
PCOMp
All measures, except for precision, look
comparable or better in relation to Pc ,
including d&apos;, which measures the actual power of
DP to discriminate questions with and without
presuppositions. Of course, picking a criterion
with better matches does not improve the
system&apos;s performance in itself.
</bodyText>
<subsectionHeader confidence="0.668899">
3 An updated version of DP
</subsectionHeader>
<bodyText confidence="0.999012611111111">
Based on the first results, we made a few
modifications and then reevaluated DP. In
particular, we added items to the possession
exception list based on the new corpus and made
some of the no-presupposition rules more
specific. As a more drastic change, we updated
the decision tree structure so that presupposition
indicators overrule indicators against
presuppositions, increasing the number of
reported presuppositions for cases of conflicting
indicators:
If there is evidence for a problem, report &amp;quot;Problem&amp;quot;
Else
if evidence against problem, report &amp;quot;No problem&amp;quot;
else, report &amp;quot;Probably not a problem&amp;quot;
Separate analyses show that the modification of
the decision tree accounts for most of the
performance improvement.
</bodyText>
<subsectionHeader confidence="0.838984">
3.1 Results
</subsectionHeader>
<bodyText confidence="0.9999265">
Table 4 lists the performance measures for the
updated DP. Hit and recall rate increased, but so
did the false alarm rate, resulting in a lower
precision score. The d&apos; score of the updated
system with respect to Pconv (1.3) is substantially
better. The recall rate for this setting is perfect,
i.e., DP did not miss any presuppositions. Since
survey methodologists will decide whether the
presupposition is really a problem, a higher false
alarm rate is preferable to missing out
presupposition cases. Thus, the updated DP is an
improvement over the first version.
</bodyText>
<page confidence="0.999555">
94
</page>
<tableCaption confidence="0.999573">
Table 4: Performance measures for the updated DP with respect to hits, false alarms, and misses.
</tableCaption>
<table confidence="0.979708666666667">
False alarm rate Recall Precision d&apos;
0.44 0.84 0.75 0.8
0.52 1.00 0.46 1.3
Hit rate
Prnai 0.75
Pcomp 0.90
</table>
<sectionHeader confidence="0.545533" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999652690476191">
DP can detect presuppositions, and can thereby
reliably help a survey methodologist to eliminate
incorrect presuppositions. The results for DP
with respect to Pcomp are comparable to, and in
some cases even better than, the results for the
other five categories. This is a very good result,
since most of the five problems allow for &amp;quot;easy&amp;quot;
and &amp;quot;elegant&amp;quot; solutions, whereas DP needs to be
adjusted to a variety of problems.
It is interesting that the performance of DP looks
so much better when compared to the complete
agreement score, Peemp than when compared to
Pmaj. Recall that Pcomp only reports a
presupposition if all the raters report one. The
high agreement of the raters in these cases can
presumably be explained by the salience of the
presupposition problem. This indicates that DP
makes use of reliable indicators for its
performance. Good agreement with the other
measure, Pmai, would suggest that DP additionally
reports presuppositions in cases where humans do
not agree that a presupposition is present. The
higher agreement with the stricter measure is thus
a good result.
DP currently works like the other modules of
QUAD: it reports potential problems, but leaves
it to the survey methodologist to decide whether
to act upon the feedback. As such, DP is a
substantial addition to QUAD. A future
challenge is to turn DP into a DIP (detector of
incorrect presuppositions), that is, to reduce the
number of reported presuppositions to those
likely to be incorrect. DP currently evaluates all
questions independent of context, resulting in
frequent detections. For example, 20 questions
about &amp;quot;this person&amp;quot; may follow one question that
establishes the referent. High-frequency
repetitive presupposition reports could easily get
annoying.
Is a DEP system feasible? At present, it is
difficult for NLP systems to use information from
context in the evaluation of a statement. What is
required to solve this problem is a mechanism that
determines whether a presupposed entity (an
object, an activity, an assertion, etc.) has been
established as applicable in the previous discourse
(e.g., in preceding questions).
The Construction Integration (CI) model by
Kintsch (1998) provides a good example for how
such reference ambiguity can be resolved. CI uses
a semantic network that represents an entity in the
discourse focus (such as &amp;quot;this person&amp;quot;) through
higher activations of its links to other concept
nodes. Perhaps models such as the CI model can
be integrated into the QUAD model to perform
context analyses, in combination with tools like
Latent Semantic Analysis (LSA, Landauer &amp;
Dumais, 1997), which represents text units as
vectors in a high-dimensional semantic space.
LSA measures the semantic similarity of text units
(such as questions) by computing vector cosines.
This feature may make LSA a useful tool in the
detection of a previous question that establishes a
presupposed entity in a later question.
However, questionnaires differ from connected
discourse, such as coherent stories, in aspects that
make the present problem rather more difficult.
Most importantly, the referent for &amp;quot;this person&amp;quot;
may have been established in question number 1,
and the current question containing the
presupposition &amp;quot;this person&amp;quot; is question number
52. A DIP system would have to handle a flexible
amount of context, because the distance between
questions establishing the correctness of a
presupposition and a question building up on it can
vary. On the one hand, one could limit the
considered context to, say, three questions and risk
missing the critical question. On the other hand, it
is computationally expensive to keep the complete
previous context in the systems &amp;quot;working
memory&amp;quot; to evaluate the few presuppositions
which may refer back over a large number of
questions. Solving this problem will likely require
comparing a variety of different settings.
</bodyText>
<page confidence="0.998354">
95
</page>
<sectionHeader confidence="0.980841" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99994175">
This work was partially supported by the Census
Bureau (43-YA-BC-802930) and by a grant from
the National Science Foundation (SBR 9720314
and SBR 9977969). We wish to acknowledge
three colleagues for rating the questions in our
evaluation text corpus, and our collaborator
Susan Goldman as well as two anonymous
reviewers for helpful comments.
</bodyText>
<sectionHeader confidence="0.992281" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998184226415094">
Abney, S. (1996a). Partial parsing via finite-state
cascades. In Proceedings of the ESSLLI &apos;96 Robust
Parsing Workshop.
Abney, S. (1996b). Methods and statistical linguistics.
In J. Klavans &amp; P. Resnik (Eds.), The Balancing
Act. Cambridge, MA: MIT Press
Brill, E. (1992). A simple rule-based part of speech
tagger. In Proceedings of the Third Conference on
Applied Natural Language Processing. ACL.
Brill, E. (1993). A corpus-based approach to language
learning. Ph.D. thesis, University of Pennsylvania,
Philadelphia, PA.
Brill, E. (1994). Some advances in rule-based part of
speech tagging. In Proceedings of the Twelfth
National Conference on Articial Intelligence. AAAI
Press.
Dijkstra, T., &amp; de Smedt, K. (1996). Computational
psycholinguistics. Al and connectionist models of
human language processing. London: Taylor &amp;
Francis.
Graesser, A. C., Bonunareddy, S., Swamer, S., &amp;
Golding, J. (1996). Integrating questionnaire design
with a cognitive computational model of human
question answering. In N. Schwarz &amp; S. Sudman
(Eds.), Answering questions: Methods of
determining cognitive and communicative processes
in survey research (pp. 343-175). San Francisco,
CA: Jossey-B ass.
Graesser, A.C., &amp; Franklin, S.P. (1990). QUEST: A
cognitive model of question answering, Discourse
Processes, 13, 279-304.
Graesser, A.C., Kennedy, T., Wiemer-Hastings, P., &amp;
Ottati, V. (1999). The use of computational
cognitive models to improve questions on surveys
and questionnaires. In M. Sirken, D. Herrmann, S.
Schechter, N. Schwarz, J. Tanur, &amp; R. Tourangeau
(Eds.), Cognition and Survey Research (pp. 199-
216). New York: John Wiley &amp; Sons.
Graesser, A.C., Wiemer-Hastings, K., Kreuz, R.,
Wiemer-Hastings, P., &amp; Marquis, K. (in press).
QUAID: A questionnaire evaluation aid for survey
methodologists. Behavior Research Methods,
Instruments, &amp; Computers.
Kintsch, W. (1998). Comprehension. A paradigm for
cognition. Cambridge, UK: Cambridge University
Press.
Landauer, T.K., &amp; Dumais, S.T. (1997). A solution to
Plato&apos;s problem: The latent semantic analysis theory
of acquisition, induction, and representation of
knowledge. Psychological Review, 104, 211-240.
McCawley, J.D. (1981). Everything that linguists have
always wanted to know about logic. Chicago:
University of Chicago Press.
</reference>
<page confidence="0.998484">
96
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.233977">
<title confidence="0.943997">DP: A Detector for Presuppositions in survey questions Katj a WIEMER-HASTINGS Psychology Department / Institute for Intelligent Systems</title>
<affiliation confidence="0.9994">University of Memphis</affiliation>
<address confidence="0.997971">Memphis, TN 38152</address>
<email confidence="0.99975">kwiemer@latte.memphis.edu</email>
<author confidence="0.994853">Peter WIEMER-HASTINGS</author>
<affiliation confidence="0.929578666666667">Human Communication Research Centre University of Edinburgh 2 Buccleuch Place</affiliation>
<address confidence="0.997603">Edinburgh EH8 9LW, UK</address>
<email confidence="0.987927">peterwh@cogsci.ed.ac.uk</email>
<author confidence="0.789111">Sonya RAJAN</author>
<author confidence="0.789111">Art GRAESSER</author>
<author confidence="0.789111">Roger KREUZ</author>
<author confidence="0.789111">Ashish KARNAVAT</author>
<affiliation confidence="0.448923">Institute for Intelligent Systems, University of Memphis, Memphis, TN 38152</affiliation>
<email confidence="0.98855">sonyarajan@hotmail.com,graesser@memphis.edu,rkreuz@memphis.edu,akarnavat@hotmail.com</email>
<abstract confidence="0.990288833333333">This paper describes and evaluates a detector of presuppositions (DP) for survey questions. Incorrect presuppositions can make it difficult to answer a question correctly. Since they can be difficult to detect, DP is a useful tool for questionnaire designer. DP performs well using local characteristics of presuppositions. It reports the presupposition to the survey methodologist who can determine whether the presupposition is valid.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Partial parsing via finite-state cascades.</title>
<date>1996</date>
<booktitle>In Proceedings of the ESSLLI &apos;96 Robust Parsing Workshop.</booktitle>
<marker>Abney, 1996</marker>
<rawString>Abney, S. (1996a). Partial parsing via finite-state cascades. In Proceedings of the ESSLLI &apos;96 Robust Parsing Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Abney</author>
</authors>
<title>Methods and statistical linguistics. In</title>
<date>1996</date>
<publisher>MIT Press</publisher>
<location>Cambridge, MA:</location>
<marker>Abney, 1996</marker>
<rawString>Abney, S. (1996b). Methods and statistical linguistics. In J. Klavans &amp; P. Resnik (Eds.), The Balancing Act. Cambridge, MA: MIT Press</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A simple rule-based part of speech tagger.</title>
<date>1992</date>
<booktitle>In Proceedings of the Third Conference on Applied Natural Language Processing.</booktitle>
<publisher>ACL.</publisher>
<marker>Brill, 1992</marker>
<rawString>Brill, E. (1992). A simple rule-based part of speech tagger. In Proceedings of the Third Conference on Applied Natural Language Processing. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A corpus-based approach to language learning.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania,</institution>
<location>Philadelphia, PA.</location>
<marker>Brill, 1993</marker>
<rawString>Brill, E. (1993). A corpus-based approach to language learning. Ph.D. thesis, University of Pennsylvania, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>Some advances in rule-based part of speech tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of the Twelfth National Conference on Articial Intelligence.</booktitle>
<publisher>AAAI Press.</publisher>
<marker>Brill, 1994</marker>
<rawString>Brill, E. (1994). Some advances in rule-based part of speech tagging. In Proceedings of the Twelfth National Conference on Articial Intelligence. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dijkstra</author>
<author>K de Smedt</author>
</authors>
<title>Computational psycholinguistics. Al and connectionist models of human language processing.</title>
<date>1996</date>
<publisher>Taylor &amp; Francis.</publisher>
<location>London:</location>
<marker>Dijkstra, de Smedt, 1996</marker>
<rawString>Dijkstra, T., &amp; de Smedt, K. (1996). Computational psycholinguistics. Al and connectionist models of human language processing. London: Taylor &amp; Francis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A C Graesser</author>
<author>S Bonunareddy</author>
<author>S Swamer</author>
<author>J Golding</author>
</authors>
<title>Integrating questionnaire design with a cognitive computational model of human question answering. In</title>
<date>1996</date>
<pages>343--175</pages>
<location>San Francisco, CA:</location>
<note>Jossey-B ass.</note>
<marker>Graesser, Bonunareddy, Swamer, Golding, 1996</marker>
<rawString>Graesser, A. C., Bonunareddy, S., Swamer, S., &amp; Golding, J. (1996). Integrating questionnaire design with a cognitive computational model of human question answering. In N. Schwarz &amp; S. Sudman (Eds.), Answering questions: Methods of determining cognitive and communicative processes in survey research (pp. 343-175). San Francisco, CA: Jossey-B ass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A C Graesser</author>
<author>S P Franklin</author>
</authors>
<title>QUEST: A cognitive model of question answering,</title>
<date>1990</date>
<booktitle>Discourse Processes,</booktitle>
<volume>13</volume>
<pages>279--304</pages>
<contexts>
<context position="2473" citStr="Graesser &amp; Franklin, 1990" startWordPosition="349" endWordPosition="352">, assuming that people feel obliged to answer them anyway, their answers present false information. This biases survey statistics, or, in an extreme case, makes them useless. The detector for presuppositions (DP) is part of the computer tool QUAD (Graesser, WiemerHastings, Kreuz, Wiemer-Hastings &amp; Marquis, in press), which helps survey methodologists design questions that are easy to process. DP detects a presupposition and reports it to the survey methodologist, who can examine if the presupposition is correct. QUAID is a computerized QUEST questionnaire evaluation aid. It is based on QUEST (Graesser &amp; Franklin, 1990), a computational model of the cognitive processes underlying human question answering. QUAD critiques questions with respect to unfamiliar technical terms, vague terms, working memory overload, complex syntax, incorrect presuppositions, and unclear question purpose or category. These problems are a subset of potential problems that have been identified by Graesser, Bommareddy, Swamer, and Golding (1996; see also Graesser, Kennedy, Wiemer-Hastings &amp; Ottati, 1999). QUAD performs reliably on the first five problem categories. In comparison to these five problems, presupposition detection is even</context>
</contexts>
<marker>Graesser, Franklin, 1990</marker>
<rawString>Graesser, A.C., &amp; Franklin, S.P. (1990). QUEST: A cognitive model of question answering, Discourse Processes, 13, 279-304.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A C Graesser</author>
<author>T Kennedy</author>
<author>P Wiemer-Hastings</author>
</authors>
<publisher></publisher>
<marker>Graesser, Kennedy, Wiemer-Hastings, </marker>
<rawString>Graesser, A.C., Kennedy, T., Wiemer-Hastings, P., &amp;</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Ottati</author>
</authors>
<title>The use of computational cognitive models to improve questions on surveys and questionnaires. In</title>
<date>1999</date>
<booktitle>Cognition and Survey Research</booktitle>
<pages>199--216</pages>
<publisher>John Wiley &amp; Sons.</publisher>
<location>New York:</location>
<contexts>
<context position="2940" citStr="Ottati, 1999" startWordPosition="413" endWordPosition="414">ine if the presupposition is correct. QUAID is a computerized QUEST questionnaire evaluation aid. It is based on QUEST (Graesser &amp; Franklin, 1990), a computational model of the cognitive processes underlying human question answering. QUAD critiques questions with respect to unfamiliar technical terms, vague terms, working memory overload, complex syntax, incorrect presuppositions, and unclear question purpose or category. These problems are a subset of potential problems that have been identified by Graesser, Bommareddy, Swamer, and Golding (1996; see also Graesser, Kennedy, Wiemer-Hastings &amp; Ottati, 1999). QUAD performs reliably on the first five problem categories. In comparison to these five problems, presupposition detection is even more challenging. For unfamiliar technical terms, for example, QUAD reports words with frequencies below a certain threshold. Such an elegant solution is impossible for presuppositions. Their forms vary widely across presupposition types. Therefore, their detection requires a complex set of rules, carefully tuned to identify a variety of presupposition problems. DP prints out the 90 presuppositions of a question, and relies on the survey methodologist to make th</context>
</contexts>
<marker>Ottati, 1999</marker>
<rawString>Ottati, V. (1999). The use of computational cognitive models to improve questions on surveys and questionnaires. In M. Sirken, D. Herrmann, S. Schechter, N. Schwarz, J. Tanur, &amp; R. Tourangeau (Eds.), Cognition and Survey Research (pp. 199-216). New York: John Wiley &amp; Sons.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A C Graesser</author>
<author>K Wiemer-Hastings</author>
<author>R Kreuz</author>
<author>P Wiemer-Hastings</author>
<author>K Marquis</author>
</authors>
<title>(in press). QUAID: A questionnaire evaluation aid for survey methodologists.</title>
<journal>Behavior Research Methods, Instruments, &amp; Computers.</journal>
<marker>Graesser, Wiemer-Hastings, Kreuz, Wiemer-Hastings, Marquis, </marker>
<rawString>Graesser, A.C., Wiemer-Hastings, K., Kreuz, R., Wiemer-Hastings, P., &amp; Marquis, K. (in press). QUAID: A questionnaire evaluation aid for survey methodologists. Behavior Research Methods, Instruments, &amp; Computers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Kintsch</author>
</authors>
<title>Comprehension. A paradigm for cognition.</title>
<date>1998</date>
<publisher>Cambridge University Press.</publisher>
<location>Cambridge, UK:</location>
<contexts>
<context position="19338" citStr="Kintsch (1998)" startWordPosition="3019" endWordPosition="3020">tions. For example, 20 questions about &amp;quot;this person&amp;quot; may follow one question that establishes the referent. High-frequency repetitive presupposition reports could easily get annoying. Is a DEP system feasible? At present, it is difficult for NLP systems to use information from context in the evaluation of a statement. What is required to solve this problem is a mechanism that determines whether a presupposed entity (an object, an activity, an assertion, etc.) has been established as applicable in the previous discourse (e.g., in preceding questions). The Construction Integration (CI) model by Kintsch (1998) provides a good example for how such reference ambiguity can be resolved. CI uses a semantic network that represents an entity in the discourse focus (such as &amp;quot;this person&amp;quot;) through higher activations of its links to other concept nodes. Perhaps models such as the CI model can be integrated into the QUAD model to perform context analyses, in combination with tools like Latent Semantic Analysis (LSA, Landauer &amp; Dumais, 1997), which represents text units as vectors in a high-dimensional semantic space. LSA measures the semantic similarity of text units (such as questions) by computing vector co</context>
</contexts>
<marker>Kintsch, 1998</marker>
<rawString>Kintsch, W. (1998). Comprehension. A paradigm for cognition. Cambridge, UK: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T K Landauer</author>
<author>S T Dumais</author>
</authors>
<title>A solution to Plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge.</title>
<date>1997</date>
<journal>Psychological Review,</journal>
<volume>104</volume>
<pages>211--240</pages>
<contexts>
<context position="19766" citStr="Landauer &amp; Dumais, 1997" startWordPosition="3087" endWordPosition="3090"> (an object, an activity, an assertion, etc.) has been established as applicable in the previous discourse (e.g., in preceding questions). The Construction Integration (CI) model by Kintsch (1998) provides a good example for how such reference ambiguity can be resolved. CI uses a semantic network that represents an entity in the discourse focus (such as &amp;quot;this person&amp;quot;) through higher activations of its links to other concept nodes. Perhaps models such as the CI model can be integrated into the QUAD model to perform context analyses, in combination with tools like Latent Semantic Analysis (LSA, Landauer &amp; Dumais, 1997), which represents text units as vectors in a high-dimensional semantic space. LSA measures the semantic similarity of text units (such as questions) by computing vector cosines. This feature may make LSA a useful tool in the detection of a previous question that establishes a presupposed entity in a later question. However, questionnaires differ from connected discourse, such as coherent stories, in aspects that make the present problem rather more difficult. Most importantly, the referent for &amp;quot;this person&amp;quot; may have been established in question number 1, and the current question containing th</context>
</contexts>
<marker>Landauer, Dumais, 1997</marker>
<rawString>Landauer, T.K., &amp; Dumais, S.T. (1997). A solution to Plato&apos;s problem: The latent semantic analysis theory of acquisition, induction, and representation of knowledge. Psychological Review, 104, 211-240.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J D McCawley</author>
</authors>
<title>Everything that linguists have always wanted to know about logic. Chicago:</title>
<date>1981</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="1236" citStr="McCawley, 1981" startWordPosition="162" endWordPosition="163">tector of presuppositions (DP) for survey questions. Incorrect presuppositions can make it difficult to answer a question correctly. Since they can be difficult to detect, DP is a useful tool for questionnaire designer. DP performs well using local characteristics of presuppositions. It reports the presupposition to the survey methodologist who can determine whether the presupposition is valid. Introduction Presuppositions are propositions that take some information as given, or as &amp;quot;the logical assumptions underlying utterances&amp;quot; (Dijkstra &amp; de Smedt , 1996, p. 255; for a general overview, see McCawley, 1981). Presupposed information includes state of affairs, such as being married; events, such as a graduation; possessions, such as a house, children, knowledge about something; and others. For example, the question, &amp;quot;when did you graduate from college&amp;quot;, presupposes the event that the respondent did in fact graduate from college. The answer options may be ranges of years, such as &amp;quot;between 1970 and 1980&amp;quot;. Someone who has never attended college can either not respond at all, or give a random (and false) reply. Thus, incorrect presuppositions cause two problems. First, the question is difficult to ans</context>
</contexts>
<marker>McCawley, 1981</marker>
<rawString>McCawley, J.D. (1981). Everything that linguists have always wanted to know about logic. Chicago: University of Chicago Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>