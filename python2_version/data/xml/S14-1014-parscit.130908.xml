<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.990695">
Generating Simulations of Motion Events from Verbal Descriptions
</title>
<author confidence="0.992103">
James Pustejovsky
</author>
<affiliation confidence="0.976222">
Computer Science Dept.
Brandeis University
</affiliation>
<address confidence="0.525837">
Waltham, MA USA
</address>
<email confidence="0.998522">
jamesp@cs.brandeis.edu
</email>
<sectionHeader confidence="0.993899" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999451875">
In this paper, we describe a computational
model for motion events in natural lan-
guage that maps from linguistic expres-
sions, through a dynamic event interpreta-
tion, into three-dimensional temporal sim-
ulations in a model. Starting with the
model from (Pustejovsky and Moszkow-
icz, 2011), we analyze motion events us-
ing temporally-traced Labelled Transition
Systems. We model the distinction be-
tween path- and manner-motion in an op-
erational semantics, and further distin-
guish different types of manner-of-motion
verbs in terms of the mereo-topological re-
lations that hold throughout the process of
movement. From these representations,
we generate minimal models, which are
realized as three-dimensional simulations
in software developed with the game en-
gine, Unity. The generated simulations
act as a conceptual “debugger” for the se-
mantics of different motion verbs: that
is, by testing for consistency and infor-
mativeness in the model, simulations ex-
pose the presuppositions associated with
linguistic expressions and their composi-
tions. Because the model generation com-
ponent is still incomplete, this paper fo-
cuses on an implementation which maps
directly from linguistic interpretations into
the Unity code snippets that create the sim-
ulations.
</bodyText>
<sectionHeader confidence="0.999337" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999664">
Semantic interpretation requires access to both
knowledge about words and how they compose.
As the linguistic phenomena associated with lexi-
cal semantics have become better understood, sev-
eral assumptions have emerged across most mod-
els of word meaning. These include the following:
</bodyText>
<note confidence="0.71902225">
Nikhil Krishnaswamy
Computer Science Dept.
Brandeis University
Waltham, MA USA
</note>
<email confidence="0.977791">
nkrishna@brandeis.edu
</email>
<bodyText confidence="0.97244">
(1) a. Lexical meaning involves some sort of
“componential analysis”, either through
predicative primitives or a system of
types.
b. The selectional properties of predicators
can be explained in terms of these com-
ponents;
c. An understanding of event semantics and
the different role of event participants
seems crucial for modeling linguistic ut-
terances.
As a starting point in lexical semantic analysis,
a standard methodology in both theoretical and
computational linguistics is to identify features in
a corpus that differentiate the data in meaningful
ways; meaningful in terms of prior theoretical as-
sumptions or in terms of observably differentiated
behaviors. Combining these strategies we might,
for instance, take a theoretical constraint that we
hope to justify through behavioral distinctions in
the data. An example of this is the theoretical
claim that motion verbs can be meaningfully di-
vided into two classes: manner- and path-oriented
predicates (Talmy, 1985; Jackendoff, 1983; Talmy,
2000). These constructions can be viewed as en-
coding two aspects of meaning: how the move-
ment is happening and where it is happening. The
former strategy is illustrated in (2a) and the latter
in (2b) (where m indicates a manner verb, and p
indicates a path verb).
(2) a. The ball rolledm.
b. The ball crossedp the room.
With both of the verb types, adjunction can make
reference to the missing aspect of motion, by intro-
ducing a path (as in (3a)) or the manner of move-
ment (in (3b)).
</bodyText>
<listItem confidence="0.783179">
(3) a. The ball rolledm across the room.
</listItem>
<bodyText confidence="0.866017333333333">
b. The ball crossedp the room rolling.
Differences in syntactic distribution and grammat-
ical behavior in large datasets, in fact, correlate
</bodyText>
<page confidence="0.982474">
99
</page>
<note confidence="0.980903">
Proceedings of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 99–109,
Dublin, Ireland, August 23-24 2014.
</note>
<bodyText confidence="0.999745666666667">
fairly closely with the theoretical claims made by
linguists using small introspective datasets.
The path-manner classification is a case where
there are data-derived distinctions that corre-
late nicely with theoretically inspired predictions.
More often than not, however, lexical semantic
distinctions are formal stipulations in a linguistic
model, that often have no observable correlations
to data. For example, an examination of the man-
ner of movement class from Levin (1993) illus-
trates this point. The verbs below are all Levin-
class manner of motion verbs:
</bodyText>
<listItem confidence="0.555596">
(4) MANNER OF MOTION VERBS: drive, walk,
run, crawl, fly, swim, drag, slide, hop, roll
</listItem>
<bodyText confidence="0.999431913043479">
Assuming the two-way distinction between path
and manner predication of motion mentioned
above, these verbs do, in fact, tend to pattern ac-
cording to the latter class in the corpus. Given
that they are all manner of motion verbs, however,
any data-derived distinctions that emerge within
this class will have to be made in terms of addi-
tional syntactic or semantic dimensions. While it
is most likely possible to differentiate, for exam-
ple, the verbs slide from roll, or walk from hop in
the corpus, given enough data, it is important to
realize that conceptual and theoretical modeling is
often necessary to reveal the factors that semanti-
cally distinguish such linguistic expressions, in the
first place.
We argue that this problem can be approached
with the use of minimal model generation. As
Blackburn and Bos (2008) point out, theorem
proving (essentially type satisfaction of a verb in
one class as opposed to another) provides a “nega-
tive handle” on the problem of determining consis-
tency and informativeness for an utterance, while
model building provides a “positive handle” on
both. For our concerns, simulation construction
provides a positive handle on whether two man-
ner of motion processes are distinguished in the
model. Further, the simulation must specify how
they are distinguished, the analogue to informa-
tiveness.
In this paper, we argue that traditional lexical
modeling can benefit greatly from examining how
semantic interpretations are contextually and con-
ceptually grounded. We explore a dynamic in-
terpretation of the lexical semantic model devel-
oped in Generative Lexicon Theory (Pustejovsky,
1995; Pustejovsky et al., 2014). Specifically, we
are interested in using model building (Blackburn
and Bos, 2008; Konrad, 2004; Gardent and Kon-
rad, 2000) and simulation generation (Coyne and
Sproat, 2001; Siskind, 2011) to reveal the concep-
tual presuppositions inherent in natural language
expressions. In this paper, we focus our attention
on motion verbs, in order to distinguish between
manner and path motion verbs, as well as to model
mereotopological distinctions within the manner
class.
</bodyText>
<sectionHeader confidence="0.57908" genericHeader="method">
2 Situating Motion in Space and Time
</sectionHeader>
<bodyText confidence="0.999917325">
The interpretation of motion in language has been
one of the most researched areas in linguistics
and Artificial Intelligence (Kuipers, 2000; Freksa,
1992; Galton, 2000; Levinson, 2003; Mani and
Pustejovsky, 2012). Because of their grammatical
and semantic import, linguistic interest in identi-
fying where events happen has focused largely on
motion verbs and the role played by paths. Jack-
endoff (1983), for example, elaborates a semantics
for motion verbs incorporating explicit reference
to the path traversed by the mover, from source to
destination (goal) locations. Talmy (1983) devel-
ops a similar conceptual template, where the path
followed by the figure is integral to the conceptu-
alization of the motion against a ground. Hence,
the path can be identified as the central element in
defining the location of the event (Talmy, 2000).
Related to this idea, both Zwarts (2005) and Puste-
jovsky and Moszkowicz (2011) develop mecha-
nisms for dynamically creating the path traversed
by a mover in a manner of motion predicate, such
as run or drive. Starting with this approach, the
localization of a motion event, therefore, is at
least minimally associated with the path created
by virtue of the activity.
In addition to capturing the spatial trace of the
object in motion, several researchers have pointed
out that identifying the shape of the path dur-
ing motion is also critical for fully interpreting
the semantics of movement. Eschenbach et al.
(1999) discusses the orientation associated with
the trajectory, something they refer to as oriented
curves. Motivated more by linguistic considera-
tions, Zwarts (2006) introduces the notion of an
event shape, which is the trajectory associated
with an event in space represented by a path. He
defines a shape function, which is a partial func-
tion assigning unique paths to those events involv-
ing motion or extension in physical space. This
work suggests that the localization of an event
</bodyText>
<page confidence="0.985926">
100
</page>
<bodyText confidence="0.9999320625">
makes reference to orientational as well as config-
urational factors, a view that is pursued in Puste-
jovsky (2013b). This forces us to look at the var-
ious spatio-temporal regions associated with the
event participants, and the interactions between
them.
These issues are relevant to our present con-
cerns, because in order to construct a simulation, a
motion event must be embedded within an appro-
priate minimal embedding space. This must suf-
ficiently enclose the event localization, while op-
tionally including room enough for a frame of ref-
erence visualization of the event (the viewer’s per-
spective). We return to this issue later in the paper
when constructing our simulation from the seman-
tic interpretation associated with motion events.
</bodyText>
<sectionHeader confidence="0.896919" genericHeader="method">
3 Modeling Motion in Language
</sectionHeader>
<subsectionHeader confidence="0.996089">
3.1 Theoretical Assumptions
</subsectionHeader>
<bodyText confidence="0.999773607142857">
The advantage of adopting a dynamic interpre-
tation of motion is that we can directly distin-
guish path predication from manner of motion
predication in an operational semantics (Miller
and Charles, 1991; Miller and Johnson-Laird,
1976) that maps nicely to a simulation environ-
ment. Models of processes using updating typi-
cally make reference to the notion of a state tran-
sition (van Benthem, 1991; Harel, 1984). This is
done by distinguishing between formulae, φ, and
programs, π. A formula is interpreted as a clas-
sical propositional expression, with assignment of
a truth value in a specific model. We will inter-
pret specific models by reference to specific states.
A state is a set of propositions with assignments
to variables at a specific index. Atomic programs
are input/output relations ( [π] ⊆ S × S), and
compound programs are constructed from atomic
ones following rules of dynamic logic (Harel et al.,
2000).
For the present discussion, we represent the dy-
namics of actions in terms of Labeled Transition
Systems (LTSs) (van Benthem, 1991).1 An LTS
consists of a triple, hS, Act, →i, where: S is the
set of states; Act is a set of actions; and → is a to-
tal transition relation: →⊆ S×Act×S. An action,
α ∈ Act, provides the labeling on an arrow, mak-
ing it explicit what brings about a state-to-state
</bodyText>
<footnote confidence="0.981331">
1This is consistent with the approach developed in (Fer-
nando, 2009; Fernando, 2013). This approach to a dynamic
interpretation of change in language semantics is also in-
spired by Steedman (2002).
</footnote>
<bodyText confidence="0.892386285714286">
transition. As a shorthand for (e1, α, e2) ∈→, we
will also use e1 −→ e2. If reference to the state
α
content (rather than state name) is required for in-
terpretation purposes (van Benthem et al., 1994),
then as shorthand for ({φ}
¬φ .Finally, when referring
</bodyText>
<equation confidence="0.759334">
e2
</equation>
<bodyText confidence="0.9237805">
to temporally-indexed states in the model, where
ei@i indicates the state ei interpreted at time i, as
shorthand for ({φ}e1@i, α, {¬φ}e2@i+1) ∈→, we
, as described in Puste-
</bodyText>
<equation confidence="0.783699">
e2
jovsky(2013).
</equation>
<subsectionHeader confidence="0.999989">
3.2 Distinguishing Path and Manner Motion
</subsectionHeader>
<bodyText confidence="0.99843025">
We will assume that change of location of an ob-
ject can be viewed as a special instance of a first-
order program, which we will refer to as ν (Puste-
jovsky and Moszkowicz, 2011).2
</bodyText>
<listItem confidence="0.508176285714286">
(5) x := y (ν-transition, where loc(z) is value
being updated)
“x assumes the value given to y in the next
state.”
hM, (i, i + 1), (u, u[x/u(y)])i |= x := y
iff hM, i, ui |= loc(z) = x ∧ hM, i +
1, u[x/u(y)]i |= loc(z) = y
</listItem>
<bodyText confidence="0.994418076923077">
Given a simple transition, a process can be viewed
as simply an iteration of ν (Fernando, 2009).
However, as (Pustejovsky, 2013a) points out, since
most manner motion verbs in language are ac-
tually directed processes, simple decompositions
into change-of-location are inadequate. That is,
they are guarded transitions where the test is not
just non-coreference, but makes reference to val-
ues on a scale, C, and ensures that it continues in
an order-preserving change through the iterations.
When this test references the values on a scale, C,
we call this a directed ν-transition (~ν), e.g., x -,&lt; y,
x &gt; ,--y:
</bodyText>
<equation confidence="0.99694925">
(6) ν~ =df
loc(z) = y1 e1 −→ . . .
ν�
loc(z) = yn e,,,
</equation>
<bodyText confidence="0.990904">
This now provides us with our dynamic interpre-
tation of directed manner of motion verbs, such
as slide, swim, roll, where we have an iteration of
assignments of locations, undistinguished except
2Cf. Groenendijk and Stokhof (1990) for dynamic updat-
ing, and Naumann (2001) for a related analysis.
</bodyText>
<equation confidence="0.999080461538462">
e1, α, {¬φ}e2) ∈→, we
−→ α
use,
φ
e1
i −→α
will use, φ
e1
¬φ
i+1
� C? ν
ei −→ ei+1.
(7) loc(z) = x e0 −→ ν�
</equation>
<page confidence="0.958112">
101
</page>
<bodyText confidence="0.997631076923077">
that the values are order-preserving according to a
scalar constraint.
This is quite different from the dynamic inter-
pretation of path predicates. Following (Galton,
2004; Pustejovsky and Moszkowicz, 2011), path
predicates such as arrive and leave make refer-
ence to a “distinguished location”, not an arbi-
trary location. For example, the ball enters the
room is satisified when the distinguished location,
D, (the room) is successfully tested as the loca-
tion for the moving object. That is, the location
is tested against the current location for an object
((loc(x) =� D)?), and retested until it is satisfied
</bodyText>
<equation confidence="0.988594571428571">
((loc(x) = D)?).
(loc(x)=,4D)?
x
loc(z) = y1 e1
(loc(x)=D)?
x
loc(z) = yn en
</equation>
<bodyText confidence="0.999896666666667">
While beyond the scope of the present discus-
sion, it is worth noting that the model of event
structure adopted here for motion verbs fits well
with most of the major semantic and syntactic phe-
nomena associated with event classes and Aktion-
sarten.3
</bodyText>
<subsectionHeader confidence="0.99969">
3.3 Mereotopological Distinctions in Manner
</subsectionHeader>
<bodyText confidence="0.991479851851852">
Given the formal distinction between path and
manner predicates as described above, let us ex-
amine how to differentiate meaning within the
manner class. Levin (1993) differentiates this
class in terms of argument alternation patterns,
and identifies the following verb groupings: ROLL,
RUN, EPONYMOUS VEHICLE, WALTZ, ACCOM-
PANY, and CHASE verbs. While suggestive, these
distinctions are only partially useful towards actu-
ally teasing apart the semantic dimensions along
which we identify the contributing factors of man-
ner.
Mani and Pustejovsky (2012) suggest a differ-
ent strategy involving the identification of seman-
tic parameters that clearly differentiate verb senses
from each other within this class. One parameter
exploited quite extensively within the motion class
involves the mereotopological contraints that in-
here throughout the movement of the object (Ran-
dell et al., 1992; Asher and Vieu, 1995; Gal-
ton, 2000). Using this parameter, we are able to
distinguish several of Levin’s classes of manner
3Cf. (Pustejovsky, 2013a) and (Krifka, 1992).
as well as some novel ones, as described in (9),
where a class is defined by the constraints that hold
throughout the event (where EC is “externally con-
nected”, and DC is “disconnected”).
</bodyText>
<listItem confidence="0.992602625">
(9) For Figure (F) relative to Ground (G):
a. EC(F,G), throughout motion:
b. DC(F,G), throughout motion:
c. EC(F,G) followed by DC(F,G), through-
out motion:
d. Sub-part(F’,F), EC(F’,G) followed by
DC(F’,G), throughout motion:
e. Containment of F in a Vehicle (V).
</listItem>
<bodyText confidence="0.999716727272727">
For example, consider the semantic distinction be-
tween the verbs slide and hop or bounce. When the
latter are employed in induced (directed) motion
constructions (Levin, 1993; Jackendoff, 1996),
they take on the meaning of manner of motion
verbs. Distinguishing between a sliding and hop-
ping motion involves inspecting the next-state
content in the motion n-gram: namely, there is a
continuous satisfaction of EC(F,G) throughout the
motion for slide and a toggling effect (on-off) for
the predicates bounce and hop, as shown in (10).
</bodyText>
<equation confidence="0.989131666666667">
-DC(x,G)?
x
(10) loc(z) = x e0
-DC(x,G)?
x
loc(z) = y2 e2
</equation>
<bodyText confidence="0.9798005">
With the surface as the ground argument, these
verbs are defined in terms of two transitions.4
</bodyText>
<figureCaption confidence="0.999868">
Figure 1: Slide Motion
Figure 2: Hop Motion
</figureCaption>
<bodyText confidence="0.65035375">
4Many natural language predicates require reference to at
least three states. These include the semelfactives mentioned
above, as well as blink and iterative uses of knock and clap
(Vendler, 1967; Dowty, 1979; Rothstein, 2008).
</bodyText>
<figure confidence="0.91088416">
s1
s2
s3
A
A
A
B
l1 l2 l3
s1
s2
s3
A
A
B
l1 l2 l3
A
(loc(x)=,4D)?
x
(8) loc(z) = x e0 −→ v
−→ . . .
v
DC(x,G)?
x
loc(z) = y1 e1 −→ v
−→v
</figure>
<page confidence="0.987284">
102
</page>
<bodyText confidence="0.97615340625">
Distinguishing between a sliding motion and a
rolling motion is also fairly straightforward. We
have the entailments that result from each kind of
motion, given a set of initial conditions, as in the
following short sentence describing the motion of
a ball relative to a floor (the domain for our event
simulations).
• The ball slid.: At the termination of the ac-
tion, object ball has moved relative to a sur-
face in a manner that is [+translate].
That is, the movement is a translocation
across absolute space, but other attributes
(such as the ball’s orientation) do not change.
• The ball rolled.: At the termination of the
action, object ball has moved relative to a
surface in a manner that is [+translate]
and [+rotate]. Here, the translocation
across space is preserved, with the addition
of an orientation change.
We can further decompose these features, cast-
ing the [+translate] in terms of the trans-
lation’s dimensionality. For both the ball slid
and the ball rolled, it is required that the ball re-
main in the contact with the relevant surface, thus
we can enforce a [-3-dimensional] con-
straint on the [+translate] feature. Thus,
we arrive at the following differentiating se-
mantic constraints for these verbs: (a) slide,
[+translate], [-3-dimensional]; (b)
roll, [+translate], [-3-dimensional],
[+rotate]. This is illustrated below over three
states of execution.
</bodyText>
<figureCaption confidence="0.994144">
Figure 3: Roll Motion
</figureCaption>
<bodyText confidence="0.999785222222222">
In our approach to conceptual modeling, we hy-
pothesize that between the members of any pair of
motion verbs, there exists at least one distinctive
feature of physical motion that distinguishes the
two predicates. While this may be too strong, it
is helpful in our use of simulations for debugging
the lexical semantics of linguistic expressions.5 In
order to quantify the qualitative distinctions be-
tween motion predicates and identify the precise
primitive components of a motion verb, we build
a real-time simulation, within which the individ-
ual features of a single motion verb can be defined
and isolated in three-dimensional space.
The idea of constructing simulations from lin-
guistic utterances is, of course, not new. There
are two groups of researchers who have developed
related ideas quite extensively: simulation theo-
rists, working in the philosophy of mind, such as
Alvin Goldman and Robert Gordon; and cogni-
tive scientists and linguists, such as Jerry Feldman,
Ron Langacker, and Ben Bergen. According to
Goldman (1989), simulation provides a process-
driven theory of mind and mental attribution, dif-
fering from the theory-driven models proposed by
Churchland and others (Churchland, 1991). From
the cognitive linguistics tradition, simulation se-
mantics has come to denote the mental instanti-
ation of an interpretation of any linguistic utter-
ance (Feldman, 2006; Bergen et al., 2007; Bergen,
2012). While these communities do not seem to
reference each other, it is clear from our perspec-
tive, that they are both pursuing similar programs,
where distinct linguistic utterances correspond to
generated models that have differentiated struc-
tures and behaviors (Narayanan, 1999; Siskind,
2011; Goldman, 2006).
</bodyText>
<sectionHeader confidence="0.971924" genericHeader="method">
4 Simulations as Minimal Models
</sectionHeader>
<bodyText confidence="0.959370823529412">
The approach to simulation construction intro-
duced in the previous section is inspired by work
in minimal model generation (Blackburn and Bos,
2008; Konrad, 2004). Type satisfaction in the
compositional process mirrors the theorem prov-
ing component, while construction of the specific
model helps us distinguish what is inherent in the
different manner of motion events. This latter as-
pect is the “positive handle”, (Blackburn and Bos,
2008) which demonstrates the informativeness of
a distinction in our simulation.
Simulation software must be able to map a pred-
icate to a known behavior, its arguments to objects
in the scene, and then prompt those objects to ex-
ecute the behavior. A simple input sentence needs
5Obviously, true synonyms in the lexicon would not be
distinguishable in a model.
</bodyText>
<figure confidence="0.995146823529412">
s1
A
c
b
a
B
s2
A
a c
b
B
s3
b
e
A
c
a
</figure>
<page confidence="0.99613">
103
</page>
<bodyText confidence="0.9993525">
to be tagged and parsed and transformed into pred-
icate/argument representation, and from there into
a dynamic event structure, as in (Pustejovsky and
Moszkowicz, 2011). The event structure is inter-
preted as the transformation executed over the ob-
ject or objects in each frame, and then rendered.
</bodyText>
<table confidence="0.5240245">
SBJ OBJ
Ball1/NNP crossed/VBD Floor/NNP
SBJ
Ball1/NNP rolled/VBD
</table>
<tableCaption confidence="0.853224">
Table 1: Dependency parses for Ball1 crossed
Floor (top) and Ball1 rolled (bottom).
</tableCaption>
<bodyText confidence="0.9980298">
We currently use only proper names to refer to
objects in the scene, to simplify model generation,
hence Ball1 and Floor. This facilitates easy object
identification in this prototype development stage.
Given a tagged and dependency parsed sen-
tence, we can the transform the parse into a pred-
icate formula, using the root of the parse as the
predicate, the subject as a singleton first argument,
and all objects as an optional stack of subsequent
arguments.
</bodyText>
<figure confidence="0.78739875">
1. pred := cross 1. pred := roll
2. x := Ball1 2. x := Ball1
3. y.push(Floor)
cross(Ball1,[Floor]) roll(Ball1)
</figure>
<tableCaption confidence="0.967201">
Table 2: Transformation to predicate formula for
</tableCaption>
<subsubsectionHeader confidence="0.419469">
Ball1 crossed Floor and Ball1 rolled.
</subsubsectionHeader>
<bodyText confidence="0.9993666">
The resulting predicates are represented in Ta-
ble 3 as expressions in Dynamic Interval Tempo-
ral Logic (DITL) (Pustejovsky and Moszkowicz,
2011), which are equivalent to the LTS expres-
sions used above.
</bodyText>
<equation confidence="0.994703875">
cross(Ball1,Floor)
loc(Ball1) := y, target(Ball1) := z; b := y;
(y := w; y # w; d(b,y) &lt; d(b,w),
d(b,z) &gt; d(z,w), IN(y,Floor))+
roll(Ball1)
loc(Ball1) := y, rot(Ball1) := z; bloc := y,
brot := z; (y := w; y 54 w; d(bloc,y) &lt; d(bloc,w),
IN(y,Floor))+, (z := v; z # v; z-brot &lt; v-brot)+
</equation>
<bodyText confidence="0.879145">
Table 3: DITL expressions for Ball1 crossed Floor
and Ball1 rolled.
The DITL expression forms the basis of the
coded behavior. The first two initialization steps
are coded into the behavior’s start function while
the the third, Kleene iterated step, is encoded in
the behavior’s update function.
</bodyText>
<sectionHeader confidence="0.988688" genericHeader="method">
5 Generating Simulations
</sectionHeader>
<bodyText confidence="0.9202396">
We use the freely-available game engine, Unity,
(Goldstone, 2009) to handle all underlying graph-
ics processing, and limited our object library to
simple primitive shapes of spheroids, rectangular
prisms, and planes. For every instance of an ob-
ject, the game engine maintains a data structure for
the object’s virtual representation. Table 4 shows
the data structure for Entity, the superclass of
all movable objects.
Entity:
</bodyText>
<tableCaption confidence="0.990921">
Table 4: Data structure of motion-capable entities.
</tableCaption>
<bodyText confidence="0.999970482758621">
The position and scale of the object are
represented as 3-vectors of floating point numbers.
The rotation is represented as the Euler angles
of the object’s current rotation, also a 3-vector.
This 3-vector is computed as a quaternion for ren-
dering purposes. The transform matrix com-
poses the position, scale, and quaternion rotation
into the complete transformation applied to the ob-
ject at any given frame. The geometry is amesh.
The points, edges, faces, and texture attributes that
comprise the mesh are all immutable at the mo-
ment so the mesh type is considered atomic for
our purposes. The collider contains the coor-
dinates of the center of the object, minimum and
maximum extents of the object’s boundaries, and
radius of the boundaries (for spherical objects).
Behaviors can only be executed over Entity
instances, so we also provide each one with a
currentBehavior property, referencing the
code to be executed over the object every frame
that said behavior is being run. This code performs
a transformation over the object at every step, gen-
erating a new state in a dynamic model of the
event denoted by the a given predicate. Thus, the
event6 is decomposed into frame-by-frame trans-
formations representing the ν-transition from Sec-
tion 3.2.
We generate example simulations of behaviors
in a sample environment, shown in Figure 4, that
</bodyText>
<footnote confidence="0.966062">
6These events are linguistic events, and not the same as
“events” as used in software development or with event han-
dlers.
</footnote>
<figure confidence="0.6472012">
position: 3-vector rotation: 3-vector
scale: 3-vector transform: Matrix
collider = center: 3-vector geometry: Mesh
min: 3-vector
max: 3-vector
radius: float
currentBehavior: Behavior
104
consists of a sealed four-walled room that contains
a number of primitive objects.
</figure>
<figureCaption confidence="0.9925585">
Figure 4: Sample environment in top-down and
perspective views.
</figureCaption>
<bodyText confidence="0.999741714285714">
The behaviors currently coded into our software
map directly from DITL to the simulation. The
various parts of the DITL formula that describes a
given behavior are coded into the behavior’s start
or update functions in Unity. Below is one such
C# code snippet: the per-frame transformation for
roll.
</bodyText>
<equation confidence="0.988157857142857">
(11) transform.rotation = new Vector3(
0.0,0.0,transform.rotation.z+
(rotSpeed*deltaTime));
transform.position = new Vector3(
transform.position.x-radius*
deltaTime,transform.position.y,
transform.position.z);
</equation>
<bodyText confidence="0.954990931818182">
This “translates” the DITL expression (y := w; y
7� w; d(bloc,y) &lt; d(bloc,w))+, (z := v; z 7� v; z-brot
&lt; v-brot),IN(y,Floor)+ while explicitly calculat-
ing the value of the precise differences in location
and rotation between each frame or time step. The
variables moveSpeed, rotSpeed and radius
are given explicit value. deltaTime refers to the
time elapsed between frames.
Translating a DITL formula into executable
code makes evident the differences in minimal
verb pairs, such as the ball (or box) rolled and the
ball (or box) slid. When an object rolls, one area
on the object must remain in contact with the sup-
porting surface, and that area must be adjacent to
the area contacting the surface in the previous time
step. When an object slides, the same area on the
object must contact the supporting surface. Com-
pare the per-frame transformation for slide below
to the given transformation for roll.
(12) transform.position = new Vector3(
transform.position.x-radius*deltaTime,
transform.position.y,
transform.position.z);
This maps the DITL expression (y := w; y 74 w;
d(bloc,y) &lt; d(bloc,w),IN(y,Floor))+. Here, the ob-
ject’s location changes along a path leading away
from the start location, but does not rotate as in
roll.
DITL expressions and their coded equivalents
can also be composed into new, more specific mo-
tions. The cross formula from Section 4 can be
composed with that for roll to describe a “roll
across” motion.
In a model, a path verb such as cross does
not necessarily need an explicit manner of mo-
tion specified. In a simulation, the manner needs
to be given a value, requiring the composition of
the path verb (e.g., cross) with one of a certain
subsets of manner verbs specifying how the ob-
ject moves relative to the supporting surface. Be-
low are DITL expressions and code implementa-
tions for two cross predicates, the first a cross mo-
tion while sliding, the second a cross motion while
rolling.
</bodyText>
<equation confidence="0.986039083333333">
(13) loc(Ball1) := y, tar et(Ball1) := z; b := y;
(y := w; y � w; dxj) &lt; d(b,w), d(b,z) &gt;
d(z,w), IN(y,Floor))+
offset = transform.position-
destination;
offset = Vector3.Normalize(offset);
transform.position = new Vector3(
transform.position.x-offset.x*
radius*deltaTime,
transform.position.y,
transform.position.z-
offset.z*radius*deltaTime);
</equation>
<bodyText confidence="0.97415925">
At each frame, the distance between the object’s
current position and its previously computed des-
tination is computed again, and the update moves
the object away from its current position (d(b,y) &lt;
d(b,w)) toward the destination (d(b,z) &gt; d(z,w)).
Since no other manner of motion is specified, the
object does not turn or rotate as it moves, but sim-
ply “slides.”
</bodyText>
<page confidence="0.979003">
105
</page>
<equation confidence="0.874248529411765">
(14) loc(Ball]) := y, target(Ball]) := z; b := y; (y
:= w; y 7� w; d(blo,,y) &lt; d(blo,,w), d(blo,,z)
&gt; d(z,w), (u := v; u 7� v; u-brot &lt; v-brot),
IN(y,Floor))+
offset = transform.position-
destination;
offset = Vector3.Normalize(offset);
transform.rotation = new Vector3(
0.0,arccos(offset.z)*(360/PI*2),
transform.rotation.z+
(rotSpeed*deltaTime));
transform.position = new Vector3(
transform.position.x-offset.x*
radius*deltaTime,
transform.position.y,
transform.position.z-offset.z*
radius*deltaTime);
</equation>
<bodyText confidence="0.999980878787879">
Here the update is the same as above, but
with the introduction of the rolling motion. In
both code snippets, the non-changing value of
transform.position.y implicitly maps the
IN RCC condition in the DITL formulas, and
keeps the moving object attached to the floor.
If there exists a behavior corresponding to the
predicate (by name) on an entity bearing the name
of the predicate’s first (subject) argument, the
transformation encoded in that behavior is per-
formed over the entity until an end condition spe-
cific to the behavior is met. The resulting animated
motion depicts the manner of motion denoted by
the predicate. Given a predicate of arity greater
than 1, the simulator tries to prompt a behavior on
the first argument that can be run using parameters
of the subsequent arguments.
A cross behavior, for example, divides the
supporting surface into regions and attempts to
move the crossing object from one region to the
the opposite region. In figure 5, the bounds of
Floor completely surround the bounds of Ball2
(IN(Ball2,Floor) in RCC8). This configuration
makes it possible for the simulation to compute a
motion moving the Ball2 object from one side of
the Floor to the other.
The left side of figure 5 shows a ball rolling and
a box sliding, a depiction of two predicates: Box]
slid and Ball] rolled. The right side depicts Ball2
crossed Floor (from the rear center to the front
center). The starting state of each scene is over-
laid semi-transparently while the in-progress state
is fully opaque.
</bodyText>
<sectionHeader confidence="0.992106" genericHeader="discussions">
6 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.99577075">
In this paper, we describe a model for mapping
natural language motion expressions into a 3D
simulation environment. Our strategy has been to
use minimal simulation generation as a conceptual
</bodyText>
<figureCaption confidence="0.8623365">
Figure 5: Roll and slide motions in progress (top),
and cross motion in progress (bottom).
</figureCaption>
<bodyText confidence="0.991510428571429">
debugging tool, in order to tease out the semantic
differences between linguistic expressions; specif-
ically those between verbs that are members of
conventionally homogeneous classes, according to
linguistic analysis.
It should be pointed out that our goal is different
from WordsEye (Coyne and Sproat, 2001). While
we are interested in using simulation generation
to differentiate semantic distinctions in both lex-
ical classes and compositional constructions, the
goal behind WordsEye is to provide an enhanced
interface to allow non-specialists create 3D scenes
without being familiar with special software mod-
els for everyday objects and relations. There are
obvious synergies between these two goals that
can be pursued.
The simulations we create provide an interpre-
tation of the given motion predicate over the given
entity, but not the only interpretation. Just as
Coyne et al. (2010) does for static objects in the
WordsEye system, we must apply some implicit
constraints to our motion predicates to allow them
to be visually simulated. For instance, in the roll
and slide examples given in Figure 5, both objects
are moving in the same direction–parallel to the
back wall of the room object. Had the objects been
moving perpendicular to the back wall or in any
other direction, as long as they remained in con-
</bodyText>
<page confidence="0.996458">
106
</page>
<bodyText confidence="0.99999459770115">
tact with the floor at all times, the simulated mo-
tion would still be considered a “roll” (if rotating
around an axis parallel to the floor), or a “slide”
(if not), regardless of what the precise direction of
motion is. Minimal pairs in a model have to be
compared and contrasted in a discriminative way,
and thus in modeling a slide predicate versus a roll
predicate, knowing that the distinction is one of
rotation parallel to the surface is enough to distin-
guish the two predicates in a model.
In a simulation, the discriminative process re-
quires that the two contrasting behaviors look dif-
ferent, and as such, the simulation software must
be able to completely render a scene for each
frame from behavior start to behavior finish, and
so every variable for every object being rendered
must have an assigned value, including the posi-
tion of the object from frame to frame. If these
values are left unspecified, the software either fails
to compile or throws an exception. Thus, we are
forced to arbitrarily choose a direction of motion
(as well as direction of rotation, speed of rota-
tion, speed of motion, etc.). As long as all non-
changing variables are kept consistent between a
minimal pair of behaviors, we can evaluate the
quantitative and qualitative differences between
the values that do change. As simulations re-
quire values to be assigned to variables that can be
left unspecified in an ordinary modeling process,
simulations expose presuppositions about the se-
mantics of motion verbs and of compositions that
would not be necessary in a model alone.
In order to evaluate the appropriateness of a
given simulation, we are currently experimenting
with a strategy often used in classification and an-
notation tasks, namely pairwise similarity judg-
ments (Rumshisky et al., 2012; Pustejovsky and
Rumshisky, 2014). This involves presenting a user
with a simple discrimination task that has a re-
duced cognitive load, comparing the similarity of
the example to the target instances. In the present
context, a subject is shown a specific simulation
resulting from the translation from textual input,
through DITL, to the visualization. A set of ac-
tivity or event descriptions is given, and the sub-
ject is then asked to select which best describes
the simulation shown; e.g., “Is this a sliding?”, “Is
this a rolling?”. The results of this experiment are
presently being evaluated.
The system is currently in the prototype stage
and needs to be expanded in three main areas: ob-
ject library, parsing pipeline, and predicate han-
dling. Our object and behavior libraries are cur-
rently limited to geometric primitives and the mo-
tions that can be applied over them. While roll,
slide, and cross behaviors can be scripted for
spheres and cubes and shapes derived from them,
a predicate like walk cannot be supported on the
current infrastructure. Thus, we intend to expand
the object library to include more complex inan-
imate objects (tables, chairs, or other household
objects) as well as animate objects. Having an ob-
ject library containing forms capable of executing
greater numbers of predicates will allow us to im-
plement those predicates.
The parsing pipeline described in Section 4 is
only partially implemented, with the only com-
pleted parts being the latter stages, relating a for-
mulas to a scripted behavior and its arguments. We
intend to expand the parsing pipeline to include all
the steps described in this paper: taking input as
a simple natural language sentence, tagging and
parsing it to extract the constituent parts of a pred-
icate/argument representation, and using that out-
put to prompt a behavior in software as a dynamic
event structure. More robust parsing will afford
us the opportunity to expand the diversity of pred-
icates that the software can handle as well (Mc-
Donald and Pustejovsky, 2014). While currently
limited to unary and binary predicates, we need
to extend the capability to ternary predicates and
predicates of greater arity, including the use of ad-
junct phrases and indirect objects. We are in the
process of developing an implementation that uses
Boxer (Curran et al., 2007) so that we can create
first-order models from the dynamic expressions
used here.
</bodyText>
<sectionHeader confidence="0.99495" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9999275">
We would like to thank David McDonald for com-
ments and discussion. We would also like to thank
the reviewers for several substantial suggestions
for improvements and clarifications to the paper.
All remaining errors are of course the responsi-
bilities of the authors. This work was supported
in part by the Department of the Navy, Office of
Naval Research under grant N00014-13-1-0228.
Any opinions, findings, and conclusions or recom-
mendations expressed in this material are those of
the authors and do not necessarily reflect the views
of the Office of Naval Research.
</bodyText>
<page confidence="0.99832">
107
</page>
<sectionHeader confidence="0.989728" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999115757281553">
Nicholas Asher and Laure Vieu. 1995. Towards a ge-
ometry of common sense: a semantics and a com-
plete axiomatisation of merotopology. In Proceed-
ings of IJCAI95, Montreal, Canada.
Benjamin K. Bergen, Shane Lindsay, Teenie Matlock,
and Srini Narayanan. 2007. Spatial and linguistic
aspects of visual imagery in sentence comprehen-
sion. Cognitive Science, 31(5):733–764.
Benjamin K Bergen. 2012. Louder than words: The
new science of how the mind makes meaning. Basic
Books.
Patrick Blackburn and Johan Bos. 2008. Computa-
tional semantics. THEORIA. An International Jour-
nal for Theory, History and Foundations of Science,
18(1).
Paul M Churchland. 1991. Folk psychology and the
explanation of human behavior. The future of folk
psychology: Intentionality and cognitive science,
pages 51–69.
Bob Coyne and Richard Sproat. 2001. Wordseye: an
automatic text-to-scene conversion system. In Pro-
ceedings of the 28th annual conference on Computer
graphics and interactive techniques, pages 487–496.
ACM.
Bob Coyne, Owen Rambow, Julia Hirschberg, and
Richard Sproat. 2010. Frame semantics in text-to-
scene generation. In Knowledge-Based and Intel-
ligent Information and Engineering Systems, pages
375–384. Springer.
James Curran, Stephen Clark, and Johan Bos. 2007.
Linguistically motivated large-scale nlp with c&amp;c
and boxer. In Proceedings of the 45th Annual Meet-
ing of the Association for Computational Linguis-
tics Companion Volume Proceedings of the Demo
and Poster Sessions, pages 33–36, Prague, Czech
Republic, June. Association for Computational Lin-
guistics.
David R Dowty. 1979. Word meaning and Mon-
tague grammar: The semantics of verbs and times in
generative semantics and in Montague’s PTQ, vol-
ume 7. Springer.
C. Eschenbach, C. Habel, L. Kulik, et al. 1999. Rep-
resenting simple trajectories as oriented curves. In
FLAIRS-99, Proceedings of the 12th International
Florida AI Research Society Conference, pages 431–
436.
Jerome Feldman. 2006. From molecule to metaphor:
A neural theory of language. MIT press.
Tim Fernando. 2009. Situations in ltl as strings. Infor-
mation and Computation, 207(10):980–999.
Tim Fernando. 2013. Segmenting temporal intervals
for tense and aspect. In The 13th Meeting on the
Mathematics of Language, page 30.
Christian Freksa. 1992. Using orientation information
for qualitative spatial reasoning. Springer.
Antony Galton. 2000. Qualitative Spatial Change.
Oxford University Press, Oxford.
Antony Galton. 2004. Fields and objects in space,
time, and space-time. Spatial Cognition and Com-
putation, 4(1).
Claire Gardent and Karsten Konrad. 2000. Interpreting
definites using model generation. Journal of Lan-
guage and Computation, 1(2):193–209.
Alvin I Goldman. 1989. Interpretation psycholo-
gized*. Mind &amp; Language, 4(3):161–185.
Alvin I Goldman. 2006. Simulating minds: The phi-
losophy, psychology, and neuroscience of mindread-
ing. Oxford University Press.
Will Goldstone. 2009. Unity Game Development Es-
sentials. Packt Publishing Ltd.
Jeroen Groenendijk and Martin Stokhof. 1990. Dy-
namic predicate logic. Linguistics and Philosophy,
14:39–100.
David Harel, Dexter Kozen, and Jerzy Tiuyn. 2000.
Dynamic Logic. The MIT Press, 1st edition.
David Harel. 1984. Dynamic logic. In M. Gabbay
and F. Gunthner, editors, Handbook of Philosophi-
cal Logic, Volume II: Extensions of Classical Logic,
page 497?604. Reidel.
Ray Jackendoff. 1983. Semantics and Cognition. MIT
Press.
Ray Jackendoff. 1996. The proper treatment of mea-
suring out, telicity, and perhaps even quantification
in english. Natural Language &amp; Linguistic Theory,
14(2):305–354.
Karsten Konrad. 2004. Model generation for natural
language interpretation and analysis, volume 2953.
Springer.
Manfred Krifka. 1992. Thematic relations as links be-
tween nominal reference and temporal constitution.
Lexical matters, 2953.
Benjamin Kuipers. 2000. The spatial semantic hierar-
chy. Artificial Intelligence, 119(1):191–233.
Beth Levin. 1993. English verb class and alternations:
a preliminary investigation. University of Chicago
Press.
S.C. Levinson. 2003. Space in Language and Cog-
nition: Explorations in Cognitive Diversity. Lan-
guage, culture, and cognition. Cambridge University
Press.
Inderjeet Mani and James Pustejovsky. 2012. Inter-
preting Motion: Grounded Representations for Spa-
tial Language. Oxford University Press.
</reference>
<page confidence="0.997357">
108
</page>
<bodyText confidence="0.788770285714286">
Leonard Talmy. 1983. How language structures space.
In Herbert Pick and Linda Acredolo, editors, Spa-
tial Orientation: Theory, Research, and Application.
Plenum Press.
David McDonald and James Pustejovsky. 2014. On
the representation of inferences and their lexicaliza-
tion. In Advances in Cognitive Systems, volume 3.
</bodyText>
<reference confidence="0.999851735294118">
G. Miller and W. Charles. 1991. Contextual corre-
lates of semantic similarity. Language and Cogni-
tive Processes, 6(1):1–28.
George A Miller and Philip N Johnson-Laird. 1976.
Language and perception. Belknap Press.
Srinivas Narayanan. 1999. Reasoning about actions in
narrative understanding. IJCAI, 99:350–357.
Ralf Naumann. 2001. Aspects of changes: a dynamic
event semantics. Journal of semantics, 18:27–81.
James Pustejovsky and Jessica Moszkowicz. 2011.
The qualitative spatial dynamics of motion. The
Journal of Spatial Cognition and Computation.
James Pustejovsky and Anna Rumshisky. 2014. Deep
semantic annotation with shallow methods. LREC
Tutorial, May.
James Pustejovsky, Anna Rumshisky, Olga Batiukova,
and Jessica Moszkowicz. 2014. Annotation of com-
positional operations with glml. In Harry Bunt, ed-
itor, Computing Meaning, pages 217–234. Springer
Netherlands.
J. Pustejovsky. 1995. The Generative Lexicon. Brad-
ford Book. Mit Press.
James Pustejovsky. 2013a. Dynamic event structure
and habitat theory. In Proceedings of the 6th Inter-
national Conference on Generative Approaches to
the Lexicon (GL2013), pages 1–10. ACL.
James Pustejovsky. 2013b. Where things happen: On
the semantics of event localization. In Proceedings
of ISA-9: International Workshop on Semantic An-
notation.
David Randell, Zhan Cui, and Anthony Cohn. 1992.
A spatial logic based on regions and connections. In
Morgan Kaufmann, editor, Proceedings of the 3rd
Internation Conference on Knowledge Representa-
tion and REasoning, pages 165–176, San Mateo.
Susan Rothstein. 2008. Two puzzles for a theory of
lexical aspect: Semelfactives and degree achieve-
ments. Event structures in linguistic form and in-
terpretation, 5:175.
Anna Rumshisky, Nick Botchan, Sophie Kushkuley,
and James Pustejovsky. 2012. Word sense inven-
tories by non-experts. In LREC, pages 4055–4059.
Jeffrey Mark Siskind. 2011. Grounding the lexi-
cal semantics of verbs in visual perception using
force dynamics and event logic. arXiv preprint
arXiv:1106.0256.
Mark Steedman. 2002. Plans, affordances, and combi-
natory grammar. Linguistics and Philosophy, 25(5-
6):723–753.
Leonard Talmy. 1985. Lexicalization patterns: seman-
tic structure in lexical forms. In T. Shopen, editor,
Language typology and semantic description Vol-
ume 3:, pages 36–149. Cambridge University Press.
Leonard Talmy. 2000. Towards a cognitive semantics.
MIT Press.
Johan van Benthem, Jan van Eijck, and Vera Ste-
bletsova. 1994. Modal logic, transition systems
and processes. Journal of Logic and Computation,
4(5):811–855.
Johannes Franciscus Abraham Karel van Benthem.
1991. Logic and the flow of information.
Z. Vendler. 1967. Linguistics in philosophy. Cornell
University Press Ithaca.
J. Zwarts. 2005. Prepositional aspect and the algebra
of paths. Linguistics and Philosophy, 28(6):739–
779.
J. Zwarts. 2006. Event shape: Paths in the semantics
of verbs.
</reference>
<page confidence="0.998958">
109
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.596919">
<title confidence="0.999977">Generating Simulations of Motion Events from Verbal Descriptions</title>
<author confidence="0.994738">James</author>
<affiliation confidence="0.891206">Computer Science Brandeis</affiliation>
<address confidence="0.984463">Waltham, MA USA</address>
<email confidence="0.999858">jamesp@cs.brandeis.edu</email>
<abstract confidence="0.992964242424243">In this paper, we describe a computational model for motion events in natural language that maps from linguistic expressions, through a dynamic event interpretation, into three-dimensional temporal simulations in a model. Starting with the model from (Pustejovsky and Moszkowicz, 2011), we analyze motion events using temporally-traced Labelled Transition Systems. We model the distinction beand in an operational semantics, and further distinguish different types of manner-of-motion verbs in terms of the mereo-topological relations that hold throughout the process of movement. From these representations, we generate minimal models, which are realized as three-dimensional simulations in software developed with the game en- The generated simulations act as a conceptual “debugger” for the semantics of different motion verbs: that is, by testing for consistency and informativeness in the model, simulations expose the presuppositions associated with linguistic expressions and their compositions. Because the model generation component is still incomplete, this paper focuses on an implementation which maps directly from linguistic interpretations into the Unity code snippets that create the simulations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Laure Vieu</author>
</authors>
<title>Towards a geometry of common sense: a semantics and a complete axiomatisation of merotopology.</title>
<date>1995</date>
<booktitle>In Proceedings of IJCAI95,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="14540" citStr="Asher and Vieu, 1995" startWordPosition="2340" endWordPosition="2343">RUN, EPONYMOUS VEHICLE, WALTZ, ACCOMPANY, and CHASE verbs. While suggestive, these distinctions are only partially useful towards actually teasing apart the semantic dimensions along which we identify the contributing factors of manner. Mani and Pustejovsky (2012) suggest a different strategy involving the identification of semantic parameters that clearly differentiate verb senses from each other within this class. One parameter exploited quite extensively within the motion class involves the mereotopological contraints that inhere throughout the movement of the object (Randell et al., 1992; Asher and Vieu, 1995; Galton, 2000). Using this parameter, we are able to distinguish several of Levin’s classes of manner 3Cf. (Pustejovsky, 2013a) and (Krifka, 1992). as well as some novel ones, as described in (9), where a class is defined by the constraints that hold throughout the event (where EC is “externally connected”, and DC is “disconnected”). (9) For Figure (F) relative to Ground (G): a. EC(F,G), throughout motion: b. DC(F,G), throughout motion: c. EC(F,G) followed by DC(F,G), throughout motion: d. Sub-part(F’,F), EC(F’,G) followed by DC(F’,G), throughout motion: e. Containment of F in a Vehicle (V). </context>
</contexts>
<marker>Asher, Vieu, 1995</marker>
<rawString>Nicholas Asher and Laure Vieu. 1995. Towards a geometry of common sense: a semantics and a complete axiomatisation of merotopology. In Proceedings of IJCAI95, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin K Bergen</author>
<author>Shane Lindsay</author>
<author>Teenie Matlock</author>
<author>Srini Narayanan</author>
</authors>
<title>Spatial and linguistic aspects of visual imagery in sentence comprehension.</title>
<date>2007</date>
<journal>Cognitive Science,</journal>
<volume>31</volume>
<issue>5</issue>
<contexts>
<context position="19031" citStr="Bergen et al., 2007" startWordPosition="3079" endWordPosition="3082">oped related ideas quite extensively: simulation theorists, working in the philosophy of mind, such as Alvin Goldman and Robert Gordon; and cognitive scientists and linguists, such as Jerry Feldman, Ron Langacker, and Ben Bergen. According to Goldman (1989), simulation provides a processdriven theory of mind and mental attribution, differing from the theory-driven models proposed by Churchland and others (Churchland, 1991). From the cognitive linguistics tradition, simulation semantics has come to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced in the previous section is inspired by work in minimal model generation (Blackburn and Bos, 2008; Konrad, 2004). Type satisfaction in the compositional process mirrors the theorem proving comp</context>
</contexts>
<marker>Bergen, Lindsay, Matlock, Narayanan, 2007</marker>
<rawString>Benjamin K. Bergen, Shane Lindsay, Teenie Matlock, and Srini Narayanan. 2007. Spatial and linguistic aspects of visual imagery in sentence comprehension. Cognitive Science, 31(5):733–764.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin K Bergen</author>
</authors>
<title>Louder than words: The new science of how the mind makes meaning.</title>
<date>2012</date>
<publisher>Basic Books.</publisher>
<contexts>
<context position="19046" citStr="Bergen, 2012" startWordPosition="3083" endWordPosition="3084">ite extensively: simulation theorists, working in the philosophy of mind, such as Alvin Goldman and Robert Gordon; and cognitive scientists and linguists, such as Jerry Feldman, Ron Langacker, and Ben Bergen. According to Goldman (1989), simulation provides a processdriven theory of mind and mental attribution, differing from the theory-driven models proposed by Churchland and others (Churchland, 1991). From the cognitive linguistics tradition, simulation semantics has come to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced in the previous section is inspired by work in minimal model generation (Blackburn and Bos, 2008; Konrad, 2004). Type satisfaction in the compositional process mirrors the theorem proving component, while co</context>
</contexts>
<marker>Bergen, 2012</marker>
<rawString>Benjamin K Bergen. 2012. Louder than words: The new science of how the mind makes meaning. Basic Books.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Blackburn</author>
<author>Johan Bos</author>
</authors>
<date>2008</date>
<booktitle>Computational semantics. THEORIA. An International Journal for Theory, History and Foundations of Science,</booktitle>
<volume>18</volume>
<issue>1</issue>
<contexts>
<context position="5108" citStr="Blackburn and Bos (2008)" startWordPosition="784" endWordPosition="787"> are all manner of motion verbs, however, any data-derived distinctions that emerge within this class will have to be made in terms of additional syntactic or semantic dimensions. While it is most likely possible to differentiate, for example, the verbs slide from roll, or walk from hop in the corpus, given enough data, it is important to realize that conceptual and theoretical modeling is often necessary to reveal the factors that semantically distinguish such linguistic expressions, in the first place. We argue that this problem can be approached with the use of minimal model generation. As Blackburn and Bos (2008) point out, theorem proving (essentially type satisfaction of a verb in one class as opposed to another) provides a “negative handle” on the problem of determining consistency and informativeness for an utterance, while model building provides a “positive handle” on both. For our concerns, simulation construction provides a positive handle on whether two manner of motion processes are distinguished in the model. Further, the simulation must specify how they are distinguished, the analogue to informativeness. In this paper, we argue that traditional lexical modeling can benefit greatly from exa</context>
<context position="19535" citStr="Blackburn and Bos, 2008" startWordPosition="3154" endWordPosition="3157">to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced in the previous section is inspired by work in minimal model generation (Blackburn and Bos, 2008; Konrad, 2004). Type satisfaction in the compositional process mirrors the theorem proving component, while construction of the specific model helps us distinguish what is inherent in the different manner of motion events. This latter aspect is the “positive handle”, (Blackburn and Bos, 2008) which demonstrates the informativeness of a distinction in our simulation. Simulation software must be able to map a predicate to a known behavior, its arguments to objects in the scene, and then prompt those objects to execute the behavior. A simple input sentence needs 5Obviously, true synonyms in the </context>
</contexts>
<marker>Blackburn, Bos, 2008</marker>
<rawString>Patrick Blackburn and Johan Bos. 2008. Computational semantics. THEORIA. An International Journal for Theory, History and Foundations of Science, 18(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul M Churchland</author>
</authors>
<title>Folk psychology and the explanation of human behavior. The future of folk psychology: Intentionality and cognitive science,</title>
<date>1991</date>
<pages>51--69</pages>
<contexts>
<context position="18838" citStr="Churchland, 1991" startWordPosition="3051" endWordPosition="3052"> be defined and isolated in three-dimensional space. The idea of constructing simulations from linguistic utterances is, of course, not new. There are two groups of researchers who have developed related ideas quite extensively: simulation theorists, working in the philosophy of mind, such as Alvin Goldman and Robert Gordon; and cognitive scientists and linguists, such as Jerry Feldman, Ron Langacker, and Ben Bergen. According to Goldman (1989), simulation provides a processdriven theory of mind and mental attribution, differing from the theory-driven models proposed by Churchland and others (Churchland, 1991). From the cognitive linguistics tradition, simulation semantics has come to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced</context>
</contexts>
<marker>Churchland, 1991</marker>
<rawString>Paul M Churchland. 1991. Folk psychology and the explanation of human behavior. The future of folk psychology: Intentionality and cognitive science, pages 51–69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Coyne</author>
<author>Richard Sproat</author>
</authors>
<title>Wordseye: an automatic text-to-scene conversion system.</title>
<date>2001</date>
<booktitle>In Proceedings of the 28th annual conference on Computer graphics and interactive techniques,</booktitle>
<pages>487--496</pages>
<publisher>ACM.</publisher>
<contexts>
<context position="6111" citStr="Coyne and Sproat, 2001" startWordPosition="935" endWordPosition="938">es are distinguished in the model. Further, the simulation must specify how they are distinguished, the analogue to informativeness. In this paper, we argue that traditional lexical modeling can benefit greatly from examining how semantic interpretations are contextually and conceptually grounded. We explore a dynamic interpretation of the lexical semantic model developed in Generative Lexicon Theory (Pustejovsky, 1995; Pustejovsky et al., 2014). Specifically, we are interested in using model building (Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Because of their grammatical and semantic import, lingui</context>
<context position="30190" citStr="Coyne and Sproat, 2001" startWordPosition="4839" endWordPosition="4842">ue. 6 Discussion and Conclusion In this paper, we describe a model for mapping natural language motion expressions into a 3D simulation environment. Our strategy has been to use minimal simulation generation as a conceptual Figure 5: Roll and slide motions in progress (top), and cross motion in progress (bottom). debugging tool, in order to tease out the semantic differences between linguistic expressions; specifically those between verbs that are members of conventionally homogeneous classes, according to linguistic analysis. It should be pointed out that our goal is different from WordsEye (Coyne and Sproat, 2001). While we are interested in using simulation generation to differentiate semantic distinctions in both lexical classes and compositional constructions, the goal behind WordsEye is to provide an enhanced interface to allow non-specialists create 3D scenes without being familiar with special software models for everyday objects and relations. There are obvious synergies between these two goals that can be pursued. The simulations we create provide an interpretation of the given motion predicate over the given entity, but not the only interpretation. Just as Coyne et al. (2010) does for static o</context>
</contexts>
<marker>Coyne, Sproat, 2001</marker>
<rawString>Bob Coyne and Richard Sproat. 2001. Wordseye: an automatic text-to-scene conversion system. In Proceedings of the 28th annual conference on Computer graphics and interactive techniques, pages 487–496. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bob Coyne</author>
<author>Owen Rambow</author>
<author>Julia Hirschberg</author>
<author>Richard Sproat</author>
</authors>
<title>Frame semantics in text-toscene generation.</title>
<date>2010</date>
<booktitle>In Knowledge-Based and Intelligent Information and Engineering Systems,</booktitle>
<pages>375--384</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="30772" citStr="Coyne et al. (2010)" startWordPosition="4928" endWordPosition="4931">rom WordsEye (Coyne and Sproat, 2001). While we are interested in using simulation generation to differentiate semantic distinctions in both lexical classes and compositional constructions, the goal behind WordsEye is to provide an enhanced interface to allow non-specialists create 3D scenes without being familiar with special software models for everyday objects and relations. There are obvious synergies between these two goals that can be pursued. The simulations we create provide an interpretation of the given motion predicate over the given entity, but not the only interpretation. Just as Coyne et al. (2010) does for static objects in the WordsEye system, we must apply some implicit constraints to our motion predicates to allow them to be visually simulated. For instance, in the roll and slide examples given in Figure 5, both objects are moving in the same direction–parallel to the back wall of the room object. Had the objects been moving perpendicular to the back wall or in any other direction, as long as they remained in con106 tact with the floor at all times, the simulated motion would still be considered a “roll” (if rotating around an axis parallel to the floor), or a “slide” (if not), rega</context>
</contexts>
<marker>Coyne, Rambow, Hirschberg, Sproat, 2010</marker>
<rawString>Bob Coyne, Owen Rambow, Julia Hirschberg, and Richard Sproat. 2010. Frame semantics in text-toscene generation. In Knowledge-Based and Intelligent Information and Engineering Systems, pages 375–384. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Curran</author>
<author>Stephen Clark</author>
<author>Johan Bos</author>
</authors>
<title>Linguistically motivated large-scale nlp with c&amp;c and boxer.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions,</booktitle>
<pages>33--36</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="35314" citStr="Curran et al., 2007" startWordPosition="5687" endWordPosition="5690">sing it to extract the constituent parts of a predicate/argument representation, and using that output to prompt a behavior in software as a dynamic event structure. More robust parsing will afford us the opportunity to expand the diversity of predicates that the software can handle as well (McDonald and Pustejovsky, 2014). While currently limited to unary and binary predicates, we need to extend the capability to ternary predicates and predicates of greater arity, including the use of adjunct phrases and indirect objects. We are in the process of developing an implementation that uses Boxer (Curran et al., 2007) so that we can create first-order models from the dynamic expressions used here. Acknowledgements We would like to thank David McDonald for comments and discussion. We would also like to thank the reviewers for several substantial suggestions for improvements and clarifications to the paper. All remaining errors are of course the responsibilities of the authors. This work was supported in part by the Department of the Navy, Office of Naval Research under grant N00014-13-1-0228. Any opinions, findings, and conclusions or recommendations expressed in this material are those of the authors and d</context>
</contexts>
<marker>Curran, Clark, Bos, 2007</marker>
<rawString>James Curran, Stephen Clark, and Johan Bos. 2007. Linguistically motivated large-scale nlp with c&amp;c and boxer. In Proceedings of the 45th Annual Meeting of the Association for Computational Linguistics Companion Volume Proceedings of the Demo and Poster Sessions, pages 33–36, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David R Dowty</author>
</authors>
<title>Word meaning and Montague grammar: The semantics of verbs and times in generative semantics and in Montague’s PTQ,</title>
<date>1979</date>
<volume>7</volume>
<publisher>Springer.</publisher>
<contexts>
<context position="16079" citStr="Dowty, 1979" startWordPosition="2591" endWordPosition="2592">state content in the motion n-gram: namely, there is a continuous satisfaction of EC(F,G) throughout the motion for slide and a toggling effect (on-off) for the predicates bounce and hop, as shown in (10). -DC(x,G)? x (10) loc(z) = x e0 -DC(x,G)? x loc(z) = y2 e2 With the surface as the ground argument, these verbs are defined in terms of two transitions.4 Figure 1: Slide Motion Figure 2: Hop Motion 4Many natural language predicates require reference to at least three states. These include the semelfactives mentioned above, as well as blink and iterative uses of knock and clap (Vendler, 1967; Dowty, 1979; Rothstein, 2008). s1 s2 s3 A A A B l1 l2 l3 s1 s2 s3 A A B l1 l2 l3 A (loc(x)=,4D)? x (8) loc(z) = x e0 −→ v −→ . . . v DC(x,G)? x loc(z) = y1 e1 −→ v −→v 102 Distinguishing between a sliding motion and a rolling motion is also fairly straightforward. We have the entailments that result from each kind of motion, given a set of initial conditions, as in the following short sentence describing the motion of a ball relative to a floor (the domain for our event simulations). • The ball slid.: At the termination of the action, object ball has moved relative to a surface in a manner that is [+tran</context>
</contexts>
<marker>Dowty, 1979</marker>
<rawString>David R Dowty. 1979. Word meaning and Montague grammar: The semantics of verbs and times in generative semantics and in Montague’s PTQ, volume 7. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Eschenbach</author>
<author>C Habel</author>
<author>L Kulik</author>
</authors>
<title>Representing simple trajectories as oriented curves.</title>
<date>1999</date>
<booktitle>In FLAIRS-99, Proceedings of the 12th International Florida AI Research Society Conference,</booktitle>
<pages>431--436</pages>
<contexts>
<context position="7897" citStr="Eschenbach et al. (1999)" startWordPosition="1219" endWordPosition="1222">, 2000). Related to this idea, both Zwarts (2005) and Pustejovsky and Moszkowicz (2011) develop mechanisms for dynamically creating the path traversed by a mover in a manner of motion predicate, such as run or drive. Starting with this approach, the localization of a motion event, therefore, is at least minimally associated with the path created by virtue of the activity. In addition to capturing the spatial trace of the object in motion, several researchers have pointed out that identifying the shape of the path during motion is also critical for fully interpreting the semantics of movement. Eschenbach et al. (1999) discusses the orientation associated with the trajectory, something they refer to as oriented curves. Motivated more by linguistic considerations, Zwarts (2006) introduces the notion of an event shape, which is the trajectory associated with an event in space represented by a path. He defines a shape function, which is a partial function assigning unique paths to those events involving motion or extension in physical space. This work suggests that the localization of an event 100 makes reference to orientational as well as configurational factors, a view that is pursued in Pustejovsky (2013b)</context>
</contexts>
<marker>Eschenbach, Habel, Kulik, 1999</marker>
<rawString>C. Eschenbach, C. Habel, L. Kulik, et al. 1999. Representing simple trajectories as oriented curves. In FLAIRS-99, Proceedings of the 12th International Florida AI Research Society Conference, pages 431– 436.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jerome Feldman</author>
</authors>
<title>From molecule to metaphor: A neural theory of language.</title>
<date>2006</date>
<publisher>MIT press.</publisher>
<contexts>
<context position="19010" citStr="Feldman, 2006" startWordPosition="3077" endWordPosition="3078"> who have developed related ideas quite extensively: simulation theorists, working in the philosophy of mind, such as Alvin Goldman and Robert Gordon; and cognitive scientists and linguists, such as Jerry Feldman, Ron Langacker, and Ben Bergen. According to Goldman (1989), simulation provides a processdriven theory of mind and mental attribution, differing from the theory-driven models proposed by Churchland and others (Churchland, 1991). From the cognitive linguistics tradition, simulation semantics has come to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced in the previous section is inspired by work in minimal model generation (Blackburn and Bos, 2008; Konrad, 2004). Type satisfaction in the compositional process mirrors the</context>
</contexts>
<marker>Feldman, 2006</marker>
<rawString>Jerome Feldman. 2006. From molecule to metaphor: A neural theory of language. MIT press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>Situations in ltl as strings.</title>
<date>2009</date>
<journal>Information and Computation,</journal>
<volume>207</volume>
<issue>10</issue>
<contexts>
<context position="10558" citStr="Fernando, 2009" startWordPosition="1660" endWordPosition="1662">rams are input/output relations ( [π] ⊆ S × S), and compound programs are constructed from atomic ones following rules of dynamic logic (Harel et al., 2000). For the present discussion, we represent the dynamics of actions in terms of Labeled Transition Systems (LTSs) (van Benthem, 1991).1 An LTS consists of a triple, hS, Act, →i, where: S is the set of states; Act is a set of actions; and → is a total transition relation: →⊆ S×Act×S. An action, α ∈ Act, provides the labeling on an arrow, making it explicit what brings about a state-to-state 1This is consistent with the approach developed in (Fernando, 2009; Fernando, 2013). This approach to a dynamic interpretation of change in language semantics is also inspired by Steedman (2002). transition. As a shorthand for (e1, α, e2) ∈→, we will also use e1 −→ e2. If reference to the state α content (rather than state name) is required for interpretation purposes (van Benthem et al., 1994), then as shorthand for ({φ} ¬φ .Finally, when referring e2 to temporally-indexed states in the model, where ei@i indicates the state ei interpreted at time i, as shorthand for ({φ}e1@i, α, {¬φ}e2@i+1) ∈→, we , as described in Pustee2 jovsky(2013). 3.2 Distinguishing P</context>
</contexts>
<marker>Fernando, 2009</marker>
<rawString>Tim Fernando. 2009. Situations in ltl as strings. Information and Computation, 207(10):980–999.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tim Fernando</author>
</authors>
<title>Segmenting temporal intervals for tense and aspect.</title>
<date>2013</date>
<booktitle>In The 13th Meeting on the Mathematics of Language,</booktitle>
<pages>30</pages>
<contexts>
<context position="10575" citStr="Fernando, 2013" startWordPosition="1663" endWordPosition="1664">utput relations ( [π] ⊆ S × S), and compound programs are constructed from atomic ones following rules of dynamic logic (Harel et al., 2000). For the present discussion, we represent the dynamics of actions in terms of Labeled Transition Systems (LTSs) (van Benthem, 1991).1 An LTS consists of a triple, hS, Act, →i, where: S is the set of states; Act is a set of actions; and → is a total transition relation: →⊆ S×Act×S. An action, α ∈ Act, provides the labeling on an arrow, making it explicit what brings about a state-to-state 1This is consistent with the approach developed in (Fernando, 2009; Fernando, 2013). This approach to a dynamic interpretation of change in language semantics is also inspired by Steedman (2002). transition. As a shorthand for (e1, α, e2) ∈→, we will also use e1 −→ e2. If reference to the state α content (rather than state name) is required for interpretation purposes (van Benthem et al., 1994), then as shorthand for ({φ} ¬φ .Finally, when referring e2 to temporally-indexed states in the model, where ei@i indicates the state ei interpreted at time i, as shorthand for ({φ}e1@i, α, {¬φ}e2@i+1) ∈→, we , as described in Pustee2 jovsky(2013). 3.2 Distinguishing Path and Manner Mo</context>
</contexts>
<marker>Fernando, 2013</marker>
<rawString>Tim Fernando. 2013. Segmenting temporal intervals for tense and aspect. In The 13th Meeting on the Mathematics of Language, page 30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian Freksa</author>
</authors>
<title>Using orientation information for qualitative spatial reasoning.</title>
<date>1992</date>
<publisher>Springer.</publisher>
<contexts>
<context position="6594" citStr="Freksa, 1992" startWordPosition="1011" endWordPosition="1012">odel building (Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Because of their grammatical and semantic import, linguistic interest in identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, the path can be</context>
</contexts>
<marker>Freksa, 1992</marker>
<rawString>Christian Freksa. 1992. Using orientation information for qualitative spatial reasoning. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antony Galton</author>
</authors>
<title>Qualitative Spatial Change.</title>
<date>2000</date>
<publisher>Oxford University Press,</publisher>
<location>Oxford.</location>
<contexts>
<context position="6608" citStr="Galton, 2000" startWordPosition="1013" endWordPosition="1014">(Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Because of their grammatical and semantic import, linguistic interest in identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, the path can be identified as</context>
<context position="14555" citStr="Galton, 2000" startWordPosition="2344" endWordPosition="2346">, WALTZ, ACCOMPANY, and CHASE verbs. While suggestive, these distinctions are only partially useful towards actually teasing apart the semantic dimensions along which we identify the contributing factors of manner. Mani and Pustejovsky (2012) suggest a different strategy involving the identification of semantic parameters that clearly differentiate verb senses from each other within this class. One parameter exploited quite extensively within the motion class involves the mereotopological contraints that inhere throughout the movement of the object (Randell et al., 1992; Asher and Vieu, 1995; Galton, 2000). Using this parameter, we are able to distinguish several of Levin’s classes of manner 3Cf. (Pustejovsky, 2013a) and (Krifka, 1992). as well as some novel ones, as described in (9), where a class is defined by the constraints that hold throughout the event (where EC is “externally connected”, and DC is “disconnected”). (9) For Figure (F) relative to Ground (G): a. EC(F,G), throughout motion: b. DC(F,G), throughout motion: c. EC(F,G) followed by DC(F,G), throughout motion: d. Sub-part(F’,F), EC(F’,G) followed by DC(F’,G), throughout motion: e. Containment of F in a Vehicle (V). For example, co</context>
</contexts>
<marker>Galton, 2000</marker>
<rawString>Antony Galton. 2000. Qualitative Spatial Change. Oxford University Press, Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antony Galton</author>
</authors>
<title>Fields and objects in space, time, and space-time.</title>
<date>2004</date>
<journal>Spatial Cognition and Computation,</journal>
<volume>4</volume>
<issue>1</issue>
<contexts>
<context position="12825" citStr="Galton, 2004" startWordPosition="2072" endWordPosition="2073">1 e1 −→ . . . ν� loc(z) = yn e,,, This now provides us with our dynamic interpretation of directed manner of motion verbs, such as slide, swim, roll, where we have an iteration of assignments of locations, undistinguished except 2Cf. Groenendijk and Stokhof (1990) for dynamic updating, and Naumann (2001) for a related analysis. e1, α, {¬φ}e2) ∈→, we −→ α use, φ e1 i −→α will use, φ e1 ¬φ i+1 � C? ν ei −→ ei+1. (7) loc(z) = x e0 −→ ν� 101 that the values are order-preserving according to a scalar constraint. This is quite different from the dynamic interpretation of path predicates. Following (Galton, 2004; Pustejovsky and Moszkowicz, 2011), path predicates such as arrive and leave make reference to a “distinguished location”, not an arbitrary location. For example, the ball enters the room is satisified when the distinguished location, D, (the room) is successfully tested as the location for the moving object. That is, the location is tested against the current location for an object ((loc(x) =� D)?), and retested until it is satisfied ((loc(x) = D)?). (loc(x)=,4D)? x loc(z) = y1 e1 (loc(x)=D)? x loc(z) = yn en While beyond the scope of the present discussion, it is worth noting that the model</context>
</contexts>
<marker>Galton, 2004</marker>
<rawString>Antony Galton. 2004. Fields and objects in space, time, and space-time. Spatial Cognition and Computation, 4(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Claire Gardent</author>
<author>Karsten Konrad</author>
</authors>
<title>Interpreting definites using model generation.</title>
<date>2000</date>
<journal>Journal of Language and Computation,</journal>
<volume>1</volume>
<issue>2</issue>
<contexts>
<context position="6061" citStr="Gardent and Konrad, 2000" startWordPosition="927" endWordPosition="931">sitive handle on whether two manner of motion processes are distinguished in the model. Further, the simulation must specify how they are distinguished, the analogue to informativeness. In this paper, we argue that traditional lexical modeling can benefit greatly from examining how semantic interpretations are contextually and conceptually grounded. We explore a dynamic interpretation of the lexical semantic model developed in Generative Lexicon Theory (Pustejovsky, 1995; Pustejovsky et al., 2014). Specifically, we are interested in using model building (Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Becaus</context>
</contexts>
<marker>Gardent, Konrad, 2000</marker>
<rawString>Claire Gardent and Karsten Konrad. 2000. Interpreting definites using model generation. Journal of Language and Computation, 1(2):193–209.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alvin I Goldman</author>
</authors>
<title>Interpretation psychologized*.</title>
<date>1989</date>
<journal>Mind &amp; Language,</journal>
<volume>4</volume>
<issue>3</issue>
<contexts>
<context position="18669" citStr="Goldman (1989)" startWordPosition="3027" endWordPosition="3028">ates and identify the precise primitive components of a motion verb, we build a real-time simulation, within which the individual features of a single motion verb can be defined and isolated in three-dimensional space. The idea of constructing simulations from linguistic utterances is, of course, not new. There are two groups of researchers who have developed related ideas quite extensively: simulation theorists, working in the philosophy of mind, such as Alvin Goldman and Robert Gordon; and cognitive scientists and linguists, such as Jerry Feldman, Ron Langacker, and Ben Bergen. According to Goldman (1989), simulation provides a processdriven theory of mind and mental attribution, differing from the theory-driven models proposed by Churchland and others (Churchland, 1991). From the cognitive linguistics tradition, simulation semantics has come to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have di</context>
</contexts>
<marker>Goldman, 1989</marker>
<rawString>Alvin I Goldman. 1989. Interpretation psychologized*. Mind &amp; Language, 4(3):161–185.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alvin I Goldman</author>
</authors>
<title>Simulating minds: The philosophy, psychology, and neuroscience of mindreading.</title>
<date>2006</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="19354" citStr="Goldman, 2006" startWordPosition="3128" endWordPosition="3129">tion, differing from the theory-driven models proposed by Churchland and others (Churchland, 1991). From the cognitive linguistics tradition, simulation semantics has come to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced in the previous section is inspired by work in minimal model generation (Blackburn and Bos, 2008; Konrad, 2004). Type satisfaction in the compositional process mirrors the theorem proving component, while construction of the specific model helps us distinguish what is inherent in the different manner of motion events. This latter aspect is the “positive handle”, (Blackburn and Bos, 2008) which demonstrates the informativeness of a distinction in our simulation. Simulation software must be able to map a predica</context>
</contexts>
<marker>Goldman, 2006</marker>
<rawString>Alvin I Goldman. 2006. Simulating minds: The philosophy, psychology, and neuroscience of mindreading. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Will Goldstone</author>
</authors>
<title>Unity Game Development Essentials.</title>
<date>2009</date>
<publisher>Packt Publishing Ltd.</publisher>
<contexts>
<context position="22200" citStr="Goldstone, 2009" startWordPosition="3602" endWordPosition="3603"> b := y; (y := w; y # w; d(b,y) &lt; d(b,w), d(b,z) &gt; d(z,w), IN(y,Floor))+ roll(Ball1) loc(Ball1) := y, rot(Ball1) := z; bloc := y, brot := z; (y := w; y 54 w; d(bloc,y) &lt; d(bloc,w), IN(y,Floor))+, (z := v; z # v; z-brot &lt; v-brot)+ Table 3: DITL expressions for Ball1 crossed Floor and Ball1 rolled. The DITL expression forms the basis of the coded behavior. The first two initialization steps are coded into the behavior’s start function while the the third, Kleene iterated step, is encoded in the behavior’s update function. 5 Generating Simulations We use the freely-available game engine, Unity, (Goldstone, 2009) to handle all underlying graphics processing, and limited our object library to simple primitive shapes of spheroids, rectangular prisms, and planes. For every instance of an object, the game engine maintains a data structure for the object’s virtual representation. Table 4 shows the data structure for Entity, the superclass of all movable objects. Entity: Table 4: Data structure of motion-capable entities. The position and scale of the object are represented as 3-vectors of floating point numbers. The rotation is represented as the Euler angles of the object’s current rotation, also a 3-vect</context>
</contexts>
<marker>Goldstone, 2009</marker>
<rawString>Will Goldstone. 2009. Unity Game Development Essentials. Packt Publishing Ltd.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeroen Groenendijk</author>
<author>Martin Stokhof</author>
</authors>
<date>1990</date>
<booktitle>Dynamic predicate logic. Linguistics and Philosophy,</booktitle>
<pages>14--39</pages>
<contexts>
<context position="12477" citStr="Groenendijk and Stokhof (1990)" startWordPosition="2002" endWordPosition="2005">e inadequate. That is, they are guarded transitions where the test is not just non-coreference, but makes reference to values on a scale, C, and ensures that it continues in an order-preserving change through the iterations. When this test references the values on a scale, C, we call this a directed ν-transition (~ν), e.g., x -,&lt; y, x &gt; ,--y: (6) ν~ =df loc(z) = y1 e1 −→ . . . ν� loc(z) = yn e,,, This now provides us with our dynamic interpretation of directed manner of motion verbs, such as slide, swim, roll, where we have an iteration of assignments of locations, undistinguished except 2Cf. Groenendijk and Stokhof (1990) for dynamic updating, and Naumann (2001) for a related analysis. e1, α, {¬φ}e2) ∈→, we −→ α use, φ e1 i −→α will use, φ e1 ¬φ i+1 � C? ν ei −→ ei+1. (7) loc(z) = x e0 −→ ν� 101 that the values are order-preserving according to a scalar constraint. This is quite different from the dynamic interpretation of path predicates. Following (Galton, 2004; Pustejovsky and Moszkowicz, 2011), path predicates such as arrive and leave make reference to a “distinguished location”, not an arbitrary location. For example, the ball enters the room is satisified when the distinguished location, D, (the room) is</context>
</contexts>
<marker>Groenendijk, Stokhof, 1990</marker>
<rawString>Jeroen Groenendijk and Martin Stokhof. 1990. Dynamic predicate logic. Linguistics and Philosophy, 14:39–100.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Harel</author>
<author>Dexter Kozen</author>
<author>Jerzy Tiuyn</author>
</authors>
<title>Dynamic Logic.</title>
<date>2000</date>
<publisher>The MIT Press,</publisher>
<contexts>
<context position="10100" citStr="Harel et al., 2000" startWordPosition="1575" endWordPosition="1578">s using updating typically make reference to the notion of a state transition (van Benthem, 1991; Harel, 1984). This is done by distinguishing between formulae, φ, and programs, π. A formula is interpreted as a classical propositional expression, with assignment of a truth value in a specific model. We will interpret specific models by reference to specific states. A state is a set of propositions with assignments to variables at a specific index. Atomic programs are input/output relations ( [π] ⊆ S × S), and compound programs are constructed from atomic ones following rules of dynamic logic (Harel et al., 2000). For the present discussion, we represent the dynamics of actions in terms of Labeled Transition Systems (LTSs) (van Benthem, 1991).1 An LTS consists of a triple, hS, Act, →i, where: S is the set of states; Act is a set of actions; and → is a total transition relation: →⊆ S×Act×S. An action, α ∈ Act, provides the labeling on an arrow, making it explicit what brings about a state-to-state 1This is consistent with the approach developed in (Fernando, 2009; Fernando, 2013). This approach to a dynamic interpretation of change in language semantics is also inspired by Steedman (2002). transition. </context>
</contexts>
<marker>Harel, Kozen, Tiuyn, 2000</marker>
<rawString>David Harel, Dexter Kozen, and Jerzy Tiuyn. 2000. Dynamic Logic. The MIT Press, 1st edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Harel</author>
</authors>
<title>Dynamic logic.</title>
<date>1984</date>
<booktitle>Handbook of Philosophical Logic, Volume II: Extensions of Classical Logic,</booktitle>
<pages>497--604</pages>
<editor>In M. Gabbay and F. Gunthner, editors,</editor>
<contexts>
<context position="9591" citStr="Harel, 1984" startWordPosition="1492" endWordPosition="1493">ve). We return to this issue later in the paper when constructing our simulation from the semantic interpretation associated with motion events. 3 Modeling Motion in Language 3.1 Theoretical Assumptions The advantage of adopting a dynamic interpretation of motion is that we can directly distinguish path predication from manner of motion predication in an operational semantics (Miller and Charles, 1991; Miller and Johnson-Laird, 1976) that maps nicely to a simulation environment. Models of processes using updating typically make reference to the notion of a state transition (van Benthem, 1991; Harel, 1984). This is done by distinguishing between formulae, φ, and programs, π. A formula is interpreted as a classical propositional expression, with assignment of a truth value in a specific model. We will interpret specific models by reference to specific states. A state is a set of propositions with assignments to variables at a specific index. Atomic programs are input/output relations ( [π] ⊆ S × S), and compound programs are constructed from atomic ones following rules of dynamic logic (Harel et al., 2000). For the present discussion, we represent the dynamics of actions in terms of Labeled Tran</context>
</contexts>
<marker>Harel, 1984</marker>
<rawString>David Harel. 1984. Dynamic logic. In M. Gabbay and F. Gunthner, editors, Handbook of Philosophical Logic, Volume II: Extensions of Classical Logic, page 497?604. Reidel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>Semantics and Cognition.</title>
<date>1983</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2816" citStr="Jackendoff, 1983" startWordPosition="409" endWordPosition="410">n lexical semantic analysis, a standard methodology in both theoretical and computational linguistics is to identify features in a corpus that differentiate the data in meaningful ways; meaningful in terms of prior theoretical assumptions or in terms of observably differentiated behaviors. Combining these strategies we might, for instance, take a theoretical constraint that we hope to justify through behavioral distinctions in the data. An example of this is the theoretical claim that motion verbs can be meaningfully divided into two classes: manner- and path-oriented predicates (Talmy, 1985; Jackendoff, 1983; Talmy, 2000). These constructions can be viewed as encoding two aspects of meaning: how the movement is happening and where it is happening. The former strategy is illustrated in (2a) and the latter in (2b) (where m indicates a manner verb, and p indicates a path verb). (2) a. The ball rolledm. b. The ball crossedp the room. With both of the verb types, adjunction can make reference to the missing aspect of motion, by introducing a path (as in (3a)) or the manner of movement (in (3b)). (3) a. The ball rolledm across the room. b. The ball crossedp the room rolling. Differences in syntactic di</context>
<context position="6843" citStr="Jackendoff (1983)" startWordPosition="1048" endWordPosition="1050">we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Because of their grammatical and semantic import, linguistic interest in identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, the path can be identified as the central element in defining the location of the event (Talmy, 2000). Related to this idea, both Zwarts (2005) and Pustejovsky and Moszkowicz (2011) develop mechanisms for dynamically creating the path traversed by a mover in a man</context>
</contexts>
<marker>Jackendoff, 1983</marker>
<rawString>Ray Jackendoff. 1983. Semantics and Cognition. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>The proper treatment of measuring out, telicity, and perhaps even quantification in english.</title>
<date>1996</date>
<journal>Natural Language &amp; Linguistic Theory,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="15333" citStr="Jackendoff, 1996" startWordPosition="2467" endWordPosition="2468"> as described in (9), where a class is defined by the constraints that hold throughout the event (where EC is “externally connected”, and DC is “disconnected”). (9) For Figure (F) relative to Ground (G): a. EC(F,G), throughout motion: b. DC(F,G), throughout motion: c. EC(F,G) followed by DC(F,G), throughout motion: d. Sub-part(F’,F), EC(F’,G) followed by DC(F’,G), throughout motion: e. Containment of F in a Vehicle (V). For example, consider the semantic distinction between the verbs slide and hop or bounce. When the latter are employed in induced (directed) motion constructions (Levin, 1993; Jackendoff, 1996), they take on the meaning of manner of motion verbs. Distinguishing between a sliding and hopping motion involves inspecting the next-state content in the motion n-gram: namely, there is a continuous satisfaction of EC(F,G) throughout the motion for slide and a toggling effect (on-off) for the predicates bounce and hop, as shown in (10). -DC(x,G)? x (10) loc(z) = x e0 -DC(x,G)? x loc(z) = y2 e2 With the surface as the ground argument, these verbs are defined in terms of two transitions.4 Figure 1: Slide Motion Figure 2: Hop Motion 4Many natural language predicates require reference to at leas</context>
</contexts>
<marker>Jackendoff, 1996</marker>
<rawString>Ray Jackendoff. 1996. The proper treatment of measuring out, telicity, and perhaps even quantification in english. Natural Language &amp; Linguistic Theory, 14(2):305–354.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Karsten Konrad</author>
</authors>
<title>Model generation for natural language interpretation and analysis,</title>
<date>2004</date>
<volume>volume</volume>
<pages>2953</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="6034" citStr="Konrad, 2004" startWordPosition="925" endWordPosition="926"> provides a positive handle on whether two manner of motion processes are distinguished in the model. Further, the simulation must specify how they are distinguished, the analogue to informativeness. In this paper, we argue that traditional lexical modeling can benefit greatly from examining how semantic interpretations are contextually and conceptually grounded. We explore a dynamic interpretation of the lexical semantic model developed in Generative Lexicon Theory (Pustejovsky, 1995; Pustejovsky et al., 2014). Specifically, we are interested in using model building (Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and</context>
<context position="19550" citStr="Konrad, 2004" startWordPosition="3158" endWordPosition="3159">antiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced in the previous section is inspired by work in minimal model generation (Blackburn and Bos, 2008; Konrad, 2004). Type satisfaction in the compositional process mirrors the theorem proving component, while construction of the specific model helps us distinguish what is inherent in the different manner of motion events. This latter aspect is the “positive handle”, (Blackburn and Bos, 2008) which demonstrates the informativeness of a distinction in our simulation. Simulation software must be able to map a predicate to a known behavior, its arguments to objects in the scene, and then prompt those objects to execute the behavior. A simple input sentence needs 5Obviously, true synonyms in the lexicon would n</context>
</contexts>
<marker>Konrad, 2004</marker>
<rawString>Karsten Konrad. 2004. Model generation for natural language interpretation and analysis, volume 2953. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Manfred Krifka</author>
</authors>
<title>Thematic relations as links between nominal reference and temporal constitution. Lexical matters,</title>
<date>1992</date>
<pages>2953</pages>
<contexts>
<context position="14687" citStr="Krifka, 1992" startWordPosition="2365" endWordPosition="2366">he semantic dimensions along which we identify the contributing factors of manner. Mani and Pustejovsky (2012) suggest a different strategy involving the identification of semantic parameters that clearly differentiate verb senses from each other within this class. One parameter exploited quite extensively within the motion class involves the mereotopological contraints that inhere throughout the movement of the object (Randell et al., 1992; Asher and Vieu, 1995; Galton, 2000). Using this parameter, we are able to distinguish several of Levin’s classes of manner 3Cf. (Pustejovsky, 2013a) and (Krifka, 1992). as well as some novel ones, as described in (9), where a class is defined by the constraints that hold throughout the event (where EC is “externally connected”, and DC is “disconnected”). (9) For Figure (F) relative to Ground (G): a. EC(F,G), throughout motion: b. DC(F,G), throughout motion: c. EC(F,G) followed by DC(F,G), throughout motion: d. Sub-part(F’,F), EC(F’,G) followed by DC(F’,G), throughout motion: e. Containment of F in a Vehicle (V). For example, consider the semantic distinction between the verbs slide and hop or bounce. When the latter are employed in induced (directed) motion</context>
</contexts>
<marker>Krifka, 1992</marker>
<rawString>Manfred Krifka. 1992. Thematic relations as links between nominal reference and temporal constitution. Lexical matters, 2953.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Benjamin Kuipers</author>
</authors>
<title>The spatial semantic hierarchy.</title>
<date>2000</date>
<journal>Artificial Intelligence,</journal>
<volume>119</volume>
<issue>1</issue>
<contexts>
<context position="6580" citStr="Kuipers, 2000" startWordPosition="1009" endWordPosition="1010">sted in using model building (Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Because of their grammatical and semantic import, linguistic interest in identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, t</context>
</contexts>
<marker>Kuipers, 2000</marker>
<rawString>Benjamin Kuipers. 2000. The spatial semantic hierarchy. Artificial Intelligence, 119(1):191–233.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English verb class and alternations: a preliminary investigation.</title>
<date>1993</date>
<publisher>University of Chicago Press.</publisher>
<contexts>
<context position="4116" citStr="Levin (1993)" startWordPosition="620" endWordPosition="621"> of the Third Joint Conference on Lexical and Computational Semantics (*SEM 2014), pages 99–109, Dublin, Ireland, August 23-24 2014. fairly closely with the theoretical claims made by linguists using small introspective datasets. The path-manner classification is a case where there are data-derived distinctions that correlate nicely with theoretically inspired predictions. More often than not, however, lexical semantic distinctions are formal stipulations in a linguistic model, that often have no observable correlations to data. For example, an examination of the manner of movement class from Levin (1993) illustrates this point. The verbs below are all Levinclass manner of motion verbs: (4) MANNER OF MOTION VERBS: drive, walk, run, crawl, fly, swim, drag, slide, hop, roll Assuming the two-way distinction between path and manner predication of motion mentioned above, these verbs do, in fact, tend to pattern according to the latter class in the corpus. Given that they are all manner of motion verbs, however, any data-derived distinctions that emerge within this class will have to be made in terms of additional syntactic or semantic dimensions. While it is most likely possible to differentiate, f</context>
<context position="13799" citStr="Levin (1993)" startWordPosition="2233" endWordPosition="2234">t location for an object ((loc(x) =� D)?), and retested until it is satisfied ((loc(x) = D)?). (loc(x)=,4D)? x loc(z) = y1 e1 (loc(x)=D)? x loc(z) = yn en While beyond the scope of the present discussion, it is worth noting that the model of event structure adopted here for motion verbs fits well with most of the major semantic and syntactic phenomena associated with event classes and Aktionsarten.3 3.3 Mereotopological Distinctions in Manner Given the formal distinction between path and manner predicates as described above, let us examine how to differentiate meaning within the manner class. Levin (1993) differentiates this class in terms of argument alternation patterns, and identifies the following verb groupings: ROLL, RUN, EPONYMOUS VEHICLE, WALTZ, ACCOMPANY, and CHASE verbs. While suggestive, these distinctions are only partially useful towards actually teasing apart the semantic dimensions along which we identify the contributing factors of manner. Mani and Pustejovsky (2012) suggest a different strategy involving the identification of semantic parameters that clearly differentiate verb senses from each other within this class. One parameter exploited quite extensively within the motion</context>
<context position="15314" citStr="Levin, 1993" startWordPosition="2465" endWordPosition="2466">e novel ones, as described in (9), where a class is defined by the constraints that hold throughout the event (where EC is “externally connected”, and DC is “disconnected”). (9) For Figure (F) relative to Ground (G): a. EC(F,G), throughout motion: b. DC(F,G), throughout motion: c. EC(F,G) followed by DC(F,G), throughout motion: d. Sub-part(F’,F), EC(F’,G) followed by DC(F’,G), throughout motion: e. Containment of F in a Vehicle (V). For example, consider the semantic distinction between the verbs slide and hop or bounce. When the latter are employed in induced (directed) motion constructions (Levin, 1993; Jackendoff, 1996), they take on the meaning of manner of motion verbs. Distinguishing between a sliding and hopping motion involves inspecting the next-state content in the motion n-gram: namely, there is a continuous satisfaction of EC(F,G) throughout the motion for slide and a toggling effect (on-off) for the predicates bounce and hop, as shown in (10). -DC(x,G)? x (10) loc(z) = x e0 -DC(x,G)? x loc(z) = y2 e2 With the surface as the ground argument, these verbs are defined in terms of two transitions.4 Figure 1: Slide Motion Figure 2: Hop Motion 4Many natural language predicates require r</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English verb class and alternations: a preliminary investigation. University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S C Levinson</author>
</authors>
<title>Space in Language and Cognition: Explorations in Cognitive Diversity. Language, culture, and cognition.</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="6624" citStr="Levinson, 2003" startWordPosition="1015" endWordPosition="1016"> Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Because of their grammatical and semantic import, linguistic interest in identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, the path can be identified as the central ele</context>
</contexts>
<marker>Levinson, 2003</marker>
<rawString>S.C. Levinson. 2003. Space in Language and Cognition: Explorations in Cognitive Diversity. Language, culture, and cognition. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Inderjeet Mani</author>
<author>James Pustejovsky</author>
</authors>
<title>Interpreting Motion: Grounded Representations for Spatial Language.</title>
<date>2012</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6653" citStr="Mani and Pustejovsky, 2012" startWordPosition="1017" endWordPosition="1020">ad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Because of their grammatical and semantic import, linguistic interest in identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, the path can be identified as the central element in defining the location</context>
<context position="14184" citStr="Mani and Pustejovsky (2012)" startWordPosition="2286" endWordPosition="2289">event classes and Aktionsarten.3 3.3 Mereotopological Distinctions in Manner Given the formal distinction between path and manner predicates as described above, let us examine how to differentiate meaning within the manner class. Levin (1993) differentiates this class in terms of argument alternation patterns, and identifies the following verb groupings: ROLL, RUN, EPONYMOUS VEHICLE, WALTZ, ACCOMPANY, and CHASE verbs. While suggestive, these distinctions are only partially useful towards actually teasing apart the semantic dimensions along which we identify the contributing factors of manner. Mani and Pustejovsky (2012) suggest a different strategy involving the identification of semantic parameters that clearly differentiate verb senses from each other within this class. One parameter exploited quite extensively within the motion class involves the mereotopological contraints that inhere throughout the movement of the object (Randell et al., 1992; Asher and Vieu, 1995; Galton, 2000). Using this parameter, we are able to distinguish several of Levin’s classes of manner 3Cf. (Pustejovsky, 2013a) and (Krifka, 1992). as well as some novel ones, as described in (9), where a class is defined by the constraints th</context>
</contexts>
<marker>Mani, Pustejovsky, 2012</marker>
<rawString>Inderjeet Mani and James Pustejovsky. 2012. Interpreting Motion: Grounded Representations for Spatial Language. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>W Charles</author>
</authors>
<title>Contextual correlates of semantic similarity.</title>
<date>1991</date>
<booktitle>Language and Cognitive Processes,</booktitle>
<pages>6--1</pages>
<contexts>
<context position="9383" citStr="Miller and Charles, 1991" startWordPosition="1456" endWordPosition="1459">ded within an appropriate minimal embedding space. This must sufficiently enclose the event localization, while optionally including room enough for a frame of reference visualization of the event (the viewer’s perspective). We return to this issue later in the paper when constructing our simulation from the semantic interpretation associated with motion events. 3 Modeling Motion in Language 3.1 Theoretical Assumptions The advantage of adopting a dynamic interpretation of motion is that we can directly distinguish path predication from manner of motion predication in an operational semantics (Miller and Charles, 1991; Miller and Johnson-Laird, 1976) that maps nicely to a simulation environment. Models of processes using updating typically make reference to the notion of a state transition (van Benthem, 1991; Harel, 1984). This is done by distinguishing between formulae, φ, and programs, π. A formula is interpreted as a classical propositional expression, with assignment of a truth value in a specific model. We will interpret specific models by reference to specific states. A state is a set of propositions with assignments to variables at a specific index. Atomic programs are input/output relations ( [π] ⊆</context>
</contexts>
<marker>Miller, Charles, 1991</marker>
<rawString>G. Miller and W. Charles. 1991. Contextual correlates of semantic similarity. Language and Cognitive Processes, 6(1):1–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Philip N Johnson-Laird</author>
</authors>
<title>Language and perception.</title>
<date>1976</date>
<publisher>Belknap Press.</publisher>
<contexts>
<context position="9416" citStr="Miller and Johnson-Laird, 1976" startWordPosition="1460" endWordPosition="1463">minimal embedding space. This must sufficiently enclose the event localization, while optionally including room enough for a frame of reference visualization of the event (the viewer’s perspective). We return to this issue later in the paper when constructing our simulation from the semantic interpretation associated with motion events. 3 Modeling Motion in Language 3.1 Theoretical Assumptions The advantage of adopting a dynamic interpretation of motion is that we can directly distinguish path predication from manner of motion predication in an operational semantics (Miller and Charles, 1991; Miller and Johnson-Laird, 1976) that maps nicely to a simulation environment. Models of processes using updating typically make reference to the notion of a state transition (van Benthem, 1991; Harel, 1984). This is done by distinguishing between formulae, φ, and programs, π. A formula is interpreted as a classical propositional expression, with assignment of a truth value in a specific model. We will interpret specific models by reference to specific states. A state is a set of propositions with assignments to variables at a specific index. Atomic programs are input/output relations ( [π] ⊆ S × S), and compound programs ar</context>
</contexts>
<marker>Miller, Johnson-Laird, 1976</marker>
<rawString>George A Miller and Philip N Johnson-Laird. 1976. Language and perception. Belknap Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Srinivas Narayanan</author>
</authors>
<title>Reasoning about actions in narrative understanding.</title>
<date>1999</date>
<booktitle>IJCAI,</booktitle>
<pages>99--350</pages>
<contexts>
<context position="19323" citStr="Narayanan, 1999" startWordPosition="3124" endWordPosition="3125">heory of mind and mental attribution, differing from the theory-driven models proposed by Churchland and others (Churchland, 1991). From the cognitive linguistics tradition, simulation semantics has come to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced in the previous section is inspired by work in minimal model generation (Blackburn and Bos, 2008; Konrad, 2004). Type satisfaction in the compositional process mirrors the theorem proving component, while construction of the specific model helps us distinguish what is inherent in the different manner of motion events. This latter aspect is the “positive handle”, (Blackburn and Bos, 2008) which demonstrates the informativeness of a distinction in our simulation. Simulation softwar</context>
</contexts>
<marker>Narayanan, 1999</marker>
<rawString>Srinivas Narayanan. 1999. Reasoning about actions in narrative understanding. IJCAI, 99:350–357.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralf Naumann</author>
</authors>
<title>Aspects of changes: a dynamic event semantics.</title>
<date>2001</date>
<journal>Journal of semantics,</journal>
<pages>18--27</pages>
<contexts>
<context position="12518" citStr="Naumann (2001)" startWordPosition="2011" endWordPosition="2012"> the test is not just non-coreference, but makes reference to values on a scale, C, and ensures that it continues in an order-preserving change through the iterations. When this test references the values on a scale, C, we call this a directed ν-transition (~ν), e.g., x -,&lt; y, x &gt; ,--y: (6) ν~ =df loc(z) = y1 e1 −→ . . . ν� loc(z) = yn e,,, This now provides us with our dynamic interpretation of directed manner of motion verbs, such as slide, swim, roll, where we have an iteration of assignments of locations, undistinguished except 2Cf. Groenendijk and Stokhof (1990) for dynamic updating, and Naumann (2001) for a related analysis. e1, α, {¬φ}e2) ∈→, we −→ α use, φ e1 i −→α will use, φ e1 ¬φ i+1 � C? ν ei −→ ei+1. (7) loc(z) = x e0 −→ ν� 101 that the values are order-preserving according to a scalar constraint. This is quite different from the dynamic interpretation of path predicates. Following (Galton, 2004; Pustejovsky and Moszkowicz, 2011), path predicates such as arrive and leave make reference to a “distinguished location”, not an arbitrary location. For example, the ball enters the room is satisified when the distinguished location, D, (the room) is successfully tested as the location for </context>
</contexts>
<marker>Naumann, 2001</marker>
<rawString>Ralf Naumann. 2001. Aspects of changes: a dynamic event semantics. Journal of semantics, 18:27–81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jessica Moszkowicz</author>
</authors>
<title>The qualitative spatial dynamics of motion.</title>
<date>2011</date>
<journal>The Journal of Spatial Cognition and Computation.</journal>
<contexts>
<context position="7360" citStr="Pustejovsky and Moszkowicz (2011)" startWordPosition="1129" endWordPosition="1133"> identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, the path can be identified as the central element in defining the location of the event (Talmy, 2000). Related to this idea, both Zwarts (2005) and Pustejovsky and Moszkowicz (2011) develop mechanisms for dynamically creating the path traversed by a mover in a manner of motion predicate, such as run or drive. Starting with this approach, the localization of a motion event, therefore, is at least minimally associated with the path created by virtue of the activity. In addition to capturing the spatial trace of the object in motion, several researchers have pointed out that identifying the shape of the path during motion is also critical for fully interpreting the semantics of movement. Eschenbach et al. (1999) discusses the orientation associated with the trajectory, some</context>
<context position="11355" citStr="Pustejovsky and Moszkowicz, 2011" startWordPosition="1798" endWordPosition="1802">, α, e2) ∈→, we will also use e1 −→ e2. If reference to the state α content (rather than state name) is required for interpretation purposes (van Benthem et al., 1994), then as shorthand for ({φ} ¬φ .Finally, when referring e2 to temporally-indexed states in the model, where ei@i indicates the state ei interpreted at time i, as shorthand for ({φ}e1@i, α, {¬φ}e2@i+1) ∈→, we , as described in Pustee2 jovsky(2013). 3.2 Distinguishing Path and Manner Motion We will assume that change of location of an object can be viewed as a special instance of a firstorder program, which we will refer to as ν (Pustejovsky and Moszkowicz, 2011).2 (5) x := y (ν-transition, where loc(z) is value being updated) “x assumes the value given to y in the next state.” hM, (i, i + 1), (u, u[x/u(y)])i |= x := y iff hM, i, ui |= loc(z) = x ∧ hM, i + 1, u[x/u(y)]i |= loc(z) = y Given a simple transition, a process can be viewed as simply an iteration of ν (Fernando, 2009). However, as (Pustejovsky, 2013a) points out, since most manner motion verbs in language are actually directed processes, simple decompositions into change-of-location are inadequate. That is, they are guarded transitions where the test is not just non-coreference, but makes re</context>
<context position="12860" citStr="Pustejovsky and Moszkowicz, 2011" startWordPosition="2074" endWordPosition="2077">ν� loc(z) = yn e,,, This now provides us with our dynamic interpretation of directed manner of motion verbs, such as slide, swim, roll, where we have an iteration of assignments of locations, undistinguished except 2Cf. Groenendijk and Stokhof (1990) for dynamic updating, and Naumann (2001) for a related analysis. e1, α, {¬φ}e2) ∈→, we −→ α use, φ e1 i −→α will use, φ e1 ¬φ i+1 � C? ν ei −→ ei+1. (7) loc(z) = x e0 −→ ν� 101 that the values are order-preserving according to a scalar constraint. This is quite different from the dynamic interpretation of path predicates. Following (Galton, 2004; Pustejovsky and Moszkowicz, 2011), path predicates such as arrive and leave make reference to a “distinguished location”, not an arbitrary location. For example, the ball enters the room is satisified when the distinguished location, D, (the room) is successfully tested as the location for the moving object. That is, the location is tested against the current location for an object ((loc(x) =� D)?), and retested until it is satisfied ((loc(x) = D)?). (loc(x)=,4D)? x loc(z) = y1 e1 (loc(x)=D)? x loc(z) = yn en While beyond the scope of the present discussion, it is worth noting that the model of event structure adopted here fo</context>
<context position="20394" citStr="Pustejovsky and Moszkowicz, 2011" startWordPosition="3302" endWordPosition="3305">is latter aspect is the “positive handle”, (Blackburn and Bos, 2008) which demonstrates the informativeness of a distinction in our simulation. Simulation software must be able to map a predicate to a known behavior, its arguments to objects in the scene, and then prompt those objects to execute the behavior. A simple input sentence needs 5Obviously, true synonyms in the lexicon would not be distinguishable in a model. s1 A c b a B s2 A a c b B s3 b e A c a 103 to be tagged and parsed and transformed into predicate/argument representation, and from there into a dynamic event structure, as in (Pustejovsky and Moszkowicz, 2011). The event structure is interpreted as the transformation executed over the object or objects in each frame, and then rendered. SBJ OBJ Ball1/NNP crossed/VBD Floor/NNP SBJ Ball1/NNP rolled/VBD Table 1: Dependency parses for Ball1 crossed Floor (top) and Ball1 rolled (bottom). We currently use only proper names to refer to objects in the scene, to simplify model generation, hence Ball1 and Floor. This facilitates easy object identification in this prototype development stage. Given a tagged and dependency parsed sentence, we can the transform the parse into a predicate formula, using the root </context>
</contexts>
<marker>Pustejovsky, Moszkowicz, 2011</marker>
<rawString>James Pustejovsky and Jessica Moszkowicz. 2011. The qualitative spatial dynamics of motion. The Journal of Spatial Cognition and Computation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Anna Rumshisky</author>
</authors>
<title>Deep semantic annotation with shallow methods.</title>
<date>2014</date>
<tech>LREC Tutorial,</tech>
<contexts>
<context position="33023" citStr="Pustejovsky and Rumshisky, 2014" startWordPosition="5308" endWordPosition="5311">mal pair of behaviors, we can evaluate the quantitative and qualitative differences between the values that do change. As simulations require values to be assigned to variables that can be left unspecified in an ordinary modeling process, simulations expose presuppositions about the semantics of motion verbs and of compositions that would not be necessary in a model alone. In order to evaluate the appropriateness of a given simulation, we are currently experimenting with a strategy often used in classification and annotation tasks, namely pairwise similarity judgments (Rumshisky et al., 2012; Pustejovsky and Rumshisky, 2014). This involves presenting a user with a simple discrimination task that has a reduced cognitive load, comparing the similarity of the example to the target instances. In the present context, a subject is shown a specific simulation resulting from the translation from textual input, through DITL, to the visualization. A set of activity or event descriptions is given, and the subject is then asked to select which best describes the simulation shown; e.g., “Is this a sliding?”, “Is this a rolling?”. The results of this experiment are presently being evaluated. The system is currently in the prot</context>
</contexts>
<marker>Pustejovsky, Rumshisky, 2014</marker>
<rawString>James Pustejovsky and Anna Rumshisky. 2014. Deep semantic annotation with shallow methods. LREC Tutorial, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Anna Rumshisky</author>
<author>Olga Batiukova</author>
<author>Jessica Moszkowicz</author>
</authors>
<title>Annotation of compositional operations with glml.</title>
<date>2014</date>
<booktitle>Computing Meaning,</booktitle>
<pages>217--234</pages>
<editor>In Harry Bunt, editor,</editor>
<publisher>Springer Netherlands.</publisher>
<contexts>
<context position="5938" citStr="Pustejovsky et al., 2014" startWordPosition="909" endWordPosition="912">terance, while model building provides a “positive handle” on both. For our concerns, simulation construction provides a positive handle on whether two manner of motion processes are distinguished in the model. Further, the simulation must specify how they are distinguished, the analogue to informativeness. In this paper, we argue that traditional lexical modeling can benefit greatly from examining how semantic interpretations are contextually and conceptually grounded. We explore a dynamic interpretation of the lexical semantic model developed in Generative Lexicon Theory (Pustejovsky, 1995; Pustejovsky et al., 2014). Specifically, we are interested in using model building (Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics </context>
</contexts>
<marker>Pustejovsky, Rumshisky, Batiukova, Moszkowicz, 2014</marker>
<rawString>James Pustejovsky, Anna Rumshisky, Olga Batiukova, and Jessica Moszkowicz. 2014. Annotation of compositional operations with glml. In Harry Bunt, editor, Computing Meaning, pages 217–234. Springer Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>The Generative Lexicon.</title>
<date>1995</date>
<publisher>Bradford Book. Mit Press.</publisher>
<contexts>
<context position="5911" citStr="Pustejovsky, 1995" startWordPosition="907" endWordPosition="908">ativeness for an utterance, while model building provides a “positive handle” on both. For our concerns, simulation construction provides a positive handle on whether two manner of motion processes are distinguished in the model. Further, the simulation must specify how they are distinguished, the analogue to informativeness. In this paper, we argue that traditional lexical modeling can benefit greatly from examining how semantic interpretations are contextually and conceptually grounded. We explore a dynamic interpretation of the lexical semantic model developed in Generative Lexicon Theory (Pustejovsky, 1995; Pustejovsky et al., 2014). Specifically, we are interested in using model building (Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most resea</context>
</contexts>
<marker>Pustejovsky, 1995</marker>
<rawString>J. Pustejovsky. 1995. The Generative Lexicon. Bradford Book. Mit Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>Dynamic event structure and habitat theory.</title>
<date>2013</date>
<booktitle>In Proceedings of the 6th International Conference on Generative Approaches to the Lexicon (GL2013),</booktitle>
<pages>1--10</pages>
<publisher>ACL.</publisher>
<contexts>
<context position="8495" citStr="Pustejovsky (2013" startWordPosition="1317" endWordPosition="1319">nbach et al. (1999) discusses the orientation associated with the trajectory, something they refer to as oriented curves. Motivated more by linguistic considerations, Zwarts (2006) introduces the notion of an event shape, which is the trajectory associated with an event in space represented by a path. He defines a shape function, which is a partial function assigning unique paths to those events involving motion or extension in physical space. This work suggests that the localization of an event 100 makes reference to orientational as well as configurational factors, a view that is pursued in Pustejovsky (2013b). This forces us to look at the various spatio-temporal regions associated with the event participants, and the interactions between them. These issues are relevant to our present concerns, because in order to construct a simulation, a motion event must be embedded within an appropriate minimal embedding space. This must sufficiently enclose the event localization, while optionally including room enough for a frame of reference visualization of the event (the viewer’s perspective). We return to this issue later in the paper when constructing our simulation from the semantic interpretation as</context>
<context position="11708" citStr="Pustejovsky, 2013" startWordPosition="1873" endWordPosition="1874">∈→, we , as described in Pustee2 jovsky(2013). 3.2 Distinguishing Path and Manner Motion We will assume that change of location of an object can be viewed as a special instance of a firstorder program, which we will refer to as ν (Pustejovsky and Moszkowicz, 2011).2 (5) x := y (ν-transition, where loc(z) is value being updated) “x assumes the value given to y in the next state.” hM, (i, i + 1), (u, u[x/u(y)])i |= x := y iff hM, i, ui |= loc(z) = x ∧ hM, i + 1, u[x/u(y)]i |= loc(z) = y Given a simple transition, a process can be viewed as simply an iteration of ν (Fernando, 2009). However, as (Pustejovsky, 2013a) points out, since most manner motion verbs in language are actually directed processes, simple decompositions into change-of-location are inadequate. That is, they are guarded transitions where the test is not just non-coreference, but makes reference to values on a scale, C, and ensures that it continues in an order-preserving change through the iterations. When this test references the values on a scale, C, we call this a directed ν-transition (~ν), e.g., x -,&lt; y, x &gt; ,--y: (6) ν~ =df loc(z) = y1 e1 −→ . . . ν� loc(z) = yn e,,, This now provides us with our dynamic interpretation of direc</context>
<context position="14666" citStr="Pustejovsky, 2013" startWordPosition="2362" endWordPosition="2363"> actually teasing apart the semantic dimensions along which we identify the contributing factors of manner. Mani and Pustejovsky (2012) suggest a different strategy involving the identification of semantic parameters that clearly differentiate verb senses from each other within this class. One parameter exploited quite extensively within the motion class involves the mereotopological contraints that inhere throughout the movement of the object (Randell et al., 1992; Asher and Vieu, 1995; Galton, 2000). Using this parameter, we are able to distinguish several of Levin’s classes of manner 3Cf. (Pustejovsky, 2013a) and (Krifka, 1992). as well as some novel ones, as described in (9), where a class is defined by the constraints that hold throughout the event (where EC is “externally connected”, and DC is “disconnected”). (9) For Figure (F) relative to Ground (G): a. EC(F,G), throughout motion: b. DC(F,G), throughout motion: c. EC(F,G) followed by DC(F,G), throughout motion: d. Sub-part(F’,F), EC(F’,G) followed by DC(F’,G), throughout motion: e. Containment of F in a Vehicle (V). For example, consider the semantic distinction between the verbs slide and hop or bounce. When the latter are employed in indu</context>
</contexts>
<marker>Pustejovsky, 2013</marker>
<rawString>James Pustejovsky. 2013a. Dynamic event structure and habitat theory. In Proceedings of the 6th International Conference on Generative Approaches to the Lexicon (GL2013), pages 1–10. ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
</authors>
<title>Where things happen: On the semantics of event localization.</title>
<date>2013</date>
<booktitle>In Proceedings of ISA-9: International Workshop on Semantic Annotation.</booktitle>
<contexts>
<context position="8495" citStr="Pustejovsky (2013" startWordPosition="1317" endWordPosition="1319">nbach et al. (1999) discusses the orientation associated with the trajectory, something they refer to as oriented curves. Motivated more by linguistic considerations, Zwarts (2006) introduces the notion of an event shape, which is the trajectory associated with an event in space represented by a path. He defines a shape function, which is a partial function assigning unique paths to those events involving motion or extension in physical space. This work suggests that the localization of an event 100 makes reference to orientational as well as configurational factors, a view that is pursued in Pustejovsky (2013b). This forces us to look at the various spatio-temporal regions associated with the event participants, and the interactions between them. These issues are relevant to our present concerns, because in order to construct a simulation, a motion event must be embedded within an appropriate minimal embedding space. This must sufficiently enclose the event localization, while optionally including room enough for a frame of reference visualization of the event (the viewer’s perspective). We return to this issue later in the paper when constructing our simulation from the semantic interpretation as</context>
<context position="11708" citStr="Pustejovsky, 2013" startWordPosition="1873" endWordPosition="1874">∈→, we , as described in Pustee2 jovsky(2013). 3.2 Distinguishing Path and Manner Motion We will assume that change of location of an object can be viewed as a special instance of a firstorder program, which we will refer to as ν (Pustejovsky and Moszkowicz, 2011).2 (5) x := y (ν-transition, where loc(z) is value being updated) “x assumes the value given to y in the next state.” hM, (i, i + 1), (u, u[x/u(y)])i |= x := y iff hM, i, ui |= loc(z) = x ∧ hM, i + 1, u[x/u(y)]i |= loc(z) = y Given a simple transition, a process can be viewed as simply an iteration of ν (Fernando, 2009). However, as (Pustejovsky, 2013a) points out, since most manner motion verbs in language are actually directed processes, simple decompositions into change-of-location are inadequate. That is, they are guarded transitions where the test is not just non-coreference, but makes reference to values on a scale, C, and ensures that it continues in an order-preserving change through the iterations. When this test references the values on a scale, C, we call this a directed ν-transition (~ν), e.g., x -,&lt; y, x &gt; ,--y: (6) ν~ =df loc(z) = y1 e1 −→ . . . ν� loc(z) = yn e,,, This now provides us with our dynamic interpretation of direc</context>
<context position="14666" citStr="Pustejovsky, 2013" startWordPosition="2362" endWordPosition="2363"> actually teasing apart the semantic dimensions along which we identify the contributing factors of manner. Mani and Pustejovsky (2012) suggest a different strategy involving the identification of semantic parameters that clearly differentiate verb senses from each other within this class. One parameter exploited quite extensively within the motion class involves the mereotopological contraints that inhere throughout the movement of the object (Randell et al., 1992; Asher and Vieu, 1995; Galton, 2000). Using this parameter, we are able to distinguish several of Levin’s classes of manner 3Cf. (Pustejovsky, 2013a) and (Krifka, 1992). as well as some novel ones, as described in (9), where a class is defined by the constraints that hold throughout the event (where EC is “externally connected”, and DC is “disconnected”). (9) For Figure (F) relative to Ground (G): a. EC(F,G), throughout motion: b. DC(F,G), throughout motion: c. EC(F,G) followed by DC(F,G), throughout motion: d. Sub-part(F’,F), EC(F’,G) followed by DC(F’,G), throughout motion: e. Containment of F in a Vehicle (V). For example, consider the semantic distinction between the verbs slide and hop or bounce. When the latter are employed in indu</context>
</contexts>
<marker>Pustejovsky, 2013</marker>
<rawString>James Pustejovsky. 2013b. Where things happen: On the semantics of event localization. In Proceedings of ISA-9: International Workshop on Semantic Annotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Randell</author>
<author>Zhan Cui</author>
<author>Anthony Cohn</author>
</authors>
<title>A spatial logic based on regions and connections.</title>
<date>1992</date>
<booktitle>Proceedings of the 3rd Internation Conference on Knowledge Representation and REasoning,</booktitle>
<pages>165--176</pages>
<editor>In Morgan Kaufmann, editor,</editor>
<location>San Mateo.</location>
<contexts>
<context position="14518" citStr="Randell et al., 1992" startWordPosition="2335" endWordPosition="2339">verb groupings: ROLL, RUN, EPONYMOUS VEHICLE, WALTZ, ACCOMPANY, and CHASE verbs. While suggestive, these distinctions are only partially useful towards actually teasing apart the semantic dimensions along which we identify the contributing factors of manner. Mani and Pustejovsky (2012) suggest a different strategy involving the identification of semantic parameters that clearly differentiate verb senses from each other within this class. One parameter exploited quite extensively within the motion class involves the mereotopological contraints that inhere throughout the movement of the object (Randell et al., 1992; Asher and Vieu, 1995; Galton, 2000). Using this parameter, we are able to distinguish several of Levin’s classes of manner 3Cf. (Pustejovsky, 2013a) and (Krifka, 1992). as well as some novel ones, as described in (9), where a class is defined by the constraints that hold throughout the event (where EC is “externally connected”, and DC is “disconnected”). (9) For Figure (F) relative to Ground (G): a. EC(F,G), throughout motion: b. DC(F,G), throughout motion: c. EC(F,G) followed by DC(F,G), throughout motion: d. Sub-part(F’,F), EC(F’,G) followed by DC(F’,G), throughout motion: e. Containment o</context>
</contexts>
<marker>Randell, Cui, Cohn, 1992</marker>
<rawString>David Randell, Zhan Cui, and Anthony Cohn. 1992. A spatial logic based on regions and connections. In Morgan Kaufmann, editor, Proceedings of the 3rd Internation Conference on Knowledge Representation and REasoning, pages 165–176, San Mateo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan Rothstein</author>
</authors>
<title>Two puzzles for a theory of lexical aspect: Semelfactives and degree achievements. Event structures in linguistic form and interpretation,</title>
<date>2008</date>
<pages>5--175</pages>
<contexts>
<context position="16097" citStr="Rothstein, 2008" startWordPosition="2593" endWordPosition="2594"> in the motion n-gram: namely, there is a continuous satisfaction of EC(F,G) throughout the motion for slide and a toggling effect (on-off) for the predicates bounce and hop, as shown in (10). -DC(x,G)? x (10) loc(z) = x e0 -DC(x,G)? x loc(z) = y2 e2 With the surface as the ground argument, these verbs are defined in terms of two transitions.4 Figure 1: Slide Motion Figure 2: Hop Motion 4Many natural language predicates require reference to at least three states. These include the semelfactives mentioned above, as well as blink and iterative uses of knock and clap (Vendler, 1967; Dowty, 1979; Rothstein, 2008). s1 s2 s3 A A A B l1 l2 l3 s1 s2 s3 A A B l1 l2 l3 A (loc(x)=,4D)? x (8) loc(z) = x e0 −→ v −→ . . . v DC(x,G)? x loc(z) = y1 e1 −→ v −→v 102 Distinguishing between a sliding motion and a rolling motion is also fairly straightforward. We have the entailments that result from each kind of motion, given a set of initial conditions, as in the following short sentence describing the motion of a ball relative to a floor (the domain for our event simulations). • The ball slid.: At the termination of the action, object ball has moved relative to a surface in a manner that is [+translate]. That is, t</context>
</contexts>
<marker>Rothstein, 2008</marker>
<rawString>Susan Rothstein. 2008. Two puzzles for a theory of lexical aspect: Semelfactives and degree achievements. Event structures in linguistic form and interpretation, 5:175.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna Rumshisky</author>
<author>Nick Botchan</author>
<author>Sophie Kushkuley</author>
<author>James Pustejovsky</author>
</authors>
<title>Word sense inventories by non-experts.</title>
<date>2012</date>
<booktitle>In LREC,</booktitle>
<pages>4055--4059</pages>
<contexts>
<context position="32989" citStr="Rumshisky et al., 2012" startWordPosition="5304" endWordPosition="5307">onsistent between a minimal pair of behaviors, we can evaluate the quantitative and qualitative differences between the values that do change. As simulations require values to be assigned to variables that can be left unspecified in an ordinary modeling process, simulations expose presuppositions about the semantics of motion verbs and of compositions that would not be necessary in a model alone. In order to evaluate the appropriateness of a given simulation, we are currently experimenting with a strategy often used in classification and annotation tasks, namely pairwise similarity judgments (Rumshisky et al., 2012; Pustejovsky and Rumshisky, 2014). This involves presenting a user with a simple discrimination task that has a reduced cognitive load, comparing the similarity of the example to the target instances. In the present context, a subject is shown a specific simulation resulting from the translation from textual input, through DITL, to the visualization. A set of activity or event descriptions is given, and the subject is then asked to select which best describes the simulation shown; e.g., “Is this a sliding?”, “Is this a rolling?”. The results of this experiment are presently being evaluated. T</context>
</contexts>
<marker>Rumshisky, Botchan, Kushkuley, Pustejovsky, 2012</marker>
<rawString>Anna Rumshisky, Nick Botchan, Sophie Kushkuley, and James Pustejovsky. 2012. Word sense inventories by non-experts. In LREC, pages 4055–4059.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Mark Siskind</author>
</authors>
<title>Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic. arXiv preprint arXiv:1106.0256.</title>
<date>2011</date>
<contexts>
<context position="6127" citStr="Siskind, 2011" startWordPosition="939" endWordPosition="940">the model. Further, the simulation must specify how they are distinguished, the analogue to informativeness. In this paper, we argue that traditional lexical modeling can benefit greatly from examining how semantic interpretations are contextually and conceptually grounded. We explore a dynamic interpretation of the lexical semantic model developed in Generative Lexicon Theory (Pustejovsky, 1995; Pustejovsky et al., 2014). Specifically, we are interested in using model building (Blackburn and Bos, 2008; Konrad, 2004; Gardent and Konrad, 2000) and simulation generation (Coyne and Sproat, 2001; Siskind, 2011) to reveal the conceptual presuppositions inherent in natural language expressions. In this paper, we focus our attention on motion verbs, in order to distinguish between manner and path motion verbs, as well as to model mereotopological distinctions within the manner class. 2 Situating Motion in Space and Time The interpretation of motion in language has been one of the most researched areas in linguistics and Artificial Intelligence (Kuipers, 2000; Freksa, 1992; Galton, 2000; Levinson, 2003; Mani and Pustejovsky, 2012). Because of their grammatical and semantic import, linguistic interest in</context>
<context position="19338" citStr="Siskind, 2011" startWordPosition="3126" endWordPosition="3127"> mental attribution, differing from the theory-driven models proposed by Churchland and others (Churchland, 1991). From the cognitive linguistics tradition, simulation semantics has come to denote the mental instantiation of an interpretation of any linguistic utterance (Feldman, 2006; Bergen et al., 2007; Bergen, 2012). While these communities do not seem to reference each other, it is clear from our perspective, that they are both pursuing similar programs, where distinct linguistic utterances correspond to generated models that have differentiated structures and behaviors (Narayanan, 1999; Siskind, 2011; Goldman, 2006). 4 Simulations as Minimal Models The approach to simulation construction introduced in the previous section is inspired by work in minimal model generation (Blackburn and Bos, 2008; Konrad, 2004). Type satisfaction in the compositional process mirrors the theorem proving component, while construction of the specific model helps us distinguish what is inherent in the different manner of motion events. This latter aspect is the “positive handle”, (Blackburn and Bos, 2008) which demonstrates the informativeness of a distinction in our simulation. Simulation software must be able </context>
</contexts>
<marker>Siskind, 2011</marker>
<rawString>Jeffrey Mark Siskind. 2011. Grounding the lexical semantics of verbs in visual perception using force dynamics and event logic. arXiv preprint arXiv:1106.0256.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>Plans, affordances, and combinatory grammar.</title>
<date>2002</date>
<journal>Linguistics and Philosophy,</journal>
<pages>25--5</pages>
<contexts>
<context position="10686" citStr="Steedman (2002)" startWordPosition="1681" endWordPosition="1682">ic logic (Harel et al., 2000). For the present discussion, we represent the dynamics of actions in terms of Labeled Transition Systems (LTSs) (van Benthem, 1991).1 An LTS consists of a triple, hS, Act, →i, where: S is the set of states; Act is a set of actions; and → is a total transition relation: →⊆ S×Act×S. An action, α ∈ Act, provides the labeling on an arrow, making it explicit what brings about a state-to-state 1This is consistent with the approach developed in (Fernando, 2009; Fernando, 2013). This approach to a dynamic interpretation of change in language semantics is also inspired by Steedman (2002). transition. As a shorthand for (e1, α, e2) ∈→, we will also use e1 −→ e2. If reference to the state α content (rather than state name) is required for interpretation purposes (van Benthem et al., 1994), then as shorthand for ({φ} ¬φ .Finally, when referring e2 to temporally-indexed states in the model, where ei@i indicates the state ei interpreted at time i, as shorthand for ({φ}e1@i, α, {¬φ}e2@i+1) ∈→, we , as described in Pustee2 jovsky(2013). 3.2 Distinguishing Path and Manner Motion We will assume that change of location of an object can be viewed as a special instance of a firstorder pr</context>
</contexts>
<marker>Steedman, 2002</marker>
<rawString>Mark Steedman. 2002. Plans, affordances, and combinatory grammar. Linguistics and Philosophy, 25(5-6):723–753.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Talmy</author>
</authors>
<title>Lexicalization patterns: semantic structure in lexical forms. In</title>
<date>1985</date>
<booktitle>Language typology and semantic description Volume 3:,</booktitle>
<pages>36--149</pages>
<editor>T. Shopen, editor,</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="2798" citStr="Talmy, 1985" startWordPosition="407" endWordPosition="408">rting point in lexical semantic analysis, a standard methodology in both theoretical and computational linguistics is to identify features in a corpus that differentiate the data in meaningful ways; meaningful in terms of prior theoretical assumptions or in terms of observably differentiated behaviors. Combining these strategies we might, for instance, take a theoretical constraint that we hope to justify through behavioral distinctions in the data. An example of this is the theoretical claim that motion verbs can be meaningfully divided into two classes: manner- and path-oriented predicates (Talmy, 1985; Jackendoff, 1983; Talmy, 2000). These constructions can be viewed as encoding two aspects of meaning: how the movement is happening and where it is happening. The former strategy is illustrated in (2a) and the latter in (2b) (where m indicates a manner verb, and p indicates a path verb). (2) a. The ball rolledm. b. The ball crossedp the room. With both of the verb types, adjunction can make reference to the missing aspect of motion, by introducing a path (as in (3a)) or the manner of movement (in (3b)). (3) a. The ball rolledm across the room. b. The ball crossedp the room rolling. Differenc</context>
</contexts>
<marker>Talmy, 1985</marker>
<rawString>Leonard Talmy. 1985. Lexicalization patterns: semantic structure in lexical forms. In T. Shopen, editor, Language typology and semantic description Volume 3:, pages 36–149. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonard Talmy</author>
</authors>
<title>Towards a cognitive semantics.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="2830" citStr="Talmy, 2000" startWordPosition="411" endWordPosition="412"> analysis, a standard methodology in both theoretical and computational linguistics is to identify features in a corpus that differentiate the data in meaningful ways; meaningful in terms of prior theoretical assumptions or in terms of observably differentiated behaviors. Combining these strategies we might, for instance, take a theoretical constraint that we hope to justify through behavioral distinctions in the data. An example of this is the theoretical claim that motion verbs can be meaningfully divided into two classes: manner- and path-oriented predicates (Talmy, 1985; Jackendoff, 1983; Talmy, 2000). These constructions can be viewed as encoding two aspects of meaning: how the movement is happening and where it is happening. The former strategy is illustrated in (2a) and the latter in (2b) (where m indicates a manner verb, and p indicates a path verb). (2) a. The ball rolledm. b. The ball crossedp the room. With both of the verb types, adjunction can make reference to the missing aspect of motion, by introducing a path (as in (3a)) or the manner of movement (in (3b)). (3) a. The ball rolledm across the room. b. The ball crossedp the room rolling. Differences in syntactic distribution and</context>
<context position="7280" citStr="Talmy, 2000" startWordPosition="1119" endWordPosition="1120">eir grammatical and semantic import, linguistic interest in identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, the path can be identified as the central element in defining the location of the event (Talmy, 2000). Related to this idea, both Zwarts (2005) and Pustejovsky and Moszkowicz (2011) develop mechanisms for dynamically creating the path traversed by a mover in a manner of motion predicate, such as run or drive. Starting with this approach, the localization of a motion event, therefore, is at least minimally associated with the path created by virtue of the activity. In addition to capturing the spatial trace of the object in motion, several researchers have pointed out that identifying the shape of the path during motion is also critical for fully interpreting the semantics of movement. Eschenb</context>
</contexts>
<marker>Talmy, 2000</marker>
<rawString>Leonard Talmy. 2000. Towards a cognitive semantics. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan van Benthem</author>
<author>Jan van Eijck</author>
<author>Vera Stebletsova</author>
</authors>
<title>Modal logic, transition systems and processes.</title>
<date>1994</date>
<journal>Journal of Logic and Computation,</journal>
<volume>4</volume>
<issue>5</issue>
<marker>van Benthem, van Eijck, Stebletsova, 1994</marker>
<rawString>Johan van Benthem, Jan van Eijck, and Vera Stebletsova. 1994. Modal logic, transition systems and processes. Journal of Logic and Computation, 4(5):811–855.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Franciscus Abraham Karel van Benthem</author>
</authors>
<title>Logic and the flow of information.</title>
<date>1991</date>
<marker>van Benthem, 1991</marker>
<rawString>Johannes Franciscus Abraham Karel van Benthem. 1991. Logic and the flow of information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Vendler</author>
</authors>
<title>Linguistics in philosophy.</title>
<date>1967</date>
<publisher>Cornell University Press</publisher>
<location>Ithaca.</location>
<contexts>
<context position="16066" citStr="Vendler, 1967" startWordPosition="2589" endWordPosition="2590">cting the next-state content in the motion n-gram: namely, there is a continuous satisfaction of EC(F,G) throughout the motion for slide and a toggling effect (on-off) for the predicates bounce and hop, as shown in (10). -DC(x,G)? x (10) loc(z) = x e0 -DC(x,G)? x loc(z) = y2 e2 With the surface as the ground argument, these verbs are defined in terms of two transitions.4 Figure 1: Slide Motion Figure 2: Hop Motion 4Many natural language predicates require reference to at least three states. These include the semelfactives mentioned above, as well as blink and iterative uses of knock and clap (Vendler, 1967; Dowty, 1979; Rothstein, 2008). s1 s2 s3 A A A B l1 l2 l3 s1 s2 s3 A A B l1 l2 l3 A (loc(x)=,4D)? x (8) loc(z) = x e0 −→ v −→ . . . v DC(x,G)? x loc(z) = y1 e1 −→ v −→v 102 Distinguishing between a sliding motion and a rolling motion is also fairly straightforward. We have the entailments that result from each kind of motion, given a set of initial conditions, as in the following short sentence describing the motion of a ball relative to a floor (the domain for our event simulations). • The ball slid.: At the termination of the action, object ball has moved relative to a surface in a manner t</context>
</contexts>
<marker>Vendler, 1967</marker>
<rawString>Z. Vendler. 1967. Linguistics in philosophy. Cornell University Press Ithaca.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zwarts</author>
</authors>
<title>Prepositional aspect and the algebra of paths.</title>
<date>2005</date>
<journal>Linguistics and Philosophy,</journal>
<volume>28</volume>
<issue>6</issue>
<pages>779</pages>
<contexts>
<context position="7322" citStr="Zwarts (2005)" startWordPosition="1126" endWordPosition="1127">uistic interest in identifying where events happen has focused largely on motion verbs and the role played by paths. Jackendoff (1983), for example, elaborates a semantics for motion verbs incorporating explicit reference to the path traversed by the mover, from source to destination (goal) locations. Talmy (1983) develops a similar conceptual template, where the path followed by the figure is integral to the conceptualization of the motion against a ground. Hence, the path can be identified as the central element in defining the location of the event (Talmy, 2000). Related to this idea, both Zwarts (2005) and Pustejovsky and Moszkowicz (2011) develop mechanisms for dynamically creating the path traversed by a mover in a manner of motion predicate, such as run or drive. Starting with this approach, the localization of a motion event, therefore, is at least minimally associated with the path created by virtue of the activity. In addition to capturing the spatial trace of the object in motion, several researchers have pointed out that identifying the shape of the path during motion is also critical for fully interpreting the semantics of movement. Eschenbach et al. (1999) discusses the orientatio</context>
</contexts>
<marker>Zwarts, 2005</marker>
<rawString>J. Zwarts. 2005. Prepositional aspect and the algebra of paths. Linguistics and Philosophy, 28(6):739– 779.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Zwarts</author>
</authors>
<title>Event shape: Paths in the semantics of verbs.</title>
<date>2006</date>
<contexts>
<context position="8058" citStr="Zwarts (2006)" startWordPosition="1243" endWordPosition="1244">r of motion predicate, such as run or drive. Starting with this approach, the localization of a motion event, therefore, is at least minimally associated with the path created by virtue of the activity. In addition to capturing the spatial trace of the object in motion, several researchers have pointed out that identifying the shape of the path during motion is also critical for fully interpreting the semantics of movement. Eschenbach et al. (1999) discusses the orientation associated with the trajectory, something they refer to as oriented curves. Motivated more by linguistic considerations, Zwarts (2006) introduces the notion of an event shape, which is the trajectory associated with an event in space represented by a path. He defines a shape function, which is a partial function assigning unique paths to those events involving motion or extension in physical space. This work suggests that the localization of an event 100 makes reference to orientational as well as configurational factors, a view that is pursued in Pustejovsky (2013b). This forces us to look at the various spatio-temporal regions associated with the event participants, and the interactions between them. These issues are relev</context>
</contexts>
<marker>Zwarts, 2006</marker>
<rawString>J. Zwarts. 2006. Event shape: Paths in the semantics of verbs.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>