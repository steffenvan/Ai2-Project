<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000191">
<title confidence="0.972408">
NAIST.Japan: Temporal Relation Identification Using Dependency Parsed
Tree
</title>
<author confidence="0.998077">
Yuchang Cheng, Masayuki Asahara and Yuji Matsumoto
</author>
<affiliation confidence="0.9986705">
Graduate School of Informatino Science,
Nara Institute of Science and Technology
</affiliation>
<address confidence="0.570742">
8916-5 Takayama, Ikoma, Nara, 630-0192, Japan
</address>
<email confidence="0.998635">
{yuchan-c, masayu-a, matsu}@is.naist.jp
</email>
<sectionHeader confidence="0.995649" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999906083333333">
In this paper, we attempt to use a sequence
labeling model with features from depen-
dency parsed tree for temporal relation iden-
tification. In the sequence labeling model,
the relations of contextual pairs can be used
as features for relation identification of the
current pair. Head-modifier relations be-
tween pairs of words within one sentence
can be also used as the features. In our pre-
liminary experiments, these features are ef-
fective for the temporal relation identifica-
tion tasks.
</bodyText>
<sectionHeader confidence="0.69729" genericHeader="method">
1 Overview of our system
</sectionHeader>
<bodyText confidence="0.999783">
This paper presents a temporal relation identifier by
the team NAIST.Japan. Our identifier has two char-
actaristics: sequence labeling model and use of de-
pendency parsed tree.
Firstly, we treated each problem a sequence la-
beling problem, such that event/time pairs were or-
dered by the position of the events and times in the
document. This idea is for task B and C. In task
B, the neighbouring relations between an EVENT
and DCT-TIMEX3 tend to interact. In task C, when
EVENT-a, EVENT-b, and EVENT-c are linearly or-
dered, the relation between EVENT-a and EVENT-
b tends to affect the one between EVENT-b and
EVENT-c.
Secondly, we introduced dependency features
where each word was annotated with a label indi-
cating its tree position to the event and the time, e.g.
“descendant” of the event and “ancestor” of the time.
The dependency features are introduced for our ma-
chine learning-based relation identifier. In task A,
we need to label several different event-time pairs
within the same sentence. We can use information
from TIMEX3, which is a descendent of the target
EVENT in the dependency tree.
Section 2 shows how to use a sequence labeling
model for the task. Section 3 shows how to use
the dependency parsed tree for the model. Section
4 presents the results and discussions.
</bodyText>
<sectionHeader confidence="0.745017" genericHeader="method">
2 Temporal Relation Identification by
Sequence Labeling
</sectionHeader>
<bodyText confidence="0.999475375">
Our approach to identify temporal relation is based
on a sequence labeling model. The target pairs are
linearly ordered in the texts.
Sequence labeling model can be defined as a
method to estimate an optimal label sequence g =
(gi, g2, ... , g,) over an observed sequence x =
(XI, x2i ... �xn). We consider, w-parameterized
function
</bodyText>
<equation confidence="0.960188">
f(x) = arg m �x F&apos; (x, g; w) = arg max (w, -4�(x,Y))-
</equation>
<bodyText confidence="0.74471">
Here, y denotes all possible label combinations over
g; -4�(x, g) denotes a feature expression over x, g.
Introducing a kernel function:
K((x, y), (x, y)) _ (-I�(x, y), -4�(x, 9)),
we have a dual representation:
</bodyText>
<equation confidence="0.900713">
m
F(x, y) � azK((x(z ), ����), (x, y)),
Z=i
</equation>
<page confidence="0.962628">
245
</page>
<bodyText confidence="0.667662615384615">
Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 245–248,
Prague, June 2007. c�2007 Association for Computational Linguistics
Before
Before
After
Overlap
Overlap
yx
given a training data set
{(,Vm, ������� ... , � �(-))1. We use
HMM SVM (Altun et al., 2003) as the sequence
labeling model, in which the training is performed
to maximize a margin
</bodyText>
<equation confidence="0.989025">
7j = F(�(k), �(k))k� F(x(k)&gt;Y)•
m
</equation>
<bodyText confidence="0.99988765">
The sequence labeling approach is natural for task
B and C. In task B, if a document is about affairs in
the past, the relations between events and a docu-
ment creation time tend to be “BEFORE”. All rela-
tions in task B depend on each other. In task C, if a
relation between the preceding event and the current
one is “AFTER”, the current one is in the past. The
information helps to determine the relation between
the current and succeeding one. Whereas we have
reasonable explanation to introduce sequence label-
ing for task B and C, we cannot for task A. However,
in our preliminary experiments with trial data, the
sequence labeling model outperformed point-wise
models for task A. Thus, we introduce the sequence
labeling model for task A.
Now, we present the sequence labeling approach
for each task in detail by figure 1, 2 and 3. The
left parts of figures are the graphical models of the
sequence labeling. The right parts are the tagged
corpus: (S) and (/S) are sentence boundaries; a
EVENT-nn denotes an EVENT; a TIME-nn de-
notes a TIMEX3; a TIME-DCT in figure 2 de-
notes a TIMEX3 with document creation time; a
boxed EVENT-nn in figure 3 denotes a matrix verb
EVENT.
For task A (figure 1), x is a sequence of pairs be-
tween an EVENT and a TIMEX3 within the same
sentence. y is a sequence of corresponding relations.
Event-time pairs are ordered first by sentence posi-
tion, then by event position and finally by time posi-
tion. For task B (figure 2), x is a sequence of pairs
between an EVENT and a DCT-TIMEX3. y is a se-
quence of corresponding relations. All pairs in the
same text are linearly ordered and connected. For
task C (figure 3), x is a sequence of pairs between
two matrix verb EVENTs in the neighboring sen-
tences. y is a sequence of corresponding relations.
All pairs in the same text are linearly ordered and
connected, even if the two relations are not in the
adjacent sentences.
</bodyText>
<figure confidence="0.990016777777778">
&lt;s&gt;
EVENT_01⇔TIME_01 EVENT_01...TIME_01 ......................
..............TIME
_02..........................
EVENT_01⇔TIME_02 .................EVENT_02..............
EVENT_02⇔TIME_01 &lt;/s&gt;
&lt;s&gt;
EVENT_02⇔TIME_02 ......TIME_03 .........EVENT_03.......
EVENT_03⇔TIME_03 &lt;/s&gt;
</figure>
<figureCaption confidence="0.996904">
Figure 1: Sequence Labeling Model for Task A
</figureCaption>
<figure confidence="0.927610333333333">
yx
EVENT_01⇔TIME_DCT
EVENT_02⇔TIME_DCT
EVENT_03⇔TIME_DCT
EVENT_04⇔TIME_DCT
EVENT_05⇔TIME_DCT
</figure>
<figureCaption confidence="0.96033">
Figure 2: Sequence Labeling Model for Task B
</figureCaption>
<figure confidence="0.998089692307692">
y x &lt;s&gt;
EVENT_01 ..................................
................. EVENT_02
&lt;/s&gt;
&lt;s&gt;
......... EVENT 03 ...........
&lt;/s&gt;
&lt;s&gt;
................. EVENT 04 ............... EVENT_05
&lt;/s&gt;
&lt;s&gt;
......... EVENT 06 ...........
&lt;/s&gt;
</figure>
<figureCaption confidence="0.999616">
Figure 3: Sequence Labeling Model for Task C
</figureCaption>
<sectionHeader confidence="0.988592" genericHeader="method">
3 Features from Dependency Parsed Tree
</sectionHeader>
<bodyText confidence="0.999608421052631">
A dependency relation is a head-modifier relation on
a syntactic tree. Figure 4 shows an example de-
pendency parsed tree of the following sentence –
“The warrants may be exercised until 90 days after
their issue date”. We parsed the TimeEval data us-
ing MSTParser v0.2 (McDonald and Pereira, 2006),
which is trained with all Penn Treebank (Marcus et
al., 1993) without dependency label.
We introduce tree position labels between an tar-
get node and another node on the dependency parsed
tree: ANC (ancestor), DES (descendant), SIB (sib-
ling), and TARGET (target word). Figure 5 shows
the labels, in which the box with double lines is the
target node. The tree position between the target
EVENT and a word in the target TIMEX3 is used
as a feature for our machine learning-based relation
identifier.
We also use the words in the sentence including
the target entities as features. Each word is anno-
</bodyText>
<figure confidence="0.990229166666667">
Before
Before
Overlap
Before
Before
TIME_DCT
&lt;s&gt;
EVENT_01..................................
.................EVENT_02
&lt;/s&gt;
&lt;s&gt;
.........EVENT_03...........
&lt;/s&gt;
&lt;s&gt;
.................EVENT_04.................
.................EVENT_05
&lt;/s&gt;
Before
After
Overlap
EVENT_01⇔EVENT_03
EVENT_03⇔EVENT_04
EVENT_04⇔EVENT_06
246
warrants
The
90
days
exercised
until
after
may
their
date
be
issue
</figure>
<figureCaption confidence="0.990755">
Figure 4: An example of dependency parsed tree
</figureCaption>
<table confidence="0.913497">
ANC
ANC ANC ANC
SIB TARGET SIB
DES DES DES
</table>
<figureCaption confidence="0.996576">
Figure 5: Tree position labels
</figureCaption>
<figure confidence="0.997987281690141">
TARGET
DES/SIB
SIB
DES
days
date
days
date
days
DES
date
TARGET
DES/SIB
SIB
DES
DES
90
issue
90
issue
90
issue
DES/TARGET
DES/TARGET
may
ANC
may
ANC
may
ANC/ANC
ANC
warrants
be
ANC
ANC
warrants
be
ANC
ANC/ANC
warrants
be
ANC/ANC
TARGET ANC The
ANC
The
exercised
exercised
exercised
until
DES
until
ANC
until
DES/ANC
after
DES
after
ANC
after
DES/ANC
DES
their
SIB
their
DES/SIB
their
ANC ANC/ANC The
TARGET/ANC
TARGET node: “exercised” TARGET nodes: “90” and “days” TARGET-A node: “exercised”
TARGET-B nodes: “90” and “days”
(1) EVENT-based (2) TIMEX3-based (3) JOINT
</figure>
<figureCaption confidence="0.999916">
Figure 6: Tree position labels on the example dependency parsed tree
</figureCaption>
<bodyText confidence="0.998893333333334">
tated with (1) its tree position to the EVENT, (2)
its tree position to the TIMEX3, and (3) the com-
bination of the labels from (1) and (2). Fig. 6
shows the labels of tree positions. The left picture
shows (1) EVENT-based labels of the tree position
with the target EVENT “exercised”. The center pic-
ture shows (2) TIMEX3-based ones with the target
TIMEX3 “90 days”. The right picture shows (3)
JOINT ones which are combinations of the relation
label with the EVENT and with the TIMEX3. We
perform feature selection on the words in the cur-
rent sentence according to the tree position labels.
Note that, when MSTparser outputs more than one
trees for a sentence, we introduce a meta-root node
to bundle the ones in a tree.
</bodyText>
<sectionHeader confidence="0.999424" genericHeader="conclusions">
4 Results and Discussions
</sectionHeader>
<bodyText confidence="0.999654333333333">
We use HMM SVM 1as a sequence labeling model
with features in Table 1, 2 and 3 for task A, B and
C, respectively. The attributes value in TIMEX3
</bodyText>
<footnote confidence="0.98235">
1http://svmlight.joachims.org/svm_
struct.html
</footnote>
<page confidence="0.992057">
247
</page>
<bodyText confidence="0.999776285714286">
is encoded as the relation with DCT-TIMEX3:
{BEFORE, OVERLAP, AFTER, VAGUE}. In
task A, only words in the current sentence with
JOINT relation labels “TARGET/*” or “ANC/*” or
“*/DES”2 were used. In task C, attributes in the
TIMEX3 are annotated with the flag whether the
TIMEX3 entity is the highest (namely the nearest
to the root node) in the tree. Some adverbs and con-
junctions in the succeeding sentence help to deter-
mine the adjacent two relations. Thus, we introduce
all words in the succeeding sentence for Task A and
B. These features are determined by our preliminary
experiments with the trial data.
Table 4 is our results on the test data. Whereas,
our system is average rank in task A and B, it is
worst mark in task C. The features from dependency
parsed trees are effective for task A and B. However,
these are not for task C.
Now, we focus on what went wrong instead of
what went right in our preliminary experiments in
trial data. We tried point-wise methods with other
</bodyText>
<tableCaption confidence="0.546017">
2’*’ stands for wild cards.
Table 1: Features for Task A
</tableCaption>
<table confidence="0.606003681818182">
all attributes in the target EVENT
all attributes in the target TIMEX3
-the attributes value is encoded as the relation with
DCT-TIMEX3
all words in the current sentence with TIMEX3-based
label (2) of tree position
words in the current sentence with JOINT label (3) of
tree position
- only relation label with “TARGET/*” or “ANC/*” or
“*/DES” (* stands for wild cards)
label (1) of tree position from the EVENT to the
TIMEX3
all words in the succeeding sentence
Table 2: Features for Task B
all attributes in the target EVENT
all attributes in the target TIMEX3 of in the current sen-
tence with EVENT-based label (1) of tree position
all attributes in the target TIMEX3 of in the preceding
and succeeding sentence
all words in the current sentence with EVENT-based la-
bel (1) of tree position
all words in the succeeding sentence
</table>
<tableCaption confidence="0.911484">
Table 3: Features for Task C
</tableCaption>
<bodyText confidence="0.994038">
all attributes in the target two EVENTs (EVENT-1 and
EVENT-2)
all attributes in the TIMEX3 in the sentence including
EVENT-1 with the label (1) of tree position to EVENT-
1
all attributes in the TIMEX3 in the sentence including
EVENT-2 with the label (1) of tree position to EVENT-
2
all words in the sentence including EVENT-1 with the
label (1) of tree position to EVENT-1
all words in the sentence including EVENT-2 with the
label (1) of tree position to EVENT-2
machine learners such as maximum entropy and
multi-class support vector machines. However, se-
quence labeling method with HMM SVM outper-
formed other point-wise methods in the trial data.
We have dependency parsed trees of the sen-
tences. Naturally, it would be effective to intro-
duce point-wise tree-based classifiers such as Tree
Kernels in SVM (Collins and Duffy, 2002; Vish-
wanathan and Smola, 2002) and boosting for clas-
sification of trees (Kudo and Matsumoto, 2004). We
tried a boosting learner 3which enables us to perform
subtree feature selection for the tasks. However, the
boosting learner selected only one-node subtrees as
useful features. Thus, we perform simple vector-
based feature engineering on HMM SVM.
</bodyText>
<tableCaption confidence="0.995421">
Table 4: Results
</tableCaption>
<table confidence="0.700307285714286">
Task P R F Rank
Task A (strict) 0.61 0.61 0.61 2/6
Task A (relaxed) 0.63 0.63 0.63 2/6
Task B (strict) 0.75 0.75 0.75 2/6
Task B (relaxed) 0.76 0.76 0.76 2/6
Task C (strict) 0.49 0.49 0.49 5/6
Task C (relaxed) 0.56 0.56 0.56 6/6
</table>
<bodyText confidence="0.999365428571429">
We believe that it is necessary for solving task C
to incorporate knowledge of verb-verb relation. We
also tried to use features in verb ontology such as
VERBOCEAN (Chklovsky and Pantel, 2004) which
is used in (Mani et al., 2006). It did not improved
performance in our preliminary experiments with
trial data.
</bodyText>
<sectionHeader confidence="0.99942" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999758">
Y. Altun, I. Tsochantaridis, and T. Hofmann. 2003. Hid-
den markov support vector machines. In Proc. of
ICML-2003.
T. Chklovsky and P. Pantel. 2004. Verbocean: Mining
the web for fine-grained semantiv verb relations. In
Proc. ofEMNLP-2004.
M. Collins and N. Duffy. 2002. New ranking algorithms
for parsing and tagging: Kernels over discrete struc-
tures, and the voted perceptron. In Proc. ofACL-2002.
T. Kudo and Y. Matsumoto. 2004. A boosting algorithm
for classification of semi-structured text. In Proc. of
EMNLP-2004.
I. Mani, M. Verhagen, B. Wellner, C. M. Lee, and
J. Pustejovsky. 2006. Machine learning of temporal
relations. InProc. ofACL-2006.
M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993.
Building a large annotated corpus of English: the Penn
Treebank. 19(2):313–330.
R. McDonald and F. Pereira. 2006. Online learning of
approximate dependency parsing algorithms. In Proc.
of EACL-2006.
M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple,
and J. Pustejovsky. 2007. Semeval-2007 task 15:
Tempeval temporal relation identification. In Proc. of
SemEval-2007.
S. V. N. Vishwanathan and A. J. Smola. 2002. Fast ker-
nels on strings and trees. In Proc. ofNIPS-2002.
</reference>
<footnote confidence="0.8099">
3http://chasen.org/˜taku/software/bact/
</footnote>
<page confidence="0.987455">
248
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.020614">
<title confidence="0.996324">NAIST.Japan: Temporal Relation Identification Using Dependency Parsed Tree</title>
<author confidence="0.992382">Yuchang Cheng</author>
<author confidence="0.992382">Masayuki Asahara</author>
<author confidence="0.992382">Yuji Matsumoto</author>
<affiliation confidence="0.9992315">Graduate School of Informatino Science, Nara Institute of Science and Technology</affiliation>
<address confidence="0.999601">8916-5 Takayama, Ikoma, Nara, 630-0192, Japan</address>
<email confidence="0.988432">masayu-a,</email>
<abstract confidence="0.974020568123393">In this paper, we attempt to use a sequence labeling model with features from dependency parsed tree for temporal relation identification. In the sequence labeling model, the relations of contextual pairs can be used as features for relation identification of the current pair. Head-modifier relations between pairs of words within one sentence can be also used as the features. In our preliminary experiments, these features are effective for the temporal relation identification tasks. 1 Overview of our system This paper presents a temporal relation identifier by the team NAIST.Japan. Our identifier has two charactaristics: sequence labeling model and use of dependency parsed tree. Firstly, we treated each problem a sequence labeling problem, such that event/time pairs were ordered by the position of the events and times in the document. This idea is for task B and C. In task B, the neighbouring relations between an EVENT and DCT-TIMEX3 tend to interact. In task C, when EVENT-a, EVENT-b, and EVENT-c are linearly ordered, the relation between EVENT-a and EVENTb tends to affect the one between EVENT-b and EVENT-c. Secondly, we introduced dependency features where each word was annotated with a label indicating its tree position to the event and the time, e.g. “descendant” of the event and “ancestor” of the time. The dependency features are introduced for our machine learning-based relation identifier. In task A, we need to label several different event-time pairs within the same sentence. We can use information from TIMEX3, which is a descendent of the target EVENT in the dependency tree. Section 2 shows how to use a sequence labeling model for the task. Section 3 shows how to use the dependency parsed tree for the model. Section 4 presents the results and discussions. 2 Temporal Relation Identification by Sequence Labeling Our approach to identify temporal relation is based on a sequence labeling model. The target pairs are linearly ordered in the texts. Sequence labeling model can be defined as a to estimate an optimal label sequence ... , an observed sequence We consider, function = �x = all possible label combinations over a feature expression over Introducing a kernel function: _ we have a dual representation: m � 245 of the 4th International Workshop on Semantic Evaluations pages 245–248, June 2007. Association for Computational Linguistics Before Before After Overlap Overlap yx given a training data set ... , � We use HMM SVM (Altun et al., 2003) as the sequence labeling model, in which the training is performed to maximize a margin m The sequence labeling approach is natural for task B and C. In task B, if a document is about affairs in the past, the relations between events and a document creation time tend to be “BEFORE”. All relations in task B depend on each other. In task C, if a relation between the preceding event and the current one is “AFTER”, the current one is in the past. The information helps to determine the relation between the current and succeeding one. Whereas we have reasonable explanation to introduce sequence labeling for task B and C, we cannot for task A. However, in our preliminary experiments with trial data, the sequence labeling model outperformed point-wise models for task A. Thus, we introduce the sequence labeling model for task A. Now, we present the sequence labeling approach for each task in detail by figure 1, 2 and 3. The left parts of figures are the graphical models of the sequence labeling. The right parts are the tagged sentence boundaries; a an EVENT; a denotes a TIMEX3; a TIME-DCT in figure 2 denotes a TIMEX3 with document creation time; a figure 3 denotes a matrix verb EVENT. task A (figure 1), a sequence of pairs between an EVENT and a TIMEX3 within the same a sequence of corresponding relations. Event-time pairs are ordered first by sentence position, then by event position and finally by time posi- For task B (figure 2), a sequence of pairs an EVENT and a DCT-TIMEX3. a sequence of corresponding relations. All pairs in the same text are linearly ordered and connected. For C (figure 3), a sequence of pairs between two matrix verb EVENTs in the neighboring sena sequence of corresponding relations. All pairs in the same text are linearly ordered and connected, even if the two relations are not in the adjacent sentences. &lt;s&gt; EVENT_01...TIME_01 ...................... ..............TIME _02.......................... .................EVENT_02.............. &lt;/s&gt; &lt;s&gt; ......TIME_03 .........EVENT_03....... &lt;/s&gt; Figure 1: Sequence Labeling Model for Task A yx Figure 2: Sequence Labeling Model for Task B x ................. EVENT_02 &lt;/s&gt; &lt;s&gt; 03 &lt;/s&gt; &lt;s&gt; 04 EVENT_05 &lt;/s&gt; &lt;s&gt; 06 &lt;/s&gt; Figure 3: Sequence Labeling Model for Task C 3 Features from Dependency Parsed Tree A dependency relation is a head-modifier relation on a syntactic tree. Figure 4 shows an example dependency parsed tree of the following sentence – warrants may be exercised until 90 days after issue We parsed the TimeEval data using MSTParser v0.2 (McDonald and Pereira, 2006), which is trained with all Penn Treebank (Marcus et al., 1993) without dependency label. introduce position between an target node and another node on the dependency parsed tree: ANC (ancestor), DES (descendant), SIB (sibling), and TARGET (target word). Figure 5 shows the labels, in which the box with double lines is the target node. The tree position between the target EVENT and a word in the target TIMEX3 is used as a feature for our machine learning-based relation identifier. We also use the words in the sentence including target entities as features. Each word is anno- Before Before Overlap Before Before TIME_DCT &lt;s&gt; EVENT_01.................................. .................EVENT_02 &lt;/s&gt; &lt;s&gt; .........EVENT_03........... &lt;/s&gt; &lt;s&gt; .................EVENT_04................. .................EVENT_05 &lt;/s&gt; Before After Overlap EVENT_01⇔EVENT_03 EVENT_03⇔EVENT_04 246 warrants The 90 days exercised until after may their date be issue Figure 4: An example of dependency parsed tree ANC ANC ANC ANC SIB TARGET SIB DES DES DES Figure 5: Tree position labels TARGET DES/SIB SIB DES days date days date days DES date TARGET DES/SIB SIB DES DES 90 issue 90 issue 90 issue DES/TARGET DES/TARGET may ANC may ANC may ANC/ANC ANC warrants be ANC ANC warrants be ANC ANC/ANC warrants be ANC/ANC ANC The exercised exercised exercised until DES until ANC until DES/ANC after DES after ANC after DES/ANC DES their SIB their DES/SIB their ANC/ANC TARGET/ANC TARGET node: TARGET nodes: and TARGET-A node: nodes: and (1) EVENT-based (2) TIMEX3-based (3) JOINT Figure 6: Tree position labels on the example dependency parsed tree tated with (1) its tree position to the EVENT, (2) its tree position to the TIMEX3, and (3) the combination of the labels from (1) and (2). Fig. 6 shows the labels of tree positions. The left picture shows (1) EVENT-based labels of the tree position the target EVENT The center picture shows (2) TIMEX3-based ones with the target The right picture shows (3) JOINT ones which are combinations of the relation label with the EVENT and with the TIMEX3. We perform feature selection on the words in the current sentence according to the tree position labels. Note that, when MSTparser outputs more than one trees for a sentence, we introduce a meta-root node to bundle the ones in a tree. 4 Results and Discussions use HMM SVM a sequence labeling model with features in Table 1, 2 and 3 for task A, B and respectively. The attributes TIMEX3 struct.html 247 is encoded as the relation with DCT-TIMEX3: OVERLAP, AFTER, In task A, only words in the current sentence with relation labels or or were used. In task C, attributes in the TIMEX3 are annotated with the flag whether the TIMEX3 entity is the highest (namely the nearest to the root node) in the tree. Some adverbs and conjunctions in the succeeding sentence help to determine the adjacent two relations. Thus, we introduce all words in the succeeding sentence for Task A and B. These features are determined by our preliminary experiments with the trial data. Table 4 is our results on the test data. Whereas, our system is average rank in task A and B, it is worst mark in task C. The features from dependency parsed trees are effective for task A and B. However, these are not for task C. Now, we focus on what went wrong instead of what went right in our preliminary experiments in trial data. We tried point-wise methods with other stands for wild cards. Table 1: Features for Task A all attributes in the target EVENT all attributes in the target TIMEX3 attributes encoded as the relation with DCT-TIMEX3 all words in the current sentence with TIMEX3-based label (2) of tree position words in the current sentence with JOINT label (3) of tree position relation label with or or for wild cards) label (1) of tree position from the EVENT to the TIMEX3 all words in the succeeding sentence Table 2: Features for Task B all attributes in the target EVENT all attributes in the target TIMEX3 of in the current sen-tence with EVENT-based label (1) of tree position all attributes in the target TIMEX3 of in the preceding and succeeding sentence all words in the current sentence with EVENT-based la-bel (1) of tree position all words in the succeeding sentence Table 3: Features for Task C all attributes in the target two EVENTs (EVENT-1 and EVENT-2) all attributes in the TIMEX3 in the sentence including with the label (1) of tree position to EVENT- 1 all attributes in the TIMEX3 in the sentence including with the label (1) of tree position to EVENT- 2 all words in the sentence including EVENT-1 with the label (1) of tree position to EVENT-1 all words in the sentence including EVENT-2 with the label (1) of tree position to EVENT-2 machine learners such as maximum entropy and multi-class support vector machines. However, sequence labeling method with HMM SVM outperformed other point-wise methods in the trial data. We have dependency parsed trees of the sentences. Naturally, it would be effective to introduce point-wise tree-based classifiers such as Tree Kernels in SVM (Collins and Duffy, 2002; Vishwanathan and Smola, 2002) and boosting for classification of trees (Kudo and Matsumoto, 2004). We a boosting learner enables us to perform subtree feature selection for the tasks. However, the boosting learner selected only one-node subtrees as useful features. Thus, we perform simple vectorbased feature engineering on HMM SVM. Table 4: Results Task P R F Rank Task A (strict) 0.61 0.61 0.61 2/6 Task A (relaxed) 0.63 0.63 0.63 2/6 Task B (strict) 0.75 0.75 0.75 2/6 Task B (relaxed) 0.76 0.76 0.76 2/6 Task C (strict) 0.49 0.49 0.49 5/6 Task C (relaxed) 0.56 0.56 0.56 6/6 We believe that it is necessary for solving task C to incorporate knowledge of verb-verb relation. We also tried to use features in verb ontology such as VERBOCEAN (Chklovsky and Pantel, 2004) which is used in (Mani et al., 2006). It did not improved performance in our preliminary experiments with trial data. References Y. Altun, I. Tsochantaridis, and T. Hofmann. 2003. Hidmarkov support vector machines. In of T. Chklovsky and P. Pantel. 2004. Verbocean: Mining the web for fine-grained semantiv verb relations. In M. Collins and N. Duffy. 2002. New ranking algorithms for parsing and tagging: Kernels over discrete strucand the voted perceptron. In T. Kudo and Y. Matsumoto. 2004. A boosting algorithm classification of semi-structured text. In of I. Mani, M. Verhagen, B. Wellner, C. M. Lee, and J. Pustejovsky. 2006. Machine learning of temporal M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. 19(2):313–330. R. McDonald and F. Pereira. 2006. Online learning of dependency parsing algorithms. In M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple, and J. Pustejovsky. 2007. Semeval-2007 task 15: temporal relation identification. In of S. V. N. Vishwanathan and A. J. Smola. 2002. Fast keron strings and trees. In</abstract>
<intro confidence="0.307761">248</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Altun</author>
<author>I Tsochantaridis</author>
<author>T Hofmann</author>
</authors>
<title>Hidden markov support vector machines.</title>
<date>2003</date>
<booktitle>In Proc. of ICML-2003.</booktitle>
<contexts>
<context position="3100" citStr="Altun et al., 2003" startWordPosition="504" endWordPosition="507">tion f(x) = arg m �x F&apos; (x, g; w) = arg max (w, -4�(x,Y))- Here, y denotes all possible label combinations over g; -4�(x, g) denotes a feature expression over x, g. Introducing a kernel function: K((x, y), (x, y)) _ (-I�(x, y), -4�(x, 9)), we have a dual representation: m F(x, y) � azK((x(z ), ����), (x, y)), Z=i 245 Proceedings of the 4th International Workshop on Semantic Evaluations (SemEval-2007), pages 245–248, Prague, June 2007. c�2007 Association for Computational Linguistics Before Before After Overlap Overlap yx given a training data set {(,Vm, ������� ... , � �(-))1. We use HMM SVM (Altun et al., 2003) as the sequence labeling model, in which the training is performed to maximize a margin 7j = F(�(k), �(k))k� F(x(k)&gt;Y)• m The sequence labeling approach is natural for task B and C. In task B, if a document is about affairs in the past, the relations between events and a document creation time tend to be “BEFORE”. All relations in task B depend on each other. In task C, if a relation between the preceding event and the current one is “AFTER”, the current one is in the past. The information helps to determine the relation between the current and succeeding one. Whereas we have reasonable expla</context>
</contexts>
<marker>Altun, Tsochantaridis, Hofmann, 2003</marker>
<rawString>Y. Altun, I. Tsochantaridis, and T. Hofmann. 2003. Hidden markov support vector machines. In Proc. of ICML-2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Chklovsky</author>
<author>P Pantel</author>
</authors>
<title>Verbocean: Mining the web for fine-grained semantiv verb relations.</title>
<date>2004</date>
<booktitle>In Proc. ofEMNLP-2004.</booktitle>
<marker>Chklovsky, Pantel, 2004</marker>
<rawString>T. Chklovsky and P. Pantel. 2004. Verbocean: Mining the web for fine-grained semantiv verb relations. In Proc. ofEMNLP-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
<author>N Duffy</author>
</authors>
<title>New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron. In</title>
<date>2002</date>
<booktitle>Proc. ofACL-2002.</booktitle>
<contexts>
<context position="11595" citStr="Collins and Duffy, 2002" startWordPosition="1904" endWordPosition="1907">sentence including EVENT-2 with the label (1) of tree position to EVENT2 all words in the sentence including EVENT-1 with the label (1) of tree position to EVENT-1 all words in the sentence including EVENT-2 with the label (1) of tree position to EVENT-2 machine learners such as maximum entropy and multi-class support vector machines. However, sequence labeling method with HMM SVM outperformed other point-wise methods in the trial data. We have dependency parsed trees of the sentences. Naturally, it would be effective to introduce point-wise tree-based classifiers such as Tree Kernels in SVM (Collins and Duffy, 2002; Vishwanathan and Smola, 2002) and boosting for classification of trees (Kudo and Matsumoto, 2004). We tried a boosting learner 3which enables us to perform subtree feature selection for the tasks. However, the boosting learner selected only one-node subtrees as useful features. Thus, we perform simple vectorbased feature engineering on HMM SVM. Table 4: Results Task P R F Rank Task A (strict) 0.61 0.61 0.61 2/6 Task A (relaxed) 0.63 0.63 0.63 2/6 Task B (strict) 0.75 0.75 0.75 2/6 Task B (relaxed) 0.76 0.76 0.76 2/6 Task C (strict) 0.49 0.49 0.49 5/6 Task C (relaxed) 0.56 0.56 0.56 6/6 We be</context>
</contexts>
<marker>Collins, Duffy, 2002</marker>
<rawString>M. Collins and N. Duffy. 2002. New ranking algorithms for parsing and tagging: Kernels over discrete structures, and the voted perceptron. In Proc. ofACL-2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kudo</author>
<author>Y Matsumoto</author>
</authors>
<title>A boosting algorithm for classification of semi-structured text.</title>
<date>2004</date>
<booktitle>In Proc. of EMNLP-2004.</booktitle>
<contexts>
<context position="11694" citStr="Kudo and Matsumoto, 2004" startWordPosition="1920" endWordPosition="1923">e including EVENT-1 with the label (1) of tree position to EVENT-1 all words in the sentence including EVENT-2 with the label (1) of tree position to EVENT-2 machine learners such as maximum entropy and multi-class support vector machines. However, sequence labeling method with HMM SVM outperformed other point-wise methods in the trial data. We have dependency parsed trees of the sentences. Naturally, it would be effective to introduce point-wise tree-based classifiers such as Tree Kernels in SVM (Collins and Duffy, 2002; Vishwanathan and Smola, 2002) and boosting for classification of trees (Kudo and Matsumoto, 2004). We tried a boosting learner 3which enables us to perform subtree feature selection for the tasks. However, the boosting learner selected only one-node subtrees as useful features. Thus, we perform simple vectorbased feature engineering on HMM SVM. Table 4: Results Task P R F Rank Task A (strict) 0.61 0.61 0.61 2/6 Task A (relaxed) 0.63 0.63 0.63 2/6 Task B (strict) 0.75 0.75 0.75 2/6 Task B (relaxed) 0.76 0.76 0.76 2/6 Task C (strict) 0.49 0.49 0.49 5/6 Task C (relaxed) 0.56 0.56 0.56 6/6 We believe that it is necessary for solving task C to incorporate knowledge of verb-verb relation. We al</context>
</contexts>
<marker>Kudo, Matsumoto, 2004</marker>
<rawString>T. Kudo and Y. Matsumoto. 2004. A boosting algorithm for classification of semi-structured text. In Proc. of EMNLP-2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Mani</author>
<author>M Verhagen</author>
<author>B Wellner</author>
<author>C M Lee</author>
<author>J Pustejovsky</author>
</authors>
<title>Machine learning of temporal relations.</title>
<date>2006</date>
<booktitle>InProc. ofACL-2006.</booktitle>
<marker>Mani, Verhagen, Wellner, Lee, Pustejovsky, 2006</marker>
<rawString>I. Mani, M. Verhagen, B. Wellner, C. M. Lee, and J. Pustejovsky. 2006. Machine learning of temporal relations. InProc. ofACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: the Penn Treebank.</title>
<date>1993</date>
<contexts>
<context position="6244" citStr="Marcus et al., 1993" startWordPosition="1009" endWordPosition="1012">.... ................. EVENT_02 &lt;/s&gt; &lt;s&gt; ......... EVENT 03 ........... &lt;/s&gt; &lt;s&gt; ................. EVENT 04 ............... EVENT_05 &lt;/s&gt; &lt;s&gt; ......... EVENT 06 ........... &lt;/s&gt; Figure 3: Sequence Labeling Model for Task C 3 Features from Dependency Parsed Tree A dependency relation is a head-modifier relation on a syntactic tree. Figure 4 shows an example dependency parsed tree of the following sentence – “The warrants may be exercised until 90 days after their issue date”. We parsed the TimeEval data using MSTParser v0.2 (McDonald and Pereira, 2006), which is trained with all Penn Treebank (Marcus et al., 1993) without dependency label. We introduce tree position labels between an target node and another node on the dependency parsed tree: ANC (ancestor), DES (descendant), SIB (sibling), and TARGET (target word). Figure 5 shows the labels, in which the box with double lines is the target node. The tree position between the target EVENT and a word in the target TIMEX3 is used as a feature for our machine learning-based relation identifier. We also use the words in the sentence including the target entities as features. Each word is annoBefore Before Overlap Before Before TIME_DCT &lt;s&gt; EVENT_01........</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. Marcinkiewicz. 1993. Building a large annotated corpus of English: the Penn Treebank. 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
</authors>
<title>Online learning of approximate dependency parsing algorithms.</title>
<date>2006</date>
<booktitle>In Proc. of EACL-2006.</booktitle>
<contexts>
<context position="6181" citStr="McDonald and Pereira, 2006" startWordPosition="998" endWordPosition="1001">eling Model for Task B y x &lt;s&gt; EVENT_01 .................................. ................. EVENT_02 &lt;/s&gt; &lt;s&gt; ......... EVENT 03 ........... &lt;/s&gt; &lt;s&gt; ................. EVENT 04 ............... EVENT_05 &lt;/s&gt; &lt;s&gt; ......... EVENT 06 ........... &lt;/s&gt; Figure 3: Sequence Labeling Model for Task C 3 Features from Dependency Parsed Tree A dependency relation is a head-modifier relation on a syntactic tree. Figure 4 shows an example dependency parsed tree of the following sentence – “The warrants may be exercised until 90 days after their issue date”. We parsed the TimeEval data using MSTParser v0.2 (McDonald and Pereira, 2006), which is trained with all Penn Treebank (Marcus et al., 1993) without dependency label. We introduce tree position labels between an target node and another node on the dependency parsed tree: ANC (ancestor), DES (descendant), SIB (sibling), and TARGET (target word). Figure 5 shows the labels, in which the box with double lines is the target node. The tree position between the target EVENT and a word in the target TIMEX3 is used as a feature for our machine learning-based relation identifier. We also use the words in the sentence including the target entities as features. Each word is annoBe</context>
</contexts>
<marker>McDonald, Pereira, 2006</marker>
<rawString>R. McDonald and F. Pereira. 2006. Online learning of approximate dependency parsing algorithms. In Proc. of EACL-2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Verhagen</author>
<author>R Gaizauskas</author>
<author>F Schilder</author>
<author>M Hepple</author>
<author>J Pustejovsky</author>
</authors>
<title>Semeval-2007 task 15: Tempeval temporal relation identification.</title>
<date>2007</date>
<booktitle>In Proc. of SemEval-2007.</booktitle>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Pustejovsky, 2007</marker>
<rawString>M. Verhagen, R. Gaizauskas, F. Schilder, M. Hepple, and J. Pustejovsky. 2007. Semeval-2007 task 15: Tempeval temporal relation identification. In Proc. of SemEval-2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S V N Vishwanathan</author>
<author>A J Smola</author>
</authors>
<title>Fast kernels on strings and trees.</title>
<date>2002</date>
<booktitle>In Proc. ofNIPS-2002.</booktitle>
<contexts>
<context position="11626" citStr="Vishwanathan and Smola, 2002" startWordPosition="1908" endWordPosition="1912">2 with the label (1) of tree position to EVENT2 all words in the sentence including EVENT-1 with the label (1) of tree position to EVENT-1 all words in the sentence including EVENT-2 with the label (1) of tree position to EVENT-2 machine learners such as maximum entropy and multi-class support vector machines. However, sequence labeling method with HMM SVM outperformed other point-wise methods in the trial data. We have dependency parsed trees of the sentences. Naturally, it would be effective to introduce point-wise tree-based classifiers such as Tree Kernels in SVM (Collins and Duffy, 2002; Vishwanathan and Smola, 2002) and boosting for classification of trees (Kudo and Matsumoto, 2004). We tried a boosting learner 3which enables us to perform subtree feature selection for the tasks. However, the boosting learner selected only one-node subtrees as useful features. Thus, we perform simple vectorbased feature engineering on HMM SVM. Table 4: Results Task P R F Rank Task A (strict) 0.61 0.61 0.61 2/6 Task A (relaxed) 0.63 0.63 0.63 2/6 Task B (strict) 0.75 0.75 0.75 2/6 Task B (relaxed) 0.76 0.76 0.76 2/6 Task C (strict) 0.49 0.49 0.49 5/6 Task C (relaxed) 0.56 0.56 0.56 6/6 We believe that it is necessary for </context>
</contexts>
<marker>Vishwanathan, Smola, 2002</marker>
<rawString>S. V. N. Vishwanathan and A. J. Smola. 2002. Fast kernels on strings and trees. In Proc. ofNIPS-2002.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>