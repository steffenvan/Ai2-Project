<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016677">
<title confidence="0.645186666666667">
A Pragmatic Approach to Summary Extraction in Clinical Trials
Graciela Rosemblat
National Library of Medicine
</title>
<note confidence="0.404227">
NIH, Bethesda, Maryland
</note>
<email confidence="0.954282">
rosem@nlm.nih.gov
</email>
<sectionHeader confidence="0.890407" genericHeader="abstract">
Background and Introduction
</sectionHeader>
<bodyText confidence="0.999869256410256">
ClinicalTrials.gov, the National Library of
Medicine clinical trials registry, is a monolingual
clinical research website with over 29,000 records
at present. The information is presented in static
and free-text fields. Static fields contain high-level
informational text, descriptors, and controlled vo-
cabularies that remain constant across all clinical
studies (headings, general information). Free-text
data are detailed and trial-specific, such as the Pur-
pose section, which presents each trial’s goal, with
large inter-trial variability in length as well as in
technical difficulty. The crux of the trial purpose is
generally found in 1-3 sentences, often introduced
by clearly identified natural language markers.
In the Spanish cross-language information re-
trieval (CLIR) ClinicalTrials.gov prototype, indi-
vidual studies are displayed as abridged Spanish-
language records, with Spanish static field descrip-
tors, and a manual Spanish translation for the free-
text study title. The Purpose section of these ab-
breviated documents only contains a link (in Span-
ish) to the full-text English record. The premise
was that the gist could be obtained from the Span-
ish title, the link to the English document, and the
Spanish descriptors. However, in a recently con-
ducted user study on the Spanish CLIR prototype,
Spanish-speaking consumers did not use the Pur-
pose section link, as doing so entailed leaving a
Spanish webpage to go to an English one. Further,
feedback from an earlier study indicated a need for
some Spanish text in the Purpose section to pro-
vide the gist of the trial while avoiding the infor-
mation overload in the full-text English record.
Thus, in an alternative display format, extractive
summarization plus translation was used to en-
hance the abbreviated Spanish document and sup-
plement the link to the English record. The trial
purpose--up to three sentences--was algorithmi-
cally extracted from the English document Purpose
</bodyText>
<subsectionHeader confidence="0.955773">
Laurel Graham
National Library of Medicine
</subsectionHeader>
<bodyText confidence="0.984402869565217">
NIH, Bethesda, Maryland
lagraham@mail.nih.gov
section, and translated into Spanish via post-edited
machine translation for display in the Spanish re-
cord Purpose section (Rosemblat et al., 2005).
Our extraction technique, which combines sen-
tence boundary detection, regular expressions, and
decision-based rules, was validated by the user
study for facilitating user relevance judgment. All
participants endorsed this alternative display for-
mat over the initial schematic design, especially
when the Purpose extract makes up the entire Pur-
pose section in the English document, as is the case
in 48% of all trials. For Purpose sections that span
many paragraphs and exceed 1,000 words, human
translation is not viable. Machine translation is
used to reduce the burden, and using excerpts of
the original text as opposed to entire documents
further reduces the resource cost. Human post-
editing ensures the accuracy of translations. Auto-
mated extraction of key goal-describing text may
provide relevant excerpts of the original text via
topic recognition techniques (Hovy, 2003).
</bodyText>
<sectionHeader confidence="0.8345535" genericHeader="keywords">
1 RegExp Detection and Pattern Match-
ing
</sectionHeader>
<bodyText confidence="0.9998836">
Linguistic analysis of the natural language ex-
pressions in the clinical trial records’ Purpose sec-
tion was performed manually on a large sample of
documents. Common language patterns across
studies introducing the purpose/goal of each trial
served as cue phrases. These cue phrases contained
both quality features and the rhetorical role of
GOAL (Teufel and Moens, 1999). The crux of the
purpose was generally condensed in 1-3 sentences
within the Purpose section, showing definite pat-
terns and a limited set of productive, straightfor-
ward linguistic markers. From these common
patterns, the ClinicalTrials.gov Purpose Extractor
Algorithm (PEA) was devised, and developed in
Java (1.5) using the native regexp package.
</bodyText>
<page confidence="0.950699">
124
</page>
<note confidence="0.778573">
Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 124–125,
New York City, June 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.996350666666667">
Natural language expressions in the purpose
sentences include three basic elements, making
them well suited to regular expressions:
</bodyText>
<listItem confidence="0.864091666666667">
a) A small, closed set of verbs (determine, test)
b) Specific purpose triggers or cues (goal, aim)
c) Particular types of sentence constructs, as in:
</listItem>
<bodyText confidence="0.987447451612903">
This study will evaluate two medications...
PEA incorporates sentence boundary detection
(A), purpose statement matching (B), and a series
of decision steps (C) to ensure the extracted text is
semantically and syntactically correct:
A) To improve regexp performance and en-
sure that extraction occurred in complete sen-
tences, sentence boundary detection was
implemented. Grok (OpenNLP), open source Java
NLP software, was used for this task, corpus-
trained and validated, and supplemented with
rules-based post-processing.
B) Regular expressions were rank ordered
from most specific to the more general with a de-
fault expression should all others fail to match. The
regexp patterns allowed for possible tense and op-
tional modal variations, and included a range of all
possible patterns that resulted from combining
verbs and triggers, controlled for case-sensitivity.
The default for cases that differed from the stan-
dard patterns relied solely on the verb set provided.
C) Checks were made for (a) length normali-
zation (a maximum of 450 characters), with pur-
pose-specific text in enumerated or bulleted lists
overriding this restriction; and (b) discourse mark-
ers pointing to extra-sentential information for the
semantic processing of the text. In this case, PEA
determines the anchor sentence (main crux of the
purpose), and then whether to include a leading
and trailing sentence, or two leading sentences or
two trailing ones, to reach the 3-sentence limit.
</bodyText>
<table confidence="0.99848175">
RegExp Patterns Description Case
PURPOSE Sentence label (purpose) Yes
To VERB SET Study action starts section No
In THIS STUDY General actions in study No
</table>
<tableCaption confidence="0.999818">
Table 1. Some purpose patterns used by PEA
</tableCaption>
<sectionHeader confidence="0.971125" genericHeader="method">
2 Evaluation
</sectionHeader>
<bodyText confidence="0.998505875">
Manual PEA validation was done on a random
sample of 300 trials. For a stricter test, the 13,110
studies with Purpose sections short enough to in-
clude in full without any type of processing or de-
cision were not part of the random sample.
Judgments were provided by the authors, one of
whom was not involved in the development of
PEA code. The 300 English extracts (before trans-
lation) were compared against the full-text Purpose
sections in the clinical trials, with compression rate
averaging 30%. Evaluation was done on a 3-point
scale: perfect extraction, appropriate, wrong text.
Inter-annotator agreement using Cohen’s kappa
was considered to be good (Kappa = 0.756987).
Table 2 shows evaluation results after inter-rater
differences were reconciled:
</bodyText>
<table confidence="0.9722755">
CRITERIA TRIALS RATIO
Perfect extraction 275 92%
Appropriate extraction 18 6%
Extraction of wrong text 7 2%
</table>
<tableCaption confidence="0.999016">
Table 2: Results: 300 Clinical trials random sample
</tableCaption>
<sectionHeader confidence="0.993515" genericHeader="conclusions">
3 Conclusion
</sectionHeader>
<bodyText confidence="0.999984">
This pragmatic approach to task-specific (pur-
posive) summary extraction in a limited domain
(ClinicalTrials.gov) using regular expressions has
shown a 92% precision. Further research will de-
termine if this method is appropriate for CLIR and
query language display via machine translation and
subsequent post-editing in clinical trials informa-
tion systems for other registries and sponsors.
</bodyText>
<sectionHeader confidence="0.996004" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999900666666667">
The authors thank Tony Tse and the anonymous
reviewers for valuable feedback. Work supported
by the NIH, NLM Intramural Research Program.
</bodyText>
<sectionHeader confidence="0.999255" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999861">
Eduard Hovy. 2003. Text Summarization. In Ruslan
Mitkov (Ed.), The Oxford Handbook of Computa-
tional Linguistics (pp. 583-598). Oxford University
Press.
Graciela Rosemblat, Tony Tse, Darren Gemoets, John
E. Gillen, and Nicholas C. Ide. 2005. Supporting Ac-
cess to Consumer Health Information Across Lan-
guages. Proceedings of the 8th International ISKO
Conference. London, England. pp. 315-321
Grok part of the OpenNLP project. [Accessed at
http://grok.sourceforge.net]
Simone Teufel and Marc Moens. 1999. Argumentative
classification of extracted sentences as a step towards
flexible abstracting. In Advances in Automatic Text
Summarization, I. Mani and M.T. Maybury (eds.),
pp. 155-171. MIT Press.
</reference>
<page confidence="0.998497">
125
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.804924">
<title confidence="0.999801">A Pragmatic Approach to Summary Extraction in Clinical Trials</title>
<author confidence="0.979567">Graciela Rosemblat</author>
<affiliation confidence="0.995373">National Library of Medicine</affiliation>
<address confidence="0.905612">NIH, Bethesda, Maryland</address>
<email confidence="0.899071">rosem@nlm.nih.gov</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
</authors>
<title>Text Summarization.</title>
<date>2003</date>
<booktitle>In Ruslan Mitkov (Ed.), The Oxford Handbook of Computational Linguistics</booktitle>
<pages>583--598</pages>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="3239" citStr="Hovy, 2003" startWordPosition="481" endWordPosition="482">hematic design, especially when the Purpose extract makes up the entire Purpose section in the English document, as is the case in 48% of all trials. For Purpose sections that span many paragraphs and exceed 1,000 words, human translation is not viable. Machine translation is used to reduce the burden, and using excerpts of the original text as opposed to entire documents further reduces the resource cost. Human postediting ensures the accuracy of translations. Automated extraction of key goal-describing text may provide relevant excerpts of the original text via topic recognition techniques (Hovy, 2003). 1 RegExp Detection and Pattern Matching Linguistic analysis of the natural language expressions in the clinical trial records’ Purpose section was performed manually on a large sample of documents. Common language patterns across studies introducing the purpose/goal of each trial served as cue phrases. These cue phrases contained both quality features and the rhetorical role of GOAL (Teufel and Moens, 1999). The crux of the purpose was generally condensed in 1-3 sentences within the Purpose section, showing definite patterns and a limited set of productive, straightforward linguistic markers</context>
</contexts>
<marker>Hovy, 2003</marker>
<rawString>Eduard Hovy. 2003. Text Summarization. In Ruslan Mitkov (Ed.), The Oxford Handbook of Computational Linguistics (pp. 583-598). Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graciela Rosemblat</author>
<author>Tony Tse</author>
<author>Darren Gemoets</author>
<author>John E Gillen</author>
<author>Nicholas C Ide</author>
</authors>
<title>Supporting Access to Consumer Health Information Across Languages.</title>
<date>2005</date>
<booktitle>Proceedings of the 8th International ISKO Conference.</booktitle>
<pages>315--321</pages>
<location>London, England.</location>
<contexts>
<context position="2358" citStr="Rosemblat et al., 2005" startWordPosition="346" endWordPosition="349">ide the gist of the trial while avoiding the information overload in the full-text English record. Thus, in an alternative display format, extractive summarization plus translation was used to enhance the abbreviated Spanish document and supplement the link to the English record. The trial purpose--up to three sentences--was algorithmically extracted from the English document Purpose Laurel Graham National Library of Medicine NIH, Bethesda, Maryland lagraham@mail.nih.gov section, and translated into Spanish via post-edited machine translation for display in the Spanish record Purpose section (Rosemblat et al., 2005). Our extraction technique, which combines sentence boundary detection, regular expressions, and decision-based rules, was validated by the user study for facilitating user relevance judgment. All participants endorsed this alternative display format over the initial schematic design, especially when the Purpose extract makes up the entire Purpose section in the English document, as is the case in 48% of all trials. For Purpose sections that span many paragraphs and exceed 1,000 words, human translation is not viable. Machine translation is used to reduce the burden, and using excerpts of the </context>
</contexts>
<marker>Rosemblat, Tse, Gemoets, Gillen, Ide, 2005</marker>
<rawString>Graciela Rosemblat, Tony Tse, Darren Gemoets, John E. Gillen, and Nicholas C. Ide. 2005. Supporting Access to Consumer Health Information Across Languages. Proceedings of the 8th International ISKO Conference. London, England. pp. 315-321</rawString>
</citation>
<citation valid="false">
<title>Grok part of the OpenNLP project.</title>
<note>[Accessed at http://grok.sourceforge.net]</note>
<marker></marker>
<rawString>Grok part of the OpenNLP project. [Accessed at http://grok.sourceforge.net]</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simone Teufel</author>
<author>Marc Moens</author>
</authors>
<title>Argumentative classification of extracted sentences as a step towards flexible abstracting.</title>
<date>1999</date>
<booktitle>In Advances in Automatic Text Summarization,</booktitle>
<pages>155--171</pages>
<editor>I. Mani and M.T. Maybury (eds.),</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="3651" citStr="Teufel and Moens, 1999" startWordPosition="543" endWordPosition="546">rce cost. Human postediting ensures the accuracy of translations. Automated extraction of key goal-describing text may provide relevant excerpts of the original text via topic recognition techniques (Hovy, 2003). 1 RegExp Detection and Pattern Matching Linguistic analysis of the natural language expressions in the clinical trial records’ Purpose section was performed manually on a large sample of documents. Common language patterns across studies introducing the purpose/goal of each trial served as cue phrases. These cue phrases contained both quality features and the rhetorical role of GOAL (Teufel and Moens, 1999). The crux of the purpose was generally condensed in 1-3 sentences within the Purpose section, showing definite patterns and a limited set of productive, straightforward linguistic markers. From these common patterns, the ClinicalTrials.gov Purpose Extractor Algorithm (PEA) was devised, and developed in Java (1.5) using the native regexp package. 124 Proceedings of the BioNLP Workshop on Linking Natural Language Processing and Biology at HLT-NAACL 06, pages 124–125, New York City, June 2006. c�2006 Association for Computational Linguistics Natural language expressions in the purpose sentences </context>
</contexts>
<marker>Teufel, Moens, 1999</marker>
<rawString>Simone Teufel and Marc Moens. 1999. Argumentative classification of extracted sentences as a step towards flexible abstracting. In Advances in Automatic Text Summarization, I. Mani and M.T. Maybury (eds.), pp. 155-171. MIT Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>