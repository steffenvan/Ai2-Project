<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000803">
<note confidence="0.723016666666667">
BBN System Description for WMT10 System Combination Task
Antti-Veikko I. Rosti and Bing Zhang and Spyros Matsoukas and Richard Schwartz
Raytheon BBN Technologies, 10 Moulton Street, Cambridge, MA 02138, USA
</note>
<email confidence="0.955819">
{arosti,bzhang,smatsouk,schwartz}@bbn.com
</email>
<sectionHeader confidence="0.996894" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999701428571429">
BBN submitted system combination out-
puts for Czech-English, German-English,
Spanish-English, French-English, and All-
English language pairs. All combinations
were based on confusion network decod-
ing. An incremental hypothesis alignment
algorithm with flexible matching was used
to build the networks. The bi-gram de-
coding weights for the single source lan-
guage translations were tuned directly to
maximize the BLEU score of the decod-
ing output. Approximate expected BLEU
was used as the objective function in gra-
dient based optimization of the combina-
tion weights for a 44 system multi-source
language combination (All-English). The
system combination gained around 0.4-
2.0 BLEU points over the best individual
systems on the single source conditions.
On the multi-source condition, the system
combination gained 6.6 BLEU points.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999896438596492">
The BBN submissions to the WMT10 system
combination task were based on confusion net-
work decoding. The confusion networks were
built using the incremental hypothesis alignment
algorithm with flexible matching introduced in the
BBN submission for the WMT09 system combi-
nation task (Rosti et al., 2009). This year, the
system combination weights were tuned to max-
imize the BLEU score (Papineni et al., 2002) of
the 1-best decoding output (lattice based BLEU
tuning) using downhill simplex method (Press et
al., 2007). A 44 system multi-source combina-
tion was also submitted. Since the gradient-free
optimization algorithms do not seem to be able to
handle more than 20-30 weights, a gradient ascent
to maximize an approximate expected BLEU ob-
jective was used to optimize the larger number of
weights.
The lattice based BLEU tuning may be imple-
mented using any optimization algorithm that does
not require the gradient of the objective function.
Due to the size of the lattices, the objective func-
tion evaluation may have to be distributed to mul-
tiple servers. The optimizer client accumulates the
BLEU statistics of the 1-best hypotheses from the
servers for given search weights, computes the fi-
nal BLEU score, and passes it to the optimiza-
tion algorithm which returns a new set of search
weights. The lattice based tuning explores the en-
tire search space and does not require multiple de-
coding iterations with N-best list merging to ap-
proximate the search space as in the standard min-
imum error rate training (Och, 2003). This allows
much faster turnaround in weight tuning.
Differentiable approximations of BLEU have
been proposed for consensus decoding. Tromble
et al. (2008) used a linear approximation and Pauls
et al. (2009) used a closer approximation called
CoBLEU. CoBLEU is based on the BLEU for-
mula but the n-gram counts are replaced by ex-
pected counts over a translation forest. Due to the
min-functions required in converting the n-gram
counts to matches and a non-differentiable brevity
penalty, a sub-gradient ascent must be used. In
this work, an approximate expected BLEU (Exp-
BLEU) defined over N-best lists was used as a
differentiable objective function. ExpBLEU uses
expected BLEU statistics where the min-function
is not needed as the statistics are computed off-
line and the brevity penalty is replaced by a dif-
ferentiable approximation. The ExpBLEU tun-
ing yields comparable results to direct BLEU tun-
ing using gradient-free algorithms on combina-
tions of small number of systems (fewer than 20-
30 weights). Results on a 44 system combination
show that the gradient based optimization is more
robust with larger number of weights.
</bodyText>
<page confidence="0.983791">
321
</page>
<note confidence="0.4530005">
Proceedings of the Joint 5th Workshop on Statistical Machine Translation and MetricsMATR, pages 321–326,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.999741363636364">
This paper is organized as follows. Section
2 reviews the incremental hypothesis alignment
algorithm used to built the confusion networks.
Decoding weight optimization using direct lattice
1-best BLEU tuning and N-best list based Exp-
BLEU tuning are presented in Section 3. Exper-
imental results on combining single source lan-
guage to English outputs and all 44 English out-
puts are detailed in Section 4. Finally, Section 5
concludes this paper with some ideas for future
work.
</bodyText>
<sectionHeader confidence="0.958937" genericHeader="method">
2 Hypothesis Alignment
</sectionHeader>
<bodyText confidence="0.9999685">
The confusion networks were built by using the
incremental hypothesis alignment algorithm with
flexible matching introduced in Rosti et al. (2009).
The algorithm is reviewed in more detail here. It
is loosely related to the alignment performed in
the calculation of the translation edit rate (TER)
(Snover et al., 2006) which estimates the edit
distance between two strings allowing shifts of
blocks of words in addition to insertions, dele-
tions, and substitutions. Calculating an exact TER
for strings longer than a few tokens1 is not compu-
tationally feasible, so the tercom2 software uses
heuristic shift constraints and pruning to find an
upper bound of TER. In this work, the hypothe-
ses were aligned incrementally with the confusion
network, thus using tokens from all previously
aligned hypotheses in computing the edit distance.
Lower substitution costs were assigned to tokens
considered equivalent and the heuristic shift con-
straints of tercom were relaxed3.
First, tokens from all hypotheses are put into
equivalence classes if they belong to the same
WordNet (Fellbaum, 1998) synonym set or have
the same stem. The 1-best hypothesis from each
system is used as the confusion network skeleton
which defines the final word order of the decod-
ing output. Second, a trivial confusion network
is generated from the skeleton hypothesis by gen-
erating a single arc for each token. The align-
ment algorithm explores shifts of blocks of words
that minimize the edit distance between the cur-
rent confusion network and an unaligned hypothe-
</bodyText>
<footnote confidence="0.992037714285714">
1Hypotheses are tokenized and lower-cased prior to align-
ment. Tokens generally refer to words and punctuation.
2http://www.cs.umd.edu/˜snover/tercom/
current version 0.7.25.
3This algorithm is not equivalent to an incremental TER-
Plus (Snover et al., 2009) due to different shift constraints and
the lack of paraphrase matching
</footnote>
<figure confidence="0.9935785">
(a) Skeleton hypothesis.
(b) Two hypotheses (insertion).
(c) Three hypotheses (deletion).
(d) Four hypotheses (substitution).
</figure>
<figureCaption confidence="0.999738">
Figure 1: Example of incrementally aligning “cat
</figureCaption>
<bodyText confidence="0.971763037037037">
sat mat”, “cat sat on mat”, “sat mat”, and “cat sat
hat”.
sis. Third, the hypothesis with the lowest edit dis-
tance to the current confusion network is aligned
into the network. The heuristically selected edit
costs used in the WMT10 system were 1.0 for
insertions, deletions, and shifts, 0.2 for substitu-
tions of tokens in the same equivalence class, and
1.0001 for substitutions of non-equivalent tokens.
An insertion with respect to the network always
results in a new node and two new arcs. The first
arc contains the inserted token and the second arc
contains a NULL token representing the missing
token from all previously aligned hypotheses. A
substitution/deletion results in a new token/NULL
arc or increase in the confidence of an existing to-
ken/NULL arc. The process is repeated until all
hypotheses are aligned into the network.
For example, given the following hypotheses
from four systems: “cat sat mat”, “cat sat on mat”,
“sat mat”, and “cat sat hat”, an initial network in
Figure 1(a) is generated. The following two hy-
potheses have a distance of one edit from the initial
network, so the second can be aligned next. Figure
1(b) shows the additional node created and the two
new arcs for ‘on’ and ‘NULL’ tokens. The third
hypothesis has deleted token ‘cat’ and matches the
</bodyText>
<equation confidence="0.8805302">
cat(1) sat(1) mat(1)
0 1 2
3
cat(1,1) sat(1,1) on(0,1)
0 1 2 3
NULL(1,0)
mat(1,1)
4
cat(1,1,0)
0 1
NULL(0,0,1)
sat(1,1,1) on(0,1,0)
2 3
NULL(1,0,1)
mat(1,1,1)
4
cat(1,1,0,1)
0 1
NULL(0,0,1,0)
sat(1,1,1,1) on(0,1,0,0)
2 3
NULL(1,0,1,1)
mat(1,1,1,0)
hat(0,0,0,1)
4
</equation>
<page confidence="0.988652">
322
</page>
<bodyText confidence="0.948432380952381">
‘NULL’ token between nodes 2 and 3 as seen in
Figure 1(c). The fourth hypothesis matches all but
the final token ‘hat’ which becomes a substitution
for ‘mat’ in Figure 1(d). The binary vectors in
the parentheses following each token show which
system generated the token aligned to that arc. If
the systems generated N-best hypotheses, a frac-
tional increment could be added to these vectors
as in (Rosti et al., 2007). Given these system spe-
cific scores are normalized to sum to one over all
arcs connecting two consecutive nodes, they may
be viewed as system specific word arc posterior
estimates. Note, for 1-best hypotheses the scores
sum to one without normalization.
Given system outputs £ = {E1, ... , EN3},
an algorithm to build a set of Ns confusion
networks C = {C1, ... , CN3} may be written
as:
for n = 1 to Ns do
Cn &lt;-- Init(En) {initialize confusion net-
work from the skeleton}
</bodyText>
<equation confidence="0.722190875">
£&apos; &lt;-- £ − En {set of unaligned hypotheses}
while £&apos; =� 0 do
Em &lt;-- argminEE£, Dist(E, Cn)
{compute edit distances}
Cn &lt;-- Align(Em, Cn) {align closest hy-
pothesis}
£&apos; &lt;-- £&apos; − Em {update set of unaligned
hypotheses}
</equation>
<bodyText confidence="0.935251176470588">
end while
end for
The set of Ns confusion networks are expanded to
separate paths with distinct bi-gram contexts and
connected in parallel into a big lattice with com-
mon start and end nodes with NULL token arcs.
A prior probability estimate is assigned to the sys-
tem specific word arc confidences connecting the
common start node and the first node in each sub-
network. A heuristic prior is estimated as:
where en is the total cost of aligning all hypothe-
ses when using system n as the skeleton, Nn is
the number of nodes in the confusion network be-
fore bi-gram expansion, and Z is a scaling factor
to guarantee pn sum to one. This gives a higher
prior for a network with fewer alignment errors
and longer expected decoding output.
</bodyText>
<sectionHeader confidence="0.990591" genericHeader="method">
3 Weight Optimization
</sectionHeader>
<bodyText confidence="0.9996035">
Standard search algorithms may be used to find N-
best hypotheses from the final lattice. The score
</bodyText>
<equation confidence="0.88043025">
for arc l is computed as:
N3
(sl = log E )σnsnl + λL(wl|wP(l)) + ωS(wl)
n�1
</equation>
<bodyText confidence="0.993280692307693">
(2)
where σn are the system weights constrained to
sum to one, snl are the system specific arc pos-
teriors, λ is a language model (LM) scaling fac-
tor, L(wl|wP(l)) is the bi-gram log-probability for
the token wl on the arc l given the token wP(l)
on the arc P(l) preceding the arc l, ω is the word
insertion scaling factor, and S(wl) is zero if wl
is a NULL token and one otherwise. The path
with the highest total score under summation is
the 1-best decoding output. The decoding weights
θ = {σ1,... , σN3, λ, ω} are tuned to optimize two
objective functions described next.
</bodyText>
<subsectionHeader confidence="0.998902">
3.1 Lattice Based BLEU Optimization
</subsectionHeader>
<bodyText confidence="0.999989379310345">
Powell’s method (Press et al., 2007) on N-best
lists was used in system combination weight tun-
ing in Rosti et al. (2007). This requires multiple
decoding iterations and merging the N-best lists
between tuning runs to approximate the full search
space as in Och (2003). To speed up the tuning
process, a distributed optimization method can be
used. The lattices are divided into multiple chunks
each of which are loaded into memory by a server.
A client runs the optimization algorithm relying
on the servers for parallelized objective function
evaluation. The client sends a new set of search
weights to the servers which decode the chunks
of lattices and return the 1-best hypothesis BLEU
statistics back to the client. The client accumulates
the BLEU statistics from all servers and computes
the final BLEU score used as the objective func-
tion by the optimization algorithm. Results similar
to Powell’s method can be obtained with fewer it-
erations by using the downhill simplex method in
multi-dimensions (Amoeba) (Press et al., 2007).
To enforce the sum to one constraint of the sys-
tem weights σn, the search weights are restricted
to [0, 1] by assigning a large penalty if any cor-
responding search weight breaches the limits and
these restricted search weights are scaled to sum
to one before the objective function evaluation.
After optimizing the bi-gram decoding weights
directly on the lattices, a 300-best list are gener-
</bodyText>
<equation confidence="0.996547333333333">
pn =
1 exp(−100 en )
Z Nn (1)
</equation>
<page confidence="0.995199">
323
</page>
<bodyText confidence="0.9998605">
ated. The 300-best hypotheses are re-scored using
a 5-gram LM and another set of re-scoring weights
are tuned on the development set using the stan-
dard N-best list based method. Multiple random
restarts may be used in both lattice and N-best list
based optimization to decrease chances of finding
a local minimum. Twenty sets of initial weights
(the weights from the previous tuning and 19 ran-
domly perturbed weights) were used in all experi-
ments.
</bodyText>
<subsectionHeader confidence="0.9820815">
3.2 Approximate Expected BLEU
Optimization
</subsectionHeader>
<bodyText confidence="0.999886142857143">
The gradient-free optimization algorithms like
Powell’s method and downhill simplex work well
for up to around 20-30 weights. When the number
of weights is larger, the algorithms often get stuck
in local optima even if multiple random restarts
are used. The BLEU score for a 1-best output is
defined as follows:
</bodyText>
<equation confidence="0.9932255">
1 4 Ei ri l
C1 − Ei h1i / (3)
</equation>
<bodyText confidence="0.98357728125">
where mni is the number of n-gram matches be-
tween the hypothesis and reference for segment
i, hni is the number of n-grams in the hypothesis,
ri is the reference length (or the reference length
closest to the hypothesis if multiple references are
available), and φ(x) = min(1.0, ex) is the brevity
penalty. The first term in Equation 3 is a harmonic
mean of the n-gram precisions up to n = 4. The
selection of 1-best hypotheses is discrete and the
brevity penalty is not continuous, so the BLEU
score is not differentiable and gradient based op-
timization cannot be used. Given a posterior dis-
tribution over all possible decoding outputs could
be defined, an expected BLEU could be optimized
using gradient ascent. However, this posterior dis-
tribution can only be approximated by expensive
sampling methods.
A differentiable objective function over N-best
lists to approximate the BLEU score can be de-
fined using expected BLEU statistics and a con-
tinuous approximation of the brevity penalty. The
posterior probability for hypothesis j of segment i
is simply the normalized decoder score:
where γ is a posterior scaling factor and Sij is the
total score of hypothesis j of segment i. The pos-
terior scaling factor controls the shape of the pos-
terior distribution: γ &gt; 1.0 moves the probability
mass toward the 1-best hypothesis and γ &lt; 1.0
flattens the distribution. The BLEU statistics in
Equation 3 are replaced by the expected statistics;
for example, mni = Ej pijmij, and the brevity
penalty φ(x) is approximated by:
</bodyText>
<equation confidence="0.9653935">
ex − 1
ϕ(x) = e1000x + 1 + 1 (5)
</equation>
<bodyText confidence="0.9998221">
ExpBLEU has a closed form solution for the gra-
dient, provided the total decoder score is differen-
tiable.
The penalty used to restrict the search weights
corresponding to the system weights σn in
gradient-free BLEU tuning is not differentiable.
For expected BLEU tuning, the search weights ςn
are unrestricted but the system weights are ob-
tained by a sigmoid transform and normalized to
sum to one:
</bodyText>
<equation confidence="0.999779">
σn = Em δ(ςm)
δ(ςn) (6)
</equation>
<bodyText confidence="0.99907465">
where δ(ςn) = 1/(1 + e−ςn).
The expected BLEU tuning is performed on N-
best lists in similar fashion to direct BLEU tuning.
Tuned weights from one decoding iteration are
used to generate a new N-best list, the new N-best
list is merged with the N-best list from the previ-
ous tuning run, and a new set of weights are op-
timized using limited memory Broyden-Fletcher-
Goldfarb-Shanno method (lBFGS) (Liu and No-
cedal, 1989). Since the posterior distribution is
affected by the size of the N-best list and differ-
ent decoding weights, the posterior scaling factor
can be set for each tuning run so that the perplex-
ity of the posterior distribution given the merged
N-best list is constant. A target perplexity of 5.0
was used in the experiments. Four iterations of
bi-gram decoding weight tuning were performed
using 300-best lists. The final 300-best list was re-
scored with a 5-gram and another set of re-scoring
weights was tuned on the development set.
</bodyText>
<sectionHeader confidence="0.996589" genericHeader="method">
4 Experimental Evaluation
</sectionHeader>
<bodyText confidence="0.999741">
System outputs for all language pairs with En-
glish as the target were combined. Unpruned En-
glish bi-gram and 5-gram language model com-
ponents were trained using the WMT10 corpora:
EuroParl, GigaFrEn, NewsCommentary,
and News. Additional six Gigaword v4 com-
ponents were trained: AFP, APW, XIN+CNA,
</bodyText>
<equation confidence="0.594342428571428">
BLEU = 4 Ei mni 1
H Ei hni J
n�1
E (4)
k eγSik
eγSij
pij =
</equation>
<page confidence="0.992169">
324
</page>
<table confidence="0.8359824">
tune cz-en de-en es-en fr-en
System TER BLEU TER BLEU TER BLEU TER BLEU
worst 68.99 13.85 68.45 15.07 60.86 21.02 71.17 15.00
best 56.77 22.84 57.76 25.05 51.81 30.10 53.66 28.64
syscomb 57.31 25.11 54.97 27.75 50.46 31.54 51.35 31.16
test cz-en de-en es-en fr-en
System TER BLEU TER BLEU TER BLEU TER BLEU
worst 68.65 14.29 67.50 15.66 60.52 21.86 68.36 16.82
best 56.13 23.56 58.12 24.34 51.45 30.56 52.16 29.79
syscomb 56.89 25.12 55.60 26.38 50.33 31.59 51.36 30.16
</table>
<tableCaption confidence="0.9239475">
Table 1: Case insensitive TER and BLEU scores on syscombtune (tune) and syscombtest (test)
for combinations of outputs from four source languages.
</tableCaption>
<bodyText confidence="0.999712722222222">
LTW, NYT, and Headlines+Datelines. In-
terpolation weights for the ten components
were tuned so as to minimize perplexity on
the newstest2009-ref.en development set.
The LMs used modified Kneser-Ney smoothing.
On the multi-source condition (xx-en) another
LM was trained from the system outputs and in-
terpolated with the general LM using an interpola-
tion weight 0.3 for the LM trained on the system
outputs. This LM is referred to as biasLM later.
A tri-gram true casing model was trained using all
available English data. This model was used to
restore the case of the lower-case system combi-
nation output.
All six 1-best system outputs on cz-en, 16
outputs on de-en, 8 outputs on es-en, and
14 outputs on fr-en were combined. The lat-
tice based BLEU tuning was used to optimize the
bi-gram decoding weights and N-best list based
BLEU tuning was used to optimize the 5-gram re-
scoring weights. Results for these single source
language experiments are shown in Table 1. The
gains on syscombtune were similar to those on
syscombtest for all but French-English. The
tuning set contained only 455 segments but ap-
peared to be well matched with the larger (2034
segments) test set. The characteristics of the indi-
vidual system outputs were probably different for
the tuning and test sets on French-English transla-
tion. In our experience, optimizing system com-
bination weights using the ExpBLEU tuning for
a small number of systems yields similar results
to lattice based BLEU tuning. The lattice based
BLEU tuning is faster as there is no need for mul-
tiple decoding and tuning iterations. Using the bi-
asLM on the single source combinations did not
</bodyText>
<table confidence="0.904602857142857">
xx-en tune test
System TER BLEU TER BLEU
worst 71.17 13.85 68.65 14.29
best 51.81 30.10 51.45 30.56
lattice 43.15 35.72 43.79 35.29
expBLEU 44.07 36.91 44.35 36.62
+biasLM 43.63 37.61 44.50 37.12
</table>
<tableCaption confidence="0.96839">
Table 2: Case insensitive TER and BLEU scores
</tableCaption>
<bodyText confidence="0.994103333333333">
on syscombtune (tune) and syscombtest
(test) for xx-en combination. Combinations us-
ing lattice BLEU tuning, expected BLEU tuning,
and after adding the system output biased LM are
shown.
yield any gains. The output for these conditions
probably did not contain enough data for biasLM
training given the small tuning set and small num-
ber of systems.
Finally, experiments combining all 44 1-best
system outputs were performed to produce a
multi-source combination output. The first experi-
ment used the lattice based BLEU tuning and gave
a 5.6 BLEU point gain on the tuning set as seen in
Table 2. The ExpBLEU tuning gave an additional
1.2 point gain which suggests that the direct lattice
based BLEU tuning got stuck in a local optimum.
Using the system output biased LM gave an addi-
tional 0.7 point gain. The gains on the test set were
similar and the best combination gave a 6.6 point
gain over the best individual system.
</bodyText>
<sectionHeader confidence="0.999688" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.998945333333333">
The BBN submissions for WMT10 system com-
bination task were described in this paper. The
combination was based on confusion network de-
</bodyText>
<page confidence="0.996917">
325
</page>
<bodyText confidence="0.999952368421053">
coding. The confusion networks were built us-
ing an incremental hypothesis alignment algo-
rithm with flexible matching. The bi-gram de-
coding weights for the single source conditions
were optimized directly to maximize the BLEU
scores of the 1-best decoding outputs and the 5-
gram re-scoring weights were tuned on 300-best
lists. The BLEU gains over the best individual
system outputs were around 1.5 points on cz-en,
2.0 points on de-en, 1.0 points on es-en, and
0.4 points on fr-en. The system combination
weights on xx-en were tuned to maximize Exp-
BLEU, and a system output biased LM was used.
The BLEU gain over the best individual system
was 6.6 points. Future work will investigate tuning
of the edit costs used in the alignment. A lattice
based ExpBLEU tuning will be investigated. Also,
weights for more complicated functions with addi-
tional features may be tuned using ExpBLEU.
</bodyText>
<sectionHeader confidence="0.999506" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999576">
This work was supported by DARPA/IPTO Con-
tract No. HR0011-06-C-0022 under the GALE
program.
</bodyText>
<sectionHeader confidence="0.999451" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999804037735849">
Christiane Fellbaum, editor. 1998. WordNet: An Elec-
tronic Lexical Database. MIT Press.
Dong C. Liu and Jorge Nocedal. 1989. On the limited
memory method for large scale optimization. Math-
ematical Programming, 45(3):503–528.
Franz J. Och. 2003. Minimum error rate training in
statistical machine translation. In Proceedings of the
41st Annual Meeting of the Association for Compu-
tational Linguistics, pages 160–167.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. BLEU: a method for automatic
evaluation of machine translation. In Proceedings
of the 40th Annual Meeting of the Association for
Computational Linguistics, pages 311–318.
Adam Pauls, John DeNero, and DanKlein. 2009. Con-
sensus training for consensus decoding in machine
translation. In Proceedings of the 2009 Conference
on Empirical Methods in Natural Language Pro-
cessing, pages 1418–1427.
William H. Press, Saul A. Teukolsky, William T. Vet-
terling, and Brian P. Flannery. 2007. Numerical
recipes: the art of scientific computing. Cambridge
University Press, 3rd edition.
Antti-Veikko I. Rosti, Spyros Matsoukas, and Richard
Schwartz. 2007. Improved word-level system com-
bination for machine translation. In Proceedings of
the 45th Annual Meeting of the Association of Com-
putational Linguistics, pages 312–319.
Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas,
and Richard Schwartz. 2009. Incremental hy-
pothesis alignment with flexible matching for build-
ing confusion networks: BBN system description
for WMT09 system combination task. In Proceed-
ings of the Fourth Workshop on Statistical Machine
Translation, pages 61–65.
Matthew Snover, Bonnie Dorr, Richard Schwartz, Lin-
nea Micciula, and John Makhoul. 2006. A study of
translation edit rate with targeted human annotation.
In Proceedings of the 7th Conference of the Associa-
tion for Machine Translation in the Americas, pages
223–231.
Matthew Snover, Nitin Madnani, Bonnie Dorr, and
Richard Schwartz. 2009. Fluency, adequacy, or
HTER? exploring different human judgments with
a tunable MT metric. In Proceedings of the Fourth
Workshop on Statistical Machine Translation, pages
259–268.
Roy W. Tromble, Shankar Kumar, Franz Och, and
Wolfgang Macherey. 2008. Lattice minimum
bayes-risk decoding for statistical machine transla-
tion. In Proceedings of the 2008 Conference on Em-
pirical Methods in Natural Language Processing,
pages 620–629.
</reference>
<page confidence="0.999104">
326
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.412877">
<title confidence="0.995711">BBN System Description for WMT10 System Combination Task</title>
<author confidence="0.694152">I Rosti Zhang Matsoukas Raytheon BBN Technologies</author>
<author confidence="0.694152">Moulton Street</author>
<author confidence="0.694152">MA Cambridge</author>
<abstract confidence="0.996104181818182">BBN submitted system combination outputs for Czech-English, German-English, Spanish-English, French-English, and All- English language pairs. All combinations were based on confusion network decoding. An incremental hypothesis alignment algorithm with flexible matching was used to build the networks. The bi-gram decoding weights for the single source language translations were tuned directly to maximize the BLEU score of the decoding output. Approximate expected BLEU was used as the objective function in gradient based optimization of the combination weights for a 44 system multi-source language combination (All-English). The system combination gained around 0.4- 2.0 BLEU points over the best individual systems on the single source conditions. On the multi-source condition, the system combination gained 6.6 BLEU points.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>WordNet: An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet: An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dong C Liu</author>
<author>Jorge Nocedal</author>
</authors>
<title>On the limited memory method for large scale optimization.</title>
<date>1989</date>
<booktitle>Mathematical Programming,</booktitle>
<volume>45</volume>
<issue>3</issue>
<contexts>
<context position="15366" citStr="Liu and Nocedal, 1989" startWordPosition="2534" endWordPosition="2538">ning is not differentiable. For expected BLEU tuning, the search weights ςn are unrestricted but the system weights are obtained by a sigmoid transform and normalized to sum to one: σn = Em δ(ςm) δ(ςn) (6) where δ(ςn) = 1/(1 + e−ςn). The expected BLEU tuning is performed on Nbest lists in similar fashion to direct BLEU tuning. Tuned weights from one decoding iteration are used to generate a new N-best list, the new N-best list is merged with the N-best list from the previous tuning run, and a new set of weights are optimized using limited memory Broyden-FletcherGoldfarb-Shanno method (lBFGS) (Liu and Nocedal, 1989). Since the posterior distribution is affected by the size of the N-best list and different decoding weights, the posterior scaling factor can be set for each tuning run so that the perplexity of the posterior distribution given the merged N-best list is constant. A target perplexity of 5.0 was used in the experiments. Four iterations of bi-gram decoding weight tuning were performed using 300-best lists. The final 300-best list was rescored with a 5-gram and another set of re-scoring weights was tuned on the development set. 4 Experimental Evaluation System outputs for all language pairs with </context>
</contexts>
<marker>Liu, Nocedal, 1989</marker>
<rawString>Dong C. Liu and Jorge Nocedal. 1989. On the limited memory method for large scale optimization. Mathematical Programming, 45(3):503–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<contexts>
<context position="2623" citStr="Och, 2003" startWordPosition="403" endWordPosition="404">dient of the objective function. Due to the size of the lattices, the objective function evaluation may have to be distributed to multiple servers. The optimizer client accumulates the BLEU statistics of the 1-best hypotheses from the servers for given search weights, computes the final BLEU score, and passes it to the optimization algorithm which returns a new set of search weights. The lattice based tuning explores the entire search space and does not require multiple decoding iterations with N-best list merging to approximate the search space as in the standard minimum error rate training (Och, 2003). This allows much faster turnaround in weight tuning. Differentiable approximations of BLEU have been proposed for consensus decoding. Tromble et al. (2008) used a linear approximation and Pauls et al. (2009) used a closer approximation called CoBLEU. CoBLEU is based on the BLEU formula but the n-gram counts are replaced by expected counts over a translation forest. Due to the min-functions required in converting the n-gram counts to matches and a non-differentiable brevity penalty, a sub-gradient ascent must be used. In this work, an approximate expected BLEU (ExpBLEU) defined over N-best li</context>
<context position="10947" citStr="Och (2003)" startWordPosition="1782" endWordPosition="1783">ing the arc l, ω is the word insertion scaling factor, and S(wl) is zero if wl is a NULL token and one otherwise. The path with the highest total score under summation is the 1-best decoding output. The decoding weights θ = {σ1,... , σN3, λ, ω} are tuned to optimize two objective functions described next. 3.1 Lattice Based BLEU Optimization Powell’s method (Press et al., 2007) on N-best lists was used in system combination weight tuning in Rosti et al. (2007). This requires multiple decoding iterations and merging the N-best lists between tuning runs to approximate the full search space as in Och (2003). To speed up the tuning process, a distributed optimization method can be used. The lattices are divided into multiple chunks each of which are loaded into memory by a server. A client runs the optimization algorithm relying on the servers for parallelized objective function evaluation. The client sends a new set of search weights to the servers which decode the chunks of lattices and return the 1-best hypothesis BLEU statistics back to the client. The client accumulates the BLEU statistics from all servers and computes the final BLEU score used as the objective function by the optimization a</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz J. Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 160–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>311--318</pages>
<contexts>
<context position="1508" citStr="Papineni et al., 2002" startWordPosition="215" endWordPosition="218">The system combination gained around 0.4- 2.0 BLEU points over the best individual systems on the single source conditions. On the multi-source condition, the system combination gained 6.6 BLEU points. 1 Introduction The BBN submissions to the WMT10 system combination task were based on confusion network decoding. The confusion networks were built using the incremental hypothesis alignment algorithm with flexible matching introduced in the BBN submission for the WMT09 system combination task (Rosti et al., 2009). This year, the system combination weights were tuned to maximize the BLEU score (Papineni et al., 2002) of the 1-best decoding output (lattice based BLEU tuning) using downhill simplex method (Press et al., 2007). A 44 system multi-source combination was also submitted. Since the gradient-free optimization algorithms do not seem to be able to handle more than 20-30 weights, a gradient ascent to maximize an approximate expected BLEU objective was used to optimize the larger number of weights. The lattice based BLEU tuning may be implemented using any optimization algorithm that does not require the gradient of the objective function. Due to the size of the lattices, the objective function evalua</context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. BLEU: a method for automatic evaluation of machine translation. In Proceedings of the 40th Annual Meeting of the Association for Computational Linguistics, pages 311–318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Pauls</author>
<author>John DeNero</author>
<author>DanKlein</author>
</authors>
<title>Consensus training for consensus decoding in machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1418--1427</pages>
<contexts>
<context position="2832" citStr="Pauls et al. (2009)" startWordPosition="432" endWordPosition="435"> of the 1-best hypotheses from the servers for given search weights, computes the final BLEU score, and passes it to the optimization algorithm which returns a new set of search weights. The lattice based tuning explores the entire search space and does not require multiple decoding iterations with N-best list merging to approximate the search space as in the standard minimum error rate training (Och, 2003). This allows much faster turnaround in weight tuning. Differentiable approximations of BLEU have been proposed for consensus decoding. Tromble et al. (2008) used a linear approximation and Pauls et al. (2009) used a closer approximation called CoBLEU. CoBLEU is based on the BLEU formula but the n-gram counts are replaced by expected counts over a translation forest. Due to the min-functions required in converting the n-gram counts to matches and a non-differentiable brevity penalty, a sub-gradient ascent must be used. In this work, an approximate expected BLEU (ExpBLEU) defined over N-best lists was used as a differentiable objective function. ExpBLEU uses expected BLEU statistics where the min-function is not needed as the statistics are computed offline and the brevity penalty is replaced by a d</context>
</contexts>
<marker>Pauls, DeNero, DanKlein, 2009</marker>
<rawString>Adam Pauls, John DeNero, and DanKlein. 2009. Consensus training for consensus decoding in machine translation. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1418–1427.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William H Press</author>
<author>Saul A Teukolsky</author>
<author>William T Vetterling</author>
<author>Brian P Flannery</author>
</authors>
<title>Numerical recipes: the art of scientific computing.</title>
<date>2007</date>
<publisher>Cambridge University Press,</publisher>
<note>3rd edition.</note>
<contexts>
<context position="1617" citStr="Press et al., 2007" startWordPosition="232" endWordPosition="235">conditions. On the multi-source condition, the system combination gained 6.6 BLEU points. 1 Introduction The BBN submissions to the WMT10 system combination task were based on confusion network decoding. The confusion networks were built using the incremental hypothesis alignment algorithm with flexible matching introduced in the BBN submission for the WMT09 system combination task (Rosti et al., 2009). This year, the system combination weights were tuned to maximize the BLEU score (Papineni et al., 2002) of the 1-best decoding output (lattice based BLEU tuning) using downhill simplex method (Press et al., 2007). A 44 system multi-source combination was also submitted. Since the gradient-free optimization algorithms do not seem to be able to handle more than 20-30 weights, a gradient ascent to maximize an approximate expected BLEU objective was used to optimize the larger number of weights. The lattice based BLEU tuning may be implemented using any optimization algorithm that does not require the gradient of the objective function. Due to the size of the lattices, the objective function evaluation may have to be distributed to multiple servers. The optimizer client accumulates the BLEU statistics of </context>
<context position="10716" citStr="Press et al., 2007" startWordPosition="1741" endWordPosition="1744"> weights constrained to sum to one, snl are the system specific arc posteriors, λ is a language model (LM) scaling factor, L(wl|wP(l)) is the bi-gram log-probability for the token wl on the arc l given the token wP(l) on the arc P(l) preceding the arc l, ω is the word insertion scaling factor, and S(wl) is zero if wl is a NULL token and one otherwise. The path with the highest total score under summation is the 1-best decoding output. The decoding weights θ = {σ1,... , σN3, λ, ω} are tuned to optimize two objective functions described next. 3.1 Lattice Based BLEU Optimization Powell’s method (Press et al., 2007) on N-best lists was used in system combination weight tuning in Rosti et al. (2007). This requires multiple decoding iterations and merging the N-best lists between tuning runs to approximate the full search space as in Och (2003). To speed up the tuning process, a distributed optimization method can be used. The lattices are divided into multiple chunks each of which are loaded into memory by a server. A client runs the optimization algorithm relying on the servers for parallelized objective function evaluation. The client sends a new set of search weights to the servers which decode the chu</context>
</contexts>
<marker>Press, Teukolsky, Vetterling, Flannery, 2007</marker>
<rawString>William H. Press, Saul A. Teukolsky, William T. Vetterling, and Brian P. Flannery. 2007. Numerical recipes: the art of scientific computing. Cambridge University Press, 3rd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Improved word-level system combination for machine translation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>312--319</pages>
<contexts>
<context position="8454" citStr="Rosti et al., 2007" startWordPosition="1327" endWordPosition="1330">LL(1,0) mat(1,1) 4 cat(1,1,0) 0 1 NULL(0,0,1) sat(1,1,1) on(0,1,0) 2 3 NULL(1,0,1) mat(1,1,1) 4 cat(1,1,0,1) 0 1 NULL(0,0,1,0) sat(1,1,1,1) on(0,1,0,0) 2 3 NULL(1,0,1,1) mat(1,1,1,0) hat(0,0,0,1) 4 322 ‘NULL’ token between nodes 2 and 3 as seen in Figure 1(c). The fourth hypothesis matches all but the final token ‘hat’ which becomes a substitution for ‘mat’ in Figure 1(d). The binary vectors in the parentheses following each token show which system generated the token aligned to that arc. If the systems generated N-best hypotheses, a fractional increment could be added to these vectors as in (Rosti et al., 2007). Given these system specific scores are normalized to sum to one over all arcs connecting two consecutive nodes, they may be viewed as system specific word arc posterior estimates. Note, for 1-best hypotheses the scores sum to one without normalization. Given system outputs £ = {E1, ... , EN3}, an algorithm to build a set of Ns confusion networks C = {C1, ... , CN3} may be written as: for n = 1 to Ns do Cn &lt;-- Init(En) {initialize confusion network from the skeleton} £&apos; &lt;-- £ − En {set of unaligned hypotheses} while £&apos; =� 0 do Em &lt;-- argminEE£, Dist(E, Cn) {compute edit distances} Cn &lt;-- Alig</context>
<context position="10800" citStr="Rosti et al. (2007)" startWordPosition="1757" endWordPosition="1760"> a language model (LM) scaling factor, L(wl|wP(l)) is the bi-gram log-probability for the token wl on the arc l given the token wP(l) on the arc P(l) preceding the arc l, ω is the word insertion scaling factor, and S(wl) is zero if wl is a NULL token and one otherwise. The path with the highest total score under summation is the 1-best decoding output. The decoding weights θ = {σ1,... , σN3, λ, ω} are tuned to optimize two objective functions described next. 3.1 Lattice Based BLEU Optimization Powell’s method (Press et al., 2007) on N-best lists was used in system combination weight tuning in Rosti et al. (2007). This requires multiple decoding iterations and merging the N-best lists between tuning runs to approximate the full search space as in Och (2003). To speed up the tuning process, a distributed optimization method can be used. The lattices are divided into multiple chunks each of which are loaded into memory by a server. A client runs the optimization algorithm relying on the servers for parallelized objective function evaluation. The client sends a new set of search weights to the servers which decode the chunks of lattices and return the 1-best hypothesis BLEU statistics back to the client.</context>
</contexts>
<marker>Rosti, Matsoukas, Schwartz, 2007</marker>
<rawString>Antti-Veikko I. Rosti, Spyros Matsoukas, and Richard Schwartz. 2007. Improved word-level system combination for machine translation. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 312–319.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antti-Veikko I Rosti</author>
<author>Bing Zhang</author>
<author>Spyros Matsoukas</author>
<author>Richard Schwartz</author>
</authors>
<title>Incremental hypothesis alignment with flexible matching for building confusion networks: BBN system description for WMT09 system combination task.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>61--65</pages>
<contexts>
<context position="1403" citStr="Rosti et al., 2009" startWordPosition="197" endWordPosition="200">imization of the combination weights for a 44 system multi-source language combination (All-English). The system combination gained around 0.4- 2.0 BLEU points over the best individual systems on the single source conditions. On the multi-source condition, the system combination gained 6.6 BLEU points. 1 Introduction The BBN submissions to the WMT10 system combination task were based on confusion network decoding. The confusion networks were built using the incremental hypothesis alignment algorithm with flexible matching introduced in the BBN submission for the WMT09 system combination task (Rosti et al., 2009). This year, the system combination weights were tuned to maximize the BLEU score (Papineni et al., 2002) of the 1-best decoding output (lattice based BLEU tuning) using downhill simplex method (Press et al., 2007). A 44 system multi-source combination was also submitted. Since the gradient-free optimization algorithms do not seem to be able to handle more than 20-30 weights, a gradient ascent to maximize an approximate expected BLEU objective was used to optimize the larger number of weights. The lattice based BLEU tuning may be implemented using any optimization algorithm that does not requi</context>
<context position="4591" citStr="Rosti et al. (2009)" startWordPosition="705" endWordPosition="708"> follows. Section 2 reviews the incremental hypothesis alignment algorithm used to built the confusion networks. Decoding weight optimization using direct lattice 1-best BLEU tuning and N-best list based ExpBLEU tuning are presented in Section 3. Experimental results on combining single source language to English outputs and all 44 English outputs are detailed in Section 4. Finally, Section 5 concludes this paper with some ideas for future work. 2 Hypothesis Alignment The confusion networks were built by using the incremental hypothesis alignment algorithm with flexible matching introduced in Rosti et al. (2009). The algorithm is reviewed in more detail here. It is loosely related to the alignment performed in the calculation of the translation edit rate (TER) (Snover et al., 2006) which estimates the edit distance between two strings allowing shifts of blocks of words in addition to insertions, deletions, and substitutions. Calculating an exact TER for strings longer than a few tokens1 is not computationally feasible, so the tercom2 software uses heuristic shift constraints and pruning to find an upper bound of TER. In this work, the hypotheses were aligned incrementally with the confusion network, </context>
</contexts>
<marker>Rosti, Zhang, Matsoukas, Schwartz, 2009</marker>
<rawString>Antti-Veikko I. Rosti, Bing Zhang, Spyros Matsoukas, and Richard Schwartz. 2009. Incremental hypothesis alignment with flexible matching for building confusion networks: BBN system description for WMT09 system combination task. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 61–65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
<author>Linnea Micciula</author>
<author>John Makhoul</author>
</authors>
<title>A study of translation edit rate with targeted human annotation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas,</booktitle>
<pages>223--231</pages>
<contexts>
<context position="4764" citStr="Snover et al., 2006" startWordPosition="734" endWordPosition="737">EU tuning and N-best list based ExpBLEU tuning are presented in Section 3. Experimental results on combining single source language to English outputs and all 44 English outputs are detailed in Section 4. Finally, Section 5 concludes this paper with some ideas for future work. 2 Hypothesis Alignment The confusion networks were built by using the incremental hypothesis alignment algorithm with flexible matching introduced in Rosti et al. (2009). The algorithm is reviewed in more detail here. It is loosely related to the alignment performed in the calculation of the translation edit rate (TER) (Snover et al., 2006) which estimates the edit distance between two strings allowing shifts of blocks of words in addition to insertions, deletions, and substitutions. Calculating an exact TER for strings longer than a few tokens1 is not computationally feasible, so the tercom2 software uses heuristic shift constraints and pruning to find an upper bound of TER. In this work, the hypotheses were aligned incrementally with the confusion network, thus using tokens from all previously aligned hypotheses in computing the edit distance. Lower substitution costs were assigned to tokens considered equivalent and the heuri</context>
</contexts>
<marker>Snover, Dorr, Schwartz, Micciula, Makhoul, 2006</marker>
<rawString>Matthew Snover, Bonnie Dorr, Richard Schwartz, Linnea Micciula, and John Makhoul. 2006. A study of translation edit rate with targeted human annotation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas, pages 223–231.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Snover</author>
<author>Nitin Madnani</author>
<author>Bonnie Dorr</author>
<author>Richard Schwartz</author>
</authors>
<title>Fluency, adequacy, or HTER? exploring different human judgments with a tunable MT metric.</title>
<date>2009</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Machine Translation,</booktitle>
<pages>259--268</pages>
<contexts>
<context position="6235" citStr="Snover et al., 2009" startWordPosition="963" endWordPosition="966"> the confusion network skeleton which defines the final word order of the decoding output. Second, a trivial confusion network is generated from the skeleton hypothesis by generating a single arc for each token. The alignment algorithm explores shifts of blocks of words that minimize the edit distance between the current confusion network and an unaligned hypothe1Hypotheses are tokenized and lower-cased prior to alignment. Tokens generally refer to words and punctuation. 2http://www.cs.umd.edu/˜snover/tercom/ current version 0.7.25. 3This algorithm is not equivalent to an incremental TERPlus (Snover et al., 2009) due to different shift constraints and the lack of paraphrase matching (a) Skeleton hypothesis. (b) Two hypotheses (insertion). (c) Three hypotheses (deletion). (d) Four hypotheses (substitution). Figure 1: Example of incrementally aligning “cat sat mat”, “cat sat on mat”, “sat mat”, and “cat sat hat”. sis. Third, the hypothesis with the lowest edit distance to the current confusion network is aligned into the network. The heuristically selected edit costs used in the WMT10 system were 1.0 for insertions, deletions, and shifts, 0.2 for substitutions of tokens in the same equivalence class, an</context>
</contexts>
<marker>Snover, Madnani, Dorr, Schwartz, 2009</marker>
<rawString>Matthew Snover, Nitin Madnani, Bonnie Dorr, and Richard Schwartz. 2009. Fluency, adequacy, or HTER? exploring different human judgments with a tunable MT metric. In Proceedings of the Fourth Workshop on Statistical Machine Translation, pages 259–268.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roy W Tromble</author>
<author>Shankar Kumar</author>
<author>Franz Och</author>
<author>Wolfgang Macherey</author>
</authors>
<title>Lattice minimum bayes-risk decoding for statistical machine translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>620--629</pages>
<contexts>
<context position="2780" citStr="Tromble et al. (2008)" startWordPosition="423" endWordPosition="426">. The optimizer client accumulates the BLEU statistics of the 1-best hypotheses from the servers for given search weights, computes the final BLEU score, and passes it to the optimization algorithm which returns a new set of search weights. The lattice based tuning explores the entire search space and does not require multiple decoding iterations with N-best list merging to approximate the search space as in the standard minimum error rate training (Och, 2003). This allows much faster turnaround in weight tuning. Differentiable approximations of BLEU have been proposed for consensus decoding. Tromble et al. (2008) used a linear approximation and Pauls et al. (2009) used a closer approximation called CoBLEU. CoBLEU is based on the BLEU formula but the n-gram counts are replaced by expected counts over a translation forest. Due to the min-functions required in converting the n-gram counts to matches and a non-differentiable brevity penalty, a sub-gradient ascent must be used. In this work, an approximate expected BLEU (ExpBLEU) defined over N-best lists was used as a differentiable objective function. ExpBLEU uses expected BLEU statistics where the min-function is not needed as the statistics are compute</context>
</contexts>
<marker>Tromble, Kumar, Och, Macherey, 2008</marker>
<rawString>Roy W. Tromble, Shankar Kumar, Franz Och, and Wolfgang Macherey. 2008. Lattice minimum bayes-risk decoding for statistical machine translation. In Proceedings of the 2008 Conference on Empirical Methods in Natural Language Processing, pages 620–629.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>