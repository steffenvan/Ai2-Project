<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000082">
<title confidence="0.76855">
Understanding Information Graphics: A Discourse-Level Problem *
</title>
<author confidence="0.93527">
*Sandra Carberry, *Stephanie Elzer, **Nancy Green, *Kathleen McCoy, and *Daniel Chester
</author>
<affiliation confidence="0.939875">
*Dept. of Computer Science, University of Delaware, Newark, DE 19716
</affiliation>
<email confidence="0.596185">
(carberry, elzer, mccoy, chester@cis.udel.edu)
</email>
<affiliation confidence="0.765875">
**Dept. of Math. Sciences, Univ. of North Carolina at Greensboro, Greensboro, NC 27402
</affiliation>
<email confidence="0.995644">
(nlgreen@uncg.edu)
</email>
<sectionHeader confidence="0.998972" genericHeader="abstract">
Abstract
</sectionHeader>
<keyword confidence="0.9088335">
Keywords: graphics, understanding, dis-
course, plan-based models
</keyword>
<bodyText confidence="0.999655380952381">
Information graphics that appear in newspa-
pers and magazines generally have a message that
the viewer is intended to recognize. This paper ar-
gues that understanding such information graph-
ics is a discourse-level problem. In particular,
it requires assimilating information from multi-
ple knowledge sources to recognize the intended
message of the graphic, just as recognizing in-
tention in text does. Moreover, when an article
is composed of text and graphics, the intended
message of the information graphic (its discourse
intention) must be integrated into the discourse
structure of the surrounding text and contributes
to the overall discourse intention of the article.
This paper describes how we extend plan-based
techniques that have been used for understanding
traditional discourse to the understanding of in-
formation graphics. This work is part of a project
to develop an interactive natural language system
that provides sight-impaired users with access to
information graphics.
</bodyText>
<sectionHeader confidence="0.999164" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999673111111111">
Information graphics (non-pictorial graphics
such as bar charts and line graphs) are a variant of
language with many similarities to other forms of
communication. Information graphics are preva-
lent in information resources since they enable
complex information to be assimilated perceptu-
ally with ease. Unfortunately, knowledge sources
such as information graphics are not accessible to
some users. For example, individuals with im-
</bodyText>
<footnote confidence="0.6457015">
0The work of the third author was supported by the Na-
tional Science Foundation under Grant No. 0132821.
</footnote>
<bodyText confidence="0.998802388888889">
paired eyesight have limited access to information
graphics, thus preventing them from fully utiliz-
ing information resources.
Some information graphics are only intended
to display data values; (Yu et al., 2002) devel-
oped a pattern recognition algorithm for summa-
rizing interesting features of automatically gener-
ated graphics of time-series data from a gas tur-
bine engine. However, the overwhelming major-
ity of the graphics that we have examined (taken
from newspaper, magazine, and web articles) ap-
pear to have some underlying goal, such as get-
ting the viewer to believe that interest rates have
fallen substantially and that this would therefore
be a good time to refinance a mortgage. We
have found that understanding information graph-
ics is a discourse-level problem. In particular,
it requires assimilating information from multi-
ple knowledge sources to recognize the intended
message of the graphic, just as recognizing inten-
tion in text does. Moreover, the communicative
intention of the information graphic must be in-
tegrated into the discourse intentions of the sur-
rounding text.
We are developing an interactive natural lan-
guage system that infers the intended message
underlying an information graphic, augments it
with related interesting features of the graphic,
provides an initial summary of the graphic, and
then responds to followup questions from the
user. This paper presents the system architecture,
shows why interpreting information graphics is
a discourse-level problem, and outlines how we
extend techniques that have been used for under-
standing traditional discourse to the understand-
ing of information graphics.
</bodyText>
<sectionHeader confidence="0.84279" genericHeader="method">
2 A Natural Language Modality
</sectionHeader>
<bodyText confidence="0.9999928">
Information is the key to knowledge and ef-
fective decision-making. But information is use-
ful only if it is accessible in a form that can be
easily assimilated. For sighted users, information
graphics capture complex information and enable
it to be assimilated perceptually with ease. For
individuals who have serious sight-impairments,
documents that contain information graphics pose
challenging problems. Although devices have
been developed for conveying information graph-
ics in alternative mediums such as musical tones
or tactile images, these approaches have serious
limitations. For example, systems that attempt to
convey graphics via a soundscape(Meijer, 1992)
do not facilitate easy comparison of two line
graphs linked in a single graphical display. More-
over, these approaches require the user to con-
struct a “mental map” of the graphic, which is
difficult for congenitally blind users who do not
have the personal knowledge to assist them in the
interpretation of the image(Kennel, 1996). The
underlying hypothesis of our work is that alterna-
tive access to what the graphic looks like is not
enough — the user should be provided with the
message and knowledge that one would gain from
viewing the graphic in order to enable effective
and efficient use of this information resource. To
accomplish this objective, we are developing an
interactive natural language system for communi-
cating the content of an information graphic. Our
methodology offers promise as a means of provid-
ing access to information graphics without expen-
sive equipment, with few limitations on the com-
plexity of the graphic that can be handled, and
with relatively little cognitive load on the user.
</bodyText>
<sectionHeader confidence="0.981703" genericHeader="method">
3 Architecture and Overview
</sectionHeader>
<bodyText confidence="0.999993822222223">
Our current work is concerned with bar charts,
line graphs, and pie charts, although eventually
we will handle other kinds of graphics. Figure 1
shows the architecture of our system for convey-
ing information graphics. The visual extraction
component (VEC) analyzes the graphic and pro-
vides an XML representation of the graphic to
the intention recognition component (IRC). The
IRC is responsible for recognizing the intended
message of the information graphic and sending it
to the content planning component (CPC), which
will augment the intended message of the graphic
with related interesting features. The message or-
ganization component (MOC) then organizes the
most salient propositions into a coherent sum-
mary, which will be rendered in natural language
and conveyed to the user via speech synthesis.
The followup question component (FQC) will al-
low the user to interactively seek additional infor-
mation about the graphic.
Our work thus far (Section 4) has focused on
understanding an information graphic so that its
intended message can be conveyed to the user.
Section 4.1 discusses the extension of speech act
theory to the generation and understanding of in-
formation graphics. Section 4.2 argues that un-
derstanding information graphics is a discourse-
level problem in which the system must recog-
nize the intended message of the graphic and in-
tegrate it into the intentions of any surrounding
text; it further argues that understanding informa-
tion graphics requires similar kinds of knowledge
and processing as does the understanding of tra-
ditional textual discourse. Section 4.3 provides
a brief overview of the visual extraction compo-
nent that analyzes the graphical image and con-
structs an XML representation of the graphic for
use by the graphic understanding system. Sec-
tion 4.4 then describes how we have extended
techniques used for understanding traditional dis-
course and dialogue to the understanding of infor-
mation graphics. Section 5 gives a brief overview
of future work on the rest of the system. The Ap-
pendix contains information graphics that are part
of the corpus on which our work is based.
</bodyText>
<sectionHeader confidence="0.950874" genericHeader="method">
4 Understanding Information Graphics
</sectionHeader>
<subsectionHeader confidence="0.986275">
4.1 Intention in Information Graphics
</subsectionHeader>
<bodyText confidence="0.9934373">
Information graphics are a variant of language.
As noted by Clark(Clark, 1996), language is more
than just words. It is any “signal” (or lack of sig-
nal when one is expected), where a signal is a de-
liberate action that is intended to convey a mes-
sage. According to speech act theory, a speaker
or writer executes a speech act whose intended
meaning he expects the listener or reader to be
able to deduce(Searle, 1970; Grice, 1969; Clark,
1996). In their work on multimedia generation,
</bodyText>
<figureCaption confidence="0.999532">
Figure 1: System Architecture
</figureCaption>
<bodyText confidence="0.999973098360656">
the AutoBrief group proposed that speech act the-
ory could be extended to cover the generation
of graphical representations(Kerpedjiev and Roth,
2000). They developed a multimedia presenta-
tion system that generated text and information
graphics. It included 1) an algorithm that could
map communicative goals to a set of perceptual
and cognitive tasks that must be enabled for a
viewer to recognize the goals and 2) an automatic
graph designer that used constraint satisfaction to
construct an information graphic that best facili-
tated those tasks, subject to competing constraints
among the tasks.
The overwhelming majority of information
graphics accompanying newspaper and magazine
articles appear to carry a message that the de-
signer intends to convey to the viewer by virtue
of the graphic’s design and the data presented in
the graphic. Consider the graphic in Figure 9. It
conveys the message that the salary of women
in science, mathematics, and engineering fields
is consistently less than that of men in the same
fields. Other messages could have been con-
veyed by a different graphic design. For ex-
ample, by grouping the bars for men together,
grouping the bars for women together, and or-
dering the bars for each group by height, the
graphic would have conveyed the message that
both men and women earn the least in the so-
cial sciences and the most in engineering. Or
if the bars for Computer/Mathematical Sciences
were highlighted in Figure 9 by coloring them
significantly differently from the other bars in the
graphic, the graphic would have invoked a com-
parison of the discrepancies between male and
female salaries in Computer/Mathematical Sci-
ences and the salary discrepancies between men
and women in other fields. Although a graphic’s
caption can be helpful in identifying its intended
message (as in Figure 8), Corio performed a large
corpus study(Corio and Lapalme, 1999) in which
he found that captions are often missing or fail
to provide any indication of what the information
graphic conveys (as in Figures 6 and 10). Thus
we cannot rely entirely on the presence of useful
captions to identify the intended message of an
information graphic.
Language research has posited that the listener
or reader who is interpreting a speech act identi-
fies its intended meaning by reasoning about the
observed signals and the mutual beliefs of author
and interpreter(Grice, 1969; Clark, 1996). Ap-
plying this to graphical displays, it is reasonable
to presume that the author of a graphic similarly
expects the viewer to use perceptual skills along
with other knowledge sources to deduce from the
graphic the message that he intended to convey.
Thus we are applying speech act theory in the re-
verse direction of the AutoBrief project, namely
to the recognition of the intended message under-
lying an information graphic.
</bodyText>
<subsectionHeader confidence="0.983676">
4.2 A Discourse Level Problem
</subsectionHeader>
<bodyText confidence="0.999929800000001">
This section argues that interpreting informa-
tion graphics is a discourse-level problem — not
only is it necessary to recognize the intention of
the graphic as noted in Section 4.1, but under-
standing an information graphic requires similar
kinds of knowledge and processing as does un-
derstanding traditional discourse.
Grosz and Sidner contended that discourse
has a structure comprised of discourse segments.
Each discourse segment has a discourse seg-
ment purpose that contributes to the discourse
purpose or intention underlying the overall dis-
course(Grosz and Sidner, 1986). When an arti-
cle is comprised of text and graphics, the graphic
generally expands on the text and contributes to
the discourse purpose of the article. Consider the
graphic and partial surrounding text reproduced
in Figure 6. Nowhere in the text is it stated that
the income of black women has risen dramati-
cally over the last decade and has reached the
level of white women. Yet this message is clearly
conveyed by the graphic and contributes to the
overall communicative intention of this portion
of the article — namely, that there has been a
“monumental shifting of the sands” with regard
to the achievements of black women. Not only
does the intended message of the graphic (its dis-
course segment purpose) contribute to this overall
intention, but in fact the discourse intention of the
graphic helps to recognize the overall intention.
Even when the graphic stands in isolation as
in Figures 7 and 8, understanding the graphic
is a discourse-level problem. Grosz and Sid-
ner(Grosz and Sidner, 1986) claim that a robust
model of discourse understanding must use mul-
tiple knowledge sources in order to recognize the
complex relationships that utterances have to one
another. Information graphics have similar com-
plex relationships among their component ele-
ments. Not only might the graphic include mul-
tiple elements that must be related to one another
(such as multiple lines in a line graph, or individ-
ual bars in a bar chart), but information graphics
often include highlighting of certain elements to
make them particularly salient (as in Figure 10)
or include captions that might contribute to rec-
ognizing the graphic’s intention. The graphic in
Figure 8 includes such a helpful caption, although
many graphics, such as the ones in Figures 7
and 9, do not.
Furthermore, identifying the intended message
of a composite graphic (one comprised of multi-
ple individual graphics) requires relating the in-
dividual graphics to one another to identify the
intended message of the composite. Figure 11 il-
lustrates a composite information graphic. The
discourse purpose of the composite graphic is that
audits of affluent taxpayers are declining with re-
spect to audits of all taxpayers. This message can
only be deduced by relating the two individual
graphics and their underlying messages.
Moreover, understanding information graphics
requires the use of multiple knowledge sources.
In earlier work on recognizing expressions of
doubt, we developed an algorithm that combined
linguistic, contextual, and world knowledge and
applied it to the recognition of complex discourse
acts(Carberry and Lambert, 1999). In the case
of information graphics, the corollary to linguis-
tic knowledge is perceptual knowledge, by which
one recognizes the individual elements of the
graphic (for example, the bars in a bar chart), the
relation of the individual elements in the graphic
to one another, the type of graphic (line graph,
bar chart, pie chart, etc.), and what the different
graphic types can be used to convey. For exam-
ple, both a scatter plot and a pie chart can be
used to portray how an entity (such as govern-
ment income) is divided up among several cate-
gories (such as social welfare, military spending,
etc.); however, a graphic designer will choose a
pie chart if the intent is to convey the relative dis-
tributions as opposed to their absolute amounts.
Furthermore, a particular type of graphic (such as
a line graph) might be appropriate for conveying
several different intentions (maximum data point,
data trend, data variation, etc.).
Contextual and world knowledge are also es-
sential for understanding information graphics.
Contextual knowledge includes the caption as-
sociated with the graphic, any highlighting of
graphic elements that affects the focus of atten-
tion in the graphic, and the discourse structure and
focus of attention in any surrounding text. World
knowledge consists of mutual beliefs between de-
signer and viewer about entities of interest to the
intended viewing audience. For example, if an in-
formation graphic appears in a document targeted
at residents of New York City, then both the de-
signer and the viewer will mutually believe that
entities such as New York City, its football and
baseball teams, etc. will be particularly salient
to the viewer. Our methodology for understand-
ing information graphics takes these knowledge
sources into account.
</bodyText>
<subsectionHeader confidence="0.998733">
4.3 The Visual Extraction Component
</subsectionHeader>
<bodyText confidence="0.99998905">
The visual extraction component (VEC) cap-
tures much of the perceptual knowledge discussed
in Section 4.2. It is responsible for recogniz-
ing the individual components comprising the
graphic, identifying the relationship of the differ-
ent components to one another and to the graphic
as a whole, and classifying the graphic as to type.
Extracted components include not only the bars,
lines, or wedges of a graphic but also the titles of
the axes, the legend, and the graphic’s title or cap-
tion. The present implementation deals only with
gray scale images (in pgm format) of bar charts,
pie charts, and line graphs, though eventually it
will be extended to handle color and other kinds
of information graphics. Words and numbers that
appear in the chart are associated with particular
bars, wedges and lines by their proximity to the
chart component in question. The output of the
visual extraction component is an XML file that
describes the chart and all of its components.
</bodyText>
<subsectionHeader confidence="0.9956955">
4.4 Applying Discourse Understanding
Strategies
</subsectionHeader>
<bodyText confidence="0.999929735294118">
Many researchers have cast the understanding
of discourse and dialogue as a plan recognition
problem — that is, the writer or speaker (or char-
acters in the case of a story) has an underlying
goal and a plan for accomplishing that goal, and
understanding requires that the reader or listener
infer the plan and in turn the goal that the plan is
intended to achieve. (Perrault and Allen, 1980;
Wilensky, 1983; Litman and Allen, 1987; Car-
berry, 1990; Charniak and Goldman, 1993; Ardis-
onno and Sestero, 1996) are just a few examples
of such systems.
Since understanding information graphics is a
discourse-level problem, we are extending plan
inference techniques to recognizing the intended
message of an information graphic(Elzer et al.,
2003) and to identifying its contribution to an
extended discourse that includes both text and
graphics. Planning and plan inference systems re-
quire knowledge about goals and how they can
be achieved. Typically, this is provided by a li-
brary of operators. Each operator encodes a goal
in its header; the body of the operator encodes
the subgoals that must be accomplished in order
to achieve the operator’s goal. A planning sys-
tem starts with a high-level goal, and uses oper-
ators to decompose the goal into a set of simpler
subgoals, which eventually decompose into prim-
itive subgoals that can be accomplished by prim-
itive actions in the domain. On the other hand,
a plan inference system starts with the primitive
goals associated with observed actions, and uses
the operators to chain backwards to higher-level
goals which the lower-level subgoals contribute to
achieving. In the case of traditional discourse and
dialogue, the subgoals in the plan operators are ei-
ther communicative or domain goals, and the ob-
served actions that start the plan inference process
are the speech acts represented by the utterances
in a story or a dialogue.
To extend plan inference to information graph-
ics, the plan operators must include goals that
can be accomplished by viewing an information
graphic, as opposed to being the recipient of an
utterance. As discussed in Section 4.1, the Auto-
Brief project(Kerpedjiev and Roth, 2000) devel-
oped an algorithm to map communicative goals to
a sequence of perceptual and cognitive tasks that
the graphic should support. Perceptual tasks are
tasks that can be performed by simply viewing the
graphic, such as finding the top of a bar in a bar
chart; cognitive tasks are tasks that are performed
via mental computations, such as computing the
difference between two numbers. We draw on
the AutoBrief notion of perceptual and cognitive
tasks enabled by an information graphic. Our plan
operators not only encode knowledge about how
to achieve domain and communicative goals (the
latter of which may require that the viewer per-
form perceptual and cognitive tasks) but they also
encode knowledge about how information-access
tasks, such as finding the value of an entity in
a graphic, can be decomposed into simpler sub-
goals. Figures 2 and 3 present two plan operators
for achieving the goal of finding the value &lt;v&gt; of
an attribute &lt;att&gt; for a graphical element &lt;e&gt;
(for example, the value associated with the top of
a bar in a bar chart). The body of the operator in
</bodyText>
<table confidence="0.963646846153846">
Goal: Find-value(&lt;viewer&gt;, &lt;g&gt;, &lt;e&gt;, &lt;ds&gt;, &lt;att&gt;, &lt;v&gt;)
Gloss: Given graphical element &lt;e&gt; in graphic &lt;g&gt;, &lt;viewer&gt; can find the value &lt;v&gt;
in dataset &lt;ds&gt; of attribute &lt;att&gt; for &lt;e&gt;
Data-req: Dependent-variable(&lt;att&gt;, &lt;ds&gt;)
Body: 1. Perceive-dependent-value(&lt;viewer&gt;, &lt;g&gt;, &lt;att&gt;, &lt;e&gt;, &lt;v&gt;)
Figure 2: Operator for achieving a goal perceptually
Goal: Find-value(&lt;viewer&gt;, &lt;g&gt;, &lt;e&gt;, &lt;ds&gt;, &lt;att&gt;, &lt;v&gt;)
Gloss: Given graphical element &lt;e&gt; in graphic &lt;g&gt;, &lt;viewer&gt; can find the value &lt;v&gt;
in dataset &lt;ds&gt; of attribute &lt;att&gt; for &lt;e&gt;
Data-req: Natural-quantitative-ordering(&lt;att&gt;)
Display-const: Ordered-values-on-axis(&lt;g&gt;, &lt;axis&gt;, &lt;att&gt;)
Body: 1. Perceive-info-to-interpolate(&lt;viewer&gt;,&lt;g&gt;,&lt;axis&gt;,&lt;e&gt;,&lt;l1&gt;,&lt;l2&gt;,&lt;f&gt;)
2. Interpolate(&lt;viewer&gt;, &lt;l1&gt;, &lt;l2&gt;, &lt;f&gt;, &lt;v&gt;)
</table>
<figureCaption confidence="0.654013428571428">
Figure 3: Operator that employs both perceptual and cognitive subgoals
Figure 2 specifies that the goal can be achieved
by a primitive perceptual task in which the viewer
just perceives the value; this could be done, for
example, if the element in the graphic is annotated
with its value, as are the bars in the bar chart in
Figure 8 of the Appendix. On the other hand, the
</figureCaption>
<bodyText confidence="0.9715846">
body of the operator in Figure 3 captures a differ-
ent way of finding the value, one that presumably
requires more effort. It specifies the perceptual
task of finding the values &lt;l1&gt; and &lt;l2&gt; sur-
rounding the desired value on the axis along with
the fraction &lt;f&gt; of the distance that the desired
value lies between &lt;l1&gt; and &lt;l2&gt;, followed by
the cognitive task of interpolating between the re-
trieved values &lt;l1&gt; and &lt;l2&gt;.
Our operators contain data requirements (la-
belled Data-req) which the data must satisfy in
order for the operator to be applicable in a graphic
planning paradigm; they may also contain display
constraints (labelled Display-const) which con-
strain how the information graphic is constructed
if this operator is part of a final plan. In the case
of plan recognition, these constraints are used
in reverse. The display constraints are used to
eliminate operators from consideration, since if
a graphic does not satisfy the operator’s display
constraints, then the operator could not be part of
a plan that led to the graphic. If a graphic meets
the display constraints of an operator, then the
data requirements are used to limit how the op-
erator’s parameters might be instantiated.
</bodyText>
<subsectionHeader confidence="0.915806">
4.4.1 Beginning the Plan Inference Process
</subsectionHeader>
<bodyText confidence="0.986544175675676">
Traditional plan inference systems used for
language understanding start with the primitive
goal achieved by the speech act in the dialogue
or discourse. In the case of information graphics,
the role of the speech act is played by the primi-
tive perceptual tasks that the viewer performs on
the graphic. To limit the set of perceptual tasks
that are considered, we make two observations:
• The graphic designer has many alternative
ways of designing a graphic, and the de-
sign choices facilitate some perceptual tasks
more than others. Following the Auto-
Brief work(Kerpedjiev and Roth, 2000) on
generating graphics that fulfill communica-
tive goals, we hypothesize that the designer
chooses a design that best facilitates the
tasks that are most important to conveying
his intended message, subject to the con-
straints imposed by competing tasks.
• Entities may become particularly salient by
virtue of highlighting in the graphic (for ex-
ample, coloring certain elements different
from the others, annotating an element with
an asterisk, or exploding one piece of a pie
chart1), by their mention in the caption or
surrounding text, or via world knowledge
1(Mittal, 1997) discusses a variety of such design tech-
niques in the context of distorting the message inferred from
a graphic.
capturing mutual beliefs about entities of in-
terest to the intended audience. We hypoth-
esize that the designer relies on the viewer
recognizing particularly salient entities, in
order to make certain perceptual tasks more
salient to the viewer.
As noted in Section 4.1, one cannot rely on a
graphic’s caption to provide the intended mes-
sage of the graphic. Consequently, the plan in-
ference process starts with both the set of tasks
that are best enabled by the information graphic
and the set of tasks (if any) that are particularly
salient. These will be referred to as candidate
tasks. The next two subsections describe how
candidate tasks are identified.
Identifying the Best Enabled Tasks The
APTE (Analysis of Perceptual Task Effort) sub-
module, shown in Figure 1 as part of the Inten-
tion Recognition Component, captures perceptual
knowledge about performing primitive perceptual
tasks2, and it encapsulates the results of cognitive
psychology research to estimate the relative effort
required for different tasks. The output of APTE
is the set of perceptual tasks that are best enabled
by the graphic. These become candidate tasks.
Each APTE rule captures a primitive percep-
tual task that can be performed on a particu-
lar type of information graphic, the conditions
(graphic design choices) that affect the difficulty
of performing that task, and the estimated effort
expended by a viewer if those conditions are sat-
isfied in the graphic. The condition-computation
pairs are ordered so that the ones producing the
lowest effort estimates appear first in a rule.
To derive the effort estimates in the rules, we
have followed the GOMS approach(Card et al.,
1983) by breaking down the tasks that are re-
garded as primitive in our plan operators into
even more basic component tasks, and then sum-
ming the effort estimates for these very basic
tasks. Lohse’s work(Lohse, 1993) is an exam-
ple of the GOMS architecture applied to predict-
ing performance on graph comprehension tasks,
and many of our effort estimates are based on
Lohse’s research. For example, Figure 4 dis-
</bodyText>
<footnote confidence="0.961943666666667">
2Primitive perceptual tasks are those that we do not de-
compose into a set of simpler subtasks; this is not to be con-
fused with the notion of a psychological primitive.
</footnote>
<bodyText confidence="0.997311240740741">
plays the APTE rule for the task of finding the
value associated with the top of a bar in a bar
chart. If the bar is annotated with its value,
then condition-computation pair B1-1 estimates
its effort as 150 units for discriminating the label
(based on work by Lohse(Lohse, 1993)) and 300
units for recognizing a 6-letter word (John and
Newell, 1990). If the bar is not annotated with its
value but is aligned with a tick mark on the axis,
then condition-computation pair B1-2 estimates
the perceptual effort in terms of the distance to the
dependent axis (in order to capture the degrees of
visual arc scanned(Kosslyn, 1989)) plus the effort
of discriminating and recognizing the label. Fig-
ure 5 displays the APTE rule associated with the
first subgoal in Figure 3. It estimates the effort for
the primitive task Perceive-info-to-interpolate as
the effort of the scan to the dependent axis (based
on (Kosslyn, 1989)), the effort of discriminating
the intersection location on the axis (150 units
based on (Lohse, 1993)), plus the effort of the sac-
cade to each label (230 units each (Russo, 1978))
along with the effort involved in discriminating
and recognizing the labels. Similarly, there is a
cognitive rule (not discussed here) for estimating
the effort associated with the cognitive task Inter-
polate (the second subgoal in the operator in Fig-
ure 3). (Elzer et al., 2003a) presents a more ex-
tensive discussion of the cognitive principles un-
derlying the APTE rules.
Given the XML representation of an informa-
tion graphic, each APTE rule that is applicable
to the graphic produces an effort estimate for the
task captured by the rule. When a task might be
instantiated in multiple ways and still satisfy the
conditions of a condition-computation pair (for
example, the task of finding the value of the top
of a bar could be instantiated for each bar in a
bar chart), only the instantiation that produces the
lowest effort estimate becomes a candidate task.
(If the bars are not annotated with values, then the
instantiation that will produce the lowest effort es-
timate for the task of finding the value of the top
of a bar in a bar chart would be the bar with the
shortest scan to the dependent axis.) This is con-
sistent with the idea that the graphic designer will
make the important tasks easy to perform. The
set of perceptual tasks that require the least effort
become candidate tasks.
Rule-1:Estimate effort for task Perceive-dependent-value(&lt;viewer&gt;, &lt;g&gt;, &lt;att&gt;, &lt;e&gt;, &lt;v&gt;)
Graphic-type: bar-chart
Gloss: Compute effort for finding the exact value &lt;v&gt; for attribute &lt;att&gt; represented by top &lt;e&gt;
of a bar &lt;b&gt; in graph &lt;g&gt;
B1-1: IF the top of bar &lt;b&gt; is annotated with a value,
</bodyText>
<equation confidence="0.446525">
THEN effort--150 + 300
</equation>
<bodyText confidence="0.417307">
B1-2: IF the top &lt;e&gt; of bar &lt;b&gt; aligns with a labelled tick mark on the dependent axis,
THEN effort--scan + 150 + 300
</bodyText>
<figureCaption confidence="0.997692">
Figure 4: A rule for estimating effort for the primitive perceptual task Perceive-value
</figureCaption>
<figure confidence="0.461064333333333">
Rule-2:Estimate effort for task
Perceive-info-to-interpolate(&lt;viewer&gt;,&lt;g&gt;,&lt;axis&gt;,&lt;e&gt;,&lt;l1&gt;,&lt;l2&gt;,&lt;f&gt;)
Graphic-type: bar-chart
</figure>
<figureCaption confidence="0.30193725">
Gloss: Compute effort for finding the information needed for interpolation, including the labels
&lt;l1&gt; and &lt;l2&gt; on either side of entity &lt;e&gt; on axis &lt;axis&gt; in graph &lt;g&gt;,
and the fraction &lt;f&gt; that is the distance between &lt;l1&gt; and entity &lt;e&gt; on &lt;axis&gt;
relative to the distance between &lt;l1&gt; and &lt;l2&gt;
</figureCaption>
<figure confidence="0.361588">
B2-1: IF &lt;axis&gt; is labelled with values THEN effort--scan + 150 + ((230 + 150 + 300) x 2)
</figure>
<figureCaption confidence="0.998617">
Figure 5: A rule for estimating effort for the primitive perceptual task Perceive-info-to-interpolate
</figureCaption>
<bodyText confidence="0.98927925">
Identifying Particularly Salient Tasks
Salient tasks are those that the viewer might
perform because they relate to entities that are
in the viewer’s current focus of attention, as
determined by contextual knowledge provided
by the caption, highlighting, and the surrounding
text and by world knowledge in the form of
mutual beliefs about items of particular interest
to the viewing audience.
Ideally, a caption will provide clues about the
message that an information graphic is intended
to convey, and thus noun phrases in captions rep-
resent salient entities.3 The graphic designer can
also call into focus certain aspects of the graphic
by using attention-getting devices such as col-
oring it differently from the rest of the graphic,
annotating it with an arrow, etc. Our working
hypothesis is that if the graphic designer goes
to the effort of employing such attention-getting
devices, then the highlighted items almost cer-
tainly contribute to the intended message. Thus
the attributes of these highlighted items (for ex-
ample, the attributes of a highlighted bar in a bar
chart), which are captured in the XML represen-
</bodyText>
<footnote confidence="0.851574">
3Verb phrases in captions also provide evidence, but they
suggest particular operators of interest rather than instanti-
ated perceptual tasks, and thus we associate verbs with oper-
ators in the plan library.
</footnote>
<bodyText confidence="0.9999632">
tation of the graphic, are also regarded as salient
entities. Salient entities also include those that
world knowledge suggests are mutually believed
to be of interest to the viewing audience. We en-
vision in the future using the notion of lexical
chains(Silber and McCoy, 2000) to identify enti-
ties that the accompanying text makes particularly
salient. Perceptual tasks that are instantiated with
a salient entity and that can be performed on the
graphic are designated salient tasks.
</bodyText>
<subsectionHeader confidence="0.849302">
4.4.2 The Search Process
</subsectionHeader>
<bodyText confidence="0.999978558441559">
Candidate tasks consist of the set of percep-
tual tasks that require the least effort and the set of
salient tasks. Once the set of candidate tasks has
been identified, plan inference begins. Initial can-
didate plans are constructed from each operator
in which a candidate task appears as a subgoal;
the root of the candidate plan is the goal of the
operator, and its children are the subgoals in the
body of the operator. Chaining from the root goal
to other operators whose body contains the root
goal as a subgoal produces larger candidate plans
with higher-level goals as the new root goal.
Plan inference systems have used a variety of
heuristics to evaluate candidate plans and to se-
lect the candidate plan to expand further. These
heuristics help to guide the search through the
space of candidate plans in order to hypothe-
size the plan that best represents the user’s in-
tentions. These heuristics have included increas-
ing the rating of partial plans as their arguments
become instantiated(Perrault and Allen, 1980),
preferring coherent discourse moves(Litman and
Allen, 1987; Carberry, 1990), and biasing the
plan inference process based on knowledge about
the user group(Gertner and Webber, 1996). We
have identified several kinds of evidence for guid-
ing plan inference from information graphics, in-
cluding the estimated effort required by a candi-
date plan, the basis for instantiating parameters in
the plan, adherence to the proximity compatibil-
ity principle from cognitive science research, and
the relation between a candidate plan and the es-
tablished discourse context.
Since our working hypothesis is that the
graphic designer tried to enable those tasks neces-
sary to recognize his intended message, candidate
plans that require substantially more effort than
other candidate plans are less likely to represent
the intentions of the designer. The effort associ-
ated with a candidate plan is measured as the sum
of the effort of the tasks comprising it.
There are many ways that a parameter in a task
or subgoal might become instantiated, and the ba-
sis for the instantiation provides evidence about
the likelihood that a hypothesized candidate plan
represents the graphic designer’s intentions. If
an instantiation is suggested by highlighting or
a caption or entities that are particularly salient
to the targeted audience, that partial plan should
be evaluated more favorably since the designer of
the graphic has provided reasons for the viewer to
use these instantiations in recognizing his inten-
tions. Similarly, if the instantiation is one of sev-
eral possible alternatives with no reason for pre-
ferring one over the other, then the partial plan
should be evaluated less favorably since the de-
signer did not give the viewer any reason to prefer
one over the other. This relates to Allen’s forking
heuristic(Perrault and Allen, 1980). The proxim-
ity compatibility principle(Wickens and Carswell,
1995) also suggests that candidate plans which
use similarly encoded elements (for example, all
red bars) in an integrated fashion should be eval-
uated more favorably than those that do not.
If there is a context established by the text pre-
ceding or surrounding the graphic, then candidate
plans whose root goal contributes to the exist-
ing discourse context should be preferred. If the
surrounding text has a reference to the graphic,
then focusing heuristics(Carberry, 1990) will pre-
fer candidate plans that relate most closely to the
current focus of attention at that point in the sur-
rounding text. However, the surrounding text of-
ten does not refer to accompanying graphics, as is
the case in the Newsweek article whose excerpt is
shown in Figure 6. Future work will investigate
how we should handle instances such as this.
</bodyText>
<sectionHeader confidence="0.982222" genericHeader="method">
5 Response Generation and Followup
</sectionHeader>
<bodyText confidence="0.99999235">
The intended message of the graphic must be
augmented with additional propositions that con-
vey interesting features that a viewer would glean
from the graphic. For example, the intended mes-
sage of the graphic in Figure 6 appears to be that
the income of black women has risen dramati-
cally over the last decade and reached the level
of white women. But other interesting features of
the graphic might include the trends over the past
several decades, periods where they were closest,
etc. In future work, we anticipate developing a
methodology for identifying propositions that ex-
pand on the message of the graphic designer and
for including the most salient of these in the sum-
marization of the graphic. We also envision re-
sponding to followup requests for further infor-
mation about the graphic by selecting the highest
ranking propositions that were not included in the
initial message, organizing them into a coherent
response, and conveying it to the user.
</bodyText>
<sectionHeader confidence="0.998625" genericHeader="conclusions">
6 Summary
</sectionHeader>
<bodyText confidence="0.999985538461538">
This paper has argued that understanding
information graphics is a discourse-level prob-
lem. Not only must the system recognize the in-
tended message of the information graphic, but
the recognition process requires similar kinds of
knowledge sources and similar kinds of process-
ing as does the understanding of traditional dis-
course and dialogue. Moreover, when an article
is composed of text and graphics, the intended
message of the information graphic must be in-
tegrated into the discourse structure of the sur-
rounding text, and it contributes to the overall dis-
course intention of the article.
</bodyText>
<sectionHeader confidence="0.98345" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998803530612245">
L. Ardisonno and D. Sestero. 1996. Using dynamic
user models in the recognition of the plans of the
user. User Modeling and User-Adapted Interac-
tion, 5(2):157–190.
S. Carberry and L. Lambert. 1999. A process model
for recognizing communicative acts and modeling
negotiation subdialogues. Computational Linguis-
tics, 25(1):1–53.
S. Carberry. 1990. Plan Recognition in Natural Lan-
guage Dialogue. ACL-MIT Press Series on Natural
Language Processing. MIT Press, Cambridge, MA.
S. Card, T. Moran, and A. Newell. 1983. The Psychol-
ogy of Human-Computer Interaction. Lawrence
Erlbaum Associates, Inc., Hillsdale, NJ.
E. Charniak and R. Goldman. 1993. A bayesian
model of plan recognition. Artificial Intelligence,
64:53–79.
H. Clark. 1996. Using Language. Cambridge Univer-
sity Press.
M. Corio and G. Lapalme. 1999. Generation of texts
for information graphics. In Proceedings of the 7th
European Workshop on Natural Language Genera-
tion EWNLG’99, pages 49–58.
S. Elzer, N. Green, and S. Carberry. 2003a. Exploit-
ing cognitive psychology research for recognizing
intention in information graphics. In Proceedings
of the 25th Annual Meeting of the Cognitive Science
Society. To appear.
S. Elzer, N. Green, S. Carberry, and K. McCoy. 2003.
Extending plan inference techniques to recognize
intentions in information graphics. In Proceedings
ofthe Ninth International Conference on User Mod-
eling. To appear.
A. Gertner and B. Webber. 1996. A Bias Towards
Relevance: Recognizing Plans Where Goal Mini-
mization Fails. In Proc. of the Thirteenth National
Conference on Artificial Intelligence, pages 1133–
1138.
H. P. Grice. 1969. Utterer’s Meaning and Intentions.
Philosophical Review, 68:147–177.
B. Grosz and C. Sidner. 1986. Attention, Intentions,
and the Structure of Discourse. Computational Lin-
guistics, 12(3):175–204.
B. John and A. Newell. 1990. Toward an engi-
neering model of stimulus response compatibility.
In R. Gilmore and T. Reeve, editors, Stimulus-
response compatibility: An integrated approach,
pages 107–115. North-Holland, New York.
A. Kennel. 1996. Audiograf: A diagram-reader for
the blind. In Second Annual ACM Conference on
Assistive Technologies, pages 51–56.
S. Kerpedjiev and S. Roth. 2000. Mapping com-
municative goals into conceptual tasks to generate
graphics in discourse. In Proc. of the International
Conference on Intelligent User Interfaces, pages
60–67.
S. Kosslyn. 1989. Understanding charts and graphs.
Applied Cognitive Psychology, 3:185–226.
D. Litman and J. Allen. 1987. A Plan Recognition
Model for Subdialogues in Conversation. Cognitive
Science, 11:163–200.
G. Lohse. 1993. A cognitive model for understand-
ing graphical perception. Human-Computer Inter-
action, 8:353–388.
Peter B. Meijer. 1992. An experimental system for
auditory image representations. IEEE Transactions
on Biomedical Engineering, 39(2):291–300, Febru-
ary.
V. Mittal. 1997. Visual prompts and graphical design:
A framework for exploring the design space of 2-D
charts and graphs. In Proc. of the Fourteenth Na-
tional Conference on Artificial Intelligence, pages
57–63.
R. Perrault and J. Allen. 1980. A Plan-Based Anal-
ysis of Indirect Speech Acts. American Journal of
Computational Linguistics, 6(3-4):167–182.
J. Russo. 1978. Adaptation of cognitive processes to
eye movement systems. In J. Senders, D. Fisher,
and R. Monty, editors, Eye movements and higher
psychological functions. Lawrence Erlbaum, Hills-
dale, NJ.
J. Searle. 1970. Speech Acts: An Essay in the Phi-
losophy ofLanguage. Cambridge University Press,
London.
G. Silber and K. McCoy. 2000. Efficient text summa-
rization using lexical chains. In Proc. of the Inter-
national Conference on Intelligent User Interfaces,
pages 252–255.
C. Wickens and M. Carswell. 1995. The proximity
compatibility principle: Its psychological founda-
tion and relevance to display design. Human Fac-
tors, 37(3):473–494.
R. Wilensky. 1983. Planning and Understanding.
Addison-Wesley.
J. Yu, J. Hunter, E. Reiter, and S. Sripada. 2002.
Recognising visual patterns to communicate gas
turbine time-series data. In ES2002, pages 105–
118.
</reference>
<figure confidence="0.864181285714286">
Metric Tons
Appendix of Graphics from our Corpus
Graphic from Newsweek Article
Median Income
In thousands of 2001 dollars
1948 60 70 80 90 01
Relevant Text from Newsweek Article
</figure>
<bodyText confidence="0.999904666666667">
This is not to say that black women have
climbed the storied crystal stair. They remain
“in the proving stage”, observes Alabama ex-
ecutive Alice Gordon. Nearly 14 percent of
working black women remain below the poverty
level. And women don’t yet out-earn black men.
But the growing educational-achievement gap
portends a monumental shifting of the sands.
College-educated black women already earn
more than the median for all black working men
— or, for that matter, for all women. And as
women in general move up the corporate pyra-
mid, black women, increasingly, are part of the
parade. In 1995 women held less than 9 per-
cent of corporate-officer positions in Fortune
500 companies, according to Catalyst, a New
York-based organization that promotes the inter-
ests of women in business. Last year they held
close to 16 percent, a significant step up. Of
those 2,140 women, 163 were black — a minus-
cule proportion, but one that is certain to grow.
</bodyText>
<figureCaption confidence="0.996715">
Figure 6: Excerpt from Newsweek Magazine
</figureCaption>
<figure confidence="0.993235555555555">
Trusting DNA
How reliable adults think DNA tests are for identifying an individual:
Very reliable
Somewhat
reliable
Somewhat
unreliable
Very unreliable
Don’t know
</figure>
<figureCaption confidence="0.9999945">
Figure 7: Standalone Graphic from USA Today
Figure 8: Standalone Graphic from USA Today
</figureCaption>
<figure confidence="0.998498">
$15
White women
10
Black women
5
South Africa tops
in gold production
Leading producers in
metric tons
South
Africa United
428 States
355
Other
African
countries Canada
187 155
Europe
21
23%
4%
3%
68%
2%
Median Salaries (in dollars), Full−Time Employed SMET Doctorates, by Field and Gender, 1997
80,000 Female
70,000 Male
60,000
50,000
40,000
30,000
20,000
10,000
0
All SMET Computer/ Engineering Life Sciences Physical Sciences Social Sciences
Mathematical
Sciences
</figure>
<figureCaption confidence="0.999066">
Figure 9: Graphic from Report of the NSF Committee on Equal Opportunities in Science &amp; Engineering
</figureCaption>
<bodyText confidence="0.91669">
Audits of affluent
continue to slide
Percentae of taxpayers who
were audited by the IRS:
</bodyText>
<figure confidence="0.991891904761905">
Salaries (in dollars)
Delaware bankruptcy 1.8%
personal filings
1.2%
3000
0.6%
2500
0
2000
1500 3.0%
1000
2.0%
1998 1999 2000 2001
Figure 10: Graphic from Wilmington News 1.0%
Journal
0
All taxpayers
0.6%
’96 ’97 ’98 ’99 ’00 ’01
Affluent taxpayers
0.8%
</figure>
<figureCaption confidence="0.947072">
’96 ’97 ’98 ’99 ’00 ’01
Figure 11: Graphic from USA Today
</figureCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.431616">
<title confidence="0.982693">Information Graphics: A Discourse-Level Problem</title>
<author confidence="0.877098">Elzer Carberry</author>
<author confidence="0.877098">McCoy Green</author>
<affiliation confidence="0.8474">of Computer Science, University of Delaware, Newark, DE</affiliation>
<address confidence="0.8211035">elzer, mccoy, of Math. Sciences, Univ. of North Carolina at Greensboro, Greensboro, NC</address>
<abstract confidence="0.983433458333333">Keywords: graphics, understanding, discourse, plan-based models Information graphics that appear in newspapers and magazines generally have a message that the viewer is intended to recognize. This paper argues that understanding such information graphics is a discourse-level problem. In particular, it requires assimilating information from multiple knowledge sources to recognize the intended message of the graphic, just as recognizing intention in text does. Moreover, when an article is composed of text and graphics, the intended message of the information graphic (its discourse intention) must be integrated into the discourse structure of the surrounding text and contributes to the overall discourse intention of the article. This paper describes how we extend plan-based techniques that have been used for understanding traditional discourse to the understanding of information graphics. This work is part of a project to develop an interactive natural language system that provides sight-impaired users with access to information graphics.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Ardisonno</author>
<author>D Sestero</author>
</authors>
<title>Using dynamic user models in the recognition of the plans of the user. User Modeling and User-Adapted Interaction,</title>
<date>1996</date>
<pages>5--2</pages>
<contexts>
<context position="17440" citStr="Ardisonno and Sestero, 1996" startWordPosition="2754" endWordPosition="2758">omponent is an XML file that describes the chart and all of its components. 4.4 Applying Discourse Understanding Strategies Many researchers have cast the understanding of discourse and dialogue as a plan recognition problem — that is, the writer or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators. Each operator encodes a goal in its header; the body of the operator encodes the subgoals that must be accomplis</context>
</contexts>
<marker>Ardisonno, Sestero, 1996</marker>
<rawString>L. Ardisonno and D. Sestero. 1996. Using dynamic user models in the recognition of the plans of the user. User Modeling and User-Adapted Interaction, 5(2):157–190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Carberry</author>
<author>L Lambert</author>
</authors>
<title>A process model for recognizing communicative acts and modeling negotiation subdialogues.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>1</issue>
<contexts>
<context position="14111" citStr="Carberry and Lambert, 1999" startWordPosition="2208" endWordPosition="2211"> composite. Figure 11 illustrates a composite information graphic. The discourse purpose of the composite graphic is that audits of affluent taxpayers are declining with respect to audits of all taxpayers. This message can only be deduced by relating the two individual graphics and their underlying messages. Moreover, understanding information graphics requires the use of multiple knowledge sources. In earlier work on recognizing expressions of doubt, we developed an algorithm that combined linguistic, contextual, and world knowledge and applied it to the recognition of complex discourse acts(Carberry and Lambert, 1999). In the case of information graphics, the corollary to linguistic knowledge is perceptual knowledge, by which one recognizes the individual elements of the graphic (for example, the bars in a bar chart), the relation of the individual elements in the graphic to one another, the type of graphic (line graph, bar chart, pie chart, etc.), and what the different graphic types can be used to convey. For example, both a scatter plot and a pie chart can be used to portray how an entity (such as government income) is divided up among several categories (such as social welfare, military spending, etc.)</context>
</contexts>
<marker>Carberry, Lambert, 1999</marker>
<rawString>S. Carberry and L. Lambert. 1999. A process model for recognizing communicative acts and modeling negotiation subdialogues. Computational Linguistics, 25(1):1–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Carberry</author>
</authors>
<title>Plan Recognition in Natural Language Dialogue.</title>
<date>1990</date>
<booktitle>Series on Natural Language Processing.</booktitle>
<publisher>ACL-MIT Press</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="17382" citStr="Carberry, 1990" startWordPosition="2747" endWordPosition="2749">stion. The output of the visual extraction component is an XML file that describes the chart and all of its components. 4.4 Applying Discourse Understanding Strategies Many researchers have cast the understanding of discourse and dialogue as a plan recognition problem — that is, the writer or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators. Each operator encodes a goal in its header; the body o</context>
<context position="32511" citStr="Carberry, 1990" startWordPosition="5210" endWordPosition="5211">tains the root goal as a subgoal produces larger candidate plans with higher-level goals as the new root goal. Plan inference systems have used a variety of heuristics to evaluate candidate plans and to select the candidate plan to expand further. These heuristics help to guide the search through the space of candidate plans in order to hypothesize the plan that best represents the user’s intentions. These heuristics have included increasing the rating of partial plans as their arguments become instantiated(Perrault and Allen, 1980), preferring coherent discourse moves(Litman and Allen, 1987; Carberry, 1990), and biasing the plan inference process based on knowledge about the user group(Gertner and Webber, 1996). We have identified several kinds of evidence for guiding plan inference from information graphics, including the estimated effort required by a candidate plan, the basis for instantiating parameters in the plan, adherence to the proximity compatibility principle from cognitive science research, and the relation between a candidate plan and the established discourse context. Since our working hypothesis is that the graphic designer tried to enable those tasks necessary to recognize his in</context>
<context position="34798" citStr="Carberry, 1990" startWordPosition="5572" endWordPosition="5573"> the other. This relates to Allen’s forking heuristic(Perrault and Allen, 1980). The proximity compatibility principle(Wickens and Carswell, 1995) also suggests that candidate plans which use similarly encoded elements (for example, all red bars) in an integrated fashion should be evaluated more favorably than those that do not. If there is a context established by the text preceding or surrounding the graphic, then candidate plans whose root goal contributes to the existing discourse context should be preferred. If the surrounding text has a reference to the graphic, then focusing heuristics(Carberry, 1990) will prefer candidate plans that relate most closely to the current focus of attention at that point in the surrounding text. However, the surrounding text often does not refer to accompanying graphics, as is the case in the Newsweek article whose excerpt is shown in Figure 6. Future work will investigate how we should handle instances such as this. 5 Response Generation and Followup The intended message of the graphic must be augmented with additional propositions that convey interesting features that a viewer would glean from the graphic. For example, the intended message of the graphic in </context>
</contexts>
<marker>Carberry, 1990</marker>
<rawString>S. Carberry. 1990. Plan Recognition in Natural Language Dialogue. ACL-MIT Press Series on Natural Language Processing. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Card</author>
<author>T Moran</author>
<author>A Newell</author>
</authors>
<title>The Psychology of Human-Computer Interaction. Lawrence Erlbaum Associates,</title>
<date>1983</date>
<publisher>Inc.,</publisher>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="25479" citStr="Card et al., 1983" startWordPosition="4046" endWordPosition="4049">t of perceptual tasks that are best enabled by the graphic. These become candidate tasks. Each APTE rule captures a primitive perceptual task that can be performed on a particular type of information graphic, the conditions (graphic design choices) that affect the difficulty of performing that task, and the estimated effort expended by a viewer if those conditions are satisfied in the graphic. The condition-computation pairs are ordered so that the ones producing the lowest effort estimates appear first in a rule. To derive the effort estimates in the rules, we have followed the GOMS approach(Card et al., 1983) by breaking down the tasks that are regarded as primitive in our plan operators into even more basic component tasks, and then summing the effort estimates for these very basic tasks. Lohse’s work(Lohse, 1993) is an example of the GOMS architecture applied to predicting performance on graph comprehension tasks, and many of our effort estimates are based on Lohse’s research. For example, Figure 4 dis2Primitive perceptual tasks are those that we do not decompose into a set of simpler subtasks; this is not to be confused with the notion of a psychological primitive. plays the APTE rule for the t</context>
</contexts>
<marker>Card, Moran, Newell, 1983</marker>
<rawString>S. Card, T. Moran, and A. Newell. 1983. The Psychology of Human-Computer Interaction. Lawrence Erlbaum Associates, Inc., Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Charniak</author>
<author>R Goldman</author>
</authors>
<title>A bayesian model of plan recognition.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<pages>64--53</pages>
<contexts>
<context position="17410" citStr="Charniak and Goldman, 1993" startWordPosition="2750" endWordPosition="2753">t of the visual extraction component is an XML file that describes the chart and all of its components. 4.4 Applying Discourse Understanding Strategies Many researchers have cast the understanding of discourse and dialogue as a plan recognition problem — that is, the writer or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators. Each operator encodes a goal in its header; the body of the operator encodes the s</context>
</contexts>
<marker>Charniak, Goldman, 1993</marker>
<rawString>E. Charniak and R. Goldman. 1993. A bayesian model of plan recognition. Artificial Intelligence, 64:53–79.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Clark</author>
</authors>
<title>Using Language.</title>
<date>1996</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="7635" citStr="Clark, 1996" startWordPosition="1163" endWordPosition="1164">yzes the graphical image and constructs an XML representation of the graphic for use by the graphic understanding system. Section 4.4 then describes how we have extended techniques used for understanding traditional discourse and dialogue to the understanding of information graphics. Section 5 gives a brief overview of future work on the rest of the system. The Appendix contains information graphics that are part of the corpus on which our work is based. 4 Understanding Information Graphics 4.1 Intention in Information Graphics Information graphics are a variant of language. As noted by Clark(Clark, 1996), language is more than just words. It is any “signal” (or lack of signal when one is expected), where a signal is a deliberate action that is intended to convey a message. According to speech act theory, a speaker or writer executes a speech act whose intended meaning he expects the listener or reader to be able to deduce(Searle, 1970; Grice, 1969; Clark, 1996). In their work on multimedia generation, Figure 1: System Architecture the AutoBrief group proposed that speech act theory could be extended to cover the generation of graphical representations(Kerpedjiev and Roth, 2000). They develope</context>
<context position="10474" citStr="Clark, 1996" startWordPosition="1630" endWordPosition="1631">its intended message (as in Figure 8), Corio performed a large corpus study(Corio and Lapalme, 1999) in which he found that captions are often missing or fail to provide any indication of what the information graphic conveys (as in Figures 6 and 10). Thus we cannot rely entirely on the presence of useful captions to identify the intended message of an information graphic. Language research has posited that the listener or reader who is interpreting a speech act identifies its intended meaning by reasoning about the observed signals and the mutual beliefs of author and interpreter(Grice, 1969; Clark, 1996). Applying this to graphical displays, it is reasonable to presume that the author of a graphic similarly expects the viewer to use perceptual skills along with other knowledge sources to deduce from the graphic the message that he intended to convey. Thus we are applying speech act theory in the reverse direction of the AutoBrief project, namely to the recognition of the intended message underlying an information graphic. 4.2 A Discourse Level Problem This section argues that interpreting information graphics is a discourse-level problem — not only is it necessary to recognize the intention o</context>
</contexts>
<marker>Clark, 1996</marker>
<rawString>H. Clark. 1996. Using Language. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Corio</author>
<author>G Lapalme</author>
</authors>
<title>Generation of texts for information graphics.</title>
<date>1999</date>
<booktitle>In Proceedings of the 7th European Workshop on Natural Language Generation EWNLG’99,</booktitle>
<pages>49--58</pages>
<contexts>
<context position="9962" citStr="Corio and Lapalme, 1999" startWordPosition="1544" endWordPosition="1547">yed the message that both men and women earn the least in the social sciences and the most in engineering. Or if the bars for Computer/Mathematical Sciences were highlighted in Figure 9 by coloring them significantly differently from the other bars in the graphic, the graphic would have invoked a comparison of the discrepancies between male and female salaries in Computer/Mathematical Sciences and the salary discrepancies between men and women in other fields. Although a graphic’s caption can be helpful in identifying its intended message (as in Figure 8), Corio performed a large corpus study(Corio and Lapalme, 1999) in which he found that captions are often missing or fail to provide any indication of what the information graphic conveys (as in Figures 6 and 10). Thus we cannot rely entirely on the presence of useful captions to identify the intended message of an information graphic. Language research has posited that the listener or reader who is interpreting a speech act identifies its intended meaning by reasoning about the observed signals and the mutual beliefs of author and interpreter(Grice, 1969; Clark, 1996). Applying this to graphical displays, it is reasonable to presume that the author of a </context>
</contexts>
<marker>Corio, Lapalme, 1999</marker>
<rawString>M. Corio and G. Lapalme. 1999. Generation of texts for information graphics. In Proceedings of the 7th European Workshop on Natural Language Generation EWNLG’99, pages 49–58.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Elzer</author>
<author>N Green</author>
<author>S Carberry</author>
</authors>
<title>Exploiting cognitive psychology research for recognizing intention in information graphics.</title>
<date>2003</date>
<booktitle>In Proceedings of the 25th Annual Meeting of the Cognitive Science</booktitle>
<publisher>Society.</publisher>
<note>To appear.</note>
<contexts>
<context position="17677" citStr="Elzer et al., 2003" startWordPosition="2789" endWordPosition="2792"> or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators. Each operator encodes a goal in its header; the body of the operator encodes the subgoals that must be accomplished in order to achieve the operator’s goal. A planning system starts with a high-level goal, and uses operators to decompose the goal into a set of simpler subgoals, which eventually decompose into primitive subgoals that can be accompl</context>
<context position="27425" citStr="Elzer et al., 2003" startWordPosition="4378" endWordPosition="4381">Figure 3. It estimates the effort for the primitive task Perceive-info-to-interpolate as the effort of the scan to the dependent axis (based on (Kosslyn, 1989)), the effort of discriminating the intersection location on the axis (150 units based on (Lohse, 1993)), plus the effort of the saccade to each label (230 units each (Russo, 1978)) along with the effort involved in discriminating and recognizing the labels. Similarly, there is a cognitive rule (not discussed here) for estimating the effort associated with the cognitive task Interpolate (the second subgoal in the operator in Figure 3). (Elzer et al., 2003a) presents a more extensive discussion of the cognitive principles underlying the APTE rules. Given the XML representation of an information graphic, each APTE rule that is applicable to the graphic produces an effort estimate for the task captured by the rule. When a task might be instantiated in multiple ways and still satisfy the conditions of a condition-computation pair (for example, the task of finding the value of the top of a bar could be instantiated for each bar in a bar chart), only the instantiation that produces the lowest effort estimate becomes a candidate task. (If the bars ar</context>
</contexts>
<marker>Elzer, Green, Carberry, 2003</marker>
<rawString>S. Elzer, N. Green, and S. Carberry. 2003a. Exploiting cognitive psychology research for recognizing intention in information graphics. In Proceedings of the 25th Annual Meeting of the Cognitive Science Society. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Elzer</author>
<author>N Green</author>
<author>S Carberry</author>
<author>K McCoy</author>
</authors>
<title>Extending plan inference techniques to recognize intentions in information graphics.</title>
<date>2003</date>
<booktitle>In Proceedings ofthe Ninth International Conference on User Modeling.</booktitle>
<note>To appear.</note>
<contexts>
<context position="17677" citStr="Elzer et al., 2003" startWordPosition="2789" endWordPosition="2792"> or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators. Each operator encodes a goal in its header; the body of the operator encodes the subgoals that must be accomplished in order to achieve the operator’s goal. A planning system starts with a high-level goal, and uses operators to decompose the goal into a set of simpler subgoals, which eventually decompose into primitive subgoals that can be accompl</context>
<context position="27425" citStr="Elzer et al., 2003" startWordPosition="4378" endWordPosition="4381">Figure 3. It estimates the effort for the primitive task Perceive-info-to-interpolate as the effort of the scan to the dependent axis (based on (Kosslyn, 1989)), the effort of discriminating the intersection location on the axis (150 units based on (Lohse, 1993)), plus the effort of the saccade to each label (230 units each (Russo, 1978)) along with the effort involved in discriminating and recognizing the labels. Similarly, there is a cognitive rule (not discussed here) for estimating the effort associated with the cognitive task Interpolate (the second subgoal in the operator in Figure 3). (Elzer et al., 2003a) presents a more extensive discussion of the cognitive principles underlying the APTE rules. Given the XML representation of an information graphic, each APTE rule that is applicable to the graphic produces an effort estimate for the task captured by the rule. When a task might be instantiated in multiple ways and still satisfy the conditions of a condition-computation pair (for example, the task of finding the value of the top of a bar could be instantiated for each bar in a bar chart), only the instantiation that produces the lowest effort estimate becomes a candidate task. (If the bars ar</context>
</contexts>
<marker>Elzer, Green, Carberry, McCoy, 2003</marker>
<rawString>S. Elzer, N. Green, S. Carberry, and K. McCoy. 2003. Extending plan inference techniques to recognize intentions in information graphics. In Proceedings ofthe Ninth International Conference on User Modeling. To appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gertner</author>
<author>B Webber</author>
</authors>
<title>A Bias Towards Relevance: Recognizing Plans Where Goal Minimization Fails.</title>
<date>1996</date>
<booktitle>In Proc. of the Thirteenth National Conference on Artificial Intelligence,</booktitle>
<pages>1133--1138</pages>
<contexts>
<context position="32617" citStr="Gertner and Webber, 1996" startWordPosition="5224" endWordPosition="5227">new root goal. Plan inference systems have used a variety of heuristics to evaluate candidate plans and to select the candidate plan to expand further. These heuristics help to guide the search through the space of candidate plans in order to hypothesize the plan that best represents the user’s intentions. These heuristics have included increasing the rating of partial plans as their arguments become instantiated(Perrault and Allen, 1980), preferring coherent discourse moves(Litman and Allen, 1987; Carberry, 1990), and biasing the plan inference process based on knowledge about the user group(Gertner and Webber, 1996). We have identified several kinds of evidence for guiding plan inference from information graphics, including the estimated effort required by a candidate plan, the basis for instantiating parameters in the plan, adherence to the proximity compatibility principle from cognitive science research, and the relation between a candidate plan and the established discourse context. Since our working hypothesis is that the graphic designer tried to enable those tasks necessary to recognize his intended message, candidate plans that require substantially more effort than other candidate plans are less</context>
</contexts>
<marker>Gertner, Webber, 1996</marker>
<rawString>A. Gertner and B. Webber. 1996. A Bias Towards Relevance: Recognizing Plans Where Goal Minimization Fails. In Proc. of the Thirteenth National Conference on Artificial Intelligence, pages 1133– 1138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H P Grice</author>
</authors>
<title>Utterer’s Meaning and Intentions. Philosophical Review,</title>
<date>1969</date>
<pages>68--147</pages>
<contexts>
<context position="7985" citStr="Grice, 1969" startWordPosition="1228" endWordPosition="1229"> system. The Appendix contains information graphics that are part of the corpus on which our work is based. 4 Understanding Information Graphics 4.1 Intention in Information Graphics Information graphics are a variant of language. As noted by Clark(Clark, 1996), language is more than just words. It is any “signal” (or lack of signal when one is expected), where a signal is a deliberate action that is intended to convey a message. According to speech act theory, a speaker or writer executes a speech act whose intended meaning he expects the listener or reader to be able to deduce(Searle, 1970; Grice, 1969; Clark, 1996). In their work on multimedia generation, Figure 1: System Architecture the AutoBrief group proposed that speech act theory could be extended to cover the generation of graphical representations(Kerpedjiev and Roth, 2000). They developed a multimedia presentation system that generated text and information graphics. It included 1) an algorithm that could map communicative goals to a set of perceptual and cognitive tasks that must be enabled for a viewer to recognize the goals and 2) an automatic graph designer that used constraint satisfaction to construct an information graphic t</context>
<context position="10460" citStr="Grice, 1969" startWordPosition="1628" endWordPosition="1629"> identifying its intended message (as in Figure 8), Corio performed a large corpus study(Corio and Lapalme, 1999) in which he found that captions are often missing or fail to provide any indication of what the information graphic conveys (as in Figures 6 and 10). Thus we cannot rely entirely on the presence of useful captions to identify the intended message of an information graphic. Language research has posited that the listener or reader who is interpreting a speech act identifies its intended meaning by reasoning about the observed signals and the mutual beliefs of author and interpreter(Grice, 1969; Clark, 1996). Applying this to graphical displays, it is reasonable to presume that the author of a graphic similarly expects the viewer to use perceptual skills along with other knowledge sources to deduce from the graphic the message that he intended to convey. Thus we are applying speech act theory in the reverse direction of the AutoBrief project, namely to the recognition of the intended message underlying an information graphic. 4.2 A Discourse Level Problem This section argues that interpreting information graphics is a discourse-level problem — not only is it necessary to recognize t</context>
</contexts>
<marker>Grice, 1969</marker>
<rawString>H. P. Grice. 1969. Utterer’s Meaning and Intentions. Philosophical Review, 68:147–177.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Grosz</author>
<author>C Sidner</author>
</authors>
<date>1986</date>
<booktitle>Attention, Intentions, and the Structure of Discourse. Computational Linguistics,</booktitle>
<pages>12--3</pages>
<contexts>
<context position="11507" citStr="Grosz and Sidner, 1986" startWordPosition="1790" endWordPosition="1794">rmation graphic. 4.2 A Discourse Level Problem This section argues that interpreting information graphics is a discourse-level problem — not only is it necessary to recognize the intention of the graphic as noted in Section 4.1, but understanding an information graphic requires similar kinds of knowledge and processing as does understanding traditional discourse. Grosz and Sidner contended that discourse has a structure comprised of discourse segments. Each discourse segment has a discourse segment purpose that contributes to the discourse purpose or intention underlying the overall discourse(Grosz and Sidner, 1986). When an article is comprised of text and graphics, the graphic generally expands on the text and contributes to the discourse purpose of the article. Consider the graphic and partial surrounding text reproduced in Figure 6. Nowhere in the text is it stated that the income of black women has risen dramatically over the last decade and has reached the level of white women. Yet this message is clearly conveyed by the graphic and contributes to the overall communicative intention of this portion of the article — namely, that there has been a “monumental shifting of the sands” with regard to the </context>
</contexts>
<marker>Grosz, Sidner, 1986</marker>
<rawString>B. Grosz and C. Sidner. 1986. Attention, Intentions, and the Structure of Discourse. Computational Linguistics, 12(3):175–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B John</author>
<author>A Newell</author>
</authors>
<title>Toward an engineering model of stimulus response compatibility. In</title>
<date>1990</date>
<booktitle>Stimulusresponse compatibility: An integrated approach,</booktitle>
<pages>107--115</pages>
<editor>R. Gilmore and T. Reeve, editors,</editor>
<publisher>North-Holland,</publisher>
<location>New York.</location>
<contexts>
<context position="26400" citStr="John and Newell, 1990" startWordPosition="4208" endWordPosition="4211">hension tasks, and many of our effort estimates are based on Lohse’s research. For example, Figure 4 dis2Primitive perceptual tasks are those that we do not decompose into a set of simpler subtasks; this is not to be confused with the notion of a psychological primitive. plays the APTE rule for the task of finding the value associated with the top of a bar in a bar chart. If the bar is annotated with its value, then condition-computation pair B1-1 estimates its effort as 150 units for discriminating the label (based on work by Lohse(Lohse, 1993)) and 300 units for recognizing a 6-letter word (John and Newell, 1990). If the bar is not annotated with its value but is aligned with a tick mark on the axis, then condition-computation pair B1-2 estimates the perceptual effort in terms of the distance to the dependent axis (in order to capture the degrees of visual arc scanned(Kosslyn, 1989)) plus the effort of discriminating and recognizing the label. Figure 5 displays the APTE rule associated with the first subgoal in Figure 3. It estimates the effort for the primitive task Perceive-info-to-interpolate as the effort of the scan to the dependent axis (based on (Kosslyn, 1989)), the effort of discriminating th</context>
</contexts>
<marker>John, Newell, 1990</marker>
<rawString>B. John and A. Newell. 1990. Toward an engineering model of stimulus response compatibility. In R. Gilmore and T. Reeve, editors, Stimulusresponse compatibility: An integrated approach, pages 107–115. North-Holland, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kennel</author>
</authors>
<title>Audiograf: A diagram-reader for the blind.</title>
<date>1996</date>
<booktitle>In Second Annual ACM Conference on Assistive Technologies,</booktitle>
<pages>51--56</pages>
<contexts>
<context position="4653" citStr="Kennel, 1996" startWordPosition="687" endWordPosition="688">hallenging problems. Although devices have been developed for conveying information graphics in alternative mediums such as musical tones or tactile images, these approaches have serious limitations. For example, systems that attempt to convey graphics via a soundscape(Meijer, 1992) do not facilitate easy comparison of two line graphs linked in a single graphical display. Moreover, these approaches require the user to construct a “mental map” of the graphic, which is difficult for congenitally blind users who do not have the personal knowledge to assist them in the interpretation of the image(Kennel, 1996). The underlying hypothesis of our work is that alternative access to what the graphic looks like is not enough — the user should be provided with the message and knowledge that one would gain from viewing the graphic in order to enable effective and efficient use of this information resource. To accomplish this objective, we are developing an interactive natural language system for communicating the content of an information graphic. Our methodology offers promise as a means of providing access to information graphics without expensive equipment, with few limitations on the complexity of the </context>
</contexts>
<marker>Kennel, 1996</marker>
<rawString>A. Kennel. 1996. Audiograf: A diagram-reader for the blind. In Second Annual ACM Conference on Assistive Technologies, pages 51–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kerpedjiev</author>
<author>S Roth</author>
</authors>
<title>Mapping communicative goals into conceptual tasks to generate graphics in discourse.</title>
<date>2000</date>
<booktitle>In Proc. of the International Conference on Intelligent User Interfaces,</booktitle>
<pages>60--67</pages>
<contexts>
<context position="8220" citStr="Kerpedjiev and Roth, 2000" startWordPosition="1260" endWordPosition="1263"> language. As noted by Clark(Clark, 1996), language is more than just words. It is any “signal” (or lack of signal when one is expected), where a signal is a deliberate action that is intended to convey a message. According to speech act theory, a speaker or writer executes a speech act whose intended meaning he expects the listener or reader to be able to deduce(Searle, 1970; Grice, 1969; Clark, 1996). In their work on multimedia generation, Figure 1: System Architecture the AutoBrief group proposed that speech act theory could be extended to cover the generation of graphical representations(Kerpedjiev and Roth, 2000). They developed a multimedia presentation system that generated text and information graphics. It included 1) an algorithm that could map communicative goals to a set of perceptual and cognitive tasks that must be enabled for a viewer to recognize the goals and 2) an automatic graph designer that used constraint satisfaction to construct an information graphic that best facilitated those tasks, subject to competing constraints among the tasks. The overwhelming majority of information graphics accompanying newspaper and magazine articles appear to carry a message that the designer intends to c</context>
<context position="19091" citStr="Kerpedjiev and Roth, 2000" startWordPosition="3022" endWordPosition="3025">ards to higher-level goals which the lower-level subgoals contribute to achieving. In the case of traditional discourse and dialogue, the subgoals in the plan operators are either communicative or domain goals, and the observed actions that start the plan inference process are the speech acts represented by the utterances in a story or a dialogue. To extend plan inference to information graphics, the plan operators must include goals that can be accomplished by viewing an information graphic, as opposed to being the recipient of an utterance. As discussed in Section 4.1, the AutoBrief project(Kerpedjiev and Roth, 2000) developed an algorithm to map communicative goals to a sequence of perceptual and cognitive tasks that the graphic should support. Perceptual tasks are tasks that can be performed by simply viewing the graphic, such as finding the top of a bar in a bar chart; cognitive tasks are tasks that are performed via mental computations, such as computing the difference between two numbers. We draw on the AutoBrief notion of perceptual and cognitive tasks enabled by an information graphic. Our plan operators not only encode knowledge about how to achieve domain and communicative goals (the latter of wh</context>
<context position="23124" citStr="Kerpedjiev and Roth, 2000" startWordPosition="3667" endWordPosition="3670">Beginning the Plan Inference Process Traditional plan inference systems used for language understanding start with the primitive goal achieved by the speech act in the dialogue or discourse. In the case of information graphics, the role of the speech act is played by the primitive perceptual tasks that the viewer performs on the graphic. To limit the set of perceptual tasks that are considered, we make two observations: • The graphic designer has many alternative ways of designing a graphic, and the design choices facilitate some perceptual tasks more than others. Following the AutoBrief work(Kerpedjiev and Roth, 2000) on generating graphics that fulfill communicative goals, we hypothesize that the designer chooses a design that best facilitates the tasks that are most important to conveying his intended message, subject to the constraints imposed by competing tasks. • Entities may become particularly salient by virtue of highlighting in the graphic (for example, coloring certain elements different from the others, annotating an element with an asterisk, or exploding one piece of a pie chart1), by their mention in the caption or surrounding text, or via world knowledge 1(Mittal, 1997) discusses a variety of</context>
</contexts>
<marker>Kerpedjiev, Roth, 2000</marker>
<rawString>S. Kerpedjiev and S. Roth. 2000. Mapping communicative goals into conceptual tasks to generate graphics in discourse. In Proc. of the International Conference on Intelligent User Interfaces, pages 60–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Kosslyn</author>
</authors>
<title>Understanding charts and graphs.</title>
<date>1989</date>
<journal>Applied Cognitive Psychology,</journal>
<pages>3--185</pages>
<contexts>
<context position="26675" citStr="Kosslyn, 1989" startWordPosition="4257" endWordPosition="4258">PTE rule for the task of finding the value associated with the top of a bar in a bar chart. If the bar is annotated with its value, then condition-computation pair B1-1 estimates its effort as 150 units for discriminating the label (based on work by Lohse(Lohse, 1993)) and 300 units for recognizing a 6-letter word (John and Newell, 1990). If the bar is not annotated with its value but is aligned with a tick mark on the axis, then condition-computation pair B1-2 estimates the perceptual effort in terms of the distance to the dependent axis (in order to capture the degrees of visual arc scanned(Kosslyn, 1989)) plus the effort of discriminating and recognizing the label. Figure 5 displays the APTE rule associated with the first subgoal in Figure 3. It estimates the effort for the primitive task Perceive-info-to-interpolate as the effort of the scan to the dependent axis (based on (Kosslyn, 1989)), the effort of discriminating the intersection location on the axis (150 units based on (Lohse, 1993)), plus the effort of the saccade to each label (230 units each (Russo, 1978)) along with the effort involved in discriminating and recognizing the labels. Similarly, there is a cognitive rule (not discusse</context>
</contexts>
<marker>Kosslyn, 1989</marker>
<rawString>S. Kosslyn. 1989. Understanding charts and graphs. Applied Cognitive Psychology, 3:185–226.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Litman</author>
<author>J Allen</author>
</authors>
<title>A Plan Recognition Model for Subdialogues in Conversation. Cognitive Science,</title>
<date>1987</date>
<pages>11--163</pages>
<contexts>
<context position="17366" citStr="Litman and Allen, 1987" startWordPosition="2743" endWordPosition="2746">e chart component in question. The output of the visual extraction component is an XML file that describes the chart and all of its components. 4.4 Applying Discourse Understanding Strategies Many researchers have cast the understanding of discourse and dialogue as a plan recognition problem — that is, the writer or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators. Each operator encodes a goal in its he</context>
<context position="32494" citStr="Litman and Allen, 1987" startWordPosition="5206" endWordPosition="5209">operators whose body contains the root goal as a subgoal produces larger candidate plans with higher-level goals as the new root goal. Plan inference systems have used a variety of heuristics to evaluate candidate plans and to select the candidate plan to expand further. These heuristics help to guide the search through the space of candidate plans in order to hypothesize the plan that best represents the user’s intentions. These heuristics have included increasing the rating of partial plans as their arguments become instantiated(Perrault and Allen, 1980), preferring coherent discourse moves(Litman and Allen, 1987; Carberry, 1990), and biasing the plan inference process based on knowledge about the user group(Gertner and Webber, 1996). We have identified several kinds of evidence for guiding plan inference from information graphics, including the estimated effort required by a candidate plan, the basis for instantiating parameters in the plan, adherence to the proximity compatibility principle from cognitive science research, and the relation between a candidate plan and the established discourse context. Since our working hypothesis is that the graphic designer tried to enable those tasks necessary to</context>
</contexts>
<marker>Litman, Allen, 1987</marker>
<rawString>D. Litman and J. Allen. 1987. A Plan Recognition Model for Subdialogues in Conversation. Cognitive Science, 11:163–200.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Lohse</author>
</authors>
<title>A cognitive model for understanding graphical perception. Human-Computer Interaction,</title>
<date>1993</date>
<pages>8--353</pages>
<contexts>
<context position="25689" citStr="Lohse, 1993" startWordPosition="4084" endWordPosition="4085">ditions (graphic design choices) that affect the difficulty of performing that task, and the estimated effort expended by a viewer if those conditions are satisfied in the graphic. The condition-computation pairs are ordered so that the ones producing the lowest effort estimates appear first in a rule. To derive the effort estimates in the rules, we have followed the GOMS approach(Card et al., 1983) by breaking down the tasks that are regarded as primitive in our plan operators into even more basic component tasks, and then summing the effort estimates for these very basic tasks. Lohse’s work(Lohse, 1993) is an example of the GOMS architecture applied to predicting performance on graph comprehension tasks, and many of our effort estimates are based on Lohse’s research. For example, Figure 4 dis2Primitive perceptual tasks are those that we do not decompose into a set of simpler subtasks; this is not to be confused with the notion of a psychological primitive. plays the APTE rule for the task of finding the value associated with the top of a bar in a bar chart. If the bar is annotated with its value, then condition-computation pair B1-1 estimates its effort as 150 units for discriminating the la</context>
<context position="27069" citStr="Lohse, 1993" startWordPosition="4320" endWordPosition="4321">ed with a tick mark on the axis, then condition-computation pair B1-2 estimates the perceptual effort in terms of the distance to the dependent axis (in order to capture the degrees of visual arc scanned(Kosslyn, 1989)) plus the effort of discriminating and recognizing the label. Figure 5 displays the APTE rule associated with the first subgoal in Figure 3. It estimates the effort for the primitive task Perceive-info-to-interpolate as the effort of the scan to the dependent axis (based on (Kosslyn, 1989)), the effort of discriminating the intersection location on the axis (150 units based on (Lohse, 1993)), plus the effort of the saccade to each label (230 units each (Russo, 1978)) along with the effort involved in discriminating and recognizing the labels. Similarly, there is a cognitive rule (not discussed here) for estimating the effort associated with the cognitive task Interpolate (the second subgoal in the operator in Figure 3). (Elzer et al., 2003a) presents a more extensive discussion of the cognitive principles underlying the APTE rules. Given the XML representation of an information graphic, each APTE rule that is applicable to the graphic produces an effort estimate for the task cap</context>
</contexts>
<marker>Lohse, 1993</marker>
<rawString>G. Lohse. 1993. A cognitive model for understanding graphical perception. Human-Computer Interaction, 8:353–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter B Meijer</author>
</authors>
<title>An experimental system for auditory image representations.</title>
<date>1992</date>
<journal>IEEE Transactions on Biomedical Engineering,</journal>
<volume>39</volume>
<issue>2</issue>
<contexts>
<context position="4323" citStr="Meijer, 1992" startWordPosition="632" endWordPosition="633">on-making. But information is useful only if it is accessible in a form that can be easily assimilated. For sighted users, information graphics capture complex information and enable it to be assimilated perceptually with ease. For individuals who have serious sight-impairments, documents that contain information graphics pose challenging problems. Although devices have been developed for conveying information graphics in alternative mediums such as musical tones or tactile images, these approaches have serious limitations. For example, systems that attempt to convey graphics via a soundscape(Meijer, 1992) do not facilitate easy comparison of two line graphs linked in a single graphical display. Moreover, these approaches require the user to construct a “mental map” of the graphic, which is difficult for congenitally blind users who do not have the personal knowledge to assist them in the interpretation of the image(Kennel, 1996). The underlying hypothesis of our work is that alternative access to what the graphic looks like is not enough — the user should be provided with the message and knowledge that one would gain from viewing the graphic in order to enable effective and efficient use of th</context>
</contexts>
<marker>Meijer, 1992</marker>
<rawString>Peter B. Meijer. 1992. An experimental system for auditory image representations. IEEE Transactions on Biomedical Engineering, 39(2):291–300, February.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Mittal</author>
</authors>
<title>Visual prompts and graphical design: A framework for exploring the design space of 2-D charts and graphs.</title>
<date>1997</date>
<booktitle>In Proc. of the Fourteenth National Conference on Artificial Intelligence,</booktitle>
<pages>57--63</pages>
<contexts>
<context position="23701" citStr="Mittal, 1997" startWordPosition="3760" endWordPosition="3761">rief work(Kerpedjiev and Roth, 2000) on generating graphics that fulfill communicative goals, we hypothesize that the designer chooses a design that best facilitates the tasks that are most important to conveying his intended message, subject to the constraints imposed by competing tasks. • Entities may become particularly salient by virtue of highlighting in the graphic (for example, coloring certain elements different from the others, annotating an element with an asterisk, or exploding one piece of a pie chart1), by their mention in the caption or surrounding text, or via world knowledge 1(Mittal, 1997) discusses a variety of such design techniques in the context of distorting the message inferred from a graphic. capturing mutual beliefs about entities of interest to the intended audience. We hypothesize that the designer relies on the viewer recognizing particularly salient entities, in order to make certain perceptual tasks more salient to the viewer. As noted in Section 4.1, one cannot rely on a graphic’s caption to provide the intended message of the graphic. Consequently, the plan inference process starts with both the set of tasks that are best enabled by the information graphic and th</context>
</contexts>
<marker>Mittal, 1997</marker>
<rawString>V. Mittal. 1997. Visual prompts and graphical design: A framework for exploring the design space of 2-D charts and graphs. In Proc. of the Fourteenth National Conference on Artificial Intelligence, pages 57–63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Perrault</author>
<author>J Allen</author>
</authors>
<title>A Plan-Based Analysis of Indirect Speech Acts.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics,</journal>
<pages>6--3</pages>
<contexts>
<context position="17326" citStr="Perrault and Allen, 1980" startWordPosition="2737" endWordPosition="2740"> wedges and lines by their proximity to the chart component in question. The output of the visual extraction component is an XML file that describes the chart and all of its components. 4.4 Applying Discourse Understanding Strategies Many researchers have cast the understanding of discourse and dialogue as a plan recognition problem — that is, the writer or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators</context>
<context position="32434" citStr="Perrault and Allen, 1980" startWordPosition="5199" endWordPosition="5202">the body of the operator. Chaining from the root goal to other operators whose body contains the root goal as a subgoal produces larger candidate plans with higher-level goals as the new root goal. Plan inference systems have used a variety of heuristics to evaluate candidate plans and to select the candidate plan to expand further. These heuristics help to guide the search through the space of candidate plans in order to hypothesize the plan that best represents the user’s intentions. These heuristics have included increasing the rating of partial plans as their arguments become instantiated(Perrault and Allen, 1980), preferring coherent discourse moves(Litman and Allen, 1987; Carberry, 1990), and biasing the plan inference process based on knowledge about the user group(Gertner and Webber, 1996). We have identified several kinds of evidence for guiding plan inference from information graphics, including the estimated effort required by a candidate plan, the basis for instantiating parameters in the plan, adherence to the proximity compatibility principle from cognitive science research, and the relation between a candidate plan and the established discourse context. Since our working hypothesis is that t</context>
<context position="34262" citStr="Perrault and Allen, 1980" startWordPosition="5487" endWordPosition="5490">on is suggested by highlighting or a caption or entities that are particularly salient to the targeted audience, that partial plan should be evaluated more favorably since the designer of the graphic has provided reasons for the viewer to use these instantiations in recognizing his intentions. Similarly, if the instantiation is one of several possible alternatives with no reason for preferring one over the other, then the partial plan should be evaluated less favorably since the designer did not give the viewer any reason to prefer one over the other. This relates to Allen’s forking heuristic(Perrault and Allen, 1980). The proximity compatibility principle(Wickens and Carswell, 1995) also suggests that candidate plans which use similarly encoded elements (for example, all red bars) in an integrated fashion should be evaluated more favorably than those that do not. If there is a context established by the text preceding or surrounding the graphic, then candidate plans whose root goal contributes to the existing discourse context should be preferred. If the surrounding text has a reference to the graphic, then focusing heuristics(Carberry, 1990) will prefer candidate plans that relate most closely to the cur</context>
</contexts>
<marker>Perrault, Allen, 1980</marker>
<rawString>R. Perrault and J. Allen. 1980. A Plan-Based Analysis of Indirect Speech Acts. American Journal of Computational Linguistics, 6(3-4):167–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Russo</author>
</authors>
<title>Adaptation of cognitive processes to eye movement systems.</title>
<date>1978</date>
<editor>In J. Senders, D. Fisher, and R. Monty, editors,</editor>
<location>Hillsdale, NJ.</location>
<contexts>
<context position="27146" citStr="Russo, 1978" startWordPosition="4335" endWordPosition="4336">es the perceptual effort in terms of the distance to the dependent axis (in order to capture the degrees of visual arc scanned(Kosslyn, 1989)) plus the effort of discriminating and recognizing the label. Figure 5 displays the APTE rule associated with the first subgoal in Figure 3. It estimates the effort for the primitive task Perceive-info-to-interpolate as the effort of the scan to the dependent axis (based on (Kosslyn, 1989)), the effort of discriminating the intersection location on the axis (150 units based on (Lohse, 1993)), plus the effort of the saccade to each label (230 units each (Russo, 1978)) along with the effort involved in discriminating and recognizing the labels. Similarly, there is a cognitive rule (not discussed here) for estimating the effort associated with the cognitive task Interpolate (the second subgoal in the operator in Figure 3). (Elzer et al., 2003a) presents a more extensive discussion of the cognitive principles underlying the APTE rules. Given the XML representation of an information graphic, each APTE rule that is applicable to the graphic produces an effort estimate for the task captured by the rule. When a task might be instantiated in multiple ways and sti</context>
</contexts>
<marker>Russo, 1978</marker>
<rawString>J. Russo. 1978. Adaptation of cognitive processes to eye movement systems. In J. Senders, D. Fisher, and R. Monty, editors, Eye movements and higher psychological functions. Lawrence Erlbaum, Hillsdale, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Searle</author>
</authors>
<title>Speech Acts: An Essay in the Philosophy ofLanguage.</title>
<date>1970</date>
<publisher>Cambridge University Press,</publisher>
<location>London.</location>
<contexts>
<context position="7972" citStr="Searle, 1970" startWordPosition="1226" endWordPosition="1227">he rest of the system. The Appendix contains information graphics that are part of the corpus on which our work is based. 4 Understanding Information Graphics 4.1 Intention in Information Graphics Information graphics are a variant of language. As noted by Clark(Clark, 1996), language is more than just words. It is any “signal” (or lack of signal when one is expected), where a signal is a deliberate action that is intended to convey a message. According to speech act theory, a speaker or writer executes a speech act whose intended meaning he expects the listener or reader to be able to deduce(Searle, 1970; Grice, 1969; Clark, 1996). In their work on multimedia generation, Figure 1: System Architecture the AutoBrief group proposed that speech act theory could be extended to cover the generation of graphical representations(Kerpedjiev and Roth, 2000). They developed a multimedia presentation system that generated text and information graphics. It included 1) an algorithm that could map communicative goals to a set of perceptual and cognitive tasks that must be enabled for a viewer to recognize the goals and 2) an automatic graph designer that used constraint satisfaction to construct an informat</context>
</contexts>
<marker>Searle, 1970</marker>
<rawString>J. Searle. 1970. Speech Acts: An Essay in the Philosophy ofLanguage. Cambridge University Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Silber</author>
<author>K McCoy</author>
</authors>
<title>Efficient text summarization using lexical chains.</title>
<date>2000</date>
<booktitle>In Proc. of the International Conference on Intelligent User Interfaces,</booktitle>
<pages>252--255</pages>
<contexts>
<context position="31180" citStr="Silber and McCoy, 2000" startWordPosition="4990" endWordPosition="4993">ributes of these highlighted items (for example, the attributes of a highlighted bar in a bar chart), which are captured in the XML represen3Verb phrases in captions also provide evidence, but they suggest particular operators of interest rather than instantiated perceptual tasks, and thus we associate verbs with operators in the plan library. tation of the graphic, are also regarded as salient entities. Salient entities also include those that world knowledge suggests are mutually believed to be of interest to the viewing audience. We envision in the future using the notion of lexical chains(Silber and McCoy, 2000) to identify entities that the accompanying text makes particularly salient. Perceptual tasks that are instantiated with a salient entity and that can be performed on the graphic are designated salient tasks. 4.4.2 The Search Process Candidate tasks consist of the set of perceptual tasks that require the least effort and the set of salient tasks. Once the set of candidate tasks has been identified, plan inference begins. Initial candidate plans are constructed from each operator in which a candidate task appears as a subgoal; the root of the candidate plan is the goal of the operator, and its </context>
</contexts>
<marker>Silber, McCoy, 2000</marker>
<rawString>G. Silber and K. McCoy. 2000. Efficient text summarization using lexical chains. In Proc. of the International Conference on Intelligent User Interfaces, pages 252–255.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Wickens</author>
<author>M Carswell</author>
</authors>
<title>The proximity compatibility principle: Its psychological foundation and relevance to display design.</title>
<date>1995</date>
<journal>Human Factors,</journal>
<volume>37</volume>
<issue>3</issue>
<contexts>
<context position="34329" citStr="Wickens and Carswell, 1995" startWordPosition="5495" endWordPosition="5498"> particularly salient to the targeted audience, that partial plan should be evaluated more favorably since the designer of the graphic has provided reasons for the viewer to use these instantiations in recognizing his intentions. Similarly, if the instantiation is one of several possible alternatives with no reason for preferring one over the other, then the partial plan should be evaluated less favorably since the designer did not give the viewer any reason to prefer one over the other. This relates to Allen’s forking heuristic(Perrault and Allen, 1980). The proximity compatibility principle(Wickens and Carswell, 1995) also suggests that candidate plans which use similarly encoded elements (for example, all red bars) in an integrated fashion should be evaluated more favorably than those that do not. If there is a context established by the text preceding or surrounding the graphic, then candidate plans whose root goal contributes to the existing discourse context should be preferred. If the surrounding text has a reference to the graphic, then focusing heuristics(Carberry, 1990) will prefer candidate plans that relate most closely to the current focus of attention at that point in the surrounding text. Howe</context>
</contexts>
<marker>Wickens, Carswell, 1995</marker>
<rawString>C. Wickens and M. Carswell. 1995. The proximity compatibility principle: Its psychological foundation and relevance to display design. Human Factors, 37(3):473–494.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wilensky</author>
</authors>
<title>Planning and Understanding.</title>
<date>1983</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="17342" citStr="Wilensky, 1983" startWordPosition="2741" endWordPosition="2742"> proximity to the chart component in question. The output of the visual extraction component is an XML file that describes the chart and all of its components. 4.4 Applying Discourse Understanding Strategies Many researchers have cast the understanding of discourse and dialogue as a plan recognition problem — that is, the writer or speaker (or characters in the case of a story) has an underlying goal and a plan for accomplishing that goal, and understanding requires that the reader or listener infer the plan and in turn the goal that the plan is intended to achieve. (Perrault and Allen, 1980; Wilensky, 1983; Litman and Allen, 1987; Carberry, 1990; Charniak and Goldman, 1993; Ardisonno and Sestero, 1996) are just a few examples of such systems. Since understanding information graphics is a discourse-level problem, we are extending plan inference techniques to recognizing the intended message of an information graphic(Elzer et al., 2003) and to identifying its contribution to an extended discourse that includes both text and graphics. Planning and plan inference systems require knowledge about goals and how they can be achieved. Typically, this is provided by a library of operators. Each operator </context>
</contexts>
<marker>Wilensky, 1983</marker>
<rawString>R. Wilensky. 1983. Planning and Understanding. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Yu</author>
<author>J Hunter</author>
<author>E Reiter</author>
<author>S Sripada</author>
</authors>
<title>Recognising visual patterns to communicate gas turbine time-series data. In</title>
<date>2002</date>
<booktitle>ES2002,</booktitle>
<pages>105--118</pages>
<contexts>
<context position="2196" citStr="Yu et al., 2002" startWordPosition="311" endWordPosition="314">to other forms of communication. Information graphics are prevalent in information resources since they enable complex information to be assimilated perceptually with ease. Unfortunately, knowledge sources such as information graphics are not accessible to some users. For example, individuals with im0The work of the third author was supported by the National Science Foundation under Grant No. 0132821. paired eyesight have limited access to information graphics, thus preventing them from fully utilizing information resources. Some information graphics are only intended to display data values; (Yu et al., 2002) developed a pattern recognition algorithm for summarizing interesting features of automatically generated graphics of time-series data from a gas turbine engine. However, the overwhelming majority of the graphics that we have examined (taken from newspaper, magazine, and web articles) appear to have some underlying goal, such as getting the viewer to believe that interest rates have fallen substantially and that this would therefore be a good time to refinance a mortgage. We have found that understanding information graphics is a discourse-level problem. In particular, it requires assimilatin</context>
</contexts>
<marker>Yu, Hunter, Reiter, Sripada, 2002</marker>
<rawString>J. Yu, J. Hunter, E. Reiter, and S. Sripada. 2002. Recognising visual patterns to communicate gas turbine time-series data. In ES2002, pages 105– 118.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>