<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010714">
<title confidence="0.9696585">
A hybrid approach to the development of dialogue systems
directed by semantics
</title>
<author confidence="0.965016">
Emilio Sanchis, Isabel Galiano, Fernando Garcia, Antonio Cano
</author>
<affiliation confidence="0.726761666666667">
Departamento de Sistemas Informaticos y Computacion
Universidad Politecnica de Valencia
Camino de Vera s/n, 46020-Valencia, SPAIN
</affiliation>
<email confidence="0.993342">
esanchis,mgaliano,fgarcia,acano@dsic.upv.es
</email>
<sectionHeader confidence="0.979661" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999941333333333">
In this work we present an approach
to the development of the BA-
SURDE1 dialogue system, which an-
swers telephone queries about rail-
way timetables in Spanish. We will
focus on the understanding and di-
alogue components which are mod-
eled under a stochastic framework.
The preliminary results from seman-
tic and dialogue interpretations of
user dialogue turns are also included
in this work.
</bodyText>
<sectionHeader confidence="0.996303" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.996867948717949">
In the development of dialogue systems many
knowledge sources must be taken into ac-
count. The specific characteristics of each
knowledge source imply that different kinds
of models and different architectures can be
used. It is widely accepted that stochastic
models are a good representation for some
of these knowledge sources and some spe-
cific works have been done to represent the
semantic of the sentences and the dialogue
structure (Pieraccini et al., 1997)(Baggia et
al., 1999)(Lamel et al., 2000)(Martinez et al.,
2000)(Segarra et al., 2001).
We present an approach in which the dia-
logue structure is represented by a stochastic
network of dialogue acts. One advantage of
this kind of network is that it can be learnt
from annotated training samples. Moreover,
it gives us a prediction of the next dialogue
acts which are expected from the user as well
Work partially funded by CICYT under project
TIC98-0423-C06
as some information about the possible dia-
logue acts that can be generated by the sys-
tem. The identification of the user dialogue
acts is done through the semantic represen-
tation of the sentence. This semantic inter-
pretation not only supplies the corresponding
dialogue act but also supplies the informa-
tion given about the query constraints, such
us Date, Departure city, etc.
To be able to provide the information re-
quested by the user, the system has to man-
age the values supplied by the user during the
conversation. We do this by means of a record
of current values that is updated after each
user turn and is used to generate the database
queries and to participate in the generation of
the dialogue turns of the system.
</bodyText>
<sectionHeader confidence="0.705359" genericHeader="method">
2 The Dialogue module
</sectionHeader>
<bodyText confidence="0.999977473684211">
The dialogue model proposed is a stochastic
network which is automatically learnt from
a training set of dialogue samples obtained
by the Wizard of Oz technique (Figure 1).
A dialogue sample is a concatenation of di-
alogue acts which represents the translation
of a given user utterance into a sentence of a
dialogue act language.
One important decision is the definition of
the set of dialogue acts associated to the ap-
plication. If we establish a low number of
dialogue acts that are independent from the
task, we can expect a good modelization of
the dialogue structure and an easy identifica-
tion of the dialogue acts which are generated
by the user; we could also change the applica-
tion without having to make many changes in
the dialogue model. However, in order for the
system to generate its dialogue turn, more in-
</bodyText>
<figure confidence="0.997391333333333">
U:Opening:Nil
M:New_question:Nil
M:Answer:Departure_time
M:Closing:Nil
M:Opening:Nil
U:Closing:Nil
DataBase Answer
U:Question:Departure_time
DataBase Query
ANSWER
GENERATION
DataBase
(Departure_time)
Departure_city:Valencia
Arrival_city:Barcelona
Date: 23/06/2001
...
Record _of_Current_Values
</figure>
<figureCaption confidence="0.999753">
Figure 1: An example of a part of the Dialogue model.
</figureCaption>
<bodyText confidence="0.999900433333333">
formation about the content of the sentences
is required.
If we increase the number of dialogue acts
so that each dialogue act has a more specific
meaning, then the variability of decisions (or
actions) associated to each state in the net-
work is reduced. In other words, a dialogue
act will have a very specific intention, but
we will need a huge number of labeled dia-
logues to learn the model. For example, if
the act is Question there are many kinds of
questions associated to it, but if the act is
Question:Departure time it only represents a
question about the departure time.
Since a balance between the number of la-
bels and the model structure is needed, within
the BASURDE project we have defined a set
of three-level dialogue acts. This set repre-
sents not only information about a general di-
alogue behaviour but also information about
the task (Martinez et al., 2000).
The first level of each dialogue act labels
the dialogue behaviour. The labels we define
at this level are generic for any task. The sec-
ond level is related to the semantic represen-
tation of a sentence and it is specific to the
task. In the Dialogue model presented here
only the first two levels are considered.
The following labels have been de-
fined for the first level: Opening, Clos-
</bodyText>
<construct confidence="0.70856">
ing, Undefined, Not understood, Waiting,
Affirmation, Rejection, Question, Con-
</construct>
<bodyText confidence="0.941478191489362">
firmation, Answer. The labels defined
for the second level are: Departure time,
Return departure time, Arrival time, Re-
turn arrival time, Price, Departure city,
Arrival city, Lenght of trip, Stops, Depar-
ture date, Arrival date, Train type, Services.
For example, a dialogue turn can be labeled
as follows:
Me puede decir el horario de los trenes a Valencia
el proximo lunes ?
(Can you tell me the timetable to Valencia for
next Monday ?)
(Question: Departure time)
The stochastic network representing the Di-
alogue model is obtained from a training set
of dialogues which are labeled in terms of dia-
logue act sequences. This network is built by
using the bigram probabilities.
The dialogue act network can be used in
two ways:
- To predict the next dialogue act of the
user; helping the recognition and understand-
ing processes.
- To decide the next action of the system.
As there are not enough samples to learn an
accurate model this decision making process
should be driven by the semantics.
Now we will describe how the dialogue
manager works. It has two main compo-
nents: the dialogue network and the record
of current values. The input of this mod-
ule is supplied by the Understanding module.
This input is a frame representation of the
semantic information obtained from the user
turn. We can extract the corresponding di-
alogue act from each input frame as well as
the constraints about the query given by the
user. The Dialogue Manager uses this infor-
mation in two ways: it determines the next di-
alogue transition to be made and updates the
record of current values using the constraints
obtained from the query.
The Dialogue Manager output, which is
also a frame representation, is sent to the an-
swer generator and then to the synthesizer.
The dynamics of this process is given by the
following Dialogue Manager algorithm:
</bodyText>
<figure confidence="0.9717575">
/*Initialization*/
Put State=Opening
Init(Record of Current Values) /*Init(RCV)*/
Repeat
Sentence=obtain sentence from the user turn
Frame=extract meaning(Sentence)
State=Transition to(State,Frame)
RCV=Update(Frame)
/* actions of the manager */
if complete query(RCV)
then
Send Database query
State=Choose transition
else
select transitions permitted by RCV
State=Choose one of these selected transitions
Generate output frame
until State=Closing
</figure>
<bodyText confidence="0.999833384615385">
The dialogue manager accepts the frames
obtained from the user turn as input. First
it modifies the record of current values if nec-
essary. If there is enough information in this
record, a query to the database is made, an
output frame with the answer is generated,
and a transition in the dialogue network is
made. Otherwise the record of current values
is used to determine which transitions of the
dialogue network should be pruned, i.e. those
that are not compatible with the updated in-
formation. This situation occurs because the
model is learnt from a limited set of samples
and it is a bigram model with just one label
history, and then the constraints given in pre-
vious turns can not be taken into account.
For example, one of the transitions of the
network might imply asking the user about
the departure city and this information has
already been given in a previous turn. In
this case the corresponding transition would
be forbidden. After the set of allowed tran-
sitions is determined, one of them is selected
and the corresponding output frame is gener-
ated. The process finish when a Closing label
is found.
</bodyText>
<sectionHeader confidence="0.921849" genericHeader="method">
3 The Understanding module
</sectionHeader>
<bodyText confidence="0.999986954545455">
We use frames to represent the meaning of
sentences. Each frame represents a concept
and can have some attributes associated to
it. We have defined 18 types of frames; some
of them are related to the task (for example
Departure time, Price, etc.), and others are
related to the general characteristics of the
dialogues (for example, Not understood, Af-
firmation, etc.). Note that each type of frame
has a corresponding dialogue act associated
to it.
We use a two phases approach for the un-
derstanding process (Figure 2). In the first
phase a sequence of semantic units and its
corresponding segmentation is obtained from
an input sentence. In the second phase one or
more frames are extracted from this semantic
sentence.
The first phase is implemented from a
stochastic transduction point of view (Segarra
et al., 2001); that is, the input sentence (in
words) is translated into an output sentence
of a semantic language. The vocabulary of
this semantic language is composed by a set
of semantic units, that represents meanings of
segments of words.
The segmentation of these sentences allows
us to define two kind of stochastic models:
the Semantic model and the Semantic-Unit
model. The Semantic model represents the
allowed sequences of semantic units and their
probabilities. The Semantic-Unit model rep-
resents the allowed sequences of words and
their probabilities which are associated to
each semantic unit.
These models can be automatically learnt
from a set of annotated training samples. In
this work, we have used bigram models, but
any other type of stochastic model, like n-
grams or automata learnt by Grammatical
Inference techniques (Segarra et al., 2001),
could be used. These models can be inte-
grated into a unique understanding model;
each semantic unit of the Semantic model
</bodyText>
<figure confidence="0.959627842105263">
Can you tell me the timetable
to Valencia for next Monday ?
INPUT SENTENCE
ORTOGRAPHIC/
SEMANTIC
DECODING
Can you tell me:Query
(Departure_time)
to:Destination_marker
Destination_city: Valencia
Valencia:Destination_city
Departure_date: 14/05/2001
SECUENCE OF PAIRS
SEGMENT/SEMANTIC UNIT
the timetable:&lt;Departure_time&gt;
for next Monday:Departure_date
FRAME
GENERATION
FRAME
</figure>
<figureCaption confidence="0.999879">
Figure 2: Transduction approach in two phases.
</figureCaption>
<bodyText confidence="0.99987415">
is substituted by its corresponding Semantic-
Unit model.
As we already have the Dialogue model of
the system, we can obtain a specific Semantic
model for each user dialogue act. However,
the use of specific models can lead to a lack
of training samples and therefore to the use
of tied models. In our case, we have defined
only specific models for the first level of our
set of dialogue labels.
A Viterbi decoding algorithm supplies the
most likely sequence of semantic units for the
input sentence and its corresponding segmen-
tation. As the output of the Understanding
module is a frame, a set of rules is applied to
obtain the corresponding frame. These rules
permit us to leave behind semantic units such
as courtesy, markers, etc., and select only the
semantic units that have a corresponding slot
associated to the frame.
</bodyText>
<sectionHeader confidence="0.999179" genericHeader="evaluation">
4 Experimental Results
</sectionHeader>
<bodyText confidence="0.999979785714286">
In this section we report the preliminary re-
sults from semantic and dialogue interpreta-
tions of user dialogue turns.
We defined a training set of 175 dialogues
with 1,141 user utterances and a test set of
40 dialogues with 268 user utterances from
the orthographic transcription of a set of 215
dialogues, obtained through a Wizard of Oz
technique. The number of words in these two
sets was 11,987 and the medium length of
the utterances was 10.5 words. The percent-
age of correctly understood sentences (correct
frames) was 80%, and the percentage of cor-
rect user dialogue act identification was 87%.
</bodyText>
<sectionHeader confidence="0.999303" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999930928571429">
We have presented an approach for the devel-
opment of dialogue systems based on stochas-
tic models which are automatically learnt
from training samples. We have proposed a
system architecture which includes an Under-
standing module that extracts the semantics
of the user turns in terms of frames. A prelim-
inary implementation of the system has been
done, and preliminary results are reported.
We hope that the behaviour of the system
improves when we have more dialogue train-
ing samples. We will model other dialogue
situations which were not encountered in our
current training corpus.
</bodyText>
<sectionHeader confidence="0.998057" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996787230769231">
Baggia P., Kelner A., P�erennou E., Popovici C.,
Strum J., Wessel F. 1999. Language Model-
ing and Spoken Dialogue Systems the ARISE
experience. Eurospeech99, pp. 1767{1770.
Bonafonte A., Castell N., LLeida E., Marino J.B.,
Sanchis E., Torres M.I., Aibar P. 2000. Desar-
rollo de un sistema de dialogo oral en domin-
ios restringidos. I Jornadas en Tecnologia del
Habla, Sevilla.
Lamel L., Rosset S., Gauvain J.L., Bennacef S.,
Garnier-Rizet M., Prouts B. 2000. The LIMSI
Arise system. Speech Communication,31, pp.
339{353.
Martinez C., and Casacuberta F. 2000. A pattern
recognition approach to dialog labelling using
finite- state transducers. V Iberoamerican Sym-
posium on Pattern Recognition, pp. 669{677.
Pieraccini R, Levin E., and Eckert W. 1997.
AMICA: the AT&amp;T Mixed Initiative Conver-
sational Architecture. Eurospeech97, pp. 1875{
1878.
Segarra E., Sanchis E., Galiano M., Garcfa F.,
Hurtado L.F. 2001. Extracting semantic infor-
mation through automatic learning techniques.
IX Spanish Symposium on Pattern Recognition
and Image Analysis (AERFAI), Castellon.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.646015">
<title confidence="0.889258">A hybrid approach to the development of dialogue directed by semantics</title>
<author confidence="0.997791">Emilio Sanchis</author>
<author confidence="0.997791">Isabel Galiano</author>
<author confidence="0.997791">Fernando Garcia</author>
<author confidence="0.997791">Antonio</author>
<affiliation confidence="0.977473">Departamento de Sistemas Informaticos y Universidad Politecnica de</affiliation>
<address confidence="0.771638">Camino de Vera s/n, 46020-Valencia,</address>
<email confidence="0.977176">esanchis,mgaliano,fgarcia,acano@dsic.upv.es</email>
<abstract confidence="0.998008230769231">In this work we present an approach to the development of the BAdialogue system, which answers telephone queries about railway timetables in Spanish. We will focus on the understanding and dialogue components which are modeled under a stochastic framework. The preliminary results from semantic and dialogue interpretations of user dialogue turns are also included in this work.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>P Baggia</author>
<author>A Kelner</author>
<author>E P�erennou</author>
<author>C Popovici</author>
<author>J Strum</author>
<author>F Wessel</author>
</authors>
<date>1999</date>
<booktitle>Language Modeling and Spoken Dialogue Systems the ARISE experience. Eurospeech99,</booktitle>
<pages>1767--1770</pages>
<marker>Baggia, Kelner, P�erennou, Popovici, Strum, Wessel, 1999</marker>
<rawString>Baggia P., Kelner A., P�erennou E., Popovici C., Strum J., Wessel F. 1999. Language Modeling and Spoken Dialogue Systems the ARISE experience. Eurospeech99, pp. 1767{1770.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bonafonte</author>
<author>N Castell</author>
<author>E LLeida</author>
<author>J B Marino</author>
<author>E Sanchis</author>
<author>M I Torres</author>
<author>P Aibar</author>
</authors>
<title>Desarrollo de un sistema de dialogo oral en dominios restringidos. I Jornadas en Tecnologia del Habla,</title>
<date>2000</date>
<location>Sevilla.</location>
<marker>Bonafonte, Castell, LLeida, Marino, Sanchis, Torres, Aibar, 2000</marker>
<rawString>Bonafonte A., Castell N., LLeida E., Marino J.B., Sanchis E., Torres M.I., Aibar P. 2000. Desarrollo de un sistema de dialogo oral en dominios restringidos. I Jornadas en Tecnologia del Habla, Sevilla.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Lamel</author>
<author>S Rosset</author>
<author>J L Gauvain</author>
<author>S Bennacef</author>
<author>M Garnier-Rizet</author>
<author>B Prouts</author>
</authors>
<date>2000</date>
<booktitle>The LIMSI Arise system. Speech Communication,31,</booktitle>
<pages>339--353</pages>
<contexts>
<context position="1229" citStr="Lamel et al., 2000" startWordPosition="180" endWordPosition="183">s from semantic and dialogue interpretations of user dialogue turns are also included in this work. 1 Introduction In the development of dialogue systems many knowledge sources must be taken into account. The specific characteristics of each knowledge source imply that different kinds of models and different architectures can be used. It is widely accepted that stochastic models are a good representation for some of these knowledge sources and some specific works have been done to represent the semantic of the sentences and the dialogue structure (Pieraccini et al., 1997)(Baggia et al., 1999)(Lamel et al., 2000)(Martinez et al., 2000)(Segarra et al., 2001). We present an approach in which the dialogue structure is represented by a stochastic network of dialogue acts. One advantage of this kind of network is that it can be learnt from annotated training samples. Moreover, it gives us a prediction of the next dialogue acts which are expected from the user as well Work partially funded by CICYT under project TIC98-0423-C06 as some information about the possible dialogue acts that can be generated by the system. The identification of the user dialogue acts is done through the semantic representation of t</context>
</contexts>
<marker>Lamel, Rosset, Gauvain, Bennacef, Garnier-Rizet, Prouts, 2000</marker>
<rawString>Lamel L., Rosset S., Gauvain J.L., Bennacef S., Garnier-Rizet M., Prouts B. 2000. The LIMSI Arise system. Speech Communication,31, pp. 339{353.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Martinez</author>
<author>F Casacuberta</author>
</authors>
<title>A pattern recognition approach to dialog labelling using finite- state transducers. V Iberoamerican</title>
<date>2000</date>
<booktitle>Symposium on Pattern Recognition,</booktitle>
<pages>669--677</pages>
<marker>Martinez, Casacuberta, 2000</marker>
<rawString>Martinez C., and Casacuberta F. 2000. A pattern recognition approach to dialog labelling using finite- state transducers. V Iberoamerican Symposium on Pattern Recognition, pp. 669{677.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Pieraccini</author>
<author>E Levin</author>
<author>W Eckert</author>
</authors>
<date>1997</date>
<booktitle>AMICA: the AT&amp;T Mixed Initiative Conversational Architecture. Eurospeech97,</booktitle>
<pages>1875--1878</pages>
<contexts>
<context position="1188" citStr="Pieraccini et al., 1997" startWordPosition="174" endWordPosition="177">a stochastic framework. The preliminary results from semantic and dialogue interpretations of user dialogue turns are also included in this work. 1 Introduction In the development of dialogue systems many knowledge sources must be taken into account. The specific characteristics of each knowledge source imply that different kinds of models and different architectures can be used. It is widely accepted that stochastic models are a good representation for some of these knowledge sources and some specific works have been done to represent the semantic of the sentences and the dialogue structure (Pieraccini et al., 1997)(Baggia et al., 1999)(Lamel et al., 2000)(Martinez et al., 2000)(Segarra et al., 2001). We present an approach in which the dialogue structure is represented by a stochastic network of dialogue acts. One advantage of this kind of network is that it can be learnt from annotated training samples. Moreover, it gives us a prediction of the next dialogue acts which are expected from the user as well Work partially funded by CICYT under project TIC98-0423-C06 as some information about the possible dialogue acts that can be generated by the system. The identification of the user dialogue acts is done</context>
</contexts>
<marker>Pieraccini, Levin, Eckert, 1997</marker>
<rawString>Pieraccini R, Levin E., and Eckert W. 1997. AMICA: the AT&amp;T Mixed Initiative Conversational Architecture. Eurospeech97, pp. 1875{ 1878.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Segarra</author>
<author>E Sanchis</author>
<author>M Galiano</author>
<author>F Garcfa</author>
<author>L F Hurtado</author>
</authors>
<title>Extracting semantic information through automatic learning techniques.</title>
<date>2001</date>
<booktitle>IX Spanish Symposium on Pattern Recognition and Image Analysis (AERFAI), Castellon.</booktitle>
<contexts>
<context position="1274" citStr="Segarra et al., 2001" startWordPosition="186" endWordPosition="189">s of user dialogue turns are also included in this work. 1 Introduction In the development of dialogue systems many knowledge sources must be taken into account. The specific characteristics of each knowledge source imply that different kinds of models and different architectures can be used. It is widely accepted that stochastic models are a good representation for some of these knowledge sources and some specific works have been done to represent the semantic of the sentences and the dialogue structure (Pieraccini et al., 1997)(Baggia et al., 1999)(Lamel et al., 2000)(Martinez et al., 2000)(Segarra et al., 2001). We present an approach in which the dialogue structure is represented by a stochastic network of dialogue acts. One advantage of this kind of network is that it can be learnt from annotated training samples. Moreover, it gives us a prediction of the next dialogue acts which are expected from the user as well Work partially funded by CICYT under project TIC98-0423-C06 as some information about the possible dialogue acts that can be generated by the system. The identification of the user dialogue acts is done through the semantic representation of the sentence. This semantic interpretation not</context>
<context position="9144" citStr="Segarra et al., 2001" startWordPosition="1490" endWordPosition="1493">e task (for example Departure time, Price, etc.), and others are related to the general characteristics of the dialogues (for example, Not understood, Affirmation, etc.). Note that each type of frame has a corresponding dialogue act associated to it. We use a two phases approach for the understanding process (Figure 2). In the first phase a sequence of semantic units and its corresponding segmentation is obtained from an input sentence. In the second phase one or more frames are extracted from this semantic sentence. The first phase is implemented from a stochastic transduction point of view (Segarra et al., 2001); that is, the input sentence (in words) is translated into an output sentence of a semantic language. The vocabulary of this semantic language is composed by a set of semantic units, that represents meanings of segments of words. The segmentation of these sentences allows us to define two kind of stochastic models: the Semantic model and the Semantic-Unit model. The Semantic model represents the allowed sequences of semantic units and their probabilities. The Semantic-Unit model represents the allowed sequences of words and their probabilities which are associated to each semantic unit. These</context>
</contexts>
<marker>Segarra, Sanchis, Galiano, Garcfa, Hurtado, 2001</marker>
<rawString>Segarra E., Sanchis E., Galiano M., Garcfa F., Hurtado L.F. 2001. Extracting semantic information through automatic learning techniques. IX Spanish Symposium on Pattern Recognition and Image Analysis (AERFAI), Castellon.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>