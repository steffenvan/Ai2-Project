<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.047711">
<title confidence="0.845161">
Mining User Experiences from Online Forums: An Exploration*
Valentin Jijkoun Maarten de Rijke
</title>
<author confidence="0.987278">
Wouter Weerkamp
</author>
<affiliation confidence="0.998599">
ISLA, University of Amsterdam
</affiliation>
<address confidence="0.9593115">
Science Park 107
1098 XG Amsterdam, The Netherlands
</address>
<email confidence="0.998014">
jijkoun,m.derijke,w.weerkamp@uva.nl
</email>
<author confidence="0.300341">
Paul Ackermans Gijs Geleijnse
</author>
<affiliation confidence="0.214059">
Philips Research Europe
</affiliation>
<address confidence="0.470527">
High Tech Campus 34
5656 AE Eindhoven, The Netherlands
</address>
<email confidence="0.9846405">
paul.ackermans@philips.com
gijs.geleijnse@philips.com
</email>
<sectionHeader confidence="0.999539" genericHeader="abstract">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99990280952381">
Recent years have shown a large increase in the
usage of content creation platforms—blogs, com-
munity QA sites, forums, etc.—aimed at the gen-
eral public.User generated data contains emotional,
opinionated, sentimental, and personal posts. This
characteristic makes it an interesting data source
for exploring new types of linguistic analysis, as is
demonstrated by research on, e.g., sentiment analy-
sis [4], opinion retrieval [3], and mood detection [1].
We introduce the task of experience mining. Here,
the goal is to gain insights into criteria that people
formulate to judge or rate a product or its usage.
These criteria can be formulated as the expectations
that people have of the product in advance (i.e., the
reasons to buy), but can also be expressed as reports
of experiences while using the product and compar-
isons with other products. We focus on the latter:
reports of experiences with products. In this paper,
we define the task, describe guidelines for manual
annotation and analyze linguistic features that can
be used in an automatic experience mining system.
</bodyText>
<sectionHeader confidence="0.975916" genericHeader="keywords">
2 Motivation
</sectionHeader>
<bodyText confidence="0.995230076923077">
Our main use-case is user-centered design for prod-
uct development. User-centered design [2] is an in-
novation paradigm where users of a product are in-
volved in each step of the research and development
process. The first stage of the product design process
is to identify unmet needs and demands of users for
a specific product or a class of products. Forums,
*This research was supported by project STE-09-12 within
the STEVIN programme funded by the Dutch and Flemish gov-
ernments, and by the Netherlands Organisation for Scientific
Research (NWO) under projects 640.001.501, 640.002.501,
612.066.512, 612.061.814, 612.061.815, 640.004.802.
review sites, and mailing lists are platforms where
people share experiences about a subject they care
about. Although statements found in such platforms
may not always be representative for the general user
group, they can accelerate user-centered design.
Another use-case comes from online communi-
ties themselves. Users of online forums are often in-
terested in other people’s experiences with concrete
products and/or solutions for specific problems. To
quote one such user: [t]he polls are the only in-
formation we have, though, except for individual
[users] giving their own evaluations. With the vol-
ume of online data increasing rapidly, users need im-
proved access to previously reported experiences.
</bodyText>
<sectionHeader confidence="0.990058" genericHeader="introduction">
3 Experience mining
</sectionHeader>
<bodyText confidence="0.999668636363636">
Experiences are particular instances of personally
encountering or undergoing something. We want
to identify experiences about a specific target prod-
uct, that are personal, involve an activity related to
the target and, moreover, are accompanied by judge-
ments or evaluative statements. Experience mining
is related to sentiment analysis and opinion retrieval,
in that it involves identifying attitudes; the key dif-
ference is, however, that we are looking for attitudes
towards specific experiences with products, not atti-
tudes towards the products themselves.
</bodyText>
<sectionHeader confidence="0.981526" genericHeader="method">
4 An explorative study
</sectionHeader>
<bodyText confidence="0.999890666666667">
To assess the feasibility of automatic experience
mining, we carried out an explorative study: we
asked human assessors to find experiences in ac-
tual forum data and then examined linguistic fea-
tures likely to be useful for identifying experiences
automatically.
</bodyText>
<page confidence="0.986678">
17
</page>
<note confidence="0.8725065">
Proceedings of the NAACL HLT 2010 Workshop on Computational Linguistics in a World of Social Media, pages 17–18,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<table confidence="0.99955">
Feature Mean and deviation in posts
with exper. without exper.
subjectivity score2 0.07 ±0.23 0.17 ±0.35
polarity score2 0.87 ±0.30 0.77 ±0.38
#words per post 102.57 ±80.09 52.46 ±53.24
#sentences per post 6.00 ±4.16 3.34 ±2.33
# words per sentence 17.07 ±4.69 15.71 ±7.61
#questions per post 0.32 ±0.63 0.54 ±0.89
p(post contains question) 0.25 ±0.43 0.33 ±0.47
#I’s per post 5.76 ±4.75 2.09 ±2.88
#I’s per sentence 1.01 ±0.48 0.54 ±0.60
p(sentence in post contains I) 0.67 ±0.23 0.40 ±0.35
#non-modal verbs per post 19.62 ±15.08 9.82 ±9.57
#non-modal verbs per sent. 3.30 ±1.18 2.82 ±1.37
#modal verbs per sent. 0.22 ±0.22 0.26 ±0.36
fraction of past-tense verbs 0.26 ±0.17 0.17 ±0.19
fraction of present tense verbs 0.42 ±0.18 0.41 ±0.23
</table>
<tableCaption confidence="0.995518">
Table 1: Comparison of surface text features for posts
with and without experience; p(·) denotes probability.
</tableCaption>
<bodyText confidence="0.9999215">
We acquired data by crawling two forums on
shaving,1 with 111,268 posts written by 2,880 users.
Manual assessments Two assessors (both authors
of this paper) were asked to search for posts on five
specific target products using a standard keyword
search, and label each result post as:
</bodyText>
<table confidence="0.835420166666667">
With experience Without experience
used 0.15, found 0.09, got 0.09, thought 0.09,
bought 0.07, tried 0.07, switched 0.06, meant 0.06,
got 0.07, went 0.07, started used 0.06, went 0.06, ig-
0.05, switched 0.04, liked nored 0.03, quoted 0.03,
0.03, decided 0.03 discovered 0.03, heard 0.03
</table>
<tableCaption confidence="0.993285">
Table 2: Most frequent past tense verbs following I in
posts with and without experience, with rel. frequencies.
</tableCaption>
<bodyText confidence="0.99974075">
with no experience. Table 1 lists the features and
the comparison results. Remarkably, the subjectiv-
ity score is lower for experience posts: this indicates
that our task is indeed different from sentiment re-
trieval. Experience posts are on average twice as
long as non-experience posts and contain more sen-
tences with pronoun I. They also contain more con-
tent (non-modal) verbs, especially past tense verbs.
Table 2 presents a more detailed analysis of the verb
use. Experience posts appear to contain more verbs
referring to concrete actions rather than to attitude
and perception. It is still to be seen, though, whether
this informal observation can be quantified using re-
sources such as standard semantic verb classification
(state, process, action), WordNet verb hierarchy or
FrameNet semantic frames.
</bodyText>
<listItem confidence="0.998149333333333">
• reporting no experience, or
• reporting an off-target experience, or
• reporting an on-target experience.
</listItem>
<bodyText confidence="0.9978125">
Moreover, posts should be marked as reporting an
experience only if (i) the author explicitly reports
his or someone else’s (a concrete person’s) use of
a product; and (ii) the author makes some conclu-
sions/judgements about the experience.
In total, 203 posts were labeled by the two asses-
sors, with 101 posts marked as reporting an experi-
ence by at least one assessor (71% of those an on-
target experience). The inter-annotator agreement
was 0.84, with Cohen’s n = 0.71. If we merge
on- and off-target experience labels, the agreement
is 0.88, with n = 0.76. The high level of agreement
demonstrates the validity of the task definition.
Features for experience mining We considered a
number of linguistic features and compared posts re-
porting experience (on- or off-target) to the posts
</bodyText>
<footnote confidence="0.9998015">
1www.shavemyface.com, www.menessentials.com/community
2Computed using LingPipe: http://alias-i.com/lingpipe
</footnote>
<sectionHeader confidence="0.999021" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999988875">
We introduced the novel task of experience min-
ing. Users of products share their experiences, and
mining these could help define requirements for
next-generation products. We developed annotation
guidelines for labeling experiences, and used them
to annotate data from online forums. An initial ex-
ploration revealed multiple features that might prove
useful for automatic labeling via classification.
</bodyText>
<sectionHeader confidence="0.999285" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99416775">
[1] K. Balog, G. Mishne, and M. de Rijke. Why are they
excited?: identifying and explaining spikes in blog
mood levels. In EACL ’06, pages 207–210, 2006.
[2] B. Buxton. Sketching User Experiences: Getting the
Design Right and the Right Design. Morgan Kauf-
mann Publishers Inc., 2007.
[3] I.Ounis, C. Macdonald, M. de Rijke, G. Mishne, and
I. Soboroff. Overview of the TREC 2006 Blog Track.
In TREC 2006, 2007.
[4] B. Pang and L. Lee. Opinion mining and senti-
ment analysis. Found. Trends Inf. Retr., 2(1-2):1–135,
2008.
</reference>
<page confidence="0.999279">
18
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.566506">
<title confidence="0.998314">User Experiences from Online Forums: An</title>
<author confidence="0.970665">Valentin Jijkoun Maarten de_Rijke</author>
<affiliation confidence="0.886177666666667">Wouter ISLA, University of Science Park</affiliation>
<address confidence="0.998959">1098 XG Amsterdam, The Netherlands</address>
<email confidence="0.997699">jijkoun,m.derijke,w.weerkamp@uva.nl</email>
<author confidence="0.959655">Paul Ackermans Gijs Geleijnse</author>
<affiliation confidence="0.913015">Philips Research</affiliation>
<address confidence="0.9623655">High Tech Campus 34 5656 AE Eindhoven, The Netherlands</address>
<email confidence="0.991719">gijs.geleijnse@philips.com</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>K Balog</author>
<author>G Mishne</author>
<author>M de Rijke</author>
</authors>
<title>Why are they excited?: identifying and explaining spikes in blog mood levels.</title>
<date>2006</date>
<booktitle>In EACL ’06,</booktitle>
<pages>207--210</pages>
<contexts>
<context position="858" citStr="[1]" startWordPosition="114" endWordPosition="114">se Philips Research Europe High Tech Campus 34 5656 AE Eindhoven, The Netherlands paul.ackermans@philips.com gijs.geleijnse@philips.com 1 Introduction Recent years have shown a large increase in the usage of content creation platforms—blogs, community QA sites, forums, etc.—aimed at the general public.User generated data contains emotional, opinionated, sentimental, and personal posts. This characteristic makes it an interesting data source for exploring new types of linguistic analysis, as is demonstrated by research on, e.g., sentiment analysis [4], opinion retrieval [3], and mood detection [1]. We introduce the task of experience mining. Here, the goal is to gain insights into criteria that people formulate to judge or rate a product or its usage. These criteria can be formulated as the expectations that people have of the product in advance (i.e., the reasons to buy), but can also be expressed as reports of experiences while using the product and comparisons with other products. We focus on the latter: reports of experiences with products. In this paper, we define the task, describe guidelines for manual annotation and analyze linguistic features that can be used in an automatic e</context>
</contexts>
<marker>[1]</marker>
<rawString>K. Balog, G. Mishne, and M. de Rijke. Why are they excited?: identifying and explaining spikes in blog mood levels. In EACL ’06, pages 207–210, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Buxton</author>
</authors>
<title>Sketching User Experiences: Getting the Design Right and the Right Design.</title>
<date>2007</date>
<publisher>Morgan Kaufmann Publishers Inc.,</publisher>
<contexts>
<context position="1587" citStr="[2]" startWordPosition="233" endWordPosition="233">or rate a product or its usage. These criteria can be formulated as the expectations that people have of the product in advance (i.e., the reasons to buy), but can also be expressed as reports of experiences while using the product and comparisons with other products. We focus on the latter: reports of experiences with products. In this paper, we define the task, describe guidelines for manual annotation and analyze linguistic features that can be used in an automatic experience mining system. 2 Motivation Our main use-case is user-centered design for product development. User-centered design [2] is an innovation paradigm where users of a product are involved in each step of the research and development process. The first stage of the product design process is to identify unmet needs and demands of users for a specific product or a class of products. Forums, *This research was supported by project STE-09-12 within the STEVIN programme funded by the Dutch and Flemish governments, and by the Netherlands Organisation for Scientific Research (NWO) under projects 640.001.501, 640.002.501, 612.066.512, 612.061.814, 612.061.815, 640.004.802. review sites, and mailing lists are platforms wher</context>
</contexts>
<marker>[2]</marker>
<rawString>B. Buxton. Sketching User Experiences: Getting the Design Right and the Right Design. Morgan Kaufmann Publishers Inc., 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Macdonald I Ounis</author>
<author>M de Rijke</author>
<author>G Mishne</author>
<author>I Soboroff</author>
</authors>
<title>Blog Track. In TREC</title>
<date>2006</date>
<journal>Overview of the TREC</journal>
<contexts>
<context position="834" citStr="[3]" startWordPosition="110" endWordPosition="110">l Ackermans Gijs Geleijnse Philips Research Europe High Tech Campus 34 5656 AE Eindhoven, The Netherlands paul.ackermans@philips.com gijs.geleijnse@philips.com 1 Introduction Recent years have shown a large increase in the usage of content creation platforms—blogs, community QA sites, forums, etc.—aimed at the general public.User generated data contains emotional, opinionated, sentimental, and personal posts. This characteristic makes it an interesting data source for exploring new types of linguistic analysis, as is demonstrated by research on, e.g., sentiment analysis [4], opinion retrieval [3], and mood detection [1]. We introduce the task of experience mining. Here, the goal is to gain insights into criteria that people formulate to judge or rate a product or its usage. These criteria can be formulated as the expectations that people have of the product in advance (i.e., the reasons to buy), but can also be expressed as reports of experiences while using the product and comparisons with other products. We focus on the latter: reports of experiences with products. In this paper, we define the task, describe guidelines for manual annotation and analyze linguistic features that can b</context>
</contexts>
<marker>[3]</marker>
<rawString>I.Ounis, C. Macdonald, M. de Rijke, G. Mishne, and I. Soboroff. Overview of the TREC 2006 Blog Track. In TREC 2006, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>L Lee</author>
</authors>
<title>Opinion mining and sentiment analysis.</title>
<date>2008</date>
<journal>Found. Trends Inf. Retr.,</journal>
<pages>2--1</pages>
<contexts>
<context position="811" citStr="[4]" startWordPosition="107" endWordPosition="107">e,w.weerkamp@uva.nl Paul Ackermans Gijs Geleijnse Philips Research Europe High Tech Campus 34 5656 AE Eindhoven, The Netherlands paul.ackermans@philips.com gijs.geleijnse@philips.com 1 Introduction Recent years have shown a large increase in the usage of content creation platforms—blogs, community QA sites, forums, etc.—aimed at the general public.User generated data contains emotional, opinionated, sentimental, and personal posts. This characteristic makes it an interesting data source for exploring new types of linguistic analysis, as is demonstrated by research on, e.g., sentiment analysis [4], opinion retrieval [3], and mood detection [1]. We introduce the task of experience mining. Here, the goal is to gain insights into criteria that people formulate to judge or rate a product or its usage. These criteria can be formulated as the expectations that people have of the product in advance (i.e., the reasons to buy), but can also be expressed as reports of experiences while using the product and comparisons with other products. We focus on the latter: reports of experiences with products. In this paper, we define the task, describe guidelines for manual annotation and analyze linguis</context>
</contexts>
<marker>[4]</marker>
<rawString>B. Pang and L. Lee. Opinion mining and sentiment analysis. Found. Trends Inf. Retr., 2(1-2):1–135, 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>