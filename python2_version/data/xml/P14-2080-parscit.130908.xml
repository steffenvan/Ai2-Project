<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002772">
<title confidence="0.9981335">
Learning Translational and Knowledge-based Similarities
from Relevance Rankings for Cross-Language Retrieval
</title>
<author confidence="0.994224">
Shigehiko Schamoni and Felix Hieber and Artem Sokolov and Stefan Riezler
</author>
<affiliation confidence="0.781079">
Department of Computational Linguistics
Heidelberg University, 69120 Heidelberg, Germany
</affiliation>
<email confidence="0.995599">
{schamoni,hieber,sokolov,riezler}@cl.uni-heidelberg.de
</email>
<sectionHeader confidence="0.99379" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999835571428571">
We present an approach to cross-language
retrieval that combines dense knowledge-
based features and sparse word transla-
tions. Both feature types are learned di-
rectly from relevance rankings of bilin-
gual documents in a pairwise ranking
framework. In large-scale experiments for
patent prior art search and cross-lingual re-
trieval in Wikipedia, our approach yields
considerable improvements over learning-
to-rank with either only dense or only
sparse features, and over very competitive
baselines that combine state-of-the-art ma-
chine translation and retrieval.
</bodyText>
<sectionHeader confidence="0.998766" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999655515625">
Cross-Language Information Retrieval (CLIR) for
the domain of web search successfully lever-
ages state-of-the-art Statistical Machine Transla-
tion (SMT) to either produce a single most prob-
able translation, or a weighted list of alternatives,
that is used as search query to a standard search
engine (Chin et al., 2008; Ture et al., 2012). This
approach is advantageous if large amounts of in-
domain sentence-parallel data are available to train
SMT systems, but relevance rankings to train re-
trieval models are not.
The situation is different for CLIR in special
domains such as patents or Wikipedia. Paral-
lel data for translation have to be extracted with
some effort from comparable or noisy parallel data
(Utiyama and Isahara, 2007; Smith et al., 2010),
however, relevance judgments are often straight-
forwardly encoded in special domains. For ex-
ample, in patent prior art search, patents granted
at any patent office worldwide are considered rel-
evant if they constitute prior art with respect to
the invention claimed in the query patent. Since
patent applicants and lawyers are required to list
relevant prior work explicitly in the patent appli-
cation, patent citations can be used to automati-
cally extract large amounts of relevance judgments
across languages (Graf and Azzopardi, 2008). In
Wikipedia search, one can imagine a Wikipedia
author trying to investigate whether a Wikipedia
article covering the subject the author intends to
write about already exists in another language.
Since authors are encouraged to avoid orphan arti-
cles and to cite their sources, Wikipedia has a rich
linking structure between related articles, which
can be exploited to create relevance links between
articles across languages (Bai et al., 2010).
Besides a rich citation structure, patent docu-
ments and Wikipedia articles contain a number
of further cues on relatedness that can be ex-
ploited as features in learning-to-rank approaches.
For monolingual patent retrieval, Guo and Gomes
(2009) and Oh et al. (2013) advocate the use of
dense features encoding domain knowledge on
inventors, assignees, location and date, together
with dense similarity scores based on bag-of-word
representations of patents. Bai et al. (2010) show
that for the domain of Wikipedia, learning a sparse
matrix of word associations between the query and
document vocabularies from relevance rankings is
useful in monolingual and cross-lingual retrieval.
Sokolov et al. (2013) apply the idea of learning
a sparse matrix of bilingual phrase associations
from relevance rankings to cross-lingual retrieval
in the patent domain. Both show improvements
of learning-to-rank on relevance data over SMT-
based approaches on their respective domains.
The main contribution of this paper is a thor-
ough evaluation of dense and sparse features
for learning-to-rank that have so far been used
only monolingually or only on either patents or
Wikipedia. We show that for both domains,
patents and Wikipedia, jointly learning bilingual
sparse word associations and dense knowledge-
based similarities directly on relevance ranked
</bodyText>
<page confidence="0.981251">
488
</page>
<bodyText confidence="0.973919">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Short Papers), pages 488–494,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
data improves significantly over approaches that
use either only sparse or only dense features, and
over approaches that combine query translation
by SMT with standard retrieval in the target lan-
guage. Furthermore, we show that our approach
can be seen as supervised model combination
that allows to combine SMT-based and ranking-
based approaches for further substantial improve-
ments. We conjecture that the gains are due to
orthogonal information contributed by domain-
knowledge, ranking-based word associations, and
translation-based information.
</bodyText>
<sectionHeader confidence="0.999725" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999978073170732">
CLIR addresses the problem of translating or pro-
jecting a query into the language of the document
repository across which retrieval is performed. In
a direct translation approach (DT), a state-of-the-
art SMT system is used to produce a single best
translation that is used as search query in the target
language. For example, Google’s CLIR approach
combines their state-of-the-art SMT system with
their proprietary search engine (Chin et al., 2008).
Alternative approaches avoid to solve the hard
problem of word reordering, and instead rely on
token-to-token translations that are used to project
the query terms into the target language with a
probabilistic weighting of the standard term tf-
idf scheme. Darwish and Oard (2003) termed
this method the probabilistic structured query ap-
proach (PSQ). The advantage of this technique
is an implicit query expansion effect due to the
use of probability distributions over term trans-
lations (Xu et al., 2001). Ture et al. (2012)
brought SMT back into this paradigm by pro-
jecting terms from n-best translations from syn-
chronous context-free grammars.
Ranking approaches have been presented by
Guo and Gomes (2009) and Oh et al. (2013).
Their method is a classical learning-to-rank setup
where pairwise ranking is applied to a few hun-
dred dense features. Methods to learn sparse
word-based translation correspondences from su-
pervised ranking signals have been presented by
Bai et al. (2010) and Sokolov et al. (2013). Both
approaches work in a cross-lingual setting, the for-
mer on Wikipedia data, the latter on patents.
Our approach extends the work of Sokolov et
al. (2013) by presenting an alternative learning-
to-rank approach that can be used for supervised
model combination to integrate dense and sparse
features, and by evaluating both approaches on
cross-lingual retrieval for patents and Wikipedia.
This relates our work to supervised model merg-
ing approaches (Sheldon et al., 2011).
</bodyText>
<sectionHeader confidence="0.835652" genericHeader="method">
3 Translation and Ranking for CLIR
</sectionHeader>
<bodyText confidence="0.965621833333333">
SMT-based Models. We will refer to DT and
PSQ as SMT-based models that translate a query,
and then perform monolingual retrieval using
BM25. Translation is agnostic of the retrieval task.
Linear Ranking for Word-Based Models. Let
q E {0,1}Q be a query and d E {0,1}D be a doc-
ument where the jth vector dimension indicates the
occurrence of the jth word for dictionaries of size
Q and D. A linear ranking model is defined as
f(q, d) = qTWd =
where W E IRQ×D encodes a matrix of ranking-
specific word associations (Bai et al., 2010) . We
optimize this model by pairwise ranking, which
assumes labeled data in the form of a set R of tu-
ples (q, d+, d−), where d+ is a relevant (or higher
ranked) document and d− an irrelevant (or lower
ranked) document for query q. The goal is to
find a weight matrix W such that an inequality
f(q, d+) &gt; f(q, d−) is violated for the fewest
number of tuples from R. We present two meth-
ods for optimizing W in the following.
Pairwise Ranking using Boosting (BM). The
Boosting-based Ranking baseline (Freund et al.,
2003) optimizes an exponential loss:
</bodyText>
<equation confidence="0.98783">
ELexp = D(q, d+, d−)ef(q,d−)−f(q,d+),
(q,d+,d−)ER
</equation>
<bodyText confidence="0.958975153846154">
where D(q, d+, d−) is a non-negative importance
function on tuples. The algorithm of Sokolov et
al. (2013) combines batch boosting with bagging
over a number of independently drawn bootstrap
data samples from R. In each step, the single word
pair feature is selected that provides the largest de-
crease of Lexp. The found corresponding models
are averaged. To reduce memory requirements we
used random feature hashing with the size of the
hash of 30 bits (Shi et al., 2009). For regulariza-
tion we rely on early stopping.
Pairwise Ranking with SGD (VW). The sec-
ond objective is an `1-regularized hinge loss:
</bodyText>
<equation confidence="0.986685857142857">
ELlyng = (f(q, d+) − f(q, d−)) + + A||W||1,
(q,d+,d−)ER
E Q
i=1
qiWijdj,
ED
j=1
</equation>
<page confidence="0.978867">
489
</page>
<bodyText confidence="0.9999075">
where (x)+ = max(0,1 − x) and A is the regu-
larization parameter. This newly added model uti-
lizes the standard implementation of online SGD
from the Vowpal Wabbit (VW) toolkit (Goel et al.,
2008) and was run on a data sample of 5M to 10M
tuples from R. On each step, W is updated with
a scaled gradient vector VWLhng and clipped to
account for `1-regularization. Memory usage was
reduced using the same hashing technique as for
boosting.
Domain Knowledge Models. Domain knowl-
edge features for patents were inspired by Guo
and Gomes (2009): a feature fires if two patents
share similar aspects, e.g. a common inventor. As
we do not have access to address data, we omit
geolocation features and instead add features that
evaluate similarity w.r.t. patent classes extracted
from IPC codes. Documents within a patent sec-
tion, i.e. the topmost hierarchy, are too diverse
to provide useful information but more detailed
classes and the count of matching classes do.
For Wikipedia, we implemented features that
compare the relative length of documents, num-
ber of links and images, the number of common
links and common images, and Wikipedia cat-
egories: Given the categories associated with a
foreign query, we use the language links on the
Wikipedia category pages to generate a set of
“translated” English categories S. The English-
side category graph is used to construct sets of
super- and subcategories related to the candidate
document’s categories. This expansion is done in
both directions for two levels resulting in 5 cat-
egory sets. The intersection between target set
Tn and the source category set S reflects the cat-
egory level similarity between query and docu-
ment, which we calculate as a mutual containment
score sn = 2(|S n Tn|/|S |+ |S n Tn|/|Tn|) for
</bodyText>
<equation confidence="0.789787">
1
n E {−2, −1, 0, +1, +2} (Broder, 1997).
</equation>
<bodyText confidence="0.999909625">
Optimization for these additional models in-
cluding domain knowledge features was done by
overloading the vector representation of queries q
and documents d in the VW linear learner: Instead
of sparse word-based features, q and d are rep-
resented by real-valued vectors of dense domain-
knowledge features. Optimization for the over-
loaded vectors is done as described above for VW.
</bodyText>
<sectionHeader confidence="0.985243" genericHeader="method">
4 Model Combination
</sectionHeader>
<bodyText confidence="0.985701777777778">
Combination by Borda Counts. The baseline
consensus-based voting Borda Count procedure
endows each voter with a fixed amount of voting
points which he is free to distribute among the
scored documents (Aslam and Montague, 2001;
Sokolov et al., 2013). The aggregate score for
two rankings f1(q, d) and f2(q, d) for all (q, d)
in the test set is then a simple linear interpolation:
fagg(q, d) = κ f1(q,d)
</bodyText>
<equation confidence="0.916849">
� d f1(q,d) +(1−κ)f2(q,d)
�d f2(q,d). Pa-
</equation>
<bodyText confidence="0.988697384615385">
rameter κ was adjusted on the dev set.
Combination by Linear Learning. In order to
acquire the best combination of more than two
models, we created vectors of model scores along
with domain knowledge features and reused the
VW pairwise ranking approach. This means
that the vector representation of queries q and
documents d in the VW linear learner is over-
loaded once more: In addition to dense domain-
knowledge features, we incorporate arbitrary
ranking models as dense features whose value is
the score of the ranking model. Training data was
sampled from the dev set and processed with VW.
</bodyText>
<sectionHeader confidence="0.996422" genericHeader="method">
5 Data
</sectionHeader>
<bodyText confidence="0.987987185185185">
Patent Prior Art Search (JP-EN). We use
BoostCLIR1, a Japanese-English (JP-EN) corpus
of patent abstracts from the MAREC and NTCIR
data (Sokolov et al., 2013). It contains automati-
cally induced relevance judgments for patent ab-
stracts (Graf and Azzopardi, 2008): EN patents
are regarded as relevant with level (3) to a JP query
patent, if they are in a family relationship (e.g.,
same invention), cited by the patent examiner (2),
or cited by the applicant (1). Statistics on the rank-
ing data are given in Table 1. On average, queries
and documents contain about 5 sentences.
Wikipedia Article Retrieval (DE-EN). The in-
tuition behind our Wikipedia retrieval setup is as
follows: Consider the situation where the German
(DE) Wikipedia article on geological sea stacks
does not yet exist. A native speaker of Ger-
man with profound knowledge in geology intends
to write it, naming it “Brandungspfeiler”, while
seeking to align its structure with the EN counter-
part. The task of a CLIR engine is to return rele-
vant EN Wikipedia articles that may describe the
very same concept (Stack (geology)), or relevant
instances of it (Bako National Park, Lange Anna).
The information need may be paraphrased as a
high-level definition of the topic. Since typically
the first sentence of any Wikipedia article is such
</bodyText>
<footnote confidence="0.986712">
1www.cl.uni-heidelberg.de/boostclir
</footnote>
<page confidence="0.96575">
490
</page>
<table confidence="0.999936666666667">
#q #d #d+/q #wards/q
Patents (JP-EN)
train 107,061 888,127 13.28 178.74
dev 2,000 100,000 13.24 181.70
test 2,000 100,000 12.59 182.39
Wikipedia (DE-EN) 225,294 1,226,741 13.04 25.80
train
dev 10,000 113,553 12.97 25.75
test 10,000 115,131 13.22 25.73
</table>
<tableCaption confidence="0.868089">
Table 1: Ranking data statistics: number of queries and doc-
uments, avg. number of relevant documents per query, avg.
number of words per query.
</tableCaption>
<bodyText confidence="0.998923638888889">
a well-formed definition, this allows us to extract
a large set of one sentence queries from Wikipedia
articles. For example: “Brandungspfeiler sind vor
einer Kliffk¨uste aufragende Felsent¨urme und ver-
gleichbare Formationen, die durch Brandungsero-
sion gebildet werden.”2 Similar to Bai et al. (2010)
we induce relevance judgments by aligning DE
queries with their EN counterparts (“mates”) via
the graph of inter-language links available in arti-
cles and Wikidata3. We assign relevance level (3)
to the EN mate and level (2) to all other EN ar-
ticles that link to the mate, and are linked by the
mate. Instead of using all outgoing links from the
mate, we only use articles with bidirectional links.
To create this data4 we downloaded XML and
SQL dumps of the DE and EN Wikipedia from,
resp., 22nd and 4th of November 2013. Wikipedia
markup removal and link extraction was carried
out using the Cloud9 toolkit5. Sentence extrac-
tion was done with NLTK6. Since Wikipedia arti-
cles vary greatly in length, we restricted EN doc-
uments to the first 200 words after extracting the
link graph to reduce the number of features for BM
and VW models. To avoid rendering the task too
easy for literal keyword matching of queries about
named entities, we removed title words from the
German queries. Statistics are given in Table 1.
Preprocessing Ranking Data. In addition to
lowercasing and punctuation removal, we applied
Correlated Feature Hashing (CFH), that makes
collisions more likely for words with close mean-
ing (Bai et al., 2010). For patents, vocabularies
contained 60k and 365k words for JP and EN.
Filtering special symbols and stopwords reduced
the JP vocabulary size to 50k (small enough not
to resort to CFH). To reduce the EN vocabulary
</bodyText>
<footnote confidence="0.9995438">
2de.wikipedia.org/wiki/Brandungspfeiler
3www.wikidata.org/
4www.cl.uni-heidelberg.de/wikiclir
5lintool.github.io/Cloud9/index.html
6www.nltk.org/
</footnote>
<bodyText confidence="0.9988631">
to a comparable size, we applied similar prepro-
cessing and CFH with F=30k and k=5. Since for
Wikipedia data, the DE and EN vocabularies were
both large (6.7M and 6M), we used the same filter-
ing and preprocessing as for the patent data before
applying CFH with F=40k and k=5 on both sides.
Parallel Data for SMT-based CLIR. For both
tasks, DT and PSQ require an SMT baseline
system trained on parallel corpora that are dis-
junct from the ranking data. A JP-EN sys-
tem was trained on data described and prepro-
cessed by Sokolov et al. (2013), consisting of
1.8M parallel sentences from the NTCIR-7 JP-EN
PatentMT subtask (Fujii et al., 2008) and 2k par-
allel sentences for parameter development from
the NTCIR-8 test collection. For Wikipedia, we
trained a DE-EN system on 4.1M parallel sen-
tences from Europarl, Common Crawl, and News-
Commentary. Parameter tuning was done on 3k
parallel sentences from the WMT’11 test set.
</bodyText>
<sectionHeader confidence="0.999467" genericHeader="evaluation">
6 Experiments
</sectionHeader>
<bodyText confidence="0.999754793103449">
Experiment Settings. The SMT-based models
use cdec (Dyer et al., 2010). Word align-
ments were created with mgiza (JP-EN) and
fast align (Dyer et al., 2013) (DE-EN). Lan-
guage models were trained with the KenLM
toolkit (Heafield, 2011). The JP-EN system uses
a 5-gram language model from the EN side of the
training data. For the DE-EN system, a 4-gram
model was built on the EN side of the training
data and the EN Wikipedia documents. Weights
for the standard feature set were optimized using
cdec’s MERT (JP-EN) and MIRA (DE-EN) im-
plementations (Och, 2003; Chiang et al., 2008).
PSQ on patents reuses settings found by Sokolov
et al. (2013); settings for Wikipedia were adjusted
on its dev set (n=1000, A=0.4, L=0, C=1).
Patent retrieval for DT was done by sentence-
wise translation and subsequent re-joining to form
one query per patent, which was ranked against the
documents using BM25. For PSQ, BM25 is com-
puted on expected term and document frequencies.
For ranking-based retrieval, we compare several
combinations of learners and features (Table 2).
VW denotes a sparse model using word-based fea-
tures trained with SGD. BM denotes a similar
model trained using Boosting. DK denotes VW
training of a model that represents queries q and
documents d by dense domain-knowledge fea-
tures instead of by sparse word-based vectors. In
</bodyText>
<page confidence="0.997692">
491
</page>
<bodyText confidence="0.999921294117647">
order to simulate pass-through behavior of out-of-
vocabulary terms in SMT systems, additional fea-
tures accounting for source and target term iden-
tity were added to DK and BM models. The pa-
rameter λ for VW was found on dev set. Statis-
tical significance testing was performed using the
paired randomization test (Smucker et al., 2007).
Borda denotes model combination by Borda
Count voting where the linear interpolation pa-
rameter is adjusted for MAP on the respective de-
velopment sets with grid search. This type of
model combination only allows to combine pairs
of rankings. We present a combination of SMT-
based CLIR, DT+PSQ, a combination of dense
and sparse features, DK+VW, and a combination
of both combinations, (DT+PSQ)+(DK+VW).
LinLearn denotes model combination by over-
loading the vector representation of queries q and
documents d in the VW linear learner by incor-
porating arbitrary ranking models as dense fea-
tures. In difference to grid search for Borda, opti-
mal weights for the linear combination of incorpo-
rated ranking models can be learned automatically.
We investigate the same combinations of rank-
ing models as described for Borda above. We do
not report combination results including the sparse
BM model since they were consistently lower than
the ones with the sparse VW model.
Test Results. Experimental results on test data
are given in Table 2. Results are reported
with respect to MAP (Manning et al., 2008),
NDCG (J¨arvelin and Kek¨al¨ainen, 2002), and
PRES (Magdy and Jones, 2010). Scores were
computed on the top 1,000 retrieved documents.
As can be seen from inspecting the two blocks
of results, one for patents, one for Wikipedia, we
find the same system rankings on both datasets. In
both cases, as standalone systems, DT and PSQ
are very close and far better than any ranking ap-
proach, irrespective of the objective function or the
choice of sparse or dense features. Model combi-
nation of similar models, e.g., DT and PSQ, gives
minimal gains, compared to combining orthogo-
nal models, e.g. DK and VW. The best result is
achieved by combining DT and PSQ with DK and
VW. This is due to the already high scores of the
combined models, but also to the combination of
yet other types of orthogonal information. Borda
voting gives the best result under MAP which is
probably due to the adjustment of the interpola-
tion parameter for MAP on the development set.
</bodyText>
<table confidence="0.999910217391304">
models MAP NDCG PRES
DT 0.2554 0.5397 0.5680
PSQ 0.2659 0.5508 0.5851
DK 0.2203 0.4874 0.5171
VW 0.2205 0.4989 0.4911
BM 0.1669 0.4167 0.4665
DT+PSQ *0.2747 *0.5618 *0.5988
DK+VW *0.3023 *0.5980 *0.6137
(DT+PSQ)+(DK+VW) *0.3465 *0.6420 *0.6858
DT+PSQ †*0.2707 †*0.5578 †*0.5941
DK+VW †*0.3283 †*0.6366 †*0.7104
DT+PSQ+DK+VW †*0.3739 †*0.6755 †*0.7599
DT 0.3678 0.5691 0.7219
PSQ 0.3642 0.5671 0.7165
DK 0.2661 0.4584 0.6717
VW 0.1249 0.3389 0.6466
BM 0.1386 0.3418 0.6145
DT+PSQ *0.3742 *0.5777 *0.7306
DK+VW *0.3238 *0.5484 *0.7736
(DT+PSQ)+(DK+VW) *0.4173 *0.6333 *0.8031
DT+PSQ †*0.3718 †*0.5751 †*0.7251
DK+VW †*0.3436 †*0.5686 †*0.7914
DT+PSQ+DK+VW *0.4137 †*0.6435 †*0.8233
</table>
<tableCaption confidence="0.995304">
Table 2: Test results for standalone CLIR models using di-
</tableCaption>
<bodyText confidence="0.787706333333333">
rect translation (DT), probabilistic structured queries (PSQ),
sparse model with CFH (VW), sparse boosting model (BM),
dense domain knowledge features (DK), and model combi-
nations using Borda Count voting (Borda) or linear super-
vised model combination (LinLearn). Significant differences
(at P=0.01) between aggregated systems and all its compo-
nents are indicated by ∗, between LinLearn and the respective
Borda system by †.
Under NDCG and PRES, LinLearn achieves the
best results, showing the advantage of automati-
cally learning combination weights that leads to
stable results across various metrics.
</bodyText>
<sectionHeader confidence="0.992153" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999964071428572">
Special domains such as patents or Wikipedia of-
fer the possibility to extract cross-lingual rele-
vance data from citation and link graphs. These
data can be used to directly optimizing cross-
lingual ranking models. We showed on two differ-
ent large-scale ranking scenarios that a supervised
combination of orthogonal information sources
such as domain-knowledge, translation knowl-
edge, and ranking-specific word associations by
far outperforms a pipeline of query translation and
retrieval. We conjecture that if these types of in-
formation sources are available, a supervised rank-
ing approach will yield superior results in other re-
trieval scenarios as well.
</bodyText>
<sectionHeader confidence="0.99843" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.673860333333333">
This research was supported in part by DFG
grant RI-2221/1-1 “Cross-language Learning-to-
Rank for Patent Retrieval”.
</bodyText>
<table confidence="0.764555857142857">
combination
Patents (JP-EN) standalone
Borda
LinLearn
Wikipedia (DE-EN) standalone
Borda
LinLearn
</table>
<page confidence="0.993483">
492
</page>
<note confidence="0.9418165">
Erik Graf and Leif Azzopardi. 2008. A methodol-
ogy for building a patent test collection for prior
art search. In Proceedings of the 2nd Interna-
tional Workshop on Evaluating Information Access
(EVIA’08), Tokyo, Japan.
References
Javed A. Aslam and Mark Montague. 2001. Models
for metasearch. In Proceedings of the ACM SIGIR
Conference on Research and Development in Infor-
mation Retrieval (SIGIR’01), New Orleans, LA.
</note>
<reference confidence="0.999334663265306">
Bing Bai, Jason Weston, David Grangier, Ronan Col-
lobert, Kunihiko Sadamasa, Yanjun Qi, Olivier
Chapelle, and Kilian Weinberger. 2010. Learning
to rank with (a lot of) word features. Information
Retrieval Journal, 13(3):291–314.
Andrei Z. Broder. 1997. On the resemblance and con-
tainment of documents. In Compression and Com-
plexity of Sequences (SEQUENCES’97), pages 21–
29. IEEE Computer Society.
David Chiang, Yuval Marton, and Philip Resnik. 2008.
Online large-margin training of syntactic and struc-
tural translation features. In Proceedings of the Con-
ference on Empirical Methods in Natural Language
Processing (EMNLP’08), Waikiki, Hawaii.
Jeffrey Chin, Maureen Heymans, Alexandre Ko-
joukhov, Jocelyn Lin, and Hui Tan. 2008. Cross-
language information retrieval. Patent Application.
US 2008/0288474 A1.
Kareem Darwish and Douglas W. Oard. 2003. Proba-
bilistic structured query methods. In Proceedings.
of the ACM SIGIR Conference on Research and
Development in Information Retrieval (SIGIR’03),
Toronto, Canada.
Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan
Weese, Ferhan Ture, Phil Blunsom, Hendra Seti-
awan, Vladimir Eidelman, and Philip Resnik. 2010.
cdec: A decoder, alignment, and learning framework
for finite-state and context-free translation models.
In Proceedings of the ACL 2010 System Demonstra-
tions, Uppsala, Sweden.
Chris Dyer, Victor Chahuneau, and Noah A. Smith.
2013. A simple, fast, and effective reparameteriza-
tion of IBM Model 2. In Proceedings of the Con-
ference of the North American Chapter of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, Atlanta, GA.
Yoav Freund, Ray Iyer, Robert E. Schapire, and Yoram
Singer. 2003. An efficient boosting algorithm for
combining preferences. Journal of Machine Learn-
ing Research, 4:933–969.
Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, and
Takehito Utsuro. 2008. Overview of the patent
translation task at the NTCIR-7 workshop. In Pro-
ceedings of NTCIR-7 Workshop Meeting, Tokyo,
Japan.
Sharad Goel, John Langford, and Alexander L. Strehl.
2008. Predictive indexing for fast search. In Ad-
vances in Neural Information Processing Systems,
Vancouver, Canada.
Yunsong Guo and Carla Gomes. 2009. Ranking struc-
tured documents: A large margin based approach for
patent prior art search. In Proceedings of the Inter-
national Joint Conference on Artificial Intelligence
(IJCAI’09), Pasadena, CA.
Kenneth Heafield. 2011. KenLM: faster and smaller
language model queries. In Proceedings of the
EMNLP 2011 Sixth Workshop on Statistical Ma-
chine Translation (WMT’11), Edinburgh, UK.
Kalervo J¨arvelin and Jaana Kek¨al¨ainen. 2002. Cumu-
lated gain-based evaluation of IR techniques. ACM
Transactions in Information Systems, 20(4):422–
446.
Walid Magdy and Gareth J.F. Jones. 2010. PRES:
a score metric for evaluating recall-oriented infor-
mation retrieval applications. In Proceedings of the
ACM SIGIR conference on Research and develop-
ment in information retrieval (SIGIR’10), New York,
NY.
Christopher D. Manning, Prabhakar Raghavan, and
Hinrich Sch¨utze. 2008. Introduction to Information
Retrieval. Cambridge University Press.
Franz Josef Och. 2003. Minimum error rate training
in statistical machine translation. In Proceedings of
the 41st Meeting on Association for Computational
Linguistics (ACL’03), Sapporo, Japan.
Sooyoung Oh, Zhen Lei, Wang-Chien Lee, Prasenjit
Mitra, and John Yen. 2013. CV-PCR: A context-
guided value-driven framework for patent citation
recommendation. In Proceedings of the Interna-
tional Conference on Information and Knowledge
Management (CIKM’13), San Francisco, CA.
Daniel Sheldon, Milad Shokouhi, Martin Szummer,
and Nick Craswell. 2011. Lambdamerge: Merging
the results of query reformulations. In Proceedings
of WSDM’11, Hong Kong, China.
Qinfeng Shi, James Petterson, Gideon Dror, John
Langford, Alexander J. Smola, Alexander L. Strehl,
and Vishy Vishwanathan. 2009. Hash Kernels. In
Proceedings of the 12th Int. Conference on Artifi-
cial Intelligence and Statistics (AISTATS’09), Irvine,
CA.
Jason R. Smith, Chris Quirk, and Kristina Toutanova.
2010. Extracting parallel sentences from compa-
rable corpora using document level alignment. In
Proceedings of Human Language Technologies: The
11th Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics (NAACL-HLT’10), Los Angeles, CA.
</reference>
<page confidence="0.991306">
493
</page>
<reference confidence="0.99951848">
Mark D. Smucker, James Allan, and Ben Carterette.
2007. A comparison of statistical significance tests
for information retrieval evaluation. In Proceedings
of the 16th ACM conference on Conference on Infor-
mation and Knowledge Management (CIKM ’07),
New York, NY.
Artem Sokolov, Laura Jehl, Felix Hieber, and Stefan
Riezler. 2013. Boosting cross-language retrieval
by learning bilingual phrase associations from rele-
vance rankings. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing (EMNLP’13).
Ferhan Ture, Jimmy Lin, and Douglas W. Oard.
2012. Combining statistical translation techniques
for cross-language information retrieval. In Pro-
ceedings of the International Conference on Compu-
tational Linguistics (COLING’12), Bombay, India.
Masao Utiyama and Hitoshi Isahara. 2007. A
Japanese-English patent parallel corpus. In Pro-
ceedings of MT Summit XI, Copenhagen, Denmark.
Jinxi Xu, Ralph Weischedel, and Chanh Nguyen. 2001.
Evaluating a probabilistic model for cross-lingual
information retrieval. In Proceedings of the ACM
SIGIR Conference on Research and Development in
Information Retrieval (SIGIR’01), New York, NY.
</reference>
<page confidence="0.998997">
494
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.900882">
<title confidence="0.995856">Learning Translational and Knowledge-based from Relevance Rankings for Cross-Language Retrieval</title>
<author confidence="0.998091">Schamoni Hieber Sokolov</author>
<affiliation confidence="0.973546">Department of Computational Heidelberg University, 69120 Heidelberg,</affiliation>
<abstract confidence="0.997327866666667">We present an approach to cross-language retrieval that combines dense knowledgebased features and sparse word translations. Both feature types are learned directly from relevance rankings of bilingual documents in a pairwise ranking framework. In large-scale experiments for patent prior art search and cross-lingual retrieval in Wikipedia, our approach yields considerable improvements over learningto-rank with either only dense or only sparse features, and over very competitive baselines that combine state-of-the-art machine translation and retrieval.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bing Bai</author>
<author>Jason Weston</author>
<author>David Grangier</author>
<author>Ronan Collobert</author>
<author>Kunihiko Sadamasa</author>
<author>Yanjun Qi</author>
<author>Olivier Chapelle</author>
<author>Kilian Weinberger</author>
</authors>
<title>Learning to rank with (a lot of) word features.</title>
<date>2010</date>
<journal>Information Retrieval Journal,</journal>
<volume>13</volume>
<issue>3</issue>
<contexts>
<context position="2643" citStr="Bai et al., 2010" startWordPosition="384" endWordPosition="387">xplicitly in the patent application, patent citations can be used to automatically extract large amounts of relevance judgments across languages (Graf and Azzopardi, 2008). In Wikipedia search, one can imagine a Wikipedia author trying to investigate whether a Wikipedia article covering the subject the author intends to write about already exists in another language. Since authors are encouraged to avoid orphan articles and to cite their sources, Wikipedia has a rich linking structure between related articles, which can be exploited to create relevance links between articles across languages (Bai et al., 2010). Besides a rich citation structure, patent documents and Wikipedia articles contain a number of further cues on relatedness that can be exploited as features in learning-to-rank approaches. For monolingual patent retrieval, Guo and Gomes (2009) and Oh et al. (2013) advocate the use of dense features encoding domain knowledge on inventors, assignees, location and date, together with dense similarity scores based on bag-of-word representations of patents. Bai et al. (2010) show that for the domain of Wikipedia, learning a sparse matrix of word associations between the query and document vocabul</context>
<context position="6192" citStr="Bai et al. (2010)" startWordPosition="921" endWordPosition="924">this technique is an implicit query expansion effect due to the use of probability distributions over term translations (Xu et al., 2001). Ture et al. (2012) brought SMT back into this paradigm by projecting terms from n-best translations from synchronous context-free grammars. Ranking approaches have been presented by Guo and Gomes (2009) and Oh et al. (2013). Their method is a classical learning-to-rank setup where pairwise ranking is applied to a few hundred dense features. Methods to learn sparse word-based translation correspondences from supervised ranking signals have been presented by Bai et al. (2010) and Sokolov et al. (2013). Both approaches work in a cross-lingual setting, the former on Wikipedia data, the latter on patents. Our approach extends the work of Sokolov et al. (2013) by presenting an alternative learningto-rank approach that can be used for supervised model combination to integrate dense and sparse features, and by evaluating both approaches on cross-lingual retrieval for patents and Wikipedia. This relates our work to supervised model merging approaches (Sheldon et al., 2011). 3 Translation and Ranking for CLIR SMT-based Models. We will refer to DT and PSQ as SMT-based mode</context>
<context position="13828" citStr="Bai et al. (2010)" startWordPosition="2199" endWordPosition="2202">00 100,000 13.24 181.70 test 2,000 100,000 12.59 182.39 Wikipedia (DE-EN) 225,294 1,226,741 13.04 25.80 train dev 10,000 113,553 12.97 25.75 test 10,000 115,131 13.22 25.73 Table 1: Ranking data statistics: number of queries and documents, avg. number of relevant documents per query, avg. number of words per query. a well-formed definition, this allows us to extract a large set of one sentence queries from Wikipedia articles. For example: “Brandungspfeiler sind vor einer Kliffk¨uste aufragende Felsent¨urme und vergleichbare Formationen, die durch Brandungserosion gebildet werden.”2 Similar to Bai et al. (2010) we induce relevance judgments by aligning DE queries with their EN counterparts (“mates”) via the graph of inter-language links available in articles and Wikidata3. We assign relevance level (3) to the EN mate and level (2) to all other EN articles that link to the mate, and are linked by the mate. Instead of using all outgoing links from the mate, we only use articles with bidirectional links. To create this data4 we downloaded XML and SQL dumps of the DE and EN Wikipedia from, resp., 22nd and 4th of November 2013. Wikipedia markup removal and link extraction was carried out using the Cloud9</context>
<context position="15052" citStr="Bai et al., 2010" startWordPosition="2408" endWordPosition="2411">t5. Sentence extraction was done with NLTK6. Since Wikipedia articles vary greatly in length, we restricted EN documents to the first 200 words after extracting the link graph to reduce the number of features for BM and VW models. To avoid rendering the task too easy for literal keyword matching of queries about named entities, we removed title words from the German queries. Statistics are given in Table 1. Preprocessing Ranking Data. In addition to lowercasing and punctuation removal, we applied Correlated Feature Hashing (CFH), that makes collisions more likely for words with close meaning (Bai et al., 2010). For patents, vocabularies contained 60k and 365k words for JP and EN. Filtering special symbols and stopwords reduced the JP vocabulary size to 50k (small enough not to resort to CFH). To reduce the EN vocabulary 2de.wikipedia.org/wiki/Brandungspfeiler 3www.wikidata.org/ 4www.cl.uni-heidelberg.de/wikiclir 5lintool.github.io/Cloud9/index.html 6www.nltk.org/ to a comparable size, we applied similar preprocessing and CFH with F=30k and k=5. Since for Wikipedia data, the DE and EN vocabularies were both large (6.7M and 6M), we used the same filtering and preprocessing as for the patent data befo</context>
</contexts>
<marker>Bai, Weston, Grangier, Collobert, Sadamasa, Qi, Chapelle, Weinberger, 2010</marker>
<rawString>Bing Bai, Jason Weston, David Grangier, Ronan Collobert, Kunihiko Sadamasa, Yanjun Qi, Olivier Chapelle, and Kilian Weinberger. 2010. Learning to rank with (a lot of) word features. Information Retrieval Journal, 13(3):291–314.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrei Z Broder</author>
</authors>
<title>On the resemblance and containment of documents.</title>
<date>1997</date>
<booktitle>In Compression and Complexity of Sequences (SEQUENCES’97),</booktitle>
<pages>21--29</pages>
<publisher>IEEE Computer Society.</publisher>
<contexts>
<context position="10348" citStr="Broder, 1997" startWordPosition="1639" endWordPosition="1640">reign query, we use the language links on the Wikipedia category pages to generate a set of “translated” English categories S. The Englishside category graph is used to construct sets of super- and subcategories related to the candidate document’s categories. This expansion is done in both directions for two levels resulting in 5 category sets. The intersection between target set Tn and the source category set S reflects the category level similarity between query and document, which we calculate as a mutual containment score sn = 2(|S n Tn|/|S |+ |S n Tn|/|Tn|) for 1 n E {−2, −1, 0, +1, +2} (Broder, 1997). Optimization for these additional models including domain knowledge features was done by overloading the vector representation of queries q and documents d in the VW linear learner: Instead of sparse word-based features, q and d are represented by real-valued vectors of dense domainknowledge features. Optimization for the overloaded vectors is done as described above for VW. 4 Model Combination Combination by Borda Counts. The baseline consensus-based voting Borda Count procedure endows each voter with a fixed amount of voting points which he is free to distribute among the scored documents </context>
</contexts>
<marker>Broder, 1997</marker>
<rawString>Andrei Z. Broder. 1997. On the resemblance and containment of documents. In Compression and Complexity of Sequences (SEQUENCES’97), pages 21– 29. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Yuval Marton</author>
<author>Philip Resnik</author>
</authors>
<title>Online large-margin training of syntactic and structural translation features.</title>
<date>2008</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’08),</booktitle>
<location>Waikiki, Hawaii.</location>
<contexts>
<context position="16921" citStr="Chiang et al., 2008" startWordPosition="2708" endWordPosition="2711">es from the WMT’11 test set. 6 Experiments Experiment Settings. The SMT-based models use cdec (Dyer et al., 2010). Word alignments were created with mgiza (JP-EN) and fast align (Dyer et al., 2013) (DE-EN). Language models were trained with the KenLM toolkit (Heafield, 2011). The JP-EN system uses a 5-gram language model from the EN side of the training data. For the DE-EN system, a 4-gram model was built on the EN side of the training data and the EN Wikipedia documents. Weights for the standard feature set were optimized using cdec’s MERT (JP-EN) and MIRA (DE-EN) implementations (Och, 2003; Chiang et al., 2008). PSQ on patents reuses settings found by Sokolov et al. (2013); settings for Wikipedia were adjusted on its dev set (n=1000, A=0.4, L=0, C=1). Patent retrieval for DT was done by sentencewise translation and subsequent re-joining to form one query per patent, which was ranked against the documents using BM25. For PSQ, BM25 is computed on expected term and document frequencies. For ranking-based retrieval, we compare several combinations of learners and features (Table 2). VW denotes a sparse model using word-based features trained with SGD. BM denotes a similar model trained using Boosting. D</context>
</contexts>
<marker>Chiang, Marton, Resnik, 2008</marker>
<rawString>David Chiang, Yuval Marton, and Philip Resnik. 2008. Online large-margin training of syntactic and structural translation features. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’08), Waikiki, Hawaii.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeffrey Chin</author>
<author>Maureen Heymans</author>
<author>Alexandre Kojoukhov</author>
<author>Jocelyn Lin</author>
<author>Hui Tan</author>
</authors>
<title>Crosslanguage information retrieval. Patent Application.</title>
<date>2008</date>
<journal>US</journal>
<volume>2008</volume>
<pages>1</pages>
<contexts>
<context position="1224" citStr="Chin et al., 2008" startWordPosition="160" endWordPosition="163">for patent prior art search and cross-lingual retrieval in Wikipedia, our approach yields considerable improvements over learningto-rank with either only dense or only sparse features, and over very competitive baselines that combine state-of-the-art machine translation and retrieval. 1 Introduction Cross-Language Information Retrieval (CLIR) for the domain of web search successfully leverages state-of-the-art Statistical Machine Translation (SMT) to either produce a single most probable translation, or a weighted list of alternatives, that is used as search query to a standard search engine (Chin et al., 2008; Ture et al., 2012). This approach is advantageous if large amounts of indomain sentence-parallel data are available to train SMT systems, but relevance rankings to train retrieval models are not. The situation is different for CLIR in special domains such as patents or Wikipedia. Parallel data for translation have to be extracted with some effort from comparable or noisy parallel data (Utiyama and Isahara, 2007; Smith et al., 2010), however, relevance judgments are often straightforwardly encoded in special domains. For example, in patent prior art search, patents granted at any patent offic</context>
<context position="5207" citStr="Chin et al., 2008" startWordPosition="765" endWordPosition="768">ecture that the gains are due to orthogonal information contributed by domainknowledge, ranking-based word associations, and translation-based information. 2 Related Work CLIR addresses the problem of translating or projecting a query into the language of the document repository across which retrieval is performed. In a direct translation approach (DT), a state-of-theart SMT system is used to produce a single best translation that is used as search query in the target language. For example, Google’s CLIR approach combines their state-of-the-art SMT system with their proprietary search engine (Chin et al., 2008). Alternative approaches avoid to solve the hard problem of word reordering, and instead rely on token-to-token translations that are used to project the query terms into the target language with a probabilistic weighting of the standard term tfidf scheme. Darwish and Oard (2003) termed this method the probabilistic structured query approach (PSQ). The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations (Xu et al., 2001). Ture et al. (2012) brought SMT back into this paradigm by projecting terms from n-best transl</context>
</contexts>
<marker>Chin, Heymans, Kojoukhov, Lin, Tan, 2008</marker>
<rawString>Jeffrey Chin, Maureen Heymans, Alexandre Kojoukhov, Jocelyn Lin, and Hui Tan. 2008. Crosslanguage information retrieval. Patent Application. US 2008/0288474 A1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kareem Darwish</author>
<author>Douglas W Oard</author>
</authors>
<title>Probabilistic structured query methods.</title>
<date>2003</date>
<booktitle>In Proceedings. of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’03),</booktitle>
<location>Toronto, Canada.</location>
<contexts>
<context position="5487" citStr="Darwish and Oard (2003)" startWordPosition="809" endWordPosition="812">tory across which retrieval is performed. In a direct translation approach (DT), a state-of-theart SMT system is used to produce a single best translation that is used as search query in the target language. For example, Google’s CLIR approach combines their state-of-the-art SMT system with their proprietary search engine (Chin et al., 2008). Alternative approaches avoid to solve the hard problem of word reordering, and instead rely on token-to-token translations that are used to project the query terms into the target language with a probabilistic weighting of the standard term tfidf scheme. Darwish and Oard (2003) termed this method the probabilistic structured query approach (PSQ). The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations (Xu et al., 2001). Ture et al. (2012) brought SMT back into this paradigm by projecting terms from n-best translations from synchronous context-free grammars. Ranking approaches have been presented by Guo and Gomes (2009) and Oh et al. (2013). Their method is a classical learning-to-rank setup where pairwise ranking is applied to a few hundred dense features. Methods to learn sparse word-b</context>
</contexts>
<marker>Darwish, Oard, 2003</marker>
<rawString>Kareem Darwish and Douglas W. Oard. 2003. Probabilistic structured query methods. In Proceedings. of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’03), Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Adam Lopez</author>
<author>Juri Ganitkevitch</author>
<author>Jonathan Weese</author>
<author>Ferhan Ture</author>
<author>Phil Blunsom</author>
<author>Hendra Setiawan</author>
<author>Vladimir Eidelman</author>
<author>Philip Resnik</author>
</authors>
<title>cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 System Demonstrations,</booktitle>
<location>Uppsala,</location>
<contexts>
<context position="16414" citStr="Dyer et al., 2010" startWordPosition="2620" endWordPosition="2623">ained on parallel corpora that are disjunct from the ranking data. A JP-EN system was trained on data described and preprocessed by Sokolov et al. (2013), consisting of 1.8M parallel sentences from the NTCIR-7 JP-EN PatentMT subtask (Fujii et al., 2008) and 2k parallel sentences for parameter development from the NTCIR-8 test collection. For Wikipedia, we trained a DE-EN system on 4.1M parallel sentences from Europarl, Common Crawl, and NewsCommentary. Parameter tuning was done on 3k parallel sentences from the WMT’11 test set. 6 Experiments Experiment Settings. The SMT-based models use cdec (Dyer et al., 2010). Word alignments were created with mgiza (JP-EN) and fast align (Dyer et al., 2013) (DE-EN). Language models were trained with the KenLM toolkit (Heafield, 2011). The JP-EN system uses a 5-gram language model from the EN side of the training data. For the DE-EN system, a 4-gram model was built on the EN side of the training data and the EN Wikipedia documents. Weights for the standard feature set were optimized using cdec’s MERT (JP-EN) and MIRA (DE-EN) implementations (Och, 2003; Chiang et al., 2008). PSQ on patents reuses settings found by Sokolov et al. (2013); settings for Wikipedia were </context>
</contexts>
<marker>Dyer, Lopez, Ganitkevitch, Weese, Ture, Blunsom, Setiawan, Eidelman, Resnik, 2010</marker>
<rawString>Chris Dyer, Adam Lopez, Juri Ganitkevitch, Jonathan Weese, Ferhan Ture, Phil Blunsom, Hendra Setiawan, Vladimir Eidelman, and Philip Resnik. 2010. cdec: A decoder, alignment, and learning framework for finite-state and context-free translation models. In Proceedings of the ACL 2010 System Demonstrations, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Dyer</author>
<author>Victor Chahuneau</author>
<author>Noah A Smith</author>
</authors>
<title>A simple, fast, and effective reparameterization of IBM Model 2.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<location>Atlanta, GA.</location>
<contexts>
<context position="16498" citStr="Dyer et al., 2013" startWordPosition="2635" endWordPosition="2638">s trained on data described and preprocessed by Sokolov et al. (2013), consisting of 1.8M parallel sentences from the NTCIR-7 JP-EN PatentMT subtask (Fujii et al., 2008) and 2k parallel sentences for parameter development from the NTCIR-8 test collection. For Wikipedia, we trained a DE-EN system on 4.1M parallel sentences from Europarl, Common Crawl, and NewsCommentary. Parameter tuning was done on 3k parallel sentences from the WMT’11 test set. 6 Experiments Experiment Settings. The SMT-based models use cdec (Dyer et al., 2010). Word alignments were created with mgiza (JP-EN) and fast align (Dyer et al., 2013) (DE-EN). Language models were trained with the KenLM toolkit (Heafield, 2011). The JP-EN system uses a 5-gram language model from the EN side of the training data. For the DE-EN system, a 4-gram model was built on the EN side of the training data and the EN Wikipedia documents. Weights for the standard feature set were optimized using cdec’s MERT (JP-EN) and MIRA (DE-EN) implementations (Och, 2003; Chiang et al., 2008). PSQ on patents reuses settings found by Sokolov et al. (2013); settings for Wikipedia were adjusted on its dev set (n=1000, A=0.4, L=0, C=1). Patent retrieval for DT was done </context>
</contexts>
<marker>Dyer, Chahuneau, Smith, 2013</marker>
<rawString>Chris Dyer, Victor Chahuneau, and Noah A. Smith. 2013. A simple, fast, and effective reparameterization of IBM Model 2. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies, Atlanta, GA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Ray Iyer</author>
<author>Robert E Schapire</author>
<author>Yoram Singer</author>
</authors>
<title>An efficient boosting algorithm for combining preferences.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>4--933</pages>
<contexts>
<context position="7777" citStr="Freund et al., 2003" startWordPosition="1200" endWordPosition="1203"> d) = qTWd = where W E IRQ×D encodes a matrix of rankingspecific word associations (Bai et al., 2010) . We optimize this model by pairwise ranking, which assumes labeled data in the form of a set R of tuples (q, d+, d−), where d+ is a relevant (or higher ranked) document and d− an irrelevant (or lower ranked) document for query q. The goal is to find a weight matrix W such that an inequality f(q, d+) &gt; f(q, d−) is violated for the fewest number of tuples from R. We present two methods for optimizing W in the following. Pairwise Ranking using Boosting (BM). The Boosting-based Ranking baseline (Freund et al., 2003) optimizes an exponential loss: ELexp = D(q, d+, d−)ef(q,d−)−f(q,d+), (q,d+,d−)ER where D(q, d+, d−) is a non-negative importance function on tuples. The algorithm of Sokolov et al. (2013) combines batch boosting with bagging over a number of independently drawn bootstrap data samples from R. In each step, the single word pair feature is selected that provides the largest decrease of Lexp. The found corresponding models are averaged. To reduce memory requirements we used random feature hashing with the size of the hash of 30 bits (Shi et al., 2009). For regularization we rely on early stopping</context>
</contexts>
<marker>Freund, Iyer, Schapire, Singer, 2003</marker>
<rawString>Yoav Freund, Ray Iyer, Robert E. Schapire, and Yoram Singer. 2003. An efficient boosting algorithm for combining preferences. Journal of Machine Learning Research, 4:933–969.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Atsushi Fujii</author>
<author>Masao Utiyama</author>
<author>Mikio Yamamoto</author>
<author>Takehito Utsuro</author>
</authors>
<title>Overview of the patent translation task at the NTCIR-7 workshop.</title>
<date>2008</date>
<booktitle>In Proceedings of NTCIR-7 Workshop Meeting,</booktitle>
<location>Tokyo, Japan.</location>
<contexts>
<context position="16049" citStr="Fujii et al., 2008" startWordPosition="2562" endWordPosition="2565">ize, we applied similar preprocessing and CFH with F=30k and k=5. Since for Wikipedia data, the DE and EN vocabularies were both large (6.7M and 6M), we used the same filtering and preprocessing as for the patent data before applying CFH with F=40k and k=5 on both sides. Parallel Data for SMT-based CLIR. For both tasks, DT and PSQ require an SMT baseline system trained on parallel corpora that are disjunct from the ranking data. A JP-EN system was trained on data described and preprocessed by Sokolov et al. (2013), consisting of 1.8M parallel sentences from the NTCIR-7 JP-EN PatentMT subtask (Fujii et al., 2008) and 2k parallel sentences for parameter development from the NTCIR-8 test collection. For Wikipedia, we trained a DE-EN system on 4.1M parallel sentences from Europarl, Common Crawl, and NewsCommentary. Parameter tuning was done on 3k parallel sentences from the WMT’11 test set. 6 Experiments Experiment Settings. The SMT-based models use cdec (Dyer et al., 2010). Word alignments were created with mgiza (JP-EN) and fast align (Dyer et al., 2013) (DE-EN). Language models were trained with the KenLM toolkit (Heafield, 2011). The JP-EN system uses a 5-gram language model from the EN side of the t</context>
</contexts>
<marker>Fujii, Utiyama, Yamamoto, Utsuro, 2008</marker>
<rawString>Atsushi Fujii, Masao Utiyama, Mikio Yamamoto, and Takehito Utsuro. 2008. Overview of the patent translation task at the NTCIR-7 workshop. In Proceedings of NTCIR-7 Workshop Meeting, Tokyo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sharad Goel</author>
<author>John Langford</author>
<author>Alexander L Strehl</author>
</authors>
<title>Predictive indexing for fast search.</title>
<date>2008</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<location>Vancouver, Canada.</location>
<contexts>
<context position="8743" citStr="Goel et al., 2008" startWordPosition="1365" endWordPosition="1368"> that provides the largest decrease of Lexp. The found corresponding models are averaged. To reduce memory requirements we used random feature hashing with the size of the hash of 30 bits (Shi et al., 2009). For regularization we rely on early stopping. Pairwise Ranking with SGD (VW). The second objective is an `1-regularized hinge loss: ELlyng = (f(q, d+) − f(q, d−)) + + A||W||1, (q,d+,d−)ER E Q i=1 qiWijdj, ED j=1 489 where (x)+ = max(0,1 − x) and A is the regularization parameter. This newly added model utilizes the standard implementation of online SGD from the Vowpal Wabbit (VW) toolkit (Goel et al., 2008) and was run on a data sample of 5M to 10M tuples from R. On each step, W is updated with a scaled gradient vector VWLhng and clipped to account for `1-regularization. Memory usage was reduced using the same hashing technique as for boosting. Domain Knowledge Models. Domain knowledge features for patents were inspired by Guo and Gomes (2009): a feature fires if two patents share similar aspects, e.g. a common inventor. As we do not have access to address data, we omit geolocation features and instead add features that evaluate similarity w.r.t. patent classes extracted from IPC codes. Document</context>
</contexts>
<marker>Goel, Langford, Strehl, 2008</marker>
<rawString>Sharad Goel, John Langford, and Alexander L. Strehl. 2008. Predictive indexing for fast search. In Advances in Neural Information Processing Systems, Vancouver, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yunsong Guo</author>
<author>Carla Gomes</author>
</authors>
<title>Ranking structured documents: A large margin based approach for patent prior art search.</title>
<date>2009</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI’09),</booktitle>
<location>Pasadena, CA.</location>
<contexts>
<context position="2888" citStr="Guo and Gomes (2009)" startWordPosition="421" endWordPosition="424">estigate whether a Wikipedia article covering the subject the author intends to write about already exists in another language. Since authors are encouraged to avoid orphan articles and to cite their sources, Wikipedia has a rich linking structure between related articles, which can be exploited to create relevance links between articles across languages (Bai et al., 2010). Besides a rich citation structure, patent documents and Wikipedia articles contain a number of further cues on relatedness that can be exploited as features in learning-to-rank approaches. For monolingual patent retrieval, Guo and Gomes (2009) and Oh et al. (2013) advocate the use of dense features encoding domain knowledge on inventors, assignees, location and date, together with dense similarity scores based on bag-of-word representations of patents. Bai et al. (2010) show that for the domain of Wikipedia, learning a sparse matrix of word associations between the query and document vocabularies from relevance rankings is useful in monolingual and cross-lingual retrieval. Sokolov et al. (2013) apply the idea of learning a sparse matrix of bilingual phrase associations from relevance rankings to cross-lingual retrieval in the paten</context>
<context position="5916" citStr="Guo and Gomes (2009)" startWordPosition="877" endWordPosition="880">rely on token-to-token translations that are used to project the query terms into the target language with a probabilistic weighting of the standard term tfidf scheme. Darwish and Oard (2003) termed this method the probabilistic structured query approach (PSQ). The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations (Xu et al., 2001). Ture et al. (2012) brought SMT back into this paradigm by projecting terms from n-best translations from synchronous context-free grammars. Ranking approaches have been presented by Guo and Gomes (2009) and Oh et al. (2013). Their method is a classical learning-to-rank setup where pairwise ranking is applied to a few hundred dense features. Methods to learn sparse word-based translation correspondences from supervised ranking signals have been presented by Bai et al. (2010) and Sokolov et al. (2013). Both approaches work in a cross-lingual setting, the former on Wikipedia data, the latter on patents. Our approach extends the work of Sokolov et al. (2013) by presenting an alternative learningto-rank approach that can be used for supervised model combination to integrate dense and sparse featu</context>
<context position="9086" citStr="Guo and Gomes (2009)" startWordPosition="1425" endWordPosition="1428">Llyng = (f(q, d+) − f(q, d−)) + + A||W||1, (q,d+,d−)ER E Q i=1 qiWijdj, ED j=1 489 where (x)+ = max(0,1 − x) and A is the regularization parameter. This newly added model utilizes the standard implementation of online SGD from the Vowpal Wabbit (VW) toolkit (Goel et al., 2008) and was run on a data sample of 5M to 10M tuples from R. On each step, W is updated with a scaled gradient vector VWLhng and clipped to account for `1-regularization. Memory usage was reduced using the same hashing technique as for boosting. Domain Knowledge Models. Domain knowledge features for patents were inspired by Guo and Gomes (2009): a feature fires if two patents share similar aspects, e.g. a common inventor. As we do not have access to address data, we omit geolocation features and instead add features that evaluate similarity w.r.t. patent classes extracted from IPC codes. Documents within a patent section, i.e. the topmost hierarchy, are too diverse to provide useful information but more detailed classes and the count of matching classes do. For Wikipedia, we implemented features that compare the relative length of documents, number of links and images, the number of common links and common images, and Wikipedia cate</context>
</contexts>
<marker>Guo, Gomes, 2009</marker>
<rawString>Yunsong Guo and Carla Gomes. 2009. Ranking structured documents: A large margin based approach for patent prior art search. In Proceedings of the International Joint Conference on Artificial Intelligence (IJCAI’09), Pasadena, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Heafield</author>
</authors>
<title>KenLM: faster and smaller language model queries.</title>
<date>2011</date>
<booktitle>In Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation (WMT’11),</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="16576" citStr="Heafield, 2011" startWordPosition="2649" endWordPosition="2650"> of 1.8M parallel sentences from the NTCIR-7 JP-EN PatentMT subtask (Fujii et al., 2008) and 2k parallel sentences for parameter development from the NTCIR-8 test collection. For Wikipedia, we trained a DE-EN system on 4.1M parallel sentences from Europarl, Common Crawl, and NewsCommentary. Parameter tuning was done on 3k parallel sentences from the WMT’11 test set. 6 Experiments Experiment Settings. The SMT-based models use cdec (Dyer et al., 2010). Word alignments were created with mgiza (JP-EN) and fast align (Dyer et al., 2013) (DE-EN). Language models were trained with the KenLM toolkit (Heafield, 2011). The JP-EN system uses a 5-gram language model from the EN side of the training data. For the DE-EN system, a 4-gram model was built on the EN side of the training data and the EN Wikipedia documents. Weights for the standard feature set were optimized using cdec’s MERT (JP-EN) and MIRA (DE-EN) implementations (Och, 2003; Chiang et al., 2008). PSQ on patents reuses settings found by Sokolov et al. (2013); settings for Wikipedia were adjusted on its dev set (n=1000, A=0.4, L=0, C=1). Patent retrieval for DT was done by sentencewise translation and subsequent re-joining to form one query per pa</context>
</contexts>
<marker>Heafield, 2011</marker>
<rawString>Kenneth Heafield. 2011. KenLM: faster and smaller language model queries. In Proceedings of the EMNLP 2011 Sixth Workshop on Statistical Machine Translation (WMT’11), Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kalervo J¨arvelin</author>
<author>Jaana Kek¨al¨ainen</author>
</authors>
<title>Cumulated gain-based evaluation of IR techniques.</title>
<date>2002</date>
<journal>ACM Transactions in Information Systems,</journal>
<volume>20</volume>
<issue>4</issue>
<pages>446</pages>
<marker>J¨arvelin, Kek¨al¨ainen, 2002</marker>
<rawString>Kalervo J¨arvelin and Jaana Kek¨al¨ainen. 2002. Cumulated gain-based evaluation of IR techniques. ACM Transactions in Information Systems, 20(4):422– 446.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Walid Magdy</author>
<author>Gareth J F Jones</author>
</authors>
<title>PRES: a score metric for evaluating recall-oriented information retrieval applications.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACM SIGIR conference on Research and development in information retrieval (SIGIR’10),</booktitle>
<location>New York, NY.</location>
<contexts>
<context position="19183" citStr="Magdy and Jones, 2010" startWordPosition="3076" endWordPosition="3079">rbitrary ranking models as dense features. In difference to grid search for Borda, optimal weights for the linear combination of incorporated ranking models can be learned automatically. We investigate the same combinations of ranking models as described for Borda above. We do not report combination results including the sparse BM model since they were consistently lower than the ones with the sparse VW model. Test Results. Experimental results on test data are given in Table 2. Results are reported with respect to MAP (Manning et al., 2008), NDCG (J¨arvelin and Kek¨al¨ainen, 2002), and PRES (Magdy and Jones, 2010). Scores were computed on the top 1,000 retrieved documents. As can be seen from inspecting the two blocks of results, one for patents, one for Wikipedia, we find the same system rankings on both datasets. In both cases, as standalone systems, DT and PSQ are very close and far better than any ranking approach, irrespective of the objective function or the choice of sparse or dense features. Model combination of similar models, e.g., DT and PSQ, gives minimal gains, compared to combining orthogonal models, e.g. DK and VW. The best result is achieved by combining DT and PSQ with DK and VW. This </context>
</contexts>
<marker>Magdy, Jones, 2010</marker>
<rawString>Walid Magdy and Gareth J.F. Jones. 2010. PRES: a score metric for evaluating recall-oriented information retrieval applications. In Proceedings of the ACM SIGIR conference on Research and development in information retrieval (SIGIR’10), New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Prabhakar Raghavan</author>
<author>Hinrich Sch¨utze</author>
</authors>
<title>Introduction to Information Retrieval.</title>
<date>2008</date>
<publisher>Cambridge University Press.</publisher>
<marker>Manning, Raghavan, Sch¨utze, 2008</marker>
<rawString>Christopher D. Manning, Prabhakar Raghavan, and Hinrich Sch¨utze. 2008. Introduction to Information Retrieval. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Meeting on Association for Computational Linguistics (ACL’03),</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="16899" citStr="Och, 2003" startWordPosition="2706" endWordPosition="2707">lel sentences from the WMT’11 test set. 6 Experiments Experiment Settings. The SMT-based models use cdec (Dyer et al., 2010). Word alignments were created with mgiza (JP-EN) and fast align (Dyer et al., 2013) (DE-EN). Language models were trained with the KenLM toolkit (Heafield, 2011). The JP-EN system uses a 5-gram language model from the EN side of the training data. For the DE-EN system, a 4-gram model was built on the EN side of the training data and the EN Wikipedia documents. Weights for the standard feature set were optimized using cdec’s MERT (JP-EN) and MIRA (DE-EN) implementations (Och, 2003; Chiang et al., 2008). PSQ on patents reuses settings found by Sokolov et al. (2013); settings for Wikipedia were adjusted on its dev set (n=1000, A=0.4, L=0, C=1). Patent retrieval for DT was done by sentencewise translation and subsequent re-joining to form one query per patent, which was ranked against the documents using BM25. For PSQ, BM25 is computed on expected term and document frequencies. For ranking-based retrieval, we compare several combinations of learners and features (Table 2). VW denotes a sparse model using word-based features trained with SGD. BM denotes a similar model tra</context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In Proceedings of the 41st Meeting on Association for Computational Linguistics (ACL’03), Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sooyoung Oh</author>
<author>Zhen Lei</author>
<author>Wang-Chien Lee</author>
<author>Prasenjit Mitra</author>
<author>John Yen</author>
</authors>
<title>CV-PCR: A contextguided value-driven framework for patent citation recommendation.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Conference on Information and Knowledge Management (CIKM’13),</booktitle>
<location>San Francisco, CA.</location>
<contexts>
<context position="2909" citStr="Oh et al. (2013)" startWordPosition="426" endWordPosition="429">dia article covering the subject the author intends to write about already exists in another language. Since authors are encouraged to avoid orphan articles and to cite their sources, Wikipedia has a rich linking structure between related articles, which can be exploited to create relevance links between articles across languages (Bai et al., 2010). Besides a rich citation structure, patent documents and Wikipedia articles contain a number of further cues on relatedness that can be exploited as features in learning-to-rank approaches. For monolingual patent retrieval, Guo and Gomes (2009) and Oh et al. (2013) advocate the use of dense features encoding domain knowledge on inventors, assignees, location and date, together with dense similarity scores based on bag-of-word representations of patents. Bai et al. (2010) show that for the domain of Wikipedia, learning a sparse matrix of word associations between the query and document vocabularies from relevance rankings is useful in monolingual and cross-lingual retrieval. Sokolov et al. (2013) apply the idea of learning a sparse matrix of bilingual phrase associations from relevance rankings to cross-lingual retrieval in the patent domain. Both show i</context>
<context position="5937" citStr="Oh et al. (2013)" startWordPosition="882" endWordPosition="885">anslations that are used to project the query terms into the target language with a probabilistic weighting of the standard term tfidf scheme. Darwish and Oard (2003) termed this method the probabilistic structured query approach (PSQ). The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations (Xu et al., 2001). Ture et al. (2012) brought SMT back into this paradigm by projecting terms from n-best translations from synchronous context-free grammars. Ranking approaches have been presented by Guo and Gomes (2009) and Oh et al. (2013). Their method is a classical learning-to-rank setup where pairwise ranking is applied to a few hundred dense features. Methods to learn sparse word-based translation correspondences from supervised ranking signals have been presented by Bai et al. (2010) and Sokolov et al. (2013). Both approaches work in a cross-lingual setting, the former on Wikipedia data, the latter on patents. Our approach extends the work of Sokolov et al. (2013) by presenting an alternative learningto-rank approach that can be used for supervised model combination to integrate dense and sparse features, and by evaluatin</context>
</contexts>
<marker>Oh, Lei, Lee, Mitra, Yen, 2013</marker>
<rawString>Sooyoung Oh, Zhen Lei, Wang-Chien Lee, Prasenjit Mitra, and John Yen. 2013. CV-PCR: A contextguided value-driven framework for patent citation recommendation. In Proceedings of the International Conference on Information and Knowledge Management (CIKM’13), San Francisco, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Sheldon</author>
<author>Milad Shokouhi</author>
<author>Martin Szummer</author>
<author>Nick Craswell</author>
</authors>
<title>Lambdamerge: Merging the results of query reformulations.</title>
<date>2011</date>
<booktitle>In Proceedings of WSDM’11,</booktitle>
<location>Hong Kong, China.</location>
<contexts>
<context position="6692" citStr="Sheldon et al., 2011" startWordPosition="1000" endWordPosition="1003">rn sparse word-based translation correspondences from supervised ranking signals have been presented by Bai et al. (2010) and Sokolov et al. (2013). Both approaches work in a cross-lingual setting, the former on Wikipedia data, the latter on patents. Our approach extends the work of Sokolov et al. (2013) by presenting an alternative learningto-rank approach that can be used for supervised model combination to integrate dense and sparse features, and by evaluating both approaches on cross-lingual retrieval for patents and Wikipedia. This relates our work to supervised model merging approaches (Sheldon et al., 2011). 3 Translation and Ranking for CLIR SMT-based Models. We will refer to DT and PSQ as SMT-based models that translate a query, and then perform monolingual retrieval using BM25. Translation is agnostic of the retrieval task. Linear Ranking for Word-Based Models. Let q E {0,1}Q be a query and d E {0,1}D be a document where the jth vector dimension indicates the occurrence of the jth word for dictionaries of size Q and D. A linear ranking model is defined as f(q, d) = qTWd = where W E IRQ×D encodes a matrix of rankingspecific word associations (Bai et al., 2010) . We optimize this model by pairw</context>
</contexts>
<marker>Sheldon, Shokouhi, Szummer, Craswell, 2011</marker>
<rawString>Daniel Sheldon, Milad Shokouhi, Martin Szummer, and Nick Craswell. 2011. Lambdamerge: Merging the results of query reformulations. In Proceedings of WSDM’11, Hong Kong, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qinfeng Shi</author>
<author>James Petterson</author>
<author>Gideon Dror</author>
<author>John Langford</author>
<author>Alexander J Smola</author>
<author>Alexander L Strehl</author>
<author>Vishy Vishwanathan</author>
</authors>
<title>Hash Kernels.</title>
<date>2009</date>
<booktitle>In Proceedings of the 12th Int. Conference on Artificial Intelligence and Statistics (AISTATS’09),</booktitle>
<location>Irvine, CA.</location>
<contexts>
<context position="8331" citStr="Shi et al., 2009" startWordPosition="1290" endWordPosition="1293">(BM). The Boosting-based Ranking baseline (Freund et al., 2003) optimizes an exponential loss: ELexp = D(q, d+, d−)ef(q,d−)−f(q,d+), (q,d+,d−)ER where D(q, d+, d−) is a non-negative importance function on tuples. The algorithm of Sokolov et al. (2013) combines batch boosting with bagging over a number of independently drawn bootstrap data samples from R. In each step, the single word pair feature is selected that provides the largest decrease of Lexp. The found corresponding models are averaged. To reduce memory requirements we used random feature hashing with the size of the hash of 30 bits (Shi et al., 2009). For regularization we rely on early stopping. Pairwise Ranking with SGD (VW). The second objective is an `1-regularized hinge loss: ELlyng = (f(q, d+) − f(q, d−)) + + A||W||1, (q,d+,d−)ER E Q i=1 qiWijdj, ED j=1 489 where (x)+ = max(0,1 − x) and A is the regularization parameter. This newly added model utilizes the standard implementation of online SGD from the Vowpal Wabbit (VW) toolkit (Goel et al., 2008) and was run on a data sample of 5M to 10M tuples from R. On each step, W is updated with a scaled gradient vector VWLhng and clipped to account for `1-regularization. Memory usage was red</context>
</contexts>
<marker>Shi, Petterson, Dror, Langford, Smola, Strehl, Vishwanathan, 2009</marker>
<rawString>Qinfeng Shi, James Petterson, Gideon Dror, John Langford, Alexander J. Smola, Alexander L. Strehl, and Vishy Vishwanathan. 2009. Hash Kernels. In Proceedings of the 12th Int. Conference on Artificial Intelligence and Statistics (AISTATS’09), Irvine, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jason R Smith</author>
<author>Chris Quirk</author>
<author>Kristina Toutanova</author>
</authors>
<title>Extracting parallel sentences from comparable corpora using document level alignment.</title>
<date>2010</date>
<booktitle>In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT’10),</booktitle>
<location>Los Angeles, CA.</location>
<contexts>
<context position="1661" citStr="Smith et al., 2010" startWordPosition="232" endWordPosition="235">ranslation (SMT) to either produce a single most probable translation, or a weighted list of alternatives, that is used as search query to a standard search engine (Chin et al., 2008; Ture et al., 2012). This approach is advantageous if large amounts of indomain sentence-parallel data are available to train SMT systems, but relevance rankings to train retrieval models are not. The situation is different for CLIR in special domains such as patents or Wikipedia. Parallel data for translation have to be extracted with some effort from comparable or noisy parallel data (Utiyama and Isahara, 2007; Smith et al., 2010), however, relevance judgments are often straightforwardly encoded in special domains. For example, in patent prior art search, patents granted at any patent office worldwide are considered relevant if they constitute prior art with respect to the invention claimed in the query patent. Since patent applicants and lawyers are required to list relevant prior work explicitly in the patent application, patent citations can be used to automatically extract large amounts of relevance judgments across languages (Graf and Azzopardi, 2008). In Wikipedia search, one can imagine a Wikipedia author trying</context>
</contexts>
<marker>Smith, Quirk, Toutanova, 2010</marker>
<rawString>Jason R. Smith, Chris Quirk, and Kristina Toutanova. 2010. Extracting parallel sentences from comparable corpora using document level alignment. In Proceedings of Human Language Technologies: The 11th Annual Conference of the North American Chapter of the Association for Computational Linguistics (NAACL-HLT’10), Los Angeles, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark D Smucker</author>
<author>James Allan</author>
<author>Ben Carterette</author>
</authors>
<title>A comparison of statistical significance tests for information retrieval evaluation.</title>
<date>2007</date>
<booktitle>In Proceedings of the 16th ACM conference on Conference on Information and Knowledge Management (CIKM ’07),</booktitle>
<location>New York, NY.</location>
<contexts>
<context position="18010" citStr="Smucker et al., 2007" startWordPosition="2887" endWordPosition="2890">Table 2). VW denotes a sparse model using word-based features trained with SGD. BM denotes a similar model trained using Boosting. DK denotes VW training of a model that represents queries q and documents d by dense domain-knowledge features instead of by sparse word-based vectors. In 491 order to simulate pass-through behavior of out-ofvocabulary terms in SMT systems, additional features accounting for source and target term identity were added to DK and BM models. The parameter λ for VW was found on dev set. Statistical significance testing was performed using the paired randomization test (Smucker et al., 2007). Borda denotes model combination by Borda Count voting where the linear interpolation parameter is adjusted for MAP on the respective development sets with grid search. This type of model combination only allows to combine pairs of rankings. We present a combination of SMTbased CLIR, DT+PSQ, a combination of dense and sparse features, DK+VW, and a combination of both combinations, (DT+PSQ)+(DK+VW). LinLearn denotes model combination by overloading the vector representation of queries q and documents d in the VW linear learner by incorporating arbitrary ranking models as dense features. In dif</context>
</contexts>
<marker>Smucker, Allan, Carterette, 2007</marker>
<rawString>Mark D. Smucker, James Allan, and Ben Carterette. 2007. A comparison of statistical significance tests for information retrieval evaluation. In Proceedings of the 16th ACM conference on Conference on Information and Knowledge Management (CIKM ’07), New York, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Artem Sokolov</author>
<author>Laura Jehl</author>
<author>Felix Hieber</author>
<author>Stefan Riezler</author>
</authors>
<title>Boosting cross-language retrieval by learning bilingual phrase associations from relevance rankings.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’13).</booktitle>
<contexts>
<context position="3348" citStr="Sokolov et al. (2013)" startWordPosition="490" endWordPosition="493"> a number of further cues on relatedness that can be exploited as features in learning-to-rank approaches. For monolingual patent retrieval, Guo and Gomes (2009) and Oh et al. (2013) advocate the use of dense features encoding domain knowledge on inventors, assignees, location and date, together with dense similarity scores based on bag-of-word representations of patents. Bai et al. (2010) show that for the domain of Wikipedia, learning a sparse matrix of word associations between the query and document vocabularies from relevance rankings is useful in monolingual and cross-lingual retrieval. Sokolov et al. (2013) apply the idea of learning a sparse matrix of bilingual phrase associations from relevance rankings to cross-lingual retrieval in the patent domain. Both show improvements of learning-to-rank on relevance data over SMTbased approaches on their respective domains. The main contribution of this paper is a thorough evaluation of dense and sparse features for learning-to-rank that have so far been used only monolingually or only on either patents or Wikipedia. We show that for both domains, patents and Wikipedia, jointly learning bilingual sparse word associations and dense knowledgebased similar</context>
<context position="6218" citStr="Sokolov et al. (2013)" startWordPosition="926" endWordPosition="929">mplicit query expansion effect due to the use of probability distributions over term translations (Xu et al., 2001). Ture et al. (2012) brought SMT back into this paradigm by projecting terms from n-best translations from synchronous context-free grammars. Ranking approaches have been presented by Guo and Gomes (2009) and Oh et al. (2013). Their method is a classical learning-to-rank setup where pairwise ranking is applied to a few hundred dense features. Methods to learn sparse word-based translation correspondences from supervised ranking signals have been presented by Bai et al. (2010) and Sokolov et al. (2013). Both approaches work in a cross-lingual setting, the former on Wikipedia data, the latter on patents. Our approach extends the work of Sokolov et al. (2013) by presenting an alternative learningto-rank approach that can be used for supervised model combination to integrate dense and sparse features, and by evaluating both approaches on cross-lingual retrieval for patents and Wikipedia. This relates our work to supervised model merging approaches (Sheldon et al., 2011). 3 Translation and Ranking for CLIR SMT-based Models. We will refer to DT and PSQ as SMT-based models that translate a query,</context>
<context position="7965" citStr="Sokolov et al. (2013)" startWordPosition="1228" endWordPosition="1231">of a set R of tuples (q, d+, d−), where d+ is a relevant (or higher ranked) document and d− an irrelevant (or lower ranked) document for query q. The goal is to find a weight matrix W such that an inequality f(q, d+) &gt; f(q, d−) is violated for the fewest number of tuples from R. We present two methods for optimizing W in the following. Pairwise Ranking using Boosting (BM). The Boosting-based Ranking baseline (Freund et al., 2003) optimizes an exponential loss: ELexp = D(q, d+, d−)ef(q,d−)−f(q,d+), (q,d+,d−)ER where D(q, d+, d−) is a non-negative importance function on tuples. The algorithm of Sokolov et al. (2013) combines batch boosting with bagging over a number of independently drawn bootstrap data samples from R. In each step, the single word pair feature is selected that provides the largest decrease of Lexp. The found corresponding models are averaged. To reduce memory requirements we used random feature hashing with the size of the hash of 30 bits (Shi et al., 2009). For regularization we rely on early stopping. Pairwise Ranking with SGD (VW). The second objective is an `1-regularized hinge loss: ELlyng = (f(q, d+) − f(q, d−)) + + A||W||1, (q,d+,d−)ER E Q i=1 qiWijdj, ED j=1 489 where (x)+ = max</context>
<context position="10996" citStr="Sokolov et al., 2013" startWordPosition="1739" endWordPosition="1742">ditional models including domain knowledge features was done by overloading the vector representation of queries q and documents d in the VW linear learner: Instead of sparse word-based features, q and d are represented by real-valued vectors of dense domainknowledge features. Optimization for the overloaded vectors is done as described above for VW. 4 Model Combination Combination by Borda Counts. The baseline consensus-based voting Borda Count procedure endows each voter with a fixed amount of voting points which he is free to distribute among the scored documents (Aslam and Montague, 2001; Sokolov et al., 2013). The aggregate score for two rankings f1(q, d) and f2(q, d) for all (q, d) in the test set is then a simple linear interpolation: fagg(q, d) = κ f1(q,d) � d f1(q,d) +(1−κ)f2(q,d) �d f2(q,d). Parameter κ was adjusted on the dev set. Combination by Linear Learning. In order to acquire the best combination of more than two models, we created vectors of model scores along with domain knowledge features and reused the VW pairwise ranking approach. This means that the vector representation of queries q and documents d in the VW linear learner is overloaded once more: In addition to dense domainknow</context>
<context position="15949" citStr="Sokolov et al. (2013)" startWordPosition="2547" endWordPosition="2550">ww.cl.uni-heidelberg.de/wikiclir 5lintool.github.io/Cloud9/index.html 6www.nltk.org/ to a comparable size, we applied similar preprocessing and CFH with F=30k and k=5. Since for Wikipedia data, the DE and EN vocabularies were both large (6.7M and 6M), we used the same filtering and preprocessing as for the patent data before applying CFH with F=40k and k=5 on both sides. Parallel Data for SMT-based CLIR. For both tasks, DT and PSQ require an SMT baseline system trained on parallel corpora that are disjunct from the ranking data. A JP-EN system was trained on data described and preprocessed by Sokolov et al. (2013), consisting of 1.8M parallel sentences from the NTCIR-7 JP-EN PatentMT subtask (Fujii et al., 2008) and 2k parallel sentences for parameter development from the NTCIR-8 test collection. For Wikipedia, we trained a DE-EN system on 4.1M parallel sentences from Europarl, Common Crawl, and NewsCommentary. Parameter tuning was done on 3k parallel sentences from the WMT’11 test set. 6 Experiments Experiment Settings. The SMT-based models use cdec (Dyer et al., 2010). Word alignments were created with mgiza (JP-EN) and fast align (Dyer et al., 2013) (DE-EN). Language models were trained with the Ken</context>
</contexts>
<marker>Sokolov, Jehl, Hieber, Riezler, 2013</marker>
<rawString>Artem Sokolov, Laura Jehl, Felix Hieber, and Stefan Riezler. 2013. Boosting cross-language retrieval by learning bilingual phrase associations from relevance rankings. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP’13).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ferhan Ture</author>
<author>Jimmy Lin</author>
<author>Douglas W Oard</author>
</authors>
<title>Combining statistical translation techniques for cross-language information retrieval.</title>
<date>2012</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING’12),</booktitle>
<location>Bombay, India.</location>
<contexts>
<context position="1244" citStr="Ture et al., 2012" startWordPosition="164" endWordPosition="167">t search and cross-lingual retrieval in Wikipedia, our approach yields considerable improvements over learningto-rank with either only dense or only sparse features, and over very competitive baselines that combine state-of-the-art machine translation and retrieval. 1 Introduction Cross-Language Information Retrieval (CLIR) for the domain of web search successfully leverages state-of-the-art Statistical Machine Translation (SMT) to either produce a single most probable translation, or a weighted list of alternatives, that is used as search query to a standard search engine (Chin et al., 2008; Ture et al., 2012). This approach is advantageous if large amounts of indomain sentence-parallel data are available to train SMT systems, but relevance rankings to train retrieval models are not. The situation is different for CLIR in special domains such as patents or Wikipedia. Parallel data for translation have to be extracted with some effort from comparable or noisy parallel data (Utiyama and Isahara, 2007; Smith et al., 2010), however, relevance judgments are often straightforwardly encoded in special domains. For example, in patent prior art search, patents granted at any patent office worldwide are cons</context>
<context position="5732" citStr="Ture et al. (2012)" startWordPosition="849" endWordPosition="852">es their state-of-the-art SMT system with their proprietary search engine (Chin et al., 2008). Alternative approaches avoid to solve the hard problem of word reordering, and instead rely on token-to-token translations that are used to project the query terms into the target language with a probabilistic weighting of the standard term tfidf scheme. Darwish and Oard (2003) termed this method the probabilistic structured query approach (PSQ). The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations (Xu et al., 2001). Ture et al. (2012) brought SMT back into this paradigm by projecting terms from n-best translations from synchronous context-free grammars. Ranking approaches have been presented by Guo and Gomes (2009) and Oh et al. (2013). Their method is a classical learning-to-rank setup where pairwise ranking is applied to a few hundred dense features. Methods to learn sparse word-based translation correspondences from supervised ranking signals have been presented by Bai et al. (2010) and Sokolov et al. (2013). Both approaches work in a cross-lingual setting, the former on Wikipedia data, the latter on patents. Our approa</context>
</contexts>
<marker>Ture, Lin, Oard, 2012</marker>
<rawString>Ferhan Ture, Jimmy Lin, and Douglas W. Oard. 2012. Combining statistical translation techniques for cross-language information retrieval. In Proceedings of the International Conference on Computational Linguistics (COLING’12), Bombay, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masao Utiyama</author>
<author>Hitoshi Isahara</author>
</authors>
<title>A Japanese-English patent parallel corpus.</title>
<date>2007</date>
<booktitle>In Proceedings of MT</booktitle>
<location>Summit XI, Copenhagen, Denmark.</location>
<contexts>
<context position="1640" citStr="Utiyama and Isahara, 2007" startWordPosition="228" endWordPosition="231">e-art Statistical Machine Translation (SMT) to either produce a single most probable translation, or a weighted list of alternatives, that is used as search query to a standard search engine (Chin et al., 2008; Ture et al., 2012). This approach is advantageous if large amounts of indomain sentence-parallel data are available to train SMT systems, but relevance rankings to train retrieval models are not. The situation is different for CLIR in special domains such as patents or Wikipedia. Parallel data for translation have to be extracted with some effort from comparable or noisy parallel data (Utiyama and Isahara, 2007; Smith et al., 2010), however, relevance judgments are often straightforwardly encoded in special domains. For example, in patent prior art search, patents granted at any patent office worldwide are considered relevant if they constitute prior art with respect to the invention claimed in the query patent. Since patent applicants and lawyers are required to list relevant prior work explicitly in the patent application, patent citations can be used to automatically extract large amounts of relevance judgments across languages (Graf and Azzopardi, 2008). In Wikipedia search, one can imagine a Wi</context>
</contexts>
<marker>Utiyama, Isahara, 2007</marker>
<rawString>Masao Utiyama and Hitoshi Isahara. 2007. A Japanese-English patent parallel corpus. In Proceedings of MT Summit XI, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jinxi Xu</author>
<author>Ralph Weischedel</author>
<author>Chanh Nguyen</author>
</authors>
<title>Evaluating a probabilistic model for cross-lingual information retrieval.</title>
<date>2001</date>
<booktitle>In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’01),</booktitle>
<location>New York, NY.</location>
<contexts>
<context position="5712" citStr="Xu et al., 2001" startWordPosition="845" endWordPosition="848">IR approach combines their state-of-the-art SMT system with their proprietary search engine (Chin et al., 2008). Alternative approaches avoid to solve the hard problem of word reordering, and instead rely on token-to-token translations that are used to project the query terms into the target language with a probabilistic weighting of the standard term tfidf scheme. Darwish and Oard (2003) termed this method the probabilistic structured query approach (PSQ). The advantage of this technique is an implicit query expansion effect due to the use of probability distributions over term translations (Xu et al., 2001). Ture et al. (2012) brought SMT back into this paradigm by projecting terms from n-best translations from synchronous context-free grammars. Ranking approaches have been presented by Guo and Gomes (2009) and Oh et al. (2013). Their method is a classical learning-to-rank setup where pairwise ranking is applied to a few hundred dense features. Methods to learn sparse word-based translation correspondences from supervised ranking signals have been presented by Bai et al. (2010) and Sokolov et al. (2013). Both approaches work in a cross-lingual setting, the former on Wikipedia data, the latter on</context>
</contexts>
<marker>Xu, Weischedel, Nguyen, 2001</marker>
<rawString>Jinxi Xu, Ralph Weischedel, and Chanh Nguyen. 2001. Evaluating a probabilistic model for cross-lingual information retrieval. In Proceedings of the ACM SIGIR Conference on Research and Development in Information Retrieval (SIGIR’01), New York, NY.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>