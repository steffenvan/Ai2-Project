<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011197">
<title confidence="0.9976895">
Reengineering a domain-independent framework
for Spoken Dialogue Systems
</title>
<author confidence="0.976544">
Filipe M. Martins, Ana Mendes, M´arcio Viveiros, Joana Paulo Pardal,
Pedro Arez, Nuno J. Mamede and Jo˜ao Paulo Neto
</author>
<affiliation confidence="0.964153">
Spoken Language Systems Laboratory, L2F – INESC-ID
Department of Computer Science and Engineering,
Instituto Superior T´ecnico, Technical University of Lisbon
</affiliation>
<address confidence="0.75379">
R. Alves Redol, 9 - 2° – 1000-029 Lisboa, Portugal
</address>
<email confidence="0.849039">
{fmfm,acbm,mviveiros,joana,pedro,njm,jpn}@l2f.inesc-id.pt
http://www.l2f.inesc-id.pt
</email>
<sectionHeader confidence="0.990917" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999781368421053">
Our work in this area started as a re-
search project but when L2F joined TecnoVoz,
a Portuguese national consortium including
Academia and Industry partners, our focus
shifted to real-time professional solutions.
The integration of our domain-independent
Spoken Dialogue System (SDS) framework
into commercial products led to a major
reengineering process.
This paper describes the changes that the
framework went through and that deeply af-
fected its entire architecture. The communi-
cation core was enhanced, the modules inter-
faces were redefined for an easier integration,
the SDS deployment process was optimized
and the framework robustness was improved.
The work was done according to software en-
gineering guidelines and making use of design
patterns.
</bodyText>
<sectionHeader confidence="0.999134" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999967953488372">
Our SDS framework was created back in
2000 (Mour˜ao et al., 2004), as the result of
three graduation theses (Cassaca and Maia, 2002;
Mour˜ao et al., 2002; Viveiros, 2004), one of which
evolved into a masters thesis (Mour˜ao, 2005).
The framework is highly inspired on the TRIPS
architecture (Allen et al., 2000): it is a frame-based
domain-independent framework that can be used
to build domain-specific dialogue systems. Every
domain is described by a frame, composed by
domain slots that are filled with user requests.
When a set of domain slots is filled, a service is
executed. In order to do so, the dialogue system
interacts with the user until enough information is
provided.
From the initial version of the framework two
systems were created for two different domains: a
bus ticket vending system, which provides an in-
terface to access bus timetables; and a digital vir-
tual butler named Ambr´osio that controls home de-
vices, such as TVs (volume and channel), acclima-
tization systems, and lights (switch on/off and in-
tensity) through the X10 electrical protocol and the
IrDA (Infrared Data Association) standard. Since
2003, Ambr´osio is publicly available in the “House
of the Future”1, on the Portuguese Telecommunica-
tions Museum2.
As proof of concept, we have also built a pro-
totype system that helps the user while performing
some task. This was tested for the cooking domain
and the automobile reparation domain.
After the successful deployment of the mentioned
systems, we began developing two new automatic
telephone-based systems: a home banking system
and a personal assistant. These are part of a project
of the TecnoVoz3 consortium technology migration
to enterprises. To answer to the challenges that the
creation of those new systems brought to light, the
focus of the framework shifted from academic issues
to interactive use, real-time response and real users.
Since our goal was to integrate our SDS framework
into enterprise products, we started the development
of a commercial solution. Nevertheless, despite this
</bodyText>
<footnote confidence="0.999527">
1http://www.casadofuturo.org/
2http://www.fpc.pt/
3http://www.tecnovoz.pt/
</footnote>
<page confidence="0.988596">
68
</page>
<subsubsectionHeader confidence="0.470135">
Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 68–76,
</subsubsectionHeader>
<page confidence="0.44176">
Columbus, Ohio, USA, June 2008. c�2008 Association for Computational Linguistics
</page>
<bodyText confidence="0.999935333333334">
new focus, we wanted to maintain the research fea-
tures of the framework. This situation led to deep
changes in the framework development process: as
more robust techniques needed to be used to ensure
that new systems could easily be created to respond
to client requests. From this point of view, the goal
of the reengineering process was to create a frame-
work that provides means of rapid prototyping simi-
lar to those of Nuance4, Loquendo5 or Artificial So-
lutions6.
Also, the new systems we wanted to built carried
a significant change on the paradigm of the frame-
work: while in the first systems the effects of users’
actions were visible (as they could watch the lights
turning on and off, for instance) and a virtual agent
face provided feedback, in the new scenarios com-
munication is established only through a phone and,
being so, voice is the only feedback.
The new paradigm was the trigger to this pro-
cess and whenever a new issue needed to be solved
the best practices in similar successful systems were
studied. Not all can be mentioned. The most rele-
vant are described in what follows.
As it was previously mentioned, TRIPS was
the main inspiration for this framework. It is a
well known and stable architecture that has proven
its merits in accommodating a range of different
tasks (Allen et al., 2007; Jung et al., 2007). The
main modules of the system interact through a
Facilitator (Ferguson et al., 1996), similar to the
Galaxy HUB7 (Polifroni and Seneff, 2000) with
KQML (Labrou and Finin, 1997) messages. How-
ever, in TRIPS, the routing task is decentralized
since the sender modules decide where to send its
messages. At the same time, any module can sub-
scribe to selected messages through the Facilitator
according to the sender, the type of message or its
contents. This mechanism makes it easier to inte-
grate new modules that subscribe the relevant mes-
sages without the senders’ acknowledgment.
Like our framework, the CMU Olympus is a clas-
sical pipeline dialog system architecture (Bohus et
</bodyText>
<footnote confidence="0.999883333333333">
4http://www.nuance.com/
5http://www.loquendo.com/
6http://www.artificial-solutions.com/
7The Galaxy Hub maintains connections to modules (parser,
speech recognizer, back-end, etc.), and routes messages among
them. Seehttp://communicator.sourceforge.net/
</footnote>
<bodyText confidence="0.999754135135135">
al., 2007) where the modules are connected via a
Galaxy HUB that uses a central hub and a set of
rules for relaying messages from one component to
the other. It has the three usual main blocks: Lan-
guage Understanding, through Phoenix parser and
Helios confidence-based annotation module, Dia-
logue Management, through RavenClaw (Raux et
al., 2005; Bohus, 2004), and Language Generation,
through Rosetta. Recognition is made with Sphinx
and synthesis with Theta. The back-end applications
are directly connected to the HUB through an in-
cluded stub.
Some of our recent developments are also inspired
in Voice XML8, in an effort to simplify the frame-
work parameterization and development, required in
the enterprise context. Voice XML provides stan-
dard means of declarative configuration of new sys-
tems reducing the need of coding to the related de-
vices implementation (Nyberg et al., 2002).
Our reengineering work aimed at: i) making the
framework more robust and flexible, enhancing the
creation of new systems for different domains; ii)
simplifying the system’s development, debug and
deployment processes through common techniques
from software engineering areas, such as design pat-
terns (Gamma et al., 1994; Freeman et al., 2004).
By doing this, we are trying to promote the de-
velopment and deployment of new dialogue systems
with our framework.
This paper is organized as follows: Section 2
presents the initial version of the framework; Sec-
tion 3 describes its problems and limitations, as well
as the techniques we adopted to solve them; Sec-
tion 4 describes a brief empirical evaluation of the
reengineering work; finally, Section 5 closes the pa-
per with conclusions and some remarks about future
work directions.
</bodyText>
<sectionHeader confidence="0.94941" genericHeader="method">
2 Framework description
</sectionHeader>
<bodyText confidence="0.9994782">
This section briefly presents our architecture, at its
initial stage, before the reengineering process. We
also introduce some problems of the initial architec-
ture, as they will be later explained in the next sec-
tion.
</bodyText>
<footnote confidence="0.978624">
8http://www.w3.org/Voice/
</footnote>
<page confidence="0.999089">
69
</page>
<subsectionHeader confidence="0.66084">
2.1 Domain Model
</subsectionHeader>
<bodyText confidence="0.999923352941177">
The domain model that characterizes our framework
is composed by the following entities:
Domain, which includes a frame realization and
generalizes the information about several de-
vices;
Frame, which states the subset of slots to fill for a
given domain;
Device, which represents a real device with several
states and services. Only one active state exists,
at each time, for each device;
State, which includes a subset of services that are
active when the state is active;
Service, which instantiates a defined frame and
specifies a set of slots type of data and restric-
tions for that service.
When developing a new domain all these entities
have to be defined and instantiated.
</bodyText>
<subsectionHeader confidence="0.999666">
2.2 Framework architecture
</subsectionHeader>
<bodyText confidence="0.999949285714286">
Our initial framework came into existence as the re-
sult of the integration of three main modules:
Input/Output Manager, that controls an Automatic
Speech Recognition (ASR) module (Meinedo,
2008), a Text-To-Speech (TTS) module (Paulo
et al., 2008) and provides a virtual agent
face (Viveiros, 2004);
Dialogue Manager, that interprets the user inten-
tions and generates output messages (Mour˜ao
et al., 2002; Mour˜ao, 2005);
Service Manager, that provides a dialogue man-
ager interface to execute the requested services,
and an external application interface through
the device concept (Cassaca and Maia, 2002).
</bodyText>
<subsectionHeader confidence="0.989428">
2.3 Input/Output Manager
</subsectionHeader>
<bodyText confidence="0.99998612">
The Input/Output Manager (IOManager) controls an
ASR module and a TTS module. It also integrates
a virtual agent face, providing a more realistic in-
teraction with the user. The synchronization be-
tween the TTS output and the animated face is done
by an audio–face synchronization manager, which
generates the visemes9 for the corresponding TTS
phonemes information. The provided virtual agent
face is based on a state machine that informs, among
others, when the system is “thinking” or when what
the user said was not understood.
Besides, a Graphical User Interface (GUI) exists
for text interactions between the user and the system.
Although this input interface is usually only used for
test and debug proposes (as it skips the ASR mod-
ule), it could be used in combination with speech,
if requested by any specific multi-modal system im-
plementation.
The IOManager provides an interface to the Di-
alogue Manager that only includes text input and
output functions. However, the Dialogue Manager
needs to rely on other information, such as the in-
stant the user starts to speak or the moment a syn-
thesized sentence ends. These events are useful, for
instance, to set and trigger for user input timeouts.
</bodyText>
<subsectionHeader confidence="0.997814">
2.4 Dialogue Manager
</subsectionHeader>
<bodyText confidence="0.9969186">
The architecture of the Dialogue Manager (Figure 1)
has seven main modules: a Parser, an Interpretation
Manager, a Task Manager, a Behavior Agent, a Gen-
eration Manager, a Surface Generation and a Dis-
course Context.
</bodyText>
<figureCaption confidence="0.9379235">
Figure 1: Dialogue Manager architecture through the
central HUB. Numbers show the execution sequence.
</figureCaption>
<footnote confidence="0.913697666666667">
9A viseme is the visual representation of a phoneme and is
usually associated with muscles positioned near the region of
the mouth (Neto et al., 2006).
</footnote>
<figure confidence="0.9991904">
Input/
Output
Manager
[1, 20]
Discourse
Context
[4, 14]
Parser
[2]
Surface
Generation
[16, 19]
Interpretation
Manager
[3, 5, 8, 11]
HUB
Generation
Manager
[13, 15]
Task
Manager
[6, 9, 17]
Behavior
Agent
[12]
Service
Manager
[7,10,18]
External
Applications
</figure>
<page confidence="0.975402">
70
</page>
<bodyText confidence="0.999975375">
These modules have specific code from the im-
plementations of the two first systems (the bus ticket
vending system and the butler). When building a
generic dialogue framework, this situation turns out
to be a problem since domain-dependent code was
being used that was not appropriate in new systems.
Also, the modules have many code for HUB messag-
ing, which makes debug and development harder.
</bodyText>
<subsectionHeader confidence="0.999149">
2.5 Service Manager
</subsectionHeader>
<bodyText confidence="0.999390333333333">
The Service Manager (Figure 2) was initially devel-
oped to handle all domain specific information. It
has the following components:
Service Manager Galaxy Server, that works like a
HUB stub, managing the interface with the de-
vices and the Dialogue Manager;
Device Manager, that stores information related to
all devices. This information is used by the Di-
alogue Manager to find the service that should
be executed after an interaction;
Access Manager, that controls the user access to
some devices registered in the system;
Domain Manager, that stores all the information
about the domains. This information is used to
build interpretations and for the language gen-
eration process;
Object Recognition Manager, that recognizes the
discourse objects associated with a device;
Device Proxy, abstracts all communication with
the Device Core and device specific informa-
tion protocol. This is done through the Virtual
Proxy design pattern
Device Core, that implements the other part of the
communication protocol with the Service Man-
ager and the Dialogue Manager.
Since the Service Manager interface is shared by
the Dialogue Manager and all devices, a device can
execute a service that belongs to another device or
even access to internal Dialogue Manager informa-
tion.
</bodyText>
<figureCaption confidence="0.990495">
Figure 2: Service Manager architecture.
</figureCaption>
<sectionHeader confidence="0.811489" genericHeader="method">
3 Reengineering a framework
</sectionHeader>
<bodyText confidence="0.999934222222222">
When the challenge of building two new SDSs on
our framework appeared, some of the mentioned ar-
chitectural problems were highlighted. A reengi-
neering process was critical. A starting point for the
reengineering process was needed, even though that
decision was not clear.
By observing the framework’s data and control
flow, we noticed that part of the code in the different
modules was related with HUB messaging, namely
the creation of messages to send, and the conversion
of received messages into internal structures (mar-
shalling). A considerable amount of time was spent
in this task that was repeated across the framework.
Based on that, we decided that the first step should
be the analysis of the Galaxy HUB communication
flow and the XML structures used to encode those
messages, replacing them with more appropriate and
efficient protocols.
</bodyText>
<subsectionHeader confidence="0.998691">
3.1 Galaxy HUB and XML
</subsectionHeader>
<bodyText confidence="0.999974166666667">
The Galaxy HUB protocol is based in generic XML
messages. That allows new modules to be easily
plugged into the framework, written in any program-
ming language, without modifying any line of code.
However, we needed to improve the development
and debugging processes of the existing modules,
</bodyText>
<figure confidence="0.999441782608696">
Object
Recognition
Manager
HUB
Access
Manager
Device
Proxy
Service
Manager
Galaxy
Server
Device
Manager
Device Core
Device
specific
Implementation
Domain
Manager
External
Application
Database
</figure>
<page confidence="0.989412">
71
</page>
<bodyText confidence="0.999984051282051">
and having a time consuming task that was repeated
whenever two modules needed to communicate was
a serious drawback.
Considering this, we decided to remove the
Galaxy HUB. This decision was enforced by the
fact that all the framework modules were written
in the Java programming language, which already
provides direct invocations and objects serialization
through Java Remote Method Invocation (RMI).
The major advantage associated with the use of
this protocol, was the possibility of removing all the
XML-based messaging that repeatedly forced the
creation and interpretation of generic messages in
execution time. With the use of RMI, these struc-
tures were replaced by Java objects that are inter-
changed between modules transparently. Not only
RMI is native to Java.
This was not a simple task, as the team that was
responsible for this process was not the team who
originally developed the framework. Because of
this, the new team lacked familiarity with the overall
code structure. In order to reduce the complexity of
the process, it was necessary to create a proper in-
terface for each module removing the several entry
points that each one had. To better understand the
real flow and to minimize the introduction of new
bugs while refactoring the code we made the infor-
mation flow temporarily synchronous.
The internal structure of each module was re-
designed and every block of code with unknown
functionality was commented out.
This substitution improved the code quality and
both the development and the debugging processes.
We believe that it also improved the runtime effi-
ciency of the system, even though no evaluation of
the performance was made. Empirically, we can say
that in the new version of the system less time is
needed to complete a task since no explicit conver-
sion of the objects into generic messages is made.
</bodyText>
<subsectionHeader confidence="0.998147">
3.2 Domain dependent code
</subsectionHeader>
<bodyText confidence="0.999985714285714">
The code of the Parser, the Interpretation Manager
and the Surface Generation modules had domain de-
pendent code and it was necessary to clean it out.
Since we were modifying the Galaxy HUB code,
we took the opportunity and redesigned that code in
the aforementioned modules to make it more generic
(and, consequently less domain dependent). Being
so, the code cleaning process took place while the
Galaxy HUB was being replaced.
We were unable to redesign the domain dependent
code. Cases like hard-coded word replacement, used
both to provide a richer interpretation of the user ut-
terances and to allow giving a natural response to the
user. In such cases, we either isolated the domain
specific portions of the code or deleted them, even if
the interpretation or generation processes were de-
graded. It can be recovered in the future by includ-
ing the domain specific knowledge in the dynamic
configuration of the Interpretation and Generation
managers as suggested by Paulo Pardal (2007)
An example of this process is the split-
ting of the parser specific code into several
parsers: some domain-dependent, some domain-
independent, while creating a mechanism to com-
bine them in a configurable chain (through a pipes
and filters architecture). This allows the building
of smaller data-type specific parsers that the Inter-
pretation Manager selects to achieve the best pars-
ing result, according to the expectations of the sys-
tem (Martins et al., 2008). These expectations are
created according to the assumption that the user
will follow the mixed-initiative dialogue flow that
the system “suggests” during its turn in the interac-
tion. The strategy also handles those cases were the
user does not keep up with those expectations.
</bodyText>
<subsectionHeader confidence="0.998592">
3.3 Dialogue Manager Interface
</subsectionHeader>
<bodyText confidence="0.999983722222222">
The enhancements introduced at the IOManager
level augmented the amount of the information in-
terchanged between this module and the Dialogue
Manager, as it could deal with more data coming
from the ASR, TTS and the virtual agent face.
However, the Dialogue Manager Interface was
continuously evolving and changing. This lack of
stability made it harder to maintain the successive
versions completely functional during the process.
Following the software engineering practices, and
using the Template Method design pattern, we
started with the definition of modules interfaces and
only after that the implementation code of the meth-
ods was written. This allows the simultaneous de-
velopment of different modules that interact. Only
when some conflict is reported, the parallel develop-
ment processes need to be synchronized resulting in
the possible revision of the interfaces. Even when
</bodyText>
<page confidence="0.996137">
72
</page>
<bodyText confidence="0.999969647058824">
an interface was not fully supported by the Dialogue
Manager, it was useful since it lead the IOManager
continuous improvements and allowed simultaneous
developments in the Dialogue Manager.
In order to ease the creation of this interface,
an Input/Output adapter was created. This adapter
makes the conversion of the information sent by the
IOManager to the Dialogue Manager specific for-
mat. Having this, when the information exchanged
with the Dialogue Manager changes, the Dialogue
Manager Interface does not need any transforma-
tion. In addition, the Dialogue Manager is able to
interact with other Input/Output platforms without
the need of internal changes.
This solution for the interfaces follows the Facade
design pattern, which provides an unique interface
for several internal modules.
</bodyText>
<subsectionHeader confidence="0.98492">
3.4 File system reorganization
</subsectionHeader>
<bodyText confidence="0.9998864">
When the different dialogue systems were fully im-
plemented in the new version of the framework, we
wanted to keep providing simultaneous access to the
several available domains during the same execution
of the system.
In fact, in our initial framework it was already
possible to have several different domains running in
parallel. When an interaction is domain ambiguous,
the system tries to solve the ambiguity by asking the
user which domain is being referred.
</bodyText>
<figure confidence="0.8932645">
User: Ligar
System: O que deseja fazer:
ligar um electrodom´estico
ou fazer um telefonema?
</figure>
<figureCaption confidence="0.988006">
Figure 3: Example of a domain ambiguous interaction
while running with two different running domains. In
Portuguese “ligar” means “switch on” and “call”
</figureCaption>
<bodyText confidence="0.99995635">
Consider the example on Figure 3: an user inter-
action with two different running domains, the but-
ler and the personal digital assistant. In Portuguese,
the verb “ligar” means “to switch something on” or
“to make a phone call”. Since there are two running
domains, and the user utterance is domain ambigu-
ous, the systems requests for a disambiguation in its
next turn (O que deseja fazer), by asking if the user
wants to switch on a home device (ligar um elec-
trodom´estico) or make a phone call (fazer um tele-
fonema).
While using this feature, it came to our attention
that it was necessary to reorganize the file system:
the system folder held the code of all domains, and
every time we needed to change a specific domain
property, we had hundreds of properties files to look
at. This situation was even harder for novice frame-
work developers, since it was difficult to find ex-
actly which files needed to be modified in that dense
file system structure. Moreover, the ASR, TTS and
virtual agent configurations were shared by all do-
mains.
To solve this problem we applied the concept
of system–instance. A system–instance has one or
more domains. When the system starts, it receives
a parameter that specifies which instance we want
to run. The configuration of the existing instances
is split across different folders. A library folder
was created and organized in external libraries (li-
braries from an external source), internal libraries
(library developed internally at our laboratory) and
instance specific libraries (specific libraries of a
system–instance).
With this organization we improved the version-
ing management and updates. The conflicting con-
figuration was removed since each system–instance
has now its own configuration. The configuration
files are organized and whenever we need to deliver
a new version of a system–instance, we simply need
to select the files related with it.
</bodyText>
<subsectionHeader confidence="0.997281">
3.5 Service Manager redesign
</subsectionHeader>
<bodyText confidence="0.999898375">
The Service Manager code had too many dependen-
cies with different modules. The Service Manager
design was based on the Virtual Proxy design pat-
tern. However, it was not possible to develop new
devices without creating dependencies on all of the
Service Manager code, as the Device Core code re-
lied heavily on some classes of the Service Manager.
This situation created difficulties in the SDSs de-
velopment process and affected new developments
since the Service Manager code needed to be copied
whenever a Device Core was running in another
computer or in a web container. This is a known
bad practice in software engineering, since the code
is scattered, making it harder to maintain updated
code in all the relevant locations.
It was necessary to split the Service Manager code
</bodyText>
<page confidence="0.997365">
73
</page>
<bodyText confidence="0.997900125">
for the communication protocol between communi-
cation itself and the device specific code.
Also, the Service Manager class10 interface was
shared by the Dialogue Manager and all devices. Be-
ing so, it was possible that a device requested the
execution of a service in other device, as well as to
access the internal information exchanged between
the Service Manager and the Dialogue Manager.
</bodyText>
<figureCaption confidence="0.996892">
Figure 4: Service Manager architecture.
</figureCaption>
<bodyText confidence="0.999988047619048">
Like we did with the Dialogue Manager, we spec-
ified a coherent interface for the different Service
Manager modules, removing the unwanted entry
points. The Service Manager class interface was
split and the Device Manager is now the interface
between the Service Manager and the devices (Fig-
ure 4). Also, the Service Manager class interface is
only accessed by the Dialogue Manager. The classes
between the Service Manager and the Device imple-
mentation were organized in a small library, contain-
ing the classes and the Device Core code. This li-
brary is all what is needed to create a new device
and to connect it to both the Service Manager and
the Dialogue Manager.
Finally, we changed the Access Manager to con-
trol not only user access to registered devices, but
also the registry of devices in the system. This
prevents a device which is running on a specific
system–instance to be registered in some other run-
ning system–instance. This module changed its po-
sition in the framework architecture: now it is be-
</bodyText>
<footnote confidence="0.997129">
10The Service Manager Galaxy Server was renamed to Ser-
vice Manager. However, we decided to call it here by Service
Manager class so it will not be mistaken with the Service Man-
ager module.
</footnote>
<bodyText confidence="0.5641045">
tween the Service Manager class and the Device
Manager.
</bodyText>
<subsectionHeader confidence="0.998643">
3.6 Event Manager
</subsectionHeader>
<bodyText confidence="0.999798931818182">
In the initial stage, when the Galaxy HUB was
removed, all the communication was made syn-
chronous. After that, to enhance the framework and
allow mixed initiative interactions, a mechanism that
provides asynchronous communication was needed.
Also, it was necessary to propagate information be-
tween the ASR, TTS, GUI and the Dialogue System,
crucial for the error handling and recovery tasks.
We came to the conclusion that most of the frame-
works deal with these problems by using event man-
agement dedicated modules. Although TRIPS, the
framework that initially inspired ours, has an Event
Manager, that was not available in ours. The ASR
and TTS modules provided already an event-based
information propagation, and we needed to imple-
ment a dedicated module to make the access to this
sort of information simpler. This decision was en-
forced by the existence of a requirement on han-
dling events originated by an external Private Branch
eXchange (PBX) system, like incoming call and
closed call events. The PBX system was integrated
with the personal assistant that is available through
a phone connection. SDS.
We decided to create an Event Manager in the
IOManager. The Dialogue Manager implements an
event handler that receives events from the Event
Manager and knows where to deliver them. Quickly
we understood that the event handler needed to be
dependent of the system–instance since the events
and their handling are different across systems (like
a telephone system and kiosk system). With this in
mind, we implemented the event handler module,
following the Simple Factory design pattern, by del-
egating the events handling to the specific system-
instance handler. If this specific system–instance
event handler is not specified, the system will use
a default event handler with “generic” behavior.
This developments were responsible for the con-
tinuous developments in the IOManager, referred in
section 3.3, and occurred at the same time.
With this approach, we can propagate and handle
all the ASR events, the TTS events, GUI events and
external applications events.
The Event Manager has evolved to a decentral-
</bodyText>
<figure confidence="0.9996170625">
Dialogue
Manager
Interface
Dialogue
Manager
Service Access Device
Manager Manager Manager
Class
Service Manager
Example Device
Device
specific
Implementation
Device Core
Devices
Interface
</figure>
<page confidence="0.992448">
74
</page>
<bodyText confidence="0.9999774">
ized HUB. Through this, the sender can set identi-
fiers in some events. These identifiers are used by
other modules to identify messages relevant to them.
In TRIPS a similar service is provided by the Facil-
itator, that routes messages according to the recipi-
ents specified by the sender, and following the sub-
scriptions that modules can do by informing the Fa-
cilitator. This approach eases the integration of new
modules without changing the existing ones, just by
subscribing the relevant type of messages.
</bodyText>
<subsectionHeader confidence="0.987354">
3.7 Dialogue Manager distribution
</subsectionHeader>
<bodyText confidence="0.999995869565217">
Currently, there are some clients interested in our
framework to create their own SDS. However, since
the code is completely written in Java, distributions
are made available through jar files that can be eas-
ily decoded, giving access to the source of our code.
To avoid this we need to obfuscate the code.
Even though obfuscation is an interesting solu-
tion, our code used Java’s reflexion in several points.
This technique enables dynamic retrieval of classes
and data structures by name. By doing so, it needs to
know the specific name of the classes being reflected
so that the Java class loader knows where to find
them. Obfuscation, among other things, changes
class names and locations, preventing the Java class
loader from finding them.
To cope with this additional challenge, the code
that makes use of reflexion was replaced using the
Simple Factory design pattern. This change allows
the translation of the hard-coded names to the new
obfuscated names in obfuscation time. After that,
when some class needs to instantiate one of those
classes that used reflection, that instance can be cre-
ated through the proper factory.
</bodyText>
<sectionHeader confidence="0.999462" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999954615384615">
Although a SDS was successfully deployed in our
initial framework, which is publicly available at a
Museum since 2003, no formal evaluation was made
at that initial time. Due to this, effective or numeric
comparison between the framework as it was before
the reengineering work and as it is now, is not possi-
ble. Previous performance parameters are not avail-
able. However, some empirical evaluation is pos-
sible, based on generic principles of Software (re)
Engineering.
In the baseline framework, each improvement,
like modifications in the dialogue flow or at the
parser level, was a process that took more than two
weeks of work, of two software engineers. With the
new version, similar changes are done in less than
one week, by the same team. This includes internal
improvements, and external developments made by
entities using the system. The system is more stable
and reliable now: in the beginning, the system had
an incorrect behavior after some hours of running
time; currently with a similar load, it runs for more
than one month without needing to be restarted.
This is one great step for the adoption of our
framework. This stability, reliability and develop-
ment speed convinced our partners to create their
Spoken Dialogue Systems with our framework.
</bodyText>
<sectionHeader confidence="0.998743" genericHeader="conclusions">
5 Conclusions and Future Work
</sectionHeader>
<bodyText confidence="0.997298103448276">
Currently, our efforts are concentrated on interpreta-
tion improvement and on error handling and recov-
ery (Harris et al., 2004).
Currently, we are working on representing emo-
tions within the SDS framework. We want to test
the integration, and how people will react to a sys-
tem with desires and moods.
The next big step will be the inclusion of an ef-
ficient morpho-syntactic parser which generates and
provides more information (based on speech acts) to
the Interpretation Manager.
Another step we have in mind is to investigate
how the events and probabilistic information that the
ASR module injects in the system can be used to re-
cover recognition errors.
The integration of a Question-Answering (QA)
system (Mendes et al., 2007) in this framework is
also in our horizon. This might require architectural
changes in order to bring together the interpretation
and disambiguation features from the SDS with the
Information Retrieval (IR) features of QA systems.
This would provide information-providing systems
through voice interaction (Mendes, 2008).
Another ongoing work is the study of whether
ontologies can enrich a SDS. Namely, if they can
be used to abstract knowledge sources allowing the
system to focus only on dialogue phenomena rather
than architecture adaptation, when including new
domains (Paulo Pardal, 2007).
</bodyText>
<page confidence="0.998402">
75
</page>
<sectionHeader confidence="0.998818" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.993535428571429">
This work was partially funded by TECNOVOZ,
PRIME National Project number 03/165.
It was also partially funded by DIGA, project
POST/PLP/14319/2001 of Fundac¸˜ao para a
Ciˆencia e Tecnologia (FCT).
Joana Paulo Pardal is supported by a PhD fellow-
ship from FCT (SFRH/BD/30791/2006).
</bodyText>
<sectionHeader confidence="0.998683" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999297875">
James Allen, Donna Byron, Myroslava Dzikovska,
George Ferguson, Lucian Galescu, and Amanda Stent.
2000. An architecture for a generic dialogue shell.
Natural Language Engineering, Cambridge Univer-
sity Press, 6.
James Allen, Nathanael Chambers, George Ferguson,
Lucian Galescu, Hyuckchul Jung, Mary Swift, and
William Taysom. 2007. Plow: A collaborative task
learning agent. In Proc. 221h AAAI Conf. AAAI Press.
Dan Bohus, Antoine Raux, Thomas Harris, Maxine Es-
kenazi, and Alexander Rudnicky. 2007. Olympus:
an open-source framework for conversational spoken
language interface research. In Workshop on Bridging
the Gap: Academic and Industrial Research in Dialog
Technology, HLT-NAACL.
Dan Bohus. 2004. Building spoken dialog systems with
the RavenClaw/Communicator architecture. Presenta-
tion at Sphinx Lunch Talk, CMU, Fall.
Renato Cassaca and Rui Maia. 2002. Assistente electr´o-
nica. Instituto Superior T´ecnico (IST), Universidade
T´ecnica de Lisboa (UTL), Graduation Thesis.
George Ferguson, James Allen, Brad Miller, and Eric
Ringger. 1996. The design and implementation of
the TRAINS-96 system: A prototype mixed-initiative
planning assistant. Technical Report TN96-5.
Elisabeth Freeman, Eric Freeman, Bert Bates, and Kathy
Sierra. 2004. Head First Design Patterns. O’Reilly.
Erich Gamma, Richard Helm, Ralph Johnson, and John
Vlissides. 1994. Design Patterns: Elements of
Reusable Object-Oriented Software. Addison-Wesley
Professional Computing Series.
Thomas Harris, Satanjeev Banerjee, Alexander Rud-
nicky, June Sison, Kerry Bodine, and Alan Black.
2004. A research platform for multi-agent dialogue
dynamics. In 13th IEEE Intl. Workshop on Robot and
Human Interactive Communication (ROMAN).
Hyuckchul Jung, James Allen, Nathanael Chambers, Lu-
cian Galescu, Mary Swift, and William Taysom. 2007.
Utilizing natural language for one-shot task learning.
Journal of Logic and Computation.
Yannis Labrou and Tim Finin. 1997. A proposal for a
new KQML specification. Technical Report CS-97-
03, Computer Science and Electrical Engineering De-
partment, Univ. of Maryland Baltimore County.
Filipe M. Martins, Ana Mendes, Joana Paulo Pardal,
Nuno J. Mamede, and Jo˜ao Paulo Neto. 2008. Us-
ing system expectations to manage user interactions.
In Proc. PROPOR 2008 (to appear), LNCS. Springer.
Hugo Meinedo. 2008. Audio Pre-processing and Speech
Recognition for Broadcast News. Ph.D. thesis, IST,
UTL.
Ana Mendes, Lu´ısa Coheur, Nuno J. Mamede, Lu´ıs
Rom˜ao, Jo˜ao Loureiro, Ricardo Daniel Ribeiro, Fer-
nando Batista, and David Martins de Matos. 2007.
QA@L2F@QA@CLEF. In Cross Language Evalua-
tion Forum: Working Notes - CLEF 2007 Workshop.
Ana Mendes. 2008. Introducing dialogue in a QA sys-
tem. In Doctoral Symposium of 131h Intl. Conf. Apps.
Nat. Lang. to Information Systems, NLDB (to appear).
M´arcio Mour˜ao, Pedro Madeira, and Miguel Rodrigues.
2002. Dialog manager. IST, UTL, Graduation Thesis.
M´arcio Mour˜ao, Renato Cassaca, and Nuno J. Mamede.
2004. An independent domain dialogue system
through a service manager. In EsTAL, volume 3230
of LNCS. Springer.
M´arcio Mour˜ao. 2005. Gest˜ao e representac¸˜ao de do-
m´ınios em sistemas de di´alogo. Master’s thesis, IST,
UTL.
Jo˜ao Paulo Neto, Renato Cassaca, M´arcio Viveiros, and
M´arcio Mour˜ao. 2006. Design of a Multimodal Input
Interface for a Dialogue System. In Proc. PROPOR
2006, volume 3960 of LNCS. Springer.
Eric Nyberg, Teruko Mitamura, and Nobuo Hataoka.
2002. DialogXML: extending Voice XML for dy-
namic dialog management. In Proc. 21h Int. Conf.
on Human Language Technology Research. Morgan
Kaufmann Publishers Inc.
S´ergio Paulo, Lu´ıs C. Oliveira, Carlos Mendes, Lu´ıs
Figueira, Renato Cassaca, C´eu Viana, and Helena Mo-
niz. 2008. DIXI - A Generic Text-to-Speech System
for European Portuguese. In Proc. PROPOR 2008 (to
appear), LNCS. Springer.
Joana Paulo Pardal. 2007. Dynamic use of ontologies in
dialogue systems. In NAACL-HLT Doctoral Consor-
tium.
Joseph Polifroni and Stephanie Seneff. 2000. GALAXY-
II as an architecture for spoken dialogue evaluation. In
Proc. 2,d Int. Conf. Language Resources and Evalua-
tion (LREC).
Antoine Raux, Brian Langner, Dan Bohus, Alan Black,
and Maxine Eskenazi. 2005. Let’s go public! tak-
ing a spoken dialog system to the real world. In Proc.
INTERSPEECH.
M´arcio Viveiros. 2004. Cara falante – uma interface vi-
sual para um sistema de di´alogo falado. IST, UTL,
Graduation Thesis.
</reference>
<page confidence="0.991593">
76
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.147278">
<title confidence="0.999409">Reengineering a domain-independent for Spoken Dialogue Systems</title>
<author confidence="0.988673">Filipe M Martins</author>
<author confidence="0.988673">Ana Mendes</author>
<author confidence="0.988673">M´arcio Viveiros</author>
<author confidence="0.988673">Joana Paulo</author>
<affiliation confidence="0.748866333333333">Arez, Nuno J. Mamede and Paulo Language Systems Laboratory, – Department of Computer Science and</affiliation>
<note confidence="0.629996">Instituto Superior T´ecnico, Technical University of Alves Redol, 9 - – 1000-029 Lisboa,</note>
<web confidence="0.688019">http://www.l2f.inesc-id.pt</web>
<abstract confidence="0.9930512">Our work in this area started as a reproject but when joined TecnoVoz, a Portuguese national consortium including Academia and Industry partners, our focus shifted to real-time professional solutions. The integration of our domain-independent Spoken Dialogue System (SDS) framework into commercial products led to a major reengineering process. This paper describes the changes that the framework went through and that deeply affected its entire architecture. The communication core was enhanced, the modules interfaces were redefined for an easier integration, the SDS deployment process was optimized and the framework robustness was improved. The work was done according to software engineering guidelines and making use of design patterns.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>Donna Byron</author>
<author>Myroslava Dzikovska</author>
<author>George Ferguson</author>
<author>Lucian Galescu</author>
<author>Amanda Stent</author>
</authors>
<title>An architecture for a generic dialogue shell. Natural Language Engineering,</title>
<date>2000</date>
<pages>6</pages>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="1575" citStr="Allen et al., 2000" startWordPosition="223" endWordPosition="226">tecture. The communication core was enhanced, the modules interfaces were redefined for an easier integration, the SDS deployment process was optimized and the framework robustness was improved. The work was done according to software engineering guidelines and making use of design patterns. 1 Introduction Our SDS framework was created back in 2000 (Mour˜ao et al., 2004), as the result of three graduation theses (Cassaca and Maia, 2002; Mour˜ao et al., 2002; Viveiros, 2004), one of which evolved into a masters thesis (Mour˜ao, 2005). The framework is highly inspired on the TRIPS architecture (Allen et al., 2000): it is a frame-based domain-independent framework that can be used to build domain-specific dialogue systems. Every domain is described by a frame, composed by domain slots that are filled with user requests. When a set of domain slots is filled, a service is executed. In order to do so, the dialogue system interacts with the user until enough information is provided. From the initial version of the framework two systems were created for two different domains: a bus ticket vending system, which provides an interface to access bus timetables; and a digital virtual butler named Ambr´osio that c</context>
</contexts>
<marker>Allen, Byron, Dzikovska, Ferguson, Galescu, Stent, 2000</marker>
<rawString>James Allen, Donna Byron, Myroslava Dzikovska, George Ferguson, Lucian Galescu, and Amanda Stent. 2000. An architecture for a generic dialogue shell. Natural Language Engineering, Cambridge University Press, 6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Allen</author>
<author>Nathanael Chambers</author>
<author>George Ferguson</author>
<author>Lucian Galescu</author>
<author>Hyuckchul Jung</author>
<author>Mary Swift</author>
<author>William Taysom</author>
</authors>
<title>Plow: A collaborative task learning agent.</title>
<date>2007</date>
<booktitle>In Proc. 221h AAAI Conf.</booktitle>
<publisher>AAAI Press.</publisher>
<contexts>
<context position="4874" citStr="Allen et al., 2007" startWordPosition="752" endWordPosition="755">r instance) and a virtual agent face provided feedback, in the new scenarios communication is established only through a phone and, being so, voice is the only feedback. The new paradigm was the trigger to this process and whenever a new issue needed to be solved the best practices in similar successful systems were studied. Not all can be mentioned. The most relevant are described in what follows. As it was previously mentioned, TRIPS was the main inspiration for this framework. It is a well known and stable architecture that has proven its merits in accommodating a range of different tasks (Allen et al., 2007; Jung et al., 2007). The main modules of the system interact through a Facilitator (Ferguson et al., 1996), similar to the Galaxy HUB7 (Polifroni and Seneff, 2000) with KQML (Labrou and Finin, 1997) messages. However, in TRIPS, the routing task is decentralized since the sender modules decide where to send its messages. At the same time, any module can subscribe to selected messages through the Facilitator according to the sender, the type of message or its contents. This mechanism makes it easier to integrate new modules that subscribe the relevant messages without the senders’ acknowledgmen</context>
</contexts>
<marker>Allen, Chambers, Ferguson, Galescu, Jung, Swift, Taysom, 2007</marker>
<rawString>James Allen, Nathanael Chambers, George Ferguson, Lucian Galescu, Hyuckchul Jung, Mary Swift, and William Taysom. 2007. Plow: A collaborative task learning agent. In Proc. 221h AAAI Conf. AAAI Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Bohus</author>
<author>Antoine Raux</author>
<author>Thomas Harris</author>
<author>Maxine Eskenazi</author>
<author>Alexander Rudnicky</author>
</authors>
<title>Olympus: an open-source framework for conversational spoken language interface research.</title>
<date>2007</date>
<booktitle>In Workshop on Bridging the Gap: Academic and Industrial Research in Dialog Technology, HLT-NAACL.</booktitle>
<marker>Bohus, Raux, Harris, Eskenazi, Rudnicky, 2007</marker>
<rawString>Dan Bohus, Antoine Raux, Thomas Harris, Maxine Eskenazi, and Alexander Rudnicky. 2007. Olympus: an open-source framework for conversational spoken language interface research. In Workshop on Bridging the Gap: Academic and Industrial Research in Dialog Technology, HLT-NAACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Bohus</author>
</authors>
<title>Building spoken dialog systems with the RavenClaw/Communicator architecture. Presentation at Sphinx Lunch Talk,</title>
<date>2004</date>
<location>CMU, Fall.</location>
<contexts>
<context position="6187" citStr="Bohus, 2004" startWordPosition="949" endWordPosition="950">http://www.nuance.com/ 5http://www.loquendo.com/ 6http://www.artificial-solutions.com/ 7The Galaxy Hub maintains connections to modules (parser, speech recognizer, back-end, etc.), and routes messages among them. Seehttp://communicator.sourceforge.net/ al., 2007) where the modules are connected via a Galaxy HUB that uses a central hub and a set of rules for relaying messages from one component to the other. It has the three usual main blocks: Language Understanding, through Phoenix parser and Helios confidence-based annotation module, Dialogue Management, through RavenClaw (Raux et al., 2005; Bohus, 2004), and Language Generation, through Rosetta. Recognition is made with Sphinx and synthesis with Theta. The back-end applications are directly connected to the HUB through an included stub. Some of our recent developments are also inspired in Voice XML8, in an effort to simplify the framework parameterization and development, required in the enterprise context. Voice XML provides standard means of declarative configuration of new systems reducing the need of coding to the related devices implementation (Nyberg et al., 2002). Our reengineering work aimed at: i) making the framework more robust an</context>
</contexts>
<marker>Bohus, 2004</marker>
<rawString>Dan Bohus. 2004. Building spoken dialog systems with the RavenClaw/Communicator architecture. Presentation at Sphinx Lunch Talk, CMU, Fall.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Renato Cassaca</author>
<author>Rui Maia</author>
</authors>
<title>Assistente electr´onica. Instituto Superior T´ecnico (IST), Universidade T´ecnica de Lisboa (UTL), Graduation Thesis.</title>
<date>2002</date>
<contexts>
<context position="1395" citStr="Cassaca and Maia, 2002" startWordPosition="194" endWordPosition="197">DS) framework into commercial products led to a major reengineering process. This paper describes the changes that the framework went through and that deeply affected its entire architecture. The communication core was enhanced, the modules interfaces were redefined for an easier integration, the SDS deployment process was optimized and the framework robustness was improved. The work was done according to software engineering guidelines and making use of design patterns. 1 Introduction Our SDS framework was created back in 2000 (Mour˜ao et al., 2004), as the result of three graduation theses (Cassaca and Maia, 2002; Mour˜ao et al., 2002; Viveiros, 2004), one of which evolved into a masters thesis (Mour˜ao, 2005). The framework is highly inspired on the TRIPS architecture (Allen et al., 2000): it is a frame-based domain-independent framework that can be used to build domain-specific dialogue systems. Every domain is described by a frame, composed by domain slots that are filled with user requests. When a set of domain slots is filled, a service is executed. In order to do so, the dialogue system interacts with the user until enough information is provided. From the initial version of the framework two sy</context>
<context position="9147" citStr="Cassaca and Maia, 2002" startWordPosition="1410" endWordPosition="1413">ork architecture Our initial framework came into existence as the result of the integration of three main modules: Input/Output Manager, that controls an Automatic Speech Recognition (ASR) module (Meinedo, 2008), a Text-To-Speech (TTS) module (Paulo et al., 2008) and provides a virtual agent face (Viveiros, 2004); Dialogue Manager, that interprets the user intentions and generates output messages (Mour˜ao et al., 2002; Mour˜ao, 2005); Service Manager, that provides a dialogue manager interface to execute the requested services, and an external application interface through the device concept (Cassaca and Maia, 2002). 2.3 Input/Output Manager The Input/Output Manager (IOManager) controls an ASR module and a TTS module. It also integrates a virtual agent face, providing a more realistic interaction with the user. The synchronization between the TTS output and the animated face is done by an audio–face synchronization manager, which generates the visemes9 for the corresponding TTS phonemes information. The provided virtual agent face is based on a state machine that informs, among others, when the system is “thinking” or when what the user said was not understood. Besides, a Graphical User Interface (GUI) e</context>
</contexts>
<marker>Cassaca, Maia, 2002</marker>
<rawString>Renato Cassaca and Rui Maia. 2002. Assistente electr´onica. Instituto Superior T´ecnico (IST), Universidade T´ecnica de Lisboa (UTL), Graduation Thesis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Ferguson</author>
<author>James Allen</author>
<author>Brad Miller</author>
<author>Eric Ringger</author>
</authors>
<title>The design and implementation of the TRAINS-96 system: A prototype mixed-initiative planning assistant.</title>
<date>1996</date>
<tech>Technical Report TN96-5.</tech>
<contexts>
<context position="4981" citStr="Ferguson et al., 1996" startWordPosition="770" endWordPosition="773">ed only through a phone and, being so, voice is the only feedback. The new paradigm was the trigger to this process and whenever a new issue needed to be solved the best practices in similar successful systems were studied. Not all can be mentioned. The most relevant are described in what follows. As it was previously mentioned, TRIPS was the main inspiration for this framework. It is a well known and stable architecture that has proven its merits in accommodating a range of different tasks (Allen et al., 2007; Jung et al., 2007). The main modules of the system interact through a Facilitator (Ferguson et al., 1996), similar to the Galaxy HUB7 (Polifroni and Seneff, 2000) with KQML (Labrou and Finin, 1997) messages. However, in TRIPS, the routing task is decentralized since the sender modules decide where to send its messages. At the same time, any module can subscribe to selected messages through the Facilitator according to the sender, the type of message or its contents. This mechanism makes it easier to integrate new modules that subscribe the relevant messages without the senders’ acknowledgment. Like our framework, the CMU Olympus is a classical pipeline dialog system architecture (Bohus et 4http:/</context>
</contexts>
<marker>Ferguson, Allen, Miller, Ringger, 1996</marker>
<rawString>George Ferguson, James Allen, Brad Miller, and Eric Ringger. 1996. The design and implementation of the TRAINS-96 system: A prototype mixed-initiative planning assistant. Technical Report TN96-5.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Elisabeth Freeman</author>
<author>Eric Freeman</author>
<author>Bert Bates</author>
<author>Kathy Sierra</author>
</authors>
<date>2004</date>
<note>Head First Design Patterns. O’Reilly.</note>
<contexts>
<context position="7058" citStr="Freeman et al., 2004" startWordPosition="1081" endWordPosition="1084">8, in an effort to simplify the framework parameterization and development, required in the enterprise context. Voice XML provides standard means of declarative configuration of new systems reducing the need of coding to the related devices implementation (Nyberg et al., 2002). Our reengineering work aimed at: i) making the framework more robust and flexible, enhancing the creation of new systems for different domains; ii) simplifying the system’s development, debug and deployment processes through common techniques from software engineering areas, such as design patterns (Gamma et al., 1994; Freeman et al., 2004). By doing this, we are trying to promote the development and deployment of new dialogue systems with our framework. This paper is organized as follows: Section 2 presents the initial version of the framework; Section 3 describes its problems and limitations, as well as the techniques we adopted to solve them; Section 4 describes a brief empirical evaluation of the reengineering work; finally, Section 5 closes the paper with conclusions and some remarks about future work directions. 2 Framework description This section briefly presents our architecture, at its initial stage, before the reengin</context>
</contexts>
<marker>Freeman, Freeman, Bates, Sierra, 2004</marker>
<rawString>Elisabeth Freeman, Eric Freeman, Bert Bates, and Kathy Sierra. 2004. Head First Design Patterns. O’Reilly.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Erich Gamma</author>
<author>Richard Helm</author>
<author>Ralph Johnson</author>
<author>John Vlissides</author>
</authors>
<title>Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley Professional Computing Series.</title>
<date>1994</date>
<contexts>
<context position="7035" citStr="Gamma et al., 1994" startWordPosition="1077" endWordPosition="1080">nspired in Voice XML8, in an effort to simplify the framework parameterization and development, required in the enterprise context. Voice XML provides standard means of declarative configuration of new systems reducing the need of coding to the related devices implementation (Nyberg et al., 2002). Our reengineering work aimed at: i) making the framework more robust and flexible, enhancing the creation of new systems for different domains; ii) simplifying the system’s development, debug and deployment processes through common techniques from software engineering areas, such as design patterns (Gamma et al., 1994; Freeman et al., 2004). By doing this, we are trying to promote the development and deployment of new dialogue systems with our framework. This paper is organized as follows: Section 2 presents the initial version of the framework; Section 3 describes its problems and limitations, as well as the techniques we adopted to solve them; Section 4 describes a brief empirical evaluation of the reengineering work; finally, Section 5 closes the paper with conclusions and some remarks about future work directions. 2 Framework description This section briefly presents our architecture, at its initial st</context>
</contexts>
<marker>Gamma, Helm, Johnson, Vlissides, 1994</marker>
<rawString>Erich Gamma, Richard Helm, Ralph Johnson, and John Vlissides. 1994. Design Patterns: Elements of Reusable Object-Oriented Software. Addison-Wesley Professional Computing Series.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Harris</author>
<author>Satanjeev Banerjee</author>
<author>Alexander Rudnicky</author>
<author>June Sison</author>
<author>Kerry Bodine</author>
<author>Alan Black</author>
</authors>
<title>A research platform for multi-agent dialogue dynamics.</title>
<date>2004</date>
<booktitle>In 13th IEEE Intl. Workshop on Robot and Human Interactive Communication</booktitle>
<location>(ROMAN).</location>
<contexts>
<context position="30098" citStr="Harris et al., 2004" startWordPosition="4789" endWordPosition="4792">lopments made by entities using the system. The system is more stable and reliable now: in the beginning, the system had an incorrect behavior after some hours of running time; currently with a similar load, it runs for more than one month without needing to be restarted. This is one great step for the adoption of our framework. This stability, reliability and development speed convinced our partners to create their Spoken Dialogue Systems with our framework. 5 Conclusions and Future Work Currently, our efforts are concentrated on interpretation improvement and on error handling and recovery (Harris et al., 2004). Currently, we are working on representing emotions within the SDS framework. We want to test the integration, and how people will react to a system with desires and moods. The next big step will be the inclusion of an efficient morpho-syntactic parser which generates and provides more information (based on speech acts) to the Interpretation Manager. Another step we have in mind is to investigate how the events and probabilistic information that the ASR module injects in the system can be used to recover recognition errors. The integration of a Question-Answering (QA) system (Mendes et al., 2</context>
</contexts>
<marker>Harris, Banerjee, Rudnicky, Sison, Bodine, Black, 2004</marker>
<rawString>Thomas Harris, Satanjeev Banerjee, Alexander Rudnicky, June Sison, Kerry Bodine, and Alan Black. 2004. A research platform for multi-agent dialogue dynamics. In 13th IEEE Intl. Workshop on Robot and Human Interactive Communication (ROMAN).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hyuckchul Jung</author>
<author>James Allen</author>
<author>Nathanael Chambers</author>
<author>Lucian Galescu</author>
<author>Mary Swift</author>
<author>William Taysom</author>
</authors>
<title>Utilizing natural language for one-shot task learning.</title>
<date>2007</date>
<journal>Journal of Logic and Computation.</journal>
<contexts>
<context position="4894" citStr="Jung et al., 2007" startWordPosition="756" endWordPosition="759">rtual agent face provided feedback, in the new scenarios communication is established only through a phone and, being so, voice is the only feedback. The new paradigm was the trigger to this process and whenever a new issue needed to be solved the best practices in similar successful systems were studied. Not all can be mentioned. The most relevant are described in what follows. As it was previously mentioned, TRIPS was the main inspiration for this framework. It is a well known and stable architecture that has proven its merits in accommodating a range of different tasks (Allen et al., 2007; Jung et al., 2007). The main modules of the system interact through a Facilitator (Ferguson et al., 1996), similar to the Galaxy HUB7 (Polifroni and Seneff, 2000) with KQML (Labrou and Finin, 1997) messages. However, in TRIPS, the routing task is decentralized since the sender modules decide where to send its messages. At the same time, any module can subscribe to selected messages through the Facilitator according to the sender, the type of message or its contents. This mechanism makes it easier to integrate new modules that subscribe the relevant messages without the senders’ acknowledgment. Like our framewor</context>
</contexts>
<marker>Jung, Allen, Chambers, Galescu, Swift, Taysom, 2007</marker>
<rawString>Hyuckchul Jung, James Allen, Nathanael Chambers, Lucian Galescu, Mary Swift, and William Taysom. 2007. Utilizing natural language for one-shot task learning. Journal of Logic and Computation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yannis Labrou</author>
<author>Tim Finin</author>
</authors>
<title>A proposal for a new KQML specification.</title>
<date>1997</date>
<tech>Technical Report CS-97-03,</tech>
<institution>Computer Science and Electrical Engineering Department, Univ. of Maryland Baltimore County.</institution>
<contexts>
<context position="5073" citStr="Labrou and Finin, 1997" startWordPosition="785" endWordPosition="788"> trigger to this process and whenever a new issue needed to be solved the best practices in similar successful systems were studied. Not all can be mentioned. The most relevant are described in what follows. As it was previously mentioned, TRIPS was the main inspiration for this framework. It is a well known and stable architecture that has proven its merits in accommodating a range of different tasks (Allen et al., 2007; Jung et al., 2007). The main modules of the system interact through a Facilitator (Ferguson et al., 1996), similar to the Galaxy HUB7 (Polifroni and Seneff, 2000) with KQML (Labrou and Finin, 1997) messages. However, in TRIPS, the routing task is decentralized since the sender modules decide where to send its messages. At the same time, any module can subscribe to selected messages through the Facilitator according to the sender, the type of message or its contents. This mechanism makes it easier to integrate new modules that subscribe the relevant messages without the senders’ acknowledgment. Like our framework, the CMU Olympus is a classical pipeline dialog system architecture (Bohus et 4http://www.nuance.com/ 5http://www.loquendo.com/ 6http://www.artificial-solutions.com/ 7The Galaxy</context>
</contexts>
<marker>Labrou, Finin, 1997</marker>
<rawString>Yannis Labrou and Tim Finin. 1997. A proposal for a new KQML specification. Technical Report CS-97-03, Computer Science and Electrical Engineering Department, Univ. of Maryland Baltimore County.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Filipe M Martins</author>
</authors>
<location>Ana Mendes, Joana Paulo Pardal,</location>
<marker>Martins, </marker>
<rawString>Filipe M. Martins, Ana Mendes, Joana Paulo Pardal,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuno J Mamede</author>
<author>Jo˜ao Paulo Neto</author>
</authors>
<title>Using system expectations to manage user interactions.</title>
<date>2008</date>
<marker>Mamede, Neto, 2008</marker>
<rawString>Nuno J. Mamede, and Jo˜ao Paulo Neto. 2008. Using system expectations to manage user interactions.</rawString>
</citation>
<citation valid="true">
<title>Audio Pre-processing and Speech Recognition for Broadcast News.</title>
<date>2008</date>
<booktitle>In Proc. PROPOR</booktitle>
<tech>Ph.D. thesis, IST, UTL.</tech>
<publisher>LNCS. Springer.</publisher>
<location>Hugo Meinedo.</location>
<note>(to appear),</note>
<marker>2008</marker>
<rawString>In Proc. PROPOR 2008 (to appear), LNCS. Springer. Hugo Meinedo. 2008. Audio Pre-processing and Speech Recognition for Broadcast News. Ph.D. thesis, IST, UTL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana Mendes</author>
<author>Lu´ısa Coheur</author>
<author>Nuno J Mamede</author>
<author>Lu´ıs Rom˜ao</author>
<author>Jo˜ao Loureiro</author>
<author>Ricardo Daniel Ribeiro</author>
<author>Fernando Batista</author>
<author>David Martins de Matos</author>
</authors>
<title>QA@L2F@QA@CLEF. In Cross Language Evaluation Forum: Working Notes - CLEF</title>
<date>2007</date>
<note>Workshop.</note>
<marker>Mendes, Coheur, Mamede, Rom˜ao, Loureiro, Ribeiro, Batista, de Matos, 2007</marker>
<rawString>Ana Mendes, Lu´ısa Coheur, Nuno J. Mamede, Lu´ıs Rom˜ao, Jo˜ao Loureiro, Ricardo Daniel Ribeiro, Fernando Batista, and David Martins de Matos. 2007. QA@L2F@QA@CLEF. In Cross Language Evaluation Forum: Working Notes - CLEF 2007 Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ana Mendes</author>
</authors>
<title>Introducing dialogue in a QA system.</title>
<date>2008</date>
<booktitle>In Doctoral Symposium of 131h Intl. Conf. Apps.</booktitle>
<marker>Mendes, 2008</marker>
<rawString>Ana Mendes. 2008. Introducing dialogue in a QA system. In Doctoral Symposium of 131h Intl. Conf. Apps.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lang</author>
</authors>
<title>to Information Systems, NLDB (to appear). M´arcio Mour˜ao, Pedro Madeira, and Miguel Rodrigues.</title>
<date>2002</date>
<marker>Lang, 2002</marker>
<rawString>Nat. Lang. to Information Systems, NLDB (to appear). M´arcio Mour˜ao, Pedro Madeira, and Miguel Rodrigues. 2002. Dialog manager. IST, UTL, Graduation Thesis. M´arcio Mour˜ao, Renato Cassaca, and Nuno J. Mamede.</rawString>
</citation>
<citation valid="true">
<title>An independent domain dialogue system through a service manager.</title>
<date>2004</date>
<booktitle>In EsTAL,</booktitle>
<volume>3230</volume>
<publisher>Springer.</publisher>
<marker>2004</marker>
<rawString>2004. An independent domain dialogue system through a service manager. In EsTAL, volume 3230 of LNCS. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M´arcio Mour˜ao</author>
</authors>
<title>Gest˜ao e representac¸˜ao de dom´ınios em sistemas de di´alogo.</title>
<date>2005</date>
<booktitle>Master’s thesis, IST, UTL.</booktitle>
<marker>Mour˜ao, 2005</marker>
<rawString>M´arcio Mour˜ao. 2005. Gest˜ao e representac¸˜ao de dom´ınios em sistemas de di´alogo. Master’s thesis, IST, UTL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jo˜ao Paulo Neto</author>
<author>Renato Cassaca</author>
<author>M´arcio Viveiros</author>
<author>M´arcio Mour˜ao</author>
</authors>
<title>Design of a Multimodal Input Interface for a Dialogue System. In</title>
<date>2006</date>
<booktitle>Proc. PROPOR</booktitle>
<volume>3960</volume>
<publisher>Springer.</publisher>
<marker>Neto, Cassaca, Viveiros, Mour˜ao, 2006</marker>
<rawString>Jo˜ao Paulo Neto, Renato Cassaca, M´arcio Viveiros, and M´arcio Mour˜ao. 2006. Design of a Multimodal Input Interface for a Dialogue System. In Proc. PROPOR 2006, volume 3960 of LNCS. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Nyberg</author>
<author>Teruko Mitamura</author>
<author>Nobuo Hataoka</author>
</authors>
<title>DialogXML: extending Voice XML for dynamic dialog management.</title>
<date>2002</date>
<booktitle>In Proc. 21h Int. Conf. on Human Language Technology Research.</booktitle>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<contexts>
<context position="6714" citStr="Nyberg et al., 2002" startWordPosition="1030" endWordPosition="1033">ed annotation module, Dialogue Management, through RavenClaw (Raux et al., 2005; Bohus, 2004), and Language Generation, through Rosetta. Recognition is made with Sphinx and synthesis with Theta. The back-end applications are directly connected to the HUB through an included stub. Some of our recent developments are also inspired in Voice XML8, in an effort to simplify the framework parameterization and development, required in the enterprise context. Voice XML provides standard means of declarative configuration of new systems reducing the need of coding to the related devices implementation (Nyberg et al., 2002). Our reengineering work aimed at: i) making the framework more robust and flexible, enhancing the creation of new systems for different domains; ii) simplifying the system’s development, debug and deployment processes through common techniques from software engineering areas, such as design patterns (Gamma et al., 1994; Freeman et al., 2004). By doing this, we are trying to promote the development and deployment of new dialogue systems with our framework. This paper is organized as follows: Section 2 presents the initial version of the framework; Section 3 describes its problems and limitatio</context>
</contexts>
<marker>Nyberg, Mitamura, Hataoka, 2002</marker>
<rawString>Eric Nyberg, Teruko Mitamura, and Nobuo Hataoka. 2002. DialogXML: extending Voice XML for dynamic dialog management. In Proc. 21h Int. Conf. on Human Language Technology Research. Morgan Kaufmann Publishers Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S´ergio Paulo</author>
<author>Lu´ıs C Oliveira</author>
<author>Carlos Mendes</author>
<author>Lu´ıs Figueira</author>
<author>Renato Cassaca</author>
<author>C´eu Viana</author>
<author>Helena Moniz</author>
</authors>
<title>DIXI - A Generic Text-to-Speech System for European Portuguese. In</title>
<date>2008</date>
<booktitle>Proc. PROPOR</booktitle>
<publisher>LNCS. Springer.</publisher>
<note>(to appear),</note>
<contexts>
<context position="8787" citStr="Paulo et al., 2008" startWordPosition="1357" endWordPosition="1360">ne active state exists, at each time, for each device; State, which includes a subset of services that are active when the state is active; Service, which instantiates a defined frame and specifies a set of slots type of data and restrictions for that service. When developing a new domain all these entities have to be defined and instantiated. 2.2 Framework architecture Our initial framework came into existence as the result of the integration of three main modules: Input/Output Manager, that controls an Automatic Speech Recognition (ASR) module (Meinedo, 2008), a Text-To-Speech (TTS) module (Paulo et al., 2008) and provides a virtual agent face (Viveiros, 2004); Dialogue Manager, that interprets the user intentions and generates output messages (Mour˜ao et al., 2002; Mour˜ao, 2005); Service Manager, that provides a dialogue manager interface to execute the requested services, and an external application interface through the device concept (Cassaca and Maia, 2002). 2.3 Input/Output Manager The Input/Output Manager (IOManager) controls an ASR module and a TTS module. It also integrates a virtual agent face, providing a more realistic interaction with the user. The synchronization between the TTS outp</context>
</contexts>
<marker>Paulo, Oliveira, Mendes, Figueira, Cassaca, Viana, Moniz, 2008</marker>
<rawString>S´ergio Paulo, Lu´ıs C. Oliveira, Carlos Mendes, Lu´ıs Figueira, Renato Cassaca, C´eu Viana, and Helena Moniz. 2008. DIXI - A Generic Text-to-Speech System for European Portuguese. In Proc. PROPOR 2008 (to appear), LNCS. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joana Paulo Pardal</author>
</authors>
<title>Dynamic use of ontologies in dialogue systems.</title>
<date>2007</date>
<booktitle>In NAACL-HLT Doctoral Consortium.</booktitle>
<contexts>
<context position="17080" citStr="Pardal (2007)" startWordPosition="2689" endWordPosition="2690">s took place while the Galaxy HUB was being replaced. We were unable to redesign the domain dependent code. Cases like hard-coded word replacement, used both to provide a richer interpretation of the user utterances and to allow giving a natural response to the user. In such cases, we either isolated the domain specific portions of the code or deleted them, even if the interpretation or generation processes were degraded. It can be recovered in the future by including the domain specific knowledge in the dynamic configuration of the Interpretation and Generation managers as suggested by Paulo Pardal (2007) An example of this process is the splitting of the parser specific code into several parsers: some domain-dependent, some domainindependent, while creating a mechanism to combine them in a configurable chain (through a pipes and filters architecture). This allows the building of smaller data-type specific parsers that the Interpretation Manager selects to achieve the best parsing result, according to the expectations of the system (Martins et al., 2008). These expectations are created according to the assumption that the user will follow the mixed-initiative dialogue flow that the system “sug</context>
</contexts>
<marker>Pardal, 2007</marker>
<rawString>Joana Paulo Pardal. 2007. Dynamic use of ontologies in dialogue systems. In NAACL-HLT Doctoral Consortium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joseph Polifroni</author>
<author>Stephanie Seneff</author>
</authors>
<title>GALAXYII as an architecture for spoken dialogue evaluation.</title>
<date>2000</date>
<booktitle>In Proc. 2,d Int. Conf. Language Resources and Evaluation (LREC).</booktitle>
<contexts>
<context position="5038" citStr="Polifroni and Seneff, 2000" startWordPosition="779" endWordPosition="782">only feedback. The new paradigm was the trigger to this process and whenever a new issue needed to be solved the best practices in similar successful systems were studied. Not all can be mentioned. The most relevant are described in what follows. As it was previously mentioned, TRIPS was the main inspiration for this framework. It is a well known and stable architecture that has proven its merits in accommodating a range of different tasks (Allen et al., 2007; Jung et al., 2007). The main modules of the system interact through a Facilitator (Ferguson et al., 1996), similar to the Galaxy HUB7 (Polifroni and Seneff, 2000) with KQML (Labrou and Finin, 1997) messages. However, in TRIPS, the routing task is decentralized since the sender modules decide where to send its messages. At the same time, any module can subscribe to selected messages through the Facilitator according to the sender, the type of message or its contents. This mechanism makes it easier to integrate new modules that subscribe the relevant messages without the senders’ acknowledgment. Like our framework, the CMU Olympus is a classical pipeline dialog system architecture (Bohus et 4http://www.nuance.com/ 5http://www.loquendo.com/ 6http://www.ar</context>
</contexts>
<marker>Polifroni, Seneff, 2000</marker>
<rawString>Joseph Polifroni and Stephanie Seneff. 2000. GALAXYII as an architecture for spoken dialogue evaluation. In Proc. 2,d Int. Conf. Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Antoine Raux</author>
<author>Brian Langner</author>
<author>Dan Bohus</author>
<author>Alan Black</author>
<author>Maxine Eskenazi</author>
</authors>
<title>Let’s go public! taking a spoken dialog system to the real world. In</title>
<date>2005</date>
<booktitle>Proc. INTERSPEECH.</booktitle>
<contexts>
<context position="6173" citStr="Raux et al., 2005" startWordPosition="945" endWordPosition="948">tecture (Bohus et 4http://www.nuance.com/ 5http://www.loquendo.com/ 6http://www.artificial-solutions.com/ 7The Galaxy Hub maintains connections to modules (parser, speech recognizer, back-end, etc.), and routes messages among them. Seehttp://communicator.sourceforge.net/ al., 2007) where the modules are connected via a Galaxy HUB that uses a central hub and a set of rules for relaying messages from one component to the other. It has the three usual main blocks: Language Understanding, through Phoenix parser and Helios confidence-based annotation module, Dialogue Management, through RavenClaw (Raux et al., 2005; Bohus, 2004), and Language Generation, through Rosetta. Recognition is made with Sphinx and synthesis with Theta. The back-end applications are directly connected to the HUB through an included stub. Some of our recent developments are also inspired in Voice XML8, in an effort to simplify the framework parameterization and development, required in the enterprise context. Voice XML provides standard means of declarative configuration of new systems reducing the need of coding to the related devices implementation (Nyberg et al., 2002). Our reengineering work aimed at: i) making the framework </context>
</contexts>
<marker>Raux, Langner, Bohus, Black, Eskenazi, 2005</marker>
<rawString>Antoine Raux, Brian Langner, Dan Bohus, Alan Black, and Maxine Eskenazi. 2005. Let’s go public! taking a spoken dialog system to the real world. In Proc. INTERSPEECH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M´arcio Viveiros</author>
</authors>
<title>Cara falante – uma interface visual para um sistema de di´alogo falado. IST, UTL, Graduation Thesis.</title>
<date>2004</date>
<contexts>
<context position="1434" citStr="Viveiros, 2004" startWordPosition="202" endWordPosition="203">a major reengineering process. This paper describes the changes that the framework went through and that deeply affected its entire architecture. The communication core was enhanced, the modules interfaces were redefined for an easier integration, the SDS deployment process was optimized and the framework robustness was improved. The work was done according to software engineering guidelines and making use of design patterns. 1 Introduction Our SDS framework was created back in 2000 (Mour˜ao et al., 2004), as the result of three graduation theses (Cassaca and Maia, 2002; Mour˜ao et al., 2002; Viveiros, 2004), one of which evolved into a masters thesis (Mour˜ao, 2005). The framework is highly inspired on the TRIPS architecture (Allen et al., 2000): it is a frame-based domain-independent framework that can be used to build domain-specific dialogue systems. Every domain is described by a frame, composed by domain slots that are filled with user requests. When a set of domain slots is filled, a service is executed. In order to do so, the dialogue system interacts with the user until enough information is provided. From the initial version of the framework two systems were created for two different do</context>
<context position="8838" citStr="Viveiros, 2004" startWordPosition="1367" endWordPosition="1368">State, which includes a subset of services that are active when the state is active; Service, which instantiates a defined frame and specifies a set of slots type of data and restrictions for that service. When developing a new domain all these entities have to be defined and instantiated. 2.2 Framework architecture Our initial framework came into existence as the result of the integration of three main modules: Input/Output Manager, that controls an Automatic Speech Recognition (ASR) module (Meinedo, 2008), a Text-To-Speech (TTS) module (Paulo et al., 2008) and provides a virtual agent face (Viveiros, 2004); Dialogue Manager, that interprets the user intentions and generates output messages (Mour˜ao et al., 2002; Mour˜ao, 2005); Service Manager, that provides a dialogue manager interface to execute the requested services, and an external application interface through the device concept (Cassaca and Maia, 2002). 2.3 Input/Output Manager The Input/Output Manager (IOManager) controls an ASR module and a TTS module. It also integrates a virtual agent face, providing a more realistic interaction with the user. The synchronization between the TTS output and the animated face is done by an audio–face s</context>
</contexts>
<marker>Viveiros, 2004</marker>
<rawString>M´arcio Viveiros. 2004. Cara falante – uma interface visual para um sistema de di´alogo falado. IST, UTL, Graduation Thesis.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>