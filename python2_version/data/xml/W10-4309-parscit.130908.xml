<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011892">
<title confidence="0.998952">
Towards Semi-Supervised Classification of Discourse Relations using
Feature Correlations
</title>
<author confidence="0.996517">
Hugo Hernault and Danushka Bollegala and Mitsuru Ishizuka
</author>
<affiliation confidence="0.9967125">
Graduate School of Information Science &amp; Technology
The University of Tokyo
</affiliation>
<address confidence="0.85452">
7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656, Japan
</address>
<email confidence="0.986509666666667">
hugo@mi.ci.i.u-tokyo.ac.jp
danushka@iba.t.u-tokyo.ac.jp
ishizuka@i.u-tokyo.ac.jp
</email>
<sectionHeader confidence="0.997322" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999908576923077">
Two of the main corpora available for
training discourse relation classifiers are
the RST Discourse Treebank (RST-DT)
and the Penn Discourse Treebank (PDTB),
which are both based on the Wall Street
Journal corpus. Most recent work us-
ing discourse relation classifiers have em-
ployed fully-supervised methods on these
corpora. However, certain discourse rela-
tions have little labeled data, causing low
classification performance for their asso-
ciated classes. In this paper, we attempt
to tackle this problem by employing a
semi-supervised method for discourse re-
lation classification. The proposed method
is based on the analysis of feature co-
occurrences in unlabeled data. This in-
formation is then used as a basis to ex-
tend the feature vectors during training.
The proposed method is evaluated on both
RST-DT and PDTB, where it significantly
outperformed baseline classifiers. We be-
lieve that the proposed method is a first
step towards improving classification per-
formance, particularly for discourse rela-
tions lacking annotated data.
</bodyText>
<sectionHeader confidence="0.99947" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999918191489362">
The RST Discourse Treebank (RST-DT) (Carl-
son et al., 2001), based on the Rhetorical Struc-
ture Theory (RST) (Mann and Thompson, 1988)
framework, and the Penn Discourse Treebank
(PDTB) (Prasad et al., 2008), are two of the most
widely-used corpora for training discourse rela-
tion classifiers. They are both based on the Wall
Street Journal (WSJ) corpus, although there are
substantial differences in the relation taxonomy
used to annotate the corpus. These corpora have
been used in most of the recent work employ-
ing discourse relation classifiers, which are based
on fully-supervised machine learning approaches
(duVerle and Prendinger, 2009; Pitler et al., 2009;
Lin et al., 2009).
Still, when building a discourse relation clas-
sifier on either corpus, one is faced with the
same practical issue: Certain relations are very
prevalent, such as ELABORATION[N][S] (RST-
DT), with more than 4000 instances, whereas
other occur rarely, such as EVALUATION[N][N]1
(RST-DT), with three instances, or COMPARI-
SON.PRAGMATIC CONCESSION (PDTB), with 12
instances. This lack of training data causes poor
classification performance on the classes associ-
ated to these relations.
In this paper, we try to tackle this problem by
using feature co-occurrence information, extracted
from unlabeled data, as a way to inform the classi-
fier when unseen features are found in test vectors.
The advantage of the method is that it relies solely
on unlabeled data, which is abundant, and cheap
to collect.
The contributions of this paper are the follow-
ing: First, we propose a semi-supervised method
that exploits the abundant, freely-available un-
labeled data, which is harvested for feature co-
occurrence information, and used as a basis to ex-
tend feature vectors to help classification for cases
where unknown features are found in test vec-
tors. Second, the proposed method is evaluated
on the RST-DT and PDTB corpus, where it signif-
icantly improves F-score when trained on moder-
ately small datasets. For instance, when trained on
a dataset with around 1000 instances, the proposed
method increases the macro-average F-score up to
30%, compared to a baseline classifier.
</bodyText>
<sectionHeader confidence="0.999673" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.9011495">
Since the release in 2002 of the RST-DT corpus,
several fully-supervised discourse parsers have
</bodyText>
<footnote confidence="0.988847">
1We use the notation [N] and [S] respectively to denote
the nucleus and satellite in a RST discourse relation.
</footnote>
<affiliation confidence="0.4834215">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 55–58,
The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics
</affiliation>
<page confidence="0.999632">
55
</page>
<bodyText confidence="0.999930060606061">
been built in the RST framework. In duVerle and
Prendinger (2009), a discourse parser based on
Support Vector Machines (SVM) (Vapnik, 1995)
is proposed. Shallow lexical, syntactic and struc-
tural features, including ‘dominance sets’ (Soricut
and Marcu, 2003) are used.
The unsupervised method of Marcu and Echi-
habi (2002) was the first to try to detect ‘implicit’
relations (i.e. relations not accompanied by a cue
phrase, such as ‘however’, ‘but’), using word pairs
extracted from two spans of text. Their method
attempts to capture the difference of polarity in
words.
Discourse relation classifiers have also been
trained using PDTB. Pitler et al. (2008) performed
a corpus study of the PDTB, and found that ‘ex-
plicit’ relations can be most of the times distin-
guished by their discourse connectives.
Lin et al. (2009) studied the problem of detect-
ing implicit relations in PDTB. Their relational
classifier is trained using features extracted from
dependency paths, contextual information, word
pairs and production rules in parse trees. For the
same task, Pitler et al. (2009) also use word pairs,
as well as several other types of features such as
verb classes, modality, context, and lexical fea-
tures.
In this paper, we are not aiming at defining
novel features for improving performance in RST
or PDTB relation classification. Instead we incor-
porate features that have already shown to be use-
ful for discourse relation learning and explore the
possibilities of using unlabeled data for this task.
</bodyText>
<sectionHeader confidence="0.980811" genericHeader="method">
3 Method
</sectionHeader>
<bodyText confidence="0.999768428571428">
In this section, we describe a semi-supervised
method for relation classification, based on feature
vector extension. The extension process employs
feature co-occurrence information. Co-occurrence
information is useful in this context as, for in-
stance, we might know that the word pair (for,
when) is a good indicator of a TEMPORAL rela-
tion. Or, after analyzing a large body of unlabeled
data, we might also notice that this word pair co-
occurs often with the word ‘run-up’ placed at the
end of a span of text. Suppose now that we have to
classify a test instance containing the feature ‘run-
up’, but not the word pair (for, when). In this case,
by using the co-occurrence information, we know
that the instance has a chance of being a TEM-
PORAL relation. We first explain how to compute
a feature correlation matrix, using unlabeled data.
In a second section, we show how to extend fea-
ture vectors in order to include co-occurrence in-
formation. Finally, we describe the features used
in the discourse relation classifiers.
</bodyText>
<subsectionHeader confidence="0.997015">
3.1 Feature Correlation Matrix
</subsectionHeader>
<bodyText confidence="0.998969555555555">
A training/test instance is represented using a d-
dimensional feature vector f = [f1, ... , fd]T,
where fi E 10, 11. We define a feature correla-
tion matrix, C such that the (i, j)-th element of
C, C(i,j) E 10, 11 denotes the correlation between
the two features fi and fj. If both fi and fj appear
in a feature vector then we define them to be co-
occurring. The number of different feature vectors
in which fi and fj co-occur is used as a basis to
compute C(i,j). Importantly, feature correlations
can be calculated using only unlabeled data.
It is noteworthy that feature correlation matri-
ces can be computed using any correlation mea-
sure. For the current task we use the χ2-measure
(Plackett, 1983) as the preferred correlation mea-
sure because of its simplicity. We create the fea-
ture correlation matrix C, such that, for all pairs of
features (fi, fj),
</bodyText>
<equation confidence="0.7617865">
� 1 if χ2i,j &gt; c
C(i,j) = 0 otherwise. (1)
</equation>
<bodyText confidence="0.998303333333333">
Here c is the critical value, which, for a confi-
dence level of 0.05 and one degree of freedom, can
be set to 3.84.
</bodyText>
<subsectionHeader confidence="0.998999">
3.2 Feature Vector Extension
</subsectionHeader>
<bodyText confidence="0.999955052631579">
Once the feature correlation matrix is computed
using unlabeled data as described in Section 3.1,
we can use it to extend a feature vector during
testing. One of the reasons explaining why a clas-
sifier might perform poorly on a test instance, is
that there are features in the test instance that were
not observed during training. Let us represent the
feature vector corresponding to a test instance x
by fx. Then, we use the feature correlation ma-
trix to find the set of correlated features Fc(fi) of
a particular feature fi that occur in fx.
Specifically, for a feature fi E fx, F&apos;(fi) con-
sists of features fj, where C(i,j) = 1. We define
the extended feature vector f&apos;x of fx as the union of
all the features that appear in fx and Fc(fx). Since
a discourse relation is defined between two spans
of short texts (elementary discourse units), which
are typically two clauses or sentences, a particu-
lar feature does not usually occur more than once
</bodyText>
<page confidence="0.984965">
56
</page>
<bodyText confidence="0.9999192">
in a feature vector. Therefore, we introduced the
proposed method in the context of binary valued
features. However, the above mentioned discus-
sion can be naturally extended to cover real-valued
features.
</bodyText>
<subsectionHeader confidence="0.978147">
3.3 Features
</subsectionHeader>
<bodyText confidence="0.997920769230769">
Figure 1 shows the parse tree for a sentence com-
posed of two discourse units, which serve as argu-
ments of a discourse relation we want to generate
a feature vector from. Lexical heads have been
calculated using the projection rules of Magerman
(1995), and indicated between brackets. For each
argument, surrounded by dots, is the minimal set
of sub-parse trees containing strictly all the words
of the argument.
We extract all possible lemmatized word pairs
from the two arguments. Next, we extract from
left and right argument separately, all production
rules from the sub-parse trees. Finally, we encode
in our features three nodes of the parse tree, which
capture the local context at the connection point
between the two arguments (Soricut and Marcu,
2003): The first node, which we call N,,,, is the
highest ancestor of the first argument’s last word
w, and is such that N,,,’s right-sibling is the an-
cestor of the second argument’s first word. N,,,’s
right-sibling node is called N,.. Finally, we call Np
the parent of N,,, and N,.. For each node, we en-
code in the feature vector its part-of-speech (POS)
and lexical head. For instance, in Figure 1, we
have N,,, = S(comment), N,. = SBAR(when), and
Np = VP(declined).
</bodyText>
<sectionHeader confidence="0.999687" genericHeader="evaluation">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999754652173913">
It is worth noting that the proposed method is inde-
pendent of any particular classification algorithm.
As our goal is strictly to evaluate the relative ben-
efit of employing the proposed method, we se-
lect a logistic regression classifier, for its simplic-
ity. We used the multi-class logistic regression
(maximum entropy model) implemented in Clas-
sias (Okazaki, 2009). Regularization parameters
are set to their default value of one.
Unlabeled instances are created by selecting
texts of the WSJ, and segmenting them into ele-
mentary discourse units (EDUs) using our sequen-
tial discourse segmenter (Hernault et al., 2010).
As there is no segmentation tool for the PDTB
framework, we assumed that feature correlation
information taken from EDUs created using a RST
segmenter is also useful for extending feature vec-
tors of PDTB relations.
Since we are interested in measuring the over-
all performance of a discourse relation classifier
across all relation types, we use macro-averaged
F-score as the preferred evaluation metric for this
task. We train a multi-class logistic regression
model without extending the feature vectors as
a baseline method. This baseline is expected to
show the effect of using the proposed feature ex-
tension approach for the task of discourse relation
learning.
Experimental results on RST-DT and PDTB
datasets are depicted in Figures 2 and 3. We ob-
serve that the proposed feature extension method
outperforms the baseline for both RST-DT and
PDTB datasets for the full range of training dataset
sizes. However, the difference between the two
methods decreases as we increase the amount of
training data. Specifically, with 200 training in-
stances, for RST-DT, the baseline method has a
macro-averaged F-score of 0.079, whereas the the
proposed method has a macro-averaged F-score
of 0.159 (around 101% increase in F-score). For
1000 training instances, the F-score for RST-DT
increases by 29.2%, from 0.143 to 0.185, while
the F-score for PDTB increases by 27.9%, from
0.109 to 0.139. However, the difference between
the two methods diminishes beyond 10000 train-
ing instances.
</bodyText>
<figure confidence="0.998824444444444">
0.30
0.25
0.20
0.15
0.10
Proposed method
Baseline RST-DT
0.050 5000 10000 15000 20000
Number of training instances
</figure>
<figureCaption confidence="0.888212">
Figure 2: Macro-average F-score (RST-DT) as a
function of the number of training instances used.
</figureCaption>
<sectionHeader confidence="0.995726" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.888215666666667">
We presented a semi-supervised method for im-
proving the performance of discourse relation
classifiers. The proposed method is based on
the analysis of co-occurrence information har-
vested from unlabeled data only. We evaluated
Macro-average F-score
</bodyText>
<page confidence="0.711375">
57
</page>
<figure confidence="0.9920495">
S (declined)
Argument 1 Argument 2
</figure>
<figureCaption confidence="0.996528">
Figure 1: Two arguments of a discourse relation, and the minimum set of subtrees that contain them—
lexical heads are indicated between brackets.
</figureCaption>
<figure confidence="0.999395526315789">
NNP NNP VBD (declined)
Mr. Sherry declined to
NP (Sherry)
TO VP
VP (comment)
S (comment)
VP (declined)
comment when asked about the sales
VB
WHADVP (when)
WRB
SBAR (when)
S (asked)
VP (asked)
VBN PP (about)
IN NP (sales)
DT NNS
. (.)
.
</figure>
<figureCaption confidence="0.858944">
Figure 3: Macro-average F-score (PDTB) as a
function of the number of training instances used.
</figureCaption>
<bodyText confidence="0.9998608">
the method on two of the most widely-used dis-
course corpora, RST-DT and PDTB. The method
performs significantly better than a baseline classi-
fier trained on the same features, especially when
the number of labeled instances used for training is
small. For instance, using 1000 training instances,
we observed an increase of nearly 30% in macro-
average F-score. This is an interesting perspective
for improving classification performance of rela-
tions with little training data. In the future, we
plan to improve the method by employing ranked
co-occurrences. This way, only the most relevant
correlated features can be selected during feature
vector extension. Finally, we plan to investigate
using larger amounts of unlabeled training data.
</bodyText>
<sectionHeader confidence="0.999325" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998721951219512">
L. Carlson, D. Marcu, and M. E. Okurowski. 2001.
Building a discourse-tagged corpus in the frame-
work of Rhetorical Structure Theory. Proc. of Sec-
ond SIGdial Workshop on Discourse and Dialogue-
Volume 16, pages 1–10.
D. A. duVerle and H. Prendinger. 2009. A novel
discourse parser based on Support Vector Machine
classification. In Proc. of ACL’09, pages 665–673.
H. Hernault, D. Bollegala, and M. Ishizuka. 2010.
A sequential model for discourse segmentation. In
Proc. of CICLing’10, pages 315–326.
Z. Lin, M-Y. Kan, and H. T. Ng. 2009. Recognizing
implicit discourse relations in the Penn Discourse
Treebank. In Proc. of EMNLP’09, pages 343–351.
D. M. Magerman. 1995. Statistical decision-tree mod-
els for parsing. Proc. of ACL’95, pages 276–283.
W. C. Mann and S. A. Thompson. 1988. Rhetorical
Structure Theory: Toward a functional theory of text
organization. Text, 8(3):243–281.
D. Marcu and A. Echihabi. 2002. An unsupervised ap-
proach to recognizing discourse relations. In Proc.
ofACL’02, pages 368–375.
N. Okazaki. 2009. Classias: A collection of machine-
learning algorithms for classification.
E. Pitler, M. Raghupathy, H. Mehta, A. Nenkova,
A. Lee, and A. Joshi. 2008. Easily identifiable dis-
course relations. In Proc. of COLING’08 (Posters),
pages 87–90.
E. Pitler, A. Louis, and A. Nenkova. 2009. Automatic
sense prediction for implicit discourse relations in
text. In Proc. of ACL’09, pages 683–691.
R. L. Plackett. 1983. Karl Pearson and the chi-squared
test. International Statistical Review, 51(1):59–72.
R. Prasad, N. Dinesh, A. Lee, E. Miltsakaki,
L. Robaldo, A. Joshi, and B. Webber. 2008. The
Penn Discourse Treebank 2.0. In Proc. of LREC’08.
R. Soricut and D. Marcu. 2003. Sentence level dis-
course parsing using syntactic and lexical informa-
tion. Proc. of NA-ACL’03, 1:149–156.
V. N. Vapnik. 1995. The Nature of Statistical Learning
Theory. Springer-Verlag New York, Inc.
</reference>
<figure confidence="0.998873916666667">
0.35
0.30
0.25
0.20
0.15
0.10
Proposed method
Baseline PDTB
0.000 2000 4000 6000 8000 10000
Number of training instances
Macro-average F-score
0.05
</figure>
<page confidence="0.985373">
58
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.898153">
<title confidence="0.999406">Towards Semi-Supervised Classification of Discourse Relations Feature Correlations</title>
<author confidence="0.979523">Hernault Bollegala</author>
<affiliation confidence="0.99706">Graduate School of Information Science &amp; The University of</affiliation>
<address confidence="0.955344">7-3-1 Hongo, Bunkyo-ku, Tokyo 113-8656,</address>
<email confidence="0.970414">ishizuka@i.u-tokyo.ac.jp</email>
<abstract confidence="0.999334111111111">Two of the main corpora available for training discourse relation classifiers are the RST Discourse Treebank (RST-DT) and the Penn Discourse Treebank (PDTB), which are both based on the Wall Street Journal corpus. Most recent work using discourse relation classifiers have employed fully-supervised methods on these corpora. However, certain discourse relations have little labeled data, causing low classification performance for their associated classes. In this paper, we attempt to tackle this problem by employing a semi-supervised method for discourse relation classification. The proposed method is based on the analysis of feature cooccurrences in unlabeled data. This information is then used as a basis to extend the feature vectors during training. The proposed method is evaluated on both RST-DT and PDTB, where it significantly outperformed baseline classifiers. We believe that the proposed method is a first step towards improving classification performance, particularly for discourse relations lacking annotated data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>L Carlson</author>
<author>D Marcu</author>
<author>M E Okurowski</author>
</authors>
<title>Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory.</title>
<date>2001</date>
<booktitle>Proc. of Second SIGdial Workshop on Discourse and DialogueVolume 16,</booktitle>
<pages>1--10</pages>
<contexts>
<context position="1467" citStr="Carlson et al., 2001" startWordPosition="203" endWordPosition="207">ackle this problem by employing a semi-supervised method for discourse relation classification. The proposed method is based on the analysis of feature cooccurrences in unlabeled data. This information is then used as a basis to extend the feature vectors during training. The proposed method is evaluated on both RST-DT and PDTB, where it significantly outperformed baseline classifiers. We believe that the proposed method is a first step towards improving classification performance, particularly for discourse relations lacking annotated data. 1 Introduction The RST Discourse Treebank (RST-DT) (Carlson et al., 2001), based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) framework, and the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), are two of the most widely-used corpora for training discourse relation classifiers. They are both based on the Wall Street Journal (WSJ) corpus, although there are substantial differences in the relation taxonomy used to annotate the corpus. These corpora have been used in most of the recent work employing discourse relation classifiers, which are based on fully-supervised machine learning approaches (duVerle and Prendinger, 2009; Pitler et al., 2</context>
</contexts>
<marker>Carlson, Marcu, Okurowski, 2001</marker>
<rawString>L. Carlson, D. Marcu, and M. E. Okurowski. 2001. Building a discourse-tagged corpus in the framework of Rhetorical Structure Theory. Proc. of Second SIGdial Workshop on Discourse and DialogueVolume 16, pages 1–10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A duVerle</author>
<author>H Prendinger</author>
</authors>
<title>A novel discourse parser based on Support Vector Machine classification.</title>
<date>2009</date>
<booktitle>In Proc. of ACL’09,</booktitle>
<pages>665--673</pages>
<contexts>
<context position="2049" citStr="duVerle and Prendinger, 2009" startWordPosition="293" endWordPosition="296">ourse Treebank (RST-DT) (Carlson et al., 2001), based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) framework, and the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), are two of the most widely-used corpora for training discourse relation classifiers. They are both based on the Wall Street Journal (WSJ) corpus, although there are substantial differences in the relation taxonomy used to annotate the corpus. These corpora have been used in most of the recent work employing discourse relation classifiers, which are based on fully-supervised machine learning approaches (duVerle and Prendinger, 2009; Pitler et al., 2009; Lin et al., 2009). Still, when building a discourse relation classifier on either corpus, one is faced with the same practical issue: Certain relations are very prevalent, such as ELABORATION[N][S] (RSTDT), with more than 4000 instances, whereas other occur rarely, such as EVALUATION[N][N]1 (RST-DT), with three instances, or COMPARISON.PRAGMATIC CONCESSION (PDTB), with 12 instances. This lack of training data causes poor classification performance on the classes associated to these relations. In this paper, we try to tackle this problem by using feature co-occurrence inf</context>
<context position="4063" citStr="duVerle and Prendinger (2009)" startWordPosition="611" endWordPosition="614">000 instances, the proposed method increases the macro-average F-score up to 30%, compared to a baseline classifier. 2 Related Work Since the release in 2002 of the RST-DT corpus, several fully-supervised discourse parsers have 1We use the notation [N] and [S] respectively to denote the nucleus and satellite in a RST discourse relation. Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 55–58, The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics 55 been built in the RST framework. In duVerle and Prendinger (2009), a discourse parser based on Support Vector Machines (SVM) (Vapnik, 1995) is proposed. Shallow lexical, syntactic and structural features, including ‘dominance sets’ (Soricut and Marcu, 2003) are used. The unsupervised method of Marcu and Echihabi (2002) was the first to try to detect ‘implicit’ relations (i.e. relations not accompanied by a cue phrase, such as ‘however’, ‘but’), using word pairs extracted from two spans of text. Their method attempts to capture the difference of polarity in words. Discourse relation classifiers have also been trained using PDTB. Pitler et al. (2008) performe</context>
</contexts>
<marker>duVerle, Prendinger, 2009</marker>
<rawString>D. A. duVerle and H. Prendinger. 2009. A novel discourse parser based on Support Vector Machine classification. In Proc. of ACL’09, pages 665–673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Hernault</author>
<author>D Bollegala</author>
<author>M Ishizuka</author>
</authors>
<title>A sequential model for discourse segmentation.</title>
<date>2010</date>
<booktitle>In Proc. of CICLing’10,</booktitle>
<pages>315--326</pages>
<contexts>
<context position="10628" citStr="Hernault et al., 2010" startWordPosition="1720" endWordPosition="1723">nts It is worth noting that the proposed method is independent of any particular classification algorithm. As our goal is strictly to evaluate the relative benefit of employing the proposed method, we select a logistic regression classifier, for its simplicity. We used the multi-class logistic regression (maximum entropy model) implemented in Classias (Okazaki, 2009). Regularization parameters are set to their default value of one. Unlabeled instances are created by selecting texts of the WSJ, and segmenting them into elementary discourse units (EDUs) using our sequential discourse segmenter (Hernault et al., 2010). As there is no segmentation tool for the PDTB framework, we assumed that feature correlation information taken from EDUs created using a RST segmenter is also useful for extending feature vectors of PDTB relations. Since we are interested in measuring the overall performance of a discourse relation classifier across all relation types, we use macro-averaged F-score as the preferred evaluation metric for this task. We train a multi-class logistic regression model without extending the feature vectors as a baseline method. This baseline is expected to show the effect of using the proposed feat</context>
</contexts>
<marker>Hernault, Bollegala, Ishizuka, 2010</marker>
<rawString>H. Hernault, D. Bollegala, and M. Ishizuka. 2010. A sequential model for discourse segmentation. In Proc. of CICLing’10, pages 315–326.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Lin</author>
<author>M-Y Kan</author>
<author>H T Ng</author>
</authors>
<title>Recognizing implicit discourse relations in the Penn Discourse Treebank.</title>
<date>2009</date>
<booktitle>In Proc. of EMNLP’09,</booktitle>
<pages>343--351</pages>
<contexts>
<context position="2089" citStr="Lin et al., 2009" startWordPosition="301" endWordPosition="304">ed on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) framework, and the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), are two of the most widely-used corpora for training discourse relation classifiers. They are both based on the Wall Street Journal (WSJ) corpus, although there are substantial differences in the relation taxonomy used to annotate the corpus. These corpora have been used in most of the recent work employing discourse relation classifiers, which are based on fully-supervised machine learning approaches (duVerle and Prendinger, 2009; Pitler et al., 2009; Lin et al., 2009). Still, when building a discourse relation classifier on either corpus, one is faced with the same practical issue: Certain relations are very prevalent, such as ELABORATION[N][S] (RSTDT), with more than 4000 instances, whereas other occur rarely, such as EVALUATION[N][N]1 (RST-DT), with three instances, or COMPARISON.PRAGMATIC CONCESSION (PDTB), with 12 instances. This lack of training data causes poor classification performance on the classes associated to these relations. In this paper, we try to tackle this problem by using feature co-occurrence information, extracted from unlabeled data,</context>
<context position="4817" citStr="Lin et al. (2009)" startWordPosition="732" endWordPosition="735">s, including ‘dominance sets’ (Soricut and Marcu, 2003) are used. The unsupervised method of Marcu and Echihabi (2002) was the first to try to detect ‘implicit’ relations (i.e. relations not accompanied by a cue phrase, such as ‘however’, ‘but’), using word pairs extracted from two spans of text. Their method attempts to capture the difference of polarity in words. Discourse relation classifiers have also been trained using PDTB. Pitler et al. (2008) performed a corpus study of the PDTB, and found that ‘explicit’ relations can be most of the times distinguished by their discourse connectives. Lin et al. (2009) studied the problem of detecting implicit relations in PDTB. Their relational classifier is trained using features extracted from dependency paths, contextual information, word pairs and production rules in parse trees. For the same task, Pitler et al. (2009) also use word pairs, as well as several other types of features such as verb classes, modality, context, and lexical features. In this paper, we are not aiming at defining novel features for improving performance in RST or PDTB relation classification. Instead we incorporate features that have already shown to be useful for discourse rel</context>
</contexts>
<marker>Lin, Kan, Ng, 2009</marker>
<rawString>Z. Lin, M-Y. Kan, and H. T. Ng. 2009. Recognizing implicit discourse relations in the Penn Discourse Treebank. In Proc. of EMNLP’09, pages 343–351.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D M Magerman</author>
</authors>
<title>Statistical decision-tree models for parsing.</title>
<date>1995</date>
<booktitle>Proc. of ACL’95,</booktitle>
<pages>276--283</pages>
<contexts>
<context position="9022" citStr="Magerman (1995)" startWordPosition="1459" endWordPosition="1460">rt texts (elementary discourse units), which are typically two clauses or sentences, a particular feature does not usually occur more than once 56 in a feature vector. Therefore, we introduced the proposed method in the context of binary valued features. However, the above mentioned discussion can be naturally extended to cover real-valued features. 3.3 Features Figure 1 shows the parse tree for a sentence composed of two discourse units, which serve as arguments of a discourse relation we want to generate a feature vector from. Lexical heads have been calculated using the projection rules of Magerman (1995), and indicated between brackets. For each argument, surrounded by dots, is the minimal set of sub-parse trees containing strictly all the words of the argument. We extract all possible lemmatized word pairs from the two arguments. Next, we extract from left and right argument separately, all production rules from the sub-parse trees. Finally, we encode in our features three nodes of the parse tree, which capture the local context at the connection point between the two arguments (Soricut and Marcu, 2003): The first node, which we call N,,,, is the highest ancestor of the first argument’s last</context>
</contexts>
<marker>Magerman, 1995</marker>
<rawString>D. M. Magerman. 1995. Statistical decision-tree models for parsing. Proc. of ACL’95, pages 276–283.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Mann</author>
<author>S A Thompson</author>
</authors>
<title>Rhetorical Structure Theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="1541" citStr="Mann and Thompson, 1988" startWordPosition="216" endWordPosition="219">relation classification. The proposed method is based on the analysis of feature cooccurrences in unlabeled data. This information is then used as a basis to extend the feature vectors during training. The proposed method is evaluated on both RST-DT and PDTB, where it significantly outperformed baseline classifiers. We believe that the proposed method is a first step towards improving classification performance, particularly for discourse relations lacking annotated data. 1 Introduction The RST Discourse Treebank (RST-DT) (Carlson et al., 2001), based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) framework, and the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), are two of the most widely-used corpora for training discourse relation classifiers. They are both based on the Wall Street Journal (WSJ) corpus, although there are substantial differences in the relation taxonomy used to annotate the corpus. These corpora have been used in most of the recent work employing discourse relation classifiers, which are based on fully-supervised machine learning approaches (duVerle and Prendinger, 2009; Pitler et al., 2009; Lin et al., 2009). Still, when building a discourse relation classifi</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>W. C. Mann and S. A. Thompson. 1988. Rhetorical Structure Theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Marcu</author>
<author>A Echihabi</author>
</authors>
<title>An unsupervised approach to recognizing discourse relations.</title>
<date>2002</date>
<booktitle>In Proc. ofACL’02,</booktitle>
<pages>368--375</pages>
<contexts>
<context position="4318" citStr="Marcu and Echihabi (2002)" startWordPosition="648" endWordPosition="652">] respectively to denote the nucleus and satellite in a RST discourse relation. Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 55–58, The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics 55 been built in the RST framework. In duVerle and Prendinger (2009), a discourse parser based on Support Vector Machines (SVM) (Vapnik, 1995) is proposed. Shallow lexical, syntactic and structural features, including ‘dominance sets’ (Soricut and Marcu, 2003) are used. The unsupervised method of Marcu and Echihabi (2002) was the first to try to detect ‘implicit’ relations (i.e. relations not accompanied by a cue phrase, such as ‘however’, ‘but’), using word pairs extracted from two spans of text. Their method attempts to capture the difference of polarity in words. Discourse relation classifiers have also been trained using PDTB. Pitler et al. (2008) performed a corpus study of the PDTB, and found that ‘explicit’ relations can be most of the times distinguished by their discourse connectives. Lin et al. (2009) studied the problem of detecting implicit relations in PDTB. Their relational classifier is trained </context>
</contexts>
<marker>Marcu, Echihabi, 2002</marker>
<rawString>D. Marcu and A. Echihabi. 2002. An unsupervised approach to recognizing discourse relations. In Proc. ofACL’02, pages 368–375.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Okazaki</author>
</authors>
<title>Classias: A collection of machinelearning algorithms for classification.</title>
<date>2009</date>
<contexts>
<context position="10375" citStr="Okazaki, 2009" startWordPosition="1683" endWordPosition="1684">. Finally, we call Np the parent of N,,, and N,.. For each node, we encode in the feature vector its part-of-speech (POS) and lexical head. For instance, in Figure 1, we have N,,, = S(comment), N,. = SBAR(when), and Np = VP(declined). 4 Experiments It is worth noting that the proposed method is independent of any particular classification algorithm. As our goal is strictly to evaluate the relative benefit of employing the proposed method, we select a logistic regression classifier, for its simplicity. We used the multi-class logistic regression (maximum entropy model) implemented in Classias (Okazaki, 2009). Regularization parameters are set to their default value of one. Unlabeled instances are created by selecting texts of the WSJ, and segmenting them into elementary discourse units (EDUs) using our sequential discourse segmenter (Hernault et al., 2010). As there is no segmentation tool for the PDTB framework, we assumed that feature correlation information taken from EDUs created using a RST segmenter is also useful for extending feature vectors of PDTB relations. Since we are interested in measuring the overall performance of a discourse relation classifier across all relation types, we use </context>
</contexts>
<marker>Okazaki, 2009</marker>
<rawString>N. Okazaki. 2009. Classias: A collection of machinelearning algorithms for classification.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Pitler</author>
<author>M Raghupathy</author>
<author>H Mehta</author>
<author>A Nenkova</author>
<author>A Lee</author>
<author>A Joshi</author>
</authors>
<title>Easily identifiable discourse relations.</title>
<date>2008</date>
<booktitle>In Proc. of COLING’08 (Posters),</booktitle>
<pages>87--90</pages>
<contexts>
<context position="4654" citStr="Pitler et al. (2008)" startWordPosition="703" endWordPosition="706">duVerle and Prendinger (2009), a discourse parser based on Support Vector Machines (SVM) (Vapnik, 1995) is proposed. Shallow lexical, syntactic and structural features, including ‘dominance sets’ (Soricut and Marcu, 2003) are used. The unsupervised method of Marcu and Echihabi (2002) was the first to try to detect ‘implicit’ relations (i.e. relations not accompanied by a cue phrase, such as ‘however’, ‘but’), using word pairs extracted from two spans of text. Their method attempts to capture the difference of polarity in words. Discourse relation classifiers have also been trained using PDTB. Pitler et al. (2008) performed a corpus study of the PDTB, and found that ‘explicit’ relations can be most of the times distinguished by their discourse connectives. Lin et al. (2009) studied the problem of detecting implicit relations in PDTB. Their relational classifier is trained using features extracted from dependency paths, contextual information, word pairs and production rules in parse trees. For the same task, Pitler et al. (2009) also use word pairs, as well as several other types of features such as verb classes, modality, context, and lexical features. In this paper, we are not aiming at defining nove</context>
</contexts>
<marker>Pitler, Raghupathy, Mehta, Nenkova, Lee, Joshi, 2008</marker>
<rawString>E. Pitler, M. Raghupathy, H. Mehta, A. Nenkova, A. Lee, and A. Joshi. 2008. Easily identifiable discourse relations. In Proc. of COLING’08 (Posters), pages 87–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Pitler</author>
<author>A Louis</author>
<author>A Nenkova</author>
</authors>
<title>Automatic sense prediction for implicit discourse relations in text.</title>
<date>2009</date>
<booktitle>In Proc. of ACL’09,</booktitle>
<pages>683--691</pages>
<contexts>
<context position="2070" citStr="Pitler et al., 2009" startWordPosition="297" endWordPosition="300">on et al., 2001), based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) framework, and the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), are two of the most widely-used corpora for training discourse relation classifiers. They are both based on the Wall Street Journal (WSJ) corpus, although there are substantial differences in the relation taxonomy used to annotate the corpus. These corpora have been used in most of the recent work employing discourse relation classifiers, which are based on fully-supervised machine learning approaches (duVerle and Prendinger, 2009; Pitler et al., 2009; Lin et al., 2009). Still, when building a discourse relation classifier on either corpus, one is faced with the same practical issue: Certain relations are very prevalent, such as ELABORATION[N][S] (RSTDT), with more than 4000 instances, whereas other occur rarely, such as EVALUATION[N][N]1 (RST-DT), with three instances, or COMPARISON.PRAGMATIC CONCESSION (PDTB), with 12 instances. This lack of training data causes poor classification performance on the classes associated to these relations. In this paper, we try to tackle this problem by using feature co-occurrence information, extracted f</context>
<context position="5077" citStr="Pitler et al. (2009)" startWordPosition="771" endWordPosition="774"> pairs extracted from two spans of text. Their method attempts to capture the difference of polarity in words. Discourse relation classifiers have also been trained using PDTB. Pitler et al. (2008) performed a corpus study of the PDTB, and found that ‘explicit’ relations can be most of the times distinguished by their discourse connectives. Lin et al. (2009) studied the problem of detecting implicit relations in PDTB. Their relational classifier is trained using features extracted from dependency paths, contextual information, word pairs and production rules in parse trees. For the same task, Pitler et al. (2009) also use word pairs, as well as several other types of features such as verb classes, modality, context, and lexical features. In this paper, we are not aiming at defining novel features for improving performance in RST or PDTB relation classification. Instead we incorporate features that have already shown to be useful for discourse relation learning and explore the possibilities of using unlabeled data for this task. 3 Method In this section, we describe a semi-supervised method for relation classification, based on feature vector extension. The extension process employs feature co-occurren</context>
</contexts>
<marker>Pitler, Louis, Nenkova, 2009</marker>
<rawString>E. Pitler, A. Louis, and A. Nenkova. 2009. Automatic sense prediction for implicit discourse relations in text. In Proc. of ACL’09, pages 683–691.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R L Plackett</author>
</authors>
<title>Karl Pearson and the chi-squared test.</title>
<date>1983</date>
<journal>International Statistical Review,</journal>
<volume>51</volume>
<issue>1</issue>
<contexts>
<context position="7260" citStr="Plackett, 1983" startWordPosition="1147" endWordPosition="1148">, ... , fd]T, where fi E 10, 11. We define a feature correlation matrix, C such that the (i, j)-th element of C, C(i,j) E 10, 11 denotes the correlation between the two features fi and fj. If both fi and fj appear in a feature vector then we define them to be cooccurring. The number of different feature vectors in which fi and fj co-occur is used as a basis to compute C(i,j). Importantly, feature correlations can be calculated using only unlabeled data. It is noteworthy that feature correlation matrices can be computed using any correlation measure. For the current task we use the χ2-measure (Plackett, 1983) as the preferred correlation measure because of its simplicity. We create the feature correlation matrix C, such that, for all pairs of features (fi, fj), � 1 if χ2i,j &gt; c C(i,j) = 0 otherwise. (1) Here c is the critical value, which, for a confidence level of 0.05 and one degree of freedom, can be set to 3.84. 3.2 Feature Vector Extension Once the feature correlation matrix is computed using unlabeled data as described in Section 3.1, we can use it to extend a feature vector during testing. One of the reasons explaining why a classifier might perform poorly on a test instance, is that there </context>
</contexts>
<marker>Plackett, 1983</marker>
<rawString>R. L. Plackett. 1983. Karl Pearson and the chi-squared test. International Statistical Review, 51(1):59–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Prasad</author>
<author>N Dinesh</author>
<author>A Lee</author>
<author>E Miltsakaki</author>
<author>L Robaldo</author>
<author>A Joshi</author>
<author>B Webber</author>
</authors>
<title>The Penn Discourse Treebank 2.0. In</title>
<date>2008</date>
<booktitle>Proc. of LREC’08.</booktitle>
<contexts>
<context position="1613" citStr="Prasad et al., 2008" startWordPosition="227" endWordPosition="230">ture cooccurrences in unlabeled data. This information is then used as a basis to extend the feature vectors during training. The proposed method is evaluated on both RST-DT and PDTB, where it significantly outperformed baseline classifiers. We believe that the proposed method is a first step towards improving classification performance, particularly for discourse relations lacking annotated data. 1 Introduction The RST Discourse Treebank (RST-DT) (Carlson et al., 2001), based on the Rhetorical Structure Theory (RST) (Mann and Thompson, 1988) framework, and the Penn Discourse Treebank (PDTB) (Prasad et al., 2008), are two of the most widely-used corpora for training discourse relation classifiers. They are both based on the Wall Street Journal (WSJ) corpus, although there are substantial differences in the relation taxonomy used to annotate the corpus. These corpora have been used in most of the recent work employing discourse relation classifiers, which are based on fully-supervised machine learning approaches (duVerle and Prendinger, 2009; Pitler et al., 2009; Lin et al., 2009). Still, when building a discourse relation classifier on either corpus, one is faced with the same practical issue: Certain</context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>R. Prasad, N. Dinesh, A. Lee, E. Miltsakaki, L. Robaldo, A. Joshi, and B. Webber. 2008. The Penn Discourse Treebank 2.0. In Proc. of LREC’08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Soricut</author>
<author>D Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>Proc. of NA-ACL’03,</booktitle>
<pages>1--149</pages>
<contexts>
<context position="4255" citStr="Soricut and Marcu, 2003" startWordPosition="638" endWordPosition="641">ervised discourse parsers have 1We use the notation [N] and [S] respectively to denote the nucleus and satellite in a RST discourse relation. Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 55–58, The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics 55 been built in the RST framework. In duVerle and Prendinger (2009), a discourse parser based on Support Vector Machines (SVM) (Vapnik, 1995) is proposed. Shallow lexical, syntactic and structural features, including ‘dominance sets’ (Soricut and Marcu, 2003) are used. The unsupervised method of Marcu and Echihabi (2002) was the first to try to detect ‘implicit’ relations (i.e. relations not accompanied by a cue phrase, such as ‘however’, ‘but’), using word pairs extracted from two spans of text. Their method attempts to capture the difference of polarity in words. Discourse relation classifiers have also been trained using PDTB. Pitler et al. (2008) performed a corpus study of the PDTB, and found that ‘explicit’ relations can be most of the times distinguished by their discourse connectives. Lin et al. (2009) studied the problem of detecting impl</context>
<context position="9532" citStr="Soricut and Marcu, 2003" startWordPosition="1538" endWordPosition="1541">o generate a feature vector from. Lexical heads have been calculated using the projection rules of Magerman (1995), and indicated between brackets. For each argument, surrounded by dots, is the minimal set of sub-parse trees containing strictly all the words of the argument. We extract all possible lemmatized word pairs from the two arguments. Next, we extract from left and right argument separately, all production rules from the sub-parse trees. Finally, we encode in our features three nodes of the parse tree, which capture the local context at the connection point between the two arguments (Soricut and Marcu, 2003): The first node, which we call N,,,, is the highest ancestor of the first argument’s last word w, and is such that N,,,’s right-sibling is the ancestor of the second argument’s first word. N,,,’s right-sibling node is called N,.. Finally, we call Np the parent of N,,, and N,.. For each node, we encode in the feature vector its part-of-speech (POS) and lexical head. For instance, in Figure 1, we have N,,, = S(comment), N,. = SBAR(when), and Np = VP(declined). 4 Experiments It is worth noting that the proposed method is independent of any particular classification algorithm. As our goal is stri</context>
</contexts>
<marker>Soricut, Marcu, 2003</marker>
<rawString>R. Soricut and D. Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. Proc. of NA-ACL’03, 1:149–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V N Vapnik</author>
</authors>
<title>The Nature of Statistical Learning Theory.</title>
<date>1995</date>
<publisher>Springer-Verlag</publisher>
<location>New York, Inc.</location>
<contexts>
<context position="4137" citStr="Vapnik, 1995" startWordPosition="624" endWordPosition="625"> to a baseline classifier. 2 Related Work Since the release in 2002 of the RST-DT corpus, several fully-supervised discourse parsers have 1We use the notation [N] and [S] respectively to denote the nucleus and satellite in a RST discourse relation. Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 55–58, The University of Tokyo, September 24-25, 2010. p@c 2010 Association for Computational Linguistics 55 been built in the RST framework. In duVerle and Prendinger (2009), a discourse parser based on Support Vector Machines (SVM) (Vapnik, 1995) is proposed. Shallow lexical, syntactic and structural features, including ‘dominance sets’ (Soricut and Marcu, 2003) are used. The unsupervised method of Marcu and Echihabi (2002) was the first to try to detect ‘implicit’ relations (i.e. relations not accompanied by a cue phrase, such as ‘however’, ‘but’), using word pairs extracted from two spans of text. Their method attempts to capture the difference of polarity in words. Discourse relation classifiers have also been trained using PDTB. Pitler et al. (2008) performed a corpus study of the PDTB, and found that ‘explicit’ relations can be m</context>
</contexts>
<marker>Vapnik, 1995</marker>
<rawString>V. N. Vapnik. 1995. The Nature of Statistical Learning Theory. Springer-Verlag New York, Inc.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>