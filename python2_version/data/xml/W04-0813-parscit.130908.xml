<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004753">
<title confidence="0.723187">
The Basque Country University system: English and Basque tasks
Eneko Agirre
</title>
<author confidence="0.464782">
IXA NLP Group
</author>
<affiliation confidence="0.675876">
Basque Country University
</affiliation>
<address confidence="0.53913">
Donostia, Spain
</address>
<email confidence="0.952082">
eneko@si.ehu.es
</email>
<author confidence="0.717553">
David Martinez
</author>
<affiliation confidence="0.5569735">
IXA NLP Group
Basque Country University
</affiliation>
<address confidence="0.723816">
Donostia, Spain
</address>
<email confidence="0.947768">
davidm@si.ehu.es
</email>
<sectionHeader confidence="0.992759" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999574181818182">
Our group participated in the Basque and En-
glish lexical sample tasks in Senseval-3. A
language-specific feature set was defined for
Basque. Four different learning algorithms were
applied, and also a method that combined their
outputs. Before submission, the performance
of the methods was tested for each task on the
Senseval-3 training data using cross validation.
Finally, two systems were submitted for each
language: the best single algorithm and the best
ensemble.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999961044444444">
Our group (BCU, Basque Country University),
participated in the Basque and English lexical
sample tasks in Senseval-3. We applied 4 differ-
ent learning algorithms (Decision Lists, Naive
Bayes, Vector Space Model, and Support Vector
Machines), and also a method that combined
their outputs. These algorithms were previously
tested and tuned on the Senseval-2 data for En-
glish. Before submission, the performance of
the methods was tested for each task on the
Senseval-3 training data using 10 fold cross val-
idation. Finally, two systems were submitted
for each language, the best single algorithm and
the best ensemble in cross-validation.
The main difference between the Basque and
English systems was the feature set. A rich
set of features was used for English, includ-
ing syntactic dependencies and domain infor-
mation, extracted with different tools, and also
from external resources like WordNet Domains
(Magnini and Cavagli´a, 2000). The features for
Basque were different, as Basque is an agglu-
tinative language, and syntactic information is
given by inflectional suffixes. We tried to rep-
resent this information in local features, relying
on the analysis of a deep morphological analyzer
developed in our group (Aduriz et al., 2000).
In order to improve the performance of the al-
gorithms, different smoothing techniques were
tested on the English Senseval-2 lexical sam-
ple data (Agirre and Martinez, 2004), and ap-
plied to Senseval-3. These methods helped to
obtain better estimations for the features, and
to avoid the problem of 0 counts Decision Lists
and Naive Bayes.
This paper is organized as follows. The learn-
ing algorithms are first introduced in Section 2,
and Section 3 describes the features applied to
each task. In Section 4, we present the exper-
iments performed on training data before sub-
mission; this section also covers the final config-
uration of each algorithm, and the performance
obtained on training data. Finally, the official
results in Senseval-3 are presented and discussed
in Section 5.
</bodyText>
<sectionHeader confidence="0.916337" genericHeader="method">
2 Learning Algorithms
</sectionHeader>
<bodyText confidence="0.999795272727273">
The algorithms presented in this section rely on
features extracted from the context of the target
word to make their decisions.
The Decision List (DL) algorithm is de-
scribed in (Yarowsky, 1995b). In this algorithm
the sense with the highest weighted feature is se-
lected, as shown below. We can avoid undeter-
mined values by discarding features that have a
0 probability in the divisor. More sophisticated
smoothing techniques have also been tried (cf.
Section 4).
</bodyText>
<equation confidence="0.996487">
w(sk, fi) = log( Pr(skIfi) )
Ej=,4k Pr(sj |fi)
</equation>
<bodyText confidence="0.99861">
The Naive Bayes (NB) algorithm is based
on the conditional probability of each sense
given the features in the context. It also re-
quires smoothing.
</bodyText>
<equation confidence="0.98423">
P(sk) M11 P(fi|sk)
</equation>
<bodyText confidence="0.986580666666667">
For the Vector Space Model (V) algo-
rithm, we represent each occurrence context as
a vector, where each feature will have a 1 or 0
</bodyText>
<figure confidence="0.84167975">
arg max
k
arg max
k
</figure>
<footnote confidence="0.821841">
SENSEVAL-3: Third International Workshop on the Evaluation of Systems
for the Semantic Analysis of Text, Barcelona, Spain, July 2004
</footnote>
<subsectionHeader confidence="0.761228">
Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.999968333333333">
value to indicate the occurrence/absence of the
feature. For each sense in training, one cen-
troid vector is obtained. These centroids are
compared with the vectors that represent test-
ing examples, by means of the cosine similarity
function. The closest centroid is used to assign
its sense to the testing example. No smooth-
ing is required to apply this algorithm, but it is
possible to use smoothed values.
</bodyText>
<subsectionHeader confidence="0.934096">
Regarding Support Vector Machines
</subsectionHeader>
<bodyText confidence="0.99987275">
(SVM) we utilized SVM-Light (Joachims,
1999), a public distribution of SVM. Linear ker-
nels were applied, and the soft margin (C) was
estimated per each word (cf. Section 4).
</bodyText>
<sectionHeader confidence="0.999926" genericHeader="method">
3 Features
</sectionHeader>
<subsectionHeader confidence="0.970171">
3.1 Features for English
</subsectionHeader>
<bodyText confidence="0.9999282">
We relied on an extensive set of features of
different types, obtained by means of different
tools and resources. The features used can be
grouped in four groups:
Local collocations: bigrams and trigrams
formed with the words around the target. These
features are constituted with lemmas, word-
forms, or PoS tags1. Other local features
are those formed with the previous/posterior
lemma/word-form in the context.
Syntactic dependencies: syntactic depen-
dencies were extracted using heuristic patterns,
and regular expressions defined with the PoS
tags around the target2. The following rela-
tions were used: object, subject, noun-modifier,
preposition, and sibling.
Bag-of-words features: we extract the
lemmas of the content words in the whole con-
text, and in a ±4-word window around the tar-
get. We also obtain salient bigrams in the con-
text, with the methods and the software de-
scribed in (Pedersen, 2001).
Domain features: The WordNet Domains
resource was used to identify the most relevant
domains in the context. Following the relevance
formula presented in (Magnini and Cavagli´a,
2000), we defined 2 feature types: (1) the most
relevant domain, and (2) a list of domains above
a predefined threshold3. Other experiments us-
ing domains from SUMO, the EuroWordNet
</bodyText>
<footnote confidence="0.991536">
1The PoS tagging was performed with the fnTBL
toolkit (Ngai and Florian, 2001).
2This software was kindly provided by David
Yarowsky’s group, from Johns Hopkins University.
3The software to obtain the relevant domains was
kindly provided by Gerard Escudero’s group, from Uni-
versitat Politecnica de Catalunya
</footnote>
<bodyText confidence="0.998189333333333">
top-ontology, and WordNet’s Semantic Fields
were performed, but these features were dis-
carded from the final set.
</bodyText>
<subsectionHeader confidence="0.974268">
3.2 Features for Basque
</subsectionHeader>
<bodyText confidence="0.997557428571428">
Basque is an agglutinative language, and syn-
tactic information is given by inflectional suf-
fixes. The morphological analysis of the text is
a necessary previous step in order to select in-
formative features. The data provided by the
task organization includes information about
the lemma, declension case, and PoS for the par-
ticipating systems. Our group used directly the
output of the parser (Aduriz et al., 2000), which
includes some additional features: number, de-
terminer mark, ambiguous analyses and elliptic
words. For a few examples, the morphological
analysis was not available, due to parsing errors.
In Basque, the determiner, the number and
the declension case are appended to the last el-
ement of the phrase. When defining our fea-
ture set for Basque, we tried to introduce the
same knowledge that is represented by features
that work well for English. We will describe
our feature set with an example: for the phrase
”elizaren arduradunei” (which means ”to the
directors of the church”) we get the following
analysis from our analyzer:
eliza|-ren |arduradun|-ei
church |of the |director |to the +pl.
The order of the words is the inverse in En-
glish. We extract the following information for
each word:
</bodyText>
<table confidence="0.976880333333333">
elizaren:
Lemma: eliza (church)
PoS: noun
Declension Case: genitive (of)
Number: singular
Determiner mark: yes
arduradunei:
Lemma: arduradun (director)
PoS: noun
Declension Case: dative (to)
Number: plural
Determiner mark: yes
</table>
<bodyText confidence="0.9998975">
We will assume that eliza (church) is the
target word. Words and lemmas are shown
in lowercase and the other information in up-
percase. As local features we defined different
types of unigrams, bigrams, trigrams and a
window of ±4 words. The unigrams were con-
structed combining word forms, lemmas, case,
number, and determiner mark. We defined 4
</bodyText>
<table confidence="0.8286106">
kinds of unigrams:
Uni wf0 elizaren
Uni wf1 eliza SING+DET
Uni wf2 eliza GENITIVE
Uni wf3 eliza SING+DET GENITIVE
</table>
<bodyText confidence="0.96360123255814">
As for English, we defined bigrams based on
word forms, lemmas and parts-of-speech. But
in order to simulate the bigrams and trigrams
used for English, we defined different kinds of
features. For word forms, we distinguished two
cases: using the text string (Big wf0), or using
the tags from the analysis (Big wf1). The word
form bigrams for the example are shown below.
In the case of the feature type “Big wf1”, the
information is split in three features:
Big wf0 elizaren arduradunei
Big wf1 eliza GENITIVE
Big wf1 GENITIVE arduradun PLUR+DET
Big wf1 arduradun PLUR+DET DATIVE
Similarly, depending on the use of the de-
clension case, we defined three kinds of bigrams
based on lemmas:
Big lem0 eliza arduradun
Big lem1 eliza GENITIVE
Big lem1 GENITIVE arduradun
Big lem1 arduradun DATIVE
Big lem2 eliza GENITIVE
Big lem2 arduradun DATIVE
The bigrams constructed using Part-of-
speech are illustrated below. We included the
declension case as if it was another PoS:
Big pos -1 NOUN GENITIVE
Big pos -1 GENITIVE NOUN
Big pos -1 NOUN DATIVE
Trigrams are built similarly, by combining the
information from three consecutive words. We
also used as local features all the content words
in a window of ±4 words around the target. Fi-
nally, as global features we took all the con-
tent lemmas appearing in the context, which
was constituted by the target sentence and the
two previous and posterior sentences.
One difficult case to model in Basque is the el-
lipsis. For example, the word “elizakoa” means
“the one from the church”. We were able to
extract this information from our analyzer and
we represented it in the features, using a special
symbol in place of the elliptic word.
</bodyText>
<sectionHeader confidence="0.988858" genericHeader="method">
4 Experiments on training data
</sectionHeader>
<bodyText confidence="0.999933083333333">
The algorithms that we applied were first tested
on the Senseval-2 lexical sample task for En-
glish. The best versions were then evaluated by
10 fold cross-validation on the Senseval-3 data,
both for Basque and English. We also used the
training data in cross-validation to tune the pa-
rameters, such as the smoothed frequencies, or
the soft margin for SVM. In this section we will
describe first the parameters of each method
(including the smoothing procedure), and then
the cross-validation results on the Senseval-3
training data.
</bodyText>
<subsectionHeader confidence="0.997985">
4.1 Methods and Parameters
</subsectionHeader>
<bodyText confidence="0.991479472222222">
DL: On Senseval-2 data, we observed that
DL improved significantly its performance with
a smoothing technique based on (Yarowsky,
1995a). For our implementation, the smoothed
probabilities were obtained by grouping the ob-
servations by raw frequencies and feature types.
As this method seems sensitive to the feature
types and the amount of examples, we tested
3 DL versions: DL smooth (using smoothed
probabilities), DL fixed (replacing 0 counts with
0.1), and DL discard (discarding features ap-
pearing with only one sense).
NB: We applied a simple smoothing method
presented in (Ng, 1997), where zero counts are
replaced by the probability of the given sense
divided by the number of examples.
V: The same smoothing method used for NB
was applied for vectors. For Basque, two ver-
sions were tested: as the Basque parser can re-
turn ambiguous analyses, partial weights are as-
signed to the features in the context, and we can
chose to use these partial weights (p), or assign
the full weight to all features (f).
SVM: No smoothing was applied. We esti-
mated the soft margin using a greedy process in
cross-validation on the training data per each
word.
Combination: Single voting was used,
where each system voted for its best ranked
sense, and the most voted sense was chosen.
More sophisticate schemes like ranked voting,
were tried on Senseval-2 data, but the results
did not improve. We tested combinations of
the 4 algorithms, leaving one out, and the two
best. The best results were obtained combining
3 methods (leave one out).
</bodyText>
<table confidence="0.9994215">
Method Recall
vector 73,9
SVM 73,5
DL smooth 69,4
NB 69,4
DL fixed 65,6
DL discard 65,4
MFS 57,1
</table>
<tableCaption confidence="0.9946465">
Table 1: Single systems (English) in cross-
validation, sorted by recall.
</tableCaption>
<table confidence="0.999833333333333">
Combination Recall
SVM-vector-DL smooth-NB 73,2
SVM-vector-DL fixed-NB 72,7
SVM-vector-DL smooth 74,0
SVM-vector-DL fixed 73,8
SVM-vector-NB 73,6
SVM-DL smooth-NB 72,4
SVM-DL fixed-NB 71,3
SVM-vector 73,1
</table>
<tableCaption confidence="0.9965575">
Table 2: Combined systems (English) in cross-
validation, best recall in bold.
</tableCaption>
<table confidence="0.999816444444444">
Method Recall
SVM 71,1
NB 68,5
vector(f) 66,8
DL smooth 65,9
DL fixed 65,2
vector(p) 65,0
DL discard 60,7
MFS 53,0
</table>
<tableCaption confidence="0.993352">
Table 3: Single systems (Basque) in cross-
validation, sorted by recall.
</tableCaption>
<table confidence="0.9998259">
Combination Recall
SVM-vector-DL smooth-NB 70,6
SVM-vector-DL fixed-NB 71,1
SVM-vector-DL smooth 70,6
SVM-vector-DL fixed 70,8
SVM-vector-NB 71,1
SVM-DL smooth-NB 70,2
SVM-DL fixed-NB 70,5
SVM-vector 69,0
SVM-NB 69,8
</table>
<tableCaption confidence="0.996357666666667">
Table 4: Combined systems (Basque) in cross-
validation, best recall in bold. Only vector(f)
was used for combination.
</tableCaption>
<subsectionHeader confidence="0.97259">
4.2 Results on English Training Data
</subsectionHeader>
<bodyText confidence="0.999951764705883">
The results using cross-validation on the
Senseval-3 data are shown in Table 1 for single
systems, and in Table 2 for combined methods.
All the algorithms have full-coverage (for En-
glish and Basque), therefore the recall and the
precision are the same. The most frequent sense
(MFS) baseline is also provided, and it is easily
beaten by all the algorithms.
We have to note that these figures are consis-
tent with the performance we observed in the
Senseval-2 data, where the vector method is
the best performing single system, and the best
combination is SVM-vector-DL smooth. There
is a small gain when combining 3 systems, which
we expected would be higher. We submitted the
best single system, and the best combination for
this task.
</bodyText>
<subsectionHeader confidence="0.980269">
4.3 Results on Basque Training Data
</subsectionHeader>
<bodyText confidence="0.999854055555556">
The performance on the Senseval-3 Basque
training data is given in Table 1 for single sys-
tems, and in Table 2 for combined methods. In
this case, the vector method, and DL smooth
obtain lower performance in relation to other
methods. This can be due to the type of fea-
tures used, which have not been tested as ex-
tensively as for English. In fact, it could hap-
pen that some features contribute mostly noise.
Also, the domain tag of the examples, which
could provide useful information, was not used.
There is no improvement when combining dif-
ferent systems, and the result of the combina-
tion of 4 systems is unusually high in relation
to the English experiments. We also submit-
ted two systems for this task: the best single
method in cross-validation (SVM), and the best
3-method combination (SVM-vector-NB).
</bodyText>
<sectionHeader confidence="0.99973" genericHeader="evaluation">
5 Results and Conclusions
</sectionHeader>
<bodyText confidence="0.999975357142857">
Table 5 shows the performance obtained by our
systems and the winning system in the Senseval-
3 evaluation. We can see that we are very close
to the best algorithms in both languages.
The recall of our systems is 1.2%-1.9% lower
than cross-validation for every system and task,
which is not surprising when we change the set-
ting. The combination of methods is useful for
English, where we improve the recall in 0.3%,
reaching 72.3%. The difference is statistically
significant according to McNemar’s test.
However, the combination of methods does
not improve the results in the the Basque task,
where the SVM method alone provides better
</bodyText>
<table confidence="0.999005">
Task Code Method Rec.
Eng. Senseval-3 Best ? 72,9
Eng. BCU comb SVM-vector- 72,3
DL smooth
Eng. BCU-english vector 72,0
Basq. Senseval-3 Best ? 70,4
Basq. BCU-basque SVM 69,9
Basq. BCU-Basque comb SVM-vector- 69,5
NB
</table>
<tableCaption confidence="0.9452685">
Table 5: Official results for the English and
Basque lexical tasks (recall).
</tableCaption>
<bodyText confidence="0.998474466666667">
results (69.9% recall). In this case the difference
is not significant applying McNemar’s test.
Our disambiguation procedure shows a sim-
ilar behavior on the Senseval-2 and Senseval-3
data for English (both in cross-validation and
in the testing part), where the ensemble works
best, followed by the vector model. This did
not apply to the Basque dataset, where some
algorithms seem to perform below the expecta-
tions. For future work, we plan to study better
the Basque feature set and include new features,
such as domain tags.
Overall, the ensemble of algorithms provides
a more robust system for WSD, and is able to
achieve state-of-the-art performance.
</bodyText>
<sectionHeader confidence="0.999431" genericHeader="conclusions">
6 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999552142857143">
We wish to thank both David Yarowsky’s group,
from Johns Hopkins University, and Gerard Es-
cudero’s group, from Universitat Politecnica de
Catalunya, for providing us software for the ac-
quisition of features. This research has been
partially funded by the European Commission
(MEANING IST-2001-34460).
</bodyText>
<sectionHeader confidence="0.999271" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999749857142857">
I. Aduriz, E. Agirre, I. Aldezabal, I. Alegria,
X. Arregi, J. Arriola, X. Artola, K. Gojenola,
A. Maritxalar, K. Sarasola, and M. Urkia.
2000. A word-grammar based morphological
analyzer for agglutinative languages. In Pro-
ceedings of the International Conference on
Computational Linguistics COLING, Saar-
brucken, Germany.
Eneko Agirre and David Martinez. 2004.
Smoothing and word sense disambiguation.
(submitted).
T. Joachims. 1999. Making large–scale SVM
learning practical. In Advances in Kernel
Methods — Support Vector Learning, pages
169–184, Cambridge, MA. MIT Press.
Bernardo Magnini and Gabriela Cavagli´a. 2000.
Integrating subject field codes into WordNet.
In Proceedings of the Second International
LREC Conference, Athens, Greece.
Hwee Tou Ng. 1997. Exemplar-based word
sense disambiguation: Some recent improve-
ments. In Proceedings of the Second EMNLP
Conference. ACL, Somerset, New Jersey.
Grace Ngai and Radu Florian. 2001.
Transformation-based learning in the fast
lane. Proceedings of the Second Conference
of the NAACL, Pittsburgh, PA, USA.
Ted Pedersen. 2001. A decision tree of bi-
grams is an accurate predictor of word sense.
Proceedings of the Second Meeting of the
NAACL, Pittsburgh, PA.
David Yarowsky. 1995a. Three machine learn-
ing algorithms for lexical ambiguity resolu-
tion. In PhD thesis, Department of Com-
puter and Information Sciences, University of
Pennsylvania.
David Yarowsky. 1995b. Unsupervised word
sense disambiguation rivaling supervised
methods. In Proceedings of the 33rd An-
nual Meeting of the Association for Compu-
tational Linguistics (ACL), pages 189–196,
Cambridge, MA.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.549161">
<title confidence="0.999492">The Basque Country University system: English and Basque tasks</title>
<author confidence="0.901579">Eneko</author>
<affiliation confidence="0.961219">IXA NLP Group Basque Country</affiliation>
<address confidence="0.790525">Donostia,</address>
<email confidence="0.952151">eneko@si.ehu.es</email>
<author confidence="0.998561">David Martinez</author>
<affiliation confidence="0.9994005">IXA NLP Group Basque Country University</affiliation>
<address confidence="0.994342">Donostia,</address>
<email confidence="0.99761">davidm@si.ehu.es</email>
<abstract confidence="0.989348166666667">Our group participated in the Basque and English lexical sample tasks in Senseval-3. A language-specific feature set was defined for Basque. Four different learning algorithms were applied, and also a method that combined their outputs. Before submission, the performance of the methods was tested for each task on the Senseval-3 training data using cross validation. Finally, two systems were submitted for each language: the best single algorithm and the best ensemble.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>I Aduriz</author>
<author>E Agirre</author>
<author>I Aldezabal</author>
<author>I Alegria</author>
<author>X Arregi</author>
<author>J Arriola</author>
<author>X Artola</author>
<author>K Gojenola</author>
<author>A Maritxalar</author>
<author>K Sarasola</author>
<author>M Urkia</author>
</authors>
<title>A word-grammar based morphological analyzer for agglutinative languages.</title>
<date>2000</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics COLING, Saarbrucken,</booktitle>
<location>Germany.</location>
<contexts>
<context position="1969" citStr="Aduriz et al., 2000" startWordPosition="294" endWordPosition="297">in cross-validation. The main difference between the Basque and English systems was the feature set. A rich set of features was used for English, including syntactic dependencies and domain information, extracted with different tools, and also from external resources like WordNet Domains (Magnini and Cavagli´a, 2000). The features for Basque were different, as Basque is an agglutinative language, and syntactic information is given by inflectional suffixes. We tried to represent this information in local features, relying on the analysis of a deep morphological analyzer developed in our group (Aduriz et al., 2000). In order to improve the performance of the algorithms, different smoothing techniques were tested on the English Senseval-2 lexical sample data (Agirre and Martinez, 2004), and applied to Senseval-3. These methods helped to obtain better estimations for the features, and to avoid the problem of 0 counts Decision Lists and Naive Bayes. This paper is organized as follows. The learning algorithms are first introduced in Section 2, and Section 3 describes the features applied to each task. In Section 4, we present the experiments performed on training data before submission; this section also co</context>
<context position="6551" citStr="Aduriz et al., 2000" startWordPosition="1029" endWordPosition="1032"> Gerard Escudero’s group, from Universitat Politecnica de Catalunya top-ontology, and WordNet’s Semantic Fields were performed, but these features were discarded from the final set. 3.2 Features for Basque Basque is an agglutinative language, and syntactic information is given by inflectional suffixes. The morphological analysis of the text is a necessary previous step in order to select informative features. The data provided by the task organization includes information about the lemma, declension case, and PoS for the participating systems. Our group used directly the output of the parser (Aduriz et al., 2000), which includes some additional features: number, determiner mark, ambiguous analyses and elliptic words. For a few examples, the morphological analysis was not available, due to parsing errors. In Basque, the determiner, the number and the declension case are appended to the last element of the phrase. When defining our feature set for Basque, we tried to introduce the same knowledge that is represented by features that work well for English. We will describe our feature set with an example: for the phrase ”elizaren arduradunei” (which means ”to the directors of the church”) we get the follo</context>
</contexts>
<marker>Aduriz, Agirre, Aldezabal, Alegria, Arregi, Arriola, Artola, Gojenola, Maritxalar, Sarasola, Urkia, 2000</marker>
<rawString>I. Aduriz, E. Agirre, I. Aldezabal, I. Alegria, X. Arregi, J. Arriola, X. Artola, K. Gojenola, A. Maritxalar, K. Sarasola, and M. Urkia. 2000. A word-grammar based morphological analyzer for agglutinative languages. In Proceedings of the International Conference on Computational Linguistics COLING, Saarbrucken, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eneko Agirre</author>
<author>David Martinez</author>
</authors>
<title>Smoothing and word sense disambiguation.</title>
<date>2004</date>
<note>(submitted).</note>
<contexts>
<context position="2142" citStr="Agirre and Martinez, 2004" startWordPosition="321" endWordPosition="324">ependencies and domain information, extracted with different tools, and also from external resources like WordNet Domains (Magnini and Cavagli´a, 2000). The features for Basque were different, as Basque is an agglutinative language, and syntactic information is given by inflectional suffixes. We tried to represent this information in local features, relying on the analysis of a deep morphological analyzer developed in our group (Aduriz et al., 2000). In order to improve the performance of the algorithms, different smoothing techniques were tested on the English Senseval-2 lexical sample data (Agirre and Martinez, 2004), and applied to Senseval-3. These methods helped to obtain better estimations for the features, and to avoid the problem of 0 counts Decision Lists and Naive Bayes. This paper is organized as follows. The learning algorithms are first introduced in Section 2, and Section 3 describes the features applied to each task. In Section 4, we present the experiments performed on training data before submission; this section also covers the final configuration of each algorithm, and the performance obtained on training data. Finally, the official results in Senseval-3 are presented and discussed in Sec</context>
</contexts>
<marker>Agirre, Martinez, 2004</marker>
<rawString>Eneko Agirre and David Martinez. 2004. Smoothing and word sense disambiguation. (submitted).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Joachims</author>
</authors>
<title>Making large–scale SVM learning practical.</title>
<date>1999</date>
<booktitle>In Advances in Kernel Methods — Support Vector Learning,</booktitle>
<pages>169--184</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="4260" citStr="Joachims, 1999" startWordPosition="671" endWordPosition="672">he Evaluation of Systems for the Semantic Analysis of Text, Barcelona, Spain, July 2004 Association for Computational Linguistics value to indicate the occurrence/absence of the feature. For each sense in training, one centroid vector is obtained. These centroids are compared with the vectors that represent testing examples, by means of the cosine similarity function. The closest centroid is used to assign its sense to the testing example. No smoothing is required to apply this algorithm, but it is possible to use smoothed values. Regarding Support Vector Machines (SVM) we utilized SVM-Light (Joachims, 1999), a public distribution of SVM. Linear kernels were applied, and the soft margin (C) was estimated per each word (cf. Section 4). 3 Features 3.1 Features for English We relied on an extensive set of features of different types, obtained by means of different tools and resources. The features used can be grouped in four groups: Local collocations: bigrams and trigrams formed with the words around the target. These features are constituted with lemmas, wordforms, or PoS tags1. Other local features are those formed with the previous/posterior lemma/word-form in the context. Syntactic dependencies</context>
</contexts>
<marker>Joachims, 1999</marker>
<rawString>T. Joachims. 1999. Making large–scale SVM learning practical. In Advances in Kernel Methods — Support Vector Learning, pages 169–184, Cambridge, MA. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernardo Magnini</author>
<author>Gabriela Cavagli´a</author>
</authors>
<title>Integrating subject field codes into WordNet.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second International LREC Conference,</booktitle>
<location>Athens, Greece.</location>
<marker>Magnini, Cavagli´a, 2000</marker>
<rawString>Bernardo Magnini and Gabriela Cavagli´a. 2000. Integrating subject field codes into WordNet. In Proceedings of the Second International LREC Conference, Athens, Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
</authors>
<title>Exemplar-based word sense disambiguation: Some recent improvements.</title>
<date>1997</date>
<booktitle>In Proceedings of the Second EMNLP Conference. ACL,</booktitle>
<location>Somerset, New Jersey.</location>
<contexts>
<context position="10888" citStr="Ng, 1997" startWordPosition="1741" endWordPosition="1742">hods and Parameters DL: On Senseval-2 data, we observed that DL improved significantly its performance with a smoothing technique based on (Yarowsky, 1995a). For our implementation, the smoothed probabilities were obtained by grouping the observations by raw frequencies and feature types. As this method seems sensitive to the feature types and the amount of examples, we tested 3 DL versions: DL smooth (using smoothed probabilities), DL fixed (replacing 0 counts with 0.1), and DL discard (discarding features appearing with only one sense). NB: We applied a simple smoothing method presented in (Ng, 1997), where zero counts are replaced by the probability of the given sense divided by the number of examples. V: The same smoothing method used for NB was applied for vectors. For Basque, two versions were tested: as the Basque parser can return ambiguous analyses, partial weights are assigned to the features in the context, and we can chose to use these partial weights (p), or assign the full weight to all features (f). SVM: No smoothing was applied. We estimated the soft margin using a greedy process in cross-validation on the training data per each word. Combination: Single voting was used, whe</context>
</contexts>
<marker>Ng, 1997</marker>
<rawString>Hwee Tou Ng. 1997. Exemplar-based word sense disambiguation: Some recent improvements. In Proceedings of the Second EMNLP Conference. ACL, Somerset, New Jersey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grace Ngai</author>
<author>Radu Florian</author>
</authors>
<title>Transformation-based learning in the fast lane.</title>
<date>2001</date>
<booktitle>Proceedings of the Second Conference of the NAACL,</booktitle>
<location>Pittsburgh, PA, USA.</location>
<contexts>
<context position="5769" citStr="Ngai and Florian, 2001" startWordPosition="908" endWordPosition="911">nt words in the whole context, and in a ±4-word window around the target. We also obtain salient bigrams in the context, with the methods and the software described in (Pedersen, 2001). Domain features: The WordNet Domains resource was used to identify the most relevant domains in the context. Following the relevance formula presented in (Magnini and Cavagli´a, 2000), we defined 2 feature types: (1) the most relevant domain, and (2) a list of domains above a predefined threshold3. Other experiments using domains from SUMO, the EuroWordNet 1The PoS tagging was performed with the fnTBL toolkit (Ngai and Florian, 2001). 2This software was kindly provided by David Yarowsky’s group, from Johns Hopkins University. 3The software to obtain the relevant domains was kindly provided by Gerard Escudero’s group, from Universitat Politecnica de Catalunya top-ontology, and WordNet’s Semantic Fields were performed, but these features were discarded from the final set. 3.2 Features for Basque Basque is an agglutinative language, and syntactic information is given by inflectional suffixes. The morphological analysis of the text is a necessary previous step in order to select informative features. The data provided by the </context>
</contexts>
<marker>Ngai, Florian, 2001</marker>
<rawString>Grace Ngai and Radu Florian. 2001. Transformation-based learning in the fast lane. Proceedings of the Second Conference of the NAACL, Pittsburgh, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Pedersen</author>
</authors>
<title>A decision tree of bigrams is an accurate predictor of word sense.</title>
<date>2001</date>
<booktitle>Proceedings of the Second Meeting of the NAACL,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="5330" citStr="Pedersen, 2001" startWordPosition="841" endWordPosition="842">wordforms, or PoS tags1. Other local features are those formed with the previous/posterior lemma/word-form in the context. Syntactic dependencies: syntactic dependencies were extracted using heuristic patterns, and regular expressions defined with the PoS tags around the target2. The following relations were used: object, subject, noun-modifier, preposition, and sibling. Bag-of-words features: we extract the lemmas of the content words in the whole context, and in a ±4-word window around the target. We also obtain salient bigrams in the context, with the methods and the software described in (Pedersen, 2001). Domain features: The WordNet Domains resource was used to identify the most relevant domains in the context. Following the relevance formula presented in (Magnini and Cavagli´a, 2000), we defined 2 feature types: (1) the most relevant domain, and (2) a list of domains above a predefined threshold3. Other experiments using domains from SUMO, the EuroWordNet 1The PoS tagging was performed with the fnTBL toolkit (Ngai and Florian, 2001). 2This software was kindly provided by David Yarowsky’s group, from Johns Hopkins University. 3The software to obtain the relevant domains was kindly provided b</context>
</contexts>
<marker>Pedersen, 2001</marker>
<rawString>Ted Pedersen. 2001. A decision tree of bigrams is an accurate predictor of word sense. Proceedings of the Second Meeting of the NAACL, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Three machine learning algorithms for lexical ambiguity resolution. In</title>
<date>1995</date>
<tech>PhD thesis,</tech>
<institution>Department of Computer and Information Sciences, University of Pennsylvania.</institution>
<contexts>
<context position="2965" citStr="Yarowsky, 1995" startWordPosition="458" endWordPosition="459">rning algorithms are first introduced in Section 2, and Section 3 describes the features applied to each task. In Section 4, we present the experiments performed on training data before submission; this section also covers the final configuration of each algorithm, and the performance obtained on training data. Finally, the official results in Senseval-3 are presented and discussed in Section 5. 2 Learning Algorithms The algorithms presented in this section rely on features extracted from the context of the target word to make their decisions. The Decision List (DL) algorithm is described in (Yarowsky, 1995b). In this algorithm the sense with the highest weighted feature is selected, as shown below. We can avoid undetermined values by discarding features that have a 0 probability in the divisor. More sophisticated smoothing techniques have also been tried (cf. Section 4). w(sk, fi) = log( Pr(skIfi) ) Ej=,4k Pr(sj |fi) The Naive Bayes (NB) algorithm is based on the conditional probability of each sense given the features in the context. It also requires smoothing. P(sk) M11 P(fi|sk) For the Vector Space Model (V) algorithm, we represent each occurrence context as a vector, where each feature will</context>
<context position="10433" citStr="Yarowsky, 1995" startWordPosition="1669" endWordPosition="1670">e task for English. The best versions were then evaluated by 10 fold cross-validation on the Senseval-3 data, both for Basque and English. We also used the training data in cross-validation to tune the parameters, such as the smoothed frequencies, or the soft margin for SVM. In this section we will describe first the parameters of each method (including the smoothing procedure), and then the cross-validation results on the Senseval-3 training data. 4.1 Methods and Parameters DL: On Senseval-2 data, we observed that DL improved significantly its performance with a smoothing technique based on (Yarowsky, 1995a). For our implementation, the smoothed probabilities were obtained by grouping the observations by raw frequencies and feature types. As this method seems sensitive to the feature types and the amount of examples, we tested 3 DL versions: DL smooth (using smoothed probabilities), DL fixed (replacing 0 counts with 0.1), and DL discard (discarding features appearing with only one sense). NB: We applied a simple smoothing method presented in (Ng, 1997), where zero counts are replaced by the probability of the given sense divided by the number of examples. V: The same smoothing method used for N</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995a. Three machine learning algorithms for lexical ambiguity resolution. In PhD thesis, Department of Computer and Information Sciences, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<pages>189--196</pages>
<location>Cambridge, MA.</location>
<contexts>
<context position="2965" citStr="Yarowsky, 1995" startWordPosition="458" endWordPosition="459">rning algorithms are first introduced in Section 2, and Section 3 describes the features applied to each task. In Section 4, we present the experiments performed on training data before submission; this section also covers the final configuration of each algorithm, and the performance obtained on training data. Finally, the official results in Senseval-3 are presented and discussed in Section 5. 2 Learning Algorithms The algorithms presented in this section rely on features extracted from the context of the target word to make their decisions. The Decision List (DL) algorithm is described in (Yarowsky, 1995b). In this algorithm the sense with the highest weighted feature is selected, as shown below. We can avoid undetermined values by discarding features that have a 0 probability in the divisor. More sophisticated smoothing techniques have also been tried (cf. Section 4). w(sk, fi) = log( Pr(skIfi) ) Ej=,4k Pr(sj |fi) The Naive Bayes (NB) algorithm is based on the conditional probability of each sense given the features in the context. It also requires smoothing. P(sk) M11 P(fi|sk) For the Vector Space Model (V) algorithm, we represent each occurrence context as a vector, where each feature will</context>
<context position="10433" citStr="Yarowsky, 1995" startWordPosition="1669" endWordPosition="1670">e task for English. The best versions were then evaluated by 10 fold cross-validation on the Senseval-3 data, both for Basque and English. We also used the training data in cross-validation to tune the parameters, such as the smoothed frequencies, or the soft margin for SVM. In this section we will describe first the parameters of each method (including the smoothing procedure), and then the cross-validation results on the Senseval-3 training data. 4.1 Methods and Parameters DL: On Senseval-2 data, we observed that DL improved significantly its performance with a smoothing technique based on (Yarowsky, 1995a). For our implementation, the smoothed probabilities were obtained by grouping the observations by raw frequencies and feature types. As this method seems sensitive to the feature types and the amount of examples, we tested 3 DL versions: DL smooth (using smoothed probabilities), DL fixed (replacing 0 counts with 0.1), and DL discard (discarding features appearing with only one sense). NB: We applied a simple smoothing method presented in (Ng, 1997), where zero counts are replaced by the probability of the given sense divided by the number of examples. V: The same smoothing method used for N</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>David Yarowsky. 1995b. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the 33rd Annual Meeting of the Association for Computational Linguistics (ACL), pages 189–196, Cambridge, MA.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>