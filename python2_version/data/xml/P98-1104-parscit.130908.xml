<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001312">
<title confidence="0.990385">
A Statistical Analysis of Morphemes in Japanese Terminology
</title>
<author confidence="0.875223">
Kyo KAGEURA
</author>
<affiliation confidence="0.91144">
National Center for Science Information Systems
</affiliation>
<address confidence="0.862919">
3-29-1 Otsuka, Bunkyo-ku, Tokyo, 112-8640 Japan
</address>
<email confidence="0.999854">
E-Mail: kyo@rd.nacsis.acjp
</email>
<sectionHeader confidence="0.994035" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9966606">
In this paper I will report the result of a quan-
titative analysis of the dynamics of the con-
stituent elements of Japanese terminology. In
Japanese technical terms, the linguistic contri-
bution of morphemes greatly differ according to
their types of origin. To analyse this aspect, a
quantitative method is applied, which can prop-
erly characterise the dynamic nature of mor-
phemes in terminology on the basis of a small
sample.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999907677419355">
In computational linguistics, the interest in ter-
minological applications such as automatic term
extraction is growing, and many studies use
the quantitative information (cf. Kageura &amp;
Umino, 1996). However, the basic quantita-
tive nature of terminological structure, which
is essential for terminological theory and appli-
cations, has not yet been exploited. The static
quantitative descriptions are not sufficient, as
there are terms which do not appear in the sam-
ple. So it is crucial to establish some models, by
which the terminological structure beyond the
sample size can be properly described.
In Japanese terminology, the roles of mor-
phemes are different according to their types
of origin, i.e. the morphemes borrowed mainly
from Western languages (borrowed morphemes)
and the native morphemes including Chinese-
origined morphemes which are the majority.
There are some quantitative studies (Ishii, 1987;
Nomura &amp; Ishii, 1989), but they only treat the
static nature of the sample.
Located in the intersection of these two
backgrounds, the aim of the present study is
twofold, i.e. (1) to introduce a quantitative
framework in which the dynamic nature of ter-
minology can be described, and to examine
its theoretical validity, and (2) to describe the
quantitative dynamics of morphemes as a &apos;mass&apos;
in Japanese terminology, with reference to the
types of origin.
</bodyText>
<sectionHeader confidence="0.995451" genericHeader="method">
2 Terminological Data
</sectionHeader>
<subsectionHeader confidence="0.966682">
2.1 The Data
</subsectionHeader>
<bodyText confidence="0.999766931034483">
We use a list of different terms as a sample,
and observe the quantitative nature of the con-
stituent elements or morphemes. The quantita-
tive regularities is expected to be observed at
this level, because a large portion of terms is
complex (Nomura Sz Ishii, 1989), whose forma-
tion is systematic (Sager, 1990), and the quan-
titative nature of morphemes in terminology is
independent of the token frequency of terms, be-
cause the term formation is a lexical formation.
With the correspondences between text and
terminology, sentences and terms, and words
and morphemes, the present work can be re-
garded as parallel to the quantitative study of
words in texts (Baayen, 1991; Baayen, 1993;
Mandelbrot, 1962; Simon, 1955; Yule, 1944;
Zipf, 1935). Such terms as &apos;type&apos;, &apos;token&apos;, &apos;vo-
cabulary&apos;, etc. will be used in this context.
Two Japanese terminological data are used
in this study: computer science (CS: Aiso, 1993)
and psychology (PS: Japanese Ministry of Ed-
ucation, 1986). The basic quantitative data are
given in Table 1, where T, N, and V(N) in-
dicate the number of terms, of running mor-
phemes (tokens), and of different morphemes
(types), respectively.
In computer science, the frequencies of the
borrowed and the native morphemes are not
very different. In psychology, the borrowed
</bodyText>
<page confidence="0.997762">
638
</page>
<table confidence="0.999760857142857">
Domain V(N) N/T N/V(N) I Cf. 1
CS all 14983 36640 5176 2.45 7.08 0.211
borrowed 14696 2809 5.23 0.242
native 21944 2367 9.27 0.174
PS all 6272 14314 3594 2.28 3.98 0.235
borrowed 1641 995 1.55 0.309
native 12773 2599 4.91 0.207
</table>
<tableCaption confidence="0.999772">
Table 1. Basic Figures of the Terminological Data
</tableCaption>
<bodyText confidence="0.9954974">
morphemes constitute only slightly more than
10% of the tokens. The mean frequency
NIV(N) of the borrowed morphemes is much
lower than the native morphemes in both do-
mains.
</bodyText>
<subsectionHeader confidence="0.998929">
2.2 LNRE Nature of the Data
</subsectionHeader>
<bodyText confidence="0.9996665">
The LNRE (Large Number of Rare Events)
zone (Chitashvili &amp; Baayen, 1993) is defined as
the range of sample size where the population
events (different morphemes) are far from being
exhausted. This is shown by the fact that the
numbers of hapax legomena and of dislegomena
are increasing (see Figure 1 for hapax).
A convenient test to see if the sample is lo-
cated in the LNRE zone is to see the ratio of
loss of the number of morpheme types, calcu-
lated by the sample relative frequencies as the
estimates of population probabilities. Assuming
the binomial model, the ratio of loss is obtained
by:
</bodyText>
<equation confidence="0.925246727272727">
CL = (V(N) — (N)])/V(N)
En-,&gt;1 v(m, N)(1 - P(i[f(z,N).,.], N))N
V(N)
where:
f (i, N) : frequency of a morpheme w, in a sample
of N.
p(i, N) = f (i, N)I N : sample relative frequency.
m : frequency class or a number of occurrence.
V(m, N) : the number of morpheme types occur-
ring m times (spectrum elements) in a sample
of N.
</equation>
<bodyText confidence="0.99845225">
In the two data, we underestimate the number
of morpheme types by more than 20% (CI, in
Table 1), which indicates that they are clearly
located in the LNRE zone.
</bodyText>
<sectionHeader confidence="0.99122" genericHeader="method">
3 The LNRE Framework
</sectionHeader>
<bodyText confidence="0.9999565">
When a sample is located in the LNRE zone,
values of statistical measures such as type-token
ratio, the parameters of &apos;laws&apos; (e.g. of Mandel-
brot, 1962) of word frequency distributions, etc.
change systematically according to the sample
size, due to the unobserved events. To treat
LNRE samples, therefore, the factor of sample
size should be taken into consideration.
Good (1953) gives a method of re-estimating
the population probabilities of the types in the
sample as well as estimating the probability
mass of unseen types. There is also work on
the estimation of the theoretical vocabulary size
(Efron &amp; Thisted, 1976; National Language Re-
search Institute, 1958; Tuldava, 1980). How-
ever, they do not give means to estimate such
values as V(N), V(m, N) for arbitrary sample
size, which are what we need. The LNRE frame-
work (Chitashvili &amp; Baayen, 1993) offers the
means suitable for the present study.
</bodyText>
<subsectionHeader confidence="0.990381">
3.1 Binomial/Poisson Assumption
</subsectionHeader>
<bodyText confidence="0.992032875">
Assume that there are S different morphemes
wi, i = 1,2, ...S, in the terminological pop-
ulation, with a probability pi associated with
each of them. Assuming the binomial distribu-
tion and its Poisson approximation, we can ex-
press the expected numbers of morphemes and
of spectrum elements in a given sample of size
N as follows:
</bodyText>
<equation confidence="0.9997536">
E[V(N)1 = S — E(1 — p2)N = E(1 (1)
,=1
E[V(m,N)1 = E (N)p,ino. poN,
E(Npi)me-NPilm!. (2)
i=1
</equation>
<bodyText confidence="0.999921">
As our data is in the LNRE zone, we cannot
estimate pi. Good (1953) and Good Sz Toulmin
(1956) introduced the method of interpolating
and extrapolating the number of types for ar-
bitrary sample size, but it cannot be used for
extrapolating to a very large size.
</bodyText>
<subsectionHeader confidence="0.99871">
3.2 The LNRE Models
</subsectionHeader>
<bodyText confidence="0.998588333333334">
Assume that the distribution of grouped proba-
bility p follows a distribution &apos;law&apos;, which can be
expressed by some structural type distribution
</bodyText>
<listItem confidence="0.931558">
G(p) = &gt; where I = 1 when pi p
and 0 otherwise. Using G(p), the expressions
(1) and (2) can be re-expressed as follows:
</listItem>
<equation confidence="0.93242625">
E[V (N)] = (1 — e-NP) dG(p). (3)
639
00
E[V(m,N)]= 0 (Np)me-NP Im! dG(p). (4)
</equation>
<bodyText confidence="0.998448210526316">
where dG(p) = G(pi) - G(pi+i) around pi, and
0 otherwise, in which p is now grouped for the
same value and indexed by the subscript j that
indicates in ascending order the values of p.
In using some explicit expressions such as
lognormal &apos;law&apos; (Carrol, 1967) for G(p), we
again face the problem of sample size depen-
dency of the parameters of these &apos;laws&apos;. To over-
come the problem, a certain distribution model
for the population is assumed, which manifests
itself as one of the &apos;laws&apos; at a pivotal sample size
Z. By explicitly incorporating Z as a parame-
ter, the models can be completed, and it be-
comes possible (i) to represent the distribution
of population probabilities by means of G(p)
with Z and to estimate the theoretical vocabu-
lary size, and (ii) to interpolate and extrapolate
V (N) and V (m, N) to the arbitrary sample size
N, by such an expression:
</bodyText>
<equation confidence="0.967975">
E[V(m,N)]= (-(ZP))m) 4 z e- dG(p)
m!
</equation>
<bodyText confidence="0.999831272727273">
The parameters of the model, i.e. the orig-
inal parameters of the &apos;laws&apos; of word frequency
distributions and the pivotal sample size Z, are
estimated by looking for the values that most
properly describe the distributions of spectrum
elements and the vocabulary size at the given
sample size. In this study, four LNRE mod-
els were tried, which incorporate the lognormal
&apos;law&apos; (Carrol, 1967), the inverse Gauss-Poisson
&apos;law&apos; (Sichel, 1986), Zipf&apos;s &apos;law&apos; (Zipf, 1935) and
Yule-Simon &apos;law&apos; (Simon, 1955).
</bodyText>
<sectionHeader confidence="0.935909" genericHeader="method">
4 Analysis of Terminology
</sectionHeader>
<subsectionHeader confidence="0.999653">
4.1 Random Permutation
</subsectionHeader>
<bodyText confidence="0.999972230769231">
Unlike texts, the order of terms in a given ter-
minological sample is basically arbitrary. Thus
term-level random permutation can be used to
obtain the better descriptions of sub-samples.
In the following, we use the results of 1000 term-
level random permutations for the empirical de-
scriptions of sub-samples.
In fact, the results of the term-level and
morpheme-level permutations almost coincide,
with no statistically significant difference. From
this we can conclude that the binomial/Poisson
assumption of the LNRE models in the previous
section holds for the terminological data.
</bodyText>
<subsectionHeader confidence="0.995085">
4.2 Quantitative Measures
</subsectionHeader>
<bodyText confidence="0.998873333333333">
Two measures are used for observing the dy-
namics of morphemes in terminology. The first
is the mean frequency of morphemes:
</bodyText>
<equation confidence="0.996346">
X(V(N)) - (5)
V(N)
</equation>
<bodyText confidence="0.999993928571429">
The repeated occurrence of a morpheme indi-
cates that it is used as a constituent element of
terms, as the samples consist of term types. As
it is not likely that the same morpheme occurs
twice in a term, the mean frequency indicates
the average number of terms which is connected
by a common morpheme.
A more important measure is the growth
rate, P(N). If we observe E[V(N)] for changing
N, we obtain the growth curve of the morpheme
types. The slope of the growth curve gives the
growth rate. By taking the first derivate of
E[V(N)] given by equation (3), therefore, we
obtain the growth rate of the morpheme types:
</bodyText>
<equation confidence="0.997845666666667">
P(N)= —dE[V(N)1= ERV(1,N)]
(6)
dN
</equation>
<bodyText confidence="0.991871">
This &amp;quot;expresses in a very real sense the proba-
bility that new types will be encountered when
the ... sample is increased&amp;quot; (Baayen, 1991).
For convenience, we introduce the notation
for the complement of P(N), the reuse ratio:
</bodyText>
<equation confidence="0.985911">
R(N) =1- P(N) (7)
</equation>
<bodyText confidence="0.999900285714286">
which expresses the probability that the existing
types will be encountered.
For each type of morpheme, there are two
ways of calculating P(N). The first is on the
basis of the total number of the running mor-
phemes (frame sample). For the borrowed mor-
phemes, for instance, it is defined as:
</bodyText>
<equation confidence="0.98569">
Pfb(N) = E[liorrowed(1, NA I N
</equation>
<bodyText confidence="0.999220666666667">
The second is on the basis of the number of
running morphemes of each type (item sample).
For instance, for the borrowed morphemes:
</bodyText>
<equation confidence="0.890508">
Pb(N) = E[Vborrowed(1, N)]! Nborroured
</equation>
<bodyText confidence="0.999897555555556">
Correspondingly, the reuse ratio R(N) is also
defined in two ways.
Pi reflects the growth rate of the morphemes
of each type observed separately. Each of them
expresses the probability of encountering a new
morpheme for the separate sample consisting of
the morphemes of the same type, and does not
in itself indicate any characteristics in the frame
sample.
</bodyText>
<page confidence="0.988903">
640
</page>
<bodyText confidence="0.999911">
On the other hand, Pf and Rf express the
quantitative status of the morphemes of each
type as a mass in terminology. So the transi-
tions of P1 and Rf, with changing N, express
the changes of the status of the morphemes of
each type in the terminology. In terminology,
P1 can be interpreted as the probability of in-
corporating new conceptual elements.
</bodyText>
<subsectionHeader confidence="0.99995">
4.3 Application of LNRE Models
</subsectionHeader>
<bodyText confidence="0.999730769230769">
Table 2 shows the results of the application of
the LNRE models, for the models whose mean
square errors of V(N) and V(1, N) are mini-
mal for 40 equally-spaced intervals of the sam-
ple. Figure 1 shows the growth curve of the
morpheme types up to the original sample size
(LNRE estimations by lines and the empirical
values by dots). According to Baayen (1993),
a good lognormal fit indicates high productiv-
ity, and the large Z of Yule-Simon model also
means richness of the vocabulary. Figure 1 and
the chosen models in Table 2 confirm these in-
terpretations.
</bodyText>
<table confidence="0.96543775">
Domain Model Z S V(N) E[V(N)]
CS all Gauss-Poisson 236 56085 5176 5176.0
borrowed Lognormal 419 75296 2809 2809.0
native Gauss-Poisson 104 6095 2367 2362.6
PS all Lognormal 1283 30691 3594 3594.0
borrowed Yule-Simon 38051 CC 995 995.0
native Gauss-Poisson 231 10191 2599 2599.0
Z p votal sample !use , S population number of types
</table>
<tableCaption confidence="0.999853">
Table 2. The Applications of LNRE Models
</tableCaption>
<bodyText confidence="0.99857875">
From Figure 1, it is observed that the num-
ber of the borrowed morpheme types in com-
puter science becomes bigger than that of the
native morphemes around N = 15000, while in
psychology the number of the borrowed mor-
phemes is much smaller within the given sam-
ple range. All the elements are still growing,
which implies that the quantitative measures
keep changing.
Figure 2 shows the empirical and LNRE es-
timation of the spectrum elements, for m = 1
to 10. In both domains, the differences be-
tween V(1, N) and V(2, N) of the borrowed
morphemes are bigger than those of the native
morphemes.
Both the growth curves in Figure 1 and the
distributions of the spectrum elements in Figure
2 show, at least to the eye, the reasonable fits of
the LNRE models. In the discussions below, we
assume that the LNRE based estimations are
</bodyText>
<figure confidence="0.9090505">
lines LNRE estimations ; dots : empirical values
(a) Computer Science (b) Psychology
</figure>
<figureCaption confidence="0.990934">
Fig. 1. Empirical and LNRE Growth Curve
</figureCaption>
<figure confidence="0.761555">
lines LNRE estimations ; dots : empirical values
(a) Computer Science (b) Psychology
</figure>
<figureCaption confidence="0.999948">
Fig. 2. Empirical and LNRE Spectrum Elements
</figureCaption>
<bodyText confidence="0.997896">
valid, within the reasonable range of N. The
statistical validity will be examined later.
</bodyText>
<subsectionHeader confidence="0.893137">
4.3.1 Mean Frequency
</subsectionHeader>
<bodyText confidence="0.999924533333333">
As the population numbers of morphemes
are estimated to be finite with the excep-
tion of the borrowed morphemes in psychology,
X(V(N)) = oo, which is not of much
interest. The more important and interesting
is the actual transition of the mean frequencies
within a realistic range of N, because the size
of a terminology in practice is expected to be
limited.
Figure 3 shows the transitions of X(V(N)),
based on the LNRE models, up to 2N in com-
puter science and 5N in psychology, plotted ac-
cording to the size of the frame sample. The
mean frequencies are consistently higher in com-
puter science than in psychology. Around N =
</bodyText>
<figure confidence="0.94350958974359">
V(N):all
•-- V(N):borrowed
•-- V(N):native
• - --V(1,N):borrowed
•--V(1,N):native
0 10000 20000 30000 0 2000100060003000 12000
2 4 6
8 10 2 4 6
8
10
•--V(m,N):borrowed
•--V(m,N):native
•--V(m,N):borrowed
•--V(m,N):native
641
— Pt : all
- • Pt: borrowed
- Pt : native
• Pi : borrowed
• • • Pi : native
- Rt : borrowed
- Rt: native
Turning point of Pt
for native and borrowed Morphemes
-
------------- - - - - - ------------------------ -
60000
20000
40000
— CS : all
--- CS : borrowed
cs, -- CS : native
— PS : all
-- PS : borrowed
- - PS : native
......................
..........
-----------------------
(NI
</figure>
<figureCaption confidence="0.998866">
Fig. 3. Mean Frequencies
</figureCaption>
<bodyText confidence="0.99404525">
70000, X (V (N)) in computer science is ex-
pected to be 10, while in psychology it is 9.
The particularly low value of X (V (Nbo„„wed))
in psychology is also notable.
</bodyText>
<subsectionHeader confidence="0.567789">
4.3.2 Growth Rate/Reuse Ratio
</subsectionHeader>
<bodyText confidence="0.99862221875">
Figure 4 shows the values of Pf, Pi and flf, for
the same range of N as in Figure 3. The values
of Pib(N) and Pin(N) in both domains show
that, in general, the borrowed morphemes are
more &apos;productive&apos; than the native morphemes,
though the actual value depends on the domain.
Comparing the two domains by Pfall(N), we
can observe that at the beginning the terminol-
ogy of psychology relies more on the new mor-
phemes than in computer science, but the values
are expected to become about the same around
N = 70000.
Pfs for the borrowed and native morphemes
show interesting characteristics in each domain.
Firstly, in computer science, at the relatively
early stage of terminological growth (i.e. N
3500), the borrowed morphemes begin to take
the bigger role in incorporating new conceptual
elements. Pfb(N) in psychology is expected to
become bigger than P1(N) around N = 47000.
As the model estimates the population num-
ber of the borrowed morphemes to be infinite
in psychology, that the Pfb(N) becomes bigger
than Pfn(N) at some stage is logically expected.
What is important here is that, even in psychol-
ogy, where the overall role of the borrowed mor-
phemes is marginal, P1(N) is expected to be-
come bigger around N 47000, i.e. T 21000,
which is well within the realistic value for a pos-
sible terminological size.
Unlike Pf, the values of R f show stable tran-
sition beyond N = 20000 in both domains,
</bodyText>
<figure confidence="0.930879">
20000 40000 60000
(a) Computer Science
</figure>
<listItem confidence="0.789273142857143">
i\sbTurning point of Pt — Pt : all
for native and borrowed morphemes - - - • PI : borrowed
- Pt: native
• Pi: borrowed
• • • P1: native
- Rt : borrowed
- Rt : native
</listItem>
<figure confidence="0.9984145">
0 20000 40000 60000
(b) Psychology
</figure>
<figureCaption confidence="0.999812">
Fig. 4. Changes of the Growth Rates
</figureCaption>
<bodyText confidence="0.9994095">
gradually approaching the relative token fre-
quencies.
</bodyText>
<sectionHeader confidence="0.937735" genericHeader="method">
5 Theoretical Validity
</sectionHeader>
<subsectionHeader confidence="0.996653">
5.1 Linguistic Validity
</subsectionHeader>
<bodyText confidence="0.9999847">
We have seen that the LNRE models offer a
useful means to observe the dynamics of mor-
phemes, beyond the sample size. As mentioned,
what is important in terminological analyses is
to obtain the patterns of transitions of some
characteristic quantities beyond the sample size
but still within the realistic range, e.g. 2N, 3N,
etc. Because we have been concerned with the
morphemes as a mass, we could safely use N in-
stead of T to discuss the status of morphemes,
</bodyText>
<page confidence="0.996452">
642
</page>
<bodyText confidence="0.999973064516129">
implicitly assuming that the average number of
constituent morphemes in a term is stable.
Among the measures we used in the anal-
ysis of morphemes, the most important is the
growth rate. The growth rate as the mea-
sure of the productivity of affixes (Baayen,
1991) was critically examined by van Marle
(1991). One of his essential points was the re-
lation between the performance-based measure
and the competence-based concept of produc-
tivity. As the growth rate is by definition a
performance-based measure, it is not unnatu-
ral that the competence-based interpretation of
the performance-based productivity measure is
requested, when the object of the analysis is di-
rectly related to such competence-oriented no-
tion as derivation. In terminology, however,
this is not the case, because the notion of
terminology is essentially performance-oriented
(Kageura, 1995). The growth rate, which con-
cerns with the linguistic performance, directly
reflects the inherent nature of terminological
structurel.
One thing which may also have to be ac-
counted for is the influence of the starting sam-
ple size. Although we assumed that the order of
terms in a given terminology is arbitrary, it may
not be the case, because usually a smaller sam-
ple may well include more &apos;central&apos; terms. We
may need further study concerning the status of
the available terminological corpora.
</bodyText>
<subsectionHeader confidence="0.999889">
5.2 Statistical Validity
</subsectionHeader>
<bodyText confidence="0.999921166666667">
Figure 5 plots the values of the z-score for EY]
and E[V(1)], for the models used in the analy-
ses, at 20 equally-spaced intervals for the first
half of the sample2. In psychology, all but one
values are within the 95% confidence interval.
In computer science, however, the fit is not so
good as in psychology.
Table 3 shows the x2 values calculated on
the basis of the first 15 spectrum elements at
the original sample size. Unfortunately, the x2
values show that the models have obtained the
fits which are not ideal, and the null hypothesis
</bodyText>
<footnote confidence="0.9919422">
&apos;Note however that the level of what is meant by the
word &apos;performance&apos; is different, as Baayen (1991) is text-
oriented, while here it is vocabulary-oriented.
2To calculate the variance we need V (2N), so the test
can be applied only for the first half of the sample
</footnote>
<figureCaption confidence="0.988132">
Fig. 5. Z-Scores for E[V] and E[V(1)]
</figureCaption>
<bodyText confidence="0.8810985">
is rejected at 95% level, for all the models we
used.
</bodyText>
<table confidence="0.999824857142857">
Data Model x2 DF
CS all Gauss-Poisson 129.70 14
borrowed Lognormal 259.08 14
native Gauss-Poisson 60.30 13
PS all Lognormal 72.21 14
borrowed Yule-Simon 179.36 14
native Gauss-Poisson 135.30 13
</table>
<tableCaption confidence="0.999254">
Table 3. x2 Values for the Models
</tableCaption>
<bodyText confidence="0.999890153846154">
Unlike texts (Baayen, 1996a;1996b), the ill-
fits of the growth curve of the models are not
caused by the randomness assumption of the
model, because the results of the term-level per-
mutations, used for calculating z-scores, are sta-
tistically identical to the results of morpheme-
level permutations. This implies that we need
better models if we pursue the better curve-
fitting. On the other hand, if we emphasise
the theoretical assumption of the models of fre-
quency distributions used in the LNRE analy-
ses, it is necessary to introduce the finer distinc-
tions of morphemes.
</bodyText>
<sectionHeader confidence="0.999498" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.999973090909091">
Using the LNRE models, we have succesfully
analysed the dynamic nature of the morphemes
in Japanese terminology. As the majority of
the terminological data is located in the LNRE
zone, it is important to use the statistical frame-
work which allows for the LNRE characteristics.
The LNRE models give the suitable means.
We are currently extending our research to
integrating the quantitative nature of morpho-
logical distributions to the qualitative model of
term formation, by taking into account the p0-
</bodyText>
<figure confidence="0.997943111111111">
20 0 5 10 15
Intervals up to N/2
20
0 5 10 15
Intervals up to N/2
(a) Computer Science
(b) Psychology
Co
V(N):all
•-- V(N):borrowa
,ire74.02 V(N):native
ti t:rv
-11
•64,
V(1,N):all
• - - 1/(1.N):borrowe
▪ V(1_,Nynative
1 -
</figure>
<page confidence="0.997522">
643
</page>
<bodyText confidence="0.999576">
sitional and combinatorial nature of morphemes
and the distributions of term length.
</bodyText>
<sectionHeader confidence="0.945727" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.963041375">
I would like to express my thanks to Dr. Har-
ald Baayen of the Max Plank Institute for Psy-
cholinguistics, for introducing me to the LNRE
models and giving me advice. Without him,
this work coudn&apos;t have been carried out. I
also thank to Ms. Clare McCauley of the NLP
group, Department of Computer Science, the
University of Sheffield, for checking the draft.
</bodyText>
<sectionHeader confidence="0.998685" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996625018867925">
population parameters.&amp;quot; Biometrika. 40(3-
4), p. 237-264.
[10] Good, I. J. and Toulmin, G. H. (1956) &amp;quot;The
number of new species, and the increase in
population coverage, when a sample is in-
creased.&amp;quot; Biometrika. 43(1), p. 45-63.
[11] Ishii, M. (1987) &amp;quot;Economy in Japanese
scientific terminology.&amp;quot; Terminology and
Knowledge Engineering &apos;87. p. 123-136.
[12] Japanese Ministry of Education (1986)
Japanese Scientific Terms: Psychology.
Tokyo: Gakujutu-Sinkokai.
[13] Kageura, K. (1995) &amp;quot;Toward the theoret-
ical study of terms.&amp;quot; Terminology. 2(2),
239-257.
[14] Kageura, K. and Umino, B. (1996) &amp;quot;Meth-
ods of automatic term recognition: A re-
view.&amp;quot; Terminology. 3(2), 259-289.
[15] Mandelbrot, B. (1962). &amp;quot;On the theory of
word frequencies and on related Marko-
vian models of discourse.&amp;quot; In: Jakobson, Ft.
(ed.) Structure of Language and its Math-
ematical Aspects. Rhode Island: American
Mathematical Society. p. 190-219.
[16] Marle, J. van. (1991). &amp;quot;The relationship be-
tween morphological productivity and fre-
quency.&amp;quot; Yearbook of Morphology 1991. p.
151-163.
[17] National Language Research Institute
(1958) Research on Vocabulary in Cultural
Reviews. Tokyo: NLRI.
[18] Nomura, M. and Ishii, M. (1989) Gakujutu
Yogo Goki-Hyo. Tokyo: NLRI.
[19] Sager, J. C. (1990) A Practical Course in
Terminology Processing. Amsterdam: John
Benjamins.
[20] Sichel, H. S. (1986) &amp;quot;Word frequency dis-
tributions and type-token characteristics.&amp;quot;
Mathematical Scientist. 11(1), p. 45-72.
[21] Simon, H. A. (1955) &amp;quot;On a class of skew
distribution functions.&amp;quot; Biometrika. 42(4),
p. 435-440.
[22] Tuldava, J. (1980) &amp;quot;A mathematical model
of the vocabulary-text relation.&amp;quot; COL-
ING&apos;80. p. 600-604.
[23] Yule, G. U. (1944) The Statistical Study
of Literary Vocabulary. Cambridge: Cam-
bridge University Press.
[24] Zipf, G. K. (1935). The Psycho-Biology of
Language. Boston: Houghton Mifflin.
[1] Aiso, H. (ed.) (1993) Joho Syori Yogo Dai-
jiten. Tokyo: Ohm.
[2] Baayen, R. H. (1991) &amp;quot;Quantitative as-
</reference>
<bodyText confidence="0.960777741935484">
pects of morphological productivity.&amp;quot; Year-
book of Morphology 1991. p. 109-149.
[3] Baayen, It. H. (1993) &amp;quot;Statistical models
for word frequency distributions: A lin-
guistic evaluation.&amp;quot; Computers and the Hu-
manities. 26(5-6), p. 347-363.
[4] Baayen, R. H. (1996a) &amp;quot;The randomness
assumption in word frequency statistics.&amp;quot;
Research in Humanities Computing 5. p.
17-31.
[5] Baayen, R. H. (1996b) &amp;quot;The effects of lex-
ical specialization on the growth curve of
the vocabulary.&amp;quot; Computational Linguis-
tics. 22(4), p. 455-480.
[6] Carrol, J. B. (1967) &amp;quot;On sampling from a
lognormal model of word frequency distri-
bution.&amp;quot; In: Kucera, H. and Francis, W. N.
(eds.) Computational Analysis of Present-
Day American English. Province: Brown
University Press. p. 406-424.
[7] Chitashvili, R. J. and Baayen, Ft. H.
(1993) &amp;quot;Word frequency distributions.&amp;quot;
In: Hrebicek, L. and Altmann, G. (eds.)
Quantitative Text Analysis. Trier: Wis-
senschaftlicher Verlag. p. 54-135.
[8] Efron, B. and Thisted, R. (1976) &amp;quot;Es-
timating the number of unseen species:
How many words did Shakespeare know?&amp;quot;
Biometrika. 63(3), p. 435-447.
[9] Good, I. J. (1953) &amp;quot;The population fre-
quencies of species and the estimation of
</bodyText>
<page confidence="0.994116">
644
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99881">A Statistical Analysis of Morphemes in Japanese Terminology</title>
<author confidence="0.947154">Kyo KAGEURA</author>
<affiliation confidence="0.986538">National Center for Science Information Systems</affiliation>
<address confidence="0.983474">3-29-1 Otsuka, Bunkyo-ku, Tokyo, 112-8640 Japan</address>
<email confidence="0.999501">E-Mail:kyo@rd.nacsis.acjp</email>
<abstract confidence="0.982631611111112">In this paper I will report the result of a quantitative analysis of the dynamics of the constituent elements of Japanese terminology. In Japanese technical terms, the linguistic contribution of morphemes greatly differ according to their types of origin. To analyse this aspect, a quantitative method is applied, which can properly characterise the dynamic nature of morphemes in terminology on the basis of a small sample. In computational linguistics, the interest in terminological applications such as automatic term extraction is growing, and many studies use the quantitative information (cf. Kageura &amp; Umino, 1996). However, the basic quantitative nature of terminological structure, which is essential for terminological theory and applications, has not yet been exploited. The static quantitative descriptions are not sufficient, as there are terms which do not appear in the sample. So it is crucial to establish some models, by which the terminological structure beyond the sample size can be properly described. In Japanese terminology, the roles of morphemes are different according to their types of origin, i.e. the morphemes borrowed mainly from Western languages (borrowed morphemes) and the native morphemes including Chineseorigined morphemes which are the majority. There are some quantitative studies (Ishii, 1987; Nomura &amp; Ishii, 1989), but they only treat the static nature of the sample. Located in the intersection of these two backgrounds, the aim of the present study is twofold, i.e. (1) to introduce a quantitative framework in which the dynamic nature of terminology can be described, and to examine its theoretical validity, and (2) to describe the quantitative dynamics of morphemes as a &apos;mass&apos; in Japanese terminology, with reference to the types of origin. Terminological 2.1 The Data We use a list of different terms as a sample, and observe the quantitative nature of the constituent elements or morphemes. The quantitative regularities is expected to be observed at this level, because a large portion of terms is complex (Nomura Sz Ishii, 1989), whose formation is systematic (Sager, 1990), and the quantitative nature of morphemes in terminology is independent of the token frequency of terms, because the term formation is a lexical formation. With the correspondences between text and terminology, sentences and terms, and words and morphemes, the present work can be regarded as parallel to the quantitative study of words in texts (Baayen, 1991; Baayen, 1993; Mandelbrot, 1962; Simon, 1955; Yule, 1944; Zipf, 1935). Such terms as &apos;type&apos;, &apos;token&apos;, &apos;vocabulary&apos;, etc. will be used in this context. Two Japanese terminological data are used in this study: computer science (CS: Aiso, 1993) and psychology (PS: Japanese Ministry of Education, 1986). The basic quantitative data are in Table 1, where N, indicate the number of terms, of running morphemes (tokens), and of different morphemes (types), respectively. In computer science, the frequencies of the borrowed and the native morphemes are not very different. In psychology, the borrowed 638 Domain V(N) N/T N/V(N) I Cf. 1 14983 36640 5176 2.45 7.08 0.211 borrowed 14696 2809 5.23 0.242 native 21944 2367 9.27 0.174 6272 14314 3594 2.28 3.98 0.235 borrowed 1641 995 1.55 0.309 native 12773 2599 4.91 0.207 Table 1. Basic Figures of the Terminological Data morphemes constitute only slightly more than 10% of the tokens. The mean frequency the borrowed morphemes is much lower than the native morphemes in both domains. 2.2 LNRE Nature of the Data The LNRE (Large Number of Rare Events) zone (Chitashvili &amp; Baayen, 1993) is defined as the range of sample size where the population events (different morphemes) are far from being exhausted. This is shown by the fact that the numbers of hapax legomena and of dislegomena are increasing (see Figure 1 for hapax). A convenient test to see if the sample is located in the LNRE zone is to see the ratio of loss of the number of morpheme types, calculated by the sample relative frequencies as the estimates of population probabilities. Assuming the binomial model, the ratio of loss is obtained by: — (N)])/V(N) - N))N V(N) where: (i, N) : of a morpheme w, in a sample N) = f (i, N : relative frequency. m : frequency class or a number of occurrence. : number of morpheme types occurring m times (spectrum elements) in a sample In the two data, we underestimate the number morpheme types by more than 20% Table 1), which indicates that they are clearly located in the LNRE zone. 3 The LNRE Framework When a sample is located in the LNRE zone, values of statistical measures such as type-token ratio, the parameters of &apos;laws&apos; (e.g. of Mandelbrot, 1962) of word frequency distributions, etc. change systematically according to the sample size, due to the unobserved events. To treat LNRE samples, therefore, the factor of sample size should be taken into consideration. Good (1953) gives a method of re-estimating the population probabilities of the types in the sample as well as estimating the probability mass of unseen types. There is also work on the estimation of the theoretical vocabulary size (Efron &amp; Thisted, 1976; National Language Research Institute, 1958; Tuldava, 1980). However, they do not give means to estimate such as V(m, N) arbitrary sample size, which are what we need. The LNRE framework (Chitashvili &amp; Baayen, 1993) offers the means suitable for the present study. 3.1 Binomial/Poisson Assumption that there are morphemes = the terminological population, with a probability pi associated with each of them. Assuming the binomial distribution and its Poisson approximation, we can express the expected numbers of morphemes and of spectrum elements in a given sample of size follows: = S E(1 — = ,=1 = E i=1 As our data is in the LNRE zone, we cannot (1953) and Good (1956) introduced the method of interpolating and extrapolating the number of types for arbitrary sample size, but it cannot be used for extrapolating to a very large size. 3.2 The LNRE Models Assume that the distribution of grouped probaa distribution &apos;law&apos;, which can be expressed by some structural type distribution = = when p 0 otherwise. Using expressions (1) and (2) can be re-expressed as follows: (N)] = (1 — (3) 639 00 0Im! dG(p). = G(pi) - 0 otherwise, in which p is now grouped for the value and indexed by the subscript in ascending order the values of In using some explicit expressions such as &apos;law&apos; (Carrol, 1967) for again face the problem of sample size dependency of the parameters of these &apos;laws&apos;. To overcome the problem, a certain distribution model for the population is assumed, which manifests itself as one of the &apos;laws&apos; at a pivotal sample size explicitly incorporating a parameter, the models can be completed, and it becomes possible (i) to represent the distribution population probabilities by means of to estimate the theoretical vocabulary size, and (ii) to interpolate and extrapolate (N) (m, N) the arbitrary sample size such an expression: 4 zdG(p) m! The parameters of the model, i.e. the original parameters of the &apos;laws&apos; of word frequency and the pivotal sample size estimated by looking for the values that most properly describe the distributions of spectrum elements and the vocabulary size at the given sample size. In this study, four LNRE models were tried, which incorporate the lognormal &apos;law&apos; (Carrol, 1967), the inverse Gauss-Poisson &apos;law&apos; (Sichel, 1986), Zipf&apos;s &apos;law&apos; (Zipf, 1935) and Yule-Simon &apos;law&apos; (Simon, 1955). 4 Analysis of Terminology 4.1 Random Permutation Unlike texts, the order of terms in a given terminological sample is basically arbitrary. Thus term-level random permutation can be used to obtain the better descriptions of sub-samples. In the following, we use the results of 1000 termlevel random permutations for the empirical descriptions of sub-samples. In fact, the results of the term-level and morpheme-level permutations almost coincide, with no statistically significant difference. From this we can conclude that the binomial/Poisson assumption of the LNRE models in the previous section holds for the terminological data. 4.2 Quantitative Measures Two measures are used for observing the dynamics of morphemes in terminology. The first is the mean frequency of morphemes: - V(N) The repeated occurrence of a morpheme indicates that it is used as a constituent element of terms, as the samples consist of term types. As it is not likely that the same morpheme occurs twice in a term, the mean frequency indicates the average number of terms which is connected by a common morpheme. A more important measure is the growth we observe changing obtain the growth curve of the morpheme types. The slope of the growth curve gives the growth rate. By taking the first derivate of by equation (3), therefore, we obtain the growth rate of the morpheme types: (6) dN This &amp;quot;expresses in a very real sense the probability that new types will be encountered when the ... sample is increased&amp;quot; (Baayen, 1991). For convenience, we introduce the notation the complement of reuse ratio: which expresses the probability that the existing types will be encountered. For each type of morpheme, there are two of calculating first is on the basis of the total number of the running morphemes (frame sample). For the borrowed morphemes, for instance, it is defined as: = I N The second is on the basis of the number of running morphemes of each type (item sample). For instance, for the borrowed morphemes: N)]! Nborroured the reuse ratio also defined in two ways. Pi reflects the growth rate of the morphemes of each type observed separately. Each of them expresses the probability of encountering a new morpheme for the separate sample consisting of the morphemes of the same type, and does not in itself indicate any characteristics in the frame sample. 640 the other hand, the quantitative status of the morphemes of each type as a mass in terminology. So the transiof changing the changes of the status of the morphemes of each type in the terminology. In terminology, be interpreted as the probability of incorporating new conceptual elements. 4.3 Application of LNRE Models Table 2 shows the results of the application of the LNRE models, for the models whose mean errors of V(1, minimal for 40 equally-spaced intervals of the sample. Figure 1 shows the growth curve of the morpheme types up to the original sample size (LNRE estimations by lines and the empirical values by dots). According to Baayen (1993), a good lognormal fit indicates high productivand the large Yule-Simon model also means richness of the vocabulary. Figure 1 and the chosen models in Table 2 confirm these interpretations. Domain Model Z S V(N) E[V(N)] CS all Gauss-Poisson 236 56085 5176 5176.0 borrowed Lognormal 419 75296 2809 2809.0 native Gauss-Poisson 104 6095 2367 2362.6 PS all Lognormal 1283 30691 3594 3594.0 borrowed Yule-Simon 38051 CC 995 995.0 native Gauss-Poisson 231 10191 2599 2599.0 votal sample !use , number of types Table 2. The Applications of LNRE Models From Figure 1, it is observed that the number of the borrowed morpheme types in computer science becomes bigger than that of the morphemes around = while in psychology the number of the borrowed morphemes is much smaller within the given sample range. All the elements are still growing, which implies that the quantitative measures keep changing. Figure 2 shows the empirical and LNRE estimation of the spectrum elements, for m = 1 to 10. In both domains, the differences be- V(1, V(2, the borrowed morphemes are bigger than those of the native morphemes. Both the growth curves in Figure 1 and the distributions of the spectrum elements in Figure 2 show, at least to the eye, the reasonable fits of the LNRE models. In the discussions below, we assume that the LNRE based estimations are lines LNRE estimations ; dots : empirical values (a) Computer Science (b) Psychology Fig. 1. Empirical and LNRE Growth Curve lines LNRE estimations ; dots : empirical values (a) Computer Science (b) Psychology Fig. 2. Empirical and LNRE Spectrum Elements within the reasonable range of statistical validity will be examined later. 4.3.1 Mean Frequency As the population numbers of morphemes are estimated to be finite with the exception of the borrowed morphemes in psychology, = oo, is not of much interest. The more important and interesting is the actual transition of the mean frequencies a realistic range of the size of a terminology in practice is expected to be limited. 3 shows the transitions of based on the LNRE models, up to 2N in computer science and 5N in psychology, plotted according to the size of the frame sample. The mean frequencies are consistently higher in comscience than in psychology. Around = V(N):all •-- V(N):borrowed •-- V(N):native • - --V(1,N):borrowed •--V(1,N):native</abstract>
<phone confidence="0.701908666666667">0 10000 20000 30000 0 2000100060003000 12000 2 4 6 8 10 2 4 6</phone>
<note confidence="0.781313">8 10 •--V(m,N):borrowed •--V(m,N):native •--V(m,N):borrowed •--V(m,N):native 641</note>
<degree confidence="0.606523666666667">Pt : all - • Pt: borrowed - Pt : native • Pi : borrowed • • • Pi : native - Rt : borrowed - Rt: native Turning point of Pt for native and borrowed Morphemes</degree>
<affiliation confidence="0.4731565"></affiliation>
<address confidence="0.966594666666667">60000 20000 40000</address>
<abstract confidence="0.986130458333333">CS : all --- CS : borrowed cs, -- CS : native — PS : all -- PS : borrowed - - PS : native ...................... .......... ----------------------- (NI Fig. 3. Mean Frequencies (V (N)) computer science is expected to be 10, while in psychology it is 9. particularly low value of in psychology is also notable. Growth Rate/Reuse 4 shows the values of and same range of in Figure 3. The values both domains show that, in general, the borrowed morphemes are more &apos;productive&apos; than the native morphemes, though the actual value depends on the domain. the two domains by can observe that at the beginning the terminology of psychology relies more on the new morphemes than in computer science, but the values are expected to become about the same around = the borrowed and native morphemes show interesting characteristics in each domain. Firstly, in computer science, at the relatively stage of terminological growth (i.e. 3500), the borrowed morphemes begin to take the bigger role in incorporating new conceptual psychology is expected to bigger than = As the model estimates the population number of the borrowed morphemes to be infinite psychology, that the bigger some stage is logically expected. What is important here is that, even in psychology, where the overall role of the borrowed moris marginal, expected to bebigger around i.e. which is well within the realistic value for a possible terminological size. values of stable tranbeyond = in both domains,</abstract>
<phone confidence="0.525438">20000 40000 60000</phone>
<affiliation confidence="0.58434">(a) Computer Science</affiliation>
<degree confidence="0.606386285714286">point of Ptfor native and borrowed morphemes — Pt : all - - - • PI : borrowed - Pt: native • Pi: borrowed • • • P1: native - Rt : borrowed - Rt : native</degree>
<phone confidence="0.771627">40000 60000</phone>
<affiliation confidence="0.580415">(b) Psychology</affiliation>
<address confidence="0.414868">Fig. 4. Changes of the Growth Rates</address>
<abstract confidence="0.993557747474747">gradually approaching the relative token frequencies. 5 Theoretical Validity 5.1 Linguistic Validity We have seen that the LNRE models offer a useful means to observe the dynamics of morphemes, beyond the sample size. As mentioned, what is important in terminological analyses is to obtain the patterns of transitions of some characteristic quantities beyond the sample size but still within the realistic range, e.g. 2N, 3N, etc. Because we have been concerned with the as a mass, we could safely use inof discuss the status of morphemes, 642 implicitly assuming that the average number of constituent morphemes in a term is stable. Among the measures we used in the analysis of morphemes, the most important is the growth rate. The growth rate as the measure of the productivity of affixes (Baayen, 1991) was critically examined by van Marle (1991). One of his essential points was the relation between the performance-based measure and the competence-based concept of productivity. As the growth rate is by definition a performance-based measure, it is not unnatural that the competence-based interpretation of the performance-based productivity measure is requested, when the object of the analysis is directly related to such competence-oriented notion as derivation. In terminology, however, this is not the case, because the notion of terminology is essentially performance-oriented (Kageura, 1995). The growth rate, which concerns with the linguistic performance, directly reflects the inherent nature of terminological One thing which may also have to be accounted for is the influence of the starting sample size. Although we assumed that the order of terms in a given terminology is arbitrary, it may not be the case, because usually a smaller sample may well include more &apos;central&apos; terms. We may need further study concerning the status of the available terminological corpora. 5.2 Statistical Validity Figure 5 plots the values of the z-score for EY] and E[V(1)], for the models used in the analyses, at 20 equally-spaced intervals for the first of the In psychology, all but one values are within the 95% confidence interval. In computer science, however, the fit is not so good as in psychology. 3 shows the values calculated on the basis of the first 15 spectrum elements at original sample size. Unfortunately, the values show that the models have obtained the fits which are not ideal, and the null hypothesis &apos;Note however that the level of what is meant by the word &apos;performance&apos; is different, as Baayen (1991) is textoriented, while here it is vocabulary-oriented. the variance we need (2N), the test only for the first half of the sample 5. Z-Scores for E[V(1)] is rejected at 95% level, for all the models we used. Data Model DF CS all Gauss-Poisson 129.70 14 borrowed Lognormal 259.08 14 native Gauss-Poisson 60.30 13 PS all Lognormal 72.21 14 borrowed Yule-Simon 179.36 14 native Gauss-Poisson 135.30 13 3. Values for the Models Unlike texts (Baayen, 1996a;1996b), the illfits of the growth curve of the models are not caused by the randomness assumption of the model, because the results of the term-level permutations, used for calculating z-scores, are statistically identical to the results of morphemelevel permutations. This implies that we need better models if we pursue the better curvefitting. On the other hand, if we emphasise the theoretical assumption of the models of frequency distributions used in the LNRE analyses, it is necessary to introduce the finer distinctions of morphemes. 6 Conclusions Using the LNRE models, we have succesfully analysed the dynamic nature of the morphemes in Japanese terminology. As the majority of the terminological data is located in the LNRE zone, it is important to use the statistical framework which allows for the LNRE characteristics. The LNRE models give the suitable means. We are currently extending our research to integrating the quantitative nature of morphological distributions to the qualitative model of formation, by taking into account the p0-</abstract>
<phone confidence="0.50637">20 0 5 10 15</phone>
<note confidence="0.7750675">Intervals up to N/2 20 0 5 10 15 Intervals up to N/2</note>
<affiliation confidence="0.944617">(a) Computer Science (b) Psychology</affiliation>
<address confidence="0.552229">Co</address>
<email confidence="0.497791">V(N):all</email>
<abstract confidence="0.862071604651163">V(N):borrowa V(N):native ti t:rv -11 • V(1,N):all • - - 1/(1.N):borrowe ▪ V(1_,Nynative 1 - 643 sitional and combinatorial nature of morphemes and the distributions of term length. Acknowledgement I would like to express my thanks to Dr. Harald Baayen of the Max Plank Institute for Psycholinguistics, for introducing me to the LNRE models and giving me advice. Without him, this work coudn&apos;t have been carried out. I also thank to Ms. Clare McCauley of the NLP group, Department of Computer Science, the University of Sheffield, for checking the draft. References parameters.&amp;quot; 40(3- 4), p. 237-264. [10] Good, I. J. and Toulmin, G. H. (1956) &amp;quot;The number of new species, and the increase in population coverage, when a sample is inp. 45-63. [11] Ishii, M. (1987) &amp;quot;Economy in Japanese terminology.&amp;quot; and Engineering &apos;87. 123-136. [12] Japanese Ministry of Education (1986) Japanese Scientific Terms: Psychology. Tokyo: Gakujutu-Sinkokai. [13] Kageura, K. (1995) &amp;quot;Toward the theoretstudy of terms.&amp;quot; 239-257. [14] Kageura, K. and Umino, B. (1996) &amp;quot;Methods of automatic term recognition: A re- 259-289. [15] Mandelbrot, B. (1962). &amp;quot;On the theory of word frequencies and on related Markovian models of discourse.&amp;quot; In: Jakobson, Ft.</abstract>
<note confidence="0.8590034375">of Language and its Math- Aspects. Island: American Mathematical Society. p. 190-219. [16] Marle, J. van. (1991). &amp;quot;The relationship between morphological productivity and freof Morphology 1991. 151-163. [17] National Language Research Institute on Vocabulary in Cultural NLRI. Nomura, M. and Ishii, M. (1989) Goki-Hyo. NLRI. Sager, J. C. (1990) Practical Course in Processing. John Benjamins. [20] Sichel, H. S. (1986) &amp;quot;Word frequency dis-</note>
<abstract confidence="0.7451395">tributions and type-token characteristics.&amp;quot; Scientist. p. 45-72. [21] Simon, H. A. (1955) &amp;quot;On a class of skew functions.&amp;quot; p. 435-440. [22] Tuldava, J. (1980) &amp;quot;A mathematical model the vocabulary-text relation.&amp;quot; COL- 600-604.</abstract>
<author confidence="0.793503">Cam-</author>
<affiliation confidence="0.998403">bridge University Press.</affiliation>
<address confidence="0.924611">Zipf, G. K. (1935). Psycho-Biology of</address>
<affiliation confidence="0.775408">Houghton Mifflin.</affiliation>
<address confidence="0.799155">Aiso, H. (ed.) (1993) Syori Yogo Dai-</address>
<abstract confidence="0.949009210526316">Ohm. [2] Baayen, R. H. (1991) &amp;quot;Quantitative asof morphological productivity.&amp;quot; Yearof Morphology 1991. 109-149. [3] Baayen, It. H. (1993) &amp;quot;Statistical models for word frequency distributions: A linevaluation.&amp;quot; and the Hup. 347-363. [4] Baayen, R. H. (1996a) &amp;quot;The randomness assumption in word frequency statistics.&amp;quot; in Humanities Computing 5. 17-31. [5] Baayen, R. H. (1996b) &amp;quot;The effects of lexical specialization on the growth curve of vocabulary.&amp;quot; Linguisp. 455-480. [6] Carrol, J. B. (1967) &amp;quot;On sampling from a lognormal model of word frequency distribution.&amp;quot; In: Kucera, H. and Francis, W. N.</abstract>
<title confidence="0.507777">Analysis of Present-</title>
<author confidence="0.776736">Brown</author>
<note confidence="0.8624795">University Press. p. 406-424. [7] Chitashvili, R. J. and Baayen, Ft. H. (1993) &amp;quot;Word frequency distributions.&amp;quot; In: Hrebicek, L. and Altmann, G. (eds.)</note>
<author confidence="0.321724">Wis-</author>
<abstract confidence="0.702053285714286">senschaftlicher Verlag. p. 54-135. [8] Efron, B. and Thisted, R. (1976) &amp;quot;Estimating the number of unseen species: How many words did Shakespeare know?&amp;quot; p. 435-447. [9] Good, I. J. (1953) &amp;quot;The population frequencies of species and the estimation of</abstract>
<intro confidence="0.379057">644</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>population parameters.&amp;quot;</title>
<journal>Biometrika.</journal>
<volume>40</volume>
<issue>3</issue>
<pages>237--264</pages>
<marker></marker>
<rawString> population parameters.&amp;quot; Biometrika. 40(3-4), p. 237-264.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I J Good</author>
<author>G H Toulmin</author>
</authors>
<title>The number of new species, and the increase in population coverage, when a sample is increased.&amp;quot;</title>
<date>1956</date>
<journal>Biometrika.</journal>
<volume>43</volume>
<issue>1</issue>
<pages>45--63</pages>
<marker>[10]</marker>
<rawString>Good, I. J. and Toulmin, G. H. (1956) &amp;quot;The number of new species, and the increase in population coverage, when a sample is increased.&amp;quot; Biometrika. 43(1), p. 45-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Ishii</author>
</authors>
<title>Economy in Japanese scientific terminology.&amp;quot;</title>
<date>1987</date>
<journal>Terminology and Knowledge Engineering</journal>
<volume>87</volume>
<pages>123--136</pages>
<marker>[11]</marker>
<rawString>Ishii, M. (1987) &amp;quot;Economy in Japanese scientific terminology.&amp;quot; Terminology and Knowledge Engineering &apos;87. p. 123-136.</rawString>
</citation>
<citation valid="true">
<title>Japanese Scientific Terms: Psychology.</title>
<date>1986</date>
<institution>Japanese Ministry of Education</institution>
<location>Tokyo: Gakujutu-Sinkokai.</location>
<marker>[12]</marker>
<rawString>Japanese Ministry of Education (1986) Japanese Scientific Terms: Psychology. Tokyo: Gakujutu-Sinkokai.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kageura</author>
</authors>
<title>Toward the theoretical study of terms.&amp;quot;</title>
<date>1995</date>
<journal>Terminology.</journal>
<volume>2</volume>
<issue>2</issue>
<pages>239--257</pages>
<marker>[13]</marker>
<rawString>Kageura, K. (1995) &amp;quot;Toward the theoretical study of terms.&amp;quot; Terminology. 2(2), 239-257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kageura</author>
<author>B Umino</author>
</authors>
<title>Methods of automatic term recognition: A review.&amp;quot;</title>
<date>1996</date>
<journal>Terminology.</journal>
<volume>3</volume>
<issue>2</issue>
<pages>259--289</pages>
<marker>[14]</marker>
<rawString>Kageura, K. and Umino, B. (1996) &amp;quot;Methods of automatic term recognition: A review.&amp;quot; Terminology. 3(2), 259-289.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Mandelbrot</author>
</authors>
<title>On the theory of word frequencies and on related Markovian models of discourse.&amp;quot;</title>
<date>1962</date>
<booktitle>Structure of Language and its Mathematical Aspects. Rhode Island: American Mathematical Society.</booktitle>
<pages>190--219</pages>
<editor>In: Jakobson, Ft. (ed.)</editor>
<marker>[15]</marker>
<rawString>Mandelbrot, B. (1962). &amp;quot;On the theory of word frequencies and on related Markovian models of discourse.&amp;quot; In: Jakobson, Ft. (ed.) Structure of Language and its Mathematical Aspects. Rhode Island: American Mathematical Society. p. 190-219.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J van Marle</author>
</authors>
<title>The relationship between morphological productivity and frequency.&amp;quot;</title>
<date>1991</date>
<journal>Yearbook of Morphology</journal>
<pages>151--163</pages>
<marker>[16]</marker>
<rawString>Marle, J. van. (1991). &amp;quot;The relationship between morphological productivity and frequency.&amp;quot; Yearbook of Morphology 1991. p. 151-163.</rawString>
</citation>
<citation valid="true">
<title>Research on Vocabulary in Cultural Reviews.</title>
<date>1958</date>
<publisher>NLRI.</publisher>
<institution>National Language Research Institute</institution>
<location>Tokyo:</location>
<marker>[17]</marker>
<rawString>National Language Research Institute (1958) Research on Vocabulary in Cultural Reviews. Tokyo: NLRI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Nomura</author>
<author>M Ishii</author>
</authors>
<title>Gakujutu Yogo Goki-Hyo.</title>
<date>1989</date>
<publisher>NLRI.</publisher>
<location>Tokyo:</location>
<marker>[18]</marker>
<rawString>Nomura, M. and Ishii, M. (1989) Gakujutu Yogo Goki-Hyo. Tokyo: NLRI.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J C Sager</author>
</authors>
<title>A Practical Course</title>
<date>1990</date>
<booktitle>in Terminology Processing.</booktitle>
<location>Amsterdam: John Benjamins.</location>
<marker>[19]</marker>
<rawString>Sager, J. C. (1990) A Practical Course in Terminology Processing. Amsterdam: John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H S Sichel</author>
</authors>
<title>Word frequency distributions and type-token characteristics.&amp;quot;</title>
<date>1986</date>
<journal>Mathematical Scientist.</journal>
<volume>11</volume>
<issue>1</issue>
<pages>45--72</pages>
<marker>[20]</marker>
<rawString>Sichel, H. S. (1986) &amp;quot;Word frequency distributions and type-token characteristics.&amp;quot; Mathematical Scientist. 11(1), p. 45-72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H A Simon</author>
</authors>
<title>On a class of skew distribution functions.&amp;quot;</title>
<date>1955</date>
<journal>Biometrika.</journal>
<volume>42</volume>
<issue>4</issue>
<pages>435--440</pages>
<marker>[21]</marker>
<rawString>Simon, H. A. (1955) &amp;quot;On a class of skew distribution functions.&amp;quot; Biometrika. 42(4), p. 435-440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Tuldava</author>
</authors>
<title>A mathematical model of the vocabulary-text relation.&amp;quot; COLING&apos;80.</title>
<date>1980</date>
<pages>600--604</pages>
<marker>[22]</marker>
<rawString>Tuldava, J. (1980) &amp;quot;A mathematical model of the vocabulary-text relation.&amp;quot; COLING&apos;80. p. 600-604.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G U Yule</author>
</authors>
<title>The Statistical Study of Literary Vocabulary. Cambridge:</title>
<date>1944</date>
<publisher>Cambridge University Press.</publisher>
<marker>[23]</marker>
<rawString>Yule, G. U. (1944) The Statistical Study of Literary Vocabulary. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G K Zipf</author>
</authors>
<title>The Psycho-Biology of Language.</title>
<date>1935</date>
<location>Boston: Houghton Mifflin.</location>
<marker>[24]</marker>
<rawString>Zipf, G. K. (1935). The Psycho-Biology of Language. Boston: Houghton Mifflin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Aiso</author>
</authors>
<title>Joho Syori Yogo Daijiten.</title>
<date>1993</date>
<location>Tokyo: Ohm.</location>
<marker>[1]</marker>
<rawString>Aiso, H. (ed.) (1993) Joho Syori Yogo Daijiten. Tokyo: Ohm.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R H Baayen</author>
</authors>
<title>Quantitative as-</title>
<date>1991</date>
<marker>[2]</marker>
<rawString>Baayen, R. H. (1991) &amp;quot;Quantitative as-</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>