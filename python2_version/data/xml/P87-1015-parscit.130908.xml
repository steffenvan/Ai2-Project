<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000017">
<note confidence="0.926744">
CHARACTERIZING STRUCTURAL DESCRIPTIONS PRODUCED BY VARIOUS
GRAMMATICAL FORMALISMS*
</note>
<author confidence="0.560204">
K. Vijay-Shanker David J. Weir Aravind K. Joshi
</author>
<affiliation confidence="0.7571635">
Department of Computer and Information Science
University of Pennsylvania
</affiliation>
<address confidence="0.393388">
Philadelphia, Pa 19104
</address>
<sectionHeader confidence="0.796229" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999913">
We consider the structural descriptions produced by vari-
ous grammatical formalisms in terms of the complexity of the
paths and the relationship between paths in the sets of structural
descriptions that each system can generate. In considering the
relationship between formalisms, we show that it is useful to
abstract away from the details of the formalism, and examine
the nature of their derivation process as reflected by properties
of their derivation trees. We find that several of the formalisms
considered can be seen as being closely related since they have
derivation tree sets with the same structure as those produced
by Context-Free Grammars On the basis of this observation,
we describe a class of formalisms which we call Linear Context-
Free Rewriting Systems, and show they are recognizable in poly-
nomial time and generate only semilinear languages.
</bodyText>
<sectionHeader confidence="0.998428" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99030725">
Much of the study of grammatical systems in computational
linguistics has been focused on the weak generative capacity of
grammatical formalism. Little attention, however, has been paid
to the structural descriptions that these formalisms can assign to
strings, i.e. their strong generative capacity. This aspect of the
formalism is both linguistically and computationally important.
For example, Gazdar (1985) discusses the applicability of In-
dexed Grammars (IG&apos;s) to Natural Language in terms of the
structural descriptions assigned; and Berwick (1984) discusses
the strong generative capacity of Lexical-Functional Grammar
(LFG) and Government and Bindings grammars (GB). The work
of Thatcher (1973) and Rounds (1969) define formal systems
that generate tree sets that are related to CFG&apos;s and IG&apos;s.
We consider properties of the tree sets generated by CFG&apos;s,
Tree Adjoining Grammars (TAG&apos;s), Head Grammars (HG&apos;s),
Categorial Grammars (CG&apos;s), and IG&apos;s. We examine both the
complexity of the paths of trees in the tree sets, and the kinds
of dependencies that the formalisms can impose between paths.
These two properties of the tree sets are not only linguistically
relevant, but also have computational importance. By consider-
ing derivation trees, and thus abstracting away from the details of
the composition operation and the structures being manipulated,
we are able to state the similarities and differences between the
&apos;This work was partially supported by NSF grants MCS42-19116-CER, MCS-
82-07294 and DCR-84-10413, ARO grant DAA 29-84-9-0027, and DARPA grant
N00014-85-K0018. We are very grateful to Tony Kroc.h, Michael Pails, Sunil
Shende, and Mark Steedman for valuable discussions.
formalisms. It is striking that from this point of view many for-
malisms can be grouped together as having identically structured
derivation tree sets. This suggests that by generalizing the notion
of context-freeness in CFG&apos;s, we can define a class of grammati-
cal formalisms that manipulate more complex structures. In this
paper, we outline how such family of formalisms can be defined,
and show that like CFG&apos;s, each member possesses a number of
desirable linguistic and computational properties: in particular,
the constant growth property and polynomial recognizability.
</bodyText>
<sectionHeader confidence="0.975079" genericHeader="method">
2 Tree Sets of Various Formalisms
</sectionHeader>
<subsectionHeader confidence="0.920577">
2.1 Context-Free Grammars
</subsectionHeader>
<bodyText confidence="0.9999248125">
From Thatcher&apos;s (1973) work, it is obvious that the complexity
of the set of paths from root to frontier of trees in a local set (the
tree set of a CFG) is regular&apos;. We define the path set of a tree 1
as the set of strings that label a path from the root to frontier of
7. The path set of a tree set is the union of the path sets of trees
in that tree set. It can be easily shown from Thatcher&apos;s result
that the path set of every local set is a regular set. As a result,
CFG&apos;s can not provide the structural descriptions in which there
are nested dependencies between symbols labelling a path. For
example, CFG&apos;s cannot produce trees of the form shown in Fig-
ure 1 in which there are nested dependencies between S and NP
nodes appearing on the spine of the tree. Gazdar (1985) argues
this is the appropriate analysis of unbounded dependencies in the
hypothetical Scandinavian language Norwedish. He also argues
that paired English complementizers may also require structural
descriptions whose path sets have nested dependencies.
</bodyText>
<subsectionHeader confidence="0.99982">
2.2 Head Grammars and Generalized CFG&apos;s
</subsectionHeader>
<bodyText confidence="0.9998819">
Head Grammars (HG&apos;s), introduced by Pollard (1984), is a for-
malism that manipulates headed strings: i.e., strings, one of
whose symbols is distinguished as the head. Not only is con-
catenation of these strings possible, but head wrapping can be
used to split a string and wrap it around another string. The
productions of HG&apos;s are very similar to those of CFG&apos;s except
that the operation used must be made explicit. Thus, the tree
sets generated by HG&apos;s are similar to those of CFG&apos;s, with each
node annotated by the operation (concatenation or wrapping)
used to combine the headed strings derived by the daughters of
</bodyText>
<footnote confidence="0.876639">
1Thatckier actually characterized recognizable sets: for the purposes of this
paper we do not distinguish them from local sets.
</footnote>
<page confidence="0.99667">
104
</page>
<figure confidence="0.9896804">
Y:
S.
NP
NP VP
V S&apos;
NP
NP VP
V 3
NP VP
V PP
</figure>
<figureCaption confidence="0.79713275">
Figure 3: Adjunction operation
Figure 1: Nested dependencies in Norwedish
that node. A derivation tree giving an analysis of Dutch subor-
dinate clauses is given in Figure 2.
</figureCaption>
<figure confidence="0.924858857142857">
S LC2
NP VP RR1
I
V S
Jan zag NP VP RRJ
/\ I
de kindaen annum&apos;
</figure>
<figureCaption confidence="0.996347">
Figure 2: HG analysis of Dutch subordinate clauses
</figureCaption>
<listItem confidence="0.652779833333333">
HG&apos;s are a special case of a class of formalisms called
Generalized Context-Free Grammars, also introduced by Pol-
lard (1984). A formalism in this class is defined by a finite
set of operations (of which concatenation and wrapping are two
possibilities). As in the case of HG&apos;s the annotated tree sets for
these formalisms have the same structure as local sets.
</listItem>
<subsectionHeader confidence="0.829848">
23 Tree Adjoining Grammars
</subsectionHeader>
<bodyText confidence="0.996233315789474">
Tree Adjoining Grammars, a tree rewriting formalism, was intro-
duced by Joshi, Levy and Takahashi (1975) and Joshi (1983/85).
A TAG consists of a finite set of elementary trees that are ei-
ther initial trees or auxiliary trees. Trees are composed using
an operation called adjoining, which is defined as follows. Let
n be some node labeled X in a tree -y (see Figure 3). Let 71 be
a tree with root and foot labeled by X. When 7&apos; is adjoined
at ?I in the tree 7 we obtain a tree v&amp;quot;. The subtree under,;
is excised from 7, the tree 7&apos; is inserted in its place and the
excised subtree is inserted below the foot of y&apos;.
It can be shown that the path set of the tree set generated by
a TAG G is a context-free language. TAG&apos;s can be used to give
the structural descriptions discussed by Gazdar (1985) for the
unbounded nested dependencies in Norwedish, for cross serial
dependencies in Dutch subordinate clauses, and for the nestings
of paired English complementizers.
From the definition of TAG&apos;s, it follows that the choice of
adjunction is not dependent on the history of the derivation.
Like CFG&apos;s, the choice is predetermined by a finite number of
rules encapsulated in the grammar. Thus, the derivation trees
for TAG&apos;s have the same structure as local sets. As with HG&apos;s
derivation structures are annotated; in the case of TAG&apos;s, by the
trees used for adjunction and addresses of nodes of the elemen-
tary tree where adjunctions occurred.
We can define derivation trees inductively on the length of
the derivation of a tree 1. If 7 is an elementary tree, the deriva-
tion tree consists of a single node labeled 7. Suppose -y results
from the adjunction of 71, ,-y, at the k distinct tree addresses
141, , nk in some elementary tree 7&apos;, respectively. The tree
denoting this derivation of 7 is rooted with a node labeled 7&apos;
having k subtrees for the derivations of 71, ... ,7a. The edge
from the root to the subtree for the derivation of 7i is labeled
by the address ni. To show that the derivation tree set of a
TAG is a local set, nodes are labeled by pairs consisting of the
name of an elementary tree and the address at which it was ad-
joined, instead of labelling edges with addresses. The following
rule corresponds to the above derivation, where 71, , 7k are
derived from the auxiliary trees , , fik, respectively.
</bodyText>
<equation confidence="0.907645">
(7&apos;,n) (fli,ni)...(/3k, nk)
</equation>
<bodyText confidence="0.995227">
for all addresses n in some elementary tree at which 7&apos; can be
adjoined. If 7&apos; is an initial tree we do not include an address on
the left-hand side.
</bodyText>
<subsectionHeader confidence="0.995017">
2.4 Indexed Grammars
</subsectionHeader>
<bodyText confidence="0.9999482">
There has been recent interest in the application of Indexed
Grammars (IG&apos;s) to natural languages. Gazdar (1985) considers
a number of linguistic analyses which IG&apos;s (but not CFG&apos;s) can
make, for example, the Norwedish example shown in Figure 1.
The work of Rounds (1969) shows that the path sets of trees de-
rived by IG&apos;s (like those of TAG&apos;s) are context-free languages.
Trees derived by IG&apos;s exhibit a property that is not exhibited by
the trees sets derived by TAG&apos;s or CFG&apos;s. Informally, two or
more paths can be dependent on each other: for example, they
could be required to be of equal length as in the trees in Figure 4.
</bodyText>
<equation confidence="0.8677666">
N V SLC
Pia Ww NP VP RRI
V S LC2
I I
Mire !ripen NP VP
</equation>
<page confidence="0.927837">
105
</page>
<figure confidence="0.995676214285714">
b2
push q
share stack
pop
pop n
ar ar b b2
IG&apos;s can generate trees with dependent paths as in Figure 4b.
Although the path set for trees in Figure 4a is regular, no CFG
}
/A /B
a b A
/A /B
a b
(b)
</figure>
<figureCaption confidence="0.999808">
Figure 4: Example with dependent paths
</figureCaption>
<bodyText confidence="0.811431285714286">
generates such a tree set. We focus on this difference between
the tree sets of CFG&apos;s and IG&apos;s, and formalize the notion of
dependence between paths in a tree set in Section 3.
An IG can be viewed as a CFG in which each nonterminal
is associated with a stack. Each production can push or pop
symbols on the stack as can be seen in the following productions
that generate tree of the form shown in Figure 4b.
</bodyText>
<figure confidence="0.987242333333333">
S(a) S(170)
S(a) A(a)B(a)
A(lia) —* aA(a)
B(ria) --• bB(a)
A() a
B() b
</figure>
<bodyText confidence="0.996047555555556">
Gazdar (1985) argues that sharing of stacks can be used to give
analyses for coordination. Analogous to the sharing of stacks
in IC&apos;s, Lexical-Functional Grammar&apos;s (LFG&apos;s) use the unifi-
cation of unbounded hierarchical structures. Unification is used
in LFG&apos;s to produce structures having two dependent spines
of unbounded length as in Figure 5. Bresnan, Kaplan, Peters,
and Zaenen (1982) argue that these structures are needed to de-
scribe crossed-serial dependencies in Dutch subordinate clauses.
Gazdar (1985) considers a restriction of IG&apos;s in which no more
</bodyText>
<figure confidence="0.971801666666667">
NP VP
NP VP V&apos;
I V\ /N.
Piet NP VP V&apos;
I
MN&amp; NP sir V
Wpm V V&apos;
I I
Ism V
</figure>
<figureCaption confidence="0.998714">
Figure 5: LFG analysis of Dutch subordinate clauses
</figureCaption>
<bodyText confidence="0.999823666666667">
than one nonterminal on the right-hand-side of a production can
inherit the stack from the left-hand-side. Unbounded dependen-
cies between branches are not possible in such a system. TAG&apos;s
can be shown to be equivalent to this restricted system. Thus,
TAG&apos;s can not give analyses in which dependencies between
arbitrarily large branches exist.
</bodyText>
<subsectionHeader confidence="0.997213">
2.5 Categorial Grammars
</subsectionHeader>
<bodyText confidence="0.937273181818182">
Steedman (1986) considers Categorial Grammars in which both
the operations of function application and composition may be
used, and in which function can specify whether they take their
arguments from their right or left. While the generative power
of CG&apos;s is greater that of CFG&apos;s, it appears to be highly con-
strained. Hence, their relationship to formalisms such as HG&apos;s
and TAG&apos;s is of interest. On the one hand, the definition of com-
position in Steedman (1985), which technically permits compo-
sition of functions with unbounded number of arguments, gen-
erates tree sets with dependent paths such as those shown in
Figure 6. This kind of dependency arises from the use of the
</bodyText>
<figure confidence="0.943779">
a 6}
</figure>
<figureCaption confidence="0.999269">
Figure 6: Dependent branches from Categorial Grammars
</figureCaption>
<bodyText confidence="0.991613133333333">
composition operation to compose two arbitrarily large cate-
gories. This allows an unbounded amount of information about
two separate paths (e.g. an encoding of their length) to be com-
bined and used to influence the later derivation. A consequence
of the ability to generate tree sets with this property is that CC&apos;s
under this definition can generate the following language which
can not be generated by either TAG&apos;s or HG&apos;s.
0n0&apos;i&apos;i0&apos;2&amp;quot;bin242bn I n = 711 + n2 }
On the other hand, no linguistic use is made of this general
form of composition and Steedman (personal communication)
and Steedman (1986) argues that a more limited definition of
composition is more natural. With this restriction the resulting
tree sets will have independent paths. The equivalence of CC&apos;s
with this restriction to TAG&apos;s and HG&apos;s is, however, still an
open problem.
</bodyText>
<subsectionHeader confidence="0.993122">
2.6 Multicomponent TAG&apos;s
</subsectionHeader>
<bodyText confidence="0.999644">
An extension of the TAG system was introduced by Joshi et al.
(1975) and later redefined by Joshi (1987) in which the adjunc-
tion operation is defined on sets of elementary trees rather than
single trees. A multicomponent Tree Adjoining Grammar (MC-
TAG) consists of a finite set of finite elementary tree sets. We
must adjoin all trees in an auxiliary tree set together as a single
step in the derivation. The adjunction operation with respect
to tree sets (multicomponent adjunction) is defined as follows.
</bodyText>
<figure confidence="0.998193428571429">
/A /B
a b
/A /B
a b
(a)
a
Mt #12
</figure>
<page confidence="0.988242">
106
</page>
<bodyText confidence="0.995810458333333">
Each member of a set of trees can be adjoined into distinct nodes
of trees in a single elementary tree set, i.e, derivations always
involve the adjunction of a derived auxiliary tree set into an
elementary tree set.
Lilo CFG&apos;s, TAG&apos;s, and HG&apos;s the derivation tree set of a
MCTAG will be a local set. The derivation trees of a MCTAG
are similar to those of a TAG. Instead of the names of elementary
trees of a TAG, the nodes are labeled by a sequence of names
of trees in an elementary tree set. Since trees in a tree set
are adjoined together, the addressing scheme uses a sequence of
pairings of the address and name of the elementary tree adjoined
at that address. The following context-free production captures
the derivation step of the grammar shown in Figure 7, in which
the trees in the auxiliary tree set are adjoined into themselves at
the root node (address c).
((fii, Q2, Pa) , —■ (01, i32, 03) , e),(02,e) Oa, en)
The path complexity of the tee set generated by a MCTAG is not
necessarily context-free. Like the string languages of MCTAG&apos;s,
the complexity of the path set increases as the cardinality of the
elementary tee sets increases, though both the string languages
and path sets will always be semilinear.
MCTAG&apos;s are able to generate tee sets having dependent
paths. For example, the MCTAG shown in Figure 7 generates
trees of the form shown in Figure 4b. The number of paths that
</bodyText>
<figure confidence="0.9732095">
S
aA
</figure>
<figureCaption confidence="0.999973">
Figure 7: A MCTAG with dependent paths
</figureCaption>
<bodyText confidence="0.9993024">
can be dependent is bounded by the grammar (in fact the max-
imum cardinality of a tree set determines this bound). Hence,
trees shown in Figure 8 can not be generated by any MCTAG
(but can be generated by an IG) because the number of pairs of
dependent paths grows with n.
</bodyText>
<figure confidence="0.996573444444444">
beige. n
S
A
A A
A A •
A A A A A
a 0 a a A A
I I
0
</figure>
<figureCaption confidence="0.999902">
Figure 8: Trees with unbounded dependencies
</figureCaption>
<bodyText confidence="0.999987133333333">
Since the derivation tees of TAG&apos;s, MCTAG&apos;s, and HG&apos;s
are local sets, the choice of the structure used at each point in
a derivation in these systems does not depend on the context
at that point within the derivation. Thus, as in CFG&apos;s, at any
point in the derivation, the set of structures that can be applied
is determined only by a finite set of rules encapsulated by the
grammar. We characterize a class of formalisms that have this
property in Section 4. We loosely describe the class of all such
systems as Linear Context-Free Rewriting Formalisms. As is
described in Section 4, the property of having a derivation tree
set that is a local set appears to be useful in showing important
properties of the languages generated by the formalisms. The
semilinearity of Tree Adjoining Languages (TAL&apos;s), MCTAL&apos;s,
and Head Languages (HL&apos;s) can be proved using this property,
with suitable restrictions on the composition operations.
</bodyText>
<sectionHeader confidence="0.99664" genericHeader="method">
3 Dependencies between Paths
</sectionHeader>
<bodyText confidence="0.9998855">
Roughly speaking, we say that a tee set contains trees with
dependent paths if there are two paths p., = vim., and g., =
in each 7 E r such that v., is some, possibly empty,
shared initial subpath; v., and wi are not bounded in length;
and there is some &amp;quot;dependence&amp;quot; (such as equal length) between
the set of all v., and w., for each 7 Er. A tree set may be
said to have dependencies between paths if some &amp;quot;appropriate&amp;quot;
subset can be shown to have dependent paths as defined above.
We attempt to formalize this notion in terms of the tee
pumping lemma which can be used to show that a tee set
does not have dependent paths. Thatcher (1973) describes a
tee pumping lemma for recognizable sets related to the string
pumping lemma for regular sets. The tee in Figure 9a can be
denoted by t1 i223 where tee substitution is used instead of con-
catenation. The tee pumping lemma states that if there is tree,
t = 22 t2t3, generated by a CFG G, whose height is more than
a predetermined bound k, then all trees of the form ti tP3 for
each i &gt; 0 will also generated by G (as shown in Figure 9b).
The string pumping lemma for CFG&apos;s (uvwxy-theorem) can be
seen as a corollary of this lemma.
</bodyText>
<figure confidence="0.9424325">
v
(a) (b)
</figure>
<figureCaption confidence="0.995995">
Figure 9: Tree pumping lemma for local sets
</figureCaption>
<figure confidence="0.930133818181818">
The fact that local sets do not have dependent paths follows
V X
3
X
A. P2: A B
/ I
a A
A • a
0,•••■,
A A
• •
</figure>
<page confidence="0.981012">
107
</page>
<bodyText confidence="0.996769444444445">
from this pumping lemma: a single path can be pumped in-
dependently. For example, let us consider a tree set containing
trees of the form shown in Figure 4a. The tree t2 must be on one
of the two branches. Pumping t2 will change only one branch
and leave the other branch unaffected. Hence, the resulting trees
will no longer have two branches of equal size.
We can give a tree pumping lemma for TAG&apos;s by adapt-
ing the uvwxy-theorem for CFL&apos;s since the tree sets of TAG&apos;s
have independent and context-free paths. This pumping lemma
states that if there is tree, t = t2t3t4t5, generated by a TAG
G, such that its height is more than a predetermined bound k,
then all trees of the form ti it tstt ts for each i &gt; 0 will also
generated by G. Similarly, for tree sets with independent paths
and more complex path sets, tree pumping lemmas can be given.
We adapt the string pumping lemma for the class of languages
corresponding to the complexity of the path set.
A geometrical progression of language families defined by
Weir (1987) involves tree sets with increasingly complex path
sets. The independence of paths in the tree sets of the k
tI
grammatical formalism in this hierarchy can be shown by means
of tree pumping lemma of the form t1ti3t . . .t
The path set of tree sets at level k +1 have the complexity of
the string language of level k.
The independence of paths in a tree set appears to be an
important property. A formalism generating tree sets with com-
plex path sets can still generate only semilinear languages if
its tree sets have independent paths, and semilinear path sets.
For example, the formalisms in the hierarchy described above
generate semilinear languages although their path sets become
increasingly more complex as one moves up the hierarchy. From
the point of view of recognition, independent paths in the deriva-
tion structures suggests that a top-down parser (for example) can
work on each branch independently, which may lead to efficient
parsing using an algorithm based on the Divide and Conquer
technique.
</bodyText>
<sectionHeader confidence="0.998221" genericHeader="method">
4 Linear Context-Free Rewriting Systems
</sectionHeader>
<bodyText confidence="0.9991515">
From the discussion so far it is clear that a number of formalisms
involve some type of context-free rewriting (they have derivation
trees that are local sets). Our goal is to define a class of formal
systems, and show that any member of this class will possess
certain attractive properties. In the remainder of the paper, we
outline how a class of Linear Context-Free Rewriting Systems
(LCFRS&apos;s) may be defined and sketch how semilinearity and
polynomial recognition of these systems follows.
</bodyText>
<subsectionHeader confidence="0.977366">
4.1 Definition
</subsectionHeader>
<bodyText confidence="0.983247785714286">
In defining LCFRS&apos;s, we hope to generalize the definition of
CFG&apos;s to formalisms manipulating any structure, e.g. strings,
trees, or graphs. To be a member of LCFRS a formalism must
satisfy two restrictions. First, any grammar must involve a fi-
nite number of elementary structures, composed using a finite
number of composition operations. These operations, as we see
below, are restricted to be size preserving (as in the case of
concatenation in CFG) which implies that they will be linear
and non-erasing. A second restriction on the formalisms is that
choices during the derivation are independent of the context in
the derivation. As will be obvious later, their derivation tree
sets will be local sets as are those of CFG&apos;s.
Each derivation of a grammar can be represented by a gener-
alized context-free derivation tree. These derivation trees show
how the composition operations were used to derive the final
structures from elementary structures. Nodes are annotated by
the name of the composition operation used at that step in the
derivation. As in the case of the derivation trees of CFG&apos;s,
nodes are labeled by a member of some finite set of symbols
(perhaps only implicit in the grammar as in TAG&apos;s) used to de-
note derived structures. Frontier nodes are annotated by zero
arty functions corresponding to elementary structures. Each
treelet (an internal node with all its children) represents the use
of a rule that is encapsulated by the grammar The grammar
encapsulates (either explicitly or implicitly) a finite number of
rules that can be written as follows:
n &gt; 0
In the case of CFG&apos;s, for each production
</bodyText>
<equation confidence="0.42186725">
p = A urAr • • • UnAnUn+1
(where u, is a string of terminals) the function fp is defined as
follows.
fp(Xi, ..• Xn) = Ul X1 • • • UnXnUn+1
</equation>
<bodyText confidence="0.93165">
In the case of TAG&apos;s, a derivation step in which the derived
trees RI, • • • , On are adjoined into fi at rhe addresses • • • • in.
would involve the use of the following rule2.
</bodyText>
<equation confidence="0.779939">
/) • • • RIO
</equation>
<bodyText confidence="0.997459913043478">
The composition operations in the case of CFG&apos;s are parame-
terized by the productions. In TAG&apos;s the elementary tree and
addresses where adjunction takes place are used to instantiate
the operation.
To show that the derivation trees of any grammar in LCFRS
is a local set, we can rewrite the annotated derivation trees
such that every node is labelled by a pair to include the com-
position operations. These systems are similar to those de-
scribed by Pollard (1984) as Generalized Context-Free Gram-
mars (GCFG&apos;s). Unlike GCFG&apos;s, however, the composition
operations of LCFRS&apos;s are restricted to be linear (do not du-
plicate unboundedly large structures) and nonerasing (do not
erase unbounded structures, a restriction made in most modern
transformational grammars). These two restrictions impose the
constraint that the result of composing any two structures should
be a structure whose &amp;quot;size&amp;quot; is the sum of its constituents plus
some constant For example, the operation 4, discussed in the
case of CFG&apos;s (in Section 4.1) adds the constant equal to the
sum of the length of the strings VI, un+r•
Since we are considering formalisms with arbitrary struc-
tures it is difficult to precisely specify all of the restrictions
on the composition operations that we believe would appropri-
ately generalize the concatenation operation for the particular
</bodyText>
<footnote confidence="0.921167">
2We denote a tree derived from the elementazy tree 7 by the symbol 1.
</footnote>
<page confidence="0.998148">
108
</page>
<bodyText confidence="0.999951428571428">
structures used by the formalism. In considering recognition of
LCFRS&apos;s, we make further assumption concerning the contri-
bution of each structure to the input string, and how the com-
position operations combine structures in this respect. We can
show that languages generated by LCFRS&apos;s are semilinear as
long as the composition operation does not remove any terminal
symbols from its arguments.
</bodyText>
<subsectionHeader confidence="0.999922">
4.2 Semilinearity of LCFRL&apos;s
</subsectionHeader>
<bodyText confidence="0.999929709677419">
Semilinearity and the closely related constant growth property
(a consequence of semilinearity) have been discussed in the con-
text of grammars for natural languages by Joshi (1983/85) and
Berwick and Weinberg (1984). Roughly speaking, a language,
L, has the property of semilinearity if the number of occurrences
of each symbol in any string is a linear combination of the oc-
currences of these symbols in some fixed finite set of strings.
Thus, the length of any string in L is a linear combination of the
length of strings in some fixed finite subset of L, and thus L is
said to have the constant growth property. Although this prop-
erty is not structural, it depends on the structural property that
sentences can be built from a finite set of clauses of bounded
structure as noted by Joshi (1983/85).
The property of semilinearity is concerned only with the
occurrence of symbols in strings and not their order. Thus, any
language that is letter equivalent to a semilinear language is
also semilinear. Two strings are letter equivalent if they contain
equal number of occurrences of each terminal symbol, and two
languages are letter equivalent if every string in one language is
letter equivalent to a string in the other language and vice-versa.
Since every CFL is known to be semilinear (Parikh, 1966), in
order to show semilinearity of some language, we need only
show the existence of a letter equivalent CFL
Our definition of LCFRS&apos;s insists that the composition op-
erations are linear and nonerasing. Hence, the terminal sym-
bols appearing in the structures that are composed are not lost
(though a constant number of new symbols may be introduced).
If 0(A) gives the number of occurrences of each terminal in the
structure named by A, then, given the constraints imposed on
the formalism, for each rule A --. fp(Ai, , An) we have the
equality
</bodyText>
<equation confidence="0.99226">
t,b(A) = 0(Ai) + . . . + tfi(An) +
</equation>
<bodyText confidence="0.9992864">
where c„ is some constant. We can obtain a letter equivalent
CFL defined by a CFG in which the for each rule as above,
we have the production A —* A1 Anup where tk (up) = cp.
Thus, the language generated by a grammar of a LCFRS is
semilinear.
</bodyText>
<subsectionHeader confidence="0.996948">
43 Recognition of LCFRL&apos;s
</subsectionHeader>
<bodyText confidence="0.991875471698113">
We now turn our attention to the recognition of string languages
generated by these formalisms (LCFRL&apos;s). As suggested at the
end of Section 3, the restrictions that have been specified in
the definition of LCFRS&apos;s suggest that they can be efficiently
recognized. In this section for the purposes of showing that
polynomial time recognition is possible, we make the additional
restriction that the contribution of a derived structure to the in-
put string can be specified by a bounded sequence of substrings
of the input. Since each composition operation is linear and
nonerasing, a bounded sequences of substrings associated with
the resulting structure is obtained by combining the substrings in
each of its arguments using only the concatenation operation, in-
cluding each substring exactly once. CFG&apos;s, TAG&apos;s, MCTAG&apos;s
and HG&apos;s are all members of this class since they satisfy these
restrictions.
Giving a recognition algorithm for LCFRL&apos;s involves de-
scribing the substrings of the input that are spanned by the
structures derived by the LCFRS&apos;s and how the composition
operation combines these substrings. For example, in TAG&apos;s
a derived auxiliary tree spans two substrings (to the left and
right of the foot node), and the adjunction operation inserts an-
other substring (spanned by the subtree under the node where
adjunction takes place) between them (see Figure 3). We can
represent any derived tree of a TAG by the two substrings that
appear in its frontier, and then define how the adjunction opera-
tion concatenates the substrings. Similarly, for all the LCFRS&apos;s,
discussed in Section 2, we can define the relationship between a
structure and the sequence of substrings it spans, and the effect
of the composition operations on sequences of substrings.
A derived structure will be mapped onto a sequence
zi of substrings (not necessarily contiguous in the in-
put), and the composition operations will be mapped onto func-
tions that can defined as follows3.
f((zi,• • • , zni), (m.,• • • ,Yn3)) = (Z1, • • • , Zn3)
where each z, is the concatenation of strings from z,&apos;s and yk&apos;s.
The linear and nonerasing assumptions about the operations dis-
cussed in Section 4.1 require that each z, and yk is used exactly
once to define the strings zi, ,z1,3. Some of the operations
will be constant functions, corresponding to elementary struc-
tures, and will be written as f () = zi), where each z, is
a constant, the string of terminal symbols al an,,,.
This representation of structures by substrings and the com-
position operation by its effect on substrings is related to the
work of Rounds (1985). Although embedding this version of
LCFRS&apos;s in the framework of ILFP developed by Rounds (1985)
is straightforward, our motivation was to capture properties
shared by a family of grammatical systems and generalize them
defining a class of related formalisms. This class of formalisms
have the properties that their derivation trees are local sets, and
manipulate objects, using a finite number of composition oper-
ations that use a finite number of symbols. With the additional
assumptions, inspired by Rounds (1985), we can show that mem-
bers of this class can be recognized in polynomial time.
</bodyText>
<subsectionHeader confidence="0.99427">
4.3.1 Alternating Turing Machines
</subsectionHeader>
<bodyText confidence="0.999893">
We use Alternating Turing Machines (Chandra, Kozen, and
Stockmeyer, 1981) to show that polynomial time recognition
is possible for the languages discussed in Section 4.3. An ATM
has two types of states, existential and universal. In an existen-
tial state an ATM behaves like a nondeterministic TM, accepting
</bodyText>
<footnote confidence="0.8183195">
31n order to simplify the following discussion, we assume that each composition
operation is binary. It is easy to generalize to the case of n-ary operations.
</footnote>
<page confidence="0.998471">
109
</page>
<bodyText confidence="0.999945842105263">
if one of the applicable moves leads to acceptance; in an uni-
versal state the ATM accepts if all the applicable moves lead to
acceptance. An ATM may be thought of as spawning indepen-
dent processes for each applicable move. A k-tape ATM, M,
has a read-only input tape and k read-write work tapes. A step
of an ATM consists of reading a symbol from each tape and
optionally moving each head to the left or right one tape cell.
A configuration of M consists of a state of the finite control,
the nonblank contents of the input tape and k work tapes, and
the position of each head. The space of a configuration is the
sum of the lengths of the nonblank tape contents of the k work
tapes. M works in space S(n) if for every string that M ac-
cepts no configuration exceeds space S(n). It has been shown
in (Chandra et al., 1981) that if M works in space log n then
there is a deterministic TM which accepts the same language in
polynomial time. In the next section, we show how an ATM
can accept the strings generated by a grammar in a LCFRS for-
malism in logspace, and hence show that each family can be
recognized in polynomial time.
</bodyText>
<subsectionHeader confidence="0.628281">
4.3.2 Recognition by ATM
</subsectionHeader>
<bodyText confidence="0.999619219512195">
We define an ATM, M, recognizing a language generated by
a grammar, G, having the properties discussed in Section 43.
It can be seen that M performs a top-down recognition of the
input al ... nin logspace.
The rewrite rules and the definition of the composition op-
erations may be stored in the finite state control since G uses
a finite number of them. Suppose M has to determine whether
the k substrings ,.. .,ak can be derived from some symbol
A. Since each zi is a contiguous substring of the input (say
ai,), and no two substrings overlap, we can represent zi
by the pair of integers (i2, i2). We assume that M is in an ex-
istential state qA, with integers i1 and i2 representing zi in the
(2i — 1)th and 22th work tape, for 1 &lt; i &lt; k.
For each rule p : A fp(B, C) such that fp is mapped
onto the function fp defined by the following rule.
jp((xi,.. • ,rnt), (1ii, • • • • Yn3))= (Zi , • • • , Zk)
M breaks xi , zk into substrings xi, , xn, and
yi,...,y&amp;quot; conforming to the definition of fp. M spawns as
many processes as there are ways of breaking up ri , .. • , zt,
and rules with A on their left-hand-side. Each spawned process
must check if xi , , xn, and , yn, can be derived from
B and C, respectively. To do this, the x&apos;s and y&apos;s are stored
in the next 2ni + 2n2 tapes, and M goes to a universal state.
Two processes are spawned requiring B to derive z,..,
and C to derive yi , , y,. Thus, for example, one successor
process will be have M to be in the existential state qa with
the indices encoding xi , , xn, in the first 2n i tapes.
For rules p : A fpo such that fp is constant func-
tion, giving an elementary structure, fp is defined such that
fp() = (Si ... xi() where each z is a constant string. M must
enter a universal state and check that each of the k constant
substrings are in the appropriate place (as determined by the
contents of the first 2k work tapes) on the input tape. In addi-
tion to the tapes required to store the indices, M requires one
work tape for splitting the substrings. Thus, the ATM has no
more than 6km&amp;quot; + 1 work tapes, where km&amp;quot; is the maximum
number of substrings spanned by a derived structure. Since the
work tapes store integers (which can be written in binary) that
never exceed the size of the input, no configuration has space ex-
ceeding 0(log n). Thus, M works in logspace and recognition
can be done on a deterministic TM in polynomial tape.
</bodyText>
<sectionHeader confidence="0.999777" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999969086956522">
We have studied the structural descriptions (tree sets) that can
be assigned by various grammatical systems, and classified these
formalisms on the basis of two features: path complexity; and
path independence. We contrasted formalisms such as CFG&apos;s,
HG&apos;s, TAG&apos;s and MCTAG&apos;s, with formalisms such as IG&apos;s and
unificational systems such as LFG&apos;s and FUG&apos;s.
We address the question of whether or not a formalism
can generate only structural descriptions with independent paths.
This property reflects an important aspect of the underlying lin-
guistic theory associated with the formalism. In a grammar
which generates independent paths the derivations of sibling
constituents can not share an unbounded amount of information.
The importance of this property becomes clear in contrasting the-
ories underlying GPSG (Gazdar, Klein, Pulluna, and Sag, 1985),
and GB (as described by Berwick, 1984) with those underly-
ing LFG and FUG. It is interesting to note, however, that the
ability to produce a bounded number of dependent paths (where
two dependent paths can share an unbounded amount of infor-
mation) does not require machinery as powerful as that used in
LFG, FUG and IG&apos;s. As illustrated by MCTAG&apos;s, it is possible
for a formalism to give tree sets with bounded dependent paths
while still sharing the constrained rewriting properties of CFG&apos;s,
HG&apos;s, and TAG&apos;s.
In order to observe the similarity between these constrained
systems, it is crucial to abstract away from the details of the
structures and operations used by the system. The similarities
become apparent when they are studied at the level of deriva-
tion structures: derivation nee sets of CFG&apos;s, HG&apos;s, TAG&apos;s,
and MCTAG&apos;s are all local sets. Independence of paths at this
level reflects context freeness of rewriting and suggests why they
can be recognized efficiently. As suggested in Section 4.3.2, a
derivation with independent paths can be divided into subcom-
putations with limited sharing of information.
We outlined the definition of a family of constrained gram-
matical formalisms, called Linear Context-Free Rewriting Sys-
tems. This family represents an attempt to generalize the prop-
erties shared by CFG&apos;s, HG&apos;s, TAG&apos;s, and MCTAG&apos;s. Like
HG&apos;s, TAG&apos;s, and MCTAG&apos;s, members of LCFRS can manipu-
late structures more complex than terminal strings and use com-
position operations that are more complex that concatenation.
We place certain restrictions on the composition operations of
LCFRS&apos;s, restrictions that are shared by the composition opera-
tions of the constrained grammatical systems that we have con-
sidered. The operations must be linear and nonerasing, i.e., they
can not duplicate or erase structure from their arguments. Notice
that even though IG&apos;s and LFG&apos;s involve CFG-like productions,
</bodyText>
<page confidence="0.992249">
110
</page>
<bodyText confidence="0.999932709090909">
they are (linguistically) fundamentally different from CFG&apos;s be-
cause the composition operations need not be linear. By sharing
stacks (in IG&apos;s) or by using nonlinear equations over f-structures
(in FUG&apos;s and LFG&apos;s), structures with unbounded dependencies
between paths can be generated. LCFRS&apos;s share several proper-
ties possessed by the class of mildly context-sensitive formalisms
discussed by Joshi (1983/85). The results described in this paper
suggest a characterization of mild context-sensitivity in terms of
generalized context-freeness.
Having defined LCFRS&apos;s, in Section 4.2 we established the
semilinearity (and hence constant growth property) of the lan-
guages generated. In considering the recognition of these lan-
guages, we were forced to be more specific regarding the re-
lationship between the structures derived by these formalisms
and the substrings they span. We insisted that each structure
dominates a bounded number of (not necessarily adjacent) sub-
strings. The composition operations are mapped onto operations
that use concatenation to define the substrings spanned by the
resulting structures. We showed that any system defined in this
way can be recognized in polynomial time. Members of LCFRS
whose operations have this property can be translated into the
ILFP notation (Rounds, 1985). However, in order to capture the
properties of various grammatical systems under consideration,
our notation is more restrictive that ILFP, which was designed
as a general logical notation to characterize the complete class of
languages that are recognizable in polynomial time. It is known
that CFG&apos;s, HG&apos;s, and TAG&apos;s can be recognized in polynomial
time since polynomial time algorithms exist in for each of these
formalisms. A corollary of the result of Section 4.3 is that poly-
nomial time recognition of MCTAG&apos;s is possible.
As discussed in Section 3, independent paths in tree sets,
rather than the path complexity, may be crucial in characteriz-
ing semilinearity and polynomial time recognition. We would
like to relax somewhat the constraint on the path complexity
of formalisms in LCFRS. Formalisms such as the restricted in-
dexed grammars (Gazdar, 1985) and members of the hierarchy
of grammatical systems given by Weir (1987) have independent
paths, but more complex path sets. Since these path sets are
semilinear, the property of independent paths in their tree sets
is sufficient to cause semilinearity of the languages generated
by them. In addition, the restricted version of CG&apos;s (discussed
in Section 6) generates tree sets with independent paths and we
hope that it can be included in a more general definition of
LCFRS&apos;s containing formalisms whose tree sets have path sets
that are themselves LCFRL&apos;s (as in the case of the restricted
indexed grammars, and the hierarchy defined by Weir).
LCFRS&apos;s have only been loosely defined in this paper; we
have yet to provide a complete set of formal properties associ-
ated with members of this class. In this paper, our goal has been
to use the notion of LCFRS&apos;s to classify grammatical systems
on the basis of their strong generative capacity. In considering
this aspect of a formalism, we hope to better understand the re-
lationship between the structural descriptions generated by the
grammars of a formalism, and the properties of semilinearity
and polynomial recognizability.
</bodyText>
<sectionHeader confidence="0.998444" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.987705255813954">
Berwick, R., 1984. Strong generative capacity, weak generative capac-
ity, and modern linguistic theories. Campus. Ling. 10:189-202.
Berwick, R. and Weinberg, A., 1984. The Grammatical Basis of Lin-
guLstit Performance. MIT Press, Cambridge, MA.
Bresnan, J. W.; Kaplan, R. M.; Peters, P. S.; and Zaenen, A., 1982.
Cross-serial Dependencies in Dutch. Ling. Inquiry 13:613-635.
Chandra, A. K.; Kozen, D. C.; and Stockmeyer, L. J., 1981. Alternation.
J. ACM 28:114-122.
Gazdar, G., 1985. Applicability of Indexed Grammars to Natural Lan-
guages. Technical Report CSLI-85-34, Center for Study of Language
and Information.
Gazdar, G.; Klein, E.; Pullum, G. K.; and Sag, I. A., 1985. General-
ized Phrase Structure Grammars. Blackwell Publishing, Oxford. Also
published by Harvard University Press, Cambridge, MA.
Joshi, A. K., 1985. How Much Context-Sensitivity is Necessary for
Characterizing Structural Descriptions — Tree Adjoining Grammars. In
Dowty, D.; Karttunen, L.; and Zwicky, A. (editors), Natural Language
Processing — Theoretical, Computational and Psychological Perspec-
tive. Cambridge University Press, New York, NY. Originally presented
in 1983.
Joshi, A. K., 1987. An Introduction to Tree Adjoining Grammars. In
Manaster-Ramer, A. (editor), Mathematics of Language. John Ben-
jarnins, Amsterdam.
Joshi, A. K.; Levy, L. S.; and Takahashi, M., 1975. Tree Adjunct
Grammars. J. Comilla. Syst. Sci. 10(1).
Parikh, R., 1966. On Context Free Languages. J. ACM 13:570-581.
Pollard, C., 1984. Generalized Phrase Structure Grammars, Head
Grammars and Natural Language. PhD thesis, Stanford University.
Rounds, W. C. LFP: A Logic for Linguistic Descriptions and an Anal-
ysis of its Complexity. To appear in Campus. Ling.
Rounds, W. C., 1969. Context-free Grammars on Trees. In IEEE 10th
Annual Symposium on Switching and Automata Theory.
Steedman, M. J., 1985. Dependency and Coordination in the Grammar
of Dutch and English. Language 61:523-568.
Steedman, M., 1986. Combinatory Grammars and Parasitic Gaps. Nat-
ural Language and Linguistic Theory (to appear).
Thatcher, J. W., 1973. Tree Automata: An informal survey. In Aho,
A. V. (editor), Currents in the Theory of Computing, pages 143-172.
Prentice Hall Inc., Englewood Cliffs, NJ.
Weir, D. J., 1987. Context-Free Grammars to Tree Adjoining Gran-
nvnars and Beyond. Technical Report, Department of Computer and
Information Science, University of Pennsylvania, Philadelphia.
1 1 1
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.962950">
<title confidence="0.994061">CHARACTERIZING STRUCTURAL DESCRIPTIONS PRODUCED BY VARIOUS GRAMMATICAL FORMALISMS*</title>
<author confidence="0.999959">K Vijay-Shanker David J Weir Aravind K Joshi</author>
<affiliation confidence="0.9999075">Department of Computer and Information Science University of Pennsylvania</affiliation>
<address confidence="0.99867">Philadelphia, Pa 19104</address>
<abstract confidence="0.997753333333333">We consider the structural descriptions produced by various grammatical formalisms in terms of the complexity of the paths and the relationship between paths in the sets of structural descriptions that each system can generate. In considering the relationship between formalisms, we show that it is useful to abstract away from the details of the formalism, and examine the nature of their derivation process as reflected by properties their trees. find that several of the formalisms considered can be seen as being closely related since they have derivation tree sets with the same structure as those produced by Context-Free Grammars On the basis of this observation, we describe a class of formalisms which we call Linear Context- Free Rewriting Systems, and show they are recognizable in polynomial time and generate only semilinear languages.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Berwick</author>
</authors>
<title>Strong generative capacity, weak generative capacity, and modern linguistic theories.</title>
<date>1984</date>
<journal>Campus. Ling.</journal>
<pages>10--189</pages>
<contexts>
<context position="1670" citStr="Berwick (1984)" startWordPosition="245" endWordPosition="246">time and generate only semilinear languages. 1 Introduction Much of the study of grammatical systems in computational linguistics has been focused on the weak generative capacity of grammatical formalism. Little attention, however, has been paid to the structural descriptions that these formalisms can assign to strings, i.e. their strong generative capacity. This aspect of the formalism is both linguistically and computationally important. For example, Gazdar (1985) discusses the applicability of Indexed Grammars (IG&apos;s) to Natural Language in terms of the structural descriptions assigned; and Berwick (1984) discusses the strong generative capacity of Lexical-Functional Grammar (LFG) and Government and Bindings grammars (GB). The work of Thatcher (1973) and Rounds (1969) define formal systems that generate tree sets that are related to CFG&apos;s and IG&apos;s. We consider properties of the tree sets generated by CFG&apos;s, Tree Adjoining Grammars (TAG&apos;s), Head Grammars (HG&apos;s), Categorial Grammars (CG&apos;s), and IG&apos;s. We examine both the complexity of the paths of trees in the tree sets, and the kinds of dependencies that the formalisms can impose between paths. These two properties of the tree sets are not only </context>
<context position="33888" citStr="Berwick, 1984" startWordPosition="5897" endWordPosition="5898">, with formalisms such as IG&apos;s and unificational systems such as LFG&apos;s and FUG&apos;s. We address the question of whether or not a formalism can generate only structural descriptions with independent paths. This property reflects an important aspect of the underlying linguistic theory associated with the formalism. In a grammar which generates independent paths the derivations of sibling constituents can not share an unbounded amount of information. The importance of this property becomes clear in contrasting theories underlying GPSG (Gazdar, Klein, Pulluna, and Sag, 1985), and GB (as described by Berwick, 1984) with those underlying LFG and FUG. It is interesting to note, however, that the ability to produce a bounded number of dependent paths (where two dependent paths can share an unbounded amount of information) does not require machinery as powerful as that used in LFG, FUG and IG&apos;s. As illustrated by MCTAG&apos;s, it is possible for a formalism to give tree sets with bounded dependent paths while still sharing the constrained rewriting properties of CFG&apos;s, HG&apos;s, and TAG&apos;s. In order to observe the similarity between these constrained systems, it is crucial to abstract away from the details of the str</context>
</contexts>
<marker>Berwick, 1984</marker>
<rawString>Berwick, R., 1984. Strong generative capacity, weak generative capacity, and modern linguistic theories. Campus. Ling. 10:189-202.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Berwick</author>
<author>A Weinberg</author>
</authors>
<title>The Grammatical Basis of LinguLstit Performance.</title>
<date>1984</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="23812" citStr="Berwick and Weinberg (1984)" startWordPosition="4116" endWordPosition="4119">sed by the formalism. In considering recognition of LCFRS&apos;s, we make further assumption concerning the contribution of each structure to the input string, and how the composition operations combine structures in this respect. We can show that languages generated by LCFRS&apos;s are semilinear as long as the composition operation does not remove any terminal symbols from its arguments. 4.2 Semilinearity of LCFRL&apos;s Semilinearity and the closely related constant growth property (a consequence of semilinearity) have been discussed in the context of grammars for natural languages by Joshi (1983/85) and Berwick and Weinberg (1984). Roughly speaking, a language, L, has the property of semilinearity if the number of occurrences of each symbol in any string is a linear combination of the occurrences of these symbols in some fixed finite set of strings. Thus, the length of any string in L is a linear combination of the length of strings in some fixed finite subset of L, and thus L is said to have the constant growth property. Although this property is not structural, it depends on the structural property that sentences can be built from a finite set of clauses of bounded structure as noted by Joshi (1983/85). The property </context>
</contexts>
<marker>Berwick, Weinberg, 1984</marker>
<rawString>Berwick, R. and Weinberg, A., 1984. The Grammatical Basis of LinguLstit Performance. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Bresnan</author>
<author>R M Kaplan</author>
<author>P S Peters</author>
<author>A Zaenen</author>
</authors>
<date>1982</date>
<booktitle>Cross-serial Dependencies in Dutch. Ling. Inquiry</booktitle>
<pages>13--613</pages>
<marker>Bresnan, Kaplan, Peters, Zaenen, 1982</marker>
<rawString>Bresnan, J. W.; Kaplan, R. M.; Peters, P. S.; and Zaenen, A., 1982. Cross-serial Dependencies in Dutch. Ling. Inquiry 13:613-635.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Chandra</author>
<author>D C Kozen</author>
<author>L J Stockmeyer</author>
</authors>
<date>1981</date>
<journal>Alternation. J. ACM</journal>
<pages>28--114</pages>
<contexts>
<context position="29044" citStr="Chandra, Kozen, and Stockmeyer, 1981" startWordPosition="4999" endWordPosition="5003">ILFP developed by Rounds (1985) is straightforward, our motivation was to capture properties shared by a family of grammatical systems and generalize them defining a class of related formalisms. This class of formalisms have the properties that their derivation trees are local sets, and manipulate objects, using a finite number of composition operations that use a finite number of symbols. With the additional assumptions, inspired by Rounds (1985), we can show that members of this class can be recognized in polynomial time. 4.3.1 Alternating Turing Machines We use Alternating Turing Machines (Chandra, Kozen, and Stockmeyer, 1981) to show that polynomial time recognition is possible for the languages discussed in Section 4.3. An ATM has two types of states, existential and universal. In an existential state an ATM behaves like a nondeterministic TM, accepting 31n order to simplify the following discussion, we assume that each composition operation is binary. It is easy to generalize to the case of n-ary operations. 109 if one of the applicable moves leads to acceptance; in an universal state the ATM accepts if all the applicable moves lead to acceptance. An ATM may be thought of as spawning independent processes for e</context>
<context position="30263" citStr="Chandra et al., 1981" startWordPosition="5222" endWordPosition="5225"> each applicable move. A k-tape ATM, M, has a read-only input tape and k read-write work tapes. A step of an ATM consists of reading a symbol from each tape and optionally moving each head to the left or right one tape cell. A configuration of M consists of a state of the finite control, the nonblank contents of the input tape and k work tapes, and the position of each head. The space of a configuration is the sum of the lengths of the nonblank tape contents of the k work tapes. M works in space S(n) if for every string that M accepts no configuration exceeds space S(n). It has been shown in (Chandra et al., 1981) that if M works in space log n then there is a deterministic TM which accepts the same language in polynomial time. In the next section, we show how an ATM can accept the strings generated by a grammar in a LCFRS formalism in logspace, and hence show that each family can be recognized in polynomial time. 4.3.2 Recognition by ATM We define an ATM, M, recognizing a language generated by a grammar, G, having the properties discussed in Section 43. It can be seen that M performs a top-down recognition of the input al ... nin logspace. The rewrite rules and the definition of the composition operat</context>
</contexts>
<marker>Chandra, Kozen, Stockmeyer, 1981</marker>
<rawString>Chandra, A. K.; Kozen, D. C.; and Stockmeyer, L. J., 1981. Alternation. J. ACM 28:114-122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
</authors>
<title>Applicability of Indexed Grammars to Natural Languages.</title>
<date>1985</date>
<tech>Technical Report CSLI-85-34,</tech>
<institution>Center for Study of Language and Information.</institution>
<contexts>
<context position="1526" citStr="Gazdar (1985)" startWordPosition="224" endWordPosition="225">bservation, we describe a class of formalisms which we call Linear ContextFree Rewriting Systems, and show they are recognizable in polynomial time and generate only semilinear languages. 1 Introduction Much of the study of grammatical systems in computational linguistics has been focused on the weak generative capacity of grammatical formalism. Little attention, however, has been paid to the structural descriptions that these formalisms can assign to strings, i.e. their strong generative capacity. This aspect of the formalism is both linguistically and computationally important. For example, Gazdar (1985) discusses the applicability of Indexed Grammars (IG&apos;s) to Natural Language in terms of the structural descriptions assigned; and Berwick (1984) discusses the strong generative capacity of Lexical-Functional Grammar (LFG) and Government and Bindings grammars (GB). The work of Thatcher (1973) and Rounds (1969) define formal systems that generate tree sets that are related to CFG&apos;s and IG&apos;s. We consider properties of the tree sets generated by CFG&apos;s, Tree Adjoining Grammars (TAG&apos;s), Head Grammars (HG&apos;s), Categorial Grammars (CG&apos;s), and IG&apos;s. We examine both the complexity of the paths of trees i</context>
<context position="4221" citStr="Gazdar (1985)" startWordPosition="666" endWordPosition="667">r&apos;. We define the path set of a tree 1 as the set of strings that label a path from the root to frontier of 7. The path set of a tree set is the union of the path sets of trees in that tree set. It can be easily shown from Thatcher&apos;s result that the path set of every local set is a regular set. As a result, CFG&apos;s can not provide the structural descriptions in which there are nested dependencies between symbols labelling a path. For example, CFG&apos;s cannot produce trees of the form shown in Figure 1 in which there are nested dependencies between S and NP nodes appearing on the spine of the tree. Gazdar (1985) argues this is the appropriate analysis of unbounded dependencies in the hypothetical Scandinavian language Norwedish. He also argues that paired English complementizers may also require structural descriptions whose path sets have nested dependencies. 2.2 Head Grammars and Generalized CFG&apos;s Head Grammars (HG&apos;s), introduced by Pollard (1984), is a formalism that manipulates headed strings: i.e., strings, one of whose symbols is distinguished as the head. Not only is concatenation of these strings possible, but head wrapping can be used to split a string and wrap it around another string. The </context>
<context position="6776" citStr="Gazdar (1985)" startWordPosition="1117" endWordPosition="1118"> are either initial trees or auxiliary trees. Trees are composed using an operation called adjoining, which is defined as follows. Let n be some node labeled X in a tree -y (see Figure 3). Let 71 be a tree with root and foot labeled by X. When 7&apos; is adjoined at ?I in the tree 7 we obtain a tree v&amp;quot;. The subtree under,; is excised from 7, the tree 7&apos; is inserted in its place and the excised subtree is inserted below the foot of y&apos;. It can be shown that the path set of the tree set generated by a TAG G is a context-free language. TAG&apos;s can be used to give the structural descriptions discussed by Gazdar (1985) for the unbounded nested dependencies in Norwedish, for cross serial dependencies in Dutch subordinate clauses, and for the nestings of paired English complementizers. From the definition of TAG&apos;s, it follows that the choice of adjunction is not dependent on the history of the derivation. Like CFG&apos;s, the choice is predetermined by a finite number of rules encapsulated in the grammar. Thus, the derivation trees for TAG&apos;s have the same structure as local sets. As with HG&apos;s derivation structures are annotated; in the case of TAG&apos;s, by the trees used for adjunction and addresses of nodes of the e</context>
<context position="8608" citStr="Gazdar (1985)" startWordPosition="1437" endWordPosition="1438"> a local set, nodes are labeled by pairs consisting of the name of an elementary tree and the address at which it was adjoined, instead of labelling edges with addresses. The following rule corresponds to the above derivation, where 71, , 7k are derived from the auxiliary trees , , fik, respectively. (7&apos;,n) (fli,ni)...(/3k, nk) for all addresses n in some elementary tree at which 7&apos; can be adjoined. If 7&apos; is an initial tree we do not include an address on the left-hand side. 2.4 Indexed Grammars There has been recent interest in the application of Indexed Grammars (IG&apos;s) to natural languages. Gazdar (1985) considers a number of linguistic analyses which IG&apos;s (but not CFG&apos;s) can make, for example, the Norwedish example shown in Figure 1. The work of Rounds (1969) shows that the path sets of trees derived by IG&apos;s (like those of TAG&apos;s) are context-free languages. Trees derived by IG&apos;s exhibit a property that is not exhibited by the trees sets derived by TAG&apos;s or CFG&apos;s. Informally, two or more paths can be dependent on each other: for example, they could be required to be of equal length as in the trees in Figure 4. N V SLC Pia Ww NP VP RRI V S LC2 I I Mire !ripen NP VP 105 b2 push q share stack po</context>
<context position="9912" citStr="Gazdar (1985)" startWordPosition="1696" endWordPosition="1697">he path set for trees in Figure 4a is regular, no CFG } /A /B a b A /A /B a b (b) Figure 4: Example with dependent paths generates such a tree set. We focus on this difference between the tree sets of CFG&apos;s and IG&apos;s, and formalize the notion of dependence between paths in a tree set in Section 3. An IG can be viewed as a CFG in which each nonterminal is associated with a stack. Each production can push or pop symbols on the stack as can be seen in the following productions that generate tree of the form shown in Figure 4b. S(a) S(170) S(a) A(a)B(a) A(lia) —* aA(a) B(ria) --• bB(a) A() a B() b Gazdar (1985) argues that sharing of stacks can be used to give analyses for coordination. Analogous to the sharing of stacks in IC&apos;s, Lexical-Functional Grammar&apos;s (LFG&apos;s) use the unification of unbounded hierarchical structures. Unification is used in LFG&apos;s to produce structures having two dependent spines of unbounded length as in Figure 5. Bresnan, Kaplan, Peters, and Zaenen (1982) argue that these structures are needed to describe crossed-serial dependencies in Dutch subordinate clauses. Gazdar (1985) considers a restriction of IG&apos;s in which no more NP VP NP VP V&apos; I V\ /N. Piet NP VP V&apos; I MN&amp; NP sir V </context>
<context position="37934" citStr="Gazdar, 1985" startWordPosition="6522" endWordPosition="6523">ecognizable in polynomial time. It is known that CFG&apos;s, HG&apos;s, and TAG&apos;s can be recognized in polynomial time since polynomial time algorithms exist in for each of these formalisms. A corollary of the result of Section 4.3 is that polynomial time recognition of MCTAG&apos;s is possible. As discussed in Section 3, independent paths in tree sets, rather than the path complexity, may be crucial in characterizing semilinearity and polynomial time recognition. We would like to relax somewhat the constraint on the path complexity of formalisms in LCFRS. Formalisms such as the restricted indexed grammars (Gazdar, 1985) and members of the hierarchy of grammatical systems given by Weir (1987) have independent paths, but more complex path sets. Since these path sets are semilinear, the property of independent paths in their tree sets is sufficient to cause semilinearity of the languages generated by them. In addition, the restricted version of CG&apos;s (discussed in Section 6) generates tree sets with independent paths and we hope that it can be included in a more general definition of LCFRS&apos;s containing formalisms whose tree sets have path sets that are themselves LCFRL&apos;s (as in the case of the restricted indexed</context>
</contexts>
<marker>Gazdar, 1985</marker>
<rawString>Gazdar, G., 1985. Applicability of Indexed Grammars to Natural Languages. Technical Report CSLI-85-34, Center for Study of Language and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
<author>E Klein</author>
<author>G K Pullum</author>
<author>I A Sag</author>
</authors>
<title>Generalized Phrase Structure Grammars.</title>
<date>1985</date>
<publisher>Blackwell Publishing,</publisher>
<location>Oxford.</location>
<note>Also published by</note>
<marker>Gazdar, Klein, Pullum, Sag, 1985</marker>
<rawString>Gazdar, G.; Klein, E.; Pullum, G. K.; and Sag, I. A., 1985. Generalized Phrase Structure Grammars. Blackwell Publishing, Oxford. Also published by Harvard University Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>How Much Context-Sensitivity is Necessary for Characterizing Structural Descriptions — Tree Adjoining Grammars.</title>
<date>1985</date>
<booktitle>Natural Language Processing — Theoretical, Computational and Psychological Perspective.</booktitle>
<editor>In Dowty, D.; Karttunen, L.; and Zwicky, A. (editors),</editor>
<publisher>Cambridge University Press,</publisher>
<location>New York, NY.</location>
<note>Originally presented in</note>
<marker>Joshi, 1985</marker>
<rawString>Joshi, A. K., 1985. How Much Context-Sensitivity is Necessary for Characterizing Structural Descriptions — Tree Adjoining Grammars. In Dowty, D.; Karttunen, L.; and Zwicky, A. (editors), Natural Language Processing — Theoretical, Computational and Psychological Perspective. Cambridge University Press, New York, NY. Originally presented in 1983.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
</authors>
<title>An Introduction to Tree Adjoining Grammars.</title>
<date>1987</date>
<booktitle>Mathematics of Language. John Benjarnins,</booktitle>
<editor>In Manaster-Ramer, A. (editor),</editor>
<location>Amsterdam.</location>
<contexts>
<context position="12663" citStr="Joshi (1987)" startWordPosition="2150" endWordPosition="2151"> language which can not be generated by either TAG&apos;s or HG&apos;s. 0n0&apos;i&apos;i0&apos;2&amp;quot;bin242bn I n = 711 + n2 } On the other hand, no linguistic use is made of this general form of composition and Steedman (personal communication) and Steedman (1986) argues that a more limited definition of composition is more natural. With this restriction the resulting tree sets will have independent paths. The equivalence of CC&apos;s with this restriction to TAG&apos;s and HG&apos;s is, however, still an open problem. 2.6 Multicomponent TAG&apos;s An extension of the TAG system was introduced by Joshi et al. (1975) and later redefined by Joshi (1987) in which the adjunction operation is defined on sets of elementary trees rather than single trees. A multicomponent Tree Adjoining Grammar (MCTAG) consists of a finite set of finite elementary tree sets. We must adjoin all trees in an auxiliary tree set together as a single step in the derivation. The adjunction operation with respect to tree sets (multicomponent adjunction) is defined as follows. /A /B a b /A /B a b (a) a Mt #12 106 Each member of a set of trees can be adjoined into distinct nodes of trees in a single elementary tree set, i.e, derivations always involve the adjunction of a d</context>
</contexts>
<marker>Joshi, 1987</marker>
<rawString>Joshi, A. K., 1987. An Introduction to Tree Adjoining Grammars. In Manaster-Ramer, A. (editor), Mathematics of Language. John Benjarnins, Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
<author>M Takahashi</author>
</authors>
<date>1975</date>
<journal>Tree Adjunct Grammars. J. Comilla. Syst. Sci.</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="12627" citStr="Joshi et al. (1975)" startWordPosition="2142" endWordPosition="2145"> this definition can generate the following language which can not be generated by either TAG&apos;s or HG&apos;s. 0n0&apos;i&apos;i0&apos;2&amp;quot;bin242bn I n = 711 + n2 } On the other hand, no linguistic use is made of this general form of composition and Steedman (personal communication) and Steedman (1986) argues that a more limited definition of composition is more natural. With this restriction the resulting tree sets will have independent paths. The equivalence of CC&apos;s with this restriction to TAG&apos;s and HG&apos;s is, however, still an open problem. 2.6 Multicomponent TAG&apos;s An extension of the TAG system was introduced by Joshi et al. (1975) and later redefined by Joshi (1987) in which the adjunction operation is defined on sets of elementary trees rather than single trees. A multicomponent Tree Adjoining Grammar (MCTAG) consists of a finite set of finite elementary tree sets. We must adjoin all trees in an auxiliary tree set together as a single step in the derivation. The adjunction operation with respect to tree sets (multicomponent adjunction) is defined as follows. /A /B a b /A /B a b (a) a Mt #12 106 Each member of a set of trees can be adjoined into distinct nodes of trees in a single elementary tree set, i.e, derivations </context>
</contexts>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>Joshi, A. K.; Levy, L. S.; and Takahashi, M., 1975. Tree Adjunct Grammars. J. Comilla. Syst. Sci. 10(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Parikh</author>
</authors>
<title>On Context Free Languages.</title>
<date>1966</date>
<journal>J. ACM</journal>
<pages>13--570</pages>
<contexts>
<context position="24902" citStr="Parikh, 1966" startWordPosition="4306" endWordPosition="4307">ty that sentences can be built from a finite set of clauses of bounded structure as noted by Joshi (1983/85). The property of semilinearity is concerned only with the occurrence of symbols in strings and not their order. Thus, any language that is letter equivalent to a semilinear language is also semilinear. Two strings are letter equivalent if they contain equal number of occurrences of each terminal symbol, and two languages are letter equivalent if every string in one language is letter equivalent to a string in the other language and vice-versa. Since every CFL is known to be semilinear (Parikh, 1966), in order to show semilinearity of some language, we need only show the existence of a letter equivalent CFL Our definition of LCFRS&apos;s insists that the composition operations are linear and nonerasing. Hence, the terminal symbols appearing in the structures that are composed are not lost (though a constant number of new symbols may be introduced). If 0(A) gives the number of occurrences of each terminal in the structure named by A, then, given the constraints imposed on the formalism, for each rule A --. fp(Ai, , An) we have the equality t,b(A) = 0(Ai) + . . . + tfi(An) + where c„ is some con</context>
</contexts>
<marker>Parikh, 1966</marker>
<rawString>Parikh, R., 1966. On Context Free Languages. J. ACM 13:570-581.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
</authors>
<title>Generalized Phrase Structure Grammars, Head Grammars and Natural Language. PhD thesis,</title>
<date>1984</date>
<institution>Stanford University.</institution>
<contexts>
<context position="4565" citStr="Pollard (1984)" startWordPosition="712" endWordPosition="713">al descriptions in which there are nested dependencies between symbols labelling a path. For example, CFG&apos;s cannot produce trees of the form shown in Figure 1 in which there are nested dependencies between S and NP nodes appearing on the spine of the tree. Gazdar (1985) argues this is the appropriate analysis of unbounded dependencies in the hypothetical Scandinavian language Norwedish. He also argues that paired English complementizers may also require structural descriptions whose path sets have nested dependencies. 2.2 Head Grammars and Generalized CFG&apos;s Head Grammars (HG&apos;s), introduced by Pollard (1984), is a formalism that manipulates headed strings: i.e., strings, one of whose symbols is distinguished as the head. Not only is concatenation of these strings possible, but head wrapping can be used to split a string and wrap it around another string. The productions of HG&apos;s are very similar to those of CFG&apos;s except that the operation used must be made explicit. Thus, the tree sets generated by HG&apos;s are similar to those of CFG&apos;s, with each node annotated by the operation (concatenation or wrapping) used to combine the headed strings derived by the daughters of 1Thatckier actually characterized</context>
<context position="22223" citStr="Pollard (1984)" startWordPosition="3871" endWordPosition="3872">p in which the derived trees RI, • • • , On are adjoined into fi at rhe addresses • • • • in. would involve the use of the following rule2. /) • • • RIO The composition operations in the case of CFG&apos;s are parameterized by the productions. In TAG&apos;s the elementary tree and addresses where adjunction takes place are used to instantiate the operation. To show that the derivation trees of any grammar in LCFRS is a local set, we can rewrite the annotated derivation trees such that every node is labelled by a pair to include the composition operations. These systems are similar to those described by Pollard (1984) as Generalized Context-Free Grammars (GCFG&apos;s). Unlike GCFG&apos;s, however, the composition operations of LCFRS&apos;s are restricted to be linear (do not duplicate unboundedly large structures) and nonerasing (do not erase unbounded structures, a restriction made in most modern transformational grammars). These two restrictions impose the constraint that the result of composing any two structures should be a structure whose &amp;quot;size&amp;quot; is the sum of its constituents plus some constant For example, the operation 4, discussed in the case of CFG&apos;s (in Section 4.1) adds the constant equal to the sum of the len</context>
</contexts>
<marker>Pollard, 1984</marker>
<rawString>Pollard, C., 1984. Generalized Phrase Structure Grammars, Head Grammars and Natural Language. PhD thesis, Stanford University.</rawString>
</citation>
<citation valid="false">
<authors>
<author>W C Rounds</author>
</authors>
<title>LFP: A Logic for Linguistic Descriptions and an Analysis of its Complexity.</title>
<note>To appear in Campus. Ling.</note>
<marker>Rounds, </marker>
<rawString>Rounds, W. C. LFP: A Logic for Linguistic Descriptions and an Analysis of its Complexity. To appear in Campus. Ling.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W C Rounds</author>
</authors>
<title>Context-free Grammars on Trees.</title>
<date>1969</date>
<booktitle>In IEEE 10th Annual Symposium on Switching and Automata Theory.</booktitle>
<contexts>
<context position="1836" citStr="Rounds (1969)" startWordPosition="268" endWordPosition="269">ve capacity of grammatical formalism. Little attention, however, has been paid to the structural descriptions that these formalisms can assign to strings, i.e. their strong generative capacity. This aspect of the formalism is both linguistically and computationally important. For example, Gazdar (1985) discusses the applicability of Indexed Grammars (IG&apos;s) to Natural Language in terms of the structural descriptions assigned; and Berwick (1984) discusses the strong generative capacity of Lexical-Functional Grammar (LFG) and Government and Bindings grammars (GB). The work of Thatcher (1973) and Rounds (1969) define formal systems that generate tree sets that are related to CFG&apos;s and IG&apos;s. We consider properties of the tree sets generated by CFG&apos;s, Tree Adjoining Grammars (TAG&apos;s), Head Grammars (HG&apos;s), Categorial Grammars (CG&apos;s), and IG&apos;s. We examine both the complexity of the paths of trees in the tree sets, and the kinds of dependencies that the formalisms can impose between paths. These two properties of the tree sets are not only linguistically relevant, but also have computational importance. By considering derivation trees, and thus abstracting away from the details of the composition operat</context>
<context position="8767" citStr="Rounds (1969)" startWordPosition="1464" endWordPosition="1465"> addresses. The following rule corresponds to the above derivation, where 71, , 7k are derived from the auxiliary trees , , fik, respectively. (7&apos;,n) (fli,ni)...(/3k, nk) for all addresses n in some elementary tree at which 7&apos; can be adjoined. If 7&apos; is an initial tree we do not include an address on the left-hand side. 2.4 Indexed Grammars There has been recent interest in the application of Indexed Grammars (IG&apos;s) to natural languages. Gazdar (1985) considers a number of linguistic analyses which IG&apos;s (but not CFG&apos;s) can make, for example, the Norwedish example shown in Figure 1. The work of Rounds (1969) shows that the path sets of trees derived by IG&apos;s (like those of TAG&apos;s) are context-free languages. Trees derived by IG&apos;s exhibit a property that is not exhibited by the trees sets derived by TAG&apos;s or CFG&apos;s. Informally, two or more paths can be dependent on each other: for example, they could be required to be of equal length as in the trees in Figure 4. N V SLC Pia Ww NP VP RRI V S LC2 I I Mire !ripen NP VP 105 b2 push q share stack pop pop n ar ar b b2 IG&apos;s can generate trees with dependent paths as in Figure 4b. Although the path set for trees in Figure 4a is regular, no CFG } /A /B a b A </context>
</contexts>
<marker>Rounds, 1969</marker>
<rawString>Rounds, W. C., 1969. Context-free Grammars on Trees. In IEEE 10th Annual Symposium on Switching and Automata Theory.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M J Steedman</author>
</authors>
<date>1985</date>
<booktitle>Dependency and Coordination in the Grammar of Dutch and English. Language</booktitle>
<pages>61--523</pages>
<contexts>
<context position="11414" citStr="Steedman (1985)" startWordPosition="1944" endWordPosition="1945">t to this restricted system. Thus, TAG&apos;s can not give analyses in which dependencies between arbitrarily large branches exist. 2.5 Categorial Grammars Steedman (1986) considers Categorial Grammars in which both the operations of function application and composition may be used, and in which function can specify whether they take their arguments from their right or left. While the generative power of CG&apos;s is greater that of CFG&apos;s, it appears to be highly constrained. Hence, their relationship to formalisms such as HG&apos;s and TAG&apos;s is of interest. On the one hand, the definition of composition in Steedman (1985), which technically permits composition of functions with unbounded number of arguments, generates tree sets with dependent paths such as those shown in Figure 6. This kind of dependency arises from the use of the a 6} Figure 6: Dependent branches from Categorial Grammars composition operation to compose two arbitrarily large categories. This allows an unbounded amount of information about two separate paths (e.g. an encoding of their length) to be combined and used to influence the later derivation. A consequence of the ability to generate tree sets with this property is that CC&apos;s under this </context>
</contexts>
<marker>Steedman, 1985</marker>
<rawString>Steedman, M. J., 1985. Dependency and Coordination in the Grammar of Dutch and English. Language 61:523-568.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Combinatory Grammars and Parasitic Gaps. Natural Language and Linguistic Theory</title>
<date>1986</date>
<note>(to appear).</note>
<contexts>
<context position="10965" citStr="Steedman (1986)" startWordPosition="1869" endWordPosition="1870">al dependencies in Dutch subordinate clauses. Gazdar (1985) considers a restriction of IG&apos;s in which no more NP VP NP VP V&apos; I V\ /N. Piet NP VP V&apos; I MN&amp; NP sir V Wpm V V&apos; I I Ism V Figure 5: LFG analysis of Dutch subordinate clauses than one nonterminal on the right-hand-side of a production can inherit the stack from the left-hand-side. Unbounded dependencies between branches are not possible in such a system. TAG&apos;s can be shown to be equivalent to this restricted system. Thus, TAG&apos;s can not give analyses in which dependencies between arbitrarily large branches exist. 2.5 Categorial Grammars Steedman (1986) considers Categorial Grammars in which both the operations of function application and composition may be used, and in which function can specify whether they take their arguments from their right or left. While the generative power of CG&apos;s is greater that of CFG&apos;s, it appears to be highly constrained. Hence, their relationship to formalisms such as HG&apos;s and TAG&apos;s is of interest. On the one hand, the definition of composition in Steedman (1985), which technically permits composition of functions with unbounded number of arguments, generates tree sets with dependent paths such as those shown i</context>
<context position="12288" citStr="Steedman (1986)" startWordPosition="2089" endWordPosition="2090">rial Grammars composition operation to compose two arbitrarily large categories. This allows an unbounded amount of information about two separate paths (e.g. an encoding of their length) to be combined and used to influence the later derivation. A consequence of the ability to generate tree sets with this property is that CC&apos;s under this definition can generate the following language which can not be generated by either TAG&apos;s or HG&apos;s. 0n0&apos;i&apos;i0&apos;2&amp;quot;bin242bn I n = 711 + n2 } On the other hand, no linguistic use is made of this general form of composition and Steedman (personal communication) and Steedman (1986) argues that a more limited definition of composition is more natural. With this restriction the resulting tree sets will have independent paths. The equivalence of CC&apos;s with this restriction to TAG&apos;s and HG&apos;s is, however, still an open problem. 2.6 Multicomponent TAG&apos;s An extension of the TAG system was introduced by Joshi et al. (1975) and later redefined by Joshi (1987) in which the adjunction operation is defined on sets of elementary trees rather than single trees. A multicomponent Tree Adjoining Grammar (MCTAG) consists of a finite set of finite elementary tree sets. We must adjoin all t</context>
</contexts>
<marker>Steedman, 1986</marker>
<rawString>Steedman, M., 1986. Combinatory Grammars and Parasitic Gaps. Natural Language and Linguistic Theory (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J W Thatcher</author>
</authors>
<title>Tree Automata: An informal survey.</title>
<date>1973</date>
<booktitle>Currents in the Theory of Computing,</booktitle>
<pages>143--172</pages>
<editor>In Aho, A. V. (editor),</editor>
<publisher>Prentice Hall Inc.,</publisher>
<location>Englewood Cliffs, NJ.</location>
<contexts>
<context position="1818" citStr="Thatcher (1973)" startWordPosition="265" endWordPosition="266">on the weak generative capacity of grammatical formalism. Little attention, however, has been paid to the structural descriptions that these formalisms can assign to strings, i.e. their strong generative capacity. This aspect of the formalism is both linguistically and computationally important. For example, Gazdar (1985) discusses the applicability of Indexed Grammars (IG&apos;s) to Natural Language in terms of the structural descriptions assigned; and Berwick (1984) discusses the strong generative capacity of Lexical-Functional Grammar (LFG) and Government and Bindings grammars (GB). The work of Thatcher (1973) and Rounds (1969) define formal systems that generate tree sets that are related to CFG&apos;s and IG&apos;s. We consider properties of the tree sets generated by CFG&apos;s, Tree Adjoining Grammars (TAG&apos;s), Head Grammars (HG&apos;s), Categorial Grammars (CG&apos;s), and IG&apos;s. We examine both the complexity of the paths of trees in the tree sets, and the kinds of dependencies that the formalisms can impose between paths. These two properties of the tree sets are not only linguistically relevant, but also have computational importance. By considering derivation trees, and thus abstracting away from the details of the </context>
<context position="16514" citStr="Thatcher (1973)" startWordPosition="2853" endWordPosition="2854"> that a tee set contains trees with dependent paths if there are two paths p., = vim., and g., = in each 7 E r such that v., is some, possibly empty, shared initial subpath; v., and wi are not bounded in length; and there is some &amp;quot;dependence&amp;quot; (such as equal length) between the set of all v., and w., for each 7 Er. A tree set may be said to have dependencies between paths if some &amp;quot;appropriate&amp;quot; subset can be shown to have dependent paths as defined above. We attempt to formalize this notion in terms of the tee pumping lemma which can be used to show that a tee set does not have dependent paths. Thatcher (1973) describes a tee pumping lemma for recognizable sets related to the string pumping lemma for regular sets. The tee in Figure 9a can be denoted by t1 i223 where tee substitution is used instead of concatenation. The tee pumping lemma states that if there is tree, t = 22 t2t3, generated by a CFG G, whose height is more than a predetermined bound k, then all trees of the form ti tP3 for each i &gt; 0 will also generated by G (as shown in Figure 9b). The string pumping lemma for CFG&apos;s (uvwxy-theorem) can be seen as a corollary of this lemma. v (a) (b) Figure 9: Tree pumping lemma for local sets The f</context>
</contexts>
<marker>Thatcher, 1973</marker>
<rawString>Thatcher, J. W., 1973. Tree Automata: An informal survey. In Aho, A. V. (editor), Currents in the Theory of Computing, pages 143-172. Prentice Hall Inc., Englewood Cliffs, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D J Weir</author>
</authors>
<title>Context-Free Grammars to Tree Adjoining Grannvnars and Beyond.</title>
<date>1987</date>
<tech>Technical Report,</tech>
<volume>1</volume>
<institution>Department of Computer and Information Science, University of Pennsylvania, Philadelphia.</institution>
<contexts>
<context position="18249" citStr="Weir (1987)" startWordPosition="3188" endWordPosition="3189">e uvwxy-theorem for CFL&apos;s since the tree sets of TAG&apos;s have independent and context-free paths. This pumping lemma states that if there is tree, t = t2t3t4t5, generated by a TAG G, such that its height is more than a predetermined bound k, then all trees of the form ti it tstt ts for each i &gt; 0 will also generated by G. Similarly, for tree sets with independent paths and more complex path sets, tree pumping lemmas can be given. We adapt the string pumping lemma for the class of languages corresponding to the complexity of the path set. A geometrical progression of language families defined by Weir (1987) involves tree sets with increasingly complex path sets. The independence of paths in the tree sets of the k tI grammatical formalism in this hierarchy can be shown by means of tree pumping lemma of the form t1ti3t . . .t The path set of tree sets at level k +1 have the complexity of the string language of level k. The independence of paths in a tree set appears to be an important property. A formalism generating tree sets with complex path sets can still generate only semilinear languages if its tree sets have independent paths, and semilinear path sets. For example, the formalisms in the hie</context>
<context position="38007" citStr="Weir (1987)" startWordPosition="6534" endWordPosition="6535"> be recognized in polynomial time since polynomial time algorithms exist in for each of these formalisms. A corollary of the result of Section 4.3 is that polynomial time recognition of MCTAG&apos;s is possible. As discussed in Section 3, independent paths in tree sets, rather than the path complexity, may be crucial in characterizing semilinearity and polynomial time recognition. We would like to relax somewhat the constraint on the path complexity of formalisms in LCFRS. Formalisms such as the restricted indexed grammars (Gazdar, 1985) and members of the hierarchy of grammatical systems given by Weir (1987) have independent paths, but more complex path sets. Since these path sets are semilinear, the property of independent paths in their tree sets is sufficient to cause semilinearity of the languages generated by them. In addition, the restricted version of CG&apos;s (discussed in Section 6) generates tree sets with independent paths and we hope that it can be included in a more general definition of LCFRS&apos;s containing formalisms whose tree sets have path sets that are themselves LCFRL&apos;s (as in the case of the restricted indexed grammars, and the hierarchy defined by Weir). LCFRS&apos;s have only been loo</context>
</contexts>
<marker>Weir, 1987</marker>
<rawString>Weir, D. J., 1987. Context-Free Grammars to Tree Adjoining Grannvnars and Beyond. Technical Report, Department of Computer and Information Science, University of Pennsylvania, Philadelphia. 1 1 1</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>