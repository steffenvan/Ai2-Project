<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.024518">
<note confidence="0.9942325">
Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,
Philadelphia, July 2002, pp. 125-128. Association for Computational Linguistics.
</note>
<title confidence="0.995912">
Probabilistic Dialogue Modelling
</title>
<author confidence="0.964392">
Oliver Lemon Prashant Parikh Stanley Peters
</author>
<affiliation confidence="0.863994">
CSLI IRCS CSLI
Stanford University University of Pennsylvania Stanford University
</affiliation>
<email confidence="0.998608">
lemon@csli.stanford.edu, pjparikh@aol.com peters@csli.stanford.edu
</email>
<sectionHeader confidence="0.995645" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99956275">
We show how Bayesian networks and re-
lated probabilistic methods provide an ef-
ficient way of capturing the complex bal-
ancing of different factors that determine
interpretation and generation in dialogue.
As a case study, we show how a prob-
abilistic approach can be used to model
anaphora resolution in dialogues.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971388888889">
The use of probabilistic and decision-theoretic in-
ference in dialogue modelling and management has
been explored in preliminary fashion by (Pulman,
1996) and (Keizer, 2001). Probabilistic meth-
ods look promising when modelling systems where
there is uncertainty, and simple true/false judge-
ments obscure some of the subtleties of represen-
tation and processing that are required of an accu-
rate model. Dialogue systems are of this nature be-
cause uncertainty is present due to speech recogni-
tion noise, speech-act uncertainty, and so on. Epis-
temic uncertainty is rife in dialogue, and probability
distributions provide a natural model of the ambigu-
ities that thus arise. For these reasons it is natural to
explore probabilistic representations and algorithms
in dialogue management, rather than purely deter-
ministic models. We have experience building deter-
ministic dialogue managers (see e.g. (Lemon et al.,
</bodyText>
<footnote confidence="0.941889">
&apos;This research was (partially) funded under the Wallenberg
laboratory for research on Information Technology and Au-
tonomous Systems (WITAS) Project, Link¨oping University, by
the Wallenberg Foundation, Sweden.
</footnote>
<bodyText confidence="0.989063916666667">
2001; Lemon et al., 2002)) which use deterministic
context update rules.
This paper briefly describes our construction of a
Bayes Net modelling dialogue context. We will con-
sider a series of examples of increasing complexity
involving anaphoric resolution in Section 3.1. We
will point out how they are to be resolved intuitively,
and then discuss how our Bayesian net fares. We
will see that many of the best insights of determin-
istic approaches (e.g. in the axiomatic BDI tradition
and in the planning literature) can be preserved, of-
ten in less brittle forms, in a probabilistic setting.
</bodyText>
<subsectionHeader confidence="0.998912">
1.1 Probabilistic modelling ideas
</subsectionHeader>
<bodyText confidence="0.999718916666667">
Our approach to resolving anaphora (and dialogue
moves) was to generate a probability distribution of
the random variable of interest (e.g. salience of ref-
erent) and then choose the value of the variable cor-
responding to the highest probability as the interpre-
tation (e.g. the referent). This decision has a theo-
retical justification that can be found in a theorem in
(Parikh, 1990) in the context of his game-theoretic
model of language use. The theorem states that un-
der certain conditions (which hold in our context)
the correct interpretation of an utterance is the most
likely one.
</bodyText>
<sectionHeader confidence="0.942269" genericHeader="introduction">
2 Interpretation and Generation
</sectionHeader>
<bodyText confidence="0.9990709375">
The two major aspects of dialogue management are
the interpretation of incoming (user) utterances, and
the timely and appropriate generation of utterances
by the dialogue system. To cover these aspects we
have constructed a Bayes Net as shown in Figure 1.
In the implementation of this network we used
CIspace’s Java-based Bayes Net toolkit.2
The conditional probability table for the nodes
representing the dialogue move at time and
salience list at time are obviously the core of
the network. These tables are too large to present
in this paper. We constructed them by hand, us-
ing heuristics gained from experience in program-
ming rule-based dialogue systems. In future, the ta-
bles could be learned from data, or could instantiate
continuous-valued functions of rule-based systems.
</bodyText>
<figureCaption confidence="0.9421975">
Figure 1: A Prototype Bayes Net for dialogue man-
agement
</figureCaption>
<sectionHeader confidence="0.967217" genericHeader="method">
3 Anaphora resolution
</sectionHeader>
<bodyText confidence="0.9999811">
Several different factors enter into the resolution of
anaphora in a dialogue. How recently a potential
referent was referred to is one important factor, an-
other is the embedding activity within which the
anaphoric reference was made (e.g. the type of verb
phrase in which the referent appears), a third is the
intra-sentential location of the relevant noun phrases
in the preceding dialogue, a fourth is the relative
prominence of a potential referent in the dialogue
situation, and so on. The basic idea is that condi-
</bodyText>
<footnote confidence="0.738601">
2www.cs.ubc.ca/labs/lci/CIspace/
</footnote>
<bodyText confidence="0.999947933333333">
tional probability distributions are generated dynam-
ically in the Bayesian network. When we look at a
distribution corresponding to a node we are inter-
ested in, then the most salient object in the context
will be the one whose value has the highest proba-
bility.
We point out that an obvious deterministic way
to rank different combinations of factors (in an
optimality-theoretic way, for example), and choose
the most salient object based on this ranking, does
not seem to work – because any potential ranking
of principles (e.g. “Recency overrides subject place-
ment”) would have to be context-dependent, and this
defeats the idea of a ranking. See the examples in
Figures 5 and 6.
</bodyText>
<subsectionHeader confidence="0.991167">
3.1 Examples
</subsectionHeader>
<bodyText confidence="0.996800214285714">
Here we work with two basic activities of the
WITAS robot helicopter (see (Lemon et al., 2002))
which our dialogue system interfaces to – moving
and searching. The helicopter can move to vari-
ous landmarks (e.g. the tower, the church) and way-
points, and can see various objects (e.g. landmarks,
vehicles). Our results use the network in Figure 1. In
reading the tables (the figures appear after the refer-
ences), use the following key:
U=user, S=system, r=red car, g=green car,
w=waypoint, s= search, m=move. All examples
start with an even distribution of 0.2 for all variables
(all objects are equally salient) at the start of each
dialogue.
</bodyText>
<subsectionHeader confidence="0.761313">
3.1.1 Activity and recency
</subsectionHeader>
<bodyText confidence="0.999972266666666">
We will start with what may be the simplest type
of example of anaphoric reference, in Figure 2. Here
it is intuitively clear that “it” is intended to pick out
the green car. The contribution of “see it” is mod-
elled as an observed even distribution over all possi-
ble referents which can be seen (i.e. and each
get a 0.5 weight). The conditional probability table
for Salience List at time is then used to compute the
new probability distribution over the object-activity
pairs ( ). Here we see that the
green car is the most salient after the user’s second
utterance ( ), and that this salience increases after
the utterance “it”, because was both the most re-
cent NP, and is also a possible object in the context
of the “seeing” activity.
</bodyText>
<figure confidence="0.997577703703704">
Salience
List
t−1
Salience
List
t
Activity
System
Utterance
t
t
Input
Logical
Form t
User
User
Dialogue
Move
t
Dialogue
Move
System
t−1
User
Dialogue
Move
t−1
</figure>
<bodyText confidence="0.999975045454546">
In the example in Figure 3, the anaphoric pronoun
“it” should pick out the red car and not the waypoint,
even though the waypoint was referred to more re-
cently. Intuitively, this is because the embedding ac-
tivity of looking for the red car is tied to the pro-
noun, and this fact overrides the most recent refer-
ent. Here, the waypoint is not a possible object in
the “seeing” activity, whereas the red car has been
introduced as part of that activity. Thus the pronoun
“it” in the user’s final utterance has the effect of rais-
ing the probabilities of all the objects which can be
seen, and this in fact overrides the recency effect of
the utterance of “waypoint”.
An extended example (not shown) shows how ac-
tivity information can outweigh recency in an inter-
leaved fashion and then that a newly introduced ref-
erent can become the most salient. Having consid-
ered the ways in which activity and recency interact
in determining salience for anaphoric resolution, we
then investigated adding another determining factor
in the model – the syntactic placement of the refer-
ring expression.
</bodyText>
<subsectionHeader confidence="0.902373">
3.1.2 Placement, activity, and recency
</subsectionHeader>
<bodyText confidence="0.99994425">
Figure 4 shows how subject placement influences
availability for anaphoric reference. Here, the sub-
ject (“red car”) of the user’s second utterance is in-
tuitively the one picked out by the later anaphoric
expression, and not the green car, even though “the
green car” is the most recent NP. See Figure 4 for our
results, using an extension of the network in Figure
1, where the “Activity ” node was enriched to in-
clude syntactic information about the input – specif-
ically, what referring expressions appear in subject
and object places. Note here that the red car be-
comes the most salient object after the user’s sec-
ond utterance. We model the referential import of
this sentence as an input triple “ ”to the Activ-
ity node – denoting: red car (subject), no activity,
green car (object). The updated table for this node
ensures that objects in subject place are given more
weight than those in object place.
In Figure 5, the subject (“red car”) of the user’s
second utterance is intuitively the one picked out by
the later anaphoric expression, and not the green car,
even though “the green car” is involved in the “see-
ing” activity.
In Figure 6 the red car is most salient after the
second utterance, but the waypoint becomes more
salient, even though the red car was in subject po-
sition, because the waypoint is involved in the ac-
tivity of moving, as is the pronoun “it”, and so is
a better candidate for anaphoric resolution. Com-
bined with Figure 5 this shows that no static ranking
of anaphoric binding principles will cover all situ-
ations, and that a probabilistic approach is useful –
even as a theoretical model.
Obviously this model could be made more com-
plex with representations for direct and indirect ob-
jects, and so forth, but we leave this for future work.
</bodyText>
<sectionHeader confidence="0.999585" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.9999897">
We presented a Bayes Net which we have imple-
mented to deal with dialogue move interpretation
and reference resolution, and gave examples of its
use for weighing a variety of factors (recency, activ-
ity, placement) in anaphoric resolution in particular.
We saw that many of the insights of deterministic ap-
proaches (e.g. the WITAS Project, see (Lemon et al.,
2002)) can be preserved, often in less brittle forms,
in a probabilistic setting. We also have unpublished
results for dialogue move classification.
</bodyText>
<sectionHeader confidence="0.998574" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995527409090909">
Simon Keizer. 2001. A probabilistic approach to dia-
logue act clarification. In Proceedings of Bi-Dialog
2001.
Oliver Lemon, Anne Bracy, Alexander Gruenstein, and
Stanley Peters. 2001. Information states in a multi-
modal dialogue system for human-robot conversation.
In Peter K¨uhnlein, Hans Reiser, and Henk Zeevat, edi-
tors, 5th Workshop on Formal Semantics and Pragmat-
ics ofDialogue (Bi-Dialog 2001), pages 57 – 67.
Oliver Lemon, Alexander Gruenstein, Alexis Battle, and
Stanley Peters. 2002. Multi-tasking and collabora-
tive activities in dialogue systems. In Proceedings
of 3rd SIGdial Workshop on Discourse and Dialogue,
Philadelphia. (to appear).
Prashant Parikh. 1990. Situations, games, and ambigu-
ity. In R. Cooper, K. Mukai, and J. Perry, editors, Situ-
ation Theory and its ApplicationsI. CSLI Publications.
Prashant Parikh. 2001. The Use of Language. CSLI
Publications, Stanford, CA.
Stephen G. Pulman. 1996. Conversational games, belief
revision and bayesian networks. In 7th Computational
Linguistics in the Netherlands (CLIN) meeting.
</reference>
<figure confidence="0.605542666666667">
Utterance P(rm) P(gm) P(wm) P(rs) P(gs) Salient
U: Search for the red car .22 .06 .06 .6 .06 red car
S: Okay
U: Go to the green car .066 .53 .018 .18 .206 green car
S: Okay
U: Can you see it? .0196 .7002 .0054 .054 .2206 green car
</figure>
<figureCaption confidence="0.865646">
Figure 2: Probability distributions in example: Recency
</figureCaption>
<figure confidence="0.767119666666667">
Utterance P(rm) P(gm) P(wm) P(rs) P(gs) Salient
U: Do you see the red car? .18 .06 .06 .64 .06 red car
S: No
U: Go to the waypoint .054 .018 .718 .192 .008 waypoint
S: Okay
U: Do you see it? .1108 .1036 .2154 .313 .2572 red car
</figure>
<figureCaption confidence="0.881178888888889">
Figure 3: Probability distributions in example: Activity overrides recency
Utterance P(rm) P(gm) P(wm) P(rs) P(gs) Salient
U: Go to the green car .06 .524 .06 .06 .296 green car
S: Okay
U: The red car is beside the .333 .1899 .018 .333 .1261 red car
green car
S: Okay
U: Can you see it? .1955 .1622 .0054 .3543 .2825 red car
Figure 4: Probability distributions in example: Subject placement overrides recency
</figureCaption>
<table confidence="0.636714428571429">
Utterance P(rm) P(gm) P(wm) P(rs) P(gs) Salient
U: Search for the green car .06 .296 .06 .06 .524 green car
S: Okay
U: The red car is beside the .263 .2006 .018 .263 .2554 red car
green car
S: Okay
U: Can you see it? .1796 .1622 .0054 .3282 .3206 red car
</table>
<figureCaption confidence="0.693528714285714">
Figure 5: Probability distributions in example: Subject placement overrides activity
Utterance P(rm) P(gm) P(wm) P(rs) P(gs) Salient
U: Go to the waypoint .06 .06 .76 .06 .06 waypoint
R: The red car is at the way- .333 .018 .298 .333 .018 red car
point
U: Did you get to it? .2888 .1582 .3288 .1444 .0913 waypoint
Figure 6: Probability distributions for example: Activity overrides subject placement
</figureCaption>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.293733">
<note confidence="0.600445">Proceedings of the Third SIGdial Workshop on Discourse and Dialogue, Philadelphia, July 2002, pp. 125-128. Association for Computational Linguistics.</note>
<title confidence="0.984203">Probabilistic Dialogue Modelling</title>
<author confidence="0.9942">Oliver Lemon Prashant Parikh Stanley Peters</author>
<affiliation confidence="0.997686">CSLI IRCS CSLI Stanford University University of Pennsylvania Stanford University</affiliation>
<email confidence="0.996167">lemon@csli.stanford.edu,pjparikh@aol.competers@csli.stanford.edu</email>
<abstract confidence="0.949643">We show how Bayesian networks and related probabilistic methods provide an efficient way of capturing the complex balancing of different factors that determine interpretation and generation in dialogue. As a case study, we show how a probabilistic approach can be used to model resolution in</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Simon Keizer</author>
</authors>
<title>A probabilistic approach to dialogue act clarification.</title>
<date>2001</date>
<booktitle>In Proceedings of Bi-Dialog</booktitle>
<contexts>
<context position="884" citStr="Keizer, 2001" startWordPosition="118" endWordPosition="119">y of Pennsylvania Stanford University lemon@csli.stanford.edu, pjparikh@aol.com peters@csli.stanford.edu Abstract We show how Bayesian networks and related probabilistic methods provide an efficient way of capturing the complex balancing of different factors that determine interpretation and generation in dialogue. As a case study, we show how a probabilistic approach can be used to model anaphora resolution in dialogues. 1 Introduction The use of probabilistic and decision-theoretic inference in dialogue modelling and management has been explored in preliminary fashion by (Pulman, 1996) and (Keizer, 2001). Probabilistic methods look promising when modelling systems where there is uncertainty, and simple true/false judgements obscure some of the subtleties of representation and processing that are required of an accurate model. Dialogue systems are of this nature because uncertainty is present due to speech recognition noise, speech-act uncertainty, and so on. Epistemic uncertainty is rife in dialogue, and probability distributions provide a natural model of the ambiguities that thus arise. For these reasons it is natural to explore probabilistic representations and algorithms in dialogue manag</context>
</contexts>
<marker>Keizer, 2001</marker>
<rawString>Simon Keizer. 2001. A probabilistic approach to dialogue act clarification. In Proceedings of Bi-Dialog 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Anne Bracy</author>
<author>Alexander Gruenstein</author>
<author>Stanley Peters</author>
</authors>
<title>Information states in a multimodal dialogue system for human-robot conversation.</title>
<date>2001</date>
<booktitle>5th Workshop on Formal Semantics and Pragmatics ofDialogue (Bi-Dialog</booktitle>
<pages>57--67</pages>
<editor>In Peter K¨uhnlein, Hans Reiser, and Henk Zeevat, editors,</editor>
<marker>Lemon, Bracy, Gruenstein, Peters, 2001</marker>
<rawString>Oliver Lemon, Anne Bracy, Alexander Gruenstein, and Stanley Peters. 2001. Information states in a multimodal dialogue system for human-robot conversation. In Peter K¨uhnlein, Hans Reiser, and Henk Zeevat, editors, 5th Workshop on Formal Semantics and Pragmatics ofDialogue (Bi-Dialog 2001), pages 57 – 67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Alexander Gruenstein</author>
<author>Alexis Battle</author>
<author>Stanley Peters</author>
</authors>
<title>Multi-tasking and collaborative activities in dialogue systems.</title>
<date>2002</date>
<booktitle>In Proceedings of 3rd SIGdial Workshop on Discourse and Dialogue,</booktitle>
<location>Philadelphia.</location>
<note>(to appear).</note>
<contexts>
<context position="1852" citStr="Lemon et al., 2002" startWordPosition="260" endWordPosition="263">, and so on. Epistemic uncertainty is rife in dialogue, and probability distributions provide a natural model of the ambiguities that thus arise. For these reasons it is natural to explore probabilistic representations and algorithms in dialogue management, rather than purely deterministic models. We have experience building deterministic dialogue managers (see e.g. (Lemon et al., &apos;This research was (partially) funded under the Wallenberg laboratory for research on Information Technology and Autonomous Systems (WITAS) Project, Link¨oping University, by the Wallenberg Foundation, Sweden. 2001; Lemon et al., 2002)) which use deterministic context update rules. This paper briefly describes our construction of a Bayes Net modelling dialogue context. We will consider a series of examples of increasing complexity involving anaphoric resolution in Section 3.1. We will point out how they are to be resolved intuitively, and then discuss how our Bayesian net fares. We will see that many of the best insights of deterministic approaches (e.g. in the axiomatic BDI tradition and in the planning literature) can be preserved, often in less brittle forms, in a probabilistic setting. 1.1 Probabilistic modelling ideas </context>
<context position="5273" citStr="Lemon et al., 2002" startWordPosition="814" endWordPosition="817">most salient object in the context will be the one whose value has the highest probability. We point out that an obvious deterministic way to rank different combinations of factors (in an optimality-theoretic way, for example), and choose the most salient object based on this ranking, does not seem to work – because any potential ranking of principles (e.g. “Recency overrides subject placement”) would have to be context-dependent, and this defeats the idea of a ranking. See the examples in Figures 5 and 6. 3.1 Examples Here we work with two basic activities of the WITAS robot helicopter (see (Lemon et al., 2002)) which our dialogue system interfaces to – moving and searching. The helicopter can move to various landmarks (e.g. the tower, the church) and waypoints, and can see various objects (e.g. landmarks, vehicles). Our results use the network in Figure 1. In reading the tables (the figures appear after the references), use the following key: U=user, S=system, r=red car, g=green car, w=waypoint, s= search, m=move. All examples start with an even distribution of 0.2 for all variables (all objects are equally salient) at the start of each dialogue. 3.1.1 Activity and recency We will start with what m</context>
</contexts>
<marker>Lemon, Gruenstein, Battle, Peters, 2002</marker>
<rawString>Oliver Lemon, Alexander Gruenstein, Alexis Battle, and Stanley Peters. 2002. Multi-tasking and collaborative activities in dialogue systems. In Proceedings of 3rd SIGdial Workshop on Discourse and Dialogue, Philadelphia. (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prashant Parikh</author>
</authors>
<title>Situations, games, and ambiguity.</title>
<date>1990</date>
<editor>In R. Cooper, K. Mukai, and J. Perry, editors,</editor>
<publisher>CSLI Publications.</publisher>
<contexts>
<context position="2834" citStr="Parikh, 1990" startWordPosition="421" endWordPosition="422">any of the best insights of deterministic approaches (e.g. in the axiomatic BDI tradition and in the planning literature) can be preserved, often in less brittle forms, in a probabilistic setting. 1.1 Probabilistic modelling ideas Our approach to resolving anaphora (and dialogue moves) was to generate a probability distribution of the random variable of interest (e.g. salience of referent) and then choose the value of the variable corresponding to the highest probability as the interpretation (e.g. the referent). This decision has a theoretical justification that can be found in a theorem in (Parikh, 1990) in the context of his game-theoretic model of language use. The theorem states that under certain conditions (which hold in our context) the correct interpretation of an utterance is the most likely one. 2 Interpretation and Generation The two major aspects of dialogue management are the interpretation of incoming (user) utterances, and the timely and appropriate generation of utterances by the dialogue system. To cover these aspects we have constructed a Bayes Net as shown in Figure 1. In the implementation of this network we used CIspace’s Java-based Bayes Net toolkit.2 The conditional prob</context>
</contexts>
<marker>Parikh, 1990</marker>
<rawString>Prashant Parikh. 1990. Situations, games, and ambiguity. In R. Cooper, K. Mukai, and J. Perry, editors, Situation Theory and its ApplicationsI. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Prashant Parikh</author>
</authors>
<title>The Use of Language.</title>
<date>2001</date>
<publisher>CSLI Publications,</publisher>
<location>Stanford, CA.</location>
<marker>Parikh, 2001</marker>
<rawString>Prashant Parikh. 2001. The Use of Language. CSLI Publications, Stanford, CA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen G Pulman</author>
</authors>
<title>Conversational games, belief revision and bayesian networks.</title>
<date>1996</date>
<booktitle>In 7th Computational Linguistics in the Netherlands (CLIN) meeting.</booktitle>
<contexts>
<context position="865" citStr="Pulman, 1996" startWordPosition="115" endWordPosition="116">niversity University of Pennsylvania Stanford University lemon@csli.stanford.edu, pjparikh@aol.com peters@csli.stanford.edu Abstract We show how Bayesian networks and related probabilistic methods provide an efficient way of capturing the complex balancing of different factors that determine interpretation and generation in dialogue. As a case study, we show how a probabilistic approach can be used to model anaphora resolution in dialogues. 1 Introduction The use of probabilistic and decision-theoretic inference in dialogue modelling and management has been explored in preliminary fashion by (Pulman, 1996) and (Keizer, 2001). Probabilistic methods look promising when modelling systems where there is uncertainty, and simple true/false judgements obscure some of the subtleties of representation and processing that are required of an accurate model. Dialogue systems are of this nature because uncertainty is present due to speech recognition noise, speech-act uncertainty, and so on. Epistemic uncertainty is rife in dialogue, and probability distributions provide a natural model of the ambiguities that thus arise. For these reasons it is natural to explore probabilistic representations and algorithm</context>
</contexts>
<marker>Pulman, 1996</marker>
<rawString>Stephen G. Pulman. 1996. Conversational games, belief revision and bayesian networks. In 7th Computational Linguistics in the Netherlands (CLIN) meeting.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>