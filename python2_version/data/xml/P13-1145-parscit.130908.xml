<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.994155">
Argument Inference from Relevant Event Mentions in Chinese
Argument Extraction
</title>
<author confidence="0.999505">
Peifeng Li, Qiaoming Zhu, Guodong Zhou*
</author>
<affiliation confidence="0.999777">
School of Computer Science &amp; Technology
</affiliation>
<address confidence="0.921081">
Soochow University, Suzhou, 215006, China
</address>
<email confidence="0.998689">
{pfli, qmzhu, gdzhou}@suda.edu.cn
</email>
<sectionHeader confidence="0.993907" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99997">
As a paratactic language, sentence-level
argument extraction in Chinese suffers
much from the frequent occurrence of
ellipsis with regard to inter-sentence
arguments. To resolve such problem, this
paper proposes a novel global argument
inference model to explore specific
relationships, such as Coreference,
Sequence and Parallel, among relevant
event mentions to recover those inter-
sentence arguments in the sentence,
discourse and document layers which
represent the cohesion of an event or a
topic. Evaluation on the ACE 2005
Chinese corpus justifies the effectiveness
of our global argument inference model
over a state-of-the-art baseline.
</bodyText>
<sectionHeader confidence="0.998991" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999485491228071">
The task of event extraction is to recognize event
mentions of a predefined event type and their
arguments (participants and attributes).
Generally, it can be divided into two subtasks:
trigger extraction, which aims to identify
trigger/event mentions and determine their event
type, and argument extraction, which aims to
extract various arguments of a specific event and
assign the roles to them. In this paper, we focus
on argument extraction in Chinese event
extraction. While most of previous studies in
Chinese event extraction deal with Chinese
trigger extraction (e.g., Chen and Ji, 2009a; Qin
et al., 2010; Li et al., 2012a, 2012b), there are
only a few on Chinese argument extraction (e.g.,
Tan et al., 2008; Chen and Ji, 2009b). Following
previous studies, we divide argument extraction
into two components, argument identification
and role determination, where the former
recognizes the arguments in a specific event
mention and the latter classifies these arguments
by roles.
With regard to methodology, most of previous
studies on argument extraction recast it as a
Semantic Role Labeling (SRL) task and focus on
intra-sentence information to identify the
arguments and their roles. However, argument
extraction is much different from SRL in the
sense that, while the relationship between a
predicate and its arguments in SRL can be
mainly decided from the syntactic structure, the
relationship between an event trigger and its
arguments are more semantics-based, especially
in Chinese, as a paratactic (e.g., discourse-driven
and pro-drop) language with the wide spread of
ellipsis and the open flexible sentence structure.
Therefore, some arguments of a specific event
mention are far away from the trigger and how to
recover those inter-sentence arguments becomes
a challenging issue in Chinese argument
extraction. Consider the following discourse
(from ACE 2005 Chinese corpus) as a sample:
D1: 巴勒斯坦自治政府否认和加沙走廊 20 号
清晨造成两名以色列人丧生(E1)的炸弹攻击
(E2)事件有关...表示将对这起攻击(E3)事件展
开 调查。 (The Palestinian National Authority
denied any involvement in the bomb attack (E2)
occurred in the Gaza Strip on the morning of the
20th, which killed (E1) two Israelites. ... They
claimed that they will be investigating this
attack (E3).) - From CBS20001120.1000.0823
In above discourse, there are three event
mentions, one kill (E1) and two Attack (E2, E3).
While it is relatively easy to identify 20 号清晨
(morning of 20th), 加沙走廊 (Gaza Strip) and 炸
弹 (bomb) as the Time, Place and Instrument
roles in E2 by a sentence-based argument
</bodyText>
<page confidence="0.946973">
1477
</page>
<note confidence="0.913601">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, pages 1477–1487,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.999327428571428">
extractor, it is really challenging to recognize
these entities as the arguments of its corefered
mention E3 since to reduce redundancy in a
Chinese discourse, the later Chinese sentences
omit many of these entities already mentioned in
previous sentences. Similarly, it is hard to
recognize Wj--Pi�4t3�JA (two Israelites) as the
Target role for event mention E2 and identify kt
0 (bomb) as the Instrument role for event
mention E1. An alternative way is to employ
various relationships among relevant event
mentions in a discourse to infer those inter-
sentence arguments.
The contributions of this paper are:
</bodyText>
<listItem confidence="0.982951">
1) We propose a novel global argument
inference model, in which various kinds of
event relations are involved to infer more
arguments on their semantic relations.
2) Different from Liao and Grishman (2010)
and Hong et al. (2011), which only consider
</listItem>
<bodyText confidence="0.8411602">
document-level consistency, we propose a
more fine-gained consistency model to
enforce the consistency in the sentence,
discourse and document layers.
3) We incorporate argument semantics into our
global argument inference model to unify the
semantics of the event and its arguments.
The rest of this paper is organized as follows.
Section 2 overviews the related work. Section 3
describes a state-of-the-art Chinese argument
extraction system as the baseline. Section 4
introduces our global model in inferring those
inter-sentence arguments. Section 5 reports
experimental results and gives deep analysis.
Finally, we conclude our work in Section 6.
</bodyText>
<sectionHeader confidence="0.999745" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999918888888889">
Almost all the existing studies on argument
extraction concern English. While some apply
pattern-based approaches (e.g., Riloff, 1996;
Califf and Mooney, 2003; Patwardhan and Riloff,
2007; Chambers and Jurafsky, 2011), the others
use machine learning-based approaches (e.g.,
Grishman et al., 2005; Ahn, 2006; Patwardhan
and Riloff, 2009; Lu and Roth, 2012), most of
which rely on various kinds of features in the
context of a sentence. In comparison, there are
only a few studies exploring inter-sentence
information or argument semantics (e.g., Liao
and Grishman, 2010; Hong et al., 2011; Huang
and Riloff, 2011, 2012).
Compared with the tremendous work on
English event extraction, there are only a few
studies (e.g., Tan et al., 2008; Chen and Ji, 2009b;
Fu et al., 2010; Qin et al., 2010; Li et al., 2012)
on Chinese event extraction with focus on either
feature engineering or trigger expansion, under
the same framework as English trigger
identification. In additional, there are only very
few of them focusing on Chinese argument
extraction and almost all aim to feature
engineering and are based on sentence-level
information and recast this task as an SRL-style
task. Tan et al. (2008) introduce multiple levels
of patterns to improve the coverage in Chinese
argument classification. Chen and Ji (2009b)
apply various kinds of lexical, syntactic and
semantic features to address the special issues in
Chinese argument extraction. Fu et al. (2010) use
a feature weighting scheme to re-weight various
features for Chinese argument extraction. Li et al.
(2012b) introduce more refined features to the
system of Chen and Ji (2009b) as their baseline.
Specially, several studies have successfully
incorporated cross-document or document-level
information and argument semantics into event
extraction, most of them focused on English.
Yangarber et al. (2007) apply a cross-
document inference mechanism to refine local
extraction results for the disease name, location
and start/end time. Mann (2007) proposes some
constraints on relationship rescoring to impose
the discourse consistency on the CEO’s personal
information. Chambers and Jurafsky (2008)
propose a narrative event chain which are
partially ordered sets of event mentions centered
around a common protagonist and this chain can
represent the relationship among the relevant
event mentions in a document.
Ji and Grishman (2008) employ a rule-based
approach to propagate consistent triggers and
arguments across topic-related documents. Liao
and Grishman (2010) mainly focus on employing
the cross-event consistency information to
improve sentence-level trigger extraction and
they also propose an inference method to infer
the arguments following role consistency in a
document. Hong et al. (2011) employ the
background information to divide an entity type
into more cohesive subtypes to create the bridge
between two entities and then infer arguments
and their roles using cross-entity inference on the
subtypes of entities. Huang and Rillof (2012)
propose a sequentially structured sentence
classifier which uses lexical associations and
discourse relations across sentences to identify
event-related document contexts and then apply
it to recognize arguments and their roles on the
relation among triggers and arguments.
</bodyText>
<page confidence="0.996101">
1478
</page>
<sectionHeader confidence="0.998813" genericHeader="method">
3 Baseline
</sectionHeader>
<bodyText confidence="0.999939818181818">
In the task of event extraction as defined in ACE
evaluations, an event is defined as a specific
occurrence involving participants (e.g., Person,
Attacker, Agent, Defendant) and attributes (e.g.,
Place, Time). Commonly, an event mention is
triggered via a word (trigger) in a phrase or
sentence which clearly expresses the occurrence
of a specific event. The arguments are the entity
mentions involved in an event mention with a
specific role, the relation of an argument to an
event where it participates. Hence, extracting an
event consists of four basic steps, identifying an
event trigger, determining its event type,
identifying involved arguments (participants and
attributes) and determining their roles.
As the baseline, we choose a state-of-the-art
Chinese event extraction system, as described in
Li et al. (2012b), which consists of four typical
components: trigger identification, event type
determination, argument identification and role
determination. In their system, the former two
components, trigger identification and event type
determination, are processed in a joint model,
where the latter two components are run in a
pipeline way. Besides, the Maximum-Entropy
(ME) model is employed to train individual
component classifiers for above four components.
This paper focuses on argument identification
and role determination. In order to provide a
stronger baseline, we introduce more refined
features in such two components, besides those
adopted in Li et al. (2012b). Following is a list of
features adopted in our baseline.
</bodyText>
<listItem confidence="0.9973665">
1) Basic features: trigger, POS (Part Of Speech)
of the trigger, event type, head word of the
entity, entity type, entity subtype;
2) Neighbouring features: left neighbouring
word of the entity + its POS, right neighbour
word of the entity + its POS, left neighbour
word of the trigger + its POS, right neighbour
word of the trigger + its POS;
3) Dependency features: dependency path from
the entity to the trigger, depth of the
dependency path;
4) Syntactic features: path from the trigger to the
entity, difference of the depths of the trigger
and entity, place of the entity (before trigger
or after trigger), depth of the path from the
trigger to the entity, siblings of the entity;
5) Semantic features: semantic role of the entity
tagged by an SRL tool (e.g., ARG0, ARG1)
(Li et al., 2010), sememe of trigger in Hownet
(Dong and Dong, 2006).
</listItem>
<sectionHeader confidence="0.860446" genericHeader="method">
4 Inferring Inter-Sentence Arguments
on Relevant Event Mentions
</sectionHeader>
<bodyText confidence="0.999971">
In this paper, a global argument inference model
is proposed to infer those inter-sentence
arguments and their roles, incorporating with
semantic relations between relevant event
mention pairs and argument semantics.
</bodyText>
<subsectionHeader confidence="0.99743">
4.1 Motivation
</subsectionHeader>
<bodyText confidence="0.999908029411764">
It’s well-known that Chinese is a paratactic
language, with an open flexible sentence
structure and often omits the subject or the object,
while English is a hypotactic language with a
strict sentence structure and emphasizes on
cohesion between clauses. Hence, there are two
issues in Chinese argument extraction, associated
with its nature of the paratactic language.
The first is that many arguments of an event
mention are out of the event mention scope since
ellipsis is a common phenomenon in Chinese.
We call them inter-sentence arguments in this
paper. Table 1 gives the statistics of intra-
sentence and inter-sentence arguments in the
ACE 2005 Chinese corpus and it shows that
20.8% of the arguments are inter-sentence ones
while this figure is less than 1% of the ACE 2005
English corpus. The main reason of that
difference is that some Chinese arguments are
omitted in the same sentence of the trigger since
Chinese is a paratactic language with the wide
spread of ellipsis. Besides, a Chinese sentence
does not always end with a full stop. In particular,
a comma is used frequently as the stop sign of a
sentence in Chinese. We detect sentence
boundaries, relying on both full stop and comma
signs, since in a Chinese document, comma can
be also used to sign the end of a sentence. In
particular, we detect sentence boundaries on full
stop, exclamatory mark and question mark firstly.
Then, we identify the sentence boundaries on
comma, using a binary classifier with a set of
lexical and constituent-based syntactic features,
similar to Xue and Yang (2010).
</bodyText>
<table confidence="0.62441325">
Category Number
#Arguments 8032
#Inter-sentence 1673(20.8%)
#Intra-sentence 6359(79.2%)
</table>
<tableCaption confidence="0.863817333333333">
Table 1. Statistics: Chinese argument extraction
with regard to intra- sentence and inter-sentence
arguments.
</tableCaption>
<bodyText confidence="0.995743">
The second issue is that the Chinese word
order in a sentence is rather agile for the open
</bodyText>
<page confidence="0.977149">
1479
</page>
<bodyText confidence="0.999929153846154">
flexible sentence structure. Hence, different word
orders can often express the same semantics. For
example, a Die event mention “Three person
died in this accident.” can be expressed in many
different orders in Chinese, such as “在事故中三
人死亡。”, “事故中死亡三人。”, “三人在事故
中死亡。”, etc.
In a word, above two issues indicate that
syntactic feature-based approaches are limited in
identifying Chinese arguments and it will lead to
low recall in argument identification. Therefore,
employing those high level information to
capture the semantic relation, not only the
syntactic structure, between the trigger and its
long distance arguments is the key to improve
the performance of the Chinese argument
identification. Unfortunately, it is really hard to
find their direct relations since they always
appear in different clauses or sentences. An
alternative way is to link the different event
mentions with their predicates (triggers) and use
the trigger as a bridge to connect the arguments
to the trigger in another event mention indirectly.
Hence, the semantic relations among event
mentions are helpful to be a bridge to identify
those inter-sentence arguments.
</bodyText>
<subsectionHeader confidence="0.998434">
4.2 Relations of Event Mention Pairs
</subsectionHeader>
<bodyText confidence="0.980827423076923">
In a discourse, most event mentions are
surrounding a specific topic. It’s obvious that
those mentions have the intrinsic relationships to
reveal the essential structure of a discourse.
Those relevant semantics-based relations are
helpful to infer the arguments for a specific
trigger mention when the syntactic relations in
Chinese argument extraction are not as effective
as that in English. In this paper, we divide the
relations among relevant event mentions into
three categories: Coreference, Sequence and
Parallel.
An event may have more than one mention in
a document and coreference event mentions refer
to the same event, as same as the definition in the
ACE evaluations. Those coreference event
mentions always have the same arguments and
roles. Therefore, employing this relation can
infer the arguments of an event mention from
their Coreference ones. For example, we can
recover the Time, Place and Instrument for E3
via its Coreference mention E2 in discourse D1,
mentioned in Section 1.
Li et al. (2012a) find out that sometimes two
trigger mentions are within a Chinese word
whose morphological structure is Coordination.
Take the following sentence as a sample:
D2: 一名 17岁的少年劫持一辆巴士,刺(E4)
死 (E5)一名妇 女 。 (A 12-year-old younger
hijacked a bus and then stabbed (E4) a woman
to death (E5).) - From ZBN20001218.0400.0005
In D2, 刺 死 (stab a person to death) is a
trigger with the Coordination structure and can
be divided into two single-morpheme words 刺
(stab) and 死 (die) while the former triggers an
Attack event and the latter refers to a Die one.
It’s interesting that they share all arguments in
this sentence. The relation between those event
mentions whose triggers merge a Chinese word
or share the subject and the object are Parallel.
For the errors in the syntactic parsing, the second
single-morpheme trigger is often assigned a
wrong tag (e.g., NN, JJ) and this leads to the
errors in the argument extraction. Therefore,
inferring the arguments of the second single-
morpheme trigger from that of the first one based
on Parallel relation is also an available way to
recover arguments.
Like that the topic is an axis in a discourse, the
relations among those relevant event mentions
with the different types is the bone to link them
into a narration. There are a few studies on using
the event relations in NLP (e.g., summarization
(Li et al., 2006), learning narrative event chains
(Chambers and Jurafsky, 2007)) to ensure its
effectiveness. In this paper, we define two types
of Sequence relations of relevant event mentions:
Cause and Temporal for their high probabilities
of sharing arguments.
The Cause relation between the event
mentions are similar to that in the Penn
Discourse TreeBank 2.0 (Prasad et al., 2008).
For example, an Attack event often is the cause
of an Die or Injure event. Our Temporal relation
is limited to those mentions with the same or
relevant event types (e.g., Transport and Arrest)
for the high probabilities of sharing arguments.
Take the following discourse as a sample:
D3: 这批战俘离开(E6)阿尔及利亚西部城市廷
杜夫前往(E7)摩洛哥西南部城市阿加迪尔。
(These prisoners left (E6) Tindouf, a western
city of Algeria, and went (E7) to Agadir, a
southwestern city of Morocco.) - From
Xin20001215.2000.0158
In D3, there are two Transport mentions and it
is natural to infer 阿 加 迪尔 (Agadir) as the
Destination role of E6 and 廷杜夫 (Tindouf) as
the Origin role of E7 via their Sequence relation.
</bodyText>
<page confidence="0.945883">
1480
</page>
<subsectionHeader confidence="0.9888535">
4.3 Identifying Relations of Event Mention
Pairs
</subsectionHeader>
<bodyText confidence="0.999823615384616">
Currently, there are only few studies focusing on
such area (e.g., Ahn, 2006; Chamber and
Jurafsky, 2007; Huang and Rillof, 2012; Do et al.,
2012) and their approaches cannot be introduced
to our system directly for the language nature
and the different goal. We try to achieve a higher
accuracy in this stage so that our argument
inference can recover more true arguments.
Inspired by Li and Zhou (2012), we also use
the morphological structure to identify the
Parallel relation. Two parallel event mentions
with the adjacent trigger mentions w1 and w2 must
satisfy follows two conditions:
</bodyText>
<equation confidence="0.8902005">
1) Morph(w1,w2) is Coordination
2) HM(w1 )∈ Ti , HM(w2)∈ Tj i ≠ j
</equation>
<bodyText confidence="0.956642878787879">
where Morph(w1,w2) is a function to recognize
the morphological structure of joint word w1w2,
HM(wi) is to identify the head morpheme1 in
word wi and Ti is the set of the head morphemes
with ith event type. These constraints are
enlightened by the fact that only Chinese words
with Coordination structure can be divided into
two new words and each word can trigger an
event with the different event type 2 . The
implementation of Morph(w1,w2) and HM(w) are
described in Li and Zhou (2012).
The Coreference relation is divided into two
types: Noun-based Coreference (NC) and Event-
based Coreference (EC) while the former always
uses a verbal noun to refer to an event mentioned
in current or previous sentence and the latter is
that an event is mentioned twice or more actually.
For example, the relation between E2 and E3 in
D1 is NC while the trigger of E3 is only a verbal
noun without any direct arguments and it refers
to E2.
We adopt a simple rule to recognize those NC
relations: for each event mention whose trigger is
a noun and doesn’t act as the subject/object, we
regard their relation as NC if there is another
event mention with the same trigger in current or
previous sentence.
Inspired by Ahn (2006), we use the following
conditions to infer the EC relations between two
event mentions with the same event type:
1) Their trigger mentions refer to the same
trigger;
2) They have at least one same or similar
</bodyText>
<footnote confidence="0.7793235">
1 It acts as the governing semantic element in a Chinese
word.
2 If they have the same event type, they will be regarded as
a single event mention.
</footnote>
<bodyText confidence="0.93273">
subject/object;
3) The score of cosine similarity of two event
mentions is more than a threshold3.
Finally, for the Sequence relation, instead of
identifying and classifying the relations clearly
and correctly, our goal is to identify whether
there are relevant event mentions in a long
sentence or two adjacent short sentences who
share arguments. Algorithm 1 illustrates a
knowledge-based approach to identify the
Sequence event relation in a discourse for any
two trigger mentions tri1 and tri2 as follows:
Algorithm 1
</bodyText>
<listItem confidence="0.99265675">
1: input: tri1 and tri2 and their type et1 and et2
2: output: whether their relation is Sequence
3: begin
4: hm1 ←HM(tri1); hm2 ←HM(tri2)
5: MP ←FindAllMP(hm1,et1,hm2,et2)
6: for any mpi in MP
7: if ShareArg(mpi) is true then
8: return true // Sequence
9: end if
10: end for
11: return false
12: end
</listItem>
<bodyText confidence="0.999900210526316">
In algorithm 1, HM(tri) is to identify the head
morpheme in trigger tri and FindAllMP(hm1, et1,
hm2, et2) is to find all event mention pairs in the
training set which satisfy the condition that their
head morphemes are hm1 and hm2, and their
event types are et1 and et2 respectively. Besides,
ShareArg(mpi)is used to identify whether the
event mention pair mpi sharing at least one
argument. In this algorithm, since the relations
on the event types are too coarse, we introduce a
more fine-gained Sequence relation both on the
event types and the head morphemes of the
triggers which can divide an event type into
many subtypes on the head morpheme. Li and
Zhou (2012) have ensured the effectiveness of
using head morpheme to infer the triggers and
our experiment results also show it is helpful for
identifying relevant event mentions which aims
to the higher accuracy.
</bodyText>
<subsectionHeader confidence="0.989229">
4.4 Global Argument Inference Model
</subsectionHeader>
<bodyText confidence="0.9998724">
Our global argument inference model is
composed of two steps: 1) training two sentence-
based classifiers: argument identifier (AI) and
role determiner (RD) that estimate the score of a
candidate acts as an argument and belongs to a
</bodyText>
<page confidence="0.8286655">
3 The threshold is tuned to 0.78 on the training set.
1481
</page>
<bodyText confidence="0.99982996">
specific role following Section 3. 2) Using the
scores of two classifiers and the event relations
in a sentence, a discourse or a document, we
perform global optimization to infer those
missing or long distance arguments and their
roles.
To incorporate those event relations with our
global argument inference model, we regard a
document as a tree and divide it into three layers:
document, discourse and sentence. A document
is composed of a set of the discourses while a
discourse contains three sentences. Since almost
all arguments (~98%) of a specific event mention
in the ACE 2005 Chinese corpus appear in the
sentence containing the specific event mention
and its two adjacent sentences (previous and next
sentences), we only consider these three
sentences as a discourse to simplify the process
of identifying the scope of a discourse.
We incorporate different event relations into
our model on the different layer and the goal of
our global argument inference model is to
achieve the maximized scores over a document
on its three layers and two classifiers: AI and RD.
The score of document D is defined as
</bodyText>
<table confidence="0.933693259259259">
“--,g
-,&apos;9Mi`4H”
of the role relations
learning from the training set.
Event type pair Role pair
Parallel relation: Sentence-based
optimization is used to incorporate the Parallel
relation of two event mentions into our model
and they share all arguments in a sentence. Since
Attack-Die Attacker-Agent;
Target-
Victim;...
different event type may have different role set,
each role in a specific event should be mapped to
the corresponding role in its Parallel event when
they have the different event type. For example,
Injure-Die Agent-Agent;
Victim-
Victim;...
the argument 17
Transport- Art (A 12-year-
old younger) in D2 acts as the Attacker role in
the Attack event and the Agent role in the Die
event. We learn those role-pairs from the training
ifact-Entity;
Demonstrate Destination-Place;...
set and Table 2 shows part
</table>
<tableCaption confidence="0.993345">
Table 2. Part of role-pairs for those event
</tableCaption>
<bodyText confidence="0.608828">
mention pairs with Parallel relation.
</bodyText>
<equation confidence="0.999016545454545">
(1)
^
D = arg max (α ∑ ∑ ∑ ∑ (
Y Ii DS i j Ii
∈ &lt; &gt;∈
, T i j k S i j
&lt; &gt;∈ &lt; &gt;
, , , AZ T i j k
∈ &lt; &gt;
, ,
fI (EZ )XZ + (1− fI (EZ ))(1−
</equation>
<bodyText confidence="0.98654275">
To infer the arguments an
d their roles on the
Parallel relation, we enforce the consistency on
the role-pair as follows:
</bodyText>
<equation confidence="0.830558723404255">
X,
))
XZ
(1
+
Y=
&lt; &gt; Y&lt;
i j k l m
, , , , i j k l m
, , &apos;, &apos;, &apos; &gt;
α) ∑ ∑ ∑ ∑ ∑(
∀ ∈ ∧
I D S&lt; &gt;∈ ∧ &lt; &gt; &lt; &gt; &lt; &gt;
∈
i j i i j k i j k
I T ,T S ∧
i , , , , &apos;, &apos; i ,j
A&lt; &gt; &lt; &gt; &lt;
∈ T ∧A &gt; &lt; &gt;
∈ T
i j k l ∧
, , , i j k
, , i j k l
, , &apos;, &apos; i j k
, , &apos;
(6)
Ii DS i j Ii
∈ &lt; &gt;∈
, T i j k S i j
&lt; &gt;∈ &lt; &gt;
, , , AZ T i j k m R
∈ &lt; &gt; ∈
, ,
s.t. XZ E {0,1}
&gt;
))
(1
Y&lt;
(EZ,Rm)Y&lt;
+&gt;+
fD
Z,m
fD(EZ ,Rm))(1−
Z,m
XZ
R (4)
mER
</equation>
<bodyText confidence="0.750932105263158">
where
is the ith discourses in document D;
is the jth sentences in discourse
T&lt;i,j,k&gt; is
the kth event mentions in sentence
is the lth candidate arguments in event mention
T&lt;i,j,k&gt;; Z is used to denote
is the
score of
identifying entity mention EZ as an
argument, where EZ is the lth entity of the kth
event mention of the jth sentence of the ith
discourse in document D.
is the score
of RD assigning role Rm to argument EZ. Finally,
XZ and Y&lt;Z,m&gt; are the indicators denoting whether
entity EZ is an argument and whether the role Rm
is assigned to entity EZ respectively. Besides, Eq.
4 and Eq. 5 are the inferences to enforce that:
</bodyText>
<listItem confidence="0.800704">
1) if an entity belongs to a role, it must be an
argument;
2) if a entity is an
</listItem>
<equation confidence="0.931223631578947">
Y &lt; Z , m &gt; E {0,1} (3)
≥Y&lt;Z,m&gt;∀m∈
X Z = Y &lt; Z , m &gt; (5)
�
Ii
S&lt;i,j&gt;
Ii;
S&lt;i,j&gt;;A&lt;i,j,k,l&gt;
&lt;i,j,k,l&gt;;fI(EZ)
AI
fD(EZ,Rm)
argument of a specific event
mention, it must have a role.
&gt;∈RP ∧E
× &lt; &gt; &lt;
= E
eth eth&apos; i j k l
, , , i j k l
, , &apos;, &apos;&gt;
</equation>
<bodyText confidence="0.947879235294118">
two Parallel event mention eth and
and
=
means they refer to the
same entity mention. With the transitivity
between the indicators X and Y, Eq. 6 also
enforces the consistency
Coreference relation: Since the NC and EC
relcation between two event mentions are
different in the event expression, we introduce
the discourse-based optimization for the former
and document-based optimization for the latter.
For two NC mentions, we ensure that the
succeeding mentions can inherit the arguments
form the previous one. To enforce this
consistency, we just replace all
and
</bodyText>
<equation confidence="0.612949">
eth’
E&lt;i,j,k,l&gt;
E&lt;i,j,k&apos;,l&apos;&gt;
on X&lt;i,j,k,l&gt;and X&lt;i,j,k’,l’&gt;.
fI(EZ)
</equation>
<bodyText confidence="0.98099">
fD(EZ,
Rm) of the succeeding event mention with that of
the previous one, since the previous one have the
more context information.
As for two EC event mentions, algorithm 2
shows how to create the constraints for our
</bodyText>
<equation confidence="0.420192">
m&apos;
(2)
&lt;m,
</equation>
<bodyText confidence="0.923127">
where RPeth×eth&apos; is the set of role-pairs between
</bodyText>
<page confidence="0.977641">
1482
</page>
<bodyText confidence="0.863178666666667">
global argument inference model to infer
arguments and roles.
Algorithm 2
</bodyText>
<listItem confidence="0.993549272727273">
1: input: two event mentions T, T’ and their
arguments set A and A’
2: output: the constraints set C
3: begin
4: for each argument a in A do
5: a’←FindSim(a)
6: if a’≠∅ then
7: C ← C ∪ Consistency(Ya , Ya&apos;)
8: end if
9: end for
10: end
</listItem>
<bodyText confidence="0.9991775">
In algorithm 2, the function FindSim(a) is
used to find a similar candidate argument a’ in
A’ for a. If it’s found, we enforce the consistency
of argument a and a’ in the role by using
Consistency(Ya,Ya’) where Ya and Ya’ are the
indicators in Eq. 1. To evaluate the similarity
between two candidates a and a’, we regard them
as similar ones when they are the same word or
in the same entity coreference chain. We use a
coreference resolution tool to construct the entity
coreference chains, as described in Kong et al
(2010).
Sequence relation: For any two event
mentions in a discourse, we use the event type
pair with their head morphemes (e.g., Attack:—#
(burst) - Die:R(die), Trial-Hearing:*&apos;(trial) -
Sentence:A(sentence)) to search the training set
and then obtain the probabilities of sharing the
arguments as mentioned in algorithm 1. We
denoted Pro&lt;et,et’,HM(tri),HM(tri’),Rm,Rm’&gt; as the
probability of the trigger mentions tri and tri’
(their event types are et and et’ respectively.)
sharing an argument whose roles are Rm and Rm’
respectively. We propose following discourse-
based constraint to enforce the consistency
between the roles of two arguments, which are
related semantically, temporally, causally or
conditionally, based on the probability of sharing
an argument and the absolute value of the
difference between the scores of RD:
</bodyText>
<equation confidence="0.991565157894737">
Y=
&lt; &gt; Y&lt;
i j k l m
, , , , i j k l m
, &apos;, &apos;, &apos;, &apos; &gt;
∈ I T
∧ &lt; &gt; &lt; &gt;
∈ S
i i j k
, , i j
, (7)
∧T&lt;j&apos;,k&apos;&gt;∈ S&lt;,j&apos;&gt; ∧m,m&apos; ER∧Ei j,k,l&gt; =Ei,j&apos;,k&apos;,r&gt;
∧Pr ( , &apos; , ( ), ( &apos;), , )
o et et HM tri HM tri R R &gt;δ∧
m m &apos;
f E
D i j k l m
( &lt; &gt; , R
, &apos;, &apos;, &apos; &apos;
</equation>
<bodyText confidence="0.999606">
where δ and X are the thresholds learned from the
development set; tri and tri’ are triggers of kth
and k’th event mention whose event types are et
and et’ in S&lt;i,j&gt; and S&lt;i,j’&gt; respectively.
</bodyText>
<subsectionHeader confidence="0.9970055">
4.5 Incorporating Argument Semantics into
Global Argument Inference Model
</subsectionHeader>
<bodyText confidence="0.99999116">
We also introduce the argument semantics,
which represent the semantic relations of
argument-argument pair, argument-role pair and
argument-trigger pair, to reflect the cohesion
inside an event. Hong et al. (2011) found out that
there is a strong argument and role consistency in
the ACE 2005 English corpus. Those
consistencies also occur in Chinese and they
reveal the relation between the trigger and its
arguments, and also explore the relation between
the argument and its role. Besides, those entities
act as non-argument also have the consistency
with high probabilities.
To let the global argument inference model
combine those knowledges of argument
semantics, we compute the prior probabilities
P(X&lt;i,j&gt;=1) and P(Y&lt;i,j,m&gt;=1) that entity enj
occurrs in a specific event type eti as an
argument and its role is Rm respectively. To
overcome the sparsity of the entities, we cluster
those entities into more cohesive subtype
following Hong et al. (2011). Hence, following
the independence assumptions described by
Berant et al. (2011), we modify the fI(EZ) and
fD(EZ,Rm)in Eq. 1 as follows:
</bodyText>
<equation confidence="0.999879">
fI (EZ) = log P(XZ =1 |FZ)P(XZ =1) (8)
0)
fD(EZ,Rm) = log P(Y&lt;Z,m&gt; =1  |F&lt;Z,m&gt;)P(X&lt;Z,m&gt; =1)9)
(1−P(X&lt;Z,m&gt; = 1  |F&lt;Z,m&gt;)P(X&lt;Z,m&gt; = 0) (
</equation>
<bodyText confidence="0.998299833333333">
where P(XZ =1  |FZ) and P(Y&lt;Z,m&gt; =1  |F&lt;Z,m&gt; )
are the probabilities from the AI and AD
respectively while FZ and F&lt;Z,m&gt; are the feature
vectors. Besides, P(X&lt;Z ,m&gt; =1) and P(XZ =1)
are the prior probabilities learning from the
training set.
</bodyText>
<sectionHeader confidence="0.994909" genericHeader="method">
5 Experimentation
</sectionHeader>
<bodyText confidence="0.9999258">
In this section, we first describe the experimental
settings and the baseline, and then evaluate our
global argument inference model incorporating
with relevant event mentions and argument
semantics to infer arguments and their roles.
</bodyText>
<subsectionHeader confidence="0.99913">
5.1 Experimental Settings and Baseline
</subsectionHeader>
<bodyText confidence="0.999486666666667">
For fair comparison, we adopt the same
experimental settings as the state-of-the-art event
extraction system (Li et al. 2012b) and all the
</bodyText>
<equation confidence="0.795751526315789">
∈
D S
∧
∀Ii
&lt; &gt; &lt; &gt;
i j i j
,S
, , &apos;
fE
D i j k l m
( &lt; &gt; , )
R
, , ,
)
&gt;λ
|
(1− P(XZ =1
FZ)P(XZ
=
</equation>
<page confidence="0.929439">
1483
</page>
<bodyText confidence="0.999434423076923">
evaluations are experimented on the ACE 2005
Chinese corpus. We randomly select 567
documents as the training set and the remaining
66 documents as the test set. Besides, we reserve
33 documents in the training set as the
development set and use the ground truth entities,
times and values for our training and testing. As
for evaluation, we also follow the standards as
defined in Li et al. (2012b). Finally, all the
sentences in the corpus are divided into words
using a Chinese word segmentation tool
(ICTCLAS)1 with all entities annotated in the
corpus kept. We use Berkeley Parser 2 and
Stanford Parser 3 to create the constituent and
dependency parse trees. Besides, the ME tool
(Maxent) 4 is employed to train individual
component classifiers and lp_solver5 is used to
construct our global argument inference model.
Besides, all the experiments on argument
extraction are done on the output of the trigger
extraction system as described in Li et al.
(2012b). Table 3 shows the performance of the
baseline trigger extraction system and Line 1 in
Table 4 illustrates the results of argument
identification and role determination based on
this system.
</bodyText>
<table confidence="0.99714625">
Trigger Event type
identification determination
P(%) R(%) F1 P(%) R(%) F1
74.4 71.9 73.1 71.4 68.9 70.2
</table>
<tableCaption confidence="0.900747">
Table 3. Performance of the baseline on trigger
identification and event type determination.
</tableCaption>
<subsectionHeader confidence="0.996024">
5.2 Inferring Arguments on Relevant Event
Mentions and Argument Semantics
</subsectionHeader>
<bodyText confidence="0.999919428571429">
We develop a baseline system as mentioned in
Section 3 and Line 2 in Table 4 shows that it
slightly improves the F1-measure by 0.9% over
Li et al. (2012b) due to the incorporation of more
refined features. This result indicates the
limitation of syntactic-based feature engineering.
Before evaluating our global argument
inference model, we should identify the event
relations between two mentions in a sentence, a
discourse or a document. The experimental
results show that the accuracies of identifying
NC, EC, Parallel and Sequence relation are
80.0%, 72.4%, 88.5% and 87.7% respectively.
Those results ensure that our simple methods are
</bodyText>
<footnote confidence="0.9988312">
1http://ictclas.org/
2 http://code.google.com/p/berkeleyparser/
3 http://nlp.stanford.edu/software/lex-parser.shtml
4 http://mallet.cs.umass.edu/
5 http://lpsolve.sourceforge.net/5.5/
</footnote>
<bodyText confidence="0.994700833333333">
effective. Our statistics on the development set
shows almost 65% of the event mentions are
involved in those Correfrence, Parallel and
Sequence relations, which occupy 63%, 50%, 9%
respectively6. Most of the exceptions are isolated
event mentions.
</bodyText>
<table confidence="0.999754125">
System Argument Argument role
identification determination
P(%) R(%) F1 P(%) R(%) F1
Li et al.(2012b) 59.1 57.2 58.1 55.8 52.1 53.9
Baseline 60.5 57.6 59.0 55.7 53.0 54.4
BIM 59.3 60.1 59.7 54.4 55.2 54.8
BIM+RE 60.2 65.6 62.8 55.0 60.0 57.4
BIM+RE+AS 62.9 66.1 64.4 57.2 60.2 58.7
</table>
<tableCaption confidence="0.880761666666667">
Table 4. Performance comparison of argument
extraction on argument identification and role
determination.
</tableCaption>
<bodyText confidence="0.998600794117647">
Once the classifier AI and RD are trained, we
would like to apply our global argument
inference model to infer more inter-sentence
arguments and roles. To achieve an optimal
solution, we formulate the global inference
problem as an Integer Linear Program (ILP),
which leads to maximize the objective function.
ILP is a mathematical method for constraint-
based inference to find the optimal values for a
set of variables that maximize an objective
function in satisfying a certain number of
constraints. In the literature, ILP has been widely
used in many NLP applications (e.g., Barzilay
and Lapata, 2006; Do et al., 2012; Li et al.,
2012b).
For our systems, we firstly evaluate the
performance of our basic global argument
inference model (BIM) with the Eq. 2–5 which
enforce the consistency on AI and RD and then
introduce the inference on the relevant event
mentions (RE) and argument semantics (AS) to
BIM. Table 4 shows their results and we can find
out that:
1) BIM only slightly improves the performance
in F1-measure, as the result of more increase
in recall (R) than decrease in precision (P).
This suggests that those constraints just
enforcing the consistency on AI and RD is not
effective enough to infer more arguments.
2) Compared to the BIM, our model BIM+RE
enhances the performance of argument
identification and role determination by 3.1%
and 2.6% improvement in F1-measure
respectively. This suggests the effectiveness
</bodyText>
<footnote confidence="0.912181">
6 20% of the mentions belongs to both Coreference and
Sequence relations.
</footnote>
<page confidence="0.992435">
1484
</page>
<bodyText confidence="0.997165142857143">
of our global argument inference model on
the relevant event mentions to infer inter-
sentence arguments. Table 5 shows the
contributions of the different event relations
while the Sequence relation gains the highest
improvement of argument identification and
role determination in F1-measure respectively.
</bodyText>
<table confidence="0.9997865">
Constraint Argument Argument role
identification determination
P(%) R(%) F1 P(%) R(%) F1
BIM 59.3 60.1 59.7 54.4 55.2 54.8
+Parallel +0.6 +0.7 +0.6 +0.4 +0.6 +0.5
+NC +0.0 +0.8 +0.4 -0.2 +0.6 +0.2
+EC +0.6 +1.2 +0.9 +0.5 +1.0 +0.7
+ Sequence -0.3 +2.8 +1.2 -0.2 +2.6 +1.1
</table>
<tableCaption confidence="0.983035666666667">
Table 5. Contributions of different event
relations on argument identification and role
determination. (Incremental)
</tableCaption>
<bodyText confidence="0.991911045454545">
3) Our model BIM+ER+AS gains 1.6%
improvement for argument identification, and
1.3% for role determination. The results
ensure that argument semantics not only can
improve the performance of argument
identification, but also is helpful to assign a
correct role to an argument in role
determination.
Table 3 shows 25.6% of trigger mentions
introduced into argument extraction are pseudo
ones. If we use the golden trigger extraction, our
exploration shows that the precision and recall of
argument identification can be up to 78.6% and
88.3% respectively. Table 6 shows the
performance comparison of argument extraction
on AI and RD given golden trigger extraction.
Compared to the Baseline, our system improves
the performance of argument identification and
role determination by 6.4% and 5.8%
improvement in F1-measure respectively, largely
due to the dramatic increase in recall of 10.9%
and 10.4%.
</bodyText>
<table confidence="0.998872">
System Argument Argument role
identification determination
P(%) R(%) F1 P(%) R(%) F1
Baseline 76.2 77.4 76.8 70.4 72.0 71.2
Model2 78.6 88.3 83.2 72.3 82.4 77.0
</table>
<tableCaption confidence="0.799709">
Table 6. Performance comparison of argument
identification and type determination. (Golden
trigger extraction)
</tableCaption>
<subsectionHeader confidence="0.900252">
5.3 Discussion
</subsectionHeader>
<bodyText confidence="0.999991230769231">
The initiation of our paper is that syntactic
features play an important role in current
machine learning-based approaches for English
event extraction, however, their effectiveness is
much reduced in Chinese. So the improvement of
our model for English event extraction is much
less than that of Chinese. However, our model
can be an effective complement of the sentence-
level English argument extraction systems since
the performance of argument extraction is still
low in English and using discourse-level
information is a way to improve its performance,
especially for those event mentions whose
arguments spread in complex sentences.
Moreover, our exploration shows that our
global argument inference model can mine those
arguments within a long distance which are un-
annotated as arguments of a special event
mention in the corpus since the annotators just
tagged arguments in a narrow scope or omitted a
few arguments. Actually, they are the true ones
to our knowledge and are more than 30.6% of
those pseudo arguments inferred by our model.
This ensures that our global argument inference
model and those relations among event mentions
is helpful to argument extraction.
</bodyText>
<sectionHeader confidence="0.999237" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999545277777778">
In this paper we propose a global argument
inference model to extract those inter-sentence
arguments due to the nature of Chinese that it is a
discourse-driven pro-drop language with the
wide spread of ellipsis and the open flexible
sentence structure. In particular, we incorporate
various kinds of event relations and the argument
semantics into the model in the sentence,
discourse and document layers which represent
the cohesion of an event or a topic. The
experimental results ensure that our global
argument inference model outperforms the state-
of-the-art system.
In future work, we will focus on introducing
more semantic information and cross-document
information into the global argument inference
model to improve the performance of argument
extraction.
</bodyText>
<sectionHeader confidence="0.998293" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999240625">
The authors would like to thank three
anonymous reviewers for their comments on this
paper. This research was supported by the
National Natural Science Foundation of China
under Grant No. 61070123, No. 61272260 and
No. 61273320, the National 863 Project of China
under Grant No. 2012AA011102. The co-author
tagged with “*” is the corresponding author.
</bodyText>
<page confidence="0.987958">
1485
</page>
<sectionHeader confidence="0.995875" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999746386792453">
David Ahn. 2006. The Stages of Event Extraction. In
Proc. COLING/ACL 2006 Workshop on
Annotating and Reasoning about Time and Events.
Pages 1-8, Sydney, Australia.
Regina Barzilay and Miralla Lapata. 2006.
Aggregation via Set Partitioning for Natural
Language Generation. In Proc. NAACL 2006,
pages 359-366, New York City, NY.
Jonathan Berant, Ido Dagan and Jacob Goldberger.
2011. Global Learning of Typed Entailment Rules.
In Proc. ACL 2011, pages 610-619, Portland, OR.
Mary Elaine Califf and Raymond J. Mooney. 2003.
Bottom-up Relational Learning of Pattern
Matching rules for Information Extraction. Journal
of Machine Learning Research, 4:177–210.
Nathanael Chambers and Dan Jurafsky. 2008.
Unsupervised Learning of Narrative Event Chains.
In Proc. ACL 2008, pages 789-797, Columbus, OH.
Nathanael Chambers and Dan Jurafsky. 2011.
Template-based Information Extraction without the
Templates. In Proc. ACL 2011, pages 976-986,
Portland, OR.
Zheng Chen and Heng Ji. 2009a. Can One Language
Bootstrap the Other: A Case Study on Event
Extraction. In Proc. NAACL/HLT 2009 Workshop
on Semi-supervised Learning for Natural Language
Processing, pages 66-74, Boulder, Colorado.
Zheng Chen and Heng Ji. 2009b. Language Specific
Issue and Feature Exploration in Chinese Event
Extraction. In Proc. NAACL HLT 2009, pages
209-212, Boulder, Colorado.
Zhengdong Dong and Qiang Dong. 2006. HowNet
and the Computation of Meaning. World Scientific
Pub Co. Inc.
Quang Xuan Do, Wei Lu and Dan Roth. 2012. Joint
Inference for Event Timeline Construction. In Proc.
EMNLP 2012, pages 677-687, Jeju, Korea.
Jianfeng Fu, Zongtian Liu, Zhaoman Zhong and
Jianfang Shan. 2010. Chinese Event Extraction
Based on Feature Weighting. Information
Technology Journal, 9: 184-187.
Ralph Grishman, David Westbrook and Adam Meyers.
2005. NYU’s English ACE 2005 System
Description. In Proc. ACE 2005 Evaluation
Workshop, Gaithersburg, MD.
Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao,
Guodong Zhou and Qiaoming Zhu. 2011. Using
Cross-Entity Inference to Improve Event Extraction.
In Proc. ACL 2011, pages 1127-1136, Portland,
OR.
Ruihong Huang and Ellen Riloff. 2011. Peeling Back
the Layers: Detecting Event Role Fillers in
Secondary Contexts, In Proc. ACL 2011, pages
1137-1147, Portland, OR.
Ruihong Huang and Ellen Riloff. 2012. Modeling
Textual Cohesion for Event Extraction. In Proc.
AAAI 2012, pages 1664-1770, Toronto, Canada.
Heng Ji and Ralph Grishman. 2008. Refining Event
Extraction through Cross-Document Inference. In
Proc. ACL 2008, pages 254-262, Columbus, OH.
Fang Kong, Guodong Zhou, Longhua Qian and
Qiaoming Zhu. 2010. Dependency-driven
Anaphoricity Determination for Coreference
Resolution. In Proc. COLING 2010, pages 599-607,
Beijing, China.
Junhui Li, Guodong Zhou and Hwee Tou Ng. 2010.
Joint Syntactic and Semantic Parsing of Chinese.
In Proc. ACL 2010, pages 1108-1117, Uppsala,
Sweden.
Peifeng Li, Guodong Zhou, Qiaoming Zhu and Libin
Hou. 2012a. Employing Compositional Semantics
and Discourse Consistency in Chinese Event
Extraction. In Proc. EMNLP 2012, pages 1006-
1016, Jeju, Korea.
Peifeng Li, Qiaoming Zhu, Hongjun Diao and
Guodong Zhou. 2012b. Joint Modeling of Trigger
Identification and Event Type Determination in
Chinese Event Extraction. In Proc. COLING 2012,
pages 1635-1652, Mumbai, India.
Peifeng Li and Guodong Zhou. 2012. Employing
Morphological Structures and Sememes for
Chinese Event Extraction. In Proc. COLING 2012,
pages 1619-1634, Mumbai, India.
Wenjie Li, Mingliu Wu, Qin Lu, Wei Xu and Chunfa
Yuan. 2006. Extractive Summarization using Inter-
and Intra- Event Relevance. In Proc.
COLING/ACL 2006, pages 369-376, Sydney,
Australia.
Shasha Liao and Ralph Grishman. 2010. Using
Document Level Cross-Event Inference to Improve
Event Extraction. In Proc. ACL 2010, pages 789-
797, Uppsala, Sweden.
Wei Lu and Dan Roth. 2012. Automatic Event
Extraction with Structured Preference Modeling.
In Proc. ACL 2012, pages 835-844, Jeju, Korea.
Gideon Mann. 2007. Multi-document Relationship
Fusion via Constraints on Probabilistic Databases.
In Proc. HLT/NAACL 2007, pages 332-229,
Rochester, NY.
Siddharth Patwardhan and Ellen Riloff. 2007.
Effective Information Extraction with Semantic
Affinity Patterns and Relevant Regions. In Proc.
EMNLP/CoNLL 2007, pages 717-727, Prague,
Czech Republic.
Siddharth Patwardhan and Ellen Riloff. 2009. A
Unified Model of Phrasal and Sentential Evidence
</reference>
<page confidence="0.833005">
1486
</page>
<reference confidence="0.999863419354839">
for Information Extraction. In Proc. EMNLP 2009,
pages 151-160, Singapore.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni
Miltsakaki, Livio Robaldo, Aravind Joshi and
Bonnie Webber. 2008. The Penn Discourse
Treebank 2.0. In Proc. LREC 2008, pages 2961-
2968, Marrakech, Morocco.
Bing Qin, Yanyan Zhao, Xiao Ding, Ting Liu and
Guofu Zhai. 2010. Event Type Recognition Based
on Trigger Expansion. Tsinghua Science and
Technology, 15(3): 251-258, Beijing, China.
Ellen Riloff. 1996. Automatically Generating
Extraction Patterns from Untagged Text. In Proc.
AAAI 1996, pages 1044–1049, Portland, OR.
Hongye Tan, Tiejun Zhao, Jiaheng Zheng. 2008.
Identification of Chinese Event and Their
Argument Roles. In Proc. 2008 IEEE International
Conference on Computer and Information
Technology Workshops, pages 14-19, Sydney,
Australia.
Nianwen Xue and Yaqin Yang. 2010. Chinese
Sentence Segmentation as Comma ClassiÞcation.
In Proc. ACL 2010, pages 631-635, Uppsala,
Sweden.
Roman Yangarber, Clive Best, Peter von Etter, Flavio
Fuart, David Horby and Ralf Steinberger. 2007.
Combining Information about Epidemic Threats
from Multiple Sources. In Proc. RANLP 2007
Workshop on Multi-source, Multilingual
Information Extraction and Summarization, pages
41-48, Borovets, Bulgaria.
</reference>
<page confidence="0.993911">
1487
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.887642">
<title confidence="0.9965565">Argument Inference from Relevant Event Mentions in Argument Extraction</title>
<author confidence="0.998838">Peifeng Li</author>
<author confidence="0.998838">Qiaoming Zhu</author>
<author confidence="0.998838">Guodong</author>
<affiliation confidence="0.999847">School of Computer Science &amp;</affiliation>
<address confidence="0.904423">Soochow University, Suzhou, 215006, China</address>
<email confidence="0.992538">pfli@suda.edu.cn</email>
<email confidence="0.992538">qmzhu@suda.edu.cn</email>
<email confidence="0.992538">gdzhou@suda.edu.cn</email>
<abstract confidence="0.999729555555556">As a paratactic language, sentence-level argument extraction in Chinese suffers much from the frequent occurrence of ellipsis with regard to inter-sentence arguments. To resolve such problem, this paper proposes a novel global argument inference model to explore specific such as relevant event mentions to recover those intersentence arguments in the sentence, discourse and document layers which represent the cohesion of an event or a topic. Evaluation on the ACE 2005 Chinese corpus justifies the effectiveness of our global argument inference model over a state-of-the-art baseline.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Ahn</author>
</authors>
<title>The Stages of Event Extraction.</title>
<date>2006</date>
<booktitle>In Proc. COLING/ACL 2006 Workshop on Annotating and Reasoning about Time and Events.</booktitle>
<pages>1--8</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="5455" citStr="Ahn, 2006" startWordPosition="817" endWordPosition="818">ork. Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental results and gives deep analysis. Finally, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under </context>
<context position="17733" citStr="Ahn, 2006" startWordPosition="2750" endWordPosition="2751">rest) for the high probabilities of sharing arguments. Take the following discourse as a sample: D3: 这批战俘离开(E6)阿尔及利亚西部城市廷 杜夫前往(E7)摩洛哥西南部城市阿加迪尔。 (These prisoners left (E6) Tindouf, a western city of Algeria, and went (E7) to Agadir, a southwestern city of Morocco.) - From Xin20001215.2000.0158 In D3, there are two Transport mentions and it is natural to infer 阿 加 迪尔 (Agadir) as the Destination role of E6 and 廷杜夫 (Tindouf) as the Origin role of E7 via their Sequence relation. 1480 4.3 Identifying Relations of Event Mention Pairs Currently, there are only few studies focusing on such area (e.g., Ahn, 2006; Chamber and Jurafsky, 2007; Huang and Rillof, 2012; Do et al., 2012) and their approaches cannot be introduced to our system directly for the language nature and the different goal. We try to achieve a higher accuracy in this stage so that our argument inference can recover more true arguments. Inspired by Li and Zhou (2012), we also use the morphological structure to identify the Parallel relation. Two parallel event mentions with the adjacent trigger mentions w1 and w2 must satisfy follows two conditions: 1) Morph(w1,w2) is Coordination 2) HM(w1 )∈ Ti , HM(w2)∈ Tj i ≠ j where Morph(w1,w2) </context>
<context position="19527" citStr="Ahn (2006)" startWordPosition="3062" endWordPosition="3063">hile the former always uses a verbal noun to refer to an event mentioned in current or previous sentence and the latter is that an event is mentioned twice or more actually. For example, the relation between E2 and E3 in D1 is NC while the trigger of E3 is only a verbal noun without any direct arguments and it refers to E2. We adopt a simple rule to recognize those NC relations: for each event mention whose trigger is a noun and doesn’t act as the subject/object, we regard their relation as NC if there is another event mention with the same trigger in current or previous sentence. Inspired by Ahn (2006), we use the following conditions to infer the EC relations between two event mentions with the same event type: 1) Their trigger mentions refer to the same trigger; 2) They have at least one same or similar 1 It acts as the governing semantic element in a Chinese word. 2 If they have the same event type, they will be regarded as a single event mention. subject/object; 3) The score of cosine similarity of two event mentions is more than a threshold3. Finally, for the Sequence relation, instead of identifying and classifying the relations clearly and correctly, our goal is to identify whether t</context>
</contexts>
<marker>Ahn, 2006</marker>
<rawString>David Ahn. 2006. The Stages of Event Extraction. In Proc. COLING/ACL 2006 Workshop on Annotating and Reasoning about Time and Events. Pages 1-8, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Miralla Lapata</author>
</authors>
<title>Aggregation via Set Partitioning for Natural Language Generation.</title>
<date>2006</date>
<booktitle>In Proc. NAACL</booktitle>
<pages>359--366</pages>
<location>New York City, NY.</location>
<contexts>
<context position="34128" citStr="Barzilay and Lapata, 2006" startWordPosition="5675" endWordPosition="5678">d role determination. Once the classifier AI and RD are trained, we would like to apply our global argument inference model to infer more inter-sentence arguments and roles. To achieve an optimal solution, we formulate the global inference problem as an Integer Linear Program (ILP), which leads to maximize the objective function. ILP is a mathematical method for constraintbased inference to find the optimal values for a set of variables that maximize an objective function in satisfying a certain number of constraints. In the literature, ILP has been widely used in many NLP applications (e.g., Barzilay and Lapata, 2006; Do et al., 2012; Li et al., 2012b). For our systems, we firstly evaluate the performance of our basic global argument inference model (BIM) with the Eq. 2–5 which enforce the consistency on AI and RD and then introduce the inference on the relevant event mentions (RE) and argument semantics (AS) to BIM. Table 4 shows their results and we can find out that: 1) BIM only slightly improves the performance in F1-measure, as the result of more increase in recall (R) than decrease in precision (P). This suggests that those constraints just enforcing the consistency on AI and RD is not effective eno</context>
</contexts>
<marker>Barzilay, Lapata, 2006</marker>
<rawString>Regina Barzilay and Miralla Lapata. 2006. Aggregation via Set Partitioning for Natural Language Generation. In Proc. NAACL 2006, pages 359-366, New York City, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jonathan Berant</author>
<author>Ido Dagan</author>
<author>Jacob Goldberger</author>
</authors>
<title>Global Learning of Typed Entailment Rules.</title>
<date>2011</date>
<booktitle>In Proc. ACL 2011,</booktitle>
<pages>610--619</pages>
<location>Portland, OR.</location>
<contexts>
<context position="29671" citStr="Berant et al. (2011)" startWordPosition="4958" endWordPosition="4961">nd also explore the relation between the argument and its role. Besides, those entities act as non-argument also have the consistency with high probabilities. To let the global argument inference model combine those knowledges of argument semantics, we compute the prior probabilities P(X&lt;i,j&gt;=1) and P(Y&lt;i,j,m&gt;=1) that entity enj occurrs in a specific event type eti as an argument and its role is Rm respectively. To overcome the sparsity of the entities, we cluster those entities into more cohesive subtype following Hong et al. (2011). Hence, following the independence assumptions described by Berant et al. (2011), we modify the fI(EZ) and fD(EZ,Rm)in Eq. 1 as follows: fI (EZ) = log P(XZ =1 |FZ)P(XZ =1) (8) 0) fD(EZ,Rm) = log P(Y&lt;Z,m&gt; =1 |F&lt;Z,m&gt;)P(X&lt;Z,m&gt; =1)9) (1−P(X&lt;Z,m&gt; = 1 |F&lt;Z,m&gt;)P(X&lt;Z,m&gt; = 0) ( where P(XZ =1 |FZ) and P(Y&lt;Z,m&gt; =1 |F&lt;Z,m&gt; ) are the probabilities from the AI and AD respectively while FZ and F&lt;Z,m&gt; are the feature vectors. Besides, P(X&lt;Z ,m&gt; =1) and P(XZ =1) are the prior probabilities learning from the training set. 5 Experimentation In this section, we first describe the experimental settings and the baseline, and then evaluate our global argument inference model incorporating with </context>
</contexts>
<marker>Berant, Dagan, Goldberger, 2011</marker>
<rawString>Jonathan Berant, Ido Dagan and Jacob Goldberger. 2011. Global Learning of Typed Entailment Rules. In Proc. ACL 2011, pages 610-619, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Elaine Califf</author>
<author>Raymond J Mooney</author>
</authors>
<title>Bottom-up Relational Learning of Pattern Matching rules for Information Extraction.</title>
<date>2003</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>4--177</pages>
<contexts>
<context position="5306" citStr="Califf and Mooney, 2003" startWordPosition="794" endWordPosition="797">l argument inference model to unify the semantics of the event and its arguments. The rest of this paper is organized as follows. Section 2 overviews the related work. Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental results and gives deep analysis. Finally, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; </context>
</contexts>
<marker>Califf, Mooney, 2003</marker>
<rawString>Mary Elaine Califf and Raymond J. Mooney. 2003. Bottom-up Relational Learning of Pattern Matching rules for Information Extraction. Journal of Machine Learning Research, 4:177–210.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Unsupervised Learning of Narrative Event Chains.</title>
<date>2008</date>
<booktitle>In Proc. ACL</booktitle>
<pages>789--797</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="7301" citStr="Chambers and Jurafsky (2008)" startWordPosition="1100" endWordPosition="1103">ese argument extraction. Li et al. (2012b) introduce more refined features to the system of Chen and Ji (2009b) as their baseline. Specially, several studies have successfully incorporated cross-document or document-level information and argument semantics into event extraction, most of them focused on English. Yangarber et al. (2007) apply a crossdocument inference mechanism to refine local extraction results for the disease name, location and start/end time. Mann (2007) proposes some constraints on relationship rescoring to impose the discourse consistency on the CEO’s personal information. Chambers and Jurafsky (2008) propose a narrative event chain which are partially ordered sets of event mentions centered around a common protagonist and this chain can represent the relationship among the relevant event mentions in a document. Ji and Grishman (2008) employ a rule-based approach to propagate consistent triggers and arguments across topic-related documents. Liao and Grishman (2010) mainly focus on employing the cross-event consistency information to improve sentence-level trigger extraction and they also propose an inference method to infer the arguments following role consistency in a document. Hong et al</context>
</contexts>
<marker>Chambers, Jurafsky, 2008</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2008. Unsupervised Learning of Narrative Event Chains. In Proc. ACL 2008, pages 789-797, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
<author>Dan Jurafsky</author>
</authors>
<title>Template-based Information Extraction without the Templates.</title>
<date>2011</date>
<booktitle>In Proc. ACL 2011,</booktitle>
<pages>976--986</pages>
<location>Portland, OR.</location>
<contexts>
<context position="5365" citStr="Chambers and Jurafsky, 2011" startWordPosition="802" endWordPosition="805">he event and its arguments. The rest of this paper is organized as follows. Section 2 overviews the related work. Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental results and gives deep analysis. Finally, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chin</context>
</contexts>
<marker>Chambers, Jurafsky, 2011</marker>
<rawString>Nathanael Chambers and Dan Jurafsky. 2011. Template-based Information Extraction without the Templates. In Proc. ACL 2011, pages 976-986, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Heng Ji</author>
</authors>
<title>Can One Language Bootstrap the Other: A Case Study on Event Extraction.</title>
<date>2009</date>
<booktitle>In Proc. NAACL/HLT 2009 Workshop on Semi-supervised Learning for Natural Language Processing,</booktitle>
<pages>66--74</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="1499" citStr="Chen and Ji, 2009" startWordPosition="213" endWordPosition="216">eline. 1 Introduction The task of event extraction is to recognize event mentions of a predefined event type and their arguments (participants and attributes). Generally, it can be divided into two subtasks: trigger extraction, which aims to identify trigger/event mentions and determine their event type, and argument extraction, which aims to extract various arguments of a specific event and assign the roles to them. In this paper, we focus on argument extraction in Chinese event extraction. While most of previous studies in Chinese event extraction deal with Chinese trigger extraction (e.g., Chen and Ji, 2009a; Qin et al., 2010; Li et al., 2012a, 2012b), there are only a few on Chinese argument extraction (e.g., Tan et al., 2008; Chen and Ji, 2009b). Following previous studies, we divide argument extraction into two components, argument identification and role determination, where the former recognizes the arguments in a specific event mention and the latter classifies these arguments by roles. With regard to methodology, most of previous studies on argument extraction recast it as a Semantic Role Labeling (SRL) task and focus on intra-sentence information to identify the arguments and their roles</context>
<context position="5903" citStr="Chen and Ji, 2009" startWordPosition="890" endWordPosition="893">iff and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English trigger identification. In additional, there are only very few of them focusing on Chinese argument extraction and almost all aim to feature engineering and are based on sentence-level information and recast this task as an SRL-style task. Tan et al. (2008) introduce multiple levels of patterns to improve the coverage in Chinese argument classification. Chen and Ji (2009b) apply various kinds of lexical, syntactic </context>
</contexts>
<marker>Chen, Ji, 2009</marker>
<rawString>Zheng Chen and Heng Ji. 2009a. Can One Language Bootstrap the Other: A Case Study on Event Extraction. In Proc. NAACL/HLT 2009 Workshop on Semi-supervised Learning for Natural Language Processing, pages 66-74, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zheng Chen</author>
<author>Heng Ji</author>
</authors>
<title>Language Specific Issue and Feature Exploration in Chinese Event Extraction.</title>
<date>2009</date>
<booktitle>In Proc. NAACL HLT</booktitle>
<pages>209--212</pages>
<location>Boulder, Colorado.</location>
<contexts>
<context position="1499" citStr="Chen and Ji, 2009" startWordPosition="213" endWordPosition="216">eline. 1 Introduction The task of event extraction is to recognize event mentions of a predefined event type and their arguments (participants and attributes). Generally, it can be divided into two subtasks: trigger extraction, which aims to identify trigger/event mentions and determine their event type, and argument extraction, which aims to extract various arguments of a specific event and assign the roles to them. In this paper, we focus on argument extraction in Chinese event extraction. While most of previous studies in Chinese event extraction deal with Chinese trigger extraction (e.g., Chen and Ji, 2009a; Qin et al., 2010; Li et al., 2012a, 2012b), there are only a few on Chinese argument extraction (e.g., Tan et al., 2008; Chen and Ji, 2009b). Following previous studies, we divide argument extraction into two components, argument identification and role determination, where the former recognizes the arguments in a specific event mention and the latter classifies these arguments by roles. With regard to methodology, most of previous studies on argument extraction recast it as a Semantic Role Labeling (SRL) task and focus on intra-sentence information to identify the arguments and their roles</context>
<context position="5903" citStr="Chen and Ji, 2009" startWordPosition="890" endWordPosition="893">iff and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English trigger identification. In additional, there are only very few of them focusing on Chinese argument extraction and almost all aim to feature engineering and are based on sentence-level information and recast this task as an SRL-style task. Tan et al. (2008) introduce multiple levels of patterns to improve the coverage in Chinese argument classification. Chen and Ji (2009b) apply various kinds of lexical, syntactic </context>
</contexts>
<marker>Chen, Ji, 2009</marker>
<rawString>Zheng Chen and Heng Ji. 2009b. Language Specific Issue and Feature Exploration in Chinese Event Extraction. In Proc. NAACL HLT 2009, pages 209-212, Boulder, Colorado.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhengdong Dong</author>
<author>Qiang Dong</author>
</authors>
<title>HowNet and the Computation of Meaning. World Scientific Pub Co.</title>
<date>2006</date>
<publisher>Inc.</publisher>
<contexts>
<context position="10845" citStr="Dong and Dong, 2006" startWordPosition="1646" endWordPosition="1649">of the entity + its POS, left neighbour word of the trigger + its POS, right neighbour word of the trigger + its POS; 3) Dependency features: dependency path from the entity to the trigger, depth of the dependency path; 4) Syntactic features: path from the trigger to the entity, difference of the depths of the trigger and entity, place of the entity (before trigger or after trigger), depth of the path from the trigger to the entity, siblings of the entity; 5) Semantic features: semantic role of the entity tagged by an SRL tool (e.g., ARG0, ARG1) (Li et al., 2010), sememe of trigger in Hownet (Dong and Dong, 2006). 4 Inferring Inter-Sentence Arguments on Relevant Event Mentions In this paper, a global argument inference model is proposed to infer those inter-sentence arguments and their roles, incorporating with semantic relations between relevant event mention pairs and argument semantics. 4.1 Motivation It’s well-known that Chinese is a paratactic language, with an open flexible sentence structure and often omits the subject or the object, while English is a hypotactic language with a strict sentence structure and emphasizes on cohesion between clauses. Hence, there are two issues in Chinese argument</context>
</contexts>
<marker>Dong, Dong, 2006</marker>
<rawString>Zhengdong Dong and Qiang Dong. 2006. HowNet and the Computation of Meaning. World Scientific Pub Co. Inc.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Quang Xuan Do</author>
<author>Wei Lu</author>
<author>Dan Roth</author>
</authors>
<title>Joint Inference for Event Timeline Construction.</title>
<date>2012</date>
<booktitle>In Proc. EMNLP 2012,</booktitle>
<pages>677--687</pages>
<location>Jeju,</location>
<contexts>
<context position="17803" citStr="Do et al., 2012" startWordPosition="2760" endWordPosition="2763"> following discourse as a sample: D3: 这批战俘离开(E6)阿尔及利亚西部城市廷 杜夫前往(E7)摩洛哥西南部城市阿加迪尔。 (These prisoners left (E6) Tindouf, a western city of Algeria, and went (E7) to Agadir, a southwestern city of Morocco.) - From Xin20001215.2000.0158 In D3, there are two Transport mentions and it is natural to infer 阿 加 迪尔 (Agadir) as the Destination role of E6 and 廷杜夫 (Tindouf) as the Origin role of E7 via their Sequence relation. 1480 4.3 Identifying Relations of Event Mention Pairs Currently, there are only few studies focusing on such area (e.g., Ahn, 2006; Chamber and Jurafsky, 2007; Huang and Rillof, 2012; Do et al., 2012) and their approaches cannot be introduced to our system directly for the language nature and the different goal. We try to achieve a higher accuracy in this stage so that our argument inference can recover more true arguments. Inspired by Li and Zhou (2012), we also use the morphological structure to identify the Parallel relation. Two parallel event mentions with the adjacent trigger mentions w1 and w2 must satisfy follows two conditions: 1) Morph(w1,w2) is Coordination 2) HM(w1 )∈ Ti , HM(w2)∈ Tj i ≠ j where Morph(w1,w2) is a function to recognize the morphological structure of joint word w</context>
<context position="34145" citStr="Do et al., 2012" startWordPosition="5679" endWordPosition="5682">the classifier AI and RD are trained, we would like to apply our global argument inference model to infer more inter-sentence arguments and roles. To achieve an optimal solution, we formulate the global inference problem as an Integer Linear Program (ILP), which leads to maximize the objective function. ILP is a mathematical method for constraintbased inference to find the optimal values for a set of variables that maximize an objective function in satisfying a certain number of constraints. In the literature, ILP has been widely used in many NLP applications (e.g., Barzilay and Lapata, 2006; Do et al., 2012; Li et al., 2012b). For our systems, we firstly evaluate the performance of our basic global argument inference model (BIM) with the Eq. 2–5 which enforce the consistency on AI and RD and then introduce the inference on the relevant event mentions (RE) and argument semantics (AS) to BIM. Table 4 shows their results and we can find out that: 1) BIM only slightly improves the performance in F1-measure, as the result of more increase in recall (R) than decrease in precision (P). This suggests that those constraints just enforcing the consistency on AI and RD is not effective enough to infer more</context>
</contexts>
<marker>Do, Lu, Roth, 2012</marker>
<rawString>Quang Xuan Do, Wei Lu and Dan Roth. 2012. Joint Inference for Event Timeline Construction. In Proc. EMNLP 2012, pages 677-687, Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jianfeng Fu</author>
</authors>
<title>Zongtian Liu, Zhaoman Zhong and Jianfang Shan.</title>
<date>2010</date>
<journal>Information Technology Journal,</journal>
<volume>9</volume>
<pages>184--187</pages>
<marker>Fu, 2010</marker>
<rawString>Jianfeng Fu, Zongtian Liu, Zhaoman Zhong and Jianfang Shan. 2010. Chinese Event Extraction Based on Feature Weighting. Information Technology Journal, 9: 184-187.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ralph Grishman</author>
<author>David Westbrook</author>
<author>Adam Meyers</author>
</authors>
<date>2005</date>
<booktitle>NYU’s English ACE 2005 System Description. In Proc. ACE 2005 Evaluation Workshop,</booktitle>
<location>Gaithersburg, MD.</location>
<contexts>
<context position="5444" citStr="Grishman et al., 2005" startWordPosition="813" endWordPosition="816">overviews the related work. Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental results and gives deep analysis. Finally, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expans</context>
</contexts>
<marker>Grishman, Westbrook, Meyers, 2005</marker>
<rawString>Ralph Grishman, David Westbrook and Adam Meyers. 2005. NYU’s English ACE 2005 System Description. In Proc. ACE 2005 Evaluation Workshop, Gaithersburg, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yu Hong</author>
<author>Jianfeng Zhang</author>
<author>Bin Ma</author>
<author>Jianmin Yao</author>
</authors>
<title>Guodong Zhou and Qiaoming Zhu.</title>
<date>2011</date>
<booktitle>In Proc. ACL 2011,</booktitle>
<pages>1127--1136</pages>
<location>Portland, OR.</location>
<contexts>
<context position="4459" citStr="Hong et al. (2011)" startWordPosition="670" endWordPosition="673">eady mentioned in previous sentences. Similarly, it is hard to recognize Wj--Pi�4t3�JA (two Israelites) as the Target role for event mention E2 and identify kt 0 (bomb) as the Instrument role for event mention E1. An alternative way is to employ various relationships among relevant event mentions in a discourse to infer those intersentence arguments. The contributions of this paper are: 1) We propose a novel global argument inference model, in which various kinds of event relations are involved to infer more arguments on their semantic relations. 2) Different from Liao and Grishman (2010) and Hong et al. (2011), which only consider document-level consistency, we propose a more fine-gained consistency model to enforce the consistency in the sentence, discourse and document layers. 3) We incorporate argument semantics into our global argument inference model to unify the semantics of the event and its arguments. The rest of this paper is organized as follows. Section 2 overviews the related work. Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental res</context>
<context position="5736" citStr="Hong et al., 2011" startWordPosition="861" endWordPosition="864">in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English trigger identification. In additional, there are only very few of them focusing on Chinese argument extraction and almost all aim to feature engineering and are based on sentence-level information and recast this task as an SRL-style task. Tan et al. </context>
<context position="7909" citStr="Hong et al. (2011)" startWordPosition="1188" endWordPosition="1191">sky (2008) propose a narrative event chain which are partially ordered sets of event mentions centered around a common protagonist and this chain can represent the relationship among the relevant event mentions in a document. Ji and Grishman (2008) employ a rule-based approach to propagate consistent triggers and arguments across topic-related documents. Liao and Grishman (2010) mainly focus on employing the cross-event consistency information to improve sentence-level trigger extraction and they also propose an inference method to infer the arguments following role consistency in a document. Hong et al. (2011) employ the background information to divide an entity type into more cohesive subtypes to create the bridge between two entities and then infer arguments and their roles using cross-entity inference on the subtypes of entities. Huang and Rillof (2012) propose a sequentially structured sentence classifier which uses lexical associations and discourse relations across sentences to identify event-related document contexts and then apply it to recognize arguments and their roles on the relation among triggers and arguments. 1478 3 Baseline In the task of event extraction as defined in ACE evaluat</context>
<context position="28844" citStr="Hong et al. (2011)" startWordPosition="4829" endWordPosition="4832">&lt;,j&apos;&gt; ∧m,m&apos; ER∧Ei j,k,l&gt; =Ei,j&apos;,k&apos;,r&gt; ∧Pr ( , &apos; , ( ), ( &apos;), , ) o et et HM tri HM tri R R &gt;δ∧ m m &apos; f E D i j k l m ( &lt; &gt; , R , &apos;, &apos;, &apos; &apos; where δ and X are the thresholds learned from the development set; tri and tri’ are triggers of kth and k’th event mention whose event types are et and et’ in S&lt;i,j&gt; and S&lt;i,j’&gt; respectively. 4.5 Incorporating Argument Semantics into Global Argument Inference Model We also introduce the argument semantics, which represent the semantic relations of argument-argument pair, argument-role pair and argument-trigger pair, to reflect the cohesion inside an event. Hong et al. (2011) found out that there is a strong argument and role consistency in the ACE 2005 English corpus. Those consistencies also occur in Chinese and they reveal the relation between the trigger and its arguments, and also explore the relation between the argument and its role. Besides, those entities act as non-argument also have the consistency with high probabilities. To let the global argument inference model combine those knowledges of argument semantics, we compute the prior probabilities P(X&lt;i,j&gt;=1) and P(Y&lt;i,j,m&gt;=1) that entity enj occurrs in a specific event type eti as an argument and its ro</context>
</contexts>
<marker>Hong, Zhang, Ma, Yao, 2011</marker>
<rawString>Yu Hong, Jianfeng Zhang, Bin Ma, Jianmin Yao, Guodong Zhou and Qiaoming Zhu. 2011. Using Cross-Entity Inference to Improve Event Extraction. In Proc. ACL 2011, pages 1127-1136, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruihong Huang</author>
<author>Ellen Riloff</author>
</authors>
<title>Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts,</title>
<date>2011</date>
<booktitle>In Proc. ACL 2011,</booktitle>
<pages>1137--1147</pages>
<location>Portland, OR.</location>
<contexts>
<context position="5760" citStr="Huang and Riloff, 2011" startWordPosition="865" endWordPosition="868">ated Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English trigger identification. In additional, there are only very few of them focusing on Chinese argument extraction and almost all aim to feature engineering and are based on sentence-level information and recast this task as an SRL-style task. Tan et al. (2008) introduce multipl</context>
</contexts>
<marker>Huang, Riloff, 2011</marker>
<rawString>Ruihong Huang and Ellen Riloff. 2011. Peeling Back the Layers: Detecting Event Role Fillers in Secondary Contexts, In Proc. ACL 2011, pages 1137-1147, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruihong Huang</author>
<author>Ellen Riloff</author>
</authors>
<title>Modeling Textual Cohesion for Event Extraction. In</title>
<date>2012</date>
<booktitle>Proc. AAAI 2012,</booktitle>
<pages>1664--1770</pages>
<location>Toronto, Canada.</location>
<marker>Huang, Riloff, 2012</marker>
<rawString>Ruihong Huang and Ellen Riloff. 2012. Modeling Textual Cohesion for Event Extraction. In Proc. AAAI 2012, pages 1664-1770, Toronto, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heng Ji</author>
<author>Ralph Grishman</author>
</authors>
<title>Refining Event Extraction through Cross-Document Inference.</title>
<date>2008</date>
<booktitle>In Proc. ACL</booktitle>
<pages>254--262</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="7539" citStr="Ji and Grishman (2008)" startWordPosition="1137" endWordPosition="1140">nt semantics into event extraction, most of them focused on English. Yangarber et al. (2007) apply a crossdocument inference mechanism to refine local extraction results for the disease name, location and start/end time. Mann (2007) proposes some constraints on relationship rescoring to impose the discourse consistency on the CEO’s personal information. Chambers and Jurafsky (2008) propose a narrative event chain which are partially ordered sets of event mentions centered around a common protagonist and this chain can represent the relationship among the relevant event mentions in a document. Ji and Grishman (2008) employ a rule-based approach to propagate consistent triggers and arguments across topic-related documents. Liao and Grishman (2010) mainly focus on employing the cross-event consistency information to improve sentence-level trigger extraction and they also propose an inference method to infer the arguments following role consistency in a document. Hong et al. (2011) employ the background information to divide an entity type into more cohesive subtypes to create the bridge between two entities and then infer arguments and their roles using cross-entity inference on the subtypes of entities. H</context>
</contexts>
<marker>Ji, Grishman, 2008</marker>
<rawString>Heng Ji and Ralph Grishman. 2008. Refining Event Extraction through Cross-Document Inference. In Proc. ACL 2008, pages 254-262, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fang Kong</author>
<author>Guodong Zhou</author>
<author>Longhua Qian</author>
<author>Qiaoming Zhu</author>
</authors>
<title>Dependency-driven Anaphoricity Determination for Coreference Resolution. In</title>
<date>2010</date>
<booktitle>Proc. COLING 2010,</booktitle>
<pages>599--607</pages>
<location>Beijing, China.</location>
<contexts>
<context position="27291" citStr="Kong et al (2010)" startWordPosition="4541" endWordPosition="4544">a’←FindSim(a) 6: if a’≠∅ then 7: C ← C ∪ Consistency(Ya , Ya&apos;) 8: end if 9: end for 10: end In algorithm 2, the function FindSim(a) is used to find a similar candidate argument a’ in A’ for a. If it’s found, we enforce the consistency of argument a and a’ in the role by using Consistency(Ya,Ya’) where Ya and Ya’ are the indicators in Eq. 1. To evaluate the similarity between two candidates a and a’, we regard them as similar ones when they are the same word or in the same entity coreference chain. We use a coreference resolution tool to construct the entity coreference chains, as described in Kong et al (2010). Sequence relation: For any two event mentions in a discourse, we use the event type pair with their head morphemes (e.g., Attack:—# (burst) - Die:R(die), Trial-Hearing:*&apos;(trial) - Sentence:A(sentence)) to search the training set and then obtain the probabilities of sharing the arguments as mentioned in algorithm 1. We denoted Pro&lt;et,et’,HM(tri),HM(tri’),Rm,Rm’&gt; as the probability of the trigger mentions tri and tri’ (their event types are et and et’ respectively.) sharing an argument whose roles are Rm and Rm’ respectively. We propose following discoursebased constraint to enforce the consis</context>
</contexts>
<marker>Kong, Zhou, Qian, Zhu, 2010</marker>
<rawString>Fang Kong, Guodong Zhou, Longhua Qian and Qiaoming Zhu. 2010. Dependency-driven Anaphoricity Determination for Coreference Resolution. In Proc. COLING 2010, pages 599-607, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Junhui Li</author>
</authors>
<title>Guodong Zhou and Hwee Tou Ng.</title>
<date>2010</date>
<booktitle>In Proc. ACL 2010,</booktitle>
<pages>1108--1117</pages>
<location>Uppsala,</location>
<marker>Li, 2010</marker>
<rawString>Junhui Li, Guodong Zhou and Hwee Tou Ng. 2010. Joint Syntactic and Semantic Parsing of Chinese. In Proc. ACL 2010, pages 1108-1117, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peifeng Li</author>
</authors>
<title>Guodong Zhou, Qiaoming Zhu and Libin Hou.</title>
<date></date>
<booktitle>2012a. Employing Compositional Semantics and Discourse Consistency in Chinese Event Extraction. In Proc. EMNLP 2012,</booktitle>
<pages>1006--1016</pages>
<location>Jeju,</location>
<marker>Li, </marker>
<rawString>Peifeng Li, Guodong Zhou, Qiaoming Zhu and Libin Hou. 2012a. Employing Compositional Semantics and Discourse Consistency in Chinese Event Extraction. In Proc. EMNLP 2012, pages 1006-1016, Jeju, Korea.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Peifeng Li</author>
</authors>
<title>Qiaoming Zhu, Hongjun Diao and Guodong Zhou. 2012b. Joint Modeling of Trigger Identification and Event Type Determination in Chinese Event Extraction.</title>
<booktitle>In Proc. COLING 2012,</booktitle>
<pages>1635--1652</pages>
<location>Mumbai, India.</location>
<marker>Li, </marker>
<rawString>Peifeng Li, Qiaoming Zhu, Hongjun Diao and Guodong Zhou. 2012b. Joint Modeling of Trigger Identification and Event Type Determination in Chinese Event Extraction. In Proc. COLING 2012, pages 1635-1652, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peifeng Li</author>
<author>Guodong Zhou</author>
</authors>
<title>Employing Morphological Structures and Sememes for Chinese Event Extraction.</title>
<date>2012</date>
<booktitle>In Proc. COLING 2012,</booktitle>
<pages>1619--1634</pages>
<location>Mumbai, India.</location>
<contexts>
<context position="18061" citStr="Li and Zhou (2012)" startWordPosition="2804" endWordPosition="2807">sport mentions and it is natural to infer 阿 加 迪尔 (Agadir) as the Destination role of E6 and 廷杜夫 (Tindouf) as the Origin role of E7 via their Sequence relation. 1480 4.3 Identifying Relations of Event Mention Pairs Currently, there are only few studies focusing on such area (e.g., Ahn, 2006; Chamber and Jurafsky, 2007; Huang and Rillof, 2012; Do et al., 2012) and their approaches cannot be introduced to our system directly for the language nature and the different goal. We try to achieve a higher accuracy in this stage so that our argument inference can recover more true arguments. Inspired by Li and Zhou (2012), we also use the morphological structure to identify the Parallel relation. Two parallel event mentions with the adjacent trigger mentions w1 and w2 must satisfy follows two conditions: 1) Morph(w1,w2) is Coordination 2) HM(w1 )∈ Ti , HM(w2)∈ Tj i ≠ j where Morph(w1,w2) is a function to recognize the morphological structure of joint word w1w2, HM(wi) is to identify the head morpheme1 in word wi and Ti is the set of the head morphemes with ith event type. These constraints are enlightened by the fact that only Chinese words with Coordination structure can be divided into two new words and each</context>
<context position="21374" citStr="Li and Zhou (2012)" startWordPosition="3378" endWordPosition="3381">pheme in trigger tri and FindAllMP(hm1, et1, hm2, et2) is to find all event mention pairs in the training set which satisfy the condition that their head morphemes are hm1 and hm2, and their event types are et1 and et2 respectively. Besides, ShareArg(mpi)is used to identify whether the event mention pair mpi sharing at least one argument. In this algorithm, since the relations on the event types are too coarse, we introduce a more fine-gained Sequence relation both on the event types and the head morphemes of the triggers which can divide an event type into many subtypes on the head morpheme. Li and Zhou (2012) have ensured the effectiveness of using head morpheme to infer the triggers and our experiment results also show it is helpful for identifying relevant event mentions which aims to the higher accuracy. 4.4 Global Argument Inference Model Our global argument inference model is composed of two steps: 1) training two sentencebased classifiers: argument identifier (AI) and role determiner (RD) that estimate the score of a candidate acts as an argument and belongs to a 3 The threshold is tuned to 0.78 on the training set. 1481 specific role following Section 3. 2) Using the scores of two classifie</context>
</contexts>
<marker>Li, Zhou, 2012</marker>
<rawString>Peifeng Li and Guodong Zhou. 2012. Employing Morphological Structures and Sememes for Chinese Event Extraction. In Proc. COLING 2012, pages 1619-1634, Mumbai, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenjie Li</author>
<author>Mingliu Wu</author>
<author>Qin Lu</author>
<author>Wei Xu</author>
<author>Chunfa Yuan</author>
</authors>
<title>Extractive Summarization using Interand Intra- Event Relevance.</title>
<date>2006</date>
<booktitle>In Proc. COLING/ACL</booktitle>
<pages>369--376</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="16564" citStr="Li et al., 2006" startWordPosition="2560" endWordPosition="2563">. For the errors in the syntactic parsing, the second single-morpheme trigger is often assigned a wrong tag (e.g., NN, JJ) and this leads to the errors in the argument extraction. Therefore, inferring the arguments of the second singlemorpheme trigger from that of the first one based on Parallel relation is also an available way to recover arguments. Like that the topic is an axis in a discourse, the relations among those relevant event mentions with the different types is the bone to link them into a narration. There are a few studies on using the event relations in NLP (e.g., summarization (Li et al., 2006), learning narrative event chains (Chambers and Jurafsky, 2007)) to ensure its effectiveness. In this paper, we define two types of Sequence relations of relevant event mentions: Cause and Temporal for their high probabilities of sharing arguments. The Cause relation between the event mentions are similar to that in the Penn Discourse TreeBank 2.0 (Prasad et al., 2008). For example, an Attack event often is the cause of an Die or Injure event. Our Temporal relation is limited to those mentions with the same or relevant event types (e.g., Transport and Arrest) for the high probabilities of shar</context>
</contexts>
<marker>Li, Wu, Lu, Xu, Yuan, 2006</marker>
<rawString>Wenjie Li, Mingliu Wu, Qin Lu, Wei Xu and Chunfa Yuan. 2006. Extractive Summarization using Interand Intra- Event Relevance. In Proc. COLING/ACL 2006, pages 369-376, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shasha Liao</author>
<author>Ralph Grishman</author>
</authors>
<title>Using Document Level Cross-Event Inference to Improve Event Extraction.</title>
<date>2010</date>
<booktitle>In Proc. ACL 2010,</booktitle>
<pages>789--797</pages>
<location>Uppsala,</location>
<contexts>
<context position="4436" citStr="Liao and Grishman (2010)" startWordPosition="665" endWordPosition="668">it many of these entities already mentioned in previous sentences. Similarly, it is hard to recognize Wj--Pi�4t3�JA (two Israelites) as the Target role for event mention E2 and identify kt 0 (bomb) as the Instrument role for event mention E1. An alternative way is to employ various relationships among relevant event mentions in a discourse to infer those intersentence arguments. The contributions of this paper are: 1) We propose a novel global argument inference model, in which various kinds of event relations are involved to infer more arguments on their semantic relations. 2) Different from Liao and Grishman (2010) and Hong et al. (2011), which only consider document-level consistency, we propose a more fine-gained consistency model to enforce the consistency in the sentence, discourse and document layers. 3) We incorporate argument semantics into our global argument inference model to unify the semantics of the event and its arguments. The rest of this paper is organized as follows. Section 2 overviews the related work. Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 r</context>
<context position="5717" citStr="Liao and Grishman, 2010" startWordPosition="857" endWordPosition="860">ly, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English trigger identification. In additional, there are only very few of them focusing on Chinese argument extraction and almost all aim to feature engineering and are based on sentence-level information and recast this task as an SRL-styl</context>
<context position="7672" citStr="Liao and Grishman (2010)" startWordPosition="1154" endWordPosition="1157">ism to refine local extraction results for the disease name, location and start/end time. Mann (2007) proposes some constraints on relationship rescoring to impose the discourse consistency on the CEO’s personal information. Chambers and Jurafsky (2008) propose a narrative event chain which are partially ordered sets of event mentions centered around a common protagonist and this chain can represent the relationship among the relevant event mentions in a document. Ji and Grishman (2008) employ a rule-based approach to propagate consistent triggers and arguments across topic-related documents. Liao and Grishman (2010) mainly focus on employing the cross-event consistency information to improve sentence-level trigger extraction and they also propose an inference method to infer the arguments following role consistency in a document. Hong et al. (2011) employ the background information to divide an entity type into more cohesive subtypes to create the bridge between two entities and then infer arguments and their roles using cross-entity inference on the subtypes of entities. Huang and Rillof (2012) propose a sequentially structured sentence classifier which uses lexical associations and discourse relations </context>
</contexts>
<marker>Liao, Grishman, 2010</marker>
<rawString>Shasha Liao and Ralph Grishman. 2010. Using Document Level Cross-Event Inference to Improve Event Extraction. In Proc. ACL 2010, pages 789-797, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Lu</author>
<author>Dan Roth</author>
</authors>
<title>Automatic Event Extraction with Structured Preference Modeling.</title>
<date>2012</date>
<booktitle>In Proc. ACL 2012,</booktitle>
<pages>835--844</pages>
<location>Jeju,</location>
<contexts>
<context position="5504" citStr="Lu and Roth, 2012" startWordPosition="823" endWordPosition="826">art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental results and gives deep analysis. Finally, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English trigger identificat</context>
</contexts>
<marker>Lu, Roth, 2012</marker>
<rawString>Wei Lu and Dan Roth. 2012. Automatic Event Extraction with Structured Preference Modeling. In Proc. ACL 2012, pages 835-844, Jeju, Korea.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gideon Mann</author>
</authors>
<title>Multi-document Relationship Fusion via Constraints on Probabilistic Databases.</title>
<date>2007</date>
<booktitle>In Proc. HLT/NAACL 2007,</booktitle>
<pages>332--229</pages>
<location>Rochester, NY.</location>
<contexts>
<context position="7149" citStr="Mann (2007)" startWordPosition="1082" endWordPosition="1083">e special issues in Chinese argument extraction. Fu et al. (2010) use a feature weighting scheme to re-weight various features for Chinese argument extraction. Li et al. (2012b) introduce more refined features to the system of Chen and Ji (2009b) as their baseline. Specially, several studies have successfully incorporated cross-document or document-level information and argument semantics into event extraction, most of them focused on English. Yangarber et al. (2007) apply a crossdocument inference mechanism to refine local extraction results for the disease name, location and start/end time. Mann (2007) proposes some constraints on relationship rescoring to impose the discourse consistency on the CEO’s personal information. Chambers and Jurafsky (2008) propose a narrative event chain which are partially ordered sets of event mentions centered around a common protagonist and this chain can represent the relationship among the relevant event mentions in a document. Ji and Grishman (2008) employ a rule-based approach to propagate consistent triggers and arguments across topic-related documents. Liao and Grishman (2010) mainly focus on employing the cross-event consistency information to improve</context>
</contexts>
<marker>Mann, 2007</marker>
<rawString>Gideon Mann. 2007. Multi-document Relationship Fusion via Constraints on Probabilistic Databases. In Proc. HLT/NAACL 2007, pages 332-229, Rochester, NY.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Ellen Riloff</author>
</authors>
<title>Effective Information Extraction with Semantic Affinity Patterns and Relevant Regions.</title>
<date>2007</date>
<booktitle>In Proc. EMNLP/CoNLL 2007,</booktitle>
<pages>717--727</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="5335" citStr="Patwardhan and Riloff, 2007" startWordPosition="798" endWordPosition="801">l to unify the semantics of the event and its arguments. The rest of this paper is organized as follows. Section 2 overviews the related work. Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental results and gives deep analysis. Finally, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., </context>
</contexts>
<marker>Patwardhan, Riloff, 2007</marker>
<rawString>Siddharth Patwardhan and Ellen Riloff. 2007. Effective Information Extraction with Semantic Affinity Patterns and Relevant Regions. In Proc. EMNLP/CoNLL 2007, pages 717-727, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Ellen Riloff</author>
</authors>
<title>A Unified Model of Phrasal and Sentential Evidence for Information Extraction.</title>
<date>2009</date>
<booktitle>In Proc. EMNLP 2009,</booktitle>
<pages>151--160</pages>
<contexts>
<context position="5484" citStr="Patwardhan and Riloff, 2009" startWordPosition="819" endWordPosition="822">n 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental results and gives deep analysis. Finally, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English</context>
</contexts>
<marker>Patwardhan, Riloff, 2009</marker>
<rawString>Siddharth Patwardhan and Ellen Riloff. 2009. A Unified Model of Phrasal and Sentential Evidence for Information Extraction. In Proc. EMNLP 2009, pages 151-160, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The Penn Discourse Treebank 2.0. In</title>
<date>2008</date>
<booktitle>Proc. LREC</booktitle>
<pages>2961--2968</pages>
<location>Marrakech, Morocco.</location>
<contexts>
<context position="16935" citStr="Prasad et al., 2008" startWordPosition="2617" endWordPosition="2620">topic is an axis in a discourse, the relations among those relevant event mentions with the different types is the bone to link them into a narration. There are a few studies on using the event relations in NLP (e.g., summarization (Li et al., 2006), learning narrative event chains (Chambers and Jurafsky, 2007)) to ensure its effectiveness. In this paper, we define two types of Sequence relations of relevant event mentions: Cause and Temporal for their high probabilities of sharing arguments. The Cause relation between the event mentions are similar to that in the Penn Discourse TreeBank 2.0 (Prasad et al., 2008). For example, an Attack event often is the cause of an Die or Injure event. Our Temporal relation is limited to those mentions with the same or relevant event types (e.g., Transport and Arrest) for the high probabilities of sharing arguments. Take the following discourse as a sample: D3: 这批战俘离开(E6)阿尔及利亚西部城市廷 杜夫前往(E7)摩洛哥西南部城市阿加迪尔。 (These prisoners left (E6) Tindouf, a western city of Algeria, and went (E7) to Agadir, a southwestern city of Morocco.) - From Xin20001215.2000.0158 In D3, there are two Transport mentions and it is natural to infer 阿 加 迪尔 (Agadir) as the Destination role of E6 and </context>
</contexts>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proc. LREC 2008, pages 2961-2968, Marrakech, Morocco.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bing Qin</author>
<author>Yanyan Zhao</author>
<author>Xiao Ding</author>
<author>Ting Liu</author>
<author>Guofu Zhai</author>
</authors>
<title>Event Type Recognition Based on Trigger Expansion.</title>
<date>2010</date>
<booktitle>Tsinghua Science and Technology,</booktitle>
<volume>15</volume>
<issue>3</issue>
<pages>251--258</pages>
<location>Beijing, China.</location>
<contexts>
<context position="1518" citStr="Qin et al., 2010" startWordPosition="217" endWordPosition="220">n The task of event extraction is to recognize event mentions of a predefined event type and their arguments (participants and attributes). Generally, it can be divided into two subtasks: trigger extraction, which aims to identify trigger/event mentions and determine their event type, and argument extraction, which aims to extract various arguments of a specific event and assign the roles to them. In this paper, we focus on argument extraction in Chinese event extraction. While most of previous studies in Chinese event extraction deal with Chinese trigger extraction (e.g., Chen and Ji, 2009a; Qin et al., 2010; Li et al., 2012a, 2012b), there are only a few on Chinese argument extraction (e.g., Tan et al., 2008; Chen and Ji, 2009b). Following previous studies, we divide argument extraction into two components, argument identification and role determination, where the former recognizes the arguments in a specific event mention and the latter classifies these arguments by roles. With regard to methodology, most of previous studies on argument extraction recast it as a Semantic Role Labeling (SRL) task and focus on intra-sentence information to identify the arguments and their roles. However, argument</context>
<context position="5939" citStr="Qin et al., 2010" startWordPosition="898" endWordPosition="901">Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English trigger identification. In additional, there are only very few of them focusing on Chinese argument extraction and almost all aim to feature engineering and are based on sentence-level information and recast this task as an SRL-style task. Tan et al. (2008) introduce multiple levels of patterns to improve the coverage in Chinese argument classification. Chen and Ji (2009b) apply various kinds of lexical, syntactic and semantic features to address the</context>
</contexts>
<marker>Qin, Zhao, Ding, Liu, Zhai, 2010</marker>
<rawString>Bing Qin, Yanyan Zhao, Xiao Ding, Ting Liu and Guofu Zhai. 2010. Event Type Recognition Based on Trigger Expansion. Tsinghua Science and Technology, 15(3): 251-258, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
</authors>
<title>Automatically Generating Extraction Patterns from Untagged Text.</title>
<date>1996</date>
<booktitle>In Proc. AAAI</booktitle>
<pages>1044--1049</pages>
<location>Portland, OR.</location>
<contexts>
<context position="5281" citStr="Riloff, 1996" startWordPosition="792" endWordPosition="793">into our global argument inference model to unify the semantics of the event and its arguments. The rest of this paper is organized as follows. Section 2 overviews the related work. Section 3 describes a state-of-the-art Chinese argument extraction system as the baseline. Section 4 introduces our global model in inferring those inter-sentence arguments. Section 5 reports experimental results and gives deep analysis. Finally, we conclude our work in Section 6. 2 Related Work Almost all the existing studies on argument extraction concern English. While some apply pattern-based approaches (e.g., Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2</context>
</contexts>
<marker>Riloff, 1996</marker>
<rawString>Ellen Riloff. 1996. Automatically Generating Extraction Patterns from Untagged Text. In Proc. AAAI 1996, pages 1044–1049, Portland, OR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hongye Tan</author>
<author>Tiejun Zhao</author>
<author>Jiaheng Zheng</author>
</authors>
<title>Identification of Chinese Event and Their Argument Roles. In</title>
<date>2008</date>
<booktitle>Proc. 2008 IEEE International Conference on Computer and Information Technology Workshops,</booktitle>
<pages>14--19</pages>
<location>Sydney, Australia.</location>
<contexts>
<context position="1621" citStr="Tan et al., 2008" startWordPosition="236" endWordPosition="239">ments (participants and attributes). Generally, it can be divided into two subtasks: trigger extraction, which aims to identify trigger/event mentions and determine their event type, and argument extraction, which aims to extract various arguments of a specific event and assign the roles to them. In this paper, we focus on argument extraction in Chinese event extraction. While most of previous studies in Chinese event extraction deal with Chinese trigger extraction (e.g., Chen and Ji, 2009a; Qin et al., 2010; Li et al., 2012a, 2012b), there are only a few on Chinese argument extraction (e.g., Tan et al., 2008; Chen and Ji, 2009b). Following previous studies, we divide argument extraction into two components, argument identification and role determination, where the former recognizes the arguments in a specific event mention and the latter classifies these arguments by roles. With regard to methodology, most of previous studies on argument extraction recast it as a Semantic Role Labeling (SRL) task and focus on intra-sentence information to identify the arguments and their roles. However, argument extraction is much different from SRL in the sense that, while the relationship between a predicate an</context>
<context position="5884" citStr="Tan et al., 2008" startWordPosition="886" endWordPosition="889"> Riloff, 1996; Califf and Mooney, 2003; Patwardhan and Riloff, 2007; Chambers and Jurafsky, 2011), the others use machine learning-based approaches (e.g., Grishman et al., 2005; Ahn, 2006; Patwardhan and Riloff, 2009; Lu and Roth, 2012), most of which rely on various kinds of features in the context of a sentence. In comparison, there are only a few studies exploring inter-sentence information or argument semantics (e.g., Liao and Grishman, 2010; Hong et al., 2011; Huang and Riloff, 2011, 2012). Compared with the tremendous work on English event extraction, there are only a few studies (e.g., Tan et al., 2008; Chen and Ji, 2009b; Fu et al., 2010; Qin et al., 2010; Li et al., 2012) on Chinese event extraction with focus on either feature engineering or trigger expansion, under the same framework as English trigger identification. In additional, there are only very few of them focusing on Chinese argument extraction and almost all aim to feature engineering and are based on sentence-level information and recast this task as an SRL-style task. Tan et al. (2008) introduce multiple levels of patterns to improve the coverage in Chinese argument classification. Chen and Ji (2009b) apply various kinds of </context>
</contexts>
<marker>Tan, Zhao, Zheng, 2008</marker>
<rawString>Hongye Tan, Tiejun Zhao, Jiaheng Zheng. 2008. Identification of Chinese Event and Their Argument Roles. In Proc. 2008 IEEE International Conference on Computer and Information Technology Workshops, pages 14-19, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
<author>Yaqin Yang</author>
</authors>
<title>Chinese Sentence Segmentation as Comma ClassiÞcation.</title>
<date>2010</date>
<booktitle>In Proc. ACL 2010,</booktitle>
<pages>631--635</pages>
<location>Uppsala,</location>
<contexts>
<context position="12711" citStr="Xue and Yang (2010)" startWordPosition="1947" endWordPosition="1950">e with the wide spread of ellipsis. Besides, a Chinese sentence does not always end with a full stop. In particular, a comma is used frequently as the stop sign of a sentence in Chinese. We detect sentence boundaries, relying on both full stop and comma signs, since in a Chinese document, comma can be also used to sign the end of a sentence. In particular, we detect sentence boundaries on full stop, exclamatory mark and question mark firstly. Then, we identify the sentence boundaries on comma, using a binary classifier with a set of lexical and constituent-based syntactic features, similar to Xue and Yang (2010). Category Number #Arguments 8032 #Inter-sentence 1673(20.8%) #Intra-sentence 6359(79.2%) Table 1. Statistics: Chinese argument extraction with regard to intra- sentence and inter-sentence arguments. The second issue is that the Chinese word order in a sentence is rather agile for the open 1479 flexible sentence structure. Hence, different word orders can often express the same semantics. For example, a Die event mention “Three person died in this accident.” can be expressed in many different orders in Chinese, such as “在事故中三 人死亡。”, “事故中死亡三人。”, “三人在事故 中死亡。”, etc. In a word, above two issues in</context>
</contexts>
<marker>Xue, Yang, 2010</marker>
<rawString>Nianwen Xue and Yaqin Yang. 2010. Chinese Sentence Segmentation as Comma ClassiÞcation. In Proc. ACL 2010, pages 631-635, Uppsala, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roman Yangarber</author>
<author>Clive Best</author>
<author>Peter von Etter</author>
<author>Flavio Fuart</author>
<author>David Horby</author>
<author>Ralf Steinberger</author>
</authors>
<title>Combining Information about Epidemic Threats from Multiple Sources.</title>
<date>2007</date>
<booktitle>In Proc. RANLP 2007 Workshop on Multi-source, Multilingual Information Extraction and Summarization,</booktitle>
<pages>41--48</pages>
<location>Borovets, Bulgaria.</location>
<marker>Yangarber, Best, von Etter, Fuart, Horby, Steinberger, 2007</marker>
<rawString>Roman Yangarber, Clive Best, Peter von Etter, Flavio Fuart, David Horby and Ralf Steinberger. 2007. Combining Information about Epidemic Threats from Multiple Sources. In Proc. RANLP 2007 Workshop on Multi-source, Multilingual Information Extraction and Summarization, pages 41-48, Borovets, Bulgaria.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>