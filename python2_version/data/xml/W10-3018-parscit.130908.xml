<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000251">
<title confidence="0.992967">
Exploiting CCG Structures with Tree Kernels for Speculation Detection
</title>
<author confidence="0.988907">
Liliana Mamani S´anchez, Baoli Li, Carl Vogel
</author>
<affiliation confidence="0.981198">
Computational Linguistics Group
Trinity College Dublin
</affiliation>
<address confidence="0.837509">
Dublin 2, Ireland
</address>
<email confidence="0.999132">
{mamanisl,baoli.li,vogel}@tcd.ie
</email>
<sectionHeader confidence="0.997384" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999477227272727">
Our CoNLL-2010 speculative sentence
detector disambiguates putative keywords
based on the following considerations: a
speculative keyword may be composed of
one or more word tokens; a speculative
sentence may have one or more specula-
tive keywords; and if a sentence contains
at least one real speculative keyword, it is
deemed speculative. A tree kernel classi-
fier is used to assess whether a potential
speculative keyword conveys speculation.
We exploit information implicit in tree
structures. For prediction efficiency, only
a segment of the whole tree around a spec-
ulation keyword is considered, along with
morphological features inside the segment
and information about the containing doc-
ument. A maximum entropy classifier
is used for sentences not covered by the
tree kernel classifier. Experiments on the
Wikipedia data set show that our system
achieves 0.55 F-measure (in-domain).
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999704894736842">
Speculation and its impact on argumentation has
been studied by linguists and logicians since at
least as far back as Aristotle (trans 1991, 1407a,
1407b), and under the category of linguistic
“hedges” since Lakoff (1973). Practical appli-
cation of this research has emerged due to the
efforts to create a biomedical database of sen-
tences tagged with speculation information: Bio-
Scope (Szarvas et al., 2008) and because of the
association of some kinds of Wikipedia data with
the speculation phenomenon (Ganter and Strube,
2009). It is clear that specific words can be con-
sidered as clues that can qualify a sentence as
speculative. However, the presence of a specu-
lative keyword not always conveys a speculation
assertion which makes the speculation detection a
tough problem. For instance, the sentences below
contain the speculative keyword “may”, but only
the sentence (a) is speculative.
</bodyText>
<listItem confidence="0.5873135">
(a) These effects may be reversible.
(b) Members of an alliance may not attack each other.
</listItem>
<bodyText confidence="0.996720090909091">
The CoNLL-2010 Shared Task (Farkas et al.,
2010), “Learning to detect hedges and their scope
in natural language text” proposed two tasks re-
lated to speculation research. Task 1 aims to detect
sentences containing uncertainty and Task 2 aims
to resolve the intra-sentential scope of hedge cues.
We engaged in the first task in the biomedical and
Wikipedia domains as proposed by the organizers,
but eventually we got to submit only Wikipedia
domain results. However, in this paper we include
results in the biomedical domain as well.
The BioScope corpus is a linguistically hand an-
notated corpus of negation and speculation phe-
nomena for medical free texts, biomedical article
abstracts and full biomedical articles. The afore-
said phenomena have been annotated at sentence
level with keyword tags and linguistic scope tags.
Some previous research on speculation detection
and boundary determination over biomedical data
has been done by Medlock &amp; Briscoe (2007) and
¨Ozg¨ur &amp; Radev (2009) from a computational view
using machine learning methods.
The Wikipedia speculation dataset was gener-
ated by exploiting a weasel word marking. As
weasel words convey vagueness and ambiguity by
providing an unsupported opinion, they are dis-
couraged by Wikipedia editors. Ganter &amp; Strube
(2009) proposed a system to detect hedges based
on frequency measures and shallow information,
achieving a F-score of 0.691.
We formulate the speculation detection prob-
lem as a word disambiguation problem and de-
veloped a system as a pipelined set of natural
</bodyText>
<footnote confidence="0.971982">
1They used different Wikipedia data.
</footnote>
<page confidence="0.946281">
126
</page>
<bodyText confidence="0.931971055555556">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 126–131,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
language processing tools and procedures to pre-
process the datasets. A Combinatory Categorial
Grammar parsing (CCG) (Steedman, 2000) tool
and a Tree Kernel (TK) classifier constitute the
core of the system.
The Section 2 of this paper describes the over-
all architecture of our system. Section 3 depicts
the dataset pre-processing. Section 4 shows how
we built the speculation detection module, outlines
the procedure of examples generation and the use
of the Tree-kernel classifier. Section 5 presents
the experiments and results, we show that sentence
CCG derivation information helps to differentiate
between apparent and real speculative words for
speculation detection. Finally Section 6 gives our
conclusions.
</bodyText>
<sectionHeader confidence="0.932316" genericHeader="method">
2 Speculation detection system
</sectionHeader>
<bodyText confidence="0.999794875">
Our system for speculation detection is a machine
learning (ML) based system (Figure 1). In the pre-
processing module a dataset of speculative/non-
speculative sentences goes through a process of
information extraction of three kinds: specula-
tive word or keyword extraction,2 sentence extrac-
tion and document feature extraction (i.e docu-
ment section). Later the extracted keywords are
used to tag potential speculative sentences in the
training/evaluation datasets and used as features
by the classifiers. The sentences are submitted to
the tokenization and parsing modules in order to
provide a richer set of features necessary for creat-
ing the training/evaluation datasets, including the
document features as well.
In the ML module two types of dataset are built:
one used by a TK classifier and other one by a bag-
of-features based maximum entropy classifier. As
the first one processes only those sentences that
contain speculative words, we use the second clas-
sifier, which is able to process samples of all the
sentences.
The models built by these classifiers are com-
bined in order to provide a better performance and
coverage for the speculation problem in the clas-
sification module which finally outputs sentences
labeled as speculative or non-speculative. Used
tools are the GeniaTagger (Tsuruoka et al., 2005)
for tokenization and lemmatization, and the C&amp;C
Parser (Clark and Curran, 2004). The next sec-
tions explain in detail the main system compo-
nents.
</bodyText>
<footnote confidence="0.558653">
2Extraction of keywords for the training stage.
</footnote>
<sectionHeader confidence="0.9883345" genericHeader="method">
3 Dataset pre-processing for rich feature
extraction
</sectionHeader>
<bodyText confidence="0.9999772">
The pre-processing module extracts keywords,
sentences and document information.
All sentences are processed by the tok-
enizer/lemmatizer and at the same time specific in-
formation about the keywords is extracted.
</bodyText>
<subsectionHeader confidence="0.662227">
Speculative keywords
</subsectionHeader>
<bodyText confidence="0.827918">
Speculative sentences are evidenced by the pres-
ence of speculation keywords. We have the fol-
lowing observations:
</bodyText>
<listItem confidence="0.995756666666667">
• A hedge cue or speculative keyword 3 may be
composed of one or more word tokens.
• In terms of major linguistic categories, the
word tokens are heterogeneous: they may be
verbs, adjectives, nouns, determiners, etc. A
stop-word removing strategy was dismissed,
since no linguistic category can be elimi-
nated.
• A keyword may be covered by another longer
one. For instance, the keyword most can be
seen in keywords like most of all the heroes
or the most common.
</listItem>
<bodyText confidence="0.999940833333333">
Considering these characteristics for each sen-
tence, in the training stage, the keyword extraction
module retrieves the speculative/non-speculative
property of each sentence, the keyword occur-
rences, number of keywords in a sentence, the ini-
tial word token position and the number of word
tokens in the keyword. We build a keyword lex-
icon with all the extracted keywords and their
frequency in the training dataset, this speculative
keyword lexicon is used to tag keyword occur-
rences in non-speculative training sentences and
in all the evaluation dataset sentences.
The overlapping problem when tagging key-
words is solved by maximal matching strategy. It
is curious that speculation phrases come in de-
grees of specificity; the approach adopted here
favors “specific” multi-word phrases over single-
word expressions.
</bodyText>
<subsectionHeader confidence="0.818865">
Sentence processing
</subsectionHeader>
<bodyText confidence="0.999977">
Often, speculation keywords convey certain in-
formation that can not be successfully expressed
by morphology or syntactic relations provided by
phrase structure grammar parsers. On the other
</bodyText>
<footnote confidence="0.832963">
3Or just “keyword” for sake of simplicity.
</footnote>
<page confidence="0.990828">
127
</page>
<figureCaption confidence="0.99971">
Figure 1: Block diagram for the speculation detection system.
</figureCaption>
<bodyText confidence="0.999623066666667">
hand, CCG derivations or dependencies provide
deeper information, in form of predicate-argument
relations. Previous works on semantic role label-
ing (Gildea and Hockenmaier, 2003; Boxwell et
al., 2009) have used features derived from CCG
parsings and obtained better results.
C&amp;C parser provides CCG predicate-argument
dependencies and Briscoe and Carroll (2006) style
grammatical relations. We parsed the tokenized
sentences to obtain CCG derivations which are
binary trees as shown in the Figure 2. The
CCG derivation trees contain function category
and part-of-speech labels; this information is con-
tained in the tree structures to be used in building
a subtree dataset for the TK classifier.
</bodyText>
<sectionHeader confidence="0.961654" genericHeader="method">
4 Speculative sentence classifier
</sectionHeader>
<subsectionHeader confidence="0.995571">
4.1 Tree Kernel classification
</subsectionHeader>
<bodyText confidence="0.9999494375">
The subtree dataset is processed by a Tree Kernel
classifier (Moschitti, 2006) based on Support Vec-
tor Machines. TK uses a kernel function between
two trees, allowing a comparison between their
substructures, which can be subtrees (ST) or sub-
set trees (SST). We chose the comparison between
subset trees since it expands the kernel calculation
to those substructures with constituents that are
not in the leaves. Our intuition is that real specula-
tive sentences have deep semantic structures that
are particularly different from those ones in ap-
parent speculative sentences, and consequently the
comparison between the structures of well identi-
fied and potential speculative sentences may en-
hance the identification of real speculative key-
words.
</bodyText>
<subsectionHeader confidence="0.994961">
4.2 Extracting tree structures
</subsectionHeader>
<bodyText confidence="0.999496517241379">
The depth of a CCG derivation tree is propor-
tional to the number of word tokens in the sen-
tence. Therefore, the processing of a whole deriva-
tion tree by the classifier is highly demanding and
many subtrees are not relevant for the classifica-
tion of speculative/non-speculative sentences, in
particular when the scope of the speculation is a
small proportion of a sentence.
In order to tackle this problem, a fragment of
the CCG derivation tree is extracted. This frag-
ment or subtree spans the keyword together with
neighbors terms in a fixed-size window of n word
tokens, (i.e. n word tokens to the left and n word
tokens to the right of the keyword) and has as root
the lower upper bound node of the first and last
tokens of this span. After applying the subtree ex-
traction, the subtree can contain more word tokens
in addition to those contained in the n-span, which
are replaced by a common symbol.
Potential speculative sentences are turned into
training examples. However, as described in Sec-
tion 3, a speculative sentence can contain one or
more speculative keywords. This can produce an
overlapping between their respective n-spans of
individual keywords during the subtree extraction,
producing subtrees with identical roots for both
keywords. For instance, in the following sen-
tence(c), the spans for the keywords suggests and
thought will overlap if n = 3.
</bodyText>
<construct confidence="0.5019775">
(c) This suggests that diverse agents thought to ac-
tivate NF-kappa B ...
</construct>
<bodyText confidence="0.989855">
The overlapping interacts with the windows size
and potential extraction of dependency relations
</bodyText>
<page confidence="0.982487">
128
</page>
<bodyText confidence="0.613226">
It was reported to have burned for a day
</bodyText>
<figure confidence="0.9535778">
PRP VBD VBN TO VB VBN IN DT NN
NP (S[dcl]\NP)/(S[pss]\NP) (S[pss]\NP)/(S[to]\NP) (S[to]\NP)/(S[b]\NP) (S[b]\NP)/(S[pt]\NP) S[pt]\NP ((S\NP)\(S\NP))/NP NP[nb]/N N
NP[nb]
(S[X]\NP)\(S[X]\NP)
S[pt]\NP
S[b]\NP
S[to]\NP
S[pss]\NP
S[dcl]\NP
S[dcl]
</figure>
<figureCaption confidence="0.999594">
Figure 2: CCG derivations tree for It was reported to have burned for a day.
</figureCaption>
<bodyText confidence="0.99985075">
shared by terms belonging to the two different
spans. We deal with this issue by extracting one
training example if two spans have a common root
and two different examples otherwise.
</bodyText>
<subsectionHeader confidence="0.999005">
4.3 Bag of features model
</subsectionHeader>
<bodyText confidence="0.999452555555556">
By default, our system classifies the sentences not
covered by the TK model using a baseline clas-
sifier that labels a sentence as speculative if this
has at least one keyword. Alternatively, a bag of
features classifier is used to complement the tree
kernel, aimed to provide a more precise method
that might detect even speculative sentences with
new keywords in the evaluation dataset. The set of
features used to build this model includes:
</bodyText>
<listItem confidence="0.99587592">
a) Word unigrams;
b) Lemma unigrams;
c) Word+POS unigrams;
d) Lemma+POS unigrams;
e) Word+Supertag unigrams;
f) Lemma+Supertag unigrams;
g) POS+Supertag unigrams;
h) Lemma bigrams;
i) POS bigrams;
j) Supertag bigrams;
k) Lemma+POS bigrams;
l) Lemma+Supertag bigrams;
m) POS+Supertag bigrams;
n) Lemma trigrams;
o) POS trigrams;
p) Supertag trigrams;
q) Lemma+POS trigrams;
r) Lemma+Supertag trigrams;
s) POS+Supertag trigrams;
t) Number of tokens;
u) Type of section in the document (Title, Text,
Section);
v) Name of section in the document;
w) Position of the sentence in a section starting
from beginning;
</listItem>
<table confidence="0.998467">
Dataset Dev. Train. Eval.
Biomedical 39 14541 5003
Wikipedia 124 11111 9634
</table>
<tableCaption confidence="0.999645">
Table 1: Datasets sizes.
</tableCaption>
<bodyText confidence="0.896501285714286">
x) Position of the sentence in a section starting
from end.
Position of the sentence information, composed by
the last four features, represents the information
about the sentence relative to a whole document.
The bag of features model is generated using a
Maximum Entropy algorithm (Zhang, 2004).
</bodyText>
<sectionHeader confidence="0.995796" genericHeader="evaluation">
5 Experiments and results
</sectionHeader>
<subsectionHeader confidence="0.808457">
5.1 Datasets
</subsectionHeader>
<bodyText confidence="0.999930318181818">
In the CoNLL-2010 Task 1, biomedical and
Wikipedia datasets were provided for develop-
ment, training and evaluation in the BioScope
XML format. Development and training datasets
are tagged with cue labels and a certainty feature.4
The number of sentences for each dataset 5 is de-
tailed in Table 1.
After manual revision of sentences not parsed
by C&amp;C parser, we found that they contain equa-
tions, numbering elements (e.g. (i), (ii).. 1),
2) ), or long n-grams of named-entities, for in-
stance: ...mannose-capped lipoarabinomannan (
ManLAM ) of Mycobacterium tuberculosis ( M.
tuberculosis )... that out of a biomedical domain
appear to be ungrammatical. Similarly, in the
Wikipedia datasets, some sentences have many
named entities. This suggests the need of a spe-
cific pre-processor or a parser for this kind of sen-
tences like a named entity tagger.
In Table 2, we present the number of parsed sen-
tences, processed sentences by the TK model and
examples obtained in the tree structure extraction.
</bodyText>
<footnote confidence="0.922972333333333">
4certainty=“uncertain” and certainty=“certain”.
5The biomedical abstracts and biomedical articles training
datasets are processed as a single dataset.
</footnote>
<page confidence="0.993715">
129
</page>
<table confidence="0.9994756">
Dataset Parsed Process. Samples
Biomedical train. 14442 10852 23511
Biomedical eval. 4903 3395 7826
Wikipedia train. 10972 7793 13461
Wikipedia eval. 9559 4666 8467
</table>
<tableCaption confidence="0.998122">
Table 2: Count of processed sentences.
</tableCaption>
<subsectionHeader confidence="0.998483">
5.2 Experimental results
</subsectionHeader>
<bodyText confidence="0.989018923076923">
The CoNLL-2010 organizers proposed in-domain
and cross-domain evaluations. In cross-domain
experiments, test datasets of one domain can be
used with classifiers trained on the other or on the
union of both domains. We report here our results
for the Wikipedia and biomedical datasets.
So far, we mentioned two settings for our clas-
sifier: a TK classifier complemented by a baseline
classifier (BL) and TK classifier complemented
by a bag of features classifier (TK+BF). Table
3 shows the scores of our submitted system (in-
domain Task 1) on the Wikipedia dataset, whereas
Table 4 gives the scores of the baseline system.
</bodyText>
<table confidence="0.9996865">
TP FP FN Precision Recall F
Our system 1033 480 1201 0.6828 0.4624 0.5514
Max. 1154 448 1080 0.7204 0.5166 0.6017
Min. 147 9 2087 0.9423 0.0658 0.123
</table>
<tableCaption confidence="0.901990666666667">
Table 3: Comparative scores for our system with
CoNLL official maximum and minimum scores in
Task 1, Wikipedia dataset in-domain.
</tableCaption>
<table confidence="0.999848">
TP FP FN Precision Recall F
Biomedical 786 2690 4 0.2261 0.9949 0.3685
Wikipedia 1980 2747 254 0.4189 0.8863 0.5689
</table>
<tableCaption confidence="0.99945">
Table 4: Baseline results.
</tableCaption>
<bodyText confidence="0.999979875">
Additionally, we consider a bag of features clas-
sifier (BF) and a classifier that combines the base-
line applied to the sentences that have at least one
keyword plus the BF classifier for the remaining
sentences (BL+BF). In Tables 5 to 10, results for
the four classifiers (TK, TK+BF, BF, BL+BF) with
evaluations in-domain and cross-domain are pre-
sented6.
The baseline scores confirm that relying on just
the keywords is not enough to identify speculative
sentences. In the biomedical domain, the classi-
fiers give high recall but too low precision result-
ing in low F-scores. Still, the TK, TK+BF and BF
(in-domain configurations) gives much better re-
sults than BL and BL+BF which indicates that the
information from CCG improves the performance
</bodyText>
<footnote confidence="0.994176666666667">
6It is worth to note that the keyword lexicons have been
not used in cross-domain way, so the TK and TK+BF models
have not been tested in regards to keywords.
</footnote>
<table confidence="0.999474666666667">
TP FP FN Precision Recall F
BL 1980 2747 254 0.4189 0.8863 0.5689
TK 1033 480 1201 0.6828 0.4624 0.5514
TK+BF 1059 516 1175 0.6729 0.4740 0.5560
BF 772 264 1462 0.7452 0.3456 0.4722
BL+BF 2028 2810 206 0.4192 0.9078 0.5735
</table>
<tableCaption confidence="0.829264">
Table 5: Results for Wikipedia dataset in-domain.
</tableCaption>
<table confidence="0.999962666666667">
TP FP FN Precision Recall F
BL 1980 2747 254 0.4189 0.8863 0.5689
TK 1776 2192 458 0.4476 0.7950 0.5727
TK+BF 1763 2194 471 0.4455 0.7892 0.5695
BF 403 323 1831 0.5551 0.1804 0.2723
BL+BF 1988 2772 246 0.4176 0.8899 0.5685
</table>
<tableCaption confidence="0.9851955">
Table 6: Wikipedia data classified with biomedical
model scores (cross-domain).
</tableCaption>
<table confidence="0.999952333333333">
TP FP FN Precision Recall F
BL 1980 2747 254 0.4189 0.8863 0.5689
TK 1081 624 1153 0.6340 0.4839 0.5489
TK+BF 1099 636 1135 0.6334 0.4919 0.5538
BF 770 271 1464 0.7397 0.3447 0.4702
BL+BF 2017 2786 217 0.4199 0.9029 0.5733
</table>
<tableCaption confidence="0.847994">
Table 7: Wikipedia data classified with biomedical
</tableCaption>
<table confidence="0.969954285714286">
+ Wikipedia model scores (cross-domain).
TP FP FN Precision Recall F
BL 786 2690 4 0.2261 0.9949 0.3685
TK 759 777 31 0.4941 0.9606 0.6526
TK+BF 751 724 39 0.5092 0.9506 0.6631
BF 542 101 248 0.8429 0.6861 0.7565
BL+BF 786 2695 4 0.2258 0.9949 0.3681
</table>
<tableCaption confidence="0.835044">
Table 8: Biomedical data scores (in-domain).
</tableCaption>
<table confidence="0.999957833333333">
TP FP FN Precision Recall F
BL 786 2690 4 0.2261 0.9949 0.3685
TK 786 2690 4 0.2261 0.9949 0.3685
TK+BF 771 2667 19 0.2243 0.9759 0.3647
BF 174 199 616 0.4665 0.2206 0.2992
BL+BF 787 2723 3 0.2242 0.9962 0.3660
</table>
<tableCaption confidence="0.940812">
Table 9: Biomedical data classified with
Wikipedia model scores (cross-domain).
</tableCaption>
<table confidence="0.999857833333333">
TP FP FN Precision Recall F
BL 786 2690 4 0.2261 0.9949 0.3685
TK 697 357 93 0.6613 0.8823 0.7560
TK+BF 685 305 105 0.6919 0.8671 0.7697
BF 494 136 296 0.7841 0.6253 0.6958
BL+BF 786 2696 4 0.2257 0.9949 0.3679
</table>
<tableCaption confidence="0.697278">
Table 10: Biomedical data classified with biomed-
ical + Wikipedia model scores (cross-domain).
</tableCaption>
<bodyText confidence="0.999435538461539">
of the classifiers when compared to the baseline
classifier.
Even though in the Wikipedia domain the
TK+BF score is less than the baseline score, still
the performance of the classifiers do not fall much
in any of the in-domain and cross-domain exper-
iments. On the other hand, BF does not have a
good performance in 5 of 6 the experiments. To
make a more precise comparison between TK and
BF, the TK and BL+BF scores show that BL+BF
performs better than TK in only 2 of the 6 ex-
periments but the better performances achieved
by BL+BF are very small. This suggests that
</bodyText>
<page confidence="0.989491">
130
</page>
<bodyText confidence="0.9999596">
the complex processing made by tree kernels is
more useful when disambiguating speculative key-
words than BF. Nonetheless, the bag-of-features
approach is also of importance for the task at hand
when combined with TK. We observe that the TK
classifer and BF classifier perform well making us
believe that the CCG derivations provide relevant
information for speculation detection. The use of
tree kernels needs further investigations in order to
evaluate the suitability of this approach.
</bodyText>
<sectionHeader confidence="0.983653" genericHeader="conclusions">
6 Concluding remarks
</sectionHeader>
<bodyText confidence="0.999966066666667">
Speculation detection is found to be a tough task
given the high ambiguity of speculative keywords.
We think these results can be improved by study-
ing the influences of context on speculation asser-
tions.
This paper presents a new approach for disam-
biguating apparent speculative keywords by us-
ing CCG information in the form of supertags and
CCG derivations. We introduce the use of the tree
kernel approach for CCG derivations trees. The
inclusion of other features like grammatical rela-
tions provided by the parser needs to be studied
before incorporating this information into the cur-
rent classifier and possibly to resolve the boundary
speculation detection problem.
</bodyText>
<sectionHeader confidence="0.998738" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.904944">
This research is supported by the Trinity College
Research Scholarship Program and the Science
Foundation Ireland (Grant 07/CE/I1142) as part
of the Centre for Next Generation Localisation
(www.cngl.ie) at Trinity College of Dublin.
</bodyText>
<sectionHeader confidence="0.998093" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998087915492958">
Aristotle. trans. 1991. The Art of Rhetoric. Penguin
Classics, London. Translated with an Introduction
and Notes by H.C. Lawson-Tancred.
Stephen Boxwell, Dennis Mehay, and Chris Brew.
2009. Brutus: A semantic role labeling system in-
corporating CCG, CFG, and dependency features.
In Proceedings of the Joint Conference of the 47th
Annual Meeting of the ACL and the 4th International
Joint Conference on Natural Language Processing
of the AFNLP, pages 37–45, Suntec, Singapore.
Ted Briscoe and John Carroll. 2006. Evaluating the
accuracy of an unlexicalized statistical parser on
the PARC DepBank. In Proceedings of the COL-
ING/ACL on Main conference poster sessions, pages
41–48, Morristown, NJ, USA.
Stephen Clark and James R. Curran. 2004. Parsing
the WSJ using CCG and log-linear models. In ACL
’04: Proceedings of the 42nd Annual Meeting on As-
sociation for Computational Linguistics, page 103,
Morristown, NJ, USA.
Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos
Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL-
2010 Shared Task: Learning to Detect Hedges and
their Scope in Natural Language Text. In Proceed-
ings of the Fourteenth Conference on Computational
Natural Language Learning (CoNLL-2010): Shared
Task, pages 1–12, Uppsala, Sweden, July. Associa-
tion for Computational Linguistics.
Viola Ganter and Michael Strube. 2009. Finding
hedges by chasing weasels: Hedge detection using
Wikipedia tags and shallow linguistic features. In
Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, pages 173–176, Suntec, Singapore.
Daniel Gildea and Julia Hockenmaier. 2003. Identi-
fying semantic roles using combinatory categorial
grammar. In Proceedings of 2003 Conference on
Empirical Methods in Natural Language Processing
(EMNLP), Sapporo, Japan.
George Lakoff. 1973. Hedges: A study in meaning
criteria and the logic of fuzzy concepts. Journal of
Philosophical Logic, 2(4):458–508.
Ben Medlock and Ted Briscoe. 2007. Weakly super-
vised learning for hedge classification in scientific
literature. In Proceedings of the 45th Annual Meet-
ing of the Association of Computational Linguistics,
pages 992–999, Prague, Czech Republic.
Alessandro Moschitti. 2006. Making tree kernels prac-
tical for natural language learning. In Proceedings
of the 11th Conference of the European Chapter of
the Association for Computational Linguistics.
Arzucan ¨Ozg¨ur and Dragomir R. Radev. 2009. Detect-
ing speculations and their scopes in scientific text.
In Proceedings of the 2009 Conference on Empiri-
cal Methods in Natural Language Processing, pages
1398–1407, Singapore.
Mark Steedman. 2000. The syntactic process. MIT
Press, Cambridge, MA, USA.
Gy¨orgy Szarvas, Veronika Vincze, Rich´ard Farkas, and
J´anos Csirik. 2008. The BioScope corpus: anno-
tation for negation, uncertainty and their scope in
biomedical texts. In Proceedings of the Workshop
on Current Trends in Biomedical Natural Language
Processing, pages 38–45, Columbus, Ohio.
Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim,
Tomoko Ohta, John McNaught, Sophia Ananiadou,
and Jun’ichi Tsujii. 2005. Developing a robust part-
of-speech tagger for biomedical text. In Advances in
Informatics, pages 382–392.
Le Zhang. 2004. Maximum entropy modeling toolkit
for Python and C++ (version 20041229). In Natural
Language Processing Lab, Northeastern.
</reference>
<page confidence="0.998296">
131
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.356637">
<title confidence="0.999963">Exploiting CCG Structures with Tree Kernels for Speculation Detection</title>
<author confidence="0.997025">Liliana Mamani S´anchez</author>
<author confidence="0.997025">Baoli Li</author>
<author confidence="0.997025">Carl</author>
<affiliation confidence="0.9936535">Computational Linguistics Trinity College</affiliation>
<address confidence="0.396708">Dublin 2,</address>
<abstract confidence="0.995976173913043">Our CoNLL-2010 speculative sentence detector disambiguates putative keywords based on the following considerations: a speculative keyword may be composed of one or more word tokens; a speculative sentence may have one or more speculative keywords; and if a sentence contains at least one real speculative keyword, it is deemed speculative. A tree kernel classifier is used to assess whether a potential speculative keyword conveys speculation. We exploit information implicit in tree structures. For prediction efficiency, only a segment of the whole tree around a speculation keyword is considered, along with morphological features inside the segment and information about the containing document. A maximum entropy classifier is used for sentences not covered by the tree kernel classifier. Experiments on the Wikipedia data set show that our system achieves 0.55 F-measure (in-domain).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>trans</author>
</authors>
<title>The Art of Rhetoric. Penguin Classics, London. Translated with an Introduction and Notes by H.C.</title>
<date>1991</date>
<publisher>Lawson-Tancred.</publisher>
<contexts>
<context position="1275" citStr="trans 1991" startWordPosition="184" endWordPosition="185">culation. We exploit information implicit in tree structures. For prediction efficiency, only a segment of the whole tree around a speculation keyword is considered, along with morphological features inside the segment and information about the containing document. A maximum entropy classifier is used for sentences not covered by the tree kernel classifier. Experiments on the Wikipedia data set show that our system achieves 0.55 F-measure (in-domain). 1 Introduction Speculation and its impact on argumentation has been studied by linguists and logicians since at least as far back as Aristotle (trans 1991, 1407a, 1407b), and under the category of linguistic “hedges” since Lakoff (1973). Practical application of this research has emerged due to the efforts to create a biomedical database of sentences tagged with speculation information: BioScope (Szarvas et al., 2008) and because of the association of some kinds of Wikipedia data with the speculation phenomenon (Ganter and Strube, 2009). It is clear that specific words can be considered as clues that can qualify a sentence as speculative. However, the presence of a speculative keyword not always conveys a speculation assertion which makes the s</context>
</contexts>
<marker>trans, 1991</marker>
<rawString>Aristotle. trans. 1991. The Art of Rhetoric. Penguin Classics, London. Translated with an Introduction and Notes by H.C. Lawson-Tancred.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Boxwell</author>
<author>Dennis Mehay</author>
<author>Chris Brew</author>
</authors>
<title>Brutus: A semantic role labeling system incorporating CCG, CFG, and dependency features.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>37--45</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="8341" citStr="Boxwell et al., 2009" startWordPosition="1270" endWordPosition="1273">cificity; the approach adopted here favors “specific” multi-word phrases over singleword expressions. Sentence processing Often, speculation keywords convey certain information that can not be successfully expressed by morphology or syntactic relations provided by phrase structure grammar parsers. On the other 3Or just “keyword” for sake of simplicity. 127 Figure 1: Block diagram for the speculation detection system. hand, CCG derivations or dependencies provide deeper information, in form of predicate-argument relations. Previous works on semantic role labeling (Gildea and Hockenmaier, 2003; Boxwell et al., 2009) have used features derived from CCG parsings and obtained better results. C&amp;C parser provides CCG predicate-argument dependencies and Briscoe and Carroll (2006) style grammatical relations. We parsed the tokenized sentences to obtain CCG derivations which are binary trees as shown in the Figure 2. The CCG derivation trees contain function category and part-of-speech labels; this information is contained in the tree structures to be used in building a subtree dataset for the TK classifier. 4 Speculative sentence classifier 4.1 Tree Kernel classification The subtree dataset is processed by a Tr</context>
</contexts>
<marker>Boxwell, Mehay, Brew, 2009</marker>
<rawString>Stephen Boxwell, Dennis Mehay, and Chris Brew. 2009. Brutus: A semantic role labeling system incorporating CCG, CFG, and dependency features. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 37–45, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Briscoe</author>
<author>John Carroll</author>
</authors>
<title>Evaluating the accuracy of an unlexicalized statistical parser on the PARC DepBank.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>41--48</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="8502" citStr="Briscoe and Carroll (2006)" startWordPosition="1292" endWordPosition="1295"> certain information that can not be successfully expressed by morphology or syntactic relations provided by phrase structure grammar parsers. On the other 3Or just “keyword” for sake of simplicity. 127 Figure 1: Block diagram for the speculation detection system. hand, CCG derivations or dependencies provide deeper information, in form of predicate-argument relations. Previous works on semantic role labeling (Gildea and Hockenmaier, 2003; Boxwell et al., 2009) have used features derived from CCG parsings and obtained better results. C&amp;C parser provides CCG predicate-argument dependencies and Briscoe and Carroll (2006) style grammatical relations. We parsed the tokenized sentences to obtain CCG derivations which are binary trees as shown in the Figure 2. The CCG derivation trees contain function category and part-of-speech labels; this information is contained in the tree structures to be used in building a subtree dataset for the TK classifier. 4 Speculative sentence classifier 4.1 Tree Kernel classification The subtree dataset is processed by a Tree Kernel classifier (Moschitti, 2006) based on Support Vector Machines. TK uses a kernel function between two trees, allowing a comparison between their substru</context>
</contexts>
<marker>Briscoe, Carroll, 2006</marker>
<rawString>Ted Briscoe and John Carroll. 2006. Evaluating the accuracy of an unlexicalized statistical parser on the PARC DepBank. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 41–48, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephen Clark</author>
<author>James R Curran</author>
</authors>
<title>Parsing the WSJ using CCG and log-linear models.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>103</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6030" citStr="Clark and Curran, 2004" startWordPosition="916" endWordPosition="919">by a TK classifier and other one by a bagof-features based maximum entropy classifier. As the first one processes only those sentences that contain speculative words, we use the second classifier, which is able to process samples of all the sentences. The models built by these classifiers are combined in order to provide a better performance and coverage for the speculation problem in the classification module which finally outputs sentences labeled as speculative or non-speculative. Used tools are the GeniaTagger (Tsuruoka et al., 2005) for tokenization and lemmatization, and the C&amp;C Parser (Clark and Curran, 2004). The next sections explain in detail the main system components. 2Extraction of keywords for the training stage. 3 Dataset pre-processing for rich feature extraction The pre-processing module extracts keywords, sentences and document information. All sentences are processed by the tokenizer/lemmatizer and at the same time specific information about the keywords is extracted. Speculative keywords Speculative sentences are evidenced by the presence of speculation keywords. We have the following observations: • A hedge cue or speculative keyword 3 may be composed of one or more word tokens. • In</context>
</contexts>
<marker>Clark, Curran, 2004</marker>
<rawString>Stephen Clark and James R. Curran. 2004. Parsing the WSJ using CCG and log-linear models. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 103, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rich´ard Farkas</author>
<author>Veronika Vincze</author>
<author>Gy¨orgy M´ora</author>
<author>J´anos Csirik</author>
<author>Gy¨orgy Szarvas</author>
</authors>
<title>The CoNLL2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text.</title>
<date>2010</date>
<booktitle>In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task,</booktitle>
<pages>1--12</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<marker>Farkas, Vincze, M´ora, Csirik, Szarvas, 2010</marker>
<rawString>Rich´ard Farkas, Veronika Vincze, Gy¨orgy M´ora, J´anos Csirik, and Gy¨orgy Szarvas. 2010. The CoNLL2010 Shared Task: Learning to Detect Hedges and their Scope in Natural Language Text. In Proceedings of the Fourteenth Conference on Computational Natural Language Learning (CoNLL-2010): Shared Task, pages 1–12, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viola Ganter</author>
<author>Michael Strube</author>
</authors>
<title>Finding hedges by chasing weasels: Hedge detection using Wikipedia tags and shallow linguistic features.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers,</booktitle>
<pages>173--176</pages>
<location>Suntec, Singapore.</location>
<contexts>
<context position="1663" citStr="Ganter and Strube, 2009" startWordPosition="243" endWordPosition="246"> the Wikipedia data set show that our system achieves 0.55 F-measure (in-domain). 1 Introduction Speculation and its impact on argumentation has been studied by linguists and logicians since at least as far back as Aristotle (trans 1991, 1407a, 1407b), and under the category of linguistic “hedges” since Lakoff (1973). Practical application of this research has emerged due to the efforts to create a biomedical database of sentences tagged with speculation information: BioScope (Szarvas et al., 2008) and because of the association of some kinds of Wikipedia data with the speculation phenomenon (Ganter and Strube, 2009). It is clear that specific words can be considered as clues that can qualify a sentence as speculative. However, the presence of a speculative keyword not always conveys a speculation assertion which makes the speculation detection a tough problem. For instance, the sentences below contain the speculative keyword “may”, but only the sentence (a) is speculative. (a) These effects may be reversible. (b) Members of an alliance may not attack each other. The CoNLL-2010 Shared Task (Farkas et al., 2010), “Learning to detect hedges and their scope in natural language text” proposed two tasks relate</context>
<context position="3400" citStr="Ganter &amp; Strube (2009)" startWordPosition="517" endWordPosition="520">iomedical article abstracts and full biomedical articles. The aforesaid phenomena have been annotated at sentence level with keyword tags and linguistic scope tags. Some previous research on speculation detection and boundary determination over biomedical data has been done by Medlock &amp; Briscoe (2007) and ¨Ozg¨ur &amp; Radev (2009) from a computational view using machine learning methods. The Wikipedia speculation dataset was generated by exploiting a weasel word marking. As weasel words convey vagueness and ambiguity by providing an unsupported opinion, they are discouraged by Wikipedia editors. Ganter &amp; Strube (2009) proposed a system to detect hedges based on frequency measures and shallow information, achieving a F-score of 0.691. We formulate the speculation detection problem as a word disambiguation problem and developed a system as a pipelined set of natural 1They used different Wikipedia data. 126 Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 126–131, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics language processing tools and procedures to preprocess the datasets. A Combinatory Categorial Grammar parsing (</context>
</contexts>
<marker>Ganter, Strube, 2009</marker>
<rawString>Viola Ganter and Michael Strube. 2009. Finding hedges by chasing weasels: Hedge detection using Wikipedia tags and shallow linguistic features. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, pages 173–176, Suntec, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Julia Hockenmaier</author>
</authors>
<title>Identifying semantic roles using combinatory categorial grammar.</title>
<date>2003</date>
<booktitle>In Proceedings of 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP),</booktitle>
<location>Sapporo, Japan.</location>
<contexts>
<context position="8318" citStr="Gildea and Hockenmaier, 2003" startWordPosition="1266" endWordPosition="1269">phrases come in degrees of specificity; the approach adopted here favors “specific” multi-word phrases over singleword expressions. Sentence processing Often, speculation keywords convey certain information that can not be successfully expressed by morphology or syntactic relations provided by phrase structure grammar parsers. On the other 3Or just “keyword” for sake of simplicity. 127 Figure 1: Block diagram for the speculation detection system. hand, CCG derivations or dependencies provide deeper information, in form of predicate-argument relations. Previous works on semantic role labeling (Gildea and Hockenmaier, 2003; Boxwell et al., 2009) have used features derived from CCG parsings and obtained better results. C&amp;C parser provides CCG predicate-argument dependencies and Briscoe and Carroll (2006) style grammatical relations. We parsed the tokenized sentences to obtain CCG derivations which are binary trees as shown in the Figure 2. The CCG derivation trees contain function category and part-of-speech labels; this information is contained in the tree structures to be used in building a subtree dataset for the TK classifier. 4 Speculative sentence classifier 4.1 Tree Kernel classification The subtree datas</context>
</contexts>
<marker>Gildea, Hockenmaier, 2003</marker>
<rawString>Daniel Gildea and Julia Hockenmaier. 2003. Identifying semantic roles using combinatory categorial grammar. In Proceedings of 2003 Conference on Empirical Methods in Natural Language Processing (EMNLP), Sapporo, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<title>Hedges: A study in meaning criteria and the logic of fuzzy concepts.</title>
<date>1973</date>
<journal>Journal of Philosophical Logic,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="1357" citStr="Lakoff (1973)" startWordPosition="196" endWordPosition="197">ficiency, only a segment of the whole tree around a speculation keyword is considered, along with morphological features inside the segment and information about the containing document. A maximum entropy classifier is used for sentences not covered by the tree kernel classifier. Experiments on the Wikipedia data set show that our system achieves 0.55 F-measure (in-domain). 1 Introduction Speculation and its impact on argumentation has been studied by linguists and logicians since at least as far back as Aristotle (trans 1991, 1407a, 1407b), and under the category of linguistic “hedges” since Lakoff (1973). Practical application of this research has emerged due to the efforts to create a biomedical database of sentences tagged with speculation information: BioScope (Szarvas et al., 2008) and because of the association of some kinds of Wikipedia data with the speculation phenomenon (Ganter and Strube, 2009). It is clear that specific words can be considered as clues that can qualify a sentence as speculative. However, the presence of a speculative keyword not always conveys a speculation assertion which makes the speculation detection a tough problem. For instance, the sentences below contain th</context>
</contexts>
<marker>Lakoff, 1973</marker>
<rawString>George Lakoff. 1973. Hedges: A study in meaning criteria and the logic of fuzzy concepts. Journal of Philosophical Logic, 2(4):458–508.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ben Medlock</author>
<author>Ted Briscoe</author>
</authors>
<title>Weakly supervised learning for hedge classification in scientific literature.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>992--999</pages>
<location>Prague, Czech Republic.</location>
<contexts>
<context position="3080" citStr="Medlock &amp; Briscoe (2007)" startWordPosition="468" endWordPosition="471">ical and Wikipedia domains as proposed by the organizers, but eventually we got to submit only Wikipedia domain results. However, in this paper we include results in the biomedical domain as well. The BioScope corpus is a linguistically hand annotated corpus of negation and speculation phenomena for medical free texts, biomedical article abstracts and full biomedical articles. The aforesaid phenomena have been annotated at sentence level with keyword tags and linguistic scope tags. Some previous research on speculation detection and boundary determination over biomedical data has been done by Medlock &amp; Briscoe (2007) and ¨Ozg¨ur &amp; Radev (2009) from a computational view using machine learning methods. The Wikipedia speculation dataset was generated by exploiting a weasel word marking. As weasel words convey vagueness and ambiguity by providing an unsupported opinion, they are discouraged by Wikipedia editors. Ganter &amp; Strube (2009) proposed a system to detect hedges based on frequency measures and shallow information, achieving a F-score of 0.691. We formulate the speculation detection problem as a word disambiguation problem and developed a system as a pipelined set of natural 1They used different Wikiped</context>
</contexts>
<marker>Medlock, Briscoe, 2007</marker>
<rawString>Ben Medlock and Ted Briscoe. 2007. Weakly supervised learning for hedge classification in scientific literature. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 992–999, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alessandro Moschitti</author>
</authors>
<title>Making tree kernels practical for natural language learning.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="8979" citStr="Moschitti, 2006" startWordPosition="1367" endWordPosition="1368">rived from CCG parsings and obtained better results. C&amp;C parser provides CCG predicate-argument dependencies and Briscoe and Carroll (2006) style grammatical relations. We parsed the tokenized sentences to obtain CCG derivations which are binary trees as shown in the Figure 2. The CCG derivation trees contain function category and part-of-speech labels; this information is contained in the tree structures to be used in building a subtree dataset for the TK classifier. 4 Speculative sentence classifier 4.1 Tree Kernel classification The subtree dataset is processed by a Tree Kernel classifier (Moschitti, 2006) based on Support Vector Machines. TK uses a kernel function between two trees, allowing a comparison between their substructures, which can be subtrees (ST) or subset trees (SST). We chose the comparison between subset trees since it expands the kernel calculation to those substructures with constituents that are not in the leaves. Our intuition is that real speculative sentences have deep semantic structures that are particularly different from those ones in apparent speculative sentences, and consequently the comparison between the structures of well identified and potential speculative sen</context>
</contexts>
<marker>Moschitti, 2006</marker>
<rawString>Alessandro Moschitti. 2006. Making tree kernels practical for natural language learning. In Proceedings of the 11th Conference of the European Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arzucan ¨Ozg¨ur</author>
<author>Dragomir R Radev</author>
</authors>
<title>Detecting speculations and their scopes in scientific text.</title>
<date>2009</date>
<booktitle>In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1398--1407</pages>
<marker>¨Ozg¨ur, Radev, 2009</marker>
<rawString>Arzucan ¨Ozg¨ur and Dragomir R. Radev. 2009. Detecting speculations and their scopes in scientific text. In Proceedings of the 2009 Conference on Empirical Methods in Natural Language Processing, pages 1398–1407, Singapore.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Steedman</author>
</authors>
<title>The syntactic process.</title>
<date>2000</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="4021" citStr="Steedman, 2000" startWordPosition="608" endWordPosition="609">sed a system to detect hedges based on frequency measures and shallow information, achieving a F-score of 0.691. We formulate the speculation detection problem as a word disambiguation problem and developed a system as a pipelined set of natural 1They used different Wikipedia data. 126 Proceedings of the Fourteenth Conference on Computational Natural Language Learning: Shared Task, pages 126–131, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics language processing tools and procedures to preprocess the datasets. A Combinatory Categorial Grammar parsing (CCG) (Steedman, 2000) tool and a Tree Kernel (TK) classifier constitute the core of the system. The Section 2 of this paper describes the overall architecture of our system. Section 3 depicts the dataset pre-processing. Section 4 shows how we built the speculation detection module, outlines the procedure of examples generation and the use of the Tree-kernel classifier. Section 5 presents the experiments and results, we show that sentence CCG derivation information helps to differentiate between apparent and real speculative words for speculation detection. Finally Section 6 gives our conclusions. 2 Speculation det</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>Mark Steedman. 2000. The syntactic process. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gy¨orgy Szarvas</author>
<author>Veronika Vincze</author>
<author>Rich´ard Farkas</author>
<author>J´anos Csirik</author>
</authors>
<title>The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing,</booktitle>
<pages>38--45</pages>
<location>Columbus, Ohio.</location>
<contexts>
<context position="1542" citStr="Szarvas et al., 2008" startWordPosition="224" endWordPosition="227">document. A maximum entropy classifier is used for sentences not covered by the tree kernel classifier. Experiments on the Wikipedia data set show that our system achieves 0.55 F-measure (in-domain). 1 Introduction Speculation and its impact on argumentation has been studied by linguists and logicians since at least as far back as Aristotle (trans 1991, 1407a, 1407b), and under the category of linguistic “hedges” since Lakoff (1973). Practical application of this research has emerged due to the efforts to create a biomedical database of sentences tagged with speculation information: BioScope (Szarvas et al., 2008) and because of the association of some kinds of Wikipedia data with the speculation phenomenon (Ganter and Strube, 2009). It is clear that specific words can be considered as clues that can qualify a sentence as speculative. However, the presence of a speculative keyword not always conveys a speculation assertion which makes the speculation detection a tough problem. For instance, the sentences below contain the speculative keyword “may”, but only the sentence (a) is speculative. (a) These effects may be reversible. (b) Members of an alliance may not attack each other. The CoNLL-2010 Shared T</context>
</contexts>
<marker>Szarvas, Vincze, Farkas, Csirik, 2008</marker>
<rawString>Gy¨orgy Szarvas, Veronika Vincze, Rich´ard Farkas, and J´anos Csirik. 2008. The BioScope corpus: annotation for negation, uncertainty and their scope in biomedical texts. In Proceedings of the Workshop on Current Trends in Biomedical Natural Language Processing, pages 38–45, Columbus, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoshimasa Tsuruoka</author>
<author>Yuka Tateishi</author>
<author>Jin-Dong Kim</author>
<author>Tomoko Ohta</author>
<author>John McNaught</author>
<author>Sophia Ananiadou</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Developing a robust partof-speech tagger for biomedical text.</title>
<date>2005</date>
<booktitle>In Advances in Informatics,</booktitle>
<pages>382--392</pages>
<contexts>
<context position="5950" citStr="Tsuruoka et al., 2005" startWordPosition="904" endWordPosition="907">nt features as well. In the ML module two types of dataset are built: one used by a TK classifier and other one by a bagof-features based maximum entropy classifier. As the first one processes only those sentences that contain speculative words, we use the second classifier, which is able to process samples of all the sentences. The models built by these classifiers are combined in order to provide a better performance and coverage for the speculation problem in the classification module which finally outputs sentences labeled as speculative or non-speculative. Used tools are the GeniaTagger (Tsuruoka et al., 2005) for tokenization and lemmatization, and the C&amp;C Parser (Clark and Curran, 2004). The next sections explain in detail the main system components. 2Extraction of keywords for the training stage. 3 Dataset pre-processing for rich feature extraction The pre-processing module extracts keywords, sentences and document information. All sentences are processed by the tokenizer/lemmatizer and at the same time specific information about the keywords is extracted. Speculative keywords Speculative sentences are evidenced by the presence of speculation keywords. We have the following observations: • A hed</context>
</contexts>
<marker>Tsuruoka, Tateishi, Kim, Ohta, McNaught, Ananiadou, Tsujii, 2005</marker>
<rawString>Yoshimasa Tsuruoka, Yuka Tateishi, Jin-Dong Kim, Tomoko Ohta, John McNaught, Sophia Ananiadou, and Jun’ichi Tsujii. 2005. Developing a robust partof-speech tagger for biomedical text. In Advances in Informatics, pages 382–392.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Le Zhang</author>
</authors>
<title>Maximum entropy modeling toolkit for Python and C++ (version 20041229).</title>
<date>2004</date>
<booktitle>In Natural Language Processing Lab, Northeastern.</booktitle>
<marker>Le Zhang, 2004</marker>
<rawString>Le Zhang. 2004. Maximum entropy modeling toolkit for Python and C++ (version 20041229). In Natural Language Processing Lab, Northeastern.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>