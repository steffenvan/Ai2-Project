<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000006">
<title confidence="0.998494">
A Method for Word Sense Disambiguation of Unrestricted Text
</title>
<author confidence="0.998301">
Rada Mihalcea and Dan I. Moldovan
</author>
<affiliation confidence="0.8788265">
Department of Computer Science and Engineering
Southern Methodist University
</affiliation>
<address confidence="0.637609">
Dallas, Texas, 75275-0122
</address>
<email confidence="0.714037">
{ rada,moldovan}Oseas.smu.edu
</email>
<sectionHeader confidence="0.990753" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982733333333">
Selecting the most appropriate sense for an am-
biguous word in a sentence is a central prob-
lem in Natural Language Processing. In this
paper, we present a method that attempts
to disambiguate all the nouns, verbs, adverbs
and adjectives in a text, using the senses pro-
vided in WordNet. The senses are ranked us-
ing two sources of information: (1) the Inter-
net for gathering statistics for word-word co-
occurrences and (2) WordNet for measuring the
semantic density for a pair of words. We report
an average accuracy of 80% for the first ranked
sense, and 91% for the first two ranked senses.
Extensions of this method for larger windows of
more than two words are considered.
</bodyText>
<sectionHeader confidence="0.999433" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.978283833333333">
Word Sense Disambiguation (WSD) is an open
problem in Natural Language Processing. Its
solution impacts other tasks such as discourse,
reference resolution, coherence, inference and
others. WSD methods can be broadly classified
into three types:
</bodyText>
<listItem confidence="0.985288230769231">
1. WSD that make use of the information
provided by machine readable dictionaries
(Cowie et al., 1992), (Miller et al., 1994),
(Agirre and Rigau, 1995), (Li et al., 1995),
(McRoy, 1992);
2. WSD that use information gathered from
training on a corpus that has already
been semantically disambiguated (super-
vised training methods) (Gale et al., 1992),
(Ng and Lee, 1996);
3. WSD that use information gathered from
raw corpora (unsupervised training meth-
ods) (Yarowsky, 1995) (Resnik, 1997).
</listItem>
<bodyText confidence="0.999916692307692">
There are also hybrid methods that combine
several sources of knowledge such as lexicon in-
formation, heuristics, collocations and others
(McRoy, 1992) (Bruce and Wiebe, 1994) (Ng
and Lee, 1996) (Rigau et al., 1997).
Statistical methods produce high accuracy re-
sults for small number of preselected words. A
lack of widely available semantically tagged cor-
pora almost excludes supervised learning meth-
ods. A possible solution for automatic acqui-
sition of sense tagged corpora has been pre-
sented in (Mihalcea and Moldovan, 1999), but
the corpora acquired with this method has not
been yet tested for statistical disambiguation of
words. On the other hand, the disambiguation
using unsupervised methods has the disadvan-
tage that the senses are not well defined. None
of the statistical methods disambiguate adjec-
tives or adverbs so far.
In this paper, we introduce a method that at-
tempts to disambiguate all the nouns, verbs, ad-
jectives and adverbs in a text, using the senses
provided in WordNet (Fellbaum, 1998). To
our knowledge, there is only one other method,
recently reported, that disambiguates unre-
stricted words in texts (Stetina et al., 1998).
</bodyText>
<sectionHeader confidence="0.9873855" genericHeader="introduction">
2 A word-word dependency
approach
</sectionHeader>
<bodyText confidence="0.999935454545455">
The method presented here takes advantage of
the sentence context. The words are paired and
an attempt is made to disambiguate one word
within the context of the other word. This
is done by searching on Internet with queries
formed using different senses of one word, while
keeping the other word fixed. The senses are
ranked simply by the order provided by the
number of hits. A good accuracy is obtained,
perhaps because the number of texts on the In-
ternet is so large. In this way, all the words are
</bodyText>
<page confidence="0.996258">
152
</page>
<bodyText confidence="0.99996572">
processed and the senses are ranked. We use
the ranking of senses to curb the computational
complexity in the step that follows. Only the
most promising senses are kept.
The next step is to refine the ordering of
senses by using a completely different method,
namely the semantic density. This is measured
by the number of common words that are within
a semantic distance of two or more words. The
closer the semantic relationship between two
words the higher the semantic density between
them. We introduce the semantic density be-
cause it is relatively easy to measure it on a
MRD like WordNet. A metric is introduced in
this sense which when applied to all possible
combinations of the senses of two or more words
it ranks them.
An essential aspect of the WSD method pre-
sented here is that it provides a raking of pos-
sible associations between words instead of a
binary yes/no decision for each possible sense
combination. This allows for a controllable pre-
cision as other modules may be able to distin-
guish later the correct sense association from
such a small pool.
</bodyText>
<sectionHeader confidence="0.91949" genericHeader="method">
3 Contextual ranking of word senses
</sectionHeader>
<bodyText confidence="0.99978975">
Since the Internet contains the largest collection
of texts electronically stored, we use the Inter-
net as a source of corpora for ranking the senses
of the words.
</bodyText>
<subsectionHeader confidence="0.998889">
3.1 Algorithm 1
</subsectionHeader>
<bodyText confidence="0.9824375">
For a better explanation of this algorithm, we
provide the steps below with an example. We
considered the verb-noun pair &amp;quot;investigate re-
port&amp;quot;; in order to make easier the understand-
ing of these examples, we took into considera-
tion only the first two senses of the noun re-
port. These two senses, as defined in WordNet,
appear in the synsets: {report#1, study} and
{report#2, news report, story, account, write
up}.
INPUT: semantically untagged wordi - word2
pair (W1 — W2)
OUTPUT: ranking the senses of one word
PROCEDURE:
STEP 1. Form a similarity list for each sense
of one of the words. Pick one of the words,
say W2, and using WordNet, form a similarity
list for each sense of that word. For this, use
the words from the synset of each sense and the
words from the hypernym synsets. Consider,
for example, that W2 has m senses, thus W2
appears in m similarity lists:
</bodyText>
<equation confidence="0.986941666666667">
0471, w21(1)) w21(2), w21(ki))
w22(1), w22(2), w22(k2))
(wr, w2m(1), wr(2), ...7 Wm(km)
</equation>
<bodyText confidence="0.988014">
where WI, 14q, wp are the senses of W2)
and 14f;i(s) represents the synonym number s of
the sense WI as defined in WordNet.
Example The similarity lists for the first two
senses of the noun report are:
</bodyText>
<equation confidence="0.937322428571429">
(report, study)
(report, news report, story, account, write up)
STEP 2. Form W1 - W2i(s) pairs
may be formed are:
(W1 — W/,1471 WP1)) W1 —
(W1 — w22, 1471 — wr), w1 —
—W&apos;)
</equation>
<bodyText confidence="0.945330466666667">
Example The pairs formed with the verb inves-
tigate and the words in the similarity lists of the
noun report are:
(investigate-report, investigate-study)
(investigate-report, investigate-news report, investigate-
story, investigate-account, investigate-write up)
STEP 3. Search the Internet and rank the senses
W2i(s). A search performed on the Internet for
each set of pairs as defined above, results in a
value indicating the frequency of occurrences for
W1 and the sense of W2. In our experiments we
used (Altavista, 1996) since it is one of the most
powerful search engines currently available. Us-
ing the operators provided by AltaVista, query-
forms are defined for each W1 — W22(3) set above:
</bodyText>
<listItem confidence="0.95557075">
(a) (&amp;quot;WI M&amp;quot; OR &amp;quot;WIL 141(1)&amp;quot; OR &amp;quot;Wi W2i(2)&amp;quot; OR ...
OR &amp;quot;WI 147(kl)&amp;quot;)
(b) ((W1 NEAR Wj) OR (W1 NEAR 1,17;l(1)) OR (W1
NEAR 147(2)) OR ... OR (W1 NEAR 147(ki)))
</listItem>
<bodyText confidence="0.999007875">
for all 1 &lt; i &lt; m. Using one of these queries,
we get the number of hits for each sense i of W2
and this provides a ranking of the m senses of
W2 as they relate with W1.
Example The types of query that can be formed
using the verb investigate and the similarity lists
of the noun report, are shown below. After each
query, we indicate the number of hits obtained
</bodyText>
<equation confidence="0.800265666666667">
. The pairs that
_ wpki))
w22(k2))
</equation>
<page confidence="0.98963">
153
</page>
<bodyText confidence="0.841883">
by a search on the Internet, using AltaVista.
</bodyText>
<listItem confidence="0.9600523">
(a) (&amp;quot;investigate report&amp;quot; OR &amp;quot;investigate study&amp;quot;) (478)
(&amp;quot;investigate report&amp;quot; OR &amp;quot;investigate news report&amp;quot; OR
&amp;quot;investigate story&amp;quot; OR &amp;quot;investigate account&amp;quot; OR &amp;quot;inves-
tigate write up&amp;quot;) (281)
(b) ((investigate NEAR report) OR (investigate NEAR
study)) (34880)
((investigate NEAR report) OR (investigate NEAR news
report) OR (investigate NEAR story) OR (investigate
NEAR account) OR (investigate NEAR write up))
(15884)
</listItem>
<bodyText confidence="0.999896571428571">
A similar algorithm is used to rank the
senses of W1 while keeping W2 constant (un-
disambiguated). Since these two procedures are
done over a large corpora (the Internet), and
with the help of similarity lists, there is little
correlation between the results produced by the
two procedures.
</bodyText>
<subsubsectionHeader confidence="0.50162">
3.1.1 Procedure Evaluation
</subsubsectionHeader>
<bodyText confidence="0.958653739130435">
This method was tested on 384 pairs: 200 verb-
noun (file br-a01, br-a02), 127 adjective-noun
(file br-a01), and 57 adverb-verb (file br-a01),
extracted from SemCor 1.6 of the Brown corpus.
Using query form (a) on AltaVista, we obtained
the results shown in Table 1. The table indi-
cates the percentages of correct senses (as given
by SemCor) ranked by us in top 1, top 2, top
3, and top 4 of our list. We concluded that by
keeping the top four choices for verbs and nouns
and the top two choices for adjectives and ad-
verbs, we cover with high percentage (mid and
upper 90&apos;s) all relevant senses. Looking from a
different point of view, the meaning of the pro-
cedure so far is that it excludes the senses that
do not apply, and this can save a considerable
amount of computation time as many words are
highly polysemous.
top 1 top 2 top 3 top 4
noun 76% 83% 86% 98%
verb 60% 68% 86% 87%
adjective 79.8% 93%
adverb 87% 97%
</bodyText>
<tableCaption confidence="0.9197805">
Table 1: Statistics gather from the Internet for
384 word pairs.
</tableCaption>
<bodyText confidence="0.99983075">
We also used the query form (b), but the re-
sults obtained were similar; using the operator
NEAR, a larger number of hits is reported, but
the sense ranking remains more or less the same.
</bodyText>
<subsectionHeader confidence="0.999726">
3.2 Conceptual density algorithm
</subsectionHeader>
<bodyText confidence="0.999978727272727">
A measure of the relatedness between words can
be a knowledge source for several decisions in
NLP applications. The approach we take here
is to construct a linguistic context for each sense
of the verb and noun, and to measure the num-
ber of the common nouns shared by the verb
and the noun contexts. In WordNet each con-
cept has a gloss that acts as a micro-context for
that concept. This is a rich source of linguistic
information that we found useful in determining
conceptual density between words.
</bodyText>
<subsectionHeader confidence="0.72155">
3.2.1 Algorithm 2
</subsectionHeader>
<bodyText confidence="0.995000875">
INPUT: semantically untagged verb - noun pair
and a ranking of noun senses (as determined by
Algorithm 1)
OUTPUT: sense tagged verb - noun pair
PROCEDURE:
STEP 1. Given a verb-noun pair V — N, denote
with &lt; vi, v2, ..., vh &gt; and &lt; ni, n2, &gt; the
possible senses of the verb and the noun using
WordNet.
STEP 2. Using Algorithm 1, the senses of the
noun are ranked. Only the first t possible senses
indicated by this ranking will be considered.
The rest are dropped to reduce the computa-
tional complexity.
STEP 3. For each possible pair vi — nj, the con-
ceptual density is computed as follows:
</bodyText>
<listItem confidence="0.952738933333333">
(a) Extract all the glosses from the sub-
hierarchy including vi (the rationale for select-
ing the sub-hierarchy is explained below)
(b) Determine the nouns from these glosses.
These constitute the noun-context of the verb.
Each such noun is stored together with a weight
w that indicates the level in the sub-hierarchy
of the verb concept in whose gloss the noun was
found.
(c) Determine the nouns from the noun sub-
hierarchy including nj.
(d) Determine the conceptual density Cij of
common concepts between the nouns obtained
at (b) and the nouns obtained at (c) using the
metric:
</listItem>
<equation confidence="0.9762255">
lcdij I
= log(descendentsi) (1)
</equation>
<bodyText confidence="0.761052">
where:
</bodyText>
<listItem confidence="0.948904">
• led,, I is the number of common concepts between
the hierarchies of vi and n;
</listItem>
<page confidence="0.995675">
154
</page>
<table confidence="0.99078215">
REVISE
/. revise#1 )
=&gt; ( rewrite)
2. (retool, revise#2)
=&gt; reorganize, shake up)
LAW
/.1 law#1, jurisprudence]
=&gt; (collection, aggregation,
2. (law#2) accumulation, assemblage)
=&gt; (rule, prescript) ...
3. (law#3, natural law)
=&gt; concept, conception, abstract)
4. (law#4, law of nature)
=&gt; ( concept, conception, abstract]
5. (jurisprudence, law#5, legal philosophy)
=&gt; (philosophy)
6. (law#6, practice of law)
=&gt; ( learned profession)
7. (police, police force, constabulary, law#7)
=&gt; ( force, personnel)
</table>
<listItem confidence="0.854708">
• wk are the levels of the nouns in the hierarchy of
verb vi
• descendents, is the total number of words within
the hierarchy of noun n,
STEP 4. C ranks each pair vi — n3, for all i and
3.
Rationale
1. In WordNet, a gloss explains a concept and
</listItem>
<bodyText confidence="0.981358571428571">
provides one or more examples with typical us-
age of that concept. In order to determine the
most appropriate noun and verb hierarchies, we
performed some experiments using SemCor and
concluded that the noun sub-hierarchy should
include all the nouns in the class of n3. The
sub-hierarchy of verb vi is taken as the hierar-
chy of the highest hypernym hi of the verb v. It
is necessary to consider a larger hierarchy then
just the one provided by synonyms and direct
hyponyms. As we replaced the role of a corpora
with glosses, better results are achieved if more
glosses are considered. Still, we do not want to
enlarge the context too much.
</bodyText>
<listItem confidence="0.991282923076923">
2. As the nouns with a big hierarchy tend
to have a larger value for lcdij I, the weighted
sum of common concepts is normalized with re-
spect to the dimension of the noun hierarchy.
Since the size of a hierarchy grows exponentially
with its depth, we used the logarithm of the to-
tal number of descendants in the hierarchy, i.e.
log(descendentsj).
3. We also took into consideration and have
experimented with a few other metrics. But af-
ter running the program on several examples,
the formula from Algorithm 2 provided the best
results.
</listItem>
<sectionHeader confidence="0.958055" genericHeader="method">
4 An Example
</sectionHeader>
<bodyText confidence="0.994537230769231">
As an example, let us consider the verb-noun
collocation revise law. The verb revise has two
possible senses in WordNet 1.6 and the noun law
has seven senses. Figure 1 presents the synsets
in which the different meanings of this verb and
noun appear.
First, Algorithm 1 was applied and search
the Internet using AltaVista, for all possi-
ble pairs V-N that may be created using re-
vise and the words from the similarity lists of
law. The following ranking of senses was ob-
tained: /aw#2(2829), law#3(648), /aw#4(640),
/aw#6(397), /aw#/(224), law#5(37), law#7(0),
</bodyText>
<figureCaption confidence="0.8743075">
Figure 1: Synsets and hypernyms for the differ-
ent meanings , as defined in WordNet
</figureCaption>
<bodyText confidence="0.999855833333333">
where the numbers in parentheses indicate the
number of hits. By setting the threshold at
t = 2, we keep only sense #2 and #3.
Next, Algorithm 2 is applied to rank the four
possible combinations (two for the verb times
two for the noun). The results are summarized
in Table 2: (1) lcdii I - the number of common
concepts between the verb and noun hierarchies;
(2) deseendantsi the total number of nouns
within the hierarchy of each sense ni; and (3)
the conceptual density Cij for each pair ni — vj
derived using the formula presented above.
</bodyText>
<table confidence="0.5102425">
lediJI descendants;
n2 n3 n2 n3 122 n3
vi 5 4 975 1265 0.30 0.28
V2 0 0 975 1265 0 0
</table>
<tableCaption confidence="0.623021">
Table 2: Values used in computing the concep-
</tableCaption>
<bodyText confidence="0.978962">
tual density and the conceptual density Cii
The largest conceptual density C12 = 0.30
corresponds to v1 — n2: revise#1/2 — /aw#2/5
(the notation #iln means sense i out of n pos-
</bodyText>
<page confidence="0.998176">
155
</page>
<bodyText confidence="0.999339666666667">
sible senses given by WordNet). This combina-
tion of verb-noun senses also appears in Sem-
Cor, file br-a01.
</bodyText>
<sectionHeader confidence="0.9111525" genericHeader="method">
5 Evaluation and comparison with
other methods
</sectionHeader>
<subsectionHeader confidence="0.993857">
5.1 Tests against SemCor
</subsectionHeader>
<bodyText confidence="0.963592833333333">
The method was tested on 384 pairs selected
from the first two tagged files of SemCor 1.6
(file br-a01, br-a02). From these, there are 200
verb-noun pairs, 127 adjective-noun pairs and
57 adverb-verb pairs.
In Table 3, we present a summary of the results.
</bodyText>
<table confidence="0.920373">
top 1 top 2 top 3 top 4
noun 86.5% 96% 97% 98%
verb 67% 79% 86% 87%
adjective 79.8% 93%
adverb 87% 97%
</table>
<tableCaption confidence="0.942363333333333">
Table 3: Final results obtained for 384 word
pairs using both algorithms.
Table 3 shows the results obtained using both
algorithms; for nouns and verbs, these results
are improved with respect to those shown in
Table 1, where only the first algorithm was ap-
</tableCaption>
<bodyText confidence="0.911814472222222">
plied. The results for adjectives and adverbs are
the same in both these tables; this is because the
second algorithm is not used with adjectives and
adverbs, as words having this part of speech are
not structured in hierarchies in WordNet, but
in clusters; the small size of the clusters limits
the applicability of the second algorithm.
Discussion of results When evaluating these
results, one should take into consideration that:
1. Using the glosses as a base for calculat-
ing the conceptual density has the advantage of
eliminating the use of a large corpus. But a dis-
advantage that comes from the use of glosses
is that they are not part-of-speech tagged, like
some corpora are (i.e. Treebank). For this rea-
son, when determining the nouns from the verb
glosses, an error rate is introduced, as some
verbs (like make, have, go, do) are lexically am-
biguous having a noun representation in Word-
Net as well. We believe that future work on
part-of-speech tagging the glosses of WordNet
will improve our results.
2. The determination of senses in SemCor
was done of course within a larger context, the
context of sentence and discourse. By working
only with a pair of words we do not take advan-
tage of such a broader context. For example,
when disambiguating the pair protect court our
method picked the court meaning &amp;quot;a room in
which a law court sits&amp;quot; which seems reasonable
given only two words, whereas SemCor gives the
court meaning &amp;quot;an assembly to conduct judicial
business&amp;quot; which results from the sentence con-
text (this was our second choice). In the next
section we extend our method to more than two
words disambiguated at the same time.
</bodyText>
<subsectionHeader confidence="0.999972">
5.2 Comparison with other methods
</subsectionHeader>
<bodyText confidence="0.999299473684211">
As indicated in (Resnik and Yarowsky, 1997),
it is difficult to compare the WSD methods,
as long as distinctions reside in the approach
considered (MRD based methods, supervised
or unsupervised statistical methods), and in
the words that are disambiguated. A method
that disambiguates unrestricted nouns, verbs,
adverbs and adjectives in texts is presented in
(Stetina et al., 1998); it attempts to exploit sen-
tential and discourse contexts and is based on
the idea of semantic distance between words,
and lexical relations. It uses WordNet and it
was tested on SemCor.
Table 4 presents the accuracy obtained by
other WSD methods. The baseline of this com-
parison is considered to be the simplest method
for WSD, in which each word is tagged with
its most common sense, i.e. the first sense as
defined in WordNet.
</bodyText>
<table confidence="0.999429285714286">
Base Stetina Yarowsky Our
line method
noun 80.3% 85.7% 93.9% 86.5%
verb 62.5% 63.9% - 67%
adjective 81.8% 83.6% - 79.8
adverb 84.3% 86.5% - 87%
AVERAGE I 77% 80% 1 - 80.1%
</table>
<tableCaption confidence="0.9004225">
Table 4: A comparison with other WSD meth-
ods.
</tableCaption>
<bodyText confidence="0.986539714285714">
As it can be seen from this table, (Stetina et
al., 1998) reported an average accuracy of 85.7%
for nouns, 63.9% for verbs, 83.6% for adjectives
and 86.5% for adverbs, slightly less than our re-
sults. Moreover, for applications such as infor-
mation retrieval we can use more than one sense
combination; if we take the top 2 ranked com-
</bodyText>
<tableCaption confidence="0.631798">
binations our average accuracy is 91.5% (from
Table 3).
Other methods that were reported in the lit-
</tableCaption>
<page confidence="0.99814">
156
</page>
<bodyText confidence="0.999957">
erature disambiguate either one part of speech
word (i.e. nouns), or in the case of purely statis-
tical methods focus on very limited number of
words. Some of the best results were reported
in (Yarowsky, 1995) who uses a large training
corpus. For the noun drug Yarowsky obtains
91.4% correct performance and when consider-
ing the restriction &amp;quot;one sense per discourse&amp;quot; the
accuracy increases to 93.9%, result represented
in the third column in Table 4.
</bodyText>
<sectionHeader confidence="0.997366" genericHeader="evaluation">
6 Extensions
</sectionHeader>
<subsectionHeader confidence="0.999083">
6.1 Noun-noun and verb-verb pairs
</subsectionHeader>
<bodyText confidence="0.9999944">
The method presented here can be applied in a
similar way to determine the conceptual density
within noun-noun pairs, or verb-verb pairs (in
these cases, the NEAR operator should be used
for the first step of this algorithm).
</bodyText>
<subsectionHeader confidence="0.99985">
6.2 Larger window size
</subsectionHeader>
<bodyText confidence="0.9920536">
We have extended the disambiguation method
to more than two words co-occurrences. Con-
sider for example:
The bombs caused damage but no injuries.
The senses specified in SemCor, are:
</bodyText>
<equation confidence="0.9318845">
la. bomb(#1/3) cause(#1/2) damage(#1/5)
injury(#1/4)
</equation>
<bodyText confidence="0.9997497">
For each word X, we considered all possible
combinations with the other words Y from the
sentence, two at a time. The conceptual density
C was computed for the combinations X - Y
as a summation of the conceptual densities be-
tween the sense i of the word X and all the
senses of the words Y. The results are shown
in the tables below where the conceptual den-
sity calculated for the sense #i of word X is
presented in the column denoted by C#i:
</bodyText>
<table confidence="0.8304948">
X - Y C#1 C#2 C#3
bomb-cause 0.57 0 0
bomb-damage 5.09 0.13 0
bomb-injury 2.69 0.15 0
SCORE 8.35 0.28 0
</table>
<bodyText confidence="0.931855333333333">
By selecting the largest values for the con-
ceptual density, the words are tagged with their
senses as follows:
</bodyText>
<equation confidence="0.6232875">
lb. bomb(#1/3) cause(#1/2) damage(#1/5)
injury(#2/4)
</equation>
<table confidence="0.991375">
X - Y C#1 C#2
cause-bomb 5.16 1.34
cause-damage 12.83 2.64
cause-injury 12.63 1.75
SCORE 30.62 5.73
X - Y C#1 C#2 C#3 C#4 C#5
damage-bomb 5.60 2.14 1.95 0.88 2.16
damage-cause 1.73 2.63 0.17 0.16 3.80
damage-injury 9.87 2.57 3.24 1.56 7.59
SCORE 17.20 7.34 5.36 2.60 13.55
</table>
<bodyText confidence="0.998214947368421">
Note that the senses for word injury differ from
la. to lb.; the one determined by our method
(#2/4) is described in WordNet as &amp;quot;an acci-
dent that results in physical damage or hurt&amp;quot;
(hypernym: accident), and the sense provided
in SemCor (#1/4) is defined as &amp;quot;any physical
damage &amp;quot;(hypernym: health problem).
This is a typical example of a mismatch
caused by the fine granularity of senses in Word-
Net which translates into a human judgment
that is not a clear cut. We think that the
sense selection provided by our method is jus-
tified, as both damage and injury are objects
of the same verb cause; the relatedness of dam-
age(#1/5) and injury(#2/4) is larger, as both
are of the same class noun.event as opposed to
injury(#1/4) which is of class noun.state.
Some other randomly selected examples con-
sidered were:
</bodyText>
<figure confidence="0.971100307692308">
2a. The terrorists(#1/1) bombed(#1/3) the
embassies(#1/1).
2b. terrorist(#1/1) bomb(#1/3)
embassy(#1/1)
3a. A car-bomb(#1/1) exploded(#2/10) in
front of PRC(#1/1) embassy(#1/1).
3b. car-bomb(#1/1) explode(#2/10)
PR C(#1/1) embassy(#1/1)
4a. The bombs(#1/3) broke(#23/27)
windows(#1/4) and destroyed (&apos;#2/4) the two
vehicles(#1/2).
4b. bomb(#1/3) break(#3/27) window(#1/4)
destroy(#2/4) vehicle(#1/2)
</figure>
<bodyText confidence="0.9988432">
where sentences 2a, 3a and 4a are extracted
from SemCor, with the associated senses for
each word, and sentences 2b, 3b and 4b show
the verbs and the nouns tagged with their senses
by our method. The only discrepancy is for the
</bodyText>
<page confidence="0.989857">
157
</page>
<table confidence="0.9843432">
X - Y C#1 C#2 C#3 C#4
injury-bomb 2.35 5.35 0.41 2.28
injury-cause 0 4.48 0.05 0.01
injury-damage 5.05 10.40 0.81 9.69
SCORE 7.40 20.23 1.27 11.98
</table>
<bodyText confidence="0.99390475">
word broke and perhaps this is due to the large
number of its senses. The other word with a
large number of senses explode was tagged cor-
rectly, which was encouraging.
</bodyText>
<sectionHeader confidence="0.998574" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.9999481">
WordNet is a fine grain MRD and this makes it
more difficult to pinpoint the correct sense com-
bination since there are many to choose from
and many are semantically close. For appli-
cations such as machine translation, fine grain
disambiguation works well but for information
extraction and some other applications this is
an overkill, and some senses may be lumped to-
gether. The ranking of senses is useful for many
applications.
</bodyText>
<sectionHeader confidence="0.999106" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999833452054795">
E. Agirre and G. Rigau. 1995. A proposal for
word sense disambiguation using conceptual
distance. In Proceedings of the First Inter-
national Conference on Recent Advances in
Natural Language Processing, Velingrad.
Altavista. 1996. Digital equipment corpora-
tion. &amp;quot;http://www.altavista.com&amp;quot;.
R. Bruce and J. Wiebe. 1994. Word sense
disambiguation using decomposable models.
In Proceedings of the Thirty Second An-
nual Meeting of the Association for Computa-
tional Linguistics (ACL-94), pages 139-146,
LasCruces, NM, June.
J. Cowie, L. Guthrie, and J. Guthrie. 1992.
Lexical disambiguation using simulated an-
nealing. In Proceedings of the Fifth Interna-
tional Conference on Computational Linguis-
tics COLING-92, pages 157-161.
C. Fellbaum. 1998. WordNet, An Electronic
Lexical Database. The MIT Press.
W. Gale, K. Church, and D. Yarowsky. 1992.
One sense per discourse. In Proceedings of the
DARPA Speech and Natural Language Work-
shop, Harriman, New York.
X. Li, S. Szpakowicz, and M. Matwin. 1995.
A wordnet-based algorithm for word seman-
tic sense disambiguation. In Proceedings of
the Forteen International Joint Conference
on Artificial Intelligence IJCAI-95, Montreal,
Canada.
S. McRoy. 1992. Using multiple knowledge
sources for word sense disambiguation. Com-
putational Linguistics, 18(1):1-30.
R. Mihalcea and D.I. Moldovan. 1999. An au-
tomatic method for generating sense tagged
corpora. In Proceedings of AAAI-99, Or-
lando, FL, July. (to appear).
G. Miller, M. Chodorow, S. Landes, C. Leacock,
and R. Thomas. 1994. Using a semantic con-
cordance for sense identification. In Proceed-
ings of the ARPA Human Language Technol-
ogy Workshop, pages 240-243.
H.T. Ng and H.B. Lee. 1996. Integrating multi-
ple knowledge sources to disambiguate word
sense: An examplar-based approach. In Pro-
ceedings of the Thirtyfour Annual Meeting of
the Association for Computational Linguis-
tics (ACL-96), Santa Cruz.
P. Resnik and D. Yarowsky. 1997. A perspec-
tive on word sense disambiguation methods
and their evaluation. In Proceedings of ACL
Siglex Workshop on Tagging Text with Lexical
Semantics, Why, What and How?, Washing-
ton DC, April.
P. Resnik. 1997. Selectional preference and
sense disambiguation. In Proceedings of ACL
Siglex Workshop on Tagging Text with Lexical
Semantics, Why, What and How?, Washing-
ton DC, April.
G. Rigau, J. Atserias, and E. Agirre. 1997.
Combining unsupervised lexical knowledge
methods for word sense disambiguation.
Computational Linguistics.
J. Stetina, S. Kurohashi, and M. Nagao. 1998.
General word sense disambiguation method
based on a full sentential context. In Us-
age of WordNet in Natural Language Process-
ing, Proceedings of COLING-ACL Workshop,
Montreal, Canada, July.
D. Yarowsky. 1995. Unsupervised word sense
disambiguation rivaling supervised methods.
In Proceedings of the Thirtythird Association
of Computational Linguistics.
</reference>
<page confidence="0.997091">
158
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.980771">
<title confidence="0.99981">A Method for Word Sense Disambiguation of Unrestricted Text</title>
<author confidence="0.999973">Mihalcea I Moldovan</author>
<affiliation confidence="0.997239">Department of Computer Science and Engineering Southern Methodist University</affiliation>
<address confidence="0.999898">Dallas, Texas, 75275-0122</address>
<email confidence="0.99776">radaOseas.smu.edu</email>
<email confidence="0.99776">moldovanOseas.smu.edu</email>
<abstract confidence="0.9990356875">Selecting the most appropriate sense for an ambiguous word in a sentence is a central problem in Natural Language Processing. In this paper, we present a method that attempts to disambiguate all the nouns, verbs, adverbs and adjectives in a text, using the senses provided in WordNet. The senses are ranked using two sources of information: (1) the Internet for gathering statistics for word-word cooccurrences and (2) WordNet for measuring the semantic density for a pair of words. We report average accuracy of the first ranked sense, and 91% for the first two ranked senses. Extensions of this method for larger windows of more than two words are considered.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>G Rigau</author>
</authors>
<title>A proposal for word sense disambiguation using conceptual distance.</title>
<date>1995</date>
<booktitle>In Proceedings of the First International Conference on Recent Advances in Natural Language Processing,</booktitle>
<location>Velingrad.</location>
<contexts>
<context position="1321" citStr="Agirre and Rigau, 1995" startWordPosition="206" endWordPosition="209">for a pair of words. We report an average accuracy of 80% for the first ranked sense, and 91% for the first two ranked senses. Extensions of this method for larger windows of more than two words are considered. 1 Introduction Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy resu</context>
</contexts>
<marker>Agirre, Rigau, 1995</marker>
<rawString>E. Agirre and G. Rigau. 1995. A proposal for word sense disambiguation using conceptual distance. In Proceedings of the First International Conference on Recent Advances in Natural Language Processing, Velingrad.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Altavista</author>
</authors>
<title>Digital equipment corporation. &amp;quot;http://www.altavista.com&amp;quot;.</title>
<date>1996</date>
<contexts>
<context position="6491" citStr="Altavista, 1996" startWordPosition="1083" endWordPosition="1084">1 - W2i(s) pairs may be formed are: (W1 — W/,1471 WP1)) W1 — (W1 — w22, 1471 — wr), w1 — —W&apos;) Example The pairs formed with the verb investigate and the words in the similarity lists of the noun report are: (investigate-report, investigate-study) (investigate-report, investigate-news report, investigatestory, investigate-account, investigate-write up) STEP 3. Search the Internet and rank the senses W2i(s). A search performed on the Internet for each set of pairs as defined above, results in a value indicating the frequency of occurrences for W1 and the sense of W2. In our experiments we used (Altavista, 1996) since it is one of the most powerful search engines currently available. Using the operators provided by AltaVista, queryforms are defined for each W1 — W22(3) set above: (a) (&amp;quot;WI M&amp;quot; OR &amp;quot;WIL 141(1)&amp;quot; OR &amp;quot;Wi W2i(2)&amp;quot; OR ... OR &amp;quot;WI 147(kl)&amp;quot;) (b) ((W1 NEAR Wj) OR (W1 NEAR 1,17;l(1)) OR (W1 NEAR 147(2)) OR ... OR (W1 NEAR 147(ki))) for all 1 &lt; i &lt; m. Using one of these queries, we get the number of hits for each sense i of W2 and this provides a ranking of the m senses of W2 as they relate with W1. Example The types of query that can be formed using the verb investigate and the similarity lists of </context>
</contexts>
<marker>Altavista, 1996</marker>
<rawString>Altavista. 1996. Digital equipment corporation. &amp;quot;http://www.altavista.com&amp;quot;.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bruce</author>
<author>J Wiebe</author>
</authors>
<title>Word sense disambiguation using decomposable models.</title>
<date>1994</date>
<booktitle>In Proceedings of the Thirty Second Annual Meeting of the Association for Computational Linguistics (ACL-94),</booktitle>
<pages>139--146</pages>
<location>LasCruces, NM,</location>
<contexts>
<context position="1833" citStr="Bruce and Wiebe, 1994" startWordPosition="284" endWordPosition="287">rovided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods. A possible solution for automatic acquisition of sense tagged corpora has been presented in (Mihalcea and Moldovan, 1999), but the corpora acquired with this method has not been yet tested for statistical disambiguation of words. On the other hand, the disambiguation using unsupervised methods has the disadvantage that the senses are not well defined. None of the sta</context>
</contexts>
<marker>Bruce, Wiebe, 1994</marker>
<rawString>R. Bruce and J. Wiebe. 1994. Word sense disambiguation using decomposable models. In Proceedings of the Thirty Second Annual Meeting of the Association for Computational Linguistics (ACL-94), pages 139-146, LasCruces, NM, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Cowie</author>
<author>L Guthrie</author>
<author>J Guthrie</author>
</authors>
<title>Lexical disambiguation using simulated annealing.</title>
<date>1992</date>
<booktitle>In Proceedings of the Fifth International Conference on Computational Linguistics COLING-92,</booktitle>
<pages>157--161</pages>
<contexts>
<context position="1272" citStr="Cowie et al., 1992" startWordPosition="198" endWordPosition="201">) WordNet for measuring the semantic density for a pair of words. We report an average accuracy of 80% for the first ranked sense, and 91% for the first two ranked senses. Extensions of this method for larger windows of more than two words are considered. 1 Introduction Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997</context>
</contexts>
<marker>Cowie, Guthrie, Guthrie, 1992</marker>
<rawString>J. Cowie, L. Guthrie, and J. Guthrie. 1992. Lexical disambiguation using simulated annealing. In Proceedings of the Fifth International Conference on Computational Linguistics COLING-92, pages 157-161.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet, An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="2669" citStr="Fellbaum, 1998" startWordPosition="422" endWordPosition="423"> methods. A possible solution for automatic acquisition of sense tagged corpora has been presented in (Mihalcea and Moldovan, 1999), but the corpora acquired with this method has not been yet tested for statistical disambiguation of words. On the other hand, the disambiguation using unsupervised methods has the disadvantage that the senses are not well defined. None of the statistical methods disambiguate adjectives or adverbs so far. In this paper, we introduce a method that attempts to disambiguate all the nouns, verbs, adjectives and adverbs in a text, using the senses provided in WordNet (Fellbaum, 1998). To our knowledge, there is only one other method, recently reported, that disambiguates unrestricted words in texts (Stetina et al., 1998). 2 A word-word dependency approach The method presented here takes advantage of the sentence context. The words are paired and an attempt is made to disambiguate one word within the context of the other word. This is done by searching on Internet with queries formed using different senses of one word, while keeping the other word fixed. The senses are ranked simply by the order provided by the number of hits. A good accuracy is obtained, perhaps because t</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>C. Fellbaum. 1998. WordNet, An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Gale</author>
<author>K Church</author>
<author>D Yarowsky</author>
</authors>
<title>One sense per discourse.</title>
<date>1992</date>
<booktitle>In Proceedings of the DARPA Speech and Natural Language Workshop,</booktitle>
<location>Harriman, New York.</location>
<contexts>
<context position="1518" citStr="Gale et al., 1992" startWordPosition="237" endWordPosition="240">sidered. 1 Introduction Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods. A possible solution for automatic acquisition of sense</context>
</contexts>
<marker>Gale, Church, Yarowsky, 1992</marker>
<rawString>W. Gale, K. Church, and D. Yarowsky. 1992. One sense per discourse. In Proceedings of the DARPA Speech and Natural Language Workshop, Harriman, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Li</author>
<author>S Szpakowicz</author>
<author>M Matwin</author>
</authors>
<title>A wordnet-based algorithm for word semantic sense disambiguation.</title>
<date>1995</date>
<booktitle>In Proceedings of the Forteen International Joint Conference on Artificial Intelligence IJCAI-95,</booktitle>
<location>Montreal, Canada.</location>
<contexts>
<context position="1340" citStr="Li et al., 1995" startWordPosition="210" endWordPosition="213">port an average accuracy of 80% for the first ranked sense, and 91% for the first two ranked senses. Extensions of this method for larger windows of more than two words are considered. 1 Introduction Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small numbe</context>
</contexts>
<marker>Li, Szpakowicz, Matwin, 1995</marker>
<rawString>X. Li, S. Szpakowicz, and M. Matwin. 1995. A wordnet-based algorithm for word semantic sense disambiguation. In Proceedings of the Forteen International Joint Conference on Artificial Intelligence IJCAI-95, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S McRoy</author>
</authors>
<title>Using multiple knowledge sources for word sense disambiguation.</title>
<date>1992</date>
<journal>Computational Linguistics,</journal>
<pages>18--1</pages>
<contexts>
<context position="1355" citStr="McRoy, 1992" startWordPosition="214" endWordPosition="215">uracy of 80% for the first ranked sense, and 91% for the first two ranked senses. Extensions of this method for larger windows of more than two words are considered. 1 Introduction Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small number of preselecte</context>
</contexts>
<marker>McRoy, 1992</marker>
<rawString>S. McRoy. 1992. Using multiple knowledge sources for word sense disambiguation. Computational Linguistics, 18(1):1-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>D I Moldovan</author>
</authors>
<title>An automatic method for generating sense tagged corpora.</title>
<date>1999</date>
<booktitle>In Proceedings of AAAI-99,</booktitle>
<location>Orlando, FL,</location>
<note>(to appear).</note>
<contexts>
<context position="2185" citStr="Mihalcea and Moldovan, 1999" startWordPosition="340" endWordPosition="343">nformation gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods. A possible solution for automatic acquisition of sense tagged corpora has been presented in (Mihalcea and Moldovan, 1999), but the corpora acquired with this method has not been yet tested for statistical disambiguation of words. On the other hand, the disambiguation using unsupervised methods has the disadvantage that the senses are not well defined. None of the statistical methods disambiguate adjectives or adverbs so far. In this paper, we introduce a method that attempts to disambiguate all the nouns, verbs, adjectives and adverbs in a text, using the senses provided in WordNet (Fellbaum, 1998). To our knowledge, there is only one other method, recently reported, that disambiguates unrestricted words in text</context>
</contexts>
<marker>Mihalcea, Moldovan, 1999</marker>
<rawString>R. Mihalcea and D.I. Moldovan. 1999. An automatic method for generating sense tagged corpora. In Proceedings of AAAI-99, Orlando, FL, July. (to appear).</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Miller</author>
<author>M Chodorow</author>
<author>S Landes</author>
<author>C Leacock</author>
<author>R Thomas</author>
</authors>
<title>Using a semantic concordance for sense identification.</title>
<date>1994</date>
<booktitle>In Proceedings of the ARPA Human Language Technology Workshop,</booktitle>
<pages>240--243</pages>
<contexts>
<context position="1295" citStr="Miller et al., 1994" startWordPosition="202" endWordPosition="205">g the semantic density for a pair of words. We report an average accuracy of 80% for the first ranked sense, and 91% for the first two ranked senses. Extensions of this method for larger windows of more than two words are considered. 1 Introduction Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods </context>
</contexts>
<marker>Miller, Chodorow, Landes, Leacock, Thomas, 1994</marker>
<rawString>G. Miller, M. Chodorow, S. Landes, C. Leacock, and R. Thomas. 1994. Using a semantic concordance for sense identification. In Proceedings of the ARPA Human Language Technology Workshop, pages 240-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H T Ng</author>
<author>H B Lee</author>
</authors>
<title>Integrating multiple knowledge sources to disambiguate word sense: An examplar-based approach.</title>
<date>1996</date>
<booktitle>In Proceedings of the Thirtyfour Annual Meeting of the Association for Computational Linguistics (ACL-96),</booktitle>
<location>Santa Cruz.</location>
<contexts>
<context position="1538" citStr="Ng and Lee, 1996" startWordPosition="241" endWordPosition="244">on Word Sense Disambiguation (WSD) is an open problem in Natural Language Processing. Its solution impacts other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods. A possible solution for automatic acquisition of sense tagged corpora has </context>
</contexts>
<marker>Ng, Lee, 1996</marker>
<rawString>H.T. Ng and H.B. Lee. 1996. Integrating multiple knowledge sources to disambiguate word sense: An examplar-based approach. In Proceedings of the Thirtyfour Annual Meeting of the Association for Computational Linguistics (ACL-96), Santa Cruz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
<author>D Yarowsky</author>
</authors>
<title>A perspective on word sense disambiguation methods and their evaluation.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL Siglex Workshop on Tagging Text with Lexical Semantics, Why, What and How?,</booktitle>
<location>Washington DC,</location>
<contexts>
<context position="16963" citStr="Resnik and Yarowsky, 1997" startWordPosition="2927" endWordPosition="2930"> the context of sentence and discourse. By working only with a pair of words we do not take advantage of such a broader context. For example, when disambiguating the pair protect court our method picked the court meaning &amp;quot;a room in which a law court sits&amp;quot; which seems reasonable given only two words, whereas SemCor gives the court meaning &amp;quot;an assembly to conduct judicial business&amp;quot; which results from the sentence context (this was our second choice). In the next section we extend our method to more than two words disambiguated at the same time. 5.2 Comparison with other methods As indicated in (Resnik and Yarowsky, 1997), it is difficult to compare the WSD methods, as long as distinctions reside in the approach considered (MRD based methods, supervised or unsupervised statistical methods), and in the words that are disambiguated. A method that disambiguates unrestricted nouns, verbs, adverbs and adjectives in texts is presented in (Stetina et al., 1998); it attempts to exploit sentential and discourse contexts and is based on the idea of semantic distance between words, and lexical relations. It uses WordNet and it was tested on SemCor. Table 4 presents the accuracy obtained by other WSD methods. The baseline</context>
</contexts>
<marker>Resnik, Yarowsky, 1997</marker>
<rawString>P. Resnik and D. Yarowsky. 1997. A perspective on word sense disambiguation methods and their evaluation. In Proceedings of ACL Siglex Workshop on Tagging Text with Lexical Semantics, Why, What and How?, Washington DC, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Resnik</author>
</authors>
<title>Selectional preference and sense disambiguation.</title>
<date>1997</date>
<booktitle>In Proceedings of ACL Siglex Workshop on Tagging Text with Lexical Semantics, Why, What and How?,</booktitle>
<location>Washington DC,</location>
<contexts>
<context position="1657" citStr="Resnik, 1997" startWordPosition="260" endWordPosition="261"> as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods. A possible solution for automatic acquisition of sense tagged corpora has been presented in (Mihalcea and Moldovan, 1999), but the corpora acquired with this method has not been yet tested for </context>
</contexts>
<marker>Resnik, 1997</marker>
<rawString>P. Resnik. 1997. Selectional preference and sense disambiguation. In Proceedings of ACL Siglex Workshop on Tagging Text with Lexical Semantics, Why, What and How?, Washington DC, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Rigau</author>
<author>J Atserias</author>
<author>E Agirre</author>
</authors>
<title>Combining unsupervised lexical knowledge methods for word sense disambiguation. Computational Linguistics.</title>
<date>1997</date>
<contexts>
<context position="1873" citStr="Rigau et al., 1997" startWordPosition="292" endWordPosition="295">owie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods. A possible solution for automatic acquisition of sense tagged corpora has been presented in (Mihalcea and Moldovan, 1999), but the corpora acquired with this method has not been yet tested for statistical disambiguation of words. On the other hand, the disambiguation using unsupervised methods has the disadvantage that the senses are not well defined. None of the statistical methods disambiguate adjectives</context>
</contexts>
<marker>Rigau, Atserias, Agirre, 1997</marker>
<rawString>G. Rigau, J. Atserias, and E. Agirre. 1997. Combining unsupervised lexical knowledge methods for word sense disambiguation. Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Stetina</author>
<author>S Kurohashi</author>
<author>M Nagao</author>
</authors>
<title>General word sense disambiguation method based on a full sentential context.</title>
<date>1998</date>
<booktitle>In Usage of WordNet in Natural Language Processing, Proceedings of COLING-ACL Workshop,</booktitle>
<location>Montreal, Canada,</location>
<contexts>
<context position="2809" citStr="Stetina et al., 1998" startWordPosition="442" endWordPosition="445">ut the corpora acquired with this method has not been yet tested for statistical disambiguation of words. On the other hand, the disambiguation using unsupervised methods has the disadvantage that the senses are not well defined. None of the statistical methods disambiguate adjectives or adverbs so far. In this paper, we introduce a method that attempts to disambiguate all the nouns, verbs, adjectives and adverbs in a text, using the senses provided in WordNet (Fellbaum, 1998). To our knowledge, there is only one other method, recently reported, that disambiguates unrestricted words in texts (Stetina et al., 1998). 2 A word-word dependency approach The method presented here takes advantage of the sentence context. The words are paired and an attempt is made to disambiguate one word within the context of the other word. This is done by searching on Internet with queries formed using different senses of one word, while keeping the other word fixed. The senses are ranked simply by the order provided by the number of hits. A good accuracy is obtained, perhaps because the number of texts on the Internet is so large. In this way, all the words are 152 processed and the senses are ranked. We use the ranking o</context>
<context position="17302" citStr="Stetina et al., 1998" startWordPosition="2978" endWordPosition="2981">assembly to conduct judicial business&amp;quot; which results from the sentence context (this was our second choice). In the next section we extend our method to more than two words disambiguated at the same time. 5.2 Comparison with other methods As indicated in (Resnik and Yarowsky, 1997), it is difficult to compare the WSD methods, as long as distinctions reside in the approach considered (MRD based methods, supervised or unsupervised statistical methods), and in the words that are disambiguated. A method that disambiguates unrestricted nouns, verbs, adverbs and adjectives in texts is presented in (Stetina et al., 1998); it attempts to exploit sentential and discourse contexts and is based on the idea of semantic distance between words, and lexical relations. It uses WordNet and it was tested on SemCor. Table 4 presents the accuracy obtained by other WSD methods. The baseline of this comparison is considered to be the simplest method for WSD, in which each word is tagged with its most common sense, i.e. the first sense as defined in WordNet. Base Stetina Yarowsky Our line method noun 80.3% 85.7% 93.9% 86.5% verb 62.5% 63.9% - 67% adjective 81.8% 83.6% - 79.8 adverb 84.3% 86.5% - 87% AVERAGE I 77% 80% 1 - 80.</context>
</contexts>
<marker>Stetina, Kurohashi, Nagao, 1998</marker>
<rawString>J. Stetina, S. Kurohashi, and M. Nagao. 1998. General word sense disambiguation method based on a full sentential context. In Usage of WordNet in Natural Language Processing, Proceedings of COLING-ACL Workshop, Montreal, Canada, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Yarowsky</author>
</authors>
<title>Unsupervised word sense disambiguation rivaling supervised methods.</title>
<date>1995</date>
<booktitle>In Proceedings of the Thirtythird Association of Computational Linguistics.</booktitle>
<contexts>
<context position="1642" citStr="Yarowsky, 1995" startWordPosition="258" endWordPosition="259"> other tasks such as discourse, reference resolution, coherence, inference and others. WSD methods can be broadly classified into three types: 1. WSD that make use of the information provided by machine readable dictionaries (Cowie et al., 1992), (Miller et al., 1994), (Agirre and Rigau, 1995), (Li et al., 1995), (McRoy, 1992); 2. WSD that use information gathered from training on a corpus that has already been semantically disambiguated (supervised training methods) (Gale et al., 1992), (Ng and Lee, 1996); 3. WSD that use information gathered from raw corpora (unsupervised training methods) (Yarowsky, 1995) (Resnik, 1997). There are also hybrid methods that combine several sources of knowledge such as lexicon information, heuristics, collocations and others (McRoy, 1992) (Bruce and Wiebe, 1994) (Ng and Lee, 1996) (Rigau et al., 1997). Statistical methods produce high accuracy results for small number of preselected words. A lack of widely available semantically tagged corpora almost excludes supervised learning methods. A possible solution for automatic acquisition of sense tagged corpora has been presented in (Mihalcea and Moldovan, 1999), but the corpora acquired with this method has not been </context>
<context position="18594" citStr="Yarowsky, 1995" startWordPosition="3212" endWordPosition="3213">table, (Stetina et al., 1998) reported an average accuracy of 85.7% for nouns, 63.9% for verbs, 83.6% for adjectives and 86.5% for adverbs, slightly less than our results. Moreover, for applications such as information retrieval we can use more than one sense combination; if we take the top 2 ranked combinations our average accuracy is 91.5% (from Table 3). Other methods that were reported in the lit156 erature disambiguate either one part of speech word (i.e. nouns), or in the case of purely statistical methods focus on very limited number of words. Some of the best results were reported in (Yarowsky, 1995) who uses a large training corpus. For the noun drug Yarowsky obtains 91.4% correct performance and when considering the restriction &amp;quot;one sense per discourse&amp;quot; the accuracy increases to 93.9%, result represented in the third column in Table 4. 6 Extensions 6.1 Noun-noun and verb-verb pairs The method presented here can be applied in a similar way to determine the conceptual density within noun-noun pairs, or verb-verb pairs (in these cases, the NEAR operator should be used for the first step of this algorithm). 6.2 Larger window size We have extended the disambiguation method to more than two w</context>
</contexts>
<marker>Yarowsky, 1995</marker>
<rawString>D. Yarowsky. 1995. Unsupervised word sense disambiguation rivaling supervised methods. In Proceedings of the Thirtythird Association of Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>