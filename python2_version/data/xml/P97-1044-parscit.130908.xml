<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.921348">
Maximal Incrementality in Linear Categorial Deduction
</title>
<author confidence="0.995854">
Mark Hepple
</author>
<affiliation confidence="0.869426333333333">
Dept. of Computer Science
University of Sheffield
Regent Court, Portobello Street
</affiliation>
<address confidence="0.988556">
Sheffield Si 4DP, UK
</address>
<email confidence="0.999245">
hepple@dcs.shef.ac.uk
</email>
<sectionHeader confidence="0.994799" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99971015">
Recent work has seen the emergence of a
common framework for parsing categorial
grammar (CG) formalisms that fall within
the &apos;type-logical&apos; tradition (such as the
Lambek calculus and related systems),
whereby some method of linear logic the-
orem proving is used in combination with
a system of labelling that ensures only de-
ductions appropriate to the relevant gram-
matical logic are allowed. The approaches
realising this framework, however, have not
so far addressed the task of incremental
parsing — a key issue in earlier work with
&apos;flexible&apos; categorial grammars. In this pa-
per, the approach of (Hepple, 1996) is mod-
ified to yield a linear deduction system that
does allow flexible deduction and hence in-
cremental processing, but that hence also
suffers the problem of &apos;spurious ambiguity&apos;.
This problem is avoided via normalisation.
</bodyText>
<sectionHeader confidence="0.998879" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.992066160714286">
A key attraction of the class of formalisms known as
&apos;flexible&apos; categorial grammars is their compatibility
with an incremental style of processing, in allow-
ing sentences to be assigned analyses that are fully
or primarily left-branching. Such analyses designate
many initial substrings of a sentence as interpretable
constituents, allowing its interpretation to be gener-
ated &apos;on-line&apos; as it is presented. Incremental inter-
pretation has been argued to provide for efficient
language processing, by allowing early filtering of
implausible readings.&apos;
This paper is concerned with the parsing of cat-
egorial formalisms that fall within the &apos;type-logical&apos;
1Within the categorial field, the significance of incre-
mentality has been emphasised most notably in the work
of Steedman, e.g. (Steedman, 1989).
tradition, whose most familiar representative is the
associative Lambek calculus (Lambek, 1958). Re-
cent work has seen proposals for a range of such
systems, differing in their resource sensitivity (and
hence, implicitly, their underlying notion of &apos;lin-
guistic structure&apos;), in some cases combining differ-
ing resource sensitivities in one system.&apos; Many of
these proposals employ a &apos;labelled deductive sys-
tem&apos; methodology (Gabbay, 1996), whereby types in
proofs are associated with labels which record proof
information for use in ensuring correct inferencing.
A common framework is emerging for parsing
type-logical formalisms, which exploits the labelled
deduction idea. Approaches within this framework
employ a theorem proving method that is appropri-
ate for use with linear logic, and combine it with a
labelling system that restricts admitted deductions
to be those of a weaker system. Crucially, linear logic
stands above all of the type-logical formalisms pro-
posed in the hierarchy of substructural logics, and
hence linear logic deduction methods can provide a
common basis for parsing all of these systems. For
example, Moortgat (1992) combines a linear proof
net method with labelling to provide deduction for
several categorial systems. Morrill (1995) shows
how types of the associative Lambek calculus may
be translated to labelled implicational linear types,
with deduction implemented via a version of SLD
resolution. Hepple (1996) introduces a linear deduc-
tion method, involving compilation to first order for-
mulae, which can be combined with various labelling
disciplines. These approaches, however, are not dir-
ected toward incremental processing.
In what follows, we show how the method of
(Hepple, 1996) can be modified to allow processing
which has a high degree of incrementality. These
modifications, however, give a system which suffers
2See, for example, the formalisms developed in
(Moortgat &amp; Morrill, 1991), (Moortgat &amp; Oehrle, 1994),
(Morrill, 1994), (Hepple, 1995).
</bodyText>
<page confidence="0.997513">
344
</page>
<bodyText confidence="0.999911">
the problem of &apos;derivational equivalence&apos;, also called
&apos;spurious ambiguity&apos;, i.e. allowing multiple proofs
which assign the same reading for some combina-
tion, a fact which threatens processing efficiency. We
show how this problem is solved via normalisation.
</bodyText>
<sectionHeader confidence="0.956252" genericHeader="introduction">
2 Implicational Linear Logic
</sectionHeader>
<bodyText confidence="0.999065222222222">
Linear logic is an example of a &amp;quot;resource-sensitive&amp;quot;
logic, requiring that each assumption (&apos;resource&apos;) is
used precisely once in any deduction. For the implic-
ational fragment, the set of formulae .7- are defined
by .7&amp;quot; ::= A I o— .7. (with A a nonempty set of
atomic types). A natural deduction formulation re-
quires the elimination and introduction rules in (1),
which correspond semantically to steps of functional
application and abstraction, respectively.
</bodyText>
<figure confidence="0.45528975">
(1) Ao—B:a B:b
o- E
A : (ab)
Ao—B: Av.a
</figure>
<bodyText confidence="0.9967284">
The proof (2) (which omits lambda terms) illustrates
that &apos;hypothetical reasoning&apos; in proofs (i.e. the use
of additional assumptions that are later discharged
or cancelled, such as Z here) is driven by the presence
of higher-order formulae (such as X0— (Yo— Z) here).
</bodyText>
<equation confidence="0.985133333333333">
(2) X0—(Yo—Z) Yo—W Wo—Z [Z]
Yo—Z
X
</equation>
<bodyText confidence="0.999742952380952">
Various type-logical categorial formalisms (or
strictly their implicational fragments) differ from
the above system only in imposing further restric-
tions on resource usage. For example, the associ-
ative Lambek calculus imposes a linear order over
formulae, in which context, implication divides into
two cases, (usually written \ and /) depending on
whether the argument type appears to the left or
right of the functor. Then, formulae may combine
only if they are adjacent and in the appropriate
left-right order. The non-associative Lambek cal-
culus (Lambek, 1961) sets the further requirement
that types combine under some fixed initial brack-
etting. Such weaker systems can be implemented
by combining implicational linear logic with a la-
belling system whose labels are structured objects
that record relevant resource information, i.e. of se-
quencing and/or bracketting, and then using this in-
formation in restricting permitted inferences to only
those that satisfy the resource requirements of the
weaker logic.
</bodyText>
<sectionHeader confidence="0.997689" genericHeader="method">
3 First-order Compilation
</sectionHeader>
<bodyText confidence="0.999479851851852">
The first-order formulae are those with only atomic
argument types (i.e. ..F ::= A I .Tc-- A).
Hepple (1996) shows how deductions in implica-
tional linear logic can be recast as deductions in-
volving only first-order formulae.3 The method in-
volves compiling the original formulae to indexed
first-order formulae, where a higher-order initial for-
mula yields multiple compiled formulae, e.g. (omit-
ting indices) Xo— (Yo— Z) would yield Xo—Y and Z,
i.e. with the subformula relevant to hypothetical
reasoning (Z) effectively excised from the initial for-
mulae, to be treated as a separate assumption, leav-
ing a first-order residue. Indexing is used in ensuring
general linear use of resources, but also notably to
ensure proper use of excised subformulae, i.e. so that
Z, in our example, must be used in deriving the argu-
ment of Xo—Y, and not elsewhere (otherwise invalid
deductions would be derivable).
The approach is best explained by example. In
proving Xo— (Yo— Z), Yo—W, Wo— Z = X, compila-
tion of the premise formulae yields the indexed for-
mulae that form the assumptions of (3), where for-
mulae (i) and (iv) both derive from Xo—(Yo—Z).
(Note in (3) that the lambda terms of assumptions
are written below their indexed types, simply to help
the proof fit in the column.) Combination is allowed
by the single inference rule (4).
</bodyText>
<equation confidence="0.988512666666666">
(3) (i) (ii) (iii) (iv)
{i} : Xo—(Y:{j}) {k} : Yo—(W:0) {/} : Wo—(Z:0) {j} : Z
At.x(Az.t) Au.yu Av.wv
j, l} : W: wz
{j, k,l} :Y : y(wz)
j,k,l} : X: x(Az.y(wz))
</equation>
<listItem confidence="0.918592">
(4) : A0—(B:oi) : Av.a : B : b ir = Sbeib
: A : a[b v]
</listItem>
<bodyText confidence="0.763492266666667">
Each assumption in (3) is associated with a set con-
taining a single index, which serves as the unique
3The point of this manoeuvre (i.e. compiling to first-
order formulae) is to create a deduction method which,
like chart parsing for phrase-structure grammar, avoids
the need to recompute intermediate results when search-
ing exhaustively for all possible analyses, i.e. where any
combination of types contributes to more than one over-
all analysis, it need only be computed once. The incre-
mental system to be developed in this paper is similarly
compatible with a &apos;chart-like&apos; processing approach, al-
though this issue will not be further addressed within
this paper. For earlier work on chart-parsing type-logical
formalisms, specifically the associative Lambek calculus,
see K8nig (1990), Hepple (1992), KOnig (1994).
</bodyText>
<figure confidence="0.77851">
[B: v]
A : a
o-I
</figure>
<page confidence="0.997058">
345
</page>
<bodyText confidence="0.999756461538462">
identifier for that assumption. The index sets of a
derived formula identify precisely those assumptions
from which it is derived. The rule (4) ensures appro-
priate indexation, i.e. via the condition 7r =
where W stands for disjoint union (ensuring linear
usage). The common origin of assumptions (i) and
(iv) (i.e. from Xo— (Yo—Z)) is recorded by the fact
that (i)&apos;s argument is marked with (iv)&apos;s index (j).
The condition a C &apos;0 of (4) ensures that (iv) must
contribute to the derivation of (i)&apos;s argument (which
is needed to ensure correct inferencing). Finally, ob-
serve that the semantics of (4) is handled not by
simple application, but rather by direct substitution
for the variable of a lambda expression, employing a
special variant of substitution, notated _L/L1 (e.g.
t[sfiv] to indicate substitution of s for v in t), which
specifically does not act to avoid accidental binding.
In the final inference of (3), this method allows the
variable z to fall within the scope of an abstraction
over z, and so become bound. Recall that introduc-
tion inferences of the original formulation are associ-
ated with abstraction steps. In this approach, these
inferences are no longer required, their effects hav-
ing been compiled into the semantics. See (Hepple,
1996) for more details, including a precise statement
of the compilation procedure.
</bodyText>
<sectionHeader confidence="0.990733" genericHeader="method">
4 Flexible Deduction
</sectionHeader>
<bodyText confidence="0.998436433333333">
The approach just outlined is unsuited to incre-
mental processing. Its single inference rule allows
only a rigid style of combining formulae, where or-
der of combination is completely determined by the
argument order of functors. The formulae of (3), for
example, must combine precisely as shown. It is not
possible, say, to combine assumptions (i) and (ii) to-
gether first as part of a derivation. To overcome this
limitation, we might generalise the combination rule
to allow composition of functions, i.e. combinations
akin to e.g. Xo—Y, Yo—W = Xo—W. However, the
treatment of indexation in the above system is one
that does not readily adapt to flexible combination.
We will transform these indexed formulae to an-
other form which better suits our needs, using the
compilation procedure (5). This procedure returns
a modified formula plus a set of equations that spe-
cify constraints on its indexation. For example, the
assumptions (i-iv) of (3) yield the results (6) (ignor-
ing semantic terms, which remain unchanged). Each
atomic formula is partnered with an index set (or
typically a variable over such), which corresponds
to the full set of indices to be associated with the
complete object of that category, e.g. in (i) we have
(X+0), plus the equation 0 = {i}thr which tells us
that X&apos;s index set 0 includes the argument formula
Y&apos;s index set 7r plus its own index i. The further
constraint equation 0 = 101:07r indicates that the
argument&apos;s index set should include j (c.f. the con-
ditions for using the original indexed formula).
</bodyText>
<listItem confidence="0.436006">
(5) a (0 : X :t), ((X+0):t, 0)
where X atomic
</listItem>
<equation confidence="0.930595652173913">
( : X 0— Y : t) = (Z : t , C)
where al (0, Xo—Y) = (Z, C)
(71(0, X) = ((X+/), = 45})
where X atomic, 7 a fresh variable
(4), (17 7r)) = (X20— (Y+7), CI)
where 6,7 fresh variables, 6 :=0.1-7
cji (5, X1) = (X2, C)
=CU{7rC7}
(unless 7r = 0, when C = C&apos;)
(6) i. old formula: {i} : xo--(y:{i})
new formula: (x+0)0--(Y+r)
constraints: {0 = {j} c
old formula: {k}:Y 0—(W:0)
1-4 new formula: (Y+a)o— (W+0)
constraints: {a = {k}l±10}
old formula: : Wo—(Z:0)
1-4 new formula: (W-1-7)o—(Z+O)
constraints: {-y = I/165}
iv. old formula: {j}:Z
1-4 new formula: (Z-Efil)
constraints: 0
(7) Ao—B:Av.a B:b
A : a[bfiv]
</equation>
<bodyText confidence="0.99952875">
The previous inference rule (4) modifies to (7),
which is simpler since indexation constraints are now
handled by the separate constraint equations. We
leave implicit the fact that use of the rule involves
unification of the index variables associated with the
two occurrences of &amp;quot;B&amp;quot; (in the standard manner).
The constraint equations for the result of the com-
bination are simply the sum of those for the formulae
combined (as affected by the unification step). For
example, combination of the formulae from (iii) and
(iv) of (6) requires unification of the index set expres-
sions 6 and {j}, yielding the result formula (W+-y)
plus the single constraint equation 7 =
which is obviously satisfiable (with -y = 0,0). A
combination is not allowed if it results in an unsat-
isfiable set of constraints. The modified approach
so neatly moves indexation requirements off into the
constraint equation domain that we shall henceforth
drop all consideration of them, assuming them to be
appropriately managed in the background.
</bodyText>
<page confidence="0.994984">
346
</page>
<bodyText confidence="0.999137818181818">
We can now state a generalised composition rule
as in (8). The inference is marked as [m, n], where
m is the argument position of the `functor&apos; (always
the lefthand premise) that is involved in the com-
bination, and n indicates the number of arguments
inherited from the &apos;argument&apos; (righthand premise).
The notation &amp;quot;0-- Zn...0-- Z1&amp;quot; indicates a sequence of
n arguments, where n may be zero, e.g. the case [1,0]
corresponds precisely to the rule (7). Rule (8) allows
the non-applicative derivation (9) over the formulae
from (6) (c.f. the earlier derivation (3)).
</bodyText>
<equation confidence="0.711587">
Xo-Z„...o- Z1 o-Y,„„_1...0-Yi [m, u1
(9) (i) (ii) (iii) (iv)
Xo-Y Yo-W Wo-Z
At.x(Az.t) Au.yu Av.wv
[1,1]
Xo-W: Au.x(Az.yu)
[1,11
Xo-Z : Av.x(Az.y(wv))
X: x(Az.y(wz))
</equation>
<sectionHeader confidence="0.977687" genericHeader="method">
5 Incremental Derivation
</sectionHeader>
<bodyText confidence="0.999980565217391">
As noted earlier, the relevance of flexible CGs to
incremental processing relates to their ability to
assign highly left-branching analyses to sentences,
so that many initial substrings are treated as in-
terpretable constituents. Although we have adap-
ted the (Hepple, 1996) approach to allow flexibility
in deduction, the applicability of the notion &apos;left-
branching&apos; is not clear since it describes the form
of structures built in proof systems where formu-
lae are placed in a linear order, with combination
dependent on adjacency. Linear deduction meth-
ods, on the other hand, work with unordered collec-
tions of formulae. Of course, the system of labelling
that is in use — where the constraints of the &apos;real&apos;
grammatical logic reside — may well import word
order information that limits combination possibil-
ities, but in designing a general parsing method for
linear categorial formalisms, these constraints must
remain with the labelling system.
This is not to say that there is no order informa-
tion available to be considered in distinguishing in-
cremental and non-incremental analyses. In an in-
cremental processing context, the words of a sen-
tence are delivered to the parser one-by-one, in &apos;left-
to-right&apos; order. Given lexical look-up, there will then
be an &apos;order of delivery&apos; of lexical formulae to the
parser. Consequently, we can characterise an incre-
mental analysis as being one that at any stage in-
cludes the maximal amount of `contentful&apos; combin-
ation of the formulae (and hence also lexical mean-
ings) so far delivered, within the limits of possible
combination that the proof system allows. Note
that we have not in these comments reintroduced
an ordered proof system of the familiar kind by the
back door. In particular, we do not require formu-
lae to combine under any notion of &apos;adjacency&apos;, but
simply &apos;as soon as possible&apos;.
For example, if the order of arrival of the formulae
in (9) were (i,iv)-&lt;(ii)-&lt;(iii) (recall that (i,iv) origin-
ate from the same initial formula, and so must ar-
rive together), then the proof (9) would be an incre-
mental analysis. However, if the order instead was
(ii)-&lt;(iii)-&lt;(i,iv), then (9) would not be incremental,
since at the stage when only (ii) and (iii) had ar-
rived, they could combine (as part of an equivalent
alternative analysis), but are not so combined in (9).
</bodyText>
<sectionHeader confidence="0.9934105" genericHeader="method">
6 Derivational Equivalence,
Dependency Sz Normalisation
</sectionHeader>
<bodyText confidence="0.9999925">
It seems we have achieved our aim of a linear deduc-
tion method that allows incremental analysis quite
easily, i.e. simply by generalising the combina-
tion rule as in (8), having modified indexed formu-
lae using (5). However, without further work, this
&apos;achievement&apos; is of little value, because the result-
ing system will be very computationally expensive
due to the problem of &apos;derivational equivalence&apos; or
&apos;spurious ambiguity&apos;, i.e. the existence of multiple
distinct proofs which assign the same reading. For
example, in addition to the proof (9), we have also
the equivalent proof (10).
</bodyText>
<equation confidence="0.996962428571429">
(10) (i) (ii) (iii) (iv)
Xo-Y Yo-W Wo-Z
At.x(Az.t) Au.yu Av.wv
[1,11
Yo-Z : Av.y(wv)
Y : y(wz)
X: x(Az.y(wz))
</equation>
<bodyText confidence="0.890819181818182">
The solution to this problem involves specifying a
normal form for deductions, and allowing that only
normal form proofs are constructed.4 Our route to
specifying a normal form for proofs exploits a corres-
pondence between proofs and dependency structures.
Dependency grammar (DG) takes as fundamental
&amp;quot;This approach of &apos;normal form parsing&apos; has been
applied to the associative Lambek calculus in (Konig,
1989), (Hepple, 1990), (Hendriks, 1992), and to Combin-
atory Categorial Grammar in (Hepple &amp; Morrill, 1989),
(Eisner, 1996).
</bodyText>
<figure confidence="0.998845333333333">
[1,0]
[1,0]
[1,0]
</figure>
<page confidence="0.992392">
347
</page>
<bodyText confidence="0.999973571428571">
the notions of head and dependent. An analogy is
often drawn between CG and DG based on equating
categorial functors with heads, whereby the argu-
ments sought by a functor are seen as its dependents.
The two approaches have some obvious differences.
Firstly, the argument requirements of a categorial
functor are ordered. Secondly, arguments in CG are
phrasal, whereas in DG dependencies are between
words. However, to identify the dependency rela-
tions entailed by a proof, we may simply ignore argu-
ment ordering, and we can trace through the proof to
identify those initial assumptions (&apos;words&apos;) that are
related as head and dependent by each combination
of the proof. This simple idea unfortunately runs
into complications, due to the presence of higher or-
der functions. For example, in the proof (2), since
the higher order functor&apos;s argument category (i.e.
Yo–Z) has subformuiae corresponding to compon-
ents of both of the other two assumptions, Yo–W
and Wo–Z, it is not clear whether we should view
the higher order functor as having a dependency re-
lation only to the &apos;functionally dominant&apos; assump-
tion Yo–W, i.e. with dependencies as in (11a), or to
both the assumptions Yo–W and Wo–Z, i.e. with
dependencies as perhaps in either (11b) or (11c).
The compilation approach, however, lacks this prob-
lem, since we have only first order formulae, amongst
which the dependencies are clear, e.g. as in (12).
</bodyText>
<equation confidence="0.983693">
r
Xo–(Yo–Z) Yo–W Wo–Z
•Xo–(Yo–Z) Yo–W Wo–Z
(7Th rTh,
Xo–(Yo–Z) Yo–W Wo–Z
r
Xo–Y Yo–W Wo–Z Z
</equation>
<bodyText confidence="0.999758333333333">
Some preliminaries. We assume that proof as-
sumptions explicitly record &apos;order of delivery&apos; in-
formation, marked by a natural number, and so take
</bodyText>
<listItem confidence="0.719656">
the form:
— [a]
</listItem>
<equation confidence="0.682783">
X
</equation>
<bodyText confidence="0.984774833333333">
Further, we require the ordering to go beyond simple
&apos;order of delivery&apos; in relatively ordering first order as-
sumptions that derive from the same original higher-
order formula. (This move simply introduces some
extra arbitrary bias as a basis for distinguishing
proofs.) It is convenient to have a &apos;linear&apos; nota-
tion for writing proofs. We will write (n/ X [a])
for an assumption (such as that just shown), and
(X Y / Z [m,n]) for a combination of subproofs X
and Y to give result formula Z by inference [m, n].
(13) dep((X Y / Z [m,n])) = {(i, j,k)}
where gov(m, X) = (i, k), fun(Y) = j
</bodyText>
<equation confidence="0.845999">
(14) dep*((n/X [a])) = 0
dep*((X Y / Z [m,n]))
= {6} U dep*(X) U dep*(Y)
</equation>
<bodyText confidence="0.991050625">
where 6 = dep((X Y / Z [m,n]))
The procedure dep, defined in (13), identifies the
dependency relation established by any combina-
tion, i.e. for any subproof P = (X Y / Z [m,n]),
dep(P) returns a triple (i, j, k), where i, j identify
the head and dependent assumptions for the com-
bination, and k indicates the argument position of
the head assumption that is involved (which has
now been inherited to be argument m of the functor
of the combination). The procedure dep*, defined
in (14), returns the set of dependencies established
within a subproof. Note that dep employs the pro-
cedures gov (which traces the relevant argument
back to its source assumption the head) and fun
(which finds the functionally dominant assumption
within the argument subproof the dependent).
</bodyText>
<listItem confidence="0.436733">
(15) gov(i, (n/ X [a])) = (n,i)
</listItem>
<bodyText confidence="0.90958">
gov(i, (X Y / Z [m,n])) = gov((i – m + 1), Y)
where m &lt;i &lt; (m + n)
gov(i, (X Y / Z [m, n])) = gov(i, X)
where i &lt;m
gov(i, (X Y / Z [m, n])) = gov((i – n + 1), X)
where (m + n) &lt;i
</bodyText>
<equation confidence="0.9744545">
(16) fun ((n/X [a])) = n
fun((X Y / Z [m,n])) = fun(X)
</equation>
<bodyText confidence="0.999813">
From earlier discussion, it should be clear that an
&apos;incremental analysis&apos; is one in which any depend-
ency to be established is established as soon as pos-
sible in terms of the order of delivery of assumptions.
The relation &lt;&lt; of (17) orders dependencies in terms
of which can be established earlier on, i.e. 6 &lt;&lt; -y if
the later-arriving assumption of 6 arrives before the
later-arriving assumption of -y. Note however that
6, -y may have the same later arriving assumption
(i.e. if this assumption is involved in more than one
dependency). In this case, &lt;&lt; arbitrarily gives pre-
cedence to the dependency whose two assumptions
occur closer together in delivery order.
</bodyText>
<page confidence="0.98972">
348
</page>
<listItem confidence="0.26985375">
(17) 6 &lt;&lt;y (where 6 = (i, j, k) ,-y = (x , y , z))
if (max(i, j) &lt; max(x, y) V
(max(i, j) = max(x, y) A
min(i, j) &gt; min(x,y)))
</listItem>
<bodyText confidence="0.999943583333333">
We can use &lt;&lt; to define an incremental normal
form for proofs, i.e. an incremental proof is one
that is well-ordered with respect to &lt;&lt; in the sense
that every combination (X Y / Z [m, n]) within it
establishes a dependency 6 which follows under &lt;&lt;
every dependency 6&apos; established within the sub-
proofs X and Y it combines, i.e. 6&apos; &lt;&lt; 6 for each
6&apos; E dep*(X) U dep*(Y). This normal form is useful
only if we can show that every proof has an equi-
valent normal form. For present purposes, we can
take two proofs to be equivalent if they establish
identical sets of dependency relations.5
</bodyText>
<equation confidence="0.993004076923077">
(18) trace(i, j, (i/X [a])) = j
trace(i, j, (X Y / Z [m, n])) = (m + k — 1)
where i E assum(Y)
trace(i, j, Y) = k
trace(i, j, (X Y / Z [m, n])) = k
where i E assum(X)
trace(i, j, X) = k, k &lt; m
trace(i, j, (X Y / Z [m, n])) = (k + n —1)
where i E assum(X)
trace(i, j, X) = k, k &gt; m
(19) assum((i/X [a])) = {i}
assum((X Y / Z [m, n]))
= assum(X) U assum(Y)
</equation>
<bodyText confidence="0.987100418604651">
We can specify a method such that given a set
of dependency relations D we can construct a cor-
responding proof. The process works with a set of
subproofs P, which are initially just the set of as-
sumptions (i.e. each of the form (n I F [a])), and
proceeds by combining pairs of subproofs together,
until finally just a single proof remains. Each step
involves selecting a dependency 5 (6 = (i , j , k)) from
D (setting D := D — {6} for subsequent purposes),
removing the subproofs P, Q from P which contain
the assumptions i, j (respectively), combining P, Q
(with P as functor) to give a new subproof R which
5This criterion turns out to be equivalent to one
stated in terms of the lambda terms that proofs generate,
i.e. two proofs will yield identical sets of dependency re-
lations if they yield proof terms that are i-equivalent.
This observation should not be surprising, since the set
of &apos;dependency relations&apos; returned for a proof is in es-
sence just a rather unstructured summary of its func-
tional relations.
is added to P (i.e. P := (P — {P, Q}) U {R}). It is
important to get the right value for in in the combin-
ation [in, it] used to combine P, Q, so that the correct
argument of the assumption i (as now inherited to
the end-type of P) is involved. This value is given
by m = trace(i, k, P) (with trace as defined in (18)).
The process of proof construction is nondetermin-
istic, in the order of selection of dependencies for in-
corporation, and so a single set of dependences can
yield multiple distinct, but equivalent, proofs (as we
would expect).
To build normal form proofs, we only need to limit
the order of selection of dependencies using &lt;&lt;, i.e.
requiring that the minimal element under &lt;&lt; is se-
lected at each stage. Note that this ordering restric-
tion makes the selection process deterministic, from
which it follows that normal forms are unique. Put-
ting the above methods together, we have a complete
normal form method for proofs of the first-order lin-
ear deduction system, i.e. for any proof P, we can
extract its dependency relations and use these to
construct a unique, maximally incremental, altern-
ative proof — the normal form of P.
</bodyText>
<sectionHeader confidence="0.5958985" genericHeader="method">
7 Proof Reduction and
Normalisation
</sectionHeader>
<bodyText confidence="0.99986862962963">
The above normalisation approach is somewhat non-
standard. We shall next briefly sketch how normal-
isation could instead be handled via the standard
method of proof reduction. This method involves
defining a contraction relation (c&gt;1) between proofs,
which is typically stated as a number of contraction
rules of the form X &gt;1 Y, where X is termed a redex
and Y its contractum. Each rule allows that a proof
containing a redex be transformed into one where
that occurrence is replaced by its contractum. A
proof is in normal form if it contains no redexes.
The contraction relation generates a reduction rela-
tion (c&gt;) such that X reduces to Y (X I&gt; Y) if Y is
obtained from X by a finite series (possibly zero) of
contractions. A term Y is a normal form of X if Y
is a normal form and X i&gt; Y.
We again require the ordering relation &lt;&lt; defined
in (17). A redex is any subproof whose final step
is a combination of two well-ordered subproofs,
which establishes a dependency that undermines
well-orderedness. A contraction step modifies the
proof to swap this final combination with the final
one of an immediate subproof, so that the depend-
encies the two combinations establish are now ap-
propriately ordered with respect to each other. The
possibilities for reordering combination steps divide
into four cases, which are shown in Figure 1. This re-
</bodyText>
<page confidence="0.992058">
349
</page>
<figure confidence="0.97850324137931">
X Y where s &lt; m X Z
[m, n] [s, t]
V V&apos;
[(m + t — 1),n]
[8, t]
X Y where M &lt; S
[m, n]
V
[s, t]
s&lt; (m + n)
X Y
n]
V
W
X Y Z X Y Z
[m, n] [s, (t — n + 1)]
V D V&apos;
[s, t]
W W
[s, t]
where s &gt; ern + n)
X Y Z
[(s m+ 1), t]
V&apos;
[m, (n + t — 1)]
X Z
V&apos;
[(m+ s — 1),n]
[m, n]
</figure>
<figureCaption confidence="0.99965">
Figure I: Local Reordering of Combination Steps: the four cases
</figureCaption>
<bodyText confidence="0.9992925">
duction system can be shown to exhibit the property
(called strong normalisation) that every reduction is
finite, from which it follows that every proof has a
normal form.6
</bodyText>
<sectionHeader confidence="0.96258" genericHeader="method">
8 Normal form parsing
</sectionHeader>
<bodyText confidence="0.999959714285714">
The technique of normal form parsing involves en-
suring that only normal form proofs are construc-
ted by the parser, avoiding the unnecessary work
of building all the non-normal form proofs. At any
stage, all subproofs so far constructed are in normal
form, and the result of any combination is admitted
only provided it is in normal form, otherwise it is
discarded. The result of a combination is recognised
as non-normal form if it establishes a dependency
that is out of order with respect to that of the fi-
nal combination of at least one of the two subproofs
combined (which is an adequate criterion since the
subproofs are well-ordered). The procedures defined
above can be used to identify these dependencies.
</bodyText>
<sectionHeader confidence="0.989898" genericHeader="method">
9 The Degree of Incrementality
</sectionHeader>
<bodyText confidence="0.998941617021277">
Let us next consider the degree of incrementality
that the above system allows, and the sense in which
6To prove strong normalisation, it is sufficient to give
a metric which assigns to each proof a finite non-negative
integer score, and under which every contraction reduces
a proof&apos;s score by a non-zero amount. The following
metric it can be shown to suffice: (a) for P = (n/ X [a]),
it(P) = 0, (b) for P = (X Y / Z [m, n]), whose final
step establishes a dependency 6, it(P) = pt(X)+ it(Y)±
D, where D is the number of dependencies 6&apos; such that
&lt;&lt;5&apos;, which are established in X and Y, i.e. D= lAi
where A = {5&apos; I E dep*(X) u dep*(Y) A 6 &lt;&lt;5&apos;}.
it might be considered maximal. Clearly, the system
does not allow full &apos;word-by-word&apos; incrementality,
i.e. where the words that have been delivered at any
stage in incremental processing are combined to give
a single result formula, with combinations to incor-
porate each new lexical formula as it arrives.7 For
example, in incremental processing of Today John
sang, the first two words might yield (after compil-
ation) the first-order formulae so—s and np, which
will not combine under the rule (8).8
Instead, the above system will allow precisely
those combinations that establish functional rela-
tions that are marked out in lexical type structure
(i.e. subcategorisation), which, given the parallel-
ism of syntax and semantics, corresponds to allow-
ing those combinations that establish semantically
relevant functional relations amongst lexical mean-
ings. Thus, we believe the above system to exhibit
maximal incrementality in relation to allowing &apos;se-
mantically contentful&apos; combinations. In dependency
terms, the system allows any set of initial formulae
to combine to a single result if they form a con-
nected graph under the dependency relations that
obtain amongst them.
Note that the extent of incrementality allowed by
using &apos;generalised composition&apos; in the compiled first-
order system should not be equated with that which
7For an example of a system allowing word-by-word
incrementality, see (Milward, 1995).
81Vote that this is not to say that the system is un-
able to combine these two types, e.g. a combination
so—s, np so—(so—np) is derivable, with appropriate
compilation. The point rather is that such a combina-
tion will typically not happen as a component in a proof
of some other overall deduction.
</bodyText>
<page confidence="0.986184">
350
</page>
<bodyText confidence="0.984035166666667">
would be allowed by such a rule in the original (non-
compiled) system. We can illustrate this point using
the following type combination, which is not an in-
stance of even &apos;generalised&apos; composition.
X0-(Yo-Z), Yo-W = X0-(Wo-Z)
Compilation of the higher-order assumption would
yield Xo-Y plus Z, of which the first formula can
compose with the second assumption Yo-W to give
Xo-W, thereby achieving some semantically con-
tentful combination of their associated meanings,
which would not be allowed by composition over the
original formulae.9
</bodyText>
<sectionHeader confidence="0.997162" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.9999405">
We have shown how the linear categorial deduction
method of (Hepple, 1996) can be modified to allow
incremental derivation, and specified an incremental
normal form for proofs of the system. These results
provide for an efficient incremental linear deduction
method that can be used with various labelling dis-
ciplines as a basis for parsing a range of type-logical
formalisms.
</bodyText>
<sectionHeader confidence="0.998802" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988834295774648">
Jason Eisner 1996. &apos;Efficient Normal-Form Parsing
for Combinatory Categorial Grammar.&apos; Proc. of
ACL-34.
Dov M. Gabbay. 1996. Labelled deductive systems.
Volume 1. Oxford University Press.
Herman Hendriks. 1992. &apos;Lambek Semantics: nor-
malisation, spurious ambiguity, partial deduction
and proof nets&apos;, Proc, of Eighth Amsterdam Col-
loquium, ILLI, University of Amsterdam.
Mark Hepple. 1990. &apos;Normal form theorem proving
for the Lambek calculus&apos;. Proc. of COLING-90.
Mark Hepple. 1992. Chart Parsing Lambek Gram-
mars: Modal Extensions and Incrementality&apos;,
Proc, of COLING-92.
Mark Hepple. 1995. `Mixing Modes of Linguistic
Description in Categorial Grammar&apos;. Proceedings
EACL-7, Dublin.
Mark Hepple. 1996. &apos;A Compilation-Chart Method
for Linear Categorial Deduction&apos;. Proc. of
COLING-96, Copenhagen.
&apos;This combination corresponds to what in a direc-
tional system Wittenburg (1987) has termed a &apos;predict-
ive combinator&apos;, e.g. such as X/(Y/Z), Y/W r W/Z.
Indeed, the semantic result for the combination in the
first-order system corresponds closely to that which
would be produced under Wittenburg&apos;s rule.
Mark Hepple &amp; Glyn Morrill. 1989. &apos;Parsing and
derivational equivalence.&apos; Proc. of EACL-4.
Esther Konig. 1989. &apos;Parsing as natural deduction&apos;.
Proc. of ACL-27.
Esther Konig. 1990. &apos;The complexity of pars-
ing with extended categorial grammars&apos; Proc. of
COLING-90.
Esther K8nig. 1994. &apos;A Hypothetical Reasoning Al-
gorithm for Linguistic Analysis.&apos; Journal of Logic
and Computation, Vol. 4, No 1, pp1-19.
Joachim Lambek. 1958. &apos;The mathematics of
sentence structure.&apos; American Mathematical
Monthly, 65, pp154-170.
Joachim Lambek. 1961. &apos;On the calculus of syn-
tactic types.&apos; R. Jakobson (Ed), Structure of
Language and its Mathematical Aspects, Proceed-
ings of the Symposia in Applied Mathematics XII,
American Mathematical Society.
David Milward. 1995. &apos;Incremental Interpretation
of Categorial Grammar.&apos; Proceedings EA CL-?&apos;,
Dublin.
Michael Moortgat. 1992. `Labelled deductive sys-
tems for categorial theorem proving&apos;. Proc. of
Eighth Amsterdam Colloquium, ILLI, University
of Amsterdam.
Michael Moortgat &amp; Richard T. Oehrle. 1994. &apos;Ad-
jacency, dependency and order&apos;. Proc. of Ninth
Amsterdam Colloquium.
Michael Moortgat &amp; Glyn Morrill. 1991. &apos;Heads
and Phrases: Type Calculus for Dependency and
Constituency.&apos; To appear: Journal of Language,
Logic and Information.
Glyn Morrill. 1994. Type Logical Grammar: Cat-
egorial Logic of Signs. Kluwer Academic Publish-
ers, Dordrecht.
Glyn Morrill. 1995. &apos;Higher-order Linear Logic
Programming of Categorial Deduction&apos;. Proc. of
EACL-7, Dublin.
Mark J. Steedman. 1989. &apos;Grammar, interpreta-
tion and processing from the lexicon.&apos; In Marslen-
Wilson, W. (Ed), Lexical Representation and Pro-
cess, MIT Press, Cambridge, MA.
Kent Wittenburg. 1987. &apos;Predictive Combinators:
A method for efficient parsing of Combinatory
Categorial Grammars.&apos; Proc. of ACL-25.
</reference>
<page confidence="0.998668">
351
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.281803">
<title confidence="0.999921">Maximal Incrementality in Linear Categorial Deduction</title>
<author confidence="0.999965">Mark Hepple</author>
<affiliation confidence="0.9998895">Dept. of Computer Science University of Sheffield</affiliation>
<address confidence="0.7848485">Regent Court, Portobello Street Sheffield Si 4DP, UK</address>
<email confidence="0.997089">hepple@dcs.shef.ac.uk</email>
<abstract confidence="0.975884095238095">Recent work has seen the emergence of a common framework for parsing categorial grammar (CG) formalisms that fall within the &apos;type-logical&apos; tradition (such as the Lambek calculus and related systems), whereby some method of linear logic theorem proving is used in combination with a system of labelling that ensures only deductions appropriate to the relevant grammatical logic are allowed. The approaches realising this framework, however, have not so far addressed the task of incremental parsing — a key issue in earlier work with &apos;flexible&apos; categorial grammars. In this paper, the approach of (Hepple, 1996) is modified to yield a linear deduction system that does allow flexible deduction and hence incremental processing, but that hence also suffers the problem of &apos;spurious ambiguity&apos;. This problem is avoided via normalisation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jason Eisner</author>
</authors>
<title>Efficient Normal-Form Parsing for Combinatory Categorial Grammar.&apos;</title>
<date>1996</date>
<booktitle>Proc. of ACL-34.</booktitle>
<contexts>
<context position="17259" citStr="Eisner, 1996" startWordPosition="2785" endWordPosition="2786">) Xo-Y Yo-W Wo-Z At.x(Az.t) Au.yu Av.wv [1,11 Yo-Z : Av.y(wv) Y : y(wz) X: x(Az.y(wz)) The solution to this problem involves specifying a normal form for deductions, and allowing that only normal form proofs are constructed.4 Our route to specifying a normal form for proofs exploits a correspondence between proofs and dependency structures. Dependency grammar (DG) takes as fundamental &amp;quot;This approach of &apos;normal form parsing&apos; has been applied to the associative Lambek calculus in (Konig, 1989), (Hepple, 1990), (Hendriks, 1992), and to Combinatory Categorial Grammar in (Hepple &amp; Morrill, 1989), (Eisner, 1996). [1,0] [1,0] [1,0] 347 the notions of head and dependent. An analogy is often drawn between CG and DG based on equating categorial functors with heads, whereby the arguments sought by a functor are seen as its dependents. The two approaches have some obvious differences. Firstly, the argument requirements of a categorial functor are ordered. Secondly, arguments in CG are phrasal, whereas in DG dependencies are between words. However, to identify the dependency relations entailed by a proof, we may simply ignore argument ordering, and we can trace through the proof to identify those initial as</context>
</contexts>
<marker>Eisner, 1996</marker>
<rawString>Jason Eisner 1996. &apos;Efficient Normal-Form Parsing for Combinatory Categorial Grammar.&apos; Proc. of ACL-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dov M Gabbay</author>
</authors>
<title>Labelled deductive systems. Volume 1.</title>
<date>1996</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="2280" citStr="Gabbay, 1996" startWordPosition="338" endWordPosition="339">at fall within the &apos;type-logical&apos; 1Within the categorial field, the significance of incrementality has been emphasised most notably in the work of Steedman, e.g. (Steedman, 1989). tradition, whose most familiar representative is the associative Lambek calculus (Lambek, 1958). Recent work has seen proposals for a range of such systems, differing in their resource sensitivity (and hence, implicitly, their underlying notion of &apos;linguistic structure&apos;), in some cases combining differing resource sensitivities in one system.&apos; Many of these proposals employ a &apos;labelled deductive system&apos; methodology (Gabbay, 1996), whereby types in proofs are associated with labels which record proof information for use in ensuring correct inferencing. A common framework is emerging for parsing type-logical formalisms, which exploits the labelled deduction idea. Approaches within this framework employ a theorem proving method that is appropriate for use with linear logic, and combine it with a labelling system that restricts admitted deductions to be those of a weaker system. Crucially, linear logic stands above all of the type-logical formalisms proposed in the hierarchy of substructural logics, and hence linear logic</context>
</contexts>
<marker>Gabbay, 1996</marker>
<rawString>Dov M. Gabbay. 1996. Labelled deductive systems. Volume 1. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herman Hendriks</author>
</authors>
<title>Lambek Semantics: normalisation, spurious ambiguity, partial deduction and proof nets&apos;,</title>
<date>1992</date>
<booktitle>Proc, of Eighth Amsterdam Colloquium, ILLI,</booktitle>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="17176" citStr="Hendriks, 1992" startWordPosition="2772" endWordPosition="2773">ion to the proof (9), we have also the equivalent proof (10). (10) (i) (ii) (iii) (iv) Xo-Y Yo-W Wo-Z At.x(Az.t) Au.yu Av.wv [1,11 Yo-Z : Av.y(wv) Y : y(wz) X: x(Az.y(wz)) The solution to this problem involves specifying a normal form for deductions, and allowing that only normal form proofs are constructed.4 Our route to specifying a normal form for proofs exploits a correspondence between proofs and dependency structures. Dependency grammar (DG) takes as fundamental &amp;quot;This approach of &apos;normal form parsing&apos; has been applied to the associative Lambek calculus in (Konig, 1989), (Hepple, 1990), (Hendriks, 1992), and to Combinatory Categorial Grammar in (Hepple &amp; Morrill, 1989), (Eisner, 1996). [1,0] [1,0] [1,0] 347 the notions of head and dependent. An analogy is often drawn between CG and DG based on equating categorial functors with heads, whereby the arguments sought by a functor are seen as its dependents. The two approaches have some obvious differences. Firstly, the argument requirements of a categorial functor are ordered. Secondly, arguments in CG are phrasal, whereas in DG dependencies are between words. However, to identify the dependency relations entailed by a proof, we may simply ignore</context>
</contexts>
<marker>Hendriks, 1992</marker>
<rawString>Herman Hendriks. 1992. &apos;Lambek Semantics: normalisation, spurious ambiguity, partial deduction and proof nets&apos;, Proc, of Eighth Amsterdam Colloquium, ILLI, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
</authors>
<title>Normal form theorem proving for the Lambek calculus&apos;.</title>
<date>1990</date>
<booktitle>Proc. of COLING-90.</booktitle>
<contexts>
<context position="17158" citStr="Hepple, 1990" startWordPosition="2770" endWordPosition="2771">xample, in addition to the proof (9), we have also the equivalent proof (10). (10) (i) (ii) (iii) (iv) Xo-Y Yo-W Wo-Z At.x(Az.t) Au.yu Av.wv [1,11 Yo-Z : Av.y(wv) Y : y(wz) X: x(Az.y(wz)) The solution to this problem involves specifying a normal form for deductions, and allowing that only normal form proofs are constructed.4 Our route to specifying a normal form for proofs exploits a correspondence between proofs and dependency structures. Dependency grammar (DG) takes as fundamental &amp;quot;This approach of &apos;normal form parsing&apos; has been applied to the associative Lambek calculus in (Konig, 1989), (Hepple, 1990), (Hendriks, 1992), and to Combinatory Categorial Grammar in (Hepple &amp; Morrill, 1989), (Eisner, 1996). [1,0] [1,0] [1,0] 347 the notions of head and dependent. An analogy is often drawn between CG and DG based on equating categorial functors with heads, whereby the arguments sought by a functor are seen as its dependents. The two approaches have some obvious differences. Firstly, the argument requirements of a categorial functor are ordered. Secondly, arguments in CG are phrasal, whereas in DG dependencies are between words. However, to identify the dependency relations entailed by a proof, we</context>
</contexts>
<marker>Hepple, 1990</marker>
<rawString>Mark Hepple. 1990. &apos;Normal form theorem proving for the Lambek calculus&apos;. Proc. of COLING-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
</authors>
<title>Chart Parsing Lambek Grammars: Modal Extensions and Incrementality&apos;,</title>
<date>1992</date>
<booktitle>Proc, of COLING-92.</booktitle>
<contexts>
<context position="8315" citStr="Hepple (1992)" startWordPosition="1300" endWordPosition="1301">duction method which, like chart parsing for phrase-structure grammar, avoids the need to recompute intermediate results when searching exhaustively for all possible analyses, i.e. where any combination of types contributes to more than one overall analysis, it need only be computed once. The incremental system to be developed in this paper is similarly compatible with a &apos;chart-like&apos; processing approach, although this issue will not be further addressed within this paper. For earlier work on chart-parsing type-logical formalisms, specifically the associative Lambek calculus, see K8nig (1990), Hepple (1992), KOnig (1994). [B: v] A : a o-I 345 identifier for that assumption. The index sets of a derived formula identify precisely those assumptions from which it is derived. The rule (4) ensures appropriate indexation, i.e. via the condition 7r = where W stands for disjoint union (ensuring linear usage). The common origin of assumptions (i) and (iv) (i.e. from Xo— (Yo—Z)) is recorded by the fact that (i)&apos;s argument is marked with (iv)&apos;s index (j). The condition a C &apos;0 of (4) ensures that (iv) must contribute to the derivation of (i)&apos;s argument (which is needed to ensure correct inferencing). Finally</context>
</contexts>
<marker>Hepple, 1992</marker>
<rawString>Mark Hepple. 1992. Chart Parsing Lambek Grammars: Modal Extensions and Incrementality&apos;, Proc, of COLING-92.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
</authors>
<title>Mixing Modes of Linguistic Description in Categorial Grammar&apos;.</title>
<date>1995</date>
<booktitle>Proceedings EACL-7,</booktitle>
<location>Dublin.</location>
<contexts>
<context position="3836" citStr="Hepple, 1995" startWordPosition="572" endWordPosition="573">duction implemented via a version of SLD resolution. Hepple (1996) introduces a linear deduction method, involving compilation to first order formulae, which can be combined with various labelling disciplines. These approaches, however, are not directed toward incremental processing. In what follows, we show how the method of (Hepple, 1996) can be modified to allow processing which has a high degree of incrementality. These modifications, however, give a system which suffers 2See, for example, the formalisms developed in (Moortgat &amp; Morrill, 1991), (Moortgat &amp; Oehrle, 1994), (Morrill, 1994), (Hepple, 1995). 344 the problem of &apos;derivational equivalence&apos;, also called &apos;spurious ambiguity&apos;, i.e. allowing multiple proofs which assign the same reading for some combination, a fact which threatens processing efficiency. We show how this problem is solved via normalisation. 2 Implicational Linear Logic Linear logic is an example of a &amp;quot;resource-sensitive&amp;quot; logic, requiring that each assumption (&apos;resource&apos;) is used precisely once in any deduction. For the implicational fragment, the set of formulae .7- are defined by .7&amp;quot; ::= A I o— .7. (with A a nonempty set of atomic types). A natural deduction formulatio</context>
</contexts>
<marker>Hepple, 1995</marker>
<rawString>Mark Hepple. 1995. `Mixing Modes of Linguistic Description in Categorial Grammar&apos;. Proceedings EACL-7, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
</authors>
<title>A Compilation-Chart Method for Linear Categorial Deduction&apos;.</title>
<date>1996</date>
<booktitle>Proc. of COLING-96,</booktitle>
<location>Copenhagen.</location>
<contexts>
<context position="811" citStr="Hepple, 1996" startWordPosition="121" endWordPosition="122">t Recent work has seen the emergence of a common framework for parsing categorial grammar (CG) formalisms that fall within the &apos;type-logical&apos; tradition (such as the Lambek calculus and related systems), whereby some method of linear logic theorem proving is used in combination with a system of labelling that ensures only deductions appropriate to the relevant grammatical logic are allowed. The approaches realising this framework, however, have not so far addressed the task of incremental parsing — a key issue in earlier work with &apos;flexible&apos; categorial grammars. In this paper, the approach of (Hepple, 1996) is modified to yield a linear deduction system that does allow flexible deduction and hence incremental processing, but that hence also suffers the problem of &apos;spurious ambiguity&apos;. This problem is avoided via normalisation. 1 Introduction A key attraction of the class of formalisms known as &apos;flexible&apos; categorial grammars is their compatibility with an incremental style of processing, in allowing sentences to be assigned analyses that are fully or primarily left-branching. Such analyses designate many initial substrings of a sentence as interpretable constituents, allowing its interpretation t</context>
<context position="3289" citStr="Hepple (1996)" startWordPosition="490" endWordPosition="491">tricts admitted deductions to be those of a weaker system. Crucially, linear logic stands above all of the type-logical formalisms proposed in the hierarchy of substructural logics, and hence linear logic deduction methods can provide a common basis for parsing all of these systems. For example, Moortgat (1992) combines a linear proof net method with labelling to provide deduction for several categorial systems. Morrill (1995) shows how types of the associative Lambek calculus may be translated to labelled implicational linear types, with deduction implemented via a version of SLD resolution. Hepple (1996) introduces a linear deduction method, involving compilation to first order formulae, which can be combined with various labelling disciplines. These approaches, however, are not directed toward incremental processing. In what follows, we show how the method of (Hepple, 1996) can be modified to allow processing which has a high degree of incrementality. These modifications, however, give a system which suffers 2See, for example, the formalisms developed in (Moortgat &amp; Morrill, 1991), (Moortgat &amp; Oehrle, 1994), (Morrill, 1994), (Hepple, 1995). 344 the problem of &apos;derivational equivalence&apos;, also</context>
<context position="6081" citStr="Hepple (1996)" startWordPosition="921" endWordPosition="922">ambek calculus (Lambek, 1961) sets the further requirement that types combine under some fixed initial bracketting. Such weaker systems can be implemented by combining implicational linear logic with a labelling system whose labels are structured objects that record relevant resource information, i.e. of sequencing and/or bracketting, and then using this information in restricting permitted inferences to only those that satisfy the resource requirements of the weaker logic. 3 First-order Compilation The first-order formulae are those with only atomic argument types (i.e. ..F ::= A I .Tc-- A). Hepple (1996) shows how deductions in implicational linear logic can be recast as deductions involving only first-order formulae.3 The method involves compiling the original formulae to indexed first-order formulae, where a higher-order initial formula yields multiple compiled formulae, e.g. (omitting indices) Xo— (Yo— Z) would yield Xo—Y and Z, i.e. with the subformula relevant to hypothetical reasoning (Z) effectively excised from the initial formulae, to be treated as a separate assumption, leaving a first-order residue. Indexing is used in ensuring general linear use of resources, but also notably to e</context>
<context position="9613" citStr="Hepple, 1996" startWordPosition="1518" endWordPosition="1519">by direct substitution for the variable of a lambda expression, employing a special variant of substitution, notated _L/L1 (e.g. t[sfiv] to indicate substitution of s for v in t), which specifically does not act to avoid accidental binding. In the final inference of (3), this method allows the variable z to fall within the scope of an abstraction over z, and so become bound. Recall that introduction inferences of the original formulation are associated with abstraction steps. In this approach, these inferences are no longer required, their effects having been compiled into the semantics. See (Hepple, 1996) for more details, including a precise statement of the compilation procedure. 4 Flexible Deduction The approach just outlined is unsuited to incremental processing. Its single inference rule allows only a rigid style of combining formulae, where order of combination is completely determined by the argument order of functors. The formulae of (3), for example, must combine precisely as shown. It is not possible, say, to combine assumptions (i) and (ii) together first as part of a derivation. To overcome this limitation, we might generalise the combination rule to allow composition of functions,</context>
<context position="13942" citStr="Hepple, 1996" startWordPosition="2246" endWordPosition="2247">rresponds precisely to the rule (7). Rule (8) allows the non-applicative derivation (9) over the formulae from (6) (c.f. the earlier derivation (3)). Xo-Z„...o- Z1 o-Y,„„_1...0-Yi [m, u1 (9) (i) (ii) (iii) (iv) Xo-Y Yo-W Wo-Z At.x(Az.t) Au.yu Av.wv [1,1] Xo-W: Au.x(Az.yu) [1,11 Xo-Z : Av.x(Az.y(wv)) X: x(Az.y(wz)) 5 Incremental Derivation As noted earlier, the relevance of flexible CGs to incremental processing relates to their ability to assign highly left-branching analyses to sentences, so that many initial substrings are treated as interpretable constituents. Although we have adapted the (Hepple, 1996) approach to allow flexibility in deduction, the applicability of the notion &apos;leftbranching&apos; is not clear since it describes the form of structures built in proof systems where formulae are placed in a linear order, with combination dependent on adjacency. Linear deduction methods, on the other hand, work with unordered collections of formulae. Of course, the system of labelling that is in use — where the constraints of the &apos;real&apos; grammatical logic reside — may well import word order information that limits combination possibilities, but in designing a general parsing method for linear categor</context>
</contexts>
<marker>Hepple, 1996</marker>
<rawString>Mark Hepple. 1996. &apos;A Compilation-Chart Method for Linear Categorial Deduction&apos;. Proc. of COLING-96, Copenhagen.</rawString>
</citation>
<citation valid="true">
<title>This combination corresponds to what in a directional system Wittenburg</title>
<date>1987</date>
<marker>1987</marker>
<rawString>&apos;This combination corresponds to what in a directional system Wittenburg (1987) has termed a &apos;predictive combinator&apos;, e.g. such as X/(Y/Z), Y/W r W/Z. Indeed, the semantic result for the combination in the first-order system corresponds closely to that which would be produced under Wittenburg&apos;s rule.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark Hepple</author>
<author>Glyn Morrill</author>
</authors>
<title>Parsing and derivational equivalence.&apos;</title>
<date>1989</date>
<booktitle>Proc. of EACL-4.</booktitle>
<contexts>
<context position="17243" citStr="Hepple &amp; Morrill, 1989" startWordPosition="2781" endWordPosition="2784">). (10) (i) (ii) (iii) (iv) Xo-Y Yo-W Wo-Z At.x(Az.t) Au.yu Av.wv [1,11 Yo-Z : Av.y(wv) Y : y(wz) X: x(Az.y(wz)) The solution to this problem involves specifying a normal form for deductions, and allowing that only normal form proofs are constructed.4 Our route to specifying a normal form for proofs exploits a correspondence between proofs and dependency structures. Dependency grammar (DG) takes as fundamental &amp;quot;This approach of &apos;normal form parsing&apos; has been applied to the associative Lambek calculus in (Konig, 1989), (Hepple, 1990), (Hendriks, 1992), and to Combinatory Categorial Grammar in (Hepple &amp; Morrill, 1989), (Eisner, 1996). [1,0] [1,0] [1,0] 347 the notions of head and dependent. An analogy is often drawn between CG and DG based on equating categorial functors with heads, whereby the arguments sought by a functor are seen as its dependents. The two approaches have some obvious differences. Firstly, the argument requirements of a categorial functor are ordered. Secondly, arguments in CG are phrasal, whereas in DG dependencies are between words. However, to identify the dependency relations entailed by a proof, we may simply ignore argument ordering, and we can trace through the proof to identify </context>
</contexts>
<marker>Hepple, Morrill, 1989</marker>
<rawString>Mark Hepple &amp; Glyn Morrill. 1989. &apos;Parsing and derivational equivalence.&apos; Proc. of EACL-4.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esther Konig</author>
</authors>
<title>Parsing as natural deduction&apos;.</title>
<date>1989</date>
<booktitle>Proc. of ACL-27.</booktitle>
<contexts>
<context position="17142" citStr="Konig, 1989" startWordPosition="2768" endWordPosition="2769"> reading. For example, in addition to the proof (9), we have also the equivalent proof (10). (10) (i) (ii) (iii) (iv) Xo-Y Yo-W Wo-Z At.x(Az.t) Au.yu Av.wv [1,11 Yo-Z : Av.y(wv) Y : y(wz) X: x(Az.y(wz)) The solution to this problem involves specifying a normal form for deductions, and allowing that only normal form proofs are constructed.4 Our route to specifying a normal form for proofs exploits a correspondence between proofs and dependency structures. Dependency grammar (DG) takes as fundamental &amp;quot;This approach of &apos;normal form parsing&apos; has been applied to the associative Lambek calculus in (Konig, 1989), (Hepple, 1990), (Hendriks, 1992), and to Combinatory Categorial Grammar in (Hepple &amp; Morrill, 1989), (Eisner, 1996). [1,0] [1,0] [1,0] 347 the notions of head and dependent. An analogy is often drawn between CG and DG based on equating categorial functors with heads, whereby the arguments sought by a functor are seen as its dependents. The two approaches have some obvious differences. Firstly, the argument requirements of a categorial functor are ordered. Secondly, arguments in CG are phrasal, whereas in DG dependencies are between words. However, to identify the dependency relations entaile</context>
</contexts>
<marker>Konig, 1989</marker>
<rawString>Esther Konig. 1989. &apos;Parsing as natural deduction&apos;. Proc. of ACL-27.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esther Konig</author>
</authors>
<title>The complexity of parsing with extended categorial grammars&apos;</title>
<date>1990</date>
<booktitle>Proc. of COLING-90.</booktitle>
<marker>Konig, 1990</marker>
<rawString>Esther Konig. 1990. &apos;The complexity of parsing with extended categorial grammars&apos; Proc. of COLING-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esther K8nig</author>
</authors>
<title>A Hypothetical Reasoning Algorithm for Linguistic Analysis.&apos;</title>
<date>1994</date>
<journal>Journal of Logic and Computation,</journal>
<volume>4</volume>
<pages>1--19</pages>
<marker>K8nig, 1994</marker>
<rawString>Esther K8nig. 1994. &apos;A Hypothetical Reasoning Algorithm for Linguistic Analysis.&apos; Journal of Logic and Computation, Vol. 4, No 1, pp1-19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>The mathematics of sentence structure.&apos;</title>
<date>1958</date>
<journal>American Mathematical Monthly,</journal>
<volume>65</volume>
<pages>154--170</pages>
<contexts>
<context position="1942" citStr="Lambek, 1958" startWordPosition="287" endWordPosition="288">strings of a sentence as interpretable constituents, allowing its interpretation to be generated &apos;on-line&apos; as it is presented. Incremental interpretation has been argued to provide for efficient language processing, by allowing early filtering of implausible readings.&apos; This paper is concerned with the parsing of categorial formalisms that fall within the &apos;type-logical&apos; 1Within the categorial field, the significance of incrementality has been emphasised most notably in the work of Steedman, e.g. (Steedman, 1989). tradition, whose most familiar representative is the associative Lambek calculus (Lambek, 1958). Recent work has seen proposals for a range of such systems, differing in their resource sensitivity (and hence, implicitly, their underlying notion of &apos;linguistic structure&apos;), in some cases combining differing resource sensitivities in one system.&apos; Many of these proposals employ a &apos;labelled deductive system&apos; methodology (Gabbay, 1996), whereby types in proofs are associated with labels which record proof information for use in ensuring correct inferencing. A common framework is emerging for parsing type-logical formalisms, which exploits the labelled deduction idea. Approaches within this fr</context>
</contexts>
<marker>Lambek, 1958</marker>
<rawString>Joachim Lambek. 1958. &apos;The mathematics of sentence structure.&apos; American Mathematical Monthly, 65, pp154-170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Lambek</author>
</authors>
<title>On the calculus of syntactic types.&apos;</title>
<date>1961</date>
<booktitle>Structure of Language and its Mathematical Aspects, Proceedings of the Symposia in Applied Mathematics XII,</booktitle>
<publisher>American Mathematical Society.</publisher>
<contexts>
<context position="5497" citStr="Lambek, 1961" startWordPosition="832" endWordPosition="833">Yo— Z) here). (2) X0—(Yo—Z) Yo—W Wo—Z [Z] Yo—Z X Various type-logical categorial formalisms (or strictly their implicational fragments) differ from the above system only in imposing further restrictions on resource usage. For example, the associative Lambek calculus imposes a linear order over formulae, in which context, implication divides into two cases, (usually written \ and /) depending on whether the argument type appears to the left or right of the functor. Then, formulae may combine only if they are adjacent and in the appropriate left-right order. The non-associative Lambek calculus (Lambek, 1961) sets the further requirement that types combine under some fixed initial bracketting. Such weaker systems can be implemented by combining implicational linear logic with a labelling system whose labels are structured objects that record relevant resource information, i.e. of sequencing and/or bracketting, and then using this information in restricting permitted inferences to only those that satisfy the resource requirements of the weaker logic. 3 First-order Compilation The first-order formulae are those with only atomic argument types (i.e. ..F ::= A I .Tc-- A). Hepple (1996) shows how deduc</context>
</contexts>
<marker>Lambek, 1961</marker>
<rawString>Joachim Lambek. 1961. &apos;On the calculus of syntactic types.&apos; R. Jakobson (Ed), Structure of Language and its Mathematical Aspects, Proceedings of the Symposia in Applied Mathematics XII, American Mathematical Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Milward</author>
</authors>
<title>Incremental Interpretation of Categorial Grammar.&apos;</title>
<date>1995</date>
<booktitle>Proceedings EA CL-?&apos;,</booktitle>
<location>Dublin.</location>
<contexts>
<context position="29244" citStr="Milward, 1995" startWordPosition="4975" endWordPosition="4976">y relevant functional relations amongst lexical meanings. Thus, we believe the above system to exhibit maximal incrementality in relation to allowing &apos;semantically contentful&apos; combinations. In dependency terms, the system allows any set of initial formulae to combine to a single result if they form a connected graph under the dependency relations that obtain amongst them. Note that the extent of incrementality allowed by using &apos;generalised composition&apos; in the compiled firstorder system should not be equated with that which 7For an example of a system allowing word-by-word incrementality, see (Milward, 1995). 81Vote that this is not to say that the system is unable to combine these two types, e.g. a combination so—s, np so—(so—np) is derivable, with appropriate compilation. The point rather is that such a combination will typically not happen as a component in a proof of some other overall deduction. 350 would be allowed by such a rule in the original (noncompiled) system. We can illustrate this point using the following type combination, which is not an instance of even &apos;generalised&apos; composition. X0-(Yo-Z), Yo-W = X0-(Wo-Z) Compilation of the higher-order assumption would yield Xo-Y plus Z, of w</context>
</contexts>
<marker>Milward, 1995</marker>
<rawString>David Milward. 1995. &apos;Incremental Interpretation of Categorial Grammar.&apos; Proceedings EA CL-?&apos;, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
</authors>
<title>Labelled deductive systems for categorial theorem proving&apos;.</title>
<date>1992</date>
<booktitle>Proc. of Eighth Amsterdam Colloquium, ILLI,</booktitle>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="2988" citStr="Moortgat (1992)" startWordPosition="446" endWordPosition="447">n ensuring correct inferencing. A common framework is emerging for parsing type-logical formalisms, which exploits the labelled deduction idea. Approaches within this framework employ a theorem proving method that is appropriate for use with linear logic, and combine it with a labelling system that restricts admitted deductions to be those of a weaker system. Crucially, linear logic stands above all of the type-logical formalisms proposed in the hierarchy of substructural logics, and hence linear logic deduction methods can provide a common basis for parsing all of these systems. For example, Moortgat (1992) combines a linear proof net method with labelling to provide deduction for several categorial systems. Morrill (1995) shows how types of the associative Lambek calculus may be translated to labelled implicational linear types, with deduction implemented via a version of SLD resolution. Hepple (1996) introduces a linear deduction method, involving compilation to first order formulae, which can be combined with various labelling disciplines. These approaches, however, are not directed toward incremental processing. In what follows, we show how the method of (Hepple, 1996) can be modified to all</context>
</contexts>
<marker>Moortgat, 1992</marker>
<rawString>Michael Moortgat. 1992. `Labelled deductive systems for categorial theorem proving&apos;. Proc. of Eighth Amsterdam Colloquium, ILLI, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
<author>Richard T Oehrle</author>
</authors>
<title>Adjacency, dependency and order&apos;.</title>
<date>1994</date>
<booktitle>Proc. of Ninth</booktitle>
<location>Amsterdam Colloquium.</location>
<contexts>
<context position="3803" citStr="Moortgat &amp; Oehrle, 1994" startWordPosition="566" endWordPosition="569">labelled implicational linear types, with deduction implemented via a version of SLD resolution. Hepple (1996) introduces a linear deduction method, involving compilation to first order formulae, which can be combined with various labelling disciplines. These approaches, however, are not directed toward incremental processing. In what follows, we show how the method of (Hepple, 1996) can be modified to allow processing which has a high degree of incrementality. These modifications, however, give a system which suffers 2See, for example, the formalisms developed in (Moortgat &amp; Morrill, 1991), (Moortgat &amp; Oehrle, 1994), (Morrill, 1994), (Hepple, 1995). 344 the problem of &apos;derivational equivalence&apos;, also called &apos;spurious ambiguity&apos;, i.e. allowing multiple proofs which assign the same reading for some combination, a fact which threatens processing efficiency. We show how this problem is solved via normalisation. 2 Implicational Linear Logic Linear logic is an example of a &amp;quot;resource-sensitive&amp;quot; logic, requiring that each assumption (&apos;resource&apos;) is used precisely once in any deduction. For the implicational fragment, the set of formulae .7- are defined by .7&amp;quot; ::= A I o— .7. (with A a nonempty set of atomic types</context>
</contexts>
<marker>Moortgat, Oehrle, 1994</marker>
<rawString>Michael Moortgat &amp; Richard T. Oehrle. 1994. &apos;Adjacency, dependency and order&apos;. Proc. of Ninth Amsterdam Colloquium.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Moortgat</author>
<author>Glyn Morrill</author>
</authors>
<title>Heads and Phrases: Type Calculus for Dependency and Constituency.&apos; To appear:</title>
<date>1991</date>
<journal>Journal of Language, Logic and Information.</journal>
<contexts>
<context position="3776" citStr="Moortgat &amp; Morrill, 1991" startWordPosition="562" endWordPosition="565">lculus may be translated to labelled implicational linear types, with deduction implemented via a version of SLD resolution. Hepple (1996) introduces a linear deduction method, involving compilation to first order formulae, which can be combined with various labelling disciplines. These approaches, however, are not directed toward incremental processing. In what follows, we show how the method of (Hepple, 1996) can be modified to allow processing which has a high degree of incrementality. These modifications, however, give a system which suffers 2See, for example, the formalisms developed in (Moortgat &amp; Morrill, 1991), (Moortgat &amp; Oehrle, 1994), (Morrill, 1994), (Hepple, 1995). 344 the problem of &apos;derivational equivalence&apos;, also called &apos;spurious ambiguity&apos;, i.e. allowing multiple proofs which assign the same reading for some combination, a fact which threatens processing efficiency. We show how this problem is solved via normalisation. 2 Implicational Linear Logic Linear logic is an example of a &amp;quot;resource-sensitive&amp;quot; logic, requiring that each assumption (&apos;resource&apos;) is used precisely once in any deduction. For the implicational fragment, the set of formulae .7- are defined by .7&amp;quot; ::= A I o— .7. (with A a n</context>
</contexts>
<marker>Moortgat, Morrill, 1991</marker>
<rawString>Michael Moortgat &amp; Glyn Morrill. 1991. &apos;Heads and Phrases: Type Calculus for Dependency and Constituency.&apos; To appear: Journal of Language, Logic and Information.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glyn Morrill</author>
</authors>
<title>Type Logical Grammar: Categorial Logic of Signs.</title>
<date>1994</date>
<publisher>Kluwer Academic Publishers,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="3820" citStr="Morrill, 1994" startWordPosition="570" endWordPosition="571">ar types, with deduction implemented via a version of SLD resolution. Hepple (1996) introduces a linear deduction method, involving compilation to first order formulae, which can be combined with various labelling disciplines. These approaches, however, are not directed toward incremental processing. In what follows, we show how the method of (Hepple, 1996) can be modified to allow processing which has a high degree of incrementality. These modifications, however, give a system which suffers 2See, for example, the formalisms developed in (Moortgat &amp; Morrill, 1991), (Moortgat &amp; Oehrle, 1994), (Morrill, 1994), (Hepple, 1995). 344 the problem of &apos;derivational equivalence&apos;, also called &apos;spurious ambiguity&apos;, i.e. allowing multiple proofs which assign the same reading for some combination, a fact which threatens processing efficiency. We show how this problem is solved via normalisation. 2 Implicational Linear Logic Linear logic is an example of a &amp;quot;resource-sensitive&amp;quot; logic, requiring that each assumption (&apos;resource&apos;) is used precisely once in any deduction. For the implicational fragment, the set of formulae .7- are defined by .7&amp;quot; ::= A I o— .7. (with A a nonempty set of atomic types). A natural dedu</context>
</contexts>
<marker>Morrill, 1994</marker>
<rawString>Glyn Morrill. 1994. Type Logical Grammar: Categorial Logic of Signs. Kluwer Academic Publishers, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Glyn Morrill</author>
</authors>
<title>Higher-order Linear Logic Programming of Categorial Deduction&apos;.</title>
<date>1995</date>
<booktitle>Proc. of EACL-7,</booktitle>
<location>Dublin.</location>
<contexts>
<context position="3106" citStr="Morrill (1995)" startWordPosition="463" endWordPosition="464">labelled deduction idea. Approaches within this framework employ a theorem proving method that is appropriate for use with linear logic, and combine it with a labelling system that restricts admitted deductions to be those of a weaker system. Crucially, linear logic stands above all of the type-logical formalisms proposed in the hierarchy of substructural logics, and hence linear logic deduction methods can provide a common basis for parsing all of these systems. For example, Moortgat (1992) combines a linear proof net method with labelling to provide deduction for several categorial systems. Morrill (1995) shows how types of the associative Lambek calculus may be translated to labelled implicational linear types, with deduction implemented via a version of SLD resolution. Hepple (1996) introduces a linear deduction method, involving compilation to first order formulae, which can be combined with various labelling disciplines. These approaches, however, are not directed toward incremental processing. In what follows, we show how the method of (Hepple, 1996) can be modified to allow processing which has a high degree of incrementality. These modifications, however, give a system which suffers 2Se</context>
</contexts>
<marker>Morrill, 1995</marker>
<rawString>Glyn Morrill. 1995. &apos;Higher-order Linear Logic Programming of Categorial Deduction&apos;. Proc. of EACL-7, Dublin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mark J Steedman</author>
</authors>
<title>Grammar, interpretation and processing from the lexicon.&apos;</title>
<date>1989</date>
<booktitle>In MarslenWilson, W. (Ed), Lexical Representation and Process,</booktitle>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="1845" citStr="Steedman, 1989" startWordPosition="275" endWordPosition="276">igned analyses that are fully or primarily left-branching. Such analyses designate many initial substrings of a sentence as interpretable constituents, allowing its interpretation to be generated &apos;on-line&apos; as it is presented. Incremental interpretation has been argued to provide for efficient language processing, by allowing early filtering of implausible readings.&apos; This paper is concerned with the parsing of categorial formalisms that fall within the &apos;type-logical&apos; 1Within the categorial field, the significance of incrementality has been emphasised most notably in the work of Steedman, e.g. (Steedman, 1989). tradition, whose most familiar representative is the associative Lambek calculus (Lambek, 1958). Recent work has seen proposals for a range of such systems, differing in their resource sensitivity (and hence, implicitly, their underlying notion of &apos;linguistic structure&apos;), in some cases combining differing resource sensitivities in one system.&apos; Many of these proposals employ a &apos;labelled deductive system&apos; methodology (Gabbay, 1996), whereby types in proofs are associated with labels which record proof information for use in ensuring correct inferencing. A common framework is emerging for parsi</context>
</contexts>
<marker>Steedman, 1989</marker>
<rawString>Mark J. Steedman. 1989. &apos;Grammar, interpretation and processing from the lexicon.&apos; In MarslenWilson, W. (Ed), Lexical Representation and Process, MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kent Wittenburg</author>
</authors>
<title>Predictive Combinators: A method for efficient parsing of Combinatory Categorial Grammars.&apos;</title>
<date>1987</date>
<booktitle>Proc. of ACL-25.</booktitle>
<marker>Wittenburg, 1987</marker>
<rawString>Kent Wittenburg. 1987. &apos;Predictive Combinators: A method for efficient parsing of Combinatory Categorial Grammars.&apos; Proc. of ACL-25.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>