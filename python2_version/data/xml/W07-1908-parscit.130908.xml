<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000392">
<title confidence="0.9964685">
Dynamic Movement and Positioning of Embodied Agents in Multiparty
Conversations
</title>
<author confidence="0.930629">
Duˇsan Jan
</author>
<affiliation confidence="0.920828">
USC Institute for Creative Technologies
</affiliation>
<address confidence="0.8944245">
13274 Fiji Way
Marina del Rey, CA 90292
</address>
<email confidence="0.998514">
jan@ict.usc.edu
</email>
<author confidence="0.867016">
David R. Traum
</author>
<affiliation confidence="0.859755">
USC Institute for Creative Technologies
</affiliation>
<address confidence="0.8828985">
13274 Fiji Way
Marina del Rey, CA 90292
</address>
<email confidence="0.998957">
traum@ict.usc.edu
</email>
<sectionHeader confidence="0.996662" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999467411764706">
For embodied agents to engage in realis-
tic multiparty conversation, they must stand
in appropriate places with respect to other
agents and the environment. When these
factors change, for example when an agent
joins a conversation, the agents must dynam-
ically move to a new location and/or orien-
tation to accommodate. This paper presents
an algorithm for simulating the movement
of agents based on observed human behav-
ior using techniques developed for pedes-
trian movement in crowd simulations. We
extend a previous group conversation simu-
lation to include an agent motion algorithm.
We examine several test cases and show how
the simulation generates results that mirror
real-life conversation settings.
</bodyText>
<sectionHeader confidence="0.998889" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999906923076923">
When we look at human conversation in a casual,
open setting, such as a party or marketplace, one of
the first things we notice is a tendency for people
to cluster into sub-groups involved in different con-
versations. These groupings are not fixed, however,
people will often join and leave groups and often
move from one group to another. Groups themselves
may fragment into subgroups, and smaller groups
sometimes merge into one larger group. Participants
in these groups adapt their positions and orientations
to account for these circumstances, often without
missing a beat or otherwise disrupting their conver-
sations.
</bodyText>
<page confidence="0.982692">
59
</page>
<bodyText confidence="0.999949029411765">
In order to create believable social environments
for games or training simulations we need agents
that can perform these same kinds of behaviors in
a realistic way. There are a number of crowd sim-
ulations (Sung et al., 2004; Shao and Terzopou-
los, 2005; Still, 2000; Helbing and Moln´ar, 1995),
but most of these place an emphasis on large-scale
movement of agents and do not model the low-level
aspects of conversational interaction in a realistic
way — movement of agents in multiparty conver-
sation is more about positioning and repositioning
on a local scale. There is also a large body of work
on embodied conversational agents (Cassell et al.,
2000), which attempt to model realistic conversa-
tional non-verbal behaviors. Most of this work fo-
cuses on aspects such as gaze, facial expressions,
and hand and arm gestures, rather than positioning
and orientation in a group. There is some important
work on authored presentation agents and avatars for
human participants which take account of position
in the modelling (Vilhjalmsson and Cassell, 1998;
Rehm et al., 2005), but none of this work presents
fully explicit algorithms for controlling the position-
ing and movement behavior of autonomous agents in
dynamic conversations.
In previous work, it has been shown that incor-
rect positioning of animated agents has a negative ef-
fect on the believability of dynamic group conversa-
tion (Jan and Traum, 2005). Research from anthro-
pologists and social psychologists such as the classic
work on proxemics by Hall (1968) and positioning
by Kendon (1990) provide social reasons to explain
how people position themselves in different situa-
tions. It is also important to know that people expect
</bodyText>
<subsectionHeader confidence="0.573715">
Proceedings of the Workshop on Embodied Language Processing, pages 59–66,
Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics
</subsectionHeader>
<bodyText confidence="0.999930678571429">
similar behavior in virtual environments as in real
life as shown by Bailenson et al. (2003). This gives
us basic principles on which to base the simulation
and provides some qualitative expectations, but is
not suitable to directly convert into algorithms. The
social force model (Helbing and Moln´ar, 1995) de-
veloped for crowd simulations gives a good frame-
work for movement simulation. While the basic
model shows how to handle pedestrian motion we
apply the model to the problem of movement in con-
versation setting.
Our implementation of conversational movement
and positioning is an extension of prior work in
group conversation simulation using autonomous
agents. Carletta and Padilha (2002) presented a sim-
ulation of the external view of a group conversation,
in which the group members take turns speaking and
listening to others. Previous work on turn-taking
is used to form a probabilistic algorithm in which
agents can perform basic behaviors such as speaking
and listening, beginning, continuing or concluding
a speaking turn, giving positive and negative feed-
back, head nods, gestures, posture shifts, and gaze.
Behaviors are generated using a stochastic algorithm
that compares randomly generated numbers against
parameters that can take on values between 0 and 1.
This work was further extended by (Jan and
Traum, 2005), who used new bodies in the Unreal
Tournament game engine, and added support for dy-
namic creation of conversation groups. This simu-
lation allowed dynamic creation, splitting, joining,
entry and exit of sub-conversations. However, the
characters were located in fixed positions. As indi-
cated in their subject evaluations, this significantly
decreased believability when conversation groups
did not coincide with positioning of the agents.
Adding support for movement of characters is a nat-
ural step to counter these less believable situations.
We augment this work by adding a movement and
positioning component that allows agents to moni-
tor “forces” that make it more desirable to move to
one place or another, iteratively select new destina-
tions and move while remaining engaged in conver-
sations.
The rest of the paper is organized as follows. Sec-
tion 2 describes the main motivations that agents
have for moving from their current position in con-
versation. Section 3 presents the social force model,
which specifies a set of forces that pressure an agent
to move in one direction or another, and a deci-
sion algorithm for deciding which forces to act on
in different situations. Section 4 presents a series of
test cases for the algorithm, demonstrating that the
model behaves as desired for some benchmark prob-
lems in this space. We conclude in section 5 with a
description of future work in this area.
</bodyText>
<sectionHeader confidence="0.99869" genericHeader="method">
2 Reasons for Movement
</sectionHeader>
<bodyText confidence="0.961105">
There are several reasons why someone engaged in
conversation would want to shift position. Some of
these include:
</bodyText>
<listItem confidence="0.999512888888889">
• one is listening to a speaker who is too far and
or not loud enough to hear,
• there is too much noise from other nearby
sound sources,
• the background noise is louder than the
speaker,
• one is too close to others to feel comfortable,
• one has an occluded view or is occluding the
view of others.
</listItem>
<bodyText confidence="0.999816904761905">
Any of these factors (or a combination of several)
could motivate a participant to move to a more com-
fortable location. During the simulation the speakers
can change, other noise sources can start and stop,
and other agents can move around as well. These
factors can cause a variety of motion throughout the
course of interactions with others. In the rest of this
section we describe these factors in more detail. In
the next section we will develop a formal model of
reactions to these factors.
The first reason we consider for repositioning of
conversation participants is audibility of the speaker.
The deciding factor can be either the absolute vol-
ume of the speaker, or the relative volume compared
to other “noise”. Noise here describes all audio input
that is not speech by someone in the current conver-
sation group. This includes the speech of agents en-
gaged in other conversations as well as non-speech
sounds. When we are comparing the loudness of dif-
ferent sources we take into account that intensity of
the perceived signal decreases with the square of the
</bodyText>
<page confidence="0.991115">
60
</page>
<bodyText confidence="0.999640333333333">
distance and also that the loudness of several sources
is additive.
Even when the speaker can be heard over a noise
source, if outside disruptions are loud enough, the
group might want to move to a more remote area
where they can interact without interruptions. Each
of the participants may decide to shift away from a
noise source, even without an explicit group deci-
sion. Of course this may not always be possible if
the area is very crowded.
Another reason for movement is proxemics.
Hall (1968) writes that individuals generally divide
their personal space into four distinct zones. The
intimate zone is used for embracing or whispering,
the personal zone is used for conversation among
good friends, the social zone is used for conversa-
tion among acquaintances and the public zone for
public speaking. The actual distances the zones span
are different for each culture and its interpretation
may vary based on an individual’s personality. If the
speaker is outside the participant’s preferred zone,
the participant will move toward the speaker. Simi-
larly if someone invades the personal zone of a par-
ticipant, the participant will move away.
The final reason for movement is specific to mul-
tiparty conversations. When there are several people
in conversation they will tend to form a circular for-
mation. This gives the sense of inclusion to partic-
ipants and gives them a better view of one another
(Kendon, 1990).
</bodyText>
<sectionHeader confidence="0.998365" genericHeader="method">
3 Social Force Model
</sectionHeader>
<bodyText confidence="0.999915066666667">
We present our movement simulation in the context
of a social force model. Similar to movement in
crowds, the movement of people engaged in conver-
sation is to a large extent reactionary. The reaction
is usually automatic and determined by person’s ex-
perience, rather than planned for. It is possible to as-
sign a vectorial quantity for each person in conversa-
tion, that describes the desired movement direction.
This quantity can be interpreted as a social force.
This force represents the influence of the environ-
ment on the behavior of conversation participant. It
is important to note however that this force does not
directly cause the body to move, but rather provides
a motivation to move. We illustrate these forces
with figures such as Figure 1, where each circle
</bodyText>
<figureCaption confidence="0.871128">
Figure 1: A sample group positioning. Each circle
</figureCaption>
<bodyText confidence="0.962208222222222">
represents an agent. A thick border represents that
the agent is talking, filled or empty shading indicates
conversation group membership.
represents an agent, the different shadings represent
members of different conversation groups, thicker
circles represent speakers in that group, and arrows
represent forces on an agent of interest.
We associate a force with each reason for move-
ment:
</bodyText>
<equation confidence="0.8894385">
�
Fspeaker : attractive force toward a speaker
�
Fnoise : repelling force from outside noise
</equation>
<bodyText confidence="0.97692">
Fproximity : repelling force from agents that are too
close
Fcircbe : force toward circular formation of all con-
versation participants
Fspeaker is a force that is activated when the
speaker is too far from the listener. This can hap-
pen for one of two reasons. Either the speaker is not
loud enough and the listener has to move closer in
order to understand him, or he is outside the desired
zone for communication. When the agent decides
to join conversation this is the main influence that
guides the agent to his conversation group as shown
�
in Figure 2. Fspeaker is computed according to the
following equation, where rspeaker is location of the
speaker, r� is location of the agent and k is a scaling
factor (we are currently using k = 1):
</bodyText>
<equation confidence="0.761718">
Fspeaker = kKpeaker − 0
</equation>
<bodyText confidence="0.786527">
Fnoise is a sum of forces away from each source of
noise. Each component force is directed away from
</bodyText>
<page confidence="0.997077">
61
</page>
<figureCaption confidence="0.996395">
Figure 2: Attractive force toward speaker �Fspeaker. Figure 3: Repelling force away from other speakers
�Fnoise.
</figureCaption>
<bodyText confidence="0.995749">
that particular source and its size is inversely pro-
portional to square of the distance. This means that
only sources relatively close to the agent will have a
significant influence. Not all noise is a large enough
motivation for the agent to act upon. The force is
only active when the noise level exceeds a threshold
or when its relative value compared to speaker level
in the group exceeds a threshold. Figure 3 shows an
example of the latter. The following equation is used
to compute �Fnoise:
</bodyText>
<figure confidence="0.942317666666666">
ri − r
too close
k�ri − �rk3
</figure>
<figureCaption confidence="0.837143">
Figure 4: Repelling force away from agents that are
�Fproximity.
</figureCaption>
<equation confidence="0.9514485">
X�Fnoise = −
i
</equation>
<bodyText confidence="0.939072516129032">
Fproximity is also a cumulative force. It is a sum
of forces away from each agent that is too close.
The force gets stronger the closer the invading agent
is. This takes effect for both agents in the conver-
sation group and other agents. This is the second
force that is modeling proxemics. While Fspeaker
is activated when the agent is farther than the de-
�
sired social zone, Fproximity is activated when the
agent moves to a closer zone. Based on how well the
agents know each other this can be either when the
agent enters the intimate zone or the personal zone.
Figure 4 shows an example when two agents get too
close to each other. The following equation is used
to compute values for
participating in the conversation. An agent will com-
pute the center of mass of all these assumed partic-
ipants and the average distance from the center. If
an agent’s position deviates too much from the aver-
�
age, the Fcircle gets activated either toward or away
�
from center of mass. Notice that Fproximity takes
care of spreading out around the circle. The situa-
tion in Figure 5 is an example where an agent de-
cides that he has to adapt his positioning. Notice
that if this agent was not aware of the agent to his
left, the force would not get triggered. This can be
a cause for many interesting situations when agents
have different beliefs about who is part of the con-
versation.
</bodyText>
<equation confidence="0.8917165">
�Fproximity:
X
Fproximity = −
Jjri−rjj&lt;distancezone
</equation>
<bodyText confidence="0.9996488">
Fcircle is responsible for forming the conversa-
tional group into a convex, roughly circular forma-
tion. Each agent has a belief about who is currently
As described above, each force has some condi-
tions that determine whether the force plays an ac-
</bodyText>
<equation confidence="0.996471357142857">
rm =
X
N
i
1
ri
1XPcircle = λ N
i
k4, − �rmk
r − �rm
k�r −�rmk −
!r�
ri − r
k�ri − r1k2
</equation>
<page confidence="0.996831">
62
</page>
<figureCaption confidence="0.994146">
Figure 5: Agent’s deviation from circular formation
exceeds threshold and triggers force Pcircle.
</figureCaption>
<bodyText confidence="0.9838606875">
tive role in motivating movement. Since the forces
are not actually physically acting on agent’s bodies,
it is not unreasonable for agents to suppress a cer-
tain force. All the possible causes for movement
are always present, but the agents selectively decide
which ones they will act upon in a given situation.
This is unlike a kinematics calculation with physical
forces where all forces are always active. Combin-
ing all the conditions we can define which forces are
active according to a simple decision procedure. We
can view this as priorities the agent has that decide
which conditions are more important to react to.
In our implementation we use the following pri-
orities:
if speaker is too low F = Fspeaker + Fproximity
else if noise is louder than speaker F = Fspeaker +
</bodyText>
<subsubsectionHeader confidence="0.440085">
Fnoise + Fproximity
</subsubsectionHeader>
<bodyText confidence="0.969629888888889">
else if noise is too loud F = Fnoise + Fproximity
else if too close to someone F = Fproximity
otherwise F = Pcircle
Using the above priorities we have a force defined
at each point in space where an agent could be lo-
cated. We do not use this for the continuous com-
putation of movement, but rather use it to compute
destination points. In each planning cycle the agents
will consider whether they should move. To do this
an agent considers his position in the force field and
computes a destination in the direction of the force
field. This process is performed iteratively a con-
stant bound times (unless there is no movement in
an earlier iteration). This is described in the follow-
ing equations, where r� is the initial position, α is a
�
scaling factor, and Pbound is the destination for the
movement of this planning cycle:
</bodyText>
<equation confidence="0.998682333333333">
�P0 = r�
Pi+1 = Pi + αF�(Pi)
Destination� = Pbound
</equation>
<bodyText confidence="0.945434111111111">
Once we have computed the destination, we use
it as a destination point for the character movement
algorithms in the Unreal Tournament game engine.
These will manage character animation and collision
avoidance.
Figure 6 shows an example with two separate con-
versation groups, where one agent decides to leave
the shaded group and join the unshaded conversa-
tion. The figure shows the iterations he is perform-
ing in his planning cycle and the resulting final des-
tination.
Figure 6: Example of motion computation: The
lower right agent decided to join the unshaded con-
versation. He iteratively applies movement in the
direction of local forces. In each iteration the effects
of different component forces may take effect. The
thick line indicates the final destination and path the
agent chooses for this planning cycle.
</bodyText>
<sectionHeader confidence="0.892991" genericHeader="method">
4 Test Case Analysis
</sectionHeader>
<bodyText confidence="0.999980857142857">
A full evaluation of the social-force based posi-
tioning algorithm presented in the previous section
would involve analysis of simulations to see if they
improve believability over static simulations such as
simulation of Jan and Traum (2005), or other algo-
rithms. While this remains future work for the mo-
ment, we did evaluate the algorithms against a series
</bodyText>
<page confidence="0.998761">
63
</page>
<bodyText confidence="0.999988782608696">
of test cases where we know what behavior to expect
from known forces. In this section we present three
such cases, showing that the algorithm does have the
power to represent several aspects of conversational
positioning.
In the simulations we describe here we did not
change the conversational attributes of agents, but
we did constrain the grouping dynamics. In a normal
situation the agents would randomly form conver-
sation groups, based on their stochastic decisions.
Here we wanted to examine particular scenarios and
how the movement algorithm would react to specific
changes in conversation group structure. For this
reason we disabled conversational grouping deci-
sions in the algorithm and triggered the group struc-
ture changes manually from the user interface.
The only variable input to the movement algo-
rithms for different agents is the preferences for
proxemics. Each agent has defined values for all
zones, but we set all agents to use social zone
for communicating. The other parameters such as
thresholds for hearing a speaker and noise and cir-
cular formations were fixed for these experiments.
</bodyText>
<subsectionHeader confidence="0.999518">
4.1 Joining conversation
</subsectionHeader>
<bodyText confidence="0.999874318181818">
In this test case we have 4 agents. In the initial
condition three agents are engaged in conversation
while the fourth one is away from the scene. We let
the simulation run and at some point we give a com-
mand to the fourth agent to join the group of three.
At first the agent will move toward the group until
he is in a comfortable range as shown in Figure 7.
At the point in which the fourth agent decides to
join the other three, he is the only one who knows
he wants to join the conversation. The other agents
know of the presence of the fourth agent, but they
have no idea that he would like to join them. The
fourth agent is listening for a while and when he
gives a feedback signal the other agents interpret that
as a signal that he wants to join the conversation. As
a result the agents reevaluate their positioning and
one agent decides it would be appropriate to move a
step back to give more space to the new agent. Given
more space the new agent is able to move in circular
formation with the rest of the group without intrud-
ing on the personal zones of other agents. The stable
point of simulation is shown in Figure 8.
</bodyText>
<figureCaption confidence="0.9984142">
Figure 7: The agent on the left is approaching a
conversation. Arrows indicate where the agents will
move from now until the simulation stabilizes.
Figure 8: Stable point after the fourth agent joins the
conversation.
</figureCaption>
<subsectionHeader confidence="0.980587">
4.2 Conversation splitting into two separate
conversations
</subsectionHeader>
<bodyText confidence="0.995548384615385">
In this test case, we have 6 agents. After initial
placement of the agents we issue a command for all
the agents to form one conversation group. As a re-
sult they form a circular formation as can be seen in
Figure 9.
We let the agents talk for a while and then give a
command to the two agents on the right side of the
group to start a side conversation. After this a com-
plex sequence of events takes place. Initially the re-
maining agents still think that those two agents are
part of their conversation group. They have to dis-
ambiguate the speech of those two agents and decide
whether this is just an interruption or a split in the
</bodyText>
<page confidence="0.998493">
64
</page>
<figureCaption confidence="0.9655595">
Figure 9: Agents form in a circle to engage in a sin-
gle conversation.
</figureCaption>
<bodyText confidence="0.9949815">
conversation. After a while they realize that those
agents are having a separate conversation.
Deciding that the agents on the right have left the
conversation leads to a change in the force field. The
agents that were closest to the split are bothered by
the noise and start adjusting by moving away. By
doing this they change the shape of formation which
causes the farther agents to also adapt back into cir-
cular formation. At the same time the agents who
split also move away from the others until they get
to a point where all are satisfied. The point where
the simulation stabilized is shown in Figure 10.
Figure 10: After two agents leave the conversation
the agents adapt to it by repositioning.
</bodyText>
<subsectionHeader confidence="0.998568">
4.3 Effect of proxemics
</subsectionHeader>
<bodyText confidence="0.9983325">
In this test case, we examine the effects when the
social zones of the agents are not compatible. This
frequently happens when we have people from dif-
ferent cultures with a large difference in distances
for social zones. An example would be North Amer-
icans compared to Arabs. Americans prefer a much
greater inter-personal distance than Arabs. Empiri-
cal data shows that in many such situations there is
a sort of dance with one agent moving in while an-
other moves away (Scheflen, 1975).
</bodyText>
<figureCaption confidence="0.988373">
Figure 11: Incompatible social zones.
</figureCaption>
<bodyText confidence="0.97266">
Figure 11 shows an example of agents with in-
compatible social zones. The markings on the
ground indicate the minimum and maximum accept-
able distance for social zone for each agent. We can
see that the agent on the left has a much smaller
comfortable distance than the one on the right. In
the current position the left agent feels that the other
one is too far, while the right agent thinks everything
is fine. This causes the left agent to make a step for-
ward. Consequently by doing so he steps into per-
sonal zone of the right agent. Now the left agent is
satisfied with the situation but the right agent feels
uncomfortable and decides to take a step back to
keep the other agent out of his personal zone. If
nothing else intervenes, this process can continue,
as the agent on the left “chases” the one on the right
out of the marketplace.
</bodyText>
<sectionHeader confidence="0.999627" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.9972245">
In the previous section, we have shown examples of
how the movement algorithm can mirror many ef-
</bodyText>
<page confidence="0.998729">
65
</page>
<bodyText confidence="0.99999128125">
fects we see in real conversations. The examples
however were very constrained and could not show
all the possible combinations that could result from
random choices the agents can make. Given the fact
that each agent maintains his own belief about who
is currently in their conversation we can see many
interesting effects when those beliefs become un-
synchronized.
As seen in the third test case, we can get some
very interesting results when we simulate agents of
different cultures. We think that this simulation ap-
proach can be fruitful for modeling cultural differ-
ences in conversational behavior, and could be used
for inter-cultural and cross-cultural awareness and
training. We are currently exploring whether we can
model different cultural norms for conversational
behaviors in ways such that the resulting agent inter-
action can be recognized as appropriate to one cul-
ture or another.
There are still several improvements possible for
the conversation simulation. On the presentation
side we are planning to make some improvements to
the bodies and number and types of conversational
gestures they can display. We also plan to improve
the algorithm so that it will be able to generate dif-
ferent conversation styles. Currently all conversa-
tions take the same form where all the agents have
the same goals, their only goal is to engage in con-
versation with other agents. We plan to introduce the
notion of tasks so that we can better simulate differ-
ent kinds of activities such as asking for directions,
a political debate, or casual conversation.
</bodyText>
<sectionHeader confidence="0.998227" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999980666666667">
The project described here has been sponsored
by the U.S. Army Research, Development, and En-
gineering Command (RDECOM). Statements and
opinions expressed do not necessarily reflect the po-
sition or the policy of the United States Government,
and no official endorsement should be inferred.
</bodyText>
<sectionHeader confidence="0.999274" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999916234042553">
Jeremy N. Bailenson, Jim Blascovich, Andrew C. Beall,
and Jack M. Loomis. 2003. Interpersonal distance
in immersive virtual environments. Personality and
Social Psychology Bulletin, 29:819–833.
Justine Cassell, Joseph Sullivan, Scott Prevost, and Eliz-
abeth Churchill, editors. 2000. Embodied Conversa-
tional Agents. MIT Press, Cambridge, MA.
Edward T. Hall. 1968. Proxemics. Current Anthropol-
ogy, 9(2/3):83–108, apr.
Dirk Helbing and P´eter Moln´ar. 1995. Social force
model for pedestrian dynamics. Phys. Rev. E,
51(5):4282–4286, May.
Dusan Jan and David R. Traum. 2005. Dialog simulation
for background characters. Lecture Notes in Computer
Science, pages 65–74.
Adam Kendon, 1990. Spatial Organization in Social
Encounters: the F-formation System, pages 209–237.
Cambridge University Press.
E. Padilha and J. Carletta. 2002. A simulation of small
group discussion. Proceedings of EDILOG 2002:
Sixth Workshop on the Semantics and Pragmatics of
Dialogue, pages 117–124.
Matthias Rehm, Elisabeth Andre, and Michael Nischt.
2005. Let’s come together - social navigation behav-
iors of virtual and real humans. In Mark Maybury
et al., editor, INTETAIN 2005, LNAI, pages 122–131.
Springer.
Albert E. Scheflen. 1975. Micro-territories in human in-
teraction. In Adam Kendon, Richard M. Harris, and
Mary Ritchie Key, editors, World Anthropology: Or-
ganization of Behavior in Face-to-Face Interaction,
pages 159–173. Mouton, Paris.
Wei Shao and Demetri Terzopoulos. 2005. Autonomous
pedestrians. In SCA ’05: Proceedings of the 2005
ACM SIGGRAPH/Eurographics symposium on Com-
puter animation, pages 19–28, New York, NY, USA.
ACM Press.
G. Keith Still. 2000. Crowd Dynamics. Ph.D. thesis,
Warwick University.
Mankyu Sung, Michael Gleicher, and Stephen Chenney.
2004. Scalable behaviors for crowd simulation. Com-
puter Graphics Forum, 23(3):519–528.
Hannes Hogni Vilhjalmsson and Justine Cassell. 1998.
Bodychat: autonomous communicative behaviors in
avatars. In AGENTS ’98: Proceedings of the second
international conference on Autonomous agents, pages
269–276, New York, NY, USA. ACM Press.
</reference>
<page confidence="0.989014">
66
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.700832">
<title confidence="0.998719">Dynamic Movement and Positioning of Embodied Agents in Multiparty Conversations</title>
<author confidence="0.920154">Duˇsan</author>
<affiliation confidence="0.96603">USC Institute for Creative</affiliation>
<address confidence="0.919626">13274 Fiji</address>
<author confidence="0.918125">Marina del Rey</author>
<author confidence="0.918125">CA</author>
<email confidence="0.999075">jan@ict.usc.edu</email>
<author confidence="0.999014">R David</author>
<affiliation confidence="0.997036">USC Institute for Creative</affiliation>
<address confidence="0.946022">13274 Fiji</address>
<author confidence="0.933904">Marina del Rey</author>
<author confidence="0.933904">CA</author>
<email confidence="0.999184">traum@ict.usc.edu</email>
<abstract confidence="0.999690111111111">For embodied agents to engage in realistic multiparty conversation, they must stand in appropriate places with respect to other agents and the environment. When these factors change, for example when an agent joins a conversation, the agents must dynamically move to a new location and/or orientation to accommodate. This paper presents an algorithm for simulating the movement of agents based on observed human behavior using techniques developed for pedestrian movement in crowd simulations. We extend a previous group conversation simulation to include an agent motion algorithm. We examine several test cases and show how the simulation generates results that mirror real-life conversation settings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Jeremy N Bailenson</author>
<author>Jim Blascovich</author>
<author>Andrew C Beall</author>
<author>Jack M Loomis</author>
</authors>
<title>Interpersonal distance in immersive virtual environments. Personality and Social Psychology Bulletin,</title>
<date>2003</date>
<pages>29--819</pages>
<contexts>
<context position="3595" citStr="Bailenson et al. (2003)" startWordPosition="561" endWordPosition="564">negative effect on the believability of dynamic group conversation (Jan and Traum, 2005). Research from anthropologists and social psychologists such as the classic work on proxemics by Hall (1968) and positioning by Kendon (1990) provide social reasons to explain how people position themselves in different situations. It is also important to know that people expect Proceedings of the Workshop on Embodied Language Processing, pages 59–66, Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics similar behavior in virtual environments as in real life as shown by Bailenson et al. (2003). This gives us basic principles on which to base the simulation and provides some qualitative expectations, but is not suitable to directly convert into algorithms. The social force model (Helbing and Moln´ar, 1995) developed for crowd simulations gives a good framework for movement simulation. While the basic model shows how to handle pedestrian motion we apply the model to the problem of movement in conversation setting. Our implementation of conversational movement and positioning is an extension of prior work in group conversation simulation using autonomous agents. Carletta and Padilha (</context>
</contexts>
<marker>Bailenson, Blascovich, Beall, Loomis, 2003</marker>
<rawString>Jeremy N. Bailenson, Jim Blascovich, Andrew C. Beall, and Jack M. Loomis. 2003. Interpersonal distance in immersive virtual environments. Personality and Social Psychology Bulletin, 29:819–833.</rawString>
</citation>
<citation valid="true">
<title>Embodied Conversational Agents.</title>
<date>2000</date>
<editor>Justine Cassell, Joseph Sullivan, Scott Prevost, and Elizabeth Churchill, editors.</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>2000</marker>
<rawString>Justine Cassell, Joseph Sullivan, Scott Prevost, and Elizabeth Churchill, editors. 2000. Embodied Conversational Agents. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward T Hall</author>
</authors>
<date>1968</date>
<journal>Proxemics. Current Anthropology,</journal>
<volume>9</volume>
<issue>2</issue>
<contexts>
<context position="3169" citStr="Hall (1968)" startWordPosition="499" endWordPosition="500">on authored presentation agents and avatars for human participants which take account of position in the modelling (Vilhjalmsson and Cassell, 1998; Rehm et al., 2005), but none of this work presents fully explicit algorithms for controlling the positioning and movement behavior of autonomous agents in dynamic conversations. In previous work, it has been shown that incorrect positioning of animated agents has a negative effect on the believability of dynamic group conversation (Jan and Traum, 2005). Research from anthropologists and social psychologists such as the classic work on proxemics by Hall (1968) and positioning by Kendon (1990) provide social reasons to explain how people position themselves in different situations. It is also important to know that people expect Proceedings of the Workshop on Embodied Language Processing, pages 59–66, Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics similar behavior in virtual environments as in real life as shown by Bailenson et al. (2003). This gives us basic principles on which to base the simulation and provides some qualitative expectations, but is not suitable to directly convert into algorithms. The soci</context>
<context position="8253" citStr="Hall (1968)" startWordPosition="1339" endWordPosition="1340">ifferent sources we take into account that intensity of the perceived signal decreases with the square of the 60 distance and also that the loudness of several sources is additive. Even when the speaker can be heard over a noise source, if outside disruptions are loud enough, the group might want to move to a more remote area where they can interact without interruptions. Each of the participants may decide to shift away from a noise source, even without an explicit group decision. Of course this may not always be possible if the area is very crowded. Another reason for movement is proxemics. Hall (1968) writes that individuals generally divide their personal space into four distinct zones. The intimate zone is used for embracing or whispering, the personal zone is used for conversation among good friends, the social zone is used for conversation among acquaintances and the public zone for public speaking. The actual distances the zones span are different for each culture and its interpretation may vary based on an individual’s personality. If the speaker is outside the participant’s preferred zone, the participant will move toward the speaker. Similarly if someone invades the personal zone o</context>
</contexts>
<marker>Hall, 1968</marker>
<rawString>Edward T. Hall. 1968. Proxemics. Current Anthropology, 9(2/3):83–108, apr.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dirk Helbing</author>
<author>P´eter Moln´ar</author>
</authors>
<title>Social force model for pedestrian dynamics.</title>
<date>1995</date>
<journal>Phys. Rev. E,</journal>
<volume>51</volume>
<issue>5</issue>
<marker>Helbing, Moln´ar, 1995</marker>
<rawString>Dirk Helbing and P´eter Moln´ar. 1995. Social force model for pedestrian dynamics. Phys. Rev. E, 51(5):4282–4286, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dusan Jan</author>
<author>David R Traum</author>
</authors>
<title>Dialog simulation for background characters.</title>
<date>2005</date>
<journal>Lecture Notes in Computer Science,</journal>
<pages>65--74</pages>
<contexts>
<context position="3060" citStr="Jan and Traum, 2005" startWordPosition="480" endWordPosition="483">ressions, and hand and arm gestures, rather than positioning and orientation in a group. There is some important work on authored presentation agents and avatars for human participants which take account of position in the modelling (Vilhjalmsson and Cassell, 1998; Rehm et al., 2005), but none of this work presents fully explicit algorithms for controlling the positioning and movement behavior of autonomous agents in dynamic conversations. In previous work, it has been shown that incorrect positioning of animated agents has a negative effect on the believability of dynamic group conversation (Jan and Traum, 2005). Research from anthropologists and social psychologists such as the classic work on proxemics by Hall (1968) and positioning by Kendon (1990) provide social reasons to explain how people position themselves in different situations. It is also important to know that people expect Proceedings of the Workshop on Embodied Language Processing, pages 59–66, Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics similar behavior in virtual environments as in real life as shown by Bailenson et al. (2003). This gives us basic principles on which to base the simulation </context>
<context position="4837" citStr="Jan and Traum, 2005" startWordPosition="754" endWordPosition="757">lation of the external view of a group conversation, in which the group members take turns speaking and listening to others. Previous work on turn-taking is used to form a probabilistic algorithm in which agents can perform basic behaviors such as speaking and listening, beginning, continuing or concluding a speaking turn, giving positive and negative feedback, head nods, gestures, posture shifts, and gaze. Behaviors are generated using a stochastic algorithm that compares randomly generated numbers against parameters that can take on values between 0 and 1. This work was further extended by (Jan and Traum, 2005), who used new bodies in the Unreal Tournament game engine, and added support for dynamic creation of conversation groups. This simulation allowed dynamic creation, splitting, joining, entry and exit of sub-conversations. However, the characters were located in fixed positions. As indicated in their subject evaluations, this significantly decreased believability when conversation groups did not coincide with positioning of the agents. Adding support for movement of characters is a natural step to counter these less believable situations. We augment this work by adding a movement and positionin</context>
<context position="16706" citStr="Jan and Traum (2005)" startWordPosition="2799" endWordPosition="2802">tination. Figure 6: Example of motion computation: The lower right agent decided to join the unshaded conversation. He iteratively applies movement in the direction of local forces. In each iteration the effects of different component forces may take effect. The thick line indicates the final destination and path the agent chooses for this planning cycle. 4 Test Case Analysis A full evaluation of the social-force based positioning algorithm presented in the previous section would involve analysis of simulations to see if they improve believability over static simulations such as simulation of Jan and Traum (2005), or other algorithms. While this remains future work for the moment, we did evaluate the algorithms against a series 63 of test cases where we know what behavior to expect from known forces. In this section we present three such cases, showing that the algorithm does have the power to represent several aspects of conversational positioning. In the simulations we describe here we did not change the conversational attributes of agents, but we did constrain the grouping dynamics. In a normal situation the agents would randomly form conversation groups, based on their stochastic decisions. Here w</context>
</contexts>
<marker>Jan, Traum, 2005</marker>
<rawString>Dusan Jan and David R. Traum. 2005. Dialog simulation for background characters. Lecture Notes in Computer Science, pages 65–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Kendon</author>
</authors>
<title>Spatial Organization in Social Encounters: the F-formation System,</title>
<date>1990</date>
<pages>209--237</pages>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="3202" citStr="Kendon (1990)" startWordPosition="504" endWordPosition="505"> and avatars for human participants which take account of position in the modelling (Vilhjalmsson and Cassell, 1998; Rehm et al., 2005), but none of this work presents fully explicit algorithms for controlling the positioning and movement behavior of autonomous agents in dynamic conversations. In previous work, it has been shown that incorrect positioning of animated agents has a negative effect on the believability of dynamic group conversation (Jan and Traum, 2005). Research from anthropologists and social psychologists such as the classic work on proxemics by Hall (1968) and positioning by Kendon (1990) provide social reasons to explain how people position themselves in different situations. It is also important to know that people expect Proceedings of the Workshop on Embodied Language Processing, pages 59–66, Prague, Czech Republic, June 28, 2007. c�2007 Association for Computational Linguistics similar behavior in virtual environments as in real life as shown by Bailenson et al. (2003). This gives us basic principles on which to base the simulation and provides some qualitative expectations, but is not suitable to directly convert into algorithms. The social force model (Helbing and Moln´</context>
<context position="9172" citStr="Kendon, 1990" startWordPosition="1488" endWordPosition="1489">g. The actual distances the zones span are different for each culture and its interpretation may vary based on an individual’s personality. If the speaker is outside the participant’s preferred zone, the participant will move toward the speaker. Similarly if someone invades the personal zone of a participant, the participant will move away. The final reason for movement is specific to multiparty conversations. When there are several people in conversation they will tend to form a circular formation. This gives the sense of inclusion to participants and gives them a better view of one another (Kendon, 1990). 3 Social Force Model We present our movement simulation in the context of a social force model. Similar to movement in crowds, the movement of people engaged in conversation is to a large extent reactionary. The reaction is usually automatic and determined by person’s experience, rather than planned for. It is possible to assign a vectorial quantity for each person in conversation, that describes the desired movement direction. This quantity can be interpreted as a social force. This force represents the influence of the environment on the behavior of conversation participant. It is importan</context>
</contexts>
<marker>Kendon, 1990</marker>
<rawString>Adam Kendon, 1990. Spatial Organization in Social Encounters: the F-formation System, pages 209–237. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Padilha</author>
<author>J Carletta</author>
</authors>
<title>A simulation of small group discussion.</title>
<date>2002</date>
<booktitle>Proceedings of EDILOG 2002: Sixth Workshop on the Semantics and Pragmatics of Dialogue,</booktitle>
<pages>117--124</pages>
<marker>Padilha, Carletta, 2002</marker>
<rawString>E. Padilha and J. Carletta. 2002. A simulation of small group discussion. Proceedings of EDILOG 2002: Sixth Workshop on the Semantics and Pragmatics of Dialogue, pages 117–124.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthias Rehm</author>
<author>Elisabeth Andre</author>
<author>Michael Nischt</author>
</authors>
<title>Let’s come together - social navigation behaviors of virtual and real humans.</title>
<date>2005</date>
<booktitle>INTETAIN 2005, LNAI,</booktitle>
<pages>122--131</pages>
<editor>In Mark Maybury et al., editor,</editor>
<publisher>Springer.</publisher>
<contexts>
<context position="2724" citStr="Rehm et al., 2005" startWordPosition="426" endWordPosition="429">— movement of agents in multiparty conversation is more about positioning and repositioning on a local scale. There is also a large body of work on embodied conversational agents (Cassell et al., 2000), which attempt to model realistic conversational non-verbal behaviors. Most of this work focuses on aspects such as gaze, facial expressions, and hand and arm gestures, rather than positioning and orientation in a group. There is some important work on authored presentation agents and avatars for human participants which take account of position in the modelling (Vilhjalmsson and Cassell, 1998; Rehm et al., 2005), but none of this work presents fully explicit algorithms for controlling the positioning and movement behavior of autonomous agents in dynamic conversations. In previous work, it has been shown that incorrect positioning of animated agents has a negative effect on the believability of dynamic group conversation (Jan and Traum, 2005). Research from anthropologists and social psychologists such as the classic work on proxemics by Hall (1968) and positioning by Kendon (1990) provide social reasons to explain how people position themselves in different situations. It is also important to know th</context>
</contexts>
<marker>Rehm, Andre, Nischt, 2005</marker>
<rawString>Matthias Rehm, Elisabeth Andre, and Michael Nischt. 2005. Let’s come together - social navigation behaviors of virtual and real humans. In Mark Maybury et al., editor, INTETAIN 2005, LNAI, pages 122–131. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Albert E Scheflen</author>
</authors>
<title>Micro-territories in human interaction.</title>
<date>1975</date>
<booktitle>World Anthropology: Organization of Behavior in Face-to-Face Interaction,</booktitle>
<pages>159--173</pages>
<editor>In Adam Kendon, Richard M. Harris, and Mary Ritchie Key, editors,</editor>
<location>Mouton, Paris.</location>
<contexts>
<context position="21293" citStr="Scheflen, 1975" startWordPosition="3615" endWordPosition="3616">in Figure 10. Figure 10: After two agents leave the conversation the agents adapt to it by repositioning. 4.3 Effect of proxemics In this test case, we examine the effects when the social zones of the agents are not compatible. This frequently happens when we have people from different cultures with a large difference in distances for social zones. An example would be North Americans compared to Arabs. Americans prefer a much greater inter-personal distance than Arabs. Empirical data shows that in many such situations there is a sort of dance with one agent moving in while another moves away (Scheflen, 1975). Figure 11: Incompatible social zones. Figure 11 shows an example of agents with incompatible social zones. The markings on the ground indicate the minimum and maximum acceptable distance for social zone for each agent. We can see that the agent on the left has a much smaller comfortable distance than the one on the right. In the current position the left agent feels that the other one is too far, while the right agent thinks everything is fine. This causes the left agent to make a step forward. Consequently by doing so he steps into personal zone of the right agent. Now the left agent is sat</context>
</contexts>
<marker>Scheflen, 1975</marker>
<rawString>Albert E. Scheflen. 1975. Micro-territories in human interaction. In Adam Kendon, Richard M. Harris, and Mary Ritchie Key, editors, World Anthropology: Organization of Behavior in Face-to-Face Interaction, pages 159–173. Mouton, Paris.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Shao</author>
<author>Demetri Terzopoulos</author>
</authors>
<title>Autonomous pedestrians.</title>
<date>2005</date>
<booktitle>In SCA ’05: Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation,</booktitle>
<pages>pages</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1905" citStr="Shao and Terzopoulos, 2005" startWordPosition="294" endWordPosition="298">ever, people will often join and leave groups and often move from one group to another. Groups themselves may fragment into subgroups, and smaller groups sometimes merge into one larger group. Participants in these groups adapt their positions and orientations to account for these circumstances, often without missing a beat or otherwise disrupting their conversations. 59 In order to create believable social environments for games or training simulations we need agents that can perform these same kinds of behaviors in a realistic way. There are a number of crowd simulations (Sung et al., 2004; Shao and Terzopoulos, 2005; Still, 2000; Helbing and Moln´ar, 1995), but most of these place an emphasis on large-scale movement of agents and do not model the low-level aspects of conversational interaction in a realistic way — movement of agents in multiparty conversation is more about positioning and repositioning on a local scale. There is also a large body of work on embodied conversational agents (Cassell et al., 2000), which attempt to model realistic conversational non-verbal behaviors. Most of this work focuses on aspects such as gaze, facial expressions, and hand and arm gestures, rather than positioning and </context>
</contexts>
<marker>Shao, Terzopoulos, 2005</marker>
<rawString>Wei Shao and Demetri Terzopoulos. 2005. Autonomous pedestrians. In SCA ’05: Proceedings of the 2005 ACM SIGGRAPH/Eurographics symposium on Computer animation, pages 19–28, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Keith Still</author>
</authors>
<title>Crowd Dynamics.</title>
<date>2000</date>
<tech>Ph.D. thesis,</tech>
<institution>Warwick University.</institution>
<contexts>
<context position="1918" citStr="Still, 2000" startWordPosition="299" endWordPosition="300"> and leave groups and often move from one group to another. Groups themselves may fragment into subgroups, and smaller groups sometimes merge into one larger group. Participants in these groups adapt their positions and orientations to account for these circumstances, often without missing a beat or otherwise disrupting their conversations. 59 In order to create believable social environments for games or training simulations we need agents that can perform these same kinds of behaviors in a realistic way. There are a number of crowd simulations (Sung et al., 2004; Shao and Terzopoulos, 2005; Still, 2000; Helbing and Moln´ar, 1995), but most of these place an emphasis on large-scale movement of agents and do not model the low-level aspects of conversational interaction in a realistic way — movement of agents in multiparty conversation is more about positioning and repositioning on a local scale. There is also a large body of work on embodied conversational agents (Cassell et al., 2000), which attempt to model realistic conversational non-verbal behaviors. Most of this work focuses on aspects such as gaze, facial expressions, and hand and arm gestures, rather than positioning and orientation i</context>
</contexts>
<marker>Still, 2000</marker>
<rawString>G. Keith Still. 2000. Crowd Dynamics. Ph.D. thesis, Warwick University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mankyu Sung</author>
<author>Michael Gleicher</author>
<author>Stephen Chenney</author>
</authors>
<title>Scalable behaviors for crowd simulation.</title>
<date>2004</date>
<journal>Computer Graphics Forum,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="1877" citStr="Sung et al., 2004" startWordPosition="290" endWordPosition="293"> are not fixed, however, people will often join and leave groups and often move from one group to another. Groups themselves may fragment into subgroups, and smaller groups sometimes merge into one larger group. Participants in these groups adapt their positions and orientations to account for these circumstances, often without missing a beat or otherwise disrupting their conversations. 59 In order to create believable social environments for games or training simulations we need agents that can perform these same kinds of behaviors in a realistic way. There are a number of crowd simulations (Sung et al., 2004; Shao and Terzopoulos, 2005; Still, 2000; Helbing and Moln´ar, 1995), but most of these place an emphasis on large-scale movement of agents and do not model the low-level aspects of conversational interaction in a realistic way — movement of agents in multiparty conversation is more about positioning and repositioning on a local scale. There is also a large body of work on embodied conversational agents (Cassell et al., 2000), which attempt to model realistic conversational non-verbal behaviors. Most of this work focuses on aspects such as gaze, facial expressions, and hand and arm gestures, </context>
</contexts>
<marker>Sung, Gleicher, Chenney, 2004</marker>
<rawString>Mankyu Sung, Michael Gleicher, and Stephen Chenney. 2004. Scalable behaviors for crowd simulation. Computer Graphics Forum, 23(3):519–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hannes Hogni Vilhjalmsson</author>
<author>Justine Cassell</author>
</authors>
<title>Bodychat: autonomous communicative behaviors in avatars.</title>
<date>1998</date>
<booktitle>In AGENTS ’98: Proceedings of the second international conference on Autonomous agents,</booktitle>
<pages>269--276</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2704" citStr="Vilhjalmsson and Cassell, 1998" startWordPosition="422" endWordPosition="425"> interaction in a realistic way — movement of agents in multiparty conversation is more about positioning and repositioning on a local scale. There is also a large body of work on embodied conversational agents (Cassell et al., 2000), which attempt to model realistic conversational non-verbal behaviors. Most of this work focuses on aspects such as gaze, facial expressions, and hand and arm gestures, rather than positioning and orientation in a group. There is some important work on authored presentation agents and avatars for human participants which take account of position in the modelling (Vilhjalmsson and Cassell, 1998; Rehm et al., 2005), but none of this work presents fully explicit algorithms for controlling the positioning and movement behavior of autonomous agents in dynamic conversations. In previous work, it has been shown that incorrect positioning of animated agents has a negative effect on the believability of dynamic group conversation (Jan and Traum, 2005). Research from anthropologists and social psychologists such as the classic work on proxemics by Hall (1968) and positioning by Kendon (1990) provide social reasons to explain how people position themselves in different situations. It is also </context>
</contexts>
<marker>Vilhjalmsson, Cassell, 1998</marker>
<rawString>Hannes Hogni Vilhjalmsson and Justine Cassell. 1998. Bodychat: autonomous communicative behaviors in avatars. In AGENTS ’98: Proceedings of the second international conference on Autonomous agents, pages 269–276, New York, NY, USA. ACM Press.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>