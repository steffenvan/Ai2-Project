<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000013">
<title confidence="0.9983175">
Automatically Creating Bilingual Lexicons for Machine
Translation from Bilingual Text
</title>
<author confidence="0.737308">
Davide Turcato
</author>
<affiliation confidence="0.769108666666667">
Natural Language Lab TCC Communications
School of Computing Science 100-6722 Oldfield Road
Simon Fraser University Victoria, BC
</affiliation>
<address confidence="0.9627245">
Burnaby, BC, V5A 1S6 V8M 2A3
Canada Canada
</address>
<email confidence="0.88991">
turkOcs.sfu.ca turkOtcc.bc.ca
</email>
<sectionHeader confidence="0.995247" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999938888888889">
A method is presented for automatically aug-
menting the bilingual lexicon of an existing Ma-
chine Translation system, by extracting bilin-
gual entries from aligned bilingual text. The
proposed method only relies on the resources
already available in the MT system itself. It is
based on the use of bilingual lexical templates
to match the terminal symbols in the parses of
the aligned sentences.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9999905">
A novel approach to automatically building
bilingual lexicons is presented here. The term
bilingual lexicon denotes a collection of complex
equivalences as used in Machine Translation
(MT) transfer lexicons, not just word equiva-
lences. In addition to words, such lexicons in-
volve syntactic and semantic descriptions and
means to perform a correct transfer between the
two sides of a bilingual lexical entry.
A symbolic, rule-based approach of the parse-
parse-match kind is proposed. The core idea
is to use the resources of bidirectional transfer
MT systems for this purpose, taking advantage
of their features to convert them to a novel use.
In addition to having them use their bilingual
lexicons to produce translations, it is proposed
to have them use translations to produce bilin-
gual lexicons. Although other uses might be
conceived, the most appropriate use is to have
an MT system automatically augment its own
bilingual lexicon from a small initial sample.
The core of the described approach consists
of using a set of bilingual lexical templates in
matching the parses of two aligned sentences
and in turning the lexical equivalences thus es-
tablished into new bilingual lexical entries.
</bodyText>
<sectionHeader confidence="0.9976" genericHeader="method">
2 Theoretical framework
</sectionHeader>
<bodyText confidence="0.999916794871795">
The basic requirement that an MT system
should meet for the present purpose is to be
bidirectional. Bidirectionality is required in or-
der to ensure that both source and target gram-
mars can be used for parsing and that transfer
can be done in both directions. More precisely,
what is relevant is that the input and output to
transfer be the same kind of structure.
Moreover, the proposed method is most pro-
ductive with a lexicalist MT system (White-
lock, 1994). The proposed application is con-
cerned with producing bilingual lexical knowl-
edge and this sort of knowledge is the only type
of bilingual knowledge required by lexicalist sys-
tems. Nevertheless, it is also conceivable that
the present approach can be used with a non-
lexicalist transfer system, as long as the system
is bidirectional. In this case, only the lexical
portion of the bilingual knowledge can be au-
tomatically produced, assuming that the struc-
tural transfer portion is already in place. In
the rest of this paper, a lexicalist MT system
will be assumed and referred to. For the spe-
cific implementation described here and all the
examples, we will refer to an existing lexicalist
English-Spanish MT system (Popowich et al.,
1997).
The main feature of a lexicalist MT system is
that it performs no structural transfer. Transfer
is a mapping between a bag of lexical items used
in parsing (the source bag) and a corresponding
bag of target lexical items (the target bag), to
be used in generation. The source bag actu-
ally contains more information than the corre-
sponding bag of lexical items before parsing. Its
elements get enriched with additional informa-
tion instantiated during the parsing process. In-
formation of fundamental importance included
therein is a system of indices that express de-
</bodyText>
<page confidence="0.995687">
1299
</page>
<bodyText confidence="0.9987712">
pendencies among lexical items. Such depen-
dencies are transferred to the target bag and
used to constrain generation. The task of gen-
eration is to find an order in which the lexical
items can be successfully parsed.
</bodyText>
<sectionHeader confidence="0.975978" genericHeader="method">
3 Bilingual templates
</sectionHeader>
<bodyText confidence="0.9840415">
A bilingual template is a bilingual entry in which
words are left unspecified. E.g.:
</bodyText>
<equation confidence="0.988432">
(1) _ : : (L , Ocount_noun(A)
_ : : (R,Onoun(A))
\ \ trans_noun (L , R) .
</equation>
<bodyText confidence="0.988789578947368">
Here, a :&apos; operator connects a word (a vari-
able, in a template) to a description, con-
nects the left and right sides of the entry, &apos;W
introduces a transfer macro, which takes two
descriptions as arguments and performs some
additional transfer (Turcato et al., 1997). De-
scriptions are mainly expressed by macros, in-
troduced by a &apos;0&apos; operator. The macro argu-
ments are indices, as used in lexicalist transfer.
Templates have been widely used in MT
(Buschbeck-Wolf and Dorna, 1997), particu-
larly in the Example-Based Machine Transla-
tion (EBMT) framework (Kaji et al. (1992),
Giivenir and Tunc (1996)). However, in
EBMT, templates are most often used to model
sentence-level correspondences, rather then lex-
ical equivalences. Consequently, in EBMT the
relation between lexical equivalences and tem-
plates is the reverse of what is being proposed
here. In EBMT, lexical equivalences are as-
sumed and (sentential) templates are inferred
from them. In the present framework, sentential
correspondences (in the form of possible combi-
nations of lexical templates) are assumed and
lexical equivalences are inferred from them.
In a lexicalist approach, the notion of bilin-
gual lexical entry, and thus that of bilingual
template, must be intended broadly. Multiword
entries can exist. They can express dependen-
cies among lexical items, thus being suitable for
expressing phrasal equivalences. In brief, bilin-
gual lexical entries can exhaustively cover all the
bilingual information needed in transfer.
In a lexicalist MT system, transfer is accom-
plished by finding a bag of bilingual entries par-
titioning the source bag. The source side of each
entry (in the rest of this paper: the left hand
side) corresponds to a cell of the partition. The
</bodyText>
<listItem confidence="0.630138">
union of the target sides of the entries consti-
tutes the target bag. E.g.:
(2) a. Source bag:
</listItem>
<equation confidence="0.983015111111111">
Sw2::Sd2, Sw3::Sd3}
b. Bilingual entries:
&amp; Sw3::Sd3
Tdi &amp; Tw2:: Td2,
Sw2::Sd2 4-4
TW3 Td3 &amp; TW4 Td4
c. Target bag:
Tw2:: Td2, Tw3:: Td3,
Tw4:: Td4}
</equation>
<bodyText confidence="0.999977107142857">
where each Swi::Sdi and Twi::Tdi are, respec-
tively, a source and target &lt; Word,Description&gt;
pair. In addition, the bilingual entries must sat-
isfy the constraints expressed by indices in the
source and target bags. The same information
can be used to find (2b), given (2a) and (2c).
Any bilingual lexicon is partitioned by a set of
templates. The entries in each equivalence class
only differ by their words. A bilingual lexical en-
try can thus be viewed as a triple &lt;Sw,Tw,T&gt;,
where Sw is a list of source words, Tw a list of
target words, and T a template. A set of such
bilingual templates can be intuitively regarded
as a &apos;transfer grammar&apos;. A grammar defines all
the possible sequences of pre-terminal symbols,
i.e. all the possible types of sentences. Anal-
ogously, a set of bilingual templates defines all
the possible translational equivalences between
bags of pre-terminal symbols, i.e. all the possi-
ble equivalences between types of sentences.
Using this intuition, the possibility is ex-
plored of analyzing a pair of such bags by means
of a database of bilingual templates, to find a
bag of templates that correctly accounts for the
translational equivalence of the two bags, with-
out resorting to any information about words.
In the example (2), the following bag of tem-
plates would be the requested solution:
</bodyText>
<equation confidence="0.7517305">
(3) {_::Sdi &amp; _::Sd3 : Td1 &amp; Td2
Sd2 4-4 Td3 &amp; Td4
</equation>
<bodyText confidence="0.9641225">
Equivalences between (bags of) words are au-
tomatically obtained as a result of the process,
whereas in translating they are assumed and
used to select the appropriate bilingual entries.
</bodyText>
<page confidence="0.97674">
1300
</page>
<table confidence="0.998522777777778">
Templates Entries Coverage
1 5683 33.9 %
2 8726 52.1 %
3 10710 63.9 %
4 12336 73.6 %
5 13609 81.2 %
50 15473 92.3 %
500 16338 97.5 %
922 16760 100.0 %
</table>
<tableCaption confidence="0.999801">
Table 1: Incremental template coverage
</tableCaption>
<bodyText confidence="0.999978516129032">
The whole idea is based on the assumption
that a lexical item&apos;s description and the con-
straints on its indices are sufficient in most cases
to uniquely identify a lexical item in a parse out-
put bag. Although exceptions could be found
(most notably, two modifiers of the same cate-
gory modifying the same head), the idea is vi-
able enough to be worth exploring.
The impression might arise that it is difficult
and impractical to have a set of templates avail-
able in advance. However, there is empirical ev-
idence to the contrary. A count on the MT sys-
tem used here showed that a restricted number
of templates covers a large portion of a bilingual
lexicon. Table 1 shows the incremental cover-
age. Although completeness is hard to obtain,
a satisfactory coverage can be achieved with a
relatively small number of templates.
In the implementation described here, a set of
templates was extracted from the MT bilingual
lexicon and used to bootstrap further lexical
development. The whole lexical development
can be seen as an interactive process involv-
ing a bilingual lexicon and a template database.
Templates are initially derived from the lexi-
con, new entries are successively created using
the templates. Iteratively, new entries can be
manually coded when the automatic procedure
is lacking appropriate templates and new tem-
plates extracted from the manually coded en-
tries can be added to the template database.
</bodyText>
<sectionHeader confidence="0.983846" genericHeader="method">
4 The algorithm
</sectionHeader>
<bodyText confidence="0.958255260869565">
In this section the algorithm for creating bilin-
gual lexical entries is described, along with a
sample run. The procedure was implemented
in Prolog, as was the MT system at hand. Ba-
sically, a set of lexical entries is obtained from a
pair of sentences by first parsing the source and
target sentences. The source bag is then trans-
ferred using templates as transfer rules (plus en-
tries for closed-class words and possibly a pre-
existing bilingual lexicon). The transfer out-
put bag is then unified with the target sentence
parse output bag. lithe unification succeeds,
the relevant information (bilingual templates
and associated words) is retrieved to build up
the new bilingual entries. Otherwise, the sys-
tem backtracks into new parses and transfers.
The main predicate make_entries/3 matches
a source and a target sentence to produce a set
of bilingual entries:
make_entries(Source,Target,Entries):-
parse_source(Source,Deriv1),
parse_target(Target,Deriv2),
transfer(Derivl,Deriv3),
get_bag(Deriv2,Bag2),
get_bag(Deriv3,Bag3),
match_bags(Bag2,Bag3,Bag4),
get_bag(Derivl,Bagl),
make_be_info(Bagi,Bag4,Deriv3,Be),
be_info_to_entries(Be,Entries).
Each Derivn variable points to a buffer where
all the information about a specific derivation
(parse or transfer) is stored and each Bagn vari-
able refers to a bag of lexical items. Each step
will be discussed in detail in the rest of the sec-
tion. A sample run will be shown for the fol-
lowing English-Spanish pair of sentences:
(4) a. the fat man kicked out the black
dog.
b. el hombre gordo echo el perro
negro.
In the sample session no bilingual lexicon was
used for content words. Only a bilingual lexi-
con for closed class words and a set of bilingual
templates were used. Therefore, new bilingual
entries were obtained for all the content words
(or phrases) in the sentences.
</bodyText>
<subsectionHeader confidence="0.981385">
4.1 Source sentence parse
</subsectionHeader>
<bodyText confidence="0.7285634">
The parse of the source sentence is performed
by parse_source/2. The parse tree is shown in
Fig. 1. Since only lexical items are relevant for
the present purposes, only pre-terminal nodes
in the tree are labeled.
</bodyText>
<page confidence="0.847975">
1301
</page>
<figure confidence="0.999806636363637">
1
el
A
1 1
hombre gordo
V..........„.—..„........„
I
ech6 D,
I N A
el 1
1 1
perro negro
I A N
the 1 1
fat man
V AdvP
1 1
kicked out
1 A
the
1 1
black dog
</figure>
<figureCaption confidence="0.999469">
Figure 1: Source sentence parse tree.
</figureCaption>
<table confidence="0.754351888888889">
Id Word Cat Indices
1 the determiner [0]
2 fat adjective [0]
3 man noun [0]
4 kick trans_verb [10,0,9]
5 out advparticle [10]
6 the determiner [9]
7 black adjective [9]
8 dog noun [9]
</table>
<figureCaption confidence="0.992977">
Figure 2: Source sentence parse output bag.
</figureCaption>
<bodyText confidence="0.9922945">
Fig. 2 shows, in succint form, the relevant
information from the source bag, i.e. the bag
resulting from parsing the source sentence. All
the syntactic and semantic information has been
omitted and replaced by a category label. What
is relevant here is the way the indices are set, as
a result of parsing. The words {the ,f at ,man}
are tied together and so are {kick , out} and
{the ,black ,dog}. Moreover, the indices of
&apos;kick&apos; show that its second index is tied to its
subject, {the ,f at ,man}, and its third index is
tied to its object, {the ,black ,dog}.
</bodyText>
<subsectionHeader confidence="0.921711">
4.2 Target sentence parse
</subsectionHeader>
<bodyText confidence="0.999899428571428">
The parse of the target sentence is performed
by parse_target/2. Fig. 3 and 4 show,
respectively, the resulting tree and bag. In
an analogous manner to what is seen in
the source sentence, {el ,hombre gordo} and
{el ,perro ,negro} are, respectively, the sub-
ject and the object of &apos;echo&apos;.
</bodyText>
<subsectionHeader confidence="0.843049">
4.3 Transfer
</subsectionHeader>
<bodyText confidence="0.999309">
The result of parsing the source sentence is used
by transfer/2 to create a translationally equiv-
alent target bag. Fig. 5 shows the result. Trans-
fer is performed by consulting a bilingual lexi-
con, which, in the present case, contained en-
</bodyText>
<figureCaption confidence="0.569013">
Figure 3: Target sentence parse tree.
</figureCaption>
<figure confidence="0.513598625">
Id Word Cat Indices
1 el d [0]
2 hombre n [0]
3 gordo adj [0]
4 echar v [1,0,13]
5 el d [13]
6 perro n [13]
7 negro adj [13]
</figure>
<figureCaption confidence="0.999653">
Figure 4: Target sentence parse output bag.
</figureCaption>
<bodyText confidence="0.99834225">
tries for closed class words (e.g. an entry map-
ping &apos;the&apos; to &apos;el&apos;) and templates for content
words. The templates relevant to our example
are the following:
</bodyText>
<listItem confidence="0.978693888888889">
(5) a. _ : : @adj (A)
4-* &apos;word(adj/adj ,1) &apos; : :Oadj (A) .
b. _ : : (L ,@count_noun(A))
4-* &apos; word(cn/n , 1) &apos; : : (R,Onoun(A) )
\ \trans_noun(L ,R) .
c. _ : : (L Atrans_verb (A ,B,C))
&amp; _ : : @advparticle (A)
&apos; word (tv+adv/tv , 1) &apos; : :
(R,Overb_acc(A,B,C))
</listItem>
<table confidence="0.996348111111111">
\ \trans_verb(L ,R) .
Id Word Cat Indices
2-1 el d [A]
3-2 word(adj/adj,1) adj [A]
4-3 word(cn/n,l) [A]
1-4 word(tv+adv/tv,1) [B , A , I]
5-6 el d [I]
6-7 word(adj/adj,1) adj [I]
7-8 word(cn/n,1) [I]
</table>
<figureCaption confidence="0.969953">
Figure 5: Transfer output bag.
</figureCaption>
<page confidence="0.981086">
1302
</page>
<bodyText confidence="0.999978727272728">
Bilingual templates are simply bilingual en-
tries with words replaced by variables. Actually,
on the target side, words are replaced by labels
of the form word(Ti,Position), where Ti is a
template identifier and Position identifies the
position of the item in the right hand side of the
template. Thus, a label word (adj /adj ,1) iden-
tifies the first word on the right hand side of the
template that maps an adjective to an adjective.
Such labels are just implement ational technical-
ities that facilitate the retrieval of the relevant
information when a lexical entry is built up from
a template, but they have no role in the match-
ing procedure. For the present purposes they
can entirely be regarded as anonymous variables
that can unify with anything, exactly like their
source counterparts.
After transfer, the instances of the templates
used in the process are coindexed in some way,
by virtue of their unification with the source bag
items. This is analogous to what happens with
bilingual entries in the translation process.
</bodyText>
<subsectionHeader confidence="0.977603">
4.4 Target bag matching
</subsectionHeader>
<bodyText confidence="0.966420888888889">
The predicate get_bag/2 retrieves a bag of lex-
ical items associated with a derivation. There-
fore, Bag2 and Bag3 will contain the bags of
lexical items resulting, respectively, from pars-
ing the target sentence and from transfer.
The crucial step is the matching between the
transfer output bag and the target sentence
parse output bag. The predicate match_bags/3
tries to unify the two bags (returning the result
in Bag4). A successful unification entails that
the parse and transfer of the source sentence
are consistent with the parse of the target sen-
tence. In other words, the bilingual rules used
in transfer correctly map source lexical items
into target lexical items. Therefore, the lexi-
cal equivalences newly established through this
process can be asserted as new bilingual entries.
In the matching process, the order in which
the elements are listed in the figures is &apos;irrele-
vant, since the objects at hand are bags, i.e.
unordered collections. A successful match only
requires the existence of a one-to-one mapping
between the two bags, such that:
(i) the respective descriptions, here repre-
sented by category labels, are unifiable;
(ii) a further one-to-one mapping between the
indices in the two bags is induced.
The following mapping between the transfer
output bag (Fig. 5) and the target sentence
parse output bag (Fig. 4) will therefore succeed:
{&lt;2-1,1&gt;,&lt;3-2,3&gt;,&lt;4-3,2&gt;,&lt;1-4,4&gt;,
&lt;5-6,5&gt;,&lt;6-7,7&gt;,&lt;7-8,6&gt;}
In fact, in addition to correctly unifying the
descriptions, it induces the following one-to-one
mapping between the two sets of indices:
{&lt;A,0&gt;,&lt;B,1&gt;,&lt;I,13&gt;}
</bodyText>
<subsectionHeader confidence="0.767595">
4.5 Bilingual entries creation
</subsectionHeader>
<bodyText confidence="0.999382928571429">
The rest of the procedure builds up lexical en-
tries for the newly discovered equivalences and
is implementation dependent. First, the source
bag is retrieved in Bag 1. Then, make_be_info/4
links together information from the source bag,
the target bag (actually, its unification with
the target sentence parse bag) and the trans-
fer derivation, to construct a list of terms (the
variable Be) containing the information to cre-
ate an entry. Each such term has the form
be(Sw,Tw,Ti), where Sw is a list of source
words, Tw is a list of target words and Ti is
a template identifier. In our example, the fol-
lowing be/3 terms are created:
</bodyText>
<listItem confidence="0.9445326">
(6) a. be( [fat] , [gordo] ,adj/adj)
b. be( [man] , [hombre] ,cn/n)
c. be( [kick,out] , [echar] ,tv+adv/tv)
d. be([black] ,[negro] ,adj/adj)
e. be( [dog] , [perro] ,cn/n)
</listItem>
<bodyText confidence="0.99467625">
Each be/3 term is finally turned
into a bilingual entry by the predicate
be_info_to_entries/2. The following bilin-
gual entries are created:
</bodyText>
<listItem confidence="0.910602">
(7) a. fat : :Oadj (A)
4-+ gordo : :Oadj (A) .
b. man : : (D,Ocount_noun(C))
hombre ::(B4Onoun(C))
\\trans_noun(D,B).
c. kick ::(I,Otrans_verb(F,G,H))
&amp; out ::@advparticle(F)
echar ::(E,@verb_acc(F,G,H))
\\trans_verb(I,E).
</listItem>
<page confidence="0.813625">
1303
</page>
<listItem confidence="0.9966686">
d. black : :@adj (J)
4-* negro : : @adj (J) .
e. dog : : (M, Ocount_noun (L) )
4-&gt; hombre : : (K , Onoun(L) )
\\trans_noun(M,K) .
</listItem>
<bodyText confidence="0.9993791">
If a pre-existing bilingual lexicon is in use,
bilingual entries are prioritized over bilingual
templates. Consequently, only new entries are
created, the others being retrieved from the ex-
isting bilingual lexicon. Incidentally, it should
be noted that a new entry is an entry which
differs from any existing entry on either side.
Therefore, different entries are created for dif-
ferent senses of the same word, as long as the
different senses have different translations.
</bodyText>
<sectionHeader confidence="0.896891" genericHeader="method">
5 Shortcomings and future work
</sectionHeader>
<bodyText confidence="0.999937090909091">
In matching a pair of bags, two kinds of ambigu-
ity could lead to multiple results, some of which
are incorrect. Firstly, as already mentioned, a
bag could contain two lexical items with unifi-
able descriptions (e.g. two adjectives modify-
ing the same noun), possibly causing an incor-
rect match. Secondly, as the bilingual template
database grows, the chance of overlaps between
templates also grows. Two different templates
or combinations of templates might cover the
same input and output. A case in point is that
of a phrasal verb or an idiom covered by both a
single multi-word template and a compositional
combination of simpler templates.
As both potential sources of error can be au-
tomatically detected, a first step in tackling the
problem would be to block the automatic gener-
ation of the entries involved when a problematic
case occurs, or to have a user select the correct
candidate. In this way the correctness of the
output is guaranteed. The possible cost is a
lack of completeness, when no user intervention
is foreseen.
Furthermore, techniques for the automatic
resolution of template overlaps are under inves-
tigation. Such techniques assume the presence
of a bilingual lexicon. The information con-
tained therein is used to assign preferences to
competing candidate entries, in two ways.
Firstly, templates are probabilistically
ranked, using the existing bilingual lexicon
to estimate probabilities. When the choice
is between single entries, the ranking can be
performed by counting the frequency of each
competing template in the lexicon. The entry
with the most frequent template is chosen.
Secondly, heuristics are used to assign pref-
erences, based on the presence of pre-existing
entries related in some way to the candidate
entries. This technique is suited for resolv-
ing ambiguities where multiple entries are in-
volved. For instance, given the equivalence
between &apos;kick the bucket&apos; and estirar la
pata&apos;, and the competing candidates
</bodyText>
<listItem confidence="0.3800725">
(8) a. {kick &amp; bucket 4-* estirar &amp; pata}
b. {kick 4-* estirar, , bucket pata}
</listItem>
<bodyText confidence="0.9997384">
the presence of an entry &apos;bucket 4-* balde&apos; in
the bilingual lexicon might be a clue for prefer-
ring the idiomatic interpretation. Conversely, if
the hypothetical entry &apos;bucket 4-* pata&apos; were
already in the lexicon, the compositional inter-
pretation might be preferred.
Finally, efficiency is also dependant on the re-
strictiveness of grammars. The more grammars
overgenerate, the more the combinatoric inde-
terminacy in the matching process increases.
However, overgeneration is as much a problem
for translation as for bilingual generation. In
other words, no additional requirement is placed
on the MT system which is not independently
motivated by translation alone.
</bodyText>
<sectionHeader confidence="0.996548" genericHeader="method">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999987">
The parse-parse-match approach to automati-
cally building bilingual lexicons in not novel.
Proposals have been put forward, e.g., by Sadler
and Vendelmans (1990) and Kaji et al. (1992).
Wu (1995) points out some possible difficul-
ties of the parse-parse-match approach. Among
them, the facts that &amp;quot;appropriate, robust,
monolingual grammars may not be available&amp;quot;
and &amp;quot;the grammars may be incompatible across
languages&amp;quot; (Wu, 1995, 355). More generally,
in bilingual lexicon development there is a ten-
dency to minimize the need for linguistic re-
sources specifically developed for the purpose.
In this view, several proposals tend to use statis-
tical, knowledge-free methods, possibly in com-
bination with the use of existing Machine Read-
able Dictionaries (see, e.g., Klavans and Tzouk-
ermann (1995), which also contains a survey of
related proposals, pages 195-196).
</bodyText>
<page confidence="0.992623">
1304
</page>
<bodyText confidence="0.99999035483871">
The present proposal tackles the problem
from a different and novel perspective. The ac-
knowledgment that MT is the main application
domain to which bilingual resources are relevant
is taken as a starting point. The existence of an
MT system, for which the bilingual lexicon is
intended, is explicitly assumed. The potential
problems due to the need for linguistic resources
are by-passed by having the necessary resources
available in the MT system. Rather than doing
away with linguistic knowledge, the pre-existing
resources of the pursued application are utilized.
An approach like the present can be most ef-
fectively adopted to develop tools allowing MT
systems to automatically build their own bilin-
gual lexicons. A tool of this sort would use
no extra resources in addition to those already
available in the MT system itself. Such a tool
would take a small sample of a bilingual lexicon
and use it to bootstrap the automatic devel-
opment of a large lexicon. It is worth noting
that the bilingual pairs thus produced would be
complete bilingual entries that could be directly
incorporated in the MT system, with no post-
editing or addition of information.
The only requirement placed by the present
approach on MT systems is that they be bi-
directional. Therefore, although aimed at the
development of specific applications for specific
MT systems, the approach is general enough to
apply to a wide range of MT systems.
</bodyText>
<sectionHeader confidence="0.995138" genericHeader="method">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.99974925">
This research was supported by TCC Com-
munications, by a Collaborative Research and
Development Grant from the Natural Sciences
and Engineering Research Council of Canada
(NSERC), and by the Institute for Robotics
and Intelligent Systems. The author would like
to thank Fred Popowich and John Grayson for
their comments on earlier versions of this paper.
</bodyText>
<sectionHeader confidence="0.997314" genericHeader="conclusions">
References
</sectionHeader>
<reference confidence="0.953959056603774">
B. Buschbeck-Wolf and M. Dorna. 1997. Using
hybrid methods and resources in semantic-
based transfer. In Proceedings of the Interna-
tional Conference &apos;Recent Advances in Nat-
ural Language Processing&apos;, pages 104-111,
Tzigov Chark, Bulgaria.
H. A. Giivenir and A. Tunc. 1996. Corpus-
based learning of generalized parse tree rules
for translation. In G. McCalla, editor, Ad-
vances in Artificial Intelligence — 11th Bien-
nial Conference of the Canadian Society for
Computational Studies of Intelligence, pages
121-132. Springer, Berlin.
H. Kaji, Y. Kida, and Y. Morimoto. 1992.
Learning translation templates from bilin-
gual text. In Proceedings of the 14th Inter-
national Conference on Computational Lin-
guistics, pages 672-678, Nantes, France.
J. Klavans and E. Tzoukermann. 1995. Com-
bining corpus and machine-readable dictio-
nary data for building bilingual lexicons. Ma-
chine Translation, 10:185-218.
F. Popowich, D. Turcato, 0. Laurens,
P. McFetridge, J. D. Nicholson, P. Mc-
Givern, M. Corzo-Pena, L. Pidruchney, and
S. MacDonald. 1997. A le)cicalist approach
to the translation of colloquial text. In Pro-
ceedings of the 7th International Conference
on Theoretical and Methodological Issues in
Machine Translation, pages 76-86, Santa Fe,
New Mexico, USA.
V. Sadler and R. Vendelmans. 1990. Pilot im-
plementation of a bilingual knowledge bank.
In Proceedings of the 13th International Con-
ference on Computational Linguistics, pages
449-451, Helsinki, Finland.
D. Turcato, 0. Laurens, P. McFetridge, and
F. Popowich. 1997. Inflectional information
in transfer for lexicalist MT. In Proceed-
ings of the International Conference &apos;Recent
Advances in Natural Language Processing&apos;,
pages 98-103, Tzigov Chark, Bulgaria.
P. Whitelock. 1994. Shake and bake trans-
lation. In C.J. Rupp, M.A. Rosner, and
R.L. Johnson, editors, Constraints, Language
and Computation, pages 339-359. Academic
Press, London.
D. Wu. 1995. Grammarless extraction of
phrasal translation examples from parallel
texts. In Proceedings of the Sixth Interna-
tional Conference on Theoretical and Method-
ological Issues in Machine Translation, pages
354-372, Leuven, Belgium.
</reference>
<page confidence="0.997741">
1305
</page>
<sectionHeader confidence="0.971177" genericHeader="references">
Resumo*
</sectionHeader>
<bodyText confidence="0.998879594059406">
Ni prezentas metodon por automate krei dul-
ingvajn leksikojn por perkomputila tradukado
el dulingvaj tekstoj. La kerna ideo estas ke la
rimedoj de dudirektaj, transiraj traduksistemoj
ebligas ne nur uzi dulingvajn leksikajn ekviva-
lentojn por starigi dulingvajn frazajn ekvivalen-
tojn, sed ankail, inverse, uzi frazajn ekvivalen-
tojn por starigi leksikajn ekvivalentojn. La plej
tatiga apliko de tia ideo estas la evoluigo de
iloj per kiuj komputilaj traduksistemoj auto-
mate pligrandigu sian dulingvan leksikon. La
kerno de tia metodo estas la uzo de dulingvaj
leksikaj gablonoj por kongruigi la analizojn de
intertradukeblaj frazoj. La leksikajn ekvivalen-
tojn tiel starigitajn oni aldonas al la dulingva
leksiko kiel pliajn dulingvajn leksikerojn.
Tia metodo postulas ke dudirektaj traduk-
sistemoj estu uzataj. Necesas ke ambaii gra-
matikoj, kaj la fonta kaj la cela, estu uzeblaj
por ambal procezoj, kaj analizado kaj gener-
ado. Krome, necesas ke la enigo kaj la eligo de
la transirprocezo estu samspecaj reprezentajoj.
Tia metodo estas plej produktiva êe leksikismaj
traduksistemoj (Whitelock, 1994), sed i estas
same aplikebla al dudirektaj neleksikismaj sis-
temoj. Ni tamen pritraktos nur unuaspecajn
sistemojn. La plej grava trajto de leksikismaj
sistemoj estas ke ili ne uzas strukturan trans-
iron. En tiaj sistemoj, transiro estas jeto de
fonta plur&apos;aro de leksikaj unuoj al samspeca cela
plur&apos;aro. La jeto estas difinita per dulingva lek-
siko, kies leksikeroj povas esti ankau plurvortaj.
Semantikajn dependojn inter fontleksikaj unuoj
oni reprezentas per komunaj indicoj, kiuj estas
transigataj al korespondaj celleksikaj unuoj. La
tasko de generado estas ordigi la celleksikajn un-
uojn en gramatikan celfrazon plenumantan la
transigitajn semantikajn dependojn.
Dulingvaj gablonoj estas dulingvaj leksikeroj
en kiuj variabloj anstatalias vortojn. Ciu ajn
dulingva leksiko estas partigata per dulingva
gablonaro. Ciuj eroj en sama ekvivalentklaso
de la partigo diferencas nur pro siaj vortoj.
Tial oni povas rigardi dulingvan leksikeron kiel
triopon konsistigatan el fonta vortlisto, cela
vortlisto kaj gablono. Dulingva gablonaro es-
tas rigardebla kiel `transira gramatiko&apos; difinanta
aiujn eblajn tradukajn ekvivalentojn. LaU tia
intuicio, ni esploras la eblecon analizi paron de
*La anoro dankas Brian Kaneen pro lingva konsilo.
fonta kaj cela plur&apos;aroj per datumbazo de dul-
ingvaj gablonoj, celante trovi gablonpluearon
kin korekte reprezentu tradukajn ekvivalentojn
inter la du plur&apos;aroj, sen uzi informon pri vortoj.
Ekvivalentoj inter vortoj automate rezultas el la
procezo. Atingi necesan gablonaron por tia celo
ne estas malfacila tasko. Nia leksikisma traduk-
sistemo empirie evidentigas ke malgranda nom-
bro de gablonoj kovras grandan parton de la dul-
ingva leksiko. En nia realigajo, gablonaro estis
ekstraktita el la dulingva leksiko de la traduk-
sistemo kaj poste uzita por ekfunkciigi plian lek-
sikan evoluigon. La tutan evoluigon de dulingva
leksiko oni povas rigardi kiel interagan procezon
laul tiaspeca modelo.
La algoritmo por krej novajn dulingvajn lek-
sikerojn konsistas el kvin pagoj: (i—E) Fonta
kaj cela frazoj estas analizataj. Fontanal-
iza kaj celanaliza plur&apos;aroj rezultas el la pro-
cezo; (iii) Transiro el la fontanaliza plur&apos;aro es-
tas plenumata, uzante dulingvan leksikon por
fermklasaj vortoj kaj dulingvan gablonaron por
malfermklasaj vortoj. La rezulto estas transira
celplur&apos;aro; (iv) La transira celplur&apos;aro kaj la
celanaliza plur&apos;aro estas kongruigataj. Sukcesa
unuigo sekvigas ke la dulingvaj eroj uzitaj en
la transiro korekte jetas la fontan frazon al la
cela frazo. Sekve, la dulingvajn ekvivalentojn,
rezultantajn el ekzempligo de gablonoj, oni ra-
jtas aserti kiel novajn dulingvajn leksikerojn;
(v) Novaj dulingvaj leksikeroj estas kunmetataj
el triopoj de fontaj vortlistoj, celaj vortlistoj
kaj dulingvaj gablonoj. Se dulingva leksiko
estas uzata ankaii por malfermklasaj vortoj,
disponeblaj dulingvaj leksikeroj estas uzataj
anstatail gablonoj, kiam eble. Tiamaniere, nur
mankantaj dulingvaj leksikeroj estas kreataj.
La algoritmo povus erari kiam du unuoj en
la sama plur&apos;aro havas unuigeblajn priskribojn,
tial ebligante malkorektan kongruon. Krome, ju
ph gablonaro pligrandigas, des pli pligrandigas
ambigueco en kongruigo, pro interkovrigo de
gablonoj. Ambailspecaj ambiguajoj tamen es-
tas automate rimarkeblaj. Krome, probablis-
maj kaj heUristikaj teknikoj por ataki la duan
problemon estas eksplorataj.
Per la montrita metodo, komputilaj traduk-
sistemoj eblas ekfunkciigi aUtomatan evoluigon
de dulingvaj leksikoj per malgranda komenca
leksiko, sen necesi uzi pliajn rimedojn krom tiuj
jam disponeblaj en la sistemo mem.
</bodyText>
<page confidence="0.990643">
1306
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.163698">
<title confidence="0.9897065">Automatically Creating Bilingual Lexicons for Machine Translation from Bilingual Text</title>
<author confidence="0.784008">Davide Turcato</author>
<affiliation confidence="0.4940355">Natural Language Lab TCC Communications School of Computing Science 100-6722 Oldfield Road</affiliation>
<address confidence="0.611131333333333">Simon Fraser University Victoria, BC Burnaby, BC, V5A 1S6 V8M 2A3 Canada Canada</address>
<email confidence="0.947856">turkOcs.sfu.caturkOtcc.bc.ca</email>
<abstract confidence="0.9989994">A method is presented for automatically augmenting the bilingual lexicon of an existing Machine Translation system, by extracting bilingual entries from aligned bilingual text. The proposed method only relies on the resources already available in the MT system itself. It is based on the use of bilingual lexical templates to match the terminal symbols in the parses of the aligned sentences.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>B Buschbeck-Wolf</author>
<author>M Dorna</author>
</authors>
<title>Using hybrid methods and resources in semanticbased transfer.</title>
<date>1997</date>
<booktitle>In Proceedings of the International Conference &apos;Recent Advances in Natural Language Processing&apos;,</booktitle>
<pages>104--111</pages>
<location>Tzigov Chark, Bulgaria.</location>
<contexts>
<context position="4580" citStr="Buschbeck-Wolf and Dorna, 1997" startWordPosition="745" endWordPosition="748">lingual template is a bilingual entry in which words are left unspecified. E.g.: (1) _ : : (L , Ocount_noun(A) _ : : (R,Onoun(A)) \ \ trans_noun (L , R) . Here, a :&apos; operator connects a word (a variable, in a template) to a description, connects the left and right sides of the entry, &apos;W introduces a transfer macro, which takes two descriptions as arguments and performs some additional transfer (Turcato et al., 1997). Descriptions are mainly expressed by macros, introduced by a &apos;0&apos; operator. The macro arguments are indices, as used in lexicalist transfer. Templates have been widely used in MT (Buschbeck-Wolf and Dorna, 1997), particularly in the Example-Based Machine Translation (EBMT) framework (Kaji et al. (1992), Giivenir and Tunc (1996)). However, in EBMT, templates are most often used to model sentence-level correspondences, rather then lexical equivalences. Consequently, in EBMT the relation between lexical equivalences and templates is the reverse of what is being proposed here. In EBMT, lexical equivalences are assumed and (sentential) templates are inferred from them. In the present framework, sentential correspondences (in the form of possible combinations of lexical templates) are assumed and lexical e</context>
</contexts>
<marker>Buschbeck-Wolf, Dorna, 1997</marker>
<rawString>B. Buschbeck-Wolf and M. Dorna. 1997. Using hybrid methods and resources in semanticbased transfer. In Proceedings of the International Conference &apos;Recent Advances in Natural Language Processing&apos;, pages 104-111, Tzigov Chark, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H A Giivenir</author>
<author>A Tunc</author>
</authors>
<title>Corpusbased learning of generalized parse tree rules for translation.</title>
<date>1996</date>
<booktitle>Advances in Artificial Intelligence — 11th Biennial Conference of the Canadian Society for Computational Studies of Intelligence,</booktitle>
<pages>121--132</pages>
<editor>In G. McCalla, editor,</editor>
<publisher>Springer,</publisher>
<location>Berlin.</location>
<contexts>
<context position="4698" citStr="Giivenir and Tunc (1996)" startWordPosition="763" endWordPosition="766">(A)) \ \ trans_noun (L , R) . Here, a :&apos; operator connects a word (a variable, in a template) to a description, connects the left and right sides of the entry, &apos;W introduces a transfer macro, which takes two descriptions as arguments and performs some additional transfer (Turcato et al., 1997). Descriptions are mainly expressed by macros, introduced by a &apos;0&apos; operator. The macro arguments are indices, as used in lexicalist transfer. Templates have been widely used in MT (Buschbeck-Wolf and Dorna, 1997), particularly in the Example-Based Machine Translation (EBMT) framework (Kaji et al. (1992), Giivenir and Tunc (1996)). However, in EBMT, templates are most often used to model sentence-level correspondences, rather then lexical equivalences. Consequently, in EBMT the relation between lexical equivalences and templates is the reverse of what is being proposed here. In EBMT, lexical equivalences are assumed and (sentential) templates are inferred from them. In the present framework, sentential correspondences (in the form of possible combinations of lexical templates) are assumed and lexical equivalences are inferred from them. In a lexicalist approach, the notion of bilingual lexical entry, and thus that of </context>
</contexts>
<marker>Giivenir, Tunc, 1996</marker>
<rawString>H. A. Giivenir and A. Tunc. 1996. Corpusbased learning of generalized parse tree rules for translation. In G. McCalla, editor, Advances in Artificial Intelligence — 11th Biennial Conference of the Canadian Society for Computational Studies of Intelligence, pages 121-132. Springer, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kaji</author>
<author>Y Kida</author>
<author>Y Morimoto</author>
</authors>
<title>Learning translation templates from bilingual text.</title>
<date>1992</date>
<booktitle>In Proceedings of the 14th International Conference on Computational Linguistics,</booktitle>
<pages>672--678</pages>
<location>Nantes, France.</location>
<contexts>
<context position="4672" citStr="Kaji et al. (1992)" startWordPosition="759" endWordPosition="762">un(A) _ : : (R,Onoun(A)) \ \ trans_noun (L , R) . Here, a :&apos; operator connects a word (a variable, in a template) to a description, connects the left and right sides of the entry, &apos;W introduces a transfer macro, which takes two descriptions as arguments and performs some additional transfer (Turcato et al., 1997). Descriptions are mainly expressed by macros, introduced by a &apos;0&apos; operator. The macro arguments are indices, as used in lexicalist transfer. Templates have been widely used in MT (Buschbeck-Wolf and Dorna, 1997), particularly in the Example-Based Machine Translation (EBMT) framework (Kaji et al. (1992), Giivenir and Tunc (1996)). However, in EBMT, templates are most often used to model sentence-level correspondences, rather then lexical equivalences. Consequently, in EBMT the relation between lexical equivalences and templates is the reverse of what is being proposed here. In EBMT, lexical equivalences are assumed and (sentential) templates are inferred from them. In the present framework, sentential correspondences (in the form of possible combinations of lexical templates) are assumed and lexical equivalences are inferred from them. In a lexicalist approach, the notion of bilingual lexica</context>
<context position="21089" citStr="Kaji et al. (1992)" startWordPosition="3487" endWordPosition="3490">on might be preferred. Finally, efficiency is also dependant on the restrictiveness of grammars. The more grammars overgenerate, the more the combinatoric indeterminacy in the matching process increases. However, overgeneration is as much a problem for translation as for bilingual generation. In other words, no additional requirement is placed on the MT system which is not independently motivated by translation alone. 6 Conclusion The parse-parse-match approach to automatically building bilingual lexicons in not novel. Proposals have been put forward, e.g., by Sadler and Vendelmans (1990) and Kaji et al. (1992). Wu (1995) points out some possible difficulties of the parse-parse-match approach. Among them, the facts that &amp;quot;appropriate, robust, monolingual grammars may not be available&amp;quot; and &amp;quot;the grammars may be incompatible across languages&amp;quot; (Wu, 1995, 355). More generally, in bilingual lexicon development there is a tendency to minimize the need for linguistic resources specifically developed for the purpose. In this view, several proposals tend to use statistical, knowledge-free methods, possibly in combination with the use of existing Machine Readable Dictionaries (see, e.g., Klavans and Tzoukermann</context>
</contexts>
<marker>Kaji, Kida, Morimoto, 1992</marker>
<rawString>H. Kaji, Y. Kida, and Y. Morimoto. 1992. Learning translation templates from bilingual text. In Proceedings of the 14th International Conference on Computational Linguistics, pages 672-678, Nantes, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Klavans</author>
<author>E Tzoukermann</author>
</authors>
<title>Combining corpus and machine-readable dictionary data for building bilingual lexicons.</title>
<date>1995</date>
<journal>Machine Translation,</journal>
<pages>10--185</pages>
<contexts>
<context position="21696" citStr="Klavans and Tzoukermann (1995)" startWordPosition="3578" endWordPosition="3582"> and Kaji et al. (1992). Wu (1995) points out some possible difficulties of the parse-parse-match approach. Among them, the facts that &amp;quot;appropriate, robust, monolingual grammars may not be available&amp;quot; and &amp;quot;the grammars may be incompatible across languages&amp;quot; (Wu, 1995, 355). More generally, in bilingual lexicon development there is a tendency to minimize the need for linguistic resources specifically developed for the purpose. In this view, several proposals tend to use statistical, knowledge-free methods, possibly in combination with the use of existing Machine Readable Dictionaries (see, e.g., Klavans and Tzoukermann (1995), which also contains a survey of related proposals, pages 195-196). 1304 The present proposal tackles the problem from a different and novel perspective. The acknowledgment that MT is the main application domain to which bilingual resources are relevant is taken as a starting point. The existence of an MT system, for which the bilingual lexicon is intended, is explicitly assumed. The potential problems due to the need for linguistic resources are by-passed by having the necessary resources available in the MT system. Rather than doing away with linguistic knowledge, the pre-existing resources</context>
</contexts>
<marker>Klavans, Tzoukermann, 1995</marker>
<rawString>J. Klavans and E. Tzoukermann. 1995. Combining corpus and machine-readable dictionary data for building bilingual lexicons. Machine Translation, 10:185-218.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P McFetridge Laurens</author>
<author>J D Nicholson</author>
<author>P McGivern</author>
<author>M Corzo-Pena</author>
<author>L Pidruchney</author>
<author>S MacDonald</author>
</authors>
<title>A le)cicalist approach to the translation of colloquial text.</title>
<date>1997</date>
<booktitle>In Proceedings of the 7th International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>76--86</pages>
<location>Santa Fe, New Mexico, USA.</location>
<marker>Laurens, Nicholson, McGivern, Corzo-Pena, Pidruchney, MacDonald, 1997</marker>
<rawString>F. Popowich, D. Turcato, 0. Laurens, P. McFetridge, J. D. Nicholson, P. McGivern, M. Corzo-Pena, L. Pidruchney, and S. MacDonald. 1997. A le)cicalist approach to the translation of colloquial text. In Proceedings of the 7th International Conference on Theoretical and Methodological Issues in Machine Translation, pages 76-86, Santa Fe, New Mexico, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Sadler</author>
<author>R Vendelmans</author>
</authors>
<title>Pilot implementation of a bilingual knowledge bank.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<pages>449--451</pages>
<location>Helsinki, Finland.</location>
<contexts>
<context position="21066" citStr="Sadler and Vendelmans (1990)" startWordPosition="3482" endWordPosition="3485">n, the compositional interpretation might be preferred. Finally, efficiency is also dependant on the restrictiveness of grammars. The more grammars overgenerate, the more the combinatoric indeterminacy in the matching process increases. However, overgeneration is as much a problem for translation as for bilingual generation. In other words, no additional requirement is placed on the MT system which is not independently motivated by translation alone. 6 Conclusion The parse-parse-match approach to automatically building bilingual lexicons in not novel. Proposals have been put forward, e.g., by Sadler and Vendelmans (1990) and Kaji et al. (1992). Wu (1995) points out some possible difficulties of the parse-parse-match approach. Among them, the facts that &amp;quot;appropriate, robust, monolingual grammars may not be available&amp;quot; and &amp;quot;the grammars may be incompatible across languages&amp;quot; (Wu, 1995, 355). More generally, in bilingual lexicon development there is a tendency to minimize the need for linguistic resources specifically developed for the purpose. In this view, several proposals tend to use statistical, knowledge-free methods, possibly in combination with the use of existing Machine Readable Dictionaries (see, e.g., </context>
</contexts>
<marker>Sadler, Vendelmans, 1990</marker>
<rawString>V. Sadler and R. Vendelmans. 1990. Pilot implementation of a bilingual knowledge bank. In Proceedings of the 13th International Conference on Computational Linguistics, pages 449-451, Helsinki, Finland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P McFetridge Laurens</author>
<author>F Popowich</author>
</authors>
<title>Inflectional information in transfer for lexicalist MT.</title>
<date>1997</date>
<booktitle>In Proceedings of the International Conference &apos;Recent Advances in Natural Language Processing&apos;,</booktitle>
<pages>98--103</pages>
<location>Tzigov Chark, Bulgaria.</location>
<marker>Laurens, Popowich, 1997</marker>
<rawString>D. Turcato, 0. Laurens, P. McFetridge, and F. Popowich. 1997. Inflectional information in transfer for lexicalist MT. In Proceedings of the International Conference &apos;Recent Advances in Natural Language Processing&apos;, pages 98-103, Tzigov Chark, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Whitelock</author>
</authors>
<title>Shake and bake translation.</title>
<date>1994</date>
<booktitle>Constraints, Language and Computation,</booktitle>
<pages>339--359</pages>
<editor>In C.J. Rupp, M.A. Rosner, and R.L. Johnson, editors,</editor>
<publisher>Academic Press,</publisher>
<location>London.</location>
<contexts>
<context position="2397" citStr="Whitelock, 1994" startWordPosition="377" endWordPosition="379">hing the parses of two aligned sentences and in turning the lexical equivalences thus established into new bilingual lexical entries. 2 Theoretical framework The basic requirement that an MT system should meet for the present purpose is to be bidirectional. Bidirectionality is required in order to ensure that both source and target grammars can be used for parsing and that transfer can be done in both directions. More precisely, what is relevant is that the input and output to transfer be the same kind of structure. Moreover, the proposed method is most productive with a lexicalist MT system (Whitelock, 1994). The proposed application is concerned with producing bilingual lexical knowledge and this sort of knowledge is the only type of bilingual knowledge required by lexicalist systems. Nevertheless, it is also conceivable that the present approach can be used with a nonlexicalist transfer system, as long as the system is bidirectional. In this case, only the lexical portion of the bilingual knowledge can be automatically produced, assuming that the structural transfer portion is already in place. In the rest of this paper, a lexicalist MT system will be assumed and referred to. For the specific i</context>
</contexts>
<marker>Whitelock, 1994</marker>
<rawString>P. Whitelock. 1994. Shake and bake translation. In C.J. Rupp, M.A. Rosner, and R.L. Johnson, editors, Constraints, Language and Computation, pages 339-359. Academic Press, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Wu</author>
</authors>
<title>Grammarless extraction of phrasal translation examples from parallel texts.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation,</booktitle>
<pages>354--372</pages>
<location>Leuven, Belgium.</location>
<contexts>
<context position="21100" citStr="Wu (1995)" startWordPosition="3491" endWordPosition="3492">d. Finally, efficiency is also dependant on the restrictiveness of grammars. The more grammars overgenerate, the more the combinatoric indeterminacy in the matching process increases. However, overgeneration is as much a problem for translation as for bilingual generation. In other words, no additional requirement is placed on the MT system which is not independently motivated by translation alone. 6 Conclusion The parse-parse-match approach to automatically building bilingual lexicons in not novel. Proposals have been put forward, e.g., by Sadler and Vendelmans (1990) and Kaji et al. (1992). Wu (1995) points out some possible difficulties of the parse-parse-match approach. Among them, the facts that &amp;quot;appropriate, robust, monolingual grammars may not be available&amp;quot; and &amp;quot;the grammars may be incompatible across languages&amp;quot; (Wu, 1995, 355). More generally, in bilingual lexicon development there is a tendency to minimize the need for linguistic resources specifically developed for the purpose. In this view, several proposals tend to use statistical, knowledge-free methods, possibly in combination with the use of existing Machine Readable Dictionaries (see, e.g., Klavans and Tzoukermann (1995), wh</context>
</contexts>
<marker>Wu, 1995</marker>
<rawString>D. Wu. 1995. Grammarless extraction of phrasal translation examples from parallel texts. In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation, pages 354-372, Leuven, Belgium.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>