<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002149">
<title confidence="0.97408">
Syntactic tree queries in Prolog
</title>
<author confidence="0.93969">
Gerlof Bouma
</author>
<affiliation confidence="0.871481">
Universität Potsdam, Department Linguistik
</affiliation>
<address confidence="0.905312">
Campus Golm, Haus 24/35
Karl-Liebknecht-Straße 24–25
14476 Potsdam, Germany
</address>
<email confidence="0.831382">
gerlof.bouma@uni-potsdam.de
</email>
<sectionHeader confidence="0.988653" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998963">
In this paper, we argue for and demonstrate
the use of Prolog as a tool to query an-
notated corpora. We present a case study
based on the German TüBa-D/Z Treebank
to show that flexible and efficient corpus
querying can be started with a minimal
amount of effort. We end this paper with a
brief discussion of performance, that sug-
gests that the approach is both fast enough
and scalable.
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999913195121952">
Corpus investigations that go beyond formulating
queries and studying (graphical renderings of) the
retrieved annotation very quickly begin to require
a general purpose programming language to do
things like manipulating and transforming annota-
tion, categorizing results, performing non-trivial
counting and even statistical analysis, as query
tools only offer a fixed, restricted set of operations.
The use of a general purpose programming lan-
guage has drawbacks, too, however: one has to deal
with interfacing with a database, non-deterministic
search, definition of linguistically relevant relations
and properties in terms of the lower level database
relations, etcetera.
As a solution for this dilemma of trading flex-
ibility and power against the ease with which
one can query corpora, we propose to use Pro-
log. Prolog is well suited to query databases (Nils-
son and Maluszynski, 1998). Unlike in other gen-
eral purpose languages, the programmer is re-
lieved of the burden of writing functions to non-
deterministically search through the corpus or
database.
In comparison to dedicated query languages and
their processors, the fact that one can always extend
the Prolog predicates that constitute the query lan-
guage lifts many restrictions on the kinds of queries
one can pose. A more specific point is that we can
have fine grained control over the scope of nega-
tion and quantification in queries in Prolog, some-
thing that is sometimes lacking from dedicated lan-
guages (for discussion, see Lai and Bird (2004);
for a prominent example, König et al. (2003); for
an exception, Kepser (2003))
Lai and Bird (2004) formulated a number of
queries to compare query languages for syntacti-
cally annotated corpora. In this paper, we demon-
strate the ease with which a flexible and fast query
environment can be constructed by implementing
these queries and using them as a rudimentary
benchmark for performance.
</bodyText>
<sectionHeader confidence="0.919978" genericHeader="method">
2 Representing the TfiBa-D/Z corpus
</sectionHeader>
<bodyText confidence="0.98093244">
The TüBa-D/Z treebank of German newspaper arti-
cles (Telljohann et al., 2006, v5) comprises about
800k tokens in 45k sentences. We store the corpus
as collection of directed acyclic graphs, with edges
directed towards the roots of the syntactic trees
(Brants, 1997).
% node/7 SentId NodeId MotherId
% Form Edge Cat Other
node(153, 4, 503, die, -, art, [morph=asf]).
node(153, 503, 508, &apos;$phrase&apos;, hd, nx, []).
By using the sentence number as the first argument
of node/7 facts, we leverage first argument index-
ing to gain fast access to any node in the treebank.
Provided we know the sentence number, we never
need to consider more nodes than the largest tree
in the corpus. Since all nodes that stand in a syntac-
tic relation are within the same sentence, querying
syntactic structure is generally fast. An example
tree and its full representation is given in Figure 1.
Note that in this paper, we only consider the pri-
mary nodes and edges, even though we are in no
fundamental way restricted to querying only this
annotation level.
A set of interface relations provide a first level
of abstraction over this representation. Direct dom-
</bodyText>
<page confidence="0.979993">
212
</page>
<note confidence="0.6185585">
Proceedings of the Fourth Linguistic Annotation Workshop, ACL 2010, pages 212–216,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.979289">
SIMPX
“This has effects on the willingness to accept therapy.”
NX
NN
Auswirkungen
NX
NN
Bereitschaft ,
NF
MF
NX
NN
Therapieangebote
VC
VXINF
VVIZU
anzunehmen .
VF
NX
PDS
Dieser
LK
VXFIN
VAFIN
hat
MF
NX
APPR
auf
PX
ART
die
SIMPX
</figure>
<figureCaption confidence="0.843488222222222">
node(153, 0, 500, ’Dieser’, hd, pds, [morph=nsm]).
node(153, 1, 501, hat, hd, vafin, [morph=13sis&apos;]).
node(153, 2, 502, &apos;Auswirkungen&apos;, hd, nn, [morph=apf]).
node(153, 3, 508, auf, -, appr, [morph=a]).
node(153, 4, 503, die, -, art, [morph=asf]).
node(153, 5, 503, &apos;Bereitschaft&apos;, hd, nn, [morph=asf]).
node(153, 6, 0, (&apos;,&apos;), --, &apos;$,&apos;, [morph= --]).
node(153, 7, 504, &apos;Therapieangebote&apos;, hd, nn, [morph=apn]).
node(153, 8, 505, anzunehmen, hd, vvizu, [morph= --]).
</figureCaption>
<bodyText confidence="0.982351222222222">
node(153, 9, 0, &apos;. --, $., [morph= --]).
secondary(153,503,512,refint).
node(153, 515, 0, &apos;$phrase&apos;, - -, simpx, []).
node(153, 506, 515, &apos;$phrase&apos;, -, vf, []).
node(153, 500, 506, &apos;$phrase&apos;, on, nx, []).
node(153, 507, 515, &apos;$phrase&apos;, -, lk, []).
node(153, 501, 507, &apos;$phrase&apos;, hd, vxfin, []).
node(153, 513, 515, &apos;$phrase&apos;, -, mf, []).
node(153, 511, 513, &apos;$phrase&apos;, oa, nx, []).
node(153, 502, 511, &apos;$phrase&apos;, hd, nx, []).
node(153, 508, 511, &apos;$phrase&apos;, -, px, []).
node(153, 503, 508, &apos;$phrase&apos;, hd, nx, []).
node(153, 514, 515, &apos;$phrase&apos;, -, nf, []).
node(153, 512, 514, &apos;$phrase&apos;, mod, simpx, []).
node(153, 509, 512, &apos;$phrase&apos;, -, mf, []).
node(153, 504, 509, &apos;$phrase&apos;, oa, nx, []).
node(153, 510, 512, &apos;$phrase&apos;, -, vc, []).
node(153, 505, 510, &apos;$phrase&apos;, hd, vxinf, []).
</bodyText>
<figureCaption confidence="0.997939">
Figure 1: A tree from Tüba-D/Z and its Prolog representation.
</figureCaption>
<bodyText confidence="0.955747733333334">
inance and other simple relations are defined di-
rectly in terms of this interface.
has_sentid(node(A_s, , , , , , ),A s).
has_nodeid(node(_,A_n, , , , , ),A n).
has_mother(node(_,_,A_m,_,_,_,_),A_m).
has_form(node(_,_,_,A_f,_,_,_),A_f).
has_poscat(node( , , , , ,A_p,_),A_p).
is_under(A,B):-
has_mother(A,A_m,A_s),
is_phrasal(B),
has_nodeid(B,A_m,A_s).
are_sentmates(A,B):-
has_sentid(A,A_s),
has_sentid(B,A_s).
is_phrasal(A):-
has_form(A,&apos;$phrase&apos;).
None of these predicates consult the database. Ac-
tually looking up a graph involves calling the nodes
describing it. So, is_phrasal(A), A, will return
once for each phrasal node in the corpus. Transitive
closures over the relations above define familiar
tree navigation predicates like dominance (closure
of is_under/2). In contrast with the simple relations,
these closures do look up their arguments.
has_ancestor(A,B):-
has_ancestor(A,B,_).
has_ancestor(A,B,AB_path):-
are_sentmates(A,B),
A, is_under(A,A1), A1,
has_ancestor_rfl(A1,B,AB_path).
</bodyText>
<equation confidence="0.90187775">
has_ancestor_rfl(A,A,[]).
has_ancestor_rfl(A,B,[A|AB_path]):-
is_under(A,A1), A1,
has_ancestor_rfl(A1,B,AB_path).
</equation>
<bodyText confidence="0.99985375">
At this point, linear precedence is still undefined
for phrases. We define string position of a phrase
as its span over the string, which we get by taking
indices of the first and last words in its yield.
</bodyText>
<equation confidence="0.993826444444444">
yields_dl(A,Bs):-
is_phrasal(A)
-&gt; ( is_above(A,A1),
findall(A1, A1, A1s),
map(yields_dl,A1s,Bss),
fold(append_dl,Bss,Bs)
)
;% is_lexical(A)
Bs = [A|Cs]\Cs.
</equation>
<bodyText confidence="0.992714416666667">
spans(A,A_beg,A_end):-
yields_dl(A,Bs\[]),
map(has_nodeid,Bs,B_ns),
fold(min,B_ns,A_beg),
fold(max,B_ns,B_n_mx),
A_end is B_n_mx+1
Thus, the span of the word Auswirkungen in the tree
in Figure 1 is 2–3, and the span of the MF-phrase is
2–6. It makes sense to precalculate spans/3, as this
is an expensive way of calculating linear order and
we are likely to need this information frequently,
for instance in predicates like:
</bodyText>
<page confidence="0.995663">
213
</page>
<bodyText confidence="0.998087411764706">
precedes(A,B):-
are_sentmates(A,B),
spans(A,_,A_end),
spans(B,B_beg,_),
A_end =&lt; B_beg.
directly_precedes(A,B):-
are_sentmates(A,B),
spans(A,_,A_end),
spans(B,A_end,_).
are_right_aligned(A,B):-
are_sentmates(A,B),
spans(A,_,A_end),
spans(B,_,A_end).
TIGERSearch implements an alternative definition
of linear precedence, where two left-corners are
compared (König et al., 2003). It would be straight-
forward to implement this alternative.
</bodyText>
<sectionHeader confidence="0.994466" genericHeader="method">
3 Application &amp; Comparison
</sectionHeader>
<bodyText confidence="0.969311644444445">
Lai and Bird (2004) compare the expressiveness
of query languages by formulating queries that
test different aspects of a query language, such
as the ability to constrain linear order and dom-
inance, to use negation and/or universal quantifi-
cation, and to separate context from the returned
subgraphs. The queries have thus been designed
to highlight strengths and weaknesses of different
query languages in querying linguistic structure.
Six of these queries – with categories changed to
match the Tüba-D/Z corpus – are given in Table 1
and expressed in TIGERSearch query syntax in
Table 2. Since TIGERSearch does not allow for
negation to outscope existential quantification of
nodes, queries Q2 and Q5 are not expressible (also
see Marek et al. (2008) for more discussion). In
addition, Q7 has two interpretations, depending on
whether one wants to return NPs once for each PP
in the context or just once altogether. TIGERSearch
does not allow us to differentiate between these two
interpretations.
Q1 &amp; Q2 The implementation of domination,
has_ancestor/2, performs database lookup. We
therefore call it last in q1/1. To ensure the correct
scope of the negation, lookup of A in q2/1 is explicit
and outside the scope of negation-as-Prolog-failure
\+/1, whereas B is looked up inside its scope.
q1(A):-
has_cat(A,simpx),
has_surf(B,&apos;sah&apos;),
has_ancestor(B,A).
q2(A):-
has_cat(A,simpx),
has_surf(B,sah),
A, \+ has_ancestor(B,A).
Q1 Find sentences that include the word sah.
Q2 Find sentences that do not include sah.
Q3 Find NPs whose rightmost child is an N.
Q4 Find NPs that contain an AdjP immediately
followed by a noun that is immediately fol-
lowed by a prepositional phrase.
Q5 Find the first common ancestor of sequences
of an NP followed by a PP.
Q7 Find an NP dominated by a PP. Return the
subtree dominated by that NP only.
</bodyText>
<tableCaption confidence="0.93707">
Table 1: Query descriptions
</tableCaption>
<equation confidence="0.864480615384615">
Q1 [cat=&amp;quot;SIMPX&amp;quot;] &gt;* [word=&amp;quot;sah&amp;quot;]
Q2 (not expressible)
Q3 #n1:[cat=&amp;quot;NX&amp;quot;] &gt; #n2:[pos=&amp;quot;NN&amp;quot;]
&amp; #n1 &gt;®r #n2
Q4 #nx:[cat=&amp;quot;NX&amp;quot;] &gt;* #ax:[cat=&amp;quot;ADJX&amp;quot;]
&amp; #nx &gt;* #n:[pos=&amp;quot;NN&amp;quot;]
&amp; #nx &gt;* #px:[cat=&amp;quot;PX&amp;quot;]
&amp; #px &gt;®l #pxl
&amp; #ax &gt;®r #axr
&amp; #axr . #n
&amp; #n . #pxl
Q5 (not expressible)
Q7 [cat=&amp;quot;PX&amp;quot;] &gt;* #nx:[cat=&amp;quot;NX&amp;quot;]
</equation>
<tableCaption confidence="0.790341">
Table 2: TIGERSearch queries
</tableCaption>
<bodyText confidence="0.973868903225807">
Q3, Q4 The implementation of spans/3 relies on
given nodes, which means that database lookup is
performed before checking linear order constraints,
explicitly in q3/1 and implicitly in q4_a/1. In addi-
tion, these constraints are expensive to check, so
we make sure we postpone their evaluation as much
as possible.
q3(A):-
has_cat(A,nx),
has_pos(B,nn),
is_under(B,A),
A, B, are_right_aligned(A,B).
q4_a(A):-
has_cat(A,nx),
has_cat(B,adjx),
has_pos(C,nn),
has_cat(D,px),
has_ancestor(B,A),
has_ancestor(C,A),
has_ancestor(D,A),
directly_precedes(B,C),
directly_precedes(C,D).
If we precalculate spans/3, the alternative order of
checking dominance and linear precedence con-
straints becomes viable, as in q4_b/1.
q4_b(A):-
has_cat(A,nx,A_s),
has_cat(B,adjx,A_s),
has_pos(C,nn,A_s),
has_cat(D,px,A_s),
B,C,D, % (cont. on next page)
</bodyText>
<page confidence="0.99687">
214
</page>
<bodyText confidence="0.998981">
directly_precedes(B,C),
directly_precedes(C,D),
has_ancestor(B,A),
has_ancestor(C,A),
has_ancestor(D,A).
The procedural sides of Prolog make that these two
alternatives are processed with considerable speed
differences.
Q5 The lowest common ancestor part of Q5 can
be implemented by constraining the paths between
two nodes and their common ancestor:
</bodyText>
<equation confidence="0.952301625">
q5(A):-
has_cat(B,nx,A_s),
has_cat(C,px,A_s),
B, C,
precedes(B,C),
has_ancestor(B,A,BA_path),
has_ancestor(C,A,CA_path),
\+ ( last(BA_path,D), last(CA_path,D) ).
</equation>
<bodyText confidence="0.903269615384615">
Q7 Precise control over the quantification of the
two nodes in Q7 is achieved by using the built-in
once/1 predicate (�existential quantification) and
by choosing different moments of database lookup
for the two nodes.
q7_a(A):- % once for each np-pp pair
has_cat(A,nx),
has_cat(B,px),
has_ancestor(A,B).
q7_b(A):- % just once per np
has_cat(A,nx),
has_cat(B,px),
A, once(has_ancestor(A,B)).
</bodyText>
<sectionHeader confidence="0.996423" genericHeader="evaluation">
4 Performance
</sectionHeader>
<bodyText confidence="0.999636764705883">
In Table 3, we list wall-clock times for execution of
each of the queries. These serve to demonstrate the
fact that our straightforward use of Prolog results
in a system that is not only flexible and with short
development times, but that is also fast enough to
be usable. We have also included TIGERSearch
execution times for the same queries to give an
idea of the speed of querying with Prolog.1
Table 3 shows Prolog execution times fall well
within useable ranges, provided we precalculate
span/3 facts for queries that rely heavily on linear
order. The non-declarative side of Prolog is most
clearly seen in the difference between Q4-a and
Q4-b – the latter constraint ordering is more than
twice as fast. Even with precalculated span/3 facts,
the whole corpus and query code uses less than
0.5Gbytes of RAM to run.
</bodyText>
<footnote confidence="0.97239925">
1Machine specifications: 1.6Ghz Intel Core 2 Duo,
2GBytes RAM. SWI-prolog (v5.6) on a 32-bit Linux. The
TIGERSearch times were taken on the same machine. The
TIGERSearch corpus was compiled with ‘extended indexing’.
</footnote>
<table confidence="0.999843923076923">
# hits T.Search Precalc. spans
no yes
Loading from source 30 50
Loading precompiled 3 4
Precalculating spans/3 90
Q1 73 3 1
Q2 65727 1
Q3 152669 33 10 4
Q4-a 8185 200 60 50
Q4-b 21
Q5 312753 196 70
Q7-a 145737 6 8
Q7-b 119649 6
</table>
<tableCaption confidence="0.999942">
Table 3: Rounded up wall-clock times in seconds.
</tableCaption>
<bodyText confidence="0.999966625">
To give an impression of scalability, we can re-
port Prolog queries on a 40M tokens, dependency
parsed corpus (Bouma et al., 2010). The setup re-
quires about 13Gbyte of RAM on a 64-bit machine.
Loading a corpus takes under a minute when pre-
compiled. Due to first-argument indexing, time per
answer does not increase much. Handling of larger
corpora remains a topic for future work.
</bodyText>
<sectionHeader confidence="0.999484" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999986764705882">
On the basis of six queries designed to highlight
strengths and weaknesses of query languages, we
have demonstrated that querying syntactically an-
notated corpora using Prolog is straightforward,
flexible and efficient. Due to space constraints, the
example queries have been rather simple, and many
of the more interesting aspects of using a general
purpose programming language like Prolog for cor-
pus querying have not been dealt with, such as
querying structures between and above the sen-
tence, result categorization, on-the-fly annotation
transformation, and the combination of annotation
layers. For examples of these and other use cases,
we refer the reader to Witt (2005), Bouma (2008),
Bouma et al. (2010), and Bouma (Ms). This paper’s
Prolog code and further conversion scripts will be
available from the author’s website.
</bodyText>
<sectionHeader confidence="0.998747" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<reference confidence="0.588276">
This research was carried out in the context of
the SFB 632 Information Structure, subproject D4:
Methoden zur interaktiven linguistischen Korpus-
analyse von Informationsstruktur.
</reference>
<page confidence="0.999232">
215
</page>
<sectionHeader confidence="0.995868" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999772219512195">
Gerlof Bouma, Lilja Øvrelid, and Jonas Kuhn. 2010.
Towards a large parallel corpus of clefts. In Proceed-
ings of LREC 2010, Malta.
Gerlof Bouma. 2008. Starting a Sentence in Dutch: A
corpus study of subject- and object-fronting. Ph.D.
thesis, University of Groningen.
Gerlof Bouma. Ms. Querying linguistic corpora with
Prolog. Manuscript, May 2010, University of Pots-
dam.
Thorsten Brants. 1997. The negra export format. Tech-
nical report, Saarland University, SFB378.
Stephan Kepser. 2003. Finite structure query - a tool
for querying syntactically annotated corpora. In Pro-
ceedings of EACL 2003, pages 179–186.
Esther König, Wolfgang Lezius, and Holger Voormann.
2003. Tigersearch 2.1 user’s manual. Technical re-
port, IMS Stuttgart.
Catherine Lai and Steven Bird. 2004. Querying and up-
dating treebanks: A critical survey and requirements
analysis. In Proceedings of the Australasion Lan-
guage Technology Workshop, Sydney.
Torsten Marek, Joakim Lundborg, and Martin Volk.
2008. Extending the tiger query language with uni-
versal quantification. In KONVENS 2008: 9. Kon-
ferenz zur Verarbeitung natürlicher Sprache, pages
5–17, Berlin.
Ulf Nilsson and Jan Maluszynski. 1998. Logic, pro-
gramming and Prolog. John Wiley &amp; Sons, 2nd edi-
tion.
Heike Telljohann, Erhard Hinrichs, Sandra Kübler, and
Heike Zinsmeister. 2006. Stylebook for the tübin-
gen treebank of written german (tüba-d/z). revised
version. Technical report, Seminar für Sprachwis-
senschaft, Universität Tübingen.
Andreas Witt. 2005. Multiple hierarchies: New as-
pects of an old solution. In Stefani Dipper, Michael
Götze, and Manfred Stede, editors, Heterogeneity
in Focus: Creating and Using Linguistic Databases,
Interdisciplinary Studies on Information Structure
(ISIS) 2, pages 55–86. Universitätsverlag Potsdam,
Potsdam.
</reference>
<page confidence="0.999143">
216
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.169500">
<title confidence="0.980657">Syntactic tree queries in Prolog</title>
<author confidence="0.508288">Gerlof</author>
<affiliation confidence="0.721972">Universität Potsdam, Department</affiliation>
<address confidence="0.533711">Campus Golm, Haus</address>
<affiliation confidence="0.612175">Karl-Liebknecht-Straße</affiliation>
<address confidence="0.979365">14476 Potsdam,</address>
<email confidence="0.999156">gerlof.bouma@uni-potsdam.de</email>
<abstract confidence="0.998939727272727">In this paper, we argue for and demonstrate the use of Prolog as a tool to query annotated corpora. We present a case study based on the German TüBa-D/Z Treebank to show that flexible and efficient corpus querying can be started with a minimal amount of effort. We end this paper with a brief discussion of performance, that suggests that the approach is both fast enough and scalable.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>This research was carried out in the context of the</title>
<booktitle>SFB 632 Information Structure, subproject D4: Methoden zur interaktiven linguistischen Korpusanalyse von Informationsstruktur.</booktitle>
<marker></marker>
<rawString>This research was carried out in the context of the SFB 632 Information Structure, subproject D4: Methoden zur interaktiven linguistischen Korpusanalyse von Informationsstruktur.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerlof Bouma</author>
<author>Lilja Øvrelid</author>
<author>Jonas Kuhn</author>
</authors>
<title>Towards a large parallel corpus of clefts.</title>
<date>2010</date>
<booktitle>In Proceedings of LREC</booktitle>
<contexts>
<context position="13128" citStr="Bouma et al., 2010" startWordPosition="1946" endWordPosition="1949">chine specifications: 1.6Ghz Intel Core 2 Duo, 2GBytes RAM. SWI-prolog (v5.6) on a 32-bit Linux. The TIGERSearch times were taken on the same machine. The TIGERSearch corpus was compiled with ‘extended indexing’. # hits T.Search Precalc. spans no yes Loading from source 30 50 Loading precompiled 3 4 Precalculating spans/3 90 Q1 73 3 1 Q2 65727 1 Q3 152669 33 10 4 Q4-a 8185 200 60 50 Q4-b 21 Q5 312753 196 70 Q7-a 145737 6 8 Q7-b 119649 6 Table 3: Rounded up wall-clock times in seconds. To give an impression of scalability, we can report Prolog queries on a 40M tokens, dependency parsed corpus (Bouma et al., 2010). The setup requires about 13Gbyte of RAM on a 64-bit machine. Loading a corpus takes under a minute when precompiled. Due to first-argument indexing, time per answer does not increase much. Handling of larger corpora remains a topic for future work. 5 Conclusions On the basis of six queries designed to highlight strengths and weaknesses of query languages, we have demonstrated that querying syntactically annotated corpora using Prolog is straightforward, flexible and efficient. Due to space constraints, the example queries have been rather simple, and many of the more interesting aspects of u</context>
</contexts>
<marker>Bouma, Øvrelid, Kuhn, 2010</marker>
<rawString>Gerlof Bouma, Lilja Øvrelid, and Jonas Kuhn. 2010. Towards a large parallel corpus of clefts. In Proceedings of LREC 2010, Malta.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerlof Bouma</author>
</authors>
<title>Starting a Sentence in Dutch: A corpus study of subject- and object-fronting.</title>
<date>2008</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Groningen.</institution>
<marker>Bouma, 2008</marker>
<rawString>Gerlof Bouma. 2008. Starting a Sentence in Dutch: A corpus study of subject- and object-fronting. Ph.D. thesis, University of Groningen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ms</author>
</authors>
<title>Querying linguistic corpora with Prolog.</title>
<date>2010</date>
<tech>Manuscript,</tech>
<institution>University of Potsdam.</institution>
<marker>Ms, 2010</marker>
<rawString>Gerlof Bouma. Ms. Querying linguistic corpora with Prolog. Manuscript, May 2010, University of Potsdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thorsten Brants</author>
</authors>
<title>The negra export format.</title>
<date>1997</date>
<tech>Technical report,</tech>
<institution>Saarland University,</institution>
<contexts>
<context position="2806" citStr="Brants, 1997" startWordPosition="439" endWordPosition="440">) Lai and Bird (2004) formulated a number of queries to compare query languages for syntactically annotated corpora. In this paper, we demonstrate the ease with which a flexible and fast query environment can be constructed by implementing these queries and using them as a rudimentary benchmark for performance. 2 Representing the TfiBa-D/Z corpus The TüBa-D/Z treebank of German newspaper articles (Telljohann et al., 2006, v5) comprises about 800k tokens in 45k sentences. We store the corpus as collection of directed acyclic graphs, with edges directed towards the roots of the syntactic trees (Brants, 1997). % node/7 SentId NodeId MotherId % Form Edge Cat Other node(153, 4, 503, die, -, art, [morph=asf]). node(153, 503, 508, &apos;$phrase&apos;, hd, nx, []). By using the sentence number as the first argument of node/7 facts, we leverage first argument indexing to gain fast access to any node in the treebank. Provided we know the sentence number, we never need to consider more nodes than the largest tree in the corpus. Since all nodes that stand in a syntactic relation are within the same sentence, querying syntactic structure is generally fast. An example tree and its full representation is given in Figur</context>
</contexts>
<marker>Brants, 1997</marker>
<rawString>Thorsten Brants. 1997. The negra export format. Technical report, Saarland University, SFB378.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Kepser</author>
</authors>
<title>Finite structure query - a tool for querying syntactically annotated corpora.</title>
<date>2003</date>
<booktitle>In Proceedings of EACL</booktitle>
<pages>179--186</pages>
<contexts>
<context position="2193" citStr="Kepser (2003)" startWordPosition="342" endWordPosition="343"> writing functions to nondeterministically search through the corpus or database. In comparison to dedicated query languages and their processors, the fact that one can always extend the Prolog predicates that constitute the query language lifts many restrictions on the kinds of queries one can pose. A more specific point is that we can have fine grained control over the scope of negation and quantification in queries in Prolog, something that is sometimes lacking from dedicated languages (for discussion, see Lai and Bird (2004); for a prominent example, König et al. (2003); for an exception, Kepser (2003)) Lai and Bird (2004) formulated a number of queries to compare query languages for syntactically annotated corpora. In this paper, we demonstrate the ease with which a flexible and fast query environment can be constructed by implementing these queries and using them as a rudimentary benchmark for performance. 2 Representing the TfiBa-D/Z corpus The TüBa-D/Z treebank of German newspaper articles (Telljohann et al., 2006, v5) comprises about 800k tokens in 45k sentences. We store the corpus as collection of directed acyclic graphs, with edges directed towards the roots of the syntactic trees (</context>
</contexts>
<marker>Kepser, 2003</marker>
<rawString>Stephan Kepser. 2003. Finite structure query - a tool for querying syntactically annotated corpora. In Proceedings of EACL 2003, pages 179–186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Esther König</author>
<author>Wolfgang Lezius</author>
<author>Holger Voormann</author>
</authors>
<date>2003</date>
<journal>Tigersearch</journal>
<tech>Technical report, IMS Stuttgart.</tech>
<volume>2</volume>
<note>user’s manual.</note>
<contexts>
<context position="2160" citStr="König et al. (2003)" startWordPosition="335" endWordPosition="338">programmer is relieved of the burden of writing functions to nondeterministically search through the corpus or database. In comparison to dedicated query languages and their processors, the fact that one can always extend the Prolog predicates that constitute the query language lifts many restrictions on the kinds of queries one can pose. A more specific point is that we can have fine grained control over the scope of negation and quantification in queries in Prolog, something that is sometimes lacking from dedicated languages (for discussion, see Lai and Bird (2004); for a prominent example, König et al. (2003); for an exception, Kepser (2003)) Lai and Bird (2004) formulated a number of queries to compare query languages for syntactically annotated corpora. In this paper, we demonstrate the ease with which a flexible and fast query environment can be constructed by implementing these queries and using them as a rudimentary benchmark for performance. 2 Representing the TfiBa-D/Z corpus The TüBa-D/Z treebank of German newspaper articles (Telljohann et al., 2006, v5) comprises about 800k tokens in 45k sentences. We store the corpus as collection of directed acyclic graphs, with edges directed towards t</context>
<context position="7662" citStr="König et al., 2003" startWordPosition="1117" endWordPosition="1120">igure 1 is 2–3, and the span of the MF-phrase is 2–6. It makes sense to precalculate spans/3, as this is an expensive way of calculating linear order and we are likely to need this information frequently, for instance in predicates like: 213 precedes(A,B):- are_sentmates(A,B), spans(A,_,A_end), spans(B,B_beg,_), A_end =&lt; B_beg. directly_precedes(A,B):- are_sentmates(A,B), spans(A,_,A_end), spans(B,A_end,_). are_right_aligned(A,B):- are_sentmates(A,B), spans(A,_,A_end), spans(B,_,A_end). TIGERSearch implements an alternative definition of linear precedence, where two left-corners are compared (König et al., 2003). It would be straightforward to implement this alternative. 3 Application &amp; Comparison Lai and Bird (2004) compare the expressiveness of query languages by formulating queries that test different aspects of a query language, such as the ability to constrain linear order and dominance, to use negation and/or universal quantification, and to separate context from the returned subgraphs. The queries have thus been designed to highlight strengths and weaknesses of different query languages in querying linguistic structure. Six of these queries – with categories changed to match the Tüba-D/Z corpu</context>
</contexts>
<marker>König, Lezius, Voormann, 2003</marker>
<rawString>Esther König, Wolfgang Lezius, and Holger Voormann. 2003. Tigersearch 2.1 user’s manual. Technical report, IMS Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Catherine Lai</author>
<author>Steven Bird</author>
</authors>
<title>Querying and updating treebanks: A critical survey and requirements analysis.</title>
<date>2004</date>
<booktitle>In Proceedings of the Australasion Language Technology Workshop,</booktitle>
<location>Sydney.</location>
<contexts>
<context position="2114" citStr="Lai and Bird (2004)" startWordPosition="327" endWordPosition="330">nlike in other general purpose languages, the programmer is relieved of the burden of writing functions to nondeterministically search through the corpus or database. In comparison to dedicated query languages and their processors, the fact that one can always extend the Prolog predicates that constitute the query language lifts many restrictions on the kinds of queries one can pose. A more specific point is that we can have fine grained control over the scope of negation and quantification in queries in Prolog, something that is sometimes lacking from dedicated languages (for discussion, see Lai and Bird (2004); for a prominent example, König et al. (2003); for an exception, Kepser (2003)) Lai and Bird (2004) formulated a number of queries to compare query languages for syntactically annotated corpora. In this paper, we demonstrate the ease with which a flexible and fast query environment can be constructed by implementing these queries and using them as a rudimentary benchmark for performance. 2 Representing the TfiBa-D/Z corpus The TüBa-D/Z treebank of German newspaper articles (Telljohann et al., 2006, v5) comprises about 800k tokens in 45k sentences. We store the corpus as collection of directed</context>
<context position="7769" citStr="Lai and Bird (2004)" startWordPosition="1134" endWordPosition="1137"> expensive way of calculating linear order and we are likely to need this information frequently, for instance in predicates like: 213 precedes(A,B):- are_sentmates(A,B), spans(A,_,A_end), spans(B,B_beg,_), A_end =&lt; B_beg. directly_precedes(A,B):- are_sentmates(A,B), spans(A,_,A_end), spans(B,A_end,_). are_right_aligned(A,B):- are_sentmates(A,B), spans(A,_,A_end), spans(B,_,A_end). TIGERSearch implements an alternative definition of linear precedence, where two left-corners are compared (König et al., 2003). It would be straightforward to implement this alternative. 3 Application &amp; Comparison Lai and Bird (2004) compare the expressiveness of query languages by formulating queries that test different aspects of a query language, such as the ability to constrain linear order and dominance, to use negation and/or universal quantification, and to separate context from the returned subgraphs. The queries have thus been designed to highlight strengths and weaknesses of different query languages in querying linguistic structure. Six of these queries – with categories changed to match the Tüba-D/Z corpus – are given in Table 1 and expressed in TIGERSearch query syntax in Table 2. Since TIGERSearch does not a</context>
</contexts>
<marker>Lai, Bird, 2004</marker>
<rawString>Catherine Lai and Steven Bird. 2004. Querying and updating treebanks: A critical survey and requirements analysis. In Proceedings of the Australasion Language Technology Workshop, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Torsten Marek</author>
<author>Joakim Lundborg</author>
<author>Martin Volk</author>
</authors>
<title>Extending the tiger query language with universal quantification.</title>
<date>2008</date>
<booktitle>In KONVENS 2008: 9. Konferenz zur Verarbeitung natürlicher Sprache,</booktitle>
<pages>5--17</pages>
<location>Berlin.</location>
<contexts>
<context position="8503" citStr="Marek et al. (2008)" startWordPosition="1250" endWordPosition="1253">ge, such as the ability to constrain linear order and dominance, to use negation and/or universal quantification, and to separate context from the returned subgraphs. The queries have thus been designed to highlight strengths and weaknesses of different query languages in querying linguistic structure. Six of these queries – with categories changed to match the Tüba-D/Z corpus – are given in Table 1 and expressed in TIGERSearch query syntax in Table 2. Since TIGERSearch does not allow for negation to outscope existential quantification of nodes, queries Q2 and Q5 are not expressible (also see Marek et al. (2008) for more discussion). In addition, Q7 has two interpretations, depending on whether one wants to return NPs once for each PP in the context or just once altogether. TIGERSearch does not allow us to differentiate between these two interpretations. Q1 &amp; Q2 The implementation of domination, has_ancestor/2, performs database lookup. We therefore call it last in q1/1. To ensure the correct scope of the negation, lookup of A in q2/1 is explicit and outside the scope of negation-as-Prolog-failure \+/1, whereas B is looked up inside its scope. q1(A):- has_cat(A,simpx), has_surf(B,&apos;sah&apos;), has_ancestor</context>
</contexts>
<marker>Marek, Lundborg, Volk, 2008</marker>
<rawString>Torsten Marek, Joakim Lundborg, and Martin Volk. 2008. Extending the tiger query language with universal quantification. In KONVENS 2008: 9. Konferenz zur Verarbeitung natürlicher Sprache, pages 5–17, Berlin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ulf Nilsson</author>
<author>Jan Maluszynski</author>
</authors>
<title>Logic, programming and Prolog.</title>
<date>1998</date>
<publisher>John Wiley &amp; Sons,</publisher>
<note>2nd edition.</note>
<contexts>
<context position="1492" citStr="Nilsson and Maluszynski, 1998" startWordPosition="222" endWordPosition="226">ing results, performing non-trivial counting and even statistical analysis, as query tools only offer a fixed, restricted set of operations. The use of a general purpose programming language has drawbacks, too, however: one has to deal with interfacing with a database, non-deterministic search, definition of linguistically relevant relations and properties in terms of the lower level database relations, etcetera. As a solution for this dilemma of trading flexibility and power against the ease with which one can query corpora, we propose to use Prolog. Prolog is well suited to query databases (Nilsson and Maluszynski, 1998). Unlike in other general purpose languages, the programmer is relieved of the burden of writing functions to nondeterministically search through the corpus or database. In comparison to dedicated query languages and their processors, the fact that one can always extend the Prolog predicates that constitute the query language lifts many restrictions on the kinds of queries one can pose. A more specific point is that we can have fine grained control over the scope of negation and quantification in queries in Prolog, something that is sometimes lacking from dedicated languages (for discussion, s</context>
</contexts>
<marker>Nilsson, Maluszynski, 1998</marker>
<rawString>Ulf Nilsson and Jan Maluszynski. 1998. Logic, programming and Prolog. John Wiley &amp; Sons, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Heike Telljohann</author>
<author>Erhard Hinrichs</author>
<author>Sandra Kübler</author>
<author>Heike Zinsmeister</author>
</authors>
<title>Stylebook for the tübingen treebank of written german (tüba-d/z). revised version.</title>
<date>2006</date>
<tech>Technical report, Seminar für Sprachwissenschaft,</tech>
<institution>Universität Tübingen.</institution>
<contexts>
<context position="2617" citStr="Telljohann et al., 2006" startWordPosition="407" endWordPosition="410">queries in Prolog, something that is sometimes lacking from dedicated languages (for discussion, see Lai and Bird (2004); for a prominent example, König et al. (2003); for an exception, Kepser (2003)) Lai and Bird (2004) formulated a number of queries to compare query languages for syntactically annotated corpora. In this paper, we demonstrate the ease with which a flexible and fast query environment can be constructed by implementing these queries and using them as a rudimentary benchmark for performance. 2 Representing the TfiBa-D/Z corpus The TüBa-D/Z treebank of German newspaper articles (Telljohann et al., 2006, v5) comprises about 800k tokens in 45k sentences. We store the corpus as collection of directed acyclic graphs, with edges directed towards the roots of the syntactic trees (Brants, 1997). % node/7 SentId NodeId MotherId % Form Edge Cat Other node(153, 4, 503, die, -, art, [morph=asf]). node(153, 503, 508, &apos;$phrase&apos;, hd, nx, []). By using the sentence number as the first argument of node/7 facts, we leverage first argument indexing to gain fast access to any node in the treebank. Provided we know the sentence number, we never need to consider more nodes than the largest tree in the corpus. S</context>
</contexts>
<marker>Telljohann, Hinrichs, Kübler, Zinsmeister, 2006</marker>
<rawString>Heike Telljohann, Erhard Hinrichs, Sandra Kübler, and Heike Zinsmeister. 2006. Stylebook for the tübingen treebank of written german (tüba-d/z). revised version. Technical report, Seminar für Sprachwissenschaft, Universität Tübingen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Witt</author>
</authors>
<title>Multiple hierarchies: New aspects of an old solution.</title>
<date>2005</date>
<booktitle>Heterogeneity in Focus: Creating and Using Linguistic Databases, Interdisciplinary Studies on Information Structure (ISIS) 2,</booktitle>
<pages>55--86</pages>
<editor>In Stefani Dipper, Michael Götze, and Manfred Stede, editors,</editor>
<publisher>Universitätsverlag</publisher>
<location>Potsdam, Potsdam.</location>
<marker>Witt, 2005</marker>
<rawString>Andreas Witt. 2005. Multiple hierarchies: New aspects of an old solution. In Stefani Dipper, Michael Götze, and Manfred Stede, editors, Heterogeneity in Focus: Creating and Using Linguistic Databases, Interdisciplinary Studies on Information Structure (ISIS) 2, pages 55–86. Universitätsverlag Potsdam, Potsdam.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>