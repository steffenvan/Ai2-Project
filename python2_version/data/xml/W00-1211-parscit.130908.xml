<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000086">
<title confidence="0.985977">
Statistics Based Hybrid Approach to Chinese Base Phrase Identification
</title>
<author confidence="0.99427">
Tie-jun ZHAO, Mu-yun YANQ Fang LIU, Jian-min YAO, Hao YU
</author>
<affiliation confidence="0.999429">
Department of Computer Science and Engineering, Harbin Institute of Technology
</affiliation>
<email confidence="0.919299">
{tjzaho, ymy, liufang, james, yu}@mtlab.hit.edu.cn
</email>
<sectionHeader confidence="0.959524" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.943428571428571">
This paper extends the base noun
phrase(BNP) identification into a research
on Chinese base phrase identification. After
briefly introducing some basic concepts on
Chinese base phrase, this paper presents a
statistics based hybrid model for identifying
7 types of Chinese base phrases in view.
Experiments show the efficiency of the
proposed method in simplifying sentence
structure. Significance of the research lies in
it provides a solid foundation for the
Chinese parser.
Keywords: Chinese base phrase
identification, parsing, statistical model
</bodyText>
<sectionHeader confidence="0.99888" genericHeader="categories and subject descriptors">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999057863636364">
Decomposing syntactic analysis into
several phases so as to decrease its difficulty
is a new stream in NLP research. The
successful POS tagging has encouraged
researchers to explore further possibility for
resolving sub-problems in parsing(Zhou, et
al, 1999). The typical examples are the
recognition of BaseNP in English and
Chinese.
In English BNP (base noun phrase) is
defined as simple and non-nesting noun
phrases, i.e. noun phrases that do not contain
other noun phrase descendants (Church,
1988). After that researches on BNP
identification reports promising results for
such task in English. Observing that the
Chinese BNP is different form English,
(Zhao &amp; Huang, 1999) puts forward the
definition of Chinese BNP in terms of
combination of determinative modifier and
head noun. According to them a BNP in
Chinese can be recursively defined as:
</bodyText>
<construct confidence="0.7244018">
BaseIVP : := Determinative modifier +
Noun I Nominalized verb(NV)
Determinative modifier ::= Adjective I
Differentiable Adjective(DA) I Verb I Noun
Location I String I Numeral + Classifier
</construct>
<bodyText confidence="0.999630428571429">
Inspired by these researches, we extend
the concept of BNP to Base Phrase in
Chinese. It is based on such knowledge that
there are many structures, not only NP, in
which the trivial components closely attach
to their central words and constitute a basic
phrase in a Chinese sentence. Obviously,
resolving all these base phrases will greatly
benefit Chinese parser by reliving it from
some pre-processing (though non-trivial)
and enable it focus on the most subtle
syntactic structures.
Since the whole system of Chinese base
phrase is still under discussing, this paper
just presents some tentative research
achievements on statistics based hybrid
model to Chinese base phrase identification.
For the 7 types we considered at present, our
algorithm turns out promising results and
smoothes the way for a better Chinese
parser.
</bodyText>
<sectionHeader confidence="0.819288" genericHeader="general terms">
2 Statistics Based Hybrid Approach to
</sectionHeader>
<subsectionHeader confidence="0.834701">
Chinese Base Phrase Identification
2.1 Concepts and Definitions
</subsectionHeader>
<bodyText confidence="0.998566714285714">
In addition to BNP, constituents of
many local structure in Chinese centers
around a core word with certain fixed POS
sequences. Therefore their identification is
slightly different from parsing in that it
bears relatively simple phenomenon. Like
BNP identification, identification of these
phenomena before parsing will provide a
simpler sequence for parser, and thus
deserves a separate research.
Currently, we are considering 7 Chinese
base phrases in our research, namely base
adjective phrase(BADJP), base adverbial
phrase (BADVP), base noun phrase (BNP),
</bodyText>
<page confidence="0.998006">
73
</page>
<bodyText confidence="0.998455304347826">
base temporal phrase (BTN), base location
phrase (BNS), base verb phrase (By?) and
base quantity phrase (BM&apos;) . Though
theoretically definitions for these base
phrases are still unavailable, Appendix I lists
the preliminary illustrations for them in
BNF format (necessary account for POS
annotation can also be found)..
To frame the identification of Chinese
base phrases, we further develop the
following concepts:
Definition 1: Chinese based phrases are
recognized as atomic parts of a sentence
beyond words that posses certain functions
and meanings. A base phrase may consist of
words or other base phrases, but its
constituents, in turn, should not contain any
base phrases.
Definition 2: Base phrase tag is the
token representing the syntactic function of
the phrase. At present, base tag either falls in
one of the 7 Chinese base phrases we are
considering or not:
</bodyText>
<construct confidence="0.874363">
Phrase-Tag ::= BADJP I BAD VP I BNP
BT N I BNS I BVP I BMP I NULL
</construct>
<bodyText confidence="0.8377595">
Definition 3: Boundary tag denotes the
possible relative position of a word to a base
phrase. A boundary tag for a given word is
either L( left boundary of a base phrase),
R( right boundary of a ), I(inside a base
phrase) or 0(outside the base phrase).
</bodyText>
<subsectionHeader confidence="0.950009">
2.2 Duple Based HMM Parser
</subsectionHeader>
<bodyText confidence="0.97453748275862">
Based on above definitions, we could,
in view of Wojciech&apos;s proposal [Wojciech and
Thorsten, 1998], interpret the parsing of
Chinese base phrases as the following:
Suppose the input as a sequence of POS
annotations T= tn) . The task is to
find RC, a most possible sequence of duples
formed by base phrase tags and boundary
tags, among the POS sequence T.
RC= (&lt;ro,co&gt;,......, &lt;rn,cn&gt;),
in whist&apos; r (1&lt;i&lt;=n)indicates the boundary
tags, ci represents the base phrase tags.
To go along with the POS tagger
developed previously by us, we first think of
preserving HMM (hidden Markov Model)
for parsing Chinese base phrases. Thus the
following formula is usually, at hand:
RC = arg max p(RC T)
= arg max p(RC)* p(T I RC)
For a given sequence of T, this formula
can be transformed into:
= arg max p(RC IT)
= arg max p(RC)* p(T I RC)
Essentially this model could be
established through bigram or tri-gram
statistical training by a annotated corpus. In
practice, we just build our model from
10,000 manual annotated sentences with
common bi-gram training:
</bodyText>
<equation confidence="0.9990045">
p (RC ) = P(RC ,IRC 1_1)
1.1
P (T j RC ) = I RC i
i =1
</equation>
<bodyText confidence="0.999160166666667">
In realization, a Viterbi algorithm is
adopted to search the best path. An open test
on additional 1000 sentences is performed to
check its accuracy. Results are shown in
Tablel (note precision is calculated by
word).
</bodyText>
<table confidence="0.999771285714286">
Precision Precision Precision
for R for C for Both
R and C
Close 85.7% 87.5% 79.0%
Test
Open 82.4% 85.1% 74.7%
Test
</table>
<tableCaption confidence="0.999318">
Table 1. Results for Duple Based HMM
</tableCaption>
<subsectionHeader confidence="0.958491">
2.3 Triple Based MM Exploiting
Linguistic Information
</subsectionHeader>
<bodyText confidence="0.999146384615385">
Although results shown in Table 1 is
encouraging enough for research purposes,
it is still lies a long way for practical
Chinese parser we are aiming at. Reasons
for errors may be account by too
coarse-gained information provided by RC.
Observing the fact that the Chinese base
phrase occurs more frequently with some
fixed patterns, i.e. some frozen POS chains,
we decide to improved our previous model
by emphasizing the contribution given by
POS information.
Adding t denoting POS in the duple (r,
</bodyText>
<page confidence="0.993572">
74
</page>
<bodyText confidence="0.99885775">
c), we develop a triple in the form of (t,r,c)
for the calculation of a node. Naturally, the
new model is changed into a MM (Markov
model) as:
</bodyText>
<equation confidence="0.922694">
TRC = arg max p(TRC )
= arg max 121 P (TRC iiTRC i â€” 1)
i=1
</equation>
<bodyText confidence="0.997393">
To train this model, we still using a
bi-gram model. Applying the same corpus
and tests described above, we got the
performance of triple based MM identifier
for Chinese base phrases see Table 2.
</bodyText>
<table confidence="0.941035333333333">
Precision Precision Precision
for R for C for Both
R and C
Close 89.2% 91.5% 84.6%
Test
Open 88.4% 89.9% 83%
Test
2.4 Further Improvement Through TBED
Learning
</table>
<bodyText confidence="0.999090470588235">
Like other statistical models, the above
model, whether duple based or triple based,
both seem to reach an accuracy ceiling after
enlarging training set to 12, 000 or so. To
cover the remaining accuracy, we apply the
transformation-based error driven (TBED)
learning strategy described in [Brill, 1992]
to acquired desired rules.
In our module, some initial rules are
first designed as compensation of statistical
model. Applying these rules will cause new
mistakes as well as make correct
identifications. Then the module will
compare the processed texts with training
sentences, generate new rules according to
pre-defined actions and update its rule bank
after evaluation (see Fig 1.).
</bodyText>
<tableCaption confidence="0.976924">
Table 2. Result for Triple Based MM
</tableCaption>
<figureCaption confidence="0.998607">
Figure 1. TBED Learning Module
</figureCaption>
<figure confidence="0.995362181818182">
A
Identifier
Input Text
Rules Passing
Evaluation
Processed
Text
Compare and
Generate New Rules
Training
Text
</figure>
<bodyText confidence="0.999771142857143">
The dotted line in fig 2. will stop
functioning if pre-set accuracy is reached by
the identifier for the Chinese base phrase.
Evaluation of new rules is based on an
greedy algorithm: only rule with max
contribution (max correction and min error)
will be added. Design of rule generation
(pre-defmed actions) is similar to those
described in [Brill, 1992].
Table 3 shows a significant
improvement after applying rules obtained
through TBED learner. It is also the final
performance of the proposed Chinese base
phrase identification model.
</bodyText>
<table confidence="0.9997388">
Precision Precision Precision
for R for C for Both
Rand C
Close 91.2% 92.8% 89%
Open 90.4% 91.1% 87.1%
</table>
<tableCaption confidence="0.999773">
Table 3. Results after TBED Module
</tableCaption>
<sectionHeader confidence="0.974251" genericHeader="keywords">
3 Conclusions and Discussions
</sectionHeader>
<bodyText confidence="0.9998104">
We have accomplished preliminary
experiments on identification of various
types of base phrases defined in this paper.
The data shown in last section prove that our
method generates satisfactory results for
</bodyText>
<page confidence="0.997553">
75
</page>
<bodyText confidence="0.53284">
Chinese base phrase identification. The following figure.
overall process of our method is outlined the
</bodyText>
<figureCaption confidence="0.927105">
Fig 2. Processing of Chinese Based Phrase Identification
</figureCaption>
<figure confidence="0.980783636363636">
Input Chinese Sentences
after Sengmentation and
POS tagging
Triple Based Bi-gram
MM with Viterbi
Algorithm
Converted into Nodes
to Be Parsed
TBED Based
Correction
ol_Output
</figure>
<bodyText confidence="0.99919925">
However, the 7 types Chinese base
phrases we have proposed are far from
perfection. Even what we have proposed for
the 7 phrases is still under test. Further
improvement will focus on two aspects: one
is to discuss and add new base phrase for a
broader coverage; the other is to define,
theoretically or empirically, the Chinese
base phrases with more strict constraints. Of
course, new techniques to improved the
accuracy of statistical model are the constant
aim of our research.
To sum up, Chinese base phrase
identification will reduce complexity of a
Chinese parser. The successful identification
of the 7 base phrases clearly simplifies the
structure of the sentence. We expect that the
research described in this paper will lay a
solid foundation for a high-accuracy
Chinese parser.
</bodyText>
<sectionHeader confidence="0.977251" genericHeader="introduction">
Reference
</sectionHeader>
<reference confidence="0.978545277777778">
[Church, 19881 K. Church, A stochastic
parts program and noun phrase parser for
unrestricted text, In: Proc. of Second
Conference on Applied Natural Language
Processing, 1988
[Wojciech and Thorsten, 1998] Wojciech Slcut and
Thorsten Brants, Chunk Tagger, Statistical
Recongnition of Noun Phrases, In ESSLLI-98
Workshop on Automated Acquisition of Syntax
and Parsing, Saarbrvcken, 1998.
[Zhao &amp; Huang, 1999] Zhao Jun and Huang
Chang-Ning, The model for Chinese baseNP
structure analysis, Chinese J. Computer,
22(2): pp141-146
[Zhou, et al, 1999] Thou Qiang, Sun
Mao-Song, Huang Chang-Ning, Chunk
parsing scheme for Chinese sentences,
Chinese J. Computer, 22(11): pp1159-1165
</reference>
<page confidence="0.994343">
76
</page>
<bodyText confidence="0.995292125">
Appendix Illustration of 7 Chinese Base
Phrases in BNF
The patterns listed here are far from
complete (even for the 7 phrases
themselves). Theoretical definition is
beyond this paper and what we provide here
is actually stage results of expert
observation and linguistic abstraction.
</bodyText>
<sectionHeader confidence="0.3378065" genericHeader="method">
BADJP ::= dt+a I d+BADJP a+ a+BADJP
BADVP+a I BADVP+BADJP
</sectionHeader>
<construct confidence="0.978611916666667">
BADVP ::= a+usdi(it) I d+usdi I vg+usdi
BADJP+usdi I BAD&apos;VP+usdi I BMP+usdi
BMP ::= m+ I m+ +q+ I m+q+m I d+m+q
f+m+q I r+m+q I BMP+
BNP ::= a+n I a+usde(141)+n j a+usde+BNP I
a+BNP J b+n J b+usde+n J b+usde+BNP I
b+BNP I d+usde+n I f+n I f+usde+n I f+BNP
m+n I m+BNP j n+ I n+usde+n
n+usde+BNP n+usde+BMP I n+BNP q+n
q+BNP I r+a+n r+m+n r+n I r+usde+n I
r+usde+BNP I r+BNP I s+n I s+usde+n
s+usde+BNP f t+n I t+usde+n I t+usde+BNP
</construct>
<sectionHeader confidence="0.718482666666667" genericHeader="method">
vg+usde+n I vg+usde+BNP I BADJP+n
BADJP+usde+n I BADJP+usde+BNP
BADJP+BNP I BMP+n I BMP+usde+n
BMP+usde+BNP I BMP+BNP I-BNP+n
BNP+usde+n I BNP+usde+BNP
BNP+usde+BM2 I BNP+BNP
BNS+usde+n I BNS+usde+BNP
BNS+BNP BTN+usde+n
BTN+usde+BNP I BVP+usde+n
</sectionHeader>
<figure confidence="0.978975470588235">
BVP+usdc-I-BNP
BNS ::= a+nd I m+nd I n+s I r+nd
n+usde+f I n+usde+nd I n+usde+s
n+usde+BNS nd+ I r+usde+nd I r+usde+s
s+usde+nd I s+usde+BNS I BNP BNS
BNS+
BTN ::= a+t m+t r+t I t+ t+usde+t
BMP+t I BTN+t I BNP+usde+t
BVP ::= a+vg I d+vg I vg+d+a I vg+d+vq
vg+d+vb I vg+usdf( -14 )+a I vg+usdf+d
vg+usdf+vq I vg+usdf+u I vg+usdf+BADJP
vg+ut I vg+vb I vg+ut+vq I vq+vg I vq+BVP
vz+vg I vz+BVP I BADJP+vg
BADVP+vg BADVP+BVP BVP+ut
BVP+vq BVP+BVP
Symbol Part-Of-Speech Examples
a Adjective FiNA(beautiful), A &amp;(romantic)
</figure>
<bodyText confidence="0.923111588235294">
d Adverb 1E(very), liM(still)
f Temporal/spacial +(in), _h(on), ITO (between)
position word
m numeral â€”(one), :::(two), E(three)
n noun A Ft (people), 0 (tomato),
-i-I--ntn(computer)
nd Name of place It3&apos;it (Beijing), Ilk 5.1: A (Harbin),
fan(New York)
q classifier (flock), 1N(NULL)
r pronoun {(you), it(I, me), ith(he, him)
s location noun Pflid(around), A*(outside)
t time noun litX(yesterday), -EA (July)
ut tense auxiliary V ,T,1(NULL)
vb Complemental verb 34-6,it (NULL)
vg common verb 01-6(Imow), Fro42(long for)
vq directional verb ffl ,T*(NULL)
vz modal verb TIT I% (can), )Zi(should)
</bodyText>
<tableCaption confidence="0.941788">
Table for POS symbols used in Appendix
</tableCaption>
<page confidence="0.998326">
77
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.409750">
<title confidence="0.999954">Statistics Based Hybrid Approach to Chinese Base Phrase Identification</title>
<author confidence="0.998901">Tie-jun ZHAO</author>
<author confidence="0.998901">Mu-yun YANQ Fang LIU</author>
<author confidence="0.998901">Jian-min YAO</author>
<author confidence="0.998901">Hao YU</author>
<affiliation confidence="0.986434">Department of Computer Science and Engineering, Harbin Institute of</affiliation>
<email confidence="0.700764">tjzaho@mtlab.hit.edu.cn</email>
<email confidence="0.700764">ymy@mtlab.hit.edu.cn</email>
<email confidence="0.700764">liufang@mtlab.hit.edu.cn</email>
<email confidence="0.700764">james@mtlab.hit.edu.cn</email>
<email confidence="0.700764">yu@mtlab.hit.edu.cn</email>
<abstract confidence="0.999708076923077">This paper extends the base noun phrase(BNP) identification into a research on Chinese base phrase identification. After briefly introducing some basic concepts on Chinese base phrase, this paper presents a statistics based hybrid model for identifying 7 types of Chinese base phrases in view. Experiments show the efficiency of the proposed method in simplifying sentence structure. Significance of the research lies in it provides a solid foundation for the Chinese parser.</abstract>
<keyword confidence="0.794799">Keywords: Chinese base phrase identification, parsing, statistical model</keyword>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<title>A stochastic parts program and noun phrase parser for unrestricted text, In:</title>
<date>1988</date>
<booktitle>Proc. of Second Conference on Applied Natural Language Processing,</booktitle>
<marker>1988</marker>
<rawString> [Church, 19881 K. Church, A stochastic parts program and noun phrase parser for unrestricted text, In: Proc. of Second Conference on Applied Natural Language Processing, 1988</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Slcut</author>
<author>Thorsten Brants</author>
</authors>
<title>Chunk Tagger, Statistical Recongnition of Noun Phrases,</title>
<date>1998</date>
<booktitle>In ESSLLI-98 Workshop on Automated Acquisition of Syntax and Parsing, Saarbrvcken,</booktitle>
<marker>[Wojciech and Thorsten, 1998]</marker>
<rawString>Wojciech Slcut and Thorsten Brants, Chunk Tagger, Statistical Recongnition of Noun Phrases, In ESSLLI-98 Workshop on Automated Acquisition of Syntax and Parsing, Saarbrvcken, 1998.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Zhao Jun</author>
<author>Huang Chang-Ning</author>
</authors>
<title>The model for Chinese baseNP structure analysis,</title>
<journal>Chinese J. Computer,</journal>
<volume>22</volume>
<issue>2</issue>
<pages>141--146</pages>
<marker>[Zhao &amp; Huang, 1999]</marker>
<rawString>Zhao Jun and Huang Chang-Ning, The model for Chinese baseNP structure analysis, Chinese J. Computer, 22(2): pp141-146</rawString>
</citation>
<citation valid="false">
<authors>
<author>Thou Qiang</author>
</authors>
<title>Sun Mao-Song, Huang Chang-Ning, Chunk parsing scheme for Chinese sentences,</title>
<journal>Chinese J. Computer,</journal>
<volume>22</volume>
<issue>11</issue>
<pages>1159--1165</pages>
<marker>[Zhou, et al, 1999]</marker>
<rawString>Thou Qiang, Sun Mao-Song, Huang Chang-Ning, Chunk parsing scheme for Chinese sentences, Chinese J. Computer, 22(11): pp1159-1165</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>