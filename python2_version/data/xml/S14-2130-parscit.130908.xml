<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000381">
<title confidence="0.9859945">
UMCC DLSI: Sentiment Analysis in Twitter using Polirity Lexicons and
Tweet Similarity
</title>
<author confidence="0.809649">
Pedro Aniel S´anchez-Mirabal,
Yarelis Ruano Torres,
Suilen Hern´andez Alvarado
</author>
<affiliation confidence="0.990074">
University of Matanzas / Cuba
</affiliation>
<email confidence="0.956842">
pedroasm@umcc.cu
yara@umcc.cu
suilen.alvarado@umcc.cu
</email>
<sectionHeader confidence="0.993686" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999802611111111">
This paper describes a system sub-
mitted to SemEval-2014 Task 4B:
Sentiment Analysis in Twitter, by the
team UMCC DLSI Sem integrated by
researchers of the University of Matanzas,
Cuba and the University of Alicante,
Spain. The system adopts a cascade
classification process that uses two classi-
fiers, K-NN using the lexical Levenshtein
metric and a Dagging model trained over
attributes extracted from annotated cor-
pora and sentiment lexicons. Phrases that
fit the distance thresholds were automat-
ically classified by the KNN model, the
others, were evaluated with the Dagging
model. This system achieved over 52.4%
of correctly classified instances in the
Twitter message-level subtask.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999932333333333">
Nowadays, one of the most important sources of
data to extract useful and heterogeneous knowl-
edge is Textual Information. Daily, millions
of Tweets, SMS and blog comments increase
the huge volume of information available for re-
searchers. Texts can provide factual information,
such as: descriptions, lists of characteristics, or
even instructions to opinion-based information,
which would include reviews, emotions, or feel-
ings (Guti´errez et al., 2013). These facts have
motivated that dealing with the identification and
extraction of opinions and sentiments in texts re-
quires special attention. Applications of Senti-
ment Analysis are now more common than ever
in fields like politics and business. More than 50
</bodyText>
<footnote confidence="0.7551295">
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/
</footnote>
<author confidence="0.586909333333333">
Yoan Guti´errez,
Andr´es Montoyo,
Rafael Mu˜noz
</author>
<affiliation confidence="0.760549">
University of Alicante/Spain
</affiliation>
<email confidence="0.950399">
ygutierrez@dlsi.ua.es
montoyo@dlsi.ua.es
rafael@dlsi.ua.es
</email>
<bodyText confidence="0.999805195121951">
systems participating in this task, clearly indicate
the increase of interest in the scientific community.
Twitter messages can be found among of the
most used corpora nowadays for Sentiment Anal-
ysis (SA). This kind of messages involves an evi-
dent informality which has been addressed in dif-
ferent ways. For example, there are some works
like (Guti´errez et al., 2013) that apply normali-
sation textual tools to reduce the informality of
the twitter messages. Authors such as (Go et al.,
2009), (Guti´errez et al., 2013), (Fern´andez et al.,
2013) and others are focused on the application
of preprocessing processes and feature reduction
to be able to standardise twitter messages and re-
duce different types of elements like hashtags, user
nicks, urls, etc.
In terms of those techniques that can be used
for SA, we can cite (Pang et al., 2002) who built
a lexicon with associated polarity value, starting
with a set of classified seed adjectives and using
conjunctions (and) disjunctions (or, but) to deduce
the orientation of new words in a corpus. This re-
search was based on machine learning techniques
to address Sentiment Classification. Other inter-
esting research is (Turney, 2002), which classi-
fies words according to their polarity based on
the idea that terms with similar orientation tend
to co-occur in documents. There are a large quan-
tity of approaches to deal with SA, and basically
most of them are based on word bags and/or an-
notated corpora as knowledge base. Based on this
information the SA systems are able to apply dif-
ferent types of evaluation techniques such as ma-
chine learning or statistic formulas to predict the
correct classification. As part of machine learn-
ing approaches we would like to mention those
works such as (Go et al., 2009), (Mohammad et
al., 2013) and others that were based on feature
vectors and which cover a wide range settings of
SA. As a starting point, we based this work on
the (Mohammad et al., 2013) approach, adding
</bodyText>
<page confidence="0.961499">
727
</page>
<note confidence="0.7296145">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 727–731,
Dublin, Ireland, August 23-24, 2014.
</note>
<bodyText confidence="0.999746">
new features extracted from the sentiment repos-
itories Sentiment 140 1 and NRC-Hashtag Senti-
ment (Mohammad and Turney, 2013).
The remainder of this paper is structured as fol-
lows: section 2 describes in detail the approach
presented. In section 3 we explain the experiments
we carried out. Finally in section 4 conclusions
and future works are expounded.
</bodyText>
<sectionHeader confidence="0.963287" genericHeader="method">
2 System Description
</sectionHeader>
<bodyText confidence="0.999935052631579">
In this section we present our system in detail
which is able to classify the polarity of tweets as
positive, negative, or neutral.
The system is structured in two main stages.
The first stage consists of classifying a given
tweet. For that, we first recovered all the tweets
from the training corpus that have a similarity
value greater than a fixed threshold T. The sec-
ond stage consists of classifying using the K-NN
rule (Coomans and Massart, 1982), considering as
K all tweets recovered. The process begins with
T = 0.9 decreasing it until T = 0.6. In section 3
we will explain how these values were determined.
As similarity metric we use the Levenshtein
(Levenshtein, 1966) lexical distance. In case that
we cannot find any tweet fulfilling the condition,
the tweet polarity is assigned using a second clas-
sifier trained using Dagging which combines sev-
eral Logistic classifiers set by WEKA as default.
</bodyText>
<subsectionHeader confidence="0.989164">
2.1 Preprocessing
</subsectionHeader>
<bodyText confidence="0.907187923076923">
The first step in our system is to pre-process all
tweets. The following operations were applied in
the given order.
- Replacing emoticons: Each emoticon is
replaced by a word according to a
lexicon of emoticons. The mean-
ings of the emoticons were taken from
http://en.wikipedia.org/wiki/
List_of_emoticons.
- Replacing acronyms: Each acronym is re-
placed by its meaning. The meanings of the
acronyms were taken from http://www.
acronymfinder.com/.
</bodyText>
<listItem confidence="0.737483">
- Cleaning text: Remove not alphanumeric char-
acters from the tweet.
- Replacing abbreviations: Each abbrevia-
</listItem>
<bodyText confidence="0.539662">
tion is replaced by its respective words.
</bodyText>
<footnote confidence="0.890542">
1http://cs.stanford.edu/people/alecmgo/trainingandtestdata.zip
</footnote>
<bodyText confidence="0.993406111111111">
The abbreviations were taken from
http://en.wikipedia.org/wiki/
Abbreviation.
- Lemmatising: Each word is replaced by its
lemma. We use Freeling 3.0 (Padr´o and
Stanilovsky, 2012) for this purpose. We only
retain lemmas corresponding to adjectives,
adverbs, interjections, nouns and verbs.
- Expanding contractions: Each contraction
is replaced by its respective word. The
contractions were taken from http://
www.softschools.com/language_
arts/grammar/contractions/
contractions_list/.
- Deleting punctuation marks.
- Deleting stop words. The stop words
were taken from http://www.ranks.
nl/stopwords.
</bodyText>
<subsectionHeader confidence="0.999725">
2.2 Recovering tweets from similarity
</subsectionHeader>
<bodyText confidence="0.999979642857143">
As it was explained before, in a first step we tried
to classify tweets using the K-NN rule. To recover
the K similar tweets we used the Levenshtein met-
ric (Levenshtein, 1966). This measure allows to
compute the similarity of two strings of symbols
counting the minimum number of deletions, sub-
stitutions and insertions necessary to transform
one string into another. In our case, each word in
the string is considered as a symbol. In the future
we plan to improve this metric using Levenshtein
at word level and then at sentence level. This met-
ric is known as DLED (Double Levenshteins Edit
Distance) and will be taken from (Fern´andez et al.,
2012).
</bodyText>
<subsectionHeader confidence="0.616102">
2.3 Features for Dagging classifier
</subsectionHeader>
<bodyText confidence="0.999781333333333">
We represented each tweet as a vector of features
based in (Mohammad et al., 2013) plus other new
ones. Also we used the lexicons Sentiment 140
and NRC-Hashtag Sentiment as it was defined
by Mohammad.
Also two new lexicons, named NRC Emotion
Lexicon 1.0 and NRC Emotion Lexicon 2.0 were
derived from the NRC Emotion Lexicon (Mo-
hammad and Turney, 2013). In the first case we
associated to each word just the values in the
columns positive and negative of NRC Emotion
Lexicon, thus, no sentiment score was computed.
</bodyText>
<page confidence="0.989396">
728
</page>
<bodyText confidence="0.770536733333333">
For the second lexicon, the positive score was cal-
culated as the sum of the values for the classifica-
tions positive, anticipation, joy, surprise and trust.
On the other hand, the negative score was com-
puted as the sum of the values for the classifica-
tions negative, anger, disgust, fear, sadness and
trust.
In each case we computed the following at-
tributes:
- Pos: Sum of the positive scores of each token
in the tweet over the number of tokens in the
tweet.
- Neg: Sum of the negative scores of each token
in the tweet over the number of tokens in the
tweet.
</bodyText>
<equation confidence="0.3179745">
- PercentPos: 100∗Pos
Pos+Neg
</equation>
<bodyText confidence="0.99579072">
- MissNGram: Percent of tokens in the tweet that
were not found in the lexicon.
For the Sentiment 140 and NRC-Hashtag Sen-
timent lexicons we also computed the feature:
- SSE: Sum of the sentiment score of each token
in the tweet over the number of tokens in the
tweet.
Based on the information involved into Senti-
ment 140 and NRC-Hashtag Sentiment lexicons,
unigrams, bigrams and pairs were tokenised in-
volving any non-contiguous combination of the
previous n-grams. With respect to the pairs extrac-
tion were considered the following possibilities:
unigram-unigram, unigram-bigram and bigram-
bigram. Similar to (Mohammad et al., 2013) dif-
ferent set of attributes were generated for each
type of token. As result an initial set of 50 at-
tributes were obtained.
In the case of the new lexicons (NRC Emotion
Lexicon 1.0 and NRC Emotion Lexicon 2.0), only
unigrams were considered. Moreover, the feature
SSE was not computed. So, another 8 features
were taken into account with respect to these lexi-
cons.
Finally we computed:
</bodyText>
<listItem confidence="0.971172333333333">
- NCL: Percent of tokens in capital letters.
- NoE: Number of emoticons in the tweet.
- NoA: Number of acronyms in the tweet.
</listItem>
<bodyText confidence="0.782872">
In general the system works with a total of 61
attributes.
</bodyText>
<subsectionHeader confidence="0.979168">
2.4 Classifier Design
</subsectionHeader>
<bodyText confidence="0.995438375">
As training set, we joined the preprocessed tweets
from both the train and development sets pro-
vided by the Task9B of Semeval-2014. The
Dagging classifier was trained using this set
with the following parameters -F 15 -S 1 -W
weka.classifiers.functions.Logistic – -R 1.0E-8 -
M -1 using a 10 fold cross-validation as evaluation
method.
</bodyText>
<sectionHeader confidence="0.999542" genericHeader="method">
3 Experiments
</sectionHeader>
<bodyText confidence="0.999636666666667">
The experiments were evaluated over the training
dataset provided by Task 9: Sentiment Analysis in
Twitter, subtask B. Based on the explanation pro-
vided in section 2 according to the initialisation of
the threshold T to ensure that the K similar tweets
are in fact similar enough, we carried out an exper-
iment for different values of T. These experiments
refer an analysis to know how the variation of T
affects the classification results.
</bodyText>
<figure confidence="0.496908875">
T % CCI
0.9 86.7
0.8 83.3
0.7 74.1
0.6 67.2
0.5 61.1
0.4 55.0
0.3 56.0
</figure>
<tableCaption confidence="0.9974195">
Table 1: Results of the K-NN classifier using Lev-
enshtein metric.
</tableCaption>
<table confidence="0.999683">
T % CCI
0.9 81.2
0.8 83.3
0.7 74.1
0.6 66.7
0.5 63.1
0.4 60.6
0.3 54.2
</table>
<tableCaption confidence="0.954474">
Table 2: Results of the K-NN classifier using
Matching Coefficient metric.
</tableCaption>
<bodyText confidence="0.998657142857143">
The first stage of the system was applied to
compute the number of instances which have at
least one instance with a similarity value greater
than T. We computed the percent of instances
correctly classified (%CCI). Table 1 shows the
behaviour of the system when T changes. Table
2 shows the results of the K-NN classifier using
</bodyText>
<page confidence="0.994995">
729
</page>
<table confidence="0.9998648">
System LiveJournal2014 SMS2013 Twitter2013 Twitter2014 Twitter2014Sarcasm
Best result 74.8 70.3 72.1 71.0 58.2
Average result 63.5 55.6 59.8 60.6 45.4
UMCC-DLSI-Sem 53.1 50.0 52.0 55.4 42.8
Worse result 29.3 24.6 34.2 33.0 29.0
</table>
<tableCaption confidence="0.99997">
Table 3: Results in the SemEval-2014 Task 4B.
</tableCaption>
<bodyText confidence="0.99241937037037">
Matching Coefficient metric (http://www.
coli.uni-saarland.de/courses/LT1/
2011/slides/stringmetrics.pdf).
This metric counts the quantity of matched
symbols (words in this case) between two
sentences.
Furthermore, we repeated this experiment using
the Matching Coefficient similarity metric to bet-
ter tunning the algorithm and to evaluate if the re-
sults behave in a similar way when T changes. In
both cases, we use the implementation provided in
the SimMetrics library.
As those results shows, when T decrease the ac-
curacy decrease too. In practice, for the values of
T lower than 0.6 the results are worse than 61.4%
using the Dagging classifier in the 10 fold cross-
validation. For that reason, as was mentioned in 2,
we only tried to apply the first stage for values of
T ≥ 0.6 .
We evaluated our system in the challenge Task
4B: Sentiment Analysis in Twitter, using the pro-
vided training and test data of this challenge.
Based on the classifier obtained in the training pro-
cess we tested our system over the test dataset
achieving values of %CCI up to 55.4. Table 3
show detailed results for each of the 5 different
sources.
</bodyText>
<sectionHeader confidence="0.998794" genericHeader="conclusions">
4 Conclusions and Future Works
</sectionHeader>
<bodyText confidence="0.999904285714286">
Our system was based on an approach that follows
two stages to classify the polarity of tweets. Re-
gardless the fact that our system behaves worse
than the average, we consider that the approach is
suitable to deal with SA, since our results are close
to the average. As future works we will study
other approaches in order to encourage further de-
velopments of this proposal. Several issues could
be adjusted, for example, other distances should be
tested and evaluated such as DLED (Double Lev-
enshteins Edit Distance) (Fern´andez et al., 2012).
Also, features that encode information about the
presence of negation and opposition words could
be very useful.
</bodyText>
<sectionHeader confidence="0.994732" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999694777777778">
This research work has been partially funded
by the University of Alicante, Generalitat Va-
lenciana, Spanish Government and the European
Commission through the projects, ”Tratamiento
inteligente de la informacin para la ayuda a la toma
de decisiones” (GRE12-44), ATTOS (TIN2012-
38536-C03-03), LEGOLANG (TIN2012-31224),
SAM (FP7-611312), FIRST (FP7-287607) and
ACOMP/2013/067.
</bodyText>
<sectionHeader confidence="0.99884" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998311029411765">
D. Coomans and D.L. Massart. 1982. Alternative k-
nearest neighbour rules in supervised pattern recog-
nition : Part 1. k-nearest neighbour classification by
using alternative voting rules. Analytica Chimica
Acta, 136(0):15–27.
Antonio Fern´andez, Yoan Guti´errez, H´ector D´avila,
Alexander Ch´avez, Andy Gonz´alez, Rainel Estrada,
Yenier Casta˜neda, Sonia V´azquez, Andr´es Montoyo,
and Rafael Mu˜noz. 2012. Umcc dlsi: Multidimen-
sional lexical-semantic textual similarity. In *SEM
2012: The First Joint Conference on Lexical and
Computational Semantics – Volume 1: Proceedings
of the main conference and the shared task, and Vol-
ume 2: Proceedings of the Sixth International Work-
shop on Semantic Evaluation (SemEval2012), pages
608–616, Montr´eal, Canada, 7-8 June. Association
for Computational Linguistics.
Javi Fern´andez, Yoan Guti´errez, Jos´e M G´omez, Patri-
cio Martınez-Barco, Andr´es Montoyo, and Rafael
Munoz. 2013. Sentiment analysis of spanish tweets
using a ranking algorithm and skipgrams. Proc. of
the TASS workshop at SEPLN 2013. IV Congreso
Espa˜nol de Inform´atica, pages 17–20.
Alec Go, Richa Bhayani, and Lei Huang. 2009. Twit-
ter sentiment classification using distant supervision.
Processing, pages 1–6.
Yoan Guti´errez, Andy Gonz´alez, Roger P´erez, Jos´e I.
Abreu, Antonio Fern´andez Orqu´ın, Alejandro Mos-
quera, Andr´es Montoyo, Rafael Mu˜noz, and Franc
Camara. 2013. Umcc dlsi-(sa): Using a ranking
algorithm and informal features to solve sentiment
analysis in twitter. In Second Joint Conference on
Lexical and Computational Semantics (*SEM), Vol-
ume 2: Proceedings of the Seventh International
</reference>
<page confidence="0.963807">
730
</page>
<reference confidence="0.999171375">
Workshop on Semantic Evaluation (SemEval 2013),
pages 443–449, Atlanta, Georgia, USA, June. Asso-
ciation for Computational Linguistics.
Vladimir Levenshtein. 1966. Binary codes capa-
ble of correcting deletions, insertions, and rever-
sals. Cybernetics and Control Theory, 10(8):707–
710. Original in Doklady Akademii Nauk SSSR
163(4): 845–848 (1965).
Saif M. Mohammad and Peter D. Turney. 2013.
Crowdsourcing a word-emotion association lexicon.
29(3):436–465.
Saif M. Mohammad, Svetlana Kiritchenko, and Xiao-
dan Zhu. 2013. Nrc-canada: Building the state-
of-the-art in sentiment analysis of tweets. CoRR,
abs/1308.6242.
Llu´ıs Padr´o and Evgeny Stanilovsky. 2012. Freeling
3.0: Towards wider multilinguality. In Proceedings
of the Language Resources and Evaluation Confer-
ence (LREC 2012), Istanbul, Turkey, May. ELRA.
Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan.
2002. Thumbs up?: Sentiment classification using
machine learning techniques. In Proceedings of the
ACL-02 Conference on Empirical Methods in Natu-
ral Language Processing - Volume 10, EMNLP ’02,
pages 79–86, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Peter D. Turney. 2002. Thumbs up or thumbs down?:
Semantic orientation applied to unsupervised classi-
fication of reviews. In Proceedings of the 40th An-
nual Meeting on Association for Computational Lin-
guistics, ACL ’02, pages 417–424, Stroudsburg, PA,
USA. Association for Computational Linguistics.
</reference>
<page confidence="0.99801">
731
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.299073">
<title confidence="0.97305">UMCC DLSI: Sentiment Analysis in Twitter using Polirity Lexicons and Tweet Similarity</title>
<author confidence="0.947958333333333">Pedro Aniel Yarelis Ruano Suilen Hern´andez</author>
<affiliation confidence="0.998934">University of Matanzas /</affiliation>
<email confidence="0.969966">suilen.alvarado@umcc.cu</email>
<abstract confidence="0.859443263157895">This paper describes a system subto Task 4B: Analysis in by the DLSI Sem by researchers of the University of Matanzas, Cuba and the University of Alicante, Spain. The system adopts a cascade classification process that uses two classiusing the lexical Levenshtein metric and a Dagging model trained over attributes extracted from annotated corpora and sentiment lexicons. Phrases that fit the distance thresholds were automatically classified by the KNN model, the others, were evaluated with the Dagging This system achieved over of correctly classified instances in the Twitter message-level subtask.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Coomans</author>
<author>D L Massart</author>
</authors>
<title>Alternative knearest neighbour rules in supervised pattern recognition : Part 1. k-nearest neighbour classification by using alternative voting rules.</title>
<date>1982</date>
<journal>Analytica Chimica Acta,</journal>
<volume>136</volume>
<issue>0</issue>
<contexts>
<context position="4960" citStr="Coomans and Massart, 1982" startWordPosition="767" endWordPosition="770"> detail the approach presented. In section 3 we explain the experiments we carried out. Finally in section 4 conclusions and future works are expounded. 2 System Description In this section we present our system in detail which is able to classify the polarity of tweets as positive, negative, or neutral. The system is structured in two main stages. The first stage consists of classifying a given tweet. For that, we first recovered all the tweets from the training corpus that have a similarity value greater than a fixed threshold T. The second stage consists of classifying using the K-NN rule (Coomans and Massart, 1982), considering as K all tweets recovered. The process begins with T = 0.9 decreasing it until T = 0.6. In section 3 we will explain how these values were determined. As similarity metric we use the Levenshtein (Levenshtein, 1966) lexical distance. In case that we cannot find any tweet fulfilling the condition, the tweet polarity is assigned using a second classifier trained using Dagging which combines several Logistic classifiers set by WEKA as default. 2.1 Preprocessing The first step in our system is to pre-process all tweets. The following operations were applied in the given order. - Repla</context>
</contexts>
<marker>Coomans, Massart, 1982</marker>
<rawString>D. Coomans and D.L. Massart. 1982. Alternative knearest neighbour rules in supervised pattern recognition : Part 1. k-nearest neighbour classification by using alternative voting rules. Analytica Chimica Acta, 136(0):15–27.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Antonio Fern´andez</author>
<author>Yoan Guti´errez</author>
<author>H´ector D´avila</author>
<author>Alexander Ch´avez</author>
<author>Andy Gonz´alez</author>
<author>Rainel Estrada</author>
<author>Yenier Casta˜neda</author>
<author>Sonia V´azquez</author>
<author>Andr´es Montoyo</author>
<author>Rafael Mu˜noz</author>
</authors>
<title>Umcc dlsi: Multidimensional lexical-semantic textual similarity.</title>
<date>2012</date>
<booktitle>In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval2012),</booktitle>
<pages>608--616</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal,</location>
<marker>Fern´andez, Guti´errez, D´avila, Ch´avez, Gonz´alez, Estrada, Casta˜neda, V´azquez, Montoyo, Mu˜noz, 2012</marker>
<rawString>Antonio Fern´andez, Yoan Guti´errez, H´ector D´avila, Alexander Ch´avez, Andy Gonz´alez, Rainel Estrada, Yenier Casta˜neda, Sonia V´azquez, Andr´es Montoyo, and Rafael Mu˜noz. 2012. Umcc dlsi: Multidimensional lexical-semantic textual similarity. In *SEM 2012: The First Joint Conference on Lexical and Computational Semantics – Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation (SemEval2012), pages 608–616, Montr´eal, Canada, 7-8 June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Javi Fern´andez</author>
<author>Yoan Guti´errez</author>
<author>Jos´e M G´omez</author>
<author>Patricio Martınez-Barco</author>
<author>Andr´es Montoyo</author>
<author>Rafael Munoz</author>
</authors>
<title>Sentiment analysis of spanish tweets using a ranking algorithm and skipgrams.</title>
<date>2013</date>
<booktitle>Proc. of the TASS workshop at SEPLN 2013. IV Congreso Espa˜nol de Inform´atica,</booktitle>
<pages>17--20</pages>
<marker>Fern´andez, Guti´errez, G´omez, Martınez-Barco, Montoyo, Munoz, 2013</marker>
<rawString>Javi Fern´andez, Yoan Guti´errez, Jos´e M G´omez, Patricio Martınez-Barco, Andr´es Montoyo, and Rafael Munoz. 2013. Sentiment analysis of spanish tweets using a ranking algorithm and skipgrams. Proc. of the TASS workshop at SEPLN 2013. IV Congreso Espa˜nol de Inform´atica, pages 17–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alec Go</author>
<author>Richa Bhayani</author>
<author>Lei Huang</author>
</authors>
<title>Twitter sentiment classification using distant supervision.</title>
<date>2009</date>
<booktitle>Processing,</booktitle>
<pages>1--6</pages>
<contexts>
<context position="2515" citStr="Go et al., 2009" startWordPosition="360" endWordPosition="363">rez, Andr´es Montoyo, Rafael Mu˜noz University of Alicante/Spain ygutierrez@dlsi.ua.es montoyo@dlsi.ua.es rafael@dlsi.ua.es systems participating in this task, clearly indicate the increase of interest in the scientific community. Twitter messages can be found among of the most used corpora nowadays for Sentiment Analysis (SA). This kind of messages involves an evident informality which has been addressed in different ways. For example, there are some works like (Guti´errez et al., 2013) that apply normalisation textual tools to reduce the informality of the twitter messages. Authors such as (Go et al., 2009), (Guti´errez et al., 2013), (Fern´andez et al., 2013) and others are focused on the application of preprocessing processes and feature reduction to be able to standardise twitter messages and reduce different types of elements like hashtags, user nicks, urls, etc. In terms of those techniques that can be used for SA, we can cite (Pang et al., 2002) who built a lexicon with associated polarity value, starting with a set of classified seed adjectives and using conjunctions (and) disjunctions (or, but) to deduce the orientation of new words in a corpus. This research was based on machine learnin</context>
<context position="3786" citStr="Go et al., 2009" startWordPosition="573" endWordPosition="576"> interesting research is (Turney, 2002), which classifies words according to their polarity based on the idea that terms with similar orientation tend to co-occur in documents. There are a large quantity of approaches to deal with SA, and basically most of them are based on word bags and/or annotated corpora as knowledge base. Based on this information the SA systems are able to apply different types of evaluation techniques such as machine learning or statistic formulas to predict the correct classification. As part of machine learning approaches we would like to mention those works such as (Go et al., 2009), (Mohammad et al., 2013) and others that were based on feature vectors and which cover a wide range settings of SA. As a starting point, we based this work on the (Mohammad et al., 2013) approach, adding 727 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 727–731, Dublin, Ireland, August 23-24, 2014. new features extracted from the sentiment repositories Sentiment 140 1 and NRC-Hashtag Sentiment (Mohammad and Turney, 2013). The remainder of this paper is structured as follows: section 2 describes in detail the approach presented. In section 3 we expl</context>
</contexts>
<marker>Go, Bhayani, Huang, 2009</marker>
<rawString>Alec Go, Richa Bhayani, and Lei Huang. 2009. Twitter sentiment classification using distant supervision. Processing, pages 1–6.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Yoan Guti´errez</author>
<author>Andy Gonz´alez</author>
<author>Roger P´erez</author>
<author>Jos´e I Abreu</author>
<author>Antonio Fern´andez Orqu´ın</author>
<author>Alejandro Mosquera</author>
<author>Andr´es Montoyo</author>
<author>Rafael Mu˜noz</author>
<author>Franc Camara</author>
</authors>
<title>Umcc dlsi-(sa): Using a ranking algorithm and informal features to solve sentiment analysis in twitter.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval</booktitle>
<pages>443--449</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Atlanta, Georgia, USA,</location>
<marker>Guti´errez, Gonz´alez, P´erez, Abreu, Orqu´ın, Mosquera, Montoyo, Mu˜noz, Camara, 2013</marker>
<rawString>Yoan Guti´errez, Andy Gonz´alez, Roger P´erez, Jos´e I. Abreu, Antonio Fern´andez Orqu´ın, Alejandro Mosquera, Andr´es Montoyo, Rafael Mu˜noz, and Franc Camara. 2013. Umcc dlsi-(sa): Using a ranking algorithm and informal features to solve sentiment analysis in twitter. In Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Proceedings of the Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 443–449, Atlanta, Georgia, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vladimir Levenshtein</author>
</authors>
<title>Binary codes capable of correcting deletions, insertions, and reversals.</title>
<date>1966</date>
<booktitle>Cybernetics and Control Theory, 10(8):707– 710. Original in Doklady Akademii Nauk SSSR</booktitle>
<volume>163</volume>
<issue>4</issue>
<pages>845--848</pages>
<contexts>
<context position="5188" citStr="Levenshtein, 1966" startWordPosition="808" endWordPosition="809">to classify the polarity of tweets as positive, negative, or neutral. The system is structured in two main stages. The first stage consists of classifying a given tweet. For that, we first recovered all the tweets from the training corpus that have a similarity value greater than a fixed threshold T. The second stage consists of classifying using the K-NN rule (Coomans and Massart, 1982), considering as K all tweets recovered. The process begins with T = 0.9 decreasing it until T = 0.6. In section 3 we will explain how these values were determined. As similarity metric we use the Levenshtein (Levenshtein, 1966) lexical distance. In case that we cannot find any tweet fulfilling the condition, the tweet polarity is assigned using a second classifier trained using Dagging which combines several Logistic classifiers set by WEKA as default. 2.1 Preprocessing The first step in our system is to pre-process all tweets. The following operations were applied in the given order. - Replacing emoticons: Each emoticon is replaced by a word according to a lexicon of emoticons. The meanings of the emoticons were taken from http://en.wikipedia.org/wiki/ List_of_emoticons. - Replacing acronyms: Each acronym is replac</context>
<context position="6913" citStr="Levenshtein, 1966" startWordPosition="1051" endWordPosition="1052">We only retain lemmas corresponding to adjectives, adverbs, interjections, nouns and verbs. - Expanding contractions: Each contraction is replaced by its respective word. The contractions were taken from http:// www.softschools.com/language_ arts/grammar/contractions/ contractions_list/. - Deleting punctuation marks. - Deleting stop words. The stop words were taken from http://www.ranks. nl/stopwords. 2.2 Recovering tweets from similarity As it was explained before, in a first step we tried to classify tweets using the K-NN rule. To recover the K similar tweets we used the Levenshtein metric (Levenshtein, 1966). This measure allows to compute the similarity of two strings of symbols counting the minimum number of deletions, substitutions and insertions necessary to transform one string into another. In our case, each word in the string is considered as a symbol. In the future we plan to improve this metric using Levenshtein at word level and then at sentence level. This metric is known as DLED (Double Levenshteins Edit Distance) and will be taken from (Fern´andez et al., 2012). 2.3 Features for Dagging classifier We represented each tweet as a vector of features based in (Mohammad et al., 2013) plus</context>
</contexts>
<marker>Levenshtein, 1966</marker>
<rawString>Vladimir Levenshtein. 1966. Binary codes capable of correcting deletions, insertions, and reversals. Cybernetics and Control Theory, 10(8):707– 710. Original in Doklady Akademii Nauk SSSR 163(4): 845–848 (1965).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Peter D Turney</author>
</authors>
<title>Crowdsourcing a word-emotion association lexicon.</title>
<date>2013</date>
<pages>29--3</pages>
<contexts>
<context position="4256" citStr="Mohammad and Turney, 2013" startWordPosition="648" endWordPosition="651">tistic formulas to predict the correct classification. As part of machine learning approaches we would like to mention those works such as (Go et al., 2009), (Mohammad et al., 2013) and others that were based on feature vectors and which cover a wide range settings of SA. As a starting point, we based this work on the (Mohammad et al., 2013) approach, adding 727 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 727–731, Dublin, Ireland, August 23-24, 2014. new features extracted from the sentiment repositories Sentiment 140 1 and NRC-Hashtag Sentiment (Mohammad and Turney, 2013). The remainder of this paper is structured as follows: section 2 describes in detail the approach presented. In section 3 we explain the experiments we carried out. Finally in section 4 conclusions and future works are expounded. 2 System Description In this section we present our system in detail which is able to classify the polarity of tweets as positive, negative, or neutral. The system is structured in two main stages. The first stage consists of classifying a given tweet. For that, we first recovered all the tweets from the training corpus that have a similarity value greater than a fix</context>
<context position="7777" citStr="Mohammad and Turney, 2013" startWordPosition="1195" endWordPosition="1199">dered as a symbol. In the future we plan to improve this metric using Levenshtein at word level and then at sentence level. This metric is known as DLED (Double Levenshteins Edit Distance) and will be taken from (Fern´andez et al., 2012). 2.3 Features for Dagging classifier We represented each tweet as a vector of features based in (Mohammad et al., 2013) plus other new ones. Also we used the lexicons Sentiment 140 and NRC-Hashtag Sentiment as it was defined by Mohammad. Also two new lexicons, named NRC Emotion Lexicon 1.0 and NRC Emotion Lexicon 2.0 were derived from the NRC Emotion Lexicon (Mohammad and Turney, 2013). In the first case we associated to each word just the values in the columns positive and negative of NRC Emotion Lexicon, thus, no sentiment score was computed. 728 For the second lexicon, the positive score was calculated as the sum of the values for the classifications positive, anticipation, joy, surprise and trust. On the other hand, the negative score was computed as the sum of the values for the classifications negative, anger, disgust, fear, sadness and trust. In each case we computed the following attributes: - Pos: Sum of the positive scores of each token in the tweet over the numbe</context>
</contexts>
<marker>Mohammad, Turney, 2013</marker>
<rawString>Saif M. Mohammad and Peter D. Turney. 2013. Crowdsourcing a word-emotion association lexicon. 29(3):436–465.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saif M Mohammad</author>
<author>Svetlana Kiritchenko</author>
<author>Xiaodan Zhu</author>
</authors>
<title>Nrc-canada: Building the stateof-the-art in sentiment analysis of tweets.</title>
<date>2013</date>
<journal>CoRR,</journal>
<pages>1308--6242</pages>
<contexts>
<context position="3811" citStr="Mohammad et al., 2013" startWordPosition="577" endWordPosition="580">ch is (Turney, 2002), which classifies words according to their polarity based on the idea that terms with similar orientation tend to co-occur in documents. There are a large quantity of approaches to deal with SA, and basically most of them are based on word bags and/or annotated corpora as knowledge base. Based on this information the SA systems are able to apply different types of evaluation techniques such as machine learning or statistic formulas to predict the correct classification. As part of machine learning approaches we would like to mention those works such as (Go et al., 2009), (Mohammad et al., 2013) and others that were based on feature vectors and which cover a wide range settings of SA. As a starting point, we based this work on the (Mohammad et al., 2013) approach, adding 727 Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 727–731, Dublin, Ireland, August 23-24, 2014. new features extracted from the sentiment repositories Sentiment 140 1 and NRC-Hashtag Sentiment (Mohammad and Turney, 2013). The remainder of this paper is structured as follows: section 2 describes in detail the approach presented. In section 3 we explain the experiments we ca</context>
<context position="7508" citStr="Mohammad et al., 2013" startWordPosition="1150" endWordPosition="1153"> metric (Levenshtein, 1966). This measure allows to compute the similarity of two strings of symbols counting the minimum number of deletions, substitutions and insertions necessary to transform one string into another. In our case, each word in the string is considered as a symbol. In the future we plan to improve this metric using Levenshtein at word level and then at sentence level. This metric is known as DLED (Double Levenshteins Edit Distance) and will be taken from (Fern´andez et al., 2012). 2.3 Features for Dagging classifier We represented each tweet as a vector of features based in (Mohammad et al., 2013) plus other new ones. Also we used the lexicons Sentiment 140 and NRC-Hashtag Sentiment as it was defined by Mohammad. Also two new lexicons, named NRC Emotion Lexicon 1.0 and NRC Emotion Lexicon 2.0 were derived from the NRC Emotion Lexicon (Mohammad and Turney, 2013). In the first case we associated to each word just the values in the columns positive and negative of NRC Emotion Lexicon, thus, no sentiment score was computed. 728 For the second lexicon, the positive score was calculated as the sum of the values for the classifications positive, anticipation, joy, surprise and trust. On the o</context>
<context position="9166" citStr="Mohammad et al., 2013" startWordPosition="1434" endWordPosition="1437">m: Percent of tokens in the tweet that were not found in the lexicon. For the Sentiment 140 and NRC-Hashtag Sentiment lexicons we also computed the feature: - SSE: Sum of the sentiment score of each token in the tweet over the number of tokens in the tweet. Based on the information involved into Sentiment 140 and NRC-Hashtag Sentiment lexicons, unigrams, bigrams and pairs were tokenised involving any non-contiguous combination of the previous n-grams. With respect to the pairs extraction were considered the following possibilities: unigram-unigram, unigram-bigram and bigrambigram. Similar to (Mohammad et al., 2013) different set of attributes were generated for each type of token. As result an initial set of 50 attributes were obtained. In the case of the new lexicons (NRC Emotion Lexicon 1.0 and NRC Emotion Lexicon 2.0), only unigrams were considered. Moreover, the feature SSE was not computed. So, another 8 features were taken into account with respect to these lexicons. Finally we computed: - NCL: Percent of tokens in capital letters. - NoE: Number of emoticons in the tweet. - NoA: Number of acronyms in the tweet. In general the system works with a total of 61 attributes. 2.4 Classifier Design As tra</context>
</contexts>
<marker>Mohammad, Kiritchenko, Zhu, 2013</marker>
<rawString>Saif M. Mohammad, Svetlana Kiritchenko, and Xiaodan Zhu. 2013. Nrc-canada: Building the stateof-the-art in sentiment analysis of tweets. CoRR, abs/1308.6242.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Llu´ıs Padr´o</author>
<author>Evgeny Stanilovsky</author>
</authors>
<title>Freeling 3.0: Towards wider multilinguality.</title>
<date>2012</date>
<booktitle>In Proceedings of the Language Resources and Evaluation Conference (LREC 2012),</booktitle>
<publisher>ELRA.</publisher>
<location>Istanbul, Turkey,</location>
<marker>Padr´o, Stanilovsky, 2012</marker>
<rawString>Llu´ıs Padr´o and Evgeny Stanilovsky. 2012. Freeling 3.0: Towards wider multilinguality. In Proceedings of the Language Resources and Evaluation Conference (LREC 2012), Istanbul, Turkey, May. ELRA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Pang</author>
<author>Lillian Lee</author>
<author>Shivakumar Vaithyanathan</author>
</authors>
<title>Thumbs up?: Sentiment classification using machine learning techniques.</title>
<date>2002</date>
<booktitle>In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP ’02,</booktitle>
<pages>79--86</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2866" citStr="Pang et al., 2002" startWordPosition="419" endWordPosition="422">es involves an evident informality which has been addressed in different ways. For example, there are some works like (Guti´errez et al., 2013) that apply normalisation textual tools to reduce the informality of the twitter messages. Authors such as (Go et al., 2009), (Guti´errez et al., 2013), (Fern´andez et al., 2013) and others are focused on the application of preprocessing processes and feature reduction to be able to standardise twitter messages and reduce different types of elements like hashtags, user nicks, urls, etc. In terms of those techniques that can be used for SA, we can cite (Pang et al., 2002) who built a lexicon with associated polarity value, starting with a set of classified seed adjectives and using conjunctions (and) disjunctions (or, but) to deduce the orientation of new words in a corpus. This research was based on machine learning techniques to address Sentiment Classification. Other interesting research is (Turney, 2002), which classifies words according to their polarity based on the idea that terms with similar orientation tend to co-occur in documents. There are a large quantity of approaches to deal with SA, and basically most of them are based on word bags and/or anno</context>
</contexts>
<marker>Pang, Lee, Vaithyanathan, 2002</marker>
<rawString>Bo Pang, Lillian Lee, and Shivakumar Vaithyanathan. 2002. Thumbs up?: Sentiment classification using machine learning techniques. In Proceedings of the ACL-02 Conference on Empirical Methods in Natural Language Processing - Volume 10, EMNLP ’02, pages 79–86, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02,</booktitle>
<pages>417--424</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3209" citStr="Turney, 2002" startWordPosition="474" endWordPosition="475">the application of preprocessing processes and feature reduction to be able to standardise twitter messages and reduce different types of elements like hashtags, user nicks, urls, etc. In terms of those techniques that can be used for SA, we can cite (Pang et al., 2002) who built a lexicon with associated polarity value, starting with a set of classified seed adjectives and using conjunctions (and) disjunctions (or, but) to deduce the orientation of new words in a corpus. This research was based on machine learning techniques to address Sentiment Classification. Other interesting research is (Turney, 2002), which classifies words according to their polarity based on the idea that terms with similar orientation tend to co-occur in documents. There are a large quantity of approaches to deal with SA, and basically most of them are based on word bags and/or annotated corpora as knowledge base. Based on this information the SA systems are able to apply different types of evaluation techniques such as machine learning or statistic formulas to predict the correct classification. As part of machine learning approaches we would like to mention those works such as (Go et al., 2009), (Mohammad et al., 201</context>
</contexts>
<marker>Turney, 2002</marker>
<rawString>Peter D. Turney. 2002. Thumbs up or thumbs down?: Semantic orientation applied to unsupervised classification of reviews. In Proceedings of the 40th Annual Meeting on Association for Computational Linguistics, ACL ’02, pages 417–424, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>