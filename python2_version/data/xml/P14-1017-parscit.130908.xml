<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000139">
<title confidence="0.9935885">
The effect of wording on message propagation:
Topic- and author-controlled natural experiments on Twitter
</title>
<author confidence="0.995463">
Chenhao Tan Lillian Lee Bo Pang
</author>
<affiliation confidence="0.9998065">
Dept. of Computer Science Dept. of Computer Science Google Inc.
Cornell University Cornell University bopang42@gmail.com
</affiliation>
<email confidence="0.99855">
chenhao@cs.cornell.edu llee@cs.cornell.edu
</email>
<sectionHeader confidence="0.997386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999898041666667">
Consider a person trying to spread an
important message on a social network.
He/she can spend hours trying to craft the
message. Does it actually matter? While
there has been extensive prior work look-
ing into predicting popularity of social-
media content, the effect of wording per
se has rarely been studied since it is of-
ten confounded with the popularity of the
author and the topic. To control for these
confounding factors, we take advantage
of the surprising fact that there are many
pairs of tweets containing the same url and
written by the same user but employing
different wording. Given such pairs, we
ask: which version attracts more retweets?
This turns out to be a more difficult task
than predicting popular topics. Still, hu-
mans can answer this question better than
chance (but far from perfectly), and the
computational methods we develop can do
better than both an average human and a
strong competing method trained on non-
controlled data.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999800754716981">
How does one make a message “successful”? This
question is of interest to many entities, including
political parties trying to frame an issue (Chong
and Druckman, 2007), and individuals attempting
to make a point in a group meeting. In the first
case, an important type of success is achieved if
the national conversation adopts the rhetoric of the
party; in the latter case, if other group members
repeat the originating individual’s point.
The massive availability of online messages,
such as posts to social media, now affords re-
searchers new means to investigate at a very large
scale the factors affecting message propagation,
also known as adoption, sharing, spread, or vi-
rality. According to prior research, important fea-
tures include characteristics of the originating au-
thor (e.g., verified Twitter user or not, author’s
messages’ past success rate), the author’s social
network (e.g., number of followers), message tim-
ing, and message content or topic (Artzi et al.,
2012; Bakshy et al., 2011; Borghol et al., 2012;
Guerini et al., 2011; Guerini et al., 2012; Hansen
et al., 2011; Hong et al., 2011; Lakkaraju et al.,
2013; Milkman and Berger, 2012; Ma et al., 2012;
Petrovi´c et al., 2011; Romero et al., 2013; Suh et
al., 2010; Sun et al., 2013; Tsur and Rappoport,
2012). Indeed, it’s not surprising that one of the
most retweeted tweets of all time was from user
BarackObama, with 40M followers, on November
6, 2012: “Four more years. [link to photo]”.
Our interest in this paper is the effect of alterna-
tive message wording, meaning how the message
is said, rather than what the message is about. In
contrast to the identity/social/timing/topic features
mentioned above, wording is one of the few fac-
tors directly under an author’s control when he or
she seeks to convey a fixed piece of content. For
example, consider a speaker at the ACL business
meeting who has been tasked with proposing that
Paris be the next ACL location. This person can-
not on the spot become ACL president, change the
shape of his/her social network, wait until the next
morning to speak, or campaign for Rome instead;
but he/she can craft the message to be more hu-
morous, more informative, emphasize certain as-
pects instead of others, and so on. In other words,
we investigate whether a different choice of words
affects message propagation, controlling for user
and topic: would user BarackObama have gotten
significantly more (or fewer) retweets if he had
used some alternate wording to announce his re-
election?
Although we cannot create a parallel universe
</bodyText>
<page confidence="0.982154">
175
</page>
<note confidence="0.897148">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 175–185,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<tableCaption confidence="0.994842">
Table 1: Topic- and author-controlled (TAC) pairs. Topic control = inclusion of the same URL.
</tableCaption>
<note confidence="0.996986222222222">
author tweets #retweets
natlsecuritycnn t1: FIRST ON CNN: After Petraeus scandal, Paula Broadwell looks to recapture ‘normal life.’ http://t.co/qy7GGuYW n1 = 5
t2: First on CNN: Broadwell photos shared with Security Clearance as she and her family fight media portrayal of her [same URL] n2 = 29
ABC t1: Workers, families take stand against Thanksgiving hours: http://t.co/J9mQHiIEqv n1 = 46
t2: Staples, Medieval Times Workers Say Opening Thanksgiving Day Crosses the Line [same URL] n2 = 27
cactus music t1: I know at some point you’ve have been saved from hunger by our rolling food trucks friends. Let’s help support them! n1 = 2
http://t.co/zg9jwA5j
t2: Food trucks are the epitome of small independently owned LOCAL businesses! Help keep them going! Sign the petition [same n2 = 13
URL]
</note>
<bodyText confidence="0.901741125">
in which BarackObama tweeted something else1,
fortunately, a surprising characteristic of Twitter
allows us to run a fairly analogous natural exper-
iment: external forces serendipitously provide an
environment that resembles the desired controlled
setting (DiNardo, 2008). Specifically, it turns out
to be unexpectedly common for the same user to
post different tweets regarding the same URL —
a good proxy for fine-grained topic2 — within a
relatively short period of time.3 Some example
pairs are shown in Table 1; we see that the paired
tweets may differ dramatically, going far beyond
word-for-word substitutions, so that quite interest-
ing changes can be studied.
Looking at these examples, can one in fact tell
from the wording which tweet in a topic- and
author-controlled pair will be more successful?
The answer may not be a priori clear. For example,
for the first pair in the table, one person we asked
found t1’s invocation of a “scandal” to be more
attention-grabbing; but another person preferred
t2 because it is more informative about the URL’s
content and includes “fight media portrayal”. In
an Amazon Mechanical Turk (AMT) experiment
(§4), we found that humans achieved an average
accuracy of 61.3%: not that high, but better than
chance, indicating that it is somewhat possible for
humans to predict greater message spread from
different deliveries of the same information.
Buoyed by the evidence of our AMT study that
wording effects exist, we then performed a battery
of experiments to seek generally-applicable, non-
1Cf. the Music Lab “multiple universes” experiment to
test the randomness of popularity (Salganik et al., 2006).
2Although hashtags have been used as coarse-grained
topic labels in prior work, for our purposes, we have no assur-
ance that two tweets both using, say, “#Tahrir” would be at-
tempting to express the same message but in different words.
In contrast, see the same-URL examples in Table 1.
3Moreover, Twitter presents tweets to a reader in strict
chronological order, so that there are no algorithmic-ranking
effects to compensate for in determining whether readers saw
a tweet. And, Twitter accumulates retweet counts for the en-
tire retweet cascade and displays them for the original tweet
at the root of the propagation tree, so we can directly use
Twitter’s retweet counts to compare the entire reach of the
different versions.
Twitter-specific features of more successful phras-
ings. §5.1 applies hypothesis testing (with Bonfer-
roni correction to ameliorate issues with multiple
comparisons) to investigate the utility of features
like informativeness, resemblance to headlines,
and conformity to the community norm in lan-
guage use. §5.2 further validates our findings via
prediction experiments, including on completely
fresh held-out data, used only once and after an
array of standard cross-validation experiments.4
We achieved 66.5% cross-validation accuracy and
65.6% held-out accuracy with a combination of
our custom features and bag-of-words. Our clas-
sifier fared significantly better than a number of
baselines, including a strong classifier trained on
the most- and least-retweeted tweets that was even
granted access to author and timing metadata.
</bodyText>
<sectionHeader confidence="0.999855" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.9996355">
The idea of using carefully controlled experiments
to study effective communication strategies dates
back at least to Hovland et al. (1953). Recent
studies range from examining what characteris-
tics of New York Times articles correlate with high
re-sharing rates (Milkman and Berger, 2012) to
looking at how differences in description affect
the spread of content-controlled videos or images
(Borghol et al., 2012; Lakkaraju et al., 2013).
Simmons et al. (2011) examined the variation of
quotes from different sources to examine how tex-
tual memes mutate as people pass them along, but
did not control for author. Predicting the “success”
of various texts such as novels and movie quotes
has been the aim of additional prior work not al-
ready mentioned in §1 (Ashok et al., 2013; Louis
and Nenkova, 2013; Danescu-Niculescu-Mizil et
al., 2012; Pitler and Nenkova, 2008; McIntyre and
Lapata, 2009). To our knowledge, there have been
no large-scale studies exploring wording effects in
a both topic- and author-controlled setting. Em-
ploying such controls, we find that predicting the
more effective alternative wording is much harder
than the previously well-studied problem of pre-
</bodyText>
<footnote confidence="0.980564">
4And after crossing our fingers.
</footnote>
<page confidence="0.998382">
176
</page>
<bodyText confidence="0.99771675">
dicting popular content when author or topic can
freely vary.
Related work regarding the features we consid-
ered is deferred to §5.1 (features description).
</bodyText>
<sectionHeader confidence="0.99619" genericHeader="method">
3 Data
</sectionHeader>
<bodyText confidence="0.999903525">
Our main dataset was constructed by first gath-
ering 1.77M topic- and author-controlled (hence-
forth TAC) tweet pairs5 differing in more than just
spacing.6 We accomplished this by crawling time-
lines of 236K user ids that appear in prior work
(Kwak et al., 2010; Yang and Leskovec, 2011)
via the Twitter API. This crawling process also
yielded 632K TAC pairs whose only difference
was spacing, and an additional 558M “unpaired”
tweets; as shown later in this paper, we used these
extra corpora for computing language models and
other auxiliary information. We applied non-
obvious but important filtering — described later
in this section — to control for other external fac-
tors and to reduce ambiguous cases. This brought
us to a set of 11,404 pairs, with the gold-standard
labels determined by which tweet in each pair was
the one that received more retweets according to
the Twitter API. We then did a second crawl to
get an additional 1,770 pairs to serve as a held-out
dataset. The corresponding tweet IDs are available
online at http://chenhaot.com/pages/
wording-for-propagation.html. (Twit-
ter’s terms of service prohibit sharing the actual
tweets.)
Throughout, we refer to the textual content of
the earlier tweet within a TAC pair as t1, and of the
later one as t2. We denote the number of retweets
received by each tweet by n1 and n2, respectively.
We refer to the tweet with higher (lower) ni as the
“better (worse)” tweet.
Using “identical” pairs to determine how to
compensate for follower-count and timing ef-
fects. In an ideal setting, differences between
n1 and n2 would be determined solely by dif-
ferences in wording. But even with a TAC pair,
retweets might exhibit a temporal bias because of
the chronological order of tweet presentation (t1
might enjoy a first-mover advantage (Borghol et
al., 2012) because it is the “original”; alternatively,
</bodyText>
<footnote confidence="0.986918857142857">
5No data collection/processing was conducted at Google.
6The total excludes: tweets containing multiple URLs;
tweets from users posting about the same URL more than five
times (since such users might be spammers); the third, fourth,
or fifth version for users posting between three and five tweets
for the same URL; retweets (as identified by Twitter’s API or
by beginning with “RT @”); non-English tweets.
</footnote>
<bodyText confidence="0.97504975">
(a) For identical TAC pairs, (b) Avg. n2 vs. n1 for iden-
retweet-count deviation vs. tical TAC pairs, highlighting
time lag between t1 and our chosen time-lag and fol-
t2, for the author follower- lower thresholds. Bars: stan-
</bodyText>
<equation confidence="0.502669">
counts given in the legend. dard error. Diagonal line:
pEpn2|n1q “ n1.
</equation>
<figureCaption confidence="0.992121">
Figure 1: (a): The ideal case where n2 = n1
</figureCaption>
<bodyText confidence="0.97598745">
when t1 = t2 is best approximated when t2 oc-
curs within 12 hours of t1 and the author has at
least 10,000 or 5,000 followers. (b): in our chosen
setting (blue circles), n2 indeed tends to track n1,
whereas otherwise (black squares), there’s a bias
towards retweeting t1.
t2 might be preferred because retweeters consider
t1 to be “stale”). Also, the number of followers an
author has can have complicated indirect effects
on which tweets are read (space limits preclude
discussion).
We use the 632K TAC pairs wherein t1 and
t2 are identical7 to check for such confounding
effects: we see how much n2 deviates from n1
in such settings, since if wording were the only
explanatory factor, the retweet rates for identical
tweets ought to be equal. Figure 1(a) plots how
the time lag between t1 and t2 and the author’s
follower-count affect the following deviation esti-
mate:
</bodyText>
<equation confidence="0.961611">
D = Z  |pE(n2|n1) - n1|,
0ďn1ă10
</equation>
<bodyText confidence="0.962144142857143">
where pE(n2|n1) is the average value of n2 over
pairs whose t1 is retweeted n1 times. (Note that
the number of pairs whose t1 is retweeted n1 times
decays exponentially with n1; hence, we condi-
tion on n1 to keep the estimate from being domi-
nated by pairs with n1 = 0, and do not consider
n1 &gt; 10pbecause there are too few such pairs to es-
timate E(n2|n1) reliably.) Figure 1(a) shows that
the setting where we (i) minimize the confound-
ing effects of time lag and author’s follower-count
and (ii) maximize the amount of data to work with
7Identical up to spacing: Twitter prevents exact copies by
the same author appearing within a short amount of time, but
some authors work around this by inserting spaces.
</bodyText>
<figure confidence="0.999232076923077">
0
16
14
12
10
8
6
4
2
3 6 12 18 24 36 48
time lag (hours)
&gt;1K f’ers
&gt;2.5K f’ers
&gt;5K f’ers
&gt;10K f’ers
���������
10
4
0
8
6
2
0 2 4 6 8
�1
&gt;5K f’ers,&lt;12hrs
otherwise
</figure>
<page confidence="0.97922">
177
</page>
<bodyText confidence="0.999117086956522">
is: when t2 occurs within 12 hours after t1 and
the author has more than 5,000 followers. Figure
1(b) confirms that for identical TAC pairs, our cho-
sen setting indeed results in n2 being on average
close to n1, which corresponds to the desired set-
ting where wording is the dominant differentiating
factor.8
Focus on meaningful and general changes.
Even after follower-count and time-lapse filtering,
we still want to focus on TAC pairs that (i) ex-
hibit significant/interesting textual changes (as ex-
emplified in Table 1, and as opposed to typo cor-
rections and the like), and (ii) have n2 and n1 suf-
ficiently different so that we are confident in which
ti is better at attracting retweets. To take care of
(i), we discarded the 50% of pairs whose similar-
ity was above the median, where similarity was
tf-based cosine.9 For (ii), we sorted the remain-
ing pairs by n2 ´ n1 and retained only the top and
bottom 5%.10 Moreover, to ensure that we do not
overfit to the idiosyncrasies of particular authors,
we cap the number of pairs contributed by each
author to 50 before we deal with (ii).
</bodyText>
<sectionHeader confidence="0.825084" genericHeader="method">
4 Human accuracy on TAC pairs
</sectionHeader>
<bodyText confidence="0.9978266">
We first ran a pilot study on Amazon Mechan-
ical Turk (AMT) to determine whether humans
can identify, based on wording differences alone,
which of two topic- and author- controlled tweets
is spread more widely. Each of our 5 AMT tasks
involved a disjoint set of 20 randomly-sampled
TAC pairs (with t1 and t2 randomly reordered);
subjects indicated “which tweet would other peo-
ple be more likely to retweet?”, provided a short
justification for their binary response, and clicked
a checkbox if they found that their choice was a
“close call”. We received 39 judgments per pair in
aggregate from 106 subjects total (9 people com-
pleted all 5 tasks). The subjects’ justifications
were of very high quality, convincing us that they
all did the task in good faith11. Two examples for
8We also computed the Pearson correlation between n1
and n2, even though it can be dominated by pairs with smaller
n1. The correlation is 0.853 for “&gt; 5K f’ers, &lt;12hrs”,
clearly higher than the 0.305 correlation for “otherwise”.
9Idf weighting was not employed because changes to fre-
quent words are of potential interest. Urls, hashtags, @-
mentions and numbers were normalized to [url], [hashtag],
[at], and [num] before computing similarity.
10For our data, this meant n2 — n1 _&gt; 10 or 5 —15. Cf.
our median number of retweets: 30.
11We also note that the feedback we got was quite pos-
itive, including: “...It’s fun to make choices between close
tweets and use our subjective opinion. Thanks and best of
the third TAC pair in Table 1 were: “[t1 makes] the
cause relate-able to some people, therefore show-
ing more of an appeal as to why should they click
the link and support” and, expressing the opposite
view, “I like [t2] more because [t1] starts out with
a generalization that doesn’t affect me and try to
make me look like I had that experience before”.
If we view the set of 3900 binary judgments
for our 100-TAC-pair sample as constituting in-
dependent responses, then the accuracy for this
set is 62.4% (rising to 63.8% if we exclude the
587 judgments deemed “close calls”). However, if
we evaluate the accuracy of the majority response
among the 39 judgments per pair, the number rises
to 73%. The accuracy of the majority response
generally increases with the dominance of the ma-
jority, going above 90% when at least 80% of the
judgments agree (although less than a third of the
pairs satisfied this criterion).
Alternatively, we can consider the average ac-
curacy of the 106 subjects: 61.3%, which is bet-
ter than chance but far from 100%. (Variance was
high: one subject achieved 85% accuracy out of
20 pairs, but eight scored below 50%.) This re-
sult is noticeably lower than the 73.8%-81.2% re-
ported by Petrovi´c et al. (2011), who ran a sim-
ilar experiment involving two subjects and 202
tweet pairs, but where the pairs were not topic- or
author-controlled.12
We conclude that even though propagation pre-
diction becomes more challenging when topic
and author controls are applied, humans can
still to some degree tell which wording attracts
more retweets. Interested readers can try this
out themselves at http://chenhaot.com/
retweetedmore/quiz.
</bodyText>
<sectionHeader confidence="0.999755" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.999971125">
We now investigate computationally what word-
ing features correspond to messages achieving a
broader reach. We start (§5.1) by introducing a set
of generally-applicable and (mostly) non-Twitter-
specific features to capture our intuitions about
what might be better ways to phrase a message.
We then use hypothesis testing (§5.1) to evaluate
the importance of each feature for message prop-
</bodyText>
<footnote confidence="0.987159428571429">
luck with your research” and “This was very interesting and
really made me think about how I word my own tweets. Great
job on this survey!”. We only had to exclude one person (not
counted among the 106 subjects), doing so because he or she
gave the same uninformative justification for all pairs.
12The accuracy range stems from whether author’s social
features were supplied and which subject was considered.
</footnote>
<page confidence="0.994951">
178
</page>
<tableCaption confidence="0.994228">
Table 2: Notational conventions for tables in §5.1.
</tableCaption>
<table confidence="0.9266725">
One-sided paired t-test for feature ef�cacy One-sided binomial test for feature increase
TTTT: p&lt;1e-20 1111: p&gt;1-1e-20 (Do authors prefer to ‘raise’ the feature in t2?)
TTT : p&lt;0.001 111 : p&gt;0.999 YES: t2 has a higher feature score than t1, α = .05
TT : p&lt;0.01 11 : p&gt;0.99 NO : t2 has a lower feature score than t1, α = .05
T : p&lt;0.05 1 : p&gt;0.95 (x%): %(f2 &gt; f1), if sig. larger or smaller than 50%
*: passes our Bonferroni correction
</table>
<bodyText confidence="0.999138">
agation and the extent to which authors employ
it, followed by experiments on a prediction task
(§5.2) to further examine the utility of these fea-
tures.
</bodyText>
<subsectionHeader confidence="0.994213">
5.1 Features: efficacy and author preference
</subsectionHeader>
<bodyText confidence="0.999365162162162">
What kind of phrasing helps message propaga-
tion? Does it work to explicitly ask people to share
the message? Is it better to be short and concise or
long and informative? We define an array of fea-
tures to capture these and other messaging aspects.
We then examine (i) how effective each feature is
for attracting more retweets; and (ii) whether au-
thors prefer applying a given feature when issuing
a second version of a tweet.
First, for each feature, we use a one-sided paired
t-test to test whether, on our 11K TAC pairs, our
score function for that feature is larger in the bet-
ter tweet versions than in the worse tweet versions,
for significance levels α = .05, .01, .001, 1e-20.
Given that we did 39 tests in total, there is a risk
of obtaining false positives due to multiple test-
ing (Dunn, 1961; Benjamini and Hochberg, 1995).
To account for this, we also report significance re-
sults for the conservatively Bonferroni-corrected
(“BC”) significance level α = 0.05/39=1.28e-3.
Second, we examine author preference for ap-
plying a feature. We do so because one (but by no
means the only) reason authors post t2 after having
already advertised the same URL in t1 is that these
authors were dissatisfied with the amount of atten-
tion t1 got; in such cases, the changes may have
been specifically intended to attract more retweets.
We measure author preference for a feature by the
percentage of our TAC pairs13 where t2 has more
“occurrences” of the feature than t1, which we de-
note by “%(f2 &gt; f1)”. We use the one-sided bi-
nomial test to see whether %(f2 &gt; f1) is signifi-
cantly larger (or smaller) than 50%.
13 For our preference experiments, we added in pairs where
n2 — n1 was not in the top or bottom 5% (cf. §3, meaningful
changes), since to measure author preference it’s not neces-
sary that the retweet counts differ significantly.
</bodyText>
<tableCaption confidence="0.935648333333333">
Table 3: Explicit requests for sharing (where only
occurrences POS-tagged as verbs count, according
to the Gimpel et al. (2011) tagger).
</tableCaption>
<table confidence="0.999379">
effective? author-preferred?
rt TTTT * ——
retweet TTTT * YES (59%)
spread TTT * YES (56%)
please TTT * ——
pls T ——
plz TT ——
</table>
<tableCaption confidence="0.966345">
Table 4: Informativeness.
</tableCaption>
<table confidence="0.970798">
effective? author-preferred?
length (chars) TTTT * YES (54%)
verb TTTT * YES (56%)
noun TTTT * ——
adjective TTT * YES (51%)
adverb TTT * YES (55%)
proper noun TTT * NO (45%)
number TTTT * NO (48%)
hashtag T ——
@-mention 111 * YES (53%)
Not surprisingly, it helps to ask people to share.
</table>
<bodyText confidence="0.999460666666667">
(See Table 3; the notation for all tables is ex-
plained in Table 2.) The basic sanity check we
performed here was to take as features the number
of occurrences of the verbs ‘rt’, ‘retweet’, ‘please’,
‘spread’, ‘pls’, and ‘plz’ to capture explicit re-
quests (e.g. “please retweet”).
Informativeness helps. (Table 4) Messages that
are more informative have increased social ex-
change value (Homans, 1958), and so may be
more worth propagating. One crude approxima-
tion of informativeness is length, and we see that
length helps.14 In contrast, Simmons et al. (2011)
found that shorter versions of memes are more
likely to be popular. The difference may result
from TAC-pair changes being more drastic than
the variations that memes undergo.
A more refined informativeness measure is
counts of the parts of speech that correspond
to content. Our POS results, gathered using a
Twitter-specific tagger (Gimpel et al., 2011), echo
those of Ashok et al. (2013) who looked at predict-
</bodyText>
<footnote confidence="0.982837">
14Of course, simply inserting garbage isn’t going to lead
to more retweets, but adding more information generally in-
volves longer text.
</footnote>
<page confidence="0.99756">
179
</page>
<tableCaption confidence="0.982297333333333">
Table 5: Conformity to the community and one’s
own past, measured via scores assigned by various
language models.
</tableCaption>
<table confidence="0.9943336">
effective? author-preferred?
twitter unigram TTT * YES (54%)
twitter bigram TTT * YES (52%)
personal unigram TTT * YES (52%)
personal bigram ——– NO (48%)
</table>
<bodyText confidence="0.999534815789474">
ing the success of books. The diminished effect of
hashtag inclusion with respect to what has been re-
ported previously (Suh et al., 2010; Petrovi´c et al.,
2011) presumably stems from our topic and author
controls.
Be like the community, and be true to yourself
(in the words you pick, but not necessarily in
how you combine them). (Table 5) Although dis-
tinctive messages may attract attention, messages
that conform to expectations might be more eas-
ily accepted and therefore shared. Prior work has
explored this tension: Lakkaraju et al. (2013), in a
content-controlled study, found that the more up-
voted Reddit image titles balance novelty and fa-
miliarity; Danescu-Niculescu-Mizil et al. (2012)
(henceforth DCKL’12) showed that the memora-
bility of movie quotes corresponds to higher lexi-
cal distinctiveness but lower POS distinctiveness;
and Sun et al. (2013) observed that deviating from
one’s own past language patterns correlates with
more retweets.
Keeping in mind that the authors in our data
have at least 5000 followers15, we consider two
types of language-conformity constraints an au-
thor might try to satisfy: to be similar to what
is normal in the Twitter community, and to be
similar to what his or her followers expect. We
measure a tweet’s similarity to expectations by its
score according to the relevant language model,
�T� řxc-T log(p(x)), where T refers to either all
the unigrams (unigram model) or all and only bi-
grams (bigram model).16 We trained a Twitter-
community language model from our 558M un-
paired tweets, and personal language models from
each author’s tweet history.
Imitate headlines. (Table 6) News headlines are
often intentionally written to be both informative
and attention-getting, so we introduce the idea of
</bodyText>
<footnote confidence="0.703129571428571">
15This is not an artificial restriction on our set of authors; a
large follower count means (in principle) that our results draw
on a large sample of decisions whether to retweet or not.
16The tokens [at], [hashtag], [url] were ignored in the
unigram-model case to prevent their undue influence, but re-
tained in the bigram model to capture longer-range usage
(“combination”) patterns.
</footnote>
<tableCaption confidence="0.969606">
Table 6: LM-based resemblance to headlines.
</tableCaption>
<table confidence="0.986813666666667">
effective? author-preferred?
headline unigram TT YES (53%)
headline bigram TTTT * YES (52%)
</table>
<tableCaption confidence="0.994702">
Table 7: Retweet score.
</tableCaption>
<figureCaption confidence="0.580678714285714">
effective? author-preferred?
rt score TT * NO (49%)
verb rt score TTTT * ——
noun rt score TTT * ——
adjective rt score T YES (50%)
adverb rt score T YES (51%)
proper noun rt score ——– NO (48%)
</figureCaption>
<bodyText confidence="0.969634875">
scoring by a language model built from New York
Times headlines.17
Use words associated with (non-paired)
retweeted tweets. (Table 7) We expect that
provocative or sensationalistic tweets are likely
to make people react. We found it difficult to
model provocativeness directly. As a rough
approximation, we check whether the changes in
t2 with respect to t1 (which share the same topic
and author) involve words or parts-of-speech that
are associated with high retweet rate in a very
large separate sample of unpaired tweets (retweets
and replies discarded). Specifically, for each word
w that appears more than 10 times, we compute
the probability that tweets containing w are
retweeted more than once, denoted by rs(w). We
define the rt score of a tweet as maxwc-Trs(w),
where T is all the words in the tweet, and the
rt score of a particular POS tag z in a tweet as
maxwc-T&amp;tag(w)=zrs(w).
Include positive and/or negative words. (Ta-
ble 8) Prior work has found that including posi-
tive or negative sentiment increases message prop-
agation (Milkman and Berger, 2012; Godes et al.,
2005; Heath et al., 2001; Hansen et al., 2011). We
measured the occurrence of positive and negative
words as determined by the connotation lexicon
of Feng et al. (2013) (better coverage than LIWC).
Measuring the occurrence of both simultaneously
was inspired by Riloff et al. (2013).
Refer to other people (but not your audience).
(Table 9) First-person has been found useful for
success before, but in the different domains of sci-
entific abstracts (Guerini et al., 2012) and books
(Ashok et al., 2013).
17 To test whether the results stem from similarity to news
rather than headlines per se, we constructed a NYT-text LM,
which proved less effective. We also tried using Gawker
headlines (often said to be attention-getting) but pilot studies
revealed insufficient vocabulary overlap with our TAC pairs.
</bodyText>
<page confidence="0.998938">
180
</page>
<tableCaption confidence="0.9754825">
Table 8: Sentiment (contrast is measured by pres-
ence of both positive and negative sentiments).
</tableCaption>
<table confidence="0.998086">
effective? author-preferred?
positive TTT * ——
negative TTT * ——
contrast TTT * ——
</table>
<tableCaption confidence="0.960088">
Table 9: Pronouns.
</tableCaption>
<table confidence="0.953541166666667">
effective? author-preferred?
1st person singular ——– YES (51%)
1st person plural ——– YES (52%)
2nd person ——– YES (57%)
3rd person singular TT YES (55%)
3rd person plural T YES (58%)
</table>
<bodyText confidence="0.993049">
Generality helps. (Table 10) DCKL’12 posited
that movie quotes are more shared in the culture
when they are general enough to be used in multi-
ple contexts. We hence measured the presence of
indefinite articles vs. definite articles.
The easier to read, the better. (Table 11) We
measure readability by using Flesch reading ease
(Flesch, 1948) and Flesch-Kincaid grade level
(Kincaid et al., 1975), though they are not de-
signed for short texts. We use negative grade level
so that a larger value indicates easier texts to read.
Final question: Do authors prefer to do what
is effective? Recall that we use binomial tests to
determine author preference for applying a feature
more in t2. Our preference statistics show that au-
thor preferences in many cases are aligned with
feature efficacy. But there are several notable ex-
ceptions: for example, authors tend to increase the
use of @-mentions and 2nd person pronouns even
though they are ineffective. On the other hand,
they did not increase the use of effective ones
like proper nouns and numbers; nor did they tend
to increase their rate of sentiment-bearing words.
Bearing in mind that changes in t2 may not always
be intended as an effort to improve t1, it is still in-
teresting to observe that there are some contrasts
between feature efficacy and author preferences.
</bodyText>
<subsectionHeader confidence="0.999535">
5.2 Predicting the “better” wording
</subsectionHeader>
<bodyText confidence="0.9997822">
Here, we further examine the collective efficacy
of the features introduced in §5.1 via their perfor-
mance on a binary prediction task: given a TAC
pair (t1, t2), did t2 receive more retweets?
Our approach. We group the features introduced
in §5.1 into 16 lexicon-based features (Table 3,
8, 9, 10), 9 informativeness features (Table 4), 6
language model features (Table 5, 6), 6 rt score
features (Table 7), and 2 readability features (Ta-
ble 11). We refer to all 39 of them together as
</bodyText>
<tableCaption confidence="0.967483">
Table 10: Generality.
</tableCaption>
<table confidence="0.495514666666667">
effective? author-preferred?
indefinite articles (a,an) TTT * ——
definite articles (the) ——– YES (52%)
</table>
<tableCaption confidence="0.980822">
Table 11: Readability.
</tableCaption>
<bodyText confidence="0.960113227272727">
effective? author-preferred?
reading ease TT YES (52%)
negative grade level T YES (52%)
custom features. We also consider tagged bag-of-
words (“BOW”) features, which includes all the
unigram (word:POS pair) and bigram features that
appear more than 10 times in the cross-validation
data. This yields 3,568 unigram features and 4,095
bigram features, for a total of 7,663 so-called
1,2-gram features. Values for each feature are nor-
malized by linear transformation across all tweets
in the training data to lie in the range [0,1].18
For a given TAC pair, we construct its feature
vector as follows. For each feature being consid-
ered, we compute its normalized value for each
tweet in the pair and take the difference as the fea-
ture value for this pair. We use L2-regularized lo-
gistic regression as our classifier, with parameters
chosen by cross validation on the training data.
(We also experimented with SVMs. The perfor-
mance was very close, but mostly slightly lower.)
A strong non-TAC alternative, with social infor-
mation and timing thrown in. One baseline re-
sult we would like to establish is whether the topic
and author controls we have argued for, while
intuitively compelling for the purposes of trying
to determine the best way for a given author to
present some fixed content, are really necessary
in practice. To test this, we consider an alterna-
tive binary L2-regularized logistic-regression clas-
sifier that is trained on unpaired data, specifically,
on the collection of 10,000 most retweeted tweets
(gold-standard label: positive) plus the 10,000
least retweeted tweets (gold-standard label: neg-
ative) that are neither retweets nor replies. Note
that this alternative thus is granted, by design,
roughly twice the training instances that our clas-
sifiers have, as a result of having roughly the same
number of tweets, since our instances are pairs.
Moreover, we additionally include the tweet au-
thor’s follower count, and the day and hour of
posting, as features. We refer to this alternative
classifier as ,TAC+ff+time. (Mnemonic: “ff” is
used in bibliographic contexts as an abbreviation
</bodyText>
<footnote confidence="0.9833405">
18We also tried normalization by whitening, but it did not
lead to further improvements.
</footnote>
<page confidence="0.995512">
181
</page>
<figure confidence="0.984199789473684">
(a) Cross-validation and heldout accuracy for various feature sets. Blue lines inside
bars: performance when custom features are restricted to those that pass our Bon-
ferroni correction (no line for readability because no readability features passed).
Dashed vertical line: ,TAC+ff+time performance.
1000 3000 5000 7000 9000
70%
68%
66%
64%
62%
60%
58%
custom+1,2-gram
custom
1,2-gram
human
(b) Cross-validation accuracy vs data size.
Human performance was estimated from a
disjoint set of 100 pairs (see §4).
</figure>
<figureCaption confidence="0.93061825">
Figure 2: Accuracy results. Pertinent significance results are as follows. In cross-validation, custom+1,2-
gram is significantly better than ,TAC+ff+time (p=0) and 1,2-gram (p=3.8e-7). In heldout validation,
custom+1,2-gram is significantly better than ,TAC+ff+time (p=3.4e-12) and 1,2-gram (p=0.01) but not
unigram (p=0.08), perhaps due to the small size of the heldout set.
</figureCaption>
<bodyText confidence="0.984246671428572">
for “and the following”.) We apply it to a tweet
pair by computing whether it gives a higher score
to t2 or not.
Baselines. To sanity-check whether our classifier
provides any improvement over the simplest meth-
ods one could try, we also report the performance
of the majority baseline, our request-for-sharing
features, and our character-length feature.
Performance comparison. We compare the ac-
curacy (percentage of pairs whose labels were cor-
rectly predicted) of our approach against the com-
peting methods. We report 5-fold cross validation
results on our balanced set of 11,404 TAC pairs
and on our completely disjoint heldout data19 of
1,770 TAC pairs; this set was never examined dur-
ing development, and there are no authors in com-
mon between the two testing sets.
Figure 2(a) summarizes the main results. While
,TAC+ff+time outperforms the majority base-
line, using all the features we proposed beats
,TAC+ff+time by more than 10% in both cross-
validation (66.5% vs 55.9%) and heldout valida-
tion (65.6% vs 55.3%). We outperform the aver-
age human accuracy of 61% reported in our Ama-
zon Mechanical Turk experiments (for a different
data sample); ,TAC+ff+time fails to do so.
The importance of topic and author con-
trol can be seen by further investigation of
,TAC+ff+time’s performance. First, note that
19To construct this data, we used the same criteria as in
§3: written by authors with more than 5000 followers, posted
within 12 hours, n2 — n1 &gt;_ 10 or 5 —15, and cosine simi-
larity threshold value the same as in §3, cap of 50 on number
of pairs from any individual author.
it yields an accuracy of around 55% on our
alternate-version-selection task,20 even though its
cross-validation accuracy on the larger most- and
least-retweeted unpaired tweets averages out to a
high 98.8%. Furthermore, note the superior per-
formance of unigrams trained on TAC data vs
,TAC+ff+time — which is similar to our uni-
grams but trained on a larger but non-TAC dataset
that included metadata. Thus, TAC pairs are a use-
ful data source even for non-custom features. (We
also include individual feature comparisons later.)
Informativeness is the best-performing custom
feature group when run in isolation, and outper-
forms all baselines, as well as ,TAC+ff+time;
and we can see from Figure 2(a) that this is not
due just to length. The combination of all our 39
custom features yields approximately 63% accu-
racy in both testing settings, significantly outper-
forming informativeness alone (p&lt;0.001 in both
cases). Again, this is higher than our estimate of
average human performance.
Not surprisingly, the TAC-trained BOW fea-
tures (unigram and 1,2-gram) show impressive
predictive power in this task: many of our custom
features can be captured by bag-of-word features,
in a way. Still, the best performance is achieved
20One might suspect that the problem is that
,TAC+ff+time learns from its training data to over-
rely on follower-count, since that is presumably a good
feature for non-TAC tweets, and for this reason suffers when
run on TAC data where follower-counts are by construction
non-informative. But in fact, we found that removing the
follower-count feature from ,TAC+ff+time and re-training
did not lead to improved performance. Hence, it seems that
it is the non-controlled nature of the alternate training data
that explains the drop in performance.
</bodyText>
<page confidence="0.994037">
182
</page>
<bodyText confidence="0.998453176470588">
by combining our custom and 1,2-gram features
together, to a degree statistically significantly bet-
ter than using 1,2-gram features alone.
Finally, we remark on our Bonferroni correc-
tion. Recall that the intent of applying it is to
avoid false positives. However, in our case, Fig-
ure 2(a) shows that our potentially “false” posi-
tives — features whose effectiveness did not pass
the Bonferroni correction test — actually do raise
performance in our prediction tests.
Size of training data. Another interesting obser-
vation is how performance varies with data size.
For n “ 1000, 2000,.. . ,10000, we randomly
sampled n pairs from our 11,404 pairs, and com-
puted the average cross-validation accuracy on the
sampled data. Figure 2(b) shows the averages over
50 runs of the aforementioned procedure. Our cus-
tom features can achieve good performance with
little data, in the sense that for sample size 1000,
they outperform BOW features; on the other hand,
BOW features quickly surpass them. Across the
board, the custom+1,2-gram features are consis-
tently better than the 1,2-gram features alone.
Top features. Finally, we examine some of
the top-weighted individual features from our ap-
proach and from the competing TAC+ff+time
classifier. The top three rows of Table 12 show the
best custom and best and worst unigram features
for our method; the bottom two rows show the best
and worst unigrams for TAC+ff+time. Among
custom features, we see that community and per-
sonal language models, informativeness, retweet
scores, sentiment, and generality are represented.
As for unigram features, not surprisingly, “rt” and
“retweet” are top features for both our approach
and TAC+ff+time. However, the other unigrams
for the two methods seem to be a bit different in
spirit. Some of the unigrams determined to be
most poor only by our method appear to be both
surprising and yet plausible in retrospect: “icymi”
(abbreviation for “in case you missed it”) tends to
indicate a direct repetition of older information,
so people might prefer to retweet the earlier ver-
sion; “thanks” and “sorry” could correspond to
personal thank-yous and apologies not meant to
be shared with a broader audience, and similarly
@-mentioning another user may indicate a tweet
intended only for that person. The appearance of
[hashtag] in the best TAC+ff+time unigrams is
consistent with prior research in non-TAC settings
(Suh et al., 2010; Petrovi´c et al., 2011).
</bodyText>
<tableCaption confidence="0.8325625">
Table 12: Features with largest coefficients, de-
limited by commas. POS tags omitted for clarity.
</tableCaption>
<bodyText confidence="0.994061421052632">
Our approach
best 15 custom twitter bigram, length (chars), rt
(the word), retweet (the word), verb, verb retweet score,
personal unigram, proper noun, number, noun, positive
words, please (the word), proper noun retweet score,
indefinite articles (a,an), adjective
best 20 unigrams rt, retweet, [num], breaking,
is, win, never, ., people, need, official, officially, are,
please, november, world, girl, !!!, god, new
worst 20 unigrams :, [at], icymi, also, comments,
half, ?, earlier, thanks, sorry, highlights, bit, point, up-
date, last, helping, peek, what, haven’t, debate
TAC+ff+time
best 20 unigrams [hashtag], teen, fans, retweet,
sale, usa, women, butt, caught, visit, background, up-
coming, rt, this, bieber, these, each, chat, houston, book
worst 20 unigrams :, ..., boss, foundation, ?, „,
others, john, roll, ride, appreciate, page, drive, correct,
full, ’, looks, @ (not as [at]), sales, hurts
</bodyText>
<sectionHeader confidence="0.999692" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99984896875">
In this work, we conducted the first large-scale
topic- and author-controlled experiment to study
the effects of wording on information propagation.
The features we developed to choose the bet-
ter of two alternative wordings posted better per-
formance than that of all our comparison algo-
rithms, including one given access to author and
timing features but trained on non-TAC data, and
also bested our estimate of average human perfor-
mance. According to our hypothesis tests, help-
ful wording heuristics include adding more infor-
mation, making one’s language align with both
community norms and with one’s prior messages,
and mimicking news headlines. Readers may
try out their own alternate phrasings at http:
//chenhaot.com/retweetedmore/to see
what a simplified version of our classifier predicts.
In future work, it will be interesting to examine
how these features generalize to longer and more
extensive arguments. Moreover, understanding
the underlying psychological and cultural mecha-
nisms that establish the effectiveness of these fea-
tures is a fundamental problem of interest.
Acknowledgments. We thank C. Callison-Burch,
C. Danescu-Niculescu-Mizil, J. Kleinberg, P.
Mahdabi, S. Mullainathan, F. Pereira, K. Raman,
A. Swaminathan, the Cornell NLP seminar par-
ticipants and the reviewers for their comments; J.
Leskovec for providing some initial data; and the
anonymous annotators for all their labeling help.
This work was supported in part by NSF grant IIS-
0910664 and a Google Research Grant.
</bodyText>
<page confidence="0.998825">
183
</page>
<sectionHeader confidence="0.995901" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999610145631068">
Yoav Artzi, Patrick Pantel, and Michael Gamon. 2012.
Predicting responses to microblog posts. In Pro-
ceedings of NAACL (short paper).
Vikas Ganjigunte Ashok, Song Feng, and Yejin Choi.
2013. Success with style: Using writing style to
predict the success of novels. In Proceedings of
EMNLP.
Eitan Bakshy, Jake M. Hofman, Winter A. Mason, and
Duncan J. Watts. 2011. Everyone’s an influencer:
Quantifying influence on twitter. In Proceedings of
WSDM.
Yoav Benjamini and Yosef Hochberg. 1995. Control-
ling the false discovery rate: A practical and pow-
erful approach to multiple testing. Journal of the
Royal Statistical Society. Series B (Methodological),
pages 289–300.
Youmna Borghol, Sebastien Ardon, Niklas Carlsson,
Derek Eager, and Anirban Mahanti. 2012. The
untold story of the clones: Content-agnostic factors
that impact YouTube video popularity. In Proceed-
ings of KDD.
Dennis Chong and James N. Druckman. 2007. Fram-
ing theory. Annual Review of Political Science,
10:103–126.
Cristian Danescu-Niculescu-Mizil, Justin Cheng, Jon
Kleinberg, and Lillian Lee. 2012. You had me at
hello: How phrasing affects memorability. In Pro-
ceedings of ACL.
John DiNardo. 2008. Natural experiments and quasi-
natural experiments. In The New Palgrave Dictio-
nary of Economics. Palgrave Macmillan.
Olive Jean Dunn. 1961. Multiple comparisons among
means. Journal of the American Statistical Associa-
tion, 56(293):52–64.
Song Feng, Jun Seok Kang, Polina Kuznetsova, and
Yejin Choi. 2013. Connotation lexicon: A dash of
sentiment beneath the surface meaning. In Proceed-
ings of ACL.
Rudolph Flesch. 1948. A new readability yardstick.
Journal of applied psychology, 32(3):221.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech Tagging
for Twitter: Annotation, Features, and Experiments.
In Proceedings of NAACL (short paper).
David Godes, Dina Mayzlin, Yubo Chen, Sanjiv
Das, Chrysanthos Dellarocas, Bruce Pfeiffer, Barak
Libai, Subrata Sen, Mengze Shi, and Peeter Verlegh.
2005. The firm’s management of social interactions.
Marketing Letters, 16(3-4):415–428.
Marco Guerini, Carlo Strapparava, and G¨ozde ¨Ozbal.
2011. Exploring text virality in social networks. In
Proceedings of ICWSM (poster).
Marco Guerini, Alberto Pepe, and Bruno Lepri. 2012.
Do linguistic style and readability of scientific ab-
stracts affect their virality? In Proceedings of
ICWSM (poster).
Lars Kai Hansen, Adam Arvidsson, Finn ˚Arup Nielsen,
Elanor Colleoni, and Michael Etter. 2011. Good
friends, bad news-affect and virality in Twitter.
Communications in Computer and Information Sci-
ence, 185:34–43.
Chip Heath, Chris Bell, and Emily Sternberg. 2001.
Emotional selection in memes: The case of urban
legends. Journal of personality and social psychol-
ogy, 81(6):1028.
George C. Homans. 1958. Social Behavior as Ex-
change. American Journal of Sociology, 63(6):597–
606.
Liangjie Hong, Ovidiu Dan, and Brian D. Davison.
2011. Predicting popular messages in Twitter. In
Proceedings of WWW.
Carl I. Hovland, Irving L. Janis, and Harold H. Kelley.
1953. Communication and Persuasion: Psycholog-
ical Studies of Opinion Change, volume 19. Yale
University Press.
J. Peter Kincaid, Robert P. Fishburne Jr., Richard L.
Rogers, and Brad S. Chissom. 1975. Derivation
of new readability formulas (automated readability
index, fog count and flesch reading ease formula)
for navy enlisted personnel. Technical report, DTIC
Document.
Haewoon Kwak, Changhyun Lee, Hosung Park, and
Sue Moon. 2010. What is Twitter, a social network
or a news media? In Proceedings of WWW.
Himabindu Lakkaraju, Julian McAuley, and Jure
Leskovec. 2013. What’s in a name? Understanding
the interplay between titles, content, and communi-
ties in social media. In Proceedings of ICWSM.
Annie Louis and Ani Nenkova. 2013. What makes
writing great? First experiments on article quality
prediction in the science journalism domain. Trans-
actions of ACL.
Zongyang Ma, Aixin Sun, and Gao Cong. 2012. Will
this #hashtag be popular tomorrow? In Proceedings
of SIGIR.
Neil McIntyre and Mirella Lapata. 2009. Learning to
tell tales: A data-driven approach to story genera-
tion. In Proceedings of ACL-IJCNLP.
Katherine L Milkman and Jonah Berger. 2012. What
makes online content viral? Journal of Marketing
Research, 49(2):192–205.
</reference>
<page confidence="0.987314">
184
</page>
<reference confidence="0.999616742857143">
Saˇsa Petrovi´c, Miles Osborne, and Victor Lavrenko.
2011. RT to win! Predicting message propagation
in Twitter. In Proceedings of ICWSM.
Emily Pitler and Ani Nenkova. 2008. Revisiting
readability: A unified framework for predicting text
quality. In Proceedings of EMNLP.
Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalin-
dra De Silva, Nathan Gilbert, and Ruihong Huang.
2013. Sarcasm as contrast between a positive sen-
timent and negative situation. In Proceedings of
EMNLP.
Daniel M. Romero, Chenhao Tan, and Johan Ugander.
2013. On the interplay between social and topical
structure. In Proceedings of ICWSM.
Matthew J. Salganik, Peter Sheridan Dodds, and Dun-
can J. Watts. 2006. Experimental study of inequal-
ity and unpredictability in an artificial cultural mar-
ket. Science, 311(5762):854–856.
Matthew P. Simmons, Lada A Adamic, and Eytan Adar.
2011. Memes online: Extracted, subtracted, in-
jected, and recollected. In Proceedings of ICWSM.
Bongwon Suh, Lichan Hong, Peter Pirolli, and Ed H.
Chi. 2010. Want to be retweeted? Large scale an-
alytics on factors impacting retweet in Twitter net-
work. In Proceedings of SocialCom.
Tao Sun, Ming Zhang, and Qiaozhu Mei. 2013. Unex-
pected relevance: An empirical study of serendipity
in retweets. In Proceedings of ICWSM.
Oren Tsur and Ari Rappoport. 2012. What’s in a hash-
tag?: Content based prediction of the spread of ideas
in microblogging communities. In Proceedings of
WSDM.
Jaewon Yang and Jure Leskovec. 2011. Patterns of
temporal variation in online media. In Proceedings
of WSDM.
</reference>
<page confidence="0.998842">
185
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.905074">
<title confidence="0.99544">The effect of wording on message propagation: Topicand author-controlled natural experiments on Twitter</title>
<author confidence="0.999442">Chenhao Tan Lillian Lee Bo Pang</author>
<affiliation confidence="0.990428">Dept. of Computer Science Dept. of Computer Science Google Inc. Cornell University Cornell University bopang42@gmail.com</affiliation>
<email confidence="0.9987">chenhao@cs.cornell.edullee@cs.cornell.edu</email>
<abstract confidence="0.99729244">Consider a person trying to spread an important message on a social network. He/she can spend hours trying to craft the message. Does it actually matter? While there has been extensive prior work looking into predicting popularity of socialmedia content, the effect of wording per se has rarely been studied since it is often confounded with the popularity of the author and the topic. To control for these confounding factors, we take advantage of the surprising fact that there are many of tweets containing the and by the but employing different wording. Given such pairs, we ask: which version attracts more retweets? This turns out to be a more difficult task than predicting popular topics. Still, humans can answer this question better than chance (but far from perfectly), and the computational methods we develop can do better than both an average human and a strong competing method trained on noncontrolled data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Yoav Artzi</author>
<author>Patrick Pantel</author>
<author>Michael Gamon</author>
</authors>
<title>Predicting responses to microblog posts.</title>
<date>2012</date>
<booktitle>In Proceedings of NAACL</booktitle>
<note>(short paper).</note>
<contexts>
<context position="2264" citStr="Artzi et al., 2012" startWordPosition="354" endWordPosition="357">latter case, if other group members repeat the originating individual’s point. The massive availability of online messages, such as posts to social media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather t</context>
</contexts>
<marker>Artzi, Pantel, Gamon, 2012</marker>
<rawString>Yoav Artzi, Patrick Pantel, and Michael Gamon. 2012. Predicting responses to microblog posts. In Proceedings of NAACL (short paper).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vikas Ganjigunte Ashok</author>
<author>Song Feng</author>
<author>Yejin Choi</author>
</authors>
<title>Success with style: Using writing style to predict the success of novels.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="8917" citStr="Ashok et al., 2013" startWordPosition="1419" endWordPosition="1422">ange from examining what characteristics of New York Times articles correlate with high re-sharing rates (Milkman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already mentioned in §1 (Ashok et al., 2013; Louis and Nenkova, 2013; Danescu-Niculescu-Mizil et al., 2012; Pitler and Nenkova, 2008; McIntyre and Lapata, 2009). To our knowledge, there have been no large-scale studies exploring wording effects in a both topic- and author-controlled setting. Employing such controls, we find that predicting the more effective alternative wording is much harder than the previously well-studied problem of pre4And after crossing our fingers. 176 dicting popular content when author or topic can freely vary. Related work regarding the features we considered is deferred to §5.1 (features description). 3 Data </context>
<context position="23010" citStr="Ashok et al. (2013)" startWordPosition="3838" endWordPosition="3841"> more informative have increased social exchange value (Homans, 1958), and so may be more worth propagating. One crude approximation of informativeness is length, and we see that length helps.14 In contrast, Simmons et al. (2011) found that shorter versions of memes are more likely to be popular. The difference may result from TAC-pair changes being more drastic than the variations that memes undergo. A more refined informativeness measure is counts of the parts of speech that correspond to content. Our POS results, gathered using a Twitter-specific tagger (Gimpel et al., 2011), echo those of Ashok et al. (2013) who looked at predict14Of course, simply inserting garbage isn’t going to lead to more retweets, but adding more information generally involves longer text. 179 Table 5: Conformity to the community and one’s own past, measured via scores assigned by various language models. effective? author-preferred? twitter unigram TTT * YES (54%) twitter bigram TTT * YES (52%) personal unigram TTT * YES (52%) personal bigram ——– NO (48%) ing the success of books. The diminished effect of hashtag inclusion with respect to what has been reported previously (Suh et al., 2010; Petrovi´c et al., 2011) presumab</context>
<context position="27507" citStr="Ashok et al., 2013" startWordPosition="4574" endWordPosition="4577">that including positive or negative sentiment increases message propagation (Milkman and Berger, 2012; Godes et al., 2005; Heath et al., 2001; Hansen et al., 2011). We measured the occurrence of positive and negative words as determined by the connotation lexicon of Feng et al. (2013) (better coverage than LIWC). Measuring the occurrence of both simultaneously was inspired by Riloff et al. (2013). Refer to other people (but not your audience). (Table 9) First-person has been found useful for success before, but in the different domains of scientific abstracts (Guerini et al., 2012) and books (Ashok et al., 2013). 17 To test whether the results stem from similarity to news rather than headlines per se, we constructed a NYT-text LM, which proved less effective. We also tried using Gawker headlines (often said to be attention-getting) but pilot studies revealed insufficient vocabulary overlap with our TAC pairs. 180 Table 8: Sentiment (contrast is measured by presence of both positive and negative sentiments). effective? author-preferred? positive TTT * —— negative TTT * —— contrast TTT * —— Table 9: Pronouns. effective? author-preferred? 1st person singular ——– YES (51%) 1st person plural ——– YES (52%)</context>
</contexts>
<marker>Ashok, Feng, Choi, 2013</marker>
<rawString>Vikas Ganjigunte Ashok, Song Feng, and Yejin Choi. 2013. Success with style: Using writing style to predict the success of novels. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eitan Bakshy</author>
<author>Jake M Hofman</author>
<author>Winter A Mason</author>
<author>Duncan J Watts</author>
</authors>
<title>Everyone’s an influencer: Quantifying influence on twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of WSDM.</booktitle>
<contexts>
<context position="2285" citStr="Bakshy et al., 2011" startWordPosition="358" endWordPosition="361">r group members repeat the originating individual’s point. The massive availability of online messages, such as posts to social media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message </context>
</contexts>
<marker>Bakshy, Hofman, Mason, Watts, 2011</marker>
<rawString>Eitan Bakshy, Jake M. Hofman, Winter A. Mason, and Duncan J. Watts. 2011. Everyone’s an influencer: Quantifying influence on twitter. In Proceedings of WSDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Benjamini</author>
<author>Yosef Hochberg</author>
</authors>
<title>Controlling the false discovery rate: A practical and powerful approach to multiple testing.</title>
<date>1995</date>
<journal>Journal of the Royal Statistical Society. Series B (Methodological),</journal>
<pages>289--300</pages>
<contexts>
<context position="20481" citStr="Benjamini and Hochberg, 1995" startWordPosition="3403" endWordPosition="3406">o capture these and other messaging aspects. We then examine (i) how effective each feature is for attracting more retweets; and (ii) whether authors prefer applying a given feature when issuing a second version of a tweet. First, for each feature, we use a one-sided paired t-test to test whether, on our 11K TAC pairs, our score function for that feature is larger in the better tweet versions than in the worse tweet versions, for significance levels α = .05, .01, .001, 1e-20. Given that we did 39 tests in total, there is a risk of obtaining false positives due to multiple testing (Dunn, 1961; Benjamini and Hochberg, 1995). To account for this, we also report significance results for the conservatively Bonferroni-corrected (“BC”) significance level α = 0.05/39=1.28e-3. Second, we examine author preference for applying a feature. We do so because one (but by no means the only) reason authors post t2 after having already advertised the same URL in t1 is that these authors were dissatisfied with the amount of attention t1 got; in such cases, the changes may have been specifically intended to attract more retweets. We measure author preference for a feature by the percentage of our TAC pairs13 where t2 has more “oc</context>
</contexts>
<marker>Benjamini, Hochberg, 1995</marker>
<rawString>Yoav Benjamini and Yosef Hochberg. 1995. Controlling the false discovery rate: A practical and powerful approach to multiple testing. Journal of the Royal Statistical Society. Series B (Methodological), pages 289–300.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youmna Borghol</author>
<author>Sebastien Ardon</author>
<author>Niklas Carlsson</author>
<author>Derek Eager</author>
<author>Anirban Mahanti</author>
</authors>
<title>The untold story of the clones: Content-agnostic factors that impact YouTube video popularity.</title>
<date>2012</date>
<booktitle>In Proceedings of KDD.</booktitle>
<contexts>
<context position="2307" citStr="Borghol et al., 2012" startWordPosition="362" endWordPosition="365">t the originating individual’s point. The massive availability of online messages, such as posts to social media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast </context>
<context position="8554" citStr="Borghol et al., 2012" startWordPosition="1355" endWordPosition="1358">fared significantly better than a number of baselines, including a strong classifier trained on the most- and least-retweeted tweets that was even granted access to author and timing metadata. 2 Related work The idea of using carefully controlled experiments to study effective communication strategies dates back at least to Hovland et al. (1953). Recent studies range from examining what characteristics of New York Times articles correlate with high re-sharing rates (Milkman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already mentioned in §1 (Ashok et al., 2013; Louis and Nenkova, 2013; Danescu-Niculescu-Mizil et al., 2012; Pitler and Nenkova, 2008; McIntyre and Lapata, 2009). To our knowledge, there have been no large-scale studies exploring wording effects in a both topic- and author-control</context>
<context position="11331" citStr="Borghol et al., 2012" startWordPosition="1810" endWordPosition="1813">ent of the earlier tweet within a TAC pair as t1, and of the later one as t2. We denote the number of retweets received by each tweet by n1 and n2, respectively. We refer to the tweet with higher (lower) ni as the “better (worse)” tweet. Using “identical” pairs to determine how to compensate for follower-count and timing effects. In an ideal setting, differences between n1 and n2 would be determined solely by differences in wording. But even with a TAC pair, retweets might exhibit a temporal bias because of the chronological order of tweet presentation (t1 might enjoy a first-mover advantage (Borghol et al., 2012) because it is the “original”; alternatively, 5No data collection/processing was conducted at Google. 6The total excludes: tweets containing multiple URLs; tweets from users posting about the same URL more than five times (since such users might be spammers); the third, fourth, or fifth version for users posting between three and five tweets for the same URL; retweets (as identified by Twitter’s API or by beginning with “RT @”); non-English tweets. (a) For identical TAC pairs, (b) Avg. n2 vs. n1 for idenretweet-count deviation vs. tical TAC pairs, highlighting time lag between t1 and our chose</context>
</contexts>
<marker>Borghol, Ardon, Carlsson, Eager, Mahanti, 2012</marker>
<rawString>Youmna Borghol, Sebastien Ardon, Niklas Carlsson, Derek Eager, and Anirban Mahanti. 2012. The untold story of the clones: Content-agnostic factors that impact YouTube video popularity. In Proceedings of KDD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dennis Chong</author>
<author>James N Druckman</author>
</authors>
<title>Framing theory.</title>
<date>2007</date>
<journal>Annual Review of Political Science,</journal>
<pages>10--103</pages>
<contexts>
<context position="1451" citStr="Chong and Druckman, 2007" startWordPosition="225" endWordPosition="228"> the same url and written by the same user but employing different wording. Given such pairs, we ask: which version attracts more retweets? This turns out to be a more difficult task than predicting popular topics. Still, humans can answer this question better than chance (but far from perfectly), and the computational methods we develop can do better than both an average human and a strong competing method trained on noncontrolled data. 1 Introduction How does one make a message “successful”? This question is of interest to many entities, including political parties trying to frame an issue (Chong and Druckman, 2007), and individuals attempting to make a point in a group meeting. In the first case, an important type of success is achieved if the national conversation adopts the rhetoric of the party; in the latter case, if other group members repeat the originating individual’s point. The massive availability of online messages, such as posts to social media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the ori</context>
</contexts>
<marker>Chong, Druckman, 2007</marker>
<rawString>Dennis Chong and James N. Druckman. 2007. Framing theory. Annual Review of Political Science, 10:103–126.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cristian Danescu-Niculescu-Mizil</author>
<author>Justin Cheng</author>
<author>Jon Kleinberg</author>
<author>Lillian Lee</author>
</authors>
<title>You had me at hello: How phrasing affects memorability.</title>
<date>2012</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="8980" citStr="Danescu-Niculescu-Mizil et al., 2012" startWordPosition="1427" endWordPosition="1430">ew York Times articles correlate with high re-sharing rates (Milkman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already mentioned in §1 (Ashok et al., 2013; Louis and Nenkova, 2013; Danescu-Niculescu-Mizil et al., 2012; Pitler and Nenkova, 2008; McIntyre and Lapata, 2009). To our knowledge, there have been no large-scale studies exploring wording effects in a both topic- and author-controlled setting. Employing such controls, we find that predicting the more effective alternative wording is much harder than the previously well-studied problem of pre4And after crossing our fingers. 176 dicting popular content when author or topic can freely vary. Related work regarding the features we considered is deferred to §5.1 (features description). 3 Data Our main dataset was constructed by first gathering 1.77M topic</context>
<context position="24137" citStr="Danescu-Niculescu-Mizil et al. (2012)" startWordPosition="4020" endWordPosition="4023">nclusion with respect to what has been reported previously (Suh et al., 2010; Petrovi´c et al., 2011) presumably stems from our topic and author controls. Be like the community, and be true to yourself (in the words you pick, but not necessarily in how you combine them). (Table 5) Although distinctive messages may attract attention, messages that conform to expectations might be more easily accepted and therefore shared. Prior work has explored this tension: Lakkaraju et al. (2013), in a content-controlled study, found that the more upvoted Reddit image titles balance novelty and familiarity; Danescu-Niculescu-Mizil et al. (2012) (henceforth DCKL’12) showed that the memorability of movie quotes corresponds to higher lexical distinctiveness but lower POS distinctiveness; and Sun et al. (2013) observed that deviating from one’s own past language patterns correlates with more retweets. Keeping in mind that the authors in our data have at least 5000 followers15, we consider two types of language-conformity constraints an author might try to satisfy: to be similar to what is normal in the Twitter community, and to be similar to what his or her followers expect. We measure a tweet’s similarity to expectations by its score a</context>
</contexts>
<marker>Danescu-Niculescu-Mizil, Cheng, Kleinberg, Lee, 2012</marker>
<rawString>Cristian Danescu-Niculescu-Mizil, Justin Cheng, Jon Kleinberg, and Lillian Lee. 2012. You had me at hello: How phrasing affects memorability. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John DiNardo</author>
</authors>
<title>Natural experiments and quasinatural experiments.</title>
<date>2008</date>
<booktitle>In The New Palgrave Dictionary of Economics.</booktitle>
<publisher>Palgrave Macmillan.</publisher>
<contexts>
<context position="5191" citStr="DiNardo, 2008" startWordPosition="831" endWordPosition="832">ing Day Crosses the Line [same URL] n2 = 27 cactus music t1: I know at some point you’ve have been saved from hunger by our rolling food trucks friends. Let’s help support them! n1 = 2 http://t.co/zg9jwA5j t2: Food trucks are the epitome of small independently owned LOCAL businesses! Help keep them going! Sign the petition [same n2 = 13 URL] in which BarackObama tweeted something else1, fortunately, a surprising characteristic of Twitter allows us to run a fairly analogous natural experiment: external forces serendipitously provide an environment that resembles the desired controlled setting (DiNardo, 2008). Specifically, it turns out to be unexpectedly common for the same user to post different tweets regarding the same URL — a good proxy for fine-grained topic2 — within a relatively short period of time.3 Some example pairs are shown in Table 1; we see that the paired tweets may differ dramatically, going far beyond word-for-word substitutions, so that quite interesting changes can be studied. Looking at these examples, can one in fact tell from the wording which tweet in a topic- and author-controlled pair will be more successful? The answer may not be a priori clear. For example, for the fir</context>
</contexts>
<marker>DiNardo, 2008</marker>
<rawString>John DiNardo. 2008. Natural experiments and quasinatural experiments. In The New Palgrave Dictionary of Economics. Palgrave Macmillan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olive Jean Dunn</author>
</authors>
<title>Multiple comparisons among means.</title>
<date>1961</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>56</volume>
<issue>293</issue>
<contexts>
<context position="20450" citStr="Dunn, 1961" startWordPosition="3401" endWordPosition="3402">f features to capture these and other messaging aspects. We then examine (i) how effective each feature is for attracting more retweets; and (ii) whether authors prefer applying a given feature when issuing a second version of a tweet. First, for each feature, we use a one-sided paired t-test to test whether, on our 11K TAC pairs, our score function for that feature is larger in the better tweet versions than in the worse tweet versions, for significance levels α = .05, .01, .001, 1e-20. Given that we did 39 tests in total, there is a risk of obtaining false positives due to multiple testing (Dunn, 1961; Benjamini and Hochberg, 1995). To account for this, we also report significance results for the conservatively Bonferroni-corrected (“BC”) significance level α = 0.05/39=1.28e-3. Second, we examine author preference for applying a feature. We do so because one (but by no means the only) reason authors post t2 after having already advertised the same URL in t1 is that these authors were dissatisfied with the amount of attention t1 got; in such cases, the changes may have been specifically intended to attract more retweets. We measure author preference for a feature by the percentage of our TA</context>
</contexts>
<marker>Dunn, 1961</marker>
<rawString>Olive Jean Dunn. 1961. Multiple comparisons among means. Journal of the American Statistical Association, 56(293):52–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Song Feng</author>
<author>Jun Seok Kang</author>
<author>Polina Kuznetsova</author>
<author>Yejin Choi</author>
</authors>
<title>Connotation lexicon: A dash of sentiment beneath the surface meaning.</title>
<date>2013</date>
<booktitle>In Proceedings of ACL.</booktitle>
<contexts>
<context position="27173" citStr="Feng et al. (2013)" startWordPosition="4520" endWordPosition="4523">te the probability that tweets containing w are retweeted more than once, denoted by rs(w). We define the rt score of a tweet as maxwc-Trs(w), where T is all the words in the tweet, and the rt score of a particular POS tag z in a tweet as maxwc-T&amp;tag(w)=zrs(w). Include positive and/or negative words. (Table 8) Prior work has found that including positive or negative sentiment increases message propagation (Milkman and Berger, 2012; Godes et al., 2005; Heath et al., 2001; Hansen et al., 2011). We measured the occurrence of positive and negative words as determined by the connotation lexicon of Feng et al. (2013) (better coverage than LIWC). Measuring the occurrence of both simultaneously was inspired by Riloff et al. (2013). Refer to other people (but not your audience). (Table 9) First-person has been found useful for success before, but in the different domains of scientific abstracts (Guerini et al., 2012) and books (Ashok et al., 2013). 17 To test whether the results stem from similarity to news rather than headlines per se, we constructed a NYT-text LM, which proved less effective. We also tried using Gawker headlines (often said to be attention-getting) but pilot studies revealed insufficient v</context>
</contexts>
<marker>Feng, Kang, Kuznetsova, Choi, 2013</marker>
<rawString>Song Feng, Jun Seok Kang, Polina Kuznetsova, and Yejin Choi. 2013. Connotation lexicon: A dash of sentiment beneath the surface meaning. In Proceedings of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rudolph Flesch</author>
</authors>
<title>A new readability yardstick.</title>
<date>1948</date>
<journal>Journal of applied psychology,</journal>
<volume>32</volume>
<issue>3</issue>
<contexts>
<context position="28538" citStr="Flesch, 1948" startWordPosition="4743" endWordPosition="4744">hor-preferred? positive TTT * —— negative TTT * —— contrast TTT * —— Table 9: Pronouns. effective? author-preferred? 1st person singular ——– YES (51%) 1st person plural ——– YES (52%) 2nd person ——– YES (57%) 3rd person singular TT YES (55%) 3rd person plural T YES (58%) Generality helps. (Table 10) DCKL’12 posited that movie quotes are more shared in the culture when they are general enough to be used in multiple contexts. We hence measured the presence of indefinite articles vs. definite articles. The easier to read, the better. (Table 11) We measure readability by using Flesch reading ease (Flesch, 1948) and Flesch-Kincaid grade level (Kincaid et al., 1975), though they are not designed for short texts. We use negative grade level so that a larger value indicates easier texts to read. Final question: Do authors prefer to do what is effective? Recall that we use binomial tests to determine author preference for applying a feature more in t2. Our preference statistics show that author preferences in many cases are aligned with feature efficacy. But there are several notable exceptions: for example, authors tend to increase the use of @-mentions and 2nd person pronouns even though they are ineff</context>
</contexts>
<marker>Flesch, 1948</marker>
<rawString>Rudolph Flesch. 1948. A new readability yardstick. Journal of applied psychology, 32(3):221.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech Tagging for Twitter: Annotation, Features, and Experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of NAACL</booktitle>
<note>(short paper).</note>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech Tagging for Twitter: Annotation, Features, and Experiments. In Proceedings of NAACL (short paper).</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Godes</author>
<author>Dina Mayzlin</author>
<author>Yubo Chen</author>
</authors>
<title>Sanjiv Das, Chrysanthos Dellarocas, Bruce Pfeiffer, Barak Libai, Subrata Sen, Mengze Shi, and Peeter Verlegh.</title>
<date>2005</date>
<journal>Marketing Letters,</journal>
<pages>16--3</pages>
<contexts>
<context position="27009" citStr="Godes et al., 2005" startWordPosition="4492" endWordPosition="4495">et rate in a very large separate sample of unpaired tweets (retweets and replies discarded). Specifically, for each word w that appears more than 10 times, we compute the probability that tweets containing w are retweeted more than once, denoted by rs(w). We define the rt score of a tweet as maxwc-Trs(w), where T is all the words in the tweet, and the rt score of a particular POS tag z in a tweet as maxwc-T&amp;tag(w)=zrs(w). Include positive and/or negative words. (Table 8) Prior work has found that including positive or negative sentiment increases message propagation (Milkman and Berger, 2012; Godes et al., 2005; Heath et al., 2001; Hansen et al., 2011). We measured the occurrence of positive and negative words as determined by the connotation lexicon of Feng et al. (2013) (better coverage than LIWC). Measuring the occurrence of both simultaneously was inspired by Riloff et al. (2013). Refer to other people (but not your audience). (Table 9) First-person has been found useful for success before, but in the different domains of scientific abstracts (Guerini et al., 2012) and books (Ashok et al., 2013). 17 To test whether the results stem from similarity to news rather than headlines per se, we constru</context>
</contexts>
<marker>Godes, Mayzlin, Chen, 2005</marker>
<rawString>David Godes, Dina Mayzlin, Yubo Chen, Sanjiv Das, Chrysanthos Dellarocas, Bruce Pfeiffer, Barak Libai, Subrata Sen, Mengze Shi, and Peeter Verlegh. 2005. The firm’s management of social interactions. Marketing Letters, 16(3-4):415–428.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Guerini</author>
<author>Carlo Strapparava</author>
<author>G¨ozde ¨Ozbal</author>
</authors>
<title>Exploring text virality in social networks.</title>
<date>2011</date>
<booktitle>In Proceedings of ICWSM (poster).</booktitle>
<marker>Guerini, Strapparava, ¨Ozbal, 2011</marker>
<rawString>Marco Guerini, Carlo Strapparava, and G¨ozde ¨Ozbal. 2011. Exploring text virality in social networks. In Proceedings of ICWSM (poster).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Guerini</author>
<author>Alberto Pepe</author>
<author>Bruno Lepri</author>
</authors>
<title>Do linguistic style and readability of scientific abstracts affect their virality?</title>
<date>2012</date>
<booktitle>In Proceedings of ICWSM (poster).</booktitle>
<contexts>
<context position="2351" citStr="Guerini et al., 2012" startWordPosition="370" endWordPosition="373">ssive availability of online messages, such as posts to social media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features</context>
<context position="27476" citStr="Guerini et al., 2012" startWordPosition="4568" endWordPosition="4571">. (Table 8) Prior work has found that including positive or negative sentiment increases message propagation (Milkman and Berger, 2012; Godes et al., 2005; Heath et al., 2001; Hansen et al., 2011). We measured the occurrence of positive and negative words as determined by the connotation lexicon of Feng et al. (2013) (better coverage than LIWC). Measuring the occurrence of both simultaneously was inspired by Riloff et al. (2013). Refer to other people (but not your audience). (Table 9) First-person has been found useful for success before, but in the different domains of scientific abstracts (Guerini et al., 2012) and books (Ashok et al., 2013). 17 To test whether the results stem from similarity to news rather than headlines per se, we constructed a NYT-text LM, which proved less effective. We also tried using Gawker headlines (often said to be attention-getting) but pilot studies revealed insufficient vocabulary overlap with our TAC pairs. 180 Table 8: Sentiment (contrast is measured by presence of both positive and negative sentiments). effective? author-preferred? positive TTT * —— negative TTT * —— contrast TTT * —— Table 9: Pronouns. effective? author-preferred? 1st person singular ——– YES (51%) </context>
</contexts>
<marker>Guerini, Pepe, Lepri, 2012</marker>
<rawString>Marco Guerini, Alberto Pepe, and Bruno Lepri. 2012. Do linguistic style and readability of scientific abstracts affect their virality? In Proceedings of ICWSM (poster).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lars Kai Hansen</author>
<author>Adam Arvidsson</author>
<author>Finn ˚Arup Nielsen</author>
<author>Elanor Colleoni</author>
<author>Michael Etter</author>
</authors>
<title>Good friends, bad news-affect and virality in Twitter.</title>
<date>2011</date>
<booktitle>Communications in Computer and Information Science,</booktitle>
<pages>185--34</pages>
<contexts>
<context position="2372" citStr="Hansen et al., 2011" startWordPosition="374" endWordPosition="377">online messages, such as posts to social media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wor</context>
<context position="27051" citStr="Hansen et al., 2011" startWordPosition="4500" endWordPosition="4503">of unpaired tweets (retweets and replies discarded). Specifically, for each word w that appears more than 10 times, we compute the probability that tweets containing w are retweeted more than once, denoted by rs(w). We define the rt score of a tweet as maxwc-Trs(w), where T is all the words in the tweet, and the rt score of a particular POS tag z in a tweet as maxwc-T&amp;tag(w)=zrs(w). Include positive and/or negative words. (Table 8) Prior work has found that including positive or negative sentiment increases message propagation (Milkman and Berger, 2012; Godes et al., 2005; Heath et al., 2001; Hansen et al., 2011). We measured the occurrence of positive and negative words as determined by the connotation lexicon of Feng et al. (2013) (better coverage than LIWC). Measuring the occurrence of both simultaneously was inspired by Riloff et al. (2013). Refer to other people (but not your audience). (Table 9) First-person has been found useful for success before, but in the different domains of scientific abstracts (Guerini et al., 2012) and books (Ashok et al., 2013). 17 To test whether the results stem from similarity to news rather than headlines per se, we constructed a NYT-text LM, which proved less effe</context>
</contexts>
<marker>Hansen, Arvidsson, Nielsen, Colleoni, Etter, 2011</marker>
<rawString>Lars Kai Hansen, Adam Arvidsson, Finn ˚Arup Nielsen, Elanor Colleoni, and Michael Etter. 2011. Good friends, bad news-affect and virality in Twitter. Communications in Computer and Information Science, 185:34–43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chip Heath</author>
<author>Chris Bell</author>
<author>Emily Sternberg</author>
</authors>
<title>Emotional selection in memes: The case of urban legends.</title>
<date>2001</date>
<journal>Journal of personality and social psychology,</journal>
<volume>81</volume>
<issue>6</issue>
<contexts>
<context position="27029" citStr="Heath et al., 2001" startWordPosition="4496" endWordPosition="4499">rge separate sample of unpaired tweets (retweets and replies discarded). Specifically, for each word w that appears more than 10 times, we compute the probability that tweets containing w are retweeted more than once, denoted by rs(w). We define the rt score of a tweet as maxwc-Trs(w), where T is all the words in the tweet, and the rt score of a particular POS tag z in a tweet as maxwc-T&amp;tag(w)=zrs(w). Include positive and/or negative words. (Table 8) Prior work has found that including positive or negative sentiment increases message propagation (Milkman and Berger, 2012; Godes et al., 2005; Heath et al., 2001; Hansen et al., 2011). We measured the occurrence of positive and negative words as determined by the connotation lexicon of Feng et al. (2013) (better coverage than LIWC). Measuring the occurrence of both simultaneously was inspired by Riloff et al. (2013). Refer to other people (but not your audience). (Table 9) First-person has been found useful for success before, but in the different domains of scientific abstracts (Guerini et al., 2012) and books (Ashok et al., 2013). 17 To test whether the results stem from similarity to news rather than headlines per se, we constructed a NYT-text LM, </context>
</contexts>
<marker>Heath, Bell, Sternberg, 2001</marker>
<rawString>Chip Heath, Chris Bell, and Emily Sternberg. 2001. Emotional selection in memes: The case of urban legends. Journal of personality and social psychology, 81(6):1028.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George C Homans</author>
</authors>
<title>Social Behavior as Exchange.</title>
<date>1958</date>
<journal>American Journal of Sociology,</journal>
<volume>63</volume>
<issue>6</issue>
<pages>606</pages>
<contexts>
<context position="22460" citStr="Homans, 1958" startWordPosition="3750" endWordPosition="3751">YES (56%) noun TTTT * —— adjective TTT * YES (51%) adverb TTT * YES (55%) proper noun TTT * NO (45%) number TTTT * NO (48%) hashtag T —— @-mention 111 * YES (53%) Not surprisingly, it helps to ask people to share. (See Table 3; the notation for all tables is explained in Table 2.) The basic sanity check we performed here was to take as features the number of occurrences of the verbs ‘rt’, ‘retweet’, ‘please’, ‘spread’, ‘pls’, and ‘plz’ to capture explicit requests (e.g. “please retweet”). Informativeness helps. (Table 4) Messages that are more informative have increased social exchange value (Homans, 1958), and so may be more worth propagating. One crude approximation of informativeness is length, and we see that length helps.14 In contrast, Simmons et al. (2011) found that shorter versions of memes are more likely to be popular. The difference may result from TAC-pair changes being more drastic than the variations that memes undergo. A more refined informativeness measure is counts of the parts of speech that correspond to content. Our POS results, gathered using a Twitter-specific tagger (Gimpel et al., 2011), echo those of Ashok et al. (2013) who looked at predict14Of course, simply insertin</context>
</contexts>
<marker>Homans, 1958</marker>
<rawString>George C. Homans. 1958. Social Behavior as Exchange. American Journal of Sociology, 63(6):597– 606.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liangjie Hong</author>
<author>Ovidiu Dan</author>
<author>Brian D Davison</author>
</authors>
<title>Predicting popular messages in Twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of WWW.</booktitle>
<contexts>
<context position="2391" citStr="Hong et al., 2011" startWordPosition="378" endWordPosition="381"> as posts to social media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wording is one of the </context>
</contexts>
<marker>Hong, Dan, Davison, 2011</marker>
<rawString>Liangjie Hong, Ovidiu Dan, and Brian D. Davison. 2011. Predicting popular messages in Twitter. In Proceedings of WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carl I Hovland</author>
<author>Irving L Janis</author>
<author>Harold H Kelley</author>
</authors>
<title>Communication and Persuasion:</title>
<date>1953</date>
<journal>Psychological Studies of Opinion Change,</journal>
<volume>19</volume>
<publisher>Yale University Press.</publisher>
<contexts>
<context position="8281" citStr="Hovland et al. (1953)" startWordPosition="1314" endWordPosition="1317">nts, including on completely fresh held-out data, used only once and after an array of standard cross-validation experiments.4 We achieved 66.5% cross-validation accuracy and 65.6% held-out accuracy with a combination of our custom features and bag-of-words. Our classifier fared significantly better than a number of baselines, including a strong classifier trained on the most- and least-retweeted tweets that was even granted access to author and timing metadata. 2 Related work The idea of using carefully controlled experiments to study effective communication strategies dates back at least to Hovland et al. (1953). Recent studies range from examining what characteristics of New York Times articles correlate with high re-sharing rates (Milkman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already</context>
</contexts>
<marker>Hovland, Janis, Kelley, 1953</marker>
<rawString>Carl I. Hovland, Irving L. Janis, and Harold H. Kelley. 1953. Communication and Persuasion: Psychological Studies of Opinion Change, volume 19. Yale University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Peter Kincaid</author>
<author>Robert P Fishburne Jr</author>
<author>Richard L Rogers</author>
<author>Brad S Chissom</author>
</authors>
<title>Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel.</title>
<date>1975</date>
<tech>Technical report, DTIC Document.</tech>
<contexts>
<context position="28592" citStr="Kincaid et al., 1975" startWordPosition="4749" endWordPosition="4752">* —— contrast TTT * —— Table 9: Pronouns. effective? author-preferred? 1st person singular ——– YES (51%) 1st person plural ——– YES (52%) 2nd person ——– YES (57%) 3rd person singular TT YES (55%) 3rd person plural T YES (58%) Generality helps. (Table 10) DCKL’12 posited that movie quotes are more shared in the culture when they are general enough to be used in multiple contexts. We hence measured the presence of indefinite articles vs. definite articles. The easier to read, the better. (Table 11) We measure readability by using Flesch reading ease (Flesch, 1948) and Flesch-Kincaid grade level (Kincaid et al., 1975), though they are not designed for short texts. We use negative grade level so that a larger value indicates easier texts to read. Final question: Do authors prefer to do what is effective? Recall that we use binomial tests to determine author preference for applying a feature more in t2. Our preference statistics show that author preferences in many cases are aligned with feature efficacy. But there are several notable exceptions: for example, authors tend to increase the use of @-mentions and 2nd person pronouns even though they are ineffective. On the other hand, they did not increase the u</context>
</contexts>
<marker>Kincaid, Jr, Rogers, Chissom, 1975</marker>
<rawString>J. Peter Kincaid, Robert P. Fishburne Jr., Richard L. Rogers, and Brad S. Chissom. 1975. Derivation of new readability formulas (automated readability index, fog count and flesch reading ease formula) for navy enlisted personnel. Technical report, DTIC Document.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haewoon Kwak</author>
<author>Changhyun Lee</author>
<author>Hosung Park</author>
<author>Sue Moon</author>
</authors>
<title>What is Twitter, a social network or a news media?</title>
<date>2010</date>
<booktitle>In Proceedings of WWW.</booktitle>
<contexts>
<context position="9776" citStr="Kwak et al., 2010" startWordPosition="1553" endWordPosition="1556">etting. Employing such controls, we find that predicting the more effective alternative wording is much harder than the previously well-studied problem of pre4And after crossing our fingers. 176 dicting popular content when author or topic can freely vary. Related work regarding the features we considered is deferred to §5.1 (features description). 3 Data Our main dataset was constructed by first gathering 1.77M topic- and author-controlled (henceforth TAC) tweet pairs5 differing in more than just spacing.6 We accomplished this by crawling timelines of 236K user ids that appear in prior work (Kwak et al., 2010; Yang and Leskovec, 2011) via the Twitter API. This crawling process also yielded 632K TAC pairs whose only difference was spacing, and an additional 558M “unpaired” tweets; as shown later in this paper, we used these extra corpora for computing language models and other auxiliary information. We applied nonobvious but important filtering — described later in this section — to control for other external factors and to reduce ambiguous cases. This brought us to a set of 11,404 pairs, with the gold-standard labels determined by which tweet in each pair was the one that received more retweets ac</context>
</contexts>
<marker>Kwak, Lee, Park, Moon, 2010</marker>
<rawString>Haewoon Kwak, Changhyun Lee, Hosung Park, and Sue Moon. 2010. What is Twitter, a social network or a news media? In Proceedings of WWW.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Himabindu Lakkaraju</author>
<author>Julian McAuley</author>
<author>Jure Leskovec</author>
</authors>
<title>What’s in a name? Understanding the interplay between titles, content, and communities in social media.</title>
<date>2013</date>
<booktitle>In Proceedings of ICWSM.</booktitle>
<contexts>
<context position="2415" citStr="Lakkaraju et al., 2013" startWordPosition="382" endWordPosition="385"> media, now affords researchers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wording is one of the few factors directly und</context>
<context position="8579" citStr="Lakkaraju et al., 2013" startWordPosition="1359" endWordPosition="1362">tter than a number of baselines, including a strong classifier trained on the most- and least-retweeted tweets that was even granted access to author and timing metadata. 2 Related work The idea of using carefully controlled experiments to study effective communication strategies dates back at least to Hovland et al. (1953). Recent studies range from examining what characteristics of New York Times articles correlate with high re-sharing rates (Milkman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already mentioned in §1 (Ashok et al., 2013; Louis and Nenkova, 2013; Danescu-Niculescu-Mizil et al., 2012; Pitler and Nenkova, 2008; McIntyre and Lapata, 2009). To our knowledge, there have been no large-scale studies exploring wording effects in a both topic- and author-controlled setting. Employing su</context>
<context position="23986" citStr="Lakkaraju et al. (2013)" startWordPosition="3998" endWordPosition="4001">TT * YES (52%) personal unigram TTT * YES (52%) personal bigram ——– NO (48%) ing the success of books. The diminished effect of hashtag inclusion with respect to what has been reported previously (Suh et al., 2010; Petrovi´c et al., 2011) presumably stems from our topic and author controls. Be like the community, and be true to yourself (in the words you pick, but not necessarily in how you combine them). (Table 5) Although distinctive messages may attract attention, messages that conform to expectations might be more easily accepted and therefore shared. Prior work has explored this tension: Lakkaraju et al. (2013), in a content-controlled study, found that the more upvoted Reddit image titles balance novelty and familiarity; Danescu-Niculescu-Mizil et al. (2012) (henceforth DCKL’12) showed that the memorability of movie quotes corresponds to higher lexical distinctiveness but lower POS distinctiveness; and Sun et al. (2013) observed that deviating from one’s own past language patterns correlates with more retweets. Keeping in mind that the authors in our data have at least 5000 followers15, we consider two types of language-conformity constraints an author might try to satisfy: to be similar to what is</context>
</contexts>
<marker>Lakkaraju, McAuley, Leskovec, 2013</marker>
<rawString>Himabindu Lakkaraju, Julian McAuley, and Jure Leskovec. 2013. What’s in a name? Understanding the interplay between titles, content, and communities in social media. In Proceedings of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Louis</author>
<author>Ani Nenkova</author>
</authors>
<title>What makes writing great? First experiments on article quality prediction in the science journalism domain.</title>
<date>2013</date>
<journal>Transactions of ACL.</journal>
<contexts>
<context position="8942" citStr="Louis and Nenkova, 2013" startWordPosition="1423" endWordPosition="1426">what characteristics of New York Times articles correlate with high re-sharing rates (Milkman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already mentioned in §1 (Ashok et al., 2013; Louis and Nenkova, 2013; Danescu-Niculescu-Mizil et al., 2012; Pitler and Nenkova, 2008; McIntyre and Lapata, 2009). To our knowledge, there have been no large-scale studies exploring wording effects in a both topic- and author-controlled setting. Employing such controls, we find that predicting the more effective alternative wording is much harder than the previously well-studied problem of pre4And after crossing our fingers. 176 dicting popular content when author or topic can freely vary. Related work regarding the features we considered is deferred to §5.1 (features description). 3 Data Our main dataset was cons</context>
</contexts>
<marker>Louis, Nenkova, 2013</marker>
<rawString>Annie Louis and Ani Nenkova. 2013. What makes writing great? First experiments on article quality prediction in the science journalism domain. Transactions of ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zongyang Ma</author>
<author>Aixin Sun</author>
<author>Gao Cong</author>
</authors>
<title>Will this #hashtag be popular tomorrow?</title>
<date>2012</date>
<booktitle>In Proceedings of SIGIR.</booktitle>
<contexts>
<context position="2458" citStr="Ma et al., 2012" startWordPosition="390" endWordPosition="393">tigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wording is one of the few factors directly under an author’s control when he or she seeks</context>
</contexts>
<marker>Ma, Sun, Cong, 2012</marker>
<rawString>Zongyang Ma, Aixin Sun, and Gao Cong. 2012. Will this #hashtag be popular tomorrow? In Proceedings of SIGIR.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neil McIntyre</author>
<author>Mirella Lapata</author>
</authors>
<title>Learning to tell tales: A data-driven approach to story generation.</title>
<date>2009</date>
<booktitle>In Proceedings of ACL-IJCNLP.</booktitle>
<contexts>
<context position="9034" citStr="McIntyre and Lapata, 2009" startWordPosition="1435" endWordPosition="1438">kman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already mentioned in §1 (Ashok et al., 2013; Louis and Nenkova, 2013; Danescu-Niculescu-Mizil et al., 2012; Pitler and Nenkova, 2008; McIntyre and Lapata, 2009). To our knowledge, there have been no large-scale studies exploring wording effects in a both topic- and author-controlled setting. Employing such controls, we find that predicting the more effective alternative wording is much harder than the previously well-studied problem of pre4And after crossing our fingers. 176 dicting popular content when author or topic can freely vary. Related work regarding the features we considered is deferred to §5.1 (features description). 3 Data Our main dataset was constructed by first gathering 1.77M topic- and author-controlled (henceforth TAC) tweet pairs5 </context>
</contexts>
<marker>McIntyre, Lapata, 2009</marker>
<rawString>Neil McIntyre and Mirella Lapata. 2009. Learning to tell tales: A data-driven approach to story generation. In Proceedings of ACL-IJCNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katherine L Milkman</author>
<author>Jonah Berger</author>
</authors>
<title>What makes online content viral?</title>
<date>2012</date>
<journal>Journal of Marketing Research,</journal>
<volume>49</volume>
<issue>2</issue>
<contexts>
<context position="2441" citStr="Milkman and Berger, 2012" startWordPosition="386" endWordPosition="389">archers new means to investigate at a very large scale the factors affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wording is one of the few factors directly under an author’s control whe</context>
<context position="8430" citStr="Milkman and Berger, 2012" startWordPosition="1336" endWordPosition="1339">cross-validation accuracy and 65.6% held-out accuracy with a combination of our custom features and bag-of-words. Our classifier fared significantly better than a number of baselines, including a strong classifier trained on the most- and least-retweeted tweets that was even granted access to author and timing metadata. 2 Related work The idea of using carefully controlled experiments to study effective communication strategies dates back at least to Hovland et al. (1953). Recent studies range from examining what characteristics of New York Times articles correlate with high re-sharing rates (Milkman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already mentioned in §1 (Ashok et al., 2013; Louis and Nenkova, 2013; Danescu-Niculescu-Mizil et al., 2012; Pitler and Nenkova, 2008; McIntyre and Lapata, 2</context>
<context position="26989" citStr="Milkman and Berger, 2012" startWordPosition="4488" endWordPosition="4491">associated with high retweet rate in a very large separate sample of unpaired tweets (retweets and replies discarded). Specifically, for each word w that appears more than 10 times, we compute the probability that tweets containing w are retweeted more than once, denoted by rs(w). We define the rt score of a tweet as maxwc-Trs(w), where T is all the words in the tweet, and the rt score of a particular POS tag z in a tweet as maxwc-T&amp;tag(w)=zrs(w). Include positive and/or negative words. (Table 8) Prior work has found that including positive or negative sentiment increases message propagation (Milkman and Berger, 2012; Godes et al., 2005; Heath et al., 2001; Hansen et al., 2011). We measured the occurrence of positive and negative words as determined by the connotation lexicon of Feng et al. (2013) (better coverage than LIWC). Measuring the occurrence of both simultaneously was inspired by Riloff et al. (2013). Refer to other people (but not your audience). (Table 9) First-person has been found useful for success before, but in the different domains of scientific abstracts (Guerini et al., 2012) and books (Ashok et al., 2013). 17 To test whether the results stem from similarity to news rather than headline</context>
</contexts>
<marker>Milkman, Berger, 2012</marker>
<rawString>Katherine L Milkman and Jonah Berger. 2012. What makes online content viral? Journal of Marketing Research, 49(2):192–205.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Saˇsa Petrovi´c</author>
<author>Miles Osborne</author>
<author>Victor Lavrenko</author>
</authors>
<title>RT to win! Predicting message propagation in Twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of ICWSM.</booktitle>
<marker>Petrovi´c, Osborne, Lavrenko, 2011</marker>
<rawString>Saˇsa Petrovi´c, Miles Osborne, and Victor Lavrenko. 2011. RT to win! Predicting message propagation in Twitter. In Proceedings of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Revisiting readability: A unified framework for predicting text quality.</title>
<date>2008</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<contexts>
<context position="9006" citStr="Pitler and Nenkova, 2008" startWordPosition="1431" endWordPosition="1434">high re-sharing rates (Milkman and Berger, 2012) to looking at how differences in description affect the spread of content-controlled videos or images (Borghol et al., 2012; Lakkaraju et al., 2013). Simmons et al. (2011) examined the variation of quotes from different sources to examine how textual memes mutate as people pass them along, but did not control for author. Predicting the “success” of various texts such as novels and movie quotes has been the aim of additional prior work not already mentioned in §1 (Ashok et al., 2013; Louis and Nenkova, 2013; Danescu-Niculescu-Mizil et al., 2012; Pitler and Nenkova, 2008; McIntyre and Lapata, 2009). To our knowledge, there have been no large-scale studies exploring wording effects in a both topic- and author-controlled setting. Employing such controls, we find that predicting the more effective alternative wording is much harder than the previously well-studied problem of pre4And after crossing our fingers. 176 dicting popular content when author or topic can freely vary. Related work regarding the features we considered is deferred to §5.1 (features description). 3 Data Our main dataset was constructed by first gathering 1.77M topic- and author-controlled (h</context>
</contexts>
<marker>Pitler, Nenkova, 2008</marker>
<rawString>Emily Pitler and Ani Nenkova. 2008. Revisiting readability: A unified framework for predicting text quality. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Ashequl Qadir</author>
<author>Prafulla Surve</author>
<author>Lalindra De Silva</author>
<author>Nathan Gilbert</author>
<author>Ruihong Huang</author>
</authors>
<title>Sarcasm as contrast between a positive sentiment and negative situation.</title>
<date>2013</date>
<booktitle>In Proceedings of EMNLP.</booktitle>
<marker>Riloff, Qadir, Surve, De Silva, Gilbert, Huang, 2013</marker>
<rawString>Ellen Riloff, Ashequl Qadir, Prafulla Surve, Lalindra De Silva, Nathan Gilbert, and Ruihong Huang. 2013. Sarcasm as contrast between a positive sentiment and negative situation. In Proceedings of EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Romero</author>
<author>Chenhao Tan</author>
<author>Johan Ugander</author>
</authors>
<title>On the interplay between social and topical structure.</title>
<date>2013</date>
<booktitle>In Proceedings of ICWSM.</booktitle>
<contexts>
<context position="2503" citStr="Romero et al., 2013" startWordPosition="398" endWordPosition="401">affecting message propagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wording is one of the few factors directly under an author’s control when he or she seeks to convey a fixed piece of content. For exam</context>
</contexts>
<marker>Romero, Tan, Ugander, 2013</marker>
<rawString>Daniel M. Romero, Chenhao Tan, and Johan Ugander. 2013. On the interplay between social and topical structure. In Proceedings of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew J Salganik</author>
<author>Peter Sheridan Dodds</author>
<author>Duncan J Watts</author>
</authors>
<title>Experimental study of inequality and unpredictability in an artificial cultural market.</title>
<date>2006</date>
<journal>Science,</journal>
<volume>311</volume>
<issue>5762</issue>
<contexts>
<context position="6568" citStr="Salganik et al., 2006" startWordPosition="1054" endWordPosition="1057"> more informative about the URL’s content and includes “fight media portrayal”. In an Amazon Mechanical Turk (AMT) experiment (§4), we found that humans achieved an average accuracy of 61.3%: not that high, but better than chance, indicating that it is somewhat possible for humans to predict greater message spread from different deliveries of the same information. Buoyed by the evidence of our AMT study that wording effects exist, we then performed a battery of experiments to seek generally-applicable, non1Cf. the Music Lab “multiple universes” experiment to test the randomness of popularity (Salganik et al., 2006). 2Although hashtags have been used as coarse-grained topic labels in prior work, for our purposes, we have no assurance that two tweets both using, say, “#Tahrir” would be attempting to express the same message but in different words. In contrast, see the same-URL examples in Table 1. 3Moreover, Twitter presents tweets to a reader in strict chronological order, so that there are no algorithmic-ranking effects to compensate for in determining whether readers saw a tweet. And, Twitter accumulates retweet counts for the entire retweet cascade and displays them for the original tweet at the root </context>
</contexts>
<marker>Salganik, Dodds, Watts, 2006</marker>
<rawString>Matthew J. Salganik, Peter Sheridan Dodds, and Duncan J. Watts. 2006. Experimental study of inequality and unpredictability in an artificial cultural market. Science, 311(5762):854–856.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew P Simmons</author>
</authors>
<title>Lada A Adamic, and Eytan Adar.</title>
<date>2011</date>
<booktitle>In Proceedings of ICWSM.</booktitle>
<marker>Simmons, 2011</marker>
<rawString>Matthew P. Simmons, Lada A Adamic, and Eytan Adar. 2011. Memes online: Extracted, subtracted, injected, and recollected. In Proceedings of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bongwon Suh</author>
<author>Lichan Hong</author>
<author>Peter Pirolli</author>
<author>Ed H Chi</author>
</authors>
<title>Want to be retweeted? Large scale analytics on factors impacting retweet in Twitter network.</title>
<date>2010</date>
<booktitle>In Proceedings of SocialCom.</booktitle>
<contexts>
<context position="2521" citStr="Suh et al., 2010" startWordPosition="402" endWordPosition="405">pagation, also known as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wording is one of the few factors directly under an author’s control when he or she seeks to convey a fixed piece of content. For example, consider a sp</context>
<context position="23576" citStr="Suh et al., 2010" startWordPosition="3931" endWordPosition="3934">l et al., 2011), echo those of Ashok et al. (2013) who looked at predict14Of course, simply inserting garbage isn’t going to lead to more retweets, but adding more information generally involves longer text. 179 Table 5: Conformity to the community and one’s own past, measured via scores assigned by various language models. effective? author-preferred? twitter unigram TTT * YES (54%) twitter bigram TTT * YES (52%) personal unigram TTT * YES (52%) personal bigram ——– NO (48%) ing the success of books. The diminished effect of hashtag inclusion with respect to what has been reported previously (Suh et al., 2010; Petrovi´c et al., 2011) presumably stems from our topic and author controls. Be like the community, and be true to yourself (in the words you pick, but not necessarily in how you combine them). (Table 5) Although distinctive messages may attract attention, messages that conform to expectations might be more easily accepted and therefore shared. Prior work has explored this tension: Lakkaraju et al. (2013), in a content-controlled study, found that the more upvoted Reddit image titles balance novelty and familiarity; Danescu-Niculescu-Mizil et al. (2012) (henceforth DCKL’12) showed that the m</context>
<context position="39025" citStr="Suh et al., 2010" startWordPosition="6424" endWordPosition="6427">mined to be most poor only by our method appear to be both surprising and yet plausible in retrospect: “icymi” (abbreviation for “in case you missed it”) tends to indicate a direct repetition of older information, so people might prefer to retweet the earlier version; “thanks” and “sorry” could correspond to personal thank-yous and apologies not meant to be shared with a broader audience, and similarly @-mentioning another user may indicate a tweet intended only for that person. The appearance of [hashtag] in the best TAC+ff+time unigrams is consistent with prior research in non-TAC settings (Suh et al., 2010; Petrovi´c et al., 2011). Table 12: Features with largest coefficients, delimited by commas. POS tags omitted for clarity. Our approach best 15 custom twitter bigram, length (chars), rt (the word), retweet (the word), verb, verb retweet score, personal unigram, proper noun, number, noun, positive words, please (the word), proper noun retweet score, indefinite articles (a,an), adjective best 20 unigrams rt, retweet, [num], breaking, is, win, never, ., people, need, official, officially, are, please, november, world, girl, !!!, god, new worst 20 unigrams :, [at], icymi, also, comments, half, ?,</context>
</contexts>
<marker>Suh, Hong, Pirolli, Chi, 2010</marker>
<rawString>Bongwon Suh, Lichan Hong, Peter Pirolli, and Ed H. Chi. 2010. Want to be retweeted? Large scale analytics on factors impacting retweet in Twitter network. In Proceedings of SocialCom.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tao Sun</author>
<author>Ming Zhang</author>
<author>Qiaozhu Mei</author>
</authors>
<title>Unexpected relevance: An empirical study of serendipity in retweets.</title>
<date>2013</date>
<booktitle>In Proceedings of ICWSM.</booktitle>
<contexts>
<context position="2539" citStr="Sun et al., 2013" startWordPosition="406" endWordPosition="409">wn as adoption, sharing, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wording is one of the few factors directly under an author’s control when he or she seeks to convey a fixed piece of content. For example, consider a speaker at the ACL b</context>
<context position="24302" citStr="Sun et al. (2013)" startWordPosition="4045" endWordPosition="4048">true to yourself (in the words you pick, but not necessarily in how you combine them). (Table 5) Although distinctive messages may attract attention, messages that conform to expectations might be more easily accepted and therefore shared. Prior work has explored this tension: Lakkaraju et al. (2013), in a content-controlled study, found that the more upvoted Reddit image titles balance novelty and familiarity; Danescu-Niculescu-Mizil et al. (2012) (henceforth DCKL’12) showed that the memorability of movie quotes corresponds to higher lexical distinctiveness but lower POS distinctiveness; and Sun et al. (2013) observed that deviating from one’s own past language patterns correlates with more retweets. Keeping in mind that the authors in our data have at least 5000 followers15, we consider two types of language-conformity constraints an author might try to satisfy: to be similar to what is normal in the Twitter community, and to be similar to what his or her followers expect. We measure a tweet’s similarity to expectations by its score according to the relevant language model, �T� řxc-T log(p(x)), where T refers to either all the unigrams (unigram model) or all and only bigrams (bigram model).16 We </context>
</contexts>
<marker>Sun, Zhang, Mei, 2013</marker>
<rawString>Tao Sun, Ming Zhang, and Qiaozhu Mei. 2013. Unexpected relevance: An empirical study of serendipity in retweets. In Proceedings of ICWSM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oren Tsur</author>
<author>Ari Rappoport</author>
</authors>
<title>What’s in a hashtag?: Content based prediction of the spread of ideas in microblogging communities.</title>
<date>2012</date>
<booktitle>In Proceedings of WSDM.</booktitle>
<contexts>
<context position="2566" citStr="Tsur and Rappoport, 2012" startWordPosition="410" endWordPosition="413">aring, spread, or virality. According to prior research, important features include characteristics of the originating author (e.g., verified Twitter user or not, author’s messages’ past success rate), the author’s social network (e.g., number of followers), message timing, and message content or topic (Artzi et al., 2012; Bakshy et al., 2011; Borghol et al., 2012; Guerini et al., 2011; Guerini et al., 2012; Hansen et al., 2011; Hong et al., 2011; Lakkaraju et al., 2013; Milkman and Berger, 2012; Ma et al., 2012; Petrovi´c et al., 2011; Romero et al., 2013; Suh et al., 2010; Sun et al., 2013; Tsur and Rappoport, 2012). Indeed, it’s not surprising that one of the most retweeted tweets of all time was from user BarackObama, with 40M followers, on November 6, 2012: “Four more years. [link to photo]”. Our interest in this paper is the effect of alternative message wording, meaning how the message is said, rather than what the message is about. In contrast to the identity/social/timing/topic features mentioned above, wording is one of the few factors directly under an author’s control when he or she seeks to convey a fixed piece of content. For example, consider a speaker at the ACL business meeting who has bee</context>
</contexts>
<marker>Tsur, Rappoport, 2012</marker>
<rawString>Oren Tsur and Ari Rappoport. 2012. What’s in a hashtag?: Content based prediction of the spread of ideas in microblogging communities. In Proceedings of WSDM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jaewon Yang</author>
<author>Jure Leskovec</author>
</authors>
<title>Patterns of temporal variation in online media.</title>
<date>2011</date>
<booktitle>In Proceedings of WSDM.</booktitle>
<contexts>
<context position="9802" citStr="Yang and Leskovec, 2011" startWordPosition="1557" endWordPosition="1560">uch controls, we find that predicting the more effective alternative wording is much harder than the previously well-studied problem of pre4And after crossing our fingers. 176 dicting popular content when author or topic can freely vary. Related work regarding the features we considered is deferred to §5.1 (features description). 3 Data Our main dataset was constructed by first gathering 1.77M topic- and author-controlled (henceforth TAC) tweet pairs5 differing in more than just spacing.6 We accomplished this by crawling timelines of 236K user ids that appear in prior work (Kwak et al., 2010; Yang and Leskovec, 2011) via the Twitter API. This crawling process also yielded 632K TAC pairs whose only difference was spacing, and an additional 558M “unpaired” tweets; as shown later in this paper, we used these extra corpora for computing language models and other auxiliary information. We applied nonobvious but important filtering — described later in this section — to control for other external factors and to reduce ambiguous cases. This brought us to a set of 11,404 pairs, with the gold-standard labels determined by which tweet in each pair was the one that received more retweets according to the Twitter API</context>
</contexts>
<marker>Yang, Leskovec, 2011</marker>
<rawString>Jaewon Yang and Jure Leskovec. 2011. Patterns of temporal variation in online media. In Proceedings of WSDM.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>