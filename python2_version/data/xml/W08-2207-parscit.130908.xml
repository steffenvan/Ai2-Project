<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000002">
<title confidence="0.9834395">
KnowNet:
A Proposal for Building Highly
Connected and Dense
Knowledge Bases from the Web
</title>
<author confidence="0.973409">
Montse Cuadros
</author>
<affiliation confidence="0.942051">
TALP Research Center, UPC, Barcelona (Spain)
</affiliation>
<email confidence="0.996105">
email: cuadros@lsi.upc.edu
</email>
<author confidence="0.694356">
German Rigau
</author>
<affiliation confidence="0.454184">
IXA NLP Group, UPV/EHU, Donostia (Spain)
</affiliation>
<email confidence="0.984482">
email: german.rigau@ehu.es
</email>
<sectionHeader confidence="0.992543" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999592333333334">
This paper presents a new fully automatic method for building highly
dense and accurate knowledge bases from existing semantic resources.
Basically, the method uses a wide-coverage and accurate knowledge-
based Word Sense Disambiguation algorithm to assign the most appro-
priate senses to large sets of topically related words acquired from the
web. KnowNet, the resulting knowledge-base which connects large sets
of semantically-related concepts is a major step towards the autonomous
acquisition of knowledge from raw corpora. In fact, KnowNet is several
times larger than any available knowledge resource encoding relations
between synsets, and the knowledge that KnowNet contains outperform
any other resource when empirically evaluated in a common multilingual
framework.
</bodyText>
<page confidence="0.997007">
71
</page>
<note confidence="0.966867">
72 Cuadros and Rigau
</note>
<sectionHeader confidence="0.993893" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999951833333333">
Using large-scale knowledge bases, such as WordNet (Fellbaum, 1998), has become a
usual, often necessary, practice for most current Natural Language Processing (NLP)
systems. Even now, building large and rich enough knowledge bases for broad–
coverage semantic processing takes a great deal of expensive manual effort involv-
ing large research groups during long periods of development. In fact, hundreds
of person-years have been invested in the development of wordnets for various lan-
guages (Vossen, 1998). For example, in more than ten years of manual construction
(from 1995 to 2006, that is from version 1.5 to 3.0), WordNet passed from 103,445 to
235,402 semantic relations1. But this data does not seems to be rich enough to support
advanced concept-based NLP applications directly. It seems that applications will not
scale up to working in open domains without more detailed and rich general-purpose
(and also domain-specific) semantic knowledge built by automatic means. Obviously,
this fact has severely hampered the state-of-the-art of advanced NLP applications.
However, the Princeton WordNet is by far the most widely-used knowledge base
(Fellbaum, 1998). In fact, WordNet is being used world-wide for anchoring differ-
ent types of semantic knowledge including wordnets for languages other than English
(Atserias et al., 2004), domain knowledge (Magnini and Cavaglià, 2000) or ontolo-
gies like SUMO (Niles and Pease, 2001) or the EuroWordNet Top Concept Ontology
(Álvez et al., 2008). It contains manually coded information about nouns, verbs, ad-
jectives and adverbs in English and is organised around the notion of a synset. A
synset is a set of words with the same part-of-speech that can be interchanged in a cer-
tain context. For example, &lt;party, political_party&gt; form a synset because they can
be used to refer to the same concept. A synset is often further described by a gloss, in
this case: &amp;quot;an organisation to gain political power&amp;quot; and by explicit semantic relations
to other synsets.
Fortunately, during the last years the research community has devised a large set of
innovative methods and tools for large-scale automatic acquisition of lexical knowl-
edge from structured and unstructured corpora. Among others we can mention eX-
tended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic pref-
erences acquired from SemCor (Agirre and Martinez, 2001, 2002) or acquired from
British National Corpus (BNC) (McCarthy, 2001), large-scale Topic Signatures for
each synset acquired from the web (Agirre and de la Calle, 2004) or knowledge about
individuals from Wikipedia (Suchanek et al., 2007). Obviously, all these semantic re-
sources have been acquired using a very different set of processes (Snow et al., 2006),
tools and corpora. In fact, each semantic resource has different volume and accuracy
figures when evaluated in a common and controlled framework (Cuadros and Rigau,
2006).
However, not all available large-scale resources encode semantic relations between
synsets. In some cases, only relations between synsets and words have been acquired.
This is the case of the Topic Signatures (Agirre et al., 2000) acquired from the web
(Agirre and de la Calle, 2004). This is one of the largest semantic resources ever built
with around one hundred million relations between synsets and semantically related
</bodyText>
<footnote confidence="0.576146">
1Symmetric relations are counted only once.
</footnote>
<note confidence="0.688547">
KnowNet: A Proposal for Building Knowledge Bases from the Web 73
</note>
<bodyText confidence="0.8945715">
words.2
A knowledge net or KnowNet, is an extensible, large and accurate knowledge
base, which has been derived by semantically disambiguating the Topic Signatures
acquired from the web. Basically, the method uses a robust and accurate knowledge-
based Word Sense Disambiguation algorithm to assign the most appropriate senses
to the topic words associated to a particular synset. The resulting knowledge-base
which connects large sets of topically-related concepts is a major step towards the au-
tonomous acquisition of knowledge from raw text. In fact, KnowNet is several times
larger than WordNet and the knowledge contained in KnowNet outperforms WordNet
when empirically evaluated in a common framework.
Table 1 compares the different volumes of semantic relations between synset pairs
of available knowledge bases and the newly created KnowNets3.
</bodyText>
<tableCaption confidence="0.999694">
Table 1: Number of synset relations
</tableCaption>
<table confidence="0.997270888888889">
Source #relations
Princeton WN3.0 235,402
Selectional Preferences from SemCor 203,546
eXtended WN 550,922
Co-occurring relations from SemCor 932,008
New KnowNet-5 231,163
New KnowNet-10 689,610
New KnowNet-15 1,378,286
New KnowNet-20 2,358,927
</table>
<bodyText confidence="0.998747888888889">
Varying from five to twenty the number of processed words from each Topic Signa-
ture, we created automatically four different KnowNets with millions of new semantic
relations between synsets.
After this introduction, Section 2 describes the Topic Signatures acquired from the
web. Section 3 presents the approach we plan to follow for building highly dense and
accurate knowledge bases. Section 4 describes the methods we followed for building
KnowNet. In Section 5, we present the evaluation framework used in this study. Sec-
tion 6 describes the results when evaluating different versions of KnowNet and finally,
Section 7 presents some concluding remarks and future work.
</bodyText>
<sectionHeader confidence="0.987119" genericHeader="method">
2 Topic Signatures
</sectionHeader>
<bodyText confidence="0.968436">
Topic Signatures (TS) are word vectors related to a particular topic (Lin and Hovy,
2000). Topic Signatures are built by retrieving context words of a target topic from
large corpora. In our case, we consider word senses as topics. Basically, the acquisi-
tion of TS consists of:
• acquiring the best possible corpus examples for a particular word sense (usually
characterising each word sense as a query and performing a search on the corpus
</bodyText>
<footnote confidence="0.999399">
2Available athttp://ixa.si.ehu.es/Ixa/resources/sensecorpus
3These KnowNet versions can be downloaded from http://adimen.si.ehu.es
</footnote>
<note confidence="0.878585">
74 Cuadros and Rigau
</note>
<tableCaption confidence="0.998418">
Table 2: TS of party#n#1 (first 10 out of 12,890 total words)
</tableCaption>
<table confidence="0.6953929">
tammany#n 0.0319
alinement#n 0.0316
federalist#n 0.0315
whig#n 0.0300
missionary#j 0.0229
Democratic#n 0.0218
nazi#j 0.0202
republican#n 0.0189
constitutional#n 0.0186
organization#n 0.0163
</table>
<bodyText confidence="0.936280588235294">
for those examples that best match the queries)
• building the TS by deriving the context words that best represent the word sense
from the selected corpora.
The Topic Signatures acquired from the web (hereinafter TSWEB) constitutes one
of the largest available semantic resources with around 100 million relations (between
synsets and words) (Agirre and de la Calle, 2004). Inspired by the work of Leacock
et al. (1998), TSWEB was constructed using monosemous relatives from WN (syn-
onyms, hypernyms, direct and indirect hyponyms, and siblings), querying Google and
retrieving up to one thousand snippets per query (that is, a word sense), extracting
the salient words with distinctive frequency using TFIDF. Thus, TSWEB consist of a
large ordered list of words with weights associated to each of the senses of the poly-
semous nouns of WordNet 1.6. The number of constructed topic signatures is 35,250
with an average size per signature of 6,877 words. When evaluating TSWEB, we used
at maximum the first 700 words while for building KnowNet we used at maximum the
first 20 words.
For example, Table 2 present the first words (lemmas and part-of-speech) and
weights of the Topic Signature acquired for party#n#1.
</bodyText>
<sectionHeader confidence="0.67535" genericHeader="method">
3 Building highly connected and dense knowledge bases
</sectionHeader>
<bodyText confidence="0.999973">
It is our belief, that accurate semantic processing (such as WSD) would rely not
only on sophisticated algorithms but on knowledge intensive approaches. In fact,
the cycling arquitecture of the MEANING4 project demonstrated that acquiring bet-
ter knowledge allow to perform better Word Sense Disambiguation (WSD) and that
having improved WSD systems we are able to acquire better knowledge (Rigau et al.,
2002).
Thus, we plan to acquire by fully automatic means highly connected and dense
knowledge bases from large corpora or the web by using the knowledge already avail-
able, increasing the total number of relations from less than one million (the current
number of available relations) to millions.
</bodyText>
<footnote confidence="0.834279">
4http://www.lsi.upc.edu/~nlp/meaning
</footnote>
<note confidence="0.354207">
KnowNet: A Proposal for Building Knowledge Bases from the Web 75
</note>
<bodyText confidence="0.84391">
The current proposal consist of:
</bodyText>
<listItem confidence="0.9740766">
• to follow Cuadros et al. (2005) and Cuadros and Rigau (2006) for acquiring
highly accurate Topic Signatures for all monosemous words in WordNet (for
instance, using InfoMap (Dorow and Widdows, 2003)). That is, to acquire
word vectors closely related to a particular monosemous word (for instance, air-
port#n#1) from BNC or other large text collections like GigaWord, Wikipedia
or the web.
• to apply a very accurate knowledge–based all–words disambiguation algorithm
to the Topic Signatures in order to obtain sense vectors instead of word vectors
(for instance, using a version of Structural Semantic Interconnections algorithm
(SSI) (Navigli and Velardi, 2005)).
</listItem>
<bodyText confidence="0.960947433333333">
For instance, consider the first ten weighted words (with Part-of-Speech) appear-
ing in the Topic Signature (TS) of the word sense airport#n#1 corresponding to the
monosemous word airport, as shown in Table 3. This TS has been obtained from
BNC using InfoMap. From the ten words appearing in the TS, two of them do not
appear in WN (corresponding to the proper names heathrow#n and gatwick#n), four
words are monosemous (airport#n, airfield#n, travelling#n and passenger#n) and four
other are polysemous (flight#n, train#n, station#n and ferry#n).
Table 3: First ten words with weigths and number of senses in WN of the Topic
Signature for airport#n#1 obtained from BNC using InfoMap
word+pos weight #senses
1.000000 1
0.843162 0
0.768215 0
0.765804 9
0.740861 1
0.739805 6
0.732794 1
0.722912 1
0.722364 4
0.717653 2
airport#n
heathrow#n
gatwick#n
flight#n
airfield#n
train#n
travelling#n
passenger#n
station#n
ferry#n
</bodyText>
<subsectionHeader confidence="0.58626">
SSI-Dijkstra
</subsectionHeader>
<bodyText confidence="0.999076142857143">
We have implemented a version of the Structural Semantic Interconnections algorithm
(SSI), a knowledge-based iterative approach to Word Sense Disambiguation (Navigli
and Velardi, 2005). The SSI algorithm is very simple and consists of an initialisation
step and a set of iterative steps. Given W, an ordered list of words to be disambiguated,
the SSI algorithm performs as follows. During the initialisation step, all monosemous
words are included into the set I of already interpreted words, and the polysemous
words are included in P (all of them pending to be disambiguated). At each step, the
</bodyText>
<note confidence="0.564314">
76 Cuadros and Rigau
</note>
<tableCaption confidence="0.971226">
Table 4: Minimum distances from airport#n#1
</tableCaption>
<figure confidence="0.98508225">
Synsets Distance
4 6
4530 5
64713 4
29767 3
597 2
20 1
1 0
</figure>
<bodyText confidence="0.998460333333333">
set I is used to disambiguate one word of P, selecting the word sense which is closer
to the set I of already disambiguated words. Once a sense is disambiguated, the word
sense is removed from P and included into I. The algorithm finishes when no more
pending words remain in P.
Initially, the list I of interpreted words should include the senses of the monosemous
words in W, or a fixed set of word senses5. However, in this case, when disambiguating
a TS derived from a monosemous word m, the list I includes since the beginning at
least the sense of the monosemous word m (in our example, airport#n#1).
In order to measure the proximity of one synset (of the word to be disambiguated at
each step) to a set of synsets (those word senses already interpreted in I), the original
SSI uses an in-house knowledge base derived semi-automatically which integrates a
variety of online resources (Navigli, 2005). This very rich knowledge-base is used to
calculate graph distances between synsets. In order to avoid the exponential explosion
of possibilities, not all paths are considered. They used a context-free grammar of
relations trained on SemCor to filter-out inappropriate paths and to provide weights to
the appropriate paths.
Instead, we use part of the knowledge already available to build a very large con-
nected graph with 99,635 nodes (synsets) and 636,077 edges (the set of direct relations
between synsets gathered from WordNet and eXtended WordNet). On that graph, we
used a very efficient graph library to compute the Dijkstra algorithm.6 The Dijkstra
algorithm is a greedy algorithm that computes the shortest path distance between one
node an the rest of nodes of a graph. In that way, we can compute very efficiently
the shortest distance between any two given nodes of a graph. This version of the SSI
algorithm is called SSI-Dijkstra.
For instance, Table 4 shows the volumes of the minimum distances from airport#n#1
to the rest of the synsets of the graph. Interestingly, from airport#n#1 all synsets of
the graph are accessible following paths of at maximum six edges. While there is
only one synset at distance zero (airport#n#1) and twenty synsets directly connected
to airport#n#1, 95% of the total graph is accessible at distance four or less.
SSI-Dijkstra has very interesting properties. For instance, SSI-Dijkstra always pro-
</bodyText>
<footnote confidence="0.998255666666667">
5If no monosemous words are found or if no initial senses are provided, the algorithm could make an
initial guess based on the most probable sense of the less ambiguous word of W.
6See http://www.boost.org
</footnote>
<note confidence="0.600011">
KnowNet: A Proposal for Building Knowledge Bases from the Web 77
</note>
<bodyText confidence="0.98626875">
vides an answer when comparing the distances between the synsets of a word and all
the synsets already interpreted in I. That is, the Dijkstra algorithm always provides
an answer being the minimum distance close or far7. At each step, the SSI-Dijkstra
algorithm selects the synset which is closer to I (the set of already interpreted words).
Table 5 presents the result of the word–sense disambiguation process with the SSI-
Dijkstra algorithm on the TS presented in Table 38. Now, part of the TS obtained
from BNC using InfoMap have been disambiguated at a synset level resulting on a
word–sense disambiguated TS. Those words not present in WN1.6 have been ignored
(heathrow and gatwick). Some others, being monosemous in WordNet were consid-
ered already disambiguated (travelling, passenger, airport and airfield). But the rest,
have been correctly disambiguated (flight with nine senses, train with six senses, sta-
tion with four and ferry with two).
</bodyText>
<tableCaption confidence="0.9877025">
Table 5: Sense disambiguated TS for airport#n#1 obtained from BNC using InfoMap
and SSI-Dijkstra
</tableCaption>
<table confidence="0.970491727272727">
.
Word Offset-WN Weight
flight#n 00195002n 0.017
travelling#n 00191846n 0
train#n 03528724n 0.012
passenger#n 07460409n 0
station#n 03404271n 0.019
airport#n 02175180n 0
ferry#n 02671945n 0.010
airfield#n 02171984n 0
Gloss
</table>
<tableCaption confidence="0.6346205">
a scheduled trip by plane between designated
airports
</tableCaption>
<bodyText confidence="0.9555924">
the act of going from one place to another
a line of railway cars coupled together and drawn
by a locomotive
a person travelling in a vehicle (a boat or bus or
car or plane or train etc) who is not operating it
a building equipped with special equipment and
personnel for a particular purpose
an airfield equipped with control tower and hangers
as well as accommodations for passengers and cargo
a boat that transports people or vehicles across a
body of water and operates on a regular schedule
a place where planes take off and land
This sense disambiguated TS represents seven direct new semantic relations be-
tween airport#n#1 and the first words of the TS. It could be directly integrated into a
new knowledge base (for instance, airport#n#1 –related–&gt; flight#n#9), but also all the
indirect relations of the disambiguated TS (for instance, flight#n#9 –related–&gt; trav-
elling#n#1). In that way, having n disambiguated word senses, a total of (n2 −n)/2
relations could be created. That is, for the ten initial words of the TS of airport#n#1,
twenty-eight new direct relations between synsets could be created.
This process could be repeated for all monosemous words of WordNet appearing
in the selected corpus. The total number of monosemous words in WN1.6 is 98,953.
Obviously, not all these monosemous words are expected to appear in the corpus.
However, we expect to obtain in that way several millions of new semantic relations
between synsets. This method will allow to derive by fully automatic means a huge
knowledge base with millions of new semantic relations.
</bodyText>
<footnote confidence="0.978455666666667">
7In contrast, the original SSI algorithm not always provides a path distance because it depends on the
grammar.
8It took 4.6 seconds to disambiguate the TS on a modern personal computer.
</footnote>
<note confidence="0.944029">
78 Cuadros and Rigau
</note>
<bodyText confidence="0.99967475">
Furthermore, this approach is completely language independent. It could be re-
peated for any language having words connected to WordNet.
It remains for further study and research, how to convert the relations created in
that way to more specific and informed relations.
</bodyText>
<sectionHeader confidence="0.976146" genericHeader="method">
4 Building KnowNet
</sectionHeader>
<bodyText confidence="0.999017875">
As a proof of concept, we developed KnowNet (KN), a large-scale and extensible
knowledge base obtained by applying the SSI-Dijkstra algorithm to each topic signa-
ture from TSWEB. That is, instead of using InfoMap and a large corpora for acquiring
new Topic Signatures for all the monosemous terms in WN, we used the already avail-
able TSWEB. We have generated four different versions of KonwNet applying SSI-
Dijkstra to the first 5, 10, 15 and 20 words for each TS. SSI-Dijkstra used only the
knowledge present in WordNet and eXtended WordNet which consist of a very large
connected graph with 99,635 nodes (synsets) and 636,077 edges (semantic relations).
We generated each KnowNet by applying the SSI-Dijkstra algorithm to the whole
TSWEB (processing the first words of each of the 35,250 topic signatures). For each
TS, we obtained the direct and indirect relations from the topic (a word sense) to the
disambiguated word senses of the TS. Then, as explained in Section 3, we also gen-
erated the indirect relations for each TS. Finally, we removed symmetric and repeated
relations.
Table 6 shows the percentage of the overlapping between each KnowNet with re-
spect the knowledge contained into WordNet and eXtended WordNet, the total number
of relations and synsets of each resource. For instance, only an 8,6% of the total rela-
tions included into WN+XWN are also present in KN-20. This means that the rest of
relations from KN-20 are new. This table also shows the different KnowNet volumes.
As expected, each KnowNet is very large, ranging from hundreds of thousands to
millions of new semantic relations between synsets among increasing sets of synsets.
Surprisingly, the overlapping between the semantic relations of KnowNet and the
knowledge bases used for building the SSI-Dijkstra graph (WordNet and eXtended
WordNet) is very small, possibly indicating disjunct types of knowledge.
</bodyText>
<tableCaption confidence="0.8997885">
Table 6: Size and percentage of overlapping relations between KnowNet versions and
WN+XWN
</tableCaption>
<table confidence="0.998784">
KB WN+XWN #relations #synsets
KN-5 3.2% 231,164 39,837
KN-10 5.4% 689,610 45,770
KN-15 7.0% 1,378,286 48,461
KN-20 8.6% 2,358,927 50,705
</table>
<tableCaption confidence="0.8909162">
Table 7 presents the percentage of overlapping relations between KnowNet ver-
sions. The upper triangular part of the matrix presents the overlapping percentage
covered by larger KnowNet versions.That is, most of the knowledge from KN-5 is
also contained in larger versions of KnowNet. Interestingly, the knowledge contained
into KN-10 is only partially covered by KN-15 and KN-20. The lower triangular
</tableCaption>
<bodyText confidence="0.717231">
KnowNet: A Proposal for Building Knowledge Bases from the Web 79
part of the matrix presents the overlapping percentage covered by smaller KnowNet
versions.
</bodyText>
<tableCaption confidence="0.997831">
Table 7: Percentage of overlapping relations between KnowNet versions
</tableCaption>
<table confidence="0.9996214">
overlapping KN-5 KN-10 KN-15 KN-20
KN-5 100 93,3 97,7 97,2
KN-10 31,2 100 88,5 88,9
KN-15 16,4 44,4 100 97.14
KN-20 9,5 26,0 56,7 100
</table>
<sectionHeader confidence="0.997467" genericHeader="method">
5 Evaluation framework
</sectionHeader>
<bodyText confidence="0.999848111111111">
In order to empirically establish the relative quality of these KnowNet versions with
respect already available semantic resources, we used the noun-set of Senseval-3 En-
glish Lexical Sample task which consists of 20 nouns.
Trying to be as neutral as possible with respect to the resources studied, we applied
systematically the same disambiguation method to all of them. Recall that our main
goal is to establish a fair comparison of the knowledge resources rather than providing
the best disambiguation technique for a particular resource. Thus, all the semantic re-
sources studied are evaluated as Topic Signatures. That is, word vectors with weights
associated to a particular synset (topic) which are obtained by collecting those word
senses appearing in the synsets directly related to the topics.
A common WSD method has been applied to all knowledge resources. A simple
word overlapping counting is performed between the Topic Signature and the test
example9. The synset having higher overlapping word counts is selected. In fact, this
is a very simple WSD method which only considers the topical information around
the word to be disambiguated. All performances are evaluated on the test data using
the fine-grained scoring system provided by the organisers. Finally, we should remark
that the results are not skewed (for instance, for resolving ties) by the most frequent
sense in WN or any other statistically predicted knowledge.
</bodyText>
<subsectionHeader confidence="0.996543">
5.1 Baselines
</subsectionHeader>
<bodyText confidence="0.994338545454546">
We have designed a number of baselines in order to establish a complete evaluation
framework for comparing the performance of each semantic resource on the English
WSD task.
RANDOM: For each target word, this method selects a random sense. This base-
line can be considered as a lower-bound.
SEMCOR-MFS: This baseline selects the most frequent sense of the target word
in SemCor.
WN-MFS: This baseline is obtained by selecting the most frequent sense (the first
sense in WN1.6) of the target word. WordNet word-senses were ranked using SemCor
and other sense-annotated corpora. Thus, WN-MFS and SemCor-MFS are similar, but
not equal.
</bodyText>
<footnote confidence="0.942813">
9We also consider the multiword terms.
</footnote>
<note confidence="0.915196">
80 Cuadros and Rigau
</note>
<bodyText confidence="0.980369285714286">
TRAIN-MFS: This baseline selects the most frequent sense in the training corpus
of the target word.
TRAIN: This baseline uses the training corpus to directly build a Topic Signature
using TFIDF measure for each word sense. Note that in WSD evaluation frameworks,
this is a very basic baseline. However, in our evaluation framework, this &amp;quot;WSD base-
line&amp;quot; could be considered as an upper-bound. We do not expect to obtain better topic
signatures for a particular sense than from its own annotated corpus.
</bodyText>
<subsectionHeader confidence="0.999921">
5.2 Large-scale Knowledge Resources
</subsectionHeader>
<bodyText confidence="0.99834805">
In order to measure the relative quality of the new resources, we include in the evalu-
ation a wide range of large-scale knowledge resources connected to WordNet.
WN (Fellbaum, 1998): This resource uses the different direct relations encoded in
WN1.6 and WN2.0. We also tested WN2 using relations at distance 1 and 2, WN3
using relations at distances 1 to 3 and WN4 using relations at distances 1 to 4.
XWN (Mihalcea and Moldovan, 2001): This resource uses the direct relations en-
coded in eXtended WN.
WN+XWN: This resource uses the direct relations included in WN and XWN. We
also tested (WN+XWN)2 (using either WN or XWN relations at distances 1 and 2).
spBNC (McCarthy, 2001): This resource contains 707,618 selectional preferences
acquired for subjects and objects from BNC.
spSemCor (Agirre and Martinez, 2002): This resource contains the selectional
preferences acquired for subjects and objects from SemCor.
MCR (Atserias et al., 2004): This resource uses the direct relations of WN, XWN
and spSemCor (we excluded spBNC because of its poor performance).
TSSEM (Cuadros et al., 2007): These Topic Signatures have been constructed
using the part of SemCor having all words tagged by PoS, lemmatized and sense
tagged according to WN1.6 totalizing 192,639 words. For each word-sense appearing
in SemCor, we gather all sentences for that word sense, building a TS using TFIDF
for all word-senses co-occurring in those sentences.
</bodyText>
<sectionHeader confidence="0.983837" genericHeader="method">
6 KnowNet Evaluation
</sectionHeader>
<bodyText confidence="0.994120826086957">
We evaluated KnowNet using the framework of Section 5, that is, the noun part of the
test set from the Senseval-3 English lexical sample task.
Table 8 presents ordered by F1 measure, the performance in terms of precision
(P), recall (R) and F1 measure (F1, harmonic mean of recall and precision) of each
knowledge resource on Senseval-3 and its average size of the TS per word-sense. The
different KnowNet versions appear marked in bold and the baselines appear in italics.
In this table, TRAIN has been calculated with a vector size of at maximum 450 words.
As expected, RANDOM baseline obtains the poorest result. The most frequent senses
obtained from SemCor (SEMCOR-MFS) and WN (WN-MFS) are both below the
most frequent sense of the training corpus (TRAIN-MFS). However, all of them are
far below to the Topic Signatures acquired using the training corpus (TRAIN).
The best resources would be those obtaining better performances with a smaller
number of related words per synset. The best results are obtained by TSSEM (with
F1 of 52.4). The lowest result is obtained by the knowledge directly gathered from
WN mainly because of its poor coverage (R of 18.4 and F1 of 26.1). Interestingly,
KnowNet: A Proposal for Building Knowledge Bases from the Web 81
the knowledge integrated in the MCR although partly derived by automatic means
performs much better in terms of precision, recall and F1 measures than using them
separately (F1 with 18.4 points higher than WN, 9.1 than XWN and 3.7 than spSem-
Cor).
Despite its small size, the resources derived from SemCor obtain better results than
its counterparts using much larger corpora (TSSEM vs. TSWEB and spSemCor vs.
spBNC).
Regarding the baselines, all knowledge resources surpass RANDOM, but none
achieves neither WN-MFS, TRAIN-MFS nor TRAIN. Only TSSEM obtains better
results than SEMCOR-MFS and is very close to the most frequent sense of WN (WN-
MFS) and the training (TRAIN-MFS).
The different versions of KnowNet consistently obtain better performances as they
increase the window size of processed words of TSWEB. As expected, KnowNet-
5 obtain the lower results. However, it performs better than WN (and all its ex-
tensions) and spBNC. Interestingly, from KnowNet-10, all KnowNet versions sur-
pass the knowledge resources used for their construction (WN, XWN, TSWEB and
WN+XWN).
Furthermore, the integration of WN+XWN+KN−20 performs better than MCR
and similarly to MCR2 (having less than 50 times its size). It is also interesting to note
that WN+XWN+KN−20 has a better performance than their individual resources,
indicating a complementary knowledge. In fact, WN+XWN+KN−20 performs much
better than the resources from which it derives (WN, XWN and TSWEB).
These initial results seem to be very promising. If we do not consider the re-
sources derived from manually sense annotated data (spSemCor, MCR, TSSEM, etc.),
KnowNet-10 performs better that any knowledge resource derived by manual or au-
tomatic means. In fact, KnowNet-15 and KnowNet-20 outperforms spSemCor which
was derived from manually annotated corpora. This is a very interesting result since
these KnowNet versions have been derived only with the knowledge coming from
WN and the web (that is, TSWEB), and WN and XWN as a knowledge source for
SSI-Dijkstra (eXtended WordNet only has 17,185 manually labelled senses).
</bodyText>
<sectionHeader confidence="0.994981" genericHeader="conclusions">
7 Conclusions and future research
</sectionHeader>
<bodyText confidence="0.999715384615385">
The initial results obtained for the different versions of KnowNet seem to be very
promising, since they seem to be of a better quality than other available knowledge
resources encoding relations between synsets derived from non-annotated sense cor-
pora.
We tested all these resources and the different versions of KnowNet on SemEval-
2007 English Lexical Sample Task (Cuadros and Rigau, 2008a). When comparing
the ranking of the different knowledge resources, the different versions of KnowNet
seem to be more robust and stable across corpora changes than the rest of resources.
Furthermore, we also tested the performance of KnowNet when ported to Spanish (as
the Spanish WordNet is also integrated into the MCR). Starting from KnowNet-10,
all KnowNet versions perform better than any other knowledge resource on Spanish
derived by manual or automatic means (including the MCR) (Cuadros and Rigau,
2008b).
</bodyText>
<note confidence="0.91891">
82 Cuadros and Rigau
</note>
<tableCaption confidence="0.99194">
Table 8: P, R and F1 fine-grained results for the resources evaluated at Senseval-3,
</tableCaption>
<table confidence="0.98937904">
English Lexical Sample Task
KB P R F1 Av. Size
TRAIN 65.1 65.1 65.1 450
TRAIN-MFS 54.5 54.5 54.5
WN-MFS 53.0 53.0 53.0
TSSEM 52.5 52.4 52.4 103
SEMCOR-MFS 49.0 49.1 49.0
MCR2 45.1 45.1 45.1 26,429
WN+XWN+KN-20 44.8 44.8 44.8 671
MCR 45.3 43.7 44.5 129
KnowNet-20 44.1 44.1 44.1 610
KnowNet-15 43.9 43.9 43.9 339
spSemCor 43.1 38.7 40.8 56
KnowNet-10 40.1 40.0 40.0 154
(WN+XWN)2 38.5 38.0 38.3 5,730
WN+XWN 40.0 34.2 36.8 74
TSWEB 36.1 35.9 36.0 1,721
XWN 38.8 32.5 35.4 69
KnowNet-5 35.0 35.0 35.0 44
WN3 35.0 34.7 34.8 503
WN4 33.2 33.1 33.2 2,346
WN2 33.1 27.5 30.0 105
spBNC 36.3 25.4 29.9 128
WN 44.9 18.4 26.1 14
RANDOM 19.1 19.1 19.1
</table>
<bodyText confidence="0.962106">
In sum, this is a preliminary step towards improved KnowNets we plan to obtain
exploiting the Topic Signatures derived from monosemous words as explained in Sec-
tion 3.
</bodyText>
<sectionHeader confidence="0.81619" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998952333333333">
We want to thank Aitor Soroa for his technical support and the anonymous reviewers
for their comments. This work has been supported by KNOW (TIN2006-15049-C03-
01) and KYOTO (ICT-2007-211423).
</bodyText>
<sectionHeader confidence="0.99945" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996956868852459">
Agirre, E., O. Ansa, D. Martinez, and E. Hovy (2000). Enriching very large ontologies
with topic signatures. In Proceedings of ECAI’00 workshop on Ontology Learning,
Berlin, Germany.
Agirre, E. and O. L. de la Calle (2004). Publicly available topic signatures for all
wordnet nominal senses. In Proceedings of LREC, Lisbon, Portugal.
KnowNet: A Proposal for Building Knowledge Bases from the Web 83
Agirre, E. and D. Martinez (2001). Learning class-to-class selectional preferences. In
Proceedings of CoNLL, Toulouse, France.
Agirre, E. and D. Martinez (2002). Integrating selectional preferences in wordnet. In
Proceedings of GWC, Mysore, India.
Álvez, J., J. Atserias, J. Carrera, S. Climent, A. Oliver, and G. Rigau (2008). Consis-
tent annotation of eurowordnet with the top concept ontology. In Proceedings of
Fourth International WordNet Conference (GWC’08).
Atserias, J., L. Villarejo, G. Rigau, E. Agirre, J. Carroll, B. Magnini, and P. Vossen
(2004). The meaning multilingual central repository. In Proceedings of GWC,
Brno, Czech Republic.
Cuadros, M., L. Padró, and G. Rigau (2005). Comparing methods for automatic ac-
quisition of topic signatures. In Proceedings of RANLP, Borovets, Bulgaria.
Cuadros, M. and G. Rigau (2006). Quality assessment of large scale knowledge re-
sources. In Proceedings of the EMNLP.
Cuadros, M. and G. Rigau (2008a). KnowNet: Building a L´narge Net of Knowledge
from the Web. In Proceedings of COLING.
Cuadros, M. and G. Rigau (2008b). Multilingual Evaluation of KnowNet. In Pro-
ceedings of SEPLN.
Cuadros, M., G. Rigau, and M. Castillo (2007). Evaluating large-scale knowledge
resources across languages. In Proceedings of RANLP.
Dorow, B. and D. Widdows (2003). Discovering corpus-specific word senses. In
EACL, Budapest.
Fellbaum, C. (1998). WordNet. An Electronic Lexical Database. The MIT Press.
Leacock, C., M. Chodorow, and G. Miller (1998). Using Corpus Statistics and Word-
Net Relations for Sense Identification. Computational Linguistics 24(1), 147–166.
Lin, C. and E. Hovy (2000). The automated acquisition of topic signatures for text
summarization. In Proceedings of COLING. Strasbourg, France.
Magnini, B. and G. Cavaglià (2000). Integrating subject field codes into wordnet. In
Proceedings of LREC, Athens. Greece.
McCarthy, D. (2001). Lexical Acquisition at the Syntax-Semantics Interface: Diathe-
sis Aternations, Subcategorization Frames and Selectional Preferences. Ph. D.
thesis, University of Sussex.
Mihalcea, R. and D. Moldovan (2001). extended wordnet: Progress report. In Pro-
ceedings of NAACL Workshop on WordNet and Other Lexical Resources, Pitts-
burgh, PA.
84 Cuadros and Rigau
Navigli, R. (2005). Semi-automatic extension of large-scale linguistic knowledge
bases. In Proc. of 18th FLAIRS International Conference (FLAIRS), Clearwater
Beach, Florida.
Navigli, R. and P. Velardi (2005). Structural semantic interconnections: a knowledge-
based approach to word sense disambiguation. IEEE Transactions on Pattern Anal-
ysis and Machine Intelligence (PAMI) 27(7), 1063–1074.
Niles, I. and A. Pease (2001). Towards a standard upper ontology. In C. Welty and
B. Smith (Eds.), Proc. of the 2nd International Conference on Formal Ontology in
Information Systems (FOIS-2001), pp. 17–19.
Rigau, G., B. Magnini, E. Agirre, P. Vossen, and J. Carroll (2002). Meaning: A
roadmap to knowledge technologies. In Proceedings of COLING’2002 Workshop
on A Roadmap for Computational Linguistics, Taipei, Taiwan.
Snow, R., D. Jurafsky, and A. Y. Ng (2006). Semantic taxonomy induction from
heterogenous evidence. In Proceedings of COLING-ACL.
Suchanek, F. M., G. Kasneci, and G. Weikum (2007). Yago: A Core of Semantic
Knowledge. In 16th international World Wide Web conference (WWW 2007), New
York, NY, USA. ACM Press.
Vossen, P. (1998). EuroWordNet: A Multilingual Database with Lexical Semantic
Networks. Kluwer Academic Publishers.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.110822">
<title confidence="0.987737">KnowNet: A Proposal for Building Highly Connected and Dense Knowledge Bases from the Web</title>
<author confidence="0.495597">Montse Cuadros</author>
<affiliation confidence="0.563063">TALP Research Center, UPC, Barcelona (Spain)</affiliation>
<author confidence="0.910678">German Rigau</author>
<affiliation confidence="0.843087">IXA NLP Group, UPV/EHU, Donostia (Spain)</affiliation>
<abstract confidence="0.999001153846154">This paper presents a new fully automatic method for building highly dense and accurate knowledge bases from existing semantic resources. Basically, the method uses a wide-coverage and accurate knowledgebased Word Sense Disambiguation algorithm to assign the most appropriate senses to large sets of topically related words acquired from the web. KnowNet, the resulting knowledge-base which connects large sets of semantically-related concepts is a major step towards the autonomous acquisition of knowledge from raw corpora. In fact, KnowNet is several times larger than any available knowledge resource encoding relations between synsets, and the knowledge that KnowNet contains outperform any other resource when empirically evaluated in a common multilingual framework.</abstract>
<note confidence="0.4332235">71 72 Cuadros and Rigau</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O Ansa</author>
<author>D Martinez</author>
<author>E Hovy</author>
</authors>
<title>Enriching very large ontologies with topic signatures.</title>
<date>2000</date>
<booktitle>In Proceedings of ECAI’00 workshop on Ontology Learning,</booktitle>
<location>Berlin, Germany.</location>
<contexts>
<context position="4227" citStr="Agirre et al., 2000" startWordPosition="634" endWordPosition="637">rre and de la Calle, 2004) or knowledge about individuals from Wikipedia (Suchanek et al., 2007). Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al., 2006), tools and corpora. In fact, each semantic resource has different volume and accuracy figures when evaluated in a common and controlled framework (Cuadros and Rigau, 2006). However, not all available large-scale resources encode semantic relations between synsets. In some cases, only relations between synsets and words have been acquired. This is the case of the Topic Signatures (Agirre et al., 2000) acquired from the web (Agirre and de la Calle, 2004). This is one of the largest semantic resources ever built with around one hundred million relations between synsets and semantically related 1Symmetric relations are counted only once. KnowNet: A Proposal for Building Knowledge Bases from the Web 73 words.2 A knowledge net or KnowNet, is an extensible, large and accurate knowledge base, which has been derived by semantically disambiguating the Topic Signatures acquired from the web. Basically, the method uses a robust and accurate knowledgebased Word Sense Disambiguation algorithm to assign</context>
</contexts>
<marker>Agirre, Ansa, Martinez, Hovy, 2000</marker>
<rawString>Agirre, E., O. Ansa, D. Martinez, and E. Hovy (2000). Enriching very large ontologies with topic signatures. In Proceedings of ECAI’00 workshop on Ontology Learning, Berlin, Germany.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O L</author>
</authors>
<title>de la Calle</title>
<date>2004</date>
<booktitle>In Proceedings of LREC, Lisbon, Portugal. KnowNet: A Proposal for Building Knowledge Bases from the Web</booktitle>
<volume>83</volume>
<marker>Agirre, L, 2004</marker>
<rawString>Agirre, E. and O. L. de la Calle (2004). Publicly available topic signatures for all wordnet nominal senses. In Proceedings of LREC, Lisbon, Portugal. KnowNet: A Proposal for Building Knowledge Bases from the Web 83</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Martinez</author>
</authors>
<title>Learning class-to-class selectional preferences.</title>
<date>2001</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="3463" citStr="Agirre and Martinez, 2001" startWordPosition="517" endWordPosition="520">, political_party&gt; form a synset because they can be used to refer to the same concept. A synset is often further described by a gloss, in this case: &amp;quot;an organisation to gain political power&amp;quot; and by explicit semantic relations to other synsets. Fortunately, during the last years the research community has devised a large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), large-scale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or knowledge about individuals from Wikipedia (Suchanek et al., 2007). Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al., 2006), tools and corpora. In fact, each semantic resource has different volume and accuracy figures when evaluated in a common and controlled framework (Cuadros and Rigau, 2006). However, not all available large-scale resources encode semantic r</context>
</contexts>
<marker>Agirre, Martinez, 2001</marker>
<rawString>Agirre, E. and D. Martinez (2001). Learning class-to-class selectional preferences. In Proceedings of CoNLL, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Martinez</author>
</authors>
<title>Integrating selectional preferences in wordnet.</title>
<date>2002</date>
<booktitle>In Proceedings of GWC, Mysore,</booktitle>
<contexts>
<context position="24027" citStr="Agirre and Martinez, 2002" startWordPosition="3764" endWordPosition="3767">resource uses the different direct relations encoded in WN1.6 and WN2.0. We also tested WN2 using relations at distance 1 and 2, WN3 using relations at distances 1 to 3 and WN4 using relations at distances 1 to 4. XWN (Mihalcea and Moldovan, 2001): This resource uses the direct relations encoded in eXtended WN. WN+XWN: This resource uses the direct relations included in WN and XWN. We also tested (WN+XWN)2 (using either WN or XWN relations at distances 1 and 2). spBNC (McCarthy, 2001): This resource contains 707,618 selectional preferences acquired for subjects and objects from BNC. spSemCor (Agirre and Martinez, 2002): This resource contains the selectional preferences acquired for subjects and objects from SemCor. MCR (Atserias et al., 2004): This resource uses the direct relations of WN, XWN and spSemCor (we excluded spBNC because of its poor performance). TSSEM (Cuadros et al., 2007): These Topic Signatures have been constructed using the part of SemCor having all words tagged by PoS, lemmatized and sense tagged according to WN1.6 totalizing 192,639 words. For each word-sense appearing in SemCor, we gather all sentences for that word sense, building a TS using TFIDF for all word-senses co-occurring in t</context>
</contexts>
<marker>Agirre, Martinez, 2002</marker>
<rawString>Agirre, E. and D. Martinez (2002). Integrating selectional preferences in wordnet. In Proceedings of GWC, Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Álvez</author>
<author>J Atserias</author>
<author>J Carrera</author>
<author>S Climent</author>
<author>A Oliver</author>
<author>G Rigau</author>
</authors>
<title>Consistent annotation of eurowordnet with the top concept ontology.</title>
<date>2008</date>
<booktitle>In Proceedings of Fourth International WordNet Conference (GWC’08).</booktitle>
<contexts>
<context position="2573" citStr="Álvez et al., 2008" startWordPosition="374" endWordPosition="377">etailed and rich general-purpose (and also domain-specific) semantic knowledge built by automatic means. Obviously, this fact has severely hampered the state-of-the-art of advanced NLP applications. However, the Princeton WordNet is by far the most widely-used knowledge base (Fellbaum, 1998). In fact, WordNet is being used world-wide for anchoring different types of semantic knowledge including wordnets for languages other than English (Atserias et al., 2004), domain knowledge (Magnini and Cavaglià, 2000) or ontologies like SUMO (Niles and Pease, 2001) or the EuroWordNet Top Concept Ontology (Álvez et al., 2008). It contains manually coded information about nouns, verbs, adjectives and adverbs in English and is organised around the notion of a synset. A synset is a set of words with the same part-of-speech that can be interchanged in a certain context. For example, &lt;party, political_party&gt; form a synset because they can be used to refer to the same concept. A synset is often further described by a gloss, in this case: &amp;quot;an organisation to gain political power&amp;quot; and by explicit semantic relations to other synsets. Fortunately, during the last years the research community has devised a large set of innov</context>
</contexts>
<marker>Álvez, Atserias, Carrera, Climent, Oliver, Rigau, 2008</marker>
<rawString>Álvez, J., J. Atserias, J. Carrera, S. Climent, A. Oliver, and G. Rigau (2008). Consistent annotation of eurowordnet with the top concept ontology. In Proceedings of Fourth International WordNet Conference (GWC’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Atserias</author>
<author>L Villarejo</author>
<author>G Rigau</author>
<author>E Agirre</author>
<author>J Carroll</author>
<author>B Magnini</author>
<author>P Vossen</author>
</authors>
<title>The meaning multilingual central repository.</title>
<date>2004</date>
<booktitle>In Proceedings of GWC,</booktitle>
<location>Brno, Czech Republic.</location>
<contexts>
<context position="2417" citStr="Atserias et al., 2004" startWordPosition="349" endWordPosition="352">rich enough to support advanced concept-based NLP applications directly. It seems that applications will not scale up to working in open domains without more detailed and rich general-purpose (and also domain-specific) semantic knowledge built by automatic means. Obviously, this fact has severely hampered the state-of-the-art of advanced NLP applications. However, the Princeton WordNet is by far the most widely-used knowledge base (Fellbaum, 1998). In fact, WordNet is being used world-wide for anchoring different types of semantic knowledge including wordnets for languages other than English (Atserias et al., 2004), domain knowledge (Magnini and Cavaglià, 2000) or ontologies like SUMO (Niles and Pease, 2001) or the EuroWordNet Top Concept Ontology (Álvez et al., 2008). It contains manually coded information about nouns, verbs, adjectives and adverbs in English and is organised around the notion of a synset. A synset is a set of words with the same part-of-speech that can be interchanged in a certain context. For example, &lt;party, political_party&gt; form a synset because they can be used to refer to the same concept. A synset is often further described by a gloss, in this case: &amp;quot;an organisation to gain poli</context>
<context position="24154" citStr="Atserias et al., 2004" startWordPosition="3782" endWordPosition="3785">3 using relations at distances 1 to 3 and WN4 using relations at distances 1 to 4. XWN (Mihalcea and Moldovan, 2001): This resource uses the direct relations encoded in eXtended WN. WN+XWN: This resource uses the direct relations included in WN and XWN. We also tested (WN+XWN)2 (using either WN or XWN relations at distances 1 and 2). spBNC (McCarthy, 2001): This resource contains 707,618 selectional preferences acquired for subjects and objects from BNC. spSemCor (Agirre and Martinez, 2002): This resource contains the selectional preferences acquired for subjects and objects from SemCor. MCR (Atserias et al., 2004): This resource uses the direct relations of WN, XWN and spSemCor (we excluded spBNC because of its poor performance). TSSEM (Cuadros et al., 2007): These Topic Signatures have been constructed using the part of SemCor having all words tagged by PoS, lemmatized and sense tagged according to WN1.6 totalizing 192,639 words. For each word-sense appearing in SemCor, we gather all sentences for that word sense, building a TS using TFIDF for all word-senses co-occurring in those sentences. 6 KnowNet Evaluation We evaluated KnowNet using the framework of Section 5, that is, the noun part of the test </context>
</contexts>
<marker>Atserias, Villarejo, Rigau, Agirre, Carroll, Magnini, Vossen, 2004</marker>
<rawString>Atserias, J., L. Villarejo, G. Rigau, E. Agirre, J. Carroll, B. Magnini, and P. Vossen (2004). The meaning multilingual central repository. In Proceedings of GWC, Brno, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Cuadros</author>
<author>L Padró</author>
<author>G Rigau</author>
</authors>
<title>Comparing methods for automatic acquisition of topic signatures.</title>
<date>2005</date>
<booktitle>In Proceedings of RANLP, Borovets,</booktitle>
<contexts>
<context position="9333" citStr="Cuadros et al. (2005)" startWordPosition="1409" endWordPosition="1412">owledge allow to perform better Word Sense Disambiguation (WSD) and that having improved WSD systems we are able to acquire better knowledge (Rigau et al., 2002). Thus, we plan to acquire by fully automatic means highly connected and dense knowledge bases from large corpora or the web by using the knowledge already available, increasing the total number of relations from less than one million (the current number of available relations) to millions. 4http://www.lsi.upc.edu/~nlp/meaning KnowNet: A Proposal for Building Knowledge Bases from the Web 75 The current proposal consist of: • to follow Cuadros et al. (2005) and Cuadros and Rigau (2006) for acquiring highly accurate Topic Signatures for all monosemous words in WordNet (for instance, using InfoMap (Dorow and Widdows, 2003)). That is, to acquire word vectors closely related to a particular monosemous word (for instance, airport#n#1) from BNC or other large text collections like GigaWord, Wikipedia or the web. • to apply a very accurate knowledge–based all–words disambiguation algorithm to the Topic Signatures in order to obtain sense vectors instead of word vectors (for instance, using a version of Structural Semantic Interconnections algorithm (SS</context>
</contexts>
<marker>Cuadros, Padró, Rigau, 2005</marker>
<rawString>Cuadros, M., L. Padró, and G. Rigau (2005). Comparing methods for automatic acquisition of topic signatures. In Proceedings of RANLP, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Cuadros</author>
<author>G Rigau</author>
</authors>
<title>Quality assessment of large scale knowledge resources.</title>
<date>2006</date>
<booktitle>In Proceedings of the EMNLP.</booktitle>
<contexts>
<context position="3995" citStr="Cuadros and Rigau, 2006" startWordPosition="599" endWordPosition="602">), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), large-scale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or knowledge about individuals from Wikipedia (Suchanek et al., 2007). Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al., 2006), tools and corpora. In fact, each semantic resource has different volume and accuracy figures when evaluated in a common and controlled framework (Cuadros and Rigau, 2006). However, not all available large-scale resources encode semantic relations between synsets. In some cases, only relations between synsets and words have been acquired. This is the case of the Topic Signatures (Agirre et al., 2000) acquired from the web (Agirre and de la Calle, 2004). This is one of the largest semantic resources ever built with around one hundred million relations between synsets and semantically related 1Symmetric relations are counted only once. KnowNet: A Proposal for Building Knowledge Bases from the Web 73 words.2 A knowledge net or KnowNet, is an extensible, large and </context>
<context position="9362" citStr="Cuadros and Rigau (2006)" startWordPosition="1414" endWordPosition="1417">etter Word Sense Disambiguation (WSD) and that having improved WSD systems we are able to acquire better knowledge (Rigau et al., 2002). Thus, we plan to acquire by fully automatic means highly connected and dense knowledge bases from large corpora or the web by using the knowledge already available, increasing the total number of relations from less than one million (the current number of available relations) to millions. 4http://www.lsi.upc.edu/~nlp/meaning KnowNet: A Proposal for Building Knowledge Bases from the Web 75 The current proposal consist of: • to follow Cuadros et al. (2005) and Cuadros and Rigau (2006) for acquiring highly accurate Topic Signatures for all monosemous words in WordNet (for instance, using InfoMap (Dorow and Widdows, 2003)). That is, to acquire word vectors closely related to a particular monosemous word (for instance, airport#n#1) from BNC or other large text collections like GigaWord, Wikipedia or the web. • to apply a very accurate knowledge–based all–words disambiguation algorithm to the Topic Signatures in order to obtain sense vectors instead of word vectors (for instance, using a version of Structural Semantic Interconnections algorithm (SSI) (Navigli and Velardi, 2005</context>
</contexts>
<marker>Cuadros, Rigau, 2006</marker>
<rawString>Cuadros, M. and G. Rigau (2006). Quality assessment of large scale knowledge resources. In Proceedings of the EMNLP.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Cuadros</author>
<author>G</author>
</authors>
<title>Rigau (2008a). KnowNet: Building a L´narge Net of Knowledge from the Web. In</title>
<booktitle>Proceedings of COLING.</booktitle>
<marker>Cuadros, G, </marker>
<rawString>Cuadros, M. and G. Rigau (2008a). KnowNet: Building a L´narge Net of Knowledge from the Web. In Proceedings of COLING.</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Cuadros</author>
<author>G</author>
</authors>
<title>Rigau (2008b). Multilingual Evaluation of KnowNet.</title>
<booktitle>In Proceedings of SEPLN.</booktitle>
<marker>Cuadros, G, </marker>
<rawString>Cuadros, M. and G. Rigau (2008b). Multilingual Evaluation of KnowNet. In Proceedings of SEPLN.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Cuadros</author>
<author>G Rigau</author>
<author>M Castillo</author>
</authors>
<title>Evaluating large-scale knowledge resources across languages.</title>
<date>2007</date>
<booktitle>In Proceedings of RANLP.</booktitle>
<contexts>
<context position="24301" citStr="Cuadros et al., 2007" startWordPosition="3806" endWordPosition="3809">relations encoded in eXtended WN. WN+XWN: This resource uses the direct relations included in WN and XWN. We also tested (WN+XWN)2 (using either WN or XWN relations at distances 1 and 2). spBNC (McCarthy, 2001): This resource contains 707,618 selectional preferences acquired for subjects and objects from BNC. spSemCor (Agirre and Martinez, 2002): This resource contains the selectional preferences acquired for subjects and objects from SemCor. MCR (Atserias et al., 2004): This resource uses the direct relations of WN, XWN and spSemCor (we excluded spBNC because of its poor performance). TSSEM (Cuadros et al., 2007): These Topic Signatures have been constructed using the part of SemCor having all words tagged by PoS, lemmatized and sense tagged according to WN1.6 totalizing 192,639 words. For each word-sense appearing in SemCor, we gather all sentences for that word sense, building a TS using TFIDF for all word-senses co-occurring in those sentences. 6 KnowNet Evaluation We evaluated KnowNet using the framework of Section 5, that is, the noun part of the test set from the Senseval-3 English lexical sample task. Table 8 presents ordered by F1 measure, the performance in terms of precision (P), recall (R) </context>
</contexts>
<marker>Cuadros, Rigau, Castillo, 2007</marker>
<rawString>Cuadros, M., G. Rigau, and M. Castillo (2007). Evaluating large-scale knowledge resources across languages. In Proceedings of RANLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dorow</author>
<author>D Widdows</author>
</authors>
<title>Discovering corpus-specific word senses.</title>
<date>2003</date>
<booktitle>In EACL,</booktitle>
<location>Budapest.</location>
<contexts>
<context position="9500" citStr="Dorow and Widdows, 2003" startWordPosition="1434" endWordPosition="1437">hus, we plan to acquire by fully automatic means highly connected and dense knowledge bases from large corpora or the web by using the knowledge already available, increasing the total number of relations from less than one million (the current number of available relations) to millions. 4http://www.lsi.upc.edu/~nlp/meaning KnowNet: A Proposal for Building Knowledge Bases from the Web 75 The current proposal consist of: • to follow Cuadros et al. (2005) and Cuadros and Rigau (2006) for acquiring highly accurate Topic Signatures for all monosemous words in WordNet (for instance, using InfoMap (Dorow and Widdows, 2003)). That is, to acquire word vectors closely related to a particular monosemous word (for instance, airport#n#1) from BNC or other large text collections like GigaWord, Wikipedia or the web. • to apply a very accurate knowledge–based all–words disambiguation algorithm to the Topic Signatures in order to obtain sense vectors instead of word vectors (for instance, using a version of Structural Semantic Interconnections algorithm (SSI) (Navigli and Velardi, 2005)). For instance, consider the first ten weighted words (with Part-of-Speech) appearing in the Topic Signature (TS) of the word sense airp</context>
</contexts>
<marker>Dorow, Widdows, 2003</marker>
<rawString>Dorow, B. and D. Widdows (2003). Discovering corpus-specific word senses. In EACL, Budapest.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Fellbaum</author>
</authors>
<title>WordNet. An Electronic Lexical Database.</title>
<date>1998</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="1146" citStr="Fellbaum, 1998" startWordPosition="159" endWordPosition="160">ppropriate senses to large sets of topically related words acquired from the web. KnowNet, the resulting knowledge-base which connects large sets of semantically-related concepts is a major step towards the autonomous acquisition of knowledge from raw corpora. In fact, KnowNet is several times larger than any available knowledge resource encoding relations between synsets, and the knowledge that KnowNet contains outperform any other resource when empirically evaluated in a common multilingual framework. 71 72 Cuadros and Rigau 1 Introduction Using large-scale knowledge bases, such as WordNet (Fellbaum, 1998), has become a usual, often necessary, practice for most current Natural Language Processing (NLP) systems. Even now, building large and rich enough knowledge bases for broad– coverage semantic processing takes a great deal of expensive manual effort involving large research groups during long periods of development. In fact, hundreds of person-years have been invested in the development of wordnets for various languages (Vossen, 1998). For example, in more than ten years of manual construction (from 1995 to 2006, that is from version 1.5 to 3.0), WordNet passed from 103,445 to 235,402 semanti</context>
<context position="23394" citStr="Fellbaum, 1998" startWordPosition="3662" endWordPosition="3663">IN: This baseline uses the training corpus to directly build a Topic Signature using TFIDF measure for each word sense. Note that in WSD evaluation frameworks, this is a very basic baseline. However, in our evaluation framework, this &amp;quot;WSD baseline&amp;quot; could be considered as an upper-bound. We do not expect to obtain better topic signatures for a particular sense than from its own annotated corpus. 5.2 Large-scale Knowledge Resources In order to measure the relative quality of the new resources, we include in the evaluation a wide range of large-scale knowledge resources connected to WordNet. WN (Fellbaum, 1998): This resource uses the different direct relations encoded in WN1.6 and WN2.0. We also tested WN2 using relations at distance 1 and 2, WN3 using relations at distances 1 to 3 and WN4 using relations at distances 1 to 4. XWN (Mihalcea and Moldovan, 2001): This resource uses the direct relations encoded in eXtended WN. WN+XWN: This resource uses the direct relations included in WN and XWN. We also tested (WN+XWN)2 (using either WN or XWN relations at distances 1 and 2). spBNC (McCarthy, 2001): This resource contains 707,618 selectional preferences acquired for subjects and objects from BNC. spS</context>
</contexts>
<marker>Fellbaum, 1998</marker>
<rawString>Fellbaum, C. (1998). WordNet. An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
<author>G Miller</author>
</authors>
<title>Using Corpus Statistics and WordNet Relations for Sense Identification.</title>
<date>1998</date>
<journal>Computational Linguistics</journal>
<volume>24</volume>
<issue>1</issue>
<pages>147--166</pages>
<contexts>
<context position="7618" citStr="Leacock et al. (1998)" startWordPosition="1139" endWordPosition="1142">tal words) tammany#n 0.0319 alinement#n 0.0316 federalist#n 0.0315 whig#n 0.0300 missionary#j 0.0229 Democratic#n 0.0218 nazi#j 0.0202 republican#n 0.0189 constitutional#n 0.0186 organization#n 0.0163 for those examples that best match the queries) • building the TS by deriving the context words that best represent the word sense from the selected corpora. The Topic Signatures acquired from the web (hereinafter TSWEB) constitutes one of the largest available semantic resources with around 100 million relations (between synsets and words) (Agirre and de la Calle, 2004). Inspired by the work of Leacock et al. (1998), TSWEB was constructed using monosemous relatives from WN (synonyms, hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense), extracting the salient words with distinctive frequency using TFIDF. Thus, TSWEB consist of a large ordered list of words with weights associated to each of the senses of the polysemous nouns of WordNet 1.6. The number of constructed topic signatures is 35,250 with an average size per signature of 6,877 words. When evaluating TSWEB, we used at maximum the first 700 words while </context>
</contexts>
<marker>Leacock, Chodorow, Miller, 1998</marker>
<rawString>Leacock, C., M. Chodorow, and G. Miller (1998). Using Corpus Statistics and WordNet Relations for Sense Identification. Computational Linguistics 24(1), 147–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lin</author>
<author>E Hovy</author>
</authors>
<title>The automated acquisition of topic signatures for text summarization.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING.</booktitle>
<location>Strasbourg, France.</location>
<contexts>
<context position="6442" citStr="Lin and Hovy, 2000" startWordPosition="966" endWordPosition="969">c relations between synsets. After this introduction, Section 2 describes the Topic Signatures acquired from the web. Section 3 presents the approach we plan to follow for building highly dense and accurate knowledge bases. Section 4 describes the methods we followed for building KnowNet. In Section 5, we present the evaluation framework used in this study. Section 6 describes the results when evaluating different versions of KnowNet and finally, Section 7 presents some concluding remarks and future work. 2 Topic Signatures Topic Signatures (TS) are word vectors related to a particular topic (Lin and Hovy, 2000). Topic Signatures are built by retrieving context words of a target topic from large corpora. In our case, we consider word senses as topics. Basically, the acquisition of TS consists of: • acquiring the best possible corpus examples for a particular word sense (usually characterising each word sense as a query and performing a search on the corpus 2Available athttp://ixa.si.ehu.es/Ixa/resources/sensecorpus 3These KnowNet versions can be downloaded from http://adimen.si.ehu.es 74 Cuadros and Rigau Table 2: TS of party#n#1 (first 10 out of 12,890 total words) tammany#n 0.0319 alinement#n 0.031</context>
</contexts>
<marker>Lin, Hovy, 2000</marker>
<rawString>Lin, C. and E. Hovy (2000). The automated acquisition of topic signatures for text summarization. In Proceedings of COLING. Strasbourg, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavaglià</author>
</authors>
<title>Integrating subject field codes into wordnet.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Athens. Greece.</location>
<contexts>
<context position="2464" citStr="Magnini and Cavaglià, 2000" startWordPosition="355" endWordPosition="358">sed NLP applications directly. It seems that applications will not scale up to working in open domains without more detailed and rich general-purpose (and also domain-specific) semantic knowledge built by automatic means. Obviously, this fact has severely hampered the state-of-the-art of advanced NLP applications. However, the Princeton WordNet is by far the most widely-used knowledge base (Fellbaum, 1998). In fact, WordNet is being used world-wide for anchoring different types of semantic knowledge including wordnets for languages other than English (Atserias et al., 2004), domain knowledge (Magnini and Cavaglià, 2000) or ontologies like SUMO (Niles and Pease, 2001) or the EuroWordNet Top Concept Ontology (Álvez et al., 2008). It contains manually coded information about nouns, verbs, adjectives and adverbs in English and is organised around the notion of a synset. A synset is a set of words with the same part-of-speech that can be interchanged in a certain context. For example, &lt;party, political_party&gt; form a synset because they can be used to refer to the same concept. A synset is often further described by a gloss, in this case: &amp;quot;an organisation to gain political power&amp;quot; and by explicit semantic relations</context>
</contexts>
<marker>Magnini, Cavaglià, 2000</marker>
<rawString>Magnini, B. and G. Cavaglià (2000). Integrating subject field codes into wordnet. In Proceedings of LREC, Athens. Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
</authors>
<title>Lexical Acquisition at the Syntax-Semantics Interface: Diathesis Aternations, Subcategorization Frames and Selectional Preferences.</title>
<date>2001</date>
<tech>Ph. D. thesis,</tech>
<institution>University of Sussex.</institution>
<contexts>
<context position="3534" citStr="McCarthy, 2001" startWordPosition="529" endWordPosition="530">ncept. A synset is often further described by a gloss, in this case: &amp;quot;an organisation to gain political power&amp;quot; and by explicit semantic relations to other synsets. Fortunately, during the last years the research community has devised a large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), large-scale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or knowledge about individuals from Wikipedia (Suchanek et al., 2007). Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al., 2006), tools and corpora. In fact, each semantic resource has different volume and accuracy figures when evaluated in a common and controlled framework (Cuadros and Rigau, 2006). However, not all available large-scale resources encode semantic relations between synsets. In some cases, only relations between synsets</context>
<context position="23890" citStr="McCarthy, 2001" startWordPosition="3748" endWordPosition="3749"> we include in the evaluation a wide range of large-scale knowledge resources connected to WordNet. WN (Fellbaum, 1998): This resource uses the different direct relations encoded in WN1.6 and WN2.0. We also tested WN2 using relations at distance 1 and 2, WN3 using relations at distances 1 to 3 and WN4 using relations at distances 1 to 4. XWN (Mihalcea and Moldovan, 2001): This resource uses the direct relations encoded in eXtended WN. WN+XWN: This resource uses the direct relations included in WN and XWN. We also tested (WN+XWN)2 (using either WN or XWN relations at distances 1 and 2). spBNC (McCarthy, 2001): This resource contains 707,618 selectional preferences acquired for subjects and objects from BNC. spSemCor (Agirre and Martinez, 2002): This resource contains the selectional preferences acquired for subjects and objects from SemCor. MCR (Atserias et al., 2004): This resource uses the direct relations of WN, XWN and spSemCor (we excluded spBNC because of its poor performance). TSSEM (Cuadros et al., 2007): These Topic Signatures have been constructed using the part of SemCor having all words tagged by PoS, lemmatized and sense tagged according to WN1.6 totalizing 192,639 words. For each wor</context>
</contexts>
<marker>McCarthy, 2001</marker>
<rawString>McCarthy, D. (2001). Lexical Acquisition at the Syntax-Semantics Interface: Diathesis Aternations, Subcategorization Frames and Selectional Preferences. Ph. D. thesis, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>D Moldovan</author>
</authors>
<title>extended wordnet: Progress report.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL Workshop on WordNet and Other Lexical Resources,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="3372" citStr="Mihalcea and Moldovan, 2001" startWordPosition="504" endWordPosition="507">ith the same part-of-speech that can be interchanged in a certain context. For example, &lt;party, political_party&gt; form a synset because they can be used to refer to the same concept. A synset is often further described by a gloss, in this case: &amp;quot;an organisation to gain political power&amp;quot; and by explicit semantic relations to other synsets. Fortunately, during the last years the research community has devised a large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), large-scale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or knowledge about individuals from Wikipedia (Suchanek et al., 2007). Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al., 2006), tools and corpora. In fact, each semantic resource has different volume and accuracy figures when evaluated in a common and controlled framework (C</context>
<context position="23648" citStr="Mihalcea and Moldovan, 2001" startWordPosition="3705" endWordPosition="3708">seline&amp;quot; could be considered as an upper-bound. We do not expect to obtain better topic signatures for a particular sense than from its own annotated corpus. 5.2 Large-scale Knowledge Resources In order to measure the relative quality of the new resources, we include in the evaluation a wide range of large-scale knowledge resources connected to WordNet. WN (Fellbaum, 1998): This resource uses the different direct relations encoded in WN1.6 and WN2.0. We also tested WN2 using relations at distance 1 and 2, WN3 using relations at distances 1 to 3 and WN4 using relations at distances 1 to 4. XWN (Mihalcea and Moldovan, 2001): This resource uses the direct relations encoded in eXtended WN. WN+XWN: This resource uses the direct relations included in WN and XWN. We also tested (WN+XWN)2 (using either WN or XWN relations at distances 1 and 2). spBNC (McCarthy, 2001): This resource contains 707,618 selectional preferences acquired for subjects and objects from BNC. spSemCor (Agirre and Martinez, 2002): This resource contains the selectional preferences acquired for subjects and objects from SemCor. MCR (Atserias et al., 2004): This resource uses the direct relations of WN, XWN and spSemCor (we excluded spBNC because o</context>
</contexts>
<marker>Mihalcea, Moldovan, 2001</marker>
<rawString>Mihalcea, R. and D. Moldovan (2001). extended wordnet: Progress report. In Proceedings of NAACL Workshop on WordNet and Other Lexical Resources, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
</authors>
<title>Semi-automatic extension of large-scale linguistic knowledge bases.</title>
<date>2005</date>
<booktitle>In Proc. of 18th FLAIRS International Conference (FLAIRS),</booktitle>
<location>Clearwater Beach, Florida.</location>
<contexts>
<context position="12525" citStr="Navigli, 2005" startWordPosition="1927" endWordPosition="1928">e list I of interpreted words should include the senses of the monosemous words in W, or a fixed set of word senses5. However, in this case, when disambiguating a TS derived from a monosemous word m, the list I includes since the beginning at least the sense of the monosemous word m (in our example, airport#n#1). In order to measure the proximity of one synset (of the word to be disambiguated at each step) to a set of synsets (those word senses already interpreted in I), the original SSI uses an in-house knowledge base derived semi-automatically which integrates a variety of online resources (Navigli, 2005). This very rich knowledge-base is used to calculate graph distances between synsets. In order to avoid the exponential explosion of possibilities, not all paths are considered. They used a context-free grammar of relations trained on SemCor to filter-out inappropriate paths and to provide weights to the appropriate paths. Instead, we use part of the knowledge already available to build a very large connected graph with 99,635 nodes (synsets) and 636,077 edges (the set of direct relations between synsets gathered from WordNet and eXtended WordNet). On that graph, we used a very efficient graph</context>
</contexts>
<marker>Navigli, 2005</marker>
<rawString>Navigli, R. (2005). Semi-automatic extension of large-scale linguistic knowledge bases. In Proc. of 18th FLAIRS International Conference (FLAIRS), Clearwater Beach, Florida.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>P Velardi</author>
</authors>
<title>Structural semantic interconnections: a knowledgebased approach to word sense disambiguation.</title>
<date>2005</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI)</journal>
<volume>27</volume>
<issue>7</issue>
<pages>1063--1074</pages>
<contexts>
<context position="9963" citStr="Navigli and Velardi, 2005" startWordPosition="1503" endWordPosition="1506"> Cuadros and Rigau (2006) for acquiring highly accurate Topic Signatures for all monosemous words in WordNet (for instance, using InfoMap (Dorow and Widdows, 2003)). That is, to acquire word vectors closely related to a particular monosemous word (for instance, airport#n#1) from BNC or other large text collections like GigaWord, Wikipedia or the web. • to apply a very accurate knowledge–based all–words disambiguation algorithm to the Topic Signatures in order to obtain sense vectors instead of word vectors (for instance, using a version of Structural Semantic Interconnections algorithm (SSI) (Navigli and Velardi, 2005)). For instance, consider the first ten weighted words (with Part-of-Speech) appearing in the Topic Signature (TS) of the word sense airport#n#1 corresponding to the monosemous word airport, as shown in Table 3. This TS has been obtained from BNC using InfoMap. From the ten words appearing in the TS, two of them do not appear in WN (corresponding to the proper names heathrow#n and gatwick#n), four words are monosemous (airport#n, airfield#n, travelling#n and passenger#n) and four other are polysemous (flight#n, train#n, station#n and ferry#n). Table 3: First ten words with weigths and number o</context>
</contexts>
<marker>Navigli, Velardi, 2005</marker>
<rawString>Navigli, R. and P. Velardi (2005). Structural semantic interconnections: a knowledgebased approach to word sense disambiguation. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI) 27(7), 1063–1074.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Niles</author>
<author>A Pease</author>
</authors>
<title>Towards a standard upper ontology. In</title>
<date>2001</date>
<booktitle>Proc. of the 2nd International Conference on Formal Ontology in Information Systems (FOIS-2001),</booktitle>
<pages>17--19</pages>
<contexts>
<context position="2512" citStr="Niles and Pease, 2001" startWordPosition="364" endWordPosition="367">ions will not scale up to working in open domains without more detailed and rich general-purpose (and also domain-specific) semantic knowledge built by automatic means. Obviously, this fact has severely hampered the state-of-the-art of advanced NLP applications. However, the Princeton WordNet is by far the most widely-used knowledge base (Fellbaum, 1998). In fact, WordNet is being used world-wide for anchoring different types of semantic knowledge including wordnets for languages other than English (Atserias et al., 2004), domain knowledge (Magnini and Cavaglià, 2000) or ontologies like SUMO (Niles and Pease, 2001) or the EuroWordNet Top Concept Ontology (Álvez et al., 2008). It contains manually coded information about nouns, verbs, adjectives and adverbs in English and is organised around the notion of a synset. A synset is a set of words with the same part-of-speech that can be interchanged in a certain context. For example, &lt;party, political_party&gt; form a synset because they can be used to refer to the same concept. A synset is often further described by a gloss, in this case: &amp;quot;an organisation to gain political power&amp;quot; and by explicit semantic relations to other synsets. Fortunately, during the last </context>
</contexts>
<marker>Niles, Pease, 2001</marker>
<rawString>Niles, I. and A. Pease (2001). Towards a standard upper ontology. In C. Welty and B. Smith (Eds.), Proc. of the 2nd International Conference on Formal Ontology in Information Systems (FOIS-2001), pp. 17–19.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Rigau</author>
<author>B Magnini</author>
<author>E Agirre</author>
<author>P Vossen</author>
<author>J Carroll</author>
</authors>
<title>Meaning: A roadmap to knowledge technologies.</title>
<date>2002</date>
<booktitle>In Proceedings of COLING’2002 Workshop on A Roadmap for Computational Linguistics,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="8873" citStr="Rigau et al., 2002" startWordPosition="1338" endWordPosition="1341">mum the first 20 words. For example, Table 2 present the first words (lemmas and part-of-speech) and weights of the Topic Signature acquired for party#n#1. 3 Building highly connected and dense knowledge bases It is our belief, that accurate semantic processing (such as WSD) would rely not only on sophisticated algorithms but on knowledge intensive approaches. In fact, the cycling arquitecture of the MEANING4 project demonstrated that acquiring better knowledge allow to perform better Word Sense Disambiguation (WSD) and that having improved WSD systems we are able to acquire better knowledge (Rigau et al., 2002). Thus, we plan to acquire by fully automatic means highly connected and dense knowledge bases from large corpora or the web by using the knowledge already available, increasing the total number of relations from less than one million (the current number of available relations) to millions. 4http://www.lsi.upc.edu/~nlp/meaning KnowNet: A Proposal for Building Knowledge Bases from the Web 75 The current proposal consist of: • to follow Cuadros et al. (2005) and Cuadros and Rigau (2006) for acquiring highly accurate Topic Signatures for all monosemous words in WordNet (for instance, using InfoMa</context>
</contexts>
<marker>Rigau, Magnini, Agirre, Vossen, Carroll, 2002</marker>
<rawString>Rigau, G., B. Magnini, E. Agirre, P. Vossen, and J. Carroll (2002). Meaning: A roadmap to knowledge technologies. In Proceedings of COLING’2002 Workshop on A Roadmap for Computational Linguistics, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Snow</author>
<author>D Jurafsky</author>
<author>A Y Ng</author>
</authors>
<title>Semantic taxonomy induction from heterogenous evidence.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING-ACL.</booktitle>
<contexts>
<context position="3823" citStr="Snow et al., 2006" startWordPosition="573" endWordPosition="576">e-scale automatic acquisition of lexical knowledge from structured and unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), large-scale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or knowledge about individuals from Wikipedia (Suchanek et al., 2007). Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al., 2006), tools and corpora. In fact, each semantic resource has different volume and accuracy figures when evaluated in a common and controlled framework (Cuadros and Rigau, 2006). However, not all available large-scale resources encode semantic relations between synsets. In some cases, only relations between synsets and words have been acquired. This is the case of the Topic Signatures (Agirre et al., 2000) acquired from the web (Agirre and de la Calle, 2004). This is one of the largest semantic resources ever built with around one hundred million relations between synsets and semantically related 1</context>
</contexts>
<marker>Snow, Jurafsky, Ng, 2006</marker>
<rawString>Snow, R., D. Jurafsky, and A. Y. Ng (2006). Semantic taxonomy induction from heterogenous evidence. In Proceedings of COLING-ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F M Suchanek</author>
<author>G Kasneci</author>
<author>G Weikum</author>
</authors>
<title>Yago: A Core of Semantic Knowledge.</title>
<date>2007</date>
<booktitle>In 16th international World Wide Web conference (WWW</booktitle>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="3703" citStr="Suchanek et al., 2007" startWordPosition="553" endWordPosition="556">. Fortunately, during the last years the research community has devised a large set of innovative methods and tools for large-scale automatic acquisition of lexical knowledge from structured and unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), large-scale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or knowledge about individuals from Wikipedia (Suchanek et al., 2007). Obviously, all these semantic resources have been acquired using a very different set of processes (Snow et al., 2006), tools and corpora. In fact, each semantic resource has different volume and accuracy figures when evaluated in a common and controlled framework (Cuadros and Rigau, 2006). However, not all available large-scale resources encode semantic relations between synsets. In some cases, only relations between synsets and words have been acquired. This is the case of the Topic Signatures (Agirre et al., 2000) acquired from the web (Agirre and de la Calle, 2004). This is one of the la</context>
</contexts>
<marker>Suchanek, Kasneci, Weikum, 2007</marker>
<rawString>Suchanek, F. M., G. Kasneci, and G. Weikum (2007). Yago: A Core of Semantic Knowledge. In 16th international World Wide Web conference (WWW 2007), New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<title>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</title>
<date>1998</date>
<publisher>Kluwer Academic Publishers.</publisher>
<contexts>
<context position="1585" citStr="Vossen, 1998" startWordPosition="225" endWordPosition="226">urce when empirically evaluated in a common multilingual framework. 71 72 Cuadros and Rigau 1 Introduction Using large-scale knowledge bases, such as WordNet (Fellbaum, 1998), has become a usual, often necessary, practice for most current Natural Language Processing (NLP) systems. Even now, building large and rich enough knowledge bases for broad– coverage semantic processing takes a great deal of expensive manual effort involving large research groups during long periods of development. In fact, hundreds of person-years have been invested in the development of wordnets for various languages (Vossen, 1998). For example, in more than ten years of manual construction (from 1995 to 2006, that is from version 1.5 to 3.0), WordNet passed from 103,445 to 235,402 semantic relations1. But this data does not seems to be rich enough to support advanced concept-based NLP applications directly. It seems that applications will not scale up to working in open domains without more detailed and rich general-purpose (and also domain-specific) semantic knowledge built by automatic means. Obviously, this fact has severely hampered the state-of-the-art of advanced NLP applications. However, the Princeton WordNet i</context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Vossen, P. (1998). EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>