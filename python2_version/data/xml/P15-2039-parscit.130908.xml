<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000383">
<title confidence="0.9955775">
Word-based Japanese typed dependency parsing with grammatical
function analysis
</title>
<author confidence="0.957767">
Takaaki Tanaka Nagata Masaaki
</author>
<affiliation confidence="0.886616">
NTT Communication Science Laboratories, NTT Corporation
</affiliation>
<address confidence="0.922152">
2-4, Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237, Japan
</address>
<email confidence="0.999636">
{tanaka.takaaki,nagata.masaaki}@lab.ntt.co.jp
</email>
<sectionHeader confidence="0.9974" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999815181818182">
We present a novel scheme for word-
based Japanese typed dependency parser
which integrates syntactic structure analy-
sis and grammatical function analysis such
as predicate-argument structure analysis.
Compared to bunsetsu-based dependency
parsing, which is predominantly used in
Japanese NLP, it provides a natural way
of extracting syntactic constituents, which
is useful for downstream applications such
as statistical machine translation. It also
makes it possible to jointly decide de-
pendency and predicate-argument struc-
ture, which is usually implemented as two
separate steps. We convert an existing
treebank to the new dependency scheme
and report parsing results as a baseline
for future research. We achieved a bet-
ter accuracy for assigning function labels
than a predicate-argument structure ana-
lyzer by using grammatical functions as
dependency label.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999975704545455">
The goal of our research is to design a Japanese
typed dependency parsing that has sufficient lin-
guistically derived structural and relational infor-
mation for NLP applications such as statistical
machine translation. We focus on the Japanese-
specific aspects of designing a kind of Stanford
typed dependencies (de Marneffe et al., 2008).
Syntactic structures are usually represented as
dependencies between chunks called bunsetsus. A
bunsetsu is a Japanese grammatical and phono-
logical unit that consists of one or more con-
tent words such as a noun, verb, or adverb fol-
lowed by a sequence of zero or more function
words such as auxiliary verbs, postpositional par-
ticles, or sentence-final particles. Most publicly
available Japanese parsers, including CaboCha 1
(Kudo et al., 2002) and KNP 2 (Kawahara et al.,
2006), return bunsetsu-based dependency as syn-
tactic structure. Such parsers are generally highly
accurate and have been widely used in various
NLP applications.
However, bunsetsu-based representations also
have two serious shortcomings: one is the discrep-
ancy between syntactic and semantic units, and the
other is insufficient syntactic information (Butler
et al., 2012; Tanaka et al., 2013).
Bunsetsu chunks do not always correspond to
constituents (e.g. NP, VP), which complicates the
task of extracting semantic units from bunsetsu-
based representations. This kind of problem of-
ten arises in handling such nesting structures as
coordinating constructions. For example, there
are three dependencies in a sentence (1): a co-
ordinating dependency b2 – b3 and ordinary de-
pendencies b1 – b3 and b3 – b4. In extracting
predicate-argument structures, it is not possible to
directly extract a coordinated noun phrase 94
/LM “wine and sake” as a direct object of the
verb PXlvfz` “drank”. In other words, we need
an implicit interpretation rule in order to extract
NP in coordinating construction: head bunsetsu
b3 should be divided into a content word M and
a function word 0), then the content word should
be merged with the dependent bunsetsu b2.
</bodyText>
<equation confidence="0.899235">
(1) b1 ON/Z�
nonda
drank
</equation>
<bodyText confidence="0.906976333333333">
‘A list of wine and sake that (someone) drank’
Therefore, predicate-argument structure analysis
is usually implemented as a post-processor of
bunsetsu-based syntactic parser, not just for as-
signing grammatical functions, but for identifying
constituents, such as an analyzer SynCha 3 (Iida
</bodyText>
<footnote confidence="0.999556666666667">
1http://taku910.github.io/cabocha/.
2http://nlp.ist.i.kyoto-u.ac.jp/EN/index.php?KNP.
3http://www.cl.cs.titech.ac.jp/—ryu-i/syncha/.
</footnote>
<figure confidence="0.778889181818182">
 |b2 94/ L
wain to
wine CONJ
 |b3 A 0)
sake
no
sake
GEN
1b4 9Ar
risuto
list
</figure>
<page confidence="0.741443">
237
</page>
<bodyText confidence="0.841134454545455">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 237–242,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
A / 7714 t- *&apos;^ P 7)1 / � /Ut/4�0 /0
fish / fry -ACC eat -PAST may calico / cat
“the calico cat that may have eaten fried fish”
et al., 2011), which uses the parsing results from
CaboCha. We assume that using a word as a pars-
ing unit instead of a bunsetsu chunk helps to main-
tain consistency between syntactic structure anal-
ysis and predicate-argument structure analysis.
Another problem is that linguistically different
constructions share the same representation. The
difference of a gapped relative clause and a gapless
relative clause is a typical example. In sentences
(2) and (3), we cannot discriminate the two rela-
tions between bunsetsus Q and U using unlabeled
dependency: the former is a subject-predicate con-
struction of the noun 猫 “cat” and the verb 食べ
る “eat” (subject gap relative clause) while the lat-
ter is not a predicate-argument construction (gap-
less relative clause).
</bodyText>
<figure confidence="0.9741005">
cal
SUW
NN/NN
NN/NN PCS
VB AUX P/P/VB/AUX
VB
AUX
AUX
NN
NN
LUW
PCS
</figure>
<figureCaption confidence="0.882158">
Figure 1: A tokenized and chunked sentence.
</figureCaption>
<figure confidence="0.9573464">
NP 毛猫三
(2) b1 魚 を
sakana o
fish ACC
|b2 食べ
た
tabe ta
eat PAST
 |b3 猫
neko
cat
‘the cat that ate fish’
(3) b1 魚 を  |b2 食べ た  |b3 話
sakana o tabe ta hanashi
fish ACC eat PAST story
</figure>
<figureCaption confidence="0.239024">
‘the story about having eaten fish’
</figureCaption>
<bodyText confidence="0.999878444444444">
We aim to build a Japanese typed depen-
dency scheme that can properly deal with syn-
tactic constituency and grammatical functions in
the same representation without implicit interpre-
tation rules. The design of Japanese typed depen-
dencies is described in Section 3, and we present
our evaluation of the dependency parsing results
for a parser trained with a dependency corpus in
Section 4.
</bodyText>
<sectionHeader confidence="0.999769" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.9976675">
Mori et al. (2014) built word-based dependency
corpora in Japanese. The reported parsing
achieved an unlabeled attachment score of over
90%; however, there was no information on
the syntactic relations between the words in this
corpus. Uchimoto et al. (2008) also proposed
the criteria and definitions of word-level depen-
dency structure mainly for annotation of a sponta-
neous speech corpus, the Corpus of Spontaneous
Japanese (CSJ) (Maekawa et al., 2000), and they
do not make a distinction between detailed syntac-
tic functions either.
</bodyText>
<page confidence="0.998637">
238
</page>
<tableCaption confidence="0.998484">
Table 1: Dependency types (excerpt).
</tableCaption>
<bodyText confidence="0.999978066666667">
We proposed a typed dependency scheme based
on the well-known and widely used Stanford typed
dependencies (SD), which originated in English
and has since been extended to many languages,
but not to Japanese. The Universal dependencies
(UD) (McDonald et al., 2013; de Marneffe et al.,
2014) has been developed based on SD in order to
design the cross-linguistically consistent treebank
annotation 4. The UD for Japanese has also been
discussed, but no treebanks have been provided
yet. We focus on the feasibility of word-based
Japanese typed dependency parsing rather than on
cross-linguistic consistency. We plan to examine
the conversion between UD and our scheme in the
future.
</bodyText>
<sectionHeader confidence="0.947004" genericHeader="method">
3 Typed dependencies in Japanese
</sectionHeader>
<bodyText confidence="0.9999585">
To design a scheme of Japanese typed depen-
dencies, there are three essential points: what
should be used as parsing units, which dependency
scheme is appropriate for Japanese sentence struc-
ture, and what should be defined as dependency
types.
</bodyText>
<subsectionHeader confidence="0.999871">
3.1 Parsing unit
</subsectionHeader>
<bodyText confidence="0.999983">
Defining a word unit is indispensable for word-
based dependency parsing. However, this is not
a trivial question, especially in Japanese, where
words are not segmented by white spaces in its or-
thography. We adopted two types of word units
defined by NINJL 5 for building the Balanced
Corpus of Contemporary Written Japanese (BC-
CWJ) (Maekawa et al., 2014; Den et al., 2008):
Short unit word (SUW) is the shortest token con-
veying morphological information, and the long
unit word (LUW) is the basic unit for parsing, con-
sisting of one or more SUWs. Figure 1 shows ex-
</bodyText>
<footnote confidence="0.99828">
4http://universaldependencies.github.io/docs/.
5National Institute for Japanese Language and Linguistics.
</footnote>
<bodyText confidence="0.999052666666667">
ample results from the preprocessing of parsing.
In the figure, “/” denotes a border of SUWs in an
LUW, and “∥” denotes a bunsetsu boundary.
</bodyText>
<subsectionHeader confidence="0.99967">
3.2 Dependency scheme
</subsectionHeader>
<bodyText confidence="0.9998701">
Basically, Japanese dependency structure is re-
garded as an aggregation of pairs of a left-
side dependent word and a right-side head word,
i.e. right-headed dependency, since Japanese is a
head-final language. However, how to analyze a
predicate constituent is a matter of debate. We de-
fine two types of schemes depending on the struc-
ture related to the predicate constituent: first con-
joining predicate and arguments, and first conjoin-
ing predicate and function words such as auxiliary
verbs.
As shown in sentence (4), a predicate bunsetsu
consists of a main verb followed by a sequence
of auxiliary verbs in Japanese. We consider two
ways of constructing a verb phrase (VP). One is
first conjoining the main verb and its arguments to
construct VP as in sentence (4a), and the other is
first conjoining the main verb and auxiliary verbs
as in sentence (4b). These two types correspond to
sentences (5a) and (5b), respectively, in English.
</bodyText>
<figure confidence="0.978743">
かもしれない
may
‘the cat may have eaten the fish’
a. [ [ [VP 猫が 魚を 食べ ] た ] かもしれない ]
S O V aux aux
b. [ The cat [ [VP may have eaten] the fish] ] .
S aux aux V O
</figure>
<bodyText confidence="0.989516916666667">
The structures in sentences (4a) and (5a) are
similar to a structure based on generative gram-
mar. On the other hand, the structures in sentences
(4b) and (5b) are similar to the bunsetsu structure.
We defined two dependency schemes Head Fi-
nal type 1 (HF1) and Head Final type 2 (HF2) as
shown in Figure 2, which correspond to structures
of sentences (4a) and (4b), respectively. Addi-
tionally, we introduced Predicate Content word
Head type (PCH), where a content word (e.g.
verb) is treated as a head in a predicate phrase so as
to link the predicate to its argument more directly.
</bodyText>
<subsectionHeader confidence="0.997016">
3.3 Dependency type
</subsectionHeader>
<bodyText confidence="0.999347333333333">
We defined 35 dependency types for Japanese
based on SD, where 4-50 types are assigned for
syntactic relations in English and other languages.
</bodyText>
<figure confidence="0.997754789473685">
Category
Dep. type
case (argument)
case (adjunct)
gapped relative clause
adnominal clause
adverbial clause
coordinating construction
apposition
nsubj subject
dobj direct object
iobj indirect object
tmod temporal
lmod locative
rcmod nsubj subject gap relative clause
rcmod dobj direct object gap relative clause
rcmod iobj indirect object gap relative clause
ncmod gapless relative clause
advcl
conj
appos
function word relation
aux relation between an auxiliary
verb and other word
pobj relation between a particle
and other word
b. [ 猫が [ 魚を [VP 食べ た かもしれない ]]]
S O V aux aux
(5) a. [ The
S
cat [ may have
aux aux
[VP eaten
V
the fish] ] ] .
O
(4) 猫 が 魚 を 食べ た
cat NOM fish ACC eat PAST
</figure>
<page confidence="0.967094">
239
</page>
<table confidence="0.9730105">
LUW (Long Unit Word) source
SUW (Short Unit Word)
</table>
<tableCaption confidence="0.756463">
Table 2: Word attributes used for parser features.
* 26 non-terminal symbols (e.g. NN, VB) are employed as
coarse POS tags (CPOS) from an original treebank. ** Se-
mantic classes SEMCLASS and PNCLASS are used for gen-
eral nouns and proper nouns, respectively from a Japanese
thesaurus (Ikehara et al., 1997) to generalize the nouns.
</tableCaption>
<bodyText confidence="0.993918947368421">
Table 1 shows the major dependency types. To
discriminate between a gapped relative clause and
a gapless relative clause as described in Section
1, we assigned two dependency types rcmod and
ncmod respectively. Moreover, we introduced gap
information by subdividing rcmod into three types
to extract predicate-argument relations, while the
original SD make no distinction between them.
The labels of case and gapped relative clause
enable us to extract predicate-argument struc-
tures by simply tracing dependency paths.
In the case of HF1 in Figure 2, we find two
paths between content words: 魚フライ “fried
fish”(NN)←pobj←dobj← 食 べ “eat”(VB) and
食 べ(VB)←aux←aux←rcmod nsubj← 三
猫 “calico cat”(NN). By marking the dependency
types dobj and rcmod nsubj, we can extract the
arguments for predicate 食べる, i.e., 魚フライ as
a direct object and 三毛猫 as a subject.
</bodyText>
<sectionHeader confidence="0.999175" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.9997592">
We demonstrated the performance of the typed de-
pendency parsing based on our scheme by using
the dependency corpus automatically converted
from a constituent treebank and an off-the-self
parser.
</bodyText>
<subsectionHeader confidence="0.907904">
4.1 Resources
</subsectionHeader>
<bodyText confidence="0.999962857142857">
We used a dependency corpus that was converted
from the Japanese constituent treebank (Tanaka et
al., 2013) built by re-annotating the Kyoto Uni-
versity Text Corpus (Kurohashi et al., 2003) with
phrase structure and function labels. The Kyoto
corpus consists of approximately 40,000 sentences
from newspaper articles, and from these 17,953
sentences have been re-annotated. The treebank is
designed to have complete binary trees, which can
be easily converted to dependency trees by adapt-
ing head rules and dependency-type rules for each
partial tree. We divided this corpus into 15,953
sentences (339,573 LUWs) for the training set and
2,000 sentences (41,154 LUWs) for the test set.
</bodyText>
<subsectionHeader confidence="0.989716">
4.2 Parser and features
</subsectionHeader>
<bodyText confidence="0.99997412">
In the analysis process, sentences are first tok-
enized into SUW and tagged with SUW POS by
the morphological analyzer MeCab (Kudo et al.,
2004). The LUW analyzer Comainu (Kozawa et
al., 2014) chunks the SUW sequences into LUW
sequences. We used the MaltParser (Nivre et al.,
2007), which marked over 81 % in labeled attach-
ment score (LAS), for English SD. Stack algo-
rithm (projective) and LIBLINEAR were chosen
as the parsing algorithm and the learner, respec-
tively. We built and tested the three types of pars-
ing models with the three dependency schemes.
Features of the parsing model are made by
combining word attributes as shown in Table
2. We employed SUW-based attributes as well
as LUW-based attributes because LUW contains
many multiword expressions such as compound
nouns, and features combining LUW-based at-
tributes tend to be sparse. The SUW-based at-
tributes are extracted by using the leftmost or
rightmost SUW of the target LUW. For instance,
for LUW 魚フライ in Figure 1, the SUW-based
attributes are s LEMMA L (the leftmost SUW’s
lemma 魚 “fish”) and s LEMMA R (the rightmost
SUW’s lemma フライ “fry”).
</bodyText>
<subsectionHeader confidence="0.842458">
4.3 Results
</subsectionHeader>
<bodyText confidence="0.999976071428571">
The parsing results for the three dependency
schemes are shown in Table 3 (a). The depen-
dency schemes HF1 and HF2 are comparable, but
PCH is slightly lower than them, which is prob-
ably because PCH is a more complicated struc-
ture, having left-to-right dependencies in the pred-
icate phrase, than the head-final types HF1 and
HF2. The performances of the LUW-based pars-
ings are considered to be comparable to the results
of a bunsetsu-dependency parser CaboCha on the
same data set, i.e. a UAS of 92.7%, although we
cannot directly compare them due to the difference
in parsing units. Table 3 (b) shows the results for
each dependency type. The argument types (nsubj,
</bodyText>
<figure confidence="0.952206625">
l FORM
l LEMMA
l UPOS
l INFTYPE
l INFFORM
l CPOS
l SEMCLASS
l PNCLASS
</figure>
<table confidence="0.9001198">
form LUW chunker
lemma LUW chunker
POS LUW chunker
inflection type LUW chunker
inflection form LUW chunker
non-terminal symbol *
semantic class thesaurus**
NE class thesaurus**
s FORM R
s FORM L
s LEMMA R
s LEMMA L
s UPOS R
s CPOS R
s SEMCLASS R
s PNCLASS R
form (rightmost) tokenizer
form (leftmost) tokenizer
lemma (rightmost) tokenizer
lemma (leftmost) tokenizer
POS tokenizer
non-terminal symbol *
semantic class thesaurus**
NE class thesaurus**
240
Scheme UAS LAS
HF1 94.09 89.49
HF2 94.21 89.66
PCH 93.53 89.22
(a) Overall results
dep. type F1 score
HF1 HF2 PCH
nsubj 80.47 82.12 81.08
dobj 92.06 90.28 92.29
iobj 82.05 80.22 81.89
tmod 55.54 56.01 54.09
lmod 52.10 53.56 48.48
rcmod nsubj 60.38 61.10 62.95
rcmod dobj 28.07 33.33 39.46
rcmod iobj 32.65 33.90 36.36
ncmod 82.81 83.07 82.94
advcl 65.28 66.70 60.69
conj 70.78 70.68 69.53
appos 51.11 57.45 46.32
(b) Results for each dependency type
</table>
<tableCaption confidence="0.996789">
Table 3: Parsing results.
</tableCaption>
<table confidence="0.9999374">
Scheme Precision Recall F1 score
HF1 82.1 71.4 76.4
HF2 81.9 67.0 73.7
PCH 82.5 72.4 77.1
SynCha 76.6 65.3 70.5
</table>
<tableCaption confidence="0.999576">
Table 4: Predicate-argument structure analysis.
</tableCaption>
<bodyText confidence="0.999939150000001">
dobj and iobj) resulted in relatively high scores
in comparison to the temporal (tmod) and locative
(lmod) cases. These types are typically labeled as
belonging to the postpositional phrase consisting
of a noun phrase and particles, and case particles
such as �a “ga”, ;�- “o” and 6,:! “ni” strongly sug-
gest an argument by their combination with verbs,
while particles 6,:! and -C “de” are widely used out-
side the temporal and locative cases.
Predicate-argument structure We ex-
tracted predicate-argument structure informa-
tion as triplets, which are pairs of predicates
and arguments connected by a relation, i.e.
(pred, rel, arg), from the dependency parsing re-
sults by tracing the paths with the argument and
gapped relative clause types. pred in a triplet is
a verb or an adjective, arg is a head noun of an
argument, and rel is nsubj, dobj or iobj.
The gold standard data is built by converting
predicate-argument structures in NAIST Text Cor-
pus (Iida et al., 2007) into the above triples. Ba-
sically, the cases “ga”, “o” and “ni” in the corpus
correspond to “nsubj”, “dobj“ and “iobj”, respec-
tively, however, we should apply the alternative
conversion to passive or causative voice, since the
annotation is based on active voice. The conver-
sion for case alternation was manually done for
each triple. We filtered out the triples including
zero pronouns or arguments without the direct de-
pendencies on their predicates from the converted
triples, finally 6,435 triplets remained.
Table 4 shows the results of comparing the ex-
tracted triples with the gold data. PCH marks the
highest score here in spite of getting the lowest
score in the parsing results. It is assumed that the
characteristics of PCH, where content words tend
to be directly linked, are responsible. The table
also contains the results of the predicate-argument
structure analyzer SynCha. Note that we focus on
only the relations between a predicate and its de-
pendents, while SynCha is designed to deal with
zero anaphora resolution in addition to predicate-
argument structure analysis over syntactic depen-
dencies. Since SynCha uses the syntactic pars-
ing results of CaboCha in a cascaded process, the
parsing error may cause conflict between syntac-
tic structure and predicate-argument structure. A
typical example is that case where a gapped rel-
ative clause modifies a noun phrase A 0) B “B
of A”, e.g., [VP !A_ Ma6 A6f ft [NP S 0) Z
9] “footprints of the cat that escaped from a
garden.” If the noun A is an argument of a main
predicate in a relative clause, the predicate is a de-
pendent of the noun A; however, this is not actu-
ally reliable because two analyses are separately
processed. There are 75 constructions of this type
in the test set; the LUW-based dependency pars-
ing captured 42 correct predicate-argument rela-
tions (and dependencies), while the cascaded pars-
ing was limited to obtaining 6 relations.
</bodyText>
<sectionHeader confidence="0.999449" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999987125">
We proposed a scheme of Japanese typed-
dependency parsing for dealing with constituents
and capturing the grammatical function as a de-
pendency type that bypasses the traditional lim-
itations of bunsetsu-based dependency parsing.
The evaluations demonstrated that a word-based
dependency parser achieves high accuracies that
are comparable to those of a bunsetsu-based de-
pendency parser, and moreover, provides detailed
syntactic information such as predicate-argument
structures. Recently, discussion has begun toward
Universal Dependencies, including Japanese. The
work presented here can be viewed as a feasibility
study of UD for Japanese. We are planning to port
our corpus and compare our scheme with UD to
contribute to the improvement of UD for Japanese.
</bodyText>
<page confidence="0.996778">
241
</page>
<sectionHeader confidence="0.996238" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999799375">
Alastair Butler, Zhen Zhou and Kei Yoshimoto. 2012.
Problems for successful bunsetsu based parsing and
some solutions. In Proceedings of the Eighteenth
Annual Meeting on the Association for Natural Lan-
guage Processing, pp. 951–954.
Marie-Catherine de Marneffe and Christopher D. Man-
ning. 2008. The Stanford typed dependencies rep-
resentation. In Proceedings of COLING 2008 Work-
shop on Cross-framework and Cross-domain Parser
Evaluation.
Marie-Catherine de Marneffe, Natalia Silveira, Tim-
othy Dozat, Katri Haverinen, Filip Ginter, Joakim
Nivre, and Christopher D. Manning. 2014. Uni-
versal Stanford Dependencies: A cross-linguistic ty-
pology. In Proceedings of the Ninth International
Conference on Language Resources and Evaluation
(LREC-2014).
Yasuharu Den, Junpei Nakamura, Toshinobu Ogiso and
Hideki Ogura. 2008. A proper approach to Japanese
morphological analysis: Dictionary, model and eval-
uation. In Proceedings of the Sixth International
Conference on Language Resources and Evaluation
(LREC-2008).
Ryu Iida, Mamoru Komachi, Kentaro Inui and Yuji
Matsumoto. 2007. Annotating a Japanese Text Cor-
pus with Predicate-argument and Coreference Rela-
tions. In Proceedings of the the Linguistic Annota-
tion Workshop (LAW ’07), pp. 132–139.
Ryu Iida and Massimo Poesio. 2011. A Cross-Lingual
ILP Solution to Zero Anaphora Resolution. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies (ACL-HLT 2011), pp. 804-813.
Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai,
Akio Yokoo, Kentaro Ogura, Yoshifumi Ooyama
and Yoshihiko Hayashi. 1998. Nihongo Goitaikei.
Iwanami Shoten, In Japanese.
Daisuke Kawahara and Sadao Kurohashi. 2006. A
fully-lexicalized probabilistic model for Japanese
syntactic and case structure analysis. In Proceedings
of the Human Language Technology Conference of
the North American Chapter of the Association of
Computational Linguistics (HLT-NAACL 2006), pp.
176–183.
Shunsuke Kozawa, Kiyotaka Uchimoto and Yasuharu
Den. 2014. Adaptation of long-unit-word analysis
system to different part-of-speech tagset. In Journal
ofNatural Language Processing, Vol. 21, No. 2, pp.
379–401 (in Japanese).
Taku Kudo, Kaoru Yamamoto and Yuji Matsumoto.
2004. Applying conditional random fields to
Japanese morphological analysis. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing (EMNLP-2004), pp. 230–237.
Taku Kudo and Yuji Matsumoto. 2002. Japanese de-
pendency analysis using cascaded chunking. In Pro-
ceedings ofthe 6th Conference on Natural Language
Learning (CoNLL-2002), Volume 20, pp. 1–7.
Sadao Kurohashi and Makoto Nagao. 2003. Building a
Japanese parsed corpus – while improving the pars-
ing system. In Abeille (ed.), Treebanks: Building
and Using Parsed Corpora, Chap. 14, pp. 249–260.
Kluwer Academic Publishers.
Kikuo Maekawa, Hanae Koiso, Sasaoki Furui, Hitoshi
Isahara. 2000. Spontaneous Speech Corpus of
Japanese. In Proceedings of the Second Interna-
tional Conference on Language Resources and Eval-
uation (LREC-2000), pp. 947–952.
Kikuo Maekawa, Makoto Yamazaki, Toshinobu
Ogiso, Takehiko Maruyama, Hideki Ogura, Wakako
Kashino, Hanae Koiso, Masaya Yamaguchi, Makiro
Tanaka and Yasuharu Den. 2014. Balanced Corpus
of Contemporary Written Japanese. Language Re-
sources and Evaluation, Vol. 48, pp. 345–371.
Ryan McDonald, Joakim Nivre, Yvonne Quirmbach-
Brundage, Yoav Goldberg, Dipanjan Das, Kuzman
Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Os-
car T¨ackstr¨om, Claudia Bedini, N´uria Bertomeu
Castell´o, and Jungmee Lee. 2013. Universal De-
pendency Annotation for Multilingual Parsing. In
Proceedings of the 51st Annual Meeting of the ACL
(ACL 2013).
Shunsuke Mori, Hideki Ogura and Teturo Sasada.
2014. A Japanese word dependency corpus. In Pro-
ceedings of the Ninth International Conference on
Language Resources and Evaluation (LREC-2014),
pp. 753–758.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, G¨uls¸en Eryiˇgit, Sandra K¨ubler, Svetoslav
Marinov and Erwin Marsi. 2007. MaltParser: A
language-independent system for data-driven depen-
dency parsing, In Journal of Natural Language En-
gineering, Vol. 13, No. 2, pp. 95–135.
Takaaki Tanaka and Masaaki Nagata. 2013. Construct-
ing a Practical Constituent Parser from a Japanese
Treebank with Function Labels. In Proceedings
of the Fourth Workshop on Statistical Parsing of
Morphologically-Rich Languages, pp. 108–118.
Kiyotaka Uchimoto and Yasuharu Den. 2008. Word-
level Dependency-structure Annotation to Corpus
of Spontaneous Japanese and its Application. In
Proceedings of the International Conference on
Language Resources and Evaluation (LREC 2008),
pp.3118–3122.
</reference>
<page confidence="0.997688">
242
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.862909">
<title confidence="0.9966155">Word-based Japanese typed dependency parsing with function analysis</title>
<author confidence="0.99854">Takaaki Tanaka Nagata</author>
<affiliation confidence="0.988546">NTT Communication Science Laboratories, NTT</affiliation>
<address confidence="0.942304">2-4, Hikaridai, Seika-cho, Soraku-gun, Kyoto, 619-0237,</address>
<abstract confidence="0.995260826086957">We present a novel scheme for wordbased Japanese typed dependency parser which integrates syntactic structure analysis and grammatical function analysis such as predicate-argument structure analysis. Compared to bunsetsu-based dependency parsing, which is predominantly used in Japanese NLP, it provides a natural way of extracting syntactic constituents, which is useful for downstream applications such as statistical machine translation. It also makes it possible to jointly decide dependency and predicate-argument structure, which is usually implemented as two separate steps. We convert an existing treebank to the new dependency scheme and report parsing results as a baseline for future research. We achieved a better accuracy for assigning function labels than a predicate-argument structure analyzer by using grammatical functions as dependency label.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alastair Butler</author>
<author>Zhen Zhou</author>
<author>Kei Yoshimoto</author>
</authors>
<title>Problems for successful bunsetsu based parsing and some solutions.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eighteenth Annual Meeting on the Association for Natural Language Processing,</booktitle>
<pages>951--954</pages>
<contexts>
<context position="2340" citStr="Butler et al., 2012" startWordPosition="330" endWordPosition="333">erb followed by a sequence of zero or more function words such as auxiliary verbs, postpositional particles, or sentence-final particles. Most publicly available Japanese parsers, including CaboCha 1 (Kudo et al., 2002) and KNP 2 (Kawahara et al., 2006), return bunsetsu-based dependency as syntactic structure. Such parsers are generally highly accurate and have been widely used in various NLP applications. However, bunsetsu-based representations also have two serious shortcomings: one is the discrepancy between syntactic and semantic units, and the other is insufficient syntactic information (Butler et al., 2012; Tanaka et al., 2013). Bunsetsu chunks do not always correspond to constituents (e.g. NP, VP), which complicates the task of extracting semantic units from bunsetsubased representations. This kind of problem often arises in handling such nesting structures as coordinating constructions. For example, there are three dependencies in a sentence (1): a coordinating dependency b2 – b3 and ordinary dependencies b1 – b3 and b3 – b4. In extracting predicate-argument structures, it is not possible to directly extract a coordinated noun phrase 94 /LM “wine and sake” as a direct object of the verb PXlvf</context>
</contexts>
<marker>Butler, Zhou, Yoshimoto, 2012</marker>
<rawString>Alastair Butler, Zhen Zhou and Kei Yoshimoto. 2012. Problems for successful bunsetsu based parsing and some solutions. In Proceedings of the Eighteenth Annual Meeting on the Association for Natural Language Processing, pp. 951–954.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Christopher D Manning</author>
</authors>
<title>The Stanford typed dependencies representation.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING 2008 Workshop on Cross-framework and Cross-domain Parser Evaluation.</booktitle>
<marker>de Marneffe, Manning, 2008</marker>
<rawString>Marie-Catherine de Marneffe and Christopher D. Manning. 2008. The Stanford typed dependencies representation. In Proceedings of COLING 2008 Workshop on Cross-framework and Cross-domain Parser Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Natalia Silveira</author>
<author>Timothy Dozat</author>
<author>Katri Haverinen</author>
<author>Filip Ginter</author>
<author>Joakim Nivre</author>
<author>Christopher D Manning</author>
</authors>
<title>Universal Stanford Dependencies: A cross-linguistic typology.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014).</booktitle>
<marker>de Marneffe, Silveira, Dozat, Haverinen, Ginter, Nivre, Manning, 2014</marker>
<rawString>Marie-Catherine de Marneffe, Natalia Silveira, Timothy Dozat, Katri Haverinen, Filip Ginter, Joakim Nivre, and Christopher D. Manning. 2014. Universal Stanford Dependencies: A cross-linguistic typology. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yasuharu Den</author>
<author>Junpei Nakamura</author>
</authors>
<title>Toshinobu Ogiso and Hideki Ogura.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC-2008).</booktitle>
<marker>Den, Nakamura, 2008</marker>
<rawString>Yasuharu Den, Junpei Nakamura, Toshinobu Ogiso and Hideki Ogura. 2008. A proper approach to Japanese morphological analysis: Dictionary, model and evaluation. In Proceedings of the Sixth International Conference on Language Resources and Evaluation (LREC-2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Mamoru Komachi</author>
<author>Kentaro Inui</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Annotating a Japanese Text Corpus with Predicate-argument and Coreference Relations.</title>
<date>2007</date>
<booktitle>In Proceedings of the the Linguistic Annotation Workshop (LAW ’07),</booktitle>
<pages>132--139</pages>
<contexts>
<context position="16616" citStr="Iida et al., 2007" startWordPosition="2705" endWordPosition="2708">s, while particles 6,:! and -C “de” are widely used outside the temporal and locative cases. Predicate-argument structure We extracted predicate-argument structure information as triplets, which are pairs of predicates and arguments connected by a relation, i.e. (pred, rel, arg), from the dependency parsing results by tracing the paths with the argument and gapped relative clause types. pred in a triplet is a verb or an adjective, arg is a head noun of an argument, and rel is nsubj, dobj or iobj. The gold standard data is built by converting predicate-argument structures in NAIST Text Corpus (Iida et al., 2007) into the above triples. Basically, the cases “ga”, “o” and “ni” in the corpus correspond to “nsubj”, “dobj“ and “iobj”, respectively, however, we should apply the alternative conversion to passive or causative voice, since the annotation is based on active voice. The conversion for case alternation was manually done for each triple. We filtered out the triples including zero pronouns or arguments without the direct dependencies on their predicates from the converted triples, finally 6,435 triplets remained. Table 4 shows the results of comparing the extracted triples with the gold data. PCH m</context>
</contexts>
<marker>Iida, Komachi, Inui, Matsumoto, 2007</marker>
<rawString>Ryu Iida, Mamoru Komachi, Kentaro Inui and Yuji Matsumoto. 2007. Annotating a Japanese Text Corpus with Predicate-argument and Coreference Relations. In Proceedings of the the Linguistic Annotation Workshop (LAW ’07), pp. 132–139.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryu Iida</author>
<author>Massimo Poesio</author>
</authors>
<title>A Cross-Lingual ILP Solution to Zero Anaphora Resolution.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT</booktitle>
<pages>804--813</pages>
<marker>Iida, Poesio, 2011</marker>
<rawString>Ryu Iida and Massimo Poesio. 2011. A Cross-Lingual ILP Solution to Zero Anaphora Resolution. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies (ACL-HLT 2011), pp. 804-813.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Satoru Ikehara</author>
</authors>
<title>Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Kentaro Ogura, Yoshifumi Ooyama and Yoshihiko Hayashi.</title>
<date>1998</date>
<marker>Ikehara, 1998</marker>
<rawString>Satoru Ikehara, Masahiro Miyazaki, Satoshi Shirai, Akio Yokoo, Kentaro Ogura, Yoshifumi Ooyama and Yoshihiko Hayashi. 1998. Nihongo Goitaikei. Iwanami Shoten, In Japanese.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daisuke Kawahara</author>
<author>Sadao Kurohashi</author>
</authors>
<title>A fully-lexicalized probabilistic model for Japanese syntactic and case structure analysis.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL</booktitle>
<pages>176--183</pages>
<marker>Kawahara, Kurohashi, 2006</marker>
<rawString>Daisuke Kawahara and Sadao Kurohashi. 2006. A fully-lexicalized probabilistic model for Japanese syntactic and case structure analysis. In Proceedings of the Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics (HLT-NAACL 2006), pp. 176–183.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shunsuke Kozawa</author>
<author>Kiyotaka Uchimoto</author>
<author>Yasuharu Den</author>
</authors>
<title>Adaptation of long-unit-word analysis system to different part-of-speech tagset.</title>
<date>2014</date>
<booktitle>In Journal ofNatural Language Processing,</booktitle>
<volume>21</volume>
<pages>379--401</pages>
<note>(in Japanese).</note>
<contexts>
<context position="12892" citStr="Kozawa et al., 2014" startWordPosition="2073" endWordPosition="2076">00 sentences from newspaper articles, and from these 17,953 sentences have been re-annotated. The treebank is designed to have complete binary trees, which can be easily converted to dependency trees by adapting head rules and dependency-type rules for each partial tree. We divided this corpus into 15,953 sentences (339,573 LUWs) for the training set and 2,000 sentences (41,154 LUWs) for the test set. 4.2 Parser and features In the analysis process, sentences are first tokenized into SUW and tagged with SUW POS by the morphological analyzer MeCab (Kudo et al., 2004). The LUW analyzer Comainu (Kozawa et al., 2014) chunks the SUW sequences into LUW sequences. We used the MaltParser (Nivre et al., 2007), which marked over 81 % in labeled attachment score (LAS), for English SD. Stack algorithm (projective) and LIBLINEAR were chosen as the parsing algorithm and the learner, respectively. We built and tested the three types of parsing models with the three dependency schemes. Features of the parsing model are made by combining word attributes as shown in Table 2. We employed SUW-based attributes as well as LUW-based attributes because LUW contains many multiword expressions such as compound nouns, and featu</context>
</contexts>
<marker>Kozawa, Uchimoto, Den, 2014</marker>
<rawString>Shunsuke Kozawa, Kiyotaka Uchimoto and Yasuharu Den. 2014. Adaptation of long-unit-word analysis system to different part-of-speech tagset. In Journal ofNatural Language Processing, Vol. 21, No. 2, pp. 379–401 (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Kaoru Yamamoto</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Applying conditional random fields to Japanese morphological analysis.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2004),</booktitle>
<pages>230--237</pages>
<contexts>
<context position="12844" citStr="Kudo et al., 2004" startWordPosition="2065" endWordPosition="2068">he Kyoto corpus consists of approximately 40,000 sentences from newspaper articles, and from these 17,953 sentences have been re-annotated. The treebank is designed to have complete binary trees, which can be easily converted to dependency trees by adapting head rules and dependency-type rules for each partial tree. We divided this corpus into 15,953 sentences (339,573 LUWs) for the training set and 2,000 sentences (41,154 LUWs) for the test set. 4.2 Parser and features In the analysis process, sentences are first tokenized into SUW and tagged with SUW POS by the morphological analyzer MeCab (Kudo et al., 2004). The LUW analyzer Comainu (Kozawa et al., 2014) chunks the SUW sequences into LUW sequences. We used the MaltParser (Nivre et al., 2007), which marked over 81 % in labeled attachment score (LAS), for English SD. Stack algorithm (projective) and LIBLINEAR were chosen as the parsing algorithm and the learner, respectively. We built and tested the three types of parsing models with the three dependency schemes. Features of the parsing model are made by combining word attributes as shown in Table 2. We employed SUW-based attributes as well as LUW-based attributes because LUW contains many multiwo</context>
</contexts>
<marker>Kudo, Yamamoto, Matsumoto, 2004</marker>
<rawString>Taku Kudo, Kaoru Yamamoto and Yuji Matsumoto. 2004. Applying conditional random fields to Japanese morphological analysis. In Proceedings of the Conference on Empirical Methods in Natural Language Processing (EMNLP-2004), pp. 230–237.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Japanese dependency analysis using cascaded chunking.</title>
<date>2002</date>
<booktitle>In Proceedings ofthe 6th Conference on Natural Language Learning (CoNLL-2002),</booktitle>
<volume>20</volume>
<pages>1--7</pages>
<marker>Kudo, Matsumoto, 2002</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2002. Japanese dependency analysis using cascaded chunking. In Proceedings ofthe 6th Conference on Natural Language Learning (CoNLL-2002), Volume 20, pp. 1–7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<title>Building a Japanese parsed corpus – while improving the parsing system.</title>
<date>2003</date>
<booktitle>In Abeille (ed.), Treebanks: Building and Using Parsed Corpora, Chap. 14,</booktitle>
<pages>249--260</pages>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Kurohashi, Nagao, 2003</marker>
<rawString>Sadao Kurohashi and Makoto Nagao. 2003. Building a Japanese parsed corpus – while improving the parsing system. In Abeille (ed.), Treebanks: Building and Using Parsed Corpora, Chap. 14, pp. 249–260. Kluwer Academic Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kikuo Maekawa</author>
</authors>
<title>Hanae Koiso, Sasaoki Furui, Hitoshi Isahara.</title>
<date>2000</date>
<booktitle>In Proceedings of the Second International Conference on Language Resources and Evaluation (LREC-2000),</booktitle>
<pages>947--952</pages>
<marker>Maekawa, 2000</marker>
<rawString>Kikuo Maekawa, Hanae Koiso, Sasaoki Furui, Hitoshi Isahara. 2000. Spontaneous Speech Corpus of Japanese. In Proceedings of the Second International Conference on Language Resources and Evaluation (LREC-2000), pp. 947–952.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kikuo Maekawa</author>
<author>Makoto Yamazaki</author>
</authors>
<title>Toshinobu Ogiso, Takehiko Maruyama, Hideki Ogura, Wakako Kashino, Hanae Koiso,</title>
<date>2014</date>
<journal>Balanced Corpus of Contemporary Written Japanese. Language Resources and Evaluation,</journal>
<volume>48</volume>
<pages>345--371</pages>
<location>Masaya Yamaguchi, Makiro Tanaka</location>
<marker>Maekawa, Yamazaki, 2014</marker>
<rawString>Kikuo Maekawa, Makoto Yamazaki, Toshinobu Ogiso, Takehiko Maruyama, Hideki Ogura, Wakako Kashino, Hanae Koiso, Masaya Yamaguchi, Makiro Tanaka and Yasuharu Den. 2014. Balanced Corpus of Contemporary Written Japanese. Language Resources and Evaluation, Vol. 48, pp. 345–371.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria Bertomeu Castell´o, and</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the ACL</booktitle>
<marker>McDonald, Nivre, 2013</marker>
<rawString>Ryan McDonald, Joakim Nivre, Yvonne QuirmbachBrundage, Yoav Goldberg, Dipanjan Das, Kuzman Ganchev, Keith Hall, Slav Petrov, Hao Zhang, Oscar T¨ackstr¨om, Claudia Bedini, N´uria Bertomeu Castell´o, and Jungmee Lee. 2013. Universal Dependency Annotation for Multilingual Parsing. In Proceedings of the 51st Annual Meeting of the ACL (ACL 2013).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shunsuke Mori</author>
</authors>
<title>Hideki Ogura and Teturo Sasada.</title>
<date>2014</date>
<booktitle>In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014),</booktitle>
<pages>753--758</pages>
<marker>Mori, 2014</marker>
<rawString>Shunsuke Mori, Hideki Ogura and Teturo Sasada. 2014. A Japanese word dependency corpus. In Proceedings of the Ninth International Conference on Language Resources and Evaluation (LREC-2014), pp. 753–758.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Atanas Chanev, G¨uls¸en Eryiˇgit, Sandra K¨ubler, Svetoslav Marinov and Erwin Marsi.</title>
<date>2007</date>
<journal>In Journal of Natural Language Engineering,</journal>
<volume>13</volume>
<pages>95--135</pages>
<contexts>
<context position="12981" citStr="Nivre et al., 2007" startWordPosition="2088" endWordPosition="2091">ed. The treebank is designed to have complete binary trees, which can be easily converted to dependency trees by adapting head rules and dependency-type rules for each partial tree. We divided this corpus into 15,953 sentences (339,573 LUWs) for the training set and 2,000 sentences (41,154 LUWs) for the test set. 4.2 Parser and features In the analysis process, sentences are first tokenized into SUW and tagged with SUW POS by the morphological analyzer MeCab (Kudo et al., 2004). The LUW analyzer Comainu (Kozawa et al., 2014) chunks the SUW sequences into LUW sequences. We used the MaltParser (Nivre et al., 2007), which marked over 81 % in labeled attachment score (LAS), for English SD. Stack algorithm (projective) and LIBLINEAR were chosen as the parsing algorithm and the learner, respectively. We built and tested the three types of parsing models with the three dependency schemes. Features of the parsing model are made by combining word attributes as shown in Table 2. We employed SUW-based attributes as well as LUW-based attributes because LUW contains many multiword expressions such as compound nouns, and features combining LUW-based attributes tend to be sparse. The SUW-based attributes are extrac</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, G¨uls¸en Eryiˇgit, Sandra K¨ubler, Svetoslav Marinov and Erwin Marsi. 2007. MaltParser: A language-independent system for data-driven dependency parsing, In Journal of Natural Language Engineering, Vol. 13, No. 2, pp. 95–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takaaki Tanaka</author>
<author>Masaaki Nagata</author>
</authors>
<title>Constructing a Practical Constituent Parser from a Japanese Treebank with Function Labels.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>108--118</pages>
<marker>Tanaka, Nagata, 2013</marker>
<rawString>Takaaki Tanaka and Masaaki Nagata. 2013. Constructing a Practical Constituent Parser from a Japanese Treebank with Function Labels. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pp. 108–118.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyotaka Uchimoto</author>
<author>Yasuharu Den</author>
</authors>
<title>Wordlevel Dependency-structure Annotation to Corpus of Spontaneous Japanese and its Application.</title>
<date>2008</date>
<booktitle>In Proceedings of the International Conference on Language Resources and Evaluation (LREC 2008),</booktitle>
<pages>3118--3122</pages>
<marker>Uchimoto, Den, 2008</marker>
<rawString>Kiyotaka Uchimoto and Yasuharu Den. 2008. Wordlevel Dependency-structure Annotation to Corpus of Spontaneous Japanese and its Application. In Proceedings of the International Conference on Language Resources and Evaluation (LREC 2008), pp.3118–3122.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>