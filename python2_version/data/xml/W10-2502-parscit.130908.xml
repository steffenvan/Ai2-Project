<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.9992715">
A Decoder for
Probabilistic Synchronous Tree Insertion Grammars
</title>
<author confidence="0.88344">
Steve DeNeefe * and Kevin Knight *
</author>
<affiliation confidence="0.841343">
USC Information Sciences Institute
</affiliation>
<address confidence="0.789854">
4676 Admiralty Way
Marina del Rey, CA 90292, USA
</address>
<email confidence="0.99563">
{sdeneefe,knight}@isi.edu
</email>
<author confidence="0.893958">
Heiko Vogler †
</author>
<affiliation confidence="0.913136">
Department of Computer Science
Technische Universit¨at Dresden
</affiliation>
<address confidence="0.523545">
D-01062 Dresden
</address>
<email confidence="0.573018">
Heiko.Vogler@tu-dresden.de
</email>
<sectionHeader confidence="0.983563" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998944875">
Synchronous tree insertion grammars
(STIG) are formal models for syntax-
based machine translation. We formal-
ize a decoder for probabilistic STIG; the
decoder transforms every source-language
string into a target-language tree and cal-
culates the probability of this transforma-
tion.
</bodyText>
<sectionHeader confidence="0.998429" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999966230769231">
Tree adjoining grammars (TAG) were invented in
(Joshi et al. 1975) in order to better character-
ize the string sets of natural languages1. One of
TAG’s important features is the ability to introduce
two related syntactic units in a single rule, then
push those two units arbitrarily far apart in sub-
sequent derivation steps. For machine translation
(MT) between two natural languages, each being
generated by a TAG, the derivations of the two
TAG may be synchronized (Abeille et al., 1990;
Shieber and Shabes, 1990) in the spirit of syntax-
directed transductions (Lewis and Stearns, 1968);
this results in synchronous TAG (STAG). Recently,
in (Nesson et al., 2005, 2006) probabilistic syn-
chronous tree insertion grammars (pSTIG) were
discussed as model of MT; a tree insertion gram-
mar is a particular TAG in which the parsing prob-
lem is solvable in cubic-time (Schabes and Wa-
ters, 1994). In (DeNeefe, 2009; DeNeefe and
Knight 2009) a decoder for pSTIG has been pro-
posed which transforms source-language strings
into (modifications of) derivation trees of the
pSTIG. Nowadays, large-scale linguistic STAG
rule bases are available.
In an independent tradition, the automata-
theoretic investigation of the translation of trees
</bodyText>
<footnote confidence="0.681632">
∗ financially supported by NSF STAGES project, grant
#IIS-0908532.
† financially supported by DFG VO 1011/5-1.
1see (Joshi and Shabes, 1997) for a survey
</footnote>
<bodyText confidence="0.999815266666667">
led to the rich theory of tree transducers (G´ecseg
and Steinby, 1984, 1997). Roughly speaking, a
tree transducer is a finite term rewriting system. If
each rewrite rule carries a probablity or, in gen-
eral, a weight from some semiring, then they are
weighted tree transducers (Maletti, 2006, 2006a;
F¨ul¨op and Vogler, 2009). Such weighted tree
transducers have also been used for the specifi-
cation of MT of natural languages (Yamada and
Knight, 2001; Knight and Graehl, 2005; Graehl et
al., 2008; Knight and May 2009).
Martin and Vere (1970) and Schreiber (1975)
established the first connections between the two
traditions; also Shieber (2004, 2006) and Maletti
(2008, 2010) investigated their relationship.
The problem addressed in this paper is the
decoding of source-language strings into target-
language trees where the transformation is de-
scribed by a pSTIG. Currently, this decoding re-
quires two steps: first, every source string is
translated into a derivation tree of the underly-
ing pSTIG (DeNeefe, 2009; DeNeefe and Knight
2009), and second, the derivation tree is trans-
formed into the target tree using an embedded tree
transducer (Shieber, 2006). We propose a trans-
ducer model, called a bottom-up tree adjoining
transducer, which performs this decoding in a sin-
gle step and, simultaneously, computes the prob-
abilities of its derivations. As a basis of our ap-
proach, we present a formal definition of pSTIG.
</bodyText>
<sectionHeader confidence="0.993908" genericHeader="introduction">
2 Preliminaries
</sectionHeader>
<bodyText confidence="0.999881222222222">
For two sets E and A, we let UE(A) be the set of
all (unranked) trees over E in which also elements
of A may label leaves. We abbreviate UE(∅) by
UE. We denote the set of positions, leaves, and
non-leaves of � E UE by pos(�) C N*, lv(�), and
nlv(�), resp., where E denotes the root of � and
w�i denotes the ith child of position w; nlv(0 =
pos(�) \ lv(�). For a position w E pos(�), the la-
bel of � at w (resp., subtree of � at w) is denoted
</bodyText>
<page confidence="0.987195">
10
</page>
<note confidence="0.989224">
Proceedings of the 2010 Workshop on Applications of Tree Automata in Natural Language Processing, ACL 2010, pages 10–18,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.997073">
a
/3
St
B
a
B↓ /3
a
⇐⇒ ��
Se
a A↓ A
</figure>
<equation confidence="0.962198933333333">
P(r1) = 1
P��
���(a) = .9
eB B,
6
P(r2) = .4
P��
���(b) = .2
P��
���(c) = .6
P(r3) = .6
P��
���(d) = .3
P��
, ���(e) = .8
</equation>
<figure confidence="0.963502642857143">
b
B
Ab,.
⇐⇒��
A �
,
B
d,e
Ad
A A
, e
A
⇐⇒ ��
µ B
</figure>
<bodyText confidence="0.997924272727273">
by �(w) (resp., �|w). If additionally ( ∈ UE(A),
then�[(]w denotes the tree which is obtained from
� by replacing its subtree at w by (. For every
A ⊆ E ∪ A, the set poso(�) is the set of all those
positions w ∈ pos(�) such that �(w) ∈ A. Simi-
larly, we can define lvo(�) and nlvo(�). The yield
of � is the sequence yield(ξ) ∈ (E ∪ A)∗ of sym-
bols that label the leaves from left to right.
If we associate with a ∈ E a rank k ∈ N, then
we require that in every tree � ∈ UE(A) every a-
labeled position has exactly k children.
</bodyText>
<sectionHeader confidence="0.841459" genericHeader="method">
3 Probabilistic STAG and STIG
</sectionHeader>
<bodyText confidence="0.9825476">
First we will define probabilistic STAG, and sec-
ond, as a special case, probabilistic STIG.
Let N and T be two disjoint sets of, resp., non-
terminals and terminals. A substitution rule r is a
tuple ((s, (t, V, W, Pr�dj) where
</bodyText>
<listItem confidence="0.9870041875">
• (s, (t ∈ UN(T) (source and target tree) and
|lvN((s) |= |lvN((t)|,
• V ⊆ lvN((s)×lvN((t) (substitution sites), V
is a one-to-one relation, and |V  |= |lvN((s)|,
• W ⊆ nlvN((s)×nlvN((t) (potential adjoin-
ing sites), and
• Pr�dj : W → [0, 1] (adjoining probability).
An auxiliary rule r is a tuple ((s, (t, V, W, ∗, Pr�dj)
where (s, (t, W, and Pradj are defined as above and
• V is defined as above except that |V  |=
|lvN((s) |− 1 and
• ∗ = (∗s, ∗t) ∈ lvN((s) × lvN((t) and neither
∗s nor ∗t occurs in any element of V ; more-
over, (s(E) = (s(∗s) and (t(E) = (t(∗t), and
∗s =6 E =6 ∗t; the node ∗s (and ∗t) is called
the foot-node of (s (resp., (t).
</listItem>
<bodyText confidence="0.986211545454545">
An (elementary) rule is either a substitution rule
or an auxiliary rule. The root-category of a rule r
is the tuple ((s(E), (t(E)), denoted by rc(r).
A probabilistic synchronous tree ad-
joining grammar (pSTAG) is a tuple
G = (N, T, (Ss, St), S, A, P) such that N
and T are two disjoint sets (resp., of nonterminals
and terminals), (Ss, St) ∈ N ×N (start nontermi-
nal), S and A are finite sets of, resp., substitution
rules and auxiliary rules, and P : S ∪ A → [0, 1]
such that for every (A, B) ∈ N × N,
</bodyText>
<equation confidence="0.998097666666667">
� P(r) = 1 and � P(r) = 1
rES rEA
rc(r)=(A,B) rc(r)=(A,B)
</equation>
<bodyText confidence="0.978064">
assuming that in each case the number of sum-
mands is not zero. In the following, let G always
denote an arbitrary pSTAG.
</bodyText>
<figure confidence="0.9391805">
A B
⇐⇒ �� P(r4) = .1
a /3
A B
⇐⇒�� P(r5) = .9
7 6
</figure>
<figureCaption confidence="0.99999">
Figure 1: The running example pSTAG G.
</figureCaption>
<bodyText confidence="0.99795275">
In Fig. 1 we show the rules of our running ex-
ample pSTAG, where the capital Roman letters are
the nonterminals and the small Greek letters are
the terminals. The substitution site (in rule r1) is
indicated by ↓, and the potential adjoining sites are
denoted2 by a, b, c, d, and e. For instance, in for-
mal notation the rules r1 and r2 are written as fol-
lows:
</bodyText>
<equation confidence="0.997373">
r1 = (S3(a, A, A(a)), St(B(Q), B, Q), {11, {a1, P��
��j)
</equation>
<bodyText confidence="0.505787">
where ↓ = (2, 2) and a = (3, 1), and
</bodyText>
<equation confidence="0.995104">
r2 = (A(A, -y), B(B(S), B), 0, {b, c1, *, P��
��j)
</equation>
<bodyText confidence="0.993789">
where b = (E, E), c = (E, 1), and ∗ = (1, 2).
In the derivation relation of G we will distin-
guish four types of steps:
</bodyText>
<listItem confidence="0.99196975">
1. substitution of a rule at a substitution site
(substitution),
2. deciding to turn a potential adjoining site into
an activated adjoining site (activation),
3. deciding to drop a potential adjoining site,
i.e., not to adjoin, (non-adjoining) and
4. adjoining of a rule at an activated adjoining
site (adjoining).
</listItem>
<bodyText confidence="0.948696166666667">
In the sentential forms (defined below) we will
maintain for every adjoining site w a two-valued
flag g(w) indicating whether w is a potential
(g(w) = p) or an activated site (g(w) = a).
The set ofsententialforms of G is the set SF(G)
of all tuples r. = (�s, fit, V, W, g) with
</bodyText>
<footnote confidence="0.9997625">
2Their placement (as left or right index) does not play a
role yet, but will later when we introduce pSTIG.
</footnote>
<page confidence="0.998707">
11
</page>
<listItem confidence="0.9995868">
• ξs, ξt E UN(T),
• V C_ lvN(ξs) x lvN(ξt) is a one-to-one rela-
tion, |V  |= |lvN(ξs) |= |lvN(ξt)|,
• W C_ nlvN(ξs) x nlvN(ξt), and
• g : W —* {p, a}.
</listItem>
<bodyText confidence="0.8796108">
The derivation relation (of G) is the binary
relation ==&gt;&apos; C_ SF(G) x SF(G) such that
for every κ1 = (ξ1s, ξ1t , V1, W1, g1) and κ2 =
(ξ2s, ξ2t , V2, W2, g2) we have κ1 ==&gt;&apos; κ2 iff one of
the following is true:
</bodyText>
<listItem confidence="0.7628495">
1. (substitution) there are w = (ws, wt) E V1
and r = (ζs, ζt, V, W, Pr
</listItem>
<equation confidence="0.959137">
adj) E S such that
– (ξ1 s(ws), ξ1 t (wt)) = rc(r),
– ξ2 s = ξ1 s[ζs]ws and ξ2t = ξ1t [ζt]wt,
– V2 = (V1 \ {w}) U w.V ,3
– W2 = W1 U w.W, and
– g2 is the union of g1 and the set of pairs
(w.u, p) for every u E W;
w,r
</equation>
<bodyText confidence="0.70509">
this step is denoted by κ1 ===&gt;&apos; κ2;
</bodyText>
<listItem confidence="0.975952">
2. (activation) there is a w E W1 with g1(w) =
p and (ξ1s,ξ1t ,V1,W1) = (ξ2 s,ξ2 t ,V2,W2),
and g2 is the same as g1 except that g2(w) =
a; this step is denoted by κ1 ===&gt;&apos; κ2;
w
3. (non-adjoining) there is w E W1 with
g1(w) = p and (ξ1s,ξ1t ,V1) = (ξ2s, ξ2t , V2),
W2 = W1 \ {w}, and g2 is g1 restricted to
W2; this step is denoted by κ1 ===&gt;&apos; κ2;
—w
4. (adjoining) there are w E W1 with g1(w) =
a, and r = (ζs, ζt, V, W, *, Pradj) E A such
that, for w = (ws, wt),
</listItem>
<equation confidence="0.99682275">
– (ξ1s(ws), ξ1t (wt)) = rc(r),
– ξ2s = ξ1 s[ζ′ s]ws where ζ′s = ζs[ξ1s|ws]*s,
ξ2t = ξ1t [ζ′t]wt where ζ′t = ζt[ξ1t |wt]*t,
– V2 is the smallest set such that (i) for
</equation>
<bodyText confidence="0.978324357142857">
every (us, ut) E V1 we have (u′s, u′t) E V2
where
_ r us if ws is not a prefix of us,
u′s S ws. *s .u if us = ws.u for some u;
and u′t is obtained in the same way from ut,
wt, and *t, and (ii) V2 contains w.V ;
– W2 is the smallest set such that (i) for every
(us, ut) E W1 \ {w} we have (u′s, u′t) E
W2 where u′s and u′t are obtained in the
same way as for V2, and g2(u′s,u′t) =
g1(us, ut) and (ii) W2 contains w.W and
g2(w.u) = p for every u E W;
w,r
this step is denoted by κ1 ===&gt;&apos; κ2.
</bodyText>
<equation confidence="0.967967">
3w.V = {(ws.vs, wt.vt)  |(vs, vt) E V }
</equation>
<bodyText confidence="0.99983975">
In Fig. 2 we show a derivation of our running
example pSTAG where activated adjoining sites
are indicated by surrounding circles, the other ad-
joining sites are potential.
</bodyText>
<equation confidence="0.975684285714286">
Ss1 St1
substitution of=P(r1) = 1
r1 at (ε, ε)
Ss
α A1 A
α
substitution of
P(r4) = .1
r4 at (2, 2)
==&gt;&apos;=
adjoining of
P(r2) = .4
r2 at a = (3, 1)
==&gt;&apos;=
</equation>
<figure confidence="0.920481704545455">
Ss
α A
�==&gt;&apos;
β
δ β
==&gt;&apos;=
non-adjoining 1 − Pr�
���(c) = .4
at c = (3, 1.1)
Ss
α A
�==&gt;&apos;
β
δ β
==&gt;&apos;=
non-adjoining 1 − Pr�
���(b) = .8
at b = (3, 1)
Ss
α A
�==&gt;&apos;
B B β
δ β
β
B
α
α
β
β
activation=Pa�(a) = .9
at a = (3, 1)
Ss
α A
Aa
�==&gt;&apos;
B
St
a
a
�==&gt;&apos;
B
β
Ss
α A
α
Aa
α
β
β
St
B
St
a
B1 β
a
�==&gt;&apos;
B
β
α
A
γ
α
Ab,c
c
B
B
St
b
B
B
β
St
α A γ
α
Ab
B
B
b
B
B
β
St
α A
α
A
γ
B B
β
</figure>
<figureCaption confidence="0.990874">
Figure 2: An example derivation with total proba-
bility 1 x .1 x .9 x .4 x .4 x .8 = .01152.
</figureCaption>
<bodyText confidence="0.998715571428571">
The only initial sentential form is κin =
(Ss, St, {(ε, ε)}, 0, 0). A sentential form κ is final
if it has the form (ξs, ξt, 0, 0, 0). Let κ E SF(G).
A derivation (of κ) is a sequence d of the form
κ0u1κ1 ... unκn with κ0 = κin and n &gt; 0,
==&gt;&apos; κi for every 1 G i G n (and κn = κ). We
ui
</bodyText>
<page confidence="0.8697485">
κi−1
12
</page>
<bodyText confidence="0.9997611875">
denote κn also by last(d), and the set of all deriva-
tions of κ (resp., derivations) by D(κ) (resp., D).
We call d E D successful if last(d) is final.
The tree transformation computed by G is
the relation τG C_ UN(T) x UN(T) with
(ξs, ξt) E τG iff there is a successful derivation
of (ξs, ξt, 0, 0, 0).
Our definition of the probability of a deriva-
tion is based on the following observation.4 Let
d E D(κ) for some κ = (ξs, ξt, V, W, g). Then,
for every w E W, the rule which created w and
the corresponding local position in that rule can
be retrieved from d. Let us denote this rule by
r(d, κ, w) and the local position by l(d, κ, w).
Now let d be the derivation κ0u1κ1 ... unκn.
Then the probability of d is defined by
</bodyText>
<equation confidence="0.839373090909091">
Pd(κi−1 � κi)
u�
where
w,r
1. (substitution) Pd(κi−1 =� κi) = P(r)
2. (activation)
Pd(κi−1 =� κi) = Pr′
w adj(w′) where r′ =
r(d, κi−1, w) and w′ = l(d, κi−1, w)
3. (non-adjoining)
Pd(κi−1 =� κi) = 1 − Pr′
</equation>
<bodyText confidence="0.803186">
¬w adj(w′) where r′
and w′ are defined as in the activation case
</bodyText>
<listItem confidence="0.585912">
4. (adjoining)
</listItem>
<equation confidence="0.8849125">
w,r
Pd(κi−1 =� κi) = P(r).
</equation>
<bodyText confidence="0.99997215">
In order to describe the generative model of
G, we impose a deterministic strategy sel on the
derivation relation in order to obtain, for every
sentential form, a probability distribution among
the follow-up sentential forms. A deterministic
derivation strategy is a mapping sel : SF(G) —*
(N∗ x N∗) U {1} such that for every κ =
(ξs, ξt, V, W, g) E SF(G), we have that sel(κ) E
V U W if V U W =� 0, and sel(κ) = 1 otherwise.
In other words, sel chooses the next site to operate
on. Then we define in the same way as ==�- but
in each of the cases we require that w = sel(κ1).
Moreover, for every derivation d E D, we denote
by next(d) the set of all derivations of the form
duκ where last(d) =u=&gt;sel κ.
The generative model of G comprises all the
generative stories of G. A generative story is a
tree t E UD; the root of t is labeled by κin. Let
w E pos(t) and t(w) = d. Then either w is a
leaf, because we have stopped the generative story
</bodyText>
<footnote confidence="0.9517415">
4We note that a different definition occurs in (Nesson et
al., 2005, 2006).
</footnote>
<bodyText confidence="0.9989418">
at w, or w has |next(d) |children, each one repre-
sents exactly one possible decision about how to
extend d by a single derivation step (where their
order does not matter). Then, for every generative
story t, we have that
</bodyText>
<equation confidence="0.994139">
� P(t(w)) = 1 .
w∈lv(t)
</equation>
<bodyText confidence="0.999462666666667">
We note that (D, next, µ) can be considered as
a discrete Markov chain (cf., e.g. (Baier et al.,
2009)) where the initial probability distribution
µ : D —* [0, 1] maps d = κin to 1, and all the
other derivations to 0.
A probabilistic synchronous tree insertion
grammar (pSTIG) G is a pSTAG except that
for every rule r = (ζs, ζt, V, W, Pradj) or r =
(ζs, ζt, V, W, *, Pradj) we have that
</bodyText>
<listItem confidence="0.966043071428571">
• if r E A, then |lv(ζs) |&gt; 2 and |lv(ζt) |&gt; 2,
• for * = (*s, *t) we have that *s is either the
rightmost leaf of ζs or its leftmost one; then
we call r, resp., L-auxiliary in the source and
R-auxiliary in the source; similarly, we re-
strict *t; the source-spine of r (target-spine
of r) is the set of prefixes of *s (resp., of *t)
• W C_ nlvN(ζs)x{L, R}xnlvN(ζt)x{L, R}
where the new components are the direction-
type of the potential adjoining site, and
• for every (ws, δs, wt, δt) E W, if ws lies on
the source-spine of r and r is L-auxiliary (R-
auxiliary) in the source, then δs = L (resp.,
δs = R), and corresponding restrictions hold
</listItem>
<bodyText confidence="0.947284">
for the target component.
According to the four possibilities for the foot-
node * we call r LL-, LR-, RL-, or RR-auxiliary.
The restriction for the probability distribution P of
G is modified such that for every (A, B) E N xN
and x, y E {L, R}:
</bodyText>
<equation confidence="0.985209">
P(r) = 1 .
r∈A, rc(r)=(A,B)
r is xy−auxiliary
</equation>
<bodyText confidence="0.9999667">
In the derivation relation of the pSTIG G we
will have to make sure that the direction-type of
the chosen adjoining site w matches with the type
of auxiliarity of the auxiliary rule. Again we as-
sume that the data structure SF(G) is enriched
such that for every potential adjoining site w of
κ E SF(G) we know its direction-type dir(w).
We define the derivation relation of the pSTIG
G to be the binary relation ==&gt;.I C_ SF(G)xSF(G)
such that we have κ1 ==�&apos;I κ2 iff (i) κ1 ==�&apos; κ2 and
</bodyText>
<equation confidence="0.977577">
P(d) = �
1≤i≤n
</equation>
<page confidence="0.974942">
13
</page>
<bodyText confidence="0.9976362">
(ii) if adjoining takes place at w, then the used aux-
iliary rule must be dir(w)-auxiliary. Since ⇒I is
a subset of ⇒, the concepts of derivation, success-
ful derivation, and tree transformation are defined
also for a pSTIG.
In fact, our running example pSTAG in Fig. 1 is
a pSTIG, where r2 and r3 are RL-auxiliary and
every potential adjoining site has direction-type
RL; the derivation shown in Fig. 2 is a pSTIG-
derivation.
</bodyText>
<sectionHeader confidence="0.958693" genericHeader="method">
4 Bottom-up tree adjoining transducer
</sectionHeader>
<bodyText confidence="0.999054193548387">
Here we introduce the concept of a bottom-up tree
adjoining transducer (BUTAT) which will be used
to formalize a decoder for a pSTIG.
A BUTAT is a finite-state machine which trans-
lates strings into trees. The left-hand side of each
rule is a string over terminal symbols and state-
variable combinations. A variable is either a sub-
stitution variable or an adjoining variable; a substi-
tution variable (resp., adjoining variable) can have
an output tree (resp., output tree with foot node) as
value. Intuitively, each variable value is a transla-
tion of the string that has been reduced to the cor-
responding state. The right-hand side of a rule has
the form q(ζ) where q is a state and ζ is an output
tree (with or without foot-node); ζ may contain the
variables from the left-hand side of the rule. Each
rule has a probability p ∈ [0, 1].
In fact, BUTAT can be viewed as the string-
to-tree version of bottom-up tree transducers (En-
gelfriet, 1975; Gecseg and Steinby, 1984,1997) in
which, in addition to substitution, adjoining is al-
lowed.
Formally, we let X = {x1, x2, ...} and F =
{f1, f2,...} be the sets of substitution variables
and adjoining variables, resp. Each substitu-
tion variable (resp., adjoining variable) has rank
0 (resp., 1). Thus when used in a tree, substitu-
tion variables are leaves, while adjoining variables
have a single child.
A bottom-up tree adjoining transducer (BU-
TAT) is a tuple M = (Q, F, A, Qf, R) where
</bodyText>
<listItem confidence="0.9972255">
• Q is a finite set (of states),
• IF is an alphabet (of input symbols), assuming
that Q ∩ r = ∅,
• A is an alphabet (of output symbols),
• Qf ⊆ Q (set offinal states), and
• R is a finite set of rules of the form
</listItem>
<equation confidence="0.8366015">
�
γ0 q1(z1) γ1 ... qk(zk) γk → q(ζ) (†)
</equation>
<bodyText confidence="0.9470245">
where p ∈ [0, 1] (probability of (†)), k ≥ 0,
γ0,γ1,...,γk ∈ P, q,q1,...,qk ∈ Q,
z1, ... , zk ∈ X ∪ F, and ζ ∈ RHS(k)
where RHS(k) is the set of all trees over
A ∪ {z1, ... , zk} ∪ {∗} in which the nullary
∗ occurs at most once.
The set of intermediate results of M is the set
IR(M) = {ι  |ι ∈ UΔ({∗}), |pos{*}(ι) |≤ 1}
and the set of sentential forms of M is the set
SF(M) = (F ∪ {q(ι)  |q ∈ Q, ι ∈ IR(M)})*.
The derivation relation induced by M is the bi-
nary relation ⇒ ⊆ SF(M) × SF(M) such that
for every ξ1, ξ2 ∈ SF(M) we define ξ1 ⇒ ξ2 iff
there are ξ, ξ′ ∈ SF(M), there is a rule of the form
(†) in R, and there are ζ1, ... , ζk ∈ IR(M) such
that:
</bodyText>
<listItem confidence="0.9978478">
• for every 1 ≤ i ≤ k: if zz ∈ X, then ζz does
not contain ∗; if zz ∈ F, then ζz contains ∗
exactly once,
• ξ1 = ξ γ0 q1(ζ1)γ1 ... qk(ζk)γk ξ′, and
• ξ2 = ξ q(θ(ζ)) ξ′
</listItem>
<bodyText confidence="0.996838">
where θ is a function that replaces variables
in a right-hand side with their values (subtrees)
from the left-hand side of the rule. Formally,
</bodyText>
<equation confidence="0.5668962">
θ : RHS(k) → IR(M) is defined as follows:
(i) for every ξ = δ(ξ1, ... , ξry,,) ∈ RHS(k), δ ∈
A, we have θ(ξ) = δ(θ(ξ1), ... , θ(ξ�)),
(ii) (substitution) for every zz ∈ X, we have
θ(zz) = ζz,
</equation>
<bodyText confidence="0.87646475">
(iii) (adjoining) for every zz ∈ F and ξ ∈
RHS(k), we have θ(zz(ξ)) = ζz[θ(ξ)]�
where v is the uniquely determined position
of ∗ in ζz, and
</bodyText>
<equation confidence="0.731698">
(iv) θ(∗) = ∗.
</equation>
<bodyText confidence="0.997179666666667">
Clearly, the probablity of a rule carries over to
derivation steps that employ this rule. Since, as
usual, a derivation d is a sequence of derivation
steps, we let the probability of d be the product of
the probabilities of its steps.
The string-to-tree transformation computed by
M is the set τM of all tuples (γ, ξ) ∈ I&apos;*×UΔ such
that there is a derivation of the form γ ⇒* q(ξ) for
some q ∈ Qf.
</bodyText>
<sectionHeader confidence="0.999237" genericHeader="conclusions">
5 Decoder for pSTIG
</sectionHeader>
<bodyText confidence="0.998656666666667">
Now we construct the decoder dec(G) for a pSTIG
G that transforms source strings directly into tar-
get trees and simultaneously computes the proba-
bility of the corresponding derivation of G. This
decoder is formalized as a BUTAT.
Since dec(G) is a string-to-tree transducer, we
</bodyText>
<page confidence="0.997836">
14
</page>
<bodyText confidence="0.999917591836735">
have to transform the source tree ζs of a rule r
into a left-hand side ρ of a dec(G)-rule. This is
done similarly to (DeNeefe and Knight, 2009) by
traversing ζs via recursive descent using a map-
ping ϕ (see an example after Theorem 1); this
creates appropriate state-variable combinations for
all substitution sites and potential adjoining sites
of r. In particular, the source component of the
direction-type of a potential adjoining site deter-
mines the position of the corresponding combina-
tion in ρ. If there are several potential adjoining
sites with the same source component, then we
create a ρ for every permutation of these sites. The
right-hand side of a dec(G)-rule is obtained by
traversing the target tree ζt via recursive descent
using a mapping ψρ and, whenever a nonterminal
with a potential adjoining site w is met, a new po-
sition labeled by fw is inserted.5 If there is more
than one potential adjoining site, then the set of
all those sites is ordered as in the left-hand side ρ
from top to bottom.
Apart from these main rules we will employ
rules which implement the decision of whether or
not to turn a potential adjoining site w into an ac-
tivated adjoining site. Rules for the first purpose
just pass the already computed output tree through
from left to right, whereas rules for the second pur-
pose create for an empty left-hand side the output
tree *.
We will use the state behavior of dec(G) in or-
der to check that (i) the nonterminals of a substi-
tution or potential adjoining site match the root-
category of the used rule, (ii) the direction-type
of an adjoining site matches the auxiliarity of the
chosen auxiliary rule, and (iii) the decisions of
whether or not to adjoin for each rule r of G are
kept separate.
Whereas each pair (ξs, ξt) in the translation of
G is computed in a top-down way, starting at the
initial sentential form and substituting and adjoin-
ing to the present sentential form, dec(G) builds
ξt in a bottom-up way. This change of direction is
legitimate, because adjoining is associative (Vijay-
Shanker and Weir, 1994), i.e., it leads to the same
result whether we first adjoin r2 to r1, and then
align r3 to the resulting tree, or first adjoin r3 to
r2, and then adjoin the resulting tree to r1.
In Fig. 3 we show some rules of the decoder
of our running example pSTIG and in Fig. 4 the
</bodyText>
<footnote confidence="0.899782333333333">
5We will allow variables to have structured indices that
are not elements of N. However, by applying a bijective re-
naming, we can always obtain rules of the form (†).
</footnote>
<bodyText confidence="0.999111333333333">
derivation of this decoder which correponds to the
derivation in Fig. 2.
Theorem 1. Let G be a pSTIG over N and T.
Then there is a BUTAT dec(G) such that for ev-
ery (ξs, ξt) E UN(T) x UN(T) and p E [0, 1] the
following two statements are equivalent:
</bodyText>
<listItem confidence="0.9227905">
1. there is a successful derivation of
(ξs, ξt, 0, 0, 0) by G with probability p,
2. there is a derivation from yield(ξs) to
[Ss, St](ξt) by dec(G) with probability p.
</listItem>
<bodyText confidence="0.8062715">
PROOF. Let G = (N, T, [Ss, St], S, A, P) be a
pSTIG. We will construct the BUTAT dec(G) =
(Q, T, N U T, {[Ss, St]}, R) as follows (where the
mappings ϕ and ψρ will be defined below):
</bodyText>
<listItem confidence="0.999114">
• Q = [N x N] U [N x {L, R} x N x {L, R}]
U{[r, w]  |r E A, w is an adjoining site of r},
• R is the smallest set R′ of rules such
that for every r E S U A of the form
(ζs, ζt, V, W, Pr ��j) or (ζs, ζt, V, W, *, Pr��j):
– for every ρ E ϕ(ε), if r E S, then the
main rule
</listItem>
<equation confidence="0.9975345">
P �r)
ρ y [ζs(ε), ζt(ε)]�ψρ(ε)�
</equation>
<bodyText confidence="0.998756">
is in R′, and if r E A and r is δsδt-
auxiliary, then the main rule
</bodyText>
<equation confidence="0.9901045">
P �r)
ρ y [ζs(ε), δs, ζt(ε), δt]�ψρ(ε)�
</equation>
<bodyText confidence="0.666283">
is in R′, and
– for every w = (ws, δs, wt, δt) E W the
rules
</bodyText>
<equation confidence="0.990051">
qw (fw) P�adj�w)
s [r, w] (fw(*))
</equation>
<bodyText confidence="0.738682">
with qw = [ζ(ws), δs, ζt(wt), δt] for ac-
tivation at w, and the rule
</bodyText>
<equation confidence="0.9841995">
1−P� adj�w)
ε �y [r, w](*)
</equation>
<bodyText confidence="0.999908">
for non-adjoining at w are in R′.
We define the mapping
</bodyText>
<equation confidence="0.709028">
ϕ : pos(ζs) y P((T U Q(X U F))*)
</equation>
<bodyText confidence="0.917258">
with Q(X U F) = {q(z)  |q E Q, z E X U F}
inductively on its argument as follows. Let w E
pos(ζs) and let w have n children.
</bodyText>
<figure confidence="0.4316342">
(a) Let ζs(w) E T. Then ϕ(w) = {ζs(w)}.
15
(b) (substitution site) Let ζs(w) ∈ N and let
w′ ∈ pos(ζt) such that (w, w′) ∈ V . Then
ϕ(w) = {[ζs(w),ζt(w′)](x(w,w′))}.
</figure>
<listItem confidence="0.982446285714286">
(c) (adjoining site) Let ζs(w) ∈ N and let there
be an adjoining site in W with w as first
component. Then, we define ϕ(w) to be the
smallest set such that for every permutation
(u1, ... , ul) (resp., (v1, ... , vm)) of all the L-
adjoining (resp., R-adjoining) sites in W with
w as first component, the set6
</listItem>
<equation confidence="0.441846">
J ◦ ϕ(w.1) ◦ ... ◦ ϕ(w.n) ◦ K
</equation>
<bodyText confidence="0.534713">
is a subset of ϕ(w), where J = {u′1 ... u′l}
and K = {v′m ... v′1} and
</bodyText>
<equation confidence="0.801617">
)
u′i = [r, ui](fui) and v′ j = [r, vj](fv�
for 1 ≤ i ≤ l and 1 ≤ j ≤ m.
</equation>
<listItem confidence="0.7171125">
(d) Let ζs(w) ∈ N, w =6 ∗, and let w be neither
the first component of a substitution site in V
nor the first component of an adjoining site in
W. Then
</listItem>
<equation confidence="0.96976125">
ϕ(w) = ϕ(w.1) ◦ ... ◦ ϕ(w.n) .
(e) Let w = ∗. Then we define ϕ(w) = {ε}.
For every ρ ∈ ϕ(ε), we define the mapping
ψρ : pos(ζt) → UN∪F∪X(T ∪ {∗})
</equation>
<bodyText confidence="0.816764">
inductively on its argument as follows. Let
w ∈ pos(ζt) and let w have n children.
</bodyText>
<listItem confidence="0.891994333333333">
(a) Let ζt(w) ∈ T. Then ψρ(w) = ζt(w).
(b) (substitution site) Let ζt(w) ∈ N and let
w′ ∈ pos(ζs) such that (w′, w) ∈ V . Then
ψρ(w) = x(w′,w).
(c) (adjoining site) Let ζt(w) ∈ N and let there
be an adjoining site in W with w as third
component. Then let {u1, ... , ul} ⊆ W be
the set of all potential adjoining sites with w
as third component, and we define
</listItem>
<equation confidence="0.968807">
ψρ(w) = fu1(... fup(ζ) ...)
</equation>
<bodyText confidence="0.996658">
where ζ = ζt(w)(ψρ(w.1), ... , ψρ(w.n))
and the ui’s occur in ψρ(w) (from the root
towards the leaves) in exactly the same order
as they occur in ρ (from left to right).
(d) Let ζt(w) ∈ N, w =6 ∗, and let w be neither
the second component of a substitution site
in V nor the third component of an adjoining
site in W. Then
</bodyText>
<equation confidence="0.586826333333333">
ψρ(w) = ζt(w)(ψρ(w.1), ... , ψρ(w.n)).
6using the usual concatenation ◦ of formal languages
(e) Let w = ∗. Then ψρ(w) = ∗.
</equation>
<bodyText confidence="0.967552461538462">
With dec(G) constructed as shown, for each
derivation of G there is a corresponding deriva-
tion of dec(G), with the same probability, and vice
versa. The derivations proceed in opposite direc-
tions. Each sentential form in one has an equiv-
alent sentential form in the other, and each step
of the derivations correspond. There is no space
to present the full proof, but let us give a slightly
more precise idea about the formal relationship be-
tween the derivations of G and dec(G).
In the usual way we can associate a deriva-
tion tree dt with every successful derivation d of
G. Assume that last(d) = (ξs, ξt, ∅, ∅, ∅), and
let Es and Et be the embedded tree transducers
(Shieber, 2006) associated with, respectively, the
source component and the target component of
G. Then it was shown in (Shieber, 2006) that
τE3(dt) = ξs and τEt(dt) = ξt where τE de-
notes the tree-to-tree transduction computed by an
embedded tree transducer E. Roughly speaking,
Es and Et reproduce the derivations of, respec-
tively, the source component and the target com-
ponent of G that are prescribed by dt. Thus, for
κ = (ξ′ s, ξ′ t,V, W, g), if κin ⇒∗G κ and κ is a prefix
of d, then there is exactly one subtree dt[(w, w′)]
of dt associated with every (w, w′) ∈ V ∪ W,
which prescribes how to continue at (w, w′) with
the reproduction of d. Having this in mind, we ob-
tain the sentential form of the dec(G)-derivation
which corresponds to κ by applying a modifica-
tion of ϕ to κ where the modification amounts to
replacing x(w,w′) and f(w,w′) by τEt(dt[(w, w′)]);
note that τEt(dt[(w, w′)]) might contain ∗. 0
As illustration of the construction in Theorem 1
let us apply the mappings ϕ and ψρ to rule r2 of
Fig. 1, i.e., to r2 = (ζs, ζt, ∅, {b, c}, ∗, P2.)
with ζs = A(A,γ), ζt = B(B(δ), K
b = (ε, R, ε, L), c = (ε, R,1, L), and ∗ = (1, 2).
Let us calculate ϕ(ε) on ζs. Due to (c),
</bodyText>
<equation confidence="0.974952">
ϕ(ε) = J ◦ ϕ(1) ◦ ϕ(2) ◦ K.
</equation>
<bodyText confidence="0.961141666666667">
Since there are no L-adjoinings at ε, we have that
J = {ε}. Since there are the R-adjoinings b and c
at ε, we have the two permutations (b, c) and (c, b).
</bodyText>
<equation confidence="0.5261745">
(v1, v2) = (b, c): K = {[r2, c](fc)[r2, b](fb)}
(v1, v2) = (c, b): K = {[r2, b](fb)[r2, c](fc)}
</equation>
<bodyText confidence="0.604015666666667">
Due to (e) and (a), we have that ϕ(1) = {ε} and
ϕ(2) = {γ}, resp. Thus, ϕ(ε) is the set:
{γ [r2, c](fc) [r2, b](fb), γ [r2, b](fb) [r2, c](fc)}.
</bodyText>
<page confidence="0.995685">
16
</page>
<figureCaption confidence="0.9947425">
Figure 3: Some rules of the running example de-
coder.
</figureCaption>
<bodyText confidence="0.7395115">
Now let ρ = γ [r2, b](fb) [r2, c](fc). Let us cal-
culate ψp(ε) on ζt.
</bodyText>
<equation confidence="0.99844775">
ψp(ε) (c)= fb(B(ψp(1), ψp(2)))
(c) fb(B(fc(B(ψp(1.1))), ψp(2)))
(a) = fb(B(fc(B(δ)), ψp(2)))
(e) fb(B(fc(B(δ)), ∗))
</equation>
<bodyText confidence="0.9221435">
Hence we obtain the rule
γ [r2, b](fb) [r2, c](fc) →
[A, R, B, L](fb(B(fc(B(δ)), ∗)))
which is also shown in Fig. 3.
</bodyText>
<figure confidence="0.999093395348837">
r1
[A, B]
α
x(2,2)
(r1, a)
[A, R, B, L]
fa
r2
B
β
[r1, a]
fa
∗
[A, R, B, L]
b
f
(r2, ¬b)
.8
ε
−→
r4
.1
α −→
[r2, b]
∗
[A, B]
B
β
(r2, ¬c)
−→
.4
B
δ
ε
B
−→
.4
γ
c
[r2, c]
fc
[r2, b]
fb
∗
f
[Ss, St]
St
.9
−→
[r2, c]
∗
α
−→ 1
[r1, a]
fa
fa x(2,2) β
B
∗
β
B
B
B
δ
β
α α α γ
[r2, b]
[r2, c]
α α α γ
∗
∗
[r2, b]
α α α γ
∗
[A, R, B, L]
B
α α α
�⇒
prob..8
(r2, ¬b)
�⇒
prob..4
(r2, ¬c)
�⇒
prob..4
(r2, bc)
δ
</figure>
<figureCaption confidence="0.998298">
Figure 4: Derivation of the decoder corresponding
to the derivation in Fig. 2.
</figureCaption>
<figure confidence="0.999618769230769">
[A, B]
α B
β
B
� � �
prob..9
[r1, a]
B
B
δ
∗
prob..1
[r1, a]
B
B
δ
∗
prob..1
[Ss, St]
St
β
r4
α
r1
(r1, a)
α α α
</figure>
<page confidence="0.992803">
17
</page>
<sectionHeader confidence="0.993079" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999932198019801">
A. Abeille, Y. Schabes, A.K. Joshi. Using lexicalized
TAGs for machine translation. In Proceedings of
the 13th International Conference on Computational
Linguistics, volume 3, pp. 1–6, Helsinki, Finland,
1990.
C. Baier, M. Gr¨olier, F. Ciesinski. Model checking
linear-time properties of probabilistic systems. In
Handbook of Weighted Automata, Chapter 13, pp.
519–570, Springer, 2009.
S. DeNeefe. Tree adjoining machine translation. Ph.D.
thesis proposal, Univ. of Southern California, 2009.
S. DeNeefe, K. Knight. Synchronous tree adjoining
machine translation. In Proc. of Conf. Empirical
Methods in NLP, pp. 727–736, 2009.
J. Engelfriet. Bottom-up and top-down tree transfor-
mations — a comparison. Math. Systems Theory,
9(3):198–231, 1975.
J. Engelfriet. Tree transducers and syntax-directed se-
mantics. In CAAP 1982: Lille, France, 1982.
A. Fujiyoshi, T. Kasai. Spinal-formed context-free tree
grammars. Theory of Computing Systems, 33:59–
83, 2000.
Z. F¨ul¨op, H. Vogler. Weighted tree automata and tree
transducers. In Handbook of Weighted Automata,
Chapter 9, pp. 313–403, Spinger, 2009.
F. G´ecseg, M. Steinby. Tree Automata. Akad´emiai
Kiad´o, Budapest, 1984.
F. G´ecseg, M. Steinby. Tree languages. In Handbook
of Formal Languages, volume 3, chapter 1, pages
1–68. Springer-Verlag, 1997.
J. Graehl, K. Knight, J. May. Training tree transducers.
Computational Linguistics, 34(3):391–427, 2008
A.K. Joshi, L.S. Levy, M. Takahashi. Tree adjunct
grammars. Journal of Computer and System Sci-
ences, 10(1):136–163, 1975.
A.K. Joshi, Y. Schabes. Tree-adjoining grammars. In
Handbook ofFormal Languages. Chapter 2, pp. 69–
123, Springer-Verlag, 1997.
K. Knight, J. Graehl. An overview of probabilis-
tic tree transducers for natural language processing.
In Computational Linguistics and Intelligent Text
Processing, CICLing 2005, LNCS 3406, pp. 1–24,
Springer, 2005.
K. Knight, J. May. Applications of Weighted Au-
tomata in Natural Language Processing. In Hand-
book of Weighted Automata, Chapter 14, pp. 571–
596, Springer, 2009.
P.M. Lewis, R.E. Stearns. Syntax-directed transduc-
tions. Journal of the ACM, 15:465–488, 1968.
A. Maletti. Compositions of tree series transforma-
tions. Theoret. Comput. Sci., 366:248–271, 2006.
A. Maletti. The Power of Tree Series Transducers.
Ph.D. thesis, TU Dresden, Germany, 2006.
A. Maletti. Compositions of extended top-down
tree transducers. Information and Computation,
206:1187–1196, 2008.
A. Maletti. Why synchronous tree substitution gram-
mars? in Proc. 11th Conf. North American Chap-
ter of the Association of Computational Linguistics.
2010.
D.F. Martin and S.A. Vere. On syntax-directed trans-
ductions and tree transducers. In Ann. ACM Sympo-
sium on Theory of Computing, pp. 129–135, 1970.
R. Nesson, S.M. Shieber, and A. Rush. Induction
of probabilistic synchronous tree-insertion gram-
mars. Technical Report TR-20-05, Computer Sci-
ence Group, Harvard Univeristy, Cambridge, Mas-
sachusetts, 2005.
R. Nesson, S.M. Shieber, and A. Rush. Induction of
probabilistic synchronous tree-inserting grammars
for machine translation. In Proceedings of the 7th
Conference of the Association for Machine Transla-
tion in the Americas (AMTA 2006), 2006.
Y. Schabes, R.C. Waters. Tree insertion grammars:
a cubic-time, parsable formalism that lexicalizes
context-free grammar without changing the trees
produced. Computational Linguistics, 21:479–513,
1994.
P.P. Schreiber. Tree-transducers and syntax-connected
transductions. In Automata Theory and Formal
Languages, Lecture Notes in Computer Science 33,
pp. 202–208, Springer, 1975.
S.M. Shieber. Synchronous grammars and tree trans-
ducers. In Proc. 7th Workshop on Tree Adjoin-
ing Grammars and Related Formalisms, pp. 88–95,
2004.
S.M. Shieber. Unifying synchronous tree-adjoining
grammars and tree transducers via bimorphisms. In
Proc. 11th Conf. European Chapter of ACL, EACL
06, pp. 377–384, 2006.
S.M. Shieber, Y. Schabes. Synchronous tree-adjoining
grammars. In Proceedings of the 13th Interna-
tional Conference on Computational Linguistics,
volume 3, pp. 253–258, Helsinki, Finland, 1990.
K. Vijay-Shanker, D.J. Weir. The equivalence of four
extensions of context-free grammars. Mathematical
Systems Theory, 27:511–546, 1994.
K. Yamada and K. Knight. A syntax-based statistical
translation model. In Proc. of 39th Annual Meeting
of the Assoc. Computational Linguistics, pp. 523–
530, 2001.
</reference>
<page confidence="0.999292">
18
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.357450">
<title confidence="0.9991985">A Decoder for Probabilistic Synchronous Tree Insertion Grammars</title>
<author confidence="0.999544">DeNeefe Kevin Knight</author>
<affiliation confidence="0.999843">USC Information Sciences</affiliation>
<address confidence="0.9728845">4676 Admiralty Marina del Rey, CA 90292,</address>
<author confidence="0.613703">Vogler</author>
<affiliation confidence="0.987789">Department of Computer Technische Universit¨at</affiliation>
<address confidence="0.769154">D-01062</address>
<email confidence="0.945042">Heiko.Vogler@tu-dresden.de</email>
<abstract confidence="0.984652222222222">Synchronous tree insertion grammars (STIG) are formal models for syntaxbased machine translation. We formalize a decoder for probabilistic STIG; the decoder transforms every source-language string into a target-language tree and calculates the probability of this transformation.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Abeille</author>
<author>Y Schabes</author>
<author>A K Joshi</author>
</authors>
<title>Using lexicalized TAGs for machine translation.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<volume>3</volume>
<pages>1--6</pages>
<location>Helsinki, Finland,</location>
<contexts>
<context position="1121" citStr="Abeille et al., 1990" startWordPosition="162" endWordPosition="165">forms every source-language string into a target-language tree and calculates the probability of this transformation. 1 Introduction Tree adjoining grammars (TAG) were invented in (Joshi et al. 1975) in order to better characterize the string sets of natural languages1. One of TAG’s important features is the ability to introduce two related syntactic units in a single rule, then push those two units arbitrarily far apart in subsequent derivation steps. For machine translation (MT) between two natural languages, each being generated by a TAG, the derivations of the two TAG may be synchronized (Abeille et al., 1990; Shieber and Shabes, 1990) in the spirit of syntaxdirected transductions (Lewis and Stearns, 1968); this results in synchronous TAG (STAG). Recently, in (Nesson et al., 2005, 2006) probabilistic synchronous tree insertion grammars (pSTIG) were discussed as model of MT; a tree insertion grammar is a particular TAG in which the parsing problem is solvable in cubic-time (Schabes and Waters, 1994). In (DeNeefe, 2009; DeNeefe and Knight 2009) a decoder for pSTIG has been proposed which transforms source-language strings into (modifications of) derivation trees of the pSTIG. Nowadays, large-scale l</context>
</contexts>
<marker>Abeille, Schabes, Joshi, 1990</marker>
<rawString>A. Abeille, Y. Schabes, A.K. Joshi. Using lexicalized TAGs for machine translation. In Proceedings of the 13th International Conference on Computational Linguistics, volume 3, pp. 1–6, Helsinki, Finland, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Baier</author>
<author>M Gr¨olier</author>
<author>F Ciesinski</author>
</authors>
<title>Model checking linear-time properties of probabilistic systems.</title>
<date>2009</date>
<journal>In Handbook of Weighted Automata, Chapter</journal>
<volume>13</volume>
<pages>519--570</pages>
<publisher>Springer,</publisher>
<marker>Baier, Gr¨olier, Ciesinski, 2009</marker>
<rawString>C. Baier, M. Gr¨olier, F. Ciesinski. Model checking linear-time properties of probabilistic systems. In Handbook of Weighted Automata, Chapter 13, pp. 519–570, Springer, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S DeNeefe</author>
</authors>
<title>Tree adjoining machine translation.</title>
<date>2009</date>
<tech>Ph.D. thesis proposal,</tech>
<institution>Univ. of Southern California,</institution>
<contexts>
<context position="1537" citStr="DeNeefe, 2009" startWordPosition="232" endWordPosition="233">t in subsequent derivation steps. For machine translation (MT) between two natural languages, each being generated by a TAG, the derivations of the two TAG may be synchronized (Abeille et al., 1990; Shieber and Shabes, 1990) in the spirit of syntaxdirected transductions (Lewis and Stearns, 1968); this results in synchronous TAG (STAG). Recently, in (Nesson et al., 2005, 2006) probabilistic synchronous tree insertion grammars (pSTIG) were discussed as model of MT; a tree insertion grammar is a particular TAG in which the parsing problem is solvable in cubic-time (Schabes and Waters, 1994). In (DeNeefe, 2009; DeNeefe and Knight 2009) a decoder for pSTIG has been proposed which transforms source-language strings into (modifications of) derivation trees of the pSTIG. Nowadays, large-scale linguistic STAG rule bases are available. In an independent tradition, the automatatheoretic investigation of the translation of trees ∗ financially supported by NSF STAGES project, grant #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite te</context>
<context position="3021" citStr="DeNeefe, 2009" startWordPosition="462" endWordPosition="463">of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the target tree using an embedded tree transducer (Shieber, 2006). We propose a transducer model, called a bottom-up tree adjoining transducer, which performs this decoding in a single step and, simultaneously, computes the probabilities of its derivations. As a basis of our approach, we present a formal definition of pSTIG. 2 Preliminaries For two sets E and A, we let UE(A) be the set of all (unranked) trees over E in which also elements of A may label leaves. We abbreviate UE(∅) by UE. We denote the set of positi</context>
</contexts>
<marker>DeNeefe, 2009</marker>
<rawString>S. DeNeefe. Tree adjoining machine translation. Ph.D. thesis proposal, Univ. of Southern California, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S DeNeefe</author>
<author>K Knight</author>
</authors>
<title>Synchronous tree adjoining machine translation.</title>
<date>2009</date>
<booktitle>In Proc. of Conf. Empirical Methods in NLP,</booktitle>
<pages>727--736</pages>
<contexts>
<context position="1563" citStr="DeNeefe and Knight 2009" startWordPosition="234" endWordPosition="237"> derivation steps. For machine translation (MT) between two natural languages, each being generated by a TAG, the derivations of the two TAG may be synchronized (Abeille et al., 1990; Shieber and Shabes, 1990) in the spirit of syntaxdirected transductions (Lewis and Stearns, 1968); this results in synchronous TAG (STAG). Recently, in (Nesson et al., 2005, 2006) probabilistic synchronous tree insertion grammars (pSTIG) were discussed as model of MT; a tree insertion grammar is a particular TAG in which the parsing problem is solvable in cubic-time (Schabes and Waters, 1994). In (DeNeefe, 2009; DeNeefe and Knight 2009) a decoder for pSTIG has been proposed which transforms source-language strings into (modifications of) derivation trees of the pSTIG. Nowadays, large-scale linguistic STAG rule bases are available. In an independent tradition, the automatatheoretic investigation of the translation of trees ∗ financially supported by NSF STAGES project, grant #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If ea</context>
<context position="3047" citStr="DeNeefe and Knight 2009" startWordPosition="464" endWordPosition="467">l languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the target tree using an embedded tree transducer (Shieber, 2006). We propose a transducer model, called a bottom-up tree adjoining transducer, which performs this decoding in a single step and, simultaneously, computes the probabilities of its derivations. As a basis of our approach, we present a formal definition of pSTIG. 2 Preliminaries For two sets E and A, we let UE(A) be the set of all (unranked) trees over E in which also elements of A may label leaves. We abbreviate UE(∅) by UE. We denote the set of positions, leaves, and non-leave</context>
<context position="19159" citStr="DeNeefe and Knight, 2009" startWordPosition="3815" endWordPosition="3818">ties of its steps. The string-to-tree transformation computed by M is the set τM of all tuples (γ, ξ) ∈ I&apos;*×UΔ such that there is a derivation of the form γ ⇒* q(ξ) for some q ∈ Qf. 5 Decoder for pSTIG Now we construct the decoder dec(G) for a pSTIG G that transforms source strings directly into target trees and simultaneously computes the probability of the corresponding derivation of G. This decoder is formalized as a BUTAT. Since dec(G) is a string-to-tree transducer, we 14 have to transform the source tree ζs of a rule r into a left-hand side ρ of a dec(G)-rule. This is done similarly to (DeNeefe and Knight, 2009) by traversing ζs via recursive descent using a mapping ϕ (see an example after Theorem 1); this creates appropriate state-variable combinations for all substitution sites and potential adjoining sites of r. In particular, the source component of the direction-type of a potential adjoining site determines the position of the corresponding combination in ρ. If there are several potential adjoining sites with the same source component, then we create a ρ for every permutation of these sites. The right-hand side of a dec(G)-rule is obtained by traversing the target tree ζt via recursive descent u</context>
</contexts>
<marker>DeNeefe, Knight, 2009</marker>
<rawString>S. DeNeefe, K. Knight. Synchronous tree adjoining machine translation. In Proc. of Conf. Empirical Methods in NLP, pp. 727–736, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Engelfriet</author>
</authors>
<title>Bottom-up and top-down tree transformations — a comparison.</title>
<date>1975</date>
<journal>Math. Systems Theory,</journal>
<volume>9</volume>
<issue>3</issue>
<contexts>
<context position="16265" citStr="Engelfriet, 1975" startWordPosition="3221" endWordPosition="3223">a substitution variable or an adjoining variable; a substitution variable (resp., adjoining variable) can have an output tree (resp., output tree with foot node) as value. Intuitively, each variable value is a translation of the string that has been reduced to the corresponding state. The right-hand side of a rule has the form q(ζ) where q is a state and ζ is an output tree (with or without foot-node); ζ may contain the variables from the left-hand side of the rule. Each rule has a probability p ∈ [0, 1]. In fact, BUTAT can be viewed as the stringto-tree version of bottom-up tree transducers (Engelfriet, 1975; Gecseg and Steinby, 1984,1997) in which, in addition to substitution, adjoining is allowed. Formally, we let X = {x1, x2, ...} and F = {f1, f2,...} be the sets of substitution variables and adjoining variables, resp. Each substitution variable (resp., adjoining variable) has rank 0 (resp., 1). Thus when used in a tree, substitution variables are leaves, while adjoining variables have a single child. A bottom-up tree adjoining transducer (BUTAT) is a tuple M = (Q, F, A, Qf, R) where • Q is a finite set (of states), • IF is an alphabet (of input symbols), assuming that Q ∩ r = ∅, • A is an alp</context>
</contexts>
<marker>Engelfriet, 1975</marker>
<rawString>J. Engelfriet. Bottom-up and top-down tree transformations — a comparison. Math. Systems Theory, 9(3):198–231, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Engelfriet</author>
</authors>
<title>Tree transducers and syntax-directed semantics.</title>
<date>1982</date>
<booktitle>In CAAP 1982:</booktitle>
<location>Lille, France,</location>
<marker>Engelfriet, 1982</marker>
<rawString>J. Engelfriet. Tree transducers and syntax-directed semantics. In CAAP 1982: Lille, France, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Fujiyoshi</author>
<author>T Kasai</author>
</authors>
<title>Spinal-formed context-free tree grammars.</title>
<date>2000</date>
<journal>Theory of Computing Systems,</journal>
<volume>33</volume>
<marker>Fujiyoshi, Kasai, 2000</marker>
<rawString>A. Fujiyoshi, T. Kasai. Spinal-formed context-free tree grammars. Theory of Computing Systems, 33:59– 83, 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z F¨ul¨op</author>
<author>H Vogler</author>
</authors>
<title>Weighted tree automata and tree transducers.</title>
<date>2009</date>
<booktitle>In Handbook of Weighted Automata, Chapter 9,</booktitle>
<pages>313--403</pages>
<location>Spinger,</location>
<marker>F¨ul¨op, Vogler, 2009</marker>
<rawString>Z. F¨ul¨op, H. Vogler. Weighted tree automata and tree transducers. In Handbook of Weighted Automata, Chapter 9, pp. 313–403, Spinger, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F G´ecseg</author>
<author>M Steinby</author>
</authors>
<title>Tree Automata. Akad´emiai Kiad´o,</title>
<date>1984</date>
<location>Budapest,</location>
<marker>G´ecseg, Steinby, 1984</marker>
<rawString>F. G´ecseg, M. Steinby. Tree Automata. Akad´emiai Kiad´o, Budapest, 1984.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F G´ecseg</author>
<author>M Steinby</author>
</authors>
<title>Tree languages.</title>
<date>1997</date>
<booktitle>In Handbook of Formal Languages,</booktitle>
<volume>3</volume>
<pages>1--68</pages>
<publisher>Springer-Verlag,</publisher>
<marker>G´ecseg, Steinby, 1997</marker>
<rawString>F. G´ecseg, M. Steinby. Tree languages. In Handbook of Formal Languages, volume 3, chapter 1, pages 1–68. Springer-Verlag, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Graehl</author>
<author>K Knight</author>
<author>J May</author>
</authors>
<title>Training tree transducers.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>3</issue>
<contexts>
<context position="2505" citStr="Graehl et al., 2008" startWordPosition="381" endWordPosition="384">STAGES project, grant #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the </context>
</contexts>
<marker>Graehl, Knight, May, 2008</marker>
<rawString>J. Graehl, K. Knight, J. May. Training tree transducers. Computational Linguistics, 34(3):391–427, 2008</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>L S Levy</author>
<author>M Takahashi</author>
</authors>
<title>Tree adjunct grammars.</title>
<date>1975</date>
<journal>Journal of Computer and System Sciences,</journal>
<volume>10</volume>
<issue>1</issue>
<contexts>
<context position="700" citStr="Joshi et al. 1975" startWordPosition="92" endWordPosition="95">d Kevin Knight * USC Information Sciences Institute 4676 Admiralty Way Marina del Rey, CA 90292, USA {sdeneefe,knight}@isi.edu Heiko Vogler † Department of Computer Science Technische Universit¨at Dresden D-01062 Dresden Heiko.Vogler@tu-dresden.de Abstract Synchronous tree insertion grammars (STIG) are formal models for syntaxbased machine translation. We formalize a decoder for probabilistic STIG; the decoder transforms every source-language string into a target-language tree and calculates the probability of this transformation. 1 Introduction Tree adjoining grammars (TAG) were invented in (Joshi et al. 1975) in order to better characterize the string sets of natural languages1. One of TAG’s important features is the ability to introduce two related syntactic units in a single rule, then push those two units arbitrarily far apart in subsequent derivation steps. For machine translation (MT) between two natural languages, each being generated by a TAG, the derivations of the two TAG may be synchronized (Abeille et al., 1990; Shieber and Shabes, 1990) in the spirit of syntaxdirected transductions (Lewis and Stearns, 1968); this results in synchronous TAG (STAG). Recently, in (Nesson et al., 2005, 200</context>
</contexts>
<marker>Joshi, Levy, Takahashi, 1975</marker>
<rawString>A.K. Joshi, L.S. Levy, M. Takahashi. Tree adjunct grammars. Journal of Computer and System Sciences, 10(1):136–163, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A K Joshi</author>
<author>Y Schabes</author>
</authors>
<title>Tree-adjoining grammars.</title>
<date>1997</date>
<booktitle>In Handbook ofFormal Languages. Chapter 2,</booktitle>
<pages>69--123</pages>
<publisher>Springer-Verlag,</publisher>
<marker>Joshi, Schabes, 1997</marker>
<rawString>A.K. Joshi, Y. Schabes. Tree-adjoining grammars. In Handbook ofFormal Languages. Chapter 2, pp. 69– 123, Springer-Verlag, 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J Graehl</author>
</authors>
<title>An overview of probabilistic tree transducers for natural language processing.</title>
<date>2005</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing, CICLing 2005, LNCS 3406,</booktitle>
<pages>1--24</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="2484" citStr="Knight and Graehl, 2005" startWordPosition="377" endWordPosition="380">ncially supported by NSF STAGES project, grant #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is </context>
</contexts>
<marker>Knight, Graehl, 2005</marker>
<rawString>K. Knight, J. Graehl. An overview of probabilistic tree transducers for natural language processing. In Computational Linguistics and Intelligent Text Processing, CICLing 2005, LNCS 3406, pp. 1–24, Springer, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>J May</author>
</authors>
<title>Applications of Weighted Automata in Natural Language Processing.</title>
<date>2009</date>
<booktitle>In Handbook of Weighted Automata, Chapter 14,</booktitle>
<pages>571--596</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="2527" citStr="Knight and May 2009" startWordPosition="385" endWordPosition="388"> #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the target tree using an e</context>
</contexts>
<marker>Knight, May, 2009</marker>
<rawString>K. Knight, J. May. Applications of Weighted Automata in Natural Language Processing. In Handbook of Weighted Automata, Chapter 14, pp. 571– 596, Springer, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P M Lewis</author>
<author>R E Stearns</author>
</authors>
<title>Syntax-directed transductions.</title>
<date>1968</date>
<journal>Journal of the ACM,</journal>
<volume>15</volume>
<contexts>
<context position="1220" citStr="Lewis and Stearns, 1968" startWordPosition="177" endWordPosition="180">f this transformation. 1 Introduction Tree adjoining grammars (TAG) were invented in (Joshi et al. 1975) in order to better characterize the string sets of natural languages1. One of TAG’s important features is the ability to introduce two related syntactic units in a single rule, then push those two units arbitrarily far apart in subsequent derivation steps. For machine translation (MT) between two natural languages, each being generated by a TAG, the derivations of the two TAG may be synchronized (Abeille et al., 1990; Shieber and Shabes, 1990) in the spirit of syntaxdirected transductions (Lewis and Stearns, 1968); this results in synchronous TAG (STAG). Recently, in (Nesson et al., 2005, 2006) probabilistic synchronous tree insertion grammars (pSTIG) were discussed as model of MT; a tree insertion grammar is a particular TAG in which the parsing problem is solvable in cubic-time (Schabes and Waters, 1994). In (DeNeefe, 2009; DeNeefe and Knight 2009) a decoder for pSTIG has been proposed which transforms source-language strings into (modifications of) derivation trees of the pSTIG. Nowadays, large-scale linguistic STAG rule bases are available. In an independent tradition, the automatatheoretic investi</context>
</contexts>
<marker>Lewis, Stearns, 1968</marker>
<rawString>P.M. Lewis, R.E. Stearns. Syntax-directed transductions. Journal of the ACM, 15:465–488, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Maletti</author>
</authors>
<title>Compositions of tree series transformations.</title>
<date>2006</date>
<journal>Theoret. Comput. Sci.,</journal>
<volume>366</volume>
<contexts>
<context position="2299" citStr="Maletti, 2006" startWordPosition="349" endWordPosition="350"> the pSTIG. Nowadays, large-scale linguistic STAG rule bases are available. In an independent tradition, the automatatheoretic investigation of the translation of trees ∗ financially supported by NSF STAGES project, grant #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding </context>
</contexts>
<marker>Maletti, 2006</marker>
<rawString>A. Maletti. Compositions of tree series transformations. Theoret. Comput. Sci., 366:248–271, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Maletti</author>
</authors>
<title>The Power of Tree Series Transducers.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>TU Dresden,</institution>
<contexts>
<context position="2299" citStr="Maletti, 2006" startWordPosition="349" endWordPosition="350"> the pSTIG. Nowadays, large-scale linguistic STAG rule bases are available. In an independent tradition, the automatatheoretic investigation of the translation of trees ∗ financially supported by NSF STAGES project, grant #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding </context>
</contexts>
<marker>Maletti, 2006</marker>
<rawString>A. Maletti. The Power of Tree Series Transducers. Ph.D. thesis, TU Dresden, Germany, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Maletti</author>
</authors>
<title>Compositions of extended top-down tree transducers.</title>
<date>2008</date>
<journal>Information and Computation,</journal>
<volume>206</volume>
<contexts>
<context position="2678" citStr="Maletti (2008" startWordPosition="409" endWordPosition="410">Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the target tree using an embedded tree transducer (Shieber, 2006). We propose a transducer model, called a bottom-up tree adjoining transducer, which performs this decoding in a</context>
</contexts>
<marker>Maletti, 2008</marker>
<rawString>A. Maletti. Compositions of extended top-down tree transducers. Information and Computation, 206:1187–1196, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Maletti</author>
</authors>
<title>Why synchronous tree substitution grammars? in</title>
<date>2010</date>
<booktitle>Proc. 11th Conf. North American Chapter of the Association of Computational Linguistics.</booktitle>
<marker>Maletti, 2010</marker>
<rawString>A. Maletti. Why synchronous tree substitution grammars? in Proc. 11th Conf. North American Chapter of the Association of Computational Linguistics. 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D F Martin</author>
<author>S A Vere</author>
</authors>
<title>On syntax-directed transductions and tree transducers.</title>
<date>1970</date>
<booktitle>In Ann. ACM Symposium on Theory of Computing,</booktitle>
<pages>129--135</pages>
<contexts>
<context position="2551" citStr="Martin and Vere (1970)" startWordPosition="389" endWordPosition="392">cially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the target tree using an embedded tree transducer </context>
</contexts>
<marker>Martin, Vere, 1970</marker>
<rawString>D.F. Martin and S.A. Vere. On syntax-directed transductions and tree transducers. In Ann. ACM Symposium on Theory of Computing, pp. 129–135, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Nesson</author>
<author>S M Shieber</author>
<author>A Rush</author>
</authors>
<title>Induction of probabilistic synchronous tree-insertion grammars.</title>
<date>2005</date>
<tech>Technical Report TR-20-05,</tech>
<institution>Computer Science Group, Harvard Univeristy,</institution>
<location>Cambridge, Massachusetts,</location>
<contexts>
<context position="1295" citStr="Nesson et al., 2005" startWordPosition="189" endWordPosition="192">d in (Joshi et al. 1975) in order to better characterize the string sets of natural languages1. One of TAG’s important features is the ability to introduce two related syntactic units in a single rule, then push those two units arbitrarily far apart in subsequent derivation steps. For machine translation (MT) between two natural languages, each being generated by a TAG, the derivations of the two TAG may be synchronized (Abeille et al., 1990; Shieber and Shabes, 1990) in the spirit of syntaxdirected transductions (Lewis and Stearns, 1968); this results in synchronous TAG (STAG). Recently, in (Nesson et al., 2005, 2006) probabilistic synchronous tree insertion grammars (pSTIG) were discussed as model of MT; a tree insertion grammar is a particular TAG in which the parsing problem is solvable in cubic-time (Schabes and Waters, 1994). In (DeNeefe, 2009; DeNeefe and Knight 2009) a decoder for pSTIG has been proposed which transforms source-language strings into (modifications of) derivation trees of the pSTIG. Nowadays, large-scale linguistic STAG rule bases are available. In an independent tradition, the automatatheoretic investigation of the translation of trees ∗ financially supported by NSF STAGES pr</context>
<context position="12789" citStr="Nesson et al., 2005" startWordPosition="2566" endWordPosition="2569"> U W =� 0, and sel(κ) = 1 otherwise. In other words, sel chooses the next site to operate on. Then we define in the same way as ==�- but in each of the cases we require that w = sel(κ1). Moreover, for every derivation d E D, we denote by next(d) the set of all derivations of the form duκ where last(d) =u=&gt;sel κ. The generative model of G comprises all the generative stories of G. A generative story is a tree t E UD; the root of t is labeled by κin. Let w E pos(t) and t(w) = d. Then either w is a leaf, because we have stopped the generative story 4We note that a different definition occurs in (Nesson et al., 2005, 2006). at w, or w has |next(d) |children, each one represents exactly one possible decision about how to extend d by a single derivation step (where their order does not matter). Then, for every generative story t, we have that � P(t(w)) = 1 . w∈lv(t) We note that (D, next, µ) can be considered as a discrete Markov chain (cf., e.g. (Baier et al., 2009)) where the initial probability distribution µ : D —* [0, 1] maps d = κin to 1, and all the other derivations to 0. A probabilistic synchronous tree insertion grammar (pSTIG) G is a pSTAG except that for every rule r = (ζs, ζt, V, W, Pradj) or </context>
</contexts>
<marker>Nesson, Shieber, Rush, 2005</marker>
<rawString>R. Nesson, S.M. Shieber, and A. Rush. Induction of probabilistic synchronous tree-insertion grammars. Technical Report TR-20-05, Computer Science Group, Harvard Univeristy, Cambridge, Massachusetts, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Nesson</author>
<author>S M Shieber</author>
<author>A Rush</author>
</authors>
<title>Induction of probabilistic synchronous tree-inserting grammars for machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA</booktitle>
<marker>Nesson, Shieber, Rush, 2006</marker>
<rawString>R. Nesson, S.M. Shieber, and A. Rush. Induction of probabilistic synchronous tree-inserting grammars for machine translation. In Proceedings of the 7th Conference of the Association for Machine Translation in the Americas (AMTA 2006), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>R C Waters</author>
</authors>
<title>Tree insertion grammars: a cubic-time, parsable formalism that lexicalizes context-free grammar without changing the trees produced.</title>
<date>1994</date>
<journal>Computational Linguistics,</journal>
<volume>21</volume>
<contexts>
<context position="1518" citStr="Schabes and Waters, 1994" startWordPosition="226" endWordPosition="230"> two units arbitrarily far apart in subsequent derivation steps. For machine translation (MT) between two natural languages, each being generated by a TAG, the derivations of the two TAG may be synchronized (Abeille et al., 1990; Shieber and Shabes, 1990) in the spirit of syntaxdirected transductions (Lewis and Stearns, 1968); this results in synchronous TAG (STAG). Recently, in (Nesson et al., 2005, 2006) probabilistic synchronous tree insertion grammars (pSTIG) were discussed as model of MT; a tree insertion grammar is a particular TAG in which the parsing problem is solvable in cubic-time (Schabes and Waters, 1994). In (DeNeefe, 2009; DeNeefe and Knight 2009) a decoder for pSTIG has been proposed which transforms source-language strings into (modifications of) derivation trees of the pSTIG. Nowadays, large-scale linguistic STAG rule bases are available. In an independent tradition, the automatatheoretic investigation of the translation of trees ∗ financially supported by NSF STAGES project, grant #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transd</context>
</contexts>
<marker>Schabes, Waters, 1994</marker>
<rawString>Y. Schabes, R.C. Waters. Tree insertion grammars: a cubic-time, parsable formalism that lexicalizes context-free grammar without changing the trees produced. Computational Linguistics, 21:479–513, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P P Schreiber</author>
</authors>
<title>Tree-transducers and syntax-connected transductions.</title>
<date>1975</date>
<booktitle>In Automata Theory and Formal Languages, Lecture Notes in Computer Science 33,</booktitle>
<pages>202--208</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="2572" citStr="Schreiber (1975)" startWordPosition="394" endWordPosition="395">1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the target tree using an embedded tree transducer (Shieber, 2006). We p</context>
</contexts>
<marker>Schreiber, 1975</marker>
<rawString>P.P. Schreiber. Tree-transducers and syntax-connected transductions. In Automata Theory and Formal Languages, Lecture Notes in Computer Science 33, pp. 202–208, Springer, 1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Synchronous grammars and tree transducers.</title>
<date>2004</date>
<booktitle>In Proc. 7th Workshop on Tree Adjoining Grammars and Related Formalisms,</booktitle>
<pages>88--95</pages>
<contexts>
<context position="2653" citStr="Shieber (2004" startWordPosition="405" endWordPosition="406">transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the target tree using an embedded tree transducer (Shieber, 2006). We propose a transducer model, called a bottom-up tree adjoining transducer, which pe</context>
</contexts>
<marker>Shieber, 2004</marker>
<rawString>S.M. Shieber. Synchronous grammars and tree transducers. In Proc. 7th Workshop on Tree Adjoining Grammars and Related Formalisms, pp. 88–95, 2004.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Unifying synchronous tree-adjoining grammars and tree transducers via bimorphisms. In</title>
<date>2006</date>
<booktitle>Proc. 11th Conf. European Chapter of ACL, EACL 06,</booktitle>
<pages>377--384</pages>
<contexts>
<context position="3166" citStr="Shieber, 2006" startWordPosition="485" endWordPosition="486">and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second, the derivation tree is transformed into the target tree using an embedded tree transducer (Shieber, 2006). We propose a transducer model, called a bottom-up tree adjoining transducer, which performs this decoding in a single step and, simultaneously, computes the probabilities of its derivations. As a basis of our approach, we present a formal definition of pSTIG. 2 Preliminaries For two sets E and A, we let UE(A) be the set of all (unranked) trees over E in which also elements of A may label leaves. We abbreviate UE(∅) by UE. We denote the set of positions, leaves, and non-leaves of � E UE by pos(�) C N*, lv(�), and nlv(�), resp., where E denotes the root of � and w�i denotes the ith child of po</context>
<context position="25466" citStr="Shieber, 2006" startWordPosition="5085" endWordPosition="5086">a corresponding derivation of dec(G), with the same probability, and vice versa. The derivations proceed in opposite directions. Each sentential form in one has an equivalent sentential form in the other, and each step of the derivations correspond. There is no space to present the full proof, but let us give a slightly more precise idea about the formal relationship between the derivations of G and dec(G). In the usual way we can associate a derivation tree dt with every successful derivation d of G. Assume that last(d) = (ξs, ξt, ∅, ∅, ∅), and let Es and Et be the embedded tree transducers (Shieber, 2006) associated with, respectively, the source component and the target component of G. Then it was shown in (Shieber, 2006) that τE3(dt) = ξs and τEt(dt) = ξt where τE denotes the tree-to-tree transduction computed by an embedded tree transducer E. Roughly speaking, Es and Et reproduce the derivations of, respectively, the source component and the target component of G that are prescribed by dt. Thus, for κ = (ξ′ s, ξ′ t,V, W, g), if κin ⇒∗G κ and κ is a prefix of d, then there is exactly one subtree dt[(w, w′)] of dt associated with every (w, w′) ∈ V ∪ W, which prescribes how to continue at (w, </context>
</contexts>
<marker>Shieber, 2006</marker>
<rawString>S.M. Shieber. Unifying synchronous tree-adjoining grammars and tree transducers via bimorphisms. In Proc. 11th Conf. European Chapter of ACL, EACL 06, pp. 377–384, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
<author>Y Schabes</author>
</authors>
<title>Synchronous tree-adjoining grammars.</title>
<date>1990</date>
<booktitle>In Proceedings of the 13th International Conference on Computational Linguistics,</booktitle>
<volume>3</volume>
<pages>253--258</pages>
<location>Helsinki, Finland,</location>
<marker>Shieber, Schabes, 1990</marker>
<rawString>S.M. Shieber, Y. Schabes. Synchronous tree-adjoining grammars. In Proceedings of the 13th International Conference on Computational Linguistics, volume 3, pp. 253–258, Helsinki, Finland, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>D J Weir</author>
</authors>
<title>The equivalence of four extensions of context-free grammars.</title>
<date>1994</date>
<booktitle>Mathematical Systems Theory,</booktitle>
<pages>27--511</pages>
<marker>Vijay-Shanker, Weir, 1994</marker>
<rawString>K. Vijay-Shanker, D.J. Weir. The equivalence of four extensions of context-free grammars. Mathematical Systems Theory, 27:511–546, 1994.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Yamada</author>
<author>K Knight</author>
</authors>
<title>A syntax-based statistical translation model.</title>
<date>2001</date>
<booktitle>In Proc. of 39th Annual Meeting of the Assoc. Computational Linguistics,</booktitle>
<pages>523--530</pages>
<contexts>
<context position="2459" citStr="Yamada and Knight, 2001" startWordPosition="373" endWordPosition="376">anslation of trees ∗ financially supported by NSF STAGES project, grant #IIS-0908532. † financially supported by DFG VO 1011/5-1. 1see (Joshi and Shabes, 1997) for a survey led to the rich theory of tree transducers (G´ecseg and Steinby, 1984, 1997). Roughly speaking, a tree transducer is a finite term rewriting system. If each rewrite rule carries a probablity or, in general, a weight from some semiring, then they are weighted tree transducers (Maletti, 2006, 2006a; F¨ul¨op and Vogler, 2009). Such weighted tree transducers have also been used for the specification of MT of natural languages (Yamada and Knight, 2001; Knight and Graehl, 2005; Graehl et al., 2008; Knight and May 2009). Martin and Vere (1970) and Schreiber (1975) established the first connections between the two traditions; also Shieber (2004, 2006) and Maletti (2008, 2010) investigated their relationship. The problem addressed in this paper is the decoding of source-language strings into targetlanguage trees where the transformation is described by a pSTIG. Currently, this decoding requires two steps: first, every source string is translated into a derivation tree of the underlying pSTIG (DeNeefe, 2009; DeNeefe and Knight 2009), and second</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>K. Yamada and K. Knight. A syntax-based statistical translation model. In Proc. of 39th Annual Meeting of the Assoc. Computational Linguistics, pp. 523– 530, 2001.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>