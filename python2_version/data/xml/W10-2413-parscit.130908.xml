<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.011157">
<title confidence="0.984006">
Phrase-based Transliteration System with Simple Heuristics
</title>
<author confidence="0.781075">
Avinesh PVS and Ankur Parikh
</author>
<affiliation confidence="0.88296">
IIIT Hyderabad
Language Technologies Research Centre
</affiliation>
<email confidence="0.992737">
{avinesh,shaileshkumar.parikh}@students.iiit.ac.in
</email>
<sectionHeader confidence="0.997304" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999979333333333">
This paper presents modeling of translit-
eration as a phrase-based machine transla-
tion system. We used a popular phrase-
based machine translation system for
English-Hindi machine transliteration. We
have achieved an accuracy of 38.1% on the
test set. We used some basic rules to mod-
ulate the existing phrased-based transliter-
ation system. Our experiments show that
phrase-based machine translation systems
can be adopted by modulating the system
to fit the transliteration problem.
</bodyText>
<sectionHeader confidence="0.999394" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999935053571429">
Transliteration is the practice of converting a text
from one writing system into another in a system-
atic way. Most significantly it is used in Machine
Translation (MT) systems, Information Retrieval
systems where a large portion of unknown words
(out of vocabulary) are observed. Named enti-
ties (NE), technical words, borrowed words and
loan words constitute the majority of the unknown
words. So, transliteration can also be termed as
the process of obtaining the phonetic translation
of names across various languages (Shishtla et al.,
2009). Transcribing the words from one language
to another without the help of bilingual dictionary
is a challenging task.
Previous work in transliteration include
(Surana and Singh, 2009) who propose a translit-
eration system using two different approaches
of transliterating the named entities based on
their origin. (Sherif and Kondrak, 2007) use
the Viterbi based monotone search algorithm for
searching possible candidate sub-string translit-
erations. (Malik, 2006) solved some special
cases of transliteration for Punjabi using a set of
transliteration rules.
In the recent years Statistical Machine Trans-
lation (SMT) systems (Brown et al., 1990), (Ya-
mada and Knight, 2001), (Chiang, 2005), (Char-
niak et al., 2003) have been in focus. It is easy
to develop a MT system for a new pair of lan-
guage using an existing SMT system and a par-
allel corpora. It isn’t a surprise to see SMT being
attractive in terms of less human labour as com-
pared to other traditional systems. These SMT
systems have also become popular in the transliter-
ation field (Finch and Sumita, 2008), (Finch and
Sumita, 2009), (Rama and Gali, 2009). (Finch
and Sumita, 2008) use a bi-directional decoder
whereas (Finch and Sumita, 2009) use a machine
translation system comprising of two phrase-based
decoders. The first decoder generated from first
token of the target to the last. The second decoder
generated the target from last to first. (Rama and
Gali, 2009) modeled the phrase-based SMT sys-
tem using minimum error rate training (MERT) for
learning model weights.
In this paper we present a phrase-based ma-
chine transliteration technique with simple heuris-
tics for transliterating named entities of English-
Hindi pair using small amount of training and de-
velopment data. The structure of our paper is as
follows. Section 2 describes the modeling of trans-
lation problem to transliteration. Modeling of the
parameters and the heuristics are presented in Sec-
tion 3. Section 4 and 5 we give a brief description
about the data-set and error-analysis. Finally we
conclude in Section 6.
</bodyText>
<sectionHeader confidence="0.794056" genericHeader="method">
2 Modeling Approach
</sectionHeader>
<bodyText confidence="0.99844">
Transliteration can be viewed as a task of
character-level machine translation process. Both
the problems involve transformation of source to-
kens in one language to target tokens in another
language.
Transliteration differs from machine translation in
two ways (Finch and Sumita, 2009):
</bodyText>
<listItem confidence="0.780209">
1. Reordering of the target tokens is generally
</listItem>
<page confidence="0.964049">
81
</page>
<note confidence="0.7298865">
Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 81–84,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<figure confidence="0.885946333333333">
HANUMAN
hanumAna
hanuman
hanumAna
h a num a n
h a num A na
h a n u m a n
h a n u m A n a
Input Lowercase After Giza Alignments Post−Processing
</figure>
<figureCaption confidence="0.9844645">
Figure 1: English-Hindi transliteration example through our system(To represent Hindi font roman script
is used)
</figureCaption>
<bodyText confidence="0.971764928571429">
abscent in transliteration.
2. Number of token types (vocabulary) in the
data is relatively very less and finite as com-
pared to the translation data.
The work in this paper is related to the work of
(Rama and Gali, 2009) who also use SMT directly
to transliterate. We can model the translation
problem to transliteration problem by replacing
words with characters. So instead of sentences
let us assume a given word is represented as a
sequence of characters of the source language
F=f1,f2,f3,...fn which needs to be transcribed as
a sequence of characters in the target language
E=e1,e2,e3,...em.
</bodyText>
<equation confidence="0.734453">
1
</equation>
<bodyText confidence="0.998722666666667">
The best possible target language sequence of
characters among the possible candidate charac-
ters can be represented as:
</bodyText>
<equation confidence="0.803541">
Ebest = ArgmaxE P(E|F)
</equation>
<bodyText confidence="0.999763">
The above equation can be represented in terms
of noisy channel model using Bayes Rule:
</bodyText>
<equation confidence="0.86906">
Ebest = ArgmaxE P(F|E) * P(E)
</equation>
<bodyText confidence="0.997538222222222">
Here P(F|E) represents the transcription model
where as P(E) represents the language model i.e
the character n-gram of the target language. The
above equation returns the best possible output
sequence of characters for the given sequence of
characters F.
We used some heuristics on top of Moses tool
kit, which is a publicly available tool provided by
(Hoang et al., 2007).
</bodyText>
<footnote confidence="0.817387">
1F,E is used to name source and target language sequences
as used in conventional machine translation notations
</footnote>
<sectionHeader confidence="0.997878" genericHeader="method">
3 Method
</sectionHeader>
<subsectionHeader confidence="0.999949">
3.1 Pre-processing
</subsectionHeader>
<bodyText confidence="0.999981875">
Firstly the data on the English side is converted to
lowercase to reduce data sparsity. Each character
of the words in the training and development data
are separated with spaces. We also came across
multi-word sequences which posed a challenge for
our approach. We segmented the multi-words into
separate words, such that they would be transliter-
ated as different words.
</bodyText>
<subsectionHeader confidence="0.999558">
3.2 Alignment and Post Processing
</subsectionHeader>
<bodyText confidence="0.999103857142857">
Parallel word lists are given to GIZA++ for char-
acter alignments. We observed grow-diag-final-
and as the best alignment heuristic. From the
differences mentioned above between translitera-
tion and translation we came up with some simple
heuristics to do post processing on the GIZA++
alignments.
</bodyText>
<listItem confidence="0.908021454545455">
1. As reordering of the target tokens is not al-
lowed in transliteration. Crossing of the arcs
during the alignments are removed.
As shown in Fig 1. above.
The second A —* a is removed as it was cross-
ing the arcs.
2. If the target character is aligned to NULL
character on the source side then the NULL
is removed, and the target language character
is aligned to the source character aligned to
previous target character.
</listItem>
<equation confidence="0.53470525">
From Fig 1.
n —* n
NULL —* a
to
</equation>
<page confidence="0.971786">
82
</page>
<bodyText confidence="0.930734">
n—*na
</bodyText>
<subsectionHeader confidence="0.995696">
3.3 Training and Parameter Tuning
</subsectionHeader>
<bodyText confidence="0.999919823529412">
The language models and translation models were
built on the combined training and the develop-
ment data. But the learning of log-linear weights
during the MERT step is done using development
data separately. It is obvious that the system would
perform better if it was trained on the combined
data. 8-gram language model and a maximum
phrase length of 7 is used during training.
The transliteration systems were modeled using
the minimum error rate training procedure intro-
duced by (Och, 2003). We used BLUE score as a
evaluation metric for our convenience during tun-
ing. BLUE score is commonly used to evaluate
machine translation systems and it is a function of
geometric mean of n-gram precision. It was ob-
served that improvement of the BLUE score also
showed improvements in ACC.
</bodyText>
<sectionHeader confidence="0.998652" genericHeader="method">
4 Experiments and Results
</sectionHeader>
<bodyText confidence="0.998459368421053">
Training data of 9975 words is used to build
the system models, while the development data
of 1974 words is used for tuning the log-linear
weights for the translation engines. Our accuracies
on test-data are reported in Table 1. Due to time
constraints we couldn’t focus on multiple correct
answers in the training data, we picked just the
first one for our training. Some of the translation
features like word penalty, phrase penalty, reorder
parameters don’t play any role in transliteration
process hence we didn’t include them.
Before the release of the test-data we tested the
system without tuning i.e. default weights were
used on the development data. Later once the test-
data was released the system was tuned on the de-
velopment data to model the weights. We evalu-
ated our system on ACC which accounts for Word
Accuracy for top-1, Mean F-score, Mean Recipro-
cal Rank (MRR).
</bodyText>
<tableCaption confidence="0.999819">
Table 1: Evaluation on Test Data
</tableCaption>
<table confidence="0.9957662">
Measure Result
ACC 0.381
Mean F-score 0.860
MRR 0.403
MAPTef 0.381
</table>
<sectionHeader confidence="0.990066" genericHeader="method">
5 Error Analysis
</sectionHeader>
<bodyText confidence="0.9999666">
From the reference corpora we examined that ma-
jority of the errors were due to foreign origin
words. As the phonetic transcription of these
words is different from the other words. We also
observed from error analysis that the correct tar-
get sequence of characters were occurring at lower
rank in the 20-best list. We would like to see how
different ranking mechanisms like SVM re-rank
etc would help in boosting the correct accuracies
of the system.
</bodyText>
<sectionHeader confidence="0.995522" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999054285714286">
In this paper we show that the usage of some
heuristics on top of popular phrase-based machine
translation works well for the task of translit-
eration. First the source and target characters
are aligned using GIZA++. Then some heuris-
tics are used to modify the alignments. These
modified alignments are used during estimation
of the weights during minimum error rate train-
ing (MERT). Finally the Hindi characters are de-
coded using the beam-search based decoder. We
also produced the 20-best outputs using the n-best
list provided by moses toolkit. It is very interesting
to see how simple heuristics helped in performing
better than other systems.
</bodyText>
<sectionHeader confidence="0.99916" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990023428571428">
Peter F. Brown, John Cocke, Stephen A. Della Pietra,
Vincent J. Della Pietra, Fredrick Jelinek, John D.
Lafferty, Robert L. Mercer, and Paul S. Roossin.
1990. A statistical approach to machine translation.
COMPUTATIONAL LINGUISTICS, 16(2):79–85.
Eugene Charniak, Kevin Knight, and Kenji Yamada.
2003. Syntax-based language models for statistical
machine translation. In MT Summit IY Intl. Assoc.
for Machine Translation.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In In ACL,
pages 263–270.
Andrew Finch and Eiichiro Sumita. 2008. Phrase-
based machine transliteration. In In Proc. 3rd Int’l.
Joint ConfNLP, volume 1.
Andrew Finch and Eiichiro Sumita. 2009. Translit-
eration by bidirectional statistical machine transla-
tion. In NEWS ’09: Proceedings of the 2009 Named
Entities Workshop: Shared Task on Transliteration,
pages 52–56, Morristown, NJ, USA. Association for
Computational Linguistics.
</reference>
<page confidence="0.994996">
83
</page>
<reference confidence="0.989919555555556">
Hieu Hoang, Alexandra Birch, Chris Callison-burch,
Richard Zens, Rwth Aachen, Alexandra Constantin,
Marcello Federico, Nicola Bertoldi, Chris Dyer,
Brooke Cowan, Wade Shen, Christine Moran, and
Ondej Bojar. 2007. Moses: Open source toolkit for
statistical machine translation. pages 177–180.
M. G. Abbas Malik. 2006. Punjabi machine translit-
eration. In ACL-44: Proceedings of the 21st Inter-
national Conference on Computational Linguistics
and the 44th annual meeting of the Association for
Computational Linguistics, pages 1137–1144, Mor-
ristown, NJ, USA. Association for Computational
Linguistics.
Franz Josef Och. 2003. Minimum error rate train-
ing in statistical machine translation. In ACL ’03:
Proceedings of the 41st Annual Meeting on Asso-
ciation for Computational Linguistics, pages 160–
167, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Taraka Rama and Karthik Gali. 2009. Modeling ma-
chine transliteration as a phrase based statistical ma-
chine translation problem. In NEWS ’09: Proceed-
ings of the 2009 Named Entities Workshop: Shared
Task on Transliteration, pages 124–127, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
Tarek Sherif and Grzegorz Kondrak. 2007. Substring-
based transliteration. In Proceedings of the 45th An-
nual Meeting of the Association of Computational
Linguistics, pages 944–951, Prague, Czech Repub-
lic, June. Association for Computational Linguis-
tics.
Praneeth Shishtla, V. Surya Ganesh, Sethuramalingam
Subramaniam, and Vasudeva Varma. 2009. A
language-independent transliteration schema using
character aligned models at news 2009. In NEWS
’09: Proceedings of the 2009 Named Entities Work-
shop: Shared Task on Transliteration, pages 40–
43, Morristown, NJ, USA. Association for Compu-
tational Linguistics.
Harshit Surana and Anil Kumar Singh. 2009. Digitiz-
ing The Legacy ofIndian Languages. ICFAI Books,
Hyderabad.
Kenji Yamada and Kevin Knight. 2001. A syntax-
based statistical translation model. pages 523–530.
</reference>
<page confidence="0.999234">
84
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.559600">
<title confidence="0.75606375">Phrase-based Transliteration System with Simple Heuristics PVS IIIT Language Technologies Research</title>
<abstract confidence="0.998972384615385">This paper presents modeling of transliteration as a phrase-based machine translation system. We used a popular phrasebased machine translation system for English-Hindi machine transliteration. We have achieved an accuracy of 38.1% on the test set. We used some basic rules to modulate the existing phrased-based transliteration system. Our experiments show that phrase-based machine translation systems can be adopted by modulating the system to fit the transliteration problem.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>John Cocke</author>
<author>Stephen A Della Pietra</author>
<author>Vincent J Della Pietra</author>
<author>Fredrick Jelinek</author>
<author>John D Lafferty</author>
<author>Robert L Mercer</author>
<author>Paul S Roossin</author>
</authors>
<title>A statistical approach to machine translation.</title>
<date>1990</date>
<journal>COMPUTATIONAL LINGUISTICS,</journal>
<volume>16</volume>
<issue>2</issue>
<contexts>
<context position="1885" citStr="Brown et al., 1990" startWordPosition="268" endWordPosition="271">rom one language to another without the help of bilingual dictionary is a challenging task. Previous work in transliteration include (Surana and Singh, 2009) who propose a transliteration system using two different approaches of transliterating the named entities based on their origin. (Sherif and Kondrak, 2007) use the Viterbi based monotone search algorithm for searching possible candidate sub-string transliterations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared to other traditional systems. These SMT systems have also become popular in the transliteration field (Finch and Sumita, 2008), (Finch and Sumita, 2009), (Rama and Gali, 2009). (Finch and Sumita, 2008) use a bi-directional decoder whereas (Finch and Sumita, 2009) use a machine translation system comprising</context>
</contexts>
<marker>Brown, Cocke, Pietra, Pietra, Jelinek, Lafferty, Mercer, Roossin, 1990</marker>
<rawString>Peter F. Brown, John Cocke, Stephen A. Della Pietra, Vincent J. Della Pietra, Fredrick Jelinek, John D. Lafferty, Robert L. Mercer, and Paul S. Roossin. 1990. A statistical approach to machine translation. COMPUTATIONAL LINGUISTICS, 16(2):79–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Kevin Knight</author>
<author>Kenji Yamada</author>
</authors>
<title>Syntax-based language models for statistical machine translation.</title>
<date>2003</date>
<booktitle>In MT Summit IY Intl. Assoc. for Machine Translation.</booktitle>
<contexts>
<context position="1953" citStr="Charniak et al., 2003" startWordPosition="279" endWordPosition="283">ary is a challenging task. Previous work in transliteration include (Surana and Singh, 2009) who propose a transliteration system using two different approaches of transliterating the named entities based on their origin. (Sherif and Kondrak, 2007) use the Viterbi based monotone search algorithm for searching possible candidate sub-string transliterations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared to other traditional systems. These SMT systems have also become popular in the transliteration field (Finch and Sumita, 2008), (Finch and Sumita, 2009), (Rama and Gali, 2009). (Finch and Sumita, 2008) use a bi-directional decoder whereas (Finch and Sumita, 2009) use a machine translation system comprising of two phrase-based decoders. The first decoder generated from firs</context>
</contexts>
<marker>Charniak, Knight, Yamada, 2003</marker>
<rawString>Eugene Charniak, Kevin Knight, and Kenji Yamada. 2003. Syntax-based language models for statistical machine translation. In MT Summit IY Intl. Assoc. for Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation. In</title>
<date>2005</date>
<booktitle>In ACL,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="1928" citStr="Chiang, 2005" startWordPosition="277" endWordPosition="278">ilingual dictionary is a challenging task. Previous work in transliteration include (Surana and Singh, 2009) who propose a transliteration system using two different approaches of transliterating the named entities based on their origin. (Sherif and Kondrak, 2007) use the Viterbi based monotone search algorithm for searching possible candidate sub-string transliterations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared to other traditional systems. These SMT systems have also become popular in the transliteration field (Finch and Sumita, 2008), (Finch and Sumita, 2009), (Rama and Gali, 2009). (Finch and Sumita, 2008) use a bi-directional decoder whereas (Finch and Sumita, 2009) use a machine translation system comprising of two phrase-based decoders. The first de</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In In ACL, pages 263–270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Phrasebased machine transliteration. In</title>
<date>2008</date>
<booktitle>In Proc. 3rd Int’l. Joint ConfNLP,</booktitle>
<volume>1</volume>
<contexts>
<context position="2304" citStr="Finch and Sumita, 2008" startWordPosition="347" endWordPosition="350">rations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared to other traditional systems. These SMT systems have also become popular in the transliteration field (Finch and Sumita, 2008), (Finch and Sumita, 2009), (Rama and Gali, 2009). (Finch and Sumita, 2008) use a bi-directional decoder whereas (Finch and Sumita, 2009) use a machine translation system comprising of two phrase-based decoders. The first decoder generated from first token of the target to the last. The second decoder generated the target from last to first. (Rama and Gali, 2009) modeled the phrase-based SMT system using minimum error rate training (MERT) for learning model weights. In this paper we present a phrase-based machine transliteration technique with simple heuristics for transliterating named entiti</context>
</contexts>
<marker>Finch, Sumita, 2008</marker>
<rawString>Andrew Finch and Eiichiro Sumita. 2008. Phrasebased machine transliteration. In In Proc. 3rd Int’l. Joint ConfNLP, volume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrew Finch</author>
<author>Eiichiro Sumita</author>
</authors>
<title>Transliteration by bidirectional statistical machine translation.</title>
<date>2009</date>
<booktitle>In NEWS ’09: Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration,</booktitle>
<pages>52--56</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2330" citStr="Finch and Sumita, 2009" startWordPosition="351" endWordPosition="354">ved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared to other traditional systems. These SMT systems have also become popular in the transliteration field (Finch and Sumita, 2008), (Finch and Sumita, 2009), (Rama and Gali, 2009). (Finch and Sumita, 2008) use a bi-directional decoder whereas (Finch and Sumita, 2009) use a machine translation system comprising of two phrase-based decoders. The first decoder generated from first token of the target to the last. The second decoder generated the target from last to first. (Rama and Gali, 2009) modeled the phrase-based SMT system using minimum error rate training (MERT) for learning model weights. In this paper we present a phrase-based machine transliteration technique with simple heuristics for transliterating named entities of EnglishHindi pair us</context>
<context position="3595" citStr="Finch and Sumita, 2009" startWordPosition="550" endWordPosition="553">nt data. The structure of our paper is as follows. Section 2 describes the modeling of translation problem to transliteration. Modeling of the parameters and the heuristics are presented in Section 3. Section 4 and 5 we give a brief description about the data-set and error-analysis. Finally we conclude in Section 6. 2 Modeling Approach Transliteration can be viewed as a task of character-level machine translation process. Both the problems involve transformation of source tokens in one language to target tokens in another language. Transliteration differs from machine translation in two ways (Finch and Sumita, 2009): 1. Reordering of the target tokens is generally 81 Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 81–84, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics HANUMAN hanumAna hanuman hanumAna h a num a n h a num A na h a n u m a n h a n u m A n a Input Lowercase After Giza Alignments Post−Processing Figure 1: English-Hindi transliteration example through our system(To represent Hindi font roman script is used) abscent in transliteration. 2. Number of token types (vocabulary) in the data is relatively very less and finite as compared to the transla</context>
</contexts>
<marker>Finch, Sumita, 2009</marker>
<rawString>Andrew Finch and Eiichiro Sumita. 2009. Transliteration by bidirectional statistical machine translation. In NEWS ’09: Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration, pages 52–56, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hieu Hoang</author>
<author>Alexandra Birch</author>
<author>Chris Callison-burch</author>
<author>Richard Zens</author>
<author>Rwth Aachen</author>
<author>Alexandra Constantin</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Chris Dyer</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
<author>Christine Moran</author>
<author>Ondej Bojar</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<pages>177--180</pages>
<contexts>
<context position="5289" citStr="Hoang et al., 2007" startWordPosition="833" endWordPosition="836">ble target language sequence of characters among the possible candidate characters can be represented as: Ebest = ArgmaxE P(E|F) The above equation can be represented in terms of noisy channel model using Bayes Rule: Ebest = ArgmaxE P(F|E) * P(E) Here P(F|E) represents the transcription model where as P(E) represents the language model i.e the character n-gram of the target language. The above equation returns the best possible output sequence of characters for the given sequence of characters F. We used some heuristics on top of Moses tool kit, which is a publicly available tool provided by (Hoang et al., 2007). 1F,E is used to name source and target language sequences as used in conventional machine translation notations 3 Method 3.1 Pre-processing Firstly the data on the English side is converted to lowercase to reduce data sparsity. Each character of the words in the training and development data are separated with spaces. We also came across multi-word sequences which posed a challenge for our approach. We segmented the multi-words into separate words, such that they would be transliterated as different words. 3.2 Alignment and Post Processing Parallel word lists are given to GIZA++ for characte</context>
</contexts>
<marker>Hoang, Birch, Callison-burch, Zens, Aachen, Constantin, Federico, Bertoldi, Dyer, Cowan, Shen, Moran, Bojar, 2007</marker>
<rawString>Hieu Hoang, Alexandra Birch, Chris Callison-burch, Richard Zens, Rwth Aachen, Alexandra Constantin, Marcello Federico, Nicola Bertoldi, Chris Dyer, Brooke Cowan, Wade Shen, Christine Moran, and Ondej Bojar. 2007. Moses: Open source toolkit for statistical machine translation. pages 177–180.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M G Abbas Malik</author>
</authors>
<title>Punjabi machine transliteration. In</title>
<date>2006</date>
<booktitle>ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>1137--1144</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1703" citStr="Malik, 2006" startWordPosition="242" endWordPosition="243">So, transliteration can also be termed as the process of obtaining the phonetic translation of names across various languages (Shishtla et al., 2009). Transcribing the words from one language to another without the help of bilingual dictionary is a challenging task. Previous work in transliteration include (Surana and Singh, 2009) who propose a transliteration system using two different approaches of transliterating the named entities based on their origin. (Sherif and Kondrak, 2007) use the Viterbi based monotone search algorithm for searching possible candidate sub-string transliterations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared to other traditional systems. These SMT systems have also become popular in the transliteration field (Finch and Sumita, 2008</context>
</contexts>
<marker>Malik, 2006</marker>
<rawString>M. G. Abbas Malik. 2006. Punjabi machine transliteration. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 1137–1144, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
</authors>
<title>Minimum error rate training in statistical machine translation.</title>
<date>2003</date>
<booktitle>In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>160--167</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="7120" citStr="Och, 2003" startWordPosition="1141" endWordPosition="1142">ter aligned to previous target character. From Fig 1. n —* n NULL —* a to 82 n—*na 3.3 Training and Parameter Tuning The language models and translation models were built on the combined training and the development data. But the learning of log-linear weights during the MERT step is done using development data separately. It is obvious that the system would perform better if it was trained on the combined data. 8-gram language model and a maximum phrase length of 7 is used during training. The transliteration systems were modeled using the minimum error rate training procedure introduced by (Och, 2003). We used BLUE score as a evaluation metric for our convenience during tuning. BLUE score is commonly used to evaluate machine translation systems and it is a function of geometric mean of n-gram precision. It was observed that improvement of the BLUE score also showed improvements in ACC. 4 Experiments and Results Training data of 9975 words is used to build the system models, while the development data of 1974 words is used for tuning the log-linear weights for the translation engines. Our accuracies on test-data are reported in Table 1. Due to time constraints we couldn’t focus on multiple </context>
</contexts>
<marker>Och, 2003</marker>
<rawString>Franz Josef Och. 2003. Minimum error rate training in statistical machine translation. In ACL ’03: Proceedings of the 41st Annual Meeting on Association for Computational Linguistics, pages 160– 167, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taraka Rama</author>
<author>Karthik Gali</author>
</authors>
<title>Modeling machine transliteration as a phrase based statistical machine translation problem.</title>
<date>2009</date>
<booktitle>In NEWS ’09: Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration,</booktitle>
<pages>124--127</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2353" citStr="Rama and Gali, 2009" startWordPosition="355" endWordPosition="358">transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared to other traditional systems. These SMT systems have also become popular in the transliteration field (Finch and Sumita, 2008), (Finch and Sumita, 2009), (Rama and Gali, 2009). (Finch and Sumita, 2008) use a bi-directional decoder whereas (Finch and Sumita, 2009) use a machine translation system comprising of two phrase-based decoders. The first decoder generated from first token of the target to the last. The second decoder generated the target from last to first. (Rama and Gali, 2009) modeled the phrase-based SMT system using minimum error rate training (MERT) for learning model weights. In this paper we present a phrase-based machine transliteration technique with simple heuristics for transliterating named entities of EnglishHindi pair using small amount of tra</context>
<context position="4276" citStr="Rama and Gali, 2009" startWordPosition="670" endWordPosition="673">ngs of the 2010 Named Entities Workshop, ACL 2010, pages 81–84, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics HANUMAN hanumAna hanuman hanumAna h a num a n h a num A na h a n u m a n h a n u m A n a Input Lowercase After Giza Alignments Post−Processing Figure 1: English-Hindi transliteration example through our system(To represent Hindi font roman script is used) abscent in transliteration. 2. Number of token types (vocabulary) in the data is relatively very less and finite as compared to the translation data. The work in this paper is related to the work of (Rama and Gali, 2009) who also use SMT directly to transliterate. We can model the translation problem to transliteration problem by replacing words with characters. So instead of sentences let us assume a given word is represented as a sequence of characters of the source language F=f1,f2,f3,...fn which needs to be transcribed as a sequence of characters in the target language E=e1,e2,e3,...em. 1 The best possible target language sequence of characters among the possible candidate characters can be represented as: Ebest = ArgmaxE P(E|F) The above equation can be represented in terms of noisy channel model using B</context>
</contexts>
<marker>Rama, Gali, 2009</marker>
<rawString>Taraka Rama and Karthik Gali. 2009. Modeling machine transliteration as a phrase based statistical machine translation problem. In NEWS ’09: Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration, pages 124–127, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tarek Sherif</author>
<author>Grzegorz Kondrak</author>
</authors>
<title>Substringbased transliteration.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<pages>944--951</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1579" citStr="Sherif and Kondrak, 2007" startWordPosition="224" endWordPosition="227">abulary) are observed. Named entities (NE), technical words, borrowed words and loan words constitute the majority of the unknown words. So, transliteration can also be termed as the process of obtaining the phonetic translation of names across various languages (Shishtla et al., 2009). Transcribing the words from one language to another without the help of bilingual dictionary is a challenging task. Previous work in transliteration include (Surana and Singh, 2009) who propose a transliteration system using two different approaches of transliterating the named entities based on their origin. (Sherif and Kondrak, 2007) use the Viterbi based monotone search algorithm for searching possible candidate sub-string transliterations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared t</context>
</contexts>
<marker>Sherif, Kondrak, 2007</marker>
<rawString>Tarek Sherif and Grzegorz Kondrak. 2007. Substringbased transliteration. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics, pages 944–951, Prague, Czech Republic, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Praneeth Shishtla</author>
<author>V Surya Ganesh</author>
<author>Sethuramalingam Subramaniam</author>
<author>Vasudeva Varma</author>
</authors>
<title>A language-independent transliteration schema using character aligned models at news</title>
<date>2009</date>
<booktitle>In NEWS ’09: Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration,</booktitle>
<pages>40--43</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1240" citStr="Shishtla et al., 2009" startWordPosition="174" endWordPosition="177">d by modulating the system to fit the transliteration problem. 1 Introduction Transliteration is the practice of converting a text from one writing system into another in a systematic way. Most significantly it is used in Machine Translation (MT) systems, Information Retrieval systems where a large portion of unknown words (out of vocabulary) are observed. Named entities (NE), technical words, borrowed words and loan words constitute the majority of the unknown words. So, transliteration can also be termed as the process of obtaining the phonetic translation of names across various languages (Shishtla et al., 2009). Transcribing the words from one language to another without the help of bilingual dictionary is a challenging task. Previous work in transliteration include (Surana and Singh, 2009) who propose a transliteration system using two different approaches of transliterating the named entities based on their origin. (Sherif and Kondrak, 2007) use the Viterbi based monotone search algorithm for searching possible candidate sub-string transliterations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine T</context>
</contexts>
<marker>Shishtla, Ganesh, Subramaniam, Varma, 2009</marker>
<rawString>Praneeth Shishtla, V. Surya Ganesh, Sethuramalingam Subramaniam, and Vasudeva Varma. 2009. A language-independent transliteration schema using character aligned models at news 2009. In NEWS ’09: Proceedings of the 2009 Named Entities Workshop: Shared Task on Transliteration, pages 40– 43, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harshit Surana</author>
<author>Anil Kumar Singh</author>
</authors>
<title>Digitizing The Legacy ofIndian Languages.</title>
<date>2009</date>
<publisher>ICFAI Books,</publisher>
<location>Hyderabad.</location>
<contexts>
<context position="1423" citStr="Surana and Singh, 2009" startWordPosition="201" endWordPosition="204">c way. Most significantly it is used in Machine Translation (MT) systems, Information Retrieval systems where a large portion of unknown words (out of vocabulary) are observed. Named entities (NE), technical words, borrowed words and loan words constitute the majority of the unknown words. So, transliteration can also be termed as the process of obtaining the phonetic translation of names across various languages (Shishtla et al., 2009). Transcribing the words from one language to another without the help of bilingual dictionary is a challenging task. Previous work in transliteration include (Surana and Singh, 2009) who propose a transliteration system using two different approaches of transliterating the named entities based on their origin. (Sherif and Kondrak, 2007) use the Viterbi based monotone search algorithm for searching possible candidate sub-string transliterations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair </context>
</contexts>
<marker>Surana, Singh, 2009</marker>
<rawString>Harshit Surana and Anil Kumar Singh. 2009. Digitizing The Legacy ofIndian Languages. ICFAI Books, Hyderabad.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Yamada</author>
<author>Kevin Knight</author>
</authors>
<title>A syntaxbased statistical translation model.</title>
<date>2001</date>
<pages>523--530</pages>
<contexts>
<context position="1912" citStr="Yamada and Knight, 2001" startWordPosition="272" endWordPosition="276">other without the help of bilingual dictionary is a challenging task. Previous work in transliteration include (Surana and Singh, 2009) who propose a transliteration system using two different approaches of transliterating the named entities based on their origin. (Sherif and Kondrak, 2007) use the Viterbi based monotone search algorithm for searching possible candidate sub-string transliterations. (Malik, 2006) solved some special cases of transliteration for Punjabi using a set of transliteration rules. In the recent years Statistical Machine Translation (SMT) systems (Brown et al., 1990), (Yamada and Knight, 2001), (Chiang, 2005), (Charniak et al., 2003) have been in focus. It is easy to develop a MT system for a new pair of language using an existing SMT system and a parallel corpora. It isn’t a surprise to see SMT being attractive in terms of less human labour as compared to other traditional systems. These SMT systems have also become popular in the transliteration field (Finch and Sumita, 2008), (Finch and Sumita, 2009), (Rama and Gali, 2009). (Finch and Sumita, 2008) use a bi-directional decoder whereas (Finch and Sumita, 2009) use a machine translation system comprising of two phrase-based decode</context>
</contexts>
<marker>Yamada, Knight, 2001</marker>
<rawString>Kenji Yamada and Kevin Knight. 2001. A syntaxbased statistical translation model. pages 523–530.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>