<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003108">
<title confidence="0.998032">
Active Semi-Supervised Learning for Improving Word Alignment
</title>
<author confidence="0.89979">
Vamshi Ambati, Stephan Vogel and Jaime Carbonell
</author>
<email confidence="0.821453">
{vamshi,vogel,jgc}@cs.cmu.edu
</email>
<affiliation confidence="0.8999275">
Language Technologies Institute, Carnegie Mellon University
5000 Forbes Avenue, Pittsburgh, PA 15213, USA
</affiliation>
<sectionHeader confidence="0.993743" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99929485">
Word alignment models form an important
part of building statistical machine transla-
tion systems. Semi-supervised word align-
ment aims to improve the accuracy of auto-
matic word alignment by incorporating full
or partial alignments acquired from humans.
Such dedicated elicitation effort is often ex-
pensive and depends on availability of bilin-
gual speakers for the language-pair. In this
paper we study active learning query strate-
gies to carefully identify highly uncertain or
most informative alignment links that are pro-
posed under an unsupervised word alignment
model. Manual correction of such informative
links can then be applied to create a labeled
dataset used by a semi-supervised word align-
ment model. Our experiments show that using
active learning leads to maximal reduction of
alignment error rates with reduced human ef-
fort.
</bodyText>
<sectionHeader confidence="0.999472" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.995370695652174">
The success of statistical approaches to Machine
Translation (MT) can be attributed to the IBM mod-
els (Brown et al., 1993) that characterize word-
level alignments in parallel corpora. Parameters of
these alignment models are learnt in an unsupervised
manner using the EM algorithm over sentence-level
aligned parallel corpora. While the ease of auto-
matically aligning sentences at the word-level with
tools like GIZA++ (Och and Ney, 2003) has enabled
fast development of statistical machine translation
(SMT) systems for various language pairs, the qual-
ity of alignment is typically quite low for language
pairs that diverge from the independence assump-
tions made by the generative models. Also, an im-
mense amount of parallel data enables better estima-
tion of the model parameters, but a large number of
language pairs still lack parallel data.
Two directions of research have been pursued for
improving generative word alignment. The first is to
relax or update the independence assumptions based
on more information, usually syntactic, from the
language pairs (Cherry and Lin, 2006). The sec-
ond is to use extra annotation, typically word-level
human alignment for some sentence pairs, in con-
junction with the parallel data to learn alignment in
a semi-supervised manner. Our research is in the
direction of the latter, and aims to reduce the effort
involved in hand-generation of word alignments by
using active learning strategies for careful selection
of word pairs to seek alignment.
Active learning for MT has not yet been explored
to its full potential. Much of the literature has ex-
plored one task – selecting sentences to translate
and add to the training corpus (Haffari et al., 2009).
In this paper we explore active learning for word
alignment, where the input to the active learner is
a sentence pair (si , ti), present in two different lan-
guages S = {s*} and T = {t*}, and the annotation
elicited from human is a set of links {(j, i) : j =
0 · · · J; i = 0 · · · I}. Unlike previous approaches,
our work does not require elicitation of full align-
ment for the sentence pair, which could be effort-
intensive. We use standard active learning query
strategies to selectively elicit partial alignment infor-
mation. This partial alignment information is then
fed into a semi-supervised word aligner which per-
</bodyText>
<page confidence="0.980997">
10
</page>
<note confidence="0.9665655">
Proceedings of the NAACL HLT 2010 Workshop on Active Learning for Natural Language Processing, pages 10–17,
Los Angeles, California, June 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.9987645">
forms an improved word alignment over the entire
parallel corpus.
Rest of the paper is organized as follows. We
present related work in Section 2. Section 3 gives
an overview of unsupervised word alignment mod-
els and its semi-supervised improvisation. Section 4
details our active learning framework with discus-
sion of the link selection strategies in Section 5. Ex-
periments in Section 6 have shown that our selection
strategies reduce alignment error rates significantly
over baseline. We conclude with discussion on fu-
ture work.
</bodyText>
<sectionHeader confidence="0.999943" genericHeader="introduction">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999946564516129">
Semi-supervised learning is a broader area of Ma-
chine Learning, focusing on improving the learn-
ing process by usage of unlabeled data in conjunc-
tion with labeled data (Chapelle et al., 2006). Many
semi-supervised learning algorithms use co-training
framework, which assumes that the dataset has mul-
tiple views, and training different classifiers on a
non-overlapping subset of these features provides
additional labeled data (Zhu, 2005). Active query
selection for training a semi-supervised learning al-
gorithm is an interesting method that has been ap-
plied to clustering problems. Tomanek and Hahn
(2009) applied active semi supervised learning to
the sequence-labeling problem. Tur et al. (2005) de-
scribe active and semi-supervised learning methods
for reducing labeling effort for spoken language un-
derstanding. They train supervised classification al-
gorithms for the task of call classification and apply
it to a large unlabeled dataset to select the least con-
fident instances for human labeling.
Researchers have begun to explore semi-
supervised word alignment models that use both
labeled and unlabeled data. Fraser and Marcu
(2006) pose the problem of alignment as a search
problem in log-linear space with features coming
from the IBM alignment models. The log-linear
model is trained on the available labeled data
to improve performance. They propose a semi-
supervised training algorithm which alternates
between discriminative error training on the la-
beled data to learn the weighting parameters and
maximum-likelihood EM training on unlabeled
data to estimate the parameters. Callison-Burch et
al. (2004) also improve alignment by interpolating
human alignments with automatic alignments. They
observe that while working with such datasets,
alignments of higher quality should be given a much
higher weight than the lower-quality alignments.
Wu et al. (2006) learn separate models from labeled
and unlabeled data using the standard EM algo-
rithm. The two models are then interpolated as a
learner in the semi-supervised AdaBoost algorithm
to improve word alignment.
Active learning has been applied to various fields
of Natural Language Processing like statistical pars-
ing, entity recognition among others (Hwa, 2004;
Tang et al., 2001; Shen et al., 2004). In case of
MT, the potential of active learning has remained
largely unexplored. For Statistical Machine Transla-
tion, application of active learning has been focused
on the task of selecting the most informative sen-
tences to train the model, in order to reduce cost
of data acquisition. Recent work in this area dis-
cussed multiple query selection strategies for a Sta-
tistical Phrase Based Translation system (Haffari et
al., 2009). Their framework requires source text to
be translated by the system and the translated data
is used in a self-training setting to train MT models.
To our knowledge, we are not aware of any work
that has looked at reducing human effort by selec-
tive elicitation of alignment information using active
learning techniques.
</bodyText>
<sectionHeader confidence="0.983064" genericHeader="method">
3 Word Alignment
</sectionHeader>
<subsectionHeader confidence="0.990105">
3.1 IBM models
</subsectionHeader>
<bodyText confidence="0.999378222222222">
IBM models provide a generative framework for
performing word alignment of parallel corpus.
Given two strings from source and target languages
sJ1 = s1,··· , sj, ··· sJ and tI1 = t1, ··· ,ti, ··· tI,
an alignment A is defined as a subset of the Carte-
sian product of the word indices as shown in Eq 1.
In IBM models, since alignment is treated as a func-
tion, all the source positions must be covered exactly
once (Brown et al., 1993).
</bodyText>
<equation confidence="0.632769">
A C {(j,i) : j = 0···J;i = 0 ··· I} (1)
</equation>
<bodyText confidence="0.9993725">
For the task of translation, we would ideally want
to model P(sI1�tJ1 ), which is the probability of ob-
serving source sentence sI1 given target sentence tJ1 .
This requires a lot of parallel corpus for estimation
</bodyText>
<page confidence="0.998486">
11
</page>
<bodyText confidence="0.958085333333333">
and so it is then factored over the word alignment
A for the sentence pair, which is a hidden variable.
Word alignment is therefore a by-product in the pro-
cess of modeling translation. We can also represent
the same under some parameterization of θ, which
is the model we are interested to estimate.
</bodyText>
<equation confidence="0.997185">
Pr(sJ1 , A|tJ1) (2)
pθ(sJ1 , A|tI1) (3)
</equation>
<bodyText confidence="0.9983308">
Given a parallel corpus U of sentence pairs
{(sk, tk) : k = 1, · · · , K} the parameters can be
estimated by maximizing the conditional likelihood
over the data. IBM models (Brown et al., 1993) from
1 to 5 are different ways of factoring the probability
model to estimate the parameter set θ. For example
in the simplest of the models, IBM model 1, only the
lexical translation probability is considered treating
each word being translated independent of the other
words.
</bodyText>
<equation confidence="0.751808">
pθ(sk, A|tk) (4)
</equation>
<bodyText confidence="0.9999838">
The parameters of the model above are estimated
as ˆθ, using the EM algorithm. We can also extract
the Viterbi alignment , ˆA, for all the sentence pairs,
which is the alignment with the highest probability
under the current model parameters θ:
</bodyText>
<equation confidence="0.7594995">
Aˆ = arg maxpˆθ(sJ 1 , A|tI 1) (5)
A
</equation>
<bodyText confidence="0.9980605">
The alignment models are asymmetric and dif-
fer with the choice of translation direction. We can
therefore perform the above after switching the di-
rection of the language pair and obtain models and
Viterbi alignments for the corpus as represented be-
low:
</bodyText>
<equation confidence="0.90964525">
θˆ = arg max
θ
Aˆ = arg maxpˆθ(tI 1, A|sJ 1 ) (7)
A
</equation>
<bodyText confidence="0.998744285714286">
Given the Viterbi alignment for each sentence
pair in the parallel corpus, we can also compute the
word-level alignment probabilities using simple rel-
ative likelihood estimation for both the directions.
As we will discuss in Section 5, the alignments and
the computed lexicons form an important part of our
link selection strategies.
</bodyText>
<equation confidence="0.995620333333333">
Ps count(ti, sj; ˆA)
P(sj/ti) = (8)
Ps count(ti)
P scount(ti, sj; ˆA)
P(ti/sj) = P (9)
s count(sj)
</equation>
<bodyText confidence="0.9998632">
We perform all our experiments on a symmetrized
alignment that combines the bidirectional align-
ments using heuristics as discussed in (Koehn et al.,
2007). We represent this alignment as A = {aij :
i = 0···J E sJ1;j = 0···I E tI1}.
</bodyText>
<subsectionHeader confidence="0.999521">
3.2 Semi-Supervised Word Alignment
</subsectionHeader>
<bodyText confidence="0.999992761904762">
We use an extended version of MGIZA++ (Gao
and Vogel, 2008) to perform the constrained semi-
supervised word alignment. To get full benefit
from the manual alignments, MGIZA++ modifies all
alignment models used in the standard training pro-
cedure, i.e. the IBM1, HMM, IBM3 and IBM4 mod-
els. Manual alignments are incorporated in the EM
training phase of these models as constraints that
restrict the summation over all possible alignment
paths. Typically in the EM procedure for IBM mod-
els, the training procedure requires for each source
sentence position, the summation over all positions
in the target sentence. The manual alignments al-
low for one-to-many alignments and many-to-many
alignments in both directions. For each position i
in the source sentence, there can be more than one
manually aligned target word. The restricted train-
ing will allow only those paths, which are consistent
with the manual alignments. Therefore, the restric-
tion of the alignment paths reduces to restricting the
summation in EM.
</bodyText>
<sectionHeader confidence="0.9727" genericHeader="method">
4 Active Learning for Word Alignment
</sectionHeader>
<bodyText confidence="0.999961111111111">
Active learning attempts to optimize performance
by selecting the most informative instances to la-
bel, where ‘informativeness’ is defined as maximal
expected improvement in accuracy. The objective
is to select optimal instance for an external expert
to label and then run the learning method on the
newly-labeled and previously-labeled instances to
minimize prediction or translation error, repeating
until either the maximal number of external queries
</bodyText>
<equation confidence="0.567567944444444">
XP(sJ1 |tI1) =
ai
1
X=
A
θˆ = arg max
θ
K
Y
k=1
X
A
pθ(tk,a|sk) (6)
K
Y
k=1
X
a
</equation>
<page confidence="0.966757">
12
</page>
<bodyText confidence="0.982911466666667">
is reached or a desired accuracy level is achieved.
Several studies (Tong and Koller, 2002; Nguyen
and Smeulders, 2004; Donmez and Carbonell, 2008)
show that active learning greatly helps to reduce the
labeling effort in various classification tasks.
We discuss our active learning setup for word
alignment in Algorithm 1. We start with an un-
labeled dataset U = {(Sk, Tk)}, indexed by k,
and a seed pool of partial alignment links A0 =
{akij, ∀si ∈ Sk, tj ∈ Tk}. Each ak ij represents an
alignment link from a sentence pair k that connects
source word si with tj.
This is usually an empty set at iteration t = 0. We
iterate for T iterations. We take a pool-based active
learning strategy, where we have access to all the au-
tomatically aligned links and we can score the links
based on our active learning query strategy. The
query strategy uses the automatically trained align-
ment model θt from the current iteration t, for scor-
ing the links. Re-training and re-tuning an SMT sys-
tem for each link at a time is computationally infea-
sible. We therefore perform batch learning by se-
lecting a set of N links scored high by our query
strategy. We seek manual corrections for the se-
lected links and add the alignment data to the cur-
rent labeled dataset. The word-level aligned labeled
dataset is then provided to our semi-supervised word
alignment algorithm, which uses it to produces the
alignment model θt+1 for U.
Algorithm 1 AL FOR WORD ALIGNMENT
</bodyText>
<listItem confidence="0.99858825">
1: Unlabeled Data Set: U = {(sk, tk)}
2: Manual Alignment Set : A0 = {akij, ∀si ∈
Sk, tj ∈ Tk}
3: Train Semi-supervised Word Alignment using
(U, A0) → θ0
4: N: batch size
5: fort = 0 to T do
6: Lt = LinkSelection(U,At,θt,N)
7: Request Human Alignment for Lt
8: At+1 = At + Lt
9: Re-train Semi-Supervised Word Align-
ment on (U, At+1) → θt+1
</listItem>
<sectionHeader confidence="0.492212" genericHeader="method">
10: end for
</sectionHeader>
<bodyText confidence="0.99972725">
We can iteratively perform the algorithm for a de-
fined number of iterations T or until a certain desired
performance is reached, which is measured by align-
ment error rate (AER) (Fraser and Marcu, 2007) in
the case of word alignment. In a more typical sce-
nario, since reducing human effort or cost of elici-
tation is the objective, we iterate until the available
budget is exhausted.
</bodyText>
<sectionHeader confidence="0.930057" genericHeader="method">
5 Query Strategies for Link Selection
</sectionHeader>
<bodyText confidence="0.9999928">
We propose multiple query selection strategies for
our active learning setup. The scoring criteria is
designed to select alignment links across sentence
pairs that are highly uncertain under current au-
tomatic translation models. These links are diffi-
cult to align correctly by automatic alignment and
will cause incorrect phrase pairs to be extracted in
the translation model, in turn hurting the transla-
tion quality of the SMT system. Manual correction
of such links produces the maximal benefit to the
model. We would ideally like to elicit the least num-
ber of manual corrections possible in order to reduce
the cost of data acquisition. In this section we dis-
cuss our link selection strategies based on the stan-
dard active learning paradigm of ‘uncertainty sam-
pling’(Lewis and Catlett, 1994). We use the au-
tomatically trained translation model θt for scoring
each link for uncertainty. In particular θt consists of
bidirectional lexicon tables computed from the bidi-
rectional alignments as discussed in Section 3.
</bodyText>
<subsectionHeader confidence="0.992695">
5.1 Uncertainty based: Bidirectional
Alignment Scores
</subsectionHeader>
<bodyText confidence="0.998925727272727">
The automatic Viterbi alignment produced by the
alignment models is used to obtain translation lexi-
cons, as discussed in Section 3. These lexicons cap-
ture the conditional distributions of source-given-
target P(s/t) and target-given-source P(t/s) prob-
abilities at the word level where si ∈ S and tj ∈ T.
We define certainty of a link as the harmonic mean
of the bidirectional probabilities. The selection strat-
egy selects the least scoring links according to the
formula below which corresponds to links with max-
imum uncertainty:
</bodyText>
<equation confidence="0.8844695">
1 ) = 2 ∗ P (tj/si) ∗ P (si/tj)
Score(aij/sI 1,tJ P(tj/si) + P(si/tj) (10)
</equation>
<subsectionHeader confidence="0.963778">
5.2 Confidence Based: Posterior Alignment
probabilities
</subsectionHeader>
<bodyText confidence="0.993876">
Confidence estimation for MT output is an interest-
ing area with meaningful initial exploration (Blatz
</bodyText>
<page confidence="0.997962">
13
</page>
<bodyText confidence="0.999992947368421">
et al., 2004; Ueffing and Ney, 2007). Given a sen-
tence pair (sI1, tJ1) and its word alignment, we com-
pute two confidence metrics at alignment link level –
based on the posterior link probability and a simple
IBM Model 1 as seen in Equation 13. We select the
alignment links that the initial word aligner is least
confident according to our metric and seek manual
correction of the links. We use t2s to denote com-
putation using higher order (IBM4) target-given-
source models and s2t to denote source-given-target
models. Targeting some of the uncertain parts of
word alignment has already been shown to improve
translation quality in SMT (Huang, 2009). In our
current work, we use confidence metrics as an ac-
tive learning sampling strategy to obtain most infor-
mative links. We also experiment with other con-
fidence metrics as discussed in (Ueffing and Ney,
2007), especially the IBM 1 model score metric
which showed some improvement as well.
</bodyText>
<equation confidence="0.998761285714286">
Pt2s(aij,tJ1/sI) = pt2s(�/si,aij C A)(11)
Ei pt2s(tj/si)
Ps2t(aij,
Ei pt2s(tj/si)
2 * Pt2s * Ps2t
Conf(aij/S, T) = (13)
Pt2s + Ps2t
</equation>
<subsectionHeader confidence="0.995633">
5.3 Agreement Based: Query by Committee
</subsectionHeader>
<bodyText confidence="0.999801111111111">
The generative alignments produced differ based on
the choice of direction of the language pair. We use
As2t to denote alignment in the source to target di-
rection and At2s to denote the target to source direc-
tion. We consider these alignments to be two experts
that have two different views of the alignment pro-
cess. We formulate our query strategy to select links,
where the agreement differs across these two align-
ments. In general query by committee is a standard
sampling strategy in active learning(Freund et al.,
1997), where the committee consists of any number
of experts with varying opinions, in this case align-
ments in different directions. We formulate a query
by committee sampling strategy for word alignment
as shown in Equation 14. In order to break ties, we
extend this approach to select the link with higher
average frequency of occurrence of words involved
in the link.
</bodyText>
<table confidence="0.9984005">
Language Sentences Words
Src Tgt
Ch-En 21,863 424,683 524,882
Ar-En 29,876 630,101 821,938
</table>
<tableCaption confidence="0.987163">
Table 1: Corpus Statistics of Human Data
</tableCaption>
<table confidence="0.997147333333333">
Alignment Automatic Links Manual Links
Ch-En 491,887 588,075
Ar-En 786,223 712,583
</table>
<tableCaption confidence="0.996525">
Table 2: Alignment Statistics of Human Data
</tableCaption>
<equation confidence="0.98501025">
Score(aij) = α where (14)
{ 2 aij C At2s n At2s
1 aij C At2s U At2s
0 otherwise
</equation>
<sectionHeader confidence="0.998052" genericHeader="method">
6 Experiments
</sectionHeader>
<subsectionHeader confidence="0.998644">
6.1 Data Analysis
</subsectionHeader>
<bodyText confidence="0.999860636363636">
To run our active learning and semi-supervised word
alignment experiments iteratively, we simulate the
setup by using a parallel corpus for which the
gold standard human alignment is already available.
We experiment with two language pairs - Chinese-
English and Arabic-English. Corpus-level statistics
for both language pairs can be seen in Table 1 and
their alignment link level statistics can be seen in
Table 2. Both datasets were released by LDC as part
of the GALE project.
Chinese-English dataset consists of 21,863 sen-
tence pairs with complete manual alignment. The
human alignment for this dataset is much denser
than the automatic word alignment. On an aver-
age each source word is linked to more than one
target word. Similarly, the Arabic-English dataset
consisting of 29,876 sentence pairs also has a denser
manual alignment. Automatic word alignment in
both cases was computed as a symmetrized version
of the bidirectional alignments obtained from using
GIZA++ (Och and Ney, 2003) in each direction sep-
arately.
</bodyText>
<subsectionHeader confidence="0.999702">
6.2 Word Alignment Results
</subsectionHeader>
<bodyText confidence="0.997631">
We first perform an unsupervised word alignment of
the parallel corpus. We then use the learned model
</bodyText>
<equation confidence="0.938267857142857">
ps2t (si/t aij C A)
t
) = Z �� Z�j
I1/
J1
(12)
α =
</equation>
<page confidence="0.993669">
14
</page>
<figureCaption confidence="0.99948">
Figure 1: Chinese-English: Link Selection Results Figure 2: Arabic-English: Link Selection Results
</figureCaption>
<bodyText confidence="0.999958933333334">
in running our link selection algorithm over the en-
tire alignments to determine the most uncertain links
according to each active learning strategy. The links
are then looked up in the gold standard human align-
ment database and corrected. In scenarios where
an alignment link is not present in the gold stan-
dard data for the source word, we introduce a NULL
alignment constraint, else we select all the links as
given in the gold standard. The aim of our work is to
show that active learning can help in selecting infor-
mative alignment links, which if manually labeled
can reduce the overall alignment error rate of the
given corpus. We, therefore measure the reduction
of alignment error rate (AER) of a semi-supervised
word aligner that uses this extra information to align
the corpus. We plot performance curves for both
Chinese-English, Figure 1 and Arabic-English, Fig-
ure 2, with number of manual links elicited on x-axis
and AER on y-axis. In each iteration of the experi-
ment, we gradually increase the number of links se-
lected from gold standard and make them available
to the semi-supervised word aligner and measure the
overall reduction of AER on the corpus. We com-
pare our link selection strategies to a baseline ap-
proach, where links are selected at random for man-
ual correction.
All our approaches perform equally or better than
the baseline for both language pairs. Query by
committee (qbc) performs similar to the baseline in
Chinese-English and only slightly better for Arabic-
English. This could be due to our committee con-
sisting of two alignments that differ only in direc-
tion and so are not sufficient in deciding for uncer-
tainty. We will be exploring alternative formulations
to this strategy. Confidence based and uncertainty
based metrics perform significantly better than the
baseline in both language pairs. We can interpret the
improvements in two ways. For the same number
of manual alignments elicited, our selection strate-
gies select links that provide higher reduction of er-
ror when compared to the baseline. An alternative
interpretation is that assuming a uniform cost per
link, our best selection strategy achieves similar per-
formance to the baseline, at a much lower cost of
elicitation.
</bodyText>
<subsectionHeader confidence="0.999839">
6.3 Translation Results
</subsectionHeader>
<bodyText confidence="0.999952384615384">
We also perform end-to-end machine translation ex-
periments to show that our improvement of align-
ment quality leads to an improvement of translation
scores. For Chinese-English, we train a standard
phrase-based SMT system (Koehn et al., 2007) over
the available 21,863 sentences. We tune on the MT-
Eval 2004 dataset and test on a subset of MT-Eval
2005 dataset consisting of 631 sentences. The lan-
guage model we use is built using only the English
side of the parallel corpus. We understand that this
language model is not the optimal choice, but we
are interested in testing the word alignment accu-
racy, which primarily affects the translation model.
</bodyText>
<page confidence="0.98921">
15
</page>
<table confidence="0.9997105">
Cn-En BLEU METEOR
Baseline 18.82 42.70
Human Alignment 19.96 44.22
Active Selection 20% 19.34 43.25
</table>
<tableCaption confidence="0.999897">
Table 3: Effect of Alignment on Translation Quality
</tableCaption>
<bodyText confidence="0.999972681818182">
We first obtain the baseline score by training in an
unsupervised manner, where no manual alignment
is used. We also train a configuration, where we
substitute the final word alignment with gold stan-
dard manual alignment for the entire parallel corpus.
This is an upper bound on the translation accuracy
that can be achieved by any alignment link selec-
tion algorithm for this dataset. We now take our
best link selection criteria, which is the confidence
based method and re-train the MT system after elic-
iting manual information for only 20% of the align-
ment links. We observe that at this point we have
reduced the AER from 37.09 to 26.57. The trans-
lation accuracy reported in Table 3, as measured by
BLEU (Papineni et al., 2002) and METEOR (Lavie
and Agarwal, 2007), also shows significant improve-
ment and approaches the quality achieved using gold
standard data. We did not perform MT experiments
with Arabic-English dataset due to the incompatibil-
ity of tokenization schemes between the manually
aligned parallel corpora and publicly available eval-
uation sets.
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="method">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999961625">
Word-Alignment is a particularly challenging prob-
lem and has been addressed in a completely unsuper-
vised manner thus far (Brown et al., 1993). While
generative alignment models have been successful,
lack of sufficient data, model assumptions and lo-
cal optimum during training are well known prob-
lems. Semi-supervised techniques use partial man-
ual alignment data to address some of these issues.
We have shown that active learning strategies can
reduce the effort involved in eliciting human align-
ment data. The reduction in effort is due to care-
ful selection of maximally uncertain links that pro-
vide the most benefit to the alignment model when
used in a semi-supervised training fashion. Experi-
ments on Chinese-English have shown considerable
improvements.
</bodyText>
<sectionHeader confidence="0.999179" genericHeader="discussions">
8 Future Work
</sectionHeader>
<bodyText confidence="0.999896666666667">
In future, we wish to work with word alignments for
other language pairs as well as study the effect of
manual alignments by varying the size of available
parallel data. We also plan to obtain alignments from
non-experts over online marketplaces like Amazon
Mechanical Turk to further reduce the cost of an-
notation. We will be experimenting with obtain-
ing full-alignment vs. partial alignment from non-
experts. Our hypothesis is that, humans are good
at performing tasks of smaller size and so we can
extract high quality alignments in the partial align-
ment case. Cost of link annotation in our current
work is assumed to be uniform, but this needs to
be revisited. We will also experiment with active
learning techniques for identifying sentence pairs
with very low alignment confidence, where obtain-
ing full-alignment is equivalent to obtaining multi-
ple partial alignments.
</bodyText>
<sectionHeader confidence="0.998384" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999733714285714">
This research was partially supported by DARPA
under grant NBCHC080097. Any opinions, find-
ings, and conclusions expressed in this paper are
those of the authors and do not necessarily reflect the
views of the DARPA. The first author would like to
thank Qin Gao for the semi-supervised word align-
ment software and help with running experiments.
</bodyText>
<sectionHeader confidence="0.999155" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997467722222222">
John Blatz, Erin Fitzgerald, George Foster, Simona Gan-
drabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis,
and Nicola Ueffing. 2004. Confidence estimation for
machine translation. In Proceedings of Coling 2004,
pages 315–321, Geneva, Switzerland, Aug 23–Aug
27. COLING.
Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della
Pietra, and Robert L. Mercer. 1993. The mathemat-
ics of statistical machine translation: parameter esti-
mation. Computational Linguistics, 19(2):263–311.
Chris Callison-Burch, David Talbot, and Miles Osborne.
2004. Statistical machine translation with word- and
sentence-aligned parallel corpora. In ACL 2004, page
175, Morristown, NJ, USA. Association for Computa-
tional Linguistics.
O. Chapelle, B. Sch¨olkopf, and A. Zien, editors. 2006.
Semi-Supervised Learning. MIT Press, Cambridge,
MA.
</reference>
<page confidence="0.988697">
16
</page>
<reference confidence="0.998107396039604">
Colin Cherry and Dekang Lin. 2006. Soft syntactic
constraints for word alignment through discriminative
training. In Proceedings of the COLING/ACL on Main
conference poster sessions, pages 105–112, Morris-
town, NJ, USA.
Pinar Donmez and Jaime G. Carbonell. 2008. Opti-
mizing estimated loss reduction for active sampling in
rank learning. In ICML ’08: Proceedings of the 25th
international conference on Machine learning, pages
248–255, New York, NY, USA. ACM.
Alexander Fraser and Daniel Marcu. 2006. Semi-
supervised training for statistical word alignment. In
ACL-44: Proceedings of the 21st International Con-
ference on Computational Linguistics and the 44th
annual meeting of the Association for Computational
Linguistics, pages 769–776, Morristown, NJ, USA.
Association for Computational Linguistics.
Alexander Fraser and Daniel Marcu. 2007. Measuring
word alignment quality for statistical machine transla-
tion. Comput. Linguist., 33(3):293–303.
Yoav Freund, Sebastian H. Seung, Eli Shamir, and Naf-
tali Tishby. 1997. Selective sampling using the query
by committee algorithm. Machine. Learning., 28(2-
3):133–168.
Qin Gao and Stephan Vogel. 2008. Parallel implemen-
tations of word alignment tool. In Software Engi-
neering, Testing, and Quality Assurance for Natural
Language Processing, pages 49–57, Columbus, Ohio,
June. Association for Computational Linguistics.
Gholamreza Haffari, Maxim Roy, and Anoop Sarkar.
2009. Active learning for statistical phrase-based ma-
chine translation. In Proceedings of HLT NAACL
2009, pages 415–423, Boulder, Colorado, June. As-
sociation for Computational Linguistics.
Fei Huang. 2009. Confidence measure for word align-
ment. In Proceedings of the Joint ACL and IJCNLP,
pages 932–940, Suntec, Singapore, August. Associa-
tion for Computational Linguistics.
Rebecca Hwa. 2004. Sample selection for statistical
parsing. Comput. Linguist., 30(3):253–276.
Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne,
Christopher Callison-Burch, Marcello Federico,
Nicola Bertoldi, Brooke Cowan, Wade Shen, Chris-
tine Moran, Richard Zens, Chris Dyer, Ondrej Bojar,
Alexandra Constantin, and Evan Herbst. 2007.
Moses: Open source toolkit for statistical machine
translation. In ACL Demonstration Session.
Alon Lavie and Abhaya Agarwal. 2007. Meteor: an au-
tomatic metric for mt evaluation with high levels of
correlation with human judgments. In WMT 2007,
pages 228–231, Morristown, NJ, USA.
David D. Lewis and Jason Catlett. 1994. Heterogeneous
uncertainty sampling for supervised learning. In In
Proceedings of the Eleventh International Conference
on Machine Learning, pages 148–156. Morgan Kauf-
mann.
Hieu T. Nguyen and Arnold Smeulders. 2004. Active
learning using pre-clustering. In ICML.
Franz Josef Och and Hermann Ney. 2003. A system-
atic comparison of various statistical alignment mod-
els. Computational Linguistics, pages 19–51.
Kishore Papineni, Salim Roukos, Todd Ward, and Wei-
Jing Zhu. 2002. Bleu: a method for automatic evalua-
tion of machine translation. In ACL 2002, pages 311–
318, Morristown, NJ, USA.
Dan Shen, Jie Zhang, Jian Su, Guodong Zhou, and Chew-
Lim Tan. 2004. Multi-criteria-based active learning
for named entity recognition. In ACL ’04: Proceed-
ings of the 42nd Annual Meeting on Association for
Computational Linguistics, page 589, Morristown, NJ,
USA. Association for Computational Linguistics.
Min Tang, Xiaoqiang Luo, and Salim Roukos. 2001. Ac-
tive learning for statistical natural language parsing. In
ACL ’02, pages 120–127, Morristown, NJ, USA.
Katrin Tomanek and Udo Hahn. 2009. Semi-supervised
active learning for sequence labeling. In Proceedings
of the Joint Conference of the 47th Annual Meeting
of the ACL and the 4th International Joint Conference
on Natural Language Processing of the AFNLP, pages
1039–1047, Suntec, Singapore, August. Association
for Computational Linguistics.
Simon Tong and Daphne Koller. 2002. Support vector
machine active learning with applications to text clas-
sification. Journal of Machine Learning, pages 45–66.
Gokhan Tur, Dilek Hakkani-Tr, and Robert E. Schapire.
2005. Combining active and semi-supervised learning
for spoken language understanding. Speech Commu-
nication, 45(2):171 – 186.
Nicola Ueffing and Hermann Ney. 2007. Word-level
confidence estimation for machine translation. Com-
put. Linguist., 33(1):9–40.
Hua Wu, Haifeng Wang, and Zhanyi Liu. 2006. Boosting
statistical word alignment using labeled and unlabeled
data. In Proceedings of the COLING/ACL on Main
conference poster sessions, pages 913–920, Morris-
town, NJ, USA. Association for Computational Lin-
guistics.
X. Zhu. 2005. Semi-Supervised Learning Lit-
erature Survey. Technical Report 1530, Com-
puter Sciences, University of Wisconsin-Madison.
http://www.cs.wisc.edu/∼jerryzhu/pub/ssl survey.pdf.
</reference>
<page confidence="0.999369">
17
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.645711">
<title confidence="0.999028">Active Semi-Supervised Learning for Improving Word Alignment</title>
<author confidence="0.910875">Vamshi Ambati</author>
<author confidence="0.910875">Stephan Vogel</author>
<author confidence="0.910875">Jaime</author>
<affiliation confidence="0.848607">Language Technologies Institute, Carnegie Mellon</affiliation>
<address confidence="0.998455">5000 Forbes Avenue, Pittsburgh, PA 15213, USA</address>
<abstract confidence="0.989387523809524">Word alignment models form an important part of building statistical machine translation systems. Semi-supervised word alignment aims to improve the accuracy of automatic word alignment by incorporating full or partial alignments acquired from humans. Such dedicated elicitation effort is often expensive and depends on availability of bilingual speakers for the language-pair. In this paper we study active learning query strategies to carefully identify highly uncertain or most informative alignment links that are proposed under an unsupervised word alignment model. Manual correction of such informative links can then be applied to create a labeled dataset used by a semi-supervised word alignment model. Our experiments show that using active learning leads to maximal reduction of alignment error rates with reduced human effort.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Blatz</author>
<author>Erin Fitzgerald</author>
<author>George Foster</author>
<author>Simona Gandrabur</author>
<author>Cyril Goutte</author>
<author>Alex Kulesza</author>
<author>Alberto Sanchis</author>
<author>Nicola Ueffing</author>
</authors>
<title>Confidence estimation for machine translation.</title>
<date>2004</date>
<booktitle>In Proceedings of Coling</booktitle>
<pages>315--321</pages>
<publisher>COLING.</publisher>
<location>Geneva, Switzerland,</location>
<marker>Blatz, Fitzgerald, Foster, Gandrabur, Goutte, Kulesza, Sanchis, Ueffing, 2004</marker>
<rawString>John Blatz, Erin Fitzgerald, George Foster, Simona Gandrabur, Cyril Goutte, Alex Kulesza, Alberto Sanchis, and Nicola Ueffing. 2004. Confidence estimation for machine translation. In Proceedings of Coling 2004, pages 315–321, Geneva, Switzerland, Aug 23–Aug 27. COLING.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Vincent J Della Pietra</author>
<author>Stephen A Della Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of statistical machine translation: parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="1230" citStr="Brown et al., 1993" startWordPosition="177" endWordPosition="180">or the language-pair. In this paper we study active learning query strategies to carefully identify highly uncertain or most informative alignment links that are proposed under an unsupervised word alignment model. Manual correction of such informative links can then be applied to create a labeled dataset used by a semi-supervised word alignment model. Our experiments show that using active learning leads to maximal reduction of alignment error rates with reduced human effort. 1 Introduction The success of statistical approaches to Machine Translation (MT) can be attributed to the IBM models (Brown et al., 1993) that characterize wordlevel alignments in parallel corpora. Parameters of these alignment models are learnt in an unsupervised manner using the EM algorithm over sentence-level aligned parallel corpora. While the ease of automatically aligning sentences at the word-level with tools like GIZA++ (Och and Ney, 2003) has enabled fast development of statistical machine translation (SMT) systems for various language pairs, the quality of alignment is typically quite low for language pairs that diverge from the independence assumptions made by the generative models. Also, an immense amount of parall</context>
<context position="7643" citStr="Brown et al., 1993" startWordPosition="1208" endWordPosition="1211"> we are not aware of any work that has looked at reducing human effort by selective elicitation of alignment information using active learning techniques. 3 Word Alignment 3.1 IBM models IBM models provide a generative framework for performing word alignment of parallel corpus. Given two strings from source and target languages sJ1 = s1,··· , sj, ··· sJ and tI1 = t1, ··· ,ti, ··· tI, an alignment A is defined as a subset of the Cartesian product of the word indices as shown in Eq 1. In IBM models, since alignment is treated as a function, all the source positions must be covered exactly once (Brown et al., 1993). A C {(j,i) : j = 0···J;i = 0 ··· I} (1) For the task of translation, we would ideally want to model P(sI1�tJ1 ), which is the probability of observing source sentence sI1 given target sentence tJ1 . This requires a lot of parallel corpus for estimation 11 and so it is then factored over the word alignment A for the sentence pair, which is a hidden variable. Word alignment is therefore a by-product in the process of modeling translation. We can also represent the same under some parameterization of θ, which is the model we are interested to estimate. Pr(sJ1 , A|tJ1) (2) pθ(sJ1 , A|tI1) (3) Gi</context>
<context position="23600" citStr="Brown et al., 1993" startWordPosition="3898" endWordPosition="3901">ave reduced the AER from 37.09 to 26.57. The translation accuracy reported in Table 3, as measured by BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007), also shows significant improvement and approaches the quality achieved using gold standard data. We did not perform MT experiments with Arabic-English dataset due to the incompatibility of tokenization schemes between the manually aligned parallel corpora and publicly available evaluation sets. 7 Conclusion Word-Alignment is a particularly challenging problem and has been addressed in a completely unsupervised manner thus far (Brown et al., 1993). While generative alignment models have been successful, lack of sufficient data, model assumptions and local optimum during training are well known problems. Semi-supervised techniques use partial manual alignment data to address some of these issues. We have shown that active learning strategies can reduce the effort involved in eliciting human alignment data. The reduction in effort is due to careful selection of maximally uncertain links that provide the most benefit to the alignment model when used in a semi-supervised training fashion. Experiments on Chinese-English have shown considera</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Vincent J. Della Pietra, Stephen A. Della Pietra, and Robert L. Mercer. 1993. The mathematics of statistical machine translation: parameter estimation. Computational Linguistics, 19(2):263–311.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Callison-Burch</author>
<author>David Talbot</author>
<author>Miles Osborne</author>
</authors>
<title>Statistical machine translation with word- and sentence-aligned parallel corpora.</title>
<date>2004</date>
<booktitle>In ACL 2004,</booktitle>
<pages>175</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="5776" citStr="Callison-Burch et al. (2004)" startWordPosition="898" endWordPosition="901">human labeling. Researchers have begun to explore semisupervised word alignment models that use both labeled and unlabeled data. Fraser and Marcu (2006) pose the problem of alignment as a search problem in log-linear space with features coming from the IBM alignment models. The log-linear model is trained on the available labeled data to improve performance. They propose a semisupervised training algorithm which alternates between discriminative error training on the labeled data to learn the weighting parameters and maximum-likelihood EM training on unlabeled data to estimate the parameters. Callison-Burch et al. (2004) also improve alignment by interpolating human alignments with automatic alignments. They observe that while working with such datasets, alignments of higher quality should be given a much higher weight than the lower-quality alignments. Wu et al. (2006) learn separate models from labeled and unlabeled data using the standard EM algorithm. The two models are then interpolated as a learner in the semi-supervised AdaBoost algorithm to improve word alignment. Active learning has been applied to various fields of Natural Language Processing like statistical parsing, entity recognition among others</context>
</contexts>
<marker>Callison-Burch, Talbot, Osborne, 2004</marker>
<rawString>Chris Callison-Burch, David Talbot, and Miles Osborne. 2004. Statistical machine translation with word- and sentence-aligned parallel corpora. In ACL 2004, page 175, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>O Chapelle</author>
<author>B Sch¨olkopf</author>
<author>A Zien</author>
<author>editors</author>
</authors>
<title>Semi-Supervised Learning.</title>
<date>2006</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA.</location>
<marker>Chapelle, Sch¨olkopf, Zien, editors, 2006</marker>
<rawString>O. Chapelle, B. Sch¨olkopf, and A. Zien, editors. 2006. Semi-Supervised Learning. MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Cherry</author>
<author>Dekang Lin</author>
</authors>
<title>Soft syntactic constraints for word alignment through discriminative training.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>105--112</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="2191" citStr="Cherry and Lin, 2006" startWordPosition="325" endWordPosition="328">ment of statistical machine translation (SMT) systems for various language pairs, the quality of alignment is typically quite low for language pairs that diverge from the independence assumptions made by the generative models. Also, an immense amount of parallel data enables better estimation of the model parameters, but a large number of language pairs still lack parallel data. Two directions of research have been pursued for improving generative word alignment. The first is to relax or update the independence assumptions based on more information, usually syntactic, from the language pairs (Cherry and Lin, 2006). The second is to use extra annotation, typically word-level human alignment for some sentence pairs, in conjunction with the parallel data to learn alignment in a semi-supervised manner. Our research is in the direction of the latter, and aims to reduce the effort involved in hand-generation of word alignments by using active learning strategies for careful selection of word pairs to seek alignment. Active learning for MT has not yet been explored to its full potential. Much of the literature has explored one task – selecting sentences to translate and add to the training corpus (Haffari et </context>
</contexts>
<marker>Cherry, Lin, 2006</marker>
<rawString>Colin Cherry and Dekang Lin. 2006. Soft syntactic constraints for word alignment through discriminative training. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 105–112, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pinar Donmez</author>
<author>Jaime G Carbonell</author>
</authors>
<title>Optimizing estimated loss reduction for active sampling in rank learning.</title>
<date>2008</date>
<booktitle>In ICML ’08: Proceedings of the 25th international conference on Machine learning,</booktitle>
<pages>248--255</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="11748" citStr="Donmez and Carbonell, 2008" startWordPosition="1912" endWordPosition="1915">cting the most informative instances to label, where ‘informativeness’ is defined as maximal expected improvement in accuracy. The objective is to select optimal instance for an external expert to label and then run the learning method on the newly-labeled and previously-labeled instances to minimize prediction or translation error, repeating until either the maximal number of external queries XP(sJ1 |tI1) = ai 1 X= A θˆ = arg max θ K Y k=1 X A pθ(tk,a|sk) (6) K Y k=1 X a 12 is reached or a desired accuracy level is achieved. Several studies (Tong and Koller, 2002; Nguyen and Smeulders, 2004; Donmez and Carbonell, 2008) show that active learning greatly helps to reduce the labeling effort in various classification tasks. We discuss our active learning setup for word alignment in Algorithm 1. We start with an unlabeled dataset U = {(Sk, Tk)}, indexed by k, and a seed pool of partial alignment links A0 = {akij, ∀si ∈ Sk, tj ∈ Tk}. Each ak ij represents an alignment link from a sentence pair k that connects source word si with tj. This is usually an empty set at iteration t = 0. We iterate for T iterations. We take a pool-based active learning strategy, where we have access to all the automatically aligned link</context>
</contexts>
<marker>Donmez, Carbonell, 2008</marker>
<rawString>Pinar Donmez and Jaime G. Carbonell. 2008. Optimizing estimated loss reduction for active sampling in rank learning. In ICML ’08: Proceedings of the 25th international conference on Machine learning, pages 248–255, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Semisupervised training for statistical word alignment.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics,</booktitle>
<pages>769--776</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="5300" citStr="Fraser and Marcu (2006)" startWordPosition="827" endWordPosition="830">an interesting method that has been applied to clustering problems. Tomanek and Hahn (2009) applied active semi supervised learning to the sequence-labeling problem. Tur et al. (2005) describe active and semi-supervised learning methods for reducing labeling effort for spoken language understanding. They train supervised classification algorithms for the task of call classification and apply it to a large unlabeled dataset to select the least confident instances for human labeling. Researchers have begun to explore semisupervised word alignment models that use both labeled and unlabeled data. Fraser and Marcu (2006) pose the problem of alignment as a search problem in log-linear space with features coming from the IBM alignment models. The log-linear model is trained on the available labeled data to improve performance. They propose a semisupervised training algorithm which alternates between discriminative error training on the labeled data to learn the weighting parameters and maximum-likelihood EM training on unlabeled data to estimate the parameters. Callison-Burch et al. (2004) also improve alignment by interpolating human alignments with automatic alignments. They observe that while working with su</context>
</contexts>
<marker>Fraser, Marcu, 2006</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2006. Semisupervised training for statistical word alignment. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics, pages 769–776, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexander Fraser</author>
<author>Daniel Marcu</author>
</authors>
<title>Measuring word alignment quality for statistical machine translation.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>3</issue>
<contexts>
<context position="13598" citStr="Fraser and Marcu, 2007" startWordPosition="2252" endWordPosition="2255">uces the alignment model θt+1 for U. Algorithm 1 AL FOR WORD ALIGNMENT 1: Unlabeled Data Set: U = {(sk, tk)} 2: Manual Alignment Set : A0 = {akij, ∀si ∈ Sk, tj ∈ Tk} 3: Train Semi-supervised Word Alignment using (U, A0) → θ0 4: N: batch size 5: fort = 0 to T do 6: Lt = LinkSelection(U,At,θt,N) 7: Request Human Alignment for Lt 8: At+1 = At + Lt 9: Re-train Semi-Supervised Word Alignment on (U, At+1) → θt+1 10: end for We can iteratively perform the algorithm for a defined number of iterations T or until a certain desired performance is reached, which is measured by alignment error rate (AER) (Fraser and Marcu, 2007) in the case of word alignment. In a more typical scenario, since reducing human effort or cost of elicitation is the objective, we iterate until the available budget is exhausted. 5 Query Strategies for Link Selection We propose multiple query selection strategies for our active learning setup. The scoring criteria is designed to select alignment links across sentence pairs that are highly uncertain under current automatic translation models. These links are difficult to align correctly by automatic alignment and will cause incorrect phrase pairs to be extracted in the translation model, in t</context>
</contexts>
<marker>Fraser, Marcu, 2007</marker>
<rawString>Alexander Fraser and Daniel Marcu. 2007. Measuring word alignment quality for statistical machine translation. Comput. Linguist., 33(3):293–303.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Freund</author>
<author>Sebastian H Seung</author>
<author>Eli Shamir</author>
<author>Naftali Tishby</author>
</authors>
<title>Selective sampling using the query by committee algorithm.</title>
<date>1997</date>
<journal>Machine. Learning.,</journal>
<pages>28--2</pages>
<contexts>
<context position="17289" citStr="Freund et al., 1997" startWordPosition="2858" endWordPosition="2861">j/si) 2 * Pt2s * Ps2t Conf(aij/S, T) = (13) Pt2s + Ps2t 5.3 Agreement Based: Query by Committee The generative alignments produced differ based on the choice of direction of the language pair. We use As2t to denote alignment in the source to target direction and At2s to denote the target to source direction. We consider these alignments to be two experts that have two different views of the alignment process. We formulate our query strategy to select links, where the agreement differs across these two alignments. In general query by committee is a standard sampling strategy in active learning(Freund et al., 1997), where the committee consists of any number of experts with varying opinions, in this case alignments in different directions. We formulate a query by committee sampling strategy for word alignment as shown in Equation 14. In order to break ties, we extend this approach to select the link with higher average frequency of occurrence of words involved in the link. Language Sentences Words Src Tgt Ch-En 21,863 424,683 524,882 Ar-En 29,876 630,101 821,938 Table 1: Corpus Statistics of Human Data Alignment Automatic Links Manual Links Ch-En 491,887 588,075 Ar-En 786,223 712,583 Table 2: Alignment </context>
</contexts>
<marker>Freund, Seung, Shamir, Tishby, 1997</marker>
<rawString>Yoav Freund, Sebastian H. Seung, Eli Shamir, and Naftali Tishby. 1997. Selective sampling using the query by committee algorithm. Machine. Learning., 28(2-3):133–168.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Qin Gao</author>
<author>Stephan Vogel</author>
</authors>
<title>Parallel implementations of word alignment tool.</title>
<date>2008</date>
<booktitle>In Software Engineering, Testing, and Quality Assurance for Natural Language Processing,</booktitle>
<pages>49--57</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Columbus, Ohio,</location>
<contexts>
<context position="10076" citStr="Gao and Vogel, 2008" startWordPosition="1643" endWordPosition="1646"> simple relative likelihood estimation for both the directions. As we will discuss in Section 5, the alignments and the computed lexicons form an important part of our link selection strategies. Ps count(ti, sj; ˆA) P(sj/ti) = (8) Ps count(ti) P scount(ti, sj; ˆA) P(ti/sj) = P (9) s count(sj) We perform all our experiments on a symmetrized alignment that combines the bidirectional alignments using heuristics as discussed in (Koehn et al., 2007). We represent this alignment as A = {aij : i = 0···J E sJ1;j = 0···I E tI1}. 3.2 Semi-Supervised Word Alignment We use an extended version of MGIZA++ (Gao and Vogel, 2008) to perform the constrained semisupervised word alignment. To get full benefit from the manual alignments, MGIZA++ modifies all alignment models used in the standard training procedure, i.e. the IBM1, HMM, IBM3 and IBM4 models. Manual alignments are incorporated in the EM training phase of these models as constraints that restrict the summation over all possible alignment paths. Typically in the EM procedure for IBM models, the training procedure requires for each source sentence position, the summation over all positions in the target sentence. The manual alignments allow for one-to-many alig</context>
</contexts>
<marker>Gao, Vogel, 2008</marker>
<rawString>Qin Gao and Stephan Vogel. 2008. Parallel implementations of word alignment tool. In Software Engineering, Testing, and Quality Assurance for Natural Language Processing, pages 49–57, Columbus, Ohio, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gholamreza Haffari</author>
<author>Maxim Roy</author>
<author>Anoop Sarkar</author>
</authors>
<title>Active learning for statistical phrase-based machine translation.</title>
<date>2009</date>
<booktitle>In Proceedings of HLT NAACL</booktitle>
<pages>415--423</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="2801" citStr="Haffari et al., 2009" startWordPosition="427" endWordPosition="430"> Lin, 2006). The second is to use extra annotation, typically word-level human alignment for some sentence pairs, in conjunction with the parallel data to learn alignment in a semi-supervised manner. Our research is in the direction of the latter, and aims to reduce the effort involved in hand-generation of word alignments by using active learning strategies for careful selection of word pairs to seek alignment. Active learning for MT has not yet been explored to its full potential. Much of the literature has explored one task – selecting sentences to translate and add to the training corpus (Haffari et al., 2009). In this paper we explore active learning for word alignment, where the input to the active learner is a sentence pair (si , ti), present in two different languages S = {s*} and T = {t*}, and the annotation elicited from human is a set of links {(j, i) : j = 0 · · · J; i = 0 · · · I}. Unlike previous approaches, our work does not require elicitation of full alignment for the sentence pair, which could be effortintensive. We use standard active learning query strategies to selectively elicit partial alignment information. This partial alignment information is then fed into a semi-supervised wo</context>
<context position="6858" citStr="Haffari et al., 2009" startWordPosition="1067" endWordPosition="1070">Active learning has been applied to various fields of Natural Language Processing like statistical parsing, entity recognition among others (Hwa, 2004; Tang et al., 2001; Shen et al., 2004). In case of MT, the potential of active learning has remained largely unexplored. For Statistical Machine Translation, application of active learning has been focused on the task of selecting the most informative sentences to train the model, in order to reduce cost of data acquisition. Recent work in this area discussed multiple query selection strategies for a Statistical Phrase Based Translation system (Haffari et al., 2009). Their framework requires source text to be translated by the system and the translated data is used in a self-training setting to train MT models. To our knowledge, we are not aware of any work that has looked at reducing human effort by selective elicitation of alignment information using active learning techniques. 3 Word Alignment 3.1 IBM models IBM models provide a generative framework for performing word alignment of parallel corpus. Given two strings from source and target languages sJ1 = s1,··· , sj, ··· sJ and tI1 = t1, ··· ,ti, ··· tI, an alignment A is defined as a subset of the Ca</context>
</contexts>
<marker>Haffari, Roy, Sarkar, 2009</marker>
<rawString>Gholamreza Haffari, Maxim Roy, and Anoop Sarkar. 2009. Active learning for statistical phrase-based machine translation. In Proceedings of HLT NAACL 2009, pages 415–423, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fei Huang</author>
</authors>
<title>Confidence measure for word alignment.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint ACL and IJCNLP,</booktitle>
<pages>932--940</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="16301" citStr="Huang, 2009" startWordPosition="2694" endWordPosition="2695"> Given a sentence pair (sI1, tJ1) and its word alignment, we compute two confidence metrics at alignment link level – based on the posterior link probability and a simple IBM Model 1 as seen in Equation 13. We select the alignment links that the initial word aligner is least confident according to our metric and seek manual correction of the links. We use t2s to denote computation using higher order (IBM4) target-givensource models and s2t to denote source-given-target models. Targeting some of the uncertain parts of word alignment has already been shown to improve translation quality in SMT (Huang, 2009). In our current work, we use confidence metrics as an active learning sampling strategy to obtain most informative links. We also experiment with other confidence metrics as discussed in (Ueffing and Ney, 2007), especially the IBM 1 model score metric which showed some improvement as well. Pt2s(aij,tJ1/sI) = pt2s(�/si,aij C A)(11) Ei pt2s(tj/si) Ps2t(aij, Ei pt2s(tj/si) 2 * Pt2s * Ps2t Conf(aij/S, T) = (13) Pt2s + Ps2t 5.3 Agreement Based: Query by Committee The generative alignments produced differ based on the choice of direction of the language pair. We use As2t to denote alignment in the </context>
</contexts>
<marker>Huang, 2009</marker>
<rawString>Fei Huang. 2009. Confidence measure for word alignment. In Proceedings of the Joint ACL and IJCNLP, pages 932–940, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rebecca Hwa</author>
</authors>
<title>Sample selection for statistical parsing.</title>
<date>2004</date>
<journal>Comput. Linguist.,</journal>
<volume>30</volume>
<issue>3</issue>
<contexts>
<context position="6387" citStr="Hwa, 2004" startWordPosition="991" endWordPosition="992">lso improve alignment by interpolating human alignments with automatic alignments. They observe that while working with such datasets, alignments of higher quality should be given a much higher weight than the lower-quality alignments. Wu et al. (2006) learn separate models from labeled and unlabeled data using the standard EM algorithm. The two models are then interpolated as a learner in the semi-supervised AdaBoost algorithm to improve word alignment. Active learning has been applied to various fields of Natural Language Processing like statistical parsing, entity recognition among others (Hwa, 2004; Tang et al., 2001; Shen et al., 2004). In case of MT, the potential of active learning has remained largely unexplored. For Statistical Machine Translation, application of active learning has been focused on the task of selecting the most informative sentences to train the model, in order to reduce cost of data acquisition. Recent work in this area discussed multiple query selection strategies for a Statistical Phrase Based Translation system (Haffari et al., 2009). Their framework requires source text to be translated by the system and the translated data is used in a self-training setting </context>
</contexts>
<marker>Hwa, 2004</marker>
<rawString>Rebecca Hwa. 2004. Sample selection for statistical parsing. Comput. Linguist., 30(3):253–276.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Philipp Koehn</author>
<author>Hieu Hoang</author>
<author>Alexandra Birch Mayne</author>
<author>Christopher Callison-Burch</author>
<author>Marcello Federico</author>
<author>Nicola Bertoldi</author>
<author>Brooke Cowan</author>
<author>Wade Shen</author>
</authors>
<location>Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar,</location>
<marker>Koehn, Hoang, Mayne, Callison-Burch, Federico, Bertoldi, Cowan, Shen, </marker>
<rawString>Philipp Koehn, Hieu Hoang, Alexandra Birch Mayne, Christopher Callison-Burch, Marcello Federico, Nicola Bertoldi, Brooke Cowan, Wade Shen, Christine Moran, Richard Zens, Chris Dyer, Ondrej Bojar,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandra Constantin</author>
<author>Evan Herbst</author>
</authors>
<title>Moses: Open source toolkit for statistical machine translation.</title>
<date>2007</date>
<booktitle>In ACL Demonstration Session.</booktitle>
<marker>Constantin, Herbst, 2007</marker>
<rawString>Alexandra Constantin, and Evan Herbst. 2007. Moses: Open source toolkit for statistical machine translation. In ACL Demonstration Session.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alon Lavie</author>
<author>Abhaya Agarwal</author>
</authors>
<title>Meteor: an automatic metric for mt evaluation with high levels of correlation with human judgments.</title>
<date>2007</date>
<booktitle>In WMT 2007,</booktitle>
<pages>228--231</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="23148" citStr="Lavie and Agarwal, 2007" startWordPosition="3830" endWordPosition="3833">e we substitute the final word alignment with gold standard manual alignment for the entire parallel corpus. This is an upper bound on the translation accuracy that can be achieved by any alignment link selection algorithm for this dataset. We now take our best link selection criteria, which is the confidence based method and re-train the MT system after eliciting manual information for only 20% of the alignment links. We observe that at this point we have reduced the AER from 37.09 to 26.57. The translation accuracy reported in Table 3, as measured by BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007), also shows significant improvement and approaches the quality achieved using gold standard data. We did not perform MT experiments with Arabic-English dataset due to the incompatibility of tokenization schemes between the manually aligned parallel corpora and publicly available evaluation sets. 7 Conclusion Word-Alignment is a particularly challenging problem and has been addressed in a completely unsupervised manner thus far (Brown et al., 1993). While generative alignment models have been successful, lack of sufficient data, model assumptions and local optimum during training are well know</context>
</contexts>
<marker>Lavie, Agarwal, 2007</marker>
<rawString>Alon Lavie and Abhaya Agarwal. 2007. Meteor: an automatic metric for mt evaluation with high levels of correlation with human judgments. In WMT 2007, pages 228–231, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Lewis</author>
<author>Jason Catlett</author>
</authors>
<title>Heterogeneous uncertainty sampling for supervised learning. In</title>
<date>1994</date>
<booktitle>In Proceedings of the Eleventh International Conference on Machine Learning,</booktitle>
<pages>148--156</pages>
<publisher>Morgan Kaufmann.</publisher>
<contexts>
<context position="14611" citStr="Lewis and Catlett, 1994" startWordPosition="2417" endWordPosition="2421">ghly uncertain under current automatic translation models. These links are difficult to align correctly by automatic alignment and will cause incorrect phrase pairs to be extracted in the translation model, in turn hurting the translation quality of the SMT system. Manual correction of such links produces the maximal benefit to the model. We would ideally like to elicit the least number of manual corrections possible in order to reduce the cost of data acquisition. In this section we discuss our link selection strategies based on the standard active learning paradigm of ‘uncertainty sampling’(Lewis and Catlett, 1994). We use the automatically trained translation model θt for scoring each link for uncertainty. In particular θt consists of bidirectional lexicon tables computed from the bidirectional alignments as discussed in Section 3. 5.1 Uncertainty based: Bidirectional Alignment Scores The automatic Viterbi alignment produced by the alignment models is used to obtain translation lexicons, as discussed in Section 3. These lexicons capture the conditional distributions of source-giventarget P(s/t) and target-given-source P(t/s) probabilities at the word level where si ∈ S and tj ∈ T. We define certainty o</context>
</contexts>
<marker>Lewis, Catlett, 1994</marker>
<rawString>David D. Lewis and Jason Catlett. 1994. Heterogeneous uncertainty sampling for supervised learning. In In Proceedings of the Eleventh International Conference on Machine Learning, pages 148–156. Morgan Kaufmann.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hieu T Nguyen</author>
<author>Arnold Smeulders</author>
</authors>
<title>Active learning using pre-clustering.</title>
<date>2004</date>
<booktitle>In ICML.</booktitle>
<contexts>
<context position="11719" citStr="Nguyen and Smeulders, 2004" startWordPosition="1908" endWordPosition="1911">optimize performance by selecting the most informative instances to label, where ‘informativeness’ is defined as maximal expected improvement in accuracy. The objective is to select optimal instance for an external expert to label and then run the learning method on the newly-labeled and previously-labeled instances to minimize prediction or translation error, repeating until either the maximal number of external queries XP(sJ1 |tI1) = ai 1 X= A θˆ = arg max θ K Y k=1 X A pθ(tk,a|sk) (6) K Y k=1 X a 12 is reached or a desired accuracy level is achieved. Several studies (Tong and Koller, 2002; Nguyen and Smeulders, 2004; Donmez and Carbonell, 2008) show that active learning greatly helps to reduce the labeling effort in various classification tasks. We discuss our active learning setup for word alignment in Algorithm 1. We start with an unlabeled dataset U = {(Sk, Tk)}, indexed by k, and a seed pool of partial alignment links A0 = {akij, ∀si ∈ Sk, tj ∈ Tk}. Each ak ij represents an alignment link from a sentence pair k that connects source word si with tj. This is usually an empty set at iteration t = 0. We iterate for T iterations. We take a pool-based active learning strategy, where we have access to all t</context>
</contexts>
<marker>Nguyen, Smeulders, 2004</marker>
<rawString>Hieu T. Nguyen and Arnold Smeulders. 2004. Active learning using pre-clustering. In ICML.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz Josef Och</author>
<author>Hermann Ney</author>
</authors>
<title>A systematic comparison of various statistical alignment models. Computational Linguistics,</title>
<date>2003</date>
<pages>pages</pages>
<contexts>
<context position="1545" citStr="Och and Ney, 2003" startWordPosition="224" endWordPosition="227"> semi-supervised word alignment model. Our experiments show that using active learning leads to maximal reduction of alignment error rates with reduced human effort. 1 Introduction The success of statistical approaches to Machine Translation (MT) can be attributed to the IBM models (Brown et al., 1993) that characterize wordlevel alignments in parallel corpora. Parameters of these alignment models are learnt in an unsupervised manner using the EM algorithm over sentence-level aligned parallel corpora. While the ease of automatically aligning sentences at the word-level with tools like GIZA++ (Och and Ney, 2003) has enabled fast development of statistical machine translation (SMT) systems for various language pairs, the quality of alignment is typically quite low for language pairs that diverge from the independence assumptions made by the generative models. Also, an immense amount of parallel data enables better estimation of the model parameters, but a large number of language pairs still lack parallel data. Two directions of research have been pursued for improving generative word alignment. The first is to relax or update the independence assumptions based on more information, usually syntactic, </context>
<context position="19017" citStr="Och and Ney, 2003" startWordPosition="3139" endWordPosition="3142">level statistics can be seen in Table 2. Both datasets were released by LDC as part of the GALE project. Chinese-English dataset consists of 21,863 sentence pairs with complete manual alignment. The human alignment for this dataset is much denser than the automatic word alignment. On an average each source word is linked to more than one target word. Similarly, the Arabic-English dataset consisting of 29,876 sentence pairs also has a denser manual alignment. Automatic word alignment in both cases was computed as a symmetrized version of the bidirectional alignments obtained from using GIZA++ (Och and Ney, 2003) in each direction separately. 6.2 Word Alignment Results We first perform an unsupervised word alignment of the parallel corpus. We then use the learned model ps2t (si/t aij C A) t ) = Z �� Z�j I1/ J1 (12) α = 14 Figure 1: Chinese-English: Link Selection Results Figure 2: Arabic-English: Link Selection Results in running our link selection algorithm over the entire alignments to determine the most uncertain links according to each active learning strategy. The links are then looked up in the gold standard human alignment database and corrected. In scenarios where an alignment link is not pres</context>
</contexts>
<marker>Och, Ney, 2003</marker>
<rawString>Franz Josef Och and Hermann Ney. 2003. A systematic comparison of various statistical alignment models. Computational Linguistics, pages 19–51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
<author>WeiJing Zhu</author>
</authors>
<title>Bleu: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In ACL 2002,</booktitle>
<pages>311--318</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="23111" citStr="Papineni et al., 2002" startWordPosition="3824" endWordPosition="3827">We also train a configuration, where we substitute the final word alignment with gold standard manual alignment for the entire parallel corpus. This is an upper bound on the translation accuracy that can be achieved by any alignment link selection algorithm for this dataset. We now take our best link selection criteria, which is the confidence based method and re-train the MT system after eliciting manual information for only 20% of the alignment links. We observe that at this point we have reduced the AER from 37.09 to 26.57. The translation accuracy reported in Table 3, as measured by BLEU (Papineni et al., 2002) and METEOR (Lavie and Agarwal, 2007), also shows significant improvement and approaches the quality achieved using gold standard data. We did not perform MT experiments with Arabic-English dataset due to the incompatibility of tokenization schemes between the manually aligned parallel corpora and publicly available evaluation sets. 7 Conclusion Word-Alignment is a particularly challenging problem and has been addressed in a completely unsupervised manner thus far (Brown et al., 1993). While generative alignment models have been successful, lack of sufficient data, model assumptions and local </context>
</contexts>
<marker>Papineni, Roukos, Ward, Zhu, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, and WeiJing Zhu. 2002. Bleu: a method for automatic evaluation of machine translation. In ACL 2002, pages 311– 318, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Shen</author>
<author>Jie Zhang</author>
<author>Jian Su</author>
<author>Guodong Zhou</author>
<author>ChewLim Tan</author>
</authors>
<title>Multi-criteria-based active learning for named entity recognition.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics,</booktitle>
<pages>589</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6426" citStr="Shen et al., 2004" startWordPosition="997" endWordPosition="1000">polating human alignments with automatic alignments. They observe that while working with such datasets, alignments of higher quality should be given a much higher weight than the lower-quality alignments. Wu et al. (2006) learn separate models from labeled and unlabeled data using the standard EM algorithm. The two models are then interpolated as a learner in the semi-supervised AdaBoost algorithm to improve word alignment. Active learning has been applied to various fields of Natural Language Processing like statistical parsing, entity recognition among others (Hwa, 2004; Tang et al., 2001; Shen et al., 2004). In case of MT, the potential of active learning has remained largely unexplored. For Statistical Machine Translation, application of active learning has been focused on the task of selecting the most informative sentences to train the model, in order to reduce cost of data acquisition. Recent work in this area discussed multiple query selection strategies for a Statistical Phrase Based Translation system (Haffari et al., 2009). Their framework requires source text to be translated by the system and the translated data is used in a self-training setting to train MT models. To our knowledge, w</context>
</contexts>
<marker>Shen, Zhang, Su, Zhou, Tan, 2004</marker>
<rawString>Dan Shen, Jie Zhang, Jian Su, Guodong Zhou, and ChewLim Tan. 2004. Multi-criteria-based active learning for named entity recognition. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics, page 589, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min Tang</author>
<author>Xiaoqiang Luo</author>
<author>Salim Roukos</author>
</authors>
<title>Active learning for statistical natural language parsing.</title>
<date>2001</date>
<booktitle>In ACL ’02,</booktitle>
<pages>120--127</pages>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6406" citStr="Tang et al., 2001" startWordPosition="993" endWordPosition="996"> alignment by interpolating human alignments with automatic alignments. They observe that while working with such datasets, alignments of higher quality should be given a much higher weight than the lower-quality alignments. Wu et al. (2006) learn separate models from labeled and unlabeled data using the standard EM algorithm. The two models are then interpolated as a learner in the semi-supervised AdaBoost algorithm to improve word alignment. Active learning has been applied to various fields of Natural Language Processing like statistical parsing, entity recognition among others (Hwa, 2004; Tang et al., 2001; Shen et al., 2004). In case of MT, the potential of active learning has remained largely unexplored. For Statistical Machine Translation, application of active learning has been focused on the task of selecting the most informative sentences to train the model, in order to reduce cost of data acquisition. Recent work in this area discussed multiple query selection strategies for a Statistical Phrase Based Translation system (Haffari et al., 2009). Their framework requires source text to be translated by the system and the translated data is used in a self-training setting to train MT models.</context>
</contexts>
<marker>Tang, Luo, Roukos, 2001</marker>
<rawString>Min Tang, Xiaoqiang Luo, and Salim Roukos. 2001. Active learning for statistical natural language parsing. In ACL ’02, pages 120–127, Morristown, NJ, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Katrin Tomanek</author>
<author>Udo Hahn</author>
</authors>
<title>Semi-supervised active learning for sequence labeling.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP,</booktitle>
<pages>1039--1047</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Suntec, Singapore,</location>
<contexts>
<context position="4768" citStr="Tomanek and Hahn (2009)" startWordPosition="747" endWordPosition="750">k. 2 Related Work Semi-supervised learning is a broader area of Machine Learning, focusing on improving the learning process by usage of unlabeled data in conjunction with labeled data (Chapelle et al., 2006). Many semi-supervised learning algorithms use co-training framework, which assumes that the dataset has multiple views, and training different classifiers on a non-overlapping subset of these features provides additional labeled data (Zhu, 2005). Active query selection for training a semi-supervised learning algorithm is an interesting method that has been applied to clustering problems. Tomanek and Hahn (2009) applied active semi supervised learning to the sequence-labeling problem. Tur et al. (2005) describe active and semi-supervised learning methods for reducing labeling effort for spoken language understanding. They train supervised classification algorithms for the task of call classification and apply it to a large unlabeled dataset to select the least confident instances for human labeling. Researchers have begun to explore semisupervised word alignment models that use both labeled and unlabeled data. Fraser and Marcu (2006) pose the problem of alignment as a search problem in log-linear spa</context>
</contexts>
<marker>Tomanek, Hahn, 2009</marker>
<rawString>Katrin Tomanek and Udo Hahn. 2009. Semi-supervised active learning for sequence labeling. In Proceedings of the Joint Conference of the 47th Annual Meeting of the ACL and the 4th International Joint Conference on Natural Language Processing of the AFNLP, pages 1039–1047, Suntec, Singapore, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Tong</author>
<author>Daphne Koller</author>
</authors>
<title>Support vector machine active learning with applications to text classification.</title>
<date>2002</date>
<journal>Journal of Machine Learning,</journal>
<pages>45--66</pages>
<contexts>
<context position="11691" citStr="Tong and Koller, 2002" startWordPosition="1904" endWordPosition="1907">e learning attempts to optimize performance by selecting the most informative instances to label, where ‘informativeness’ is defined as maximal expected improvement in accuracy. The objective is to select optimal instance for an external expert to label and then run the learning method on the newly-labeled and previously-labeled instances to minimize prediction or translation error, repeating until either the maximal number of external queries XP(sJ1 |tI1) = ai 1 X= A θˆ = arg max θ K Y k=1 X A pθ(tk,a|sk) (6) K Y k=1 X a 12 is reached or a desired accuracy level is achieved. Several studies (Tong and Koller, 2002; Nguyen and Smeulders, 2004; Donmez and Carbonell, 2008) show that active learning greatly helps to reduce the labeling effort in various classification tasks. We discuss our active learning setup for word alignment in Algorithm 1. We start with an unlabeled dataset U = {(Sk, Tk)}, indexed by k, and a seed pool of partial alignment links A0 = {akij, ∀si ∈ Sk, tj ∈ Tk}. Each ak ij represents an alignment link from a sentence pair k that connects source word si with tj. This is usually an empty set at iteration t = 0. We iterate for T iterations. We take a pool-based active learning strategy, w</context>
</contexts>
<marker>Tong, Koller, 2002</marker>
<rawString>Simon Tong and Daphne Koller. 2002. Support vector machine active learning with applications to text classification. Journal of Machine Learning, pages 45–66.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gokhan Tur</author>
<author>Dilek Hakkani-Tr</author>
<author>Robert E Schapire</author>
</authors>
<title>Combining active and semi-supervised learning for spoken language understanding.</title>
<date>2005</date>
<journal>Speech Communication,</journal>
<volume>45</volume>
<issue>2</issue>
<pages>186</pages>
<contexts>
<context position="4860" citStr="Tur et al. (2005)" startWordPosition="760" endWordPosition="763">oving the learning process by usage of unlabeled data in conjunction with labeled data (Chapelle et al., 2006). Many semi-supervised learning algorithms use co-training framework, which assumes that the dataset has multiple views, and training different classifiers on a non-overlapping subset of these features provides additional labeled data (Zhu, 2005). Active query selection for training a semi-supervised learning algorithm is an interesting method that has been applied to clustering problems. Tomanek and Hahn (2009) applied active semi supervised learning to the sequence-labeling problem. Tur et al. (2005) describe active and semi-supervised learning methods for reducing labeling effort for spoken language understanding. They train supervised classification algorithms for the task of call classification and apply it to a large unlabeled dataset to select the least confident instances for human labeling. Researchers have begun to explore semisupervised word alignment models that use both labeled and unlabeled data. Fraser and Marcu (2006) pose the problem of alignment as a search problem in log-linear space with features coming from the IBM alignment models. The log-linear model is trained on th</context>
</contexts>
<marker>Tur, Hakkani-Tr, Schapire, 2005</marker>
<rawString>Gokhan Tur, Dilek Hakkani-Tr, and Robert E. Schapire. 2005. Combining active and semi-supervised learning for spoken language understanding. Speech Communication, 45(2):171 – 186.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicola Ueffing</author>
<author>Hermann Ney</author>
</authors>
<title>Word-level confidence estimation for machine translation.</title>
<date>2007</date>
<journal>Comput. Linguist.,</journal>
<volume>33</volume>
<issue>1</issue>
<contexts>
<context position="15688" citStr="Ueffing and Ney, 2007" startWordPosition="2588" endWordPosition="2591">utions of source-giventarget P(s/t) and target-given-source P(t/s) probabilities at the word level where si ∈ S and tj ∈ T. We define certainty of a link as the harmonic mean of the bidirectional probabilities. The selection strategy selects the least scoring links according to the formula below which corresponds to links with maximum uncertainty: 1 ) = 2 ∗ P (tj/si) ∗ P (si/tj) Score(aij/sI 1,tJ P(tj/si) + P(si/tj) (10) 5.2 Confidence Based: Posterior Alignment probabilities Confidence estimation for MT output is an interesting area with meaningful initial exploration (Blatz 13 et al., 2004; Ueffing and Ney, 2007). Given a sentence pair (sI1, tJ1) and its word alignment, we compute two confidence metrics at alignment link level – based on the posterior link probability and a simple IBM Model 1 as seen in Equation 13. We select the alignment links that the initial word aligner is least confident according to our metric and seek manual correction of the links. We use t2s to denote computation using higher order (IBM4) target-givensource models and s2t to denote source-given-target models. Targeting some of the uncertain parts of word alignment has already been shown to improve translation quality in SMT </context>
</contexts>
<marker>Ueffing, Ney, 2007</marker>
<rawString>Nicola Ueffing and Hermann Ney. 2007. Word-level confidence estimation for machine translation. Comput. Linguist., 33(1):9–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hua Wu</author>
<author>Haifeng Wang</author>
<author>Zhanyi Liu</author>
</authors>
<title>Boosting statistical word alignment using labeled and unlabeled data.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL on Main conference poster sessions,</booktitle>
<pages>913--920</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="6030" citStr="Wu et al. (2006)" startWordPosition="935" endWordPosition="938"> models. The log-linear model is trained on the available labeled data to improve performance. They propose a semisupervised training algorithm which alternates between discriminative error training on the labeled data to learn the weighting parameters and maximum-likelihood EM training on unlabeled data to estimate the parameters. Callison-Burch et al. (2004) also improve alignment by interpolating human alignments with automatic alignments. They observe that while working with such datasets, alignments of higher quality should be given a much higher weight than the lower-quality alignments. Wu et al. (2006) learn separate models from labeled and unlabeled data using the standard EM algorithm. The two models are then interpolated as a learner in the semi-supervised AdaBoost algorithm to improve word alignment. Active learning has been applied to various fields of Natural Language Processing like statistical parsing, entity recognition among others (Hwa, 2004; Tang et al., 2001; Shen et al., 2004). In case of MT, the potential of active learning has remained largely unexplored. For Statistical Machine Translation, application of active learning has been focused on the task of selecting the most in</context>
</contexts>
<marker>Wu, Wang, Liu, 2006</marker>
<rawString>Hua Wu, Haifeng Wang, and Zhanyi Liu. 2006. Boosting statistical word alignment using labeled and unlabeled data. In Proceedings of the COLING/ACL on Main conference poster sessions, pages 913–920, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Zhu</author>
</authors>
<title>Semi-Supervised Learning Literature Survey.</title>
<date>2005</date>
<tech>Technical Report 1530,</tech>
<institution>Computer Sciences, University of Wisconsin-Madison.</institution>
<note>http://www.cs.wisc.edu/∼jerryzhu/pub/ssl survey.pdf.</note>
<contexts>
<context position="4599" citStr="Zhu, 2005" startWordPosition="723" endWordPosition="724">ts in Section 6 have shown that our selection strategies reduce alignment error rates significantly over baseline. We conclude with discussion on future work. 2 Related Work Semi-supervised learning is a broader area of Machine Learning, focusing on improving the learning process by usage of unlabeled data in conjunction with labeled data (Chapelle et al., 2006). Many semi-supervised learning algorithms use co-training framework, which assumes that the dataset has multiple views, and training different classifiers on a non-overlapping subset of these features provides additional labeled data (Zhu, 2005). Active query selection for training a semi-supervised learning algorithm is an interesting method that has been applied to clustering problems. Tomanek and Hahn (2009) applied active semi supervised learning to the sequence-labeling problem. Tur et al. (2005) describe active and semi-supervised learning methods for reducing labeling effort for spoken language understanding. They train supervised classification algorithms for the task of call classification and apply it to a large unlabeled dataset to select the least confident instances for human labeling. Researchers have begun to explore s</context>
</contexts>
<marker>Zhu, 2005</marker>
<rawString>X. Zhu. 2005. Semi-Supervised Learning Literature Survey. Technical Report 1530, Computer Sciences, University of Wisconsin-Madison. http://www.cs.wisc.edu/∼jerryzhu/pub/ssl survey.pdf.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>