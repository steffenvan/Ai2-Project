<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.013915">
<title confidence="0.952031">
HLT-FBK: a Complete Temporal Processing System for QA TempEval
</title>
<author confidence="0.711859">
Paramita Mirza Anne-Lyse Minard
</author>
<affiliation confidence="0.722314">
FBK, Trento, Italy FBK, Trento, Italy
University of Trento minard@fbk.eu
</affiliation>
<email confidence="0.99543">
paramita@fbk.eu
</email>
<sectionHeader confidence="0.995586" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999572333333333">
The HLT-FBK system is a suite of SVMs-
based classification models for extracting time
expressions, events and temporal relations,
each with a set of features obtained with the
NewsReader NLP pipeline. HLT-FBK’s best
system runs ranked 1st in all three domains,
with a recall of 0.30 over all domains. Our at-
tempts on increasing recall by considering all
SRL predicates as events as well as utilizing
event co-reference information in extracting
temporal links result in significant improve-
ments.
</bodyText>
<sectionHeader confidence="0.998973" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999694">
QA TempEval is a continuation of the TempEval
task series (Verhagen et al., 2007; Verhagen et al.,
2010; UzZaman et al., 2013), which shifts its eval-
uation methodology from temporal information ex-
traction accuracy to temporal question-answering
(QA) accuracy. However, the main task is the same
as its predecessor tasks, which is to automatically
annotate texts with temporal information following
TimeML specification (Pustejovsky et al., 2003a).
This paper describes the HLT-FBK system sub-
mitted to QA TempEval. The system decomposes
the task into three sub-tasks, i.e. temporal expres-
sion (timex) extraction, event extraction and tempo-
ral relation extraction. Each sub-task is formulated
as a supervised classification problem using SVMs-
based classifiers, which make use of the information
acquired from the NewsReader1 NLP pipeline.
</bodyText>
<footnote confidence="0.93159">
1http://www.newsreader-project.eu
</footnote>
<sectionHeader confidence="0.629673" genericHeader="method">
2 Data, Resources and Tools
</sectionHeader>
<bodyText confidence="0.999919931034483">
The training data set is the TimeML annotated
data released by the task organizers, which includes
TBAQ-cleaned and TE3-Platinum corpora reused
from the TempEval-3 task (UzZaman et al., 2013).
We extended the training corpus for the timex ex-
traction system with the TempEval-3 silver corpus.
The test data are 30 plain texts of News, Wikipedia
and Blogs domains (10 documents each). For evalu-
ating the system, 294 temporal-based questions and
the test data annotated with entities relevant for the
questions are used.
The resources used by the system to extract some
features are lists of temporal signals extracted from
the TimeBank corpus (Pustejovsky et al., 2003b) and
a list of nominalizations extracted from the SPE-
CIALIST Lexicon2 distributed by the U.S. National
Library of Medicine, which contains commonly oc-
curring English words in addition to biomedical
terms, with syntactic and morphological informa-
tion. We extracted all nouns resulting from a nom-
inalization. Other features come from the annota-
tion of the addDiscourse tool (Pitler and Nenkova,
2009), which identifies discourse connectives and
assigns them to one of the four semantic classes:
Temporal, Expansion, Contingency and Compari-
son.
The MorphoPro module, part of the TextPro tool
suite3, is used to get the morphological analysis
of each token in a text. The time expression nor-
</bodyText>
<footnote confidence="0.99995">
2http://www.nlm.nih.gov/research/umls/
new_users/online_learning/LEX_001.html
3http://textpro.fbk.eu/
</footnote>
<page confidence="0.947047">
801
</page>
<bodyText confidence="0.911193642857143">
Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 801–805,
Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics
malization sub-task is carried out by TimeNorm4
(Bethard, 2013), a library for converting natural lan-
guage expressions of dates and times into their nor-
malized form.
The HLT-FBK system is a suite of classification
models that have been built and applied using Yam-
Cha5 (Kudo and Matsumoto, 2003), a text chunker
using the Support Vector Machines (SVMs) algo-
rithm. It supports the dynamic features that are de-
cided dynamically during the classification, multi-
class classification using either one-vs-rest or one-
vs-one strategies, and polynomial kernels.
</bodyText>
<sectionHeader confidence="0.977126" genericHeader="method">
3 The End-to-end System
</sectionHeader>
<subsectionHeader confidence="0.999928">
3.1 Pre-processing: NewsReader Pipeline
</subsectionHeader>
<bodyText confidence="0.999936333333333">
The data pre-processing was done using the NLP
pipeline developed for the NewsReader project.
The pipeline includes, amongst others, tokenization,
part-of-speech tagging, constituency parser, depen-
dency parser, named entity recognition, semantic
role labeling (SRL) and event co-reference.6
</bodyText>
<subsectionHeader confidence="0.999868">
3.2 Timex Extraction System
</subsectionHeader>
<bodyText confidence="0.999983052631579">
The task of recognizing the extent of a timex, as well
as determining the timex type (i.e. DATE, TIME, DU-
RATION and SET), is taken as a text chunking task.
Since the timex extent can be a multi-token expres-
sion, we employ the IOB2 tagging to annotate the
data, so each token will be classified into 9 classes:
B-DATE, I-DATE, B-TIME, I-TIME, B-DURATION, I-
DURATION, B-SET, I-SET and O (for other).
The classifier is built with one-vs-one strategy
for multi-class classification. The features used to
represent a token are token’s text, lemma, part-of-
speech (PoS) tag, chunk, named entity type (if any),
and whether a token matches regular expression pat-
terns for a time unit, part of a day, name of days,
name of months, duration (e.g. 1h3’), etc. In ad-
dition, all mentioned features for the preceding 4
and following 4 tokens, and the preceding 4 labels
tagged by the classifier, are also included in the fea-
ture set.
</bodyText>
<footnote confidence="0.782712166666667">
4http://github.com/bethard/timenorm
5http://chasen.org/˜taku/software/
yamcha/
6More information about the NewsReader pipeline, as well
as a demo, are available on the project website http://www.
newsreader-project.eu/results/.
</footnote>
<bodyText confidence="0.999704333333333">
For timex normalization, we decided to use
TimeNorm. For English, it is shown to be the
best performing system for most evaluation corpora
(Llorens et al., 2012). We added pre- and post-
processing rules in order to obtain the best normal-
ized form.
</bodyText>
<subsectionHeader confidence="0.999804">
3.3 Event Extraction System
</subsectionHeader>
<bodyText confidence="0.999928387096774">
Event detection is taken as a text chunking task, in
which tokens have to be classified into two classes:
EVENT (i.e. the token is included in an event extent)
or O (for other). Then events are classified into one
of the 7 TimeML classes (i.e. REPORTING, PERCEP-
TION, ASPECTUAL, I ACTION, I STATE, STATE and
OCCURRENCE).
The classification models are built with one-vs-
rest strategy for multi-class classification. For both
event extent identification and event classification
tasks we use various features to represent each to-
ken. The classic features are token’s lemma, PoS
tag, and entity type (if the token is part of a named
entity or a time expression). Other features that are
more specific for the task include: verb’s tense and
polarity7, whether the token is annotated as predi-
cate by the SRL module, whether it is part of an
event co-reference chain and whether it is in the
nominalization list. In addition, all mentioned fea-
tures for the preceding 4 and following 4 tokens, and
the preceding 4 labels tagged by the classifier, are
also considered as features.
Specifically for event classification, additional
features are used: token’s chunk, whether the token
is part of a temporal discourse connective, whether a
verb is the main verb of the sentence (root verb), the
predicate for which the token is part of a participant
and its semantic role (e.g. Arg0, Arg1), and finally
whether the token is in an event extent (annotated in
the previous step).
We submitted two different runs:
</bodyText>
<listItem confidence="0.99193">
• Run 1 (ev1) Two classifiers are used as described
above.
• Run 2 (ev2) We consider all predicates identified
by the SRL module as events. We then used a
classifier to determine the class of each event.
</listItem>
<footnote confidence="0.916574">
7The tense, aspect and polarity attributes of events, as de-
fined in TimeML, are obtained through manually written rules
based on the morphological analysis produced by MorphoPro.
</footnote>
<page confidence="0.987864">
802
</page>
<subsectionHeader confidence="0.851444">
3.4 Temporal Relation Extraction System
</subsectionHeader>
<bodyText confidence="0.998358585365854">
The temporal relation extraction system extracts
temporal relations (TLINKs) holding between two
events or between an event and a time expression.
We consider all combinations of event/event and
event/timex pairs within the same sentence (in a
forward manner8), and pairs of main events (root
verbs) of consecutive sentences, as candidate tem-
poral links.
Given an ordered pair of entities (e1, e2), either
event/event or event/timex pair, the classifier has
to assign a label, i.e one of the 13 TimeML tem-
poral relation types. However, we simplified the
considered temporal relation types to better fit the
QA TempEval task description and to deal with the
unbalanced training data as follows: (i) IDENTITY
and DURING are mapped to SIMULTANEOUS; (ii)
IBEFORE/IAFTER are mapped to BEFORE/AFTER;9
and (iii) INCLUDES, BEGINS and ENDS are con-
verted to their inverse counterparts (IS INCLUDED,
BEGUN BY and ENDED BY, resp.) by exchanging
the order of entities in the pair. In the end, we only
consider 6 temporal relation types (i.e. SIMULTANE-
OUS, BEFORE, AFTER, IS INCLUDED, BEGUN BY
and ENDED BY).
The classification models for event/event and
event/timex pairs are built with one-vs-one strategy
for multi-class classification. The overall approach
is largely inspired by an existing work for classifing
temporal relations (Mirza and Tonelli, 2014). The
implemented features are as follows:
String and grammatical features. Tokens, lem-
mas, PoS tags and chunks of e1 and e2, along with
a binary feature indicating whether e1 and e2 in an
event/event pair have the same PoS tags.
Textual context. Sentence distance (e.g. 0 if e1
and e2 are in the same sentence) and entity distance
inside a sentence (i.e. the number of entities occur-
ring between e1 and e2).
Entity attributes. Event attributes (class, tense,
aspect and polarity) taken from the output of the
event extraction module, and the timex attribute
</bodyText>
<footnote confidence="0.8364026">
8For example, for a sentence “...ev1...tmx1...ev2...”, the can-
didate pairs are (ev1, tmx1), (ev1, ev3) and (ev2, tmx1).
9Because event pairs of IBEFORE/IAFTER types are too
scarce as training examples, and they are by definition specific
types of BEFORE/AFTER.
</footnote>
<bodyText confidence="0.999215153846154">
(type) obtained from the timex extraction module of
e1 and e2; a binary feature to represent whether the
timex in an event/timex pair is the document creation
time; and four binary features to represent whether
e1 and e2 in an event/event pair have the same event
attributes or not. We also include as features the PoS
chain of VP chunks containing events (e.g. VHZ-
VBN-VVG for has been [raining]11, VM-VVB for
would [send]12), which captures tense and aspect,
as well as modality information of the event.
Dependency information. Dependency path ex-
isting between e1 and e2, and binary features indi-
cating whether e1/e2 is the root verb.
Temporal signals. Tokens of temporal signals oc-
curring around e1 and e2 and their positions with re-
spect to e1 and e2 (i.e. before/after e1, before/after
e2, or at the beginning of the sentence).
Temporal discourse connectives. We take into
account discourse connectives belonging to the Tem-
poral class, acquired from the addDiscourse tool.
Similar to temporal signals, tokens of connectives
occurring in the textual context of e1 and e2, and
their position with respect to e1 and e2, are used
as features. These features are only relevant for
event/event pairs.
There are two variations of system submitted:
</bodyText>
<listItem confidence="0.951728636363636">
• Run 1 (trel1) We incorporate pre-processing rules
based on timex pattern matching (e.g. from...to...,
between...and...), to recognize event/timex pairs
of BEGUN BY and ENDED BY types, which are
not well represented in the training corpus.
• Run 2 (trel2) Similar as Run 1, however, we also
incorporate the event co-reference information
obtained from the NewsReader pipeline. When-
ever two events co-refer, the event/event pair is
excluded from the classifier, and automatically la-
belled SIMULTANEOUS.
</listItem>
<sectionHeader confidence="0.999657" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999927714285714">
We submitted 4 system runs, i.e. the combinations
of 2 system runs for event extraction (ev1 and ev2)
and 2 system runs for temporal relation extraction
(trel1 and trel2). Table 1 shows HLT-FBK system
results in terms of coverage, precision, recall and F1-
score for the three considered domains; recall is the
main evaluation metric used to rank the systems.
</bodyText>
<page confidence="0.99691">
803
</page>
<table confidence="0.999876833333333">
Cov News F1 Cov Wikipedia F1 Cov Blogs F1 All domains
P R P R P R R
ev1-trel1 0.29 0.59 0.17 0.27 0.29 0.55 0.16 0.25 0.32 0.57 0.18 0.28 0.17
ev1-trel2 0.55 0.43 0.23 0.30 0.50 0.52 0.26 0.35 0.43 0.43 0.18 0.26 0.23
ev2-trel1 0.36 0.56 0.20 0.30 0.29 0.58 0.17 0.26 0.29 0.47 0.14 0.21 0.17
ev2-trel2 0.69 0.43 0.29 0.35 0.58 0.62 0.36 0.46 0.58 0.34 0.20 0.25 0.30
</table>
<tableCaption confidence="0.993691">
Table 1: HLT-FBK system results in terms of coverage (Cov), precision (P), recall (R) and F1-score (F1).
</tableCaption>
<table confidence="0.9995796">
Q News Unknown Q Wikipedia Unknown Q Blogs Unknown
Answered Ent Rel Answered Ent Rel Answered Ent Rel
Cor Inc Cor Inc Cor Inc
ev2-trel1 99 20 16 17 46 130 22 16 48 44 65 9 10 22 24
ev2-trel2 99 29 39 16 15 130 47 29 48 6 65 13 25 22 5
</table>
<tableCaption confidence="0.99088">
Table 2: HLT-FBK system results in terms of number of answered questions, correctly (Cor) and incorrectly (Inc), and
unanswered questions because of unknown entities (Ent) and unknown relations (Rel).
</tableCaption>
<table confidence="0.99977875">
News Wikipedia Blogs
ev tx ev tx ev tx
ev1 0.72 0.83 0.81 0.59 0.68 0.35
ev2 0.80 0.83 0.84 0.54 0.70 0.35
</table>
<tableCaption confidence="0.9931935">
Table 3: HLT-FBK system results in terms of recall on
identifying events (ev) and timexes (tx) with strict match.
</tableCaption>
<bodyText confidence="0.999936125">
The best results are achieved with the combina-
tion of ev2 and trel2, which significantly outper-
formed other participating systems and reported off-
the-shelf systems (not optimized for the task), i.e.
CAEVO with 0.17 and 0.18 recall scores on News
and Blogs respectively, and TIPSem with 0.19 recall
on Wikipedia.
Table 2 compares trel1 and trel2 runs, in terms
of the number of answered questions (correctly and
incorrectly) and unanswered questions (due to un-
known entities and non-established/unknown rela-
tions). Meanwhile, Table 3 compares ev1 and ev2
in terms of recall scores on identifying EVENT and
TIMEX3 tags, with the annotated test data as the
gold standard.10 Both results give more insight on
the question answering-based evaluation.
</bodyText>
<sectionHeader confidence="0.998594" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.980163675675676">
The timex extraction system performs well on News
texts, but not on texts from Wikipedia and Blogs (see
Table 3). Our error analysis shows that many time
10The gold standard only contains the annotated entities rel-
evant for answering the set of questions. For this reason, we
computed only the recall.
expressions in Wikipedia texts are not represented
in the training corpus (e.g. 4th millennium BCE).
Considering all SRL predicates as events (ev2)
improves the recall on identifying relevant events
(see Table 3), but lowers the precision on answer-
ing the questions (except for Wikipedia, in which
the precision is also improved, see Table 1). In this
task, the focus is on the recall and as expected the
best results are obtained by the system with the best
recall (ev2).
For temporal relation extraction, using event co-
reference information (trel2) reduces the number of
unknown relations (Rel) down by 77% in average for
all domains (see Table 2). Hence, the recall scores
increase significantly as shown in Table 1, especially
for the Wikipedia domain with almost 20% improve-
ment.
Our attempts on improving the overall perfor-
mance by increasing the recall (ev2 and trel2 runs)
work well on News and Wikipedia, shown by im-
proving F1-scores. This unfortunately does not hold
for Blogs, since the precision is greatly compro-
mised while the recall is only slightly improved.
In general, the system performs best on News and
Wikipedia texts, but not so well on informal Blogs
texts. This difference can be due to the fact that
our systems, as well as most of the pipeline’s mod-
ules, are trained using the corpus of formal news
texts. Moreover, Blogs texts contain orthographic
errors, a lot of punctuation signs, etc. and their pre-
processing with the pipeline do not run well.
</bodyText>
<page confidence="0.997545">
804
</page>
<sectionHeader confidence="0.998327" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999707333333333">
The research leading to this paper was partially sup-
ported by the European Union’s 7th Framework Pro-
gramme via the NewsReader Project (ICT-316404).
</bodyText>
<sectionHeader confidence="0.990249" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999731672727273">
Steven Bethard. 2013. A Synchronous Context Free
Grammar for Time Normalization. In Proceedings of
the 2013 Conference on Empirical Methods in Natural
Language Processing, pages 821–826, Seattle, Wash-
ington, USA.
Taku Kudo and Yuji Matsumoto. 2003. Fast Methods
for Kernel-based Text Analysis. In Proceedings of
the 41st Annual Meeting on Association for Computa-
tional Linguistics - Volume 1, ACL ’03, pages 24–31,
Stroudsburg, PA, USA.
Hector Llorens, Leon Derczynski, Robert Gaizauskas,
and Estela Saquete. 2012. TIMEN: An Open Tempo-
ral Expression Normalisation Resource. In Proceed-
ings of the Eight International Conference on Lan-
guage Resources and Evaluation (LREC’12), pages
3044–3051, Istanbul, Turkey.
Paramita Mirza and Sara Tonelli. 2014. Classifying
Temporal Relations with Simple Features. In Proceed-
ings of the 14th Conference of the European Chap-
ter of the Association for Computational Linguistics,
pages 308–317, Gothenburg, Sweden.
Emily Pitler and Ani Nenkova. 2009. Using Syntax to
Disambiguate Explicit Discourse Connectives in Text.
In Proceedings of the ACL-IJCNLP 2009 Conference
Short Papers, ACLShort ’09, pages 13–16, Strouds-
burg, PA, USA.
James Pustejovsky, Jos´e Casta˜no, Robert Ingria, Roser
Sauri, Robert Gaizauskas, Andrea Setzer, and Graham
Katz. 2003a. TimeML: Robust Specification of Event
and Temporal Expressions in Text. In Proceedings
of the Fifth International Workshop on Computational
Semantics (IWCS-5).
James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew
See, Robert Gaizauskas, Andrea Setzer, Dragomir
Radev, Beth Sundheim, David Day, Lisa Ferro, and
Marcia Lazo. 2003b. The TIMEBANK Corpus. In
Proceedings of Corpus Linguistics 2003, pages 647–
656, Lancaster, March.
Naushad UzZaman, Hector Llorens, Leon Derczynski,
James Allen, Marc Verhagen, and James Pustejovsky.
2013. SemEval-2013 Task 1: TempEval-3: Evaluating
Time Expressions, Events, and Temporal Relations.
In Proceedings of the Seventh International Workshop
on Semantic Evaluation, SemEval ’13, pages 1–9, At-
lanta, Georgia, USA.
Marc Verhagen, Robert Gaizauskas, Frank Schilder,
Mark Hepple, Graham Katz, and James Pustejovsky.
2007. SemEval-2007 Task 15: TempEval Tempo-
ral Relation Identification. In Proceedings of the
Fourth International Workshop on Semantic Evalua-
tions (SemEval-2007), pages 75–80.
Marc Verhagen, Roser Sauri, Tommaso Caselli, and
James Pustejovsky. 2010. SemEval-2010 Task 13:
TempEval-2. In Proceedings of the 5th International
Workshop on Semantic Evaluation, pages 57–62.
</reference>
<page confidence="0.998797">
805
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.139291">
<title confidence="0.994344">HLT-FBK: a Complete Temporal Processing System for QA TempEval</title>
<author confidence="0.680313">Paramita Mirza Anne-Lyse Minard</author>
<address confidence="0.434505">FBK, Trento, Italy FBK, Trento, Italy</address>
<affiliation confidence="0.449143">of Trento</affiliation>
<email confidence="0.983787">paramita@fbk.eu</email>
<abstract confidence="0.987972538461538">The HLT-FBK system is a suite of SVMsbased classification models for extracting time expressions, events and temporal relations, each with a set of features obtained with the NewsReader NLP pipeline. HLT-FBK’s best system runs ranked 1st in all three domains, with a recall of 0.30 over all domains. Our attempts on increasing recall by considering all SRL predicates as events as well as utilizing event co-reference information in extracting temporal links result in significant improvements.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
</authors>
<title>A Synchronous Context Free Grammar for Time Normalization.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>821--826</pages>
<location>Seattle, Washington, USA.</location>
<contexts>
<context position="3309" citStr="Bethard, 2013" startWordPosition="481" endWordPosition="482">e connectives and assigns them to one of the four semantic classes: Temporal, Expansion, Contingency and Comparison. The MorphoPro module, part of the TextPro tool suite3, is used to get the morphological analysis of each token in a text. The time expression nor2http://www.nlm.nih.gov/research/umls/ new_users/online_learning/LEX_001.html 3http://textpro.fbk.eu/ 801 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 801–805, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics malization sub-task is carried out by TimeNorm4 (Bethard, 2013), a library for converting natural language expressions of dates and times into their normalized form. The HLT-FBK system is a suite of classification models that have been built and applied using YamCha5 (Kudo and Matsumoto, 2003), a text chunker using the Support Vector Machines (SVMs) algorithm. It supports the dynamic features that are decided dynamically during the classification, multiclass classification using either one-vs-rest or onevs-one strategies, and polynomial kernels. 3 The End-to-end System 3.1 Pre-processing: NewsReader Pipeline The data pre-processing was done using the NLP </context>
</contexts>
<marker>Bethard, 2013</marker>
<rawString>Steven Bethard. 2013. A Synchronous Context Free Grammar for Time Normalization. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 821–826, Seattle, Washington, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Taku Kudo</author>
<author>Yuji Matsumoto</author>
</authors>
<title>Fast Methods for Kernel-based Text Analysis.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03,</booktitle>
<pages>24--31</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="3540" citStr="Kudo and Matsumoto, 2003" startWordPosition="518" endWordPosition="521">h token in a text. The time expression nor2http://www.nlm.nih.gov/research/umls/ new_users/online_learning/LEX_001.html 3http://textpro.fbk.eu/ 801 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 801–805, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics malization sub-task is carried out by TimeNorm4 (Bethard, 2013), a library for converting natural language expressions of dates and times into their normalized form. The HLT-FBK system is a suite of classification models that have been built and applied using YamCha5 (Kudo and Matsumoto, 2003), a text chunker using the Support Vector Machines (SVMs) algorithm. It supports the dynamic features that are decided dynamically during the classification, multiclass classification using either one-vs-rest or onevs-one strategies, and polynomial kernels. 3 The End-to-end System 3.1 Pre-processing: NewsReader Pipeline The data pre-processing was done using the NLP pipeline developed for the NewsReader project. The pipeline includes, amongst others, tokenization, part-of-speech tagging, constituency parser, dependency parser, named entity recognition, semantic role labeling (SRL) and event co</context>
</contexts>
<marker>Kudo, Matsumoto, 2003</marker>
<rawString>Taku Kudo and Yuji Matsumoto. 2003. Fast Methods for Kernel-based Text Analysis. In Proceedings of the 41st Annual Meeting on Association for Computational Linguistics - Volume 1, ACL ’03, pages 24–31, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hector Llorens</author>
<author>Leon Derczynski</author>
<author>Robert Gaizauskas</author>
<author>Estela Saquete</author>
</authors>
<title>TIMEN: An Open Temporal Expression Normalisation Resource.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12),</booktitle>
<pages>3044--3051</pages>
<location>Istanbul, Turkey.</location>
<contexts>
<context position="5488" citStr="Llorens et al., 2012" startWordPosition="813" endWordPosition="816">ay, name of days, name of months, duration (e.g. 1h3’), etc. In addition, all mentioned features for the preceding 4 and following 4 tokens, and the preceding 4 labels tagged by the classifier, are also included in the feature set. 4http://github.com/bethard/timenorm 5http://chasen.org/˜taku/software/ yamcha/ 6More information about the NewsReader pipeline, as well as a demo, are available on the project website http://www. newsreader-project.eu/results/. For timex normalization, we decided to use TimeNorm. For English, it is shown to be the best performing system for most evaluation corpora (Llorens et al., 2012). We added pre- and postprocessing rules in order to obtain the best normalized form. 3.3 Event Extraction System Event detection is taken as a text chunking task, in which tokens have to be classified into two classes: EVENT (i.e. the token is included in an event extent) or O (for other). Then events are classified into one of the 7 TimeML classes (i.e. REPORTING, PERCEPTION, ASPECTUAL, I ACTION, I STATE, STATE and OCCURRENCE). The classification models are built with one-vsrest strategy for multi-class classification. For both event extent identification and event classification tasks we us</context>
</contexts>
<marker>Llorens, Derczynski, Gaizauskas, Saquete, 2012</marker>
<rawString>Hector Llorens, Leon Derczynski, Robert Gaizauskas, and Estela Saquete. 2012. TIMEN: An Open Temporal Expression Normalisation Resource. In Proceedings of the Eight International Conference on Language Resources and Evaluation (LREC’12), pages 3044–3051, Istanbul, Turkey.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paramita Mirza</author>
<author>Sara Tonelli</author>
</authors>
<title>Classifying Temporal Relations with Simple Features.</title>
<date>2014</date>
<booktitle>In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics,</booktitle>
<pages>308--317</pages>
<location>Gothenburg,</location>
<contexts>
<context position="8872" citStr="Mirza and Tonelli, 2014" startWordPosition="1364" endWordPosition="1367">mapped to SIMULTANEOUS; (ii) IBEFORE/IAFTER are mapped to BEFORE/AFTER;9 and (iii) INCLUDES, BEGINS and ENDS are converted to their inverse counterparts (IS INCLUDED, BEGUN BY and ENDED BY, resp.) by exchanging the order of entities in the pair. In the end, we only consider 6 temporal relation types (i.e. SIMULTANEOUS, BEFORE, AFTER, IS INCLUDED, BEGUN BY and ENDED BY). The classification models for event/event and event/timex pairs are built with one-vs-one strategy for multi-class classification. The overall approach is largely inspired by an existing work for classifing temporal relations (Mirza and Tonelli, 2014). The implemented features are as follows: String and grammatical features. Tokens, lemmas, PoS tags and chunks of e1 and e2, along with a binary feature indicating whether e1 and e2 in an event/event pair have the same PoS tags. Textual context. Sentence distance (e.g. 0 if e1 and e2 are in the same sentence) and entity distance inside a sentence (i.e. the number of entities occurring between e1 and e2). Entity attributes. Event attributes (class, tense, aspect and polarity) taken from the output of the event extraction module, and the timex attribute 8For example, for a sentence “...ev1...tm</context>
</contexts>
<marker>Mirza, Tonelli, 2014</marker>
<rawString>Paramita Mirza and Sara Tonelli. 2014. Classifying Temporal Relations with Simple Features. In Proceedings of the 14th Conference of the European Chapter of the Association for Computational Linguistics, pages 308–317, Gothenburg, Sweden.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emily Pitler</author>
<author>Ani Nenkova</author>
</authors>
<title>Using Syntax to Disambiguate Explicit Discourse Connectives in Text.</title>
<date>2009</date>
<booktitle>In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09,</booktitle>
<pages>13--16</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="2668" citStr="Pitler and Nenkova, 2009" startWordPosition="397" endWordPosition="400">d the test data annotated with entities relevant for the questions are used. The resources used by the system to extract some features are lists of temporal signals extracted from the TimeBank corpus (Pustejovsky et al., 2003b) and a list of nominalizations extracted from the SPECIALIST Lexicon2 distributed by the U.S. National Library of Medicine, which contains commonly occurring English words in addition to biomedical terms, with syntactic and morphological information. We extracted all nouns resulting from a nominalization. Other features come from the annotation of the addDiscourse tool (Pitler and Nenkova, 2009), which identifies discourse connectives and assigns them to one of the four semantic classes: Temporal, Expansion, Contingency and Comparison. The MorphoPro module, part of the TextPro tool suite3, is used to get the morphological analysis of each token in a text. The time expression nor2http://www.nlm.nih.gov/research/umls/ new_users/online_learning/LEX_001.html 3http://textpro.fbk.eu/ 801 Proceedings of the 9th International Workshop on Semantic Evaluation (SemEval 2015), pages 801–805, Denver, Colorado, June 4-5, 2015. c�2015 Association for Computational Linguistics malization sub-task is</context>
</contexts>
<marker>Pitler, Nenkova, 2009</marker>
<rawString>Emily Pitler and Ani Nenkova. 2009. Using Syntax to Disambiguate Explicit Discourse Connectives in Text. In Proceedings of the ACL-IJCNLP 2009 Conference Short Papers, ACLShort ’09, pages 13–16, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Jos´e Casta˜no</author>
<author>Robert Ingria</author>
<author>Roser Sauri</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
</authors>
<title>TimeML: Robust Specification of Event and Temporal Expressions in Text.</title>
<date>2003</date>
<booktitle>In Proceedings of the Fifth International Workshop on Computational Semantics (IWCS-5).</booktitle>
<marker>Pustejovsky, Casta˜no, Ingria, Sauri, Gaizauskas, Setzer, Katz, 2003</marker>
<rawString>James Pustejovsky, Jos´e Casta˜no, Robert Ingria, Roser Sauri, Robert Gaizauskas, Andrea Setzer, and Graham Katz. 2003a. TimeML: Robust Specification of Event and Temporal Expressions in Text. In Proceedings of the Fifth International Workshop on Computational Semantics (IWCS-5).</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Patrick Hanks</author>
<author>Roser Sauri</author>
<author>Andrew See</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Dragomir Radev</author>
<author>Beth Sundheim</author>
<author>David Day</author>
<author>Lisa Ferro</author>
<author>Marcia Lazo</author>
</authors>
<title>The TIMEBANK Corpus.</title>
<date>2003</date>
<booktitle>In Proceedings of Corpus Linguistics</booktitle>
<pages>647--656</pages>
<location>Lancaster,</location>
<contexts>
<context position="1147" citStr="Pustejovsky et al., 2003" startWordPosition="167" endWordPosition="170">all by considering all SRL predicates as events as well as utilizing event co-reference information in extracting temporal links result in significant improvements. 1 Introduction QA TempEval is a continuation of the TempEval task series (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), which shifts its evaluation methodology from temporal information extraction accuracy to temporal question-answering (QA) accuracy. However, the main task is the same as its predecessor tasks, which is to automatically annotate texts with temporal information following TimeML specification (Pustejovsky et al., 2003a). This paper describes the HLT-FBK system submitted to QA TempEval. The system decomposes the task into three sub-tasks, i.e. temporal expression (timex) extraction, event extraction and temporal relation extraction. Each sub-task is formulated as a supervised classification problem using SVMsbased classifiers, which make use of the information acquired from the NewsReader1 NLP pipeline. 1http://www.newsreader-project.eu 2 Data, Resources and Tools The training data set is the TimeML annotated data released by the task organizers, which includes TBAQ-cleaned and TE3-Platinum corpora reused f</context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, Lazo, 2003</marker>
<rawString>James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See, Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim, David Day, Lisa Ferro, and Marcia Lazo. 2003b. The TIMEBANK Corpus. In Proceedings of Corpus Linguistics 2003, pages 647– 656, Lancaster, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naushad UzZaman</author>
<author>Hector Llorens</author>
<author>Leon Derczynski</author>
<author>James Allen</author>
<author>Marc Verhagen</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2013 Task 1: TempEval-3: Evaluating Time Expressions, Events, and Temporal Relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the Seventh International Workshop on Semantic Evaluation, SemEval ’13,</booktitle>
<pages>1--9</pages>
<location>Atlanta, Georgia, USA.</location>
<contexts>
<context position="829" citStr="UzZaman et al., 2013" startWordPosition="123" endWordPosition="126">tem is a suite of SVMsbased classification models for extracting time expressions, events and temporal relations, each with a set of features obtained with the NewsReader NLP pipeline. HLT-FBK’s best system runs ranked 1st in all three domains, with a recall of 0.30 over all domains. Our attempts on increasing recall by considering all SRL predicates as events as well as utilizing event co-reference information in extracting temporal links result in significant improvements. 1 Introduction QA TempEval is a continuation of the TempEval task series (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), which shifts its evaluation methodology from temporal information extraction accuracy to temporal question-answering (QA) accuracy. However, the main task is the same as its predecessor tasks, which is to automatically annotate texts with temporal information following TimeML specification (Pustejovsky et al., 2003a). This paper describes the HLT-FBK system submitted to QA TempEval. The system decomposes the task into three sub-tasks, i.e. temporal expression (timex) extraction, event extraction and temporal relation extraction. Each sub-task is formulated as a supervised classification prob</context>
</contexts>
<marker>UzZaman, Llorens, Derczynski, Allen, Verhagen, Pustejovsky, 2013</marker>
<rawString>Naushad UzZaman, Hector Llorens, Leon Derczynski, James Allen, Marc Verhagen, and James Pustejovsky. 2013. SemEval-2013 Task 1: TempEval-3: Evaluating Time Expressions, Events, and Temporal Relations. In Proceedings of the Seventh International Workshop on Semantic Evaluation, SemEval ’13, pages 1–9, Atlanta, Georgia, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Robert Gaizauskas</author>
<author>Frank Schilder</author>
<author>Mark Hepple</author>
<author>Graham Katz</author>
<author>James Pustejovsky</author>
</authors>
<title>SemEval-2007 Task 15: TempEval Temporal Relation Identification.</title>
<date>2007</date>
<booktitle>In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007),</booktitle>
<pages>75--80</pages>
<contexts>
<context position="783" citStr="Verhagen et al., 2007" startWordPosition="115" endWordPosition="118">bk.eu paramita@fbk.eu Abstract The HLT-FBK system is a suite of SVMsbased classification models for extracting time expressions, events and temporal relations, each with a set of features obtained with the NewsReader NLP pipeline. HLT-FBK’s best system runs ranked 1st in all three domains, with a recall of 0.30 over all domains. Our attempts on increasing recall by considering all SRL predicates as events as well as utilizing event co-reference information in extracting temporal links result in significant improvements. 1 Introduction QA TempEval is a continuation of the TempEval task series (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), which shifts its evaluation methodology from temporal information extraction accuracy to temporal question-answering (QA) accuracy. However, the main task is the same as its predecessor tasks, which is to automatically annotate texts with temporal information following TimeML specification (Pustejovsky et al., 2003a). This paper describes the HLT-FBK system submitted to QA TempEval. The system decomposes the task into three sub-tasks, i.e. temporal expression (timex) extraction, event extraction and temporal relation extraction. Each sub-task is </context>
</contexts>
<marker>Verhagen, Gaizauskas, Schilder, Hepple, Katz, Pustejovsky, 2007</marker>
<rawString>Marc Verhagen, Robert Gaizauskas, Frank Schilder, Mark Hepple, Graham Katz, and James Pustejovsky. 2007. SemEval-2007 Task 15: TempEval Temporal Relation Identification. In Proceedings of the Fourth International Workshop on Semantic Evaluations (SemEval-2007), pages 75–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Verhagen</author>
<author>Roser Sauri</author>
<author>Tommaso Caselli</author>
<author>James Pustejovsky</author>
</authors>
<date>2010</date>
<booktitle>SemEval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation,</booktitle>
<pages>57--62</pages>
<contexts>
<context position="806" citStr="Verhagen et al., 2010" startWordPosition="119" endWordPosition="122">bstract The HLT-FBK system is a suite of SVMsbased classification models for extracting time expressions, events and temporal relations, each with a set of features obtained with the NewsReader NLP pipeline. HLT-FBK’s best system runs ranked 1st in all three domains, with a recall of 0.30 over all domains. Our attempts on increasing recall by considering all SRL predicates as events as well as utilizing event co-reference information in extracting temporal links result in significant improvements. 1 Introduction QA TempEval is a continuation of the TempEval task series (Verhagen et al., 2007; Verhagen et al., 2010; UzZaman et al., 2013), which shifts its evaluation methodology from temporal information extraction accuracy to temporal question-answering (QA) accuracy. However, the main task is the same as its predecessor tasks, which is to automatically annotate texts with temporal information following TimeML specification (Pustejovsky et al., 2003a). This paper describes the HLT-FBK system submitted to QA TempEval. The system decomposes the task into three sub-tasks, i.e. temporal expression (timex) extraction, event extraction and temporal relation extraction. Each sub-task is formulated as a supervi</context>
</contexts>
<marker>Verhagen, Sauri, Caselli, Pustejovsky, 2010</marker>
<rawString>Marc Verhagen, Roser Sauri, Tommaso Caselli, and James Pustejovsky. 2010. SemEval-2010 Task 13: TempEval-2. In Proceedings of the 5th International Workshop on Semantic Evaluation, pages 57–62.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>