<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000079">
<title confidence="0.992547">
Context-dependent Semantic Parsing for Time Expressions
</title>
<author confidence="0.85546">
Kenton Lee†, Yoav Artzi†, Jesse Dodge‡∗, and Luke Zettlemoyer†
</author>
<affiliation confidence="0.417657">
† Computer Science &amp; Engineering, University of Washington, Seattle, WA
</affiliation>
<email confidence="0.819106">
{kentonl, yoav, lsz}@cs.washington.edu
</email>
<affiliation confidence="0.435377">
‡ Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA
</affiliation>
<email confidence="0.987244">
jessed@cs.cmu.edu
</email>
<sectionHeader confidence="0.993442" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999920846153846">
We present an approach for learning
context-dependent semantic parsers to
identify and interpret time expressions.
We use a Combinatory Categorial Gram-
mar to construct compositional meaning
representations, while considering contex-
tual cues, such as the document creation
time and the tense of the governing verb,
to compute the final time values. Exper-
iments on benchmark datasets show that
our approach outperforms previous state-
of-the-art systems, with error reductions of
13% to 21% in end-to-end performance.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998710400000001">
Time expressions present a number of challenges
for language understanding systems. They have
rich, compositional structure (e.g., “2nd Friday of
July”), can be easily confused with non-temporal
phrases (e.g., the word “May” can be a month
name or a verb), and can vary in meaning in dif-
ferent linguistic contexts (e.g., the word “Friday”
refers to different dates in the sentences “We met
on Friday” and “We will meet on Friday”). Recov-
ering the meaning of time expressions is therefore
challenging, but provides opportunities to study
context-dependent language use. In this paper, we
present the first context-dependent semantic pars-
ing approach for learning to identify and interpret
time expressions, addressing all three challenges.
Existing state-of-the-art methods use hand-
engineered rules for reasoning about time expres-
sions (Str¨otgen and Gertz, 2013). This includes
both detection, identifying a phrase as a time ex-
pression, and resolution, mapping such a phrase
into a standardized time value. While rule-based
approaches provide a natural way to express ex-
pert knowledge, it is relatively difficult to en-
∗Work conducted at the University of Washington.
code preferences between similar competing hy-
potheses and provide prediction confidence. Re-
cently, methods for learning probabilistic seman-
tic parsers have been shown to address such limi-
tations (Angeli et al., 2012; Angeli and Uszkoreit,
2013). However, these approaches do not account
for any surrounding linguistic context and were
mainly evaluated with gold standard mentions.
We propose to use a context-dependent se-
mantic parser for both detection and resolution
of time expressions. For both tasks, we make
use of a hand-engineered Combinatory Catego-
rial Grammar (CCG) to construct a set of mean-
ing representations that identify the time being
described. For example, this grammar maps the
phrase “2nd Friday of July” to the meaning repre-
sentation intersect(nth(2, friday), july), which
encodes the set of all such days. Detection is then
performed with a binary classifier to prune the set
of text spans that can be parsed with the gram-
mar (e.g., to tell that “born in 2000” has a time
expression but “a 2000 piece puzzle” does not).
For resolution, we consider mentions sequentially
and use a log-linear model to select the most likely
meaning for each. This choice depends on contex-
tual cues such as previous time expressions and
the tense of the governing verb (e.g., as required
to correctly resolve cases like “We should meet on
the 2nd Friday of July”).
Such an approach provides a good balance be-
tween hand engineering and learning. For the rel-
atively closed-class time expressions, we demon-
strate that it is possible to engineer a high quality
CCG lexicon. We take a data-driven approach for
grammar design, preferring a grammar with high
coverage even if it results in parsing ambiguities.
We then learn a model to accurately select between
competing parses and incorporate signals from the
surrounding context, both more difficult to model
with deterministic rules.
For both problems, we learn from TimeML an-
</bodyText>
<page confidence="0.943151">
1437
</page>
<note confidence="0.83105">
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1437–1447,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.999241846153846">
notations (Pustejovsky et al., 2005), which mark
mentions and the specific times they reference.
Training the detector is a supervised learning
problem, but resolution is more challenging, re-
quiring us to reason about latent parsing and
context-dependent decisions.
We evaluate performance in two domains: the
TempEval-3 corpus of newswire text (Uzzaman et
al., 2013) and the WikiWars corpus of Wikipedia
history articles (Mazur and Dale, 2010). On these
benchmark datasets, we present new state-of-the-
art results, with error reductions of up to 28% for
the detection task and 21% for the end-to-end task.
</bodyText>
<sectionHeader confidence="0.997999" genericHeader="introduction">
2 Formal Overview
</sectionHeader>
<bodyText confidence="0.999685193548387">
Time Expressions We follow the TIMEX3 stan-
dard (Pustejovsky et al., 2005) for defining time
expressions within documents. Let a document
D = (wi, ... , wn) be a sequence of n words wi
and a mention m = (i, j) indicate start and end
indices for a phrase (wi, ... , wj) in D. Define
a time expression e = (t, v) to include both a
temporal type t and value v.1 The temporal type
t E {Date, Time, Duration, Set} can take one of
four possible values, indicating if the expression
e is a date (e.g., “January 10, 2014”), time (e.g.,
“11:59 pm”), duration (e.g., “6 months”), or set
(e.g., “every year”). The value v is an extension
of the ISO 8601 standard, which encodes the time
that mention m refers to in the context provided by
document D. For example, in a document written
on Tuesday, January 7, 2014, “Friday,” “three days
later,” and “January 10th” would all resolve to the
value 2014-01-10. The time values are similarly
defined for a wide range of expressions, such as
underspecified dates (e.g., XXXX-01-10 for “Ja-
nunary 10th” when the year is not inferable from
context) and durations (P2D for “two days”).
Tasks Our goal is to find all time expressions in
an input document. We divide the problem into
two parts: detection and resolution. The detection
problem is to take an input document D and output
a mention set M = {mi  |i = 1... n} of phrases
in D that describe time expressions. The resolu-
tion problem (often also called normalization) is,
given a document D and a set of mentions M, to
</bodyText>
<footnote confidence="0.51168">
1Time expressions also have optional modifier values
for non-TIMEX properties (e.g., the modifier would contain
EARLY for the phrase “early march”). We do recover these
modifiers but omit them from the discussion since they are
not part of the official evaluation metrics.
</footnote>
<bodyText confidence="0.9919406">
map each m E M to the referred time expression
e. This paper addresses both of these tasks.
Approach We learn separate, but related, mod-
els for detection and resolution. For both tasks, we
define the space of possible compositional mean-
ing representations i, where each z E i defines
a unique time expression e. We use a log-linear
CCG (Steedman, 1996; Clark and Curran, 2007)
to rank possible meanings z E i for each men-
tion m in a document D, as described in Sec-
tion 4. Both detection (Section 5) and resolution
(Section 6) rely on the semantic parser to identify
likely mentions and resolve them within context.
For learning we assume access to TimeML data
containing documents labeled with time expres-
sions. Each document D has a set {(mi, ei)|i =
1... n}, where each mention mi marks a phrase
that resolves to the time expression ei.
Evaluation We evaluate performance (Sec-
tion 8) for both newswire text and Wikipedia
articles. We compare to the state-of-the-art
systems for end-to-end resolution (Str¨otgen and
Gertz, 2013) and resolution given gold men-
tions (Bethard, 2013b), both of which do not use
any machine learning techniques.
</bodyText>
<sectionHeader confidence="0.927547" genericHeader="method">
3 Representing Time
</sectionHeader>
<bodyText confidence="0.999370318181818">
We use simply typed lambda calculus to represent
time expressions. Our representation draws heav-
ily from the representation proposed by Angeli et
al. (2012), who introduced semantic parsing for
this task. There are five primitive types: duration
d, sequence s, range r, approximate reference a,
and numeral n, as described below. Table 1 lists
the available constants for each type.
Duration A period of time. Each duration is a
multiple of one of a closed set of possible base
durations (e.g., hour, day, and quarter), which
we refer to as its granularity. Table 1 includes the
complete set of base durations used.
Range A specific interval of time, following an
interval-based theory of time (Allen, 1981). The
interval length is one of the base durations, which
is the granularity of the range. Given two ranges
R and R&apos;, we say that R ⊆ R&apos; if the endpoints of
R lie on or within R&apos;.
Sequence A set of ranges with identical granu-
larity. The granularity of the sequence is that of
its members. For example, thursday, which has a
</bodyText>
<page confidence="0.986188">
1438
</page>
<table confidence="0.999694266666667">
Type Primitive Constants
Duration second, minute, hour, timeofday, day,
month, season, quarter, weekend,
week, year, decade, century , temp d
Sequence monday, tuesday, wednesday,
thursday, friday, saturday, sunday,
january, february, march, april,
may, june, july, august, september,
october, november, december, winter,
spring, summer, fall, night, morning,
afternoon, evening
Range ref time
Approximate present, future, past, unknown
reference
Numeral 1, 2, 3, 1999, 2000, 2001, .. .
</table>
<tableCaption confidence="0.9929905">
Table 1: The types and primitive logical constants sup-
ported by the logical language for time.
</tableCaption>
<bodyText confidence="0.999380107142857">
day granularity, denotes the set of all day-granular
ranges enclosing specific Thursdays. Given a
range R and sequence S, we say that R E S if
R is a member of S. Given two sequences S and
S&apos; we say that S C S&apos; if R E S implies R E S&apos;.
Approximate Reference An approximate time
relative to the reference time. For example, past
and future. To handle mentions such as “a while,”
we add the constant unknown.
Numeral An integer, for example, 5 or 1990.
Numerals are used to denote specific ranges, such
as the year 2001, or to modify a duration’s length.
Functions We also allow for functional types,
for example (s, r) is assigned to a function that
maps from sequences to ranges. Table 2 lists all
supported functions with example mentions.
Context Dependent Constants To mark places
where context-dependent choices will need to be
made during resolution, we use two placeholder
constants. First, ref time denotes the mention ref-
erence time, which is later set to either the docu-
ment time or a previously resolved mention. Sec-
ond, temp d is used in the shift function to deter-
mine its return granularity, as described in Table 2,
and is later replaced with the granularity of either
the first or second argument of the enclosing shift
function. Section 4.3 describes how these deci-
sions are made.
</bodyText>
<sectionHeader confidence="0.948333" genericHeader="method">
4 Parsing Time Expressions
</sectionHeader>
<bodyText confidence="0.937132">
We define a three-step derivation to resolve men-
tions to their TIMEX3 value. First, we use a CCG
to generate an initial logical form for the mention.
Next, we apply a set of operations that modify the
one week ago
</bodyText>
<equation confidence="0.9190145">
C N NP\NP
1 week ax.shift(ref time, −1 x x, temp d)
N/N
ax.1 x x
NP
1 x week
NP
shift(ref time, −1 x 1 x week, temp d)
</equation>
<figureCaption confidence="0.89186">
Figure 1: A CCG parse tree for the mention “one week
ago.” The tree includes forward (&gt;) and backward (&lt;)
application, as well as two type-shifting operations
</figureCaption>
<bodyText confidence="0.999165666666667">
initial logical form, as appropriate for its context.
Finally, the logical form is resolved to a TIMEX3
value using a deterministic process.
</bodyText>
<subsectionHeader confidence="0.98582">
4.1 Combinatory Categorial Grammars
</subsectionHeader>
<bodyText confidence="0.99995975">
CCG is a linguistically motivated categorial for-
malism for modeling a wide range of language
phenomena (Steedman, 1996; Steedman, 2000). A
CCG is defined by a lexicon and a set of combina-
tors. The lexicon pairs words with categories and
the combinators define how to combine categories
to create complete parse trees.
For example, Figure 1 shows a CCG parse tree
for the phrase “one week ago.” The parse tree is
read top to bottom, starting from assigning cate-
gories to words using the lexicon. The lexical en-
try ago �- NP\NP : λx.shift(ref time, −1 x
x, temp d) for the word “ago” pairs it with a cate-
gory that has syntactic type NP\NP and seman-
tics λx.shift(ref time, −1 x x, temp d). Each
intermediate parse node is then constructed by ap-
plying one of a small set of binary or unary opera-
tions (Steedman, 1996; Steedman, 2000), which
modify both the syntax and semantics. We use
backward (&lt;) and forward (&gt;) application and
several unary type-shifting rules to handle number
combinations. For example, in Figure 1 the cate-
gory of the span “one week” is combined with the
category of “ago” using backward application (&lt;).
Parsing concludes with a logical form representing
the meaning of the complete mention.
Hand Engineered Lexicon To parse time ex-
pressions, we use a CCG lexicon that includes 287
manually designed entries, along with automati-
cally generated entries such as numbers and com-
mon formats of dates and times. Figure 2 shows
example entries from our lexicon.
</bodyText>
<equation confidence="0.799719">
N
1 x week
</equation>
<page confidence="0.908172">
1439
</page>
<table confidence="0.543984666666667">
Function Description Example
Operations on durations.
xhn,hd,dii Given a duration D and a numeral N, return a duration D0 “after three days of questioning”
somehd,di that is N times longer than D. 3 x day
seqhd,si Given a duration D, returns D0, s.t. D0 is the result of Dxn “he left for a few days”
for some n &gt; 1. some(day)
</table>
<bodyText confidence="0.987323694444445">
Given a duration D, generate a sequence S, s.t. S includes “went to last year’s event”
all ranges of type D. previous(seq(year), ref time)
Operations for extracting a specific range from a sequence.
thishs hr rii Given a sequence S and a range R, returns the range R0 E “a meeting thisf ”
nexths,hr,rii S, s.t. there exists a range R00 where R C R00 and R0 C re
previoushs,hr,rii R00, and the length of R00 is minimal. this (friday, ref time)
nearest forwardhs,hr,rii Given a sequence S and a range R, returns the range R0 E S ti
nearest backwardhs,hr,rii that is the one after/before this(S, R). “arriving next month”
Given a sequence S and a range R, returns the range R0 E S next(seq(month), ref time)
that is closest to R in the forward/backward direction. “during the coming weekend”
nearest forward(seq(weekend), ref time)
Operations for sequences.
nthhn,hs,hs,siii Given a number N, a sequence S and a sequence S0, returns “until the second quarter of the year”
nthhn,hs,sii a sequence S00 C S s.t. for each Q E S00 there exists nth(2, seq(quarter), seq(year))
intersecths,hs,sii P E S0 and Q is the N-th entry in S that is a sub-interval “starts on June 28”
shifthr,hd,hd,riii of P. For the two-argument version, we use heuristics to intersect(june, nth(28, seq(day),
infer the third argument by determining a sequence of higher seq(month)))
granularity that is likely to contain the second argument. “a week ago, we went home”
Given sequences S, S0, where the duration of entries in S is shift(ref time, −1 x 1 x week, temp d)
shorter than these in S0, return a sequence S00 C S, where
for each R E S00 there exists R0 E S0 s.t. R C R0.
Given a range R, a duration D, and a duration G, return the
range R0, s.t. the starting point of R0 is moved by the length
of D. R0 is converted to represent a range of granularity G
by expanding if G has larger granularity, and is undefined if
G has smaller granularity.
Operations on numbers.
xhn,hn,nii Given two numerals, N0 and N00, returns a numeral N000 “the battle lasted for one hundred days”
+hn,hn,nii representing their product N0 x N00. 1 x 100 x day
Given two numerals, N0 and N00, returns a numeral N000 “open twenty four hours”
representing their sum N0 + N00. (20 + 4) x hour
Operations to mark sequences for specific TIMEX3 type annotations.
everyhs,si Given a sequence S, returns a sequence with SET temporal “one dose each day”
bchs,si type. every(seq(day))
Convert a year to BC. “during five hundred BC”
bc(nth(500,seq(year)))
</bodyText>
<tableCaption confidence="0.9677">
Table 2: Functional constants used to build logical expressions for representing time.
</tableCaption>
<subsectionHeader confidence="0.446888">
Manually Designed Entries:
</subsectionHeader>
<equation confidence="0.7751331875">
several �- NP/N : Ax.some(x)
this �- NP/N : Ax.this(x, ref time)
each �- NP/N : Ax.every(x)
before �- N\NP/NP :
Ax.Ay.shift(x, −1 x y, temp d)
year �- N : year
wednesday �- N : wednesday
’20s �- N : nth(192, seq(decade))
yesterday N : shift(ref time, −1 x day, temp d)
Automatically Generated Entries:
1992 �- N : nth(1992, seq(year))
nineteen ninety two �- N : nth(1992, seq(year))
09:30 �- N : intersect(nth(10, seq(hour), seq(day)),
nth(31, seq(minute), seq(hour)))
3rd �- N\N :
Ax.intersect(x, nth(3, seq(day), seq(month)))
</equation>
<figureCaption confidence="0.98987">
Figure 2: Example lexical entries.
</figureCaption>
<subsectionHeader confidence="0.983343">
4.2 Context-dependent Operations
</subsectionHeader>
<bodyText confidence="0.999740416666666">
To correctly resolve mentions to TIMEX3 val-
ues, the system must account for contextual in-
formation from various sources, including previ-
ous mentions in the document, the document cre-
ation time, and the sentence containing the men-
tion. We consider three types of context opera-
tions, each takes as input a logical form z&apos;, mod-
ifies it and returns a new logical form z. Each
context-dependent parse y specifies one operator
of each type, which are applied to the logical form
constructed by the CCG grammar, to produce the
final, context-dependent logical form LF(y).
Reference Time Resolution The logical con-
stant ref time is replaced by either dct, repre-
senting the document creation time, or last range,
the last r-typed mention resolved in the document.
For example, consider the mention “the follow-
ing year”, which is represented using the logical
form next(seq(year), ref time). Within the sen-
tence “1998 was colder than the following year”,
the resolution of “the following year” depends on
the previous mention “1998”. In contrast, in “The
following year will be warmer”, its resolution de-
pends on the document creation time.
</bodyText>
<page confidence="0.945816">
1440
</page>
<bodyText confidence="0.997180631578947">
Directionality Resolution If z0 is s-typed
we modify it to nearest forward(z0, ref time),
nearest backward(z0, ref time), or z0. For ex-
ample, given the sentence “...will be launched
in april”, the mention “april”, and its logi-
cal form april, we would like to resolve it to
the coming April, and therefore modify it to
nearest forward(april, ref time).
Shifting Granularity Every occurrence of the
logical constant temp d, which is used as an ar-
gument to the function shift (see Table 2), is re-
placed with the granularity of either the first argu-
ment, the origin of the shift, or the second argu-
ment, the delta of the shift. This determines the
final granularity of the output. For example, if the
reference time is 2002-01, the mention “two years
earlier” would resolve to either a month (since the
reference time is of month granularity) or a year
(since the delta is of year granularity).
</bodyText>
<subsectionHeader confidence="0.997912">
4.3 Resolving Logical Forms
</subsectionHeader>
<bodyText confidence="0.999985111111111">
For a context-dependent parse y, we compute the
TIMEX3 value TM(y) from the logical form z =
LF(y) with a deterministic step that performs a
single traversal of z. Each primitive logical con-
stant from Table 1 contributes to setting part of the
TIMEX3 value (for example, specifying the day of
the week) and the functional constants in Table 2
dictate transformations on the TIMEX3 values (for
example, shifting forward or backward in time).2
</bodyText>
<sectionHeader confidence="0.998325" genericHeader="method">
5 Detection
</sectionHeader>
<bodyText confidence="0.999850625">
The detection problem is to take an input docu-
ment D and output a mention set M = {mi  |i =
1, ... , n}, where each mention mi indexes a spe-
cific phrase in D that delimits a time expression.
Algorithm The detection algorithm considers
all phrases that our CCG grammar A (Section 4)
can parse, uses a learned classifier to further filter
this set, and finally resolves conflicts between any
overlapping predictions. We use a CKY algorithm
to efficiently determine which phrases the CCG
grammar can parse and only allow logical forms
for which there exists some context in which they
would produce a valid time expression, e.g. rul-
ing out intersect(monday, tuesday). Finally, we
build the set M of non-overlapping mentions us-
ing a step similar to non-maximum suppression:
</bodyText>
<footnote confidence="0.9936155">
2The full details are beyond the scope of this paper, but an
implementation is available on the author’s website.
</footnote>
<equation confidence="0.9887995">
P(t|m, D; A, θ) = B m,D,A)
1 + e &apos;O(
</equation>
<bodyText confidence="0.999863264705882">
where t indicates whether m is a time expression.
Features We use three types of indicator fea-
tures that test properties of the words in and
around the potential mention m.
Context tokens Indicate the presence of a set of
manually specified tokens near the mention. These
include quotations around the mention, the word
“old” after the mention, and prepositions of time
(such as “in”, “until”, and “during”) before.
Part of speech Indicators that pair each word
with its part of speech, as assigned by the Stanford
tagger (Toutanova et al., 2003).
Lexical group Each lexical entry belongs to one
of thirteen manually defined lexical groups which
cluster entries that contribute to the final time ex-
pression similarly. These groups include numbers,
days of the week, months, seasons, etc. For each
group, we include a feature indicating whether the
parse includes a lexical entry from that group.
Determiner dependency Indicates the presence
of a determiner in the mention and whether its par-
ent in the dependency tree (generated by the Stan-
ford parser (de Marneffe et al., 2006)) also resides
within the mention.
Learning Finally, we construct the training data
by considering all spans that (1) the CCG tempo-
ral grammar can parse and (2) are not strict sub-
spans of an annotated mention. All spans that ex-
actly matched the gold labels are used as positive
examples and all others are negatives. Given this
relaxed data, we learn the feature weights θ with
L1-regularization. We set the probability thresh-
old for detecting a time expression by optimizing
the F1 score over the training data.
</bodyText>
<sectionHeader confidence="0.999459" genericHeader="method">
6 Resolution
</sectionHeader>
<bodyText confidence="0.999676">
The resolution problem is to, given a document D
and a set of mentions M, map each m E M to
the correct time expression e. Section 4 defined
the mentions are sorted by length (longest first)
and iteratively added to M, as long as they do not
overlap with any mention already in M.
Filtering Model Given a mention m, its docu-
ment D, a feature function φ, the CCG lexicon A,
and feature weights θ, we use a logistic regression
model to define the probability distribution:
</bodyText>
<equation confidence="0.732832">
eθ·φ(m,D,A)
</equation>
<page confidence="0.899329">
1441
</page>
<bodyText confidence="0.999862554347826">
the space of possible time expression that can be
constructed for an input mention m in the context
of a document D. In general, there will be many
different possible derivations, and we will learn a
model for selecting the best one.
Model Let y be a context-dependent CCG parse,
which includes a parse tree TR(y), a set of context
operations CNTX(y) applied to the logical form
at the root of the tree, a final context-dependent
logical form LF(y) and a TIMEX3 value TM(y).
Define φ(m, D, y) E Rd to be a d-dimensional
feature–vector representation and θ E Rd to be a
parameter vector. The probability of a parse y for
mention m and document D is:
The inference problem at test time requires find-
ing the best resolution by solving y*(m, D) =
argmaxy P(y|m, D; θ, A), where the final output
TIMEX3 value is TM(y*(m, D)).
Inference We find the best context-dependent
parse y by enumeration, as follows. We first
parse the input mention m with a CKY-style algo-
rithm, following previous work (Zettlemoyer and
Collins, 2005). Due to the short length of time
expressions and the manually constructed lexicon,
we can perform exact inference. Given a parse,
we then enumerate all possible outcomes for the
context resolution operators. In practice, there are
never more than one hundred possibilities.
Features The resolution features test properties
of the linguistic context surrounding the mention
m, relative to the context-dependent CCG parse y.
Governor verb We define the governor verb to be
the nearest ancestor verb in the dependency parse
of any token in m. We include features indicat-
ing the concatenation of the part-of-speech of the
governor verb, its auxiliary verb if present, and
the selected direction resolution operator (see Sec-
tion 4.2). This feature helps to distinguish “They
met on Friday” from “They will meet on Friday.”
Temporal offset If the final logical form LF(y)
is a range, we define t to be the time difference
between TM(y) and the reference time. For ex-
ample, if the reference time is 2000-01-10 and the
mention resolves to 2000-01-01, then t is -9 days.
This feature indicates one of eleven bucketed val-
ues for t, including same day, less than a week,
less than a month, etc. It allows the model to en-
code the likely temporal progression of a narrative.
This feature is ignored if the granularity of TM(y)
or the reference time is greater than a year.
Shift granularity The logical constant shift (Ta-
ble 2) takes three arguments: the origin (range),
the delta (duration), and the output granularity
(duration). This indicator feature is the concate-
nation of each argument’s granularity for every
shift in LF(y). It allows the model to determine
whether “a year ago” refers to a year or a day.
Reference type Let r denote whether the refer-
ence time is the document creation time dct or the
last range last range. Let gl and gr denote the
granularities of LF(y) and the reference time, re-
spectively. We include features indicating the con-
catenations: r+gl, r+gr, and r+gl+gr. Addition-
ally, we include features indicating the concatena-
tion of r with each lexical entry used in the parse
TR(y). These features allow the model to encode
preferences in selecting the correct reference time.
Fine-grained type These features indicate the
fine-grained type of TM(y), such as day of the
month or week of the year. We also include a fea-
ture indicating the concatenation of each of these
features with the direction resolution operator that
was used. These features allow the model to repre-
sent, for example, that minutes of the year are less
likely than days of the month.
Intersections These features indicate the concate-
nation of the granularities of any two sequences
that appear as arguments to an intersect constant.
Learning To estimate the model parameters θ
we assume access to a set of training examples
{(mi, di, ei) : i = 1, ... , n}, where each mention
mi is paired with a document di and a TIMEX3
value ei. We use the AdaGrad algorithm (Duchi
et al., 2011) to optimize the conditional, marginal
log-likelihood of the data. For each mention, we
marginalize over all possible context-dependent
parses, using the predictions from the model on the
previous gold mentions to fill in missing context,
where necessary. After parameter estimation, we
set a probability threshold for retaining a resolved
time expression by optimizing value F1 (see Sec-
tion 8) over the training data.
</bodyText>
<sectionHeader confidence="0.999538" genericHeader="method">
7 Related Work
</sectionHeader>
<bodyText confidence="0.9932795">
Semantic parsers map sentences to logical repre-
sentations of their underlying meaning, e.g., Zelle
</bodyText>
<equation confidence="0.999169">
P(y|m, D; θ, A) = B �
�y� e &apos;O�m,D,y)
eθ·φ(m,D,y)
</equation>
<page confidence="0.956359">
1442
</page>
<bodyText confidence="0.999964647058824">
and Mooney (1996), Zettlemoyer and Collins
(2005), and Wong and Mooney (2007). Re-
cently, research in this area has focused on learn-
ing for various forms of relatively weak but eas-
ily gathered supervision. This includes learn-
ing from question-answer pairs (Clarke et al.,
2010; Liang et al., 2011; Kwiatkowski et al.,
2013), from conversational logs (Artzi and Zettle-
moyer, 2011), with distant supervision (Krish-
namurthy and Mitchell, 2012; Cai and Yates,
2013), and from sentences paired with system be-
havior (Goldwasser and Roth, 2011; Chen and
Mooney, 2011; Artzi and Zettlemoyer, 2013b).
Recently, Angeli et al. introduced the idea of
learning semantic parsers to resolve time expres-
sions (Angeli et al., 2012) and showed that the ap-
proach can generalize to multiple languages (An-
geli and Uszkoreit, 2013). Similarly, Bethard
demonstrated that a hand-engineered semantic
parser is also effective (Bethard, 2013b). How-
ever, these approaches did not use the semantic
parser for detection and did not model linguistic
context during resolution.
We build on a number of existing algorithmic
ideas, including using CCGs to build meaning
representations (Zettlemoyer and Collins, 2005;
Zettlemoyer and Collins, 2007; Kwiatkowski et
al., 2010; Kwiatkowski et al., 2011), building
derivations to transform the output of the CCG
parser based on context (Zettlemoyer and Collins,
2009), and using weakly supervised parameter up-
dates (Artzi and Zettlemoyer, 2011; Artzi and
Zettlemoyer, 2013b). However, we are the first to
use a semantic parsing grammar within a mention
detection algorithm, thereby avoiding the need to
represent the meaning of complete sentences, and
the first to develop a context-dependent model for
semantic parsing of time expressions.
Time expressions have been extensively stud-
ied as part of the TimeEx task, including 9 teams
who competed in the 2013 TempEval-3 com-
petition (Uzzaman et al., 2013). This line of
work builds on ideas from TimeBank (Puste-
jovsky et al., 2003) and a number of different
formal models for temporal reasoning, e.g. Allen
(1983), Moens and Steedman (1988). In 2013,
HeidelTime (Str¨otgen and Gertz, 2013) was the
top performing system. It used deterministic rules
defined over regular expressions to perform both
detection and resolution, and will provide a com-
parison system for our evaluation in Section 9. In
</bodyText>
<table confidence="0.997488">
Corpus Doc. Token TimeEx
TempEval-3 (Dev) 256 95,391 1,822
TempEval-3 (Test) 20 6,375 138
WikiWars (Dev) 17 98,746 2,228
WikiWars (Test) 5 19,052 363
</table>
<figureCaption confidence="0.992194">
Figure 3: Corpus statistics.
</figureCaption>
<bodyText confidence="0.989547454545455">
general, many different rule-based systems, e.g.
NavyTime (Chambers, 2013) and SUTime (Chang
and Manning, 2012), and learning systems, e.g.
ClearTK (Bethard, 2013a) and MANTime (Filan-
nino et al., 2013), did well for detection. How-
ever, rule-based approaches dominated in resolu-
tion; none of the top performers attempted to learn
to do resolution. Our approach is a hybrid of rule
based and learning, by using latent-variable learn-
ing techniques to estimate CCG parsing and con-
text resolution models from the provided data.
</bodyText>
<sectionHeader confidence="0.998296" genericHeader="method">
8 Experimental Setup
</sectionHeader>
<bodyText confidence="0.999794827586207">
Data We evaluate performance on the
TempEval-3 (Uzzaman et al., 2013) and Wiki-
Wars (Mazur and Dale, 2010) datasets. Figure 3
shows summary statistics for both datasets. For
the TempEval-3 corpus, we use the given training
and testing set splits. Since the training set
has lower inter-annotator agreement than the
testing set (Uzzaman et al., 2013), we manually
corrected all of the mistakes we found in the
training data.3 The original training set is denoted
Dev* and the corrected Dev. We report (1)
cross-validation development results on Dev*, (2)
cross-validation development and ablation results
for Dev, and (3) held-out test results after training
with Dev. For WikiWars, we randomly assigned
the data to include 17 training documents (2,228
time expressions) and 5 test documents (363 time
expressions). We use cross-validation on the train-
ing data for development. All cross-validation
experiments used 10 folds.
Implementation Our system was implemented
using the open source University of Washington
Semantic Parsing Framework (Artzi and Zettle-
moyer, 2013a). We used LIBLINEAR (Fan et al.,
2008) to learn the detection model.
Parameter Settings We use the same set of pa-
rameters for both datasets, chosen based on devel-
opment experiments. For detection, we set the reg-
ularization parameter to 10 with a stopping crite-
</bodyText>
<footnote confidence="0.78822">
3We modified the annotations for 18% of the mentions.
This relabeled corpus is available on the author’s website.
</footnote>
<page confidence="0.86725">
1443
</page>
<table confidence="0.982509368421053">
System Strict Detection Relaxed Detection Type Res. Value Resolution
Pre. Rec. F1 Pre. Rec. F1 Acc. F1 Acc. Pre. Rec. F1
Dev* This work 84.6 83.4 84.0 92.8 91.5 92.1 94.6 87.1 84.0 77.9 76.8 77.4
HeidelTime 83.7 83.4 83.5 91.7 91.4 91.6 95.0 87.0 84.1 77.1 76.8 77.0
Dev This work 92.7 89.6 91.1 97.4 94.1 95.7 97.1 92.9 91.5 89.1 86.1 87.6
Context ablation 92.7 89.3 91.0 97.5 93.9 95.7 97.1 92.9 89.8 87.6 84.3 85.9
HeidelTime 90.2 84.8 87.4 96.5 90.7 93.5 96.1 89.9 88.4 85.3 80.2 82.7
Test This work 86.1 80.4 83.1 94.6 88.4 91.4 93.4 85.4 90.2 85.3 79.7 82.4
HeidelTime 83.9 79.0 81.3 93.1 87.7 90.3 90.9 82.1 86.0 80.1 75.4 77.7
NavyTime 78.7 80.4 79.6 89.4 91.3 90.3 88.9 80.3 78.6 70.3 71.8 71.0
ClearTK 85.9 79.7 82.7 93.8 87.0 90.2 93.3 84.2 71.7 67.3 62.4 64.7
Figure 4: TempEval-3 development and test results, compared to the top systems in the shared task.
System Strict Detection Relaxed Detection Value Resolution
Pre. Rec. F1 Pre. Rec. F1 Acc. Pre. Rec. F1
Dev This work 90.3 83.0 86.5 98.1 90.1 93.9 87.6 85.9 78.9 82.3
Context ablation 90.9 80.1 85.2 98.2 86.5 92.0 68.5 67.3 59.3 63.0
HeidelTime 86.0 75.3 80.3 95.4 83.5 89.0 90.5 86.3 75.6 80.6
Test This work 87.7 78.8 83.0 97.6 87.6 92.3 84.6 82.5 74.1 78.1
HeidelTime 85.2 79.3 82.1 92.6 86.2 89.3 83.7 77.5 72.1 74.7
</table>
<figureCaption confidence="0.993692">
Figure 5: WikiWars development and test results.
</figureCaption>
<bodyText confidence="0.999926387096774">
rion of 0.01. For resolution, we set the learning
rate to 0.25 and ran AdaGrad for 5 iterations. All
features are initialized to have zero weights.
Evaluation Metrics We use the official
TempEval-3 scoring script and report the standard
metrics. We report detection precision, recall and
F1 with relaxed and strict metrics; a gold mention
is considered detected for the relaxed metric if
any of the output candidates overlap with it and is
detected for the strict metric if the extent of any
output candidates matches exactly. For resolution,
we report value accuracy, measuring correctness
of time expressions detected according to the
relaxed metric. We also report value precision,
recall, and F1, which score an expression as
correct if it is both correctly detected (relaxed)
and resolved. For end-to-end performance, value
F1 is the primary metric. Finally, we report
accuracy and F1 for temporal types, as defined in
Section 2, for the TempEval dataset (WikiWars
does not include type labels).
Comparison Systems We compare our system
primarily to HeidelTime (Str¨otgen and Gertz,
2013), which is state of the art in the end-to-
end task. For the TempEval-3 dataset, we also
compare to two other strong participants of the
shared task. These include NavyTime (Chambers,
2013), which had the top relaxed detection score,
and ClearTK (Bethard, 2013a), which had the top
strict detection score and type F1 score. We also
include a comparison with Bethard’s synchronous
</bodyText>
<table confidence="0.945013">
System Dev* Dev Test
This work 81.8 90.1 82.6
SCFG 77.0 81.6 78.9
</table>
<figureCaption confidence="0.995198">
Figure 6: TempEval-3 gold mention value accuracy.
</figureCaption>
<bodyText confidence="0.946505333333333">
context free grammar (SCFG) (Bethard, 2013b),
which is state-of-the-art in the task of resolution
with gold mention boundaries.
</bodyText>
<sectionHeader confidence="0.999284" genericHeader="evaluation">
9 Results
</sectionHeader>
<bodyText confidence="0.999919777777778">
End-to-end results Figure 4 shows develop-
ment and test results for TempEval-3. Figure 5
shows these numbers for WikiWars. In both
datasets, we achieve state-of-the-art test scores.
For detection, we show up to 3-point improve-
ments in strict and relaxed F1 scores. These num-
bers outperform all systems participating in the
shared task, which used a variety of techniques in-
cluding hand-engineered rules, CRF tagging mod-
els, and SVMs. For resolution, we show up to
4-point improvements in the value F1 score, also
outperforming participating systems, all of which
used hand-engineered rules for resolution.
Gold Mentions Figure 6 reports development
and test results with gold mentions.4 Our approach
outperforms the state of the art, SCFG (Bethard,
2013b), which also used a hand engineered gram-
mar, but did not use machine learning techniques.
</bodyText>
<footnote confidence="0.9921855">
4These numbers vary slightly from those reported; we did
not count the document creation times as mentions.
</footnote>
<page confidence="0.946112">
1444
</page>
<table confidence="0.99809125">
Error description %
Wrong directionality context operator 34.6
Wrong reference time context operator 15.7
Wrong shifting granularity context operator 14.4
Requires joint reasoning with events 9.2
Cascading error due to wrong detection 7.8
CCG parse error 2.0
Other error 16.3
</table>
<figureCaption confidence="0.984104">
Figure 8: Resolution errors from 10-fold cross valida-
tion of the TempEval-3 Dev dataset.
</figureCaption>
<figure confidence="0.997653736842105">
Value Precision (%)
TempEval-3 Dev WikiWars Dev
65 70 75 80 85 90
65 70 75 80 85 90
Value Recall (%)
94
92
90
88
86
84
94
92
90
88
86
84
This work
HeidelTime
</figure>
<figureCaption confidence="0.99869">
Figure 7: Value precision vs. recall for 10-fold cross
validation on TempEval-3 Dev and WikiWars Dev.
</figureCaption>
<bodyText confidence="0.999632444444444">
Precision vs. Recall Our probabilistic model
of time expression resolution allows us to eas-
ily tradeoff precision and recall for end-to-end
performance by varying the resolution probability
threshold. Figure 7 shows the precision vs. recall
of the resolved values from 10-fold cross valida-
tion of TempEval-3 Dev and WikiWars Dev. We
are able to achieve precision at or above 90% with
reasonable recall, nearly 70% for WikiWars and
over 85% for TempEval-3.
Ablation Study Figures 4-5 also show compar-
isons for our system with no context. We ablate
the ability to refer to the context during resolution
by removing contextual information from the res-
olution features and only allowing the document
creation time to be the reference time.
We see an interesting asymmetry in the effect of
modeling context across the two domains. We find
that context is much more important in WikiWars
(19 point difference) than in TempEval (2 point
difference). This result reaffirms the difference in
domains that Str¨otgen and Gertz (2012) noted dur-
ing the development of HeidelTime: history arti-
cles have narrative structure that moves back and
forth through time while newspaper text typically
describes events happening near the document cre-
ation time. This difference helps us to understand
why previous learning systems have been able to
ignore context and perform well on newswire text.
Error Analysis To investigate the source of er-
ror, we compute oracle results for resolving gold
mentions over the TempEval-3 Dev dataset. We
found that our system produces a correct candidate
derivation for 96% of the mentions.
We also manually categorized all resolution
errors for end-to-end performance with 10-fold
cross validation of the TempEval-3 Dev dataset,
shown in Figure 8. The lexicon allows for effec-
tive parsing, contributing to only 2% of the overall
errors. However, context is more challenging. The
three largest categories, responsible for 64.7% of
the errors, were incorrect use of the context oper-
ators. More expressive modeling will be required
to fully capture the complex pragmatics involved
in understanding time expressions.
</bodyText>
<sectionHeader confidence="0.99665" genericHeader="conclusions">
10 Conclusion
</sectionHeader>
<bodyText confidence="0.99999815">
We presented the first context-dependent semantic
parsing system to detect and resolve time expres-
sions. Both models used a Combinatory Catego-
rial Grammar (CCG) to construct a set of possible
temporal meaning representations. This grammar
defined the possible phrases for detection and the
inputs to a context-dependent reasoning step that
was used to construct the output time expression
during resolution. Experiments demonstrated that
our approach outperforms state-of-the-art systems.
In the future, we aim to develop joint models
for reasoning about events and time expressions,
including detection and resolution of temporal re-
lations. We are also interested in testing coverage
in new domains and investigating techniques for
semi-supervised learning and learning with noisy
data. We hypothesize that semantic parsing tech-
niques could help in all of these settings, provid-
ing a unified mechanism for compositional analy-
sis within temporal understanding problems.
</bodyText>
<sectionHeader confidence="0.997487" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.99993825">
The research was supported in part by
DARPA under the DEFT program through
the AFRL (FA8750-13-2-0019) and the CSSG
(N11AP20020), and the NSF (IIS-1115966, IIS-
1252835). The authors thank Nicholas FitzGerald,
Tom Kwiatkowski, and Mark Yatskar for helpful
discussions, and the anonymous reviewers for
helpful comments.
</bodyText>
<page confidence="0.989652">
1445
</page>
<sectionHeader confidence="0.990167" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999822911764706">
James F. Allen. 1981. An interval-based representa-
tion of temporal knowledge. In Proceedings of the
7th International Joint Conference on Artificial In-
telligence.
James F Allen. 1983. Maintaining knowledge about
temporal intervals. Communications of the ACM,
26(11):832–843.
Gabor Angeli and Jakob Uszkoreit. 2013. Language-
independent discriminative parsing of temporal ex-
pressions. In Proceedings of the Conference of the
Association of Computational Linguistics.
Gabor Angeli, Christopher D Manning, and Daniel Ju-
rafsky. 2012. Parsing time: Learning to interpret
time expressions. In Proceedings of the Conference
of the North American Chapter of the Association
for Computational Linguistics.
Y. Artzi and L.S. Zettlemoyer. 2011. Bootstrapping se-
mantic parsers from conversations. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing.
Y. Artzi and L.S. Zettlemoyer. 2013a. UW SPF: The
University of Washington Semantic Parsing Frame-
work.
Y. Artzi and L.S. Zettlemoyer. 2013b. Weakly super-
vised learning of semantic parsers for mapping in-
structions to actions. Transactions of the Associa-
tion for Computational Linguistics, 1(1):49–62.
Steven Bethard. 2013a. Cleartk-timeml: A minimalist
approach to tempeval 2013. In Second Joint Confer-
ence on Lexical and Computational Semantics.
Steven Bethard. 2013b. A synchronous context free
grammar for time normalization. In Proceedings
of the Conference on Empirical Methods in Natural
Language Processing.
Q. Cai and A. Yates. 2013. Semantic parsing free-
base: Towards open-domain semantic parsing. In
Joint Conference on Lexical and Computational Se-
mantics: Proceedings of the Main Conference and
the Shared Task: Semantic Textual Similarity.
Nathanael Chambers. 2013. Navytime: Event and
time ordering from raw text. In Second Joint Con-
ference on Lexical and Computational Semantics.
Angel X Chang and Christopher Manning. 2012. Su-
time: A library for recognizing and normalizing time
expressions. In Proceedings of the 8th International
Conference on Language Resources and Evaluation.
D.L. Chen and R.J. Mooney. 2011. Learning to in-
terpret natural language navigation instructions from
observations. In Proceedings of the National Con-
ference on Artificial Intelligence.
S. Clark and J. R. Curran. 2007. Wide-coverage ef-
ficient statistical parsing with CCG and log-linear
models. Computational Linguistics, 33(4):493–552.
J. Clarke, D. Goldwasser, M. Chang, and D. Roth.
2010. Driving semantic parsing from the world’s re-
sponse. In Proceedings of the Conference on Com-
putational Natural Language Learning.
Marie-Catherine de Marneffe, Bill MacCartney, and
Christopher D. Manning. 2006. Generating typed
dependency parses from phrase structure parses. In
Proceedings of the 5th International Conference on
Language Resources and Evaluation.
John Duchi, Elad Hazan, and Yoram Singer. 2011.
Adaptive subgradient methods for online learning
and stochastic optimization. The Journal of Ma-
chine Learning Research, 12:2121–2159.
Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, Xiang-
Rui Wang, and Chih-Jen Lin. 2008. LIBLINEAR:
A library for large linear classification. Journal of
Machine Learning Research, 9:1871–1874.
Michele Filannino, Gavin Brown, and Goran Nenadic.
2013. Mantime: Temporal expression identification
and normalization in the tempeval-3 challenge. In
Second Joint Conference on Lexical and Computa-
tional Semantics.
D. Goldwasser and D. Roth. 2011. Learning from
natural instructions. In Proceedings of the Interna-
tional Joint Conference on Artificial Intelligence.
J. Krishnamurthy and T. Mitchell. 2012. Weakly su-
pervised training of semantic parsers. In Proceed-
ings of the Joint Conference on Empirical Methods
in Natural Language Processing and Computational
Natural Language Learning.
T. Kwiatkowski, L.S. Zettlemoyer, S. Goldwater, and
M. Steedman. 2010. Inducing probabilistic CCG
grammars from logical form with higher-order uni-
fication. In Proceedings of the Conference on Em-
pirical Methods in Natural Language Processing.
T. Kwiatkowski, L.S. Zettlemoyer, S. Goldwater, and
M. Steedman. 2011. Lexical Generalization in CCG
Grammar Induction for Semantic Parsing. In Pro-
ceedings of the Conference on Empirical Methods
in Natural Language Processing.
T. Kwiatkowski, E. Choi, Y. Artzi, and L. Zettlemoyer.
2013. Scaling semantic parsers with on-the-fly on-
tology matching. In Proceedings of the Conference
on Empirical Methods in Natural Language Pro-
cessing.
P. Liang, M.I. Jordan, and D. Klein. 2011. Learn-
ing dependency-based compositional semantics. In
Proceedings of the Conference of the Association for
Computational Linguistics.
</reference>
<page confidence="0.834061">
1446
</page>
<reference confidence="0.999669953846154">
Pawet Mazur and Robert Dale. 2010. Wikiwars: a new
corpus for research on temporal expressions. In Pro-
ceedings of the Conference on Empirical Methods in
Natural Language Processing.
Marc Moens and Mark Steedman. 1988. Temporal on-
tology and temporal reference. Computational lin-
guistics, 14(2):15–28.
James Pustejovsky, Patrick Hanks, Roser Sauri, An-
drew See, Robert Gaizauskas, Andrea Setzer,
Dragomir Radev, Beth Sundheim, David Day, Lisa
Ferro, et al. 2003. The timebank corpus. In Corpus
linguistics.
James Pustejovsky, Bob Ingria, Roser Sauri, Jose Cas-
tano, Jessica Littman, Rob Gaizauskas, Andrea Set-
zer, Graham Katz, and Inderjeet Mani. 2005. The
specification language timeml. The language of
time: A reader, pages 545–557.
M. Steedman. 1996. Surface Structure and Interpreta-
tion. The MIT Press.
M. Steedman. 2000. The Syntactic Process. The MIT
Press.
Jannik Str¨otgen and Michael Gertz. 2012. Tempo-
ral tagging on different domains: Challenges, strate-
gies, and gold standards. In Proceedings of the Eigth
International Conference on Language Resources
and Evaluation.
Jannik Str¨otgen and Michael Gertz. 2013. Multilin-
gual and cross-domain temporal tagging. Language
Resources and Evaluation, 47(2):269–298.
Kristina Toutanova, Dan Klein, Christopher D Man-
ning, and Yoram Singer. 2003. Feature-rich part-of-
speech tagging with a cyclic dependency network.
In Proceedings of the 2003 Conference of the North
American Chapter of the Association for Computa-
tional Linguistics on Human Language Technology-
Volume 1.
N. Uzzaman, H. Llorens, L. Derczynski, M. Verhagen,
J. Allen, and J. Pustejovsky. 2013. Semeval-2013
task 1: Tempeval-3: Evaluating time expressions,
events, and temporal relations. In Proceedings of the
International Workshop on Semantic Evaluation.
Y.W. Wong and R.J. Mooney. 2007. Learning
synchronous grammars for semantic parsing with
lambda calculus. In Proceedings of the Conference
of the Association for Computational Linguistics.
J.M. Zelle and R.J. Mooney. 1996. Learning to
parse database queries using inductive logic pro-
gramming. In Proceedings of the National Confer-
ence on Artificial Intelligence.
L.S. Zettlemoyer and M. Collins. 2005. Learning to
map sentences to logical form: Structured classifica-
tion with probabilistic categorial grammars. In Pro-
ceedings of the Conference on Uncertainty in Artifi-
cial Intelligence.
L.S. Zettlemoyer and M. Collins. 2007. Online learn-
ing of relaxed CCG grammars for parsing to logi-
cal form. In Proceedings of the Joint Conference on
Empirical Methods in Natural Language Processing
and Computational Natural Language Learning.
L.S. Zettlemoyer and M. Collins. 2009. Learning
context-dependent mappings from sentences to log-
ical form. In Proceedings of the Joint Conference
of the Association for Computational Linguistics
and International Joint Conference on Natural Lan-
guage Processing.
</reference>
<page confidence="0.99387">
1447
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.745221">
<title confidence="0.999796">Context-dependent Semantic Parsing for Time Expressions</title>
<author confidence="0.992248">Yoav Jesse</author>
<author confidence="0.992248">Luke</author>
<affiliation confidence="0.92896">Science &amp; Engineering, University of Washington, Seattle,</affiliation>
<email confidence="0.959604">yoav,</email>
<affiliation confidence="0.991683">Technologies Institute, Carnegie Mellon University, Pittsburgh,</affiliation>
<email confidence="0.999925">jessed@cs.cmu.edu</email>
<abstract confidence="0.988160642857143">We present an approach for learning context-dependent semantic parsers to identify and interpret time expressions. We use a Combinatory Categorial Grammar to construct compositional meaning representations, while considering contextual cues, such as the document creation time and the tense of the governing verb, to compute the final time values. Experiments on benchmark datasets show that our approach outperforms previous stateof-the-art systems, with error reductions of 13% to 21% in end-to-end performance.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>An interval-based representation of temporal knowledge.</title>
<date>1981</date>
<booktitle>In Proceedings of the 7th International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="8427" citStr="Allen, 1981" startWordPosition="1357" endWordPosition="1358">vily from the representation proposed by Angeli et al. (2012), who introduced semantic parsing for this task. There are five primitive types: duration d, sequence s, range r, approximate reference a, and numeral n, as described below. Table 1 lists the available constants for each type. Duration A period of time. Each duration is a multiple of one of a closed set of possible base durations (e.g., hour, day, and quarter), which we refer to as its granularity. Table 1 includes the complete set of base durations used. Range A specific interval of time, following an interval-based theory of time (Allen, 1981). The interval length is one of the base durations, which is the granularity of the range. Given two ranges R and R&apos;, we say that R ⊆ R&apos; if the endpoints of R lie on or within R&apos;. Sequence A set of ranges with identical granularity. The granularity of the sequence is that of its members. For example, thursday, which has a 1438 Type Primitive Constants Duration second, minute, hour, timeofday, day, month, season, quarter, weekend, week, year, decade, century , temp d Sequence monday, tuesday, wednesday, thursday, friday, saturday, sunday, january, february, march, april, may, june, july, august</context>
</contexts>
<marker>Allen, 1981</marker>
<rawString>James F. Allen. 1981. An interval-based representation of temporal knowledge. In Proceedings of the 7th International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James F Allen</author>
</authors>
<title>Maintaining knowledge about temporal intervals.</title>
<date>1983</date>
<journal>Communications of the ACM,</journal>
<volume>26</volume>
<issue>11</issue>
<contexts>
<context position="28522" citStr="Allen (1983)" startWordPosition="4771" endWordPosition="4772"> and Zettlemoyer, 2013b). However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions. Time expressions have been extensively studied as part of the TimeEx task, including 9 teams who competed in the 2013 TempEval-3 competition (Uzzaman et al., 2013). This line of work builds on ideas from TimeBank (Pustejovsky et al., 2003) and a number of different formal models for temporal reasoning, e.g. Allen (1983), Moens and Steedman (1988). In 2013, HeidelTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3: Corpus statistics. general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.</context>
</contexts>
<marker>Allen, 1983</marker>
<rawString>James F Allen. 1983. Maintaining knowledge about temporal intervals. Communications of the ACM, 26(11):832–843.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabor Angeli</author>
<author>Jakob Uszkoreit</author>
</authors>
<title>Languageindependent discriminative parsing of temporal expressions.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="2275" citStr="Angeli and Uszkoreit, 2013" startWordPosition="326" endWordPosition="329">ineered rules for reasoning about time expressions (Str¨otgen and Gertz, 2013). This includes both detection, identifying a phrase as a time expression, and resolution, mapping such a phrase into a standardized time value. While rule-based approaches provide a natural way to express expert knowledge, it is relatively difficult to en∗Work conducted at the University of Washington. code preferences between similar competing hypotheses and provide prediction confidence. Recently, methods for learning probabilistic semantic parsers have been shown to address such limitations (Angeli et al., 2012; Angeli and Uszkoreit, 2013). However, these approaches do not account for any surrounding linguistic context and were mainly evaluated with gold standard mentions. We propose to use a context-dependent semantic parser for both detection and resolution of time expressions. For both tasks, we make use of a hand-engineered Combinatory Categorial Grammar (CCG) to construct a set of meaning representations that identify the time being described. For example, this grammar maps the phrase “2nd Friday of July” to the meaning representation intersect(nth(2, friday), july), which encodes the set of all such days. Detection is the</context>
<context position="27257" citStr="Angeli and Uszkoreit, 2013" startWordPosition="4575" endWordPosition="4579">y gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised </context>
</contexts>
<marker>Angeli, Uszkoreit, 2013</marker>
<rawString>Gabor Angeli and Jakob Uszkoreit. 2013. Languageindependent discriminative parsing of temporal expressions. In Proceedings of the Conference of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabor Angeli</author>
<author>Christopher D Manning</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Parsing time: Learning to interpret time expressions.</title>
<date>2012</date>
<booktitle>In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2246" citStr="Angeli et al., 2012" startWordPosition="322" endWordPosition="325">t methods use handengineered rules for reasoning about time expressions (Str¨otgen and Gertz, 2013). This includes both detection, identifying a phrase as a time expression, and resolution, mapping such a phrase into a standardized time value. While rule-based approaches provide a natural way to express expert knowledge, it is relatively difficult to en∗Work conducted at the University of Washington. code preferences between similar competing hypotheses and provide prediction confidence. Recently, methods for learning probabilistic semantic parsers have been shown to address such limitations (Angeli et al., 2012; Angeli and Uszkoreit, 2013). However, these approaches do not account for any surrounding linguistic context and were mainly evaluated with gold standard mentions. We propose to use a context-dependent semantic parser for both detection and resolution of time expressions. For both tasks, we make use of a hand-engineered Combinatory Categorial Grammar (CCG) to construct a set of meaning representations that identify the time being described. For example, this grammar maps the phrase “2nd Friday of July” to the meaning representation intersect(nth(2, friday), july), which encodes the set of al</context>
<context position="7876" citStr="Angeli et al. (2012)" startWordPosition="1263" endWordPosition="1266">e expressions. Each document D has a set {(mi, ei)|i = 1... n}, where each mention mi marks a phrase that resolves to the time expression ei. Evaluation We evaluate performance (Section 8) for both newswire text and Wikipedia articles. We compare to the state-of-the-art systems for end-to-end resolution (Str¨otgen and Gertz, 2013) and resolution given gold mentions (Bethard, 2013b), both of which do not use any machine learning techniques. 3 Representing Time We use simply typed lambda calculus to represent time expressions. Our representation draws heavily from the representation proposed by Angeli et al. (2012), who introduced semantic parsing for this task. There are five primitive types: duration d, sequence s, range r, approximate reference a, and numeral n, as described below. Table 1 lists the available constants for each type. Duration A period of time. Each duration is a multiple of one of a closed set of possible base durations (e.g., hour, day, and quarter), which we refer to as its granularity. Table 1 includes the complete set of base durations used. Range A specific interval of time, following an interval-based theory of time (Allen, 1981). The interval length is one of the base duration</context>
<context position="27162" citStr="Angeli et al., 2012" startWordPosition="4560" endWordPosition="4563">arch in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output o</context>
</contexts>
<marker>Angeli, Manning, Jurafsky, 2012</marker>
<rawString>Gabor Angeli, Christopher D Manning, and Daniel Jurafsky. 2012. Parsing time: Learning to interpret time expressions. In Proceedings of the Conference of the North American Chapter of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Artzi</author>
<author>L S Zettlemoyer</author>
</authors>
<title>Bootstrapping semantic parsers from conversations.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="26827" citStr="Artzi and Zettlemoyer, 2011" startWordPosition="4507" endWordPosition="4511">d time expression by optimizing value F1 (see Section 8) over the training data. 7 Related Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2011</marker>
<rawString>Y. Artzi and L.S. Zettlemoyer. 2011. Bootstrapping semantic parsers from conversations. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Artzi</author>
<author>L S Zettlemoyer</author>
</authors>
<date>2013</date>
<institution>UW SPF: The University of Washington Semantic Parsing Framework.</institution>
<contexts>
<context position="27036" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="4540" endWordPosition="4543"> = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zett</context>
<context position="30597" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="5087" endWordPosition="5091">ning set is denoted Dev* and the corrected Dev. We report (1) cross-validation development results on Dev*, (2) cross-validation development and ablation results for Dev, and (3) held-out test results after training with Dev. For WikiWars, we randomly assigned the data to include 17 training documents (2,228 time expressions) and 5 test documents (363 time expressions). We use cross-validation on the training data for development. All cross-validation experiments used 10 folds. Implementation Our system was implemented using the open source University of Washington Semantic Parsing Framework (Artzi and Zettlemoyer, 2013a). We used LIBLINEAR (Fan et al., 2008) to learn the detection model. Parameter Settings We use the same set of parameters for both datasets, chosen based on development experiments. For detection, we set the regularization parameter to 10 with a stopping crite3We modified the annotations for 18% of the mentions. This relabeled corpus is available on the author’s website. 1443 System Strict Detection Relaxed Detection Type Res. Value Resolution Pre. Rec. F1 Pre. Rec. F1 Acc. F1 Acc. Pre. Rec. F1 Dev* This work 84.6 83.4 84.0 92.8 91.5 92.1 94.6 87.1 84.0 77.9 76.8 77.4 HeidelTime 83.7 83.4 83</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2013</marker>
<rawString>Y. Artzi and L.S. Zettlemoyer. 2013a. UW SPF: The University of Washington Semantic Parsing Framework.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Artzi</author>
<author>L S Zettlemoyer</author>
</authors>
<title>Weakly supervised learning of semantic parsers for mapping instructions to actions.</title>
<date>2013</date>
<journal>Transactions of the Association for Computational Linguistics,</journal>
<volume>1</volume>
<issue>1</issue>
<contexts>
<context position="27036" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="4540" endWordPosition="4543"> = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zett</context>
<context position="30597" citStr="Artzi and Zettlemoyer, 2013" startWordPosition="5087" endWordPosition="5091">ning set is denoted Dev* and the corrected Dev. We report (1) cross-validation development results on Dev*, (2) cross-validation development and ablation results for Dev, and (3) held-out test results after training with Dev. For WikiWars, we randomly assigned the data to include 17 training documents (2,228 time expressions) and 5 test documents (363 time expressions). We use cross-validation on the training data for development. All cross-validation experiments used 10 folds. Implementation Our system was implemented using the open source University of Washington Semantic Parsing Framework (Artzi and Zettlemoyer, 2013a). We used LIBLINEAR (Fan et al., 2008) to learn the detection model. Parameter Settings We use the same set of parameters for both datasets, chosen based on development experiments. For detection, we set the regularization parameter to 10 with a stopping crite3We modified the annotations for 18% of the mentions. This relabeled corpus is available on the author’s website. 1443 System Strict Detection Relaxed Detection Type Res. Value Resolution Pre. Rec. F1 Pre. Rec. F1 Acc. F1 Acc. Pre. Rec. F1 Dev* This work 84.6 83.4 84.0 92.8 91.5 92.1 94.6 87.1 84.0 77.9 76.8 77.4 HeidelTime 83.7 83.4 83</context>
</contexts>
<marker>Artzi, Zettlemoyer, 2013</marker>
<rawString>Y. Artzi and L.S. Zettlemoyer. 2013b. Weakly supervised learning of semantic parsers for mapping instructions to actions. Transactions of the Association for Computational Linguistics, 1(1):49–62.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
</authors>
<title>Cleartk-timeml: A minimalist approach to tempeval 2013.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics.</booktitle>
<contexts>
<context position="7638" citStr="Bethard, 2013" startWordPosition="1228" endWordPosition="1229">on 4. Both detection (Section 5) and resolution (Section 6) rely on the semantic parser to identify likely mentions and resolve them within context. For learning we assume access to TimeML data containing documents labeled with time expressions. Each document D has a set {(mi, ei)|i = 1... n}, where each mention mi marks a phrase that resolves to the time expression ei. Evaluation We evaluate performance (Section 8) for both newswire text and Wikipedia articles. We compare to the state-of-the-art systems for end-to-end resolution (Str¨otgen and Gertz, 2013) and resolution given gold mentions (Bethard, 2013b), both of which do not use any machine learning techniques. 3 Representing Time We use simply typed lambda calculus to represent time expressions. Our representation draws heavily from the representation proposed by Angeli et al. (2012), who introduced semantic parsing for this task. There are five primitive types: duration d, sequence s, range r, approximate reference a, and numeral n, as described below. Table 1 lists the available constants for each type. Duration A period of time. Each duration is a multiple of one of a closed set of possible base durations (e.g., hour, day, and quarter)</context>
<context position="27362" citStr="Bethard, 2013" startWordPosition="4591" endWordPosition="4592">atkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b). However, we are the first </context>
<context position="29147" citStr="Bethard, 2013" startWordPosition="4865" endWordPosition="4866">Steedman (1988). In 2013, HeidelTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3: Corpus statistics. general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a) and MANTime (Filannino et al., 2013), did well for detection. However, rule-based approaches dominated in resolution; none of the top performers attempted to learn to do resolution. Our approach is a hybrid of rule based and learning, by using latent-variable learning techniques to estimate CCG parsing and context resolution models from the provided data. 8 Experimental Setup Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets. Figure 3 shows summary statistics for both datasets. For the TempEval-3 corpus, we use the given train</context>
<context position="33670" citStr="Bethard, 2013" startWordPosition="5615" endWordPosition="5616">if it is both correctly detected (relaxed) and resolved. For end-to-end performance, value F1 is the primary metric. Finally, we report accuracy and F1 for temporal types, as defined in Section 2, for the TempEval dataset (WikiWars does not include type labels). Comparison Systems We compare our system primarily to HeidelTime (Str¨otgen and Gertz, 2013), which is state of the art in the end-toend task. For the TempEval-3 dataset, we also compare to two other strong participants of the shared task. These include NavyTime (Chambers, 2013), which had the top relaxed detection score, and ClearTK (Bethard, 2013a), which had the top strict detection score and type F1 score. We also include a comparison with Bethard’s synchronous System Dev* Dev Test This work 81.8 90.1 82.6 SCFG 77.0 81.6 78.9 Figure 6: TempEval-3 gold mention value accuracy. context free grammar (SCFG) (Bethard, 2013b), which is state-of-the-art in the task of resolution with gold mention boundaries. 9 Results End-to-end results Figure 4 shows development and test results for TempEval-3. Figure 5 shows these numbers for WikiWars. In both datasets, we achieve state-of-the-art test scores. For detection, we show up to 3-point improvem</context>
</contexts>
<marker>Bethard, 2013</marker>
<rawString>Steven Bethard. 2013a. Cleartk-timeml: A minimalist approach to tempeval 2013. In Second Joint Conference on Lexical and Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven Bethard</author>
</authors>
<title>A synchronous context free grammar for time normalization.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="7638" citStr="Bethard, 2013" startWordPosition="1228" endWordPosition="1229">on 4. Both detection (Section 5) and resolution (Section 6) rely on the semantic parser to identify likely mentions and resolve them within context. For learning we assume access to TimeML data containing documents labeled with time expressions. Each document D has a set {(mi, ei)|i = 1... n}, where each mention mi marks a phrase that resolves to the time expression ei. Evaluation We evaluate performance (Section 8) for both newswire text and Wikipedia articles. We compare to the state-of-the-art systems for end-to-end resolution (Str¨otgen and Gertz, 2013) and resolution given gold mentions (Bethard, 2013b), both of which do not use any machine learning techniques. 3 Representing Time We use simply typed lambda calculus to represent time expressions. Our representation draws heavily from the representation proposed by Angeli et al. (2012), who introduced semantic parsing for this task. There are five primitive types: duration d, sequence s, range r, approximate reference a, and numeral n, as described below. Table 1 lists the available constants for each type. Duration A period of time. Each duration is a multiple of one of a closed set of possible base durations (e.g., hour, day, and quarter)</context>
<context position="27362" citStr="Bethard, 2013" startWordPosition="4591" endWordPosition="4592">atkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b). However, we are the first </context>
<context position="29147" citStr="Bethard, 2013" startWordPosition="4865" endWordPosition="4866">Steedman (1988). In 2013, HeidelTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3: Corpus statistics. general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a) and MANTime (Filannino et al., 2013), did well for detection. However, rule-based approaches dominated in resolution; none of the top performers attempted to learn to do resolution. Our approach is a hybrid of rule based and learning, by using latent-variable learning techniques to estimate CCG parsing and context resolution models from the provided data. 8 Experimental Setup Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets. Figure 3 shows summary statistics for both datasets. For the TempEval-3 corpus, we use the given train</context>
<context position="33670" citStr="Bethard, 2013" startWordPosition="5615" endWordPosition="5616">if it is both correctly detected (relaxed) and resolved. For end-to-end performance, value F1 is the primary metric. Finally, we report accuracy and F1 for temporal types, as defined in Section 2, for the TempEval dataset (WikiWars does not include type labels). Comparison Systems We compare our system primarily to HeidelTime (Str¨otgen and Gertz, 2013), which is state of the art in the end-toend task. For the TempEval-3 dataset, we also compare to two other strong participants of the shared task. These include NavyTime (Chambers, 2013), which had the top relaxed detection score, and ClearTK (Bethard, 2013a), which had the top strict detection score and type F1 score. We also include a comparison with Bethard’s synchronous System Dev* Dev Test This work 81.8 90.1 82.6 SCFG 77.0 81.6 78.9 Figure 6: TempEval-3 gold mention value accuracy. context free grammar (SCFG) (Bethard, 2013b), which is state-of-the-art in the task of resolution with gold mention boundaries. 9 Results End-to-end results Figure 4 shows development and test results for TempEval-3. Figure 5 shows these numbers for WikiWars. In both datasets, we achieve state-of-the-art test scores. For detection, we show up to 3-point improvem</context>
</contexts>
<marker>Bethard, 2013</marker>
<rawString>Steven Bethard. 2013b. A synchronous context free grammar for time normalization. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Q Cai</author>
<author>A Yates</author>
</authors>
<title>Semantic parsing freebase: Towards open-domain semantic parsing.</title>
<date>2013</date>
<booktitle>In Joint Conference on Lexical and Computational Semantics: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity.</booktitle>
<contexts>
<context position="26909" citStr="Cai and Yates, 2013" startWordPosition="4520" endWordPosition="4523"> Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a n</context>
</contexts>
<marker>Cai, Yates, 2013</marker>
<rawString>Q. Cai and A. Yates. 2013. Semantic parsing freebase: Towards open-domain semantic parsing. In Joint Conference on Lexical and Computational Semantics: Proceedings of the Main Conference and the Shared Task: Semantic Textual Similarity.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nathanael Chambers</author>
</authors>
<title>Navytime: Event and time ordering from raw text.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics.</booktitle>
<contexts>
<context position="29059" citStr="Chambers, 2013" startWordPosition="4852" endWordPosition="4853"> a number of different formal models for temporal reasoning, e.g. Allen (1983), Moens and Steedman (1988). In 2013, HeidelTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3: Corpus statistics. general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a) and MANTime (Filannino et al., 2013), did well for detection. However, rule-based approaches dominated in resolution; none of the top performers attempted to learn to do resolution. Our approach is a hybrid of rule based and learning, by using latent-variable learning techniques to estimate CCG parsing and context resolution models from the provided data. 8 Experimental Setup Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets. Figure 3 shows</context>
<context position="33599" citStr="Chambers, 2013" startWordPosition="5604" endWordPosition="5605">rt value precision, recall, and F1, which score an expression as correct if it is both correctly detected (relaxed) and resolved. For end-to-end performance, value F1 is the primary metric. Finally, we report accuracy and F1 for temporal types, as defined in Section 2, for the TempEval dataset (WikiWars does not include type labels). Comparison Systems We compare our system primarily to HeidelTime (Str¨otgen and Gertz, 2013), which is state of the art in the end-toend task. For the TempEval-3 dataset, we also compare to two other strong participants of the shared task. These include NavyTime (Chambers, 2013), which had the top relaxed detection score, and ClearTK (Bethard, 2013a), which had the top strict detection score and type F1 score. We also include a comparison with Bethard’s synchronous System Dev* Dev Test This work 81.8 90.1 82.6 SCFG 77.0 81.6 78.9 Figure 6: TempEval-3 gold mention value accuracy. context free grammar (SCFG) (Bethard, 2013b), which is state-of-the-art in the task of resolution with gold mention boundaries. 9 Results End-to-end results Figure 4 shows development and test results for TempEval-3. Figure 5 shows these numbers for WikiWars. In both datasets, we achieve stat</context>
</contexts>
<marker>Chambers, 2013</marker>
<rawString>Nathanael Chambers. 2013. Navytime: Event and time ordering from raw text. In Second Joint Conference on Lexical and Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angel X Chang</author>
<author>Christopher Manning</author>
</authors>
<title>Sutime: A library for recognizing and normalizing time expressions.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation.</booktitle>
<contexts>
<context position="29096" citStr="Chang and Manning, 2012" startWordPosition="4856" endWordPosition="4859">l models for temporal reasoning, e.g. Allen (1983), Moens and Steedman (1988). In 2013, HeidelTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3: Corpus statistics. general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a) and MANTime (Filannino et al., 2013), did well for detection. However, rule-based approaches dominated in resolution; none of the top performers attempted to learn to do resolution. Our approach is a hybrid of rule based and learning, by using latent-variable learning techniques to estimate CCG parsing and context resolution models from the provided data. 8 Experimental Setup Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets. Figure 3 shows summary statistics for both datasets</context>
</contexts>
<marker>Chang, Manning, 2012</marker>
<rawString>Angel X Chang and Christopher Manning. 2012. Sutime: A library for recognizing and normalizing time expressions. In Proceedings of the 8th International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L Chen</author>
<author>R J Mooney</author>
</authors>
<title>Learning to interpret natural language navigation instructions from observations.</title>
<date>2011</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="27007" citStr="Chen and Mooney, 2011" startWordPosition="4536" endWordPosition="4539">, Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettle</context>
</contexts>
<marker>Chen, Mooney, 2011</marker>
<rawString>D.L. Chen and R.J. Mooney. 2011. Learning to interpret natural language navigation instructions from observations. In Proceedings of the National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Clark</author>
<author>J R Curran</author>
</authors>
<title>Wide-coverage efficient statistical parsing with CCG and log-linear models.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<volume>33</volume>
<issue>4</issue>
<contexts>
<context position="6935" citStr="Clark and Curran, 2007" startWordPosition="1107" endWordPosition="1110">e optional modifier values for non-TIMEX properties (e.g., the modifier would contain EARLY for the phrase “early march”). We do recover these modifiers but omit them from the discussion since they are not part of the official evaluation metrics. map each m E M to the referred time expression e. This paper addresses both of these tasks. Approach We learn separate, but related, models for detection and resolution. For both tasks, we define the space of possible compositional meaning representations i, where each z E i defines a unique time expression e. We use a log-linear CCG (Steedman, 1996; Clark and Curran, 2007) to rank possible meanings z E i for each mention m in a document D, as described in Section 4. Both detection (Section 5) and resolution (Section 6) rely on the semantic parser to identify likely mentions and resolve them within context. For learning we assume access to TimeML data containing documents labeled with time expressions. Each document D has a set {(mi, ei)|i = 1... n}, where each mention mi marks a phrase that resolves to the time expression ei. Evaluation We evaluate performance (Section 8) for both newswire text and Wikipedia articles. We compare to the state-of-the-art systems </context>
</contexts>
<marker>Clark, Curran, 2007</marker>
<rawString>S. Clark and J. R. Curran. 2007. Wide-coverage efficient statistical parsing with CCG and log-linear models. Computational Linguistics, 33(4):493–552.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Clarke</author>
<author>D Goldwasser</author>
<author>M Chang</author>
<author>D Roth</author>
</authors>
<title>Driving semantic parsing from the world’s response.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Computational Natural Language Learning.</booktitle>
<contexts>
<context position="26724" citStr="Clarke et al., 2010" startWordPosition="4492" endWordPosition="4495"> necessary. After parameter estimation, we set a probability threshold for retaining a resolved time expression by optimizing value F1 (see Section 8) over the training data. 7 Related Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic p</context>
</contexts>
<marker>Clarke, Goldwasser, Chang, Roth, 2010</marker>
<rawString>J. Clarke, D. Goldwasser, M. Chang, and D. Roth. 2010. Driving semantic parsing from the world’s response. In Proceedings of the Conference on Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie-Catherine de Marneffe</author>
<author>Bill MacCartney</author>
<author>Christopher D Manning</author>
</authors>
<title>Generating typed dependency parses from phrase structure parses.</title>
<date>2006</date>
<booktitle>In Proceedings of the 5th International Conference on Language Resources and Evaluation.</booktitle>
<marker>de Marneffe, MacCartney, Manning, 2006</marker>
<rawString>Marie-Catherine de Marneffe, Bill MacCartney, and Christopher D. Manning. 2006. Generating typed dependency parses from phrase structure parses. In Proceedings of the 5th International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Duchi</author>
<author>Elad Hazan</author>
<author>Yoram Singer</author>
</authors>
<title>Adaptive subgradient methods for online learning and stochastic optimization.</title>
<date>2011</date>
<journal>The Journal of Machine Learning Research,</journal>
<pages>12--2121</pages>
<contexts>
<context position="25861" citStr="Duchi et al., 2011" startWordPosition="4355" endWordPosition="4358">g the concatenation of each of these features with the direction resolution operator that was used. These features allow the model to represent, for example, that minutes of the year are less likely than days of the month. Intersections These features indicate the concatenation of the granularities of any two sequences that appear as arguments to an intersect constant. Learning To estimate the model parameters θ we assume access to a set of training examples {(mi, di, ei) : i = 1, ... , n}, where each mention mi is paired with a document di and a TIMEX3 value ei. We use the AdaGrad algorithm (Duchi et al., 2011) to optimize the conditional, marginal log-likelihood of the data. For each mention, we marginalize over all possible context-dependent parses, using the predictions from the model on the previous gold mentions to fill in missing context, where necessary. After parameter estimation, we set a probability threshold for retaining a resolved time expression by optimizing value F1 (see Section 8) over the training data. 7 Related Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (</context>
</contexts>
<marker>Duchi, Hazan, Singer, 2011</marker>
<rawString>John Duchi, Elad Hazan, and Yoram Singer. 2011. Adaptive subgradient methods for online learning and stochastic optimization. The Journal of Machine Learning Research, 12:2121–2159.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rong-En Fan</author>
<author>Kai-Wei Chang</author>
<author>Cho-Jui Hsieh</author>
<author>XiangRui Wang</author>
<author>Chih-Jen Lin</author>
</authors>
<title>LIBLINEAR: A library for large linear classification.</title>
<date>2008</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>9--1871</pages>
<contexts>
<context position="30637" citStr="Fan et al., 2008" startWordPosition="5095" endWordPosition="5098"> report (1) cross-validation development results on Dev*, (2) cross-validation development and ablation results for Dev, and (3) held-out test results after training with Dev. For WikiWars, we randomly assigned the data to include 17 training documents (2,228 time expressions) and 5 test documents (363 time expressions). We use cross-validation on the training data for development. All cross-validation experiments used 10 folds. Implementation Our system was implemented using the open source University of Washington Semantic Parsing Framework (Artzi and Zettlemoyer, 2013a). We used LIBLINEAR (Fan et al., 2008) to learn the detection model. Parameter Settings We use the same set of parameters for both datasets, chosen based on development experiments. For detection, we set the regularization parameter to 10 with a stopping crite3We modified the annotations for 18% of the mentions. This relabeled corpus is available on the author’s website. 1443 System Strict Detection Relaxed Detection Type Res. Value Resolution Pre. Rec. F1 Pre. Rec. F1 Acc. F1 Acc. Pre. Rec. F1 Dev* This work 84.6 83.4 84.0 92.8 91.5 92.1 94.6 87.1 84.0 77.9 76.8 77.4 HeidelTime 83.7 83.4 83.5 91.7 91.4 91.6 95.0 87.0 84.1 77.1 76</context>
</contexts>
<marker>Fan, Chang, Hsieh, Wang, Lin, 2008</marker>
<rawString>Rong-En Fan, Kai-Wei Chang, Cho-Jui Hsieh, XiangRui Wang, and Chih-Jen Lin. 2008. LIBLINEAR: A library for large linear classification. Journal of Machine Learning Research, 9:1871–1874.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michele Filannino</author>
<author>Gavin Brown</author>
<author>Goran Nenadic</author>
</authors>
<title>Mantime: Temporal expression identification and normalization in the tempeval-3 challenge.</title>
<date>2013</date>
<booktitle>In Second Joint Conference on Lexical and Computational Semantics.</booktitle>
<contexts>
<context position="29186" citStr="Filannino et al., 2013" startWordPosition="4869" endWordPosition="4873">delTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3: Corpus statistics. general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a) and MANTime (Filannino et al., 2013), did well for detection. However, rule-based approaches dominated in resolution; none of the top performers attempted to learn to do resolution. Our approach is a hybrid of rule based and learning, by using latent-variable learning techniques to estimate CCG parsing and context resolution models from the provided data. 8 Experimental Setup Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets. Figure 3 shows summary statistics for both datasets. For the TempEval-3 corpus, we use the given training and testing set splits. Since the t</context>
</contexts>
<marker>Filannino, Brown, Nenadic, 2013</marker>
<rawString>Michele Filannino, Gavin Brown, and Goran Nenadic. 2013. Mantime: Temporal expression identification and normalization in the tempeval-3 challenge. In Second Joint Conference on Lexical and Computational Semantics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Goldwasser</author>
<author>D Roth</author>
</authors>
<title>Learning from natural instructions.</title>
<date>2011</date>
<booktitle>In Proceedings of the International Joint Conference on Artificial Intelligence.</booktitle>
<contexts>
<context position="26984" citStr="Goldwasser and Roth, 2011" startWordPosition="4532" endWordPosition="4535">ir underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning </context>
</contexts>
<marker>Goldwasser, Roth, 2011</marker>
<rawString>D. Goldwasser and D. Roth. 2011. Learning from natural instructions. In Proceedings of the International Joint Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Krishnamurthy</author>
<author>T Mitchell</author>
</authors>
<title>Weakly supervised training of semantic parsers.</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="26887" citStr="Krishnamurthy and Mitchell, 2012" startWordPosition="4515" endWordPosition="4519"> over the training data. 7 Related Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resol</context>
</contexts>
<marker>Krishnamurthy, Mitchell, 2012</marker>
<rawString>J. Krishnamurthy and T. Mitchell. 2012. Weakly supervised training of semantic parsers. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>L S Zettlemoyer</author>
<author>S Goldwater</author>
<author>M Steedman</author>
</authors>
<title>Inducing probabilistic CCG grammars from logical form with higher-order unification.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="27687" citStr="Kwiatkowski et al., 2010" startWordPosition="4637" endWordPosition="4640"> introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b). However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions. Time expressions have been extensively studied as part of the TimeEx task, including 9</context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2010</marker>
<rawString>T. Kwiatkowski, L.S. Zettlemoyer, S. Goldwater, and M. Steedman. 2010. Inducing probabilistic CCG grammars from logical form with higher-order unification. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>L S Zettlemoyer</author>
<author>S Goldwater</author>
<author>M Steedman</author>
</authors>
<title>Lexical Generalization in CCG Grammar Induction for Semantic Parsing.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="27714" citStr="Kwiatkowski et al., 2011" startWordPosition="4641" endWordPosition="4644">arning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b). However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions. Time expressions have been extensively studied as part of the TimeEx task, including 9 teams who competed in the </context>
</contexts>
<marker>Kwiatkowski, Zettlemoyer, Goldwater, Steedman, 2011</marker>
<rawString>T. Kwiatkowski, L.S. Zettlemoyer, S. Goldwater, and M. Steedman. 2011. Lexical Generalization in CCG Grammar Induction for Semantic Parsing. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Kwiatkowski</author>
<author>E Choi</author>
<author>Y Artzi</author>
<author>L Zettlemoyer</author>
</authors>
<title>Scaling semantic parsers with on-the-fly ontology matching.</title>
<date>2013</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="26771" citStr="Kwiatkowski et al., 2013" startWordPosition="4500" endWordPosition="4503">e set a probability threshold for retaining a resolved time expression by optimizing value F1 (see Section 8) over the training data. 7 Related Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). Howev</context>
</contexts>
<marker>Kwiatkowski, Choi, Artzi, Zettlemoyer, 2013</marker>
<rawString>T. Kwiatkowski, E. Choi, Y. Artzi, and L. Zettlemoyer. 2013. Scaling semantic parsers with on-the-fly ontology matching. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Liang</author>
<author>M I Jordan</author>
<author>D Klein</author>
</authors>
<title>Learning dependency-based compositional semantics.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="26744" citStr="Liang et al., 2011" startWordPosition="4496" endWordPosition="4499">ameter estimation, we set a probability threshold for retaining a resolved time expression by optimizing value F1 (see Section 8) over the training data. 7 Related Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effect</context>
</contexts>
<marker>Liang, Jordan, Klein, 2011</marker>
<rawString>P. Liang, M.I. Jordan, and D. Klein. 2011. Learning dependency-based compositional semantics. In Proceedings of the Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pawet Mazur</author>
<author>Robert Dale</author>
</authors>
<title>Wikiwars: a new corpus for research on temporal expressions.</title>
<date>2010</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</booktitle>
<contexts>
<context position="4604" citStr="Mazur and Dale, 2010" startWordPosition="694" endWordPosition="697">nd Annual Meeting of the Association for Computational Linguistics, pages 1437–1447, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics notations (Pustejovsky et al., 2005), which mark mentions and the specific times they reference. Training the detector is a supervised learning problem, but resolution is more challenging, requiring us to reason about latent parsing and context-dependent decisions. We evaluate performance in two domains: the TempEval-3 corpus of newswire text (Uzzaman et al., 2013) and the WikiWars corpus of Wikipedia history articles (Mazur and Dale, 2010). On these benchmark datasets, we present new state-of-theart results, with error reductions of up to 28% for the detection task and 21% for the end-to-end task. 2 Formal Overview Time Expressions We follow the TIMEX3 standard (Pustejovsky et al., 2005) for defining time expressions within documents. Let a document D = (wi, ... , wn) be a sequence of n words wi and a mention m = (i, j) indicate start and end indices for a phrase (wi, ... , wj) in D. Define a time expression e = (t, v) to include both a temporal type t and value v.1 The temporal type t E {Date, Time, Duration, Set} can take one</context>
<context position="29634" citStr="Mazur and Dale, 2010" startWordPosition="4943" endWordPosition="4946">-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a) and MANTime (Filannino et al., 2013), did well for detection. However, rule-based approaches dominated in resolution; none of the top performers attempted to learn to do resolution. Our approach is a hybrid of rule based and learning, by using latent-variable learning techniques to estimate CCG parsing and context resolution models from the provided data. 8 Experimental Setup Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets. Figure 3 shows summary statistics for both datasets. For the TempEval-3 corpus, we use the given training and testing set splits. Since the training set has lower inter-annotator agreement than the testing set (Uzzaman et al., 2013), we manually corrected all of the mistakes we found in the training data.3 The original training set is denoted Dev* and the corrected Dev. We report (1) cross-validation development results on Dev*, (2) cross-validation development and ablation results for Dev, and (3) held-out test results after training with Dev. For WikiWars, we randomly assigned the</context>
</contexts>
<marker>Mazur, Dale, 2010</marker>
<rawString>Pawet Mazur and Robert Dale. 2010. Wikiwars: a new corpus for research on temporal expressions. In Proceedings of the Conference on Empirical Methods in Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marc Moens</author>
<author>Mark Steedman</author>
</authors>
<title>Temporal ontology and temporal reference.</title>
<date>1988</date>
<journal>Computational linguistics,</journal>
<volume>14</volume>
<issue>2</issue>
<contexts>
<context position="28549" citStr="Moens and Steedman (1988)" startWordPosition="4773" endWordPosition="4776">er, 2013b). However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions. Time expressions have been extensively studied as part of the TimeEx task, including 9 teams who competed in the 2013 TempEval-3 competition (Uzzaman et al., 2013). This line of work builds on ideas from TimeBank (Pustejovsky et al., 2003) and a number of different formal models for temporal reasoning, e.g. Allen (1983), Moens and Steedman (1988). In 2013, HeidelTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3: Corpus statistics. general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a)</context>
</contexts>
<marker>Moens, Steedman, 1988</marker>
<rawString>Marc Moens and Mark Steedman. 1988. Temporal ontology and temporal reference. Computational linguistics, 14(2):15–28.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Patrick Hanks</author>
<author>Roser Sauri</author>
<author>Andrew See</author>
<author>Robert Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Dragomir Radev</author>
<author>Beth Sundheim</author>
<author>David Day</author>
<author>Lisa Ferro</author>
</authors>
<title>The timebank corpus. In Corpus linguistics.</title>
<date>2003</date>
<contexts>
<context position="28440" citStr="Pustejovsky et al., 2003" startWordPosition="4755" endWordPosition="4759">llins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b). However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions. Time expressions have been extensively studied as part of the TimeEx task, including 9 teams who competed in the 2013 TempEval-3 competition (Uzzaman et al., 2013). This line of work builds on ideas from TimeBank (Pustejovsky et al., 2003) and a number of different formal models for temporal reasoning, e.g. Allen (1983), Moens and Steedman (1988). In 2013, HeidelTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3: Corpus statistics. general, many different rule-based systems, e.g. NavyTi</context>
</contexts>
<marker>Pustejovsky, Hanks, Sauri, See, Gaizauskas, Setzer, Radev, Sundheim, Day, Ferro, 2003</marker>
<rawString>James Pustejovsky, Patrick Hanks, Roser Sauri, Andrew See, Robert Gaizauskas, Andrea Setzer, Dragomir Radev, Beth Sundheim, David Day, Lisa Ferro, et al. 2003. The timebank corpus. In Corpus linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James Pustejovsky</author>
<author>Bob Ingria</author>
<author>Roser Sauri</author>
<author>Jose Castano</author>
<author>Jessica Littman</author>
<author>Rob Gaizauskas</author>
<author>Andrea Setzer</author>
<author>Graham Katz</author>
<author>Inderjeet Mani</author>
</authors>
<title>The specification language timeml. The language of time: A reader,</title>
<date>2005</date>
<pages>545--557</pages>
<contexts>
<context position="4196" citStr="Pustejovsky et al., 2005" startWordPosition="633" endWordPosition="636">neer a high quality CCG lexicon. We take a data-driven approach for grammar design, preferring a grammar with high coverage even if it results in parsing ambiguities. We then learn a model to accurately select between competing parses and incorporate signals from the surrounding context, both more difficult to model with deterministic rules. For both problems, we learn from TimeML an1437 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1437–1447, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics notations (Pustejovsky et al., 2005), which mark mentions and the specific times they reference. Training the detector is a supervised learning problem, but resolution is more challenging, requiring us to reason about latent parsing and context-dependent decisions. We evaluate performance in two domains: the TempEval-3 corpus of newswire text (Uzzaman et al., 2013) and the WikiWars corpus of Wikipedia history articles (Mazur and Dale, 2010). On these benchmark datasets, we present new state-of-theart results, with error reductions of up to 28% for the detection task and 21% for the end-to-end task. 2 Formal Overview Time Express</context>
</contexts>
<marker>Pustejovsky, Ingria, Sauri, Castano, Littman, Gaizauskas, Setzer, Katz, Mani, 2005</marker>
<rawString>James Pustejovsky, Bob Ingria, Roser Sauri, Jose Castano, Jessica Littman, Rob Gaizauskas, Andrea Setzer, Graham Katz, and Inderjeet Mani. 2005. The specification language timeml. The language of time: A reader, pages 545–557.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>Surface Structure and Interpretation.</title>
<date>1996</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="6910" citStr="Steedman, 1996" startWordPosition="1105" endWordPosition="1106">essions also have optional modifier values for non-TIMEX properties (e.g., the modifier would contain EARLY for the phrase “early march”). We do recover these modifiers but omit them from the discussion since they are not part of the official evaluation metrics. map each m E M to the referred time expression e. This paper addresses both of these tasks. Approach We learn separate, but related, models for detection and resolution. For both tasks, we define the space of possible compositional meaning representations i, where each z E i defines a unique time expression e. We use a log-linear CCG (Steedman, 1996; Clark and Curran, 2007) to rank possible meanings z E i for each mention m in a document D, as described in Section 4. Both detection (Section 5) and resolution (Section 6) rely on the semantic parser to identify likely mentions and resolve them within context. For learning we assume access to TimeML data containing documents labeled with time expressions. Each document D has a set {(mi, ei)|i = 1... n}, where each mention mi marks a phrase that resolves to the time expression ei. Evaluation We evaluate performance (Section 8) for both newswire text and Wikipedia articles. We compare to the </context>
<context position="11448" citStr="Steedman, 1996" startWordPosition="1878" endWordPosition="1879"> operations that modify the one week ago C N NP\NP 1 week ax.shift(ref time, −1 x x, temp d) N/N ax.1 x x NP 1 x week NP shift(ref time, −1 x 1 x week, temp d) Figure 1: A CCG parse tree for the mention “one week ago.” The tree includes forward (&gt;) and backward (&lt;) application, as well as two type-shifting operations initial logical form, as appropriate for its context. Finally, the logical form is resolved to a TIMEX3 value using a deterministic process. 4.1 Combinatory Categorial Grammars CCG is a linguistically motivated categorial formalism for modeling a wide range of language phenomena (Steedman, 1996; Steedman, 2000). A CCG is defined by a lexicon and a set of combinators. The lexicon pairs words with categories and the combinators define how to combine categories to create complete parse trees. For example, Figure 1 shows a CCG parse tree for the phrase “one week ago.” The parse tree is read top to bottom, starting from assigning categories to words using the lexicon. The lexical entry ago �- NP\NP : λx.shift(ref time, −1 x x, temp d) for the word “ago” pairs it with a category that has syntactic type NP\NP and semantics λx.shift(ref time, −1 x x, temp d). Each intermediate parse node is</context>
</contexts>
<marker>Steedman, 1996</marker>
<rawString>M. Steedman. 1996. Surface Structure and Interpretation. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>The MIT Press.</publisher>
<contexts>
<context position="11465" citStr="Steedman, 2000" startWordPosition="1880" endWordPosition="1881"> modify the one week ago C N NP\NP 1 week ax.shift(ref time, −1 x x, temp d) N/N ax.1 x x NP 1 x week NP shift(ref time, −1 x 1 x week, temp d) Figure 1: A CCG parse tree for the mention “one week ago.” The tree includes forward (&gt;) and backward (&lt;) application, as well as two type-shifting operations initial logical form, as appropriate for its context. Finally, the logical form is resolved to a TIMEX3 value using a deterministic process. 4.1 Combinatory Categorial Grammars CCG is a linguistically motivated categorial formalism for modeling a wide range of language phenomena (Steedman, 1996; Steedman, 2000). A CCG is defined by a lexicon and a set of combinators. The lexicon pairs words with categories and the combinators define how to combine categories to create complete parse trees. For example, Figure 1 shows a CCG parse tree for the phrase “one week ago.” The parse tree is read top to bottom, starting from assigning categories to words using the lexicon. The lexical entry ago �- NP\NP : λx.shift(ref time, −1 x x, temp d) for the word “ago” pairs it with a category that has syntactic type NP\NP and semantics λx.shift(ref time, −1 x x, temp d). Each intermediate parse node is then constructed</context>
</contexts>
<marker>Steedman, 2000</marker>
<rawString>M. Steedman. 2000. The Syntactic Process. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jannik Str¨otgen</author>
<author>Michael Gertz</author>
</authors>
<title>Temporal tagging on different domains: Challenges, strategies, and gold standards.</title>
<date>2012</date>
<booktitle>In Proceedings of the Eigth International Conference on Language Resources and Evaluation.</booktitle>
<marker>Str¨otgen, Gertz, 2012</marker>
<rawString>Jannik Str¨otgen and Michael Gertz. 2012. Temporal tagging on different domains: Challenges, strategies, and gold standards. In Proceedings of the Eigth International Conference on Language Resources and Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jannik Str¨otgen</author>
<author>Michael Gertz</author>
</authors>
<title>Multilingual and cross-domain temporal tagging.</title>
<date>2013</date>
<journal>Language Resources and Evaluation,</journal>
<volume>47</volume>
<issue>2</issue>
<marker>Str¨otgen, Gertz, 2013</marker>
<rawString>Jannik Str¨otgen and Michael Gertz. 2013. Multilingual and cross-domain temporal tagging. Language Resources and Evaluation, 47(2):269–298.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kristina Toutanova</author>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
<author>Yoram Singer</author>
</authors>
<title>Feature-rich part-ofspeech tagging with a cyclic dependency network.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language TechnologyVolume 1.</booktitle>
<contexts>
<context position="20327" citStr="Toutanova et al., 2003" startWordPosition="3405" endWordPosition="3408">n is available on the author’s website. P(t|m, D; A, θ) = B m,D,A) 1 + e &apos;O( where t indicates whether m is a time expression. Features We use three types of indicator features that test properties of the words in and around the potential mention m. Context tokens Indicate the presence of a set of manually specified tokens near the mention. These include quotations around the mention, the word “old” after the mention, and prepositions of time (such as “in”, “until”, and “during”) before. Part of speech Indicators that pair each word with its part of speech, as assigned by the Stanford tagger (Toutanova et al., 2003). Lexical group Each lexical entry belongs to one of thirteen manually defined lexical groups which cluster entries that contribute to the final time expression similarly. These groups include numbers, days of the week, months, seasons, etc. For each group, we include a feature indicating whether the parse includes a lexical entry from that group. Determiner dependency Indicates the presence of a determiner in the mention and whether its parent in the dependency tree (generated by the Stanford parser (de Marneffe et al., 2006)) also resides within the mention. Learning Finally, we construct th</context>
</contexts>
<marker>Toutanova, Klein, Manning, Singer, 2003</marker>
<rawString>Kristina Toutanova, Dan Klein, Christopher D Manning, and Yoram Singer. 2003. Feature-rich part-ofspeech tagging with a cyclic dependency network. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language TechnologyVolume 1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Uzzaman</author>
<author>H Llorens</author>
<author>L Derczynski</author>
<author>M Verhagen</author>
<author>J Allen</author>
<author>J Pustejovsky</author>
</authors>
<title>Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations.</title>
<date>2013</date>
<booktitle>In Proceedings of the International Workshop on Semantic Evaluation.</booktitle>
<contexts>
<context position="4527" citStr="Uzzaman et al., 2013" startWordPosition="682" endWordPosition="685">c rules. For both problems, we learn from TimeML an1437 Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 1437–1447, Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics notations (Pustejovsky et al., 2005), which mark mentions and the specific times they reference. Training the detector is a supervised learning problem, but resolution is more challenging, requiring us to reason about latent parsing and context-dependent decisions. We evaluate performance in two domains: the TempEval-3 corpus of newswire text (Uzzaman et al., 2013) and the WikiWars corpus of Wikipedia history articles (Mazur and Dale, 2010). On these benchmark datasets, we present new state-of-theart results, with error reductions of up to 28% for the detection task and 21% for the end-to-end task. 2 Formal Overview Time Expressions We follow the TIMEX3 standard (Pustejovsky et al., 2005) for defining time expressions within documents. Let a document D = (wi, ... , wn) be a sequence of n words wi and a mention m = (i, j) indicate start and end indices for a phrase (wi, ... , wj) in D. Define a time expression e = (t, v) to include both a temporal type t</context>
<context position="28364" citStr="Uzzaman et al., 2013" startWordPosition="4742" endWordPosition="4745">nsform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b). However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions. Time expressions have been extensively studied as part of the TimeEx task, including 9 teams who competed in the 2013 TempEval-3 competition (Uzzaman et al., 2013). This line of work builds on ideas from TimeBank (Pustejovsky et al., 2003) and a number of different formal models for temporal reasoning, e.g. Allen (1983), Moens and Steedman (1988). In 2013, HeidelTime (Str¨otgen and Gertz, 2013) was the top performing system. It used deterministic rules defined over regular expressions to perform both detection and resolution, and will provide a comparison system for our evaluation in Section 9. In Corpus Doc. Token TimeEx TempEval-3 (Dev) 256 95,391 1,822 TempEval-3 (Test) 20 6,375 138 WikiWars (Dev) 17 98,746 2,228 WikiWars (Test) 5 19,052 363 Figure 3</context>
<context position="29598" citStr="Uzzaman et al., 2013" startWordPosition="4936" endWordPosition="4939">istics. general, many different rule-based systems, e.g. NavyTime (Chambers, 2013) and SUTime (Chang and Manning, 2012), and learning systems, e.g. ClearTK (Bethard, 2013a) and MANTime (Filannino et al., 2013), did well for detection. However, rule-based approaches dominated in resolution; none of the top performers attempted to learn to do resolution. Our approach is a hybrid of rule based and learning, by using latent-variable learning techniques to estimate CCG parsing and context resolution models from the provided data. 8 Experimental Setup Data We evaluate performance on the TempEval-3 (Uzzaman et al., 2013) and WikiWars (Mazur and Dale, 2010) datasets. Figure 3 shows summary statistics for both datasets. For the TempEval-3 corpus, we use the given training and testing set splits. Since the training set has lower inter-annotator agreement than the testing set (Uzzaman et al., 2013), we manually corrected all of the mistakes we found in the training data.3 The original training set is denoted Dev* and the corrected Dev. We report (1) cross-validation development results on Dev*, (2) cross-validation development and ablation results for Dev, and (3) held-out test results after training with Dev. Fo</context>
</contexts>
<marker>Uzzaman, Llorens, Derczynski, Verhagen, Allen, Pustejovsky, 2013</marker>
<rawString>N. Uzzaman, H. Llorens, L. Derczynski, M. Verhagen, J. Allen, and J. Pustejovsky. 2013. Semeval-2013 task 1: Tempeval-3: Evaluating time expressions, events, and temporal relations. In Proceedings of the International Workshop on Semantic Evaluation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y W Wong</author>
<author>R J Mooney</author>
</authors>
<title>Learning synchronous grammars for semantic parsing with lambda calculus.</title>
<date>2007</date>
<booktitle>In Proceedings of the Conference of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="26526" citStr="Wong and Mooney (2007)" startWordPosition="4459" endWordPosition="4462">likelihood of the data. For each mention, we marginalize over all possible context-dependent parses, using the predictions from the model on the previous gold mentions to fill in missing context, where necessary. After parameter estimation, we set a probability threshold for retaining a resolved time expression by optimizing value F1 (see Section 8) over the training data. 7 Related Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve ti</context>
</contexts>
<marker>Wong, Mooney, 2007</marker>
<rawString>Y.W. Wong and R.J. Mooney. 2007. Learning synchronous grammars for semantic parsing with lambda calculus. In Proceedings of the Conference of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J M Zelle</author>
<author>R J Mooney</author>
</authors>
<title>Learning to parse database queries using inductive logic programming.</title>
<date>1996</date>
<booktitle>In Proceedings of the National Conference on Artificial Intelligence.</booktitle>
<marker>Zelle, Mooney, 1996</marker>
<rawString>J.M. Zelle and R.J. Mooney. 1996. Learning to parse database queries using inductive logic programming. In Proceedings of the National Conference on Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars.</title>
<date>2005</date>
<booktitle>In Proceedings of the Conference on Uncertainty in Artificial Intelligence.</booktitle>
<contexts>
<context position="22893" citStr="Zettlemoyer and Collins, 2005" startWordPosition="3850" endWordPosition="3853"> of the tree, a final context-dependent logical form LF(y) and a TIMEX3 value TM(y). Define φ(m, D, y) E Rd to be a d-dimensional feature–vector representation and θ E Rd to be a parameter vector. The probability of a parse y for mention m and document D is: The inference problem at test time requires finding the best resolution by solving y*(m, D) = argmaxy P(y|m, D; θ, A), where the final output TIMEX3 value is TM(y*(m, D)). Inference We find the best context-dependent parse y by enumeration, as follows. We first parse the input mention m with a CKY-style algorithm, following previous work (Zettlemoyer and Collins, 2005). Due to the short length of time expressions and the manually constructed lexicon, we can perform exact inference. Given a parse, we then enumerate all possible outcomes for the context resolution operators. In practice, there are never more than one hundred possibilities. Features The resolution features test properties of the linguistic context surrounding the mention m, relative to the context-dependent CCG parse y. Governor verb We define the governor verb to be the nearest ancestor verb in the dependency parse of any token in m. We include features indicating the concatenation of the par</context>
<context position="26498" citStr="Zettlemoyer and Collins (2005)" startWordPosition="4454" endWordPosition="4457">imize the conditional, marginal log-likelihood of the data. For each mention, we marginalize over all possible context-dependent parses, using the predictions from the model on the previous gold mentions to fill in missing context, where necessary. After parameter estimation, we set a probability threshold for retaining a resolved time expression by optimizing value F1 (see Section 8) over the training data. 7 Related Work Semantic parsers map sentences to logical representations of their underlying meaning, e.g., Zelle P(y|m, D; θ, A) = B � �y� e &apos;O�m,D,y) eθ·φ(m,D,y) 1442 and Mooney (1996), Zettlemoyer and Collins (2005), and Wong and Mooney (2007). Recently, research in this area has focused on learning for various forms of relatively weak but easily gathered supervision. This includes learning from question-answer pairs (Clarke et al., 2010; Liang et al., 2011; Kwiatkowski et al., 2013), from conversational logs (Artzi and Zettlemoyer, 2011), with distant supervision (Krishnamurthy and Mitchell, 2012; Cai and Yates, 2013), and from sentences paired with system behavior (Goldwasser and Roth, 2011; Chen and Mooney, 2011; Artzi and Zettlemoyer, 2013b). Recently, Angeli et al. introduced the idea of learning se</context>
</contexts>
<marker>Zettlemoyer, Collins, 2005</marker>
<rawString>L.S. Zettlemoyer and M. Collins. 2005. Learning to map sentences to logical form: Structured classification with probabilistic categorial grammars. In Proceedings of the Conference on Uncertainty in Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Online learning of relaxed CCG grammars for parsing to logical form.</title>
<date>2007</date>
<booktitle>In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</booktitle>
<contexts>
<context position="27661" citStr="Zettlemoyer and Collins, 2007" startWordPosition="4633" endWordPosition="4636">2013b). Recently, Angeli et al. introduced the idea of learning semantic parsers to resolve time expressions (Angeli et al., 2012) and showed that the approach can generalize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b). However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions. Time expressions have been extensively studied as part of th</context>
</contexts>
<marker>Zettlemoyer, Collins, 2007</marker>
<rawString>L.S. Zettlemoyer and M. Collins. 2007. Online learning of relaxed CCG grammars for parsing to logical form. In Proceedings of the Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L S Zettlemoyer</author>
<author>M Collins</author>
</authors>
<title>Learning context-dependent mappings from sentences to logical form.</title>
<date>2009</date>
<booktitle>In Proceedings of the Joint Conference of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing.</booktitle>
<contexts>
<context position="27827" citStr="Zettlemoyer and Collins, 2009" startWordPosition="4658" endWordPosition="4661">eneralize to multiple languages (Angeli and Uszkoreit, 2013). Similarly, Bethard demonstrated that a hand-engineered semantic parser is also effective (Bethard, 2013b). However, these approaches did not use the semantic parser for detection and did not model linguistic context during resolution. We build on a number of existing algorithmic ideas, including using CCGs to build meaning representations (Zettlemoyer and Collins, 2005; Zettlemoyer and Collins, 2007; Kwiatkowski et al., 2010; Kwiatkowski et al., 2011), building derivations to transform the output of the CCG parser based on context (Zettlemoyer and Collins, 2009), and using weakly supervised parameter updates (Artzi and Zettlemoyer, 2011; Artzi and Zettlemoyer, 2013b). However, we are the first to use a semantic parsing grammar within a mention detection algorithm, thereby avoiding the need to represent the meaning of complete sentences, and the first to develop a context-dependent model for semantic parsing of time expressions. Time expressions have been extensively studied as part of the TimeEx task, including 9 teams who competed in the 2013 TempEval-3 competition (Uzzaman et al., 2013). This line of work builds on ideas from TimeBank (Pustejovsky </context>
</contexts>
<marker>Zettlemoyer, Collins, 2009</marker>
<rawString>L.S. Zettlemoyer and M. Collins. 2009. Learning context-dependent mappings from sentences to logical form. In Proceedings of the Joint Conference of the Association for Computational Linguistics and International Joint Conference on Natural Language Processing.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>