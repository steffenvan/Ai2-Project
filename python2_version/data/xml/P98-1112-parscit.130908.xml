<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001245">
<title confidence="0.982388">
Role of Verbs in Document Analysis
</title>
<author confidence="0.993912">
Judith Klavans* and Min-Yen Kan**
</author>
<affiliation confidence="0.991933">
Center for Research on Information Access* and Department of Computer Science**
Columbia University
</affiliation>
<address confidence="0.918665">
New York, NY 10027, USA
</address>
<sectionHeader confidence="0.930413" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99982896">
We present results of two methods for assessing
the event profile of news articles as a function
of verb type. The unique contribution of this
research is the focus on the role of verbs, rather
than nouns. Two algorithms are presented and
evaluated, one of which is shown to accurately
discriminate documents by type and semantic
properties, i.e. the event profile. The initial
method, using WordNet (Miller et al. 1990),
produced multiple cross-classification of arti-
cles, primarily due to the bushy nature of the
verb tree coupled with the sense disambiguation
problem. Our second approach using English
Verb Classes and Alternations (EVCA) Levin
(1993) showed that monosemous categorization
of the frequent verbs in WSJ made it possible to
usefully discriminate documents. For example,
our results show that articles in which commu-
nication verbs predominate tend to be opinion
pieces, whereas articles with a high percentage
of agreement verbs tend to be about mergers or
legal cases. An evaluation is performed on the
results using Kendall&apos;s r. We present convinc-
ing evidence for using verb semantic classes as
a discriminant in document classification.1
</bodyText>
<sectionHeader confidence="0.98859" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.99995725">
We present techniques to characterize document
type and event by using semantic classification
of verbs. The intuition motivating our research
is illustrated by an examination of the role of
</bodyText>
<footnote confidence="0.884111444444444">
&apos;The authors acknowledge earlier implementations by
James Shaw, and very valuable discussion from Vasileios
Hatzivassiloglou, Kathleen McKeown and Nina Wa-
cholder. Partial funding for this project was provided
by NSF award #IRI-9618797 STIMULATE: Generating
Coherent Summaries of On-Line Documents: Combining
Statistical and Symbolic Techniques (co-PI&apos;s McKeown
and Klavans), and by the Columbia University Center
for Research on Information Access.
</footnote>
<bodyText confidence="0.9535715">
nouns and verbs in documents. The listing be-
low shows the ontological categories which ex-
press the fundamental conceptual components
of propositions, using the framework of Jack-
endoff (1983). Each category permits the for-
mation of a wh-question, e.g. for [THING] &amp;quot;what
did you buy?&amp;quot; can be answered by the noun
&amp;quot;a fish&amp;quot;. The wh-questions for [ACTION] and
[EVENT] can only be answered by verbal con-
structions, e.g. in the question &amp;quot;what did you
do?&amp;quot;, where the response must be a verb, e.g.
jog, write, fall, etc.
[THING] [DIRECTION] [ACTION]
[PLACE] [MANNER] [EVENT]
[AMOUNT]
The distinction in the ontological categories
of nouns and verbs is reflected in information ex-
traction systems. For example, given the noun
phrases fares and US Air that occur within a
particular article, the reader will know what the
story is about, i.e. fares and US Air. However,
the reader will not know the [EVENT], i.e. what
happened to the fares or to US Air. Did airfare
prices rise, fall or stabilize? These are the verbs
most typically applicable to prices, and which
embody the event.
</bodyText>
<subsectionHeader confidence="0.995691">
1.1 Focus on the Noun
</subsectionHeader>
<bodyText confidence="0.998967583333333">
Many natural language analysis systems focus
on nouns and noun phrases in order to identify
information on who, what, and where. For ex-
ample, in summarization, Barzilay and Elhadad
(1997) and Lin and Hovy (1997) focus on multi-
word noun phrases. For information extraction
tasks, such as the DARPA-sponsored Message
Understanding Conferences (1992), only a few
projects use verb phrases (events), e.g. Ap-
pelt et al. (1993), Lin (1993). In contrast, the
named entity task, which identifies nouns and
noun phrases, has generated numerous projects
</bodyText>
<page confidence="0.995685">
680
</page>
<bodyText confidence="0.999947235294118">
as evidenced by a host of papers in recent con-
ferences, (e.g. Wacholder et al. 1997, Palmer
and Day 1997, Neumann et al. 1997). Although
rich information on nominal participants, ac-
tors, and other entities is provided, the named
entity task provides no information on what
happened in the document, i.e. the event or
action. Less progress has been made on ways
to utilize verbal information efficiently. In ear-
lier systems with stemming, many of the verbal
and nominal forms were conflated, sometimes
erroneously. With the development of more so-
phisticated tools, such as part of speech taggers,
more accurate verb phrase identification is pos-
sible. We present in this paper an effective way
to utilize verbal information for document type
discrimination.
</bodyText>
<subsectionHeader confidence="0.991823">
1.2 Focus on the Verb
</subsectionHeader>
<bodyText confidence="0.99951009375">
Our initial observations suggested that both oc-
currence and distribution of verbs in news arti-
cles provide meaningful insights into both ar-
ticle type and content. Exploratory analysis
of parsed Wall Street Journal data2 suggested
that articles characterized by movement verbs
such as drop, plunge, or fall have a different
event profile from articles with a high percent-
age of communication verbs, such as report, say,
comment, or complain. However, without asso-
ciated nominal arguments, it is impossible to
know whether the [THING] that drops refers to
airfare prices or projected earnings.
In this paper, we assume that the set of verbs
in a document, when considered as a whole, can
be viewed as part of the conceptual map of the
events and action in a document, in the same
way that the set of nouns has been used as a
concept map for entities. This paper reports on
two methods using verbs to determine an event
profile of the document, while also reliably cat-
egorizing documents by type. Intuitively, the
event profile refers to the classification of an ar-
ticle by the kind of event. For example, the
article could be a discussion event, a reporting
event, or an argument event.
To illustrate, consider a sample article from
WSJ of average length (12 sentences in length)
with a high percentage of communication verbs.
The profile of the article shows that there are
19 verbs: 11 (57%) are communication verbs,
including add, report, say, and tell. Other
</bodyText>
<footnote confidence="0.9191075">
2Penn TreeBank (Marcus et al. 1994) from the Lin-
guistic Data Consortium.
</footnote>
<bodyText confidence="0.996976">
verbs include be skeptical, carry, produce, and
close. Representative nouns include Polaroid
Corp., Michael Ellmann, Wertheim Schroder eY
Co., Prudential-Bache, savings, operating re-
sults, gain, revenue, cuts, profit, loss, sales, an-
alyst, and spokesman.
In this case, the verbs clearly contribute in-
formation that this article is a report with
more opinions than new facts. The prepon-
derance of communication verbs, coupled with
proper noun subjects and human nouns (e.g.
spokesman, analyst) suggest a discussion arti-
cle. If verbs are ignored, this fact would be
overlooked. Matches on frequent nouns like gain
and loss do not discriminate this article from
one which announces a gain or loss as breaking
news; indeed, according to our results, a break-
ing news article would feature a higher percent-
age of motion verbs rather than verbs of com-
munication.
</bodyText>
<subsectionHeader confidence="0.997876">
1.3 On Genre Detection
</subsectionHeader>
<bodyText confidence="0.999889193548387">
Verbs are an important factor in providing an
event profile, which in turn might be used in cat-
egorizing articles into different genres. Turning
to the literature in genre classification, Biber
(1989) outlines five dimensions which can be
used to characterize genre. Properties for dis-
tinguishing dimensions include verbal features
such as tense, agentless passives and infinitives.
Biber also refers to three verb classes: private,
public, and suasive verbs. Karlgren and Cut-
ting (1994) take a computationally tractable set
of these properties and use them to compute a
score to recognize text genre using discriminant
analysis. The only verbal feature used in their
study is present-tense verb count. As Karlgren
and Cutting show, their techniques are effective
in genre categorization, but they do not claim
to show how genres differ. Kessler et al. (1997)
discuss some of the complexities in automatic
detection of genre using a set of computation-
ally efficient cues, such as punctuation, abbrevi-
ations, or presence of Latinate suffixes. The tax-
onomy of genres and facets developed in Kessler
et al. is useful for a wide range of types, such
as found in the Brown corpus. Although some
of their discriminators could be useful for news
articles (e.g. presence of second person pronoun
tends to indicate a letter to the editor), the in-
dicators do not appear to be directly applicable
to a finer classification of news articles.
News articles can be divided into several stan-
</bodyText>
<page confidence="0.993533">
681
</page>
<bodyText confidence="0.969016">
dard categories typically addressed in journal-
ism textbooks. We base our article category
ontology, shown in lowercase, on Hill and Breen
(1977), in uppercase:
</bodyText>
<listItem confidence="0.9998235">
1. FEATURE STORIES : feature;
2. INTERPRETIVE STORIES: editorial, opinion, report;
3. PROFILES;
4. PRESS RELEASES: announcements, mergers, legal cases;
5. OBITUARIES;
6. STATISTICAL INTERPRETATION: posted earnings;
7. ANECDOTES;
8. OTHER: poems.
</listItem>
<bodyText confidence="0.999712625">
The goal of our research is to identify the
role of verbs, keeping in mind that event profile
is but one of many factors in determining text
type. In our study, we explored the contribu-
tion of verbs as one factor in document type dis-
crimination; we show how article types can be
successfully classified within the news domain
using verb semantic classes.
</bodyText>
<sectionHeader confidence="0.997819" genericHeader="introduction">
2 Initial Observations
</sectionHeader>
<bodyText confidence="0.999996233333334">
We initially considered two specific categories of
verbs in the corpus: communication verbs and
support verbs. In the WSJ corpus, the two most
common main verbs are say, a communication
verb, and be, a support verb. In addition to
say, other high frequency communication verbs
include report, announce, and state. In journal-
istic prose, as seen by the statistics in Table 1,
at least 20% of the sentences contain commu-
nication verbs such as say and announce; these
sentences report point of view or indicate an
attributed comment. In these cases, the subor-
dinated complement represents the main event,
e.g. in &amp;quot;Advisors announced that IBM stock
rose 36 points over a three year period,&amp;quot; there
are two actions: announce and rise. In sen-
tences with a communication verb as main verb
we considered both the main and the subor-
dinate verb; this decision augmented our verb
count an additional 20% and, even more im-
portantly, further captured information on the
actual event in an article, not just the commu-
nication event. As shown in Table 1, support
verbs, such as go (&amp;quot;go out of business&amp;quot;) or get
(&amp;quot;get along&amp;quot;), constitute 30%, and other con-
tent verbs, such as fall, adapt, recognize, or vow,
make up the remaining 50%. If we exclude all
support type verbs, 70% of the verbs yield in-
formation in answering the question &amp;quot;what hap-
pened?&amp;quot; or &amp;quot;what did X do?&amp;quot;
</bodyText>
<sectionHeader confidence="0.977458" genericHeader="method">
3 Event Profile: WordNet and EVCA
</sectionHeader>
<bodyText confidence="0.999306">
Since our first intuition of the data suggested
that articles with a preponderance of verbs of
</bodyText>
<subsectionHeader confidence="0.712051">
Verb Type Sample Verbs
</subsectionHeader>
<bodyText confidence="0.985447795918368">
communication say, announce, ...
support have, get, go, ...
remainder abuse, claim, offer, ...
Table 1: Approximate Frequency of verbs by
type from the Wall Street Journal (main and
selected subordinate verbs, n = 10,295).
a certain semantic type might reveal aspects of
document type, we tested the hypothesis that
verbs could be used as a predictor in provid-
ing an event profile. We developed two algo-
rithms to: (1) explore WordNet (WN-Verber)
to cluster related verbs and build a set of verb
chains in a document, much as Morris and Hirst
(1991) used Roget&apos;s Thesaurus or like Hirst and
St. Onge (1998) used WordNet to build noun
chains; (2) classify verbs according to a se-
mantic classification system, in this case, us-
ing Levin&apos;s (1993) English Verb Classes and
Alternations (EVCA-Verber) as a basis. For
source material, we used the manually-parsed
Linguistic Data Consortium&apos;s Wall Street Jour-
nal (WSJ) corpus from which we extracted main
and complement of communication verbs to test
the algorithms on.
Using WordNet. Our first technique was
to use WordNet to build links between verbs
and to provide a semantic profile of the docu-
ment. WordNet is a general lexical resource in
which words are organized into synonym sets,
each representing one underlying lexical concept
(Miller et al. 1990). These synonym sets - or
synsets - are connected by different semantic
relationships such as hypernymy (i.e. plunging
is a way of descending), synonymy, antonymy,
and others (see Fellbaum 1990). The determina-
tion of relatedness via taxonomic relations has a
rich history (see Resnik 1993 for a review). The
premise is that words with similar meanings will
be located relatively close to each other in the
hierarchy. Figure 1 shows the verbs cite and
post, which are related via a common ancestor
inform, ... , let know.
The WN-Verber tool. We used the hypernym
relationship in WordNet because of its high cov-
erage. We counted the number of edges needed
to find a common ancestor for a pair of verbs.
Given the hierarchical structure of WordNet,
the lower the edge count, in principle, the closer
the verbs are semantically. Because WordNet
</bodyText>
<figure confidence="0.988587666666667">
20%
30%
50%
</figure>
<page confidence="0.896311">
682
</page>
<bodyText confidence="0.768927166666667">
common ancestor
inform__ let know
testify to, ...
indicate, ... announce, ...
■
abduce, ..., cite attest, report post sound
</bodyText>
<figureCaption confidence="0.9861925">
Figure 1: Taxonomic Relations for cite and post
in WordNet.
</figureCaption>
<bodyText confidence="0.998436785714286">
allows individual words (via synsets) to be the
descendent of possibly more than one ances-
tor, two words can often be related by more
than one common ancestor via different paths,
possibly with the same relationship (grandpar-
ent and grandparent, or with different relations
(grandparent and uncle).
Results from WN-Verber. . We ran all arti-
cles longer than 10 sentences in the WSJ cor-
pus (1236 articles) through WN-Verber. Output
showed that several verbs - e.g. go, take, and
say - participate in a very large percentage of
the high frequency synsets (approximate 30%).
This is due to the width of the verb forest in
WordNet (see Fellbaum 1990); top level verb
synsets tend to have a large number of descen-
dants which are arranged in fewer generations,
resulting in a flat and bushy tree structure. For
example, a top level verb synset, inform, ... ,
give information, let know has over 40 children,
whereas a similar top level noun synset, entity,
only has 15 children. As a result, using fewer
than two levels resulted in groupings that were
too limited to aggregate verbs effectively. Thus,
for our system, we allowed up to two edges to in-
tervene between a common ancestor synset and
each of the verbs&apos; respective synsets, as in Fig-
ure 2.
</bodyText>
<figureCaption confidence="0.786984">
Figure 2: Configurations for relating verbs in
our system.
</figureCaption>
<bodyText confidence="0.999493157894737">
In addition to the problem of the flat na-
ture of the verb hierarchy, our results from
WN-Verber are degraded by ambiguity; similar
effects have been reported for nouns. Verbs with
differences in high versus low frequency senses
caused certain verbs to be incorrectly related;
for example, have and drop are related by the
synset meaning &amp;quot;to give birth&amp;quot; although this
sense of drop is rare in WSJ.
The results of WN-Verber in Table 2 reflect
the effects of bushiness and ambiguity. The five
most frequent synsets are given in column 1; col-
umn 2 shows some typical verbs which partici-
pate in the clustering; column 3 shows the type
of article which tends to contain these synsets.
Most articles (864/1236 = 70%) end up in the
top five nodes. This illustrates the ineffective-
ness of these most frequent WordNet synset to
discriminate between article types.
</bodyText>
<table confidence="0.999071529411765">
Synset Sample Article types
Verbs (listed in order)
in Synset
Act have, relate, announcements, editori-
(interact, act to- give, tell als, features
gether, ...)
Communicate give, get, in- announcements, editori-
(communicate, form, tell als, features, poems
intercommunicate,
...)
Change have, modify, poems, editorials, an-
(change) take nouncements, features
Alter convert, announcements, poems,
(alter, change) make, get editorials
Inform inform, ex- announcements, poems,
(inform, round on, plain, de- features
scribe
</table>
<tableCaption confidence="0.998629">
Table 2: Frequent synsets and article types.
</tableCaption>
<bodyText confidence="0.982580375">
Evaluation using Kendall&apos;s Tau. We
sought independent confirmation to assess the
correlation between two variables&apos; rank for
WN-Verber results. To evaluate the effects of
one synset&apos;s frequency on another, we used
Kendall&apos;s tau (7) rank order statistic (Kendall
1970). For example, was it the case that verbs
under the synset act tend not to occur with
verbs under the synset think? If so, do ar-
ticles with this property fit a particular pro-
file? In our results, we have information about
synset frequency, where each of the 1236 arti-
cles in the corpus constitutes a sample. Ta-
ble 3 shows the results of calculating Kendall&apos;s
T with considerations for ranking ties, for all
(TN
) = 45 pairing combinations of the top 10
most frequently occurring synsets. Correlations
can range from -1.0 reflecting inverse correla-
tion, to +1.0 showing direct correlation, i.e. the
presence of one class increases as the presence
of the correlated verb class increases. A r value
of 0 would show that the two variables&apos; values
are independent of each other.
</bodyText>
<figure confidence="0.989228272727273">
acceptable
• 1 •
20 • 20 •2
• v2 • •
vi vi v2
• unacceptable
vt• 1 •
4 •• • 3
vi
• •
v2 • v2 •
</figure>
<page confidence="0.99658">
683
</page>
<bodyText confidence="0.989260454545455">
Results show a significant positive correlation
between the synsets. The range of correlation
is from .850 between the communication verb
synset (give, get, inform, ...) and the act verb
synset (have, relate, give, ...) to .238 between
the think verb synset (plan, study, give, ...) and
the change state verb synset (fall, come, close,
..)
These correlations show that frequent synsets
do not behave independently of each other and
thus confirm that the WordNet results are not
an effective way to achieve document discrim-
ination. Although the WordNet results were
not discriminatory, we were still convinced that
our initial hypothesis on the role of verbs in
determining event profile was worth pursuing.
We believe that these results are a by-product
of lexical ambiguity and of the richness of the
WordNet hierarchy. We thus decided to pur-
sue a new approach to test our hypothesis, one
which turned out to provide us with clearer and
more robust results.
</bodyText>
<table confidence="0.9702376">
act corn chng alter infra exps thnk judg trnf
state .407 .296 .672 .461 .286 .269 .238 .355 .268
trnsf .437 .436 .251 .436 .251 .404 .369 .359
judge .444 .414 .435 .450 .340 .348 .427
exprs .444 .414 .435 .397 .322 .432
think .444 .414 .435 .397 .398
infrm .614 .649 .341 .380
alter .501 .454 .619
chnge .496 .393
comun .850
</table>
<tableCaption confidence="0.8225755">
Table 3: Kendall&apos;s T for frequent WordNet
synsets.
</tableCaption>
<bodyText confidence="0.998097529411765">
Utilizing EVCA. A different approach to
test the hypothesis was to use another semantic
categorization method; we chose the semantic
classes of Levin&apos;s EVCA as a basis for our next
analysis.3 Levin&apos;s seminal work is based on the
time-honored observation that verbs which par-
ticipate in similar syntactic alternations tend to
share semantic properties. Thus, the behavior
of a verb with respect to the expression and in-
terpretation of its arguments can be said to be,
in large part, determined by its meaning. Levin
has meticulously set out a list of syntactic tests
(about 100 in all), which predict membership in
no less than 48 classes, each of which is divided
into numerous sub-classes. The rigor and thor-
oughness of Levin&apos;s study permitted us to en-
code our algorithm, EVCA-Verber, on a sub-set
</bodyText>
<footnote confidence="0.9231516">
3Strictly speaking, our classification is based on
EVCA. Although many of our classes are precisely de-
fined in terms of EVCA tests, we did impose some ex-
tensions. For example, support verbs are not an EVCA
category.
</footnote>
<bodyText confidence="0.999410625">
of the EVCA classes, ones which were frequent
in our corpus. First, we manually categorized
the 100 most frequent verbs, as well as 50 addi-
tional verbs, which covers 56% of the verbs by
token in the corpus. We subjected each verb to
a set of strict linguistic tests, as shown in Ta-
ble 4 and verified primary verb usage against
the corpus.
</bodyText>
<table confidence="0.947355">
Verb Class Sample Test
(sample verbs)
Communication (1) Does this involve a transfer of ideas?
(add, say, an- (2) X verbed &amp;quot;something.&amp;quot;
nounce, ...)
Motion (1) •&amp;quot;X verbed without moving&amp;quot;.
(rise, fall, decline,
Agreement (1) &amp;quot;They verbed to join forces.&amp;quot;
(agree, accept, con- (2) involves more than one participant.
cur, ...)
Argument (1) &amp;quot;They verbed (over) the issue.&amp;quot;
(argue, debate„ (2) indicates conflicting views.
(3) involves more than one participant.
Causative (1) X verbed Y (to happen/happened).
(cause) (2) X brings about a change in Y.
</table>
<tableCaption confidence="0.999373">
Table 4: EVCA verb class test
</tableCaption>
<bodyText confidence="0.9995546">
Results from EVCA-Verber. In order to be
able to compare article types and emphasize
their differences, we selected articles that had
the highest percentage of a particular verb class
from each of the ten verb classes; we chose five
articles from each EVCA class, yielding a to-
tal of 50 articles for analysis from the full set
of 1236 articles. We observed that each class
discriminated between different article types as
shown in Table 5. In contrast to Table 2, the ar-
ticle types are well discriminated by verb class.
For example, a concentration of communica-
tion class verbs (say, report, announce, . ..) in-
dicated that the article type was a general an-
nouncement of short or medium length, or a
longer feature article with many opinions in the
text. Articles high in motion verbs were also
announcements, but differed from the commu-
nication ones, in that they were commonly post-
ings of company earnings reaching a new high
or dropping from last quarter. Agreement and
argument verbs appeared in many of the same
articles, involving issues of some controversy.
However, we noted that articles with agreement
verbs were a superset of the argument ones in
that, in our corpus, argument verbs did not ap-
pear in articles concerning joint ventures and
mergers. Articles marked by causative class
verbs tended to be a bit longer, possibly re-
flecting prose on both the cause and effect of
</bodyText>
<page confidence="0.99768">
684
</page>
<bodyText confidence="0.998861">
a particular action. We also used EVCA-Verber
to investigate articles marked by the absence of
members of each verb class, such as articles lack-
ing any verbs in the motion verb class. However,
we found that absence of a verb class was not
discriminatory.
</bodyText>
<table confidence="0.977109214285714">
Verb Class Article types
(sample verbs) (listed by frequency)
Communication issues, reports, opinions, editorials
(add, bay, announce, .. )
Motion posted earnings, announcements
(rise, fall, decline.....
Agreement mergers, legal cases, transactions
(agree, accept, concur, (without buying and selling)
...)
Argument legal cases, opinions
(argue, indicate, contend,
...)
Causative opinions, feature, editorials
(cause)
</table>
<tableCaption confidence="0.999516">
Table 5: EVCA-based verb class results.
</tableCaption>
<bodyText confidence="0.995874157894737">
Evaluation of EVCA verb classes. To
strengthen the observations that articles domi-
nated by verbs of one class reflect distinct arti-
cle types, we verified that the verb classes be-
haved independently of each other. Correlations
for EVCA classes are shown in Table 6. These
show a markedly lower level of correlation be-
tween verb classes than the results for WordNet
synsets, the range being from .265 between mo-
tion and aspectual verbs to —.026 for motion
verbs and agreement verbs. These low values
of .7- for pairs of verb classes reflects the inde-
pendence of the classes. For example, the com-
munication and experience verb classes are
weakly correlated; this, we surmise, may be due
to the different ways opinions can be expressed,
i.e. as factual quotes using communication
class verbs or as beliefs using experience class
verbs.
</bodyText>
<table confidence="0.774893">
comun motion agree argue exp aspect cause
appear .122 .076 .077 .072 .182 .112 .037
cause .093 .083 .000 .000 .073 .096
aspect .246 .265 .034 .110 .189
exp .260 .130 .054 .054
argue .162 .045 .033
argree .071 -.026
motion .259
</table>
<tableCaption confidence="0.807723">
Table 6: Kendall&apos;s 7 for EVCA based verb
classes.
</tableCaption>
<sectionHeader confidence="0.999164" genericHeader="evaluation">
4 Results and Future Work.
</sectionHeader>
<subsectionHeader confidence="0.876735">
Basis for WordNet and EVCA compari-
</subsectionHeader>
<bodyText confidence="0.997678055555556">
son. This paper reports results from two ap-
proaches, one using WordNet and other based
on EVCA classes. However, the basis for com-
parison must be made explicit. In the case
of WordNet, all verb tokens (n = 10K) were
considered in all senses, whereas in the case of
EVCA, a subset of less ambiguous verbs were
manually selected. As reported above, we cov-
ered 56% of the verbs by token. Indeed, when
we attempted to add more verbs to EVCA cat-
egories, at the 59% mark we reached a point of
difficulty in adding new verbs due to ambigu-
ity, e.g. verbs such as get. Thus, although our
results using EVCA are revealing in important
ways, it must be emphasized that the compar-
ison has some imbalance which puts WordNet
in an unnaturally negative light. In order to ac-
curately compare the two approaches, we would
need to process either the same less ambiguous
verb subset with WordNet, or the full set of all
verbs in all senses with EVCA. Although the re-
sults reported in this paper permitted the vali-
dation of our hypothesis, unless a fair compari-
son between resources is performed, conclusions
about WordNet as a resource versus EVCA class
distinctions should not be inferred.
Verb Patterns. In addition to considering
verb type frequencies in texts, we have observed
that verb distribution and patterns might also
reveal subtle information in text. Verb class dis-
tribution within the document and within par-
ticular sub-sections also carry meaning. For ex-
ample, we have observed that when sentences
with movement verbs such as rise or fall are fol-
lowed by sentences with cause and then a telic
aspectual verb such as reach, this indicates that
a value rose to a certain point due to the actions
of some entity. Identification of such sequences
will enable us to assign functions to particular
sections of contiguous text in an article, in much
the same way that text segmentation program
seeks identify topics from distributional vocab-
ulary (Hearst, 1994; Kan et al., 1998). We can
also use specific sequences of verbs to help in
determining methods for performing semantic
aggregation of individual clauses in text gener-
ation for summarization.
Future Work. Our plans are to extend the
current research in terms of verb coverage and
in terms of article coverage. For verbs, we plan
to (1) increase the verbs that we cover to include
phrasal verbs; (2) increase coverage of verbs
by categorizing additional high frequency verbs
into EVCA classes; (3) examine the effects of
</bodyText>
<page confidence="0.997201">
685
</page>
<bodyText confidence="0.999968838709677">
increased coverage on determining article type.
For articles, we plan to explore a general parser
so we can test our hypothesis on additional texts
and examine how our conclusions scale up. Fi-
nally, we would like to combine our techniques
with other indicators to form a more robust sys-
tem, such as that envisioned in Biber (1989) or
suggested in Kessler et al. (1997).
Conclusion. We have outlined a novel ap-
proach to document analysis for news articles
which permits discrimination of the event pro-
file of news articles. The goal of this research is
to determine the role of verbs in document anal-
ysis, keeping in mind that event profile is one of
many factors in determining text type. Our re-
sults show that Levin&apos;s EVCA verb classes pro-
vide reliable indicators of article type within the
news domain. We have applied the algorithm to
WSJ data and have discriminated articles with
five EVCA semantic classes into categories such
as features, opinions, and announcements. This
approach to document type classification using
verbs has not been explored previously in the
literature. Our results on verb analysis coupled
with what is already known about NP identi-
fication convinces us that future combinations
of information will be even more successful in
categorization of documents. Results such as
these are useful in applications such as passage
retrieval, summarization, and information ex-
traction.
</bodyText>
<sectionHeader confidence="0.998986" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999790988095238">
D. Appelt, J. Hobbs, J. Bear, D. Isreal, and M. Tyson.
1993. Fastus: A finite state processor for information
extraction from real world text. In Proceedings of the
13th International Joint Conference on Artificial In-
telligence (IJCAI), Chambery, France.
Regina Barzilay and Michael Elhadad. 1997. Using lex-
ical chains for text summarization. In Proceedings
of the Intelligent Scalable Text Summarization Work-
shop (ISTS&apos;97), ACL, Madrid, Spain.
Douglas Biber. 1989. A typology of english texts. Lan-
guage, 27:3-43.
Christiane Fellbaum. 1990. English verbs as a semantic
net. International Journal of Lexicography, 3(4):278-
301.
Maarti A. Hearst. 1994. Multi-paragraph segmentation
of expository text. In Proceedings of the 32th Annual
Meeting of the Association of Computational Linguis-
tics.
Evan Hill and John J. Breen. 1977. Reporting E4 Writ-
ing the News. Little, Brown and Company, Boston,
Massachusetts.
Graeme Hirst and David St-Onge. 1998. Lexical chains
as representations of context for the detection and cor-
rection of malapropisms. WordNet: An electronic lex-
ical database and some of its applications.
Ray Jackendoff. 1983. Semantics and Cognition. MIT
University Press, Cambridge, Massachusetts.
Min-Yen Kan, Judith L. Klavans, and Kathleen R. McK-
eown. 1998. Linear segmentation and segment rele-
vance. Unpublished Manuscript.
Jussi Karlgren and Douglass Cutting. 1994. Recogniz-
ing text genres with simple metrics using discrimi-
nant analysis. In Fifteenth International Conference
on Computational Linguistics (COLING &apos;94), Kyoto,
Japan.
Maurice G. Kendall. 1970. Rank Correlation Methods.
Griffin, London, England, 4th edition.
Brent Kessler, Geoffrey Nunberg, and Hinrich Schiitze.
1997. Automatic detection of text genre. In Proceed-
ings of the 35th Annual Meeting of the Association of
Computational Linguistics, Madrid, Spain.
Beth Levin. 1993. English Verb Classes and Alterna-
tions. University of Chicago Press, Chicago, Ohio.
Chin-Yew Lin and Eduard Hovy. 1997. Identifying top-
ics by position. In Proceedings of the 5th A CL Confer-
ence on Applied Natural Language Processing, pages
283-290, Washington, D.C., April.
Delcang Lin. 1993. University of Manitoba: Descrip-
tion of the NUBA System as Used for MUC-5. In
Proceedings of the Fifth Conference on Message Un-
derstanding MUC-5, pages 263-275, Baltimore, Mary-
land. ARPA.
Mitch Marcus et al. 1994. The Penn Treebank: Anno-
tating Predicate Argument Structure. ARPA Human
Language Technology Workshop.
George A. Miller, Richard Beckwith, Christiane Fell-
baum, Derek Gross, and Katherine J. Miller.
1990. Introduction to WordNet: An on-line lexical
database. International Journal of Lexicography (spe-
cial issue), 3(4):235-312.
Jane Morris and Graeme Hirst. 1991. Lexical coher-
ence computed by thesaural relations as an indicator
of the structure of text. Computational Linguistics,
17(1):21-42.
1992. Message Understanding Conference — MUG.
Gunter Neumann, Rolf Backofen, Judith Baur, Marcus
Becker, and Christian Braun. 1997. An information
extraction core system for real world german text pro-
cessing. In Proceedings of the 5th A CL Conference on
Applied Natural Language Processing, pages 209-216,
Washington, D.C., April.
David D. Palmer and David S. Day. 1997. A statistical
profile of the named entity task. In Proceedings of
the 5th A CL Conference on Applied Natural Language
Processing, pages 190-193, Washington, D.C., April.
Philip Resnik. 1993. Selection and Information: A
Class-Based Approach to Lexical Relationships. Ph.D.
thesis, Department of Computer and Information Sci-
ence, University of Pennsylvania.
Nina Wacholder, Yael Ravin, and Misook Choi. 1997.
Disambiguation of proper names in text. In Proceed-
ings of the 5th A CL Conference on Applied Natural
Language Processing, volume 1, pages 202-209, Wash-
ington, D.C., April.
</reference>
<page confidence="0.998743">
686
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000239">
<title confidence="0.998967">Role of Verbs in Document Analysis</title>
<author confidence="0.991666">Klavans Kan</author>
<affiliation confidence="0.999873">Center for Research on Information Access* and Department of Computer Science** Columbia University</affiliation>
<address confidence="0.999673">New York, NY 10027, USA</address>
<abstract confidence="0.98259046875">present results two methods for assessing the event profile of news articles as a function of verb type. The unique contribution of this research is the focus on the role of verbs, rather than nouns. Two algorithms are presented and evaluated, one of which is shown to accurately discriminate documents by type and semantic properties, i.e. the event profile. The initial method, using WordNet (Miller et al. 1990), produced multiple cross-classification of articles, primarily due to the bushy nature of the verb tree coupled with the sense disambiguation problem. Our second approach using English Verb Classes and Alternations (EVCA) Levin (1993) showed that monosemous categorization of the frequent verbs in WSJ made it possible to usefully discriminate documents. For example, our results show that articles in which communication verbs predominate tend to be opinion pieces, whereas articles with a high percentage of agreement verbs tend to be about mergers or legal cases. An evaluation is performed on the using Kendall&apos;s convincing evidence for using verb semantic classes as discriminant in document 1 Motivation We present techniques to characterize document type and event by using semantic classification of verbs. The intuition motivating our research is illustrated by an examination of the role of &apos;The authors acknowledge earlier implementations by</abstract>
<author confidence="0.8782705">James Shaw</author>
<author confidence="0.8782705">very valuable discussion from Vasileios Hatzivassiloglou</author>
<author confidence="0.8782705">Kathleen McKeown</author>
<author confidence="0.8782705">Nina Wa-</author>
<degree confidence="0.419475">cholder. Partial funding for this project was provided</degree>
<title confidence="0.5635055">by NSF award #IRI-9618797 STIMULATE: Generating Coherent Summaries of On-Line Documents: Combining</title>
<author confidence="0.681428">Statistical</author>
<author confidence="0.681428">Symbolic Techniques</author>
<affiliation confidence="0.855274">and Klavans), and by the Columbia University Center</affiliation>
<abstract confidence="0.998747452459018">for Research on Information Access. nouns and verbs in documents. The listing below shows the ontological categories which express the fundamental conceptual components of propositions, using the framework of Jackendoff (1983). Each category permits the formation of a wh-question, e.g. for [THING] &amp;quot;what did you buy?&amp;quot; can be answered by the noun fish&amp;quot;. The wh-questions for [EVENT] can only be answered by verbal constructions, e.g. in the question &amp;quot;what did you do?&amp;quot;, where the response must be a verb, e.g. write, fall, [THING] [DIRECTION] [ACTION] [PLACE] [MANNER] [EVENT] [AMOUNT] The distinction in the ontological categories of nouns and verbs is reflected in information extraction systems. For example, given the noun that occur within a particular article, the reader will know what the is about, i.e. Air. the reader will not know the [EVENT], i.e. what to the to Air. airfare fall are the verbs most typically applicable to prices, and which embody the event. 1.1 Focus on the Noun Many natural language analysis systems focus on nouns and noun phrases in order to identify information on who, what, and where. For example, in summarization, Barzilay and Elhadad (1997) and Lin and Hovy (1997) focus on multiword noun phrases. For information extraction tasks, such as the DARPA-sponsored Message Understanding Conferences (1992), only a few projects use verb phrases (events), e.g. Appelt et al. (1993), Lin (1993). In contrast, the named entity task, which identifies nouns and noun phrases, has generated numerous projects 680 as evidenced by a host of papers in recent conferences, (e.g. Wacholder et al. 1997, Palmer and Day 1997, Neumann et al. 1997). Although rich information on nominal participants, actors, and other entities is provided, the named task provides no information on the document, i.e. the progress has been made on ways to utilize verbal information efficiently. In earlier systems with stemming, many of the verbal and nominal forms were conflated, sometimes erroneously. With the development of more sophisticated tools, such as part of speech taggers, more accurate verb phrase identification is possible. We present in this paper an effective way to utilize verbal information for document type discrimination. 1.2 Focus on the Verb Our initial observations suggested that both occurrence and distribution of verbs in news articles provide meaningful insights into both article type and content. Exploratory analysis parsed Wall Street Journal suggested that articles characterized by movement verbs as plunge, a different event profile from articles with a high percentof communication verbs, such as say, without associated nominal arguments, it is impossible to whether the [THING] that to airfare prices or projected earnings. In this paper, we assume that the set of verbs in a document, when considered as a whole, can be viewed as part of the conceptual map of the events and action in a document, in the same way that the set of nouns has been used as a concept map for entities. This paper reports on two methods using verbs to determine an event profile of the document, while also reliably categorizing documents by type. Intuitively, the event profile refers to the classification of an article by the kind of event. For example, the article could be a discussion event, a reporting event, or an argument event. To illustrate, consider a sample article from WSJ of average length (12 sentences in length) with a high percentage of communication verbs. The profile of the article shows that there are 19 verbs: 11 (57%) are communication verbs, report, say, TreeBank (Marcus et al. 1994) from the Linguistic Data Consortium. include skeptical, carry, produce, nouns include Corp., Michael Ellmann, Wertheim Schroder eY Co., Prudential-Bache, savings, operating results, gain, revenue, cuts, profit, loss, sales, an- In this case, the verbs clearly contribute information that this article is a report with more opinions than new facts. The preponderance of communication verbs, coupled with proper noun subjects and human nouns (e.g. spokesman, analyst) suggest a discussion article. If verbs are ignored, this fact would be Matches on frequent nouns like not discriminate this article from which announces a breaking news; indeed, according to our results, a breaking news article would feature a higher percentage of motion verbs rather than verbs of communication. 1.3 On Genre Detection Verbs are an important factor in providing an event profile, which in turn might be used in categorizing articles into different genres. Turning to the literature in genre classification, Biber (1989) outlines five dimensions which can be used to characterize genre. Properties for distinguishing dimensions include verbal features such as tense, agentless passives and infinitives. Biber also refers to three verb classes: private, public, and suasive verbs. Karlgren and Cutting (1994) take a computationally tractable set of these properties and use them to compute a score to recognize text genre using discriminant analysis. The only verbal feature used in their study is present-tense verb count. As Karlgren and Cutting show, their techniques are effective in genre categorization, but they do not claim to show how genres differ. Kessler et al. (1997) discuss some of the complexities in automatic detection of genre using a set of computationally efficient cues, such as punctuation, abbreviations, or presence of Latinate suffixes. The taxonomy of genres and facets developed in Kessler et al. is useful for a wide range of types, such as found in the Brown corpus. Although some of their discriminators could be useful for news articles (e.g. presence of second person pronoun tends to indicate a letter to the editor), the indicators do not appear to be directly applicable to a finer classification of news articles. articles can be divided into several stan- 681 dard categories typically addressed in journalism textbooks. We base our article category ontology, shown in lowercase, on Hill and Breen (1977), in uppercase: 1. FEATURE STORIES : feature; 2. INTERPRETIVE STORIES: editorial, opinion, report; 3. PROFILES; 4. PRESS RELEASES: announcements, mergers, legal cases; 5. OBITUARIES; 6. STATISTICAL INTERPRETATION: posted earnings; 7. ANECDOTES; 8. OTHER: poems. The goal of our research is to identify the role of verbs, keeping in mind that event profile is but one of many factors in determining text type. In our study, we explored the contribution of verbs as one factor in document type discrimination; we show how article types can be successfully classified within the news domain using verb semantic classes. 2 Initial Observations We initially considered two specific categories of verbs in the corpus: communication verbs and support verbs. In the WSJ corpus, the two most common main verbs are say, a communication and support verb. In addition to say, other high frequency communication verbs announce, journalistic prose, as seen by the statistics in Table 1, at least 20% of the sentences contain commuverbs such as say and sentences report point of view or indicate an attributed comment. In these cases, the subordinated complement represents the main event, in &amp;quot;Advisors IBM stock points over a three year period,&amp;quot; there two actions: sentences with a communication verb as main verb we considered both the main and the subordinate verb; this decision augmented our verb count an additional 20% and, even more importantly, further captured information on the actual event in an article, not just the communication event. As shown in Table 1, support such as out of business&amp;quot;) or (&amp;quot;get along&amp;quot;), constitute 30%, and other converbs, such as adapt, recognize, make up the remaining 50%. If we exclude all support type verbs, 70% of the verbs yield information in answering the question &amp;quot;what happened?&amp;quot; or &amp;quot;what did X do?&amp;quot; 3 Event Profile: WordNet and EVCA Since our first intuition of the data suggested that articles with a preponderance of verbs of Verb Type Sample Verbs announce, ... get, go, ... claim, offer, ... Table 1: Approximate Frequency of verbs by from the Street Journal and selected subordinate verbs, n = 10,295). a certain semantic type might reveal aspects of document type, we tested the hypothesis that verbs could be used as a predictor in providing an event profile. We developed two algoto: (1) explore WordNet to cluster related verbs and build a set of verb chains in a document, much as Morris and Hirst (1991) used Roget&apos;s Thesaurus or like Hirst and St. Onge (1998) used WordNet to build noun chains; (2) classify verbs according to a seclassification system, in this us- Levin&apos;s (1993) Verb Classes and a basis. For source material, we used the manually-parsed Data Consortium&apos;s Street Jourcorpus from which we extracted main and complement of communication verbs to test the algorithms on. WordNet. first technique was to use WordNet to build links between verbs and to provide a semantic profile of the document. WordNet is a general lexical resource in which words are organized into synonym sets, each representing one underlying lexical concept (Miller et al. 1990). These synonym sets or synsets are connected by different semantic such as hypernymy (i.e. a way of antonymy, and others (see Fellbaum 1990). The determination of relatedness via taxonomic relations has a rich history (see Resnik 1993 for a review). The premise is that words with similar meanings will be located relatively close to each other in the Figure 1 shows the verbs are related via a common ancestor inform, ... , let know. WN-Verber tool. used the hypernym relationship in WordNet because of its high coverage. We counted the number of edges needed to find a common ancestor for a pair of verbs. Given the hierarchical structure of WordNet, the lower the edge count, in principle, the closer the verbs are semantically. Because WordNet 20% 30% 50% 682 common ancestor inform__ let know testify to, ... ... ... ■ ..., cite report 1: Taxonomic Relations for in WordNet. allows individual words (via synsets) to be the descendent of possibly more than one ancestor, two words can often be related by more than one common ancestor via different paths, possibly with the same relationship (grandparent and grandparent, or with different relations (grandparent and uncle). from . ran all articles longer than 10 sentences in the WSJ cor- (1236 articles) through that several verbs e.g. take, say participate in a very large percentage of the high frequency synsets (approximate 30%). This is due to the width of the verb forest in WordNet (see Fellbaum 1990); top level verb synsets tend to have a large number of descendants which are arranged in fewer generations, resulting in a flat and bushy tree structure. For a top level verb synset, ... , information, let know over 40 children, a similar top level noun synset, only has 15 children. As a result, using fewer than two levels resulted in groupings that were too limited to aggregate verbs effectively. Thus, for our system, we allowed up to two edges to intervene between a common ancestor synset and each of the verbs&apos; respective synsets, as in Figure 2. Figure 2: Configurations for relating verbs in our system. In addition to the problem of the flat nature of the verb hierarchy, our results from degraded by ambiguity; similar effects have been reported for nouns. Verbs with differences in high versus low frequency senses caused certain verbs to be incorrectly related; example, related by the synset meaning &amp;quot;to give birth&amp;quot; although this of rare in WSJ. results of Table 2 reflect the effects of bushiness and ambiguity. The five most frequent synsets are given in column 1; column 2 shows some typical verbs which participate in the clustering; column 3 shows the type of article which tends to contain these synsets. Most articles (864/1236 = 70%) end up in the top five nodes. This illustrates the ineffectiveness of these most frequent WordNet synset to discriminate between article types. Synset Sample Verbs in Synset Article types (listed in order) Act have, relate, announcements, als, features editori- (interact, act togive, tell gether, ...) Communicate give, get, inannouncements, editori- (communicate, intercommunicate, form, tell als, features, poems ...) Change have, modify, editorials, an- (change) take nouncements, features Alter convert, make, get announcements, poems, (alter, change) editorials Inform exannouncements, features poems, (inform, round on, describe Table 2: Frequent synsets and article types. using Kendall&apos;s Tau. sought independent confirmation to assess the correlation between two variables&apos; rank for To evaluate the effects of one synset&apos;s frequency on another, we used Kendall&apos;s tau (7) rank order statistic (Kendall 1970). For example, was it the case that verbs the synset not to occur with under the synset so, do articles with this property fit a particular profile? In our results, we have information about synset frequency, where each of the 1236 articles in the corpus constitutes a sample. Table 3 shows the results of calculating Kendall&apos;s considerations for ranking ties, for all (TN ) = 45 pairing combinations of the top 10 most frequently occurring synsets. Correlations can range from -1.0 reflecting inverse correlato direct correlation, i.e. the presence of one class increases as the presence the correlated verb class increases. A of 0 would show that the two variables&apos; values are independent of each other. acceptable • 1 • • • v2 • • vi vi v2 • unacceptable vt• 1 • • vi • • • v2 • 683 Results show a significant positive correlation between the synsets. The range of correlation from .850 between the get, inform, ...) the relate, give, ...) .238 between synset study, give, ...) state synset come, close, ..) These correlations show that frequent synsets do not behave independently of each other and thus confirm that the WordNet results are not an effective way to achieve document discrimination. Although the WordNet results were not discriminatory, we were still convinced that our initial hypothesis on the role of verbs in determining event profile was worth pursuing. We believe that these results are a by-product of lexical ambiguity and of the richness of the WordNet hierarchy. We thus decided to pursue a new approach to test our hypothesis, one which turned out to provide us with clearer and more robust results. act corn chng alter infra exps thnk judg trnf state .407 .296 .672 .461 .286 .269 .238 .355 .268 trnsf .437 .436 .251 .436 .251 .404 .369 .359 judge .444 .414 .435 .450 .340 .348 .427 exprs .444 .414 .435 .397 .322 .432 think .444 .414 .435 .397 .398 infrm .614 .649 .341 .380 alter .501 .454 .619 chnge .496 .393 comun .850 3: Kendall&apos;s frequent WordNet synsets. EVCA. different approach to test the hypothesis was to use another semantic categorization method; we chose the semantic classes of Levin&apos;s EVCA as a basis for our next Levin&apos;s seminal work is based on the time-honored observation that verbs which participate in similar syntactic alternations tend to share semantic properties. Thus, the behavior of a verb with respect to the expression and interpretation of its arguments can be said to be, in large part, determined by its meaning. Levin has meticulously set out a list of syntactic tests (about 100 in all), which predict membership in no less than 48 classes, each of which is divided into numerous sub-classes. The rigor and thoroughness of Levin&apos;s study permitted us to enour algorithm, a sub-set speaking, our classification is based on EVCA. Although many of our classes are precisely defined in terms of EVCA tests, we did impose some extensions. For example, support verbs are not an EVCA category. of the EVCA classes, ones which were frequent in our corpus. First, we manually categorized the 100 most frequent verbs, as well as 50 additional verbs, which covers 56% of the verbs by token in the corpus. We subjected each verb to a set of strict linguistic tests, as shown in Table 4 and verified primary verb usage against the corpus. Verb Class Sample Test (sample verbs) Does this involve a transfer of ideas? (add, say, an- (2) X verbed &amp;quot;something.&amp;quot; nounce, ...) verbed without moving&amp;quot;. (rise, fall, decline, &amp;quot;They verbed to join forces.&amp;quot; (agree, accept, con- (2) involves more than one participant. cur, ...) &amp;quot;They verbed (over) the issue.&amp;quot; (argue, debate„ (2) indicates conflicting views. (3) involves more than one participant. X verbed Y (to happen/happened). (cause) (2) X brings about a change in Y. Table 4: EVCA verb class test from order to be able to compare article types and emphasize their differences, we selected articles that had the highest percentage of a particular verb class from each of the ten verb classes; we chose five articles from each EVCA class, yielding a total of 50 articles for analysis from the full set of 1236 articles. We observed that each class discriminated between different article types as shown in Table 5. In contrast to Table 2, the article types are well discriminated by verb class. example, a concentration of communicaverbs (say, announce, . ..) indicated that the article type was a general announcement of short or medium length, or a longer feature article with many opinions in the Articles high in were also announcements, but differed from the communication ones, in that they were commonly postings of company earnings reaching a new high dropping from last quarter. appeared in many of the same articles, involving issues of some controversy. However, we noted that articles with agreement verbs were a superset of the argument ones in that, in our corpus, argument verbs did not appear in articles concerning joint ventures and Articles marked by verbs tended to be a bit longer, possibly reflecting prose on both the cause and effect of 684 particular action. We also used to investigate articles marked by the absence of members of each verb class, such as articles lacking any verbs in the motion verb class. However, we found that absence of a verb class was not discriminatory. Class Article (sample verbs) (listed by frequency) Communication issues, reports, opinions, editorials (add, bay, announce, .. ) Motion posted earnings, announcements (rise, fall, decline..... legal cases, transactions (agree, accept, concur, (without buying and selling) ...) Argument legal cases, opinions (argue, indicate, contend, ...) feature, editorials (cause) Table 5: EVCA-based verb class results. of EVCA verb classes. strengthen the observations that articles dominated by verbs of one class reflect distinct article types, we verified that the verb classes behaved independently of each other. Correlations for EVCA classes are shown in Table 6. These show a markedly lower level of correlation between verb classes than the results for WordNet synsets, the range being from .265 between motion and aspectual verbs to —.026 for motion verbs and agreement verbs. These low values of .7for pairs of verb classes reflects the indeof the classes. For example, the comclasses are weakly correlated; this, we surmise, may be due to the different ways opinions can be expressed, as factual quotes using verbs or as beliefs using verbs. comun motion agree argue exp aspect cause appear .122 .076 .077 .072 .182 .112 .037 cause .093 .083 .000 .000 .073 .096 aspect .246 .265 .034 .110 .189 exp .260 .130 .054 .054 argue .162 .045 .033 argree .071 -.026 motion .259 6: Kendall&apos;s EVCA based verb classes. 4 Results and Future Work. Basis for WordNet and EVCA comparipaper reports results from two approaches, one using WordNet and other based on EVCA classes. However, the basis for comparison must be made explicit. In the case of WordNet, all verb tokens (n = 10K) were considered in all senses, whereas in the case of EVCA, a subset of less ambiguous verbs were manually selected. As reported above, we covered 56% of the verbs by token. Indeed, when we attempted to add more verbs to EVCA categories, at the 59% mark we reached a point of difficulty in adding new verbs due to ambigue.g. verbs such as although our results using EVCA are revealing in important ways, it must be emphasized that the comparison has some imbalance which puts WordNet in an unnaturally negative light. In order to accurately compare the two approaches, we would need to process either the same less ambiguous verb subset with WordNet, or the full set of all verbs in all senses with EVCA. Although the results reported in this paper permitted the validation of our hypothesis, unless a fair comparison between resources is performed, conclusions about WordNet as a resource versus EVCA class distinctions should not be inferred. Patterns. addition to considering verb type frequencies in texts, we have observed that verb distribution and patterns might also reveal subtle information in text. Verb class distribution within the document and within particular sub-sections also carry meaning. For example, we have observed that when sentences movement verbs such as folby sentences with then a telic verb such as indicates that a value rose to a certain point due to the actions of some entity. Identification of such sequences will enable us to assign functions to particular sections of contiguous text in an article, in much the same way that text segmentation program seeks identify topics from distributional vocabulary (Hearst, 1994; Kan et al., 1998). We can also use specific sequences of verbs to help in determining methods for performing semantic aggregation of individual clauses in text generation for summarization. Work. plans are to extend the current research in terms of verb coverage and in terms of article coverage. For verbs, we plan to (1) increase the verbs that we cover to include phrasal verbs; (2) increase coverage of verbs by categorizing additional high frequency verbs into EVCA classes; (3) examine the effects of 685 increased coverage on determining article type. For articles, we plan to explore a general parser so we can test our hypothesis on additional texts and examine how our conclusions scale up. Finally, we would like to combine our techniques with other indicators to form a more robust system, such as that envisioned in Biber (1989) or suggested in Kessler et al. (1997). have outlined a novel approach to document analysis for news articles which permits discrimination of the event profile of news articles. The goal of this research is to determine the role of verbs in document analysis, keeping in mind that event profile is one of many factors in determining text type. Our results show that Levin&apos;s EVCA verb classes provide reliable indicators of article type within the news domain. We have applied the algorithm to WSJ data and have discriminated articles with five EVCA semantic classes into categories such as features, opinions, and announcements. This approach to document type classification using verbs has not been explored previously in the literature. Our results on verb analysis coupled with what is already known about NP identification convinces us that future combinations of information will be even more successful in categorization of documents. Results such as these are useful in applications such as passage retrieval, summarization, and information extraction.</abstract>
<note confidence="0.933628318181818">References D. Appelt, J. Hobbs, J. Bear, D. Isreal, and M. Tyson. 1993. Fastus: A finite state processor for information from real world text. In of the 13th International Joint Conference on Artificial In- (IJCAI), France. Regina Barzilay and Michael Elhadad. 1997. Using lexchains for text summarization. In of the Intelligent Scalable Text Summarization Work- (ISTS&apos;97), ACL, Spain. Biber. 1989. A typology of english texts. Lan- Christiane Fellbaum. 1990. English verbs as a semantic Journal of Lexicography, 3(4):278- 301. Maarti A. Hearst. 1994. Multi-paragraph segmentation expository text. In of the 32th Annual Meeting of the Association of Computational Linguistics. Hill and John J. Breen. 1977. E4 Writthe News. Brown and Company, Boston, Massachusetts. Graeme Hirst and David St-Onge. 1998. Lexical chains</note>
<abstract confidence="0.901573666666667">representations of context for the detection and corof malapropisms. An electronic lexical database and some of its applications.</abstract>
<note confidence="0.71247975">Jackendoff. 1983. and Cognition. University Press, Cambridge, Massachusetts. Min-Yen Kan, Judith L. Klavans, and Kathleen R. McKeown. 1998. Linear segmentation and segment relevance. Unpublished Manuscript. Jussi Karlgren and Douglass Cutting. 1994. Recognizing text genres with simple metrics using discrimianalysis. In International Conference Computational Linguistics (COLING &apos;94), Japan. G. Kendall. 1970. Correlation Methods. Griffin, London, England, 4th edition. Brent Kessler, Geoffrey Nunberg, and Hinrich Schiitze. Automatic detection of text genre. In Proceedings of the 35th Annual Meeting of the Association of Linguistics, Spain. Levin. 1993. Verb Classes and Alternaof Chicago Press, Chicago, Ohio. Chin-Yew Lin and Eduard Hovy. 1997. Identifying topby position. In of the 5th A CL Conferon Applied Natural Language Processing, 283-290, Washington, D.C., April. Delcang Lin. 1993. University of Manitoba: Description of the NUBA System as Used for MUC-5. In Proceedings of the Fifth Conference on Message Un- MUC-5, 263-275, Baltimore, Maryland. ARPA. Marcus et al. 1994. Penn Treebank: Anno- Predicate Argument Structure. Human Language Technology Workshop. George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>D Appelt</author>
<author>J Hobbs</author>
<author>J Bear</author>
<author>D Isreal</author>
<author>M Tyson</author>
</authors>
<title>Fastus: A finite state processor for information extraction from real world text.</title>
<date>1993</date>
<booktitle>In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI),</booktitle>
<location>Chambery, France.</location>
<contexts>
<context position="3530" citStr="Appelt et al. (1993)" startWordPosition="549" endWordPosition="553">, i.e. what happened to the fares or to US Air. Did airfare prices rise, fall or stabilize? These are the verbs most typically applicable to prices, and which embody the event. 1.1 Focus on the Noun Many natural language analysis systems focus on nouns and noun phrases in order to identify information on who, what, and where. For example, in summarization, Barzilay and Elhadad (1997) and Lin and Hovy (1997) focus on multiword noun phrases. For information extraction tasks, such as the DARPA-sponsored Message Understanding Conferences (1992), only a few projects use verb phrases (events), e.g. Appelt et al. (1993), Lin (1993). In contrast, the named entity task, which identifies nouns and noun phrases, has generated numerous projects 680 as evidenced by a host of papers in recent conferences, (e.g. Wacholder et al. 1997, Palmer and Day 1997, Neumann et al. 1997). Although rich information on nominal participants, actors, and other entities is provided, the named entity task provides no information on what happened in the document, i.e. the event or action. Less progress has been made on ways to utilize verbal information efficiently. In earlier systems with stemming, many of the verbal and nominal form</context>
</contexts>
<marker>Appelt, Hobbs, Bear, Isreal, Tyson, 1993</marker>
<rawString>D. Appelt, J. Hobbs, J. Bear, D. Isreal, and M. Tyson. 1993. Fastus: A finite state processor for information extraction from real world text. In Proceedings of the 13th International Joint Conference on Artificial Intelligence (IJCAI), Chambery, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Regina Barzilay</author>
<author>Michael Elhadad</author>
</authors>
<title>Using lexical chains for text summarization.</title>
<date>1997</date>
<booktitle>In Proceedings of the Intelligent Scalable Text Summarization Workshop (ISTS&apos;97), ACL,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="3296" citStr="Barzilay and Elhadad (1997)" startWordPosition="513" endWordPosition="516">n information extraction systems. For example, given the noun phrases fares and US Air that occur within a particular article, the reader will know what the story is about, i.e. fares and US Air. However, the reader will not know the [EVENT], i.e. what happened to the fares or to US Air. Did airfare prices rise, fall or stabilize? These are the verbs most typically applicable to prices, and which embody the event. 1.1 Focus on the Noun Many natural language analysis systems focus on nouns and noun phrases in order to identify information on who, what, and where. For example, in summarization, Barzilay and Elhadad (1997) and Lin and Hovy (1997) focus on multiword noun phrases. For information extraction tasks, such as the DARPA-sponsored Message Understanding Conferences (1992), only a few projects use verb phrases (events), e.g. Appelt et al. (1993), Lin (1993). In contrast, the named entity task, which identifies nouns and noun phrases, has generated numerous projects 680 as evidenced by a host of papers in recent conferences, (e.g. Wacholder et al. 1997, Palmer and Day 1997, Neumann et al. 1997). Although rich information on nominal participants, actors, and other entities is provided, the named entity tas</context>
</contexts>
<marker>Barzilay, Elhadad, 1997</marker>
<rawString>Regina Barzilay and Michael Elhadad. 1997. Using lexical chains for text summarization. In Proceedings of the Intelligent Scalable Text Summarization Workshop (ISTS&apos;97), ACL, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Douglas Biber</author>
</authors>
<title>A typology of english texts.</title>
<date>1989</date>
<journal>Language,</journal>
<pages>27--3</pages>
<contexts>
<context position="7048" citStr="Biber (1989)" startWordPosition="1128" endWordPosition="1129">(e.g. spokesman, analyst) suggest a discussion article. If verbs are ignored, this fact would be overlooked. Matches on frequent nouns like gain and loss do not discriminate this article from one which announces a gain or loss as breaking news; indeed, according to our results, a breaking news article would feature a higher percentage of motion verbs rather than verbs of communication. 1.3 On Genre Detection Verbs are an important factor in providing an event profile, which in turn might be used in categorizing articles into different genres. Turning to the literature in genre classification, Biber (1989) outlines five dimensions which can be used to characterize genre. Properties for distinguishing dimensions include verbal features such as tense, agentless passives and infinitives. Biber also refers to three verb classes: private, public, and suasive verbs. Karlgren and Cutting (1994) take a computationally tractable set of these properties and use them to compute a score to recognize text genre using discriminant analysis. The only verbal feature used in their study is present-tense verb count. As Karlgren and Cutting show, their techniques are effective in genre categorization, but they do</context>
<context position="26158" citStr="Biber (1989)" startWordPosition="4334" endWordPosition="4335">esearch in terms of verb coverage and in terms of article coverage. For verbs, we plan to (1) increase the verbs that we cover to include phrasal verbs; (2) increase coverage of verbs by categorizing additional high frequency verbs into EVCA classes; (3) examine the effects of 685 increased coverage on determining article type. For articles, we plan to explore a general parser so we can test our hypothesis on additional texts and examine how our conclusions scale up. Finally, we would like to combine our techniques with other indicators to form a more robust system, such as that envisioned in Biber (1989) or suggested in Kessler et al. (1997). Conclusion. We have outlined a novel approach to document analysis for news articles which permits discrimination of the event profile of news articles. The goal of this research is to determine the role of verbs in document analysis, keeping in mind that event profile is one of many factors in determining text type. Our results show that Levin&apos;s EVCA verb classes provide reliable indicators of article type within the news domain. We have applied the algorithm to WSJ data and have discriminated articles with five EVCA semantic classes into categories suc</context>
</contexts>
<marker>Biber, 1989</marker>
<rawString>Douglas Biber. 1989. A typology of english texts. Language, 27:3-43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christiane Fellbaum</author>
</authors>
<title>English verbs as a semantic net.</title>
<date>1990</date>
<journal>International Journal of Lexicography,</journal>
<pages>3--4</pages>
<contexts>
<context position="12112" citStr="Fellbaum 1990" startWordPosition="1962" endWordPosition="1963">m&apos;s Wall Street Journal (WSJ) corpus from which we extracted main and complement of communication verbs to test the algorithms on. Using WordNet. Our first technique was to use WordNet to build links between verbs and to provide a semantic profile of the document. WordNet is a general lexical resource in which words are organized into synonym sets, each representing one underlying lexical concept (Miller et al. 1990). These synonym sets - or synsets - are connected by different semantic relationships such as hypernymy (i.e. plunging is a way of descending), synonymy, antonymy, and others (see Fellbaum 1990). The determination of relatedness via taxonomic relations has a rich history (see Resnik 1993 for a review). The premise is that words with similar meanings will be located relatively close to each other in the hierarchy. Figure 1 shows the verbs cite and post, which are related via a common ancestor inform, ... , let know. The WN-Verber tool. We used the hypernym relationship in WordNet because of its high coverage. We counted the number of edges needed to find a common ancestor for a pair of verbs. Given the hierarchical structure of WordNet, the lower the edge count, in principle, the clos</context>
<context position="13604" citStr="Fellbaum 1990" startWordPosition="2216" endWordPosition="2217">nsets) to be the descendent of possibly more than one ancestor, two words can often be related by more than one common ancestor via different paths, possibly with the same relationship (grandparent and grandparent, or with different relations (grandparent and uncle). Results from WN-Verber. . We ran all articles longer than 10 sentences in the WSJ corpus (1236 articles) through WN-Verber. Output showed that several verbs - e.g. go, take, and say - participate in a very large percentage of the high frequency synsets (approximate 30%). This is due to the width of the verb forest in WordNet (see Fellbaum 1990); top level verb synsets tend to have a large number of descendants which are arranged in fewer generations, resulting in a flat and bushy tree structure. For example, a top level verb synset, inform, ... , give information, let know has over 40 children, whereas a similar top level noun synset, entity, only has 15 children. As a result, using fewer than two levels resulted in groupings that were too limited to aggregate verbs effectively. Thus, for our system, we allowed up to two edges to intervene between a common ancestor synset and each of the verbs&apos; respective synsets, as in Figure 2. Fi</context>
</contexts>
<marker>Fellbaum, 1990</marker>
<rawString>Christiane Fellbaum. 1990. English verbs as a semantic net. International Journal of Lexicography, 3(4):278-301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maarti A Hearst</author>
</authors>
<title>Multi-paragraph segmentation of expository text.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32th Annual Meeting of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="25304" citStr="Hearst, 1994" startWordPosition="4190" endWordPosition="4191">n text. Verb class distribution within the document and within particular sub-sections also carry meaning. For example, we have observed that when sentences with movement verbs such as rise or fall are followed by sentences with cause and then a telic aspectual verb such as reach, this indicates that a value rose to a certain point due to the actions of some entity. Identification of such sequences will enable us to assign functions to particular sections of contiguous text in an article, in much the same way that text segmentation program seeks identify topics from distributional vocabulary (Hearst, 1994; Kan et al., 1998). We can also use specific sequences of verbs to help in determining methods for performing semantic aggregation of individual clauses in text generation for summarization. Future Work. Our plans are to extend the current research in terms of verb coverage and in terms of article coverage. For verbs, we plan to (1) increase the verbs that we cover to include phrasal verbs; (2) increase coverage of verbs by categorizing additional high frequency verbs into EVCA classes; (3) examine the effects of 685 increased coverage on determining article type. For articles, we plan to exp</context>
</contexts>
<marker>Hearst, 1994</marker>
<rawString>Maarti A. Hearst. 1994. Multi-paragraph segmentation of expository text. In Proceedings of the 32th Annual Meeting of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Evan Hill</author>
<author>John J Breen</author>
</authors>
<date>1977</date>
<booktitle>Reporting E4 Writing the News. Little, Brown and Company,</booktitle>
<location>Boston, Massachusetts.</location>
<contexts>
<context position="8472" citStr="Hill and Breen (1977)" startWordPosition="1356" endWordPosition="1359">ons, or presence of Latinate suffixes. The taxonomy of genres and facets developed in Kessler et al. is useful for a wide range of types, such as found in the Brown corpus. Although some of their discriminators could be useful for news articles (e.g. presence of second person pronoun tends to indicate a letter to the editor), the indicators do not appear to be directly applicable to a finer classification of news articles. News articles can be divided into several stan681 dard categories typically addressed in journalism textbooks. We base our article category ontology, shown in lowercase, on Hill and Breen (1977), in uppercase: 1. FEATURE STORIES : feature; 2. INTERPRETIVE STORIES: editorial, opinion, report; 3. PROFILES; 4. PRESS RELEASES: announcements, mergers, legal cases; 5. OBITUARIES; 6. STATISTICAL INTERPRETATION: posted earnings; 7. ANECDOTES; 8. OTHER: poems. The goal of our research is to identify the role of verbs, keeping in mind that event profile is but one of many factors in determining text type. In our study, we explored the contribution of verbs as one factor in document type discrimination; we show how article types can be successfully classified within the news domain using verb s</context>
</contexts>
<marker>Hill, Breen, 1977</marker>
<rawString>Evan Hill and John J. Breen. 1977. Reporting E4 Writing the News. Little, Brown and Company, Boston, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Graeme Hirst</author>
<author>David St-Onge</author>
</authors>
<title>Lexical chains as representations of context for the detection and correction of malapropisms. WordNet: An electronic lexical database and some of its applications.</title>
<date>1998</date>
<marker>Hirst, St-Onge, 1998</marker>
<rawString>Graeme Hirst and David St-Onge. 1998. Lexical chains as representations of context for the detection and correction of malapropisms. WordNet: An electronic lexical database and some of its applications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ray Jackendoff</author>
</authors>
<title>Semantics and Cognition.</title>
<date>1983</date>
<publisher>MIT University Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="2204" citStr="Jackendoff (1983)" startWordPosition="328" endWordPosition="330">ge earlier implementations by James Shaw, and very valuable discussion from Vasileios Hatzivassiloglou, Kathleen McKeown and Nina Wacholder. Partial funding for this project was provided by NSF award #IRI-9618797 STIMULATE: Generating Coherent Summaries of On-Line Documents: Combining Statistical and Symbolic Techniques (co-PI&apos;s McKeown and Klavans), and by the Columbia University Center for Research on Information Access. nouns and verbs in documents. The listing below shows the ontological categories which express the fundamental conceptual components of propositions, using the framework of Jackendoff (1983). Each category permits the formation of a wh-question, e.g. for [THING] &amp;quot;what did you buy?&amp;quot; can be answered by the noun &amp;quot;a fish&amp;quot;. The wh-questions for [ACTION] and [EVENT] can only be answered by verbal constructions, e.g. in the question &amp;quot;what did you do?&amp;quot;, where the response must be a verb, e.g. jog, write, fall, etc. [THING] [DIRECTION] [ACTION] [PLACE] [MANNER] [EVENT] [AMOUNT] The distinction in the ontological categories of nouns and verbs is reflected in information extraction systems. For example, given the noun phrases fares and US Air that occur within a particular article, the read</context>
</contexts>
<marker>Jackendoff, 1983</marker>
<rawString>Ray Jackendoff. 1983. Semantics and Cognition. MIT University Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Min-Yen Kan</author>
<author>Judith L Klavans</author>
<author>Kathleen R McKeown</author>
</authors>
<title>Linear segmentation and segment relevance. Unpublished Manuscript.</title>
<date>1998</date>
<contexts>
<context position="25323" citStr="Kan et al., 1998" startWordPosition="4192" endWordPosition="4195">lass distribution within the document and within particular sub-sections also carry meaning. For example, we have observed that when sentences with movement verbs such as rise or fall are followed by sentences with cause and then a telic aspectual verb such as reach, this indicates that a value rose to a certain point due to the actions of some entity. Identification of such sequences will enable us to assign functions to particular sections of contiguous text in an article, in much the same way that text segmentation program seeks identify topics from distributional vocabulary (Hearst, 1994; Kan et al., 1998). We can also use specific sequences of verbs to help in determining methods for performing semantic aggregation of individual clauses in text generation for summarization. Future Work. Our plans are to extend the current research in terms of verb coverage and in terms of article coverage. For verbs, we plan to (1) increase the verbs that we cover to include phrasal verbs; (2) increase coverage of verbs by categorizing additional high frequency verbs into EVCA classes; (3) examine the effects of 685 increased coverage on determining article type. For articles, we plan to explore a general pars</context>
</contexts>
<marker>Kan, Klavans, McKeown, 1998</marker>
<rawString>Min-Yen Kan, Judith L. Klavans, and Kathleen R. McKeown. 1998. Linear segmentation and segment relevance. Unpublished Manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jussi Karlgren</author>
<author>Douglass Cutting</author>
</authors>
<title>Recognizing text genres with simple metrics using discriminant analysis.</title>
<date>1994</date>
<booktitle>In Fifteenth International Conference on Computational Linguistics (COLING &apos;94),</booktitle>
<location>Kyoto, Japan.</location>
<contexts>
<context position="7335" citStr="Karlgren and Cutting (1994)" startWordPosition="1167" endWordPosition="1171">sults, a breaking news article would feature a higher percentage of motion verbs rather than verbs of communication. 1.3 On Genre Detection Verbs are an important factor in providing an event profile, which in turn might be used in categorizing articles into different genres. Turning to the literature in genre classification, Biber (1989) outlines five dimensions which can be used to characterize genre. Properties for distinguishing dimensions include verbal features such as tense, agentless passives and infinitives. Biber also refers to three verb classes: private, public, and suasive verbs. Karlgren and Cutting (1994) take a computationally tractable set of these properties and use them to compute a score to recognize text genre using discriminant analysis. The only verbal feature used in their study is present-tense verb count. As Karlgren and Cutting show, their techniques are effective in genre categorization, but they do not claim to show how genres differ. Kessler et al. (1997) discuss some of the complexities in automatic detection of genre using a set of computationally efficient cues, such as punctuation, abbreviations, or presence of Latinate suffixes. The taxonomy of genres and facets developed i</context>
</contexts>
<marker>Karlgren, Cutting, 1994</marker>
<rawString>Jussi Karlgren and Douglass Cutting. 1994. Recognizing text genres with simple metrics using discriminant analysis. In Fifteenth International Conference on Computational Linguistics (COLING &apos;94), Kyoto, Japan.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maurice G Kendall</author>
</authors>
<title>Rank Correlation Methods.</title>
<date>1970</date>
<location>Griffin, London, England,</location>
<note>4th edition.</note>
<contexts>
<context position="15943" citStr="Kendall 1970" startWordPosition="2592" endWordPosition="2593">icate, form, tell als, features, poems intercommunicate, ...) Change have, modify, poems, editorials, an(change) take nouncements, features Alter convert, announcements, poems, (alter, change) make, get editorials Inform inform, ex- announcements, poems, (inform, round on, plain, de- features scribe Table 2: Frequent synsets and article types. Evaluation using Kendall&apos;s Tau. We sought independent confirmation to assess the correlation between two variables&apos; rank for WN-Verber results. To evaluate the effects of one synset&apos;s frequency on another, we used Kendall&apos;s tau (7) rank order statistic (Kendall 1970). For example, was it the case that verbs under the synset act tend not to occur with verbs under the synset think? If so, do articles with this property fit a particular profile? In our results, we have information about synset frequency, where each of the 1236 articles in the corpus constitutes a sample. Table 3 shows the results of calculating Kendall&apos;s T with considerations for ranking ties, for all (TN ) = 45 pairing combinations of the top 10 most frequently occurring synsets. Correlations can range from -1.0 reflecting inverse correlation, to +1.0 showing direct correlation, i.e. the pr</context>
</contexts>
<marker>Kendall, 1970</marker>
<rawString>Maurice G. Kendall. 1970. Rank Correlation Methods. Griffin, London, England, 4th edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brent Kessler</author>
<author>Geoffrey Nunberg</author>
<author>Hinrich Schiitze</author>
</authors>
<title>Automatic detection of text genre.</title>
<date>1997</date>
<booktitle>In Proceedings of the 35th Annual Meeting of the Association of Computational Linguistics,</booktitle>
<location>Madrid,</location>
<contexts>
<context position="7707" citStr="Kessler et al. (1997)" startWordPosition="1228" endWordPosition="1231"> used to characterize genre. Properties for distinguishing dimensions include verbal features such as tense, agentless passives and infinitives. Biber also refers to three verb classes: private, public, and suasive verbs. Karlgren and Cutting (1994) take a computationally tractable set of these properties and use them to compute a score to recognize text genre using discriminant analysis. The only verbal feature used in their study is present-tense verb count. As Karlgren and Cutting show, their techniques are effective in genre categorization, but they do not claim to show how genres differ. Kessler et al. (1997) discuss some of the complexities in automatic detection of genre using a set of computationally efficient cues, such as punctuation, abbreviations, or presence of Latinate suffixes. The taxonomy of genres and facets developed in Kessler et al. is useful for a wide range of types, such as found in the Brown corpus. Although some of their discriminators could be useful for news articles (e.g. presence of second person pronoun tends to indicate a letter to the editor), the indicators do not appear to be directly applicable to a finer classification of news articles. News articles can be divided </context>
<context position="26196" citStr="Kessler et al. (1997)" startWordPosition="4339" endWordPosition="4342">rage and in terms of article coverage. For verbs, we plan to (1) increase the verbs that we cover to include phrasal verbs; (2) increase coverage of verbs by categorizing additional high frequency verbs into EVCA classes; (3) examine the effects of 685 increased coverage on determining article type. For articles, we plan to explore a general parser so we can test our hypothesis on additional texts and examine how our conclusions scale up. Finally, we would like to combine our techniques with other indicators to form a more robust system, such as that envisioned in Biber (1989) or suggested in Kessler et al. (1997). Conclusion. We have outlined a novel approach to document analysis for news articles which permits discrimination of the event profile of news articles. The goal of this research is to determine the role of verbs in document analysis, keeping in mind that event profile is one of many factors in determining text type. Our results show that Levin&apos;s EVCA verb classes provide reliable indicators of article type within the news domain. We have applied the algorithm to WSJ data and have discriminated articles with five EVCA semantic classes into categories such as features, opinions, and announcem</context>
</contexts>
<marker>Kessler, Nunberg, Schiitze, 1997</marker>
<rawString>Brent Kessler, Geoffrey Nunberg, and Hinrich Schiitze. 1997. Automatic detection of text genre. In Proceedings of the 35th Annual Meeting of the Association of Computational Linguistics, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Levin</author>
</authors>
<title>English Verb Classes and Alternations.</title>
<date>1993</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, Ohio.</location>
<contexts>
<context position="857" citStr="Levin (1993)" startWordPosition="132" endWordPosition="133">sing the event profile of news articles as a function of verb type. The unique contribution of this research is the focus on the role of verbs, rather than nouns. Two algorithms are presented and evaluated, one of which is shown to accurately discriminate documents by type and semantic properties, i.e. the event profile. The initial method, using WordNet (Miller et al. 1990), produced multiple cross-classification of articles, primarily due to the bushy nature of the verb tree coupled with the sense disambiguation problem. Our second approach using English Verb Classes and Alternations (EVCA) Levin (1993) showed that monosemous categorization of the frequent verbs in WSJ made it possible to usefully discriminate documents. For example, our results show that articles in which communication verbs predominate tend to be opinion pieces, whereas articles with a high percentage of agreement verbs tend to be about mergers or legal cases. An evaluation is performed on the results using Kendall&apos;s r. We present convincing evidence for using verb semantic classes as a discriminant in document classification.1 1 Motivation We present techniques to characterize document type and event by using semantic cla</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Beth Levin. 1993. English Verb Classes and Alternations. University of Chicago Press, Chicago, Ohio.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chin-Yew Lin</author>
<author>Eduard Hovy</author>
</authors>
<title>Identifying topics by position.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th A CL Conference on Applied Natural Language Processing,</booktitle>
<pages>283--290</pages>
<location>Washington, D.C.,</location>
<contexts>
<context position="3320" citStr="Lin and Hovy (1997)" startWordPosition="518" endWordPosition="521">. For example, given the noun phrases fares and US Air that occur within a particular article, the reader will know what the story is about, i.e. fares and US Air. However, the reader will not know the [EVENT], i.e. what happened to the fares or to US Air. Did airfare prices rise, fall or stabilize? These are the verbs most typically applicable to prices, and which embody the event. 1.1 Focus on the Noun Many natural language analysis systems focus on nouns and noun phrases in order to identify information on who, what, and where. For example, in summarization, Barzilay and Elhadad (1997) and Lin and Hovy (1997) focus on multiword noun phrases. For information extraction tasks, such as the DARPA-sponsored Message Understanding Conferences (1992), only a few projects use verb phrases (events), e.g. Appelt et al. (1993), Lin (1993). In contrast, the named entity task, which identifies nouns and noun phrases, has generated numerous projects 680 as evidenced by a host of papers in recent conferences, (e.g. Wacholder et al. 1997, Palmer and Day 1997, Neumann et al. 1997). Although rich information on nominal participants, actors, and other entities is provided, the named entity task provides no informatio</context>
</contexts>
<marker>Lin, Hovy, 1997</marker>
<rawString>Chin-Yew Lin and Eduard Hovy. 1997. Identifying topics by position. In Proceedings of the 5th A CL Conference on Applied Natural Language Processing, pages 283-290, Washington, D.C., April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Delcang Lin</author>
</authors>
<title>University of Manitoba: Description of the NUBA System as Used for MUC-5.</title>
<date>1993</date>
<booktitle>In Proceedings of the Fifth Conference on Message Understanding MUC-5,</booktitle>
<pages>263--275</pages>
<location>Baltimore, Maryland. ARPA.</location>
<contexts>
<context position="3542" citStr="Lin (1993)" startWordPosition="554" endWordPosition="555">o the fares or to US Air. Did airfare prices rise, fall or stabilize? These are the verbs most typically applicable to prices, and which embody the event. 1.1 Focus on the Noun Many natural language analysis systems focus on nouns and noun phrases in order to identify information on who, what, and where. For example, in summarization, Barzilay and Elhadad (1997) and Lin and Hovy (1997) focus on multiword noun phrases. For information extraction tasks, such as the DARPA-sponsored Message Understanding Conferences (1992), only a few projects use verb phrases (events), e.g. Appelt et al. (1993), Lin (1993). In contrast, the named entity task, which identifies nouns and noun phrases, has generated numerous projects 680 as evidenced by a host of papers in recent conferences, (e.g. Wacholder et al. 1997, Palmer and Day 1997, Neumann et al. 1997). Although rich information on nominal participants, actors, and other entities is provided, the named entity task provides no information on what happened in the document, i.e. the event or action. Less progress has been made on ways to utilize verbal information efficiently. In earlier systems with stemming, many of the verbal and nominal forms were confl</context>
</contexts>
<marker>Lin, 1993</marker>
<rawString>Delcang Lin. 1993. University of Manitoba: Description of the NUBA System as Used for MUC-5. In Proceedings of the Fifth Conference on Message Understanding MUC-5, pages 263-275, Baltimore, Maryland. ARPA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitch Marcus</author>
</authors>
<title>The Penn Treebank: Annotating Predicate Argument Structure. ARPA Human Language Technology Workshop.</title>
<date>1994</date>
<marker>Marcus, 1994</marker>
<rawString>Mitch Marcus et al. 1994. The Penn Treebank: Annotating Predicate Argument Structure. ARPA Human Language Technology Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George A Miller</author>
<author>Richard Beckwith</author>
<author>Christiane Fellbaum</author>
<author>Derek Gross</author>
<author>Katherine J Miller</author>
</authors>
<title>Introduction to WordNet: An on-line lexical database.</title>
<date>1990</date>
<journal>International Journal of Lexicography (special issue),</journal>
<pages>3--4</pages>
<contexts>
<context position="622" citStr="Miller et al. 1990" startWordPosition="96" endWordPosition="99">e of Verbs in Document Analysis Judith Klavans* and Min-Yen Kan** Center for Research on Information Access* and Department of Computer Science** Columbia University New York, NY 10027, USA Abstract We present results of two methods for assessing the event profile of news articles as a function of verb type. The unique contribution of this research is the focus on the role of verbs, rather than nouns. Two algorithms are presented and evaluated, one of which is shown to accurately discriminate documents by type and semantic properties, i.e. the event profile. The initial method, using WordNet (Miller et al. 1990), produced multiple cross-classification of articles, primarily due to the bushy nature of the verb tree coupled with the sense disambiguation problem. Our second approach using English Verb Classes and Alternations (EVCA) Levin (1993) showed that monosemous categorization of the frequent verbs in WSJ made it possible to usefully discriminate documents. For example, our results show that articles in which communication verbs predominate tend to be opinion pieces, whereas articles with a high percentage of agreement verbs tend to be about mergers or legal cases. An evaluation is performed on th</context>
<context position="11918" citStr="Miller et al. 1990" startWordPosition="1930" endWordPosition="1933">ic classification system, in this case, using Levin&apos;s (1993) English Verb Classes and Alternations (EVCA-Verber) as a basis. For source material, we used the manually-parsed Linguistic Data Consortium&apos;s Wall Street Journal (WSJ) corpus from which we extracted main and complement of communication verbs to test the algorithms on. Using WordNet. Our first technique was to use WordNet to build links between verbs and to provide a semantic profile of the document. WordNet is a general lexical resource in which words are organized into synonym sets, each representing one underlying lexical concept (Miller et al. 1990). These synonym sets - or synsets - are connected by different semantic relationships such as hypernymy (i.e. plunging is a way of descending), synonymy, antonymy, and others (see Fellbaum 1990). The determination of relatedness via taxonomic relations has a rich history (see Resnik 1993 for a review). The premise is that words with similar meanings will be located relatively close to each other in the hierarchy. Figure 1 shows the verbs cite and post, which are related via a common ancestor inform, ... , let know. The WN-Verber tool. We used the hypernym relationship in WordNet because of its</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>George A. Miller, Richard Beckwith, Christiane Fellbaum, Derek Gross, and Katherine J. Miller. 1990. Introduction to WordNet: An on-line lexical database. International Journal of Lexicography (special issue), 3(4):235-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Morris</author>
<author>Graeme Hirst</author>
</authors>
<title>Lexical coherence computed by thesaural relations as an indicator of the structure of text.</title>
<date>1991</date>
<journal>Computational Linguistics,</journal>
<booktitle>Message Understanding Conference — MUG.</booktitle>
<pages>17--1</pages>
<contexts>
<context position="11166" citStr="Morris and Hirst (1991)" startWordPosition="1809" endWordPosition="1812">sted that articles with a preponderance of verbs of Verb Type Sample Verbs communication say, announce, ... support have, get, go, ... remainder abuse, claim, offer, ... Table 1: Approximate Frequency of verbs by type from the Wall Street Journal (main and selected subordinate verbs, n = 10,295). a certain semantic type might reveal aspects of document type, we tested the hypothesis that verbs could be used as a predictor in providing an event profile. We developed two algorithms to: (1) explore WordNet (WN-Verber) to cluster related verbs and build a set of verb chains in a document, much as Morris and Hirst (1991) used Roget&apos;s Thesaurus or like Hirst and St. Onge (1998) used WordNet to build noun chains; (2) classify verbs according to a semantic classification system, in this case, using Levin&apos;s (1993) English Verb Classes and Alternations (EVCA-Verber) as a basis. For source material, we used the manually-parsed Linguistic Data Consortium&apos;s Wall Street Journal (WSJ) corpus from which we extracted main and complement of communication verbs to test the algorithms on. Using WordNet. Our first technique was to use WordNet to build links between verbs and to provide a semantic profile of the document. Wor</context>
</contexts>
<marker>Morris, Hirst, 1991</marker>
<rawString>Jane Morris and Graeme Hirst. 1991. Lexical coherence computed by thesaural relations as an indicator of the structure of text. Computational Linguistics, 17(1):21-42. 1992. Message Understanding Conference — MUG.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gunter Neumann</author>
<author>Rolf Backofen</author>
<author>Judith Baur</author>
<author>Marcus Becker</author>
<author>Christian Braun</author>
</authors>
<title>An information extraction core system for real world german text processing.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th A CL Conference on Applied Natural Language Processing,</booktitle>
<pages>209--216</pages>
<location>Washington, D.C.,</location>
<contexts>
<context position="3783" citStr="Neumann et al. 1997" startWordPosition="593" endWordPosition="596">and noun phrases in order to identify information on who, what, and where. For example, in summarization, Barzilay and Elhadad (1997) and Lin and Hovy (1997) focus on multiword noun phrases. For information extraction tasks, such as the DARPA-sponsored Message Understanding Conferences (1992), only a few projects use verb phrases (events), e.g. Appelt et al. (1993), Lin (1993). In contrast, the named entity task, which identifies nouns and noun phrases, has generated numerous projects 680 as evidenced by a host of papers in recent conferences, (e.g. Wacholder et al. 1997, Palmer and Day 1997, Neumann et al. 1997). Although rich information on nominal participants, actors, and other entities is provided, the named entity task provides no information on what happened in the document, i.e. the event or action. Less progress has been made on ways to utilize verbal information efficiently. In earlier systems with stemming, many of the verbal and nominal forms were conflated, sometimes erroneously. With the development of more sophisticated tools, such as part of speech taggers, more accurate verb phrase identification is possible. We present in this paper an effective way to utilize verbal information for </context>
</contexts>
<marker>Neumann, Backofen, Baur, Becker, Braun, 1997</marker>
<rawString>Gunter Neumann, Rolf Backofen, Judith Baur, Marcus Becker, and Christian Braun. 1997. An information extraction core system for real world german text processing. In Proceedings of the 5th A CL Conference on Applied Natural Language Processing, pages 209-216, Washington, D.C., April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David D Palmer</author>
<author>David S Day</author>
</authors>
<title>A statistical profile of the named entity task.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th A CL Conference on Applied Natural Language Processing,</booktitle>
<pages>190--193</pages>
<location>Washington, D.C.,</location>
<contexts>
<context position="3761" citStr="Palmer and Day 1997" startWordPosition="589" endWordPosition="592">stems focus on nouns and noun phrases in order to identify information on who, what, and where. For example, in summarization, Barzilay and Elhadad (1997) and Lin and Hovy (1997) focus on multiword noun phrases. For information extraction tasks, such as the DARPA-sponsored Message Understanding Conferences (1992), only a few projects use verb phrases (events), e.g. Appelt et al. (1993), Lin (1993). In contrast, the named entity task, which identifies nouns and noun phrases, has generated numerous projects 680 as evidenced by a host of papers in recent conferences, (e.g. Wacholder et al. 1997, Palmer and Day 1997, Neumann et al. 1997). Although rich information on nominal participants, actors, and other entities is provided, the named entity task provides no information on what happened in the document, i.e. the event or action. Less progress has been made on ways to utilize verbal information efficiently. In earlier systems with stemming, many of the verbal and nominal forms were conflated, sometimes erroneously. With the development of more sophisticated tools, such as part of speech taggers, more accurate verb phrase identification is possible. We present in this paper an effective way to utilize v</context>
</contexts>
<marker>Palmer, Day, 1997</marker>
<rawString>David D. Palmer and David S. Day. 1997. A statistical profile of the named entity task. In Proceedings of the 5th A CL Conference on Applied Natural Language Processing, pages 190-193, Washington, D.C., April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philip Resnik</author>
</authors>
<title>Selection and Information: A Class-Based Approach to Lexical Relationships.</title>
<date>1993</date>
<tech>Ph.D. thesis,</tech>
<institution>Department of Computer and Information Science, University of Pennsylvania.</institution>
<contexts>
<context position="12206" citStr="Resnik 1993" startWordPosition="1977" endWordPosition="1978"> verbs to test the algorithms on. Using WordNet. Our first technique was to use WordNet to build links between verbs and to provide a semantic profile of the document. WordNet is a general lexical resource in which words are organized into synonym sets, each representing one underlying lexical concept (Miller et al. 1990). These synonym sets - or synsets - are connected by different semantic relationships such as hypernymy (i.e. plunging is a way of descending), synonymy, antonymy, and others (see Fellbaum 1990). The determination of relatedness via taxonomic relations has a rich history (see Resnik 1993 for a review). The premise is that words with similar meanings will be located relatively close to each other in the hierarchy. Figure 1 shows the verbs cite and post, which are related via a common ancestor inform, ... , let know. The WN-Verber tool. We used the hypernym relationship in WordNet because of its high coverage. We counted the number of edges needed to find a common ancestor for a pair of verbs. Given the hierarchical structure of WordNet, the lower the edge count, in principle, the closer the verbs are semantically. Because WordNet 20% 30% 50% 682 common ancestor inform__ let kn</context>
</contexts>
<marker>Resnik, 1993</marker>
<rawString>Philip Resnik. 1993. Selection and Information: A Class-Based Approach to Lexical Relationships. Ph.D. thesis, Department of Computer and Information Science, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nina Wacholder</author>
<author>Yael Ravin</author>
<author>Misook Choi</author>
</authors>
<title>Disambiguation of proper names in text.</title>
<date>1997</date>
<booktitle>In Proceedings of the 5th A CL Conference on Applied Natural Language Processing,</booktitle>
<volume>1</volume>
<pages>202--209</pages>
<location>Washington, D.C.,</location>
<contexts>
<context position="3740" citStr="Wacholder et al. 1997" startWordPosition="585" endWordPosition="588">al language analysis systems focus on nouns and noun phrases in order to identify information on who, what, and where. For example, in summarization, Barzilay and Elhadad (1997) and Lin and Hovy (1997) focus on multiword noun phrases. For information extraction tasks, such as the DARPA-sponsored Message Understanding Conferences (1992), only a few projects use verb phrases (events), e.g. Appelt et al. (1993), Lin (1993). In contrast, the named entity task, which identifies nouns and noun phrases, has generated numerous projects 680 as evidenced by a host of papers in recent conferences, (e.g. Wacholder et al. 1997, Palmer and Day 1997, Neumann et al. 1997). Although rich information on nominal participants, actors, and other entities is provided, the named entity task provides no information on what happened in the document, i.e. the event or action. Less progress has been made on ways to utilize verbal information efficiently. In earlier systems with stemming, many of the verbal and nominal forms were conflated, sometimes erroneously. With the development of more sophisticated tools, such as part of speech taggers, more accurate verb phrase identification is possible. We present in this paper an effec</context>
</contexts>
<marker>Wacholder, Ravin, Choi, 1997</marker>
<rawString>Nina Wacholder, Yael Ravin, and Misook Choi. 1997. Disambiguation of proper names in text. In Proceedings of the 5th A CL Conference on Applied Natural Language Processing, volume 1, pages 202-209, Washington, D.C., April.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>