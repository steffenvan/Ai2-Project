<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000491">
<title confidence="0.998079">
Lexical Operations in a Unification-based Framework
</title>
<author confidence="0.998921">
Ann Copestake, Ted Briscoe
</author>
<affiliation confidence="0.999605">
Computer Laboratory, University of Cambridge, Pembroke Street,
</affiliation>
<address confidence="0.911138">
Cambridge, CBe VG, UK
</address>
<email confidence="0.971061">
aac@cl.cam.ac.uk ejb@cl.cam.ac.uk
</email>
<sectionHeader confidence="0.954363" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999282">
We consider lexical operations and their representation in a unification based lexicon
and the role of lexical semantic information. We describe a unified treatment of
the linguistic aspects of sense extension and derivational morphological processes
which delimit the range of possible coercions between lexemes and give a preliminary
account of how default interpretations may arise.
</bodyText>
<sectionHeader confidence="0.999345" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999810066666667">
In this paper we consider the nature and extent of lexical operations, arguing for a
declarative and computationally tractable definition of a lexical rule as a component of
a unification-based lexicon employing (default) inheritance and typed feature structures.
We claim that this notion of lexical rule is capable of capturing the linguistic element of
derivational morphological processes as well as metonymic and metaphoric sense exten-
sions, but is not adequate for the statement of certain types of logical metonymy (e.g.
Pustejovsky, 1989a). We argue that such operations must be treated as, in part, &apos;linguis-
tic&apos; because they have morphological and syntactic consequences, undergo &apos;blocking&apos;, are
triggered by grammatically-defined type mismatches and involve default interpretations
based on lexical organisation. However, we also argue that such default interpretations
can be overridden by contextual information on the basis of more general and open-ended
&apos;pragmatic&apos; inference. Our account contrasts with that of, say, Hobbs et al. (1987) who
posit an underspecified and impoverished lexical semantic representation which is en-
riched through an open-ended process of abductive or deductive reasoning with world (or
domain) knowledge. Our lexical knowledge representation language does not support gen-
eral inference, although our lexical semantic representations are often &apos;richer&apos; than those
standardly assumed.
A standard example of metonymic sense extension is the use of a word denoting a
place to refer to (some of) the people inhabiting that place (e.g. &amp;quot;village&amp;quot;, &amp;quot;palace&amp;quot;).
This process seems to involve the foregrounding of one component of the meaning of the
place denoting word â€” we follow Pustejovsky (1989a,b,c) in assuming that the lexical
semantic representation of nouns includes information about typical relations which the
objects they denote enter into; in particular, the &amp;quot;qualia structure&amp;quot; for such nouns will
contain (telic) information which allows direct access to the information that they are
inhabited. A well-known example of metaphoric sense extension is that involving use of
a word denoting an animal to refer to humans (&amp;quot;John is a pig&amp;quot;, &amp;quot;John is a wombat&amp;quot; etc).
Although the sense extension from animals into metaphorical senses denoting humans
with some particular characteristic is apparently productive, the actual characteristics
involved, and even whether the word can be applied to men or to women or both, cannot
be predicted from knowledge of the animal sense. Thus, the properties ascribed to a
</bodyText>
<page confidence="0.997842">
88
</page>
<bodyText confidence="0.999952104166667">
person by &amp;quot;pig&amp;quot; are arguably no more than stereotypical associations with the animal,
rather than central aspects of its meaning / qualia structure. In the case of &amp;quot;wombat&amp;quot; we
would argue that the association of foolishness derives from the phonological form of the
word, rather than beliefs about the animal. Despite the more associative or analogical
nature of metaphorical sense extension, we would argue that there is a core component
to such processes which should be expressed in terms of a lexical rule, rather than in
terms of general purpose reasoning. As with the metonymic cases (Pustejovsky, 1989c;
Briscoe et al., 1990), we believe that the notion of coercion during syntactic and semantic
interpretation provides an account of when a metaphorical interpretation will be adopted,
and we would like to characterise coercion in terms of possible mappings defined by lexical
rules.
An example of a derivational morphological process is the addition of the &amp;quot;Cr&amp;quot; suffix to
verbs, typically creating a noun denoting the agent of the action denoted by the verb (e.g.
&amp;quot;teach&amp;quot;, &amp;quot;teacher&amp;quot;). There are several apparent differences between this type of process
and the metonymic and metaphoric sense extensions considered above. The derivational
rule involves a change of syntactic class, it affects the argument structure of the derived
predicate, it involves affixation, and although there is a foregrounding of one aspect of the
verb meaning, the result would not traditionally be described as a metonymic, or indeed
metaphorical, usage. Nevertheless, there are clearly derivational processes which do not
affect syntactic class (e.g. &amp;quot;re-program&amp;quot;, &amp;quot;un-reprogrammable&amp;quot;) and of sense extensions
which do; for example, countability of nouns changes depending on whether they are
interpreted as types, substances or portions (e.g. &amp;quot;There was beer all over the table&amp;quot;,
&amp;quot;John drank a beer&amp;quot;). Not all derivational processes affect argument structure (e.g. &amp;quot;un-
kind&amp;quot;), whilst metonymic sense extensions (e.g. &amp;quot;John enjoyed the film&amp;quot;, John finished
the beer&amp;quot;) can, at least given the analyses of Pustejovsky (1989c) and Briscoe et al.
(1990). Finally, processes of conversion and derivation can be identical; for example, both
&amp;quot;purchase&amp;quot; and &amp;quot;replace&amp;quot; have deverbal nominal forms &amp;quot;purchase&amp;quot; and &amp;quot;replacement&amp;quot;,
both nouns can denote the action involved and take appropriate complements (&amp;quot;Bill&apos;s
purchase of his new car&amp;quot;, &amp;quot;Bill&apos;s replacement of John with Mary&amp;quot;), and both can denote
the result of the action (&amp;quot;Bill&apos;s purchases were many and varied&amp;quot; &amp;quot;Bill&apos;s replacement was
young&amp;quot;). Traditionally, this latter resultative meaning would be described as metonymic
and probably specialised and non-productive. We think that our definition of lexical
rule will allow an account of both conversion and derivation as productive syntactic and
semantic operations mapping between lexical entries. The difference between metaphorical
and metonymic operations is a matter of the degree to which the interaction of the lexical
rule with the basic entry determines or circumscribes the eventual interpretation.
There are other similarities between sense extension and derivational morphology;
clearly, productivity is an issue in both, and in particular, sense extension processes may
apparently be blocked (preempted by synonymy), in a way comparable to the situation
in derivational morphology (see e.g. Bauer 1983:87f). For example, the regular form
&amp;quot;stealer&amp;quot; does not generally occur, apparently because of the availability of &amp;quot;thief&amp;quot;. An-
other productive metonymic sense extension is that of animal denoting (count) nouns to
(mass) nouns denoting their meat (e.g. &amp;quot;lamb&amp;quot;), but this process too is blocked by the
presence of a synonymous lexeme with different form (&amp;quot;pig&amp;quot;, &amp;quot;pork&amp;quot;). By representing
such processes in terms of lexical rules mapping between entries, we hope to account
for blocking in terms of syntactic and semantic identity with an entry defined without
recourse to the relevant lexical rule. In addition, we hope to express sense extension pro-
cesses, and indeed derivational ones, as fully productive processes which apply to finely
</bodyText>
<page confidence="0.999587">
89
</page>
<bodyText confidence="0.958662518518519">
specified subsets of the lexicon, defined in terms of both syntactic and semantic properties
expressed in the type system underlying the organisation of the lexicon.
In Briscoe et al. (1990) we offered an account of logical metonymies such as that
involved in the interpretation of &amp;quot;Bill enjoyed / regretted that paper&amp;quot;, drawing on Puste-
jovsky (1989a), in which a unary syntactic rule is used to coerce the entity-denoting NP
&amp;quot;that paper&amp;quot; into an event-denoting NP with an underspecified predicate. We argued
that a default specification of this predicate is supplied by the qualia structure of the
noun and that this is determined by the organisation of the lexicon as a default inher-
itance network. Specifically, &amp;quot;paper&amp;quot; in the relevant sense will inherit a telic role read&apos;
and agentive role write&apos; and &amp;quot;enjoy&amp;quot; will by default select the telic role of an NP object,
whilst &amp;quot;regret&amp;quot; will select the agentive role. We presented evidence based on corpus data
that such default interpretations are appropriate in unmarked informationally-weak con-
texts, but that they are overridden in marked contexts in which such an interpretation
would be clearly inappropriate. The corpus evidence suggests, firstly, that the default in-
terpretation is appropriate with most such logical metonymies and, secondly, that where
it is not, the context is sufficient to block it. By contrast, an account such as that of
Hobbs et al. (1987) has difficulty explaining why the default interpretation is adopted
in the absence of contextual information, unless the effects of lexical organisation are re-
constructed in terms of weightings encoding preferences amongst inferences. Whilst this
account of the division of labour between default but circumscribed linguistic processes
and more open-ended inference remains attractive, the treatment of coercion in this case
as a unary syntactic rule, or in Pustejovsky&apos;s (1989c) alternative account as a lexical rule,
seems inadequate. The interpretation of an individual-denoting nominal or noun phrase
as an event-denoting one may be more a matter of systematic vagueness than ambiguity
between determinate senses. Pustejovsky (1989a) argues that in examples such as a), b)
or c) &amp;quot;long&amp;quot; will have an interpretation in which it modifies the telic or agentive role of
&amp;quot;book&amp;quot; because it is an event modifier.
</bodyText>
<listItem confidence="0.900396333333333">
a) John bought and read the long book.
b) John enjoyed the long book.
c) John bought, read and enjoyed the long book.
</listItem>
<bodyText confidence="0.999782">
However, this coercion of &amp;quot;book&amp;quot; into, say, &amp;quot;long book to read&amp;quot; does not preclude
either an event-denoting or individual-denoting interpretation of the complete NP, as a)
and b) demonstrate (where presumably &amp;quot;read&amp;quot; and &amp;quot;bought&amp;quot; select the straightforward
referential interpretation, whilst &amp;quot;enjoy&amp;quot; forces another round of coercion). Furthermore,
an example like c) which involves a &amp;quot;crossed&amp;quot; interpretation in which &amp;quot;the long book&amp;quot; is
simultaneously interpreted as individual- and event-denoting does not seem odd. However,
in cases of genuine ambiguity, as opposed to vagueness, such readings are usually blocked
(Zwicky &amp; Sadock, 1975):
</bodyText>
<listItem confidence="0.966313666666667">
a) John likes landing planes and so does Bill.
b) ? Peter&apos;s purchase of hi fi took hours and was expensive.
c) ? John played with and then ate his lamb.
d) John ate and enjoyed the salmon.
e) Bill picked up and finished his beer.
f) John wrote but later regretted that paper.
</listItem>
<bodyText confidence="0.9912885">
Thus a) has two, not four, readings in which both John and Bill like watching planes
landing or like landing them themselves, but not readings in which the interpretation of
</bodyText>
<page confidence="0.996449">
90
</page>
<bodyText confidence="0.999962583333333">
&amp;quot;landing planes&amp;quot; varies between conjuncts. Similarly, b) is odd because the first con-
junct forces a deverbal event-denoting interpretation of &amp;quot;purchase&amp;quot; whilst the second
strongly prefers a resultative reading and c) is odd because the first conjunct prefers the
animal-denoting interpretation of &amp;quot;lamb&amp;quot; whilst the second selects the food-denoting one
(although the overall preferred interpretation will probably involve treating &amp;quot;played with&amp;quot;
to mean something like &apos;fiddle with or pick at (food)&apos;). By contrast, d-f) all involve mov-
ing between individual- and event-denoting readings of the final NPs, but do not seem
problematic.
These observations suggest to us that an adequate account of the coercion process in
these cases will involve positing systematic vaguenesses in interpretation of NPs, perhaps
along the lines of type ladder polymorphism (e.g. Partee &amp; Rooth 1983) or in terms of
lexical operations which apply to the predicates, like &amp;quot;enjoy&amp;quot; which introduce such logical
metonymies (rather than to the NP objects of these predicates). In this paper, though we
concentrate on ambiguities in interpretation which can be treated in terms of lexical rules
which apply to noun entries. We illustrate our approach with reference mainly to the
process of &apos;grinding&apos;. It is well known that any count noun denoting a physical object can
be used in a mass sense to denote a substance derived from that object, when it occurs in
a sufficiently marked context. We refer to this as &apos;grinding&apos; because the context normally
suggested is the &amp;quot;Universal Grinder&amp;quot; (see Pelletier and Schubert 1986). So if &amp;quot;a table&amp;quot; is
ground up the result can be referred to as &amp;quot;table&amp;quot; (&amp;quot;there was table all over the floor&amp;quot;).
Several regular sense extensions can be regarded as special cases of &apos;grinding&apos;, where the
extension may have become established. Thus besides the animal/meat examples, trees
used for wood (&amp;quot;beech&amp;quot;) have a sense denoting the wood, and so forth. Before we describe
this process in detail, we present the framework in which our account will be couched.
</bodyText>
<sectionHeader confidence="0.862218" genericHeader="method">
2 The Lexical Representation Language
</sectionHeader>
<bodyText confidence="0.9999686">
Our lexical representation language is unification-based, allowing complex interconnec-
tions between syntactic and semantic information to be defined, and making a tight inter-
face possible between the lexicon and a parser/interpreter. It supports a restricted range
of operations; (default) unification, (default) inheritance and lexical rule application. It
does not support arbitrary inference. The language is based on the use of typed feature
structures similar to those described in Carpenter (1990). Feature structures must be well-
formed with respect to types and particular features will only be appropriate to specified
types and their subtypes. Types are hierarchically ordered; the association of constraints
with types allows non-default inheritance. We augment this with a restricted concept of
default inheritance (allowing only &apos;orthogonal&apos; multiple inheritance (Touretzky 1986)); de-
fault inheritance is formalised in terms of default unification of feature structures ordered
by an inheritance hierarchy. The type system constrains both default inheritance and
lexical rule application. This representation language is described in detail in Copestake
et al (1991); the following sections are an informal description illustrated with relevant
examples.
</bodyText>
<subsectionHeader confidence="0.998715">
2.1 The type system
</subsectionHeader>
<bodyText confidence="0.99985">
The type hierarchy defines a partial ordering (notated C) on the types and specifies which
types are consistent. Only feature structures with mutually consistent types can be unified
</bodyText>
<page confidence="0.987613">
91
</page>
<figure confidence="0.9849582">
nomrqs
physobj artifact
ind_obj
inan_obj
an
artifact_o
substance food
food_substance
creature
person
</figure>
<figureCaption confidence="0.999991">
Figure 1: A fragment of a type hierarchy
</figureCaption>
<bodyText confidence="0.997980068965517">
â€” two types which are unordered in the hierarchy are assumed to be inconsistent unless
the user explicitly specifies a common subtype. Every consistent set of types S C TYPE
has a unique greatest lower bound or meet (notation nS). This condition allows feature
structures to be typed deterministically â€” if two feature structures of types a and b are
unified the type of the result will be a n b, which must be unique if it exists. If a n b does
not exist unification fails. Thus in the fragment of a type hierarchy shown in Figure 1
artifact and physobj are consistent; artifact n physobj = artifact_obj.
Our system differs somewhat from that described by Carpenter (1990) in that we adopt
a different notion of well-formedness of typed feature structures. In our system every type
must have exactly one associated feature structure which acts as a constraint on all feature
structures of that type; by subsuming all well-formed feature structures of that type. The
constraint also defines which features are appropriate for a particular type; a well formed
feature structure may only contain appropriate features. Constraints are inherited by all
subtypes of a type, but a subtype may introduce new features (which will be inherited as
appropriate features by all its subtypes). A constraint on a type is a well-formed feature
structure of that type; all constraints must therefore be mutually consistent. Constraints
can be seen as extending the PATR-II notion of templates (eg. Shieber, 1986) in that
the inheritance of constraints allows concise definitions of all feature structures, not just
lexical entries; but in an untyped system, such as PATR-II, there is no restriction on the
features that can occur in a feature structure.
For example the constraints associated with the types artifact and physobj might
be:
[[artifact
&apos;1&apos;1.11.1i: . formula
physobj
routm = physform
YSIC A 1,-STATI.: = solid
Bold case indicates types; thus, for instance formula is a type and any feature structure
of type artifact must have a feature structure of type formula as the value for its
</bodyText>
<page confidence="0.976883">
92
</page>
<bodyText confidence="0.9710639">
TELIC (purpose) feature, formula is intended to represent a formula in predicate logic,
it therefore has a complex constraint itself:
[formula
&apos;ND = entity
mom = logical-pred
AIMS = arg-list
In contrast solid is an atomic type, it has no appropriate features and its constraint is
simply the atomic feature structure [solid].
The constraint on artifact_obj will contain information inherited from both parents,
thus:
</bodyText>
<figure confidence="0.901386666666666">
[artifact_obj
roam = physform
l&apos;HYSICAI.-STATI.; = solid
T1.11.1C = formula
Further examples of constraints and features which we will use in examples in this paper
are:
ind_obj
physform
mum =
SHAN.; = individuated
[creature
AGO = scalar
stoc = gender
[animal
mnisi.p: = boolean
substance
rola&apos; =
[physform
SHAN.: = unindividuated
food formula
T10,1(: = Nam = eat
We shall also make use of the following types to define syntactic properties etc:
lex-sign C top [lex-sign
oirrii = string
noun
noun C lex-sign SYNTAX = COUN&apos;l = boolean
11.(4S = nomrqs
noun
count-noun C lex-sign
SYNTAX = COUNT = +
93
mass-noun C lex-sign [noun [ (*.MINA
SYNTAX =
</figure>
<bodyText confidence="0.783688666666667">
The feature structure below is well-formed since it contains all the appropriate features
and no inappropriate ones, it is subsumed by the constraints on its type and all its
substructures are well-formed.
</bodyText>
<equation confidence="0.731052333333333">
count-noun
ourrn = &amp;quot;haddock&amp;quot;
[SYNTAX = COUNT = +
</equation>
<table confidence="0.789219">
INS = animal
smx = gender
AGE = scalar
mulum.1 = boolean
PHYSICAL-ST/011 = solid
I&apos; um physform
=
SHAPE = individuated
Given the type system introduced above, a lexical entry, such as:
haddock 1 count-noun
&lt;rqs&gt; = animal.
would be expanded out into such a feature structurel .
</table>
<subsectionHeader confidence="0.990026">
2.2 Default inheritance
</subsectionHeader>
<bodyText confidence="0.978598095238095">
To allow default inheritance we introduce the concept of psort; a feature structure from
which another feature structure inherits information, by default. The hierarchical order-
ing on psorts (which must be consistent with the type hierarchy) provides an order on
defaults. Default inheritance is implemented by a version of default unification. Only
orthogonal multiple inheritance (Touretzky 1986) is allowed; information inherited from
multiple parents must not be contradictory. (A default inheritance hierarchy which con-
nects semantic parts of lexical entries can be derived semi-automatically from taxonomies
extracted from conventional dictionaries, see Copestake, 1990a). We refer to this particu-
lar case of the psort hierarchy as an IS_A hierarchy. Values of features can be associated
either manually or semi-automatically with psorts in the IS_A hierarchy; the more specific
word senses then inherit them, by default. (Defaults may also be useful in the represen-
tation of syntactic information in the lexicon (e.g. Flickinger, 1987).)
Since the type system constrains the psort system it also constrains multiple default
inheritance. If the value of the FOOD-TEMPERATURE feature for &amp;quot;drink 2 (1)&amp;quot; is low then
this information would be inherited by the entry for &amp;quot;beer&amp;quot; which is below &amp;quot;drink 2 (1)&amp;quot;
in the IS_A hierarchy. However inherited information may be overridden by associating
other values with psorts lower in the hierarchy; for example although &amp;quot;tea&amp;quot; is under &amp;quot;drink
2 (1)&amp;quot; in the hierarchy, its FOOD-TEMPERATURE can be specified to be high rather than
low.
1 The actual type system being employed is considerably more complex, since only the relevant features
are being shown in these examples.
</bodyText>
<page confidence="0.998688">
94
</page>
<bodyText confidence="0.999532142857143">
Types and features thus provide an organisation on the information which is neces-
sary for interaction with lexical and syntactic rules. The IS_A hierarchy is motivated by
defining its semantics in terms of the real world entities corresponding to the word senses
and demonstrating that default inheritance of attributes in the lexicon correlates with de-
fault reasoning about properties of the entities. Copestake (1990a) outlines a preliminary
attempt to formalise the relationship between this aspect of lexical semantics and world
knowledge.
</bodyText>
<subsectionHeader confidence="0.99837">
2.3 Lexical rules
</subsectionHeader>
<bodyText confidence="0.9383075">
A lexical rule is a feature structure of type lexical-rule. The expanded constraint for the
type is:
</bodyText>
<equation confidence="0.706742333333333">
[lexical_rule
0 = lex_sign
1 = lex_sign
</equation>
<bodyText confidence="0.984952545454545">
thus a 1 lexical rules have to have the features 0 and 1 which must both have values which
are of type lex_sign.
New lexical signs may be generated by unifying a copy of the lexical entry with the
feature structure at the end of the path &lt;1&gt; in a copy of the lexical rule â€” the feature
structure at the end of the path &lt;0&gt; is then the new lexical sign. Lexical rules are indexed
by the type of their &amp;quot;input&amp;quot; and &amp;quot;output&amp;quot; feature structures, so they will only be applied
to entries of the appropriate type and will only create well-typed entries.
A number of productive or quasi-productive phenomena, such as deverbal nominali-
sation, &apos;grinding&apos;, and so forth, can be represented as lexical rules which generate further
lexical entries. A general type for grinding lexical rules could be specified in our system
as follows:
</bodyText>
<equation confidence="0.828276375">
grinding C lexical_rule grinding [ count-noun
1 = ri =
0 = m I
13
acis = ind_obj
[ mass-noun
(arm = II
a.gs = substance
</equation>
<bodyText confidence="0.999135692307692">
The effect of the lexical rule is to transform a count noun with the `relativised qualia
structure&apos; (RQS, Calzolari, 1991) properties appropriate to an individuated physical object
ind_obj into a mass noun with properties appropriate for a substance substance. Thus
the core component of grinding is a linguistic, syntactic operation which affects syntactic
realisation, such as the ability to appear without a determiner, correlated with an abstract
and underspecified semantic operation. We would claim that specific predicational and
syntactic contexts will result in coercion (application of the lexical rule) and that this
much, at least, of the &apos;grinding&apos; family of sense extensions must be seen as a non-default
and essentially linguistic process.
We specialise the grinding rule to allow for cases such as the animal/meat regular
sense extension explicitly. The typed framework provides us with a natural method of
characterising the subparts of the lexicon to which such rules should apply. The lexical
rules can, in effect, be parameterised by inheritance in the type system. As our theory
</bodyText>
<page confidence="0.995228">
9
</page>
<bodyText confidence="0.999712285714286">
of lexical organisation allows us to make fine distinctions between classes of lexemes, in
terms of both syntactic and semantic properties encoded in the type system, we expect
that many processes which have been characterised as partially productive or semantic
specialisations of productive processes will be characterisable as fully productive rules of
sense extension applying to smaller semantically coherent subsets of the lexicon.
For example given the type hierarchy shown in Figure 1 we can give rules which inherit
information from grinding such as animal_grinding:
</bodyText>
<figure confidence="0.947906294117647">
animal_grinding
grinding
1= ILQS =
[animal
Kui aux =
= INS = food_substance
Thus given the lexical entry for &amp;quot;haddock&amp;quot; shown above we can apply the lexical rule to
generate a sense meaning &amp;quot;haddock-flesh&amp;quot; (partially represented as):
_
mass-noun
owl n . haddock
SYNTAX = [LI CON&apos;l =
1
food_substance
INS = [ Ii formula 1
o. u- =
mum = eat
</figure>
<bodyText confidence="0.999612090909091">
(where the specification of the value eat for the telic role arises from the constraint on
the type food...substance, inherited from food, and the type mass-noun arises from
grinding.) It would not be possible to apply this lexical rule to &amp;quot;book&amp;quot; and get a sense
denoting &amp;quot;book-flesh&amp;quot; because &amp;quot;book&amp;quot; has the type inanimate_obj which is incompatible
with animal. It would still be possible to apply the general lexical rule for grinding and
to get a mass use of &amp;quot;book&amp;quot; but the denotation of the mass sense would be underspecified.
We would expect the context to provide a more specific interpretation of the mass sense
in such a (less-conventionalised) case.
Furthermore, our approach provides a natural mechanism for dealing with semantic
specialisation or restriction. We can represent lexicalised items as inheriting information
by default from a psort which is the result of applying an appropriate lexical rule to the
base form. Such items may have specific information associated with them. In cases
where the lexical rule predicts the extended sense exactly, the specific information will
duplicate information already present. If the rule is correct, but incomplete, the specific
information will augment the inherited information. If it is partially incorrect, the more
specific information will override that inherited from the result of lexical rule application.
In an untyped system this representation would not constrain the structures associated
with lexicalised derived forms, since the entire feature structure output by the lexical
rule might be overridden. However default inheritance is constrained by the type system
so that information may only be inherited from a structure of the same or higher type,
and thus this treatment predicts that a derived form can never have a type which is
incompatible with that determined by the lexical rule.
</bodyText>
<page confidence="0.979338">
96
</page>
<bodyText confidence="0.991560514285714">
We can illustrate the manner in which this type of semi-productivity might be dealt
with if we assume that we are attempting to construct a lexicon semi-automatically from a
conventional dictionary (e.g. Copestake, 1990a). If the result of applying a lexical rule to a
sense is notated as sense+rule-name (eg lamb_l+animaLgrinding) then the representation
of the sense lamb (2) (&amp;quot;the meat&amp;quot;, from the Longman Dictionary of Contemporary English
LDOCE) might be:
lamb 2 &lt; lamb_ 1+ an imal _gr ind ing
In this case no extra information need be added. In contrast the entry for lamb (3) (&amp;quot;a
young gentle person&amp;quot; LDOCE) might augment the information inherited from the lexical
rule:
lamb 3 &lt; lamb_l+animal_metaphor
&lt; rqs : age &gt; = low.
In the case of &amp;quot;haddock&amp;quot;, where no LDOCE entry is found, the structure derived from
the lexical rule alone would be used.
We can regard morphological rules as a particular type of lexical rule where the or-
thography of the output is not equal to that of the input (we assume that the regular
spelling changes involved in affixation will be dealt with by a separate system, e.g. Cahill,
1990). In this case we could represent irregular forms as having an orthographic form
which overrides that produced by rule application. In principle, multiple lexical rules may
be applied in sequence. For example the resultative senses of &amp;quot;replacement&amp;quot; and &amp;quot;pur-
chase&amp;quot; mentioned in the introduction would be the result of applying a metonymic sense
extension rule to the result of the nominalisation process. All outputs of lexical rules must
be potentially valid lexical entries. In the case of conversion or zero-derivational processes
we wish to restrict the set of lexical rules so that application may not be circular â€” that is
if there is a lexical rule which could generate the set of feature structures F2 from the set
Fl, no other lexical rule or sequence of lexical rules may be specified which could generate
any member of Fl, or a feature structure subsuming any member of Fl, starting from
any member of the set F2, since lexical rule application would not then terminate. (We
can check for such potential circularities relatively efficiently by looking at the type of the
feature structure that a lexical rule generates rather than the entire feature structure.)
However, this condition is overrestrictive in general because some types of derivational
rule can apply to their own output iteratively (&amp;quot;meta-meta-theory&amp;quot;, &amp;quot;anti-anti-missile&amp;quot;,
&amp;quot;great-great-grandmother&amp;quot;, &amp;quot;re-re-program&amp;quot;). This observation suggests that we need
to distinguish types of lexical rule, such as at least derivational rules and processes of
conversion, and associate slightly different constraints with them.
</bodyText>
<sectionHeader confidence="0.984512" genericHeader="method">
3 Grinding
</sectionHeader>
<bodyText confidence="0.99868">
In this section we justify our treatment of grinding as a lexical rule and show why relatively
complex semantic information is needed to adequately account for this sense extension..
The first point to consider is that grinding processes appear to be genuinely productive.
Thus we find:
Badger hams are a delicacy in China while mole is eaten in many parts of
Africa.
</bodyText>
<page confidence="0.999035">
97
</page>
<bodyText confidence="0.998526045454545">
in the Lancaster-Bergen/Oslo (LOB) corpus. We therefore cannot assume that the ground
senses are necessarily lexicalised, even in the relatively conventionalised uses to mean meat,
fur etc.
One approach which allows for this productivity is to treat all nouns as being initially
underspecified with respect to the count/mass distinction. Thus it is possible to produce
a grammar where nouns are initially undefined with respect to a syntactic count feature
and where lamb&apos; is, in effect, taken as denoting both animals and meat and so on (see
the &amp;quot;p-theory&amp;quot; in Pelletier and Schubert 1986 and also Copestake 1990b). In contexts
where one interpretation is forced (&amp;quot;a piece of lamb&amp;quot; vs &amp;quot;two lambs&amp;quot;) the predicate can
be restricted to denote either count or the mass senses (in this case either the animal
or the meat senses). However this seems to predict that NPs such as &amp;quot;the lamb&amp;quot; are
vague rather than ambiguous between count and mass readings. Thus the peculiarity of
sentences such as:
? John fed and carved the lamb.
is not accounted for (see also the introduction). It is perhaps significant that in most
dictionaries the mass sense is specified as well as a count sense for the conventionalised
grinding examples we have been considering. Lexicographers are sometimes aware of
the regularity of the extension (Atkins 1990) but have no way of representing this in a
conventional dictionary. We thus regard a noun like &amp;quot;lamb&amp;quot; as ambiguous between mass
and count senses rather than vague, and the mass (meat) sense as an extension of the
count (animal) sense, specified by lexical rule. (There are cases where it is reasonable to
claim that a nominal should be underspecified with respect to the count/mass distinction;
it is frequently unclear whether individuation is occurring with nouns like &amp;quot;data&amp;quot;, however
in the grinding examples there is a clear change in meaning.)
Our current treatment thus has similarities to the &amp;quot;s-theory&amp;quot; of Pelletier and Schu-
bert (1986) where &amp;quot;lexical extension rules&amp;quot; are used to produce mass nouns from count
nouns. However these rules merely change the value of the syntactic count feature, apply
a predicate operator which is the same for all cases of grinding, and mark the mass sense
resulting as &amp;quot;-t-EXT&amp;quot; which is supposed to suggest that it is in some way abnormal. This
is clearly inadequate:
John carved the lamb.
would be marked &amp;quot;-1-EXT&amp;quot; for the reading where lamb was used in a mass sense and not
for the count sense reading. By having an inheritance ordering on lexical rules we can
express the conventionalised processes that apply to semantically specified parts of the
lexicon and account for the possibility of multiple distinct mass senses being possible; for
example &amp;quot;rabbit&amp;quot; is given distinct senses in LDOCE for the meat and the fur, and (in
context) an underspecified sense is available:
After several lorries had run over the body, there was rabbit splattered all over
the road.
Although the denotation of the count sense and the mass sense are distinct there
clearly is some relationship between them. A full account of sense extension must be able
to represent relationships between the senses&apos; denotations. For grinding in general the
most specific claim that can apparently be made is that the ground sense denotes some
&amp;quot;stuff&amp;quot; which was at some past time part of one or more individuals denoted by the count
</bodyText>
<page confidence="0.988215">
98
</page>
<bodyText confidence="0.980761808510639">
sense. (We can formally specify this relationship between the ground sense G and the
base sense B as
Vx, t[G(x, t) 3y, t1[* B(y,e) At&apos; &lt;t A x Co
using the formalisation developed in Copestake (1990a) following Krifka (1987) where
nominal predicates are taken as being true of quantities of matter at some time index,
where *B denotes a potentially plural entity, and where Co represents a relationship of
material constituency. In the lexicon we actually use a feature ORIGIN which can be taken
as an abbreviation for the relationship specified above.)
A good theory of sense extension should give some treatment of blocking, which ap-
pears to occur with some cases of regular sense extension in a way that seems similar to
derivational morphology. For example the use of &amp;quot;pig&amp;quot; to denote the meat seems to be
blocked by the existence of &amp;quot;pork&amp;quot; â€” &amp;quot;pig&amp;quot; can be used in the extended sense but such
a use is marked, suggesting for example that the meat is distinctly inferior. To account
for this we need to be able to recognise that &amp;quot;pork&amp;quot; is equivalent to the sense obtained
from &amp;quot;pig&amp;quot; using the lexical rule. Although there are many problems with this (what
do we mean by equivalence, why does this apparently not apply to metaphorical sense
extension) in order to do it at all we clearly need a rich representation which indicates
information such as &amp;quot;origin&amp;quot;.
Bauer (1983) distinguishes two types of non-productivity (which he refers to as estab-
lished senses) â€“ lexicalisation and institutionalisation. Lexicalisation is defined as irregular
and unpredictable modification of some or all of the semantic, syntactic or phonological
properties of a derived form. Institutionalisation, by contrast, involves restriction, rather
than modification along one of these dimensions; thus &amp;quot;telephone box&amp;quot; is institutionalised
to mean telephone kiosk unambiguously, although the liberal rules of noun compounding
predict other possibilities. In our approach, we can treat institutionalisation as a form of
blocking in which forms such as &amp;quot;telephone box&amp;quot; would have separate entries equivalent to
one productive meaning predicted by a putative lexical rule of compounding. This would
predict a strong preference for this interpretation (except in a marked context). Bauer
(1983:58) points out that some treatment along these lines will be required since the other
meanings are not completely ruled out, and therefore simply listing them as independent
entries will be inadequate. The more specific rules of grinding (as opposed to the most
general rule) are instances of productive institutionalisation within sub-classes in that the
specific interpretations they introduce can be overridden in marked contexts.
Similarly, lexicalisation is usually a partial process which affects one aspect of a derived
lexical entry, whilst the rest remains productive. Bauer gives the example of &amp;quot;disbelieve&amp;quot;
which can be productively derived through a lexical rule which prefixes &amp;quot;dis+&amp;quot; to the
verb &amp;quot;believe&amp;quot; with a predictable change of meaning, except that &amp;quot;disbelieve&amp;quot; does not
inherit the syntactic properties of &amp;quot;believe&amp;quot; because it cannot take sentential or infinitival
complements. The productive aspects of the relation between the two verbs can be ex-
pressed by a lexical rule for &amp;quot;dis+&amp;quot; prefixation, whilst the non-productive aspects can be
captured naturally in this framework by positing an independent entry for &amp;quot;disbelieve&amp;quot;
which overrides some of the information provided by the lexical rule.
We think of lexical rules as defining the limits of coercion amongst lexemes and argue
that lexical rule application, or selection of the derived entry (which is equivalent in many
cases), will be forced when the type of the basic entry is incompatible with the syntactic or
predicational context in which the lexeme occurs. Consider the following example, taken
from the Lancaster-Bergen/Oslo (LOB) corpus:
</bodyText>
<page confidence="0.994886">
99
</page>
<bodyText confidence="0.999928333333333">
More than 1,000 union men and their families arrived to play bowls, eat bar-
becued chicken and row on his fish-infested lake.
The application of a grinding lexical rule is triggered by a combination of syntactic and
semantic effects arising from the context (for example the predicate &amp;quot;eat&amp;quot; takes an object
denoting food in preference to an animal, the bare NP &amp;quot;mole&amp;quot; in the earlier example
must have a negative value for the syntactic feature count). By default, the most spe-
cific lexical rule applicable will be used, in this case &amp;quot;animal_grinding&amp;quot; as opposed to
the general grinding rule and so the interpretation of &amp;quot;chicken&amp;quot; as &amp;quot;chicken-flesh&amp;quot; and
&amp;quot;mole&amp;quot; as &amp;quot;mole-flesh&amp;quot; is possible, by default. More open-ended (non-lexical) reasoning
might cause the default interpretation of the mass sense to be overridden in some marked
informationally-rich contexts. For example:
John bit into the lamb.
It kicked and struggled.
We assume a similar account of the overriding of default interpretations with these types
of example as we offered in the case of logical metonymies (Briscoe et al., 1990).
</bodyText>
<sectionHeader confidence="0.99969" genericHeader="conclusions">
4 Conclusion
</sectionHeader>
<bodyText confidence="0.999992636363636">
We have argued that our notion of lexical rule can capture the productive linguistic
element of derivational morphological processes and metonymic and metaphorical sense
extensions. In order to do this adequately we need rich lexical semantic information but
we do not need to resort to general deductive or abductive inference on unconstrained
world knowledge. By using semantic information to structure the lexicon, by means of
types and inheritance, we can represent relationships between lexical rules and view them
as essentially fully productive over defined subparts of the lexicon, while providing an
initial account of blocking and lexicalisation. However the work described here is at a
preliminary stage. We need to provide detailed accounts of a range of derivation and
conversion processes to see how adequately we can represent them as lexical rules, while
structuring the lexicon and type system appropriately to constrain their operation.
</bodyText>
<sectionHeader confidence="0.995756" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9997835">
This work was supported by Esprit BRA-3030, ACQUILEX &apos;The Acquisition of lexical
knowledge for Natural Language Processing systems&apos;.
</bodyText>
<sectionHeader confidence="0.999173" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99051775">
Atkins B(1990) Lexical Rules: a starter pack, Ms. OUP
Bauer L(1983) English Word-formation, CUP
Briscoe E J, Copestake A A and Boguraev B K(1990) &apos;Enjoy the paper: Lexical semantics
via lexicology&apos;, Proceedings of the 13th Coling, Helsinki, pp.42-47
Cahill L(1990) &apos;Syllable based morphology&apos;, Proceedings of the 13th Coling, Helsinki,
pp.48-54
Calzolari N(1991) Representation of semantic information in a lexical knowledge base,
ACQUILEX WP no ??, 1st ACQUILEX workshop, Cambridge
</reference>
<page confidence="0.872206">
100
</page>
<reference confidence="0.99576440625">
Carpenter R(1990) &apos;Typed feature structures: Inheritance, (In)equality and Extensional-
ity&apos;, Proceedings of the Inheritance in Natural Language Processing, Tilburg, pp.9-18
Copestake A A(1990a) An approach to building the hierarchical element of a lexical knowl-
edge base from a machine readable dictionary, Workshop on Inheritance in NLP,
Tilburg
Copestake, A.A.(1990b) Some notes on Mass Terms and Plurals, Technical Report 190,
Computer Laboratory, University of Cambridge
Copestake A A, de Paiva V C V, Sanfilippo A and Briscoe E J(1991) Functionality of the
LAT, Ms. Computer Laboratory, University of Cambridge
Flickinger D(1987) Lexical rules in the hierarchical lexicon, PhD dissertation, Stanford
University
Hobbs J, Croft W, Davies T, Edwards D and Law K(1987) &apos;Commonsense metaphysics
and lexical semantics&apos;, Computational Linguistics, vol.13, 241-250
Krifka, M.(1987) &apos;Nominal Reference and Temporal Constitution: Towards a Semantics of
Quantity&apos;, Proceedings of the 6th Amsterdam Colloquium, University of Amsterdam,
pp.153-173
Partee B and Rooth M(1983) &apos;Generalized Conjunction and Type Ambiguity&apos; in Bauerle
R, Schwarze C and von Stechow A (eds.), Meaning, Use and Interpretation of Lan-
guage, de Gruyter, pp.361-368
Pelletier, F.J., and Schubert, L. K.(1986, forthcoming) &apos;Mass Expressions.&apos; in Gabbay
and Guenthner (eds.), Handbook of Philosophical Logic, Vol 4, Reidel, Dordrecht
Pustejovsky J(1989a) The Generative Lexicon, Ms. Brandeis University
Pustejovsky J(1989b) &apos;Current issues in computational lexical semantics&apos;, Proceedings of
the 4th European ACL, Manchester, pp.xviiâ€”xxv
Pustejovsky J(1989c) &apos;Type coercion and selection&apos;, Proceedings of the West Coast Con-
ference on Formal Linguistics, Vancouver
Shieber S(1986) An Introduction to Unification-based Approaches to Grammar, University
of Chicago Press, Chicago
Touretzky D F(1986) The mathematics of inheritance systems, Morgan Kaufmann, Los
Altos
Zwicky A M and Sadock J M(1975) &apos;Ambiguity tests and how to fail them&apos; in Kimball J
P (eds.), Syntax and Semantics IV, Academic Press, New York, pp.1-36
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.894703">
<title confidence="0.999822">Lexical Operations in a Unification-based Framework</title>
<author confidence="0.999367">Ann Copestake</author>
<author confidence="0.999367">Ted Briscoe</author>
<affiliation confidence="0.974756">Computer Laboratory, University of Cambridge, Pembroke</affiliation>
<address confidence="0.998654">Cambridge, CBe VG, UK</address>
<email confidence="0.970395">aac@cl.cam.ac.ukejb@cl.cam.ac.uk</email>
<abstract confidence="0.991239666666667">We consider lexical operations and their representation in a unification based lexicon and the role of lexical semantic information. We describe a unified treatment of the linguistic aspects of sense extension and derivational morphological processes which delimit the range of possible coercions between lexemes and give a preliminary account of how default interpretations may arise.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Atkins B(1990) Lexical Rules: a starter pack, Ms.</title>
<booktitle>OUP Bauer L(1983) English Word-formation, CUP</booktitle>
<marker></marker>
<rawString>Atkins B(1990) Lexical Rules: a starter pack, Ms. OUP Bauer L(1983) English Word-formation, CUP</rawString>
</citation>
<citation valid="false">
<authors>
<author>E J Briscoe</author>
</authors>
<title>Copestake A A and Boguraev B K(1990) &apos;Enjoy the paper: Lexical semantics via lexicology&apos;,</title>
<booktitle>Proceedings of the 13th Coling,</booktitle>
<pages>42--47</pages>
<location>Helsinki,</location>
<marker>Briscoe, </marker>
<rawString>Briscoe E J, Copestake A A and Boguraev B K(1990) &apos;Enjoy the paper: Lexical semantics via lexicology&apos;, Proceedings of the 13th Coling, Helsinki, pp.42-47</rawString>
</citation>
<citation valid="false">
<title>Cahill L(1990) &apos;Syllable based morphology&apos;,</title>
<booktitle>Proceedings of the 13th Coling,</booktitle>
<pages>48--54</pages>
<location>Helsinki,</location>
<marker></marker>
<rawString>Cahill L(1990) &apos;Syllable based morphology&apos;, Proceedings of the 13th Coling, Helsinki, pp.48-54</rawString>
</citation>
<citation valid="false">
<title>Calzolari N(1991) Representation of semantic information in a lexical knowledge base,</title>
<booktitle>ACQUILEX WP no ??, 1st ACQUILEX workshop,</booktitle>
<location>Cambridge</location>
<marker></marker>
<rawString>Calzolari N(1991) Representation of semantic information in a lexical knowledge base, ACQUILEX WP no ??, 1st ACQUILEX workshop, Cambridge</rawString>
</citation>
<citation valid="false">
<title>Carpenter R(1990) &apos;Typed feature structures: Inheritance, (In)equality and Extensionality&apos;,</title>
<booktitle>Proceedings of the Inheritance in Natural Language Processing,</booktitle>
<pages>9--18</pages>
<location>Tilburg,</location>
<marker></marker>
<rawString>Carpenter R(1990) &apos;Typed feature structures: Inheritance, (In)equality and Extensionality&apos;, Proceedings of the Inheritance in Natural Language Processing, Tilburg, pp.9-18</rawString>
</citation>
<citation valid="false">
<title>Copestake A A(1990a) An approach to building the hierarchical element of a lexical knowledge base from a machine readable dictionary,</title>
<booktitle>Workshop on Inheritance in NLP,</booktitle>
<location>Tilburg</location>
<marker></marker>
<rawString>Copestake A A(1990a) An approach to building the hierarchical element of a lexical knowledge base from a machine readable dictionary, Workshop on Inheritance in NLP, Tilburg</rawString>
</citation>
<citation valid="true">
<authors>
<author>Copestake</author>
</authors>
<title>Some notes on Mass Terms and Plurals,</title>
<date>1990</date>
<tech>Technical Report 190,</tech>
<institution>Computer Laboratory, University of Cambridge</institution>
<contexts>
<context position="18923" citStr="Copestake, 1990" startWordPosition="2911" endWordPosition="2912">rt; a feature structure from which another feature structure inherits information, by default. The hierarchical ordering on psorts (which must be consistent with the type hierarchy) provides an order on defaults. Default inheritance is implemented by a version of default unification. Only orthogonal multiple inheritance (Touretzky 1986) is allowed; information inherited from multiple parents must not be contradictory. (A default inheritance hierarchy which connects semantic parts of lexical entries can be derived semi-automatically from taxonomies extracted from conventional dictionaries, see Copestake, 1990a). We refer to this particular case of the psort hierarchy as an IS_A hierarchy. Values of features can be associated either manually or semi-automatically with psorts in the IS_A hierarchy; the more specific word senses then inherit them, by default. (Defaults may also be useful in the representation of syntactic information in the lexicon (e.g. Flickinger, 1987).) Since the type system constrains the psort system it also constrains multiple default inheritance. If the value of the FOOD-TEMPERATURE feature for &amp;quot;drink 2 (1)&amp;quot; is low then this information would be inherited by the entry for &amp;quot;be</context>
<context position="20384" citStr="Copestake (1990" startWordPosition="3144" endWordPosition="3145">EMPERATURE can be specified to be high rather than low. 1 The actual type system being employed is considerably more complex, since only the relevant features are being shown in these examples. 94 Types and features thus provide an organisation on the information which is necessary for interaction with lexical and syntactic rules. The IS_A hierarchy is motivated by defining its semantics in terms of the real world entities corresponding to the word senses and demonstrating that default inheritance of attributes in the lexicon correlates with default reasoning about properties of the entities. Copestake (1990a) outlines a preliminary attempt to formalise the relationship between this aspect of lexical semantics and world knowledge. 2.3 Lexical rules A lexical rule is a feature structure of type lexical-rule. The expanded constraint for the type is: [lexical_rule 0 = lex_sign 1 = lex_sign thus a 1 lexical rules have to have the features 0 and 1 which must both have values which are of type lex_sign. New lexical signs may be generated by unifying a copy of the lexical entry with the feature structure at the end of the path &lt;1&gt; in a copy of the lexical rule â€” the feature structure at the end of the p</context>
<context position="25712" citStr="Copestake, 1990" startWordPosition="4002" endWordPosition="4003">alised derived forms, since the entire feature structure output by the lexical rule might be overridden. However default inheritance is constrained by the type system so that information may only be inherited from a structure of the same or higher type, and thus this treatment predicts that a derived form can never have a type which is incompatible with that determined by the lexical rule. 96 We can illustrate the manner in which this type of semi-productivity might be dealt with if we assume that we are attempting to construct a lexicon semi-automatically from a conventional dictionary (e.g. Copestake, 1990a). If the result of applying a lexical rule to a sense is notated as sense+rule-name (eg lamb_l+animaLgrinding) then the representation of the sense lamb (2) (&amp;quot;the meat&amp;quot;, from the Longman Dictionary of Contemporary English LDOCE) might be: lamb 2 &lt; lamb_ 1+ an imal _gr ind ing In this case no extra information need be added. In contrast the entry for lamb (3) (&amp;quot;a young gentle person&amp;quot; LDOCE) might augment the information inherited from the lexical rule: lamb 3 &lt; lamb_l+animal_metaphor &lt; rqs : age &gt; = low. In the case of &amp;quot;haddock&amp;quot;, where no LDOCE entry is found, the structure derived from the l</context>
<context position="29200" citStr="Copestake 1990" startWordPosition="4567" endWordPosition="4568">7 in the Lancaster-Bergen/Oslo (LOB) corpus. We therefore cannot assume that the ground senses are necessarily lexicalised, even in the relatively conventionalised uses to mean meat, fur etc. One approach which allows for this productivity is to treat all nouns as being initially underspecified with respect to the count/mass distinction. Thus it is possible to produce a grammar where nouns are initially undefined with respect to a syntactic count feature and where lamb&apos; is, in effect, taken as denoting both animals and meat and so on (see the &amp;quot;p-theory&amp;quot; in Pelletier and Schubert 1986 and also Copestake 1990b). In contexts where one interpretation is forced (&amp;quot;a piece of lamb&amp;quot; vs &amp;quot;two lambs&amp;quot;) the predicate can be restricted to denote either count or the mass senses (in this case either the animal or the meat senses). However this seems to predict that NPs such as &amp;quot;the lamb&amp;quot; are vague rather than ambiguous between count and mass readings. Thus the peculiarity of sentences such as: ? John fed and carved the lamb. is not accounted for (see also the introduction). It is perhaps significant that in most dictionaries the mass sense is specified as well as a count sense for the conventionalised grinding </context>
<context position="32161" citStr="Copestake (1990" startWordPosition="5064" endWordPosition="5065">tion of the count sense and the mass sense are distinct there clearly is some relationship between them. A full account of sense extension must be able to represent relationships between the senses&apos; denotations. For grinding in general the most specific claim that can apparently be made is that the ground sense denotes some &amp;quot;stuff&amp;quot; which was at some past time part of one or more individuals denoted by the count 98 sense. (We can formally specify this relationship between the ground sense G and the base sense B as Vx, t[G(x, t) 3y, t1[* B(y,e) At&apos; &lt;t A x Co using the formalisation developed in Copestake (1990a) following Krifka (1987) where nominal predicates are taken as being true of quantities of matter at some time index, where *B denotes a potentially plural entity, and where Co represents a relationship of material constituency. In the lexicon we actually use a feature ORIGIN which can be taken as an abbreviation for the relationship specified above.) A good theory of sense extension should give some treatment of blocking, which appears to occur with some cases of regular sense extension in a way that seems similar to derivational morphology. For example the use of &amp;quot;pig&amp;quot; to denote the meat s</context>
</contexts>
<marker>Copestake, 1990</marker>
<rawString>Copestake, A.A.(1990b) Some notes on Mass Terms and Plurals, Technical Report 190, Computer Laboratory, University of Cambridge</rawString>
</citation>
<citation valid="false">
<authors>
<author>A A Copestake</author>
<author>V C V de Paiva</author>
</authors>
<booktitle>Sanfilippo A and Briscoe E J(1991) Functionality of the LAT,</booktitle>
<institution>Ms. Computer Laboratory, University of Cambridge</institution>
<marker>Copestake, de Paiva, </marker>
<rawString>Copestake A A, de Paiva V C V, Sanfilippo A and Briscoe E J(1991) Functionality of the LAT, Ms. Computer Laboratory, University of Cambridge</rawString>
</citation>
<citation valid="false">
<title>Flickinger D(1987) Lexical rules in the hierarchical lexicon,</title>
<institution>Stanford University</institution>
<note>PhD dissertation,</note>
<marker></marker>
<rawString>Flickinger D(1987) Lexical rules in the hierarchical lexicon, PhD dissertation, Stanford University</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Hobbs</author>
<author>W Croft</author>
<author>T Davies</author>
<author>D Edwards</author>
</authors>
<title>and Law K(1987) &apos;Commonsense metaphysics and lexical semantics&apos;,</title>
<journal>Computational Linguistics,</journal>
<volume>13</volume>
<pages>241--250</pages>
<marker>Hobbs, Croft, Davies, Edwards, </marker>
<rawString>Hobbs J, Croft W, Davies T, Edwards D and Law K(1987) &apos;Commonsense metaphysics and lexical semantics&apos;, Computational Linguistics, vol.13, 241-250</rawString>
</citation>
<citation valid="false">
<authors>
<author>M Krifka</author>
</authors>
<title>Nominal Reference and Temporal Constitution: Towards a Semantics of Quantity&apos;,</title>
<booktitle>Proceedings of the 6th</booktitle>
<pages>153--173</pages>
<institution>Amsterdam Colloquium, University of Amsterdam,</institution>
<marker>Krifka, </marker>
<rawString>Krifka, M.(1987) &apos;Nominal Reference and Temporal Constitution: Towards a Semantics of Quantity&apos;, Proceedings of the 6th Amsterdam Colloquium, University of Amsterdam, pp.153-173</rawString>
</citation>
<citation valid="false">
<authors>
<author>B Partee</author>
</authors>
<title>and Rooth M(1983) &apos;Generalized Conjunction and Type Ambiguity&apos;</title>
<booktitle>in Bauerle R, Schwarze C and von Stechow A (eds.), Meaning, Use and Interpretation of Language, de Gruyter,</booktitle>
<pages>361--368</pages>
<marker>Partee, </marker>
<rawString>Partee B and Rooth M(1983) &apos;Generalized Conjunction and Type Ambiguity&apos; in Bauerle R, Schwarze C and von Stechow A (eds.), Meaning, Use and Interpretation of Language, de Gruyter, pp.361-368</rawString>
</citation>
<citation valid="false">
<authors>
<author>F J Pelletier</author>
<author>L Schubert</author>
</authors>
<title>K.(1986, forthcoming) &apos;Mass Expressions.&apos;</title>
<booktitle>in Gabbay and Guenthner (eds.), Handbook of Philosophical Logic, Vol 4, Reidel, Dordrecht Pustejovsky J(1989a) The Generative Lexicon,</booktitle>
<publisher>Brandeis University</publisher>
<location>Ms.</location>
<marker>Pelletier, Schubert, </marker>
<rawString>Pelletier, F.J., and Schubert, L. K.(1986, forthcoming) &apos;Mass Expressions.&apos; in Gabbay and Guenthner (eds.), Handbook of Philosophical Logic, Vol 4, Reidel, Dordrecht Pustejovsky J(1989a) The Generative Lexicon, Ms. Brandeis University</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>Current issues in computational lexical semantics&apos;,</title>
<booktitle>Proceedings of the 4th European ACL,</booktitle>
<location>Manchester, pp.xviiâ€”xxv</location>
<marker>Pustejovsky, </marker>
<rawString>Pustejovsky J(1989b) &apos;Current issues in computational lexical semantics&apos;, Proceedings of the 4th European ACL, Manchester, pp.xviiâ€”xxv</rawString>
</citation>
<citation valid="false">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>Type coercion and selection&apos;,</title>
<booktitle>Proceedings of the West Coast Conference on Formal Linguistics,</booktitle>
<location>Vancouver</location>
<marker>Pustejovsky, </marker>
<rawString>Pustejovsky J(1989c) &apos;Type coercion and selection&apos;, Proceedings of the West Coast Conference on Formal Linguistics, Vancouver</rawString>
</citation>
<citation valid="false">
<title>Shieber S(1986) An Introduction to Unification-based Approaches to Grammar,</title>
<publisher>University of Chicago Press,</publisher>
<location>Chicago</location>
<marker></marker>
<rawString>Shieber S(1986) An Introduction to Unification-based Approaches to Grammar, University of Chicago Press, Chicago</rawString>
</citation>
<citation valid="false">
<authors>
<author>D Touretzky</author>
</authors>
<title>F(1986) The mathematics of inheritance systems,</title>
<publisher>Morgan Kaufmann,</publisher>
<location>Los Altos</location>
<marker>Touretzky, </marker>
<rawString>Touretzky D F(1986) The mathematics of inheritance systems, Morgan Kaufmann, Los Altos</rawString>
</citation>
<citation valid="false">
<title>Zwicky A M and Sadock J M(1975) &apos;Ambiguity tests and how to fail them&apos;</title>
<booktitle>Syntax and Semantics IV,</booktitle>
<pages>1--36</pages>
<editor>in Kimball J P (eds.),</editor>
<publisher>Academic Press,</publisher>
<location>New York,</location>
<marker></marker>
<rawString>Zwicky A M and Sadock J M(1975) &apos;Ambiguity tests and how to fail them&apos; in Kimball J P (eds.), Syntax and Semantics IV, Academic Press, New York, pp.1-36</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>