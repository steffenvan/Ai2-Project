<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.734094">
A Finite-State Parser for Use in Speech Recognition
</title>
<note confidence="0.6649545">
Kenneth W. Church
NE43-307
</note>
<bodyText confidence="0.944449">
Massachusetts Institute of Technology
Cambridge, MA. 02139
This paper is divided into two parts.1 The first section motivates
the application of finite-state parsing techniques at the phonetic level in
order to exploit certain classes of contextual constraints. -In the second
section, the parsing framework is extended in order to account for
&apos;feature spreading&apos; (e.g., agreement and co-articulation) in a natural
way.
</bodyText>
<listItem confidence="0.980184">
1. Parsing at the Phonetic Level
</listItem>
<bodyText confidence="0.999488846153846">
It is well known that phonemes have different acoustic/phonetic
realizations depending on the context. For example, the phoneme A/
is typically realized with a different allophone (phonetic variant) in
syllable initial position than in syllabic final position. In syllable initial
position (e.g., Tom), It/ is almost always released (with a strong burst of
energy) and aspirated (with h-like noise), whereas in syllable final
position (e.g., cal), /t/ is often unreleased and unaspirated. It is
common practice in speech research to distinguish acoustic/phonetic
properties that vary a great deal with context (e.g., release and
aspiration) from those that are relatively invariant to context (e.g.,
place, manner and voicing).2 In the past, the emphasis has been on
invariants; allophonic variation is traditionally seen as problematic for
recognition.
</bodyText>
<listItem confidence="0.932988">
(1) &amp;quot;In most systems for sentence recognition, such modifications
</listItem>
<bodyText confidence="0.950576432432433">
must be viewed as a kind of &apos;noise&apos; that makes it more difficult
to hypothesize lexical candidates given an input phonetic
transcription. To see that this must be the case, we note that
each phonological rule [in an example to be presented below]
I. This research was supported (in part) by the National 1nstitutes of Ilealth Grant No. I
POI 1M 03374-01 and 03374-02 from the National Library of Medicine.
2. Place refers to the location of the constriction in the vocal tract. fIxamples include:
labial (at the lips) /p, b. f, v. m/. velar /k. g, r1/. dental (at the teeth) /5, r„ t. d, 1, n/ and
palatal rs, 2, tri/ Manner distinguishes among vowels, liquids and glides (e.g., /1, r, y,
w/L fricatives (e.g., /,,z, f, v/), nasals (e.g., In. m. no and stops /p, t, k, b. d, g/).
Voicing (periodic vibration of the vocal fold.$) distinguishes sounds like lb, d, g/ from
sounds like /p, t, kJ.
results in irreversible ambiguity — the phonological rule does
not have a unique inverse that could be used to recover the
underlying phonemic representation for a lexical item. For
example, ... schwa vowels could be the first vowel in is word like
&apos;about&apos; or the surface realization of almost any English vowel
appearing in a sufficiently &amp;stressed word. The tongue flap [C1
could have come from a /t/ or a /d/.&amp;quot; Klatt (Nun
[21, pp. 548-5491
This view of allophonic variation is representative of much of the
speech recognition literature, especially during the ARPA speech
project. One can find similar statements by Cole and ,Jakirnik (CM U)
[5] and by Jelinek (IBM) [171.
I prefer to think of variation as useful. It is well known that allo-
phonic contrasts can be distinctive, as illustrated by the following
famous minimal pairs where the crucial distinctions seem to lie in the
allophonic realization of the /t/:
a tease / at ease aspirated / flapped
night rate / nitrate unreleased / retroflexed
great wine / gray twine unreleased / rounded
This evidence suggests that allophonic variation provides a rich source
of constraints on syllable structure and word stress. The recognizer to
be discussed here (and partly implemented in Church (41) is designed to
exploit allophonic and phonotactic cues by parsing the input utterance
into syllables and other suprasegmental constituents using phrase-
structure parsing techniques.
</bodyText>
<subsectionHeader confidence="0.989576">
1.1 An Example of Lexical Retrieval
</subsectionHeader>
<bodyText confidence="0.9988115">
It might be helpful to work out an example in order to illustrate
how parsing can play a role in lexical retrieval. Consider the phonetic
transcription, mentioned above in the citation from Klatt [20, p. 1346]
[21, pp. 548-5491:
</bodyText>
<page confidence="0.995186">
91
</page>
<listItem confidence="0.577617333333333">
(3) [d1lahl[11.1 taml
It is desired to decode (3) into the string of words:
(4) Did you hit it to Tom?
</listItem>
<bodyText confidence="0.9874488">
In practice, the lexical retrieval problem is complicated by errors in the
front end. However, even with an ideal error-free front-end, it is
difficult to decode (3) because, among other things, there arc extensive
rule-governed changes affecting the way that words arc pronounced in
different sentence contexts, as Klan&apos;s example illustrates:
</bodyText>
<listItem confidence="0.9686012">
(5a) Palatalization of /d/ before /y/ in did you
(5b Reduction of unstressed /u/ to schwa in nu
(5c) Flapping of intervocalic /t/ in hit it
(5d) Reduction of schwa and devoicing of /u/ in IQ
(5e) Reduction of geminate /t/ in it Lo
</listItem>
<bodyText confidence="0.9930424">
These allophonic processes often appear to neutralize phonemic
distinctions. For example, the voicing contrast between /t] and /d/,
which is usually distinctive, is almost completely lost in writer/rider,
where both /t/ and /d/ are realized in American English with a tongue
flap (CI.
</bodyText>
<subsectionHeader confidence="0.998263">
1.2 An Optimistic View of Neutralization
</subsectionHeader>
<bodyText confidence="0.997574">
Fortunately, there are many fewer cases of true neutralization
than it might seem. Even in writer! rider, the voicing contrast is not
completely lost. The vowel in rider tends to be longer than the vowel in
writer due to a general process that lengthens vowels before voiced
consonants (e.g., /d/) and shortens them before unvoiced consonants
(e.g., /t/).
A similar lengthening argument can be used to separate /n/ and
Ind/ (at least in some cases). It might be suggested that /0/ is merged
with /nd/ by a Id/ deletion rule that applies in words like mend wind
(noun). wind ( .erb), and find. (Admittedly there is little if any direct
acoustic evidence for a /d/ segment in this environment.) However, I
suspect that these words can often be distinguished from men, win,
wow, and fine mostly on the basis of the duration of the nasal murmur
which is lengthened in the precedence of a voiced obstruent like /d/.
Thus, this Id/-deletion process is probably not a true case of
neutralization.
Recent studies in acoustic/phonetics seem to indicate that more
and more cases of apparent neutralization can be separated as the field
progresses. For instance, it has been said that /s/ merges with /V in a
context like gas shortage [121. However, a recent experiment 1271
suggests that the /sS/ sequence can he distinguished from in/ las in
fish shortage) on the basis of a spectral tilt: the /sS/ &apos;spectrum is more
Is/-like in the beginning and more /V-like at the end, whereas the /W
spectrum is relatively constant throughout. A similar spectral tilt
argument can be used to separate other cases of apparent gemination
(e.g., /zg/ in is the).
As a final example of apparent neutralization, consider the
portion of the spectrogram in Figure 1 between 0.85 and 1.1 seconds.
This corresponds to The two adjacent /t/s in Did you hit if o Tom?
Klatt analyzed this region with a single geminated /t/. However, upon
further investigation of the spectrum. I believe that there are acoustic
cues for two segments. Note especially the total energy, which displays
two peaks at 0.95 and 1.02 seconds. On the basis of this evidence, I will
replace Klaus transcription (6a) with (6b):
</bodyText>
<equation confidence="0.493722">
(6a) tdIjahICIti tam]
(6b) [dIjah ICI t titan)]
</equation>
<subsectionHeader confidence="0.986292">
1.3 Parsing and Matching
</subsectionHeader>
<bodyText confidence="0.999713333333333">
Even though I might be able to re-interpret many cases of
apparent neutralization, it remains extremely difficult to &amp;quot;undo&amp;quot; the
allophonic rules by inverse transformational parsing techniques. Let
me suggest an alternative proposal. I will treat syllable structure as an
intermediate level of representation between the input segment lattice
and the output word lattice. In so doing, I have replaced the lexical
retrieval problem with two (hopefully simpler) problems: (a) parse the
segment lattice into syllable structure, and (b) match the resulting
constituents against the lexicon. I will illustrate the approach with
</bodyText>
<figureCaption confidence="0.956321">
Fig. I. 1)id you lilt it to Tom? 7&apos;.. (.....nd.)
</figureCaption>
<figure confidence="0.945450642857143">
a 0.9 1.0 1.1 13 1.3 1.• 1.e
0.0 - 0,1 &apos; 0.1 • 9,3 - 0.4 —9 6-9i —r .6-91--- 0-i- --
_.
16. 4 . Zef.0 Greasily, Rata
9&apos;i &apos; .. , • &apos; ,...
Tout Cri•ray ; , 0
as ;10
1 1.rtergy —.---,26,-;-.17,-7,1tri-,....,
• tee
liii.
&apos;ill &apos;dill&apos;
#0,010.-401-4111P100--
I .— I . L I —.I LI I I
Did you hit it to Tom
</figure>
<page confidence="0.852133">
92
</page>
<bodyText confidence="0.8520605">
Klatt&apos;s example (enhanced with allophonic diacritics to show aspiration
and glottalization):
</bodyText>
<equation confidence="0.7067175">
(7) [drjahl[11 thi tham]
TT T
</equation>
<bodyText confidence="0.993600777777778">
Using phonotactic and allophonic constraints on syllable structure such
as:3
Lax vowels are restricted to closed syllables (syllables ending in a
consonant) RI. However, in this case. Ill cannot meet the closed
syllable restriction because the following consonant is aspirated (and
therefore syllable initial). Thus the transcription is internally
inconsistent. The parser should probably reject die transcrintinn and
hope that the front end can fix the problem. Alternatively, the parser
might attempt to correct the error by hypothesizing a second /t/.4
</bodyText>
<listItem confidence="0.9724335">
(8a) /h/ is always syllable initial, phonotactic There are many other examples like (10) where phonotactic
(8b) [Li is always syllable final, allophonic constraints and allophonic constraints overlap. Consider the pairs
(Sc) n is always syllable final, and allophonic found in figure 2, where there are multiple arguments for assigning the
(8d) [till is always syllable initial. allophonic crucial syllable boundary. In de-prive vs. dep-rivation, for instance, the
the parser can insert the following syllable boundaries: difference is revealed by the vowel argument above5 and by the
(9) (dna # # chi tharn] aspiration rule.6 In addition, the stress contrast will probably be cor-
</listItem>
<bodyText confidence="0.917058428571428">
related with a number of so-called &apos;suprasegmental&apos; cues, e.g., duration,
fundamental frequency, and intensity [8].
It is now it is relatively easy to decode the utterance with lexical
matching routines similar to those in Smith&apos;s Noah program at CMU
[241.
parsed transcription decoding
cup —4 did you
hic hit
it
thf to
tham Tom
In summary. I believe that the lexical retrieval device will be in a
superior position to hypothesize word candidates if it exploits allo-
phonic and phonotactic constraints on syllable structure.
</bodyText>
<subsectionHeader confidence="0.997892">
1.4 Exploiting Redundancy
</subsectionHeader>
<bodyText confidence="0.9995766">
In many cases, allophonic and phonotactic constraints are
redundant. Even if the parser should miss a few of the cues for syllable
structure, it will often be able to find the correct structure by taking
advantage of some other redundant cue. For example, suppose that the
front end failed to notice die glottalized /t/ in the word it.
</bodyText>
<listItem confidence="0.740307">
(10) aria # hl[ # I # tha # tham
</listItem>
<bodyText confidence="0.96431">
The parser could deduce that the input transcription (10) is internally
inconsistent, because of a phonotactic constraint on the lax vowel /I/.
</bodyText>
<footnote confidence="0.662292">
3. This formulation of the constraints is oversimplified for expository convenience; see
110. 13, 151 and references therein for discussion of the more subtle issues.
</footnote>
<bodyText confidence="0.9988777">
In general, there seem to be a large number of multiple low level
cues for syllable structure. This observation, if correct, could be viewed
as a form of a &apos;constituency hypothesis&apos;. Just as syntacticians have
argued for the constituent-hood of noun phrases, verb phrases and
sentences on the grounds that these constituents seem to capture crucial
linguistic generalizations (e.g., question formation, wh-movement), so
too. I might argue (along with certain phonologists such as Kahn (13])
that syllables, onsets, and rhymes are constituents because they also
capture important generalizations such as aspiration, tensing and lazing.
If this constituency hypothesis for phonology is correct (and I believe
</bodyText>
<figureCaption confidence="0.935505">
Fig. 2. Some Structural Contrasts
</figureCaption>
<bodyText confidence="0.962657846153846">
1
de-prive di-plomacy
dep-rivation dip-lomatic
a-ttribute
att-ribute
de-crease de-cline a-cqu ire
dcc-riment dec-lination acq-uisition
cele-bration o-bligatory
celeb-rity ob-ligation
a-ddress
add-ress
de-grade
deg-radation
</bodyText>
<footnote confidence="0.984056666666667">
4. Personally, I favor the first alternative: after years of witnessing Victor Zue read
spectrograms. I have become most impressed with the nchness of low level phonetic cues.
S. The syllable de- is open because the vowel is tense (diphthongircd): dep- is closed
because the vowel is lax
6. The /p/ in -prune is syllable initial because it is aspirated whereas the /p/ in dep- is
sy liable final because a is unaspirated.
</footnote>
<page confidence="0.997667">
93
</page>
<bodyText confidence="0.99312925">
that it. is). then it seems natural to propose a syllable parser for
processing speech, by analogy with sentence parsers that have become
standard practice in the natural language community for processing
text.
</bodyText>
<listItem confidence="0.74914">
2. Parser Implementation and Feature Spreading
</listItem>
<bodyText confidence="0.998465428571429">
A program has been implemented [41 which parses a lattice of
phonetic segments into a lattice of syllables and other phonological
constituents. Except for its novel mechanism for handling features, it is
very much like a standard chart parser (e.g., Earley&apos;s Algorithm [71).
Recall that a chart parser takes as input a sentence and a context-free
grammar and produces as output a chart like that below, indicating the
starting point and ending point of each phrase in the input string.
</bodyText>
<equation confidence="0.996183769230769">
liap.L.4 alarm: 0 They I are 2 flying 3 planes 4
G rammar:
N they V are dying
A flying V flying N •—■ planes
S NP VP VP --* V NP VP --■ V VP
NP NP --■ AP NP NP --. VP AP --+ A
Chart:
I°
0 { } rs:P.N,they}
{} (1
2 fl { }
3 {1 {}
4 1 ( 1
</equation>
<bodyText confidence="0.913415125">
Each entry in the chart represents the possible analyses of the input
words between a start position (the row index) and a finish position (the
column index). For example, the entry {NP, VP) in Chart(2, 4)
represents two alternative analyses of the words between 2 and 4:
„flying planes] and [vp flying planesi.
[NI
The same parsing methods can be used to find syllable structure
from an input transcription.
</bodyText>
<equation confidence="0.978657428571428">
Chart:
o (1 tff,onsetsodal
)
{
{ }
I
I
</equation>
<bodyText confidence="0.984239333333333">
This chart shows that the input sentence can be decomposed into two
syllables, one from 0 to 3 (this) and another one from 4 to 5 (is).
Alternatively, the input sentence can be decomposed into [1&apos;t biz]. In
this way, standard chart parsing techniques can be adopted to process
allophonic and phonotactic constraints, if the constraints are
reformulated in terms of a grammar.
How can allophonic and phonotactic constraints be cast in terms
of context-free rules? In many cases, the constraints can be carried over
in a straightforward way. For example, the following set of rules
express the aspiration constraint discussed above. These rules allow
aspiration in syllable initial position (under the onset node), but not in
syllable final position (under the coda).
</bodyText>
<listItem confidence="0.74376325">
(11a) utterance —■ syllable*
(1 lb) syllable --• (onset) peak (coda)
(11e) onset --• aspirated-ti aspirated-k I aspirated-P 1...
(11d) coda unreleased-ti unreleased-k I unreleased-p I ...
</listItem>
<bodyText confidence="0.999367333333333">
The aspiration constraint (as stated above) is relatively easy to cast in
terms of context-free rules. Other allophonic and plionotactic processes
may be more difficult!
</bodyText>
<subsectionHeader confidence="0.983784">
2.1 The Agreement Problem
</subsectionHeader>
<bodyText confidence="0.87483175">
In particular, context-free rules are generally considered to be
awkward for expressing agreement facts. For example, in order to
express subject-verb agreement in &amp;quot;pure&amp;quot; context-free rules, it is
probably necessary to expand the rule S NP VP into two cases:
</bodyText>
<figure confidence="0.780970454545454">
2 3 4
{S) (SI
{VP} (VP)
(NP,VP.AP,N.V.A,flyingl (NP,VP)
{l {NP,N.planes}
}
2 3 4 5
)
2 (
(I
4
5 ( I
(syl} { (I
(syl) } 1 1
{S.onset,codal {syl} (syl}
I) (1.peak,syl) {syl)
{ (I {Z,onset.coda)
I (I {
Innut Sentence: 0 5. it 2.S 3 4 Z. (this is) (12a) S singular-NP singular-VP singular case
Grammar: (12b) S plural-NP plural-VP plural case
onset ISIZ peak 11
coda g ISlz syl (onset) peak (coda)
</figure>
<footnote confidence="0.476233">
7. For example, there may be a problem with constraints that depend on rule ordering,
since rule ordenng is not supported in the context-free formalism. This topic is discussed
at length in 141.
</footnote>
<page confidence="0.999142">
94
</page>
<bodyText confidence="0.99988925">
The agreement problem also arises in phonology. Consider the
example of homorganic nasal clusters (e.g., cam, caa1, sank), where
the nasal agrees with the following obstruent in place of articulation.
That is, the labial nasal /m/ is found before the labial stop /p/, the
coronal nasal /n/ before the corona! stop /t/, and the velar nasal krj/
before the velar stop /k/. This constraint, like subject-verb agreement,
poses a problem for pure unaugmented context-free rules; it seems to
be necessary to expand out each of the three cases:
</bodyText>
<listItem confidence="0.97679">
(13a) homorganic-nasal-cluster labial-nasal labial-obstruent
(13b) homorganic-nasal-cluster coronal-nasal coronal-obstruent
(13c) homorganic-nasal-cluster —■ velar-nasal velar-obstruent
</listItem>
<bodyText confidence="0.911977555555556">
In an effort to alleviate this expansion problem, many researchers have
proposed augmentations of various sorts (e.g., ATN registers [26], LFG
constraint equations [16], GPSG meta-rules [Ill, local constraints (18],
bit vectors [6, 22]). My own solution will be suggested after I have had
a chance to describe the parser in further detail.
L2 A Parser Based on Matrix Operations
This section will show how the grammar can be implemented in
terms of operations on binary matrices. Suppose that the chart is
decomposed into a sum of binary matrices:
</bodyText>
<listItem confidence="0.884365">
(14) Chart = syl Ms)/ + onset Monset ± peak Mpeak
</listItem>
<bodyText confidence="0.99991625">
where Msyi is a binary matrix8 describing the location of syllables and
Monset is a binary matrix describing the location of onsets. and so forth.
Each of these binary matrices has a 1 in position (i, j) if there is a
constituent of the appropriate part of speech spanning from the ith
position in the input sentence to the jth position.9 (See figure 3).
Phrase-structure rules will be implemented with simple oper-
ations on these binary matrices. For example, the homorganic rule (13)
could be implemented as:
</bodyText>
<footnote confidence="0.830354222222222">
8. Mese matnas will sometimes be called segmentation lattices for historical reasons.
Technically. these matnces need not conform to the restrictions of a lattice, and therefore,
the weaker term graph LS more correct
9 In a probabilistic framework, one could replace all of the I &apos;sand O&apos;s with probabilities.
A high probability in location (i.p of the syllable matnx would say that there probably is
a syllable from position ito position I: a low probability would say that there probably
isn&apos;t a syllable between land j. Most of the following applies to probability matrices as
well as binary matrices, though the probability matrices may be less sparse and
consequently less efficient.
</footnote>
<figureCaption confidence="0.948072">
Fig. 3. Mso, Momer, and M rhyme or.
</figureCaption>
<bodyText confidence="0.9762386875">
0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0
0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0
0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0
0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0
The matrices tend to be very sparse (almost entirely full of O&apos;s) because
syllable grammars are highly constrained. In principle, there could be
n2 entries. However, it can be shown that c (the number of l&apos;s) is
linearly related to n because syllables have finite length. In Church [4],
sharpen this result by arguing that c tends to be bounded by 4n as a
consequence of a phonotactic principle known as sonority. Many more
edges will be ruled out by a number of other linguistic constraints
mentioned above: voicing and place assimilation, aspiration, flapping,
etc. In short, these matrices are sparse because allophonic and phono-
tactic constraints are useful.
</bodyText>
<equation confidence="0.5932365">
(15) (setq homorganic-nasal-lattice
(M + (Ms (phoneme-lattice rt /m) labial-lattice)
(Ms (phoneme-lattice # /n) coronal-lattice)
(Ms (phoneme-lattice #/G) velar-lattice)))
</equation>
<bodyText confidence="0.999584222222222">
illustrating the use of M+ (matrix addition) to express the union of
several alternatives and M* (matrix multiplication) to express the
concatenation of subparts. It is well known that any finite-state
grammar could be implemented in this way with just three matrix
operations: Ms, M+, and M** (transitive closure). If context-free
power were required. Valient&apos;s algorithm [25] could be employed.
However, since there doesn&apos;t seem to be a need for additional
generative capacity in speech applications, the system is restricted to
handle only the simpler finite state case.10
</bodyText>
<subsectionHeader confidence="0.995258">
2.3 Feature Manipulation
</subsectionHeader>
<bodyText confidence="0.999946875">
Although &amp;quot;pure&amp;quot; unaugmented finite state grammars may be
adequate for speech applications (in the weak generative capacity
sense), I may, nevertheless, wish to introduce additional mechanism in
order to account for agreement facts in a natural way. As discussed
above, the formulation of the homorganic rule in (15) is unattractive
because it splits the rule into three cases, one for each place of
articulation. It would be preferable to state the agreement constraint
just once, by defining a homorganic nasal cluster to be a nasal cluster
</bodyText>
<footnote confidence="0.460815">
10. I personally hold a much more controversial position, that finite state grammars are
sufficient for most if not all, natural language tasks (3).
</footnote>
<page confidence="0.997922">
95
</page>
<bodyText confidence="0.794660285714286">
subject to place assimilation.. In ifly language of matrix operations. I
can say just exactly that:
(16) (setq homorganic-nasal-cluster-lattice
(M&amp; nasal-cluster-lattice
place-assimilation))
where M&amp; (element-wise intersection) implements the subject to
constraint. Nasal-cluster and place-assimilation are defined as:
</bodyText>
<equation confidence="0.955637833333333">
(17a) (setq nasal-cluster-lattice
(Ms nasal-lattice obstruent-lattice))
(17b) (setq place-assimilation-lattice
(M+ (M** labial-lattice)
(M** dental-lattice)
(M&amp;quot; velar-lattice)))
</equation>
<bodyText confidence="0.948001192307692">
In this way, M&amp; seems to be an attractive solution to the agreement
problem.
In addition, M&amp; might also shed some light on co-articulation,
another problem of &apos;feature spreading&apos;. Co-articulation (articulation of
multiple phonemes at the same time) makes it extremely difficult
(perhaps impossible) to segment the speech waveform into phoneme-
co-articulation, Fujimura suggests that place, manner and other
articulatory features be thought of as asynchronous processes, which
have a certain amount of freedom to overlap in time.
(18a) &amp;quot;Speech is commonly viewed as the result of concatenating
phonetic segments. In most discussions of the temporal
structure of speech, a segment in such a model is assumed to
represent a phoneme-sized phonetic unit, which possesses an
inherent [invariant] target value in terms of articulation or
acoustic manifestation. Any deviation from such an
interpretation of observed phenomena requires special
attention ... [Biased on some preliminary results of X-ray
microbcam studies [which associate lip, tongue and jaw
movements with phonetic events in the utterance&apos;, it will be
suggested that understanding articulatory processes, which are
inherently multi-dimensional [and (more or less) asynchronous&apos;,
may be essential for a successful description of temporal
structures of speech.&amp;quot; [9 p. 664
In light of Fujimura&apos;s suggestion, I might re-interpret my parser as a
highly parallel feature-based asynchronous architecture. For example,
the parser can process homorganic nasal clusters by processing place
and manner phrases in parallel, and then synchronizing the results at
the coda node with M&amp;. That is, (17a) can be computed in parallel with
(1M). and then the results arc aligned when the coda is computed with
(16). as illustrated below for the word tent. Imagine that the front end
produces the following analysis:
dental:
vowel:
stop:
nasalization:
where many of the features overlap in an asynchronous way. The
parser will correctly locate the coda by intersecting the nasal cluster
lattice (computed with (17a)) with the homorganic lattice (computed
with (17b)).
nasal cluster:
homorganic:
coda:
This parser is a bold departure from a standard practice in two respects:
(1) the input stream is feature-based rather than segmental, and (2) the
output parse is a hcterarchy of overlapping constituents (e.g., place and
manner phrases) as opposed to a list of hierarchical parse-trees. I find
these two modifications most exciting and worthy of further
investigation.
In summary, two points have been made. First. I suggested the
use of parsing techniques at the segmental/feature level in speech
applications. Secondly, I introduced M&amp; as a possible solution to the
agreement/co-articulation problem.
</bodyText>
<sectionHeader confidence="0.992879" genericHeader="acknowledgments">
3. Acknowledgements
</sectionHeader>
<bodyText confidence="0.998686333333333">
I have received a considerable amount of help and support over
the course of this project. Let mc mention just a few of the people that
I should thank: Jon Allen, Glenn Burke, Francine Chen, Scott Cyphers,
Sarah Ferguson. Margaret Fleck. Dan Huttenlocher. Jay Keyser. Lori
Lamel, Ramesh Pull. Janet Picrrehumbert, Dave Shipman, Pete
Szolovits. Meg Withgott and Victor Zue.
</bodyText>
<sectionHeader confidence="0.998379" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990411222222222">
1. Barnwell, T., An Algorithm for Segment Durations in a
Reading Machine Context, unpublished doctoral dis-
sertation, department of Electrical Engineering and
Computer Science, mrr, 1970.
2. Chomsky. N. and Halle, M., The Sound Pattern of English,
Harper &amp; Row, 1968.
3. Church, K., On ;Slentory Limitations in Natural Language
Processing, MS Thesis, MIT, Mr17LCS/TR-245, 1980
(also available from Indiana University Linguistics Club).
</reference>
<equation confidence="0.331035">
t
</equation>
<page confidence="0.976347">
96
</page>
<reference confidence="0.999969121212122">
4. Church, K., Phrase-Structure Parsing: A Method jiff Taking
Advantage of Allophonic Constraints, unpublished
doctoral dissertation, department of Electrical Engineering
and Computer Science, MIT, 1983 (also to appear. LCS
and RLE publications, MIT).
5. Cole, R., and Jakimik, J., A Model of Speech Perception, in
R. Cole (ed.), Perception and Production of Fluent Speech,
Lawrence Erlbaum, Hillsdale, N.J., 1980.
6. Dostcrt, B., and Thompson, F., How Features Resolve
Syntactic Ambiguity, in Proceedings of the Symposium on
Information Storage and Retrieval, Minker, J., and
Rosenfeld, S. (ed.), 1971.
7. Earley, J., An Efficient Context-Free Parsing Algorithm,
CACM, 13:2, February, 1970.
8. Fry, D., Duration and Intensity as Physical Correlates of
Linguistic Stress, JASA 17:4, 1955, (reprinted in Lehiste
(ed.), Readings in Acoustic Phonetics, MIT Press, 1967.)
9. Fujimura, 0., Temporal Organization of Articulatory Move
ments as tfultidimensional Phrasal Structure, Phonctica,
33: pp. 66-83, 1981.
10. 1-7ujimura, 0., and Lovins, J., Syllables as Concatenative
Phonetic Units, Indiana University Linguistics Club, 1982.
11. Gazdar, G., Phrase Structure Grammar, in P. Jacobson and
G. Pullum (eds.), The Nature of Syntactic Representation,
D. Reidel, Dordrecht, in press, 1982.
12. Heffner, R., General Phonetics, The University of
Wisconsin Press, 1960.
13. Kahn, D., Syllable- Based Generalizations in English Pho-
nology, Indiana University Linguistics Club, 1976.
14. Kiparsky, P., Remarks on the Metrical Structure of the Syl-
lable, in W. Dressler (ed.) Phonologica 1980. Proceedings
of the Fourth International Phonology Meeting, 1981.
15. Kiparsky, P., Metrical Structure Assignments in Cyclic,
I.inguistic Inquiry, 10, pp. 421-441, 1979.
16. Kaplan, R. and Bresnan, J., Lexical-Functional Grammar:
A Formal System for Granmiatical Representation, in
Bresnan (ed.), The Mental Representation of Granunatical
Relations, MIT Press. 1982.
17. Jelinek, F., course notes, MIT, 1982.
18. Josh&apos;, A., and Levy, L.. Phrase Structure Trees Rear More
Fruit Than You Would Have Thought, AJC1., 8:1, 1982.
19. Klatt, D., Word Verification in a Speech Understanding
System, in R. Reddy (ed.), Speech Recognition, Invited
Papers Presented at the 1974 IEEE Symposium, Academic
Press, pp. 321-344, 1974.
20. Klatt, D., Review of the ARPA Speech Understanding
Project, JASA, 62:6, December 1977.
21. Klatt, D., Scriber and Lafs: Two New Approaches to Speech
Analysis, chapter 25 in W. Lea, Trends in Speech Recog-
nition, Prentice- Flail, 1980.
22. Martin, W., Church, K., and Patil, R., Preliminary Analysis
of a Breadth-First Parsing Algorithni: Theoretical and Er
pet-internal Results. MIT/LCS/TR-261, 1981 (also to
appear in L. 13o1c (cd.), Natural Language Parsing
Systems, Macmillan, London).
23. Reddy, R., Speech Recognition by Machine: A Review,
Proceedings of the IEEE, pp. 501-531, April 1976.
24. Smith, A., Word Hypothesization in the hearsay-Il Speech
System, Proc. IEEE Int. Conf. ASSP, pp. 549-552, 1976.
25. Valient, L., General Context Free Recognition in Less Than
Cubic Time, J. Computer and System Sciences 10, pp. 308-
315. 1975.
26. Woods, W., Transition Network Grammars for Natural
Language Analysis, CACM, 13:10, 1970.
27. Zue, V., and Shattuck-Hufnagcl, S., When is a /V not a
/V?, ASA, Atlanta, 1980.
</reference>
<page confidence="0.999694">
97
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000040">
<title confidence="0.999966">A Finite-State Parser for Use in Speech Recognition</title>
<author confidence="0.999781">Kenneth W Church</author>
<pubnum confidence="0.772004">NE43-307</pubnum>
<affiliation confidence="0.999831">Massachusetts Institute of Technology</affiliation>
<address confidence="0.999982">Cambridge, MA. 02139</address>
<abstract confidence="0.995696264880952">paper is divided into two The first section motivates the application of finite-state parsing techniques at the phonetic level in order to exploit certain classes of contextual constraints. -In the second section, the parsing framework is extended in order to account for &apos;feature spreading&apos; (e.g., agreement and co-articulation) in a natural way. 1. Parsing at the Phonetic Level It is well known that phonemes have different acoustic/phonetic realizations depending on the context. For example, the phoneme A/ is typically realized with a different allophone (phonetic variant) in syllable initial position than in syllabic final position. In syllable initial (e.g., is almost always released (with a strong burst of energy) and aspirated (with h-like noise), whereas in syllable final (e.g., is often unreleased and unaspirated. It is common practice in speech research to distinguish acoustic/phonetic properties that vary a great deal with context (e.g., release and aspiration) from those that are relatively invariant to context (e.g., manner and In the past, the emphasis has been on invariants; allophonic variation is traditionally seen as problematic for recognition. (1) &amp;quot;In most systems for sentence recognition, such modifications must be viewed as a kind of &apos;noise&apos; that makes it more difficult to hypothesize lexical candidates given an input phonetic transcription. To see that this must be the case, we note that each phonological rule [in an example to be presented below] I. This research was supported (in part) by the National 1nstitutes of Ilealth Grant No. I POI 1M 03374-01 and 03374-02 from the National Library of Medicine. Place to the location of the constriction in the vocal tract. fIxamples include: (at the lips) /p, b. f, v. m/. velar /k. g, r1/. dental teeth) /5, d, 1, n/ and rs, 2, Manner among vowels, liquids and glides (e.g., /1, y, fricatives (e.g., /,,z, f, v/), nasals (e.g., In. m. stops /p, t, k, b. d, g/). vibration of the vocal fold.$) distinguishes sounds like lb, d, g/ from /p, t, results in irreversible ambiguity — the phonological rule does not have a unique inverse that could be used to recover the underlying phonemic representation for a lexical item. For example, ... schwa vowels could be the first vowel in is word like &apos;about&apos; or the surface realization of almost any English vowel appearing in a sufficiently &amp;stressed word. The tongue flap [C1 have come from a /t/ or a /d/.&amp;quot; Klatt [21, pp. 548-5491 This view of allophonic variation is representative of much of the speech recognition literature, especially during the ARPA speech One can find similar statements by Cole and (CM U) [5] and by Jelinek (IBM) [171. prefer to think of variation as is well known that allophonic contrasts can be distinctive, as illustrated by the following famous minimal pairs where the crucial distinctions seem to lie in the allophonic realization of the /t/: a tease / at ease night rate / nitrate great wine / gray twine This evidence suggests that allophonic variation provides a rich source of constraints on syllable structure and word stress. The recognizer to be discussed here (and partly implemented in Church (41) is designed to exploit allophonic and phonotactic cues by parsing the input utterance into syllables and other suprasegmental constituents using phrasestructure parsing techniques. 1.1 An Example of Lexical Retrieval It might be helpful to work out an example in order to illustrate how parsing can play a role in lexical retrieval. Consider the phonetic transcription, mentioned above in the citation from Klatt [20, p. 1346] [21, pp. 548-5491: 91 (3) [d1lahl[11.1 taml It is desired to decode (3) into the string of words: (4) Did you hit it to Tom? In practice, the lexical retrieval problem is complicated by errors in the front end. However, even with an ideal error-free front-end, it is difficult to decode (3) because, among other things, there arc extensive rule-governed changes affecting the way that words arc pronounced in different sentence contexts, as Klan&apos;s example illustrates: Palatalization of /d/ before /y/ in you Reduction of unstressed /u/ to schwa in Flapping of intervocalic /t/ in it Reduction of schwa and devoicing of /u/ in Reduction of geminate /t/ in allophonic processes often appear to distinctions. For example, the voicing contrast between /t] and /d/, is usually distinctive, is almost completely lost in where both /t/ and /d/ are realized in American English with a tongue An View of Neutralization Fortunately, there are many fewer cases of true neutralization it might seem. Even rider, voicing contrast is not lost. The vowel in to be longer than the vowel in to a general process that lengthens vowels before voiced consonants (e.g., /d/) and shortens them before unvoiced consonants (e.g., /t/). A similar lengthening argument can be used to separate /n/ and Ind/ (at least in some cases). It might be suggested that /0/ is merged /nd/ by a Id/ deletion rule that applies in words like wind .erb), and there is little if any direct acoustic evidence for a /d/ segment in this environment.) However, I that these words can often be distinguished from win, on the basis of the duration of the nasal murmur which is lengthened in the precedence of a voiced obstruent like /d/. Thus, this Id/-deletion process is probably not a true case of neutralization. Recent studies in acoustic/phonetics seem to indicate that more more apparent neutralization can be separated as the field For instance, it has been said that /s/ merges with a like shortage However, a recent experiment 1271 that the /sS/ sequence can he distinguished from in shortage) the basis of a spectral tilt: the &apos;spectrum is more in the beginning and more at the end, whereas the /W spectrum is relatively constant throughout. A similar spectral tilt argument can be used to separate other cases of apparent gemination /zg/ in the). As a final example of apparent neutralization, consider the portion of the spectrogram in Figure 1 between 0.85 and 1.1 seconds. corresponds to The two adjacent /t/s in you hit o Klatt analyzed this region with a single geminated /t/. However, upon further investigation of the spectrum. I believe that there are acoustic cues for two segments. Note especially the total energy, which displays two peaks at 0.95 and 1.02 seconds. On the basis of this evidence, I will replace Klaus transcription (6a) with (6b): (6a) tdIjahICIti tam] [dIjah ICI t 1.3 Parsing and Matching Even though I might be able to re-interpret many cases of apparent neutralization, it remains extremely difficult to &amp;quot;undo&amp;quot; the allophonic rules by inverse transformational parsing techniques. Let me suggest an alternative proposal. I will treat syllable structure as an intermediate level of representation between the input segment lattice and the output word lattice. In so doing, I have replaced the lexical problem with (hopefully simpler) problems: (a) parsethe segment lattice into syllable structure, and (b) match the resulting the lexicon. I will illustrate the approach with I. 1)id you lilt it to Tom? a 0.9 1.0 1.1 13 1.3 1.• 1.e 0.0- 0.1• - 0.4-- _. . Rata &apos; .. , • &apos; ,... Cri•ray , 0 ;10 1.rtergy —.---,26,-;-.17,-7,1tri-,...., • tee &apos;ill &apos;dill&apos; I .— I . L I —.I LI I I Did you hit it to Tom 92 Klatt&apos;s example (enhanced with allophonic diacritics to show aspiration and glottalization): TT T Using phonotactic and allophonic constraints on syllable structure such vowels are restricted to closed syllables (syllables ending in consonant) RI. However, in this case. Ill cannot meet the closed syllable restriction because the following consonant is aspirated (and therefore syllable initial). Thus the transcription is internally The parser should probably reject transcrintinn that the front end the problem. Alternatively, the parser attempt to correct the error by hypothesizing a second (8a) /h/ is always syllable initial, phonotactic allophonic allophonic allophonic There are many other examples like (10) where phonotactic constraints and allophonic constraints overlap. Consider the pairs found in figure 2, where there are multiple arguments for assigning the syllable boundary. In vs. dep-rivation, instance, the is revealed by the vowel argument and by the In addition, the stress contrast will probably be cor-related with a number of so-called &apos;suprasegmental&apos; cues, e.g., duration, fundamental frequency, and intensity [8]. (8b) [Li is always syllable final, (Sc) n is always syllable final, and is always syllable initial. the parser can insert the following syllable boundaries: (dna It is now it is relatively easy to decode the utterance with lexical matching routines similar to those in Smith&apos;s Noah program at CMU [241. parsed transcription decoding you it to Tom In summary. I believe that the lexical retrieval device will be in a superior position to hypothesize word candidates if it exploits allophonic and phonotactic constraints on syllable structure. 1.4 Exploiting Redundancy In many cases, allophonic and phonotactic constraints are redundant. Even if the parser should miss a few of the cues for syllable often be able to find the correct structure by taking advantage of some other redundant cue. For example, suppose that the end failed to notice die glottalized /t/ in the word aria # # I # # The parser could deduce that the input transcription (10) is internally inconsistent, because of a phonotactic constraint on the lax vowel /I/. 3. This formulation of the constraints is oversimplified for expository convenience; see 110. 13, 151 and references therein for discussion of the more subtle issues. In general, there seem to be a large number of multiple low level cues for syllable structure. This observation, if correct, could be viewed as a form of a &apos;constituency hypothesis&apos;. Just as syntacticians have argued for the constituent-hood of noun phrases, verb phrases and sentences on the grounds that these constituents seem to capture crucial linguistic generalizations (e.g., question formation, wh-movement), so too. I might argue (along with certain phonologists such as Kahn (13]) that syllables, onsets, and rhymes are constituents because they also capture important generalizations such as aspiration, tensing and lazing. If this constituency hypothesis for phonology is correct (and I believe Fig. 2. Some Structural Contrasts 1 de-prive di-plomacy dep-rivation dip-lomatic a-ttribute att-ribute de-crease de-cline a-cqu ire dcc-riment dec-lination acq-uisition cele-bration o-bligatory celeb-rity ob-ligation a-ddress add-ress de-grade deg-radation Personally, I favor the first alternative: after years of Zue read I have become most impressed with the nchness level phonetic cues. The syllable open because the vowel is tense (diphthongircd): closed because the vowel is lax The in syllable initial because it is aspirated whereas the in is final because a is unaspirated. 93 that it. is). then it seems natural to propose a syllable parser for processing speech, by analogy with sentence parsers that have become standard practice in the natural language community for processing text. 2. Parser Implementation and Feature Spreading A program has been implemented [41 which parses a lattice of phonetic segments into a lattice of syllables and other phonological constituents. Except for its novel mechanism for handling features, it is very much like a standard chart parser (e.g., Earley&apos;s Algorithm [71). Recall that a chart parser takes as input a sentence and a context-free grammar and produces as output a chart like that below, indicating the starting point and ending point of each phrase in the input string. alarm: 0They Iare 2flying 3planes 4 G rammar: they V dying V flying N •—■ planes S NP VP VP --* V NP VP --■ V VP NP --■ AP NP NP --. VP AP --+ Chart: } rs:P.N,they} {} (1 2fl } 3 {1 {} 4 1 ( 1 Each entry in the chart represents the possible analyses of the input words between a start position (the row index) and a finish position (the column index). For example, the entry {NP, VP) in Chart(2, 4) represents two alternative analyses of the words between 2 and 4: planes] flying planesi. The same parsing methods can be used to find syllable structure from an input transcription. Chart: tff,onsetsodal ) { { } I I This chart shows that the input sentence can be decomposed into two one from 0 to 3 another one from 4 to 5 Alternatively, the input sentence can be decomposed into [1&apos;t biz]. In this way, standard chart parsing techniques can be adopted to process allophonic and phonotactic constraints, if the constraints are reformulated in terms of a grammar. How can allophonic and phonotactic constraints be cast in terms of context-free rules? In many cases, the constraints can be carried over in a straightforward way. For example, the following set of rules express the aspiration constraint discussed above. These rules allow aspiration in syllable initial position (under the onset node), but not in syllable final position (under the coda). (11a) utterance —■ syllable* (1 lb) syllable --• (onset) peak (coda) (11e) onset --• aspirated-ti aspirated-k I aspirated-P 1... (11d) coda unreleased-ti unreleased-k I unreleased-p I ... The aspiration constraint (as stated above) is relatively easy to cast in terms of context-free rules. Other allophonic and plionotactic processes may be more difficult! 2.1 The Agreement Problem In particular, context-free rules are generally considered to be awkward for expressing agreement facts. For example, in order to express subject-verb agreement in &amp;quot;pure&amp;quot; context-free rules, it is probably necessary to expand the rule S NP VP into two cases: 3 {S) (SI {VP} (VP) (NP,VP.AP,N.V.A,flyingl (NP,VP) {l {NP,N.planes} } 4 5 ) (I 4 I (syl} { (I (syl) } 1 1 {S.onset,codal {syl} (syl} I) (1.peak,syl) {syl) { (I {Z,onset.coda) { I (I Sentence:0 4Z. is) (12a) S singular-NP singular-VP singular case plural case Grammar: (12b) S plural-NP plural-VP onset ISIZ peak 11 coda g ISlz syl (onset) peak (coda) 7. For example, there may be a problem with constraints that depend on rule ordering, since rule ordenng is not supported in the context-free formalism. This topic is discussed at length in 141. 94 The agreement problem also arises in phonology. Consider the of homorganic nasal clusters (e.g., caa1, sank), the nasal agrees with the following obstruent in place of articulation. That is, the labial nasal /m/ is found before the labial stop /p/, the nasal /n/ before the corona! stop /t/, and the velar nasal before the velar stop /k/. This constraint, like subject-verb agreement, poses a problem for pure unaugmented context-free rules; it seems to be necessary to expand out each of the three cases: (13a) homorganic-nasal-cluster labial-nasal labial-obstruent (13b) homorganic-nasal-cluster coronal-nasal coronal-obstruent (13c) homorganic-nasal-cluster —■ velar-nasal velar-obstruent In an effort to alleviate this expansion problem, many researchers have proposed augmentations of various sorts (e.g., ATN registers [26], LFG constraint equations [16], GPSG meta-rules [Ill, local constraints (18], bit vectors [6, 22]). My own solution will be suggested after I have had a chance to describe the parser in further detail. L2 A Parser Based on Matrix Operations This section will show how the grammar can be implemented in terms of operations on binary matrices. Suppose that the chart is decomposed into a sum of binary matrices: Chart = syl onset is a binary describing the location of syllables and is a binary matrix describing the location of onsets. and so forth. Each of these binary matrices has a 1 in position (i, j) if there is a of the appropriate part of speech spanning from the in the input sentence (See figure 3). Phrase-structure rules will be implemented with simple operations on these binary matrices. For example, the homorganic rule (13) could be implemented as: Mese matnas will sometimes be called lattices historical reasons. Technically. these matnces need not conform to the restrictions of a lattice, and therefore, weaker term correct 9 In a probabilistic framework, one could replace all of the I &apos;sand O&apos;s with probabilities. A high probability in location (i.p of the syllable matnx would say that there probably is syllable from position ito position low probability would say that there probably a syllable between j. Most of the following applies to probability matrices as well as binary matrices, though the probability matrices may be less sparse and consequently less efficient.</abstract>
<note confidence="0.641436">3. and M rhymeor. 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0</note>
<phone confidence="0.606536666666667">0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0</phone>
<abstract confidence="0.993737584158416">matrices tend to be very sparse(almost entirely full of O&apos;s) because syllable grammars are highly constrained. In principle, there could be However, it can be shown that c (the number of l&apos;s) is linearly related to n because syllables have finite length. In Church [4], sharpen this result by arguing that c tends to be bounded by 4n as a consequence of a phonotactic principle known as sonority. Many more edges will be ruled out by a number of other linguistic constraints mentioned above: voicing and place assimilation, aspiration, flapping, In short, these matrices are sparse because and phonotactic constraints are useful. (15) (setq homorganic-nasal-lattice (M + (Ms (phoneme-lattice rt /m) labial-lattice) (Ms (phoneme-lattice # /n) coronal-lattice) (Ms (phoneme-lattice #/G) velar-lattice))) illustrating the use of M+ (matrix addition) to express the union of several alternatives and M* (matrix multiplication) to express the concatenation of subparts. It is well known that any finite-state grammar could be implemented in this way with just three matrix operations: Ms, M+, and M** (transitive closure). If context-free power were required. Valient&apos;s algorithm [25] could be employed. However, since there doesn&apos;t seem to be a need for additional generative capacity in speech applications, the system is restricted to only the simpler finite state 2.3 Feature Manipulation Although &amp;quot;pure&amp;quot; unaugmented finite state grammars may be adequate for speech applications (in the weak generative capacity sense), I may, nevertheless, wish to introduce additional mechanism in order to account for agreement facts in a natural way. As discussed above, the formulation of the homorganic rule in (15) is unattractive because it splits the rule into three cases, one for each place of articulation. It would be preferable to state the agreement constraint just once, by defining a homorganic nasal cluster to be a nasal cluster 10. I personally hold a much more controversial position, that finite state grammars are sufficient for most if not all, natural language tasks (3). 95 subject to place assimilation.. In ifly language of matrix operations. I can say just exactly that: (16) (setq homorganic-nasal-cluster-lattice (M&amp; nasal-cluster-lattice place-assimilation)) M&amp; (element-wise intersection) implements the to constraint. Nasal-cluster and place-assimilation are defined as: (17a) (setq nasal-cluster-lattice (Ms nasal-lattice obstruent-lattice)) (17b) (setq place-assimilation-lattice (M+ (M** labial-lattice) (M** dental-lattice) (M&amp;quot; velar-lattice))) In this way, M&amp; seems to be an attractive solution to the agreement problem. In addition, M&amp; might also shed some light on co-articulation, another problem of &apos;feature spreading&apos;. Co-articulation (articulation of multiple phonemes at the same time) makes it extremely difficult impossible) to segment the speech waveform into phonemeco-articulation, Fujimura suggests that place, manner and other articulatory features be thought of as asynchronous processes, which have a certain amount of freedom to overlap in time. (18a) &amp;quot;Speech is commonly viewed as the result of concatenating phonetic segments. In most discussions of the temporal structure of speech, a segment in such a model is assumed to represent a phoneme-sized phonetic unit, which possesses an inherent [invariant] target value in terms of articulation or acoustic manifestation. Any deviation from such an interpretation of observed phenomena requires special attention ... [Biased on some preliminary results of X-ray microbcam studies [which associate lip, tongue and jaw movements with phonetic events in the utterance&apos;, it will be suggested that understanding articulatory processes, which are inherently multi-dimensional [and (more or less) asynchronous&apos;, may be essential for a successful description of temporal structures of speech.&amp;quot; [9 p. 664 In light of Fujimura&apos;s suggestion, I might re-interpret my parser as a highly parallel feature-based asynchronous architecture. For example, the parser can process homorganic nasal clusters by processing place and manner phrases in parallel, and then synchronizing the results at the coda node with M&amp;. That is, (17a) can be computed in parallel with and the results arc aligned when the coda is computed with as illustrated below for the word that the front end produces the following analysis: dental: vowel: stop: nasalization: where many of the features overlap in an asynchronous way. The parser will correctly locate the coda by intersecting the nasal cluster lattice (computed with (17a)) with the homorganic lattice (computed with (17b)). nasal cluster: homorganic: coda: This parser is a bold departure from a standard practice in two respects: (1) the input stream is feature-based rather than segmental, and (2) the output parse is a hcterarchy of overlapping constituents (e.g., place and manner phrases) as opposed to a list of hierarchical parse-trees. I find these two modifications most exciting and worthy of further investigation. In summary, two points have been made. First. I suggested the use of parsing techniques at the segmental/feature level in speech applications. Secondly, I introduced M&amp; as a possible solution to the agreement/co-articulation problem. 3. Acknowledgements I have received a considerable amount of help and support over the course of this project. Let mc mention just a few of the people that I should thank: Jon Allen, Glenn Burke, Francine Chen, Scott Cyphers,</abstract>
<author confidence="0.716672666666667">Margaret Fleck Dan Huttenlocher Jay Keyser Lori Lamel</author>
<author confidence="0.716672666666667">Ramesh Pull Janet Picrrehumbert</author>
<author confidence="0.716672666666667">Dave Shipman</author>
<author confidence="0.716672666666667">Pete Szolovits Meg Withgott</author>
<author confidence="0.716672666666667">Victor Zue</author>
<affiliation confidence="0.336422">References</affiliation>
<address confidence="0.260638">Barnwell, T., Algorithm for Segment Durations in a</address>
<affiliation confidence="0.7807396">Machine Context, doctoral dissertation, department of Electrical Engineering and Science, Chomsky. N. and Halle, M., Sound Pattern of English, &amp; Row,</affiliation>
<address confidence="0.482421">Church, K., On in Natural Language</address>
<note confidence="0.963903485714286">Thesis, MIT, Mr17LCS/TR-245, 1980 (also available from Indiana University Linguistics Club). t 96 Church, K., Parsing: A Method jiff Taking of Allophonic Constraints, doctoral dissertation, department of Electrical Engineering and Computer Science, MIT, 1983 (also to appear. LCS and RLE publications, MIT). Cole, R., and Jakimik, A Model of Speech Perception, Cole (ed.), and Production of Fluent Speech, Lawrence Erlbaum, Hillsdale, N.J., 1980. Dostcrt, B., and Thompson, F., Features Resolve Ambiguity, Proceedings of the Symposium on Information Storage and Retrieval, Minker, J., and Rosenfeld, S. (ed.), 1971. Earley, J., Efficient Context-Free Parsing Algorithm, CACM, 13:2, February, 1970. Fry, D., and Intensity as Physical Correlates of Stress, 17:4, 1955, (reprinted in Lehiste in Acoustic Phonetics, Press, 1967.) Fujimura, 0., Organization of Articulatory Move as tfultidimensional Phrasal Structure, 33: pp. 66-83, 1981. 10. 0., and Lovins, J., as Concatenative Units, University Linguistics Club, 1982. Gazdar, G., Structure Grammar, P. Jacobson and Pullum (eds.), Nature of Syntactic Representation, D. Reidel, Dordrecht, in press, 1982. Heffner, R., Phonetics, University of Wisconsin Press, 1960. Kahn, Syllable- Based Generalizations in English Pho- University Linguistics Club, 1976. Kiparsky, P., on the Metrical Structure of the Syl- W. Dressler (ed.) 1980. Proceedings the Fourth International Phonology Meeting, Kiparsky, P., Structure Assignments in Cyclic, Inquiry, 421-441, 1979. Kaplan, R. and Bresnan, J., Grammar: Formal System for Granmiatical Representation, (ed.), Mental Representation of Granunatical Press. 1982. 17. Jelinek, F., course notes, MIT, 1982. Josh&apos;, A., and Levy, L.. Structure Trees Rear More Than You Would Have Thought, 8:1, 1982. Klatt, D., Verification in a Speech Understanding R. Reddy (ed.), Recognition, Papers Presented at the 1974 IEEE Symposium, Academic Press, pp. 321-344, 1974. Klatt, D., of the ARPA Speech Understanding 62:6, December 1977. Klatt, D., and Lafs: Two New Approaches to Speech 25 in W. Lea, in Speech Recog- Flail, 1980. Martin, K., and Patil, R., Analysis of a Breadth-First Parsing Algorithni: Theoretical and Er Results. 1981 (also to in L. 13o1c (cd.), Language Parsing London). Reddy, R., Recognition by Machine: A Review, Proceedings of the IEEE, pp. 501-531, April 1976. Smith, A., Hypothesization in the hearsay-Il Speech IEEE Int. Conf. ASSP, pp. 549-552, 1976. Valient, L., Context Free Recognition in Less Than Time, Computer and System Sciences 10, pp. 308- 315. 1975. Woods, W., Network Grammars for Natural Analysis, 13:10, 1970. Zue, V., and Shattuck-Hufnagcl, S., is a /V not a /V?, ASA, Atlanta, 1980.</note>
<intro confidence="0.467762">97</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Barnwell</author>
</authors>
<title>An Algorithm for Segment Durations in a Reading Machine Context, unpublished doctoral dissertation, department of Electrical Engineering and Computer Science,</title>
<date>1970</date>
<location>mrr,</location>
<contexts>
<context position="1389" citStr="(1)" startWordPosition="204" endWordPosition="204">ition. In syllable initial position (e.g., Tom), It/ is almost always released (with a strong burst of energy) and aspirated (with h-like noise), whereas in syllable final position (e.g., cal), /t/ is often unreleased and unaspirated. It is common practice in speech research to distinguish acoustic/phonetic properties that vary a great deal with context (e.g., release and aspiration) from those that are relatively invariant to context (e.g., place, manner and voicing).2 In the past, the emphasis has been on invariants; allophonic variation is traditionally seen as problematic for recognition. (1) &amp;quot;In most systems for sentence recognition, such modifications must be viewed as a kind of &apos;noise&apos; that makes it more difficult to hypothesize lexical candidates given an input phonetic transcription. To see that this must be the case, we note that each phonological rule [in an example to be presented below] I. This research was supported (in part) by the National 1nstitutes of Ilealth Grant No. I POI 1M 03374-01 and 03374-02 from the National Library of Medicine. 2. Place refers to the location of the constriction in the vocal tract. fIxamples include: labial (at the lips) /p, b. f, v. m/. ve</context>
<context position="23282" citStr="(1)" startWordPosition="3804" endWordPosition="3804">oda node with M&amp;. That is, (17a) can be computed in parallel with (1M). and then the results arc aligned when the coda is computed with (16). as illustrated below for the word tent. Imagine that the front end produces the following analysis: dental: vowel: stop: nasalization: where many of the features overlap in an asynchronous way. The parser will correctly locate the coda by intersecting the nasal cluster lattice (computed with (17a)) with the homorganic lattice (computed with (17b)). nasal cluster: homorganic: coda: This parser is a bold departure from a standard practice in two respects: (1) the input stream is feature-based rather than segmental, and (2) the output parse is a hcterarchy of overlapping constituents (e.g., place and manner phrases) as opposed to a list of hierarchical parse-trees. I find these two modifications most exciting and worthy of further investigation. In summary, two points have been made. First. I suggested the use of parsing techniques at the segmental/feature level in speech applications. Secondly, I introduced M&amp; as a possible solution to the agreement/co-articulation problem. 3. Acknowledgements I have received a considerable amount of help and supp</context>
</contexts>
<marker>1.</marker>
<rawString>Barnwell, T., An Algorithm for Segment Durations in a Reading Machine Context, unpublished doctoral dissertation, department of Electrical Engineering and Computer Science, mrr, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N</author>
<author>M Halle</author>
</authors>
<title>The Sound Pattern of English,</title>
<date>1968</date>
<location>Harper &amp; Row,</location>
<contexts>
<context position="13422" citStr="(2, 4)" startWordPosition="2198" endWordPosition="2199">ntence and a context-free grammar and produces as output a chart like that below, indicating the starting point and ending point of each phrase in the input string. liap.L.4 alarm: 0 They I are 2 flying 3 planes 4 G rammar: N they V are dying A flying V flying N •—■ planes S NP VP VP --* V NP VP --■ V VP NP NP --■ AP NP NP --. VP AP --+ A Chart: I° 0 { } rs:P.N,they} {} (1 2 fl { } 3 {1 {} 4 1 ( 1 Each entry in the chart represents the possible analyses of the input words between a start position (the row index) and a finish position (the column index). For example, the entry {NP, VP) in Chart(2, 4) represents two alternative analyses of the words between 2 and 4: „flying planes] and [vp flying planesi. [NI The same parsing methods can be used to find syllable structure from an input transcription. Chart: o (1 tff,onsetsodal ) { { } I I This chart shows that the input sentence can be decomposed into two syllables, one from 0 to 3 (this) and another one from 4 to 5 (is). Alternatively, the input sentence can be decomposed into [1&apos;t biz]. In this way, standard chart parsing techniques can be adopted to process allophonic and phonotactic constraints, if the constraints are reformulated in t</context>
<context position="23347" citStr="(2)" startWordPosition="3814" endWordPosition="3814"> (1M). and then the results arc aligned when the coda is computed with (16). as illustrated below for the word tent. Imagine that the front end produces the following analysis: dental: vowel: stop: nasalization: where many of the features overlap in an asynchronous way. The parser will correctly locate the coda by intersecting the nasal cluster lattice (computed with (17a)) with the homorganic lattice (computed with (17b)). nasal cluster: homorganic: coda: This parser is a bold departure from a standard practice in two respects: (1) the input stream is feature-based rather than segmental, and (2) the output parse is a hcterarchy of overlapping constituents (e.g., place and manner phrases) as opposed to a list of hierarchical parse-trees. I find these two modifications most exciting and worthy of further investigation. In summary, two points have been made. First. I suggested the use of parsing techniques at the segmental/feature level in speech applications. Secondly, I introduced M&amp; as a possible solution to the agreement/co-articulation problem. 3. Acknowledgements I have received a considerable amount of help and support over the course of this project. Let mc mention just a few of</context>
</contexts>
<marker>2.</marker>
<rawString>Chomsky. N. and Halle, M., The Sound Pattern of English, Harper &amp; Row, 1968.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>On ;Slentory Limitations in Natural Language Processing, MS Thesis,</title>
<date>1980</date>
<institution>Indiana University Linguistics Club).</institution>
<location>MIT, Mr17LCS/TR-245,</location>
<note>also available from</note>
<contexts>
<context position="4046" citStr="(3)" startWordPosition="652" endWordPosition="652">rovides a rich source of constraints on syllable structure and word stress. The recognizer to be discussed here (and partly implemented in Church (41) is designed to exploit allophonic and phonotactic cues by parsing the input utterance into syllables and other suprasegmental constituents using phrasestructure parsing techniques. 1.1 An Example of Lexical Retrieval It might be helpful to work out an example in order to illustrate how parsing can play a role in lexical retrieval. Consider the phonetic transcription, mentioned above in the citation from Klatt [20, p. 1346] [21, pp. 548-5491: 91 (3) [d1lahl[11.1 taml It is desired to decode (3) into the string of words: (4) Did you hit it to Tom? In practice, the lexical retrieval problem is complicated by errors in the front end. However, even with an ideal error-free front-end, it is difficult to decode (3) because, among other things, there arc extensive rule-governed changes affecting the way that words arc pronounced in different sentence contexts, as Klan&apos;s example illustrates: (5a) Palatalization of /d/ before /y/ in did you (5b Reduction of unstressed /u/ to schwa in nu (5c) Flapping of intervocalic /t/ in hit it (5d) Reduction o</context>
<context position="20564" citStr="(3)" startWordPosition="3417" endWordPosition="3417">ons (in the weak generative capacity sense), I may, nevertheless, wish to introduce additional mechanism in order to account for agreement facts in a natural way. As discussed above, the formulation of the homorganic rule in (15) is unattractive because it splits the rule into three cases, one for each place of articulation. It would be preferable to state the agreement constraint just once, by defining a homorganic nasal cluster to be a nasal cluster 10. I personally hold a much more controversial position, that finite state grammars are sufficient for most if not all, natural language tasks (3). 95 subject to place assimilation.. In ifly language of matrix operations. I can say just exactly that: (16) (setq homorganic-nasal-cluster-lattice (M&amp; nasal-cluster-lattice place-assimilation)) where M&amp; (element-wise intersection) implements the subject to constraint. Nasal-cluster and place-assimilation are defined as: (17a) (setq nasal-cluster-lattice (Ms nasal-lattice obstruent-lattice)) (17b) (setq place-assimilation-lattice (M+ (M** labial-lattice) (M** dental-lattice) (M&amp;quot; velar-lattice))) In this way, M&amp; seems to be an attractive solution to the agreement problem. In addition, M&amp; might</context>
</contexts>
<marker>3.</marker>
<rawString>Church, K., On ;Slentory Limitations in Natural Language Processing, MS Thesis, MIT, Mr17LCS/TR-245, 1980 (also available from Indiana University Linguistics Club).</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Church</author>
</authors>
<title>Phrase-Structure Parsing: A Method jiff Taking Advantage of Allophonic Constraints, unpublished doctoral dissertation, department of Electrical Engineering and Computer Science, MIT,</title>
<date>1983</date>
<note>(also to appear. LCS and RLE publications, MIT).</note>
<contexts>
<context position="18724" citStr="[4]" startWordPosition="3137" endWordPosition="3137">lity matrices may be less sparse and consequently less efficient. Fig. 3. Mso, Momer, and M rhyme or. 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 0 1 1 0 0 0 1 0 0 0 0 0 0 0 0 0 0 0 0 1 1 0 0 0 0 0 1 0 0 0 0 1 1 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 The matrices tend to be very sparse (almost entirely full of O&apos;s) because syllable grammars are highly constrained. In principle, there could be n2 entries. However, it can be shown that c (the number of l&apos;s) is linearly related to n because syllables have finite length. In Church [4], sharpen this result by arguing that c tends to be bounded by 4n as a consequence of a phonotactic principle known as sonority. Many more edges will be ruled out by a number of other linguistic constraints mentioned above: voicing and place assimilation, aspiration, flapping, etc. In short, these matrices are sparse because allophonic and phonotactic constraints are useful. (15) (setq homorganic-nasal-lattice (M + (Ms (phoneme-lattice rt /m) labial-lattice) (Ms (phoneme-lattice # /n) coronal-lattice) (Ms (phoneme-lattice #/G) velar-lattice))) illustrating the use of M+ (matrix addition) to ex</context>
</contexts>
<marker>4.</marker>
<rawString>Church, K., Phrase-Structure Parsing: A Method jiff Taking Advantage of Allophonic Constraints, unpublished doctoral dissertation, department of Electrical Engineering and Computer Science, MIT, 1983 (also to appear. LCS and RLE publications, MIT).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cole</author>
<author>J Jakimik</author>
</authors>
<title>A Model of Speech Perception,</title>
<date>1980</date>
<booktitle>Perception and Production of Fluent Speech, Lawrence Erlbaum,</booktitle>
<editor>in R. Cole (ed.),</editor>
<location>Hillsdale, N.J.,</location>
<contexts>
<context position="2993" citStr="[5]" startWordPosition="482" endWordPosition="482">logical rule does not have a unique inverse that could be used to recover the underlying phonemic representation for a lexical item. For example, ... schwa vowels could be the first vowel in is word like &apos;about&apos; or the surface realization of almost any English vowel appearing in a sufficiently &amp;stressed word. The tongue flap [C1 could have come from a /t/ or a /d/.&amp;quot; Klatt (Nun [21, pp. 548-5491 This view of allophonic variation is representative of much of the speech recognition literature, especially during the ARPA speech project. One can find similar statements by Cole and ,Jakirnik (CM U) [5] and by Jelinek (IBM) [171. I prefer to think of variation as useful. It is well known that allophonic contrasts can be distinctive, as illustrated by the following famous minimal pairs where the crucial distinctions seem to lie in the allophonic realization of the /t/: a tease / at ease aspirated / flapped night rate / nitrate unreleased / retroflexed great wine / gray twine unreleased / rounded This evidence suggests that allophonic variation provides a rich source of constraints on syllable structure and word stress. The recognizer to be discussed here (and partly implemented in Church (41)</context>
</contexts>
<marker>5.</marker>
<rawString>Cole, R., and Jakimik, J., A Model of Speech Perception, in R. Cole (ed.), Perception and Production of Fluent Speech, Lawrence Erlbaum, Hillsdale, N.J., 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Dostcrt</author>
<author>F Thompson</author>
</authors>
<title>How Features Resolve Syntactic Ambiguity,</title>
<date>1971</date>
<booktitle>in Proceedings of the Symposium on Information Storage</booktitle>
<editor>and Retrieval, Minker, J., and Rosenfeld, S. (ed.),</editor>
<contexts>
<context position="16625" citStr="[6, 22]" startWordPosition="2707" endWordPosition="2708">he velar stop /k/. This constraint, like subject-verb agreement, poses a problem for pure unaugmented context-free rules; it seems to be necessary to expand out each of the three cases: (13a) homorganic-nasal-cluster labial-nasal labial-obstruent (13b) homorganic-nasal-cluster coronal-nasal coronal-obstruent (13c) homorganic-nasal-cluster —■ velar-nasal velar-obstruent In an effort to alleviate this expansion problem, many researchers have proposed augmentations of various sorts (e.g., ATN registers [26], LFG constraint equations [16], GPSG meta-rules [Ill, local constraints (18], bit vectors [6, 22]). My own solution will be suggested after I have had a chance to describe the parser in further detail. L2 A Parser Based on Matrix Operations This section will show how the grammar can be implemented in terms of operations on binary matrices. Suppose that the chart is decomposed into a sum of binary matrices: (14) Chart = syl Ms)/ + onset Monset ± peak Mpeak where Msyi is a binary matrix8 describing the location of syllables and Monset is a binary matrix describing the location of onsets. and so forth. Each of these binary matrices has a 1 in position (i, j) if there is a constituent of the </context>
</contexts>
<marker>6.</marker>
<rawString>Dostcrt, B., and Thompson, F., How Features Resolve Syntactic Ambiguity, in Proceedings of the Symposium on Information Storage and Retrieval, Minker, J., and Rosenfeld, S. (ed.), 1971.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Earley</author>
</authors>
<title>An Efficient Context-Free Parsing Algorithm,</title>
<date>1970</date>
<journal>CACM,</journal>
<pages>13--2</pages>
<contexts>
<context position="8355" citStr="(7)" startWordPosition="1380" endWordPosition="1380">ms: (a) parse the segment lattice into syllable structure, and (b) match the resulting constituents against the lexicon. I will illustrate the approach with Fig. I. 1)id you lilt it to Tom? 7&apos;.. (.....nd.) a 0.9 1.0 1.1 13 1.3 1.• 1.e 0.0 - 0,1 &apos; 0.1 • 9,3 - 0.4 —9 6-9i —r .6-91--- 0-i- -- _. 16. 4 . Zef.0 Greasily, Rata 9&apos;i &apos; .. , • &apos; ,... Tout Cri•ray ; , 0 as ;10 1 1.rtergy —.---,26,-;-.17,-7,1tri-,...., • tee liii. &apos;ill &apos;dill&apos; #0,010.-401-4111P100-- I .— I . L I —.I LI I I Did you hit it to Tom 92 Klatt&apos;s example (enhanced with allophonic diacritics to show aspiration and glottalization): (7) [drjahl[11 thi tham] TT T Using phonotactic and allophonic constraints on syllable structure such as:3 Lax vowels are restricted to closed syllables (syllables ending in a consonant) RI. However, in this case. Ill cannot meet the closed syllable restriction because the following consonant is aspirated (and therefore syllable initial). Thus the transcription is internally inconsistent. The parser should probably reject die transcrintinn and hope that the front end can fix the problem. Alternatively, the parser might attempt to correct the error by hypothesizing a second /t/.4 (8a) /h/ is alway</context>
</contexts>
<marker>7.</marker>
<rawString>Earley, J., An Efficient Context-Free Parsing Algorithm, CACM, 13:2, February, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Fry</author>
</authors>
<title>Duration and Intensity as Physical Correlates of Linguistic Stress,</title>
<date>1967</date>
<booktitle>JASA 17:4, 1955, (reprinted in Lehiste (ed.), Readings in Acoustic Phonetics,</booktitle>
<publisher>MIT Press,</publisher>
<contexts>
<context position="9732" citStr="[8]" startWordPosition="1585" endWordPosition="1585"> overlap. Consider the pairs (Sc) n is always syllable final, and allophonic found in figure 2, where there are multiple arguments for assigning the (8d) [till is always syllable initial. allophonic crucial syllable boundary. In de-prive vs. dep-rivation, for instance, the the parser can insert the following syllable boundaries: difference is revealed by the vowel argument above5 and by the (9) (dna # # chi tharn] aspiration rule.6 In addition, the stress contrast will probably be correlated with a number of so-called &apos;suprasegmental&apos; cues, e.g., duration, fundamental frequency, and intensity [8]. It is now it is relatively easy to decode the utterance with lexical matching routines similar to those in Smith&apos;s Noah program at CMU [241. parsed transcription decoding cup —4 did you hic hit it thf to tham Tom In summary. I believe that the lexical retrieval device will be in a superior position to hypothesize word candidates if it exploits allophonic and phonotactic constraints on syllable structure. 1.4 Exploiting Redundancy In many cases, allophonic and phonotactic constraints are redundant. Even if the parser should miss a few of the cues for syllable structure, it will often be able </context>
</contexts>
<marker>8.</marker>
<rawString>Fry, D., Duration and Intensity as Physical Correlates of Linguistic Stress, JASA 17:4, 1955, (reprinted in Lehiste (ed.), Readings in Acoustic Phonetics, MIT Press, 1967.)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fujimura</author>
</authors>
<title>Temporal Organization of Articulatory Move ments as tfultidimensional</title>
<date>1981</date>
<journal>Phrasal Structure, Phonctica,</journal>
<volume>33</volume>
<pages>66--83</pages>
<contexts>
<context position="9526" citStr="(9)" startWordPosition="1554" endWordPosition="1554">a second /t/.4 (8a) /h/ is always syllable initial, phonotactic There are many other examples like (10) where phonotactic (8b) [Li is always syllable final, allophonic constraints and allophonic constraints overlap. Consider the pairs (Sc) n is always syllable final, and allophonic found in figure 2, where there are multiple arguments for assigning the (8d) [till is always syllable initial. allophonic crucial syllable boundary. In de-prive vs. dep-rivation, for instance, the the parser can insert the following syllable boundaries: difference is revealed by the vowel argument above5 and by the (9) (dna # # chi tharn] aspiration rule.6 In addition, the stress contrast will probably be correlated with a number of so-called &apos;suprasegmental&apos; cues, e.g., duration, fundamental frequency, and intensity [8]. It is now it is relatively easy to decode the utterance with lexical matching routines similar to those in Smith&apos;s Noah program at CMU [241. parsed transcription decoding cup —4 did you hic hit it thf to tham Tom In summary. I believe that the lexical retrieval device will be in a superior position to hypothesize word candidates if it exploits allophonic and phonotactic constraints on syll</context>
</contexts>
<marker>9.</marker>
<rawString>Fujimura, 0., Temporal Organization of Articulatory Move ments as tfultidimensional Phrasal Structure, Phonctica, 33: pp. 66-83, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Lovins</author>
</authors>
<title>Syllables as Concatenative Phonetic Units,</title>
<date>1982</date>
<institution>Indiana University Linguistics Club,</institution>
<contexts>
<context position="9026" citStr="(10)" startWordPosition="1480" endWordPosition="1480">ints on syllable structure such as:3 Lax vowels are restricted to closed syllables (syllables ending in a consonant) RI. However, in this case. Ill cannot meet the closed syllable restriction because the following consonant is aspirated (and therefore syllable initial). Thus the transcription is internally inconsistent. The parser should probably reject die transcrintinn and hope that the front end can fix the problem. Alternatively, the parser might attempt to correct the error by hypothesizing a second /t/.4 (8a) /h/ is always syllable initial, phonotactic There are many other examples like (10) where phonotactic (8b) [Li is always syllable final, allophonic constraints and allophonic constraints overlap. Consider the pairs (Sc) n is always syllable final, and allophonic found in figure 2, where there are multiple arguments for assigning the (8d) [till is always syllable initial. allophonic crucial syllable boundary. In de-prive vs. dep-rivation, for instance, the the parser can insert the following syllable boundaries: difference is revealed by the vowel argument above5 and by the (9) (dna # # chi tharn] aspiration rule.6 In addition, the stress contrast will probably be correlated </context>
<context position="10508" citStr="(10)" startWordPosition="1716" endWordPosition="1716"> cup —4 did you hic hit it thf to tham Tom In summary. I believe that the lexical retrieval device will be in a superior position to hypothesize word candidates if it exploits allophonic and phonotactic constraints on syllable structure. 1.4 Exploiting Redundancy In many cases, allophonic and phonotactic constraints are redundant. Even if the parser should miss a few of the cues for syllable structure, it will often be able to find the correct structure by taking advantage of some other redundant cue. For example, suppose that the front end failed to notice die glottalized /t/ in the word it. (10) aria # hl[ # I # tha # tham The parser could deduce that the input transcription (10) is internally inconsistent, because of a phonotactic constraint on the lax vowel /I/. 3. This formulation of the constraints is oversimplified for expository convenience; see 110. 13, 151 and references therein for discussion of the more subtle issues. In general, there seem to be a large number of multiple low level cues for syllable structure. This observation, if correct, could be viewed as a form of a &apos;constituency hypothesis&apos;. Just as syntacticians have argued for the constituent-hood of noun phrases, v</context>
</contexts>
<marker>10.</marker>
<rawString>1-7ujimura, 0., and Lovins, J., Syllables as Concatenative Phonetic Units, Indiana University Linguistics Club, 1982.</rawString>
</citation>
<citation valid="false">
<authors>
<author>G Gazdar</author>
</authors>
<title>Phrase Structure Grammar,</title>
<booktitle>The Nature of Syntactic Representation,</booktitle>
<pages>1982</pages>
<editor>in P. Jacobson and G. Pullum (eds.),</editor>
<marker>11.</marker>
<rawString>Gazdar, G., Phrase Structure Grammar, in P. Jacobson and G. Pullum (eds.), The Nature of Syntactic Representation, D. Reidel, Dordrecht, in press, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Heffner</author>
<author>General Phonetics</author>
</authors>
<date>1960</date>
<publisher>The University of Wisconsin Press,</publisher>
<marker>12.</marker>
<rawString>Heffner, R., General Phonetics, The University of Wisconsin Press, 1960.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kahn</author>
</authors>
<title>Syllable- Based Generalizations in English Phonology,</title>
<date>1976</date>
<institution>Indiana University Linguistics Club,</institution>
<contexts>
<context position="17472" citStr="(13)" startWordPosition="2857" endWordPosition="2857">. Suppose that the chart is decomposed into a sum of binary matrices: (14) Chart = syl Ms)/ + onset Monset ± peak Mpeak where Msyi is a binary matrix8 describing the location of syllables and Monset is a binary matrix describing the location of onsets. and so forth. Each of these binary matrices has a 1 in position (i, j) if there is a constituent of the appropriate part of speech spanning from the ith position in the input sentence to the jth position.9 (See figure 3). Phrase-structure rules will be implemented with simple operations on these binary matrices. For example, the homorganic rule (13) could be implemented as: 8. Mese matnas will sometimes be called segmentation lattices for historical reasons. Technically. these matnces need not conform to the restrictions of a lattice, and therefore, the weaker term graph LS more correct 9 In a probabilistic framework, one could replace all of the I &apos;sand O&apos;s with probabilities. A high probability in location (i.p of the syllable matnx would say that there probably is a syllable from position ito position I: a low probability would say that there probably isn&apos;t a syllable between land j. Most of the following applies to probability matric</context>
</contexts>
<marker>13.</marker>
<rawString>Kahn, D., Syllable- Based Generalizations in English Phonology, Indiana University Linguistics Club, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kiparsky</author>
</authors>
<title>Remarks on the Metrical Structure of the Syllable,</title>
<date>1981</date>
<booktitle>Phonologica 1980. Proceedings of the Fourth International Phonology Meeting,</booktitle>
<editor>in W. Dressler (ed.)</editor>
<contexts>
<context position="16942" citStr="(14)" startWordPosition="2764" endWordPosition="2764">rganic-nasal-cluster —■ velar-nasal velar-obstruent In an effort to alleviate this expansion problem, many researchers have proposed augmentations of various sorts (e.g., ATN registers [26], LFG constraint equations [16], GPSG meta-rules [Ill, local constraints (18], bit vectors [6, 22]). My own solution will be suggested after I have had a chance to describe the parser in further detail. L2 A Parser Based on Matrix Operations This section will show how the grammar can be implemented in terms of operations on binary matrices. Suppose that the chart is decomposed into a sum of binary matrices: (14) Chart = syl Ms)/ + onset Monset ± peak Mpeak where Msyi is a binary matrix8 describing the location of syllables and Monset is a binary matrix describing the location of onsets. and so forth. Each of these binary matrices has a 1 in position (i, j) if there is a constituent of the appropriate part of speech spanning from the ith position in the input sentence to the jth position.9 (See figure 3). Phrase-structure rules will be implemented with simple operations on these binary matrices. For example, the homorganic rule (13) could be implemented as: 8. Mese matnas will sometimes be called segm</context>
</contexts>
<marker>14.</marker>
<rawString>Kiparsky, P., Remarks on the Metrical Structure of the Syllable, in W. Dressler (ed.) Phonologica 1980. Proceedings of the Fourth International Phonology Meeting, 1981.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Kiparsky</author>
</authors>
<title>Metrical Structure Assignments in Cyclic,</title>
<date>1979</date>
<journal>I.inguistic Inquiry,</journal>
<volume>10</volume>
<pages>421--441</pages>
<contexts>
<context position="19106" citStr="(15)" startWordPosition="3198" endWordPosition="3198">s) because syllable grammars are highly constrained. In principle, there could be n2 entries. However, it can be shown that c (the number of l&apos;s) is linearly related to n because syllables have finite length. In Church [4], sharpen this result by arguing that c tends to be bounded by 4n as a consequence of a phonotactic principle known as sonority. Many more edges will be ruled out by a number of other linguistic constraints mentioned above: voicing and place assimilation, aspiration, flapping, etc. In short, these matrices are sparse because allophonic and phonotactic constraints are useful. (15) (setq homorganic-nasal-lattice (M + (Ms (phoneme-lattice rt /m) labial-lattice) (Ms (phoneme-lattice # /n) coronal-lattice) (Ms (phoneme-lattice #/G) velar-lattice))) illustrating the use of M+ (matrix addition) to express the union of several alternatives and M* (matrix multiplication) to express the concatenation of subparts. It is well known that any finite-state grammar could be implemented in this way with just three matrix operations: Ms, M+, and M** (transitive closure). If context-free power were required. Valient&apos;s algorithm [25] could be employed. However, since there doesn&apos;t seem t</context>
</contexts>
<marker>15.</marker>
<rawString>Kiparsky, P., Metrical Structure Assignments in Cyclic, I.inguistic Inquiry, 10, pp. 421-441, 1979.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kaplan</author>
<author>J Bresnan</author>
</authors>
<title>Lexical-Functional Grammar: A Formal System for Granmiatical Representation,</title>
<date>1982</date>
<booktitle>The Mental Representation of Granunatical Relations,</booktitle>
<editor>in Bresnan (ed.),</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="16558" citStr="[16]" startWordPosition="2698" endWordPosition="2698">/ before the corona! stop /t/, and the velar nasal krj/ before the velar stop /k/. This constraint, like subject-verb agreement, poses a problem for pure unaugmented context-free rules; it seems to be necessary to expand out each of the three cases: (13a) homorganic-nasal-cluster labial-nasal labial-obstruent (13b) homorganic-nasal-cluster coronal-nasal coronal-obstruent (13c) homorganic-nasal-cluster —■ velar-nasal velar-obstruent In an effort to alleviate this expansion problem, many researchers have proposed augmentations of various sorts (e.g., ATN registers [26], LFG constraint equations [16], GPSG meta-rules [Ill, local constraints (18], bit vectors [6, 22]). My own solution will be suggested after I have had a chance to describe the parser in further detail. L2 A Parser Based on Matrix Operations This section will show how the grammar can be implemented in terms of operations on binary matrices. Suppose that the chart is decomposed into a sum of binary matrices: (14) Chart = syl Ms)/ + onset Monset ± peak Mpeak where Msyi is a binary matrix8 describing the location of syllables and Monset is a binary matrix describing the location of onsets. and so forth. Each of these binary ma</context>
</contexts>
<marker>16.</marker>
<rawString>Kaplan, R. and Bresnan, J., Lexical-Functional Grammar: A Formal System for Granmiatical Representation, in Bresnan (ed.), The Mental Representation of Granunatical Relations, MIT Press. 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Jelinek</author>
</authors>
<title>course notes,</title>
<date>1982</date>
<location>MIT,</location>
<marker>17.</marker>
<rawString>Jelinek, F., course notes, MIT, 1982.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Josh&apos;</author>
<author>L Levy</author>
</authors>
<title>Phrase Structure Trees Rear More Fruit Than You Would Have Thought,</title>
<volume>1</volume>
<pages>1982</pages>
<marker>18.</marker>
<rawString>Josh&apos;, A., and Levy, L.. Phrase Structure Trees Rear More Fruit Than You Would Have Thought, AJC1., 8:1, 1982.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klatt</author>
</authors>
<title>Word Verification in a Speech Understanding System,</title>
<date>1974</date>
<booktitle>Speech Recognition, Invited Papers Presented at the 1974 IEEE Symposium,</booktitle>
<pages>321--344</pages>
<editor>in R. Reddy (ed.),</editor>
<publisher>Academic Press,</publisher>
<marker>19.</marker>
<rawString>Klatt, D., Word Verification in a Speech Understanding System, in R. Reddy (ed.), Speech Recognition, Invited Papers Presented at the 1974 IEEE Symposium, Academic Press, pp. 321-344, 1974.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klatt</author>
</authors>
<title>Review of the ARPA Speech Understanding Project,</title>
<date>1977</date>
<journal>JASA,</journal>
<pages>62--6</pages>
<marker>20.</marker>
<rawString>Klatt, D., Review of the ARPA Speech Understanding Project, JASA, 62:6, December 1977.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klatt</author>
</authors>
<title>Scriber and Lafs: Two New Approaches to Speech Analysis,</title>
<date>1980</date>
<publisher>Prentice- Flail,</publisher>
<note>chapter 25 in</note>
<marker>21.</marker>
<rawString>Klatt, D., Scriber and Lafs: Two New Approaches to Speech Analysis, chapter 25 in W. Lea, Trends in Speech Recognition, Prentice- Flail, 1980.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Martin</author>
<author>K Church</author>
<author>R Patil</author>
</authors>
<title>Preliminary Analysis of a Breadth-First Parsing Algorithni: Theoretical and Er pet-internal Results.</title>
<date>1981</date>
<tech>MIT/LCS/TR-261,</tech>
<location>Macmillan, London).</location>
<contexts>
<context position="16625" citStr="[6, 22]" startWordPosition="2707" endWordPosition="2708">he velar stop /k/. This constraint, like subject-verb agreement, poses a problem for pure unaugmented context-free rules; it seems to be necessary to expand out each of the three cases: (13a) homorganic-nasal-cluster labial-nasal labial-obstruent (13b) homorganic-nasal-cluster coronal-nasal coronal-obstruent (13c) homorganic-nasal-cluster —■ velar-nasal velar-obstruent In an effort to alleviate this expansion problem, many researchers have proposed augmentations of various sorts (e.g., ATN registers [26], LFG constraint equations [16], GPSG meta-rules [Ill, local constraints (18], bit vectors [6, 22]). My own solution will be suggested after I have had a chance to describe the parser in further detail. L2 A Parser Based on Matrix Operations This section will show how the grammar can be implemented in terms of operations on binary matrices. Suppose that the chart is decomposed into a sum of binary matrices: (14) Chart = syl Ms)/ + onset Monset ± peak Mpeak where Msyi is a binary matrix8 describing the location of syllables and Monset is a binary matrix describing the location of onsets. and so forth. Each of these binary matrices has a 1 in position (i, j) if there is a constituent of the </context>
</contexts>
<marker>22.</marker>
<rawString>Martin, W., Church, K., and Patil, R., Preliminary Analysis of a Breadth-First Parsing Algorithni: Theoretical and Er pet-internal Results. MIT/LCS/TR-261, 1981 (also to appear in L. 13o1c (cd.), Natural Language Parsing Systems, Macmillan, London).</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Reddy</author>
</authors>
<title>Speech Recognition by Machine: A Review,</title>
<date>1976</date>
<booktitle>Proceedings of the IEEE,</booktitle>
<pages>501--531</pages>
<marker>23.</marker>
<rawString>Reddy, R., Speech Recognition by Machine: A Review, Proceedings of the IEEE, pp. 501-531, April 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Smith</author>
</authors>
<title>Word Hypothesization in the hearsay-Il Speech System,</title>
<date>1976</date>
<booktitle>Proc. IEEE Int. Conf. ASSP,</booktitle>
<pages>549--552</pages>
<marker>24.</marker>
<rawString>Smith, A., Word Hypothesization in the hearsay-Il Speech System, Proc. IEEE Int. Conf. ASSP, pp. 549-552, 1976.</rawString>
</citation>
<citation valid="false">
<authors>
<author>L Valient</author>
</authors>
<title>General Context Free Recognition in Less Than Cubic Time,</title>
<journal>J. Computer and System Sciences</journal>
<volume>10</volume>
<pages>308</pages>
<contexts>
<context position="19651" citStr="[25]" startWordPosition="3273" endWordPosition="3273">use allophonic and phonotactic constraints are useful. (15) (setq homorganic-nasal-lattice (M + (Ms (phoneme-lattice rt /m) labial-lattice) (Ms (phoneme-lattice # /n) coronal-lattice) (Ms (phoneme-lattice #/G) velar-lattice))) illustrating the use of M+ (matrix addition) to express the union of several alternatives and M* (matrix multiplication) to express the concatenation of subparts. It is well known that any finite-state grammar could be implemented in this way with just three matrix operations: Ms, M+, and M** (transitive closure). If context-free power were required. Valient&apos;s algorithm [25] could be employed. However, since there doesn&apos;t seem to be a need for additional generative capacity in speech applications, the system is restricted to handle only the simpler finite state case.10 2.3 Feature Manipulation Although &amp;quot;pure&amp;quot; unaugmented finite state grammars may be adequate for speech applications (in the weak generative capacity sense), I may, nevertheless, wish to introduce additional mechanism in order to account for agreement facts in a natural way. As discussed above, the formulation of the homorganic rule in (15) is unattractive because it splits the rule into three cases,</context>
</contexts>
<marker>25.</marker>
<rawString>Valient, L., General Context Free Recognition in Less Than Cubic Time, J. Computer and System Sciences 10, pp. 308-</rawString>
</citation>
<citation valid="false">
<date>1975</date>
<marker>315.</marker>
<rawString>1975.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Woods</author>
</authors>
<title>Transition Network Grammars for Natural Language Analysis,</title>
<date>1970</date>
<location>CACM, 13:10,</location>
<contexts>
<context position="16527" citStr="[26]" startWordPosition="2694" endWordPosition="2694"> stop /p/, the coronal nasal /n/ before the corona! stop /t/, and the velar nasal krj/ before the velar stop /k/. This constraint, like subject-verb agreement, poses a problem for pure unaugmented context-free rules; it seems to be necessary to expand out each of the three cases: (13a) homorganic-nasal-cluster labial-nasal labial-obstruent (13b) homorganic-nasal-cluster coronal-nasal coronal-obstruent (13c) homorganic-nasal-cluster —■ velar-nasal velar-obstruent In an effort to alleviate this expansion problem, many researchers have proposed augmentations of various sorts (e.g., ATN registers [26], LFG constraint equations [16], GPSG meta-rules [Ill, local constraints (18], bit vectors [6, 22]). My own solution will be suggested after I have had a chance to describe the parser in further detail. L2 A Parser Based on Matrix Operations This section will show how the grammar can be implemented in terms of operations on binary matrices. Suppose that the chart is decomposed into a sum of binary matrices: (14) Chart = syl Ms)/ + onset Monset ± peak Mpeak where Msyi is a binary matrix8 describing the location of syllables and Monset is a binary matrix describing the location of onsets. and so</context>
</contexts>
<marker>26.</marker>
<rawString>Woods, W., Transition Network Grammars for Natural Language Analysis, CACM, 13:10, 1970.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Zue</author>
<author>S Shattuck-Hufnagcl</author>
</authors>
<title>When is a /V not a /V?,</title>
<date>1980</date>
<location>ASA, Atlanta,</location>
<marker>27.</marker>
<rawString>Zue, V., and Shattuck-Hufnagcl, S., When is a /V not a /V?, ASA, Atlanta, 1980.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>