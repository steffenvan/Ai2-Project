<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000208">
<note confidence="0.602300666666667">
Proceedings of the Workshop on Natural Language Processing in
the Biomedical Domain, Philadelphia, July 2002, pp. 37-44.
Association for Computational Linguistics.
</note>
<title confidence="0.893473">
A Transformational-based Learner for Dependency Grammars in
Discharge Summaries
</title>
<author confidence="0.410826">
David A. Campbell M. Phil., Stephen B. Johnson Ph.D.
</author>
<affiliation confidence="0.993352">
Department of Medical Informatics, Columbia University
</affiliation>
<sectionHeader confidence="0.978624" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999842954545455">
NLP systems will be more portable
among medical domains if acquisition
of semantic lexicons can be
facilitated. We are pursuing lexical
acquisition through the syntactic
relationships of words in medical
corpora. Therefore we require a
syntactic parser which is flexible,
portable, captures head-modifier pairs
and does not require a large training
set. We have designed a dependency
grammar parser that learns through a
transformational-based algorithm.
We propose a novel design for
templates and transformations which
capitalize on the dependency structure
directly and produces human-readable
rules. Our parser achieved a 77%
accurate parse training on only 830
sentences. Further work will evaluate
the usefulness of this parse for lexical
acquisition.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9998915">
Natural Language is a vital medium in
medicine. Health care providers rely on medical
narratives for recording, representing and
sharing complex medical information such as
the description of images, explanation of test
results, or the summary of a patient’s hospital
visit. Natural Language Processing (NLP) tools
have been applied to medical narrative for a
variety of applications, such as triggering
clinical alerts (Friedman, 1997) and document
classification (Wilcox, 2000).
The effort required to create and maintain
NLP systems in the medical setting can be
prohibitive. Most language processors require a
domain-specific semantic lexicon to function
and, so far, these lexica have been created
manually. The time and cost involved in
creating these knowledge structures put limits
on the extensibility and portability of NLP
systems (Hripcsak, 1998). One solution to this
bottleneck is to use machine learning to assist in
categorizing lexemes into semantic classes.
Such a tool could reduce the difficulty in porting
NLP systems from one domain to another.
</bodyText>
<sectionHeader confidence="0.994331" genericHeader="method">
2 Dependency Grammars
</sectionHeader>
<bodyText confidence="0.99982753125">
One approach to semantic categorization is
the use of syntactic features (Kokkinakis, 2001).
This is based on the assumption that lexemes
that share similar syntactic relations to other
lexemes in the corpus will be semantically
similar (Dorr, 2000). The idea of clustering
words based on syntactic features has been well
investigated in general language (Pereira, 1993;
Li, 1998) However, (Harris, 1991) states that
the syntactic relationships are more well-defined
and have less variation in scientific languages
(sublanguages), such as the ones used in medical
texts. Identifying word classes using syntactic
relationships should be simpler and potentially
more useful in these types of languages.
Dependency grammars (Hudson, 1991)
generate parses where words in a sentence are
related directly to the word which is its syntactic
head. Each word, except for the root has exactly
one head, and the structure is a tree. The
analysis does not generate any intermediate
syntactic structures. Figure 1 shows an example
of a sentence with a dependency grammar parse.
There has been interest in learning dependency
grammars from corpora. Collins (Collins, 1996)
used dependencies as the backbone for his
probabilistic parser and there has been work on
learning both probabilistic (Carroll, 1992; Lee,
1999; Paskin, 2001) and transformation based
dependency grammars (Hajic, 1997).
There are a number of attributes of
dependency grammars which make them ideal
for our goal of investigating medical
sublanguage. First, the semantics of a word are
often defined by a feature space of related
words. The head-dependent relationships
generated by a dependency parse can be used as
the relationship for acquisition. Second,
dependency grammars may be a better fit for
parsing medical text. Medical text is frequently
include telegraphic omissions, run-on structures,
improper use of conjunctions, left attaching
noun modifiers etc (Sager, 1981). In many
cases, many traditional phrase structures are
absent or altered, making a phrase structure
parse using traditional production rules difficult.
A dependency grammar may still capture useful
syntactic relationships when an accurate phrase
grammar parse is not possible. In this way, a
dependency parse may be compared to a
shallow parse, in that it can return a partial
analysis. However, even with a shallow parser,
we would still interested in the dependency
relationships inside the chunks. Third, the
syntactic grammar of medical English,
specifically regarding discharge summaries, is
simpler overall (Campbell, 2001). We are not
interested so much in the labeling of
intermediate syntactic structures, such as noun
phrases and prepositional phrases. Dependency
grammars may allow us to capitalize on the
relative syntactic simplicity of medical language
without the overhead of generating and
identifying structures which will not be used.
</bodyText>
<figureCaption confidence="0.770917">
Figure 1. Dependency grammar parse of the
sentence “In general she was sleeping quietly.”
</figureCaption>
<bodyText confidence="0.999987">
The dependency grammar used in this
experiment did not allow crossing dependencies
(projectivity). Crossing dependencies are ones
where the parent and child of a relationship are
on opposite sides of a common ancestor.
</bodyText>
<sectionHeader confidence="0.981939" genericHeader="method">
3 Transformational Based
</sectionHeader>
<subsectionHeader confidence="0.59141">
Learning
</subsectionHeader>
<bodyText confidence="0.999095325581396">
Transformational Based Learning (TBL) has
been applied to numerous language learning
problems, including part-of-speech tagging
(Brill, 1994) , and parsing (Florian, 1998). It
also has been used for learning dependency
grammars (Hajic, 1997). In general, TBL
algorithms generate smaller rule sets and require
less training material than probabilistic
approaches. Brill produced a part-of-speech
tagger which was comparable in accuracy to
other tagging methods.
In language, the general paradigm for TBL is
to generate logical rules which apply
transformations to the text. The training text is
first annotated with the goal state. In this case,
the sentences would be assigned a dependency
parse. An initial state annotator is then applied
to an unannotated copy of the text. For
example, a right branching dependency tree was
used in our experiment as the initial state
(compare figure 1 and figure 2). The goal of
TBL is to then generate rules which transform
the naïve training state into the goal state. In
order to do so, the TBL algorithm will have
templates which describe the environment in the
training corpus where a transformation can
occur. The algorithm also has a scoring
function which allows the comparison of the
training state to the goal state. After iterating
through the training corpus and testing all
combinations of templates and transformations,
the paired template and transformation which
has the highest score becomes a rule. In other
words, the best rule is the one which results in a
corpus closest to the goal state after applying the
transformation at the locations indicated by the
template. This best rule is applied to the
training corpus to produce a refined corpus. The
process is then repeated, using the refined
corpus as the training corpus, until no more
positively scoring rules are produced. The final
product is an ordered set of rules which can be
applied to any unannotated corpus.
</bodyText>
<figureCaption confidence="0.8330515">
Figure 2. The initial dependency parse of the
sentence “In general she was sleeping quietly.”
</figureCaption>
<bodyText confidence="0.989909142857143">
TBL is a good choice for learning a
dependency grammar of medical language.
Assigning dependency heads is a task that is
similar to part-of-speech tagging; each word in
the text has exactly one dependency head,
represented by the index of the head word.
Transformations to this representation consist of
</bodyText>
<equation confidence="0.990281833333333">
general/JJ
.
was/VBD
In/IN
she/PN
sleeping/VBG
quietly/RB
general/JJ
In/IN was/VBD
she/PN sleeping/VBG
.
quietly/RB
</equation>
<bodyText confidence="0.994882">
changing a word’s dependency head from one
word to another.
</bodyText>
<sectionHeader confidence="0.99183" genericHeader="method">
4 The Learning Algorithm
</sectionHeader>
<subsectionHeader confidence="0.999406">
4.1 Template Design
</subsectionHeader>
<bodyText confidence="0.999933584905661">
In TBL, transformations occur when a
specific environment in the text is found. These
environments, or triggers, are defined by the
proximal relationship of two or more parts of
speech within a sentence. For example, in
Brill’s early work with POS tagging, one trigger
was the existence of another specific POS tag
immediately preceding the one to be
transformed. The triggers, therefore, compose
the ‘if’ component of the ‘if-then’
transformational rules.
When considering what triggers would be
appropriate for dependency grammars, it was
noted that many arcs in the grammar span a
number of words. For example, the arc between
a verb and the head of a noun phrase may span
many words, especially in medical narratives
where noun phrases can be especially lengthy.
In previous attempts to parse language using
TBL templates, the triggers have been tokens in
the vicinity of the token to be transformed.
While this has been successful for POS tagging,
where the context necessary to correctly
transform the tag may be found within two or
three surrounding tokens, the distance of some
dependency relationships can be much greater.
In order to capture long distance relationships
explicitly in a trigger, it would be necessary to
expand the vicinity to be searched.
In the case of a dependency grammar parse,
words are related to each other not only through
their left-to-right arrangement, but also through
the dependency tree. We sought to design
triggers that take advantage of the dependency
tree itself. Using the dependency relationships
directly in the trigger is in the spirit of TBL
where learning must change the triggering
environments in the corpus from one iteration to
the next. For example, in the case of POS tag
learning, newly learned POS tags are used in
subsequent iterations of the algorithm as
triggers. Similarly, by using the dependency
relationship directly in the trigger, we would
expect the learner to capitalize on parse
improvements through the learning process.
Each trigger used in this experiment had six
parameters, which defined the vicinity around a
target token, summarized in figure 3. Triggers
can search using solely word distance, tree
distance, or a combination of both. Any
template can have multiple triggers, requiring
multiple criteria to be met before considered
true.
</bodyText>
<figureCaption confidence="0.984621">
Figure 3. Trigger design and examples
</figureCaption>
<bodyText confidence="0.9999309">
The parameters of direction and distance are
self-explanatory. Scope defines whether or not
the triggering token must be exactly at the
location defined by the distance, or within that
distance. The third setting for scope is a special
case. If the scope is set to all the template will
search all tokens in the direction set, regardless
of distance (e.g. if the tree direction is set to left
and the scope is set to all, the trigger will match
all tokens to the left, regardless of distance).
</bodyText>
<figure confidence="0.713290523809524">
Trigger parameters
1. Word distance
2. Word direction (left, right, either)
3. Word scope (exactly at, within, all)
4. Tree distance
5. Tree direction (parent, child, either)
6. Tree scope (exactly at, within, all)
Example 1.
2
x
Trigger:
W-dist = 2 W-dir = right W-scp = within
T-dist = 1 T-dir = child T-scp = within
Example 2
2
x
2
Trigger:
W-dist = 2 W-dir = right W-scp = ex. at.
T-dist = 2 T-dir = par T-scp = ex. at
1
</figure>
<bodyText confidence="0.99976125">
Two examples of triggers are given in figure 3.
In both cases the triggers are searching for
elements near token x which meet the correct
criteria. In the first example, the trigger criteria
will be met by any token within the shaded area
of the tree, those tokens which are either one or
two tokens to the right of x and are descendents
of x with a tree distance of one. The second
trigger will match a single token, shown as a
black circle, that is exactly two tokens to the
right of x and is also an ancestor of tree distance
two.
</bodyText>
<subsectionHeader confidence="0.908763">
4.2 Transformations
</subsectionHeader>
<bodyText confidence="0.999730181818182">
The second principal component of a TBL
rule is the transformation, which defines a
change to the structure of the sentence. For
example, in the case of POS tagging, the
transformation would be to change POS tag x to
POS tag y. When TBL has been applied to
parsing, the transformations have been on
bracketed parse trees and have added or deleted
brackets in a balanced method. Where the
transformations seem intuitive for POS tagging,
they are not as transparent for parsing. A rule
for POS tagging may read, “If tag x is DT and
tag y immediately to the right is VB, change tag
y to NN.” (see figure 4) This makes sense, for
we do not expect verbs to immediately trail
determiners, and transforming the verb to a noun
would likely correct an error. A rule for parsing
may read “If a bracket is immediately left of
NN, delete a bracket to the left of the NN.” This
rule will combine a phrase which has a noun as
the left-most component with the phrase which
covers it. While this makes some sense, as
many phrases do not have nouns as their left-
most component, there are also many phrases
which do. The linguistic motivation behind the
transformation is not immediately obvious.
We wanted to give our transformations
the intuitive readability of the rules seen in the
POS tagging rules. In the case of our
dependency grammar, we wanted our
transformations to describe changes made
directly to the tree. We considered four ways in
which one token in the tree could be moved in
relation to another outlined in figure 5. All four
of the transformations decompose to the first
transform. These transformations make intuitive
sense for dependency grammars. We want to
identify tokens in the text which are in the
incorrect tree configuration and transform the
tree by changing the dependency relationships.
For example, the transformations “Make a noun
the child of a verb” or “Make adjectives siblings
of each other” are both readable in English and
are linguistically reasonable.
</bodyText>
<table confidence="0.87652425">
Part-of-speech rule application
Before: The/DT fly/VB on/IN the/DT wall/NN
Apply Rule: If VB right of DT change VB to NN
After: The/DT fly/NN on/IN the/DT wall/NN
</table>
<figureCaption confidence="0.9977435">
Figure 4. Examples of applying
transformations in POS tagging and parsing
</figureCaption>
<bodyText confidence="0.999858545454545">
Some transformations are disallowed in the
special case that the root node is involved. The
root node has no parent and can have no siblings
and therefore transformations which would
create these circumstances are not allowed. The
shape of the dependency tree is restricted in
other ways as described above, in that the trees
have no crossing dependencies. These
restrictions are not enforced by the
transformations and it is possible that they could
generate trees that violate these restrictions.
</bodyText>
<subsectionHeader confidence="0.99936">
4.3 Rule Scoring
</subsectionHeader>
<bodyText confidence="0.998553222222222">
At every iteration, it is necessary to evaluate the
goodness of the parse that results from the
application of all tested rules. The rule which
produces the best parse for that iteration is the
one that is chosen and applied before continuing
on to the next iteration. A number of measures
for measuring parsing accuracy have been
established, including bracketing sensitivity and
specificity. Parsing accuracy for dependency
</bodyText>
<figure confidence="0.526214">
Bracketed-tree rule application
Before:
(((The/DT (fly/NN on/IN)) the/DT) wall/NN)
Apply Rule: If ‘(‘ left of NN delete ‘(‘ on left
After
(((The/DT fly/NN on/IN) the/DT) wall/NN)
</figure>
<bodyText confidence="0.9973215">
grammars is often measured as a function of the
number of tokens which have the correct
ancestors, or dependency accuracy. Keeping
our goal of generating word-modifier pairs for
subsequent machine learning, we chose an
aggressive scoring function, counting only
correct parent-child relationships. This also
keeps the scoring function as simple as possible.
</bodyText>
<figureCaption confidence="0.984218">
Figure 5. The four basic transformations
</figureCaption>
<subsectionHeader confidence="0.983716">
4.4 The Algorithm
</subsectionHeader>
<bodyText confidence="0.999967833333333">
The general design of TBL algorithms has
been well described (Brill, 1994). The essential
components, outlined above, include the
template design, the transformations used, and
the scoring system. The initial state of the
dependency tree is the right branching tree
shown in figure 2. To improve efficiency, we
use the indexed TBL method outlined by
Ramshaw and Marcus (Ramshaw, 1994). Rules
have pointers to the sentences to which they
apply, and similarly each sentence has pointers
to the rules which have applied to it in the past.
Rules are held on a heap based on their score,
allowing the best rule to be found immediately
after each iteration. The rule is applied to the
list of sentences to which it points, and this list
is used in the next iteration so no sentences
which have not been modified need be seen.
</bodyText>
<sectionHeader confidence="0.999148" genericHeader="method">
5 Methods
</sectionHeader>
<bodyText confidence="0.999910769230769">
A corpus of 1000 sentences (16,949 words)
of text from medical discharge summaries was
split into a training set of 830 sentences (13,954
words) and a test set of 170 sentences (2,995
words). The entire corpus was first POS tagged
using a tagger trained specifically for discharge
summaries (Campbell, 2001). The corpus was
then hand parsed with a dependency grammar,
and the TBL learner was allowed to learn rules
on the training set. The sentences in the corpus
were not restricted by length. Three sets of
increasingly complex templates were used to
learn rules, summarized in figure 6.
</bodyText>
<figureCaption confidence="0.978046">
Figure 6. Three template sets used
</figureCaption>
<figure confidence="0.949385852941176">
x
x
y
x y
x
Corpus score = # correct dependencies
# of dependencies in corpus
Dependency grammar transformations
1. Make x the child of y
y
x y
y
3. Make x the sibling of y keeping x’s
parent
4. Make x the sibling of y keeping y’s
parent
w
x
w
y x y
z
z
y
x
2. Make x the parent of y
Template Set #3
1. Word distance:
2. Word direction:
3. Word scope:
4. Tree distance:
5. Tree direction:
6. Tree scope:
all of set 1, 2, and. . .
1,2 or 3
</figure>
<figureCaption confidence="0.616491666666667">
left, right, or either
exactly at, within, or all
1, 2, or 3
child, parent or either
exactly at, within, or all
Template Set #1 1, 2, or 3
</figureCaption>
<listItem confidence="0.949445833333333">
1. Word distance: left, right, or either
2. Word direction: exactly at, within, or all
3. Word scope: not used
4. Tree distance: not used
5. Tree direction: not used
6. Tree scope:
</listItem>
<figure confidence="0.933379357142857">
Template Set #2
1. Word distance:
2. Word direction:
3. Word scope:
4. Tree distance:
5. Tree direction:
6. Tree scope:
all of set 1, and . . .
not used
not used
not used
1, 2, or 3
child, parent or either
exactly at, within, or all
</figure>
<sectionHeader confidence="0.989807" genericHeader="evaluation">
6 Results
</sectionHeader>
<bodyText confidence="0.993164">
The three template sets generated three rule
sets, each of which was evaluated on the 170
sentence test set. Each template set was trained
with increasing amounts of the training corpus
to measure the effect of the training set size on
the learner’s accuracy. Chart 1 shows the
improvement in accuracy gained through larger
training sets. The best dependency accuracy and
number of rules generated for each template set
is reported in table 1.
</bodyText>
<table confidence="0.984416">
Template Rules Parser Tree Parse
Set tested Rules Rules acc.
Set 1 48K+ 424 0 76.5%
Set 2 93K+ 498 127 77.0%
Set 3 187K+ 541 249 77.0%
</table>
<tableCaption confidence="0.984247">
Table 1. Results for three template sets used
</tableCaption>
<table confidence="0.9998406">
Test set Sentence Total Avg. Parse
length Sents. Length acc.
1 n &lt;= 10 61 7.1 87.6%
2 n &lt;= 20 127 11.4 80.1%
Full all n 200 17.9 77.0%
</table>
<tableCaption confidence="0.999824">
Table 2. Effect of sentence length on accuracy
</tableCaption>
<bodyText confidence="0.9999541">
To measure the effect of sentence length on
parsing accuracy, the best parser rules were re-
tested on two subsets of the test sets. The first
subset contained sentences with a length less
than ten words and the second contained
sentences of length less than twenty. The
resulting accuracy of the parser on these
sentences is summarized in table 2. The top ten
rules acquired with the third template set are
reported in table 3.
</bodyText>
<sectionHeader confidence="0.977718" genericHeader="discussions">
7 Discussion and Further Work
</sectionHeader>
<bodyText confidence="0.997846043478261">
For all sets of templates, the learner produced a
rule-based parser with dependency accuracy
exceeding 75% when sentence length was not
restricted. For the best parser generated,
limiting the sentence length to 20 and 10 words
improved the parsing accuracy to 80.1% and
87.6%. Little difference among the template
sets was found, although the use of tree-based
templates gave slightly better performance.
Although we expected the inclusion of tree
based templates to improve the performance of
the parser by a greater extent than observed, it is
significant that the learner was reasonably
successful with only word-order information.
The strongest syntactic dependencies in medical
language may be local and the addition of the
tree-oriented templates is not very significant.
However, when the tree information is available,
the learner does use it, as can be seen by the
number of rules using tree information in the
three sets shows (table 1). For the third template
set, 46% of the rules learned incorporated tree
information.
</bodyText>
<table confidence="0.928974714285714">
Base Trg. W W W T T T Xf
POS POS Dis Dir Scp Dis Dir Scp
1 NN IN 3 -1 2 0 0 0 2
2 IN NN -1 1 2 0 0 0 2
3 VBD NN 0 0 0 2 1 1 1
4 JJ NN 2 1 2 0 0 0 2
5 VBD VBN 3 1 2 0 0 0 1
Base POS {POS of current token}
Trig. POS {POS to be found by trigger}
W/T Dis {# of tokens trigger is from base}
W Dir {1 = right, -1 = left, 0 = either }
T Dir {1 = par, -1 = child, 0 = either }
W/T Scp {1 = at, 2 = within, 3 = all}
Xf {1 = make child, 2 = make par}
</table>
<tableCaption confidence="0.917353">
Table 3. First 5 rules learned by template set 3
</tableCaption>
<bodyText confidence="0.999372">
The rules generated are easily translated into
English and make good linguistic sense. The
first rule in Table 2 reads “If this is a singular
noun (Base POS = NN) and there is a
preposition (Trg POS = IN) within (W. scp = 2)
three tokens (W. dis = 3) to the left (W. dir =-1)
then make the preposition the parent of the
noun.” This is the type of rule we would expect
to see, as it begins forming prepositional
phrases attaching to prepositions on the left.
The third rule uses information in the
dependency tree, reading “If this is a simple past
verb and there is a singular noun that is the
grandparent, make that noun the child of the
verb.”
</bodyText>
<figure confidence="0.9880463">
Dependency accuracy
0.75
0.65
0.8
0.7
0 100 200 300 400 500 600 700 800 900
Training set size (sentences)
Template Set 1
Template Set 2
Template Set 3
</figure>
<figureCaption confidence="0.937056">
Chart 1. Effect of training set size on dependency accuracy for three template sets
</figureCaption>
<bodyText confidence="0.999991446153846">
The greatest drawback to this approach is
the computing requirements. The consequence
of the complex template design used is a large
number of rules which need to be kept in
memory. The third template set generated over
187,000 rules which need to be stored in
memory. Of these, only 240 rules were kept in
the rule set. Because each rule needs to store a
list of pointers back to the sentences to which it
applied, the size of a rule grows with the size of
the training set. It will be crucial to incorporate
rule pruning in the future to allow larger training
sets and more complex templates.
Although the results shown here are for
training on a specific corpus of discharge
summaries, the learning algorithm itself is
domain independent. We foresee generating
parsers on a number of medical corpora,
including radiology reports, pathology reports
and progress notes. Therefore, we require a
flexible solution that would not demand
reengineering the parser for every new domain.
The learning algorithm described here could be
used on any general corpus where the sentences
can be given a dependency parse. We intend to
evaluate the algorithm on more general corpora
in the future.
Overall, the results are very encouraging.
Keeping in mind our goal of gathering head-
modifier pairs for machine learning, a 77%
accurate parse is approaching an acceptable
parse (Sekine, 1992). The results also show that
limiting the sentence length can improve the
accuracy of the parser. If our sole desire is the
generation of head-modifier pairs, using a large
number of shorter sentences may be equivalent
to using fewer longer ones. We also believe that
the parser may be improved through
lexicalization, but that remains future work.
The ability to generate a good parser from
such a small training set is important in the
medical domain. Previous work has shown that
different medical domains have to be treated as
separate languages for successful NLP
(Friedman, 1995). Therefore, it is likely that
any medical domain we wish to parse will
require its own training set for the parser. If
extensive training set preparation was required,
then we are simply trading one difficult task for
another: the task of manually creating and
maintaining a semantic lexicon with the task of
hand dependency-parsing large amounts of text.
Although the task of hand-parsing 1,000
sentences of discharge summaries is not trivial,
it is reasonable and manageable and does not
require extensive medical knowledge. The
shift-reduce parser described by (Hermjakob,
1997) also requires relatively few training
examples but requires semantic features that
may require medical knowledge to construct
and assign. Although we do not propose here a
specific application for a dependency grammar
in a medical domain, we believe it will be
valuable for future clustering, disambiguation
and indexing applications.
</bodyText>
<sectionHeader confidence="0.998874" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999959541666667">
Natural language processors in the medical
domain will be more flexible and portable with
assisted lexicon design. The syntactic
dependencies in a dependency grammar may be
useful for the lexical acquisition necessary to
make this possible. We have investigated using
transformational-based learning as a technique
for learning a dependency grammar in a medical
corpus. To better learn dependency grammars
we used a template design which uses the
structure of the parse tree explicitly and
transformations that operated directly on the
trees. Training on a set of 830 sentences of
parsed medical discharge summaries gave a best
parser with 77% accuracy. The inclusion of tree
information in the template design slightly
improved the parser. The rules produced were
intuitive and understandable, and the limited
amount of training material will allow the
technique to be used on other medical domains
without extensive manual parsing. Further work
will test the utility of head-dependency
relationships for machine learning semantic
classes.
</bodyText>
<sectionHeader confidence="0.999386" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999466387096774">
Brill, E. (1994). A report of recent progress in
transformation-based error-driven learning. In
Proceedings of the Twelfth National
Conference on Artificial Intelligence,
Princeton, NJ.
Campbell, D.A., Johnson, S.B. (2001).
Comparing Syntactic Complexity in Medical
and non-Medical Corpora. In Proc AMIA
Annu Fall Symp. 90-94.
Carroll, G., Charniak, E. (1992). Two
experiments on learning probabilistic
dependency grammars from corpora. In
Workshop Notes for Statistically-Based NLP
Techniques, AAAI. 1-13.
Collins, M. (1996.). A new statistical parser
based on bigram lexical dependencies. In
Proceedings of the 34th Annual Meeting of
ACL. 184-191.
Dorr, B. J., Jones, D. (2000). Acquisition of
Semantic Lexicons: Using Word Sense
Disambiguation to Improve Precision, in
Evelyn Viegas (Ed), Breadth and Depth of
Semantic Lexicons, Kluwer Academic
Publishers: Norwell, MA, 79-98.
Florian, R., Brill, E. (1998). Transformation
Based Parsing. Ph.D. Qualifier Project,
Computer Science Department, Johns Hopkins
University.
Friedman, C. (1997). Towards a comprehensive
medical language processing system: methods
and issues. In Proc AMIA Annu Fall Symp.
595-9.
Friedman C, et. al (1995). Architectural
requirements for a multipurpose natural
language processor in the clinical
environment. In Proc 19th Annu SCAMC.
347-51.
Hajic, J. and K. Ribarov (1997). Rule-Based
Dependencies. Workshop on Empirical
Learning of Natural Language Processing
Tasks, Prague, Czech Republic.
Harris, Z. (1991). A Theory of Language and
Information. Oxford University Press:
Oxford.
Hermjakob U. &amp; Mooney R.J. (1997) Learning
Parse and Translation Decisions From
Examples With Rich Context, Proc. of ACL-
EACL Conf. 482-489.
Hripcsak, G., G. Kuperman, et al. (1998).
Extracting Findings from Narrative Reports:
Software Transferability and Sources of
Physician Disagreement. Methods Inf Med 37.
1-7.
Hudson, Richard. (1991). English Word
Grammar. Blackwell: Cambridge, Mass.
Kokkinakis D. (2001), Syntactic Parsing as a
Step for Automatically Augmenting Semantic
Lexicons, In Proceedings of the 39th ACL and
the 10th EACL, Toulouse, France. Student
Workshop. 13-18.
Lee, S. and K.-S. Choi (1999). A Reestimation
Algorithm for Probabilistic Dependency
Grammars. Natural Language Engineering
5(3). 251-270.
Li H. and Abe N.(1998). Word clustering and
disambiguation based on co-occurrence data.
In Proceedings of COLING - ACL&apos;98. 749-
755
Paskin, M. (2001). Grammatical Bigrams. In T.
Dietterich, S. Becker, and Z. Gharahmani eds.,
Advances in Neural Information Processing
Systems 14. MIT Press: Cambridge, MA.
Pereira F., Tishby, N., Lee, L (1993).
Distributional clustering of English words. In
30th Annual Meeting of the ACL, 183-190.
Ramshaw, L. A., Marcus, M. P. (1994).
Exploring the statistical derivation of
transformational rule sequences for part-of-
speech tagging. In Proceedings of the
Balancing Act Workshop on Combining
Symbolic and Statistical Approaches to
Language, Association for Computational
Linguistics. 86-95.
Sager N. (1981). Natural Language Information
Processing: A Computer Grammar of English
and its Applications. Addison-Wesley:
Reading, Massachusetts.
Sekine, S. et. al (1992) Automatic Learning for
Semantic Collocation. In 3rd Conf. on Applied
Natural Language Processing :Trent - Italy.
Wilcox, A, Hripcsak G. (2000). Medical Text
Representations for Inductive Learning. Proc
AMIA Symp. 923-7.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.861758666666667">Proceedings of the Workshop on Natural Language Processing in the Biomedical Domain, Philadelphia, July 2002, pp. 37-44. Association for Computational Linguistics.</note>
<title confidence="0.9365465">A Transformational-based Learner for Dependency Grammars in Discharge Summaries</title>
<author confidence="0.999649">David A Campbell M Phil</author>
<author confidence="0.999649">Stephen B Johnson Ph D</author>
<affiliation confidence="0.999842">Department of Medical Informatics, Columbia University</affiliation>
<abstract confidence="0.980851463565894">NLP systems will be more portable among medical domains if acquisition of semantic lexicons can be facilitated. We are pursuing lexical acquisition through the syntactic relationships of words in medical corpora. Therefore we require a syntactic parser which is flexible, portable, captures head-modifier pairs and does not require a large training set. We have designed a dependency grammar parser that learns through a transformational-based We propose a novel design for templates and transformations which capitalize on the dependency structure directly and produces human-readable rules. Our parser achieved a 77% accurate parse training on only 830 sentences. Further work will evaluate the usefulness of this parse for lexical acquisition. Natural Language is a vital medium in medicine. Health care providers rely on medical narratives for recording, representing and sharing complex medical information such as the description of images, explanation of test results, or the summary of a patient’s hospital visit. Natural Language Processing (NLP) tools have been applied to medical narrative for a variety of applications, such as triggering clinical alerts (Friedman, 1997) and document classification (Wilcox, 2000). The effort required to create and maintain NLP systems in the medical setting can be prohibitive. Most language processors require a domain-specific semantic lexicon to function and, so far, these lexica have been created manually. The time and cost involved in creating these knowledge structures put limits on the extensibility and portability of NLP systems (Hripcsak, 1998). One solution to this bottleneck is to use machine learning to assist in categorizing lexemes into semantic classes. Such a tool could reduce the difficulty in porting NLP systems from one domain to another. Grammars One approach to semantic categorization is the use of syntactic features (Kokkinakis, 2001). This is based on the assumption that lexemes that share similar syntactic relations to other lexemes in the corpus will be semantically similar (Dorr, 2000). The idea of clustering words based on syntactic features has been well investigated in general language (Pereira, 1993; Li, 1998) However, (Harris, 1991) states that the syntactic relationships are more well-defined and have less variation in scientific languages (sublanguages), such as the ones used in medical texts. Identifying word classes using syntactic relationships should be simpler and potentially more useful in these types of languages. Dependency grammars (Hudson, 1991) generate parses where words in a sentence are related directly to the word which is its syntactic head. Each word, except for the root has exactly one head, and the structure is a tree. The analysis does not generate any intermediate syntactic structures. Figure 1 shows an example of a sentence with a dependency grammar parse. There has been interest in learning dependency grammars from corpora. Collins (Collins, 1996) used dependencies as the backbone for his probabilistic parser and there has been work on learning both probabilistic (Carroll, 1992; Lee, 1999; Paskin, 2001) and transformation based dependency grammars (Hajic, 1997). There are a number of attributes of dependency grammars which make them ideal for our goal of investigating medical sublanguage. First, the semantics of a word are often defined by a feature space of related words. The head-dependent generated by a dependency parse can be used as the relationship for acquisition. dependency grammars may be a better fit for parsing medical text. Medical text is frequently include telegraphic omissions, run-on structures, improper use of conjunctions, left attaching noun modifiers etc (Sager, 1981). In many cases, many traditional phrase structures are absent or altered, making a phrase structure parse using traditional production rules difficult. A dependency grammar may still capture useful syntactic relationships when an accurate phrase grammar parse is not possible. In this way, a dependency parse may be compared to a shallow parse, in that it can return a partial analysis. However, even with a shallow parser, we would still interested in the dependency relationships inside the chunks. Third, the syntactic grammar of medical English, specifically regarding discharge summaries, is simpler overall (Campbell, 2001). We are not interested so much in the labeling of intermediate syntactic structures, such as noun phrases and prepositional phrases. Dependency grammars may allow us to capitalize on the relative syntactic simplicity of medical language without the overhead of generating and identifying structures which will not be used. Figure 1. Dependency grammar parse of the sentence “In general she was sleeping quietly.” The dependency grammar used in this experiment did not allow crossing dependencies (projectivity). Crossing dependencies are ones where the parent and child of a relationship are on opposite sides of a common ancestor. Based Learning Transformational Based Learning (TBL) has been applied to numerous language learning problems, including part-of-speech tagging (Brill, 1994) , and parsing (Florian, 1998). It also has been used for learning dependency grammars (Hajic, 1997). In general, TBL algorithms generate smaller rule sets and require less training material than probabilistic approaches. Brill produced a part-of-speech tagger which was comparable in accuracy to other tagging methods. In language, the general paradigm for TBL is to generate logical rules which apply transformations to the text. The training text is first annotated with the goal state. In this case, the sentences would be assigned a dependency parse. An initial state annotator is then applied to an unannotated copy of the text. For example, a right branching dependency tree was used in our experiment as the initial state (compare figure 1 and figure 2). The goal of TBL is to then generate rules which transform the naïve training state into the goal state. In order to do so, the TBL algorithm will have describe the environment in the corpus where a The algorithm also has a allows the comparison of the training state to the goal state. After iterating through the training corpus and testing all combinations of templates and transformations, the paired template and transformation which the highest score becomes a In other words, the best rule is the one which results in a corpus closest to the goal state after applying the transformation at the locations indicated by the template. This best rule is applied to the training corpus to produce a refined corpus. The process is then repeated, using the refined corpus as the training corpus, until no more positively scoring rules are produced. The final product is an ordered set of rules which can be applied to any unannotated corpus. Figure 2. The initial dependency parse of the sentence “In general she was sleeping quietly.” TBL is a good choice for learning a dependency grammar of medical language. Assigning dependency heads is a task that is similar to part-of-speech tagging; each word in the text has exactly one dependency head, represented by the index of the head word. Transformations to this representation consist of general/JJ . was/VBD In/IN she/PN general/JJ In/IN was/VBD she/PN . changing a word’s dependency head from one word to another. Learning Algorithm 4.1 Template Design In TBL, transformations occur when a specific environment in the text is found. These or are defined by the proximal relationship of two or more parts of speech within a sentence. For example, in Brill’s early work with POS tagging, one trigger was the existence of another specific POS tag immediately preceding the one to be transformed. The triggers, therefore, compose the ‘if’ component of the ‘if-then’ transformational rules. When considering what triggers would be appropriate for dependency grammars, it was noted that many arcs in the grammar span a number of words. For example, the arc between a verb and the head of a noun phrase may span many words, especially in medical narratives where noun phrases can be especially lengthy. In previous attempts to parse language using TBL templates, the triggers have been tokens in the vicinity of the token to be transformed. While this has been successful for POS tagging, where the context necessary to correctly transform the tag may be found within two or three surrounding tokens, the distance of some dependency relationships can be much greater. In order to capture long distance relationships explicitly in a trigger, it would be necessary to expand the vicinity to be searched. In the case of a dependency grammar parse, words are related to each other not only through their left-to-right arrangement, but also through the dependency tree. We sought to design triggers that take advantage of the dependency tree itself. Using the dependency relationships directly in the trigger is in the spirit of TBL where learning must change the triggering environments in the corpus from one iteration to the next. For example, in the case of POS tag learning, newly learned POS tags are used in subsequent iterations of the algorithm as triggers. Similarly, by using the dependency relationship directly in the trigger, we would expect the learner to capitalize on parse improvements through the learning process. Each trigger used in this experiment had six parameters, which defined the vicinity around a target token, summarized in figure 3. Triggers can search using solely word distance, tree distance, or a combination of both. Any template can have multiple triggers, requiring multiple criteria to be met before considered true. Figure 3. Trigger design and examples The parameters of direction and distance are self-explanatory. Scope defines whether or not triggering token must be at defined by the distance, or distance. The third setting for scope is a special If the scope is set to template will search all tokens in the direction set, regardless distance (e.g. if the tree direction is set to the scope is set to trigger will match all tokens to the left, regardless of distance). Trigger parameters 1. Word distance 2. Word direction (left, right, either) 3. Word scope (exactly at, within, all) 4. Tree distance 5. Tree direction (parent, child, either) 6. Tree scope (exactly at, within, all) Example 1. 2 x Trigger: W-dist = 2 W-dir = right W-scp = within T-dist = 1 T-dir = child T-scp = within Example 2 2 x 2 Trigger: W-dist = 2 W-dir = right W-scp = ex. at. = 2 T-dir par= ex. at 1 Two examples of triggers are given in figure 3. In both cases the triggers are searching for near token meet the correct criteria. In the first example, the trigger criteria will be met by any token within the shaded area of the tree, those tokens which are either one or tokens to the right of are descendents a tree distance of one. The second trigger will match a single token, shown as a black circle, that is exactly two tokens to the of is also an ancestor of tree distance two. 4.2 Transformations The second principal component of a TBL is the which defines a change to the structure of the sentence. For example, in the case of POS tagging, the would be to change POS tag tag When TBL has been applied to parsing, the transformations have been on bracketed parse trees and have added or deleted brackets in a balanced method. Where the transformations seem intuitive for POS tagging, they are not as transparent for parsing. A rule POS tagging may read, “If tag DT and to the right is VB, change tag NN.” (see figure 4) This makes sense, for we do not expect verbs to immediately trail determiners, and transforming the verb to a noun would likely correct an error. A rule for parsing may read “If a bracket is immediately left of NN, delete a bracket to the left of the NN.” This rule will combine a phrase which has a noun as the left-most component with the phrase which covers it. While this makes some sense, as many phrases do not have nouns as their leftmost component, there are also many phrases which do. The linguistic motivation behind the transformation is not immediately obvious. We wanted to give our transformations the intuitive readability of the rules seen in the POS tagging rules. In the case of dependency grammar, we wanted our transformations to describe changes made directly to the tree. We considered four ways in which one token in the tree could be moved in relation to another outlined in figure 5. All four of the transformations decompose to the first transform. These transformations make intuitive sense for dependency grammars. We want to identify tokens in the text which are in the incorrect tree configuration and transform the tree by changing the dependency relationships. For example, the transformations “Make a noun the child of a verb” or “Make adjectives siblings of each other” are both readable in English and are linguistically reasonable. Part-of-speech rule application the/DT wall/NN If of the/DT wall/NN Figure 4. Examples of applying transformations in POS tagging and parsing Some transformations are disallowed in the special case that the root node is involved. The root node has no parent and can have no siblings and therefore transformations which would create these circumstances are not allowed. The shape of the dependency tree is restricted in other ways as described above, in that the trees have no crossing dependencies. restrictions are not enforced by the transformations and it is possible that they could generate trees that violate these restrictions. 4.3 Rule Scoring At every iteration, it is necessary to evaluate the goodness of the parse that results from the application of all tested rules. The rule which produces the best parse for that iteration is the one that is chosen and applied before continuing on to the next iteration. A number of measures for measuring parsing accuracy have been established, including bracketing sensitivity and specificity. Parsing accuracy for dependency Bracketed-tree rule application Before: the/DT) wall/NN) If of left After the/DT) wall/NN) grammars is often measured as a function of the number of tokens which have the correct ancestors, or dependency accuracy. Keeping our goal of generating word-modifier pairs for subsequent machine learning, we chose an aggressive scoring function, counting only correct parent-child relationships. This also keeps the scoring function as simple as possible. Figure 5. The four basic transformations 4.4 The Algorithm The general design of TBL algorithms has been well described (Brill, 1994). The essential components, outlined above, include the template design, the transformations used, and the scoring system. The initial state of the dependency tree is the right branching tree shown in figure 2. To improve efficiency, we use the indexed TBL method outlined by Ramshaw and Marcus (Ramshaw, 1994). Rules have pointers to the sentences to which they apply, and similarly each sentence has pointers to the rules which have applied to it in the past. Rules are held on a heap based on their score, allowing the best rule to be found immediately after each iteration. The rule is applied to the list of sentences to which it points, and this list is used in the next iteration so no sentences which have not been modified need be seen. A corpus of 1000 sentences (16,949 words) of text from medical discharge summaries was split into a training set of 830 sentences (13,954 words) and a test set of 170 sentences (2,995 words). The entire corpus was first POS tagged using a tagger trained specifically for discharge summaries (Campbell, 2001). The corpus was then hand parsed with a dependency grammar, and the TBL learner was allowed to learn rules on the training set. The sentences in the corpus were not restricted by length. Three sets of increasingly complex templates were used to learn rules, summarized in figure 6. Figure 6. Three template sets used x x y x y x Corpus score = # correct dependencies Dependency grammar transformations Make child of y x y y Make sibling of parent Make sibling of parent w x w y x y z z y x Make parent of Template Set #3 1. Word distance: 2. Word direction: 3. Word scope: 4. Tree distance: 5. Tree direction: 6. Tree scope: all of set 1, 2, and. . . 1,2 or 3 left, right, or either exactly at, within, or all 1, 2, or 3 child, parent or either exactly at, within, or all Template Set #1 1, 2, or 3 left, right, or either exactly at, within, or all not used not used not used 1. Word distance: 2. Word direction: 3. Word scope: 4. Tree distance: 5. Tree direction: 6. Tree scope: Template Set #2 1. Word distance: 2. Word direction: 3. Word scope: 4. Tree distance: 5. Tree direction: 6. Tree scope: all of set 1, and . . . not used not used not used 1, 2, or 3 child, parent or either exactly at, within, or all The three template sets generated three rule sets, each of which was evaluated on the 170 sentence test set. Each template set was trained with increasing amounts of the training corpus to measure the effect of the training set size on the learner’s accuracy. Chart 1 shows the improvement in accuracy gained through larger training sets. The best dependency accuracy and number of rules generated for each template set is reported in table 1. Template Set Rules tested Parser Rules Tree Rules Parse acc. Set 1 48K+ 424 0 76.5% Set 2 93K+ 498 127 77.0% Set 3 187K+ 541 249 77.0% Table 1. Results for three template sets used Test set Sentence length Total Sents. Avg. Length Parse acc. 1 n &lt;= 10 61 7.1 87.6% 2 n &lt;= 20 127 11.4 80.1% Full all n 200 17.9 77.0% Table 2. Effect of sentence length on accuracy To measure the effect of sentence length on parsing accuracy, the best parser rules were retested on two subsets of the test sets. The first subset contained sentences with a length less than ten words and the second contained sentences of length less than twenty. The resulting accuracy of the parser on these sentences is summarized in table 2. The top ten rules acquired with the third template set are reported in table 3. and Further Work For all sets of templates, the learner produced a rule-based parser with dependency accuracy exceeding 75% when sentence length was not restricted. For the best parser limiting the sentence length to 20 and 10 words improved the parsing accuracy to 80.1% and 87.6%. Little difference among the template sets was found, although the use of tree-based templates gave slightly better performance. Although we expected the inclusion of tree based templates to improve the performance of the parser by a greater extent than observed, it is significant that the learner was reasonably successful with only word-order information. The strongest syntactic dependencies in medical language may be local and the addition of the tree-oriented templates is not very significant. However, when the tree information is available, the learner does use it, as can be seen by the number of rules using tree information in the three sets shows (table 1). For the third template set, 46% of the rules learned incorporated tree information. Base POS Trg. POS W Dis W Dir W Scp T Dis T Dir T Scp Xf 1 NN IN 3 -1 2 0 0 0 2 2 IN NN -1 1 2 0 0 0 2 3 VBD NN 0 0 0 2 1 1 1 4 JJ NN 2 1 2 0 0 0 2 5 VBD VBN 3 1 2 0 0 0 1 Base POS {POS of current token} Trig. POS {POS to be found by trigger} W/T Dis {# of tokens trigger is from base} W Dir {1 = right, -1 = left, 0 = either } T Dir {1 = par, -1 = child, 0 = either } W/T Scp {1 = at, 2 = within, 3 = all} Xf {1 = make child, 2 = make par} Table 3. First 5 rules learned by template set 3 The rules generated are easily translated into English and make good linguistic sense. The first rule in Table 2 reads “If this is a singular noun (Base POS = NN) and there is a preposition (Trg POS = IN) within (W. scp = 2) three tokens (W. dis = 3) to the left (W. dir =-1) then make the preposition the parent of the noun.” This is the type of rule we would expect to see, as it begins forming prepositional phrases attaching to prepositions on the left. The third rule uses information in the dependency tree, reading “If this is a simple past verb and there is a singular noun that is the grandparent, make that noun the child of the verb.” Dependency accuracy 0.75 0.65 0.8 0.7 0 100 200 300 400 500 600 700 800 900 Training set size (sentences) Template Set Template Set Template Set 3 Chart 1. Effect of training set size on dependency accuracy for three template sets The greatest drawback to this approach is the computing requirements. The consequence of the complex template design used is a large number of rules which need to be kept in memory. The third template set generated over 187,000 rules which need to be stored in memory. Of these, only 240 rules were kept in the rule set. Because each rule needs to store a list of pointers back to the sentences to which it applied, the size of a rule grows with the size of the training set. It will be crucial to incorporate rule pruning in the future to allow larger training sets and more complex templates. Although the results shown here are for training on a specific corpus of discharge summaries, the learning algorithm itself is domain independent. We foresee generating parsers on a number of medical corpora, including radiology reports, pathology reports and progress notes. Therefore, we require a flexible solution that would not demand reengineering the parser for every new domain. The learning algorithm described here could be used on any general corpus where the sentences can be given a dependency parse. We intend to evaluate the algorithm on more general corpora in the future. Overall, the results are very encouraging. Keeping in mind our goal of gathering headmodifier pairs for machine learning, a 77% accurate parse is approaching an acceptable parse (Sekine, 1992). The results also show that limiting the sentence length can improve the accuracy of the parser. If our sole desire is the generation of head-modifier pairs, using a large number of shorter sentences may be equivalent to using fewer longer ones. We also believe that the parser may be improved through lexicalization, but that remains future work. The ability to generate a good parser from such a small training set is important in the medical domain. Previous work has shown that different medical domains have to be treated as separate languages for successful NLP (Friedman, 1995). Therefore, it is likely that any medical domain we wish to parse will require its own training set for the parser. If extensive training set preparation was required, then we are simply trading one difficult task for another: the task of manually creating and maintaining a semantic lexicon with the task of hand dependency-parsing large amounts of text. Although the task of hand-parsing 1,000 sentences of discharge summaries is not trivial, it is reasonable and manageable and does not require extensive medical knowledge. The shift-reduce parser described by (Hermjakob, 1997) also requires relatively few training examples but requires semantic features that may require medical knowledge to construct and assign. Although we do not propose here a specific application for a dependency grammar in a medical domain, we believe it will be valuable for future clustering, disambiguation and indexing applications. Natural language processors in the medical domain will be more flexible and portable with assisted lexicon design. The dependencies in a dependency grammar may be useful for the lexical acquisition necessary to make this possible. We have investigated using transformational-based learning as a technique for learning a dependency grammar in a medical corpus. To better learn dependency grammars we used a template design which uses the structure of the parse tree explicitly and transformations that operated directly on the trees. Training on a set of 830 sentences of parsed medical discharge summaries gave a best parser with 77% accuracy. The inclusion of tree information in the template design slightly improved the parser. The rules produced were intuitive and understandable, and the limited amount of training material will allow the technique to be used on other medical domains without extensive manual parsing. Further work will test the utility of head-dependency relationships for machine learning semantic classes.</abstract>
<note confidence="0.948671769230769">References Brill, E. (1994). A report of recent progress in transformation-based error-driven learning. In Proceedings of the Twelfth National on Artificial Princeton, NJ. Campbell, D.A., Johnson, S.B. (2001). Comparing Syntactic Complexity in Medical non-Medical Corpora. In AMIA Fall Symp. Carroll, G., Charniak, E. (1992). Two experiments on learning probabilistic dependency grammars from corpora. In Workshop Notes for Statistically-Based NLP AAAI. 1-13. Collins, M. (1996.). A new statistical parser based on bigram lexical dependencies. In Proceedings of the 34th Annual Meeting of 184-191. Dorr, B. J., Jones, D. (2000). Acquisition of Semantic Lexicons: Using Word Sense Disambiguation to Improve Precision, in Viegas (Ed), and Depth of Kluwer Academic Publishers: Norwell, MA, 79-98. Florian, R., Brill, E. (1998). Transformation</note>
<author confidence="0.92251">Qualifier</author>
<affiliation confidence="0.9277385">Computer Science Department, Johns Hopkins University.</affiliation>
<abstract confidence="0.859424">Friedman, C. (1997). Towards a comprehensive medical language processing system: methods issues. In AMIA Annu Fall 595-9. Friedman C, et. al (1995). Architectural requirements for a multipurpose natural language processor in the clinical In 19th Annu 347-51. Hajic, J. and K. Ribarov (1997). Rule-Based on Empirical</abstract>
<affiliation confidence="0.517737">Learning of Natural Language Processing</affiliation>
<address confidence="0.7196215">Prague, Czech Republic. Z. (1991). Theory of Language and</address>
<affiliation confidence="0.979906">Oxford University Press:</affiliation>
<address confidence="0.523719">Oxford.</address>
<note confidence="0.832675">Hermjakob U. &amp; Mooney R.J. (1997) Learning Parse and Translation Decisions From With Rich Context, of ACL- 482-489. Hripcsak, G., G. Kuperman, et al. (1998). Extracting Findings from Narrative Reports: Software Transferability and Sources of Disagreement. Inf Med 1-7. Richard. (1991). Word Blackwell: Cambridge, Mass. Kokkinakis D. (2001), Syntactic Parsing as a Step for Automatically Augmenting Semantic In of the 39th ACL and 10th Toulouse, France. Student Workshop. 13-18. Lee, S. and K.-S. Choi (1999). A Reestimation</note>
<title confidence="0.6309455">Algorithm for Probabilistic Dependency Language Engineering</title>
<abstract confidence="0.681398">5(3). 251-270. Li H. and Abe N.(1998). Word clustering and disambiguation based on co-occurrence data.</abstract>
<note confidence="0.9767165">In Proceedings of COLING - ACL&apos;98. 749- 755 Paskin, M. (2001). Grammatical Bigrams. In T. Dietterich, S. Becker, and Z. Gharahmani eds., Advances in Neural Information Processing MIT Press: Cambridge, MA. Pereira F., Tishby, N., Lee, L (1993). Distributional clustering of English words. In Annual Meeting of the 183-190. Ramshaw, L. A., Marcus, M. P. (1994).</note>
<title confidence="0.407518">Exploring the statistical derivation of transformational rule sequences for part-oftagging. In of the Balancing Act Workshop on Combining Symbolic and Statistical Approaches to Association for Computational</title>
<note confidence="0.948056272727273">Linguistics. 86-95. N. (1981). Language Information Processing: A Computer Grammar of English its Addison-Wesley: Reading, Massachusetts. Sekine, S. et. al (1992) Automatic Learning for Collocation. In Conf. on Applied Language Processing - Italy. Wilcox, A, Hripcsak G. (2000). Medical Text for Inductive Proc 923-7.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Brill</author>
</authors>
<title>A report of recent progress in transformation-based error-driven learning.</title>
<date>1994</date>
<booktitle>In Proceedings of the Twelfth National Conference on Artificial Intelligence,</booktitle>
<location>Princeton, NJ.</location>
<contexts>
<context position="5596" citStr="Brill, 1994" startWordPosition="818" endWordPosition="819"> syntactic simplicity of medical language without the overhead of generating and identifying structures which will not be used. Figure 1. Dependency grammar parse of the sentence “In general she was sleeping quietly.” The dependency grammar used in this experiment did not allow crossing dependencies (projectivity). Crossing dependencies are ones where the parent and child of a relationship are on opposite sides of a common ancestor. 3 Transformational Based Learning Transformational Based Learning (TBL) has been applied to numerous language learning problems, including part-of-speech tagging (Brill, 1994) , and parsing (Florian, 1998). It also has been used for learning dependency grammars (Hajic, 1997). In general, TBL algorithms generate smaller rule sets and require less training material than probabilistic approaches. Brill produced a part-of-speech tagger which was comparable in accuracy to other tagging methods. In language, the general paradigm for TBL is to generate logical rules which apply transformations to the text. The training text is first annotated with the goal state. In this case, the sentences would be assigned a dependency parse. An initial state annotator is then applied t</context>
<context position="15655" citStr="Brill, 1994" startWordPosition="2485" endWordPosition="2486">on/IN)) the/DT) wall/NN) Apply Rule: If ‘(‘ left of NN delete ‘(‘ on left After (((The/DT fly/NN on/IN) the/DT) wall/NN) grammars is often measured as a function of the number of tokens which have the correct ancestors, or dependency accuracy. Keeping our goal of generating word-modifier pairs for subsequent machine learning, we chose an aggressive scoring function, counting only correct parent-child relationships. This also keeps the scoring function as simple as possible. Figure 5. The four basic transformations 4.4 The Algorithm The general design of TBL algorithms has been well described (Brill, 1994). The essential components, outlined above, include the template design, the transformations used, and the scoring system. The initial state of the dependency tree is the right branching tree shown in figure 2. To improve efficiency, we use the indexed TBL method outlined by Ramshaw and Marcus (Ramshaw, 1994). Rules have pointers to the sentences to which they apply, and similarly each sentence has pointers to the rules which have applied to it in the past. Rules are held on a heap based on their score, allowing the best rule to be found immediately after each iteration. The rule is applied to</context>
</contexts>
<marker>Brill, 1994</marker>
<rawString>Brill, E. (1994). A report of recent progress in transformation-based error-driven learning. In Proceedings of the Twelfth National Conference on Artificial Intelligence, Princeton, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D A Campbell</author>
<author>S B Johnson</author>
</authors>
<date>2001</date>
<booktitle>Comparing Syntactic Complexity in Medical and non-Medical Corpora. In Proc AMIA Annu Fall Symp.</booktitle>
<pages>90--94</pages>
<marker>Campbell, Johnson, 2001</marker>
<rawString>Campbell, D.A., Johnson, S.B. (2001). Comparing Syntactic Complexity in Medical and non-Medical Corpora. In Proc AMIA Annu Fall Symp. 90-94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Carroll</author>
<author>E Charniak</author>
</authors>
<title>Two experiments on learning probabilistic dependency grammars from corpora.</title>
<date>1992</date>
<booktitle>In Workshop Notes for Statistically-Based NLP Techniques, AAAI.</booktitle>
<pages>1--13</pages>
<marker>Carroll, Charniak, 1992</marker>
<rawString>Carroll, G., Charniak, E. (1992). Two experiments on learning probabilistic dependency grammars from corpora. In Workshop Notes for Statistically-Based NLP Techniques, AAAI. 1-13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>A new statistical parser based on bigram lexical dependencies.</title>
<date>1996</date>
<booktitle>In Proceedings of the 34th Annual Meeting of ACL.</booktitle>
<pages>184--191</pages>
<contexts>
<context position="3381" citStr="Collins, 1996" startWordPosition="494" endWordPosition="495">nes used in medical texts. Identifying word classes using syntactic relationships should be simpler and potentially more useful in these types of languages. Dependency grammars (Hudson, 1991) generate parses where words in a sentence are related directly to the word which is its syntactic head. Each word, except for the root has exactly one head, and the structure is a tree. The analysis does not generate any intermediate syntactic structures. Figure 1 shows an example of a sentence with a dependency grammar parse. There has been interest in learning dependency grammars from corpora. Collins (Collins, 1996) used dependencies as the backbone for his probabilistic parser and there has been work on learning both probabilistic (Carroll, 1992; Lee, 1999; Paskin, 2001) and transformation based dependency grammars (Hajic, 1997). There are a number of attributes of dependency grammars which make them ideal for our goal of investigating medical sublanguage. First, the semantics of a word are often defined by a feature space of related words. The head-dependent relationships generated by a dependency parse can be used as the relationship for acquisition. Second, dependency grammars may be a better fit for</context>
</contexts>
<marker>Collins, 1996</marker>
<rawString>Collins, M. (1996.). A new statistical parser based on bigram lexical dependencies. In Proceedings of the 34th Annual Meeting of ACL. 184-191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B J Dorr</author>
<author>D Jones</author>
</authors>
<title>Acquisition of Semantic Lexicons: Using Word Sense Disambiguation to Improve Precision,</title>
<date>2000</date>
<booktitle>in Evelyn Viegas (Ed), Breadth and Depth of Semantic Lexicons,</booktitle>
<pages>79--98</pages>
<publisher>Kluwer Academic Publishers:</publisher>
<location>Norwell, MA,</location>
<marker>Dorr, Jones, 2000</marker>
<rawString>Dorr, B. J., Jones, D. (2000). Acquisition of Semantic Lexicons: Using Word Sense Disambiguation to Improve Precision, in Evelyn Viegas (Ed), Breadth and Depth of Semantic Lexicons, Kluwer Academic Publishers: Norwell, MA, 79-98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Florian</author>
<author>E Brill</author>
</authors>
<title>Transformation Based Parsing.</title>
<date>1998</date>
<tech>Ph.D. Qualifier Project,</tech>
<institution>Computer Science Department, Johns Hopkins University.</institution>
<marker>Florian, Brill, 1998</marker>
<rawString>Florian, R., Brill, E. (1998). Transformation Based Parsing. Ph.D. Qualifier Project, Computer Science Department, Johns Hopkins University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
</authors>
<title>Towards a comprehensive medical language processing system: methods and issues.</title>
<date>1997</date>
<booktitle>In Proc AMIA Annu Fall Symp.</booktitle>
<pages>595--9</pages>
<contexts>
<context position="1570" citStr="Friedman, 1997" startWordPosition="219" endWordPosition="220">le rules. Our parser achieved a 77% accurate parse training on only 830 sentences. Further work will evaluate the usefulness of this parse for lexical acquisition. 1 Introduction Natural Language is a vital medium in medicine. Health care providers rely on medical narratives for recording, representing and sharing complex medical information such as the description of images, explanation of test results, or the summary of a patient’s hospital visit. Natural Language Processing (NLP) tools have been applied to medical narrative for a variety of applications, such as triggering clinical alerts (Friedman, 1997) and document classification (Wilcox, 2000). The effort required to create and maintain NLP systems in the medical setting can be prohibitive. Most language processors require a domain-specific semantic lexicon to function and, so far, these lexica have been created manually. The time and cost involved in creating these knowledge structures put limits on the extensibility and portability of NLP systems (Hripcsak, 1998). One solution to this bottleneck is to use machine learning to assist in categorizing lexemes into semantic classes. Such a tool could reduce the difficulty in porting NLP syste</context>
</contexts>
<marker>Friedman, 1997</marker>
<rawString>Friedman, C. (1997). Towards a comprehensive medical language processing system: methods and issues. In Proc AMIA Annu Fall Symp. 595-9.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Friedman</author>
</authors>
<title>Architectural requirements for a multipurpose natural language processor in the clinical environment.</title>
<date>1995</date>
<booktitle>In Proc 19th Annu SCAMC.</booktitle>
<pages>347--51</pages>
<contexts>
<context position="23666" citStr="Friedman, 1995" startWordPosition="3957" endWordPosition="3958">cceptable parse (Sekine, 1992). The results also show that limiting the sentence length can improve the accuracy of the parser. If our sole desire is the generation of head-modifier pairs, using a large number of shorter sentences may be equivalent to using fewer longer ones. We also believe that the parser may be improved through lexicalization, but that remains future work. The ability to generate a good parser from such a small training set is important in the medical domain. Previous work has shown that different medical domains have to be treated as separate languages for successful NLP (Friedman, 1995). Therefore, it is likely that any medical domain we wish to parse will require its own training set for the parser. If extensive training set preparation was required, then we are simply trading one difficult task for another: the task of manually creating and maintaining a semantic lexicon with the task of hand dependency-parsing large amounts of text. Although the task of hand-parsing 1,000 sentences of discharge summaries is not trivial, it is reasonable and manageable and does not require extensive medical knowledge. The shift-reduce parser described by (Hermjakob, 1997) also requires rel</context>
</contexts>
<marker>Friedman, 1995</marker>
<rawString>Friedman C, et. al (1995). Architectural requirements for a multipurpose natural language processor in the clinical environment. In Proc 19th Annu SCAMC. 347-51.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hajic</author>
<author>K Ribarov</author>
</authors>
<title>Rule-Based Dependencies.</title>
<date>1997</date>
<booktitle>Workshop on Empirical Learning of Natural Language Processing Tasks,</booktitle>
<location>Prague, Czech Republic.</location>
<marker>Hajic, Ribarov, 1997</marker>
<rawString>Hajic, J. and K. Ribarov (1997). Rule-Based Dependencies. Workshop on Empirical Learning of Natural Language Processing Tasks, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z Harris</author>
</authors>
<title>A Theory of Language and Information.</title>
<date>1991</date>
<publisher>Oxford University Press: Oxford.</publisher>
<contexts>
<context position="2627" citStr="Harris, 1991" startWordPosition="379" endWordPosition="380"> bottleneck is to use machine learning to assist in categorizing lexemes into semantic classes. Such a tool could reduce the difficulty in porting NLP systems from one domain to another. 2 Dependency Grammars One approach to semantic categorization is the use of syntactic features (Kokkinakis, 2001). This is based on the assumption that lexemes that share similar syntactic relations to other lexemes in the corpus will be semantically similar (Dorr, 2000). The idea of clustering words based on syntactic features has been well investigated in general language (Pereira, 1993; Li, 1998) However, (Harris, 1991) states that the syntactic relationships are more well-defined and have less variation in scientific languages (sublanguages), such as the ones used in medical texts. Identifying word classes using syntactic relationships should be simpler and potentially more useful in these types of languages. Dependency grammars (Hudson, 1991) generate parses where words in a sentence are related directly to the word which is its syntactic head. Each word, except for the root has exactly one head, and the structure is a tree. The analysis does not generate any intermediate syntactic structures. Figure 1 sho</context>
</contexts>
<marker>Harris, 1991</marker>
<rawString>Harris, Z. (1991). A Theory of Language and Information. Oxford University Press: Oxford.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hermjakob</author>
<author>R J Mooney</author>
</authors>
<title>Learning Parse and Translation Decisions From Examples With Rich Context,</title>
<date>1997</date>
<booktitle>Proc. of ACLEACL Conf.</booktitle>
<pages>482--489</pages>
<marker>Hermjakob, Mooney, 1997</marker>
<rawString>Hermjakob U. &amp; Mooney R.J. (1997) Learning Parse and Translation Decisions From Examples With Rich Context, Proc. of ACLEACL Conf. 482-489.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Hripcsak</author>
<author>G Kuperman</author>
</authors>
<title>Extracting Findings from Narrative Reports: Software Transferability and Sources of Physician Disagreement.</title>
<date>1998</date>
<journal>Methods Inf Med</journal>
<volume>37</volume>
<pages>1--7</pages>
<marker>Hripcsak, Kuperman, 1998</marker>
<rawString>Hripcsak, G., G. Kuperman, et al. (1998). Extracting Findings from Narrative Reports: Software Transferability and Sources of Physician Disagreement. Methods Inf Med 37. 1-7.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Hudson</author>
</authors>
<title>English Word Grammar.</title>
<date>1991</date>
<location>Blackwell: Cambridge, Mass.</location>
<contexts>
<context position="2958" citStr="Hudson, 1991" startWordPosition="425" endWordPosition="426">on that lexemes that share similar syntactic relations to other lexemes in the corpus will be semantically similar (Dorr, 2000). The idea of clustering words based on syntactic features has been well investigated in general language (Pereira, 1993; Li, 1998) However, (Harris, 1991) states that the syntactic relationships are more well-defined and have less variation in scientific languages (sublanguages), such as the ones used in medical texts. Identifying word classes using syntactic relationships should be simpler and potentially more useful in these types of languages. Dependency grammars (Hudson, 1991) generate parses where words in a sentence are related directly to the word which is its syntactic head. Each word, except for the root has exactly one head, and the structure is a tree. The analysis does not generate any intermediate syntactic structures. Figure 1 shows an example of a sentence with a dependency grammar parse. There has been interest in learning dependency grammars from corpora. Collins (Collins, 1996) used dependencies as the backbone for his probabilistic parser and there has been work on learning both probabilistic (Carroll, 1992; Lee, 1999; Paskin, 2001) and transformatio</context>
</contexts>
<marker>Hudson, 1991</marker>
<rawString>Hudson, Richard. (1991). English Word Grammar. Blackwell: Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Kokkinakis</author>
</authors>
<title>Syntactic Parsing as a Step for Automatically Augmenting Semantic Lexicons,</title>
<date>2001</date>
<booktitle>In Proceedings of the 39th ACL and the 10th EACL,</booktitle>
<pages>13--18</pages>
<publisher>Student</publisher>
<location>Toulouse, France.</location>
<contexts>
<context position="2314" citStr="Kokkinakis, 2001" startWordPosition="331" endWordPosition="332">be prohibitive. Most language processors require a domain-specific semantic lexicon to function and, so far, these lexica have been created manually. The time and cost involved in creating these knowledge structures put limits on the extensibility and portability of NLP systems (Hripcsak, 1998). One solution to this bottleneck is to use machine learning to assist in categorizing lexemes into semantic classes. Such a tool could reduce the difficulty in porting NLP systems from one domain to another. 2 Dependency Grammars One approach to semantic categorization is the use of syntactic features (Kokkinakis, 2001). This is based on the assumption that lexemes that share similar syntactic relations to other lexemes in the corpus will be semantically similar (Dorr, 2000). The idea of clustering words based on syntactic features has been well investigated in general language (Pereira, 1993; Li, 1998) However, (Harris, 1991) states that the syntactic relationships are more well-defined and have less variation in scientific languages (sublanguages), such as the ones used in medical texts. Identifying word classes using syntactic relationships should be simpler and potentially more useful in these types of l</context>
</contexts>
<marker>Kokkinakis, 2001</marker>
<rawString>Kokkinakis D. (2001), Syntactic Parsing as a Step for Automatically Augmenting Semantic Lexicons, In Proceedings of the 39th ACL and the 10th EACL, Toulouse, France. Student Workshop. 13-18.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Lee</author>
<author>K-S Choi</author>
</authors>
<title>A Reestimation Algorithm for Probabilistic Dependency Grammars.</title>
<date>1999</date>
<journal>Natural Language Engineering</journal>
<volume>5</volume>
<issue>3</issue>
<pages>251--270</pages>
<marker>Lee, Choi, 1999</marker>
<rawString>Lee, S. and K.-S. Choi (1999). A Reestimation Algorithm for Probabilistic Dependency Grammars. Natural Language Engineering 5(3). 251-270.</rawString>
</citation>
<citation valid="false">
<authors>
<author>H Li</author>
</authors>
<title>and Abe N.(1998). Word clustering and disambiguation based on co-occurrence data.</title>
<booktitle>In Proceedings of COLING - ACL&apos;98.</booktitle>
<pages>749--755</pages>
<marker>Li, </marker>
<rawString>Li H. and Abe N.(1998). Word clustering and disambiguation based on co-occurrence data. In Proceedings of COLING - ACL&apos;98. 749-755</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Paskin</author>
</authors>
<title>Grammatical Bigrams. In</title>
<date>2001</date>
<booktitle>Advances in Neural Information Processing Systems 14.</booktitle>
<editor>T. Dietterich, S. Becker, and Z. Gharahmani eds.,</editor>
<publisher>MIT Press:</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="3540" citStr="Paskin, 2001" startWordPosition="518" endWordPosition="519">endency grammars (Hudson, 1991) generate parses where words in a sentence are related directly to the word which is its syntactic head. Each word, except for the root has exactly one head, and the structure is a tree. The analysis does not generate any intermediate syntactic structures. Figure 1 shows an example of a sentence with a dependency grammar parse. There has been interest in learning dependency grammars from corpora. Collins (Collins, 1996) used dependencies as the backbone for his probabilistic parser and there has been work on learning both probabilistic (Carroll, 1992; Lee, 1999; Paskin, 2001) and transformation based dependency grammars (Hajic, 1997). There are a number of attributes of dependency grammars which make them ideal for our goal of investigating medical sublanguage. First, the semantics of a word are often defined by a feature space of related words. The head-dependent relationships generated by a dependency parse can be used as the relationship for acquisition. Second, dependency grammars may be a better fit for parsing medical text. Medical text is frequently include telegraphic omissions, run-on structures, improper use of conjunctions, left attaching noun modifiers</context>
</contexts>
<marker>Paskin, 2001</marker>
<rawString>Paskin, M. (2001). Grammatical Bigrams. In T. Dietterich, S. Becker, and Z. Gharahmani eds., Advances in Neural Information Processing Systems 14. MIT Press: Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Pereira</author>
<author>N Tishby</author>
<author>L Lee</author>
</authors>
<title>Distributional clustering of English words.</title>
<date>1993</date>
<booktitle>In 30th Annual Meeting of the ACL,</booktitle>
<pages>183--190</pages>
<marker>Pereira, Tishby, Lee, 1993</marker>
<rawString>Pereira F., Tishby, N., Lee, L (1993). Distributional clustering of English words. In 30th Annual Meeting of the ACL, 183-190.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ramshaw</author>
<author>M P Marcus</author>
</authors>
<title>Exploring the statistical derivation of transformational rule sequences for part-ofspeech tagging.</title>
<date>1994</date>
<booktitle>In Proceedings of the Balancing Act Workshop on Combining Symbolic and Statistical Approaches to Language, Association for Computational Linguistics.</booktitle>
<pages>86--95</pages>
<marker>Ramshaw, Marcus, 1994</marker>
<rawString>Ramshaw, L. A., Marcus, M. P. (1994). Exploring the statistical derivation of transformational rule sequences for part-ofspeech tagging. In Proceedings of the Balancing Act Workshop on Combining Symbolic and Statistical Approaches to Language, Association for Computational Linguistics. 86-95.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Sager</author>
</authors>
<title>Natural Language Information Processing: A Computer Grammar of English and its Applications.</title>
<date>1981</date>
<location>Addison-Wesley: Reading, Massachusetts.</location>
<contexts>
<context position="4158" citStr="Sager, 1981" startWordPosition="609" endWordPosition="610">ransformation based dependency grammars (Hajic, 1997). There are a number of attributes of dependency grammars which make them ideal for our goal of investigating medical sublanguage. First, the semantics of a word are often defined by a feature space of related words. The head-dependent relationships generated by a dependency parse can be used as the relationship for acquisition. Second, dependency grammars may be a better fit for parsing medical text. Medical text is frequently include telegraphic omissions, run-on structures, improper use of conjunctions, left attaching noun modifiers etc (Sager, 1981). In many cases, many traditional phrase structures are absent or altered, making a phrase structure parse using traditional production rules difficult. A dependency grammar may still capture useful syntactic relationships when an accurate phrase grammar parse is not possible. In this way, a dependency parse may be compared to a shallow parse, in that it can return a partial analysis. However, even with a shallow parser, we would still interested in the dependency relationships inside the chunks. Third, the syntactic grammar of medical English, specifically regarding discharge summaries, is si</context>
</contexts>
<marker>Sager, 1981</marker>
<rawString>Sager N. (1981). Natural Language Information Processing: A Computer Grammar of English and its Applications. Addison-Wesley: Reading, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Sekine</author>
</authors>
<title>Automatic Learning for Semantic Collocation.</title>
<date>1992</date>
<booktitle>In 3rd Conf. on Applied Natural Language Processing :Trent -</booktitle>
<contexts>
<context position="23081" citStr="Sekine, 1992" startWordPosition="3861" endWordPosition="3862"> parsers on a number of medical corpora, including radiology reports, pathology reports and progress notes. Therefore, we require a flexible solution that would not demand reengineering the parser for every new domain. The learning algorithm described here could be used on any general corpus where the sentences can be given a dependency parse. We intend to evaluate the algorithm on more general corpora in the future. Overall, the results are very encouraging. Keeping in mind our goal of gathering headmodifier pairs for machine learning, a 77% accurate parse is approaching an acceptable parse (Sekine, 1992). The results also show that limiting the sentence length can improve the accuracy of the parser. If our sole desire is the generation of head-modifier pairs, using a large number of shorter sentences may be equivalent to using fewer longer ones. We also believe that the parser may be improved through lexicalization, but that remains future work. The ability to generate a good parser from such a small training set is important in the medical domain. Previous work has shown that different medical domains have to be treated as separate languages for successful NLP (Friedman, 1995). Therefore, it</context>
</contexts>
<marker>Sekine, 1992</marker>
<rawString>Sekine, S. et. al (1992) Automatic Learning for Semantic Collocation. In 3rd Conf. on Applied Natural Language Processing :Trent - Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Wilcox</author>
<author>G Hripcsak</author>
</authors>
<title>Medical Text Representations for Inductive Learning.</title>
<date>2000</date>
<booktitle>Proc AMIA Symp.</booktitle>
<pages>923--7</pages>
<marker>Wilcox, Hripcsak, 2000</marker>
<rawString>Wilcox, A, Hripcsak G. (2000). Medical Text Representations for Inductive Learning. Proc AMIA Symp. 923-7.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>