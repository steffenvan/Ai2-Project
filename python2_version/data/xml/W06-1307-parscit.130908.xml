<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.944203">
DRT Representation of Degrees of Belief
</title>
<author confidence="0.985765">
Yafa Al-Raheb
</author>
<affiliation confidence="0.9796795">
National Centre for Language Technology
Dublin City University
</affiliation>
<address confidence="0.640335">
Ireland
</address>
<email confidence="0.990464">
yafa.alraheb@gmail.com
</email>
<sectionHeader confidence="0.993689" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9992249">
This paper investigates the problems facing mod-
elling agents’ beliefs in Discourse Representation
Theory (DRT) and presents a viable solution in the
form of a dialogue-based DRT representation of
beliefs. Integrating modelling dialogue interaction
into DRT allows modelling agents’ beliefs, inten-
tions and mutual beliefs. Furthermore, it is one of
the aims of the paper to account for the important
notion of agents’ varying degrees of belief in differ-
ent contexts.1
</bodyText>
<sectionHeader confidence="0.998793" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999922789473684">
Heydrich et al. remark that ‘serious description of
natural dialogue seems to necessitate that we con-
sider the mental states of the speakers involved’
(1998).2 This is a step that is by no means easy. It
is the aim of this paper to integrate previous work
on beliefs in DRT and dialogue theory in order to
model the mental states of agents in dialogue.
The connection between beliefs, intentions and
speech or dialogue acts has been noted in the liter-
ature. Stalnaker notes, for instance, that
[i]f we understand contexts, and the
speech acts made in contexts, in terms
of the speaker’s beliefs and intentions,
we have a better chance of giving sim-
pler and more transparent explanations
of linguistic behaviour (Stalnaker 2002:
720).
The kind of agent beliefs we are concerned with
here arises in dialogue interaction. The nature of
</bodyText>
<footnote confidence="0.9826614">
1I gratefully acknowledge support from Science Founda-
tion Ireland grant 04/IN/I527.
2Other names for mental state used in the literature in-
clude ‘information state’, ‘conversational score’, and ‘dis-
course context’ (Larsson and Traum 2000).
</footnote>
<bodyText confidence="0.997894">
interaction dictates that the strength or degree of
belief varies depending on contextual factors. This
can be seen from the following example:
</bodyText>
<listItem confidence="0.7024644">
(1) A: I want to make a booking for my
wife.
B: Yeah.
A: What time is the Thailand flight on
Monday?
</listItem>
<bodyText confidence="0.9821399">
B: It’s at 2 pm.
In example (1) B does not necessarily need to be-
lieve the presupposition (given information) that
A has a wife. For the purposes of the conversa-
tion, which is providing A with information, B can
simply ‘go along with’ the presupposition and not
have it as a member of his beliefs (i.e. his belief
set) (Stalnaker 2002). Similarly, let us consider the
following example, (2). The speaker is a customer
in a clothing shop.
</bodyText>
<listItem confidence="0.789603857142857">
(2) S1: I want to buy a dress for my wife.
H1: Is it for a formal occasion?
S2: Yes.
H2: What is her favourite colour?
S3: She doesn’t like red anymore.
H3: Does your wife like black?
S4: Yes
</listItem>
<bodyText confidence="0.9999035">
As the speaker, S, introduces the presupposition
that he has a wife, the hearer, H, can come to the
conclusion that S believes S has a wife. However,
when the hearer comes to refer to S’s wife, H does
not necessarily have to believe S has a wife. H
can simply go along with the information that the
speaker has a wife and use this form of acceptance
in H2 without committing to ‘strongly believing’
it. Indeed, the speaker may be buying a dress for
his mistress rather than his wife. By going along
</bodyText>
<page confidence="0.992663">
46
</page>
<note confidence="0.5651655">
Proceedings of the 7th SIGdial Workshop on Discourse and Dialogue, pages 46–53,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.995592333333333">
with it, the hearer does not have to commit him-
self to believing that the speaker has a wife. What
is more at stake than believing that the speaker in-
deed has a wife and not a mistress is closing the
sale. Contrast examples (1) and (2) with example
(3):
</bodyText>
<listItem confidence="0.942564125">
(3) S1: You have to get Peter’s son a Chris-
tening present.
H1: Peter has a son?
S2: Sorry I forgot to mention that be-
fore.
H2: Ok, what sort of present should I
get him?
S3: A toy would be nice.
</listItem>
<bodyText confidence="0.999969468085107">
In this context, the hearer, H, is required to commit
more strongly to the presupposition of Peter hav-
ing a son than simply going along with it, since H
is being asked to buy a Christening present. The
fact that H2 agrees to buying a present for Peter’s
son reflects more commitment to the presuppo-
sition than B shows in example (1). Considera-
tions of this kind lead to the conclusion that dif-
ferent contexts call for varying strengths of beliefs
and belief representation. We shall not attempt to
describe all the contextual factors that can cause
strength of belief to vary. The point is, rather, that
we clearly need to model strength of belief and
no current model of DRT incorporates such a pro-
posal. This paper, thus, makes an original proposal
for including a system for graded beliefs in the be-
lief spaces (or sets) of both the speaker and the
hearer.
Bearing this in mind, there is a need in DRT for
representing the differing beliefs of agents in dia-
logue and their beliefs (meta-beliefs) about other
agents’ beliefs or mental state. By focussing on
the intentions of speakers and hearers and infer-
ring agents’ intentions in making an utterance, the
approach presented in this paper aims at fulfilling
this need. It follows that, to have a ‘full’ theory of
beliefs and to have an insight into the mental states
of agents in dialogue (the speaker and the hearer),
it is necessary to have a representation of agents’
beliefs, degrees of beliefs, and the dialogue acts
expressed by their utterances (Asher 1986). This is
also in order to strengthen the link between utter-
ances and agents’ intentions in dialogue. The di-
alogue act or function performed by the utterance
tells us something about the speaker’s beliefs. Fur-
thermore, what is also needed is a representation
of beliefs that are shared between, or are common
to, the two agents.
The question is: how can DRT best model be-
liefs? The following section, 2, outlines the prob-
lems facing modelling beliefs in DRT. Section 3
presents a graded view of agents’ beliefs in dia-
logue as a solution to these problems. This is fol-
lowed by a description of the relationship between
belief and mutual belief, section 4, and then of the
relationship between belief and dialogue acts, sec-
tion 5.
</bodyText>
<sectionHeader confidence="0.9910325" genericHeader="method">
2 Problems Facing Modelling Beliefs in
DRT
</sectionHeader>
<bodyText confidence="0.999933243243243">
According to Heydrich et al. (1998), paradigms of
dynamic semantics (DRT, Situation Semantics and
Dynamic Predicate Logic) face three obstacles in
modelling dialogue. First, there is the problem of
adapting the paradigm, originally made to model
monological discourse, to the description of dia-
logue with different agents. The second problem
is the description of mental states and the beliefs
of the agents. The third problem is in explaining
how the mental states are related to overt linguistic
behaviour.
With respect to the first problem, DRT has grad-
ually attempted to address problems of belief rep-
resentation in dialogue. For example, in Prole-
gomena, Kamp introduces a simple model of ver-
bal communication (Kamp 1990: 71), which con-
sists of two agents, A and B, and their mental
states K(A) and K(B). Later work by Kamp et
al. (2005) introduces agent modelling for single-
sentence discourse, namely the hearer. The treat-
ment presented in this paper allows the represen-
tation of dialogue with different agents, thus, ad-
dressing the first problem identified by Heydrich
et al. (1998).
With regard to the second problem, however,
DRT has been primarily concerned with repre-
senting utterances containing propositional atti-
tudes such as ‘believe’, rather than the beliefs and
meta-beliefs of agents. Segmented-DRT (SDRT)
has mainly focused on belief update and revision
(Asher and Lascarides 2003). The treatment in
this paper takes previous work on beliefs in dy-
namic semantics as a starting point and extends it
to reach a richer representation of the interaction
between mental states and the linguistic content of
utterances. For example, both speaker and hearer
mental states are represented and the beliefs and
</bodyText>
<page confidence="0.998693">
47
</page>
<bodyText confidence="0.999145380952381">
meta-beliefs of agents are reviewed after each ut-
terance.
As a semantic theory, DRT tells us which dis-
course referents are needed in context. However,
DRT does not deal with planning, nor with prag-
matic aspects of contexts rendered through re-
lating the current utterance to agents’ intentions.
Kamp et al.’s (2005) expansion of the original,
also known as ‘vanilla’, DRT (Poesio and Traum
1997a), deal minimally with intentions. To deal
with the third problem mentioned by Heydrich et
al., Al-Raheb (2005) has already outlined a prag-
matic extension to DRT that makes it appropriate
for linking the current utterance and agents’ inten-
tions.
The present paper aims to show how that link
can be strengthened through modelling agents’ in-
tentions and relating them to the dialogue acts
communicated via utterances. In relation to this
link, the significance of degrees of belief is ex-
plained in the following section.
</bodyText>
<figure confidence="0.38969">
iyoum
</figure>
<figureCaption confidence="0.995514">
Figure 1: Hearer Recognition of S1
</figureCaption>
<sectionHeader confidence="0.905353" genericHeader="method">
3 Degrees of Belief
</sectionHeader>
<bodyText confidence="0.999632228571429">
To our knowledge, there is no account in DRT
that accommodates strengths or degrees of belief
of agents in dialogue. This section addresses this
gap and proposes initially two strengths of belief
involved in dialogue to be expanded in future re-
search to include further degrees of belief. Modal
expressions, including words such as ‘possibly’
and ‘might’, are evidence that there exist more de-
grees of belief than the ones discussed in this pa-
per.
The beliefs of an agent are ‘her model of how
things are’ (Traum 1994: 15). The notion of belief
(or strong belief) is to be understood in relation
to the agent: it is what the agent takes to be true.
There is an important philosophical background to
the discussion of ‘belief’ and ‘knowledge’. It is
outside the scope of this paper to review all the
literature here. Quine (1960), Hintikka (1962),
Lewis (1969, 1979), and Davidson (1983) are rep-
resentative. The term ‘belief’ is understood in this
paper to refer to propositions strongly held by the
agent to be true and when making utterances relat-
ing to them, the speaker not only commits herself
to their truth but also communicates to the hearer
that she, the speaker, believes those proposition to
be true.
Another degree of belief called acceptance is
accounted for in this model. Acceptance consists
of the agent’s weakly believed propositions. The
agent may be going along with what the speaker
is saying or has acquired a new proposition based
on the speaker’s utterance which has not yet been
confirmed into a stronger belief.
To illustrate what is meant by the distinction be-
tween belief and acceptance, let us look at:
</bodyText>
<listItem confidence="0.728402">
(4) S1: I need to buy new shoes for Mary’s
</listItem>
<bodyText confidence="0.958148166666667">
party.
H1: Try Next on Henry Street.
The speaker tells the hearer that she has to buy
new shoes for Mary’s party. In this example, the
hearer already (strongly) believes there is a party
and he suggests a place where the speaker can buy
them. Figure 1 demonstrates the hearer’s mental
state after hearing the speaker’s utterance, S1. The
hearer’s mental state is represented by a Discourse
Representation Structure (DRS), which contains
three sub-DRSs, one for intention (referred to by
‘attitude(you, ‘INT’, drs6)’ and the label for the
intention DRS, drs6), another for the belief DRS
containing strong beliefs (referred to by ‘attitude(i,
‘BEL’, drs4)’ and the the label for the belief DRS,
drs4), and finally the acceptance DRS contain-
ing weak beliefs (referred to by ‘attitude(i, ‘AC-
CEPT’, drs2)’ and the the label for the acceptance
</bodyText>
<figure confidence="0.881754419354839">
s
c1: buy(you,c2)
c2: newShoes(s)
attitude(you, ‘ACCEPT’, drs3)
drs3:
attitude(i, ‘ACCEPT’, drs2)
attitude(i, ‘BEL’, drs4)
y
b1: mary(m)
b2: party(y)
b3: has(m,y)
attitude(you, ‘BEL’, drs5)
s
b4: mary(m)
b5: party(y)
b6: has(m,y)
b7: buy(you,b8)
b8: newShoes(s)
drs5:
attitude(you, ‘INT’, drs6)
y s
p1: mary(m)
p2:party(y)
p3: has(m,y)
a1: buy(you,a2)
a2: newShoes(s)
inform(you, i, a1)
drs2:
drs4:
drs6:
drs1:
</figure>
<page confidence="0.976133">
48
</page>
<bodyText confidence="0.9391035">
DRS, drs2).3
If we change example (4) so that the hearer does
not actually hold the belief that there is a party, as
in:
</bodyText>
<listItem confidence="0.426858666666667">
(5) S1: I need to buy new shoes for Mary’s
party.
H1: I didn’t realize Mary is throwing a
party.
S2: Yeah she is. It’s next Tuesday.
H2: You can probably buy them at Next.
</listItem>
<bodyText confidence="0.9997931">
The hearer does not necessarily need to strongly
believe that Mary is throwing a party. He can ‘go
along with’ or accept it and even suggest a place
where the speaker can buy the shoes. The exis-
tence of a party does not affect the hearer person-
ally or directly, i.e. he does not need to act on
it. However, let us now consider the effect if we
change the example again so that the hearer does
not know about Mary’s party, nor that he is re-
quired to buy new shoes, as in:
</bodyText>
<listItem confidence="0.562976285714286">
(6) S1: You need to buy new shoes for
Mary’s party.
H1: I didn’t realize Mary is throwing a
party.
S2: Yeah she is. You should try Next on
Henry Street.
H2: I will.
</listItem>
<bodyText confidence="0.999959666666667">
This time, for the hearer to commit to buying
something for a party (in H2) that he did not even
know existed suggests a stronger degree of belief
than that of ‘going along with’ the speaker having
to buy it. The existence of the party affects the
hearer personally and directly. Therefore, agree-
ing to buy new shoes justifies the inference that he
believes rather than just accepts there is a party.
This is what the paper describes as belief, or a
strong degree of belief. Contrast Figure 1 with the
figure representing the speaker’s mental state after
hearing H2 in example 6, Figure 2.
</bodyText>
<sectionHeader confidence="0.988196" genericHeader="method">
4 Beliefs and Mutual Beliefs
</sectionHeader>
<bodyText confidence="0.999647">
The treatment of beliefs that we are developing
here requires an explicit account of how the be-
lief spaces or DRSs of two agents can interact.
</bodyText>
<footnote confidence="0.9994995">
3Inside the agent’s DRS, ‘i’ is used to refer to the agent
and ‘you’ is used to refer to the other agent. Assertions are
marked by ‘a,,,’, presuppositions by ‘p,,,’, believed informa-
tion by ‘b,,,’ and accepted information by ‘c,,,’.
</footnote>
<note confidence="0.41762">
i you m
</note>
<figureCaption confidence="0.996956">
Figure 2: Speaker Recognition of H2
</figureCaption>
<bodyText confidence="0.999282538461539">
‘Mutual belief’, also referred to as ‘mutual knowl-
edge’, is the term used by Traum (1994) among
others, where a group of individuals may believe
X, where X may or may not be true. Stalnaker’s
(2002) ‘common belief’ is comparable to what
others call mutual belief. For X to be a mutual
belief, it has to be accessible to a group; all be-
lieve X and all believe that all believe X, and all
believe that all believe that all believe X.
In face-to-face communication, the hearer be-
lieves that the speaker believes what she, the
speaker, is communicating. On the other hand, un-
less the hearer indicates doubt or objects to what
the speaker is saying, the speaker assumes that the
hearer believes what the speaker has said – which
is consistent with expectations under Gricean co-
operativeness assumptions (1989). The speaker
also assumes that the hearer now has the belief that
the speaker believes what she just said. This as-
sumption is what leads to ‘mutual’ beliefs (Kamp
1990: 79).
However, mutual belief can be viewed as the
process of establishing that the speaker and the
hearer hold the same belief. One way in which
this process may occur is when the speaker holds
a belief and communicates that belief to the hearer.
</bodyText>
<figure confidence="0.99457825">
attitude(you, ‘ACCEPT’, drs3)
drs4:
attitude(i, ‘ACCEPT’, drs2)
attitude(i, ‘BEL’, drs4)
s n
b1: mary(m)
b2:party(y)
b3: has(m,y)
b4: buy(you,b5)
b5: newShoes(s)
b6: try(you,b7)
b7: next(n)
attitude(you, ‘BEL’, drs5)
b8: mary(m)
b9:party(y)
b10: has(m,y)
b11: buy(you,b12)
b12: newShoes(s)
b13: try(you,b13)
b14: next(n)
drs5:
attitude(you, ‘INT’, drs7)
s n
p1: newShoes(s)
p2: next(n)
drs7: a1: buy(you,p1)
a2: try(you,p2)
inform(you,i,a1)
inform(you,i,a2)
drs2:
drs4:
drs1:
</figure>
<page confidence="0.997343">
49
</page>
<bodyText confidence="0.999876461538462">
This belief may then be adopted by the hearer who
can provide feedback to the speaker that the infor-
mation communicated has now acquired the status
of belief in an ideal situation with a cooperative
hearer. When both participants reach the conclu-
sion that S bel(ieves) X, H bel X, H bel S bel X,
and S bel H bel X, then mutual belief is estab-
lished. The speaker in example (7) believes her
neighbour is a weirdo. Whether the utterance is
informative (new) or not depends on the context.
In this example, (7), the speaker may not already
have the belief that the hearer believes her neigh-
bour is a weirdo.
</bodyText>
<listItem confidence="0.7338875">
(7) Speaker: My neighbour is such a
weirdo.
</listItem>
<bodyText confidence="0.99922825">
Hearer: Yeah, he is. I saw him peeping
through your window the other day.
However, after the hearer makes his utterance, the
speaker can now strongly believe that the hearer
believes her neighbour is a weirdo, that he believes
she believes her neighbour is a weirdo, and now
she believes he believes her neighbour is a weirdo.
Figure 3 shows the level of nesting to accommo-
date the mutual belief that the speaker’s neighbour
is a weirdo. It is possible when this level of nesting
is reached to have a separate DRS or space for mu-
tual beliefs, called ‘mutual belief DRS’. In which
case, the propositions held in drs6, can now be
removed from drs6 and added to the ‘mutual be-
lief DRS’. Figure 3 represents the speaker’s men-
tal state after the hearer makes his utterance. For
the purposes of this example, the DRT represented
in Figure 3 will mainly focus on the speaker’s be-
lief DRT.
Achieving mutual belief is immensely helped
by dialogue acts. For example, when a hearer
provides strong feedback about a new proposition
(cf. drs7 in Figure 3), the speaker can come to
believe the hearer believes that proposition. Sec-
tion 5 shows the importance of considering the di-
alogue acts expressed by an assertion (new infor-
mation) and their relationship to degrees of belief
and strengthening of beliefs.
</bodyText>
<sectionHeader confidence="0.968637" genericHeader="evaluation">
5 Beliefs and Dialogue Acts
</sectionHeader>
<bodyText confidence="0.99990025">
When someone makes an assertion, they commu-
nicate not only information they assume to be new
to the hearer, but also communicate to the hearer
information about their own beliefs. In order to
</bodyText>
<figure confidence="0.309367">
i you
</figure>
<figureCaption confidence="0.998424">
Figure 3: Speaker Recognition
</figureCaption>
<bodyText confidence="0.99985219047619">
model beliefs in dialogue, it is necessary to un-
derstand what the representation of dialogue in-
volves. A dialogue is ‘a cooperative undertaking
of agents engaged in developing and transform-
ing their common situation’, involving verbal and
non-verbal action (Heydrich et al. 1998: 21). In
a dialogue, utterances give rise to dialogue acts
(cf. agents’ intention DRSs in Figures 1, 2 and
3), named speech acts by some, and conversation
acts by others (Traum 1994).
One of the features of dialogue acts is how they
affect the agents’ mental states. As Traum points
out, ‘... speech acts are a good link between the
mental states of agents and purposeful communi-
cation’ (Traum 1999: 30). Each agent in dialogue
needs to have a representation of their beliefs and
the other agent’s beliefs or cognitive state in or-
der for a dialogue act to be felicitous in Austin’s
and Searle’s sense (Asher 1986). That is to say,
dialogue acts depend on agents’ beliefs for inter-
pretation.
</bodyText>
<figure confidence="0.988938357142857">
attitude(you, ‘ACCEPT’, drs3)
drs3:
attitude(i, ‘ACCEPT’, drs2)
attitude(i, ‘BEL’, drs4)
x y
b1: neighbour(x)
b2: have(i,x)
b3: weirdo(x)
b4: window(y)
b5: have(i,y)
b6: peeping-through(x,y)
b7: saw(you,b6)
attitude(you, ‘BEL’, drs5)
b8: neighbour(x)
b9: have(i,x)
b10: weirdo(x)
b11: window(y)
b12: have(i,y)
b13: peeping-through(x,y)
b14: saw(you,b13)
attitude(i, ‘BEL’, drs6)
b15: neighbour(x)
b16: have(i,x)
b17: weirdo(x)
drs6: b18: window(y)
b19: have(i,y)
b20: peeping-through(x,y)
b21: saw(you,b20)
drs5:
attitude(you, ‘INT’, drs7)
x y
p1: neighbour(x)
p2: weirdo(x)
p3: window(y)
drs7: p4: have(i,y)
a1: peeping-through(x,y)
a2: saw(you,a1)
strongPosFeedback(you,i,p2)
inform(you,i,a2)
drs2:
drs4:
drs1:
</figure>
<page confidence="0.992389">
50
</page>
<bodyText confidence="0.985568960784314">
Each assertion made has one ‘function’ or more.
For example, the function of a statement could be
to make a claim about the world. Traum (1997) di-
vides statements into ‘assert’, ‘re-assert’, and ‘in-
form’. ‘Assert’ is trying to ‘change’ the belief of
the addressee. The result of assert is that the hearer
now assumes that the speaker is trying to get the
hearer to believe the assertion. ‘Re-assert’ can be
used when participants try to verify old informa-
tion, and not necessarily inform of something new.
‘Inform’ means that the speaker is trying to pro-
vide the hearer with information that the hearer
did not have before. However, Traum does not
go further to discuss cases where agents believe
their utterances (Traum 1994: 14). It is one of the
claims of this paper that agents in dialogue either
strongly or weakly believe their utterances in order
to be cooperative. It is possible to extend this ap-
proach in order to include cases where agents are
purposefully deceitful. However, this is left for fu-
ture research.
The adapted dialogue acts, or functions, in thiss
paper’s treatment of beliefs in DRT are mainly
‘inform’, ‘change belief’ and ‘other’. ‘Inform’
is used to communicate new information to the
hearer, whereas ‘change belief’ (or to use Poesio
and Traum’s (1997b) dialogue act term ‘assert’)
is used to change the hearer’s beliefs about some
proposition. The importance of the representation
introduced in section 3 in relation to dialogue acts
transpires in allowing us to make the distinction
between the dialogue acts ‘inform’ and ‘change
belief’ (‘assert’). To ‘inform’ the hearer of X, the
speaker needs to have the belief in her beliefs that
the hearer does not believe X, i.e. bel(S,-, bel(H,
X)). This is a constraint to making an informative
utterance. Figure 4 shows the speaker’s beliefs be-
fore making the utterance in example (8).
(8) The X-Files DVD is on sale on Amazon.
The speaker believes the hearer does not al-
ready believe that the X-Files DVD is on sale on
Amazon, drs3. This is demonstrated by the miss-
ing propositions representing ‘on sale on Amazon’
‘onSale(x, b4)’ and ‘at(a)’ from drs3 in Figure 4.
On the other hand, to make a ‘change belief’ or
an ‘assert’, the speaker would have reason to be-
lieve that the hearer believes something different
or the opposite of what the speaker believes, bel(S,
bel(H, -, X)). The DRT treatment of beliefs pro-
posed in this paper allows us to reflect this in
iyouxa
</bodyText>
<figureCaption confidence="0.996286">
Figure 4: Inform: Speaker’s utterance
</figureCaption>
<figure confidence="0.617703">
iyouxa
</figure>
<figureCaption confidence="0.999725">
Figure 5: Change belief
</figureCaption>
<bodyText confidence="0.959528434782609">
Figure 5, drs3, in which the speaker believes the
hearer believes the X-Files DVD is not on sale,
‘not(onSale(x))’.
The category ‘Other’ embraces any dialogue act
other than ‘inform’ and ‘change belief’, whose
recognition involves the same process explained
for others, e.g. ‘suggest’, ‘clarify’, and ‘explain’.4
The dialogue acts ‘accept’ and ‘reject’ come un-
der the umbrella of feedback as they can be in re-
sponse to, for instance, a ‘suggest’ dialogue act.
The dialogue act ‘clarify’ is used when a hearer
is having difficulty recognizing the speaker’s ut-
terance.5 On the other hand, ‘explain’ is when
the speaker responds to the hearer’s clarification
request and provides a clarifying utterance. The
hearer can accept, believe, or reject that explana-
tion. The dialogue act ‘suggest’ also instigates one
of three reactions: the hearer can accept, believe or
reject that suggestion and may provide feedback to
indicate which is his reaction. It is of more inter-
est to this paper to examine the effects of dialogue
acts on the hearer’s beliefs, and what dialogue acts
suggest about the speaker’s beliefs.
</bodyText>
<footnote confidence="0.995511166666667">
4It is possible for this category to be expanded to in-
clude more dialogue acts such as ‘question’, ‘answer’, ‘self-
correct’ and ‘offer’.
5Clarification is a form of feedback. ‘I didn’t hear what
you said’ is both ‘feedback’ act and an ‘inform’ (Schegloff et
al. 1977).
</footnote>
<figure confidence="0.98399295">
attitude(i, ‘BEL’, drs2)
b1: xFilesDVD(x)
b2: amazon(a)
b3: onSale(x, b4)
b4: at(a)
attitude(you, ‘BEL’, drs3)
drs3:
b5: xFilesDVD(x)
drs2:
attitude(i, ‘BEL’, drs2)
b1: xFilesDVD(x)
b2: amazon(a)
b3: onSale(x, b4)
b4: at(a)
attitude(you, ‘BEL’, drs3)
drs3: b5: xFilesDVD(x)
b6: not(onSale(x))
drs2:
drs1:
drs1:
</figure>
<page confidence="0.839822">
51
</page>
<figureCaption confidence="0.991862">
Figure 6: Feedback
</figureCaption>
<figure confidence="0.9990816">
Feedback
No
Feedback
H Accept
H Accept
Weak
Positive
Feedback
Strong
Positive
Feedback
H Bel
H Reject
Negative
Feedback
</figure>
<subsectionHeader confidence="0.962108">
5.1 Feedback and Agents’ Beliefs
</subsectionHeader>
<bodyText confidence="0.954674891304348">
Traum (1994) suggests that when an assertion is
made, the hearer has an obligation to produce
an ‘understanding act’. In general, acknowledge-
ment is expected in Traum’s treatment of speech
acts. This means that when a hearer responds with
‘okay’, the hearer can be taken to be providing
an acknowledgement and an acceptance. How-
ever, the hearer does not always provide feedback.
Grounding often happens as a result of implicit
rather than overt feedback and acknowledgement
(Bunt 1995).6 In fact, the treatment outlined in
this paper maintains that the lack of feedback is to
be considered a form of ‘weak positive feedback’,
an extension to Dynamic Interpretation Theory’s
(DIT) positive feedback (Bunt 1995). The hearer
does not object to the speaker’s utterance by not
providing feedback, since if the hearer did object,
he would explicitly do so.
When the speaker makes an assertion, the
hearer may indicate that the message has been re-
ceived (weak positive feedback), example (9.b).
Weak positive feedback may indicate understand-
ing, continued attention, or acknowledgement,
such as ‘uh huh’, and ‘yeah’ (Clark and Schaefer
1989). Another case of weak positive feedback is
provided by example (9.a) where the hearer does
not say anything. It is assumed that the hearer did
not have any problems and has received the asser-
tion, A. In the case of weak feedback, it can be
argued that this represents the ‘acceptance’ of A.7
Another response for the hearer is ‘strong posi-
6Grounding is a term adapted by Traum (1994) from
Clark and Schaefer’s (1989) work on establishing common
ground.
7This does not cancel cases where for social reasons, such
as politeness, the hearer does not necessarily agree with the
speaker, but does not wish to indicate it. The speaker can
wrongly or rightly come to the conclusion that the hearer ac-
cepts the assertion.
tive feedback’ (another extension to DIT’s positive
feedback), where the hearer not only indicates re-
ception of A, but also that she agrees that A (cf.
drs7 Figure 3). This is where confirming adoption
of new beliefs takes place, example (9.c). Reject-
ing A is another way of giving feedback, negative
feedback, as in example (9.d).
</bodyText>
<listItem confidence="0.992288666666667">
(9) Speaker: Mary loves John.
a. Hearer:
b. Hearer: aha.
c. Hearer: I couldn’t agree more!
d. Hearer: No, Mary is besotted with
Tom!
</listItem>
<bodyText confidence="0.999881444444444">
There are also degrees of belief that can be ex-
pressed according to the speech act used, firm ver-
sus ‘tentative’. Poesio and Traum pay less atten-
tion to ‘the attitudes expressed by the acts’ (Poesio
and Traum 1998: 221). Unlike Traum’s model, the
effects of the dialogue acts’ employed in agents’
DRSs on agents’ beliefs are considered in this pa-
per. Figure 6 demonstrates the link between feed-
back dialogue acts and agents’ beliefs.
</bodyText>
<sectionHeader confidence="0.999249" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999958785714286">
As this paper has demonstrated, beliefs vary in
strength according to context. Beliefs also change
with the coming of new information. The DRT
treatment discussed here allows for the represen-
tation of strong beliefs and weaker beliefs as well
as changes to beliefs. Agents in a dialogue may
form stronger beliefs as the dialogue progresses,
requiring moving the content of their weaker be-
liefs to the stronger belief space.
In sum, there is no account in standard DRT that
accommodates degrees of belief of agents in dia-
logue. This paper has addressed this omission and
suggested two degrees of belief involved in dia-
logue, namely ‘belief’ and ‘acceptance’. It is sug-
</bodyText>
<page confidence="0.994533">
52
</page>
<bodyText confidence="0.999981857142857">
gested that this is the initial step in representing
agents’ mental states in dialogue-oriented DRT.
However, this paper does not deal with words
which introduce more degrees of belief than the
two addressed in the model. It would be interest-
ing to see more degrees of belief represented in a
DRT dialogue model of agents in future research.
It is possible that such modal expressions can be
arranged on a scale corresponding to degrees of
belief (cf. Werth 1999). Moreover, this paper has
accounted for agent’s mutual beliefs and linked
agents’ beliefs and intentions to the dialogue acts
of their utterances, in order to address the prob-
lematic nature of accounting for belief in DRT.
</bodyText>
<sectionHeader confidence="0.999434" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999699606382979">
Al-Raheb, Y. 2005. Speaker/Hearer Representation in a Dis-
course Representation Theory Model ofPresupposition: A
Computational-Linguistic Approach. Phd. University of
East Anglia.
Asher, N. 1986. ‘Belief in Discourse Representation The-
ory’. Journal of Philosophical Logic 15, pp. 127–189.
Asher, N. and Lascarides, A. 2003. Logics of Conversation.
Cambridge: Cambridge University Press.
Bunt, H. 1995. ‘Dynamic Interpretation and Dialogue The-
ory’. In: M. Taylor, F. Neel, and D. Bouwhuis (Eds.). The
Structure ofMultimodal Dialogue, Volume 2. pp. 139–166.
Amsterdam: John Benjamins 2000.
Clark, H. and Schaefer, E. 1989. ‘Contributing to Discourse’.
Cognitive Science 13, pp. 259–294.
Davidson, D. 1983. ‘A Coherence Theory of Truth and
Knowledge’. In: D. Henrich (Ed.). Kant oder Hegel. pp.
433–438. Stuttgart: Klett-Cotta Buchhandlung.
Gazdar, G. 1979. ‘A Solution to the Projection Problem’.
In: C. Oh and D. Dineen (Eds.). Syntax and Semantics II:
Presupposition. New York: Academic Press.
Grice, P. 1989. Studies in the Way of Words. Cambridge,
MA: Harvard University Press.
Heydrich, W., Kuhnlein, P., and Rieser, H. 1998. ‘A DRT-
Style Modelling of Agents’ Mental States in Construction
Dialogue’. In: Proceedings of Workshop on Language
Technology 13 (Twendial ’98), TWLT. Faculty of Infor-
matics, the University of Twente: The Netherlands.
Hintikka, J. 1962. Knowledge and Belief: An Introduction to
the Logic of the Two Notions. Mimeo: Indiana University
Linguisitics Club.
Horton, D. and Hirst, G. 1988. ‘Presuppositions as Beliefs’.
In: Coling-88: Proceedings of the 12th International Con-
ference on Computational Linguistics. pp. 255–260. Bu-
dapest: Hungary.
Kamp, H. 1990. ‘Prolegomena to a Structural Account of Be-
lief and Other Attitudes’. In: C. Anderson and J. Owens
(Eds.). Propositional Attitudes: The Role of Content in
Logic, Language, and Mind. Stanford, CA: CSLI Publi-
cations.
Kamp, H., van Genabith, J., and Reyle, U. 2005.
The Handbook of Logic. Unpublished Manuscript.
http://www.ims.uni-stuttgart.de/hans/.
Larsson, S. and Traum, D. 2000. ‘Information State and Dia-
logue Management in the TRINDI Dialogue Move Engine
Toolkit’. In: Natural Language Engineering. Special Is-
sue on Spoken Language Dialogue System Engineering.
pp. 323–340.
Lewis, D. 1969. Convention: A Philosophical Study. Har-
vard University Press.
Lewis, D. 1979. ‘Attitudes de dicto and de re’. Philosophical
Review 88, pp. 513–543.
Poesio, M. and Traum, D. 1997a. ‘Conversational Actions
and Discourse Situations’. Computational Intelligence 13,
pp. 309–347.
Poesio, M. and Traum, D. 1997b. ‘Representing Conversa-
tion Acts in a Unified Semantic/Pragmatic Framework’.
In: Working Notes of AAAI Fall Symposium on Com-
municative Action in Humans and Machines. pp. 67–74.
Cambridge, MA: MIT Press.
Poesio, M. and Traum, D. 1998. ‘Towards an Axiomatization
of Dialogue Acts’. In: J. Hulstijn and A. Nijholt (Eds.).
Formal Semantics and Pragmatics of Dialogue, Proceed-
ings of Twendial’ 98. pp. 207–221. Universiteit Twente:
Enschede.
Quine, W. 1960. Word and Object. Cambridge MA: MIT
Press.
Schegloff, E., Jefferson, G., and Sacks, H. 1977. ‘The Prefer-
ence for Self-Correction in the Organization of Repair in
Conversation’. Language 53, pp. 361–382.
Stalnaker, R. 1974. ‘Pragmatic Presupposition’. In: M. Mu-
nitz and P. Unger (Eds.). Semantic and Philosophy. pp.
197–214. New York: New York University Press.
Stalnaker, R. 1988. ‘Belief Attribution and Context’. In: R.
Grimm and D. Merrill (Eds.). Contents of Thought. Pro-
ceedings of the 1985 Oberlin Colloquium in Philosophy.
pp. 140–156. Tucson State: The University of Arizona
Press.
Stalnaker, R. 1999. Context and Content. Oxford: Oxford
University Press.
Stalnaker, R. 2002. ‘Common ground’. Linguistics and Phi-
losophy 25(5-6), pp. 701–721.
Traum, D. 1994. A Computational Theory of Grounding in
Natural Language Conversation. Phd and tr 545. Com-
puter Science Department, Univeristy of Rochester.
Traum, D. 1997. ‘Report on Multiparty Dialogue Sub-group
on Forward-looking Communicative Function’. In: Stan-
dards for Dialogue Coding in Natural Language Process-
ing, Dagstuhl-Seminar Report no. 167.
Traum, D. 1999. ‘Computational Models of Grounding in
Collaborative Systems’. In: Working notes of AAAI Fall
Symposium on Psychological Models of Communication.
pp. 124-131. North Falmouth, Massachusetts.
Werth, P. 1999. Text Worlds: Representing Conceptual Space
in Discourse. New York: Longman.
</reference>
<page confidence="0.999343">
53
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.600270">
<title confidence="0.801401">DRT Representation of Degrees of Belief Yafa National Centre for Language</title>
<author confidence="0.69382">Dublin City</author>
<email confidence="0.999481">yafa.alraheb@gmail.com</email>
<abstract confidence="0.9901831">This paper investigates the problems facing modelling agents’ beliefs in Discourse Representation Theory (DRT) and presents a viable solution in the form of a dialogue-based DRT representation of beliefs. Integrating modelling dialogue interaction into DRT allows modelling agents’ beliefs, intentions and mutual beliefs. Furthermore, it is one of the aims of the paper to account for the important notion of agents’ varying degrees of belief in differ-</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Y Al-Raheb</author>
</authors>
<title>Speaker/Hearer Representation in a Discourse Representation Theory Model ofPresupposition: A Computational-Linguistic Approach.</title>
<date>2005</date>
<institution>Phd. University of East Anglia.</institution>
<contexts>
<context position="8203" citStr="Al-Raheb (2005)" startWordPosition="1390" endWordPosition="1391">tent of utterances. For example, both speaker and hearer mental states are represented and the beliefs and 47 meta-beliefs of agents are reviewed after each utterance. As a semantic theory, DRT tells us which discourse referents are needed in context. However, DRT does not deal with planning, nor with pragmatic aspects of contexts rendered through relating the current utterance to agents’ intentions. Kamp et al.’s (2005) expansion of the original, also known as ‘vanilla’, DRT (Poesio and Traum 1997a), deal minimally with intentions. To deal with the third problem mentioned by Heydrich et al., Al-Raheb (2005) has already outlined a pragmatic extension to DRT that makes it appropriate for linking the current utterance and agents’ intentions. The present paper aims to show how that link can be strengthened through modelling agents’ intentions and relating them to the dialogue acts communicated via utterances. In relation to this link, the significance of degrees of belief is explained in the following section. iyoum Figure 1: Hearer Recognition of S1 3 Degrees of Belief To our knowledge, there is no account in DRT that accommodates strengths or degrees of belief of agents in dialogue. This section a</context>
</contexts>
<marker>Al-Raheb, 2005</marker>
<rawString>Al-Raheb, Y. 2005. Speaker/Hearer Representation in a Discourse Representation Theory Model ofPresupposition: A Computational-Linguistic Approach. Phd. University of East Anglia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Asher</author>
</authors>
<title>Belief in Discourse Representation Theory’.</title>
<date>1986</date>
<journal>Journal of Philosophical Logic</journal>
<volume>15</volume>
<pages>127--189</pages>
<contexts>
<context position="5204" citStr="Asher 1986" startWordPosition="900" endWordPosition="901">r representing the differing beliefs of agents in dialogue and their beliefs (meta-beliefs) about other agents’ beliefs or mental state. By focussing on the intentions of speakers and hearers and inferring agents’ intentions in making an utterance, the approach presented in this paper aims at fulfilling this need. It follows that, to have a ‘full’ theory of beliefs and to have an insight into the mental states of agents in dialogue (the speaker and the hearer), it is necessary to have a representation of agents’ beliefs, degrees of beliefs, and the dialogue acts expressed by their utterances (Asher 1986). This is also in order to strengthen the link between utterances and agents’ intentions in dialogue. The dialogue act or function performed by the utterance tells us something about the speaker’s beliefs. Furthermore, what is also needed is a representation of beliefs that are shared between, or are common to, the two agents. The question is: how can DRT best model beliefs? The following section, 2, outlines the problems facing modelling beliefs in DRT. Section 3 presents a graded view of agents’ beliefs in dialogue as a solution to these problems. This is followed by a description of the rel</context>
<context position="18358" citStr="Asher 1986" startWordPosition="3142" endWordPosition="3143">1). In a dialogue, utterances give rise to dialogue acts (cf. agents’ intention DRSs in Figures 1, 2 and 3), named speech acts by some, and conversation acts by others (Traum 1994). One of the features of dialogue acts is how they affect the agents’ mental states. As Traum points out, ‘... speech acts are a good link between the mental states of agents and purposeful communication’ (Traum 1999: 30). Each agent in dialogue needs to have a representation of their beliefs and the other agent’s beliefs or cognitive state in order for a dialogue act to be felicitous in Austin’s and Searle’s sense (Asher 1986). That is to say, dialogue acts depend on agents’ beliefs for interpretation. attitude(you, ‘ACCEPT’, drs3) drs3: attitude(i, ‘ACCEPT’, drs2) attitude(i, ‘BEL’, drs4) x y b1: neighbour(x) b2: have(i,x) b3: weirdo(x) b4: window(y) b5: have(i,y) b6: peeping-through(x,y) b7: saw(you,b6) attitude(you, ‘BEL’, drs5) b8: neighbour(x) b9: have(i,x) b10: weirdo(x) b11: window(y) b12: have(i,y) b13: peeping-through(x,y) b14: saw(you,b13) attitude(i, ‘BEL’, drs6) b15: neighbour(x) b16: have(i,x) b17: weirdo(x) drs6: b18: window(y) b19: have(i,y) b20: peeping-through(x,y) b21: saw(you,b20) drs5: attitude(</context>
</contexts>
<marker>Asher, 1986</marker>
<rawString>Asher, N. 1986. ‘Belief in Discourse Representation Theory’. Journal of Philosophical Logic 15, pp. 127–189.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Asher</author>
<author>A Lascarides</author>
</authors>
<title>Logics of Conversation. Cambridge:</title>
<date>2003</date>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="7375" citStr="Asher and Lascarides 2003" startWordPosition="1253" endWordPosition="1256"> their mental states K(A) and K(B). Later work by Kamp et al. (2005) introduces agent modelling for singlesentence discourse, namely the hearer. The treatment presented in this paper allows the representation of dialogue with different agents, thus, addressing the first problem identified by Heydrich et al. (1998). With regard to the second problem, however, DRT has been primarily concerned with representing utterances containing propositional attitudes such as ‘believe’, rather than the beliefs and meta-beliefs of agents. Segmented-DRT (SDRT) has mainly focused on belief update and revision (Asher and Lascarides 2003). The treatment in this paper takes previous work on beliefs in dynamic semantics as a starting point and extends it to reach a richer representation of the interaction between mental states and the linguistic content of utterances. For example, both speaker and hearer mental states are represented and the beliefs and 47 meta-beliefs of agents are reviewed after each utterance. As a semantic theory, DRT tells us which discourse referents are needed in context. However, DRT does not deal with planning, nor with pragmatic aspects of contexts rendered through relating the current utterance to age</context>
</contexts>
<marker>Asher, Lascarides, 2003</marker>
<rawString>Asher, N. and Lascarides, A. 2003. Logics of Conversation. Cambridge: Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Bunt</author>
</authors>
<title>Dynamic Interpretation and Dialogue Theory’. In:</title>
<date>1995</date>
<booktitle>The Structure ofMultimodal Dialogue,</booktitle>
<volume>2</volume>
<pages>139--166</pages>
<location>Amsterdam: John Benjamins</location>
<contexts>
<context position="24013" citStr="Bunt 1995" startWordPosition="4041" endWordPosition="4042">t H Accept Weak Positive Feedback Strong Positive Feedback H Bel H Reject Negative Feedback 5.1 Feedback and Agents’ Beliefs Traum (1994) suggests that when an assertion is made, the hearer has an obligation to produce an ‘understanding act’. In general, acknowledgement is expected in Traum’s treatment of speech acts. This means that when a hearer responds with ‘okay’, the hearer can be taken to be providing an acknowledgement and an acceptance. However, the hearer does not always provide feedback. Grounding often happens as a result of implicit rather than overt feedback and acknowledgement (Bunt 1995).6 In fact, the treatment outlined in this paper maintains that the lack of feedback is to be considered a form of ‘weak positive feedback’, an extension to Dynamic Interpretation Theory’s (DIT) positive feedback (Bunt 1995). The hearer does not object to the speaker’s utterance by not providing feedback, since if the hearer did object, he would explicitly do so. When the speaker makes an assertion, the hearer may indicate that the message has been received (weak positive feedback), example (9.b). Weak positive feedback may indicate understanding, continued attention, or acknowledgement, such </context>
</contexts>
<marker>Bunt, 1995</marker>
<rawString>Bunt, H. 1995. ‘Dynamic Interpretation and Dialogue Theory’. In: M. Taylor, F. Neel, and D. Bouwhuis (Eds.). The Structure ofMultimodal Dialogue, Volume 2. pp. 139–166. Amsterdam: John Benjamins 2000.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Clark</author>
<author>E Schaefer</author>
</authors>
<title>Contributing to Discourse’.</title>
<date>1989</date>
<journal>Cognitive Science</journal>
<volume>13</volume>
<pages>259--294</pages>
<contexts>
<context position="24662" citStr="Clark and Schaefer 1989" startWordPosition="4141" endWordPosition="4144"> outlined in this paper maintains that the lack of feedback is to be considered a form of ‘weak positive feedback’, an extension to Dynamic Interpretation Theory’s (DIT) positive feedback (Bunt 1995). The hearer does not object to the speaker’s utterance by not providing feedback, since if the hearer did object, he would explicitly do so. When the speaker makes an assertion, the hearer may indicate that the message has been received (weak positive feedback), example (9.b). Weak positive feedback may indicate understanding, continued attention, or acknowledgement, such as ‘uh huh’, and ‘yeah’ (Clark and Schaefer 1989). Another case of weak positive feedback is provided by example (9.a) where the hearer does not say anything. It is assumed that the hearer did not have any problems and has received the assertion, A. In the case of weak feedback, it can be argued that this represents the ‘acceptance’ of A.7 Another response for the hearer is ‘strong posi6Grounding is a term adapted by Traum (1994) from Clark and Schaefer’s (1989) work on establishing common ground. 7This does not cancel cases where for social reasons, such as politeness, the hearer does not necessarily agree with the speaker, but does not wis</context>
</contexts>
<marker>Clark, Schaefer, 1989</marker>
<rawString>Clark, H. and Schaefer, E. 1989. ‘Contributing to Discourse’. Cognitive Science 13, pp. 259–294.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Davidson</author>
</authors>
<title>A Coherence Theory of Truth</title>
<date>1983</date>
<pages>433--438</pages>
<location>Stuttgart: Klett-Cotta Buchhandlung.</location>
<contexts>
<context position="9558" citStr="Davidson (1983)" startWordPosition="1620" endWordPosition="1621">egrees of belief. Modal expressions, including words such as ‘possibly’ and ‘might’, are evidence that there exist more degrees of belief than the ones discussed in this paper. The beliefs of an agent are ‘her model of how things are’ (Traum 1994: 15). The notion of belief (or strong belief) is to be understood in relation to the agent: it is what the agent takes to be true. There is an important philosophical background to the discussion of ‘belief’ and ‘knowledge’. It is outside the scope of this paper to review all the literature here. Quine (1960), Hintikka (1962), Lewis (1969, 1979), and Davidson (1983) are representative. The term ‘belief’ is understood in this paper to refer to propositions strongly held by the agent to be true and when making utterances relating to them, the speaker not only commits herself to their truth but also communicates to the hearer that she, the speaker, believes those proposition to be true. Another degree of belief called acceptance is accounted for in this model. Acceptance consists of the agent’s weakly believed propositions. The agent may be going along with what the speaker is saying or has acquired a new proposition based on the speaker’s utterance which h</context>
</contexts>
<marker>Davidson, 1983</marker>
<rawString>Davidson, D. 1983. ‘A Coherence Theory of Truth and Knowledge’. In: D. Henrich (Ed.). Kant oder Hegel. pp. 433–438. Stuttgart: Klett-Cotta Buchhandlung.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Gazdar</author>
</authors>
<title>A Solution to the Projection Problem’. In:</title>
<date>1979</date>
<publisher>Academic Press.</publisher>
<location>New York:</location>
<marker>Gazdar, 1979</marker>
<rawString>Gazdar, G. 1979. ‘A Solution to the Projection Problem’. In: C. Oh and D. Dineen (Eds.). Syntax and Semantics II: Presupposition. New York: Academic Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Grice</author>
</authors>
<title>Studies in the Way of Words.</title>
<date>1989</date>
<publisher>Harvard University Press.</publisher>
<location>Cambridge, MA:</location>
<marker>Grice, 1989</marker>
<rawString>Grice, P. 1989. Studies in the Way of Words. Cambridge, MA: Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Heydrich</author>
<author>P Kuhnlein</author>
<author>H Rieser</author>
</authors>
<title>A DRTStyle Modelling of Agents’ Mental States in Construction Dialogue’. In:</title>
<date>1998</date>
<booktitle>Proceedings of Workshop on Language Technology 13 (Twendial ’98), TWLT. Faculty of Informatics, the</booktitle>
<institution>University of Twente: The Netherlands.</institution>
<contexts>
<context position="6011" citStr="Heydrich et al. (1998)" startWordPosition="1038" endWordPosition="1041">e speaker’s beliefs. Furthermore, what is also needed is a representation of beliefs that are shared between, or are common to, the two agents. The question is: how can DRT best model beliefs? The following section, 2, outlines the problems facing modelling beliefs in DRT. Section 3 presents a graded view of agents’ beliefs in dialogue as a solution to these problems. This is followed by a description of the relationship between belief and mutual belief, section 4, and then of the relationship between belief and dialogue acts, section 5. 2 Problems Facing Modelling Beliefs in DRT According to Heydrich et al. (1998), paradigms of dynamic semantics (DRT, Situation Semantics and Dynamic Predicate Logic) face three obstacles in modelling dialogue. First, there is the problem of adapting the paradigm, originally made to model monological discourse, to the description of dialogue with different agents. The second problem is the description of mental states and the beliefs of the agents. The third problem is in explaining how the mental states are related to overt linguistic behaviour. With respect to the first problem, DRT has gradually attempted to address problems of belief representation in dialogue. For e</context>
<context position="17744" citStr="Heydrich et al. 1998" startWordPosition="3032" endWordPosition="3035">nformation) and their relationship to degrees of belief and strengthening of beliefs. 5 Beliefs and Dialogue Acts When someone makes an assertion, they communicate not only information they assume to be new to the hearer, but also communicate to the hearer information about their own beliefs. In order to i you Figure 3: Speaker Recognition model beliefs in dialogue, it is necessary to understand what the representation of dialogue involves. A dialogue is ‘a cooperative undertaking of agents engaged in developing and transforming their common situation’, involving verbal and non-verbal action (Heydrich et al. 1998: 21). In a dialogue, utterances give rise to dialogue acts (cf. agents’ intention DRSs in Figures 1, 2 and 3), named speech acts by some, and conversation acts by others (Traum 1994). One of the features of dialogue acts is how they affect the agents’ mental states. As Traum points out, ‘... speech acts are a good link between the mental states of agents and purposeful communication’ (Traum 1999: 30). Each agent in dialogue needs to have a representation of their beliefs and the other agent’s beliefs or cognitive state in order for a dialogue act to be felicitous in Austin’s and Searle’s sens</context>
</contexts>
<marker>Heydrich, Kuhnlein, Rieser, 1998</marker>
<rawString>Heydrich, W., Kuhnlein, P., and Rieser, H. 1998. ‘A DRTStyle Modelling of Agents’ Mental States in Construction Dialogue’. In: Proceedings of Workshop on Language Technology 13 (Twendial ’98), TWLT. Faculty of Informatics, the University of Twente: The Netherlands.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hintikka</author>
</authors>
<title>Knowledge and Belief: An Introduction to the Logic of the Two Notions. Mimeo:</title>
<date>1962</date>
<institution>Indiana University Linguisitics Club.</institution>
<contexts>
<context position="9517" citStr="Hintikka (1962)" startWordPosition="1614" endWordPosition="1615">d in future research to include further degrees of belief. Modal expressions, including words such as ‘possibly’ and ‘might’, are evidence that there exist more degrees of belief than the ones discussed in this paper. The beliefs of an agent are ‘her model of how things are’ (Traum 1994: 15). The notion of belief (or strong belief) is to be understood in relation to the agent: it is what the agent takes to be true. There is an important philosophical background to the discussion of ‘belief’ and ‘knowledge’. It is outside the scope of this paper to review all the literature here. Quine (1960), Hintikka (1962), Lewis (1969, 1979), and Davidson (1983) are representative. The term ‘belief’ is understood in this paper to refer to propositions strongly held by the agent to be true and when making utterances relating to them, the speaker not only commits herself to their truth but also communicates to the hearer that she, the speaker, believes those proposition to be true. Another degree of belief called acceptance is accounted for in this model. Acceptance consists of the agent’s weakly believed propositions. The agent may be going along with what the speaker is saying or has acquired a new proposition</context>
</contexts>
<marker>Hintikka, 1962</marker>
<rawString>Hintikka, J. 1962. Knowledge and Belief: An Introduction to the Logic of the Two Notions. Mimeo: Indiana University Linguisitics Club.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Horton</author>
<author>G Hirst</author>
</authors>
<title>Presuppositions as Beliefs’. In:</title>
<date>1988</date>
<booktitle>Coling-88: Proceedings of the 12th International Conference on Computational Linguistics.</booktitle>
<pages>255--260</pages>
<location>Budapest:</location>
<marker>Horton, Hirst, 1988</marker>
<rawString>Horton, D. and Hirst, G. 1988. ‘Presuppositions as Beliefs’. In: Coling-88: Proceedings of the 12th International Conference on Computational Linguistics. pp. 255–260. Budapest: Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
</authors>
<title>Prolegomena to a Structural Account of Belief and Other Attitudes’. In:</title>
<date>1990</date>
<publisher>CSLI Publications.</publisher>
<location>Stanford, CA:</location>
<contexts>
<context position="6700" citStr="Kamp 1990" startWordPosition="1148" endWordPosition="1149"> Logic) face three obstacles in modelling dialogue. First, there is the problem of adapting the paradigm, originally made to model monological discourse, to the description of dialogue with different agents. The second problem is the description of mental states and the beliefs of the agents. The third problem is in explaining how the mental states are related to overt linguistic behaviour. With respect to the first problem, DRT has gradually attempted to address problems of belief representation in dialogue. For example, in Prolegomena, Kamp introduces a simple model of verbal communication (Kamp 1990: 71), which consists of two agents, A and B, and their mental states K(A) and K(B). Later work by Kamp et al. (2005) introduces agent modelling for singlesentence discourse, namely the hearer. The treatment presented in this paper allows the representation of dialogue with different agents, thus, addressing the first problem identified by Heydrich et al. (1998). With regard to the second problem, however, DRT has been primarily concerned with representing utterances containing propositional attitudes such as ‘believe’, rather than the beliefs and meta-beliefs of agents. Segmented-DRT (SDRT) h</context>
<context position="14538" citStr="Kamp 1990" startWordPosition="2495" endWordPosition="2496"> all believe X, and all believe that all believe that all believe X. In face-to-face communication, the hearer believes that the speaker believes what she, the speaker, is communicating. On the other hand, unless the hearer indicates doubt or objects to what the speaker is saying, the speaker assumes that the hearer believes what the speaker has said – which is consistent with expectations under Gricean cooperativeness assumptions (1989). The speaker also assumes that the hearer now has the belief that the speaker believes what she just said. This assumption is what leads to ‘mutual’ beliefs (Kamp 1990: 79). However, mutual belief can be viewed as the process of establishing that the speaker and the hearer hold the same belief. One way in which this process may occur is when the speaker holds a belief and communicates that belief to the hearer. attitude(you, ‘ACCEPT’, drs3) drs4: attitude(i, ‘ACCEPT’, drs2) attitude(i, ‘BEL’, drs4) s n b1: mary(m) b2:party(y) b3: has(m,y) b4: buy(you,b5) b5: newShoes(s) b6: try(you,b7) b7: next(n) attitude(you, ‘BEL’, drs5) b8: mary(m) b9:party(y) b10: has(m,y) b11: buy(you,b12) b12: newShoes(s) b13: try(you,b13) b14: next(n) drs5: attitude(you, ‘INT’, drs7</context>
</contexts>
<marker>Kamp, 1990</marker>
<rawString>Kamp, H. 1990. ‘Prolegomena to a Structural Account of Belief and Other Attitudes’. In: C. Anderson and J. Owens (Eds.). Propositional Attitudes: The Role of Content in Logic, Language, and Mind. Stanford, CA: CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Kamp</author>
<author>J van Genabith</author>
<author>U Reyle</author>
</authors>
<date>2005</date>
<booktitle>The Handbook of Logic. Unpublished Manuscript. http://www.ims.uni-stuttgart.de/hans/.</booktitle>
<marker>Kamp, van Genabith, Reyle, 2005</marker>
<rawString>Kamp, H., van Genabith, J., and Reyle, U. 2005. The Handbook of Logic. Unpublished Manuscript. http://www.ims.uni-stuttgart.de/hans/.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Larsson</author>
<author>D Traum</author>
</authors>
<title>Information State and Dialogue Management in the TRINDI Dialogue Move Engine Toolkit’.</title>
<date>2000</date>
<journal>In: Natural Language Engineering. Special Issue on Spoken Language Dialogue System Engineering.</journal>
<pages>323--340</pages>
<contexts>
<context position="1710" citStr="Larsson and Traum 2000" startWordPosition="263" endWordPosition="266">terature. Stalnaker notes, for instance, that [i]f we understand contexts, and the speech acts made in contexts, in terms of the speaker’s beliefs and intentions, we have a better chance of giving simpler and more transparent explanations of linguistic behaviour (Stalnaker 2002: 720). The kind of agent beliefs we are concerned with here arises in dialogue interaction. The nature of 1I gratefully acknowledge support from Science Foundation Ireland grant 04/IN/I527. 2Other names for mental state used in the literature include ‘information state’, ‘conversational score’, and ‘discourse context’ (Larsson and Traum 2000). interaction dictates that the strength or degree of belief varies depending on contextual factors. This can be seen from the following example: (1) A: I want to make a booking for my wife. B: Yeah. A: What time is the Thailand flight on Monday? B: It’s at 2 pm. In example (1) B does not necessarily need to believe the presupposition (given information) that A has a wife. For the purposes of the conversation, which is providing A with information, B can simply ‘go along with’ the presupposition and not have it as a member of his beliefs (i.e. his belief set) (Stalnaker 2002). Similarly, let u</context>
</contexts>
<marker>Larsson, Traum, 2000</marker>
<rawString>Larsson, S. and Traum, D. 2000. ‘Information State and Dialogue Management in the TRINDI Dialogue Move Engine Toolkit’. In: Natural Language Engineering. Special Issue on Spoken Language Dialogue System Engineering. pp. 323–340.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lewis</author>
</authors>
<title>Convention: A Philosophical Study.</title>
<date>1969</date>
<publisher>Harvard University Press.</publisher>
<contexts>
<context position="9530" citStr="Lewis (1969" startWordPosition="1616" endWordPosition="1617">rch to include further degrees of belief. Modal expressions, including words such as ‘possibly’ and ‘might’, are evidence that there exist more degrees of belief than the ones discussed in this paper. The beliefs of an agent are ‘her model of how things are’ (Traum 1994: 15). The notion of belief (or strong belief) is to be understood in relation to the agent: it is what the agent takes to be true. There is an important philosophical background to the discussion of ‘belief’ and ‘knowledge’. It is outside the scope of this paper to review all the literature here. Quine (1960), Hintikka (1962), Lewis (1969, 1979), and Davidson (1983) are representative. The term ‘belief’ is understood in this paper to refer to propositions strongly held by the agent to be true and when making utterances relating to them, the speaker not only commits herself to their truth but also communicates to the hearer that she, the speaker, believes those proposition to be true. Another degree of belief called acceptance is accounted for in this model. Acceptance consists of the agent’s weakly believed propositions. The agent may be going along with what the speaker is saying or has acquired a new proposition based on the</context>
</contexts>
<marker>Lewis, 1969</marker>
<rawString>Lewis, D. 1969. Convention: A Philosophical Study. Harvard University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lewis</author>
</authors>
<title>Attitudes de dicto and de re’.</title>
<date>1979</date>
<journal>Philosophical Review</journal>
<volume>88</volume>
<pages>513--543</pages>
<marker>Lewis, 1979</marker>
<rawString>Lewis, D. 1979. ‘Attitudes de dicto and de re’. Philosophical Review 88, pp. 513–543.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>D Traum</author>
</authors>
<date>1997</date>
<booktitle>Conversational Actions and Discourse Situations’. Computational Intelligence 13,</booktitle>
<pages>309--347</pages>
<contexts>
<context position="8091" citStr="Poesio and Traum 1997" startWordPosition="1371" endWordPosition="1374"> point and extends it to reach a richer representation of the interaction between mental states and the linguistic content of utterances. For example, both speaker and hearer mental states are represented and the beliefs and 47 meta-beliefs of agents are reviewed after each utterance. As a semantic theory, DRT tells us which discourse referents are needed in context. However, DRT does not deal with planning, nor with pragmatic aspects of contexts rendered through relating the current utterance to agents’ intentions. Kamp et al.’s (2005) expansion of the original, also known as ‘vanilla’, DRT (Poesio and Traum 1997a), deal minimally with intentions. To deal with the third problem mentioned by Heydrich et al., Al-Raheb (2005) has already outlined a pragmatic extension to DRT that makes it appropriate for linking the current utterance and agents’ intentions. The present paper aims to show how that link can be strengthened through modelling agents’ intentions and relating them to the dialogue acts communicated via utterances. In relation to this link, the significance of degrees of belief is explained in the following section. iyoum Figure 1: Hearer Recognition of S1 3 Degrees of Belief To our knowledge, t</context>
</contexts>
<marker>Poesio, Traum, 1997</marker>
<rawString>Poesio, M. and Traum, D. 1997a. ‘Conversational Actions and Discourse Situations’. Computational Intelligence 13, pp. 309–347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>D Traum</author>
</authors>
<title>Representing Conversation Acts in a Unified Semantic/Pragmatic Framework’. In:</title>
<date>1997</date>
<booktitle>Working Notes of AAAI Fall Symposium on Communicative Action in Humans and Machines.</booktitle>
<pages>67--74</pages>
<publisher>MIT Press.</publisher>
<location>Cambridge, MA:</location>
<contexts>
<context position="8091" citStr="Poesio and Traum 1997" startWordPosition="1371" endWordPosition="1374"> point and extends it to reach a richer representation of the interaction between mental states and the linguistic content of utterances. For example, both speaker and hearer mental states are represented and the beliefs and 47 meta-beliefs of agents are reviewed after each utterance. As a semantic theory, DRT tells us which discourse referents are needed in context. However, DRT does not deal with planning, nor with pragmatic aspects of contexts rendered through relating the current utterance to agents’ intentions. Kamp et al.’s (2005) expansion of the original, also known as ‘vanilla’, DRT (Poesio and Traum 1997a), deal minimally with intentions. To deal with the third problem mentioned by Heydrich et al., Al-Raheb (2005) has already outlined a pragmatic extension to DRT that makes it appropriate for linking the current utterance and agents’ intentions. The present paper aims to show how that link can be strengthened through modelling agents’ intentions and relating them to the dialogue acts communicated via utterances. In relation to this link, the significance of degrees of belief is explained in the following section. iyoum Figure 1: Hearer Recognition of S1 3 Degrees of Belief To our knowledge, t</context>
</contexts>
<marker>Poesio, Traum, 1997</marker>
<rawString>Poesio, M. and Traum, D. 1997b. ‘Representing Conversation Acts in a Unified Semantic/Pragmatic Framework’. In: Working Notes of AAAI Fall Symposium on Communicative Action in Humans and Machines. pp. 67–74. Cambridge, MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Poesio</author>
<author>D Traum</author>
</authors>
<title>Towards an Axiomatization of Dialogue Acts’.</title>
<date>1998</date>
<journal>In: J. Hulstijn</journal>
<booktitle>Proceedings of Twendial’ 98.</booktitle>
<pages>207--221</pages>
<institution>Universiteit Twente: Enschede.</institution>
<contexts>
<context position="26055" citStr="Poesio and Traum 1998" startWordPosition="4384" endWordPosition="4387">ack), where the hearer not only indicates reception of A, but also that she agrees that A (cf. drs7 Figure 3). This is where confirming adoption of new beliefs takes place, example (9.c). Rejecting A is another way of giving feedback, negative feedback, as in example (9.d). (9) Speaker: Mary loves John. a. Hearer: b. Hearer: aha. c. Hearer: I couldn’t agree more! d. Hearer: No, Mary is besotted with Tom! There are also degrees of belief that can be expressed according to the speech act used, firm versus ‘tentative’. Poesio and Traum pay less attention to ‘the attitudes expressed by the acts’ (Poesio and Traum 1998: 221). Unlike Traum’s model, the effects of the dialogue acts’ employed in agents’ DRSs on agents’ beliefs are considered in this paper. Figure 6 demonstrates the link between feedback dialogue acts and agents’ beliefs. 6 Conclusion As this paper has demonstrated, beliefs vary in strength according to context. Beliefs also change with the coming of new information. The DRT treatment discussed here allows for the representation of strong beliefs and weaker beliefs as well as changes to beliefs. Agents in a dialogue may form stronger beliefs as the dialogue progresses, requiring moving the cont</context>
</contexts>
<marker>Poesio, Traum, 1998</marker>
<rawString>Poesio, M. and Traum, D. 1998. ‘Towards an Axiomatization of Dialogue Acts’. In: J. Hulstijn and A. Nijholt (Eds.). Formal Semantics and Pragmatics of Dialogue, Proceedings of Twendial’ 98. pp. 207–221. Universiteit Twente: Enschede.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Quine</author>
</authors>
<title>Word and Object.</title>
<date>1960</date>
<publisher>MIT Press.</publisher>
<location>Cambridge MA:</location>
<contexts>
<context position="9500" citStr="Quine (1960)" startWordPosition="1612" endWordPosition="1613"> to be expanded in future research to include further degrees of belief. Modal expressions, including words such as ‘possibly’ and ‘might’, are evidence that there exist more degrees of belief than the ones discussed in this paper. The beliefs of an agent are ‘her model of how things are’ (Traum 1994: 15). The notion of belief (or strong belief) is to be understood in relation to the agent: it is what the agent takes to be true. There is an important philosophical background to the discussion of ‘belief’ and ‘knowledge’. It is outside the scope of this paper to review all the literature here. Quine (1960), Hintikka (1962), Lewis (1969, 1979), and Davidson (1983) are representative. The term ‘belief’ is understood in this paper to refer to propositions strongly held by the agent to be true and when making utterances relating to them, the speaker not only commits herself to their truth but also communicates to the hearer that she, the speaker, believes those proposition to be true. Another degree of belief called acceptance is accounted for in this model. Acceptance consists of the agent’s weakly believed propositions. The agent may be going along with what the speaker is saying or has acquired </context>
</contexts>
<marker>Quine, 1960</marker>
<rawString>Quine, W. 1960. Word and Object. Cambridge MA: MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Schegloff</author>
<author>G Jefferson</author>
<author>H Sacks</author>
</authors>
<date>1977</date>
<booktitle>The Preference for Self-Correction in the Organization of Repair in Conversation’. Language 53,</booktitle>
<pages>361--382</pages>
<contexts>
<context position="23040" citStr="Schegloff et al. 1977" startWordPosition="3891" endWordPosition="3894">lanation. The dialogue act ‘suggest’ also instigates one of three reactions: the hearer can accept, believe or reject that suggestion and may provide feedback to indicate which is his reaction. It is of more interest to this paper to examine the effects of dialogue acts on the hearer’s beliefs, and what dialogue acts suggest about the speaker’s beliefs. 4It is possible for this category to be expanded to include more dialogue acts such as ‘question’, ‘answer’, ‘selfcorrect’ and ‘offer’. 5Clarification is a form of feedback. ‘I didn’t hear what you said’ is both ‘feedback’ act and an ‘inform’ (Schegloff et al. 1977). attitude(i, ‘BEL’, drs2) b1: xFilesDVD(x) b2: amazon(a) b3: onSale(x, b4) b4: at(a) attitude(you, ‘BEL’, drs3) drs3: b5: xFilesDVD(x) drs2: attitude(i, ‘BEL’, drs2) b1: xFilesDVD(x) b2: amazon(a) b3: onSale(x, b4) b4: at(a) attitude(you, ‘BEL’, drs3) drs3: b5: xFilesDVD(x) b6: not(onSale(x)) drs2: drs1: drs1: 51 Figure 6: Feedback Feedback No Feedback H Accept H Accept Weak Positive Feedback Strong Positive Feedback H Bel H Reject Negative Feedback 5.1 Feedback and Agents’ Beliefs Traum (1994) suggests that when an assertion is made, the hearer has an obligation to produce an ‘understanding </context>
</contexts>
<marker>Schegloff, Jefferson, Sacks, 1977</marker>
<rawString>Schegloff, E., Jefferson, G., and Sacks, H. 1977. ‘The Preference for Self-Correction in the Organization of Repair in Conversation’. Language 53, pp. 361–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Stalnaker</author>
</authors>
<title>Pragmatic Presupposition’. In:</title>
<date>1974</date>
<booktitle>Semantic and Philosophy.</booktitle>
<pages>197--214</pages>
<publisher>University Press.</publisher>
<location>New York: New York</location>
<marker>Stalnaker, 1974</marker>
<rawString>Stalnaker, R. 1974. ‘Pragmatic Presupposition’. In: M. Munitz and P. Unger (Eds.). Semantic and Philosophy. pp. 197–214. New York: New York University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Stalnaker</author>
</authors>
<title>Belief Attribution</title>
<date>1988</date>
<booktitle>Proceedings of the 1985 Oberlin Colloquium in Philosophy.</booktitle>
<pages>140--156</pages>
<publisher>Press.</publisher>
<institution>Tucson State: The University of Arizona</institution>
<marker>Stalnaker, 1988</marker>
<rawString>Stalnaker, R. 1988. ‘Belief Attribution and Context’. In: R. Grimm and D. Merrill (Eds.). Contents of Thought. Proceedings of the 1985 Oberlin Colloquium in Philosophy. pp. 140–156. Tucson State: The University of Arizona Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Stalnaker</author>
</authors>
<title>Context and Content.</title>
<date>1999</date>
<publisher>University Press.</publisher>
<location>Oxford: Oxford</location>
<marker>Stalnaker, 1999</marker>
<rawString>Stalnaker, R. 1999. Context and Content. Oxford: Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Stalnaker</author>
</authors>
<title>Common ground’.</title>
<date>2002</date>
<journal>Linguistics and Philosophy</journal>
<pages>25--5</pages>
<contexts>
<context position="1365" citStr="Stalnaker 2002" startWordPosition="213" endWordPosition="214">ental states of the speakers involved’ (1998).2 This is a step that is by no means easy. It is the aim of this paper to integrate previous work on beliefs in DRT and dialogue theory in order to model the mental states of agents in dialogue. The connection between beliefs, intentions and speech or dialogue acts has been noted in the literature. Stalnaker notes, for instance, that [i]f we understand contexts, and the speech acts made in contexts, in terms of the speaker’s beliefs and intentions, we have a better chance of giving simpler and more transparent explanations of linguistic behaviour (Stalnaker 2002: 720). The kind of agent beliefs we are concerned with here arises in dialogue interaction. The nature of 1I gratefully acknowledge support from Science Foundation Ireland grant 04/IN/I527. 2Other names for mental state used in the literature include ‘information state’, ‘conversational score’, and ‘discourse context’ (Larsson and Traum 2000). interaction dictates that the strength or degree of belief varies depending on contextual factors. This can be seen from the following example: (1) A: I want to make a booking for my wife. B: Yeah. A: What time is the Thailand flight on Monday? B: It’s </context>
</contexts>
<marker>Stalnaker, 2002</marker>
<rawString>Stalnaker, R. 2002. ‘Common ground’. Linguistics and Philosophy 25(5-6), pp. 701–721.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
</authors>
<title>A Computational Theory of Grounding in Natural Language Conversation. Phd and tr 545.</title>
<date>1994</date>
<institution>Computer Science Department, Univeristy of Rochester.</institution>
<contexts>
<context position="9189" citStr="Traum 1994" startWordPosition="1557" endWordPosition="1558">ained in the following section. iyoum Figure 1: Hearer Recognition of S1 3 Degrees of Belief To our knowledge, there is no account in DRT that accommodates strengths or degrees of belief of agents in dialogue. This section addresses this gap and proposes initially two strengths of belief involved in dialogue to be expanded in future research to include further degrees of belief. Modal expressions, including words such as ‘possibly’ and ‘might’, are evidence that there exist more degrees of belief than the ones discussed in this paper. The beliefs of an agent are ‘her model of how things are’ (Traum 1994: 15). The notion of belief (or strong belief) is to be understood in relation to the agent: it is what the agent takes to be true. There is an important philosophical background to the discussion of ‘belief’ and ‘knowledge’. It is outside the scope of this paper to review all the literature here. Quine (1960), Hintikka (1962), Lewis (1969, 1979), and Davidson (1983) are representative. The term ‘belief’ is understood in this paper to refer to propositions strongly held by the agent to be true and when making utterances relating to them, the speaker not only commits herself to their truth but </context>
<context position="13655" citStr="Traum (1994)" startWordPosition="2340" endWordPosition="2341">nting the speaker’s mental state after hearing H2 in example 6, Figure 2. 4 Beliefs and Mutual Beliefs The treatment of beliefs that we are developing here requires an explicit account of how the belief spaces or DRSs of two agents can interact. 3Inside the agent’s DRS, ‘i’ is used to refer to the agent and ‘you’ is used to refer to the other agent. Assertions are marked by ‘a,,,’, presuppositions by ‘p,,,’, believed information by ‘b,,,’ and accepted information by ‘c,,,’. i you m Figure 2: Speaker Recognition of H2 ‘Mutual belief’, also referred to as ‘mutual knowledge’, is the term used by Traum (1994) among others, where a group of individuals may believe X, where X may or may not be true. Stalnaker’s (2002) ‘common belief’ is comparable to what others call mutual belief. For X to be a mutual belief, it has to be accessible to a group; all believe X and all believe that all believe X, and all believe that all believe that all believe X. In face-to-face communication, the hearer believes that the speaker believes what she, the speaker, is communicating. On the other hand, unless the hearer indicates doubt or objects to what the speaker is saying, the speaker assumes that the hearer believes</context>
<context position="17927" citStr="Traum 1994" startWordPosition="3066" endWordPosition="3067">sume to be new to the hearer, but also communicate to the hearer information about their own beliefs. In order to i you Figure 3: Speaker Recognition model beliefs in dialogue, it is necessary to understand what the representation of dialogue involves. A dialogue is ‘a cooperative undertaking of agents engaged in developing and transforming their common situation’, involving verbal and non-verbal action (Heydrich et al. 1998: 21). In a dialogue, utterances give rise to dialogue acts (cf. agents’ intention DRSs in Figures 1, 2 and 3), named speech acts by some, and conversation acts by others (Traum 1994). One of the features of dialogue acts is how they affect the agents’ mental states. As Traum points out, ‘... speech acts are a good link between the mental states of agents and purposeful communication’ (Traum 1999: 30). Each agent in dialogue needs to have a representation of their beliefs and the other agent’s beliefs or cognitive state in order for a dialogue act to be felicitous in Austin’s and Searle’s sense (Asher 1986). That is to say, dialogue acts depend on agents’ beliefs for interpretation. attitude(you, ‘ACCEPT’, drs3) drs3: attitude(i, ‘ACCEPT’, drs2) attitude(i, ‘BEL’, drs4) x </context>
<context position="19877" citStr="Traum 1994" startWordPosition="3365" endWordPosition="3366">bout the world. Traum (1997) divides statements into ‘assert’, ‘re-assert’, and ‘inform’. ‘Assert’ is trying to ‘change’ the belief of the addressee. The result of assert is that the hearer now assumes that the speaker is trying to get the hearer to believe the assertion. ‘Re-assert’ can be used when participants try to verify old information, and not necessarily inform of something new. ‘Inform’ means that the speaker is trying to provide the hearer with information that the hearer did not have before. However, Traum does not go further to discuss cases where agents believe their utterances (Traum 1994: 14). It is one of the claims of this paper that agents in dialogue either strongly or weakly believe their utterances in order to be cooperative. It is possible to extend this approach in order to include cases where agents are purposefully deceitful. However, this is left for future research. The adapted dialogue acts, or functions, in thiss paper’s treatment of beliefs in DRT are mainly ‘inform’, ‘change belief’ and ‘other’. ‘Inform’ is used to communicate new information to the hearer, whereas ‘change belief’ (or to use Poesio and Traum’s (1997b) dialogue act term ‘assert’) is used to cha</context>
<context position="23540" citStr="Traum (1994)" startWordPosition="3965" endWordPosition="3966">a form of feedback. ‘I didn’t hear what you said’ is both ‘feedback’ act and an ‘inform’ (Schegloff et al. 1977). attitude(i, ‘BEL’, drs2) b1: xFilesDVD(x) b2: amazon(a) b3: onSale(x, b4) b4: at(a) attitude(you, ‘BEL’, drs3) drs3: b5: xFilesDVD(x) drs2: attitude(i, ‘BEL’, drs2) b1: xFilesDVD(x) b2: amazon(a) b3: onSale(x, b4) b4: at(a) attitude(you, ‘BEL’, drs3) drs3: b5: xFilesDVD(x) b6: not(onSale(x)) drs2: drs1: drs1: 51 Figure 6: Feedback Feedback No Feedback H Accept H Accept Weak Positive Feedback Strong Positive Feedback H Bel H Reject Negative Feedback 5.1 Feedback and Agents’ Beliefs Traum (1994) suggests that when an assertion is made, the hearer has an obligation to produce an ‘understanding act’. In general, acknowledgement is expected in Traum’s treatment of speech acts. This means that when a hearer responds with ‘okay’, the hearer can be taken to be providing an acknowledgement and an acceptance. However, the hearer does not always provide feedback. Grounding often happens as a result of implicit rather than overt feedback and acknowledgement (Bunt 1995).6 In fact, the treatment outlined in this paper maintains that the lack of feedback is to be considered a form of ‘weak positi</context>
<context position="25046" citStr="Traum (1994)" startWordPosition="4212" endWordPosition="4213">icate that the message has been received (weak positive feedback), example (9.b). Weak positive feedback may indicate understanding, continued attention, or acknowledgement, such as ‘uh huh’, and ‘yeah’ (Clark and Schaefer 1989). Another case of weak positive feedback is provided by example (9.a) where the hearer does not say anything. It is assumed that the hearer did not have any problems and has received the assertion, A. In the case of weak feedback, it can be argued that this represents the ‘acceptance’ of A.7 Another response for the hearer is ‘strong posi6Grounding is a term adapted by Traum (1994) from Clark and Schaefer’s (1989) work on establishing common ground. 7This does not cancel cases where for social reasons, such as politeness, the hearer does not necessarily agree with the speaker, but does not wish to indicate it. The speaker can wrongly or rightly come to the conclusion that the hearer accepts the assertion. tive feedback’ (another extension to DIT’s positive feedback), where the hearer not only indicates reception of A, but also that she agrees that A (cf. drs7 Figure 3). This is where confirming adoption of new beliefs takes place, example (9.c). Rejecting A is another w</context>
</contexts>
<marker>Traum, 1994</marker>
<rawString>Traum, D. 1994. A Computational Theory of Grounding in Natural Language Conversation. Phd and tr 545. Computer Science Department, Univeristy of Rochester.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
</authors>
<title>Report on Multiparty Dialogue Sub-group on Forward-looking Communicative Function’. In: Standards for Dialogue Coding in Natural Language Processing, Dagstuhl-Seminar Report no.</title>
<date>1997</date>
<pages>167</pages>
<contexts>
<context position="8091" citStr="Traum 1997" startWordPosition="1373" endWordPosition="1374">extends it to reach a richer representation of the interaction between mental states and the linguistic content of utterances. For example, both speaker and hearer mental states are represented and the beliefs and 47 meta-beliefs of agents are reviewed after each utterance. As a semantic theory, DRT tells us which discourse referents are needed in context. However, DRT does not deal with planning, nor with pragmatic aspects of contexts rendered through relating the current utterance to agents’ intentions. Kamp et al.’s (2005) expansion of the original, also known as ‘vanilla’, DRT (Poesio and Traum 1997a), deal minimally with intentions. To deal with the third problem mentioned by Heydrich et al., Al-Raheb (2005) has already outlined a pragmatic extension to DRT that makes it appropriate for linking the current utterance and agents’ intentions. The present paper aims to show how that link can be strengthened through modelling agents’ intentions and relating them to the dialogue acts communicated via utterances. In relation to this link, the significance of degrees of belief is explained in the following section. iyoum Figure 1: Hearer Recognition of S1 3 Degrees of Belief To our knowledge, t</context>
<context position="19295" citStr="Traum (1997)" startWordPosition="3267" endWordPosition="3268">(x) b9: have(i,x) b10: weirdo(x) b11: window(y) b12: have(i,y) b13: peeping-through(x,y) b14: saw(you,b13) attitude(i, ‘BEL’, drs6) b15: neighbour(x) b16: have(i,x) b17: weirdo(x) drs6: b18: window(y) b19: have(i,y) b20: peeping-through(x,y) b21: saw(you,b20) drs5: attitude(you, ‘INT’, drs7) x y p1: neighbour(x) p2: weirdo(x) p3: window(y) drs7: p4: have(i,y) a1: peeping-through(x,y) a2: saw(you,a1) strongPosFeedback(you,i,p2) inform(you,i,a2) drs2: drs4: drs1: 50 Each assertion made has one ‘function’ or more. For example, the function of a statement could be to make a claim about the world. Traum (1997) divides statements into ‘assert’, ‘re-assert’, and ‘inform’. ‘Assert’ is trying to ‘change’ the belief of the addressee. The result of assert is that the hearer now assumes that the speaker is trying to get the hearer to believe the assertion. ‘Re-assert’ can be used when participants try to verify old information, and not necessarily inform of something new. ‘Inform’ means that the speaker is trying to provide the hearer with information that the hearer did not have before. However, Traum does not go further to discuss cases where agents believe their utterances (Traum 1994: 14). It is one o</context>
</contexts>
<marker>Traum, 1997</marker>
<rawString>Traum, D. 1997. ‘Report on Multiparty Dialogue Sub-group on Forward-looking Communicative Function’. In: Standards for Dialogue Coding in Natural Language Processing, Dagstuhl-Seminar Report no. 167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Traum</author>
</authors>
<title>Computational Models of Grounding in Collaborative Systems’. In: Working notes of AAAI Fall</title>
<date>1999</date>
<booktitle>Symposium on Psychological Models of Communication.</booktitle>
<pages>124--131</pages>
<publisher>North</publisher>
<location>Falmouth, Massachusetts.</location>
<contexts>
<context position="18143" citStr="Traum 1999" startWordPosition="3104" endWordPosition="3105">epresentation of dialogue involves. A dialogue is ‘a cooperative undertaking of agents engaged in developing and transforming their common situation’, involving verbal and non-verbal action (Heydrich et al. 1998: 21). In a dialogue, utterances give rise to dialogue acts (cf. agents’ intention DRSs in Figures 1, 2 and 3), named speech acts by some, and conversation acts by others (Traum 1994). One of the features of dialogue acts is how they affect the agents’ mental states. As Traum points out, ‘... speech acts are a good link between the mental states of agents and purposeful communication’ (Traum 1999: 30). Each agent in dialogue needs to have a representation of their beliefs and the other agent’s beliefs or cognitive state in order for a dialogue act to be felicitous in Austin’s and Searle’s sense (Asher 1986). That is to say, dialogue acts depend on agents’ beliefs for interpretation. attitude(you, ‘ACCEPT’, drs3) drs3: attitude(i, ‘ACCEPT’, drs2) attitude(i, ‘BEL’, drs4) x y b1: neighbour(x) b2: have(i,x) b3: weirdo(x) b4: window(y) b5: have(i,y) b6: peeping-through(x,y) b7: saw(you,b6) attitude(you, ‘BEL’, drs5) b8: neighbour(x) b9: have(i,x) b10: weirdo(x) b11: window(y) b12: have(i,</context>
</contexts>
<marker>Traum, 1999</marker>
<rawString>Traum, D. 1999. ‘Computational Models of Grounding in Collaborative Systems’. In: Working notes of AAAI Fall Symposium on Psychological Models of Communication. pp. 124-131. North Falmouth, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Werth</author>
</authors>
<title>Text Worlds: Representing Conceptual Space in Discourse.</title>
<date>1999</date>
<publisher>Longman.</publisher>
<location>New York:</location>
<marker>Werth, 1999</marker>
<rawString>Werth, P. 1999. Text Worlds: Representing Conceptual Space in Discourse. New York: Longman.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>