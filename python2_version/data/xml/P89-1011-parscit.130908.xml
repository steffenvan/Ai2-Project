<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.006861">
<note confidence="0.592162">
LEXICAL ACCESS IN CONNECTED SPEECH RECOGNITION
</note>
<author confidence="0.607748">
Ted Briscoe
</author>
<affiliation confidence="0.630311">
Computer Laboratory
University of Cambridge
</affiliation>
<address confidence="0.565106">
Cambridge, CB2 3Q0, UK.
</address>
<email confidence="0.366297">
ABSTRACT
</email>
<bodyText confidence="0.999916">
This paper addresses two issues concerning lexical
access in connected speech recognition: 1) the nature of
the Fe-lexical representation used to initiate lexical look-
up 2) the points at which lexical look-up is triggered off
this representation. The results of an experiment are
reported which was designed to evaluate a number of
access strategies proposed in the literature in conjunction
with several plausible pre-lexical representations of the
speech input. The experiment also extends previous work
by utilising a dictionary database containing a realistic
rather than illustrative English vocabulary.
</bodyText>
<sectionHeader confidence="0.972504" genericHeader="method">
THEORETICAL BACKGROUND
</sectionHeader>
<bodyText confidence="0.9998925">
In most recent work on the process of word
recognition during comprehension of connected speech
(either by human or machine) a distinction is made
between lexical access and word recognition (eg.
Marslen-Wilson &amp; Welsh, 1978; Klatt, 1979). Lexical
access is the process by which contact is made with the
lexicon on the basis of an initial acoustic-phonetic or
phonological representation of some portion of the
speech input. The result of lexical access is a cohort of
potential word candidates which are compatible with this
initial analysis. (The term cohort is used descriptively in
this paper and does not represent any commitment to the
particular account of lexical access and word recognition
provided by any version of the cohort theory (e.g.
Marslen-Wilson, 1987).) Most theories assume that the
candidates in this cohort are successively whittled down
both on the basis of further acoustic-phonetic or
phonological information, as more of the speech input
becomes available, and on the basis of the candidates&apos;
compatibility with the linguistic and extralinguistic
context of utterance. When only one candidate remains,
word recognition is said to have taken place.
Most psycholinguistic work in this area has focussed
on the process of word recognition after a cohort of
candidates has been selected, emphasising the role of
further lexical or &apos;higher-level&apos; linguistic constraints such
as word frequency, lexical semantic relations, or
syntactic and semantic congruity of candidates with the
linguistic context (e.g. Bradley &amp; Forster, 1987; Marslen-
Wilson &amp; Welsh, 1978). The few explicit and well-
developed models of lexical access and word recognition
in continuous speech (e.g. TRACE, McClelland &amp;
Elman, 1986) have small and unrealistic lexicons of, at
most, a few hundred words and ignore phonological
processes which occur in fluent speech. Therefore, they
tend to overestimate the amount and reliability of
acoustic information which can be directly extracted
from the speech signal (either by human or machine) and
make unrealistic and overly-optimistic assumptions
concerning the size and diversity of candidates in a
typical cohort. This, in turn, casts doubt on the real
efficacy of the putative mechanisms which are intended
to select the correct word from the cohort.
The bulk of engineering systems for speech
recognition have finessed the issues of lexical access and
word recognition by attempting to map directly from the
acoustic signal to candidate words by pairing words with
acoustic representations of the canonical pronunciation of
the word in the lexicon and employing pattern-matching,
best-fit techniques to select the most likely candidate
(e.g. Sakoe &amp; Chiba, 1971). However, these techniques
have only proved effective for isolated word recognition
of small vocabularies with the system trained to an
individual speaker, as, for example, Zue &amp; Huttenlocher
(1983) argue. Furthermore, any direct access model of
this type which does not incorporate a pre-lexical
symbolic representation of the input will have difficulty
capturing many rule-governed phonological processes
which affect the pronunciation of words in fluent speech,
since these processes can only be characterised
adequately in terms of operations on a symbolic,
phonological representation of the speech input (e.g.
Church, 1987; Frazier, 1987; Wiese, 1986).
The research reported here forms part of an ongoing
programme to develop a computationally explicit account
of lexical access and word recognition in connected
speech, which is at least informed by experimental
results concerning the psychological processes and
mechanisms which underlie this task. To guide research,
we make use of a substantial lexical database of English
derived from machine-readable versions of the Longman
Dictionary of Contemporary English (see Boguraev at
aL, 1987; Boguraev &amp; Briscoe, 1989) and of the Medical
Research Council&apos;s psycholinguistic database (Wilson,
1988), which incorporates word frequency information.
This specialised database system provides flexible and
powerful querying facilities into a database of
approximately 30,000 English word forms (with 60,000
separate entries). The querying facilities can be used to
explore the lexical structure of English and simulate
different approaches to lexical access and word
recognition. Previous work in this area has often relied
on small illustrative lexicons which tends to lead to
overestimation of the effectiveness of various
approaches.
There are two broad questions to ask concerning the
process of lexical access. Firstly, what is the nature of
the initial representation which makes contact with the
lexicon? Secondly, at what points during the (continuous)
analysis of the speech signal is lexical look-up triggered?
</bodyText>
<page confidence="0.994443">
8)4
</page>
<bodyText confidence="0.997504333333333">
We can illustrate the import of these questions by
considering an example like (1) (modified from Klan via
Church, 1987).
</bodyText>
<equation confidence="0.722992333333333">
(1)
a) Did you hit it to Tom?
b) [dIjEhld17tEtarn]
</equation>
<bodyText confidence="0.999403451612903">
(Where &apos;I&apos; represents a high, front vowel, &apos;E&apos; schwa, &apos;d&apos;
a flapped or neutralised stop, and 1&apos; a glottal stop.) The
phonetic transcription of one possible utterance of (la) in
(lb) demonstrates some of the problems involved in any
&apos;direct&apos; mapping from the speech input to lexical entries
not mediated by the application of phonological rules.
For example, the palatalisation of final Id/ before /y/ in
/did/ means that any attempt to relate that portion of the
speech input to the lexical entry for did is likely to fail.
Similar points cm be made about the flapping and
glottalisation of the N phonemes in /Mt/ and /1t/, and the
vowel reductions to schwa. In addition. (1) illustrates the
well-known point that there are no 100% reliable
phonetic or phonological cues to word boundaries in
connected speech. Without further phonological and
lexical analysis there is no indication in a transcription
like (lb) of where words begin or end; for example, how
does the lexical access system distinguish word-initial /I/
in /17/ from word-internal /I/ in /1ild/7
In this paper, I shall argue for a model which splits
the lexical access process into a pre-lexical phonological
parsing stage and then a lexical entry retrieval stage. The
model is similar to that of Church (1987), however I
argue, firstly, that the initial phonological representation
recovered from the speech input is more variable and
often less detailed than that assumed by Church and,
secondly, that the lexical entry retrieval stage is more
directed and discriminatory, in order to reduce the
number of spurious lexical entries accessed and to
compensate for likely indetenninacies in the initial
representation.
</bodyText>
<sectionHeader confidence="0.996324" genericHeader="method">
THE PRE-LEXICAL
PHONOLOGICAL REPRESENTATION
</sectionHeader>
<bodyText confidence="0.999862088607595">
Several researchers have argued that phonological
processes, such as the palatalisation of /d/ in (1), create
problems for the word recognition system because they
&apos;distort&apos; the phonological form of the word. Church
(1987) and Frazier (1987) argue persuasively that, far
from creating problems, such phonological processes
provide important clues to the correct syllabic
segmentation of the input and thus, to the location of
word boundaries. However, this argument only goes
through on the assumption that quite detailed &apos;narrow&apos;
phonetic information is recovered from the signal, such
as aspiration of N in /tE/ and /tarn/ in (1) in order to
recognise the preceding syllable boundaries. It is only in.
terms of this representation that phonological processes
can be recognised and their effects &apos;undone&apos; in order to
allow correct matching of the input against the canonical
phonological representations contained in lexical entries.
Other researchers (e.g. Shipman &amp; Zue, 1982) have
argued (in the context of isolated word recognition) that
the initial representation which contacts the lexicon
should be a broad manner-class transcription of the
stressed syllables in the speech signal. The evidence in
favour of this approach is, firstly, that extraction of more
detailed information is notoriously difficult and,
secondly, that a broad transcription of this type appears
to be very effective in partitioning the English lexicon
into small cohorts. For example, Huttenlocher (1985)
reports an average cohort size of 21 words for a 20,000
word lexicon using a six-category manner of articulation
transcription scheme (employing the categories: Stop,
Strong-Fricative, Weak-Fricative, Nasal, Glide-Liquid,
and Vowel).
This claim suggests that the English lexicon is
functionally organised to favour a system which initiates
lexical access from a broad manner class pre-lexical
representation, because most of the discriminatory
information between different words is concentrated in
the manner articulation of stressed syllables. Elsewhere,
we have argued that these ideas are misleadingly
presented and that there is, in fact, no significant
advantage for manner information in stressed syllables
(e.g. Carter et al., 1987; Carter, 1987, 1989). We found
that there is no advantage per se to a manner class
analysis of stressed syllables, since a similar analysis of
unstressed syllables is as discriminatory and yields as
good a partitioning of the English lexicon. However,
concentrating on a full phonemic analysis of stressed
syllables provides about 10% more information than a
similar analysis of unstressed syllables. This research
suggests, then, that the pre-lexical representation used to
initiate lexical access can only afford to concentrate
exclusively on stressed syllables if these are analysed (at
least) phonemically. None of these studies consider the
extractability of the classifications from speech input;
however, whilst there is a general belief that it is easier
to extract information from stressed portions of the
signal, there is little reason to believe that manner class
information is, in general, more or less accessible than
other phonologically relevant features.
A second argument which can be made against the
use of broad representations to contact the lexicon (in
the context of connected speech) is that such
representations will not support the phonological parsing
necessary to &apos;undo&apos; such processes as palatalisation. For
example, in (1) the final Id/ of did will be realised as hi
and categorised as a strong-fricative followed by liquid-
glide using the proposed broad manner transcription.
Therefore, palatalisation will need to be recognised
before the required stop-vowel-stop representation can be
recovered and used to initiate lexical access. However,
applying such phonological rules in a constrained and
useful manner requires a more detailed input
transcription. Palatalisation illustrates this point very
clearly; not all sequences which will be transcribed as
strong-fricative followed by liquid-glide can undergo this
Process by any means (e.g. /gib, but there will be no
way of preventing the rule overapplying in many
inappropriate contexts and thus presumably leading to
the generation of many spurious word candidates.
</bodyText>
<page confidence="0.998654">
85
</page>
<bodyText confidence="0.999992851851852">
A third argument against the use of exclusively
broad representations is that these representations will
not support the effective recognition of syllable-
boundaries and some word-boundaries on the basis of
phonotactic and other phonological sequencing
constraints. For example, Church (1987) proposes an
initial syllabification of the input as a prerequisite to
lexical access, but his syllabification of the speech input
exploits phonotactic constraints and relies on the
extraction of allophonic features, such as aspiration, to
guide this process. Similarly, Harrington et al. (1988)
argue that approximately 45% of word boundaries are, in
principle, recognisable because they occur in phoneme
sequences which are rare or forbidden word-internally.
However, exploitation of these English phonological
constraints would be considerably impaired if the pre-
lexical representation of the input is restricted to a broad
classification.
It might seem self-evident that people are able to
recognise phonemes in speech, but in fact the
psychological evidence suggests that this ability is
mediated by the output of the word recognition process
rather than being an essential prerequisite to its success
Phoneme-monitoring experiments, in which subjects
listen for specified phonemes in speech, are sensitive to
lexical effects such as word frequency, semantic
association, and so forth (see Cutler at al., 1987 for a
summary of the experimental literature and putative
explanation of the effect), suggesting that information
concerning at least some of the phonetic content of a
word is not available until after the word is recognised.
Thus, people&apos;s ability to recognise phonemes tells us
very little about the nature of the representation used to
initiate lexical access. Better (but still indirect) evidence
comes from mispronunciation monitoring and phoneme
confusion experiments (Cole, 1973; Miller &amp; Nicely,
1955; Sheperd, 1972) which suggest that listeners are
likely to confuse or conflate phonemes along the
dimensions predicted by distinctive feature theory. Most
errors result in reporting phonemes which differ in only
one feature from the target, This result suggests that
listeners are actively considering detailed phonetic
information along a number of dimensions (rather than
simply, say, manner of articulation).
Theoretical and experimental considerations suggest
then that, regardless of the current capabilities of
automated acoustic-phonetic front-ends, systems must be
developed to extract as phonetically detailed a pre-lexical
phonological representation as possible. Without such a
representation, phonological processes cannot be
effectively recognised and compensated for in the word
recognition process and the &apos;extra&apos; information conveyed
in stressed syllables cannot be exploited. Nevertheless in
fluent connected speech, unstressed syllables often
undergo phonological processes which render them
highly indeterminate; for example, the vowel reductions
in (1). Therefore, it is implausible to assume that any
(human or machine) front-end will always output an
accurate narrow phonetic, phonemic or perhaps even
broad (say, manner class) transcription of the speech
input. For this reason, further processes involved in
lexical access will need to function effectively despite
the very variable quality of information extracted from
the speech signal.
This last point creates a serious difficulty for the
design of effective phonological parsers. Church (1987),
for example, allows himself the idealisation of an
accurate &apos;narrow&apos; phonetic transcription. It remains to be
demonstrated that any parsing techniques developed for
determinate symbolic input will transfer effectively to
real speech input (and such a test may have to await
considerably better automated front-ends). For the
purposes of the next section, I assume that some such
account of phonological parsing can be developed and
that the pre-lexical representation used to initiate lexical
access is one in which phonological processes have been
&apos;undone&apos; in order to construct a representation close to
the canonical (phonemic) representation of a word&apos;s
pronunciation. However, I do not assume that this
representation will necessarily be accurate to the same
degree of detail throughout the input.
</bodyText>
<sectionHeader confidence="0.99086" genericHeader="method">
LEXICAL ACCESS STRATEGIES
</sectionHeader>
<bodyText confidence="0.970171594594594">
Any theory of word recognition must provide a
mechanism for the segmentation of connected speech
into words. In effect, the theory must explain how the
process of lexical access is triggered at appropriate
points in the speech signal in the absence of completely
reliable phonetic/phonological cues to word boundaries.
The various theories of lexical access and word
recognition in connected speech propose mechanisms
which appear to cover the full spectrum of logical
possibilities. Klatt (1979) suggests that lexical access is
triggered off each successive spectral frame derived from
the signal (i.e. approximately every 5 msecs.),
McClelland &amp; Elman (1986) suggest each successive
phoneme, Church (1987) suggests each syllable onset.
Grosjean &amp; Gee (1987) suggest each stressed syllable
onset, and Cutler &amp; Norris (1985) suggest each
prosodically strong syllable onset. Finally, Marslen-
Wilson &amp; Welsh (1978) suggest that segmentation of the
speech input and recognition of word boundaries is an
indivisible process in which the endpoint of the previous
word defines the point at which lexical access is
triggered again.
Some of these access strategies have been evaluated
with respect to three input transcriptions (which are
plausible candidates for the pre-lexical representation on
the basis of the work discussed in the previous section)
in the context of a realistic sized lexicon. The
experiment involved one sentence taken from a reading
of the &apos;Rainbow passage&apos; which had been analysed by
several phoneticians for independent purposes. This
sentence is reproduced in (2a) with the syllables which
were judged to be strong by the phoneticians underlined.
(2)
a) The rainbow is a division of white light into
many beautiful colours
b) WF-V rein bEu V-SF V S-V vi SF-V-N V-SF
wait laic V-N S-V men V bju: S-V WF-V-G KM
</bodyText>
<page confidence="0.7498825">
V-SF
86
</page>
<bodyText confidence="0.999959180000001">
This utterance was transcribed: 1) fine class, using
phonemic transcription throughout; 2) mid class, using
phonemic transcription of strong syllables and a six-
category manner of articulation transcription of weak
syllables; 3) broad class, as mid class but suppressing
voicing distinctions in the strong syllable transcriptions.
(2b) gives the mid class transcription of the utterance. In
this transcription, phonemes are represented in a manner
compatible with the scheme employed in the Longman
Dictionary of Contemporary English and the manner
class categories in capitals are Stop, Strong-Fricative,
Weak-Fricative, Nasal, Glide-liquid, and Vowel, as in
Huttenlocher (1982) and elsewhere. The terms, fine, mid
and broad, for each transcription scheme are intended
purely descriptively and are not necessarily related to
other uses of these terms in the literature. Each of the
schemes is intended to represent a possible behaviour of
an acoustic-phonetic front-end. The less determinate
transcriptions can be viewed either as the result of
transcription errors and indeterrninacies or as the output
of a less ambitious front-end design. The definition of
syllable botmdmy employed is, of necessity, that built
into the syllable parser which acts as the interface to the
dictionary database (e.g. Carter, 1989). The parser
syllabifies phonemic transcriptions according to the
phonotactic constraints given in Gimson (1980) and
utilises the maximal onset principle (Selkirk, 1978)
where this leads to ambiguity.
Each of the three transcriptions was used as a
putative pre-lexical representation to test some of the
different access strategies, which were used to initiate
lexical look-up into the dictionary database. The four
access strategies which were tested were: 1) phoneme,
using each successive phoneme to trigger an access
attempt; 2) word, using the offset of the previous
(correct) word in the input to control access attempts; 3)
syllable, attempting look-up at each syllable boundary; 4)
strong syllable, attempting look-up at each strong
syllable boundary. That is, the first strategy assumes a
word may begin at any phoneme boundary, the second
that a word may only begin at the end of the previous
one, the third that a word may begin at any syllable
boundary, and the fourth that a word may begin at a
strong syllable boundary.
The strong syllable strategy uses a separate look-up
process for typically unstressed grammatical, closed-class
vocabulary and allows the possibility of extending look-
up &apos;backwards over one preceding weak syllable. It was
assumed, for the purposes of the experiment, that look-
up off weak syllables would be restricted to closed-class
vocabulary, would not extend into a strong syllable, and
that this process would precede attempts to incorporate a
weak syllable &apos;backwards&apos; into an open-class word.
The direct access approach was not considered
because of its implausibility in the light of the discussion
in the previous section. The stressed syllable account is
very similar to the strong syllable approach, but given
the problem of stress shift in fluent speech, a formulation
in terms of strong syllables, which are defined in terms
of the absence of vowel reduction, is preferable.
Work by Marslen-Wilson and his colleagues (e.g.
Marslen-Wilson &amp; Warren, 1987) suggests that, whatever
access strategy is used, there is no delay in the
availability of information derived from the speech signal
to further select from the cohort of word candidates. This
suggests that a model in which units (say syllabics) of
the pre-lexical representation are &apos;pre-packaged&apos; and then
used to trigger a look-up attempt are implausible. Rather
the look-up process must involve the continuous
integration of information from the pre-lexical
representation immediately it becomes available. Thus
the question of access strategy concerns only the points
at which this look-up process is initiated.
In order to simulate the continuous aspect of lexical
access using the dictionary database, database look-up
queries for each strategy were initiated using the two
phonemes/segments from the trigger point and then again
with three phonemes/segments and so on until no further
English words in the database were compatible with the
look-up query (except for closed-class access with the
strong syllable strategy where a strong syllable boundary
terminated the sequence of accesses). The size of the
resulting cohorts was measured for each successively
larger query; for example, using a fine class transcription
and triggering access from the /r/ of rainbow yields an
initial cohort of 89 candidates compatible with /ref/. This
cohort drops to 12 words when /n/ is added and to 1
word when /b/ is also included and finally goes to 0
when the vowel of is is added. Each sequence of queries
of this type which all begin at the same point in the
signal will be referred to as an access path. The
difference between the access strategies is mostly in the
number of distinct access paths they generate.
Simulating access attempts using the dictionary
database involves generating database queries consisting
of partial phonological representations which return sets
of words and entries which satisfy the query. For
example, Figure 1 represents the query corresponding to
the complete broad-class transcription of appoint. This
query matches 37 word forms in the database.
</bodyText>
<figure confidence="0.9589227">
( (pron
(ney1.13 21
[al
[peak ?]
(.2
[streets 21
[onset (OR bdgkp t)
[peak 7]
[coda (OR m n N)
(ORbdgkpt)))))
</figure>
<figureCaption confidence="0.984765">
Figure I — Database query for &apos;appoint&apos;.
</figureCaption>
<bodyText confidence="0.999958666666667">
The experiment involved generating sequences of
queries of this type and recording the number of words
found in the database which matched each query. Figure
2 shows the partial word lattice for the mid class
transcription of the rainbow is, using the strong syllable
access strategy. In this lattice access paths involving
successively larger portions of the signal are illustrated.
The number under each access attempt represents the
size of the set of words whose phonology is compatible
</bodyText>
<page confidence="0.997633">
87
</page>
<bodyText confidence="0.919247">
with the quay. Lines preceded by an arrow indicate a
query which forms part of an access path, adding a
further segment to the query above it.
Th e rain bow is a
--- I --I —I
</bodyText>
<figure confidence="0.985332625">
1 4 89 59 5 8
&gt;—I &gt;---I
12 3
&gt;----- &gt;--
1 0
&gt;--I I
1 0
&gt;---
</figure>
<figureCaption confidence="0.998339">
Figure 2 — Partial Word Lattice
</figureCaption>
<bodyText confidence="0.966195166666667">
The corresponding complete word lattice for the
same portion of input using a mid-class transcription and
the strong syllable strategy is shown in Figure 3. In this
lattice, only words whose complete phonology is
compatible with the input are shown.
The rain bow is a
</bodyText>
<figure confidence="0.9947324">
I -- I I -- I I -- I I — I I
14 1 2 5 8
I ---- I
3
1
</figure>
<figureCaption confidence="0.981464">
Figure 3 — Canplete Word Lattice
</figureCaption>
<bodyText confidence="0.9999586">
The different strategies were evaluated relative to the
3 transcription schemes by summing the total number of
partial words matched for the test sentence under each
strategy and transcription and also by looking at the total
number of complete words matched.
</bodyText>
<sectionHeader confidence="0.984642" genericHeader="evaluation">
RESULTS
</sectionHeader>
<bodyText confidence="0.999496588235294">
Table 1 below gives a selection of the more
important results for each strategy by transcription
scheme for the test sentence in (2). Column 1 shows the
total number of access paths initiated for the test
sentence under each strategy. Columns 2 to 6 shows the
number of words in all the cohorts produced by the
particular access strategy for the test sentence after 2 to
6 phonemes/segments of the transcription have been
incorporated into each access path. Column 7 shows the
total number of words which achieve a complete match
during the application of the particular access strategy to
the test sentence.
Table 1 provides an index of the efficiency of each
access strategy in terms of the overall number of
candidate words which appear in cohorts and also the
overall number of words which receive a full match for
the test sentence. In addition, the relative performance of
each strategy as the transcription scheme becomes less
determinate is clear.
The test sentence contains 12 words, 20 syllables,
and 45 phonemes; for the purposes of this experiment
the word a in the test sentence does not trigger a look-
up attempt with the word strategy because cohort sizes
were only recorded for sequences of two or more
phonemes/segments. Assuming a fine class transcription
serving as pre-lexical input, the phoneme strategy
produces 41 full matches as compared to 20 for the
strong syllable strategy. This demonstrates that the strong
syllable strategy is more effective at ruling out spurious
word candidates for the test sentence. Furthermore, the
total number of candidates considered using the phoneme
strategy is 1544 (after 2 phonemes/segments) but only
720 for the strong syllable strategy, again indicating the
greater effectiveness of the latter strategy. When we
</bodyText>
<table confidence="0.999324428571429">
Access Access No. of words after x segments: 6 Complete
Strategy Paths 2 3 4 5 Matches
Fine Class
Phoneme 45 1544 251 46 6 2 41
Word 11 719 193 32 5 2 25
Syllable 20 1090 210 36 6 2 28
StrongS 17 720 105 24 5 2 20
Mid Class
Word 11 4701 1738 802 54 8 249
Syllable 20 12995 3221 1530 103 9 380
StrongS 17 760 232 89 13 4 80
Broad Class
Syllable 20 13744 3407 1591 140 23 402
StrongS 17 1170 228 100 18 9 117
</table>
<tableCaption confidence="0.999569">
Table I
</tableCaption>
<page confidence="0.998839">
88
</page>
<bodyText confidence="0.999987735632184">
consider the less determinate transcriptions it becomes
even clearer that only the strong syllable strategy
remains reasonably effective and does not result in a
massive increase in the number of spurious candidates
accessed and fully matched. (The phoneme strategy
results are not reported for mid and broad class
transcriptions because the cohort sizes were too large for
the database query facilities to cope reliably.)
The word candidates recovered using the phoneme
strategy with a fine class transcription include 10 full
matches resulting from accesses triggered at non-syllabic
boundaries; for example arraign is found using the
second phoneme of the and rain. This problem becomes
considerably worse when moving to a less determinate
transcription, illustrating very clearly the undesirable
consequences of ignoring the basic linguistic constraint
that word boundaries occur at syllable boundaries.
Systems such as TRACE (McClelland &amp; Ehnen. 1986)
which use this strategy appear to compensate by using a
global best-fit evaluation metric for the entire utterance
which strongly disfavours &apos;unattached&apos; input. However,
these models still make the implausible claim that
candidates like arraign will be highly-activated by the
speech input.
The results concerning the word based strategy
presume that it is possible to determinately recognise the
endpoint of the preceding word. This assumption is
based on the Cohort theory claim (e.g. Marslen-Wilson
&amp; Welsh, 1978) that words can be recognised before
their acoustic offset, using syntactic and semantic
expectations to filter the cohort. This claim has been
challenged experimentally by Grosjean (1985) and Bard
et al. (1988) who demonstrate that many monosyllabic
words in context are not recognised until after their
acoustic offset. The experiment reported here supports
this experimental result because even with the fine class
transcription there are 5 word candidates which extend
beyond the correct word boundary and 11 full matches
which end before the correct boundary. With the mid
class transcription, these numbers rise to 849 and 57,
respectively. It seems implausible that expectation-based
constraints could be powerful enough to correctly select
a unique candidate before its acoustic offset in all
contexts. Therefore, the results for the word strategy
reported here are overly-optimistic, because in order to
guarantee that the correct sequence of words are in the
cohorts recovered from the input, a lexical access system
based on the word strategy would need to operate non-
deterministically; that is, it would need to consider
several potential word boundaries in most cases.
Therefore, the results for a practical system based on this
approach are likely to be significantly worse.
The syllable strategy is effective under the
assumption of a determinate and accurate phonemic pre-
lexical representation, but once we abandon this
idealisation, the effectiveness of this strategy declines
sharply. Under the plausible assumption that the pre-
lexical input representation is Moly to be least
accurate/determinate for unstressed/weak syllables, the
strong syllable strategy is far more robust. This it a
direct consequence of triggering look-up attempts off the
more determinate parts of the pre-lexical representation.
Further theoretical evidence in support of the strong
syllable strategy is provided by Cutler &amp; Carter (1987)
who demonstrate that a listener is six dines more likely
to encounter a word with a prosodically strong initial
syllable than one with a weak initial syllable when
listening to English speech. Experimental evidence is
provided by Cutler &amp; Norris (1988) who report results
which suggest that listeners tend to treat strong, but not
weak, syllables as appropriate points at which to
undertake pre-lexical segmentation of the speech input.
The architecture of a lexical access system based on
the syllable strategy can be quite simple in terms of the
organisation of the lexicon and its access routines. It is
only necessary to index the lexicon by syllable types
(Church, 1987). By contrast, the strong syllable strategy
requires a separate closed-class word lexicon and access
system, indexing of the open-class vocabulary by strong
syllable and a more complex matching procedure capable
of incorporating preceding weak syllables for words such
as division. Nevertheless, the experimental results
reported here suggest that the extra complexity is
warranted because the resulting system will be
considerably more robust in the face of inaccurate or
indeterminate input concerning the nature of the weak
syllables in the input utterance.
</bodyText>
<sectionHeader confidence="0.992848" genericHeader="conclusions">
CONCLUSION
</sectionHeader>
<bodyText confidence="0.999959434782609">
The experiment reported above suggests that the
strong syllable access strategy will provide the most
effective technique for producing minimal cohorts
guaranteed to contain the correct word candidate from a
pre-lexical phonological representation which may be
partly inaccurate or indeterminate. Further work to be
undertaken includes the rerunning of the experiment with
further input transcriptions containing pseudo-random
typical phoneme perception errors and the inclusion of
further test sentences designed to yield a &apos;phonetically-
balanced&apos; corpus. In addition, the relative internal
discriminability (in terms of further phonological and
&apos;higher-level&apos; syntactic and semantic constraints) of the
word candidates in the varying cohorts generated with
the different strategies should be examined.
The importance of making use of a dictionary
database with a realistic vocabulary size in order to
evaluate proposals concerning lexical access and word
recognition systems is highlighted by the results of this
experiment, which demonstrate the theoretical
implausibility of many of the proposals in the literature
when we consider the consequences in a simulation
involving more than a few hundred illustrative words.
</bodyText>
<page confidence="0.999684">
89
</page>
<sectionHeader confidence="0.99636" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999708142857143">
I would like to thank Longman Group Ltd. for
making the typesetting tape of the Longman Dictionary
of Contemporary English available to us for research
purposes. Part of the work reported here was supported
by SERC grant 0R/D/4217. I also thank Anne Cutler,
Francis Nolan and Tun Sholicar for useful comments and
advice. All errors remain my own.
</bodyText>
<sectionHeader confidence="0.999731" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.999834043956044">
Bard, E., Shillcock, R. 8c Altmarm, G. (1988). The
recognition of words after their acoustic offsets in
spontaneous speech: effects of subsequent context.
Perception &amp; Psychophysics, 44, 395-408.
Boguraev, B. 8t Briscoe, E. (1989). Computational
Lexicography for Natural Language Processing.
Longman Limited, London.
Boguraev, B., Carter, D. &amp; Briscoe, E. (1987). A multi-
purpose interface to an on-line dictionary. 3rd
Conference of Eur. Assoc. for Computational Linguistics,
Copenhagen.
Bradley, D. &amp; Forster, K. (1987). A reader&apos;s view of
listening. Cognition, 25, 103-34.
Carter, D. (1987). An information-theoretic analysis of
phonetic dictionary access. Computer Speech and
Language, 2, 1-11.
Carter, D., Boguraev, B. &amp; Briscoe, E. (1987). Lexical
stress and phonetic information: which segments are
most informative. Proc. of Eur. Conference on Speech
Technology, Edinburgh.
Carter, D. (1989). LDOCE and speech recognition. In
Boguraev &amp; Briscoe (1989) pp. 135-52.
Church. K. (1987). Phonological parsing and lexical
retrieval. Cognition, 25, 53-69.
Cole, R. (1973). Listening for mispronunciations: a
measure of what we hear during speech. Perception &amp;
Psychophysics, 1. 153-6.
Cutler, A. &amp; Carter, D. (1987). The predominance of
strong initial syllables in the English vocabulary.
Computer Speech and Language, 2, 133-42.
Cutler, A., Mehler, J., Norris, D. &amp; Segui, J. (1987).
Phoneme identification and the lexicon. Cognitive
Psychology, 19, 141-77.
Cutler, A. &amp; Norris, D. (1988). The role of strong
syllables in segmentation for lexical access. J. of
Experimental Psychology: Human Perception and
Performance, 14, 113-21.
Frazier, L (1987). Structure in auditory word
recognition. Cognition, 25, 157-87.
Gimson, A. (1980). An Introduction to the Pronunciation
of English. 3rd Edition, Edward Arnold, London.
Grosjean, F. &amp; Gee, J. (1987). Prosodic structure and
spoken word recognition. Cognition, 25, 135-155.
Harrington, J., Watson, G. &amp; Cooper, M. (1988). Word
boundary identification from phoneme sequence
constraints in automatic continuous speech recognition.
Proc. of 12th Int. Conf. on Computational Linguistics.
Budapest, pp. 225-30.
Huttenlocher, D. (1985). Exploiting sequential phonetic
constraints in recognizing spoken words. Nor. AL Lab.
Memo 867.
Klatt, D. (1979). Speech perception a model of acoustic-
phonetic analysis and lexical access. Journal of
Phonetics, 7, 279-312.
Marslen-Wilson, M. (1987). Functional parallelism in
spoken word recognition. Cognition, 25, 71-102.
Marslen-Wilson, W. &amp; Warren, P. (1987). Continuous
uptake of acoustic cues in spoken word recognition.
Perception &amp; Psychophysics, 41, 262-75.
Marslen-Wilson, W. &amp; Welsh, A. (1978). Processing
interactions and lexical access during word recognition in
continuous speech. Cognitive Psychology, 10, 29-63.
McClelland, J. &amp; Elman, J. (1986). The TRACE model
of speech perception. Cognitive Psychology, 18, 1-86.
Miller, G. &amp; Nicely, P. (1955). Analysis of some
perceptual confusions among some English consonants.
Journal of Acoustical Society of America, 27, 338-52.
Sakoe, H. &amp; Chiba, S. (1971). A dynamic programming
optimization for spoken word recognition. IEEE
Transactions, Acoustics, Speech and Signal Processing,
ASSP-26, 43-49.
Selkirk, E. (1978). On prosodic structure and its relation
to syntactic structure. Indiana University Linguistics
Club, Bloomington, Indiana.
Sheperd, R. (1972) Psychological representation of
speech sounds. In David, E. &amp; Denes, P. Human
Cormnunication: A Unified View, New York: McGraw-
Hill.
Shipman. D. &amp; Zue, V. (1982). Properties of large
lexicons: implications for advanced isolated word
recognition systems. IEEE ICASSP, Paris, 546-549.
Wiese, R. (1986). The role of phonology in speech
processing. Proc. of 11th Int. Conf. on Computational
Linguistics, Bonn, pp. 608-11.
Wilson, M. (1988). MRC psycholinguistic database:
machine-usable dictionary, version 2.0 Behaviour
Research Methods, Instrumentation &amp; Computers, 20,
6-10.
Zue, V. &amp; Huttenlocher, D. (1983). Computer
recognition of isolated words from large vocabularies.
IEEE Conference on Trends and Applications.
</reference>
<page confidence="0.998585">
90
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000014">
<title confidence="0.999219">LEXICAL ACCESS IN CONNECTED SPEECH RECOGNITION</title>
<author confidence="0.999938">Ted Briscoe</author>
<affiliation confidence="0.9999865">Computer Laboratory University of Cambridge</affiliation>
<address confidence="0.999283">Cambridge, CB2 3Q0, UK.</address>
<abstract confidence="0.979020832083961">This paper addresses two issues concerning lexical access in connected speech recognition: 1) the nature of the Fe-lexical representation used to initiate lexical lookup 2) the points at which lexical look-up is triggered off this representation. The results of an experiment are reported which was designed to evaluate a number of access strategies proposed in the literature in conjunction with several plausible pre-lexical representations of the speech input. The experiment also extends previous work by utilising a dictionary database containing a realistic rather than illustrative English vocabulary. THEORETICAL BACKGROUND In most recent work on the process of word recognition during comprehension of connected speech (either by human or machine) a distinction is made between lexical access and word recognition (eg. Marslen-Wilson &amp; Welsh, 1978; Klatt, 1979). Lexical access is the process by which contact is made with the lexicon on the basis of an initial acoustic-phonetic or phonological representation of some portion of the input. The result of lexical access is a potential word candidates which are compatible with this analysis. (The term used descriptively in this paper and does not represent any commitment to the particular account of lexical access and word recognition by any version of the theory Marslen-Wilson, 1987).) Most theories assume that the candidates in this cohort are successively whittled down both on the basis of further acoustic-phonetic or phonological information, as more of the speech input becomes available, and on the basis of the candidates&apos; compatibility with the linguistic and extralinguistic context of utterance. When only one candidate remains, word recognition is said to have taken place. Most psycholinguistic work in this area has focussed the process of word recognition cohort of candidates has been selected, emphasising the role of further lexical or &apos;higher-level&apos; linguistic constraints such as word frequency, lexical semantic relations, or syntactic and semantic congruity of candidates with the linguistic context (e.g. Bradley &amp; Forster, 1987; Marslen- Wilson &amp; Welsh, 1978). The few explicit and wellmodels of lexical access recognition in continuous speech (e.g. TRACE, McClelland &amp; Elman, 1986) have small and unrealistic lexicons of, at most, a few hundred words and ignore phonological processes which occur in fluent speech. Therefore, they tend to overestimate the amount and reliability of acoustic information which can be directly extracted from the speech signal (either by human or machine) and make unrealistic and overly-optimistic assumptions concerning the size and diversity of candidates in a typical cohort. This, in turn, casts doubt on the real efficacy of the putative mechanisms which are intended to select the correct word from the cohort. The bulk of engineering systems for speech recognition have finessed the issues of lexical access and word recognition by attempting to map directly from the acoustic signal to candidate words by pairing words with acoustic representations of the canonical pronunciation of the word in the lexicon and employing pattern-matching, best-fit techniques to select the most likely candidate (e.g. Sakoe &amp; Chiba, 1971). However, these techniques have only proved effective for isolated word recognition of small vocabularies with the system trained to an individual speaker, as, for example, Zue &amp; Huttenlocher (1983) argue. Furthermore, any direct access model of this type which does not incorporate a pre-lexical symbolic representation of the input will have difficulty capturing many rule-governed phonological processes which affect the pronunciation of words in fluent speech, since these processes can only be characterised adequately in terms of operations on a symbolic, phonological representation of the speech input (e.g. Church, 1987; Frazier, 1987; Wiese, 1986). The research reported here forms part of an ongoing programme to develop a computationally explicit account lexical word recognition in connected speech, which is at least informed by experimental results concerning the psychological processes and mechanisms which underlie this task. To guide research, we make use of a substantial lexical database of English from machine-readable versions of the of Contemporary English Boguraev at aL, 1987; Boguraev &amp; Briscoe, 1989) and of the Medical Research Council&apos;s psycholinguistic database (Wilson, 1988), which incorporates word frequency information. This specialised database system provides flexible and powerful querying facilities into a database of approximately 30,000 English word forms (with 60,000 separate entries). The querying facilities can be used to explore the lexical structure of English and simulate different approaches to lexical access and word recognition. Previous work in this area has often relied on small illustrative lexicons which tends to lead to overestimation of the effectiveness of various approaches. There are two broad questions to ask concerning the process of lexical access. Firstly, what is the nature of the initial representation which makes contact with the lexicon? Secondly, at what points during the (continuous) analysis of the speech signal is lexical look-up triggered? 8)4 We can illustrate the import of these questions by considering an example like (1) (modified from Klan via Church, 1987). (1) a) Did you hit it to Tom? b) [dIjEhld17tEtarn] (Where &apos;I&apos; represents a high, front vowel, &apos;E&apos; schwa, &apos;d&apos; a flapped or neutralised stop, and 1&apos; a glottal stop.) The phonetic transcription of one possible utterance of (la) in (lb) demonstrates some of the problems involved in any &apos;direct&apos; mapping from the speech input to lexical entries not mediated by the application of phonological rules. example, the palatalisation of final Id/ before /did/ means that any attempt to relate that portion of the input to the lexical entry for likely to fail. Similar points cm be made about the flapping and of the in /Mt/ and /1t/, and the vowel reductions to schwa. In addition. (1) illustrates the well-known point that there are no 100% reliable phonetic or phonological cues to word boundaries in connected speech. Without further phonological and lexical analysis there is no indication in a transcription like (lb) of where words begin or end; for example, how does the lexical access system distinguish word-initial /I/ in /17/ from word-internal /I/ in /1ild/7 I shall argue for a model which splits the lexical access process into a pre-lexical phonological parsing stage and then a lexical entry retrieval stage. The model is similar to that of Church (1987), however I argue, firstly, that the initial phonological representation recovered from the speech input is more variable and often less detailed than that assumed by Church and, secondly, that the lexical entry retrieval stage is more directed and discriminatory, in order to reduce the number of spurious lexical entries accessed and to compensate for likely indetenninacies in the initial representation. THE PRE-LEXICAL PHONOLOGICAL REPRESENTATION Several researchers have argued that phonological processes, such as the palatalisation of /d/ in (1), create problems for the word recognition system because they &apos;distort&apos; the phonological form of the word. Church (1987) and Frazier (1987) argue persuasively that, far from creating problems, such phonological processes provide important clues to the correct syllabic segmentation of the input and thus, to the location of boundaries. However, only goes through on the assumption that quite detailed &apos;narrow&apos; phonetic information is recovered from the signal, such aspiration of and /tarn/ in (1) in order to recognise the preceding syllable boundaries. It is only in. terms of this representation that phonological processes can be recognised and their effects &apos;undone&apos; in order to allow correct matching of the input against the canonical phonological representations contained in lexical entries. Other researchers (e.g. Shipman &amp; Zue, 1982) have argued (in the context of isolated word recognition) that the initial representation which contacts the lexicon should be a broad manner-class transcription of the stressed syllables in the speech signal. The evidence in favour of this approach is, firstly, that extraction of more detailed information is notoriously difficult and, secondly, that a broad transcription of this type appears to be very effective in partitioning the English lexicon into small cohorts. For example, Huttenlocher (1985) reports an average cohort size of 21 words for a 20,000 word lexicon using a six-category manner of articulation transcription scheme (employing the categories: Stop, Strong-Fricative, Weak-Fricative, Nasal, Glide-Liquid, and Vowel). This claim suggests that the English lexicon is functionally organised to favour a system which initiates lexical access from a broad manner class pre-lexical representation, because most of the discriminatory information between different words is concentrated in the manner articulation of stressed syllables. Elsewhere, we have argued that these ideas are misleadingly presented and that there is, in fact, no significant advantage for manner information in stressed syllables (e.g. Carter et al., 1987; Carter, 1987, 1989). We found there is no advantage se a manner class analysis of stressed syllables, since a similar analysis of unstressed syllables is as discriminatory and yields as good a partitioning of the English lexicon. However, concentrating on a full phonemic analysis of stressed syllables provides about 10% more information than a similar analysis of unstressed syllables. This research suggests, then, that the pre-lexical representation used to initiate lexical access can only afford to concentrate exclusively on stressed syllables if these are analysed (at least) phonemically. None of these studies consider the extractability of the classifications from speech input; however, whilst there is a general belief that it is easier to extract information from stressed portions of the signal, there is little reason to believe that manner class information is, in general, more or less accessible than other phonologically relevant features. A second argument which can be made against the use of broad representations to contact the lexicon (in the context of connected speech) is that such representations will not support the phonological parsing necessary to &apos;undo&apos; such processes as palatalisation. For in (1) the final Id/ of be realised as categorised strong-fricative followed by liquidglide using the proposed broad manner transcription. Therefore, palatalisation will need to be recognised before the required stop-vowel-stop representation can be recovered and used to initiate lexical access. However, applying such phonological rules in a constrained and useful manner requires a more detailed input transcription. Palatalisation illustrates this point very clearly; not all sequences which will be transcribed as strong-fricative followed by liquid-glide can undergo this Process by any means (e.g. /gib, but there will be no way of preventing the rule overapplying in many inappropriate contexts and thus presumably leading to the generation of many spurious word candidates. 85 third argument against use exclusively broad representations is that these representations will not support the effective recognition of syllableboundaries and some word-boundaries on the basis of phonotactic and other phonological sequencing constraints. For example, Church (1987) proposes an initial syllabification of the input as a prerequisite to lexical access, but his syllabification of the speech input exploits phonotactic constraints and relies on the extraction of allophonic features, such as aspiration, to guide this process. Similarly, Harrington et al. (1988) argue that approximately 45% of word boundaries are, in principle, recognisable because they occur in phoneme sequences which are rare or forbidden word-internally. However, exploitation of these English phonological constraints would be considerably impaired if the prelexical representation of the input is restricted to a broad classification. It might seem self-evident that people are able to recognise phonemes in speech, but in fact the psychological evidence suggests that this ability is mediated by the output of the word recognition process rather than being an essential prerequisite to its success Phoneme-monitoring experiments, in which subjects listen for specified phonemes in speech, are sensitive to effects as word frequency, semantic association, and so forth (see Cutler at al., 1987 for a summary of the experimental literature and putative explanation of the effect), suggesting that information concerning at least some of the phonetic content of a word is not available until after the word is recognised. Thus, people&apos;s ability to recognise phonemes tells us very little about the nature of the representation used to initiate lexical access. Better (but still indirect) evidence comes from mispronunciation monitoring and phoneme confusion experiments (Cole, 1973; Miller &amp; Nicely, Sheperd, 1972) which suggest that listeners likely to confuse or conflate phonemes along the dimensions predicted by distinctive feature theory. Most errors result in reporting phonemes which differ in only one feature from the target, This result suggests that listeners are actively considering detailed phonetic information along a number of dimensions (rather than simply, say, manner of articulation). Theoretical and experimental considerations suggest then that, regardless of the current capabilities of automated acoustic-phonetic front-ends, systems must be developed to extract as phonetically detailed a pre-lexical phonological representation as possible. Without such a representation, phonological processes cannot be effectively recognised and compensated for in the word recognition process and the &apos;extra&apos; information conveyed in stressed syllables cannot be exploited. Nevertheless in connected unstressed syllables often undergo phonological processes which render them highly indeterminate; for example, the vowel reductions in (1). Therefore, it is implausible to assume that any (human or machine) front-end will always output an accurate narrow phonetic, phonemic or perhaps even broad (say, manner class) transcription of the speech For further processes involved in lexical access will need to function effectively despite the very variable quality of information extracted from the speech signal. This last point creates a serious difficulty for the design of effective phonological parsers. Church (1987), for example, allows himself the idealisation of an accurate &apos;narrow&apos; phonetic transcription. It remains to be demonstrated that any parsing techniques developed for determinate symbolic input will transfer effectively to real speech input (and such a test may have to await considerably better automated front-ends). For the purposes of the next section, I assume that some such account of phonological parsing can be developed and that the pre-lexical representation used to initiate lexical access is one in which phonological processes have been &apos;undone&apos; in order to construct a representation close to the canonical (phonemic) representation of a word&apos;s pronunciation. However, I do not assume that this representation will necessarily be accurate to the same degree of detail throughout the input. LEXICAL ACCESS STRATEGIES Any theory of word recognition must provide a mechanism for the segmentation of connected speech into words. In effect, the theory must explain how the process of lexical access is triggered at appropriate points in the speech signal in the absence of completely reliable phonetic/phonological cues to word boundaries. The various theories of lexical access and word recognition in connected speech propose mechanisms which appear to cover the full spectrum of logical possibilities. Klatt (1979) suggests that lexical access is triggered off each successive spectral frame derived from the signal (i.e. approximately every 5 msecs.), McClelland &amp; Elman (1986) suggest each successive phoneme, Church (1987) suggests each syllable onset. Grosjean &amp; Gee (1987) suggest each stressed syllable onset, and Cutler &amp; Norris (1985) suggest each prosodically strong syllable onset. Finally, Marslen- Wilson &amp; Welsh (1978) suggest that segmentation of the speech input and recognition of word boundaries is an indivisible process in which the endpoint of the previous word defines the point at which lexical access is triggered again. Some of these access strategies have been evaluated with respect to three input transcriptions (which are plausible candidates for the pre-lexical representation on the basis of the work discussed in the previous section) in the context of a realistic sized lexicon. The experiment involved one sentence taken from a reading of the &apos;Rainbow passage&apos; which had been analysed by several phoneticians for independent purposes. This sentence is reproduced in (2a) with the syllables which were judged to be strong by the phoneticians underlined. (2) The rainbowis a division of lightinto manybeautiful colours b) WF-V rein bEu V-SF V S-V vi SF-V-N V-SF wait laic V-N S-V men V bju: S-V WF-V-G KM V-SF 86 This utterance was transcribed: 1) fine class, using phonemic transcription throughout; 2) mid class, using phonemic transcription of strong syllables and a sixcategory manner of articulation transcription of weak syllables; 3) broad class, as mid class but suppressing voicing distinctions in the strong syllable transcriptions. (2b) gives the mid class transcription of the utterance. In this transcription, phonemes are represented in a manner with the scheme employed in the of Contemporary English the manner class categories in capitals are Stop, Strong-Fricative, Weak-Fricative, Nasal, Glide-liquid, and Vowel, as in Huttenlocher (1982) and elsewhere. The terms, fine, mid and broad, for each transcription scheme are intended purely descriptively and are not necessarily related to other uses of these terms in the literature. Each of the schemes is intended to represent a possible behaviour of an acoustic-phonetic front-end. The less determinate transcriptions can be viewed either as the result of transcription errors and indeterrninacies or as the output of a less ambitious front-end design. The definition of syllable botmdmy employed is, of necessity, that built into the syllable parser which acts as the interface to the dictionary database (e.g. Carter, 1989). The parser syllabifies phonemic transcriptions according to the phonotactic constraints given in Gimson (1980) and the onset principle 1978) where this leads to ambiguity. of the three transcriptions was used as putative pre-lexical representation to test some of the different access strategies, which were used to initiate lexical look-up into the dictionary database. The four which were tested were: 1) phoneme, using each successive phoneme to trigger an access attempt; 2) word, using the offset of the previous (correct) word in the input to control access attempts; 3) syllable, attempting look-up at each syllable boundary; 4) strong syllable, attempting look-up at each strong syllable boundary. That is, the first strategy assumes a word may begin at any phoneme boundary, the second word only begin at the end of the previous one, the third that a word may begin at any syllable boundary, and the fourth that a word may begin at a strong syllable boundary. strong syllable strategy separate look-up process for typically unstressed grammatical, closed-class vocabulary and allows the possibility of extending lookup &apos;backwards over one preceding weak syllable. It was assumed, for the purposes of the experiment, that lookup off weak syllables would be restricted to closed-class vocabulary, would not extend into a strong syllable, and that this process would precede attempts to incorporate a weak syllable &apos;backwards&apos; into an open-class word. The direct access approach was not considered because of its implausibility in the light of the discussion in the previous section. The stressed syllable account is very similar to the strong syllable approach, but given the problem of stress shift in fluent speech, a formulation in terms of strong syllables, which are defined in terms of the absence of vowel reduction, is preferable. Work by Marslen-Wilson and his colleagues (e.g. Marslen-Wilson &amp; Warren, 1987) suggests that, whatever access strategy is used, there is no delay in the availability of information derived from the speech signal to further select from the cohort of word candidates. This suggests that a model in which units (say syllabics) of the pre-lexical representation are &apos;pre-packaged&apos; and then used to trigger a look-up attempt are implausible. Rather the look-up process must involve the continuous integration of information from the pre-lexical representation immediately it becomes available. Thus question of access strategy concerns only the at which this look-up process is initiated. In order to simulate the continuous aspect of lexical access using the dictionary database, database look-up queries for each strategy were initiated using the two phonemes/segments from the trigger point and then again with three phonemes/segments and so on until no further English words in the database were compatible with the look-up query (except for closed-class access with the strong syllable strategy where a strong syllable boundary terminated the sequence of accesses). The size of the resulting cohorts was measured for each successively query; for example, using fine transcription triggering access from the /r/ of an initial cohort of 89 candidates compatible with /ref/. This cohort drops to 12 words when /n/ is added and to 1 word when /b/ is also included and finally goes to 0 the vowel of added. Each sequence of queries of this type which all begin at the same point in the signal will be referred to as an access path. The difference between the access strategies is mostly in the number of distinct access paths they generate. Simulating access attempts using the dictionary database involves generating database queries consisting of partial phonological representations which return sets of words and entries which satisfy the query. For example, Figure 1 represents the query corresponding to complete broad-class transcription of query matches 37 word forms in the database. ( (pron (ney1.13 21 [al [peak ?] (.2 [streets 21 [onset (OR bdgkp t) [peak 7] [coda (OR m n N) (ORbdgkpt))))) Figure I — Database query for &apos;appoint&apos;. The experiment involved generating sequences of queries of this type and recording the number of words found in the database which matched each query. Figure 2 shows the partial word lattice for the mid class of rainbow is, the strong syllable access strategy. In this lattice access paths involving successively larger portions of the signal are illustrated. number under attempt represents the size of the set of words whose phonology is compatible with the quay. Lines preceded by an arrow indicate a query which forms part of an access path, adding a further segment to the query above it. Th e rain bow is a --- I 1 4 89 59 5 8 &gt;---I 12 3 &gt;----- &gt;-- 1 0 1 0 &gt;--- Figure 2 — Partial Word Lattice The corresponding complete word lattice for the same portion of input using a mid-class transcription and the strong syllable strategy is shown in Figure 3. In this lattice, only words whose complete phonology is compatible with the input are shown. The rain bow is a I -- I I -- I I -- I I — I I 14 1 2 5 8 I ---- I 3 1 Figure 3 — Canplete Word Lattice The different strategies were evaluated relative to the 3 transcription schemes by summing the total number of partial words matched for the test sentence under each strategy and transcription and also by looking at the total number of complete words matched. RESULTS Table 1 below gives a selection of the more important results for each strategy by transcription scheme for the test sentence in (2). Column 1 shows the number of access paths initiated for the sentence under each strategy. Columns 2 to 6 shows the number of words in all the cohorts produced by the for the test sentence after 2 to 6 phonemes/segments of the transcription have been incorporated into each access path. Column 7 shows the total number of words which achieve a complete match during the application of the particular access strategy to the test sentence. Table 1 provides an index of the efficiency of each access strategy in terms of the overall number of candidate words which appear in cohorts and also the overall number of words which receive a full match for the test sentence. In addition, the relative performance of each strategy as the transcription scheme becomes less determinate is clear. The test sentence contains 12 words, 20 syllables, and 45 phonemes; for the purposes of this experiment the word a in the test sentence does not trigger a lookup attempt with the word strategy because cohort sizes were only recorded for sequences of two or more phonemes/segments. Assuming a fine class transcription serving as pre-lexical input, the phoneme strategy produces 41 full matches as compared to 20 for the strong syllable strategy. This demonstrates that the strong syllable strategy is more effective at ruling out spurious word candidates for the test sentence. Furthermore, the total number of candidates considered using the phoneme strategy is 1544 (after 2 phonemes/segments) but only 720 for the strong syllable strategy, again indicating the greater effectiveness of the latter strategy. When we Access Strategy Access Paths No. of words after x segments: 6 Complete Matches Fine Class 2 3 4 5 Phoneme 45 1544 251 46 6 2 41 Word 11 719 193 32 5 2 25 Syllable 20 1090 210 36 6 2 28 StrongS 17 720 105 24 5 2 20 Mid Class Word 11 4701 1738 802 54 8 249 Syllable 20 12995 3221 1530 103 9 380 StrongS 17 760 232 89 13 4 80 Broad Class Syllable 20 13744 3407 1591 140 23 402 StrongS 17 1170 228 100 18 9 117 88 consider the less determinate transcriptions it becomes even clearer that only the strong syllable strategy remains reasonably effective and does not result in a massive increase in the number of spurious candidates accessed and fully matched. (The phoneme strategy results are not reported for mid and broad class transcriptions because the cohort sizes were too large for the database query facilities to cope reliably.) The word candidates recovered using the phoneme strategy with a fine class transcription include 10 full matches resulting from accesses triggered at non-syllabic for example found using the phoneme of the and problem becomes considerably worse when moving to a less determinate transcription, illustrating very clearly the undesirable consequences of ignoring the basic linguistic constraint that word boundaries occur at syllable boundaries. Systems such as TRACE (McClelland &amp; Ehnen. 1986) use this strategy compensate by using a global best-fit evaluation metric for the entire utterance which strongly disfavours &apos;unattached&apos; input. However, these models still make the implausible claim that like be highly-activated by the speech input. The results concerning the word based strategy presume that it is possible to determinately recognise the endpoint of the preceding word. This assumption is based on the Cohort theory claim (e.g. Marslen-Wilson &amp; Welsh, 1978) that words can be recognised before their acoustic offset, using syntactic and semantic expectations to filter the cohort. This claim has been challenged experimentally by Grosjean (1985) and Bard et al. (1988) who demonstrate that many monosyllabic words in context are not recognised until after their acoustic offset. The experiment reported here supports this experimental result because even with the fine class transcription there are 5 word candidates which extend beyond the correct word boundary and 11 full matches which end before the correct boundary. With the mid class transcription, these numbers rise to 849 and 57, respectively. It seems implausible that expectation-based constraints could be powerful enough to correctly select a unique candidate before its acoustic offset in all contexts. Therefore, the results for the word strategy reported here are overly-optimistic, because in order to guarantee that the correct sequence of words are in the cohorts recovered from the input, a lexical access system based on the word strategy would need to operate nondeterministically; that is, it would need to consider several potential word boundaries in most cases. the results for a practical system this approach are likely to be significantly worse. The syllable strategy is effective under the assumption of a determinate and accurate phonemic prelexical representation, but once we abandon this idealisation, the effectiveness of this strategy declines sharply. Under the plausible assumption that the prelexical input representation is Moly to be least accurate/determinate for unstressed/weak syllables, the strong syllable strategy is far more robust. This it a direct consequence of triggering look-up attempts off the more determinate parts of the pre-lexical representation. Further theoretical evidence in support of the strong syllable strategy is provided by Cutler &amp; Carter (1987) who demonstrate that a listener is six dines more likely to encounter a word with a prosodically strong initial syllable than one with a weak initial syllable when listening to English speech. Experimental evidence is provided by Cutler &amp; Norris (1988) who report results which suggest that listeners tend to treat strong, but not weak, syllables as appropriate points at which to undertake pre-lexical segmentation of the speech input. The architecture of a lexical access system based on the syllable strategy can be quite simple in terms of the organisation of the lexicon and its access routines. It is only necessary to index the lexicon by syllable types (Church, 1987). By contrast, the strong syllable strategy requires a separate closed-class word lexicon and access system, indexing of the open-class vocabulary by strong syllable and a more complex matching procedure capable of incorporating preceding weak syllables for words such the experimental results reported here suggest that the extra complexity is warranted because the resulting system will be considerably more robust in the face of inaccurate or indeterminate input concerning the nature of the weak syllables in the input utterance. CONCLUSION The experiment reported above suggests that the syllable will provide the most effective technique for producing minimal cohorts guaranteed to contain the correct word candidate from a pre-lexical phonological representation which may be partly inaccurate or indeterminate. Further work to be undertaken includes the rerunning of the experiment with further input transcriptions containing pseudo-random typical phoneme perception errors and the inclusion of designed to yield a &apos;phoneticallybalanced&apos; corpus. In addition, the relative internal discriminability (in terms of further phonological and &apos;higher-level&apos; syntactic and semantic constraints) of the word candidates in the varying cohorts generated with the different strategies should be examined. The importance of making use of a dictionary database with a realistic vocabulary size in order to evaluate proposals concerning lexical access and word recognition systems is highlighted by the results of this experiment, which demonstrate the theoretical implausibility of many of the proposals in the literature when we consider the consequences in a simulation involving more than a few hundred illustrative words. 89 ACKNOWLEDGEMENTS would thank Longman Group Ltd. for the typesetting tape of Longman Dictionary Contemporary English to us for research purposes. Part of the work reported here was supported by SERC grant 0R/D/4217. I also thank Anne Cutler, Francis Nolan and Tun Sholicar for useful comments and advice. All errors remain my own. REFERENCES Bard, E., Shillcock, R. 8c Altmarm, G. (1988). The recognition of words after their acoustic offsets in spontaneous speech: effects of subsequent context.</abstract>
<note confidence="0.824670285714286">amp; Psychophysics, 395-408. B. 8t Briscoe, E. (1989). Lexicography for Natural Language Processing. Longman Limited, London. Boguraev, B., Carter, D. &amp; Briscoe, E. (1987). A multiinterface to an on-line dictionary. Conference of Eur. Assoc. for Computational Linguistics, Copenhagen. Bradley, D. &amp; Forster, K. (1987). A reader&apos;s view of 103-34. Carter, D. (1987). An information-theoretic analysis of dictionary access. Speech and 1-11. Carter, D., Boguraev, B. &amp; Briscoe, E. (1987). Lexical</note>
<title confidence="0.3706025">stress and phonetic information: which segments are informative. of Eur. Conference on Speech</title>
<author confidence="0.481901">In</author>
<note confidence="0.785402788732394">Boguraev &amp; Briscoe (1989) pp. 135-52. Church. K. (1987). Phonological parsing and lexical 53-69. Cole, R. (1973). Listening for mispronunciations: a of what we hear during speech. &amp; 153-6. Cutler, A. &amp; Carter, D. (1987). The predominance of strong initial syllables in the English vocabulary. Speech and Language, 133-42. Cutler, A., Mehler, J., Norris, D. &amp; Segui, J. (1987). identification and the lexicon. 141-77. Cutler, A. &amp; Norris, D. (1988). The role of strong in segmentation for lexical access. of Experimental Psychology: Human Perception and 113-21. Frazier, L (1987). Structure in auditory word 157-87. A. (1980). An to the Pronunciation English. Edition, Edward Arnold, London. Grosjean, F. &amp; Gee, J. (1987). Prosodic structure and word recognition. 135-155. Harrington, J., Watson, G. &amp; Cooper, M. (1988). Word boundary identification from phoneme sequence constraints in automatic continuous speech recognition. Proc. of 12th Int. Conf. on Computational Linguistics. Budapest, pp. 225-30. Huttenlocher, D. (1985). Exploiting sequential phonetic in recognizing spoken words. Lab. Memo 867. Klatt, D. (1979). Speech perception a model of acousticanalysis and lexical access. of 279-312. Marslen-Wilson, M. (1987). Functional parallelism in word recognition. 71-102. Marslen-Wilson, W. &amp; Warren, P. (1987). Continuous uptake of acoustic cues in spoken word recognition. &amp; Psychophysics, 262-75. Marslen-Wilson, W. &amp; Welsh, A. (1978). Processing interactions and lexical access during word recognition in speech. Psychology, 29-63. McClelland, J. &amp; Elman, J. (1986). The TRACE model speech perception. Psychology, 1-86. Miller, G. &amp; Nicely, P. (1955). Analysis of some perceptual confusions among some English consonants. of Acoustical Society of America, 338-52. Sakoe, H. &amp; Chiba, S. (1971). A dynamic programming for spoken word recognition. Transactions, Acoustics, Speech and Signal Processing, ASSP-26, 43-49. Selkirk, E. (1978). On prosodic structure and its relation to syntactic structure. Indiana University Linguistics Club, Bloomington, Indiana. Sheperd, R. (1972) Psychological representation of sounds. In David, E. &amp; Denes, P. A Unified View, York: McGraw- Hill. Shipman. D. &amp; Zue, V. (1982). Properties of large lexicons: implications for advanced isolated word systems. ICASSP, 546-549. Wiese, R. (1986). The role of phonology in speech of 11th Int. Conf. on Computational pp. 608-11. Wilson, M. (1988). MRC psycholinguistic database: dictionary, version 2.0 Methods, Instrumentation &amp; Computers, 6-10. Zue, V. &amp; Huttenlocher, D. (1983). Computer recognition of isolated words from large vocabularies. IEEE Conference on Trends and Applications. 90</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Bard</author>
<author>R 8c Altmarm Shillcock</author>
<author>G</author>
</authors>
<title>The recognition of words after their acoustic offsets in spontaneous speech: effects of subsequent context.</title>
<date>1988</date>
<journal>Perception &amp; Psychophysics,</journal>
<volume>44</volume>
<pages>395--408</pages>
<contexts>
<context position="28692" citStr="Bard et al. (1988)" startWordPosition="4418" endWordPosition="4421">rance which strongly disfavours &apos;unattached&apos; input. However, these models still make the implausible claim that candidates like arraign will be highly-activated by the speech input. The results concerning the word based strategy presume that it is possible to determinately recognise the endpoint of the preceding word. This assumption is based on the Cohort theory claim (e.g. Marslen-Wilson &amp; Welsh, 1978) that words can be recognised before their acoustic offset, using syntactic and semantic expectations to filter the cohort. This claim has been challenged experimentally by Grosjean (1985) and Bard et al. (1988) who demonstrate that many monosyllabic words in context are not recognised until after their acoustic offset. The experiment reported here supports this experimental result because even with the fine class transcription there are 5 word candidates which extend beyond the correct word boundary and 11 full matches which end before the correct boundary. With the mid class transcription, these numbers rise to 849 and 57, respectively. It seems implausible that expectation-based constraints could be powerful enough to correctly select a unique candidate before its acoustic offset in all contexts. </context>
</contexts>
<marker>Bard, Shillcock, G, 1988</marker>
<rawString>Bard, E., Shillcock, R. 8c Altmarm, G. (1988). The recognition of words after their acoustic offsets in spontaneous speech: effects of subsequent context. Perception &amp; Psychophysics, 44, 395-408.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B 8t Briscoe Boguraev</author>
<author>E</author>
</authors>
<title>Computational Lexicography for Natural Language Processing.</title>
<date>1989</date>
<publisher>Longman Limited,</publisher>
<location>London.</location>
<marker>Boguraev, E, 1989</marker>
<rawString>Boguraev, B. 8t Briscoe, E. (1989). Computational Lexicography for Natural Language Processing. Longman Limited, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Boguraev</author>
<author>D Carter</author>
<author>E Briscoe</author>
</authors>
<title>A multipurpose interface to an on-line dictionary.</title>
<date>1987</date>
<booktitle>3rd Conference of Eur. Assoc. for Computational Linguistics,</booktitle>
<location>Copenhagen.</location>
<marker>Boguraev, Carter, Briscoe, 1987</marker>
<rawString>Boguraev, B., Carter, D. &amp; Briscoe, E. (1987). A multipurpose interface to an on-line dictionary. 3rd Conference of Eur. Assoc. for Computational Linguistics, Copenhagen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bradley</author>
<author>K Forster</author>
</authors>
<title>A reader&apos;s view of listening.</title>
<date>1987</date>
<journal>Cognition,</journal>
<volume>25</volume>
<pages>103--34</pages>
<contexts>
<context position="2320" citStr="Bradley &amp; Forster, 1987" startWordPosition="341" endWordPosition="344">rmation, as more of the speech input becomes available, and on the basis of the candidates&apos; compatibility with the linguistic and extralinguistic context of utterance. When only one candidate remains, word recognition is said to have taken place. Most psycholinguistic work in this area has focussed on the process of word recognition after a cohort of candidates has been selected, emphasising the role of further lexical or &apos;higher-level&apos; linguistic constraints such as word frequency, lexical semantic relations, or syntactic and semantic congruity of candidates with the linguistic context (e.g. Bradley &amp; Forster, 1987; MarslenWilson &amp; Welsh, 1978). The few explicit and welldeveloped models of lexical access and word recognition in continuous speech (e.g. TRACE, McClelland &amp; Elman, 1986) have small and unrealistic lexicons of, at most, a few hundred words and ignore phonological processes which occur in fluent speech. Therefore, they tend to overestimate the amount and reliability of acoustic information which can be directly extracted from the speech signal (either by human or machine) and make unrealistic and overly-optimistic assumptions concerning the size and diversity of candidates in a typical cohort</context>
</contexts>
<marker>Bradley, Forster, 1987</marker>
<rawString>Bradley, D. &amp; Forster, K. (1987). A reader&apos;s view of listening. Cognition, 25, 103-34.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Carter</author>
</authors>
<title>An information-theoretic analysis of phonetic dictionary access.</title>
<date>1987</date>
<journal>Computer Speech and Language,</journal>
<volume>2</volume>
<pages>1--11</pages>
<contexts>
<context position="9689" citStr="Carter, 1987" startWordPosition="1454" endWordPosition="1455">ing the categories: Stop, Strong-Fricative, Weak-Fricative, Nasal, Glide-Liquid, and Vowel). This claim suggests that the English lexicon is functionally organised to favour a system which initiates lexical access from a broad manner class pre-lexical representation, because most of the discriminatory information between different words is concentrated in the manner articulation of stressed syllables. Elsewhere, we have argued that these ideas are misleadingly presented and that there is, in fact, no significant advantage for manner information in stressed syllables (e.g. Carter et al., 1987; Carter, 1987, 1989). We found that there is no advantage per se to a manner class analysis of stressed syllables, since a similar analysis of unstressed syllables is as discriminatory and yields as good a partitioning of the English lexicon. However, concentrating on a full phonemic analysis of stressed syllables provides about 10% more information than a similar analysis of unstressed syllables. This research suggests, then, that the pre-lexical representation used to initiate lexical access can only afford to concentrate exclusively on stressed syllables if these are analysed (at least) phonemically. No</context>
<context position="30412" citStr="Carter (1987)" startWordPosition="4677" endWordPosition="4678">ctive under the assumption of a determinate and accurate phonemic prelexical representation, but once we abandon this idealisation, the effectiveness of this strategy declines sharply. Under the plausible assumption that the prelexical input representation is Moly to be least accurate/determinate for unstressed/weak syllables, the strong syllable strategy is far more robust. This it a direct consequence of triggering look-up attempts off the more determinate parts of the pre-lexical representation. Further theoretical evidence in support of the strong syllable strategy is provided by Cutler &amp; Carter (1987) who demonstrate that a listener is six dines more likely to encounter a word with a prosodically strong initial syllable than one with a weak initial syllable when listening to English speech. Experimental evidence is provided by Cutler &amp; Norris (1988) who report results which suggest that listeners tend to treat strong, but not weak, syllables as appropriate points at which to undertake pre-lexical segmentation of the speech input. The architecture of a lexical access system based on the syllable strategy can be quite simple in terms of the organisation of the lexicon and its access routines</context>
</contexts>
<marker>Carter, 1987</marker>
<rawString>Carter, D. (1987). An information-theoretic analysis of phonetic dictionary access. Computer Speech and Language, 2, 1-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Carter</author>
<author>B Boguraev</author>
<author>E Briscoe</author>
</authors>
<title>Lexical stress and phonetic information: which segments are most informative.</title>
<date>1987</date>
<booktitle>Proc. of Eur. Conference on Speech Technology,</booktitle>
<location>Edinburgh.</location>
<contexts>
<context position="9675" citStr="Carter et al., 1987" startWordPosition="1450" endWordPosition="1453">iption scheme (employing the categories: Stop, Strong-Fricative, Weak-Fricative, Nasal, Glide-Liquid, and Vowel). This claim suggests that the English lexicon is functionally organised to favour a system which initiates lexical access from a broad manner class pre-lexical representation, because most of the discriminatory information between different words is concentrated in the manner articulation of stressed syllables. Elsewhere, we have argued that these ideas are misleadingly presented and that there is, in fact, no significant advantage for manner information in stressed syllables (e.g. Carter et al., 1987; Carter, 1987, 1989). We found that there is no advantage per se to a manner class analysis of stressed syllables, since a similar analysis of unstressed syllables is as discriminatory and yields as good a partitioning of the English lexicon. However, concentrating on a full phonemic analysis of stressed syllables provides about 10% more information than a similar analysis of unstressed syllables. This research suggests, then, that the pre-lexical representation used to initiate lexical access can only afford to concentrate exclusively on stressed syllables if these are analysed (at least) ph</context>
</contexts>
<marker>Carter, Boguraev, Briscoe, 1987</marker>
<rawString>Carter, D., Boguraev, B. &amp; Briscoe, E. (1987). Lexical stress and phonetic information: which segments are most informative. Proc. of Eur. Conference on Speech Technology, Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Carter</author>
</authors>
<title>LDOCE and speech recognition.</title>
<date>1989</date>
<booktitle>In Boguraev &amp; Briscoe</booktitle>
<pages>135--52</pages>
<contexts>
<context position="19199" citStr="Carter, 1989" startWordPosition="2859" endWordPosition="2860">ms, fine, mid and broad, for each transcription scheme are intended purely descriptively and are not necessarily related to other uses of these terms in the literature. Each of the schemes is intended to represent a possible behaviour of an acoustic-phonetic front-end. The less determinate transcriptions can be viewed either as the result of transcription errors and indeterrninacies or as the output of a less ambitious front-end design. The definition of syllable botmdmy employed is, of necessity, that built into the syllable parser which acts as the interface to the dictionary database (e.g. Carter, 1989). The parser syllabifies phonemic transcriptions according to the phonotactic constraints given in Gimson (1980) and utilises the maximal onset principle (Selkirk, 1978) where this leads to ambiguity. Each of the three transcriptions was used as a putative pre-lexical representation to test some of the different access strategies, which were used to initiate lexical look-up into the dictionary database. The four access strategies which were tested were: 1) phoneme, using each successive phoneme to trigger an access attempt; 2) word, using the offset of the previous (correct) word in the input </context>
</contexts>
<marker>Carter, 1989</marker>
<rawString>Carter, D. (1989). LDOCE and speech recognition. In Boguraev &amp; Briscoe (1989) pp. 135-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K</author>
</authors>
<title>Phonological parsing and lexical retrieval.</title>
<date>1987</date>
<journal>Cognition,</journal>
<volume>25</volume>
<pages>53--69</pages>
<marker>K, 1987</marker>
<rawString>Church. K. (1987). Phonological parsing and lexical retrieval. Cognition, 25, 53-69.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Cole</author>
</authors>
<title>Listening for mispronunciations: a measure of what we hear during speech.</title>
<date>1973</date>
<journal>Perception &amp; Psychophysics,</journal>
<volume>1</volume>
<pages>153--6</pages>
<contexts>
<context position="13622" citStr="Cole, 1973" startWordPosition="2035" endWordPosition="2036">speech, are sensitive to lexical effects such as word frequency, semantic association, and so forth (see Cutler at al., 1987 for a summary of the experimental literature and putative explanation of the effect), suggesting that information concerning at least some of the phonetic content of a word is not available until after the word is recognised. Thus, people&apos;s ability to recognise phonemes tells us very little about the nature of the representation used to initiate lexical access. Better (but still indirect) evidence comes from mispronunciation monitoring and phoneme confusion experiments (Cole, 1973; Miller &amp; Nicely, 1955; Sheperd, 1972) which suggest that listeners are likely to confuse or conflate phonemes along the dimensions predicted by distinctive feature theory. Most errors result in reporting phonemes which differ in only one feature from the target, This result suggests that listeners are actively considering detailed phonetic information along a number of dimensions (rather than simply, say, manner of articulation). Theoretical and experimental considerations suggest then that, regardless of the current capabilities of automated acoustic-phonetic front-ends, systems must be dev</context>
</contexts>
<marker>Cole, 1973</marker>
<rawString>Cole, R. (1973). Listening for mispronunciations: a measure of what we hear during speech. Perception &amp; Psychophysics, 1. 153-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cutler</author>
<author>D Carter</author>
</authors>
<title>The predominance of strong initial syllables in the English vocabulary.</title>
<date>1987</date>
<journal>Computer Speech and Language,</journal>
<volume>2</volume>
<pages>133--42</pages>
<contexts>
<context position="30412" citStr="Cutler &amp; Carter (1987)" startWordPosition="4675" endWordPosition="4678">y is effective under the assumption of a determinate and accurate phonemic prelexical representation, but once we abandon this idealisation, the effectiveness of this strategy declines sharply. Under the plausible assumption that the prelexical input representation is Moly to be least accurate/determinate for unstressed/weak syllables, the strong syllable strategy is far more robust. This it a direct consequence of triggering look-up attempts off the more determinate parts of the pre-lexical representation. Further theoretical evidence in support of the strong syllable strategy is provided by Cutler &amp; Carter (1987) who demonstrate that a listener is six dines more likely to encounter a word with a prosodically strong initial syllable than one with a weak initial syllable when listening to English speech. Experimental evidence is provided by Cutler &amp; Norris (1988) who report results which suggest that listeners tend to treat strong, but not weak, syllables as appropriate points at which to undertake pre-lexical segmentation of the speech input. The architecture of a lexical access system based on the syllable strategy can be quite simple in terms of the organisation of the lexicon and its access routines</context>
</contexts>
<marker>Cutler, Carter, 1987</marker>
<rawString>Cutler, A. &amp; Carter, D. (1987). The predominance of strong initial syllables in the English vocabulary. Computer Speech and Language, 2, 133-42.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cutler</author>
<author>J Mehler</author>
<author>D Norris</author>
<author>J Segui</author>
</authors>
<title>Phoneme identification and the lexicon.</title>
<date>1987</date>
<journal>Cognitive Psychology,</journal>
<volume>19</volume>
<pages>141--77</pages>
<marker>Cutler, Mehler, Norris, Segui, 1987</marker>
<rawString>Cutler, A., Mehler, J., Norris, D. &amp; Segui, J. (1987). Phoneme identification and the lexicon. Cognitive Psychology, 19, 141-77.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Cutler</author>
<author>D Norris</author>
</authors>
<title>The role of strong syllables in segmentation for lexical access.</title>
<date>1988</date>
<journal>J. of Experimental Psychology: Human Perception and Performance,</journal>
<volume>14</volume>
<pages>113--21</pages>
<contexts>
<context position="30665" citStr="Cutler &amp; Norris (1988)" startWordPosition="4716" endWordPosition="4719">presentation is Moly to be least accurate/determinate for unstressed/weak syllables, the strong syllable strategy is far more robust. This it a direct consequence of triggering look-up attempts off the more determinate parts of the pre-lexical representation. Further theoretical evidence in support of the strong syllable strategy is provided by Cutler &amp; Carter (1987) who demonstrate that a listener is six dines more likely to encounter a word with a prosodically strong initial syllable than one with a weak initial syllable when listening to English speech. Experimental evidence is provided by Cutler &amp; Norris (1988) who report results which suggest that listeners tend to treat strong, but not weak, syllables as appropriate points at which to undertake pre-lexical segmentation of the speech input. The architecture of a lexical access system based on the syllable strategy can be quite simple in terms of the organisation of the lexicon and its access routines. It is only necessary to index the lexicon by syllable types (Church, 1987). By contrast, the strong syllable strategy requires a separate closed-class word lexicon and access system, indexing of the open-class vocabulary by strong syllable and a more </context>
</contexts>
<marker>Cutler, Norris, 1988</marker>
<rawString>Cutler, A. &amp; Norris, D. (1988). The role of strong syllables in segmentation for lexical access. J. of Experimental Psychology: Human Perception and Performance, 14, 113-21.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Frazier</author>
</authors>
<title>Structure in auditory word recognition.</title>
<date>1987</date>
<journal>Cognition,</journal>
<volume>25</volume>
<pages>157--87</pages>
<contexts>
<context position="4116" citStr="Frazier, 1987" startWordPosition="612" endWordPosition="613">e only proved effective for isolated word recognition of small vocabularies with the system trained to an individual speaker, as, for example, Zue &amp; Huttenlocher (1983) argue. Furthermore, any direct access model of this type which does not incorporate a pre-lexical symbolic representation of the input will have difficulty capturing many rule-governed phonological processes which affect the pronunciation of words in fluent speech, since these processes can only be characterised adequately in terms of operations on a symbolic, phonological representation of the speech input (e.g. Church, 1987; Frazier, 1987; Wiese, 1986). The research reported here forms part of an ongoing programme to develop a computationally explicit account of lexical access and word recognition in connected speech, which is at least informed by experimental results concerning the psychological processes and mechanisms which underlie this task. To guide research, we make use of a substantial lexical database of English derived from machine-readable versions of the Longman Dictionary of Contemporary English (see Boguraev at aL, 1987; Boguraev &amp; Briscoe, 1989) and of the Medical Research Council&apos;s psycholinguistic database (Wi</context>
<context position="7691" citStr="Frazier (1987)" startWordPosition="1162" endWordPosition="1163">red from the speech input is more variable and often less detailed than that assumed by Church and, secondly, that the lexical entry retrieval stage is more directed and discriminatory, in order to reduce the number of spurious lexical entries accessed and to compensate for likely indetenninacies in the initial representation. THE PRE-LEXICAL PHONOLOGICAL REPRESENTATION Several researchers have argued that phonological processes, such as the palatalisation of /d/ in (1), create problems for the word recognition system because they &apos;distort&apos; the phonological form of the word. Church (1987) and Frazier (1987) argue persuasively that, far from creating problems, such phonological processes provide important clues to the correct syllabic segmentation of the input and thus, to the location of word boundaries. However, this argument only goes through on the assumption that quite detailed &apos;narrow&apos; phonetic information is recovered from the signal, such as aspiration of N in /tE/ and /tarn/ in (1) in order to recognise the preceding syllable boundaries. It is only in. terms of this representation that phonological processes can be recognised and their effects &apos;undone&apos; in order to allow correct matching </context>
</contexts>
<marker>Frazier, 1987</marker>
<rawString>Frazier, L (1987). Structure in auditory word recognition. Cognition, 25, 157-87.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Gimson</author>
</authors>
<title>An Introduction to the Pronunciation of English. 3rd Edition,</title>
<date>1980</date>
<location>Edward Arnold, London.</location>
<contexts>
<context position="19311" citStr="Gimson (1980)" startWordPosition="2873" endWordPosition="2874"> related to other uses of these terms in the literature. Each of the schemes is intended to represent a possible behaviour of an acoustic-phonetic front-end. The less determinate transcriptions can be viewed either as the result of transcription errors and indeterrninacies or as the output of a less ambitious front-end design. The definition of syllable botmdmy employed is, of necessity, that built into the syllable parser which acts as the interface to the dictionary database (e.g. Carter, 1989). The parser syllabifies phonemic transcriptions according to the phonotactic constraints given in Gimson (1980) and utilises the maximal onset principle (Selkirk, 1978) where this leads to ambiguity. Each of the three transcriptions was used as a putative pre-lexical representation to test some of the different access strategies, which were used to initiate lexical look-up into the dictionary database. The four access strategies which were tested were: 1) phoneme, using each successive phoneme to trigger an access attempt; 2) word, using the offset of the previous (correct) word in the input to control access attempts; 3) syllable, attempting look-up at each syllable boundary; 4) strong syllable, attem</context>
</contexts>
<marker>Gimson, 1980</marker>
<rawString>Gimson, A. (1980). An Introduction to the Pronunciation of English. 3rd Edition, Edward Arnold, London.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Grosjean</author>
<author>J Gee</author>
</authors>
<title>Prosodic structure and spoken word recognition.</title>
<date>1987</date>
<journal>Cognition,</journal>
<volume>25</volume>
<pages>135--155</pages>
<contexts>
<context position="16808" citStr="Grosjean &amp; Gee (1987)" startWordPosition="2489" endWordPosition="2492">plain how the process of lexical access is triggered at appropriate points in the speech signal in the absence of completely reliable phonetic/phonological cues to word boundaries. The various theories of lexical access and word recognition in connected speech propose mechanisms which appear to cover the full spectrum of logical possibilities. Klatt (1979) suggests that lexical access is triggered off each successive spectral frame derived from the signal (i.e. approximately every 5 msecs.), McClelland &amp; Elman (1986) suggest each successive phoneme, Church (1987) suggests each syllable onset. Grosjean &amp; Gee (1987) suggest each stressed syllable onset, and Cutler &amp; Norris (1985) suggest each prosodically strong syllable onset. Finally, MarslenWilson &amp; Welsh (1978) suggest that segmentation of the speech input and recognition of word boundaries is an indivisible process in which the endpoint of the previous word defines the point at which lexical access is triggered again. Some of these access strategies have been evaluated with respect to three input transcriptions (which are plausible candidates for the pre-lexical representation on the basis of the work discussed in the previous section) in the contex</context>
</contexts>
<marker>Grosjean, Gee, 1987</marker>
<rawString>Grosjean, F. &amp; Gee, J. (1987). Prosodic structure and spoken word recognition. Cognition, 25, 135-155.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Harrington</author>
<author>G Watson</author>
<author>M Cooper</author>
</authors>
<title>Word boundary identification from phoneme sequence constraints in automatic continuous speech recognition.</title>
<date>1988</date>
<booktitle>Proc. of 12th Int. Conf. on Computational Linguistics. Budapest,</booktitle>
<pages>225--30</pages>
<contexts>
<context position="12317" citStr="Harrington et al. (1988)" startWordPosition="1841" endWordPosition="1844"> of many spurious word candidates. 85 A third argument against the use of exclusively broad representations is that these representations will not support the effective recognition of syllableboundaries and some word-boundaries on the basis of phonotactic and other phonological sequencing constraints. For example, Church (1987) proposes an initial syllabification of the input as a prerequisite to lexical access, but his syllabification of the speech input exploits phonotactic constraints and relies on the extraction of allophonic features, such as aspiration, to guide this process. Similarly, Harrington et al. (1988) argue that approximately 45% of word boundaries are, in principle, recognisable because they occur in phoneme sequences which are rare or forbidden word-internally. However, exploitation of these English phonological constraints would be considerably impaired if the prelexical representation of the input is restricted to a broad classification. It might seem self-evident that people are able to recognise phonemes in speech, but in fact the psychological evidence suggests that this ability is mediated by the output of the word recognition process rather than being an essential prerequisite to </context>
</contexts>
<marker>Harrington, Watson, Cooper, 1988</marker>
<rawString>Harrington, J., Watson, G. &amp; Cooper, M. (1988). Word boundary identification from phoneme sequence constraints in automatic continuous speech recognition. Proc. of 12th Int. Conf. on Computational Linguistics. Budapest, pp. 225-30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Huttenlocher</author>
</authors>
<title>Exploiting sequential phonetic constraints in recognizing spoken words.</title>
<date>1985</date>
<journal>Nor. AL Lab. Memo</journal>
<volume>867</volume>
<contexts>
<context position="8935" citStr="Huttenlocher (1985)" startWordPosition="1348" endWordPosition="1349">canonical phonological representations contained in lexical entries. Other researchers (e.g. Shipman &amp; Zue, 1982) have argued (in the context of isolated word recognition) that the initial representation which contacts the lexicon should be a broad manner-class transcription of the stressed syllables in the speech signal. The evidence in favour of this approach is, firstly, that extraction of more detailed information is notoriously difficult and, secondly, that a broad transcription of this type appears to be very effective in partitioning the English lexicon into small cohorts. For example, Huttenlocher (1985) reports an average cohort size of 21 words for a 20,000 word lexicon using a six-category manner of articulation transcription scheme (employing the categories: Stop, Strong-Fricative, Weak-Fricative, Nasal, Glide-Liquid, and Vowel). This claim suggests that the English lexicon is functionally organised to favour a system which initiates lexical access from a broad manner class pre-lexical representation, because most of the discriminatory information between different words is concentrated in the manner articulation of stressed syllables. Elsewhere, we have argued that these ideas are mislea</context>
</contexts>
<marker>Huttenlocher, 1985</marker>
<rawString>Huttenlocher, D. (1985). Exploiting sequential phonetic constraints in recognizing spoken words. Nor. AL Lab. Memo 867.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Klatt</author>
</authors>
<title>Speech perception a model of acousticphonetic analysis and lexical access.</title>
<date>1979</date>
<journal>Journal of Phonetics,</journal>
<volume>7</volume>
<pages>279--312</pages>
<contexts>
<context position="1006" citStr="Klatt, 1979" startWordPosition="143" endWordPosition="144"> of an experiment are reported which was designed to evaluate a number of access strategies proposed in the literature in conjunction with several plausible pre-lexical representations of the speech input. The experiment also extends previous work by utilising a dictionary database containing a realistic rather than illustrative English vocabulary. THEORETICAL BACKGROUND In most recent work on the process of word recognition during comprehension of connected speech (either by human or machine) a distinction is made between lexical access and word recognition (eg. Marslen-Wilson &amp; Welsh, 1978; Klatt, 1979). Lexical access is the process by which contact is made with the lexicon on the basis of an initial acoustic-phonetic or phonological representation of some portion of the speech input. The result of lexical access is a cohort of potential word candidates which are compatible with this initial analysis. (The term cohort is used descriptively in this paper and does not represent any commitment to the particular account of lexical access and word recognition provided by any version of the cohort theory (e.g. Marslen-Wilson, 1987).) Most theories assume that the candidates in this cohort are suc</context>
<context position="16545" citStr="Klatt (1979)" startWordPosition="2453" endWordPosition="2454">sentation will necessarily be accurate to the same degree of detail throughout the input. LEXICAL ACCESS STRATEGIES Any theory of word recognition must provide a mechanism for the segmentation of connected speech into words. In effect, the theory must explain how the process of lexical access is triggered at appropriate points in the speech signal in the absence of completely reliable phonetic/phonological cues to word boundaries. The various theories of lexical access and word recognition in connected speech propose mechanisms which appear to cover the full spectrum of logical possibilities. Klatt (1979) suggests that lexical access is triggered off each successive spectral frame derived from the signal (i.e. approximately every 5 msecs.), McClelland &amp; Elman (1986) suggest each successive phoneme, Church (1987) suggests each syllable onset. Grosjean &amp; Gee (1987) suggest each stressed syllable onset, and Cutler &amp; Norris (1985) suggest each prosodically strong syllable onset. Finally, MarslenWilson &amp; Welsh (1978) suggest that segmentation of the speech input and recognition of word boundaries is an indivisible process in which the endpoint of the previous word defines the point at which lexical</context>
</contexts>
<marker>Klatt, 1979</marker>
<rawString>Klatt, D. (1979). Speech perception a model of acousticphonetic analysis and lexical access. Journal of Phonetics, 7, 279-312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marslen-Wilson</author>
</authors>
<title>Functional parallelism in spoken word recognition.</title>
<date>1987</date>
<journal>Cognition,</journal>
<volume>25</volume>
<pages>71--102</pages>
<contexts>
<context position="1540" citStr="Marslen-Wilson, 1987" startWordPosition="228" endWordPosition="229">een lexical access and word recognition (eg. Marslen-Wilson &amp; Welsh, 1978; Klatt, 1979). Lexical access is the process by which contact is made with the lexicon on the basis of an initial acoustic-phonetic or phonological representation of some portion of the speech input. The result of lexical access is a cohort of potential word candidates which are compatible with this initial analysis. (The term cohort is used descriptively in this paper and does not represent any commitment to the particular account of lexical access and word recognition provided by any version of the cohort theory (e.g. Marslen-Wilson, 1987).) Most theories assume that the candidates in this cohort are successively whittled down both on the basis of further acoustic-phonetic or phonological information, as more of the speech input becomes available, and on the basis of the candidates&apos; compatibility with the linguistic and extralinguistic context of utterance. When only one candidate remains, word recognition is said to have taken place. Most psycholinguistic work in this area has focussed on the process of word recognition after a cohort of candidates has been selected, emphasising the role of further lexical or &apos;higher-level&apos; li</context>
</contexts>
<marker>Marslen-Wilson, 1987</marker>
<rawString>Marslen-Wilson, M. (1987). Functional parallelism in spoken word recognition. Cognition, 25, 71-102.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Marslen-Wilson</author>
<author>P Warren</author>
</authors>
<title>Continuous uptake of acoustic cues in spoken word recognition.</title>
<date>1987</date>
<journal>Perception &amp; Psychophysics,</journal>
<volume>41</volume>
<pages>262--75</pages>
<contexts>
<context position="21199" citStr="Marslen-Wilson &amp; Warren, 1987" startWordPosition="3170" endWordPosition="3173">cabulary, would not extend into a strong syllable, and that this process would precede attempts to incorporate a weak syllable &apos;backwards&apos; into an open-class word. The direct access approach was not considered because of its implausibility in the light of the discussion in the previous section. The stressed syllable account is very similar to the strong syllable approach, but given the problem of stress shift in fluent speech, a formulation in terms of strong syllables, which are defined in terms of the absence of vowel reduction, is preferable. Work by Marslen-Wilson and his colleagues (e.g. Marslen-Wilson &amp; Warren, 1987) suggests that, whatever access strategy is used, there is no delay in the availability of information derived from the speech signal to further select from the cohort of word candidates. This suggests that a model in which units (say syllabics) of the pre-lexical representation are &apos;pre-packaged&apos; and then used to trigger a look-up attempt are implausible. Rather the look-up process must involve the continuous integration of information from the pre-lexical representation immediately it becomes available. Thus the question of access strategy concerns only the points at which this look-up proce</context>
</contexts>
<marker>Marslen-Wilson, Warren, 1987</marker>
<rawString>Marslen-Wilson, W. &amp; Warren, P. (1987). Continuous uptake of acoustic cues in spoken word recognition. Perception &amp; Psychophysics, 41, 262-75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Marslen-Wilson</author>
<author>A Welsh</author>
</authors>
<title>Processing interactions and lexical access during word recognition in continuous speech.</title>
<date>1978</date>
<journal>Cognitive Psychology,</journal>
<volume>10</volume>
<pages>29--63</pages>
<contexts>
<context position="992" citStr="Marslen-Wilson &amp; Welsh, 1978" startWordPosition="139" endWordPosition="142">is representation. The results of an experiment are reported which was designed to evaluate a number of access strategies proposed in the literature in conjunction with several plausible pre-lexical representations of the speech input. The experiment also extends previous work by utilising a dictionary database containing a realistic rather than illustrative English vocabulary. THEORETICAL BACKGROUND In most recent work on the process of word recognition during comprehension of connected speech (either by human or machine) a distinction is made between lexical access and word recognition (eg. Marslen-Wilson &amp; Welsh, 1978; Klatt, 1979). Lexical access is the process by which contact is made with the lexicon on the basis of an initial acoustic-phonetic or phonological representation of some portion of the speech input. The result of lexical access is a cohort of potential word candidates which are compatible with this initial analysis. (The term cohort is used descriptively in this paper and does not represent any commitment to the particular account of lexical access and word recognition provided by any version of the cohort theory (e.g. Marslen-Wilson, 1987).) Most theories assume that the candidates in this </context>
<context position="28481" citStr="Marslen-Wilson &amp; Welsh, 1978" startWordPosition="4386" endWordPosition="4389">c constraint that word boundaries occur at syllable boundaries. Systems such as TRACE (McClelland &amp; Ehnen. 1986) which use this strategy appear to compensate by using a global best-fit evaluation metric for the entire utterance which strongly disfavours &apos;unattached&apos; input. However, these models still make the implausible claim that candidates like arraign will be highly-activated by the speech input. The results concerning the word based strategy presume that it is possible to determinately recognise the endpoint of the preceding word. This assumption is based on the Cohort theory claim (e.g. Marslen-Wilson &amp; Welsh, 1978) that words can be recognised before their acoustic offset, using syntactic and semantic expectations to filter the cohort. This claim has been challenged experimentally by Grosjean (1985) and Bard et al. (1988) who demonstrate that many monosyllabic words in context are not recognised until after their acoustic offset. The experiment reported here supports this experimental result because even with the fine class transcription there are 5 word candidates which extend beyond the correct word boundary and 11 full matches which end before the correct boundary. With the mid class transcription, t</context>
</contexts>
<marker>Marslen-Wilson, Welsh, 1978</marker>
<rawString>Marslen-Wilson, W. &amp; Welsh, A. (1978). Processing interactions and lexical access during word recognition in continuous speech. Cognitive Psychology, 10, 29-63.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J McClelland</author>
<author>J Elman</author>
</authors>
<title>The TRACE model of speech perception.</title>
<date>1986</date>
<journal>Cognitive Psychology,</journal>
<volume>18</volume>
<pages>1--86</pages>
<contexts>
<context position="2492" citStr="McClelland &amp; Elman, 1986" startWordPosition="368" endWordPosition="371">en only one candidate remains, word recognition is said to have taken place. Most psycholinguistic work in this area has focussed on the process of word recognition after a cohort of candidates has been selected, emphasising the role of further lexical or &apos;higher-level&apos; linguistic constraints such as word frequency, lexical semantic relations, or syntactic and semantic congruity of candidates with the linguistic context (e.g. Bradley &amp; Forster, 1987; MarslenWilson &amp; Welsh, 1978). The few explicit and welldeveloped models of lexical access and word recognition in continuous speech (e.g. TRACE, McClelland &amp; Elman, 1986) have small and unrealistic lexicons of, at most, a few hundred words and ignore phonological processes which occur in fluent speech. Therefore, they tend to overestimate the amount and reliability of acoustic information which can be directly extracted from the speech signal (either by human or machine) and make unrealistic and overly-optimistic assumptions concerning the size and diversity of candidates in a typical cohort. This, in turn, casts doubt on the real efficacy of the putative mechanisms which are intended to select the correct word from the cohort. The bulk of engineering systems </context>
<context position="16709" citStr="McClelland &amp; Elman (1986)" startWordPosition="2475" endWordPosition="2478"> provide a mechanism for the segmentation of connected speech into words. In effect, the theory must explain how the process of lexical access is triggered at appropriate points in the speech signal in the absence of completely reliable phonetic/phonological cues to word boundaries. The various theories of lexical access and word recognition in connected speech propose mechanisms which appear to cover the full spectrum of logical possibilities. Klatt (1979) suggests that lexical access is triggered off each successive spectral frame derived from the signal (i.e. approximately every 5 msecs.), McClelland &amp; Elman (1986) suggest each successive phoneme, Church (1987) suggests each syllable onset. Grosjean &amp; Gee (1987) suggest each stressed syllable onset, and Cutler &amp; Norris (1985) suggest each prosodically strong syllable onset. Finally, MarslenWilson &amp; Welsh (1978) suggest that segmentation of the speech input and recognition of word boundaries is an indivisible process in which the endpoint of the previous word defines the point at which lexical access is triggered again. Some of these access strategies have been evaluated with respect to three input transcriptions (which are plausible candidates for the p</context>
</contexts>
<marker>McClelland, Elman, 1986</marker>
<rawString>McClelland, J. &amp; Elman, J. (1986). The TRACE model of speech perception. Cognitive Psychology, 18, 1-86. Miller, G. &amp; Nicely, P. (1955). Analysis of some perceptual confusions among some English consonants. Journal of Acoustical Society of America, 27, 338-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Sakoe</author>
<author>S Chiba</author>
</authors>
<title>A dynamic programming optimization for spoken word recognition.</title>
<date>1971</date>
<journal>IEEE Transactions, Acoustics, Speech and Signal Processing,</journal>
<volume>26</volume>
<pages>43--49</pages>
<contexts>
<context position="3472" citStr="Sakoe &amp; Chiba, 1971" startWordPosition="518" endWordPosition="521"> concerning the size and diversity of candidates in a typical cohort. This, in turn, casts doubt on the real efficacy of the putative mechanisms which are intended to select the correct word from the cohort. The bulk of engineering systems for speech recognition have finessed the issues of lexical access and word recognition by attempting to map directly from the acoustic signal to candidate words by pairing words with acoustic representations of the canonical pronunciation of the word in the lexicon and employing pattern-matching, best-fit techniques to select the most likely candidate (e.g. Sakoe &amp; Chiba, 1971). However, these techniques have only proved effective for isolated word recognition of small vocabularies with the system trained to an individual speaker, as, for example, Zue &amp; Huttenlocher (1983) argue. Furthermore, any direct access model of this type which does not incorporate a pre-lexical symbolic representation of the input will have difficulty capturing many rule-governed phonological processes which affect the pronunciation of words in fluent speech, since these processes can only be characterised adequately in terms of operations on a symbolic, phonological representation of the sp</context>
</contexts>
<marker>Sakoe, Chiba, 1971</marker>
<rawString>Sakoe, H. &amp; Chiba, S. (1971). A dynamic programming optimization for spoken word recognition. IEEE Transactions, Acoustics, Speech and Signal Processing, ASSP-26, 43-49.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Selkirk</author>
</authors>
<title>On prosodic structure and its relation to syntactic structure.</title>
<date>1978</date>
<institution>Indiana University Linguistics Club,</institution>
<location>Bloomington, Indiana.</location>
<contexts>
<context position="19368" citStr="Selkirk, 1978" startWordPosition="2881" endWordPosition="2882"> Each of the schemes is intended to represent a possible behaviour of an acoustic-phonetic front-end. The less determinate transcriptions can be viewed either as the result of transcription errors and indeterrninacies or as the output of a less ambitious front-end design. The definition of syllable botmdmy employed is, of necessity, that built into the syllable parser which acts as the interface to the dictionary database (e.g. Carter, 1989). The parser syllabifies phonemic transcriptions according to the phonotactic constraints given in Gimson (1980) and utilises the maximal onset principle (Selkirk, 1978) where this leads to ambiguity. Each of the three transcriptions was used as a putative pre-lexical representation to test some of the different access strategies, which were used to initiate lexical look-up into the dictionary database. The four access strategies which were tested were: 1) phoneme, using each successive phoneme to trigger an access attempt; 2) word, using the offset of the previous (correct) word in the input to control access attempts; 3) syllable, attempting look-up at each syllable boundary; 4) strong syllable, attempting look-up at each strong syllable boundary. That is, </context>
</contexts>
<marker>Selkirk, 1978</marker>
<rawString>Selkirk, E. (1978). On prosodic structure and its relation to syntactic structure. Indiana University Linguistics Club, Bloomington, Indiana.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sheperd</author>
</authors>
<title>Psychological representation of speech sounds. In</title>
<date>1972</date>
<publisher>McGrawHill.</publisher>
<location>New York:</location>
<contexts>
<context position="13661" citStr="Sheperd, 1972" startWordPosition="2041" endWordPosition="2042">fects such as word frequency, semantic association, and so forth (see Cutler at al., 1987 for a summary of the experimental literature and putative explanation of the effect), suggesting that information concerning at least some of the phonetic content of a word is not available until after the word is recognised. Thus, people&apos;s ability to recognise phonemes tells us very little about the nature of the representation used to initiate lexical access. Better (but still indirect) evidence comes from mispronunciation monitoring and phoneme confusion experiments (Cole, 1973; Miller &amp; Nicely, 1955; Sheperd, 1972) which suggest that listeners are likely to confuse or conflate phonemes along the dimensions predicted by distinctive feature theory. Most errors result in reporting phonemes which differ in only one feature from the target, This result suggests that listeners are actively considering detailed phonetic information along a number of dimensions (rather than simply, say, manner of articulation). Theoretical and experimental considerations suggest then that, regardless of the current capabilities of automated acoustic-phonetic front-ends, systems must be developed to extract as phonetically detai</context>
</contexts>
<marker>Sheperd, 1972</marker>
<rawString>Sheperd, R. (1972) Psychological representation of speech sounds. In David, E. &amp; Denes, P. Human Cormnunication: A Unified View, New York: McGrawHill.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D</author>
<author>V Zue</author>
</authors>
<title>Properties of large lexicons: implications for advanced isolated word recognition systems.</title>
<date>1982</date>
<journal>IEEE ICASSP, Paris,</journal>
<pages>546--549</pages>
<marker>D, Zue, 1982</marker>
<rawString>Shipman. D. &amp; Zue, V. (1982). Properties of large lexicons: implications for advanced isolated word recognition systems. IEEE ICASSP, Paris, 546-549.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Wiese</author>
</authors>
<title>The role of phonology in speech processing.</title>
<date>1986</date>
<booktitle>Proc. of 11th Int. Conf. on Computational Linguistics,</booktitle>
<pages>608--11</pages>
<location>Bonn,</location>
<contexts>
<context position="4130" citStr="Wiese, 1986" startWordPosition="614" endWordPosition="615">ffective for isolated word recognition of small vocabularies with the system trained to an individual speaker, as, for example, Zue &amp; Huttenlocher (1983) argue. Furthermore, any direct access model of this type which does not incorporate a pre-lexical symbolic representation of the input will have difficulty capturing many rule-governed phonological processes which affect the pronunciation of words in fluent speech, since these processes can only be characterised adequately in terms of operations on a symbolic, phonological representation of the speech input (e.g. Church, 1987; Frazier, 1987; Wiese, 1986). The research reported here forms part of an ongoing programme to develop a computationally explicit account of lexical access and word recognition in connected speech, which is at least informed by experimental results concerning the psychological processes and mechanisms which underlie this task. To guide research, we make use of a substantial lexical database of English derived from machine-readable versions of the Longman Dictionary of Contemporary English (see Boguraev at aL, 1987; Boguraev &amp; Briscoe, 1989) and of the Medical Research Council&apos;s psycholinguistic database (Wilson, 1988), w</context>
</contexts>
<marker>Wiese, 1986</marker>
<rawString>Wiese, R. (1986). The role of phonology in speech processing. Proc. of 11th Int. Conf. on Computational Linguistics, Bonn, pp. 608-11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Wilson</author>
</authors>
<title>MRC psycholinguistic database: machine-usable dictionary, version 2.0</title>
<date>1988</date>
<journal>Behaviour Research Methods, Instrumentation &amp; Computers,</journal>
<volume>20</volume>
<pages>6--10</pages>
<contexts>
<context position="4727" citStr="Wilson, 1988" startWordPosition="700" endWordPosition="701">87; Wiese, 1986). The research reported here forms part of an ongoing programme to develop a computationally explicit account of lexical access and word recognition in connected speech, which is at least informed by experimental results concerning the psychological processes and mechanisms which underlie this task. To guide research, we make use of a substantial lexical database of English derived from machine-readable versions of the Longman Dictionary of Contemporary English (see Boguraev at aL, 1987; Boguraev &amp; Briscoe, 1989) and of the Medical Research Council&apos;s psycholinguistic database (Wilson, 1988), which incorporates word frequency information. This specialised database system provides flexible and powerful querying facilities into a database of approximately 30,000 English word forms (with 60,000 separate entries). The querying facilities can be used to explore the lexical structure of English and simulate different approaches to lexical access and word recognition. Previous work in this area has often relied on small illustrative lexicons which tends to lead to overestimation of the effectiveness of various approaches. There are two broad questions to ask concerning the process of le</context>
</contexts>
<marker>Wilson, 1988</marker>
<rawString>Wilson, M. (1988). MRC psycholinguistic database: machine-usable dictionary, version 2.0 Behaviour Research Methods, Instrumentation &amp; Computers, 20, 6-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Zue</author>
<author>D Huttenlocher</author>
</authors>
<title>Computer recognition of isolated words from large vocabularies.</title>
<date>1983</date>
<booktitle>IEEE Conference on Trends and Applications.</booktitle>
<contexts>
<context position="3671" citStr="Zue &amp; Huttenlocher (1983)" startWordPosition="547" endWordPosition="550">m the cohort. The bulk of engineering systems for speech recognition have finessed the issues of lexical access and word recognition by attempting to map directly from the acoustic signal to candidate words by pairing words with acoustic representations of the canonical pronunciation of the word in the lexicon and employing pattern-matching, best-fit techniques to select the most likely candidate (e.g. Sakoe &amp; Chiba, 1971). However, these techniques have only proved effective for isolated word recognition of small vocabularies with the system trained to an individual speaker, as, for example, Zue &amp; Huttenlocher (1983) argue. Furthermore, any direct access model of this type which does not incorporate a pre-lexical symbolic representation of the input will have difficulty capturing many rule-governed phonological processes which affect the pronunciation of words in fluent speech, since these processes can only be characterised adequately in terms of operations on a symbolic, phonological representation of the speech input (e.g. Church, 1987; Frazier, 1987; Wiese, 1986). The research reported here forms part of an ongoing programme to develop a computationally explicit account of lexical access and word reco</context>
</contexts>
<marker>Zue, Huttenlocher, 1983</marker>
<rawString>Zue, V. &amp; Huttenlocher, D. (1983). Computer recognition of isolated words from large vocabularies. IEEE Conference on Trends and Applications.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>