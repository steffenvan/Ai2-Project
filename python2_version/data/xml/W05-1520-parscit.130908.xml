<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.003557">
<title confidence="0.986464">
Statistical Shallow Semantic Parsing despite Little Training Data
</title>
<author confidence="0.938349">
Rahul Bhagat
</author>
<affiliation confidence="0.9475055">
Information Sciences
Institute
University of Southern
California
</affiliation>
<address confidence="0.5553015">
Marina del Rey,
CA, 90292, USA
</address>
<email confidence="0.996325">
rahul@isi.edu
</email>
<author confidence="0.92481">
Anton Leuski
</author>
<affiliation confidence="0.9548855">
Institute for Creative
Technologies
University of Southern
California
</affiliation>
<address confidence="0.553625">
Marina del Rey,
CA, 90292, USA
</address>
<email confidence="0.993459">
leuski@ict.usc.edu
</email>
<author confidence="0.820145">
Eduard Hovy
</author>
<affiliation confidence="0.902214">
Information Sciences
Institute
University of Southern
California
</affiliation>
<address confidence="0.554177">
Marina del Rey,
CA, 90292, USA
</address>
<email confidence="0.996636">
hovy@isi.edu
</email>
<sectionHeader confidence="0.996982" genericHeader="abstract">
1 Introduction and Related Work
</sectionHeader>
<bodyText confidence="0.99999396875">
Natural language understanding is an essential mod-
ule in any dialogue system. To obtain satisfac-
tory performance levels, a dialogue system needs
a semantic parser/natural language understanding
system (NLU) that produces accurate and detailed
dialogue oriented semantic output. Recently, a
number of semantic parsers trained using either
the FrameNet (Baker et al., 1998) or the Prop-
Bank (Kingsbury et al., 2002) have been reported.
Despite their reasonable performances on general
tasks, these parsers do not work so well in spe-
cific domains. Also, where these general purpose
parsers tend to provide case-frame structures, that
include the standard core case roles (Agent, Patient,
Instrument, etc.), dialogue oriented domains tend
to require additional information about addressees,
modality, speech acts, etc. Where general-purpose
resources such as PropBank and Framenet provide
invaluable training data for general case, it tends to
be a problem to obtain enough training data in a spe-
cific dialogue oriented domain.
We in this paper propose and compare a num-
ber of approaches for building a statistically trained
domain specific parser/NLU for a dialogue system.
Our NLU is a part of Mission Rehearsal Exercise
(MRE) project (Swartout et al., 2001). MRE is a
large system that is being built to train experts, in
which a trainee interacts with a Virtual Human using
voice input. The purpose of our NLU is to convert
the sentence strings produced by the speech recog-
nizer into internal shallow semantic frames com-
posed of slot-value pairs, for the dialogue module.
</bodyText>
<sectionHeader confidence="0.998069" genericHeader="keywords">
2 Parsing Methods
</sectionHeader>
<subsectionHeader confidence="0.854023">
2.1 Voting Model
</subsectionHeader>
<bodyText confidence="0.9999493">
We use a simple conditional probability model
P(f I W) for parsing. The model represents the
probability of producing slot-value pair f as an out-
put given that we have seen a particular word or
n-gram W as input. Our two-stage procedure for
generating a frame for a given input sentence is: (1)
Find a set of all slot-value that correspond with each
word/ngram (2) Select the top portion of these can-
didates to form the final frame (Bhagat et al., 2005;
Feng and Hovy, 2003).
</bodyText>
<subsectionHeader confidence="0.99769">
2.2 Maximum Entropy
</subsectionHeader>
<bodyText confidence="0.999887">
Our next approach is the Maximum Entropy (Berger
et al., 1996) classification approach. Here, we cast
our problem as a problem of ranking using a classi-
fier where each slot-value pair in the training data is
considered a class and feature set consists of the un-
igrams, bigrams and trigrams in the sentences (Bha-
gat et al., 2005).
</bodyText>
<subsectionHeader confidence="0.999354">
2.3 Support Vector Machines
</subsectionHeader>
<bodyText confidence="0.99990575">
We use another commonly used classifier, Support
Vector Machine (Burges, 1998), to perform the
same task (Bhagat et al., 2005). Approach is sim-
ilar to Section 2.2.
</bodyText>
<subsectionHeader confidence="0.893715">
2.4 Language Model
</subsectionHeader>
<bodyText confidence="0.99996375">
As a fourth approach to the problem, we use the Sta-
tistical Language Model (Ponte and Croft, 1997).
We estimate the language model for the slot-value
pairs, then we construct our target interpretation as
</bodyText>
<page confidence="0.966773">
186
</page>
<note confidence="0.552937">
Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 186–187,
</note>
<table confidence="0.939991">
Vancouver, October 2005. c�2005 Association for Computational Linguistics
Method Precison Recall F-score
Voting 0.82 0.78 0.80
ME 0.77 0.80 0.78
SVM 0.79 0.72 0.75
LM1 0.80 0.84 0.82
LM2 0.82 0.84 0.83
</table>
<tableCaption confidence="0.7938484">
Table 1: Performance of different systems on test
data.
a set of the most likely slot-value pairs. We use
unigram-based and trigram-based language mod-
els (Bhagat et al., 2005).
</tableCaption>
<sectionHeader confidence="0.996459" genericHeader="introduction">
3 Experiments and Results
</sectionHeader>
<bodyText confidence="0.999934857142857">
We train all our systems on a training set of 477
sentence-frame pairs. The systems are then tested on
an unseen test set of 50 sentences. For the test sen-
tences, the system generated frames are compared
against the manually built gold standard frames, and
Precision, Recall and F-scores are calculated for
each frame.
Table 1 shows the average Precision, Recall and
F-scores of the different systems for the 50 test sen-
tences: Voting based (Voting), Maximum Entropy
based (ME), Support Vector Machine based (SVM),
Language Model based with unigrams (LM1) and
Language Model based with trigrams (LM2). The
F-scores show that the LM2 system performs the
best though the system scores in general for all the
systems are very close. To test the statistical signifi-
cance of these scores, we conduct a two-tailed paired
Student’s t test (Manning and Schtze, 1999) on the
F-scores of these systems for the 50 test cases. The
test shows that there is no statistically significant dif-
ference in their performances.
</bodyText>
<sectionHeader confidence="0.99812" genericHeader="method">
4 Conclusions
</sectionHeader>
<bodyText confidence="0.999912375">
This work illustrates that one can achieve fair suc-
cess in building a statistical NLU engine for a re-
stricted domain using relatively little training data
and surprisingly using a rather simple voting model.
The consistently good results obtained from all the
systems on the task clearly indicate the feasibility of
using using only word/ngram level features for pars-
ing.
</bodyText>
<sectionHeader confidence="0.996454" genericHeader="method">
5 Future Work
</sectionHeader>
<bodyText confidence="0.99999472">
Having successfully met the initial challenge of
building a statistical NLU with limited training data,
we have identified multiple avenues for further ex-
ploration. Firstly, we wish to build an hybrid system
that will combine the strengths of all the systems to
produce a much more accurate system. Secondly,
we wish to see the effect that ASR output has on
each of the systems. We want to test the robustness
of systems against an increase in the ASR word er-
ror rate. Thirdly, we want to build a multi-clause
utterance chunker to integrate with our systems. We
have identified that complex multi-clause utterances
have consistently hurt the system performances. To
handle this, we are making efforts along with our
colleagues in the speech community to build a real-
time speech utterance-chunker. We are eager to dis-
cover any performance benefits. Finally, since we
already have a corpus containing sentence and their
corresponding semantic-frames, we want to explore
the possibility of building a Statistical Generator us-
ing the same corpus that would take a frame as input
and produce a sentence as output. This would take
us a step closer to the idea of building a Reversible
System that can act as a parser when used in one
direction and as a generator when used in the other.
</bodyText>
<sectionHeader confidence="0.998588" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99973804">
Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The berkeley
framenet project. In Proceedings of COLING/ACL, page 8690, Montreal,
Canada.
Adam L. Berger, Stephen Della Pietra, and Vincent J. Della Pietra. 1996. A
maximum entropy approach to natural language processing. Computational
Linguistics, 22(1):39–71.
Rahul Bhagat, Anton Leuski, and Eduard Hovy. 2005. Statistical shallow
semantic parsing despite little training data. Technical report available at
http://www.isi.edu/˜rahul.
Christopher J. C. Burges. 1998. A tutorial on support vector machines for pattern
recognition. Data Mining and Knowledge Discovery, 2(2):121–167.
Donghui Feng and Eduard Hovy. 2003. Semantics-oriented language understand-
ing with automatic adaptability. In Proceedings ofNatural Language Process-
ing and Knowledge Engineering.
Paul Kingsbury, Martha Palmer, and Mitch Marcus. 2002. Adding semantic an-
notation to the penn treebank. In Proceedings of HLT Conference.
Christopher D. Manning and Hinrich Schtze. 1999. Foundations of Statistical
Natural Language Processing. The MIT Press, Cambridge, MA.
Jay M. Ponte and W. Bruce Croft. 1997. Text segmentation by topic. In Proceed-
ings of the First European Conference on Research and Advanced Technology
for Digital Libraries, pages 120–129.
W. Swartout, R. Hill, J. Gratch, W. Johnson, C. Kyriakakis, C. LaBore, R. Lind-
heim, S. Marsella, D. Miraglia, B. Moore, J. Morie, J. Rickel, M. Thiebaux,
L. Tuch, R. Whitney, and J. Douglas. 2001. Toward the holodeck: Integrating
graphics, sound, character and story. In Proceedings ofAutonomous Agents.
</reference>
<page confidence="0.997929">
187
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.151661">
<title confidence="0.992372">Statistical Shallow Semantic Parsing despite Little Training Data</title>
<author confidence="0.620812">Rahul</author>
<affiliation confidence="0.9104355">Information University of</affiliation>
<author confidence="0.869777">Marina del</author>
<address confidence="0.909814">CA, 90292,</address>
<email confidence="0.999517">rahul@isi.edu</email>
<author confidence="0.86424">Anton</author>
<affiliation confidence="0.9942785">Institute for University of</affiliation>
<author confidence="0.86242">Marina del</author>
<address confidence="0.905639">CA, 90292,</address>
<email confidence="0.999524">leuski@ict.usc.edu</email>
<author confidence="0.66233">Eduard</author>
<affiliation confidence="0.9692885">Information University of</affiliation>
<author confidence="0.86488">Marina del</author>
<address confidence="0.897986">CA, 90292,</address>
<email confidence="0.967126">hovy@isi.edu</email>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Collin F Baker</author>
<author>Charles J Fillmore</author>
<author>John B Lowe</author>
</authors>
<title>The berkeley framenet project.</title>
<date>1998</date>
<booktitle>In Proceedings of COLING/ACL,</booktitle>
<pages>8690</pages>
<location>Montreal, Canada.</location>
<contexts>
<context position="846" citStr="Baker et al., 1998" startWordPosition="111" endWordPosition="114">chnologies University of Southern California Marina del Rey, CA, 90292, USA leuski@ict.usc.edu Eduard Hovy Information Sciences Institute University of Southern California Marina del Rey, CA, 90292, USA hovy@isi.edu 1 Introduction and Related Work Natural language understanding is an essential module in any dialogue system. To obtain satisfactory performance levels, a dialogue system needs a semantic parser/natural language understanding system (NLU) that produces accurate and detailed dialogue oriented semantic output. Recently, a number of semantic parsers trained using either the FrameNet (Baker et al., 1998) or the PropBank (Kingsbury et al., 2002) have been reported. Despite their reasonable performances on general tasks, these parsers do not work so well in specific domains. Also, where these general purpose parsers tend to provide case-frame structures, that include the standard core case roles (Agent, Patient, Instrument, etc.), dialogue oriented domains tend to require additional information about addressees, modality, speech acts, etc. Where general-purpose resources such as PropBank and Framenet provide invaluable training data for general case, it tends to be a problem to obtain enough tr</context>
</contexts>
<marker>Baker, Fillmore, Lowe, 1998</marker>
<rawString>Collin F. Baker, Charles J. Fillmore, and John B. Lowe. 1998. The berkeley framenet project. In Proceedings of COLING/ACL, page 8690, Montreal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam L Berger</author>
<author>Stephen Della Pietra</author>
<author>Vincent J Della Pietra</author>
</authors>
<title>A maximum entropy approach to natural language processing.</title>
<date>1996</date>
<journal>Computational Linguistics,</journal>
<volume>22</volume>
<issue>1</issue>
<contexts>
<context position="2639" citStr="Berger et al., 1996" startWordPosition="409" endWordPosition="412">, for the dialogue module. 2 Parsing Methods 2.1 Voting Model We use a simple conditional probability model P(f I W) for parsing. The model represents the probability of producing slot-value pair f as an output given that we have seen a particular word or n-gram W as input. Our two-stage procedure for generating a frame for a given input sentence is: (1) Find a set of all slot-value that correspond with each word/ngram (2) Select the top portion of these candidates to form the final frame (Bhagat et al., 2005; Feng and Hovy, 2003). 2.2 Maximum Entropy Our next approach is the Maximum Entropy (Berger et al., 1996) classification approach. Here, we cast our problem as a problem of ranking using a classifier where each slot-value pair in the training data is considered a class and feature set consists of the unigrams, bigrams and trigrams in the sentences (Bhagat et al., 2005). 2.3 Support Vector Machines We use another commonly used classifier, Support Vector Machine (Burges, 1998), to perform the same task (Bhagat et al., 2005). Approach is similar to Section 2.2. 2.4 Language Model As a fourth approach to the problem, we use the Statistical Language Model (Ponte and Croft, 1997). We estimate the langu</context>
</contexts>
<marker>Berger, Pietra, Pietra, 1996</marker>
<rawString>Adam L. Berger, Stephen Della Pietra, and Vincent J. Della Pietra. 1996. A maximum entropy approach to natural language processing. Computational Linguistics, 22(1):39–71.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rahul Bhagat</author>
<author>Anton Leuski</author>
<author>Eduard Hovy</author>
</authors>
<title>Statistical shallow semantic parsing despite little training data. Technical report available at http://www.isi.edu/˜rahul.</title>
<date>2005</date>
<contexts>
<context position="2533" citStr="Bhagat et al., 2005" startWordPosition="391" endWordPosition="394">ings produced by the speech recognizer into internal shallow semantic frames composed of slot-value pairs, for the dialogue module. 2 Parsing Methods 2.1 Voting Model We use a simple conditional probability model P(f I W) for parsing. The model represents the probability of producing slot-value pair f as an output given that we have seen a particular word or n-gram W as input. Our two-stage procedure for generating a frame for a given input sentence is: (1) Find a set of all slot-value that correspond with each word/ngram (2) Select the top portion of these candidates to form the final frame (Bhagat et al., 2005; Feng and Hovy, 2003). 2.2 Maximum Entropy Our next approach is the Maximum Entropy (Berger et al., 1996) classification approach. Here, we cast our problem as a problem of ranking using a classifier where each slot-value pair in the training data is considered a class and feature set consists of the unigrams, bigrams and trigrams in the sentences (Bhagat et al., 2005). 2.3 Support Vector Machines We use another commonly used classifier, Support Vector Machine (Burges, 1998), to perform the same task (Bhagat et al., 2005). Approach is similar to Section 2.2. 2.4 Language Model As a fourth app</context>
<context position="3798" citStr="Bhagat et al., 2005" startWordPosition="598" endWordPosition="601">Language Model (Ponte and Croft, 1997). We estimate the language model for the slot-value pairs, then we construct our target interpretation as 186 Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 186–187, Vancouver, October 2005. c�2005 Association for Computational Linguistics Method Precison Recall F-score Voting 0.82 0.78 0.80 ME 0.77 0.80 0.78 SVM 0.79 0.72 0.75 LM1 0.80 0.84 0.82 LM2 0.82 0.84 0.83 Table 1: Performance of different systems on test data. a set of the most likely slot-value pairs. We use unigram-based and trigram-based language models (Bhagat et al., 2005). 3 Experiments and Results We train all our systems on a training set of 477 sentence-frame pairs. The systems are then tested on an unseen test set of 50 sentences. For the test sentences, the system generated frames are compared against the manually built gold standard frames, and Precision, Recall and F-scores are calculated for each frame. Table 1 shows the average Precision, Recall and F-scores of the different systems for the 50 test sentences: Voting based (Voting), Maximum Entropy based (ME), Support Vector Machine based (SVM), Language Model based with unigrams (LM1) and Language Mod</context>
</contexts>
<marker>Bhagat, Leuski, Hovy, 2005</marker>
<rawString>Rahul Bhagat, Anton Leuski, and Eduard Hovy. 2005. Statistical shallow semantic parsing despite little training data. Technical report available at http://www.isi.edu/˜rahul.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher J C Burges</author>
</authors>
<title>A tutorial on support vector machines for pattern recognition.</title>
<date>1998</date>
<journal>Data Mining and Knowledge Discovery,</journal>
<volume>2</volume>
<issue>2</issue>
<contexts>
<context position="3013" citStr="Burges, 1998" startWordPosition="473" endWordPosition="474">alue that correspond with each word/ngram (2) Select the top portion of these candidates to form the final frame (Bhagat et al., 2005; Feng and Hovy, 2003). 2.2 Maximum Entropy Our next approach is the Maximum Entropy (Berger et al., 1996) classification approach. Here, we cast our problem as a problem of ranking using a classifier where each slot-value pair in the training data is considered a class and feature set consists of the unigrams, bigrams and trigrams in the sentences (Bhagat et al., 2005). 2.3 Support Vector Machines We use another commonly used classifier, Support Vector Machine (Burges, 1998), to perform the same task (Bhagat et al., 2005). Approach is similar to Section 2.2. 2.4 Language Model As a fourth approach to the problem, we use the Statistical Language Model (Ponte and Croft, 1997). We estimate the language model for the slot-value pairs, then we construct our target interpretation as 186 Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 186–187, Vancouver, October 2005. c�2005 Association for Computational Linguistics Method Precison Recall F-score Voting 0.82 0.78 0.80 ME 0.77 0.80 0.78 SVM 0.79 0.72 0.75 LM1 0.80 0.84 0.82 LM2 0.82 </context>
</contexts>
<marker>Burges, 1998</marker>
<rawString>Christopher J. C. Burges. 1998. A tutorial on support vector machines for pattern recognition. Data Mining and Knowledge Discovery, 2(2):121–167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donghui Feng</author>
<author>Eduard Hovy</author>
</authors>
<title>Semantics-oriented language understanding with automatic adaptability.</title>
<date>2003</date>
<booktitle>In Proceedings ofNatural Language Processing and Knowledge Engineering.</booktitle>
<contexts>
<context position="2555" citStr="Feng and Hovy, 2003" startWordPosition="395" endWordPosition="398">speech recognizer into internal shallow semantic frames composed of slot-value pairs, for the dialogue module. 2 Parsing Methods 2.1 Voting Model We use a simple conditional probability model P(f I W) for parsing. The model represents the probability of producing slot-value pair f as an output given that we have seen a particular word or n-gram W as input. Our two-stage procedure for generating a frame for a given input sentence is: (1) Find a set of all slot-value that correspond with each word/ngram (2) Select the top portion of these candidates to form the final frame (Bhagat et al., 2005; Feng and Hovy, 2003). 2.2 Maximum Entropy Our next approach is the Maximum Entropy (Berger et al., 1996) classification approach. Here, we cast our problem as a problem of ranking using a classifier where each slot-value pair in the training data is considered a class and feature set consists of the unigrams, bigrams and trigrams in the sentences (Bhagat et al., 2005). 2.3 Support Vector Machines We use another commonly used classifier, Support Vector Machine (Burges, 1998), to perform the same task (Bhagat et al., 2005). Approach is similar to Section 2.2. 2.4 Language Model As a fourth approach to the problem, </context>
</contexts>
<marker>Feng, Hovy, 2003</marker>
<rawString>Donghui Feng and Eduard Hovy. 2003. Semantics-oriented language understanding with automatic adaptability. In Proceedings ofNatural Language Processing and Knowledge Engineering.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Kingsbury</author>
<author>Martha Palmer</author>
<author>Mitch Marcus</author>
</authors>
<title>Adding semantic annotation to the penn treebank.</title>
<date>2002</date>
<booktitle>In Proceedings of HLT Conference.</booktitle>
<contexts>
<context position="887" citStr="Kingsbury et al., 2002" startWordPosition="119" endWordPosition="122">ifornia Marina del Rey, CA, 90292, USA leuski@ict.usc.edu Eduard Hovy Information Sciences Institute University of Southern California Marina del Rey, CA, 90292, USA hovy@isi.edu 1 Introduction and Related Work Natural language understanding is an essential module in any dialogue system. To obtain satisfactory performance levels, a dialogue system needs a semantic parser/natural language understanding system (NLU) that produces accurate and detailed dialogue oriented semantic output. Recently, a number of semantic parsers trained using either the FrameNet (Baker et al., 1998) or the PropBank (Kingsbury et al., 2002) have been reported. Despite their reasonable performances on general tasks, these parsers do not work so well in specific domains. Also, where these general purpose parsers tend to provide case-frame structures, that include the standard core case roles (Agent, Patient, Instrument, etc.), dialogue oriented domains tend to require additional information about addressees, modality, speech acts, etc. Where general-purpose resources such as PropBank and Framenet provide invaluable training data for general case, it tends to be a problem to obtain enough training data in a specific dialogue orient</context>
</contexts>
<marker>Kingsbury, Palmer, Marcus, 2002</marker>
<rawString>Paul Kingsbury, Martha Palmer, and Mitch Marcus. 2002. Adding semantic annotation to the penn treebank. In Proceedings of HLT Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher D Manning</author>
<author>Hinrich Schtze</author>
</authors>
<title>Foundations of Statistical Natural Language Processing.</title>
<date>1999</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="4684" citStr="Manning and Schtze, 1999" startWordPosition="744" endWordPosition="747">ld standard frames, and Precision, Recall and F-scores are calculated for each frame. Table 1 shows the average Precision, Recall and F-scores of the different systems for the 50 test sentences: Voting based (Voting), Maximum Entropy based (ME), Support Vector Machine based (SVM), Language Model based with unigrams (LM1) and Language Model based with trigrams (LM2). The F-scores show that the LM2 system performs the best though the system scores in general for all the systems are very close. To test the statistical significance of these scores, we conduct a two-tailed paired Student’s t test (Manning and Schtze, 1999) on the F-scores of these systems for the 50 test cases. The test shows that there is no statistically significant difference in their performances. 4 Conclusions This work illustrates that one can achieve fair success in building a statistical NLU engine for a restricted domain using relatively little training data and surprisingly using a rather simple voting model. The consistently good results obtained from all the systems on the task clearly indicate the feasibility of using using only word/ngram level features for parsing. 5 Future Work Having successfully met the initial challenge of bu</context>
</contexts>
<marker>Manning, Schtze, 1999</marker>
<rawString>Christopher D. Manning and Hinrich Schtze. 1999. Foundations of Statistical Natural Language Processing. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jay M Ponte</author>
<author>W Bruce Croft</author>
</authors>
<title>Text segmentation by topic.</title>
<date>1997</date>
<booktitle>In Proceedings of the First European Conference on Research and Advanced Technology for Digital Libraries,</booktitle>
<pages>120--129</pages>
<contexts>
<context position="3216" citStr="Ponte and Croft, 1997" startWordPosition="508" endWordPosition="511"> is the Maximum Entropy (Berger et al., 1996) classification approach. Here, we cast our problem as a problem of ranking using a classifier where each slot-value pair in the training data is considered a class and feature set consists of the unigrams, bigrams and trigrams in the sentences (Bhagat et al., 2005). 2.3 Support Vector Machines We use another commonly used classifier, Support Vector Machine (Burges, 1998), to perform the same task (Bhagat et al., 2005). Approach is similar to Section 2.2. 2.4 Language Model As a fourth approach to the problem, we use the Statistical Language Model (Ponte and Croft, 1997). We estimate the language model for the slot-value pairs, then we construct our target interpretation as 186 Proceedings of the Ninth International Workshop on Parsing Technologies (IWPT), pages 186–187, Vancouver, October 2005. c�2005 Association for Computational Linguistics Method Precison Recall F-score Voting 0.82 0.78 0.80 ME 0.77 0.80 0.78 SVM 0.79 0.72 0.75 LM1 0.80 0.84 0.82 LM2 0.82 0.84 0.83 Table 1: Performance of different systems on test data. a set of the most likely slot-value pairs. We use unigram-based and trigram-based language models (Bhagat et al., 2005). 3 Experiments an</context>
</contexts>
<marker>Ponte, Croft, 1997</marker>
<rawString>Jay M. Ponte and W. Bruce Croft. 1997. Text segmentation by topic. In Proceedings of the First European Conference on Research and Advanced Technology for Digital Libraries, pages 120–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Swartout</author>
<author>R Hill</author>
<author>J Gratch</author>
<author>W Johnson</author>
<author>C Kyriakakis</author>
<author>C LaBore</author>
<author>R Lindheim</author>
<author>S Marsella</author>
<author>D Miraglia</author>
<author>B Moore</author>
<author>J Morie</author>
<author>J Rickel</author>
<author>M Thiebaux</author>
<author>L Tuch</author>
<author>R Whitney</author>
<author>J Douglas</author>
</authors>
<title>Toward the holodeck: Integrating graphics, sound, character and story.</title>
<date>2001</date>
<booktitle>In Proceedings ofAutonomous Agents.</booktitle>
<contexts>
<context position="1730" citStr="Swartout et al., 2001" startWordPosition="248" endWordPosition="251">lude the standard core case roles (Agent, Patient, Instrument, etc.), dialogue oriented domains tend to require additional information about addressees, modality, speech acts, etc. Where general-purpose resources such as PropBank and Framenet provide invaluable training data for general case, it tends to be a problem to obtain enough training data in a specific dialogue oriented domain. We in this paper propose and compare a number of approaches for building a statistically trained domain specific parser/NLU for a dialogue system. Our NLU is a part of Mission Rehearsal Exercise (MRE) project (Swartout et al., 2001). MRE is a large system that is being built to train experts, in which a trainee interacts with a Virtual Human using voice input. The purpose of our NLU is to convert the sentence strings produced by the speech recognizer into internal shallow semantic frames composed of slot-value pairs, for the dialogue module. 2 Parsing Methods 2.1 Voting Model We use a simple conditional probability model P(f I W) for parsing. The model represents the probability of producing slot-value pair f as an output given that we have seen a particular word or n-gram W as input. Our two-stage procedure for generati</context>
</contexts>
<marker>Swartout, Hill, Gratch, Johnson, Kyriakakis, LaBore, Lindheim, Marsella, Miraglia, Moore, Morie, Rickel, Thiebaux, Tuch, Whitney, Douglas, 2001</marker>
<rawString>W. Swartout, R. Hill, J. Gratch, W. Johnson, C. Kyriakakis, C. LaBore, R. Lindheim, S. Marsella, D. Miraglia, B. Moore, J. Morie, J. Rickel, M. Thiebaux, L. Tuch, R. Whitney, and J. Douglas. 2001. Toward the holodeck: Integrating graphics, sound, character and story. In Proceedings ofAutonomous Agents.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>