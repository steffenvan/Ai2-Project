<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.002668">
<title confidence="0.973203">
Transliteration Mining with Phonetic Conflation and Iterative Training
</title>
<author confidence="0.997241">
Kareem Darwish
</author>
<affiliation confidence="0.995176">
Cairo Microsoft Innovation Center
</affiliation>
<address confidence="0.605156">
Cairo, Egypt
</address>
<email confidence="0.988215">
kareemd@microsoft.com
</email>
<sectionHeader confidence="0.997277" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999589888888889">
This paper presents transliteration mining on the
ACL 2010 NEWS workshop shared translitera-
tion mining task data. Transliteration mining
was done using a generative transliteration model
applied on the source language and whose output
was constrained on the words in the target lan-
guage. A total of 30 runs were performed on 5
language pairs, with 6 runs for each language
pair. In the presence of limited resources, the
runs explored the use of phonetic conflation and
iterative training of the transliteration model to
improve recall. Using letter conflation improved
recall by as much as 48%, with improvements in
recall dwarfing drops in precision. Using itera-
tive training improved recall, but often at the cost
of significant drops in precision. The best runs
typically used both letter conflation and iterative
learning.
</bodyText>
<sectionHeader confidence="0.99939" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99984168">
Transliteration Mining (TM) is the process of find-
ing transliterated word pairs in parallel or compa-
rable corpora. TM has many potential applications
such as building training data for training translit-
erators and improving lexical coverage for machine
translation and cross language search via transla-
tion resource expansion. TM has been gaining
some attention of late with a shared task in the
ACL 2010 NEWS workshop1. In this paper, TM
was performed using a transliterator that was used
to generate possible transliterations of a word while
constraining the output to tokens that exist in a tar-
get language word sequence. The paper presents
the use of phonetic letter conflation and iterative
transliterator training to improve TM when only
limited transliteration training data is available.
For phonetic letter conflation, a variant of
SOUNDEX (Russell, 1918) was used to improve
the coverage of existing training data. As for itera-
tive transliterator training, an initial transliterator,
which was trained on initial set of transliteration
pairs, was used to mine transliterations in parallel
text. Then, the automatically found transliterations
pairs were considered correct and were used to re-
train the transliterator.
</bodyText>
<footnote confidence="0.74758">
1 http://translit.i2r.a-star.edu.sg/news2010/
</footnote>
<bodyText confidence="0.999027461538461">
The proposed improvements in TM were tested
using the ACL 2010 NEWS workshop data for Ar-
abic, English-Chinese, English-Hindi, English-
Russian, and English-Tamil. For language pair, a
base set of 1,000 transliteration pairs were available
for training.
The rest of the paper is organized as follows: Sec-
tion 2 surveys prior work on transliteration mining;
Section 3 describes the TM approach and the pro-
posed improvements; Section 4 describes the ex-
perimental setup including the evaluation sets; Sec-
tion 5 reports on experimental results; and Section
6 concludes the paper.
</bodyText>
<sectionHeader confidence="0.992854" genericHeader="introduction">
2 Background
</sectionHeader>
<bodyText confidence="0.999502242424242">
Much work has been done on TM for different lan-
guage pairs such as English-Chinese (Kuo et al.,
2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al.
2008;), English-Tamil (Saravanan and Kumaran,
2008; Udupa and Khapra, 2010), English-Korean
(Oh and Isahara, 2006; Oh and Choi, 2006), Eng-
lish-Japanese (Brill et al., 2001; Oh and Isahara,
2006), English-Hindi (Fei et al., 2003; Mahesh and
Sinha, 2009), and English-Russian (Klementiev
and Roth, 2006). The most common approach for
determining letter sequence mapping between two
languages is using automatic letter alignment of a
training set of transliteration pairs. Automatic
alignment can be performed using different algo-
rithms such as the EM algorithm (Kuo et al., 2008;
Lee and Chang, 2003) or using an HMM aligner
(Udupa et al., 2009a; Udupa et al., 2009b). Anoth-
er method is to use automatic speech recognition
confusion tables to extract phonetically equivalent
character sequences to discover monolingual and
cross lingual pronunciation variations (Kuo and
Yang, 2005). Alternatively, letters can be mapped
into a common character set. One example of that
is to use a predefined transliteration scheme to
transliterate a word in one character set into another
character set (Oh and Choi, 2006). Different meth-
ods were proposed to ascertain if two words can be
transliterations of each other. One such way is to
use a generative model that attempts to generate
possible transliterations given the character map-
pings between two character sets (Fei et al., 2003;
Lee and Chang, 2003, Udupa et al., 2009a). A sim-
ilar alternative is to use back-transliteration to de-
</bodyText>
<page confidence="0.992762">
53
</page>
<note confidence="0.6334495">
Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 53–56,
Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics
</note>
<bodyText confidence="0.99988625">
termine if one sequence could have been generated
by successively mapping character sequences from
one language into another (Brill et al., 2001; Bilac
and Tanaka, 2005; Oh and Isahara, 2006). Another
mapping method is to map candidate translitera-
tions into a common representation space (Udupa
et al., 2010). When using a predefined translitera-
tion scheme, edit distance was used to determine if
candidate transliterations were indeed translitera-
tions (Oh and Choi, 2006). Also letter conflation
was used to find transliterations (Mahesh and Sin-
ha, 2009). Different methods were proposed to
improve the recall of mining. For example, Oh and
Choi (2006) used a SOUNDEX like scheme to
minimize the effect of vowels and different
schemes of phonetically coding names.
SOUNDEX is used to convert English words into a
simplified phonetic representation, in which vowels
are removed and phonetically similar characters are
conflated. Another method involved expanding
character sequence maps by automatically mining
transliteration pairs and then aligning these pairs to
generate an expanded set of character sequence
maps (Fei et al., 2003).
</bodyText>
<sectionHeader confidence="0.983567" genericHeader="method">
3 Transliteration Mining
</sectionHeader>
<bodyText confidence="0.992008833333333">
TM proposed in this paper uses a generative trans-
literation model, which is trained on a set of trans-
literation pairs. The training involved automatical-
ly aligning character sequences. SOUNDEX like
letter conflation and iterative transliterator training
was used to improve recall. Akin to phrasal align-
ment in machine translation, character sequence
alignment was treated as a word alignment problem
between parallel sentences, where transliterations
were treated as if they were sentences and the char-
acters from which they were composed were treat-
ed as if they were words. The alignment was per-
formed using a Bayesian learner that trained on
word dependent transition models for HMM based
word alignment (He, 2007). Alignment produced a
mapping of source character sequence to a target
character sequence along with the probability of
source given target.
For all the work reported herein, given an English-
foreign language transliteration candidate pair,
English was treated as the target language and the
foreign language as the source. Given a foreign
source language word sequence Fi and an English
target word sequence El&amp;quot;, Fi E Fi is a potential
transliteration of Ej E El&amp;quot;. Given Fi, composed of
the character sequence f1 ... fo, and Ej, composed of
the character sequence e1 ... ep, P(Fi|Ej) is calculat-
ed using the trained model, as follows:
`Ei |FjJ — n
The non-overlapping segments fx ... fy are generated
by finding all possible 2n-1 segmentations of the
word Fi. For example, given “man” then all pos-
sible segmentations are (m,a,n), (ma,n), (m,an), and
(man). The segmentation producing the highest
probability is chosen. All segment sequences e’k ...
e’l known to produce fx ... fy for each of the possible
segmentations are produced. If a set of non-
overlapping sequences of e’k ... e’l generates the
sequence e1 ... ep (word Ej E El&amp;quot;), then Ej is con-
sidered a transliteration of Fi. If multiple target
words have P(Fi|Ej) &gt; 0, then Ej that maximizes
P(Fi|Ej) is taken as the proper transliteration. A
suffix tree containing El&amp;quot; was used to constrain
generation, improving efficiency. No smoothing
was used.
To improve recall, a variant of SOUNDEX was
used on the English targets. The original
SOUNDEX scheme applies the following rules:
</bodyText>
<listItem confidence="0.999413666666667">
1. Retain the first letter in a word
2. Remove all vowels, H, and W
3. Perform the following mappings:
</listItem>
<equation confidence="0.967895">
B, F, P, V  1 C, G, J, K, Q, S, X, Z  2
Dj  3 L  4
M,N  5 R  6
</equation>
<listItem confidence="0.996595909090909">
4. Trim all result sequences to 4 characters
5. Pad short sequences with zeros to have exactly
4 characters.
SOUNDEX was modified as follows:
1. The first letter in a word was not retained and
was changed according the mapping in step 3
of SOUNDEX.
2. Resultant sequences longer than 4 characters
were not trimmed.
3. Short resultant strings were not padded with
zeros.
</listItem>
<bodyText confidence="0.9762582">
SOUNDEX after the aforementioned modifications
is referred at S-mod. Alignment was performed
between transliteration pairs where English words
were replaced with their S-mod representation.
Case folding was always applied to English.
Iterative transliterator training involved training a
transliterator using an initial seed of transliteration
pairs, which was used to automatically mine trans-
literations from a large set of parallel words se-
quences. Automatically mined transliteration pairs
were assumed to be correct and were used to retrain
the transliterator. S-mod and iterative training were
used in isolation or in combination as is shown in
the next section.
Russian and Arabic were preprocessed as follows:
</bodyText>
<listItem confidence="0.825945666666667">
• Russian: characters were case-folded
• Arabic: the different forms of alef (alef, alef
maad, alef with hamza on top, and alef with
hamza below it) were normalized to alef, ya
and alef maqsoura were normalized to ya, and
ta marbouta was mapped to ha.
</listItem>
<page confidence="0.993962">
54
</page>
<bodyText confidence="0.99990725">
No preprocessing was performed for the other lan-
guages. Since Wikipedia English entries often had
non-English characters, the following letter confla-
tions were performed:
</bodyText>
<equation confidence="0.964008833333333">
ž, ż  z á, â, ä, à, ã, ā, ą, æ  a
é, ę, è  e ć, č, q  c
ł  l ï, í, ì, î  i
ó, ō, ö, õ  o ń, fi, ṅ  n
ş, ś, ß, š  s ř  r
ý  y ū, ü, ix, û  u
</equation>
<table confidence="0.872196333333333">
Language Pair # of Parallel Sequences
English-Arabic 90,926
English-Chinese 196,047
English-Hindi 16,963
English-Russian 345,969
English-Tamil 13,883
</table>
<tableCaption confidence="0.99749">
Table 1: Language pairs and no. of parallel sequences
</tableCaption>
<table confidence="0.997100857142857">
Run Precision Recall F-score
1 0.900 0.796 0.845
2 0.966 0.587 0.730
3 0.952 0.588 0.727
4 0.886 0.817 0.850
5 0.895 0.678 0.771
6 0.818 0.827 0.822
</table>
<tableCaption confidence="0.966182">
Table 2: English-Arabic mining results
</tableCaption>
<figure confidence="0.565017428571429">
Run Precision Recall F-score
1 1.000 0.024 0.047
2 1.000 0.016 0.032
3 1.000 0.016 0.032
4 1.000 0.026 0.050
5 1.000 0.022 0.044
6 1.000 0.030 0.059
</figure>
<tableCaption confidence="0.99719">
Table 3: English-Chinese mining results
</tableCaption>
<table confidence="0.998812285714286">
Run Precision Recall F-score
1 0.959 0.786 0.864
2 0.987 0.559 0.714
3 0.984 0.569 0.721
4 0.951 0.812 0.876
5 0.981 0.687 0.808
6 0.953 0.855 0.902
</table>
<tableCaption confidence="0.991176">
Table 4: English-Hindi mining results
</tableCaption>
<table confidence="0.999360142857143">
Run Precision Recall F-score
1 0.813 0.839 0.826
2 0.868 0.748 0.804
3 0.843 0.747 0.792
4 0.716 0.868 0.785
5 0.771 0.794 0.782
6 0.673 0.881 0.763
</table>
<tableCaption confidence="0.993685">
Table 5: English-Russian mining results
</tableCaption>
<table confidence="0.997074285714286">
Run Precision Recall F-score
1 0.963 0.604 0.743
2 0.976 0.407 0.575
3 0.975 0.446 0.612
4 0.952 0.668 0.785
5 0.968 0.567 0.715
6 0.939 0.741 0.828
</table>
<tableCaption confidence="0.99916">
Table 6: English-Tamil mining results
</tableCaption>
<bodyText confidence="0.9970232">
For each foreign language (F) and English (E) pair,
a set of 6 runs were performed. The first two runs
involved training a transliterator using the 1,000
transliteration pairs and using it for TM as in sec-
tion 3. The runs were:
</bodyText>
<equation confidence="0.3088905">
Run 1: align F with S-mod(E)
Run 2: align F with E
</equation>
<bodyText confidence="0.734782">
The four other runs involved iterative training in
which all automatically mined transliterations from
Runs 1 and 2 were considered correct, and were
used to retrain the transliterator. The runs were:
Run 3: Use Run 2 output, align F with E
Run 4: Use Run 2 output, align F with S-mod(E)
Run 5: Use Run 1 output, align F with E
Run 6: Use Run 1 output, align F with S-mod(E)
For evaluation, the system would mine translitera-
tions and a set of 1,000 parallel sequences were
chosen randomly for evaluation. The figures of
merit are precision, recall, F1 measure.
</bodyText>
<sectionHeader confidence="0.998227" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<bodyText confidence="0.9999867">
The experiments were done on the ACL-2010
NEWS Workshop TM shared task datasets. The
datasets cover 5 language pairs. For each pair, a
dataset includes a list of 1,000 transliterated words
to train a transliterator, and list of parallel word
sequences between both languages. The parallel
sequences were extracted parallel Wikipedia article
titles for which cross language links exist between
both languages. Table 1 lists the language pairs
and the number of the parallel word sequences.
</bodyText>
<sectionHeader confidence="0.991984" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999841782608696">
Tables 2, 3, 4, 5, and 6 report results for Arabic,
Chinese, Hindi, Russian and Tamil respectively.
As shown in Table 3, the recall for English-Chinese
TM was dismal and suggests problems in experi-
mental setup. This would require further investiga-
tion. For the other 4 languages, the results show
that not using S-mod and not using iterative train-
ing, as in Run 2, led to the highest precision. Using
both S-mod and iterative training, as in Run 6, led
to the highest recall.
In comparing Runs 1 and 2, where 1 uses S-mod
and 2 does not, using S-mod led to 35.6%, 40.6%,
12.2%, and 48.4% improvement in recall and to
6.8%, 2.8%, 6.3%, and 1.3% decline in precision
for Arabic, Chinese, Russian, and Tamil respective-
ly. Except for Russian, the improvements in recall
dwarf decline in precision, leading to overall im-
provements in F-measure for all 4 languages.
In comparing runs 2 and 3 where iterative training
is used, iterative training had marginal impact on
precision and recall. When using S-mod, compar-
ing run 6 where iterative training was performed
over the output from run 1, recall increased by
</bodyText>
<page confidence="0.99673">
55
</page>
<bodyText confidence="0.99958575">
3.9%, 8.8%, 5.0%, and 22.7% for Arabic, Chinese,
Russian, and Tamil respectively. The drop in pre-
cision was 9.1% and 17.2% for Arabic and Russian
respectively and marginal for Hindi and Tamil.
Except for Russian, the best runs for all languages
included the use of S-mod and iterative training.
The best runs were 4 for Arabic and Hindi and 6
for Tamil. For Russian, the best runs involved us-
ing S-mod only without iterative training. The
drop in Russian could be attributed to the relatively
large size of training data compared to the other
languages (345,969 parallel word sequences).
</bodyText>
<sectionHeader confidence="0.999341" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999992476190476">
This paper presented two methods for improving
transliteration mining, namely phonetic conflation
of letters and iterative training of a transliteration
model. The methods were tested using on the ACL
2010 NEWS workshop shared transliteration min-
ing task data. Phonetic conflation of letters in-
volved using a SOUNDEX like conflation scheme
for English. This led to much improved recall and
general improvements in F-measure. The iterative
training of the transliteration model led to im-
proved recall, but recall improvements were often
offset by decreases in precision. However, the best
experimental setups typically involved the use of
both improvements.
The success of phonetic conflation for English
may indicate that similar success may be attained if
phonetic conflation is applied to other languages.
Further, the use of smoothing of the transliteration
model may help improve recall. The recall for
transliteration mining between English and Chinese
were dismal and require further investigation.
</bodyText>
<sectionHeader confidence="0.99912" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999815055555556">
Slaven Bilac, Hozumi Tanaka. Extracting transliteration
pairs from comparable corpora. NLP-2005, 2005.
Eric Brill, Gary Kacmarcik, Chris Brockett. Automati-
cally harvesting Katakana-English term pairs from
search engine query logs. NLPRS 2001, pages 393–
399, 2001.
Huang Fei, Stephan Vogel, and Alex Waibel. 2003. Ex-
tracting Named Entity Translingual Equivalence with
Limited Resources. TALIP, 2(2):124–129.
Xiaodong He, 2007. Using Word-Dependent Transition
Models in HMM based Word Alignment for Statisti-
cal Machine Translation. ACL-07 2nd SMT workshop.
Chengguo Jin, Dong-Il Kim, Seung-Hoon Na, Jong-
Hyeok Lee. 2008. Automatic Extraction of English-
Chinese Transliteration Pairs using Dynamic Window
and Tokenizer. Sixth SIGHAN Workshop on Chi-
nese Language Processing, 2008.
Alexandre Klementiev and Dan Roth. 2006. Named En-
tity Transliteration and Discovery from Multilingual
Comparable Corpora. HLT Conf. of the North Ameri-
can Chapter of the ACL, pages 82–88.
Jin-Shea Kuo, Haizhou Li, Ying-Kuei Yang. 2006.
Learning Transliteration Lexicons from the Web.
COLING-ACL2006, Sydney, Australia, 1129 – 1136.
Jin-shea Kuo, Haizhou Li, Ying-kuei Yang. A phonetic
similarity model for automatic extraction of translit-
eration pairs. TALIP, 2007
Jin-Shea Kuo, Haizhou Li, Chih-Lung Lin. 2008. Min-
ing Transliterations from Web Query Results: An In-
cremental Approach. Sixth SIGHAN Workshop on
Chinese Language Processing, 2008.
Jin-shea Kuo, Ying-kuei Yang. 2005. Incorporating
Pronunciation Variation into Extraction of Translit-
erated-term Pairs from Web Corpora. Journal of Chi-
nese Language and Computing, 15 (1): (33-44).
Chun-Jen Lee, Jason S. Chang. Acquisition of English-
Chinese transliterated word pairs from parallel-
aligned texts using a statistical machine transliteration
model. Workshop on Building and Using Parallel
Texts, HLT-NAACL-2003, 2003.
R. Mahesh, K. Sinha. 2009. Automated Mining Of
Names Using Parallel Hindi-English Corpus. 7th
Workshop on Asian Language Resources, ACL-
IJCNLP 2009, pages 48–54, Suntec, Singapore, 2009.
Jong-Hoon Oh, Key-Sun Choi. 2006. Recognizing
transliteration equivalents for enriching domain-
specific thesauri. 3rd Intl. WordNet Conf. (GWC-06),
pages 231–237, 2006.
Jong-Hoon Oh, Hitoshi Isahara. 2006. Mining the Web
for Transliteration Lexicons: Joint-Validation Ap-
proach. pp.254-261, 2006 IEEE/WIC/ACM Intl.
Conf. on Web Intelligence (WI&apos;06), 2006.
Raghavendra Udupa, K. Saravanan, Anton Bakalov, and
Abhijit Bhole. 2009a. &amp;quot;They Are Out There, If You
Know Where to Look&amp;quot;: Mining Transliterations of
OOV Query Terms for Cross-Language Information
Retrieval. ECIR-2009, Toulouse, France, 2009.
Raghavendra Udupa, K. Saravanan, A. Kumaran, and
Jagadeesh Jagarlamudi. 2009b. MINT: A Method
for Effective and Scalable Mining of Named Entity
Transliterations from Large Comparable Corpora.
EACL 2009.
Raghavendra Udupa and Mitesh Khapra. 2010. Trans-
literation Equivalence using Canonical Correlation
Analysis. ECIR-2010, 2010.
Robert Russell. 1918. Specifications of Letters. US
patent number 1,261,167.
K Saravanan, A Kumaran. 2008. Some Experiments in
Mining Named Entity Transliteration Pairs from
Comparable Corpora. The 2nd Intl. Workshop on
Cross Lingual Information Access addressing the
need of multilingual societies, 2008.
</reference>
<page confidence="0.998409">
56
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.465687">
<title confidence="0.999957">Transliteration Mining with Phonetic Conflation and Iterative Training</title>
<author confidence="0.983105">Kareem</author>
<affiliation confidence="0.7432875">Cairo Microsoft Innovation Cairo,</affiliation>
<email confidence="0.999919">kareemd@microsoft.com</email>
<abstract confidence="0.997820315789473">This paper presents transliteration mining on the ACL 2010 NEWS workshop shared transliteration mining task data. Transliteration mining was done using a generative transliteration model applied on the source language and whose output was constrained on the words in the target language. A total of 30 runs were performed on 5 language pairs, with 6 runs for each language pair. In the presence of limited resources, the runs explored the use of phonetic conflation and iterative training of the transliteration model to improve recall. Using letter conflation improved recall by as much as 48%, with improvements in recall dwarfing drops in precision. Using iterative training improved recall, but often at the cost of significant drops in precision. The best runs typically used both letter conflation and iterative learning.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Slaven Bilac</author>
</authors>
<title>Hozumi Tanaka. Extracting transliteration pairs from comparable corpora. NLP-2005,</title>
<date>2005</date>
<marker>Bilac, 2005</marker>
<rawString>Slaven Bilac, Hozumi Tanaka. Extracting transliteration pairs from comparable corpora. NLP-2005, 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Brill</author>
<author>Gary Kacmarcik</author>
<author>Chris Brockett</author>
</authors>
<title>Automatically harvesting Katakana-English term pairs from search engine query logs. NLPRS</title>
<date>2001</date>
<pages>393--399</pages>
<contexts>
<context position="3186" citStr="Brill et al., 2001" startWordPosition="483" endWordPosition="486"> follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion tables to extract phonetically equivalen</context>
<context position="4788" citStr="Brill et al., 2001" startWordPosition="733" endWordPosition="736">two words can be transliterations of each other. One such way is to use a generative model that attempts to generate possible transliterations given the character mappings between two character sets (Fei et al., 2003; Lee and Chang, 2003, Udupa et al., 2009a). A similar alternative is to use back-transliteration to de53 Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 53–56, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics termine if one sequence could have been generated by successively mapping character sequences from one language into another (Brill et al., 2001; Bilac and Tanaka, 2005; Oh and Isahara, 2006). Another mapping method is to map candidate transliterations into a common representation space (Udupa et al., 2010). When using a predefined transliteration scheme, edit distance was used to determine if candidate transliterations were indeed transliterations (Oh and Choi, 2006). Also letter conflation was used to find transliterations (Mahesh and Sinha, 2009). Different methods were proposed to improve the recall of mining. For example, Oh and Choi (2006) used a SOUNDEX like scheme to minimize the effect of vowels and different schemes of phone</context>
</contexts>
<marker>Brill, Kacmarcik, Brockett, 2001</marker>
<rawString>Eric Brill, Gary Kacmarcik, Chris Brockett. Automatically harvesting Katakana-English term pairs from search engine query logs. NLPRS 2001, pages 393– 399, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Huang Fei</author>
<author>Stephan Vogel</author>
<author>Alex Waibel</author>
</authors>
<title>Extracting Named Entity Translingual Equivalence with Limited Resources.</title>
<date>2003</date>
<journal>TALIP,</journal>
<volume>2</volume>
<issue>2</issue>
<contexts>
<context position="3242" citStr="Fei et al., 2003" startWordPosition="492" endWordPosition="495">mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion tables to extract phonetically equivalent character sequences to discover monolingual and cross </context>
<context position="5780" citStr="Fei et al., 2003" startWordPosition="883" endWordPosition="886">literations (Mahesh and Sinha, 2009). Different methods were proposed to improve the recall of mining. For example, Oh and Choi (2006) used a SOUNDEX like scheme to minimize the effect of vowels and different schemes of phonetically coding names. SOUNDEX is used to convert English words into a simplified phonetic representation, in which vowels are removed and phonetically similar characters are conflated. Another method involved expanding character sequence maps by automatically mining transliteration pairs and then aligning these pairs to generate an expanded set of character sequence maps (Fei et al., 2003). 3 Transliteration Mining TM proposed in this paper uses a generative transliteration model, which is trained on a set of transliteration pairs. The training involved automatically aligning character sequences. SOUNDEX like letter conflation and iterative transliterator training was used to improve recall. Akin to phrasal alignment in machine translation, character sequence alignment was treated as a word alignment problem between parallel sentences, where transliterations were treated as if they were sentences and the characters from which they were composed were treated as if they were word</context>
</contexts>
<marker>Fei, Vogel, Waibel, 2003</marker>
<rawString>Huang Fei, Stephan Vogel, and Alex Waibel. 2003. Extracting Named Entity Translingual Equivalence with Limited Resources. TALIP, 2(2):124–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaodong He</author>
</authors>
<title>Using Word-Dependent Transition Models in HMM based Word Alignment for Statistical Machine Translation.</title>
<date>2007</date>
<booktitle>ACL-07 2nd SMT workshop.</booktitle>
<contexts>
<context position="6524" citStr="He, 2007" startWordPosition="1000" endWordPosition="1001">ion pairs. The training involved automatically aligning character sequences. SOUNDEX like letter conflation and iterative transliterator training was used to improve recall. Akin to phrasal alignment in machine translation, character sequence alignment was treated as a word alignment problem between parallel sentences, where transliterations were treated as if they were sentences and the characters from which they were composed were treated as if they were words. The alignment was performed using a Bayesian learner that trained on word dependent transition models for HMM based word alignment (He, 2007). Alignment produced a mapping of source character sequence to a target character sequence along with the probability of source given target. For all the work reported herein, given an Englishforeign language transliteration candidate pair, English was treated as the target language and the foreign language as the source. Given a foreign source language word sequence Fi and an English target word sequence El&amp;quot;, Fi E Fi is a potential transliteration of Ej E El&amp;quot;. Given Fi, composed of the character sequence f1 ... fo, and Ej, composed of the character sequence e1 ... ep, P(Fi|Ej) is calculated u</context>
</contexts>
<marker>He, 2007</marker>
<rawString>Xiaodong He, 2007. Using Word-Dependent Transition Models in HMM based Word Alignment for Statistical Machine Translation. ACL-07 2nd SMT workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chengguo Jin</author>
<author>Dong-Il Kim</author>
<author>Seung-Hoon Na</author>
<author>JongHyeok Lee</author>
</authors>
<title>Automatic Extraction of EnglishChinese Transliteration Pairs using Dynamic Window and Tokenizer.</title>
<date>2008</date>
<booktitle>Sixth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<contexts>
<context position="3019" citStr="Jin et al. 2008" startWordPosition="459" endWordPosition="462">, EnglishRussian, and English-Tamil. For language pair, a base set of 1,000 transliteration pairs were available for training. The rest of the paper is organized as follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or us</context>
</contexts>
<marker>Jin, Kim, Na, Lee, 2008</marker>
<rawString>Chengguo Jin, Dong-Il Kim, Seung-Hoon Na, JongHyeok Lee. 2008. Automatic Extraction of EnglishChinese Transliteration Pairs using Dynamic Window and Tokenizer. Sixth SIGHAN Workshop on Chinese Language Processing, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alexandre Klementiev</author>
<author>Dan Roth</author>
</authors>
<title>Named Entity Transliteration and Discovery from Multilingual Comparable Corpora.</title>
<date>2006</date>
<booktitle>HLT Conf. of the North American Chapter of the ACL,</booktitle>
<pages>82--88</pages>
<contexts>
<context position="3316" citStr="Klementiev and Roth, 2006" startWordPosition="502" endWordPosition="505">rovements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion tables to extract phonetically equivalent character sequences to discover monolingual and cross lingual pronunciation variations (Kuo and Yang, 2005). Alternatively, lett</context>
</contexts>
<marker>Klementiev, Roth, 2006</marker>
<rawString>Alexandre Klementiev and Dan Roth. 2006. Named Entity Transliteration and Discovery from Multilingual Comparable Corpora. HLT Conf. of the North American Chapter of the ACL, pages 82–88.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Shea Kuo</author>
<author>Haizhou Li</author>
<author>Ying-Kuei Yang</author>
</authors>
<date>2006</date>
<booktitle>Learning Transliteration Lexicons from the Web. COLING-ACL2006,</booktitle>
<pages>1136</pages>
<location>Sydney, Australia,</location>
<contexts>
<context position="2966" citStr="Kuo et al., 2006" startWordPosition="447" endWordPosition="450">rkshop data for Arabic, English-Chinese, English-Hindi, EnglishRussian, and English-Tamil. For language pair, a base set of 1,000 transliteration pairs were available for training. The rest of the paper is organized as follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM al</context>
</contexts>
<marker>Kuo, Li, Yang, 2006</marker>
<rawString>Jin-Shea Kuo, Haizhou Li, Ying-Kuei Yang. 2006. Learning Transliteration Lexicons from the Web. COLING-ACL2006, Sydney, Australia, 1129 – 1136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-shea Kuo</author>
<author>Haizhou Li</author>
<author>Ying-kuei Yang</author>
</authors>
<title>A phonetic similarity model for automatic extraction of transliteration pairs. TALIP,</title>
<date>2007</date>
<contexts>
<context position="2984" citStr="Kuo et al., 2007" startWordPosition="451" endWordPosition="454">abic, English-Chinese, English-Hindi, EnglishRussian, and English-Tamil. For language pair, a base set of 1,000 transliteration pairs were available for training. The rest of the paper is organized as follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al</context>
</contexts>
<marker>Kuo, Li, Yang, 2007</marker>
<rawString>Jin-shea Kuo, Haizhou Li, Ying-kuei Yang. A phonetic similarity model for automatic extraction of transliteration pairs. TALIP, 2007</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-Shea Kuo</author>
<author>Haizhou Li</author>
<author>Chih-Lung Lin</author>
</authors>
<title>Mining Transliterations from Web Query Results: An Incremental Approach.</title>
<date>2008</date>
<booktitle>Sixth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<contexts>
<context position="3002" citStr="Kuo et al., 2008" startWordPosition="455" endWordPosition="458">ese, English-Hindi, EnglishRussian, and English-Tamil. For language pair, a base set of 1,000 transliteration pairs were available for training. The rest of the paper is organized as follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and C</context>
</contexts>
<marker>Kuo, Li, Lin, 2008</marker>
<rawString>Jin-Shea Kuo, Haizhou Li, Chih-Lung Lin. 2008. Mining Transliterations from Web Query Results: An Incremental Approach. Sixth SIGHAN Workshop on Chinese Language Processing, 2008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jin-shea Kuo</author>
<author>Ying-kuei Yang</author>
</authors>
<title>Incorporating Pronunciation Variation into Extraction of Transliterated-term Pairs from Web Corpora.</title>
<date>2005</date>
<journal>Journal of Chinese Language and Computing,</journal>
<volume>15</volume>
<issue>1</issue>
<pages>33--44</pages>
<contexts>
<context position="3895" citStr="Kuo and Yang, 2005" startWordPosition="590" endWordPosition="593">lish-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion tables to extract phonetically equivalent character sequences to discover monolingual and cross lingual pronunciation variations (Kuo and Yang, 2005). Alternatively, letters can be mapped into a common character set. One example of that is to use a predefined transliteration scheme to transliterate a word in one character set into another character set (Oh and Choi, 2006). Different methods were proposed to ascertain if two words can be transliterations of each other. One such way is to use a generative model that attempts to generate possible transliterations given the character mappings between two character sets (Fei et al., 2003; Lee and Chang, 2003, Udupa et al., 2009a). A similar alternative is to use back-transliteration to de53 Pro</context>
</contexts>
<marker>Kuo, Yang, 2005</marker>
<rawString>Jin-shea Kuo, Ying-kuei Yang. 2005. Incorporating Pronunciation Variation into Extraction of Transliterated-term Pairs from Web Corpora. Journal of Chinese Language and Computing, 15 (1): (33-44).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chun-Jen Lee</author>
<author>Jason S Chang</author>
</authors>
<title>Acquisition of EnglishChinese transliterated word pairs from parallelaligned texts using a statistical machine transliteration model. Workshop on Building and Using Parallel Texts,</title>
<date>2003</date>
<contexts>
<context position="3613" citStr="Lee and Chang, 2003" startWordPosition="548" endWordPosition="551">al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion tables to extract phonetically equivalent character sequences to discover monolingual and cross lingual pronunciation variations (Kuo and Yang, 2005). Alternatively, letters can be mapped into a common character set. One example of that is to use a predefined transliteration scheme to transliterate a word in one character set into another character set (Oh and Choi, 2006). Different methods were proposed to ascertain if two words can be transliterations of each o</context>
</contexts>
<marker>Lee, Chang, 2003</marker>
<rawString>Chun-Jen Lee, Jason S. Chang. Acquisition of EnglishChinese transliterated word pairs from parallelaligned texts using a statistical machine transliteration model. Workshop on Building and Using Parallel Texts, HLT-NAACL-2003, 2003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mahesh</author>
<author>K Sinha</author>
</authors>
<title>Automated Mining Of Names Using Parallel Hindi-English Corpus.</title>
<date>2009</date>
<booktitle>7th Workshop on Asian Language Resources, ACLIJCNLP 2009,</booktitle>
<pages>48--54</pages>
<location>Suntec, Singapore,</location>
<contexts>
<context position="3267" citStr="Mahesh and Sinha, 2009" startWordPosition="496" endWordPosition="499">describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion tables to extract phonetically equivalent character sequences to discover monolingual and cross lingual pronunciation var</context>
<context position="5199" citStr="Mahesh and Sinha, 2009" startWordPosition="795" endWordPosition="799">den, 16 July 2010. c�2010 Association for Computational Linguistics termine if one sequence could have been generated by successively mapping character sequences from one language into another (Brill et al., 2001; Bilac and Tanaka, 2005; Oh and Isahara, 2006). Another mapping method is to map candidate transliterations into a common representation space (Udupa et al., 2010). When using a predefined transliteration scheme, edit distance was used to determine if candidate transliterations were indeed transliterations (Oh and Choi, 2006). Also letter conflation was used to find transliterations (Mahesh and Sinha, 2009). Different methods were proposed to improve the recall of mining. For example, Oh and Choi (2006) used a SOUNDEX like scheme to minimize the effect of vowels and different schemes of phonetically coding names. SOUNDEX is used to convert English words into a simplified phonetic representation, in which vowels are removed and phonetically similar characters are conflated. Another method involved expanding character sequence maps by automatically mining transliteration pairs and then aligning these pairs to generate an expanded set of character sequence maps (Fei et al., 2003). 3 Transliteration</context>
</contexts>
<marker>Mahesh, Sinha, 2009</marker>
<rawString>R. Mahesh, K. Sinha. 2009. Automated Mining Of Names Using Parallel Hindi-English Corpus. 7th Workshop on Asian Language Resources, ACLIJCNLP 2009, pages 48–54, Suntec, Singapore, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Key-Sun Choi</author>
</authors>
<title>Recognizing transliteration equivalents for enriching domainspecific thesauri. 3rd Intl. WordNet Conf.</title>
<date>2006</date>
<pages>231--237</pages>
<contexts>
<context position="3148" citStr="Oh and Choi, 2006" startWordPosition="477" endWordPosition="480"> The rest of the paper is organized as follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion ta</context>
<context position="5116" citStr="Oh and Choi, 2006" startWordPosition="783" endWordPosition="786">dings of the 2010 Named Entities Workshop, ACL 2010, pages 53–56, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics termine if one sequence could have been generated by successively mapping character sequences from one language into another (Brill et al., 2001; Bilac and Tanaka, 2005; Oh and Isahara, 2006). Another mapping method is to map candidate transliterations into a common representation space (Udupa et al., 2010). When using a predefined transliteration scheme, edit distance was used to determine if candidate transliterations were indeed transliterations (Oh and Choi, 2006). Also letter conflation was used to find transliterations (Mahesh and Sinha, 2009). Different methods were proposed to improve the recall of mining. For example, Oh and Choi (2006) used a SOUNDEX like scheme to minimize the effect of vowels and different schemes of phonetically coding names. SOUNDEX is used to convert English words into a simplified phonetic representation, in which vowels are removed and phonetically similar characters are conflated. Another method involved expanding character sequence maps by automatically mining transliteration pairs and then aligning these pairs to genera</context>
</contexts>
<marker>Oh, Choi, 2006</marker>
<rawString>Jong-Hoon Oh, Key-Sun Choi. 2006. Recognizing transliteration equivalents for enriching domainspecific thesauri. 3rd Intl. WordNet Conf. (GWC-06), pages 231–237, 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jong-Hoon Oh</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Mining the Web for Transliteration Lexicons: Joint-Validation Approach.</title>
<date>2006</date>
<booktitle>IEEE/WIC/ACM Intl. Conf. on Web Intelligence (WI&apos;06),</booktitle>
<pages>254--261</pages>
<contexts>
<context position="3128" citStr="Oh and Isahara, 2006" startWordPosition="473" endWordPosition="476">vailable for training. The rest of the paper is organized as follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech reco</context>
<context position="4835" citStr="Oh and Isahara, 2006" startWordPosition="741" endWordPosition="744">her. One such way is to use a generative model that attempts to generate possible transliterations given the character mappings between two character sets (Fei et al., 2003; Lee and Chang, 2003, Udupa et al., 2009a). A similar alternative is to use back-transliteration to de53 Proceedings of the 2010 Named Entities Workshop, ACL 2010, pages 53–56, Uppsala, Sweden, 16 July 2010. c�2010 Association for Computational Linguistics termine if one sequence could have been generated by successively mapping character sequences from one language into another (Brill et al., 2001; Bilac and Tanaka, 2005; Oh and Isahara, 2006). Another mapping method is to map candidate transliterations into a common representation space (Udupa et al., 2010). When using a predefined transliteration scheme, edit distance was used to determine if candidate transliterations were indeed transliterations (Oh and Choi, 2006). Also letter conflation was used to find transliterations (Mahesh and Sinha, 2009). Different methods were proposed to improve the recall of mining. For example, Oh and Choi (2006) used a SOUNDEX like scheme to minimize the effect of vowels and different schemes of phonetically coding names. SOUNDEX is used to conver</context>
</contexts>
<marker>Oh, Isahara, 2006</marker>
<rawString>Jong-Hoon Oh, Hitoshi Isahara. 2006. Mining the Web for Transliteration Lexicons: Joint-Validation Approach. pp.254-261, 2006 IEEE/WIC/ACM Intl. Conf. on Web Intelligence (WI&apos;06), 2006.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghavendra Udupa</author>
<author>K Saravanan</author>
<author>Anton Bakalov</author>
<author>Abhijit Bhole</author>
</authors>
<title>They Are Out There, If You Know Where to Look&amp;quot;: Mining Transliterations of OOV Query Terms for Cross-Language Information Retrieval.</title>
<date>2009</date>
<booktitle>ECIR-2009,</booktitle>
<location>Toulouse, France,</location>
<contexts>
<context position="3657" citStr="Udupa et al., 2009" startWordPosition="557" endWordPosition="560">aravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion tables to extract phonetically equivalent character sequences to discover monolingual and cross lingual pronunciation variations (Kuo and Yang, 2005). Alternatively, letters can be mapped into a common character set. One example of that is to use a predefined transliteration scheme to transliterate a word in one character set into another character set (Oh and Choi, 2006). Different methods were proposed to ascertain if two words can be transliterations of each other. One such way is to use a generative mo</context>
</contexts>
<marker>Udupa, Saravanan, Bakalov, Bhole, 2009</marker>
<rawString>Raghavendra Udupa, K. Saravanan, Anton Bakalov, and Abhijit Bhole. 2009a. &amp;quot;They Are Out There, If You Know Where to Look&amp;quot;: Mining Transliterations of OOV Query Terms for Cross-Language Information Retrieval. ECIR-2009, Toulouse, France, 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghavendra Udupa</author>
<author>K Saravanan</author>
<author>A Kumaran</author>
<author>Jagadeesh Jagarlamudi</author>
</authors>
<title>MINT: A Method for Effective and Scalable Mining of Named Entity Transliterations from Large Comparable Corpora. EACL</title>
<date>2009</date>
<contexts>
<context position="3657" citStr="Udupa et al., 2009" startWordPosition="557" endWordPosition="560">aravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another method is to use automatic speech recognition confusion tables to extract phonetically equivalent character sequences to discover monolingual and cross lingual pronunciation variations (Kuo and Yang, 2005). Alternatively, letters can be mapped into a common character set. One example of that is to use a predefined transliteration scheme to transliterate a word in one character set into another character set (Oh and Choi, 2006). Different methods were proposed to ascertain if two words can be transliterations of each other. One such way is to use a generative mo</context>
</contexts>
<marker>Udupa, Saravanan, Kumaran, Jagarlamudi, 2009</marker>
<rawString>Raghavendra Udupa, K. Saravanan, A. Kumaran, and Jagadeesh Jagarlamudi. 2009b. MINT: A Method for Effective and Scalable Mining of Named Entity Transliterations from Large Comparable Corpora. EACL 2009.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghavendra Udupa</author>
<author>Mitesh Khapra</author>
</authors>
<title>Transliteration Equivalence using Canonical Correlation Analysis.</title>
<date>2010</date>
<contexts>
<context position="3090" citStr="Udupa and Khapra, 2010" startWordPosition="468" endWordPosition="471">set of 1,000 transliteration pairs were available for training. The rest of the paper is organized as follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa et al., 2009b). Another </context>
</contexts>
<marker>Udupa, Khapra, 2010</marker>
<rawString>Raghavendra Udupa and Mitesh Khapra. 2010. Transliteration Equivalence using Canonical Correlation Analysis. ECIR-2010, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert Russell</author>
</authors>
<date>1918</date>
<booktitle>Specifications of Letters. US patent number</booktitle>
<pages>1--261</pages>
<contexts>
<context position="1871" citStr="Russell, 1918" startWordPosition="283" endWordPosition="284">ne translation and cross language search via translation resource expansion. TM has been gaining some attention of late with a shared task in the ACL 2010 NEWS workshop1. In this paper, TM was performed using a transliterator that was used to generate possible transliterations of a word while constraining the output to tokens that exist in a target language word sequence. The paper presents the use of phonetic letter conflation and iterative transliterator training to improve TM when only limited transliteration training data is available. For phonetic letter conflation, a variant of SOUNDEX (Russell, 1918) was used to improve the coverage of existing training data. As for iterative transliterator training, an initial transliterator, which was trained on initial set of transliteration pairs, was used to mine transliterations in parallel text. Then, the automatically found transliterations pairs were considered correct and were used to retrain the transliterator. 1 http://translit.i2r.a-star.edu.sg/news2010/ The proposed improvements in TM were tested using the ACL 2010 NEWS workshop data for Arabic, English-Chinese, English-Hindi, EnglishRussian, and English-Tamil. For language pair, a base set </context>
</contexts>
<marker>Russell, 1918</marker>
<rawString>Robert Russell. 1918. Specifications of Letters. US patent number 1,261,167.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Saravanan</author>
<author>A Kumaran</author>
</authors>
<title>Some Experiments in Mining Named Entity Transliteration Pairs from Comparable Corpora. The 2nd Intl. Workshop on Cross Lingual Information Access addressing the need of multilingual societies,</title>
<date>2008</date>
<contexts>
<context position="3065" citStr="Saravanan and Kumaran, 2008" startWordPosition="464" endWordPosition="467">l. For language pair, a base set of 1,000 transliteration pairs were available for training. The rest of the paper is organized as follows: Section 2 surveys prior work on transliteration mining; Section 3 describes the TM approach and the proposed improvements; Section 4 describes the experimental setup including the evaluation sets; Section 5 reports on experimental results; and Section 6 concludes the paper. 2 Background Much work has been done on TM for different language pairs such as English-Chinese (Kuo et al., 2006; Kuo et al., 2007; Kuo et al., 2008; Jin et al. 2008;), English-Tamil (Saravanan and Kumaran, 2008; Udupa and Khapra, 2010), English-Korean (Oh and Isahara, 2006; Oh and Choi, 2006), English-Japanese (Brill et al., 2001; Oh and Isahara, 2006), English-Hindi (Fei et al., 2003; Mahesh and Sinha, 2009), and English-Russian (Klementiev and Roth, 2006). The most common approach for determining letter sequence mapping between two languages is using automatic letter alignment of a training set of transliteration pairs. Automatic alignment can be performed using different algorithms such as the EM algorithm (Kuo et al., 2008; Lee and Chang, 2003) or using an HMM aligner (Udupa et al., 2009a; Udupa</context>
</contexts>
<marker>Saravanan, Kumaran, 2008</marker>
<rawString>K Saravanan, A Kumaran. 2008. Some Experiments in Mining Named Entity Transliteration Pairs from Comparable Corpora. The 2nd Intl. Workshop on Cross Lingual Information Access addressing the need of multilingual societies, 2008.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>