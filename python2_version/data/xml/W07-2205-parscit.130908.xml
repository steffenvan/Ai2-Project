<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.037980">
<title confidence="0.967275">
The Impact of Deep Linguistic Processing on Parsing Technology
</title>
<author confidence="0.998482">
Timothy Baldwin Mark Dras
</author>
<affiliation confidence="0.998055">
University of Melbourne Macquarie University
</affiliation>
<email confidence="0.988847">
tim@csse.unimelb.edu.au madras@ics.mq.edu.au
</email>
<author confidence="0.998701">
Julia Hockenmaier Tracy Holloway King Gertjan van Noord
</author>
<affiliation confidence="0.998863">
University of Pennsylvania PARC University of Groningen
</affiliation>
<email confidence="0.999139">
juliahr@cis.upenn.edu thking@parc.com vannoord@let.rug.nl
</email>
<sectionHeader confidence="0.995646" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999982333333333">
As the organizers of the ACL 2007 Deep
Linguistic Processing workshop (Baldwin et
al., 2007), we were asked to discuss our per-
spectives on the role of current trends in
deep linguistic processing for parsing tech-
nology. We are particularly interested in
the ways in which efficient, broad coverage
parsing systems for linguistically expressive
grammars can be built and integrated into
applications which require richer syntactic
structures than shallow approaches can pro-
vide. This often requires hybrid technolo-
gies which use shallow or statistical methods
for pre- or post-processing, to extend cover-
age, or to disambiguate the output.
</bodyText>
<sectionHeader confidence="0.998993" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999894363636364">
Our talk will provide a view on the relevance of deep
linguistic processing for parsing technologies from
the perspective of the organizers of the ACL 2007
Workshop on Deep Linguistic Processing (Baldwin
et al., 2007). The workshop was conceived with the
broader aim of bringing together the different com-
putational linguistic sub-communities which model
language predominantly by way of theoretical syn-
tax, either in the form of a particular theory (e.g.
CCG, HPSG, LFG, TAG, the Prague School) or a
more general framework which draws on theoretical
and descriptive linguistics. These “deep linguistic
processing” approaches differ from shallower meth-
ods in that they yield richer, more expressive, struc-
tural representations which capture long-distance
dependencies or the underlying predicate-argument
structure directly.
Aspects of this research have often had their own
separate fora, such as the ACL 2005 workshop on
deep lexical acquisition (Baldwin et al., 2005), as
well as the TAG+ (Kallmeyer and Becker, 2006),
Alpino (van der Beek et al., 2005), ParGram (Butt
et al., 2002) and DELPH-IN (Oepen et al., 2002)
projects and meetings. However, the fundamental
approaches to building a linguistically-founded sys-
tem and many of the techniques used to engineer
efficient systems are common across these projects
and independent of the specific grammar formal-
ism chosen. As such, we felt the need for a com-
mon meeting in which experiences could be shared
among a wider community, similar to the role played
by recent meetings on grammar engineering (Wint-
ner, 2006; Bender and King, 2007).
</bodyText>
<sectionHeader confidence="0.486078" genericHeader="method">
2 The promise of deep parsing
</sectionHeader>
<bodyText confidence="0.999973642857143">
Deep linguistic processing has traditionally been
concerned with grammar development (for use in
both parsing and generation). However, the linguis-
tic precision and complexity of the grammars meant
that they had to be manually developed and main-
tained, and were computationally expensive to run.
In recent years, machine learning approaches
have fundamentally altered the field of natural lan-
guage processing. The availability of large, manu-
ally annotated, treebanks (which typically take years
of prior linguistic groundwork to produce) enabled
the rapid creation of robust, wide-coverage parsers.
However, the standard evaluation metrics for which
such parsers have been optimized generally ignore
</bodyText>
<page confidence="0.931723">
36
</page>
<bodyText confidence="0.955567518518519">
Proceedings of the 10th Conference on Parsing Technologies, pages 36–38,
Prague, Czech Republic, June 2007. c�2007 Association for Computational Linguistics
much of the rich linguistic information in the orig-
inal treebanks. It is therefore perhaps only natural
that deep processing methods, which often require
substantial amounts of manual labor, have received
considerably less attention during this period.
But even if further work is required for deep
processing techniques to fully mature, we believe
that applications that require natural language under-
standing or inference, among others, will ultimately
need detailed syntactic representations (capturing,
e.g., bounded and unbounded long-range dependen-
cies) from which semantic interpretations can eas-
ily be built. There is already some evidence that
our current deep techniques can, in some cases, out-
perform shallow approaches. There has been work
demonstrating this in question answering, targeted
information extraction and the recent textual entail-
ment recognition task, and perhaps most notably in
machine translation: in this latter field, after a period
of little use of linguistic knowledge, deeper tech-
niques are beginning to lead to better performance,
e.g. by redefining phrases by syntactic “treelets”
rather than contiguous word sequences, or by explic-
itly including a syntactic component in the probabil-
ity model, or by syntactic preprocessing of the data.
</bodyText>
<sectionHeader confidence="0.984651" genericHeader="method">
3 Closing the divide
</sectionHeader>
<bodyText confidence="0.981714924242425">
In the past few years, the divide between “deep”,
rule-based, methods and “shallow”, statistical, ap-
proaches, has begun to close from both sides. Re-
cent advances in using the same treebanks that have
advanced shallow techniques to extract more expres-
sive grammars or to train statistical disambiguators
for them, and in developing framework-specific tree-
banks, have made it possible to obtain similar cov-
erage, robustness, and disambiguation accuracy for
parsers that use richer structural representations. As
witnessed by many of the papers in our workshop
(Baldwin et al., 2007), a large proportion of current
deep systems have statistical components to them,
e.g., as pre- or post-processing to control ambigu-
ity, as means of acquiring and extending lexical re-
sources, or even use machine learning techniques
to acquire deep grammars automatically. From the
other side of the divide, many of the purely statistical
approaches are using progressively richer linguistic
features and are taking advantage of these more ex-
pressive features to tackle problems that were tradi-
tionally thought to require deep systems, such as the
recovery of traces or semantic roles.
4 The continued need for research on deep
processing
Although statistical techniques are becoming com-
monplace even for systems built around hand-
written grammars, there is still a need for further
linguistic research and manual grammar develop-
ment. For example, supervised machine-learning
approaches rely on large amounts of manually anno-
tated data. Where such data are available, develop-
ers of deep parsers and grammars can exploit them
to determine frequency of certain constructions, to
bootstrap gold standards for their systems, and to
provide training data for the statistical components
of their systems such as parse disambiguators. But
for the majority of the world’s languages, and even
for many languages with large numbers of speakers,
such corpora are unavailable. Under these circum-
stances, manual grammar development is unavoid-
able, and recent progress has allowed the underlying
systems to become increasingly better engineered,
allowing for more rapid development of any given
grammar, as well as for overlay grammars that adapt
to particular domains and applications and for port-
ing of grammars from one language to another.
Despite recent work on (mostly dependency
grammar-based) multilingual parsing, it is still the
case that most research on statistical parsing is done
on English, a fixed word-order language where sim-
ple context-free approximations are often sufficient.
It is unclear whether our current models and al-
gorithms carry over to morphologically richer lan-
guages with more flexible word order, and it is possi-
ble that the more complex structural representations
allowed by expressive formalisms will cease to re-
main a luxury.
Further research is required on all aspects of
deep linguistic processing, including novel linguis-
tic analyses and implementations for different lan-
guages, formal comparisons of different frame-
works, efficient parse and learning algorithms, better
statistical models, innovative uses of existing data
resources, and new evaluation tools and methodolo-
gies. We were fortunate to receive so many high-
</bodyText>
<page confidence="0.998478">
37
</page>
<bodyText confidence="0.866582">
quality submissions on all of these topics for our
workshop.
</bodyText>
<sectionHeader confidence="0.799317" genericHeader="conclusions">
5 Conclusion and outlook
</sectionHeader>
<bodyText confidence="0.999974153846154">
Deep linguistic processing brings together a range of
perspectives. It covers current approaches to gram-
mar development and issues of theoretical linguis-
tic and algorithmic properties, as well as the appli-
cation of deep linguistic techniques to large-scale
applications such as question answering and dialog
systems. Having industrial-scale, efficient parsers
and generators opens up new application domains
for natural language processing, as well as inter-
esting new ways in which to approach existing ap-
plications, e.g., by combining statistical and deep
processing techniques in a triage process to pro-
cess massive data quickly and accurately at a fine
level of detail. Notably, several of the papers ad-
dressed the relationship of deep linguistic process-
ing to topical statistical approaches, in particular in
the area of parsing. There is an increasing inter-
est in deep linguistic processing, an interest which
is buoyed by the realization that new, often hybrid,
techniques combined with highly engineered parsers
and generators and state-of-the-art machines opens
the way towards practical, real-world application of
this research. We look forward to further opportu-
nities for the different computational linguistic sub-
communities who took part in this workshop, and
others, to continue to come together in the future.
</bodyText>
<sectionHeader confidence="0.998599" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999817625">
Timothy Baldwin, Anna Korhonen, and Aline Villavicen-
cio, editors. 2005. Proceedings of the ACL-SIGLEX
Workshop on Deep Lexical Acquisition. Ann Arbor,
USA.
Timothy Baldwin, Mark Dras, Julia Hockenmaier,
Tracy Holloway King, and Gertjan van Noord, editors.
2007. Proceedings of the ACL Workshop on Deep Lin-
guistic Processing, Prague, Czech Republic.
Emily Bender and Tracy Holloway King, editors. 2007.
Grammar Engineering Across Frameworks, Stanford
University. CSLI On-line Publications. to appear.
Miriam Butt, Helge Dyvik, T. H. King, Hiroshi Masuichi,
and Christian Rohrer. 2002. The parallel grammar
project. In COLING Workshop on Grammar Engi-
neering and Evaluation, Taipei, Taiwan.
Laura Kallmeyer and Tilman Becker, editors. 2006. Pro-
ceedings of the Eighth International Workshop on Tree
Adjoining Grammar and Related Formalisms (TAG+),
Sydney, Australia.
Stephan Oepen, Dan Flickinger, J. Tsujii, and Hand
Uszkoreit, editors. 2002. Collaborative Language En-
gineering: A Case Study in Efficient Grammar-based
Processing. CSLI Publications.
Leonoor van der Beek, Gosse Bouma, Jan Daciuk, Tanja
Gaustad, Robert Malouf, Mark-Jan Nederhof, Gert-
jan van Noord, Robbert Prins, and Bego na Vil-
lada Moir´on. 2005. Algorithms for linguistic pro-
cessing. NWO Pionier final report. Technical report,
University of Groningen.
Shuly Wintner. 2006. Large-scale grammar development
and grammar engineering. Research workshop of the
Israel Science Foundation.
</reference>
<page confidence="0.999353">
38
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.608274">
<title confidence="0.999616">The Impact of Deep Linguistic Processing on Parsing Technology</title>
<author confidence="0.999842">Timothy Baldwin Mark Dras</author>
<affiliation confidence="0.999985">University of Melbourne Macquarie University</affiliation>
<email confidence="0.70028">tim@csse.unimelb.edu.aumadras@ics.mq.edu.au</email>
<author confidence="0.997568">Julia Hockenmaier Tracy Holloway King Gertjan van_Noord</author>
<affiliation confidence="0.999599">University of Pennsylvania PARC University of Groningen</affiliation>
<email confidence="0.971517">juliahr@cis.upenn.eduthking@parc.comvannoord@let.rug.nl</email>
<abstract confidence="0.993224625">As the organizers of the ACL 2007 Deep Linguistic Processing workshop (Baldwin et al., 2007), we were asked to discuss our perspectives on the role of current trends in deep linguistic processing for parsing technology. We are particularly interested in the ways in which efficient, broad coverage parsing systems for linguistically expressive grammars can be built and integrated into applications which require richer syntactic structures than shallow approaches can provide. This often requires hybrid technologies which use shallow or statistical methods for preor post-processing, to extend coverage, or to disambiguate the output.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<date>2005</date>
<booktitle>Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition.</booktitle>
<editor>Timothy Baldwin, Anna Korhonen, and Aline Villavicencio, editors.</editor>
<location>Ann Arbor, USA.</location>
<marker>2005</marker>
<rawString>Timothy Baldwin, Anna Korhonen, and Aline Villavicencio, editors. 2005. Proceedings of the ACL-SIGLEX Workshop on Deep Lexical Acquisition. Ann Arbor, USA.</rawString>
</citation>
<citation valid="true">
<date>2007</date>
<booktitle>Proceedings of the ACL Workshop on Deep Linguistic Processing,</booktitle>
<editor>Timothy Baldwin, Mark Dras, Julia Hockenmaier, Tracy Holloway King, and Gertjan van Noord, editors.</editor>
<location>Prague, Czech Republic.</location>
<marker>2007</marker>
<rawString>Timothy Baldwin, Mark Dras, Julia Hockenmaier, Tracy Holloway King, and Gertjan van Noord, editors. 2007. Proceedings of the ACL Workshop on Deep Linguistic Processing, Prague, Czech Republic.</rawString>
</citation>
<citation valid="true">
<title>Grammar Engineering Across Frameworks,</title>
<date>2007</date>
<editor>Emily Bender and Tracy Holloway King, editors.</editor>
<publisher>CSLI On-line Publications.</publisher>
<location>Stanford University.</location>
<note>to appear.</note>
<marker>2007</marker>
<rawString>Emily Bender and Tracy Holloway King, editors. 2007. Grammar Engineering Across Frameworks, Stanford University. CSLI On-line Publications. to appear.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
<author>Helge Dyvik</author>
<author>T H King</author>
<author>Hiroshi Masuichi</author>
<author>Christian Rohrer</author>
</authors>
<title>The parallel grammar project.</title>
<date>2002</date>
<booktitle>In COLING Workshop on Grammar Engineering and Evaluation,</booktitle>
<location>Taipei, Taiwan.</location>
<contexts>
<context position="2097" citStr="Butt et al., 2002" startWordPosition="301" endWordPosition="304">LFG, TAG, the Prague School) or a more general framework which draws on theoretical and descriptive linguistics. These “deep linguistic processing” approaches differ from shallower methods in that they yield richer, more expressive, structural representations which capture long-distance dependencies or the underlying predicate-argument structure directly. Aspects of this research have often had their own separate fora, such as the ACL 2005 workshop on deep lexical acquisition (Baldwin et al., 2005), as well as the TAG+ (Kallmeyer and Becker, 2006), Alpino (van der Beek et al., 2005), ParGram (Butt et al., 2002) and DELPH-IN (Oepen et al., 2002) projects and meetings. However, the fundamental approaches to building a linguistically-founded system and many of the techniques used to engineer efficient systems are common across these projects and independent of the specific grammar formalism chosen. As such, we felt the need for a common meeting in which experiences could be shared among a wider community, similar to the role played by recent meetings on grammar engineering (Wintner, 2006; Bender and King, 2007). 2 The promise of deep parsing Deep linguistic processing has traditionally been concerned w</context>
</contexts>
<marker>Butt, Dyvik, King, Masuichi, Rohrer, 2002</marker>
<rawString>Miriam Butt, Helge Dyvik, T. H. King, Hiroshi Masuichi, and Christian Rohrer. 2002. The parallel grammar project. In COLING Workshop on Grammar Engineering and Evaluation, Taipei, Taiwan.</rawString>
</citation>
<citation valid="true">
<date>2006</date>
<booktitle>Proceedings of the Eighth International Workshop on Tree Adjoining Grammar and Related Formalisms (TAG+),</booktitle>
<editor>Laura Kallmeyer and Tilman Becker, editors.</editor>
<location>Sydney, Australia.</location>
<marker>2006</marker>
<rawString>Laura Kallmeyer and Tilman Becker, editors. 2006. Proceedings of the Eighth International Workshop on Tree Adjoining Grammar and Related Formalisms (TAG+), Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<title>Collaborative Language Engineering: A Case Study in Efficient Grammar-based Processing.</title>
<date>2002</date>
<editor>Stephan Oepen, Dan Flickinger, J. Tsujii, and Hand Uszkoreit, editors.</editor>
<publisher>CSLI Publications.</publisher>
<marker>2002</marker>
<rawString>Stephan Oepen, Dan Flickinger, J. Tsujii, and Hand Uszkoreit, editors. 2002. Collaborative Language Engineering: A Case Study in Efficient Grammar-based Processing. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leonoor van der Beek</author>
<author>Gosse Bouma</author>
<author>Jan Daciuk</author>
<author>Tanja Gaustad</author>
<author>Robert Malouf</author>
</authors>
<title>Mark-Jan Nederhof, Gertjan van Noord, Robbert Prins, and Bego na Villada Moir´on.</title>
<date>2005</date>
<tech>Technical report,</tech>
<institution>University of Groningen.</institution>
<marker>van der Beek, Bouma, Daciuk, Gaustad, Malouf, 2005</marker>
<rawString>Leonoor van der Beek, Gosse Bouma, Jan Daciuk, Tanja Gaustad, Robert Malouf, Mark-Jan Nederhof, Gertjan van Noord, Robbert Prins, and Bego na Villada Moir´on. 2005. Algorithms for linguistic processing. NWO Pionier final report. Technical report, University of Groningen.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Shuly Wintner</author>
</authors>
<title>Large-scale grammar development and grammar engineering. Research workshop of the Israel Science Foundation.</title>
<date>2006</date>
<contexts>
<context position="2580" citStr="Wintner, 2006" startWordPosition="380" endWordPosition="382">n et al., 2005), as well as the TAG+ (Kallmeyer and Becker, 2006), Alpino (van der Beek et al., 2005), ParGram (Butt et al., 2002) and DELPH-IN (Oepen et al., 2002) projects and meetings. However, the fundamental approaches to building a linguistically-founded system and many of the techniques used to engineer efficient systems are common across these projects and independent of the specific grammar formalism chosen. As such, we felt the need for a common meeting in which experiences could be shared among a wider community, similar to the role played by recent meetings on grammar engineering (Wintner, 2006; Bender and King, 2007). 2 The promise of deep parsing Deep linguistic processing has traditionally been concerned with grammar development (for use in both parsing and generation). However, the linguistic precision and complexity of the grammars meant that they had to be manually developed and maintained, and were computationally expensive to run. In recent years, machine learning approaches have fundamentally altered the field of natural language processing. The availability of large, manually annotated, treebanks (which typically take years of prior linguistic groundwork to produce) enable</context>
</contexts>
<marker>Wintner, 2006</marker>
<rawString>Shuly Wintner. 2006. Large-scale grammar development and grammar engineering. Research workshop of the Israel Science Foundation.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>