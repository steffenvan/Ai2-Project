<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.067280">
<title confidence="0.985129">
An Annotation Type System for a Data-Driven NLP Pipeline
</title>
<author confidence="0.969075">
Udo Hahn Ekaterina Buyko Katrin Tomanek
</author>
<affiliation confidence="0.929495">
Jena University Language &amp; Information Engineering (JULIE) Lab
</affiliation>
<address confidence="0.439448">
F¨urstengraben 30, 07743 Jena, Germany
</address>
<email confidence="0.396536">
{hahn|buyko|tomanek}@coling-uni-jena.de
</email>
<author confidence="0.995913">
Scott Piao John McNaught Yoshimasa Tsuruoka Sophia Ananiadou
</author>
<affiliation confidence="0.994945">
NaCTeM and School of Computer Science
University of Manchester
</affiliation>
<email confidence="0.995427">
{scott.piao|john.mcnaught|yoshimasa.tsuruoka|sophia.ananiadou}@manchester.ac.uk
</email>
<sectionHeader confidence="0.995587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99869325">
We introduce an annotation type system for
a data-driven NLP core system. The specifi-
cations cover formal document structure and
document meta information, as well as the
linguistic levels of morphology, syntax and
semantics. The type system is embedded in
the framework of the Unstructured Informa-
tion Management Architecture (UIMA).
</bodyText>
<sectionHeader confidence="0.998797" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999977">
With the maturation of language technology, soft-
ware engineering issues such as re-usability, in-
teroperability, or portability are getting more and
more attention. As dozens of stand-alone compo-
nents such as tokenizers, stemmers, lemmatizers,
chunkers, parsers, etc. are made accessible in vari-
ous NLP software libraries and repositories the idea
sounds intriguing to (re-)use them on an ‘as is’ basis
and thus save expenditure and manpower when one
configures a composite NLP pipeline.
As a consequence, two questions arise. First, how
can we abstract away from the specific code level of
those single modules which serve, by and large, the
same functionality? Second, how can we build NLP
systems by composing them, at the abstract level
of functional specification, from these already ex-
isting component building blocks disregarding con-
crete implementation matters? Yet another burning
issue relates to the increasing availability of multiple
metadata annotations both in corpora and language
processors. If alternative annotation tag sets are cho-
sen for the same functional task a ‘data conversion’
problem is created which should be solved at the ab-
stract specification level as well (Ide et al., 2003).
Software engineering methodology points out that
these requirements are best met by properly identi-
fying input/output capabilities of constituent compo-
nents and by specifying a general data model (e.g.,
based on UML (Rumbaugh et al., 1999)) in or-
der to get rid of the low-level implementation (i.e.,
coding) layer. A particularly promising proposal
along this line of thought is the Unstructured Infor-
mation Management Architecture (UIMA) (Ferrucci
and Lally, 2004) originating from IBM research ac-
tivities.1 UIMA is but the latest attempt in a series
of proposals concerned with more generic NLP en-
gines such as ATLAS (Laprun et al., 2002) or GATE
(Cunningham, 2002). These frameworks have in
common a data-driven architecture and a data model
based on annotation graphs as an adaptation of the
TIPSTER architecture (Grishman, 1997). They suf-
fer, however, from a lack of standards for data ex-
change and abstraction mechanisms at the level of
specification languages.
This can be achieved by the definition of a com-
mon annotation scheme. We propose an UIMA
schema which accounts for a significant part of the
complete NLP cycle – from the collection of doc-
uments and their internal formal structure, via sen-
tence splitting, tokenization, POS tagging, and pars-
ing, up until the semantic layer (still excluding dis-
course) – and which aims at the implementation-
independent specification of a core NLP system.
</bodyText>
<footnote confidence="0.945487333333333">
1Though designed for any sort of unstructured data (text,
audio and video data), we here focus on special requirements
for the analysis of written documents.
</footnote>
<page confidence="0.983576">
33
</page>
<note confidence="0.901139">
Proceedings of the Linguistic Annotation Workshop, pages 33–40,
Prague, June 2007. c�2007 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.997417" genericHeader="introduction">
2 Related work
</sectionHeader>
<bodyText confidence="0.99998880952381">
Efforts towards the design of annotation schemata
for language resources and their standardization
have a long-standing tradition in the NLP commu-
nity. In the very beginning, this work often fo-
cused exclusively on subdomains of text analysis
such as document structure meta-information, syn-
tactic or semantic analysis. The Text Encoding Ini-
tiative (TEI)2 provided schemata for the exchange
of documents of various genres. The Dublin Core
Metadata Initiative3 established a de facto standard
for the Semantic Web.4 For (computational) lin-
guistics proper, syntactic annotation schemes, such
as the one from the Penn Treebank (Marcus et al.,
1993), or semantic annotations, such as the one un-
derlying ACE (Doddington et al., 2004), are increas-
ingly being used in a quasi standard way.
In recent years, however, the NLP community is
trying to combine and merge different kinds of an-
notations for single linguistic layers. XML formats
play a central role here. An XML-based encod-
ing standard for linguistic corpora XCES (Ide et al.,
2000) is based on CES (Corpus Encoding Standard)
as part of the EAGLES Guidelines.5 Work on TIGER
(Brants and Hansen, 2002) is an example for the li-
aison of dependency- and constituent-based syntac-
tic annotations. New standardization efforts such as
the Syntactic Annotation Framework (SYNAF) (De-
clerck, 2006) aim to combine different proposals and
create standards for syntactic annotation.
We also encounter a tendency towards multiple
annotations for a single corpus. Major bio-medical
corpora, such as GENIA (Ohta et al., 2002) or
PennBioIE,6 combine several layers of linguistic
information in terms of morpho-syntactic, syntac-
tic and semantic annotations (named entities and
events). In the meantime, the Annotation Compat-
ibility Working Group (Meyers, 2006) began to con-
centrate its activities on the mutual compatibility of
annotation schemata for, e.g., POS tagging, tree-
banking, role labeling, time annotation, etc.
The goal of these initiatives, however, has never
been to design an annotation scheme for a complete
</bodyText>
<footnote confidence="0.9999464">
2http://www.tei-c.org
3http://dublincore.org
4http://www.w3.org/2001/sw
5http://www.ilc.cnr.it/EAGLES96/
6http://bioie.ldc.upenn.edu
</footnote>
<bodyText confidence="0.999647736842105">
NLP pipeline as needed, e.g., for information ex-
traction or text mining tasks (Hahn and Wermter,
2006). This lack is mainly due to missing standards
for specifying comprehensive NLP software archi-
tectures. The MEANING format (Pianta et al., 2006)
is designed to integrate different levels of morpho-
syntactic annotations. The HEART OF GOLD mid-
dleware (Sch¨afer, 2006) combines multidimensional
mark-up produced by several NLP components. An
XML-based NLP tool suite for analyzing and anno-
tating medical language in an NLP pipeline was also
proposed by (Grover et al., 2002). All these propos-
als share their explicit linkage to a specific NLP tool
suite or NLP system and thus lack a generic annota-
tion framework that can be re-used in other develop-
mental environments.
Buitelaar et al. developed in the context of an in-
formation extraction project an XML-based multi-
layered annotation scheme that covers morpho-
syntactic, shallow parsing and semantic annotation
(Buitelaar et al., 2003). Their scheme borrows con-
cepts from object-oriented programming (e.g., ab-
stract types, polymorphism). The object-oriented
perspective already allows the development of a
domain-independent schema and extensions of core
types without affecting the base schema. This
schema is comprehensive indeed and covers a sig-
nificant part of advanced NLP pipelines but it is also
not connected to a generic framework.
It is our intention to come full circle within a
general annotation framework. Accordingly, we
cover a significant part of the NLP pipeline from
document meta information and formal document
structure, morpho-syntactic and syntactic analysis
up to semantic processing. The scheme we propose
is intended to be compatible with on-going work
in standardization efforts from task-specific annota-
tions and to adhere to object-oriented principles.
</bodyText>
<sectionHeader confidence="0.996604" genericHeader="method">
3 Data-Driven NLP Architecture
</sectionHeader>
<bodyText confidence="0.999937857142857">
As the framework for our specification efforts, we
adopted the Unstructured Information Management
Architecture (UIMA) (Ferrucci and Lally, 2004). It
provides a formal specification layer based on UML,
as well as a run-time environment for the interpreta-
tion and use of these specifications. This dualism is
going to attract more and more researchers as a basis
</bodyText>
<page confidence="0.998171">
34
</page>
<bodyText confidence="0.807974">
for proper NLP system engineering.
</bodyText>
<subsectionHeader confidence="0.995574">
3.1 UIMA-based Tool Suite
</subsectionHeader>
<bodyText confidence="0.999800933333333">
UIMA provides a platfrom for the integration
of NLP components (ANALYSIS ENGINES in the
UIMA jargon) and the deployment of complex
NLP pipelines. It is more powerful than other
prominent software systems for language engineer-
ing (e.g., GATE, ATLAS) as far as its pre- and
post-processing facilities are concerned — so-called
COLLECTION READERS can be developed to handle
any kind of input format (e.g., WWW documents,
conference proceedings), while CONSUMERS, on
other hand, deal with the subsequent manipulation
of the NLP core results (e.g., automatic indexing).
Therefore, UIMA is a particularly suitable architec-
ture for advanced text analysis applications such as
text mining or information extraction.
We currently provide ANALYSIS ENGINES for
sentence splitting, tokenization, POS tagging, shal-
low and full parsing, acronym detection, named
entity recognition, and mapping from named enti-
ties to database term identifiers (the latter is mo-
tivated by our biological application context). As
we mainly deal with documents taken from the bio-
medical domain, our collection readers process doc-
uments from PUBMED,7 the most important liter-
ature resource for researchers in the life sciences.
PUBMED currently provides more than 16 million
bibliographic references to bio-medical articles. The
outcomes of ANALYSIS ENGINES are input for var-
ious CONSUMERS such as semantic search engines
or text mining tools.
</bodyText>
<subsectionHeader confidence="0.999969">
3.2 Common Analysis System
</subsectionHeader>
<bodyText confidence="0.999973909090909">
UIMA is based on a data-driven architecture. This
means that UIMA components do not exchange or
share code, they rather exchange data only. The
components operate on common data referred to
as COMMON ANALYSIS SYSTEM (CAS)(G¨otz and
Suhre, 2004). The CAS contains the subject of anal-
ysis (document) and provides meta data in the form
of annotations. Analysis engines receive annotations
through a CAS and add new annotations to the CAS.
An annotation in the CAS then associates meta data
with a region the subject of the analysis occupies
</bodyText>
<footnote confidence="0.61819">
7http://www.pubmed.gov
</footnote>
<bodyText confidence="0.999897533333333">
(e.g., the start and end positions in a document).
UIMA defines CAS interfaces for indexing, ac-
cessing and updating the CAS. CASes are modelled
independently from particular programming lan-
guages. However, JCAS, an object-oriented inter-
face to the CAS, was developed for JAVA. CASes are
crucial for the development and deployment of com-
plex NLP pipelines. All components to be integrated
in UIMA are characterized by abstract input/output
specifications, so-called capabilities. These speci-
fications are declared in terms of descriptors. The
components can be integrated by wrappers conform-
ing with the descriptors. For the integration task, we
define in advance what kind of data each component
may manipulate. This is achieved via the UIMA
annotation type system. This type system follows
the object-oriented paradigm. There are only two
kinds of data, viz. types and features. Features spec-
ify slots within a type, which either have primitive
values such as integers or strings, or have references
to instances of types in the CAS. Types, often called
feature structures, are arranged in an inheritance hi-
erarchy.
In the following section, we propose an ANNO-
TATION TYPE SYSTEM designed and implemented
for an UIMA Tool Suite that will become the back-
bone for our text mining applications. We distin-
guish between the design and implementation lev-
els, talking about the ANNOTATION SCHEME and
the TYPE SYSTEM, respectively.
</bodyText>
<sectionHeader confidence="0.861101" genericHeader="method">
4 Annotation Type System
</sectionHeader>
<bodyText confidence="0.999905133333333">
The ANNOTATION SCHEME we propose currently
consists of five layers: Document Meta, Document
Structure &amp; Style, Morpho-Syntax, Syntax and Se-
mantics. Accordingly, annotation types fall into five
corresponding categories. Document Meta and Doc-
ument Structure &amp; Style contain annotations about
each document’s bibliography, organisation and lay-
out. Morpho-Syntax and Syntax describe the results
of morpho-syntactic and syntactic analysis of texts.
The results of lemmatisation, stemming and decom-
position of words can be represented at this layer, as
well. The annotations from shallow and full parsing
are represented at the Syntax layer. The appropri-
ate types permit the representation of dependency-
and constituency-based parsing results. Semantics
</bodyText>
<page confidence="0.998223">
35
</page>
<figureCaption confidence="0.999286666666667">
Figure 1: Multi-Layered UIMA Annotation Scheme in UML Representation. 1: Basic Feature Structure and
Resource Linking. 2: Document Meta Information. 3: Morpho-Syntax. 4: Syntax. 5: Document Structure
&amp; Style. 6: Semantics.
</figureCaption>
<figure confidence="0.999759235294118">
CAS Core
4
NP
5
Title
1
3
2
PennPOSTag
DBEntry
+docType: uima.cas.String
+source:
uima.cas.String
+docID: uima.cas.String
+language: uima.cas.String
+copyright: uima.cas.String
+authors: uima.cas.FSArray = AuthorInfo
+title: uima.cas.String
+pubTypeList: uima.cas.FSArray = PubType
+...
+title: Title
+depth: uima.cas.Integer
+citationStatus: uima.cas.String {...}
+tagsetId: uima.cas.String
+language: uima.cas.String
+value: uima.cas.String
+source: uima.cas.String
+entryId: uima.cas.String
+version: uima.cas.String
Section
PhraseChunk
POSTag
TextBody
pubmed.Header
Chunk
ResourceEntry
PP
LexiconEntry
Header
Zone
+...
...
...
Paragraph
+syn: uima.cas.String
+...
NounFeats
GENIAConstituent
Misc
+language: uima.cas.String
OntologyEntry
+formFuncDisc: uima.cas.String
+gramRole: uima.cas.String
+adv: uima.cas.String
+misc: uima.cas.String
+map: Constituent
+tpc: uima.cas.Boolean
+nullElement: uima.cas.String
+ref: Constituent
GrammaticalFeats
+ISSN: uima.cas.String
+volume: uima.cas.String
+journalTitle: uima.cas.String
+impactFactor: uima.cas.String
+caption: Caption
PTBConstituent
+name: uima.cas.Sting
...
Figure
Journal
+...
PubType
...
+componentId: uima.cas.String
+confidence: uima.cas.Double
+begin: uima.cas.Integer
+end: uima.cas.Integer
uima.tcas.Annotation
+...
6
Organization
...
Annotation
+keywordList: uima.cas.FSArray = Keyword
+...
+MeSHList: uma.cas.FSArray = MeSHHeading
+...
+posTag: uima.cas.FSArray = POSTag
+lemma: Lemma
+feats: GrammaticalFeats
+stemmedForm: StemmedForm
+depRelList: uima.cas.FSArray = DependencyRelation
+orthogr: uima.cas.FSArray = String
+parent: Constituent
+head: Token
+cat: uima.cas.String
MUCEntity
pubmed.ManualDescriptor
Constituent
Person
+value: String
+dbEntry: uima.cas.FSArray = DBEntry
+ontologyEntry: uima.cas.FSArray = OntologyEntry
+specificType: uima.cas.String
ManualDescriptor
Lemma
Token
...
DepRelationSet...
Cytokine
+value: FSArray = Annotation
Entity
DiscontinuousAnnotation
Descriptor
+head: Token
+projective: uima.cas.Boolean
+label: uima.cas.String
Gene
DependencyRelation
+value: String
StemmedForm
...
Relation
+name: uima.cas.String
+source: uima.cas.String
Organism
+...
AutoDescriptor
BioEntity
+expan: String
Keyword
Abbreviation
Acronym
+...
...
Variation
</figure>
<page confidence="0.992629">
36
</page>
<bodyText confidence="0.994431">
currently covers information about named entities,
events and relations between named entities.
</bodyText>
<subsectionHeader confidence="0.997678">
4.1 Basic Feature Structure
</subsectionHeader>
<bodyText confidence="0.9999822">
All types referring to different linguistic lay-
ers derive from the basic type Annotation,
the root type in the scheme (cf. Figure 1-
1). The Annotation type itself derives infor-
mation from the default UIMA annotation type
uima.tcas.Annotation and, thus, inherits the
basic annotation features, viz. begin and end (mark-
ing spans of annotations in the subject of analysis).
Annotation extends this default feature structure
with additional features. The componentId marks
which NLP component actually computed this an-
notation. This attribute allows to manage multiple
annotations of the same type The unique linkage be-
tween an analysis component and an annotation item
is particularly relevant in cases of parallel annota-
tions. The component from which the annotation
originated also assigns a specific confidence score
to its confidence feature. Each type in the scheme is
at least supplied with these four slots inherited from
their common root type.
</bodyText>
<subsectionHeader confidence="0.991054">
4.2 Document Meta Information
</subsectionHeader>
<bodyText confidence="0.999992">
The Document Meta layer (cf. Figure 1-2) describes
the bibliographical and content information of a doc-
ument. The bibliographical information, often re-
trieved from the header of the analyzed document,
is represented in the type Header. The source
and docID attributes yield a unique identifier for
each document. We then adopted some Dublin Core
elements, e.g., language, title, docType. We dis-
tinguish between domain-independent information
such as language, title, document type and domain-
dependent information as relevant for text mining
in the bio-medical domain. Accordingly, the type
pubmed.Header was especially created for the
representation of PUBMED document information.
A more detailed description of the document’s pub-
lication data is available from types which specialize
PubType such as Journal. The latter contains
standard journal-specific attributes, e.g., ISSN, vol-
ume, journalTitle.
The description of the document’s content of-
ten comes with a list of keywords, informa-
tion assigned to the Descriptor type. We
clearly distinguish between content descriptors man-
ually provided by an author, indexer or cura-
tor, and items automatically generated by text
analysis components after document processing.
While the first kind of information will be stored
in the ManualDescriptor, the second one
will be represented in the AutoDescriptor.
The generation of domain-dependent descriptors is
also possible; currently the scheme contains the
pubmed.ManualDescriptor which allows to
assign attributes such as chemicals and genes.
</bodyText>
<subsectionHeader confidence="0.999403">
4.3 Document Structure &amp; Style
</subsectionHeader>
<bodyText confidence="0.99997076">
The Document Structure &amp; Style layer (cf. Figure 1-
5) contains information about the organization and
layout of the analyzed documents. This layer en-
ables the marking-up of document structures such
as paragraphs, rhetorical zones, figures and tables,
as well as typographical information, such as italics
and special fonts. The focus of modeling this layer is
on the annotation of scientific documents, especially
in the life sciences. We adopted here the SCIXML8
annotation schema, which was especially developed
for marking-up scientific publications. The Zone
type refers to a distinct division of text and is the par-
ent type for various subtypes such as TextBody,
Title etc. While it seems impossible to predict all
of the potential formal text segments, we first looked
at types of text zones frequently occurring in sci-
entific documents. The type Section, e.g., repre-
sents a straightforward and fairly standard division
of scientific texts into introduction, methods and re-
sults sections. The divisions not covered by current
types can be annotated with Misc. The annotation
of tables and figures with corresponding types en-
ables to link text and additional non-textual infor-
mation, an issue which is gaining more and more
attention in the text mining field.
</bodyText>
<subsectionHeader confidence="0.998034">
4.4 Morpho-Syntax
</subsectionHeader>
<bodyText confidence="0.9999098">
The Morpho-Syntax layer (cf. Figure 1-3) represents
the results of morpho-syntactic analysis such as to-
kenization, stemming, POS tagging. The small-
est annotation unit is Token which consists of five
attributes, including its part-of-speech information
</bodyText>
<footnote confidence="0.966081">
8http://www.cl.cam.ac.uk/˜aac10/
escience/sciborg.html
</footnote>
<page confidence="0.999622">
37
</page>
<bodyText confidence="0.999956603174603">
(posTag), stemmedForm, lemma, grammatical fea-
tures (feats), and orthographical information (or-
thogr).
With respect to already available POS tagsets,
the scheme allows corresponding extensions of
the supertype POSTag to, e.g., PennPOSTag
(for the Penn Tag Set (Marcus et al., 1993)) or
GeniaPOSTag (for the GENIA Tag Set (Ohta et
al., 2002)). The attribute tagsetId serves as a unique
identifier of the corresponding tagset. The value of
the POS tag (e.g., NN, VVD, CC) can be stored in
the attribute value. The potential values for the in-
stantiation of this attribute are always restricted to
the tags of the associated tagset. These constraints
enforce formal control on annotation processes.
As for morphologically normalized lexical items,
the Lemma type stores the canonical form of a lexi-
cal token which can be retrieved from a lexicon once
it is computed by a lemmatizer. The lemma value,
e.g., for the verb ‘activates’ would be ‘activate’. The
StemmedForm represents a base form of a text to-
ken as produced by stemmers (e.g., ‘activat-’ for the
noun ‘activation’).
Due to their excessive use in life science docu-
ments, abbreviations, acronyms and their expanded
forms have to be considered in terms of appropriate
types, as well. Accordingly, Abbreviation and
Acronym are defined, the latter one being a child
type of the first one. The expanded form of a short
one can easily be accessed from the attribute expan.
Grammatical features of tokens are represented
in those types which specialize the supertype
GrammaticalFeats. Its child types, viz.
NounFeats,VerbFeats,AdjectiveFeats,
PronounFeats (omitted from Figure 1-3) cover
the most important word categories. Attributes
of these types obviously reflect the properties
of particular grammatical categories. While
NounFeats comes with gender, case and num-
ber only, PronounFeats must be enhanced with
person. A more complex feature structure is asso-
ciated with VerbFeats which requires attributes
such as tense, person, number, voice and aspect. We
adapted here specifications from the TEI to allow
compatibility with other annotation schemata.
The type LexiconEntry (cf. Figure 1-1) en-
ables a link to the lexicon of choice. By designing
this type we achieve much needed flexibility in link-
ing text snaps (e.g., tokens, simplex forms, multi-
word terms) to external resources. The attributes
entryId and source yield, in combination, a unique
identifier of the current lexicon entry. Resource ver-
sion control is enabled through an attribute version.
Text annotations often mark disrupted text spans,
so-called discontinuous annotations. In coordinated
structures such as ‘T and B cell’, the annotator
should mark two named entities, viz. ‘T cell’ and ‘B
cell’, where the first one results from the combina-
tion of the disjoint parts ‘T’ and ‘cell’. In order to
represent such discontinous annotations, we intro-
duced the type DiscontinuousAnnotation
(cf. Figure 1-1) which links through its attribute
value spans of annotations to an annotation unit.
</bodyText>
<subsectionHeader confidence="0.977628">
4.5 Syntax
</subsectionHeader>
<bodyText confidence="0.999518516129032">
This layer of the scheme provides the types and at-
tributes for the representation of syntactic structures
of sentences (cf. Figure 1-4). The results from shal-
low and full parsing can be stored here.
Shallow parsing (chunking) aims at dividing
the flow of text into phrases (chunks) in a non-
overlapping and non-recursive manner. The type
Chunk accounts for different chunk tag sets by sub-
typing. Currently, the scheme supports Phrase-
Chunks with subtypes such as NP, VP, PP, or ADJP
(Marcus et al., 1993).
The scheme also reflects the most popular full
parsing approaches in NLP, viz. constituent-based
and dependency-based approaches. The results
from constituent-based parsing are represented in
a parse tree and can be stored as single nodes in
the Constituent type. The tree structure can
be reconstructed through links in the attribute par-
ent which stores the id of the parent constituent.
Besides the attribute parent, Constituent holds
the attributes cat which stores the complex syntac-
tic category of the current constituent (e.g., NP, VP),
and head which links to the head word of the con-
stituent. In order to account for multiple annota-
tions in the constituent-based approach, we intro-
duced corresponding constituent types which spe-
cialize Constituent. This parallels our approach
which we advocate for alternatives in POS tagging
and the management of alternative chunking results.
Currently, the scheme supports three differ-
ent constituent types, viz. PTBConstituent,
</bodyText>
<page confidence="0.997972">
38
</page>
<bodyText confidence="0.999631323529412">
GENIAConstituent (Miyao and Tsujii, 2005)
and PennBIoIEConstituent. The attributes
of the type PTBConstituent cover the com-
plete repertoire of annotation items contained in
the Penn Treebank, such as functional tags for
form/function dicrepancies (formFuncDisc), gram-
matical role (gramRole), adverbials (adv) and mis-
cellaneous tags (misc). The representation of null
elements, topicalized elements and gaps with corre-
sponding references to the lexicalized elements in a
tree is reflected in attributes nullElement, tpc, map
and ref, respectively. GENIAConstituent and
PennBIoIEConstituent inherit from PTB-
Constituent all listed attributes and provide, in
the case of GENIAConstituent , an additional
attribute syn to specify the syntactic idiosyncrasy
(coordination) of constituents.
Dependency parsing results are directly linked to
the token level and are thus referenced in the Token
type. The DependencyRelation type inherits
from the general Relation type and introduces
additional features which are necessary for describ-
ing a syntactic dependency. The attribute label char-
acterizes the type of the analyzed dependency rela-
tion. The attribute head indicates the head of the
dependency relation attributed to the analyzed to-
ken. The attribute projective relates to the property
of the dependency relation whether it is projective
or not. As different dependency relation sets can be
used for parsing, we propose subtyping similar to
the constituency-based parsing approaches. In order
to account for alternative dependency relation sets,
we aggregate all possible annotations in the Token
type as a list (depRelList).
</bodyText>
<subsectionHeader confidence="0.96747">
4.6 Semantics
</subsectionHeader>
<bodyText confidence="0.999796133333333">
The Semantics layer comprises currently the repre-
sentation of named entities, particularly for the bio-
medical domain. The entity types are hierarchically
organized. The supertype Entity (cf. Figure 1-
6) links annotated (named) entities to the ontologies
and databases through appropriate attributes, viz. on-
tologyEntry and sdbEntry. The attribute specific-
Type specifies the analyzed entity in a more detailed
way (e.g., Organism can be specified through
the species values ‘human’, ‘mouse’, ‘rat’, etc.)
The subtypes are currently being developed in the
bio-medical domain and cover, e.g., genes, pro-
teins, organisms, diseases, variations. This hierar-
chy can easily be extended or supplemented with
entities from other domains. For illustration pur-
poses, we extended it here by MUC (Grishman
and Sundheim, 1996) entity types such as Person,
Organization, etc.
This scheme is still under construction and will
soon also incorporate the representation of relation-
ships between entities and domain-specific events.
The general type Relation will then be extended
with specific conceptual relations such as location,
part-of, etc. The representation of events will be
covered by a type which aggregates pre-defined re-
lations between entities and the event mention. An
event type such as InhibitionEvent would link
the text spans in the sentence ‘protein A inhibits
protein B’ in attributes agent (‘protein A’), patient
(‘protein B’), mention (‘inhibits’).
</bodyText>
<sectionHeader confidence="0.991028" genericHeader="conclusions">
5 Conclusion and Future work
</sectionHeader>
<bodyText confidence="0.999899962962963">
In this paper, we introduced an UIMA annotation
type system which covers the core functionality
of morphological, syntactic and semantic analysis
components of a generic NLP system. It also in-
cludes type specifications which relate to the formal
document format and document style. Hence, the
design of this scheme allows the annotation of the
entire cycle of (sentence-level) NLP analysis (dis-
course phenomena still have to be covered).
The annotation scheme consists mostly of core
types which are designed in a domain-independent
way. Nevertheless, it can easily be extended with
types which fit other needs. The current scheme sup-
plies an extension for the bio-medical domain at the
document meta and structure level, as well as on the
semantic level. The morpho-syntactic and syntactic
levels provide types needed for the analysis of the
English language. Changes of attributes or attribute
value sets will lead to adaptations to other natural
languages.
We implemented the scheme as an UIMA type
system. The formal specifications are implemented
using the UIMA run-time environment. This direct
link of formal and implementational issues is a ma-
jor asset using UIMA unmatched by any previous
specification approach. Furthermore, all annotation
results can be converted to the XMI format within
</bodyText>
<page confidence="0.997897">
39
</page>
<bodyText confidence="0.9983429">
the UIMA framework. XMI, the XML Metadata In-
terchange format, is an OMG9 standard for the XML
representation of object graphs.
The scheme also eases the representation of an-
notation results for the same task with alternative
and often competitive components. The identifica-
tion of the component which provided specific an-
notations can be retrieved from the attribute com-
ponentId. Furthermore, the annotation with alterna-
tive and multiple tag sets is supported as well. We
have designed for each tag set a type representing
the corresponding annotation parameters. The inher-
itance trees at almost all annotation layers support
the parallelism in annotation process (e.g., tagging
may proceed with different POS tagsets).
The user of the scheme can restrict the potential
values of the types or attributes. The current scheme
makes use of the customization capability for POS
tagsets, for all attributes of constituents and chunks.
This yields additional flexibility in the design and,
once specified, an increased potential for automatic
control for annotations.
The scheme also enables a straightforward con-
nection to external resources such as ontologies,
lexicons, and databases as evidenced by the corre-
sponding subtypes ofResourceEntry (cf. Figure
1-1). These types support the specification of a re-
lation between a concrete text span and the unique
item addressed in any of these resources.
With these considerations in mind, we strive for
the elaboration of a common standard UIMA type
system for NLP engines. The advantages of such a
standard include an easy exchange and integration
of different NLP analysis engines, the facilitation
of sophisticated evaluation studies (where, e.g., al-
ternative components for NLP tasks can be plugged
in and out at the spec level), and the reusability of
single NLP components developed in various labs.
Acknowledgments. This research was funded by the EC´s 6th Framework Programme
(4th call) within the BOOTStrep project under grant FP6-028099.
</bodyText>
<sectionHeader confidence="0.999323" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996145313432836">
S. Brants and S. Hansen. 2002. Developments in the TIGER
annotation scheme and their realization in the corpus. In
Proc. of the 3rd LREC Conference, pages 1643–1649.
P. Buitelaar, T. Declerck, B. Sacaleanu, ˇS. Vintar, D. Raileanu,
and C. Crispi. 2003. A multi-layered, XML-based approach
9http://www.omg.org
to the integration of linguistic and semantic annotations. In
Proc. ofEACL 2003 Workshop NLP%ML-03.
H. Cunningham. 2002. GATE, a general architecture for text
engineering. Computers and the Humanities, 36:223–254.
T. Declerck. 2006. SYNAF: Towards a standard for syntactic
annotation. In Proc. of the 5th LREC Conference.
G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw,
S. Strassel, and R. Weischedel. 2004. The Automatic Con-
tent Extraction (ACE) Program. In Proc. of the 4th LREC
Conference, pages 837–840.
D. Ferrucci and A. Lally. 2004. UIMA: an architectural ap-
proach to unstructured information processing in the corpo-
rate research environment. Natural Language Engineering,
10(3-4):327–348.
T. G¨otz and O. Suhre. 2004. Design and implementation of the
UIMA Common Analysis System. IBM Systems Journal,
43(3):476–489.
R. Grishman and B. Sundheim. 1996. Message Understand-
ing Conference – 6: A brief history. In Proc. of the 16th
COLING, pages 466–471.
R. Grishman. 1997. Tipster architecture design document,
version 2.3. Technical report, Defense Advanced Research
Projects Agency (DARPA), U.S. Departement of Defense.
C. Grover, E. Klein, M. Lapata, and A. Lascarides. 2002.
XML-based NLP tools for analysing and annotating medi-
cal language. In Proc. of the 2nd Workshop NLP%ML-2002,
pages 1–8.
U. Hahn and J. Wermter. 2006. Levels of natural language pro-
cessing for text mining. In S. Ananiadou and J. McNaught,
editors, Text Miningfor Biology and Biomedicine, pages 13–
41. Artech House.
N. Ide, P. Bonhomme, and L. Romary. 2000. XCES: An XML-
based standard for linguistic corpora. In Proc. of the 2nd
LREC Conference, pages 825–830.
N. Ide, L. Romary, and E. de la Clergerie. 2003. International
standard for a linguistic annotation framework. In Proc. of
the HLT-NAACL 2003 SEALTS Workshop, pages 25–30.
C. Laprun, J. Fiscus, J. Garofolo, and S. Pajot. 2002. A prac-
tical introduction to ATLAS. In Proc. of the 3rd LREC Con-
ference, pages 1928–1932.
M. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993.
Building a large annotated corpus of English: The PENN
TREEBANK. Computational Linguistics, 19(2):313–330.
A. Meyers. 2006. Annotation compatibility working group re-
port. In Proc. of the COLING-ACL 2006 Workshop FLAC
2006’, pages 38–53.
Y. Miyao and J. Tsujii. 2005. Probabilistic disambiguation
models for wide-coverage HPSG parsing. In Proc. of the
ACL 2005, pages 83 – 90.
T. Ohta, Y. Tateisi, and J.-D. Kim. 2002. The GENIA corpus:
An annotated research abstract corpus in molecular biology
domain. In Proc. of the 2nd HLT, pages 82–86.
E. Pianta, L. Bentivogli, C. Girardi, and B. Magnini. 2006.
Representing and accessing multilevel linguistic annotation
using the MEANING format. In Proc. of the 5th EACL-2006
Workshop NLP%ML-2006, pages 77–80.
J. Rumbaugh, I. Jacobson, and G. Booch. 1999. The Unified
Modeling Language Reference Manual. Addison-Wesley.
U. Sch¨afer. 2006. Middleware for creating and combining
multi-dimensional NLP markup. In Proc. of the 5th EACL-
2006 Workshop NLP%ML-2006, pages 81–84.
</reference>
<page confidence="0.998629">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.329897">
<title confidence="0.999475">An Annotation Type System for a Data-Driven NLP Pipeline</title>
<author confidence="0.994037">Udo Hahn Ekaterina Buyko Katrin</author>
<affiliation confidence="0.999082">Jena University Language &amp; Information Engineering (JULIE)</affiliation>
<address confidence="0.787007">F¨urstengraben 30, 07743 Jena,</address>
<author confidence="0.880149">Scott Piao John McNaught Yoshimasa Tsuruoka Sophia</author>
<affiliation confidence="0.976579">NaCTeM and School of Computer University of</affiliation>
<abstract confidence="0.931539888888889">We introduce an annotation type system for a data-driven NLP core system. The specifications cover formal document structure and document meta information, as well as the linguistic levels of morphology, syntax and semantics. The type system is embedded in the framework of the Unstructured Information Management Architecture (UIMA).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Brants</author>
<author>S Hansen</author>
</authors>
<title>Developments in the TIGER annotation scheme and their realization in the corpus.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd LREC Conference,</booktitle>
<pages>1643--1649</pages>
<contexts>
<context position="4876" citStr="Brants and Hansen, 2002" startWordPosition="736" endWordPosition="739">ional) linguistics proper, syntactic annotation schemes, such as the one from the Penn Treebank (Marcus et al., 1993), or semantic annotations, such as the one underlying ACE (Doddington et al., 2004), are increasingly being used in a quasi standard way. In recent years, however, the NLP community is trying to combine and merge different kinds of annotations for single linguistic layers. XML formats play a central role here. An XML-based encoding standard for linguistic corpora XCES (Ide et al., 2000) is based on CES (Corpus Encoding Standard) as part of the EAGLES Guidelines.5 Work on TIGER (Brants and Hansen, 2002) is an example for the liaison of dependency- and constituent-based syntactic annotations. New standardization efforts such as the Syntactic Annotation Framework (SYNAF) (Declerck, 2006) aim to combine different proposals and create standards for syntactic annotation. We also encounter a tendency towards multiple annotations for a single corpus. Major bio-medical corpora, such as GENIA (Ohta et al., 2002) or PennBioIE,6 combine several layers of linguistic information in terms of morpho-syntactic, syntactic and semantic annotations (named entities and events). In the meantime, the Annotation C</context>
</contexts>
<marker>Brants, Hansen, 2002</marker>
<rawString>S. Brants and S. Hansen. 2002. Developments in the TIGER annotation scheme and their realization in the corpus. In Proc. of the 3rd LREC Conference, pages 1643–1649.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Buitelaar</author>
<author>T Declerck</author>
<author>B Sacaleanu</author>
<author>ˇS Vintar</author>
<author>D Raileanu</author>
<author>C Crispi</author>
</authors>
<title>A multi-layered, XML-based approach to the integration of linguistic and semantic annotations.</title>
<date>2003</date>
<booktitle>In Proc. ofEACL 2003 Workshop NLP%ML-03.</booktitle>
<contexts>
<context position="6897" citStr="Buitelaar et al., 2003" startWordPosition="1029" endWordPosition="1032">2006) combines multidimensional mark-up produced by several NLP components. An XML-based NLP tool suite for analyzing and annotating medical language in an NLP pipeline was also proposed by (Grover et al., 2002). All these proposals share their explicit linkage to a specific NLP tool suite or NLP system and thus lack a generic annotation framework that can be re-used in other developmental environments. Buitelaar et al. developed in the context of an information extraction project an XML-based multilayered annotation scheme that covers morphosyntactic, shallow parsing and semantic annotation (Buitelaar et al., 2003). Their scheme borrows concepts from object-oriented programming (e.g., abstract types, polymorphism). The object-oriented perspective already allows the development of a domain-independent schema and extensions of core types without affecting the base schema. This schema is comprehensive indeed and covers a significant part of advanced NLP pipelines but it is also not connected to a generic framework. It is our intention to come full circle within a general annotation framework. Accordingly, we cover a significant part of the NLP pipeline from document meta information and formal document str</context>
</contexts>
<marker>Buitelaar, Declerck, Sacaleanu, Vintar, Raileanu, Crispi, 2003</marker>
<rawString>P. Buitelaar, T. Declerck, B. Sacaleanu, ˇS. Vintar, D. Raileanu, and C. Crispi. 2003. A multi-layered, XML-based approach to the integration of linguistic and semantic annotations. In Proc. ofEACL 2003 Workshop NLP%ML-03.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cunningham</author>
</authors>
<title>GATE, a general architecture for text engineering. Computers and the Humanities,</title>
<date>2002</date>
<pages>36--223</pages>
<contexts>
<context position="2678" citStr="Cunningham, 2002" startWordPosition="389" endWordPosition="390">hese requirements are best met by properly identifying input/output capabilities of constituent components and by specifying a general data model (e.g., based on UML (Rumbaugh et al., 1999)) in order to get rid of the low-level implementation (i.e., coding) layer. A particularly promising proposal along this line of thought is the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004) originating from IBM research activities.1 UIMA is but the latest attempt in a series of proposals concerned with more generic NLP engines such as ATLAS (Laprun et al., 2002) or GATE (Cunningham, 2002). These frameworks have in common a data-driven architecture and a data model based on annotation graphs as an adaptation of the TIPSTER architecture (Grishman, 1997). They suffer, however, from a lack of standards for data exchange and abstraction mechanisms at the level of specification languages. This can be achieved by the definition of a common annotation scheme. We propose an UIMA schema which accounts for a significant part of the complete NLP cycle – from the collection of documents and their internal formal structure, via sentence splitting, tokenization, POS tagging, and parsing, up </context>
</contexts>
<marker>Cunningham, 2002</marker>
<rawString>H. Cunningham. 2002. GATE, a general architecture for text engineering. Computers and the Humanities, 36:223–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Declerck</author>
</authors>
<title>SYNAF: Towards a standard for syntactic annotation.</title>
<date>2006</date>
<booktitle>In Proc. of the 5th LREC Conference.</booktitle>
<contexts>
<context position="5062" citStr="Declerck, 2006" startWordPosition="764" endWordPosition="766">2004), are increasingly being used in a quasi standard way. In recent years, however, the NLP community is trying to combine and merge different kinds of annotations for single linguistic layers. XML formats play a central role here. An XML-based encoding standard for linguistic corpora XCES (Ide et al., 2000) is based on CES (Corpus Encoding Standard) as part of the EAGLES Guidelines.5 Work on TIGER (Brants and Hansen, 2002) is an example for the liaison of dependency- and constituent-based syntactic annotations. New standardization efforts such as the Syntactic Annotation Framework (SYNAF) (Declerck, 2006) aim to combine different proposals and create standards for syntactic annotation. We also encounter a tendency towards multiple annotations for a single corpus. Major bio-medical corpora, such as GENIA (Ohta et al., 2002) or PennBioIE,6 combine several layers of linguistic information in terms of morpho-syntactic, syntactic and semantic annotations (named entities and events). In the meantime, the Annotation Compatibility Working Group (Meyers, 2006) began to concentrate its activities on the mutual compatibility of annotation schemata for, e.g., POS tagging, treebanking, role labeling, time </context>
</contexts>
<marker>Declerck, 2006</marker>
<rawString>T. Declerck. 2006. SYNAF: Towards a standard for syntactic annotation. In Proc. of the 5th LREC Conference.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Doddington</author>
<author>A Mitchell</author>
<author>M Przybocki</author>
<author>L Ramshaw</author>
<author>S Strassel</author>
<author>R Weischedel</author>
</authors>
<title>The Automatic Content Extraction (ACE) Program.</title>
<date>2004</date>
<booktitle>In Proc. of the 4th LREC Conference,</booktitle>
<pages>837--840</pages>
<contexts>
<context position="4452" citStr="Doddington et al., 2004" startWordPosition="664" endWordPosition="667"> a long-standing tradition in the NLP community. In the very beginning, this work often focused exclusively on subdomains of text analysis such as document structure meta-information, syntactic or semantic analysis. The Text Encoding Initiative (TEI)2 provided schemata for the exchange of documents of various genres. The Dublin Core Metadata Initiative3 established a de facto standard for the Semantic Web.4 For (computational) linguistics proper, syntactic annotation schemes, such as the one from the Penn Treebank (Marcus et al., 1993), or semantic annotations, such as the one underlying ACE (Doddington et al., 2004), are increasingly being used in a quasi standard way. In recent years, however, the NLP community is trying to combine and merge different kinds of annotations for single linguistic layers. XML formats play a central role here. An XML-based encoding standard for linguistic corpora XCES (Ide et al., 2000) is based on CES (Corpus Encoding Standard) as part of the EAGLES Guidelines.5 Work on TIGER (Brants and Hansen, 2002) is an example for the liaison of dependency- and constituent-based syntactic annotations. New standardization efforts such as the Syntactic Annotation Framework (SYNAF) (Decle</context>
</contexts>
<marker>Doddington, Mitchell, Przybocki, Ramshaw, Strassel, Weischedel, 2004</marker>
<rawString>G. Doddington, A. Mitchell, M. Przybocki, L. Ramshaw, S. Strassel, and R. Weischedel. 2004. The Automatic Content Extraction (ACE) Program. In Proc. of the 4th LREC Conference, pages 837–840.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Ferrucci</author>
<author>A Lally</author>
</authors>
<title>UIMA: an architectural approach to unstructured information processing in the corporate research environment.</title>
<date>2004</date>
<journal>Natural Language Engineering,</journal>
<pages>10--3</pages>
<contexts>
<context position="2476" citStr="Ferrucci and Lally, 2004" startWordPosition="352" endWordPosition="355">osen for the same functional task a ‘data conversion’ problem is created which should be solved at the abstract specification level as well (Ide et al., 2003). Software engineering methodology points out that these requirements are best met by properly identifying input/output capabilities of constituent components and by specifying a general data model (e.g., based on UML (Rumbaugh et al., 1999)) in order to get rid of the low-level implementation (i.e., coding) layer. A particularly promising proposal along this line of thought is the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004) originating from IBM research activities.1 UIMA is but the latest attempt in a series of proposals concerned with more generic NLP engines such as ATLAS (Laprun et al., 2002) or GATE (Cunningham, 2002). These frameworks have in common a data-driven architecture and a data model based on annotation graphs as an adaptation of the TIPSTER architecture (Grishman, 1997). They suffer, however, from a lack of standards for data exchange and abstraction mechanisms at the level of specification languages. This can be achieved by the definition of a common annotation scheme. We propose an UIMA schema w</context>
<context position="7921" citStr="Ferrucci and Lally, 2004" startWordPosition="1175" endWordPosition="1178">ework. It is our intention to come full circle within a general annotation framework. Accordingly, we cover a significant part of the NLP pipeline from document meta information and formal document structure, morpho-syntactic and syntactic analysis up to semantic processing. The scheme we propose is intended to be compatible with on-going work in standardization efforts from task-specific annotations and to adhere to object-oriented principles. 3 Data-Driven NLP Architecture As the framework for our specification efforts, we adopted the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004). It provides a formal specification layer based on UML, as well as a run-time environment for the interpretation and use of these specifications. This dualism is going to attract more and more researchers as a basis 34 for proper NLP system engineering. 3.1 UIMA-based Tool Suite UIMA provides a platfrom for the integration of NLP components (ANALYSIS ENGINES in the UIMA jargon) and the deployment of complex NLP pipelines. It is more powerful than other prominent software systems for language engineering (e.g., GATE, ATLAS) as far as its pre- and post-processing facilities are concerned — so-c</context>
</contexts>
<marker>Ferrucci, Lally, 2004</marker>
<rawString>D. Ferrucci and A. Lally. 2004. UIMA: an architectural approach to unstructured information processing in the corporate research environment. Natural Language Engineering, 10(3-4):327–348.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T G¨otz</author>
<author>O Suhre</author>
</authors>
<title>Design and implementation of the UIMA Common Analysis System.</title>
<date>2004</date>
<journal>IBM Systems Journal,</journal>
<volume>43</volume>
<issue>3</issue>
<marker>G¨otz, Suhre, 2004</marker>
<rawString>T. G¨otz and O. Suhre. 2004. Design and implementation of the UIMA Common Analysis System. IBM Systems Journal, 43(3):476–489.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
<author>B Sundheim</author>
</authors>
<title>Message Understanding Conference – 6: A brief history.</title>
<date>1996</date>
<booktitle>In Proc. of the 16th COLING,</booktitle>
<pages>466--471</pages>
<contexts>
<context position="26087" citStr="Grishman and Sundheim, 1996" startWordPosition="3799" endWordPosition="3802">y (cf. Figure 1- 6) links annotated (named) entities to the ontologies and databases through appropriate attributes, viz. ontologyEntry and sdbEntry. The attribute specificType specifies the analyzed entity in a more detailed way (e.g., Organism can be specified through the species values ‘human’, ‘mouse’, ‘rat’, etc.) The subtypes are currently being developed in the bio-medical domain and cover, e.g., genes, proteins, organisms, diseases, variations. This hierarchy can easily be extended or supplemented with entities from other domains. For illustration purposes, we extended it here by MUC (Grishman and Sundheim, 1996) entity types such as Person, Organization, etc. This scheme is still under construction and will soon also incorporate the representation of relationships between entities and domain-specific events. The general type Relation will then be extended with specific conceptual relations such as location, part-of, etc. The representation of events will be covered by a type which aggregates pre-defined relations between entities and the event mention. An event type such as InhibitionEvent would link the text spans in the sentence ‘protein A inhibits protein B’ in attributes agent (‘protein A’), pati</context>
</contexts>
<marker>Grishman, Sundheim, 1996</marker>
<rawString>R. Grishman and B. Sundheim. 1996. Message Understanding Conference – 6: A brief history. In Proc. of the 16th COLING, pages 466–471.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Grishman</author>
</authors>
<title>Tipster architecture design document, version 2.3.</title>
<date>1997</date>
<tech>Technical report,</tech>
<institution>Defense Advanced Research Projects Agency (DARPA), U.S. Departement of Defense.</institution>
<contexts>
<context position="2844" citStr="Grishman, 1997" startWordPosition="414" endWordPosition="415">umbaugh et al., 1999)) in order to get rid of the low-level implementation (i.e., coding) layer. A particularly promising proposal along this line of thought is the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004) originating from IBM research activities.1 UIMA is but the latest attempt in a series of proposals concerned with more generic NLP engines such as ATLAS (Laprun et al., 2002) or GATE (Cunningham, 2002). These frameworks have in common a data-driven architecture and a data model based on annotation graphs as an adaptation of the TIPSTER architecture (Grishman, 1997). They suffer, however, from a lack of standards for data exchange and abstraction mechanisms at the level of specification languages. This can be achieved by the definition of a common annotation scheme. We propose an UIMA schema which accounts for a significant part of the complete NLP cycle – from the collection of documents and their internal formal structure, via sentence splitting, tokenization, POS tagging, and parsing, up until the semantic layer (still excluding discourse) – and which aims at the implementationindependent specification of a core NLP system. 1Though designed for any so</context>
</contexts>
<marker>Grishman, 1997</marker>
<rawString>R. Grishman. 1997. Tipster architecture design document, version 2.3. Technical report, Defense Advanced Research Projects Agency (DARPA), U.S. Departement of Defense.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Grover</author>
<author>E Klein</author>
<author>M Lapata</author>
<author>A Lascarides</author>
</authors>
<title>XML-based NLP tools for analysing and annotating medical language.</title>
<date>2002</date>
<booktitle>In Proc. of the 2nd Workshop NLP%ML-2002,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="6485" citStr="Grover et al., 2002" startWordPosition="963" endWordPosition="966">lc.cnr.it/EAGLES96/ 6http://bioie.ldc.upenn.edu NLP pipeline as needed, e.g., for information extraction or text mining tasks (Hahn and Wermter, 2006). This lack is mainly due to missing standards for specifying comprehensive NLP software architectures. The MEANING format (Pianta et al., 2006) is designed to integrate different levels of morphosyntactic annotations. The HEART OF GOLD middleware (Sch¨afer, 2006) combines multidimensional mark-up produced by several NLP components. An XML-based NLP tool suite for analyzing and annotating medical language in an NLP pipeline was also proposed by (Grover et al., 2002). All these proposals share their explicit linkage to a specific NLP tool suite or NLP system and thus lack a generic annotation framework that can be re-used in other developmental environments. Buitelaar et al. developed in the context of an information extraction project an XML-based multilayered annotation scheme that covers morphosyntactic, shallow parsing and semantic annotation (Buitelaar et al., 2003). Their scheme borrows concepts from object-oriented programming (e.g., abstract types, polymorphism). The object-oriented perspective already allows the development of a domain-independen</context>
</contexts>
<marker>Grover, Klein, Lapata, Lascarides, 2002</marker>
<rawString>C. Grover, E. Klein, M. Lapata, and A. Lascarides. 2002. XML-based NLP tools for analysing and annotating medical language. In Proc. of the 2nd Workshop NLP%ML-2002, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>J Wermter</author>
</authors>
<title>Levels of natural language processing for text mining.</title>
<date>2006</date>
<booktitle>Text Miningfor Biology and Biomedicine,</booktitle>
<pages>13--41</pages>
<editor>In S. Ananiadou and J. McNaught, editors,</editor>
<publisher>Artech House.</publisher>
<contexts>
<context position="6015" citStr="Hahn and Wermter, 2006" startWordPosition="891" endWordPosition="894"> semantic annotations (named entities and events). In the meantime, the Annotation Compatibility Working Group (Meyers, 2006) began to concentrate its activities on the mutual compatibility of annotation schemata for, e.g., POS tagging, treebanking, role labeling, time annotation, etc. The goal of these initiatives, however, has never been to design an annotation scheme for a complete 2http://www.tei-c.org 3http://dublincore.org 4http://www.w3.org/2001/sw 5http://www.ilc.cnr.it/EAGLES96/ 6http://bioie.ldc.upenn.edu NLP pipeline as needed, e.g., for information extraction or text mining tasks (Hahn and Wermter, 2006). This lack is mainly due to missing standards for specifying comprehensive NLP software architectures. The MEANING format (Pianta et al., 2006) is designed to integrate different levels of morphosyntactic annotations. The HEART OF GOLD middleware (Sch¨afer, 2006) combines multidimensional mark-up produced by several NLP components. An XML-based NLP tool suite for analyzing and annotating medical language in an NLP pipeline was also proposed by (Grover et al., 2002). All these proposals share their explicit linkage to a specific NLP tool suite or NLP system and thus lack a generic annotation f</context>
</contexts>
<marker>Hahn, Wermter, 2006</marker>
<rawString>U. Hahn and J. Wermter. 2006. Levels of natural language processing for text mining. In S. Ananiadou and J. McNaught, editors, Text Miningfor Biology and Biomedicine, pages 13– 41. Artech House.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>P Bonhomme</author>
<author>L Romary</author>
</authors>
<title>XCES: An XMLbased standard for linguistic corpora.</title>
<date>2000</date>
<booktitle>In Proc. of the 2nd LREC Conference,</booktitle>
<pages>825--830</pages>
<contexts>
<context position="4758" citStr="Ide et al., 2000" startWordPosition="716" endWordPosition="719">nres. The Dublin Core Metadata Initiative3 established a de facto standard for the Semantic Web.4 For (computational) linguistics proper, syntactic annotation schemes, such as the one from the Penn Treebank (Marcus et al., 1993), or semantic annotations, such as the one underlying ACE (Doddington et al., 2004), are increasingly being used in a quasi standard way. In recent years, however, the NLP community is trying to combine and merge different kinds of annotations for single linguistic layers. XML formats play a central role here. An XML-based encoding standard for linguistic corpora XCES (Ide et al., 2000) is based on CES (Corpus Encoding Standard) as part of the EAGLES Guidelines.5 Work on TIGER (Brants and Hansen, 2002) is an example for the liaison of dependency- and constituent-based syntactic annotations. New standardization efforts such as the Syntactic Annotation Framework (SYNAF) (Declerck, 2006) aim to combine different proposals and create standards for syntactic annotation. We also encounter a tendency towards multiple annotations for a single corpus. Major bio-medical corpora, such as GENIA (Ohta et al., 2002) or PennBioIE,6 combine several layers of linguistic information in terms </context>
</contexts>
<marker>Ide, Bonhomme, Romary, 2000</marker>
<rawString>N. Ide, P. Bonhomme, and L. Romary. 2000. XCES: An XMLbased standard for linguistic corpora. In Proc. of the 2nd LREC Conference, pages 825–830.</rawString>
</citation>
<citation valid="true">
<authors>
<author>N Ide</author>
<author>L Romary</author>
<author>E de la Clergerie</author>
</authors>
<title>International standard for a linguistic annotation framework.</title>
<date>2003</date>
<booktitle>In Proc. of the HLT-NAACL 2003 SEALTS Workshop,</booktitle>
<pages>25--30</pages>
<contexts>
<context position="2009" citStr="Ide et al., 2003" startWordPosition="282" endWordPosition="285">those single modules which serve, by and large, the same functionality? Second, how can we build NLP systems by composing them, at the abstract level of functional specification, from these already existing component building blocks disregarding concrete implementation matters? Yet another burning issue relates to the increasing availability of multiple metadata annotations both in corpora and language processors. If alternative annotation tag sets are chosen for the same functional task a ‘data conversion’ problem is created which should be solved at the abstract specification level as well (Ide et al., 2003). Software engineering methodology points out that these requirements are best met by properly identifying input/output capabilities of constituent components and by specifying a general data model (e.g., based on UML (Rumbaugh et al., 1999)) in order to get rid of the low-level implementation (i.e., coding) layer. A particularly promising proposal along this line of thought is the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004) originating from IBM research activities.1 UIMA is but the latest attempt in a series of proposals concerned with more generic NLP e</context>
</contexts>
<marker>Ide, Romary, Clergerie, 2003</marker>
<rawString>N. Ide, L. Romary, and E. de la Clergerie. 2003. International standard for a linguistic annotation framework. In Proc. of the HLT-NAACL 2003 SEALTS Workshop, pages 25–30.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Laprun</author>
<author>J Fiscus</author>
<author>J Garofolo</author>
<author>S Pajot</author>
</authors>
<title>A practical introduction to ATLAS.</title>
<date>2002</date>
<booktitle>In Proc. of the 3rd LREC Conference,</booktitle>
<pages>1928--1932</pages>
<contexts>
<context position="2651" citStr="Laprun et al., 2002" startWordPosition="383" endWordPosition="386"> methodology points out that these requirements are best met by properly identifying input/output capabilities of constituent components and by specifying a general data model (e.g., based on UML (Rumbaugh et al., 1999)) in order to get rid of the low-level implementation (i.e., coding) layer. A particularly promising proposal along this line of thought is the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004) originating from IBM research activities.1 UIMA is but the latest attempt in a series of proposals concerned with more generic NLP engines such as ATLAS (Laprun et al., 2002) or GATE (Cunningham, 2002). These frameworks have in common a data-driven architecture and a data model based on annotation graphs as an adaptation of the TIPSTER architecture (Grishman, 1997). They suffer, however, from a lack of standards for data exchange and abstraction mechanisms at the level of specification languages. This can be achieved by the definition of a common annotation scheme. We propose an UIMA schema which accounts for a significant part of the complete NLP cycle – from the collection of documents and their internal formal structure, via sentence splitting, tokenization, PO</context>
</contexts>
<marker>Laprun, Fiscus, Garofolo, Pajot, 2002</marker>
<rawString>C. Laprun, J. Fiscus, J. Garofolo, and S. Pajot. 2002. A practical introduction to ATLAS. In Proc. of the 3rd LREC Conference, pages 1928–1932.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of English: The PENN TREEBANK.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="4369" citStr="Marcus et al., 1993" startWordPosition="650" endWordPosition="653">gn of annotation schemata for language resources and their standardization have a long-standing tradition in the NLP community. In the very beginning, this work often focused exclusively on subdomains of text analysis such as document structure meta-information, syntactic or semantic analysis. The Text Encoding Initiative (TEI)2 provided schemata for the exchange of documents of various genres. The Dublin Core Metadata Initiative3 established a de facto standard for the Semantic Web.4 For (computational) linguistics proper, syntactic annotation schemes, such as the one from the Penn Treebank (Marcus et al., 1993), or semantic annotations, such as the one underlying ACE (Doddington et al., 2004), are increasingly being used in a quasi standard way. In recent years, however, the NLP community is trying to combine and merge different kinds of annotations for single linguistic layers. XML formats play a central role here. An XML-based encoding standard for linguistic corpora XCES (Ide et al., 2000) is based on CES (Corpus Encoding Standard) as part of the EAGLES Guidelines.5 Work on TIGER (Brants and Hansen, 2002) is an example for the liaison of dependency- and constituent-based syntactic annotations. Ne</context>
<context position="19419" citStr="Marcus et al., 1993" startWordPosition="2784" endWordPosition="2787">ning field. 4.4 Morpho-Syntax The Morpho-Syntax layer (cf. Figure 1-3) represents the results of morpho-syntactic analysis such as tokenization, stemming, POS tagging. The smallest annotation unit is Token which consists of five attributes, including its part-of-speech information 8http://www.cl.cam.ac.uk/˜aac10/ escience/sciborg.html 37 (posTag), stemmedForm, lemma, grammatical features (feats), and orthographical information (orthogr). With respect to already available POS tagsets, the scheme allows corresponding extensions of the supertype POSTag to, e.g., PennPOSTag (for the Penn Tag Set (Marcus et al., 1993)) or GeniaPOSTag (for the GENIA Tag Set (Ohta et al., 2002)). The attribute tagsetId serves as a unique identifier of the corresponding tagset. The value of the POS tag (e.g., NN, VVD, CC) can be stored in the attribute value. The potential values for the instantiation of this attribute are always restricted to the tags of the associated tagset. These constraints enforce formal control on annotation processes. As for morphologically normalized lexical items, the Lemma type stores the canonical form of a lexical token which can be retrieved from a lexicon once it is computed by a lemmatizer. Th</context>
<context position="22659" citStr="Marcus et al., 1993" startWordPosition="3297" endWordPosition="3300">ation (cf. Figure 1-1) which links through its attribute value spans of annotations to an annotation unit. 4.5 Syntax This layer of the scheme provides the types and attributes for the representation of syntactic structures of sentences (cf. Figure 1-4). The results from shallow and full parsing can be stored here. Shallow parsing (chunking) aims at dividing the flow of text into phrases (chunks) in a nonoverlapping and non-recursive manner. The type Chunk accounts for different chunk tag sets by subtyping. Currently, the scheme supports PhraseChunks with subtypes such as NP, VP, PP, or ADJP (Marcus et al., 1993). The scheme also reflects the most popular full parsing approaches in NLP, viz. constituent-based and dependency-based approaches. The results from constituent-based parsing are represented in a parse tree and can be stored as single nodes in the Constituent type. The tree structure can be reconstructed through links in the attribute parent which stores the id of the parent constituent. Besides the attribute parent, Constituent holds the attributes cat which stores the complex syntactic category of the current constituent (e.g., NP, VP), and head which links to the head word of the constituen</context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M.A. Marcinkiewicz. 1993. Building a large annotated corpus of English: The PENN TREEBANK. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Meyers</author>
</authors>
<title>Annotation compatibility working group report.</title>
<date>2006</date>
<booktitle>In Proc. of the COLING-ACL 2006 Workshop FLAC</booktitle>
<pages>38--53</pages>
<contexts>
<context position="5517" citStr="Meyers, 2006" startWordPosition="830" endWordPosition="831">on of dependency- and constituent-based syntactic annotations. New standardization efforts such as the Syntactic Annotation Framework (SYNAF) (Declerck, 2006) aim to combine different proposals and create standards for syntactic annotation. We also encounter a tendency towards multiple annotations for a single corpus. Major bio-medical corpora, such as GENIA (Ohta et al., 2002) or PennBioIE,6 combine several layers of linguistic information in terms of morpho-syntactic, syntactic and semantic annotations (named entities and events). In the meantime, the Annotation Compatibility Working Group (Meyers, 2006) began to concentrate its activities on the mutual compatibility of annotation schemata for, e.g., POS tagging, treebanking, role labeling, time annotation, etc. The goal of these initiatives, however, has never been to design an annotation scheme for a complete 2http://www.tei-c.org 3http://dublincore.org 4http://www.w3.org/2001/sw 5http://www.ilc.cnr.it/EAGLES96/ 6http://bioie.ldc.upenn.edu NLP pipeline as needed, e.g., for information extraction or text mining tasks (Hahn and Wermter, 2006). This lack is mainly due to missing standards for specifying comprehensive NLP software architectures</context>
</contexts>
<marker>Meyers, 2006</marker>
<rawString>A. Meyers. 2006. Annotation compatibility working group report. In Proc. of the COLING-ACL 2006 Workshop FLAC 2006’, pages 38–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Miyao</author>
<author>J Tsujii</author>
</authors>
<title>Probabilistic disambiguation models for wide-coverage HPSG parsing.</title>
<date>2005</date>
<booktitle>In Proc. of the ACL</booktitle>
<pages>83--90</pages>
<contexts>
<context position="23679" citStr="Miyao and Tsujii, 2005" startWordPosition="3450" endWordPosition="3453">s the attribute parent, Constituent holds the attributes cat which stores the complex syntactic category of the current constituent (e.g., NP, VP), and head which links to the head word of the constituent. In order to account for multiple annotations in the constituent-based approach, we introduced corresponding constituent types which specialize Constituent. This parallels our approach which we advocate for alternatives in POS tagging and the management of alternative chunking results. Currently, the scheme supports three different constituent types, viz. PTBConstituent, 38 GENIAConstituent (Miyao and Tsujii, 2005) and PennBIoIEConstituent. The attributes of the type PTBConstituent cover the complete repertoire of annotation items contained in the Penn Treebank, such as functional tags for form/function dicrepancies (formFuncDisc), grammatical role (gramRole), adverbials (adv) and miscellaneous tags (misc). The representation of null elements, topicalized elements and gaps with corresponding references to the lexicalized elements in a tree is reflected in attributes nullElement, tpc, map and ref, respectively. GENIAConstituent and PennBIoIEConstituent inherit from PTBConstituent all listed attributes an</context>
</contexts>
<marker>Miyao, Tsujii, 2005</marker>
<rawString>Y. Miyao and J. Tsujii. 2005. Probabilistic disambiguation models for wide-coverage HPSG parsing. In Proc. of the ACL 2005, pages 83 – 90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Ohta</author>
<author>Y Tateisi</author>
<author>J-D Kim</author>
</authors>
<title>The GENIA corpus: An annotated research abstract corpus in molecular biology domain.</title>
<date>2002</date>
<booktitle>In Proc. of the 2nd HLT,</booktitle>
<pages>82--86</pages>
<contexts>
<context position="5284" citStr="Ohta et al., 2002" startWordPosition="796" endWordPosition="799">ral role here. An XML-based encoding standard for linguistic corpora XCES (Ide et al., 2000) is based on CES (Corpus Encoding Standard) as part of the EAGLES Guidelines.5 Work on TIGER (Brants and Hansen, 2002) is an example for the liaison of dependency- and constituent-based syntactic annotations. New standardization efforts such as the Syntactic Annotation Framework (SYNAF) (Declerck, 2006) aim to combine different proposals and create standards for syntactic annotation. We also encounter a tendency towards multiple annotations for a single corpus. Major bio-medical corpora, such as GENIA (Ohta et al., 2002) or PennBioIE,6 combine several layers of linguistic information in terms of morpho-syntactic, syntactic and semantic annotations (named entities and events). In the meantime, the Annotation Compatibility Working Group (Meyers, 2006) began to concentrate its activities on the mutual compatibility of annotation schemata for, e.g., POS tagging, treebanking, role labeling, time annotation, etc. The goal of these initiatives, however, has never been to design an annotation scheme for a complete 2http://www.tei-c.org 3http://dublincore.org 4http://www.w3.org/2001/sw 5http://www.ilc.cnr.it/EAGLES96/</context>
<context position="19478" citStr="Ohta et al., 2002" startWordPosition="2795" endWordPosition="2798">gure 1-3) represents the results of morpho-syntactic analysis such as tokenization, stemming, POS tagging. The smallest annotation unit is Token which consists of five attributes, including its part-of-speech information 8http://www.cl.cam.ac.uk/˜aac10/ escience/sciborg.html 37 (posTag), stemmedForm, lemma, grammatical features (feats), and orthographical information (orthogr). With respect to already available POS tagsets, the scheme allows corresponding extensions of the supertype POSTag to, e.g., PennPOSTag (for the Penn Tag Set (Marcus et al., 1993)) or GeniaPOSTag (for the GENIA Tag Set (Ohta et al., 2002)). The attribute tagsetId serves as a unique identifier of the corresponding tagset. The value of the POS tag (e.g., NN, VVD, CC) can be stored in the attribute value. The potential values for the instantiation of this attribute are always restricted to the tags of the associated tagset. These constraints enforce formal control on annotation processes. As for morphologically normalized lexical items, the Lemma type stores the canonical form of a lexical token which can be retrieved from a lexicon once it is computed by a lemmatizer. The lemma value, e.g., for the verb ‘activates’ would be ‘act</context>
</contexts>
<marker>Ohta, Tateisi, Kim, 2002</marker>
<rawString>T. Ohta, Y. Tateisi, and J.-D. Kim. 2002. The GENIA corpus: An annotated research abstract corpus in molecular biology domain. In Proc. of the 2nd HLT, pages 82–86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Pianta</author>
<author>L Bentivogli</author>
<author>C Girardi</author>
<author>B Magnini</author>
</authors>
<title>Representing and accessing multilevel linguistic annotation using the MEANING format.</title>
<date>2006</date>
<booktitle>In Proc. of the 5th EACL-2006 Workshop NLP%ML-2006,</booktitle>
<pages>77--80</pages>
<contexts>
<context position="6159" citStr="Pianta et al., 2006" startWordPosition="913" endWordPosition="916">its activities on the mutual compatibility of annotation schemata for, e.g., POS tagging, treebanking, role labeling, time annotation, etc. The goal of these initiatives, however, has never been to design an annotation scheme for a complete 2http://www.tei-c.org 3http://dublincore.org 4http://www.w3.org/2001/sw 5http://www.ilc.cnr.it/EAGLES96/ 6http://bioie.ldc.upenn.edu NLP pipeline as needed, e.g., for information extraction or text mining tasks (Hahn and Wermter, 2006). This lack is mainly due to missing standards for specifying comprehensive NLP software architectures. The MEANING format (Pianta et al., 2006) is designed to integrate different levels of morphosyntactic annotations. The HEART OF GOLD middleware (Sch¨afer, 2006) combines multidimensional mark-up produced by several NLP components. An XML-based NLP tool suite for analyzing and annotating medical language in an NLP pipeline was also proposed by (Grover et al., 2002). All these proposals share their explicit linkage to a specific NLP tool suite or NLP system and thus lack a generic annotation framework that can be re-used in other developmental environments. Buitelaar et al. developed in the context of an information extraction project</context>
</contexts>
<marker>Pianta, Bentivogli, Girardi, Magnini, 2006</marker>
<rawString>E. Pianta, L. Bentivogli, C. Girardi, and B. Magnini. 2006. Representing and accessing multilevel linguistic annotation using the MEANING format. In Proc. of the 5th EACL-2006 Workshop NLP%ML-2006, pages 77–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Rumbaugh</author>
<author>I Jacobson</author>
<author>G Booch</author>
</authors>
<title>The Unified Modeling Language Reference Manual.</title>
<date>1999</date>
<publisher>Addison-Wesley.</publisher>
<contexts>
<context position="2250" citStr="Rumbaugh et al., 1999" startWordPosition="318" endWordPosition="321">regarding concrete implementation matters? Yet another burning issue relates to the increasing availability of multiple metadata annotations both in corpora and language processors. If alternative annotation tag sets are chosen for the same functional task a ‘data conversion’ problem is created which should be solved at the abstract specification level as well (Ide et al., 2003). Software engineering methodology points out that these requirements are best met by properly identifying input/output capabilities of constituent components and by specifying a general data model (e.g., based on UML (Rumbaugh et al., 1999)) in order to get rid of the low-level implementation (i.e., coding) layer. A particularly promising proposal along this line of thought is the Unstructured Information Management Architecture (UIMA) (Ferrucci and Lally, 2004) originating from IBM research activities.1 UIMA is but the latest attempt in a series of proposals concerned with more generic NLP engines such as ATLAS (Laprun et al., 2002) or GATE (Cunningham, 2002). These frameworks have in common a data-driven architecture and a data model based on annotation graphs as an adaptation of the TIPSTER architecture (Grishman, 1997). They</context>
</contexts>
<marker>Rumbaugh, Jacobson, Booch, 1999</marker>
<rawString>J. Rumbaugh, I. Jacobson, and G. Booch. 1999. The Unified Modeling Language Reference Manual. Addison-Wesley.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Sch¨afer</author>
</authors>
<title>Middleware for creating and combining multi-dimensional NLP markup.</title>
<date>2006</date>
<booktitle>In Proc. of the 5th EACL2006 Workshop NLP%ML-2006,</booktitle>
<pages>81--84</pages>
<marker>Sch¨afer, 2006</marker>
<rawString>U. Sch¨afer. 2006. Middleware for creating and combining multi-dimensional NLP markup. In Proc. of the 5th EACL2006 Workshop NLP%ML-2006, pages 81–84.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>