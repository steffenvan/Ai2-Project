<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000227">
<title confidence="0.948676">
An Efficient Kernel for Multilingual Generation in
Speech-to-Speech Dialogue Translation
</title>
<author confidence="0.951221">
Tilman Becker and Wolfgang Finkler and Anne Kilger and Peter PoIler
</author>
<affiliation confidence="0.874527">
German Research Center for Artificial Intelligence (DFKI GmbH)
</affiliation>
<address confidence="0.941834">
Stuhlsatzenhausweg 3
D-66123 Saarbriicken
Germany
</address>
<email confidence="0.98197">
becker@dfki.de, finkler@dfki.de, kilger@dfki.de, poller@dfki.de
</email>
<sectionHeader confidence="0.995473" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99847980952381">
We present core aspects of a fully implemented
generation component in a multilingual speech-
to-speech dialogue translation system. Its de-
sign was particularly influenced by the neces-
sity of real-time processing and usability for
multiple languages and domains. We devel-
oped a general kernel system comprising a mi-
croplanning and a syntactic realizer module.
The microplanner performs lexical and syntac-
tic choice, based on constraint-satisfaction tech-
niques. The syntactic realizer processes HPSG
grammars reflecting the latest developments of
the underlying linguistic theory, utilizing their
pre-processing into the TAG formalism. The
declarative nature of the knowledge bases, i.e.,
the microplanning constraints and the HPSG
grammars allowed an easy adaption to new do-
mains and languages. The successful integra-
tion of our component into the translation sys-
tem Verbmobil proved the fulfillment of the spe-
cific real-time constraints.
</bodyText>
<sectionHeader confidence="0.998759" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998974923076923">
In this paper we present core aspects of the mul-
tilingual natural language generation compo-
nent VM-GECO1 that has been integrated into
the research prototype of Verbmobil (Wahlster,
1993; Bub et al., 1997), a system for sponta-
neous speech—to—speech dialog translation.
In order to achieve multilinguality as ele-
gantly as possible we found that a clear modu-
lar separation between a language—independent
general kernel generator and language—specific
parts which consist of syntactic and lexical
knowledge sources was a very promising ap-
proach. Accordingly, our generation component
</bodyText>
<footnote confidence="0.8396605">
1VM—GECO is an acronym for &amp;quot;VerbMobil GEnera-
tion COmponents.&amp;quot;
</footnote>
<bodyText confidence="0.999795975">
consists of one kernel generator and language—
specific knowledge sources for the languages
used in Verbmobil: German and English with
current work on Japanese.
Additionally, the kernel generator itself can
be modularized furthermore into two separate
components. The task of the so—called rni-
croplanning component is to plan an utterance
on a phrase— or sentence—level (Hovy, 1996) in-
cluding word—choice (section 2). It generates an
annotated dependency structure which is used
by the syntactic generation component to re-
alize an appropriate surface string for it (sec-
tion 3). The main goal of this further modular-
ization is a stepwise constraining of the search—
space of alternative linguistic realizations, using
abstracted views on different choice criteria.
Multilingual generation in dialog translation
imposes strong requirements on the generation
module. A very prominent problem is the non—
wellformedness (incorrectness, irrelevance, and
inconsistency) of spontaneous input. It forces
the realization of robust generation to be able
to cope with erroneous and incomplete input
data so that the quality of the generated out-
put may vary between syntactically correct sen-
tences and semantically understandable utter-
ances. On the level of knowledge sources this
is achieved by using a highly declarative HPSG
grammar which very closely reflects the latest
developments of the underlying linguistic the-
ory (Pollard and Sag, 1994) and covers phe-
nomena of spoken language. This HPSG is
compiled into a TAG grammar in an offline
pre-processing step (Kasper et al., 1995) which
keeps the declarative nature of the grammar in-
tact (section 3).
Maybe the most important requirement on
the generation module of a speech—to—speech
translation system is real—time processing. The
</bodyText>
<page confidence="0.996085">
110
</page>
<bodyText confidence="0.999934238095238">
above mentioned features of VM-GECO con-
tribute to the efficiency of the generation com-
ponent. The TAG-formalism is well known for
the existence of efficient syntactic generation al-
gorithms (Kilger and Finkler, 1995).
In general, all knowledge sources of all mod-
ules are declarative. The main advantage is
that this allows for an easier adaptation of the
generation component to other domains, lan-
guages and semantic representation languages
besides the easier extendability of the current
system. The feasibility of the language adap-
tation was proved in the Verbmobil project it-
self where the (originally English) generator was
recently extended to cover German and is cur-
rently adapted for Japanese. The adaptation
to another domain and also to another specifi-
cation language for intermediate structures was
shown in another translation project which uses
in contrast to Verbmobil an interlingua based
approach (section 4.1).
</bodyText>
<sectionHeader confidence="0.955517" genericHeader="method">
2 The Microplanner
</sectionHeader>
<bodyText confidence="0.999957066666667">
A generation system for target language utter-
ances in an approach to speech-to-speech trans-
lation has to work on input elements represent-
ing intermediate results of recognition, analy-
sis, and transfer components. In that setting,
several of the tasks of a complete natural lan-
guage generation system such as selection and
organization of the contents to be expressed are
outside of the control of our generator. They
have been decided by the human user of the
translation system or they have been negoti-
ated and computed by a transfer component.
Nevertheless, there remain a number of different
but highly interrelated subtasks of the genera-
tion process where decisions have to be made
in order to determine and realize the trans-
lation result to be sent to a speech synthesis
component. The diverse subtasks — often col-
lectively denoted as microplanning (cf. (Levelt,
1989; Hovy, 1996)) — comprise the planning
of a rough structure of the target language ut-
terance, the determination of sentence borders,
sentence type, topicalization, theme-rheme or-
ganization of sentential units, focus control, uti-
lization of nominalized, or infinitival style, as
well as triggering the generation of anaphora
and lexical choice. In addition, they have to
address the problem of expressibility of the se-
lected contents in a text realization component,
i.e., bridging the generation gap (see (Meteer,
1990)).
The input to our microplanning component
consists of semantic representations encoded in
a minimal recursive structure following a vari-
ant of UDRT. Each individual indicated by
some input utterance is formally represented by
a discourse referent. Information about the in-
dividual is encoded within the DRS-conditions.
Relations between descriptions of different dis-
course referents lead to a hierarchical semantic
structure (see Figure 1 for a graphical represen-
tation of fragments of an example input to the
generator). Discourse referents are depicted as
boxes headed by individual names in; conditions
are illustrated within those boxes.
</bodyText>
<figureCaption confidence="0.999306">
Figure 1: Example Input to the Generator
</figureCaption>
<bodyText confidence="0.999950083333333">
Besides these input terms from the transfer
component, the generator may access knowl-
edge about the dialogue act, the dialogue his-
tory as well as some prosodic information of the
user&apos;s utterance.
The output of the microplanner is a sentence
plan that serves as input for the syntactic real-
ization component. It describes a dependency
tree over lexical items annotated with syntac-
tic, semantic, and pragmatic information which
is relevant to produce an acceptable utterance
and guide the speech synthesis component.
</bodyText>
<subsectionHeader confidence="0.994075">
2.1 Design of the Microplanning Kernel
</subsectionHeader>
<bodyText confidence="0.999577">
An important design principle of our generator
is the demand to cope with multidirectional de-
pendencies among decisions of the diverse sub-
tasks of microplanning without preferring one
</bodyText>
<equation confidence="0.68788475">
temp_loc (12 13)
work_acceptable 12
arg3 (12 14)
perspective (12 11)
temp_loc (12 IS)
\
ILE3=■1
up demonstrative (13 1t2 ht1)
</equation>
<page confidence="0.970455">
111
</page>
<bodyText confidence="0.9998003125">
order of decisions over others. E.g., the choice
of an interrogative sentence requires an (at least
elliptical) verbal phrase as a major constituent
of the sentence; nominalization or the choice
of passive voice depends on the result of word
choice, etc. Therefore, we conceived microplan-
ning as a constraint-satisfaction problem (Ku-
mar, 1992) representing undirected relations be-
tween variables. Thereby, variables are created
for elements in the input to the generator. They
are connected by means of weighted constraints.
The domains of the variables correspond to ab-
stractions of possible alternatives for syntactic
realizations of the semantic elements including
sets of specifications of lexical items and syntac-
tic features. A solution of the constraint system
is a globally consistent instantiation of the vari-
ables and is guaranteed to be a valid input for
the syntactic generation module. Since there
might be locally optimal mappings that lead to
contradiction on a global level, the microplan-
ner generally uses these weighted constraints to
direct a backtracking or propagation process.
One the one hand, the advantages of utiliz-
ing a constraint system lie in the declarativ-
ity of the knowledge sources allowing for an
easier adaptation of the system to other do-
mains and languages. We benefited from this
design decision and realized microplanning for
English and German by means of merely estab-
lishing new rule sets for lexical and syntactic
choice. The core engine for constraint process-
ing was reused without modification. On the
other hand, having defined a suitable represen-
tation of the problem to be solved, a constraint—
based approach also establishes a testbed for
examining the pros and cons of different eval-
uation methods, including backtracking, con-
straint propagation, heuristics for the order of
the instantiation of variable values, to name a
few means of dealing with competition among
alternatives and to find a solution.
The microplanner makes use of the minimal
recursive structure of its semantic input term
(see Fig. 1) by triggering activities by bundles of
conditions, discourse referents, and holes repre-
senting underspecified scope relations in the in-
put. These three input categories are reflected
by different microplanning rule sets that are ap-
plied conjointly during the process of microplan-
ning. The rules are represented as pattern-
condition—action triples. A pattern is to be
matched with part of the input, a condition
describes additional context-dependent require-
ments to be fulfilled by the input, and the ac-
tion part describes a bundle of syntactic features
realizing lexical entities and their relations to
complements and modifiers.
A microplanning rule for the combination of
the semantic predicates WORK_ACCEPTABLE, ARG3,
and PERSPECTIVE which get realized as a finite
verb, i.e., representing a 3:1 mapping of se-
mantic predicates to a syntactic specification is
shown in Figure 2.
</bodyText>
<figure confidence="0.919491833333333">
standard finite verb with 2 complements
((WORK_ACCEPTABLE (L I) ARG3 (L I 12) ;; pattern
PERSPECTIVE (Li I 13))
(Snot ($sem-match NOM (L I))) ;; condition
(WORK_ACCEPTABLE (CAT V) ;; action
(HEAD (OR SUIT_V1 SUIT_V2)) (FORM ordinary)
(TENSE $get-tense I) (VOICE $get-voice I))
(12 (GENDER (NOT MAS FEM)))
(REGENT-DEP-FUNC WORK_ACCEPTABLE 12 AGENT)
(REGENT-DEP-FUNC WORK_ACCEPTABLE 13 PATIENT)
(KEY KEY-V))
nominalized form ...
</figure>
<figureCaption confidence="0.999824">
Figure 2: Example Microplanning Content Rule
</figureCaption>
<bodyText confidence="0.99914526923077">
In the condition part of the verbal mapping
the existence of a NOM-condition within the se-
mantic input information is tested. It would
forbid the verbal form by demanding a nomi-
nalized form. The action part describes the re-
sult of lexical selection (the lemma &amp;quot;suit&amp;quot;) plus
generic functions for computing relevant syntac-
tic features like tense and voice. 12 which stands
for the ARG3 of WORK_ACCEPTABLE, defined by a
database of linking—information as the semantic
agent is characterized as neither allowing gen-
der masc(uline) nor fem(inine) for preventing
&amp;quot;he suits&amp;quot; in the sense of &amp;quot;he is okay&amp;quot;. En-
tries starting with KEY define identifiers used for
computing the preference value of a microplan-
ning rule with respect to the given situation.
In an additional database, KEYs are associated
with weights for predefined situation character-
istics such as time pressure, or register. The
microplanning content rules are not directly en-
tered by a rule writer but are compiled off—line
from several knowledge sources for lexical choice
rules, rules for syntactic decisions and linking
rules, thereby filtering out contradictory combi-
nations without requiring on—line runtime.
Regarding the sets of alternatives that result
</bodyText>
<page confidence="0.992799">
112
</page>
<bodyText confidence="0.99875">
from the application of the microplanning rules,
the most direct way of realizing a constraint
net seems to be the definition of one variable
for each condition, discourse referent, and hole,
leading to a variable net as shown in Figure 3.
</bodyText>
<table confidence="0.835375166666667">
L7 -1411Q
1.3 -E14P RASE
12
L15-TEI4P_LOC 5.4-PERSPECTIVE L -WORIC_ACCEPTABLE LA -TEDIP_LOC
13 Ii 14 IS
5.T3-TIME L10.-PRON 5.13..PRON I LS -TIME
</table>
<figureCaption confidence="0.994889">
Figure 3: Variable Net for Microplanning
</figureCaption>
<bodyText confidence="0.99998980952381">
For our task, it is not enough to define bi-
nary matching constraints between each pair
of variables that purely test the compatibility
of the described syntactic features. Some syn-
tactic specifications may contain identifications
of further entities, e.g., discourse referents and
syntactic identifiers which influence the result
of the compatibility test between a pair of vari-
ables referring to these identifiers. Thus, the
constraint net is not easily subdivided into sub-
nets that can be efficiently evaluated. The large
number of combinations of alternative values is
handled by known means for CSP such as unit-
ing variables with 1—value domains and apply-
ing matching mechanisms to their values, com-
putation of 2—consistency by matching value
pairs and filtering out inconsistent ones, storing
and reusing knowledge about binary incompat-
ibility and performing intelligent backtracking.
The result of the constraint solving process
for the input shown in Fig. 1 is given in Fig. 4.
</bodyText>
<sectionHeader confidence="0.981806" genericHeader="method">
3 The Realizer
</sectionHeader>
<bodyText confidence="0.999767">
The syntactic realizer2 proceeds from the mi-
croplanning result as shown in Figure 5. It pro-
duces a derived phrase structure from which the
output string is read off. The realizer is based
on a fully lexicalized grammar in the sense that
every lexical item selects for a finite set of possi-
ble phrase structures (called elementary trees).
In particular, we use a Feature-Based Lexical-
ized Tree-Adjoining Grammar (FB-LTAG, see
(Vijay-Shanker and Joshi, 1988; Schabes et al.,
1988)) that is derived from an HPSG grammar
(see section 4 for some more details). The el-
ementary trees (see Figure 9) can be seen as
maximal partial projections. A derivation of an
utterance is constructed by combining appro-
priate elementary trees with the two elementary
TAG operations of adjunction and substitution.
For each node (i.e., lexical item) in the de-
pendency tree, the tree selection phase deter-
mines the set of relevant TAG trees. A first
tree retrieval step maps every object of the
dependency tree into a set of applicable ele-
mentary TAG trees. The main tree selection
phase uses information from the microplanner
output to further refine the set of retrieved
trees. The combination phase finds a success-
ful combination of trees to build a (derived)
phrase structure tree. The final inflection phase
uses the information in the feature structures
of the leaves (i.e., the words) to apply appro-
priate morphological functions. An initial pre-
processing phase is needed to accommodate the
handling of auxiliaries which are not determined
in microplanning. They are derived from the
tense, aspect and sentence mood information as
supplied by microplanning.
</bodyText>
<figure confidence="0.845897333333333">
1110
HPSG
Grammar
</figure>
<figureCaption confidence="0.9553675">
Figure 5: Steps of the syntactic generator.
The two core phases are the tree selection and
</figureCaption>
<footnote confidence="0.533701">
2A more detailed description is contained in (Becker,
1998).
</footnote>
<figure confidence="0.9878144">
L21 -QUEST
(intention wh-question)
(real hs) (Cat utt-par)
L5-WORK_ACCEPTABLE
(mood indic.)
(voice active)
(head (or suit_v1
suit2))
(tense Jul.) L1 0-PRON L15-TEMP_LOC
(cat v) (pers 2a) (head then_adv)
(cat ppron) (cat adv)
L13-PRON (num sg)
(pers
(cat ppron)
(num sg)
</figure>
<figureCaption confidence="0.903926">
Figure 4: Microplanning Result for the Example
</figureCaption>
<figure confidence="0.998150045454545">
temp_spec
L6-TEMP_LOC
(head when!)
(whiocus t)
(cat adv)
Prepnicessing
(expand auxiliaries)
11111111410°
4111. 41. 41110 41110
•UIJI
I, rob
FI3 LTAG
Lem on
FB LTAG
GrAmmar
Tree eleimon
And Amnia
Tree combination
(adjoining tubtsubstitution)
Intlestu n
ti
lollattion
</figure>
<page confidence="0.998232">
113
</page>
<bodyText confidence="0.999985979591837">
the combination phase. The tree selection is
driven by the HPSG instance or word class that
is supplied by the microplanner. It is mapped to
a lexical type by a lexicon that is automatically
compiled from the HPSG grammar. The lexi-
cal types are then mapped to a tree family, i.e.,
a set of elementary TAG trees representing all
possible minimally complete phrase structures
that can be build from the instance. The ad-
ditional information in the dependency tree is
then used to add further feature values to the
trees. This additional information acts as a fil-
ter for selecting appropriate trees in two stages:
Some values are incompatible with values al-
ready present in the trees. These trees can
therefore be filtered immediately from the set.
E.g., a syntactic structure for an imperative
clause is marked as such by a feature and can
be discarded if a declarative sentence is to be
generated. Additional features can prevent the
combination with other trees during the combi-
nation phase. This is the case, e.g., with agree-
ment features.
The combination phase completely belongs to
the core machinery. It can be exchanged with
more efficient algorithms without change of the
grammar or lexicon. It explores the search space
of all possible combinations of trees from the
candidate sets for each lexical item (instance).
Since there is sufficient information available
from the microplanner result and from the trees,
a well-guided best-first search strategy can be
employed in the current system.
As part of the tree selection phase, based on
the rich annotation of the input structure, the
tree sets are sorted locally such that preferred
trees are tested first. Then a modified back-
tracking algorithm traverses the dependency
tree in a bottom-up fashion3. At each node and
for each subtree in the dependency tree, a can-
didate for the phrase structure of the subtree
is constructed. Then all possible adjunction or
substitution sites are computed, possibly sorted
(e.g., allowing for preferences in word order) and
the best candidate for a combined phrase struc-
ture is returned. Since the combination of two
partial phrase structures by adjunction or sub-
stitution might fail due to incompatible feature
structures, a backtracking algorithm must be
</bodyText>
<footnote confidence="0.9121275">
3The algorithm stores intermediate results with a
memoization technique.
</footnote>
<bodyText confidence="0.999784872340426">
used. A partial phrase structure for a subtree of
the dependency is finally checked for complete-
ness. These tests include the unifiability of all
top and bottom feature structures and the satis-
faction of all other constraints (e.g., obligatory
adjunctions or open substitution nodes) since
no further adjunctions or substitutions will oc-
cur in this subtree.
The necessity of a spoken dialog translation
system to robustly produce output calls for
some relaxations in these tests. E.g., &apos;obliga-
tory&apos; arguments may be missing in the utter-
ance. This can be caused by ellipsis in sentences
such as &amp;quot;Ok, we postpone.&amp;quot; or by false segmen-
tations in the analysis such as segmenting &amp;quot;Wir
sollten (we should) das Treffen verschieben (the
meeting postpone).&amp;quot; into two segments &amp;quot;Wir
sollten&amp;quot; and &amp;quot;das Treffen verschieben&amp;quot;. In order
to generate &amp;quot;postpone the meeting&amp;quot; for the sec-
ond segment, the tests in the syntactic genera-
tor must accept a phrase with a missing subject
if no other complete phrase can be generated.
Figure 6 shows a combination of the tree
retrieval and the tree selection phases. In
the tree retrieval phase for L5-WORK_ACCEPTABLE,
first the HEAD information is used to determine
the lexical types of the possible realizations
SUIT_V1 and SUIT_V2, namely MV_NP_TRANS_LE
and MV_EXPL_PREP_TRANS_LE respectively4. These
types are then mapped to their respective sets of
elementary trees, a total of 25 trees. In the tree
selection phase, this number is reduced to six.
For example, the tree MV_NP_TRANS_LE.2 in
Figure 9 has a feature CL-MODE with the value
IMPERATIVE. Now, the microplanner output
for the root entity LGV1 contains the informa-
tion (INTENTION WH-QUESTION). The INTENTION
information is unified with all appropriate CL-
MODE features, which in this case fails. There-
fore the tree MV_NP_TRANS_LE.2 is discarded
in the tree selection phase.
The combination phase uses the best-first
bottom-up algorithm described above to deter-
mine one suitable tree for every entity and also
a target node in the tree that is selected for the
governing entity. For the above example, the
selected trees and their combination nodes are
</bodyText>
<footnote confidence="0.996602666666667">
4MV_NP_TRANS_LE is an abbreviation for &amp;quot;Main Verb,
NP object, TRANSitive Lexical Entry&amp;quot; used in sentences
like &amp;quot;Monday suits me.&amp;quot;
</footnote>
<page confidence="0.990188">
114
</page>
<table confidence="0.977446789473684">
traverse for: L5-WORK_ACCEPTABLE
returned MV_NP_TRANS_LE
returned MV_EXPL_PREP_TRANS_LE
total: 6 trees
traverse for: L13-PRON
returned PERS_PRO_LE
total: 1 tree
traverse for: L10-PRON
returned PERS_PRO_LE
total: 1 tree
traverse for: L6-TEMP_LOC
returned WH_ADVERB_WORD_LE
total: 2 trees
traverse for: L15-TEMP_LOC
returned NP_ADV_WORD_LE
total: 5 trees
traverse for: LGV1
returned WILL_AUX_POS_LE
total: 2 trees
</table>
<figureCaption confidence="0.987409">
Figure 6: An excerpt from the tree retrieval and
selection phase.
</figureCaption>
<bodyText confidence="0.701117">
shown in Figure 75.
</bodyText>
<figure confidence="0.92633675">
WADV s. s&apos;s ADV J. WADV
/ /5 ,,_.-.. -----
V VNADV VP VP
ADS V
NP NP V NP J,,&apos; NP VP A V
I I I I \-1 I
Own on
L6-TENP_1.00 LOVI LII-PRON 1.5-SUIT 1.10-PRON L15-TRUP_LOC
</figure>
<figureCaption confidence="0.88172575">
Figure 7: The trees finally selected for the enti-
ties of the example sentence.
Figure 8 shows the final phrase structure for
the example. The inflection function selects
</figureCaption>
<bodyText confidence="0.8276758">
the base form of &amp;quot;suit&amp;quot; according to the BSE
value of the VFORM feature and correctly uses
&amp;quot;will.&amp;quot; Information about the sentence mode
WH-QUESTION can be used to annotate the re-
sulting string for the speech-synthesis module.
</bodyText>
<sectionHeader confidence="0.999965" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.914408923076923">
Our approach to separate a generation mod-
ule into a language—independent kernel and
language—specific knowledge sources has been
successfully implemented in a dialogue trans-
lation system. Furthermore, the mentioned
adaptability to other generation tasks has also
been proved by an adaptation of the generation
module to a new application domain and also to
a completely different semantic representation
5Note that the node labels shown in Figures 7 and 8
are only a concession to readability. The TAG require-
ment that in an auxiliary tree the foot node must have
the same category label as the root node is fulfilled.
</bodyText>
<figure confidence="0.636772">
suit yOU
</figure>
<figureCaption confidence="0.8875255">
Figure 8: The final phrase structure for &amp;quot;When
will it suit you then?&amp;quot;
</figureCaption>
<figure confidence="0.90041825">
IIV_NP_TRANS_LEA MV_NP_TRANS_LE.2 MV_NP_TRAN5_LE.3 NV_NP_TRANS_LEA
VP
111/fill TRANS_LE V P
MP NP 1RANS,LE
</figure>
<figureCaption confidence="0.991306">
Figure 9: Some of the trees for transitive verbs.
</figureCaption>
<bodyText confidence="0.989653">
They are compiled from the corresponding lex-
ical type MV_NP_TRANS_LE as defined in the
HPSG grammar. Trees 3 and 4 differ only with
respect to their feature structures which are not
shown in this figure.
language by adapting the microplanning knowl-
edge sources to the new formalism.
VM—GECO is fully implemented (in Common
Lisp) and integrated into the speech—to—speech
translation system Verbmobil for two output
languages, English and German. The adapta-
tion to Japanese generation will be performed in
the current project phase. Our experience from
adding German makes us confident that this
can be done straightforwardly by creating the
appropriate knowledge sources without modi-
fications of the kernel generator. To give the
reader a more detailed impression of the im-
plementation of the generation component we
present some characteristic data of the English
generator. The numbers for the German sys-
tem, especially for lexicon and processing time,
are similar.
The underlying English grammar is a lexical-
ized TAG which consists of 2844 trees. These
trees were transformed during an offline pre-
processing step from 2961 HPSG lexical en-
tries of the linguistically well motivated En-
glish HPSG grammar written at CSLI. On
the other hand the microplanner&apos;s knowledge
sources consist of 2730 partially pre-processed
microplanning rules which are utilized in an in-
</bodyText>
<figure confidence="0.921915857142857">
ADV SIADV
when V VP/ADV
VP ADV
NP awn
W.NCICLI.PrINNb
WI V Mq
MVXJRAKSJE IIVAP_MMR.LE
</figure>
<page confidence="0.995234">
115
</page>
<bodyText confidence="0.999930736842105">
tegrated handling of structural and lexical de-
cisions based on constraint propagation. The
microplanning rules are of course especially
adapted to the underlying semantic represen-
tation formalism. Furthermore, the underlying
lexicon covers the word list that has been con-
structed from a large corpus of the application
domain of the Verbmobil system, i.e., negotia-
tion dialogues in spontaneous speech.
The TAG grammar resulting from the com-
pilation step allows for highly efficient lexically
driven robust syntactic generation mainly con-
sisting of tree adjoinings, substitutions, and fea-
ture unifications. The average overall genera-
tion time per sentence (up to length 24) is 0.7
seconds on a SUN ULTRA-1 machine, 68 % of
the runtime are needed for the microplanning
while the remaining 32 % of the runtime are
needed for syntactic generation.
</bodyText>
<subsectionHeader confidence="0.979421">
4.1 Reusing the Kernel
</subsectionHeader>
<bodyText confidence="0.99976135483871">
Beside the usability for multiple languages in
Verbmobil our kernel generation component has
also proven its adaptability to a very differ-
ent semantic representation language (system-
atically and terminologically) in another still
ongoing multilingual (currently 12 languages)
translation project. The project utilizes an
interlingua-based approach to semantic rep-
resentations of utterances. The goal of this
project is to overcome the international lan-
guage barrier which is exemplarily realized by a
large corpus improvement of the transparency of
consisting of international law texts. Our part
in this project is the realization and implemen-
tation of the German generation component.
Because of our language-independent core gen-
erator the adaptation of the generation compo-
nent to this semantic representation decreased
to the adaptation of the structural and lexi-
cal knowledge bases of the microplanning com-
ponent and appropriate domain-specific exten-
sions on the lexicon of the syntactic generator.
With an average sentence length of 15 words
the average runtime per sentence on a SUN
ULTRA-2 is less than 0.5 seconds. Currently,
even the longest sentence (40 words) needs un-
der 2 seconds runtime.
Within Verbmobil, the generation component
will also be used for text generation when pro-
ducing protocols as described in (Alexandersson
and Poller, 1998).
</bodyText>
<sectionHeader confidence="0.996759" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990639530612245">
J. Alexandersson and P. Poller. 1998. Towards
multilingual protocol generation for spon-
taneous speech dialogues. In 9th INLGW,
Niagara-on-the-lake, Canada.
T. Becker. 1998. Fully lexicalized head-
driven syntactic generation. In 9th INLGW,
Niagara-on-the-lake, Canada.
Th. Bub, W. Wahlster, and A. Waibel. 1997.
Verbmobil: The combination of deep and
shallow processing for spontaneous speech
translation. In Proceedings of ICASSP &apos;97.
E. Hovy. 1996. An overview of automated natu-
ral language generation. In X. Huang, editor,
Proc. of the Intl. Symposium on NL Genera-
tion and the Processing of the Chinese Lan-
guage, INP(C)-96, Shanghai, China.
R. Kasper, B. Kiefer, K. Netter, and K. Vijay-
Shanker. 1995. Compilation of HPSG to
TAG. In 33rd ACL, Cambridge, Mass.
A. Kilger and W. Finkler. 1995. Incremen-
tal generation for real-time applications.
Research Report RR-95-11, DFKI GmbH,
Saarbriicken, Germany, July.
V. Kumar. 1992. Algorithms for constraint-
satisfaction problems: A survey. Al Maga-
zine, 13(1):32-44.
W.J.M. Levelt. 1989. Speaking: From Intention
to Articulation. The MIT Press, Cambridge,
MA.
M.W. Meteer. 1990. The &amp;quot;Generation Gap&amp;quot; -
The Problem of Expressibility in Text Plan-
ning. Ph.D. thesis, Amherst, MA. BBN Re-
port No. 7347.
C. Pollard and I. A. Sag. 1994. Head-Driven
Phrase Structure Grammar. Studies in Con-
temporary Linguistics. University of Chicago
Press, Chicago.
Y. Schabes, A. Abeille, and A. K. Joshi. 1988.
Parsing strategies with &apos;lexicalized&apos; gram-
mars: Application to tree adjoining gram-
mars. In COLING-88, pages 578-583, Bu-
dapest, Hungary.
K. Vijay-Shanker and A. K. Joshi. 1988. Fea-
ture structure based tree adjoining grammars.
In COLING-88, pages 714-719, Budapest,
Hungary.
W. Wahlster. 1993. Verbmobil: Translation
of face-to-face dialoges. In MT Summit IV,
Kobe, Japan.
</reference>
<page confidence="0.998998">
116
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.681960">
<title confidence="0.9971625">An Efficient Kernel for Multilingual Generation in Speech-to-Speech Dialogue Translation</title>
<author confidence="0.999564">Tilman Becker</author>
<author confidence="0.999564">Wolfgang Finkler</author>
<author confidence="0.999564">Anne Kilger</author>
<author confidence="0.999564">Peter PoIler</author>
<affiliation confidence="0.965571">Research Center for Artificial Intelligence GmbH</affiliation>
<address confidence="0.89815">Stuhlsatzenhausweg 3 D-66123 Saarbriicken Germany</address>
<email confidence="0.998788">becker@dfki.de,finkler@dfki.de,kilger@dfki.de,poller@dfki.de</email>
<abstract confidence="0.998995772727273">We present core aspects of a fully implemented generation component in a multilingual speechto-speech dialogue translation system. Its design was particularly influenced by the necessity of real-time processing and usability for multiple languages and domains. We developed a general kernel system comprising a microplanning and a syntactic realizer module. The microplanner performs lexical and syntactic choice, based on constraint-satisfaction techniques. The syntactic realizer processes HPSG grammars reflecting the latest developments of the underlying linguistic theory, utilizing their pre-processing into the TAG formalism. The declarative nature of the knowledge bases, i.e., the microplanning constraints and the HPSG grammars allowed an easy adaption to new domains and languages. The successful integration of our component into the translation system Verbmobil proved the fulfillment of the specific real-time constraints.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J Alexandersson</author>
<author>P Poller</author>
</authors>
<title>Towards multilingual protocol generation for spontaneous speech dialogues.</title>
<date>1998</date>
<booktitle>In 9th INLGW,</booktitle>
<location>Niagara-on-the-lake, Canada.</location>
<marker>Alexandersson, Poller, 1998</marker>
<rawString>J. Alexandersson and P. Poller. 1998. Towards multilingual protocol generation for spontaneous speech dialogues. In 9th INLGW, Niagara-on-the-lake, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Becker</author>
</authors>
<title>Fully lexicalized headdriven syntactic generation.</title>
<date>1998</date>
<booktitle>In 9th INLGW,</booktitle>
<location>Niagara-on-the-lake, Canada.</location>
<contexts>
<context position="15477" citStr="Becker, 1998" startWordPosition="2378" endWordPosition="2379"> combination of trees to build a (derived) phrase structure tree. The final inflection phase uses the information in the feature structures of the leaves (i.e., the words) to apply appropriate morphological functions. An initial preprocessing phase is needed to accommodate the handling of auxiliaries which are not determined in microplanning. They are derived from the tense, aspect and sentence mood information as supplied by microplanning. 1110 HPSG Grammar Figure 5: Steps of the syntactic generator. The two core phases are the tree selection and 2A more detailed description is contained in (Becker, 1998). L21 -QUEST (intention wh-question) (real hs) (Cat utt-par) L5-WORK_ACCEPTABLE (mood indic.) (voice active) (head (or suit_v1 suit2)) (tense Jul.) L1 0-PRON L15-TEMP_LOC (cat v) (pers 2a) (head then_adv) (cat ppron) (cat adv) L13-PRON (num sg) (pers (cat ppron) (num sg) Figure 4: Microplanning Result for the Example temp_spec L6-TEMP_LOC (head when!) (whiocus t) (cat adv) Prepnicessing (expand auxiliaries) 11111111410° 4111. 41. 41110 41110 •UIJI I, rob FI3 LTAG Lem on FB LTAG GrAmmar Tree eleimon And Amnia Tree combination (adjoining tubtsubstitution) Intlestu n ti lollattion 113 the combina</context>
</contexts>
<marker>Becker, 1998</marker>
<rawString>T. Becker. 1998. Fully lexicalized headdriven syntactic generation. In 9th INLGW, Niagara-on-the-lake, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster Bub</author>
<author>A Waibel</author>
</authors>
<title>Verbmobil: The combination of deep and shallow processing for spontaneous speech translation.</title>
<date>1997</date>
<booktitle>In Proceedings of ICASSP &apos;97.</booktitle>
<marker>Bub, Waibel, 1997</marker>
<rawString>Th. Bub, W. Wahlster, and A. Waibel. 1997. Verbmobil: The combination of deep and shallow processing for spontaneous speech translation. In Proceedings of ICASSP &apos;97.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Hovy</author>
</authors>
<title>An overview of automated natural language generation.</title>
<date>1996</date>
<booktitle>Proc. of the Intl. Symposium on NL Generation and the Processing of the Chinese Language, INP(C)-96,</booktitle>
<editor>In X. Huang, editor,</editor>
<location>Shanghai, China.</location>
<contexts>
<context position="2320" citStr="Hovy, 1996" startWordPosition="327" endWordPosition="328">el generator and language—specific parts which consist of syntactic and lexical knowledge sources was a very promising approach. Accordingly, our generation component 1VM—GECO is an acronym for &amp;quot;VerbMobil GEneration COmponents.&amp;quot; consists of one kernel generator and language— specific knowledge sources for the languages used in Verbmobil: German and English with current work on Japanese. Additionally, the kernel generator itself can be modularized furthermore into two separate components. The task of the so—called rnicroplanning component is to plan an utterance on a phrase— or sentence—level (Hovy, 1996) including word—choice (section 2). It generates an annotated dependency structure which is used by the syntactic generation component to realize an appropriate surface string for it (section 3). The main goal of this further modularization is a stepwise constraining of the search— space of alternative linguistic realizations, using abstracted views on different choice criteria. Multilingual generation in dialog translation imposes strong requirements on the generation module. A very prominent problem is the non— wellformedness (incorrectness, irrelevance, and inconsistency) of spontaneous inp</context>
<context position="5549" citStr="Hovy, 1996" startWordPosition="829" endWordPosition="830">anguage generation system such as selection and organization of the contents to be expressed are outside of the control of our generator. They have been decided by the human user of the translation system or they have been negotiated and computed by a transfer component. Nevertheless, there remain a number of different but highly interrelated subtasks of the generation process where decisions have to be made in order to determine and realize the translation result to be sent to a speech synthesis component. The diverse subtasks — often collectively denoted as microplanning (cf. (Levelt, 1989; Hovy, 1996)) — comprise the planning of a rough structure of the target language utterance, the determination of sentence borders, sentence type, topicalization, theme-rheme organization of sentential units, focus control, utilization of nominalized, or infinitival style, as well as triggering the generation of anaphora and lexical choice. In addition, they have to address the problem of expressibility of the selected contents in a text realization component, i.e., bridging the generation gap (see (Meteer, 1990)). The input to our microplanning component consists of semantic representations encoded in a </context>
</contexts>
<marker>Hovy, 1996</marker>
<rawString>E. Hovy. 1996. An overview of automated natural language generation. In X. Huang, editor, Proc. of the Intl. Symposium on NL Generation and the Processing of the Chinese Language, INP(C)-96, Shanghai, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Kasper</author>
<author>B Kiefer</author>
<author>K Netter</author>
<author>K VijayShanker</author>
</authors>
<date>1995</date>
<booktitle>Compilation of HPSG to TAG. In 33rd ACL,</booktitle>
<location>Cambridge, Mass.</location>
<contexts>
<context position="3511" citStr="Kasper et al., 1995" startWordPosition="506" endWordPosition="509">nsistency) of spontaneous input. It forces the realization of robust generation to be able to cope with erroneous and incomplete input data so that the quality of the generated output may vary between syntactically correct sentences and semantically understandable utterances. On the level of knowledge sources this is achieved by using a highly declarative HPSG grammar which very closely reflects the latest developments of the underlying linguistic theory (Pollard and Sag, 1994) and covers phenomena of spoken language. This HPSG is compiled into a TAG grammar in an offline pre-processing step (Kasper et al., 1995) which keeps the declarative nature of the grammar intact (section 3). Maybe the most important requirement on the generation module of a speech—to—speech translation system is real—time processing. The 110 above mentioned features of VM-GECO contribute to the efficiency of the generation component. The TAG-formalism is well known for the existence of efficient syntactic generation algorithms (Kilger and Finkler, 1995). In general, all knowledge sources of all modules are declarative. The main advantage is that this allows for an easier adaptation of the generation component to other domains, </context>
</contexts>
<marker>Kasper, Kiefer, Netter, VijayShanker, 1995</marker>
<rawString>R. Kasper, B. Kiefer, K. Netter, and K. VijayShanker. 1995. Compilation of HPSG to TAG. In 33rd ACL, Cambridge, Mass.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Kilger</author>
<author>W Finkler</author>
</authors>
<title>Incremental generation for real-time applications.</title>
<date>1995</date>
<tech>Research Report RR-95-11,</tech>
<institution>DFKI GmbH,</institution>
<location>Saarbriicken, Germany,</location>
<contexts>
<context position="3933" citStr="Kilger and Finkler, 1995" startWordPosition="570" endWordPosition="573">ments of the underlying linguistic theory (Pollard and Sag, 1994) and covers phenomena of spoken language. This HPSG is compiled into a TAG grammar in an offline pre-processing step (Kasper et al., 1995) which keeps the declarative nature of the grammar intact (section 3). Maybe the most important requirement on the generation module of a speech—to—speech translation system is real—time processing. The 110 above mentioned features of VM-GECO contribute to the efficiency of the generation component. The TAG-formalism is well known for the existence of efficient syntactic generation algorithms (Kilger and Finkler, 1995). In general, all knowledge sources of all modules are declarative. The main advantage is that this allows for an easier adaptation of the generation component to other domains, languages and semantic representation languages besides the easier extendability of the current system. The feasibility of the language adaptation was proved in the Verbmobil project itself where the (originally English) generator was recently extended to cover German and is currently adapted for Japanese. The adaptation to another domain and also to another specification language for intermediate structures was shown </context>
</contexts>
<marker>Kilger, Finkler, 1995</marker>
<rawString>A. Kilger and W. Finkler. 1995. Incremental generation for real-time applications. Research Report RR-95-11, DFKI GmbH, Saarbriicken, Germany, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>V Kumar</author>
</authors>
<title>Algorithms for constraintsatisfaction problems: A survey.</title>
<date>1992</date>
<journal>Al Magazine,</journal>
<pages>13--1</pages>
<contexts>
<context position="7952" citStr="Kumar, 1992" startWordPosition="1195" endWordPosition="1197">r is the demand to cope with multidirectional dependencies among decisions of the diverse subtasks of microplanning without preferring one temp_loc (12 13) work_acceptable 12 arg3 (12 14) perspective (12 11) temp_loc (12 IS) \ ILE3=■1 up demonstrative (13 1t2 ht1) 111 order of decisions over others. E.g., the choice of an interrogative sentence requires an (at least elliptical) verbal phrase as a major constituent of the sentence; nominalization or the choice of passive voice depends on the result of word choice, etc. Therefore, we conceived microplanning as a constraint-satisfaction problem (Kumar, 1992) representing undirected relations between variables. Thereby, variables are created for elements in the input to the generator. They are connected by means of weighted constraints. The domains of the variables correspond to abstractions of possible alternatives for syntactic realizations of the semantic elements including sets of specifications of lexical items and syntactic features. A solution of the constraint system is a globally consistent instantiation of the variables and is guaranteed to be a valid input for the syntactic generation module. Since there might be locally optimal mapping</context>
</contexts>
<marker>Kumar, 1992</marker>
<rawString>V. Kumar. 1992. Algorithms for constraintsatisfaction problems: A survey. Al Magazine, 13(1):32-44.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W J M Levelt</author>
</authors>
<title>Speaking: From Intention to Articulation.</title>
<date>1989</date>
<publisher>The MIT Press,</publisher>
<location>Cambridge, MA.</location>
<contexts>
<context position="5536" citStr="Levelt, 1989" startWordPosition="827" endWordPosition="828">lete natural language generation system such as selection and organization of the contents to be expressed are outside of the control of our generator. They have been decided by the human user of the translation system or they have been negotiated and computed by a transfer component. Nevertheless, there remain a number of different but highly interrelated subtasks of the generation process where decisions have to be made in order to determine and realize the translation result to be sent to a speech synthesis component. The diverse subtasks — often collectively denoted as microplanning (cf. (Levelt, 1989; Hovy, 1996)) — comprise the planning of a rough structure of the target language utterance, the determination of sentence borders, sentence type, topicalization, theme-rheme organization of sentential units, focus control, utilization of nominalized, or infinitival style, as well as triggering the generation of anaphora and lexical choice. In addition, they have to address the problem of expressibility of the selected contents in a text realization component, i.e., bridging the generation gap (see (Meteer, 1990)). The input to our microplanning component consists of semantic representations </context>
</contexts>
<marker>Levelt, 1989</marker>
<rawString>W.J.M. Levelt. 1989. Speaking: From Intention to Articulation. The MIT Press, Cambridge, MA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M W Meteer</author>
</authors>
<title>The &amp;quot;Generation Gap&amp;quot; -The Problem of Expressibility</title>
<date>1990</date>
<booktitle>in Text Planning. Ph.D. thesis,</booktitle>
<tech>BBN Report No. 7347.</tech>
<location>Amherst, MA.</location>
<contexts>
<context position="6055" citStr="Meteer, 1990" startWordPosition="905" endWordPosition="906">mponent. The diverse subtasks — often collectively denoted as microplanning (cf. (Levelt, 1989; Hovy, 1996)) — comprise the planning of a rough structure of the target language utterance, the determination of sentence borders, sentence type, topicalization, theme-rheme organization of sentential units, focus control, utilization of nominalized, or infinitival style, as well as triggering the generation of anaphora and lexical choice. In addition, they have to address the problem of expressibility of the selected contents in a text realization component, i.e., bridging the generation gap (see (Meteer, 1990)). The input to our microplanning component consists of semantic representations encoded in a minimal recursive structure following a variant of UDRT. Each individual indicated by some input utterance is formally represented by a discourse referent. Information about the individual is encoded within the DRS-conditions. Relations between descriptions of different discourse referents lead to a hierarchical semantic structure (see Figure 1 for a graphical representation of fragments of an example input to the generator). Discourse referents are depicted as boxes headed by individual names in; con</context>
</contexts>
<marker>Meteer, 1990</marker>
<rawString>M.W. Meteer. 1990. The &amp;quot;Generation Gap&amp;quot; -The Problem of Expressibility in Text Planning. Ph.D. thesis, Amherst, MA. BBN Report No. 7347.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I A Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar. Studies in Contemporary Linguistics.</title>
<date>1994</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago.</location>
<contexts>
<context position="3373" citStr="Pollard and Sag, 1994" startWordPosition="482" endWordPosition="485">oses strong requirements on the generation module. A very prominent problem is the non— wellformedness (incorrectness, irrelevance, and inconsistency) of spontaneous input. It forces the realization of robust generation to be able to cope with erroneous and incomplete input data so that the quality of the generated output may vary between syntactically correct sentences and semantically understandable utterances. On the level of knowledge sources this is achieved by using a highly declarative HPSG grammar which very closely reflects the latest developments of the underlying linguistic theory (Pollard and Sag, 1994) and covers phenomena of spoken language. This HPSG is compiled into a TAG grammar in an offline pre-processing step (Kasper et al., 1995) which keeps the declarative nature of the grammar intact (section 3). Maybe the most important requirement on the generation module of a speech—to—speech translation system is real—time processing. The 110 above mentioned features of VM-GECO contribute to the efficiency of the generation component. The TAG-formalism is well known for the existence of efficient syntactic generation algorithms (Kilger and Finkler, 1995). In general, all knowledge sources of a</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>C. Pollard and I. A. Sag. 1994. Head-Driven Phrase Structure Grammar. Studies in Contemporary Linguistics. University of Chicago Press, Chicago.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Schabes</author>
<author>A Abeille</author>
<author>A K Joshi</author>
</authors>
<title>Parsing strategies with &apos;lexicalized&apos; grammars: Application to tree adjoining grammars.</title>
<date>1988</date>
<booktitle>In COLING-88,</booktitle>
<pages>578--583</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="14145" citStr="Schabes et al., 1988" startWordPosition="2160" endWordPosition="2163">orming intelligent backtracking. The result of the constraint solving process for the input shown in Fig. 1 is given in Fig. 4. 3 The Realizer The syntactic realizer2 proceeds from the microplanning result as shown in Figure 5. It produces a derived phrase structure from which the output string is read off. The realizer is based on a fully lexicalized grammar in the sense that every lexical item selects for a finite set of possible phrase structures (called elementary trees). In particular, we use a Feature-Based Lexicalized Tree-Adjoining Grammar (FB-LTAG, see (Vijay-Shanker and Joshi, 1988; Schabes et al., 1988)) that is derived from an HPSG grammar (see section 4 for some more details). The elementary trees (see Figure 9) can be seen as maximal partial projections. A derivation of an utterance is constructed by combining appropriate elementary trees with the two elementary TAG operations of adjunction and substitution. For each node (i.e., lexical item) in the dependency tree, the tree selection phase determines the set of relevant TAG trees. A first tree retrieval step maps every object of the dependency tree into a set of applicable elementary TAG trees. The main tree selection phase uses informat</context>
</contexts>
<marker>Schabes, Abeille, Joshi, 1988</marker>
<rawString>Y. Schabes, A. Abeille, and A. K. Joshi. 1988. Parsing strategies with &apos;lexicalized&apos; grammars: Application to tree adjoining grammars. In COLING-88, pages 578-583, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Vijay-Shanker</author>
<author>A K Joshi</author>
</authors>
<title>Feature structure based tree adjoining grammars.</title>
<date>1988</date>
<booktitle>In COLING-88,</booktitle>
<pages>714--719</pages>
<location>Budapest, Hungary.</location>
<contexts>
<context position="14122" citStr="Vijay-Shanker and Joshi, 1988" startWordPosition="2156" endWordPosition="2159">binary incompatibility and performing intelligent backtracking. The result of the constraint solving process for the input shown in Fig. 1 is given in Fig. 4. 3 The Realizer The syntactic realizer2 proceeds from the microplanning result as shown in Figure 5. It produces a derived phrase structure from which the output string is read off. The realizer is based on a fully lexicalized grammar in the sense that every lexical item selects for a finite set of possible phrase structures (called elementary trees). In particular, we use a Feature-Based Lexicalized Tree-Adjoining Grammar (FB-LTAG, see (Vijay-Shanker and Joshi, 1988; Schabes et al., 1988)) that is derived from an HPSG grammar (see section 4 for some more details). The elementary trees (see Figure 9) can be seen as maximal partial projections. A derivation of an utterance is constructed by combining appropriate elementary trees with the two elementary TAG operations of adjunction and substitution. For each node (i.e., lexical item) in the dependency tree, the tree selection phase determines the set of relevant TAG trees. A first tree retrieval step maps every object of the dependency tree into a set of applicable elementary TAG trees. The main tree select</context>
</contexts>
<marker>Vijay-Shanker, Joshi, 1988</marker>
<rawString>K. Vijay-Shanker and A. K. Joshi. 1988. Feature structure based tree adjoining grammars. In COLING-88, pages 714-719, Budapest, Hungary.</rawString>
</citation>
<citation valid="true">
<authors>
<author>W Wahlster</author>
</authors>
<title>Verbmobil: Translation of face-to-face dialoges.</title>
<date>1993</date>
<booktitle>In MT Summit IV, Kobe,</booktitle>
<contexts>
<context position="1481" citStr="Wahlster, 1993" startWordPosition="204" endWordPosition="205">est developments of the underlying linguistic theory, utilizing their pre-processing into the TAG formalism. The declarative nature of the knowledge bases, i.e., the microplanning constraints and the HPSG grammars allowed an easy adaption to new domains and languages. The successful integration of our component into the translation system Verbmobil proved the fulfillment of the specific real-time constraints. 1 Introduction In this paper we present core aspects of the multilingual natural language generation component VM-GECO1 that has been integrated into the research prototype of Verbmobil (Wahlster, 1993; Bub et al., 1997), a system for spontaneous speech—to—speech dialog translation. In order to achieve multilinguality as elegantly as possible we found that a clear modular separation between a language—independent general kernel generator and language—specific parts which consist of syntactic and lexical knowledge sources was a very promising approach. Accordingly, our generation component 1VM—GECO is an acronym for &amp;quot;VerbMobil GEneration COmponents.&amp;quot; consists of one kernel generator and language— specific knowledge sources for the languages used in Verbmobil: German and English with current </context>
</contexts>
<marker>Wahlster, 1993</marker>
<rawString>W. Wahlster. 1993. Verbmobil: Translation of face-to-face dialoges. In MT Summit IV, Kobe, Japan.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>