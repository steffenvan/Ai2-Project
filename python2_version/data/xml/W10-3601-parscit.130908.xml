<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004556">
<title confidence="0.9969625">
Boosting N-gram Coverage for Unsegmented Languages Using
Multiple Text Segmentation Approach
</title>
<author confidence="0.959175">
Solomon Teferra Abate Laurent Besacier Sopheap Seng
</author>
<affiliation confidence="0.611271">
LIG Laboratory, LIG Laboratory, LIG Laboratory,
</affiliation>
<address confidence="0.572714333333333">
CNRS/UMR-5217 CNRS/UMR-5217 CNRS/UMR-5217
solomon.abate@imag.fr laurent.besacier@imag.fr MICA Center, CNRS/UMI-
2954
</address>
<email confidence="0.960806">
sopheap.seng@imag.fr
</email>
<sectionHeader confidence="0.976589" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9997368125">
Automatic word segmentation errors,
for languages having a writing system
without word boundaries, negatively af-
fect the performance of language mod-
els. As a solution, the use of multiple,
instead of unique, segmentation has re-
cently been proposed. This approach
boosts N-gram counts and generates
new N-grams. However, it also pro-
duces bad N-grams that affect the lan-
guage models&apos; performance. In this pa-
per, we study more deeply the contribu-
tion of our multiple segmentation ap-
proach and experiment on an efficient
solution to minimize the effect of adding
bad N-grams.
</bodyText>
<sectionHeader confidence="0.996302" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999993684210526">
A language model is a probability assignment
over all possible word sequences in a natural
language. It assigns a relatively large probabili-
ty to meaningful, grammatical, or frequent word
sequences and a low probability or a zero proba-
bility to nonsensical, ungrammatical or rare
ones. The statistical approach used in N-gram
language modeling requires a large amount of
text data in order to make an accurate estimation
of probabilities. These data are not available in
large quantities for under-resourced languages
and the lack of text data has a direct impact on
the performance of language models. While the
word is usually a basic unit in statistical lan-
guage modeling, word identification is not a
simple task even for languages that separate
words by a special character (a white space in
general). For unsegmented languages, which
have a writing system without obvious word de-
limiters, the N-grams of words are usually esti-
mated from the text corpus segmented into
words employing automatic methods. Automat-
ic segmentation of text is not a trivial task and
introduces errors due to the ambiguities in natu-
ral language and the presence of out of vocabu-
lary words in the text.
While the lack of text resources has a nega-
tive impact on the performance of language
models, the errors produced by the word seg-
mentation make those data even less usable. The
word N-grams not found in the training corpus
could be due not only to the errors introduced
by the automatic segmentation but also to the
fact that a sequence of characters could have
more than one correct segmentation.
In previous article (Seng et al., 2009), we
have proposed a method to estimate an N-gram
language model from the training corpus on
which each sentence is segmented into multiple
ways instead of a unique segmentation. The ob-
jective of multiple segmentation is to generate
more N-grams from the training corpus to use in
language modeling. It was possible to show that
this approach generates more N-grams (com-
pared to the classical dictionary-based unique
segmentation method) that are potentially useful
and relevant in language modeling. The applica-
tion of multiple segmentation in language mod-
eling for Khmer and Vietnamese showed im-
provement in terms of tri-gram hits and recogni-
tion error rate in Automatic Speech Recognition
(ASR) systems.
This work is a continuation of our previous
work on the use of multiple segmentation. It is
conducted on Vietnamese only. A close analysis
of N-gram counts shows that the approach has
in fact two contributions: boosting the N-gram
</bodyText>
<page confidence="0.798171">
1
</page>
<bodyText confidence="0.990658125">
Proceedings of the 1st Workshop on South and Southeast Asian Natural Language Processing (WSSANLP), pages 1–7,
the 23rd International Conference on Computational Linguistics (COLING), Beijing, August 2010
counts that are generated with first best segmen-
tation and generating new N-grams. We have
also identified that there are N-grams that nega-
tively affect the performance of the language
models. In this paper, we study the contribution
of boosting N-gram counts and of new N-grams
to the performance of the language models and
consequently to the recognition performance.
We also present experiments where rare or bad
N-grams are cut off in order to minimize their
negative effect on the performance of the lan-
guage models.
The paper is organized as follows: section 2
presents the theoretical background of our mul-
tiple segmentation approach; in section 3 we
point out the set up of our experiment; in sec-
tion 4 we present the results of our detailed sta-
tistical analysis of N-grams generated by multi-
ple segmentation systems. Section 5 presents
the evaluation results of our language models
for ASR and finally, we give concluding re-
marks.
</bodyText>
<sectionHeader confidence="0.831374" genericHeader="method">
2 Multiple Text Segmentation
</sectionHeader>
<bodyText confidence="0.999976392405063">
Text segmentation is a fundamental task in nat-
ural language processing (NLP). Many NLP ap-
plications require the input text segmented into
words before making further progress because
the word is considered the basic semantic unit in
natural languages. For unsegmented languages
segmenting text into words is not a trivial task.
Because of ambiguities in human languages, a
sequence of characters may be segmented in
more than one way to produce a sequence of
valid words. This is due to the fact that there
are different segmentation conventions and the
definition of word in a language is often am-
biguous.
Text segmentation techniques generally use
an algorithm which searches in the text the
words corresponding to those in a dictionary. In
case of ambiguity, the algorithm selects the one
that optimizes a parameter dependent on the
chosen strategy. The most common optimiza-
tion strategies consist of maximizing the length
of words (“longest matching”) or minimizing
the number of words in the entire sentence
(“maximum matching”). These techniques rely
heavily on the availability and the quality of the
dictionaries and while it is possible to automati-
cally generate a dictionary from an unsegment-
ed text corpus using unsupervised methods, dic-
tionaries are often created manually. The state-
of-the-art methods generally use a combination
of hand-crafted, dictionary and statistical tech-
niques to obtain a better result. However, statis-
tical methods need a large corpus segmented
manually beforehand. Statistical methods and
complex training methods are not appropriate in
the context of under-resourced languages as the
resources needed to implement these methods
do not exist. For an under-resourced language,
we seek segmentation methods that allow better
exploitation of the limited resources. In our pre-
vious paper (Seng et al., 2009) we have indicat-
ed the problems of existing text segmentation
approaches and introduced a weighted finite
state transducer (WFST) based multiple text
segmentation algorithm.
Our approach is implemented using the AT &amp;
T FSM Toolkit (Mohri et al., 1998). The algo-
rithm is inspired with the work on the segmen-
tation of Arabic words (Lee et al., 2003). The
multiple segmentation of a sequence of charac-
ters is made using the composition of three con-
trollers. Given a finite list of words we can
build a finite state transducer M (or word trans-
ducer) that, once composed with an acceptor I
of the input string that represent a single charac-
ter with each arc, generates a lattice of the
words that represent all of the possible segmen-
tations. To handle out-of-vocabulary entries, we
make a model of any string of characters by a
star closure operation over all the possible char-
acters. Thus, the unknown word WFST can
parse any sequence of characters and generate a
unique unk word symbol. The word transducer
can, therefore, be described in terms of the
WFST operations as M = (WD ∪ UNK)+
where WD is a WFST that represents the dictio-
nary and UNK represents the unknown word
WFST. Here, ∪ and + are the union and Kleene
“+” closure operations. A language model L is
used to score the lattice of all possible segmen-
tations obtained by the composition of our word
transducer M and the input string I. A language
model of any order can be represented by a
WFST. In our case, it is important to note that
only a simple uni-gram language model is used.
The uni-gram model is estimated from a small
training corpus segmented automatically into
words using a dictionary based method. The
composition of the sequence of input string I
</bodyText>
<page confidence="0.962554">
2
</page>
<bodyText confidence="0.99949775">
with the word transducer M yields a transducer
that represents all possible segmentations. This
transducer is then composed with the language
model L, resulting in a transducer that repre-
sents all possible segmentations for the input
string I, scored according to L. The highest
scoring paths of the compound transducer is the
segmentation m that can be defined as:
</bodyText>
<equation confidence="0.824331">
P m=maxP mk 
</equation>
<bodyText confidence="0.963919">
The segmentation procedure can then be ex-
pressed formally as:
m=bestpath I-M-L
where ◦ is the composition operator. The N-
best segmentations are obtained by decoding the
final lattice to output the N-best highest scoring
paths and will be used for the N-gram count.
</bodyText>
<sectionHeader confidence="0.998277" genericHeader="method">
3 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.996247">
3.1 Language Modeling
</subsectionHeader>
<bodyText confidence="0.999981591836735">
First, it is important to note that Vietnamese
texts are naturally segmented into syllables (not
words). Each syllable tends to have its own
meaning and thus a strong identity. However,
the Vietnamese monosyllable is not automati-
cally a word as we would define a word in Eng-
lish. Often, two syllables go together to form a
single word, which can be identified by the way
it functions grammatically in a sentence. To
have a word-based language model, word seg-
mentation would, therefore, be a must in Viet-
namese.
A Vietnamese training corpus that contains 3
millions sentences from broadcast news domain
has been used in this experiment. A Vietnamese
dictionary of 30k words has been used both for
the segmentation and counting the N-grams.
Therefore, in the experiments, the ASR vocabu-
lary always remains the same and only the lan-
guage model is changing. The segmentation of
the corpus with dictionary based, “longest
matching” unique segmentation method gives a
corpus of 46 millions words. A development
corpus of 1000 sentences, which has been seg-
mented automatically to obtain 44k words, has
been used to evaluate the tri-gram hits and the
perplexity. The performance of each language
model produced will be evaluated in terms of
the tri-gram hits and perplexity on the develop-
ment corpus and in terms of ASR performance
on a separate speech test set (different from the
development set).
First of all, a language model named lm_1 is
trained using the SRILM toolkit (Stolcke 2002)
from the first best segmentation (Segmul1),
which has the highest scoring paths (based on
the transducer explained in section 2) of each
sentence in the whole corpus. Then, additional
language models have been trained using the
corpus segmented with N-best segmentation:
the number of N-best segmentations to generate
for each sentence is fixed to 2, 5, 10, 50, 100
and 1000. The resulting texts are named accord-
ingly as Segmul2, Segmul5, Segmul10, Seg-
mul50, Segmul100, Segmul1000. Using these
as training data, we have developed different
language models. Note that a tri-gram that ap-
pears several times in multiple segmentations of
a single sentence has a count set to one.
</bodyText>
<subsectionHeader confidence="0.997336">
3.2 ASR System
</subsectionHeader>
<bodyText confidence="0.999928724137931">
Our automatic speech recognition systems use
the CMU’s Sphinx3 decoder. The decoder uses
Hidden Markov Models (HMM) with continu-
ous output probability density functions. The
model topology is a 3-state, left-to-right HMM
with 16 Gaussian mixtures per state. The pre-
processing of the system consists of extracting a
39 dimensional features vector of 13 MFCCs,
the first and second derivatives. The CMU’s
SphinxTrain has been used to train the acoustic
models used in our experiment.
The Vietnamese acoustic modeling training
corpus is made up of 14 hours of transcribed
read speech. More details on the automatic
speech recognition system for Vietnamese lan-
guage can be found in (Le et al., 2008). While
the evaluation metric WER (Word Error Rate)
is generally used to evaluate and compare the
performance of the ASR systems, this metric
does not fit well for unsegmented languages be-
cause the errors introduced during the segmen-
tation of the references and the output hypothe-
sis may prevent a fair comparison of different
ASR system outputs. We, therefore, used the
Syllable Error Rate (SER) as Vietnamese text is
composed of syllables naturally separated by
white space. The automatic speech recognition
is done on a test corpus of 270 utterances
(broadcast news domain).
</bodyText>
<page confidence="0.997746">
3
</page>
<sectionHeader confidence="0.910123" genericHeader="method">
4 Statistical Analysis of N-grams in
Multiple Text Segmentation
</sectionHeader>
<bodyText confidence="0.999932">
The change in the N-gram count that results
from multiple segmentation is two fold: first
there is a boosting of the counts of the N-grams
that are already found with the first best seg-
mentation, and secondly new N-grams are
added. As we have made a closed-vocabulary
counting, there are no new uni-grams resulting
from multiple segmentation. For the counting,
the SRILM toolkit (Stolcke 2002) is used set-
ting the -gtnmin option to zero so that all the N-
gram counts can be considered.
Figure 1 shows the distribution of tri-gram
counts for the unique and multiple segmentation
of the training corpus. It can be seen that the
majority of the tri-grams have counts in the
range of one to three.
</bodyText>
<figure confidence="0.495139">
Counts Range
</figure>
<figureCaption confidence="0.999654">
Figure 1: Distribution of tri-gram counts
</figureCaption>
<bodyText confidence="0.999545411764706">
The boosting (the counts of the tri-grams that
are already found with the first best segmenta-
tion) effect of the multiple segmentation is indi-
cated in table 1. We can see from the table that
Segmul2, for example, reduced the number of
rare tri-grams (count range 1-3) from 19.04 to
16.15 million. Consequently, the ratio of rare
tri-grams to all tri-grams that are in Segmul1 is
reduced from 94% (19.04/20.31*100) of Seg-
mul1 only to 79% (15.96/20.31*100) by the
boosting effect of Segmul1000, which increased
the number of tri-grams with count range of 4-9
from 0.91M to 3.34M. This implies, in the con-
text of under-resourced languages, that multiple
segmentation is boosting the N-gram counts.
However, one still has to verify if this boosting
is relevant or not for ASR.
</bodyText>
<table confidence="0.999528666666667">
Multiple Counts Range
Seg.
1–3 4-9 10-99 100-999 ≥1000
(M) (M) (M) (M) (M)
0.00054
0.0017
0.0017
Segmul1 19.04 0.91 0.34 0.016
Segmul2 16.15 3.23 0.89 0.043
Segmul5 16.06 3.28 0.92 0.045
Segmul10 16.03 3.30 0.93 0.045 0.0017
Segmul50 15.99 3.33 0.95 0.046 0.0017
0.0017
Segmul100 15.98 3.33 0.95 0.046
Segmul1000 15.96 3.34 0.96 0.046 0.0017
</table>
<tableCaption confidence="0.999864">
Table 1. boosting tri-gram counts
</tableCaption>
<bodyText confidence="0.999452066666667">
We have also analyzed the statistical behav-
ior of the newly added tri-grams with regard to
their count distribution (see figure 2). As we can
see from the figure, the distribution of the new
tri-grams is somehow similar to the distribution
of the whole tri-grams that is indicated in figure
1.
As shown in table 2, the total number of
newly added tri-grams is around 15 millions.
We can see from the table that the rate of new
tri-gram contribution of each segmentation in-
creases as N increases in the N-best segmenta-
tion. However, as it is indicated in figure 2, the
major contribution is in the area of rare tri-
grams.
</bodyText>
<figure confidence="0.54439">
Counts Range
</figure>
<figureCaption confidence="0.999394">
Figure 2: Distribution of new tri-gram counts
</figureCaption>
<figure confidence="0.999063382352941">
No. of tri-grams 35,000,000
30,000,000
25,000,000
20,000,000
15,000,000
10,000,000
5,000,000
0
40,000,000
Segmul1
Segmul2
Segmul5
Segmul1000
Segmul10
Segmul50
Segmul100
1—3 4—9 10—99 100-999 ≥1000
14,000,000
12,000,000
Number of tri-grams
10,000,000
8,000,000
6,000,000
4,000,000
2,000,000
0
16,000,000
1—3 4—9 10—99 100-999 ≥1000
Segmul 2
Segmul 5
Segmul 10
Segmul 50
Segmul 100
Segmul 1000
</figure>
<page confidence="0.964486">
4
</page>
<table confidence="0.617166857142857">
Mul. Segmentation No. %
Segmul2 4,125,881 26,05
Segmul5 8,249,684 52,09
Segmul10 10,355,433 65,39
Segmul50 13,002,700 82,11
Segmul100 14,672,827 92,65
Segmul1000 15,836,120 100,0
</table>
<tableCaption confidence="0.959198">
Table 2. tri-gram contribution of multiple seg-
mentation
</tableCaption>
<sectionHeader confidence="0.992564" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.999908857142857">
In this section we present the various language
models we have developed and their perfor-
mance in terms of perplexity, tri-gram hits and
ASR performance (syllable error rate).
We use the results obtained with the method
presented in (Seng et al., 2009) as baseline. This
method consists in re-estimating the N-gram
counts using the multiple segmentation of the
training data and add one to the count of a tri-
gram that appears several times in multiple seg-
mentations of a single sentence. These baseline
results are presented in Table 3. The results
show an increase of the tri-gram coverage and
slight improvements of the ASR performance.
</bodyText>
<table confidence="0.999757">
Language 3gs(M) 3g hit(% ) Ppl SER
Models
Lm_1 20.31 46.9 126.6 27
lm_2 24.06 48.6 118.1 26.2
Lm_5 28.92 49.2 125.9 27
Lm_10 32.82 49.4 129.0 26.5
Lm_50 34.20 49.7 133.4 26.7
lm_100 34.93 49.7 134.8 26.9
lm_1000 36.11 49.88 137.7 27.3
</table>
<tableCaption confidence="0.9968345">
Table 3. Results of experiments using the base-
line method presented in (Seng et al., 2009)
</tableCaption>
<subsectionHeader confidence="0.8262945">
5.1 Separate effect of boosting tri-gram
counts
</subsectionHeader>
<bodyText confidence="0.999986217391304">
To see the effect of boosting tri-gram counts
only, we have updated the counts of the tri-
grams obtained from the 1-best segmentation
(baseline approach) by the tri-gram counts of
different multiple segmentations. Note that no
new tri-grams are added here, and we evaluate
only the effect and, therefore, the tri-gram hit
remains the same as that of lm_1.
We have then developed different language
models using the uni-gram and bi-gram counts
of the first best segmentation and the updated
trigram counts after multiple segmentation. The
performance of the language models have been
evaluated in terms of perplexity and their contri-
bution to the performance improvement of a
speech recognition system. We have observed
(detailed results are not reported here) that
boosting only the tri-gram counts has not con-
tributed any improvement in the performance of
the language models. The reason is probably
due to the fact that simply updating tri-gram
counts without updating the uni-grams and the
bi-grams lead to a biased and inefficient LM.
</bodyText>
<subsectionHeader confidence="0.998752">
5.2 Separate effect of new tri-grams
</subsectionHeader>
<bodyText confidence="0.999782714285714">
To explore the contributions of only newly
added tri-grams, we have added their counts to
the N-gram counts of Segmul1. It is important
to note that the model obtained in that case is
different from the baseline model whose results
are presented in Table 3 (the counts of the tri-
grams already found in the unique segmentation
are different between models). As it is presented
in table 4, including only the newly added tri-
grams consistently improved tri-gram hits,
while the improvement in perplexity stopped at
Segmul10. Moreover, the use of only new tri-
grams do not reduce the speech recognition er-
ror rate.
</bodyText>
<table confidence="0.999564222222222">
Language 3gs 3g ppl SER
Models (M) hit(% )
lm_1 20.3 46.9 126.6 27
lm_2_new 24.4 48.7 119.1 26.9
lm_5_new 28.6 49.0 122.5 27.8
lm_10_new 30.7 49.2 124.2 27.9
lm_50_new 33.3 49.4 126.8 27.8
lm_100_new 35 49.8 127.8 28
lm_1000_new 36.1 49.9 129.7 27.9
</table>
<tableCaption confidence="0.999773">
Table 4. Contributions of new tri-grams
</tableCaption>
<subsectionHeader confidence="0.9887945">
5.3 Pooling unique and multiple segmenta-
tion models
</subsectionHeader>
<bodyText confidence="0.999908307692308">
We have developed language models by pooling
unique and multiple segmentation models alto-
gether. For instance, all the N-grams of lm_5
multiple segmentation are pooled with all N-
grams of lm_1 unique segmentation before esti-
mating the language model probabilities. In oth-
er words, ngram-count command is used with
multiple count files. The results are presented in
table 5.
As it can be noted from table 5, we have got a
significant improvement in all the evaluation
criteria as compared with the performance of
lm_1 that has perplexity of 126.6, tri-gram hit
</bodyText>
<page confidence="0.96922">
5
</page>
<bodyText confidence="0.97279675">
of 46.91% and SER of 27. The best result ob-
tained (25.4) shows a 0.8 absolute SER reduc-
tion compared to the best result presented in
(Seng et al., 2009).
</bodyText>
<table confidence="0.999759111111111">
Language 3gs 3g ppl SER
Models (M) hit(% )
lm_1 20.31 46.9 126.6 27
lm_2+lm_1 24.4 48.7 120.9 25.4
lm_5+lm_1 29.12 49.2 123.2 26.2
lm_10+lm_1 31.4 49.4 124.2 26
lm_50+lm_1 34.3 49.7 126 26
lm_100+lm_1 35 49.8 126.5 26.2
lm_1000+lm_1 36.2 49.9 128 26.2
</table>
<tableCaption confidence="0.999785">
Table 5. Performance with pooling
</tableCaption>
<subsectionHeader confidence="0.957706">
5.4 Cutting off rare tri-grams
</subsectionHeader>
<bodyText confidence="0.999955769230769">
With the assumption that bad N-grams occur
rarely, we cut off rare tri-grams from the counts
in developing language models. We consider all
tri-grams with a count of 1 to be rare. Our hope,
here, is that using this cut off we will remove
bad N-grams introduced by the multiple seg-
mentation approach, while keeping correct new
N-grams in the model. Table 6 shows the per-
formance of the language models developed
with or without tri-gram cut off for the baseline
method (the results presented on the lines indi-
cating All3gs are the same as the ones presented
in Table 3) .
</bodyText>
<table confidence="0.999515705882353">
Language models Evaluation Criteria
3gs 3g hit ppl SER
(M) (%)
lm_1 All 3gs 20.31 46.91 126.6 27
Cut off 4.17 38.09 129.3 26.6
lm_2 All 3gs 24.06 48.6 118.1 26.2
Cut off 5.11 39.6 121.0 26.7
lm_5 All 3gs 28.92 49.2 125.9 27
Cut off 6.4 40.11 129.2 26.6
lm_10 All 3gs 32.82 49.41 129.0 26.5
Cut off 6.98 40.27 132.4 26.6
lm_50 All 3gs 34.20 49.68 133.4 26.7
Cut off 7.8 40.51 136.9 26.9
lm_100 All 3gs 34.93 49.74 134.8 26.9
Cut off 7.98 40.59 138.4 26.8
lm_1000 All 3gs 36.11 49.88 137.7 27.3
Cut off 8.33 40.71 141.3 26.8
</table>
<tableCaption confidence="0.995903">
Table 6. Performance with cut off.
</tableCaption>
<bodyText confidence="0.999966333333333">
The result shows that cutting off reduced the
number of tri-grams highly (4 tri-grams over 5
are removed in that case). It, therefore, reduces
the size of the language models significantly.
Although the results obtained are not conclu-
sive, a reduction of recognition error rate has
been observed in four out of the seven cases
while the perplexity increased and the tri-gram
hits decreased in all cases.
</bodyText>
<note confidence="0.662988">
5.5 Hybrid of pooling and cutting off
methods
</note>
<bodyText confidence="0.9993225625">
As it has been already indicated, cutting off in-
creased the perplexity of the language models
and decreased the tri-gram hits. To reduce the
negative effect of cutting off on tri-gram hits
and perplexity, we have developed language
models using both pooling and cut off methods.
We then cut off tri-grams of count 1 from the
pooled N-grams. The result, as presented in ta-
ble 7, shows that we can gain significant reduc-
tion in recognition error rate and improvement
in tri-gram hits as compared to lm_1 that is de-
veloped with cut off, even if no improvement in
perplexity is observed.
The best result obtained (25.9) shows a 0.3
absolute SER reduction compared to the best
system presented in (Seng et al., 2009).
</bodyText>
<table confidence="0.9953386">
Language Models 3gs 3g hit ppl SE
(M) (% ) R
lm_1 (no cutoff) 20.3 46.9 126.6 27
lm_1 (cutoff) 4.2 38.1 129.3 26.6
lm_2+lm_1 (cutoff) 5.2 39.7 126.4 26.8
lm_5+lm_1 (cutoff) 6.4 40.2 129.5 25.9
lm_10+lm_1 (cutoff) 7.0 40.3 131.1 26.3
lm_50+lm_1 (cutoff) 7.8 40.5 133.5 26.4
lm_100+lm_1 (cutoff) 8.0 40.6 134.3 26.4
lm_1000+lm_1 (cutoff) 8.3 40.7 161.5 26.7
</table>
<tableCaption confidence="0.999787">
Table 7. Performance with hybrid method
</tableCaption>
<sectionHeader confidence="0.983293" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.9999675625">
The two major contributions of multiple seg-
mentation are generation of new N-grams and
boosting N-gram counts of those found in first
best segmentation. However, it also produces
bad N-grams that affect the performance of lan-
guage models. In this paper, we studied the con-
tribution of multiple segmentation approach
more deeply and conducted experiments on effi-
cient solutions to minimize the effect of adding
bad N-grams. Since only boosting the tri-gram
counts of first best segmentation and adding
only new tri-grams did not reduce recognition
error rate, we have proposed to pool all N-
grams of N-best segmentations to that of first
best segmentation and got a significant im-
provement in perplexity and tri-gram hits from
</bodyText>
<page confidence="0.9954">
6
</page>
<bodyText confidence="0.99992024137931">
which we obtained the maximum (0.8 absolute)
reduction in recognition error rate.
To minimize the effect of adding bad N-
grams, we have cut off rare tri-grams in lan-
guage modeling and got reduction in recogni-
tion error rate. The significant reduction of tri-
grams that resulted from the cut off revealed
that the majority of tri-grams generated by mul-
tiple segmentation have counts 1. Cutting off
such a big portion of the trigrams reduced tri-
gram hits and as a solution, we proposed a hy-
brid of both pooling and cutting off tri-grams
from which we obtained a significant reduction
in recognition error rate.
It is possible to conclude that our methods
make the multiple segmentation approach more
useful by minimizing the effect of bad N-grams
that it generates and utilizing the contribution of
different multiple segmentations.
However, we still see rooms for improve-
ment. A systematic selection of new tri-grams
(for example, based on the probabilities of the
N-grams and/or application of simple linguistic
criteria to evaluate the usefulness of new tri-
grams), with the aim of reducing bad tri-grams,
might lead to performance improvement. Thus,
we will do experiments in this line. We will also
apply these methods to other languages, such as
Khmer.
</bodyText>
<sectionHeader confidence="0.998267" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996305">
Lee, Young-Suk, Papineni, Kishore, Roukos, Salim
Emam, Ossama and Hassan, Hany. 2003. Lan-
guage model based arabic word segmentation. In
Proceedings of the ACL’03, pp. 399–406.
Le, Viet-Bac, Besacier, Laurent, Seng, Sopheap,
Bigi, Brigite and Do, Thi-Ngoc-Diep. 2008. Re-
cent advances in automatic speech recognition
for vietnamese. SLTU’08, Hanoi Vietnam.
Mohri, Mehryar, Fernando C. N. Pereira, and
Michael Riley, “A rational design for a weighted
finite-state transducer library,” in Lecture Notes in
Computer Science. Springer, 1998, pp. 144–158.
Seng, Sopheap, Besacier, Laurent, Bigi, Brigitte,
Castelli, Eric. 2009. Multiple Text Segmentation
for Statistical Language Modeling. InterSpeech,
Brighton, UK,
Stolcke, Andreas. 2002. SRILM: an extensible lan-
guage modeling toolkit. Proceedings of Interna-
tional Conference on Spoken Language Process-
ing, volume II, 901–904 . 129.88.65.115
</reference>
<page confidence="0.999518">
7
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.730795">
<title confidence="0.9992525">Boosting N-gram Coverage for Unsegmented Languages Using Multiple Text Segmentation Approach</title>
<author confidence="0.997615">Solomon Teferra Laurent Sopheap</author>
<affiliation confidence="0.9410105">LIG LIG LIG CNRS/UMR-5217 CNRS/UMR-5217 Center,</affiliation>
<address confidence="0.927239">solomon.abate@imag.fr laurent.besacier@imag.fr 2954</address>
<email confidence="0.989425">sopheap.seng@imag.fr</email>
<abstract confidence="0.993101588235294">Automatic word segmentation errors, for languages having a writing system without word boundaries, negatively affect the performance of language models. As a solution, the use of multiple, instead of unique, segmentation has recently been proposed. This approach boosts N-gram counts and generates new N-grams. However, it also produces bad N-grams that affect the language models&apos; performance. In this paper, we study more deeply the contribution of our multiple segmentation approach and experiment on an efficient solution to minimize the effect of adding bad N-grams.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Young-Suk Lee</author>
<author>Kishore Papineni</author>
<author>Salim Emam Roukos</author>
<author>Ossama</author>
<author>Hany Hassan</author>
</authors>
<title>Language model based arabic word segmentation.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL’03,</booktitle>
<pages>399--406</pages>
<contexts>
<context position="6849" citStr="Lee et al., 2003" startWordPosition="1080" endWordPosition="1083"> in the context of under-resourced languages as the resources needed to implement these methods do not exist. For an under-resourced language, we seek segmentation methods that allow better exploitation of the limited resources. In our previous paper (Seng et al., 2009) we have indicated the problems of existing text segmentation approaches and introduced a weighted finite state transducer (WFST) based multiple text segmentation algorithm. Our approach is implemented using the AT &amp; T FSM Toolkit (Mohri et al., 1998). The algorithm is inspired with the work on the segmentation of Arabic words (Lee et al., 2003). The multiple segmentation of a sequence of characters is made using the composition of three controllers. Given a finite list of words we can build a finite state transducer M (or word transducer) that, once composed with an acceptor I of the input string that represent a single character with each arc, generates a lattice of the words that represent all of the possible segmentations. To handle out-of-vocabulary entries, we make a model of any string of characters by a star closure operation over all the possible characters. Thus, the unknown word WFST can parse any sequence of characters an</context>
</contexts>
<marker>Lee, Papineni, Roukos, Ossama, Hassan, 2003</marker>
<rawString>Lee, Young-Suk, Papineni, Kishore, Roukos, Salim Emam, Ossama and Hassan, Hany. 2003. Language model based arabic word segmentation. In Proceedings of the ACL’03, pp. 399–406.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Viet-Bac Le</author>
<author>Laurent Besacier</author>
<author>Sopheap Seng</author>
<author>Brigite Bigi</author>
<author>Thi-Ngoc-Diep Do</author>
</authors>
<title>Recent advances in automatic speech recognition for vietnamese. SLTU’08,</title>
<date>2008</date>
<location>Hanoi</location>
<contexts>
<context position="11789" citStr="Le et al., 2008" startWordPosition="1910" endWordPosition="1913">oder uses Hidden Markov Models (HMM) with continuous output probability density functions. The model topology is a 3-state, left-to-right HMM with 16 Gaussian mixtures per state. The preprocessing of the system consists of extracting a 39 dimensional features vector of 13 MFCCs, the first and second derivatives. The CMU’s SphinxTrain has been used to train the acoustic models used in our experiment. The Vietnamese acoustic modeling training corpus is made up of 14 hours of transcribed read speech. More details on the automatic speech recognition system for Vietnamese language can be found in (Le et al., 2008). While the evaluation metric WER (Word Error Rate) is generally used to evaluate and compare the performance of the ASR systems, this metric does not fit well for unsegmented languages because the errors introduced during the segmentation of the references and the output hypothesis may prevent a fair comparison of different ASR system outputs. We, therefore, used the Syllable Error Rate (SER) as Vietnamese text is composed of syllables naturally separated by white space. The automatic speech recognition is done on a test corpus of 270 utterances (broadcast news domain). 3 4 Statistical Analys</context>
</contexts>
<marker>Le, Besacier, Seng, Bigi, Do, 2008</marker>
<rawString>Le, Viet-Bac, Besacier, Laurent, Seng, Sopheap, Bigi, Brigite and Do, Thi-Ngoc-Diep. 2008. Recent advances in automatic speech recognition for vietnamese. SLTU’08, Hanoi Vietnam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mehryar Mohri</author>
<author>Fernando C N Pereira</author>
<author>Michael Riley</author>
</authors>
<title>A rational design for a weighted finite-state transducer library,”</title>
<date>1998</date>
<booktitle>in Lecture Notes in Computer Science.</booktitle>
<pages>144--158</pages>
<publisher>Springer,</publisher>
<contexts>
<context position="6753" citStr="Mohri et al., 1998" startWordPosition="1061" endWordPosition="1064">egmented manually beforehand. Statistical methods and complex training methods are not appropriate in the context of under-resourced languages as the resources needed to implement these methods do not exist. For an under-resourced language, we seek segmentation methods that allow better exploitation of the limited resources. In our previous paper (Seng et al., 2009) we have indicated the problems of existing text segmentation approaches and introduced a weighted finite state transducer (WFST) based multiple text segmentation algorithm. Our approach is implemented using the AT &amp; T FSM Toolkit (Mohri et al., 1998). The algorithm is inspired with the work on the segmentation of Arabic words (Lee et al., 2003). The multiple segmentation of a sequence of characters is made using the composition of three controllers. Given a finite list of words we can build a finite state transducer M (or word transducer) that, once composed with an acceptor I of the input string that represent a single character with each arc, generates a lattice of the words that represent all of the possible segmentations. To handle out-of-vocabulary entries, we make a model of any string of characters by a star closure operation over </context>
</contexts>
<marker>Mohri, Pereira, Riley, 1998</marker>
<rawString>Mohri, Mehryar, Fernando C. N. Pereira, and Michael Riley, “A rational design for a weighted finite-state transducer library,” in Lecture Notes in Computer Science. Springer, 1998, pp. 144–158.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sopheap Seng</author>
<author>Laurent Besacier</author>
<author>Brigitte Bigi</author>
<author>Eric Castelli</author>
</authors>
<title>Multiple Text Segmentation for Statistical Language Modeling. InterSpeech,</title>
<date>2009</date>
<location>Brighton, UK,</location>
<contexts>
<context position="2546" citStr="Seng et al., 2009" startWordPosition="397" endWordPosition="400">hods. Automatic segmentation of text is not a trivial task and introduces errors due to the ambiguities in natural language and the presence of out of vocabulary words in the text. While the lack of text resources has a negative impact on the performance of language models, the errors produced by the word segmentation make those data even less usable. The word N-grams not found in the training corpus could be due not only to the errors introduced by the automatic segmentation but also to the fact that a sequence of characters could have more than one correct segmentation. In previous article (Seng et al., 2009), we have proposed a method to estimate an N-gram language model from the training corpus on which each sentence is segmented into multiple ways instead of a unique segmentation. The objective of multiple segmentation is to generate more N-grams from the training corpus to use in language modeling. It was possible to show that this approach generates more N-grams (compared to the classical dictionary-based unique segmentation method) that are potentially useful and relevant in language modeling. The application of multiple segmentation in language modeling for Khmer and Vietnamese showed impro</context>
<context position="6502" citStr="Seng et al., 2009" startWordPosition="1022" endWordPosition="1025">nsupervised methods, dictionaries are often created manually. The stateof-the-art methods generally use a combination of hand-crafted, dictionary and statistical techniques to obtain a better result. However, statistical methods need a large corpus segmented manually beforehand. Statistical methods and complex training methods are not appropriate in the context of under-resourced languages as the resources needed to implement these methods do not exist. For an under-resourced language, we seek segmentation methods that allow better exploitation of the limited resources. In our previous paper (Seng et al., 2009) we have indicated the problems of existing text segmentation approaches and introduced a weighted finite state transducer (WFST) based multiple text segmentation algorithm. Our approach is implemented using the AT &amp; T FSM Toolkit (Mohri et al., 1998). The algorithm is inspired with the work on the segmentation of Arabic words (Lee et al., 2003). The multiple segmentation of a sequence of characters is made using the composition of three controllers. Given a finite list of words we can build a finite state transducer M (or word transducer) that, once composed with an acceptor I of the input st</context>
<context position="15913" citStr="Seng et al., 2009" startWordPosition="2583" endWordPosition="2586">000 0 16,000,000 1—3 4—9 10—99 100-999 ≥1000 Segmul 2 Segmul 5 Segmul 10 Segmul 50 Segmul 100 Segmul 1000 4 Mul. Segmentation No. % Segmul2 4,125,881 26,05 Segmul5 8,249,684 52,09 Segmul10 10,355,433 65,39 Segmul50 13,002,700 82,11 Segmul100 14,672,827 92,65 Segmul1000 15,836,120 100,0 Table 2. tri-gram contribution of multiple segmentation 5 Experimental Results In this section we present the various language models we have developed and their performance in terms of perplexity, tri-gram hits and ASR performance (syllable error rate). We use the results obtained with the method presented in (Seng et al., 2009) as baseline. This method consists in re-estimating the N-gram counts using the multiple segmentation of the training data and add one to the count of a trigram that appears several times in multiple segmentations of a single sentence. These baseline results are presented in Table 3. The results show an increase of the tri-gram coverage and slight improvements of the ASR performance. Language 3gs(M) 3g hit(% ) Ppl SER Models Lm_1 20.31 46.9 126.6 27 lm_2 24.06 48.6 118.1 26.2 Lm_5 28.92 49.2 125.9 27 Lm_10 32.82 49.4 129.0 26.5 Lm_50 34.20 49.7 133.4 26.7 lm_100 34.93 49.7 134.8 26.9 lm_1000 3</context>
<context position="19414" citStr="Seng et al., 2009" startWordPosition="3170" endWordPosition="3173">. For instance, all the N-grams of lm_5 multiple segmentation are pooled with all Ngrams of lm_1 unique segmentation before estimating the language model probabilities. In other words, ngram-count command is used with multiple count files. The results are presented in table 5. As it can be noted from table 5, we have got a significant improvement in all the evaluation criteria as compared with the performance of lm_1 that has perplexity of 126.6, tri-gram hit 5 of 46.91% and SER of 27. The best result obtained (25.4) shows a 0.8 absolute SER reduction compared to the best result presented in (Seng et al., 2009). Language 3gs 3g ppl SER Models (M) hit(% ) lm_1 20.31 46.9 126.6 27 lm_2+lm_1 24.4 48.7 120.9 25.4 lm_5+lm_1 29.12 49.2 123.2 26.2 lm_10+lm_1 31.4 49.4 124.2 26 lm_50+lm_1 34.3 49.7 126 26 lm_100+lm_1 35 49.8 126.5 26.2 lm_1000+lm_1 36.2 49.9 128 26.2 Table 5. Performance with pooling 5.4 Cutting off rare tri-grams With the assumption that bad N-grams occur rarely, we cut off rare tri-grams from the counts in developing language models. We consider all tri-grams with a count of 1 to be rare. Our hope, here, is that using this cut off we will remove bad N-grams introduced by the multiple segm</context>
<context position="22023" citStr="Seng et al., 2009" startWordPosition="3633" endWordPosition="3636"> and decreased the tri-gram hits. To reduce the negative effect of cutting off on tri-gram hits and perplexity, we have developed language models using both pooling and cut off methods. We then cut off tri-grams of count 1 from the pooled N-grams. The result, as presented in table 7, shows that we can gain significant reduction in recognition error rate and improvement in tri-gram hits as compared to lm_1 that is developed with cut off, even if no improvement in perplexity is observed. The best result obtained (25.9) shows a 0.3 absolute SER reduction compared to the best system presented in (Seng et al., 2009). Language Models 3gs 3g hit ppl SE (M) (% ) R lm_1 (no cutoff) 20.3 46.9 126.6 27 lm_1 (cutoff) 4.2 38.1 129.3 26.6 lm_2+lm_1 (cutoff) 5.2 39.7 126.4 26.8 lm_5+lm_1 (cutoff) 6.4 40.2 129.5 25.9 lm_10+lm_1 (cutoff) 7.0 40.3 131.1 26.3 lm_50+lm_1 (cutoff) 7.8 40.5 133.5 26.4 lm_100+lm_1 (cutoff) 8.0 40.6 134.3 26.4 lm_1000+lm_1 (cutoff) 8.3 40.7 161.5 26.7 Table 7. Performance with hybrid method 6 Conclusion The two major contributions of multiple segmentation are generation of new N-grams and boosting N-gram counts of those found in first best segmentation. However, it also produces bad N-gram</context>
</contexts>
<marker>Seng, Besacier, Bigi, Castelli, 2009</marker>
<rawString>Seng, Sopheap, Besacier, Laurent, Bigi, Brigitte, Castelli, Eric. 2009. Multiple Text Segmentation for Statistical Language Modeling. InterSpeech, Brighton, UK,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM: an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>Proceedings of International Conference on Spoken Language Processing, volume II,</booktitle>
<pages>901--904</pages>
<contexts>
<context position="10402" citStr="Stolcke 2002" startWordPosition="1689" endWordPosition="1690"> of the corpus with dictionary based, “longest matching” unique segmentation method gives a corpus of 46 millions words. A development corpus of 1000 sentences, which has been segmented automatically to obtain 44k words, has been used to evaluate the tri-gram hits and the perplexity. The performance of each language model produced will be evaluated in terms of the tri-gram hits and perplexity on the development corpus and in terms of ASR performance on a separate speech test set (different from the development set). First of all, a language model named lm_1 is trained using the SRILM toolkit (Stolcke 2002) from the first best segmentation (Segmul1), which has the highest scoring paths (based on the transducer explained in section 2) of each sentence in the whole corpus. Then, additional language models have been trained using the corpus segmented with N-best segmentation: the number of N-best segmentations to generate for each sentence is fixed to 2, 5, 10, 50, 100 and 1000. The resulting texts are named accordingly as Segmul2, Segmul5, Segmul10, Segmul50, Segmul100, Segmul1000. Using these as training data, we have developed different language models. Note that a tri-gram that appears several </context>
<context position="12826" citStr="Stolcke 2002" startWordPosition="2080" endWordPosition="2081">sed of syllables naturally separated by white space. The automatic speech recognition is done on a test corpus of 270 utterances (broadcast news domain). 3 4 Statistical Analysis of N-grams in Multiple Text Segmentation The change in the N-gram count that results from multiple segmentation is two fold: first there is a boosting of the counts of the N-grams that are already found with the first best segmentation, and secondly new N-grams are added. As we have made a closed-vocabulary counting, there are no new uni-grams resulting from multiple segmentation. For the counting, the SRILM toolkit (Stolcke 2002) is used setting the -gtnmin option to zero so that all the Ngram counts can be considered. Figure 1 shows the distribution of tri-gram counts for the unique and multiple segmentation of the training corpus. It can be seen that the majority of the tri-grams have counts in the range of one to three. Counts Range Figure 1: Distribution of tri-gram counts The boosting (the counts of the tri-grams that are already found with the first best segmentation) effect of the multiple segmentation is indicated in table 1. We can see from the table that Segmul2, for example, reduced the number of rare tri-g</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Stolcke, Andreas. 2002. SRILM: an extensible language modeling toolkit. Proceedings of International Conference on Spoken Language Processing, volume II, 901–904 . 129.88.65.115</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>