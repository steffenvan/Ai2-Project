<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001020">
<title confidence="0.9981505">
Automatically Distinguishing Literal and Figurative Usages
of Highly Polysemous Verbs
</title>
<author confidence="0.987125">
Afsaneh Fazly and Ryan North and Suzanne Stevenson
</author>
<affiliation confidence="0.9991335">
Department of Computer Science
University of Toronto
</affiliation>
<email confidence="0.99732">
afsaneh,ryan,suzanne @cs.toronto.edu
</email>
<sectionHeader confidence="0.99386" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999984272727273">
We investigate the meaning extensions
of very frequent and highly polysemous
verbs, both in terms of their compositional
contribution to a light verb construction
(LVC), and the patterns of acceptability of
the resulting LVC. We develop composi-
tionality and acceptability measures that
draw on linguistic properties specific to
LVCs, and demonstrate that these statisti-
cal, corpus-based measures correlate well
with human judgments of each property.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.9995494">
Due to a cognitive priority for concrete, easily visu-
alizable entities, abstract notions are often expressed
in terms of more familiar and concrete things and
situations (Newman, 1996; Nunberg et al., 1994).
This gives rise to a widespread use of metaphor
in language. In particular, certain verbs easily un-
dergo a process of metaphorization and meaning
extension (e.g., Pauwels, 2000; Newman and Rice,
2004). Many such verbs refer to states or acts that
are central to human experience (e.g., sit, put, give);
hence, they are often both highly polysemous and
highly frequent. An important class of verbs prone
to metaphorization are light verbs, on which we fo-
cus in this paper.
A light verb, such as give, take, or make, com-
bines with a wide range of complements from differ-
ent syntactic categories (including nouns, adjectives,
and prepositions) to form a new predicate called a
light verb construction (LVC). Examples of LVCs
include:
</bodyText>
<page confidence="0.963964">
38
</page>
<listItem confidence="0.9987102">
1. (a) Azin took a walk along the river.
(b) Sam gave a speech to a few students.
(c) Joan takes care of him when I am away.
(d) They made good on their promise to win.
(e) You should always take this into account.
</listItem>
<bodyText confidence="0.999912322580645">
The light verb component of an LVC is “seman-
tically bleached” to some degree; consequently, the
semantic content of an LVC is assumed to be de-
termined primarily by the complement (Butt, 2003).
Nevertheless, light verbs exhibit meaning variations
when combined with different complements. For ex-
ample, give in give (someone) a present has a literal
meaning, i.e., “transfer of possession” of a THING
to a RECIPIENT. In give a speech, give has a figura-
tive meaning: an abstract entity (a speech) is “trans-
ferred” to the audience, but no “possession” is in-
volved. In give a groan, the notion of transfer is
even further diminished.
Verbs exhibiting such meaning variations are
widespread in many languages. Hence, successful
NLP applications—especially those requiring some
degree of semantic interpretation—need to identify
and treat them appropriately. While figurative uses
of a light verb are indistinguishable on the surface
from a literal use, this distinction is essential to a
machine translation system, as Table 1 illustrates. It
is therefore important to determine automatic mech-
anisms for distinguishing literal and figurative uses
of light verbs.
Moreover, in their figurative usages, light verbs
tend to have similar patterns of cooccurrence with
semantically similar complements (e.g., Newman,
1996). Each similar group of complement nouns can
even be viewed as a possible meaning extension for
a light verb. For example, in give advice, give or-
ders, give a speech, etc., give contributes a notion of
</bodyText>
<note confidence="0.907056">
Proceedings o�the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 38–47,
Ann Alm, June 2005. c�2005 Association for Computational Linguistics
Sentence in English Intermediate semantics Translation in French
</note>
<figure confidence="0.485691142857143">
Azin gave Sam a book. (e1/give Azin a donn´e un livre a` Sam.
:agent (a1/“Azin”) Azin gave a book to Sam.
:theme (b1/“book”)
:recepient (s1/“Sam”))
Azin gave the lasagna a try. (e2/give-a-try try Azin a essay´e le lasagne.
:agent (a1/“Azin”) Azin tried the lasagna.
:theme (l1/“lasagna”))
</figure>
<tableCaption confidence="0.997589">
Table 1: Sample sentences with literal and figurative usages of give.
</tableCaption>
<bodyText confidence="0.999946347826087">
“abstract transfer”, while in give a groan, give a cry,
give a moan, etc., give contributes a notion of “emis-
sion”. There is much debate on whether light verbs
have one highly abstract (underspecified) meaning,
further determined by the context, or a number of
identifiable (related) subsenses (Pustejovsky, 1995;
Newman, 1996). Under either view, it is important
to elucidate the relation between possible interpreta-
tions of a light verb and the sets of complements it
can occur with.
This study is an initial investigation of techniques
for the automatic discovery of meaning extensions
of light verbs in English. As alluded to above, we
focus on two issues: (i) the distinction of literal ver-
sus figurative usages, and (ii) the role of semanti-
cally similar classes of complements in refining the
figurative meanings.
In addressing the first task, we note the connection
between the literal/figurative distinction and the de-
gree to which a light verb contributes composition-
ally to the semantics of an expression. In Section 2,
we elaborate on the syntactic properties that relate
to the compositionality of light verbs, and propose
a statistical measure incorporating these properties,
which places light verb usages on a continuum of
meaning from literal to figurative. Figure 1(a) de-
picts such a continuum in the semantic space ofgive,
with the literal usages represented as the core.
The second issue above relates to our long-term
goal of dividing the space of figurative uses of a
light verb into semantically coherent segments, as
shown in Figure 1(b). Section 3 describes our hy-
pothesis on the class-based nature of the ability of
potential complements to combine with a light verb.
At this point we cannot spell out the different figura-
tive meanings of the light verb associated with such
classes. We take a preliminary step in proposing a
statistical measure of the acceptability of a combi-
nation of a light verb and a class of complements,
and explore the extent to which this measure can re-
veal class-based behaviour.
Subsequent sections of the paper present the cor-
pus extraction methods for estimating our composi-
tionality and acceptability measures, the collection
of human judgments to which the measures will be
compared, experimental results, and discussion.
</bodyText>
<sectionHeader confidence="0.936714" genericHeader="introduction">
2 Compositionality of Light Verbs
</sectionHeader>
<subsectionHeader confidence="0.996504">
2.1 Linguistic Properties: Syntactic Flexibility
</subsectionHeader>
<bodyText confidence="0.997044782608696">
We focus on a broadly-documented subclass of light
verb constructions, in which the complement is an
activity noun that is often the main source of seman-
tic predication (Wierzbicka, 1982). Such comple-
ments are assumed to be indefinite, non-referential
predicative nominals (PNs) that are often morpho-
logically related to a verb (see the complements in
examples (1a–c) above). We refer to this class of
light verb constructions as “LV+PN” constructions,
or simply LVCs.
There is much linguistic evidence that semantic
properties of a lexical item determine, to a large ex-
tent, its syntactic behaviour (e.g., Rappaport Hovav
and Levin, 1998). In particular, the degree of com-
positionality (decomposability) of a multiword ex-
pression has been known to affect its participation
in syntactic transformations, i.e., its syntactic flexi-
bility (e.g., Nunberg et al., 1994). English “LV+PN”
constructions enforce certain restrictions on the syn-
tactic freedom of their noun components (Kearns,
2002). In some, the noun may be introduced by a
definite article, pluralized, passivized, relativized, or
even wh-questioned:
</bodyText>
<page confidence="0.996593">
39
</page>
<figure confidence="0.983646282051282">
more figurative
give a pull
give a kick
give advice
give a speech
give a groan
give a laugh give a yell
give a push
give opportunity
give a book
give a present
give money
give a sweep
give a wipe
give permission
give a smile
give right
give orders
give a dust
give orders
give a speech
give permission
give advice
give a push
give a kick
give a pull
give a wipe
give a sweep
give a dust
give a book
give a present
give money
give a yell
give a laugh
give a groan
give a smile
give right
give opportunity
(a) (b)
</figure>
<figureCaption confidence="0.999902">
Figure 1: Two possible partitionings of the semantic space of give.
</figureCaption>
<listItem confidence="0.997336636363636">
2. (a) Azin gave a speech to a few students.
(b) Azin gave the speech just now.
(c) Azin gave a couple of speeches last night.
(d) A speech was given by Azin just now.
(e) Which speech did Azin give?
Others have little or no syntactic freedom:
3. (a) Azin gave a groan just now.
(b) * Azin gave the groan just now.
(c) ? Azin gave a couple of groans last night.
(d) * A groan was given by Azin just now.
(e) * Which groan did Azin give?
</listItem>
<bodyText confidence="0.9998055">
Recall that give in give a groan is presumed to be
a more abstract usage than give in give a speech. In
general, the degree to which the light verb retains
aspects of its literal meaning—and contributes them
compositionally to the LVC—is reflected in the de-
gree of syntactic freedom exhibited by the LVC. We
exploit this insight to devise a statistical measure of
compositionality, which uses evidence of syntactic
(in)flexibility of a potential LVC to situate it on a
scale of literal to figurative usage of the light verb:
i.e., the more inflexible the expression, the more fig-
urative (less compositional) the meaning.
</bodyText>
<subsectionHeader confidence="0.998488">
2.2 A Statistical Measure of Compositionality
</subsectionHeader>
<bodyText confidence="0.999452285714286">
Our proposed measure quantifies the degree of syn-
tactic flexibility of a light verb usage by looking
at its frequency of occurrence in any of a set of
relevant syntactic patterns, such as those in exam-
ples (2) and (3). The measure, COMP LV N , as-
signs a score to a given combination of a light verb
(LV) and a noun (N):
</bodyText>
<sectionHeader confidence="0.992179666666667" genericHeader="method">
COMP LV N
ASSOC LV;N
DIFF ASSOC LV;N PSp,, ASSOC LV;N PS,,g
</sectionHeader>
<bodyText confidence="0.999948444444444">
That is, the greater the association between LV and
N, and the greater the difference between their asso-
ciation with positive syntactic patterns and negative
syntactic patterns, the more figurative the meaning
of the light verb, and the higher the score.
The strength of the association between the light
verb and the complement noun is measured using
pointwise mutual information (PMI) whose standard
formula is given here:&apos;
</bodyText>
<construct confidence="0.5715762">
Pr LV N
ASSOC LV;N log
Pr LV Pr N
n fLV N
log f LV f N
</construct>
<bodyText confidence="0.9360536">
where n is an estimate of the total number of verb
and object noun pairs in the corpus.
&apos;PMI is subject to overestimation for low frequency items
(Dunning, 1993), thus we require a minimum frequency of oc-
currence for the expressions under study.
</bodyText>
<page confidence="0.991304">
40
</page>
<bodyText confidence="0.999822888888889">
PSpos represents the set of syntactic patterns pre-
ferred by less-compositional (more figurative) LVCs
(e.g., as in (3a)), and PSneg represents less preferred
patterns (e.g., those in (3b–e)). Typically, these pat-
terns most affect the expression of the complement
noun. Thus, to measure the strength of association
between an expression and a set of patterns, we use
the PMI of the light verb, and the complement noun
appearing in all of the patterns in the set, as in:
</bodyText>
<equation confidence="0.7121394">
ASSOC LV;N PSpos PMI LV;N PSpos
Pr LV N PSpos
log Pr LV Pr N PSpos
n f LV N PSpos
log f LV f N PSpos
</equation>
<bodyText confidence="0.994137142857143">
in which counts of occurrences of N in syntactic
contexts represented by PSpos are summed over all
patterns in the set. ASSOC(LV;N PSneg) is defined
analogously using PSneg in place of PSpos.
DIFF measures the difference between the asso-
ciation strengths of the positive and negative pat-
tern sets, referred to as ASSOCpos and ASSOCneg,
respectively. Our calculation of ASSOC uses max-
imum likelihood estimates of the true probabilities.
To account for resulting errors, we compare the two
confidence intervals, ASSOCpos AASSOCpos and
ASSOCneg AASSOCneg , as in Lin (1999). We take
the minimum distance between the two as a conser-
vative estimate of the true difference:
DIFF ASSOC LV;N PSpos ASSOC LV;N PSneg
ASSOCpos AASSOCpos
ASSOCneg AASSOCneg
Taking the difference between confidence intervals
lessens the effect of differences that are not statisti-
cally significant. (The confidence level, 1 a, is set
to 95% in all experiments.)
</bodyText>
<sectionHeader confidence="0.967496" genericHeader="method">
3 Acceptability Across Semantic Classes
</sectionHeader>
<subsectionHeader confidence="0.993392">
3.1 Linguistic Properties: Class Behaviour
</subsectionHeader>
<bodyText confidence="0.999975730769231">
In this aspect of our work, we narrow our focus onto
a subclass of “LV+PN” constructions that have a PN
complement in a stem form identical to a verb, pre-
ceded (typically) by an indefinite determiner (as in
(1a–b) above). Kearns (2002), Wierzbicka (1982),
and others have noted that the way in which LVs
combine with such PNs to form acceptable LVCs
is semantically patterned—that is, PNs with similar
semantics appear to have the same trends of cooc-
currence with an LV.
Our hypothesis is that semantically similar
LVCs—i.e., those formed from an LV plus any of
a set of semantically similar PNs—distinguish a fig-
urative subsense of the LV. In the long run, if this is
true, it could be exploited by using class information
to extend our knowledge of acceptable LVCs and
their likely meaning (cf. such an approach to verb
particle constructions by Villavicencio, 2003).
As steps to achieving this long-term goal, we must
first devise an acceptability measure which deter-
mines, for a given LV, which PNs it successfully
combines with. We can even use this measure to
provide evidence on whether the hypothesized class-
based behaviour holds, by seeing if the measure ex-
hibits differing behaviour across semantic classes of
potential complements.
</bodyText>
<subsectionHeader confidence="0.999872">
3.2 A Statistical Measure of Acceptability
</subsectionHeader>
<bodyText confidence="0.9995428">
We develop a probability formula that captures the
likelihood of a given LV and PN forming an accept-
able LVC. The probability depends on both the LV
and the PN, and on these elements being used in an
LVC:
</bodyText>
<equation confidence="0.859622666666667">
ACPT LV PN
Pr LV PN LVC
Pr PN Pr LVCPN Pr LVPN LVC
</equation>
<bodyText confidence="0.999902">
The first factor, Pr PN , reflects the linguistic
observation that higher frequency words are more
likely to be used as LVC complements (Wierzbicka,
1982). We estimate this factor by f PN n, where n
is the number of words in the corpus.
The probability that a given LV and PN form an
acceptable LVC further depends on how likely it is
that the PN combines with any light verbs to form an
LVC. The frequency with which a PN forms LVCs is
estimated as the number of times we observe it in the
prototypical “LV a/an PN” pattern across LVs. (Note
that such counts are an overestimate, since we can-
not determine which usages are indeed LVCs vs. lit-
eral uses of the LV.) Since these counts consider the
PN only in the context of an indefinite determiner,
</bodyText>
<page confidence="0.997288">
41
</page>
<bodyText confidence="0.9984965">
we normalize over counts of “a/an PN” (noted as
aPN) to form the conditional probability estimate of
the second factor:
development and test expressions by combining give
or take with verbs from selected semantic classes of
Levin (1993), taken from Stevenson et al. (2004).
</bodyText>
<equation confidence="0.953184">
v
∑
i 1
f aPN
</equation>
<bodyText confidence="0.999204">
where v is the number of light verbs considered.
The third factor, Pr LVPN LVC , reflects that
different LVs have varying degrees of acceptability
when used with a given PN in an LVC. We similarly
estimate this factor with counts of the given LV and
PN in the typical LVC pattern: f LV aPN ✝f aPN .
Combining the estimates of the three factors
yields:
</bodyText>
<sectionHeader confidence="0.995843" genericHeader="method">
4 Materials and Methods
</sectionHeader>
<subsectionHeader confidence="0.988332">
4.1 Light Verbs
</subsectionHeader>
<bodyText confidence="0.999987571428571">
Common light verbs in English include give, take,
make, get, have, and do, among others. We focus
here on two of them, i.e., give and take, that are
frequently and productively used in light verb con-
structions, and are highly polysemous. The Word-
Net polysemy count (number of different senses) of
give and take are 44 and 42, respectively.
</bodyText>
<subsectionHeader confidence="0.956076">
4.2 Experimental Expressions
</subsectionHeader>
<bodyText confidence="0.9999746">
Experimental expressions—i.e., potential LVCs us-
ing give and take—are drawn from two sources.
The development and test data used in experiments
of compositionality (bncD and bncT, respectively)
are randomly extracted from the BNC (BNC Ref-
erence Guide, 2000), yielding expressions cover-
ing a wide range of figurative usages of give and
take, with complements from different semantic cat-
egories. In contrast, in experiments that involve ac-
ceptability, we need figurative usages of “the same
type”, i.e., with semantically similar complement
nouns, to further examine our hypothesis on the
class-based behaviour of light verb combinations.
Since in these LVCs the complement is a predica-
tive noun in stem form identical to a verb, we form
</bodyText>
<subsectionHeader confidence="0.991721">
4.3 Corpora
</subsectionHeader>
<bodyText confidence="0.999972947368421">
We gather estimates for our COMP measure from the
BNC, processed using the Collins parser (Collins,
1999) and TGrep2 (Rohde, 2004). Because some
LVCs can be rare in classical corpora, our ACPT es-
timates are drawn from the World Wide Web (the
subsection indexed by AltaVista). In our compari-
son of the two measures, we use web data for both,
using a simplified version of COMP. The high level
of noise on the web will influence the performance
of both measures, but COMP more severely, due to
its reliance on comparisons of syntactic patterns.
Web counts are based on an exact-phrase query to
AltaVista, with the number of pages containing the
search phrase recorded as its frequency.2 The size
of the corpus is estimated at 3.7 billion, the number
of hits returned in a search for the. These counts are
underestimates of the true frequencies, as a phrase
may appear more than once in a web page, but we
assume all counts to be similarly affected.
</bodyText>
<subsectionHeader confidence="0.977436">
4.4 Extraction
</subsectionHeader>
<bodyText confidence="0.9999442">
Most required frequencies are simple counts of a
word or string of words, but the syntactic patterns
used in the compositionality measure present some
complexity. Recall that PSp,,, and PS,,g are pattern
sets representing the syntactic contexts of interest.
Each pattern encodes several syntactic attributes: v,
the voice of the extracted expression (active or pas-
sive); d, the type of the determiner introducing N
(definite or indefinite); and n, the number of N (sin-
gular or plural). In our experiments, the set of pat-
terns associated with less-compositional use, PSp,,,,
consists of the single pattern with values active, in-
definite, and singular, for these attributes. PS,,, con-
sists of all patterns with at least one of these at-
tributes having the alternative value.
While our counts on the BNC can use syntac-
tic mark-up, it is not feasible to collect counts on
the web for some of the pattern attributes, such as
voice. We develop two different variations of the
measure, one for BNC counts, and a simpler one for
</bodyText>
<footnote confidence="0.363499">
2All searches were performed March 15–30, 2005.
</footnote>
<figure confidence="0.943367454545454">
f LVi aPN
Pr LVCPN
ACPT LV PN
f PN
n f aPN
v
∑
i 1
f LVi aPN
f LV aPN
f aPN
</figure>
<page confidence="0.99335">
42
</page>
<table confidence="0.9986275">
give take
Human Ratings bncD bncT bncD bncT
‘low’ 20 10 36 19
‘medium’ 35 16 9 5
‘high’ 24 10 27 10
Total 79 36 72 34
</table>
<tableCaption confidence="0.9907055">
Table 2: Distribution of development and test expressions with
respect to human compositionality ratings.
</tableCaption>
<bodyText confidence="0.9991026">
web counts. We thus subscript COMP with abbre-
viations standing for each attribute in the measure:
COMPvdn for a measure involving all three attributes
(used on BNC data), and COMPd for a measure in-
volving determiner type only (used on web data).
</bodyText>
<sectionHeader confidence="0.997949" genericHeader="method">
5 Human Judgments
</sectionHeader>
<subsectionHeader confidence="0.999067">
5.1 Judgments of Compositionality
</subsectionHeader>
<bodyText confidence="0.915567787878788">
To determine how well our proposed measure
of compositionality captures the degree of lit-
eral/figurative use of a light verb, we compare its
scores to human judgments on compositionality.
Three judges (native speakers of English with suf-
ficient linguistic knowledge) answered yes/no ques-
tions related to the contribution of the literal mean-
ing of the light verb within each experimental ex-
pression. The combination of answers to these ques-
tions is transformed to numerical ratings, ranging
from 0 (fully non-compositional) to 4 (largely com-
positional). The three sets of ratings yield linearly
weighted Kappa values of .34 and .70 for give and
take, respectively. The ratings are averaged to form
a consensus set to be used for evaluation.3
The lists of rated expressions were biased toward
figurative usages of give and take. To achieve a spec-
trum of literal to figurative usages, we augment the
lists with literal expressions having an average rating
of 5 (fully compositional). Table 2 shows the distri-
bution of the experimental expressions across three
intervals of compositionality degree, ‘low’ (ratings
1), ‘medium’ (1 ratings 3), and ‘high’ (rat-
ings 3). Table 3 presents sample expressions with
different levels of compositionality ratings.
3We asked the judges to provide short paraphrases for each
expression, and only use those expressions for which the major-
ity of judges expressed the same sense.
Sample Expressions
Human Ratings give take
‘low’ give a squeeze take a shower
‘medium’ give help take a course
‘high’ give a dose take an amount
</bodyText>
<tableCaption confidence="0.9920875">
Table 3: Sample expressions with different levels of composi-
tionality ratings.
</tableCaption>
<subsectionHeader confidence="0.998648">
5.2 Judgments of Acceptability
</subsectionHeader>
<bodyText confidence="0.999996235294118">
Our acceptability measure is compared to the hu-
man judgments gathered by Stevenson et al. (2004).
Two expert native speakers of English rated the ac-
ceptability of each potential “LV+PN” construction
generated by combining give and take with candi-
date complements from the development and test
Levin classes. Ratings were from 1 (unacceptable)
to 5 (completely natural; this was capped at 4 for
test data), allowing for “in-between” ratings as well,
such as 2.5. On test data, the two sets of ratings
yielded linearly weighted Kappa values of .39 and
.72 for give and take, respectively. (Interestingly,
a similar agreement pattern is found in our human
compositionality judgments above.) The consensus
set of ratings was formed from an average of the two
sets of ratings, once disagreements of more than one
point were discussed.
</bodyText>
<sectionHeader confidence="0.997631" genericHeader="evaluation">
6 Experimental Results
</sectionHeader>
<bodyText confidence="0.999967578947368">
To evaluate our compositionality and acceptability
measures, we compare them to the relevant con-
sensus human ratings using the Spearman rank cor-
relation coefficient, rs. For simplicity, we report
the absolute value of rs for all experiments. Since
in most cases, correlations are statistically signifi-
cant (p 01), we omit p values; those rs values
for which p is marginal (i.e., 01 p 10) are
subscripted with an “m” in the tables. Correlation
scores in boldface are those that show an improve-
ment over the baseline, PMILV,.
The PMILV, measure is an informed baseline, since
it draws on properties of LVCs. Specifically, PMILV,
measures the strength of the association between a
light verb and a noun appearing in syntactic patterns
preferred by LVCs, i.e., PMILV, PMI LV;N PSpos .
Assuming that an acceptable LVC forms a detectable
collocation, PMILV, can be interpreted as an informed
baseline for degree of acceptability. PMILV, can also
</bodyText>
<page confidence="0.999929">
43
</page>
<tableCaption confidence="0.9836525">
Table 4: Correlations (rs; n = # of items) between human com-
positionality ratings and COMP measure (counts from BNC).
</tableCaption>
<table confidence="0.999863857142857">
LV Data Set n PMILVC COMPvdn
rs rs
bncT 36 .62 .57
give bncDT 114 .68 .70
bncDT/a 79 .68 .75
bncT 34 .51 .59
take bncDT 106 .52 .61
bncDT/a 68 .63 .72
Levin class: 18.1,2 30.3 43.2
LV n=35 n=18 n=35
give % fair/good ratings 51 44 54
log of mean ACPT -6 -4 -5
take % fair/good ratings 23 28 3
log of mean ACPT -4 -3 -6
</table>
<tableCaption confidence="0.998269666666667">
Table 5: Comparison of the proportion of human ratings consid-
ered “fair” or “good” in each class, and the log10 of the mean
ACPT score for that class.
</tableCaption>
<bodyText confidence="0.9999486">
be considered as a baseline for the degree of compo-
sitionality of an expression (with respect to the light
verb component), under the assumption that the less
compositional an expression, the more its compo-
nents appear as a fixed collocation.
</bodyText>
<subsectionHeader confidence="0.999221">
6.1 Compositionality Results
</subsectionHeader>
<bodyText confidence="0.99996015">
Table 4 displays the correlation scores of the human
compositionality ratings with COMPvdn, our com-
positionality measure estimated with counts from
the BNC. Given the variety of light verb usages
in expressions used in the compositionality data,
we report correlations not only on test data (bncT),
but also on development and test data combined
(bncDT) to get more data points and hence more re-
liable correlation scores. Compared to the baseline,
COMPvdn has generally higher correlations with hu-
man ratings of compositionality.
There are two different types of expressions
among those used in compositionality experiments:
expressions with an indefinite determiner a (e.g.,
give a kick) and those without a determiner (e.g.,
give guidance). Despite shared properties, the two
types of expressions may differ with respect to syn-
tactic flexibility, due to differing semantic proper-
ties of the noun complements in the two cases. We
thus calculate correlation scores for expressions with
the indefinite determiner only, from both develop-
ment and test data (bncDT/a). We find that COMPvdn
has higher correlations (and larger improvements
over the baseline) on this subset of expressions.
(Note that there are comparable numbers of items
in bncDT and bncDT/a, and the correlation scores
are highly significant—very small p values—in both
cases.)
To explore the effect of using a larger but noisier
corpus, we compare the performance of COMPvdn
with COMPd, the compositionality measure using
web data. The correlation scores for COMPd on
bncDT are .41 and .35, for give and take, respec-
tively, compared to a baseline (using web counts) of
.37 and .32. We find that COMPvdn has significantly
higher correlation scores (larger rs and much smaller
p values), as well as larger improvements over the
baseline. This is a confirmation that using more syn-
tactic information, from less noisy data, improves
the performance of our compositionality measure.4
</bodyText>
<subsectionHeader confidence="0.999907">
6.2 Acceptability Results
</subsectionHeader>
<bodyText confidence="0.999945090909091">
We have two goals in assessing our ACPT measure:
one is to demonstrate that the measure is indeed in-
dicative of the level of acceptability of an LVC, and
the other is to explore whether it helps to indicate
class-based patterns of acceptability.
Regarding the latter, Stevenson et al. (2004) found
differing overall levels of (human) acceptability for
different Levin classes combined with give and take.
This indicates a strong influence of semantic simi-
larity on the possible LV and complement combina-
tions. Our ACPT measure also yields differing pat-
terns across the semantic classes. Table 5 shows,
for each light verb and test class, the proportion of
acceptable LVCs according to human ratings, and
the log of the mean ACPT score for that LV and
class combination. For take, the ACPT score gener-
ally reflects the difference in proportion of accepted
expressions according to the human ratings, while
for give, the measure is less consistent. (The three
development classes show the same pattern.) The
ACPT measure thus appears to reflect the differing
patterns of acceptability across the classes, at least
</bodyText>
<footnote confidence="0.9480798">
4Using the automatically parsed BNC as a source of less
noisy data improves performance. However, since these con-
structions may be infrequent with any particular complement,
we do not expect the use of cleaner but more plentiful text (such
as existing treebanks) to improve the performance any further.
</footnote>
<page confidence="0.993928">
44
</page>
<table confidence="0.99645675">
LV Levin n PMILVC ACPT
Class rs rs
18.1,2 35 .39m .55
give 30.3 18 .38m .73
43.2 35 .30m .34m
18.1.2 35 .57 .61
take 30.3 18 .55 .64
43.2 35 .43 .47
</table>
<tableCaption confidence="0.9993985">
Table 6: Correlations (rs; n = # of items) between acceptability
measures and consensus human ratings (counts from web).
</tableCaption>
<table confidence="0.999324">
Human LV n PMILVC ACPT COMPd
Ratings rs rs rs
accept. give 88 .31 .42 .40
(Levin) take 88 .58 .61 .56
compos. give 114 .37 .21m .41
(bncDT) take 106 .32 .30 .35
</table>
<tableCaption confidence="0.9781035">
Table 7: Correlations (rs; n = # of items) between each measure
and each set of human ratings (counts from web).
</tableCaption>
<bodyText confidence="0.999362785714286">
for take.
To get a finer-grained notion of the degree to
which ACPT conforms with human ratings, we
present correlation scores between the two, in
Table 6. The results show that ACPT has higher
correlation scores than the baseline—substantially
higher in the case of give. The correlations for give
also vary more widely across the classes.
These results together indicate that the accept-
ability measure may be useful, and indeed taps into
some of the differing levels of acceptability across
the classes. However, we need to look more closely
at other linguistic properties which, if taken into ac-
count, may improve the consistency of the measure.
</bodyText>
<subsectionHeader confidence="0.999466">
6.3 Comparing the Two Measures
</subsectionHeader>
<bodyText confidence="0.9999629375">
Our two measures are intended for different pur-
poses, and indeed incorporate differing linguistic in-
formation about LVCs. However, we also noted that
PMILVC can be viewed as a baseline for both, indicat-
ing some underlying commonality. It is worth ex-
ploring whether each measure taps into the differ-
ent phenomena as intended. To do so, we correlate
COMP with the human ratings of acceptability, and
ACPT with the human ratings of compositionality,
as shown in Table 7. (The formulation of the ACPT
measure here is adapted for use with determiner-less
LVCs.) For comparability, both measures use counts
from the web. The results confirm that COMPd cor-
relates better than does ACPT with compositionality
ratings, while ACPT correlates best with acceptabil-
ity ratings.
</bodyText>
<sectionHeader confidence="0.983437" genericHeader="conclusions">
7 Discussion and Concluding Remarks
</sectionHeader>
<bodyText confidence="0.999716558139535">
Recently, there has been increasing awareness of the
need for appropriate handling of multiword expres-
sions (MWEs) in NLP tasks (Sag et al., 2002). Some
research has concentrated on the automatic acqui-
sition of semantic knowledge about certain classes
of MWEs, such as compound nouns or verb parti-
cle constructions (VPCs) (e.g., Lin, 1999; McCarthy
et al., 2003; Villavicencio, 2003). Previous research
on LVCs, on the other hand, has primarily focused
on their automatic extraction (e.g., Grefenstette and
Teufel 1995; Dras and Johnson 1996; Moir´on 2004;
though see Stevenson et al. 2004).
Like most previous studies that focus on seman-
tic properties of MWEs, we are interested in the is-
sue of compositionality. Our COMP measure aims to
identify a continuum along which a light verb con-
tributes to the semantics of an expression. In this
way, our work combines aspects of earlier work on
VPC semantics. McCarthy et al. (2003) determine a
continuum of compositionality of VPCs, but do not
distinguish the contribution of the individual compo-
nents. Bannard et al. (2003), on the other hand, look
at the separate contribution of the verb and particle,
but assume that a binary decision on the composi-
tionality of each is sufficient.
Previous studies determine compositionality by
looking at the degree of distributional similarity be-
tween an expression and its component words (e.g.,
McCarthy et al., 2003; Bannard et al., 2003; Bald-
win et al., 2003). Because light verbs are highly pol-
ysemous and frequently used in LVCs, such an ap-
proach is not appropriate for determining their con-
tribution to the semantics of an expression. We in-
stead examine the degree to which a light verb usage
is “similar” to the prototypical LVC, through a sta-
tistical comparison of its behaviour within different
syntactic patterns. Syntactic flexibility and semantic
compositionality are known to be strongly correlated
for many types of MWEs (Nunberg et al., 1994). We
thus intend to extend our approach to include other
polysemous verbs with metaphorical extensions.
Our compositionality measure correlates well
with the literal/figurative spectrum represented in
</bodyText>
<page confidence="0.997617">
45
</page>
<bodyText confidence="0.999982282051282">
human judgments. We also aim to determine finer-
grained distinctions among the identified figurative
usages of a light verb, which appear to relate to the
semantic class of its complement. Semantic class
knowledge may enable us to elucidate the types of
relations between a light verb and its complement
such as those determined in the work of Wanner
(2004), but without the need for the manually la-
belled training data which his approach requires.
Villavicencio (2003) used class-based knowledge to
extend a VPC lexicon, but assumed that an unob-
served VPC is not acceptable. We instead believe
that more robust application of class-based knowl-
edge can be achieved with a better estimate of the
acceptability of various expressions.
Work indicating acceptability of MWEs is largely
limited to collocational analysis using PMI-based
measures (Lin, 1999; Stevenson et al., 2004). We
instead use a probability formula that enables flex-
ible integration of LVC-specific linguistic proper-
ties. Our ACPT measure yields good correlations
with human acceptability judgments; indeed, the av-
erage increase over the baseline is about twice as
high as that of the acceptability measure proposed
by Stevenson et al. (2004). Although ACPT also
somewhat reflects different patterns across seman-
tic classes, the results clearly indicate the need for
incorporating more knowledge into the measure to
capture class-based behaviour more consistently.
The work presented here is preliminary, but is the
first we are aware of to tie together the two issues of
compositionality and acceptability, and relate them
to the notion of class-based meaning extensions of
highly polysemous verbs. Our on-going work is fo-
cusing on the role of the noun component of LVCs,
to determine the compositional contribution of the
noun to the semantics of the expression, and the role
of noun classes in influencing the meaning exten-
sions of light verbs.
</bodyText>
<sectionHeader confidence="0.999478" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.990034294117647">
Baldwin, T., Bannard, C., Tanaka, T., and Wid-
dows, D. (2003). An empirical model of multi-
word expression decomposability. In Proceedings
of the ACL-SIGLEX Workshop on Multiword Ex-
pressions: Analysis, Acquisition and Treatment,
pages 89–96.
Bannard, C., Baldwin, T., and Lascarides, A. (2003).
A statistical approach to the semantics of verb-
particles. In Proceedings of the ACL-SIGLEX
Workshop on Multiword Expressions: Analysis,
Acquisition and Treatment, pages 65–72.
BNC Reference Guide (2000). Reference Guide for
the British National Corpus (World Edition), sec-
ond edition.
Butt, M. (2003). The light verb jungle. Workshop
on Multi-Verb Constructions.
Collins, M. (1999). Head-Driven Statistical Models
for Natural Language Parsing. PhD thesis, Uni-
versity of Pennsylvania.
Dras, M. and Johnson, M. (1996). Death and light-
ness: Using a demographic model to find support
verbs. In Proceedings of the Fifth International
Conference on the Cognitive Science of Natural
Language Processing.
Dunning, T. (1993). Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61–74.
Grefenstette, G. and Teufel, S. (1995). Corpus-
based method for automatic identification of sup-
port verbs for nominalization. In Proceedings of
the 7th Meeting of the EACL.
Kearns, K. (2002). Light verbs in English.
manuscript.
Levin, B. (1993). English Verb Classes andAlterna-
tions: A Preliminary Investigation. The Univer-
sity of Chicago Press.
Lin, D. (1999). Automatic identification of non-
compositional phrases. In Proceedings ofthe 37th
Annual Meeting of the ACL, pages 317–324.
McCarthy, D., Keller, B., and Carroll, J. (2003).
Detecting a continuum of compositionality in
phrasal verbs. In Proceedings of the ACL-SIGLEX
Workshop on Multiword Expressions: Analysis,
Acquisition and Treatment.
Moir´on, M. B. V. (2004). Discarding noise in an au-
tomatically acquired lexicon of support verb con-
structions. In Proceedings of the 4th International
Conference on Language Resources and Evalua-
tion (LREC).
Newman, J. (1996). Give: A Cognitive Linguistic
Study. Mouton de Gruyter.
</reference>
<page confidence="0.989661">
46
</page>
<reference confidence="0.999145358974359">
Newman, J. and Rice, S. (2004). Patterns of usage
for English SIT, STAND, and LIE: A cognitively
inspired exploration in corpus linguistics. Cogni-
tive Linguistics, 15(3):351–396.
Nunberg, G., Sag, I. A., and Wasow, T. (1994). Id-
ioms. Language, 70(3):491–538.
Pauwels, P. (2000). Put, Set, Lay and Place: A
Cognitive Linguistic Approach to Verbal Mean-
ing. LINCOM EUROPA.
Pustejovsky, J. (1995). The Generative Lexicon.
MIT Press.
Rappaport Hovav, M. and Levin, B. (1998). Build-
ing verb meanings. In Butt and Geuder, editors,
The Projection of Arguments: Lexical and Com-
putational Factors, pages 97–134. CSLI Publica-
tions.
Rohde, D. L. T. (2004). TGrep2 User Manual.
Sag, I. A., Baldwin, T., Bond, F., Copestake, A., and
Flickinger, D. (2002). Multiword expressions: A
pain in the neck for NLP. In Proceedings of the
3rd International Conference on Intelligent Text
Processing and Computational Linguistics (CI-
CLING’02), pages 1–15.
Stevenson, S., Fazly, A., and North, R. (2004). Sta-
tistical measures of the semi-productivity of light
verb constructions. In Proceedings of the ACL-04
Workshop on Multiword Expressions: Integrating
Processing, pages 1–8.
Villavicencio, A. (2003). Verb-particle construc-
tions and lexical resources. In Proceedings of
the ACL-SIGLEX Workshop on Multiword Ex-
pressions: Analysis, Acquisition and Treatment,
pages 57–64.
Wanner, L. (2004). Towards automatic fine-grained
semantic classification of verb-noun collocations.
Natural Language Engineering, 10(2):95–143.
Wierzbicka, A. (1982). Why can you Have a Drink
when you can’t *Have an Eat? Language,
58(4):753–799.
</reference>
<page confidence="0.99949">
47
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.921355">
<title confidence="0.9952025">Automatically Distinguishing Literal and Figurative of Highly Polysemous Verbs</title>
<author confidence="0.966282">Afsaneh Fazly</author>
<author confidence="0.966282">Ryan North</author>
<author confidence="0.966282">Suzanne</author>
<affiliation confidence="0.9988785">Department of Computer University of</affiliation>
<email confidence="0.971212">afsaneh,ryan,suzanne@cs.toronto.edu</email>
<abstract confidence="0.999380583333333">We investigate the meaning extensions of very frequent and highly polysemous verbs, both in terms of their compositional contribution to a light verb construction (LVC), and the patterns of acceptability of the resulting LVC. We develop compositionality and acceptability measures that draw on linguistic properties specific to LVCs, and demonstrate that these statistical, corpus-based measures correlate well with human judgments of each property.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>T Baldwin</author>
<author>C Bannard</author>
<author>T Tanaka</author>
<author>D Widdows</author>
</authors>
<title>An empirical model of multiword expression decomposability.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>89--96</pages>
<contexts>
<context position="29703" citStr="Baldwin et al., 2003" startWordPosition="4943" endWordPosition="4947">on. In this way, our work combines aspects of earlier work on VPC semantics. McCarthy et al. (2003) determine a continuum of compositionality of VPCs, but do not distinguish the contribution of the individual components. Bannard et al. (2003), on the other hand, look at the separate contribution of the verb and particle, but assume that a binary decision on the compositionality of each is sufficient. Previous studies determine compositionality by looking at the degree of distributional similarity between an expression and its component words (e.g., McCarthy et al., 2003; Bannard et al., 2003; Baldwin et al., 2003). Because light verbs are highly polysemous and frequently used in LVCs, such an approach is not appropriate for determining their contribution to the semantics of an expression. We instead examine the degree to which a light verb usage is “similar” to the prototypical LVC, through a statistical comparison of its behaviour within different syntactic patterns. Syntactic flexibility and semantic compositionality are known to be strongly correlated for many types of MWEs (Nunberg et al., 1994). We thus intend to extend our approach to include other polysemous verbs with metaphorical extensions. O</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Baldwin, T., Bannard, C., Tanaka, T., and Widdows, D. (2003). An empirical model of multiword expression decomposability. In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 89–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Bannard</author>
<author>T Baldwin</author>
<author>A Lascarides</author>
</authors>
<title>A statistical approach to the semantics of verbparticles.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>65--72</pages>
<contexts>
<context position="29324" citStr="Bannard et al. (2003)" startWordPosition="4882" endWordPosition="4885">sed on their automatic extraction (e.g., Grefenstette and Teufel 1995; Dras and Johnson 1996; Moir´on 2004; though see Stevenson et al. 2004). Like most previous studies that focus on semantic properties of MWEs, we are interested in the issue of compositionality. Our COMP measure aims to identify a continuum along which a light verb contributes to the semantics of an expression. In this way, our work combines aspects of earlier work on VPC semantics. McCarthy et al. (2003) determine a continuum of compositionality of VPCs, but do not distinguish the contribution of the individual components. Bannard et al. (2003), on the other hand, look at the separate contribution of the verb and particle, but assume that a binary decision on the compositionality of each is sufficient. Previous studies determine compositionality by looking at the degree of distributional similarity between an expression and its component words (e.g., McCarthy et al., 2003; Bannard et al., 2003; Baldwin et al., 2003). Because light verbs are highly polysemous and frequently used in LVCs, such an approach is not appropriate for determining their contribution to the semantics of an expression. We instead examine the degree to which a l</context>
</contexts>
<marker>Bannard, Baldwin, Lascarides, 2003</marker>
<rawString>Bannard, C., Baldwin, T., and Lascarides, A. (2003). A statistical approach to the semantics of verbparticles. In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>BNC Reference Guide</author>
</authors>
<title>Reference Guide for the British National Corpus (World Edition),</title>
<date>2000</date>
<note>second edition.</note>
<contexts>
<context position="15399" citStr="Guide, 2000" startWordPosition="2571" endWordPosition="2572">erbs in English include give, take, make, get, have, and do, among others. We focus here on two of them, i.e., give and take, that are frequently and productively used in light verb constructions, and are highly polysemous. The WordNet polysemy count (number of different senses) of give and take are 44 and 42, respectively. 4.2 Experimental Expressions Experimental expressions—i.e., potential LVCs using give and take—are drawn from two sources. The development and test data used in experiments of compositionality (bncD and bncT, respectively) are randomly extracted from the BNC (BNC Reference Guide, 2000), yielding expressions covering a wide range of figurative usages of give and take, with complements from different semantic categories. In contrast, in experiments that involve acceptability, we need figurative usages of “the same type”, i.e., with semantically similar complement nouns, to further examine our hypothesis on the class-based behaviour of light verb combinations. Since in these LVCs the complement is a predicative noun in stem form identical to a verb, we form 4.3 Corpora We gather estimates for our COMP measure from the BNC, processed using the Collins parser (Collins, 1999) and</context>
</contexts>
<marker>Guide, 2000</marker>
<rawString>BNC Reference Guide (2000). Reference Guide for the British National Corpus (World Edition), second edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Butt</author>
</authors>
<title>The light verb jungle. Workshop on Multi-Verb Constructions.</title>
<date>2003</date>
<contexts>
<context position="2049" citStr="Butt, 2003" startWordPosition="325" endWordPosition="326">a wide range of complements from different syntactic categories (including nouns, adjectives, and prepositions) to form a new predicate called a light verb construction (LVC). Examples of LVCs include: 38 1. (a) Azin took a walk along the river. (b) Sam gave a speech to a few students. (c) Joan takes care of him when I am away. (d) They made good on their promise to win. (e) You should always take this into account. The light verb component of an LVC is “semantically bleached” to some degree; consequently, the semantic content of an LVC is assumed to be determined primarily by the complement (Butt, 2003). Nevertheless, light verbs exhibit meaning variations when combined with different complements. For example, give in give (someone) a present has a literal meaning, i.e., “transfer of possession” of a THING to a RECIPIENT. In give a speech, give has a figurative meaning: an abstract entity (a speech) is “transferred” to the audience, but no “possession” is involved. In give a groan, the notion of transfer is even further diminished. Verbs exhibiting such meaning variations are widespread in many languages. Hence, successful NLP applications—especially those requiring some degree of semantic i</context>
</contexts>
<marker>Butt, 2003</marker>
<rawString>Butt, M. (2003). The light verb jungle. Workshop on Multi-Verb Constructions.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>PhD thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="15995" citStr="Collins, 1999" startWordPosition="2666" endWordPosition="2667">rence Guide, 2000), yielding expressions covering a wide range of figurative usages of give and take, with complements from different semantic categories. In contrast, in experiments that involve acceptability, we need figurative usages of “the same type”, i.e., with semantically similar complement nouns, to further examine our hypothesis on the class-based behaviour of light verb combinations. Since in these LVCs the complement is a predicative noun in stem form identical to a verb, we form 4.3 Corpora We gather estimates for our COMP measure from the BNC, processed using the Collins parser (Collins, 1999) and TGrep2 (Rohde, 2004). Because some LVCs can be rare in classical corpora, our ACPT estimates are drawn from the World Wide Web (the subsection indexed by AltaVista). In our comparison of the two measures, we use web data for both, using a simplified version of COMP. The high level of noise on the web will influence the performance of both measures, but COMP more severely, due to its reliance on comparisons of syntactic patterns. Web counts are based on an exact-phrase query to AltaVista, with the number of pages containing the search phrase recorded as its frequency.2 The size of the corp</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Collins, M. (1999). Head-Driven Statistical Models for Natural Language Parsing. PhD thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Dras</author>
<author>M Johnson</author>
</authors>
<title>Death and lightness: Using a demographic model to find support verbs.</title>
<date>1996</date>
<booktitle>In Proceedings of the Fifth International Conference on the Cognitive Science of Natural Language Processing.</booktitle>
<contexts>
<context position="28795" citStr="Dras and Johnson 1996" startWordPosition="4793" endWordPosition="4796">correlates best with acceptability ratings. 7 Discussion and Concluding Remarks Recently, there has been increasing awareness of the need for appropriate handling of multiword expressions (MWEs) in NLP tasks (Sag et al., 2002). Some research has concentrated on the automatic acquisition of semantic knowledge about certain classes of MWEs, such as compound nouns or verb particle constructions (VPCs) (e.g., Lin, 1999; McCarthy et al., 2003; Villavicencio, 2003). Previous research on LVCs, on the other hand, has primarily focused on their automatic extraction (e.g., Grefenstette and Teufel 1995; Dras and Johnson 1996; Moir´on 2004; though see Stevenson et al. 2004). Like most previous studies that focus on semantic properties of MWEs, we are interested in the issue of compositionality. Our COMP measure aims to identify a continuum along which a light verb contributes to the semantics of an expression. In this way, our work combines aspects of earlier work on VPC semantics. McCarthy et al. (2003) determine a continuum of compositionality of VPCs, but do not distinguish the contribution of the individual components. Bannard et al. (2003), on the other hand, look at the separate contribution of the verb and </context>
</contexts>
<marker>Dras, Johnson, 1996</marker>
<rawString>Dras, M. and Johnson, M. (1996). Death and lightness: Using a demographic model to find support verbs. In Proceedings of the Fifth International Conference on the Cognitive Science of Natural Language Processing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="10125" citStr="Dunning, 1993" startWordPosition="1665" endWordPosition="1666">ociation between LV and N, and the greater the difference between their association with positive syntactic patterns and negative syntactic patterns, the more figurative the meaning of the light verb, and the higher the score. The strength of the association between the light verb and the complement noun is measured using pointwise mutual information (PMI) whose standard formula is given here:&apos; Pr LV N ASSOC LV;N log Pr LV Pr N n fLV N log f LV f N where n is an estimate of the total number of verb and object noun pairs in the corpus. &apos;PMI is subject to overestimation for low frequency items (Dunning, 1993), thus we require a minimum frequency of occurrence for the expressions under study. 40 PSpos represents the set of syntactic patterns preferred by less-compositional (more figurative) LVCs (e.g., as in (3a)), and PSneg represents less preferred patterns (e.g., those in (3b–e)). Typically, these patterns most affect the expression of the complement noun. Thus, to measure the strength of association between an expression and a set of patterns, we use the PMI of the light verb, and the complement noun appearing in all of the patterns in the set, as in: ASSOC LV;N PSpos PMI LV;N PSpos Pr LV N PSp</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Dunning, T. (1993). Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Grefenstette</author>
<author>S Teufel</author>
</authors>
<title>Corpusbased method for automatic identification of support verbs for nominalization.</title>
<date>1995</date>
<booktitle>In Proceedings of the 7th Meeting of the EACL.</booktitle>
<contexts>
<context position="28772" citStr="Grefenstette and Teufel 1995" startWordPosition="4789" endWordPosition="4792">tionality ratings, while ACPT correlates best with acceptability ratings. 7 Discussion and Concluding Remarks Recently, there has been increasing awareness of the need for appropriate handling of multiword expressions (MWEs) in NLP tasks (Sag et al., 2002). Some research has concentrated on the automatic acquisition of semantic knowledge about certain classes of MWEs, such as compound nouns or verb particle constructions (VPCs) (e.g., Lin, 1999; McCarthy et al., 2003; Villavicencio, 2003). Previous research on LVCs, on the other hand, has primarily focused on their automatic extraction (e.g., Grefenstette and Teufel 1995; Dras and Johnson 1996; Moir´on 2004; though see Stevenson et al. 2004). Like most previous studies that focus on semantic properties of MWEs, we are interested in the issue of compositionality. Our COMP measure aims to identify a continuum along which a light verb contributes to the semantics of an expression. In this way, our work combines aspects of earlier work on VPC semantics. McCarthy et al. (2003) determine a continuum of compositionality of VPCs, but do not distinguish the contribution of the individual components. Bannard et al. (2003), on the other hand, look at the separate contri</context>
</contexts>
<marker>Grefenstette, Teufel, 1995</marker>
<rawString>Grefenstette, G. and Teufel, S. (1995). Corpusbased method for automatic identification of support verbs for nominalization. In Proceedings of the 7th Meeting of the EACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kearns</author>
</authors>
<date>2002</date>
<note>Light verbs in English. manuscript.</note>
<contexts>
<context position="7295" citStr="Kearns, 2002" startWordPosition="1140" endWordPosition="1141">We refer to this class of light verb constructions as “LV+PN” constructions, or simply LVCs. There is much linguistic evidence that semantic properties of a lexical item determine, to a large extent, its syntactic behaviour (e.g., Rappaport Hovav and Levin, 1998). In particular, the degree of compositionality (decomposability) of a multiword expression has been known to affect its participation in syntactic transformations, i.e., its syntactic flexibility (e.g., Nunberg et al., 1994). English “LV+PN” constructions enforce certain restrictions on the syntactic freedom of their noun components (Kearns, 2002). In some, the noun may be introduced by a definite article, pluralized, passivized, relativized, or even wh-questioned: 39 more figurative give a pull give a kick give advice give a speech give a groan give a laugh give a yell give a push give opportunity give a book give a present give money give a sweep give a wipe give permission give a smile give right give orders give a dust give orders give a speech give permission give advice give a push give a kick give a pull give a wipe give a sweep give a dust give a book give a present give money give a yell give a laugh give a groan give a smile </context>
<context position="12034" citStr="Kearns (2002)" startWordPosition="1984" endWordPosition="1985">imate of the true difference: DIFF ASSOC LV;N PSpos ASSOC LV;N PSneg ASSOCpos AASSOCpos ASSOCneg AASSOCneg Taking the difference between confidence intervals lessens the effect of differences that are not statistically significant. (The confidence level, 1 a, is set to 95% in all experiments.) 3 Acceptability Across Semantic Classes 3.1 Linguistic Properties: Class Behaviour In this aspect of our work, we narrow our focus onto a subclass of “LV+PN” constructions that have a PN complement in a stem form identical to a verb, preceded (typically) by an indefinite determiner (as in (1a–b) above). Kearns (2002), Wierzbicka (1982), and others have noted that the way in which LVs combine with such PNs to form acceptable LVCs is semantically patterned—that is, PNs with similar semantics appear to have the same trends of cooccurrence with an LV. Our hypothesis is that semantically similar LVCs—i.e., those formed from an LV plus any of a set of semantically similar PNs—distinguish a figurative subsense of the LV. In the long run, if this is true, it could be exploited by using class information to extend our knowledge of acceptable LVCs and their likely meaning (cf. such an approach to verb particle cons</context>
</contexts>
<marker>Kearns, 2002</marker>
<rawString>Kearns, K. (2002). Light verbs in English. manuscript.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Levin</author>
</authors>
<title>English Verb Classes andAlternations: A Preliminary Investigation.</title>
<date>1993</date>
<publisher>The University of Chicago Press.</publisher>
<contexts>
<context position="14329" citStr="Levin (1993)" startWordPosition="2386" endWordPosition="2387"> to form an LVC. The frequency with which a PN forms LVCs is estimated as the number of times we observe it in the prototypical “LV a/an PN” pattern across LVs. (Note that such counts are an overestimate, since we cannot determine which usages are indeed LVCs vs. literal uses of the LV.) Since these counts consider the PN only in the context of an indefinite determiner, 41 we normalize over counts of “a/an PN” (noted as aPN) to form the conditional probability estimate of the second factor: development and test expressions by combining give or take with verbs from selected semantic classes of Levin (1993), taken from Stevenson et al. (2004). v ∑ i 1 f aPN where v is the number of light verbs considered. The third factor, Pr LVPN LVC , reflects that different LVs have varying degrees of acceptability when used with a given PN in an LVC. We similarly estimate this factor with counts of the given LV and PN in the typical LVC pattern: f LV aPN ✝f aPN . Combining the estimates of the three factors yields: 4 Materials and Methods 4.1 Light Verbs Common light verbs in English include give, take, make, get, have, and do, among others. We focus here on two of them, i.e., give and take, that are frequen</context>
</contexts>
<marker>Levin, 1993</marker>
<rawString>Levin, B. (1993). English Verb Classes andAlternations: A Preliminary Investigation. The University of Chicago Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases.</title>
<date>1999</date>
<booktitle>In Proceedings ofthe 37th Annual Meeting of the ACL,</booktitle>
<pages>317--324</pages>
<contexts>
<context position="11353" citStr="Lin (1999)" startWordPosition="1875" endWordPosition="1876">PSpos n f LV N PSpos log f LV f N PSpos in which counts of occurrences of N in syntactic contexts represented by PSpos are summed over all patterns in the set. ASSOC(LV;N PSneg) is defined analogously using PSneg in place of PSpos. DIFF measures the difference between the association strengths of the positive and negative pattern sets, referred to as ASSOCpos and ASSOCneg, respectively. Our calculation of ASSOC uses maximum likelihood estimates of the true probabilities. To account for resulting errors, we compare the two confidence intervals, ASSOCpos AASSOCpos and ASSOCneg AASSOCneg , as in Lin (1999). We take the minimum distance between the two as a conservative estimate of the true difference: DIFF ASSOC LV;N PSpos ASSOC LV;N PSneg ASSOCpos AASSOCpos ASSOCneg AASSOCneg Taking the difference between confidence intervals lessens the effect of differences that are not statistically significant. (The confidence level, 1 a, is set to 95% in all experiments.) 3 Acceptability Across Semantic Classes 3.1 Linguistic Properties: Class Behaviour In this aspect of our work, we narrow our focus onto a subclass of “LV+PN” constructions that have a PN complement in a stem form identical to a verb, pre</context>
<context position="28592" citStr="Lin, 1999" startWordPosition="4765" endWordPosition="4766">ith determiner-less LVCs.) For comparability, both measures use counts from the web. The results confirm that COMPd correlates better than does ACPT with compositionality ratings, while ACPT correlates best with acceptability ratings. 7 Discussion and Concluding Remarks Recently, there has been increasing awareness of the need for appropriate handling of multiword expressions (MWEs) in NLP tasks (Sag et al., 2002). Some research has concentrated on the automatic acquisition of semantic knowledge about certain classes of MWEs, such as compound nouns or verb particle constructions (VPCs) (e.g., Lin, 1999; McCarthy et al., 2003; Villavicencio, 2003). Previous research on LVCs, on the other hand, has primarily focused on their automatic extraction (e.g., Grefenstette and Teufel 1995; Dras and Johnson 1996; Moir´on 2004; though see Stevenson et al. 2004). Like most previous studies that focus on semantic properties of MWEs, we are interested in the issue of compositionality. Our COMP measure aims to identify a continuum along which a light verb contributes to the semantics of an expression. In this way, our work combines aspects of earlier work on VPC semantics. McCarthy et al. (2003) determine </context>
<context position="31252" citStr="Lin, 1999" startWordPosition="5187" endWordPosition="5188">he types of relations between a light verb and its complement such as those determined in the work of Wanner (2004), but without the need for the manually labelled training data which his approach requires. Villavicencio (2003) used class-based knowledge to extend a VPC lexicon, but assumed that an unobserved VPC is not acceptable. We instead believe that more robust application of class-based knowledge can be achieved with a better estimate of the acceptability of various expressions. Work indicating acceptability of MWEs is largely limited to collocational analysis using PMI-based measures (Lin, 1999; Stevenson et al., 2004). We instead use a probability formula that enables flexible integration of LVC-specific linguistic properties. Our ACPT measure yields good correlations with human acceptability judgments; indeed, the average increase over the baseline is about twice as high as that of the acceptability measure proposed by Stevenson et al. (2004). Although ACPT also somewhat reflects different patterns across semantic classes, the results clearly indicate the need for incorporating more knowledge into the measure to capture class-based behaviour more consistently. The work presented h</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Lin, D. (1999). Automatic identification of noncompositional phrases. In Proceedings ofthe 37th Annual Meeting of the ACL, pages 317–324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
<author>B Keller</author>
<author>J Carroll</author>
</authors>
<title>Detecting a continuum of compositionality in phrasal verbs.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment.</booktitle>
<contexts>
<context position="28615" citStr="McCarthy et al., 2003" startWordPosition="4767" endWordPosition="4770">ner-less LVCs.) For comparability, both measures use counts from the web. The results confirm that COMPd correlates better than does ACPT with compositionality ratings, while ACPT correlates best with acceptability ratings. 7 Discussion and Concluding Remarks Recently, there has been increasing awareness of the need for appropriate handling of multiword expressions (MWEs) in NLP tasks (Sag et al., 2002). Some research has concentrated on the automatic acquisition of semantic knowledge about certain classes of MWEs, such as compound nouns or verb particle constructions (VPCs) (e.g., Lin, 1999; McCarthy et al., 2003; Villavicencio, 2003). Previous research on LVCs, on the other hand, has primarily focused on their automatic extraction (e.g., Grefenstette and Teufel 1995; Dras and Johnson 1996; Moir´on 2004; though see Stevenson et al. 2004). Like most previous studies that focus on semantic properties of MWEs, we are interested in the issue of compositionality. Our COMP measure aims to identify a continuum along which a light verb contributes to the semantics of an expression. In this way, our work combines aspects of earlier work on VPC semantics. McCarthy et al. (2003) determine a continuum of composit</context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>McCarthy, D., Keller, B., and Carroll, J. (2003). Detecting a continuum of compositionality in phrasal verbs. In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M B V Moir´on</author>
</authors>
<title>Discarding noise in an automatically acquired lexicon of support verb constructions.</title>
<date>2004</date>
<booktitle>In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC).</booktitle>
<marker>Moir´on, 2004</marker>
<rawString>Moir´on, M. B. V. (2004). Discarding noise in an automatically acquired lexicon of support verb constructions. In Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Newman</author>
</authors>
<title>Give: A Cognitive Linguistic Study. Mouton de Gruyter.</title>
<date>1996</date>
<contexts>
<context position="884" citStr="Newman, 1996" startWordPosition="121" endWordPosition="122">s of very frequent and highly polysemous verbs, both in terms of their compositional contribution to a light verb construction (LVC), and the patterns of acceptability of the resulting LVC. We develop compositionality and acceptability measures that draw on linguistic properties specific to LVCs, and demonstrate that these statistical, corpus-based measures correlate well with human judgments of each property. 1 Introduction Due to a cognitive priority for concrete, easily visualizable entities, abstract notions are often expressed in terms of more familiar and concrete things and situations (Newman, 1996; Nunberg et al., 1994). This gives rise to a widespread use of metaphor in language. In particular, certain verbs easily undergo a process of metaphorization and meaning extension (e.g., Pauwels, 2000; Newman and Rice, 2004). Many such verbs refer to states or acts that are central to human experience (e.g., sit, put, give); hence, they are often both highly polysemous and highly frequent. An important class of verbs prone to metaphorization are light verbs, on which we focus in this paper. A light verb, such as give, take, or make, combines with a wide range of complements from different syn</context>
<context position="3169" citStr="Newman, 1996" startWordPosition="493" endWordPosition="494">ages. Hence, successful NLP applications—especially those requiring some degree of semantic interpretation—need to identify and treat them appropriately. While figurative uses of a light verb are indistinguishable on the surface from a literal use, this distinction is essential to a machine translation system, as Table 1 illustrates. It is therefore important to determine automatic mechanisms for distinguishing literal and figurative uses of light verbs. Moreover, in their figurative usages, light verbs tend to have similar patterns of cooccurrence with semantically similar complements (e.g., Newman, 1996). Each similar group of complement nouns can even be viewed as a possible meaning extension for a light verb. For example, in give advice, give orders, give a speech, etc., give contributes a notion of Proceedings o�the ACL-SIGLEX Workshop on Deep Lexical Acquisition, pages 38–47, Ann Alm, June 2005. c�2005 Association for Computational Linguistics Sentence in English Intermediate semantics Translation in French Azin gave Sam a book. (e1/give Azin a donn´e un livre a` Sam. :agent (a1/“Azin”) Azin gave a book to Sam. :theme (b1/“book”) :recepient (s1/“Sam”)) Azin gave the lasagna a try. (e2/giv</context>
</contexts>
<marker>Newman, 1996</marker>
<rawString>Newman, J. (1996). Give: A Cognitive Linguistic Study. Mouton de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Newman</author>
<author>S Rice</author>
</authors>
<title>Patterns of usage for English SIT, STAND, and LIE: A cognitively inspired exploration in corpus linguistics.</title>
<date>2004</date>
<journal>Cognitive Linguistics,</journal>
<volume>15</volume>
<issue>3</issue>
<contexts>
<context position="1109" citStr="Newman and Rice, 2004" startWordPosition="155" endWordPosition="158">ty and acceptability measures that draw on linguistic properties specific to LVCs, and demonstrate that these statistical, corpus-based measures correlate well with human judgments of each property. 1 Introduction Due to a cognitive priority for concrete, easily visualizable entities, abstract notions are often expressed in terms of more familiar and concrete things and situations (Newman, 1996; Nunberg et al., 1994). This gives rise to a widespread use of metaphor in language. In particular, certain verbs easily undergo a process of metaphorization and meaning extension (e.g., Pauwels, 2000; Newman and Rice, 2004). Many such verbs refer to states or acts that are central to human experience (e.g., sit, put, give); hence, they are often both highly polysemous and highly frequent. An important class of verbs prone to metaphorization are light verbs, on which we focus in this paper. A light verb, such as give, take, or make, combines with a wide range of complements from different syntactic categories (including nouns, adjectives, and prepositions) to form a new predicate called a light verb construction (LVC). Examples of LVCs include: 38 1. (a) Azin took a walk along the river. (b) Sam gave a speech to </context>
</contexts>
<marker>Newman, Rice, 2004</marker>
<rawString>Newman, J. and Rice, S. (2004). Patterns of usage for English SIT, STAND, and LIE: A cognitively inspired exploration in corpus linguistics. Cognitive Linguistics, 15(3):351–396.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Nunberg</author>
<author>I A Sag</author>
<author>T Wasow</author>
</authors>
<date>1994</date>
<journal>Idioms. Language,</journal>
<volume>70</volume>
<issue>3</issue>
<contexts>
<context position="907" citStr="Nunberg et al., 1994" startWordPosition="123" endWordPosition="126">uent and highly polysemous verbs, both in terms of their compositional contribution to a light verb construction (LVC), and the patterns of acceptability of the resulting LVC. We develop compositionality and acceptability measures that draw on linguistic properties specific to LVCs, and demonstrate that these statistical, corpus-based measures correlate well with human judgments of each property. 1 Introduction Due to a cognitive priority for concrete, easily visualizable entities, abstract notions are often expressed in terms of more familiar and concrete things and situations (Newman, 1996; Nunberg et al., 1994). This gives rise to a widespread use of metaphor in language. In particular, certain verbs easily undergo a process of metaphorization and meaning extension (e.g., Pauwels, 2000; Newman and Rice, 2004). Many such verbs refer to states or acts that are central to human experience (e.g., sit, put, give); hence, they are often both highly polysemous and highly frequent. An important class of verbs prone to metaphorization are light verbs, on which we focus in this paper. A light verb, such as give, take, or make, combines with a wide range of complements from different syntactic categories (incl</context>
<context position="7170" citStr="Nunberg et al., 1994" startWordPosition="1121" endWordPosition="1124">erential predicative nominals (PNs) that are often morphologically related to a verb (see the complements in examples (1a–c) above). We refer to this class of light verb constructions as “LV+PN” constructions, or simply LVCs. There is much linguistic evidence that semantic properties of a lexical item determine, to a large extent, its syntactic behaviour (e.g., Rappaport Hovav and Levin, 1998). In particular, the degree of compositionality (decomposability) of a multiword expression has been known to affect its participation in syntactic transformations, i.e., its syntactic flexibility (e.g., Nunberg et al., 1994). English “LV+PN” constructions enforce certain restrictions on the syntactic freedom of their noun components (Kearns, 2002). In some, the noun may be introduced by a definite article, pluralized, passivized, relativized, or even wh-questioned: 39 more figurative give a pull give a kick give advice give a speech give a groan give a laugh give a yell give a push give opportunity give a book give a present give money give a sweep give a wipe give permission give a smile give right give orders give a dust give orders give a speech give permission give advice give a push give a kick give a pull g</context>
<context position="30198" citStr="Nunberg et al., 1994" startWordPosition="5024" endWordPosition="5027">larity between an expression and its component words (e.g., McCarthy et al., 2003; Bannard et al., 2003; Baldwin et al., 2003). Because light verbs are highly polysemous and frequently used in LVCs, such an approach is not appropriate for determining their contribution to the semantics of an expression. We instead examine the degree to which a light verb usage is “similar” to the prototypical LVC, through a statistical comparison of its behaviour within different syntactic patterns. Syntactic flexibility and semantic compositionality are known to be strongly correlated for many types of MWEs (Nunberg et al., 1994). We thus intend to extend our approach to include other polysemous verbs with metaphorical extensions. Our compositionality measure correlates well with the literal/figurative spectrum represented in 45 human judgments. We also aim to determine finergrained distinctions among the identified figurative usages of a light verb, which appear to relate to the semantic class of its complement. Semantic class knowledge may enable us to elucidate the types of relations between a light verb and its complement such as those determined in the work of Wanner (2004), but without the need for the manually </context>
</contexts>
<marker>Nunberg, Sag, Wasow, 1994</marker>
<rawString>Nunberg, G., Sag, I. A., and Wasow, T. (1994). Idioms. Language, 70(3):491–538.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Pauwels</author>
</authors>
<title>Put, Set, Lay and Place: A Cognitive Linguistic Approach to Verbal Meaning.</title>
<date>2000</date>
<publisher>LINCOM EUROPA.</publisher>
<contexts>
<context position="1085" citStr="Pauwels, 2000" startWordPosition="153" endWordPosition="154"> compositionality and acceptability measures that draw on linguistic properties specific to LVCs, and demonstrate that these statistical, corpus-based measures correlate well with human judgments of each property. 1 Introduction Due to a cognitive priority for concrete, easily visualizable entities, abstract notions are often expressed in terms of more familiar and concrete things and situations (Newman, 1996; Nunberg et al., 1994). This gives rise to a widespread use of metaphor in language. In particular, certain verbs easily undergo a process of metaphorization and meaning extension (e.g., Pauwels, 2000; Newman and Rice, 2004). Many such verbs refer to states or acts that are central to human experience (e.g., sit, put, give); hence, they are often both highly polysemous and highly frequent. An important class of verbs prone to metaphorization are light verbs, on which we focus in this paper. A light verb, such as give, take, or make, combines with a wide range of complements from different syntactic categories (including nouns, adjectives, and prepositions) to form a new predicate called a light verb construction (LVC). Examples of LVCs include: 38 1. (a) Azin took a walk along the river. (</context>
</contexts>
<marker>Pauwels, 2000</marker>
<rawString>Pauwels, P. (2000). Put, Set, Lay and Place: A Cognitive Linguistic Approach to Verbal Meaning. LINCOM EUROPA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pustejovsky</author>
</authors>
<title>The Generative Lexicon.</title>
<date>1995</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="4256" citStr="Pustejovsky, 1995" startWordPosition="662" endWordPosition="663">a` Sam. :agent (a1/“Azin”) Azin gave a book to Sam. :theme (b1/“book”) :recepient (s1/“Sam”)) Azin gave the lasagna a try. (e2/give-a-try try Azin a essay´e le lasagne. :agent (a1/“Azin”) Azin tried the lasagna. :theme (l1/“lasagna”)) Table 1: Sample sentences with literal and figurative usages of give. “abstract transfer”, while in give a groan, give a cry, give a moan, etc., give contributes a notion of “emission”. There is much debate on whether light verbs have one highly abstract (underspecified) meaning, further determined by the context, or a number of identifiable (related) subsenses (Pustejovsky, 1995; Newman, 1996). Under either view, it is important to elucidate the relation between possible interpretations of a light verb and the sets of complements it can occur with. This study is an initial investigation of techniques for the automatic discovery of meaning extensions of light verbs in English. As alluded to above, we focus on two issues: (i) the distinction of literal versus figurative usages, and (ii) the role of semantically similar classes of complements in refining the figurative meanings. In addressing the first task, we note the connection between the literal/figurative distinct</context>
</contexts>
<marker>Pustejovsky, 1995</marker>
<rawString>Pustejovsky, J. (1995). The Generative Lexicon. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rappaport Hovav</author>
<author>M</author>
<author>B Levin</author>
</authors>
<title>Building verb meanings.</title>
<date>1998</date>
<booktitle>The Projection of Arguments: Lexical and Computational Factors,</booktitle>
<pages>97--134</pages>
<editor>In Butt and Geuder, editors,</editor>
<publisher>CSLI Publications.</publisher>
<marker>Hovav, M, Levin, 1998</marker>
<rawString>Rappaport Hovav, M. and Levin, B. (1998). Building verb meanings. In Butt and Geuder, editors, The Projection of Arguments: Lexical and Computational Factors, pages 97–134. CSLI Publications.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D L T Rohde</author>
</authors>
<date>2004</date>
<note>TGrep2 User Manual.</note>
<contexts>
<context position="16020" citStr="Rohde, 2004" startWordPosition="2670" endWordPosition="2671">g expressions covering a wide range of figurative usages of give and take, with complements from different semantic categories. In contrast, in experiments that involve acceptability, we need figurative usages of “the same type”, i.e., with semantically similar complement nouns, to further examine our hypothesis on the class-based behaviour of light verb combinations. Since in these LVCs the complement is a predicative noun in stem form identical to a verb, we form 4.3 Corpora We gather estimates for our COMP measure from the BNC, processed using the Collins parser (Collins, 1999) and TGrep2 (Rohde, 2004). Because some LVCs can be rare in classical corpora, our ACPT estimates are drawn from the World Wide Web (the subsection indexed by AltaVista). In our comparison of the two measures, we use web data for both, using a simplified version of COMP. The high level of noise on the web will influence the performance of both measures, but COMP more severely, due to its reliance on comparisons of syntactic patterns. Web counts are based on an exact-phrase query to AltaVista, with the number of pages containing the search phrase recorded as its frequency.2 The size of the corpus is estimated at 3.7 bi</context>
</contexts>
<marker>Rohde, 2004</marker>
<rawString>Rohde, D. L. T. (2004). TGrep2 User Manual.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Sag</author>
<author>T Baldwin</author>
<author>F Bond</author>
<author>A Copestake</author>
<author>D Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proceedings of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLING’02),</booktitle>
<pages>1--15</pages>
<contexts>
<context position="28400" citStr="Sag et al., 2002" startWordPosition="4733" endWordPosition="4736"> so, we correlate COMP with the human ratings of acceptability, and ACPT with the human ratings of compositionality, as shown in Table 7. (The formulation of the ACPT measure here is adapted for use with determiner-less LVCs.) For comparability, both measures use counts from the web. The results confirm that COMPd correlates better than does ACPT with compositionality ratings, while ACPT correlates best with acceptability ratings. 7 Discussion and Concluding Remarks Recently, there has been increasing awareness of the need for appropriate handling of multiword expressions (MWEs) in NLP tasks (Sag et al., 2002). Some research has concentrated on the automatic acquisition of semantic knowledge about certain classes of MWEs, such as compound nouns or verb particle constructions (VPCs) (e.g., Lin, 1999; McCarthy et al., 2003; Villavicencio, 2003). Previous research on LVCs, on the other hand, has primarily focused on their automatic extraction (e.g., Grefenstette and Teufel 1995; Dras and Johnson 1996; Moir´on 2004; though see Stevenson et al. 2004). Like most previous studies that focus on semantic properties of MWEs, we are interested in the issue of compositionality. Our COMP measure aims to identif</context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Sag, I. A., Baldwin, T., Bond, F., Copestake, A., and Flickinger, D. (2002). Multiword expressions: A pain in the neck for NLP. In Proceedings of the 3rd International Conference on Intelligent Text Processing and Computational Linguistics (CICLING’02), pages 1–15.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Stevenson</author>
<author>A Fazly</author>
<author>R North</author>
</authors>
<title>Statistical measures of the semi-productivity of light verb constructions.</title>
<date>2004</date>
<booktitle>In Proceedings of the ACL-04 Workshop on Multiword Expressions: Integrating Processing,</booktitle>
<pages>1--8</pages>
<contexts>
<context position="14365" citStr="Stevenson et al. (2004)" startWordPosition="2390" endWordPosition="2393">uency with which a PN forms LVCs is estimated as the number of times we observe it in the prototypical “LV a/an PN” pattern across LVs. (Note that such counts are an overestimate, since we cannot determine which usages are indeed LVCs vs. literal uses of the LV.) Since these counts consider the PN only in the context of an indefinite determiner, 41 we normalize over counts of “a/an PN” (noted as aPN) to form the conditional probability estimate of the second factor: development and test expressions by combining give or take with verbs from selected semantic classes of Levin (1993), taken from Stevenson et al. (2004). v ∑ i 1 f aPN where v is the number of light verbs considered. The third factor, Pr LVPN LVC , reflects that different LVs have varying degrees of acceptability when used with a given PN in an LVC. We similarly estimate this factor with counts of the given LV and PN in the typical LVC pattern: f LV aPN ✝f aPN . Combining the estimates of the three factors yields: 4 Materials and Methods 4.1 Light Verbs Common light verbs in English include give, take, make, get, have, and do, among others. We focus here on two of them, i.e., give and take, that are frequently and productively used in light v</context>
<context position="20282" citStr="Stevenson et al. (2004)" startWordPosition="3389" endWordPosition="3392">and ‘high’ (ratings 3). Table 3 presents sample expressions with different levels of compositionality ratings. 3We asked the judges to provide short paraphrases for each expression, and only use those expressions for which the majority of judges expressed the same sense. Sample Expressions Human Ratings give take ‘low’ give a squeeze take a shower ‘medium’ give help take a course ‘high’ give a dose take an amount Table 3: Sample expressions with different levels of compositionality ratings. 5.2 Judgments of Acceptability Our acceptability measure is compared to the human judgments gathered by Stevenson et al. (2004). Two expert native speakers of English rated the acceptability of each potential “LV+PN” construction generated by combining give and take with candidate complements from the development and test Levin classes. Ratings were from 1 (unacceptable) to 5 (completely natural; this was capped at 4 for test data), allowing for “in-between” ratings as well, such as 2.5. On test data, the two sets of ratings yielded linearly weighted Kappa values of .39 and .72 for give and take, respectively. (Interestingly, a similar agreement pattern is found in our human compositionality judgments above.) The cons</context>
<context position="25102" citStr="Stevenson et al. (2004)" startWordPosition="4182" endWordPosition="4185">and .32. We find that COMPvdn has significantly higher correlation scores (larger rs and much smaller p values), as well as larger improvements over the baseline. This is a confirmation that using more syntactic information, from less noisy data, improves the performance of our compositionality measure.4 6.2 Acceptability Results We have two goals in assessing our ACPT measure: one is to demonstrate that the measure is indeed indicative of the level of acceptability of an LVC, and the other is to explore whether it helps to indicate class-based patterns of acceptability. Regarding the latter, Stevenson et al. (2004) found differing overall levels of (human) acceptability for different Levin classes combined with give and take. This indicates a strong influence of semantic similarity on the possible LV and complement combinations. Our ACPT measure also yields differing patterns across the semantic classes. Table 5 shows, for each light verb and test class, the proportion of acceptable LVCs according to human ratings, and the log of the mean ACPT score for that LV and class combination. For take, the ACPT score generally reflects the difference in proportion of accepted expressions according to the human r</context>
<context position="28844" citStr="Stevenson et al. 2004" startWordPosition="4801" endWordPosition="4804">scussion and Concluding Remarks Recently, there has been increasing awareness of the need for appropriate handling of multiword expressions (MWEs) in NLP tasks (Sag et al., 2002). Some research has concentrated on the automatic acquisition of semantic knowledge about certain classes of MWEs, such as compound nouns or verb particle constructions (VPCs) (e.g., Lin, 1999; McCarthy et al., 2003; Villavicencio, 2003). Previous research on LVCs, on the other hand, has primarily focused on their automatic extraction (e.g., Grefenstette and Teufel 1995; Dras and Johnson 1996; Moir´on 2004; though see Stevenson et al. 2004). Like most previous studies that focus on semantic properties of MWEs, we are interested in the issue of compositionality. Our COMP measure aims to identify a continuum along which a light verb contributes to the semantics of an expression. In this way, our work combines aspects of earlier work on VPC semantics. McCarthy et al. (2003) determine a continuum of compositionality of VPCs, but do not distinguish the contribution of the individual components. Bannard et al. (2003), on the other hand, look at the separate contribution of the verb and particle, but assume that a binary decision on th</context>
<context position="31277" citStr="Stevenson et al., 2004" startWordPosition="5189" endWordPosition="5192"> relations between a light verb and its complement such as those determined in the work of Wanner (2004), but without the need for the manually labelled training data which his approach requires. Villavicencio (2003) used class-based knowledge to extend a VPC lexicon, but assumed that an unobserved VPC is not acceptable. We instead believe that more robust application of class-based knowledge can be achieved with a better estimate of the acceptability of various expressions. Work indicating acceptability of MWEs is largely limited to collocational analysis using PMI-based measures (Lin, 1999; Stevenson et al., 2004). We instead use a probability formula that enables flexible integration of LVC-specific linguistic properties. Our ACPT measure yields good correlations with human acceptability judgments; indeed, the average increase over the baseline is about twice as high as that of the acceptability measure proposed by Stevenson et al. (2004). Although ACPT also somewhat reflects different patterns across semantic classes, the results clearly indicate the need for incorporating more knowledge into the measure to capture class-based behaviour more consistently. The work presented here is preliminary, but i</context>
</contexts>
<marker>Stevenson, Fazly, North, 2004</marker>
<rawString>Stevenson, S., Fazly, A., and North, R. (2004). Statistical measures of the semi-productivity of light verb constructions. In Proceedings of the ACL-04 Workshop on Multiword Expressions: Integrating Processing, pages 1–8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Villavicencio</author>
</authors>
<title>Verb-particle constructions and lexical resources.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment,</booktitle>
<pages>57--64</pages>
<contexts>
<context position="12667" citStr="Villavicencio, 2003" startWordPosition="2090" endWordPosition="2091">(1982), and others have noted that the way in which LVs combine with such PNs to form acceptable LVCs is semantically patterned—that is, PNs with similar semantics appear to have the same trends of cooccurrence with an LV. Our hypothesis is that semantically similar LVCs—i.e., those formed from an LV plus any of a set of semantically similar PNs—distinguish a figurative subsense of the LV. In the long run, if this is true, it could be exploited by using class information to extend our knowledge of acceptable LVCs and their likely meaning (cf. such an approach to verb particle constructions by Villavicencio, 2003). As steps to achieving this long-term goal, we must first devise an acceptability measure which determines, for a given LV, which PNs it successfully combines with. We can even use this measure to provide evidence on whether the hypothesized classbased behaviour holds, by seeing if the measure exhibits differing behaviour across semantic classes of potential complements. 3.2 A Statistical Measure of Acceptability We develop a probability formula that captures the likelihood of a given LV and PN forming an acceptable LVC. The probability depends on both the LV and the PN, and on these elements</context>
<context position="28637" citStr="Villavicencio, 2003" startWordPosition="4771" endWordPosition="4772">parability, both measures use counts from the web. The results confirm that COMPd correlates better than does ACPT with compositionality ratings, while ACPT correlates best with acceptability ratings. 7 Discussion and Concluding Remarks Recently, there has been increasing awareness of the need for appropriate handling of multiword expressions (MWEs) in NLP tasks (Sag et al., 2002). Some research has concentrated on the automatic acquisition of semantic knowledge about certain classes of MWEs, such as compound nouns or verb particle constructions (VPCs) (e.g., Lin, 1999; McCarthy et al., 2003; Villavicencio, 2003). Previous research on LVCs, on the other hand, has primarily focused on their automatic extraction (e.g., Grefenstette and Teufel 1995; Dras and Johnson 1996; Moir´on 2004; though see Stevenson et al. 2004). Like most previous studies that focus on semantic properties of MWEs, we are interested in the issue of compositionality. Our COMP measure aims to identify a continuum along which a light verb contributes to the semantics of an expression. In this way, our work combines aspects of earlier work on VPC semantics. McCarthy et al. (2003) determine a continuum of compositionality of VPCs, but </context>
<context position="30870" citStr="Villavicencio (2003)" startWordPosition="5129" endWordPosition="5130">ther polysemous verbs with metaphorical extensions. Our compositionality measure correlates well with the literal/figurative spectrum represented in 45 human judgments. We also aim to determine finergrained distinctions among the identified figurative usages of a light verb, which appear to relate to the semantic class of its complement. Semantic class knowledge may enable us to elucidate the types of relations between a light verb and its complement such as those determined in the work of Wanner (2004), but without the need for the manually labelled training data which his approach requires. Villavicencio (2003) used class-based knowledge to extend a VPC lexicon, but assumed that an unobserved VPC is not acceptable. We instead believe that more robust application of class-based knowledge can be achieved with a better estimate of the acceptability of various expressions. Work indicating acceptability of MWEs is largely limited to collocational analysis using PMI-based measures (Lin, 1999; Stevenson et al., 2004). We instead use a probability formula that enables flexible integration of LVC-specific linguistic properties. Our ACPT measure yields good correlations with human acceptability judgments; ind</context>
</contexts>
<marker>Villavicencio, 2003</marker>
<rawString>Villavicencio, A. (2003). Verb-particle constructions and lexical resources. In Proceedings of the ACL-SIGLEX Workshop on Multiword Expressions: Analysis, Acquisition and Treatment, pages 57–64.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Wanner</author>
</authors>
<title>Towards automatic fine-grained semantic classification of verb-noun collocations.</title>
<date>2004</date>
<journal>Natural Language Engineering,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="30758" citStr="Wanner (2004)" startWordPosition="5112" endWordPosition="5113">related for many types of MWEs (Nunberg et al., 1994). We thus intend to extend our approach to include other polysemous verbs with metaphorical extensions. Our compositionality measure correlates well with the literal/figurative spectrum represented in 45 human judgments. We also aim to determine finergrained distinctions among the identified figurative usages of a light verb, which appear to relate to the semantic class of its complement. Semantic class knowledge may enable us to elucidate the types of relations between a light verb and its complement such as those determined in the work of Wanner (2004), but without the need for the manually labelled training data which his approach requires. Villavicencio (2003) used class-based knowledge to extend a VPC lexicon, but assumed that an unobserved VPC is not acceptable. We instead believe that more robust application of class-based knowledge can be achieved with a better estimate of the acceptability of various expressions. Work indicating acceptability of MWEs is largely limited to collocational analysis using PMI-based measures (Lin, 1999; Stevenson et al., 2004). We instead use a probability formula that enables flexible integration of LVC-s</context>
</contexts>
<marker>Wanner, 2004</marker>
<rawString>Wanner, L. (2004). Towards automatic fine-grained semantic classification of verb-noun collocations. Natural Language Engineering, 10(2):95–143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Wierzbicka</author>
</authors>
<title>Why can you Have a Drink when you can’t *Have an Eat?</title>
<date>1982</date>
<journal>Language,</journal>
<volume>58</volume>
<issue>4</issue>
<contexts>
<context position="6493" citStr="Wierzbicka, 1982" startWordPosition="1020" endWordPosition="1021">lass of complements, and explore the extent to which this measure can reveal class-based behaviour. Subsequent sections of the paper present the corpus extraction methods for estimating our compositionality and acceptability measures, the collection of human judgments to which the measures will be compared, experimental results, and discussion. 2 Compositionality of Light Verbs 2.1 Linguistic Properties: Syntactic Flexibility We focus on a broadly-documented subclass of light verb constructions, in which the complement is an activity noun that is often the main source of semantic predication (Wierzbicka, 1982). Such complements are assumed to be indefinite, non-referential predicative nominals (PNs) that are often morphologically related to a verb (see the complements in examples (1a–c) above). We refer to this class of light verb constructions as “LV+PN” constructions, or simply LVCs. There is much linguistic evidence that semantic properties of a lexical item determine, to a large extent, its syntactic behaviour (e.g., Rappaport Hovav and Levin, 1998). In particular, the degree of compositionality (decomposability) of a multiword expression has been known to affect its participation in syntactic </context>
<context position="12053" citStr="Wierzbicka (1982)" startWordPosition="1986" endWordPosition="1987">ue difference: DIFF ASSOC LV;N PSpos ASSOC LV;N PSneg ASSOCpos AASSOCpos ASSOCneg AASSOCneg Taking the difference between confidence intervals lessens the effect of differences that are not statistically significant. (The confidence level, 1 a, is set to 95% in all experiments.) 3 Acceptability Across Semantic Classes 3.1 Linguistic Properties: Class Behaviour In this aspect of our work, we narrow our focus onto a subclass of “LV+PN” constructions that have a PN complement in a stem form identical to a verb, preceded (typically) by an indefinite determiner (as in (1a–b) above). Kearns (2002), Wierzbicka (1982), and others have noted that the way in which LVs combine with such PNs to form acceptable LVCs is semantically patterned—that is, PNs with similar semantics appear to have the same trends of cooccurrence with an LV. Our hypothesis is that semantically similar LVCs—i.e., those formed from an LV plus any of a set of semantically similar PNs—distinguish a figurative subsense of the LV. In the long run, if this is true, it could be exploited by using class information to extend our knowledge of acceptable LVCs and their likely meaning (cf. such an approach to verb particle constructions by Villav</context>
<context position="13495" citStr="Wierzbicka, 1982" startWordPosition="2233" endWordPosition="2234">nce on whether the hypothesized classbased behaviour holds, by seeing if the measure exhibits differing behaviour across semantic classes of potential complements. 3.2 A Statistical Measure of Acceptability We develop a probability formula that captures the likelihood of a given LV and PN forming an acceptable LVC. The probability depends on both the LV and the PN, and on these elements being used in an LVC: ACPT LV PN Pr LV PN LVC Pr PN Pr LVCPN Pr LVPN LVC The first factor, Pr PN , reflects the linguistic observation that higher frequency words are more likely to be used as LVC complements (Wierzbicka, 1982). We estimate this factor by f PN n, where n is the number of words in the corpus. The probability that a given LV and PN form an acceptable LVC further depends on how likely it is that the PN combines with any light verbs to form an LVC. The frequency with which a PN forms LVCs is estimated as the number of times we observe it in the prototypical “LV a/an PN” pattern across LVs. (Note that such counts are an overestimate, since we cannot determine which usages are indeed LVCs vs. literal uses of the LV.) Since these counts consider the PN only in the context of an indefinite determiner, 41 we</context>
</contexts>
<marker>Wierzbicka, 1982</marker>
<rawString>Wierzbicka, A. (1982). Why can you Have a Drink when you can’t *Have an Eat? Language, 58(4):753–799.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>