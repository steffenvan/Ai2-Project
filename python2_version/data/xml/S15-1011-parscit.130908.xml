<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000311">
<title confidence="0.9969555">
Combining Mention Context and Hyperlinks from Wikipedia
for Named Entity Disambiguation
</title>
<author confidence="0.837598">
Ander Barrena
</author>
<affiliation confidence="0.606276">
IXA NLP Group
UPV/EHU
Donostia, Basque Country
</affiliation>
<email confidence="0.990059">
ander.barrena@ehu.eus
</email>
<note confidence="0.639505333333333">
Aitor Soroa
IXA NLP Group
UPV/EHU
</note>
<address confidence="0.334163">
Donostia, Basque Country
</address>
<email confidence="0.986299">
a.soroa@ehu.eus
</email>
<note confidence="0.67548">
Eneko Agirre
IXA NLP Group
UPV/EHU
</note>
<address confidence="0.352601">
Donostia, Basque Country
</address>
<email confidence="0.994012">
e.agirre@ehu.eus
</email>
<sectionHeader confidence="0.993762" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999614133333333">
Named entity disambiguation is the task of
linking entity mentions to their intended ref-
erent, as represented in a Knowledge Base,
usually derived from Wikipedia. In this paper,
we combine local mention context and global
hyperlink structure from Wikipedia in a prob-
abilistic framework. We test our method in
eight datasets, improving the state-of-the-art
results in five. Our results show that the two
models of context, namely, words in the con-
text and hyperlink pathways to other entities
in the context, are complementary. Our results
are not tuned to any of the datasets, showing
that it is robust to out-of-domain scenarios,
and that further improvements are possible.
</bodyText>
<sectionHeader confidence="0.998992" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999970558139535">
Linking mentions occurring in documents to a
knowledge base is the main goal of Entity Link-
ing or Named Entity Disambiguation (NED). This
problem has attracted a great number of papers in
the NLP and IR communities, and a large number
of techniques, including local context and global in-
ference (Ratinov et al., 2011). We propose to use
a probabilistic framework that combines entity pop-
ularity, name popularity, local mention context and
global hyperlink structure, relying on information in
Wikipedia alone. Entity and name popularity are
useful disambiguation clues in the absence of any
context. The local mention context provides di-
rect clues (in the form of words in context) to dis-
ambiguate each mention separately. The hyperlink
structure of Wikipedia provides a global coherence
measure for all entities mentioned in the same con-
text.
The advantages of our method with respect to
other alternatives are as follows: (1) It does not in-
volve a large number of methods and classifier com-
bination. (2) The method learns the parameters di-
rectly from Wikipedia so no additional hand-labeled
data and training is needed. (3) We combine the
global hyperlink structure of Wikipedia with a lo-
cal bag-of-words probabilistic model in an intuitive
and complementary way. (4) The absence of training
allows for robust results in out-of-domain scenarios.
The evaluation of NED is fragmented, with sev-
eral popular shared tasks, such as TAC-KBP1, ERD2
or NEEL3. Other evaluation datasets include AIDA
and KORE504, which are very common in NED
evaluation. Note that each dataset poses differ-
ent problems. For instance AIDA is composed of
news, and systems need to disambiguate all occur-
ring mentions. TAC includes news and discussion
forums, and focuses on a large number of mentions
for a handful of challenging strings. KORE includes
short sentences with very ambiguous mentions. Un-
fortunately, there is no standard dataset, and many
contributions in this area report results in just one or
two datasets. We report our results on eight datasets,
improving the state-of-the-art results on five.
</bodyText>
<sectionHeader confidence="0.995983" genericHeader="introduction">
2 Resources
</sectionHeader>
<bodyText confidence="0.983994">
The knowledge used by our Bayesian network
comes from Wikipedia. We extract three informa-
</bodyText>
<footnote confidence="0.998472375">
1http://www.nist.gov/tac/2014/KBP/
2http://web-ngram.research.microsoft.
com/erd2014/
3http://www.scc.lancs.ac.uk/
microposts2015/challenge/index.html
4http://www.mpi-inf.mpg.de/departments/
databases-and-information-systems/
research/yago-naga/aida/downloads/
</footnote>
<page confidence="0.954498">
101
</page>
<note confidence="0.4513485">
Proceedings of the Fourth Joint Conference on Lexical and Computational Semantics (*SEM 2015), pages 101–105,
Denver, Colorado, June 4–5, 2015.
</note>
<bodyText confidence="0.975491754716981">
tion resources to perform the disambiguation: a dic-
tionary, textual contexts and a graph.
The dictionary is an association between strings
and Wikipedia articles. We construct the dictio-
nary using article titles, redirections, disambiguation
pages, and anchor text. If the mention links to a
disambiguation page, it is associated with all possi-
ble articles the disambiguation page points to. Each
association between a string and article is scored
with the prior probability, estimated as the number
of times that the mention occurs in the anchor text
of an article divided by the total number of occur-
rences of the mention. We choose candidate enti-
ties for disambiguation by just assigning all entities
linked to the mention in the dictionary.
In addition we build a graph using the Wikipedia
link structure, where entities are nodes and edges
are anchor links among entities from Wikipedia. We
used the third-party dictionary and graph described
in (Agirre et al., 2015), which is publicly available5.
Finally, we extract textual contexts for all the pos-
sible candidate entities from a Wikipedia dump. We
collect all the anchors including a link to each en-
tity in Wikipedia, and extract a context of 50 words
around the anchor link.
3 A Generative Bayesian Network
Given a mention s occurring in context c, our sys-
tem ranks each of the candidate entities e. Figure
1 shows the dependencies among the different vari-
ables. Note that context probability is given by two
different resources.
Candidate entities are ranked combining evi-
dences from 4 different probability distributions,
which we call entity knowledge P(e), name knowl-
edge P(s|e), context knowledge P(cbow|e) and
graph knowledge P(cgrf|e) respectively.
Entity knowledge P(e) represents the probability
of generating entity e, and is estimated as follows:
Count(e) + 1
P(e) =
|M |+ N
where Count(e) describes the entity popularity,
e.g., the number of times the entity e is refer-
enced within Wikipedia, |M |is the number of en-
tity mentions and N is the total number of entities
Figure 1: Dependencies among variables in a Bayesian
network. The network gives as a result this formula:
P(s, cbow, cgrf, e) = P(e)P(s|e)P (cbow|e)P(cgrf|e).
in Wikipedia. As can be seen, the estimation is
smoothed using the add-one method.
Name knowledge P(s|e) represents the probabil-
ity of generating a particular string s given the entity
e, and is estimated as follows:
</bodyText>
<equation confidence="0.702613">
Count(e, s) + 1
P(s|e) = Count(e) + 5
</equation>
<bodyText confidence="0.9383964375">
where Count(e, s) is the number of times mention
s is used to refer entity e and 5 is the number of
different possible names used to refer to e.
The context knowledge is modeled in two differ-
ent ways. In the bag-of-words model, P(cbow|e)
represents the probability of generating context c =
{w1, w2, ... , wn} given the entity e, and is esti-
mated as follows:
P(cbow|e) = Pe(w1)Pe(w2)...Pe(wn)
where Pe(w) is estimated as:
Pe(w) = AP0e(w) + (1 − A)Pw(w)
P0e(w) is the maximum likelihood estimation of each
word w in the context of e entity. Context words are
smoothed by Pw(w) that is the likelihood of words
in the whole Wikipedia. A parameter is set to 0.9
according to development experiments done in Aida
development set (also known as Aida test-a).
The graph knowledge is estimated using person-
alized Pagerank. We used the probabilities returned
by UKB6 (Agirre et al., 2015). This software re-
turns P(e|cgrf)7 the probability of visiting a candi-
date entity when performing a random walk on the
6http://ixa2.si.ehu.es/ukb/
7Note that, contrary to us, the results in (Agirre et al., 2015)
multiply the Pagerank probability with the prior.
5http://ixa2.si.ehu.eus/ukb/ukb-wiki.
tar.bz2
102
Wikipedia graph starting in the entity mentions in
the context. In order to introduce it in the generative
model, we must first convert it to P(cgrf|e). We use
Bayes’ formula to estimate the probability:
</bodyText>
<equation confidence="0.996907">
P(cgrf|e) = P(e|cgrf)P(cgrf)/P(e)
</equation>
<bodyText confidence="0.9103515">
Finally, the Full Model combines all evidences to
find the entity that maximizes the following formula:
</bodyText>
<equation confidence="0.768621">
e = arg max P(s, cbow, cgrf, e) =
e
arg max P(e)P(s|e)P(cbow|e)P(cgrf|e)
e
</equation>
<sectionHeader confidence="0.9918" genericHeader="method">
4 Experiments
</sectionHeader>
<bodyText confidence="0.999975">
We tested our algorithms on a wide range of
datasets: AIDA CoNLL-YAGO test-b (Hoffart et
al., 2011), KORE50 (Hoffart et al., 2012) and six
TAC-KBP8 datasets corresponding to six years of
the competition (Aida, Kore and Tac hereafter). No
corpus was used for training the parameters of the
system, apart from Wikipedia, as explained in the
previous sections.
We used gold-standard mentions and we evalu-
ated only those mentions linked to a Wikipedia en-
tity (ignoring so-called NIL cases). Depending on
the dataset, we used the customary evaluation mea-
sure: micro-accuracy (Aida, Kore, Tac09 and Tac10)
or Bcubed+ (Tac11, Tac12, Tac13 and Tac14)9.
Each gold standard uses a different Wikipedia ver-
sion: 2010 for Aida and Kore, 2008 for Tac. We
use the Wikipedia dump from 25-5-2011 to build
our resources, as this is close to the versions used at
the time. We mapped gold-standard entities to 2011
Wikipedia automatically, using redirects in the 2011
Wikipedia. This mapping could cause a small degra-
dation of our results.
</bodyText>
<sectionHeader confidence="0.505468" genericHeader="method">
4.1 Results
</sectionHeader>
<bodyText confidence="0.999891">
The top 4 rows in table 1 show the performance
of the different combinations among probabilities.
The remaining row shows the best results reported
to date on those datasets (see caption for details).
The results suggest that each probability con-
tributes to the final score of the Full Model, shown
</bodyText>
<footnote confidence="0.98667825">
8http://www.nist.gov/tac/publications/
index.html
9Note that Tac14 results correspond to the so-called Diag-
nostic Entity Linking task.
</footnote>
<bodyText confidence="0.999982368421053">
on row 4, showing that both context models are com-
plementary between each other10. The only excep-
tion is Tac13, where the bow model is best.
Our system obtains very good results in all
datasets, excelling in Tac09-10-11-12-13, where it
beats the state-of-the-art. The figures obtained by
the Full Model on Aida, Kore and Tac14 are close
to the best results. Note that the table shows the re-
sults of the system reporting the best values for each
dataset, that is, our system is compared not to one
single system but to all those systems. For exam-
ple, (Hoffart et al., 2012) reported lower figures for
Kore, 64.58. Regarding the results for TAC-KBP,
the full task includes linking to the Knowledge Base
and detecting and clustering NIL mentions. In or-
der to make results comparable to those for in Aida
and Kore, the table reports the results for mentions
which are linked to the Knowledge Base, that is, re-
sults where NIL mentions are discarded.
</bodyText>
<sectionHeader confidence="0.918051" genericHeader="method">
5 Adjusting the model to the data
</sectionHeader>
<bodyText confidence="0.99950325">
We experimented with weighting the probabilities to
adapt the Full Model mentioned above to a specific
scenario. For the Weighted Full Model, we introduce
the α, Q, -y and 6 parameters11 as follows:
</bodyText>
<equation confidence="0.91647925">
e = arg max P(s, cbow, cgrf, e) =
e
arg max P(e)αP(s|e)βP(cbow|e)γP(cgrf|e)δ
e
</equation>
<bodyText confidence="0.999682214285714">
Weighting may change the optimal configuration
for A, we thus optimized all parameters on the de-
velopment set of Aida, yielding A = 0.8, α = 0.2,
Q = 0.1, -y = 0.6 and 6 = 0.1 performing a exhaus-
tive grid search. The step size used in this experi-
ment is 0.1. The parameters yielded high results for
development, up to 82.88.
Table 2 summarizes the results of the Weighted
Full Model for Aida, showing that model reaches
83.61 points, close to the best micro accuracy re-
ported by (Houlsby and Ciaramita, 2014) and above
those reported by (Hoffart et al., 2011; Moro et
al., 2014). The values of (Hoffart et al., 2011)
and (Moro et al., 2014) for Aida are, respectively,
</bodyText>
<footnote confidence="0.6593458">
10The results of our combination involving the UKB software
are not comparable to those reported by (Agirre et al., 2015),
due to the different formulation of the probability distribution
which involves the prior.
11α + β + γ + δ = 1
</footnote>
<page confidence="0.992619">
103
</page>
<table confidence="0.9992615">
Test Aida Kore Tac09 Tac10 Tac11 Tac12 Tac13 Tac14
P(e)P(s|e) 67.51 36.11 67.46 76.76 68.09 46.34 68.20 62.51
P(e)P(s|e)P(cbow|e) 75.41 60.42 78.39 85.29* 76.24 57.80 76.34* 71.62
P(e)P(s|e)P(cgrf|e) 76.97 54.86 79.64* 83.63* 79.55 69.93* 71.67 71.56
P(e)P(s|e)P(cbow|e)P(cgrf|e) 82.45 70.14 82.15* 85.49* 81.53* 71.94* 74.92* 76.34
Best (state-of-the-art) 84.89 71.50 79.00 80.60 80.10 68.50 71.80 79.60
</table>
<tableCaption confidence="0.983290333333333">
Table 1: Bold marks the best value among probability combinations, and * those results that overcome the best value
reported in the state-of-the-art: (Houlsby and Ciaramita, 2014) for Aida, (Moro et al., 2014) for Kore, (Han and Sun,
2011) for Tac09 and see TAC-KBP proceedings for the rest8.
</tableCaption>
<table confidence="0.999626333333333">
Test Aida
P(e)P(s|e)P(cbow|e)P(cgrf|e) 82.45
P(e)αP(s|e)βP(cbow|e)γP(cgrf|e)δ 83.61
(Hoffart et al., 2011) 82.54
(Houlsby and Ciaramita, 2014) 84.89
(Moro et al., 2014) 82.10
</table>
<tableCaption confidence="0.9903545">
Table 2: Micro accuracy results for Aida introducing the
Weighted Full Model in row 2.
</tableCaption>
<bodyText confidence="0.99879125">
82.5412 and 82.10. Unfortunately the parameter dis-
tribution seems to depend on the test dataset, as the
same parameters failed to improve the results on the
other datasets.
</bodyText>
<sectionHeader confidence="0.9999" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.997496872340426">
The use of Wikipedia for named entity disambigua-
tion is a common approach in this area. In the re-
lated field of Wikification, (Ratinov et al., 2011) in-
troduced the supervised combination of a large num-
ber of global and local similarity measures. They
learn weights for each of those measures training a
supervised classifier on Wikipedia. Our approach is
different in that we just combine four intuitive meth-
ods, without having to learn weights for them. Un-
fortunately they don’t report results for NED.
(Moro et al., 2014) present a complex graph-
based approach for NED and Word Sense Disam-
biguation which works on BabelNet, a complex
combination of several resources including, among
12Note that values by (Hoffart et al., 2011) were reported on a
subset of Aida. The micro accuracy results reported in our table
correspond to the latest best model from the Aida web site:
http://www.mpi-inf.mpg.de/departments/
databases-and-information-systems/
research/yago-naga/aida/.
others, Wikipedia, WordNet and Wiktionary. Our
results are stronger over Aida, but not on the smaller
Kore.
(Hoffart et al., 2011) presents a robust method
based on entity popularity and similarity measures,
which are used to build a mention/entity graph. They
include external knowledge from Yago, and train a
classifier on the train part of Aida, obtaining results
comparable to ours. Given that we do not train on
in-domain training corpora, we think our system is
more robust.
The use of probabilistic models using Wikipedia
for NED was introduced in (Han and Sun, 2011). In
this paper, we extend the model with a global model
which takes the hyperlink structure of Wikipedia
into account.
(Houlsby and Ciaramita, 2014) presents a prob-
abilistic method using topic models, where topics
are associated to Wikipedia articles. They present
strong results, but they need to initialize the sam-
pler on another NED system, Tagme (Ferragina and
Scaiella, 2012). In some sense they also combine
the knowledge in the graph with that of a local al-
gorithm (Tagme), so their work is complementary to
ours. They only provide results on AIDA, and it is
thus not possible to see whether they are as robust as
our algorithm.
</bodyText>
<sectionHeader confidence="0.994074" genericHeader="conclusions">
7 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999886">
Bayesian networks provide a principled method to
combine knowledge sources. In this paper we com-
bine popularity, name knowledge and two methods
to model context: bag-of-words context, and hy-
perlink graph. The combination outperforms the
state-of-the-art in five out of eight datasets, show-
ing the robustness of the system in different domain
</bodyText>
<page confidence="0.996931">
104
</page>
<bodyText confidence="0.999971125">
and dataset types. Our results also show that in all
but one dataset the combination outperforms indi-
vidual models, indicating that bag-or-word context
and graph context are complementary. We show
that results can be further improved when tuning the
weights on in-domain development corpora.
Given that Bayesian networks can be further ex-
tended, we are exploring to introduce additional
models of context into a Markov Random Field al-
gorithm. Our current model assumes that the two
models of context (bag or words and graph) are in-
dependent given e, and we would like to explore al-
ternatives to relax this assumption. We would also
like to explore whether more sophisticated smooth-
ing techniques could improve our probability esti-
mates.
</bodyText>
<sectionHeader confidence="0.99856" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999935444444444">
We thank the reviewers for their suggestions. This
work was partially funded by MINECO (CHIST-
ERA READERS project – PCIN-2013-002-C02-
01, and SKaTeR project – TIN2012-38584-C06-02),
and the European Commission (QTLEAP – FP7-
ICT-2013.4.1-610516). The IXA group is funded by
the Basque Government (A type Research Group).
Ander Barrena enjoys an PhD scholarship from the
Basque Government.
</bodyText>
<sectionHeader confidence="0.999258" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999624068181818">
E. Agirre, A. Barrena, and A. Soroa. 2015. Studying
the Wikipedia Hyperlink Graph for Relatedness and
Disambiguation. ArXiv e-prints, March.
Paolo Ferragina and Ugo Scaiella. 2012. Fast and ac-
curate annotation of short texts with wikipedia pages.
IEEE Software, 29(1):70–75.
X. Han and L. Sun. 2011. A Generative Entity-mention
Model for Linking Entities with Knowledge Base. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies, volume 1, pages 945–954.
J. Hoffart, M.A. Yosef, I. Bordino, H. F¨urstenau,
M. Pinkal, M. Spaniol, B. Taneva, S. Thater, and
G. Weikum. 2011. Robust Disambiguation of Named
Entities in Text. In Conference on Empirical Meth-
ods in Natural Language Processing, Edinburgh, Scot-
land, United Kingdom 2011, pages 782–792.
Johannes Hoffart, Stephan Seufert, Dat Ba Nguyen, Mar-
tin Theobald, and Gerhard Weikum. 2012. Kore:
Keyphrase overlap relatedness for entity disambigua-
tion. In Proceedings of the 21st ACM international
conference on Information and knowledge manage-
ment, page 545554.
Neil Houlsby and Massimiliano Ciaramita. 2014. A
scalable gibbs sampler for probabilistic entity linking.
In Maarten de Rijke, Tom Kenter, ArjenP. de Vries,
ChengXiang Zhai, Franciska de Jong, Kira Radinsky,
and Katja Hofmann, editors, Advances in Information
Retrieval, volume 8416 of Lecture Notes in Computer
Science, pages 335–346. Springer International Pub-
lishing.
Andrea Moro, Alessandro Raganato, and Roberto Nav-
igli. 2014. Entity linking meets word sense dis-
ambiguation: a unied approach. Transactions of the
Association of Computational Linguistics, 2:231–244,
May.
L.A. Ratinov, D. Roth, D. Downey, and M. Anderson.
2011. Local and Global Algorithms for Disambigua-
tion to Wikipedia. In The 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies, Proceedings of the Con-
ference, 19-24 June, 2011, Portland, Oregon, USA,
pages 1375–1384. The Association for Computer Lin-
guistics.
</reference>
<page confidence="0.999001">
105
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.078038">
<title confidence="0.999082">Combining Mention Context and Hyperlinks from for Named Entity Disambiguation</title>
<author confidence="0.946035">Ander</author>
<affiliation confidence="0.980045">IXA NLP</affiliation>
<address confidence="0.896312">Donostia, Basque</address>
<email confidence="0.601104">ander.barrena@ehu.eus</email>
<author confidence="0.360751">Aitor</author>
<affiliation confidence="0.837029">IXA NLP</affiliation>
<address confidence="0.841581">Donostia, Basque</address>
<email confidence="0.85837">a.soroa@ehu.eus</email>
<author confidence="0.447563">Eneko</author>
<affiliation confidence="0.973467">IXA NLP</affiliation>
<address confidence="0.959673">Donostia, Basque</address>
<email confidence="0.979723">e.agirre@ehu.eus</email>
<abstract confidence="0.999302625">Named entity disambiguation is the task of linking entity mentions to their intended referent, as represented in a Knowledge Base, usually derived from Wikipedia. In this paper, we combine local mention context and global hyperlink structure from Wikipedia in a probabilistic framework. We test our method in eight datasets, improving the state-of-the-art results in five. Our results show that the two models of context, namely, words in the context and hyperlink pathways to other entities in the context, are complementary. Our results are not tuned to any of the datasets, showing that it is robust to out-of-domain scenarios, and that further improvements are possible.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>A Barrena</author>
<author>A Soroa</author>
</authors>
<title>Studying the Wikipedia Hyperlink Graph for Relatedness and Disambiguation. ArXiv e-prints,</title>
<date>2015</date>
<contexts>
<context position="4590" citStr="Agirre et al., 2015" startWordPosition="682" endWordPosition="685">cles the disambiguation page points to. Each association between a string and article is scored with the prior probability, estimated as the number of times that the mention occurs in the anchor text of an article divided by the total number of occurrences of the mention. We choose candidate entities for disambiguation by just assigning all entities linked to the mention in the dictionary. In addition we build a graph using the Wikipedia link structure, where entities are nodes and edges are anchor links among entities from Wikipedia. We used the third-party dictionary and graph described in (Agirre et al., 2015), which is publicly available5. Finally, we extract textual contexts for all the possible candidate entities from a Wikipedia dump. We collect all the anchors including a link to each entity in Wikipedia, and extract a context of 50 words around the anchor link. 3 A Generative Bayesian Network Given a mention s occurring in context c, our system ranks each of the candidate entities e. Figure 1 shows the dependencies among the different variables. Note that context probability is given by two different resources. Candidate entities are ranked combining evidences from 4 different probability dis</context>
<context position="6951" citStr="Agirre et al., 2015" startWordPosition="1082" endWordPosition="1085">ility of generating context c = {w1, w2, ... , wn} given the entity e, and is estimated as follows: P(cbow|e) = Pe(w1)Pe(w2)...Pe(wn) where Pe(w) is estimated as: Pe(w) = AP0e(w) + (1 − A)Pw(w) P0e(w) is the maximum likelihood estimation of each word w in the context of e entity. Context words are smoothed by Pw(w) that is the likelihood of words in the whole Wikipedia. A parameter is set to 0.9 according to development experiments done in Aida development set (also known as Aida test-a). The graph knowledge is estimated using personalized Pagerank. We used the probabilities returned by UKB6 (Agirre et al., 2015). This software returns P(e|cgrf)7 the probability of visiting a candidate entity when performing a random walk on the 6http://ixa2.si.ehu.es/ukb/ 7Note that, contrary to us, the results in (Agirre et al., 2015) multiply the Pagerank probability with the prior. 5http://ixa2.si.ehu.eus/ukb/ukb-wiki. tar.bz2 102 Wikipedia graph starting in the entity mentions in the context. In order to introduce it in the generative model, we must first convert it to P(cgrf|e). We use Bayes’ formula to estimate the probability: P(cgrf|e) = P(e|cgrf)P(cgrf)/P(e) Finally, the Full Model combines all evidences to </context>
<context position="11207" citStr="Agirre et al., 2015" startWordPosition="1790" endWordPosition="1793">= 0.1 performing a exhaustive grid search. The step size used in this experiment is 0.1. The parameters yielded high results for development, up to 82.88. Table 2 summarizes the results of the Weighted Full Model for Aida, showing that model reaches 83.61 points, close to the best micro accuracy reported by (Houlsby and Ciaramita, 2014) and above those reported by (Hoffart et al., 2011; Moro et al., 2014). The values of (Hoffart et al., 2011) and (Moro et al., 2014) for Aida are, respectively, 10The results of our combination involving the UKB software are not comparable to those reported by (Agirre et al., 2015), due to the different formulation of the probability distribution which involves the prior. 11α + β + γ + δ = 1 103 Test Aida Kore Tac09 Tac10 Tac11 Tac12 Tac13 Tac14 P(e)P(s|e) 67.51 36.11 67.46 76.76 68.09 46.34 68.20 62.51 P(e)P(s|e)P(cbow|e) 75.41 60.42 78.39 85.29* 76.24 57.80 76.34* 71.62 P(e)P(s|e)P(cgrf|e) 76.97 54.86 79.64* 83.63* 79.55 69.93* 71.67 71.56 P(e)P(s|e)P(cbow|e)P(cgrf|e) 82.45 70.14 82.15* 85.49* 81.53* 71.94* 74.92* 76.34 Best (state-of-the-art) 84.89 71.50 79.00 80.60 80.10 68.50 71.80 79.60 Table 1: Bold marks the best value among probability combinations, and * those</context>
</contexts>
<marker>Agirre, Barrena, Soroa, 2015</marker>
<rawString>E. Agirre, A. Barrena, and A. Soroa. 2015. Studying the Wikipedia Hyperlink Graph for Relatedness and Disambiguation. ArXiv e-prints, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paolo Ferragina</author>
<author>Ugo Scaiella</author>
</authors>
<title>Fast and accurate annotation of short texts with wikipedia pages.</title>
<date>2012</date>
<journal>IEEE Software,</journal>
<volume>29</volume>
<issue>1</issue>
<contexts>
<context position="14401" citStr="Ferragina and Scaiella, 2012" startWordPosition="2288" endWordPosition="2291">he train part of Aida, obtaining results comparable to ours. Given that we do not train on in-domain training corpora, we think our system is more robust. The use of probabilistic models using Wikipedia for NED was introduced in (Han and Sun, 2011). In this paper, we extend the model with a global model which takes the hyperlink structure of Wikipedia into account. (Houlsby and Ciaramita, 2014) presents a probabilistic method using topic models, where topics are associated to Wikipedia articles. They present strong results, but they need to initialize the sampler on another NED system, Tagme (Ferragina and Scaiella, 2012). In some sense they also combine the knowledge in the graph with that of a local algorithm (Tagme), so their work is complementary to ours. They only provide results on AIDA, and it is thus not possible to see whether they are as robust as our algorithm. 7 Conclusions and future work Bayesian networks provide a principled method to combine knowledge sources. In this paper we combine popularity, name knowledge and two methods to model context: bag-of-words context, and hyperlink graph. The combination outperforms the state-of-the-art in five out of eight datasets, showing the robustness of the</context>
</contexts>
<marker>Ferragina, Scaiella, 2012</marker>
<rawString>Paolo Ferragina and Ugo Scaiella. 2012. Fast and accurate annotation of short texts with wikipedia pages. IEEE Software, 29(1):70–75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>X Han</author>
<author>L Sun</author>
</authors>
<title>A Generative Entity-mention Model for Linking Entities with Knowledge Base.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<volume>1</volume>
<pages>945--954</pages>
<contexts>
<context position="11968" citStr="Han and Sun, 2011" startWordPosition="1907" endWordPosition="1910"> Tac11 Tac12 Tac13 Tac14 P(e)P(s|e) 67.51 36.11 67.46 76.76 68.09 46.34 68.20 62.51 P(e)P(s|e)P(cbow|e) 75.41 60.42 78.39 85.29* 76.24 57.80 76.34* 71.62 P(e)P(s|e)P(cgrf|e) 76.97 54.86 79.64* 83.63* 79.55 69.93* 71.67 71.56 P(e)P(s|e)P(cbow|e)P(cgrf|e) 82.45 70.14 82.15* 85.49* 81.53* 71.94* 74.92* 76.34 Best (state-of-the-art) 84.89 71.50 79.00 80.60 80.10 68.50 71.80 79.60 Table 1: Bold marks the best value among probability combinations, and * those results that overcome the best value reported in the state-of-the-art: (Houlsby and Ciaramita, 2014) for Aida, (Moro et al., 2014) for Kore, (Han and Sun, 2011) for Tac09 and see TAC-KBP proceedings for the rest8. Test Aida P(e)P(s|e)P(cbow|e)P(cgrf|e) 82.45 P(e)αP(s|e)βP(cbow|e)γP(cgrf|e)δ 83.61 (Hoffart et al., 2011) 82.54 (Houlsby and Ciaramita, 2014) 84.89 (Moro et al., 2014) 82.10 Table 2: Micro accuracy results for Aida introducing the Weighted Full Model in row 2. 82.5412 and 82.10. Unfortunately the parameter distribution seems to depend on the test dataset, as the same parameters failed to improve the results on the other datasets. 6 Related Work The use of Wikipedia for named entity disambiguation is a common approach in this area. In the r</context>
<context position="14020" citStr="Han and Sun, 2011" startWordPosition="2228" endWordPosition="2231">ormation-systems/ research/yago-naga/aida/. others, Wikipedia, WordNet and Wiktionary. Our results are stronger over Aida, but not on the smaller Kore. (Hoffart et al., 2011) presents a robust method based on entity popularity and similarity measures, which are used to build a mention/entity graph. They include external knowledge from Yago, and train a classifier on the train part of Aida, obtaining results comparable to ours. Given that we do not train on in-domain training corpora, we think our system is more robust. The use of probabilistic models using Wikipedia for NED was introduced in (Han and Sun, 2011). In this paper, we extend the model with a global model which takes the hyperlink structure of Wikipedia into account. (Houlsby and Ciaramita, 2014) presents a probabilistic method using topic models, where topics are associated to Wikipedia articles. They present strong results, but they need to initialize the sampler on another NED system, Tagme (Ferragina and Scaiella, 2012). In some sense they also combine the knowledge in the graph with that of a local algorithm (Tagme), so their work is complementary to ours. They only provide results on AIDA, and it is thus not possible to see whether </context>
</contexts>
<marker>Han, Sun, 2011</marker>
<rawString>X. Han and L. Sun. 2011. A Generative Entity-mention Model for Linking Entities with Knowledge Base. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, volume 1, pages 945–954.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hoffart</author>
<author>M A Yosef</author>
<author>I Bordino</author>
<author>H F¨urstenau</author>
<author>M Pinkal</author>
<author>M Spaniol</author>
<author>B Taneva</author>
<author>S Thater</author>
<author>G Weikum</author>
</authors>
<date>2011</date>
<booktitle>Robust Disambiguation of Named Entities in Text. In Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>782--792</pages>
<location>Edinburgh, Scotland, United Kingdom</location>
<marker>Hoffart, Yosef, Bordino, F¨urstenau, Pinkal, Spaniol, Taneva, Thater, Weikum, 2011</marker>
<rawString>J. Hoffart, M.A. Yosef, I. Bordino, H. F¨urstenau, M. Pinkal, M. Spaniol, B. Taneva, S. Thater, and G. Weikum. 2011. Robust Disambiguation of Named Entities in Text. In Conference on Empirical Methods in Natural Language Processing, Edinburgh, Scotland, United Kingdom 2011, pages 782–792.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johannes Hoffart</author>
<author>Stephan Seufert</author>
<author>Dat Ba Nguyen</author>
<author>Martin Theobald</author>
<author>Gerhard Weikum</author>
</authors>
<title>Kore: Keyphrase overlap relatedness for entity disambiguation.</title>
<date>2012</date>
<booktitle>In Proceedings of the 21st ACM international conference on Information and knowledge management,</booktitle>
<pages>545554</pages>
<contexts>
<context position="7824" citStr="Hoffart et al., 2012" startWordPosition="1216" endWordPosition="1219">he prior. 5http://ixa2.si.ehu.eus/ukb/ukb-wiki. tar.bz2 102 Wikipedia graph starting in the entity mentions in the context. In order to introduce it in the generative model, we must first convert it to P(cgrf|e). We use Bayes’ formula to estimate the probability: P(cgrf|e) = P(e|cgrf)P(cgrf)/P(e) Finally, the Full Model combines all evidences to find the entity that maximizes the following formula: e = arg max P(s, cbow, cgrf, e) = e arg max P(e)P(s|e)P(cbow|e)P(cgrf|e) e 4 Experiments We tested our algorithms on a wide range of datasets: AIDA CoNLL-YAGO test-b (Hoffart et al., 2011), KORE50 (Hoffart et al., 2012) and six TAC-KBP8 datasets corresponding to six years of the competition (Aida, Kore and Tac hereafter). No corpus was used for training the parameters of the system, apart from Wikipedia, as explained in the previous sections. We used gold-standard mentions and we evaluated only those mentions linked to a Wikipedia entity (ignoring so-called NIL cases). Depending on the dataset, we used the customary evaluation measure: micro-accuracy (Aida, Kore, Tac09 and Tac10) or Bcubed+ (Tac11, Tac12, Tac13 and Tac14)9. Each gold standard uses a different Wikipedia version: 2010 for Aida and Kore, 2008 f</context>
<context position="9732" citStr="Hoffart et al., 2012" startWordPosition="1530" endWordPosition="1533">to the so-called Diagnostic Entity Linking task. on row 4, showing that both context models are complementary between each other10. The only exception is Tac13, where the bow model is best. Our system obtains very good results in all datasets, excelling in Tac09-10-11-12-13, where it beats the state-of-the-art. The figures obtained by the Full Model on Aida, Kore and Tac14 are close to the best results. Note that the table shows the results of the system reporting the best values for each dataset, that is, our system is compared not to one single system but to all those systems. For example, (Hoffart et al., 2012) reported lower figures for Kore, 64.58. Regarding the results for TAC-KBP, the full task includes linking to the Knowledge Base and detecting and clustering NIL mentions. In order to make results comparable to those for in Aida and Kore, the table reports the results for mentions which are linked to the Knowledge Base, that is, results where NIL mentions are discarded. 5 Adjusting the model to the data We experimented with weighting the probabilities to adapt the Full Model mentioned above to a specific scenario. For the Weighted Full Model, we introduce the α, Q, -y and 6 parameters11 as fol</context>
</contexts>
<marker>Hoffart, Seufert, Nguyen, Theobald, Weikum, 2012</marker>
<rawString>Johannes Hoffart, Stephan Seufert, Dat Ba Nguyen, Martin Theobald, and Gerhard Weikum. 2012. Kore: Keyphrase overlap relatedness for entity disambiguation. In Proceedings of the 21st ACM international conference on Information and knowledge management, page 545554.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Neil Houlsby</author>
<author>Massimiliano Ciaramita</author>
</authors>
<title>A scalable gibbs sampler for probabilistic entity linking.</title>
<date>2014</date>
<booktitle>Advances in Information Retrieval,</booktitle>
<volume>8416</volume>
<pages>335--346</pages>
<editor>In Maarten de Rijke, Tom Kenter, ArjenP. de Vries, ChengXiang Zhai, Franciska de Jong, Kira Radinsky, and Katja Hofmann, editors,</editor>
<publisher>Springer International Publishing.</publisher>
<contexts>
<context position="10925" citStr="Houlsby and Ciaramita, 2014" startWordPosition="1741" endWordPosition="1744"> α, Q, -y and 6 parameters11 as follows: e = arg max P(s, cbow, cgrf, e) = e arg max P(e)αP(s|e)βP(cbow|e)γP(cgrf|e)δ e Weighting may change the optimal configuration for A, we thus optimized all parameters on the development set of Aida, yielding A = 0.8, α = 0.2, Q = 0.1, -y = 0.6 and 6 = 0.1 performing a exhaustive grid search. The step size used in this experiment is 0.1. The parameters yielded high results for development, up to 82.88. Table 2 summarizes the results of the Weighted Full Model for Aida, showing that model reaches 83.61 points, close to the best micro accuracy reported by (Houlsby and Ciaramita, 2014) and above those reported by (Hoffart et al., 2011; Moro et al., 2014). The values of (Hoffart et al., 2011) and (Moro et al., 2014) for Aida are, respectively, 10The results of our combination involving the UKB software are not comparable to those reported by (Agirre et al., 2015), due to the different formulation of the probability distribution which involves the prior. 11α + β + γ + δ = 1 103 Test Aida Kore Tac09 Tac10 Tac11 Tac12 Tac13 Tac14 P(e)P(s|e) 67.51 36.11 67.46 76.76 68.09 46.34 68.20 62.51 P(e)P(s|e)P(cbow|e) 75.41 60.42 78.39 85.29* 76.24 57.80 76.34* 71.62 P(e)P(s|e)P(cgrf|e) 7</context>
<context position="12164" citStr="Houlsby and Ciaramita, 2014" startWordPosition="1931" endWordPosition="1934">79.64* 83.63* 79.55 69.93* 71.67 71.56 P(e)P(s|e)P(cbow|e)P(cgrf|e) 82.45 70.14 82.15* 85.49* 81.53* 71.94* 74.92* 76.34 Best (state-of-the-art) 84.89 71.50 79.00 80.60 80.10 68.50 71.80 79.60 Table 1: Bold marks the best value among probability combinations, and * those results that overcome the best value reported in the state-of-the-art: (Houlsby and Ciaramita, 2014) for Aida, (Moro et al., 2014) for Kore, (Han and Sun, 2011) for Tac09 and see TAC-KBP proceedings for the rest8. Test Aida P(e)P(s|e)P(cbow|e)P(cgrf|e) 82.45 P(e)αP(s|e)βP(cbow|e)γP(cgrf|e)δ 83.61 (Hoffart et al., 2011) 82.54 (Houlsby and Ciaramita, 2014) 84.89 (Moro et al., 2014) 82.10 Table 2: Micro accuracy results for Aida introducing the Weighted Full Model in row 2. 82.5412 and 82.10. Unfortunately the parameter distribution seems to depend on the test dataset, as the same parameters failed to improve the results on the other datasets. 6 Related Work The use of Wikipedia for named entity disambiguation is a common approach in this area. In the related field of Wikification, (Ratinov et al., 2011) introduced the supervised combination of a large number of global and local similarity measures. They learn weights for each of those measures </context>
<context position="14169" citStr="Houlsby and Ciaramita, 2014" startWordPosition="2252" endWordPosition="2255">maller Kore. (Hoffart et al., 2011) presents a robust method based on entity popularity and similarity measures, which are used to build a mention/entity graph. They include external knowledge from Yago, and train a classifier on the train part of Aida, obtaining results comparable to ours. Given that we do not train on in-domain training corpora, we think our system is more robust. The use of probabilistic models using Wikipedia for NED was introduced in (Han and Sun, 2011). In this paper, we extend the model with a global model which takes the hyperlink structure of Wikipedia into account. (Houlsby and Ciaramita, 2014) presents a probabilistic method using topic models, where topics are associated to Wikipedia articles. They present strong results, but they need to initialize the sampler on another NED system, Tagme (Ferragina and Scaiella, 2012). In some sense they also combine the knowledge in the graph with that of a local algorithm (Tagme), so their work is complementary to ours. They only provide results on AIDA, and it is thus not possible to see whether they are as robust as our algorithm. 7 Conclusions and future work Bayesian networks provide a principled method to combine knowledge sources. In thi</context>
</contexts>
<marker>Houlsby, Ciaramita, 2014</marker>
<rawString>Neil Houlsby and Massimiliano Ciaramita. 2014. A scalable gibbs sampler for probabilistic entity linking. In Maarten de Rijke, Tom Kenter, ArjenP. de Vries, ChengXiang Zhai, Franciska de Jong, Kira Radinsky, and Katja Hofmann, editors, Advances in Information Retrieval, volume 8416 of Lecture Notes in Computer Science, pages 335–346. Springer International Publishing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andrea Moro</author>
<author>Alessandro Raganato</author>
<author>Roberto Navigli</author>
</authors>
<title>Entity linking meets word sense disambiguation: a unied approach.</title>
<date>2014</date>
<journal>Transactions of the Association of Computational Linguistics,</journal>
<pages>2--231</pages>
<contexts>
<context position="10995" citStr="Moro et al., 2014" startWordPosition="1754" endWordPosition="1757"> max P(e)αP(s|e)βP(cbow|e)γP(cgrf|e)δ e Weighting may change the optimal configuration for A, we thus optimized all parameters on the development set of Aida, yielding A = 0.8, α = 0.2, Q = 0.1, -y = 0.6 and 6 = 0.1 performing a exhaustive grid search. The step size used in this experiment is 0.1. The parameters yielded high results for development, up to 82.88. Table 2 summarizes the results of the Weighted Full Model for Aida, showing that model reaches 83.61 points, close to the best micro accuracy reported by (Houlsby and Ciaramita, 2014) and above those reported by (Hoffart et al., 2011; Moro et al., 2014). The values of (Hoffart et al., 2011) and (Moro et al., 2014) for Aida are, respectively, 10The results of our combination involving the UKB software are not comparable to those reported by (Agirre et al., 2015), due to the different formulation of the probability distribution which involves the prior. 11α + β + γ + δ = 1 103 Test Aida Kore Tac09 Tac10 Tac11 Tac12 Tac13 Tac14 P(e)P(s|e) 67.51 36.11 67.46 76.76 68.09 46.34 68.20 62.51 P(e)P(s|e)P(cbow|e) 75.41 60.42 78.39 85.29* 76.24 57.80 76.34* 71.62 P(e)P(s|e)P(cgrf|e) 76.97 54.86 79.64* 83.63* 79.55 69.93* 71.67 71.56 P(e)P(s|e)P(cbow|e)P</context>
<context position="12995" citStr="Moro et al., 2014" startWordPosition="2072" endWordPosition="2075">et, as the same parameters failed to improve the results on the other datasets. 6 Related Work The use of Wikipedia for named entity disambiguation is a common approach in this area. In the related field of Wikification, (Ratinov et al., 2011) introduced the supervised combination of a large number of global and local similarity measures. They learn weights for each of those measures training a supervised classifier on Wikipedia. Our approach is different in that we just combine four intuitive methods, without having to learn weights for them. Unfortunately they don’t report results for NED. (Moro et al., 2014) present a complex graphbased approach for NED and Word Sense Disambiguation which works on BabelNet, a complex combination of several resources including, among 12Note that values by (Hoffart et al., 2011) were reported on a subset of Aida. The micro accuracy results reported in our table correspond to the latest best model from the Aida web site: http://www.mpi-inf.mpg.de/departments/ databases-and-information-systems/ research/yago-naga/aida/. others, Wikipedia, WordNet and Wiktionary. Our results are stronger over Aida, but not on the smaller Kore. (Hoffart et al., 2011) presents a robust </context>
</contexts>
<marker>Moro, Raganato, Navigli, 2014</marker>
<rawString>Andrea Moro, Alessandro Raganato, and Roberto Navigli. 2014. Entity linking meets word sense disambiguation: a unied approach. Transactions of the Association of Computational Linguistics, 2:231–244, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L A Ratinov</author>
<author>D Roth</author>
<author>D Downey</author>
<author>M Anderson</author>
</authors>
<title>Local and Global Algorithms for Disambiguation to Wikipedia.</title>
<date>2011</date>
<booktitle>In The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference,</booktitle>
<pages>1375--1384</pages>
<publisher>The Association</publisher>
<institution>for Computer Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<contexts>
<context position="1339" citStr="Ratinov et al., 2011" startWordPosition="201" endWordPosition="204">how that the two models of context, namely, words in the context and hyperlink pathways to other entities in the context, are complementary. Our results are not tuned to any of the datasets, showing that it is robust to out-of-domain scenarios, and that further improvements are possible. 1 Introduction Linking mentions occurring in documents to a knowledge base is the main goal of Entity Linking or Named Entity Disambiguation (NED). This problem has attracted a great number of papers in the NLP and IR communities, and a large number of techniques, including local context and global inference (Ratinov et al., 2011). We propose to use a probabilistic framework that combines entity popularity, name popularity, local mention context and global hyperlink structure, relying on information in Wikipedia alone. Entity and name popularity are useful disambiguation clues in the absence of any context. The local mention context provides direct clues (in the form of words in context) to disambiguate each mention separately. The hyperlink structure of Wikipedia provides a global coherence measure for all entities mentioned in the same context. The advantages of our method with respect to other alternatives are as fo</context>
<context position="12620" citStr="Ratinov et al., 2011" startWordPosition="2010" endWordPosition="2013">eedings for the rest8. Test Aida P(e)P(s|e)P(cbow|e)P(cgrf|e) 82.45 P(e)αP(s|e)βP(cbow|e)γP(cgrf|e)δ 83.61 (Hoffart et al., 2011) 82.54 (Houlsby and Ciaramita, 2014) 84.89 (Moro et al., 2014) 82.10 Table 2: Micro accuracy results for Aida introducing the Weighted Full Model in row 2. 82.5412 and 82.10. Unfortunately the parameter distribution seems to depend on the test dataset, as the same parameters failed to improve the results on the other datasets. 6 Related Work The use of Wikipedia for named entity disambiguation is a common approach in this area. In the related field of Wikification, (Ratinov et al., 2011) introduced the supervised combination of a large number of global and local similarity measures. They learn weights for each of those measures training a supervised classifier on Wikipedia. Our approach is different in that we just combine four intuitive methods, without having to learn weights for them. Unfortunately they don’t report results for NED. (Moro et al., 2014) present a complex graphbased approach for NED and Word Sense Disambiguation which works on BabelNet, a complex combination of several resources including, among 12Note that values by (Hoffart et al., 2011) were reported on a</context>
</contexts>
<marker>Ratinov, Roth, Downey, Anderson, 2011</marker>
<rawString>L.A. Ratinov, D. Roth, D. Downey, and M. Anderson. 2011. Local and Global Algorithms for Disambiguation to Wikipedia. In The 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, Proceedings of the Conference, 19-24 June, 2011, Portland, Oregon, USA, pages 1375–1384. The Association for Computer Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>