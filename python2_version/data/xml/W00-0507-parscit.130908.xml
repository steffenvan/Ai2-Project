<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000418">
<title confidence="0.541434">
TransType: a Computer-Aided Translation Typing System
</title>
<note confidence="0.965756666666667">
Philippe Langlais and George Foster and Guy Lapalme
RALI/DIRO — Universite de Montréal
C.P. 6128, succursale Centre-ville
H3C 3Y7 Montréal, Canada
Phone: +1(514) 343-2145
Fax: +1(514) 343-5834
</note>
<email confidence="0.994304">
email: If elipe ,f oster,lapalmel@iro.umontreal.ca
</email>
<sectionHeader confidence="0.995587" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999853333333333">
This paper describes the embedding of a sta-
tistical translation system within a text editor
to produce TRANSTYPE, a system that watches
over the user as he or she types a translation and
repeatedly suggests completions for the text al-
ready entered. This innovative Embedded Ma-
chine Translation system is thus a specialized
means of helping produce high quality transla-
tions.
</bodyText>
<sectionHeader confidence="0.9979" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999759183673469">
TRANSTYPE is a project set up to explore an
appealing solution to the problem of using In-
teractive Machine Translation (IMT) as a tool
for professional or other highly-skilled transla-
tors. IMT first appeared as part of Kay&apos;s MIND
system (Kay, 1973), where the user&apos;s role was
to help the computer analyze the source text
by answering questions about word sense, el-
lipsis, phrasal attachments, etc. Most later
work on IMT, eg (Blanchon, 1991; Brown and
Nirenburg, 1990; Maruyama and Watanabe,
1990; Whitelock et al., 1986), has followed in
this vein, concentrating on improving the ques-
tion/answer process by having less questions,
more friendly ones, etc. Despite progress in
these endeavors, systems of this sort are gen-
erally unsuitable as tools for skilled translators
because the user serves only as an advisor, with
the MT components keeping overall control over
the translation process.
TRANSTYPE originated from the conviction
that a better approach to IMT for competent
translators would be to shift the focus of in-
teraction from the meaning of the source text
to the form of the target text. This woutd re-
lieve the translator of the burden of having to
provide explicit analyses of the source text and
allow him to translate naturally, assisted by the
machine whenever possible.
In this approach, a translation emerges from
a series of alternating contributions by human
and machine. The machine&apos;s contributions are
basically proposals for parts of the target text,
while the translator&apos;s can take many forms, in-
cluding pieces of target text, corrections to a
previous machine contribution, hints about the
nature of the desired translation, etc. In all
cases, the translator remains directly in control
of the process: the machine must respect the
constraints implicit in his contributions, and he
or she is free to accept, modify, or completely
ignore its proposals.
So TRANSTYPE is a specialized text editor
with an embedded Machine translation engine
as one of its components. In this project we
had to address the following problems: how to
interact with the user and how to find appro-
priate multi-word units for suggestions that can
be computed in real time.
</bodyText>
<sectionHeader confidence="0.973698" genericHeader="method">
2 The TransType model
</sectionHeader>
<subsectionHeader confidence="0.978639">
2.1 User Viewpoint
</subsectionHeader>
<bodyText confidence="0.999595625">
Our interactive translation system is illustrated
in figure 1 for an English to French translation.
It works as follows: a translator selects a sen-
tence and begins typing its translation. After
each character typed by the translator, the sys-
tem displays a proposed completion, which may
either be accepted using a special key or rejected
by continuing to type. This interface is simple
and its performance may be measured by the
proportion of characters or keystrokes saved in
typing a translation. Note that, throughout this
process, the translator remains in control, and
the machine must continually adapt its sugges-
tions to the translator&apos;s input. This differs from
the usual machine translation set-ups where it is
the machine that produces the first draft which
</bodyText>
<page confidence="0.998916">
46
</page>
<figure confidence="0.8188525">
• &gt;
TransType V2.1
</figure>
<subsectionHeader confidence="0.835353">
Fichier Options
</subsectionHeader>
<bodyText confidence="0.88069975">
I am pleased to take part in this debate today .
Using today s technologies , it is possible for all Canadians to
register their votes on issues of public spending and public
borrowing.
</bodyText>
<equation confidence="0.446066">
r proposal is a symbolical attexnpt to democratize
</equation>
<bodyText confidence="0.507929">
open 0:1whoidiissue of public finance.
</bodyText>
<figure confidence="0.932346666666667">
.••
II me fait plaisir de prendre la parole aujourd&apos;hui dans le cadre de ce
debat
00..r Etat
Notre p top oztorL
iii
</figure>
<figureCaption confidence="0.999985">
Figure 1: Example of an interaction in TRANSTYPE with the source text in the top half of the
</figureCaption>
<bodyText confidence="0.995144333333333">
screen. The target text is typed in the bottom half with suggestions given by the menu at the
insertion point.
then has to be corrected by the translator.
The first version of TRANSTYPE (Foster et
al., 1997) only proposed completions for the cur-
rent word. We are now working on predictions
which extend to the next several words in the
text. The potential gain from multiple-word
predictions (Langlais et al., 2000) can be ap-
preciated in the one-sentence translation task
reported in table 1, where a hypothetical user
saves over 60% of the keystrokes needed to pro-
duce a translation in a word completion sce-
nario, and about 75% in a &amp;quot;unit&amp;quot; completion
scenario
</bodyText>
<subsectionHeader confidence="0.996138">
2.2 System Viewpoint
</subsectionHeader>
<bodyText confidence="0.999834333333333">
The core of TRANSTYPE is a completion engine
which comprises two main parts: an evaluator
which assigns probabilistic scores to completion
</bodyText>
<page confidence="0.996055">
47
</page>
<bodyText confidence="0.900465">
This bill is very similar to its companion bill which we dealt with yesterday
in the house of commons
word-completion task. unit-completion task
pref. completions pref. completions
ce ce+ /loi • c/&apos; c+ /loi • c/e projet de loi
projet p+ /est • p/rojet - /de - e/st
de d+ /tres • d/e - /de • tires
loi I+ /tras - I/oi - /de • s/es • se/mblable
est e+ /de • e/st e+ /loi • a/u projet de loi sur
tres t+ /de • t/res t+ /nous • q/ui - qu/e
semblable se+ /de • s/es • se/mblable se+ /nous
au au+ /loi • a/vec a+ /nous • a/vec • av/ons
projet p+ /loi • p/rojet - /a la chambre des communes
de d+ /loi • d/e - e/n • ex/istence • exa/mine
loi I+ /nous • Voi. - /a la chambre des communes
que qu+ /nous • q/ui • qu/e qu+ h/ier
nous + /nous + /a la chambre des communes
avons av+ /nous • a/vec • av/ons av+
examine ex+ /hier • e/n • ex/amine exa+
hier + /hier h+
a la à+ /hier • a/ la +
chambre + /chambre -
des de+ /communes • d/e • de/s -
</bodyText>
<table confidence="0.867817333333333">
communes + /communes -
106 char. 23 20 accept. 14 11 accept. + 1 correc.
43 keystrokes 26 keystrokes
</table>
<tableCaption confidence="0.991289">
Table 1: A one-sentence session illustrating the word- and unit- completion tasks. The first col-
</tableCaption>
<bodyText confidence="0.966533555555556">
umn indicates the target words the user is expected to produce. The next two columns indicate
respectively the prefixes typed by the user and the completions made by the system under a word-
completion task. The last two columns provide the same information for the unit-completion task.
The total number of keystrokes for both tasks is reported in the last line. + indicates the accep-
tance key typed by the user. A Completion is denoted by a/13 where a is the typed prefix and
the completed part. Completions for different prefixes are separated by • .
hypotheses and a generator which uses the eval-
uation function to select the best candidate for
completion.
</bodyText>
<subsectionHeader confidence="0.584805">
2.2.1 The evaluator
</subsectionHeader>
<bodyText confidence="0.9997883">
The evaluator is a function p(tle, s) which as-
signs to each target-text unit t an estimate of
its probability given a source text s and the to-
kens 9 which precede tin the current translation
of s. Our approach to modeling this distribu-
tion is based to a large extent on that of the
IBM group (Brown et al., 1993), but it differs in
one significant aspect: whereas the IBM model
involves a &amp;quot;noisy channel&amp;quot; decomposition, we
use a linear combination of separate predictions
from a language model p(tIti) and a transla-
tion model p(t1s). Although the noisy channel
technique is powerful, it has the disadvantage
that p(sle ,t) is more expensive to compute than
p(tis) when using IBM-style translation models.
Since speed is crucial for our application, we
chose to forego it in the work described here.
Our linear combination model is fully described
in (Langlais and Foster, 2000) but can be seen
as follows:
</bodyText>
<page confidence="0.908521">
48
</page>
<equation confidence="0.97985325">
p(tie , s) = p(tit&apos;) A(0(t1 , s)) (1)
language
P(tIS) [1 — A(e(e,$))]
translation
</equation>
<bodyText confidence="0.9999925">
where A(0(t&apos;, s)) E [0, 1] are context-
dependent interpolation coefficients. e(t&apos;, s)
stands for any function which maps ti,s into a
set of equivalence classes. Intuitively, A(0 (e, s))
should be high when s is more informative than
t&apos; and low otherwise. For example, the trans-
lation model could have a higher weight at the
start of sentence but the contribution of the lan-
guage model can become more important in the
middle or the end of the sentence.
</bodyText>
<subsubsectionHeader confidence="0.791813">
2.2.2 The language model
</subsubsectionHeader>
<bodyText confidence="0.9999275">
We experimented with various simple linear
combinations of four different French language
models: a cache model, similar to the cache
component in Kuhn&apos;s model (Kuhn and Mori,
1990); a unigram model; a triclass model (Der-
ouault and Merialdo, 1986); and an interpolated
trigram (Jelinek, 1990).
We opted for the trigram, which gave signifi-
cantly better results than the other three mod-
els. The trigram was trained on the Hansard
corpus (about 50 million words), with 75% of
the corpus used for relative-frequency parame-
ter estimates, and 25% used to reestimate inter-
polation coefficients.
</bodyText>
<subsubsectionHeader confidence="0.787177">
2.2.3 The translation model
</subsubsectionHeader>
<bodyText confidence="0.999976333333333">
Our translation model is based on the linear in-
terpolation given in equation 2 which combines
predictions of two translation models — M, and
Mu — both based on an IBM-like model 2 (see
equation 3). M, was trained on single words
and Mu was trained on both words and units.
</bodyText>
<equation confidence="0.9363215">
p(t1s) = 0.133(tIs) + (1 — 13).p(tig(s)) (2)
word unit
</equation>
<bodyText confidence="0.999442846153846">
where p, and Pu stand for the probabilities
given respectively by M, and M. g(s) repre-
sents the new sequence of tokens obtained after
grouping the tokens of s into units.
Both models are based on IBM translation
model 2 (Brown et al., 1993) which has the
property that it generates tokens independently.
The total probability of the ith target-text to-
ken ti is just the average of the probabilities
with which it is generated by each source text
token si; this is a weighted average that takes
the distance from the generating token into ac-
count:
</bodyText>
<equation confidence="0.983761333333333">
p(tils) is&apos; (3)
Ep(tis) a(jii,131)
=o
</equation>
<bodyText confidence="0.9997348125">
where p(tilsi) is a word-for-word translation
probability, Is I is the length (counted in tokens)
of the source segment s under translation, and
a(jii, Isp is the a priori alignment probability
that the target-text token at position i will be
generated by the source text token at position
j; this is equal to a constant value of 1/(181+ 1)
for model 1. This formula follows the conven-
tion of (Brown et al., 1993) in letting so des-
ignate the null state. We modified IBM model
2 to account for invariant entities such as En-
glish forms that almost invariably translate into
French either verbatim or after having under-
gone a predictable transformation e.g. numbers
or dates. These forms are very frequent in the
Hansard corpus.
</bodyText>
<subsectionHeader confidence="0.999478">
2.3 The Generator
</subsectionHeader>
<bodyText confidence="0.999813952380952">
The task of the generator is to identify units
matching the current prefix typed by the user,
and pick the best candidate using the evalua-
tion function. Given the real time constraints
of an IMT system, we divided the French vocab-
ulary into two parts: a small active component
whose contents are always searched for a match
to the current prefix, and a much larger passive
part which comes into play only when no candi-
dates are found in the active vocabulary. Both
vocabularies are coded as tries.
The passive vocabulary is a large dictionary
containing over 380,000 word forms. The ac-
tive part is computed dynamically when a new
sentence is selected by the translator. It relies
on the fact that a small number of words ac-
count for most of the tokens in a text. It is
composed of a few entities (tokens and units)
that are likely to appear in the translation. In
practice, we found that keeping 500 words and
50 units yields good performance.
</bodyText>
<page confidence="0.999543">
49
</page>
<sectionHeader confidence="0.992425" genericHeader="method">
3 Implementation
</sectionHeader>
<bodyText confidence="0.999949421052632">
From an implementation point of view, the core
of TransType relies on a flexible object ori-
ented architecture, which facilitates the integra-
tion of any model that can predict units (words
or sequence of words) from what has been al-
ready typed and the source text being trans-
lated. This part is written in C++. Statisti-
cal translation and language models have been
integrated among others into this architecture
(Lapalme et al., 2000).
The graphical user interface is implemented
in Tcl/Tk, a multi-platform script language well
suited to interfacing problems. It offers all the
classical functions for text edition plus a pop-up
menu which contains the more probable words
or sequences of words that may complete the
ongoing translation. The proposed completions
are updated after each keystroke the translator
enters.
</bodyText>
<sectionHeader confidence="0.992286" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.999970892857143">
We have conducted a theoretical evaluation of
TransType on a word completion task, which
assumes that a translator carefully observes
each completion proposed by the system and
accepts it as soon as it is correct. Under
these optimistic conditions, we have shown that
TransType allows for the production of a trans-
lation typing less than a third of its characters.
In order to better grasp the usefulness of
TRANSTYPE, we also performed a more prac-
tical evaluation by asking ten translators to
use the prototype for about one hour to trans-
late isolated sentences. We first asked them to
translate without any help from TRANSTYPE
and then we compared their typing speed with
TRANSTYPE suggestions turned on. Overall,
translators liked the concept and found it very
useful; they all liked the suggestions although
it seemed to induce a literal style of transla-
tion. We also asked them if they thought that
TRANSTYPE improved their typing speed and
the majority of them said so; unfortunately the
figures showed that none of them did so ... The
typing rates are nevertheless quite good, given
that the users were new to this environment and
this style of looking at suggestions while trans-
lating. But interestingly this practical evalua-
tion confirmed our theoretical evaluation that a-
translation can be produced with TRANSTYPE
by typing less than 40% of the characters of a
translation. Results of this evaluation and com-
parisons with our theoretical figures are further
described in (Foster et al., 2000).
This experiment made us realize that this
concept of real-time suggestions depends very
much on the usability of the prototype; we had
first developed a much simpler editor but its
limitations were such that the translators found
it unusable. So we are convinced that the user-
interface aspects of this prototype should be
thoroughly studied. But the TRANSTYPE ap-
proach would be much more useful if it was
combined with other text editing tasks related
to translation: for example TRANSTYPE could
format the translation in the same way as the
source text, this would be especially useful for
titles and tables; it would also be possible to
localize automatically specific entities such as
dates, numbers and amounts of money. It would
also be possible to check that some translations
given by the user are correct with respect with
some normative usage of words or terminologi-
cal coherence; these facilities are already part of
TRANSCHECK, another computer aided transla-
tion tool prototype developed in our laboratory
(Jutras, 2000).
</bodyText>
<sectionHeader confidence="0.997302" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.9999764">
We have presented an innovative way of em-
bedding machine translation by means of a pro-
totype which implements an appealing interac-
tive machine translation scenario where the in-
teraction is mediated via the target text under
production. Among other advantages, this ap-
proach relieves the translator of the burden of
source analyses, and gives him or her direct con-
trol over the final translation without having to
resort to post-edition.
</bodyText>
<sectionHeader confidence="0.993204" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999846">
TRANSTYPE is a project funded by the Natu-
ral Sciences and Engineering Research Council
of Canada. We are greatly indebted to Elliott
Macklovitch and Pierre Isabelle for the fruitful
orientations they gave to this work.
</bodyText>
<sectionHeader confidence="0.988034" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.518467">
Herve Blanchon. 1991. Problemes de
desambiguIsation interactive et TAO per-
sonnelle. In L&apos;environnement Traductionnel,
</reference>
<page confidence="0.992155">
50
</page>
<bodyText confidence="0.7346052">
Journees scientifiques du Reseau thematique
de recherche &amp;quot;Lexicologie, terminologie,
traduction&amp;quot;, pages 31-48, Mons, April.
Ralf D. Brown and Sergei Nirenburg. 1990.
Human-computer interaction for semantic
</bodyText>
<reference confidence="0.998181666666667">
disambiguation. In Proceedings of the Inter-
national Conference on Computational Lin-
guistics (COLING), pages 42-47, Helsinki,
Finland, August.
Peter F. Brown, Stephen A. Della Pietra, Vin-
cent Della J. Pietra, and Robert L. Mercer.
1993. The mathematics of machine transla-
tion: Parameter estimation. Computational
Linguistics, 19(2):263-312, June.
A.-M. Derouault and B. Merialdo. 1986. Nat-
ural language modeling for phoneme-to-text
transcription. IEEE Transactions on Pattern
Analysis and Machine Intelligence (PA MI),
8(6):742-749, November.
George Foster, Pierre Isabelle, and Pierre Pla-
mondon. 1997. Target-text Mediated Inter-
active Machine Translation. Machine Trans-
lation, 12:175-194.
George Foster, Philippe Langlais, Guy
Lapalme, Dominique Let arte, Elliott
Macklovitch, and Sebastien Sauve. 2000.
Evaluation of transtype, a computer-aided
translation typing system: A comparison of
a theoretical- and a user- oriented evaluation
procedures. In Conference on Language
Resources and Evaluation (LREC), page 8
pages, Athens, Greece, June.
Frederick Jelinek. 1990. Self-organized lan-
guage modeling for speech recognition. In
A. Waibel and K. Lee, editors, Readings in
Speech Recognition, pages 450-506. Morgan
Kaufmann, San Mateo, California.
Jean-Marc Jutras. 2000. An automatic reviser:
The TransCheck system. In Applied Natu-
ral Language Processing 2000, page 10 pages,
Seattle, Washington, May.
Martin Kay. 1973. The MIND system. In
R. Rustin, editor, Natural Language Process-
ing, pages 155-188. Algorithmics Press, New
York.
Roland Kuhn and Renato De Mori. 1990.
A cache-based natural language model for
speech recognition. IEEE Transactions on
Pattern Analysis and Machine Intelligence
(PAMI), 12(6):570-583, June.
Philippe Langlais and George Foster. 2000. Us-
ing context-dependent interpolation to com-
bine statistical language and translation
models for interactive machine translation.
In Computer-Assisted Information Retrieval,
Paris, April.
Philippe Langlais, George Foster, and Guy
Lapalme. 2000. Unit completion for a
computer-aided translation typing system. In
Applied Natural Language Processing 2000,
page 10 pages, Seattle, Washington, May.
Guy Lapalme, George Foster, and Philippe
Langlais. 2000. La programmation orientee-
objet pour le developpement de modeles de
langages. In Christophe Dony and Houari A.
Sahraoui, editors, LM0&apos;00 - Langages et
modeles a objets, pages 139-147, Mont St-
Hilaire, Québec, 27 Janvier. Hermes Science.
Conference invitee.
Hiroshi Maruyama and Hideo Watanabe. 1990.
An interactive Japanese parser for machine
translation. In Proceedings of the Interna-
tional Conference on Computational Linguis-
tics (COLING), pages 257-262, Helsinki, Fin-
land, August.
P. J. Whitelock, M. McGee Wood, B. J. Chan-
dler, N. Holden, and H. J. Horsfall. 1986.
Strategies for interactive machine transla-
tion: the experience and implications of the
UMIST Japanese project. In Proceedings of
the International Conference on Computa-
tional Linguistics (COLING), pages 329-334,
Bonn, West Germany.
</reference>
<page confidence="0.999122">
51
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.240758">
<title confidence="0.999858">TransType: a Computer-Aided Translation Typing System</title>
<author confidence="0.984948">Langlais Foster</author>
<email confidence="0.96175">de</email>
<note confidence="0.3917265">C.P. 6128, succursale H3C 3Y7 Montréal,</note>
<phone confidence="0.937494">1(514) Fax: +1(514)</phone>
<email confidence="0.985324">Ifelipe,foster,lapalmel@iro.umontreal.ca</email>
<abstract confidence="0.9928289">This paper describes the embedding of a statistical translation system within a text editor to produce TRANSTYPE, a system that watches over the user as he or she types a translation and suggests the text already entered. This innovative Embedded Machine Translation system is thus a specialized means of helping produce high quality translations.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Herve Blanchon</author>
</authors>
<title>Problemes de desambiguIsation interactive et TAO personnelle. In L&apos;environnement Traductionnel, disambiguation.</title>
<date>1991</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>42--47</pages>
<location>Helsinki, Finland,</location>
<contexts>
<context position="1137" citStr="Blanchon, 1991" startWordPosition="174" endWordPosition="175">ns for the text already entered. This innovative Embedded Machine Translation system is thus a specialized means of helping produce high quality translations. 1 Introduction TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation (IMT) as a tool for professional or other highly-skilled translators. IMT first appeared as part of Kay&apos;s MIND system (Kay, 1973), where the user&apos;s role was to help the computer analyze the source text by answering questions about word sense, ellipsis, phrasal attachments, etc. Most later work on IMT, eg (Blanchon, 1991; Brown and Nirenburg, 1990; Maruyama and Watanabe, 1990; Whitelock et al., 1986), has followed in this vein, concentrating on improving the question/answer process by having less questions, more friendly ones, etc. Despite progress in these endeavors, systems of this sort are generally unsuitable as tools for skilled translators because the user serves only as an advisor, with the MT components keeping overall control over the translation process. TRANSTYPE originated from the conviction that a better approach to IMT for competent translators would be to shift the focus of interaction from th</context>
</contexts>
<marker>Blanchon, 1991</marker>
<rawString>Herve Blanchon. 1991. Problemes de desambiguIsation interactive et TAO personnelle. In L&apos;environnement Traductionnel, disambiguation. In Proceedings of the International Conference on Computational Linguistics (COLING), pages 42-47, Helsinki, Finland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Stephen A Della Pietra</author>
<author>Vincent Della J Pietra</author>
<author>Robert L Mercer</author>
</authors>
<title>The mathematics of machine translation: Parameter estimation.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<pages>19--2</pages>
<contexts>
<context position="7146" citStr="Brown et al., 1993" startWordPosition="1230" endWordPosition="1233">s the acceptance key typed by the user. A Completion is denoted by a/13 where a is the typed prefix and the completed part. Completions for different prefixes are separated by • . hypotheses and a generator which uses the evaluation function to select the best candidate for completion. 2.2.1 The evaluator The evaluator is a function p(tle, s) which assigns to each target-text unit t an estimate of its probability given a source text s and the tokens 9 which precede tin the current translation of s. Our approach to modeling this distribution is based to a large extent on that of the IBM group (Brown et al., 1993), but it differs in one significant aspect: whereas the IBM model involves a &amp;quot;noisy channel&amp;quot; decomposition, we use a linear combination of separate predictions from a language model p(tIti) and a translation model p(t1s). Although the noisy channel technique is powerful, it has the disadvantage that p(sle ,t) is more expensive to compute than p(tis) when using IBM-style translation models. Since speed is crucial for our application, we chose to forego it in the work described here. Our linear combination model is fully described in (Langlais and Foster, 2000) but can be seen as follows: 48 p(t</context>
<context position="9486" citStr="Brown et al., 1993" startWordPosition="1628" endWordPosition="1631">polation coefficients. 2.2.3 The translation model Our translation model is based on the linear interpolation given in equation 2 which combines predictions of two translation models — M, and Mu — both based on an IBM-like model 2 (see equation 3). M, was trained on single words and Mu was trained on both words and units. p(t1s) = 0.133(tIs) + (1 — 13).p(tig(s)) (2) word unit where p, and Pu stand for the probabilities given respectively by M, and M. g(s) represents the new sequence of tokens obtained after grouping the tokens of s into units. Both models are based on IBM translation model 2 (Brown et al., 1993) which has the property that it generates tokens independently. The total probability of the ith target-text token ti is just the average of the probabilities with which it is generated by each source text token si; this is a weighted average that takes the distance from the generating token into account: p(tils) is&apos; (3) Ep(tis) a(jii,131) =o where p(tilsi) is a word-for-word translation probability, Is I is the length (counted in tokens) of the source segment s under translation, and a(jii, Isp is the a priori alignment probability that the target-text token at position i will be generated by</context>
</contexts>
<marker>Brown, Pietra, Pietra, Mercer, 1993</marker>
<rawString>Peter F. Brown, Stephen A. Della Pietra, Vincent Della J. Pietra, and Robert L. Mercer. 1993. The mathematics of machine translation: Parameter estimation. Computational Linguistics, 19(2):263-312, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A-M Derouault</author>
<author>B Merialdo</author>
</authors>
<title>Natural language modeling for phoneme-to-text transcription.</title>
<date>1986</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence (PA MI),</journal>
<pages>8--6</pages>
<contexts>
<context position="8549" citStr="Derouault and Merialdo, 1986" startWordPosition="1464" endWordPosition="1468"> any function which maps ti,s into a set of equivalence classes. Intuitively, A(0 (e, s)) should be high when s is more informative than t&apos; and low otherwise. For example, the translation model could have a higher weight at the start of sentence but the contribution of the language model can become more important in the middle or the end of the sentence. 2.2.2 The language model We experimented with various simple linear combinations of four different French language models: a cache model, similar to the cache component in Kuhn&apos;s model (Kuhn and Mori, 1990); a unigram model; a triclass model (Derouault and Merialdo, 1986); and an interpolated trigram (Jelinek, 1990). We opted for the trigram, which gave significantly better results than the other three models. The trigram was trained on the Hansard corpus (about 50 million words), with 75% of the corpus used for relative-frequency parameter estimates, and 25% used to reestimate interpolation coefficients. 2.2.3 The translation model Our translation model is based on the linear interpolation given in equation 2 which combines predictions of two translation models — M, and Mu — both based on an IBM-like model 2 (see equation 3). M, was trained on single words an</context>
</contexts>
<marker>Derouault, Merialdo, 1986</marker>
<rawString>A.-M. Derouault and B. Merialdo. 1986. Natural language modeling for phoneme-to-text transcription. IEEE Transactions on Pattern Analysis and Machine Intelligence (PA MI), 8(6):742-749, November.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Foster</author>
<author>Pierre Isabelle</author>
<author>Pierre Plamondon</author>
</authors>
<date>1997</date>
<booktitle>Target-text Mediated Interactive Machine Translation. Machine Translation,</booktitle>
<pages>12--175</pages>
<contexts>
<context position="4410" citStr="Foster et al., 1997" startWordPosition="714" endWordPosition="717">ies , it is possible for all Canadians to register their votes on issues of public spending and public borrowing. r proposal is a symbolical attexnpt to democratize open 0:1whoidiissue of public finance. .•• II me fait plaisir de prendre la parole aujourd&apos;hui dans le cadre de ce debat 00..r Etat Notre p top oztorL iii Figure 1: Example of an interaction in TRANSTYPE with the source text in the top half of the screen. The target text is typed in the bottom half with suggestions given by the menu at the insertion point. then has to be corrected by the translator. The first version of TRANSTYPE (Foster et al., 1997) only proposed completions for the current word. We are now working on predictions which extend to the next several words in the text. The potential gain from multiple-word predictions (Langlais et al., 2000) can be appreciated in the one-sentence translation task reported in table 1, where a hypothetical user saves over 60% of the keystrokes needed to produce a translation in a word completion scenario, and about 75% in a &amp;quot;unit&amp;quot; completion scenario 2.2 System Viewpoint The core of TRANSTYPE is a completion engine which comprises two main parts: an evaluator which assigns probabilistic scores </context>
</contexts>
<marker>Foster, Isabelle, Plamondon, 1997</marker>
<rawString>George Foster, Pierre Isabelle, and Pierre Plamondon. 1997. Target-text Mediated Interactive Machine Translation. Machine Translation, 12:175-194.</rawString>
</citation>
<citation valid="false">
<authors>
<author>George Foster</author>
</authors>
<location>Philippe Langlais, Guy</location>
<marker>Foster, </marker>
<rawString>George Foster, Philippe Langlais, Guy</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dominique Let arte Lapalme</author>
<author>Elliott Macklovitch</author>
<author>Sebastien Sauve</author>
</authors>
<title>Evaluation of transtype, a computer-aided translation typing system: A comparison of</title>
<date>2000</date>
<contexts>
<context position="11972" citStr="Lapalme et al., 2000" startWordPosition="2060" endWordPosition="2063">d of a few entities (tokens and units) that are likely to appear in the translation. In practice, we found that keeping 500 words and 50 units yields good performance. 49 3 Implementation From an implementation point of view, the core of TransType relies on a flexible object oriented architecture, which facilitates the integration of any model that can predict units (words or sequence of words) from what has been already typed and the source text being translated. This part is written in C++. Statistical translation and language models have been integrated among others into this architecture (Lapalme et al., 2000). The graphical user interface is implemented in Tcl/Tk, a multi-platform script language well suited to interfacing problems. It offers all the classical functions for text edition plus a pop-up menu which contains the more probable words or sequences of words that may complete the ongoing translation. The proposed completions are updated after each keystroke the translator enters. 4 Evaluation We have conducted a theoretical evaluation of TransType on a word completion task, which assumes that a translator carefully observes each completion proposed by the system and accepts it as soon as it</context>
</contexts>
<marker>Lapalme, Macklovitch, Sauve, 2000</marker>
<rawString>Lapalme, Dominique Let arte, Elliott Macklovitch, and Sebastien Sauve. 2000. Evaluation of transtype, a computer-aided translation typing system: A comparison of</rawString>
</citation>
<citation valid="true">
<title>a theoretical- and a user- oriented evaluation procedures.</title>
<date></date>
<booktitle>In Conference on Language Resources and Evaluation (LREC),</booktitle>
<volume>8</volume>
<pages>page</pages>
<location>Athens, Greece,</location>
<marker></marker>
<rawString>a theoretical- and a user- oriented evaluation procedures. In Conference on Language Resources and Evaluation (LREC), page 8 pages, Athens, Greece, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Frederick Jelinek</author>
</authors>
<title>Self-organized language modeling for speech recognition.</title>
<date>1990</date>
<booktitle>Readings in Speech Recognition,</booktitle>
<pages>450--506</pages>
<editor>In A. Waibel and K. Lee, editors,</editor>
<publisher>Morgan Kaufmann,</publisher>
<location>San Mateo, California.</location>
<contexts>
<context position="8594" citStr="Jelinek, 1990" startWordPosition="1473" endWordPosition="1474">ses. Intuitively, A(0 (e, s)) should be high when s is more informative than t&apos; and low otherwise. For example, the translation model could have a higher weight at the start of sentence but the contribution of the language model can become more important in the middle or the end of the sentence. 2.2.2 The language model We experimented with various simple linear combinations of four different French language models: a cache model, similar to the cache component in Kuhn&apos;s model (Kuhn and Mori, 1990); a unigram model; a triclass model (Derouault and Merialdo, 1986); and an interpolated trigram (Jelinek, 1990). We opted for the trigram, which gave significantly better results than the other three models. The trigram was trained on the Hansard corpus (about 50 million words), with 75% of the corpus used for relative-frequency parameter estimates, and 25% used to reestimate interpolation coefficients. 2.2.3 The translation model Our translation model is based on the linear interpolation given in equation 2 which combines predictions of two translation models — M, and Mu — both based on an IBM-like model 2 (see equation 3). M, was trained on single words and Mu was trained on both words and units. p(t</context>
</contexts>
<marker>Jelinek, 1990</marker>
<rawString>Frederick Jelinek. 1990. Self-organized language modeling for speech recognition. In A. Waibel and K. Lee, editors, Readings in Speech Recognition, pages 450-506. Morgan Kaufmann, San Mateo, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Marc Jutras</author>
</authors>
<title>An automatic reviser: The TransCheck system.</title>
<date>2000</date>
<booktitle>In Applied Natural Language Processing</booktitle>
<pages>10</pages>
<location>Seattle, Washington,</location>
<contexts>
<context position="14906" citStr="Jutras, 2000" startWordPosition="2536" endWordPosition="2537"> other text editing tasks related to translation: for example TRANSTYPE could format the translation in the same way as the source text, this would be especially useful for titles and tables; it would also be possible to localize automatically specific entities such as dates, numbers and amounts of money. It would also be possible to check that some translations given by the user are correct with respect with some normative usage of words or terminological coherence; these facilities are already part of TRANSCHECK, another computer aided translation tool prototype developed in our laboratory (Jutras, 2000). 5 Conclusion We have presented an innovative way of embedding machine translation by means of a prototype which implements an appealing interactive machine translation scenario where the interaction is mediated via the target text under production. Among other advantages, this approach relieves the translator of the burden of source analyses, and gives him or her direct control over the final translation without having to resort to post-edition. Acknowledgements TRANSTYPE is a project funded by the Natural Sciences and Engineering Research Council of Canada. We are greatly indebted to Elliot</context>
</contexts>
<marker>Jutras, 2000</marker>
<rawString>Jean-Marc Jutras. 2000. An automatic reviser: The TransCheck system. In Applied Natural Language Processing 2000, page 10 pages, Seattle, Washington, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin Kay</author>
</authors>
<title>The MIND system. In</title>
<date>1973</date>
<booktitle>Natural Language Processing,</booktitle>
<pages>155--188</pages>
<editor>R. Rustin, editor,</editor>
<publisher>Algorithmics Press,</publisher>
<location>New York.</location>
<contexts>
<context position="945" citStr="Kay, 1973" startWordPosition="142" endWordPosition="143">edding of a statistical translation system within a text editor to produce TRANSTYPE, a system that watches over the user as he or she types a translation and repeatedly suggests completions for the text already entered. This innovative Embedded Machine Translation system is thus a specialized means of helping produce high quality translations. 1 Introduction TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation (IMT) as a tool for professional or other highly-skilled translators. IMT first appeared as part of Kay&apos;s MIND system (Kay, 1973), where the user&apos;s role was to help the computer analyze the source text by answering questions about word sense, ellipsis, phrasal attachments, etc. Most later work on IMT, eg (Blanchon, 1991; Brown and Nirenburg, 1990; Maruyama and Watanabe, 1990; Whitelock et al., 1986), has followed in this vein, concentrating on improving the question/answer process by having less questions, more friendly ones, etc. Despite progress in these endeavors, systems of this sort are generally unsuitable as tools for skilled translators because the user serves only as an advisor, with the MT components keeping o</context>
</contexts>
<marker>Kay, 1973</marker>
<rawString>Martin Kay. 1973. The MIND system. In R. Rustin, editor, Natural Language Processing, pages 155-188. Algorithmics Press, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roland Kuhn</author>
<author>Renato De Mori</author>
</authors>
<title>A cache-based natural language model for speech recognition.</title>
<date>1990</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI),</journal>
<pages>12--6</pages>
<marker>Kuhn, De Mori, 1990</marker>
<rawString>Roland Kuhn and Renato De Mori. 1990. A cache-based natural language model for speech recognition. IEEE Transactions on Pattern Analysis and Machine Intelligence (PAMI), 12(6):570-583, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Langlais</author>
<author>George Foster</author>
</authors>
<title>Using context-dependent interpolation to combine statistical language and translation models for interactive machine translation. In Computer-Assisted Information Retrieval,</title>
<date>2000</date>
<location>Paris,</location>
<contexts>
<context position="7711" citStr="Langlais and Foster, 2000" startWordPosition="1320" endWordPosition="1323"> a large extent on that of the IBM group (Brown et al., 1993), but it differs in one significant aspect: whereas the IBM model involves a &amp;quot;noisy channel&amp;quot; decomposition, we use a linear combination of separate predictions from a language model p(tIti) and a translation model p(t1s). Although the noisy channel technique is powerful, it has the disadvantage that p(sle ,t) is more expensive to compute than p(tis) when using IBM-style translation models. Since speed is crucial for our application, we chose to forego it in the work described here. Our linear combination model is fully described in (Langlais and Foster, 2000) but can be seen as follows: 48 p(tie , s) = p(tit&apos;) A(0(t1 , s)) (1) language P(tIS) [1 — A(e(e,$))] translation where A(0(t&apos;, s)) E [0, 1] are contextdependent interpolation coefficients. e(t&apos;, s) stands for any function which maps ti,s into a set of equivalence classes. Intuitively, A(0 (e, s)) should be high when s is more informative than t&apos; and low otherwise. For example, the translation model could have a higher weight at the start of sentence but the contribution of the language model can become more important in the middle or the end of the sentence. 2.2.2 The language model We experi</context>
</contexts>
<marker>Langlais, Foster, 2000</marker>
<rawString>Philippe Langlais and George Foster. 2000. Using context-dependent interpolation to combine statistical language and translation models for interactive machine translation. In Computer-Assisted Information Retrieval, Paris, April.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Philippe Langlais</author>
<author>George Foster</author>
<author>Guy Lapalme</author>
</authors>
<title>Unit completion for a computer-aided translation typing system.</title>
<date>2000</date>
<booktitle>In Applied Natural Language Processing 2000,</booktitle>
<volume>10</volume>
<pages>page</pages>
<location>Seattle, Washington,</location>
<contexts>
<context position="4618" citStr="Langlais et al., 2000" startWordPosition="748" endWordPosition="751">• II me fait plaisir de prendre la parole aujourd&apos;hui dans le cadre de ce debat 00..r Etat Notre p top oztorL iii Figure 1: Example of an interaction in TRANSTYPE with the source text in the top half of the screen. The target text is typed in the bottom half with suggestions given by the menu at the insertion point. then has to be corrected by the translator. The first version of TRANSTYPE (Foster et al., 1997) only proposed completions for the current word. We are now working on predictions which extend to the next several words in the text. The potential gain from multiple-word predictions (Langlais et al., 2000) can be appreciated in the one-sentence translation task reported in table 1, where a hypothetical user saves over 60% of the keystrokes needed to produce a translation in a word completion scenario, and about 75% in a &amp;quot;unit&amp;quot; completion scenario 2.2 System Viewpoint The core of TRANSTYPE is a completion engine which comprises two main parts: an evaluator which assigns probabilistic scores to completion 47 This bill is very similar to its companion bill which we dealt with yesterday in the house of commons word-completion task. unit-completion task pref. completions pref. completions ce ce+ /lo</context>
</contexts>
<marker>Langlais, Foster, Lapalme, 2000</marker>
<rawString>Philippe Langlais, George Foster, and Guy Lapalme. 2000. Unit completion for a computer-aided translation typing system. In Applied Natural Language Processing 2000, page 10 pages, Seattle, Washington, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Guy Lapalme</author>
<author>George Foster</author>
<author>Philippe Langlais</author>
</authors>
<title>La programmation orienteeobjet pour le developpement de modeles de langages.</title>
<date>2000</date>
<booktitle>In Christophe Dony and Houari A. Sahraoui, editors, LM0&apos;00 - Langages et modeles a objets,</booktitle>
<pages>139--147</pages>
<location>Mont StHilaire, Québec,</location>
<contexts>
<context position="11972" citStr="Lapalme et al., 2000" startWordPosition="2060" endWordPosition="2063">d of a few entities (tokens and units) that are likely to appear in the translation. In practice, we found that keeping 500 words and 50 units yields good performance. 49 3 Implementation From an implementation point of view, the core of TransType relies on a flexible object oriented architecture, which facilitates the integration of any model that can predict units (words or sequence of words) from what has been already typed and the source text being translated. This part is written in C++. Statistical translation and language models have been integrated among others into this architecture (Lapalme et al., 2000). The graphical user interface is implemented in Tcl/Tk, a multi-platform script language well suited to interfacing problems. It offers all the classical functions for text edition plus a pop-up menu which contains the more probable words or sequences of words that may complete the ongoing translation. The proposed completions are updated after each keystroke the translator enters. 4 Evaluation We have conducted a theoretical evaluation of TransType on a word completion task, which assumes that a translator carefully observes each completion proposed by the system and accepts it as soon as it</context>
</contexts>
<marker>Lapalme, Foster, Langlais, 2000</marker>
<rawString>Guy Lapalme, George Foster, and Philippe Langlais. 2000. La programmation orienteeobjet pour le developpement de modeles de langages. In Christophe Dony and Houari A. Sahraoui, editors, LM0&apos;00 - Langages et modeles a objets, pages 139-147, Mont StHilaire, Québec, 27 Janvier. Hermes Science. Conference invitee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hiroshi Maruyama</author>
<author>Hideo Watanabe</author>
</authors>
<title>An interactive Japanese parser for machine translation.</title>
<date>1990</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>257--262</pages>
<location>Helsinki, Finland,</location>
<contexts>
<context position="1193" citStr="Maruyama and Watanabe, 1990" startWordPosition="180" endWordPosition="183">ative Embedded Machine Translation system is thus a specialized means of helping produce high quality translations. 1 Introduction TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation (IMT) as a tool for professional or other highly-skilled translators. IMT first appeared as part of Kay&apos;s MIND system (Kay, 1973), where the user&apos;s role was to help the computer analyze the source text by answering questions about word sense, ellipsis, phrasal attachments, etc. Most later work on IMT, eg (Blanchon, 1991; Brown and Nirenburg, 1990; Maruyama and Watanabe, 1990; Whitelock et al., 1986), has followed in this vein, concentrating on improving the question/answer process by having less questions, more friendly ones, etc. Despite progress in these endeavors, systems of this sort are generally unsuitable as tools for skilled translators because the user serves only as an advisor, with the MT components keeping overall control over the translation process. TRANSTYPE originated from the conviction that a better approach to IMT for competent translators would be to shift the focus of interaction from the meaning of the source text to the form of the target t</context>
</contexts>
<marker>Maruyama, Watanabe, 1990</marker>
<rawString>Hiroshi Maruyama and Hideo Watanabe. 1990. An interactive Japanese parser for machine translation. In Proceedings of the International Conference on Computational Linguistics (COLING), pages 257-262, Helsinki, Finland, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P J Whitelock</author>
<author>M McGee Wood</author>
<author>B J Chandler</author>
<author>N Holden</author>
<author>H J Horsfall</author>
</authors>
<title>Strategies for interactive machine translation: the experience and implications of the UMIST Japanese project.</title>
<date>1986</date>
<booktitle>In Proceedings of the International Conference on Computational Linguistics (COLING),</booktitle>
<pages>329--334</pages>
<location>Bonn, West</location>
<contexts>
<context position="1218" citStr="Whitelock et al., 1986" startWordPosition="184" endWordPosition="187">ation system is thus a specialized means of helping produce high quality translations. 1 Introduction TRANSTYPE is a project set up to explore an appealing solution to the problem of using Interactive Machine Translation (IMT) as a tool for professional or other highly-skilled translators. IMT first appeared as part of Kay&apos;s MIND system (Kay, 1973), where the user&apos;s role was to help the computer analyze the source text by answering questions about word sense, ellipsis, phrasal attachments, etc. Most later work on IMT, eg (Blanchon, 1991; Brown and Nirenburg, 1990; Maruyama and Watanabe, 1990; Whitelock et al., 1986), has followed in this vein, concentrating on improving the question/answer process by having less questions, more friendly ones, etc. Despite progress in these endeavors, systems of this sort are generally unsuitable as tools for skilled translators because the user serves only as an advisor, with the MT components keeping overall control over the translation process. TRANSTYPE originated from the conviction that a better approach to IMT for competent translators would be to shift the focus of interaction from the meaning of the source text to the form of the target text. This woutd relieve t</context>
</contexts>
<marker>Whitelock, Wood, Chandler, Holden, Horsfall, 1986</marker>
<rawString>P. J. Whitelock, M. McGee Wood, B. J. Chandler, N. Holden, and H. J. Horsfall. 1986. Strategies for interactive machine translation: the experience and implications of the UMIST Japanese project. In Proceedings of the International Conference on Computational Linguistics (COLING), pages 329-334, Bonn, West Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>