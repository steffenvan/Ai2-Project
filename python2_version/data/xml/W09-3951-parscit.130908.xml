<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000007">
<title confidence="0.9760335">
Unsupervised Classification of Dialogue Acts using a Dirichlet Process
Mixture Model
</title>
<author confidence="0.853829">
Nigel Crook, Ramon Granell, and Stephen Pulman
</author>
<affiliation confidence="0.908803">
Oxford University Computing Laboratory
</affiliation>
<address confidence="0.895228">
Wolfson Building
Parks Road, OXFORD, UK
</address>
<email confidence="0.987612333333333">
nigc@comlab.ox.ac.uk
ramg@comlab.ox.ac.uk
sgp@clg.ox.ac.uk
</email>
<sectionHeader confidence="0.994705" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999911095238095">
In recent years Dialogue Acts have be-
come a popular means of modelling the
communicative intentions of human and
machine utterances in many modern di-
alogue systems. Many of these systems
rely heavily on the availability of dialogue
corpora that have been annotated with Di-
alogue Act labels. The manual annota-
tion of dialogue corpora is both tedious
and expensive. Consequently, there is a
growing interest in unsupervised systems
that are capable of automating the annota-
tion process. This paper investigates the
use of a Dirichlet Process Mixture Model
as a means of clustering dialogue utter-
ances in an unsupervised manner. These
clusters can then be analysed in terms of
the possible Dialogue Acts that they might
represent. The results presented here are
from the application of the Dirichlet Pro-
cess Mixture Model to the Dihana corpus.
</bodyText>
<sectionHeader confidence="0.998868" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999476529411765">
Dialogue Acts (DAs) are an important contribu-
tion from discourse theory to the design of di-
alogue systems. These linguistics abstractions
are based on the illocutionary force of speech
acts (Austin, 1962) and try to capture and model
the communicative intention of human or ma-
chine utterances. In recent years, several dia-
logue systems have made use of DAs for mod-
elling discourse phenomena in either the Dialogue
Manager (Keizer et al., 2008), Automatic Speech
Recogniser (Stolcke et al., 2000) or the Auto-
matic Speech Synthesiser (Zovato and Romportl,
2008). Additionally, they have been used also in
other tasks such as summarisation, (Murray et al.,
2006). Therefore, a correct DA classification of di-
alogue turns can bring benefits to the performance
of these modules and tasks.
Many machine learning approaches have been
used to automatically label DAs. They are usu-
ally based on Supervised Learning techniques
involving combinations of Ngrams and Hidden
Markov Models (Stolcke et al., 2000; Martinez-
Hinarejos et al., 2008), Neural Networks (Garfield
and Wermter, 2006) or Graphical Models (Ji and
Bilmes, 2005). Relatively few approaches to DA
classification have been based on unsupervised
learning methods. Some promising results were
reported by Anderach et al (Andernach et al.,
1997; Andernach, 1996) who applied Kohonen
Self Organising Maps (SOMs) to the problem of
DA classification. Although the SOM is nonpara-
metric in the sense that it doesn’t require that the
number of clusters to be found in the data be a pa-
rameter of the SOM that is specified before clus-
tering begins, it’s capacity to detect clusters is lim-
ited to the size of the two-dimensional lattice onto
which the clusters are projected, and the size of
this lattice is determined prior to clustering. This
paper investigates the use of an unsupervised, non-
parametric Bayesian approach to automatic DA
labelling: namely the Dirichlet Process Mixture
Model (DPMM). Specifically, the paper reports re-
sults from applying the Chinese Restaurant Pro-
cess (CRP), a popular approach to DPMMs, to
the automatic labelling of DAs in the Dihana cor-
pus. The Dihana corpus (J.M.Benediet al., 2006)
has previously been used for the same task but
with a supervised learning approach (Martinez-
Hinarejos et al., 2008). The results reported here
indicate that, treating each utterance as a bag of
words, the CRP is capable of automatically clus-
</bodyText>
<subsubsectionHeader confidence="0.64247">
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 341–348,
</subsubsectionHeader>
<affiliation confidence="0.938324">
Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics
</affiliation>
<page confidence="0.99959">
341
</page>
<bodyText confidence="0.925832">
tering most utterances according to speaker, level
</bodyText>
<listItem confidence="0.6396865">
1 and in some cases level 2 DA annotations (see
below).
</listItem>
<sectionHeader confidence="0.905581" genericHeader="method">
2 The Dihana corpus
</sectionHeader>
<bodyText confidence="0.999780368421053">
The Dihana corpus consists of human-computer
spoken dialogues in Spanish about queuing infor-
mation of train fares and timetables. The acquisi-
tion was performed using the Wizard of Oz (WoZ)
technique, where a human simulates the system
following a prefixed strategy. User and system
utterances are different in nature, user utterances
are completely spontaneous speech whereas sys-
tem utterances are based on pre-written patterns
that the WoZ selected according to what the user
said in the previous turn, the current dialogue state
and the WoZ strategy. There is a total of 900 dia-
logues with a vocabulary of 823 words. However,
after applying a process of name entity recognition
(cities, times, number, ...) and making the distinc-
tion between system and user words there are 964
different words. The same process of name en-
tity recognition was also used by Martinez Hinare-
jos (Martinez-Hinarejos et al., 2008)
</bodyText>
<subsectionHeader confidence="0.999053">
2.1 Annotation scheme
</subsectionHeader>
<bodyText confidence="0.99996695">
Dialogues were manually annotated using a dia-
logue act annotation scheme based on three lev-
els (see Table 1). The first level corresponds to
the general intention of the speaker (speech act),
the second level represents the implicit informa-
tion that is referred to in the first level and the third
level is the specific data provided in the utterance.
Using these three levels and making the distinc-
tion between user and system labels, there are 248
different labels (153 for the user and 95 for the sys-
tem). Combining only first and second level there
are 72 labels (45 for user and 27 for system), and
with only first level there are 16 labels (7 for user
and 9 for system).
Annotation was done at utterance level. That
is, each dialogue turn was divided (segmented)
into utterances such that each one corresponds to a
unique DA label. An example of the segmentation
and annotation of two turns of a dialogue can be
seen in Figure 1
</bodyText>
<sectionHeader confidence="0.999734" genericHeader="method">
3 Dirichlet Process Mixture Models
</sectionHeader>
<bodyText confidence="0.983901666666667">
This paper present a Dirichlet Process Mixture
Model (DPMM) (Maceachern and M¨uller, 1998;
Escobar and West, 1995; Antoniak, 1974) for the
</bodyText>
<table confidence="0.998653833333333">
Level Labels
First Opening, Closing, Confirmation,
Undefined, Not-understood, Waiting,
Consult, Acceptance, Rejection
Second Departure-hour, Arrival-hour,
Fare, Origin, Destination, Day,
Train-Type, Service, Class, Trip-time
Third Departure-hour, Arrival-hour,
Fare, Origin, Destination, Day,
Train-Type, Service, Class,
Trip-time, Order-number,
Number-trains, Trip-type
</table>
<tableCaption confidence="0.959412">
Table 1: Set of dialogue act labels used in the Di-
hana corpus
</tableCaption>
<bodyText confidence="0.998630909090909">
automatic, unsupervised clustering of the utter-
ances in the Dihana corpus. This approach treats
each utterance as a bag ofwords (i.e. an unordered
collection of words) (Sebastiani, 2002). Utter-
ances are clustered according to the relative counts
of word occurrences that they contain so that utter-
ances with similar histograms of word counts will,
in general, appear in the same cluster.
Bayesian methods for unsupervised data clus-
tering divide into parametric and nonparametric
approaches. Parametric approaches to clustering
such as Finite Bayesian Mixture Models (Mclach-
lan and Peel, 2000) require prior estimation of the
number of clusters that are expected to be found
in the data. However, it is not always possible to
know this in advance and often it is necessary to
repeat a modelling experiment many times over a
range of choices of cluster numbers to find an op-
timal number of clusters. Sub-optimal choices for
the number of clusters can lead to a degradation
in the generalisation performance of the model.
Nonparametric approaches to mixture modelling,
on the other hand, do not require prior estimates
of the number of clusters in the data; this is dis-
covered automatically as the model clusters the
data. Dirichlet Processes offer one approach to de-
veloping Bayesian nonparametric mixture models.
The remainder of this section briefly introduces
DPMMs, beginning with a brief look at finite
Bayesian mixture models which will serve as use-
ful background for presenting the Chinese Restau-
rant Process, the Dirichlet Process paradigm used
in this paper.
</bodyText>
<page confidence="0.993709">
342
</page>
<table confidence="0.998518625">
Speaker Utterance Transcription
Level 1 Level 2 Level 3
S S1 Welcome to the railway information system. How may I help you?
Opening Nil Nil
U U1 Could you tell me the departure times from Valencia
Question Departure-hour Origin
U2 to Madrid.
Question Departure-hour Destination
</table>
<figureCaption confidence="0.992890333333333">
Figure 1: An example of some turns from an annotated dialogue of DIHANA corpus.
Figure 2: A 3-simplex with two examples points
and the corresponding distributions
</figureCaption>
<subsectionHeader confidence="0.998299">
3.1 Finite Bayesian Mixture Models
</subsectionHeader>
<bodyText confidence="0.999961666666667">
A Dirichlet distribution is defined as a measure
on measures. Specifically, a Dirichlet distribution
defines a probability measure over the k-simplex.
The k-simplex is a convex hull constructed so that
each point on the surface of the simplex describes
a probability distribution over k outcomes:
</bodyText>
<equation confidence="0.99869725">
Qk = {(x1, ... , xk) : xi ≥ 0
k
∀i ∈ {1... k}, xi = 1}
i=1
</equation>
<bodyText confidence="0.996609">
Figure 2 shows a 3-simplex with two example
points and the corresponding distributions. The
Dirichlet distribution places a probability measure
over the k-simplex so that certain subsets of points
on the simplex (i.e. certain distributions) have
higher probabilities than others (Figure 3). The
probability measure in the Dirichlet is parame-
terised by a set of positive, non-zero concentra-
tion constants α = {α1,... αk : αi &gt; 0}, written
Dirichletk(α1, ... αk). The effects of different
values of α for the 3-simplex are shown in Figure
3.
The probability density function of the Dirichlet
Figure 3: Three example Dirichlet Distributions
over the 3-simplex with darker regions showing
areas of high probability: (a) Dirichlet(5,5,5), (b)
Dirichlet(0.2, 5, 0.2), (c) Dirichlet(0.5,0.5,0.5).
</bodyText>
<page confidence="0.962925">
343
</page>
<bodyText confidence="0.4545585">
distribution is given by:
Dirichletk(α1, ... , αk) = f(x1,... , xk; α1, ... , αk)
</bodyText>
<equation confidence="0.980257">
r(Eki=1 αi)
IIki=1 r(αi)
</equation>
<bodyText confidence="0.999905166666667">
where r(x) (= f0∞ t(x−1)e−tdt) extends the fac-
torial function to the real numbers. Since a
draw from a Dirichlet distribution (written Q ∼
Dirichletk(α)) gives a distribution, a Dirichlet
can be used as the prior for a Bayesian finite mix-
ture model:
</bodyText>
<equation confidence="0.946325">
Q ∼ Dirichletk(α1, ... , αk)
</equation>
<bodyText confidence="0.99956">
Q is a distribution over the k components of
the finite mixture model. Each component Ozi is
drawn from a base measure G0 (Ozi ∼ G0). The
choice of distribution G0 depends on the nature
of the data to be clustered; with data that is rep-
resented using the bag of words model, G0 must
generate distributions over the word vocabulary.
Hence the Dirichlet distribution is an appropriate
choice in this case:
</bodyText>
<equation confidence="0.743417">
Ozi ∼ Dirichletv(α1, ... , αv)
</equation>
<bodyText confidence="0.978537590909091">
where v is the size of the vocabulary.
For each data point (utterance) xi a component
Ozi is selected by a draw zi from the multinomial
distribution Q:
zi ∼ Multinomialk(Q)
A suitable distribution F (Ozi) is then used to draw
the data point (utterance). In the bag of words
model, the multinomial distribution is used to
draw the words for each data point xi:
xi ∼ Multinomialv(Ozi)
A small example will illustrate this generative
process. Imagine that there are just two types
of utterances with a vocabulary consisting sim-
ply of the words A, B and C. A finite Bayesian
mixture model in this case would first draw Q
from a suitable Dirichlet distribution (e.g. Q ∼
Dirichlet2(0.5,1)) as, for example, is shown in
Figure 4(a). Next the two components Oz1 and
Oz2 would be drawn from a suitable base distribu-
tion G0 (e.g. Oz1 ∼ Dirichlet3(1, 0.5, 0.5) and
Oz2 ∼ Dirichlet3(0.5, 0.5, 1), see Figure 4(b)
and 4(c)). In this case, Oz1 will tend to generate
</bodyText>
<figureCaption confidence="0.956086">
Figure 4: An example finite Bayesian mixture
model. (a) The prior distribution over components
Oz1 (b) and Oz2 (c)
</figureCaption>
<bodyText confidence="0.988046214285714">
utterances containing more occurrences of word
A than B or C, whilst Oz2 will tend to gener-
ate utterances with more C’s than A’s or B’s. A
component zi is then selected for each utterance
(zi ∼ Multinomialk(Q)). Note that in this ex-
ample, the distribution Q would lead to more utter-
ances generated by Oz2 than by Oz1. Suppose that
five utterances are to be generated by this model
and that the components for each utterance are
z1 = 1, z2 = 2, z3 = 2, z4 = 1 and z5 = 2.
The words in each utterance are then generated
by repeated draws from the corresponding com-
ponent (e.g. x1 = ACAAB, x2 = ACCBCC,
x3 = CCC, x4 = CABAAC and x5 = ACC).
</bodyText>
<subsectionHeader confidence="0.98683">
3.2 Dirichlet Processes
</subsectionHeader>
<bodyText confidence="0.999931294117647">
A Dirichlet Process can be thought of as an exten-
sion of a Dirichlet distribution where the dimen-
sions of the distribution are infinite. The prob-
lem with the infinite dimension Dirichlet distri-
bution, though, is that its probability mass would
be distributed across the whole of the distribution.
However, in most practical applications of mixture
modelling there will be a finite number of clusters.
The solution is to have a process which will tend
to place most of the probability mass at the be-
ginning of the infinite distribution, thereby mak-
ing it possible to assign probabilities to clusters
without restricting the number of clusters avail-
able. The GEM stick breaking construction (the
name comes from the first letters of Griffiths, En-
gen and McCloskey (Pitman, 2002)) achieves pre-
cisely this (Pitman and Yor, 1997). Starting with
</bodyText>
<equation confidence="0.985303">
k
i=1
xai−1
i
</equation>
<page confidence="0.987202">
344
</page>
<bodyText confidence="0.936295">
a stick of unit length, random portions β′k are re-
peatedly broken off the stick, with each part that
is broken off representing the proportion of prob-
ability assigned to a component:
β′k N Beta(1, α) βk = k−1i+1 (1 − β′i) &apos; β′k
The Dirichlet Process mixture model can now
be specified as:
β N GEM(α) φzi N G0 zi E (1... oc)
zi N Multinomial(β) xi N F(φzi)
</bodyText>
<subsectionHeader confidence="0.998658">
3.3 Chinese Restaurant Process
</subsectionHeader>
<bodyText confidence="0.9995696">
The Chinese Restaurant Process (CRP) is a popu-
lar Dirichlet Process paradigm that has been suc-
cessfully applied to many clustering problems. In
the CRP, one is asked to imagine a Chinese restau-
rant with an infinite number of tables. The cus-
tomers enter the restaurant and select, according to
a given distribution, a table at which to sit. All the
customers on the same table share the same dish.
In this paradigm, the tables represent data clusters,
the customers represent data points (xi) and the
dishes represent components (φz). As each cus-
tomer (data point) enters the restaurant the choice
of which table (cluster) and therefore which dish
(component) is determined by a draw from the fol-
lowing distribution:
</bodyText>
<equation confidence="0.995439">
�1 i − 1
(α + i − 1) �δφj + αG0
j=1
</equation>
<bodyText confidence="0.9808248">
where α is the concentration parameter for the
CRP. The summation over the δφj’s counts the
number of customers sat at each of the occupied
tables. The probability of sitting at an already oc-
cupied table, therefore, is proportional to the num-
ber of customers already sat at the table, whilst the
probability of starting a new table is proportional
to αG0. Figure 5 illustrates four iterations of this
initial clustering process.
Once all the customers (data points) have been
placed at tables (clusters), the inference process
begins. The posterior p(,3, 0, z|x) cannot be cal-
culated exactly, but Gibbs sampling can be used.
Gibbs sampling for the CRP involves iteratively
removing a randomly selected customer from their
table, calculating the posterior probability distri-
bution across all the occupied tables together with
a potential new table (with a randomly drawn dish,
Figure 5: The first four steps of the initial cluster-
ing process of the CRP. The probability distribu-
tion over the tables is also shown in each case.
i.e. component), and making a draw from that dis-
tribution to determine the new table for that cus-
tomer. The posterior distribution across the tables
is calculated as follows:
</bodyText>
<equation confidence="0.777494">
φi|φ1,...,φi−1,x
�
δφjp(xi|φj) + αG0p(xi|φi) �
</equation>
<bodyText confidence="0.93924625">
where B = αp(xk) + �i−1
j=1 p(xi|φi) is the nor-
malising constant. After a predetermined number
of samples, the dish (component) of each occupied
table is updated to further resemble the customers
(data points) sitting around it. In the bag of words
approach used here, this involves converting the
histogram of word counts in each customer (utter-
ance) sitting at the table into an empirical distribu-
tion x(xi), taking the average of these empirical
distributions and modifying the dish (component)
to further resemble this distribution:
φi = φi+ µ
mi
where µ (0 &lt; µ &lt; 1) is the learning con-
stant and mi is the number of customers around
</bodyText>
<figure confidence="0.8607603">
�
�
N
1
B
�i − 1
j=1
�mi
j=1
x(xj)
</figure>
<page confidence="0.996858">
345
</page>
<bodyText confidence="0.892081428571429">
table i. The inference process continues to it-
erate between Gibbs sampling and updating the
table dishes (components) until the process con-
verges. Convergence can be estimated by observ-
ing n consecutive samples in which the customer
was returned to the same table they were taken
from.
</bodyText>
<sectionHeader confidence="0.999647" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.998473785714286">
The CRP with Gibbs sampling was used to clus-
ter both user and system utterances from the 900
dialogues in the Dihana corpus. Each utterance is
treated as an independent bag of words where all
information about the dialogue that it came from
and the context in which it was uttered is ignored
during training. Intra-cluster and inter-cluster sim-
ilarity measures were used to evaluate the resulting
clusters. Intra-cluster similarity S′i is calculated
by averaging the Euclidean distance between ev-
ery pair of data points in the cluster i:
Inter-cluster similarity S′′ is calculated by sum-
ming the Euclidean distance between the centroids
of all pairs of clusters:
</bodyText>
<equation confidence="0.876603666666667">
n
S′′ = |Ci − Cj|
i=1;j=1
</equation>
<bodyText confidence="0.966064">
where Ci is the centroid of cluster i and n is the
number of clusters.
Two classification error measures were also
used, one from the cluster (table) perspective E′,
and the other from the perspective of the Dialogue
Act (DA) annotations (first level) of the Dihana
corpus E′′. The cluster classification error of ta-
ble i is calculated by summing up the occurrences
of each DA on the table, finding the DA with the
largest total and allocating that DA as the correct
classification for that table Di. The number of
false positives fpi for that table is the count of all
customers (utterances) with DA annotations not in
Di. The number of false negatives fin is the count
of utterances with label Di that occur on other ta-
bles. The cluster classification error for table i is
therefore:
</bodyText>
<equation confidence="0.528841">
1
E′ i = (fpi + fin)
</equation>
<bodyText confidence="0.526633333333333">
n
The DA classification error E′′ imeasures how
well DA i has been clustered, using the size of the
</bodyText>
<table confidence="0.999531875">
Cluster Ans Ask Clo Not Rej Und
No.
1 1 5
4 2 91 2
9 2 1 9
12 7 161 1 1
13 273 26 8
14 382 12 1 5
15 6 1 909 1 327 22
17 47 39 1 1
18 73 1 3
19 1 4
20 131 115 1 3 1
22 270 29 3 3
23 135 8 2 2
25 83 31 1 4
28 247 16 1 4
29 349 6 1 12
33 13 3 5 1 4 25
41 202 45 1 2 3
46 4 1
49 6 251 1 2 4
51 124 896 1 12
53 45 477 10
</table>
<tableCaption confidence="0.985908">
Table 2: Clusters of user utterances, with the
</tableCaption>
<bodyText confidence="0.860327875">
counts for each level 1 speech act. The largest
cluster for each speech act is in bold. The abbrevi-
ations are: Und = Undefined, Ans = Answering,
Ask = Asking, Clo = Closing, Rej = Rejection,
Not = Not-understood.
DA class Nci , the size of the largest cluster of utter-
ances from that DA class Mci , and the total number
of utterances n in the corpus:
</bodyText>
<equation confidence="0.51081">
1
E′′
i = (Nc i − Mc i )
n
</equation>
<bodyText confidence="0.9994545">
Table 6 summarises the results from three sep-
arate runs of the CRP, each increasing in number
of epochs. It should be noted here that the Dihana
corpus has 72 DA categories, so the ideal number
of clusters discovered by the CRP would be 72. It
should also be noted that given an initial random
clustering, a good clustering algorithm will reduce
intra-cluster similarity (¯S′), increase inter-cluster
similarity (S′′) and reduce the classification errors
(¯E′ and ¯E′′).
</bodyText>
<equation confidence="0.88529925">
1
1: S′ i = |xi − xj|
2mi i=1;j=1
mi
</equation>
<page confidence="0.961783">
346
</page>
<table confidence="0.6017445">
Epochs (K) No. Clusters �S′ S′′ �E′ �E′′
0 70 99703.6 243.74 0.05303 0.00979
1000 44 14975.4 217.56 0.01711 0.00385
1500 54 10093.7 336.15 0.01751 0.00435
</table>
<figureCaption confidence="0.833704666666667">
Figure 6: The results from three separate runs of the CRP on utterances from the Dihana corpus. Cluster
similarity measures and classification error values are shown after 0 (i.e. random clustering), 1000K, and
1500K epochs. �S′, �E′ and &amp; are averaged values.
</figureCaption>
<table confidence="0.9964144">
Level 1 Level 2 Cluster
No.
Answering Day 14
Destination 22
Fare 29
Departure-hour 28, 41
Asking Departure-hour,Fare 4
Train-type 12
Fare 49
Departure-hour 51, 53
</table>
<tableCaption confidence="0.940999">
Table 3: Clusters that have specialised on level 1
and level 2 annotations.
</tableCaption>
<sectionHeader confidence="0.999586" genericHeader="conclusions">
5 Discussion
</sectionHeader>
<bodyText confidence="0.999957793650794">
The first row of the table in Figure 6 shows the
cluster similarity measures and classification er-
rors after 0 epochs of the inference procedure (i.e.
for a random clustering of utterances). This gives a
baseline for the measures and error values used in
subsequent runs. The second row of values shows
the results after a run of 1000K epochs of the in-
ference procedure. This run finds only 44 clusters
but has a much lower value for �S′ than was found
in the random clustering, showing a significant in-
crease in the similarity between utterances within
each cluster. Surprisingly, the value for S′′ is also
reduced, showing that the differentiation between
the clusters formed at this stage is even lower than
there was with the random clustering. E′ and E′′
show suitable reductions indicating that the classi-
fication errors are being reduced by the inference
process. The third row of values show that after
1500K epochs 54 clusters have been found, intra-
cluster similarity is increased beyond that for the
random clustering, but the classification errors re-
main essentially the same as for the 1500K run.
Although the 1500K epoch run found only 54
clusters, it was able to clearly distinguish between
system and user utterances: with 30 clusters con-
taining system utterances only, 22 clusters con-
taining user utterances only and 2 clusters contain-
ing instances of both. Given that the system utter-
ances in the Dihana corpus are generated from a
restricted set of sentences, it is not surprising that
these were easy to cluster and differentiate from
user utterances. However, the CRP was also able
to cluster user utterances well, which is more of
a challenge. Table 2 shows the clusters that have
specialised on user utterances, with the counts of
the level 1 annotations in each case. The largest
cluster for each level 1 annotation is shown in bold
typeface. From here it can be seen that cluster 15
has specialised on both Closing and Rejection. It is
not surprising that these fall within the same clus-
ter since the words used in each are often the same
(e.g. “No thank you” can act as either a closing
statement or a rejection statement). Clusters 14,
22, 29, 28 and 41 have specialised to the Answer-
ing annotation, whilst clusters 4, 12 49, 51 and 53
have specialised to Asking. Table 3 shows how
each of these clusters have specialised to level 2
annotations. Cluster 14, for example, specialises
on the Answering:Day pair, whilst 22 specialises
on Answering:Destination pair.
These initial results show that, at least for the
Dihana corpus, the DPMM can successfully clus-
ter utterances into Speaker, Level 1, and Level2
classes. Whilst this looks promising, it must be
acknowledged that the Dihana corpus is restricted
to train service inquiries and it remains unclear
whether this approach will generalise to other di-
alogue corpora with a broader range of topics and
wider vocabularies. Future work will include in-
vestigating the use of ngrams of words, syntactic
features, the DAs of previous utterances and ex-
perimentation with other corpora such as Switch-
board (Godfrey et al., 1992).
</bodyText>
<sectionHeader confidence="0.999252" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999741">
This work was funded by the Companions project
(www.companions-project.org) sponsored by the
</bodyText>
<page confidence="0.994721">
347
</page>
<bodyText confidence="0.997811333333333">
European Commission as part of the Information
Society Technologies (IST) programme under EC
grant number IST-FP6-034434. We thank Jeff
Bilmes (University of Washington) for many very
helpful discussions about Dirichlet processes and
their application.
</bodyText>
<sectionHeader confidence="0.999367" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999913038461539">
Toine Andernach, Mannes Poel, and Etto Salomons.
1997. Finding classes of dialogue utterances with
kohonen networks. In In Daelemans, pages 85–94.
J.A. Andernach. 1996. A machine learning approach
to the classification and prediction of dialogue utter-
ances. In Proceedings of the 2nd International Con-
ference on New Methods in Language Processing,
pages 98–109.
Charles E. Antoniak. 1974. Mixtures of dirichlet pro-
cesses with applications to bayesian nonparametric
problems. The Annals of Statistics, 2(6):1152–1174.
J.L. Austin. 1962. How to do things with words. Ox-
ford: Clarendon Press.
Michael D. Escobar and Mike West. 1995. Bayesian
density estimation and inference using mixtures.
Journal of the American Statistical Association,
90(430):577–588.
Sheila Garfield and Stefan Wermter. 2006. Call clas-
sification using recurrent neural networks, support
vector machines and finite state automata. Knowl.
Inf. Syst., 9(2):131–156.
J. J. Godfrey, E. C. Holliman, and J. Mcdaniel. 1992.
SWITCHBOARD: telephone speech corpus for re-
search and development. In Proc. ICASSP, vol-
ume 1, pages 517–520 vol.1.
Gang Ji and J. Bilmes. 2005. Dialog act tagging using
graphical models. In Acoustics, Speech, and Signal
Processing, 2005. Proceedings. (ICASSP ’05). IEEE
International Conference on, volume 1, pages 33–
36.
J.M.Benedi, E.Lleida, A. Varona, M.J.Castro,
I.Galiano, R.Justo, I. L´opez, and A. Miguel. 2006.
Design and acquisition of a telephone spontaneous
speech dialogue corpus in spanish: Dihana. In Fifth
International Conference on Language Resources
and Evaluation (LREC), pages 1636–1639, Genova,
Italy, May.
S. Keizer, M. Gasic, F. Mairesse, B. Thomson, K. Yu,
and S. Young. 2008. Modelling user behaviour
in the his-pomdp dialogue manager. In IEEE SLT,
pages 121–124, Dec.
Steven N. Maceachern and Peter M¨uller. 1998. Esti-
mating mixture of dirichlet process models. Jour-
nal of Computational and Graphical Statistics,
7(2):223–238.
C. D. Martinez-Hinarejos, J. M. Benedi, and
R. Granell. 2008. Statistical framework for a span-
ish spoken dialogue corpus. Speech Communica-
tion, 50:992–1008.
Geoffrey Mclachlan and David Peel. 2000. Finite Mix-
ture Models. Wiley Series in Probability and Statis-
tics. Wiley-Interscience, October.
Gabriel Murray, Steve Renals, Jean Carletta, and Jo-
hanna Moore. 2006. Incorporating speaker and
discourse features into speech summarization. In
Proceedings of the main conference on Human Lan-
guage Technology Conference of the North Amer-
ican Chapter of the Association of Computational
Linguistics, pages 367–374, Morristown, NJ, USA.
Association for Computational Linguistics.
J. Pitman and M. Yor. 1997. The two-parameter
Poisson-Dirichlet distribution derived from a stable
subordinator. Annals ofProbability, 25(2):855–900.
J. Pitman. 2002. Combinatorial stochastic processes.
Fabrizio Sebastiani. 2002. Machine learning in au-
tomated text categorization. ACM Comput. Surv.,
34(1):1–47, March.
Andreas Stolcke, Noah Coccaro, Rebecca Bates, Paul
Taylor, Carol Van Ess-Dykema, Klaus Ries, Eliza-
beth Shriberg, Daniel Jurafsky, Rachel Martin, and
Marie Meteer. 2000. Dialogue act modeling for
automatic tagging and recognition of conversational
speech. Comput. Linguist., 26(3):339–373.
E. Zovato and J. Romportl. 2008. Speech synthesis
and emotions: a compromise between flexibility and
believability. In Proceedings ofFourth International
Workshop on Human-Computer Conversation, Bel-
lagio, Italy.
</reference>
<page confidence="0.998061">
348
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.272098">
<title confidence="0.930464">Unsupervised Classification of Dialogue Acts using a Dirichlet Mixture Model</title>
<author confidence="0.897008">Nigel Crook</author>
<author confidence="0.897008">Ramon Granell</author>
<author confidence="0.897008">Stephen</author>
<affiliation confidence="0.998724">Oxford University Computing</affiliation>
<title confidence="0.393441">Wolfson</title>
<author confidence="0.475631">Parks Road</author>
<author confidence="0.475631">OXFORD</author>
<email confidence="0.999283">sgp@clg.ox.ac.uk</email>
<abstract confidence="0.993517272727273">In recent years Dialogue Acts have become a popular means of modelling the communicative intentions of human and machine utterances in many modern dialogue systems. Many of these systems rely heavily on the availability of dialogue corpora that have been annotated with Dialogue Act labels. The manual annotation of dialogue corpora is both tedious and expensive. Consequently, there is a growing interest in unsupervised systems that are capable of automating the annotation process. This paper investigates the use of a Dirichlet Process Mixture Model as a means of clustering dialogue utterances in an unsupervised manner. These clusters can then be analysed in terms of the possible Dialogue Acts that they might represent. The results presented here are from the application of the Dirichlet Process Mixture Model to the Dihana corpus.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Toine Andernach</author>
<author>Mannes Poel</author>
<author>Etto Salomons</author>
</authors>
<title>Finding classes of dialogue utterances with kohonen networks.</title>
<date>1997</date>
<booktitle>In In Daelemans,</booktitle>
<pages>85--94</pages>
<contexts>
<context position="2429" citStr="Andernach et al., 1997" startWordPosition="369" endWordPosition="372">a correct DA classification of dialogue turns can bring benefits to the performance of these modules and tasks. Many machine learning approaches have been used to automatically label DAs. They are usually based on Supervised Learning techniques involving combinations of Ngrams and Hidden Markov Models (Stolcke et al., 2000; MartinezHinarejos et al., 2008), Neural Networks (Garfield and Wermter, 2006) or Graphical Models (Ji and Bilmes, 2005). Relatively few approaches to DA classification have been based on unsupervised learning methods. Some promising results were reported by Anderach et al (Andernach et al., 1997; Andernach, 1996) who applied Kohonen Self Organising Maps (SOMs) to the problem of DA classification. Although the SOM is nonparametric in the sense that it doesn’t require that the number of clusters to be found in the data be a parameter of the SOM that is specified before clustering begins, it’s capacity to detect clusters is limited to the size of the two-dimensional lattice onto which the clusters are projected, and the size of this lattice is determined prior to clustering. This paper investigates the use of an unsupervised, nonparametric Bayesian approach to automatic DA labelling: na</context>
</contexts>
<marker>Andernach, Poel, Salomons, 1997</marker>
<rawString>Toine Andernach, Mannes Poel, and Etto Salomons. 1997. Finding classes of dialogue utterances with kohonen networks. In In Daelemans, pages 85–94.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J A Andernach</author>
</authors>
<title>A machine learning approach to the classification and prediction of dialogue utterances.</title>
<date>1996</date>
<booktitle>In Proceedings of the 2nd International Conference on New Methods in Language Processing,</booktitle>
<pages>98--109</pages>
<contexts>
<context position="2447" citStr="Andernach, 1996" startWordPosition="373" endWordPosition="374">ion of dialogue turns can bring benefits to the performance of these modules and tasks. Many machine learning approaches have been used to automatically label DAs. They are usually based on Supervised Learning techniques involving combinations of Ngrams and Hidden Markov Models (Stolcke et al., 2000; MartinezHinarejos et al., 2008), Neural Networks (Garfield and Wermter, 2006) or Graphical Models (Ji and Bilmes, 2005). Relatively few approaches to DA classification have been based on unsupervised learning methods. Some promising results were reported by Anderach et al (Andernach et al., 1997; Andernach, 1996) who applied Kohonen Self Organising Maps (SOMs) to the problem of DA classification. Although the SOM is nonparametric in the sense that it doesn’t require that the number of clusters to be found in the data be a parameter of the SOM that is specified before clustering begins, it’s capacity to detect clusters is limited to the size of the two-dimensional lattice onto which the clusters are projected, and the size of this lattice is determined prior to clustering. This paper investigates the use of an unsupervised, nonparametric Bayesian approach to automatic DA labelling: namely the Dirichlet</context>
</contexts>
<marker>Andernach, 1996</marker>
<rawString>J.A. Andernach. 1996. A machine learning approach to the classification and prediction of dialogue utterances. In Proceedings of the 2nd International Conference on New Methods in Language Processing, pages 98–109.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles E Antoniak</author>
</authors>
<title>Mixtures of dirichlet processes with applications to bayesian nonparametric problems.</title>
<date>1974</date>
<journal>The Annals of Statistics,</journal>
<volume>2</volume>
<issue>6</issue>
<contexts>
<context position="5926" citStr="Antoniak, 1974" startWordPosition="950" endWordPosition="951">and 95 for the system). Combining only first and second level there are 72 labels (45 for user and 27 for system), and with only first level there are 16 labels (7 for user and 9 for system). Annotation was done at utterance level. That is, each dialogue turn was divided (segmented) into utterances such that each one corresponds to a unique DA label. An example of the segmentation and annotation of two turns of a dialogue can be seen in Figure 1 3 Dirichlet Process Mixture Models This paper present a Dirichlet Process Mixture Model (DPMM) (Maceachern and M¨uller, 1998; Escobar and West, 1995; Antoniak, 1974) for the Level Labels First Opening, Closing, Confirmation, Undefined, Not-understood, Waiting, Consult, Acceptance, Rejection Second Departure-hour, Arrival-hour, Fare, Origin, Destination, Day, Train-Type, Service, Class, Trip-time Third Departure-hour, Arrival-hour, Fare, Origin, Destination, Day, Train-Type, Service, Class, Trip-time, Order-number, Number-trains, Trip-type Table 1: Set of dialogue act labels used in the Dihana corpus automatic, unsupervised clustering of the utterances in the Dihana corpus. This approach treats each utterance as a bag ofwords (i.e. an unordered collection </context>
</contexts>
<marker>Antoniak, 1974</marker>
<rawString>Charles E. Antoniak. 1974. Mixtures of dirichlet processes with applications to bayesian nonparametric problems. The Annals of Statistics, 2(6):1152–1174.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J L Austin</author>
</authors>
<title>How to do things with words.</title>
<date>1962</date>
<publisher>Clarendon Press.</publisher>
<location>Oxford:</location>
<contexts>
<context position="1339" citStr="Austin, 1962" startWordPosition="201" endWordPosition="202">of automating the annotation process. This paper investigates the use of a Dirichlet Process Mixture Model as a means of clustering dialogue utterances in an unsupervised manner. These clusters can then be analysed in terms of the possible Dialogue Acts that they might represent. The results presented here are from the application of the Dirichlet Process Mixture Model to the Dihana corpus. 1 Introduction Dialogue Acts (DAs) are an important contribution from discourse theory to the design of dialogue systems. These linguistics abstractions are based on the illocutionary force of speech acts (Austin, 1962) and try to capture and model the communicative intention of human or machine utterances. In recent years, several dialogue systems have made use of DAs for modelling discourse phenomena in either the Dialogue Manager (Keizer et al., 2008), Automatic Speech Recogniser (Stolcke et al., 2000) or the Automatic Speech Synthesiser (Zovato and Romportl, 2008). Additionally, they have been used also in other tasks such as summarisation, (Murray et al., 2006). Therefore, a correct DA classification of dialogue turns can bring benefits to the performance of these modules and tasks. Many machine learnin</context>
</contexts>
<marker>Austin, 1962</marker>
<rawString>J.L. Austin. 1962. How to do things with words. Oxford: Clarendon Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael D Escobar</author>
<author>Mike West</author>
</authors>
<title>Bayesian density estimation and inference using mixtures.</title>
<date>1995</date>
<journal>Journal of the American Statistical Association,</journal>
<volume>90</volume>
<issue>430</issue>
<contexts>
<context position="5909" citStr="Escobar and West, 1995" startWordPosition="946" endWordPosition="949">abels (153 for the user and 95 for the system). Combining only first and second level there are 72 labels (45 for user and 27 for system), and with only first level there are 16 labels (7 for user and 9 for system). Annotation was done at utterance level. That is, each dialogue turn was divided (segmented) into utterances such that each one corresponds to a unique DA label. An example of the segmentation and annotation of two turns of a dialogue can be seen in Figure 1 3 Dirichlet Process Mixture Models This paper present a Dirichlet Process Mixture Model (DPMM) (Maceachern and M¨uller, 1998; Escobar and West, 1995; Antoniak, 1974) for the Level Labels First Opening, Closing, Confirmation, Undefined, Not-understood, Waiting, Consult, Acceptance, Rejection Second Departure-hour, Arrival-hour, Fare, Origin, Destination, Day, Train-Type, Service, Class, Trip-time Third Departure-hour, Arrival-hour, Fare, Origin, Destination, Day, Train-Type, Service, Class, Trip-time, Order-number, Number-trains, Trip-type Table 1: Set of dialogue act labels used in the Dihana corpus automatic, unsupervised clustering of the utterances in the Dihana corpus. This approach treats each utterance as a bag ofwords (i.e. an unor</context>
</contexts>
<marker>Escobar, West, 1995</marker>
<rawString>Michael D. Escobar and Mike West. 1995. Bayesian density estimation and inference using mixtures. Journal of the American Statistical Association, 90(430):577–588.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sheila Garfield</author>
<author>Stefan Wermter</author>
</authors>
<title>Call classification using recurrent neural networks, support vector machines and finite state automata.</title>
<date>2006</date>
<journal>Knowl. Inf. Syst.,</journal>
<volume>9</volume>
<issue>2</issue>
<contexts>
<context position="2210" citStr="Garfield and Wermter, 2006" startWordPosition="336" endWordPosition="339">omatic Speech Recogniser (Stolcke et al., 2000) or the Automatic Speech Synthesiser (Zovato and Romportl, 2008). Additionally, they have been used also in other tasks such as summarisation, (Murray et al., 2006). Therefore, a correct DA classification of dialogue turns can bring benefits to the performance of these modules and tasks. Many machine learning approaches have been used to automatically label DAs. They are usually based on Supervised Learning techniques involving combinations of Ngrams and Hidden Markov Models (Stolcke et al., 2000; MartinezHinarejos et al., 2008), Neural Networks (Garfield and Wermter, 2006) or Graphical Models (Ji and Bilmes, 2005). Relatively few approaches to DA classification have been based on unsupervised learning methods. Some promising results were reported by Anderach et al (Andernach et al., 1997; Andernach, 1996) who applied Kohonen Self Organising Maps (SOMs) to the problem of DA classification. Although the SOM is nonparametric in the sense that it doesn’t require that the number of clusters to be found in the data be a parameter of the SOM that is specified before clustering begins, it’s capacity to detect clusters is limited to the size of the two-dimensional latti</context>
</contexts>
<marker>Garfield, Wermter, 2006</marker>
<rawString>Sheila Garfield and Stefan Wermter. 2006. Call classification using recurrent neural networks, support vector machines and finite state automata. Knowl. Inf. Syst., 9(2):131–156.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J J Godfrey</author>
<author>E C Holliman</author>
<author>J Mcdaniel</author>
</authors>
<title>SWITCHBOARD: telephone speech corpus for research and development.</title>
<date>1992</date>
<booktitle>In Proc. ICASSP,</booktitle>
<volume>1</volume>
<pages>517--520</pages>
<marker>Godfrey, Holliman, Mcdaniel, 1992</marker>
<rawString>J. J. Godfrey, E. C. Holliman, and J. Mcdaniel. 1992. SWITCHBOARD: telephone speech corpus for research and development. In Proc. ICASSP, volume 1, pages 517–520 vol.1.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gang Ji</author>
<author>J Bilmes</author>
</authors>
<title>Dialog act tagging using graphical models.</title>
<date>2005</date>
<booktitle>In Acoustics, Speech, and Signal Processing,</booktitle>
<volume>1</volume>
<pages>33--36</pages>
<contexts>
<context position="2252" citStr="Ji and Bilmes, 2005" startWordPosition="343" endWordPosition="346">r the Automatic Speech Synthesiser (Zovato and Romportl, 2008). Additionally, they have been used also in other tasks such as summarisation, (Murray et al., 2006). Therefore, a correct DA classification of dialogue turns can bring benefits to the performance of these modules and tasks. Many machine learning approaches have been used to automatically label DAs. They are usually based on Supervised Learning techniques involving combinations of Ngrams and Hidden Markov Models (Stolcke et al., 2000; MartinezHinarejos et al., 2008), Neural Networks (Garfield and Wermter, 2006) or Graphical Models (Ji and Bilmes, 2005). Relatively few approaches to DA classification have been based on unsupervised learning methods. Some promising results were reported by Anderach et al (Andernach et al., 1997; Andernach, 1996) who applied Kohonen Self Organising Maps (SOMs) to the problem of DA classification. Although the SOM is nonparametric in the sense that it doesn’t require that the number of clusters to be found in the data be a parameter of the SOM that is specified before clustering begins, it’s capacity to detect clusters is limited to the size of the two-dimensional lattice onto which the clusters are projected, </context>
</contexts>
<marker>Ji, Bilmes, 2005</marker>
<rawString>Gang Ji and J. Bilmes. 2005. Dialog act tagging using graphical models. In Acoustics, Speech, and Signal Processing, 2005. Proceedings. (ICASSP ’05). IEEE International Conference on, volume 1, pages 33– 36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Lleida J M Benedi</author>
<author>A Varona</author>
<author>I Galiano M J Castro</author>
<author>I L´opez R Justo</author>
<author>A Miguel</author>
</authors>
<title>Design and acquisition of a telephone spontaneous speech dialogue corpus in spanish: Dihana.</title>
<date>2006</date>
<booktitle>In Fifth International Conference on Language Resources and Evaluation (LREC),</booktitle>
<pages>1636--1639</pages>
<location>Genova, Italy,</location>
<marker>Benedi, Varona, Castro, Justo, Miguel, 2006</marker>
<rawString>J.M.Benedi, E.Lleida, A. Varona, M.J.Castro, I.Galiano, R.Justo, I. L´opez, and A. Miguel. 2006. Design and acquisition of a telephone spontaneous speech dialogue corpus in spanish: Dihana. In Fifth International Conference on Language Resources and Evaluation (LREC), pages 1636–1639, Genova, Italy, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Keizer</author>
<author>M Gasic</author>
<author>F Mairesse</author>
<author>B Thomson</author>
<author>K Yu</author>
<author>S Young</author>
</authors>
<title>Modelling user behaviour in the his-pomdp dialogue manager.</title>
<date>2008</date>
<booktitle>In IEEE SLT,</booktitle>
<pages>121--124</pages>
<contexts>
<context position="1578" citStr="Keizer et al., 2008" startWordPosition="240" endWordPosition="243">ossible Dialogue Acts that they might represent. The results presented here are from the application of the Dirichlet Process Mixture Model to the Dihana corpus. 1 Introduction Dialogue Acts (DAs) are an important contribution from discourse theory to the design of dialogue systems. These linguistics abstractions are based on the illocutionary force of speech acts (Austin, 1962) and try to capture and model the communicative intention of human or machine utterances. In recent years, several dialogue systems have made use of DAs for modelling discourse phenomena in either the Dialogue Manager (Keizer et al., 2008), Automatic Speech Recogniser (Stolcke et al., 2000) or the Automatic Speech Synthesiser (Zovato and Romportl, 2008). Additionally, they have been used also in other tasks such as summarisation, (Murray et al., 2006). Therefore, a correct DA classification of dialogue turns can bring benefits to the performance of these modules and tasks. Many machine learning approaches have been used to automatically label DAs. They are usually based on Supervised Learning techniques involving combinations of Ngrams and Hidden Markov Models (Stolcke et al., 2000; MartinezHinarejos et al., 2008), Neural Netwo</context>
</contexts>
<marker>Keizer, Gasic, Mairesse, Thomson, Yu, Young, 2008</marker>
<rawString>S. Keizer, M. Gasic, F. Mairesse, B. Thomson, K. Yu, and S. Young. 2008. Modelling user behaviour in the his-pomdp dialogue manager. In IEEE SLT, pages 121–124, Dec.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Steven N Maceachern</author>
<author>Peter M¨uller</author>
</authors>
<title>Estimating mixture of dirichlet process models.</title>
<date>1998</date>
<journal>Journal of Computational and Graphical Statistics,</journal>
<volume>7</volume>
<issue>2</issue>
<marker>Maceachern, M¨uller, 1998</marker>
<rawString>Steven N. Maceachern and Peter M¨uller. 1998. Estimating mixture of dirichlet process models. Journal of Computational and Graphical Statistics, 7(2):223–238.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C D Martinez-Hinarejos</author>
<author>J M Benedi</author>
<author>R Granell</author>
</authors>
<title>Statistical framework for a spanish spoken dialogue corpus.</title>
<date>2008</date>
<journal>Speech Communication,</journal>
<pages>50--992</pages>
<contexts>
<context position="4803" citStr="Martinez-Hinarejos et al., 2008" startWordPosition="754" endWordPosition="757">tem utterances are different in nature, user utterances are completely spontaneous speech whereas system utterances are based on pre-written patterns that the WoZ selected according to what the user said in the previous turn, the current dialogue state and the WoZ strategy. There is a total of 900 dialogues with a vocabulary of 823 words. However, after applying a process of name entity recognition (cities, times, number, ...) and making the distinction between system and user words there are 964 different words. The same process of name entity recognition was also used by Martinez Hinarejos (Martinez-Hinarejos et al., 2008) 2.1 Annotation scheme Dialogues were manually annotated using a dialogue act annotation scheme based on three levels (see Table 1). The first level corresponds to the general intention of the speaker (speech act), the second level represents the implicit information that is referred to in the first level and the third level is the specific data provided in the utterance. Using these three levels and making the distinction between user and system labels, there are 248 different labels (153 for the user and 95 for the system). Combining only first and second level there are 72 labels (45 for us</context>
</contexts>
<marker>Martinez-Hinarejos, Benedi, Granell, 2008</marker>
<rawString>C. D. Martinez-Hinarejos, J. M. Benedi, and R. Granell. 2008. Statistical framework for a spanish spoken dialogue corpus. Speech Communication, 50:992–1008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Mclachlan</author>
<author>David Peel</author>
</authors>
<title>Finite Mixture Models.</title>
<date>2000</date>
<booktitle>Wiley Series in Probability and Statistics. Wiley-Interscience,</booktitle>
<contexts>
<context position="6960" citStr="Mclachlan and Peel, 2000" startWordPosition="1088" endWordPosition="1092">labels used in the Dihana corpus automatic, unsupervised clustering of the utterances in the Dihana corpus. This approach treats each utterance as a bag ofwords (i.e. an unordered collection of words) (Sebastiani, 2002). Utterances are clustered according to the relative counts of word occurrences that they contain so that utterances with similar histograms of word counts will, in general, appear in the same cluster. Bayesian methods for unsupervised data clustering divide into parametric and nonparametric approaches. Parametric approaches to clustering such as Finite Bayesian Mixture Models (Mclachlan and Peel, 2000) require prior estimation of the number of clusters that are expected to be found in the data. However, it is not always possible to know this in advance and often it is necessary to repeat a modelling experiment many times over a range of choices of cluster numbers to find an optimal number of clusters. Sub-optimal choices for the number of clusters can lead to a degradation in the generalisation performance of the model. Nonparametric approaches to mixture modelling, on the other hand, do not require prior estimates of the number of clusters in the data; this is discovered automatically as t</context>
</contexts>
<marker>Mclachlan, Peel, 2000</marker>
<rawString>Geoffrey Mclachlan and David Peel. 2000. Finite Mixture Models. Wiley Series in Probability and Statistics. Wiley-Interscience, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gabriel Murray</author>
<author>Steve Renals</author>
<author>Jean Carletta</author>
<author>Johanna Moore</author>
</authors>
<title>Incorporating speaker and discourse features into speech summarization.</title>
<date>2006</date>
<booktitle>In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics,</booktitle>
<pages>367--374</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Morristown, NJ, USA.</location>
<contexts>
<context position="1794" citStr="Murray et al., 2006" startWordPosition="273" endWordPosition="276">ntribution from discourse theory to the design of dialogue systems. These linguistics abstractions are based on the illocutionary force of speech acts (Austin, 1962) and try to capture and model the communicative intention of human or machine utterances. In recent years, several dialogue systems have made use of DAs for modelling discourse phenomena in either the Dialogue Manager (Keizer et al., 2008), Automatic Speech Recogniser (Stolcke et al., 2000) or the Automatic Speech Synthesiser (Zovato and Romportl, 2008). Additionally, they have been used also in other tasks such as summarisation, (Murray et al., 2006). Therefore, a correct DA classification of dialogue turns can bring benefits to the performance of these modules and tasks. Many machine learning approaches have been used to automatically label DAs. They are usually based on Supervised Learning techniques involving combinations of Ngrams and Hidden Markov Models (Stolcke et al., 2000; MartinezHinarejos et al., 2008), Neural Networks (Garfield and Wermter, 2006) or Graphical Models (Ji and Bilmes, 2005). Relatively few approaches to DA classification have been based on unsupervised learning methods. Some promising results were reported by And</context>
</contexts>
<marker>Murray, Renals, Carletta, Moore, 2006</marker>
<rawString>Gabriel Murray, Steve Renals, Jean Carletta, and Johanna Moore. 2006. Incorporating speaker and discourse features into speech summarization. In Proceedings of the main conference on Human Language Technology Conference of the North American Chapter of the Association of Computational Linguistics, pages 367–374, Morristown, NJ, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pitman</author>
<author>M Yor</author>
</authors>
<title>The two-parameter Poisson-Dirichlet distribution derived from a stable subordinator. Annals ofProbability,</title>
<date>1997</date>
<pages>25--2</pages>
<contexts>
<context position="12938" citStr="Pitman and Yor, 1997" startWordPosition="2111" endWordPosition="2114">ough, is that its probability mass would be distributed across the whole of the distribution. However, in most practical applications of mixture modelling there will be a finite number of clusters. The solution is to have a process which will tend to place most of the probability mass at the beginning of the infinite distribution, thereby making it possible to assign probabilities to clusters without restricting the number of clusters available. The GEM stick breaking construction (the name comes from the first letters of Griffiths, Engen and McCloskey (Pitman, 2002)) achieves precisely this (Pitman and Yor, 1997). Starting with k i=1 xai−1 i 344 a stick of unit length, random portions β′k are repeatedly broken off the stick, with each part that is broken off representing the proportion of probability assigned to a component: β′k N Beta(1, α) βk = k−1i+1 (1 − β′i) &apos; β′k The Dirichlet Process mixture model can now be specified as: β N GEM(α) φzi N G0 zi E (1... oc) zi N Multinomial(β) xi N F(φzi) 3.3 Chinese Restaurant Process The Chinese Restaurant Process (CRP) is a popular Dirichlet Process paradigm that has been successfully applied to many clustering problems. In the CRP, one is asked to imagine a </context>
</contexts>
<marker>Pitman, Yor, 1997</marker>
<rawString>J. Pitman and M. Yor. 1997. The two-parameter Poisson-Dirichlet distribution derived from a stable subordinator. Annals ofProbability, 25(2):855–900.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Pitman</author>
</authors>
<title>Combinatorial stochastic processes.</title>
<date>2002</date>
<contexts>
<context position="12890" citStr="Pitman, 2002" startWordPosition="2105" endWordPosition="2106">ite dimension Dirichlet distribution, though, is that its probability mass would be distributed across the whole of the distribution. However, in most practical applications of mixture modelling there will be a finite number of clusters. The solution is to have a process which will tend to place most of the probability mass at the beginning of the infinite distribution, thereby making it possible to assign probabilities to clusters without restricting the number of clusters available. The GEM stick breaking construction (the name comes from the first letters of Griffiths, Engen and McCloskey (Pitman, 2002)) achieves precisely this (Pitman and Yor, 1997). Starting with k i=1 xai−1 i 344 a stick of unit length, random portions β′k are repeatedly broken off the stick, with each part that is broken off representing the proportion of probability assigned to a component: β′k N Beta(1, α) βk = k−1i+1 (1 − β′i) &apos; β′k The Dirichlet Process mixture model can now be specified as: β N GEM(α) φzi N G0 zi E (1... oc) zi N Multinomial(β) xi N F(φzi) 3.3 Chinese Restaurant Process The Chinese Restaurant Process (CRP) is a popular Dirichlet Process paradigm that has been successfully applied to many clustering </context>
</contexts>
<marker>Pitman, 2002</marker>
<rawString>J. Pitman. 2002. Combinatorial stochastic processes.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fabrizio Sebastiani</author>
</authors>
<title>Machine learning in automated text categorization.</title>
<date>2002</date>
<journal>ACM Comput. Surv.,</journal>
<volume>34</volume>
<issue>1</issue>
<contexts>
<context position="6554" citStr="Sebastiani, 2002" startWordPosition="1030" endWordPosition="1031">vel Labels First Opening, Closing, Confirmation, Undefined, Not-understood, Waiting, Consult, Acceptance, Rejection Second Departure-hour, Arrival-hour, Fare, Origin, Destination, Day, Train-Type, Service, Class, Trip-time Third Departure-hour, Arrival-hour, Fare, Origin, Destination, Day, Train-Type, Service, Class, Trip-time, Order-number, Number-trains, Trip-type Table 1: Set of dialogue act labels used in the Dihana corpus automatic, unsupervised clustering of the utterances in the Dihana corpus. This approach treats each utterance as a bag ofwords (i.e. an unordered collection of words) (Sebastiani, 2002). Utterances are clustered according to the relative counts of word occurrences that they contain so that utterances with similar histograms of word counts will, in general, appear in the same cluster. Bayesian methods for unsupervised data clustering divide into parametric and nonparametric approaches. Parametric approaches to clustering such as Finite Bayesian Mixture Models (Mclachlan and Peel, 2000) require prior estimation of the number of clusters that are expected to be found in the data. However, it is not always possible to know this in advance and often it is necessary to repeat a mo</context>
</contexts>
<marker>Sebastiani, 2002</marker>
<rawString>Fabrizio Sebastiani. 2002. Machine learning in automated text categorization. ACM Comput. Surv., 34(1):1–47, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Noah Coccaro</author>
<author>Rebecca Bates</author>
<author>Paul Taylor</author>
<author>Carol Van Ess-Dykema</author>
<author>Klaus Ries</author>
<author>Elizabeth Shriberg</author>
<author>Daniel Jurafsky</author>
<author>Rachel Martin</author>
<author>Marie Meteer</author>
</authors>
<title>Dialogue act modeling for automatic tagging and recognition of conversational speech.</title>
<date>2000</date>
<journal>Comput. Linguist.,</journal>
<volume>26</volume>
<issue>3</issue>
<marker>Stolcke, Coccaro, Bates, Taylor, Van Ess-Dykema, Ries, Shriberg, Jurafsky, Martin, Meteer, 2000</marker>
<rawString>Andreas Stolcke, Noah Coccaro, Rebecca Bates, Paul Taylor, Carol Van Ess-Dykema, Klaus Ries, Elizabeth Shriberg, Daniel Jurafsky, Rachel Martin, and Marie Meteer. 2000. Dialogue act modeling for automatic tagging and recognition of conversational speech. Comput. Linguist., 26(3):339–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Zovato</author>
<author>J Romportl</author>
</authors>
<title>Speech synthesis and emotions: a compromise between flexibility and believability.</title>
<date>2008</date>
<booktitle>In Proceedings ofFourth International Workshop on Human-Computer Conversation,</booktitle>
<location>Bellagio, Italy.</location>
<contexts>
<context position="1694" citStr="Zovato and Romportl, 2008" startWordPosition="257" endWordPosition="260">richlet Process Mixture Model to the Dihana corpus. 1 Introduction Dialogue Acts (DAs) are an important contribution from discourse theory to the design of dialogue systems. These linguistics abstractions are based on the illocutionary force of speech acts (Austin, 1962) and try to capture and model the communicative intention of human or machine utterances. In recent years, several dialogue systems have made use of DAs for modelling discourse phenomena in either the Dialogue Manager (Keizer et al., 2008), Automatic Speech Recogniser (Stolcke et al., 2000) or the Automatic Speech Synthesiser (Zovato and Romportl, 2008). Additionally, they have been used also in other tasks such as summarisation, (Murray et al., 2006). Therefore, a correct DA classification of dialogue turns can bring benefits to the performance of these modules and tasks. Many machine learning approaches have been used to automatically label DAs. They are usually based on Supervised Learning techniques involving combinations of Ngrams and Hidden Markov Models (Stolcke et al., 2000; MartinezHinarejos et al., 2008), Neural Networks (Garfield and Wermter, 2006) or Graphical Models (Ji and Bilmes, 2005). Relatively few approaches to DA classifi</context>
</contexts>
<marker>Zovato, Romportl, 2008</marker>
<rawString>E. Zovato and J. Romportl. 2008. Speech synthesis and emotions: a compromise between flexibility and believability. In Proceedings ofFourth International Workshop on Human-Computer Conversation, Bellagio, Italy.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>