<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000276">
<title confidence="0.999373">
A Model for Robust Processing of Spontaneous Speech
by Integrating Viable Fragments*
</title>
<author confidence="0.884756">
Karsten L. Worm
</author>
<affiliation confidence="0.687274">
Universitat des Saarlandes
Computerlinguistik
</affiliation>
<address confidence="0.490117">
D-66041 Saarbdicken, Germany
</address>
<email confidence="0.644058">
worm@coli .uni-sb. de
</email>
<sectionHeader confidence="0.984754" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998852">
We describe the design and function of a robust pro-
cessing component which is being developed for the
Verbmobil speech translation system. Its task con-
sists of collecting partial analyses of an input utter-
ance produced by three parsers and attempting to
combine them into more meaningful, larger units. It
is used as a fallback mechanism in cases where no
complete analysis spanning the whole input can be
achieved, owing to spontaneous speech phenomena
or speech recognition errors.
</bodyText>
<sectionHeader confidence="0.998803" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999223">
In this paper we describe the function and design
of the robust semantic processing component which
we are currently developing in the context of the
Verbmobil speech translation project. We aim at im-
proving the system&apos;s performance in terms of cov-
erage and quality of translations by combining frag-
mentary analyses when no spanning analysis of the
input can be derived because of spontaneous speech
phenomena or speech recognition errors.
</bodyText>
<sectionHeader confidence="0.979374" genericHeader="method">
2 The Verbmobil Context
</sectionHeader>
<bodyText confidence="0.997795875">
Verbmobil (Wahlster, 1997) is a large scale research
project in the area of spoken language translation.
Its goal is to develop a system that translates ne-
gotiation dialogues between speakers of German,
English and Japanese in face-to-face or video con-
ferencing situations. The integrated system devel-
oped during the first project phase (1993-96), the
Research Prototype, was successfully demonstrated
</bodyText>
<note confidence="0.533923571428571">
• The author wishes to thank his colleagues Johan Bos,
Aljoscha Burchardt, Bjorn GambUck, Walter Kasper, Bernd
Kiefer, Uli Krieger, Manfred Pinkal, Tobias Ruland, C. J. Rupp,
Jorg Spilker, and Hans Weber for their collaboration. This re-
search was supported by the German Federal Ministry for Ed-
ucation, Science, Research and Technology under grant no. 01
IV 701 R4.
</note>
<bodyText confidence="0.99994378125">
in autumn 1996 (Bub et al., 1997). The final Verb-
mobil Prototype is due in 2000.
Verbmobil employs different approaches to ma-
chine translation. A semantic transfer approach
(Dorna and Emele, 1996) based on a deep linguistic
analysis of the input utterance competes with statis-
tical, example based and dialogue act based transla-
tion approaches.
The spoken input is mapped onto a word hypothe-
sis graph (WHG) by a speech recognizer. A prosody
component divides the input into segments and an-
notates the WHGs with prosodic features. Within
the semantic transfer line of processing, three dif-
ferent parsers (an HPSG-based chart parser, a chunk
parser using cascaded finite state automata, and
a statistical parser) attempt to analyse the paths
through the WHG syntactically and semantically.
All three deliver their analyses in the VIT format
(see 3). The parsers&apos; work is coordinated by an inte-
grated processing component which chooses paths
through the WHG to be analysed in parallel by the
parsers until an analysis spanning the whole input is
found or the system reaches a time limit.
Since in many cases no complete analysis span-
ning the whole input can be found, the parsers pro-
duce partial analyses along the way and send them
to the robust semantic processing component, which
stores and combines them to yield analyses of larger
parts of the input. We describe this component in
section 5.
The relevant part of the system&apos;s architecture is
shown in Figure 1.
</bodyText>
<sectionHeader confidence="0.997765" genericHeader="method">
3 The VIT Format
</sectionHeader>
<bodyText confidence="0.999584333333333">
The VIT (short for Verbmobil Interface Term) was
designed as a common output format for the two
alternative and independently developed syntactic-
semantic analysis components of the first project
phase (Bos et al., 1998). Their internal semantic for-
malisms differed, but both had to be attached to a
</bodyText>
<page confidence="0.948936">
1403
</page>
<table confidence="0.997432">
Speech HPSG Dialogue and
Recognition &amp; Parser Context
Prosody
--11€1 -111.HG
Integrated Robust Transfer VIT
Processing Semantic
Processing
VITs
Generation &amp;
Speech
Synthesis
Chunk Statistical
Parser Parser
</table>
<figureCaption confidence="0.998278">
Figure 1: Part of the system architecture.
</figureCaption>
<bodyText confidence="0.8630994">
single transfer module. The need for a common out-
put format is still present, since there are three al-
ternative syntactic-semantic parsing modules in the
new Verbmobil system, all of which again produce
output for just one transfer module.
</bodyText>
<equation confidence="0.975415111111111">
(1) vit(vitID(sid(1,a,ge,0,20,1,ge,y,
semantics),
[word(montag,13,[1116)),
word(ist,14,[1117)),
word(gut,15,[1110)))),
index(1113,1109,1104),
[dec1(1112,h105),
gut(1110,i105),
dofw(1116,1105,mon),
</equation>
<bodyText confidence="0.953507666666667">
support(1117,i104,1110),
indef(1111,i105,1115,h106)),
[ccom_plug(h105,1114),
ccom_plug(h106,1109),
in_g(1112,1113),
in_g(1117,1109),
in_g(1116,1115),
in_g(1111,1114),
leq(1114,h105),leg(1109,h106),
leq(1109,h105)),
[s_sort(1105,time)),
I),
</bodyText>
<equation confidence="0.5799944">
[num(1105,sg),pers(1105,3)),
[ta_mood(1104,ind),
ta_tense(i104,pres),
ta_perf(i104,nonperf)),
I)
</equation>
<bodyText confidence="0.9999696875">
The VIT can be viewed as a theory-independent
representation for underspecified semantic repre-
sentations (Bos et al., 1996). It specifies a set of dis-
course representation structures, DRSs, (Kamp and
Reyle, 1993). If an utterance is structurally ambigu-
ous, it will be represented by one VIT, which spec-
ifies the set of DRSs corresponding to the different
readings of the utterance.
Formally, a VIT is a nine-place PROLOG term.
There are slots for an identifier for the input segment
to which the VIT corresponds, a list of the core se-
mantic predicates, a list of scopal constraints, syn-
tactic, prosodic and pragmatic information as well
as tense and aspect and sortal information. An ex-
ample of a VIT for the sentence Montag ist gut
(&apos;Monday is fine&apos;) is given in (1).
</bodyText>
<sectionHeader confidence="0.976798" genericHeader="method">
4 Approaches to Robustness
</sectionHeader>
<bodyText confidence="0.9999435">
There are three stages in processing where a speech
understanding system can be made more robust
against spontaneous speech phenomena and recog-
nizer errors: before, during, or after parsing. While
we do not see them as mutually exclusive, we think
that the first two present significant problems.
</bodyText>
<subsectionHeader confidence="0.999342">
4.1 Before parsing
</subsectionHeader>
<bodyText confidence="0.999990625">
Detection of self corrections on transcriptions be-
fore parsing has been explored (Bear et al., 1992;
Nakatani and Hirschberg, 1993), but it is not clear
that it will be feasible on WHGs, since recognition
errors interfere and the search space may explode
due to the number of paths. Dealing with recogni-
tion errors before parsing is impossible due to lack
of structural information.
</bodyText>
<subsectionHeader confidence="0.999632">
4.2 During parsing
</subsectionHeader>
<bodyText confidence="0.999935909090909">
Treating the phenomena mentioned during parsing
would mean that the grammar or the parser would
have to be made more liberal, i. e. they would have
to accept strings which are ungrammatical. This is
problematic in the context of WHG parsing, since
the parser has to simultaneously perform two tasks:
Searching for a path to be analysed and analysing it
as well.
If the analysis procedure is too liberal, it may
already accept and analyse an ungrammatical path
when a lower ranked path which is grammatical is
</bodyText>
<page confidence="0.984553">
1404
</page>
<bodyText confidence="0.9599215">
also present in the WHO. I. e., the search through
the WHG would not be restricted enough.
</bodyText>
<sectionHeader confidence="0.971452" genericHeader="method">
5 Robust Semantic Processing
</sectionHeader>
<bodyText confidence="0.9995122">
Our approach addresses the problems mentioned af-
ter parsing. In many cases the three parsers will
not be able to find a path through the WHO that
can be assigned a complete and spanning syntactic-
semantic analysis. This is mainly due to two factors:
</bodyText>
<listItem confidence="0.999186">
• spontaneous speech phenomena, and
• speech recognition errors.
</listItem>
<bodyText confidence="0.999864153846154">
However, the parsers will usually be able to deliver
a collection of partial analyses — each covering a
part of a path through the WHG.
The goal of the robust semantic processing com-
ponent in Verbmobil-2 is to collect these partial
analyses and try to put them together on the basis
of heuristic rules to produce deep linguistic analy-
ses even if the input is not completely analysable.
We speak of robust semantic processing since we
are dealing with VITs which primarily represent se-
mantic content and apply rules which refer to se-
mantic properties and semantic structures.
The task splits into three subtasks:
</bodyText>
<listItem confidence="0.9774055">
1. Storing the partial analyses for different WHO
(sub)paths from different parsers;
2. Combining partial analyses to yield bigger
structures;
3. Choosing a sequence of partial analyses from
the set of hypotheses as output.
</listItem>
<bodyText confidence="0.99929775">
These subtasks are discussed in the following sub-
sections. Section 5.4 contains examples of the prob-
lems mentioned and outlines their treatment in the
approach described.
</bodyText>
<subsectionHeader confidence="0.999084">
5.1 Storing Partial Analyses
</subsectionHeader>
<bodyText confidence="0.999986045454546">
The first task of the robust semantic processing is
to manage a possibly large number of partial analy-
ses, each spanning a certain sub-interval of the input
utterance.
The basic mode of processing — store competing
analyses and combine them to larger analyses, while
avoiding unnecessary redundancy — resembles that
of a chart parser. Indeed we use a chart-like data
structure to store the competing partial analyses de-
livered by the parsers and new hypotheses obtained
by combining existing ones. All the advantages of
the chart in chart parsing are preserved: The chart
allows the storage of competing hypotheses, even
from different sources, without redundancy.
Since the input to the parsers consists of WHGs
rather than strings, the analyses entered cannot refer
to the string positions they span. Rather they have
to refer to a time interval. This means also that the
chart cannot be indexed by string positions, but is
indexed by the time frames the speech recognizer
uses. This makes necessary slight modifications to
the chart handling algorithms.
</bodyText>
<subsectionHeader confidence="0.999821">
5.2 Combining Partial Analyses
</subsectionHeader>
<bodyText confidence="0.99931675">
We use a set of heuristic rules to describe the con-
ditions under which two or more partial analyses
should be combined, an analysis should be left out
or modified. Each rule specifies the conditions un-
der which it should be applied, the operations to be
performed, and what the result of the rule applica-
tion is. Rules have the following format (in PROLOG
notation):
</bodyText>
<equation confidence="0.9576885">
[Condl,...,CondN] ---&gt;
[0p1,...,OpN] &amp; Result.
</equation>
<bodyText confidence="0.999978538461539">
The left hand side consists of a list of conditions
on partial analyses, Condi being a condition (or a
list of conditions) on the first partial analysis (VIT),
etc., where the order of conditions parallels the ex-
pected temporal order of the analyses. When these
conditions are met, the rule fires and the operations
Opl etc. are performed on the input VITs. One VIT,
Result, is designated as the result of the rule. Af-
ter applying the rule, an edge annotated with this
VIT is entered into the chart, spanning the minimum
time frame that includes the spans of all the analyses
on the left hand side. Examples for rules are given
in 5.4.
</bodyText>
<subsectionHeader confidence="0.999681">
5.3 Choosing a Result
</subsectionHeader>
<bodyText confidence="0.999635615384615">
When no more analyses are produced by the parsers
and all applicable rules have been applied, the last
step is to choose a &apos;best&apos; sequence of analyses from
the chart which covers the whole input and deliver
it to the transfer module. In the ideal case, there will
be an analysis spanning the whole input.
Currently, we employ a simple search which
takes into account the acoustic scores of the WHO
paths the analyses are based on, together with the
length and coverage of the individual analyses.
The length is defined as the length of the temporal
interval an analysis spans; an analysis with a greater
length is preferred. The coverage of an analysis is
</bodyText>
<page confidence="0.980738">
1405
</page>
<bodyText confidence="0.999942428571429">
the sum of the lengths of the component analyses
it consists of. Note that the coverage of an analysis
will be less than its length if some material inside
the interval the analysis spans has been left out in
the analysis; hence length and coverage are equal
for the analyses produced by the parsers.&apos; Analyses
with greater coverage are preferred.
</bodyText>
<subsectionHeader confidence="0.956432">
5.4 Examples
</subsectionHeader>
<bodyText confidence="0.9999624">
The examples in this section are taken from the
Verbmobil corpus of appointment scheduling dia-
logues. The problems we address here appeared in
WHGs produced by a speech recognizer on the orig-
inal audio data.
</bodyText>
<subsectionHeader confidence="0.756572">
5.4.1 Missing preposition
</subsectionHeader>
<bodyText confidence="0.999707266666667">
Since function words like prepositions are usually
short, speech recognizers often have trouble rec-
ognizing them. Consider an example where the
speaker uttered Mir ware es am liebsten in den
ntichsten zwei Wochen (&apos;During the next two weeks
would be most convenient for me&apos;). However, the
WHG contains no path which includes the prepo-
sition in in an appropriate position. Consequently,
the parsers delivered analyses for the segments Mir
ware es am liebsten and den niichsten zwei Wochen.
These fragments are handled by two rules. The
first turns a temporal NP like the second fragment
into a temporal modifier, expressing that something
is standing in an underspecified temporal relation to
the temporal entity the NP denotes:
</bodyText>
<equation confidence="0.898363">
[temporal_np(V1)] ---&gt;
[typeraise_to_mod(V1,V2)] &amp; V2.
</equation>
<bodyText confidence="0.9856575">
Then a very general rule can apply that modifier to
the proposition expressed by the first fragment:
</bodyText>
<equation confidence="0.660467">
[type(V1,prop),type(V2,mod)] ---&gt;
[apply(V2,V1,V3)] &amp; V3.
</equation>
<subsectionHeader confidence="0.981343">
5.4.2 Self-Correction of a Modifier
</subsectionHeader>
<bodyText confidence="0.747859588235294">
Here the speaker uttered Wir treffen uns am Montag,
nein, am Dienstag (&apos;We will meet on Monday, no,
on Tuesday&apos;). The parsers deliver three fragments,
the first being a proposition containing a modifier,
the second an interjection marking a correction, and
the third a modifier of the same type as the one in the
proposition. Under these conditions, we replace the
modifier inside the proposition with the one uttered
after the correction marker:
&apos;The chunk parser may be an exception here since it some-
times leaves out words it cannot integrate into an analysis.
Htype(V1,prop),
has_mod(V1,M1,ModType)],
correction_marker(_),
[type(V2,mod),
has_mod(V2,M2,ModType)])
---&gt; [replace_mod(V1,M1,M2,V3)] &amp; V3.
</bodyText>
<subsectionHeader confidence="0.947162">
5.4.3 Self-Correction of a Verb
</subsectionHeader>
<bodyText confidence="0.976200842105263">
In this case, the speaker uttered Am Montag treffe . . .
babe ich einen Termin., i. e. decided to continue the
utterance in a different way than originally intended.
The parsers deliver fragments for, among others, the
substrings am Montag, treffe, habe, ich, and einen
Termin (all the partial analyses received from the
parsers and built up by robust semantic processing
are shown in the chart2 in Figure 2).
Robust semantic processing then builds analyses
by applying modifiers to verbal predicates (e. g.,
analyses 71, 108) and verbal functors to possible ar-
guments (e. g., 20, 106, 47). The latter is done by
the following two rules:
[type(V1,Type),unbound_arg(V2,Type)]
---&gt; [apply(V2,V1,V3)] &amp; V3.
[uhbound_arg(V1,Type),type(V2,Type)]
---&gt; [apply(V1,V2,V3)] &amp; V3.
Note that einen Termin is not considered to be a pos-
sible argument of the verb treffe since that would
violate the verb&apos;s sortal selection restrictions.
After all partial analyses produced by the parsers
have been entered into the chart and all applicable
rules have been applied, there is still no spanning
analysis (all analyses in Figure 2 are there, except
the spanning one numbered 105). In such a case,
the robust semantic processing component proceeds
by extending active edges over passive edges which
end in a chart node in which only one passive edge
ends, or all passive edges ending there correspond
to partial analyses still missing arguments.
In this example, this applies to the node in which
edges 1 and 71 end, which both are missing the two
arguments of the transitive verb treffe. Application
of the proposition modification rule mentioned in
Section 5.4.1 to the modifyer PP am Montag has
led to an active edge still looking for a proposi-
tion. This is now being extended to end at the same
node as the two passive edges missing arguments.
</bodyText>
<footnote confidence="0.9992166">
2The analyses in the chart are numbered; the numbers in
square brackets indicate the immediate constituents an analysis
has been built from by robust semantic processing. I. e., anal-
yses with an empty list of immediate constituents have been
produced by a parser.
</footnote>
<page confidence="0.981707">
1406
</page>
<figure confidence="0.649338">
6: am montaq+treffe+ich rn .1 91
</figure>
<figureCaption confidence="0.996162">
Figure 2: The chart for Am Montag treffe . . . habe ich einen Termin.
</figureCaption>
<figure confidence="0.541725909090909">
19: ich I 46: einen tennin
57: einen termin 46
1: treffe 1 1habe
20: habe+ich 110,191
105: am montaq+habe+ich+einen termin 162,471
am mon
21: habe+Ich 110,191
106: ffe+Ich 11,191
107: ffe+Ich 11,191
47: habe+ich men termin 120,461
108: am montaq+treffe+ich [71,19]
</figure>
<bodyText confidence="0.999645">
There, it finds an edge corresponding to a propo-
sition, namely edge 47, which had been built up
earlier. The result is passive edge 105 spanning the
whole input and expressing the right interpretation.
</bodyText>
<sectionHeader confidence="0.999974" genericHeader="method">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999951428571429">
An approach similar to the one described here was
developed by Rosé (Rosé, 1997). However, that ap-
proach works on interlingual representations of ut-
terance meanings, which implies the loss of all lin-
guistic constraints on the combinatorics of partial
analyses. Apart from that, only the output of one
parser is considered.
</bodyText>
<sectionHeader confidence="0.984425" genericHeader="conclusions">
7 Conclusion and Outlook
</sectionHeader>
<bodyText confidence="0.999917692307692">
We have described a model for the combination of
partial parsing results and how it can be applied in
order to improve the robustness of a speech process-
ing system. A prototype version was integrated into
the Verbmobil system in autumn 1997 and is cur-
rently being extended.
We are working on improving the selection of re-
sults by using a stochastic model of Vii&apos; sequence
probabilities, on the extension of the rule set to
cover more spontaneous speech phenomena of Ger-
man, English and Japanese, and on refining the
mechanism for extending active edges to arrive at
a spanning analyses.
</bodyText>
<sectionHeader confidence="0.999465" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999755948717949">
John Bear, John Dowding, and Elizabeth Shriberg.
1992. Integrating multiple knowledge sources
for detection and correction of repairs in human-
computer dialog. In Proc. of the 30 th ACL, pages
56-63, Newark, DE.
Johan Bos, Bjorn Gambank, Christian Lieske,
Yoshiki Mori, Manfred Pinkal, and Karsten
Worm. 1996. Compositional semantics in Verb-
mobil. In Proc. of the 16th COLING, pages 131-
136, Copenhagen, Denmark.
Johan Bos, Bianka Buschbeck-Wolf, Michael
Dorna, and C. J. Rupp. 1998. Managing infor-
mation at linguistic interfaces. In Proc. of the
17th COLING/36th ACL, Montréal, Canada.
Thomas Bub, Wolfgang Wahlster, and Alex Waibel.
1997. Verbmobil: The combination of deep and
shallow processing for spontaneous speech trans-
lation. In Proc. Int. Conf. on Acoustics, Speech
and Signal Processing (ICASSP), pages 71-74,
Manchen, Germany. IEEE Signal Processing So-
ciety.
Michael Dorna and Martin C. Emele. 1996.
Semantic-based transfer. In Proc. of the 16th
COLING, pages 316-321, Copenhagen, Den-
mark.
Hans Kamp and Uwe Reyle. 1993. From Discourse
to Logic. Kluwer, Dordrecht.
Christine Nakatani and Julia Hirschberg. 1993. A
speech-first model for repair detection and cor-
rection. In Proc. of the 31 th ACL, pages 46-53,
Columbus, OH.
Carolyn Penstein Rosé. 1997. Robust Interactive
Dialogue Interpretation. Ph.D. thesis, Carnegie
Mellon University, Pittsburgh, PA. Language
Technologies Institute.
Wolfgang Wahlster. 1997. Verbmobil: Erken-
nung, Analyse, Transfer, Generierung und Syn-
these von Spontansprache. Verbmobil-Report
198, DFKI GmbH, Saarbrficken, June.
</reference>
<page confidence="0.993844">
1407
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.753091">
<title confidence="0.94472">A Model for Robust Processing of Spontaneous Speech by Integrating Viable Fragments*</title>
<author confidence="0.999539">Karsten L Worm</author>
<affiliation confidence="0.943344">Universitat des Saarlandes Computerlinguistik</affiliation>
<address confidence="0.991462">D-66041 Saarbdicken, Germany</address>
<email confidence="0.964149">worm@coli.uni-sb.de</email>
<abstract confidence="0.999102727272727">We describe the design and function of a robust processing component which is being developed for the Verbmobil speech translation system. Its task consists of collecting partial analyses of an input utterance produced by three parsers and attempting to combine them into more meaningful, larger units. It is used as a fallback mechanism in cases where no complete analysis spanning the whole input can be achieved, owing to spontaneous speech phenomena or speech recognition errors.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>John Bear</author>
<author>John Dowding</author>
<author>Elizabeth Shriberg</author>
</authors>
<title>Integrating multiple knowledge sources for detection and correction of repairs in humancomputer dialog.</title>
<date>1992</date>
<booktitle>In Proc. of the 30 th ACL,</booktitle>
<pages>56--63</pages>
<location>Newark, DE.</location>
<contexts>
<context position="5956" citStr="Bear et al., 1992" startWordPosition="891" endWordPosition="894">prosodic and pragmatic information as well as tense and aspect and sortal information. An example of a VIT for the sentence Montag ist gut (&apos;Monday is fine&apos;) is given in (1). 4 Approaches to Robustness There are three stages in processing where a speech understanding system can be made more robust against spontaneous speech phenomena and recognizer errors: before, during, or after parsing. While we do not see them as mutually exclusive, we think that the first two present significant problems. 4.1 Before parsing Detection of self corrections on transcriptions before parsing has been explored (Bear et al., 1992; Nakatani and Hirschberg, 1993), but it is not clear that it will be feasible on WHGs, since recognition errors interfere and the search space may explode due to the number of paths. Dealing with recognition errors before parsing is impossible due to lack of structural information. 4.2 During parsing Treating the phenomena mentioned during parsing would mean that the grammar or the parser would have to be made more liberal, i. e. they would have to accept strings which are ungrammatical. This is problematic in the context of WHG parsing, since the parser has to simultaneously perform two task</context>
</contexts>
<marker>Bear, Dowding, Shriberg, 1992</marker>
<rawString>John Bear, John Dowding, and Elizabeth Shriberg. 1992. Integrating multiple knowledge sources for detection and correction of repairs in humancomputer dialog. In Proc. of the 30 th ACL, pages 56-63, Newark, DE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Bjorn Gambank</author>
<author>Christian Lieske</author>
<author>Yoshiki Mori</author>
<author>Manfred Pinkal</author>
<author>Karsten Worm</author>
</authors>
<title>Compositional semantics in Verbmobil.</title>
<date>1996</date>
<booktitle>In Proc. of the 16th COLING,</booktitle>
<pages>131--136</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="4868" citStr="Bos et al., 1996" startWordPosition="708" endWordPosition="711">mantics), [word(montag,13,[1116)), word(ist,14,[1117)), word(gut,15,[1110)))), index(1113,1109,1104), [dec1(1112,h105), gut(1110,i105), dofw(1116,1105,mon), support(1117,i104,1110), indef(1111,i105,1115,h106)), [ccom_plug(h105,1114), ccom_plug(h106,1109), in_g(1112,1113), in_g(1117,1109), in_g(1116,1115), in_g(1111,1114), leq(1114,h105),leg(1109,h106), leq(1109,h105)), [s_sort(1105,time)), I), [num(1105,sg),pers(1105,3)), [ta_mood(1104,ind), ta_tense(i104,pres), ta_perf(i104,nonperf)), I) The VIT can be viewed as a theory-independent representation for underspecified semantic representations (Bos et al., 1996). It specifies a set of discourse representation structures, DRSs, (Kamp and Reyle, 1993). If an utterance is structurally ambiguous, it will be represented by one VIT, which specifies the set of DRSs corresponding to the different readings of the utterance. Formally, a VIT is a nine-place PROLOG term. There are slots for an identifier for the input segment to which the VIT corresponds, a list of the core semantic predicates, a list of scopal constraints, syntactic, prosodic and pragmatic information as well as tense and aspect and sortal information. An example of a VIT for the sentence Monta</context>
</contexts>
<marker>Bos, Gambank, Lieske, Mori, Pinkal, Worm, 1996</marker>
<rawString>Johan Bos, Bjorn Gambank, Christian Lieske, Yoshiki Mori, Manfred Pinkal, and Karsten Worm. 1996. Compositional semantics in Verbmobil. In Proc. of the 16th COLING, pages 131-136, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Bianka Buschbeck-Wolf</author>
<author>Michael Dorna</author>
<author>C J Rupp</author>
</authors>
<title>Managing information at linguistic interfaces.</title>
<date>1998</date>
<booktitle>In Proc. of the 17th COLING/36th ACL,</booktitle>
<location>Montréal, Canada.</location>
<contexts>
<context position="3637" citStr="Bos et al., 1998" startWordPosition="575" endWordPosition="578">. Since in many cases no complete analysis spanning the whole input can be found, the parsers produce partial analyses along the way and send them to the robust semantic processing component, which stores and combines them to yield analyses of larger parts of the input. We describe this component in section 5. The relevant part of the system&apos;s architecture is shown in Figure 1. 3 The VIT Format The VIT (short for Verbmobil Interface Term) was designed as a common output format for the two alternative and independently developed syntacticsemantic analysis components of the first project phase (Bos et al., 1998). Their internal semantic formalisms differed, but both had to be attached to a 1403 Speech HPSG Dialogue and Recognition &amp; Parser Context Prosody --11€1 -111.HG Integrated Robust Transfer VIT Processing Semantic Processing VITs Generation &amp; Speech Synthesis Chunk Statistical Parser Parser Figure 1: Part of the system architecture. single transfer module. The need for a common output format is still present, since there are three alternative syntactic-semantic parsing modules in the new Verbmobil system, all of which again produce output for just one transfer module. (1) vit(vitID(sid(1,a,ge,0</context>
</contexts>
<marker>Bos, Buschbeck-Wolf, Dorna, Rupp, 1998</marker>
<rawString>Johan Bos, Bianka Buschbeck-Wolf, Michael Dorna, and C. J. Rupp. 1998. Managing information at linguistic interfaces. In Proc. of the 17th COLING/36th ACL, Montréal, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Bub</author>
<author>Wolfgang Wahlster</author>
<author>Alex Waibel</author>
</authors>
<title>Verbmobil: The combination of deep and shallow processing for spontaneous speech translation.</title>
<date>1997</date>
<booktitle>In Proc. Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP),</booktitle>
<pages>71--74</pages>
<publisher>IEEE Signal Processing Society.</publisher>
<location>Manchen, Germany.</location>
<contexts>
<context position="1971" citStr="Bub et al., 1997" startWordPosition="301" endWordPosition="304">peakers of German, English and Japanese in face-to-face or video conferencing situations. The integrated system developed during the first project phase (1993-96), the Research Prototype, was successfully demonstrated • The author wishes to thank his colleagues Johan Bos, Aljoscha Burchardt, Bjorn GambUck, Walter Kasper, Bernd Kiefer, Uli Krieger, Manfred Pinkal, Tobias Ruland, C. J. Rupp, Jorg Spilker, and Hans Weber for their collaboration. This research was supported by the German Federal Ministry for Education, Science, Research and Technology under grant no. 01 IV 701 R4. in autumn 1996 (Bub et al., 1997). The final Verbmobil Prototype is due in 2000. Verbmobil employs different approaches to machine translation. A semantic transfer approach (Dorna and Emele, 1996) based on a deep linguistic analysis of the input utterance competes with statistical, example based and dialogue act based translation approaches. The spoken input is mapped onto a word hypothesis graph (WHG) by a speech recognizer. A prosody component divides the input into segments and annotates the WHGs with prosodic features. Within the semantic transfer line of processing, three different parsers (an HPSG-based chart parser, a </context>
</contexts>
<marker>Bub, Wahlster, Waibel, 1997</marker>
<rawString>Thomas Bub, Wolfgang Wahlster, and Alex Waibel. 1997. Verbmobil: The combination of deep and shallow processing for spontaneous speech translation. In Proc. Int. Conf. on Acoustics, Speech and Signal Processing (ICASSP), pages 71-74, Manchen, Germany. IEEE Signal Processing Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Dorna</author>
<author>Martin C Emele</author>
</authors>
<title>Semantic-based transfer.</title>
<date>1996</date>
<booktitle>In Proc. of the 16th COLING,</booktitle>
<pages>316--321</pages>
<location>Copenhagen, Denmark.</location>
<contexts>
<context position="2134" citStr="Dorna and Emele, 1996" startWordPosition="326" endWordPosition="329">-96), the Research Prototype, was successfully demonstrated • The author wishes to thank his colleagues Johan Bos, Aljoscha Burchardt, Bjorn GambUck, Walter Kasper, Bernd Kiefer, Uli Krieger, Manfred Pinkal, Tobias Ruland, C. J. Rupp, Jorg Spilker, and Hans Weber for their collaboration. This research was supported by the German Federal Ministry for Education, Science, Research and Technology under grant no. 01 IV 701 R4. in autumn 1996 (Bub et al., 1997). The final Verbmobil Prototype is due in 2000. Verbmobil employs different approaches to machine translation. A semantic transfer approach (Dorna and Emele, 1996) based on a deep linguistic analysis of the input utterance competes with statistical, example based and dialogue act based translation approaches. The spoken input is mapped onto a word hypothesis graph (WHG) by a speech recognizer. A prosody component divides the input into segments and annotates the WHGs with prosodic features. Within the semantic transfer line of processing, three different parsers (an HPSG-based chart parser, a chunk parser using cascaded finite state automata, and a statistical parser) attempt to analyse the paths through the WHG syntactically and semantically. All three</context>
</contexts>
<marker>Dorna, Emele, 1996</marker>
<rawString>Michael Dorna and Martin C. Emele. 1996. Semantic-based transfer. In Proc. of the 16th COLING, pages 316-321, Copenhagen, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hans Kamp</author>
<author>Uwe Reyle</author>
</authors>
<title>From Discourse to Logic.</title>
<date>1993</date>
<publisher>Kluwer,</publisher>
<location>Dordrecht.</location>
<contexts>
<context position="4957" citStr="Kamp and Reyle, 1993" startWordPosition="722" endWordPosition="725">1113,1109,1104), [dec1(1112,h105), gut(1110,i105), dofw(1116,1105,mon), support(1117,i104,1110), indef(1111,i105,1115,h106)), [ccom_plug(h105,1114), ccom_plug(h106,1109), in_g(1112,1113), in_g(1117,1109), in_g(1116,1115), in_g(1111,1114), leq(1114,h105),leg(1109,h106), leq(1109,h105)), [s_sort(1105,time)), I), [num(1105,sg),pers(1105,3)), [ta_mood(1104,ind), ta_tense(i104,pres), ta_perf(i104,nonperf)), I) The VIT can be viewed as a theory-independent representation for underspecified semantic representations (Bos et al., 1996). It specifies a set of discourse representation structures, DRSs, (Kamp and Reyle, 1993). If an utterance is structurally ambiguous, it will be represented by one VIT, which specifies the set of DRSs corresponding to the different readings of the utterance. Formally, a VIT is a nine-place PROLOG term. There are slots for an identifier for the input segment to which the VIT corresponds, a list of the core semantic predicates, a list of scopal constraints, syntactic, prosodic and pragmatic information as well as tense and aspect and sortal information. An example of a VIT for the sentence Montag ist gut (&apos;Monday is fine&apos;) is given in (1). 4 Approaches to Robustness There are three </context>
</contexts>
<marker>Kamp, Reyle, 1993</marker>
<rawString>Hans Kamp and Uwe Reyle. 1993. From Discourse to Logic. Kluwer, Dordrecht.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christine Nakatani</author>
<author>Julia Hirschberg</author>
</authors>
<title>A speech-first model for repair detection and correction.</title>
<date>1993</date>
<booktitle>In Proc. of the 31 th ACL,</booktitle>
<pages>46--53</pages>
<location>Columbus, OH.</location>
<contexts>
<context position="5988" citStr="Nakatani and Hirschberg, 1993" startWordPosition="895" endWordPosition="898">tic information as well as tense and aspect and sortal information. An example of a VIT for the sentence Montag ist gut (&apos;Monday is fine&apos;) is given in (1). 4 Approaches to Robustness There are three stages in processing where a speech understanding system can be made more robust against spontaneous speech phenomena and recognizer errors: before, during, or after parsing. While we do not see them as mutually exclusive, we think that the first two present significant problems. 4.1 Before parsing Detection of self corrections on transcriptions before parsing has been explored (Bear et al., 1992; Nakatani and Hirschberg, 1993), but it is not clear that it will be feasible on WHGs, since recognition errors interfere and the search space may explode due to the number of paths. Dealing with recognition errors before parsing is impossible due to lack of structural information. 4.2 During parsing Treating the phenomena mentioned during parsing would mean that the grammar or the parser would have to be made more liberal, i. e. they would have to accept strings which are ungrammatical. This is problematic in the context of WHG parsing, since the parser has to simultaneously perform two tasks: Searching for a path to be an</context>
</contexts>
<marker>Nakatani, Hirschberg, 1993</marker>
<rawString>Christine Nakatani and Julia Hirschberg. 1993. A speech-first model for repair detection and correction. In Proc. of the 31 th ACL, pages 46-53, Columbus, OH.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carolyn Penstein Rosé</author>
</authors>
<title>Robust Interactive Dialogue Interpretation.</title>
<date>1997</date>
<tech>Ph.D. thesis,</tech>
<institution>Carnegie Mellon University,</institution>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="16137" citStr="Rosé, 1997" startWordPosition="2565" endWordPosition="2566">or Am Montag treffe . . . habe ich einen Termin. 19: ich I 46: einen tennin 57: einen termin 46 1: treffe 1 1habe 20: habe+ich 110,191 105: am montaq+habe+ich+einen termin 162,471 am mon 21: habe+Ich 110,191 106: ffe+Ich 11,191 107: ffe+Ich 11,191 47: habe+ich men termin 120,461 108: am montaq+treffe+ich [71,19] There, it finds an edge corresponding to a proposition, namely edge 47, which had been built up earlier. The result is passive edge 105 spanning the whole input and expressing the right interpretation. 6 Related Work An approach similar to the one described here was developed by Rosé (Rosé, 1997). However, that approach works on interlingual representations of utterance meanings, which implies the loss of all linguistic constraints on the combinatorics of partial analyses. Apart from that, only the output of one parser is considered. 7 Conclusion and Outlook We have described a model for the combination of partial parsing results and how it can be applied in order to improve the robustness of a speech processing system. A prototype version was integrated into the Verbmobil system in autumn 1997 and is currently being extended. We are working on improving the selection of results by us</context>
</contexts>
<marker>Rosé, 1997</marker>
<rawString>Carolyn Penstein Rosé. 1997. Robust Interactive Dialogue Interpretation. Ph.D. thesis, Carnegie Mellon University, Pittsburgh, PA. Language Technologies Institute.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wolfgang Wahlster</author>
</authors>
<title>Verbmobil: Erkennung, Analyse, Transfer,</title>
<date>1997</date>
<booktitle>Generierung und Synthese von Spontansprache. Verbmobil-Report 198, DFKI GmbH, Saarbrficken,</booktitle>
<contexts>
<context position="1196" citStr="Wahlster, 1997" startWordPosition="181" endWordPosition="182">spanning the whole input can be achieved, owing to spontaneous speech phenomena or speech recognition errors. 1 Introduction In this paper we describe the function and design of the robust semantic processing component which we are currently developing in the context of the Verbmobil speech translation project. We aim at improving the system&apos;s performance in terms of coverage and quality of translations by combining fragmentary analyses when no spanning analysis of the input can be derived because of spontaneous speech phenomena or speech recognition errors. 2 The Verbmobil Context Verbmobil (Wahlster, 1997) is a large scale research project in the area of spoken language translation. Its goal is to develop a system that translates negotiation dialogues between speakers of German, English and Japanese in face-to-face or video conferencing situations. The integrated system developed during the first project phase (1993-96), the Research Prototype, was successfully demonstrated • The author wishes to thank his colleagues Johan Bos, Aljoscha Burchardt, Bjorn GambUck, Walter Kasper, Bernd Kiefer, Uli Krieger, Manfred Pinkal, Tobias Ruland, C. J. Rupp, Jorg Spilker, and Hans Weber for their collaborat</context>
</contexts>
<marker>Wahlster, 1997</marker>
<rawString>Wolfgang Wahlster. 1997. Verbmobil: Erkennung, Analyse, Transfer, Generierung und Synthese von Spontansprache. Verbmobil-Report 198, DFKI GmbH, Saarbrficken, June.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>