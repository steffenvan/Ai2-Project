<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.001786">
<title confidence="0.943248">
Word Translation Based on Machine Learning Models
Using Translation Memory and Corpora
</title>
<author confidence="0.914644">
Kiyotaka Uchimotot, Satoshi Sekinet, Masaki Muratat, and Hitoshi Isaharat
</author>
<affiliation confidence="0.957236">
t Communications Research Laboratory tNew York University
</affiliation>
<address confidence="0.9627425">
2-2-2, Hikari-dai, Seika-cho, Soraku-gun, 715 Broadway, 7th floor
Kyoto, 619-0289 Japan New York, NY 10003, USA
</address>
<email confidence="0.996533">
fuchimoto, murata, isaharal@crl.go.jp sekine@cs.nyu.edu
</email>
<sectionHeader confidence="0.995557" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999802857142857">
SENSEVAL-2 was held in Spring, 2001. It con-
sisted of several tasks in various languages. In
this paper, we describe our system used for one
of these tasks: the Japanese translation task.
With an accuracy of 63.4%, our system was the
third best system in the contest among nine sys-
tems developed by seven groups.
</bodyText>
<sectionHeader confidence="0.998522" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999907176470588">
In the Japanese translation task, the senses of a
word were defined in terms of the word&apos;s trans-
lations. Given an input sentence and a target
word in the sentence, our system first estimates
the similarity between the input sentence and
parallel example sets called &amp;quot;Translation Mem-
ory&amp;quot;. It then selects an appropriate transla-
tion of the target word by using the example
set with the highest similarity. The similarity
is calculated using dynamic programming and
a machine learning model, which assesses the
similarity based on the similarity of a string,
words to the left and to the right of the target
word in the input sentence, content words in
the input sentence and their translations, and
co-occurrence of content words in bilingual and
monolingual corpora in English and Japanese.
</bodyText>
<sectionHeader confidence="0.971528" genericHeader="method">
2 Japanese Translation Task
</sectionHeader>
<bodyText confidence="0.9999012">
In general, the definition of word senses depends
on the goal of a task. The goal of the Japanese
translation task is word selection in translation,
where the target language is English. Therefore,
word senses are defined as translations (trans-
lated words/phrases).
Before the contest, a Japanese-English par-
allel phrase/sentence set (Translation Memory,
henceforth referred to as TM) was given to the
participants as training data. In the TM, for
each Japanese headword, there was a set of pairs
of a Japanese expression including a headword
and an English translation of the expression.
We call these pairs examples. Some of the ex-
amples are shown in Figure 1.
</bodyText>
<figure confidence="0.956972105263158">
&lt;entry id= &amp;quot;1&amp;quot; headword= &amp;quot;Air&gt;
&lt;sense id= &amp;quot;1-1&amp;quot;&gt;
&lt;expression&gt; at:Alf:1-Z &lt;/jexpression&gt;
&lt;eexpression&gt;to feel constrained for one&apos;s
mother&lt;/eexpression&gt;
&lt;/sense&gt;
&lt;sense id= &amp;quot;1-2&amp;quot;&gt;
&lt;jexpression&gt; a-N0)itt$ &lt;/jexpression&gt;
&lt;eexpression&gt;constraint toward one&apos;s
mother&lt;/eexpression&gt;
&lt;transmemo&gt;UC&lt;/transmemo&gt;
&lt;/sense&gt;
&lt;sense id= &amp;quot;1-3&amp;quot;&gt;
&lt;expression&gt; t-3Arg L, 6 -3
&lt;/jexpression&gt;
&lt;eexpression&gt;to request to refrain from
donation&lt;/eexpression&gt;
&lt;/sense&gt;
&lt;/entry&gt;
</figure>
<figureCaption confidence="0.999994">
Figure 1: Examples in TM.
</figureCaption>
<bodyText confidence="0.999907571428571">
In the formal test (contest), the participants
were given a set of texts each of which was
marked by a target word. For each target word,
the participants were required to submit either
a sense id of the example (the number assigned
to each example in the TM), which can be used
to translate the target word, or a translation of
the target word. In the latter case, a translation
of the word itself, a translation of a sequence of
words including the target word, or a transla-
tion of the whole sentence could be submitted.
Answers were prepared for each target word
in the formal test. The answers could consist
of one or more sense id&apos;s in the TM, or of pos-
sible translations. The output of each system
was evaluated in terms of accuracy, defined as
a percentage of answers identified correctly by
the system. An answer was judged to have been
identified correctly when a sense id or a trans-
lation selected by the system was found in the
answer.
</bodyText>
<page confidence="0.999411">
155
</page>
<sectionHeader confidence="0.993468" genericHeader="method">
3 Word Translation Model
</sectionHeader>
<bodyText confidence="0.999248928571428">
Given an input sentence and a target word in
the sentence, our model selects an appropriate
translation of the target word or a sense id of
examples appropriate for the translation of the
target word by using examples with the high-
est similarity, estimated between the examples
and the input sentence. In this paper, we call
this model a word translation model. The source
language is Japanese and the target language
in translation is English. Henceforth we call a
headword translation an English headword.
The similarity between an input sentence and
examples is calculated by the following two
methods:
</bodyText>
<listItem confidence="0.966885571428571">
1. A method based on the similarity of a string
of characters (Method 1) : The similarity is
defined as the amount of agreement between
an input sentence and a Japanese example, ex-
pressed as a percentage.
2. A method based on machine learning models
(Method 2) : The similarity is defined as the
</listItem>
<bodyText confidence="0.94111752631579">
confidence or probability estimated by machine
learning models. English headwords are used as
classes (or categories) in machine learning mod-
els. Since the TM has examples with the same
English headword, the similarity estimated by
a model is the similarity between the input sen-
tence and a set of examples.
A model is prepared for each Japanese head-
word. Given an input sentence, the similarity
between the input sentence and each example is
calculated by a model using Method I. If the
similarity is equal to or greater than a certain
threshold, the model returns either the sense id
of the example with the highest similarity or an
English headword of the example. Otherwise, a
model in Method 2 selects and returns an En-
glish headword.
The following sections describe the two meth-
ods in greater detail.
</bodyText>
<subsectionHeader confidence="0.997478">
3.1 Method Based on the Similarity of
A String of Characters (Method 1)
</subsectionHeader>
<bodyText confidence="0.960087534883721">
When an example with the highest similarity
is found, it is given the highest priority, and
either the sense id or the English headword of
the example is selected as an output.
When calculating the agreement rate between
an input sentence and an example, the right-
most word of the Japanese example is stemmed.
In other words, when the rightmost word is
a function word or a auxiliary verb such as
&amp;quot;SURU (do)&amp;quot;, it is eliminated. When the right-
most word is a predicate, its inflectional part
is also eliminated. For example, the stemmed
examples in Figure I are
0) AHS,&amp;quot; , and &amp;quot;4,7,-itHE&amp;quot;, respectively. The
agreement rate is calculated as a percentage of
characters in the Japanese example that cor-
respond to those in the input sentence. The
correspondence is evaluated by comparing the
Japanese example and the input sentence char-
acter by character. This can be done by using
the UNIX command &amp;quot;diff&amp;quot; in a dynamic pro-
gramming method. 1 The similarity is calcu-
lated by using the following equation.
(
the number of characters )
corresponding to characters j
in input sentence
Similarity ,
the number of characters in
stemmed Japanese example ) (1)
(
When several examples with the highest sim-
ilarity are found, the one having the longest
Japanese example is selected except when the
length of corresponding part is shorter than that
of the Japanese headword.
However, it is unrealistic to expect that an
example that is almost the same as the input
sentence can be found because it is difficult
to install all possible examples into the TM.
So, when there is no example whose similarity
is equal to or greater than the threshold, the
method described in the next section is used.
</bodyText>
<subsectionHeader confidence="0.846986">
3.2 Method Based on Machine
Learning Models (Method 2) 2
</subsectionHeader>
<bodyText confidence="0.999968307692308">
To select an appropriate example with the same
usage as that of the input sentence, the sim-
ilarity must be calculated by extracting the
most important information from various con-
flicting sources of information related to the in-
put sentence and examples. Since we want to
avoid making complicated rules, we use machine
learning models to calculate the similarity. In-
stead of all examples in the TM, English head-
words are used as classes in machine learning
models. Therefore, examples having the same
English headword are put into the same class
and are considered to have the same similarity.
</bodyText>
<footnote confidence="0.8357586">
1A description on how to use &amp;quot;diff&amp;quot; can be found in
(Murata and Isahara, 2001).
2Work on using machine learning methods for the
translation of tenses, aspects, and modalities can be
found-in (Murata et at, 2001a).
</footnote>
<page confidence="0.996725">
156
</page>
<bodyText confidence="0.999939736842105">
Classes identified by machine learning mod-
els are basically English headwords in TM, and
they are detected manually. For example, En-
glish headwords of the examples in Figure 1
are &amp;quot;feel constrained&amp;quot;, &amp;quot;constraint&amp;quot;, and &amp;quot;re-
frain&amp;quot;, respectively. When English headwords
are verbs, they are represented by their basic
forms. English words obtained when a Japanese
headword is looked up in a Japanese-English
dictionary are also used as classes.
For the training data, we use not only ex-
amples in the TM but also other data col-
lected from bilingual dictionaries or a par-
allel corpus. The collected data consist of
Japanese-English parallel phrases/sentences in-
cluding both Japanese and English headwords,
and they are used as complements of the train-
ing data.
For the machine learning models, we use SVM
(Support Vector Machine), ME (Maximum En-
tropy), DL (Decision list), and SB (Simple
Bayes). For each Japanese headword, the best
model with the highest accuracy in 10-hold
cross-validation on the training data is used for
testing. The confidence of each class is esti-
mated by probability distribution p(a, b), where
b is a context in a set of contexts, B, and a is a
class in a set of classes, A. SVM is a classifier,
and in this model, the confidence of each class
cannot be represented by a probability distribu-
tion, but for the sake of convenience, we assign
probability 1 to the most confident class esti-
mated by SVM, and 0 to all other classes. The
parameters in each model follow those used in
(Murata et al., 2001b). Context b is represented
by a set of features, that is, information deriv-
able from the training data. The features used
in our experiments were as follows:
</bodyText>
<sectionHeader confidence="0.478888" genericHeader="method">
1. Morphological information
</sectionHeader>
<bodyText confidence="0.9994142">
The string, basic form, major and minor parts
of speech, and inflection type on six mor-
phemes, three morphemes to the left and three
morphemes to the right of the target word in
an input sentence.
</bodyText>
<listItem confidence="0.62293375">
2. Character n-gram
Character n-grams in an input sentence. Each
n-gram must include the target word.
3. Highest matching
</listItem>
<bodyText confidence="0.879847333333333">
An English headword in the example that has
the longest string matching that of the input
sentence and its length are used as features.
</bodyText>
<listItem confidence="0.5099455">
4. Frequency of a content word and its translation
candidates
</listItem>
<bodyText confidence="0.95700425">
We define a set of examples including the same
English headword as an example set. For each
English headword, we define the following six
example sets:
</bodyText>
<table confidence="0.9934854">
Example set 1 Japanese examples
Example set 2 English examples
Example set 3 Sentences similar to examples in
Example set 1. They are collected from a
Japanese monolingual corpus.
Example set 4 Sentences similar to examples in
Example set 2. They are collected from an
English monolingual corpus.
Example set 5 Union of Example sets 1 and 3
Example set 6 Union of Example sets 2 and 4
</table>
<bodyText confidence="0.999172135135135">
For each example set, Japanese-English par-
allel phrases/sentences including both Japanese
and English headwords are collected from bilin-
gual dictionaries or parallel corpora, and are
added to the example set.
Sentences similar to a certain example are de-
fined as sentences that include a substring of
the example. The substring must include the
headword of the example. In our model, we use
sentences collected from a monolingual corpus
because we want the model to reflect a real dis-
tribution of words, both headwords and words
to the left and right of the headwords.
As content words, we used nouns, verbs, ad-
jectives, adverbs, and attributives, except head-
words, in the input sentence. For each content
word in an input sentence and its translation
candidates, the frequencies in each example set
were used as features. The translation candi-
dates of a content word were obtained when
the content word was looked up in a Japanese-
English dictionary. Each feature is represented
by a combination of an example set, a head-
word, and the frequency of content words in the
example set. When we find that the total fre-
quency of content words in an example set is n,
we assume that every feature whose frequency
is between 1 and n is observed. For example,
when the content word found in the given sen-
tence is &amp;quot;mother&amp;quot;, and it is found three times in
the example set 1 for the headword &amp;quot;buy&amp;quot;, the
features &amp;quot;Example set 1 : buy : 1,&amp;quot; &amp;quot;Example
set 1 : buy : 2,&amp;quot; and &amp;quot;Example set 1 : buy :
3&amp;quot; are assumed to be observed. By using these
features, our model handles information about
co-occurrence words of a headword in each cor-
pus as a clue to translating the headword.
</bodyText>
<page confidence="0.997527">
157
</page>
<sectionHeader confidence="0.992105" genericHeader="method">
4 Experiment
</sectionHeader>
<subsectionHeader confidence="0.999162">
4.1 Experimental conditions
</subsectionHeader>
<bodyText confidence="0.999810736842105">
The input and evaluation of the systems fol-
lowed those of the Japanese translation task
in SENSEVAL-2. A TM for 320 headwords
was given to each participant in the middle of
March, 2001. The average number of exam-
ples prepared for each headword was approxi-
mately 20. For the formal test, 40 target words
(20 nouns and 20 verbs) were selected from the
headwords. For each target word, 30 texts in-
cluding the target words were prepared. The
total number of the target words was 1,200.
As a bilingual dictionary, we used &amp;quot;EI-
JIRO&amp;quot; available at the web site of NIFTY,
a network provider. As monolingual corpora,
we used MAINICHI newspapers from 1991 to
2000, NIKKEI newspapers from 1995 to 1999,
SANKEI newspapers from 1994 to 1999, and
LDC data collected in 1994 and 1995, which
include English newspaper articles for several
years published by the Wall Street Journal, the
Associated Press Writer, and the New York
Times.
In the formal test, the threshold of similarity
used in Method 1 was 1. JUMAN (Kurohashi
and Nagao, 1999), a Japanese morphological an-
alyzer, was used for morphological analysis in
Method 2. As sentences similar to a certain
example in Method 2, sentences that included
a string obtained by stemming Japanese exam-
ples were extracted for Japanese examples, and
sentences that included English headwords were
extracted for English examples. As for the ma-
chine learning models, we could not select the
most appropriate set of models by cross vali-
dation because not all learning processes could
be finished by the deadline for submission. The
models finally selected for the formal test were
as follows:
</bodyText>
<listItem confidence="0.999772">
• SVM : 23 words (12 nouns and 11 verbs)
• DL : 12 words (8 nouns and 4 verbs)
• SB : 5 words (5 verbs)
</listItem>
<sectionHeader confidence="0.9285385" genericHeader="method">
4.2 Experimental Results and
Discussion
</sectionHeader>
<bodyText confidence="0.9594549">
The accuracy obtained by our system in the
formal test was 63.4% (761/1,200). The accu-
racy obtained by Method 1 and 2 were 91.0%
(91/100) and 60.9% (670/1,100), respectively.
Based on our results, we can draw the following
conclusions:
• The system performance was related to the
amount of training data per class in Method 2.
• The accuracy obtained for words whose En-
glish headwords were general words was not
high even though there were more training data
for these words than for other headwords for
which the accuracy was high. We believe that
this is due to the quality of automatically col-
lected training data because general words ap-
pear in corpora quite frequently, and sometimes
parallel sentences where Japanese and English
headwords are not related to each other are
collected. Therefore, we need to select auto-
matically collected parallel sentences by align-
ing Japanese and English headwords.
• Method 1 improved the accuracy, especially for
idiomatic expressions that rarely appeared in
the training data. We applied Method 2 to the
target words to which Method 1 was applied
in the formal test, and achieved an even lower
accuracy of 34.0%(34/100).
• The accuracy obtained by the SB model was
low. We speculate that the SB model is not
suitable for the feature sets used in the test.
</bodyText>
<sectionHeader confidence="0.993563" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999984875">
This paper described our system used in
SENSEVAL-2. Our model for word translation
has the following characteristics: (1) It puts to-
gether examples having the same English head-
word into a set of examples, and selects a set of
examples most similar to the input sentence by
using machine learning models. (2) If an exam-
ple that is almost the same as the input sentence
is found, our model gives it the highest priority.
(3) It automatically collects training data and
information used for training from other lan-
guage resources that are not only a bilingual
corpus but also monolingual corpora of English
and Japanese. We do not have to supervise any-
thing except the detection of headword pairs in
the examples.
</bodyText>
<sectionHeader confidence="0.998089" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999157357142857">
Sadao Kurohashi and Makoto Nagao, 1999. Japanese Mor-
phological Analysis System JUMAN Version 3.61. De-
partment of Informatics, Kyoto University.
Masaki Murata and Hitoshi Isahara. 2001. NLP using DIFF.
In IPSJ-WGNL NLI44-18, pages 127-134. (in Japanese).
Masaki Murata, Kiyotaka Uchimoto, Qing Ma, and Hi-
toshi Isahara. 2001a. Using a Support-Vector Machine
for Japanese-to-English Translation of Tense, Aspect, and
Modality. In ACL Workshop on the Data-Driven Machine
Translation.
Masaki Murata, Masao Utiyama, Kiyotaka Uchimoto, Qing
Ma, and Hitoshi Isahara. 2001b. Experiments on Word
Sense Disambiguation Using Several Machine-leaning
Methods. In IEICE-WGNLC2001-2. (in Japanese).
</reference>
<page confidence="0.997088">
158
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.956708">
<title confidence="0.999353">Word Translation Based on Machine Learning Using Translation Memory and Corpora</title>
<author confidence="0.985031">Kiyotaka Uchimotot</author>
<author confidence="0.985031">Satoshi Sekinet</author>
<author confidence="0.985031">Masaki Muratat</author>
<author confidence="0.985031">Hitoshi Isaharat</author>
<affiliation confidence="0.999945">t Communications Research Laboratory tNew York University</affiliation>
<address confidence="0.9951865">2-2-2, Hikari-dai, Seika-cho, Soraku-gun, 715 Broadway, 7th floor Kyoto, 619-0289 Japan New York, NY 10003, USA</address>
<email confidence="0.999414">fuchimoto,murata,isaharal@crl.go.jpsekine@cs.nyu.edu</email>
<abstract confidence="0.997728">held in Spring, 2001. It consisted of several tasks in various languages. In this paper, we describe our system used for one of these tasks: the Japanese translation task. an accuracy of system was the third best system in the contest among nine systems developed by seven groups.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Sadao Kurohashi</author>
<author>Makoto Nagao</author>
</authors>
<date>1999</date>
<booktitle>Japanese Morphological Analysis System JUMAN Version 3.61.</booktitle>
<institution>Department of Informatics, Kyoto University.</institution>
<contexts>
<context position="13476" citStr="Kurohashi and Nagao, 1999" startWordPosition="2262" endWordPosition="2265">ding the target words were prepared. The total number of the target words was 1,200. As a bilingual dictionary, we used &amp;quot;EIJIRO&amp;quot; available at the web site of NIFTY, a network provider. As monolingual corpora, we used MAINICHI newspapers from 1991 to 2000, NIKKEI newspapers from 1995 to 1999, SANKEI newspapers from 1994 to 1999, and LDC data collected in 1994 and 1995, which include English newspaper articles for several years published by the Wall Street Journal, the Associated Press Writer, and the New York Times. In the formal test, the threshold of similarity used in Method 1 was 1. JUMAN (Kurohashi and Nagao, 1999), a Japanese morphological analyzer, was used for morphological analysis in Method 2. As sentences similar to a certain example in Method 2, sentences that included a string obtained by stemming Japanese examples were extracted for Japanese examples, and sentences that included English headwords were extracted for English examples. As for the machine learning models, we could not select the most appropriate set of models by cross validation because not all learning processes could be finished by the deadline for submission. The models finally selected for the formal test were as follows: • SVM</context>
</contexts>
<marker>Kurohashi, Nagao, 1999</marker>
<rawString>Sadao Kurohashi and Makoto Nagao, 1999. Japanese Morphological Analysis System JUMAN Version 3.61. Department of Informatics, Kyoto University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaki Murata</author>
<author>Hitoshi Isahara</author>
</authors>
<title>NLP using DIFF.</title>
<date>2001</date>
<booktitle>In IPSJ-WGNL NLI44-18,</booktitle>
<pages>127--134</pages>
<note>(in Japanese).</note>
<contexts>
<context position="7847" citStr="Murata and Isahara, 2001" startWordPosition="1291" endWordPosition="1294">usage as that of the input sentence, the similarity must be calculated by extracting the most important information from various conflicting sources of information related to the input sentence and examples. Since we want to avoid making complicated rules, we use machine learning models to calculate the similarity. Instead of all examples in the TM, English headwords are used as classes in machine learning models. Therefore, examples having the same English headword are put into the same class and are considered to have the same similarity. 1A description on how to use &amp;quot;diff&amp;quot; can be found in (Murata and Isahara, 2001). 2Work on using machine learning methods for the translation of tenses, aspects, and modalities can be found-in (Murata et at, 2001a). 156 Classes identified by machine learning models are basically English headwords in TM, and they are detected manually. For example, English headwords of the examples in Figure 1 are &amp;quot;feel constrained&amp;quot;, &amp;quot;constraint&amp;quot;, and &amp;quot;refrain&amp;quot;, respectively. When English headwords are verbs, they are represented by their basic forms. English words obtained when a Japanese headword is looked up in a Japanese-English dictionary are also used as classes. For the training dat</context>
</contexts>
<marker>Murata, Isahara, 2001</marker>
<rawString>Masaki Murata and Hitoshi Isahara. 2001. NLP using DIFF. In IPSJ-WGNL NLI44-18, pages 127-134. (in Japanese).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaki Murata</author>
<author>Kiyotaka Uchimoto</author>
<author>Qing Ma</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Using a Support-Vector Machine for Japanese-to-English Translation of Tense, Aspect, and Modality.</title>
<date>2001</date>
<booktitle>In ACL Workshop on the Data-Driven Machine Translation.</booktitle>
<contexts>
<context position="9504" citStr="Murata et al., 2001" startWordPosition="1572" endWordPosition="1575">Japanese headword, the best model with the highest accuracy in 10-hold cross-validation on the training data is used for testing. The confidence of each class is estimated by probability distribution p(a, b), where b is a context in a set of contexts, B, and a is a class in a set of classes, A. SVM is a classifier, and in this model, the confidence of each class cannot be represented by a probability distribution, but for the sake of convenience, we assign probability 1 to the most confident class estimated by SVM, and 0 to all other classes. The parameters in each model follow those used in (Murata et al., 2001b). Context b is represented by a set of features, that is, information derivable from the training data. The features used in our experiments were as follows: 1. Morphological information The string, basic form, major and minor parts of speech, and inflection type on six morphemes, three morphemes to the left and three morphemes to the right of the target word in an input sentence. 2. Character n-gram Character n-grams in an input sentence. Each n-gram must include the target word. 3. Highest matching An English headword in the example that has the longest string matching that of the input se</context>
</contexts>
<marker>Murata, Uchimoto, Ma, Isahara, 2001</marker>
<rawString>Masaki Murata, Kiyotaka Uchimoto, Qing Ma, and Hitoshi Isahara. 2001a. Using a Support-Vector Machine for Japanese-to-English Translation of Tense, Aspect, and Modality. In ACL Workshop on the Data-Driven Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Masaki Murata</author>
<author>Masao Utiyama</author>
<author>Kiyotaka Uchimoto</author>
<author>Qing Ma</author>
<author>Hitoshi Isahara</author>
</authors>
<title>Experiments on Word Sense Disambiguation Using Several Machine-leaning Methods. In IEICE-WGNLC2001-2.</title>
<date>2001</date>
<note>(in Japanese).</note>
<contexts>
<context position="9504" citStr="Murata et al., 2001" startWordPosition="1572" endWordPosition="1575">Japanese headword, the best model with the highest accuracy in 10-hold cross-validation on the training data is used for testing. The confidence of each class is estimated by probability distribution p(a, b), where b is a context in a set of contexts, B, and a is a class in a set of classes, A. SVM is a classifier, and in this model, the confidence of each class cannot be represented by a probability distribution, but for the sake of convenience, we assign probability 1 to the most confident class estimated by SVM, and 0 to all other classes. The parameters in each model follow those used in (Murata et al., 2001b). Context b is represented by a set of features, that is, information derivable from the training data. The features used in our experiments were as follows: 1. Morphological information The string, basic form, major and minor parts of speech, and inflection type on six morphemes, three morphemes to the left and three morphemes to the right of the target word in an input sentence. 2. Character n-gram Character n-grams in an input sentence. Each n-gram must include the target word. 3. Highest matching An English headword in the example that has the longest string matching that of the input se</context>
</contexts>
<marker>Murata, Utiyama, Uchimoto, Ma, Isahara, 2001</marker>
<rawString>Masaki Murata, Masao Utiyama, Kiyotaka Uchimoto, Qing Ma, and Hitoshi Isahara. 2001b. Experiments on Word Sense Disambiguation Using Several Machine-leaning Methods. In IEICE-WGNLC2001-2. (in Japanese).</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>