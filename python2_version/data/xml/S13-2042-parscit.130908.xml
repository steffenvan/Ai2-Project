<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000003">
<title confidence="0.986949333333333">
UMCC_DLSI: Reinforcing a Ranking Algorithm with Sense
Frequencies and Multidimensional Semantic Resources to solve
Multilingual Word Sense Disambiguation
</title>
<note confidence="0.479393538461538">
Yoan Gutiérrez, Yenier Antonio Fernández Orquín, Franc Camara
Castañeda, Andy González, Andrés Montoyo, Rafael Muñoz
Rainel Estrada, Dennys D. Piug,
Jose I. Abreu, Roger Pérez
DI, University of Matanzas DLSI, University of Alicante Independent Consultant
Matanzas, Cuba Alicante, Spain USA
{yoan.gutierrez, antonybr@yahoo.com, info@franccamara.c
yenier.castaneda, {montoyo,rafael}@dlsi.ua. om
rainel.estrada, es
dennys.puig, jose.abreu,
roger.perez}@umcc.cu,
andy.gonzalez@infonet.umcc
.cu
</note>
<sectionHeader confidence="0.929232" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99856825">
This work introduces a new unsupervised
approach to multilingual word sense
disambiguation. Its main purpose is to
automatically choose the intended sense
(meaning) of a word in a particular context for
different languages. It does so by selecting the
correct Babel synset for the word and the
various Wiki Page titles that mention the
word. BabelNet contains all the output
information that our system needs, in its Babel
synset. Through Babel synset, we find all the
possible Synsets for the word in WordNet.
Using these Synsets, we apply the
disambiguation method Ppr+Freq to find what
we need. To facilitate the work with WordNet,
we use the ISR-WN which offers the
integration of different resources to WordNet.
Our system, recognized as the best in the
competition, obtains results around 69% of
Recall.
</bodyText>
<sectionHeader confidence="0.993483" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998922228571429">
Word Sense Disambiguation (WSD) focuses on
resolving the semantic ambiguity of a given word.
This is an important task in Natural Language
Processing (NLP) because in many applications,
such as Automatic Translation, it is essential to
know the exact meaning of a word in a given
context. In order to solve semantic ambiguity,
different systems have been developed. However,
we can categorize them in two main groups:
supervised and unsupervised systems. The
supervised ones need large quantity of hand-tagged
data in order to gather enough information to build
rules, train systems, and so on. Unsupervised
systems, on the other hand, do not need such a
large amount of hand-tagged datasets. This means
that, when there aren’t enough corpora to train the
systems, an unsupervised system is a good option.
A sub-task of WSD is Multilingual Word Sense
Disambiguation (MWSD) (Navigli et al., 2013)
that aims at resolving ambiguities in different
languages.
In a language, there are words that have only one
sense (or meaning), but in other languages, the
same words can have different senses. For
example, “patient” is a word that in English can be
either a noun or an adjective, but in German, it
only has one sense - “viz” (a person that needs
treatment). This shows that the information
obtained by combining two languages can be more
useful for WSD because the word senses in each
language can complement each other. For it to be
useful, MWSD needs a multilingual resource that
contains different languages, such as BabelNet
(Navigli and Ponzetto, 2010; 2012) and
EuroWordNet (Vossen, 1998).
</bodyText>
<note confidence="0.595196666666667">
241
Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic
Evaluation (SemEval 2013), pages 241–249, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics
</note>
<bodyText confidence="0.996449761904762">
As the preferred disambiguation method, we
decided to use the Ppr+Freq (Personalized Page
Rank combined with Frequencies of senses)
(Gutiérrez, 2012) method because, among
unsupervised systems, graph-based methods have
obtained more promising results.
It is worth mentioning the relevant approaches
used by the scientific community to achieve
promising results. One approach used is structural
interconnections, such as Structural Semantic
Interconnections (SSI), which create structural
specifications of the possible senses for each word
in a context (Navigli and Velardi, 2005). The other
approaches used are “Exploring the integration of
WordNet” (Miller et al., 1990), FrameNet (Laparra
et al., 2010) and those using Page-Rank such as
(Sinha and Mihalcea, 2007) and (Agirre and Soroa,
2009).
The aforementioned types of graph based
approaches have achieved relevant results in both
the SensEval-2 and SensEval-3 competitions (see
</bodyText>
<tableCaption confidence="0.828126">
Table 1).
</tableCaption>
<table confidence="0.9991356">
Algorithm Recall
TexRank (Mihalcea, 2005) 54.2%
(Sinha and Mihalcea, 2007) 56.4%
(Tsatsaronis et al., 2007) 49.2%
Ppr (Agirre and Soroa, 2009) 58.6%
</table>
<tableCaption confidence="0.988618666666667">
Table 1. Relevant WSD approaches. Recall measure is
calculated recalls using SensEval-2 (English All Word
task) guidelines over.
</tableCaption>
<bodyText confidence="0.999397111111111">
Experiments using SensEval-2 and SensEval-3
corpora suggest that Ppr+Freq (Gutiérrez, 2012)
can lead to better results by obtaining over 64% of
Recall. Therefore we selected Ppr+Freq as the
WSD method for our system.
The key proposal for this work is an
unsupervised algorithm for MWSD, which uses an
unsupervised method, Ppr+Freq, for semantic
disambiguation with resources like BabelNet (as
sense inventory only) (Navigli and Ponzetto, 2010)
and ISR-WN (as knowledge base) (Gutiérrez et al.,
2011a; 2010a).
ISR-WN was selected as the default knowledge
base because of previous NLP research, which
included: (Fernández et al., 2012; Gutiérrez et al.,
2010b; Gutiérrez et al., 2012; 2011b; 2011c;
2011d), which achieved relevant results using ISR-
WN as their knowledge base.
</bodyText>
<sectionHeader confidence="0.811767" genericHeader="method">
2 System architecture
</sectionHeader>
<bodyText confidence="0.999926096774194">
By using one of BabelNet (BN) features, our
technique begins by looking for all the Babel
synsets (Bs) linked to the lemma of each word in
the sentence that we need to disambiguate.
Through the Bs offsets, we can get its
corresponding WordNet Synset (WNS), which
would be retrieved from WordNet (WN) using the
ISR-WN resource. As a result, for each lemma, we
have a WordNet Synset List (WNSL) from which
our Word Sense Disambiguation method obtains
one WNS as the correct meaning.
Our WSD method consists of applying a
modification of the Personalizing PageRank (Ppr)
algorithm (Agirre and Soroa, 2009), which
involves the senses frequency. More specifically,
the key proposal is known as Ppr+Freq (see
Section 2.3).
Given a set of WNSLs of WNSL, as words
window, we applied the Synsets ranking method,
Ppr+Freq, which ranks in a descending order, the
Synsets of each lemma according to a calculated
factor of relevance. The first Synset (WNS) of
each WNSL (the most relevant) is established as
the correct one and its associated Babel synset (Bs)
is also tagged as correct. To determine the Wiki
Page Titles (WK), we examine the WIKI
(Wikipedia pages) and WIKIRED (Wikipedia
pages redirections) in the correct Babel synset
obtained.
Figure 1 shows a general description of our
system that is made up of the following steps:
</bodyText>
<listItem confidence="0.8384168">
I. Obtaining lemmas
II. Obtaing WN Synset of selected lemmas
III. Applying Ppr+Freq method
IV. Assigning Synset, Babel synset and Wiki
page title
</listItem>
<bodyText confidence="0.990665666666667">
Note that ISR-WN contains WN as its nucleus.
This allows linking both resources, BabelNet and
ISR-WN.
</bodyText>
<figure confidence="0.5977625">
242
“ The struggle against the drug lords in Colombia will be a near thing.”
</figure>
<figureCaption confidence="0.993468">
Figure 1. General process description taking as instance a sentence provided by the trial dataset.
</figureCaption>
<figure confidence="0.988967074074074">
Wikipedia WordNet
WN key struggle%1:04:01:: drug_lord%1:18:00:: colombia%1:15:00::
BS bn:00009079n bn:00028876n bn:00020697n
WK -- Drug_Lord Colombia
struggle drug_lord Colombia
II. Obtaining Synset of selected lemmas
IV . Assigning Synset, Babel Synset and Wiki page title
struggle
III. Applying Ppr+Freq method
drug_lord
BabelNet
Colombia
I.Obtaing lemmas
WN-Domain
SemanticClass
WordNet
(WN)
near_thing
ISR-WN
eXtended WN3.0
eXtended WN1.7
near_thing%1:04:00::
bn:00057109n
near_thing
WN-Affect
SUMO
--
</figure>
<subsectionHeader confidence="0.989194">
2.1 Obtaining lemmas
</subsectionHeader>
<bodyText confidence="0.9830388">
For each input sentence, we extract the labeled
lemmas. As an example, for the sentence, “The
struggle against the drug lords in Colombia will be
a near thing,” the selected lemmas are: “struggle,”
“drug_lord,” “Colombia”, and “near_thing.”
</bodyText>
<figureCaption confidence="0.992309">
Figure 2. Obtaining synset of lemmas.
</figureCaption>
<subsectionHeader confidence="0.99925">
2.2 Obtaing WI Synset of selected lemmas
</subsectionHeader>
<bodyText confidence="0.9999551">
For each lemma obtained in the previous section,
we look through BabelNet to recover the Bs that
contains the lemma among its labels. When BSs
are mapped to WN, we use the ISR-WN resource
to find the corresponding Synset. Since a lemma
can appear in a different Bs, it can be mapped with
several WNS. Thus, we get a Synset list for each
lemma in the sentence. In case the lemma does not
have an associated Bs, its list would be empty. An
example of this step is shown on Figure 2.
</bodyText>
<subsectionHeader confidence="0.9996">
2.3 Applying Ppr+Freq method
</subsectionHeader>
<bodyText confidence="0.982516333333333">
In the above case, Ppr+Freq modifies the “classic”
Page Rank approach instead of assigning the same
weight for each sense of WN in the disambiguation
graph (𝐺𝐷 ).
The PageRank (Brin and Page, 1998)
adaptation, Ppr , which was popularized by (Agirre
</bodyText>
<figure confidence="0.998395583333333">
Sentence lemmas
Babel synset
WordNet synset
bn:00020697n wn:08196765n
colombia bn:02051949n
bn:02530766n
near_thing bn:00057109n wn:00193543n
drug_lord bn:00028876n wn:09394468n
struggle
bn:00074762n wn:00587514n
bn:00009079n wn:00739796n
bn:00009080n wn:00901980n
</figure>
<page confidence="0.506287">
243
</page>
<bodyText confidence="0.999888423076923">
and Soroa, 2009) in Word Sense Disambiguation
thematic, and which has obtained relevant results,
was an inspiration to us in our work. The main idea
behind this algorithm is that, for each edge
between vi and vj in graph G, a vote is made from
vi to vj. As a result, the relevance of vj is
increased.
On top of that, the vote strength from i to j
depends on vi′s relevance. The philosophy behind
it is that, the more important the vertex is, the more
strength the voter would have. Thus, PageRank is
generated by applying a random walkthrough from
the internal interconnection of G, where the final
relevance of vi represents the random walkthrough
probability over G, and ending on vi.
Ppr+Freq includes the existent semantic and
frequency patterns of each sense of the word to
disambiguate while finding a way to connect each
one of these words in a knowledge base.
The new graph-based approach of WSD
generates a graph of disambiguated words for each
input sentence. For that reason, it is necessary to
classify the word senses according to the other
words that compose the context. The general
method is shown in Figure 3. This method is
divided into three steps:
</bodyText>
<listItem confidence="0.59355825">
I. Creation of a disambiguation graph
II. Application of Ppr+Freq in the generated
graph
III. Selection of the correct answer
</listItem>
<bodyText confidence="0.987639145454545">
Creation of a disambiguation graph: In the first
step, a disambiguation graph is built by means of a
Breath First Search (BFS) over the “super” graph
composed by all the resources integrated into ISR-
WN. The components involved in this process are:
WordNet, SUMO (Zouaq et al., 2009) WordNet
Domains (Magnini and Cavaglia, 2000) WordNet
Affects (Strapparava and Valitutti, 2004) Semantic
Classes (Izquierdo et al., 2007) and eXtended
WordNet (XWN) relations (Moldovan and Rus,
2001). This search aims to recover all senses
(nodes), domain labels (from WordNet Domain
and WordNet Affects), SUMO categories, and
Semantic Classes labels through the shortest path
between every pair of senses in the WNSL set
associated with the input sentence. Using ISR-WN
as the KB, through experimentation, we obtained
the shortest paths with a length of five edges. For a
better understanding of this process, see (Gutiérrez,
2012).
Application of Ppr+Freq in the generated
graph: In the second step, we use the weighted
Personalized PageRank. Here, all the vertices from
vector v in GD are initialized with the value N ;
where N is the number of nodes in GD. On the
other hand, the vertices that represent word senses
in the analyzed sentence are not initialized with
this value. Instead, they are initialized with values
in the range [0...1], which are associated to their
occurrence frequency in SemCor1 (Corpus and
sense frequencies knowledge). In the last step,
after applying the Ppr+Freq algorithm over GD, we
get a representative vector which contains ISR-WN
nodes in GD sorted in a descending order by a
ranking score computed by this algorithm. For a
better description, see (Gutiérrez, 2012).
Selection of the correct answer: As the correct
sense, we take the highest ranked sense of each
target word involved in this vector. Note that
domain labels, SUMO categories, semantic class
labels, and affect labels are ranked too. They could
be used in the future to determine relevant
conceptualizations that would be useful for text
classification and more.
In our system, we assume the following
configuration: dumping factor c = 0.85 and like in
(Agirre and Soroa, 2009) we used 30 iterations. A
detailed explanation about PageRank algorithm
can be found in (Agirre and Soroa, 2009).
Table 2 shows an example that analyzes the
Synset for each word in the sentence and also
shows how the higher ranked Synsets of the target
words are selected as the correct ones. For a
detailed explanation of Ppr+Freq, see (Gutiérrez,
2012).
</bodyText>
<subsectionHeader confidence="0.9851005">
2.4 Assigning Synset, Babel synset and Wiki
Pages
</subsectionHeader>
<bodyText confidence="0.999748571428571">
In this step, English is handled differently from
other languages because WordNet Synsets are
available only for English. The following sections
explain how we proceed in each case. Once the
Synsets list is obtained for each lemma in section
2.3, selecting the correct answer for the lemma is
all that’s left to do.
</bodyText>
<figure confidence="0.997854518518519">
1 http://www.cse.unt.edu/~rada/downloads.html
244
footballer |cry  |winning
CreatingGD
ISR-WN
Lemmas
Disambiguation
Graph
Ppr+Freq
footballer#1  |cried#9  |winning#3
(0,9)
Footballer#1
Selecting senses
(0,2)
winning#1
cry#10
(0,2)
cry#9
(0,4)
cry#7
(0,3)
(0,3)
winning#3
cry#11
(0,2)
cry#12
(0,2)
</figure>
<figureCaption confidence="0.982135">
Figure 3. General process of WSD with Ppr+Freq.
</figureCaption>
<figure confidence="0.7054735">
“The footballer cried when winning”
2.4.1 English
</figure>
<bodyText confidence="0.999766105263158">
Given a lemma, we go through its Synset list from
beginning to end looking for the first Synset that
contains a key2 for the lemma. If such Synset
exists, it is designated as the Synset for the lemma.
Otherwise, no Synset is assigned.
As already explained, each Synset in the list is
connected to a Bs. Therefore, the lemma linked
with the correct WNS selected in the previous step,
is chosen as the correct lemma. In case no Synsets
were designated as the correct ones, we take the
first Bs in BN, which contains the lemma among
its labels.
To determine the Wiki pages titles (WK) we
examine the WIKIRED and WIKI labels in the
correct Bs selected in the preceding step. This
search is restricted only to labels corresponding to
the analyzed language and discriminating upper
and lower case letters. Table 2 shows some sample
results of the WSD process.
</bodyText>
<table confidence="0.9995635">
Lemma struggle drug lord
WNS 00739796n 09394468n
WN key struggle%1:04:01:: drug_lord%1:18:00::
Bs bn:00009079n bn:00028876n
WK - Drug_Lord
Lemma colombia near_thing
WNS 08196765n 00193543n
WN key colombia%1:15:00:: near_thing%1:04:00::
Bs bn:00020697n bn:00057109n
WK Colombia -
</table>
<tableCaption confidence="0.997902">
Table 2 : Example of English Language.
</tableCaption>
<bodyText confidence="0.9032116">
2A sense_key is the best way to represent a sense in
semantic tagging or other systems that refer to WordNet
senses. sense_key’s are independent of WordNet sense
numbers and synset_offset’s, which vary between versions of
the database.
</bodyText>
<subsectionHeader confidence="0.56846">
2.4.2 Other languages
</subsectionHeader>
<bodyText confidence="0.999909714285714">
For this scenario, we introduce a change in the first
step discussed in the previous section. The reason
is that the Synsets do not contain any keys in any
other language than English. Thus, the correct
Synset for the lemma is the first in the Synset list
for the lemma obtained, as described, in section
2.3.
</bodyText>
<sectionHeader confidence="0.999895" genericHeader="evaluation">
3 Results
</sectionHeader>
<bodyText confidence="0.999228818181818">
We tested three versions (runs) of the proposed
approach and evaluated them through a trial
dataset provided by Task123 of Semeval-2013
using babelnet-1.0.1. Table 3 shows the result for
each run. Note that the table results were
calculated with the traditional WSD recall
measure, being this measure which has ranked
WSD systems on mostly Semeval competitions.
On the other hand, note that our precision and
recall results are different because the coverage is
not 100%. See Table 5.
</bodyText>
<table confidence="0.9984712">
English French
Runs WNS Bs WK Bs WK
Run1 0.70 0.71 0.77 0.59 0.85
Run2 0.70 0.71 0.78 0.60 0.85
Run3 0.69 0.70 0.77 - -
</table>
<tableCaption confidence="0.998689">
Table 3 : Results of runs with trial recall values.
</tableCaption>
<bodyText confidence="0.989191">
As can be noticed on Table 3, results of different
versions do not have big differences, but in
general, Run2 achieves the best results; it’s better
</bodyText>
<footnote confidence="0.5792">
3 http://www.cs.york.ac.uk/semeval-2013/task12
</footnote>
<page confidence="0.797698">
245
</page>
<bodyText confidence="0.991943962962963">
than Run1 in the WK with a 78% in English and
Bs with 60% in French. The best results are in the
WK in French with a value of 85%.
Since we can choose to include different
resources into ISR-WN, it is important to analyze
how doing so would affect the results. Table 4
shows comparative results for Run 2 of a trial
dataset with BabelNet version 1.1.1.
As can be observed in Table 4, the result does not
have a significant change even though we used the
ISR-WN with all resources.
A better analysis of Ppr+Freq in, as it relates to
the influence of each resource involved in ISR-WN
(similar to Table 4 description) assessing
SensEval-2 and SensEval-3 dataset, is shown in
(Gutiérrez, 2012). There are different resource
combinations showing that only XWN1.7 and all
ISR-WN resources obtain the highest performance.
Other analysis found in (Gutiérrez, 2012) evaluates
the influence of adding the sense frequency for
Ppr+Freq.
By excluding the Factotum Domain, we obtain
the best result in Bs 54% for French (only 1%
more than the version used in the competition).
The other results are equal, with a 69% in WNS,
66% in Bs, 64% in WK for English, and 69% in
WK for French.
</bodyText>
<table confidence="0.849212666666667">
English French
WI Domains Sumo Affect Factotum SemanticClass XWI3.0 XWI1.7 WIS Bs WK Bs WK
Domain
</table>
<equation confidence="0.9806904">
X X X X X X X X 0.69 0.66 0.64 0.53 0.69
X X X X X X X 0.69 0.66 0.64 0.53 0.69
X X X X X 0.68 0.65 0.64 0.52 0.69
X X X X X X X 0.69 0.66 0.64 0.54 0.69
X X X X X X 0.68 0.65 0.65 0.53 0.69
</equation>
<tableCaption confidence="0.998876">
Table 4. Influence of different resources that integrate ISR-WN in our technique.
</tableCaption>
<table confidence="0.999969722222222">
Wikipedia BabelNet WordNet
System Language Precision Recall F-score Precision Recall F-score Precision Recall F-score
MFS DE 0.836 0.827 0.831 0.676 0.673 0.686 - - -
EN 0.86 0.753 0.803 0.665 0.665 0.656 0.63 0.63 0.63
ES 0.83 0.819 0.824 0.645 0.645 0.644 - - -
FR 0.698 0.691 0.694 0.455 0.452 0.501 - - -
IT 0.833 0.813 0.823 0.576 0.574 0.572 - - -
Run1 DE 0.758 0.46 0.572 0.619 0.617 0.618 - - -
EN 0.619 0.484 0.543 0.677 0.677 0.677 0.639 0.635 0.637
ES 0.773 0.493 0.602 0.708 0.703 0.705 - - -
FR 0.817 0.48 0.605 0.608 0.603 0.605 - - -
IT 0.785 0.458 0.578 0.659 0.656 0.657 - - -
Run2 DE 0.769 0.467 0.581 0.622 0.62 0.621 - - -
EN 0.62 0.487 0.546 0.685 0.685 0.685 0.649 0.645 0.647
ES 0.778 0.502 0.61 0.713 0.708 0.71 - - -
FR 0.815 0.478 0.603 0.608 0.603 0.605 - - -
IT 0.787 0.463 0.583 0.659 0.657 0.658 - - -
Run3 EN 0.622 0.489 0.548 0.68 0.68 0.68 0.642 0.639 0.64
</table>
<tableCaption confidence="0.999748">
Table 5. Results of Runs for Task12 of semeval-2013 using the test dataset.
</tableCaption>
<page confidence="0.783701">
246
</page>
<subsectionHeader confidence="0.997156">
3.1 Run1
</subsectionHeader>
<bodyText confidence="0.999951545454545">
In this Run, WNSLs consist of all the target words
involved in each sentence. This run is applied at
the sentence level. The results for the competition
are shown in Table 5. For this Run, the best result
was obtained for Spanish with a 70.3% in Bs and
49.3% in WK of Recall. As we can see, for Run1
the precision is high for Wikipedia disambiguation,
obtaining for French the best result of the ranking. The
low Recall in Wikipedia is due to the exact mismatching
of labels between our system output and the gold
standard. This fact, affects the rest of our runs.
</bodyText>
<subsectionHeader confidence="0.999473">
3.2 Run2
</subsectionHeader>
<bodyText confidence="0.9999855">
In this Run, WNSLs consist of all the target words
involved in each domain. We can obtain the target
words because the training and test dataset contain
the sentences grouped by topics. For instance, for
English, 13 WNSLs are established. This Run is
applied at the corpora level. The results for the
competition are shown in Table 5. It is important to
emphasize that our best results ranked our
algorithm as first place among all proposed
approaches for the MWSD task.
For this run, the best Recall was obtained for
Spanish with a 70.8% in Bs and 50.2% in WK.
This Run also has the best result of the three runs.
For the English competition, it ended up with a
64.5% in WNS, 68.5% in Bs, and 48.7% in WK.
This Run obtained promising results, which took
first place in the competition. It also had better
results than that of the First Sense (Most Frequent
Sense) baseline in Bs results for all languages,
except for German. In Bs, it only obtained lower
results in German with a 62% of Recall for our
system and 67.3% for the First Sense baseline.
</bodyText>
<subsectionHeader confidence="0.99916">
3.3 Run3
</subsectionHeader>
<bodyText confidence="0.999987285714286">
In this run, WNSLs consist of all the words
included in each sentence. This run uses target
words and non-target words of each sentence, as
they are applied to the sentence level. The results
for the competition are shown in Table 5.
As we can see, the behavior of this run is similar
to the previous runs.
</bodyText>
<sectionHeader confidence="0.996484" genericHeader="conclusions">
4 Conclusions and Future work
</sectionHeader>
<bodyText confidence="0.99053664">
The above results suggest that our proposal is a
promising approach. It is also important to notice
that a richer knowledgebase can be built by
combining different resources such as BabelNet
and ISR-WN, which can lead to an improvement
of the results. Notwithstanding, our system has
been recognized as the best in the competition,
obtaining results around 70% of Recall.
According to the Task12 results4, only the
baseline Most Frequent Sense (MFS) could
improve our scores in order to achieve better WK
and German (DE) disambiguation. Therefore, we
plan to review this point to figure out why we
obtained better results in other categories, but not
for this one. At the same time, further work will
use the internal Babel network to run the Ppr+Freq
method in an attempt to find a way to enrich the
semantic network obtained for each target sentence
to disambiguate. On top of that, we plan to
compare Ppr (Agirre and Soroa, 2009) with
Ppr+Freq using the Task12 dataset.
Availability of our Resource
In case researchers would like to use our resource,
it is available at the GPLSI5 home page or by
contacting us via email.
</bodyText>
<sectionHeader confidence="0.99549" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.998908777777778">
This research work has been partially funded by
the Spanish Government through the project
TEXT-MESS 2.0 (TIN2009-13391-C04), &amp;quot;Análisis
de Tendencias Mediante Técnicas de Opinión
Semántica&amp;quot; (TIN2012-38536-C03-03) and
“Técnicas de Deconstrucción en la Tecnologías del
Lenguaje Humano” (TIN2012-31224); and by the
Valencian Government through the project
PROMETEO (PROMETEO/2009/199).
</bodyText>
<sectionHeader confidence="0.985889" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9889938">
Agirre, E. and A. Soroa. Personalizing PageRank for
Word Sense Disambiguation. Proceedings of the 12th
conference of the European chapter of the
Association for Computational Linguistics (EACL-
2009), Athens, Greece, 2009.
</reference>
<footnote confidence="0.630388333333333">
4 http://www.cs.york.ac.uk/semeval-
2013/task12/index.php?id=results
5 http://gplsi.dlsi.ua.es/
</footnote>
<page confidence="0.500869">
247
</page>
<reference confidence="0.996195529411764">
Fernández, A.; Y. Guti6rrez; H. Dávila; A. Chávez; A.
González; R. Estrada; Y. Castañeda; S. Vázquez; A.
Montoyo and R. Muñoz. UMCC_DLSI:
Multidimensional Lexical-Semantic Textual
Similarity. {*SEM 2012}: The First Joint Conference
on Lexical and Computational Semantics -- Volume
1: Proceedings of the main conference and the shared
task, and Volume 2: Proceedings of the Sixth
International Workshop on Semantic Evaluation
{(SemEval 2012)}, Montreal, Canada, Association
for Computational Linguistics, 2012. 608--616 p.
Guti6rrez, Y. Análisis Semántico Multidimensional
aplicado a la Desambiguación del Lenguaje Natural.
Departamento de Lenguajes y Sistemas Informáticos.
Alicante, Alicante, 2012. 189. p.
Guti6rrez, Y.; A. Fernández; A. Montoyo and S.
Vázquez. Integration of semantic resources based on
WordNet. XXVI Congreso de la Sociedad Española
para el Procesamiento del Lenguaje Natural,
Universidad Polit6cnica de Valencia, Valencia,
SEPLN 2010, 2010a. 161-168 p. 1135-5948.
Guti6rrez, Y.; A. Fernández; A. Montoyo and S.
Vázquez. UMCC-DLSI: Integrative resource for
disambiguation task. Proceedings of the 5th
International Workshop on Semantic Evaluation,
Uppsala, Sweden, Association for Computational
Linguistics, 2010b. 427-432 p.
Guti6rrez, Y.; A. Fernández; A. Montoyo and S.
Vázquez Enriching the Integration of Semantic
Resources based on WordNet Procesamiento del
Lenguaje Natural, 2011a, 47: 249-257.
Guti6rrez, Y.; S. Vázquez and A. Montoyo. Improving
WSD using ISR-WN with Relevant Semantic Trees
and SemCor Senses Frequency. Proceedings of the
International Conference Recent Advances in Natural
Language Processing 2011, Hissar, Bulgaria, RANLP
2011 Organising Committee, 2011b. 233--239 p.
Guti6rrez, Y.; S. Vázquez and A. Montoyo. Sentiment
Classification Using Semantic Features Extracted
from WordNet-based Resources. Proceedings of the
2nd Workshop on Computational Approaches to
Subjectivity and Sentiment Analysis (WASSA
2.011), Portland, Oregon., Association for
Computational Linguistics, 2011c. 139--145 p.
Guti6rrez, Y.; S. Vázquez and A. Montoyo. Word Sense
Disambiguation: A Graph-Based Approach Using N-
Cliques Partitioning Technique. en: Natural
Language Processing and Information Systems.
MUÑOZ, R.;MONTOYO, A.et al, Springer Berlin /
Heidelberg, 2011d. 6716: 112-124.p.
Guti6rrez, Y.; S. Vázquez and A. Montoyo. A graph-
Based Approach to WSD Using Relevant Semantic
Trees and N-Cliques Model. CICLing 2012, New
Delhi, India, 2012. 225-237 p.
Izquierdo, R.; A. Suárez and G. Rigau A Proposal of
Automatic Selection of Coarse-grained Semantic
Classes for WSD Procesamiento del Lenguaje
Natural, 2007, 39: 189-196.
Laparra, E.; G. Rigau and M. Cuadros. Exploring the
integration of WordNet and FrameNet. Proceedings
of the 5th Global WordNet Conference (GWC&apos;10),
Mumbai, India, 2010.
Magnini, B. and G. Cavaglia. Integrating Subject Field
Codes into WordNet. Proceedings of Third
International Conference on Language Resources and
Evaluation (LREC-2000), 2000. 1413--1418 p.
Mihalcea, R. Unsupervised large-vocabulary word sense
disambiguation with graph-based algorithms for
sequence data labeling. Proceedings of HLT05,
Morristown, NJ, USA., 2005.
Miller, G. A.; R. Beckwith; C. Fellbaum; D. Gross and
K. Miller. Five papers on WordNet. Princenton
University, Cognositive Science Laboratory, 1990.
Moldovan, D. I. and V. Rus Explaining Answers with
Extended WordNet ACL, 2001.
Navigli, R.; D. Jurgens and D. Vannella. SemEval-2013
Task 12: Multilingual Word Sense Disambiguation. .
Proceedings of the 7th International Workshop on
Semantic Evaluation (SemEval 2013), in conjunction
with the Second Joint Conference on Lexical and
Computational Semantics (*SEM 2013), Atlanta,
Georgia, 2013.
Navigli, R. and S. P. Ponzetto. BabelNet: Building a
Very Large Multilingual Semantic Network.
Proceedings of the 48th Annual Meeting of the
Association for Computational Linguistics, Uppsala,
Sweden, Association for Computational Linguistics,
2010. 216--225 p.
Navigli, R. and S. P. Ponzetto BabelNet: The automatic
construction, evaluation and application of a wide-
coverage multilingual semantic network Artif. Intell.,
2012, 193: 217-250.
Navigli, R. and P. Velardi Structural Semantic
Interconnections: A Knowledge-Based Approach to
Word Sense Disambiguation IEEE Transactions on
Pattern Analysis and Machine Intelligence, 2005,
27(7): 1075-1086.
Sinha, R. and R. Mihalcea. Unsupervised Graph-based
Word Sense Disambiguation Using Measures of
Word Semantic Similarity. Proceedings of the IEEE
International Conference on Semantic Computing
(ICSC 2007), Irvine, CA, 2007.
248
Strapparava, C. and A. Valitutti. WordNet-Affect: an
affective extension of WordNet. Proceedings of the
4th International Conference on Language Resources
and Evaluation (LREC 2004), Lisbon, 2004. 1083-
1086 p.
Tsatsaronis, G.; M. Vazirgiannis and I.
Androutsopoulos. Word sense disambiguation with
spreading activation networks generated from
thesauri. IJCAI, 2007.
Vossen, P. EuroWordNet: A Multilingual Database with
Lexical Semantic Networks. Dordrecht, Kluwer
Academic Publishers, 1998.
Zouaq, A.; M. Gagnon and B. Ozell. A SUMO-based
Semantic Analysis for Knowledge Extraction.
Proceedings of the 4th Language &amp; Technology
Conference, Poznań, Poland, 2009.
</reference>
<page confidence="0.952038">
249
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.107905">
<title confidence="0.999097">UMCC_DLSI: Reinforcing a Ranking Algorithm with Sense Frequencies and Multidimensional Semantic Resources to solve Multilingual Word Sense Disambiguation</title>
<author confidence="0.9378835">Yoan Gutiérrez</author>
<author confidence="0.9378835">Yenier Antonio Fernández Orquín</author>
<author confidence="0.9378835">Franc Camara Castañeda</author>
<author confidence="0.9378835">Andy González</author>
<author confidence="0.9378835">Andrés Montoyo</author>
<author confidence="0.9378835">Rafael Muñoz Rainel Estrada</author>
<author confidence="0.9378835">Dennys D Piug</author>
<author confidence="0.9378835">Jose I Abreu</author>
<author confidence="0.9378835">Roger Pérez</author>
<affiliation confidence="0.998964">DI, University of Matanzas DLSI, University of Alicante Independent Consultant</affiliation>
<address confidence="0.965975">Matanzas, Cuba Alicante, Spain USA</address>
<email confidence="0.534845">dennys.puig,{montoyo,rafael}@dlsi.ua.info@franccamara.c.cuesom</email>
<abstract confidence="0.998839777777778">This work introduces a new unsupervised approach to multilingual word sense disambiguation. Its main purpose is to automatically choose the intended sense (meaning) of a word in a particular context for different languages. It does so by selecting the correct Babel synset for the word and the various Wiki Page titles that mention the word. BabelNet contains all the output information that our system needs, in its Babel synset. Through Babel synset, we find all the possible Synsets for the word in WordNet. Using these Synsets, we apply the disambiguation method Ppr+Freq to find what we need. To facilitate the work with WordNet, we use the ISR-WN which offers the integration of different resources to WordNet.</abstract>
<note confidence="0.475037666666667">Our system, recognized as the best in the competition, obtains results around 69% of Recall.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>A Soroa</author>
</authors>
<title>Personalizing PageRank for Word Sense Disambiguation.</title>
<date>2009</date>
<booktitle>Proceedings of the 12th conference of the European chapter of the Association for Computational Linguistics (EACL2009),</booktitle>
<location>Athens, Greece,</location>
<contexts>
<context position="4122" citStr="Agirre and Soroa, 2009" startWordPosition="606" endWordPosition="609">unsupervised systems, graph-based methods have obtained more promising results. It is worth mentioning the relevant approaches used by the scientific community to achieve promising results. One approach used is structural interconnections, such as Structural Semantic Interconnections (SSI), which create structural specifications of the possible senses for each word in a context (Navigli and Velardi, 2005). The other approaches used are “Exploring the integration of WordNet” (Miller et al., 1990), FrameNet (Laparra et al., 2010) and those using Page-Rank such as (Sinha and Mihalcea, 2007) and (Agirre and Soroa, 2009). The aforementioned types of graph based approaches have achieved relevant results in both the SensEval-2 and SensEval-3 competitions (see Table 1). Algorithm Recall TexRank (Mihalcea, 2005) 54.2% (Sinha and Mihalcea, 2007) 56.4% (Tsatsaronis et al., 2007) 49.2% Ppr (Agirre and Soroa, 2009) 58.6% Table 1. Relevant WSD approaches. Recall measure is calculated recalls using SensEval-2 (English All Word task) guidelines over. Experiments using SensEval-2 and SensEval-3 corpora suggest that Ppr+Freq (Gutiérrez, 2012) can lead to better results by obtaining over 64% of Recall. Therefore we selecte</context>
<context position="5948" citStr="Agirre and Soroa, 2009" startWordPosition="888" endWordPosition="891"> System architecture By using one of BabelNet (BN) features, our technique begins by looking for all the Babel synsets (Bs) linked to the lemma of each word in the sentence that we need to disambiguate. Through the Bs offsets, we can get its corresponding WordNet Synset (WNS), which would be retrieved from WordNet (WN) using the ISR-WN resource. As a result, for each lemma, we have a WordNet Synset List (WNSL) from which our Word Sense Disambiguation method obtains one WNS as the correct meaning. Our WSD method consists of applying a modification of the Personalizing PageRank (Ppr) algorithm (Agirre and Soroa, 2009), which involves the senses frequency. More specifically, the key proposal is known as Ppr+Freq (see Section 2.3). Given a set of WNSLs of WNSL, as words window, we applied the Synsets ranking method, Ppr+Freq, which ranks in a descending order, the Synsets of each lemma according to a calculated factor of relevance. The first Synset (WNS) of each WNSL (the most relevant) is established as the correct one and its associated Babel synset (Bs) is also tagged as correct. To determine the Wiki Page Titles (WK), we examine the WIKI (Wikipedia pages) and WIKIRED (Wikipedia pages redirections) in the</context>
<context position="12426" citStr="Agirre and Soroa, 2009" startWordPosition="1927" endWordPosition="1930">ins ISR-WN nodes in GD sorted in a descending order by a ranking score computed by this algorithm. For a better description, see (Gutiérrez, 2012). Selection of the correct answer: As the correct sense, we take the highest ranked sense of each target word involved in this vector. Note that domain labels, SUMO categories, semantic class labels, and affect labels are ranked too. They could be used in the future to determine relevant conceptualizations that would be useful for text classification and more. In our system, we assume the following configuration: dumping factor c = 0.85 and like in (Agirre and Soroa, 2009) we used 30 iterations. A detailed explanation about PageRank algorithm can be found in (Agirre and Soroa, 2009). Table 2 shows an example that analyzes the Synset for each word in the sentence and also shows how the higher ranked Synsets of the target words are selected as the correct ones. For a detailed explanation of Ppr+Freq, see (Gutiérrez, 2012). 2.4 Assigning Synset, Babel synset and Wiki Pages In this step, English is handled differently from other languages because WordNet Synsets are available only for English. The following sections explain how we proceed in each case. Once the Syn</context>
<context position="21570" citStr="Agirre and Soroa, 2009" startWordPosition="3533" endWordPosition="3536">st in the competition, obtaining results around 70% of Recall. According to the Task12 results4, only the baseline Most Frequent Sense (MFS) could improve our scores in order to achieve better WK and German (DE) disambiguation. Therefore, we plan to review this point to figure out why we obtained better results in other categories, but not for this one. At the same time, further work will use the internal Babel network to run the Ppr+Freq method in an attempt to find a way to enrich the semantic network obtained for each target sentence to disambiguate. On top of that, we plan to compare Ppr (Agirre and Soroa, 2009) with Ppr+Freq using the Task12 dataset. Availability of our Resource In case researchers would like to use our resource, it is available at the GPLSI5 home page or by contacting us via email. Acknowledgments This research work has been partially funded by the Spanish Government through the project TEXT-MESS 2.0 (TIN2009-13391-C04), &amp;quot;Análisis de Tendencias Mediante Técnicas de Opinión Semántica&amp;quot; (TIN2012-38536-C03-03) and “Técnicas de Deconstrucción en la Tecnologías del Lenguaje Humano” (TIN2012-31224); and by the Valencian Government through the project PROMETEO (PROMETEO/2009/199). Referenc</context>
</contexts>
<marker>Agirre, Soroa, 2009</marker>
<rawString>Agirre, E. and A. Soroa. Personalizing PageRank for Word Sense Disambiguation. Proceedings of the 12th conference of the European chapter of the Association for Computational Linguistics (EACL2009), Athens, Greece, 2009.</rawString>
</citation>
<citation valid="false">
<authors>
<author>A Fernández</author>
<author>Y Guti6rrez</author>
<author>H Dávila</author>
<author>A Chávez</author>
<author>A González</author>
<author>R Estrada</author>
<author>Y Castañeda</author>
<author>S Vázquez</author>
<author>A Montoyo</author>
<author>R Muñoz</author>
</authors>
<title>UMCC_DLSI: Multidimensional Lexical-Semantic Textual Similarity.</title>
<date>2012</date>
<booktitle>{*SEM 2012}: The First Joint Conference on Lexical and Computational Semantics -- Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation {(SemEval 2012)}, Montreal, Canada, Association for Computational Linguistics,</booktitle>
<pages>608--616</pages>
<marker>Fernández, Guti6rrez, Dávila, Chávez, González, Estrada, Castañeda, Vázquez, Montoyo, Muñoz, 2012</marker>
<rawString>Fernández, A.; Y. Guti6rrez; H. Dávila; A. Chávez; A. González; R. Estrada; Y. Castañeda; S. Vázquez; A. Montoyo and R. Muñoz. UMCC_DLSI: Multidimensional Lexical-Semantic Textual Similarity. {*SEM 2012}: The First Joint Conference on Lexical and Computational Semantics -- Volume 1: Proceedings of the main conference and the shared task, and Volume 2: Proceedings of the Sixth International Workshop on Semantic Evaluation {(SemEval 2012)}, Montreal, Canada, Association for Computational Linguistics, 2012. 608--616 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Guti6rrez</author>
</authors>
<title>Análisis Semántico Multidimensional aplicado a la Desambiguación del Lenguaje Natural. Departamento de Lenguajes y Sistemas Informáticos.</title>
<date>2012</date>
<pages>189</pages>
<location>Alicante, Alicante,</location>
<marker>Guti6rrez, 2012</marker>
<rawString>Guti6rrez, Y. Análisis Semántico Multidimensional aplicado a la Desambiguación del Lenguaje Natural. Departamento de Lenguajes y Sistemas Informáticos. Alicante, Alicante, 2012. 189. p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Guti6rrez</author>
<author>A Fernández</author>
<author>A Montoyo</author>
<author>S Vázquez</author>
</authors>
<title>Integration of semantic resources based on WordNet.</title>
<date>2010</date>
<booktitle>XXVI Congreso de la Sociedad Española para el Procesamiento del Lenguaje Natural, Universidad Polit6cnica de</booktitle>
<pages>2010--161</pages>
<location>Valencia, Valencia, SEPLN</location>
<marker>Guti6rrez, Fernández, Montoyo, Vázquez, 2010</marker>
<rawString>Guti6rrez, Y.; A. Fernández; A. Montoyo and S. Vázquez. Integration of semantic resources based on WordNet. XXVI Congreso de la Sociedad Española para el Procesamiento del Lenguaje Natural, Universidad Polit6cnica de Valencia, Valencia, SEPLN 2010, 2010a. 161-168 p. 1135-5948.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Guti6rrez</author>
<author>A Fernández</author>
<author>A Montoyo</author>
<author>S Vázquez</author>
</authors>
<title>UMCC-DLSI: Integrative resource for disambiguation task.</title>
<booktitle>Proceedings of the 5th International Workshop on Semantic Evaluation, Uppsala, Sweden, Association for Computational Linguistics,</booktitle>
<pages>2010--427</pages>
<marker>Guti6rrez, Fernández, Montoyo, Vázquez, </marker>
<rawString>Guti6rrez, Y.; A. Fernández; A. Montoyo and S. Vázquez. UMCC-DLSI: Integrative resource for disambiguation task. Proceedings of the 5th International Workshop on Semantic Evaluation, Uppsala, Sweden, Association for Computational Linguistics, 2010b. 427-432 p.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Guti6rrez</author>
<author>A Fernández</author>
<author>A Montoyo</author>
<author>S</author>
</authors>
<booktitle>Vázquez Enriching the Integration of Semantic Resources based on WordNet Procesamiento del Lenguaje Natural, 2011a,</booktitle>
<volume>47</volume>
<pages>249--257</pages>
<marker>Guti6rrez, Fernández, Montoyo, S, </marker>
<rawString>Guti6rrez, Y.; A. Fernández; A. Montoyo and S. Vázquez Enriching the Integration of Semantic Resources based on WordNet Procesamiento del Lenguaje Natural, 2011a, 47: 249-257.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Guti6rrez</author>
<author>S Vázquez</author>
<author>A Montoyo</author>
</authors>
<title>Improving WSD using ISR-WN with Relevant Semantic Trees and SemCor Senses Frequency.</title>
<date>2011</date>
<booktitle>Proceedings of the International Conference Recent Advances in Natural Language Processing</booktitle>
<pages>233--239</pages>
<location>Hissar, Bulgaria, RANLP</location>
<marker>Guti6rrez, Vázquez, Montoyo, 2011</marker>
<rawString>Guti6rrez, Y.; S. Vázquez and A. Montoyo. Improving WSD using ISR-WN with Relevant Semantic Trees and SemCor Senses Frequency. Proceedings of the International Conference Recent Advances in Natural Language Processing 2011, Hissar, Bulgaria, RANLP 2011 Organising Committee, 2011b. 233--239 p.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Y Guti6rrez</author>
<author>S Vázquez</author>
<author>A Montoyo</author>
</authors>
<title>Sentiment Classification Using Semantic Features Extracted from WordNet-based Resources.</title>
<journal>Association for Computational Linguistics,</journal>
<booktitle>Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis (WASSA 2.011),</booktitle>
<volume>2011</volume>
<pages>139--145</pages>
<location>Portland, Oregon.,</location>
<marker>Guti6rrez, Vázquez, Montoyo, </marker>
<rawString>Guti6rrez, Y.; S. Vázquez and A. Montoyo. Sentiment Classification Using Semantic Features Extracted from WordNet-based Resources. Proceedings of the 2nd Workshop on Computational Approaches to Subjectivity and Sentiment Analysis (WASSA 2.011), Portland, Oregon., Association for Computational Linguistics, 2011c. 139--145 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Guti6rrez</author>
<author>S Vázquez</author>
<author>A Montoyo</author>
</authors>
<title>Word Sense Disambiguation: A Graph-Based Approach Using NCliques Partitioning Technique. en:</title>
<date>2011</date>
<booktitle>Natural Language Processing and Information Systems. MUÑOZ, R.;MONTOYO, A.et al,</booktitle>
<volume>6716</volume>
<pages>112--124</pages>
<publisher>Springer</publisher>
<location>Berlin / Heidelberg,</location>
<marker>Guti6rrez, Vázquez, Montoyo, 2011</marker>
<rawString>Guti6rrez, Y.; S. Vázquez and A. Montoyo. Word Sense Disambiguation: A Graph-Based Approach Using NCliques Partitioning Technique. en: Natural Language Processing and Information Systems. MUÑOZ, R.;MONTOYO, A.et al, Springer Berlin / Heidelberg, 2011d. 6716: 112-124.p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Guti6rrez</author>
<author>S Vázquez</author>
<author>A Montoyo</author>
</authors>
<title>A graphBased Approach to WSD Using Relevant Semantic Trees and N-Cliques Model. CICLing 2012,</title>
<date>2012</date>
<pages>225--237</pages>
<location>New Delhi, India,</location>
<marker>Guti6rrez, Vázquez, Montoyo, 2012</marker>
<rawString>Guti6rrez, Y.; S. Vázquez and A. Montoyo. A graphBased Approach to WSD Using Relevant Semantic Trees and N-Cliques Model. CICLing 2012, New Delhi, India, 2012. 225-237 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Izquierdo</author>
<author>A Suárez</author>
<author>G</author>
</authors>
<title>Rigau A Proposal of Automatic Selection</title>
<date>2007</date>
<booktitle>of Coarse-grained Semantic Classes for WSD Procesamiento del Lenguaje Natural,</booktitle>
<volume>39</volume>
<pages>189--196</pages>
<contexts>
<context position="10683" citStr="Izquierdo et al., 2007" startWordPosition="1644" endWordPosition="1647">general method is shown in Figure 3. This method is divided into three steps: I. Creation of a disambiguation graph II. Application of Ppr+Freq in the generated graph III. Selection of the correct answer Creation of a disambiguation graph: In the first step, a disambiguation graph is built by means of a Breath First Search (BFS) over the “super” graph composed by all the resources integrated into ISRWN. The components involved in this process are: WordNet, SUMO (Zouaq et al., 2009) WordNet Domains (Magnini and Cavaglia, 2000) WordNet Affects (Strapparava and Valitutti, 2004) Semantic Classes (Izquierdo et al., 2007) and eXtended WordNet (XWN) relations (Moldovan and Rus, 2001). This search aims to recover all senses (nodes), domain labels (from WordNet Domain and WordNet Affects), SUMO categories, and Semantic Classes labels through the shortest path between every pair of senses in the WNSL set associated with the input sentence. Using ISR-WN as the KB, through experimentation, we obtained the shortest paths with a length of five edges. For a better understanding of this process, see (Gutiérrez, 2012). Application of Ppr+Freq in the generated graph: In the second step, we use the weighted Personalized Pa</context>
</contexts>
<marker>Izquierdo, Suárez, G, 2007</marker>
<rawString>Izquierdo, R.; A. Suárez and G. Rigau A Proposal of Automatic Selection of Coarse-grained Semantic Classes for WSD Procesamiento del Lenguaje Natural, 2007, 39: 189-196.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Laparra</author>
<author>G Rigau</author>
<author>M Cuadros</author>
</authors>
<title>Exploring the integration of WordNet and FrameNet.</title>
<date>2010</date>
<booktitle>Proceedings of the 5th Global WordNet Conference (GWC&apos;10),</booktitle>
<location>Mumbai, India,</location>
<contexts>
<context position="4032" citStr="Laparra et al., 2010" startWordPosition="591" endWordPosition="594"> Page Rank combined with Frequencies of senses) (Gutiérrez, 2012) method because, among unsupervised systems, graph-based methods have obtained more promising results. It is worth mentioning the relevant approaches used by the scientific community to achieve promising results. One approach used is structural interconnections, such as Structural Semantic Interconnections (SSI), which create structural specifications of the possible senses for each word in a context (Navigli and Velardi, 2005). The other approaches used are “Exploring the integration of WordNet” (Miller et al., 1990), FrameNet (Laparra et al., 2010) and those using Page-Rank such as (Sinha and Mihalcea, 2007) and (Agirre and Soroa, 2009). The aforementioned types of graph based approaches have achieved relevant results in both the SensEval-2 and SensEval-3 competitions (see Table 1). Algorithm Recall TexRank (Mihalcea, 2005) 54.2% (Sinha and Mihalcea, 2007) 56.4% (Tsatsaronis et al., 2007) 49.2% Ppr (Agirre and Soroa, 2009) 58.6% Table 1. Relevant WSD approaches. Recall measure is calculated recalls using SensEval-2 (English All Word task) guidelines over. Experiments using SensEval-2 and SensEval-3 corpora suggest that Ppr+Freq (Gutiérr</context>
</contexts>
<marker>Laparra, Rigau, Cuadros, 2010</marker>
<rawString>Laparra, E.; G. Rigau and M. Cuadros. Exploring the integration of WordNet and FrameNet. Proceedings of the 5th Global WordNet Conference (GWC&apos;10), Mumbai, India, 2010.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavaglia</author>
</authors>
<title>Integrating Subject Field Codes into WordNet.</title>
<date>2000</date>
<booktitle>Proceedings of Third International Conference on Language Resources and Evaluation (LREC-2000),</booktitle>
<pages>1413--1418</pages>
<contexts>
<context position="10591" citStr="Magnini and Cavaglia, 2000" startWordPosition="1632" endWordPosition="1635">ecessary to classify the word senses according to the other words that compose the context. The general method is shown in Figure 3. This method is divided into three steps: I. Creation of a disambiguation graph II. Application of Ppr+Freq in the generated graph III. Selection of the correct answer Creation of a disambiguation graph: In the first step, a disambiguation graph is built by means of a Breath First Search (BFS) over the “super” graph composed by all the resources integrated into ISRWN. The components involved in this process are: WordNet, SUMO (Zouaq et al., 2009) WordNet Domains (Magnini and Cavaglia, 2000) WordNet Affects (Strapparava and Valitutti, 2004) Semantic Classes (Izquierdo et al., 2007) and eXtended WordNet (XWN) relations (Moldovan and Rus, 2001). This search aims to recover all senses (nodes), domain labels (from WordNet Domain and WordNet Affects), SUMO categories, and Semantic Classes labels through the shortest path between every pair of senses in the WNSL set associated with the input sentence. Using ISR-WN as the KB, through experimentation, we obtained the shortest paths with a length of five edges. For a better understanding of this process, see (Gutiérrez, 2012). Application</context>
</contexts>
<marker>Magnini, Cavaglia, 2000</marker>
<rawString>Magnini, B. and G. Cavaglia. Integrating Subject Field Codes into WordNet. Proceedings of Third International Conference on Language Resources and Evaluation (LREC-2000), 2000. 1413--1418 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
</authors>
<title>Unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling.</title>
<date>2005</date>
<booktitle>Proceedings of HLT05,</booktitle>
<location>Morristown, NJ, USA.,</location>
<contexts>
<context position="4313" citStr="Mihalcea, 2005" startWordPosition="634" endWordPosition="635">ach used is structural interconnections, such as Structural Semantic Interconnections (SSI), which create structural specifications of the possible senses for each word in a context (Navigli and Velardi, 2005). The other approaches used are “Exploring the integration of WordNet” (Miller et al., 1990), FrameNet (Laparra et al., 2010) and those using Page-Rank such as (Sinha and Mihalcea, 2007) and (Agirre and Soroa, 2009). The aforementioned types of graph based approaches have achieved relevant results in both the SensEval-2 and SensEval-3 competitions (see Table 1). Algorithm Recall TexRank (Mihalcea, 2005) 54.2% (Sinha and Mihalcea, 2007) 56.4% (Tsatsaronis et al., 2007) 49.2% Ppr (Agirre and Soroa, 2009) 58.6% Table 1. Relevant WSD approaches. Recall measure is calculated recalls using SensEval-2 (English All Word task) guidelines over. Experiments using SensEval-2 and SensEval-3 corpora suggest that Ppr+Freq (Gutiérrez, 2012) can lead to better results by obtaining over 64% of Recall. Therefore we selected Ppr+Freq as the WSD method for our system. The key proposal for this work is an unsupervised algorithm for MWSD, which uses an unsupervised method, Ppr+Freq, for semantic disambiguation wit</context>
</contexts>
<marker>Mihalcea, 2005</marker>
<rawString>Mihalcea, R. Unsupervised large-vocabulary word sense disambiguation with graph-based algorithms for sequence data labeling. Proceedings of HLT05, Morristown, NJ, USA., 2005.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G A Miller</author>
<author>R Beckwith</author>
<author>C Fellbaum</author>
<author>D Gross</author>
<author>K Miller</author>
</authors>
<title>Five papers on WordNet.</title>
<date>1990</date>
<institution>Princenton University, Cognositive Science Laboratory,</institution>
<contexts>
<context position="3999" citStr="Miller et al., 1990" startWordPosition="586" endWordPosition="589">o use the Ppr+Freq (Personalized Page Rank combined with Frequencies of senses) (Gutiérrez, 2012) method because, among unsupervised systems, graph-based methods have obtained more promising results. It is worth mentioning the relevant approaches used by the scientific community to achieve promising results. One approach used is structural interconnections, such as Structural Semantic Interconnections (SSI), which create structural specifications of the possible senses for each word in a context (Navigli and Velardi, 2005). The other approaches used are “Exploring the integration of WordNet” (Miller et al., 1990), FrameNet (Laparra et al., 2010) and those using Page-Rank such as (Sinha and Mihalcea, 2007) and (Agirre and Soroa, 2009). The aforementioned types of graph based approaches have achieved relevant results in both the SensEval-2 and SensEval-3 competitions (see Table 1). Algorithm Recall TexRank (Mihalcea, 2005) 54.2% (Sinha and Mihalcea, 2007) 56.4% (Tsatsaronis et al., 2007) 49.2% Ppr (Agirre and Soroa, 2009) 58.6% Table 1. Relevant WSD approaches. Recall measure is calculated recalls using SensEval-2 (English All Word task) guidelines over. Experiments using SensEval-2 and SensEval-3 corpo</context>
</contexts>
<marker>Miller, Beckwith, Fellbaum, Gross, Miller, 1990</marker>
<rawString>Miller, G. A.; R. Beckwith; C. Fellbaum; D. Gross and K. Miller. Five papers on WordNet. Princenton University, Cognositive Science Laboratory, 1990.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D I Moldovan</author>
<author>V</author>
</authors>
<title>Rus Explaining Answers with Extended WordNet ACL,</title>
<date>2001</date>
<marker>Moldovan, V, 2001</marker>
<rawString>Moldovan, D. I. and V. Rus Explaining Answers with Extended WordNet ACL, 2001.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>D Jurgens</author>
<author>D Vannella</author>
</authors>
<title>SemEval-2013 Task 12: Multilingual Word Sense Disambiguation.</title>
<date>2013</date>
<booktitle>Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013),</booktitle>
<location>Atlanta, Georgia,</location>
<contexts>
<context position="2373" citStr="Navigli et al., 2013" startWordPosition="344" endWordPosition="347">given context. In order to solve semantic ambiguity, different systems have been developed. However, we can categorize them in two main groups: supervised and unsupervised systems. The supervised ones need large quantity of hand-tagged data in order to gather enough information to build rules, train systems, and so on. Unsupervised systems, on the other hand, do not need such a large amount of hand-tagged datasets. This means that, when there aren’t enough corpora to train the systems, an unsupervised system is a good option. A sub-task of WSD is Multilingual Word Sense Disambiguation (MWSD) (Navigli et al., 2013) that aims at resolving ambiguities in different languages. In a language, there are words that have only one sense (or meaning), but in other languages, the same words can have different senses. For example, “patient” is a word that in English can be either a noun or an adjective, but in German, it only has one sense - “viz” (a person that needs treatment). This shows that the information obtained by combining two languages can be more useful for WSD because the word senses in each language can complement each other. For it to be useful, MWSD needs a multilingual resource that contains differ</context>
</contexts>
<marker>Navigli, Jurgens, Vannella, 2013</marker>
<rawString>Navigli, R.; D. Jurgens and D. Vannella. SemEval-2013 Task 12: Multilingual Word Sense Disambiguation. . Proceedings of the 7th International Workshop on Semantic Evaluation (SemEval 2013), in conjunction with the Second Joint Conference on Lexical and Computational Semantics (*SEM 2013), Atlanta, Georgia, 2013.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>S P Ponzetto</author>
</authors>
<title>BabelNet: Building a Very Large Multilingual Semantic Network.</title>
<date>2010</date>
<booktitle>Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, Association for Computational Linguistics,</booktitle>
<pages>216--225</pages>
<contexts>
<context position="3032" citStr="Navigli and Ponzetto, 2010" startWordPosition="456" endWordPosition="459">es in different languages. In a language, there are words that have only one sense (or meaning), but in other languages, the same words can have different senses. For example, “patient” is a word that in English can be either a noun or an adjective, but in German, it only has one sense - “viz” (a person that needs treatment). This shows that the information obtained by combining two languages can be more useful for WSD because the word senses in each language can complement each other. For it to be useful, MWSD needs a multilingual resource that contains different languages, such as BabelNet (Navigli and Ponzetto, 2010; 2012) and EuroWordNet (Vossen, 1998). 241 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 241–249, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics As the preferred disambiguation method, we decided to use the Ppr+Freq (Personalized Page Rank combined with Frequencies of senses) (Gutiérrez, 2012) method because, among unsupervised systems, graph-based methods have obtained more promising results. It is worth mentioning the relevant approaches used b</context>
<context position="4993" citStr="Navigli and Ponzetto, 2010" startWordPosition="733" endWordPosition="736">et al., 2007) 49.2% Ppr (Agirre and Soroa, 2009) 58.6% Table 1. Relevant WSD approaches. Recall measure is calculated recalls using SensEval-2 (English All Word task) guidelines over. Experiments using SensEval-2 and SensEval-3 corpora suggest that Ppr+Freq (Gutiérrez, 2012) can lead to better results by obtaining over 64% of Recall. Therefore we selected Ppr+Freq as the WSD method for our system. The key proposal for this work is an unsupervised algorithm for MWSD, which uses an unsupervised method, Ppr+Freq, for semantic disambiguation with resources like BabelNet (as sense inventory only) (Navigli and Ponzetto, 2010) and ISR-WN (as knowledge base) (Gutiérrez et al., 2011a; 2010a). ISR-WN was selected as the default knowledge base because of previous NLP research, which included: (Fernández et al., 2012; Gutiérrez et al., 2010b; Gutiérrez et al., 2012; 2011b; 2011c; 2011d), which achieved relevant results using ISRWN as their knowledge base. 2 System architecture By using one of BabelNet (BN) features, our technique begins by looking for all the Babel synsets (Bs) linked to the lemma of each word in the sentence that we need to disambiguate. Through the Bs offsets, we can get its corresponding WordNet Syns</context>
</contexts>
<marker>Navigli, Ponzetto, 2010</marker>
<rawString>Navigli, R. and S. P. Ponzetto. BabelNet: Building a Very Large Multilingual Semantic Network. Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, Uppsala, Sweden, Association for Computational Linguistics, 2010. 216--225 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>S P</author>
</authors>
<title>Ponzetto BabelNet: The automatic construction, evaluation and application of a widecoverage multilingual semantic network Artif. Intell.,</title>
<date>2012</date>
<volume>193</volume>
<pages>217--250</pages>
<marker>Navigli, P, 2012</marker>
<rawString>Navigli, R. and S. P. Ponzetto BabelNet: The automatic construction, evaluation and application of a widecoverage multilingual semantic network Artif. Intell., 2012, 193: 217-250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Navigli</author>
<author>P Velardi</author>
</authors>
<title>Structural Semantic Interconnections: A Knowledge-Based Approach to Word Sense Disambiguation</title>
<date>2005</date>
<journal>IEEE Transactions on Pattern Analysis and Machine Intelligence,</journal>
<volume>27</volume>
<issue>7</issue>
<pages>1075--1086</pages>
<contexts>
<context position="3907" citStr="Navigli and Velardi, 2005" startWordPosition="572" endWordPosition="575">013 Association for Computational Linguistics As the preferred disambiguation method, we decided to use the Ppr+Freq (Personalized Page Rank combined with Frequencies of senses) (Gutiérrez, 2012) method because, among unsupervised systems, graph-based methods have obtained more promising results. It is worth mentioning the relevant approaches used by the scientific community to achieve promising results. One approach used is structural interconnections, such as Structural Semantic Interconnections (SSI), which create structural specifications of the possible senses for each word in a context (Navigli and Velardi, 2005). The other approaches used are “Exploring the integration of WordNet” (Miller et al., 1990), FrameNet (Laparra et al., 2010) and those using Page-Rank such as (Sinha and Mihalcea, 2007) and (Agirre and Soroa, 2009). The aforementioned types of graph based approaches have achieved relevant results in both the SensEval-2 and SensEval-3 competitions (see Table 1). Algorithm Recall TexRank (Mihalcea, 2005) 54.2% (Sinha and Mihalcea, 2007) 56.4% (Tsatsaronis et al., 2007) 49.2% Ppr (Agirre and Soroa, 2009) 58.6% Table 1. Relevant WSD approaches. Recall measure is calculated recalls using SensEval-</context>
</contexts>
<marker>Navigli, Velardi, 2005</marker>
<rawString>Navigli, R. and P. Velardi Structural Semantic Interconnections: A Knowledge-Based Approach to Word Sense Disambiguation IEEE Transactions on Pattern Analysis and Machine Intelligence, 2005, 27(7): 1075-1086.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Sinha</author>
<author>R Mihalcea</author>
</authors>
<title>Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity.</title>
<date>2007</date>
<booktitle>Proceedings of the IEEE International Conference on Semantic Computing (ICSC 2007),</booktitle>
<location>Irvine, CA,</location>
<contexts>
<context position="4093" citStr="Sinha and Mihalcea, 2007" startWordPosition="601" endWordPosition="604">z, 2012) method because, among unsupervised systems, graph-based methods have obtained more promising results. It is worth mentioning the relevant approaches used by the scientific community to achieve promising results. One approach used is structural interconnections, such as Structural Semantic Interconnections (SSI), which create structural specifications of the possible senses for each word in a context (Navigli and Velardi, 2005). The other approaches used are “Exploring the integration of WordNet” (Miller et al., 1990), FrameNet (Laparra et al., 2010) and those using Page-Rank such as (Sinha and Mihalcea, 2007) and (Agirre and Soroa, 2009). The aforementioned types of graph based approaches have achieved relevant results in both the SensEval-2 and SensEval-3 competitions (see Table 1). Algorithm Recall TexRank (Mihalcea, 2005) 54.2% (Sinha and Mihalcea, 2007) 56.4% (Tsatsaronis et al., 2007) 49.2% Ppr (Agirre and Soroa, 2009) 58.6% Table 1. Relevant WSD approaches. Recall measure is calculated recalls using SensEval-2 (English All Word task) guidelines over. Experiments using SensEval-2 and SensEval-3 corpora suggest that Ppr+Freq (Gutiérrez, 2012) can lead to better results by obtaining over 64% of</context>
</contexts>
<marker>Sinha, Mihalcea, 2007</marker>
<rawString>Sinha, R. and R. Mihalcea. Unsupervised Graph-based Word Sense Disambiguation Using Measures of Word Semantic Similarity. Proceedings of the IEEE International Conference on Semantic Computing (ICSC 2007), Irvine, CA, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Strapparava</author>
<author>A Valitutti</author>
</authors>
<title>WordNet-Affect: an affective extension of WordNet.</title>
<date>2004</date>
<booktitle>Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004),</booktitle>
<pages>1083--1086</pages>
<location>Lisbon,</location>
<contexts>
<context position="10641" citStr="Strapparava and Valitutti, 2004" startWordPosition="1638" endWordPosition="1641">g to the other words that compose the context. The general method is shown in Figure 3. This method is divided into three steps: I. Creation of a disambiguation graph II. Application of Ppr+Freq in the generated graph III. Selection of the correct answer Creation of a disambiguation graph: In the first step, a disambiguation graph is built by means of a Breath First Search (BFS) over the “super” graph composed by all the resources integrated into ISRWN. The components involved in this process are: WordNet, SUMO (Zouaq et al., 2009) WordNet Domains (Magnini and Cavaglia, 2000) WordNet Affects (Strapparava and Valitutti, 2004) Semantic Classes (Izquierdo et al., 2007) and eXtended WordNet (XWN) relations (Moldovan and Rus, 2001). This search aims to recover all senses (nodes), domain labels (from WordNet Domain and WordNet Affects), SUMO categories, and Semantic Classes labels through the shortest path between every pair of senses in the WNSL set associated with the input sentence. Using ISR-WN as the KB, through experimentation, we obtained the shortest paths with a length of five edges. For a better understanding of this process, see (Gutiérrez, 2012). Application of Ppr+Freq in the generated graph: In the second</context>
</contexts>
<marker>Strapparava, Valitutti, 2004</marker>
<rawString>Strapparava, C. and A. Valitutti. WordNet-Affect: an affective extension of WordNet. Proceedings of the 4th International Conference on Language Resources and Evaluation (LREC 2004), Lisbon, 2004. 1083-1086 p.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Tsatsaronis</author>
<author>M Vazirgiannis</author>
<author>I Androutsopoulos</author>
</authors>
<title>Word sense disambiguation with spreading activation networks generated from thesauri. IJCAI,</title>
<date>2007</date>
<contexts>
<context position="4379" citStr="Tsatsaronis et al., 2007" startWordPosition="642" endWordPosition="645">ral Semantic Interconnections (SSI), which create structural specifications of the possible senses for each word in a context (Navigli and Velardi, 2005). The other approaches used are “Exploring the integration of WordNet” (Miller et al., 1990), FrameNet (Laparra et al., 2010) and those using Page-Rank such as (Sinha and Mihalcea, 2007) and (Agirre and Soroa, 2009). The aforementioned types of graph based approaches have achieved relevant results in both the SensEval-2 and SensEval-3 competitions (see Table 1). Algorithm Recall TexRank (Mihalcea, 2005) 54.2% (Sinha and Mihalcea, 2007) 56.4% (Tsatsaronis et al., 2007) 49.2% Ppr (Agirre and Soroa, 2009) 58.6% Table 1. Relevant WSD approaches. Recall measure is calculated recalls using SensEval-2 (English All Word task) guidelines over. Experiments using SensEval-2 and SensEval-3 corpora suggest that Ppr+Freq (Gutiérrez, 2012) can lead to better results by obtaining over 64% of Recall. Therefore we selected Ppr+Freq as the WSD method for our system. The key proposal for this work is an unsupervised algorithm for MWSD, which uses an unsupervised method, Ppr+Freq, for semantic disambiguation with resources like BabelNet (as sense inventory only) (Navigli and P</context>
</contexts>
<marker>Tsatsaronis, Vazirgiannis, Androutsopoulos, 2007</marker>
<rawString>Tsatsaronis, G.; M. Vazirgiannis and I. Androutsopoulos. Word sense disambiguation with spreading activation networks generated from thesauri. IJCAI, 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
</authors>
<title>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</title>
<date>1998</date>
<publisher>Dordrecht, Kluwer Academic Publishers,</publisher>
<contexts>
<context position="3070" citStr="Vossen, 1998" startWordPosition="463" endWordPosition="464"> words that have only one sense (or meaning), but in other languages, the same words can have different senses. For example, “patient” is a word that in English can be either a noun or an adjective, but in German, it only has one sense - “viz” (a person that needs treatment). This shows that the information obtained by combining two languages can be more useful for WSD because the word senses in each language can complement each other. For it to be useful, MWSD needs a multilingual resource that contains different languages, such as BabelNet (Navigli and Ponzetto, 2010; 2012) and EuroWordNet (Vossen, 1998). 241 Second Joint Conference on Lexical and Computational Semantics (*SEM), Volume 2: Seventh International Workshop on Semantic Evaluation (SemEval 2013), pages 241–249, Atlanta, Georgia, June 14-15, 2013. c�2013 Association for Computational Linguistics As the preferred disambiguation method, we decided to use the Ppr+Freq (Personalized Page Rank combined with Frequencies of senses) (Gutiérrez, 2012) method because, among unsupervised systems, graph-based methods have obtained more promising results. It is worth mentioning the relevant approaches used by the scientific community to achieve </context>
</contexts>
<marker>Vossen, 1998</marker>
<rawString>Vossen, P. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Dordrecht, Kluwer Academic Publishers, 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Zouaq</author>
<author>M Gagnon</author>
<author>B Ozell</author>
</authors>
<title>A SUMO-based Semantic Analysis for Knowledge Extraction.</title>
<date>2009</date>
<booktitle>Proceedings of the 4th Language &amp; Technology Conference,</booktitle>
<location>Poznań, Poland,</location>
<contexts>
<context position="10546" citStr="Zouaq et al., 2009" startWordPosition="1626" endWordPosition="1629">ut sentence. For that reason, it is necessary to classify the word senses according to the other words that compose the context. The general method is shown in Figure 3. This method is divided into three steps: I. Creation of a disambiguation graph II. Application of Ppr+Freq in the generated graph III. Selection of the correct answer Creation of a disambiguation graph: In the first step, a disambiguation graph is built by means of a Breath First Search (BFS) over the “super” graph composed by all the resources integrated into ISRWN. The components involved in this process are: WordNet, SUMO (Zouaq et al., 2009) WordNet Domains (Magnini and Cavaglia, 2000) WordNet Affects (Strapparava and Valitutti, 2004) Semantic Classes (Izquierdo et al., 2007) and eXtended WordNet (XWN) relations (Moldovan and Rus, 2001). This search aims to recover all senses (nodes), domain labels (from WordNet Domain and WordNet Affects), SUMO categories, and Semantic Classes labels through the shortest path between every pair of senses in the WNSL set associated with the input sentence. Using ISR-WN as the KB, through experimentation, we obtained the shortest paths with a length of five edges. For a better understanding of thi</context>
</contexts>
<marker>Zouaq, Gagnon, Ozell, 2009</marker>
<rawString>Zouaq, A.; M. Gagnon and B. Ozell. A SUMO-based Semantic Analysis for Knowledge Extraction. Proceedings of the 4th Language &amp; Technology Conference, Poznań, Poland, 2009.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>