<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.016853">
<title confidence="0.968977">
Processing Unknown Words in HPSG
</title>
<author confidence="0.809991">
Petra Barg and Markus Walther*
</author>
<affiliation confidence="0.5344755">
Seminar fiir Allgemeine Sprachwissenschaft
Heinrich-Heine-Universitat Düsseldorf
</affiliation>
<address confidence="0.871717">
Universitatsstr. 1, D-40225 Düsseldorf, Germany
</address>
<email confidence="0.981535">
fbarg,waltherl@ling.uni-duesseldorf.de
</email>
<sectionHeader confidence="0.997158" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.99991265">
The lexical acquisition system presented in this pa-
per incrementally updates linguistic properties of un-
known words inferred from their surrounding con-
text by parsing sentences with an HPSG grammar
for German. We employ a gradual, information-
based concept of &amp;quot;unknownness&amp;quot; providing a uni-
form treatment for the range of completely known to
maximally unknown lexical entries. &amp;quot;Unknown&amp;quot; in-
formation is viewed as revisable information, which
is either generalizable or specializable. Updating
takes place after parsing, which only requires a mod-
ified lexical lookup. Revisable pieces of informa-
tion are identified by grammar-specified declarations
which provide access paths into the parse feature
structure. The updating mechanism revises the cor-
responding places in the lexical feature structures iff
the context actually provides new information. For
revising generalizable information, type union is re-
quired. A worked-out example demonstrates the in-
ferential capacity of our implemented system.
</bodyText>
<sectionHeader confidence="0.999471" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.958424454545454">
It is a remarkable fact that humans can often un-
derstand sentences containing unknown words, in-
fer their grammatical properties and incrementally
refine hypotheses about these words when encoun-
tering later instances. In contrast, many current NLP
systems still presuppose a complete lexicon. Notable
exceptions include Zernik (1989), Erbach (1990),
Hastings &amp; Lytinen (1994). See Zernik for an intro-
duction to the general issues involved.
This paper describes an HPSG-based system
which can incrementally learn and refine proper-
ties of unknown words after parsing individual sen-
*This work was carried out within the Sondoforschungs-
bereich 282 Theorie des Lexikons&apos; (project B3), funded by the
German Federal Research Agency DFG. We thank James Kil-
bury and members of the B3 group for fruitful discussion.
tences. It focusses on extracting linguistic proper-
ties, as compared to e.g. general concept learning
(Hahn, Klenner &amp; Schnattinger 1996). Unlike Er-
bach (1990), however, it is not confined to sim-
ple morpho-syntactic information but can also han-
dle selectional restrictions, semantic types and argu-
ment structure. Finally, while statistical approaches
like Brent (1991) can gather e.g. valence informa-
tion from large corpora, we are more interested in
full grammatical processing of individual sentences
to maximally exploit each context.
The following three goals serve to structure
our model. It should i) incorporate a gradual,
information-based conceptualization of &amp;quot;unknown-
ness&amp;quot;. Words are not unknown as a whole, but
may contain unknown, i.e. revisable pieces of infor-
mation. Consequently, even known words can un-
dergo revision to es.. acquire new senses. This view
replaces the binary distinction between open and
closed class words. It should ii) maximally exploit
the rich representations and modelling conventions
of HPSG and associated formalisms, with essen-
tially the same grammar and lexicon as compared
to closed-lexicon approaches. This is important both
to facilitate reuse of existing grammars and to en-
able meaningful feedback for linguistic theorizing..
Finally, it should iii) possess domain-independent in-
ference and lexicon-updating capabilities. The gram-
mar writer must be able to fully declare which pieces
of information are open to revision.
The system was implemented using MicroCUF,
a simplified version of the CUF typed unification
formalism (Done &amp; Dorna 1993) that we imple-
mented in SICStus Prolog. It shares both the feature
logic and the definite clause extensions with its big
brother, but substitutes a closed-world type system
for CUF&apos;s open-world regime. A feature of our type
system implementation that will be significant later
on is that type information in internal feature struc-
</bodyText>
<page confidence="0.997879">
91
</page>
<bodyText confidence="0.999128227272727">
tures (FSs) can be easily updated.
The HPSG grammar developed with MicroCUF
models a fragment of German. Since our focus is on
the lexicon, the range of syntactic variation treated
is currently limited to simplex sentences with canon-
ical word order. We have incorporated some recent
developments of HPSG, esp. the revisions of Pol-
lard &amp; Sag (1994, ch. 9), Manning &amp; Sag (1995)&apos;s
proposal for an independent level of argument struc-
ture and Bouma (1997)&apos;s use of argument structure
to eliminate procedural lexical rules in favour of re-
lational constraints. Our elaborate ontology of se-
mantic types — useful for non-trivial acquisition of
selectional restrictions and nominal sorts — was de-
rived from a systematic corpus study of a biological
domain (Knodel 1980, 154-188). The grammar also
covers all valence classes encountered in the corpus.
As for the lexicon format, we currently list full forms
only. Clearly, a morphology component would sup-
ply more contextual information from known affixes
but would still require the processing of unknown
stems.
</bodyText>
<sectionHeader confidence="0.980101" genericHeader="method">
2 Incremental Lexical Acquisition
</sectionHeader>
<bodyText confidence="0.999773">
When compared to a previous instance, a new sen-
tential context can supply either identical, more spe-
cial, more general, or even conflicting information
along a given dimension. Example pairs illustrating
the latter three relationships are given under (1)-(3)
(words assumed to be unknown in bold face).
</bodyText>
<listItem confidence="0.99295175">
a. Im Axon tritt em n Ruhepotential auf.
&apos;a rest potential occurs in the axon&apos;
b. Das Potential wandert iiber das Axon.
&apos;the potential travels along the axon&apos;
a. Das Ohr reagiert auf akustische Reize.
&apos;the ear reacts to acoustic stimuli&apos;
b. Ein Sinnesorgan reagiert auf Reize.
&apos;a sense organ reacts to stimuli&apos;
a. Die Nase ist fiir Gerfiche sensibel.
&apos;the nose is sensitive to smells&apos;
b. Die sensible Nase reagiert auf Geriiche.
&apos;the sensitive nose reacts to smells&apos;
</listItem>
<bodyText confidence="0.999973">
In contrast to (la), which provides the information
that the gender of Axon is not feminine (via im), the
context in (lb) is more specialized, assigning neuter
gender (via das). Conversely, (2b) differs from (2a)
in providing a more general selectional restriction for
the subject of reagiert, since sense organs include
ears as a subtype. Finally, the adjective sensibel is
used predicatively in (3a), but attributively in (3b).
The usage types must be formally disjoint, because
some German adjectives allow for just one usage
(ehemalig &apos;former, attr.&apos;, schuld &apos;guilty, pred.&apos;).
On the basis of contrasts like those in (1)-(3) it
makes sense to statically assign revisable informa-
tion to one of two classes, namely specializable or
generalizable.1 Apart from the specializable kinds
&apos;semantic type of nouns&apos; and &apos;gender&apos;, the inflec-
tional class of nouns is another candidate (given a
morphological component). Generalizable kinds of
information include selectional restrictions of verbs
and adjectives&apos;, &apos;predicative vs attributive usage of
adjectives&apos; as well as &apos;case and form of PP argu-
ments&apos; and &apos;valence class of verbs&apos;. Note that spe-
cializable and generalizable information can cooccur
in a given lexical entry. A particular kind of informa-
tion may also figure in both classes, as e.g. seman-
tic type of nouns and selectional restrictions of verbs
are both drawn from the same semantic ontology. Yet
the former must be invariantly specialized — indepen-
dent of the order in which contexts are processed —,
whereas selectional restrictions on NP complements
should only become more general with further con-
texts.
</bodyText>
<subsectionHeader confidence="0.95977">
2.1 Representation
</subsectionHeader>
<bodyText confidence="0.9997164">
We require all revisable or updateable information to
be expressible as formal types.2 As relational clauses
can be defined to map types to FSs, this is not much
of a restriction in practice. Figure 1 shows a rele-
vant fragment. Whereas the combination of special-
</bodyText>
<figureCaption confidence="0.99565">
Figure 1: Excerpt from type hierarchy
</figureCaption>
<bodyText confidence="0.938517571428571">
izable information translates into simple type unifi-
cation (e.g. non_f em A neut = neut), combining
&apos;The different behaviour underlying this classification has
previously been noted by e.g. Erbach (1990) and Hastings &amp;
Lytinen (1994) but received either no implementational status or
no systematic association with arbitrary kinds of information.
21n HPSG types are sometimes also referred to as sorts.
</bodyText>
<figure confidence="0.943862571428571">
prd gender u_g
nom_sem
pred atir
non_fem fem
sti sense organ
masc neut
sound smell nose ear
</figure>
<page confidence="0.897814">
92
</page>
<bodyText confidence="0.999203709090909">
generalizable information requires type union (e.g.
pred V attr = prd). The latter might pose problems
for type systems requiring the explicit definition of
all possible unions, corresponding to least common
supertypes. However, type union is easy for (Mi-
cro)CUF and similar systems which allow for arbi-
trary boolean combinations of types. Generalizable
information exhibits another peculiarity: we need
a disjoint auxiliary type u_g to correctly mark the
initial unknown information state.3 This is because
&apos;content&apos; types like prd, pred, attr are to be inter-
preted as recording what contextual information was
encountered in the past. Thus, using any of these to
prespecify the initial value — either as the side-effect
of a feature appropriateness declaration (e.g. prd) or
through grammar-controlled specification (e.g. pred,
attr)— would be wrong (cf. prd initial v attr = prd,
but V attr = u_g V attr).
Generalizable information evokes another ques-
tion: can we simply have types like those in fig. 1
within HPSG signs and do in-place type union, just
like type unification? The answer is no, for essen-
tially two reasons. First, we still want to rule out
ungrammatical constructions through (type) unifica-
tion failure of coindexed values, so that generalizable
types cannot always be combined by nonfailing type
union (e.g. *der sensible Geruch &apos;the sensitive smell&apos;
must be ruled out via sense _or g an A smell = _L).
We would ideally like to order all type unifications
pertaining to a value before all unions, but this vi-
olates the order independence of constraint solv-
ing. Secondly, we already know that a given infor-
mational token can simultaneously be generalizable
and specializable, e.g. by being coindexed through
HPSG&apos;s valence principle. However, simultaneous
in-place union and unification is contradictory.
To avoid these problems and keep the declarative
monotonic setting, we employ two independent fea-
tures gen and ctxt. ctxt is the repository of contex-
tually unified information, where conflicts result in
ungrammaticality. gen holds generalizable informa-
tion. Since all gen values contain u_g as a type dis-
junct, they are always unifiable and thus not restric-
tive during the parse. To nevertheless get correct gen
values we perform type union after parsing, i.e. dur-
ing lexicon update. We will see below how this works
out.
3Actually, the situation is more symmetrical, as we need a
dual type ti.s to correctly mark &amp;quot;unknown&amp;quot; specializable infor-
mation. This prevents incorrect updating of known information.
However, :Ls is unnecessary for the examples presented below.
The last representational issue is how to identify
revisable information in (substructures of) the parse
FS. For this purpose the grammar defines revisability
clauses like the following:
</bodyText>
<figure confidence="0.970961875">
a. generalizablea, :=
[synsem [
bc I cat I head prd [gen
ctxt
adj
b. specializable(ED :=
[synsem loc [cat I head noun
cont I ind gend
</figure>
<subsectionHeader confidence="0.972209">
2.2 Processing
</subsectionHeader>
<bodyText confidence="0.999983421052631">
The first step in processing sentences with unknown
or revisable words consists of conventional parsing.
Any HPSG-compatible parser may be used, subject
to the obvious requirement that lexical lookup must
not fail if a word&apos;s phonology is unknown. A canon-
ical entry for such unknown words is defined as the
disjunction of maximally underspecified generic lex-
ical entries for nouns, adjectives and verbs.
The actual updating of lexical entries consists of
four major steps. Step 1 projects the parse FS derived
from the whole sentence onto all participating word
tokens. This results in word FSs which are contextu-
ally enriched (as compared to their original lexicon
state) and disambiguated (choosing the compatible
disjunct per parse solution if the entry was disjunc-
tive). It then filters the set of word FSs by unification
with the right-hand side of revisability clauses like in
(4). The output of step 1 is a list of update candidates
for those words which were unifiable.
Step 2 determines concrete update values for each
word: for each matching generalizable clause we
take the type union of the gen value of the old, lexical
state of the word (LexGen) with the ctxt value of its
parse projection (Ctxt):TU = LexGenUCtxt. For
each matching specializable(Spec) clause we take
the parse value Spec.
Step 3 checks whether updating would make a dif-
ference w.r.t. the original lexical entry of each word.
The condition to be met by generalizable information
is that TU LexGen, for specializable information
we similarly require Spec C Lex S pec.
In step 4 the lexical entries of words surviving step
3 are actually modified. We retract the old lexical en-
try, revise the entry and re-assert it. For words never
encountered before, revision must obviously be pre-
ceded by making a copy of the generic unknown en-
try, but with the new word&apos;s phonology. Revision it-
self is the destructive modification of type informa-
</bodyText>
<equation confidence="0.514012">
(4)
</equation>
<page confidence="0.993228">
93
</page>
<bodyText confidence="0.9998894">
tion according to the values determined in step 2,
at the places in a word FS pointed to by the revis-
ability clauses. This is easy in MicroCUF, as types
are implemented via the attributed variable mecha-
nism of SICStus Prolog, which allows us to substi-
tute the type in-place. In comparison, general updat-
ing of Prolog-encoded FSs would typically require
the traversal of large structures and be dangerous if
structure-sharing between substituted and unaffected
parts existed. Also note that we currently assume
DNF-expanded entries, so that updates work on the
contextually selected disjunct. This can be motivated
by the advantages of working with presolved struc-
tures at run-time, avoiding description-level opera-
tions and incremental grammar recompilation.
</bodyText>
<subsectionHeader confidence="0.982724">
2.3 A Worked-Out Example
</subsectionHeader>
<bodyText confidence="0.999585">
We will illustrate how incremental lexical revision
works by going through the examples under (5)-(7).
</bodyText>
<listItem confidence="0.992910428571429">
(5) Die Nase ist em n Sinnesorgan.
&apos;the nose is a sense organ&apos;
(6) Das Ohr perzipiert.
&apos;the ear perceives&apos;
(7) Eine verschnupfte Nase perzipiert den
Gestank.
&apos;a bunged up nose perceives the stench&apos;
</listItem>
<bodyText confidence="0.999786043478261">
The relevant substructures corresponding to the lex-
ical FSs of the unknown noun and verb involved
are depicted in fig. 2. The leading feature paths
synsem I loc I cont for Nase and synsem I loc cat&apos; arg-st
for perzipiert have been omitted.
After parsing (5) the gender of the unknown noun
Nase is instantiated to fern by agreement with the
determiner die. As the specializable clause (4b)
matches and the gend parse value differs from its
lexical value gender, gender is updated to fern. Fur-
thermore, the object&apos;s semantic type has percolated
to the subject Nase. Since the object&apos;s sense_organ
type differs from generic initial nom_sem,Nase&apos;s ctxt
value is updated as well. In place of the still nonex-
isting entry for perzipiert, we have displayed the rel-
evant part of the generic unknown verb entry.
Having parsed (6) the system then knows that
perzipiert can be used intransitively with a nomi-
native subject referring to ears. Formally, an HPSG
mapping principle was successful in mediating be-
tween surface subject and complement lists and the
argument list. Argument list instantiations are them-
selves related to corresponding types by a further
</bodyText>
<figure confidence="0.988758333333333">
Nase perzipiert
after (5)
[gendfem
gen u _g
CtXt sense _organ
after (6)
[gen u _gVnpnom
Cixt arg_struc
argS ([10c I cont {gen u 4V ear , )
ctxt nom_sem]] I —
after (7)
-gen ugVnpnomvnpnorn.npacc
[gendfem
ctxt nose]
gen ug
_ ctxt argstruc
args [loc I cont
{10C I cont [ctxt
Igen u _gV )
[cut nom_sem ji -
uno_gmvsseettnise_orgal
</figure>
<figureCaption confidence="0.999898">
Figure 2: Updates on lexical FSs
</figureCaption>
<bodyText confidence="0.999951870967742">
mapping. On the basis of this type classification of
argument structure patterns, the parse derived the
ctxt value npnom. Since gen values are generaliz-
able, this new value is unioned with the old lexi-
cal gen value. Note that ctxt is properly unaffected.
The first (subject) element on the args list itself is
targeted by another revisability clause. This has the
side-effect of further instantiating the underspecified
lexical FS. Since selectional restrictions on nominal
subjects must become more general with new con-
textual evidence, the union of ear and the old value
u_g is indeed appropriate.
Sentence (7) first of all provides more specific evi-
dence about the semantic type of partially known
Nase by way of attributive modification through ver-
schnupfte. The system detects this through the differ-
ence between lexical ctxt value sense_organ and the
parse value nose, so that the entry is specialized ac-
cordingly. Since the subject&apos;s synsem value is coin-
dexed with the first ergs element, [ctxt nose] simulta-
neously appears in the FS of perzipiert. However, the
revisability clause matching there is of class general-
izable, so union takes place, yielding ear V nose =
sense_organ (w.r.t. the simplified ontology of fiv...
1 used in this paper). An analogous match with the
second element of args identifies the necessary up-
date to be the unioning-in of smell, the semantic type
of Gestank. Finally, the system has learned that an
accusative NP object can cooccur with perzipiert, so
the argument structure type of gen receives another
update through union with npnom Apace .
</bodyText>
<figure confidence="0.8680092">
[gen ug 1
Lcbd arg
[gendfem
gen u,g
ctxt sense _organ
</figure>
<page confidence="0.994656">
94
</page>
<sectionHeader confidence="0.997569" genericHeader="conclusions">
3 Discussion
</sectionHeader>
<bodyText confidence="0.999961475409836">
The incremental lexical acquisition approach de-
scribed above attains the goals stated earlier. It re-
alizes a gradual, information-based conceptualiza-
tion of unknownness by providing updateable formal
types — classified as either generalizable or special-
izable — together with grammar-defined revisability
clauses. It maximally exploits standard HPSG rep-
resentations, requiring moderate rearrangements in
grammars at best while keeping with the standard
assumptions of typed unification formalisms. One
noteworthy demand, however, is the need for a type
union operation. Parsing is conventional modulo a
modified lexical lookup. The actual lexical revision
is done in a domain-independent postprocessing step
guided by the revisability clauses.
Of course there are areas requiring further consid-
eration. In contrast to humans, who seem to leap to
conclusions based on incomplete evidence, our ap-
proach employs a conservative form of generaliza-
tion, taking the disjunction of actually observed val-
ues only. While this has the advantage of not leading
to overgeneralization, the requirement of having to
encounter all subtypes in order to infer their com-
mon supertype is not realistic (sparse-data problem).
In (2) sense_organ as the semantic type of the first
argument of perzipiert is only acquired because the
simplified hierarchy in fig. 1 has nose and ear as its
only subtypes. Here the work of Li &amp; Abe (1995)
who use the MDL principle to generalize over the
slots of observed case frames might prove fruitful.
An important question is how to administrate
alternative parses and their update hypotheses. In
Das Aktionspotential erreicht den Dendriten &apos;the
action potential reaches the dendrite(s)&apos;, Dendriten
is ambiguous between acc.sg. and dat.pl., giving
rise to two valence hypotheses npnom_npacc and
npnommpdat for erreicht. Details remain to be
worked out on how to delay the choice between such
alternative hypotheses until further contexts provide
enough information.
Another topic concerns the treatment of &apos;cooc-
currence restrictions&apos;. In fig. 2 the system has in-
dependently generalized over the selectional restric-
tions for subject and object, yet there are clear cases
where this overgenerates (e.g. *Das Ohr perzipiert
den Gestank &apos;the ear perceives the stench&apos;). An idea
worth exploring is to have a partial, extensible list of
type cooccurrences, which is traversed by a recursive
principle at parse time.
A more general issue is the apparent antagonism
between the desire to have both sharp grammatical
predictions and continuing openness to contextual
revision. If after parsing (7) we transfer the fact that
smells are acceptable objects to perzipiert into the re-
stricting ctxt feature, a later usage with an object of
type sound fails. The opposite case concerns newly
acquired specializable values. If in a later context
these are used to update a gen value, the result may
be too general. It is a topic of future research when
to consider information certain and when to make re-
visable information restrictive.
</bodyText>
<sectionHeader confidence="0.999225" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999595525">
Bouma, G. (1997). Valence Alternation without Lexi-
cal Rules. In: Papers from the seventh CLIN Meet-
ing 1996, Eindhoven, 25-40.
Brent, M. R. (1991). Automatic Acquisition of Subcat-
egorization Frames From Untagged Text. In: Pro-
ceedings of 29th ACL, Berkeley, 209-214.
Done, J. &amp; M. Dorna (1993). CUF — A Formalism for
Linguistic Knowledge Representation. In: J. Done
(Ed.), Computational Aspects of Constraint-Based
Linguistic Description. IMS, Universiffit Stuttgart.
Deliverable R1 .2.A, DYANA-2 — ESPRIT Project
6852.
Erbach, G. (1990). Syntactic Processing of Un-
known Words. IWBS Report 131, Institute
for Knowledge-Based Systems (IWBS), IBM
Stuttgart.
Hahn, U., M. Klenner &amp; K. Schnattinger (1996).
Learning from Texts - A Terminological Meta-
Reasoning Perspective. In: S. Wermter, E. Riloff
&amp; G. Scheler (Ed.), Connectionist, Statistical, and
Symbolic Approaches to Learning for Natural Lan-
guage Processing, 453-468. Berlin: Springer.
Hastings, P. M. &amp; S. L. Lytinen (1994). The Ups and
Downs of Lexical Acquisition. In: Proceedings of
AA4P94, 754-759.
Knodel, H. (1980). Linder Biologie — Lehrbuch für
die Oberstufe. Stuttgart: J.B. Metzlersche Verlags-
buchhandlung.
Li, H. &amp; N. Abe (1995). Generalizing Case Frames Us-
ing a Thesaurus and the MDL Principle. In: Pro-
ceedings of Recent Advantages in Natural Lan-
guage Processing, Velingrad, Bulgaria, 239-248.
Manning, C. &amp; I. Sag (1995). Dissociations between
argument structure and grammatical relations. Ms.,
Stanford University.
Pollard, C. &amp; I. Sag (1994). Head-Driven Phrase
Structure Grammar. Chicago University Press.
Z,ernik, U. (1989). Paradigms in Lexical Acquisition.
In: U. Z,ernik (Ed.), Proceedings of the First Inter-
national Lexical Acquisition Workshop, Detroit.
</reference>
<page confidence="0.999073">
95
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.357634">
<title confidence="0.999637">Processing Unknown Words in HPSG</title>
<author confidence="0.667278">Barg Walther Seminar fiir Allgemeine Sprachwissenschaft</author>
<affiliation confidence="0.881675">Heinrich-Heine-Universitat Düsseldorf</affiliation>
<address confidence="0.890966">Universitatsstr. 1, D-40225 Düsseldorf, Germany</address>
<abstract confidence="0.998316809523809">The lexical acquisition system presented in this paper incrementally updates linguistic properties of unknown words inferred from their surrounding context by parsing sentences with an HPSG grammar for German. We employ a gradual, informationbased concept of &amp;quot;unknownness&amp;quot; providing a uniform treatment for the range of completely known to maximally unknown lexical entries. &amp;quot;Unknown&amp;quot; information is viewed as revisable information, which is either generalizable or specializable. Updating takes place after parsing, which only requires a modified lexical lookup. Revisable pieces of information are identified by grammar-specified declarations which provide access paths into the parse feature structure. The updating mechanism revises the corresponding places in the lexical feature structures iff the context actually provides new information. For revising generalizable information, type union is required. A worked-out example demonstrates the inferential capacity of our implemented system.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>G Bouma</author>
</authors>
<title>Valence Alternation without Lexical Rules. In: Papers from the seventh CLIN Meeting</title>
<date>1997</date>
<pages>25--40</pages>
<location>Eindhoven,</location>
<contexts>
<context position="4431" citStr="Bouma (1997)" startWordPosition="657" endWordPosition="658"> for CUF&apos;s open-world regime. A feature of our type system implementation that will be significant later on is that type information in internal feature struc91 tures (FSs) can be easily updated. The HPSG grammar developed with MicroCUF models a fragment of German. Since our focus is on the lexicon, the range of syntactic variation treated is currently limited to simplex sentences with canonical word order. We have incorporated some recent developments of HPSG, esp. the revisions of Pollard &amp; Sag (1994, ch. 9), Manning &amp; Sag (1995)&apos;s proposal for an independent level of argument structure and Bouma (1997)&apos;s use of argument structure to eliminate procedural lexical rules in favour of relational constraints. Our elaborate ontology of semantic types — useful for non-trivial acquisition of selectional restrictions and nominal sorts — was derived from a systematic corpus study of a biological domain (Knodel 1980, 154-188). The grammar also covers all valence classes encountered in the corpus. As for the lexicon format, we currently list full forms only. Clearly, a morphology component would supply more contextual information from known affixes but would still require the processing of unknown stems</context>
</contexts>
<marker>Bouma, 1997</marker>
<rawString>Bouma, G. (1997). Valence Alternation without Lexical Rules. In: Papers from the seventh CLIN Meeting 1996, Eindhoven, 25-40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M R Brent</author>
</authors>
<title>Automatic Acquisition of Subcategorization Frames From Untagged Text. In:</title>
<date>1991</date>
<booktitle>Proceedings of 29th ACL,</booktitle>
<pages>209--214</pages>
<contexts>
<context position="2426" citStr="Brent (1991)" startWordPosition="344" endWordPosition="345">ng individual sen*This work was carried out within the Sondoforschungsbereich 282 Theorie des Lexikons&apos; (project B3), funded by the German Federal Research Agency DFG. We thank James Kilbury and members of the B3 group for fruitful discussion. tences. It focusses on extracting linguistic properties, as compared to e.g. general concept learning (Hahn, Klenner &amp; Schnattinger 1996). Unlike Erbach (1990), however, it is not confined to simple morpho-syntactic information but can also handle selectional restrictions, semantic types and argument structure. Finally, while statistical approaches like Brent (1991) can gather e.g. valence information from large corpora, we are more interested in full grammatical processing of individual sentences to maximally exploit each context. The following three goals serve to structure our model. It should i) incorporate a gradual, information-based conceptualization of &amp;quot;unknownness&amp;quot;. Words are not unknown as a whole, but may contain unknown, i.e. revisable pieces of information. Consequently, even known words can undergo revision to es.. acquire new senses. This view replaces the binary distinction between open and closed class words. It should ii) maximally expl</context>
</contexts>
<marker>Brent, 1991</marker>
<rawString>Brent, M. R. (1991). Automatic Acquisition of Subcategorization Frames From Untagged Text. In: Proceedings of 29th ACL, Berkeley, 209-214.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Done</author>
<author>M Dorna</author>
</authors>
<title>CUF — A Formalism for Linguistic Knowledge Representation. In:</title>
<date>1993</date>
<booktitle>Computational Aspects of Constraint-Based Linguistic Description. IMS, Universiffit Stuttgart. Deliverable R1 .2.A, DYANA-2 — ESPRIT Project</booktitle>
<pages>6852</pages>
<editor>J. Done (Ed.),</editor>
<contexts>
<context position="3647" citStr="Done &amp; Dorna 1993" startWordPosition="525" endWordPosition="528"> the rich representations and modelling conventions of HPSG and associated formalisms, with essentially the same grammar and lexicon as compared to closed-lexicon approaches. This is important both to facilitate reuse of existing grammars and to enable meaningful feedback for linguistic theorizing.. Finally, it should iii) possess domain-independent inference and lexicon-updating capabilities. The grammar writer must be able to fully declare which pieces of information are open to revision. The system was implemented using MicroCUF, a simplified version of the CUF typed unification formalism (Done &amp; Dorna 1993) that we implemented in SICStus Prolog. It shares both the feature logic and the definite clause extensions with its big brother, but substitutes a closed-world type system for CUF&apos;s open-world regime. A feature of our type system implementation that will be significant later on is that type information in internal feature struc91 tures (FSs) can be easily updated. The HPSG grammar developed with MicroCUF models a fragment of German. Since our focus is on the lexicon, the range of syntactic variation treated is currently limited to simplex sentences with canonical word order. We have incorpora</context>
</contexts>
<marker>Done, Dorna, 1993</marker>
<rawString>Done, J. &amp; M. Dorna (1993). CUF — A Formalism for Linguistic Knowledge Representation. In: J. Done (Ed.), Computational Aspects of Constraint-Based Linguistic Description. IMS, Universiffit Stuttgart. Deliverable R1 .2.A, DYANA-2 — ESPRIT Project 6852.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Erbach</author>
</authors>
<title>Syntactic Processing of Unknown Words.</title>
<date>1990</date>
<tech>IWBS Report 131,</tech>
<institution>Institute for Knowledge-Based Systems (IWBS), IBM Stuttgart.</institution>
<contexts>
<context position="1600" citStr="Erbach (1990)" startWordPosition="217" endWordPosition="218">sponding places in the lexical feature structures iff the context actually provides new information. For revising generalizable information, type union is required. A worked-out example demonstrates the inferential capacity of our implemented system. 1 Introduction It is a remarkable fact that humans can often understand sentences containing unknown words, infer their grammatical properties and incrementally refine hypotheses about these words when encountering later instances. In contrast, many current NLP systems still presuppose a complete lexicon. Notable exceptions include Zernik (1989), Erbach (1990), Hastings &amp; Lytinen (1994). See Zernik for an introduction to the general issues involved. This paper describes an HPSG-based system which can incrementally learn and refine properties of unknown words after parsing individual sen*This work was carried out within the Sondoforschungsbereich 282 Theorie des Lexikons&apos; (project B3), funded by the German Federal Research Agency DFG. We thank James Kilbury and members of the B3 group for fruitful discussion. tences. It focusses on extracting linguistic properties, as compared to e.g. general concept learning (Hahn, Klenner &amp; Schnattinger 1996). Unl</context>
<context position="7977" citStr="Erbach (1990)" startWordPosition="1216" endWordPosition="1217">onal restrictions on NP complements should only become more general with further contexts. 2.1 Representation We require all revisable or updateable information to be expressible as formal types.2 As relational clauses can be defined to map types to FSs, this is not much of a restriction in practice. Figure 1 shows a relevant fragment. Whereas the combination of specialFigure 1: Excerpt from type hierarchy izable information translates into simple type unification (e.g. non_f em A neut = neut), combining &apos;The different behaviour underlying this classification has previously been noted by e.g. Erbach (1990) and Hastings &amp; Lytinen (1994) but received either no implementational status or no systematic association with arbitrary kinds of information. 21n HPSG types are sometimes also referred to as sorts. prd gender u_g nom_sem pred atir non_fem fem sti sense organ masc neut sound smell nose ear 92 generalizable information requires type union (e.g. pred V attr = prd). The latter might pose problems for type systems requiring the explicit definition of all possible unions, corresponding to least common supertypes. However, type union is easy for (Micro)CUF and similar systems which allow for arbitr</context>
</contexts>
<marker>Erbach, 1990</marker>
<rawString>Erbach, G. (1990). Syntactic Processing of Unknown Words. IWBS Report 131, Institute for Knowledge-Based Systems (IWBS), IBM Stuttgart.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>M Klenner</author>
<author>K Schnattinger</author>
</authors>
<title>Learning from Texts - A Terminological MetaReasoning Perspective. In:</title>
<date>1996</date>
<booktitle>Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing,</booktitle>
<pages>453--468</pages>
<publisher>Springer.</publisher>
<location>Berlin:</location>
<marker>Hahn, Klenner, Schnattinger, 1996</marker>
<rawString>Hahn, U., M. Klenner &amp; K. Schnattinger (1996). Learning from Texts - A Terminological MetaReasoning Perspective. In: S. Wermter, E. Riloff &amp; G. Scheler (Ed.), Connectionist, Statistical, and Symbolic Approaches to Learning for Natural Language Processing, 453-468. Berlin: Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P M Hastings</author>
<author>S L Lytinen</author>
</authors>
<title>The Ups and Downs of Lexical Acquisition. In:</title>
<date>1994</date>
<booktitle>Proceedings of AA4P94,</booktitle>
<pages>754--759</pages>
<contexts>
<context position="1627" citStr="Hastings &amp; Lytinen (1994)" startWordPosition="219" endWordPosition="222"> in the lexical feature structures iff the context actually provides new information. For revising generalizable information, type union is required. A worked-out example demonstrates the inferential capacity of our implemented system. 1 Introduction It is a remarkable fact that humans can often understand sentences containing unknown words, infer their grammatical properties and incrementally refine hypotheses about these words when encountering later instances. In contrast, many current NLP systems still presuppose a complete lexicon. Notable exceptions include Zernik (1989), Erbach (1990), Hastings &amp; Lytinen (1994). See Zernik for an introduction to the general issues involved. This paper describes an HPSG-based system which can incrementally learn and refine properties of unknown words after parsing individual sen*This work was carried out within the Sondoforschungsbereich 282 Theorie des Lexikons&apos; (project B3), funded by the German Federal Research Agency DFG. We thank James Kilbury and members of the B3 group for fruitful discussion. tences. It focusses on extracting linguistic properties, as compared to e.g. general concept learning (Hahn, Klenner &amp; Schnattinger 1996). Unlike Erbach (1990), however,</context>
<context position="8007" citStr="Hastings &amp; Lytinen (1994)" startWordPosition="1219" endWordPosition="1222">on NP complements should only become more general with further contexts. 2.1 Representation We require all revisable or updateable information to be expressible as formal types.2 As relational clauses can be defined to map types to FSs, this is not much of a restriction in practice. Figure 1 shows a relevant fragment. Whereas the combination of specialFigure 1: Excerpt from type hierarchy izable information translates into simple type unification (e.g. non_f em A neut = neut), combining &apos;The different behaviour underlying this classification has previously been noted by e.g. Erbach (1990) and Hastings &amp; Lytinen (1994) but received either no implementational status or no systematic association with arbitrary kinds of information. 21n HPSG types are sometimes also referred to as sorts. prd gender u_g nom_sem pred atir non_fem fem sti sense organ masc neut sound smell nose ear 92 generalizable information requires type union (e.g. pred V attr = prd). The latter might pose problems for type systems requiring the explicit definition of all possible unions, corresponding to least common supertypes. However, type union is easy for (Micro)CUF and similar systems which allow for arbitrary boolean combinations of ty</context>
</contexts>
<marker>Hastings, Lytinen, 1994</marker>
<rawString>Hastings, P. M. &amp; S. L. Lytinen (1994). The Ups and Downs of Lexical Acquisition. In: Proceedings of AA4P94, 754-759.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Knodel</author>
</authors>
<title>Linder Biologie — Lehrbuch für die Oberstufe.</title>
<date>1980</date>
<publisher>J.B. Metzlersche Verlagsbuchhandlung.</publisher>
<location>Stuttgart:</location>
<contexts>
<context position="4739" citStr="Knodel 1980" startWordPosition="705" endWordPosition="706">e of syntactic variation treated is currently limited to simplex sentences with canonical word order. We have incorporated some recent developments of HPSG, esp. the revisions of Pollard &amp; Sag (1994, ch. 9), Manning &amp; Sag (1995)&apos;s proposal for an independent level of argument structure and Bouma (1997)&apos;s use of argument structure to eliminate procedural lexical rules in favour of relational constraints. Our elaborate ontology of semantic types — useful for non-trivial acquisition of selectional restrictions and nominal sorts — was derived from a systematic corpus study of a biological domain (Knodel 1980, 154-188). The grammar also covers all valence classes encountered in the corpus. As for the lexicon format, we currently list full forms only. Clearly, a morphology component would supply more contextual information from known affixes but would still require the processing of unknown stems. 2 Incremental Lexical Acquisition When compared to a previous instance, a new sentential context can supply either identical, more special, more general, or even conflicting information along a given dimension. Example pairs illustrating the latter three relationships are given under (1)-(3) (words assume</context>
</contexts>
<marker>Knodel, 1980</marker>
<rawString>Knodel, H. (1980). Linder Biologie — Lehrbuch für die Oberstufe. Stuttgart: J.B. Metzlersche Verlagsbuchhandlung.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Li</author>
<author>N Abe</author>
</authors>
<title>Generalizing Case Frames Using a Thesaurus and the MDL Principle. In:</title>
<date>1995</date>
<booktitle>Proceedings of Recent Advantages in Natural Language Processing,</booktitle>
<pages>239--248</pages>
<location>Velingrad, Bulgaria,</location>
<contexts>
<context position="18781" citStr="Li &amp; Abe (1995)" startWordPosition="2960" endWordPosition="2963">tion. In contrast to humans, who seem to leap to conclusions based on incomplete evidence, our approach employs a conservative form of generalization, taking the disjunction of actually observed values only. While this has the advantage of not leading to overgeneralization, the requirement of having to encounter all subtypes in order to infer their common supertype is not realistic (sparse-data problem). In (2) sense_organ as the semantic type of the first argument of perzipiert is only acquired because the simplified hierarchy in fig. 1 has nose and ear as its only subtypes. Here the work of Li &amp; Abe (1995) who use the MDL principle to generalize over the slots of observed case frames might prove fruitful. An important question is how to administrate alternative parses and their update hypotheses. In Das Aktionspotential erreicht den Dendriten &apos;the action potential reaches the dendrite(s)&apos;, Dendriten is ambiguous between acc.sg. and dat.pl., giving rise to two valence hypotheses npnom_npacc and npnommpdat for erreicht. Details remain to be worked out on how to delay the choice between such alternative hypotheses until further contexts provide enough information. Another topic concerns the treatm</context>
</contexts>
<marker>Li, Abe, 1995</marker>
<rawString>Li, H. &amp; N. Abe (1995). Generalizing Case Frames Using a Thesaurus and the MDL Principle. In: Proceedings of Recent Advantages in Natural Language Processing, Velingrad, Bulgaria, 239-248.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Manning</author>
<author>I Sag</author>
</authors>
<title>Dissociations between argument structure and grammatical relations. Ms.,</title>
<date>1995</date>
<institution>Stanford University.</institution>
<contexts>
<context position="4356" citStr="Manning &amp; Sag (1995)" startWordPosition="643" endWordPosition="646"> clause extensions with its big brother, but substitutes a closed-world type system for CUF&apos;s open-world regime. A feature of our type system implementation that will be significant later on is that type information in internal feature struc91 tures (FSs) can be easily updated. The HPSG grammar developed with MicroCUF models a fragment of German. Since our focus is on the lexicon, the range of syntactic variation treated is currently limited to simplex sentences with canonical word order. We have incorporated some recent developments of HPSG, esp. the revisions of Pollard &amp; Sag (1994, ch. 9), Manning &amp; Sag (1995)&apos;s proposal for an independent level of argument structure and Bouma (1997)&apos;s use of argument structure to eliminate procedural lexical rules in favour of relational constraints. Our elaborate ontology of semantic types — useful for non-trivial acquisition of selectional restrictions and nominal sorts — was derived from a systematic corpus study of a biological domain (Knodel 1980, 154-188). The grammar also covers all valence classes encountered in the corpus. As for the lexicon format, we currently list full forms only. Clearly, a morphology component would supply more contextual information</context>
</contexts>
<marker>Manning, Sag, 1995</marker>
<rawString>Manning, C. &amp; I. Sag (1995). Dissociations between argument structure and grammatical relations. Ms., Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Pollard</author>
<author>I Sag</author>
</authors>
<title>Head-Driven Phrase Structure Grammar.</title>
<date>1994</date>
<publisher>Chicago University Press.</publisher>
<contexts>
<context position="4326" citStr="Pollard &amp; Sag (1994" startWordPosition="636" endWordPosition="640">eature logic and the definite clause extensions with its big brother, but substitutes a closed-world type system for CUF&apos;s open-world regime. A feature of our type system implementation that will be significant later on is that type information in internal feature struc91 tures (FSs) can be easily updated. The HPSG grammar developed with MicroCUF models a fragment of German. Since our focus is on the lexicon, the range of syntactic variation treated is currently limited to simplex sentences with canonical word order. We have incorporated some recent developments of HPSG, esp. the revisions of Pollard &amp; Sag (1994, ch. 9), Manning &amp; Sag (1995)&apos;s proposal for an independent level of argument structure and Bouma (1997)&apos;s use of argument structure to eliminate procedural lexical rules in favour of relational constraints. Our elaborate ontology of semantic types — useful for non-trivial acquisition of selectional restrictions and nominal sorts — was derived from a systematic corpus study of a biological domain (Knodel 1980, 154-188). The grammar also covers all valence classes encountered in the corpus. As for the lexicon format, we currently list full forms only. Clearly, a morphology component would supp</context>
</contexts>
<marker>Pollard, Sag, 1994</marker>
<rawString>Pollard, C. &amp; I. Sag (1994). Head-Driven Phrase Structure Grammar. Chicago University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Z ernik</author>
<author>U</author>
</authors>
<title>Paradigms in Lexical Acquisition. In: U. Z,ernik (Ed.),</title>
<date>1989</date>
<booktitle>Proceedings of the First International Lexical Acquisition Workshop,</booktitle>
<location>Detroit.</location>
<marker>ernik, U, 1989</marker>
<rawString>Z,ernik, U. (1989). Paradigms in Lexical Acquisition. In: U. Z,ernik (Ed.), Proceedings of the First International Lexical Acquisition Workshop, Detroit.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>