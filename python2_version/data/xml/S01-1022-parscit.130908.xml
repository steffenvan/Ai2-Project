<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000158">
<title confidence="0.825351">
The SprAkdata-ML System as Used for SENSEVAL-2
</title>
<author confidence="0.871214">
Dimitrios KOKKINAKIS
</author>
<affiliation confidence="0.855374">
Spradata, Goteborg University
</affiliation>
<address confidence="0.716542">
Box 200, SE-405 30
Goteborg, Sweden
</address>
<email confidence="0.771418">
Dimitrios.Kokkinakis @svenska.gu.se
</email>
<sectionHeader confidence="0.890318" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999777666666667">
This paper describes the Sprakdata-ML
system as used in the SENSEVAL-2
exercise. The main focus of the paper is
devoted to the process of feature extraction,
preparation and organization of the test and
training data.
</bodyText>
<sectionHeader confidence="0.854179" genericHeader="introduction">
Introduction
</sectionHeader>
<bodyText confidence="0.999681275862069">
The methodology followed for sense
disambiguation of the Swedish data by the
Sprakdata-ML system is supervised, based on
Machine Learning (ML) techniques, particularly
Memory Based Learning (MBL). The MBL
implementation we used originates from the
university of Tilburg in a system called TiMBL;
details can be found in Daelemans et al, (1999).
Thus, our main contribution in this task has been
the effort to try and isolate a set of features that
could maximize the performance of the MBL
software. However, it is rather difficult to give
the exact number of features and examples
required for an adequate description of a word&apos;s
sense or which algorithm performs best. We
think that there is space for improvement of our
system&apos;s performance by better modeling of the
available resources (e.g. context, annotations),
choice of parameters and algorithms, a claim
that we have not explored to its full potential,
further exploration is required. Intelligent
example selection for supervised learning is an
important issue in ML, an issue that we have not
fully explored. In previous experiments for a
similar problem for Swedish, the algorithm that
performed best in TiMBL was a variant of the k-
nearest neighbor (Mitchell, 1997) called IB1, an
algorithm that we also used in the exercise;
(Kokkinakis &amp; Johansson Kokkinalcis, 1999).
</bodyText>
<sectionHeader confidence="0.59242" genericHeader="method">
1 Data Preparation (Train)
</sectionHeader>
<bodyText confidence="0.996829304347826">
To enhance the lexical disambiguation results
using the available resources, we perform pre-
processing in both the dictionary and the text to
be sense-disambiguated. This is motivated by
the fact that by making certain normalizations
and simplifications in the resources we
(hopefully) contribute to the production of
qualitatively better results.
Initially, a text to be disambiguated is pre-
processed by a tokeniser, a sentence boundary
identifier, an idiom&apos; and multiword identifier, a
Name-Entity recogniser2, a part-of-speech
tagger, a lemrnatiser and a semantic tagger3.
Then, the input texts are transformed to the
specified format that the MBL requires, which is
feature-vectors of a specific length and content.
The vectors we use consist of 102 features, the
last two being the id-number and class or sense
assigned to the vector. Since we do not know in
advance which features will be useful for each
particular word and sense, we chose to include
features from a number of different information
sources.
</bodyText>
<sectionHeader confidence="0.837487" genericHeader="method">
2 Vector Creation
</sectionHeader>
<bodyText confidence="0.9985165">
The vectors consisted of: (i) selected
information gathered from the dictionary entries
(5 features); (ii) near-context (5 features); (iii)
annotations applied on the training corpus (5
</bodyText>
<footnote confidence="0.8964038">
1 The idioms originate from the Gothenburg Lexical
Data B ase/Semantic Database (GLDB/SDB)
(http://spraakdata.gu.se/lb/gldb.html) and were used
for the recognition and marking of idioms in the
test/training corpus (over 4,000 idioms).
2 See http://spraakdata.gu.se/svedk/ne.html for a
demo.
3 The semantic tagger originates from work by
Kolckinakis et al. (2000) and uses the SIMPLE
semantic classes for annotation (only nouns).
</footnote>
<page confidence="0.999356">
91
</page>
<bodyText confidence="0.7714255">
features); and (iv) information acquired from the
lemmatised training corpus (85 features).
The corpus instances and dictionary were in
XML format. An example of a corpus instance
(1) for the first sense of the noun barn &apos;child&apos; and
a fragment of its dictionary description (2) are:
</bodyText>
<listItem confidence="0.959183266666667">
(1) &lt;instance id=&amp;quot;barn.114&amp;quot;&gt;&lt;answer
instance=&amp;quot;barn.114&amp;quot; senseid=&amp;quot;barn_1_1&amp;quot;
/&gt; &lt;context&gt;... forsoken sa att spadbarnen
sjalva kunde styra de retningar som de
utsattes f6r under forsoket, lnom
sprakforskningen betyder det att
&lt;head&gt;barnen&lt;/head&gt; kan paverka hur
olika talljud presenteras. Nar de far ...
&lt;/context&gt; &lt;/instance&gt;
(2) &lt;lemma-entry id=&amp;quot;barn_1&amp;quot; form= &amp;quot;barn&amp;quot;
pos=&amp;quot;n&amp;quot; inflection=&amp;quot;-et .&amp;quot;&gt;&lt;lexeme id=
&amp;quot;barn_1_1&amp;quot;&gt;&lt;definition&gt; manniska som ej
vuxit fardigt&lt;/definition&gt; &lt;definition-ext&gt;till
kropp och sjal; under ngn aldersgrans som
beror pa samman-hanget&lt;/definition-ext&gt;
</listItem>
<construct confidence="0.5504218125">
&lt;synt-example&gt;lwinnor och slapptes fria
&lt;/synt-example&gt;&lt;synt-example&gt;- under 6
ãr kommer in gratis&lt;/synt-
example&gt;&lt;compound&gt;spadbarn&lt;/compoun
cl&gt;...&lt;cycle id=&amp;quot; barn_1_1_a&amp;quot;&gt;&lt;trans&gt;spec.
cm manniska som ej Watt pubertetsaider,
straff-myndighetsalder etc.&lt;/trans&gt;&lt;synt-
example&gt; annu nagot ár är hon ett -&lt;/synt-
example&gt;&lt;compound&gt; barnarbete
&lt;/compound&gt;&lt;compound&gt;barnavardsnamn
d&lt;/compou nd&gt;&lt;I cycle&gt; ...&lt;1 lexeme&gt;&lt;lexe
me&gt; ...&lt;cycle id=&amp;quot; barn_1_2_a&amp;quot;&gt; &lt;trans&gt;
ay. utvidgat, spec. cm foster &lt;/trans&gt;&lt;synt-
example&gt;hon ar med &lt;/synt-
example&gt;&lt;valency&gt;med - &lt;/valency&gt;
&lt;/cycle&gt;...&lt;11exeme&gt;&lt;Ilemma-en try&gt;
</construct>
<subsectionHeader confidence="0.862696">
2.1 Vector Creation (Dictionary)
</subsectionHeader>
<bodyText confidence="0.99988425">
The modeling of the vectors was performed in
stages. The first stage of the processing uses the
information from the dictionary. For every sense
and sub-sense we extracted five representative
nouns from the definition (and the definition
extension) by applying part-of-speech tagging,
lemmatization and exclusion of a number of
generic nouns from a stop-list e.g. manniska
&apos;human&apos; (a). If the number of nouns were less
than five, we completed the list with compounds
(if available).
Furthermore, the syntactic examples were
used as training corpus and were added to the
training instances (b). The valency information
(if any) was also used in the same way (c).
Consequently the amount of training material
increased with 1,296 &amp;quot;new&amp;quot; disambiguated
instances. A &amp;quot;dummy&amp;quot; XXX instance-number
was given in these cases.
We did not put much effort on a more
complex processing of the definitions since
these are very short. The representations given
below use the dictionary and corpus sample
provided in (1) and (2).
</bodyText>
<figure confidence="0.976476538461538">
(a) &lt;definition&gt;manniska som ej vuxit
fardigt&lt;/definition&gt;&lt;definition-ext&gt;till
kropp och sjal; under ngn aldersgrans som
beror pa sammanhanget &lt;/definition-ext&gt;
become: barn_1_1: kropp, sjal, aldersgrans
(b) &lt;synt-example&gt;kvinnor och slapptes
fria&lt;/synt-example&gt;
become: &lt;instance id=&amp;quot;barn.XXX&amp;quot;&gt;
&lt;answer instance=&amp;quot;barn.XXX&amp;quot; senseid=
&amp;quot;barn_1_1&amp;quot;/&gt; &lt;context&gt; kvinnor och
&lt;head&gt;barn&lt;/head&gt; slapptes fria
&lt;/context&gt;&lt;/instance&gt;
(c) &lt;valency&gt;med -&lt;/valency&gt;
</figure>
<figureCaption confidence="0.75015675">
become: &lt;instance id=&amp;quot;barn.XXX&amp;quot;&gt;
&lt;answer instance=&amp;quot;barn.XXX&amp;quot; senseid=
&amp;quot;barn_1_2_a&amp;quot;/&gt;&lt;context&gt; med &lt;head&gt;barn
&lt;/head&gt; &lt;/context&gt;&lt;/instance&gt;
</figureCaption>
<subsectionHeader confidence="0.973754">
2.2 Vector Creation (Near Context)
</subsectionHeader>
<bodyText confidence="0.96986075">
The second stage involved the use of the near-
context. Punctuation, auxiliary verbs and a
number of other stop-words were removed and
the surrounding tokens (±2) of each headword in
the corpus were extracted (d). Only the lemma
form of the headwords was used, and the context
was not lemmatized:
(d) &lt;instance id=&amp;quot;barn.114&amp;quot;&gt;&lt;answer
instance=&amp;quot;barn.114&amp;quot; senseid= &amp;quot;barn_1_1&amp;quot;
/&gt;&lt;context&gt;... sprakforskningen betyder
det att &lt;head&gt;barnen &lt;/head&gt; kah paverka
huf olika ...&lt;/context&gt; &lt;/instance&gt;
</bodyText>
<footnote confidence="0.7449432">
became: &lt;instance id=&amp;quot;barn.114&amp;quot;&gt;
&lt;answer instance=&amp;quot;barn.114&amp;quot; senseid=&amp;quot;
barn_1_1&amp;quot;/&gt;&lt;context&gt;sprakforskningen
betyder &lt;head&gt;barn&lt;/head&gt; paverka olika
&lt;context&gt;&lt;/instance&gt;
</footnote>
<page confidence="0.989796">
92
</page>
<subsectionHeader confidence="0.867406">
2.3 Vector Creation (Global Features)
</subsectionHeader>
<bodyText confidence="0.999843384615385">
During the third stage, the training corpus was
processed by a name-entity recognizer (e.g.
HUMAN, TIME), an idiom identifier (IDIOM) and
a semantic tagger (e.g. BIO, ETHNOS,
PHENOMENON). The annotations produced by
these tools were gathered in the form of a list of
labels, and the five most frequent in the
respective set of instances for each sense and
sub-sense were used in the vectors. For example,
for the sense barn_l_l the five most frequent
annotations found in all training instances were:
BIO, ORGANIZATION-AGENCY, LOCATION, SITU
and OCCUPATION-AGENT.
</bodyText>
<subsectionHeader confidence="0.871087">
2.4 Vector Creation (Global Context)
</subsectionHeader>
<bodyText confidence="0.99111965">
Often, near-context cannot distinguish between
different senses. In such cases it is useful to look
at a larger context and extract keywords
representative for each sense. We made a
frequency list of all noun and verb occurrences
for all corpus instances for each sense. From the
produced lists, 85 keywords per sense were
extracted by eliminating high frequency (a word
occurred in more than X percent of the cases
with the sense) and low frequency words (a
word occurred at least Z times in the list). For
the sense barn_l_l the 85 keywords included:
ansikte, ansvar, apparatur, arm, awikelse,
barnmorska, barnomsorg, beredskap,
betala, bild, detalj, dialog, djur, docka,
erfarenhet, fel, forestallning, forslag,
After the collection and combination of the 95
features common to a sense (stages i, iii, iv in
Section 2, el), a complete case for a sense was
produced (e2):
</bodyText>
<construct confidence="0.911277333333333">
(el) Lemma_SENSE: 5 words from the
dictionary information, 5 &amp;quot;semantic&amp;quot; labels,
85 representative words from the global
context
(e2) barni kropp, sjal, smabarn, spadbarn,
aldersgrans, Bio, ORGANIZATION-AGENCY,
LOCATION, SITU, OCCUPATION-AGENT,
ansikte, ansvar, apparatur, arm, avvikelse,
barnmorska, barnomsorg,
</construct>
<bodyText confidence="0.998059142857143">
We assume then, that for each training instance
the above list is &amp;quot;true&amp;quot; and we convert the
training instances into vectors of 102 features,
where the 95 positions of the features in each
vector were substituted with &apos;1&apos; keeping intact
the near context. Thus, the truncated training
instance in (f) was re-formatted to (g):
</bodyText>
<figure confidence="0.672095333333333">
(f) &lt;instance id=&amp;quot;barn.114&amp;quot;&gt;&lt;answer
instance=&amp;quot;barn.114&amp;quot; senseid= &amp;quot;barn_1_1&amp;quot;
/&gt;&lt;context&gt;sprakforskningen betyder
&lt;head&gt;barn4head&gt; paverka olika
&lt;context&gt;&lt;/instance&gt;
(g) sprakforskningen, betyder,&lt;head&gt;bani
&lt;/head&gt;, paverka, olika, 1, 1, 1, 1, 1, 1,
barn.114, bam_1_1.
3 Data Preparation (Test)
</figure>
<bodyText confidence="0.891930486486486">
The test material consisted of 1,525 corpus
instances in the same format as the previous
training example, but without any designation of
the correct senseid. The material was processed
in a similar manner as the training one. The
major difference lies in the fact that at the
vector-creation stage we used the feature-vectors
representative for a sense, example (e)
previously, and we compared them with the
features produced for each test instance. A
feature at a specific position then was assigned
&apos;1&apos; if the feature in the test occurred in the
representative feature vector or &apos;0&apos; otherwise.
For instance, the test instance in (h) was
transformed, after processing, to a 102-feature-
vector.
(h) &lt;instance id=&amp;quot;barn.114&amp;quot;&gt;&lt;answer
instance=&amp;quot;barn.114&amp;quot; senseid= &amp;quot;9999&amp;quot;
/&gt;&lt;context&gt;I jungfrukammaren innanfor
k6ket bodde en kokerska och en husa. [ Ett
hus fyllt av minnen ] Huset är fyllt av minnen.
1 fotoalbumen kan vi se farmor omgiven av
sina sma vitkladda &lt;head&gt;barn&lt;/head&gt; och
pappa i sjornanskostym lutad mot en bjark. 1
farfars svarta, snidade skrivbord
&lt;/context&gt; &lt;/instance&gt;
The class of the representative sense-vector that
produced more &apos;1&apos;s for the test instance was
chosen as the class of that instance. In (i) there
are four &apos;1&apos;s which means that the specific test
instance had four common features with the
representative vector for sense barn_l_2_a, and
less than four for all the other representative
vectors for the rest of the senses for barn. Thus,
the class for the test instance is assigned that
sense (which may be altered by the MBL
software during the nearest-neighbor
</bodyText>
<page confidence="0.995913">
93
</page>
<bodyText confidence="0.996986222222222">
calculation). Thus, the test instance in (h) was
transformed to the format illustrated in (i). The
four Ts denote that there were four features in
common with the representative vector for
barn_1_2_a, the rest of the representative sense-
vectors for barn (e.g. barn_1_1_a, barn_1_1_b
etc.) had less common features than four, and so
barn_1_2_a was chosen:
(i) sma, vitkladda, &lt;head&gt;barn&lt;Thead&gt;, pappa,
i, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,0,
0, 0, 0, 0, 0, 0, barn.114, barn_1_2_a
The training and test feature vectors were then
fed to the TiMBL software, where the IB1
algorithm (nearest neighbor search) was used.
</bodyText>
<sectionHeader confidence="0.999816" genericHeader="evaluation">
4 Results
</sectionHeader>
<bodyText confidence="0.999950833333333">
Table 1 shows the evaluation of the test material.
Since answers were provided for the whole
material, precision and recall obtain the same
value. Coarse-grain evaluation was not used,
however coarse-grained is considered the least
interesting of the three measures.
</bodyText>
<table confidence="0.959997125">
INSTANCES FINE MIXED
ADJECTIVES 191 48,2% 54,4%
NOUNS 616 71,3% 74,9%
VERBS 718 57,8% 66,1%
MOST FREQ. 45,3%
BASELINE
WHOLE 1,525 62,0% 68,2%
SAMPLE
</table>
<tableCaption confidence="0.9625195">
Table 1. Official results for the
Sprakdata-ML system
</tableCaption>
<sectionHeader confidence="0.647162" genericHeader="conclusions">
Conclusion
</sectionHeader>
<bodyText confidence="0.999952">
The existence of sense ambiguity (polysemy and
homonymy) is one of the major problems
affecting the usefulness of basic corpus
exploration tools. In this respect, we regard
sense disambiguation as a very important
process and component when it is seen in the
context of a wider and deeper text-processing
architecture. In this paper we have described a
simple feature-vector extraction approach to
sense disambiguation that was utilized in a MBL
software. We do not believe that we have fully
exploited the capabilities of either the software
or the way we can model the available resources.
These issues will be investigated in the future, as
well as the evaluation of the sense-tagger on an
even larger scale.
</bodyText>
<sectionHeader confidence="0.992199" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997754">
Daelemans W., Zavrel J., van der Sloot K. and van
den Bosch A. (1999). TiMBL: Tilburg Memory
Based Learner, version 2.0, Reference Guide. ELK
Technical Report 99-01, Paper available from:
http://ilk. ku b. n1/-ilk/pape rs/iIk9901 .ps.gz.
Koklcinakis D. and Johansson Kolckinakis S. (1999).
Sense Tagging at the Cycle-Level Using GLDB.
Nordiska Studier i Lexikografi, vol. 27:146-167.
Gellerstam M., Johannesson K., Ralph B. and
Rogstrom L. (eds). Nordiska Foreningen for
Lexikografi &amp; Meijerbergs Institut for Svensk
Etymologisk Forskning.
Koklcinalcis D., Toporowska Gronostaj M. and
Warmenius K. (2000). Annotating, Disambiguating
&amp; Automatically Extending the Coverage of the
Swedish SIMPLE Lexicon. Proceedings of the 2nd
Languages Resources and Evaluation Conference
(LREC), vol. III:1397-1404. Athens, Hellas,
Mitchell T. M. (1997). Machine Learning. McGraw-
Hill Series on Computer Science.
</reference>
<page confidence="0.99955">
94
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.088003">
<title confidence="0.913415">The SprAkdata-ML System as Used for SENSEVAL-2 Dimitrios</title>
<author confidence="0.263565">Goteborg Spradata</author>
<address confidence="0.822752">Box 200, SE-405</address>
<email confidence="0.559686">Goteborg,</email>
<note confidence="0.643829">Dimitrios.Kokkinakis @svenska.gu.se</note>
<abstract confidence="0.997865714285714">This paper describes the Sprakdata-ML system as used in the SENSEVAL-2 exercise. The main focus of the paper is devoted to the process of feature extraction, preparation and organization of the test and training data.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>W Daelemans</author>
<author>J Zavrel</author>
<author>K van der Sloot</author>
<author>A van den Bosch</author>
</authors>
<title>TiMBL: Tilburg Memory Based Learner, version 2.0, Reference Guide.</title>
<date>1999</date>
<tech>ELK Technical Report 99-01, Paper</tech>
<marker>Daelemans, Zavrel, van der Sloot, van den Bosch, 1999</marker>
<rawString>Daelemans W., Zavrel J., van der Sloot K. and van den Bosch A. (1999). TiMBL: Tilburg Memory Based Learner, version 2.0, Reference Guide. ELK Technical Report 99-01, Paper available from: http://ilk. ku b. n1/-ilk/pape rs/iIk9901 .ps.gz.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Koklcinakis</author>
<author>Johansson Kolckinakis S</author>
</authors>
<title>Sense Tagging at the Cycle-Level Using GLDB.</title>
<date>1999</date>
<journal>Nordiska Studier i Lexikografi,</journal>
<volume>vol.</volume>
<pages>27--146</pages>
<note>Gellerstam</note>
<marker>Koklcinakis, S, 1999</marker>
<rawString>Koklcinakis D. and Johansson Kolckinakis S. (1999). Sense Tagging at the Cycle-Level Using GLDB. Nordiska Studier i Lexikografi, vol. 27:146-167. Gellerstam M., Johannesson K., Ralph B. and Rogstrom L. (eds). Nordiska Foreningen for Lexikografi &amp; Meijerbergs Institut for Svensk Etymologisk Forskning.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Koklcinalcis</author>
<author>Toporowska Gronostaj M</author>
<author>K Warmenius</author>
</authors>
<date>2000</date>
<booktitle>Annotating, Disambiguating &amp; Automatically Extending the Coverage of the Swedish SIMPLE Lexicon. Proceedings of the 2nd Languages Resources and Evaluation Conference (LREC),</booktitle>
<volume>vol.</volume>
<pages>1397--1404</pages>
<location>Athens, Hellas,</location>
<marker>Koklcinalcis, M, Warmenius, 2000</marker>
<rawString>Koklcinalcis D., Toporowska Gronostaj M. and Warmenius K. (2000). Annotating, Disambiguating &amp; Automatically Extending the Coverage of the Swedish SIMPLE Lexicon. Proceedings of the 2nd Languages Resources and Evaluation Conference (LREC), vol. III:1397-1404. Athens, Hellas,</rawString>
</citation>
<citation valid="true">
<authors>
<author>T M Mitchell</author>
</authors>
<date>1997</date>
<booktitle>Machine Learning. McGrawHill Series on Computer Science.</booktitle>
<contexts>
<context position="1638" citStr="Mitchell, 1997" startWordPosition="251" endWordPosition="252">ption of a word&apos;s sense or which algorithm performs best. We think that there is space for improvement of our system&apos;s performance by better modeling of the available resources (e.g. context, annotations), choice of parameters and algorithms, a claim that we have not explored to its full potential, further exploration is required. Intelligent example selection for supervised learning is an important issue in ML, an issue that we have not fully explored. In previous experiments for a similar problem for Swedish, the algorithm that performed best in TiMBL was a variant of the knearest neighbor (Mitchell, 1997) called IB1, an algorithm that we also used in the exercise; (Kokkinakis &amp; Johansson Kokkinalcis, 1999). 1 Data Preparation (Train) To enhance the lexical disambiguation results using the available resources, we perform preprocessing in both the dictionary and the text to be sense-disambiguated. This is motivated by the fact that by making certain normalizations and simplifications in the resources we (hopefully) contribute to the production of qualitatively better results. Initially, a text to be disambiguated is preprocessed by a tokeniser, a sentence boundary identifier, an idiom&apos; and multi</context>
</contexts>
<marker>Mitchell, 1997</marker>
<rawString>Mitchell T. M. (1997). Machine Learning. McGrawHill Series on Computer Science.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>