<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.067193">
<title confidence="0.960063">
Avoiding Repetition in Generated Text
</title>
<author confidence="0.802755">
Mary Ellen Foster
</author>
<affiliation confidence="0.5503295">
Informatik VI: Robotics and Embedded Systems
Technische Universit¨at M¨unchen
</affiliation>
<address confidence="0.619522">
Boltzmannstr. 3, 85748 Garching, Germany
</address>
<email confidence="0.979877">
foster@in.tum.de
</email>
<author confidence="0.99508">
Michael White
</author>
<affiliation confidence="0.994781">
Department of Linguistics
The Ohio State University
</affiliation>
<address confidence="0.798662">
Columbus, OH 43210 USA
</address>
<email confidence="0.998695">
mwhite@ling.osu.edu
</email>
<sectionHeader confidence="0.995638" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999302">
We investigate two methods for enhancing varia-
tion in the output of a stochastic surface realiser:
choosing from among the highest-scoring realisa-
tion candidates instead of taking the single highest-
scoring result (E-best sampling), and penalising the
words from earlier sentences in a discourse when
generating later ones (anti-repetition scoring). In
a human evaluation study, subjects were asked to
compare texts generated with and without the vari-
ation enhancements. Strikingly, subjects judged the
texts generated using these two methods to be bet-
ter written and less repetitive than the texts gener-
ated with optimal n-gram scoring; at the same time,
no significant difference in understandability was
found between the two versions. In analysing the
two methods, we show that the simpler E-best sam-
pling method is considerably more prone to intro-
ducing dispreferred variants into the output, indi-
cating that best results can be obtained using anti-
repetition scoring with strict or no E-best sampling.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999826354166667">
A classic rule of writing, found in many style
guides, is to avoid repetition in order to keep text
interesting and make it more lively. When design-
ing systems to automatically generate text, it is often
taken for granted that this stylistic goal should be
met as well: for example, van Deemter et al. (2005)
incorporated random choice into a language gener-
ation system “to maximise the variety of sentences
produced” (emphasis original).
Repetitiveness may take several forms: using the
same words or syntactic structures, repeatedly giv-
ing the same facts, or even repeating entire turns (for
example, error-handling turns in dialogue systems).
At the level of word choice and phrasing, recent
advances in stochastic text generation have made
it possible to implement corpus-based approaches
to varying output. However, as Stone et al. (2004)
note, there is an inherent conflict between produc-
ing output that is optimally similar to the corpus and
incorporating variability: varying output requires
choosing less frequent options, which inevitably re-
duces scores on corpus similarity measures. To the
extent that corpus-based measures (such as n-gram
scores) are used to avoid overgeneration and select
preferred paraphrases, it is not obvious how to en-
hance variation without reducing output quality.
With this question in mind, we investigate in this
paper the impact of two different methods for en-
hancing variation in the output generated by the
COMIC multimodal dialogue system.1 Both meth-
ods take advantage of the periphrastic ability of the
OpenCCG surface realiser (White, 2006a). In the
usual OpenCCG realisation process, when a logical
form is transformed into output text, n-gram mod-
els are used to steer the realiser towards the single
highest-scoring option for the sentence. This pro-
cess tends to select the same syntactic structure for
every sentence describing the same feature: for ex-
ample, in the COMIC domain (describing and com-
paring bathroom tiles), the structure The colours are
[colours] would be used every time the colours of a
tile design are to be presented, even though alterna-
tive paraphrases are available.
The first (and simplest) means of avoiding such
repetition using OpenCCG, E-best sampling, is to
perform n-best realisation and then to select ran-
domly from among those options whose score is
within a threshold E of the top score. The second
</bodyText>
<footnote confidence="0.984353">
1http://www.hcrc.ed.ac.uk/comic/
</footnote>
<page confidence="0.998678">
33
</page>
<bodyText confidence="0.999968155172414">
means of adding variation, anti-repetition scoring,
is to store the words from recently generated sen-
tences and to penalise a proposed realisation based
on the number of words that it shares with these
sentences. OpenCCG provides a built-in facility for
implementing such anti-repetition scorers and inte-
grating them with the normal n-gram–based scoring
algorithm (White, 2005).
To verify that it can be beneficial for a natural
language generation system to strive to avoid repeti-
tion, we first conducted a human evaluation study in
which subjects were asked to compare texts gener-
ated with and without the two variation-enhancing
methods. Strikingly, subjects judged the versions
generated using F--best sampling and anti-repetition
scoring to be both better written and less repetitive
than the versions generated with optimal n-gram
scoring. To our knowledge, this study is the first to
show a clear benefit for enhancing variation; while
other recent studies (e.g., Stent et al., 2005; Belz
and Reiter, 2006) have shown that automatic eval-
uation metrics do not always correlate well with hu-
man judgments of high quality generated texts with
periphrastic variations, these studies examined sen-
tences out of context, and thus could not take into
account the benefit of avoiding repetition as a dis-
course progresses.
Following the human evaluation study, we varied
the main parameters used in F--best sampling and
anti-repetition scoring and analysed the resulting
impact on the amount of periphrastic variation and
the number of dispreferred paraphrases in the gener-
ated outputs. The analysis revealed that the simpler
F--best sampling method is considerably more prone
to introducing dispreferred variants into the output.
It also showed that essentially the same amount of
variation can be achieved using anti-repetition scor-
ing on its own, or just with strict F--best sampling, as
using both methods together. This suggests a way
of resolving the conflict between enhancing varia-
tion and maximising corpus similarity.
The rest of this paper is structured as follows. In
Section 2, we describe previous work on generat-
ing paraphrases. In Section 3, we next summarise
the realisation process of the OpenCCG surface re-
aliser, concentrating on its use of n-gram models in
the generation process and its support for disjunc-
tive logical forms. In Section 4, we then give details
of how the two anti-repetition methods were inte-
grated into this realisation algorithm. Section 5 next
presents the result of the human evaluation study.
In Section 6, we then explore the impact of the two
anti-repetition methods on the variability and qual-
ity of the generated text, using a range of parameter
settings. In Section 7, we discuss the results of both
studies and compare them with related work. Fi-
nally, in Section 8, we give some conclusions and
outline possible extensions to this work.
</bodyText>
<sectionHeader confidence="0.99342" genericHeader="introduction">
2 Previous Work
</sectionHeader>
<bodyText confidence="0.999957952380952">
The acquisition and generation of paraphrases has
been studied for some time (cf. Iordanskaja et al.,
1991; Langkilde and Knight, 1998; Barzilay and
McKeown, 2001; Barzilay and Lee, 2003; Pang
et al., 2003). Much recent work in this area has fo-
cussed on the automated acquisition of paraphrases
from corpora, along with the use of the result-
ing paraphrases in language-processing areas such
as information extraction and retrieval, question-
answering, and machine translation.
The main technique that has been used for adding
variation to stochastically-generated output is to
modify the system so that it does not always choose
the same option in a given situation, normally by
modifying either the weights or the selection strat-
egy. When selecting a combination of speech and
body-language output for an animated character
based on a corpus of recorded behaviour, for exam-
ple, Stone et al. (2004) introduced variation by per-
turbing the scores slightly to choose from among
low-cost utterances. The outputs from the system
with perturbed weights scored nearly as high on an
automated evaluation as those from the optimised
system, and also made use of a wider range of cor-
pus data. Belz and Reiter’s (2006) “greedy roulette”
pCRU text-generation system selected among gen-
eration rules weighted by their corpus probabilities,
while Foster and Oberlander (2006) used a similar
technique to select facial displays for an animated
talking head. Both of these systems scored higher
on a human evaluation than at least one competing
system that always chose the single highest-scoring
option; see Section 7 for further discussion.
The CRAG-2 system (Isard et al., 2006) gen-
erates dialogues between pairs of agents who are
linguistically distinguishable but able to align with
each other. It uses the OpenCCG surface realiser to
select appropriate paraphrases for the desired per-
sonality of the simulated character and the stage of
the dialogue, integrating cache models built from
the preceding discourse with the primary n-gram
models to attain lexico-syntactic alignment. The
</bodyText>
<page confidence="0.998373">
34
</page>
<bodyText confidence="0.9991996">
method of anti-repetition scoring described in this
paper is similar, but the goal is opposite: instead of
increasing alignment with an interlocutor, here we
modify the n-gram scores to avoid alignment with
the system’s own previous utterances.
</bodyText>
<sectionHeader confidence="0.936136" genericHeader="method">
3 Surface Realisation with OpenCCG
</sectionHeader>
<bodyText confidence="0.999981870967742">
The studies described in this paper use the
OpenCCG open source surface realiser (White,
2006a,b), which is based on Steedman’s (2000)
Combinatory Categorial Grammar (CCG). A distin-
guishing feature of OpenCCG is that it uses a hy-
brid symbolic-statistical chart realisation algorithm
combining (1) a theoretically grounded approach to
syntax and semantic composition with (2) integrated
language models for making choices among the op-
tions left open by the grammar. In so doing, it brings
together the traditions of symbolic chart realisation
(Kay, 1996; Carroll et al., 1999) and statistical re-
alisation (Langkilde and Knight, 1998; Langkilde,
2000; Bangalore and Rambow, 2000; Langkilde-
Geary, 2002). Another recent approach to combin-
ing these traditions appears in (Carroll and Oepen,
2005), where parse selection techniques are incor-
porated into an HPSG realiser.
In OpenCCG, the search for complete realisations
makes use of n-gram language models and proceeds
in one of two modes, anytime or two-stage (pack-
ing/unpacking). In the anytime mode, a best-first
search is performed with a configurable time limit:
the scores assigned by the n-gram model determine
the order of the edges on the agenda, and thus have
an impact on realisation speed. In the two-stage
mode, a packed forest of all possible realisations
is created in the first stage; in the second stage,
the packed representation is unpacked in bottom-up
fashion, with scores assigned to the edge for each
sign as it is unpacked, much as in (Langkilde, 2000).
To realise a broad range of paraphrases,
OpenCCG implements an algorithm for efficiently
generating from disjunctive logical forms (LFs)
(White, 2006a). A disjunctive LF represents the full
set of possible syntactic paraphrases of a sentence:
the differences may be subtle (e.g., choosing be-
tween the design or it as the subject), or may involve
entirely different structures (e.g., here we have a de-
sign in the classic style vs. this design is classic).
The algorithm uses packed representations similar
to those initially proposed by Shemtov (1997), en-
abling it to run many times faster than sequential re-
alisation of an equivalent set of non-disjunctive LFs.
The implementation described here makes use of
the OpenCCG grammar developed as part of the
COMIC multimodal dialogue system. This gram-
mar was manually written with the aim of achieving
very high quality. However, to streamline grammar
development, the grammar was allowed to overgen-
erate in areas where rules are difficult to write and
where n-gram models can be reliable; in particular,
the grammar does not sufficiently constrain modi-
fier order, which in the case of adverb placement
especially can lead to a large number of possible
orderings. To select preferred word orders among
those allowed by the grammar for the input LF, we
used a backoff 4-gram model trained on approx-
imately 750 example target sentences, where cer-
tain words were replaced with their semantic classes
(e.g. MANUFACTURER, COLOUR) for better gener-
alisation, much as in (Oh and Rudnicky, 2002).
</bodyText>
<sectionHeader confidence="0.999892" genericHeader="method">
4 Anti-Repetition Methods
</sectionHeader>
<bodyText confidence="0.999325548387097">
For both studies in this paper, we used OpenCCG
to realise a range of texts describing and comparing
bathroom-tile designs. The starting point for this
implementation was the XSLT-based text planner
from the COMIC system (Foster and White, 2004),
which transforms sets of facts about tile designs into
OpenCCG logical forms. We enhanced this text
planner to produce disjunctive logical forms cover-
ing the full range of paraphrases permitted by the
most recent version of the COMIC grammar, and
then used OpenCCG realise those forms as text.
In the normal OpenCCG realisation process out-
lined above, corpus-based n-grams are used to se-
lect the single highest-scoring realisation for a given
logical form. To allow the realiser to choose para-
phrases other than the top-scoring one, we modified
the realisation process in two ways: F--best sampling
and anti-repetition scoring.
F--best sampling was implemented by creating the
full set of possible surface realisations for a given
disjunctive LF, and then randomly selecting one
from the set whose n-gram score is within a given
threshold of the top score. As the scores for sen-
tences can vary by several orders of magnitude,
the threshold was specified as a distance in log-
10 space. Depending on the threshold value, this
method can add more or less variation to the gen-
erated text. There is a danger that, if the threshold
is too large and the grammar overgenerates, the out-
put may include paraphrases that are dispreferred,
or even ungrammatical.
</bodyText>
<page confidence="0.998218">
35
</page>
<figureCaption confidence="0.72606">
Figure 1: Sample description sequence realised in both modes
Default (no anti-repetition methods)
</figureCaption>
<bodyText confidence="0.995468405405405">
This design is country. It is based on the Sand-
stein collection by Porcelaingres. The colours
are brown, grey and black. There are geomet-
ric shapes on the decorative tiles.
This design is also country. It is based on
the Cardiff collection by Aparici. The colours
are cream and dark red. It also has geometric
shapes on the decorative tiles.
With anti-repetition methods
Here is a design in the country style. It uses
tiles from the Sandstein collection by Porce-
laingres. It has brown, grey and black in the
colour scheme. The decorative tiles have geo-
metric shapes.
This one is also country. It draws from
Cardiff, by Aparici. The colour scheme fea-
tures cream and dark red. The decorative tiles
also have geometric shapes.
Anti-repetition scoring was implemented as fol-
lows. First, for a proposed realisation, the number
c of open-class words repeated from the preceding
discourse was counted. This count was weighted:
a word that appeared in the immediately preceding
context received a full count of 1, one that appeared
only in the context before that was weighted at 0.5,
one from further back at 0.25, and so on. The rep-
etition score r for a proposed realisation was then
10−p∗c, where p is the specific penalty value. This
formula returns 1 if there are no repeated items, and
returns a score that is linear in log space with the
number of repeated items otherwise. The overall
score for a proposed realisation was computed by
multiplying r by the normal corpus-based n-gram
score. In this way, preferences regarding word or-
der and function words are still determined by the
n-gram model, since the anti-repetition scorer only
considers single open-class words.
</bodyText>
<sectionHeader confidence="0.970784" genericHeader="method">
5 Human Judgement Study
</sectionHeader>
<bodyText confidence="0.9990685">
As a first test of the effectiveness of the two anti-
repetition methods, we measured human judges’
subjective responses to texts generated with and
without these methods.
</bodyText>
<subsectionHeader confidence="0.989479">
5.1 Materials and presentation
</subsectionHeader>
<bodyText confidence="0.999918333333333">
For this study, we used the text planner to cre-
ate disjunctive logical forms for a set of eight de-
scription sequences. Each sequence consisted of
four consecutive descriptions of tile patterns, us-
ing a fixed structure for all descriptions. We then
used OpenCCG to generate text from these logical
forms in two ways: in the default mode with no anti-
repetition methods enabled, and with both ε-best
sampling and anti-repetition scoring enabled, using
a value of 20 for the parameter in each. For the anti-
repetition scorer, each description as a whole pro-
vided the context for the sentences in the next: that
</bodyText>
<figureCaption confidence="0.999443">
Figure 2: Evaluation interface
</figureCaption>
<bodyText confidence="0.999964714285715">
is, an entire set of sentences describing one design
was realised, and then the words from all of those
sentences were added to the context before the next
description was processed. Figure 1 shows the first
two descriptions of one of the generated sequences
realised in both modes.
The experiment was run over the world-wide web
and proceeded as follows. A participant was pre-
sented with both versions of each generated se-
quence in turn, in an individual randomly-chosen
order. The order of presentation was counterbal-
anced so that each participant saw the default ver-
sion first for four of the sequences, and the anti-
repetition version first for the other four. A small
thumbnail image of the tile design being described
was shown beside each description. For each se-
quence, participants answered three forced-choice
questions: which of the versions was (1) easier to
understand, (2) more repetitive, and (3) better writ-
ten. Figure 2 shows the user interface for this eval-
uation running in a web browser.
</bodyText>
<page confidence="0.976712">
36
</page>
<figure confidence="0.9974985">
225
200
175
150
Choice count
125
100
75
50
25
0
210
Default Anti-repetition
157 180
135
112
82
Understandable Repetitive Better written
Mean edit distance
22.5
17.5
12.5
2.5
7.5
25
20
15
10
5
0
Penalty
0 1 5 10 20
0 1 5 10 20
Threshold
</figure>
<figureCaption confidence="0.999887">
Figure 3: Results of the human evaluation
</figureCaption>
<subsectionHeader confidence="0.967566">
5.2 Participants and results
</subsectionHeader>
<bodyText confidence="0.999994066666667">
A total of 37 subjects took part in the evaluation
study. All were native speakers of English; 20 were
female, and 17 male. Since one subject answered
half of the questions, this resulted in a total of 292
responses for each question.
The overall results are presented in Figure 3.
For the understandability question, subjects chose
the anti-repetition version in 157 cases (54%); this
preference was not significant on a binomial test
(p ≈ 0.2). However, the responses to the other two
questions did show significant preferences: subjects
chose the default version as more repetitive 210
times (72%) and the anti-repetition version as better
written 180 times (62%). Both of these preferences
are significant at the p &lt; 0.0001 level.
</bodyText>
<sectionHeader confidence="0.985392" genericHeader="method">
6 Exploring the Parameter Settings
</sectionHeader>
<bodyText confidence="0.999708117647059">
The results of the user evaluation show that subjects
found text generated with anti-repetition methods
both less repetitive and better written. However,
both methods depend on the value of a parameter:
the threshold for F--best sampling, and the repetition
penalty for anti-repetition scoring. In the human
evaluation, both parameters were set to the rather
large value of 20. In this section, we explore the rel-
ative impact of the two methods by varying the con-
figuration of the realiser and examining the gener-
ated texts for two factors: the variability across de-
scriptions and the rate of dispreferred paraphrases.
For this experiment, we created the logical forms
for a new set of 20 sequences of four descriptions,
similar to those created for the human evaluation.
For each sequence, we ran the realiser on all of the
logical forms in turn, using all combinations of the
</bodyText>
<figureCaption confidence="0.997217">
Figure 4: Mean edit distances
</figureCaption>
<bodyText confidence="0.999993733333334">
following values for each parameter: 0, 1, 5, 10, and
20. A threshold of 0 means that the realiser choose
the highest-scoring result, while a repetition penalty
of 0 amounts to no repetition penalty at all. When
both parameters are set to 0, this corresponds to the
default sequences from the human evaluation; when
both parameters are 20, this corresponds to the anti-
repetition sequences from that study.
As in the previous study, we realised all of the
sentences for a given description and then added the
results to the context for the anti-repetition scorer
for the next descriptions. To compensate for any
variability introduced into the process by the ran-
dom choice in F--best sampling, we realised the
whole set of 20 sequences a total of six times.
</bodyText>
<subsectionHeader confidence="0.988066">
6.1 Variability
</subsectionHeader>
<bodyText confidence="0.992780684210526">
To assess the variability in a generated description
sequence, we computed the edit distance between
all pairs of descriptions in the sequence; that is, the
number of insertions, deletions, and replacements
required to transform one description into another.
Gu´egan and Hernandez (2006) used a similar edit-
distance-based metric to detect parallelism in texts.
The score for a sequence was the mean edit distance
between all pairs of descriptions in the sequence,
where a higher score indicates greater variability.
As a concrete example, the edit distance between
the two default descriptions in Figure 1 is 10, while
the distance between the anti-repetition descriptions
is 24; the mean edit distance for the sequences from
the human evaluation was 13.4 for the default ver-
sions and 23.1 for the anti-repetition versions.
Figure 4 shows the mean edit distance for all set-
tings of the parameters. Each set of five bars cor-
responds to a different setting of the threshold pa-
</bodyText>
<page confidence="0.999098">
37
</page>
<figureCaption confidence="0.999281">
Figure 5: Counts for dispreferred paraphrases
</figureCaption>
<figure confidence="0.999387957446809">
Threshold
(a) Sentence-initial and sentence-final also
Threshold
(b) we have ... here and we here have
Threshold
(c) is family
Penalty
0 1 5 10 20
35
30
Description count
25
20
15
10
5
0
0 1 5 10 20
20
20
0 1 5 10
0 1 5 10
35
30
Description count
25
20
15
10
5
0
0 1 5 10 20
Penalty
0 1 5 10 20
Penalty
50
45
40
35
30
25
20
15
Description count
10
5
0
</figure>
<bodyText confidence="0.998312933333333">
rameter; within a set of bars, each shows the re-
sult with a different value for the penalty. To as-
sess the significance of these results, we performed
a linear regression, treating the values of each pa-
rameter as levels of an ordered factor. The result-
ing model explained approximately 70% of the to-
tal variance (R2 = 0.71). The regression coeffi-
cients for each of the individual factors (threshold
and penalty) were both significantly greater than
0 (p &lt; 0.0001), showing that an increase in either
tended to result in a corresponding increase in the
edit distance. However, the regression coefficient
for the interaction of the factors is negative (also
p &lt; 0.0001), indicating that the effect of the two
methods is not simply additive.
</bodyText>
<subsectionHeader confidence="0.999388">
6.2 Dispreferred paraphrases
</subsectionHeader>
<bodyText confidence="0.988097647058824">
To measure the rate of dispreferred paraphrases, we
searched for specific word sequences that are per-
mitted by the COMIC grammar, but that were delib-
erately not included in the OpenCCG n-gram mod-
els. Normally, the corpus-based n-grams ensure that
such realisations are never included in the output;
however, when the selection strategy is modified as
described here, such word sequences can end up be-
ing selected. The occurrences of the following sub-
strings were counted: sentence-initial and sentence-
final also; we here have ... and we have ... here
(instead of here we have); is family (instead of is
in the family style).2 In the anti-repetition descrip-
tions used in the human evaluation, there was one
instance each of is family and sentence-initial also.
Figure 5 shows the counts of dispreferred para-
phrases under all of the parameter settings; again,
</bodyText>
<footnote confidence="0.97704075">
2Unlike classic style, family style is actually a noun-noun
compound, but is not modelled that way in the grammar for
uniformity. This means that the grammar also generates is fam-
ily, which is odd, so n-grams were used to avoid this wording.
</footnote>
<bodyText confidence="0.999895827586207">
each group of bars corresponds to a different set-
ting of the ε-best threshold, while each bar within
the group represents a different value for the anti-
repetition penalty. A total of 480 descriptions were
generated under each combination of parameter set-
tings: 20 sequences, each consisting of 4 descrip-
tions, each generated 6 times. The count for each
setting indicates the number of those descriptions
that contained the specific substring. For example,
35 (7%) of the descriptions generated with both pa-
rameters set to 20 contained is family (Figure 5(c)).
By inspection, it is clear that all dispreferred para-
phrases tend to occur very infrequently at low pa-
rameter settings and to increase as the threshold
increases; increasing the anti-repetition appears to
have an effect only on is family.
To assess the significant factors for each of the
dispreferred paraphrases, we analysed the influence
of both parameters on the rate of that paraphrase by
fitting a log-linear model to the contingency table of
frequency counts for each of the paraphrase types;
this type of model is suitable for use on count data
and allows us to assess the influence of each of the
factors on the counts in the table. The results con-
firm what is evident from the graph: increasing the
threshold has a significant influence on the rate of
all three of the paraphrases (p &lt; 0.0001, ANOVA),
while increasing the repetition penalty affects only
the occurrence of is family (also p &lt; 0.0001).
</bodyText>
<sectionHeader confidence="0.998049" genericHeader="method">
7 Discussion
</sectionHeader>
<bodyText confidence="0.999950571428571">
The results of the user evaluation show that human
judges strongly preferred the texts generated with
the anti-repetition methods, even though the corpus-
based n-gram score of such texts is lower than the
score of the texts generated without such methods.
This result agrees with the results of other recent
studies that compared human preferences on gener-
</bodyText>
<page confidence="0.997966">
38
</page>
<bodyText confidence="0.99997871875">
ated output with the prediction of corpus-based sim-
ilarity measures (e.g., Stent et al., 2005; Belz and
Reiter, 2006; Foster and Oberlander, 2006). In all
of these studies, human judges generally preferred
outputs that incorporated more variation, even if the
results were less similar to the corpus examples; on
the other hand, corpus-based measures tended to
favour output that did not diverge far, on average,
from the corpus data.
By specifically concentrating on the effect of rep-
etition in a discourse context, the results of the
user study extend those of previous evaluations of
the impact of variation in automatically-generated
output, which generally presented the materials as
a series of isolated examples. For example, Belz
and Reiter (2006) evaluated a range of knowledge-
based stochastic surface realisers. Their “greedy
roulette” implementation, which selected genera-
tion rules based on corpus probabilities, had a sim-
ilar effect on the generated texts as our variation
methods: their implementation “will tend to use dif-
ferent words and phrases in different texts, whereas
the other statistical generators will stick to those
with the highest frequency.” This generator was pe-
nalised by automated evaluation measures because
it tended to diverge from the corpus more than the
others; however, the expert human judges ranked
the output of this generator better than their bigram
generator, though not as highly at their greedy one.
We considered two methods for avoiding repeti-
tion while generating text: ε-best sampling and anti-
repetition scoring. These two methods were both
straightforward to add to OpenCCG’s stochastic re-
alisation process. Both had a significant effect on
the variability across a sequence of descriptions, as
measured by the mean edit distance between the ele-
ments of the sequence, although the effect of the two
techniques was not additive. ε-best sampling also
tended to increase the incidence of all dispreferred
n-grams as the threshold value is increased, while
anti-repetition scoring increased the rate only of the
dispreferred n-grams that involved lexical choice.
If we compare the preferences in the user evalu-
ation with the results of the automated studies, we
see that the users tended to prefer the outputs that
had higher variability. The materials generated for
the user study happened to have very few dispre-
ferred paraphrases—one instance each of is family
and sentence-initial also—so it is difficult to draw
definitive conclusions. The responses for the also
description are similar to those on the entire set;
however, for the description with is family, the re-
sponses were significantly different. On this sin-
gle item, 70% of the subjects chose the descrip-
tion generated without the anti-repetition methods
(and therefore without the dispreferred paraphrase)
as being better written; the responses on this ques-
tion are significantly different than those on the rest
of the items (χ2 = 12.5, df = 1, p &lt; 0.0001). This
suggests that, while the variability introduced by the
anti-repetition methods is indeed appreciated by the
human judges, there is nevertheless a real danger
that departing too far from the corpus examples can
lead to undesirable outputs.
</bodyText>
<sectionHeader confidence="0.990265" genericHeader="conclusions">
8 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999989055555555">
We have described two methods for enhancing the
variation in the output of the OpenCCG surface
realiser: ε-best sampling and anti-repetition scor-
ing. In a human evaluation comparing text gen-
erated with and without these enhancements, sub-
jects judged the versions generated with these meth-
ods to be better written and less repetitive signifi-
cantly more often than the reverse, and did not re-
port any difference in understandability between the
versions. To our knowledge, this is the first study
that specifically demonstrates the benefits of avoid-
ing syntactic repetition as a discourse progresses.
When the impact of each of the two implemented
methods on the generated text is examined, both
have a similar effect on the variation across a se-
quence of descriptions. However the simpler ε-
based technique is more prone to introducing dis-
preferred variants into the output, indicating that
better results can be obtained using anti-repetition
scoring with strict or no ε-based sampling. Using
anti-repetition scoring also allows the anytime mode
of the OpenCCG realiser to be employed.
In the human evaluation, participats were asked
to give direct judgements on the quality of gener-
ated output presented as text: their responses indi-
cated that they both were aware of and appreciated
the variation in the output. In future evaluations,
we would like to measure the impact of this type
of variation on actual user interactions using tools
such as subjective user satisfaction, objective dia-
logue quality, and performance on a recall task.
An important consideration when automatically
generating paraphrases is that any changes to the
words or syntax should not alter the meaning; that
is, in machine-translation terms, a paraphrase must
be adequate. In our implementation, we ensured ad-
</bodyText>
<page confidence="0.997896">
39
</page>
<bodyText confidence="0.999961909090909">
equacy through domain-specific text-planning rules
that add options to a disjunctive logical form only
if they are considered equivalent in the domain. It
remains for future work to examine whether the en-
gineering of such rules can be streamlined through
automatic acquisition. Another question for future
work is to investigate whether cases where repeti-
tion is useful can be identified, e.g. to achieve de-
sired parallelism, and whether such insights can be
incorporated into rules which restrict the paraphrase
space accordingly.
</bodyText>
<sectionHeader confidence="0.996363" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999949">
This work was partly supported by the COMIC
project (IST-2001-32311). Thanks to Jon Oberlan-
der and the ENLG reviewers for useful comments.
</bodyText>
<sectionHeader confidence="0.999438" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999819776470589">
S. Bangalore and O. Rambow. 2000. Exploiting a proba-
bilistic hierarchical model for generation. In Proceed-
ings, COLING-00. ACL C00-1007.
R. Barzilay and L. Lee. 2003. Learning to paraphrase:
An unsupervised approach using multiple-sequence
alignment. In Proceedings, HLT-NAACL 2003. ACL
N03-1003.
R. Barzilay and K. McKeown. 2001. Extracting para-
phrases from a parallel corpus. In Proceedings,
ACL/EACL 2001. ACL P01-1008.
A. Belz and E. Reiter. 2006. Comparing automatic and
human evaluation of NLG systems. In Proceedings,
EACL 2006. ACL E06-1040.
J. Carroll, A. Copestake, D. Flickinger, and
V. Pozna´nski. 1999. An efficient chart generator
for (semi-) lexicalist grammars. In Proceedings,
EWNLG-99.
J. Carroll and S. Oepen. 2005. High efficiency realization
for a wide-coverage unification grammar. In Proceed-
ings, IJCNLP-05.
K. van Deemter, E. Krahmer, and M. Theune. 2005.
Real versus template-based natural language genera-
tion: A false opposition? Computational Linguistics,
31(1):15–24.
M. E. Foster and J. Oberlander. 2006. Data-driven gen-
eration of emphatic facial displays. In Proceedings,
EACL 2006. ACL E06-1045.
M. E. Foster and M. White. 2004. Techniques for text
planning with XSLT. In Proceedings, NLPXML 2004.
ACL W04-0601.
M. Gu´egan and N. Hernandez. 2006. Recognizing tex-
tual parallelisms with edit distance and similarity de-
gree. In Proceedings, EACL 2006. ACL E06-1036.
L. Iordanskaja, R. Kittredge, and A. Polgu`ere. 1991.
Lexical selection and paraphrase in a meaning-text
generation model. In C. L. Paris, W. R. Swartout, and
W. C. Mann, editors, Natural Language Generation in
Artificial Intelligence and Computational Linguistics,
pages 293–312. Kluwer.
A. Isard, C. Brockmann, and J. Oberlander. 2006. In-
dividuality and alignment in generated dialogues. In
Proceedings, INLG 2006. ACL W06-1405.
M. Kay. 1996. Chart generation. In Proceedings, ACL-
96. ACL P96-1027.
I. Langkilde. 2000. Forest-based statistical sentence gen-
eration. In Proceedings, NAACL-00. ACL A00-2023.
I. Langkilde and K. Knight. 1998. Generation that ex-
ploits corpus-based statistical knowledge. In Proceed-
ings, COLING-ACL 1998. ACL P98-1116.
I. Langkilde-Geary. 2002. An empirical verification of
coverage and correctness for a general-purpose sen-
tence generator. In Proceedings, INLG-02.
A. H. Oh and A. I. Rudnicky. 2002. Stochastic natural
language generation for spoken dialog systems. Com-
puter, Speech &amp; Language, 16(3/4):387–407. doi:
10.1016/S0885-2308(02)00012-8.
B. Pang, K. Knight, and D. Marcu. 2003. Syntax-based
alignment of multiple translations: Extracting para-
phrases and generating new sentences. In Proceed-
ings, HLT-NAACL 2003. ACL N03-1024.
H. Shemtov. 1997. Ambiguity Management in Natural
Language Generation. Ph.D. thesis, Stanford Univer-
sity.
M. Steedman. 2000. The Syntactic Process. MIT Press.
A. Stent, M. Marge, and M. Singhai. 2005. Evaluating
evaluation methods for generation in the presence of
variation. In Computational Linguistics and Intelli-
gent Text Processing, volume 3406/2005 of Lecture
Notes in Computer Science, pages 341–351. Springer.
doi:10.1007/b105772.
M. Stone, D. DeCarlo, I. Oh, C. Rodriguez, A. Stere,
A. Lees, and C. Bregler. 2004. Speaking with
hands: Creating animated conversational characters
from recordings of human performance. ACM Trans-
actions on Graphics (SIGGRAPH), 23(3). doi:10.
1145/1186562.1015753.
M. White. 2005. Designing an extensible API for inte-
grating language modeling and realization. In Pro-
ceedings, ACL-05 Workshop on Software.
M. White. 2006a. CCG chart realization from disjunctive
inputs. In Proceedings, INLG 2006. ACL W06-1403.
M. White. 2006b. Efficient realization of coordinate
structures in Combinatory Categorial Grammar. Re-
search on Language and Computation, 4(1):39–75.
doi:10.1007/s11168-006-9010-2.
</reference>
<page confidence="0.998626">
40
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.196264">
<title confidence="0.999625">Avoiding Repetition in Generated Text</title>
<author confidence="0.976805">Mary Ellen</author>
<note confidence="0.26685">Informatik VI: Robotics and Embedded Technische Universit¨at Boltzmannstr. 3, 85748 Garching,</note>
<email confidence="0.996829">foster@in.tum.de</email>
<author confidence="0.999978">Michael White</author>
<affiliation confidence="0.999783">Department of Linguistics The Ohio State University</affiliation>
<address confidence="0.999766">Columbus, OH 43210 USA</address>
<email confidence="0.999823">mwhite@ling.osu.edu</email>
<abstract confidence="0.997915619047619">We investigate two methods for enhancing variation in the output of a stochastic surface realiser: choosing from among the highest-scoring realisation candidates instead of taking the single highestresult and penalising the words from earlier sentences in a discourse when later ones In a human evaluation study, subjects were asked to compare texts generated with and without the variation enhancements. Strikingly, subjects judged the texts generated using these two methods to be better written and less repetitive than the texts generwith optimal scoring; at the same time, no significant difference in understandability was found between the two versions. In analysing the methods, we show that the simpler sampling method is considerably more prone to introducing dispreferred variants into the output, indicating that best results can be obtained using antiscoring with strict or no sampling.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>S Bangalore</author>
<author>O Rambow</author>
</authors>
<title>Exploiting a probabilistic hierarchical model for generation.</title>
<date>2000</date>
<booktitle>In Proceedings, COLING-00. ACL</booktitle>
<pages>00--1007</pages>
<contexts>
<context position="9677" citStr="Bangalore and Rambow, 2000" startWordPosition="1502" endWordPosition="1505">G open source surface realiser (White, 2006a,b), which is based on Steedman’s (2000) Combinatory Categorial Grammar (CCG). A distinguishing feature of OpenCCG is that it uses a hybrid symbolic-statistical chart realisation algorithm combining (1) a theoretically grounded approach to syntax and semantic composition with (2) integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the traditions of symbolic chart realisation (Kay, 1996; Carroll et al., 1999) and statistical realisation (Langkilde and Knight, 1998; Langkilde, 2000; Bangalore and Rambow, 2000; LangkildeGeary, 2002). Another recent approach to combining these traditions appears in (Carroll and Oepen, 2005), where parse selection techniques are incorporated into an HPSG realiser. In OpenCCG, the search for complete realisations makes use of n-gram language models and proceeds in one of two modes, anytime or two-stage (packing/unpacking). In the anytime mode, a best-first search is performed with a configurable time limit: the scores assigned by the n-gram model determine the order of the edges on the agenda, and thus have an impact on realisation speed. In the two-stage mode, a pack</context>
</contexts>
<marker>Bangalore, Rambow, 2000</marker>
<rawString>S. Bangalore and O. Rambow. 2000. Exploiting a probabilistic hierarchical model for generation. In Proceedings, COLING-00. ACL C00-1007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>L Lee</author>
</authors>
<title>Learning to paraphrase: An unsupervised approach using multiple-sequence alignment.</title>
<date>2003</date>
<booktitle>In Proceedings, HLT-NAACL 2003. ACL</booktitle>
<pages>03--1003</pages>
<contexts>
<context position="6832" citStr="Barzilay and Lee, 2003" startWordPosition="1061" endWordPosition="1064">hm. Section 5 next presents the result of the human evaluation study. In Section 6, we then explore the impact of the two anti-repetition methods on the variability and quality of the generated text, using a range of parameter settings. In Section 7, we discuss the results of both studies and compare them with related work. Finally, in Section 8, we give some conclusions and outline possible extensions to this work. 2 Previous Work The acquisition and generation of paraphrases has been studied for some time (cf. Iordanskaja et al., 1991; Langkilde and Knight, 1998; Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003). Much recent work in this area has focussed on the automated acquisition of paraphrases from corpora, along with the use of the resulting paraphrases in language-processing areas such as information extraction and retrieval, questionanswering, and machine translation. The main technique that has been used for adding variation to stochastically-generated output is to modify the system so that it does not always choose the same option in a given situation, normally by modifying either the weights or the selection strategy. When selecting a combination of speech and body-lang</context>
</contexts>
<marker>Barzilay, Lee, 2003</marker>
<rawString>R. Barzilay and L. Lee. 2003. Learning to paraphrase: An unsupervised approach using multiple-sequence alignment. In Proceedings, HLT-NAACL 2003. ACL N03-1003.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Barzilay</author>
<author>K McKeown</author>
</authors>
<title>Extracting paraphrases from a parallel corpus.</title>
<date>2001</date>
<journal>ACL</journal>
<booktitle>In Proceedings, ACL/EACL</booktitle>
<pages>01--1008</pages>
<contexts>
<context position="6808" citStr="Barzilay and McKeown, 2001" startWordPosition="1057" endWordPosition="1060">nto this realisation algorithm. Section 5 next presents the result of the human evaluation study. In Section 6, we then explore the impact of the two anti-repetition methods on the variability and quality of the generated text, using a range of parameter settings. In Section 7, we discuss the results of both studies and compare them with related work. Finally, in Section 8, we give some conclusions and outline possible extensions to this work. 2 Previous Work The acquisition and generation of paraphrases has been studied for some time (cf. Iordanskaja et al., 1991; Langkilde and Knight, 1998; Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003). Much recent work in this area has focussed on the automated acquisition of paraphrases from corpora, along with the use of the resulting paraphrases in language-processing areas such as information extraction and retrieval, questionanswering, and machine translation. The main technique that has been used for adding variation to stochastically-generated output is to modify the system so that it does not always choose the same option in a given situation, normally by modifying either the weights or the selection strategy. When selecting a combination</context>
</contexts>
<marker>Barzilay, McKeown, 2001</marker>
<rawString>R. Barzilay and K. McKeown. 2001. Extracting paraphrases from a parallel corpus. In Proceedings, ACL/EACL 2001. ACL P01-1008.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Belz</author>
<author>E Reiter</author>
</authors>
<title>Comparing automatic and human evaluation of NLG systems.</title>
<date>2006</date>
<journal>ACL</journal>
<booktitle>In Proceedings, EACL</booktitle>
<pages>06--1040</pages>
<contexts>
<context position="4760" citStr="Belz and Reiter, 2006" startWordPosition="728" endWordPosition="731">at it can be beneficial for a natural language generation system to strive to avoid repetition, we first conducted a human evaluation study in which subjects were asked to compare texts generated with and without the two variation-enhancing methods. Strikingly, subjects judged the versions generated using F--best sampling and anti-repetition scoring to be both better written and less repetitive than the versions generated with optimal n-gram scoring. To our knowledge, this study is the first to show a clear benefit for enhancing variation; while other recent studies (e.g., Stent et al., 2005; Belz and Reiter, 2006) have shown that automatic evaluation metrics do not always correlate well with human judgments of high quality generated texts with periphrastic variations, these studies examined sentences out of context, and thus could not take into account the benefit of avoiding repetition as a discourse progresses. Following the human evaluation study, we varied the main parameters used in F--best sampling and anti-repetition scoring and analysed the resulting impact on the amount of periphrastic variation and the number of dispreferred paraphrases in the generated outputs. The analysis revealed that the</context>
<context position="25183" citStr="Belz and Reiter, 2006" startWordPosition="4097" endWordPosition="4100"> paraphrases (p &lt; 0.0001, ANOVA), while increasing the repetition penalty affects only the occurrence of is family (also p &lt; 0.0001). 7 Discussion The results of the user evaluation show that human judges strongly preferred the texts generated with the anti-repetition methods, even though the corpusbased n-gram score of such texts is lower than the score of the texts generated without such methods. This result agrees with the results of other recent studies that compared human preferences on gener38 ated output with the prediction of corpus-based similarity measures (e.g., Stent et al., 2005; Belz and Reiter, 2006; Foster and Oberlander, 2006). In all of these studies, human judges generally preferred outputs that incorporated more variation, even if the results were less similar to the corpus examples; on the other hand, corpus-based measures tended to favour output that did not diverge far, on average, from the corpus data. By specifically concentrating on the effect of repetition in a discourse context, the results of the user study extend those of previous evaluations of the impact of variation in automatically-generated output, which generally presented the materials as a series of isolated exampl</context>
</contexts>
<marker>Belz, Reiter, 2006</marker>
<rawString>A. Belz and E. Reiter. 2006. Comparing automatic and human evaluation of NLG systems. In Proceedings, EACL 2006. ACL E06-1040.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>A Copestake</author>
<author>D Flickinger</author>
<author>V Pozna´nski</author>
</authors>
<title>An efficient chart generator for (semi-) lexicalist grammars.</title>
<date>1999</date>
<booktitle>In Proceedings, EWNLG-99.</booktitle>
<marker>Carroll, Copestake, Flickinger, Pozna´nski, 1999</marker>
<rawString>J. Carroll, A. Copestake, D. Flickinger, and V. Pozna´nski. 1999. An efficient chart generator for (semi-) lexicalist grammars. In Proceedings, EWNLG-99.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Carroll</author>
<author>S Oepen</author>
</authors>
<title>High efficiency realization for a wide-coverage unification grammar.</title>
<date>2005</date>
<booktitle>In Proceedings, IJCNLP-05.</booktitle>
<contexts>
<context position="9792" citStr="Carroll and Oepen, 2005" startWordPosition="1519" endWordPosition="1522">CCG). A distinguishing feature of OpenCCG is that it uses a hybrid symbolic-statistical chart realisation algorithm combining (1) a theoretically grounded approach to syntax and semantic composition with (2) integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the traditions of symbolic chart realisation (Kay, 1996; Carroll et al., 1999) and statistical realisation (Langkilde and Knight, 1998; Langkilde, 2000; Bangalore and Rambow, 2000; LangkildeGeary, 2002). Another recent approach to combining these traditions appears in (Carroll and Oepen, 2005), where parse selection techniques are incorporated into an HPSG realiser. In OpenCCG, the search for complete realisations makes use of n-gram language models and proceeds in one of two modes, anytime or two-stage (packing/unpacking). In the anytime mode, a best-first search is performed with a configurable time limit: the scores assigned by the n-gram model determine the order of the edges on the agenda, and thus have an impact on realisation speed. In the two-stage mode, a packed forest of all possible realisations is created in the first stage; in the second stage, the packed representatio</context>
</contexts>
<marker>Carroll, Oepen, 2005</marker>
<rawString>J. Carroll and S. Oepen. 2005. High efficiency realization for a wide-coverage unification grammar. In Proceedings, IJCNLP-05.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K van Deemter</author>
<author>E Krahmer</author>
<author>M Theune</author>
</authors>
<title>Real versus template-based natural language generation: A false opposition?</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<marker>van Deemter, Krahmer, Theune, 2005</marker>
<rawString>K. van Deemter, E. Krahmer, and M. Theune. 2005. Real versus template-based natural language generation: A false opposition? Computational Linguistics, 31(1):15–24.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Foster</author>
<author>J Oberlander</author>
</authors>
<title>Data-driven generation of emphatic facial displays.</title>
<date>2006</date>
<journal>ACL</journal>
<booktitle>In Proceedings, EACL</booktitle>
<pages>06--1045</pages>
<contexts>
<context position="8005" citStr="Foster and Oberlander (2006)" startWordPosition="1247" endWordPosition="1250">y. When selecting a combination of speech and body-language output for an animated character based on a corpus of recorded behaviour, for example, Stone et al. (2004) introduced variation by perturbing the scores slightly to choose from among low-cost utterances. The outputs from the system with perturbed weights scored nearly as high on an automated evaluation as those from the optimised system, and also made use of a wider range of corpus data. Belz and Reiter’s (2006) “greedy roulette” pCRU text-generation system selected among generation rules weighted by their corpus probabilities, while Foster and Oberlander (2006) used a similar technique to select facial displays for an animated talking head. Both of these systems scored higher on a human evaluation than at least one competing system that always chose the single highest-scoring option; see Section 7 for further discussion. The CRAG-2 system (Isard et al., 2006) generates dialogues between pairs of agents who are linguistically distinguishable but able to align with each other. It uses the OpenCCG surface realiser to select appropriate paraphrases for the desired personality of the simulated character and the stage of the dialogue, integrating cache mo</context>
<context position="25213" citStr="Foster and Oberlander, 2006" startWordPosition="4101" endWordPosition="4104">1, ANOVA), while increasing the repetition penalty affects only the occurrence of is family (also p &lt; 0.0001). 7 Discussion The results of the user evaluation show that human judges strongly preferred the texts generated with the anti-repetition methods, even though the corpusbased n-gram score of such texts is lower than the score of the texts generated without such methods. This result agrees with the results of other recent studies that compared human preferences on gener38 ated output with the prediction of corpus-based similarity measures (e.g., Stent et al., 2005; Belz and Reiter, 2006; Foster and Oberlander, 2006). In all of these studies, human judges generally preferred outputs that incorporated more variation, even if the results were less similar to the corpus examples; on the other hand, corpus-based measures tended to favour output that did not diverge far, on average, from the corpus data. By specifically concentrating on the effect of repetition in a discourse context, the results of the user study extend those of previous evaluations of the impact of variation in automatically-generated output, which generally presented the materials as a series of isolated examples. For example, Belz and Reit</context>
</contexts>
<marker>Foster, Oberlander, 2006</marker>
<rawString>M. E. Foster and J. Oberlander. 2006. Data-driven generation of emphatic facial displays. In Proceedings, EACL 2006. ACL E06-1045.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M E Foster</author>
<author>M White</author>
</authors>
<title>Techniques for text planning with XSLT.</title>
<date>2004</date>
<journal>ACL</journal>
<booktitle>In Proceedings, NLPXML</booktitle>
<pages>04--0601</pages>
<contexts>
<context position="12329" citStr="Foster and White, 2004" startWordPosition="1928" endWordPosition="1931">mber of possible orderings. To select preferred word orders among those allowed by the grammar for the input LF, we used a backoff 4-gram model trained on approximately 750 example target sentences, where certain words were replaced with their semantic classes (e.g. MANUFACTURER, COLOUR) for better generalisation, much as in (Oh and Rudnicky, 2002). 4 Anti-Repetition Methods For both studies in this paper, we used OpenCCG to realise a range of texts describing and comparing bathroom-tile designs. The starting point for this implementation was the XSLT-based text planner from the COMIC system (Foster and White, 2004), which transforms sets of facts about tile designs into OpenCCG logical forms. We enhanced this text planner to produce disjunctive logical forms covering the full range of paraphrases permitted by the most recent version of the COMIC grammar, and then used OpenCCG realise those forms as text. In the normal OpenCCG realisation process outlined above, corpus-based n-grams are used to select the single highest-scoring realisation for a given logical form. To allow the realiser to choose paraphrases other than the top-scoring one, we modified the realisation process in two ways: F--best sampling</context>
</contexts>
<marker>Foster, White, 2004</marker>
<rawString>M. E. Foster and M. White. 2004. Techniques for text planning with XSLT. In Proceedings, NLPXML 2004. ACL W04-0601.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Gu´egan</author>
<author>N Hernandez</author>
</authors>
<title>Recognizing textual parallelisms with edit distance and similarity degree.</title>
<date>2006</date>
<journal>ACL</journal>
<booktitle>In Proceedings, EACL</booktitle>
<pages>06--1036</pages>
<marker>Gu´egan, Hernandez, 2006</marker>
<rawString>M. Gu´egan and N. Hernandez. 2006. Recognizing textual parallelisms with edit distance and similarity degree. In Proceedings, EACL 2006. ACL E06-1036.</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Iordanskaja</author>
<author>R Kittredge</author>
<author>A Polgu`ere</author>
</authors>
<title>Lexical selection and paraphrase in a meaning-text generation model.</title>
<date>1991</date>
<booktitle>Natural Language Generation in Artificial Intelligence and Computational Linguistics,</booktitle>
<pages>293--312</pages>
<editor>In C. L. Paris, W. R. Swartout, and W. C. Mann, editors,</editor>
<publisher>Kluwer.</publisher>
<marker>Iordanskaja, Kittredge, Polgu`ere, 1991</marker>
<rawString>L. Iordanskaja, R. Kittredge, and A. Polgu`ere. 1991. Lexical selection and paraphrase in a meaning-text generation model. In C. L. Paris, W. R. Swartout, and W. C. Mann, editors, Natural Language Generation in Artificial Intelligence and Computational Linguistics, pages 293–312. Kluwer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Isard</author>
<author>C Brockmann</author>
<author>J Oberlander</author>
</authors>
<title>Individuality and alignment in generated dialogues.</title>
<date>2006</date>
<journal>ACL</journal>
<booktitle>In Proceedings, INLG</booktitle>
<pages>06--1405</pages>
<contexts>
<context position="8309" citStr="Isard et al., 2006" startWordPosition="1296" endWordPosition="1299">s scored nearly as high on an automated evaluation as those from the optimised system, and also made use of a wider range of corpus data. Belz and Reiter’s (2006) “greedy roulette” pCRU text-generation system selected among generation rules weighted by their corpus probabilities, while Foster and Oberlander (2006) used a similar technique to select facial displays for an animated talking head. Both of these systems scored higher on a human evaluation than at least one competing system that always chose the single highest-scoring option; see Section 7 for further discussion. The CRAG-2 system (Isard et al., 2006) generates dialogues between pairs of agents who are linguistically distinguishable but able to align with each other. It uses the OpenCCG surface realiser to select appropriate paraphrases for the desired personality of the simulated character and the stage of the dialogue, integrating cache models built from the preceding discourse with the primary n-gram models to attain lexico-syntactic alignment. The 34 method of anti-repetition scoring described in this paper is similar, but the goal is opposite: instead of increasing alignment with an interlocutor, here we modify the n-gram scores to av</context>
</contexts>
<marker>Isard, Brockmann, Oberlander, 2006</marker>
<rawString>A. Isard, C. Brockmann, and J. Oberlander. 2006. Individuality and alignment in generated dialogues. In Proceedings, INLG 2006. ACL W06-1405.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Kay</author>
</authors>
<title>Chart generation.</title>
<date>1996</date>
<booktitle>In Proceedings, ACL96. ACL</booktitle>
<pages>96--1027</pages>
<contexts>
<context position="9553" citStr="Kay, 1996" startWordPosition="1486" endWordPosition="1487"> previous utterances. 3 Surface Realisation with OpenCCG The studies described in this paper use the OpenCCG open source surface realiser (White, 2006a,b), which is based on Steedman’s (2000) Combinatory Categorial Grammar (CCG). A distinguishing feature of OpenCCG is that it uses a hybrid symbolic-statistical chart realisation algorithm combining (1) a theoretically grounded approach to syntax and semantic composition with (2) integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the traditions of symbolic chart realisation (Kay, 1996; Carroll et al., 1999) and statistical realisation (Langkilde and Knight, 1998; Langkilde, 2000; Bangalore and Rambow, 2000; LangkildeGeary, 2002). Another recent approach to combining these traditions appears in (Carroll and Oepen, 2005), where parse selection techniques are incorporated into an HPSG realiser. In OpenCCG, the search for complete realisations makes use of n-gram language models and proceeds in one of two modes, anytime or two-stage (packing/unpacking). In the anytime mode, a best-first search is performed with a configurable time limit: the scores assigned by the n-gram model</context>
</contexts>
<marker>Kay, 1996</marker>
<rawString>M. Kay. 1996. Chart generation. In Proceedings, ACL96. ACL P96-1027.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde</author>
</authors>
<title>Forest-based statistical sentence generation.</title>
<date>2000</date>
<booktitle>In Proceedings, NAACL-00. ACL</booktitle>
<pages>00--2023</pages>
<contexts>
<context position="9649" citStr="Langkilde, 2000" startWordPosition="1500" endWordPosition="1501">er use the OpenCCG open source surface realiser (White, 2006a,b), which is based on Steedman’s (2000) Combinatory Categorial Grammar (CCG). A distinguishing feature of OpenCCG is that it uses a hybrid symbolic-statistical chart realisation algorithm combining (1) a theoretically grounded approach to syntax and semantic composition with (2) integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the traditions of symbolic chart realisation (Kay, 1996; Carroll et al., 1999) and statistical realisation (Langkilde and Knight, 1998; Langkilde, 2000; Bangalore and Rambow, 2000; LangkildeGeary, 2002). Another recent approach to combining these traditions appears in (Carroll and Oepen, 2005), where parse selection techniques are incorporated into an HPSG realiser. In OpenCCG, the search for complete realisations makes use of n-gram language models and proceeds in one of two modes, anytime or two-stage (packing/unpacking). In the anytime mode, a best-first search is performed with a configurable time limit: the scores assigned by the n-gram model determine the order of the edges on the agenda, and thus have an impact on realisation speed. I</context>
</contexts>
<marker>Langkilde, 2000</marker>
<rawString>I. Langkilde. 2000. Forest-based statistical sentence generation. In Proceedings, NAACL-00. ACL A00-2023.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde</author>
<author>K Knight</author>
</authors>
<title>Generation that exploits corpus-based statistical knowledge.</title>
<date>1998</date>
<journal>ACL</journal>
<booktitle>In Proceedings, COLING-ACL</booktitle>
<pages>98--1116</pages>
<contexts>
<context position="6780" citStr="Langkilde and Knight, 1998" startWordPosition="1053" endWordPosition="1056">on methods were integrated into this realisation algorithm. Section 5 next presents the result of the human evaluation study. In Section 6, we then explore the impact of the two anti-repetition methods on the variability and quality of the generated text, using a range of parameter settings. In Section 7, we discuss the results of both studies and compare them with related work. Finally, in Section 8, we give some conclusions and outline possible extensions to this work. 2 Previous Work The acquisition and generation of paraphrases has been studied for some time (cf. Iordanskaja et al., 1991; Langkilde and Knight, 1998; Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003). Much recent work in this area has focussed on the automated acquisition of paraphrases from corpora, along with the use of the resulting paraphrases in language-processing areas such as information extraction and retrieval, questionanswering, and machine translation. The main technique that has been used for adding variation to stochastically-generated output is to modify the system so that it does not always choose the same option in a given situation, normally by modifying either the weights or the selection strategy. </context>
<context position="9632" citStr="Langkilde and Knight, 1998" startWordPosition="1496" endWordPosition="1499">tudies described in this paper use the OpenCCG open source surface realiser (White, 2006a,b), which is based on Steedman’s (2000) Combinatory Categorial Grammar (CCG). A distinguishing feature of OpenCCG is that it uses a hybrid symbolic-statistical chart realisation algorithm combining (1) a theoretically grounded approach to syntax and semantic composition with (2) integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the traditions of symbolic chart realisation (Kay, 1996; Carroll et al., 1999) and statistical realisation (Langkilde and Knight, 1998; Langkilde, 2000; Bangalore and Rambow, 2000; LangkildeGeary, 2002). Another recent approach to combining these traditions appears in (Carroll and Oepen, 2005), where parse selection techniques are incorporated into an HPSG realiser. In OpenCCG, the search for complete realisations makes use of n-gram language models and proceeds in one of two modes, anytime or two-stage (packing/unpacking). In the anytime mode, a best-first search is performed with a configurable time limit: the scores assigned by the n-gram model determine the order of the edges on the agenda, and thus have an impact on rea</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>I. Langkilde and K. Knight. 1998. Generation that exploits corpus-based statistical knowledge. In Proceedings, COLING-ACL 1998. ACL P98-1116.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Langkilde-Geary</author>
</authors>
<title>An empirical verification of coverage and correctness for a general-purpose sentence generator.</title>
<date>2002</date>
<booktitle>In Proceedings, INLG-02.</booktitle>
<marker>Langkilde-Geary, 2002</marker>
<rawString>I. Langkilde-Geary. 2002. An empirical verification of coverage and correctness for a general-purpose sentence generator. In Proceedings, INLG-02.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A H Oh</author>
<author>A I Rudnicky</author>
</authors>
<title>Stochastic natural language generation for spoken dialog systems.</title>
<date>2002</date>
<journal>Computer, Speech &amp; Language,</journal>
<volume>16</volume>
<issue>3</issue>
<pages>10--1016</pages>
<contexts>
<context position="12056" citStr="Oh and Rudnicky, 2002" startWordPosition="1886" endWordPosition="1889"> the grammar was allowed to overgenerate in areas where rules are difficult to write and where n-gram models can be reliable; in particular, the grammar does not sufficiently constrain modifier order, which in the case of adverb placement especially can lead to a large number of possible orderings. To select preferred word orders among those allowed by the grammar for the input LF, we used a backoff 4-gram model trained on approximately 750 example target sentences, where certain words were replaced with their semantic classes (e.g. MANUFACTURER, COLOUR) for better generalisation, much as in (Oh and Rudnicky, 2002). 4 Anti-Repetition Methods For both studies in this paper, we used OpenCCG to realise a range of texts describing and comparing bathroom-tile designs. The starting point for this implementation was the XSLT-based text planner from the COMIC system (Foster and White, 2004), which transforms sets of facts about tile designs into OpenCCG logical forms. We enhanced this text planner to produce disjunctive logical forms covering the full range of paraphrases permitted by the most recent version of the COMIC grammar, and then used OpenCCG realise those forms as text. In the normal OpenCCG realisati</context>
</contexts>
<marker>Oh, Rudnicky, 2002</marker>
<rawString>A. H. Oh and A. I. Rudnicky. 2002. Stochastic natural language generation for spoken dialog systems. Computer, Speech &amp; Language, 16(3/4):387–407. doi: 10.1016/S0885-2308(02)00012-8.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Pang</author>
<author>K Knight</author>
<author>D Marcu</author>
</authors>
<title>Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences.</title>
<date>2003</date>
<booktitle>In Proceedings, HLT-NAACL 2003. ACL</booktitle>
<pages>03--1024</pages>
<contexts>
<context position="6852" citStr="Pang et al., 2003" startWordPosition="1065" endWordPosition="1068">nts the result of the human evaluation study. In Section 6, we then explore the impact of the two anti-repetition methods on the variability and quality of the generated text, using a range of parameter settings. In Section 7, we discuss the results of both studies and compare them with related work. Finally, in Section 8, we give some conclusions and outline possible extensions to this work. 2 Previous Work The acquisition and generation of paraphrases has been studied for some time (cf. Iordanskaja et al., 1991; Langkilde and Knight, 1998; Barzilay and McKeown, 2001; Barzilay and Lee, 2003; Pang et al., 2003). Much recent work in this area has focussed on the automated acquisition of paraphrases from corpora, along with the use of the resulting paraphrases in language-processing areas such as information extraction and retrieval, questionanswering, and machine translation. The main technique that has been used for adding variation to stochastically-generated output is to modify the system so that it does not always choose the same option in a given situation, normally by modifying either the weights or the selection strategy. When selecting a combination of speech and body-language output for an a</context>
</contexts>
<marker>Pang, Knight, Marcu, 2003</marker>
<rawString>B. Pang, K. Knight, and D. Marcu. 2003. Syntax-based alignment of multiple translations: Extracting paraphrases and generating new sentences. In Proceedings, HLT-NAACL 2003. ACL N03-1024.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Shemtov</author>
</authors>
<date>1997</date>
<booktitle>Ambiguity Management in Natural Language Generation. Ph.D. thesis,</booktitle>
<institution>Stanford University.</institution>
<contexts>
<context position="11074" citStr="Shemtov (1997)" startWordPosition="1728" endWordPosition="1729"> for each sign as it is unpacked, much as in (Langkilde, 2000). To realise a broad range of paraphrases, OpenCCG implements an algorithm for efficiently generating from disjunctive logical forms (LFs) (White, 2006a). A disjunctive LF represents the full set of possible syntactic paraphrases of a sentence: the differences may be subtle (e.g., choosing between the design or it as the subject), or may involve entirely different structures (e.g., here we have a design in the classic style vs. this design is classic). The algorithm uses packed representations similar to those initially proposed by Shemtov (1997), enabling it to run many times faster than sequential realisation of an equivalent set of non-disjunctive LFs. The implementation described here makes use of the OpenCCG grammar developed as part of the COMIC multimodal dialogue system. This grammar was manually written with the aim of achieving very high quality. However, to streamline grammar development, the grammar was allowed to overgenerate in areas where rules are difficult to write and where n-gram models can be reliable; in particular, the grammar does not sufficiently constrain modifier order, which in the case of adverb placement e</context>
</contexts>
<marker>Shemtov, 1997</marker>
<rawString>H. Shemtov. 1997. Ambiguity Management in Natural Language Generation. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Steedman</author>
</authors>
<title>The Syntactic Process.</title>
<date>2000</date>
<publisher>MIT Press.</publisher>
<marker>Steedman, 2000</marker>
<rawString>M. Steedman. 2000. The Syntactic Process. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Stent</author>
<author>M Marge</author>
<author>M Singhai</author>
</authors>
<title>Evaluating evaluation methods for generation in the presence of variation.</title>
<date>2005</date>
<booktitle>In Computational Linguistics and Intelligent Text Processing,</booktitle>
<volume>3406</volume>
<pages>341--351</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="4736" citStr="Stent et al., 2005" startWordPosition="724" endWordPosition="727"> 2005). To verify that it can be beneficial for a natural language generation system to strive to avoid repetition, we first conducted a human evaluation study in which subjects were asked to compare texts generated with and without the two variation-enhancing methods. Strikingly, subjects judged the versions generated using F--best sampling and anti-repetition scoring to be both better written and less repetitive than the versions generated with optimal n-gram scoring. To our knowledge, this study is the first to show a clear benefit for enhancing variation; while other recent studies (e.g., Stent et al., 2005; Belz and Reiter, 2006) have shown that automatic evaluation metrics do not always correlate well with human judgments of high quality generated texts with periphrastic variations, these studies examined sentences out of context, and thus could not take into account the benefit of avoiding repetition as a discourse progresses. Following the human evaluation study, we varied the main parameters used in F--best sampling and anti-repetition scoring and analysed the resulting impact on the amount of periphrastic variation and the number of dispreferred paraphrases in the generated outputs. The an</context>
<context position="25160" citStr="Stent et al., 2005" startWordPosition="4093" endWordPosition="4096"> of all three of the paraphrases (p &lt; 0.0001, ANOVA), while increasing the repetition penalty affects only the occurrence of is family (also p &lt; 0.0001). 7 Discussion The results of the user evaluation show that human judges strongly preferred the texts generated with the anti-repetition methods, even though the corpusbased n-gram score of such texts is lower than the score of the texts generated without such methods. This result agrees with the results of other recent studies that compared human preferences on gener38 ated output with the prediction of corpus-based similarity measures (e.g., Stent et al., 2005; Belz and Reiter, 2006; Foster and Oberlander, 2006). In all of these studies, human judges generally preferred outputs that incorporated more variation, even if the results were less similar to the corpus examples; on the other hand, corpus-based measures tended to favour output that did not diverge far, on average, from the corpus data. By specifically concentrating on the effect of repetition in a discourse context, the results of the user study extend those of previous evaluations of the impact of variation in automatically-generated output, which generally presented the materials as a se</context>
</contexts>
<marker>Stent, Marge, Singhai, 2005</marker>
<rawString>A. Stent, M. Marge, and M. Singhai. 2005. Evaluating evaluation methods for generation in the presence of variation. In Computational Linguistics and Intelligent Text Processing, volume 3406/2005 of Lecture Notes in Computer Science, pages 341–351. Springer. doi:10.1007/b105772.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Stone</author>
<author>D DeCarlo</author>
<author>I Oh</author>
<author>C Rodriguez</author>
<author>A Stere</author>
<author>A Lees</author>
<author>C Bregler</author>
</authors>
<title>Speaking with hands: Creating animated conversational characters from recordings of human performance.</title>
<date>2004</date>
<journal>ACM Transactions on Graphics (SIGGRAPH),</journal>
<volume>23</volume>
<issue>3</issue>
<pages>10--1145</pages>
<contexts>
<context position="2174" citStr="Stone et al. (2004)" startWordPosition="325" endWordPosition="328">at this stylistic goal should be met as well: for example, van Deemter et al. (2005) incorporated random choice into a language generation system “to maximise the variety of sentences produced” (emphasis original). Repetitiveness may take several forms: using the same words or syntactic structures, repeatedly giving the same facts, or even repeating entire turns (for example, error-handling turns in dialogue systems). At the level of word choice and phrasing, recent advances in stochastic text generation have made it possible to implement corpus-based approaches to varying output. However, as Stone et al. (2004) note, there is an inherent conflict between producing output that is optimally similar to the corpus and incorporating variability: varying output requires choosing less frequent options, which inevitably reduces scores on corpus similarity measures. To the extent that corpus-based measures (such as n-gram scores) are used to avoid overgeneration and select preferred paraphrases, it is not obvious how to enhance variation without reducing output quality. With this question in mind, we investigate in this paper the impact of two different methods for enhancing variation in the output generated</context>
<context position="7543" citStr="Stone et al. (2004)" startWordPosition="1175" endWordPosition="1178">n of paraphrases from corpora, along with the use of the resulting paraphrases in language-processing areas such as information extraction and retrieval, questionanswering, and machine translation. The main technique that has been used for adding variation to stochastically-generated output is to modify the system so that it does not always choose the same option in a given situation, normally by modifying either the weights or the selection strategy. When selecting a combination of speech and body-language output for an animated character based on a corpus of recorded behaviour, for example, Stone et al. (2004) introduced variation by perturbing the scores slightly to choose from among low-cost utterances. The outputs from the system with perturbed weights scored nearly as high on an automated evaluation as those from the optimised system, and also made use of a wider range of corpus data. Belz and Reiter’s (2006) “greedy roulette” pCRU text-generation system selected among generation rules weighted by their corpus probabilities, while Foster and Oberlander (2006) used a similar technique to select facial displays for an animated talking head. Both of these systems scored higher on a human evaluatio</context>
</contexts>
<marker>Stone, DeCarlo, Oh, Rodriguez, Stere, Lees, Bregler, 2004</marker>
<rawString>M. Stone, D. DeCarlo, I. Oh, C. Rodriguez, A. Stere, A. Lees, and C. Bregler. 2004. Speaking with hands: Creating animated conversational characters from recordings of human performance. ACM Transactions on Graphics (SIGGRAPH), 23(3). doi:10. 1145/1186562.1015753.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M White</author>
</authors>
<title>Designing an extensible API for integrating language modeling and realization.</title>
<date>2005</date>
<booktitle>In Proceedings, ACL-05 Workshop on Software.</booktitle>
<contexts>
<context position="4124" citStr="White, 2005" startWordPosition="630" endWordPosition="631">such repetition using OpenCCG, E-best sampling, is to perform n-best realisation and then to select randomly from among those options whose score is within a threshold E of the top score. The second 1http://www.hcrc.ed.ac.uk/comic/ 33 means of adding variation, anti-repetition scoring, is to store the words from recently generated sentences and to penalise a proposed realisation based on the number of words that it shares with these sentences. OpenCCG provides a built-in facility for implementing such anti-repetition scorers and integrating them with the normal n-gram–based scoring algorithm (White, 2005). To verify that it can be beneficial for a natural language generation system to strive to avoid repetition, we first conducted a human evaluation study in which subjects were asked to compare texts generated with and without the two variation-enhancing methods. Strikingly, subjects judged the versions generated using F--best sampling and anti-repetition scoring to be both better written and less repetitive than the versions generated with optimal n-gram scoring. To our knowledge, this study is the first to show a clear benefit for enhancing variation; while other recent studies (e.g., Stent </context>
</contexts>
<marker>White, 2005</marker>
<rawString>M. White. 2005. Designing an extensible API for integrating language modeling and realization. In Proceedings, ACL-05 Workshop on Software.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M White</author>
</authors>
<title>CCG chart realization from disjunctive inputs.</title>
<date>2006</date>
<journal>ACL</journal>
<booktitle>In Proceedings, INLG</booktitle>
<pages>06--1403</pages>
<contexts>
<context position="2917" citStr="White, 2006" startWordPosition="441" endWordPosition="442"> varying output requires choosing less frequent options, which inevitably reduces scores on corpus similarity measures. To the extent that corpus-based measures (such as n-gram scores) are used to avoid overgeneration and select preferred paraphrases, it is not obvious how to enhance variation without reducing output quality. With this question in mind, we investigate in this paper the impact of two different methods for enhancing variation in the output generated by the COMIC multimodal dialogue system.1 Both methods take advantage of the periphrastic ability of the OpenCCG surface realiser (White, 2006a). In the usual OpenCCG realisation process, when a logical form is transformed into output text, n-gram models are used to steer the realiser towards the single highest-scoring option for the sentence. This process tends to select the same syntactic structure for every sentence describing the same feature: for example, in the COMIC domain (describing and comparing bathroom tiles), the structure The colours are [colours] would be used every time the colours of a tile design are to be presented, even though alternative paraphrases are available. The first (and simplest) means of avoiding such </context>
<context position="9094" citStr="White, 2006" startWordPosition="1417" endWordPosition="1418">ate paraphrases for the desired personality of the simulated character and the stage of the dialogue, integrating cache models built from the preceding discourse with the primary n-gram models to attain lexico-syntactic alignment. The 34 method of anti-repetition scoring described in this paper is similar, but the goal is opposite: instead of increasing alignment with an interlocutor, here we modify the n-gram scores to avoid alignment with the system’s own previous utterances. 3 Surface Realisation with OpenCCG The studies described in this paper use the OpenCCG open source surface realiser (White, 2006a,b), which is based on Steedman’s (2000) Combinatory Categorial Grammar (CCG). A distinguishing feature of OpenCCG is that it uses a hybrid symbolic-statistical chart realisation algorithm combining (1) a theoretically grounded approach to syntax and semantic composition with (2) integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the traditions of symbolic chart realisation (Kay, 1996; Carroll et al., 1999) and statistical realisation (Langkilde and Knight, 1998; Langkilde, 2000; Bangalore and Rambow, 2000; LangkildeGeary,</context>
<context position="10673" citStr="White, 2006" startWordPosition="1663" endWordPosition="1664">search is performed with a configurable time limit: the scores assigned by the n-gram model determine the order of the edges on the agenda, and thus have an impact on realisation speed. In the two-stage mode, a packed forest of all possible realisations is created in the first stage; in the second stage, the packed representation is unpacked in bottom-up fashion, with scores assigned to the edge for each sign as it is unpacked, much as in (Langkilde, 2000). To realise a broad range of paraphrases, OpenCCG implements an algorithm for efficiently generating from disjunctive logical forms (LFs) (White, 2006a). A disjunctive LF represents the full set of possible syntactic paraphrases of a sentence: the differences may be subtle (e.g., choosing between the design or it as the subject), or may involve entirely different structures (e.g., here we have a design in the classic style vs. this design is classic). The algorithm uses packed representations similar to those initially proposed by Shemtov (1997), enabling it to run many times faster than sequential realisation of an equivalent set of non-disjunctive LFs. The implementation described here makes use of the OpenCCG grammar developed as part of</context>
</contexts>
<marker>White, 2006</marker>
<rawString>M. White. 2006a. CCG chart realization from disjunctive inputs. In Proceedings, INLG 2006. ACL W06-1403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M White</author>
</authors>
<title>Efficient realization of coordinate structures in Combinatory Categorial Grammar.</title>
<date>2006</date>
<journal>Research on Language and Computation,</journal>
<volume>4</volume>
<issue>1</issue>
<pages>10--1007</pages>
<contexts>
<context position="2917" citStr="White, 2006" startWordPosition="441" endWordPosition="442"> varying output requires choosing less frequent options, which inevitably reduces scores on corpus similarity measures. To the extent that corpus-based measures (such as n-gram scores) are used to avoid overgeneration and select preferred paraphrases, it is not obvious how to enhance variation without reducing output quality. With this question in mind, we investigate in this paper the impact of two different methods for enhancing variation in the output generated by the COMIC multimodal dialogue system.1 Both methods take advantage of the periphrastic ability of the OpenCCG surface realiser (White, 2006a). In the usual OpenCCG realisation process, when a logical form is transformed into output text, n-gram models are used to steer the realiser towards the single highest-scoring option for the sentence. This process tends to select the same syntactic structure for every sentence describing the same feature: for example, in the COMIC domain (describing and comparing bathroom tiles), the structure The colours are [colours] would be used every time the colours of a tile design are to be presented, even though alternative paraphrases are available. The first (and simplest) means of avoiding such </context>
<context position="9094" citStr="White, 2006" startWordPosition="1417" endWordPosition="1418">ate paraphrases for the desired personality of the simulated character and the stage of the dialogue, integrating cache models built from the preceding discourse with the primary n-gram models to attain lexico-syntactic alignment. The 34 method of anti-repetition scoring described in this paper is similar, but the goal is opposite: instead of increasing alignment with an interlocutor, here we modify the n-gram scores to avoid alignment with the system’s own previous utterances. 3 Surface Realisation with OpenCCG The studies described in this paper use the OpenCCG open source surface realiser (White, 2006a,b), which is based on Steedman’s (2000) Combinatory Categorial Grammar (CCG). A distinguishing feature of OpenCCG is that it uses a hybrid symbolic-statistical chart realisation algorithm combining (1) a theoretically grounded approach to syntax and semantic composition with (2) integrated language models for making choices among the options left open by the grammar. In so doing, it brings together the traditions of symbolic chart realisation (Kay, 1996; Carroll et al., 1999) and statistical realisation (Langkilde and Knight, 1998; Langkilde, 2000; Bangalore and Rambow, 2000; LangkildeGeary,</context>
<context position="10673" citStr="White, 2006" startWordPosition="1663" endWordPosition="1664">search is performed with a configurable time limit: the scores assigned by the n-gram model determine the order of the edges on the agenda, and thus have an impact on realisation speed. In the two-stage mode, a packed forest of all possible realisations is created in the first stage; in the second stage, the packed representation is unpacked in bottom-up fashion, with scores assigned to the edge for each sign as it is unpacked, much as in (Langkilde, 2000). To realise a broad range of paraphrases, OpenCCG implements an algorithm for efficiently generating from disjunctive logical forms (LFs) (White, 2006a). A disjunctive LF represents the full set of possible syntactic paraphrases of a sentence: the differences may be subtle (e.g., choosing between the design or it as the subject), or may involve entirely different structures (e.g., here we have a design in the classic style vs. this design is classic). The algorithm uses packed representations similar to those initially proposed by Shemtov (1997), enabling it to run many times faster than sequential realisation of an equivalent set of non-disjunctive LFs. The implementation described here makes use of the OpenCCG grammar developed as part of</context>
</contexts>
<marker>White, 2006</marker>
<rawString>M. White. 2006b. Efficient realization of coordinate structures in Combinatory Categorial Grammar. Research on Language and Computation, 4(1):39–75. doi:10.1007/s11168-006-9010-2.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>