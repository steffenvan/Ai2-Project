<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000038">
<title confidence="0.9881465">
Dependency of context-based Word Sense Disambiguation from
representation and domain complexity
</title>
<author confidence="0.612689666666667">
Paola Velardi
Dipartimento di Scienze dell&apos;Informazione
University &amp;quot;La Sapienza&amp;quot;
</author>
<affiliation confidence="0.695215">
Roma
</affiliation>
<email confidence="0.901623">
Velardi@dsi.uniromal.it
</email>
<author confidence="0.781808">
Alessandro Cucchiareili
</author>
<affiliation confidence="0.855621">
Istituto di Informatica
University of Ancona
</affiliation>
<address confidence="0.692395">
Ancona
</address>
<email confidence="0.986127">
alex@inform.unian.it
</email>
<sectionHeader confidence="0.997158" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998142703703704">
Word Sense Disambiguation (WSD) is a
central task in the area of Natural
Language Processing, In the past few years
several context-based probabilistic and
machine learning methods for WSD have
been presented in literature. However, an
important area of research that has not
been given the attention it deserves is a
formal analysis of the parameters affecting
the performance of the learning task faced
by these systems. Usually performance is
estimated by measuring precision and
recall of a specific algorithm for specific
test sets and environmental conditions.
Therefore, a comparison among different
learning systems and an objective
estimation of the difficulty of the learning
task is extremely difficult.
In this paper we propose, in the framework
of Computational Learning theory, a
formal analysis of the relations between
accuracy of a context-based WSD system,
the complexity of the context
representation scheme, and the
environmental conditions (e.g. the
complexity of language domain and
concept inventory).
</bodyText>
<sectionHeader confidence="0.999629" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.993674731707317">
In the literature (see Computational Linguistics
(1998) for some recent results), there is a rather
vast repertoire of supervised and unsupervised
learning algorithms for WSD, most of which
are based on a formal characterization of the
surrounding context of a word or linguistic
conceptl, and a function f to compute the
membership of a word to a category, given its
context in running texts.
Despite the rich literature, none of these
algorithms exhibit an
acceptable&amp;quot;
performance with reference to the needs of
real-world computational task (e.g.
Information Retrieval, Information Extraction,
Machine Translation etc.), except for
particularly straightforward cases.
A very interesting WSD experiment is
Senseval (1998), a large-scale exercise in
evaluating WSD programs. One of the
objectives of this experiment was to identify
correlations between performance of the
various systems and the parameters of the
WSD task. Though the scoring of systems
appears sensitive to certain factors, such as the
degree of polysemy and the entropy of sense
distributions, these correlations could not be
consistently observed. There are words with
fewer senses (e.g. bet, consume, generous)
causing troubles to most systems, while there
are words with a very high polysemy and
entropy (e.g. shake) on which all systems
obtain good performance. The justification that
the Senseval coordinator Adam Kilgariff
provides for shake is very interesting in the
light of what we will discuss later in this paper:
&amp;quot;The items (means contexts) for shake involve
multi-word expressions, such as shake one
head. (...) Over 50% of the items for shake
involve some multi-word expression or other.&amp;quot;
In other words, the contexts for shake are very
</bodyText>
<footnote confidence="0.624694">
l The inventory of linguistic concepts is usually
extracted from on-line resources like WordNet, the
Longman dictionary (LDOCE), or HECTOR.
</footnote>
<page confidence="0.998727">
28
</page>
<bodyText confidence="0.999951235294118">
repetitive in the training set, therefore all
systems could easily learn a sense
discrimination model.
Furthermore, in Senseval (but also in other
reported evaluations experiments) it appears
that performances for individual
words/concepts are extremely uneven within
the same system. This scarce homogeneity of
results suggests that performance is not solely
related with the &amp;quot;cleverness&amp;quot; of a given
learning algorithm.
Clearly, the performances of WSD systems are
related to a variety of parameters, but the
formal nature of these dependencies is not fully
understood.
The Senseval experiment highlighted the
necessity of a more accurate analysis of the
correlations between performance of WSD
systems and the parameters that may affect this
task. In absence, a comparison of the various
WSD algorithms and an estimation of their
performance under different environmental
conditions is extremely difficult.
In the next sections we briefly present a
computational model of learning, called PAC
theory (Anthony and Biggs (1997), Kearns and
Vazirani (1994), Valiant (1984)), and we then
show that this theory may be used to determine
the formal relations between performance of
context-based WSD models arid environmental
conditions, such as the complexity of the
context representation scheme, and the the
complexity of language domain and concept
inventory.
</bodyText>
<sectionHeader confidence="0.95447" genericHeader="method">
2 A relation between sample size and
</sectionHeader>
<subsectionHeader confidence="0.945706">
complexity of learning task
</subsectionHeader>
<bodyText confidence="0.924238578125">
Formally, the problem of example-based
learning of WSD models can be stated as
follows:
1 Given a class C of concepts CI (where C
is either a hierarchy or a &amp;quot;flat&amp;quot; concept
inventory),
2 Given a context-based representation
class H for a concept class C, where H:
E*---&gt;C and E is a finite alphabet of
symbols (e.g. words or word tags),
3 Given an input space XE* of
encodings of instances in the learner&apos;s
world, e.g. feature vectors representing
contexts around words wj, where wj is a
member of Ci,
4 Given a training sample S of length m:
S ((xl ,b )...(xm,bm)) Xj € X , e {0,1)
where 131=1 if x, is a positive example of CI,
characterize formally a function h (Ci)EH that
assigns a word w to a concept Ci, given the
sentence context x of w. The hypothesis may
have the form of a Hidden Markov Model with
estimated transition probabilities, a decision
list, a cluster of points in a representation
space, a logic formula, etc.
The complexity of this learning task is related
to several aspects, such as selecting an
appropriate representation space H, an
appropriate grain for the concept inventory C,
and finally, a sufficiently representative
training sample S.
As first, H must be a &amp;quot;reasonable&amp;quot;
representation space for C. Quite intuitively, if
we represent a linguistic concept as the set of
possible morphologic tags pairs in a -±1
window, we will not be able to predict much,
simply because surrounding morphologic tags
are not sufficient to determine the semantic
category of a word.
On the opposite, if we select an overly
complex representation model, including
irrelevant features, we run through the so
called overfitting problem.
Thirdly, some of the features used in a
representation may be dependent from other
features, and again the model would result
unnecessarily complex.
The problem of noise and overfitting are well
known in the area of Machine Learning
(Russell and Norvig (1999)), therefore we will
not discuss the matter in detail here. An
analysis of this issue as applied to probabilistic
WSD learners may be found in Bruce and
Wiebe (1999).
For the purpose of this paper, we assume that
the representation space H is optimized with
respect to the choice of the relevant model
parameters. Our objective will be to determine
the size of S, given LI and C, and given certain
performance objectives.
As we said, the aim of a WSD learning
process, when instructed with a sequence S of
examples in X, is to produce an hypothesis h
which, in some sense, &amp;quot;corresponds&amp;quot; to the
</bodyText>
<page confidence="0.991689">
29
</page>
<bodyText confidence="0.968240255319149">
concept under consideration. Because S is a
finite sequence, only concepts with a finite
number of positive examples can be learned
with total success, i.e. the learner can output an
hypothesis h= C1 . In general, and this is the
case for linguistic concepts, we can only hope
that h is a good approximation of C,. In our
problem at hand, it is worth noticing that even
humans may provide only approximate
definitions of linguistic concepts!
The theory of Probably Approximately Correct
(PAC) learning, a relatively recent field at the
borderline between Artificial Intelligence and
Information Theory, states the conditions
under which h reaches this objective, i.e. the
conditions under which a computer derived
hypothesis h &apos;probably&apos; represents Ci
&apos;approximately&apos;.
Definition 1 (PAC learning). Let C be a
concept class over X. Let D be a fixed
probability distribution over the instance space
X, and EX(Ci,D) be a procedure reflecting the
probability distribution of the population we
whish to learn about. We say that C is PAC
learnable if there exists an algorithm L with
the following property: For every CC, for
every distribution D on X, and for all 0&lt;e&lt;112
and 0&lt;6&lt;112, if L is given access to EX(C1,D)
and inputs E and 8, then with probability at
least (1-5), L outputs a hypothesis h for
concept CI, satisfying error(h)&lt;E. The
parameters E and 6 have the following
meaning: E is the probability that the learner
produces a generalization of the sample that
does not coincide with the target concept,
while 8 is the probability, given D, that a
particularly unrepresentative (or noisy) training
sample is drawn. The objective of PAC theory
is to predict the performance of learning
systems by deriving a lower bound for m, as a
function of the performance parameters E and
6.
Figure 1 (from Russell and Norvig (1999))
illustrates the &amp;quot;intuitive.&apos; meaning of PAC
definition. After seeing m examples, the
probability that Hbad includes consistent
hypotheses is:
</bodyText>
<footnote confidence="0.620192">
P(HbadDlicon)-5111bad I(1--E)m..1H1(1-6)&amp;quot;
</footnote>
<figureCaption confidence="0.861967">
Figure 1 : e-sphere around the &amp;quot;true&amp;quot;
function CI
</figureCaption>
<bodyText confidence="0.986571">
And we want this to be:
1111(1—e)m-6
we hence obtain a lower bound for the number
of examples we need to submit to the learner in
order to obtain the required accuracy:
</bodyText>
<equation confidence="0.9046185">
(1) m .1(1112. +1E1
8
</equation>
<bodyText confidence="0.999736333333333">
The inequality (I) establishes a sort of worst-
case general bound, relating the size of the
learning set with the complexity of the
representation space HI. Unfortunately this
bound turns out to have limited utility in
practical applications.
For example, if the hypothesis space for a
linguistic concept Ci is the classic &amp;quot;bag of
words&amp;quot;, i.e. a set of at least k &amp;quot;typical&amp;quot; context
words selected by a probabilistic learner, after
observing m samples of the tn words around
words we Ci
</bodyText>
<equation confidence="0.587322">
(e.g. x VV,• • •Wn-1,Wn) )
</equation>
<bodyText confidence="0.9887648">
then H is any choke of _.5_1(WI words over &apos;VI
elements, where 1VI (.10 is the size of the
vocabulary. We then have:
=i+(11v1)+.... VI),
the above expression, used in inequality (1),
produces an overly high bound for m, that can
be hardly pursued especially in case the
learning algorithm is supervised!
In PAC literature, the bound for m is often
derived &amp;quot;ad hoc&amp;quot; for specific algorithms, in
order to exploit knowledge on the precise
learning conditions.
It is also worth noticing that PAC literature has
mostly a theoretical emphasis, and most
applications concentrated on the field of neural
networks and natural learning systems
(Hanson, Petsche, Kearns, Rivest (1994)). To
the knowledge of the authors, the utility of this
theory in the area of computer learning of
natural language has not been explored.
</bodyText>
<page confidence="0.99172">
30
</page>
<bodyText confidence="0.999943947368421">
In the following, we will derive a probabilistic
expression for m in the track of (1), for the
case of a context-based WSD probabilistic
learner, a learning method that includes a
rather wide class of algorithms in the area of
WSD. We believe that adapting our analysis to
other example-based WSD systems will not
require a significant effort. This relation allows
it to establish, upon an a-priori analysis of the
chosen conceptual model and of the language
domain, a more precise relation between
performance, complexity of the learning
algorithm, and environmental conditions (e.g.
complexity of the language domain).
Our objective is to show that an a-priori
analysis of the learning model and language
domain may help to tune precisely a WSD
experiment and allows a more uniform
comparison between different WSD systems.
</bodyText>
<sectionHeader confidence="0.8831645" genericHeader="method">
3. A formal estimate of accuracy for
context-based probability WSD models
</sectionHeader>
<bodyText confidence="0.9941195">
A probabilistic context-based WSD learner
may be described as follows:
</bodyText>
<equation confidence="0.987546">
Let X be a space of feature vectors:
fk=( na1i=v1,a21=v2,...ani=vr,)€91&amp;quot;, bk&apos; )),
11=1 if fk is a positive example of CI under H.
</equation>
<bodyText confidence="0.9872698125">
Each vector describes the context in which a
word we Ci is found, with variable degree of
complexity. For examples, arguments may be
any combination of plain words and their
morphologic, syntactic and semantic tags.
We assume that arguments are not statistically
independent (in case they are, the
representation of a concept is more simple, see
Bruce and Wiebe, (1999)).
An example (Cucchiarelli, Luzi and Velardi
(1998)) is the case in which fk represents a
syntactic relation between we C, and another
word in its context. For example, given the
compound district banks the following feature
is generated as an example of the category
organization:
</bodyText>
<equation confidence="0.577407">
((N_N district bank), organization(bank))
</equation>
<bodyText confidence="0.993558211538462">
We further assume that observations of
contexts are noisy, and the noise may be
originated by several factors, such as tags
ambiguity, and semantic ambiguity of the word
whose context is observed.
In the above feature vector, the syntactic tag
(first argument) could be wrong because of
syntactic ambiguity and limited coverage of
available parsers, and the ambiguous word
bank could not be, in a specific context, an
instance of the category organization, though it
is in the example above.
Probabilistic learners usually associate to
uncertain information a measure of the
confidence the system has in that information.
Therefore, we assume that each feature fk is
associated to a concept C, with a confidence
4)(1,k) .
The confidence may be calculated in several
ways, depending upon the type of selected
features for fk. For example, the Mutual
Information measures the strength of a
correlation between co-occurring arguments,
and the Plausibility (Cucchiarelli, Luzi and
Velardi (1998)) assigns a weight to a feature
vector, depending upon the degree of
ambiguity of its arguments and the frequency
of its observations in a corpus. We assume here
that ep is adjusted to be a probability, i.e.
IiCi,k)=1. The factor (1)(i,k) represents hence
an estimate of the probability that fk. is indeed
a context of CI.
Under these hypotheses, a representation he 11
for a concept Ci is the following:
(2) fk3h(Ci ) iff &gt; y
A concept is hence represented by a set of
features with associated probabilities2. Policy
(2) establishes that only features with a
probability higher than a threshold y are
assigned to a category model.
Given an unknown word w&apos; occurring in a
context represented by rk, the WSD algorithm
assigns w&apos; to the category in C that maximizes
the similarity between f&apos; k and one of its
members. Again, see Cucchiarelli, Luz!. and
Velardi (1998) and Bruce and Wiebe, (1999)
for examples of similarity functions.
2 Note that in case of statistical independence
among the features in a vector, a model for a
concept would be a set of features, rather than
feature vectors, but most of what we discuss in this
section would still apply with simple changes.
</bodyText>
<page confidence="0.999741">
31
</page>
<bodyText confidence="0.962001290322581">
Given the above, the probabilistic WSD model
for a category Ci may fail because:
1 Ci includes false positives (fp), e.g. feature
vectors erroneously assigned to Ci
2 There are false negatives (fn), i.e. feature
vectors erroneously discarded because of a
low value (1)(i,k)
3 The context f&apos;k of the word w&apos; has never
been observed around members of CI, nor
it is similar (in the precise sense of
similarity established by a given
algorithm) to any of the vectors in the
contextual models.
We then have3:
(3) P(w. is misclassified on the basis of
f&apos;
NrkE fp in C1)+P(fkEfn outside C1)+13(f. kis
unseen in C1)
Let:
m be the total number of feature vectors
extracted from a corpus
Ink the total number of occurrences of a feature
fk
the number of times the context fk occurred
with a word w&apos; member of Ci
Notice that Eimki *ink, since, because of
ambiguity, a context may be assigned to more
than one concept (or to none).
We can then estimate the three probabilities in
expression (3) as follows:
ITO(
</bodyText>
<equation confidence="0.813490555555556">
(3.1) P (fp in Ci)-=
00, Oy n1
mk
(3.2) p (fn outside C1)=. E i , k )
i , kym
(3.3) 15 (unseen in Ci)=
(i Enik ).(1 Em15 ).(i(i)) E11111:( k
m
Yin =i =1 rn k I m k
</equation>
<bodyText confidence="0.999423666666667">
The third probability is computed as the
product of three estimated factors: the
probability p of unseen contexts4 in the
</bodyText>
<footnote confidence="0.9946265">
3 In the expression 3) the three events are clearly
mutually exclusive.
4 We here assume for simplicity that the similarity
function is an identity. A muitinomial or a more
</footnote>
<bodyText confidence="0.999322153846154">
corpus, the probability of extracting contexts
around members of CI, and the average
confidence of a feature vector in C1.
Classic methods such as Chernoff bounds may
be applied to obtain good approximations for
the three probabilities above. Notice however
that in order to obtain a given accuracy of
estimate, Chemoff bounds (and other methods)
again impose a bound on the number of
observed examples (Kearns and Vazirani
(1994))
Since in (3.1) (1-0(i,k))&lt;y, in (3.2) 0(i,k))&gt;y,
and in (3.3) 4)(i,k))51, we obtain the bound:
</bodyText>
<equation confidence="0.7766">
P(w is misclassified on the basis of f&apos;k)=,
&lt; M • - N. ,
</equation>
<bodyText confidence="0.99861275">
The expression (3) establishes interesting
dependencies between the accuracy of a
context-based probabilistic WSD model and
certain environmental conditions.
</bodyText>
<subsectionHeader confidence="0.999407">
3.1 Dependency upon the corpus and
linguistic concepts
</subsectionHeader>
<bodyText confidence="0.989966">
In a complex language domain (e.g. newspaper
articles) linguistic phenomena are far less
repetitive than in a restricted language (e.g.
airline reservations). However, even in a
relatively unrestricted domain certain
categories are used in a more narrow sense.
Let us consider the probabilistic context-based
algorithm in Cuechiarelli, Luzi and Velardi
(1998), where a feature is defined by:
Pc: (syntactie_relation, w 1, wi) (e.g. (N_N
district bank))
fk 4C; if NA/1 reaches the hyperonym C1 in the
WordNet on-line taxonomy, and 4)(i,k) &gt; y
Using the 1 million word Wall Street Journal
corpus, we estimated the following
probabilities (3.3) of unseen feature vectors (m
in this experiment is 0(105));
P(unseen in artifact)=0,7692
P(unseen in person)= 0,7161
P(unseen in psychological feature)=0.8598
complex function must be used in case contexts are
considered similar if, for example, co-occurring
words have some common hyperonym. See
Cucchiarelli, Luzi and Velardi (1998) for
examples.
</bodyText>
<page confidence="0.997463">
32
</page>
<bodyText confidence="0.999874">
The linguistic concepts artifact, person and
psychological feature are three hyperonyms of
the on-line WordNet taxonomy. The above
figures show that the more &amp;quot;vague&amp;quot; concept
psychological feature occurs in more variable
contexts, though the distribution of words in
the three categories is approximately even.
</bodyText>
<subsectionHeader confidence="0.7823485">
3.2 Dependency on the representation
model
</subsectionHeader>
<bodyText confidence="0.99979275">
The representation model H also affects the
estimates of erroneous classifications. For
example, if we modify the contextual model by
removing the information on w, (that is to say,
the feature vectors in the contextual model now
only includes the syntactic relation type and
the co-occurring word wl), we obtain the
following values for the probabilies (3.3):
</bodyText>
<equation confidence="0.980149666666667">
P(unseen in artifact)=0,1778
P (unseen in person)-= 0,1714
P (unseen in psychological feature) =0,2139
</equation>
<bodyText confidence="0.996471965517241">
The probability of &amp;quot;unseens&amp;quot; in this simpler
model is considerably lower (we removed an
attribute, wi, that assumes values over V), but
clearly, the probability of false positives and
false negatives increases.
The motivation is that we now assume that a
context for a word belonging (also to) Ci is a
valid context for any word in that category.
Regardless of the specific adopted formula for
(1)(i,k), the confidence O(i,k) in such a
generalization depends on the number of
different words w, in occurring in a given
context fk. If this number is low, or is Just 1,
then the value of 4)(i,k) must be low,
accordingly. The selected threshold y then
determines the different contribution of false
positives and false negatives to the total model
accuracy.
A preliminary experiment is illustrated in
Figure 2. The figure computes (1-P(fp in CI)
for the category artifact, as a function of m and
4)(i,k), evaluated on a test set of 78 words.
The figure shows that when y is .?..0,5 the
number of false positives is rather low, after
observing sufficient examples.
On the other side, P(fn outside C,) (not shown
here for sake of space) has a specular
behavour. For y=0,9, the probability of false
negative is as low as 0,6.
</bodyText>
<sectionHeader confidence="0.99329" genericHeader="conclusions">
4. Conclusion
</sectionHeader>
<bodyText confidence="0.944506393939394">
By no means the work presented in this paper
needs more investigation, especially on the
experimental side. However, we believe that
learnability analysis of WSD models has
strong practical implications.
The quantitative and (preliminary)
experimental results of Section 2 put in
evidence that :
• In order to acquire statistically stable
contextual models of linguistic concepts,
the dimension of the analyzed corpora
must be considerably high. Paradoxically,
untrained probabilistic systems are in
better shape in this regard. Very large
repositories of language samples can be
now obtained from the WWW.
• The experimental setting (i.e. size of the
training set) must be tuned for each
category and language domain, because the
variability of contextual behavior may be
significantly different, depending on
domain complexity, e.g. the type and grain
of the selected category, and the more or
less restricted language domain
• it is possible and indeed advisable, for a
given WSD algorithm, to determine in a
formal way the relation between expected
accuracy of the WSD model and the
domain and representation complexity.
This would allow a better comparison
among systems, and an a-priori tuning of
the parameters of the disambiguation
model.
</bodyText>
<sectionHeader confidence="0.999303" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.988972111111111">
Anthony M. and Biggs, N. (1997) Computational
Learning Theory Cambridge University Press,
1997
Bruce R. and Wiebe J., (1999) Decomposable
Modeling in Natural Language Processing,
Computational Linguistics vol. 25, N. 2. 199
Computational Linguistics (1998) Special Issue on
Word Sense Disambiguation, Vol. 24 (1) March
1988
</reference>
<page confidence="0.986458">
33
</page>
<reference confidence="0.99613252631579">
Cucchiarelli A. Luzi D. and Velardi P. (1998)
Automatic Semantic Tagging of Unknown Proper
Names Proc. of joint 36 ° ACL-17 ° COLING,
Montreal, August 1998
Hanson S.J., Petsche T., Kearns M., Rivest RL.
(1994) Computational Learning Theory and
Natural Learning Systems, Vol. 1I, MIT Press,
1994
Kearns Mi. and Vazirani U.V. (1994) An
Introduction to Computational Learning Theory
MIT Press, 1994
Russell S.J and Norvig P (1999). Chapter 18:
Learning from Observations in; Artificial
Intelligence: a modern approach Prentice-hall
1999
Senseval (1998) homepage: http://www.itri.
brighton.ac.uk/events/sensevall
Valiant L. (1984) A Theory of Learnable
Communications of the ACM, 27(11), 1984
</reference>
<figureCaption confidence="0.994342">
Figure 2: (1-P(fp)) vs. Corpus Dim For the category Artifact
</figureCaption>
<figure confidence="0.9831740625">
100
95 -
90
it 85
80 -
75 -
70
0,2
—X— 0,4
—41-- 0,5
—I-- 0,6
0,7
—&apos;-0,5
OS
24943 49885 74827 59770 124712 149654
Corpus Dim.
</figure>
<page confidence="0.981491">
34
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.274084">
<title confidence="0.993776">Dependency of context-based Word Sense Disambiguation representation and domain complexity</title>
<author confidence="0.972687">Paola</author>
<affiliation confidence="0.906129">Dipartimento di Scienze University &amp;quot;La</affiliation>
<email confidence="0.53691">Velardi@dsi.uniromal.it</email>
<author confidence="0.868952">Alessandro</author>
<affiliation confidence="0.8872585">Istituto di University of</affiliation>
<email confidence="0.960763">alex@inform.unian.it</email>
<abstract confidence="0.997602035714285">Word Sense Disambiguation (WSD) is a central task in the area of Natural Language Processing, In the past few years several context-based probabilistic and machine learning methods for WSD have been presented in literature. However, an important area of research that has not been given the attention it deserves is a formal analysis of the parameters affecting the performance of the learning task faced by these systems. Usually performance is estimated by measuring precision and recall of a specific algorithm for specific test sets and environmental conditions. Therefore, a comparison among different learning systems and an objective estimation of the difficulty of the learning task is extremely difficult. In this paper we propose, in the framework of Computational Learning theory, a formal analysis of the relations between accuracy of a context-based WSD system, the complexity of the context representation scheme, and environmental conditions (e.g. the complexity of language domain and concept inventory).</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Anthony</author>
<author>N Biggs</author>
</authors>
<title>Computational Learning Theory</title>
<date>1997</date>
<publisher>Cambridge University Press,</publisher>
<contexts>
<context position="4244" citStr="Anthony and Biggs (1997)" startWordPosition="620" endWordPosition="623">arning algorithm. Clearly, the performances of WSD systems are related to a variety of parameters, but the formal nature of these dependencies is not fully understood. The Senseval experiment highlighted the necessity of a more accurate analysis of the correlations between performance of WSD systems and the parameters that may affect this task. In absence, a comparison of the various WSD algorithms and an estimation of their performance under different environmental conditions is extremely difficult. In the next sections we briefly present a computational model of learning, called PAC theory (Anthony and Biggs (1997), Kearns and Vazirani (1994), Valiant (1984)), and we then show that this theory may be used to determine the formal relations between performance of context-based WSD models arid environmental conditions, such as the complexity of the context representation scheme, and the the complexity of language domain and concept inventory. 2 A relation between sample size and complexity of learning task Formally, the problem of example-based learning of WSD models can be stated as follows: 1 Given a class C of concepts CI (where C is either a hierarchy or a &amp;quot;flat&amp;quot; concept inventory), 2 Given a context-b</context>
</contexts>
<marker>Anthony, Biggs, 1997</marker>
<rawString>Anthony M. and Biggs, N. (1997) Computational Learning Theory Cambridge University Press, 1997</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Bruce</author>
<author>J Wiebe</author>
</authors>
<title>Decomposable Modeling in Natural Language Processing,</title>
<date>1999</date>
<journal>Computational Linguistics</journal>
<volume>25</volume>
<pages>199</pages>
<contexts>
<context position="6711" citStr="Bruce and Wiebe (1999)" startWordPosition="1034" endWordPosition="1037"> to determine the semantic category of a word. On the opposite, if we select an overly complex representation model, including irrelevant features, we run through the so called overfitting problem. Thirdly, some of the features used in a representation may be dependent from other features, and again the model would result unnecessarily complex. The problem of noise and overfitting are well known in the area of Machine Learning (Russell and Norvig (1999)), therefore we will not discuss the matter in detail here. An analysis of this issue as applied to probabilistic WSD learners may be found in Bruce and Wiebe (1999). For the purpose of this paper, we assume that the representation space H is optimized with respect to the choice of the relevant model parameters. Our objective will be to determine the size of S, given LI and C, and given certain performance objectives. As we said, the aim of a WSD learning process, when instructed with a sequence S of examples in X, is to produce an hypothesis h which, in some sense, &amp;quot;corresponds&amp;quot; to the 29 concept under consideration. Because S is a finite sequence, only concepts with a finite number of positive examples can be learned with total success, i.e. the learner</context>
<context position="12193" citStr="Bruce and Wiebe, (1999)" startWordPosition="1942" endWordPosition="1945">of accuracy for context-based probability WSD models A probabilistic context-based WSD learner may be described as follows: Let X be a space of feature vectors: fk=( na1i=v1,a21=v2,...ani=vr,)€91&amp;quot;, bk&apos; )), 11=1 if fk is a positive example of CI under H. Each vector describes the context in which a word we Ci is found, with variable degree of complexity. For examples, arguments may be any combination of plain words and their morphologic, syntactic and semantic tags. We assume that arguments are not statistically independent (in case they are, the representation of a concept is more simple, see Bruce and Wiebe, (1999)). An example (Cucchiarelli, Luzi and Velardi (1998)) is the case in which fk represents a syntactic relation between we C, and another word in its context. For example, given the compound district banks the following feature is generated as an example of the category organization: ((N_N district bank), organization(bank)) We further assume that observations of contexts are noisy, and the noise may be originated by several factors, such as tags ambiguity, and semantic ambiguity of the word whose context is observed. In the above feature vector, the syntactic tag (first argument) could be wrong</context>
<context position="14402" citStr="Bruce and Wiebe, (1999)" startWordPosition="2301" endWordPosition="2304"> the probability that fk. is indeed a context of CI. Under these hypotheses, a representation he 11 for a concept Ci is the following: (2) fk3h(Ci ) iff &gt; y A concept is hence represented by a set of features with associated probabilities2. Policy (2) establishes that only features with a probability higher than a threshold y are assigned to a category model. Given an unknown word w&apos; occurring in a context represented by rk, the WSD algorithm assigns w&apos; to the category in C that maximizes the similarity between f&apos; k and one of its members. Again, see Cucchiarelli, Luz!. and Velardi (1998) and Bruce and Wiebe, (1999) for examples of similarity functions. 2 Note that in case of statistical independence among the features in a vector, a model for a concept would be a set of features, rather than feature vectors, but most of what we discuss in this section would still apply with simple changes. 31 Given the above, the probabilistic WSD model for a category Ci may fail because: 1 Ci includes false positives (fp), e.g. feature vectors erroneously assigned to Ci 2 There are false negatives (fn), i.e. feature vectors erroneously discarded because of a low value (1)(i,k) 3 The context f&apos;k of the word w&apos; has never</context>
</contexts>
<marker>Bruce, Wiebe, 1999</marker>
<rawString>Bruce R. and Wiebe J., (1999) Decomposable Modeling in Natural Language Processing, Computational Linguistics vol. 25, N. 2. 199</rawString>
</citation>
<citation valid="true">
<date>1998</date>
<journal>Special Issue on Word Sense Disambiguation,</journal>
<volume>24</volume>
<issue>1</issue>
<institution>Computational Linguistics</institution>
<contexts>
<context position="1407" citStr="(1998)" startWordPosition="194" endWordPosition="194"> of a specific algorithm for specific test sets and environmental conditions. Therefore, a comparison among different learning systems and an objective estimation of the difficulty of the learning task is extremely difficult. In this paper we propose, in the framework of Computational Learning theory, a formal analysis of the relations between accuracy of a context-based WSD system, the complexity of the context representation scheme, and the environmental conditions (e.g. the complexity of language domain and concept inventory). 1 Introduction In the literature (see Computational Linguistics (1998) for some recent results), there is a rather vast repertoire of supervised and unsupervised learning algorithms for WSD, most of which are based on a formal characterization of the surrounding context of a word or linguistic conceptl, and a function f to compute the membership of a word to a category, given its context in running texts. Despite the rich literature, none of these algorithms exhibit an acceptable&amp;quot; performance with reference to the needs of real-world computational task (e.g. Information Retrieval, Information Extraction, Machine Translation etc.), except for particularly straigh</context>
<context position="12245" citStr="(1998)" startWordPosition="1952" endWordPosition="1952">context-based WSD learner may be described as follows: Let X be a space of feature vectors: fk=( na1i=v1,a21=v2,...ani=vr,)€91&amp;quot;, bk&apos; )), 11=1 if fk is a positive example of CI under H. Each vector describes the context in which a word we Ci is found, with variable degree of complexity. For examples, arguments may be any combination of plain words and their morphologic, syntactic and semantic tags. We assume that arguments are not statistically independent (in case they are, the representation of a concept is more simple, see Bruce and Wiebe, (1999)). An example (Cucchiarelli, Luzi and Velardi (1998)) is the case in which fk represents a syntactic relation between we C, and another word in its context. For example, given the compound district banks the following feature is generated as an example of the category organization: ((N_N district bank), organization(bank)) We further assume that observations of contexts are noisy, and the noise may be originated by several factors, such as tags ambiguity, and semantic ambiguity of the word whose context is observed. In the above feature vector, the syntactic tag (first argument) could be wrong because of syntactic ambiguity and limited coverage</context>
<context position="13509" citStr="(1998)" startWordPosition="2149" endWordPosition="2149">ot be, in a specific context, an instance of the category organization, though it is in the example above. Probabilistic learners usually associate to uncertain information a measure of the confidence the system has in that information. Therefore, we assume that each feature fk is associated to a concept C, with a confidence 4)(1,k) . The confidence may be calculated in several ways, depending upon the type of selected features for fk. For example, the Mutual Information measures the strength of a correlation between co-occurring arguments, and the Plausibility (Cucchiarelli, Luzi and Velardi (1998)) assigns a weight to a feature vector, depending upon the degree of ambiguity of its arguments and the frequency of its observations in a corpus. We assume here that ep is adjusted to be a probability, i.e. IiCi,k)=1. The factor (1)(i,k) represents hence an estimate of the probability that fk. is indeed a context of CI. Under these hypotheses, a representation he 11 for a concept Ci is the following: (2) fk3h(Ci ) iff &gt; y A concept is hence represented by a set of features with associated probabilities2. Policy (2) establishes that only features with a probability higher than a threshold y ar</context>
<context position="17301" citStr="(1998)" startWordPosition="2801" endWordPosition="2801"> the basis of f&apos;k)=, &lt; M • - N. , The expression (3) establishes interesting dependencies between the accuracy of a context-based probabilistic WSD model and certain environmental conditions. 3.1 Dependency upon the corpus and linguistic concepts In a complex language domain (e.g. newspaper articles) linguistic phenomena are far less repetitive than in a restricted language (e.g. airline reservations). However, even in a relatively unrestricted domain certain categories are used in a more narrow sense. Let us consider the probabilistic context-based algorithm in Cuechiarelli, Luzi and Velardi (1998), where a feature is defined by: Pc: (syntactie_relation, w 1, wi) (e.g. (N_N district bank)) fk 4C; if NA/1 reaches the hyperonym C1 in the WordNet on-line taxonomy, and 4)(i,k) &gt; y Using the 1 million word Wall Street Journal corpus, we estimated the following probabilities (3.3) of unseen feature vectors (m in this experiment is 0(105)); P(unseen in artifact)=0,7692 P(unseen in person)= 0,7161 P(unseen in psychological feature)=0.8598 complex function must be used in case contexts are considered similar if, for example, co-occurring words have some common hyperonym. See Cucchiarelli, Luzi a</context>
</contexts>
<marker>1998</marker>
<rawString>Computational Linguistics (1998) Special Issue on Word Sense Disambiguation, Vol. 24 (1) March 1988</rawString>
</citation>
<citation valid="true">
<authors>
<author>Cucchiarelli A Luzi D</author>
<author>P Velardi</author>
</authors>
<title>Automatic Semantic Tagging of Unknown Proper Names</title>
<date>1998</date>
<booktitle>Proc. of joint 36 ° ACL-17 ° COLING,</booktitle>
<location>Montreal,</location>
<marker>D, Velardi, 1998</marker>
<rawString>Cucchiarelli A. Luzi D. and Velardi P. (1998) Automatic Semantic Tagging of Unknown Proper Names Proc. of joint 36 ° ACL-17 ° COLING, Montreal, August 1998</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Hanson</author>
<author>T Petsche</author>
<author>M Kearns</author>
<author>Rivest RL</author>
</authors>
<date>1994</date>
<booktitle>Computational Learning Theory and Natural Learning Systems, Vol. 1I,</booktitle>
<publisher>MIT Press,</publisher>
<marker>Hanson, Petsche, Kearns, RL, 1994</marker>
<rawString>Hanson S.J., Petsche T., Kearns M., Rivest RL. (1994) Computational Learning Theory and Natural Learning Systems, Vol. 1I, MIT Press, 1994</rawString>
</citation>
<citation valid="true">
<authors>
<author>U V Vazirani</author>
</authors>
<title>An Introduction to Computational Learning Theory</title>
<date>1994</date>
<publisher>MIT Press,</publisher>
<contexts>
<context position="4272" citStr="Vazirani (1994)" startWordPosition="626" endWordPosition="627">mances of WSD systems are related to a variety of parameters, but the formal nature of these dependencies is not fully understood. The Senseval experiment highlighted the necessity of a more accurate analysis of the correlations between performance of WSD systems and the parameters that may affect this task. In absence, a comparison of the various WSD algorithms and an estimation of their performance under different environmental conditions is extremely difficult. In the next sections we briefly present a computational model of learning, called PAC theory (Anthony and Biggs (1997), Kearns and Vazirani (1994), Valiant (1984)), and we then show that this theory may be used to determine the formal relations between performance of context-based WSD models arid environmental conditions, such as the complexity of the context representation scheme, and the the complexity of language domain and concept inventory. 2 A relation between sample size and complexity of learning task Formally, the problem of example-based learning of WSD models can be stated as follows: 1 Given a class C of concepts CI (where C is either a hierarchy or a &amp;quot;flat&amp;quot; concept inventory), 2 Given a context-based representation class H </context>
<context position="16575" citStr="Vazirani (1994)" startWordPosition="2693" endWordPosition="2694">xts4 in the 3 In the expression 3) the three events are clearly mutually exclusive. 4 We here assume for simplicity that the similarity function is an identity. A muitinomial or a more corpus, the probability of extracting contexts around members of CI, and the average confidence of a feature vector in C1. Classic methods such as Chernoff bounds may be applied to obtain good approximations for the three probabilities above. Notice however that in order to obtain a given accuracy of estimate, Chemoff bounds (and other methods) again impose a bound on the number of observed examples (Kearns and Vazirani (1994)) Since in (3.1) (1-0(i,k))&lt;y, in (3.2) 0(i,k))&gt;y, and in (3.3) 4)(i,k))51, we obtain the bound: P(w is misclassified on the basis of f&apos;k)=, &lt; M • - N. , The expression (3) establishes interesting dependencies between the accuracy of a context-based probabilistic WSD model and certain environmental conditions. 3.1 Dependency upon the corpus and linguistic concepts In a complex language domain (e.g. newspaper articles) linguistic phenomena are far less repetitive than in a restricted language (e.g. airline reservations). However, even in a relatively unrestricted domain certain categories are u</context>
</contexts>
<marker>Vazirani, 1994</marker>
<rawString>Kearns Mi. and Vazirani U.V. (1994) An Introduction to Computational Learning Theory MIT Press, 1994</rawString>
</citation>
<citation valid="true">
<authors>
<author>S J Russell</author>
<author>P Norvig</author>
</authors>
<title>Chapter 18: Learning from Observations in; Artificial Intelligence: a modern approach Prentice-hall</title>
<date>1999</date>
<contexts>
<context position="6546" citStr="Russell and Norvig (1999)" startWordPosition="1005" endWordPosition="1008">ncept as the set of possible morphologic tags pairs in a -±1 window, we will not be able to predict much, simply because surrounding morphologic tags are not sufficient to determine the semantic category of a word. On the opposite, if we select an overly complex representation model, including irrelevant features, we run through the so called overfitting problem. Thirdly, some of the features used in a representation may be dependent from other features, and again the model would result unnecessarily complex. The problem of noise and overfitting are well known in the area of Machine Learning (Russell and Norvig (1999)), therefore we will not discuss the matter in detail here. An analysis of this issue as applied to probabilistic WSD learners may be found in Bruce and Wiebe (1999). For the purpose of this paper, we assume that the representation space H is optimized with respect to the choice of the relevant model parameters. Our objective will be to determine the size of S, given LI and C, and given certain performance objectives. As we said, the aim of a WSD learning process, when instructed with a sequence S of examples in X, is to produce an hypothesis h which, in some sense, &amp;quot;corresponds&amp;quot; to the 29 con</context>
<context position="8970" citStr="Russell and Norvig (1999)" startWordPosition="1417" endWordPosition="1420">o EX(C1,D) and inputs E and 8, then with probability at least (1-5), L outputs a hypothesis h for concept CI, satisfying error(h)&lt;E. The parameters E and 6 have the following meaning: E is the probability that the learner produces a generalization of the sample that does not coincide with the target concept, while 8 is the probability, given D, that a particularly unrepresentative (or noisy) training sample is drawn. The objective of PAC theory is to predict the performance of learning systems by deriving a lower bound for m, as a function of the performance parameters E and 6. Figure 1 (from Russell and Norvig (1999)) illustrates the &amp;quot;intuitive.&apos; meaning of PAC definition. After seeing m examples, the probability that Hbad includes consistent hypotheses is: P(HbadDlicon)-5111bad I(1--E)m..1H1(1-6)&amp;quot; Figure 1 : e-sphere around the &amp;quot;true&amp;quot; function CI And we want this to be: 1111(1—e)m-6 we hence obtain a lower bound for the number of examples we need to submit to the learner in order to obtain the required accuracy: (1) m .1(1112. +1E1 8 The inequality (I) establishes a sort of worstcase general bound, relating the size of the learning set with the complexity of the representation space HI. Unfortunately thi</context>
</contexts>
<marker>Russell, Norvig, 1999</marker>
<rawString>Russell S.J and Norvig P (1999). Chapter 18: Learning from Observations in; Artificial Intelligence: a modern approach Prentice-hall 1999</rawString>
</citation>
<citation valid="true">
<authors>
<author>Senseval</author>
</authors>
<date>1998</date>
<note>homepage: http://www.itri. brighton.ac.uk/events/sensevall</note>
<contexts>
<context position="2075" citStr="Senseval (1998)" startWordPosition="292" endWordPosition="293">ertoire of supervised and unsupervised learning algorithms for WSD, most of which are based on a formal characterization of the surrounding context of a word or linguistic conceptl, and a function f to compute the membership of a word to a category, given its context in running texts. Despite the rich literature, none of these algorithms exhibit an acceptable&amp;quot; performance with reference to the needs of real-world computational task (e.g. Information Retrieval, Information Extraction, Machine Translation etc.), except for particularly straightforward cases. A very interesting WSD experiment is Senseval (1998), a large-scale exercise in evaluating WSD programs. One of the objectives of this experiment was to identify correlations between performance of the various systems and the parameters of the WSD task. Though the scoring of systems appears sensitive to certain factors, such as the degree of polysemy and the entropy of sense distributions, these correlations could not be consistently observed. There are words with fewer senses (e.g. bet, consume, generous) causing troubles to most systems, while there are words with a very high polysemy and entropy (e.g. shake) on which all systems obtain good </context>
</contexts>
<marker>Senseval, 1998</marker>
<rawString>Senseval (1998) homepage: http://www.itri. brighton.ac.uk/events/sensevall</rawString>
</citation>
<citation valid="true">
<authors>
<author>L Valiant</author>
</authors>
<title>A Theory of Learnable</title>
<date>1984</date>
<journal>Communications of the ACM,</journal>
<volume>27</volume>
<issue>11</issue>
<contexts>
<context position="4288" citStr="Valiant (1984)" startWordPosition="628" endWordPosition="629">tems are related to a variety of parameters, but the formal nature of these dependencies is not fully understood. The Senseval experiment highlighted the necessity of a more accurate analysis of the correlations between performance of WSD systems and the parameters that may affect this task. In absence, a comparison of the various WSD algorithms and an estimation of their performance under different environmental conditions is extremely difficult. In the next sections we briefly present a computational model of learning, called PAC theory (Anthony and Biggs (1997), Kearns and Vazirani (1994), Valiant (1984)), and we then show that this theory may be used to determine the formal relations between performance of context-based WSD models arid environmental conditions, such as the complexity of the context representation scheme, and the the complexity of language domain and concept inventory. 2 A relation between sample size and complexity of learning task Formally, the problem of example-based learning of WSD models can be stated as follows: 1 Given a class C of concepts CI (where C is either a hierarchy or a &amp;quot;flat&amp;quot; concept inventory), 2 Given a context-based representation class H for a concept cl</context>
</contexts>
<marker>Valiant, 1984</marker>
<rawString>Valiant L. (1984) A Theory of Learnable Communications of the ACM, 27(11), 1984</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>