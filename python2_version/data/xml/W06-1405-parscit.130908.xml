<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000524">
<title confidence="0.963144">
Individuality and Alignment in Generated Dialogues
</title>
<author confidence="0.995736">
Amy Isard and Carsten Brockmann and Jon Oberlander
</author>
<affiliation confidence="0.999891">
School of Informatics, University of Edinburgh
</affiliation>
<address confidence="0.825564">
2 Buccleuch Place
Edinburgh EH8 9LW, UK
</address>
<email confidence="0.995082">
{Amy.Isard, Carsten.Brockmann, J.Oberlander}@ed.ac.uk
</email>
<sectionHeader confidence="0.993706" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999967105263158">
It would be useful to enable dialogue
agents to project, through linguistic
means, their individuality or personality.
Equally, each member of a pair of agents
ought to adjust its language (to a greater or
lesser extent) to match that of its interlocu-
tor. We describe CRAG, which generates
dialogues between pairs of agents, who are
linguistically distinguishable, but able to
align. CRAG-2 makes use of OPENCCG
and an over-generation and ranking ap-
proach, guided by a set of language mod-
els covering both personality and align-
ment. We illustrate with examples of out-
put, and briefly note results from user stud-
ies with the earlier CRAG-1, indicating
how CRAG-2 will be further evaluated.
Related work is discussed, along with cur-
rent limitations and future directions.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999983857142857">
A computer agent should be individual. Nass
and collaborators find that users’ responses
to computer-agents are influenced by whether
the agent’s linguistic personality matches—or
mismatches—the personality of the user (Moon
and Nass, 1996; Nass and Lee, 2000). Similarly,
characters in virtual environments should be dis-
tinctive (Ball and Breese, 2000; Rist et al., 2003).
But an aspect of personality is how well you adjust
to other people (and their language use): align-
ment. Pickering and Garrod’s Interactive Align-
ment Model suggests that people tend to automat-
ically converge on lexical and syntactic choices,
via a low-level mechanism of interpersonal prim-
ing (Pickering and Garrod, 2004), and Brennan
has shown that people will align their language to-
wards that of computer agents (Brennan, 1996).
But it is an open issue as to whether some peo-
ple are better ‘aligners’ than others. Conversely,
alignment is only visible and interesting (among
computer agents) if they start out being individual.
We therefore set out to simulate both individ-
uality and alignment. The paper briefly surveys
the evidence for linguistic personality, for inter-
personal alignment, and for interaction between
them. It then sketches the current version of
CRAG. CRAG-2 makes use of OPENCCG and
an over-generation and ranking approach, guided
by a set of language models for personality and
alignment. We illustrate the differing linguis-
tic behaviours that it generates, and briefly note
promising results from user studies with the ear-
lier CRAG-1 system, indicating how CRAG-2 will
be further evaluated. Related work is discussed,
along with possible directions for future work.
</bodyText>
<sectionHeader confidence="0.996779" genericHeader="introduction">
2 Background
</sectionHeader>
<subsectionHeader confidence="0.993724">
2.1 Personality and Language
</subsectionHeader>
<bodyText confidence="0.999732142857143">
Current work on personality traits is dominated by
Costa and McCrae’s five-factor model (Costa and
McCrae, 1992). The five factors, or dimensions,
are: Extraversion; Neuroticism; Openness; Agree-
ableness; and Conscientiousness (Matthews et al.,
2003). It has been shown that scores on these di-
mensions correlate with some aspects of language
use (Scherer, 1979; Dewaele and Furnham, 1999).
In studies of text, the focus has been on lexical
choice, and Pennebaker and colleagues have anal-
ysed relative frequencies of use of word-stems in
a dictionary structured into semantic and syntac-
tic categories (Pennebaker et al., 2001). Amongst
other results, they have shown that High Extraverts
</bodyText>
<page confidence="0.980463">
25
</page>
<note confidence="0.6880795">
Proceedings of the Fourth International Natural Language Generation Conference, pages 25–32,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.99929725">
use: more social process talk, positive emotion
words and inclusives; and fewer negations, ten-
tative words, exclusives, causation words, nega-
tive emotion words, and articles (Pennebaker and
King, 1999; Pennebaker et al., 2002).
Computational linguistic exploitation of such
empirically-derived features has been limited. On
the one hand, in generation, there has been work
on personality-based generation. For instance, in
developing embodied conversational agents, re-
searchers have designed agents or teams of agents
with distinguishable linguistic personalities (Ball
and Breese, 2000; Rist et al., 2003; Piwek and
van Deemter, 2003; Gebhard, 2005). However,
the linguistic behaviour is usually informed by
rules based on personality stereotypes, rather than
on language statistics themselves. On the other
hand, in interpretation, more empirical work has
recently been carried out, to enable text classifi-
cation. Argamon et al. (2005) attempted to clas-
sify authors as High or Low Extravert and High
or Low Neurotic, using Pennebaker and King’s
(1999) data. They report classification accuracies
of around 58% (with a 50% baseline). Oberlander
and Nowson (2006) undertake a comparable task,
using weblog data. They report classification ac-
curacies of roughly 85% (Neuroticism) and 94%
(Extraversion), and comparable figures for Agree-
ableness and Conscientiousness. Such studies can
provide ordered lists of linguistic features which
are useful for distinguishing language producers,
and we will return to this, below.
</bodyText>
<subsectionHeader confidence="0.997735">
2.2 Alignment and Language
</subsectionHeader>
<bodyText confidence="0.999792533333333">
People converge with their interlocutors in linguis-
tic choices at a number of levels (Pickering and
Garrod, 2004). The phenomena can be seen in
both social and cognitive terms. On the social side,
co-operative processes such as audience design
are usually considered to be conscious, at least in
part (Bell, 1984). But on the cognitive side, co-
ordinative processes such as alignment are usu-
ally considered to be largely automatic (Garrod
and Doherty, 1994). Alignment can be probed
by psycholinguistic tests for interpersonal prim-
ing, establishing the extent to which participants
are more likely to use a lexical item or syntac-
tic construction after hearing their conversational
partner use it. Syntactic priming experiments in-
volve constructions such as passives, and ditransi-
tives (Pickering and Branigan, 1998).
It is possible that some people are stronger
aligners than others. Gill et al. (2004) probed
syntactic priming for passives, and investigated
whether levels of Extraversion or Neuroticism
would affect the strength of priming effects. It
was found that Extraversion has no effect, but that
Neuroticism has a non-linear effect: both High and
Low levels of Neuroticism led to weaker priming;
Mid levels led to significantly stronger priming.
Given this, if a generation system is going to simu-
late alignment, it is probably worth designing it so
that it can simulate agents with differing propensi-
ties to align.
</bodyText>
<sectionHeader confidence="0.992046" genericHeader="method">
3 The CRAG System Overview
</sectionHeader>
<bodyText confidence="0.999974866666667">
The system described in the following sections
(CRAG-2) is the successor to CRAG-1 which is
detailed in Isard et al. (2005). The system gener-
ates a dialogue between two computer agents on
the subject of opinions about a film. CRAG-2 uses
the OPENCCG parsing and generation framework
(White, 2004; White, 2006). The realiser com-
ponent takes a logical form as input and outputs
a list of candidate sentences ranked using one or
more language models. In CRAG-2, we use the
OPENCCG generator to massively over-generate
paraphrases, and the combination of n-gram mod-
els described in Section 4 to choose the best ut-
terance according to a character’s personality and
agenda, and the dialogue history.
</bodyText>
<sectionHeader confidence="0.9774445" genericHeader="method">
4 N-Grams: Personality and Alignment
Modelling
</sectionHeader>
<subsectionHeader confidence="0.999658">
4.1 N-Gram Language Models
</subsectionHeader>
<bodyText confidence="0.999985461538462">
The basic assumption underlying CRAG-2 is that
personality, as well as alignment behaviour, can
be modelled by the combination of a variety of n-
gram language models.
Language models are trained on a corpus and
subsequently used to compute probability scores
of word sequences. An n-gram language model
approximates the probability of a word given its
history of the preceding n − 1 words. According
to the chain rule, probabilities are then combined
by multiplication. Equation (1) shows a trigram
model that takes into account two words of context
to predict the probability of a word sequence wn1:
</bodyText>
<equation confidence="0.9598755">
(1) P(wn1) �
P(wiwi−1
i−2)
n
∏
i=1
</equation>
<page confidence="0.989168">
26
</page>
<subsectionHeader confidence="0.997991">
4.2 Avoiding the Length Effect
</subsectionHeader>
<bodyText confidence="0.78493875">
Because word probabilities are always less than 1
and therefore each multiplication decreases the to-
tal, if we use this standard model, longer sentences
will always receive lower scores (this is known as
the length effect). We therefore calculate the prob-
ability of a sentence as the geometric mean of the
probability of each word in the sentence as shown
in (2):
</bodyText>
<listItem confidence="0.999542833333333">
(2) P(wn1) �
4.3 Linear Combination of Language Models
OPENCCG supports the linear combination of
language models, where each model is assigned a
weight. For uniform interpolation of two language
models Pa and Pb, each receives equal weight:
</listItem>
<equation confidence="0.99885825">
Pa(wi|wi−1i−2)+Pb(wi|wi−1
i−2)
(3) P(wi|wi−1
i−2) = 2
</equation>
<bodyText confidence="0.897036333333333">
In the more general case, the language models
are assigned weights Xi, the sum of which has to
be 1:
</bodyText>
<equation confidence="0.94570825">
(4) P(wi|wi−1
i−2) = X1Pa(wi|wi−1
i−2)+X2Pb(wi|wi−1
i−2)
</equation>
<bodyText confidence="0.998064">
For example, setting X1 = 0.9 and X2 = 0.1 assigns
a high weight to the first language model.
</bodyText>
<subsectionHeader confidence="0.960057">
4.4 OPENCCG N-Gram Ranking
</subsectionHeader>
<bodyText confidence="0.999994111111111">
In the OPENCCG framework, language models
can be used to influence the chart-based realisation
process. The agenda of edges is re-sorted accord-
ing to the score an edge receives with respect to a
language model. For CRAG-2, many paraphrases
are generated from a given logical form, and they
are then ranked in order of probability according
to the combination of n-gram models appropriate
for the character and stage of the dialogue.
</bodyText>
<sectionHeader confidence="0.809173" genericHeader="method">
5 CRAG-2 Personality and Alignment
</sectionHeader>
<subsectionHeader confidence="0.511879">
Models
</subsectionHeader>
<bodyText confidence="0.9999855">
We use the SRILM toolkit (Stolcke, 2002) to com-
pute our language models. All models (except
for the cache language model described in Sec-
tion 5.4) are trigram models with backoff to bi-
grams and unigrams.
We have experimented with two strategies for
creating personality models. Since we want to
study the effects of alignment as well as person-
ality, it is essential that the two characters in a di-
alogue be distinct from one another, so that the ef-
fects of alignment can be seen. The first strategy
involves using typical language for each personal-
ity trait, and the second uses the language of one
individual. In both cases, the language models de-
scribed in the following sections are combined as
described in Section 5.5.
</bodyText>
<subsectionHeader confidence="0.999407">
5.1 Building a Personality
</subsectionHeader>
<bodyText confidence="0.999987304347826">
Nowson (2006) performed a study on language
use in weblogs. The weblog authors were asked to
complete personality questionnaires based on the
five-factor model (see Section 2.1). All weblog au-
thors scored High or Medium on the Openness di-
mension, so we have no data for typical Low Open
language.
We divided the data into High, Medium and
Low for each personality dimension, and trained
language models so that we would be able to as-
sess the probability of a word sequence given a
personality type. This means that each individual
weblog is used 5 times, once for each dimension.
For each personality dimension, the system sim-
plifies a character’s personality setting x by assign-
ing a value of High (x &gt; 70), Medium (30 &lt; x &lt;
70) or Low (x &lt; 30). The five models correspond-
ing to the character’s assigned personality are uni-
formly interpolated to give the final personality
model. If the character has been given a low Open-
ness score, since we do not have a model for this
personality type, we simply interpolate the other
four models.
</bodyText>
<subsectionHeader confidence="0.99992">
5.2 Borrowing a Personality
</subsectionHeader>
<bodyText confidence="0.9999935">
Our second strategy was to train n-gram models
on language of the individuals from the CRAG-1
corpus (Isard et al., 2005) and to use one of these
models for each character in the dialogue.
</bodyText>
<subsectionHeader confidence="0.999428">
5.3 Base Language Model
</subsectionHeader>
<bodyText confidence="0.9999418">
In the case of building a personality, a base lan-
guage model is obtained by combining a language
model computed from the corpus collected for the
CRAG-1 system and a general language model
based on data from the Switchboard corpus (Stol-
cke et al., 2000). The combined base model alone
would rank the utterances without any bias for per-
sonality or alignment. When we are borrowing a
personality, the base model is calculated from the
Switchboard corpus alone.
</bodyText>
<equation confidence="0.9981964">
i−1 1/n
P(wi |wi−2)
n
∏
i=1
</equation>
<page confidence="0.983352">
27
</page>
<subsectionHeader confidence="0.969154">
5.4 Cache Language Model
</subsectionHeader>
<bodyText confidence="0.999986">
We simulate alignment by computing a cache lan-
guage model based on the utterance that was gen-
erated immediately before. This dialogue history
cache model is the uniform interpolation of word-
and class-based n-gram models, where classes act
as a backoff mechanism when there is no exact
word match. Classes group together lexical items
with similar semantic properties, e.g.:
</bodyText>
<listItem confidence="0.9998865">
• good, bad: quality-adjective
• loved, hated: opinion-verb
</listItem>
<bodyText confidence="0.9165475">
Details of this approach can be found in Brock-
mann et al. (2005).
</bodyText>
<subsectionHeader confidence="0.990783">
5.5 Combining the Language Models
</subsectionHeader>
<bodyText confidence="0.999972">
The system uses weights to combine all the mod-
els described above. First the base and person-
ality models are interpolated to produce a base-
personality model, and finally the cache model is
introduced to add alignment effects.
</bodyText>
<sectionHeader confidence="0.985434" genericHeader="method">
6 Dialogue and Utterance Specifications
</sectionHeader>
<subsectionHeader confidence="0.994002">
6.1 Character Specification
</subsectionHeader>
<bodyText confidence="0.999991363636364">
Two computer characters are parameterised for
their personality by specifying values (on a scale
from 0 to 100) for the five dimensions: Extraver-
sion (E), Neuroticism (N), Openness (O), Agree-
ableness (A), and Conscientiousness (C). Their
alignment behaviour is set to a value between 0
(low propensity to align) and 1 (high propensity
to align). Also, each character receives an agenda
of topics they wish to discuss, along with polari-
ties (positive/negative) that indicate their opinion
on the respective topic.
</bodyText>
<subsectionHeader confidence="0.997812">
6.2 Utterance Design
</subsectionHeader>
<bodyText confidence="0.999648875">
The character with the higher Extraversion score
begins the dialogue, and their first topic is se-
lected. Once an utterance has been generated, the
other character is selected, and the system applies
the algorithm shown in (5) to decide which topic
should come next. This process continues until
there are no topics left on the agenda of the cur-
rent speaker.
</bodyText>
<listItem confidence="0.59445">
(5) if (A &lt; 46) or (C &lt; 46) or
</listItem>
<bodyText confidence="0.9866379">
(no. of utts about this topic = 2)
then take next topic from own agenda
else continue on same topic
The system creates a simple XML representa-
tion of the character’s utterance, using the speci-
fied topic and polarity. An example using the topic
music and polarity negative is shown in Figure 1.
At this point the system also decides which dis-
course connectives may be appropriate, based on
the previous topic and polarity.
</bodyText>
<figure confidence="0.9897835">
&lt;utterance&gt;
&lt;utt topic=&amp;quot;music&amp;quot; polarity=&amp;quot;dislike&amp;quot;
opp-polarity=&amp;quot;like&amp;quot; so=&amp;quot;no&amp;quot; right=&amp;quot;no&amp;quot;
also=&amp;quot;no&amp;quot; well=&amp;quot;yes&amp;quot; and=&amp;quot;no&amp;quot; but=&amp;quot;no&amp;quot;&gt;
&lt;pred adj=&amp;quot;bad&amp;quot;/&gt;
&lt;opp-pred adj=&amp;quot;good&amp;quot;/&gt;
&lt;/utt&gt;
&lt;/utterance&gt;
</figure>
<figureCaption confidence="0.999829">
Figure 1: Simple Utterance Specification
</figureCaption>
<subsectionHeader confidence="0.936607">
6.3 OPENCCG Logical Forms
</subsectionHeader>
<bodyText confidence="0.992757636363637">
Following the method described in Foster and
White (2004), the basic utterance specification is
transformed, using stylesheets written in the XSL
transformation language, into an OPENCCG log-
ical form. We make use of the facility for defin-
ing optional and alternative inputs and underspec-
ified semantics to massively over-generate candi-
date utterances. A fragment of the logical form
which results from the transformation of Figure 1
is shown in Figure 2. We also include some frag-
ments of canned text from the CRAG corpus in our
OPENCCG lexicon.
We also add optional interjections (i mean, you
know, sort of) and conversational markers (right,
but, and, well) where appropriate given the dis-
course history.
When the full logical form is processed by the
OPENCCG system, the output consists of sen-
tences of the types shown below:
(I think) the music was bad.
(I think) the music was not (wasn’t)
good.
I did not (didn’t) like the music.
I hated the music.
One thing I did not (didn’t) like was the
music.
One thing I hated was the music.
The fragmentary logical form in Figure 2 would
create all possible paraphrases from:
(well) (you know) I (kind of) [liked/loved] the
[music/score]
By using synonyms (e.g., plot=story, com-
edy=humour) and combining the sentence types
</bodyText>
<page confidence="0.992428">
28
</page>
<figure confidence="0.990243208333334">
&lt;node id=&amp;quot;l1:opinion&amp;quot; pred=&amp;quot;like&amp;quot; tense=&amp;quot;past&amp;quot;&gt;
&lt;rel name=&amp;quot;Speaker&amp;quot;&gt;
&lt;node id=&amp;quot;p1:person&amp;quot; pred=&amp;quot;pro1&amp;quot; num=&amp;quot;sg&amp;quot;/&gt;
&lt;/rel&gt;
&lt;rel name=&amp;quot;Content&amp;quot;&gt;
&lt;node id=&amp;quot;f1:cragtopic&amp;quot; pred=&amp;quot;music&amp;quot;
det=&amp;quot;the&amp;quot; num=&amp;quot;sg&amp;quot;/&gt;
&lt;/rel&gt;
&lt;opt&gt;
&lt;rel name=&amp;quot;Modifier&amp;quot;&gt;
&lt;node id=&amp;quot;w1:adv&amp;quot; pred=&amp;quot;well&amp;quot;/&gt;
&lt;/rel&gt;
&lt;opt&gt;
&lt;opt&gt;
&lt;rel name=&amp;quot;HasProp&amp;quot;&gt;
&lt;node id=&amp;quot;a2:proposition&amp;quot; pred=&amp;quot;kind-of&amp;quot;/&gt;
&lt;/rel&gt;
&lt;/opt&gt;
&lt;opt&gt;
&lt;rel name=&amp;quot;Modifier&amp;quot;&gt;
&lt;node id=&amp;quot;a1:adv&amp;quot; pred=&amp;quot;you-know&amp;quot;/&gt;
&lt;/rel&gt;
&lt;/opt&gt;
&lt;/node&gt;
</figure>
<figureCaption confidence="0.999663">
Figure 2: Fragment of Logical Form
</figureCaption>
<equation confidence="0.8906895">
Stan: E:53 N:48 A:57 C:46 O:65
agenda: film(neg), dialogue(neg),
music(pos)
other opinions: plot(neg), comedy(neg)
Eddie: E:51 N:43 A:57 C:41 O:65
agenda: plot(neg), comedy(neg),
dialogue(neg)
other opinions: music(pos), film(neg)
</equation>
<figureCaption confidence="0.999556">
Figure 3: Stan and Eddie
</figureCaption>
<bodyText confidence="0.9999435">
and optional expressions, we create up to 3000
possibilities per utterance, and the best candidate
is chosen by the specific combination of n-gram
models appropriate for the given personality and
dialogue history, as described in Section 4.
Our OPENCCG lexicon is based on the core
English lexicon included with the system and we
have added vocabulary appropriate to the movie
domain, and extended the range of grammatical
constructions where necessary.
</bodyText>
<sectionHeader confidence="0.888721" genericHeader="evaluation">
7 Output and Evaluation
</sectionHeader>
<subsectionHeader confidence="0.762513">
7.1 Output
</subsectionHeader>
<bodyText confidence="0.9999474">
In this section, we provide some example out-
puts from the CRAG-2 system, using characters
based on participants from our corpus (see Sec-
tion 5.2). Stan is higher on the Extraversion, Neu-
roticism, and Conscientiousness scales than Ed-
die. The characters’ personalities and agendas are
summarised in Figure 3.
We show three example dialogues between Stan
and Eddie. In the first (Figure 4) neither charac-
ter aligns with the other at all, while in the sec-
ond (Figure 5) Stan has a slight tendency towards
alignment and in the third (Figure 6) a more pro-
nounced tendency. In system terms, this means
that in the first dialogue the cache model was given
weight 0, while in the second and third the cache
model was given weights 0.05 and 0.1 respectively
for Stan’s utterances. It can be seen that in the
first dialogue, Eddie’s use of humour in utterance
4 is followed by Stan’s comedy, and dialogue in
utterance 6 is followed by script. In the second
dialogue, Stan aligns his first lexical choice with
Eddie’s but not his second, while in the third di-
alogue he aligns both. The syntactic structures of
Stan’s utterances in the second and third dialogue
also mirror Eddie’s progressively more closely.
</bodyText>
<listItem confidence="0.999485375">
1. Stan: I didn’t think much of the film you know.
2. Eddie: I mean I didn’t like kind of like the story.
3. Stan: Yeah there were so many little pathways that they
didn’t take you know.
4. Eddie: I mean I didn’t think the humour was really funny.
5. Stan: Yeah you know the comedy was a bit dull.
6. Eddie: I mean I didn’t like kind of like the dialogue.
7. Stan: I mean the script was a bit dull.
</listItem>
<figureCaption confidence="0.823365">
Figure 4: Zero Alignment
</figureCaption>
<listItem confidence="0.99929275">
1. Stan: I didn’t think much of the film you know.
2. Eddie: I mean I didn’t like kind of like the story.
3. Stan: Yeah there were so many little pathways that they
didn’t take you know.
4. Eddie: I mean I didn’t think the humour was really funny.
5. Stan: I mean the humour was a bit dull.
6. Eddie: I mean I didn’t like kind of like the dialogue.
7. Stan: I mean the script was a bit dull.
</listItem>
<figureCaption confidence="0.739533">
Figure 5: Little Alignment from Stan
</figureCaption>
<listItem confidence="0.999762285714286">
1. Stan: I didn’t think much of the film you know.
2. Eddie: I mean I didn’t like kind of like the story.
3. Stan: I mean the story was a bit dull.
4. Eddie: I mean I didn’t think the humour was really funny.
5. Stan: I mean the humour was a bit dull.
6. Eddie: I mean I didn’t like kind of like the dialogue.
7. Stan: I mean the dialogue was a bit dull.
</listItem>
<figureCaption confidence="0.997771">
Figure 6: More Alignment from Stan
</figureCaption>
<bodyText confidence="0.9997365">
To further illustrate the differences between the
dialogues with and without alignment, we provide
some utterance rankings. We show candidates
for the fifth utterance in each dialogue. Table 1
shows sentences from the example generated with-
out alignment, corresponding to utterance 5 (Stan)
</bodyText>
<page confidence="0.995317">
29
</page>
<figure confidence="0.9732311">
1 .03317 Yeah you know the comedy was a
bit dull.
3 .03210 Yeah you know the humour was a bit
dull.
6 .03083 Yeah to be honest I didn’t think that
the comedy was very good either.
15 .02938 I didn’t think much of the comedy
either.
24 .02861 I thought that the comedy was a bit
dull too you know.
</figure>
<tableCaption confidence="0.971191">
Table 1: Ranked Sentences with Zero Alignment
</tableCaption>
<table confidence="0.899786555555556">
1 .05384 I mean the humour was a bit dull.
8 .05239 The humour wasn’t really funny you
know.
15 .04748 I mean I didn’t think that the humour
was very good either.
19 .04518 I didn’t think much of the humour
either you know.
21 .04478 I thought the humour was a bit dull
too you know.
</table>
<tableCaption confidence="0.982626">
Table 2: Ranked Sentences with Little Alignment
from Stan
</tableCaption>
<bodyText confidence="0.9995701">
from Figure 4. We show the first five occurrences
of different sentence structures (see Section 6.3),
with their rank and their geometric mean adjusted
scores.
Table 2 shows the the top five sentences from
the fifth utterance from Figure 5 (little alignment),
and Table 3 those from Figure 6 (more align-
ment). It can be seen that when more alignment
is present, the syntactic structure used by the pre-
vious speaker rises higher in the rankings.
</bodyText>
<subsectionHeader confidence="0.989672">
7.2 Evaluation
</subsectionHeader>
<bodyText confidence="0.999893">
We have not evaluated CRAG-2. However, we
have evaluated CRAG-1. The method was to gen-
erate a set of dialogues, systematically contrasting
characters with extreme settings for the personal-
ity dimensions (High/Low Extraversion, Neuroti-
cism, and Psychoticism1).
</bodyText>
<footnote confidence="0.665803818181818">
1CRAG-1 used the simpler PEN three factor personality
model.
1 .07081 I mean the humour was a bit dull.
2 .06432 The humour wasn’t really funny you
know.
15 .05516 I mean I didn’t think that the humour
was really funny either.
27 .05000 I thought the humour was a bit dull
too you know.
36 .04884 I mean I didn’t think much of the hu-
mour either.
</footnote>
<tableCaption confidence="0.970945">
Table 3: Ranked Sentences with More Alignment
from Stan
</tableCaption>
<bodyText confidence="0.998990894736842">
Human subjects were asked to fill in a question-
naire to determine their personality. They were
then given a selection of dialogues to read. After
each dialogue, they were asked to rate their per-
ception of the interaction and of the characters in-
volved by assigning scores to a number of adjec-
tives related to the personality dimensions.
It was found that subjects could recognise dif-
ferences in the Extraversion level of the language.
Also, the personality setting of a character influ-
enced the perception of its and its dialogue part-
ner’s personality (Kahn, 2006).
We plan a similar evaluation for CRAG-2 to be
able to compare human raters’ impressions of di-
alogues generated by the two systems. We also
plan to evaluate CRAG-2 internally by varying the
weight given to the underlying language models,
and observing the effects this has on the resulting
ranking of the generated utterances.
</bodyText>
<sectionHeader confidence="0.999743" genericHeader="related work">
8 Related Work
</sectionHeader>
<bodyText confidence="0.9999414">
Related work in NLG involves either personality
or alignment. So far as we can tell, there is little
work on the latter. Varges (2005) suggests that “a
word similarity-based ranker could align the gen-
eration output (i.e. the highest-ranked candidate)
with previous utterances in the discourse context”,
but there is no report yet on an implementation of
this proposal. A rather different approach is sug-
gested by Bateman and Paris (2005), who discuss
initial work on alignment, mediated by a process
of register-recognition. Regarding generation with
personality, the most influential work is probably
Hovy’s PAULINE system, which varies both con-
tent selection and realisation according to an indi-
vidual speaker’s goals and attitudes (Hovy, 1990).
In her extremely useful survey of work on affective
(particularly, emotional) natural language gener-
ation, Belz (2003) notes that the complexity of
PAULINE’s rule system means that numerous rule
interactions can lead to unpredictable side effects.
In response, Paiva and Evans (2004) take a more
empirical line on style generation, which is closer
to that pursued here. Other relevant work includes
Loyall and Bates (1997), who explicitly propose
that personality and emotion could be used in
generation, but Belz observes that technical de-
scriptions of Hap and the Oz project suggest that
the proposals were not implemented. Walker et
al.’s (1997) system produces linguistic behaviour
which is much more varied than our current sys-
</bodyText>
<page confidence="0.995824">
30
</page>
<bodyText confidence="0.999832636363636">
tem is capable of; but there, variation is driven by
a model of social relations (based on Brown and
Levinson), rather than on personality. The NECA
project subsequently developed methods for gen-
erating scripts for pairs of dialogue agents (Piwek
and van Deemter, 2003), supported by the MIAU
platform (Rist et al., 2003). The VIRTUALHU-
MAN project is a logical successor to this work,
and its ALMA platform provides an integrated ap-
proach to affective generation, covering emotion,
mood and personality (Gebhard, 2005).
</bodyText>
<sectionHeader confidence="0.834779" genericHeader="conclusions">
9 Conclusion and Next Steps
</sectionHeader>
<bodyText confidence="0.999957892857143">
Our current system takes a much coarser-grained
approach to semantics and discourse goals than
the recent projects described above, in order to
take advantage of empirically-derived relations
between language and personality. It should be
feasible in principle to move to a more sophisti-
cated semantics, but still retain the massive over-
generation and ranking method. However, to
support more perceptible variation, we need to
exploit much larger personality-corpus resources
than have been available up to now, and our cur-
rent priority is to obtain a corpus at least an order
of magnitude larger than what is currently avail-
able. This interest in individual differences and
what corpora can (and cannot) tell us about them
is one we share with Reiter and colleagues (Reiter
and Sripada, 2004).
We also plan to integrate techniques from
CRAG-1 and CRAG-2, by passing the ranked out-
put of CRAG-2 through further processing and
ranking stages. Furthermore, we intend to inves-
tigate longer-ranging alignment processes, taking
into account more than one previous utterance,
with reduced weight by distance, to emulate mem-
ory effects.
With these enhancements, we will take further
steps towards our goal of simulating both individu-
ality and alignment in believable computer agents.
</bodyText>
<sectionHeader confidence="0.994276" genericHeader="acknowledgments">
10 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999619">
This research has been funded by Scottish Enter-
prise through the Edinburgh-Stanford Link project
“Critical Agent Dialogue” (CRAG). We would
like to thank Michael White and Scott Nowson for
their assistance and our anonymous reviewers for
their helpful comments.
</bodyText>
<sectionHeader confidence="0.990135" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.996752547169812">
Shlomo Argamon, Sushant Dhawle, Moshe Koppel,
and James W. Pennebaker. 2005. Lexical predic-
tors of personality type. In Proceedings of the 2005
Joint Annual Meeting of the Interface and the Clas-
sification Society ofNorth America.
Gene Ball and Jack Breese. 2000. Emotion and per-
sonality in a conversational agent. In J. Cassell,
J. Sullivan, S. Prevost, and E. Churchill, editors, Em-
bodied Conversational Agents, pages 189–219. MIT
Press, Cambridge, MA, USA.
John A. Bateman and C´ecile L. Paris. 2005. Adap-
tation to affective factors: architectural impacts for
natural language generation and dialogue. In Pro-
ceedings of the Workshop on Adapting the Interac-
tion Style to Affective Factors at the 10th Interna-
tional Conference on User Modeling (UM-05), Ed-
inburgh, UK.
Allan Bell. 1984. Language style as audience design.
Language in Society, 13(2):145–204.
Anja Belz. 2003. And now with feeling: Develop-
ments in emotional language generation. Techni-
cal Report ITRI-03-21, Information Technology Re-
search Institute, University of Brighton, Brighton.
Susan E. Brennan. 1996. Lexical entrainment in spon-
taneous dialog. In Proceedings of the 1996 Inter-
national Symposium on Spoken Dialogue (ISSD-96),
pages 41–44, Philadelphia, PA.
Carsten Brockmann, Amy Isard, Jon Oberlander, and
Michael White. 2005. Modelling alignment for af-
fective dialogue. In Proceedings of the Workshop on
Adapting the Interaction Style to Affective Factors at
the 10th International Conference on User Modeling
(UM-05), Edinburgh, UK.
Paul T. Costa and Robert R. McCrae, 1992. Re-
vised NEO Personality Inventory (NEO-PI-R) and
NEO Five-Factor Inventory (NEO-FFI): Profes-
sional Manual. Odessa, FL: Psychological Assess-
ment Resources.
Jean-Marc Dewaele and Adrian Furnham. 1999. Ex-
traversion: The unloved variable in applied linguis-
tic research. Language Learning, 49:509–544.
Mary Ellen Foster and Michael White. 2004. Tech-
niques for Text Planning with XSLT. In Proc. of the
4th NLPXML Workshop.
Simon Garrod and Gwyneth Doherty. 1994. Conver-
sation, co-ordination and convention: an empirical
investigation of how groups establish linguistic con-
ventions. Cognition, 53(3):181–215.
Patrick Gebhard. 2005. Alma: a layered model of af-
fect. In AAMAS ’05: Proceedings of the Fourth In-
ternational Joint Conference on Autonomous Agents
and Multiagent Systems, pages 29–36, New York,
NY, USA. ACM Press.
</reference>
<page confidence="0.999091">
31
</page>
<reference confidence="0.999737403669725">
Alastair J. Gill, Annabel J. Harrison, and Jon Ober-
lander. 2004. Interpersonality: Individual differ-
ences and interpersonal priming. In Proceedings of
the 26th Annual Conference of the Cognitive Science
Society, pages 464–469.
Eduard Hovy. 1990. Pragmatics and natural language
generation. Artificial Intelligence, 43.
Amy Isard, Carsten Brockmann, and Jon Oberlander.
2005. Re-creating dialogues from a corpus. In
Proceedings of the Workshop on Using Corpora for
Natural Language Generation at Corpus Linguistics
2005 (CL-05), pages 7–12, Birmingham, UK.
Adam S. Kahn. 2006. Master’s thesis, Stanford Uni-
versity.
A. Bryan Loyall and Joseph Bates. 1997. Personality-
rich believable agents that use language. In J. Lewis
and B. Hayes-Roth, editors, Proceedings of the
1st International Conference on Autonomous Agents
(Agents’97). ACM Press.
Gerald Matthews, Ian J. Deary, and Martha C. White-
man. 2003. Personality Traits. Cambridge Univer-
sity Press, Cambridge, 2nd edition.
Youngme Moon and Clifford Nass. 1996. How “real”
are computer personalities? Communication Re-
search, 23:651–674.
Clifford Nass and Kwan Min Lee. 2000. Does
computer-generated speech manifest personality?
an experimental test of similarity-attraction. In
Proceedings of CHI 2000, The Hague, Amsterdam,
2000, pages 329–336.
Scott Nowson. 2006. The Language of Weblogs: A
study ofgenre and individual differences. Ph.D. the-
sis, University of Edinburgh.
Jon Oberlander and Scott Nowson. 2006. Whose
thumb is it anyway? Classifying author personality
from weblog text. In Proceedings of COLING/ACL-
06: 44th Annual Meeting of the Association for
Computational Linguistics and 21st International
Conference on Computational Linguistics, Sydney.
Daniel S. Paiva and Roger Evans. 2004. A framework
for stylistically controlled generation. In Proceed-
ings of the 3rd International Conference on Natural
Language Generation, pages 120–129.
James W. Pennebaker and Laura King. 1999. Lin-
guistic styles: Language use as an individual differ-
ence. Journal ofPersonality and Social Psychology,
77:1296–1312.
James W. Pennebaker, Martha E. Francis, and Roger J.
Booth. 2001. Linguistic Inquiry and Word Count
2001. Lawrence Erlbaum Associates, Mahwah, NJ.
James W. Pennebaker, Matthias R. Mehl, and Kate G.
Neiderhoffer. 2002. Psychological aspects of nat-
ural language use: Our words, our selves. Annual
Review of Psychology, 54:547–577.
Martin J. Pickering and Holly P. Branigan. 1998. The
representation of verbs: Evidence from syntactic
priming in language production. Journal of Mem-
ory and Language, 39(4):633–651.
Martin J. Pickering and Simon Garrod. 2004. Towards
a mechanistic psychology of dialogue. Behavioral
and Brain Sciences, 27:169–225.
Paul Piwek and Kees van Deemter. 2003. Dialogue as
discourse: Controlling global properties of scripted
dialogue. In Proceedings of the AAAI Spring Sym-
posium on Natural Language Generation in Spoken
and Written Dialogue.
Ehud Reiter and Somayajulu Sripada. 2004. Contex-
tual influences on near-synonym choice. In Pro-
ceedings of the Third International Conference on
Natural Language Generation, pages 161–170.
Thomas Rist, Elisabeth Andr´e, and Stephan Baldes.
2003. A flexible platform for building applications
with life-like characters. In IUI ’03: Proceedings of
the 8th International Conference on Intelligent User
Interfaces, pages 158–165, New York, NY, USA.
ACM Press.
Klaus Scherer. 1979. Personality markers in speech.
In K. R. Scherer and H. Giles, editors, Social Mark-
ers in Speech, pages 147–209. Cambridge Univer-
sity Press, Cambridge.
Andreas Stolcke, Harry Bratt, John Butzberger, Hora-
cio Franco, Venkata Ramana Rao Gadde, Madelaine
Plauch´e, Colleen Richey, Elizabeth Shriberg, Kemal
S¨onmez, Fuliang Weng, and Jing Zheng. 2000. The
SRI March 2000 Hub-5 conversational speech tran-
scription system. In Proceedings of the 2000 Speech
Transcription Workshop, College Park, MD.
Andreas Stolcke. 2002. SRILM – an extensible lan-
guage modeling toolkit. In Proceedings of the 7th
International Conference on Spoken Language Pro-
cessing (ICSLP-02), pages 901–904, Denver, CO.
Sebastian Varges. 2005. Spatial descriptions as refer-
ring expressions in the MapTask domain. In Pro-
ceedings of the 10th European Workshop on Natural
Language Generation.
Marilyn A. Walker, Janet E. Cahn, and Steve J. Whit-
taker. 1997. Improvising linguistic style: So-
cial and affective bases for agent personality. In
J. Lewis and B. Hayes-Roth, editors, Proceedings
of the 1st International Conference on Autonomous
Agents (Agents’97), pages 96–105. ACM Press.
Michael White. 2004. Reining in CCG Chart Re-
alization. In Proceedings of the 3rd International
Conference on Natural Language Generation, pages
182–191.
Michael White. 2006. Efficient Realization of Coor-
dinate Structures in Combinatory Categorial Gram-
mar. Research on Language &amp; Computation, on-
line first, March.
</reference>
<page confidence="0.9993">
32
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.214735">
<title confidence="0.999906">Individuality and Alignment in Generated Dialogues</title>
<author confidence="0.997869">Isard Brockmann</author>
<affiliation confidence="0.9678295">School of Informatics, University of 2 Buccleuch</affiliation>
<address confidence="0.558604">Edinburgh EH8 9LW,</address>
<email confidence="0.35698">Carsten.Brockmann,</email>
<abstract confidence="0.97817745">It would be useful to enable dialogue agents to project, through linguistic means, their individuality or personality. Equally, each member of a pair of agents ought to adjust its language (to a greater or lesser extent) to match that of its interlocu- We describe which generates dialogues between pairs of agents, who are linguistically distinguishable, but able to makes use of and an over-generation and ranking approach, guided by a set of language models covering both personality and alignment. We illustrate with examples of output, and briefly note results from user studwith the earlier indicating will be further evaluated. Related work is discussed, along with current limitations and future directions.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Shlomo Argamon</author>
<author>Sushant Dhawle</author>
<author>Moshe Koppel</author>
<author>James W Pennebaker</author>
</authors>
<title>Lexical predictors of personality type.</title>
<date>2005</date>
<booktitle>In Proceedings of the 2005 Joint Annual Meeting of the Interface and the Classification Society ofNorth America.</booktitle>
<contexts>
<context position="4531" citStr="Argamon et al. (2005)" startWordPosition="674" endWordPosition="677">ted. On the one hand, in generation, there has been work on personality-based generation. For instance, in developing embodied conversational agents, researchers have designed agents or teams of agents with distinguishable linguistic personalities (Ball and Breese, 2000; Rist et al., 2003; Piwek and van Deemter, 2003; Gebhard, 2005). However, the linguistic behaviour is usually informed by rules based on personality stereotypes, rather than on language statistics themselves. On the other hand, in interpretation, more empirical work has recently been carried out, to enable text classification. Argamon et al. (2005) attempted to classify authors as High or Low Extravert and High or Low Neurotic, using Pennebaker and King’s (1999) data. They report classification accuracies of around 58% (with a 50% baseline). Oberlander and Nowson (2006) undertake a comparable task, using weblog data. They report classification accuracies of roughly 85% (Neuroticism) and 94% (Extraversion), and comparable figures for Agreeableness and Conscientiousness. Such studies can provide ordered lists of linguistic features which are useful for distinguishing language producers, and we will return to this, below. 2.2 Alignment and</context>
</contexts>
<marker>Argamon, Dhawle, Koppel, Pennebaker, 2005</marker>
<rawString>Shlomo Argamon, Sushant Dhawle, Moshe Koppel, and James W. Pennebaker. 2005. Lexical predictors of personality type. In Proceedings of the 2005 Joint Annual Meeting of the Interface and the Classification Society ofNorth America.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gene Ball</author>
<author>Jack Breese</author>
</authors>
<title>Emotion and personality in a conversational agent. In</title>
<date>2000</date>
<booktitle>Embodied Conversational Agents,</booktitle>
<pages>189--219</pages>
<editor>J. Cassell, J. Sullivan, S. Prevost, and E. Churchill, editors,</editor>
<publisher>MIT Press,</publisher>
<location>Cambridge, MA, USA.</location>
<contexts>
<context position="1389" citStr="Ball and Breese, 2000" startWordPosition="204" endWordPosition="207">y and alignment. We illustrate with examples of output, and briefly note results from user studies with the earlier CRAG-1, indicating how CRAG-2 will be further evaluated. Related work is discussed, along with current limitations and future directions. 1 Introduction A computer agent should be individual. Nass and collaborators find that users’ responses to computer-agents are influenced by whether the agent’s linguistic personality matches—or mismatches—the personality of the user (Moon and Nass, 1996; Nass and Lee, 2000). Similarly, characters in virtual environments should be distinctive (Ball and Breese, 2000; Rist et al., 2003). But an aspect of personality is how well you adjust to other people (and their language use): alignment. Pickering and Garrod’s Interactive Alignment Model suggests that people tend to automatically converge on lexical and syntactic choices, via a low-level mechanism of interpersonal priming (Pickering and Garrod, 2004), and Brennan has shown that people will align their language towards that of computer agents (Brennan, 1996). But it is an open issue as to whether some people are better ‘aligners’ than others. Conversely, alignment is only visible and interesting (among </context>
<context position="4180" citStr="Ball and Breese, 2000" startWordPosition="621" endWordPosition="624">tion for Computational Linguistics use: more social process talk, positive emotion words and inclusives; and fewer negations, tentative words, exclusives, causation words, negative emotion words, and articles (Pennebaker and King, 1999; Pennebaker et al., 2002). Computational linguistic exploitation of such empirically-derived features has been limited. On the one hand, in generation, there has been work on personality-based generation. For instance, in developing embodied conversational agents, researchers have designed agents or teams of agents with distinguishable linguistic personalities (Ball and Breese, 2000; Rist et al., 2003; Piwek and van Deemter, 2003; Gebhard, 2005). However, the linguistic behaviour is usually informed by rules based on personality stereotypes, rather than on language statistics themselves. On the other hand, in interpretation, more empirical work has recently been carried out, to enable text classification. Argamon et al. (2005) attempted to classify authors as High or Low Extravert and High or Low Neurotic, using Pennebaker and King’s (1999) data. They report classification accuracies of around 58% (with a 50% baseline). Oberlander and Nowson (2006) undertake a comparable</context>
</contexts>
<marker>Ball, Breese, 2000</marker>
<rawString>Gene Ball and Jack Breese. 2000. Emotion and personality in a conversational agent. In J. Cassell, J. Sullivan, S. Prevost, and E. Churchill, editors, Embodied Conversational Agents, pages 189–219. MIT Press, Cambridge, MA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John A Bateman</author>
<author>C´ecile L Paris</author>
</authors>
<title>Adaptation to affective factors: architectural impacts for natural language generation and dialogue.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Adapting the Interaction Style to Affective Factors at the 10th International Conference on User Modeling (UM-05),</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="22803" citStr="Bateman and Paris (2005)" startWordPosition="3723" endWordPosition="3726">e CRAG-2 internally by varying the weight given to the underlying language models, and observing the effects this has on the resulting ranking of the generated utterances. 8 Related Work Related work in NLG involves either personality or alignment. So far as we can tell, there is little work on the latter. Varges (2005) suggests that “a word similarity-based ranker could align the generation output (i.e. the highest-ranked candidate) with previous utterances in the discourse context”, but there is no report yet on an implementation of this proposal. A rather different approach is suggested by Bateman and Paris (2005), who discuss initial work on alignment, mediated by a process of register-recognition. Regarding generation with personality, the most influential work is probably Hovy’s PAULINE system, which varies both content selection and realisation according to an individual speaker’s goals and attitudes (Hovy, 1990). In her extremely useful survey of work on affective (particularly, emotional) natural language generation, Belz (2003) notes that the complexity of PAULINE’s rule system means that numerous rule interactions can lead to unpredictable side effects. In response, Paiva and Evans (2004) take </context>
</contexts>
<marker>Bateman, Paris, 2005</marker>
<rawString>John A. Bateman and C´ecile L. Paris. 2005. Adaptation to affective factors: architectural impacts for natural language generation and dialogue. In Proceedings of the Workshop on Adapting the Interaction Style to Affective Factors at the 10th International Conference on User Modeling (UM-05), Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Allan Bell</author>
</authors>
<title>Language style as audience design.</title>
<date>1984</date>
<journal>Language in Society,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="5454" citStr="Bell, 1984" startWordPosition="817" endWordPosition="818"> of roughly 85% (Neuroticism) and 94% (Extraversion), and comparable figures for Agreeableness and Conscientiousness. Such studies can provide ordered lists of linguistic features which are useful for distinguishing language producers, and we will return to this, below. 2.2 Alignment and Language People converge with their interlocutors in linguistic choices at a number of levels (Pickering and Garrod, 2004). The phenomena can be seen in both social and cognitive terms. On the social side, co-operative processes such as audience design are usually considered to be conscious, at least in part (Bell, 1984). But on the cognitive side, coordinative processes such as alignment are usually considered to be largely automatic (Garrod and Doherty, 1994). Alignment can be probed by psycholinguistic tests for interpersonal priming, establishing the extent to which participants are more likely to use a lexical item or syntactic construction after hearing their conversational partner use it. Syntactic priming experiments involve constructions such as passives, and ditransitives (Pickering and Branigan, 1998). It is possible that some people are stronger aligners than others. Gill et al. (2004) probed synt</context>
</contexts>
<marker>Bell, 1984</marker>
<rawString>Allan Bell. 1984. Language style as audience design. Language in Society, 13(2):145–204.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anja Belz</author>
</authors>
<title>And now with feeling: Developments in emotional language generation.</title>
<date>2003</date>
<tech>Technical Report ITRI-03-21,</tech>
<institution>Information Technology Research Institute, University of Brighton,</institution>
<location>Brighton.</location>
<contexts>
<context position="23232" citStr="Belz (2003)" startWordPosition="3786" endWordPosition="3787"> previous utterances in the discourse context”, but there is no report yet on an implementation of this proposal. A rather different approach is suggested by Bateman and Paris (2005), who discuss initial work on alignment, mediated by a process of register-recognition. Regarding generation with personality, the most influential work is probably Hovy’s PAULINE system, which varies both content selection and realisation according to an individual speaker’s goals and attitudes (Hovy, 1990). In her extremely useful survey of work on affective (particularly, emotional) natural language generation, Belz (2003) notes that the complexity of PAULINE’s rule system means that numerous rule interactions can lead to unpredictable side effects. In response, Paiva and Evans (2004) take a more empirical line on style generation, which is closer to that pursued here. Other relevant work includes Loyall and Bates (1997), who explicitly propose that personality and emotion could be used in generation, but Belz observes that technical descriptions of Hap and the Oz project suggest that the proposals were not implemented. Walker et al.’s (1997) system produces linguistic behaviour which is much more varied than o</context>
</contexts>
<marker>Belz, 2003</marker>
<rawString>Anja Belz. 2003. And now with feeling: Developments in emotional language generation. Technical Report ITRI-03-21, Information Technology Research Institute, University of Brighton, Brighton.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Susan E Brennan</author>
</authors>
<title>Lexical entrainment in spontaneous dialog.</title>
<date>1996</date>
<booktitle>In Proceedings of the 1996 International Symposium on Spoken Dialogue (ISSD-96),</booktitle>
<pages>41--44</pages>
<location>Philadelphia, PA.</location>
<contexts>
<context position="1841" citStr="Brennan, 1996" startWordPosition="279" endWordPosition="280">—the personality of the user (Moon and Nass, 1996; Nass and Lee, 2000). Similarly, characters in virtual environments should be distinctive (Ball and Breese, 2000; Rist et al., 2003). But an aspect of personality is how well you adjust to other people (and their language use): alignment. Pickering and Garrod’s Interactive Alignment Model suggests that people tend to automatically converge on lexical and syntactic choices, via a low-level mechanism of interpersonal priming (Pickering and Garrod, 2004), and Brennan has shown that people will align their language towards that of computer agents (Brennan, 1996). But it is an open issue as to whether some people are better ‘aligners’ than others. Conversely, alignment is only visible and interesting (among computer agents) if they start out being individual. We therefore set out to simulate both individuality and alignment. The paper briefly surveys the evidence for linguistic personality, for interpersonal alignment, and for interaction between them. It then sketches the current version of CRAG. CRAG-2 makes use of OPENCCG and an over-generation and ranking approach, guided by a set of language models for personality and alignment. We illustrate the</context>
</contexts>
<marker>Brennan, 1996</marker>
<rawString>Susan E. Brennan. 1996. Lexical entrainment in spontaneous dialog. In Proceedings of the 1996 International Symposium on Spoken Dialogue (ISSD-96), pages 41–44, Philadelphia, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Carsten Brockmann</author>
<author>Amy Isard</author>
<author>Jon Oberlander</author>
<author>Michael White</author>
</authors>
<title>Modelling alignment for affective dialogue.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Adapting the Interaction Style to Affective Factors at the 10th International Conference on User Modeling (UM-05),</booktitle>
<location>Edinburgh, UK.</location>
<contexts>
<context position="12485" citStr="Brockmann et al. (2005)" startWordPosition="1987" endWordPosition="1991">ity, the base model is calculated from the Switchboard corpus alone. i−1 1/n P(wi |wi−2) n ∏ i=1 27 5.4 Cache Language Model We simulate alignment by computing a cache language model based on the utterance that was generated immediately before. This dialogue history cache model is the uniform interpolation of wordand class-based n-gram models, where classes act as a backoff mechanism when there is no exact word match. Classes group together lexical items with similar semantic properties, e.g.: • good, bad: quality-adjective • loved, hated: opinion-verb Details of this approach can be found in Brockmann et al. (2005). 5.5 Combining the Language Models The system uses weights to combine all the models described above. First the base and personality models are interpolated to produce a basepersonality model, and finally the cache model is introduced to add alignment effects. 6 Dialogue and Utterance Specifications 6.1 Character Specification Two computer characters are parameterised for their personality by specifying values (on a scale from 0 to 100) for the five dimensions: Extraversion (E), Neuroticism (N), Openness (O), Agreeableness (A), and Conscientiousness (C). Their alignment behaviour is set to a </context>
</contexts>
<marker>Brockmann, Isard, Oberlander, White, 2005</marker>
<rawString>Carsten Brockmann, Amy Isard, Jon Oberlander, and Michael White. 2005. Modelling alignment for affective dialogue. In Proceedings of the Workshop on Adapting the Interaction Style to Affective Factors at the 10th International Conference on User Modeling (UM-05), Edinburgh, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul T Costa</author>
<author>Robert R McCrae</author>
</authors>
<title>Assessment Resources.</title>
<date>1992</date>
<booktitle>Revised NEO Personality Inventory (NEO-PI-R) and NEO Five-Factor Inventory (NEO-FFI): Professional Manual.</booktitle>
<publisher>Psychological</publisher>
<location>Odessa, FL:</location>
<contexts>
<context position="2856" citStr="Costa and McCrae, 1992" startWordPosition="434" endWordPosition="437">them. It then sketches the current version of CRAG. CRAG-2 makes use of OPENCCG and an over-generation and ranking approach, guided by a set of language models for personality and alignment. We illustrate the differing linguistic behaviours that it generates, and briefly note promising results from user studies with the earlier CRAG-1 system, indicating how CRAG-2 will be further evaluated. Related work is discussed, along with possible directions for future work. 2 Background 2.1 Personality and Language Current work on personality traits is dominated by Costa and McCrae’s five-factor model (Costa and McCrae, 1992). The five factors, or dimensions, are: Extraversion; Neuroticism; Openness; Agreeableness; and Conscientiousness (Matthews et al., 2003). It has been shown that scores on these dimensions correlate with some aspects of language use (Scherer, 1979; Dewaele and Furnham, 1999). In studies of text, the focus has been on lexical choice, and Pennebaker and colleagues have analysed relative frequencies of use of word-stems in a dictionary structured into semantic and syntactic categories (Pennebaker et al., 2001). Amongst other results, they have shown that High Extraverts 25 Proceedings of the Four</context>
</contexts>
<marker>Costa, McCrae, 1992</marker>
<rawString>Paul T. Costa and Robert R. McCrae, 1992. Revised NEO Personality Inventory (NEO-PI-R) and NEO Five-Factor Inventory (NEO-FFI): Professional Manual. Odessa, FL: Psychological Assessment Resources.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jean-Marc Dewaele</author>
<author>Adrian Furnham</author>
</authors>
<title>Extraversion: The unloved variable in applied linguistic research.</title>
<date>1999</date>
<booktitle>Language Learning,</booktitle>
<pages>49--509</pages>
<contexts>
<context position="3131" citStr="Dewaele and Furnham, 1999" startWordPosition="474" endWordPosition="477">note promising results from user studies with the earlier CRAG-1 system, indicating how CRAG-2 will be further evaluated. Related work is discussed, along with possible directions for future work. 2 Background 2.1 Personality and Language Current work on personality traits is dominated by Costa and McCrae’s five-factor model (Costa and McCrae, 1992). The five factors, or dimensions, are: Extraversion; Neuroticism; Openness; Agreeableness; and Conscientiousness (Matthews et al., 2003). It has been shown that scores on these dimensions correlate with some aspects of language use (Scherer, 1979; Dewaele and Furnham, 1999). In studies of text, the focus has been on lexical choice, and Pennebaker and colleagues have analysed relative frequencies of use of word-stems in a dictionary structured into semantic and syntactic categories (Pennebaker et al., 2001). Amongst other results, they have shown that High Extraverts 25 Proceedings of the Fourth International Natural Language Generation Conference, pages 25–32, Sydney, July 2006. c�2006 Association for Computational Linguistics use: more social process talk, positive emotion words and inclusives; and fewer negations, tentative words, exclusives, causation words, </context>
</contexts>
<marker>Dewaele, Furnham, 1999</marker>
<rawString>Jean-Marc Dewaele and Adrian Furnham. 1999. Extraversion: The unloved variable in applied linguistic research. Language Learning, 49:509–544.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mary Ellen Foster</author>
<author>Michael White</author>
</authors>
<title>Techniques for Text Planning with XSLT.</title>
<date>2004</date>
<booktitle>In Proc. of the 4th NLPXML Workshop.</booktitle>
<contexts>
<context position="14474" citStr="Foster and White (2004)" startWordPosition="2302" endWordPosition="2305">eates a simple XML representation of the character’s utterance, using the specified topic and polarity. An example using the topic music and polarity negative is shown in Figure 1. At this point the system also decides which discourse connectives may be appropriate, based on the previous topic and polarity. &lt;utterance&gt; &lt;utt topic=&amp;quot;music&amp;quot; polarity=&amp;quot;dislike&amp;quot; opp-polarity=&amp;quot;like&amp;quot; so=&amp;quot;no&amp;quot; right=&amp;quot;no&amp;quot; also=&amp;quot;no&amp;quot; well=&amp;quot;yes&amp;quot; and=&amp;quot;no&amp;quot; but=&amp;quot;no&amp;quot;&gt; &lt;pred adj=&amp;quot;bad&amp;quot;/&gt; &lt;opp-pred adj=&amp;quot;good&amp;quot;/&gt; &lt;/utt&gt; &lt;/utterance&gt; Figure 1: Simple Utterance Specification 6.3 OPENCCG Logical Forms Following the method described in Foster and White (2004), the basic utterance specification is transformed, using stylesheets written in the XSL transformation language, into an OPENCCG logical form. We make use of the facility for defining optional and alternative inputs and underspecified semantics to massively over-generate candidate utterances. A fragment of the logical form which results from the transformation of Figure 1 is shown in Figure 2. We also include some fragments of canned text from the CRAG corpus in our OPENCCG lexicon. We also add optional interjections (i mean, you know, sort of) and conversational markers (right, but, and, wel</context>
</contexts>
<marker>Foster, White, 2004</marker>
<rawString>Mary Ellen Foster and Michael White. 2004. Techniques for Text Planning with XSLT. In Proc. of the 4th NLPXML Workshop.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Simon Garrod</author>
<author>Gwyneth Doherty</author>
</authors>
<title>Conversation, co-ordination and convention: an empirical investigation of how groups establish linguistic conventions.</title>
<date>1994</date>
<journal>Cognition,</journal>
<volume>53</volume>
<issue>3</issue>
<contexts>
<context position="5597" citStr="Garrod and Doherty, 1994" startWordPosition="838" endWordPosition="841">s can provide ordered lists of linguistic features which are useful for distinguishing language producers, and we will return to this, below. 2.2 Alignment and Language People converge with their interlocutors in linguistic choices at a number of levels (Pickering and Garrod, 2004). The phenomena can be seen in both social and cognitive terms. On the social side, co-operative processes such as audience design are usually considered to be conscious, at least in part (Bell, 1984). But on the cognitive side, coordinative processes such as alignment are usually considered to be largely automatic (Garrod and Doherty, 1994). Alignment can be probed by psycholinguistic tests for interpersonal priming, establishing the extent to which participants are more likely to use a lexical item or syntactic construction after hearing their conversational partner use it. Syntactic priming experiments involve constructions such as passives, and ditransitives (Pickering and Branigan, 1998). It is possible that some people are stronger aligners than others. Gill et al. (2004) probed syntactic priming for passives, and investigated whether levels of Extraversion or Neuroticism would affect the strength of priming effects. It was</context>
</contexts>
<marker>Garrod, Doherty, 1994</marker>
<rawString>Simon Garrod and Gwyneth Doherty. 1994. Conversation, co-ordination and convention: an empirical investigation of how groups establish linguistic conventions. Cognition, 53(3):181–215.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Gebhard</author>
</authors>
<title>Alma: a layered model of affect.</title>
<date>2005</date>
<booktitle>In AAMAS ’05: Proceedings of the Fourth International Joint Conference on Autonomous Agents and Multiagent Systems,</booktitle>
<pages>29--36</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4244" citStr="Gebhard, 2005" startWordPosition="634" endWordPosition="635">ive emotion words and inclusives; and fewer negations, tentative words, exclusives, causation words, negative emotion words, and articles (Pennebaker and King, 1999; Pennebaker et al., 2002). Computational linguistic exploitation of such empirically-derived features has been limited. On the one hand, in generation, there has been work on personality-based generation. For instance, in developing embodied conversational agents, researchers have designed agents or teams of agents with distinguishable linguistic personalities (Ball and Breese, 2000; Rist et al., 2003; Piwek and van Deemter, 2003; Gebhard, 2005). However, the linguistic behaviour is usually informed by rules based on personality stereotypes, rather than on language statistics themselves. On the other hand, in interpretation, more empirical work has recently been carried out, to enable text classification. Argamon et al. (2005) attempted to classify authors as High or Low Extravert and High or Low Neurotic, using Pennebaker and King’s (1999) data. They report classification accuracies of around 58% (with a 50% baseline). Oberlander and Nowson (2006) undertake a comparable task, using weblog data. They report classification accuracies </context>
<context position="24367" citStr="Gebhard, 2005" startWordPosition="3967" endWordPosition="3968">’s (1997) system produces linguistic behaviour which is much more varied than our current sys30 tem is capable of; but there, variation is driven by a model of social relations (based on Brown and Levinson), rather than on personality. The NECA project subsequently developed methods for generating scripts for pairs of dialogue agents (Piwek and van Deemter, 2003), supported by the MIAU platform (Rist et al., 2003). The VIRTUALHUMAN project is a logical successor to this work, and its ALMA platform provides an integrated approach to affective generation, covering emotion, mood and personality (Gebhard, 2005). 9 Conclusion and Next Steps Our current system takes a much coarser-grained approach to semantics and discourse goals than the recent projects described above, in order to take advantage of empirically-derived relations between language and personality. It should be feasible in principle to move to a more sophisticated semantics, but still retain the massive overgeneration and ranking method. However, to support more perceptible variation, we need to exploit much larger personality-corpus resources than have been available up to now, and our current priority is to obtain a corpus at least an</context>
</contexts>
<marker>Gebhard, 2005</marker>
<rawString>Patrick Gebhard. 2005. Alma: a layered model of affect. In AAMAS ’05: Proceedings of the Fourth International Joint Conference on Autonomous Agents and Multiagent Systems, pages 29–36, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alastair J Gill</author>
<author>Annabel J Harrison</author>
<author>Jon Oberlander</author>
</authors>
<title>Interpersonality: Individual differences and interpersonal priming.</title>
<date>2004</date>
<booktitle>In Proceedings of the 26th Annual Conference of the Cognitive Science Society,</booktitle>
<pages>464--469</pages>
<contexts>
<context position="6042" citStr="Gill et al. (2004)" startWordPosition="905" endWordPosition="908"> at least in part (Bell, 1984). But on the cognitive side, coordinative processes such as alignment are usually considered to be largely automatic (Garrod and Doherty, 1994). Alignment can be probed by psycholinguistic tests for interpersonal priming, establishing the extent to which participants are more likely to use a lexical item or syntactic construction after hearing their conversational partner use it. Syntactic priming experiments involve constructions such as passives, and ditransitives (Pickering and Branigan, 1998). It is possible that some people are stronger aligners than others. Gill et al. (2004) probed syntactic priming for passives, and investigated whether levels of Extraversion or Neuroticism would affect the strength of priming effects. It was found that Extraversion has no effect, but that Neuroticism has a non-linear effect: both High and Low levels of Neuroticism led to weaker priming; Mid levels led to significantly stronger priming. Given this, if a generation system is going to simulate alignment, it is probably worth designing it so that it can simulate agents with differing propensities to align. 3 The CRAG System Overview The system described in the following sections (C</context>
</contexts>
<marker>Gill, Harrison, Oberlander, 2004</marker>
<rawString>Alastair J. Gill, Annabel J. Harrison, and Jon Oberlander. 2004. Interpersonality: Individual differences and interpersonal priming. In Proceedings of the 26th Annual Conference of the Cognitive Science Society, pages 464–469.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eduard Hovy</author>
</authors>
<title>Pragmatics and natural language generation.</title>
<date>1990</date>
<journal>Artificial Intelligence,</journal>
<volume>43</volume>
<contexts>
<context position="23112" citStr="Hovy, 1990" startWordPosition="3769" endWordPosition="3770">suggests that “a word similarity-based ranker could align the generation output (i.e. the highest-ranked candidate) with previous utterances in the discourse context”, but there is no report yet on an implementation of this proposal. A rather different approach is suggested by Bateman and Paris (2005), who discuss initial work on alignment, mediated by a process of register-recognition. Regarding generation with personality, the most influential work is probably Hovy’s PAULINE system, which varies both content selection and realisation according to an individual speaker’s goals and attitudes (Hovy, 1990). In her extremely useful survey of work on affective (particularly, emotional) natural language generation, Belz (2003) notes that the complexity of PAULINE’s rule system means that numerous rule interactions can lead to unpredictable side effects. In response, Paiva and Evans (2004) take a more empirical line on style generation, which is closer to that pursued here. Other relevant work includes Loyall and Bates (1997), who explicitly propose that personality and emotion could be used in generation, but Belz observes that technical descriptions of Hap and the Oz project suggest that the prop</context>
</contexts>
<marker>Hovy, 1990</marker>
<rawString>Eduard Hovy. 1990. Pragmatics and natural language generation. Artificial Intelligence, 43.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Amy Isard</author>
<author>Carsten Brockmann</author>
<author>Jon Oberlander</author>
</authors>
<title>Re-creating dialogues from a corpus.</title>
<date>2005</date>
<booktitle>In Proceedings of the Workshop on Using Corpora for Natural Language Generation at Corpus Linguistics</booktitle>
<pages>7--12</pages>
<location>Birmingham, UK.</location>
<contexts>
<context position="6716" citStr="Isard et al. (2005)" startWordPosition="1014" endWordPosition="1017">d whether levels of Extraversion or Neuroticism would affect the strength of priming effects. It was found that Extraversion has no effect, but that Neuroticism has a non-linear effect: both High and Low levels of Neuroticism led to weaker priming; Mid levels led to significantly stronger priming. Given this, if a generation system is going to simulate alignment, it is probably worth designing it so that it can simulate agents with differing propensities to align. 3 The CRAG System Overview The system described in the following sections (CRAG-2) is the successor to CRAG-1 which is detailed in Isard et al. (2005). The system generates a dialogue between two computer agents on the subject of opinions about a film. CRAG-2 uses the OPENCCG parsing and generation framework (White, 2004; White, 2006). The realiser component takes a logical form as input and outputs a list of candidate sentences ranked using one or more language models. In CRAG-2, we use the OPENCCG generator to massively over-generate paraphrases, and the combination of n-gram models described in Section 4 to choose the best utterance according to a character’s personality and agenda, and the dialogue history. 4 N-Grams: Personality and Al</context>
<context position="11380" citStr="Isard et al., 2005" startWordPosition="1801" endWordPosition="1804">ch dimension. For each personality dimension, the system simplifies a character’s personality setting x by assigning a value of High (x &gt; 70), Medium (30 &lt; x &lt; 70) or Low (x &lt; 30). The five models corresponding to the character’s assigned personality are uniformly interpolated to give the final personality model. If the character has been given a low Openness score, since we do not have a model for this personality type, we simply interpolate the other four models. 5.2 Borrowing a Personality Our second strategy was to train n-gram models on language of the individuals from the CRAG-1 corpus (Isard et al., 2005) and to use one of these models for each character in the dialogue. 5.3 Base Language Model In the case of building a personality, a base language model is obtained by combining a language model computed from the corpus collected for the CRAG-1 system and a general language model based on data from the Switchboard corpus (Stolcke et al., 2000). The combined base model alone would rank the utterances without any bias for personality or alignment. When we are borrowing a personality, the base model is calculated from the Switchboard corpus alone. i−1 1/n P(wi |wi−2) n ∏ i=1 27 5.4 Cache Language</context>
</contexts>
<marker>Isard, Brockmann, Oberlander, 2005</marker>
<rawString>Amy Isard, Carsten Brockmann, and Jon Oberlander. 2005. Re-creating dialogues from a corpus. In Proceedings of the Workshop on Using Corpora for Natural Language Generation at Corpus Linguistics 2005 (CL-05), pages 7–12, Birmingham, UK.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam S Kahn</author>
</authors>
<title>Master’s thesis,</title>
<date>2006</date>
<institution>Stanford University.</institution>
<contexts>
<context position="22023" citStr="Kahn, 2006" startWordPosition="3597" endWordPosition="3598">Ranked Sentences with More Alignment from Stan Human subjects were asked to fill in a questionnaire to determine their personality. They were then given a selection of dialogues to read. After each dialogue, they were asked to rate their perception of the interaction and of the characters involved by assigning scores to a number of adjectives related to the personality dimensions. It was found that subjects could recognise differences in the Extraversion level of the language. Also, the personality setting of a character influenced the perception of its and its dialogue partner’s personality (Kahn, 2006). We plan a similar evaluation for CRAG-2 to be able to compare human raters’ impressions of dialogues generated by the two systems. We also plan to evaluate CRAG-2 internally by varying the weight given to the underlying language models, and observing the effects this has on the resulting ranking of the generated utterances. 8 Related Work Related work in NLG involves either personality or alignment. So far as we can tell, there is little work on the latter. Varges (2005) suggests that “a word similarity-based ranker could align the generation output (i.e. the highest-ranked candidate) with p</context>
</contexts>
<marker>Kahn, 2006</marker>
<rawString>Adam S. Kahn. 2006. Master’s thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bryan Loyall</author>
<author>Joseph Bates</author>
</authors>
<title>Personalityrich believable agents that use language.</title>
<date>1997</date>
<booktitle>Proceedings of the 1st International Conference on Autonomous Agents (Agents’97).</booktitle>
<editor>In J. Lewis and B. Hayes-Roth, editors,</editor>
<publisher>ACM Press.</publisher>
<contexts>
<context position="23536" citStr="Loyall and Bates (1997)" startWordPosition="3832" endWordPosition="3835">ith personality, the most influential work is probably Hovy’s PAULINE system, which varies both content selection and realisation according to an individual speaker’s goals and attitudes (Hovy, 1990). In her extremely useful survey of work on affective (particularly, emotional) natural language generation, Belz (2003) notes that the complexity of PAULINE’s rule system means that numerous rule interactions can lead to unpredictable side effects. In response, Paiva and Evans (2004) take a more empirical line on style generation, which is closer to that pursued here. Other relevant work includes Loyall and Bates (1997), who explicitly propose that personality and emotion could be used in generation, but Belz observes that technical descriptions of Hap and the Oz project suggest that the proposals were not implemented. Walker et al.’s (1997) system produces linguistic behaviour which is much more varied than our current sys30 tem is capable of; but there, variation is driven by a model of social relations (based on Brown and Levinson), rather than on personality. The NECA project subsequently developed methods for generating scripts for pairs of dialogue agents (Piwek and van Deemter, 2003), supported by the</context>
</contexts>
<marker>Loyall, Bates, 1997</marker>
<rawString>A. Bryan Loyall and Joseph Bates. 1997. Personalityrich believable agents that use language. In J. Lewis and B. Hayes-Roth, editors, Proceedings of the 1st International Conference on Autonomous Agents (Agents’97). ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gerald Matthews</author>
<author>Ian J Deary</author>
<author>Martha C Whiteman</author>
</authors>
<title>Personality Traits.</title>
<date>2003</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge,</location>
<note>2nd edition.</note>
<contexts>
<context position="2993" citStr="Matthews et al., 2003" startWordPosition="451" endWordPosition="454">et of language models for personality and alignment. We illustrate the differing linguistic behaviours that it generates, and briefly note promising results from user studies with the earlier CRAG-1 system, indicating how CRAG-2 will be further evaluated. Related work is discussed, along with possible directions for future work. 2 Background 2.1 Personality and Language Current work on personality traits is dominated by Costa and McCrae’s five-factor model (Costa and McCrae, 1992). The five factors, or dimensions, are: Extraversion; Neuroticism; Openness; Agreeableness; and Conscientiousness (Matthews et al., 2003). It has been shown that scores on these dimensions correlate with some aspects of language use (Scherer, 1979; Dewaele and Furnham, 1999). In studies of text, the focus has been on lexical choice, and Pennebaker and colleagues have analysed relative frequencies of use of word-stems in a dictionary structured into semantic and syntactic categories (Pennebaker et al., 2001). Amongst other results, they have shown that High Extraverts 25 Proceedings of the Fourth International Natural Language Generation Conference, pages 25–32, Sydney, July 2006. c�2006 Association for Computational Linguistics</context>
</contexts>
<marker>Matthews, Deary, Whiteman, 2003</marker>
<rawString>Gerald Matthews, Ian J. Deary, and Martha C. Whiteman. 2003. Personality Traits. Cambridge University Press, Cambridge, 2nd edition.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Youngme Moon</author>
<author>Clifford Nass</author>
</authors>
<title>How “real” are computer personalities?</title>
<date>1996</date>
<journal>Communication Research,</journal>
<pages>23--651</pages>
<contexts>
<context position="1276" citStr="Moon and Nass, 1996" startWordPosition="187" endWordPosition="190">PENCCG and an over-generation and ranking approach, guided by a set of language models covering both personality and alignment. We illustrate with examples of output, and briefly note results from user studies with the earlier CRAG-1, indicating how CRAG-2 will be further evaluated. Related work is discussed, along with current limitations and future directions. 1 Introduction A computer agent should be individual. Nass and collaborators find that users’ responses to computer-agents are influenced by whether the agent’s linguistic personality matches—or mismatches—the personality of the user (Moon and Nass, 1996; Nass and Lee, 2000). Similarly, characters in virtual environments should be distinctive (Ball and Breese, 2000; Rist et al., 2003). But an aspect of personality is how well you adjust to other people (and their language use): alignment. Pickering and Garrod’s Interactive Alignment Model suggests that people tend to automatically converge on lexical and syntactic choices, via a low-level mechanism of interpersonal priming (Pickering and Garrod, 2004), and Brennan has shown that people will align their language towards that of computer agents (Brennan, 1996). But it is an open issue as to whe</context>
</contexts>
<marker>Moon, Nass, 1996</marker>
<rawString>Youngme Moon and Clifford Nass. 1996. How “real” are computer personalities? Communication Research, 23:651–674.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Clifford Nass</author>
<author>Kwan Min Lee</author>
</authors>
<title>Does computer-generated speech manifest personality? an experimental test of similarity-attraction.</title>
<date>2000</date>
<booktitle>In Proceedings of CHI 2000, The Hague,</booktitle>
<pages>329--336</pages>
<location>Amsterdam,</location>
<contexts>
<context position="1297" citStr="Nass and Lee, 2000" startWordPosition="191" endWordPosition="194">neration and ranking approach, guided by a set of language models covering both personality and alignment. We illustrate with examples of output, and briefly note results from user studies with the earlier CRAG-1, indicating how CRAG-2 will be further evaluated. Related work is discussed, along with current limitations and future directions. 1 Introduction A computer agent should be individual. Nass and collaborators find that users’ responses to computer-agents are influenced by whether the agent’s linguistic personality matches—or mismatches—the personality of the user (Moon and Nass, 1996; Nass and Lee, 2000). Similarly, characters in virtual environments should be distinctive (Ball and Breese, 2000; Rist et al., 2003). But an aspect of personality is how well you adjust to other people (and their language use): alignment. Pickering and Garrod’s Interactive Alignment Model suggests that people tend to automatically converge on lexical and syntactic choices, via a low-level mechanism of interpersonal priming (Pickering and Garrod, 2004), and Brennan has shown that people will align their language towards that of computer agents (Brennan, 1996). But it is an open issue as to whether some people are </context>
</contexts>
<marker>Nass, Lee, 2000</marker>
<rawString>Clifford Nass and Kwan Min Lee. 2000. Does computer-generated speech manifest personality? an experimental test of similarity-attraction. In Proceedings of CHI 2000, The Hague, Amsterdam, 2000, pages 329–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Scott Nowson</author>
</authors>
<title>The Language of Weblogs: A study ofgenre and individual differences.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Edinburgh.</institution>
<contexts>
<context position="4757" citStr="Nowson (2006)" startWordPosition="712" endWordPosition="713">personalities (Ball and Breese, 2000; Rist et al., 2003; Piwek and van Deemter, 2003; Gebhard, 2005). However, the linguistic behaviour is usually informed by rules based on personality stereotypes, rather than on language statistics themselves. On the other hand, in interpretation, more empirical work has recently been carried out, to enable text classification. Argamon et al. (2005) attempted to classify authors as High or Low Extravert and High or Low Neurotic, using Pennebaker and King’s (1999) data. They report classification accuracies of around 58% (with a 50% baseline). Oberlander and Nowson (2006) undertake a comparable task, using weblog data. They report classification accuracies of roughly 85% (Neuroticism) and 94% (Extraversion), and comparable figures for Agreeableness and Conscientiousness. Such studies can provide ordered lists of linguistic features which are useful for distinguishing language producers, and we will return to this, below. 2.2 Alignment and Language People converge with their interlocutors in linguistic choices at a number of levels (Pickering and Garrod, 2004). The phenomena can be seen in both social and cognitive terms. On the social side, co-operative proces</context>
<context position="10208" citStr="Nowson (2006)" startWordPosition="1597" endWordPosition="1598">trigram models with backoff to bigrams and unigrams. We have experimented with two strategies for creating personality models. Since we want to study the effects of alignment as well as personality, it is essential that the two characters in a dialogue be distinct from one another, so that the effects of alignment can be seen. The first strategy involves using typical language for each personality trait, and the second uses the language of one individual. In both cases, the language models described in the following sections are combined as described in Section 5.5. 5.1 Building a Personality Nowson (2006) performed a study on language use in weblogs. The weblog authors were asked to complete personality questionnaires based on the five-factor model (see Section 2.1). All weblog authors scored High or Medium on the Openness dimension, so we have no data for typical Low Open language. We divided the data into High, Medium and Low for each personality dimension, and trained language models so that we would be able to assess the probability of a word sequence given a personality type. This means that each individual weblog is used 5 times, once for each dimension. For each personality dimension, t</context>
</contexts>
<marker>Nowson, 2006</marker>
<rawString>Scott Nowson. 2006. The Language of Weblogs: A study ofgenre and individual differences. Ph.D. thesis, University of Edinburgh.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jon Oberlander</author>
<author>Scott Nowson</author>
</authors>
<title>Whose thumb is it anyway? Classifying author personality from weblog text.</title>
<date>2006</date>
<booktitle>In Proceedings of COLING/ACL06: 44th Annual Meeting of the Association for Computational Linguistics and 21st International Conference on Computational Linguistics,</booktitle>
<location>Sydney.</location>
<contexts>
<context position="4757" citStr="Oberlander and Nowson (2006)" startWordPosition="710" endWordPosition="713">ble linguistic personalities (Ball and Breese, 2000; Rist et al., 2003; Piwek and van Deemter, 2003; Gebhard, 2005). However, the linguistic behaviour is usually informed by rules based on personality stereotypes, rather than on language statistics themselves. On the other hand, in interpretation, more empirical work has recently been carried out, to enable text classification. Argamon et al. (2005) attempted to classify authors as High or Low Extravert and High or Low Neurotic, using Pennebaker and King’s (1999) data. They report classification accuracies of around 58% (with a 50% baseline). Oberlander and Nowson (2006) undertake a comparable task, using weblog data. They report classification accuracies of roughly 85% (Neuroticism) and 94% (Extraversion), and comparable figures for Agreeableness and Conscientiousness. Such studies can provide ordered lists of linguistic features which are useful for distinguishing language producers, and we will return to this, below. 2.2 Alignment and Language People converge with their interlocutors in linguistic choices at a number of levels (Pickering and Garrod, 2004). The phenomena can be seen in both social and cognitive terms. On the social side, co-operative proces</context>
</contexts>
<marker>Oberlander, Nowson, 2006</marker>
<rawString>Jon Oberlander and Scott Nowson. 2006. Whose thumb is it anyway? Classifying author personality from weblog text. In Proceedings of COLING/ACL06: 44th Annual Meeting of the Association for Computational Linguistics and 21st International Conference on Computational Linguistics, Sydney.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel S Paiva</author>
<author>Roger Evans</author>
</authors>
<title>A framework for stylistically controlled generation.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd International Conference on Natural Language Generation,</booktitle>
<pages>120--129</pages>
<contexts>
<context position="23397" citStr="Paiva and Evans (2004)" startWordPosition="3809" endWordPosition="3812"> by Bateman and Paris (2005), who discuss initial work on alignment, mediated by a process of register-recognition. Regarding generation with personality, the most influential work is probably Hovy’s PAULINE system, which varies both content selection and realisation according to an individual speaker’s goals and attitudes (Hovy, 1990). In her extremely useful survey of work on affective (particularly, emotional) natural language generation, Belz (2003) notes that the complexity of PAULINE’s rule system means that numerous rule interactions can lead to unpredictable side effects. In response, Paiva and Evans (2004) take a more empirical line on style generation, which is closer to that pursued here. Other relevant work includes Loyall and Bates (1997), who explicitly propose that personality and emotion could be used in generation, but Belz observes that technical descriptions of Hap and the Oz project suggest that the proposals were not implemented. Walker et al.’s (1997) system produces linguistic behaviour which is much more varied than our current sys30 tem is capable of; but there, variation is driven by a model of social relations (based on Brown and Levinson), rather than on personality. The NECA</context>
</contexts>
<marker>Paiva, Evans, 2004</marker>
<rawString>Daniel S. Paiva and Roger Evans. 2004. A framework for stylistically controlled generation. In Proceedings of the 3rd International Conference on Natural Language Generation, pages 120–129.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Laura King</author>
</authors>
<title>Linguistic styles: Language use as an individual difference.</title>
<date>1999</date>
<journal>Journal ofPersonality and Social Psychology,</journal>
<pages>77--1296</pages>
<contexts>
<context position="3794" citStr="Pennebaker and King, 1999" startWordPosition="570" endWordPosition="573">en on lexical choice, and Pennebaker and colleagues have analysed relative frequencies of use of word-stems in a dictionary structured into semantic and syntactic categories (Pennebaker et al., 2001). Amongst other results, they have shown that High Extraverts 25 Proceedings of the Fourth International Natural Language Generation Conference, pages 25–32, Sydney, July 2006. c�2006 Association for Computational Linguistics use: more social process talk, positive emotion words and inclusives; and fewer negations, tentative words, exclusives, causation words, negative emotion words, and articles (Pennebaker and King, 1999; Pennebaker et al., 2002). Computational linguistic exploitation of such empirically-derived features has been limited. On the one hand, in generation, there has been work on personality-based generation. For instance, in developing embodied conversational agents, researchers have designed agents or teams of agents with distinguishable linguistic personalities (Ball and Breese, 2000; Rist et al., 2003; Piwek and van Deemter, 2003; Gebhard, 2005). However, the linguistic behaviour is usually informed by rules based on personality stereotypes, rather than on language statistics themselves. On t</context>
</contexts>
<marker>Pennebaker, King, 1999</marker>
<rawString>James W. Pennebaker and Laura King. 1999. Linguistic styles: Language use as an individual difference. Journal ofPersonality and Social Psychology, 77:1296–1312.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Martha E Francis</author>
<author>Roger J Booth</author>
</authors>
<title>Linguistic Inquiry and Word Count 2001. Lawrence Erlbaum Associates,</title>
<date>2001</date>
<location>Mahwah, NJ.</location>
<contexts>
<context position="3368" citStr="Pennebaker et al., 2001" startWordPosition="512" endWordPosition="515">Current work on personality traits is dominated by Costa and McCrae’s five-factor model (Costa and McCrae, 1992). The five factors, or dimensions, are: Extraversion; Neuroticism; Openness; Agreeableness; and Conscientiousness (Matthews et al., 2003). It has been shown that scores on these dimensions correlate with some aspects of language use (Scherer, 1979; Dewaele and Furnham, 1999). In studies of text, the focus has been on lexical choice, and Pennebaker and colleagues have analysed relative frequencies of use of word-stems in a dictionary structured into semantic and syntactic categories (Pennebaker et al., 2001). Amongst other results, they have shown that High Extraverts 25 Proceedings of the Fourth International Natural Language Generation Conference, pages 25–32, Sydney, July 2006. c�2006 Association for Computational Linguistics use: more social process talk, positive emotion words and inclusives; and fewer negations, tentative words, exclusives, causation words, negative emotion words, and articles (Pennebaker and King, 1999; Pennebaker et al., 2002). Computational linguistic exploitation of such empirically-derived features has been limited. On the one hand, in generation, there has been work o</context>
</contexts>
<marker>Pennebaker, Francis, Booth, 2001</marker>
<rawString>James W. Pennebaker, Martha E. Francis, and Roger J. Booth. 2001. Linguistic Inquiry and Word Count 2001. Lawrence Erlbaum Associates, Mahwah, NJ.</rawString>
</citation>
<citation valid="true">
<authors>
<author>James W Pennebaker</author>
<author>Matthias R Mehl</author>
<author>Kate G Neiderhoffer</author>
</authors>
<title>Psychological aspects of natural language use: Our words, our selves. Annual Review of Psychology,</title>
<date>2002</date>
<pages>54--547</pages>
<contexts>
<context position="3820" citStr="Pennebaker et al., 2002" startWordPosition="574" endWordPosition="577">ennebaker and colleagues have analysed relative frequencies of use of word-stems in a dictionary structured into semantic and syntactic categories (Pennebaker et al., 2001). Amongst other results, they have shown that High Extraverts 25 Proceedings of the Fourth International Natural Language Generation Conference, pages 25–32, Sydney, July 2006. c�2006 Association for Computational Linguistics use: more social process talk, positive emotion words and inclusives; and fewer negations, tentative words, exclusives, causation words, negative emotion words, and articles (Pennebaker and King, 1999; Pennebaker et al., 2002). Computational linguistic exploitation of such empirically-derived features has been limited. On the one hand, in generation, there has been work on personality-based generation. For instance, in developing embodied conversational agents, researchers have designed agents or teams of agents with distinguishable linguistic personalities (Ball and Breese, 2000; Rist et al., 2003; Piwek and van Deemter, 2003; Gebhard, 2005). However, the linguistic behaviour is usually informed by rules based on personality stereotypes, rather than on language statistics themselves. On the other hand, in interpre</context>
</contexts>
<marker>Pennebaker, Mehl, Neiderhoffer, 2002</marker>
<rawString>James W. Pennebaker, Matthias R. Mehl, and Kate G. Neiderhoffer. 2002. Psychological aspects of natural language use: Our words, our selves. Annual Review of Psychology, 54:547–577.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin J Pickering</author>
<author>Holly P Branigan</author>
</authors>
<title>The representation of verbs: Evidence from syntactic priming in language production.</title>
<date>1998</date>
<journal>Journal of Memory and Language,</journal>
<volume>39</volume>
<issue>4</issue>
<contexts>
<context position="5955" citStr="Pickering and Branigan, 1998" startWordPosition="890" endWordPosition="893">ocial side, co-operative processes such as audience design are usually considered to be conscious, at least in part (Bell, 1984). But on the cognitive side, coordinative processes such as alignment are usually considered to be largely automatic (Garrod and Doherty, 1994). Alignment can be probed by psycholinguistic tests for interpersonal priming, establishing the extent to which participants are more likely to use a lexical item or syntactic construction after hearing their conversational partner use it. Syntactic priming experiments involve constructions such as passives, and ditransitives (Pickering and Branigan, 1998). It is possible that some people are stronger aligners than others. Gill et al. (2004) probed syntactic priming for passives, and investigated whether levels of Extraversion or Neuroticism would affect the strength of priming effects. It was found that Extraversion has no effect, but that Neuroticism has a non-linear effect: both High and Low levels of Neuroticism led to weaker priming; Mid levels led to significantly stronger priming. Given this, if a generation system is going to simulate alignment, it is probably worth designing it so that it can simulate agents with differing propensities</context>
</contexts>
<marker>Pickering, Branigan, 1998</marker>
<rawString>Martin J. Pickering and Holly P. Branigan. 1998. The representation of verbs: Evidence from syntactic priming in language production. Journal of Memory and Language, 39(4):633–651.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martin J Pickering</author>
<author>Simon Garrod</author>
</authors>
<title>Towards a mechanistic psychology of dialogue.</title>
<date>2004</date>
<booktitle>Behavioral and Brain Sciences,</booktitle>
<pages>27--169</pages>
<contexts>
<context position="1732" citStr="Pickering and Garrod, 2004" startWordPosition="259" endWordPosition="262">hat users’ responses to computer-agents are influenced by whether the agent’s linguistic personality matches—or mismatches—the personality of the user (Moon and Nass, 1996; Nass and Lee, 2000). Similarly, characters in virtual environments should be distinctive (Ball and Breese, 2000; Rist et al., 2003). But an aspect of personality is how well you adjust to other people (and their language use): alignment. Pickering and Garrod’s Interactive Alignment Model suggests that people tend to automatically converge on lexical and syntactic choices, via a low-level mechanism of interpersonal priming (Pickering and Garrod, 2004), and Brennan has shown that people will align their language towards that of computer agents (Brennan, 1996). But it is an open issue as to whether some people are better ‘aligners’ than others. Conversely, alignment is only visible and interesting (among computer agents) if they start out being individual. We therefore set out to simulate both individuality and alignment. The paper briefly surveys the evidence for linguistic personality, for interpersonal alignment, and for interaction between them. It then sketches the current version of CRAG. CRAG-2 makes use of OPENCCG and an over-generat</context>
<context position="5254" citStr="Pickering and Garrod, 2004" startWordPosition="782" endWordPosition="785">er and King’s (1999) data. They report classification accuracies of around 58% (with a 50% baseline). Oberlander and Nowson (2006) undertake a comparable task, using weblog data. They report classification accuracies of roughly 85% (Neuroticism) and 94% (Extraversion), and comparable figures for Agreeableness and Conscientiousness. Such studies can provide ordered lists of linguistic features which are useful for distinguishing language producers, and we will return to this, below. 2.2 Alignment and Language People converge with their interlocutors in linguistic choices at a number of levels (Pickering and Garrod, 2004). The phenomena can be seen in both social and cognitive terms. On the social side, co-operative processes such as audience design are usually considered to be conscious, at least in part (Bell, 1984). But on the cognitive side, coordinative processes such as alignment are usually considered to be largely automatic (Garrod and Doherty, 1994). Alignment can be probed by psycholinguistic tests for interpersonal priming, establishing the extent to which participants are more likely to use a lexical item or syntactic construction after hearing their conversational partner use it. Syntactic priming</context>
</contexts>
<marker>Pickering, Garrod, 2004</marker>
<rawString>Martin J. Pickering and Simon Garrod. 2004. Towards a mechanistic psychology of dialogue. Behavioral and Brain Sciences, 27:169–225.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Piwek</author>
<author>Kees van Deemter</author>
</authors>
<title>Dialogue as discourse: Controlling global properties of scripted dialogue.</title>
<date>2003</date>
<booktitle>In Proceedings of the AAAI Spring Symposium on Natural Language Generation in Spoken and Written Dialogue.</booktitle>
<marker>Piwek, van Deemter, 2003</marker>
<rawString>Paul Piwek and Kees van Deemter. 2003. Dialogue as discourse: Controlling global properties of scripted dialogue. In Proceedings of the AAAI Spring Symposium on Natural Language Generation in Spoken and Written Dialogue.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ehud Reiter</author>
<author>Somayajulu Sripada</author>
</authors>
<title>Contextual influences on near-synonym choice.</title>
<date>2004</date>
<booktitle>In Proceedings of the Third International Conference on Natural Language Generation,</booktitle>
<pages>161--170</pages>
<contexts>
<context position="25190" citStr="Reiter and Sripada, 2004" startWordPosition="4096" endWordPosition="4099">cally-derived relations between language and personality. It should be feasible in principle to move to a more sophisticated semantics, but still retain the massive overgeneration and ranking method. However, to support more perceptible variation, we need to exploit much larger personality-corpus resources than have been available up to now, and our current priority is to obtain a corpus at least an order of magnitude larger than what is currently available. This interest in individual differences and what corpora can (and cannot) tell us about them is one we share with Reiter and colleagues (Reiter and Sripada, 2004). We also plan to integrate techniques from CRAG-1 and CRAG-2, by passing the ranked output of CRAG-2 through further processing and ranking stages. Furthermore, we intend to investigate longer-ranging alignment processes, taking into account more than one previous utterance, with reduced weight by distance, to emulate memory effects. With these enhancements, we will take further steps towards our goal of simulating both individuality and alignment in believable computer agents. 10 Acknowledgements This research has been funded by Scottish Enterprise through the Edinburgh-Stanford Link project</context>
</contexts>
<marker>Reiter, Sripada, 2004</marker>
<rawString>Ehud Reiter and Somayajulu Sripada. 2004. Contextual influences on near-synonym choice. In Proceedings of the Third International Conference on Natural Language Generation, pages 161–170.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Rist</author>
<author>Elisabeth Andr´e</author>
<author>Stephan Baldes</author>
</authors>
<title>A flexible platform for building applications with life-like characters.</title>
<date>2003</date>
<booktitle>In IUI ’03: Proceedings of the 8th International Conference on Intelligent User Interfaces,</booktitle>
<pages>158--165</pages>
<publisher>ACM Press.</publisher>
<location>New York, NY, USA.</location>
<marker>Rist, Andr´e, Baldes, 2003</marker>
<rawString>Thomas Rist, Elisabeth Andr´e, and Stephan Baldes. 2003. A flexible platform for building applications with life-like characters. In IUI ’03: Proceedings of the 8th International Conference on Intelligent User Interfaces, pages 158–165, New York, NY, USA. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Klaus Scherer</author>
</authors>
<title>Personality markers in speech. In</title>
<date>1979</date>
<booktitle>Social Markers in Speech,</booktitle>
<pages>147--209</pages>
<editor>K. R. Scherer and H. Giles, editors,</editor>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="3103" citStr="Scherer, 1979" startWordPosition="472" endWordPosition="473">s, and briefly note promising results from user studies with the earlier CRAG-1 system, indicating how CRAG-2 will be further evaluated. Related work is discussed, along with possible directions for future work. 2 Background 2.1 Personality and Language Current work on personality traits is dominated by Costa and McCrae’s five-factor model (Costa and McCrae, 1992). The five factors, or dimensions, are: Extraversion; Neuroticism; Openness; Agreeableness; and Conscientiousness (Matthews et al., 2003). It has been shown that scores on these dimensions correlate with some aspects of language use (Scherer, 1979; Dewaele and Furnham, 1999). In studies of text, the focus has been on lexical choice, and Pennebaker and colleagues have analysed relative frequencies of use of word-stems in a dictionary structured into semantic and syntactic categories (Pennebaker et al., 2001). Amongst other results, they have shown that High Extraverts 25 Proceedings of the Fourth International Natural Language Generation Conference, pages 25–32, Sydney, July 2006. c�2006 Association for Computational Linguistics use: more social process talk, positive emotion words and inclusives; and fewer negations, tentative words, e</context>
</contexts>
<marker>Scherer, 1979</marker>
<rawString>Klaus Scherer. 1979. Personality markers in speech. In K. R. Scherer and H. Giles, editors, Social Markers in Speech, pages 147–209. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
<author>Harry Bratt</author>
<author>John Butzberger</author>
<author>Horacio Franco</author>
</authors>
<title>Venkata Ramana Rao Gadde, Madelaine Plauch´e, Colleen Richey, Elizabeth Shriberg, Kemal S¨onmez, Fuliang Weng, and Jing Zheng.</title>
<date>2000</date>
<booktitle>The SRI</booktitle>
<location>College Park, MD.</location>
<contexts>
<context position="11725" citStr="Stolcke et al., 2000" startWordPosition="1862" endWordPosition="1866">ven a low Openness score, since we do not have a model for this personality type, we simply interpolate the other four models. 5.2 Borrowing a Personality Our second strategy was to train n-gram models on language of the individuals from the CRAG-1 corpus (Isard et al., 2005) and to use one of these models for each character in the dialogue. 5.3 Base Language Model In the case of building a personality, a base language model is obtained by combining a language model computed from the corpus collected for the CRAG-1 system and a general language model based on data from the Switchboard corpus (Stolcke et al., 2000). The combined base model alone would rank the utterances without any bias for personality or alignment. When we are borrowing a personality, the base model is calculated from the Switchboard corpus alone. i−1 1/n P(wi |wi−2) n ∏ i=1 27 5.4 Cache Language Model We simulate alignment by computing a cache language model based on the utterance that was generated immediately before. This dialogue history cache model is the uniform interpolation of wordand class-based n-gram models, where classes act as a backoff mechanism when there is no exact word match. Classes group together lexical items with</context>
</contexts>
<marker>Stolcke, Bratt, Butzberger, Franco, 2000</marker>
<rawString>Andreas Stolcke, Harry Bratt, John Butzberger, Horacio Franco, Venkata Ramana Rao Gadde, Madelaine Plauch´e, Colleen Richey, Elizabeth Shriberg, Kemal S¨onmez, Fuliang Weng, and Jing Zheng. 2000. The SRI March 2000 Hub-5 conversational speech transcription system. In Proceedings of the 2000 Speech Transcription Workshop, College Park, MD.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Andreas Stolcke</author>
</authors>
<title>SRILM – an extensible language modeling toolkit.</title>
<date>2002</date>
<booktitle>In Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP-02),</booktitle>
<pages>901--904</pages>
<location>Denver, CO.</location>
<contexts>
<context position="9484" citStr="Stolcke, 2002" startWordPosition="1472" endWordPosition="1473">1 = 0.9 and X2 = 0.1 assigns a high weight to the first language model. 4.4 OPENCCG N-Gram Ranking In the OPENCCG framework, language models can be used to influence the chart-based realisation process. The agenda of edges is re-sorted according to the score an edge receives with respect to a language model. For CRAG-2, many paraphrases are generated from a given logical form, and they are then ranked in order of probability according to the combination of n-gram models appropriate for the character and stage of the dialogue. 5 CRAG-2 Personality and Alignment Models We use the SRILM toolkit (Stolcke, 2002) to compute our language models. All models (except for the cache language model described in Section 5.4) are trigram models with backoff to bigrams and unigrams. We have experimented with two strategies for creating personality models. Since we want to study the effects of alignment as well as personality, it is essential that the two characters in a dialogue be distinct from one another, so that the effects of alignment can be seen. The first strategy involves using typical language for each personality trait, and the second uses the language of one individual. In both cases, the language m</context>
</contexts>
<marker>Stolcke, 2002</marker>
<rawString>Andreas Stolcke. 2002. SRILM – an extensible language modeling toolkit. In Proceedings of the 7th International Conference on Spoken Language Processing (ICSLP-02), pages 901–904, Denver, CO.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sebastian Varges</author>
</authors>
<title>Spatial descriptions as referring expressions in the MapTask domain.</title>
<date>2005</date>
<booktitle>In Proceedings of the 10th European Workshop on Natural Language Generation.</booktitle>
<contexts>
<context position="22500" citStr="Varges (2005)" startWordPosition="3678" endWordPosition="3679">guage. Also, the personality setting of a character influenced the perception of its and its dialogue partner’s personality (Kahn, 2006). We plan a similar evaluation for CRAG-2 to be able to compare human raters’ impressions of dialogues generated by the two systems. We also plan to evaluate CRAG-2 internally by varying the weight given to the underlying language models, and observing the effects this has on the resulting ranking of the generated utterances. 8 Related Work Related work in NLG involves either personality or alignment. So far as we can tell, there is little work on the latter. Varges (2005) suggests that “a word similarity-based ranker could align the generation output (i.e. the highest-ranked candidate) with previous utterances in the discourse context”, but there is no report yet on an implementation of this proposal. A rather different approach is suggested by Bateman and Paris (2005), who discuss initial work on alignment, mediated by a process of register-recognition. Regarding generation with personality, the most influential work is probably Hovy’s PAULINE system, which varies both content selection and realisation according to an individual speaker’s goals and attitudes </context>
</contexts>
<marker>Varges, 2005</marker>
<rawString>Sebastian Varges. 2005. Spatial descriptions as referring expressions in the MapTask domain. In Proceedings of the 10th European Workshop on Natural Language Generation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marilyn A Walker</author>
<author>Janet E Cahn</author>
<author>Steve J Whittaker</author>
</authors>
<title>Improvising linguistic style: Social and affective bases for agent personality.</title>
<date>1997</date>
<booktitle>Proceedings of the 1st International Conference on Autonomous Agents (Agents’97),</booktitle>
<pages>96--105</pages>
<editor>In J. Lewis and B. Hayes-Roth, editors,</editor>
<publisher>ACM Press.</publisher>
<marker>Walker, Cahn, Whittaker, 1997</marker>
<rawString>Marilyn A. Walker, Janet E. Cahn, and Steve J. Whittaker. 1997. Improvising linguistic style: Social and affective bases for agent personality. In J. Lewis and B. Hayes-Roth, editors, Proceedings of the 1st International Conference on Autonomous Agents (Agents’97), pages 96–105. ACM Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>Reining in CCG Chart Realization.</title>
<date>2004</date>
<booktitle>In Proceedings of the 3rd International Conference on Natural Language Generation,</booktitle>
<pages>182--191</pages>
<contexts>
<context position="6888" citStr="White, 2004" startWordPosition="1044" endWordPosition="1045">fect: both High and Low levels of Neuroticism led to weaker priming; Mid levels led to significantly stronger priming. Given this, if a generation system is going to simulate alignment, it is probably worth designing it so that it can simulate agents with differing propensities to align. 3 The CRAG System Overview The system described in the following sections (CRAG-2) is the successor to CRAG-1 which is detailed in Isard et al. (2005). The system generates a dialogue between two computer agents on the subject of opinions about a film. CRAG-2 uses the OPENCCG parsing and generation framework (White, 2004; White, 2006). The realiser component takes a logical form as input and outputs a list of candidate sentences ranked using one or more language models. In CRAG-2, we use the OPENCCG generator to massively over-generate paraphrases, and the combination of n-gram models described in Section 4 to choose the best utterance according to a character’s personality and agenda, and the dialogue history. 4 N-Grams: Personality and Alignment Modelling 4.1 N-Gram Language Models The basic assumption underlying CRAG-2 is that personality, as well as alignment behaviour, can be modelled by the combination </context>
<context position="14474" citStr="White (2004)" startWordPosition="2304" endWordPosition="2305">ple XML representation of the character’s utterance, using the specified topic and polarity. An example using the topic music and polarity negative is shown in Figure 1. At this point the system also decides which discourse connectives may be appropriate, based on the previous topic and polarity. &lt;utterance&gt; &lt;utt topic=&amp;quot;music&amp;quot; polarity=&amp;quot;dislike&amp;quot; opp-polarity=&amp;quot;like&amp;quot; so=&amp;quot;no&amp;quot; right=&amp;quot;no&amp;quot; also=&amp;quot;no&amp;quot; well=&amp;quot;yes&amp;quot; and=&amp;quot;no&amp;quot; but=&amp;quot;no&amp;quot;&gt; &lt;pred adj=&amp;quot;bad&amp;quot;/&gt; &lt;opp-pred adj=&amp;quot;good&amp;quot;/&gt; &lt;/utt&gt; &lt;/utterance&gt; Figure 1: Simple Utterance Specification 6.3 OPENCCG Logical Forms Following the method described in Foster and White (2004), the basic utterance specification is transformed, using stylesheets written in the XSL transformation language, into an OPENCCG logical form. We make use of the facility for defining optional and alternative inputs and underspecified semantics to massively over-generate candidate utterances. A fragment of the logical form which results from the transformation of Figure 1 is shown in Figure 2. We also include some fragments of canned text from the CRAG corpus in our OPENCCG lexicon. We also add optional interjections (i mean, you know, sort of) and conversational markers (right, but, and, wel</context>
</contexts>
<marker>White, 2004</marker>
<rawString>Michael White. 2004. Reining in CCG Chart Realization. In Proceedings of the 3rd International Conference on Natural Language Generation, pages 182–191.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael White</author>
</authors>
<title>Efficient Realization of Coordinate Structures</title>
<date>2006</date>
<booktitle>in Combinatory Categorial Grammar. Research on Language &amp; Computation, online first,</booktitle>
<contexts>
<context position="6902" citStr="White, 2006" startWordPosition="1046" endWordPosition="1047">gh and Low levels of Neuroticism led to weaker priming; Mid levels led to significantly stronger priming. Given this, if a generation system is going to simulate alignment, it is probably worth designing it so that it can simulate agents with differing propensities to align. 3 The CRAG System Overview The system described in the following sections (CRAG-2) is the successor to CRAG-1 which is detailed in Isard et al. (2005). The system generates a dialogue between two computer agents on the subject of opinions about a film. CRAG-2 uses the OPENCCG parsing and generation framework (White, 2004; White, 2006). The realiser component takes a logical form as input and outputs a list of candidate sentences ranked using one or more language models. In CRAG-2, we use the OPENCCG generator to massively over-generate paraphrases, and the combination of n-gram models described in Section 4 to choose the best utterance according to a character’s personality and agenda, and the dialogue history. 4 N-Grams: Personality and Alignment Modelling 4.1 N-Gram Language Models The basic assumption underlying CRAG-2 is that personality, as well as alignment behaviour, can be modelled by the combination of a variety o</context>
</contexts>
<marker>White, 2006</marker>
<rawString>Michael White. 2006. Efficient Realization of Coordinate Structures in Combinatory Categorial Grammar. Research on Language &amp; Computation, online first, March.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>