<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000008">
<title confidence="0.974807">
Improvements in unsupervised co-occurrence based parsing
</title>
<author confidence="0.81833">
Christian H¨anig
</author>
<note confidence="0.805633666666667">
Daimler AG
Research and Technology
89081 Ulm, Germany
</note>
<email confidence="0.99728">
christian.haenig@daimler.com
</email>
<sectionHeader confidence="0.993872" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999839588235294">
This paper presents an algorithm for unsu-
pervised co-occurrence based parsing that
improves and extends existing approaches.
The proposed algorithm induces a context-
free grammar of the language in question
in an iterative manner. The resulting struc-
ture of a sentence will be given as a hier-
archical arrangement of constituents. Al-
though this algorithm does not use any a
priori knowledge about the language, it
is able to detect heads, modifiers and a
phrase type’s different compound compo-
sition possibilities. For evaluation pur-
poses, the algorithm is applied to manually
annotated part-of-speech tags (POS tags)
as well as to word classes induced by an
unsupervised part-of-speech tagger.
</bodyText>
<sectionHeader confidence="0.998994" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999952926829268">
With the growing amount of textual data available
in the Internet, unsupervised methods for natural
language processing gain a considerable amount
of interest. Due to the very special usage of lan-
guage, supervised methods trained on high quality
corpora (e. g. containing newspaper texts) do not
achieve comparable accuracy when being applied
to data from fora or blogs. Huge annotated corpora
consisting of sentences extracted from the Internet
barely exist until now.
Consequential a lot of effort has been put into
unsupervised grammar induction during the last
years and results and performance of unsuper-
vised parsers improved steadily. Klein and Man-
ning (2002)’s constituent context model (CCM)
obtains 51.2% f-score on ATIS part-of-speech
strings. The same model achieves 71.1% on Wall
Street Journal corpus sentences with length of
at most 10 POS tags. In (Klein and Manning,
2004) an approach combining constituency and
dependency models yields 77.6% f-score. Bod
(2006)’s all-subtree approach — known as Data-
Oriented Parsing (DOP) — reports 82.9% for
UML-DOP. Seginer (2007)’s common cover links
model (CCL) does not need any prior tagging and
is applied on word strings directly. The f-score
for English is 75.9%, and for German (NEGRA10)
59% is achieved. H¨anig et al. (2008) present a co-
occurrence based constituent detection algorithm
which is applied to word forms, too (unsupervised
POS tags are induced using unsuPOS, see (Bie-
mann, 2006)). An f-score of 63.4% is reported for
German data.
In this paper, we want to present a new unsu-
pervised co-occurrence based grammar induction
model based on H¨anig et al. (2008). In the fol-
lowing section, we give a short introduction to the
base algorithm unsuParse. Afterwards, we present
improvements to this algorithm. In the final sec-
tion, we evaluate the proposed model against ex-
isting ones and discuss the results.
</bodyText>
<sectionHeader confidence="0.833564" genericHeader="method">
2 Co-occurrence based parsing
</sectionHeader>
<bodyText confidence="0.999738">
It has been shown in (H¨anig et al., 2008) that
statistical methods like calculating significant co-
occurrences and context clustering are applicable
to grammar induction from raw text. The underly-
ing assumption states that each word prefers a cer-
tain position within a phrase. Two particular cases
are of special interest: a word’s occurrence at the
beginning of a sentence and a word’s occurrence at
the end of a sentence. Those positions obviously
are constituent borders and can be easily used to
extract syntactic knowledge. One possibility is to
discover constituents employing constituency tests
(see (Adger, 2003)), whereby these two cases can
be used to express and use one of them in a formal
way: the movement test.
Three neighbourhood co-occurrences express
the aforementioned observations:
</bodyText>
<page confidence="0.822142">
1
</page>
<note confidence="0.942538">
Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 1–8,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
</note>
<listItem confidence="0.92235">
• Value a denotes the significance of word A
standing at the last position of a sentence
(where $ is an imaginary word to mark a sen-
tences’ end).
a = sig (A, $) (1)
• Contrary, variable b denotes the significance
of a word B being observed at the beginning
of a sentence (where ^ is an imaginary word
to mark the beginning of a sentence).
b = sig (^, B) (2)
• Additionally, a third value is necessary to rep-
resent the statistical significance of the neigh-
bourhood co-occurrence containing word A
and B.
</listItem>
<equation confidence="0.915784">
c = sig (A, B) (3)
</equation>
<bodyText confidence="0.977610181818182">
To compute those significance values for a corpus,
the log-likelihood measure (see (Dunning, 1993))
is applied using corpus size n, term frequencies
nA and nB (for the words A and B) and frequency
nAB of the co-occurrence of A and B.
To detect constituent borders between two
words, a separation value sepAB can be defined
as:
If word A occurs more significantly at the end of
a sentence as in front of B, then a &gt; 1. Addi-
tionally, b is larger than c if B is observed more
significantly at the beginning of a sentence as af-
ter A and b
c
&gt; 1 and obviously, a constituent border would be
situated between A and B.
The basic approach to create parse trees from
separation values between two adjacent words is
to consecutively merge the two subtrees contain-
ing the words with the smallest separation value
between them — starting with each word in a sep-
arate subtree. In order to avoid data sparseness
problems, co-occurrences and separation values
are primarily calculated on part-of-speech tags.
However, word co-occurrences will be used to pre-
serve word form specific dependencies.
In this paper, we want to present unsuParse+
— an extension of this co-occurrence based ap-
proach. The first extension is the distinction be-
tween endocentric and exocentric elements which
introduces the detection of heads along with their
modifiers (see section 2.2). Furthermore, learning
of recursive constructions is facilitated. Secondly,
we will consider discontiguous dependencies and
present a possibility to detect rare constructions
like complex noun phrases (see section 2.3). As
third enhancement, we employ a simple cluster-
ing algorithm to induced phrases in order to detect
constituents holding identical syntactic functions.
Those phrases will be labeled the same way in-
stead of by different phrase numbers (see section
2.4).
First, we will start with the detection of con-
stituent candidates.
</bodyText>
<subsectionHeader confidence="0.999155">
2.1 Detection of constituent borders
</subsectionHeader>
<bodyText confidence="0.999912095238095">
Instead of using sepAB to detect constituent bor-
ders we use neighbourhood co-occurrence signif-
icances on account of an experiment in (H¨anig et
al., 2008) showing that the pure significance value
c is sufficient.
Furthermore, we do not restrict the detection
of phrases to bigrams and allow the detection of
arbitrary n-grams. The motivation behind this is
basically caused by coordinating conjunctions for
which discussions on the correct1 structure are
raised. While Chomsky (1965) argues in favor of
symmetric multiple-branching coordinating con-
structions (see Figure 1), recent discussions in the
context of unification grammars (especially head-
driven phrase structure grammar (see (Pollard and
Sag, 1994)) prefer asymmetric endocentric con-
structions (see (Kayne, 1995) and (Sag, 2002)).
The corresponding structure can be seen in Figure
2. Nevertheless, a symmetric construction con-
taining two heads seems to be more appropriate for
some languages (e. g. German, see (Lang, 2002)).
</bodyText>
<equation confidence="0.360602">
ConJ
NNS Conj’
</equation>
<footnote confidence="0.723299833333333">
cats CC NNS
and dogs
Figure 2: Asymmetric
coordinating conjunc-
tion
1correct meaning considered to be correct
</footnote>
<figure confidence="0.960974111111111">
sepAB =
(4)
c c c2
a b a · b
· =
will be &gt; 1. In this case sepAB is
NP
NNS CC NNS
cats and dogs
</figure>
<figureCaption confidence="0.950028">
Figure 1: Symmetric
coordinating conjunc-
tion
</figureCaption>
<page confidence="0.956293">
2
</page>
<bodyText confidence="0.99996225">
Thus, the presented algorithm is able to deal
with phrases containing any number of com-
pounds.
As in (H¨anig et al., 2008), phrases will be
learned in an iterative manner (see details in sec-
tion 2.5). Within each iteration, the n-gram P
yielding the highest significance is considered to
be the best candidate for being a valid constituent.
</bodyText>
<equation confidence="0.999746">
P = [p0 ... pn−11 (5)
</equation>
<bodyText confidence="0.9998875">
The preferred position of part-of-speech tags is
maintained as we define pref (A) for every POS
tag A. This value is initialized as the ratio of two
particular significances as in Equ. 6:
</bodyText>
<equation confidence="0.980103">
sig (�, A)
pref (A) = (6)
sig (A, $)
</equation>
<bodyText confidence="0.999840869565218">
Analogous to sepAB (see section 2) pref (A) is
&gt; 1 if POS tag A prefers the first position within
a phrase and vice versa.
Before a phrase candidate is used to create a
new grammar rule, its validity has to be checked.
Using the assumption that every word prefers a
certain position within a constituent leads us to
check the first word of a phrase candidate for pre-
ferring the first position and the last word for fa-
voring the last one.
But there are at least two exceptions: coordi-
nating conjunctions and compound nouns. Those
constructions (e. g. cats/NNS and/CC dogs/NNS,
dog/NN house/NN) usually start and end with the
same phrase respectively POS tag. This would
lead to wrong validation results, because NNS
or NN do prefer the last position within a con-
stituent and should not occur at the beginning. As
both constructions are endocentric, they prefer the
head’s position within the superordinating phrase
and thus, their existence does not stand in contrast
to the assumption made about preferred positions.
Formally, we get the following proposition:
</bodyText>
<equation confidence="0.9748195">
valid (P) q p0 = pn−1 V
pref (p0) &gt; ϕ n pref (pn−1) &lt;
</equation>
<bodyText confidence="0.9511242">
An uncertainty factor is introduced by ϕ, as some
parts-of-speech tend to not appear at the borders
of a sentence although they prefer a certain posi-
tion within constituents. Some examples (given in
Table 1) of the 5 most frequent English2 and Ger-
</bodyText>
<footnote confidence="0.689461">
2Penn Tree Tagset, see (Marcus et al., 1993)
</footnote>
<table confidence="0.975706857142857">
man3 parts-of-speech will demonstrate this effect.
English German
NN 0.08 NN 0.30
IN 31.45 ART 242.48
NNP 1.39 APPR 143.62
DT 84.19 ADJA 5.06
NNS 0.31 NE 1.11
</table>
<tableCaption confidence="0.8920165">
Table 1: Values of pref (POS) for the 5 most fre-
quent parts-of-speech of English and German
</tableCaption>
<bodyText confidence="0.999820714285714">
In both languages proper nouns (NNP resp. NE)
occur slightly more often at the beginning of a sen-
tence than at its end, although proper nouns pre-
fer — like normal nouns — the last position of a
phrase. To account for this effect, pref (A) will be
iteratively adapted to the observations of learned
grammar rules as given in Equ. 8:
</bodyText>
<equation confidence="0.982764666666667">
1 (8)
pref (p0) — δ pref (p0)
pref (pn−1) — δ pref (pn−1)
</equation>
<bodyText confidence="0.999872346153846">
Due to iterative learning of rules, we can use
knowledge obtained during a previous itera-
tion. Every rule contains reinforcing information
about the preferred position of a part-of-speech.
pref (A) is adapted by a factor δ (with 0 &lt; δ &lt; 1)
for the corresponding parts-of-speech and it will
converge to its preferred position.
In later iterations, significances of phrase can-
didates do not differ considerably from each other
and thus, the order of phrase candidates is not very
reliable anymore. Consequently, parts-of-speech
occur at non-preferred positions more often and
trustworthy knowledge (in form of pref (A))
about the preferred positions of parts-of-speech is
very helpful to avoid those phrase candidates from
being validated.
We want to give one example for English: ad-
jectives (JJ). Before the first iteration, pref (JJ)
is initialized with 1.046 which means that JJ has
no preferred position. The most significant rules
containing JJ are JJ NN, JJ NNS and JJ NNP
— supporting a preference of the first position
within a constituent. An iterative adaption of
pref (JJ) will represent this observation and dis-
approve constituents ending with JJ (like DT JJ or
INJJ) in upcoming iterations.
</bodyText>
<footnote confidence="0.523371">
3Stuttgart-T¨ubingen Tagset, see (Thielen et al., 1999)
</footnote>
<equation confidence="0.67398">
1 (7)
ϕ
</equation>
<page confidence="0.96385">
3
</page>
<bodyText confidence="0.99991375">
After having detected a new and valid con-
stituent, we can use context similarity and other
statistical methods to learn more about its be-
haviour and inner construction.
</bodyText>
<subsectionHeader confidence="0.9368385">
2.2 Classification into endocentric and
exocentric constructions
</subsectionHeader>
<bodyText confidence="0.999906545454545">
Endocentric constructions contain a head — or
more than one in symmetric coordinate construc-
tions — which is syntactically identical to the en-
docentric compound. Additionally, at least one
optional element subordinating to the head is con-
tained in the construction. An exocentric con-
struction on the other hand does not contain any
head element which is syntactically identical to the
whole construction.
The following example sentences will demon-
strate the distinction of these two types. Sentence
</bodyText>
<listItem confidence="0.889603090909091">
(a) contains a determiner phrase (DP: a new car)
which has a noun phrase embedded (NP: new car).
The NP can be replaced by its head as in sentence
(b) and thus is regarded to be endocentric. The DP
is exocentric — it can neither be replaced by the
determiner (sentence (c)) nor by the NP (sentence
(d)) without losing its syntactical correctness.
(a) I buy a new car.
(b) I buy a car.
(c) * I buy a.
(d) * I buy new car.
</listItem>
<bodyText confidence="0.9986655">
Detection of endocentric constructions yields
valuable information about the language in ques-
tion. It is possible to detect heads along with their
modifiers without any a priori knowledge. Fur-
thermore, detection of optional modifiers reduces
the complexity of sentences and thus, facilitates
learning of high precision rules.
Without classification into endocentric and exo-
centric constructions, two rules (P#1 JJ NN
and P#2 JJ P#1 would be necessary to
parse the phrase first civil settlement as given in
Figure 3. Using knowledge about subordinating
elements achieves the same result (see Figure 4)
with one rule (NN JJ NN). Addition-
ally, data-sparseness problems are circumvented
as no rare occurrences like JJ ... JJ NN need
to be contained in the training corpus to eventu-
ally parse those phrases.
Following the definition of endocentricity, a
phrase containing a head and an optional element
</bodyText>
<figure confidence="0.77290275">
P#2
JJ P#1
first JJ NN
civil settlement
</figure>
<figureCaption confidence="0.970747">
Figure 3: Structure
without knowledge
about endocentricity
</figureCaption>
<bodyText confidence="0.9970126">
should be equally distributed — in respect to its
context – as the head. Consequentially, a phrase
is considered to be endocentric, if it contains an
element showing high context similarity (see Equ.
9).
</bodyText>
<equation confidence="0.997955">
endocentric (P) q
(9)
9i : sim (context (P) , context (pi)) ~ V
</equation>
<bodyText confidence="0.9996956">
The global context context (P) of a phrase or
POS tag P is the sum of all local contexts of P
within the training corpus. We use the two left
and right neighbours including the aforementioned
markers for the beginning and the end of a sen-
tence if necessary. We apply the Cosine Measure
to calculate the similarity between the two con-
texts and in case of passing a defined threshold V,
the phrase is considered to be endocentric. See Ta-
ble 2 for some examples (V = 0.9).
</bodyText>
<equation confidence="0.5225426">
NNS JJ NNS
NN JJ NN
NNP NNP CC NNP
NN NN CC NN
VBZ RB VBZ
</equation>
<tableCaption confidence="0.984903">
Table 2: Examples of endocentric constructions
</tableCaption>
<subsectionHeader confidence="0.993621">
2.3 Discontiguous dependencies
</subsectionHeader>
<bodyText confidence="0.99978175">
Additionally to endocentric constructions contain-
ing a head and a modifier, some parts-of-speech
like articles and possessive pronouns do not occur
without a noun or noun phrase. While those parts-
of-speech are grouped together as determiners
(DT) in the Penn Tree Tagset, for other tagsets and
languages they might be distributed among multi-
ple classes (as in the German Stuttgart–T¨ubingen
</bodyText>
<figureCaption confidence="0.995632">
Figure 4: Structure
</figureCaption>
<figure confidence="0.993278833333333">
using knowledge
about endocentricity
NN
JJ NN
first JJ NN
civil settlement
</figure>
<page confidence="0.984613">
4
</page>
<bodyText confidence="0.991064117647059">
Tagset among ART, PPOSAT, PIAT ...). To de-
tect such strong dependencies, we propose a sim-
ple test measuring the relative score of observing
two words A and B together within a maximum
range n.
�n d=0 freq (A, B, d)
depn (A, B) = min (freq (A) , freq (B))
(10)
Equ. 10 formally describes the relative score
where freq (A, B, d) denotes the frequency of A
and B occurring together with exactly d other
tokens between them. If depn (A, B) passes a
threshold ϑ (0.9 for our experiments), then the
dependency between A and B is allowed to oc-
cur discontiguously. Including these dependen-
cies facilitates the parsing of rare and insignificant
phrases like adjectival phrases.
</bodyText>
<figure confidence="0.984149">
NP
ART AP NN
Der mit zwei Festplatten Computer
ausgestattete
The with two disks computer
equipped
</figure>
<figureCaption confidence="0.999982">
Figure 5: Adjectival Phrase
</figureCaption>
<bodyText confidence="0.999981764705882">
In the example given in Figure 5, the discon-
tiguous dependency between articles (ART) and
normal nouns (NN) can be applied to two possi-
ble word pairs. On the one hand, there is Der ...
Festplatten (The ... disks), the other possibility is
Der ... Computer (The ... computer). We choose
the pair achieving the highest neighbourhood co-
occurrence significance. Regarding our example,
it is quite obvious that Computer is the noun to
choose as Der and Computer show grammatical
agreement while this is not the case for Festplat-
ten. Consequently, the significance of Der Com-
puter is much higher than the one of Der Festplat-
ten. Although articles and other parts-of-speech
are not unambiguous regarding gender, number
and case for all languages, this approach can re-
solve some of those cases for certain languages.
</bodyText>
<subsectionHeader confidence="0.99005">
2.4 Phrase Clustering
</subsectionHeader>
<bodyText confidence="0.99997575">
One objection to unsupervised parsing is the fact
that phrases belonging to the same phrase type are
not labeled the same way. And of course, without
any prior knowledge, induced phrases will never
be labeled NP, PP or like any other known phrase
type. This complicates the application of any fur-
ther algorithms relying on that knowledge. Never-
theless, it is possible to cluster syntactic identical
phrases into one class.
As in section 2.2, similarity between two global
contexts is calculated. If the similarity of phrase P
(the one being tested) and Q (see most similar one,
see Equ. 11) exceeds a threshold ϑ, then phrase P
is considered to have the same phrase type as Q
(see Equ. 12). In this case, P will be labeled by
the label of Q and thus, is treated like Q.
</bodyText>
<equation confidence="0.99821625">
Q = arg max sim (context (P) , context (q))
q E phrases
(11)
Type (P) = Type (Q) , sim (P, Q) ~ ϑ (12)
</equation>
<bodyText confidence="0.9999505">
As it can be seen in Table 3 (ϑ = 0.9), cluster-
ing finds syntactic similar phrases and facilitates
iterative learning as rules can be learned for each
phrase type and not for each composition.
</bodyText>
<equation confidence="0.835839833333333">
P#1 DT JJ NN
P#1 DT NN
P#1 PRP$ NNS
P#2 IN P#1
P#2 IN NN
P#2 IN NNS
</equation>
<tableCaption confidence="0.99816">
Table 3: Results of phrase clustering
</tableCaption>
<subsectionHeader confidence="0.978709">
2.5 Iterative learning
</subsectionHeader>
<bodyText confidence="0.999179705882353">
Learning rules is realized as an iterative process.
A flow chart of the proposed process is given in
Figure 6.
First, an empty parser model is initialized. At
the beginning of an iteration all rules are applied
to transform the corpus. Resulting structures form
the data which is used for the next iteration. The
sentence in Figure 7 will be transformed by al-
ready induced rules.
After application of rule NN JJ NN, the
optional element JJ is removed (see Fig. 8).
The next rule (P#1 DT NN) reduces the
complexity of the sentence and from now on, fur-
ther rules will be created on those parts-of-speech
and phrases (see Fig. 9).
Learning will be aborted after one of the follow-
ing three conditions becomes true:
</bodyText>
<page confidence="0.935632">
5
</page>
<figure confidence="0.868024">
Initialization
</figure>
<figureCaption confidence="0.7690005">
Figure 6: Flow chart
of the proposed learning process
</figureCaption>
<listItem confidence="0.991533285714286">
1. The algorithm reaches the maximum number
of rules.
2. The last phrase candidate is not considered to
be significant enough. A threshold in relation
to the highest significance can be set up.
3. All sentences contained in the training corpus
are reduced to one phrase.
</listItem>
<bodyText confidence="0.99814">
Afterwards, the most significant n-gram passing
the validity test will be regarded as a phrase. In the
following steps, the label of the new phrase will be
determined. Either it is labeled by its head (in case
of an endocentric construction) or by a syntactic
identical phrase type that has been learned before.
If neither is the case, it gets a new unique label.
Afterwards, the next iteration is triggered.
</bodyText>
<figure confidence="0.835769333333333">
S
DT JJ NN VBZ $ CD
The minimum unit is $ 100
</figure>
<figureCaption confidence="0.985296">
Figure 7: Example
</figureCaption>
<figure confidence="0.986553333333333">
S
DT NN VBZ $ CD
The is $ 100
</figure>
<figureCaption confidence="0.997899">
Figure 8: Example after application of rule
</figureCaption>
<equation confidence="0.9428605">
NN +– JJ NN
S
P#1 VBZ $ CD
is $ 100
</equation>
<figureCaption confidence="0.989331">
Figure 9: Example after additional application of
rule P#1 +– DT NN
</figureCaption>
<sectionHeader confidence="0.994699" genericHeader="evaluation">
3 Evaluation
</sectionHeader>
<bodyText confidence="0.999965142857143">
To evaluate unsuParse+ against unsuParse and
other unsupervised parsing algorithms, we apply
the same experimental setup as in (Klein, 2005),
(Bod, 2006) and (H¨anig et al., 2008). For German
punctuation and empty element tags are removed
from the NEGRA corpus (see (Skut et al., 1998)).
Afterwards, all sentences containing more than 10
elements are dismissed. The resulting corpus is re-
ferred to as NEGRA10 (2175 sentences). To take
more complex sentences into account, we also pre-
pared a corpus containing sentences to a maximum
length of 40 elements (NEGRA40).
We present results for both — POS tags and
word strings. As most unsupervised parsing mod-
els (except (Seginer, 2007)), we apply the hand-
annotated data of the NEGRA corpus. Addition-
ally, we used an unsupervised part-of-speech tag-
ger (see (Biemann, 2006)) to tag the NEGRA cor-
pus to be able to present a complete unsupervised
parsing process relying on word strings only. We
applied the model de40M which has been created
</bodyText>
<figure confidence="0.992199423076923">
Begin
Application of induced rules
No
No
Yes
No
Discontinuity test
Yes
No
Create a rule
labeled by a new unique label
Detection of
new phrase candidate
Valid?
Yes
Endocentric?
Similar to
existing
phrase type?
Abort Yes End
learning?
Create a rule
labeled by
existing phrase type
Create a rule
labeled by its head
</figure>
<page confidence="0.981434">
6
</page>
<bodyText confidence="0.99975375">
on a corpus containing 40 million sentences and
contains 510 word classes.
To compare the performance of different pars-
ing algorithms, we used the Unlabeled Brackets
Measure as in (Klein and Manning, 2002) and
(Klein and Manning, 2004). Additionally to un-
labeled precision UP and unlabeled recall UR, the
unlabeled f-score UF is defined as:
</bodyText>
<equation confidence="0.999268">
2 · UP · UR (13 )
UF = UP + UR
</equation>
<bodyText confidence="0.999506916666667">
The baseline algorithm is based on neighbour-
hood co-occurrences. First, a parse tree is ini-
tialized and all tokens of a sentence are added as
leaves. Afterwards, the two adjacent nodes con-
taining the POS tags with the highest neighbour-
hood co-occurrence significance are merged con-
secutively until a binary tree has been created.
Results for NEGRA10 are given in Table 4. un-
suParse+ improves the performance of unsuParse
in both categories: supervised and unsupervised
annotated POS tags. While recall is improved sig-
nificantly for hand-annotated data, just a slight im-
provement is achieved for word strings. Especially
clustering of phrases leads to the increased recall
as rules do not need to be learned for every possi-
ble compound composition of a given phrase type
as they are already covered by the phrase type
itself. Models based on unsuParse achieve the
highest precision among all models. This is not
very surprising as most of the other models (ex-
cept Common Cover Links) generate binary parses
achieving a higher recall. Nevertheless, unsu-
Parse+ yields comparable results and obtains the
highest f-score for German data.
</bodyText>
<table confidence="0.999265153846154">
Parsing Model UP UR UF
Baseline (POS tags) 35.5 66.0 46.2
CCM 48.1 85.5 61.6
DMV + CCM 49.6 89.7 63.9
U-DOP 51.2 90.5 65.4
UML-DOP — — 67.0
U-DOP* — — 63.8
unsuParse (POS tags) 76.9 53.9 63.4
unsuParse+ (POS tags) 71.1 67.9 69.5
Baseline (words) 23.6 43.9 30.7
Common Cover Links 51.0 69.8 59.0
unsuParse (words) 61.2 59.1 60.2
unsuParse+ (words) 63.1 60.4 61.7
</table>
<tableCaption confidence="0.9930645">
Table 4: UP, UR and UF for NEGRA10
Performance drops for more complex sentences
</tableCaption>
<bodyText confidence="0.996985">
(see Table 5). As for short sentences, the recall of
our approach is in the same order as for the base-
line. However, precision is increased by a factor
of two in comparison to the baseline, which is also
similar to short sentences.
</bodyText>
<table confidence="0.992916666666667">
Parsing Model UP UR UF
Baseline (POS tags) 24.8 49.3 33.0
unsuParse+ (POS tags) 55.3 51.4 53.3
</table>
<tableCaption confidence="0.999813">
Table 5: UP, UR and UF for NEGRA40
</tableCaption>
<bodyText confidence="0.989581692307692">
Table 6 shows the most frequently over- and
under-proposed phrases for NEGRA10. Noun and
prepositional phrases are often over-proposed due
to a flat representation within the NEGRA corpus.
The most frequently under-proposed phrase NE
NE is learned and classified as endocentric con-
struction (NE &lt;-- NE NE). Due to the removal of
punctuation, proper nouns which naturally would
be separated by e. g. commas will be represented
by one flat phrase without deeper analysis of the
inner structure. This includes some underproposi-
tions which will not occur while parsing sentences
containing punctuation.
</bodyText>
<table confidence="0.9980165">
Overproposed Underproposed
ART NN 369 NE NE 42
CARD NN 111 NN NE 35
ADV ADV 103 ART NN NE 27
ADJA NN 99 ADV ART NN 24
APPR ART NN 93 APPR PPER 23
</table>
<tableCaption confidence="0.972284">
Table 6: Most frequently over- and under-
proposed constituents
</tableCaption>
<sectionHeader confidence="0.994397" genericHeader="conclusions">
4 Conclusions and further work
</sectionHeader>
<bodyText confidence="0.9959632">
In this paper, we presented an improved model for
co-occurrence based parsing. This model creates
high accuracy parses employing a constituent de-
tection algorithm yielding competitive results. Al-
though no a priori knowledge about the language
in question is taken into account, it is possible to
detect heads, modifiers and different phrase types.
Especially noun phrases and prepositional phrases
are clustered into their respective classes. For fur-
ther processing like relation extraction, precise re-
sults for the aforementioned phrase types are es-
sential and provided by this algorithm in an unsu-
pervised manner.
Our future work will include the investigation of
unsupervised methods for dependency identifica-
</bodyText>
<page confidence="0.997264">
7
</page>
<bodyText confidence="0.9997111">
tion between verbs and their arguments. Further-
more, the inclusion of further constituency tests
like substitution and deletion could provide addi-
tional certainty for constituent candidates.
Carl Pollard and Ivan A. Sag. 1994. Head-Driven
Phrase Structure Grammar. University Of Chicago
Press.
Ivan Sag. 2002. Coordination and underspecification.
In roceedings of the Ninth International Conference
on Head-Driven Phrase Structure Grammar.
</bodyText>
<sectionHeader confidence="0.996447" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.997184821428571">
David Adger. 2003. Core Syntax: A Minimalist Ap-
proach. Oxford University Press.
Chris Biemann. 2006. Unsupervised part-of-speech
tagging employing efficient graph clustering. In
Proceedings of the COLING/ACL-06 Student Re-
search Workshop, Sydney, Australia.
Rens Bod. 2006. An all-subtrees approach to un-
supervised parsing. In ACL-44: Proceedings of
the 21st International Conference on Computational
Linguistics and the 44th annual meeting of the Asso-
ciation for Computational Linguistics.
Noam Chomsky. 1965. Aspects of the Theory of Syn-
tax. MIT Press, Cambridge, Massachusetts.
Ted Dunning. 1993. Accurate methods for the statis-
tics of surprise and coincidence. Computational
Linguistics, 19(1):61–74.
Christian H¨anig, Stefan Bordag, and Uwe Quasthoff.
2008. Unsuparse: Unsupervised parsing with un-
supervised part of speech tagging. In Proceedings
of the Sixth International Language Resources and
Evaluation (LREC’08).
Richard S. Kayne. 1995. The Antisymmetry of Syntax.
MIT Press.
Dan Klein and Christopher D. Manning. 2002. A
generative constituent-context model for improved
grammar induction. In ACL ’02: Proceedings of the
40th Annual Meeting on Association for Computa-
tional Linguistics.
Dan Klein and Christopher D. Manning. 2004.
Corpus-based induction of syntactic structure: mod-
els of dependency and constituency. In ACL ’04:
Proceedings of the 42nd Annual Meeting on Associ-
ation for Computational Linguistics.
Dan Klein. 2005. The Unsupervised Learning ofNatu-
ral Language Structure. Ph.D. thesis, Stanford Uni-
versity.
Ewald Lang. 2002. Die Wortart ”Konjunktion”. In
Lexikologie. Lexicology. Ein Internationales Hand-
buch zur Natur und Struktur von W¨ortern und
Wortsch¨atzen, pages 634–641. de Gruyter.
M. Marcus, B. Santorini, and M. A. Marcinkiewicz.
1993. Building a large annotated corpus of en-
glish: The penn treebank. Computational Linguis-
tics, 19(2):313–330.
Yoav Seginer. 2007. Fast unsupervised incremental
parsing. In Proceedings of the 45th Annual Meeting
of the Association of Computational Linguistics.
Wojciech Skut, Thorsten Brants, Brigitte Krenn, and
Hans Uszkoreit. 1998. A linguistically interpreted
corpus of german newspaper text. In ESSLLI-98
Workshop on Recent Advances in Corpus Annota-
tion.
C. Thielen, A. Schiller, S. Teufel, and C. St¨ockert.
1999. Guidelines f¨ur das Tagging deutscher Tex-
tkorpora mit STTS. Technical report, University of
Stuttgart and University of T¨ubingen.
</reference>
<page confidence="0.99858">
8
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.588927">
<title confidence="0.997436">Improvements in unsupervised co-occurrence based parsing</title>
<author confidence="0.814115">Christian Daimler</author>
<affiliation confidence="0.983718">Research and</affiliation>
<address confidence="0.966154">89081 Ulm,</address>
<email confidence="0.999928">christian.haenig@daimler.com</email>
<abstract confidence="0.997502833333333">This paper presents an algorithm for unsupervised co-occurrence based parsing that improves and extends existing approaches. The proposed algorithm induces a contextfree grammar of the language in question in an iterative manner. The resulting structure of a sentence will be given as a hierarchical arrangement of constituents. Although this algorithm does not use any a priori knowledge about the language, it is able to detect heads, modifiers and a phrase type’s different compound composition possibilities. For evaluation purposes, the algorithm is applied to manually annotated part-of-speech tags (POS tags) as well as to word classes induced by an unsupervised part-of-speech tagger.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>David Adger</author>
</authors>
<title>Core Syntax: A Minimalist Approach.</title>
<date>2003</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="3401" citStr="Adger, 2003" startWordPosition="525" endWordPosition="526">een shown in (H¨anig et al., 2008) that statistical methods like calculating significant cooccurrences and context clustering are applicable to grammar induction from raw text. The underlying assumption states that each word prefers a certain position within a phrase. Two particular cases are of special interest: a word’s occurrence at the beginning of a sentence and a word’s occurrence at the end of a sentence. Those positions obviously are constituent borders and can be easily used to extract syntactic knowledge. One possibility is to discover constituents employing constituency tests (see (Adger, 2003)), whereby these two cases can be used to express and use one of them in a formal way: the movement test. Three neighbourhood co-occurrences express the aforementioned observations: 1 Proceedings of the Fourteenth Conference on Computational Natural Language Learning, pages 1–8, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics • Value a denotes the significance of word A standing at the last position of a sentence (where $ is an imaginary word to mark a sentences’ end). a = sig (A, $) (1) • Contrary, variable b denotes the significance of a word B being observ</context>
</contexts>
<marker>Adger, 2003</marker>
<rawString>David Adger. 2003. Core Syntax: A Minimalist Approach. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chris Biemann</author>
</authors>
<title>Unsupervised part-of-speech tagging employing efficient graph clustering.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL-06 Student Research Workshop,</booktitle>
<location>Sydney, Australia.</location>
<contexts>
<context position="2328" citStr="Biemann, 2006" startWordPosition="352" endWordPosition="354">at most 10 POS tags. In (Klein and Manning, 2004) an approach combining constituency and dependency models yields 77.6% f-score. Bod (2006)’s all-subtree approach — known as DataOriented Parsing (DOP) — reports 82.9% for UML-DOP. Seginer (2007)’s common cover links model (CCL) does not need any prior tagging and is applied on word strings directly. The f-score for English is 75.9%, and for German (NEGRA10) 59% is achieved. H¨anig et al. (2008) present a cooccurrence based constituent detection algorithm which is applied to word forms, too (unsupervised POS tags are induced using unsuPOS, see (Biemann, 2006)). An f-score of 63.4% is reported for German data. In this paper, we want to present a new unsupervised co-occurrence based grammar induction model based on H¨anig et al. (2008). In the following section, we give a short introduction to the base algorithm unsuParse. Afterwards, we present improvements to this algorithm. In the final section, we evaluate the proposed model against existing ones and discuss the results. 2 Co-occurrence based parsing It has been shown in (H¨anig et al., 2008) that statistical methods like calculating significant cooccurrences and context clustering are applicabl</context>
<context position="20236" citStr="Biemann, 2006" startWordPosition="3412" endWordPosition="3413"> and empty element tags are removed from the NEGRA corpus (see (Skut et al., 1998)). Afterwards, all sentences containing more than 10 elements are dismissed. The resulting corpus is referred to as NEGRA10 (2175 sentences). To take more complex sentences into account, we also prepared a corpus containing sentences to a maximum length of 40 elements (NEGRA40). We present results for both — POS tags and word strings. As most unsupervised parsing models (except (Seginer, 2007)), we apply the handannotated data of the NEGRA corpus. Additionally, we used an unsupervised part-of-speech tagger (see (Biemann, 2006)) to tag the NEGRA corpus to be able to present a complete unsupervised parsing process relying on word strings only. We applied the model de40M which has been created Begin Application of induced rules No No Yes No Discontinuity test Yes No Create a rule labeled by a new unique label Detection of new phrase candidate Valid? Yes Endocentric? Similar to existing phrase type? Abort Yes End learning? Create a rule labeled by existing phrase type Create a rule labeled by its head 6 on a corpus containing 40 million sentences and contains 510 word classes. To compare the performance of different pa</context>
</contexts>
<marker>Biemann, 2006</marker>
<rawString>Chris Biemann. 2006. Unsupervised part-of-speech tagging employing efficient graph clustering. In Proceedings of the COLING/ACL-06 Student Research Workshop, Sydney, Australia.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rens Bod</author>
</authors>
<title>An all-subtrees approach to unsupervised parsing.</title>
<date>2006</date>
<booktitle>In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1853" citStr="Bod (2006)" startWordPosition="276" endWordPosition="277">. Huge annotated corpora consisting of sentences extracted from the Internet barely exist until now. Consequential a lot of effort has been put into unsupervised grammar induction during the last years and results and performance of unsupervised parsers improved steadily. Klein and Manning (2002)’s constituent context model (CCM) obtains 51.2% f-score on ATIS part-of-speech strings. The same model achieves 71.1% on Wall Street Journal corpus sentences with length of at most 10 POS tags. In (Klein and Manning, 2004) an approach combining constituency and dependency models yields 77.6% f-score. Bod (2006)’s all-subtree approach — known as DataOriented Parsing (DOP) — reports 82.9% for UML-DOP. Seginer (2007)’s common cover links model (CCL) does not need any prior tagging and is applied on word strings directly. The f-score for English is 75.9%, and for German (NEGRA10) 59% is achieved. H¨anig et al. (2008) present a cooccurrence based constituent detection algorithm which is applied to word forms, too (unsupervised POS tags are induced using unsuPOS, see (Biemann, 2006)). An f-score of 63.4% is reported for German data. In this paper, we want to present a new unsupervised co-occurrence based </context>
<context position="19572" citStr="Bod, 2006" startWordPosition="3303" endWordPosition="3304">se of an endocentric construction) or by a syntactic identical phrase type that has been learned before. If neither is the case, it gets a new unique label. Afterwards, the next iteration is triggered. S DT JJ NN VBZ $ CD The minimum unit is $ 100 Figure 7: Example S DT NN VBZ $ CD The is $ 100 Figure 8: Example after application of rule NN +– JJ NN S P#1 VBZ $ CD is $ 100 Figure 9: Example after additional application of rule P#1 +– DT NN 3 Evaluation To evaluate unsuParse+ against unsuParse and other unsupervised parsing algorithms, we apply the same experimental setup as in (Klein, 2005), (Bod, 2006) and (H¨anig et al., 2008). For German punctuation and empty element tags are removed from the NEGRA corpus (see (Skut et al., 1998)). Afterwards, all sentences containing more than 10 elements are dismissed. The resulting corpus is referred to as NEGRA10 (2175 sentences). To take more complex sentences into account, we also prepared a corpus containing sentences to a maximum length of 40 elements (NEGRA40). We present results for both — POS tags and word strings. As most unsupervised parsing models (except (Seginer, 2007)), we apply the handannotated data of the NEGRA corpus. Additionally, we</context>
</contexts>
<marker>Bod, 2006</marker>
<rawString>Rens Bod. 2006. An all-subtrees approach to unsupervised parsing. In ACL-44: Proceedings of the 21st International Conference on Computational Linguistics and the 44th annual meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Noam Chomsky</author>
</authors>
<title>Aspects of the Theory of Syntax.</title>
<date>1965</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="6693" citStr="Chomsky (1965)" startWordPosition="1067" endWordPosition="1068">numbers (see section 2.4). First, we will start with the detection of constituent candidates. 2.1 Detection of constituent borders Instead of using sepAB to detect constituent borders we use neighbourhood co-occurrence significances on account of an experiment in (H¨anig et al., 2008) showing that the pure significance value c is sufficient. Furthermore, we do not restrict the detection of phrases to bigrams and allow the detection of arbitrary n-grams. The motivation behind this is basically caused by coordinating conjunctions for which discussions on the correct1 structure are raised. While Chomsky (1965) argues in favor of symmetric multiple-branching coordinating constructions (see Figure 1), recent discussions in the context of unification grammars (especially headdriven phrase structure grammar (see (Pollard and Sag, 1994)) prefer asymmetric endocentric constructions (see (Kayne, 1995) and (Sag, 2002)). The corresponding structure can be seen in Figure 2. Nevertheless, a symmetric construction containing two heads seems to be more appropriate for some languages (e. g. German, see (Lang, 2002)). ConJ NNS Conj’ cats CC NNS and dogs Figure 2: Asymmetric coordinating conjunction 1correct meani</context>
</contexts>
<marker>Chomsky, 1965</marker>
<rawString>Noam Chomsky. 1965. Aspects of the Theory of Syntax. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ted Dunning</author>
</authors>
<title>Accurate methods for the statistics of surprise and coincidence.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>1</issue>
<contexts>
<context position="4384" citStr="Dunning, 1993" startWordPosition="692" endWordPosition="693">e a denotes the significance of word A standing at the last position of a sentence (where $ is an imaginary word to mark a sentences’ end). a = sig (A, $) (1) • Contrary, variable b denotes the significance of a word B being observed at the beginning of a sentence (where ^ is an imaginary word to mark the beginning of a sentence). b = sig (^, B) (2) • Additionally, a third value is necessary to represent the statistical significance of the neighbourhood co-occurrence containing word A and B. c = sig (A, B) (3) To compute those significance values for a corpus, the log-likelihood measure (see (Dunning, 1993)) is applied using corpus size n, term frequencies nA and nB (for the words A and B) and frequency nAB of the co-occurrence of A and B. To detect constituent borders between two words, a separation value sepAB can be defined as: If word A occurs more significantly at the end of a sentence as in front of B, then a &gt; 1. Additionally, b is larger than c if B is observed more significantly at the beginning of a sentence as after A and b c &gt; 1 and obviously, a constituent border would be situated between A and B. The basic approach to create parse trees from separation values between two adjacent w</context>
</contexts>
<marker>Dunning, 1993</marker>
<rawString>Ted Dunning. 1993. Accurate methods for the statistics of surprise and coincidence. Computational Linguistics, 19(1):61–74.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christian H¨anig</author>
<author>Stefan Bordag</author>
<author>Uwe Quasthoff</author>
</authors>
<title>Unsuparse: Unsupervised parsing with unsupervised part of speech tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).</booktitle>
<marker>H¨anig, Bordag, Quasthoff, 2008</marker>
<rawString>Christian H¨anig, Stefan Bordag, and Uwe Quasthoff. 2008. Unsuparse: Unsupervised parsing with unsupervised part of speech tagging. In Proceedings of the Sixth International Language Resources and Evaluation (LREC’08).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard S Kayne</author>
</authors>
<title>The Antisymmetry of Syntax.</title>
<date>1995</date>
<publisher>MIT Press.</publisher>
<contexts>
<context position="6983" citStr="Kayne, 1995" startWordPosition="1106" endWordPosition="1107">g that the pure significance value c is sufficient. Furthermore, we do not restrict the detection of phrases to bigrams and allow the detection of arbitrary n-grams. The motivation behind this is basically caused by coordinating conjunctions for which discussions on the correct1 structure are raised. While Chomsky (1965) argues in favor of symmetric multiple-branching coordinating constructions (see Figure 1), recent discussions in the context of unification grammars (especially headdriven phrase structure grammar (see (Pollard and Sag, 1994)) prefer asymmetric endocentric constructions (see (Kayne, 1995) and (Sag, 2002)). The corresponding structure can be seen in Figure 2. Nevertheless, a symmetric construction containing two heads seems to be more appropriate for some languages (e. g. German, see (Lang, 2002)). ConJ NNS Conj’ cats CC NNS and dogs Figure 2: Asymmetric coordinating conjunction 1correct meaning considered to be correct sepAB = (4) c c c2 a b a · b · = will be &gt; 1. In this case sepAB is NP NNS CC NNS cats and dogs Figure 1: Symmetric coordinating conjunction 2 Thus, the presented algorithm is able to deal with phrases containing any number of compounds. As in (H¨anig et al., 20</context>
</contexts>
<marker>Kayne, 1995</marker>
<rawString>Richard S. Kayne. 1995. The Antisymmetry of Syntax. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>A generative constituent-context model for improved grammar induction.</title>
<date>2002</date>
<booktitle>In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1540" citStr="Klein and Manning (2002)" startWordPosition="226" endWordPosition="230">ailable in the Internet, unsupervised methods for natural language processing gain a considerable amount of interest. Due to the very special usage of language, supervised methods trained on high quality corpora (e. g. containing newspaper texts) do not achieve comparable accuracy when being applied to data from fora or blogs. Huge annotated corpora consisting of sentences extracted from the Internet barely exist until now. Consequential a lot of effort has been put into unsupervised grammar induction during the last years and results and performance of unsupervised parsers improved steadily. Klein and Manning (2002)’s constituent context model (CCM) obtains 51.2% f-score on ATIS part-of-speech strings. The same model achieves 71.1% on Wall Street Journal corpus sentences with length of at most 10 POS tags. In (Klein and Manning, 2004) an approach combining constituency and dependency models yields 77.6% f-score. Bod (2006)’s all-subtree approach — known as DataOriented Parsing (DOP) — reports 82.9% for UML-DOP. Seginer (2007)’s common cover links model (CCL) does not need any prior tagging and is applied on word strings directly. The f-score for English is 75.9%, and for German (NEGRA10) 59% is achieved.</context>
<context position="20924" citStr="Klein and Manning, 2002" startWordPosition="3528" endWordPosition="3531">ervised parsing process relying on word strings only. We applied the model de40M which has been created Begin Application of induced rules No No Yes No Discontinuity test Yes No Create a rule labeled by a new unique label Detection of new phrase candidate Valid? Yes Endocentric? Similar to existing phrase type? Abort Yes End learning? Create a rule labeled by existing phrase type Create a rule labeled by its head 6 on a corpus containing 40 million sentences and contains 510 word classes. To compare the performance of different parsing algorithms, we used the Unlabeled Brackets Measure as in (Klein and Manning, 2002) and (Klein and Manning, 2004). Additionally to unlabeled precision UP and unlabeled recall UR, the unlabeled f-score UF is defined as: 2 · UP · UR (13 ) UF = UP + UR The baseline algorithm is based on neighbourhood co-occurrences. First, a parse tree is initialized and all tokens of a sentence are added as leaves. Afterwards, the two adjacent nodes containing the POS tags with the highest neighbourhood co-occurrence significance are merged consecutively until a binary tree has been created. Results for NEGRA10 are given in Table 4. unsuParse+ improves the performance of unsuParse in both cate</context>
</contexts>
<marker>Klein, Manning, 2002</marker>
<rawString>Dan Klein and Christopher D. Manning. 2002. A generative constituent-context model for improved grammar induction. In ACL ’02: Proceedings of the 40th Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Corpus-based induction of syntactic structure: models of dependency and constituency.</title>
<date>2004</date>
<booktitle>In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics.</booktitle>
<contexts>
<context position="1763" citStr="Klein and Manning, 2004" startWordPosition="262" endWordPosition="265">aining newspaper texts) do not achieve comparable accuracy when being applied to data from fora or blogs. Huge annotated corpora consisting of sentences extracted from the Internet barely exist until now. Consequential a lot of effort has been put into unsupervised grammar induction during the last years and results and performance of unsupervised parsers improved steadily. Klein and Manning (2002)’s constituent context model (CCM) obtains 51.2% f-score on ATIS part-of-speech strings. The same model achieves 71.1% on Wall Street Journal corpus sentences with length of at most 10 POS tags. In (Klein and Manning, 2004) an approach combining constituency and dependency models yields 77.6% f-score. Bod (2006)’s all-subtree approach — known as DataOriented Parsing (DOP) — reports 82.9% for UML-DOP. Seginer (2007)’s common cover links model (CCL) does not need any prior tagging and is applied on word strings directly. The f-score for English is 75.9%, and for German (NEGRA10) 59% is achieved. H¨anig et al. (2008) present a cooccurrence based constituent detection algorithm which is applied to word forms, too (unsupervised POS tags are induced using unsuPOS, see (Biemann, 2006)). An f-score of 63.4% is reported </context>
<context position="20954" citStr="Klein and Manning, 2004" startWordPosition="3533" endWordPosition="3536">g on word strings only. We applied the model de40M which has been created Begin Application of induced rules No No Yes No Discontinuity test Yes No Create a rule labeled by a new unique label Detection of new phrase candidate Valid? Yes Endocentric? Similar to existing phrase type? Abort Yes End learning? Create a rule labeled by existing phrase type Create a rule labeled by its head 6 on a corpus containing 40 million sentences and contains 510 word classes. To compare the performance of different parsing algorithms, we used the Unlabeled Brackets Measure as in (Klein and Manning, 2002) and (Klein and Manning, 2004). Additionally to unlabeled precision UP and unlabeled recall UR, the unlabeled f-score UF is defined as: 2 · UP · UR (13 ) UF = UP + UR The baseline algorithm is based on neighbourhood co-occurrences. First, a parse tree is initialized and all tokens of a sentence are added as leaves. Afterwards, the two adjacent nodes containing the POS tags with the highest neighbourhood co-occurrence significance are merged consecutively until a binary tree has been created. Results for NEGRA10 are given in Table 4. unsuParse+ improves the performance of unsuParse in both categories: supervised and unsuper</context>
</contexts>
<marker>Klein, Manning, 2004</marker>
<rawString>Dan Klein and Christopher D. Manning. 2004. Corpus-based induction of syntactic structure: models of dependency and constituency. In ACL ’04: Proceedings of the 42nd Annual Meeting on Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
</authors>
<title>The Unsupervised Learning ofNatural Language Structure.</title>
<date>2005</date>
<tech>Ph.D. thesis,</tech>
<institution>Stanford University.</institution>
<contexts>
<context position="19559" citStr="Klein, 2005" startWordPosition="3301" endWordPosition="3302">its head (in case of an endocentric construction) or by a syntactic identical phrase type that has been learned before. If neither is the case, it gets a new unique label. Afterwards, the next iteration is triggered. S DT JJ NN VBZ $ CD The minimum unit is $ 100 Figure 7: Example S DT NN VBZ $ CD The is $ 100 Figure 8: Example after application of rule NN +– JJ NN S P#1 VBZ $ CD is $ 100 Figure 9: Example after additional application of rule P#1 +– DT NN 3 Evaluation To evaluate unsuParse+ against unsuParse and other unsupervised parsing algorithms, we apply the same experimental setup as in (Klein, 2005), (Bod, 2006) and (H¨anig et al., 2008). For German punctuation and empty element tags are removed from the NEGRA corpus (see (Skut et al., 1998)). Afterwards, all sentences containing more than 10 elements are dismissed. The resulting corpus is referred to as NEGRA10 (2175 sentences). To take more complex sentences into account, we also prepared a corpus containing sentences to a maximum length of 40 elements (NEGRA40). We present results for both — POS tags and word strings. As most unsupervised parsing models (except (Seginer, 2007)), we apply the handannotated data of the NEGRA corpus. Add</context>
</contexts>
<marker>Klein, 2005</marker>
<rawString>Dan Klein. 2005. The Unsupervised Learning ofNatural Language Structure. Ph.D. thesis, Stanford University.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ewald Lang</author>
</authors>
<title>Die Wortart ”Konjunktion”.</title>
<date>2002</date>
<booktitle>In Lexikologie. Lexicology. Ein Internationales Handbuch zur Natur und Struktur von W¨ortern und Wortsch¨atzen,</booktitle>
<pages>634--641</pages>
<note>de Gruyter.</note>
<contexts>
<context position="7194" citStr="Lang, 2002" startWordPosition="1140" endWordPosition="1141"> by coordinating conjunctions for which discussions on the correct1 structure are raised. While Chomsky (1965) argues in favor of symmetric multiple-branching coordinating constructions (see Figure 1), recent discussions in the context of unification grammars (especially headdriven phrase structure grammar (see (Pollard and Sag, 1994)) prefer asymmetric endocentric constructions (see (Kayne, 1995) and (Sag, 2002)). The corresponding structure can be seen in Figure 2. Nevertheless, a symmetric construction containing two heads seems to be more appropriate for some languages (e. g. German, see (Lang, 2002)). ConJ NNS Conj’ cats CC NNS and dogs Figure 2: Asymmetric coordinating conjunction 1correct meaning considered to be correct sepAB = (4) c c c2 a b a · b · = will be &gt; 1. In this case sepAB is NP NNS CC NNS cats and dogs Figure 1: Symmetric coordinating conjunction 2 Thus, the presented algorithm is able to deal with phrases containing any number of compounds. As in (H¨anig et al., 2008), phrases will be learned in an iterative manner (see details in section 2.5). Within each iteration, the n-gram P yielding the highest significance is considered to be the best candidate for being a valid co</context>
</contexts>
<marker>Lang, 2002</marker>
<rawString>Ewald Lang. 2002. Die Wortart ”Konjunktion”. In Lexikologie. Lexicology. Ein Internationales Handbuch zur Natur und Struktur von W¨ortern und Wortsch¨atzen, pages 634–641. de Gruyter.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Marcus</author>
<author>B Santorini</author>
<author>M A Marcinkiewicz</author>
</authors>
<title>Building a large annotated corpus of english: The penn treebank.</title>
<date>1993</date>
<journal>Computational Linguistics,</journal>
<volume>19</volume>
<issue>2</issue>
<contexts>
<context position="9458" citStr="Marcus et al., 1993" startWordPosition="1546" endWordPosition="1549">ccur at the beginning. As both constructions are endocentric, they prefer the head’s position within the superordinating phrase and thus, their existence does not stand in contrast to the assumption made about preferred positions. Formally, we get the following proposition: valid (P) q p0 = pn−1 V pref (p0) &gt; ϕ n pref (pn−1) &lt; An uncertainty factor is introduced by ϕ, as some parts-of-speech tend to not appear at the borders of a sentence although they prefer a certain position within constituents. Some examples (given in Table 1) of the 5 most frequent English2 and Ger2Penn Tree Tagset, see (Marcus et al., 1993) man3 parts-of-speech will demonstrate this effect. English German NN 0.08 NN 0.30 IN 31.45 ART 242.48 NNP 1.39 APPR 143.62 DT 84.19 ADJA 5.06 NNS 0.31 NE 1.11 Table 1: Values of pref (POS) for the 5 most frequent parts-of-speech of English and German In both languages proper nouns (NNP resp. NE) occur slightly more often at the beginning of a sentence than at its end, although proper nouns prefer — like normal nouns — the last position of a phrase. To account for this effect, pref (A) will be iteratively adapted to the observations of learned grammar rules as given in Equ. 8: 1 (8) pref (p0) </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>M. Marcus, B. Santorini, and M. A. Marcinkiewicz. 1993. Building a large annotated corpus of english: The penn treebank. Computational Linguistics, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Seginer</author>
</authors>
<title>Fast unsupervised incremental parsing.</title>
<date>2007</date>
<booktitle>In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics.</booktitle>
<contexts>
<context position="1958" citStr="Seginer (2007)" startWordPosition="292" endWordPosition="293">Consequential a lot of effort has been put into unsupervised grammar induction during the last years and results and performance of unsupervised parsers improved steadily. Klein and Manning (2002)’s constituent context model (CCM) obtains 51.2% f-score on ATIS part-of-speech strings. The same model achieves 71.1% on Wall Street Journal corpus sentences with length of at most 10 POS tags. In (Klein and Manning, 2004) an approach combining constituency and dependency models yields 77.6% f-score. Bod (2006)’s all-subtree approach — known as DataOriented Parsing (DOP) — reports 82.9% for UML-DOP. Seginer (2007)’s common cover links model (CCL) does not need any prior tagging and is applied on word strings directly. The f-score for English is 75.9%, and for German (NEGRA10) 59% is achieved. H¨anig et al. (2008) present a cooccurrence based constituent detection algorithm which is applied to word forms, too (unsupervised POS tags are induced using unsuPOS, see (Biemann, 2006)). An f-score of 63.4% is reported for German data. In this paper, we want to present a new unsupervised co-occurrence based grammar induction model based on H¨anig et al. (2008). In the following section, we give a short introduc</context>
<context position="20100" citStr="Seginer, 2007" startWordPosition="3390" endWordPosition="3391">sing algorithms, we apply the same experimental setup as in (Klein, 2005), (Bod, 2006) and (H¨anig et al., 2008). For German punctuation and empty element tags are removed from the NEGRA corpus (see (Skut et al., 1998)). Afterwards, all sentences containing more than 10 elements are dismissed. The resulting corpus is referred to as NEGRA10 (2175 sentences). To take more complex sentences into account, we also prepared a corpus containing sentences to a maximum length of 40 elements (NEGRA40). We present results for both — POS tags and word strings. As most unsupervised parsing models (except (Seginer, 2007)), we apply the handannotated data of the NEGRA corpus. Additionally, we used an unsupervised part-of-speech tagger (see (Biemann, 2006)) to tag the NEGRA corpus to be able to present a complete unsupervised parsing process relying on word strings only. We applied the model de40M which has been created Begin Application of induced rules No No Yes No Discontinuity test Yes No Create a rule labeled by a new unique label Detection of new phrase candidate Valid? Yes Endocentric? Similar to existing phrase type? Abort Yes End learning? Create a rule labeled by existing phrase type Create a rule lab</context>
</contexts>
<marker>Seginer, 2007</marker>
<rawString>Yoav Seginer. 2007. Fast unsupervised incremental parsing. In Proceedings of the 45th Annual Meeting of the Association of Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wojciech Skut</author>
<author>Thorsten Brants</author>
<author>Brigitte Krenn</author>
<author>Hans Uszkoreit</author>
</authors>
<title>A linguistically interpreted corpus of german newspaper text.</title>
<date>1998</date>
<booktitle>In ESSLLI-98 Workshop on Recent Advances in Corpus Annotation.</booktitle>
<contexts>
<context position="19704" citStr="Skut et al., 1998" startWordPosition="3324" endWordPosition="3327">ase, it gets a new unique label. Afterwards, the next iteration is triggered. S DT JJ NN VBZ $ CD The minimum unit is $ 100 Figure 7: Example S DT NN VBZ $ CD The is $ 100 Figure 8: Example after application of rule NN +– JJ NN S P#1 VBZ $ CD is $ 100 Figure 9: Example after additional application of rule P#1 +– DT NN 3 Evaluation To evaluate unsuParse+ against unsuParse and other unsupervised parsing algorithms, we apply the same experimental setup as in (Klein, 2005), (Bod, 2006) and (H¨anig et al., 2008). For German punctuation and empty element tags are removed from the NEGRA corpus (see (Skut et al., 1998)). Afterwards, all sentences containing more than 10 elements are dismissed. The resulting corpus is referred to as NEGRA10 (2175 sentences). To take more complex sentences into account, we also prepared a corpus containing sentences to a maximum length of 40 elements (NEGRA40). We present results for both — POS tags and word strings. As most unsupervised parsing models (except (Seginer, 2007)), we apply the handannotated data of the NEGRA corpus. Additionally, we used an unsupervised part-of-speech tagger (see (Biemann, 2006)) to tag the NEGRA corpus to be able to present a complete unsupervi</context>
</contexts>
<marker>Skut, Brants, Krenn, Uszkoreit, 1998</marker>
<rawString>Wojciech Skut, Thorsten Brants, Brigitte Krenn, and Hans Uszkoreit. 1998. A linguistically interpreted corpus of german newspaper text. In ESSLLI-98 Workshop on Recent Advances in Corpus Annotation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Thielen</author>
<author>A Schiller</author>
<author>S Teufel</author>
<author>C St¨ockert</author>
</authors>
<title>Guidelines f¨ur das Tagging deutscher Textkorpora mit STTS.</title>
<date>1999</date>
<tech>Technical report,</tech>
<institution>University of Stuttgart and University of T¨ubingen.</institution>
<marker>Thielen, Schiller, Teufel, St¨ockert, 1999</marker>
<rawString>C. Thielen, A. Schiller, S. Teufel, and C. St¨ockert. 1999. Guidelines f¨ur das Tagging deutscher Textkorpora mit STTS. Technical report, University of Stuttgart and University of T¨ubingen.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>