<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<note confidence="0.79786">
TEXTUAL EXPERTISE IN WORD EXPERTS:
AN APPROACH TO TEXT PARSING BASED ON TOPIC/COMMENT MONITORING *
</note>
<author confidence="0.4392745">
Udo Hahn
Universitaet Konstanz
</author>
<affiliation confidence="0.432609">
Informationswissenschaft
</affiliation>
<address confidence="0.776203333333333">
Projekt TOPIC
Postfach 5560
D-7750 Konstanz 1, West Germany
</address>
<email confidence="0.540408">
ABSTRACT
</email>
<bodyText confidence="0.999807818181818">
In this paper prototype versions of two word
experts for text analysis are dealt with which
demonstrate that word experts are a feasible tool
for parsing texts on the level of text cohesion as
well as text coherence. The analysis is based on
two major knowledge sources: context information
is modelled in terms of a frame knowledge base,
while the co-text keeps record of the linear
sequencing of text analysis. The result of text
parsing consists of a text graph reflecting the
thematic organization of topics in a text.
</bodyText>
<listItem confidence="0.972807">
1. Word Experts as a Text Parsing Device
</listItem>
<bodyText confidence="0.990515722891566">
This paper outlines an operational repre-
sentation of the notion of text cohesion and text
coherence based on a collection of word experts as
central procedural components of a distributed
lexical grammar.
By text cohesion, we refer to the micro level
of textuality as provided, e.g. by reference,
substitution, ellipsis, conjunction and lexical
cohesion (cf. HALLIDAY/HASAN 1976), whereas text
coherence relates to the macro level of textuality
as induced, e.g. by patterns of semantic recurrence
of topics (thematic progression) of a text (cf.
DANES 1974). On a deeper level of propositional
analysis of texts further types of semantic
development of a text can be examined, e.g.
coherence relations, such as contrast, generaliza-
tion, explanation (cf. HOBBS 1979, HOBBS 1982,
DIJK 1980a), basic modes of topic development, such
as expansion, shift, or splitting (cf. GRIMES
1978), and operations on different levels of tex-
tual macro-structures (DIJK 1980a) or schematized
superstructures (DIJK 1980b).
The identification of cohesive parts of a text
is needed to determine the continuous development
and increment of information with regard to single
thematic foci, i.e. topics of the text. As we
have topic elaborations, shifts, breaks, etc. in
texts the extension of topics has to be delimited
exactly and different topics have to be related
properly. The identification of coherent parts of
a text serves this purpose, in that the determina-
tion of the coherence relations mentioned above
Work reported in this paper is supported by
BMFT/GID under grant no. PT 200.08.
contributes to the delimitation of topics and their
organization in terms of text grammatical
well-formedness considerations. Text graphs are
used as the resulting structure of text parsing and
serve to represent corresponding relations holding
between different topics.
The word experts outlined below are part of a
genuine text-based parsing formalism incorporating
a linguistical level in terms of a distributed text
grammar and a computational level in terms of a
corresponding text parser (HAHN/REIMER 1983; for an
account of the original conception of word expert
parsing, cf. SMALL/RIEGER 1982). This paper is
intended to provide an empirical assessment of word
experts for the purpose of text parsing. We thus
arrive at a predominantly functional description of
this parsing device neglecting to a large extent
its procedural aspects.
The word expert parser is currently being
implemented as a major system component of TOPIC, a
knowledge-based text analysis system which is
Intended to provide text summarization (abstract-
ing) facilities on variable layers of informational
specifity for German language texts (each approx.
2000-4000 words) dealing with information technol-
ogy. Word expert construction and modification is
supported by a word expert editor using a special
word expert representation language fragments of
which are introduced in this paper (for a more
detailed account, cf. HAHN/REIMER 1983, HAHN
1984). Word experts are executed by interpretation
of their representation language description.
TOPIC&apos;s word expert system and its editor are
written in the C programming language and are
running under UNIX.
2. Some General Remarks about Word Expert Struc-
ture and the Knowledge Sources Available for
Text Parsing
A word expert is a procedural agent incor-
porating linguistic and world knowledge about a
particular word. This knowledge is represented
declaratively in terms of a decision net whose
nodes are constructed of various conditions. Word
experts communicate among each other as well as
with other system components in order to elaborate
a word&apos;s meaning (reading).
The conditions at least are tested for two
kinds of knowledge sources, the context and the
co-text of the corresponding word.
</bodyText>
<page confidence="0.997957">
402
</page>
<bodyText confidence="0.99954375">
Context is a frame knowledge base which con-
tains the conceptual world knowledge relevant for
the texts being processed. Simple conditions to be
tested in that knowledge base are:
</bodyText>
<equation confidence="0.551031166666667">
ACTIVE ( f ) :
f is an active frame
EISA ( f , f&apos; ) :
frame f is subordinate or instance of
frame V-
MS...SLOT ( f , s ) :
</equation>
<bodyText confidence="0.964393935064935">
frame f has slot s associated to it
HAS_SVAL ( f , s , v ) :
slot s of frame f has been assigned the
slot value v
SVAL RANGE ( str , s , f ) : &lt;===&gt;
string str is a permitted slot value with
respect to slot s of frame f
Co-text is a data repository which keeps
record of the sequential course of the text
analysis actually going on - this linear type of
information is completely lost in the context,
although it is badly needed for various sorts of
textual cohesion and coherence phenomena. As
co-text necessarily reflects basic properties of
the frame representation structures underlying the
context, some conditions to be tested in the
co-text also take certain aspects of context
knowledge into accout:
BEFORE ( exp , strl , str2 ) : &lt;==0
strl occurs maximally exp many trans-
actions before str2 in the co-text
AFTER ( exp , strl , str2 ) :
strl occurs maximally exp many trans-
actions after str2 in the co-text
IN PHRASE ( strl str2 ) : &lt;■==&gt;
strl occurs in the same sentence as str2
EQUAL ( strl , str2 ) :
strl equals str2
FACT ( f ) :
frame f was affected by an activation op-
eration in the knowledge base
SACT ( f , s ) :
slot s of frame f was affected by an ac-
tivation operation in the knowledge base
SVAL ( f , s , v ) :
slot s of frame f was affected by the as-
signment of a slot value v in the know-
ledge base
SAME TRANSACTION ( f , f&apos; ) : &lt;■=0
frame f and frame f are part of the same
transaction with respect to a single text
token, i.e. the set of all operations on
the frame knowledge base which are car-
ried out due to the readings generated by
the word experts which have been put into
operation with respect to this token
From the above atomic predicates more complex
conditions can be generated using common logical
operators (AND, OR, NOT). These expressions under-
lie an implicit existential quantification, unless
specified otherwise.
During the operation of a word expert the
variables of each condition have to be bound in
order to work out a truth value. In App.A and App.B
underlining of variables indicates that they have
already been bound, i.e. the evaluation of the
condition in which a variable occurs takes the
value already assigned, otherwise a value assign-
ment is made which satisfies the condition being
tested.
Items stored in the co-text are in the format
TOKEN actual form of text word
TYPE normalized form of text word after morpho-
logical reduction or decomposition proce-
dures have operated on it
ANNOT annotation indicating whether TYPE is iden-
tified as
FRAME a frame name
WEXP a word expert name
STOP a stop word or
NUM a numerical string
NIL an unknown text word
or TYPE consists of parameters
frame . slot . sval
which are affected by a special type of op-
eration executed in the frame knowledge
base which is alternatively denoted by
</bodyText>
<listItem confidence="0.55722425">
FACT frame activation
SACT slot activation
SVAL slot value assignment
3. Two Word Experts for Text Parsing
</listItem>
<bodyText confidence="0.999753294117647">
We now turn to an operational representation
of the notions introduced in sec.l. The discussion
will be limited to well-known cases of textual
cohesion and coherence as illustrated by the fol-
lowing text segment:
[1] In seiner Grundversion ist der Mikrocomputer
mit einem 1-80 und 48 KByte RAM ausgeruestet
und laeuft unter CP/M. An Peripherie werden
Tastatur, Bildschirm und em n Tintenspritz-
drucker bereitgestellt. Schliesslich verfuegt
das System ueber 2 Programmiersprachen: Basic
wird von SystemSoft geliefert und der Pas-
cal-Compiler kommt von PascWare.
[The basic version of the micro is supplied
with a 1-80, 48 kbyte RAM and runs under CP/M.
Peripheral devices provided include a
keyboard, a CRT display and an ink jet
printer. Finally, the system makes available 2
programming languages: Basic is supplied by
SystemSoft while PascWare furnished the Pascal
compiler.]
First, in sec.3.1 we will examine textual
cohesion phenomena illustrated by special cases of
lexical cohesion, namely the tendency of terms to
share the same lexical environment (collocation of
terms) and the occurrence of &apos;general nouns&apos; refer-
ring to more specific terms (cf. HALLIDAY/HASAN
1976). Then, in sec.3.2 our discussion will be
centered around various modes of thematic progres-
sion in texts, such as linear thematization of
rhemes (cf. DANES 1974) which is often used to
establish text coherence (for a similar approach to
combine the topic/comment analysis of texts and
knowledge representation based on the frame model,
</bodyText>
<page confidence="0.996201">
403
</page>
<bodyText confidence="0.999874615384615">
cf. CRITZ 1982; computational analysis of textual
coherence is also provided by HOBBS 1979, 1982
applying a logical representation model).
Word experts capable of handling corresponding
textual phenomena are given in App.A and App.B.
However, only simplified versions of word experts
(prototypes) can be supplied restricting their
scope to the recognition of the text structures
under examination. The representation of the
textual analysis also lacks completeness skipping a
lot of intermediary steps concerning the operation
of other (e.g. phrasal) types of word experts (for
more details, cf. HAHN 1984).
</bodyText>
<subsectionHeader confidence="0.996155">
3.1 A Word Expert for Text Cohesion
</subsectionHeader>
<bodyText confidence="0.999983">
We now illustrate the operation of the word
expert designed to handle special cases of text
cohesion (App.A) as indicated by text segment [1].
Suppose, the analysis of the text has been
carried out covering the first 9 text words of [1]
as indicated by the entries in co-text:
</bodyText>
<listItem confidence="0.7563765">
No. TOKEN TYPE
(1) In in
(2) seiner sein
(3) Grundversion
(4) ist ist
(5) der der
(86) Mikrocomputer iiikrocomputer
(7) mit mit
(8) einem emn
(9) Z-80 Z-80
</listItem>
<bodyText confidence="0.99711285483871">
The word expert given in App.A starts running
whenever a frame name occurs .in the text. Starting
at the occurrence of frame &amp;quot;Mikrocomputer&amp;quot; indi-
cated by {06} no reading is worked out. At {09} the
expert&apos;s input variable &apos;frame&apos; is bound to &amp;quot;Z-80&amp;quot;
as it starts again. A test in the knowledge base
indicates that &amp;quot;Z-80&amp;quot; is an active frame (by
default operation). Proceeding backwards from the
current entry in co-text the evaluation of nodes
#10 and #11 yields TRUE, since pronoun list con-
tains an element &amp;quot;em&amp;quot; a morphological variant of
which occurs immediately before frame (Z-80) within
the same sentence. In addition, we set frame&apos; to
&amp;quot;Mikrocomputer&amp;quot; (micro computer) as it is next
before frame (with proximity left unconstrained due
to &apos;any&apos;) in correspondence with {06}, and it is an
active frame, too. The evaluation of node #12,
finally, produces FALSE, since frame&apos; (Mikrocom-
puter) is not a subordinate or instance of frame
(2-80) - actually, &amp;quot;1-80&amp;quot; is an instance of &amp;quot;Mik-
roprozessor&amp;quot; (micro processor). Following the
FALSE arc of #12 leads to expression #2 which
evaluates to FALSE, as frame&apos; (Mikrocomputer) is a
frame which roughly consists of the following set
of slots (given by indentation)
Mikrocomputer micro computer
Mikroprozessor mirco processor
Peripherie peripheral devices
Hauptspeicher main memory
Programmiersprache programming language
Systemsoftware system software
Following the FALSE arc of #2, #3 also evaluates to
FALSE as according to the current state of analysis
context contains no information indicating that
frame&apos; (Mikrocomputer) has a slot&apos; to which has
been assigned any slot value (in addition, &amp;quot;Z-80&amp;quot;
is not used as a default slot value of any of the
slots supplied above). Turning now to the evalua-
tion of #4 slot&apos; has to be identified which must be
a slot of frame&apos; (Mikrocomputer) and frame (1-80)
must be within the value range of permitted slot
values for slot&apos; of frame&apos;. Trying &amp;quot;Mikroprozes-
sor&amp;quot; for slot&apos; succeeds, as &amp;quot;1-80&amp;quot; is an instance
of &amp;quot;Mikroprozessor&amp;quot; and thus (due to
model-dependent semantic integrity constraints
inherent to the underlying frame data model
[REIMER/HAHN 1983]) it is a permitted slot value
with respect to slot&apos; (Mikroprozessor) which in
turn is a slot of frame&apos; (Mikrocomputer). Thus,
the interpretation slot&apos; as &amp;quot;Mikroprozessor&amp;quot; holds.
The execution of word experts terminates if a
reading has been generated. Readings are labels of
leaf nodes of word experts, so following the TRUE
arc of #4 the reading SVAL ASSIGN ( Mikrocomputer ,
Mikroprozessor , Z-80 ) a reached. SVAL ASSIGN*
is a command issued to the frame knowledge 3ase (as
is done with every reading referring to cohesion
properties of texts) which leads to the assignment
of the slot value &amp;quot;Z-80&amp;quot; to the slot &amp;quot;Mikroprozes-
sor&amp;quot; of the frame &amp;quot;Mikrocomputer&amp;quot;. This operation
also gets recorded in co-text (SVAL). Therefore,
entry {09} get augmented:
</bodyText>
<equation confidence="0.719262333333333">
No. TOKM riTE ANNOT
(09) Z-80 2-80 FRAME
Mikrocomputer.Mikroprozessor.Z-80 SVAL
</equation>
<bodyText confidence="0.831669666666667">
The next steps of the analysis are skipped,
until a second basic type of text cohesion can be
examined with regard to {34}:
</bodyText>
<table confidence="0.887069157894737">
No. WACEN TIME
(11) 48 48
(12) KByte KBYte
(13) RAM RAM
(18) CP/M RAM-1.Groesse.48 KByte
(19) . mikroccmputer.Nauptspeicher.RAM-1
(21) Peripherie CP/M
(23) Tastatur Mikrocomputer.Betriebssystem.CP/M
(25) Bildschirm Peripherie
(28) Tintenspritzdrucker Mikrocceputer.Peripherie
Tastatur
Mikrocomputer.Peripherie.Tastatur
Bildschirm
Mikroomputer.Peripherie.Bildschirm
Tintenspritzdrucker
Mikrommdputer.Peripherie.Tintenspritzdrucker
(30) .
(33) das das
(34) System System
</table>
<bodyText confidence="0.917241777777778">
At {34} the word expert dealing with text cohesion
phenomena again starts running. Its input variable
&apos;frame&apos; is set to &amp;quot;System&amp;quot; (system). With respect
to #10 the evaluation of BEFORE yields a positive
result, since &amp;quot;das&amp;quot; which is an element of pronoun
list occurs immediately before frame. As the
SWEIGHT INC (f, s) which is also provided in
App.A says that the activation weight of slot
s of frame f gets incremented.
</bodyText>
<figure confidence="0.9990626">
AMMO?
STOP
STOP
NIL
STOP
STOP
FRAME
STOP
STOP
FRAME
ANNOT
NUM
WEXP
FRAME
SVAL
SVAL
FRAME
SVAL
WEXP
FRAmE
SACT
FRAME
SVAL
FRAME
SVAL
FRAME
SVAL
WEXP
STOP
FRAME
</figure>
<page confidence="0.998523">
404
</page>
<bodyText confidence="0.999672914893617">
IN PHRASE predicate also evaluates to TRUE, the
whole expression #10 turns out to be TRUE.
Proceeding backwards to the next frame which is
active in the frame knowledge base search stops at
position {28}. When more than a single frame
within the same transaction may be referred to by
word experts the following reference convention is
applied:
[21] if ANNOT FRAME and an annotation of type
FACT exists examine the frame corresponding
to FACT
[2ii] if ARNDT = FRAME or ANNOT = WEXP and annota-
tions of type SACT or SVAL exist examine f
as frame, s as slot, and v as slot value,
resp. according to the order of parameters
f . s .v
In these cases reference of word experts to the
frame correponding to the annotation FRAME would
cause the provision of insufficient or even false
structural information about the context of the
current lexical item, although more significant
information actually is available in the knowledge
sources. In the word expert considered, frame&apos; is
set to &amp;quot;Mikrocomputer&amp;quot; according to [211]. Follow-
ing the TRUE arc of #11 expression #12 states that
frame&apos; (Mikrocomputer) must be a subordinate or
instance of frame (System) which also holds TRUE.
Thus, one gets the reading SHIFT ( System , Mik-
rocomputer ) which says that the activation weight
of frame (System) has to be decremented (thus
neutralizing the default activation), while the
activation weight of frame&apos; (Mikrocomputer) gets
incremented instead. Based on this re-assignment
of activation weights the system is protected
against invalid activation states, since &amp;quot;Mikrocom-
puter&amp;quot; is referred to by &amp;quot;System&amp;quot; due to stylisti-
cal reasons only and no indication is available
that a real topical change in the the text is
implied, e.g. some generalization with respect to
the whole class of micro computers. We thus have
an augmented entry for {34} in co-text together
with the result of processing the remainder of [1]:
(partial parsing). With respect to other kinds of
cohesive phenomena in texts, e.g. pronominal
anaphora, conjunction, deixis, word experts are
available similar in structure, but adapted to
identify corresponding phenomena.
</bodyText>
<subsectionHeader confidence="0.998292">
3.2 A Word Expert for Text Coherence
</subsectionHeader>
<bodyText confidence="0.9997988">
We now examine the generation of a second type
of reading, so-called coherence readings, concern-
ing the structural organization of cohesive parts
of a text. Unlike cohesion readings, coherence
readings of that type are not issued to the frame
knowledge base to instantiate various operations,
but are passed over to a data repository in which
coherence indicators of different sorts are col-
lected continuously. A device operating on these
coherence indicators computes text structure pat-
terns in terms of a text graph which is the final
result of text parsing in TOPIC.
A text graph constructed that way is composed
of a small set of basic coherence relations. We
only mention here the application of further rela-
tions due to other types of linguistic coherence
readings (cf. HAHN 1984) as well as coherence
readings from computation procedures based
exclusively on configuration data from the frame
knowledge base (HABW/REIMER 1984). One common type
of coherence relations is accounted for in the
remainder of section which provides for a struc-
tural representation of texts which is already
well-known following DANES 1974 distinction among
various patterns of thematic progression:
</bodyText>
<table confidence="0.787922368421053">
irlimus,_wim (DERIVED THEME) itlaung_mou
r&amp;SEADING THEMES (LINEAR TNEMATIZAT ION OF 1711ElitS)
DESCENDING RMFKFS,
No. MEDI TYPE Ate.C1T
(34) System System FRAME
- Mikrocomputer FACT
(36) 2 2 NUM
(37) Programmiersprachen Progransdersprache FRAME
Mikrocomputer.Programmiersprache. SACT
(39) Basic Basic FRAME
Mikrocomputer.Programmiersprache.Basic SVAL
(42) SystemSoft SystemSoft FRAME
Basic.Nersteller.SystemSoft SVAL
(46) Pascal-Compiler Pascal-Compiler FRAME
Mikrocomputer.Systeasoftware.Pascal-Compiler SVAL
Pascal FRAME
Mikrocomputer.Programmiersprache.Pascal SVAL
(49) PasdWare PascWare FRAME
Pascal-Compiler.Nersteller.PascWare SVAL
</table>
<subsectionHeader confidence="0.877661">
Pascal.Nersteller.PascWare SVAL
</subsectionHeader>
<bodyText confidence="0.999684181818182">
While expressions #1-#4 of App.A handle the usual
kind of lexical cohesion sequencing in German a
variant form of lexical cohesion is provided for by
#5-#8 with reverse order of sequencing (&amp;quot;... die
Tastatur fuer den Mikrorechner ...&amp;quot; or &amp;quot;... die
Tastatur des Mikros ...&amp;quot;). From this outline one
gets a slight impression of the text parsing
capabilities inherent to word experts on the level
of text cohesion as parsing is performed irrespec-
tive of sentence boundaries on a primarily semantic
level of text processing in a non-expensive way
</bodyText>
<equation confidence="0.570707">
m&apos;&apos;,//;,.1
&amp;quot;Ri
</equation>
<bodyText confidence="0.886734">
Fig.1: Graphical Interpretation of Patterns of
Thematic Progression in Texts
The meaning of the coherence readings provided
in App.B with respect to the construction of the
text graph is stated below:
</bodyText>
<sectionHeader confidence="0.413162" genericHeader="abstract">
SPLITTING RHEMES ( f , f&apos; )
</sectionHeader>
<footnote confidence="0.55205675">
frame f is alpha ancestor to f&apos;
DESCENDING RHEMES ( f , f° , f&amp;quot; )
frame —f is alpha ancestor to f&apos; &amp;
frame f&apos; is alpha ancestor to f&amp;quot;
</footnote>
<page confidence="0.996821">
405
</page>
<table confidence="0.454592545454545">
CONSTANT THEME ( f , str )
frame f is beta ancestor-,string str
SPLITTING THEMES ( f , f&apos;, str )
frame f is alpha ancestor to f &amp;
frame f&apos; is beta ancestor to string str
CASCADING THEMES ( f , f&apos;, f&amp;quot; , , str )
frame f is alpha ancestor f&apos; &amp;
frame f&apos; is beta ancestor to f&amp;quot; &amp;
frame f&amp;quot; is alpha ancestor to f&amp;quot;&apos; &amp;
frame f&amp;quot;&apos; is beta ancestor to string str
SEPARATOR ( f )
</table>
<bodyText confidence="0.999194192982456">
frame f is alpha ancestor to a separator
symbol
We now illustrate the operation of the word
expert designed to handle special cases of text
coherence (App.B) as indicated by text segment [1].
It gets started whenever a frame name has been
identified in the text. Suppose, we have frame set
to &amp;quot;Mikrocomputer&amp;quot; with respect to {06}. Since #1
fails (there is no other frame&apos; available within
transaction {06}), evaluating #2 leads to the
assignment of &amp;quot;Mikrocomputer&amp;quot; to frame&apos; (with
respect to {09}), since according to convention
[2ii] and to the entries of co-text frame&apos; (Mik-
rocomputer/{09)) occurs after frame and is
immediately adjacent to frame (Mikrocomputer/06});
in addition, both, frame as well as frame&apos;, belong
to different transactions. Thus, #2 is evaluated
TRUE. Obviously, #3 also holds TRUE, whereas #4
evaluates to FALSE, since frame&apos; is annotated by
SVAL according to the co-text instead of SACT, as
is required by #4. Note that only the same trans-
action (if #1 holds TRUE) or the next transaction
(if #2 holds TRUE) is examined for appropriate
occurrences of SACTs or SVALs. With respect to #5
the SVAL annotation covers the following parameters
in {09}: frame&apos; (Mikrocomputer), slot&apos; (Mikroprozes-
sor) and sval&amp;quot; (Z-80). Proceeeding to the next
state of the word expert (#6) we have frame (Mik-
rocomputer) but no SVAL or SACT annotation with
respect to {061. Thus, #6 necessarily gets FALSE,
so that, finally, the reading SPLITTING THEMES
(Mikrocomputer , Mikroprozessor , Z-80 ) is gener-
ated.
A second example of the generation of a
coherence reading starts setting frame to &amp;quot;RAM-1&amp;quot;
at position {13} in the co-text. Evaluating #1
leads to the assigment of &amp;quot;Mikrocomputer&amp;quot; to
frame&apos;, since two frames are available within the
same transaction. Both frames being different from
each other one has to follow the FALSE arc of #3.
Similar to the case above, both transaction ele-
ments in {13} are annotated by SVAL, such that #7
as well as #9 are evaluated FALSE, thus reaching
#11. Since frame (RAN-1) has got no slot to which
has been assigned frame&apos; (Mikrocomputer), #11
evaluates to FALSE. With respect to #13 we have
frame&apos; (Mikrocomputer) whose slot&apos; (Hauptspeicher)
has been assigned a slot value which equals frame
(RAM-1). At #14, finally, slot (Groesse) and sval
(48 KByte) are determined with respect to frame
(RAM-1). The coherence reading worked out is
stated as CASCADING_THEMES ( Mikrocomputer ,
Hauptspeicher , RAM-1 , Groesse , 48 KByte ).
Completing the coherence analysis of text
segment [1] at last yields the final expansion of
co-text (note that both word experts described
operate in parallel, as they are activated by the
</bodyText>
<table confidence="0.997253333333333">
same starting criterion):
Jo. READING PARAMETERS
29) SPLITTING THEMES mikr=mcoter.Mikroprozessor.Z -80
13) spurrING THEMF_S Mikroccuputer.Hauptspeicher.RAM-1
CASCADING THEMES Mikrocaccuter.Hauptspeicher.RAM-1.Groesse.48 KByte
18) SPLITTING THEMES Mikroceeputer.Betriebssystem.GP/M
21) SPLITTING_RHEMES Mikrocomater.Peripherie
231 SPLITTIIG_THEXES mikrocacuter.Peripherie.Tastatur
.25) SPLIIIING THEMES mikrocmputer.Peripherie.Bildschinn
28) SPLITTING THEMES Mikrocalputer.Peripherie.Tintenspritzdrucker
.34) SEPARATOR Mikrocavuter
.37) SPLITTING RHEKES Mikrocomuter.Programmiersprache
:48) SPLITTING THEMES Mikrocomputer.Programiersprache.Basic
.42) CASCADING THEMES Mikroomputer.Prograinniersprache.Basic.
Hersteller.SystemSoft
46) SPLITTING Timms Mikrocurfoter.Systensoftware.Pascal-Ompiler
smIrrim THEMES Mikroconpater.Programdersprache.Pascal
49) CASCADING THEMES Mikroconcuter.Systemsoftuere.Pascal -Compiler.
Hersteller.PascWare
) CASCADING THEMES Mikcocomputer.Prcgranniersprache.Paseal.
Hersteller.PaseWare
</table>
<bodyText confidence="0.985559630434783">
The word expert just discussed accounts for a
single frame (here: Mikrocomputer) with nested
slot values of arbitrary depth. This basic descrip-
tion only slightly has to be changed to account for
knowledge structures which are implicitly connected
inthe text. Basically divergent types of coherence
patterns are worked out by word experts operating
on, e.g. aspectual or contrastive coherence rela-
tions (cf. HAHN 1984).
4. The Generation of Text Graphs Based on
Topic/Comment Monitoring
The procedure of text graph generation for
this basic type of thematic progression can be
described as follows. After initialization by
drawing upon the first frame entry occurring in
co-text the text graph gets incrementally con-
structed whenever a new coherence reading is avail-
able in the corresponding data repository. Then,
it has to be determined, whether its first
parameter equals the current node of text graph
which is either the leaf node of the initialized
text graph (when the procedure starts) or the leaf
node of the topic/comment subgraph which has pre-
viously been attached to the text graph. If
equality holds, the coherence reading is attached
to this node of the graph (including some merging
operation to exclude redundant information from the
text graph). If equality does not hold, remaining
siblings or ancestors (in this order) are tried,
until a node equal to the first parameter of the
current coherence reading is found to which the
reading will be attached directly. If no matching
node in the text graph can be found, a new text
graph is constructed which gets initialized by the
current coherence reading. The text graph as the
result of parsing of the text segment [1] with
respect to the coherence readings generated in
sec.3.2 is provided in App.C.
Note that the text graph generation procedure
allows for an interpretation of basic coherence
readings supplied by various word experts in terms
of compound patterns of thematic progression, e.g.
as given by the exposition of splitting rhemes
(DANES 1974). Nevertheless, the whole procedure
essentially depends upon the continuous
availability of reference topics to construct a
</bodyText>
<page confidence="0.997141">
406
</page>
<bodyText confidence="0.984103428571429">
coherent graph. Accordingly, the graph generation
procedure also operates as a kind of topic/comment
monitoring device. Obviously, one also has to take
into account defective topic/comment patterns in
the text under analysis. The SEPARATOR reading is
a basic indicator of interruptions of topic/comment
sequencing. Its evaluation leads to the notion of
topic/comment islands for texts which only par-
tially fulfill the requirements of topic/comment
sequencing. Further coherence readings are gener-
ated by computations based solely on world
knowledge indicators generating
condensed lists of dominant concepts (lists of
topics instead of topic graphs) (HAHN/REIMER 1984).
</bodyText>
<sectionHeader confidence="0.99851" genericHeader="conclusions">
5. Conclusion
</sectionHeader>
<bodyText confidence="0.995660166666667">
In this paper we have argued in favor of a
word expert approach to text parsing based on the
notions of text cohesion and text coherence. Read-
ings word experts work out are represented in text
graphs which illustrate the topic/comment structure
of the underlying texts. Since these graphs repre-
sent the texts thematic structure they lend them-
selves easily for abstracting purposes. Coherency
factors of the text graphs generated, the depth of
each text graph, the amount of actual branching as
compared to possible branching, etc. provide overt
assessment parameters which are intended to control
abstracting procedures based on the topic/comment
structure of texts. In addition, as much effort
will be devoted to graphical modes of system inter-
cation, graph structures are a quite natural and
direct medium of access to TOPIC as a text informa-
tion system.
</bodyText>
<sectionHeader confidence="0.998025" genericHeader="acknowledgments">
ACKNOWLEDGEMENTS
</sectionHeader>
<bodyText confidence="0.999707">
I would like to express my deep gratitude to
U. Reimer for many valuable discussions we had on
the word expert system of TOPIC. R. Hammwoehner
and U. Thiel also made helpful remarks on an ear-
lier version of this paper.
</bodyText>
<sectionHeader confidence="0.999833" genericHeader="references">
REFERENCES
</sectionHeader>
<reference confidence="0.998120509433962">
Critz, J.T.: Frame Based Recognition of Theme
Continuity. In: COLING 82: Proc. of the 9th
Int. Conf. on Computational Linguistics.
Prague: Academia, 1982, pp.71-75.
Danes, F.: Functional Sentence Perspective and the
Organization of the Text. In: F. Danes (ed):
Papers on Functional Sentence Perspective. The
Hague, Paris: Mouton, 1974, pp.106-128.
Dijk, T.A. van: Text and Context: Explorations in
the Semantics and Pragmatics of Discourse.
London, New York: Longman, (1977) 1980 (a).
Dijk, T.A. van: Macrostructures: An Interdiscipli-
nary Study of Global Structures in Discourse,
Interaction, and Cognition. Hillsdale/NJ: L.
Erlbaum, 1980 (b).
Grimes, J.E.: Topic Levels. In: TINLAP-2: Theoreti-
cal Issues in Natural Language Processing-2.
New York: ACM, 1978, pp.104-108.
Hahn, U.: Textual Expertise in Word Experts: An
Approach to Text Parsing Based on Topic/Comment
Monitoring (Extended Version). Konstanz: Univ.
Konstanz, Informationswissenschaft, (May) 1984
(= Bericht TOPIC-9/84).
Hahn, U. &amp; Reimer, U.: Word Expert Parsing: An
Approach to Text Parsing with a Distributed
Lexical Grammar. Konstanz: Univ. Konstanz,
Informationswissenschaft, (Nov) 1983 (= Bericht
TOPIC-6/83). [In: Linguistische Berichte,
No.88, (Dec) 1983, pp.56-78. (in German)]
Hahn, U. &amp; Reimer, U.: Computing Text Constituency:
An Algorithmic Approach to the Generation of
Text Graphs. Konstanz: Univ. Konstanz, Infor-
mationswissenschaft, (April) 1984 (= Bericht
TOPIC-8/84)).
Halliday, M.A.K. / Masan, R.: Cohesion in English.
London: Longman, 1976.
Hobbs, J.R.: Coherence and Coreference. In: Cogni-
tive Science 3. 1979, No.1, pp.67-90.
Hobbs, J.R.: Towards an Understanding of Coherence
in Discourse. In: In: W.G. Lehnert / M.H.
Ringle (eds): Strategies for Natural Language
Processing. Hillsdale/NJ, London: L. Erlbaum,
1982, pp.223-243.
Reimer, U. &amp; Hahn, U.: A Formal Approach to the
Semantics of a Frame Data Model. In IJCAI-83:
Proc. of the 8th Int. Joint Conf. on Artificial
Intelligence. Los Altos/CA: W. Kaufmann, 1983,
pp.337-339.
Small, S. / Rieger, C.: Parsing and Comprehending
with Word Experts (a Theory and its Realiza-
tion). In: W.G. Lehnert / M.H. Ringle (eds):
Strategies for Natural Language Processing.
Hillsdale/NJ: L. Erlbaum, 1982, pp.89-147.
</reference>
<page confidence="0.973046">
407
</page>
<figure confidence="0.998332444444444">
■Ap.
e- •N
-••
•
V
e-
-••
■••■
-4.
</figure>
<page confidence="0.976335">
408
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.987145">TEXTUAL EXPERTISE IN WORD EXPERTS: AN APPROACH TO TEXT PARSING BASED ON TOPIC/COMMENT MONITORING *</title>
<author confidence="0.998349">Udo Hahn</author>
<affiliation confidence="0.974301">Universitaet Konstanz Informationswissenschaft Projekt TOPIC</affiliation>
<address confidence="0.9887325">Postfach 5560 D-7750 Konstanz 1, West Germany</address>
<abstract confidence="0.999621280487805">In this paper prototype versions of two word experts for text analysis are dealt with which demonstrate that word experts are a feasible tool for parsing texts on the level of text cohesion as well as text coherence. The analysis is based on two major knowledge sources: context information is modelled in terms of a frame knowledge base, while the co-text keeps record of the linear sequencing of text analysis. The result of text parsing consists of a text graph reflecting the thematic organization of topics in a text. Experts as a Text Parsing Device This paper outlines an operational representation of the notion of text cohesion and text coherence based on a collection of word experts as central procedural components of a distributed lexical grammar. By text cohesion, we refer to the micro level of textuality as provided, e.g. by reference, substitution, ellipsis, conjunction and lexical cohesion (cf. HALLIDAY/HASAN 1976), whereas text coherence relates to the macro level of textuality as induced, e.g. by patterns of semantic recurrence of topics (thematic progression) of a text (cf. DANES 1974). On a deeper level of propositional analysis of texts further types of semantic development of a text can be examined, e.g. coherence relations, such as contrast, generalization, explanation (cf. HOBBS 1979, HOBBS 1982, DIJK 1980a), basic modes of topic development, such as expansion, shift, or splitting (cf. GRIMES 1978), and operations on different levels of textual macro-structures (DIJK 1980a) or schematized superstructures (DIJK 1980b). The identification of cohesive parts of a text is needed to determine the continuous development and increment of information with regard to single thematic foci, i.e. topics of the text. As we have topic elaborations, shifts, breaks, etc. in texts the extension of topics has to be delimited exactly and different topics have to be related properly. The identification of coherent parts of a text serves this purpose, in that the determination of the coherence relations mentioned above Work reported in this paper is supported by under grant no. contributes to the delimitation of topics and their organization in terms of text grammatical well-formedness considerations. Text graphs are used as the resulting structure of text parsing and serve to represent corresponding relations holding between different topics. The word experts outlined below are part of a genuine text-based parsing formalism incorporating a linguistical level in terms of a distributed text grammar and a computational level in terms of a corresponding text parser (HAHN/REIMER 1983; for an account of the original conception of word expert parsing, cf. SMALL/RIEGER 1982). This paper is intended to provide an empirical assessment of word experts for the purpose of text parsing. We thus arrive at a predominantly functional description of this parsing device neglecting to a large extent its procedural aspects. The word expert parser is currently being implemented as a major system component of TOPIC, a knowledge-based text analysis system which is Intended to provide text summarization (abstracting) facilities on variable layers of informational specifity for German language texts (each approx. 2000-4000 words) dealing with information technology. Word expert construction and modification is supported by a word expert editor using a special expert representation of which are introduced in this paper (for a more detailed account, cf. HAHN/REIMER 1983, HAHN 1984). Word experts are executed by interpretation of their representation language description. TOPIC&apos;s word expert system and its editor are written in the C programming language and are running under UNIX.</abstract>
<title confidence="0.906348">General Remarks about Word Expert Structure and the Knowledge Sources Available for Text Parsing</title>
<abstract confidence="0.958456188461539">A word expert is a procedural agent incorporating linguistic and world knowledge about a particular word. This knowledge is represented declaratively in terms of a decision net whose nodes are constructed of various conditions. Word experts communicate among each other as well as with other system components in order to elaborate a word&apos;s meaning (reading). The conditions at least are tested for two kinds of knowledge sources, the context and the co-text of the corresponding word. 402 Contextis a frame knowledge base which contains the conceptual world knowledge relevant for the texts being processed. Simple conditions to be tested in that knowledge base are: ACTIVE ( f ) : f is an active frame EISA ( f , f&apos; ) : frame f is subordinate or instance of ( f , s ) : frame f has slot s associated to it HAS_SVAL ( f , s , v ) : slot s of frame f has been assigned the slot value v SVAL RANGE ( str , s , f ) : &lt;===&gt; string str is a permitted slot value with respect to slot s of frame f Co-textis a data repository which keeps record of the sequential course of the text analysis actually going on this linear type of information is completely lost in the context, although it is badly needed for various sorts of textual cohesion and coherence phenomena. As co-text necessarily reflects basic properties of the frame representation structures underlying the context, some conditions to be tested in the co-text also take certain aspects of context knowledge into accout: BEFORE ( exp , strl , str2 ) : &lt;==0 strl occurs maximally exp many transactions before str2 in the co-text AFTER ( exp , strl , str2 ) : occurs maximally exp many transactions after str2 in the co-text IN PHRASE ( strl str2 ) : &lt;■==&gt; strl occurs in the same sentence as str2 EQUAL ( strl , str2 ) : strl equals str2 FACT ( f ) : frame f was affected by an activation operation in the knowledge base SACT ( f , s ) : slot s of frame f was affected by an activation operation in the knowledge base SVAL ( f , s , v ) : slot s of frame f was affected by the assignment of a slot value v in the knowledge base SAME TRANSACTION ( f , f&apos; ) : &lt;■=0 frame f and frame f are part of the same transaction with respect to a single text token, i.e. the set of all operations on the frame knowledge base which are carried out due to the readings generated by the word experts which have been put into operation with respect to this token From the above atomic predicates more complex conditions can be generated using common logical operators (AND, OR, NOT). These expressions underlie an implicit existential quantification, unless specified otherwise. During the operation of a word expert the variables of each condition have to be bound in order to work out a truth value. In App.A and App.B underlining of variables indicates that they have already been bound, i.e. the evaluation of the condition in which a variable occurs takes the value already assigned, otherwise a value assignment is made which satisfies the condition being tested. Items stored in the co-text are in the format TOKEN actual form of text word normalized form of text word after morphoreduction or decomposition procedures have operated on it annotation indicating whether TYPE is identified as FRAME a frame name WEXP a word expert name STOP a stop word or NUM a numerical string NIL an unknown text word or TYPE consists of parameters frame . slot . sval are affected by a special type of operation executed in the frame knowledge base which is alternatively denoted by FACT frame activation SACT slot activation SVAL slot value assignment Word Experts for Text Parsing We now turn to an operational representation of the notions introduced in sec.l. The discussion will be limited to well-known cases of textual cohesion and coherence as illustrated by the following text segment: In seiner Grundversion ist der einem 1-80 und KByte RAMausgeruestet laeuft unter CP/M. An Peripheriewerden Bildschirmund em n Tintenspritzdruckerbereitgestellt. Schliesslich verfuegt Systemueber 2 Basic von SystemSoftgeliefert und der Pascal-Compilerkommt von PascWare. [The basic version of the micro is supplied a 1-80, kbyte RAMand runs under CP/M. devicesprovided include a keyboard,a displayand an jet printer.Finally, the systemmakes available 2 languages:Basic is supplied by SystemSoftwhile PascWarefurnished the Pascal compiler.] First, in sec.3.1 we will examine textual cohesion phenomena illustrated by special cases of lexical cohesion, namely the tendency of terms to share the same lexical environment (collocation of terms) and the occurrence of &apos;general nouns&apos; referring to more specific terms (cf. HALLIDAY/HASAN 1976). Then, in sec.3.2 our discussion will be centered around various modes of thematic progression in texts, such as linear thematization of rhemes (cf. DANES 1974) which is often used to establish text coherence (for a similar approach to combine the topic/comment analysis of texts and knowledge representation based on the frame model, 403 cf. CRITZ 1982; computational analysis of textual coherence is also provided by HOBBS 1979, 1982 applying a logical representation model). Word experts capable of handling corresponding textual phenomena are given in App.A and App.B. However, only simplified versions of word experts can be supplied scope to the recognition of the text structures under examination. The representation of the textual analysis also lacks completeness skipping a lot of intermediary steps concerning the operation of other (e.g. phrasal) types of word experts (for more details, cf. HAHN 1984). Word Expert for Text Cohesion We now illustrate the operation of the word expert designed to handle special cases of text cohesion (App.A) as indicated by text segment [1]. Suppose, the analysis of the text has been carried out covering the first 9 text words of [1] as indicated by the entries in co-text: No. TOKEN TYPE (1) In in (2) seiner sein (3) Grundversion (4) ist ist (5) der der (86) Mikrocomputer iiikrocomputer (7) mit mit (8) einem emn (9) Z-80 Z-80 The word expert given in App.A starts running whenever a frame name occurs .in the text. Starting at the occurrence of frame &amp;quot;Mikrocomputer&amp;quot; indiby {06} no reading is worked out. At expert&apos;s input variable &apos;frame&apos; is bound to &amp;quot;Z-80&amp;quot; as it starts again. A test in the knowledge base indicates that &amp;quot;Z-80&amp;quot; is an active frame (by default operation). Proceeding backwards from the current entry in co-text the evaluation of nodes tains an element &amp;quot;em&amp;quot; a morphological variant of which occurs immediately before frame (Z-80) within the same sentence. In addition, we set frame&apos; to &amp;quot;Mikrocomputer&amp;quot; (micro computer) as it is next before frame (with proximity left unconstrained due to &apos;any&apos;) in correspondence with {06}, and it is an active frame, too. The evaluation of node #12, finally, produces FALSE, since frame&apos; (Mikrocomputer) is not a subordinate or instance of frame (2-80) actually, &amp;quot;1-80&amp;quot; is an instance of &amp;quot;Mikroprozessor&amp;quot; (micro processor). Following the FALSE arc of #12 leads to expression #2 which evaluates to FALSE, as frame&apos; (Mikrocomputer) is a frame which roughly consists of the following set of slots (given by indentation) Mikrocomputer micro computer Mikroprozessor mirco processor Peripherie peripheral devices Hauptspeicher main memory Programmiersprache programming language Systemsoftware system software Following the FALSE arc of #2, #3 also evaluates to FALSE as according to the current state of analysis context contains no information indicating that frame&apos; (Mikrocomputer) has a slot&apos; to which has been assigned any slot value (in addition, &amp;quot;Z-80&amp;quot; is not used as a default slot value of any of the slots supplied above). Turning now to the evaluation of #4 slot&apos; has to be identified which must be a slot of frame&apos; (Mikrocomputer) and frame (1-80) must be within the value range of permitted slot for slot&apos; of frame&apos;. Trying sor&amp;quot; for slot&apos; succeeds, as &amp;quot;1-80&amp;quot; is an instance of &amp;quot;Mikroprozessor&amp;quot; and thus (due to model-dependent semantic integrity constraints inherent to the underlying frame data model [REIMER/HAHN 1983]) it is a permitted slot value with respect to slot&apos; (Mikroprozessor) which in turn is a slot of frame&apos; (Mikrocomputer). Thus, the interpretation slot&apos; as &amp;quot;Mikroprozessor&amp;quot; holds. The execution of word experts terminates if a reading has been generated. Readings are labels of leaf nodes of word experts, so following the TRUE arc of #4 the reading SVAL ASSIGN ( Mikrocomputer , , Z-80 ) SVAL ASSIGN* a command issued to the frame knowledge (as is done with every reading referring to cohesion properties of texts) which leads to the assignment of the slot value &amp;quot;Z-80&amp;quot; to the slot &amp;quot;Mikroprozessor&amp;quot; of the frame &amp;quot;Mikrocomputer&amp;quot;. This operation also gets recorded in co-text (SVAL). Therefore, augmented: No. TOKM riTE ANNOT (09) Z-80 2-80 FRAME Mikrocomputer.Mikroprozessor.Z-80 SVAL The next steps of the analysis are skipped, until a second basic type of text cohesion can be examined with regard to {34}: No. WACEN TIME (11) 48 48 KBYte (12) KByte RAM (13) RAM RAM-1.Groesse.48 KByte mikroccmputer.Nauptspeicher.RAM-1 (18) CP/M CP/M (19) . (21) Peripherie Mikrocomputer.Betriebssystem.CP/M (23) Tastatur (25) Bildschirm Peripherie (28) Tintenspritzdrucker Mikrocceputer.Peripherie Tastatur Mikrocomputer.Peripherie.Tastatur Bildschirm Mikroomputer.Peripherie.Bildschirm Tintenspritzdrucker Mikrommdputer.Peripherie.Tintenspritzdrucker (30) . (33) das das (34) System System word expert dealing with text cohesion phenomena again starts running. Its input variable &apos;frame&apos; is set to &amp;quot;System&amp;quot; (system). With respect to #10 the evaluation of BEFORE yields a positive result, since &amp;quot;das&amp;quot; which is an element of pronoun list occurs immediately before frame. As the SWEIGHT INC (f, s) which is also provided in App.A says that the activation weight of slot s of frame f gets incremented. AMMO?</abstract>
<title confidence="0.820503357142857">STOP STOP NIL STOP STOP FRAME STOP STOP FRAME ANNOT NUM WEXP FRAME SVAL SVAL FRAME SVAL WEXP FRAmE SACT FRAME SVAL FRAME SVAL FRAME SVAL WEXP STOP</title>
<abstract confidence="0.983679473684211">FRAME 404 IN PHRASE predicate also evaluates to TRUE, the whole expression #10 turns out to be TRUE. Proceeding backwards to the next frame which is active in the frame knowledge base search stops at position {28}. When more than a single frame within the same transaction may be referred to by word experts the following reference convention is applied: [21] if ANNOT FRAME and an annotation of type FACT exists examine the frame corresponding to FACT [2ii] if ARNDT = FRAME or ANNOT = WEXP and annotations of type SACT or SVAL exist examine f as frame, s as slot, and v as slot value, resp. according to the order of parameters f . s .v In these cases reference of word experts to the frame correponding to the annotation FRAME would cause the provision of insufficient or even false structural information about the context of the current lexical item, although more significant information actually is available in the knowledge sources. In the word expert considered, frame&apos; is set to &amp;quot;Mikrocomputer&amp;quot; according to [211]. Following the TRUE arc of #11 expression #12 states that frame&apos; (Mikrocomputer) must be a subordinate or instance of frame (System) which also holds TRUE. Thus, one gets the reading SHIFT ( System , Mikrocomputer ) which says that the activation weight of frame (System) has to be decremented (thus neutralizing the default activation), while the activation weight of frame&apos; (Mikrocomputer) gets incremented instead. Based on this re-assignment of activation weights the system is protected against invalid activation states, since &amp;quot;Mikrocomputer&amp;quot; is referred to by &amp;quot;System&amp;quot; due to stylistical reasons only and no indication is available that a real topical change in the the text is implied, e.g. some generalization with respect to the whole class of micro computers. We thus have an augmented entry for {34} in co-text together with the result of processing the remainder of [1]: (partial parsing). With respect to other kinds of cohesive phenomena in texts, e.g. pronominal anaphora, conjunction, deixis, word experts are available similar in structure, but adapted to identify corresponding phenomena. Word Expert for Text Coherence We now examine the generation of a second type reading, so-called concerning the structural organization of cohesive parts of a text. Unlike cohesion readings, coherence readings of that type are not issued to the frame knowledge base to instantiate various operations, but are passed over to a data repository in which coherence indicators of different sorts are collected continuously. A device operating on these coherence indicators computes text structure patterns in terms of a text graph which is the final result of text parsing in TOPIC. A text graph constructed that way is composed of a small set of basic coherence relations. We only mention here the application of further relations due to other types of linguistic coherence readings (cf. HAHN 1984) as well as coherence readings from computation procedures based exclusively on configuration data from the frame knowledge base (HABW/REIMER 1984). One common type of coherence relations is accounted for in the remainder of section which provides for a structural representation of texts which is already well-known following DANES 1974 distinction among various patterns of thematic progression: THEME</abstract>
<note confidence="0.694694846153846">THEMES(LINEAR TNEMATIZAT ION OF 1711ElitS) DESCENDING RMFKFS, No. MEDI TYPE Ate.C1T (34) System System FRAME Mikrocomputer (36) 2 2 NUM (37) Programmiersprachen Progransdersprache FRAME Mikrocomputer.Programmiersprache. SACT (39) Basic Basic FRAME Mikrocomputer.Programmiersprache.Basic SVAL (42) SystemSoft SystemSoft FRAME Basic.Nersteller.SystemSoft SVAL (46) Pascal-Compiler Pascal-Compiler FRAME</note>
<title confidence="0.880336">Mikrocomputer.Systeasoftware.Pascal-Compiler SVAL</title>
<author confidence="0.948579">Pascal FRAME</author>
<title confidence="0.5591285">Mikrocomputer.Programmiersprache.Pascal SVAL (49) PasdWare PascWare FRAME Pascal-Compiler.Nersteller.PascWare SVAL Pascal.Nersteller.PascWare SVAL</title>
<abstract confidence="0.98683403626943">While expressions #1-#4 of App.A handle the usual kind of lexical cohesion sequencing in German a variant form of lexical cohesion is provided for by Tastatur fuer den Mikrorechner ...&amp;quot; or &amp;quot;... die Tastatur des Mikros ...&amp;quot;). From this outline one gets a slight impression of the text parsing capabilities inherent to word experts on the level of text cohesion as parsing is performed irrespective of sentence boundaries on a primarily semantic level of text processing in a non-expensive way Fig.1: Graphical Interpretation of Patterns of Thematic Progression in Texts The meaning of the coherence readings provided in App.B with respect to the construction of the text graph is stated below: SPLITTING RHEMES ( f , f&apos; ) frame f is alpha ancestor to f&apos; DESCENDING RHEMES ( f , f° , f&amp;quot; ) is alpha ancestor to f&apos; &amp; frame f&apos; is alpha ancestor to f&amp;quot; 405 CONSTANT THEME ( f , str ) f is beta str SPLITTING THEMES ( f , f&apos;, str ) frame f is alpha ancestor to f &amp; frame f&apos; is beta ancestor to string str CASCADING THEMES ( f , f&apos;, f&amp;quot; , , str ) frame f is alpha ancestor f&apos; &amp; frame f&apos; is beta ancestor to f&amp;quot; &amp; frame f&amp;quot; is alpha ancestor to f&amp;quot;&apos; &amp; frame f&amp;quot;&apos; is beta ancestor to string str SEPARATOR ( f ) frame f is alpha ancestor to a separator symbol We now illustrate the operation of the word expert designed to handle special cases of text coherence (App.B) as indicated by text segment [1]. It gets started whenever a frame name has been identified in the text. Suppose, we have frame set to &amp;quot;Mikrocomputer&amp;quot; with respect to {06}. Since #1 fails (there is no other frame&apos; available within transaction {06}), evaluating #2 leads to the assignment of &amp;quot;Mikrocomputer&amp;quot; to frame&apos; (with respect to {09}), since according to convention [2ii] and to the entries of co-text frame&apos; (Mikrocomputer/{09)) occurs after frame and is immediately adjacent to frame (Mikrocomputer/06}); in addition, both, frame as well as frame&apos;, belong to different transactions. Thus, #2 is evaluated TRUE. Obviously, #3 also holds TRUE, whereas #4 evaluates to FALSE, since frame&apos; is annotated by SVAL according to the co-text instead of SACT, as is required by #4. Note that only the same transaction (if #1 holds TRUE) or the next transaction (if #2 holds TRUE) is examined for appropriate occurrences of SACTs or SVALs. With respect to #5 the SVAL annotation covers the following parameters in {09}: frame&apos; (Mikrocomputer), slot&apos; (Mikroprozessor) and sval&amp;quot; (Z-80). Proceeeding to the next state of the word expert (#6) we have frame (Mikrocomputer) but no SVAL or SACT annotation with respect to {061. Thus, #6 necessarily gets FALSE, so that, finally, the reading SPLITTING THEMES (Mikrocomputer , Mikroprozessor , Z-80 ) is generated. A second example of the generation of a coherence reading starts setting frame to &amp;quot;RAM-1&amp;quot; at position {13} in the co-text. Evaluating #1 leads to the assigment of &amp;quot;Mikrocomputer&amp;quot; to frame&apos;, since two frames are available within the same transaction. Both frames being different from each other one has to follow the FALSE arc of #3. Similar to the case above, both transaction elements in {13} are annotated by SVAL, such that #7 as well as #9 are evaluated FALSE, thus reaching has been assigned frame&apos; (Mikrocomputer), #11 evaluates to FALSE. With respect to #13 we have frame&apos; (Mikrocomputer) whose slot&apos; (Hauptspeicher) has been assigned a slot value which equals frame (RAM-1). At #14, finally, slot (Groesse) and sval (48 KByte) are determined with respect to frame (RAM-1). The coherence reading worked out is stated as CASCADING_THEMES ( Mikrocomputer , Hauptspeicher , RAM-1 , Groesse , 48 KByte ). Completing the coherence analysis of text segment [1] at last yields the final expansion of co-text (note that both word experts described operate in parallel, as they are activated by the same starting criterion): PARAMETERS 29) SPLITTING THEMES mikr=mcoter.Mikroprozessor.Z -80 13) Mikroccuputer.Hauptspeicher.RAM-1 CASCADING THEMES Mikrocaccuter.Hauptspeicher.RAM-1.Groesse.48 KByte 18) Mikroceeputer.Betriebssystem.GP/M 21) SPLITTING_RHEMES Mikrocomater.Peripherie 231 SPLITTIIG_THEXES mikrocacuter.Peripherie.Tastatur mikrocmputer.Peripherie.Bildschinn 28) Mikrocalputer.Peripherie.Tintenspritzdrucker .34) SEPARATOR Mikrocavuter .37) Mikrocomuter.Programmiersprache :48) SPLITTING THEMES Mikrocomputer.Programiersprache.Basic .42) Mikroomputer.Prograinniersprache.Basic. Hersteller.SystemSoft 46) Mikrocurfoter.Systensoftware.Pascal-Ompiler Mikroconpater.Programdersprache.Pascal 49) Mikroconcuter.Systemsoftuere.Pascal -Compiler. Hersteller.PascWare ) CASCADING THEMES Mikcocomputer.Prcgranniersprache.Paseal. Hersteller.PaseWare The word expert just discussed accounts for a single frame (here: Mikrocomputer) with nested slot values of arbitrary depth. This basic description only slightly has to be changed to account for knowledge structures which are implicitly connected inthe text. Basically divergent types of coherence patterns are worked out by word experts operating on, e.g. aspectual or contrastive coherence relations (cf. HAHN 1984). Generation of Text Graphs Based on Topic/Comment Monitoring The procedure of text graph generation for this basic type of thematic progression can be described as follows. After initialization by drawing upon the first frame entry occurring in co-text the text graph gets incrementally constructed whenever a new coherence reading is available in the corresponding data repository. Then, it has to be determined, whether its first parameter equals the current node of text graph which is either the leaf node of the initialized text graph (when the procedure starts) or the leaf node of the topic/comment subgraph which has previously been attached to the text graph. If equality holds, the coherence reading is attached to this node of the graph (including some merging operation to exclude redundant information from the text graph). If equality does not hold, remaining siblings or ancestors (in this order) are tried, until a node equal to the first parameter of the current coherence reading is found to which the reading will be attached directly. If no matching node in the text graph can be found, a new text graph is constructed which gets initialized by the current coherence reading. The text graph as the result of parsing of the text segment [1] with respect to the coherence readings generated in sec.3.2 is provided in App.C. Note that the text graph generation procedure allows for an interpretation of basic coherence readings supplied by various word experts in terms of compound patterns of thematic progression, e.g. as given by the exposition of splitting rhemes (DANES 1974). Nevertheless, the whole procedure essentially depends upon the continuous availability of reference topics to construct a 406 coherent graph. Accordingly, the graph generation procedure also operates as a kind of topic/comment monitoring device. Obviously, one also has to take into account defective topic/comment patterns in the text under analysis. The SEPARATOR reading is a basic indicator of interruptions of topic/comment sequencing. Its evaluation leads to the notion of topic/comment islands for texts which only partially fulfill the requirements of topic/comment sequencing. Further coherence readings are generated by computations based solely on world knowledge indicators generating condensed lists of dominant concepts (lists of topics instead of topic graphs) (HAHN/REIMER 1984). In this paper we have argued in favor of a word expert approach to text parsing based on the notions of text cohesion and text coherence. Readings word experts work out are represented in text graphs which illustrate the topic/comment structure of the underlying texts. Since these graphs represent the texts thematic structure they lend themselves easily for abstracting purposes. Coherency factors of the text graphs generated, the depth of each text graph, the amount of actual branching as compared to possible branching, etc. provide overt assessment parameters which are intended to control abstracting procedures based on the topic/comment structure of texts. In addition, as much effort will be devoted to graphical modes of system intercation, graph structures are a quite natural and direct medium of access to TOPIC as a text information system. ACKNOWLEDGEMENTS I would like to express my deep gratitude to U. Reimer for many valuable discussions we had on the word expert system of TOPIC. R. Hammwoehner and U. Thiel also made helpful remarks on an earlier version of this paper.</abstract>
<note confidence="0.941547769230769">REFERENCES Critz, J.T.: Frame Based Recognition of Theme Continuity. In: COLING 82: Proc. of the 9th Int. Conf. on Computational Linguistics. Prague: Academia, 1982, pp.71-75. Danes, F.: Functional Sentence Perspective and the Organization of the Text. In: F. Danes (ed): Papers on Functional Sentence Perspective. The Hague, Paris: Mouton, 1974, pp.106-128. Dijk, T.A. van: Text and Context: Explorations in the Semantics and Pragmatics of Discourse. London, New York: Longman, (1977) 1980 (a). Dijk, T.A. van: Macrostructures: An Interdisciplinary Study of Global Structures in Discourse, Interaction, and Cognition. Hillsdale/NJ: L. Erlbaum, 1980 (b). Grimes, J.E.: Topic Levels. In: TINLAP-2: Theoretical Issues in Natural Language Processing-2. New York: ACM, 1978, pp.104-108. Hahn, U.: Textual Expertise in Word Experts: An Approach to Text Parsing Based on Topic/Comment Monitoring (Extended Version). Konstanz: Univ. Konstanz, Informationswissenschaft, (May) 1984 (= Bericht TOPIC-9/84). Hahn, U. &amp; Reimer, U.: Word Expert Parsing: An Approach to Text Parsing with a Distributed</note>
<affiliation confidence="0.953281">Lexical Grammar. Konstanz: Univ. Konstanz,</affiliation>
<address confidence="0.784372">Informationswissenschaft, (Nov) 1983 (= Bericht</address>
<note confidence="0.705100805555555">TOPIC-6/83). [In: Linguistische Berichte, No.88, (Dec) 1983, pp.56-78. (in German)] Hahn, U. &amp; Reimer, U.: Computing Text Constituency: An Algorithmic Approach to the Generation of Text Graphs. Konstanz: Univ. Konstanz, Informationswissenschaft, (April) 1984 (= Bericht TOPIC-8/84)). Halliday, M.A.K. / Masan, R.: Cohesion in English. London: Longman, 1976. Hobbs, J.R.: Coherence and Coreference. In: Cognitive Science 3. 1979, No.1, pp.67-90. Hobbs, J.R.: Towards an Understanding of Coherence in Discourse. In: In: W.G. Lehnert / M.H. Ringle (eds): Strategies for Natural Language Processing. Hillsdale/NJ, London: L. Erlbaum, 1982, pp.223-243. Reimer, U. &amp; Hahn, U.: A Formal Approach to the Semantics of a Frame Data Model. In IJCAI-83: Proc. of the 8th Int. Joint Conf. on Artificial Intelligence. Los Altos/CA: W. Kaufmann, 1983, pp.337-339. Small, S. / Rieger, C.: Parsing and Comprehending with Word Experts (a Theory and its Realization). In: W.G. Lehnert / M.H. Ringle (eds): Strategies for Natural Language Processing. Hillsdale/NJ: L. Erlbaum, 1982, pp.89-147. 407 ■Ap. -•• • V e- -•• ■••■ -4. 408</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>J T Critz</author>
</authors>
<title>Frame Based Recognition of Theme Continuity. In:</title>
<date>1982</date>
<booktitle>COLING 82: Proc. of the 9th Int. Conf. on Computational Linguistics.</booktitle>
<pages>71--75</pages>
<location>Prague: Academia,</location>
<marker>Critz, 1982</marker>
<rawString>Critz, J.T.: Frame Based Recognition of Theme Continuity. In: COLING 82: Proc. of the 9th Int. Conf. on Computational Linguistics. Prague: Academia, 1982, pp.71-75.</rawString>
</citation>
<citation valid="true">
<authors>
<author>F Danes</author>
</authors>
<title>Functional Sentence Perspective and the Organization of the Text. In: F. Danes (ed): Papers on Functional Sentence Perspective. The Hague,</title>
<date>1974</date>
<pages>106--128</pages>
<location>Paris: Mouton,</location>
<marker>Danes, 1974</marker>
<rawString>Danes, F.: Functional Sentence Perspective and the Organization of the Text. In: F. Danes (ed): Papers on Functional Sentence Perspective. The Hague, Paris: Mouton, 1974, pp.106-128.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T A van  Dijk</author>
</authors>
<title>Text and Context: Explorations in the Semantics and Pragmatics of Discourse.</title>
<date>1977</date>
<location>London, New York: Longman,</location>
<marker>Dijk, 1977</marker>
<rawString>Dijk, T.A. van: Text and Context: Explorations in the Semantics and Pragmatics of Discourse. London, New York: Longman, (1977) 1980 (a).</rawString>
</citation>
<citation valid="true">
<authors>
<author>T A van  Dijk</author>
</authors>
<title>Macrostructures: An Interdisciplinary Study of Global Structures</title>
<date>1980</date>
<booktitle>in Discourse, Interaction, and Cognition. Hillsdale/NJ: L. Erlbaum,</booktitle>
<marker>Dijk, 1980</marker>
<rawString>Dijk, T.A. van: Macrostructures: An Interdisciplinary Study of Global Structures in Discourse, Interaction, and Cognition. Hillsdale/NJ: L. Erlbaum, 1980 (b).</rawString>
</citation>
<citation valid="true">
<authors>
<author>J E Grimes</author>
</authors>
<title>Topic Levels. In: TINLAP-2: Theoretical Issues</title>
<date>1978</date>
<booktitle>in Natural Language Processing-2.</booktitle>
<pages>104--108</pages>
<publisher>ACM,</publisher>
<location>New York:</location>
<marker>Grimes, 1978</marker>
<rawString>Grimes, J.E.: Topic Levels. In: TINLAP-2: Theoretical Issues in Natural Language Processing-2. New York: ACM, 1978, pp.104-108.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
</authors>
<title>Textual Expertise in Word Experts: An Approach to Text Parsing Based on Topic/Comment Monitoring (Extended Version).</title>
<date>1984</date>
<location>Konstanz: Univ. Konstanz, Informationswissenschaft,</location>
<note>(= Bericht TOPIC-9/84).</note>
<marker>Hahn, 1984</marker>
<rawString>Hahn, U.: Textual Expertise in Word Experts: An Approach to Text Parsing Based on Topic/Comment Monitoring (Extended Version). Konstanz: Univ. Konstanz, Informationswissenschaft, (May) 1984 (= Bericht TOPIC-9/84).</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>U Reimer</author>
</authors>
<title>Word Expert Parsing: An Approach to Text Parsing with a Distributed Lexical Grammar.</title>
<date>1983</date>
<booktitle>(= Bericht TOPIC-6/83). [In: Linguistische Berichte, No.88,</booktitle>
<pages>56--78</pages>
<location>Konstanz: Univ. Konstanz, Informationswissenschaft,</location>
<note>in German</note>
<marker>Hahn, Reimer, 1983</marker>
<rawString>Hahn, U. &amp; Reimer, U.: Word Expert Parsing: An Approach to Text Parsing with a Distributed Lexical Grammar. Konstanz: Univ. Konstanz, Informationswissenschaft, (Nov) 1983 (= Bericht TOPIC-6/83). [In: Linguistische Berichte, No.88, (Dec) 1983, pp.56-78. (in German)]</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Hahn</author>
<author>U Reimer</author>
</authors>
<title>Computing Text Constituency: An Algorithmic Approach to the Generation of Text Graphs.</title>
<date>1984</date>
<location>Konstanz: Univ. Konstanz, Informationswissenschaft,</location>
<note>(= Bericht TOPIC-8/84)).</note>
<marker>Hahn, Reimer, 1984</marker>
<rawString>Hahn, U. &amp; Reimer, U.: Computing Text Constituency: An Algorithmic Approach to the Generation of Text Graphs. Konstanz: Univ. Konstanz, Informationswissenschaft, (April) 1984 (= Bericht TOPIC-8/84)).</rawString>
</citation>
<citation valid="true">
<authors>
<author>M A K Masan Halliday</author>
<author>R</author>
</authors>
<title>Cohesion in English.</title>
<date>1976</date>
<location>London: Longman,</location>
<marker>Halliday, R, 1976</marker>
<rawString>Halliday, M.A.K. / Masan, R.: Cohesion in English. London: Longman, 1976.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
</authors>
<title>Coherence and Coreference. In:</title>
<date>1979</date>
<journal>Cognitive Science</journal>
<volume>3</volume>
<pages>67--90</pages>
<marker>Hobbs, 1979</marker>
<rawString>Hobbs, J.R.: Coherence and Coreference. In: Cognitive Science 3. 1979, No.1, pp.67-90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J R Hobbs</author>
</authors>
<title>Towards an Understanding of Coherence in Discourse. In: In:</title>
<date>1982</date>
<booktitle>W.G. Lehnert / M.H. Ringle (eds): Strategies for Natural Language Processing.</booktitle>
<pages>223--243</pages>
<location>Hillsdale/NJ, London:</location>
<marker>Hobbs, 1982</marker>
<rawString>Hobbs, J.R.: Towards an Understanding of Coherence in Discourse. In: In: W.G. Lehnert / M.H. Ringle (eds): Strategies for Natural Language Processing. Hillsdale/NJ, London: L. Erlbaum, 1982, pp.223-243.</rawString>
</citation>
<citation valid="true">
<authors>
<author>U Reimer</author>
<author>U Hahn</author>
</authors>
<title>A Formal Approach to the Semantics of a Frame Data Model. In</title>
<date>1983</date>
<booktitle>IJCAI-83: Proc. of the 8th Int. Joint Conf. on Artificial Intelligence. Los Altos/CA:</booktitle>
<pages>337--339</pages>
<publisher>W. Kaufmann,</publisher>
<marker>Reimer, Hahn, 1983</marker>
<rawString>Reimer, U. &amp; Hahn, U.: A Formal Approach to the Semantics of a Frame Data Model. In IJCAI-83: Proc. of the 8th Int. Joint Conf. on Artificial Intelligence. Los Altos/CA: W. Kaufmann, 1983, pp.337-339.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Rieger Small</author>
<author>C</author>
</authors>
<title>Parsing and Comprehending with Word Experts (a Theory and its Realization). In:</title>
<date>1982</date>
<booktitle>W.G. Lehnert / M.H. Ringle (eds): Strategies for Natural Language Processing. Hillsdale/NJ: L. Erlbaum,</booktitle>
<pages>89--147</pages>
<marker>Small, C, 1982</marker>
<rawString>Small, S. / Rieger, C.: Parsing and Comprehending with Word Experts (a Theory and its Realization). In: W.G. Lehnert / M.H. Ringle (eds): Strategies for Natural Language Processing. Hillsdale/NJ: L. Erlbaum, 1982, pp.89-147.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>