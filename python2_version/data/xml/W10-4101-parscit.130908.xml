<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000385">
<title confidence="0.998333">
Word Segmentation needs change
— From a linguist’s view
</title>
<author confidence="0.999123">
Zhendong Dong Qiang Dong Changling Hao
</author>
<affiliation confidence="0.7848455">
Research Center of Computer Canada Keentime Inc. Canada Keentime Inc.
&amp; Language Engineering, CAS dongqiang@keenage.com support@keenage.com
</affiliation>
<email confidence="0.99488">
dzd@keenage.com
</email>
<sectionHeader confidence="0.99858" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999848958333333">
The authors propose that we need some
change for the current technology in
Chinese word segmentation. We should
have separate and different phases in the
so-called segmentation. First of all, we
need to limit segmentation only to the
segmentation of Chinese characters in-
stead of the so-called Chinese words. In
character segmentation, we will extract
all the information of each character.
Then we start a phase called Chinese
morphological processing (CMP). The
first step of CMP is to do a combination
of the separate characters and is then fol-
lowed by post-segmentation processing,
including all sorts of repetitive structures,
Chinese-style abbreviations, recognition
of pseudo-OOVs and their processing,
etc. The most part of post-segmentation
processing may have to be done by some
rule-based sub-routines, thus we need
change the current corpus-based meth-
odology by merging with rule-based
technique.
</bodyText>
<sectionHeader confidence="0.999629" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999765181818182">
Chinese word segmentation seems to be an old
grandma’s story. We very often hear some con-
tradictory remarks about its advance. Most of
reports from the evaluation tasks always gave us
positive, or even impressive results, such as over
96% accuracy, but some reports were rather
negative and expressed their deep concern. They
claimed that word segmentation was still entan-
gled in a difficult situation and no breakthrough
in real applications. By careful and longtime ob-
servation, the incompetence is usually caused by
the coarseness in the currently prevalent tech-
nology.
We carefully observed some Chinese-English
MT systems and found some errors were caused
even in the very early stage of the processing,
that is, in the stage of word segmentation. No
matter the MT is statistics-based or rule-based,
they have their Achilles&apos; heel in the segmenta-
tion stage. Can today’s prevalent technology
effectively cope with the problem? Or do we
need some change? The present technology is
characterized by its “trilogy”, that is, “corpora +
statistics (ML) + evaluation”. We regret to say
that many researchers today may be indulged in
methodology itself rather than the language they
have to target. They are enchanted by the scores
and ranks, but they forget the object they are
processing.
Therefore we propose that a Chinese morpho-
logical processing (CMP) should be taken to
replace the current Chinese word segmentation.
CMP includes the following components:
</bodyText>
<listItem confidence="0.9994846">
• Chinese character processing (CCP)
• Initial combination of Chinese multi-
character expressions (CMEs)
• Morphological structure processing
(MSP)
</listItem>
<sectionHeader confidence="0.753286" genericHeader="method">
2 Chinese character processing
</sectionHeader>
<subsectionHeader confidence="0.91881">
2.1 “Word” in Chinese
</subsectionHeader>
<bodyText confidence="0.999953825">
“Word or no word” may be an even older story
in Chinese linguistic circle. One assertion about
Chinese words may be quite popular, even to
most of western researchers in the NLP circle,
that is, different from English or other western
languages, there is no space between Chinese
words and thus segmentation of a running text
into words is necessary for Chinese processing.
However, do words really exist in Chinese? It is
still a vexing and controversial issue. Some
Chinese grammarians argue that in Chinese there
are no words at all, but there are only characters
instead and some express their strong objection.
What is a Chinese “word”? It was reported
that the concept of “word” had not been intro-
duced into China until the very beginning of the
last century. In fact word is alien to Chinese. At
least the concept of word in Chinese is rather
vague. In Chinese there are no clear-cut distinc-
tion between characters and so-called word, ei-
ther between multi-character words and those
that are similar to English MWE. Ordinary Eng-
lish people may be surprised if they are told that
even in popular Chinese dictionaries there are no
entries equivalent to English “pork (猪肉)”,
“beef 牛肉)”, “egg (鸡蛋)”, “rain (verb 下雨)”,
“snow (verb 下雪)”, but there are entries equiva-
lent to English “lower limbs(下肢)”, “give or-
ders (下令)”, “appendicitis (盲肠炎)”. There is
somewhat arbitrariness in recognition of Chinese
“words”, so the vocabulary in different Chinese
dictionaries may vary very greatly. Does a dic-
tionary take usage frequency into account when
it decides on its entries? Let’s compare their oc-
currence with the following entries in the dic-
tionary as shown in Table 1. Let’s compare the
occurrence with the following entries in different
dictionaries and in reference to Google’s results.
In Table 1, “-” indicates that the entry does not
occur and “+” indicates the entry occurs.
</bodyText>
<table confidence="0.971004153846154">
Entries 3 Popular dictionaries Results in
Google
身为 - 现汉1 32,500,000
- 规范2
- 新时代汉英3
身亡 - 现汉 24,300,000
+ 规范
- 新时代汉英
身居 - 现汉 16,600,000
+ 规范
- 新时代汉英
1 Modern Chinese Dictionary
2 Modern Chinese Standard Dictionary
3 New Age Chinese-English Dictionary
身故 + 现汉 6,760,000
- 规范
+ 新时代汉英
身教 + 现汉 497,000
+ 规范
+ 新时代汉英
身历 - 现汉 409,000
+ 规范
+ 新时代汉英
身受 + 现汉 900,000
+ 规范
+ 新时代汉英
</table>
<tableCaption confidence="0.9555565">
Table 1. Comparison of entry occurrence in
dictionaries
</tableCaption>
<bodyText confidence="0.999918555555556">
In a word, since “word” in Chinese is rather
vague, what is a better tactics we should take
then? The present word segmentation is bur-
dened too heavily. In comparison with English
tokenization, it goes too far. Does English to-
kenization deal with MWEs, such as “United
nations”, “free of charge”, “first lady”? Why
does Chinese word segmentation have to deal
with Chinese multi-character “word”?
</bodyText>
<subsectionHeader confidence="0.998488">
2.2 Chinese character processing (CCP)
</subsectionHeader>
<bodyText confidence="0.999947307692308">
We propose that the real task of so-called Chi-
nese word segmentation is to segment a running
text into single characters with spaces between.
We call this processing Chinese character proc-
essing (CCP). CCP is in parallel with English
tokenization. In most cases CCP can achieve
100% accuracy. The most important task for
CCP is not only to segment a text, but also to
obtain various kinds of information (syntactic,
semantic) of every character. What will be fol-
lowed depends on the tasks to be designated.
Usually a demand-led morphological processing
will be taken.
</bodyText>
<sectionHeader confidence="0.998111" genericHeader="method">
3 Initial combination
</sectionHeader>
<bodyText confidence="0.999956571428571">
In most cases, what we called initial combina-
tion of Chinese multi-character expressions
(CMEs) should be followed indispensably. It
may be either shallow or deep, and may be done
either with the help of a lexical database or a
corpus, and the longest matching may be the
frequently-used technique.
</bodyText>
<sectionHeader confidence="0.995551" genericHeader="method">
4 Morphological structure processing
(MSP)
</sectionHeader>
<subsectionHeader confidence="0.999565">
4.1 Pseudo-OOVs
</subsectionHeader>
<bodyText confidence="0.999969275862069">
The first task of MSP is to recognize and process
Chinese OOVs. What are OOVs in English?
Normally if a string between two spaces in a
running text does not exist in the lexical
database or the corpus the processing system is
using, this string is taken as an OOV. However,
what is an OOV in Chinese then? It is really not
so easy to define an OOV in Chinese as in
English. The recognition of English OOVs may
be done in the phase of tokenization, but the
recognition of Chinese OOVs should, in a strict
sense, not be done in so-called word
segmentation. It should be regarded as a special
phase of the morphological processing. It is
commonly acknowledged that OOV recognition
is the most serious factor that impairs the
performance of current Chinese word
segmentation.
We may first look at some instances of ma-
chine translation results and find the actual prob-
lems. The reason why we use MT systems to test
and evaluate segmentation is because this will
make it explicit and easy for human to assess.
One error in segmentation makes a 100% failure
in translation. In our examples, the translation (a)
is done by a statistical MT system and the trans-
lation (b) by a rule-based MT system. (C) is hu-
man translation, which may help make compari-
son and find the errors made by MT.
</bodyText>
<listItem confidence="0.982886">
1. XNKA力挺MA:FP .I 2020`&apos;VA7L�o
(a) Americans even behind the bid to host
the 2020 Olympic Games in Nanjing.
(b) American people&apos;s strength holds out
in Nanjing and bids for the 2020 Olympic
Games.
(c) Americans fully backed up Nanjing’s
bid to host the 2020 Olympic Games.
</listItem>
<bodyText confidence="0.969206923076923">
Chinese OOVs can be roughly categorized
into two classes, one is true OOVs and the other
is pseudo-OOVs. The recognition and process-
ing of true OOVs can be done as English OOVs
are treated in English. However, the recognition
and processing of Chinese pseudo-OOVs should
be done by a special processing module. Chinese
pseudo-OOVs includes two types: plain pseudo-
OOVs, such as “)JAV, “MU, “TMC”, “i 4”,
“-6#”, “�#”, and abbreviated pseudo-OOVs,
such as “��”, “V “NT”, “��”, “4k12
rp,L`”, “-RA .I ”, 7L1f , AM&apos; .I ”, “ 0 *�&apos; l ”, “ rp Z
“*049”,
</bodyText>
<listItem confidence="0.876054">
• Plain pseudo-OOVs
</listItem>
<bodyText confidence="0.999819153846154">
A pseudo-OOV is a combinatory string of
Chinese characters in which each character car-
ries one of its original meanings and the way of
combination conforms to Chinese grammatical
pattern. In the above Chinese sentence the word
“)JAV is a typical pseudo-OOV. “)JAV is a
combination of two characters, “)J” and “J;V.
“)J” has four meanings, one of which is “do
one’s best”. “J;V has six meanings, one of which
is “back up”. Originally in Chinese dictionaries
we can find the following expressions similar to
the pattern of “)J�”, such as “)Ji”, “)J�”,
“)J�”, “)J�”, “)J�”, “)J�”, “)J�”, “)J
�”, “)J�”, “)J�”, “)J�”, “)J�”. In all
these expressions the character “)J” carries the
same meaning as that in “)JJ;V, and the second
characters in the combinations are all actions.
Therefore the expression “)JJ;V is a grammati-
cal and meaningful pseudo-OOV. It should be
noticed that this kind of pseudo-OOV is highly
productive in Chinese. In addition to all the dic-
tionary entries that we listed above, we found
“)JIVlf,(to strongly state)”and “)Jr)-L(to strongly
resist)” are already used in the web. Its highly
occurrence in real texts calls our special atten-
tion. Let’s see how MT will tackle them poorly.
</bodyText>
<listItem confidence="0.990374857142857">
2. PIPA力陈�AVAo
(a) Chen multiple defense of human
doubt.
(b) Many old doubtful points of the man-
power of pleading.
(c) The pleader argued and showed many
doubtful points.
</listItem>
<bodyText confidence="0.997314666666667">
We wonder how the current technique of
segmentation tackles the problem. We are not
sure how one error in a segmentation effect the
score in Bakeoff.
Let’s look at two more examples and have a
brief discussion of them.
</bodyText>
<equation confidence="0.402232">
3.据邻居反映,案发当天中午有一个快餐
0h905来过被害人家中。
</equation>
<listItem confidence="0.983851411764706">
(a) According to neighbors reflected the
incident that day at noon there is a fast food
take-Lang came to the victim&apos;s home.
(b) According to the information of
neighbour&apos;s, a fast food takes out the my
darling to been to victim&apos;s home at noon on
the day when the case happened.
(c) According to the neighbors, at noon on
the same day a fast food takeout boy came
to the victim’s house.
4. 一个官员被���刺死了。
(a) One officer was stabbed to death the
women pedicure.
(b) An officer is trimmed the foot daughter
and assassinated.
(c) An official was stabbed to death by the
girl pedicurist.
</listItem>
<bodyText confidence="0.999164769230769">
All the four erroneous MT translations above
originate from the so-called recognition of
OOVs “外卖郎” and “修脚女” in the segmenta-
tion. The MT systems might make out “ 外
卖”and “郎” or “修脚” and “女” separately, but
fail to recognize their combinations. The combi-
nation pattern of these two plain pseudo-OOVs
is a very typical and popular one in Chinese, just
similar to the suffix “-er” or “-or” in English to
derive a noun of a doer. “外卖郎” is a combina-
tion of “外卖”(takeout) and “郎”(boy). When a
MT failed to tackle it, the translation would be
so poor.
</bodyText>
<listItem confidence="0.685014">
• Abbreviated pseudo-OOVs
</listItem>
<bodyText confidence="0.995870533333333">
Different from English abbreviations or acro-
nyms, Chinese abbreviations in essence are con-
tracted forms of words and expressions. The
contraction is mainly related to three factors: (1)
maximal preservation of the original meaning; (2)
possible maintenance of Chinese grammatical
structural pattern; (3) consideration of accept-
ableness of rhythm. Let’s take “维稳办” for ex-
ample. “维稳办” is the contraction of
“维护稳定办公室”. The literal translation of the
expression is “maintain stability office”. Thus
the first part of the expression “维护稳定” is
contracted to “维稳”, and the second part is con-
tracted to “办”. “维护稳定” grammatically is a
“verb + object” structure while “维稳” can be
regarded as the same grammatical structure.
Grammatically “办公室” is modified by
“维护稳定”, and in the contraction the word
“办” is also modified by the contraction “维稳”.
As for acceptableness of rhythm, “维稳办” is a
three-character expression, in which the first two
are a “verb + object structure and the last is sin-
gle. The structure of “2-character verb + 1-
character noun” is a highly-productive pattern of
noun expression in Chinese. So it is desirable to
process this type of structures before syntactic
processing. As the structure can usually be pat-
ternized, it is possible to have them well-
processed. We propose that we should deal with
it in the morphological processing stage.
</bodyText>
<subsectionHeader confidence="0.989614">
4.2 Repetitive structures
</subsectionHeader>
<bodyText confidence="0.999931333333333">
First let’s look at a MT translation and see what
has happened when a Chinese repetitive struc-
ture is ill-processed.
</bodyText>
<listItem confidence="0.9778026">
5. 你来%Y%Y.9,太小了。
(a) Come see Chuan Chuan, too small.
(b) You come to wear looking, it is too
small.
(c) Come and try on, it is too small.
</listItem>
<bodyText confidence="0.998069523809524">
The above two erroneous MT translations (a)
and (b) originate from the failure in dealing with
a typical verb structural pattern for expression to
urge someone to have a try. This pattern is:
“VV看”, its actual meaning is “have a try” and
“to see if ...”. The literal translation of the above
instance “穿穿看” may be “put on, put on and
let’s have a look”. Similarly we can have
“ 吃吃看” (which can be literally translated as
“taste, taste, and let’s see”).
Chinese is unique with its various types of re-
petitive structures. They are by no means rare
phenomena in real texts. Any negligence or fail-
ure in the processing of repetitive structures will
surely spoil the succedent tasks. Unfortunately
this problem has not caught enough attention of
researchers and developers of word segmenta-
tion tools. Most of neglecters usually leave the
problem to the vocabulary that they collect.
Let’s compare the following two groups of
translations:
</bodyText>
<figure confidence="0.976494428571429">
Group A
你再仔细听一听,是不是哪里漏水了。
他看了看停在旁边的火车。
Group B
你再仔细嚼一嚼,是不是有薄荷味。
他坐了下来,又向后靠了靠。
Group A1
</figure>
<bodyText confidence="0.9479685">
You listen carefully, is not where the leak
was.
He looked at the stop next to the train.
Group B1
Carefully you chew a chewing is not a
mint flavor.
He sat down, then back by the by.
The English translations of the repetitive
structures in Group A1 are acceptable for the
structures “ 听一听” and “ 看了看 ” are no doubt
in the vocabulary. And the translations of Group
B are messy enough to show that the repetitive
structures become OOVs and are not well-
processed.
Generally most of Chinese repetitive struc-
tures originate from three word classes:
</bodyText>
<listItem confidence="0.986132">
• Verb repetitive patterns:
</listItem>
<footnote confidence="0.7076908">
AA 听听, 想想, 谈谈
ABAB 商量商量, 研究研究
A一/了A 嚼一嚼, 看了看
AA 看 穿穿看 , 吃吃看
A了一/又A 闻了一闻, 按了一按,摸了又摸
</footnote>
<listItem confidence="0.867151">
• Adjective repetitive patterns:
</listItem>
<equation confidence="0.4739">
AA 大大 , 轻轻 , 红红 , 胖胖
AABB 漂漂亮亮, 大大方方 ,斯斯文文
ABAB 白胖白胖, 焦黄焦黄
</equation>
<listItem confidence="0.879736">
• Classifier repetitive patterns:
</listItem>
<equation confidence="0.950485428571429">
AA 个个(是好汉) ,
件件(是稀世珍宝)
一AA 一辆辆 , 一只只 , 一碗碗
一床床
一A一A 一件一件 , 一套一套 , 一块一块
一A又一A 一张又一张, 一朵又一朵 ,
一条又一条
</equation>
<bodyText confidence="0.9990182">
All these patterns are highly productive in
Chinese. It will be impracticable for any Chinese
parsing or MT systems to leave all the resolu-
tions of them to the vocabulary rather than spe-
cial processing module.
</bodyText>
<subsectionHeader confidence="0.999794">
4.3 Plain classifier and unit structures
</subsectionHeader>
<bodyText confidence="0.9999836">
Chinese is featured by its plenty of classifiers. In
many cases a concrete noun occurs idiomatically
with its particular classifier especially when
modified a numeral, for example, “一个人”(a
person), “两辆车”(two cars), “三公斤苹果”(3
kilos of apples). The processing of this type of
structures will surely benefit the succeeding
parsing and even word sense disambiguation.
Besides the processing is comparatively easy
even in the early stage.
</bodyText>
<subsectionHeader confidence="0.999059">
4.4 Chinese verb aspect processing
</subsectionHeader>
<bodyText confidence="0.998145928571429">
The verb aspect in Chinese is different from that
in English. In general, by using Chinese aspects,
we add some procedural tune to a verb rather
than relating to time. In other words Chinese
verb aspects give hints of the developmental
phases or results, or the capability or possibility
of the events. Chinese verb aspects are expressed
by the aspect markers, such as simple markers
“上”, “下”, “进”,
“出”, “回”, “过”, “起”, “开”,
“到” and compound markers “上来”, “下去”,
etc.
Again let’s look at two pair of Chinese-to-
English MT translations.
</bodyText>
<figure confidence="0.954483692307692">
(6) 要干的工作太多了,一个人实在是干不
过来了。
,
(a) To dry too much work, a person in-
deed dry However come.
(b) The ones that should do have too
much work, one can not really be dry.
(c) I have too much work to do, I can
hardly cope with it.
(7) 姑娘说着说着哭起来了。
(a) Said the girl spoke to cry.
(b) The girl has cried saying.
(c) The girl began to weep while talking.
</figure>
<bodyText confidence="0.99985275">
The messy translations tell us how serious the
impairment of the translation will be if we fail to
process the Chinese verb aspects.
Table 2 shows the meanings conveyed by
most Chinese aspect and its corresponding “as-
pect markers” and examples. Finally, when
speaking about Chinese aspect, one point we
would like to invite readers’ attention that dif-
ferent from the aspect of English. It is known
that English aspect is usually closely related to
tenses, for example, English verbs can be used in
progressive aspect with various tenses, such as
present progressive, progressive and future pro-
gressive tenses. However, Chinese aspects are
related to the development of the event itself, but
not related to the time when the event happens.
</bodyText>
<sectionHeader confidence="0.999301" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999695714285714">
Is it time for Chinese NLP circle to rethink what
we have actually achieved in the word segmen-
tation and consider some radical change? How
much room left is there for the current trilogy to
improve? We propose that we should have mor-
phological processing to replace the so-called
word segmentation. We have designated new
tasks for the processing. In addition, we hope
that we should design and use a new evaluation
method. The general idea of new evaluation is to
use a post-segmentation, or post-morphological-
processing task, say, chunking, to evaluate,
rather than the present method of isochronous
self-testing.
</bodyText>
<figure confidence="0.8600811875">
sememe in meaning marker examples
HowNet
{Vsuppose |presupposing 起来 读~流畅
假定}
{Vstart |发 inceptive 起来 双方对骂~
端}
上 在一旁聊~了
{Vgoingon |progressive 在 ~发言呢
进展}
正 ~睡觉呢
正在 ~干活
着 说~说~动手
了
{Vcontinue |protractive 下去 谈~会有结果
延续}
{Vend|完结} terminative 过 吃~饭再走吧
{Vachieve |perfective 出 做~新成绩
达成}
出来 算~了吗
到 接~人了吗
得 饭做~了
过来 错的地方改~
过去 被我蒙~了
好 功课做~了
见 听~了但看不 ~
上 吃~一顿饱饭
下 谈~那笔生意
着 见~要见的人
{Vable |能 capable 得到 办~
力}
得过 信~
得过来 忙~
得了 一个人干~
得起 买~
得下 装~
起 输~输不~
下 可以睡~3 个
人
{Vincapable |incapable 不得 动也动~
没能力}
不过 说~你
不过来 一个人忙~
不了 一个人可干~
不起 负担~
不下 吃~
{Vpossible |possible 得 这菜吃~吃不
可能} ~
{Vtry|试试} Trying 看 穿穿~
</figure>
<tableCaption confidence="0.7545655">
Table 2. Chinese aspect markers and their
meanings
</tableCaption>
<sectionHeader confidence="0.998954" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9996654375">
Hai Zhao and Chunyu Kit, 2008. Unsupervised
Segmentation Helps Supervised Learning of Chi-
nese Tagging for Word Segmentation and Named
Entity Recognition. In Prceedings of the Sixth
SIGHAN Workshop on Chinese Language Proc-
essing, 2008, Hyderbad, India.
Hwee Tou Ng and Jin Kiat Low, 2004. Chinese Part-
of-speech Tagging: One-at-a-Time or All-at-once?
Word-Based or Character-Based? In Proceedings
EMNLP.
Nianwen Xue, 2003. Chinese Word Segmentation as
Character Tagging. International Journal of Com-
putational Lnguistics and Chinese Language Proc-
essing, 8(1):29-48
Wenbin Jiang and Haitao Mi and Liang Huang and
Qun Liu, 2008b. Wird Lattice Reranking for Chi-
nese Word Segmentation and Part-of-speech Tag-
ging. In Proceedings of COLING
Xinnian Mao, Yuan Dong and Saike He, Sencheng
Bao and Haila Wang, Chinese Word Segmentation
and Name Entity Recognition Based on Condition
Random Fields, In Prceedings of the Sixth
SIGHAN Workshop on Chinese Language Proc-
essing, 2008, Hyderbad, India.
Zhendong Dong and Qiang Dong, 2006. HowNet and
the Computation of Meaning, World Scientific
Publishing Co. Pte. Ltd., Singapore
黄昌宁 , 赵海 , 2007, 中文分词十年回顾.
中文信息学报, 2007, 21(3):8-20.
黄居仁, 2009, 瓶颈, 挑战, 与转机 :
中文分词研究的新思维. In Proceedings of
CNCCL-2009, Yantai
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.191927">
<title confidence="0.831365">Word Segmentation needs — From a linguist’s view</title>
<author confidence="0.976938">Zhendong Dong Qiang Dong Changling Hao</author>
<affiliation confidence="0.613033">Research Center of Computer Canada Keentime Inc. Canada Keentime Language Engineering, CAS support@keenage.com</affiliation>
<email confidence="0.998697">dzd@keenage.com</email>
<abstract confidence="0.99644328">The authors propose that we need some change for the current technology in Chinese word segmentation. We should have separate and different phases in the so-called segmentation. First of all, we need to limit segmentation only to the segmentation of Chinese characters instead of the so-called Chinese words. In character segmentation, we will extract all the information of each character. Then we start a phase called Chinese morphological processing (CMP). The first step of CMP is to do a combination of the separate characters and is then followed by post-segmentation processing, including all sorts of repetitive structures, Chinese-style abbreviations, recognition of pseudo-OOVs and their processing, etc. The most part of post-segmentation processing may have to be done by some rule-based sub-routines, thus we need change the current corpus-based methodology by merging with rule-based technique.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Hai Zhao</author>
<author>Chunyu Kit</author>
</authors>
<title>Unsupervised Segmentation Helps Supervised Learning of Chinese Tagging for Word Segmentation and Named Entity Recognition.</title>
<date>2008</date>
<booktitle>In Prceedings of the Sixth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<location>Hyderbad, India.</location>
<marker>Zhao, Kit, 2008</marker>
<rawString>Hai Zhao and Chunyu Kit, 2008. Unsupervised Segmentation Helps Supervised Learning of Chinese Tagging for Word Segmentation and Named Entity Recognition. In Prceedings of the Sixth SIGHAN Workshop on Chinese Language Processing, 2008, Hyderbad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hwee Tou Ng</author>
<author>Jin Kiat Low</author>
</authors>
<title>Chinese Partof-speech Tagging: One-at-a-Time or All-at-once? Word-Based or Character-Based? In</title>
<date>2004</date>
<booktitle>Proceedings EMNLP.</booktitle>
<marker>Ng, Low, 2004</marker>
<rawString>Hwee Tou Ng and Jin Kiat Low, 2004. Chinese Partof-speech Tagging: One-at-a-Time or All-at-once? Word-Based or Character-Based? In Proceedings EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nianwen Xue</author>
</authors>
<title>Chinese Word Segmentation as Character Tagging.</title>
<date>2003</date>
<journal>International Journal of Computational Lnguistics and Chinese Language Processing,</journal>
<pages>8--1</pages>
<marker>Xue, 2003</marker>
<rawString>Nianwen Xue, 2003. Chinese Word Segmentation as Character Tagging. International Journal of Computational Lnguistics and Chinese Language Processing, 8(1):29-48</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wenbin Jiang</author>
<author>Haitao Mi</author>
<author>Liang Huang</author>
<author>Qun Liu</author>
</authors>
<title>Wird Lattice Reranking for Chinese Word Segmentation and Part-of-speech Tagging.</title>
<date>2008</date>
<booktitle>In Proceedings of COLING</booktitle>
<marker>Jiang, Mi, Huang, Liu, 2008</marker>
<rawString>Wenbin Jiang and Haitao Mi and Liang Huang and Qun Liu, 2008b. Wird Lattice Reranking for Chinese Word Segmentation and Part-of-speech Tagging. In Proceedings of COLING</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xinnian Mao</author>
<author>Yuan Dong</author>
<author>Saike He</author>
</authors>
<title>Sencheng Bao and Haila Wang, Chinese Word Segmentation and Name Entity Recognition Based on Condition Random Fields,</title>
<date>2008</date>
<booktitle>In Prceedings of the Sixth SIGHAN Workshop on Chinese Language Processing,</booktitle>
<location>Hyderbad, India.</location>
<marker>Mao, Dong, He, 2008</marker>
<rawString>Xinnian Mao, Yuan Dong and Saike He, Sencheng Bao and Haila Wang, Chinese Word Segmentation and Name Entity Recognition Based on Condition Random Fields, In Prceedings of the Sixth SIGHAN Workshop on Chinese Language Processing, 2008, Hyderbad, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhendong Dong</author>
<author>Qiang Dong</author>
</authors>
<title>HowNet and the Computation of Meaning, World Scientific Publishing Co.</title>
<date>2006</date>
<publisher>Pte. Ltd.,</publisher>
<marker>Dong, Dong, 2006</marker>
<rawString>Zhendong Dong and Qiang Dong, 2006. HowNet and the Computation of Meaning, World Scientific Publishing Co. Pte. Ltd., Singapore</rawString>
</citation>
<citation valid="false">
<date>2007</date>
<pages>21--3</pages>
<note></note>
<marker>2007</marker>
<rawString>黄昌宁 , 赵海 , 2007, 中文分词十年回顾. 中文信息学报, 2007, 21(3):8-20.</rawString>
</citation>
<citation valid="true">
<title></title>
<date>2009</date>
<booktitle>In Proceedings of CNCCL-2009,</booktitle>
<location>Yantai</location>
<marker>2009</marker>
<rawString>黄居仁, 2009, 瓶颈, 挑战, 与转机 : 中文分词研究的新思维. In Proceedings of CNCCL-2009, Yantai</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>