<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.213815">
<title confidence="0.824417">
Corpus-Based Methods in Natural Language Generation: Friend or Foe?
Extended Abstract
</title>
<author confidence="0.854">
Owen Rambow
</author>
<affiliation confidence="0.387327">
AT&amp;T Labs – Research
Florham Park, NJ, USA
</affiliation>
<email confidence="0.969678">
rambow@research.att.com
</email>
<bodyText confidence="0.999981839622642">
In computational linguistics, the 1990s were
characterized by the rapid rise to prominence of
corpus-based methods in natural language under-
standing (NLU). These methods include statis-
tical and machine-learning and approaches. In
natural language generation (NLG), in the mean
time, there was little work using statistical and
machine learning approaches. Some researchers
felt that the kind of ambiguities that appeared to
profit from corpus-based approaches in NLU did
not exist in NLG: if the input is adequately speci-
fied, then all the rules that map to a correct out-
put can also be explicitly specified. However,
this paper will argue that this view is not cor-
rect, and NLG can and does profit from corpus-
based methods. The resistance to corpus-based
approaches in NLG may have more to do with the
fact that in many NLG applications (such as re-
port or description generation) the output to be
generated is extremely limited. As is the case
with NLU, if the language is limited, hand-crafted
methods are adequate and successful. Thus, it is
not a surprise that the first use of corpus-based
techniques, at ISI (Knight and Hatzivassiloglou,
1995; Langkilde and Knight, 1998) was moti-
vated by the use of NLG not in “traditional” NLG
applications, but in machine translation, in which
the range of output language is (potentially) much
larger.
In fact, the situations in NLU and NLG do
not actually differ with respect to the notion of
ambiguity. Though it is not a trivial task, we
can fully specify a grammar such that the gen-
erated text is not ungrammatical. But the prob-
lem for NLG is not specifying a grammar, but de-
termining which part of the grammar to use: to
give a simple example, a give-event can be gen-
erated with the double-object frame (give Mary a
book) or with a prepositional object (give a book
to Mary). We can easily specify the syntax of
these two constrictions. What we need to know
is when to choose which. But the situation is ex-
actly the same in NLU: the problem is knowing
which grammar rules to use when during analy-
sis. Thus, just as the mapping from input to output
is ambiguous in NLU, it is ambiguous in NLG,
not because the grammar is wrong, but because it
leaves too many options. The difference is that in
NLG, different outputs differ not in whether they
are correct (as is the case in NLU), but in whether
they are appropriate or felicitous in a given con-
text. Thus, the need for corpus-based approaches
is less apparent.
Determining which linguistic forms are appro-
priate in what contexts is a hard task. The intro-
spective grammaticality judgment that (perhaps)
is legitimate in the study of syntax is method-
ologically suspect in the study of language use in
context, and most work in linguistic pragmatics
is in fact corpus-based, such as Prince’s work us-
ing the Watergate transcripts and similar corpora
(Prince, 1981). Thus, it is clear that the role of
corpus-based methods in NLG is not to displace
traditional methods, but rather to accelerate them.
If indeed corpus-based methods are necessary in
any case, we may as well use automated proce-
dures for discovering regularities; we no longer
need to use multi-colored pencils to mark up pa-
per copies. For the researcher, there is enough left
to do: the corpus-based techniques still require
linguistic research in order to determine which
features to code for (i.e., what linguistic phenom-
ena to count). To the extent that corpus-based
methods fail currently, it is largely because we are
substituting easily codable features for those that
are more difficult to code, or because we are sim-
ply coding the wrong features. It is not because
there is some hidden truth which traditional lin-
guistic methodologies have access to but corpus-
based methods do not, because they are not in fact
in opposition to each other.
Finally, the emphasis on evaluation that the
corpus-based techniques in NLU have brought
with them have often aroused animosity in the
NLG community. Evaluation is necessary for
development purposes when using corpus-based
techniques: it is easy to generate many differ-
ent hypotheses, and we need to be able to choose
among them. Since this is crucial, increased at-
tention needs to be paid to evaluation in gen-
eration (Bangalore et al., 2000; Rambow et al.,
2001). But again, the situation is in fact not dif-
ferent from a traditional linguistic methodology:
theories about language use in context need to be
defeasible on empirical grounds and hence need
to be evaluated against a corpus. Of course, the
choice of evaluation corpus is an important one,
and the costs associated with compiling and an-
notating corpora can greatly impact the choice of
evaluation corpus and hence the evaluation.
In conclusion, NLG has nothing to fear from
corpus-based methods. Instead, the NLG com-
munity can continue to provide a test-bed for lin-
guists to exercise their theories (to a much greater
extent than can NLU). The difference is that ev-
eryone can now start using computers.
</bodyText>
<sectionHeader confidence="0.99898" genericHeader="abstract">
References
</sectionHeader>
<reference confidence="0.99913952173913">
Srinivas Bangalore, Owen Rambow, and Steve Whit-
taker. 2000. Evaluation metrics for generation. In
Proceedings of the First International Natural Lan-
guage Generation Conference (INLG2000), Mitzpe
Ramon, Israel.
K. Knight and V. Hatzivassiloglou. 1995. Two-level,
many-paths generation. In 33rd Meeting of the As-
sociation for Computational Linguistics (ACL’95).
Irene Langkilde and Kevin Knight. 1998. The prac-
tical value of n-grams in generation. In Proceed-
ings of the Ninth International Natural Language
Generation Workshop (INLG’98), Niagara-on-the-
Lake, Ontario.
Ellen F. Prince. 1981. Topicalization, focus move-
ment and yiddish movement: A pragmatic dif fer-
entiation. In D. Alford, editor, Proceedings of the
Seventh Annual Meeting of the Berkely Linguistics
Society, pages 249–264. BLS.
Owen Rambow, Monica Rogati, and Marilyn Walker.
2001. Evaluating a trainable sentence planner for a
spoken dialogue system. In 39th Meeting of the As-
sociation for Computational Linguistics (ACL’01),
Toulouse, France.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.026247">
<title confidence="0.8131445">Corpus-Based Methods in Natural Language Generation: Friend or Foe? Extended Abstract</title>
<author confidence="0.999611">Owen Rambow</author>
<affiliation confidence="0.990354">AT&amp;T Labs –</affiliation>
<address confidence="0.997783">Florham Park, NJ, USA</address>
<email confidence="0.994415">rambow@research.att.com</email>
<abstract confidence="0.998620773584906">In computational linguistics, the 1990s were characterized by the rapid rise to prominence of corpus-based methods in natural language understanding (NLU). These methods include statistical and machine-learning and approaches. In natural language generation (NLG), in the mean time, there was little work using statistical and machine learning approaches. Some researchers felt that the kind of ambiguities that appeared to profit from corpus-based approaches in NLU did not exist in NLG: if the input is adequately specified, then all the rules that map to a correct output can also be explicitly specified. However, this paper will argue that this view is not correct, and NLG can and does profit from corpusbased methods. The resistance to corpus-based approaches in NLG may have more to do with the fact that in many NLG applications (such as report or description generation) the output to be generated is extremely limited. As is the case with NLU, if the language is limited, hand-crafted methods are adequate and successful. Thus, it is not a surprise that the first use of corpus-based techniques, at ISI (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998) was motivated by the use of NLG not in “traditional” NLG applications, but in machine translation, in which the range of output language is (potentially) much larger. In fact, the situations in NLU and NLG do not actually differ with respect to the notion of ambiguity. Though it is not a trivial task, we can fully specify a grammar such that the generated text is not ungrammatical. But the problem for NLG is not specifying a grammar, but determining which part of the grammar to use: to give a simple example, a give-event can be genwith the double-object frame Mary a or with a prepositional object a book We can easily specify the syntax of these two constrictions. What we need to know is when to choose which. But the situation is exactly the same in NLU: the problem is knowing which grammar rules to use when during analysis. Thus, just as the mapping from input to output is ambiguous in NLU, it is ambiguous in NLG, not because the grammar is wrong, but because it leaves too many options. The difference is that in NLG, different outputs differ not in whether they are correct (as is the case in NLU), but in whether they are appropriate or felicitous in a given context. Thus, the need for corpus-based approaches is less apparent. Determining which linguistic forms are appropriate in what contexts is a hard task. The introspective grammaticality judgment that (perhaps) is legitimate in the study of syntax is methodologically suspect in the study of language use in context, and most work in linguistic pragmatics is in fact corpus-based, such as Prince’s work using the Watergate transcripts and similar corpora (Prince, 1981). Thus, it is clear that the role of corpus-based methods in NLG is not to displace traditional methods, but rather to accelerate them. If indeed corpus-based methods are necessary in any case, we may as well use automated procedures for discovering regularities; we no longer need to use multi-colored pencils to mark up paper copies. For the researcher, there is enough left to do: the corpus-based techniques still require linguistic research in order to determine which features to code for (i.e., what linguistic phenomena to count). To the extent that corpus-based methods fail currently, it is largely because we are substituting easily codable features for those that are more difficult to code, or because we are simply coding the wrong features. It is not because there is some hidden truth which traditional linguistic methodologies have access to but corpusbased methods do not, because they are not in fact in opposition to each other. Finally, the emphasis on evaluation that the corpus-based techniques in NLU have brought with them have often aroused animosity in the NLG community. Evaluation is necessary for development purposes when using corpus-based techniques: it is easy to generate many different hypotheses, and we need to be able to choose among them. Since this is crucial, increased attention needs to be paid to evaluation in generation (Bangalore et al., 2000; Rambow et al., 2001). But again, the situation is in fact not different from a traditional linguistic methodology: theories about language use in context need to be defeasible on empirical grounds and hence need to be evaluated against a corpus. Of course, the choice of evaluation corpus is an important one, and the costs associated with compiling and annotating corpora can greatly impact the choice of evaluation corpus and hence the evaluation. In conclusion, NLG has nothing to fear from corpus-based methods. Instead, the NLG community can continue to provide a test-bed for linguists to exercise their theories (to a much greater extent than can NLU). The difference is that everyone can now start using computers.</abstract>
<title confidence="0.40904">References</title>
<author confidence="0.4398135">Evaluation metrics for generation In</author>
<affiliation confidence="0.718553">Proceedings of the First International Natural Lan- Generation Conference Mitzpe</affiliation>
<address confidence="0.927562">Ramon, Israel.</address>
<note confidence="0.710875">K. Knight and V. Hatzivassiloglou. 1995. Two-level, generation. In Meeting of the As-</note>
<title confidence="0.833311">for Computational Linguistics</title>
<author confidence="0.893264">The prac-</author>
<affiliation confidence="0.917186">value of n-grams in generation. In Proceedings of the Ninth International Natural Language Workshop Niagara-on-the-</affiliation>
<address confidence="0.975013">Lake, Ontario.</address>
<author confidence="0.571762">focus move- Topicalization</author>
<abstract confidence="0.949143571428571">ment and yiddish movement: A pragmatic dif fer- In D. Alford, editor, of the Seventh Annual Meeting of the Berkely Linguistics pages 249–264. BLS. Owen Rambow, Monica Rogati, and Marilyn Walker. 2001. Evaluating a trainable sentence planner for a dialogue system. In Meeting of the As-</abstract>
<affiliation confidence="0.76673">for Computational Linguistics</affiliation>
<address confidence="0.962422">Toulouse, France.</address>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Srinivas Bangalore</author>
<author>Owen Rambow</author>
<author>Steve Whittaker</author>
</authors>
<title>Evaluation metrics for generation.</title>
<date>2000</date>
<booktitle>In Proceedings of the First International Natural Language Generation Conference (INLG2000),</booktitle>
<location>Mitzpe Ramon,</location>
<contexts>
<context position="4413" citStr="Bangalore et al., 2000" startWordPosition="741" endWordPosition="744">cause there is some hidden truth which traditional linguistic methodologies have access to but corpusbased methods do not, because they are not in fact in opposition to each other. Finally, the emphasis on evaluation that the corpus-based techniques in NLU have brought with them have often aroused animosity in the NLG community. Evaluation is necessary for development purposes when using corpus-based techniques: it is easy to generate many different hypotheses, and we need to be able to choose among them. Since this is crucial, increased attention needs to be paid to evaluation in generation (Bangalore et al., 2000; Rambow et al., 2001). But again, the situation is in fact not different from a traditional linguistic methodology: theories about language use in context need to be defeasible on empirical grounds and hence need to be evaluated against a corpus. Of course, the choice of evaluation corpus is an important one, and the costs associated with compiling and annotating corpora can greatly impact the choice of evaluation corpus and hence the evaluation. In conclusion, NLG has nothing to fear from corpus-based methods. Instead, the NLG community can continue to provide a test-bed for linguists to exe</context>
</contexts>
<marker>Bangalore, Rambow, Whittaker, 2000</marker>
<rawString>Srinivas Bangalore, Owen Rambow, and Steve Whittaker. 2000. Evaluation metrics for generation. In Proceedings of the First International Natural Language Generation Conference (INLG2000), Mitzpe Ramon, Israel.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Knight</author>
<author>V Hatzivassiloglou</author>
</authors>
<title>Two-level, many-paths generation.</title>
<date>1995</date>
<booktitle>In 33rd Meeting of the Association for Computational Linguistics (ACL’95).</booktitle>
<contexts>
<context position="1313" citStr="Knight and Hatzivassiloglou, 1995" startWordPosition="206" endWordPosition="209"> specified, then all the rules that map to a correct output can also be explicitly specified. However, this paper will argue that this view is not correct, and NLG can and does profit from corpusbased methods. The resistance to corpus-based approaches in NLG may have more to do with the fact that in many NLG applications (such as report or description generation) the output to be generated is extremely limited. As is the case with NLU, if the language is limited, hand-crafted methods are adequate and successful. Thus, it is not a surprise that the first use of corpus-based techniques, at ISI (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998) was motivated by the use of NLG not in “traditional” NLG applications, but in machine translation, in which the range of output language is (potentially) much larger. In fact, the situations in NLU and NLG do not actually differ with respect to the notion of ambiguity. Though it is not a trivial task, we can fully specify a grammar such that the generated text is not ungrammatical. But the problem for NLG is not specifying a grammar, but determining which part of the grammar to use: to give a simple example, a give-event can be generated with the double-object fra</context>
</contexts>
<marker>Knight, Hatzivassiloglou, 1995</marker>
<rawString>K. Knight and V. Hatzivassiloglou. 1995. Two-level, many-paths generation. In 33rd Meeting of the Association for Computational Linguistics (ACL’95).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Irene Langkilde</author>
<author>Kevin Knight</author>
</authors>
<title>The practical value of n-grams in generation.</title>
<date>1998</date>
<booktitle>In Proceedings of the Ninth International Natural Language Generation Workshop (INLG’98),</booktitle>
<location>Niagara-on-theLake, Ontario.</location>
<contexts>
<context position="1342" citStr="Langkilde and Knight, 1998" startWordPosition="210" endWordPosition="213"> map to a correct output can also be explicitly specified. However, this paper will argue that this view is not correct, and NLG can and does profit from corpusbased methods. The resistance to corpus-based approaches in NLG may have more to do with the fact that in many NLG applications (such as report or description generation) the output to be generated is extremely limited. As is the case with NLU, if the language is limited, hand-crafted methods are adequate and successful. Thus, it is not a surprise that the first use of corpus-based techniques, at ISI (Knight and Hatzivassiloglou, 1995; Langkilde and Knight, 1998) was motivated by the use of NLG not in “traditional” NLG applications, but in machine translation, in which the range of output language is (potentially) much larger. In fact, the situations in NLU and NLG do not actually differ with respect to the notion of ambiguity. Though it is not a trivial task, we can fully specify a grammar such that the generated text is not ungrammatical. But the problem for NLG is not specifying a grammar, but determining which part of the grammar to use: to give a simple example, a give-event can be generated with the double-object frame (give Mary a book) or with</context>
</contexts>
<marker>Langkilde, Knight, 1998</marker>
<rawString>Irene Langkilde and Kevin Knight. 1998. The practical value of n-grams in generation. In Proceedings of the Ninth International Natural Language Generation Workshop (INLG’98), Niagara-on-theLake, Ontario.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen F Prince</author>
</authors>
<title>Topicalization, focus movement and yiddish movement: A pragmatic dif ferentiation. In</title>
<date>1981</date>
<booktitle>Proceedings of the Seventh Annual Meeting of the Berkely Linguistics Society,</booktitle>
<pages>249--264</pages>
<editor>D. Alford, editor,</editor>
<publisher>BLS.</publisher>
<contexts>
<context position="3023" citStr="Prince, 1981" startWordPosition="512" endWordPosition="513"> different outputs differ not in whether they are correct (as is the case in NLU), but in whether they are appropriate or felicitous in a given context. Thus, the need for corpus-based approaches is less apparent. Determining which linguistic forms are appropriate in what contexts is a hard task. The introspective grammaticality judgment that (perhaps) is legitimate in the study of syntax is methodologically suspect in the study of language use in context, and most work in linguistic pragmatics is in fact corpus-based, such as Prince’s work using the Watergate transcripts and similar corpora (Prince, 1981). Thus, it is clear that the role of corpus-based methods in NLG is not to displace traditional methods, but rather to accelerate them. If indeed corpus-based methods are necessary in any case, we may as well use automated procedures for discovering regularities; we no longer need to use multi-colored pencils to mark up paper copies. For the researcher, there is enough left to do: the corpus-based techniques still require linguistic research in order to determine which features to code for (i.e., what linguistic phenomena to count). To the extent that corpus-based methods fail currently, it is</context>
</contexts>
<marker>Prince, 1981</marker>
<rawString>Ellen F. Prince. 1981. Topicalization, focus movement and yiddish movement: A pragmatic dif ferentiation. In D. Alford, editor, Proceedings of the Seventh Annual Meeting of the Berkely Linguistics Society, pages 249–264. BLS.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Owen Rambow</author>
<author>Monica Rogati</author>
<author>Marilyn Walker</author>
</authors>
<title>Evaluating a trainable sentence planner for a spoken dialogue system.</title>
<date>2001</date>
<booktitle>In 39th Meeting of the Association for Computational Linguistics (ACL’01),</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="4435" citStr="Rambow et al., 2001" startWordPosition="745" endWordPosition="748">en truth which traditional linguistic methodologies have access to but corpusbased methods do not, because they are not in fact in opposition to each other. Finally, the emphasis on evaluation that the corpus-based techniques in NLU have brought with them have often aroused animosity in the NLG community. Evaluation is necessary for development purposes when using corpus-based techniques: it is easy to generate many different hypotheses, and we need to be able to choose among them. Since this is crucial, increased attention needs to be paid to evaluation in generation (Bangalore et al., 2000; Rambow et al., 2001). But again, the situation is in fact not different from a traditional linguistic methodology: theories about language use in context need to be defeasible on empirical grounds and hence need to be evaluated against a corpus. Of course, the choice of evaluation corpus is an important one, and the costs associated with compiling and annotating corpora can greatly impact the choice of evaluation corpus and hence the evaluation. In conclusion, NLG has nothing to fear from corpus-based methods. Instead, the NLG community can continue to provide a test-bed for linguists to exercise their theories (</context>
</contexts>
<marker>Rambow, Rogati, Walker, 2001</marker>
<rawString>Owen Rambow, Monica Rogati, and Marilyn Walker. 2001. Evaluating a trainable sentence planner for a spoken dialogue system. In 39th Meeting of the Association for Computational Linguistics (ACL’01), Toulouse, France.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>