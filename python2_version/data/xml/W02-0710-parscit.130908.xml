<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000042">
<affiliation confidence="0.369305333333333">
Proceedings of the Workshop on Speech-to-Speech Translation:
Algorithms and Systems, Philadelphia, July 2002, pp. 69-76.
Association for Computational Linguistics.
</affiliation>
<bodyText confidence="0.986147264705883">
any of the paradigms we have mentioned. In
this paper, we will be particularly interested in
medical speech translation applications. There
are good reasons to pay attention to medical do-
mains; when we have talked to people about pos-
sible practical applications of speech translation
technology, medical applications probably come
up as frequently as all other application areas
put together. The explanation is simple: there
are no other areas where the potential payoff
is as large, or as immediate. It requires little
imagination to think of scenarios, not even par-
ticularly far-fetched ones, where access to a re-
liable medical speech translator could actually
save someone&apos;s life. Anyone who has suddenly
fallen ill in a country where they do not speak
the local language will be aware that this is, for
good reasons, an extremely frightening situation
to be in. In most application areas, users are
reluctant to use speech translation technology
which is still far from perfect. With medical ap-
plications, many of these objections disappear;
when their lives are at stake, people don&apos;t tend
to be fussy.
Given the above, one might wonder why medi-
cal speech translation systems are not already in
common use. The answer is again clear. For ex-
actly the same reasons, a medical speech trans-
lation system must be totally dependable; par-
ticularly in the US, the likely consequences of
an accident resulting from a mistranslation are
enough to convince most medical professionals
that they should only use systems which they
can trust completely.
Unfortunately, this immediately rules out the
first three architectures considered above. The
completely domain-independent systems (3) are
in no way reliable enough for this kind of work,
and the inherent uncertainty involved in any
kind of statistical approach makes it hard to
believe that even a good domain-specific train-
able system (2) would be regarded as acceptable.
Elaborate linguistics-based systems (1) are bet-
ter in this respect, but still not good enough;
for example, the evaluation figures for the fi-
nal version of the Spoken Language Translator
(Carter et al., 2000) show that even correctly
recognised utterances give bad or useless trans-
lations about 4% of the time. Having worked
extensively with such systems, our strong im-
pression is that a non-trivial proportion of bad
translations is inescapable given today&apos;s meth-
ods. The key problem is that rule-based sys-
tems of this kind always permit fairly extensive
ambiguity, which is in practice resolved using
potentially fallible techniques of a statistical or
heuristic nature. In addition to the question of
reliability, it should be added that the extreme
expense associated with developing and porting
these systems would be a major practical ob-
stacle to deploying them for the large number
of sub-domains and language pairs required in
practice.
Fixed phrase translators, naturally, do not
suffer from the above problems, and can be
quite successful in some safety-critical domains.
For example the system described in (Integrat-
edWaveTechnologies, 2002), which translates
about 500 fixed phrases, has apparently been
used in real situations by the Oakland Police
Force. For medical domains, however, a fixed
phrase translator appears to be too restrictive.
A doctor doesn&apos;t simply want to ask whether
the patient experiences a certain symptom; they
typically need to ask whether they experience it
seldom or often, whether they experience it at
certain times of day or in connection with spec-
ified other activities, and so on. This can in
principle be done using a fixed phrase transla-
tor, but a little experimentation shows that the
resulting dialogues tend to be unbearably slow
and frustrating for both partners. ( &amp;quot;Do you suf-
fer from headaches?&amp;quot; ... &amp;quot;Often, sometimes, or
only occasionally?&amp;quot; ... &amp;quot;After a meal?&amp;quot;) Split-
ting up questions in this way can also introduce
misunderstandings; for example, a patient may
give a negative answer to &amp;quot;Do you suffer from
headaches?&amp;quot;, but a positive answer to &amp;quot;Do you
occasionally suffer from headaches?&amp;quot;
None the less, it seems clear to us that the
fixed-phrase approach is the one that comes clos-
est to delivering what the users actually want.
In the sequel, we will describe an architecture for
what could be called a second-generation fixed-
phrase translator; essentially, it is a phrasal
translator which allows some variation in the in-
put language. This is close in spirit to the ap-
proach used in most normal phrase-books, which
typically allow &amp;quot;slots&amp;quot; in at least some phrases
( &amp;quot;How much does cost?&amp;quot;; &amp;quot;How do I get to
?&amp;quot;). To elaborate, our architecture is motivated
by the following main considerations:
</bodyText>
<listItem confidence="0.915395230769231">
1. The system should run on standard plat-
forms, and be easy to install and use.
2. The architecture should support rapid de-
velopment of versions for new domains, sub-
domain and language-pairs; in particular,
it should be easy to add new output lan-
guages.
3. It should be possible to develop a system
without having a sizeable corpus in prac-
tice, there never is a suitable corpus avail-
able.
4. Translation must be simple enough to be
totally reliable. This will never be the case
</listItem>
<bodyText confidence="0.997783071428572">
with statistical methods hence the ar-
chitecture must be based on rule-based lin-
guistic methods, preferably simple ones. In
particular, the architecture must as far as
possible reduce both the complexity of in-
ternal representations, and their potential
ambiguity.
The rest of the paper describes a concrete
architecture motivated by the above considera-
tions. Examples will be taken from our pilot ap-
plication, a French-to-English phrasebook-style
translator with a vocabulary of about 200 words,
which allows a doctor to ask a patient questions
relating to the symptoms of hypoglycaemia.
</bodyText>
<sectionHeader confidence="0.701925" genericHeader="abstract">
2 Overview of architecture
</sectionHeader>
<bodyText confidence="0.999948236842105">
The architecture comprises three main modules.
These are respectively responsible for source lan-
guage speech recognition, including parsing and
production of semantic representation; transfer
and generation; and synthesis of target language
speech. The speech processing modules (recog-
nition and synthesis) are implemented on top of
the standard Nuance Toolkit platform (Nuance,
2002). The language processing modules (trans-
fer and generation) are a suite of simple routines
written in SICStus Prolog.
Recognition is constrained by a CFG language
model written in Nuance Grammar Specifica-
tion Language (GSL), which also specifies the se-
mantic representations produced. The grammar
is not written by hand, but is rather compiled
from a compact unification-grammar represen-
tation using the open source Regulus package
(Rayner et al., 2001); the unification grammar,
and the GSL representation it compiles into, are
described in the next section. The speech and
language processing modules communicate with
each other through a minimal file-based proto-
col.
The semantic representations on both the
source and target sides are expressed as
attribute-value structures. Transfer rules map
sets of attribute-value pairs to sets of attribute-
value pairs; the great majority of the rules map
single attribute-value pairs to single attribute-
value pairs. Generation is handled by a
small Definite Clause Grammar (DCG), which
converts attribute-value structures into surface
strings; its output is passed through a minimal
post-transfer component, which applies a set of
rules which map fixed strings to fixed strings.
Speech synthesis is performed by the Nuance
Vocalizer TTS engine.
</bodyText>
<sectionHeader confidence="0.919807" genericHeader="keywords">
3 Recognition and grammar
</sectionHeader>
<bodyText confidence="0.995728265625">
As described in the previous section, the recog-
nition module is built on top of the Nuance
Toolkit platform, using an annotated CFG
language model consisting of a Nuance GSL
grammar. This grammar is compiled from
a unification-grammar representation using the
Regulus tool. There are two important moti-
vations for using unification grammar. Firstly,
there is efficiency: the more compact nature of
unification grammar, compared to CFG, sub-
stantially reduces the implementation effort re-
quired. The grammar for our pilot application
currently contains only 28 unification-grammar
rules, excluding lexical entries; these expand out
into over 400 CFG rules.
An even more important advantage of using
unification grammar is uniformity. Since the
CFG rules are all derived automatically from
the same compact underlying code-base, the im-
plementor can be confident that related groups
of CFG rules are always kept in step with each
other. This means that it is practically fea-
sible to construct a large CFG grammar in a
short time, and keep it stable even if non-trivial
changes are introduced during the development
process.
In accordance with the generally minimalistic
design philosophy of the project, semantic repre-
sentations have been kept as simple as possible.
The basic principle is that the representation
of a clause is a flat list of attribute-value pairs:
thus for example the representation of
&amp;quot;avez-vous souvent des maux d&apos;estomac&amp;quot;
(lit: &amp;quot;have you often pains of stomach&amp;quot;)
(&amp;quot;do you often have stomach pains&amp;quot;)
is the attribute-value list
[[state, feel],
[frequency, souyent] ,
[symptom, maux],
[body_part, estomac]]]
In a broad domain, it is of course trivial to con-
struct examples where this kind of representa-
tion runs into serious problems. In the very
narrow domain of a phrasebook translator, it
has many desirable properties. Grammar rules
can in nearly all cases construct the semantic
representation of the mother node by simple
concatenation of the semantic representations
of the daughters&apos;. In general, the consequence
is that operations on semantic representations
typically manipulate lists rather than trees; the
next section illustrates some of the advantages
that follow from this fact. In a broad domain, we
would pay a heavy price: the lack of structure in
the semantic representations would often make
them ambiguous. The very simple ontology of
the phrasebook domain however means that am-
1-The only exception in our prototype grammar is the
rule which allows a clause introduced by the subordinat-
ing conjunction &amp;quot;quand&amp;quot; (&amp;quot;when&amp;quot;) to act as a modifier.
biguity is not a problem; the components of
a flat list representation can never be derived
from more than one functional structure, so this
structure does not need to be explicitly present.
</bodyText>
<sectionHeader confidence="0.702512" genericHeader="introduction">
4 Transfer and generation
</sectionHeader>
<bodyText confidence="0.997816935064935">
The minimal list-based representation language
makes it possible to implement a simple but ef-
fective transfer and generation module. Transfer
operates by applying rules which map lists of
attribute-value pairs to lists of attribute-value
pairs. Most rules are transfer lexicon (t_lex)
entries, which map single attribute-value pairs
to single attribute-value pairs associated with
grammatical categories of the same kind. These
pairs will often represent surface phrases con-
sisting of more than one word. For example,
the following two t_lex entries respectively map
&amp;quot;serrement a la poitrine&amp;quot; into &amp;quot;tightness in the
chest&amp;quot; and &amp;quot;regarder la tele&amp;quot; into &amp;quot;watch TV&amp;quot;:
t_lex([symptom, serrement_poitrine],
[symptom, tightness_in_the_chest]).
t_lex([hum_act, regarder_ty],
[hum_act, watch_ty]).
A t_lex entry may equally well map an
attribute-value pair to an attribute-value pair
associated with a different grammatical cate-
gory; for example, the following entry maps the
representation of the adjective &amp;quot;alcoolique&amp;quot; to
the representation of the noun phrase &amp;quot;an alco-
holic&amp;quot;:
t_lex([symptom, alcoolique],
[symptom, alcoholic]).
It is also possible to write proper transfer rules
(t_rules), which map a set of attribute-value
pairs to a set of attribute-value pairs; for exam-
ple, the following t_rule maps &amp;quot;etre d&apos;humeur
changeante&amp;quot; (lit. &amp;quot;be of changing mood&amp;quot;) to
&amp;quot;suffer from mood swings&amp;quot;:
t_rule( [[state, etre] ,
[symptom, d_humeur_changeante]] ,
[[state, feel],
[symptom, mood_swings]]).
The list-based representation language has al-
lowed us to implement a simple but efficient
transfer rule interpreter, which applies these
rules generally, irrespective of whether the pairs faintness, headache, confusion, convulsions,
on the left-hand occur contiguously in the and coma; one of the reasons we have chosen
source-language input. hypoglycaemia as a domain is that these
Many systems have shown that it is easy to symptoms can coincide with those relating
generate from the kind of simple attribute-value to many other conditions, which can often
representations used here. Our system performs necessitate a lengthy verbal examination. In
generation using a small DCG grammar; typ- our initial prototype, we have limited ourselves
ically, a rule absorbs one or more items from to spoken yes/no questions, which we have
the transferred attribute-value list, and gener- based on those in a questionaire constructed
ates one or more output words. Once again, the by the Association of Hypoglycaemics of Que-
list-based representation made it easy to imple- bec (Theriault, 2002). In terms of content,
ment the DCG in such a way that items can be all questions are assumed to be of the basic form
absorbed in an arbitrary order. The result is
that word-order differences between source and &amp;quot;Do you
target pose no problems for translation. ?(often/sometimes/ever/...)
Yet another advantage that follows from the (do something/experience symptom)
minimal representation formalism is that it has ?(at time/when you do something)&amp;quot;
been straightforward to write development tools
that ensure internal consistency between the The grammar provides enough phrasal patterns
source-language, transfer, and target-language that it is possible to ask about most domain
lexica. Early on in the project, we wrote a concepts in a natural way. As described in the
Prolog-based tool of this kind. If the source- first section, however, we have intentionally
language lexicon is extended or modified, the constructed the system as a phrase-book rather
tool checks that each attribute-value pair in the than as a general translator. We only supply a
source-language lexicon appears in the left-hand minimal set of grammar rules, and assume that
side of at least one transfer lexicon entry; if nec- the user will be prepared to invest a little time
essary, blank entries are added to the transfer in learning how to express themselves within
lexicon for the implementor to complete. Simi- these bounds.
larly, the tool checks that every attribute-value The reason why it is not completely trivial to
pair appearing in the right-hand side of a trans- construct a system of this kind is that one can-
fer lexicon entry also appears in at least one not naturally ask about all domain symptoms
generation lexicon entry. Use of the tool makes using a single uniform phrasal pattern. The
it possible to modify one part of the rule-base most common pattern is some version of
without manually having to keep track of the
consequences, permitting a rapid development &amp;quot;avez-vous ?&lt;freq&gt; &lt;symptom&gt; ?&lt;time&gt;&amp;quot;
cycle. (&amp;quot;do you suffer from ?&lt;freq&gt; &lt;symptom&gt;
?&lt;time&gt;&amp;quot;)
</bodyText>
<sectionHeader confidence="0.962716" genericHeader="method">
5 A medical phrasebook translator
</sectionHeader>
<bodyText confidence="0.9984249">
so for example
We have used the architecture outlined in
the previous sections to construct a proto-
type French —&gt; English medical phrasebook
translator. The basic scenario envisaged is
that a French-speaking doctor suspects that
an English-speaking patient may be suffering
from some form of hypoglycaemia (low blood
sugar). The symptoms of hypoglycaemia
include anxiety, sweating, tachycardia, tremor,
</bodyText>
<construct confidence="0.4406044">
&amp;quot;ressentez-vous des engourdissements ?1,
—&gt;
&amp;quot;do you suffer from numbness?&amp;quot; or
&amp;quot;eprouvez-vous souvent des maux de tete le
matin ?&amp;quot; —&gt;
</construct>
<bodyText confidence="0.886364777777778">
&amp;quot;do you often suffer from headache in the
morning?&amp;quot;
However, there are many cases where some
other pattern is required in order to express
the question in a natural way. For example, we
may need to use the verb &amp;quot;etre&amp;quot; (&amp;quot;be&amp;quot;), e.g.
&amp;quot;etes-vous emotive ?&amp;quot;—&gt; &amp;quot;are you emotional?&amp;quot;
or to use an intransitive or transitive verb,
e.g.
</bodyText>
<figure confidence="0.5205065">
&amp;quot;urinez-vous frequemment la nuit ?&amp;quot;—
&amp;quot;do you often urinate at night?&amp;quot;
&amp;quot;mangttez-votts toujours d&apos;energie l&apos;apres-
midi ?&amp;quot;—&gt;
</figure>
<figureCaption confidence="0.404779666666667">
(lit. &amp;quot;lack you always energy the afternoon?&amp;quot;)
&amp;quot;do you always suffer from lack of energy in the
afternoon?&amp;quot;
</figureCaption>
<bodyText confidence="0.95277328">
It may also be necessary to pose the ques-
tion in the past tense, e.g.
&amp;quot;avez-vous &amp;jet eu des convulsions ?&amp;quot; —&gt;
&amp;quot;have you ever suffered from convulsions?&amp;quot;
Finally, French has several different ways
to form yes/no questions, of which the most
common are subject/verb inversion, e.g.
&amp;quot;etes-vous enceinte ?&amp;quot;
&amp;quot;are you pregnant?&amp;quot;
and fronting of est-ce que, e.g.
&amp;quot;est-ce que vous etes enceinte ?&amp;quot;
&amp;quot;est-ce que you are pregnant?&amp;quot;
Although the est-ce que fronted construc-
tion is by default the preferred one in spoken
French, there are many cases where inversion
feels more natural, and it is in practice neces-
sary to allow both constructions. Even when
we try to keep the number of phrase types as
low as we can, the choices along these different
dimensions still multiply out to a non-trivial
number of possibilities.
The current prototype has a vocabulary of
about 200 words. The unification grammar used
to create the recogniser contains 28 non-lexical
rules and 179 lexical rules. The transfer lexi-
con contains 12 complex transfer rules and 104
transfer lexicon entries. The target language
DCG contains 24 phrase-structure rules and 141
generation lexicon entries, and the post-transfer
component contains 16 string-to-string rewrit-
ing rules. Creation of these linguistic resources
required something between one and two person-
weeks of expert effort; the most interesting as-
pect of this process was the focus we maintained
thoughout on avoiding ambiguity in the analy-
sis and generation grammars. This was primar-
ily achieved by using sortal features consistently
in both grammars, and maintaining a tight con-
trol of the domain ontology to ensure that the
same sort of object can never occur in two dif-
ferent positions in a single clause. Occasionally
this meant that the lexicon entries for a word
had to be duplicated in two versions; for exam-
ple, &amp;quot;repas&amp;quot; (&amp;quot;meal&amp;quot;) can occur both as part of
a temporal PP ( &amp;quot;manger entre repas&amp;quot;, &amp;quot;eat be-
tween meals&amp;quot;), or as the object of some verbs
(&amp;quot;sauter un repas&amp;quot;, &amp;quot;skip a meal&amp;quot;). In cases like
these, we included separate entries in the lexi-
con for the two usages of the word, giving them
distinct sortal categories in the ontology.
</bodyText>
<sectionHeader confidence="0.993348" genericHeader="evaluation">
6 Evaluation
</sectionHeader>
<bodyText confidence="0.99998378125">
The real question we would like to answer when
evaluating the prototype system is whether it
is practically useful. Unfortunately, we are not
yet in a position to do this, since the system is
not mature enough in terms of coverage for it to
be meaningful to subject it to a field trial. We
thus have to content ourselves with more mod-
est evaluation goals, and seek indirect evidence
which suggests that an expanded version of the
system could be useful. Some of this evidence
consists of tests of the system&apos;s internal valid-
ity; in particular, we have carried out systematic
checks that the analysis and generation gram-
mars really are unambiguous, and that trans-
lation always produces an output. We do this
by using the Nuance Toolkit&apos;s generate utility
to create large sets of (text) utterances within
the coverage of the analysis grammar, and then
processing them through the system with both
grammars run in an all-solutions mode. A test
of this kind on 10 000 randomly generated utter-
ances showed that all 10 000 produced an out-
put, and that for each utterance there was al-
ways exactly one possible semantic analysis, and
one possible string generated from the trans-
ferred representation.
In terms of external evaluation criteria, our
architecture is primarily aimed at providing ad-
equate recognition and reliable translation; it
consequently makes sense to start by testing
these aspects of performance. Specifically, we
investigated the following two measures:
</bodyText>
<listItem confidence="0.9458542">
1. If the user says something within the sys-
tem&apos;s coverage, how often is it correctly
recognised?
2. If what the user says is correctly recognised,
how often is it correctly translated?
</listItem>
<bodyText confidence="0.998829481481481">
We investigated recognition quality on in-
coverage utterances by again randomly pro-
ducing a set of 500 such utterances using the
generate utility. Since the recognition gram-
mar overgenerates, some of these utterances
are ungrammatical or nonsensical; a human
judge manually filtered the set to leave 195
good-quality utterances, averaging 6.8 words in
length.
The intention is that the translator would
be normally used by experts who would have
time to learn how to operate it. In order to
simulate this pattern of use, we randomly di-
vided the 195 good utterances into a &amp;quot;practice&amp;quot;
set of 150 utterances and an &amp;quot;evaluation&amp;quot; set
of 45 utterances. Five subjects (students who
had not previously had exposure to the sys-
tem) were each given twenty minutes to experi-
ment with the system by reading out sentences
from the practice set, and then competed on the
task of reading out the evaluation utterances;
each subject read each utterance once, and a
small prize was given to the subject who got
the best recognition result. Given the nature of
the task, it seems more appropriate to evaluate
in terms of sentence-level measures rather than
word error rates. We consequently scored utter-
</bodyText>
<table confidence="0.999528777777778">
Subj WordsOK SemOK Bad
Red 1 3 31
11
Rec2 32 5 8
Rec3 28 8 9
Rec4 18 6 21
Rec5 34 10 1
Av. 24.6 6.4 14.0
(55%) (14%) (31%)
</table>
<tableCaption confidence="0.787029">
Table 1: Recognition performance of 5 subjects
reading 45 in-coverage utterances
</tableCaption>
<table confidence="0.991946833333333">
Subj Good OK Bad
Trans1 141 6 3
Trans2 98 51 1
Trans3 90 55 5
Av. 110 37 3
(73%) (25%) (2%)
</table>
<tableCaption confidence="0.734154333333333">
Table 2: Quality of translation on 150 in-
coverage utterances, as evaluated by three in-
dependent judges
</tableCaption>
<bodyText confidence="0.999954447368421">
ances as belonging to one of three possible cate-
gories: &amp;quot;WordsOK&amp;quot; (no word errors), &amp;quot;SemOK&amp;quot;
(at least one word error, but the semantic repre-
sentation was correct), and &amp;quot;Bad&amp;quot; (no recogni-
tion, or incorrect semantic representation). The
results are presented in Table 1.
In order to investigate the second question
(translation quality), we randomly generated
a new set of 150 in-coverage utterances, and
process them through the system to produce
text outputs. We then asked three independent
bilingual judges to evaluate the source/target
pairs as either fully correct (&amp;quot;Good&amp;quot;), accept-
able (&amp;quot;OK&amp;quot;) or incorrect/nonsensical (&amp;quot;Bad&amp;quot;).
The results are presented in Table 2.
Although this evaluation makes no preten-
tions to being definitive, we find the results en-
couraging. Three of our five test users were able
to adapt quickly to the system, and achieved
high recognition accuracy after only a short
practice period. We were initially concerned
that as many as 2% of the utterances were
mistranslated. Analysis of the results however
revealed that these utterances were problem-
atic for reasons that had more to do with the
evaluation methodology than the system. The
judges did not appear to have strong intuitions
about the correctness or otherwise of the crit-
ical translations; no translation was marked as
bad by all three judges, and only one transla-
tion was marked as bad by two judges out of
three. It was also noticeable that at least half of
the source-language utterances which resulted in
&amp;quot;bad&amp;quot; translations were dubious either syntacti-
cally or pragmatically, and should arguably have
been filtered out when preparing the evaluation
data. We intend soon to carry out a revised
evaluation which will address these issues.
</bodyText>
<sectionHeader confidence="0.844764" genericHeader="conclusions">
7 Conclusion and further directions
</sectionHeader>
<bodyText confidence="0.999841548387097">
The main point we want to make in this paper
is that today&apos;s technology makes it possible to
build limited-domain speech to speech transla-
tors which represent an interesting compromise
between trivial fixed-phase systems on the one
hand and sophisticated VERBmoBIL-style sys-
tems on the other. These systems can offer suf-
ficient coverage to allow a user to express them-
selves fairly freely after a little practice, but
are still constrained enough that they appear to
have the potential to reach levels of reliability
appropriate for medical and other safety-critical
applications. They can be quickly constructed
on top of standard commercial platforms like the
Nuance Toolkit, and run on ordinary PCs.
As already indicated, the critical question is
whether a system of this kind can be expanded
to the point where it becomes practically use-
ful. In particular, it is still unclear how much
more grammar and vocabulary are needed in
order to achieve this goal, and how much per-
formance will degrade if coverage is increased
accordingly. In concrete terms, this amounts to
asking whether it is feasible to construct con-
trolled languages for at least some interesting
domains which achieve a suitable balance be-
tween coverage and performance. We have now
begun implementation of a second and more
elaborate version of the system, and expect to
be able to report on its performance by the time
of the workshop.
</bodyText>
<sectionHeader confidence="0.966988" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.991990636363636">
The original idea of building a medical speech
translator of this kind was suggested by Dr
Vol Van Dalsem III, of El Camino Hospital,
Mountain View, CA. Dr Van Dalsem has also
provided many suggestions concerning sub do-
mains and coverage, and is actively collaborat-
ing with us on further development of the sys-
tem. Work on the initial prototype was carried
out at TIM/ISSCO, Geneva University, under
internal funding. The paper benefited greatly
from a number of discussions with Ian Lewin.
</bodyText>
<sectionHeader confidence="0.997653" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999775066666667">
H. Alshawi, S. Bangalore, and S. Douglas. 2000.
Learning dependency translation models as collec-
tions of finite state head transducers. Computa-
tional Linguistics, 26(1).
D. Carter, M. Rayner, et al. 2000. Evaluation. In
Rayner et al. (Rayner et al., 2000).
FlexiPC, 2002. http://www.flexipc.com/product/,
then &amp;quot;translator&amp;quot;. As of 15 Mar 2002.
R. Frederking, A. Rudnicky, and C. Hogan. 1997.
Interactive speech translation in the diplomat
project. In Proceedings of the Spoken Lan-
guage Translation workshop at the 35th Meeting
of the Association for Computational Linguistics,
Madrid, Spain.
IntegratedWaveTechnologies, 2002. http://www.i-
w-t.com/investor.html. As of 15 Mar 2002.
Nuance, 2002. http://www.nuance.com. As of 1 Feb
2002.
M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and
M. Wiren, editors. 2000. The Spoken Language
Translator. Cambridge University Press.
M. Rayner, J. Dowding, and B.A. Hockey. 2001.
A baseline method for compiling typed unifica-
tion grammars into context free language models.
In Proceedings of Eurospeech 2001, pages 729-732,
Aalborg, Denmark.
M. Theriault, 2002. Questionnaire de depistage pour
adultes (in French). As of 15 Mar 2002.
W. Wahlster, editor. 2000. Verbmobil: Foundations
of Speech-to-Speech Translation. Springer.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.000042">
<note confidence="0.966392666666667">Proceedings of the Workshop on Speech-to-Speech Translation: Algorithms and Systems, Philadelphia, July 2002, pp. 69-76. Association for Computational Linguistics.</note>
<abstract confidence="0.99928228165939">any of the paradigms we have mentioned. In this paper, we will be particularly interested in medical speech translation applications. There are good reasons to pay attention to medical domains; when we have talked to people about possible practical applications of speech translation technology, medical applications probably come up as frequently as all other application areas put together. The explanation is simple: there are no other areas where the potential payoff is as large, or as immediate. It requires little imagination to think of scenarios, not even particularly far-fetched ones, where access to a reliable medical speech translator could actually save someone&apos;s life. Anyone who has suddenly fallen ill in a country where they do not speak the local language will be aware that this is, for good reasons, an extremely frightening situation to be in. In most application areas, users are reluctant to use speech translation technology which is still far from perfect. With medical applications, many of these objections disappear; when their lives are at stake, people don&apos;t tend to be fussy. Given the above, one might wonder why medical speech translation systems are not already in common use. The answer is again clear. For exactly the same reasons, a medical speech translation system must be totally dependable; particularly in the US, the likely consequences of an accident resulting from a mistranslation are enough to convince most medical professionals that they should only use systems which they can trust completely. Unfortunately, this immediately rules out the first three architectures considered above. The completely domain-independent systems (3) are in no way reliable enough for this kind of work, and the inherent uncertainty involved in any kind of statistical approach makes it hard to believe that even a good domain-specific trainable system (2) would be regarded as acceptable. Elaborate linguistics-based systems (1) are better in this respect, but still not good enough; for example, the evaluation figures for the final version of the Spoken Language Translator (Carter et al., 2000) show that even correctly recognised utterances give bad or useless translations about 4% of the time. Having worked extensively with such systems, our strong impression is that a non-trivial proportion of bad translations is inescapable given today&apos;s methods. The key problem is that rule-based systems of this kind always permit fairly extensive ambiguity, which is in practice resolved using potentially fallible techniques of a statistical or heuristic nature. In addition to the question of reliability, it should be added that the extreme expense associated with developing and porting these systems would be a major practical obstacle to deploying them for the large number of sub-domains and language pairs required in practice. Fixed phrase translators, naturally, do not suffer from the above problems, and can be quite successful in some safety-critical domains. For example the system described in (IntegratedWaveTechnologies, 2002), which translates about 500 fixed phrases, has apparently been used in real situations by the Oakland Police Force. For medical domains, however, a fixed phrase translator appears to be too restrictive. A doctor doesn&apos;t simply want to ask whether the patient experiences a certain symptom; they typically need to ask whether they experience it seldom or often, whether they experience it at certain times of day or in connection with specified other activities, and so on. This can in principle be done using a fixed phrase translator, but a little experimentation shows that the resulting dialogues tend to be unbearably slow and frustrating for both partners. ( &amp;quot;Do you suffer from headaches?&amp;quot; ... &amp;quot;Often, sometimes, or only occasionally?&amp;quot; ... &amp;quot;After a meal?&amp;quot;) Splitting up questions in this way can also introduce misunderstandings; for example, a patient may give a negative answer to &amp;quot;Do you suffer from headaches?&amp;quot;, but a positive answer to &amp;quot;Do you from headaches?&amp;quot; None the less, it seems clear to us that the fixed-phrase approach is the one that comes closest to delivering what the users actually want. In the sequel, we will describe an architecture for what could be called a second-generation fixedphrase translator; essentially, it is a phrasal which allows some variation in the input language. This is close in spirit to the approach used in most normal phrase-books, which typically allow &amp;quot;slots&amp;quot; in at least some phrases ( &amp;quot;How much does cost?&amp;quot;; &amp;quot;How do I get to ?&amp;quot;). To elaborate, our architecture is motivated by the following main considerations: 1. The system should run on standard platforms, and be easy to install and use. 2. The architecture should support rapid development of versions for new domains, subdomain and language-pairs; in particular, it should be easy to add new output languages. 3. It should be possible to develop a system a sizeable corpus in tice, there never is a suitable corpus available. 4. Translation must be simple enough to be totally reliable. This will never be the case statistical methods hence the chitecture must be based on rule-based linguistic methods, preferably simple ones. In particular, the architecture must as far as possible reduce both the complexity of internal representations, and their potential ambiguity. The rest of the paper describes a concrete architecture motivated by the above considerations. Examples will be taken from our pilot application, a French-to-English phrasebook-style translator with a vocabulary of about 200 words, which allows a doctor to ask a patient questions relating to the symptoms of hypoglycaemia. 2 Overview of architecture The architecture comprises three main modules. These are respectively responsible for source language speech recognition, including parsing and production of semantic representation; transfer and generation; and synthesis of target language speech. The speech processing modules (recognition and synthesis) are implemented on top of the standard Nuance Toolkit platform (Nuance, 2002). The language processing modules (transfer and generation) are a suite of simple routines written in SICStus Prolog. Recognition is constrained by a CFG language model written in Nuance Grammar Specification Language (GSL), which also specifies the semantic representations produced. The grammar is not written by hand, but is rather compiled from a compact unification-grammar representation using the open source Regulus package (Rayner et al., 2001); the unification grammar, and the GSL representation it compiles into, are described in the next section. The speech and language processing modules communicate with each other through a minimal file-based protocol. The semantic representations on both the source and target sides are expressed as attribute-value structures. Transfer rules map sets of attribute-value pairs to sets of attributevalue pairs; the great majority of the rules map attribute-value pairs to single attributevalue pairs. Generation is handled by small Definite Clause Grammar (DCG), which converts attribute-value structures into surface strings; its output is passed through a minimal post-transfer component, which applies a set of rules which map fixed strings to fixed strings. Speech synthesis is performed by the Nuance Vocalizer TTS engine. 3 Recognition and grammar As described in the previous section, the recognition module is built on top of the Nuance Toolkit platform, using an annotated CFG language model consisting of a Nuance GSL grammar. This grammar is compiled from a unification-grammar representation using the Regulus tool. There are two important motivations for using unification grammar. Firstly, is more compact nature of unification grammar, compared to CFG, substantially reduces the implementation effort required. The grammar for our pilot application currently contains only 28 unification-grammar rules, excluding lexical entries; these expand out into over 400 CFG rules. An even more important advantage of using grammar is the CFG rules are all derived automatically from the same compact underlying code-base, the implementor can be confident that related groups of CFG rules are always kept in step with each other. This means that it is practically feasible to construct a large CFG grammar in a short time, and keep it stable even if non-trivial changes are introduced during the development process. In accordance with the generally minimalistic design philosophy of the project, semantic representations have been kept as simple as possible. The basic principle is that the representation of a clause is a flat list of attribute-value pairs: thus for example the representation of &amp;quot;avez-vous souvent des maux d&apos;estomac&amp;quot; (lit: &amp;quot;have you often pains of stomach&amp;quot;) (&amp;quot;do you often have stomach pains&amp;quot;) is the attribute-value list [[state, feel], [frequency, souyent] , [symptom, maux], [body_part, estomac]]] In a broad domain, it is of course trivial to construct examples where this kind of representation runs into serious problems. In the very narrow domain of a phrasebook translator, it has many desirable properties. Grammar rules can in nearly all cases construct the semantic representation of the mother node by simple concatenation of the semantic representations of the daughters&apos;. In general, the consequence is that operations on semantic representations typically manipulate lists rather than trees; the next section illustrates some of the advantages that follow from this fact. In a broad domain, we would pay a heavy price: the lack of structure in the semantic representations would often make them ambiguous. The very simple ontology of phrasebook domain however means that amonly exception in our prototype grammar is the rule which allows a clause introduced by the subordinatconjunction to act as a modifier. biguity is not a problem; the components of a flat list representation can never be derived from more than one functional structure, so this structure does not need to be explicitly present. 4 Transfer and generation The minimal list-based representation language makes it possible to implement a simple but effective transfer and generation module. Transfer operates by applying rules which map lists of attribute-value pairs to lists of attribute-value Most rules are lexicon entries, which map single attribute-value pairs to single attribute-value pairs associated with grammatical categories of the same kind. These pairs will often represent surface phrases consisting of more than one word. For example, following two respectively map poitrine&amp;quot; &amp;quot;tightness in the and la tele&amp;quot; &amp;quot;watch TV&amp;quot;: t_lex([symptom, serrement_poitrine], [symptom, tightness_in_the_chest]). t_lex([hum_act, regarder_ty], [hum_act, watch_ty]). may equally well map an attribute-value pair to an attribute-value pair associated with a different grammatical category; for example, the following entry maps the of the adjective the representation of the noun phrase &amp;quot;an alcoholic&amp;quot;: t_lex([symptom, alcoolique], [symptom, alcoholic]). It is also possible to write proper transfer rules map a set of attribute-value pairs to a set of attribute-value pairs; for examthe following d&apos;humeur &amp;quot;be of changing mood&amp;quot;) to &amp;quot;suffer from mood swings&amp;quot;: t_rule( [[state, etre] , [symptom, d_humeur_changeante]] , [[state, feel], [symptom, mood_swings]]). The list-based representation language has allowed us to implement a simple but efficient transfer rule interpreter, which applies these rules generally, irrespective of whether the pairs faintness, headache, confusion, convulsions, on the left-hand occur contiguously in the and coma; one of the reasons we have chosen source-language input. hypoglycaemia as a domain is that these Many systems have shown that it is easy to symptoms can coincide with those relating generate from the kind of simple attribute-value to many other conditions, which can often representations used here. Our system performs necessitate a lengthy verbal examination. In generation using a small DCG grammar; typour initial prototype, we have limited ourselves ically, a rule absorbs one or more items from to spoken yes/no questions, which we have the transferred attribute-value list, and generbased on those in a questionaire constructed ates one or more output words. Once again, the by the Association of Hypoglycaemics of Quelist-based representation made it easy to implebec (Theriault, 2002). In terms of content, ment the DCG in such a way that items can be all questions are assumed to be of the basic form absorbed in an arbitrary order. The result is that word-order differences between source and &amp;quot;Do you target pose no problems for translation. ?(often/sometimes/ever/...) Yet another advantage that follows from the (do something/experience symptom) minimal representation formalism is that it has ?(at time/when you do something)&amp;quot; been straightforward to write development tools that ensure internal consistency between the The grammar provides enough phrasal patterns source-language, transfer, and target-language that it is possible to ask about most domain lexica. Early on in the project, we wrote a concepts in a natural way. As described in the Prolog-based tool of this kind. If the sourcefirst section, however, we have intentionally language lexicon is extended or modified, the constructed the system as a phrase-book rather tool checks that each attribute-value pair in the than as a general translator. We only supply a source-language lexicon appears in the left-hand minimal set of grammar rules, and assume that side of at least one transfer lexicon entry; if necthe user will be prepared to invest a little time essary, blank entries are added to the transfer in learning how to express themselves within lexicon for the implementor to complete. Simithese bounds. larly, the tool checks that every attribute-value The reason why it is not completely trivial pair appearing in the right-hand side of a transconstruct a system of this kind is that one canfer lexicon entry also appears in at least one not naturally ask about all domain symptoms generation lexicon entry. Use of the tool makes using a single uniform phrasal pattern. The it possible to modify one part of the rule-base most common pattern is some version of without manually having to keep track of the permitting a rapid development ?&lt;freq&gt; &lt;symptom&gt; ?&lt;time&gt;&amp;quot; cycle. (&amp;quot;do you suffer from ?&lt;freq&gt; &lt;symptom&gt; ?&lt;time&gt;&amp;quot;) 5 A medical phrasebook translator so for example We have used the architecture outlined in the previous sections to construct a prototype French —&gt; English medical phrasebook translator. The basic scenario envisaged is that a French-speaking doctor suspects that an English-speaking patient may be suffering from some form of hypoglycaemia (low blood sugar). The symptoms of include anxiety, sweating, tachycardia, tremor, des engourdissements —&gt; &amp;quot;do you suffer from numbness?&amp;quot; or &amp;quot;eprouvez-vous souvent des maux de tete le matin ?&amp;quot; —&gt; &amp;quot;do you often suffer from headache in the morning?&amp;quot; However, there are many cases where some other pattern is required in order to express the question in a natural way. For example, we need to use the verb e.g. emotive you emotional?&amp;quot; or to use an intransitive or transitive verb, e.g. frequemment la nuit ?&amp;quot;— &amp;quot;do you often urinate at night?&amp;quot; d&apos;energie l&apos;apresmidi ?&amp;quot;—&gt; (lit. &amp;quot;lack you always energy the afternoon?&amp;quot;) &amp;quot;do you always suffer from lack of energy in the afternoon?&amp;quot; It may also be necessary to pose the question in the past tense, e.g. &amp;jet eu des convulsions ?&amp;quot; &amp;quot;have you ever suffered from convulsions?&amp;quot; Finally, French has several different ways to form yes/no questions, of which the most common are subject/verb inversion, e.g. enceinte ?&amp;quot; &amp;quot;are you pregnant?&amp;quot; fronting of que, que vous etes enceinte ?&amp;quot; que are pregnant?&amp;quot; the que construction is by default the preferred one in spoken French, there are many cases where inversion feels more natural, and it is in practice necessary to allow both constructions. Even when we try to keep the number of phrase types as low as we can, the choices along these different dimensions still multiply out to a non-trivial number of possibilities. The current prototype has a vocabulary of about 200 words. The unification grammar used to create the recogniser contains 28 non-lexical rules and 179 lexical rules. The transfer lexicon contains 12 complex transfer rules and 104 transfer lexicon entries. The target language DCG contains 24 phrase-structure rules and 141 generation lexicon entries, and the post-transfer component contains 16 string-to-string rewriting rules. Creation of these linguistic resources required something between one and two personweeks of expert effort; the most interesting aspect of this process was the focus we maintained thoughout on avoiding ambiguity in the analysis and generation grammars. This was primarily achieved by using sortal features consistently in both grammars, and maintaining a tight control of the domain ontology to ensure that the same sort of object can never occur in two different positions in a single clause. Occasionally this meant that the lexicon entries for a word had to be duplicated in two versions; for examcan occur both as part of temporal PP ( entre repas&amp;quot;, between meals&amp;quot;), or as the object of some verbs un repas&amp;quot;, a meal&amp;quot;). In cases like these, we included separate entries in the lexicon for the two usages of the word, giving them distinct sortal categories in the ontology. 6 Evaluation The real question we would like to answer when evaluating the prototype system is whether it is practically useful. Unfortunately, we are not yet in a position to do this, since the system is not mature enough in terms of coverage for it to be meaningful to subject it to a field trial. We thus have to content ourselves with more modest evaluation goals, and seek indirect evidence which suggests that an expanded version of the system could be useful. Some of this evidence consists of tests of the system&apos;s internal validity; in particular, we have carried out systematic checks that the analysis and generation grammars really are unambiguous, and that translation always produces an output. We do this using the Nuance Toolkit&apos;s to create large sets of (text) utterances within the coverage of the analysis grammar, and then processing them through the system with both grammars run in an all-solutions mode. A test of this kind on 10 000 randomly generated utterances showed that all 10 000 produced an output, and that for each utterance there was always exactly one possible semantic analysis, and one possible string generated from the transferred representation. In terms of external evaluation criteria, our architecture is primarily aimed at providing adequate recognition and reliable translation; it consequently makes sense to start by testing these aspects of performance. Specifically, we investigated the following two measures: 1. If the user says something within the system&apos;s coverage, how often is it correctly recognised? 2. If what the user says is correctly recognised, how often is it correctly translated? We investigated recognition quality on incoverage utterances by again randomly producing a set of 500 such utterances using the generate utility. Since the recognition grammar overgenerates, some of these utterances are ungrammatical or nonsensical; a human judge manually filtered the set to leave 195 good-quality utterances, averaging 6.8 words in length. The intention is that the translator would be normally used by experts who would have time to learn how to operate it. In order to simulate this pattern of use, we randomly divided the 195 good utterances into a &amp;quot;practice&amp;quot; set of 150 utterances and an &amp;quot;evaluation&amp;quot; set of 45 utterances. Five subjects (students who had not previously had exposure to the system) were each given twenty minutes to experiment with the system by reading out sentences from the practice set, and then competed on the task of reading out the evaluation utterances; each subject read each utterance once, and a small prize was given to the subject who got the best recognition result. Given the nature of the task, it seems more appropriate to evaluate in terms of sentence-level measures rather than error rates. We consequently scored utter-</abstract>
<note confidence="0.656559333333333">Subj WordsOK SemOK Bad Red 1 3 31 11 Rec2 32 5 8 Rec3 28 8 9 Rec4 18 6 21</note>
<date confidence="0.468418">Rec5 34 10 1</date>
<abstract confidence="0.929946378947368">Av. 24.6 6.4 14.0 (55%) (14%) (31%) Table 1: Recognition performance of 5 subjects reading 45 in-coverage utterances Subj Good OK Bad Trans1 141 6 3 Trans2 98 51 1 Trans3 90 55 5 Av. 110 37 3 (73%) (25%) (2%) Table 2: Quality of translation on 150 incoverage utterances, as evaluated by three independent judges ances as belonging to one of three possible categories: &amp;quot;WordsOK&amp;quot; (no word errors), &amp;quot;SemOK&amp;quot; (at least one word error, but the semantic representation was correct), and &amp;quot;Bad&amp;quot; (no recognition, or incorrect semantic representation). The results are presented in Table 1. In order to investigate the second question (translation quality), we randomly generated a new set of 150 in-coverage utterances, and process them through the system to produce text outputs. We then asked three independent judges to evaluate the either fully correct (&amp;quot;Good&amp;quot;), acceptable (&amp;quot;OK&amp;quot;) or incorrect/nonsensical (&amp;quot;Bad&amp;quot;). The results are presented in Table 2. Although this evaluation makes no pretentions to being definitive, we find the results encouraging. Three of our five test users were able to adapt quickly to the system, and achieved high recognition accuracy after only a short practice period. We were initially concerned that as many as 2% of the utterances were mistranslated. Analysis of the results however revealed that these utterances were problematic for reasons that had more to do with the evaluation methodology than the system. The judges did not appear to have strong intuitions about the correctness or otherwise of the critical translations; no translation was marked as bad by all three judges, and only one translation was marked as bad by two judges out of three. It was also noticeable that at least half of the source-language utterances which resulted in &amp;quot;bad&amp;quot; translations were dubious either syntactically or pragmatically, and should arguably have been filtered out when preparing the evaluation data. We intend soon to carry out a revised which these issues. 7 Conclusion and further directions The main point we want to make in this paper is that today&apos;s technology makes it possible to build limited-domain speech to speech translators which represent an interesting compromise between trivial fixed-phase systems on the one hand and sophisticated VERBmoBIL-style systems on the other. These systems can offer sufficient coverage to allow a user to express themselves fairly freely after a little practice, but are still constrained enough that they appear to have the potential to reach levels of reliability appropriate for medical and other safety-critical applications. They can be quickly constructed on top of standard commercial platforms like the Nuance Toolkit, and run on ordinary PCs. As already indicated, the critical question is whether a system of this kind can be expanded to the point where it becomes practically useful. In particular, it is still unclear how much more grammar and vocabulary are needed in order to achieve this goal, and how much perif coverage is increased accordingly. In concrete terms, this amounts to asking whether it is feasible to construct controlled languages for at least some interesting domains which achieve a suitable balance between coverage and performance. We have now begun implementation of a second and more elaborate version of the system, and expect to be able to report on its performance by the time of the workshop. Acknowledgements The original idea of building a medical speech translator of this kind was suggested by Dr Van Dalsem El Camino Hospital, Mountain View, CA. Dr Van Dalsem has also provided many suggestions concerning sub domains and coverage, and is actively collaborating with us on further development of the system. Work on the initial prototype was carried at Geneva University, under internal funding. The paper benefited greatly from a number of discussions with Ian Lewin.</abstract>
<note confidence="0.803759428571428">References H. Alshawi, S. Bangalore, and S. Douglas. 2000. Learning dependency translation models as collecof finite state head transducers. Computa- Linguistics, D. Carter, M. Rayner, et al. 2000. Evaluation. In Rayner et al. (Rayner et al., 2000). FlexiPC, 2002. http://www.flexipc.com/product/, then &amp;quot;translator&amp;quot;. As of 15 Mar 2002. R. Frederking, A. Rudnicky, and C. Hogan. 1997. Interactive speech translation in the diplomat In of the Spoken guage Translation workshop at the 35th Meeting of the Association for Computational Linguistics,</note>
<address confidence="0.740908">Madrid, Spain. IntegratedWaveTechnologies, 2002. http://www.i-</address>
<note confidence="0.899794066666667">w-t.com/investor.html. As of 15 Mar 2002. Nuance, 2002. http://www.nuance.com. As of 1 Feb 2002. M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and Wiren, editors. 2000. Spoken Language University Press. M. Rayner, J. Dowding, and B.A. Hockey. 2001. A baseline method for compiling typed unification grammars into context free language models. of Eurospeech 2001, Aalborg, Denmark. M. Theriault, 2002. Questionnaire de depistage pour adultes (in French). As of 15 Mar 2002. Wahlster, editor. 2000. Foundations Speech-to-Speech Translation.</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>H Alshawi</author>
<author>S Bangalore</author>
<author>S Douglas</author>
</authors>
<title>Learning dependency translation models as collections of finite state head transducers.</title>
<date>2000</date>
<journal>Computational Linguistics,</journal>
<volume>26</volume>
<issue>1</issue>
<marker>Alshawi, Bangalore, Douglas, 2000</marker>
<rawString>H. Alshawi, S. Bangalore, and S. Douglas. 2000. Learning dependency translation models as collections of finite state head transducers. Computational Linguistics, 26(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Carter</author>
<author>M Rayner</author>
</authors>
<date>2000</date>
<booktitle>Evaluation. In Rayner et</booktitle>
<marker>Carter, Rayner, 2000</marker>
<rawString>D. Carter, M. Rayner, et al. 2000. Evaluation. In Rayner et al. (Rayner et al., 2000).</rawString>
</citation>
<citation valid="true">
<authors>
<author>FlexiPC</author>
</authors>
<title>http://www.flexipc.com/product/, then &amp;quot;translator&amp;quot;.</title>
<date>2002</date>
<journal>As of</journal>
<volume>15</volume>
<marker>FlexiPC, 2002</marker>
<rawString>FlexiPC, 2002. http://www.flexipc.com/product/, then &amp;quot;translator&amp;quot;. As of 15 Mar 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Frederking</author>
<author>A Rudnicky</author>
<author>C Hogan</author>
</authors>
<title>Interactive speech translation in the diplomat project.</title>
<date>1997</date>
<booktitle>In Proceedings of the Spoken Language Translation workshop at the 35th Meeting of the Association for Computational Linguistics,</booktitle>
<location>Madrid,</location>
<marker>Frederking, Rudnicky, Hogan, 1997</marker>
<rawString>R. Frederking, A. Rudnicky, and C. Hogan. 1997. Interactive speech translation in the diplomat project. In Proceedings of the Spoken Language Translation workshop at the 35th Meeting of the Association for Computational Linguistics, Madrid, Spain.</rawString>
</citation>
<citation valid="true">
<authors>
<author>IntegratedWaveTechnologies</author>
</authors>
<title>http://www.iw-t.com/investor.html.</title>
<date>2002</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="3237" citStr="IntegratedWaveTechnologies, 2002" startWordPosition="503" endWordPosition="505"> kind always permit fairly extensive ambiguity, which is in practice resolved using potentially fallible techniques of a statistical or heuristic nature. In addition to the question of reliability, it should be added that the extreme expense associated with developing and porting these systems would be a major practical obstacle to deploying them for the large number of sub-domains and language pairs required in practice. Fixed phrase translators, naturally, do not suffer from the above problems, and can be quite successful in some safety-critical domains. For example the system described in (IntegratedWaveTechnologies, 2002), which translates about 500 fixed phrases, has apparently been used in real situations by the Oakland Police Force. For medical domains, however, a fixed phrase translator appears to be too restrictive. A doctor doesn&apos;t simply want to ask whether the patient experiences a certain symptom; they typically need to ask whether they experience it seldom or often, whether they experience it at certain times of day or in connection with specified other activities, and so on. This can in principle be done using a fixed phrase translator, but a little experimentation shows that the resulting dialogues</context>
</contexts>
<marker>IntegratedWaveTechnologies, 2002</marker>
<rawString>IntegratedWaveTechnologies, 2002. http://www.iw-t.com/investor.html. As of 15 Mar 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nuance</author>
</authors>
<title>http://www.nuance.com.</title>
<date>2002</date>
<journal>As of</journal>
<volume>1</volume>
<contexts>
<context position="6313" citStr="Nuance, 2002" startWordPosition="1001" endWordPosition="1002"> our pilot application, a French-to-English phrasebook-style translator with a vocabulary of about 200 words, which allows a doctor to ask a patient questions relating to the symptoms of hypoglycaemia. 2 Overview of architecture The architecture comprises three main modules. These are respectively responsible for source language speech recognition, including parsing and production of semantic representation; transfer and generation; and synthesis of target language speech. The speech processing modules (recognition and synthesis) are implemented on top of the standard Nuance Toolkit platform (Nuance, 2002). The language processing modules (transfer and generation) are a suite of simple routines written in SICStus Prolog. Recognition is constrained by a CFG language model written in Nuance Grammar Specification Language (GSL), which also specifies the semantic representations produced. The grammar is not written by hand, but is rather compiled from a compact unification-grammar representation using the open source Regulus package (Rayner et al., 2001); the unification grammar, and the GSL representation it compiles into, are described in the next section. The speech and language processing modul</context>
</contexts>
<marker>Nuance, 2002</marker>
<rawString>Nuance, 2002. http://www.nuance.com. As of 1 Feb 2002.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>D Carter</author>
<author>P Bouillon</author>
<author>V</author>
</authors>
<title>The Spoken Language Translator.</title>
<date>2000</date>
<editor>Digalakis, and M. Wiren, editors.</editor>
<publisher>Cambridge University Press.</publisher>
<marker>Rayner, Carter, Bouillon, V, 2000</marker>
<rawString>M. Rayner, D. Carter, P. Bouillon, V. Digalakis, and M. Wiren, editors. 2000. The Spoken Language Translator. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Rayner</author>
<author>J Dowding</author>
<author>B A Hockey</author>
</authors>
<title>A baseline method for compiling typed unification grammars into context free language models.</title>
<date>2001</date>
<booktitle>In Proceedings of Eurospeech</booktitle>
<pages>729--732</pages>
<location>Aalborg, Denmark.</location>
<contexts>
<context position="6766" citStr="Rayner et al., 2001" startWordPosition="1068" endWordPosition="1071">esis of target language speech. The speech processing modules (recognition and synthesis) are implemented on top of the standard Nuance Toolkit platform (Nuance, 2002). The language processing modules (transfer and generation) are a suite of simple routines written in SICStus Prolog. Recognition is constrained by a CFG language model written in Nuance Grammar Specification Language (GSL), which also specifies the semantic representations produced. The grammar is not written by hand, but is rather compiled from a compact unification-grammar representation using the open source Regulus package (Rayner et al., 2001); the unification grammar, and the GSL representation it compiles into, are described in the next section. The speech and language processing modules communicate with each other through a minimal file-based protocol. The semantic representations on both the source and target sides are expressed as attribute-value structures. Transfer rules map sets of attribute-value pairs to sets of attributevalue pairs; the great majority of the rules map single attribute-value pairs to single attributevalue pairs. Generation is handled by a small Definite Clause Grammar (DCG), which converts attribute-value</context>
</contexts>
<marker>Rayner, Dowding, Hockey, 2001</marker>
<rawString>M. Rayner, J. Dowding, and B.A. Hockey. 2001. A baseline method for compiling typed unification grammars into context free language models. In Proceedings of Eurospeech 2001, pages 729-732, Aalborg, Denmark.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Theriault</author>
</authors>
<title>Questionnaire de depistage pour adultes (in French).</title>
<date>2002</date>
<journal>As of</journal>
<volume>15</volume>
<contexts>
<context position="12992" citStr="Theriault, 2002" startWordPosition="2010" endWordPosition="2011">enerate from the kind of simple attribute-value to many other conditions, which can often representations used here. Our system performs necessitate a lengthy verbal examination. In generation using a small DCG grammar; typ- our initial prototype, we have limited ourselves ically, a rule absorbs one or more items from to spoken yes/no questions, which we have the transferred attribute-value list, and gener- based on those in a questionaire constructed ates one or more output words. Once again, the by the Association of Hypoglycaemics of Quelist-based representation made it easy to imple- bec (Theriault, 2002). In terms of content, ment the DCG in such a way that items can be all questions are assumed to be of the basic form absorbed in an arbitrary order. The result is that word-order differences between source and &amp;quot;Do you target pose no problems for translation. ?(often/sometimes/ever/...) Yet another advantage that follows from the (do something/experience symptom) minimal representation formalism is that it has ?(at time/when you do something)&amp;quot; been straightforward to write development tools that ensure internal consistency between the The grammar provides enough phrasal patterns source-languag</context>
</contexts>
<marker>Theriault, 2002</marker>
<rawString>M. Theriault, 2002. Questionnaire de depistage pour adultes (in French). As of 15 Mar 2002.</rawString>
</citation>
<citation valid="true">
<title>Verbmobil: Foundations of Speech-to-Speech Translation.</title>
<date>2000</date>
<editor>W. Wahlster, editor.</editor>
<publisher>Springer.</publisher>
<marker>2000</marker>
<rawString>W. Wahlster, editor. 2000. Verbmobil: Foundations of Speech-to-Speech Translation. Springer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>