<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000001">
<title confidence="0.458975">
On the complexity of alignment problems in two synchronous grammar
formalisms
</title>
<author confidence="0.917728">
Anders Søgaard∗
</author>
<affiliation confidence="0.9894965">
Center for Language Technology
University of Copenhagen
</affiliation>
<email confidence="0.991836">
soegaard@hum.ku.dk
</email>
<sectionHeader confidence="0.9966" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999845">
The alignment problem for synchronous
grammars in its unrestricted form, i.e. whether
for a grammar and a string pair the grammar
induces an alignment of the two strings, re-
duces to the universal recognition problem,
but restrictions may be imposed on the align-
ment sought, e.g. alignments may be 1 : 1,
island-free or sure-possible sorted. The com-
plexities of 15 restricted alignment problems
in two very different synchronous grammar
formalisms of syntax-based machine transla-
tion, inversion transduction grammars (ITGs)
(Wu, 1997) and a restricted form of range
concatenation grammars ((2,2)-BRCGs) (Sø-
gaard, 2008), are investigated. The universal
recognition problems, and therefore also the
unrestricted alignment problems, of both for-
malisms can be solved in time O(n6|G|). The
complexities of the restricted alignment prob-
lems differ significantly, however.
</bodyText>
<sectionHeader confidence="0.99888" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99910975">
The synchronous grammar formalisms used in
syntax-based machine translation typically induce
alignments by aligning all words that are recog-
nized simultaneously (Wu, 1997; Zhang and Gildea,
</bodyText>
<footnote confidence="0.697557666666667">
∗This work was done while the first author was a Senior
Researcher at the Dpt. of Linguistics, University of Potsdam,
supported by the German Research Foundation in the Emmy
Noether project Ptolemaios on grammar learning from paral-
lel corpora; and while he was a Postdoctoral Researcher at the
ISV Computational Linguistics Group, Copenhagen Business
School, supported by the Danish Research Foundation in the
project Efficient syntax- and semantics-based machine transla-
tion.
</footnote>
<bodyText confidence="0.999682588235294">
2004). On a par with weak and strong generative ca-
pacity, it is thus possible to talk about the alignment
capacity of those formalisms. In this paper, two syn-
chronous grammar formalisms are discussed, inver-
sion transduction grammars (ITGs) (Wu, 1997) and
two-variable binary bottom-up non-erasing range
concatenation grammars ((2,2)-BRCGs) (Søgaard,
2008). It is known that ITGs do not induce the class
of inside-out alignments discussed in Wu (1997).
Another class that ITGs do not induce is that of
alignments with discontinuous translation units (Sø-
gaard, 2008). Søgaard (2008), on the other hand,
shows that the alignments induced by (2,2)-BRCGs
are closed under union, i.e. (2,2)-BRCGs induce all
possible alignments.
The universal recognition problems of both ITGs
and (2,2)-BRCGs can be solved in time O(n6|G|).
This may come as a surprise, as ITGs restrict the
alignment search space considerably, while (2,2)-
BRCGs do not. In the context of the NP-hardness of
decoding in statistical machine translation (Knight,
1999; Udupa and Maji, 2006), it is natural to ask
why the universal recognition problem of (2,2)-
BRCGs isn’t NP-hard? How can (2,2)-BRCGs in-
duce all possible alignments and still avoid NP-
hardness? This paper bridges the gap between
these results and shows that when alignments are
restricted to be 1 : 1, island-free or sure-possible
sorted (see below), or all combinations thereof,
the alignment problem of (2,2)-BRCGs is NP-hard.
(2,2)-BRCGs in a sense avoid NP-hardness by giv-
ing up control over global properties of alignments,
e.g. any pair of words may be aligned multiple times
in a derivation.
</bodyText>
<page confidence="0.983647">
60
</page>
<note confidence="0.971561">
Proceedings of SSST-3, Third Workshop on Syntax and Structure in Statistical Translation, pages 60–68,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<bodyText confidence="0.938450282051282">
The alignment structures induced by synchronous
grammars in syntax-based machine translation have
the following property: If an alignment structure in-
cludes alignments v|v′, v|w′ and w|w′, it also in-
cludes the alignment w|v′, where w, w′, v, v′ are
word instances.1 This follows from the fact that
only words that are recognized simultanously, are
aligned. Otherwise alignment structures are just a
binary symmetric relation on two strings, a source
and a target string, such that two words in the source,
resp. target string, cannot be aligned. Maximally
connected subgraphs (ignoring precedence edges)
are called translation units.
The alignment problem can be formulated this
way (with s, s′ source and target sentence, resp.):
INSTANCE: G, hs, s′i.
QUESTION: Does G induce an alignment
on hs, s′i?
The alignment problem in its unrestricted form
reduces to the universal recognition problem (Bar-
ton et al., 1987), i.e. whether for a grammar G and
a string pair hs, s′i it holds that hs, s′i ∈ L(G)?
Of course the alignment may in this case be empty
or partial. Both ITGs and (2,2)-BRCGs permit un-
aligned nodes.
This paper investigates the complexity of re-
stricted versions of the alignment problem for ITGs
and (2,2)-BRCGs. A simple example, which can
be solved in linear time for both formalisms, is the
alignment problem wrt. alignments that consist of a
single translation unit including all source and target
words. It may be formulated this way:
INSTANCE: G, hs, s′i.
QUESTION: Does G induce an alignment that
consists of a single translation unit
with no unaligned words on hs, s′i?
This can be solved for ITGs by checking if there
is a production rule that introduces all the words in
the right order such that:2
</bodyText>
<footnote confidence="0.95948475">
1w|w′ is our short hand notation for saying that w, a word
in the source string, and w′, a word in the target string, have
been aligned. In the formal definition of alignments below, it is
said that w G Vs (w is a word in the source string), w′ G Vt
(w′ is a word in the target string) and (w, w′) G A, i.e. w is
aligned to w′, and vice versa. Alignments are bidirectional in
what follows.
2In fact in normal form ITGs, we can simply check if there
</footnote>
<listItem confidence="0.9951478">
• The LHS nonterminal symbol (possibly suf-
fixed by the empty string c) can be derived from
the start symbol.
• The empty string c can be derived from all RHS
nonterminal symbols.
</listItem>
<bodyText confidence="0.996304135135135">
The only difference for (2,2)-BRCGs is that pro-
duction rules are typically referred to as clauses in
the range concatenation grammar literature.
This paper considers some more complex exam-
ples; namely, the alignment problems wrt. 1 : 1-
alignments, (source-side and/or target-side) island-
free alignments and sure-possible sorted alignments.
The formal definitions of the three properties are as
follows:
Definition 1.1. An alignment structure for a string
pair hw1 ... wn, vi ... vmi is a graph D = hV, Ei
where V = Vs : {w1,...,wn} ∪ Vt : {vi,...,vm}
and E = Es : {wi ≺ wj  |i &lt; j} ∪ Et : {vi ≺ vj |
i &lt; j} ∪ A where A ⊆ Vs × Vt. If (wi, vj) ∈ A,
also written wi|vj, wi is said to be aligned to vj,
and vice versa. An alignment structure is said to
be wellformed iff for all wi, wj, vi′, vj′ it holds that
if wi|vi′,wi|vj′ and wj|vi′ are aligned then so are
wj|vj′. An alignment structure is said to be 1 : 1 iff
no word occurs in two distinct tuples in A. An align-
ment structure is said to be island-free iff all words
in V occur in some tuple in A; it is said to be source-
side, resp. target-side, island-free if all words in Vs,
resp. Vt, occur in some tuple in A. The set of align-
ments is divided into sure and possible alignments,
i.e. A = 5 ∪ P (in most cases P = ∅). An align-
ment structure is said to be sure-possible sorted iff if
it holds that (wi, vj′) ∈ 5 then for all wj, vi′ neither
(wi, vi′) ∈ P nor (wj, vj′) ∈ P holds; similarly, if
it holds that (wi, vj′) ∈ P then for all wj, vi′ neither
(wi, vi′) ∈ 5 nor (wj, vj′) ∈ 5 holds.
The precedence relations in E are not important
for any of our definitions, but are important for
meaningful interpretation of alignment structures.
Note that synchronous grammars are guaranteed to
induce wellformed alignment structures. Some brief
motivation for the properties singled out:
</bodyText>
<footnote confidence="0.9870475">
is a production rule with the start symbol in the LHS that in-
troduces all the words in the right order, since all production
rules with nonterminal symbols in the RHS are branching and
contain no terminal symbols.
</footnote>
<page confidence="0.996492">
61
</page>
<table confidence="0.8683742">
Result 1 : 1 IF(s) IF(t) SP ITGs (2,2)-BRCGs
X O(n6|G|) NP-complete
X O(n6|G|) NP-complete
X O(n6|G|) NP-complete
X O(n6|G|) NP-complete
</table>
<equation confidence="0.919084727272727">
X X O(n6|G|) NP-complete
X X O(n6|G|) NP-complete
X X O(n6|G|) NP-complete
X X O(n6|G|) NP-complete
X X O(n6|G|) NP-complete
X X O(n6|G|) NP-complete
X X X O(n6|G|) NP-complete
X X X O(n6|G|) NP-complete
X X X O(n6|G|) NP-complete
X X X O(n6|G|) NP-complete
X X X X O(n6|G|) NP-complete
</equation>
<figureCaption confidence="0.998795">
Figure 1: The complexity of restricted alignment problems for ITGs and (2,2)-BRCGs.
</figureCaption>
<listItem confidence="0.992001071428571">
• 1 : 1-alignments have been argued to be ad-
equate by Melamed (1999) and elsewhere, and
it may therefore be useful to know if a grammar
extracted from a parallel corpus produces 1 : 1-
alignments for a finite set of sentence pairs.
• Island-free alignments are interesting to the ex-
tent that unaligned nodes increase the chance of
translation errors. An island threshold may for
instance be used to rule out risky translations.
• The notion of sure-possible sorted alignments
is more unusual, but can, for instance, be used
to check if the use of possible alignments is
consistently triggered by words that are hard to
align.
</listItem>
<bodyText confidence="0.999134555555556">
The results for all cross-classifications of the
four properties – 1 : 1, source-side island-free
(IF(s)), target-side island-free (IF(t)) and sure-
possible sorted (SP) – are presented in the table in
Figure 1.3 Note that all (24 − 1 = 15) combina-
tions of the four properties lead to NP-hard align-
ment problems for (2,2)-BRCGs. Consequently,
3One of our reviewers remarks that the Figure 1 is ’artifi-
cially blown up’, since all combinations have the same com-
plexity. It cannot really be left out, however. The numbers in
the figure’s left-most column serves as a reference in the proofs
below. Since the 15 results derive from only four proofs, it is
convenient to have a short-hand notation for the decision prob-
lems.
while the unrestricted alignment problem for (2,2)-
BRCGs can be solved in O(n6|G|), the alignment
problem turns NP-hard as soon as restrictions are put
on the alignments sought. So the extra expressivity
of (2,2)-BRCGs in a way comes at the expense of
control over the kind of alignments obtained.
On the structure of the paper: Sect. 2 and 3 briefly
introduce, resp., ITGs and (2,2)-BRCGs. Sect. 4
presents three NP-hardness proofs from which the
15 results in Figure 1 can be derived. The three
proofs are based on reconstructions of the Hamilton
circuit problem, the 3SAT problem and the vertex
cover problem (Garey and Johnson, 1979).
</bodyText>
<sectionHeader confidence="0.93019" genericHeader="method">
2 Inversion transduction grammars
</sectionHeader>
<bodyText confidence="0.99938875">
Inversion transduction grammars (ITGs) (Wu, 1997)
are a notational variant of binary syntax-directed
translation schemas (Aho and Ullman, 1972) and are
usually presented with a normal form:
</bodyText>
<figure confidence="0.494922">
A [BC]
A (BC)
A e  |f
A e  |E
A E  |f
</figure>
<bodyText confidence="0.999524666666667">
where A, B, C E N and e, f E T. The
first production rule, intuitively, says that the sub-
tree [[]B[]C]A in the source language translates into
</bodyText>
<page confidence="0.995684">
62
</page>
<bodyText confidence="0.999115142857143">
a subtree [[]B[]C]A, whereas the second produc-
tion rule inverts the order in the target language,
i.e. [[]C[]B]A. The universal recognition problem of
ITGs can be solved in time O(n6|G|) by a CYK-
style parsing algorithm with two charts.
Figure 1 tells us that all the restricted alignment
problems listed can be solved in time O(n6|G|).
The explanation is simple. It can be read off from
the syntactic form of the production rules in ITGs
whether they introduce 1 : 1-alignments, island-free
alignments or sure-possible sorted alignments. Note
that normal form ITGs only induce 1 : 1-alignments.
Consider, for example, the following grammar,
not in normal form for brevity:
</bodyText>
<listItem confidence="0.99943175">
(1) S → hASBi  |hABi
(2) A → a  |a
(3) A → a  |E
(4) B → b  |b
</listItem>
<bodyText confidence="0.996535222222222">
Note that this grammar recognizes the transla-
tion {hanbn, bnam  |n ≥ m}. To check if for a
string pair hw1 ... wn, v1 ... vmi this grammar in-
duces an island-free alignment, simply remove pro-
duction rule (3). It holds that only strings in the sub-
language {hanbn, bnan  |n ≥ 1} induce island-free
alignments. Similarly, to check if the grammar in-
duces source-side island-free alignments for string
pairs, no production rules will have to be removed.
</bodyText>
<sectionHeader confidence="0.712291" genericHeader="method">
3 Two-variable binary bottom-up
non-erasing range concatenation
grammars
</sectionHeader>
<bodyText confidence="0.995202838709677">
(2,2)-BRCGs are positive RCGs (Boullier, 1998)
with binary start predicate names, i.e. p(S) = 2. In
RCG, predicates can be negated (for complementa-
tion), and the start predicate name is typically unary.
The definition is changed only for aesthetic rea-
sons; a positive RCG with a binary start predicate
name S is turned into a positive RCG with a unary
start predicate name S′ simply by adding a clause
S′(X1X2) → S(X1,X2).
A positive RCG is a 5-tuple G = hN, T, V, P, Si.
N is a finite set of predicate names with an arity
function p: N → N, T and V are finite sets of, resp.,
terminal and variables. P is a finite set of clauses of
the form 00 → 01 ... 0m, where each of the 0z, 0 ≤
i ≤ m, is a predicate of the form A(α1, ... , αρ(A)).
Each αj ∈ (T ∪V )∗, 1 ≤ j ≤ p(A), is an argument.
S ∈ N is the start predicate name with p(S) = 2.
Note that the order of RHS predicates in a clause
is of no importance. Three subclasses of RCGs are
introduced for further reference: An RCG G =
hN, T, V, P, Si is simple iff for all c ∈ P, it holds
that no variable X occurs more than once in the
LHS of c, and if X occurs in the LHS then it oc-
curs exactly once in the RHS, and each argument
in the RHS of c contains exactly one variable. An
RCG G = hN, T, V, P, Si is a k-RCG iff for all A ∈
N, p(A) ≤ k. Finally, an RCG G = hN, T, V, P, Si
is said to be bottom-up non-erasing iff for all c ∈ P
all variables that occur in the RHS of c also occur in
its LHS.
A positive RCG is a (2,2)-BRCG iff it is a 2-RCG,
if an argument of the LHS predicate contains at most
two variables, and if it is bottom-up non-erasing.
The language of a (2,2)-BRCG is based
on the notion of range. For a string pair
hw1 ... wn, vn+2 ... vn+1+mi a range is a pair
of indices hi, ji with 0 ≤ i ≤ j ≤ n or
n &lt; i ≤ j ≤ n + 1 + m, i.e. a string span,
which denotes a substring wz+1 ... wj in the source
string or a substring vz+1 ... vj in the target string.
Only consequtive ranges can be concatenated into
new ranges. Terminals, variables and arguments
in a clause are bound to ranges by a substitution
mechanism. An instantiated clause is a clause in
which variables and arguments are consistently
replaced by ranges; its components are instantiated
predicates. For example A(hg ... hi, hi ... ji) →
B(hg ... hi, hi + 1... j − 1i) is an instantiation
of the clause A(X1,aY1b) → B(X1,Y1) if the
target string is such that vz+1 = a and vj = b.
A derive relation =⇒ is defined on strings of
instantiated predicates. If an instantiated predicate
is the LHS of some instantiated clause, it can be
replaced by the RHS of that instantiated clause. The
language of a (2,2)-BRCG G = hN, T, V, P, Si is
the set L(G) = {hw1 ... wn, vn+2 . . . vn+1+mi |
S(h0, ni, hn + 1, n + 1 + mi) =⇒∗ E}, i.e. an
input string pair hw1 ... wn, vn+2 ... vn+1+mi is
recognized iff the empty string can be derived from
S(h0, ni, hn + 1, n + 1 + mi).
It is not difficult to see that ITGs are also (2,2)-
BRCGs. The left column is ITG production rules;
</bodyText>
<page confidence="0.997473">
63
</page>
<bodyText confidence="0.99041">
Note that L(G) = {hanbmcndm, (ab)n(cd)mi |
m, n ≥ 0}.
the right column their translations in simple (2,2)-
BRCGs.
</bodyText>
<equation confidence="0.9893045">
A(X1X2,Y1Y2) → B(X1,Y1)C(X2,Y2)
A(X1X2,Y1Y2) → B(X1,Y2)C(X2,Y1)
A(e, f) → e
A(e, e) → e
</equation>
<sectionHeader confidence="0.999065" genericHeader="evaluation">
4 Results
</sectionHeader>
<subsectionHeader confidence="0.991518">
4.1 Checking island-freeness and sure-possible
</subsectionHeader>
<figure confidence="0.972549166666667">
sortedness
A → [BCI
A → hBCi
A → e  |f
A → e  |e
A → e  |f A(e, f) → e
</figure>
<bodyText confidence="0.9229285">
Consequently, (2,2)-BRCGs recognize all trans-
lations recognized by ITGs. In fact the inclusion is
strict, as shown in Søgaard (2008). The universal
recognition problem of (2,2)-BRCGs can be solved
in time O(n6|G|) by the CYK-style parsing algo-
rithm presented in Søgaard (2008).
Example 3.1. Consider the (2,2)-BRCG G =
h{Ss, S0, S′0, S1, S′1, A, B, C, D}, {a, b, c, d}, {X1,
X2, Y1, Y2}, P, Ssi with P the following set of
clauses:
</bodyText>
<equation confidence="0.995725133333333">
S3(X1,Y1) → S0(X1, Y1)S′0(X1, Y1)
S0(X1X2,Y1) → S1(X1,Y1)D(X2)
S1(aX1c,abY1) → S1(X1,Y1)
S1(X1,Y1Y2) → B(X1)C(Y1)D(Y2)
S′0(X1X2,Y1) → S′1(X2,Y1)A(X1)
S′1(bX1d,Y1cd) → S′1(X1,Y1)
S′1(X1,Y1Y2) → C(X1)A(Y1)B(Y2)
A(aX1) → A(X1)
A(e) → e
B(bX1) → B(X1)
B(e) → e
C(cX1) → C(X1)
C(e) → e
D(dX1) → D(X1)
D(e) → e
</equation>
<bodyText confidence="0.559725">
The string pair habbcdd, abcdcdi is derived:
S3(h0,6i, h0,6i)
</bodyText>
<table confidence="0.986677071428571">
=⇒ S0(h0, 6i, h0,6i)S′0(h0, 6i, h0,6i)
=⇒ S1(h0, 4i, h0,6i)D(h4, 6i)
S′0(h0,6i, h0,6i)
=⇒ S1(h0, 4i, h0,6i)S′0(h0, 6i, h0,6i) (14–15)
=⇒ S1(h1, 3i, h2,6i)S′0(h0, 6i, h0,6i)
=⇒ B(h1, 3i)C(h2, 4i)D(h4, 6i)
S′0(h0,6i, h0,6i)
=⇒ S′0(h0, 6i, h0,6i) (10–15)
=⇒ S′1(h1, 6i, h0, 6i)A(h0,1i)
=⇒ S′1(h1,6i, h0,6i) (8–9)
=⇒ S′1(h2,5i, h0,4i)
=⇒ S′1(h3,4i, h0,2i) (6)
=⇒ C(h3, 4i)A(h0,1i)B(h1, 2i)
=⇒ e (8–13)
</table>
<bodyText confidence="0.999852096774193">
One possible way to check for island-freeness and
sure-possible sortedness in the context of (2,2)-
BRCGs is to augment the CYK-style algorithm with
feature structures (Boolean vectors); all there is
needed, e.g. to check sure-possible sortedness, is to
pair up the nonterminals inserted in the cells of the
chart with a flat feature structure of the form:
where n is the length of the source, resp. tar-
get, string in the source, resp. target, chart, and
1 ≤ i ≤ n : vali ∈ {+, −}. When a clause ap-
plies that induces a sure alignment between a word
wi and some word in the target, resp. source, string,
the attribute SUREi is assigned the value +; if a pos-
sible alignment is induced between wi and another
word, the attribute is assigned the value -. This can
all be done in constant time. A copying clause now
checks if the appropriate nonterminals have been in-
serted in the cells in question, but also that the as-
sociated feature structures unify. This can be done
in linear time. Feature structures can be used the
same way to record what words have been aligned to
check island-freeness. Unfortunately, this technique
does not guarantee polynomial runtime. Note that
there can be 2n many distinct feature structures for
each nonterminal symbol in a chart. Consequently,
whereas the size of a cell in the standard CYK algo-
rithm is bounded by |N|, and in synchronous parsing
by |N |× (2n −1),4 the cells are now of exponential
size in the worst case.
The following three sections provide three NP-
hardness proofs: The first shows that the alignment
</bodyText>
<footnote confidence="0.797013333333333">
4The indices used to check that two nonterminals are derived
simultaneously (Søgaard, 2008) mean that it may be necessary
within a cell in the source, resp. target, chart to keep track of
multiple tuples with the same nonterminals. In the worst case,
there is a nonterminal for each span in the target, resp. source,
chart, i.e. 2n − 1 many.
</footnote>
<figure confidence="0.991014857142857">
SURE1 val1
...
⎤
⎦⎥⎥
SUREn valn
⎡
⎢ ⎢ ⎣
</figure>
<page confidence="0.995535">
64
</page>
<bodyText confidence="0.973188378378378">
problem wrt. 1 : 1-alignments is NP-hard for (2,2)-
BRCGs and goes by reduction of the Hamilton cir-
cuit problem for directed connected graphs. The sec-
ond shows that the alignment problem wrt. source-
or target-side island-free and sure-possible sorted
alignments is NP-hard for (2,2)-BRCGs and goes
by 3SAT reduction. The third proof is more general
and goes by reduction of the vertex cover problem.
All three formal decision problems are discussed in
detail in Garey and Johnson (1979). All 15 results
in Figure 1 are derived from modifications of these
proofs.
4.2 NP-hardness of the 1 : 1 restriction for
(2,2)-BRCGs
Theorem 4.1. The alignment problem wrt. 1 : 1-
alignments is NP-hard for (2,2)-BRCGs.
Proof. An instance of the Hamilton circuit problem
for directed connected graphs is simply a directed
connected graph G = hV, Ei and the problem is
whether there is a path that visits each vertex exactly
once and returns to its starting point? Consider, for
instance, the directed connected graph:
It is easy to see that there is no path in this case
that visits each vertex exactly once and returns to its
starting point. The intuition behind our reconstruc-
tion of the Hamilton circuit problem for directed
connected graphs is to check this via alignments be-
tween a sequence of all the vertices in the graph and
itself. The grammar permits an alignment between
two words w|v if there is a directed edge between the
corresponding nodes in the graph, e.g. (w, v) ∈ E.
The alignment structures below depict the possible
alignments induced by the grammar obtained by the
translation described below for our example graph:
Since no alignment above is 1 : 1, there is no
solution to the corresponding circuit problem. The
translation goes as follows:
</bodyText>
<listItem confidence="0.999348142857143">
• Add a rule 5(X1,Y1) → {5„i(X1,Y1) |
∀vi.∃vj.(vi, vj) ∈ E}.
• For each edge (vi, vj) ∈ E add
a rule 5„i(X1viX2,Y1vjY2) →
⊤(X1)⊤(X2)⊤(X3)⊤(X4).5
• For all vi ∈ V add a rule ⊤(viX1) → ⊤(X1).
• Add a rule ⊤(ǫ) → ǫ.
</listItem>
<bodyText confidence="0.9998482">
The grammar ensures source-side island-freeness,
and therefore if there exists a 1 : 1-alignment of any
linearization of V and itself, by connectivity of the
input graph, there is a solution to the Hamilton cir-
cuit problem for directed connected graphs.
</bodyText>
<subsectionHeader confidence="0.855446">
4.3 NP-hardness of island-freeness and
sure-possible sortedness for (2,2)-BRCGs
</subsectionHeader>
<bodyText confidence="0.956410928571429">
Theorem 4.2. The alignment problem wrt. target-
side island-free and sure-possible sorted alignments
is NP-hard for (2,2)-BRCGs.
Proof. An instance of the 3SAT problem is a propo-
sitional logic formula 0 that is a conjunction of
clauses of three literals connected by disjunctions,
and the problem whether this formula is satisfiable,
i.e. has a model? Say 0 = p∨q∨r∧ ¯p∨ ¯q∨¯r. For our
reconstruction, we use the propositional variables
in 0 as source string, and 0 itself with ∧’s omitted
and conjuncts as words as the target string. One of
the representations of a solution constructed by the
translation described below is the following align-
ment structure:
</bodyText>
<equation confidence="0.9505575">
p q r
p ∨ q ∨ r p¯∨ q¯∨ r¯
</equation>
<bodyText confidence="0.99987275">
Solid lines are sure alignments; dotted lines are
possible alignments. The intuition is to use sure
alignments to encode true assignments, and possi-
ble alignments as false assignments. The alignment
</bodyText>
<footnote confidence="0.816406">
5⊤ is an arbitrary predicate name chosen to reflect the fact
that all possible substrings over the vocabulary are recognized
by the ⊤ predicates.
</footnote>
<figure confidence="0.941633666666667">
1 2 3 4 5 1 2 3 4 5
1 2 3 4 5
1 2 3 4 5
1 2 3 4 5 1 2 3 4 5
1 2 3 4 5
1 2 3 4 5
1 2
3
4 5
</figure>
<page confidence="0.998678">
65
</page>
<bodyText confidence="0.999756">
above thus corresponds to the model {p, ¯r}, which
clearly satisfies φ.
For the translation, assume that each 3SAT in-
stance, over a set of propositional variables PROP,
consists of a set of clauses c1 ... cm that are sets of
literals of size 3. For any literal lj, if lj = ¯pj then
pos(lj) = pj and lit(lj) = —; and if lj = pj then
pos(lj) = pj and lit(lj) = +. If lj is a literal in
ci, we write lj E ci. First add the following four
clauses:
</bodyText>
<equation confidence="0.9999545">
Ss(X1,Y1) — Ss(X1,Y1)  |Sp(X1,Y1)
Sp(X1,Y1) — Ss(X1,Y1)  |Sp(X1,Y1)
</equation>
<listItem confidence="0.93021525">
• If lj E ci and lit(lj) = —, add
Sp(X1pos(lj)X2, Y1ciY2) — T(X1)T(X2)
T(Y1)T(Y2) .
• If lj E ci and lit(lj) = +, add
</listItem>
<equation confidence="0.790551">
Ss(X1pos(lj)X2,Y1ciY2) — T(X1)T(X2)
T(Y1)T(Y2) .
</equation>
<listItem confidence="0.999911333333333">
• For all pj, add T(pjX1) T(X1).
• For all ci, add T(ciX1) T(X1).
• Add a rule T(ǫ) —* ǫ.
</listItem>
<bodyText confidence="0.998786487804878">
It is easy to see that the first rule adds at most
7m clauses, which for the largest non-redundant
formulas equals 7((2|PROP|)3). The second rule
adds at most 2|PROP |clauses; and the third at most
m &lt; (2|PROP|)3 clauses. It is also easy to see that
the grammar induces a target-side island-free, sure-
possible sorted alignment if and only if the 3SAT in-
stance is satisfiable. Note that the grammar does not
guarantee that all induced alignments are target-side
island-free. Nothing, in other words, corresponds
to conjunctions in our reconstruction. This is not
necessary as long as there is at least one target-side
island-free alignment that is induced.
Note that the proof also applies in the case where
it is the source side that is required to be island-free.
All needed is to make the source string the target
string, and vice versa. Note also that the proof can
be modified for the case where both sides are island-
free: Just add a dummy symbol to the clause side
and allow (or force) all propositional variables to
be aligned to this dummy symbol. Consequently, if
there is a target-side (clause-side) island-free align-
ment there is also an island-free alignment. Re-
versely, if there is an island-free alignment there is
also a target-side island-free alignment of the string
pair in question.
Note also that a more general proof can be ob-
tained by introducing a clause, similar to the clause
introduced in the first bullet point of the Hamil-
ton circuit reduction in the proof of Theorem 4.1:
S(X1,Y1) — {Sci(X1,Y1)  |1 &lt; i &lt; m}. The
four rules used to change between sure and pos-
sible alignments then of course need to be copied
out for all Sci predicates, and the LHS predicates,
except T, of the other clauses must be properly
subscripted. Now the grammar enforces target-
side island-freeness, and sure-possible sortedness is
the only restriction needed on alignments. Conse-
quently, this reduction proves (4) that the alignment
problem wrt. sure-possible sortedness is NP-hard for
(2,2)-BRCGs.
</bodyText>
<subsectionHeader confidence="0.7702845">
4.4 NP-hardness of island-freeness for
(2,2)-BRCGs
</subsectionHeader>
<bodyText confidence="0.887844875">
Theorem 4.3. The alignment problem wrt. island-
free alignments is NP-hard for (2,2)-BRCGs.
Proof. An instance of the vertex problem is a graph
D = (V, E) and an integer k, and the prob-
lem whether there exists a vertex cover of D of
size k? Say D = (V = {a, b, c, d}, E =
{(a, c), (b, c), (b, d), (c, d)}) and k = 2. The trans-
lation described below constructs a sentence pair
</bodyText>
<equation confidence="0.48392">
(ρ1ρ2ρ3ρ4uuδδδδ,aaaabbbbccccdddd)
</equation>
<bodyText confidence="0.996781666666667">
for this instance, and a (2,2)-BRCG with the
clauses in Figure 2. Note that there are four kinds
of clauses:
</bodyText>
<listItem confidence="0.9613554">
• A clause with an S predicate in the LHS. In
general, there will be one such clause in the
grammar constructed for any instance of the
vertex cover problem.
• 8 clauses with ρi predicates in the LHS. In gen-
</listItem>
<bodyText confidence="0.5948062">
eral, there will be 2|E |many clauses of this
form in the grammars.
• 8 clauses with Ui predicates in the LHS. In gen-
eral, there will be |V |x(|V |—k) many clauses
of this form in the grammars.
</bodyText>
<page confidence="0.887994">
66
</page>
<listItem confidence="0.65306975">
• 16 clauses with δ1 predicates in the LHS. In
general, there will be (|E |× |V  |− |E |− |E |×
(|V  |− k)) × |V  |many clauses of this form in
the grammars.
</listItem>
<bodyText confidence="0.999255">
For an instance hD = hV, Ei, ki, the translation
function in general constructs the following clauses:
</bodyText>
<equation confidence="0.998111333333333">
S(X1,Y1) → {ρi(X1,Y1)  |1 ≤ i ≤ |E|}∪
{U|V |−k(X1,Y1)}∪
{δ|E|x|V |−|E|−|E|x(|V |−k)(X1, Y1)}
</equation>
<bodyText confidence="0.576884">
and for all 1 ≤ i ≤ |E |iff ei ∈ E = (e, e′):
</bodyText>
<equation confidence="0.9962706">
ρi(X1ρiX2,Y1eY2) → ⊤(X1)⊤(X2)⊤(Y1)⊤(Y2)
ρi(X1ρiX2,Y1e′Y2) → ⊤(X1)⊤(X2)⊤(Y1)⊤(Y2)
For all 2 ≤ i ≤ |V  |− k and for all v ∈ V :
Ui(X1UX2,Y1v ... vY2) → Ui−1(X1,Y1)
⊤(X2)⊤(Y2)
</equation>
<bodyText confidence="0.999569">
where |v ... v |= |E|. For the case U1, add the
clauses for all v ∈ V :
</bodyText>
<equation confidence="0.978670285714286">
U1(X1UX2,Y1v ... vY2) → ⊤(X1)⊤(Y1)
⊤(X2)⊤(Y2)
The string pair is constructed this way:
hρ1 ... ρjEjU1 ... UjV j−k
δ1 ... δjEj~jV j−jEj−jEj~(jV j−k), σi
Finally, for all words w in this string pair, add:
⊤(wX1) → ⊤(X1)
</equation>
<bodyText confidence="0.999863733333333">
Since this translation is obviously polynomial, it
follows that the alignment problem wrt. island-free
alignments for (2,2)-BRCGs is NP-hard.
Note that the proof also applies if only the source,
resp. target, side is required to be island-free, since
the grammar restricts the alignments in a way such
that if one side is island-free then so is the other side.
This gives us results (2) and (3).
It is not difficult to see either that it is possible
to convert the grammar into a grammar that induces
1 : 1-alignments. This gives us results (5), (8) and
(11). Of course by the observation that all the gram-
mars only use sure alignments, it follows that the
alignment problems in (7), (9–10) and (12–15) are
also NP-hard.
</bodyText>
<sectionHeader confidence="0.998489" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999991275862069">
The universal recognition problems of both ITGs
and (2,2)-BRCGs can be solved in time O(n6|G|).
This may come as a surprise, as ITGs restrict the
alignment space considerably, while (2,2)-BRCGs
induce all possible alignments. In the context of
the NP-hardness of decoding in statistical machine
translation (Knight, 1999; Udupa and Maji, 2006),
it is natural to ask why the universal recognition
problem of (2,2)-BRCGs isn’t NP-hard? This pa-
per bridges the gap between these results and shows
that when alignments are restricted to be 1 : 1,
island-free or sure-possible sorted, or all combi-
nations thereof, the alignment problem of (2,2)-
BRCGs is NP-hard. Consequently, while the un-
restricted alignment problem for (2,2)-BRCGs can
be solved in O(n6|G|), the alignment problem turns
NP-hard as soon as restrictions are put on the align-
ments sought. So the extra expressivity in a way
comes at the expense of control over the kind of
alignments obtained. Note also that an alignment
of two words may be enforced multiple times in a
(2,2)-BRCGs parse, since two derivation trees that
share leaves on both sides can align the same two
words.
Our results are not intended to be qualifications of
the usefulness of (2,2)-BRCGs (Søgaard, 2008), but
rather they are attempts to bridge a gap in our under-
standing of the synchronous grammar formalisms at
hand to us in syntax-based machine translation.
</bodyText>
<page confidence="0.966575">
67
</page>
<equation confidence="0.994245923076923">
S(X1,Y1) — P1(X1,Y1)P2(X1,Y1)
P3(X1,Y1)P4(X1,Y1)
U2(X1,Y1)s4(X1,Y1)
P1(X1P1X2,Y1aY2) — T(X1)T(X2)T(Y1)T(Y2)
P1(X1P1X2,Y1cY2) — T(X1)T(X2)T(Y1)T(Y2)
. . .
U2(X1UX2,aaaaY1) — U1(X1,Y1)T(X2)
U1(X1UX2,Y1bbbbY2) — T(X1)T(Y1)T(X2)T(Y2)
U2(X1UX2,Y1bbbbY2) — U1(X1,Y1)T(X2)T(Y2)
. . .
s4(X1sX2,Y1aY2) — s3(X1,Y1)T(X2)T(Y2)
s4(X1sX2,Y1bY2) — s3(X1,Y1)T(X2)T(Y2)
. . .
</equation>
<figureCaption confidence="0.994837">
Figure 2: A (2,2)-BRCG for the instance of the vertex cover problem (({a, b, c, d1, {(a, c), (b, c), (b, d), (c, d)1), 2).
</figureCaption>
<sectionHeader confidence="0.996999" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.998876833333334">
Alfred Aho and Jeffrey Ullman. 1972. The theory
ofparsing, translation and compiling. Prentice-Hall,
London, England.
Edward Barton, Robert Berwick, and Erik Ristad. 1987.
Computational complexity and natural language. MIT
Press, Cambridge, Massachusetts.
Pierre Boullier. 1998. Proposal for a natural language
processing syntactic backbone. Technical report, IN-
RIA, Le Chesnay, France.
Michael Garey and David Johnson. 1979. Computers
and intractability. W. H. Freeman &amp; Co., New York,
New York.
Kevin Knight. 1999. Decoding complexity in word-
replacement translation models. Computational Lin-
guistics, 25(4):607–615.
Dan Melamed. 1999. Bitext maps and alignment
via pattern recognition. Computational Linguistics,
25(1):107–130.
Anders Søgaard. 2008. Range concatenation gram-
mars for translation. In Proceedings of the 22nd
International Conference on Computational Linguis-
tics, Companion Volume, pages 103–106, Manchester,
England.
Raghavendra Udupa and Hemanta Maji. 2006. Compu-
tational complexity of statistical machine translation.
In Proceedings of the 11th Conference of the European
Chapter ofthe Association for Computational Linguis-
tics, pages 25–32, Trento, Italy.
Dekai Wu. 1997. Stochastic inversion transduction
grammars and bilingual parsing of parallel corpora.
Computational Linguistics, 23(3):377–403.
Hao Zhang and Daniel Gildea. 2004. Syntax-based
alignment: supervised or unsupervised? In Proceed-
ings of the 20th International Conference on Compu-
tational Linguistics, pages 418–424, Geneva, Switzer-
land.
</reference>
<page confidence="0.999439">
68
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.373077">
<title confidence="0.990677">On the complexity of alignment problems in two synchronous grammar</title>
<email confidence="0.436156">formalisms</email>
<affiliation confidence="0.964481">Center for Language University of</affiliation>
<email confidence="0.939687">soegaard@hum.ku.dk</email>
<abstract confidence="0.996454857142857">The alignment problem for synchronous grammars in its unrestricted form, i.e. whether for a grammar and a string pair the grammar induces an alignment of the two strings, reduces to the universal recognition problem, but restrictions may be imposed on the alignsought, e.g. alignments may be : island-free or sure-possible sorted. The complexities of 15 restricted alignment problems in two very different synchronous grammar formalisms of syntax-based machine translation, inversion transduction grammars (ITGs) (Wu, 1997) and a restricted form of range concatenation grammars ((2,2)-BRCGs) (Søgaard, 2008), are investigated. The universal recognition problems, and therefore also the unrestricted alignment problems, of both forcan be solved in time The complexities of the restricted alignment problems differ significantly, however.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Alfred Aho</author>
<author>Jeffrey Ullman</author>
</authors>
<title>The theory ofparsing, translation and compiling.</title>
<date>1972</date>
<publisher>Prentice-Hall,</publisher>
<location>London, England.</location>
<contexts>
<context position="10613" citStr="Aho and Ullman, 1972" startWordPosition="1773" endWordPosition="1776">essivity of (2,2)-BRCGs in a way comes at the expense of control over the kind of alignments obtained. On the structure of the paper: Sect. 2 and 3 briefly introduce, resp., ITGs and (2,2)-BRCGs. Sect. 4 presents three NP-hardness proofs from which the 15 results in Figure 1 can be derived. The three proofs are based on reconstructions of the Hamilton circuit problem, the 3SAT problem and the vertex cover problem (Garey and Johnson, 1979). 2 Inversion transduction grammars Inversion transduction grammars (ITGs) (Wu, 1997) are a notational variant of binary syntax-directed translation schemas (Aho and Ullman, 1972) and are usually presented with a normal form: A [BC] A (BC) A e |f A e |E A E |f where A, B, C E N and e, f E T. The first production rule, intuitively, says that the subtree [[]B[]C]A in the source language translates into 62 a subtree [[]B[]C]A, whereas the second production rule inverts the order in the target language, i.e. [[]C[]B]A. The universal recognition problem of ITGs can be solved in time O(n6|G|) by a CYKstyle parsing algorithm with two charts. Figure 1 tells us that all the restricted alignment problems listed can be solved in time O(n6|G|). The explanation is simple. It can be</context>
</contexts>
<marker>Aho, Ullman, 1972</marker>
<rawString>Alfred Aho and Jeffrey Ullman. 1972. The theory ofparsing, translation and compiling. Prentice-Hall, London, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Edward Barton</author>
<author>Robert Berwick</author>
<author>Erik Ristad</author>
</authors>
<title>Computational complexity and natural language.</title>
<date>1987</date>
<publisher>MIT Press,</publisher>
<location>Cambridge, Massachusetts.</location>
<contexts>
<context position="4455" citStr="Barton et al., 1987" startWordPosition="667" endWordPosition="671">at only words that are recognized simultanously, are aligned. Otherwise alignment structures are just a binary symmetric relation on two strings, a source and a target string, such that two words in the source, resp. target string, cannot be aligned. Maximally connected subgraphs (ignoring precedence edges) are called translation units. The alignment problem can be formulated this way (with s, s′ source and target sentence, resp.): INSTANCE: G, hs, s′i. QUESTION: Does G induce an alignment on hs, s′i? The alignment problem in its unrestricted form reduces to the universal recognition problem (Barton et al., 1987), i.e. whether for a grammar G and a string pair hs, s′i it holds that hs, s′i ∈ L(G)? Of course the alignment may in this case be empty or partial. Both ITGs and (2,2)-BRCGs permit unaligned nodes. This paper investigates the complexity of restricted versions of the alignment problem for ITGs and (2,2)-BRCGs. A simple example, which can be solved in linear time for both formalisms, is the alignment problem wrt. alignments that consist of a single translation unit including all source and target words. It may be formulated this way: INSTANCE: G, hs, s′i. QUESTION: Does G induce an alignment th</context>
</contexts>
<marker>Barton, Berwick, Ristad, 1987</marker>
<rawString>Edward Barton, Robert Berwick, and Erik Ristad. 1987. Computational complexity and natural language. MIT Press, Cambridge, Massachusetts.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Pierre Boullier</author>
</authors>
<title>Proposal for a natural language processing syntactic backbone.</title>
<date>1998</date>
<tech>Technical report, INRIA,</tech>
<institution>Le Chesnay,</institution>
<contexts>
<context position="12138" citStr="Boullier, 1998" startWordPosition="2046" endWordPosition="2047">ASBi |hABi (2) A → a |a (3) A → a |E (4) B → b |b Note that this grammar recognizes the translation {hanbn, bnam |n ≥ m}. To check if for a string pair hw1 ... wn, v1 ... vmi this grammar induces an island-free alignment, simply remove production rule (3). It holds that only strings in the sublanguage {hanbn, bnan |n ≥ 1} induce island-free alignments. Similarly, to check if the grammar induces source-side island-free alignments for string pairs, no production rules will have to be removed. 3 Two-variable binary bottom-up non-erasing range concatenation grammars (2,2)-BRCGs are positive RCGs (Boullier, 1998) with binary start predicate names, i.e. p(S) = 2. In RCG, predicates can be negated (for complementation), and the start predicate name is typically unary. The definition is changed only for aesthetic reasons; a positive RCG with a binary start predicate name S is turned into a positive RCG with a unary start predicate name S′ simply by adding a clause S′(X1X2) → S(X1,X2). A positive RCG is a 5-tuple G = hN, T, V, P, Si. N is a finite set of predicate names with an arity function p: N → N, T and V are finite sets of, resp., terminal and variables. P is a finite set of clauses of the form 00 →</context>
</contexts>
<marker>Boullier, 1998</marker>
<rawString>Pierre Boullier. 1998. Proposal for a natural language processing syntactic backbone. Technical report, INRIA, Le Chesnay, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Garey</author>
<author>David Johnson</author>
</authors>
<date>1979</date>
<journal>Computers</journal>
<location>New York, New York.</location>
<contexts>
<context position="10434" citStr="Garey and Johnson, 1979" startWordPosition="1750" endWordPosition="1753">stricted alignment problem for (2,2)- BRCGs can be solved in O(n6|G|), the alignment problem turns NP-hard as soon as restrictions are put on the alignments sought. So the extra expressivity of (2,2)-BRCGs in a way comes at the expense of control over the kind of alignments obtained. On the structure of the paper: Sect. 2 and 3 briefly introduce, resp., ITGs and (2,2)-BRCGs. Sect. 4 presents three NP-hardness proofs from which the 15 results in Figure 1 can be derived. The three proofs are based on reconstructions of the Hamilton circuit problem, the 3SAT problem and the vertex cover problem (Garey and Johnson, 1979). 2 Inversion transduction grammars Inversion transduction grammars (ITGs) (Wu, 1997) are a notational variant of binary syntax-directed translation schemas (Aho and Ullman, 1972) and are usually presented with a normal form: A [BC] A (BC) A e |f A e |E A E |f where A, B, C E N and e, f E T. The first production rule, intuitively, says that the subtree [[]B[]C]A in the source language translates into 62 a subtree [[]B[]C]A, whereas the second production rule inverts the order in the target language, i.e. [[]C[]B]A. The universal recognition problem of ITGs can be solved in time O(n6|G|) by a C</context>
<context position="19024" citStr="Garey and Johnson (1979)" startWordPosition="3344" endWordPosition="3347">ase, there is a nonterminal for each span in the target, resp. source, chart, i.e. 2n − 1 many. SURE1 val1 ... ⎤ ⎦⎥⎥ SUREn valn ⎡ ⎢ ⎢ ⎣ 64 problem wrt. 1 : 1-alignments is NP-hard for (2,2)- BRCGs and goes by reduction of the Hamilton circuit problem for directed connected graphs. The second shows that the alignment problem wrt. sourceor target-side island-free and sure-possible sorted alignments is NP-hard for (2,2)-BRCGs and goes by 3SAT reduction. The third proof is more general and goes by reduction of the vertex cover problem. All three formal decision problems are discussed in detail in Garey and Johnson (1979). All 15 results in Figure 1 are derived from modifications of these proofs. 4.2 NP-hardness of the 1 : 1 restriction for (2,2)-BRCGs Theorem 4.1. The alignment problem wrt. 1 : 1- alignments is NP-hard for (2,2)-BRCGs. Proof. An instance of the Hamilton circuit problem for directed connected graphs is simply a directed connected graph G = hV, Ei and the problem is whether there is a path that visits each vertex exactly once and returns to its starting point? Consider, for instance, the directed connected graph: It is easy to see that there is no path in this case that visits each vertex exact</context>
</contexts>
<marker>Garey, Johnson, 1979</marker>
<rawString>Michael Garey and David Johnson. 1979. Computers and intractability. W. H. Freeman &amp; Co., New York, New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kevin Knight</author>
</authors>
<title>Decoding complexity in wordreplacement translation models.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>4</issue>
<contexts>
<context position="2756" citStr="Knight, 1999" startWordPosition="405" endWordPosition="406">alignments discussed in Wu (1997). Another class that ITGs do not induce is that of alignments with discontinuous translation units (Sø- gaard, 2008). Søgaard (2008), on the other hand, shows that the alignments induced by (2,2)-BRCGs are closed under union, i.e. (2,2)-BRCGs induce all possible alignments. The universal recognition problems of both ITGs and (2,2)-BRCGs can be solved in time O(n6|G|). This may come as a surprise, as ITGs restrict the alignment search space considerably, while (2,2)- BRCGs do not. In the context of the NP-hardness of decoding in statistical machine translation (Knight, 1999; Udupa and Maji, 2006), it is natural to ask why the universal recognition problem of (2,2)- BRCGs isn’t NP-hard? How can (2,2)-BRCGs induce all possible alignments and still avoid NPhardness? This paper bridges the gap between these results and shows that when alignments are restricted to be 1 : 1, island-free or sure-possible sorted (see below), or all combinations thereof, the alignment problem of (2,2)-BRCGs is NP-hard. (2,2)-BRCGs in a sense avoid NP-hardness by giving up control over global properties of alignments, e.g. any pair of words may be aligned multiple times in a derivation. 6</context>
<context position="27614" citStr="Knight, 1999" startWordPosition="4892" endWordPosition="4893">ossible to convert the grammar into a grammar that induces 1 : 1-alignments. This gives us results (5), (8) and (11). Of course by the observation that all the grammars only use sure alignments, it follows that the alignment problems in (7), (9–10) and (12–15) are also NP-hard. 5 Conclusion The universal recognition problems of both ITGs and (2,2)-BRCGs can be solved in time O(n6|G|). This may come as a surprise, as ITGs restrict the alignment space considerably, while (2,2)-BRCGs induce all possible alignments. In the context of the NP-hardness of decoding in statistical machine translation (Knight, 1999; Udupa and Maji, 2006), it is natural to ask why the universal recognition problem of (2,2)-BRCGs isn’t NP-hard? This paper bridges the gap between these results and shows that when alignments are restricted to be 1 : 1, island-free or sure-possible sorted, or all combinations thereof, the alignment problem of (2,2)- BRCGs is NP-hard. Consequently, while the unrestricted alignment problem for (2,2)-BRCGs can be solved in O(n6|G|), the alignment problem turns NP-hard as soon as restrictions are put on the alignments sought. So the extra expressivity in a way comes at the expense of control ove</context>
</contexts>
<marker>Knight, 1999</marker>
<rawString>Kevin Knight. 1999. Decoding complexity in wordreplacement translation models. Computational Linguistics, 25(4):607–615.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Melamed</author>
</authors>
<title>Bitext maps and alignment via pattern recognition.</title>
<date>1999</date>
<journal>Computational Linguistics,</journal>
<volume>25</volume>
<issue>1</issue>
<contexts>
<context position="8520" citStr="Melamed (1999)" startWordPosition="1429" endWordPosition="1430">g and contain no terminal symbols. 61 Result 1 : 1 IF(s) IF(t) SP ITGs (2,2)-BRCGs X O(n6|G|) NP-complete X O(n6|G|) NP-complete X O(n6|G|) NP-complete X O(n6|G|) NP-complete X X O(n6|G|) NP-complete X X O(n6|G|) NP-complete X X O(n6|G|) NP-complete X X O(n6|G|) NP-complete X X O(n6|G|) NP-complete X X O(n6|G|) NP-complete X X X O(n6|G|) NP-complete X X X O(n6|G|) NP-complete X X X O(n6|G|) NP-complete X X X O(n6|G|) NP-complete X X X X O(n6|G|) NP-complete Figure 1: The complexity of restricted alignment problems for ITGs and (2,2)-BRCGs. • 1 : 1-alignments have been argued to be adequate by Melamed (1999) and elsewhere, and it may therefore be useful to know if a grammar extracted from a parallel corpus produces 1 : 1- alignments for a finite set of sentence pairs. • Island-free alignments are interesting to the extent that unaligned nodes increase the chance of translation errors. An island threshold may for instance be used to rule out risky translations. • The notion of sure-possible sorted alignments is more unusual, but can, for instance, be used to check if the use of possible alignments is consistently triggered by words that are hard to align. The results for all cross-classifications </context>
</contexts>
<marker>Melamed, 1999</marker>
<rawString>Dan Melamed. 1999. Bitext maps and alignment via pattern recognition. Computational Linguistics, 25(1):107–130.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Søgaard</author>
</authors>
<title>Range concatenation grammars for translation.</title>
<date>2008</date>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics, Companion Volume,</booktitle>
<pages>103--106</pages>
<location>Manchester, England.</location>
<contexts>
<context position="2082" citStr="Søgaard, 2008" startWordPosition="299" endWordPosition="300">ng from parallel corpora; and while he was a Postdoctoral Researcher at the ISV Computational Linguistics Group, Copenhagen Business School, supported by the Danish Research Foundation in the project Efficient syntax- and semantics-based machine translation. 2004). On a par with weak and strong generative capacity, it is thus possible to talk about the alignment capacity of those formalisms. In this paper, two synchronous grammar formalisms are discussed, inversion transduction grammars (ITGs) (Wu, 1997) and two-variable binary bottom-up non-erasing range concatenation grammars ((2,2)-BRCGs) (Søgaard, 2008). It is known that ITGs do not induce the class of inside-out alignments discussed in Wu (1997). Another class that ITGs do not induce is that of alignments with discontinuous translation units (Sø- gaard, 2008). Søgaard (2008), on the other hand, shows that the alignments induced by (2,2)-BRCGs are closed under union, i.e. (2,2)-BRCGs induce all possible alignments. The universal recognition problems of both ITGs and (2,2)-BRCGs can be solved in time O(n6|G|). This may come as a surprise, as ITGs restrict the alignment search space considerably, while (2,2)- BRCGs do not. In the context of th</context>
<context position="15539" citStr="Søgaard (2008)" startWordPosition="2750" endWordPosition="2751">can be derived from S(h0, ni, hn + 1, n + 1 + mi). It is not difficult to see that ITGs are also (2,2)- BRCGs. The left column is ITG production rules; 63 Note that L(G) = {hanbmcndm, (ab)n(cd)mi | m, n ≥ 0}. the right column their translations in simple (2,2)- BRCGs. A(X1X2,Y1Y2) → B(X1,Y1)C(X2,Y2) A(X1X2,Y1Y2) → B(X1,Y2)C(X2,Y1) A(e, f) → e A(e, e) → e 4 Results 4.1 Checking island-freeness and sure-possible sortedness A → [BCI A → hBCi A → e |f A → e |e A → e |f A(e, f) → e Consequently, (2,2)-BRCGs recognize all translations recognized by ITGs. In fact the inclusion is strict, as shown in Søgaard (2008). The universal recognition problem of (2,2)-BRCGs can be solved in time O(n6|G|) by the CYK-style parsing algorithm presented in Søgaard (2008). Example 3.1. Consider the (2,2)-BRCG G = h{Ss, S0, S′0, S1, S′1, A, B, C, D}, {a, b, c, d}, {X1, X2, Y1, Y2}, P, Ssi with P the following set of clauses: S3(X1,Y1) → S0(X1, Y1)S′0(X1, Y1) S0(X1X2,Y1) → S1(X1,Y1)D(X2) S1(aX1c,abY1) → S1(X1,Y1) S1(X1,Y1Y2) → B(X1)C(Y1)D(Y2) S′0(X1X2,Y1) → S′1(X2,Y1)A(X1) S′1(bX1d,Y1cd) → S′1(X1,Y1) S′1(X1,Y1Y2) → C(X1)A(Y1)B(Y2) A(aX1) → A(X1) A(e) → e B(bX1) → B(X1) B(e) → e C(cX1) → C(X1) C(e) → e D(dX1) → D(X1) D(e)</context>
<context position="18245" citStr="Søgaard, 2008" startWordPosition="3208" endWordPosition="3209">to record what words have been aligned to check island-freeness. Unfortunately, this technique does not guarantee polynomial runtime. Note that there can be 2n many distinct feature structures for each nonterminal symbol in a chart. Consequently, whereas the size of a cell in the standard CYK algorithm is bounded by |N|, and in synchronous parsing by |N |× (2n −1),4 the cells are now of exponential size in the worst case. The following three sections provide three NPhardness proofs: The first shows that the alignment 4The indices used to check that two nonterminals are derived simultaneously (Søgaard, 2008) mean that it may be necessary within a cell in the source, resp. target, chart to keep track of multiple tuples with the same nonterminals. In the worst case, there is a nonterminal for each span in the target, resp. source, chart, i.e. 2n − 1 many. SURE1 val1 ... ⎤ ⎦⎥⎥ SUREn valn ⎡ ⎢ ⎢ ⎣ 64 problem wrt. 1 : 1-alignments is NP-hard for (2,2)- BRCGs and goes by reduction of the Hamilton circuit problem for directed connected graphs. The second shows that the alignment problem wrt. sourceor target-side island-free and sure-possible sorted alignments is NP-hard for (2,2)-BRCGs and goes by 3SAT r</context>
<context position="28532" citStr="Søgaard, 2008" startWordPosition="5045" endWordPosition="5046">oblem of (2,2)- BRCGs is NP-hard. Consequently, while the unrestricted alignment problem for (2,2)-BRCGs can be solved in O(n6|G|), the alignment problem turns NP-hard as soon as restrictions are put on the alignments sought. So the extra expressivity in a way comes at the expense of control over the kind of alignments obtained. Note also that an alignment of two words may be enforced multiple times in a (2,2)-BRCGs parse, since two derivation trees that share leaves on both sides can align the same two words. Our results are not intended to be qualifications of the usefulness of (2,2)-BRCGs (Søgaard, 2008), but rather they are attempts to bridge a gap in our understanding of the synchronous grammar formalisms at hand to us in syntax-based machine translation. 67 S(X1,Y1) — P1(X1,Y1)P2(X1,Y1) P3(X1,Y1)P4(X1,Y1) U2(X1,Y1)s4(X1,Y1) P1(X1P1X2,Y1aY2) — T(X1)T(X2)T(Y1)T(Y2) P1(X1P1X2,Y1cY2) — T(X1)T(X2)T(Y1)T(Y2) . . . U2(X1UX2,aaaaY1) — U1(X1,Y1)T(X2) U1(X1UX2,Y1bbbbY2) — T(X1)T(Y1)T(X2)T(Y2) U2(X1UX2,Y1bbbbY2) — U1(X1,Y1)T(X2)T(Y2) . . . s4(X1sX2,Y1aY2) — s3(X1,Y1)T(X2)T(Y2) s4(X1sX2,Y1bY2) — s3(X1,Y1)T(X2)T(Y2) . . . Figure 2: A (2,2)-BRCG for the instance of the vertex cover problem (({a, b, c, d</context>
</contexts>
<marker>Søgaard, 2008</marker>
<rawString>Anders Søgaard. 2008. Range concatenation grammars for translation. In Proceedings of the 22nd International Conference on Computational Linguistics, Companion Volume, pages 103–106, Manchester, England.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Raghavendra Udupa</author>
<author>Hemanta Maji</author>
</authors>
<title>Computational complexity of statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 11th Conference of the European Chapter ofthe Association for Computational Linguistics,</booktitle>
<pages>25--32</pages>
<location>Trento, Italy.</location>
<contexts>
<context position="2779" citStr="Udupa and Maji, 2006" startWordPosition="407" endWordPosition="410">cussed in Wu (1997). Another class that ITGs do not induce is that of alignments with discontinuous translation units (Sø- gaard, 2008). Søgaard (2008), on the other hand, shows that the alignments induced by (2,2)-BRCGs are closed under union, i.e. (2,2)-BRCGs induce all possible alignments. The universal recognition problems of both ITGs and (2,2)-BRCGs can be solved in time O(n6|G|). This may come as a surprise, as ITGs restrict the alignment search space considerably, while (2,2)- BRCGs do not. In the context of the NP-hardness of decoding in statistical machine translation (Knight, 1999; Udupa and Maji, 2006), it is natural to ask why the universal recognition problem of (2,2)- BRCGs isn’t NP-hard? How can (2,2)-BRCGs induce all possible alignments and still avoid NPhardness? This paper bridges the gap between these results and shows that when alignments are restricted to be 1 : 1, island-free or sure-possible sorted (see below), or all combinations thereof, the alignment problem of (2,2)-BRCGs is NP-hard. (2,2)-BRCGs in a sense avoid NP-hardness by giving up control over global properties of alignments, e.g. any pair of words may be aligned multiple times in a derivation. 60 Proceedings of SSST-3</context>
<context position="27637" citStr="Udupa and Maji, 2006" startWordPosition="4894" endWordPosition="4897">vert the grammar into a grammar that induces 1 : 1-alignments. This gives us results (5), (8) and (11). Of course by the observation that all the grammars only use sure alignments, it follows that the alignment problems in (7), (9–10) and (12–15) are also NP-hard. 5 Conclusion The universal recognition problems of both ITGs and (2,2)-BRCGs can be solved in time O(n6|G|). This may come as a surprise, as ITGs restrict the alignment space considerably, while (2,2)-BRCGs induce all possible alignments. In the context of the NP-hardness of decoding in statistical machine translation (Knight, 1999; Udupa and Maji, 2006), it is natural to ask why the universal recognition problem of (2,2)-BRCGs isn’t NP-hard? This paper bridges the gap between these results and shows that when alignments are restricted to be 1 : 1, island-free or sure-possible sorted, or all combinations thereof, the alignment problem of (2,2)- BRCGs is NP-hard. Consequently, while the unrestricted alignment problem for (2,2)-BRCGs can be solved in O(n6|G|), the alignment problem turns NP-hard as soon as restrictions are put on the alignments sought. So the extra expressivity in a way comes at the expense of control over the kind of alignment</context>
</contexts>
<marker>Udupa, Maji, 2006</marker>
<rawString>Raghavendra Udupa and Hemanta Maji. 2006. Computational complexity of statistical machine translation. In Proceedings of the 11th Conference of the European Chapter ofthe Association for Computational Linguistics, pages 25–32, Trento, Italy.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekai Wu</author>
</authors>
<title>Stochastic inversion transduction grammars and bilingual parsing of parallel corpora.</title>
<date>1997</date>
<journal>Computational Linguistics,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="711" citStr="Wu, 1997" startWordPosition="102" endWordPosition="103">or Language Technology University of Copenhagen soegaard@hum.ku.dk Abstract The alignment problem for synchronous grammars in its unrestricted form, i.e. whether for a grammar and a string pair the grammar induces an alignment of the two strings, reduces to the universal recognition problem, but restrictions may be imposed on the alignment sought, e.g. alignments may be 1 : 1, island-free or sure-possible sorted. The complexities of 15 restricted alignment problems in two very different synchronous grammar formalisms of syntax-based machine translation, inversion transduction grammars (ITGs) (Wu, 1997) and a restricted form of range concatenation grammars ((2,2)-BRCGs) (Sø- gaard, 2008), are investigated. The universal recognition problems, and therefore also the unrestricted alignment problems, of both formalisms can be solved in time O(n6|G|). The complexities of the restricted alignment problems differ significantly, however. 1 Introduction The synchronous grammar formalisms used in syntax-based machine translation typically induce alignments by aligning all words that are recognized simultaneously (Wu, 1997; Zhang and Gildea, ∗This work was done while the first author was a Senior Resea</context>
<context position="1977" citStr="Wu, 1997" startWordPosition="288" endWordPosition="289">supported by the German Research Foundation in the Emmy Noether project Ptolemaios on grammar learning from parallel corpora; and while he was a Postdoctoral Researcher at the ISV Computational Linguistics Group, Copenhagen Business School, supported by the Danish Research Foundation in the project Efficient syntax- and semantics-based machine translation. 2004). On a par with weak and strong generative capacity, it is thus possible to talk about the alignment capacity of those formalisms. In this paper, two synchronous grammar formalisms are discussed, inversion transduction grammars (ITGs) (Wu, 1997) and two-variable binary bottom-up non-erasing range concatenation grammars ((2,2)-BRCGs) (Søgaard, 2008). It is known that ITGs do not induce the class of inside-out alignments discussed in Wu (1997). Another class that ITGs do not induce is that of alignments with discontinuous translation units (Sø- gaard, 2008). Søgaard (2008), on the other hand, shows that the alignments induced by (2,2)-BRCGs are closed under union, i.e. (2,2)-BRCGs induce all possible alignments. The universal recognition problems of both ITGs and (2,2)-BRCGs can be solved in time O(n6|G|). This may come as a surprise, </context>
<context position="10519" citStr="Wu, 1997" startWordPosition="1762" endWordPosition="1763">P-hard as soon as restrictions are put on the alignments sought. So the extra expressivity of (2,2)-BRCGs in a way comes at the expense of control over the kind of alignments obtained. On the structure of the paper: Sect. 2 and 3 briefly introduce, resp., ITGs and (2,2)-BRCGs. Sect. 4 presents three NP-hardness proofs from which the 15 results in Figure 1 can be derived. The three proofs are based on reconstructions of the Hamilton circuit problem, the 3SAT problem and the vertex cover problem (Garey and Johnson, 1979). 2 Inversion transduction grammars Inversion transduction grammars (ITGs) (Wu, 1997) are a notational variant of binary syntax-directed translation schemas (Aho and Ullman, 1972) and are usually presented with a normal form: A [BC] A (BC) A e |f A e |E A E |f where A, B, C E N and e, f E T. The first production rule, intuitively, says that the subtree [[]B[]C]A in the source language translates into 62 a subtree [[]B[]C]A, whereas the second production rule inverts the order in the target language, i.e. [[]C[]B]A. The universal recognition problem of ITGs can be solved in time O(n6|G|) by a CYKstyle parsing algorithm with two charts. Figure 1 tells us that all the restricted </context>
</contexts>
<marker>Wu, 1997</marker>
<rawString>Dekai Wu. 1997. Stochastic inversion transduction grammars and bilingual parsing of parallel corpora. Computational Linguistics, 23(3):377–403.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Hao Zhang</author>
<author>Daniel Gildea</author>
</authors>
<title>Syntax-based alignment: supervised or unsupervised?</title>
<date>2004</date>
<booktitle>In Proceedings of the 20th International Conference on Computational Linguistics,</booktitle>
<pages>418--424</pages>
<location>Geneva, Switzerland.</location>
<marker>Zhang, Gildea, 2004</marker>
<rawString>Hao Zhang and Daniel Gildea. 2004. Syntax-based alignment: supervised or unsupervised? In Proceedings of the 20th International Conference on Computational Linguistics, pages 418–424, Geneva, Switzerland.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>