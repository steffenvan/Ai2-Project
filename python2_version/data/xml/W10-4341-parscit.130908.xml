<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.019983">
<title confidence="0.9985105">
Pamini: A framework for assembling mixed-initiative human-robot
interaction from generic interaction patterns
</title>
<author confidence="0.915837">
Julia Peltason and Britta Wrede
</author>
<affiliation confidence="0.758863">
Applied Informatics, Faculty of Technology
Bielefeld University, Germany
</affiliation>
<email confidence="0.99085">
jpeltaso, bwrede@techfak.uni-bielefeld.de
</email>
<sectionHeader confidence="0.993527" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999852538461539">
Dialog modeling in robotics suffers from
lack of generalizability, due to the fact
that the dialog is heavily influenced by
the tasks the robot is able to perform.
We introduce interleaving interaction pat-
terns together with a general protocol for
task communication which enables us to
systematically specify the relationship be-
tween dialog structure and task structure.
We argue that this approach meets the re-
quirements of advanced dialog modeling
on robots and at the same time exhibits a
better scalability than existing concepts.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999957166666667">
The need for interaction modeling on robots is
widely acknowledged, not only for instructing
them but also for enabling them to learn from hu-
mans within interaction. Yet, today’s robotic sys-
tems often do not have a dedicated dialog system
but employ simple command-matching techniques
(e.g. (B¨ohme et al., 2003)). Other systems rely
on finite-state based dialog managers (e.g. (Bauer
et al., 2009)) that couple dialog and task man-
agement which hampers maintainability and reuse
and does not scale well for more complex interac-
tion scenarios.
On the other hand, concepts for reusable dialog
frameworks have been established within the spo-
ken dialog community for traditional information-
seeking domains where the system first collects
the required parameters, then presents the desired
information to the user, e.g. an accommodation
or travel information (e.g. (Bohus and Rudnicky,
2009)). However, these concepts are not directly
transferable to robotics, due to the situated nature
of human-robot interaction. A robot perceives the
world and acts on it – and it is supposed to com-
municate about that. For instance, a robot manip-
</bodyText>
<figureCaption confidence="0.999759">
Figure 1: The Curious Robot set-up.
</figureCaption>
<bodyText confidence="0.9999591">
ulating objects needs to be able to verbalize its in-
tended actions and give feedback about its internal
state, but it also needs to react on feedback com-
ments or corrections uttered by the human tutor. In
order to equip a robot with such fine-grained com-
munication skills, tight integration of action exe-
cution into interaction is required. In simple terms,
while the dialog frameworks mentioned can be re-
ferred to as information-oriented, we need rather
action-oriented approaches for robotics.
</bodyText>
<equation confidence="0.919489">
R: What is that? (points)
H: This is a lemon.
</equation>
<table confidence="0.876741818181818">
R: A melon. OK.
H: No, I said ’lemon’!
R: A lemon. OK.
R: How should I grasp the lemon?
H: That way. (demonstrates grip)
R: Alright, with the power grasp.
R: I am going to grasp it (starts grasping)
R: I start grasping now.
H: Robot, what objects do you know?
R: Lemon.
R: OK, I finished grasping. (stops grasping)
</table>
<tableCaption confidence="0.999775">
Table 1: A typical interaction with the Curious Robot.
</tableCaption>
<sectionHeader confidence="0.918144" genericHeader="method">
2 The Pamini framework
</sectionHeader>
<bodyText confidence="0.996608666666667">
This paper presents the Pamini (Pattern-based
mixed-initiative) human-robot interaction frame-
work. Pamini proposes a new approach for dialog
</bodyText>
<subsubsectionHeader confidence="0.676305">
Proceedings of SIGDIAL 2010: the 11th Annual Meeting of the Special Interest Group on Discourse and Dialogue, pages 229–232,
</subsubsectionHeader>
<affiliation confidence="0.890792">
The University of Tokyo, September 24-25, 2010. c�2010 Association for Computational Linguistics
</affiliation>
<page confidence="0.999623">
229
</page>
<bodyText confidence="0.999939277777778">
modeling on robots that includes (1) a task-state
protocol providing a fine-grained interface to the
complex domain processing of the robotic system
and (2) the concept of generic interaction patterns
that support rapid prototyping of human-robot in-
teractions and can be combined in a flexible way.
Previous versions of the Pamini framework
have been applied in several mixed-initiative
learning scenarios. For example, in the Home-
Tour scenario a mobile robot builds up a spatial
model of its environment and gradually improves
its model by attempting to obtain information from
the human (Peltason et al., 2009). In the Curious
Robot scenario shown in figure 1, an anthropomor-
phic robot learns to label and grasp objects, apply-
ing a proactive dialog strategy that provides guid-
ance for untrained users (L¨utkebohle et al., 2009).
A dialog excerpt is shown in table 1.
</bodyText>
<subsectionHeader confidence="0.960428">
2.1 The task state protocol
</subsectionHeader>
<bodyText confidence="0.999989928571429">
A dialog system for robotics needs to coordinate
with a number of components, e.g. for perceptual
analysis, motor control or components generating
nonverbal feedback. To realize this, we use the
concept of tasks that can be performed by com-
ponents. Tasks are described by an execution state
and a task specification containing the information
required for execution. A protocol specifies task
states relevant for coordination and possible tran-
sitions between them as shown in figure 2. Task
updates, i.e. updates of the task state and possi-
bly the task specification, cause event notifications
which are delivered to the participating compo-
nents whereupon they take an appropriate action.
</bodyText>
<figure confidence="0.46887">
CANCELLED
</figure>
<figureCaption confidence="0.9235495">
Figure 2: The task life-cycle. A task gets initiated, ac-
cepted, may be cancelled or updated, may deliver intermedi-
ate results and finally is completed. Alternatively, it can be
rejected by the handling component or execution may fail.
</figureCaption>
<bodyText confidence="0.995906">
Tight integration with action execution A
robot performing e.g. a grasp action supervised
by the human requires multi-step communication
between the dialog system and the arm control as
illustrated in figure 3. Generally, with the accepted
state, the proposed protocol enables the dialog sys-
tem to provide feedback during slow-going actions
indicating the internal system state. Further, with
the update and result available states, it supports
the modification of the task specification during
execution and thus gives the robot the ability to
react to comments, corrections and commands on-
the-fly.
</bodyText>
<figureCaption confidence="0.925501">
Figure 3: The component communication for a grasp ac-
</figureCaption>
<bodyText confidence="0.998442178571428">
tion requested by the human. As the dialog manager (DLG)
receives the grasp command, it initiates a grasp task which
is accepted by the arm control. The DLG is notified about
the task state update and acknowledges task execution. As
the human commands cancelling, the DLG sets the task state
cancel. Since the arm control fails to cancel the task, it sets
the task state cancel failed which the DLG reacts on by ex-
pressing an excuse. Finally the task is completed, and the
DLG acknowledges successful task execution.
Mixed-initiative interaction The Pamini dialog
manager offers dialog tasks for other components,
e.g. greeting the human, informing the human
about anything or conversely requesting informa-
tion from the human. While human initiative is re-
alized whenever input from a speech understand-
ing component is received, robot initiative occurs
when a system component requests a dialog task to
be executed. Situation permitting, the dialog man-
ager will accept the dialog task, go into interaction
with the human, and finally complete the dialog
task. Thus, it can react to the system’s and the hu-
man’s initiative using the same task-state protocol
Learning within interaction The task state pro-
tocol supports robotic learning within interaction
by establishing mechanisms for information trans-
fer from the dialog system to the robotic sub-
system. Once information is available from the
human, Pamini augments the task specification
</bodyText>
<figure confidence="0.99024782051282">
update
requested
update accept, reject
initiated
accepted
running
cancel_failed
rejected
failed
cancel
DONE
cancel
requested
result_available
Speech
recognition
Text-to-
Speech
Arm Control
Dialog
8:
say
(I can not stop)
1:
receive
(Grasp the apple)
receive
(Stop)
2: initiate Grasp
3: accept Grasp
6: cancel Grasp
7: cancel_failed
9: complete Grasp
say
(I am going
to grasp the apple.)
say
(I finished)
10:
</figure>
<page confidence="0.981202">
230
</page>
<bodyText confidence="0.999960714285714">
with the new information and sets the task state
result available. Since this transition may be
taken multiple times, given information can be
corrected. Also, mixed-initiative enables active
learning, where the learner provokes a situation
providing new information instead of waiting un-
til such situation eventually presents itself.
</bodyText>
<subsectionHeader confidence="0.996959">
2.2 Interaction patterns
</subsectionHeader>
<bodyText confidence="0.99991975">
In an interaction, dialog acts are not unrelated
events, but form coherent sequences. For exam-
ple, a question is usually followed by an answer,
and a request is typically either accepted or re-
jected. Influenced by the concepts of adjacency
pairs (Schegloff and Sacks, 1973), conversation
policies (Winograd, 1986) and software design
patterns, we propose the concept of interaction
patterns that describe recurring dialog structures
on a high level. Interaction patterns can be formal-
ized as transducer augmented with internal state
actions, consisting of
</bodyText>
<listItem confidence="0.999706333333334">
• a set of human dialog acts H and a set of robot dialog
acts R, e.g. H.request or R.assert;
• a set of incoming task events T, e.g. accepted or failed;
• a set of states S representing the interaction state;
• a set of actions A the dialog manager performs, e.g.
initiating or updating a task or reset interaction;
• an input alphabet E C (H U T);
• an output alphabet A C R;
• a transition function T : S x E* −+ S x A* x A*.
</listItem>
<bodyText confidence="0.99993375">
By admitting task events as input and internal
actions that perform task initiation and update,
the dialog level is linked with the domain level.
The patterns have been implemented as statecharts
(Harel, 1987), an extended form of finite state ma-
chines, which provides both an executable model
and an understandable graphical representation as
shown in figure 5. For instance, the cancellable
</bodyText>
<figureCaption confidence="0.984079">
Figure 5: Interaction patterns are represented as transducer
that takes as input human dialog acts and task events and pro-
duces robot dialog acts as output.
</figureCaption>
<bodyText confidence="0.999626">
action request pattern shown in figure 4 describes
an action request initiated by the human that can
be cancelled during execution. The normal course
of events is that the human requests the action to
be executed, the dialog manager initiates the do-
main task, the responsible system component ac-
cepts execution so that the dialog manager will
assert execution. Finally, the task is completed
and the robot acknowledges. In contrast, the cor-
rectable information request pattern is initiated by
the human. Here, on receiving the respective di-
alog task request, the dialog manager will ask for
the desired information and accept the dialog task.
Once the human provides the answer, the robot
will repeat it as implicit confirmation that can be
corrected if necessary. Table 2 lists all patterns that
have been identified so far.
</bodyText>
<table confidence="0.99355425">
Initiated by user Initiated by robot
Cancellable action request Self-initiated cancellable action
Simple action request Self-initiated simple action
Information request Correctable information request
Interaction opening Simple information request
Interaction closing Clarification
Interaction restart
System reset
</table>
<tableCaption confidence="0.998984">
Table 2: Available interaction patterns.
</tableCaption>
<bodyText confidence="0.999596617647059">
Pattern configuration The patterns themselves
do not determine what kind of task is to be ex-
ecuted or what kind of information to obtain ex-
actly. These specifics are defined by the configu-
ration associated with each pattern, and a concrete
scenario is realized by configuring a set of patterns
using a domain-specific language and registering
them with the dialog manager.
In detail, it needs to be specified for the human’s
dialog acts what kind of (possibly multimodal) in-
put is interpreted as a given dialog act which is
done by formulating conditions over the input. For
the robot’s dialog acts, their surface form needs to
be specified. Up to now, speech output and point-
ing gestures are implemented as output modalities
and can be combined. Moreover, also the task
communication needs to be configured, i.e. the
task specification itself as well as possible task
specification updates. In addition, the developer
can define context variables and use them to pa-
rameterize the robot’s dialog acts and in task spec-
ification updates. This is how e.g. for the robot’s
information request the answer is transferred from
the human to the responsible system component.
Interleaving patterns during interaction Dur-
ing interaction, the registered patterns are em-
ployed in a flexible way by admitting patterns to
be interrupted by other patterns and possibly re-
sumed later which leads to interleaving patterns.
By default, simpler patterns are permitted to be
nested within temporally extended patterns. For
example, it seems reasonable to permit monitoring
questions uttered by the human to be embedded in
the robot’s slow-going grasp execution as shown
</bodyText>
<figure confidence="0.949015555555556">
state name
action, when entered
H.dialog-act / R.dialog-act
task event / R.dialog-act
state name
/
/
state name
H.dialog-act /
</figure>
<page confidence="0.867612">
231
</page>
<figureCaption confidence="0.996404">
Figure 4: Two example interaction patterns. Cancellable action request: an action request which is initiated by the human
and can be cancelled during execution. Correctable information request: an information request with implicit confirmation
initiated by the robot where information can be corrected later if necessary.
</figureCaption>
<figure confidence="0.999087617647059">
system task canceled / R.acknowledge
H.cancel /
H.cancel /
cancel_requested
update-system-task-state(abort)
H.request / initiate system_task_accepted / R.assert asserted
initiate-system-task(ShortTerm)
system_task_rejected / R.refuse
system_task_cancel_failed / R.refuse
system_task_completed / R.acknowledge
terminated
/
failed
/
refused
/
asked
update-dialog-task-state(accepted)
H.answer /
answered
/ R.const-question
/ R.repeat
H.correct /
repeated
apply-dialog-task-spec-update
update-dialog-task-state(result_available)
H.negate /
* /
confirmed
update-dialog-task-state(completed)
disconfirmed
/
system_task_failed / R.apologize
/ R.question
</figure>
<bodyText confidence="0.999695666666667">
in table 1 which equips the robot with multitasking
capabilities. Interleaving is realized by organizing
active patterns on a stack. Whenever an input is
received, the dialog manager attempts to interpret
it in the context provided by the topmost pattern.
If it fails, the lower and inactive patterns are tried.
</bodyText>
<sectionHeader confidence="0.998836" genericHeader="discussions">
3 Discussion and Conclusion
</sectionHeader>
<bodyText confidence="0.99998945">
The presented approach to dialog modeling on
robots relies on the concept of interaction patterns
that constitute configurable (and thus reusable)
building blocks of interaction. A fine-grained task
state protocol links dialog and domain level. With
interleaving patterns, flexible dialog modeling is
achieved that goes beyond current state-of-the-art
dialog modeling on robots. Further, by encapsulat-
ing both the subtleties of dialog management and
the complexity of component integration, the pro-
posed interaction patterns support rapid prototyp-
ing of human-robot interaction scenarios.
The evaluation of the approach needs to exam-
ine framework usability, framework functionality
and usability of the resulting dialogs. With respect
to framework usability, we already showed that
developers unfamiliar with the framework were
able to build a simple interaction scenario within
one hour (Peltason and Wrede, 2010). With re-
spect to framework functionality, we demonstrated
that the robot’s mixed-initiative interaction capa-
bilities enable human and robot in the Home-Tour
scenario to jointly build up a common represen-
tation of their environment and even compensate
for classification errors (Peltason et al., 2009).
As to dialog usability, a video study indicates
that the Curious Robot’s proactive dialog strat-
egy guides unexperienced users (L¨utkebohle et al.,
2009). Further, given a dialog system architecture
that supports rapid prototyping, comparative stud-
ies become possible. Therefore, we currently pre-
pare a study to compare the curiosity strategy with
a user-directed strategy that provides more free-
dom but also more uncertainty to the user. Last
but not least, we will evaluate the patterns them-
selves and pattern interleavability. Are users likely
to interrupt a robot’s action by asking questions or
even giving new commands? Also, are there other
kinds of interaction patterns that occur in a real in-
teraction but are not captured yet?
</bodyText>
<sectionHeader confidence="0.999104" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999350310344828">
A. Bauer, D. Wollherr, and M. Buss. 2009. Information re-
trieval system for human-robot communication asking for
directions. In International Conference on Robotics and
Automation.
H.-J. B¨ohme, T. Wilhelm, J. Key, C. Schauer, C. Schr¨oter,
H.-M. Groß, and T. Hempel. 2003. An approach to multi-
modal human-machine interaction for intelligent service
robots. Robotics and Autonomous Systems, 44(1).
D. Bohus and A. I. Rudnicky. 2009. The ravenclaw dialog
management framework: Architecture and systems. Com-
puter Speech &amp; Language, 23(3):332–361.
D. Harel. 1987. Statecharts: A visual formalism for complex
systems. Science of Computer Programming, 8:231–274.
I. L¨utkebohle, J. Peltason, L. Schillingmann, C. Elbrechter,
B. Wrede, S. Wachsmuth, and R. Haschke. 2009. The
curious robot - structuring interactive robot learning. In
International Conference on Robotics and Automation.
J. Peltason and B. Wrede. 2010. Modeling human-robot in-
teraction based on generic interaction patterns. In AAAI
Technical Report: Dialog with Robots. submitted.
J. Peltason, F. Siepmann, T. Spexard, B. Wrede, M. Han-
heide, and E. Topp. 2009. Mixed-initiative in human
augmented mapping. In International Conference on
Robotics and Automation.
E. A. Schegloff and H. Sacks. 1973. Opening up closings.
Semiotica, 8(4):289–327.
T. Winograd. 1986. A language/action perspective on the
design of cooperative work. In Conference on Computer-
supported cooperative work.
</reference>
<page confidence="0.994994">
232
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.799502">
<title confidence="0.9966145">Pamini: A framework for assembling mixed-initiative interaction from generic interaction patterns</title>
<author confidence="0.987321">Julia Peltason</author>
<author confidence="0.987321">Britta</author>
<affiliation confidence="0.927825">Applied Informatics, Faculty of Bielefeld University,</affiliation>
<email confidence="0.945927">jpeltaso,bwrede@techfak.uni-bielefeld.de</email>
<abstract confidence="0.999687714285714">Dialog modeling in robotics suffers from lack of generalizability, due to the fact that the dialog is heavily influenced by the tasks the robot is able to perform. We introduce interleaving interaction patterns together with a general protocol for task communication which enables us to systematically specify the relationship between dialog structure and task structure. We argue that this approach meets the requirements of advanced dialog modeling on robots and at the same time exhibits a better scalability than existing concepts.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>A Bauer</author>
<author>D Wollherr</author>
<author>M Buss</author>
</authors>
<title>Information retrieval system for human-robot communication asking for directions.</title>
<date>2009</date>
<booktitle>In International Conference on Robotics and Automation.</booktitle>
<contexts>
<context position="1215" citStr="Bauer et al., 2009" startWordPosition="173" endWordPosition="176">ween dialog structure and task structure. We argue that this approach meets the requirements of advanced dialog modeling on robots and at the same time exhibits a better scalability than existing concepts. 1 Introduction The need for interaction modeling on robots is widely acknowledged, not only for instructing them but also for enabling them to learn from humans within interaction. Yet, today’s robotic systems often do not have a dedicated dialog system but employ simple command-matching techniques (e.g. (B¨ohme et al., 2003)). Other systems rely on finite-state based dialog managers (e.g. (Bauer et al., 2009)) that couple dialog and task management which hampers maintainability and reuse and does not scale well for more complex interaction scenarios. On the other hand, concepts for reusable dialog frameworks have been established within the spoken dialog community for traditional informationseeking domains where the system first collects the required parameters, then presents the desired information to the user, e.g. an accommodation or travel information (e.g. (Bohus and Rudnicky, 2009)). However, these concepts are not directly transferable to robotics, due to the situated nature of human-robot </context>
</contexts>
<marker>Bauer, Wollherr, Buss, 2009</marker>
<rawString>A. Bauer, D. Wollherr, and M. Buss. 2009. Information retrieval system for human-robot communication asking for directions. In International Conference on Robotics and Automation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H-J B¨ohme</author>
<author>T Wilhelm</author>
<author>J Key</author>
<author>C Schauer</author>
<author>C Schr¨oter</author>
<author>H-M Groß</author>
<author>T Hempel</author>
</authors>
<title>An approach to multimodal human-machine interaction for intelligent service robots. Robotics and Autonomous Systems,</title>
<date>2003</date>
<volume>44</volume>
<issue>1</issue>
<marker>B¨ohme, Wilhelm, Key, Schauer, Schr¨oter, Groß, Hempel, 2003</marker>
<rawString>H.-J. B¨ohme, T. Wilhelm, J. Key, C. Schauer, C. Schr¨oter, H.-M. Groß, and T. Hempel. 2003. An approach to multimodal human-machine interaction for intelligent service robots. Robotics and Autonomous Systems, 44(1).</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Bohus</author>
<author>A I Rudnicky</author>
</authors>
<title>The ravenclaw dialog management framework: Architecture and systems.</title>
<date>2009</date>
<journal>Computer Speech &amp; Language,</journal>
<volume>23</volume>
<issue>3</issue>
<contexts>
<context position="1703" citStr="Bohus and Rudnicky, 2009" startWordPosition="246" endWordPosition="249">and-matching techniques (e.g. (B¨ohme et al., 2003)). Other systems rely on finite-state based dialog managers (e.g. (Bauer et al., 2009)) that couple dialog and task management which hampers maintainability and reuse and does not scale well for more complex interaction scenarios. On the other hand, concepts for reusable dialog frameworks have been established within the spoken dialog community for traditional informationseeking domains where the system first collects the required parameters, then presents the desired information to the user, e.g. an accommodation or travel information (e.g. (Bohus and Rudnicky, 2009)). However, these concepts are not directly transferable to robotics, due to the situated nature of human-robot interaction. A robot perceives the world and acts on it – and it is supposed to communicate about that. For instance, a robot manipFigure 1: The Curious Robot set-up. ulating objects needs to be able to verbalize its intended actions and give feedback about its internal state, but it also needs to react on feedback comments or corrections uttered by the human tutor. In order to equip a robot with such fine-grained communication skills, tight integration of action execution into inter</context>
</contexts>
<marker>Bohus, Rudnicky, 2009</marker>
<rawString>D. Bohus and A. I. Rudnicky. 2009. The ravenclaw dialog management framework: Architecture and systems. Computer Speech &amp; Language, 23(3):332–361.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D Harel</author>
</authors>
<title>Statecharts: A visual formalism for complex systems.</title>
<date>1987</date>
<journal>Science of Computer Programming,</journal>
<pages>8--231</pages>
<contexts>
<context position="9168" citStr="Harel, 1987" startWordPosition="1450" endWordPosition="1451">cts H and a set of robot dialog acts R, e.g. H.request or R.assert; • a set of incoming task events T, e.g. accepted or failed; • a set of states S representing the interaction state; • a set of actions A the dialog manager performs, e.g. initiating or updating a task or reset interaction; • an input alphabet E C (H U T); • an output alphabet A C R; • a transition function T : S x E* −+ S x A* x A*. By admitting task events as input and internal actions that perform task initiation and update, the dialog level is linked with the domain level. The patterns have been implemented as statecharts (Harel, 1987), an extended form of finite state machines, which provides both an executable model and an understandable graphical representation as shown in figure 5. For instance, the cancellable Figure 5: Interaction patterns are represented as transducer that takes as input human dialog acts and task events and produces robot dialog acts as output. action request pattern shown in figure 4 describes an action request initiated by the human that can be cancelled during execution. The normal course of events is that the human requests the action to be executed, the dialog manager initiates the domain task,</context>
</contexts>
<marker>Harel, 1987</marker>
<rawString>D. Harel. 1987. Statecharts: A visual formalism for complex systems. Science of Computer Programming, 8:231–274.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I L¨utkebohle</author>
<author>J Peltason</author>
<author>L Schillingmann</author>
<author>C Elbrechter</author>
<author>B Wrede</author>
<author>S Wachsmuth</author>
<author>R Haschke</author>
</authors>
<title>The curious robot - structuring interactive robot learning.</title>
<date>2009</date>
<booktitle>In International Conference on Robotics and Automation.</booktitle>
<marker>L¨utkebohle, Peltason, Schillingmann, Elbrechter, Wrede, Wachsmuth, Haschke, 2009</marker>
<rawString>I. L¨utkebohle, J. Peltason, L. Schillingmann, C. Elbrechter, B. Wrede, S. Wachsmuth, and R. Haschke. 2009. The curious robot - structuring interactive robot learning. In International Conference on Robotics and Automation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Peltason</author>
<author>B Wrede</author>
</authors>
<title>Modeling human-robot interaction based on generic interaction patterns.</title>
<date>2010</date>
<booktitle>In AAAI Technical Report: Dialog with Robots. submitted.</booktitle>
<contexts>
<context position="14696" citStr="Peltason and Wrede, 2010" startWordPosition="2252" endWordPosition="2255">modeling is achieved that goes beyond current state-of-the-art dialog modeling on robots. Further, by encapsulating both the subtleties of dialog management and the complexity of component integration, the proposed interaction patterns support rapid prototyping of human-robot interaction scenarios. The evaluation of the approach needs to examine framework usability, framework functionality and usability of the resulting dialogs. With respect to framework usability, we already showed that developers unfamiliar with the framework were able to build a simple interaction scenario within one hour (Peltason and Wrede, 2010). With respect to framework functionality, we demonstrated that the robot’s mixed-initiative interaction capabilities enable human and robot in the Home-Tour scenario to jointly build up a common representation of their environment and even compensate for classification errors (Peltason et al., 2009). As to dialog usability, a video study indicates that the Curious Robot’s proactive dialog strategy guides unexperienced users (L¨utkebohle et al., 2009). Further, given a dialog system architecture that supports rapid prototyping, comparative studies become possible. Therefore, we currently prepa</context>
</contexts>
<marker>Peltason, Wrede, 2010</marker>
<rawString>J. Peltason and B. Wrede. 2010. Modeling human-robot interaction based on generic interaction patterns. In AAAI Technical Report: Dialog with Robots. submitted.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Peltason</author>
<author>F Siepmann</author>
<author>T Spexard</author>
<author>B Wrede</author>
<author>M Hanheide</author>
<author>E Topp</author>
</authors>
<title>Mixed-initiative in human augmented mapping.</title>
<date>2009</date>
<booktitle>In International Conference on Robotics and Automation.</booktitle>
<contexts>
<context position="3896" citStr="Peltason et al., 2009" startWordPosition="602" endWordPosition="605">stics 229 modeling on robots that includes (1) a task-state protocol providing a fine-grained interface to the complex domain processing of the robotic system and (2) the concept of generic interaction patterns that support rapid prototyping of human-robot interactions and can be combined in a flexible way. Previous versions of the Pamini framework have been applied in several mixed-initiative learning scenarios. For example, in the HomeTour scenario a mobile robot builds up a spatial model of its environment and gradually improves its model by attempting to obtain information from the human (Peltason et al., 2009). In the Curious Robot scenario shown in figure 1, an anthropomorphic robot learns to label and grasp objects, applying a proactive dialog strategy that provides guidance for untrained users (L¨utkebohle et al., 2009). A dialog excerpt is shown in table 1. 2.1 The task state protocol A dialog system for robotics needs to coordinate with a number of components, e.g. for perceptual analysis, motor control or components generating nonverbal feedback. To realize this, we use the concept of tasks that can be performed by components. Tasks are described by an execution state and a task specification</context>
<context position="14997" citStr="Peltason et al., 2009" startWordPosition="2296" endWordPosition="2299">evaluation of the approach needs to examine framework usability, framework functionality and usability of the resulting dialogs. With respect to framework usability, we already showed that developers unfamiliar with the framework were able to build a simple interaction scenario within one hour (Peltason and Wrede, 2010). With respect to framework functionality, we demonstrated that the robot’s mixed-initiative interaction capabilities enable human and robot in the Home-Tour scenario to jointly build up a common representation of their environment and even compensate for classification errors (Peltason et al., 2009). As to dialog usability, a video study indicates that the Curious Robot’s proactive dialog strategy guides unexperienced users (L¨utkebohle et al., 2009). Further, given a dialog system architecture that supports rapid prototyping, comparative studies become possible. Therefore, we currently prepare a study to compare the curiosity strategy with a user-directed strategy that provides more freedom but also more uncertainty to the user. Last but not least, we will evaluate the patterns themselves and pattern interleavability. Are users likely to interrupt a robot’s action by asking questions or</context>
</contexts>
<marker>Peltason, Siepmann, Spexard, Wrede, Hanheide, Topp, 2009</marker>
<rawString>J. Peltason, F. Siepmann, T. Spexard, B. Wrede, M. Hanheide, and E. Topp. 2009. Mixed-initiative in human augmented mapping. In International Conference on Robotics and Automation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E A Schegloff</author>
<author>H Sacks</author>
</authors>
<title>Opening up closings.</title>
<date>1973</date>
<journal>Semiotica,</journal>
<volume>8</volume>
<issue>4</issue>
<contexts>
<context position="8248" citStr="Schegloff and Sacks, 1973" startWordPosition="1284" endWordPosition="1287">e new information and sets the task state result available. Since this transition may be taken multiple times, given information can be corrected. Also, mixed-initiative enables active learning, where the learner provokes a situation providing new information instead of waiting until such situation eventually presents itself. 2.2 Interaction patterns In an interaction, dialog acts are not unrelated events, but form coherent sequences. For example, a question is usually followed by an answer, and a request is typically either accepted or rejected. Influenced by the concepts of adjacency pairs (Schegloff and Sacks, 1973), conversation policies (Winograd, 1986) and software design patterns, we propose the concept of interaction patterns that describe recurring dialog structures on a high level. Interaction patterns can be formalized as transducer augmented with internal state actions, consisting of • a set of human dialog acts H and a set of robot dialog acts R, e.g. H.request or R.assert; • a set of incoming task events T, e.g. accepted or failed; • a set of states S representing the interaction state; • a set of actions A the dialog manager performs, e.g. initiating or updating a task or reset interaction; •</context>
</contexts>
<marker>Schegloff, Sacks, 1973</marker>
<rawString>E. A. Schegloff and H. Sacks. 1973. Opening up closings. Semiotica, 8(4):289–327.</rawString>
</citation>
<citation valid="true">
<authors>
<author>T Winograd</author>
</authors>
<title>A language/action perspective on the design of cooperative work.</title>
<date>1986</date>
<booktitle>In Conference on Computersupported cooperative work.</booktitle>
<contexts>
<context position="8288" citStr="Winograd, 1986" startWordPosition="1290" endWordPosition="1291">ailable. Since this transition may be taken multiple times, given information can be corrected. Also, mixed-initiative enables active learning, where the learner provokes a situation providing new information instead of waiting until such situation eventually presents itself. 2.2 Interaction patterns In an interaction, dialog acts are not unrelated events, but form coherent sequences. For example, a question is usually followed by an answer, and a request is typically either accepted or rejected. Influenced by the concepts of adjacency pairs (Schegloff and Sacks, 1973), conversation policies (Winograd, 1986) and software design patterns, we propose the concept of interaction patterns that describe recurring dialog structures on a high level. Interaction patterns can be formalized as transducer augmented with internal state actions, consisting of • a set of human dialog acts H and a set of robot dialog acts R, e.g. H.request or R.assert; • a set of incoming task events T, e.g. accepted or failed; • a set of states S representing the interaction state; • a set of actions A the dialog manager performs, e.g. initiating or updating a task or reset interaction; • an input alphabet E C (H U T); • an out</context>
</contexts>
<marker>Winograd, 1986</marker>
<rawString>T. Winograd. 1986. A language/action perspective on the design of cooperative work. In Conference on Computersupported cooperative work.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>