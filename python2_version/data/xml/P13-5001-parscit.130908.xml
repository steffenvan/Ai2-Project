<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.219678">
<title confidence="0.998819">
Visual Features for Linguists:
Basic image analysis techniques for multimodally-curious NLPers
</title>
<author confidence="0.999479">
Elia Bruni Marco Baroni
</author>
<affiliation confidence="0.999639">
University of Trento University of Trento
</affiliation>
<email confidence="0.965541">
elia.bruni@unitn.it marco.baroni@unitn.it
</email>
<sectionHeader confidence="0.959181" genericHeader="abstract">
Description
</sectionHeader>
<bodyText confidence="0.991309948717949">
Features automatically extracted from images con-
stitute a new and rich source of semantic knowl-
edge that can complement information extracted
from text. The convergence between vision- and
text-based information can be exploited in scenar-
ios where the two modalities must be combined
to solve a target task (e.g., generating verbal de-
scriptions of images, or finding the right images
to illustrate a story). However, the potential ap-
plications for integrated visual features go beyond
mixed-media scenarios: Because of their comple-
mentary nature with respect to language, visual
features might provide perceptually grounded se-
mantic information that can be exploited in purely
linguistic domains.
The tutorial will first introduce basic techniques
to encode image contents in terms of low-level fea-
tures, such as the widely adopted SIFT descriptors.
We will then show how these low-level descriptors
are used to induce more abstract features, focus-
ing on the well-established bags-of-visual-words
method to represent images, but also briefly in-
troducing more recent developments, that include
capturing spatial information with pyramid repre-
sentations, soft visual word clustering via Fisher
encoding and attribute-based image representa-
tion. Next, we will discuss some example appli-
cations, and we will conclude with a brief practi-
cal illustration of visual feature extraction using a
software package we developed.
The tutorial is addressed to computational lin-
guists without any background in computer vi-
sion. It provides enough background material to
understand the vision-and-language literature and
the less technical articles on image analysis. After
the tutorial, the participants should also be able to
autonomously incorporate visual features in their
NLP pipelines using off-the-shelf tools.
Outline
</bodyText>
<listItem confidence="0.999109739130435">
1. Why image analysis?
• The grounding problem
• Multimodal datasets (Pascal, SUN, Im-
ageNet and ESP-Game)
2. Extraction of low-level features from images
• Challenges (viewpoint, illumination,
scale, occlusion, etc.)
• Feature detectors
• Feature descriptors
3. Visual words for higher-level representation
of visual information
• Constructing a vocabulary of visual
words
• Classic Bags-of-visual-words represen-
tation
• Recent advances
• Computer vision applications: Object
recognition and emotion analysis
4. Going multimodal: Example applications of
visual features in NLP
• Generating image descriptions
• Semantic relatedness
• Modeling selectional preference
</listItem>
<page confidence="0.47056">
1
</page>
<reference confidence="0.847429">
Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, page 1,
Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.126915">
<title confidence="0.999489">Visual Features for Linguists: Basic image analysis techniques for multimodally-curious NLPers</title>
<author confidence="0.999999">Elia Bruni Marco Baroni</author>
<affiliation confidence="0.996591">University of Trento University of Trento</affiliation>
<abstract confidence="0.966220666666667">elia.bruni@unitn.it marco.baroni@unitn.it Description Features automatically extracted from images constitute a new and rich source of semantic knowledge that can complement information extracted from text. The convergence between visionand text-based information can be exploited in scenarios where the two modalities must be combined to solve a target task (e.g., generating verbal descriptions of images, or finding the right images to illustrate a story). However, the potential applications for integrated visual features go beyond mixed-media scenarios: Because of their complementary nature with respect to language, visual features might provide perceptually grounded semantic information that can be exploited in purely linguistic domains. The tutorial will first introduce basic techniques to encode image contents in terms of low-level features, such as the widely adopted SIFT descriptors. We will then show how these low-level descriptors are used to induce more abstract features, focusing on the well-established bags-of-visual-words method to represent images, but also briefly introducing more recent developments, that include capturing spatial information with pyramid representations, soft visual word clustering via Fisher encoding and attribute-based image representation. Next, we will discuss some example applications, and we will conclude with a brief practical illustration of visual feature extraction using a software package we developed. The tutorial is addressed to computational linguists without any background in computer vision. It provides enough background material to understand the vision-and-language literature and the less technical articles on image analysis. After the tutorial, the participants should also be able to autonomously incorporate visual features in their NLP pipelines using off-the-shelf tools. Outline 1. Why image analysis? • The grounding problem • Multimodal datasets (Pascal, SUN, ImageNet and ESP-Game) 2. Extraction of low-level features from images • Challenges (viewpoint, illumination, scale, occlusion, etc.) • Feature detectors • Feature descriptors 3. Visual words for higher-level representation of visual information • Constructing a vocabulary of visual words • Classic Bags-of-visual-words representation • Recent advances • Computer vision applications: Object recognition and emotion analysis 4. Going multimodal: Example applications of visual features in NLP • Generating image descriptions • Semantic relatedness • Modeling selectional preference 1 of the 51st Annual Meeting of the Association for Computational page</abstract>
<intro confidence="0.40096">Bulgaria, August 4-9 2013. Association for Computational Linguistics</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<booktitle>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1</pages>
<marker></marker>
<rawString>Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, page 1,</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bulgaria Sofia</author>
</authors>
<date>2013</date>
<booktitle>c�2013 Association for Computational Linguistics</booktitle>
<marker>Sofia, 2013</marker>
<rawString>Sofia, Bulgaria, August 4-9 2013. c�2013 Association for Computational Linguistics</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>