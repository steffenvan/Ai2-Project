<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.010694">
<title confidence="0.9904155">
SemEval-2010 Task 8: Multi-Way Classification
of Semantic Relations Between Pairs of Nominals
</title>
<author confidence="0.905735">
Iris Hendrickx∗, Su Nam Kim† , Zornitsa Kozareva‡ , Preslav Nakov§ ,
Diarmuid O´ S´eaghdha¶, Sebastian Pad´ok, Marco Pennacchiotti∗∗,
Lorenza Romano††, Stan Szpakowicz‡‡
</author>
<sectionHeader confidence="0.950114" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997461846153846">
We present a brief overview of the main
challenges in the extraction of semantic
relations from English text, and discuss the
shortcomings of previous data sets and shared
tasks. This leads us to introduce a new
task, which will be part of SemEval-2010:
multi-way classification of mutually exclusive
semantic relations between pairs of common
nominals. The task is designed to compare
different approaches to the problem and to
provide a standard testbed for future research,
which can benefit many applications in
Natural Language Processing.
</bodyText>
<sectionHeader confidence="0.998973" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999804454545455">
The computational linguistics community has a con-
siderable interest in robust knowledge extraction,
both as an end in itself and as an intermediate step
in a variety of Natural Language Processing (NLP)
applications. Semantic relations between pairs of
words are an interesting case of such semantic
knowledge. It can guide the recovery of useful facts
about the world, the interpretation of a sentence, or
even discourse processing. For example, pears and
bowl are connected in a CONTENT-CONTAINER re-
lation in the sentence “The bowl contained apples,
</bodyText>
<affiliation confidence="0.997584555555556">
*University of Antwerp, iris.hendrickx@ua.ac.be
† University of Melbourne, snkim@csse.unimelb.edu.au
$ University of Alicante, zkozareva@dlsi.ua.es
§ National University of Singapore, nakov@comp.nus.edu.sg
¶University of Cambridge, do242@cl.cam.ac.uk
II University of Stuttgart, pado@stanford.edu
**Yahoo! Inc., pennacc@yahoo-inc.com
††Fondazione Bruno Kessler, romano@fbk.eu
$$ University of Ottawa and Polish Academy of Sciences,
</affiliation>
<email confidence="0.76495">
szpak@site.uottawa.ca
</email>
<bodyText confidence="0.999632205882353">
pears, and oranges.”, while ginseng and taste are in
an ENTITY-ORIGIN relation in “The taste is notfrom
alcohol, but from the ginseng.”.
The automatic recognition of semantic relations
can have many applications, such as information
extraction (IE), document summarization, machine
translation, or construction of thesauri and seman-
tic networks. It can also facilitate auxiliary tasks
such as word sense disambiguation, language mod-
eling, paraphrasing or recognizing textual entail-
ment. For example, semantic network construction
can benefit from detecting a FUNCTION relation be-
tween airplane and transportation in “the airplane
is used for transportation” or a PART-WHOLE rela-
tion in “the car has an engine”. Similarly, all do-
mains that require deep understanding of text rela-
tions can benefit from knowing the relations that de-
scribe events like ACQUISITION between named en-
tities in “Yahoo has made a definitive agreement to
acquire Flickr”.
In this paper, we focus on the recognition of se-
mantic relations between pairs of common nomi-
nals. We present a task which will be part of the
SemEval-2010 evaluation exercise and for which we
are developing a new benchmark data set. This data
set and the associated task address three significant
problems encountered in previous work: (1) the def-
inition of a suitable set of relations; (2) the incorpo-
ration of context; (3) the desire for a realistic exper-
imental design. We outline these issues in Section
2. Section 3 describes the inventory of relations we
adopted for the task. The annotation process, the
design of the task itself and the evaluation method-
ology are presented in Sections 4-6.
</bodyText>
<page confidence="0.995461">
94
</page>
<note confidence="0.918557">
Proceedings of the NAACL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 94–99,
Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics
</note>
<sectionHeader confidence="0.762872" genericHeader="method">
2 Semantic Relation Classification: Issues
</sectionHeader>
<subsectionHeader confidence="0.994231">
2.1 Defining the Relation Inventory
</subsectionHeader>
<bodyText confidence="0.999917225806452">
A wide variety of relation classification schemes ex-
ist in the literature, reflecting the needs and granular-
ities of various applications. Some researchers only
investigate relations between named entities or in-
ternal to noun-noun compounds, while others have a
more general focus. Some schemes are specific to a
domain such as biomedical text.
Rosario and Hearst (2001) classify noun com-
pounds from the domain of medicine into 13 classes
that describe the semantic relation between the head
noun and the modifier. Rosario et al. (2002) classify
noun compounds using the MeSH hierarchy and a
multi-level hierarchy of semantic relations, with 15
classes at the top level. Stephens et al. (2001) pro-
pose 17 very specific classes targeting relations be-
tween genes. Nastase and Szpakowicz (2003) ad-
dress the problem of classifying noun-modifier rela-
tions in general text. They propose a two-level hier-
archy, with 5 classes at the first level and 30 classes
at the second one; other researchers (Kim and Bald-
win, 2005; Nakov and Hearst, 2008; Nastase et al.,
2006; Turney, 2005; Turney and Littman, 2005)
have used their class scheme and data set. Moldovan
et al. (2004) propose a 35-class scheme to classify
relations in various phrases; the same scheme has
been applied to noun compounds and other noun
phrases (Girju et al., 2005). Lapata (2002) presents a
binary classification of relations in nominalizations.
Pantel and Pennacchiotti (2006) concentrate on five
relations in an IE-style setting. In short, there is little
agreement on relation inventories.
</bodyText>
<subsectionHeader confidence="0.99947">
2.2 The Role of Context
</subsectionHeader>
<bodyText confidence="0.99992">
A fundamental question in relation classification is
whether the relations between nominals should be
considered out of context or in context. When one
looks at real data, it becomes clear that context does
indeed play a role. Consider, for example, the noun
compound wood shed: it may refer either to a shed
made of wood, or to a shed of any material used to
store wood. This ambiguity is likely to be resolved
in particular contexts. In fact, most NLP applica-
tions will want to determine not all possible relations
between two words, but rather the relation between
two instances in a particular context. While the in-
tegration of context is common in the field of IE (cf.
work in the context of ACE1), much of the exist-
ing literature on relation extraction considers word
pairs out of context (thus, types rather than tokens).
A notable exception is SemEval-2007 Task 4 Clas-
sification of Semantic Relations between Nominals
(Girju et al., 2007; Girju et al., 2008), the first to of-
fer a standard benchmark data set for seven semantic
relations between common nouns in context.
</bodyText>
<subsectionHeader confidence="0.99995">
2.3 Style of Classification
</subsectionHeader>
<bodyText confidence="0.961404">
The design of SemEval-2007 Task 4 had an im-
portant limitation. The data set avoided the chal-
lenge of defining a single unified standard classifi-
cation scheme by creating seven separate training
and test sets, one for each semantic relation. That
made the relation recognition task on each data set
a simple binary (positive / negative) classification
task.2 Clearly, this does not easily transfer to prac-
tical NLP settings, where any relation can hold be-
tween a pair of nominals which occur in a sentence
or a discourse.
</bodyText>
<subsectionHeader confidence="0.98805">
2.4 Summary
</subsectionHeader>
<bodyText confidence="0.9999427">
While there is a substantial amount of work on re-
lation extraction, the lack of standardization makes
it difficult to compare different approaches. It is
known from other fields that the availability of stan-
dard benchmark data sets can provide a boost to the
advancement of a field. As a first step, SemEval-
2007 Task 4 offered many useful insights into the
performance of different approaches to semantic re-
lation classification; it has also motivated follow-
up research (Davidov and Rappoport, 2008; Ka-
trenko and Adriaans, 2008; Nakov and Hearst, 2008;
O´ S´eaghdha and Copestake, 2008).
Our objective is to build on the achievements of
SemEval-2007 Task 4 while addressing its short-
comings. In particular, we consider a larger set of
semantic relations (9 instead of 7), we assume a
proper multi-class classification setting, we emulate
the effect of an “open” relation inventory by means
of a tenth class OTHER, and we will release to the
research community a data set with a considerably
</bodyText>
<footnote confidence="0.99889525">
1http://www.itl.nist.gov/iad/mig/tests/
ace/
2Although it was not designed for a multi-class set-up, some
subsequent publications tried to use the data sets in that manner.
</footnote>
<page confidence="0.998635">
95
</page>
<bodyText confidence="0.98729725">
larger number of examples than SemEval-2007 Task
4 or other comparable data sets. The last point is cru-
cial for ensuring the robustness of the performance
estimates for competing systems.
</bodyText>
<sectionHeader confidence="0.8200035" genericHeader="method">
3 Designing an Inventory of Semantic Re-
lations Between Nominals
</sectionHeader>
<bodyText confidence="0.999076243243243">
We begin by considering the first of the problems
listed above: defining of an inventory of semantic
relations. Ideally, it should be exhaustive (should al-
low the description of relations between any pair of
nominals) and mutually exclusive (each pair of nom-
inals in context should map onto only one relation).
The literature, however, suggests no such inventory
that could satisfy all needs. In practice, one always
must decide on a trade-off between these two prop-
erties. For example, the gene-gene relation inven-
tory of Stephens et al. (2001), with relations like X
phosphorylates Y, arguably allows no overlaps, but
is too specific for applications to general text.
On the other hand, schemes aimed at exhaus-
tiveness tend to run into overlap issues, due
to such fundamental linguistic phenomena as
metaphor (Lakoff, 1987). For example, in the sen-
tence Dark clouds gather over Nepal., the relation
between dark clouds and Nepal is literally a type of
ENTITY-DESTINATION, but in fact it refers to the
ethnic unrest in Nepal.
We seek a pragmatic compromise between the
two extremes. We have selected nine relations with
sufficiently broad coverage to be of general and
practical interest. We aim at avoiding “real” overlap
to the extent that this is possible, but we include two
sets of similar relations (ENTITY-ORIGIN/ENTITY-
DESTINATION and CONTENT-CONTAINER/COM-
PONENT-WHOLE/MEMBER-COLLECTION), which
can help assess the models’ ability to make such
fine-grained distinctions.3
As in Semeval-2007 Task 4, we give ordered two-
word names to the relations, where each word de-
scribes the role of the corresponding argument. The
full list of our nine relations follows4 (the definitions
we show here are intended to be indicative rather
than complete):
</bodyText>
<footnote confidence="0.997116">
3COMPONENT-WHOLE and MEMBER-COLLECTION are
proper subsets of PART-WHOLE, one of the relations in
SemEval-2007 Task 4.
4We have taken the first five from SemEval-2007 Task 4.
</footnote>
<table confidence="0.431284">
Cause-Effect. An event or object leads to an effect.
Example: Smoking causes cancer.
Instrument-Agency. An agent uses an instrument.
Example: laser printer
</table>
<listItem confidence="0.5311614">
Product-Producer. A producer causes a product to
exist. Example: The farmer grows apples.
Content-Container. An object is physically stored
in a delineated area of space, the container. Ex-
ample: Earth is located in the Milky Way.
Entity-Origin. An entity is coming or is derived
from an origin (e.g., position or material). Ex-
ample: letters from foreign countries
Entity-Destination. An entity is moving towards a
destination. Example: The boy went to bed.
</listItem>
<bodyText confidence="0.9771163">
Component-Whole. An object is a component of a
larger whole. Example: My apartment has a
large kitchen.
Member-Collection. A member forms a nonfunc-
tional part of a collection. Example: There are
many trees in the forest.
Communication-Topic. An act of communication,
whether written or spoken, is about a topic. Ex-
ample: The lecture was about semantics.
We add a tenth element to this set, the pseudo-
relation OTHER. It stands for any relation which
is not one of the nine explicitly annotated relations.
This is motivated by modelling considerations. Pre-
sumably, the data for OTHER will be very nonho-
mogeneous. By including it, we force any model of
the complete data set to correctly identify the deci-
sion boundaries between the individual relations and
“everything else”. This encourages good generaliza-
tion behaviour to larger, noisier data sets commonly
seen in real-world applications.
</bodyText>
<subsectionHeader confidence="0.998663">
3.1 Semantic Relations versus Semantic Roles
</subsectionHeader>
<bodyText confidence="0.99994">
There are three main differences between our task
(classification of semantic relations between nomi-
nals) and the related task of automatic labeling of
semantic roles (Gildea and Jurafsky, 2002).
The first difference is to do with the linguistic
phenomena described. Lexical resources for theo-
ries of semantic roles such as FrameNet (Fillmore et
</bodyText>
<page confidence="0.959653">
96
</page>
<bodyText confidence="0.999914577777778">
al., 2003) and PropBank (Palmer et al., 2005) have
been developed to describe the linguistic realization
patterns of events and states. Thus, they target pri-
marily verbs (or event nominalizations) and their de-
pendents, which are typically nouns. In contrast,
semantic relations may occur between all parts of
speech, although we limit our attention to nominals
in this task. Also, semantic role descriptions typi-
cally relate an event to a set of multiple participants
and props, while semantic relations are in practice
(although not necessarily) binary.
The second major difference is the syntactic con-
text. Theories of semantic roles usually developed
out of syntactic descriptions of verb valencies, and
thus they focus on describing the linking patterns of
verbs and their direct dependents, phenomena like
raising and noninstantiations notwithstanding (Fill-
more, 2002). Semantic relations are not tied to
predicate-argument structures. They can also be es-
tablished within noun phrases, noun compounds, or
sentences more generally (cf. the examples above).
The third difference is that of the level of gen-
eralization. FrameNet currently contains more than
825 different frames (event classes). Since the se-
mantic roles are designed to be interpreted at the
frame level, there is a priori a very large number
of unrelated semantic roles. There is a rudimen-
tary frame hierarchy that defines mappings between
roles of individual frames,5 but it is far from com-
plete. The situation is similar in PropBank. Prop-
Bank does use a small number of semantic roles, but
these are again to be interpreted at the level of in-
dividual predicates, with little cross-predicate gen-
eralization. In contrast, all of the semantic relation
inventories discussed in Section 1 contain fewer than
50 types of semantic relations. More generally, se-
mantic relation inventories attempt to generalize re-
lations across wide groups of verbs (Chklovski and
Pantel, 2004) and include relations that are not verb-
centered (Nastase and Szpakowicz, 2003; Moldovan
et al., 2004). Using the same labels for similar se-
mantic relations facilitates supervised learning. For
example, a model trained with examples of sell re-
lations should be able to transfer what it has learned
to give relations. This has the potential of adding
</bodyText>
<footnote confidence="0.985837333333333">
5For example, it relates the BUYER role of the COM-
MERCE SELL frame (verb sell) to the RECIPIENT role of the
GIVING frame (verb give).
</footnote>
<listItem confidence="0.9913946">
1. People in Hawaii might be feeling
&lt;e1&gt;aftershocks&lt;/e1&gt; from that power-
ful &lt;e2&gt;earthquake&lt;/e2&gt; for weeks.
2. My new &lt;e1&gt;apartment&lt;/e1&gt; has a
&lt;e2&gt;large kitchen&lt;/e2&gt;.
</listItem>
<figureCaption confidence="0.999602">
Figure 1: Two example sentences with annotation
</figureCaption>
<bodyText confidence="0.9724805">
crucial robustness and coverage to analysis tools in
NLP applications based on semantic relations.
</bodyText>
<sectionHeader confidence="0.996069" genericHeader="method">
4 Annotation
</sectionHeader>
<bodyText confidence="0.999344">
The next step in our study will be the actual annota-
tion of relations between nominals. For the purpose
of annotation, we define a nominal as a noun or a
base noun phrase. A base noun phrase is a noun and
its pre-modifiers (e.g., nouns, adjectives, determin-
ers). We do not include complex noun phrases (e.g.,
noun phrases with attached prepositional phrases or
relative clauses). For example, lawn is a noun, lawn
mower is a base noun phrase, and the engine of the
lawn mower is a complex noun phrase.
We focus on heads that are common nouns. This
emphasis distinguishes our task from much work in
IE, which focuses on named entities and on consid-
erably more fine-grained relations than we do. For
example, Patwardhan and Riloff (2007) identify cat-
egories like Terrorist organization as participants in
terror-related semantic relations, which consists pre-
dominantly of named entities. We feel that named
entities are a specific category of nominal expres-
sions best dealt with using techniques which do not
apply to common nouns; for example, they do not
lend themselves well to semantic generalization.
Figure 1 shows two examples of annotated sen-
tences. The XML tags &lt;e1&gt; and &lt;e2&gt; mark the
target nominals. Since all nine proper semantic re-
lations in this task are asymmetric, the ordering of
the two nominals must be taken into account. In
example 1, CAUSE-EFFECT(e1, e2) does not hold,
although CAUSE-EFFECT(e2, e1) would. In exam-
ple 2, COMPONENT-WHOLE(e2, e1) holds.
We are currently developing annotation guide-
lines for each of the relations. They will give a pre-
cise definition for each relation and some prototypi-
cal examples, similarly to SemEval-2007 Task 4.
The annotation will take place in two rounds. In
the first round, we will do a coarse-grained search
</bodyText>
<page confidence="0.999035">
97
</page>
<bodyText confidence="0.999937324324324">
for positive examples for each relation. We will
collect data from the Web using a semi-automatic,
pattern-based search procedure. In order to ensure
a wide variety of example sentences, we will use
several dozen patterns per relation. We will also
ensure that patterns retrieve both positive and nega-
tive example sentences; the latter will help populate
the OTHER relation with realistic near-miss negative
examples of the other relations. The patterns will
be manually constructed following the approach of
Hearst (1992) and Nakov and Hearst (2008).6
The example collection for each relation R will
be passed to two independent annotators. In order to
maintain exclusivity of relations, only examples that
are negative for all relations but R will be included
as positive and only examples that are negative for
all nine relations will be included as OTHER. Next,
the annotators will compare their decisions and as-
sess inter-annotator agreement. Consensus will be
sought; if the annotators cannot agree on an exam-
ple it will not be included in the data set, but it will
be recorded for future analysis.
Finally, two other task organizers will look for
overlap across all relations. They will discard any
example marked as positive in two or more relations,
as well as examples in OTHER marked as positive in
any of the other classes. The OTHER relation will,
then, consist of examples that are negatives for all
other relations and near-misses for any relation.
Data sets. The annotated data will be divided into
a training set, a development set and a test set. There
will be 1000 annotated examples for each of the
ten relations: 700 for training, 100 for development
and 200 for testing. All data will be released under
the Creative Commons Attribution 3.0 Unported Li-
cense7. The annotation guidelines will be included
in the distribution.
</bodyText>
<sectionHeader confidence="0.981899" genericHeader="method">
5 The Classification Task
</sectionHeader>
<bodyText confidence="0.9999684">
The actual task that we will run at SemEval-2010
will be a multi-way classification task. Not all pairs
of nominals in each sentence will be labeled, so the
gold-standard boundaries of the nominals to be clas-
sified will be provided as part of the test data.
</bodyText>
<footnote confidence="0.9521075">
6Note that, unlike in Semeval 2007 Task 4, we will not re-
lease the patterns to the participants.
7http://creativecommons.org/licenses/by/
3.0/
</footnote>
<bodyText confidence="0.999883708333333">
In contrast with Semeval 2007 Task 4, in which
the ordering of the entities was provided with each
example, we aim at a more realistic scenario in
which the ordering of the labels is not given. Par-
ticipants in the task will be asked to discover both
the relation and the order of the arguments. Thus,
the more challenging task is to identify the most
informative ordering and relation between a pair
of nominals. The stipulation “most informative”
is necessary since with our current set of asym-
metrical relations that includes OTHER, each pair
of nominals that instantiates a relation in one di-
rection (e.g., REL(e1, e2)), instantiates OTHER in
the inverse direction (OTHER (e2, e1)). Thus, the
correct answers for the two examples in Figure 1
are CAUSE-EFFECT (earthquake, aftershocks) and
COMPONENT-WHOLE (large kitchen, apartment).
Note that unlike in SemEval-2007 Task 4, we will
not provide manually annotated WordNet senses,
thus making the task more realistic. WordNet senses
did, however, serve for disambiguation purposes in
SemEval-2007 Task 4. We will therefore have to
assess the effect of this change on inter-annotator
agreement.
</bodyText>
<sectionHeader confidence="0.99813" genericHeader="evaluation">
6 Evaluation Methodology
</sectionHeader>
<bodyText confidence="0.999990222222222">
The official ranking of the participating systems will
be based on their macro-averaged F-scores for the
nine proper relations. We will also compute and re-
port their accuracy over all ten relations, including
OTHER. We will further analyze the results quan-
titatively and qualitatively to gauge which relations
are most difficult to classify.
Similarly to SemEval-2007 Task 4, in order to
assess the effect of varying quantities of training
data, we will ask the teams to submit several sets of
guesses for the labels for the test data, using varying
fractions of the training data. We may, for example,
request test results when training on the first 50, 100,
200, 400 and all 700 examples from each relation.
We will provide a Perl-based automatic evalua-
tion tool that the participants can use when train-
ing/tuning/testing their systems. We will use the
same tool for the official evaluation.
</bodyText>
<sectionHeader confidence="0.99826" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.984139">
We have introduced a new task, which will be part of
SemEval-2010: multi-way classification of semantic
</bodyText>
<page confidence="0.989593">
98
</page>
<bodyText confidence="0.999934545454546">
relations between pairs of common nominals. The
task will compare different approaches to the prob-
lem and provide a standard testbed for future re-
search, which can benefit many NLP applications.
The description we have presented here should
be considered preliminary. We invite the in-
terested reader to visit the official task web-
sitehttp://semeval2.fbk.eu/semeval2.
php?location=tasks\#T11, where up-to-
date information will be published; there is also a
discussion group and a mailing list.
</bodyText>
<sectionHeader confidence="0.998308" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999736483516483">
Timothy Chklovski and Patrick Pantel. 2004. VerbO-
cean: Mining the web for fine-grained semantic verb
relations. In Proc. EMNLP 2004, pages 33–40.
Dmitry Davidov and Ari Rappoport. 2008. Classifica-
tion of semantic relationships between nominals using
pattern clusters. In Proc. ACL-08: HLT, pages 227–
235.
Charles J. Fillmore, Christopher R. Johnson, and
Miriam R.L. Petruck. 2003. Background to
FrameNet. International Journal of Lexicography,
16:235–250.
Charles J. Fillmore. 2002. FrameNet and the linking be-
tween semantic and syntactic relations. In Proc. COL-
ING 2002, pages 28–36.
Daniel Gildea and Daniel Jurafsky. 2002. Automatic la-
beling of semantic roles. Computational Linguistics,
28(3):245–288.
Roxana Girju, Dan Moldovan, Marta Tatu, , and Dan An-
tohe. 2005. On the semantics of noun compounds.
Computer Speech and Language, 19:479–496.
Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-
pakowicz, Peter Turney, and Deniz Yuret. 2007.
SemEval-2007 task 04: Classification of semantic re-
lations between nominals. In Proc. 4th Semantic Eval-
uation Workshop (SemEval-2007).
Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Sz-
pakowicz, Peter Turney, and Deniz Yuret. 2008.
Classification of semantic relations between nominals.
Language Resources and Evaluation. In print.
Marti A. Hearst. 1992. Automatic acquisition of hy-
ponyms from large text corpora. In Proc. COLING
92, pages 539–545.
Sophia Katrenko and Pieter Adriaans. 2008. Semantic
types of some generic relation arguments: Detection
and evaluation. In Proc. ACL-08: HLT, Short Papers,
pages 185–188.
Su Nam Kim and Timothy Baldwin. 2005. Automatic
interpretation of noun compounds using WordNet sim-
ilarity. In Proc. IJCAI, pages 945–956.
George Lakoff. 1987. Women, fire, and dangerous
things. University of Chicago Press, Chicago, IL.
Maria Lapata. 2002. The disambiguation of nominalisa-
tions. Computational Linguistics, 28:357–388.
Dan Moldovan, Adriana Badulescu, Marta Tatu, Daniel
Antohe, and Roxana Girju. 2004. Models for the se-
mantic classification of noun phrases. In HLT-NAACL
2004: Workshop on Computational Lexical Semantics,
pages 60–67.
Preslav Nakov and Marti A. Hearst. 2008. Solving rela-
tional similarity problems using the web as a corpus.
In Proc. ACL-08: HLT, pages 452–460.
Vivi Nastase and Stan Szpakowicz. 2003. Exploring
noun-modifier semantic relations. In Fifth Interna-
tional Workshop on Computational Semantics (IWCS-
5), pages 285–301.
Vivi Nastase, Jelber Sayyad-Shirabad, Marina Sokolova,
and Stan Szpakowicz. 2006. Learning noun-modifier
semantic relations with corpus-based and WordNet-
based features. In Proc. AAAI, pages 781–787.
Diarmuid O´ S´eaghdha and Ann Copestake. 2008. Se-
mantic classification with distributional kernels. In
Proc. COLING 2008, pages 649–656.
Martha Palmer, Dan Gildea, and Paul Kingsbury. 2005.
The Proposition Bank: An annotated corpus of seman-
tic roles. Computational Linguistics, 31(1):71–106.
Patrick Pantel and Marco Pennacchiotti. 2006. Espresso:
Leveraging generic patterns for automatically harvest-
ing semantic relations. In Proc. COLING/ACL, pages
113–120.
Siddharth Patwardhan and Ellen Riloff. 2007. Effective
information extraction with semantic affinity patterns
and relevant regions. In Proc. EMNLP-CoNLL), pages
717–727.
Barbara Rosario and Marti Hearst. 2001. Classifying the
semantic relations in noun compounds via a domain-
specific lexical hierarchy. In Proc. EMNLP 2001,
pages 82–90.
Barbara Rosario, Marti Hearst, and Charles Fillmore.
2002. The descent of hierarchy, and selection in re-
lational semantics. In Proc. ACL-02, pages 247–254.
Matthew Stephens, Mathew Palakal, Snehasis
Mukhopadhyay, Rajeev Raje, and Javed Mostafa.
2001. Detecting gene relations from Medline ab-
stracts. In Pacific Symposium on Biocomputing, pages
483–495.
Peter D. Turney and Michael L. Littman. 2005. Corpus-
based learning of analogies and semantic relations.
Machine Learning, 60(1-3):251–278.
Peter D. Turney. 2005. Measuring semantic similarity by
latent relational analysis. In Proc. IJCAI, pages 1136–
1141.
</reference>
<page confidence="0.998969">
99
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.204805">
<title confidence="0.73997175">SemEval-2010 Task 8: Multi-Way of Semantic Relations Between Pairs of Nominals Su Nam Zornitsa Preslav O´Sebastian Marco</title>
<author confidence="0.933462">Stan</author>
<abstract confidence="0.962576">We present a brief overview of the main challenges in the extraction of semantic relations from English text, and discuss the shortcomings of previous data sets and shared tasks. This leads us to introduce a new task, which will be part of SemEval-2010: multi-way classification of mutually exclusive semantic relations between pairs of common nominals. The task is designed to compare different approaches to the problem and to provide a standard testbed for future research, which can benefit many applications in Natural Language Processing.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Chklovski</author>
<author>Patrick Pantel</author>
</authors>
<title>VerbOcean: Mining the web for fine-grained semantic verb relations.</title>
<date>2004</date>
<booktitle>In Proc. EMNLP</booktitle>
<pages>33--40</pages>
<contexts>
<context position="14167" citStr="Chklovski and Pantel, 2004" startWordPosition="2209" endWordPosition="2212"> unrelated semantic roles. There is a rudimentary frame hierarchy that defines mappings between roles of individual frames,5 but it is far from complete. The situation is similar in PropBank. PropBank does use a small number of semantic roles, but these are again to be interpreted at the level of individual predicates, with little cross-predicate generalization. In contrast, all of the semantic relation inventories discussed in Section 1 contain fewer than 50 types of semantic relations. More generally, semantic relation inventories attempt to generalize relations across wide groups of verbs (Chklovski and Pantel, 2004) and include relations that are not verbcentered (Nastase and Szpakowicz, 2003; Moldovan et al., 2004). Using the same labels for similar semantic relations facilitates supervised learning. For example, a model trained with examples of sell relations should be able to transfer what it has learned to give relations. This has the potential of adding 5For example, it relates the BUYER role of the COMMERCE SELL frame (verb sell) to the RECIPIENT role of the GIVING frame (verb give). 1. People in Hawaii might be feeling &lt;e1&gt;aftershocks&lt;/e1&gt; from that powerful &lt;e2&gt;earthquake&lt;/e2&gt; for weeks. 2. My ne</context>
</contexts>
<marker>Chklovski, Pantel, 2004</marker>
<rawString>Timothy Chklovski and Patrick Pantel. 2004. VerbOcean: Mining the web for fine-grained semantic verb relations. In Proc. EMNLP 2004, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dmitry Davidov</author>
<author>Ari Rappoport</author>
</authors>
<title>Classification of semantic relationships between nominals using pattern clusters.</title>
<date>2008</date>
<booktitle>In Proc. ACL-08: HLT,</booktitle>
<pages>227--235</pages>
<contexts>
<context position="7484" citStr="Davidov and Rappoport, 2008" startWordPosition="1162" endWordPosition="1165">tical NLP settings, where any relation can hold between a pair of nominals which occur in a sentence or a discourse. 2.4 Summary While there is a substantial amount of work on relation extraction, the lack of standardization makes it difficult to compare different approaches. It is known from other fields that the availability of standard benchmark data sets can provide a boost to the advancement of a field. As a first step, SemEval2007 Task 4 offered many useful insights into the performance of different approaches to semantic relation classification; it has also motivated followup research (Davidov and Rappoport, 2008; Katrenko and Adriaans, 2008; Nakov and Hearst, 2008; O´ S´eaghdha and Copestake, 2008). Our objective is to build on the achievements of SemEval-2007 Task 4 while addressing its shortcomings. In particular, we consider a larger set of semantic relations (9 instead of 7), we assume a proper multi-class classification setting, we emulate the effect of an “open” relation inventory by means of a tenth class OTHER, and we will release to the research community a data set with a considerably 1http://www.itl.nist.gov/iad/mig/tests/ ace/ 2Although it was not designed for a multi-class set-up, some s</context>
</contexts>
<marker>Davidov, Rappoport, 2008</marker>
<rawString>Dmitry Davidov and Ari Rappoport. 2008. Classification of semantic relationships between nominals using pattern clusters. In Proc. ACL-08: HLT, pages 227– 235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
<author>Christopher R Johnson</author>
<author>Miriam R L Petruck</author>
</authors>
<title>Background to FrameNet.</title>
<date>2003</date>
<journal>International Journal of Lexicography,</journal>
<pages>16--235</pages>
<marker>Fillmore, Johnson, Petruck, 2003</marker>
<rawString>Charles J. Fillmore, Christopher R. Johnson, and Miriam R.L. Petruck. 2003. Background to FrameNet. International Journal of Lexicography, 16:235–250.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Charles J Fillmore</author>
</authors>
<title>FrameNet and the linking between semantic and syntactic relations.</title>
<date>2002</date>
<booktitle>In Proc. COLING</booktitle>
<pages>28--36</pages>
<contexts>
<context position="13099" citStr="Fillmore, 2002" startWordPosition="2039" endWordPosition="2041"> semantic relations may occur between all parts of speech, although we limit our attention to nominals in this task. Also, semantic role descriptions typically relate an event to a set of multiple participants and props, while semantic relations are in practice (although not necessarily) binary. The second major difference is the syntactic context. Theories of semantic roles usually developed out of syntactic descriptions of verb valencies, and thus they focus on describing the linking patterns of verbs and their direct dependents, phenomena like raising and noninstantiations notwithstanding (Fillmore, 2002). Semantic relations are not tied to predicate-argument structures. They can also be established within noun phrases, noun compounds, or sentences more generally (cf. the examples above). The third difference is that of the level of generalization. FrameNet currently contains more than 825 different frames (event classes). Since the semantic roles are designed to be interpreted at the frame level, there is a priori a very large number of unrelated semantic roles. There is a rudimentary frame hierarchy that defines mappings between roles of individual frames,5 but it is far from complete. The s</context>
</contexts>
<marker>Fillmore, 2002</marker>
<rawString>Charles J. Fillmore. 2002. FrameNet and the linking between semantic and syntactic relations. In Proc. COLING 2002, pages 28–36.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Gildea</author>
<author>Daniel Jurafsky</author>
</authors>
<title>Automatic labeling of semantic roles.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<volume>28</volume>
<issue>3</issue>
<contexts>
<context position="12071" citStr="Gildea and Jurafsky, 2002" startWordPosition="1881" endWordPosition="1884">This is motivated by modelling considerations. Presumably, the data for OTHER will be very nonhomogeneous. By including it, we force any model of the complete data set to correctly identify the decision boundaries between the individual relations and “everything else”. This encourages good generalization behaviour to larger, noisier data sets commonly seen in real-world applications. 3.1 Semantic Relations versus Semantic Roles There are three main differences between our task (classification of semantic relations between nominals) and the related task of automatic labeling of semantic roles (Gildea and Jurafsky, 2002). The first difference is to do with the linguistic phenomena described. Lexical resources for theories of semantic roles such as FrameNet (Fillmore et 96 al., 2003) and PropBank (Palmer et al., 2005) have been developed to describe the linguistic realization patterns of events and states. Thus, they target primarily verbs (or event nominalizations) and their dependents, which are typically nouns. In contrast, semantic relations may occur between all parts of speech, although we limit our attention to nominals in this task. Also, semantic role descriptions typically relate an event to a set of</context>
</contexts>
<marker>Gildea, Jurafsky, 2002</marker>
<rawString>Daniel Gildea and Daniel Jurafsky. 2002. Automatic labeling of semantic roles. Computational Linguistics, 28(3):245–288.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Dan Moldovan</author>
<author>Marta Tatu</author>
</authors>
<title>On the semantics of noun compounds. Computer Speech and Language,</title>
<date>2005</date>
<contexts>
<context position="5093" citStr="Girju et al., 2005" startWordPosition="765" endWordPosition="768"> specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relation classification is whether the relations between nominals should be considered out of context or in context. When one looks at real data, it becomes clear that context does indeed play a role. Consider, for example, the noun compound wood shed: it may refer either to a shed made of wood, or to a shed of any mate</context>
</contexts>
<marker>Girju, Moldovan, Tatu, 2005</marker>
<rawString>Roxana Girju, Dan Moldovan, Marta Tatu, , and Dan Antohe. 2005. On the semantics of noun compounds. Computer Speech and Language, 19:479–496.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Preslav Nakov</author>
<author>Vivi Nastase</author>
<author>Stan Szpakowicz</author>
<author>Peter Turney</author>
<author>Deniz Yuret</author>
</authors>
<title>SemEval-2007 task 04: Classification of semantic relations between nominals.</title>
<date>2007</date>
<booktitle>In Proc. 4th Semantic Evaluation Workshop (SemEval-2007).</booktitle>
<contexts>
<context position="6291" citStr="Girju et al., 2007" startWordPosition="963" endWordPosition="966">o a shed of any material used to store wood. This ambiguity is likely to be resolved in particular contexts. In fact, most NLP applications will want to determine not all possible relations between two words, but rather the relation between two instances in a particular context. While the integration of context is common in the field of IE (cf. work in the context of ACE1), much of the existing literature on relation extraction considers word pairs out of context (thus, types rather than tokens). A notable exception is SemEval-2007 Task 4 Classification of Semantic Relations between Nominals (Girju et al., 2007; Girju et al., 2008), the first to offer a standard benchmark data set for seven semantic relations between common nouns in context. 2.3 Style of Classification The design of SemEval-2007 Task 4 had an important limitation. The data set avoided the challenge of defining a single unified standard classification scheme by creating seven separate training and test sets, one for each semantic relation. That made the relation recognition task on each data set a simple binary (positive / negative) classification task.2 Clearly, this does not easily transfer to practical NLP settings, where any rela</context>
</contexts>
<marker>Girju, Nakov, Nastase, Szpakowicz, Turney, Yuret, 2007</marker>
<rawString>Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Szpakowicz, Peter Turney, and Deniz Yuret. 2007. SemEval-2007 task 04: Classification of semantic relations between nominals. In Proc. 4th Semantic Evaluation Workshop (SemEval-2007).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Roxana Girju</author>
<author>Preslav Nakov</author>
<author>Vivi Nastase</author>
<author>Stan Szpakowicz</author>
<author>Peter Turney</author>
<author>Deniz Yuret</author>
</authors>
<title>Classification of semantic relations between nominals. Language Resources and Evaluation. In print.</title>
<date>2008</date>
<contexts>
<context position="6312" citStr="Girju et al., 2008" startWordPosition="967" endWordPosition="970">rial used to store wood. This ambiguity is likely to be resolved in particular contexts. In fact, most NLP applications will want to determine not all possible relations between two words, but rather the relation between two instances in a particular context. While the integration of context is common in the field of IE (cf. work in the context of ACE1), much of the existing literature on relation extraction considers word pairs out of context (thus, types rather than tokens). A notable exception is SemEval-2007 Task 4 Classification of Semantic Relations between Nominals (Girju et al., 2007; Girju et al., 2008), the first to offer a standard benchmark data set for seven semantic relations between common nouns in context. 2.3 Style of Classification The design of SemEval-2007 Task 4 had an important limitation. The data set avoided the challenge of defining a single unified standard classification scheme by creating seven separate training and test sets, one for each semantic relation. That made the relation recognition task on each data set a simple binary (positive / negative) classification task.2 Clearly, this does not easily transfer to practical NLP settings, where any relation can hold between</context>
</contexts>
<marker>Girju, Nakov, Nastase, Szpakowicz, Turney, Yuret, 2008</marker>
<rawString>Roxana Girju, Preslav Nakov, Vivi Nastase, Stan Szpakowicz, Peter Turney, and Deniz Yuret. 2008. Classification of semantic relations between nominals. Language Resources and Evaluation. In print.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marti A Hearst</author>
</authors>
<title>Automatic acquisition of hyponyms from large text corpora.</title>
<date>1992</date>
<booktitle>In Proc. COLING 92,</booktitle>
<pages>539--545</pages>
<contexts>
<context position="17273" citStr="Hearst (1992)" startWordPosition="2715" endWordPosition="2716">n will take place in two rounds. In the first round, we will do a coarse-grained search 97 for positive examples for each relation. We will collect data from the Web using a semi-automatic, pattern-based search procedure. In order to ensure a wide variety of example sentences, we will use several dozen patterns per relation. We will also ensure that patterns retrieve both positive and negative example sentences; the latter will help populate the OTHER relation with realistic near-miss negative examples of the other relations. The patterns will be manually constructed following the approach of Hearst (1992) and Nakov and Hearst (2008).6 The example collection for each relation R will be passed to two independent annotators. In order to maintain exclusivity of relations, only examples that are negative for all relations but R will be included as positive and only examples that are negative for all nine relations will be included as OTHER. Next, the annotators will compare their decisions and assess inter-annotator agreement. Consensus will be sought; if the annotators cannot agree on an example it will not be included in the data set, but it will be recorded for future analysis. Finally, two othe</context>
</contexts>
<marker>Hearst, 1992</marker>
<rawString>Marti A. Hearst. 1992. Automatic acquisition of hyponyms from large text corpora. In Proc. COLING 92, pages 539–545.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sophia Katrenko</author>
<author>Pieter Adriaans</author>
</authors>
<title>Semantic types of some generic relation arguments: Detection and evaluation.</title>
<date>2008</date>
<booktitle>In Proc. ACL-08: HLT, Short Papers,</booktitle>
<pages>185--188</pages>
<contexts>
<context position="7513" citStr="Katrenko and Adriaans, 2008" startWordPosition="1166" endWordPosition="1170"> relation can hold between a pair of nominals which occur in a sentence or a discourse. 2.4 Summary While there is a substantial amount of work on relation extraction, the lack of standardization makes it difficult to compare different approaches. It is known from other fields that the availability of standard benchmark data sets can provide a boost to the advancement of a field. As a first step, SemEval2007 Task 4 offered many useful insights into the performance of different approaches to semantic relation classification; it has also motivated followup research (Davidov and Rappoport, 2008; Katrenko and Adriaans, 2008; Nakov and Hearst, 2008; O´ S´eaghdha and Copestake, 2008). Our objective is to build on the achievements of SemEval-2007 Task 4 while addressing its shortcomings. In particular, we consider a larger set of semantic relations (9 instead of 7), we assume a proper multi-class classification setting, we emulate the effect of an “open” relation inventory by means of a tenth class OTHER, and we will release to the research community a data set with a considerably 1http://www.itl.nist.gov/iad/mig/tests/ ace/ 2Although it was not designed for a multi-class set-up, some subsequent publications tried </context>
</contexts>
<marker>Katrenko, Adriaans, 2008</marker>
<rawString>Sophia Katrenko and Pieter Adriaans. 2008. Semantic types of some generic relation arguments: Detection and evaluation. In Proc. ACL-08: HLT, Short Papers, pages 185–188.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Timothy Baldwin</author>
</authors>
<title>Automatic interpretation of noun compounds using WordNet similarity.</title>
<date>2005</date>
<booktitle>In Proc. IJCAI,</booktitle>
<pages>945--956</pages>
<contexts>
<context position="4777" citStr="Kim and Baldwin, 2005" startWordPosition="711" endWordPosition="715">nds from the domain of medicine into 13 classes that describe the semantic relation between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relat</context>
</contexts>
<marker>Kim, Baldwin, 2005</marker>
<rawString>Su Nam Kim and Timothy Baldwin. 2005. Automatic interpretation of noun compounds using WordNet similarity. In Proc. IJCAI, pages 945–956.</rawString>
</citation>
<citation valid="true">
<authors>
<author>George Lakoff</author>
</authors>
<title>Women, fire, and dangerous things.</title>
<date>1987</date>
<publisher>University of Chicago Press,</publisher>
<location>Chicago, IL.</location>
<contexts>
<context position="9230" citStr="Lakoff, 1987" startWordPosition="1443" endWordPosition="1444">nals) and mutually exclusive (each pair of nominals in context should map onto only one relation). The literature, however, suggests no such inventory that could satisfy all needs. In practice, one always must decide on a trade-off between these two properties. For example, the gene-gene relation inventory of Stephens et al. (2001), with relations like X phosphorylates Y, arguably allows no overlaps, but is too specific for applications to general text. On the other hand, schemes aimed at exhaustiveness tend to run into overlap issues, due to such fundamental linguistic phenomena as metaphor (Lakoff, 1987). For example, in the sentence Dark clouds gather over Nepal., the relation between dark clouds and Nepal is literally a type of ENTITY-DESTINATION, but in fact it refers to the ethnic unrest in Nepal. We seek a pragmatic compromise between the two extremes. We have selected nine relations with sufficiently broad coverage to be of general and practical interest. We aim at avoiding “real” overlap to the extent that this is possible, but we include two sets of similar relations (ENTITY-ORIGIN/ENTITYDESTINATION and CONTENT-CONTAINER/COMPONENT-WHOLE/MEMBER-COLLECTION), which can help assess the mo</context>
</contexts>
<marker>Lakoff, 1987</marker>
<rawString>George Lakoff. 1987. Women, fire, and dangerous things. University of Chicago Press, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Maria Lapata</author>
</authors>
<title>The disambiguation of nominalisations.</title>
<date>2002</date>
<journal>Computational Linguistics,</journal>
<pages>28--357</pages>
<contexts>
<context position="5108" citStr="Lapata (2002)" startWordPosition="769" endWordPosition="770">geting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relation classification is whether the relations between nominals should be considered out of context or in context. When one looks at real data, it becomes clear that context does indeed play a role. Consider, for example, the noun compound wood shed: it may refer either to a shed made of wood, or to a shed of any material used to st</context>
</contexts>
<marker>Lapata, 2002</marker>
<rawString>Maria Lapata. 2002. The disambiguation of nominalisations. Computational Linguistics, 28:357–388.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Moldovan</author>
<author>Adriana Badulescu</author>
<author>Marta Tatu</author>
<author>Daniel Antohe</author>
<author>Roxana Girju</author>
</authors>
<title>Models for the semantic classification of noun phrases.</title>
<date>2004</date>
<booktitle>In HLT-NAACL 2004: Workshop on Computational Lexical Semantics,</booktitle>
<pages>60--67</pages>
<contexts>
<context position="4930" citStr="Moldovan et al. (2004)" startWordPosition="738" endWordPosition="741">fy noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relation classification is whether the relations between nominals should be considered out of context or in context. When one looks at real data, it becomes c</context>
<context position="14269" citStr="Moldovan et al., 2004" startWordPosition="2225" endWordPosition="2228">dividual frames,5 but it is far from complete. The situation is similar in PropBank. PropBank does use a small number of semantic roles, but these are again to be interpreted at the level of individual predicates, with little cross-predicate generalization. In contrast, all of the semantic relation inventories discussed in Section 1 contain fewer than 50 types of semantic relations. More generally, semantic relation inventories attempt to generalize relations across wide groups of verbs (Chklovski and Pantel, 2004) and include relations that are not verbcentered (Nastase and Szpakowicz, 2003; Moldovan et al., 2004). Using the same labels for similar semantic relations facilitates supervised learning. For example, a model trained with examples of sell relations should be able to transfer what it has learned to give relations. This has the potential of adding 5For example, it relates the BUYER role of the COMMERCE SELL frame (verb sell) to the RECIPIENT role of the GIVING frame (verb give). 1. People in Hawaii might be feeling &lt;e1&gt;aftershocks&lt;/e1&gt; from that powerful &lt;e2&gt;earthquake&lt;/e2&gt; for weeks. 2. My new &lt;e1&gt;apartment&lt;/e1&gt; has a &lt;e2&gt;large kitchen&lt;/e2&gt;. Figure 1: Two example sentences with annotation cru</context>
</contexts>
<marker>Moldovan, Badulescu, Tatu, Antohe, Girju, 2004</marker>
<rawString>Dan Moldovan, Adriana Badulescu, Marta Tatu, Daniel Antohe, and Roxana Girju. 2004. Models for the semantic classification of noun phrases. In HLT-NAACL 2004: Workshop on Computational Lexical Semantics, pages 60–67.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Preslav Nakov</author>
<author>Marti A Hearst</author>
</authors>
<title>Solving relational similarity problems using the web as a corpus.</title>
<date>2008</date>
<booktitle>In Proc. ACL-08: HLT,</booktitle>
<pages>452--460</pages>
<contexts>
<context position="4801" citStr="Nakov and Hearst, 2008" startWordPosition="716" endWordPosition="719">medicine into 13 classes that describe the semantic relation between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relation classification is wh</context>
<context position="7537" citStr="Nakov and Hearst, 2008" startWordPosition="1171" endWordPosition="1174">pair of nominals which occur in a sentence or a discourse. 2.4 Summary While there is a substantial amount of work on relation extraction, the lack of standardization makes it difficult to compare different approaches. It is known from other fields that the availability of standard benchmark data sets can provide a boost to the advancement of a field. As a first step, SemEval2007 Task 4 offered many useful insights into the performance of different approaches to semantic relation classification; it has also motivated followup research (Davidov and Rappoport, 2008; Katrenko and Adriaans, 2008; Nakov and Hearst, 2008; O´ S´eaghdha and Copestake, 2008). Our objective is to build on the achievements of SemEval-2007 Task 4 while addressing its shortcomings. In particular, we consider a larger set of semantic relations (9 instead of 7), we assume a proper multi-class classification setting, we emulate the effect of an “open” relation inventory by means of a tenth class OTHER, and we will release to the research community a data set with a considerably 1http://www.itl.nist.gov/iad/mig/tests/ ace/ 2Although it was not designed for a multi-class set-up, some subsequent publications tried to use the data sets in </context>
<context position="17301" citStr="Nakov and Hearst (2008)" startWordPosition="2718" endWordPosition="2721">in two rounds. In the first round, we will do a coarse-grained search 97 for positive examples for each relation. We will collect data from the Web using a semi-automatic, pattern-based search procedure. In order to ensure a wide variety of example sentences, we will use several dozen patterns per relation. We will also ensure that patterns retrieve both positive and negative example sentences; the latter will help populate the OTHER relation with realistic near-miss negative examples of the other relations. The patterns will be manually constructed following the approach of Hearst (1992) and Nakov and Hearst (2008).6 The example collection for each relation R will be passed to two independent annotators. In order to maintain exclusivity of relations, only examples that are negative for all relations but R will be included as positive and only examples that are negative for all nine relations will be included as OTHER. Next, the annotators will compare their decisions and assess inter-annotator agreement. Consensus will be sought; if the annotators cannot agree on an example it will not be included in the data set, but it will be recorded for future analysis. Finally, two other task organizers will look </context>
</contexts>
<marker>Nakov, Hearst, 2008</marker>
<rawString>Preslav Nakov and Marti A. Hearst. 2008. Solving relational similarity problems using the web as a corpus. In Proc. ACL-08: HLT, pages 452–460.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Exploring noun-modifier semantic relations.</title>
<date>2003</date>
<booktitle>In Fifth International Workshop on Computational Semantics (IWCS5),</booktitle>
<pages>285--301</pages>
<contexts>
<context position="4556" citStr="Nastase and Szpakowicz (2003)" startWordPosition="673" endWordPosition="676">nvestigate relations between named entities or internal to noun-noun compounds, while others have a more general focus. Some schemes are specific to a domain such as biomedical text. Rosario and Hearst (2001) classify noun compounds from the domain of medicine into 13 classes that describe the semantic relation between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations i</context>
<context position="14245" citStr="Nastase and Szpakowicz, 2003" startWordPosition="2221" endWordPosition="2224">s mappings between roles of individual frames,5 but it is far from complete. The situation is similar in PropBank. PropBank does use a small number of semantic roles, but these are again to be interpreted at the level of individual predicates, with little cross-predicate generalization. In contrast, all of the semantic relation inventories discussed in Section 1 contain fewer than 50 types of semantic relations. More generally, semantic relation inventories attempt to generalize relations across wide groups of verbs (Chklovski and Pantel, 2004) and include relations that are not verbcentered (Nastase and Szpakowicz, 2003; Moldovan et al., 2004). Using the same labels for similar semantic relations facilitates supervised learning. For example, a model trained with examples of sell relations should be able to transfer what it has learned to give relations. This has the potential of adding 5For example, it relates the BUYER role of the COMMERCE SELL frame (verb sell) to the RECIPIENT role of the GIVING frame (verb give). 1. People in Hawaii might be feeling &lt;e1&gt;aftershocks&lt;/e1&gt; from that powerful &lt;e2&gt;earthquake&lt;/e2&gt; for weeks. 2. My new &lt;e1&gt;apartment&lt;/e1&gt; has a &lt;e2&gt;large kitchen&lt;/e2&gt;. Figure 1: Two example sente</context>
</contexts>
<marker>Nastase, Szpakowicz, 2003</marker>
<rawString>Vivi Nastase and Stan Szpakowicz. 2003. Exploring noun-modifier semantic relations. In Fifth International Workshop on Computational Semantics (IWCS5), pages 285–301.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Vivi Nastase</author>
<author>Jelber Sayyad-Shirabad</author>
<author>Marina Sokolova</author>
<author>Stan Szpakowicz</author>
</authors>
<title>Learning noun-modifier semantic relations with corpus-based and WordNetbased features.</title>
<date>2006</date>
<booktitle>In Proc. AAAI,</booktitle>
<pages>781--787</pages>
<contexts>
<context position="4823" citStr="Nastase et al., 2006" startWordPosition="720" endWordPosition="723"> that describe the semantic relation between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relation classification is whether the relations be</context>
</contexts>
<marker>Nastase, Sayyad-Shirabad, Sokolova, Szpakowicz, 2006</marker>
<rawString>Vivi Nastase, Jelber Sayyad-Shirabad, Marina Sokolova, and Stan Szpakowicz. 2006. Learning noun-modifier semantic relations with corpus-based and WordNetbased features. In Proc. AAAI, pages 781–787.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diarmuid O´ S´eaghdha</author>
<author>Ann Copestake</author>
</authors>
<title>Semantic classification with distributional kernels.</title>
<date>2008</date>
<booktitle>In Proc. COLING</booktitle>
<pages>649--656</pages>
<marker>S´eaghdha, Copestake, 2008</marker>
<rawString>Diarmuid O´ S´eaghdha and Ann Copestake. 2008. Semantic classification with distributional kernels. In Proc. COLING 2008, pages 649–656.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Martha Palmer</author>
<author>Dan Gildea</author>
<author>Paul Kingsbury</author>
</authors>
<title>The Proposition Bank: An annotated corpus of semantic roles.</title>
<date>2005</date>
<journal>Computational Linguistics,</journal>
<volume>31</volume>
<issue>1</issue>
<contexts>
<context position="12271" citStr="Palmer et al., 2005" startWordPosition="1914" endWordPosition="1917">ndaries between the individual relations and “everything else”. This encourages good generalization behaviour to larger, noisier data sets commonly seen in real-world applications. 3.1 Semantic Relations versus Semantic Roles There are three main differences between our task (classification of semantic relations between nominals) and the related task of automatic labeling of semantic roles (Gildea and Jurafsky, 2002). The first difference is to do with the linguistic phenomena described. Lexical resources for theories of semantic roles such as FrameNet (Fillmore et 96 al., 2003) and PropBank (Palmer et al., 2005) have been developed to describe the linguistic realization patterns of events and states. Thus, they target primarily verbs (or event nominalizations) and their dependents, which are typically nouns. In contrast, semantic relations may occur between all parts of speech, although we limit our attention to nominals in this task. Also, semantic role descriptions typically relate an event to a set of multiple participants and props, while semantic relations are in practice (although not necessarily) binary. The second major difference is the syntactic context. Theories of semantic roles usually d</context>
</contexts>
<marker>Palmer, Gildea, Kingsbury, 2005</marker>
<rawString>Martha Palmer, Dan Gildea, and Paul Kingsbury. 2005. The Proposition Bank: An annotated corpus of semantic roles. Computational Linguistics, 31(1):71–106.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Patrick Pantel</author>
<author>Marco Pennacchiotti</author>
</authors>
<title>Espresso: Leveraging generic patterns for automatically harvesting semantic relations.</title>
<date>2006</date>
<booktitle>In Proc. COLING/ACL,</booktitle>
<pages>113--120</pages>
<contexts>
<context position="5206" citStr="Pantel and Pennacchiotti (2006)" startWordPosition="779" endWordPosition="782">m of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relation classification is whether the relations between nominals should be considered out of context or in context. When one looks at real data, it becomes clear that context does indeed play a role. Consider, for example, the noun compound wood shed: it may refer either to a shed made of wood, or to a shed of any material used to store wood. This ambiguity is likely to be resolved in particular contexts. In fact, most NLP applic</context>
</contexts>
<marker>Pantel, Pennacchiotti, 2006</marker>
<rawString>Patrick Pantel and Marco Pennacchiotti. 2006. Espresso: Leveraging generic patterns for automatically harvesting semantic relations. In Proc. COLING/ACL, pages 113–120.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Siddharth Patwardhan</author>
<author>Ellen Riloff</author>
</authors>
<title>Effective information extraction with semantic affinity patterns and relevant regions.</title>
<date>2007</date>
<booktitle>In Proc. EMNLP-CoNLL),</booktitle>
<pages>717--727</pages>
<contexts>
<context position="15713" citStr="Patwardhan and Riloff (2007)" startWordPosition="2466" endWordPosition="2469">annotation, we define a nominal as a noun or a base noun phrase. A base noun phrase is a noun and its pre-modifiers (e.g., nouns, adjectives, determiners). We do not include complex noun phrases (e.g., noun phrases with attached prepositional phrases or relative clauses). For example, lawn is a noun, lawn mower is a base noun phrase, and the engine of the lawn mower is a complex noun phrase. We focus on heads that are common nouns. This emphasis distinguishes our task from much work in IE, which focuses on named entities and on considerably more fine-grained relations than we do. For example, Patwardhan and Riloff (2007) identify categories like Terrorist organization as participants in terror-related semantic relations, which consists predominantly of named entities. We feel that named entities are a specific category of nominal expressions best dealt with using techniques which do not apply to common nouns; for example, they do not lend themselves well to semantic generalization. Figure 1 shows two examples of annotated sentences. The XML tags &lt;e1&gt; and &lt;e2&gt; mark the target nominals. Since all nine proper semantic relations in this task are asymmetric, the ordering of the two nominals must be taken into acco</context>
</contexts>
<marker>Patwardhan, Riloff, 2007</marker>
<rawString>Siddharth Patwardhan and Ellen Riloff. 2007. Effective information extraction with semantic affinity patterns and relevant regions. In Proc. EMNLP-CoNLL), pages 717–727.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Rosario</author>
<author>Marti Hearst</author>
</authors>
<title>Classifying the semantic relations in noun compounds via a domainspecific lexical hierarchy.</title>
<date>2001</date>
<booktitle>In Proc. EMNLP</booktitle>
<pages>82--90</pages>
<contexts>
<context position="4135" citStr="Rosario and Hearst (2001)" startWordPosition="605" endWordPosition="608">CL HLT Workshop on Semantic Evaluations: Recent Achievements and Future Directions, pages 94–99, Boulder, Colorado, June 2009. c�2009 Association for Computational Linguistics 2 Semantic Relation Classification: Issues 2.1 Defining the Relation Inventory A wide variety of relation classification schemes exist in the literature, reflecting the needs and granularities of various applications. Some researchers only investigate relations between named entities or internal to noun-noun compounds, while others have a more general focus. Some schemes are specific to a domain such as biomedical text. Rosario and Hearst (2001) classify noun compounds from the domain of medicine into 13 classes that describe the semantic relation between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one</context>
</contexts>
<marker>Rosario, Hearst, 2001</marker>
<rawString>Barbara Rosario and Marti Hearst. 2001. Classifying the semantic relations in noun compounds via a domainspecific lexical hierarchy. In Proc. EMNLP 2001, pages 82–90.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Barbara Rosario</author>
<author>Marti Hearst</author>
<author>Charles Fillmore</author>
</authors>
<title>The descent of hierarchy, and selection in relational semantics.</title>
<date>2002</date>
<booktitle>In Proc. ACL-02,</booktitle>
<pages>247--254</pages>
<contexts>
<context position="4301" citStr="Rosario et al. (2002)" startWordPosition="633" endWordPosition="636">stics 2 Semantic Relation Classification: Issues 2.1 Defining the Relation Inventory A wide variety of relation classification schemes exist in the literature, reflecting the needs and granularities of various applications. Some researchers only investigate relations between named entities or internal to noun-noun compounds, while others have a more general focus. Some schemes are specific to a domain such as biomedical text. Rosario and Hearst (2001) classify noun compounds from the domain of medicine into 13 classes that describe the semantic relation between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and dat</context>
</contexts>
<marker>Rosario, Hearst, Fillmore, 2002</marker>
<rawString>Barbara Rosario, Marti Hearst, and Charles Fillmore. 2002. The descent of hierarchy, and selection in relational semantics. In Proc. ACL-02, pages 247–254.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matthew Stephens</author>
<author>Mathew Palakal</author>
<author>Snehasis Mukhopadhyay</author>
<author>Rajeev Raje</author>
<author>Javed Mostafa</author>
</authors>
<title>Detecting gene relations from Medline abstracts.</title>
<date>2001</date>
<booktitle>In Pacific Symposium on Biocomputing,</booktitle>
<pages>483--495</pages>
<contexts>
<context position="4458" citStr="Stephens et al. (2001)" startWordPosition="658" endWordPosition="661">re, reflecting the needs and granularities of various applications. Some researchers only investigate relations between named entities or internal to noun-noun compounds, while others have a more general focus. Some schemes are specific to a domain such as biomedical text. Rosario and Hearst (2001) classify noun compounds from the domain of medicine into 13 classes that describe the semantic relation between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and othe</context>
<context position="8950" citStr="Stephens et al. (2001)" startWordPosition="1397" endWordPosition="1400">ing systems. 3 Designing an Inventory of Semantic Relations Between Nominals We begin by considering the first of the problems listed above: defining of an inventory of semantic relations. Ideally, it should be exhaustive (should allow the description of relations between any pair of nominals) and mutually exclusive (each pair of nominals in context should map onto only one relation). The literature, however, suggests no such inventory that could satisfy all needs. In practice, one always must decide on a trade-off between these two properties. For example, the gene-gene relation inventory of Stephens et al. (2001), with relations like X phosphorylates Y, arguably allows no overlaps, but is too specific for applications to general text. On the other hand, schemes aimed at exhaustiveness tend to run into overlap issues, due to such fundamental linguistic phenomena as metaphor (Lakoff, 1987). For example, in the sentence Dark clouds gather over Nepal., the relation between dark clouds and Nepal is literally a type of ENTITY-DESTINATION, but in fact it refers to the ethnic unrest in Nepal. We seek a pragmatic compromise between the two extremes. We have selected nine relations with sufficiently broad cover</context>
</contexts>
<marker>Stephens, Palakal, Mukhopadhyay, Raje, Mostafa, 2001</marker>
<rawString>Matthew Stephens, Mathew Palakal, Snehasis Mukhopadhyay, Rajeev Raje, and Javed Mostafa. 2001. Detecting gene relations from Medline abstracts. In Pacific Symposium on Biocomputing, pages 483–495.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
<author>Michael L Littman</author>
</authors>
<title>Corpusbased learning of analogies and semantic relations.</title>
<date>2005</date>
<booktitle>Machine Learning,</booktitle>
<pages>60--1</pages>
<contexts>
<context position="4864" citStr="Turney and Littman, 2005" startWordPosition="726" endWordPosition="729"> between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relation classification is whether the relations between nominals should be considered out o</context>
</contexts>
<marker>Turney, Littman, 2005</marker>
<rawString>Peter D. Turney and Michael L. Littman. 2005. Corpusbased learning of analogies and semantic relations. Machine Learning, 60(1-3):251–278.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Measuring semantic similarity by latent relational analysis.</title>
<date>2005</date>
<booktitle>In Proc. IJCAI,</booktitle>
<pages>1136--1141</pages>
<contexts>
<context position="4837" citStr="Turney, 2005" startWordPosition="724" endWordPosition="725">antic relation between the head noun and the modifier. Rosario et al. (2002) classify noun compounds using the MeSH hierarchy and a multi-level hierarchy of semantic relations, with 15 classes at the top level. Stephens et al. (2001) propose 17 very specific classes targeting relations between genes. Nastase and Szpakowicz (2003) address the problem of classifying noun-modifier relations in general text. They propose a two-level hierarchy, with 5 classes at the first level and 30 classes at the second one; other researchers (Kim and Baldwin, 2005; Nakov and Hearst, 2008; Nastase et al., 2006; Turney, 2005; Turney and Littman, 2005) have used their class scheme and data set. Moldovan et al. (2004) propose a 35-class scheme to classify relations in various phrases; the same scheme has been applied to noun compounds and other noun phrases (Girju et al., 2005). Lapata (2002) presents a binary classification of relations in nominalizations. Pantel and Pennacchiotti (2006) concentrate on five relations in an IE-style setting. In short, there is little agreement on relation inventories. 2.2 The Role of Context A fundamental question in relation classification is whether the relations between nominals</context>
</contexts>
<marker>Turney, 2005</marker>
<rawString>Peter D. Turney. 2005. Measuring semantic similarity by latent relational analysis. In Proc. IJCAI, pages 1136– 1141.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>