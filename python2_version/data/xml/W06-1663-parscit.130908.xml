<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000303">
<title confidence="0.865518">
Quality Assessment of Large Scale Knowledge Resources
</title>
<note confidence="0.639184333333333">
Montse Cuadros
IXA NLP Group
EHU/UPV
</note>
<address confidence="0.400373">
Donostia, Basque Country
</address>
<email confidence="0.982395">
mcuadros001@ikasle.ehu.es
</email>
<note confidence="0.849709">
German Rigau
IXA NLP Group
EHU/UPV
</note>
<address confidence="0.418607">
Donostia, Basque Country
</address>
<email confidence="0.990913">
german.rigau@ehu.es
</email>
<sectionHeader confidence="0.993684" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999424">
This paper presents an empirical eval-
uation of the quality of publicly avail-
able large-scale knowledge resources. The
study includes a wide range of manu-
ally and automatically derived large-scale
knowledge resources. In order to establish
a fair and neutral comparison, the qual-
ity of each knowledge resource is indi-
rectly evaluated using the same method on
a Word Sense Disambiguation task. The
evaluation framework selected has been
the Senseval-3 English Lexical Sample
Task. The study empirically demonstrates
that automatically acquired knowledge re-
sources surpass both in terms of preci-
sion and recall the knowledge resources
derived manually, and that the combina-
tion of the knowledge contained in these
resources is very close to the most frequent
sense classifier. As far as we know, this is
the first time that such a quality assessment
has been performed showing a clear pic-
ture of the current state-of-the-art of pub-
licly available wide coverage semantic re-
sources.
</bodyText>
<sectionHeader confidence="0.999133" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999152177777778">
Using large-scale semantic knowledge bases, such
as WordNet (Fellbaum, 1998), has become a
usual, often necessary, practice for most current
Natural Language Processing systems. Even now,
building large and rich enough knowledge bases
for broad–coverage semantic processing takes a
great deal of expensive manual effort involving
large research groups during long periods of de-
velopment. This fact has severely hampered the
state-of-the-art of current Natural Language Pro-
cessing (NLP) applications. For example, dozens
of person-years have been invested in the develop-
ment of wordnets for various languages (Vossen,
1998), but the data in these resources seems not to
be rich enough to support advanced concept-based
NLP applications directly. It seems that applica-
tions will not scale up to working in open domains
without more detailed and rich general-purpose
(and also domain-specific) linguistic knowledge
built by automatic means.
For instance, in more than eight years of man-
ual construction (from version 1.5 to 2.0), Word-
Net passed from 103,445 semantic relations to
204,074 semantic relations1. That is, around
twelve thousand semantic relations per year. How-
ever, during the last years the research commu-
nity has devised a large set of innovative processes
and tools for large-scale automatic acquisition of
lexical knowledge from structured or unstructured
corpora. Among others we can mention eX-
tended WordNet (Mihalcea and Moldovan, 2001),
large collections of semantic preferences acquired
from SemCor (Agirre and Martinez, 2001; Agirre
and Martinez, 2002) or acquired from British Na-
tional Corpus (BNC) (McCarthy, 2001), large-
scale Topic Signatures for each synset acquired
from the web (Agirre and de la Calle, 2004) or
acquired from the BNC (Cuadros et al., 2005).
Obviously, all these semantic resources have
been acquired using a very different set of meth-
ods, tools and corpora, resulting on a different set
of new semantic relations between synsets. In fact,
each resource has different volume and accuracy
figures. Although isolated evaluations have been
performed by their developers in different experi-
</bodyText>
<footnote confidence="0.905647">
1Symmetric relations are counted only once.
</footnote>
<page confidence="0.922342">
534
</page>
<note confidence="0.862128">
Proceedings of the 2006 Conference on Empirical Methods in Natural Language Processing (EMNLP 2006), pages 534–541,
Sydney, July 2006. c�2006 Association for Computational Linguistics
</note>
<bodyText confidence="0.999964833333333">
mental settings, to date no comparable evaluation
has been carried out in a common and controlled
framework.
This work tries to establish the relative qual-
ity of these semantic resources in a neutral envi-
ronment. The quality of each large-scale knowl-
edge resource is indirectly evaluated on a Word
Sense Disambiguation (WSD) task. In particular,
we use a well defined WSD evaluation benchmark
(Senseval-3 English Lexical Sample task) to eval-
uate the quality of each resource.
Furthermore, this work studies how these re-
sources complement each other. That is, to which
extent each knowledge base provides new knowl-
edge not provided by the others.
This paper is organized as follows: after this
introduction, section 2 describes the large-scale
knowledge resources studied in this work. Section
3 describes the evaluation framework. Section 4
presents the evaluation results of the different se-
mantic resources considered. Section 5 provides a
qualitative assessment of this empirical study and
finally, the conclusions and future work are pre-
sented in section 6.
</bodyText>
<sectionHeader confidence="0.896119" genericHeader="introduction">
2 Large Scale Knowledge Resources
</sectionHeader>
<bodyText confidence="0.997930518518518">
This study covers a wide range of large-scale
knowledge resources: WordNet (WN) (Fell-
baum, 1998), eXtended WordNet (Mihalcea and
Moldovan, 2001), large collections of semantic
preferences acquired from SemCor (Agirre and
Martinez, 2001; Agirre and Martinez, 2002) or
acquired from the BNC (McCarthy, 2001), large-
scale Topic Signatures for each synset acquired
from the web (Agirre and de la Calle, 2004) or
acquired from the BNC (Cuadros et al., 2005).
However, although these resources have been
derived using different WN versions, the research
community has the technology for the automatic
alignment of wordnets (Daud´e et al., 2003). This
technology provides a mapping among synsets of
different WN versions, maintaining the compati-
bility to all the knowledge resources which use
a particular WN version as a sense repository.
Furthermore, this technology allows to port the
knowledge associated to a particular WN version
to the rest of WN versions already connected.
Using this technology, most of these resources
are integrated into a common resource called Mul-
tilingual Central Repository (MCR) (Atserias et
al., 2004). In particular, all WordNet versions, eX-
tended WordNet, and the semantic preferences ac-
quired from SemCor and BNC.
</bodyText>
<subsectionHeader confidence="0.988222">
2.1 Multilingual Central Repository
</subsectionHeader>
<bodyText confidence="0.999900317073171">
The Multilingual Central Repository (MCR)2 fol-
lows the model proposed by the EuroWordNet
project. EuroWordNet (Vossen, 1998) is a multi-
lingual lexical database with wordnets for several
European languages, which are structured as the
Princeton WordNet. The Princeton WordNet con-
tains information about nouns, verbs, adjectives
and adverbs in English and is organized around the
notion of a synset. A synset is a set of words with
the same part-of-speech that can be interchanged
in a certain context. For example, &lt;party, po-
litical party&gt; form a synset because they can be
used to refer to the same concept. A synset is
often further described by a gloss, in this case:
”an organization to gain political power”. Finally,
synsets can be related to each other by semantic
relations, such as hyponymy (between specific and
more general concepts), meronymy (between parts
and wholes), cause, etc.
The current version of the MCR (Atserias et al.,
2004) is a result of the 5th Framework MEANING
project. The MCR integrates into the same Eu-
roWordNet framework wordnets from five differ-
ent languages (together with four English Word-
Net versions). The MCR also integrates WordNet
Domains (Magnini and Cavagli`a, 2000) and new
versions of the Base Concepts and Top Concept
Ontology. The final version of the MCR contains
1,642,389 semantic relations between synsets,
most of them acquired by automatic means. This
represents almost one order of magnitude larger
than the Princeton WordNet (204,074 unique se-
mantic relations in WordNet 2.0). Table 1 summa-
rizes the main sources for semantic relations inte-
grated into the MCR.
Table 2 shows the number of semantic relations
between synsets pairs in the MCR and its overlap-
pings. Note that, most of the relations in the MCR
between synsets-pairs are unique.
Hereinafter we will refer to each semantic re-
source as follows:
</bodyText>
<listItem confidence="0.9970524">
• WN (Fellbaum, 1998): This knowledge re-
source uses the direct relations encoded in
WordNet 1.6 or 2.0. We also tested WN-2
(using relations at distance 1 and 2) and WN-
3 (using relations at distance 1, 2 and 3).
</listItem>
<footnote confidence="0.930611">
2http://nipadio.lsi.upc.es/˜nlp/meaning
</footnote>
<page confidence="0.98937">
535
</page>
<table confidence="0.999173444444444">
Source #relations
Princeton WN1.6 138,091
Selectional Preferences from SemCor 203,546
Selectional Preferences from the BNC 707,618
New relations from Princeton WN2.0 42,212
Gold relations from eXtended WN 17,185
Silver relations from eXtended WN 239,249
Normal relations from eXtended WN 294,488
Total 1,642,389
</table>
<tableCaption confidence="0.996768">
Table 1: Main sources of semantic relations
</tableCaption>
<table confidence="0.999666428571429">
Type of Relations #relations
Total Relations 1,642,389
Different Relations 1,531,380
Unique Relations 1,390,181
Non-unique relations (&gt;1) 70,425
Non-unique relations (&gt;2) 341
Non-unique relations (&gt;3) 8
</table>
<tableCaption confidence="0.997868">
Table 2: Overlapping relations in the MCR
</tableCaption>
<listItem confidence="0.999008263157895">
• XWN (Mihalcea and Moldovan, 2001): This
knowledge resource uses the direct relations
encoded in eXtended WordNet.
• XWN+WN: This knowledge resource uses
the direct relations included in WN and
XWN.
• spBNC (McCarthy, 2001): This knowledge
resource contains the selectional preferences
acquired from the BNC.
• spSemCor (Agirre and Martinez, 2001;
Agirre and Martinez, 2002): This knowledge
resource contains the selectional preferences
acquired from SemCor.
• spBNC+spSemCor: This knowledge re-
source uses the selectional preferences ac-
quired from the BNC and SemCor.
• MCR (Atserias et al., 2004): This knowledge
resource uses the direct relations included in
MCR.
</listItem>
<subsectionHeader confidence="0.99967">
2.2 Automatically retrieved Topic Signatures
</subsectionHeader>
<bodyText confidence="0.999848705882353">
Topic Signatures (TS) are word vectors related to
a particular topic (Lin and Hovy, 2000). Topic
Signatures are built by retrieving context words
of a target topic from large volumes of text. In
our case, we consider word senses as topics. Ba-
sically, the acquisition of TS consists of A) ac-
quiring the best possible corpus examples for a
particular word sense (usually characterizing each
word sense as a query and performing a search on
the corpus for those examples that best match the
queries), and then, B) building the TS by deriv-
ing the context words that best represent the word
sense from the selected corpora.
For this study, we use the large-scale Topic Sig-
natures acquired from the web (Agirre and de la
Calle, 2004) and those acquired from the BNC
(Cuadros et al., 2005).
</bodyText>
<listItem confidence="0.967298666666667">
• TSWEB3: Inspired by the work of (Lea-
cock et al., 1998), these Topic Signatures
were constructed using monosemous rela-
tives from WordNet (synonyms, hypernyms,
direct and indirect hyponyms, and siblings),
querying Google and retrieving up to one
thousand snippets per query (that is, a word
sense). In particular, the method was as fol-
lows:
</listItem>
<bodyText confidence="0.986243533333333">
– Organizing the retrieved examples from
the web in collections, one collection
per word sense.
– Extracting the words and their frequen-
cies for each collection.
– Comparing these frequencies with those
pertaining to other word senses using
TFIDF (see formula 1).
– Gathering in an ordered list, the words
with distinctive frequency for one of the
collections, which constitutes the Topic
Signature for the respective word sense.
This constitutes the largest available seman-
tic resource with around 100 million relations
(between synsets and words).
</bodyText>
<listItem confidence="0.701861">
• TSBNC: These Topic Signatures have been
constructed using ExRetriever4, a flexible
tool to perform sense queries on large cor-
pora.
– This tool characterizes each sense of a
word as a specific query using a declar-
ative language.
– This is automatically done by using a
particular query construction strategy,
defined a priori, and using information
from a knowledge base.
</listItem>
<bodyText confidence="0.936759">
In this study, ExRetriever has been evaluated
using the BNC, WN as a knowledge base and
</bodyText>
<footnote confidence="0.999271">
3http://ixa.si.ehu.es/Ixa/resources/sensecorpus
4http://www.lsi.upc.es/˜nlp/meaning/downloads.html
</footnote>
<page confidence="0.978712">
536
</page>
<bodyText confidence="0.9837205">
TFIDF (as shown in formula 1) (Agirre and
de la Calle, 2004)5.
</bodyText>
<equation confidence="0.97261">
wf,,, N
TFIDF(w, C) = � log (1)
max,,,wf,,, Cf,,,
</equation>
<bodyText confidence="0.9975255">
Where w stands for word context, wf for the
word frecuency, C for Collection (all the cor-
pus gathered for a particular word sense), and
Cf stands for the Collection frecuency.
In this study we consider two different query
strategies:
</bodyText>
<listItem confidence="0.951629571428571">
• Monosemous A (queryA): (OR
monosemous-words). That is, the union
set of all synonym, hyponym and hyper-
onym words of a WordNet synset which are
monosemous nouns (these words can have
other senses as verbs, adjectives or adverbs).
• Monosemous W (queryW): (OR
monosemous-words). That is, the union
set of all words appearing as synonyms,
direct hyponyms, hypernyms indirect hy-
ponyms (distance 2 and 3) and siblings. In
this case, the nouns collected are monose-
mous having no other senses as verbs,
adjectives or adverbs.
</listItem>
<bodyText confidence="0.982878">
While TSWEB use the query construction
queryW, ExRetriever use both.
</bodyText>
<sectionHeader confidence="0.997862" genericHeader="method">
3 Indirect Evaluation on Word Sense
Disambiguation
</sectionHeader>
<bodyText confidence="0.9991765">
In order to measure the quality of the knowl-
edge resources described in the previous section,
we performed an indirect evaluation by using all
these resources as Topic Signatures (TS). That is,
word vectors with weights associated to a partic-
ular synset which are obtained by collecting those
word senses appearing in the synsets directly re-
lated to them 6. This simple representation tries to
be as neutral as possible with respect to the evalu-
ation framework.
All knowledge resources are indirectly evalu-
ated on a WSD task. In particular, the noun-set
</bodyText>
<footnote confidence="0.9606368">
5Although other measures have been tested, such as Mu-
tual Information or Association Ratio, the best results have
been obtained using TFIDF formula.
6A weight of 1 is given when the resource do not has as-
sociated weight.
</footnote>
<bodyText confidence="0.999111476190476">
of Senseval-3 English Lexical Sample task which
consists of 20 nouns. All performances are evalu-
ated on the test data using the fine-grained scoring
system provided by the organizers.
Furthermore, trying to be as neutral as possi-
ble with respect to the semantic resources studied,
we applied systematically the same disambigua-
tion method to all of them. Recall that our main
goal is to establish a fair comparison of the knowl-
edge resources rather than providing the best dis-
ambiguation technique for a particular semantic
knowledge base.
A common WSD method has been applied to
all knowledge resources. A simple word over-
lapping counting (or weighting) is performed be-
tween the Topic Signature and the test example7.
Thus, the occurrence evaluation measure counts
the amount of overlapped words and the weight
evaluation measure adds up the weights of the
overlapped words. The synset having higher over-
lapping word counts (or weights) is selected for a
particular test example. However, for TSWEB and
TSBNC the better results have been obtained us-
ing occurrences (the weights are only used to or-
der the words of the vector). Finally, we should
remark that the results are not skewed (for in-
stance, for resolving ties) by the most frequent
sense in WN or any other statistically predicted
knowledge.
Figure 3 presents an example of Topic Signa-
ture from TSWEB using queryW and the web and
from TSBNC using queryA and the BNC for the
first sense of the noun party. Although both auto-
matically acquired TS seem to be closely related to
the first sense of the noun party, they do not have
words in common.
As an example, table 4 shows a test example of
Senseval-3 corresponding to the first sense of the
noun party. In bold there are the words that ap-
pear in TSBNC-queryA. There are several impor-
tant words that appear in the text that also appear
in the TS.
</bodyText>
<sectionHeader confidence="0.9764615" genericHeader="method">
4 Evaluating the quality of knowledge
resources
</sectionHeader>
<bodyText confidence="0.99981475">
In order to establish a clear picture of the current
state-of-the-art of publicly available wide cover-
age knowledge resources we also consider a num-
ber of basic baselines.
</bodyText>
<footnote confidence="0.96535">
7We also consider multiword terms.
</footnote>
<page confidence="0.987051">
537
</page>
<table confidence="0.999918333333334">
democratic 0.0126 socialist 0.0062
tammany 0.0124 organization 0.0060
alinement 0.0122 conservative 0.0059
federalist 0.0115 populist 0.0053
missionary 0.0103 dixiecrats 0.0051
whig 0.0099 know-nothing 0.0049
greenback 0.0089 constitutional 0.0045
anti-masonic 0.0083 pecking 0.0043
nazi 0.0081 democratic-republican 0.0040
republican 0.0074 republicans 0.0039
alcoholics 0.0073 labor 0.0039
bull 0.0070 salvation 0.0038
party 4.9350 trade 1.5295
political 3.7722 parties 1.4083
government 2.4129 politics 1.2703
election 2.2265 campaign 1.2551
policy 2.0795 leadership 1.2277
support 1.8537 movement 1.2156
leader 1.8280 general 1.2034
years 1.7128 public 1.1874
people 1.7044 member 1.1855
local 1.6899 opposition 1.1751
conference 1.6702 unions 1.1563
power 1.6105 national 1.1474
</table>
<tableCaption confidence="0.638848222222222">
Table 3: Topic Signatures for party#n#1 using TSWEB (24 out of 15881 total words) and TS-
BNC(queryA) with TFIDF (24 out of 9069 total words)
&lt;instance id=”party.n.bnc.00008131” docsrc=”BNC”&gt; &lt;context&gt; Up to the late 1960s , catholic nationalists were split between
two main political groupings . There was the Nationalist Party , a weak organization for which local priests had to provide
some kind of legitimation. As a &lt;head&gt;party&lt;/head&gt; , it really only exercised a modicum of power in relation to the Stormont
administration. Then there were the republican parties who focused their attention on Westminster elections. The disorganized
nature of catholic nationalist politics was only turned round with the emergence of the civil rights movement of 1968 and the
subsequent forming of the SDLP in 1970 . &lt;/context&gt; &lt;/instance&gt;
Table 4: Example of test num. 00008131 for party#n which its correct sense is 1
</tableCaption>
<subsectionHeader confidence="0.980684">
4.1 Baselines
</subsectionHeader>
<bodyText confidence="0.998142333333333">
We have designed several baselines in order to es-
tablish a relative comparison of the performance
of each semantic resource:
</bodyText>
<listItem confidence="0.973568666666667">
• RANDOM: For each target word, this
method selects a random sense. This baseline
can be considered as a lower-bound.
• WordNet MFS (WN-MFS): This method
selects the most frequent sense (the first sense
in WordNet) of the target word.
• TRAIN-MFS: This method selects the most
frequent sense in the training corpus of the
target word.
• Train Topic Signatures (TRAIN): This
baseline uses the training corpus to directly
build a Topic Signature using TFIDF measure
</listItem>
<bodyText confidence="0.985533545454546">
for each word sense. Note that in this case,
this baseline can be considered as an upper-
bound of our evaluation framework.
Table 5 presents the F1 measure (harmonic
mean of recall and precision) of the different base-
lines. In this table, TRAIN has been calculated
with a fixed vector size of 450 words. As ex-
pected, RANDOM baseline obtains the poorest
result while the most frequent sense of Word-
Net (WN-MFS) is very close to the most frequent
sense of the training corpus (TRAIN-MFS), but
</bodyText>
<table confidence="0.9871336">
Baselines F1
TRAIN 65.1
TRAIN-MFS 54.5
WN-MFS 53.0
RANDOM 19.1
</table>
<tableCaption confidence="0.998226">
Table 5: Baselines
</tableCaption>
<bodyText confidence="0.9730085">
both are far below to the Topic Signatures acquired
using the training corpus (TRAIN).
</bodyText>
<subsectionHeader confidence="0.997385">
4.2 Performance of the knowledge resources
</subsectionHeader>
<bodyText confidence="0.999125777777778">
Table 6 presents the performance of each knowl-
edge resource uploaded into the MCR and the av-
erage size of its vectors. In bold appear the best
results for precision, recall and F1 measures. The
lowest result is obtained by the knowledge directly
gathered from WN mainly because of its poor cov-
erage (Recall of 17.6 and F1 of 25.6). Its perfor-
mance is improved using words at distance 1 and
2 (F1 of 33.3), but it decreases using words at dis-
tance 1, 2 and 3 (F1 of 30.4). The best precision is
obtained by WN (46.7), but the best performance
is achieved by the combined knowledge of MCR-
spBNC8 (Recall of 42.9 and F1 of 44.1). This rep-
resents a recall 18.5 points higher than WN. That
is, the knowledge integrated into the MCR (Word-
Net, eXtended WordNet and the selectional prefer-
ences acquired from SemCor) although partly de-
rived by automatic means performs much better
</bodyText>
<footnote confidence="0.918753">
8MCR without Selectional Preferences from BNC
</footnote>
<page confidence="0.981918">
538
</page>
<table confidence="0.999942363636364">
KB P R F1 Av. Size
MCR-spBNC 45.4 42.9 44.1 115
MCR 41.8 40.4 41.1 235
spSemCor 43.1 38.7 40.8 56
spBNC+spSemCor 41.4 30.1 40.7 184
WN+XWN 45.5 28.1 34.7 68
WN-2 38.0 29.7 33.3 72
XWN 45.0 25.6 32.6 55
WN-3 31.6 29.3 30.4 297
spBNC 36.3 25.4 29.9 128
WN 46.7 17.6 25.6 13
</table>
<tableCaption confidence="0.8789075">
Table 6: P, R and F1 fine-grained results for the
resources integrated into the MCR.
</tableCaption>
<bodyText confidence="0.993025676470588">
in terms of recall and F1 measures than using the
knowledge currently present in WN alone (with a
small decrease in precision). It also seems that the
knowledge from spBNC always degrades the per-
formance of their combinations9.
Regarding the baselines, all knowledge re-
sources integrated into the MCR surpass RAN-
DOM, but none achieves neither WN-MFS,
TRAIN-MFS nor TRAIN.
Figure 1 plots F1 results of the fine-grained
evaluation on the nominal part of the English lex-
ical sample of Senseval-3 of the baselines (in-
cluding upper and lower-bounds), the knowledge
bases integrated into the MCR, the best perform-
ing Topic Signatures acquired from the web and
the BNC evaluated individually and in combina-
tion with others. The figure presents F1 (Y-axis)
in terms of the size of the word vectors (X-axis)10.
In order to evaluate more deeply the quality of
each knowledge resource, we also provide some
evaluations of the combined outcomes of several
knowledge resources. The combinations are per-
formed following a very simple voting method:
first, for each knowledge resource, the scoring re-
sults obtained for each word sense are normal-
ized, and then, for each word sense, the normal-
ized scores are added up selecting the word sense
with higher score.
Regarding Topic Signatures, as expected, in
general the knowledge gathered from the web
(TSWEB) is superior to the one acquired from the
BNC either using queryA or queryW (TSBNC-
queryA and TSBNC-queryW). Interestingly, the
performance of TSBNC-queryA when using the
</bodyText>
<footnote confidence="0.991345">
9All selectional preferences acquired from SemCor or the
BNC have been considered including those with very low
confidence score.
10Only varying the size of TS for TSWEB and TSBNC.
</footnote>
<bodyText confidence="0.9999045625">
first two hundred words of the TS is slightly bet-
ter than using queryW (both using the web or the
BNC).
Although TSBNC-queryA and TSBNC-
queryW perform very similar, both knowledge
resources contain different knowledge. This is
shown when combining the outcomes of these
two different knowledge resources with TSWEB.
While no improvement is obtained when com-
bining the knowledge acquired from the web
and the BNC when using the same acquisition
method (queryW), the combination of TSWEB
and TSBNC-queryA (TSWEB+ExRetA) obtains
better F1 results than TSWEB (TSBNC-queryA
have some knowledge not included into TSWEB).
Surprisingly, the knowledge integrated into the
MCR (MCR-spBNC) surpass the knowledge from
Topic Signatures acquired from the web or the
BNC, using queryA, queryW or their combina-
tions.
Furthermore, the combination of TSWEB and
MCR-spBNC (TSWEB+MCR-spBNC) outper-
forms both resources individually indicating that
both knowledge bases contain complementary in-
formation. The maximum is achieved with TS
vectors of at most 700 words (with 49.3% preci-
sion, 49.2% recall and 49.2% F1). In fact, the
resulting combination is very close to the most
frequent sense baselines. This fact indicates that
the resulting large-scale knowledge base almost
encodes the knowledge necessary to behave as a
most frequent sense tagger.
</bodyText>
<subsectionHeader confidence="0.998745">
4.3 Senseval-3 system performances
</subsectionHeader>
<bodyText confidence="0.977738823529412">
For sake of comparison, tables 7 and 8 present the
F1 measure of the fine-grained results for nouns
of the Senseval-3 lexical sample task for the best
and worst unsupervised and supervised systems,
respectively. We also include in these tables some
of the baselines and the best performing combina-
tion of knowledge resources (including TSWEB
and MCR-spBNC)11. Regarding the knowledge
resources evaluated in this study, the best com-
bination (including TSWEB and MCR-spBNC)
achieves an F1 measure much better than some su-
pervised and unsupervised systems and it is close
to the most frequent sense of WordNet (WN-MFS)
and to the most frequent sense of the training cor-
pora (TRAIN-MFS).
11Although we maintain the classification of the organiz-
ers, system s3 wsdiit used the train data.
</bodyText>
<page confidence="0.996707">
539
</page>
<figureCaption confidence="0.989346">
Figure 1: Fine-grained evaluation results for the knowledge resources
</figureCaption>
<table confidence="0.999391">
s3 systems F1
s3 wsdiit 68.0
WN-MFS 53.0
Comb TSWEB MCR-spBNC 49.2
s3 DLSI 17.8
</table>
<tableCaption confidence="0.947595">
Table 7: Senseval-3 Unsupervised Systems
</tableCaption>
<table confidence="0.9997602">
s3 systems F1
htsa3 U.Bucharest (Grozea) 74.2
TRAIN 65.1
TRAIN-MFS 54.5
DLSI-UA-LS-SU U.Alicante (Vazquez) 41.0
</table>
<tableCaption confidence="0.998679">
Table 8: Senseval-3 Supervised Systems
</tableCaption>
<bodyText confidence="0.999872285714286">
We must recall that the main goal of this re-
search is to establish a clear and neutral view of the
relative quality of available knowledge resources,
not to provide the best WSD algorithm using these
resources. Obviously, much more sophisticated
WSD systems using these resources could be de-
vised.
</bodyText>
<sectionHeader confidence="0.996211" genericHeader="method">
5 Quality Assessment
</sectionHeader>
<bodyText confidence="0.999896407407407">
Summarizing, this study provides empirical evi-
dence for the relative quality of publicly avail-
able large-scale knowledge resources. The rela-
tive quality has been measured indirectly in terms
of precision and recall on a WSD task.
The study empirically demonstrates that auto-
matically acquired knowledge bases clearly sur-
pass both in terms of precision and recall the
knowledge manually encoded from WordNet (us-
ing relations expanded to one, two or three levels).
Surprisingly, the knowledge contained into the
MCR (WordNet, eXtended WordNet, Selectional
Preferences acquired automatically from SemCor)
is of a better quality than the automatically ac-
quired Topic Signatures. In fact, the knowledge
resulting from the combination of all these large-
scale resources outperforms each resource indi-
vidually indicating that these knowledge bases
contain complementary information. Finally, we
should remark that the resulting combination is
very close to the most frequent sense classifiers.
Regarding the automatic acquisition of large-
scale Topic Signatures it seems that those ac-
quired from the web are slightly better than those
acquired from smaller corpora (for instance, the
BNC). It also seems that queryW performs better
than queryA but that both methods (queryA and
</bodyText>
<page confidence="0.98133">
540
</page>
<bodyText confidence="0.9996475">
queryW) also produce complementary knowledge.
Finally, it seems that the weights are not useful for
measuring the strength of a vote (they are only use-
ful for ordering the words in the Topic Signature).
</bodyText>
<sectionHeader confidence="0.994813" genericHeader="conclusions">
6 Conclusions and future work
</sectionHeader>
<bodyText confidence="0.999979294117647">
During the last years the research community has
derived a large set of semantic resources using a
very different set of methods, tools and corpus, re-
sulting on a different set of new semantic relations
between synsets. In fact, each resource has dif-
ferent volume and accuracy figures. Although iso-
lated evaluations have been performed by their de-
velopers in different experimental settings, to date
no complete evaluation has been carried out in a
common framework.
In order to establish a fair comparison, the qual-
ity of each resource has been indirectly evaluated
in the same way on a WSD task. The evaluation
framework selected has been the Senseval-3 En-
glish Lexical Sample Task. The study empirically
demonstrates that automatically acquired knowl-
edge bases surpass both in terms of precision and
recall to the knowledge bases derived manually,
and that the combination of the knowledge con-
tained in these resources is very close to the most
frequent sense classifier.
Once empirically demonstrated that the knowl-
edge resulting from MCR and Topic Signatures ac-
quired from the web is complementary and close
to the most frequent sense classifier, we plan to
integrate the Topic Signatures acquired from the
web (of about 100 million relations) into the MCR.
This process will be performed by disambiguat-
ing the Topic Signatures. That is, trying to obtain
word sense vectors instead of word vectors. This
will allow to enlarge the existing knowledge bases
in several orders of magnitude by fully automatic
methods. Other evaluation frameworks such as PP
attachment will be also considered.
</bodyText>
<sectionHeader confidence="0.999294" genericHeader="acknowledgments">
7 Acknowledgements
</sectionHeader>
<bodyText confidence="0.999192">
This work is being funded by the IXA NLP
group from the Basque Country Univer-
sity, EHU/UPV-CLASS project and Basque
Government-ADIMEN project. We would like
to thank also the three anonymous reviewers for
their valuable comments.
</bodyText>
<sectionHeader confidence="0.996302" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999729186046512">
E. Agirre and O. Lopez de la Calle. 2004. Publicly
available topic signatures for all wordnet nominal
senses. In Proceedings of LREC, Lisbon, Portugal.
E. Agirre and D. Martinez. 2001. Learning class-
to-class selectional preferences. In Proceedings of
CoNLL, Toulouse, France.
E. Agirre and D. Martinez. 2002. Integrating selec-
tional preferences in wordnet. In Proceedings of
GWC, Mysore, India.
J. Atserias, L. Villarejo, G. Rigau, E. Agirre, J. Carroll,
B. Magnini, and Piek Vossen. 2004. The meaning
multilingual central repository. In Proceedings of
GWC, Brno, Czech Republic.
M. Cuadros, L. Padr´o, and G. Rigau. 2005. Compar-
ing methods for automatic acquisition of topic sig-
natures. In Proceedings of RANLP, Borovets, Bul-
garia.
J. Daud´e, L. Padr´o, and G. Rigau. 2003. Validation and
Tuning of Wordnet Mapping Techniques. In Pro-
ceedings of RANLP, Borovets, Bulgaria.
C. Fellbaum, editor. 1998. WordNet. An Electronic
Lexical Database. The MIT Press.
C. Leacock, M. Chodorow, and G. Miller. 1998. Us-
ing Corpus Statistics and WordNet Relations for
Sense Identification. Computational Linguistics,
24(1):147–166.
C. Lin and E. Hovy. 2000. The automated acquisition
of topic signatures for text summarization. In Pro-
ceedings of COLING. Strasbourg, France.
B. Magnini and G. Cavagli`a. 2000. Integrating subject
field codes into wordnet. In Proceedings of LREC,
Athens. Greece.
D. McCarthy. 2001. Lexical Acquisition at the Syntax-
Semantics Interface: Diathesis Aternations, Sub-
categorization Frames and Selectional Preferences.
Ph.D. thesis, University of Sussex.
R. Mihalcea and D. Moldovan. 2001. extended word-
net: Progress report. In Proceedings of NAACL
Workshop on WordNet and Other Lexical Resources,
Pittsburgh, PA.
P. Vossen, editor. 1998. EuroWordNet: A Multilingual
Database with Lexical Semantic Networks. Kluwer
Academic Publishers.
</reference>
<page confidence="0.997764">
541
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.214218">
<title confidence="0.999105">Quality Assessment of Large Scale Knowledge Resources</title>
<author confidence="0.393062">Montse</author>
<affiliation confidence="0.668186">IXA NLP</affiliation>
<address confidence="0.528216">Donostia, Basque</address>
<email confidence="0.802934">mcuadros001@ikasle.ehu.es</email>
<author confidence="0.944114">German</author>
<affiliation confidence="0.99434">IXA NLP</affiliation>
<address confidence="0.970627">Donostia, Basque</address>
<email confidence="0.981828">german.rigau@ehu.es</email>
<abstract confidence="0.996456192307692">This paper presents an empirical evaluation of the quality of publicly available large-scale knowledge resources. The study includes a wide range of manually and automatically derived large-scale knowledge resources. In order to establish a fair and neutral comparison, the quality of each knowledge resource is indirectly evaluated using the same method on a Word Sense Disambiguation task. The evaluation framework selected has been the Senseval-3 English Lexical Sample Task. The study empirically demonstrates that automatically acquired knowledge resources surpass both in terms of precision and recall the knowledge resources derived manually, and that the combination of the knowledge contained in these resources is very close to the most frequent sense classifier. As far as we know, this is the first time that such a quality assessment has been performed showing a clear picture of the current state-of-the-art of publicly available wide coverage semantic resources.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>O Lopez de la Calle</author>
</authors>
<title>Publicly available topic signatures for all wordnet nominal senses.</title>
<date>2004</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Lisbon, Portugal.</location>
<marker>Agirre, Calle, 2004</marker>
<rawString>E. Agirre and O. Lopez de la Calle. 2004. Publicly available topic signatures for all wordnet nominal senses. In Proceedings of LREC, Lisbon, Portugal.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Martinez</author>
</authors>
<title>Learning classto-class selectional preferences.</title>
<date>2001</date>
<booktitle>In Proceedings of CoNLL,</booktitle>
<location>Toulouse, France.</location>
<contexts>
<context position="2768" citStr="Agirre and Martinez, 2001" startWordPosition="410" endWordPosition="413">y automatic means. For instance, in more than eight years of manual construction (from version 1.5 to 2.0), WordNet passed from 103,445 semantic relations to 204,074 semantic relations1. That is, around twelve thousand semantic relations per year. However, during the last years the research community has devised a large set of innovative processes and tools for large-scale automatic acquisition of lexical knowledge from structured or unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), largescale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or acquired from the BNC (Cuadros et al., 2005). Obviously, all these semantic resources have been acquired using a very different set of methods, tools and corpora, resulting on a different set of new semantic relations between synsets. In fact, each resource has different volume and accuracy figures. Although isolated evaluations have been performed by their developers in different experi1Symmetric relat</context>
<context position="4915" citStr="Agirre and Martinez, 2001" startWordPosition="737" endWordPosition="740"> section 2 describes the large-scale knowledge resources studied in this work. Section 3 describes the evaluation framework. Section 4 presents the evaluation results of the different semantic resources considered. Section 5 provides a qualitative assessment of this empirical study and finally, the conclusions and future work are presented in section 6. 2 Large Scale Knowledge Resources This study covers a wide range of large-scale knowledge resources: WordNet (WN) (Fellbaum, 1998), eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002) or acquired from the BNC (McCarthy, 2001), largescale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or acquired from the BNC (Cuadros et al., 2005). However, although these resources have been derived using different WN versions, the research community has the technology for the automatic alignment of wordnets (Daud´e et al., 2003). This technology provides a mapping among synsets of different WN versions, maintaining the compatibility to all the knowledge resources which use a particular WN version as a sense repository. Fur</context>
<context position="9023" citStr="Agirre and Martinez, 2001" startWordPosition="1374" endWordPosition="1377">in sources of semantic relations Type of Relations #relations Total Relations 1,642,389 Different Relations 1,531,380 Unique Relations 1,390,181 Non-unique relations (&gt;1) 70,425 Non-unique relations (&gt;2) 341 Non-unique relations (&gt;3) 8 Table 2: Overlapping relations in the MCR • XWN (Mihalcea and Moldovan, 2001): This knowledge resource uses the direct relations encoded in eXtended WordNet. • XWN+WN: This knowledge resource uses the direct relations included in WN and XWN. • spBNC (McCarthy, 2001): This knowledge resource contains the selectional preferences acquired from the BNC. • spSemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002): This knowledge resource contains the selectional preferences acquired from SemCor. • spBNC+spSemCor: This knowledge resource uses the selectional preferences acquired from the BNC and SemCor. • MCR (Atserias et al., 2004): This knowledge resource uses the direct relations included in MCR. 2.2 Automatically retrieved Topic Signatures Topic Signatures (TS) are word vectors related to a particular topic (Lin and Hovy, 2000). Topic Signatures are built by retrieving context words of a target topic from large volumes of text. In our case, we consider word senses as top</context>
</contexts>
<marker>Agirre, Martinez, 2001</marker>
<rawString>E. Agirre and D. Martinez. 2001. Learning classto-class selectional preferences. In Proceedings of CoNLL, Toulouse, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>E Agirre</author>
<author>D Martinez</author>
</authors>
<title>Integrating selectional preferences in wordnet.</title>
<date>2002</date>
<booktitle>In Proceedings of GWC, Mysore,</booktitle>
<contexts>
<context position="2796" citStr="Agirre and Martinez, 2002" startWordPosition="414" endWordPosition="417">ance, in more than eight years of manual construction (from version 1.5 to 2.0), WordNet passed from 103,445 semantic relations to 204,074 semantic relations1. That is, around twelve thousand semantic relations per year. However, during the last years the research community has devised a large set of innovative processes and tools for large-scale automatic acquisition of lexical knowledge from structured or unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), largescale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or acquired from the BNC (Cuadros et al., 2005). Obviously, all these semantic resources have been acquired using a very different set of methods, tools and corpora, resulting on a different set of new semantic relations between synsets. In fact, each resource has different volume and accuracy figures. Although isolated evaluations have been performed by their developers in different experi1Symmetric relations are counted only once. </context>
<context position="4943" citStr="Agirre and Martinez, 2002" startWordPosition="741" endWordPosition="744">rge-scale knowledge resources studied in this work. Section 3 describes the evaluation framework. Section 4 presents the evaluation results of the different semantic resources considered. Section 5 provides a qualitative assessment of this empirical study and finally, the conclusions and future work are presented in section 6. 2 Large Scale Knowledge Resources This study covers a wide range of large-scale knowledge resources: WordNet (WN) (Fellbaum, 1998), eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002) or acquired from the BNC (McCarthy, 2001), largescale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or acquired from the BNC (Cuadros et al., 2005). However, although these resources have been derived using different WN versions, the research community has the technology for the automatic alignment of wordnets (Daud´e et al., 2003). This technology provides a mapping among synsets of different WN versions, maintaining the compatibility to all the knowledge resources which use a particular WN version as a sense repository. Furthermore, this technology al</context>
<context position="9051" citStr="Agirre and Martinez, 2002" startWordPosition="1378" endWordPosition="1381">tions Type of Relations #relations Total Relations 1,642,389 Different Relations 1,531,380 Unique Relations 1,390,181 Non-unique relations (&gt;1) 70,425 Non-unique relations (&gt;2) 341 Non-unique relations (&gt;3) 8 Table 2: Overlapping relations in the MCR • XWN (Mihalcea and Moldovan, 2001): This knowledge resource uses the direct relations encoded in eXtended WordNet. • XWN+WN: This knowledge resource uses the direct relations included in WN and XWN. • spBNC (McCarthy, 2001): This knowledge resource contains the selectional preferences acquired from the BNC. • spSemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002): This knowledge resource contains the selectional preferences acquired from SemCor. • spBNC+spSemCor: This knowledge resource uses the selectional preferences acquired from the BNC and SemCor. • MCR (Atserias et al., 2004): This knowledge resource uses the direct relations included in MCR. 2.2 Automatically retrieved Topic Signatures Topic Signatures (TS) are word vectors related to a particular topic (Lin and Hovy, 2000). Topic Signatures are built by retrieving context words of a target topic from large volumes of text. In our case, we consider word senses as topics. Basically, the acquisit</context>
</contexts>
<marker>Agirre, Martinez, 2002</marker>
<rawString>E. Agirre and D. Martinez. 2002. Integrating selectional preferences in wordnet. In Proceedings of GWC, Mysore, India.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Atserias</author>
<author>L Villarejo</author>
<author>G Rigau</author>
<author>E Agirre</author>
<author>J Carroll</author>
<author>B Magnini</author>
<author>Piek Vossen</author>
</authors>
<title>The meaning multilingual central repository.</title>
<date>2004</date>
<booktitle>In Proceedings of GWC,</booktitle>
<location>Brno, Czech Republic.</location>
<contexts>
<context position="5807" citStr="Atserias et al., 2004" startWordPosition="876" endWordPosition="879">using different WN versions, the research community has the technology for the automatic alignment of wordnets (Daud´e et al., 2003). This technology provides a mapping among synsets of different WN versions, maintaining the compatibility to all the knowledge resources which use a particular WN version as a sense repository. Furthermore, this technology allows to port the knowledge associated to a particular WN version to the rest of WN versions already connected. Using this technology, most of these resources are integrated into a common resource called Multilingual Central Repository (MCR) (Atserias et al., 2004). In particular, all WordNet versions, eXtended WordNet, and the semantic preferences acquired from SemCor and BNC. 2.1 Multilingual Central Repository The Multilingual Central Repository (MCR)2 follows the model proposed by the EuroWordNet project. EuroWordNet (Vossen, 1998) is a multilingual lexical database with wordnets for several European languages, which are structured as the Princeton WordNet. The Princeton WordNet contains information about nouns, verbs, adjectives and adverbs in English and is organized around the notion of a synset. A synset is a set of words with the same part-of-s</context>
<context position="9274" citStr="Atserias et al., 2004" startWordPosition="1411" endWordPosition="1414">ng relations in the MCR • XWN (Mihalcea and Moldovan, 2001): This knowledge resource uses the direct relations encoded in eXtended WordNet. • XWN+WN: This knowledge resource uses the direct relations included in WN and XWN. • spBNC (McCarthy, 2001): This knowledge resource contains the selectional preferences acquired from the BNC. • spSemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002): This knowledge resource contains the selectional preferences acquired from SemCor. • spBNC+spSemCor: This knowledge resource uses the selectional preferences acquired from the BNC and SemCor. • MCR (Atserias et al., 2004): This knowledge resource uses the direct relations included in MCR. 2.2 Automatically retrieved Topic Signatures Topic Signatures (TS) are word vectors related to a particular topic (Lin and Hovy, 2000). Topic Signatures are built by retrieving context words of a target topic from large volumes of text. In our case, we consider word senses as topics. Basically, the acquisition of TS consists of A) acquiring the best possible corpus examples for a particular word sense (usually characterizing each word sense as a query and performing a search on the corpus for those examples that best match th</context>
</contexts>
<marker>Atserias, Villarejo, Rigau, Agirre, Carroll, Magnini, Vossen, 2004</marker>
<rawString>J. Atserias, L. Villarejo, G. Rigau, E. Agirre, J. Carroll, B. Magnini, and Piek Vossen. 2004. The meaning multilingual central repository. In Proceedings of GWC, Brno, Czech Republic.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Cuadros</author>
<author>L Padr´o</author>
<author>G Rigau</author>
</authors>
<title>Comparing methods for automatic acquisition of topic signatures.</title>
<date>2005</date>
<booktitle>In Proceedings of RANLP, Borovets,</booktitle>
<marker>Cuadros, Padr´o, Rigau, 2005</marker>
<rawString>M. Cuadros, L. Padr´o, and G. Rigau. 2005. Comparing methods for automatic acquisition of topic signatures. In Proceedings of RANLP, Borovets, Bulgaria.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Daud´e</author>
<author>L Padr´o</author>
<author>G Rigau</author>
</authors>
<title>Validation and Tuning of Wordnet Mapping Techniques.</title>
<date>2003</date>
<booktitle>In Proceedings of RANLP, Borovets,</booktitle>
<editor>Bulgaria. C. Fellbaum, editor.</editor>
<publisher>The MIT Press.</publisher>
<marker>Daud´e, Padr´o, Rigau, 2003</marker>
<rawString>J. Daud´e, L. Padr´o, and G. Rigau. 2003. Validation and Tuning of Wordnet Mapping Techniques. In Proceedings of RANLP, Borovets, Bulgaria. C. Fellbaum, editor. 1998. WordNet. An Electronic Lexical Database. The MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Leacock</author>
<author>M Chodorow</author>
<author>G Miller</author>
</authors>
<title>Using Corpus Statistics and WordNet Relations for Sense Identification.</title>
<date>1998</date>
<journal>Computational Linguistics,</journal>
<volume>24</volume>
<issue>1</issue>
<contexts>
<context position="10228" citStr="Leacock et al., 1998" startWordPosition="1574" endWordPosition="1578">rd senses as topics. Basically, the acquisition of TS consists of A) acquiring the best possible corpus examples for a particular word sense (usually characterizing each word sense as a query and performing a search on the corpus for those examples that best match the queries), and then, B) building the TS by deriving the context words that best represent the word sense from the selected corpora. For this study, we use the large-scale Topic Signatures acquired from the web (Agirre and de la Calle, 2004) and those acquired from the BNC (Cuadros et al., 2005). • TSWEB3: Inspired by the work of (Leacock et al., 1998), these Topic Signatures were constructed using monosemous relatives from WordNet (synonyms, hypernyms, direct and indirect hyponyms, and siblings), querying Google and retrieving up to one thousand snippets per query (that is, a word sense). In particular, the method was as follows: – Organizing the retrieved examples from the web in collections, one collection per word sense. – Extracting the words and their frequencies for each collection. – Comparing these frequencies with those pertaining to other word senses using TFIDF (see formula 1). – Gathering in an ordered list, the words with dist</context>
</contexts>
<marker>Leacock, Chodorow, Miller, 1998</marker>
<rawString>C. Leacock, M. Chodorow, and G. Miller. 1998. Using Corpus Statistics and WordNet Relations for Sense Identification. Computational Linguistics, 24(1):147–166.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Lin</author>
<author>E Hovy</author>
</authors>
<title>The automated acquisition of topic signatures for text summarization.</title>
<date>2000</date>
<booktitle>In Proceedings of COLING.</booktitle>
<location>Strasbourg, France.</location>
<contexts>
<context position="9477" citStr="Lin and Hovy, 2000" startWordPosition="1441" endWordPosition="1444">ed in WN and XWN. • spBNC (McCarthy, 2001): This knowledge resource contains the selectional preferences acquired from the BNC. • spSemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002): This knowledge resource contains the selectional preferences acquired from SemCor. • spBNC+spSemCor: This knowledge resource uses the selectional preferences acquired from the BNC and SemCor. • MCR (Atserias et al., 2004): This knowledge resource uses the direct relations included in MCR. 2.2 Automatically retrieved Topic Signatures Topic Signatures (TS) are word vectors related to a particular topic (Lin and Hovy, 2000). Topic Signatures are built by retrieving context words of a target topic from large volumes of text. In our case, we consider word senses as topics. Basically, the acquisition of TS consists of A) acquiring the best possible corpus examples for a particular word sense (usually characterizing each word sense as a query and performing a search on the corpus for those examples that best match the queries), and then, B) building the TS by deriving the context words that best represent the word sense from the selected corpora. For this study, we use the large-scale Topic Signatures acquired from </context>
</contexts>
<marker>Lin, Hovy, 2000</marker>
<rawString>C. Lin and E. Hovy. 2000. The automated acquisition of topic signatures for text summarization. In Proceedings of COLING. Strasbourg, France.</rawString>
</citation>
<citation valid="true">
<authors>
<author>B Magnini</author>
<author>G Cavagli`a</author>
</authors>
<title>Integrating subject field codes into wordnet.</title>
<date>2000</date>
<booktitle>In Proceedings of LREC,</booktitle>
<location>Athens. Greece.</location>
<marker>Magnini, Cavagli`a, 2000</marker>
<rawString>B. Magnini and G. Cavagli`a. 2000. Integrating subject field codes into wordnet. In Proceedings of LREC, Athens. Greece.</rawString>
</citation>
<citation valid="true">
<authors>
<author>D McCarthy</author>
</authors>
<title>Lexical Acquisition at the SyntaxSemantics Interface: Diathesis Aternations, Subcategorization Frames and Selectional Preferences.</title>
<date>2001</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Sussex.</institution>
<contexts>
<context position="2860" citStr="McCarthy, 2001" startWordPosition="426" endWordPosition="427">2.0), WordNet passed from 103,445 semantic relations to 204,074 semantic relations1. That is, around twelve thousand semantic relations per year. However, during the last years the research community has devised a large set of innovative processes and tools for large-scale automatic acquisition of lexical knowledge from structured or unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), largescale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or acquired from the BNC (Cuadros et al., 2005). Obviously, all these semantic resources have been acquired using a very different set of methods, tools and corpora, resulting on a different set of new semantic relations between synsets. In fact, each resource has different volume and accuracy figures. Although isolated evaluations have been performed by their developers in different experi1Symmetric relations are counted only once. 534 Proceedings of the 2006 Conference on Empirical Methods in N</context>
<context position="4985" citStr="McCarthy, 2001" startWordPosition="750" endWordPosition="751">ection 3 describes the evaluation framework. Section 4 presents the evaluation results of the different semantic resources considered. Section 5 provides a qualitative assessment of this empirical study and finally, the conclusions and future work are presented in section 6. 2 Large Scale Knowledge Resources This study covers a wide range of large-scale knowledge resources: WordNet (WN) (Fellbaum, 1998), eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002) or acquired from the BNC (McCarthy, 2001), largescale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or acquired from the BNC (Cuadros et al., 2005). However, although these resources have been derived using different WN versions, the research community has the technology for the automatic alignment of wordnets (Daud´e et al., 2003). This technology provides a mapping among synsets of different WN versions, maintaining the compatibility to all the knowledge resources which use a particular WN version as a sense repository. Furthermore, this technology allows to port the knowledge associated to a</context>
<context position="8900" citStr="McCarthy, 2001" startWordPosition="1359" endWordPosition="1360">5 Silver relations from eXtended WN 239,249 Normal relations from eXtended WN 294,488 Total 1,642,389 Table 1: Main sources of semantic relations Type of Relations #relations Total Relations 1,642,389 Different Relations 1,531,380 Unique Relations 1,390,181 Non-unique relations (&gt;1) 70,425 Non-unique relations (&gt;2) 341 Non-unique relations (&gt;3) 8 Table 2: Overlapping relations in the MCR • XWN (Mihalcea and Moldovan, 2001): This knowledge resource uses the direct relations encoded in eXtended WordNet. • XWN+WN: This knowledge resource uses the direct relations included in WN and XWN. • spBNC (McCarthy, 2001): This knowledge resource contains the selectional preferences acquired from the BNC. • spSemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002): This knowledge resource contains the selectional preferences acquired from SemCor. • spBNC+spSemCor: This knowledge resource uses the selectional preferences acquired from the BNC and SemCor. • MCR (Atserias et al., 2004): This knowledge resource uses the direct relations included in MCR. 2.2 Automatically retrieved Topic Signatures Topic Signatures (TS) are word vectors related to a particular topic (Lin and Hovy, 2000). Topic Signatures are </context>
</contexts>
<marker>McCarthy, 2001</marker>
<rawString>D. McCarthy. 2001. Lexical Acquisition at the SyntaxSemantics Interface: Diathesis Aternations, Subcategorization Frames and Selectional Preferences. Ph.D. thesis, University of Sussex.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Mihalcea</author>
<author>D Moldovan</author>
</authors>
<title>extended wordnet: Progress report.</title>
<date>2001</date>
<booktitle>In Proceedings of NAACL Workshop on WordNet and Other Lexical Resources,</booktitle>
<location>Pittsburgh, PA.</location>
<contexts>
<context position="2677" citStr="Mihalcea and Moldovan, 2001" startWordPosition="398" endWordPosition="401">more detailed and rich general-purpose (and also domain-specific) linguistic knowledge built by automatic means. For instance, in more than eight years of manual construction (from version 1.5 to 2.0), WordNet passed from 103,445 semantic relations to 204,074 semantic relations1. That is, around twelve thousand semantic relations per year. However, during the last years the research community has devised a large set of innovative processes and tools for large-scale automatic acquisition of lexical knowledge from structured or unstructured corpora. Among others we can mention eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002) or acquired from British National Corpus (BNC) (McCarthy, 2001), largescale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or acquired from the BNC (Cuadros et al., 2005). Obviously, all these semantic resources have been acquired using a very different set of methods, tools and corpora, resulting on a different set of new semantic relations between synsets. In fact, each resource has different volume and accuracy figures. Although isola</context>
<context position="4824" citStr="Mihalcea and Moldovan, 2001" startWordPosition="725" endWordPosition="728">ledge not provided by the others. This paper is organized as follows: after this introduction, section 2 describes the large-scale knowledge resources studied in this work. Section 3 describes the evaluation framework. Section 4 presents the evaluation results of the different semantic resources considered. Section 5 provides a qualitative assessment of this empirical study and finally, the conclusions and future work are presented in section 6. 2 Large Scale Knowledge Resources This study covers a wide range of large-scale knowledge resources: WordNet (WN) (Fellbaum, 1998), eXtended WordNet (Mihalcea and Moldovan, 2001), large collections of semantic preferences acquired from SemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002) or acquired from the BNC (McCarthy, 2001), largescale Topic Signatures for each synset acquired from the web (Agirre and de la Calle, 2004) or acquired from the BNC (Cuadros et al., 2005). However, although these resources have been derived using different WN versions, the research community has the technology for the automatic alignment of wordnets (Daud´e et al., 2003). This technology provides a mapping among synsets of different WN versions, maintaining the compatibility </context>
<context position="8711" citStr="Mihalcea and Moldovan, 2001" startWordPosition="1328" endWordPosition="1331">relations Princeton WN1.6 138,091 Selectional Preferences from SemCor 203,546 Selectional Preferences from the BNC 707,618 New relations from Princeton WN2.0 42,212 Gold relations from eXtended WN 17,185 Silver relations from eXtended WN 239,249 Normal relations from eXtended WN 294,488 Total 1,642,389 Table 1: Main sources of semantic relations Type of Relations #relations Total Relations 1,642,389 Different Relations 1,531,380 Unique Relations 1,390,181 Non-unique relations (&gt;1) 70,425 Non-unique relations (&gt;2) 341 Non-unique relations (&gt;3) 8 Table 2: Overlapping relations in the MCR • XWN (Mihalcea and Moldovan, 2001): This knowledge resource uses the direct relations encoded in eXtended WordNet. • XWN+WN: This knowledge resource uses the direct relations included in WN and XWN. • spBNC (McCarthy, 2001): This knowledge resource contains the selectional preferences acquired from the BNC. • spSemCor (Agirre and Martinez, 2001; Agirre and Martinez, 2002): This knowledge resource contains the selectional preferences acquired from SemCor. • spBNC+spSemCor: This knowledge resource uses the selectional preferences acquired from the BNC and SemCor. • MCR (Atserias et al., 2004): This knowledge resource uses the di</context>
</contexts>
<marker>Mihalcea, Moldovan, 2001</marker>
<rawString>R. Mihalcea and D. Moldovan. 2001. extended wordnet: Progress report. In Proceedings of NAACL Workshop on WordNet and Other Lexical Resources, Pittsburgh, PA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>P Vossen</author>
<author>editor</author>
</authors>
<date>1998</date>
<booktitle>EuroWordNet: A Multilingual Database with Lexical Semantic Networks.</booktitle>
<publisher>Kluwer Academic Publishers.</publisher>
<marker>Vossen, editor, 1998</marker>
<rawString>P. Vossen, editor. 1998. EuroWordNet: A Multilingual Database with Lexical Semantic Networks. Kluwer Academic Publishers.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>