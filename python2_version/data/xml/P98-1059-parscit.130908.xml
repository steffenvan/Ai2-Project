<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000131">
<title confidence="0.98325">
Spelling Correction Using Context*
</title>
<author confidence="0.929593">
Mohammad Ali Elmi and Martha Evens
</author>
<affiliation confidence="0.979484">
Department of Computer Science, Illinois Institute of Technology
</affiliation>
<address confidence="0.790223">
10 West 31 Street, Chicago, Illinois 60616 (csevens@minnalitedu)
</address>
<sectionHeader confidence="0.91303" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999993090909091">
This paper describes a spelling correction system
that functions as part of an intelligent tutor that car-
ries on a natural language dialogue with its users.
The process that searches the lexicon is adaptive as
is the system filter, to speed up the process. The
basis of our approach is the interaction between the
parser and the spelling corrector. Alternative cor-
rection targets are fed back to the parser, which
does a series of syntactic and semantic checks,
based on the dialogue context, the sentence con-
text, and the phrase context.
</bodyText>
<sectionHeader confidence="0.998656" genericHeader="keywords">
1. Introduction
</sectionHeader>
<bodyText confidence="0.998935275862069">
This paper describes how context-dependent spell-
ing correction is performed in a natural language
dialogue system under control of the parser. Our
spelling correction system is a functioning part of
an intelligent tutoring system called Circsim-Tutor
[Elmi, 94] designed to help medical students learn
the language and the techniques for causal reason-
ing necessary to solve problems in cardiovascular
physiology. The users type in answers to questions
and requests for information.
In this kind of man-machine dialogue, spelling
correction is essential. The input is full of errors.
Most medical students have little experience with
keyboards and they constantly invent novel abbre-
viations. After typing a few characters of a long
word, users often decide to quit. Apparently, the
user types a few characters and decides that (s)he
has given the reader enough of a hint, so we get
&apos;spec&apos; for &apos;specification.&apos; The approach to spelling
correction is necessarily different from that used in
word processing or other authoring systems, which
submit candidate corrections and ask the user to
make a selection. Our system must make automatic
corrections and make them rapidly since the sys-
tem has only a few seconds to parse the student
input, update the student model, plan the appropri-
ate response, turn it into sentences, and display
those sentences on the screen.
Our medical sublanguage contains many long
</bodyText>
<footnote confidence="0.5990746">
*This work was supported by the Cognitive Science Pro-
gram, Office of Naval Research under Grant No. N00014-94-
1-0338, to Illinois Institute of Technology. The content does
not reflect the position or policy of the government and no
official endorsement should be inferred.
</footnote>
<bodyText confidence="0.999860076923077">
phrases that are used in the correction process. Our
filtering system is adaptive; it begins with a wide
acceptance interval and tightens the filter as better
candidates appear. Error weights are position-sen-
sitive. The parser accepts several replacement can-
didates for a misspelled string from the spelling
corrector and selects the best by applying syntactic
and semantic rules. The selection process is
dynamic and context-dependent. We believe that
our approach has significant potential applications
to other types of man-machine dialogues, espe-
cially speech-understanding systems. There are
about 4,500 words in our lexicon.
</bodyText>
<sectionHeader confidence="0.961885" genericHeader="introduction">
2. Spelling Correction Method
</sectionHeader>
<bodyText confidence="0.994071">
The first step in spelling correction is the detection
of an error. There are two possibilities:
</bodyText>
<listItem confidence="0.8983038">
1. The misspelled word is an isolated word, e.g.
&apos;teh&apos; for &apos;the.&apos; The Unix spell program is based on
this type of detection.
2. The misspelled word is a valid word, e.g. &apos;of in
place of &apos;if.&apos; The likelihood of errors that occur
</listItem>
<bodyText confidence="0.9991271">
when words garble into other words increases as
the lexicon gets larger [Peterson 86]. Golding and
Schabes [96] present a system based on trigrams
that addresses the problem of correcting spelling
errors that result in a valid word.
We have limited the detection of spelling errors
to isolated words. Once the word S is chosen for
spelling correction, we perform a series of steps to
find a replacement candidate for it. First, a set of
words from the lexicon is chosen to be compared
with S. Second, a configurable number of words
that are close to S are considered as candidates for
replacement. Finally, the context of the sentence is
used for selecting the best candidate; syntactic and
semantic information, as well as phrase lookup,
can help narrow the number of candidates.
The system allows the user to set the limit on
the number of errors. When the limit is set to k, the
program finds all words in the lexicon that have up
to k mismatches with the misspelled word.
</bodyText>
<sectionHeader confidence="0.971222" genericHeader="method">
3. Algorithm for Comparing Two Words
</sectionHeader>
<bodyText confidence="0.999078">
This process, given the erroneous string S and the
word from the lexicon W, makes the minimum
number of deletions, insertions, and replacements
in S to transform it to W. This number is referred to
</bodyText>
<page confidence="0.995166">
360
</page>
<bodyText confidence="0.977324958333333">
as the edit distance. The system ignores character
case mismatch. The error categories are:
Error Type Example
reversed order haert heart
missing character hert heart
added character hueart heart
char. substitution huart heart
We extended the edit distance by assigning
weights to each correction which takes into account
the position of the character in error. The error
weight of 90 is equivalent to an error distance of
one. If the error appears at the initial position, the
error weight is increased by 10%. In character sub-
stitution if the erroneous character is a neighboring
key of the character on the keyboard, or if the char-
acter has a similar sound to that of the substituted
character, the error weight is reduced by 10%.
3.1 Three Way Match Method. Our string com-
parison is based on the system developed by Lee
and Evens [92]. When the character at location n of
S does not match the character at location m of W,
we have an error and two other comparisons are
made. The three way comparison, and the order of
the comparison is shown below:
</bodyText>
<table confidence="0.904378714285714">
Comparison name Comparison number
1 2 3
no error T — —
reversed order F T T
missing character F F T
added character F T F
char. substitution F F F
</table>
<bodyText confidence="0.993788673913044">
For example, to convert the misspelled string
hoose to choose, the method declares missing char-
acter &apos;c&apos; in the first position since the character h in
hoose matches the second character in choose.
The three way match (3wm) is a fast and simple
algorithm with a very small overhead. However, it
has potential problems [Elmi, 94]. A few examples
are provided to illustrate the problem, and then our
extension to the algorithm is described. Let char(n)
indicate the character at location n of the erroneous
word, and char(m) indicate the character at location
m of the word from the lexicon.
3.1.1 Added Character Error. If the character o
of choose is replaced with an a, we get: chaose. The
3wm transforms choose to choose in two steps:
drops a and inserts an o.
Solution: When the 3wm detects an added char-
acter error, and char(n+1)=char(m+1) and
char(n+2)# char(m+1), we change the error to
character substitution type. The algorithm replaces
&apos;a&apos; with an &apos;o&apos; in chaose to correct it to choose.
3.1.2 Missing Character Error. If o in choose
is replaced with an we we get the string: chosse. The
3wm method converts chosse to choose in two
steps: insert &apos;o&apos; and drop the second s.
Solution: When the 3wm detects a missing
character and char(n+1)=char(m+1), we check for
the following conditions: char(n+1)#char(m+2), or
char(n+2)=char(m+2). In either case we change the
error to &amp;quot;character substitution&amp;quot;. The algorithm
replaces &apos;s&apos; with &apos;o&apos; in chose to correct it to
choose. Without the complementary conditions, the
algorithm does not work properly for converting
coose to choose, instead of inserting an h, it
replaces o with an h, and inserts an o before s.
3.1.3 Reverse Order Error. If a in canary is
dropped, we get: cnary. The 3wm converts cnary to
canary with two transformations: 1) reverse order
&apos;I&apos;m&apos;: cry and 2) insert an &apos;a&apos;: canary.
Similarly, if the character a is added to unary,
we get the string: uanary. The 3wm converts
uanary to unary with two corrections: 1) reverse
order &apos;an&apos;: unaary and 2) drop the second &apos;a&apos;:
unary.
Solution: When the 3wm detects a reverse order
and char(n+2) # char(m+2), we change the error to:
</bodyText>
<listItem confidence="0.997405857142857">
• Missing character error: if char(n+1) =
char(m+2). Insert char(m) at location n of the
misspelled word. The modified algorithm
inserts &apos;a&apos; in cnary to correct it to canary.
• Added character error: if char(n+2) =
char(m+1). Drop char(n). The algorithm drops
&apos;a&apos; in uanary to correct it to unary.
</listItem>
<subsubsectionHeader confidence="0.444052">
3.1.4 Two Mismatching Characters. The final
</subsubsectionHeader>
<bodyText confidence="0.9894586">
caveat in the three way match algorithm is that the
algorithm cannot handle two or more consecutive
errors. If the two characters at locations n and n+1
of S are extra characters, or the two characters at
locations m and m+1 of Ware missing in S. we get
to an obvious index synchronization, and we have
a disaster. For example, the algorithm compares
enabcyclopedic to encyclopedic and reports nine
substitutions and two extra characters.
Handling errors of this sort is problematic for
</bodyText>
<page confidence="0.994024">
361
</page>
<bodyText confidence="0.999981230769231">
many spelling corrector systems. For instance,
both FrameMalcer (Release 5) and Microsoft Word
(Version 7.0a) detect enabcyclopedic as an error,
but both fail to correct it to anything. Also, when
we delete the two characters `ye in encyclopedic,
Microsoft Word detects enclopedic as an error but
does not give any suggestions. FrameMaker
returns: inculpated, uncoupled, and encapsulated.
Solution: When comparing S with W we parti-
tion them as S=xuz and W=xvz. Where x is the ini-
tial segment, z is the tail segment, u and v are the
error segments. First, the initial segment is
selected. This segment can be empty if the initial
characters of S and W do not match. In an unlikely
case that S=W, this segment will contain the whole
word. Second, the tail segment is selected, and can
be empty if the last characters of S and W are dif-
ferent. Finally, the error segments are the remain-
ing characters of the two words:
Using the modified algorithm, to compare the
string enabcyclopedic, to the word encyclopedic, the
matching initial segment is en and the matching tail
segment is cyclopedic. The error segment for the
misspelled word is ab and it is empty for encyclope-
dic. Therefore, the system concludes that there are
two extra characters ab in enabcyclopedic.
</bodyText>
<sectionHeader confidence="0.519994" genericHeader="method">
4. Selection of Words from the Lexicon
</sectionHeader>
<bodyText confidence="0.999050625">
To get the best result, the sure way is to compare
the erroneous word S with all words in the lexicon.
As the size of the lexicon grows, this method
becomes impractical since many words in a large
lexicon are irrelevant to S. We have dealt with this
problem in three ways.
4.1 Adaptive Disagreement Threshold. In order
to reduce the time spent on comparing S with irrel-
evant words from the lexicon, we put a limit on the
number of mismatches depending on the size of S.
The disagreement threshold is used to terminate
the comparison of an irrelevant word with S, in
effect acting as a filter. If the number is too high (a
loose filter), we get many irrelevant words. If the
number is too low (a tight filter), a lot of good can-
didates are discarded. For this reason, we use an
adaptive method that dynamically lowers the toler-
ance for errors as better replacement candidates are
found.
The initial disagreement limit is set depending
on the size of 5: 100 for one character strings, 51*
length of S for two or more character strings. As
the two words are compared, the program keeps
track of the error weight. As soon as the error
weight exceeds this limit, the comparison is termi-
nated and the word from the lexicon is rejected as a
replacement word. Any word with error weight
less than the disagreement limit is a candidate and
is loaded in the replacement list. After the replace-
ment list is fully loaded, the disagreement limit is
lowered to the maximum value of disagreement
amongst the candidates found so far.
</bodyText>
<subsectionHeader confidence="0.81641">
4.2 Use of the Initial Character. Many studies
</subsectionHeader>
<bodyText confidence="0.999994866666667">
show that few errors occur in the first letter of a
word. We have exploited this characteristic by
starting the search in the lexicon with words hav-
ing the same initial letter as the misspelled word.
The lexicon is divided into 52 segments (26
lower case, 26 upper case) each containing all the
words beginning with a particular character.
Within each segment the words are sorted in
ascending order of their character length. This
effectively partitions the lexicon into subsegments
(314 in our lexicon) that each contains words with
the same first letter and the same character size:
The order of the search in the lexicon is depen-
dent on the first letter of the misspelled word, chr.
The segments are dynamically linked as follows:
</bodyText>
<listItem confidence="0.9899624">
1. The segment with the initial character chr.
2. The segment with the initial character as reverse
case of chr.
3. The segments with a neighboring character of chr
as the initial character in a standard keyboard.
4. The segments with an initial character that has a
sound similar to chr.
5. The segment with the initial character as the
second character of the misspelled word.
6. The rest of the segments.
</listItem>
<subsectionHeader confidence="0.810415">
4.3 Use of the Word Length. When comparing
</subsectionHeader>
<bodyText confidence="0.99987025">
the misspelled string S with length len to the word
W of the lexicon with length len+j, in the best case
scenario, we have at least j missing characters in S
for positive value off, and j extra characters in S
</bodyText>
<figure confidence="0.996988083333334">
initial
segment
error segment in S
error segment in W
tail
segment
words of
length /
words of
length 2
words of
length n
</figure>
<page confidence="0.994289">
362
</page>
<bodyText confidence="0.99997115">
for negative value of j. With the initial error weight
of 51*Ien, the program starts with the maximum
error limit of limit=len/2. We only allow compari-
son of words from the lexicon with the character
length between len-limit and len+limit.
Combining the search order with respect to the
initial character and the word length limit, the cor-
rection is done in multiple passes. In each alpha-
betical segment of the lexicon, S is compared with
the words in the subsegments containing the words
with length ler.± i, where 0 i 5_ limit. For each
value of i there is at least i extra characters in S
compared to a word of length len-i. Similarly, there
is at least i missing characters in S compared to a
word of length len+i. Therefore, for each i in the
subsegments containing the words with length
len± i, we find all the words with error distance of i
or higher. At any point when the replacement list is
loaded with words with the maximum error dis-
tance of i the program terminates.
</bodyText>
<sectionHeader confidence="0.899006" genericHeader="method">
5. Abbreviation Handling
</sectionHeader>
<bodyText confidence="0.9994852">
Abbreviations are considered only in the segments
with the same initial character as the first letter of
the misspelled word and its reverse character case.
In addition to the regular comparison of the
misspelled string S with the words with the charac-
ter length between len-limit and len+limit, for each
word W of the lexicon with the length len+m where
m&gt;/imit, we compare its first len characters to S. If
there is any mismatch, W is rejected. Otherwise, S
is considered an abbreviation of W.
</bodyText>
<sectionHeader confidence="0.914009" genericHeader="method">
6. Word Boundary Errors
</sectionHeader>
<bodyText confidence="0.999904666666667">
Word boundaries are defined by space characters
between two words. The addition or absence of the
space character is the only error that we allow in
the word boundary errors. The word boundary
errors are considered prior to regular spelling cor-
rections in the following steps:
</bodyText>
<listItem confidence="0.9778109375">
1. S is split into two words with character lengths n,
and m, where n+m=len and 15.n&lt;len. If both of
these two words are valid words, the process ter-
minates and returns the two split words. For ex-
ample, `upto&apos; will be split into `ti pto&apos; for n=1, &apos;IT
to&apos; for n=2. At this point since both words &apos;up&apos;
and &apos;to&apos; are valid words, the process terminates.
2. Concatenate S with the next input word S2. If the
result is a valid word, return the result as the
replacement for S and S2. For example, the string
`specifi&apos; in &apos;,pec (ft cation&apos; is detected as an error
and is combined with &apos;cation&apos; to produce the word
&apos;specification.&apos; Otherwise,
3. Concatenate S with the previous input word Sp If
the result is a valid word, return the result as the
replacement for S and S1. For example, in the
</listItem>
<bodyText confidence="0.8584104">
input &apos;specific ation&apos; the word &apos;specific&apos; is a valid
word and we realize we have a misspelled word
when we get to &apos;ation.&apos; In this case, &apos;ation&apos; is
combined with the previous word &apos;specific&apos; and
the valid word &apos;speccation&apos; is returned.
</bodyText>
<subsectionHeader confidence="0.607941">
7. Using the Context
</subsectionHeader>
<bodyText confidence="0.999442">
It is difficult to arrive at a perfect match for a mis-
spelled word most of the time. Kukich [92] points
out that most researchers report accuracy levels
above 90% when the first three candidates are con-
sidered instead of the first guess. Obviously, the
syntax of the language is useful for choosing the
best candidate among a few possible matching
words when there are different parts of speech
among the candidates. Further help can be obtained
by applying semantic rules, like the tense of the
verb with respect to the rest of the sentence, or
information about case arguments.
This approach is built on the idea that the parser
is capable of handling a word with multiple parts
of speech and multiple senses within a part of
speech [Elmi and Evens 93]. The steps for spelling
correction and the choice of the best candidates are
organized as follows:
</bodyText>
<listItem confidence="0.995509777777778">
1. Detection: The lexical analyzer detects that the
next input word w is misspelled.
2. Correction: The spelling corrector creates a list
of replacement words: ((wi el)... (w nen)), where wi
is a replacement word, and ei is the associated
error weight. The list is sorted in ascending order
of ei. The error weights are dropped, and the
replacement list (wi wi ...) is returned.
3. Reduction: The phrase recognizer checks
</listItem>
<bodyText confidence="0.977655666666667">
whether any word in the replacement list can be
combined with the previous/next input word(s) to
form a phrase. If a phrase can be constructed, the
word that is used in the phrase is considered the
only replacement candidate and the rest of the
words in the replacement list are ignored.
</bodyText>
<listItem confidence="0.5461705">
4. Part of speech assignment: If w. has n parts of
speech: p „ p2 pn the lexical analyzer replaces wi
in the list with: (pi w) (p2 wd... (pn wd. Then,
factors out the common part of speech, p, in: (p w)
(p wd as: (p w, w). The replacement list: ((pi wi
(p2 wkw,n...)...) is passed to the parser.
5. Syntax analysis: The parser examines each
sublist (p w, w3...) of replacement list for the part
of speech p and discards the sublists that violate
the syntactic rules. In each parse tree a word can
</listItem>
<page confidence="0.998608">
363
</page>
<bodyText confidence="0.981824">
have a single part of speech, so no two sublists of
the replacement list are in the same parse tree.
</bodyText>
<listItem confidence="0.812488">
6. Semantic analysis: If wi has n senses (s1, s2, s,,)
</listItem>
<bodyText confidence="0.963505666666667">
with the part of speech p, and wj has m senses (ti,
t2, t,n) with the part of speech p, the sublist (p
w. ...) is replaced with (p sj,s2, sn, tj, t2,
The semantic analyzer works with one parse tree
at a time and examines all senses of the words and
rejects any entry that violates the sematic rules.
</bodyText>
<sectionHeader confidence="0.844908" genericHeader="method">
8. Empirical Results from Circsim-Tutor
</sectionHeader>
<bodyText confidence="0.999924882352941">
We used the text of eight sessions by human tutors
and performed the spelling correction. The text
contains 14,703 words. The program detected 684
misspelled words and corrected all of them but two
word boundary errors. There were 336 word
boundary errors, 263 were split words that were
joined (e.g., &apos;nerv&apos; and &apos;ous&apos; for nervous) and 73
were joined words that were split (e.g., ofone for
&apos;of and &apos;one&apos;). Also, 60 misspelled words were
part of a phrase. Using phrases, the system cor-
rected &apos;end dia volum&apos; to: &apos;end diastolic volume.&apos;
The two word boundary failures resulted from
the restriction of not having any error except the
addition or the absence of a space character. The
system attempts to correct them individually:
... quite a sopfh isticated one ...
.... is a deter miniic statement ...
</bodyText>
<sectionHeader confidence="0.665874" genericHeader="evaluation">
9. Performance with a Large Lexicon
</sectionHeader>
<bodyText confidence="0.999928878048781">
To discover whether this approach would scale up
successfully we added 102,759 words from the
Collins English Dictionary to our lexicon. The new
lexicon contains 875 subsegments following the
technique described in section 4.2.
Consider the misspelled string ater [Kukich,
92]. The program started the search in the subseg-
ments with character length of 3, 4, and 5 and
returned: Axer Aten Auer after alter aster ate aver
Later water. Note that character case is ignored.
Overall, the program compared 3,039 words
from the lexicon to &apos;ater&apos;, eliminating the compari-
son of 99,720 (102759-3039) irrelevant words.
Only the segments with the initial characters
&apos;aAqwszQWSZe were searched. Note that charac-
ters &apos;qwsz&apos; are adjacent keys to `a.&apos; With the early
termination of irrelevant words, 1,810 of these
words were rejected with the comparison of the
second character. Also, 992 of the words were
rejected with the comparison of the third character.
This took 90 milliseconds in a PC using the Alle-
gro Common Lisp.
We looked for all words in the lexicon that have
error distance of one from ater. The program used
12,780 words of length 3, 4, and 5 character to find
the following 16 replacement words: Ayer Aten
Auer after alter aster ate aver cater eater eter later
mater pater tater water. Out of these 12,780 words,
11,132 words were rejected with the comparison of
the second character and 1,534 with the compari-
son of the third character.
Finally, lets look at an example with the error in
the first position. The program corrected the mis-
spelled string: `rogram&apos; into: grogram program
engram roam isogram ogham pogrom. It used
32,128 words from the lexicon. Out of these
32,128 words, 3,555 words were rejected with the
comparison of the second character, 21,281 words
were rejected with the comparison of the third
character, 5,778 words were rejected at the fourth
character, and 1,284 at the fifth character.
</bodyText>
<sectionHeader confidence="0.9701" genericHeader="conclusions">
10. Summary
</sectionHeader>
<bodyText confidence="0.9999397">
Our spelling correction algorithm extends the three
way match algorithm and deals with word bound-
ary problems and abbreviations. It can handle a
very large lexicon and uses context by combining
parsing and spelling correction.
The first goal of our future research is to detect
errors that occur when words garble into other
words in the lexicon, as form into from. We think
that our approach of combining the parser and the
spelling correction system should help us here.
</bodyText>
<sectionHeader confidence="0.961909" genericHeader="references">
11. References
</sectionHeader>
<reference confidence="0.999528272727273">
Elmi, M. 1994. A Natural Language Parser with
Interleaved Spelling Correction, Supporting Lex-
ical Functional Grammar and Ill-formed Input.
Ph.D. Dissertation, Computer Science Dept., Illi-
nois Institute of Technology, Chicago, IL.
Elmi, M., Evens, M. 1993. An Efficient Natural
Language Parsing Method. Proc. 5th Midwest
Artificial Intelligence and Cognitive Science
Conference, April, Chesterton, IN, 6-10.
Golding, A., Schabes, Y., 1996. Combining Tri-
gram-based and Feature-based Methods for Con-
text-Sensitive Spelling Correction. Proc. 34&amp;quot;
ACL, 24-27 June, 71-78.
Kukich, K. 1992. Techniques for Automatically
Correcting Words in Text. ACM Computing Sur-
veys, Vol. 24, No. 4, 377-439.
Lee, Y., Evens, M. 1992. I11-Formed Natural Input
Handling System for an Intelligent Tutoring Sys-
tem. The Second Pacific Rim Int. Conf. on Al.
Seoul, Sept 15-18, 354-360.
Peterson, J. 1986. A Note on Undetected Typing
Errors. Commun. ACM, Vol. 29, No. 7, 633-637.
</reference>
<page confidence="0.998953">
364
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.579946">
<title confidence="0.999611">Correction Using</title>
<author confidence="0.999835">Ali Elmi Evens</author>
<affiliation confidence="0.999965">Department of Computer Science, Illinois Institute of Technology</affiliation>
<address confidence="0.970746">10 West 31 Street, Chicago, Illinois 60616 (csevens@minnalitedu)</address>
<abstract confidence="0.965383666666667">This paper describes a spelling correction system that functions as part of an intelligent tutor that carries on a natural language dialogue with its users. The process that searches the lexicon is adaptive as is the system filter, to speed up the process. The basis of our approach is the interaction between the parser and the spelling corrector. Alternative correction targets are fed back to the parser, which does a series of syntactic and semantic checks, based on the dialogue context, the sentence context, and the phrase context.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>M Elmi</author>
</authors>
<title>A Natural Language Parser with Interleaved Spelling Correction, Supporting Lexical Functional Grammar and Ill-formed Input.</title>
<date>1994</date>
<tech>Ph.D. Dissertation,</tech>
<institution>Computer Science Dept., Illinois Institute of Technology,</institution>
<location>Chicago, IL.</location>
<marker>Elmi, 1994</marker>
<rawString>Elmi, M. 1994. A Natural Language Parser with Interleaved Spelling Correction, Supporting Lexical Functional Grammar and Ill-formed Input. Ph.D. Dissertation, Computer Science Dept., Illinois Institute of Technology, Chicago, IL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Elmi</author>
<author>M Evens</author>
</authors>
<title>An Efficient Natural Language Parsing Method.</title>
<date>1993</date>
<booktitle>Proc. 5th Midwest Artificial Intelligence and Cognitive Science Conference,</booktitle>
<pages>6--10</pages>
<location>April, Chesterton, IN,</location>
<marker>Elmi, Evens, 1993</marker>
<rawString>Elmi, M., Evens, M. 1993. An Efficient Natural Language Parsing Method. Proc. 5th Midwest Artificial Intelligence and Cognitive Science Conference, April, Chesterton, IN, 6-10.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Golding</author>
<author>Y Schabes</author>
</authors>
<title>Combining Trigram-based and Feature-based Methods for Context-Sensitive Spelling Correction.</title>
<date>1996</date>
<booktitle>Proc. 34&amp;quot; ACL,</booktitle>
<pages>24--27</pages>
<marker>Golding, Schabes, 1996</marker>
<rawString>Golding, A., Schabes, Y., 1996. Combining Trigram-based and Feature-based Methods for Context-Sensitive Spelling Correction. Proc. 34&amp;quot; ACL, 24-27 June, 71-78.</rawString>
</citation>
<citation valid="true">
<authors>
<author>K Kukich</author>
</authors>
<title>Techniques for Automatically Correcting Words in Text.</title>
<date>1992</date>
<journal>ACM Computing Surveys,</journal>
<volume>24</volume>
<pages>377--439</pages>
<marker>Kukich, 1992</marker>
<rawString>Kukich, K. 1992. Techniques for Automatically Correcting Words in Text. ACM Computing Surveys, Vol. 24, No. 4, 377-439.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Y Lee</author>
<author>M Evens</author>
</authors>
<title>I11-Formed Natural Input Handling System for an Intelligent Tutoring System. The Second Pacific Rim Int.</title>
<date>1992</date>
<booktitle>Conf. on Al. Seoul,</booktitle>
<pages>354--360</pages>
<marker>Lee, Evens, 1992</marker>
<rawString>Lee, Y., Evens, M. 1992. I11-Formed Natural Input Handling System for an Intelligent Tutoring System. The Second Pacific Rim Int. Conf. on Al. Seoul, Sept 15-18, 354-360.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Peterson</author>
</authors>
<title>A Note on Undetected Typing Errors.</title>
<date>1986</date>
<journal>Commun. ACM,</journal>
<volume>29</volume>
<pages>633--637</pages>
<marker>Peterson, 1986</marker>
<rawString>Peterson, J. 1986. A Note on Undetected Typing Errors. Commun. ACM, Vol. 29, No. 7, 633-637.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>