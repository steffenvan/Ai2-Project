<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000014">
<title confidence="0.992538">
Optimal Shift-Reduce Constituent Parsing with Structured Perceptron
</title>
<author confidence="0.996919">
Le Quang Thang
</author>
<affiliation confidence="0.9384715">
Hanoi University of Science
and Technology
</affiliation>
<email confidence="0.987793">
{lelightwin@gmail.com}
</email>
<sectionHeader confidence="0.997217" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9998274">
We present a constituent shift-reduce
parser with a structured perceptron that
finds the optimal parse in a practical run-
time. The key ideas are new feature tem-
plates that facilitate state merging of dy-
namic programming and A* search. Our
system achieves 91.1 F1 on a standard
English experiment, a level which cannot
be reached by other beam-based systems
even with large beam sizes.1
</bodyText>
<sectionHeader confidence="0.999392" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.99995232">
A parsing system comprises two components: a
scoring model for a tree and a search algorithm.
In shift-reduce parsing, the focus of most previ-
ous studies has been the former, typically by en-
riching feature templates, while the search quality
has often been taken less seriously. For example,
the current state-of-the-art parsers for constituency
(Zhu et al., 2013; Wang and Xue, 2014) and de-
pendency (Bohnet et al., 2013) both employ beam
search with a constant beam size, which may suf-
fer from severe search errors. This is contrary to
ordinary PCFG parsing which, while it often uses
some approximations, has nearly optimal quality
(Petrov and Klein, 2007).
In this paper, we instead investigate the question
of whether we can obtain a practical shift-reduce
parser with state-of-the-art accuracy by focusing
on optimal search quality like PCFG parsing. We
base our system on best-first search for shift-
reduce parsing formulated in Zhao et al. (2013),
but it differs from their approach in two points.
First, we focus on constituent parsing while they
use dependency grammar. Second, and more cru-
cially, they use a locally trained MaxEnt model,
which is simple but not strong, while we explore
</bodyText>
<footnote confidence="0.993193">
1The open source software of our system is available at
https://github.com/mynlp/optsr.
</footnote>
<author confidence="0.660206">
Hiroshi Noji and Yusuke Miyao
</author>
<affiliation confidence="0.8578115">
National Institute of Informatics,
The Graduate University for
</affiliation>
<address confidence="0.529495">
Advanced Studies
</address>
<email confidence="0.965874">
{noji,yusuke}@nii.ac.jp
</email>
<bodyText confidence="0.999930142857143">
a structured perceptron, the current state-of-the-art
in shift-reduce parsing (Zhu et al., 2013).
As we will see, this model change makes search
quite hard, which motivates us to invent new fea-
ture templates as well as to improve the search
algorithm. In existing parsers, features are com-
monly exploited from the parsing history, such
as the top k elements on the stack. However,
such features are expensive in terms of search ef-
ficiency. Instead of relying on features primarily
from the stack, our features mostly come from the
span of the top few nodes, an idea inspired by the
recent empirical success in CRF parsing (Hall et
al., 2014). We show that these span features also
fit quite well in the shift-reduce system and lead
to state-of-the-art accuracy. We further improve
search with new A* heuristics that make optimal
search for shift-reduce parsers with a structured
perceptron tractable for the first time.
The primary contribution of this paper is to
demonstrate the effectiveness and the practicality
of optimal search for shift-reduce parsing, espe-
cially when combined with appropriate features
and efficient search. In English Penn Treebank ex-
periments, our parser achieves an F1 score of 91.1
on test set at a speed of 13.6 sentences per second.
This score is in excess of that of a beam-based sys-
tem with larger beam size and same speed.
</bodyText>
<sectionHeader confidence="0.976322" genericHeader="introduction">
2 Background and Related Work
</sectionHeader>
<subsectionHeader confidence="0.983142">
2.1 Shift-Reduce Constituent Parsing
</subsectionHeader>
<bodyText confidence="0.999806222222222">
We first introduce the shift-reduce algorithm for
constituent structures. For space reasons, our ex-
position is rather informal; See Zhang and Clark
(2009) for details. A shift-reduce parser parses a
sentence through transitions between states, each
of which consists of two data structures of a stack
and a queue. The stack preserves intermediate
parse results, while the queue saves unprocessed
tokens. At each step, a parser selects an action,
</bodyText>
<page confidence="0.951107">
1534
</page>
<note confidence="0.976788333333333">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing, pages 1534–1544,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</note>
<bodyText confidence="0.999951857142857">
which changes the current state into the new one.
For example, SHIFT pops the front word from the
queue and pushes it onto the stack, while RE-
DUCE(X) combines the top two elements on the
stack into their parent.2 For example, if the top
two elements on the stack are DT and NN, RE-
DUCE(NP) combines these by applying the CFG
rule NP —* DT NN.
Unary Action The actions above are essentially
the same as those in shift-reduce dependency pars-
ing (Nivre, 2008), but a special action for con-
stituent parsing UNARY(X) complicates the sys-
tem and search. For example, if the top element
on the stack is NN, UNARY(NP) changes it to NP
by applying the rule NP —* NN. In particular, this
causes inconsistency in the numbers of actions be-
tween derivations (Zhu et al., 2013), which makes
it hard to apply the existing best first search for de-
pendency grammar to our system. We revisit this
problem in Section 3.1.
Model The model of a shift-reduce parser gives
a score to each derivation, i.e., an action sequence
a = (a1, · · · , a|a|), in which each ai is a shift or
reduce action. Let p = (p1, · · · , p|a|) be the se-
quence of states, where pi is the state after apply-
ing ai to pi−1. p0 is the initial state for input sen-
tence w. Then, the score for a derivation Φ(a) is
calculated as the total score of every action:
</bodyText>
<equation confidence="0.975185">
Φ(a) = � φ(ai,pi−1). (1)
1&lt;i&lt;|a|
</equation>
<bodyText confidence="0.9996926">
There are two well-known models, in which the
crucial difference is in training criteria. The Max-
Ent model is trained locally to select the correct
action at each step. It assigns a probability for each
action ai as
</bodyText>
<equation confidence="0.994497">
P(ai|pi−1) a exp(BTf(ai,pi−1)), (2)
</equation>
<bodyText confidence="0.996810333333333">
where B and f(a, p) are weight and feature vec-
tors, respectively. Note that the probability of an
action sequence a under this model is the product
of local probabilities, though we can cast the total
score in summation form (1) by using the log of
(2) as a local score φ(ai, pi−1).
The structured perceptron is instead trained
globally to select the correct action sequence given
an input sentence. It does not use probability and
</bodyText>
<footnote confidence="0.993727">
2Many existing constituent parsers use two kinds of re-
duce actions for selecting the direction of its head child while
we do not distinguish these two. In our English experiments,
we found no ambiguity for head selection in our binarized
grammar (See Section 4).
</footnote>
<bodyText confidence="0.994088090909091">
the local score is just φ(ai, pi−1) = BTf(ai, pi−1).
In practice, this global model is much stronger
than the local MaxEnt model. However, train-
ing this model without any approximation is hard,
and the common practice is to rely on well-known
heuristics such as an early update with beam
search (Collins and Roark, 2004). We are not
aware of any previous study that succeeded in
training a structured perceptron for parsing with-
out approximation. We will show how this be-
comes possible in Section 3.
</bodyText>
<subsectionHeader confidence="0.999763">
2.2 Previous Best-First Shift-Reduce Parsing
</subsectionHeader>
<bodyText confidence="0.999995315789474">
The basic idea behind best-first search (BFS) for
shift-reduce parsing is assuming each parser state
as a node on a graph and then searching for the
minimal cost path from a start state (node) to the
final state. This is the idea of Sagae and Lavie
(2006), and it was later refined by Zhao et al.
(2013). BFS gives a priority to each state, and a
state with the highest priority (lowest cost) is al-
ways processed first. BFS guarantees that the first
found goal is the best (optimality) if the superior-
ity condition is satisfied: a state never has a lower
cost than the costs of its previous states.
Though the found parse is guaranteed to be op-
timal, in practice, current BFS-based systems are
not stronger than other systems with approximate
search (Zhu et al., 2013; Wang and Xue, 2014)
since all existing systems are based on the MaxEnt
model. With this model, the speriority can easily
be accomplished by using the negative log of (2),
which is always positive and becomes smaller with
higher probability. We focus instead on the struc-
tured perceptron, but achieving superiority with
this model is not trivial. We resolve this problem
in Section 3.1.
In addition to the mathematical convenience,
the MaxEnt model itself helps search. Sagae and
Lavie ascribe the empirical success of their BFS to
the sparseness of the distribution over subsequent
actions in the MaxEnt model. In other words,
BFS is very efficient when only a few actions have
dominant probabilities in each step, and the Max-
Ent model facilitates this with its exponential oper-
ation (2). Unfortunately, this is not the case in our
global structured perceptron because the score of
each action is just the sum of the feature weights.
Resolving this search difficulty is the central prob-
lem of this paper; we illustrate this problem in Sec-
tion 4 and resolve it in Section 5.
</bodyText>
<page confidence="0.982834">
1535
</page>
<subsectionHeader confidence="0.994112">
2.3 Hypergraph Search of Zhao et al. (2013)
</subsectionHeader>
<bodyText confidence="0.999968341463415">
The worst time complexity of BFS in Sagae and
Lavie (2006) is exponential. For dependency pars-
ing, Zhao et al. (2013) reduce it to polynomial by
converting the search graph into a hypergraph by
using the state merging technique of Huang and
Sagae (2010). This hypergraph search is the basis
of our parser, so we will briefly review it here.
The algorithm is closely related to agenda-
based best-first parsing algorithms for PCFGs
(Klein and Manning, 2001; Pauls and Klein,
2009). As in those algorithms, it maintains two
data structures: a chart C that preserves processed
states as well as a priority queue (agenda) Q. The
difference is in the basic items processed in C and
Q. In PCFG parsing, they are spans. Each span
abstracts many derivations on that span and the
chart maps a span to the best (lowest cost) deriva-
tion found so far. In shift-reduce parsing, the basic
items are not spans but states, i.e., partial represen-
tations of the stack.3 We denote p = (i, j, sd...s0)
where si is the i-th top subtree on the stack and s0
spans i to j. We extract features from sd...s0. Note
that d is constant and a state usually does not con-
tain full information about a derivation. In fact, it
only keeps atomic features, the minimal informa-
tion on the stack necessary to recover the full fea-
tures and packs many derivations. The chart maps
a state to the current best derivation. For example,
if we extract features only from the root symbol of
s0, each state looks the same as a span of PCFGs.
Differently from the original shift-reduce algo-
rithm, during this search, reduce actions are de-
fined between two states p and q. The basic oper-
ation of the algorithm is to pop the best (top) state
p from the queue, push it into the chart, and then
enqueue every state that can be obtained by a re-
duce action between p and other states in the chart
or a shift action from p. The left states L(p) and
right states R(p) are important concepts. L(p) is a
set of states in the chart, with which p can reduce
from the right side. Formally,
</bodyText>
<equation confidence="0.9870185">
L((i, j, sd...s0)) = pp
{(h,i,s�d...s�0)|∀k E [1,d],fk(s�k−1) = fk(sk)},
</equation>
<bodyText confidence="0.913113133333333">
where fk(·) returns atomic features on the k-th top
node. See Figure 4 for how they look like in con-
stituent parsing. R(p) is defined similarly; p can
3Although Zhao et al. (2013) explained that the items in
Q are derivations (not states), we can implement Q as a set
of states by keeping backpointers in a starndard way.
reduce q E R(p) from the left side. When p is
popped, it searches for every L(p) and R(p) in the
chart and tries to expand the current derivation.
The priority for each state is a pair (c, v). c is
the prefix cost that is the total cost to reach that
state, while v is the inside cost, a cost to build the
top node s0. The top state in the queue has the
lowest prefix cost, or the lowest inside cost if the
two prefix costs are the same.
</bodyText>
<sectionHeader confidence="0.951924" genericHeader="method">
3 Best-First Shift-Reduce Constituent
</sectionHeader>
<subsectionHeader confidence="0.965673">
Parsing with Structured Perceptron
</subsectionHeader>
<bodyText confidence="0.999961125">
This section describes our basic parsing system,
i.e., shift-reduce constituent parsing with BFS and
the structured perceptron. We have to solve two
problems. The first is how to achieve BFS with
the structured perceptron, and the second is how
to apply that BFS to constituent parsing. Interest-
ingly, the solution to the first problem makes the
second problem relatively trivial.
</bodyText>
<subsectionHeader confidence="0.999891">
3.1 Superiority of Structured Perceptron
</subsectionHeader>
<bodyText confidence="0.99997316">
We must design each priority of a state to sat-
isfy the superiority condition. φ(ai, pi−1) =
θTf(ai, pi−1) is the usual local score employed in
structured perceptrons (Huang and Sagae, 2010)
but we cannot use it as a local cost for two rea-
sons. First, in our system, the best parse should
have the lowest cost; it is opposite in the ordinary
setting (Collins, 2002). We can resolve this con-
flict by changing the direction of structured per-
ceptron training so that the best parse has the low-
est score.4 Second, each φ(ai,pi−1) can take a
negative value but the cost should always be pos-
itive. This is in contrast to the MaxEnt model in
which the negative log probability is always pos-
itive. Our strategy is to add a constant offset δ to
every local cost. If δ is large enough so that ev-
ery score is positive, the superiority condition is
satisfied.5
Unary Merging Though this technique solves
the problem with the structured perceptron for a
simpler shift-reduce system, say for dependency
grammar, the existence of unary actions, as men-
tioned in Section 2.1, requires additional effort in
order to apply it to constituent parsing. In particu-
lar, constituent parsing takes different numbers of
</bodyText>
<footnote confidence="0.9870236">
4This is easily accomplished by inverting all signs of the
update equations.
5To find this value, we train our system using beam search
with several beam sizes, choosing the maximum value of the
action score during training.
</footnote>
<page confidence="0.86788">
1536
</page>
<equation confidence="0.986983173913043">
state p:
// ( , j, sd ... s0) : (c, &lt; n
)
,�+1,Sd-1...s01t7(w7)) (C+Csh(P),Csh(P))
W
SHU(X) state p:
( ,j, sd...s0) : (c, )
&lt; n
(j,j + 1,sd−1 ... s0|X(tj(wj))) : (c + cshu(X)(p),cshu(X)(p))
SH
state q:
(k, i,v&apos;)
s0d...s00) : (c0,
(k, j, s0d...s01|X(s00, s0)) : (c0 + v + cre(X)(p), v0 + v + cre(X)(p))
RE(X)
state p:
(i, j, sd...s0) : (c, v)
q E G(p)
state q: state p:
(k, i, s0d...s00) : (c0, v0) (i, j, sd...s0) : (c, v)
(k, j, s0d...s01|Y(X(s00, s0))) : (c0 + v + creu(Y, X)(p), v0 + v + creu(Y, X)(p))
REU(Y, X)
q E G(p)
</equation>
<figureCaption confidence="0.990046">
Figure 1: The deductive system of our best-first shift-reduce constituent parsing explaining how the
</figureCaption>
<bodyText confidence="0.893449">
prefix cost and inside cost are calculated. FIN is omitted.  |on the stack means an append operation and
a(b) means a subtree a —* b. tj is the POS tag of j-th token while wj is the surface form. ca(p) is the
cost for an action a of which features are extracted from p. Each ca(p) implicitly includes an offset δ.
actions for each derivation, which means that the
scores of two final states may contain different off-
set values. The existing modification to alleviate
this inconsistency (Zhu et al., 2013) cannot be ap-
plied here because it is designed for beam search.
We instead develop a new transition system, in
which the number of actions to reach the final state
is always 2n (n is the length of sentence). The
basic idea is merging a unary action into each shift
or reduce action. Our system uses five actions:
</bodyText>
<listItem confidence="0.999927428571429">
• SH: original shift action;
• SHU(X): shift a node, then immediately ap-
ply a unary rule to that node;
• RE(X): original reduce action;
• REU(Y, X): do reduce to X first, then imme-
diately apply an unary rule Y —* X to it;
• FIN: finish the process.
</listItem>
<bodyText confidence="0.998355222222222">
Though the system cannot perform consecutive
unary actions, in practice it can generate any unary
chains as long as those in the training corpus by
collapsing a chain into one rule. We preprocess
the corpus in this way along with binarization (See
Section 4).
Note that this system is quite similar to the tran-
sition system for dependency parsing. The only
changes are that we have several varieties of shift
and reduce actions. This modification also makes
it easy to apply an algorithm developed for de-
pendency parsing to constituent parsing, such as
dynamic programming with beam search (Huang
and Sagae, 2010), which has not been applied into
constituent parsing until quite recently (Mi and
Huang, 2015) (See Section 7).
Algorithm 1 BFS for Constituent Parsing; Only
differences from Zhao et al. (2013)
</bodyText>
<listItem confidence="0.99534175">
1: procedure SHIFT(x, Q)
2: TRYADD(sh(x), Q)
3: for y E shu(x) do
4: TRYADD(y, Q)
5: procedure REDUCE(A, B, Q)
6: for (x, y) E A x B do
7: for z E re(x, y) U reu(x, y) do
8: TRYADD(z, Q)
</listItem>
<subsectionHeader confidence="0.999731">
3.2 BFS with Dynamic Programming
</subsectionHeader>
<bodyText confidence="0.999978476190476">
Now applying BFS of Zhao et al. (2013) for de-
pendency parsing into constituent parsing is not
hard. Figure 1 shows the deductive system of dy-
namic programming, which is much similar to that
in dependency parsing. One important change is
that we include a cost for a shift (SH or SHU) ac-
tion in the prefix cost in a shift step, not a reduce
step as in Zhao et al. (2013), since it is unknown
whether the top node s0 of a state p is instantiated
with SH or SHU. This modification keeps the cor-
rectness of the algorithm and has been employed
in another system (Kuhlmann et al., 2011).
The algorithm is also slightly changed. We
show only the difference from Zhao et al. (2013)
(Algorithm 1) in Algorithm 1. shu(x) is a func-
tion which returns the set of states that can be ar-
rived at by possible SHU rules applied to the state
x. re(x, y) and reu(x, y) are similar, and they re-
turn the set of states arrived at through one of RE
or REU actions. As a speed up, we can apply a lazy
expansion technique (we do so in our experiment).
</bodyText>
<page confidence="0.948097">
1537
</page>
<figure confidence="0.998116">
processed states (x1000)
160
120
80
40
0
</figure>
<table confidence="0.99766175">
Model F1 Speed (Sent./s.)
SP (reduced features) 88.9 0.8
ME (reduced features) 85.1 4.8
ME (full features) 86.3 2.5
</table>
<tableCaption confidence="0.999486">
Table 1: Results of BFS systems with dynamic
</tableCaption>
<bodyText confidence="0.5693">
programming for the Penn Treebank development
set with different models and features. SP = the
structured perceptron; ME = the MaxEnt.
</bodyText>
<figure confidence="0.981975">
0 20 40 60
Sentence length
Perceptron
MaxEnt
</figure>
<bodyText confidence="0.9996651875">
Another difference is in training. The previ-
ous best-first shift-reduce parsers are all trained
in the same way as a parser with greedy search
since the model is local MaxEnt. In our case, we
can use structured perceptron training with exact
search (Collins, 2002); that is, at each iteration for
each sentence, we find the current argmin deriva-
tion with BFS, then update the parameters if it dif-
fers from the gold derivation. Note that at the be-
ginning of training, BFS is inefficient due to the
initial flat parameters. We use a heuristic to speed
up this process: For a few iterations (five, in our
case), we train the model with beam search and an
early update (Collins and Roark, 2004). We find
that this approximation does not affect the perfor-
mance, while it greatly reduces the training time.
</bodyText>
<sectionHeader confidence="0.864927" genericHeader="method">
4 Evaluation of Best-First Shift-Reduce
</sectionHeader>
<subsectionHeader confidence="0.597211">
Constituent Parsing
</subsectionHeader>
<bodyText confidence="0.999961">
This section evaluates the empirical performance
of our best-first constituent parser that we built in
the previous section. As mentioned in Section 2.2,
the previous empirical success of best-first shift-
reduce parsers might be due to the sparsity prop-
erty of the MaxEnt model, which may not hold
true in the structured perceptron. We investigate
the validity of this assumption by comparing two
systems, a locally trained MaxEnt model and a
globally trained structured perceptron.
Setting We follow the standard practice and
train each model on section 2-21 of the WSJ Penn
Treebank (Marcus et al., 1993), which is binarized
using the algorithm in Zhang and Clark (2009)
with the head rule of Collins (1999). We report
the F1 scores for the development set of section
22. The Stanford POS tagger is used for part-of-
speech tagging.6 We used the EVALB program
to evaluate parsing performance.7 Every exper-
iment reported here was performed on hardware
</bodyText>
<footnote confidence="0.9998995">
6http://nlp.stanford.edu/software/tagger.shtml
7http://nlp.cs.nyu.edu/evalb
</footnote>
<figureCaption confidence="0.92436">
Figure 2: Comparison of the average number of
the processed states of the structured perceptron
with those of the MaxEnt model.
equipped with an Intel Corei5 2.5GHz processor
and 16GB of RAM.
</figureCaption>
<bodyText confidence="0.999949545454545">
Feature We borrow the feature templates from
Sagae and Lavie (2006). However, we found the
full feature templates make training and decoding
of the structured perceptron much slower, and in-
stead developed simplified templates by removing
some, e.g., that access to the child information on
the second top node on the stack.8
Result Table 1 summarizes the results that indi-
cate our assumption is true. The structured per-
ceptron has the best score even though we restrict
the features. However, its parsing speed is much
slower than that of the local MaxEnt model. To see
the difference in search behaviors between the two
models, Figure 2 plots the number of processed
(popped) states during search.
Discussion This result may seem somewhat de-
pressing. We have devised a new method that en-
ables optimal search for the structured perceptron,
but it cannot handle even modestly large feature
templates. As we will see below, the time com-
plexity of the system depends on the used fea-
tures. We have tried features from Sagae and Lavie
(2006), but their features are no longer state-of-
the-art. For example, Zhu et al. (2013) report
higher scores by using beam search with much
richer feature templates, though, as we have exam-
ined, it seems implausible to apply such features
to our system. In the following, we find a practi-
cal solution for improving both parse accuracy and
search efficiency in our system. We will see that
our new features not only make BFS tractable, but
also lead to comparable or even superior accuracy
relative to the current mainstream features. When
</bodyText>
<footnote confidence="0.95634">
8The other features that we removed are features 9–14 de-
fined in Figure 1 of Sagae and Lavie (2006).
</footnote>
<page confidence="0.98511">
1538
</page>
<figureCaption confidence="0.997038">
Figure 3: A snippet of the hypergraph for the sys-
</figureCaption>
<bodyText confidence="0.9970288">
tem that simulates a simple PCFG. p is the popped
state, which is being expanded with a state of its
left states L(p) using a reduce rule.
it is combined with A* search, the speed reaches a
practical level.
</bodyText>
<sectionHeader confidence="0.981146" genericHeader="method">
5 Improving Optimal Search Efficiency
</sectionHeader>
<subsectionHeader confidence="0.984481">
5.1 Span Features
</subsectionHeader>
<bodyText confidence="0.9999693125">
The worst time complexity of hypergraph search
for shift-reduce parsing can be analyzed with the
deduction rule of the reduce step. Figure 3 shows
an example. In this case, the time complexity
is O(n3 &apos; |G |&apos; |N|) since there are three indices
(i, j, k) and four nonterminals (A, B, C, D), on
which three comprise a rule. The extra factor |N|
compared with ordinary CKY parsing comes from
the restriction that we extract features only from
one state (Huang and Sagae, 2010).
Complexity increases when we add new atomic
features to each state. For example, if we lexical-
ize this model by adding features that depend on
the head indices of s0 and/or s1, it increases to
O(n6 &apos; |G |&apos; |N|) since we have to maintain three
head indices of A, B, and C. This is why Sagae and
Lavie’s features are too expensive for our system;
they rely on head indices of s0, s1, s2, s3, the left
and right children of s0 and s1, and so on, lead-
ing prohibitively huge complexity. Historically
speaking, the success of shift-reduce approach in
constituent parsing has been led by its success in
dependency parsing (Nivre, 2008), in which the
head is the primary element, and we suspect this is
the reason why the current constituent shift-reduce
parsers mainly rely on deeper stack elements and
their heads.
The features we propose here are extracted from
fundamentally different parts from these recent
trends. Figure 4 explains how we extract atomic
features from a state and Table 2 shows the full list
of feature templates. Our system is unlexicalized;
</bodyText>
<figure confidence="0.9537955">
NP
NNP NNP .
... a subsidiary of ITT Corp .
4 5 6 7 8 9 10
</figure>
<figureCaption confidence="0.995741888888889">
Figure 4: Atomic features of our system largely
come from the span of a constituency. For each
span (s0 and s1), we extract the surface form and
POS tag of the preceding word (bw, bt), the first
word (fw, ft), the last word (lw, lt), and the subse-
quent word (aw, at). shape is the same as that in
Hall et al. (2014). Bold symbols are additional in-
formation from the system of Figure 3. The time
complexity is O(n4 &apos; |G|3 &apos; |N|).
</figureCaption>
<figure confidence="0.976045647058823">
q0.w o q0.t q1.w o q1.t q2.w o q2.t q3.w o q3.t
s0.c o s0.ft s0.c o s0.fw s0.c o s0.lt s0.c o s0.lw
s0.c o s0.at s0.c o s0.aw s0.c o s0.ft o s0.lt s0.c o s0.ft o s0.lw
s0.c o s0.fw o s0.lt s0.c o s0.fw o s0.lw s0.c o s0.len s0.c o s0.shape
s0.rule s0.shape o s0.rule
s1.c o s1.ft s1.c o s1.fw s1.c o s1.lt s1.c o s1.lw
s1.c o s1.bt s1.c o s1.bw s1.c o s1.ft o s1.lt s1.c o s1.ft o s1.lw
s1.c o s1.fw o s1.lt s1.c o s1.fw o s1.lw s1.c o s1.len s1.c o s1.shape
s1.rule s1.shape o s1.rule
s1.lw o s0.fw s0.ft o s1.lw s1.lt o s0.fw s1.lt o s0.ft
s1.c o s0.fw s0.c o s1.fw s1.c o s0.lw s0.c o s1.lw
s0.fw o q0.w s0.lw o q0.w q0.t o s0.fw q0.t o s0.lw
s0.c o q0.w s0.c o q0.t s1.fw o q0.w s1.lw o q0.w
q0.t o s1.fw q0.t o s1.lw s1.c o q0.w s1.c o q0.t
q0.w o q1.w q0.t o q1.w q0.w o q1.t q0.t o q1.t
s0.c o s1.c o q0.t s0.c o s1.c o q0.w s1.c o q0.t o s0.fw s1.c o q0.t o s0.lw
s0.c o q0.t o s1.fw s0.c o q0.t o s1.fw
</figure>
<tableCaption confidence="0.73278">
Table 2: All feature templates in our span model.
</tableCaption>
<bodyText confidence="0.998628947368421">
See Figure 4 for a description of each element. qz
is the i-th top token on the queue.
i.e., it does not use any head indices. This feature
design is largely inspired by the recent empirical
success of span features in CRF parsing (Hall et
al., 2014). Their main finding is that the surface in-
formation on a subtree, such as the first or the last
word of a span, has essentially the same amount
of information as its head. For our system, such
span features are much cheaper, so we expect they
would facilitate our dynamic programming with-
out sacrificing accuracy.
We customize their features for fitting in the
shift-reduce framework. Unlike the usual setting
of PCFG parsing, shift-reduce parsers receive a
POS-tagged sentence as input, so we use both the
POS tag and surface form for each word on the
span. One difficult part is using features with an
applied rule. We include this feature by memoriz-
</bodyText>
<figure confidence="0.87194425">
NP
DT NN
PP
IN
</figure>
<page confidence="0.989312">
1539
</page>
<bodyText confidence="0.999980857142857">
ing the previously applied rule for each span (sub-
tree). This is a bit costly, because it means we
have to preserve labels of the left and right chil-
dren for each node, which lead to an additional
|G|2 factor of complexity. However, we will see
that this problem can be alleviated by our heuris-
tic cost functions in A* search described below.
</bodyText>
<subsectionHeader confidence="0.996298">
5.2 A* Search
</subsectionHeader>
<bodyText confidence="0.986238777777778">
We now explain our A* search, another key tech-
nique for speeding up our search. To our knowl-
edge, this is the first work to successfully apply A*
search to shift-reduce parsing.
A* parsing (Klein and Manning, 2003a) mod-
ifies the calculation of priority σ(pi) for state pi.
In BFS, it is basically the prefix cost, the sum of
every local cost (Section 3.1), which we denote as
βpi:
</bodyText>
<equation confidence="0.850322333333333">
�βpi = (φ(aj, pj−1) + δ).
1&lt;j&lt;i
In A* parsing, σ(pi) = βpi + h(pi) where h(pi)
</equation>
<bodyText confidence="0.999786444444444">
is a heuristic cost. βpi corresponds to the Viterbi
inside cost of PCFG parsing (Klein and Manning,
2003a) while h(pi) is the Viterbi outside cost, an
approximation of the cost for the future best path
(action sequence) from pi.
h(pi) must be a lower bound of the true Viterbi
outside cost. In PCFG parsing, this is often
achieved with a technique called projection. Let
G* be a projected, or relaxed, grammar of the orig-
inal G; then, a rule weight in the relaxed gram-
mar wr* will become wr* = minrEG:1r(r)=r* wr,
where π(r) is a projection function which returns
the set of rules that correspond to r in G*.
In feature-based shift-reduce parsing, a rule
weight corresponds to the sum of feature weights
for an action a, that is, φ(a, pi) = θTf(a, pi).
We calculate h(pi) with a relaxed feature function
φ*(a, pi), which always returns a lower bound:
</bodyText>
<equation confidence="0.95004">
φ*(a,pi) = θ*Tf(a,ci) G θTf(a,pi) = φ(a, pi).
</equation>
<bodyText confidence="0.9997297">
Note that we only have to modify the weight vec-
tor. If a relaxed weight satisfies θ*(k) G θ(k) for
all k, that projection is correct.
Our A* parsing is essentially hierarchical A*
parsing (Pauls and Klein, 2009), and we calculate
a heuristic cost h(p) on the fly using another chart
for the relaxed space when a new state p is pushed
into the priority queue. Below we introduce two
different projection methods, which are orthogo-
nal and later combined hierarchically.
</bodyText>
<table confidence="0.976276">
a o s1.c o s1.ft θ θGP θLF
SH o VP o NN 10.53 -5.82 -5.82
SH o SBAR o NN 1.98 -5.82 -5.82
SH o NP o NN -5.82 -5.82 -5.82
� � �
SH o VP o DT 3.25 1.12 -5.82
SH o SBAR o DT 1.12 1.12 -5.82
SH o NP o DT 1.98 1.12 -5.82
� � �
</table>
<tableCaption confidence="0.923397714285714">
Table 3: Example of our feature projection. θGP is
a weight vector with the GP, which collapses every
c. θLF is with the LF, which collapses all elements
in Table 4.
s1.c s1.ft s1.fw s1.bt s1.bw
s1.len s1.shape s1.rule s0.rule
Table 4: List of feature elements ignored in the LF.
</tableCaption>
<bodyText confidence="0.948018888888889">
Grammar Projection (GP) Our first projection
borrows the idea from the filter projection of Klein
and Manning (2003a), in which the grammar sym-
bols (nonterminals) are collapsed into a single la-
bel X. Our projection, however, does not collapse
all the labels into X; instead, we utilize constituent
labels in level 2 from Charniak et al. (2006), in
which labels that tend to be head, such as S or VP
are collapsed into HP and others are collapsed into
MP. θG in Table 3 is an example of how feature
weights are relaxed with this projection. Here we
show each feature as a tuple including action name
(a). Let πGP be a feature projection function: e.g.,
((a o s1.c o s1.ft) = (SH o VP o NN))
~�1rGP ((a o s1.c o s1.ft) = (SH o HP o NN)).
Formally, for k-th feature, the weight θGP(k) is
determined by minimizing over the features col-
lapsed by πGP:
</bodyText>
<equation confidence="0.803409">
min
1&lt;k&apos;&lt;K:1rGP(gk/)=gk
</equation>
<bodyText confidence="0.99713275">
where gk is the value of the k-th feature.
Less-Feature Projection (LF) The basic idea of
our second projection is to ignore some of the
atomic features in a feature template so that we
can reduce the time complexity for computing the
heuristics. We apply this technique to the feature
elements in Table 4. We can do so by not filling in
the actual value in each feature template: e.g.,
</bodyText>
<equation confidence="0.87959675">
((a o s1.c o s1.ft) = (SH o VP o NN))
~�1rLF ((a o s1.c o s1.ft) = (SH o s1.c o s1.ft)).
θGP(k) =
θ(k&apos;),
</equation>
<page confidence="0.974819">
1540
</page>
<figure confidence="0.999405583333333">
0.30
4.0
0.25
0.20
3.0
0.15
2.0
Avg. parsing time (sec.)
0.10
Avg. parsing time (sec.)
1.0
0.05
0.0
0.00
b=16
b=32
b=64
A*-HP
BFS
A*-LF
A*-GP
A*-HP
0 20 40 60
Sentence length
</figure>
<figureCaption confidence="0.995584">
Figure 5: Comparison of parsing times between
different A* heuristics.
</figureCaption>
<bodyText confidence="0.999882260869565">
The elements in Table 4 are selected so that all
bold elements in Figure 4 would be eliminated;
the complexity is O(n3 · |G |· |N|). In practice,
this is still expensive. However, we note that the
effects of these two heuristics are complementary:
The LF reduces complexity to a cubic time bound,
while the GP greatly reduces the size of grammar
|G|; We combine these two ideas below.
Hierarchical Projection (HP) The basic idea of
this combined projection is to use the heuristics
given by the GP to lead search of the LF. This
is similar to the hierarchical A* for PCFGs with
multilevel symbol refinements (Pauls and Klein,
2009). The difference is that their hierarchy is on
the grammar symbols while our projection targets
are features. When a state p is created, its heuris-
tic score h(p) is calculated with the LF, which re-
quires search for the outside cost in the space of
the LF, but its worst time complexity is cubic. The
GP is used to guide this search. For each state pLF
in the space of the LF, the GP calculates the heuris-
tic score. We will see that this combination works
quite well in practice in the next section.
</bodyText>
<sectionHeader confidence="0.996667" genericHeader="method">
6 Experiment
</sectionHeader>
<bodyText confidence="0.9996545">
We build our final system by combining the ideas
in Section 5 and the system in Section 3. We
also build beam-based systems with or without dy-
namic programming (DP) and with the ordinary or
the new span features. All systems are trained with
the structured perceptron. We use the early update
for training beam-based systems.
Effect of A* heuristics Figure 5 shows the ef-
fects of A* heuristics. In terms of search quality,
the LF is better; it prunes 92.5% of states com-
pared to naive BFS, while the GP prunes 75%.
However, the LF takes more time to calculate
</bodyText>
<figure confidence="0.994458">
0 20 40 60
Sentence length
</figure>
<figureCaption confidence="0.934773">
Figure 6: Comparison of parsing times between
A* and beam search (with DP).
</figureCaption>
<table confidence="0.99807">
Feaure Z&amp;C feature set Span (this work)
DP ✓ ✓
F1 F1 Sent./s. F1 F1 Sent./s.
b=16 89.1 90.1 34.6 88.6 89.9 31.9
b=32 89.6 89.9 20.0 89.3 90.2 17.0
b=64 89.7 90.2 10.6 89.6 90.2 9.1
A* - - - - 90.7 13.6
BFS - - - - 90.7 1.1
</table>
<tableCaption confidence="0.918148">
Table 5: Results for the Penn Treebank develop-
</tableCaption>
<bodyText confidence="0.999122592592593">
ment set. Z&amp;C = feature set of Zhang and Clark
(2009). The speeds of non-DP and DP are the
same, so we omit them from the comparison.
heuristics than the GP. The HP combines the ad-
vantages of both, achieving the best result.
Accuracy and Speed The F1 scores for the de-
velopment set are summarized in Table 5. We can
see that the systems with our new feature (span)
perform surprisingly well, at a competitive level
with the more expensive features of Zhang and
Clark (2009) (Z&amp;C). This is particularly true with
DP; it sometimes outperforms Z&amp;C, probably be-
cause our simple features facilitate state merging
of DP, which expands search space. However, our
main result that the system with optimal search
gets a much higher score (90.7 F1) than beam-
based systems with a larger beam size (90.2 F1)
indicates that ordinary beam-based systems suffer
from severe search errors even with the help of DP.
Though our naive BFS is slow (1.12 sent./s.), A*
search considerably improves parsing speed (13.6
sent./s.), and is faster than the beam-based system
with a beam size of 64 (Figure 6).
Unary Merging We have not mentioned the ef-
fect of our unary merging (Section 3), but the re-
sult indicates it has almost the same effect as the
previously proposed padding method (Zhu et al.,
</bodyText>
<page confidence="0.970291">
1541
</page>
<table confidence="0.999883357142857">
Shift-reduce (closed) LR LP F1 Sent./s.
Sagae (2005)† 86.0 86.1 86.0 3.7
Sagae (2006)† 88.1 87.8 87.9 2.2
Zhu (2013) (Z&amp;C) 90.2 90.7 90.4 93.4
Span (b=64, DP) 90.2 90.6 90.4 8.4
Span (A*) 90.9 91.2 91.1 13.6
Other (closed)
Berkeley (2007) 90.1 90.3 90.2 6.1
Stanford (2013) (RNN) 90.3 90.7 90.5 3.3
Hall (2014) (CRF) 89.0 89.5 89.3 0.7
External/Reranking
Charniak (2005) 91.2 91.8 91.5 2.1
McClosky (2006) 92.2 92.6 92.4 1.2
Zhu (2013) +semi 91.1 91.5 91.3 47.6
</table>
<tableCaption confidence="0.973349">
Table 6: The final results for section 23 of the
</tableCaption>
<bodyText confidence="0.934775857142857">
Penn Treebank. The systems with † are re-
ported by authors running on different hardware.
We divide baseline state-of-the-art systems into
three categories: shift-reduce systems (Sagae and
Lavie, 2005; Sagae and Lavie, 2006; Zhu et
al., 2013), other chart-based systems (Petrov and
Klein, 2007; Socher et al., 2013), and the systems
with external semi supervised features or rerank-
ing (Charniak and Johnson, 2005; McClosky et al.,
2006; Zhu et al., 2013).
2013). The score with the non-DP beam size = 16
and Z&amp;C (89.1 F1) is the same as that reported in
their paper (the features are the same).
Final Experiment Table 6 compares our pars-
ing system with those of previous studies. When
we look at closed settings, where no external re-
source other than the training Penn Treebank is
used, our system outperforms all other systems
including the Berkeley parser (Petrov and Klein,
2007) and the Stanford parser (Socher et al., 2013)
in terms of F1. The parsing systems with exter-
nal features or reranking outperform our system.
However, it should be noted that our system could
also be improved by external features. For exam-
ple, the feature of type-level distributional sim-
ilarity, such as Brown clustering (Brown et al.,
1992), can be incorporated with our system with-
out changing the theoretical runtime.
</bodyText>
<sectionHeader confidence="0.999838" genericHeader="method">
7 Related Work and Discussion
</sectionHeader>
<bodyText confidence="0.999977025">
Though the framework is shift-reduce, we can
notice that our system is strikingly similar to
the CKY-based discriminative parser (Hall et al.,
2014) because our features basically come from
two nodes on the stack and their spans. From this
viewpoint, it is interesting to see that our system
outperforms theirs by a large margin (Figure 6).
Identifying the source of this performance change
is beyond the scope of this paper, but we believe
this is an important question for future parsing
research. For example, it is interesting to see
whether there is any structural advantage for shift-
reduce over CKY by comparing two systems with
exactly the same feature set.
As shown in Section 4, the previous optimal
parser on shift-reduce (Sagae and Lavie, 2006)
was not so strong because of the locality of the
model. Other optimal parsing systems are often
based on relatively simple PCFGs, such as unlex-
icalized grammar (Klein and Manning, 2003b) or
factored lexicalized grammar (Klein and Manning,
2003c) in which A* heuristics from the unlexical-
ized grammar guide search. However, those sys-
tems are not state-of-the-art probably due to the
limited context captured with a simple PCFG. A
recent trend has thus been extending the context
of each rule (Petrov and Klein, 2007; Socher et al.,
2013), but the resulting complex grammars make
exact search intractable. In our system, the main
source of information comes from spans as in CRF
parsing. This is cheap yet strong, and leads to a
fast and accurate parsing system with optimality.
Concurrently with this work, Mi and Huang
(2015) have developed another dynamic program-
ming for constituent shift-reduce parsing by keep-
ing the step size for a sentence to 4n − 2, instead
of 2n, with an un-unary (stay) action. Their final
score is 90.8 F1 on WSJ. Though they only experi-
ment with beam-search, it is possible to build BFS
with their transition system as well.
</bodyText>
<sectionHeader confidence="0.999034" genericHeader="conclusions">
8 Conclusions
</sectionHeader>
<bodyText confidence="0.999942">
To date, all practical shift-reduce parsers have re-
lied on approximate search, which suffers from
search errors but also allows to utilize unlimited
features. The main result of this paper is to show
another possibility of shift-reduce by proceeding
in an opposite direction: By selecting features and
improving search efficiency, a shift-reduce parser
with provable search optimality is able to find very
high quality parses in a practical runtime.
</bodyText>
<sectionHeader confidence="0.997751" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999726333333333">
We would like to thank Katsuhiko Hayashi for
answering our questions about dynamic program-
ming on shift-reduce parsing.
</bodyText>
<page confidence="0.995228">
1542
</page>
<sectionHeader confidence="0.995739" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999866594594594">
Bernd Bohnet, Joakim Nivre, Igor M. Boguslavsky,
Rich´ard Farkas, and Jan Hajiˇc. 2013. Joint Mor-
phological and Syntactic Analysis for Richly In-
flected Languages. Transactions of the Association
for Computational Linguistics, 1(Oct):429–440.
Peter F. Brown, Peter V. deSouza, Robert L. Mercer,
Vincent J. Della Pietra, and Jenifer C. Lai. 1992.
Class-based N-gram Models of Natural Language.
Comput. Linguist., 18(4):467–479, December.
Eugene Charniak and Mark Johnson. 2005. Coarse-
to-Fine n-Best Parsing and MaxEnt Discriminative
Reranking. In Proceedings of the 43rd Annual Meet-
ing of the Association for Computational Linguis-
tics (ACL’05), pages 173–180, Ann Arbor, Michi-
gan, June. Association for Computational Linguis-
tics.
Eugene Charniak, Mark Johnson, Micha Elsner, Joseph
Austerweil, David Ellis, Isaac Haxton, Catherine
Hill, R. Shrivaths, Jeremy Moore, Michael Pozar,
and Theresa Vu. 2006. Multilevel Coarse-to-Fine
PCFG Parsing. In Proceedings of the Human Lan-
guage Technology Conference of the NAACL, Main
Conference, pages 168–175, New York City, USA,
June. Association for Computational Linguistics.
Michael Collins and Brian Roark. 2004. Incremen-
tal Parsing with the Perceptron Algorithm. In Pro-
ceedings of the 42nd Meeting of the Association for
Computational Linguistics (ACL’04), Main Volume,
pages 111–118, Barcelona, Spain, July.
M. Collins. 1999. Head-Driven Statistical Models for
Natural Language Parsing. Ph.D. thesis, University
of Pennsylvania.
Michael Collins. 2002. Discriminative Training Meth-
ods for Hidden Markov Models: Theory and Ex-
periments with Perceptron Algorithms. In Proceed-
ings of the 2002 Conference on Empirical Methods
in Natural Language Processing, pages 1–8. Asso-
ciation for Computational Linguistics, July.
David Hall, Greg Durrett, and Dan Klein. 2014. Less
Grammar, More Features. In Proceedings of the
52nd Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
228–237, Baltimore, Maryland, June. Association
for Computational Linguistics.
Liang Huang and Kenji Sagae. 2010. Dynamic Pro-
gramming for Linear-Time Incremental Parsing. In
Proceedings of the 48th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 1077–
1086, Uppsala, Sweden, July. Association for Com-
putational Linguistics.
Dan Klein and Christopher D. Manning. 2001. Pars-
ing and Hypergraphs. In Proceedings of the Sev-
enth International Workshop on Parsing Technolo-
gies (IWPT-2001), 17-19 October 2001, Beijing,
China.
Dan Klein and Christopher D. Manning. 2003a. A*
Parsing: Fast Exact Viterbi Parse Selection. In Pro-
ceedings of the 2003 Conference of the North Amer-
ican Chapter of the Association for Computational
Linguistics on Human Language Technology - Vol-
ume 1, NAACL ’03, pages 40–47, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Dan Klein and Christopher D. Manning. 2003b. Accu-
rate Unlexicalized Parsing. In Proceedings of the
41st Annual Meeting of the Association for Com-
putational Linguistics, pages 423–430, Sapporo,
Japan, July. Association for Computational Linguis-
tics.
Dan Klein and Christopher D. Manning. 2003c. Fac-
tored A* Search for Models over Sequences and
Trees. In IJCAI-03, Proceedings of the Eighteenth
International Joint Conference on Artificial Intelli-
gence, Acapulco, Mexico, August 9-15, 2003, pages
1246–1251.
Marco Kuhlmann, Carlos G´omez-Rodr´ıguez, and Gior-
gio Satta. 2011. Dynamic Programming Algorithms
for Transition-Based Dependency Parsers. In Pro-
ceedings of the 49th Annual Meeting of the Associ-
ation for Computational Linguistics: Human Lan-
guage Technologies, pages 673–682, Portland, Ore-
gon, USA, June. Association for Computational Lin-
guistics.
Mitchell P. Marcus, Beatrice Santorini, and Mary Ann
Marcinkiewicz. 1993. Building a Large Annotated
Corpus of English: The Penn Treebank. COMPU-
TATIONAL LINGUISTICS, 19(2):313–330.
David McClosky, Eugene Charniak, and Mark John-
son. 2006. Reranking and Self-Training for Parser
Adaptation. In Proceedings of the 21st Interna-
tional Conference on Computational Linguistics and
44th Annual Meeting of the Association for Compu-
tational Linguistics, pages 337–344, Sydney, Aus-
tralia, July. Association for Computational Linguis-
tics.
Haitao Mi and Liang Huang. 2015. Shift-Reduce Con-
stituency Parsing with Dynamic Programming and
POS Tag Lattice. In Proceedings of the 2015 Con-
ference on the North American Chapter of the Asso-
ciation for Computational Linguistics Human Lan-
guage Technologies, Denver, Colorado, May. Asso-
ciation for Computational Linguistics.
Joakim Nivre. 2008. Algorithms for Deterministic In-
cremental Dependency Parsing. Computational Lin-
guistics, 34(4):513–553.
Adam Pauls and Dan Klein. 2009. Hierarchical
Search for Parsing. In Proceedings of Human Lan-
guage Technologies: The 2009 Annual Conference
of the North American Chapter of the Associa-
tion for Computational Linguistics, pages 557–565,
Boulder, Colorado, June. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.621241">
1543
</page>
<reference confidence="0.999879980392157">
Slav Petrov and Dan Klein. 2007. Improved Inference
for Unlexicalized Parsing. In Human Language
Technologies 2007: The Conference of the North
American Chapter of the Association for Computa-
tional Linguistics; Proceedings of the Main Confer-
ence, pages 404–411, Rochester, New York, April.
Association for Computational Linguistics.
Kenji Sagae and Alon Lavie, 2005. Proceedings of the
Ninth International Workshop on Parsing Technol-
ogy, chapter A Classifier-Based Parser with Linear
Run-Time Complexity, pages 125–132. Association
for Computational Linguistics.
Kenji Sagae and Alon Lavie. 2006. A Best-First Prob-
abilistic Shift-Reduce Parser. In Proceedings of the
COLING/ACL 2006 Main Conference Poster Ses-
sions, pages 691–698, Sydney, Australia, July. As-
sociation for Computational Linguistics.
Richard Socher, John Bauer, Christopher D. Manning,
and Ng Andrew Y. 2013. Parsing with Compo-
sitional Vector Grammars. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
455–465, Sofia, Bulgaria, August. Association for
Computational Linguistics.
Zhiguo Wang and Nianwen Xue. 2014. Joint POS
Tagging and Transition-based Constituent Parsing
in Chinese with Non-local Features. In Proceed-
ings of the 52nd Annual Meeting of the Association
for Computational Linguistics (Volume 1: Long Pa-
pers), pages 733–742, Baltimore, Maryland, June.
Association for Computational Linguistics.
Yue Zhang and Stephen Clark. 2009. Transition-Based
Parsing of the Chinese Treebank using a Global
Discriminative Model. In Proceedings of the 11th
International Conference on Parsing Technologies
(IWPT’09), pages 162–171, Paris, France, October.
Association for Computational Linguistics.
Kai Zhao, James Cross, and Liang Huang. 2013. Op-
timal Incremental Parsing via Best-First Dynamic
Programming. In Proceedings of the 2013 Confer-
ence on Empirical Methods in Natural Language
Processing, pages 758–768, Seattle, Washington,
USA, October. Association for Computational Lin-
guistics.
Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang,
and Jingbo Zhu. 2013. Fast and Accurate Shift-
Reduce Constituent Parsing. In Proceedings of the
51st Annual Meeting of the Association for Compu-
tational Linguistics (Volume 1: Long Papers), pages
434–443, Sofia, Bulgaria, August. Association for
Computational Linguistics.
</reference>
<page confidence="0.995912">
1544
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.482518">
<title confidence="0.999164">Optimal Shift-Reduce Constituent Parsing with Structured Perceptron</title>
<author confidence="0.946965">Le_Quang</author>
<affiliation confidence="0.8534455">Hanoi University of and</affiliation>
<abstract confidence="0.969028909090909">We present a constituent shift-reduce parser with a structured perceptron that finds the optimal parse in a practical runtime. The key ideas are new feature templates that facilitate state merging of dynamic programming and A* search. Our system achieves 91.1 F1 on a standard English experiment, a level which cannot be reached by other beam-based systems with large beam</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
<author>Joakim Nivre</author>
<author>Igor M Boguslavsky</author>
<author>Rich´ard Farkas</author>
<author>Jan Hajiˇc</author>
</authors>
<title>Joint Morphological and Syntactic Analysis for Richly Inflected Languages. Transactions of the Association for Computational Linguistics,</title>
<date>2013</date>
<marker>Bohnet, Nivre, Boguslavsky, Farkas, Hajiˇc, 2013</marker>
<rawString>Bernd Bohnet, Joakim Nivre, Igor M. Boguslavsky, Rich´ard Farkas, and Jan Hajiˇc. 2013. Joint Morphological and Syntactic Analysis for Richly Inflected Languages. Transactions of the Association for Computational Linguistics, 1(Oct):429–440.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter F Brown</author>
<author>Peter V deSouza</author>
<author>Robert L Mercer</author>
<author>Vincent J Della Pietra</author>
<author>Jenifer C Lai</author>
</authors>
<title>Class-based N-gram Models of Natural Language.</title>
<date>1992</date>
<journal>Comput. Linguist.,</journal>
<volume>18</volume>
<issue>4</issue>
<contexts>
<context position="35107" citStr="Brown et al., 1992" startWordPosition="6234" endWordPosition="6237">riment Table 6 compares our parsing system with those of previous studies. When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system outperforms all other systems including the Berkeley parser (Petrov and Klein, 2007) and the Stanford parser (Socher et al., 2013) in terms of F1. The parsing systems with external features or reranking outperform our system. However, it should be noted that our system could also be improved by external features. For example, the feature of type-level distributional similarity, such as Brown clustering (Brown et al., 1992), can be incorporated with our system without changing the theoretical runtime. 7 Related Work and Discussion Though the framework is shift-reduce, we can notice that our system is strikingly similar to the CKY-based discriminative parser (Hall et al., 2014) because our features basically come from two nodes on the stack and their spans. From this viewpoint, it is interesting to see that our system outperforms theirs by a large margin (Figure 6). Identifying the source of this performance change is beyond the scope of this paper, but we believe this is an important question for future parsing </context>
</contexts>
<marker>Brown, deSouza, Mercer, Pietra, Lai, 1992</marker>
<rawString>Peter F. Brown, Peter V. deSouza, Robert L. Mercer, Vincent J. Della Pietra, and Jenifer C. Lai. 1992. Class-based N-gram Models of Natural Language. Comput. Linguist., 18(4):467–479, December.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05),</booktitle>
<pages>173--180</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Ann Arbor, Michigan,</location>
<contexts>
<context position="34295" citStr="Charniak and Johnson, 2005" startWordPosition="6094" endWordPosition="6097">.3 Hall (2014) (CRF) 89.0 89.5 89.3 0.7 External/Reranking Charniak (2005) 91.2 91.8 91.5 2.1 McClosky (2006) 92.2 92.6 92.4 1.2 Zhu (2013) +semi 91.1 91.5 91.3 47.6 Table 6: The final results for section 23 of the Penn Treebank. The systems with † are reported by authors running on different hardware. We divide baseline state-of-the-art systems into three categories: shift-reduce systems (Sagae and Lavie, 2005; Sagae and Lavie, 2006; Zhu et al., 2013), other chart-based systems (Petrov and Klein, 2007; Socher et al., 2013), and the systems with external semi supervised features or reranking (Charniak and Johnson, 2005; McClosky et al., 2006; Zhu et al., 2013). 2013). The score with the non-DP beam size = 16 and Z&amp;C (89.1 F1) is the same as that reported in their paper (the features are the same). Final Experiment Table 6 compares our parsing system with those of previous studies. When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system outperforms all other systems including the Berkeley parser (Petrov and Klein, 2007) and the Stanford parser (Socher et al., 2013) in terms of F1. The parsing systems with external features or reranking outperform </context>
</contexts>
<marker>Charniak, Johnson, 2005</marker>
<rawString>Eugene Charniak and Mark Johnson. 2005. Coarseto-Fine n-Best Parsing and MaxEnt Discriminative Reranking. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics (ACL’05), pages 173–180, Ann Arbor, Michigan, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
<author>Micha Elsner</author>
<author>Joseph Austerweil</author>
<author>David Ellis</author>
<author>Isaac Haxton</author>
<author>Catherine Hill</author>
<author>R Shrivaths</author>
<author>Jeremy Moore</author>
<author>Michael Pozar</author>
<author>Theresa Vu</author>
</authors>
<title>Multilevel Coarse-to-Fine PCFG Parsing.</title>
<date>2006</date>
<booktitle>In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference,</booktitle>
<pages>168--175</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>New York City, USA,</location>
<contexts>
<context position="28749" citStr="Charniak et al. (2006)" startWordPosition="5088" endWordPosition="5091">able 3: Example of our feature projection. θGP is a weight vector with the GP, which collapses every c. θLF is with the LF, which collapses all elements in Table 4. s1.c s1.ft s1.fw s1.bt s1.bw s1.len s1.shape s1.rule s0.rule Table 4: List of feature elements ignored in the LF. Grammar Projection (GP) Our first projection borrows the idea from the filter projection of Klein and Manning (2003a), in which the grammar symbols (nonterminals) are collapsed into a single label X. Our projection, however, does not collapse all the labels into X; instead, we utilize constituent labels in level 2 from Charniak et al. (2006), in which labels that tend to be head, such as S or VP are collapsed into HP and others are collapsed into MP. θG in Table 3 is an example of how feature weights are relaxed with this projection. Here we show each feature as a tuple including action name (a). Let πGP be a feature projection function: e.g., ((a o s1.c o s1.ft) = (SH o VP o NN)) ~�1rGP ((a o s1.c o s1.ft) = (SH o HP o NN)). Formally, for k-th feature, the weight θGP(k) is determined by minimizing over the features collapsed by πGP: min 1&lt;k&apos;&lt;K:1rGP(gk/)=gk where gk is the value of the k-th feature. Less-Feature Projection (LF) T</context>
</contexts>
<marker>Charniak, Johnson, Elsner, Austerweil, Ellis, Haxton, Hill, Shrivaths, Moore, Pozar, Vu, 2006</marker>
<rawString>Eugene Charniak, Mark Johnson, Micha Elsner, Joseph Austerweil, David Ellis, Isaac Haxton, Catherine Hill, R. Shrivaths, Jeremy Moore, Michael Pozar, and Theresa Vu. 2006. Multilevel Coarse-to-Fine PCFG Parsing. In Proceedings of the Human Language Technology Conference of the NAACL, Main Conference, pages 168–175, New York City, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
<author>Brian Roark</author>
</authors>
<title>Incremental Parsing with the Perceptron Algorithm.</title>
<date>2004</date>
<booktitle>In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume,</booktitle>
<pages>111--118</pages>
<location>Barcelona, Spain,</location>
<contexts>
<context position="6723" citStr="Collins and Roark, 2004" startWordPosition="1115" endWordPosition="1118">entence. It does not use probability and 2Many existing constituent parsers use two kinds of reduce actions for selecting the direction of its head child while we do not distinguish these two. In our English experiments, we found no ambiguity for head selection in our binarized grammar (See Section 4). the local score is just φ(ai, pi−1) = BTf(ai, pi−1). In practice, this global model is much stronger than the local MaxEnt model. However, training this model without any approximation is hard, and the common practice is to rely on well-known heuristics such as an early update with beam search (Collins and Roark, 2004). We are not aware of any previous study that succeeded in training a structured perceptron for parsing without approximation. We will show how this becomes possible in Section 3. 2.2 Previous Best-First Shift-Reduce Parsing The basic idea behind best-first search (BFS) for shift-reduce parsing is assuming each parser state as a node on a graph and then searching for the minimal cost path from a start state (node) to the final state. This is the idea of Sagae and Lavie (2006), and it was later refined by Zhao et al. (2013). BFS gives a priority to each state, and a state with the highest prior</context>
<context position="18439" citStr="Collins and Roark, 2004" startWordPosition="3218" endWordPosition="3221">educe parsers are all trained in the same way as a parser with greedy search since the model is local MaxEnt. In our case, we can use structured perceptron training with exact search (Collins, 2002); that is, at each iteration for each sentence, we find the current argmin derivation with BFS, then update the parameters if it differs from the gold derivation. Note that at the beginning of training, BFS is inefficient due to the initial flat parameters. We use a heuristic to speed up this process: For a few iterations (five, in our case), we train the model with beam search and an early update (Collins and Roark, 2004). We find that this approximation does not affect the performance, while it greatly reduces the training time. 4 Evaluation of Best-First Shift-Reduce Constituent Parsing This section evaluates the empirical performance of our best-first constituent parser that we built in the previous section. As mentioned in Section 2.2, the previous empirical success of best-first shiftreduce parsers might be due to the sparsity property of the MaxEnt model, which may not hold true in the structured perceptron. We investigate the validity of this assumption by comparing two systems, a locally trained MaxEnt</context>
</contexts>
<marker>Collins, Roark, 2004</marker>
<rawString>Michael Collins and Brian Roark. 2004. Incremental Parsing with the Perceptron Algorithm. In Proceedings of the 42nd Meeting of the Association for Computational Linguistics (ACL’04), Main Volume, pages 111–118, Barcelona, Spain, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>M Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Pennsylvania.</institution>
<contexts>
<context position="19318" citStr="Collins (1999)" startWordPosition="3360" endWordPosition="3361">built in the previous section. As mentioned in Section 2.2, the previous empirical success of best-first shiftreduce parsers might be due to the sparsity property of the MaxEnt model, which may not hold true in the structured perceptron. We investigate the validity of this assumption by comparing two systems, a locally trained MaxEnt model and a globally trained structured perceptron. Setting We follow the standard practice and train each model on section 2-21 of the WSJ Penn Treebank (Marcus et al., 1993), which is binarized using the algorithm in Zhang and Clark (2009) with the head rule of Collins (1999). We report the F1 scores for the development set of section 22. The Stanford POS tagger is used for part-ofspeech tagging.6 We used the EVALB program to evaluate parsing performance.7 Every experiment reported here was performed on hardware 6http://nlp.stanford.edu/software/tagger.shtml 7http://nlp.cs.nyu.edu/evalb Figure 2: Comparison of the average number of the processed states of the structured perceptron with those of the MaxEnt model. equipped with an Intel Corei5 2.5GHz processor and 16GB of RAM. Feature We borrow the feature templates from Sagae and Lavie (2006). However, we found the</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>M. Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, University of Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms.</title>
<date>2002</date>
<booktitle>In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1--8</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics,</institution>
<contexts>
<context position="12559" citStr="Collins, 2002" startWordPosition="2151" endWordPosition="2152">how to achieve BFS with the structured perceptron, and the second is how to apply that BFS to constituent parsing. Interestingly, the solution to the first problem makes the second problem relatively trivial. 3.1 Superiority of Structured Perceptron We must design each priority of a state to satisfy the superiority condition. φ(ai, pi−1) = θTf(ai, pi−1) is the usual local score employed in structured perceptrons (Huang and Sagae, 2010) but we cannot use it as a local cost for two reasons. First, in our system, the best parse should have the lowest cost; it is opposite in the ordinary setting (Collins, 2002). We can resolve this conflict by changing the direction of structured perceptron training so that the best parse has the lowest score.4 Second, each φ(ai,pi−1) can take a negative value but the cost should always be positive. This is in contrast to the MaxEnt model in which the negative log probability is always positive. Our strategy is to add a constant offset δ to every local cost. If δ is large enough so that every score is positive, the superiority condition is satisfied.5 Unary Merging Though this technique solves the problem with the structured perceptron for a simpler shift-reduce sys</context>
<context position="18013" citStr="Collins, 2002" startWordPosition="3142" endWordPosition="3143"> 80 40 0 Model F1 Speed (Sent./s.) SP (reduced features) 88.9 0.8 ME (reduced features) 85.1 4.8 ME (full features) 86.3 2.5 Table 1: Results of BFS systems with dynamic programming for the Penn Treebank development set with different models and features. SP = the structured perceptron; ME = the MaxEnt. 0 20 40 60 Sentence length Perceptron MaxEnt Another difference is in training. The previous best-first shift-reduce parsers are all trained in the same way as a parser with greedy search since the model is local MaxEnt. In our case, we can use structured perceptron training with exact search (Collins, 2002); that is, at each iteration for each sentence, we find the current argmin derivation with BFS, then update the parameters if it differs from the gold derivation. Note that at the beginning of training, BFS is inefficient due to the initial flat parameters. We use a heuristic to speed up this process: For a few iterations (five, in our case), we train the model with beam search and an early update (Collins and Roark, 2004). We find that this approximation does not affect the performance, while it greatly reduces the training time. 4 Evaluation of Best-First Shift-Reduce Constituent Parsing Thi</context>
</contexts>
<marker>Collins, 2002</marker>
<rawString>Michael Collins. 2002. Discriminative Training Methods for Hidden Markov Models: Theory and Experiments with Perceptron Algorithms. In Proceedings of the 2002 Conference on Empirical Methods in Natural Language Processing, pages 1–8. Association for Computational Linguistics, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Hall</author>
<author>Greg Durrett</author>
<author>Dan Klein</author>
</authors>
<title>Less Grammar, More Features.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>228--237</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="2618" citStr="Hall et al., 2014" startWordPosition="411" endWordPosition="414">, the current state-of-the-art in shift-reduce parsing (Zhu et al., 2013). As we will see, this model change makes search quite hard, which motivates us to invent new feature templates as well as to improve the search algorithm. In existing parsers, features are commonly exploited from the parsing history, such as the top k elements on the stack. However, such features are expensive in terms of search efficiency. Instead of relying on features primarily from the stack, our features mostly come from the span of the top few nodes, an idea inspired by the recent empirical success in CRF parsing (Hall et al., 2014). We show that these span features also fit quite well in the shift-reduce system and lead to state-of-the-art accuracy. We further improve search with new A* heuristics that make optimal search for shift-reduce parsers with a structured perceptron tractable for the first time. The primary contribution of this paper is to demonstrate the effectiveness and the practicality of optimal search for shift-reduce parsing, especially when combined with appropriate features and efficient search. In English Penn Treebank experiments, our parser achieves an F1 score of 91.1 on test set at a speed of 13.6</context>
<context position="23723" citStr="Hall et al. (2014)" startWordPosition="4122" endWordPosition="4125">eatures we propose here are extracted from fundamentally different parts from these recent trends. Figure 4 explains how we extract atomic features from a state and Table 2 shows the full list of feature templates. Our system is unlexicalized; NP NNP NNP . ... a subsidiary of ITT Corp . 4 5 6 7 8 9 10 Figure 4: Atomic features of our system largely come from the span of a constituency. For each span (s0 and s1), we extract the surface form and POS tag of the preceding word (bw, bt), the first word (fw, ft), the last word (lw, lt), and the subsequent word (aw, at). shape is the same as that in Hall et al. (2014). Bold symbols are additional information from the system of Figure 3. The time complexity is O(n4 &apos; |G|3 &apos; |N|). q0.w o q0.t q1.w o q1.t q2.w o q2.t q3.w o q3.t s0.c o s0.ft s0.c o s0.fw s0.c o s0.lt s0.c o s0.lw s0.c o s0.at s0.c o s0.aw s0.c o s0.ft o s0.lt s0.c o s0.ft o s0.lw s0.c o s0.fw o s0.lt s0.c o s0.fw o s0.lw s0.c o s0.len s0.c o s0.shape s0.rule s0.shape o s0.rule s1.c o s1.ft s1.c o s1.fw s1.c o s1.lt s1.c o s1.lw s1.c o s1.bt s1.c o s1.bw s1.c o s1.ft o s1.lt s1.c o s1.ft o s1.lw s1.c o s1.fw o s1.lt s1.c o s1.fw o s1.lw s1.c o s1.len s1.c o s1.shape s1.rule s1.shape o s1.rule </context>
<context position="25049" citStr="Hall et al., 2014" startWordPosition="4409" endWordPosition="4412">s0.fw o q0.w s0.lw o q0.w q0.t o s0.fw q0.t o s0.lw s0.c o q0.w s0.c o q0.t s1.fw o q0.w s1.lw o q0.w q0.t o s1.fw q0.t o s1.lw s1.c o q0.w s1.c o q0.t q0.w o q1.w q0.t o q1.w q0.w o q1.t q0.t o q1.t s0.c o s1.c o q0.t s0.c o s1.c o q0.w s1.c o q0.t o s0.fw s1.c o q0.t o s0.lw s0.c o q0.t o s1.fw s0.c o q0.t o s1.fw Table 2: All feature templates in our span model. See Figure 4 for a description of each element. qz is the i-th top token on the queue. i.e., it does not use any head indices. This feature design is largely inspired by the recent empirical success of span features in CRF parsing (Hall et al., 2014). Their main finding is that the surface information on a subtree, such as the first or the last word of a span, has essentially the same amount of information as its head. For our system, such span features are much cheaper, so we expect they would facilitate our dynamic programming without sacrificing accuracy. We customize their features for fitting in the shift-reduce framework. Unlike the usual setting of PCFG parsing, shift-reduce parsers receive a POS-tagged sentence as input, so we use both the POS tag and surface form for each word on the span. One difficult part is using features wit</context>
<context position="35365" citStr="Hall et al., 2014" startWordPosition="6274" endWordPosition="6277">v and Klein, 2007) and the Stanford parser (Socher et al., 2013) in terms of F1. The parsing systems with external features or reranking outperform our system. However, it should be noted that our system could also be improved by external features. For example, the feature of type-level distributional similarity, such as Brown clustering (Brown et al., 1992), can be incorporated with our system without changing the theoretical runtime. 7 Related Work and Discussion Though the framework is shift-reduce, we can notice that our system is strikingly similar to the CKY-based discriminative parser (Hall et al., 2014) because our features basically come from two nodes on the stack and their spans. From this viewpoint, it is interesting to see that our system outperforms theirs by a large margin (Figure 6). Identifying the source of this performance change is beyond the scope of this paper, but we believe this is an important question for future parsing research. For example, it is interesting to see whether there is any structural advantage for shiftreduce over CKY by comparing two systems with exactly the same feature set. As shown in Section 4, the previous optimal parser on shift-reduce (Sagae and Lavie</context>
</contexts>
<marker>Hall, Durrett, Klein, 2014</marker>
<rawString>David Hall, Greg Durrett, and Dan Klein. 2014. Less Grammar, More Features. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 228–237, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic Programming for Linear-Time Incremental Parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1077--1086</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Uppsala, Sweden,</location>
<contexts>
<context position="9093" citStr="Huang and Sagae (2010)" startWordPosition="1523" endWordPosition="1526">ith its exponential operation (2). Unfortunately, this is not the case in our global structured perceptron because the score of each action is just the sum of the feature weights. Resolving this search difficulty is the central problem of this paper; we illustrate this problem in Section 4 and resolve it in Section 5. 1535 2.3 Hypergraph Search of Zhao et al. (2013) The worst time complexity of BFS in Sagae and Lavie (2006) is exponential. For dependency parsing, Zhao et al. (2013) reduce it to polynomial by converting the search graph into a hypergraph by using the state merging technique of Huang and Sagae (2010). This hypergraph search is the basis of our parser, so we will briefly review it here. The algorithm is closely related to agendabased best-first parsing algorithms for PCFGs (Klein and Manning, 2001; Pauls and Klein, 2009). As in those algorithms, it maintains two data structures: a chart C that preserves processed states as well as a priority queue (agenda) Q. The difference is in the basic items processed in C and Q. In PCFG parsing, they are spans. Each span abstracts many derivations on that span and the chart maps a span to the best (lowest cost) derivation found so far. In shift-reduce</context>
<context position="12384" citStr="Huang and Sagae, 2010" startWordPosition="2115" endWordPosition="2118">Perceptron This section describes our basic parsing system, i.e., shift-reduce constituent parsing with BFS and the structured perceptron. We have to solve two problems. The first is how to achieve BFS with the structured perceptron, and the second is how to apply that BFS to constituent parsing. Interestingly, the solution to the first problem makes the second problem relatively trivial. 3.1 Superiority of Structured Perceptron We must design each priority of a state to satisfy the superiority condition. φ(ai, pi−1) = θTf(ai, pi−1) is the usual local score employed in structured perceptrons (Huang and Sagae, 2010) but we cannot use it as a local cost for two reasons. First, in our system, the best parse should have the lowest cost; it is opposite in the ordinary setting (Collins, 2002). We can resolve this conflict by changing the direction of structured perceptron training so that the best parse has the lowest score.4 Second, each φ(ai,pi−1) can take a negative value but the cost should always be positive. This is in contrast to the MaxEnt model in which the negative log probability is always positive. Our strategy is to add a constant offset δ to every local cost. If δ is large enough so that every s</context>
<context position="15921" citStr="Huang and Sagae, 2010" startWordPosition="2753" endWordPosition="2756">process. Though the system cannot perform consecutive unary actions, in practice it can generate any unary chains as long as those in the training corpus by collapsing a chain into one rule. We preprocess the corpus in this way along with binarization (See Section 4). Note that this system is quite similar to the transition system for dependency parsing. The only changes are that we have several varieties of shift and reduce actions. This modification also makes it easy to apply an algorithm developed for dependency parsing to constituent parsing, such as dynamic programming with beam search (Huang and Sagae, 2010), which has not been applied into constituent parsing until quite recently (Mi and Huang, 2015) (See Section 7). Algorithm 1 BFS for Constituent Parsing; Only differences from Zhao et al. (2013) 1: procedure SHIFT(x, Q) 2: TRYADD(sh(x), Q) 3: for y E shu(x) do 4: TRYADD(y, Q) 5: procedure REDUCE(A, B, Q) 6: for (x, y) E A x B do 7: for z E re(x, y) U reu(x, y) do 8: TRYADD(z, Q) 3.2 BFS with Dynamic Programming Now applying BFS of Zhao et al. (2013) for dependency parsing into constituent parsing is not hard. Figure 1 shows the deductive system of dynamic programming, which is much similar to </context>
<context position="22289" citStr="Huang and Sagae, 2010" startWordPosition="3857" endWordPosition="3860">(p) using a reduce rule. it is combined with A* search, the speed reaches a practical level. 5 Improving Optimal Search Efficiency 5.1 Span Features The worst time complexity of hypergraph search for shift-reduce parsing can be analyzed with the deduction rule of the reduce step. Figure 3 shows an example. In this case, the time complexity is O(n3 &apos; |G |&apos; |N|) since there are three indices (i, j, k) and four nonterminals (A, B, C, D), on which three comprise a rule. The extra factor |N| compared with ordinary CKY parsing comes from the restriction that we extract features only from one state (Huang and Sagae, 2010). Complexity increases when we add new atomic features to each state. For example, if we lexicalize this model by adding features that depend on the head indices of s0 and/or s1, it increases to O(n6 &apos; |G |&apos; |N|) since we have to maintain three head indices of A, B, and C. This is why Sagae and Lavie’s features are too expensive for our system; they rely on head indices of s0, s1, s2, s3, the left and right children of s0 and s1, and so on, leading prohibitively huge complexity. Historically speaking, the success of shift-reduce approach in constituent parsing has been led by its success in de</context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic Programming for Linear-Time Incremental Parsing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1077– 1086, Uppsala, Sweden, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Parsing and Hypergraphs.</title>
<date>2001</date>
<booktitle>In Proceedings of the Seventh International Workshop on Parsing Technologies (IWPT-2001),</booktitle>
<pages>17--19</pages>
<location>Beijing, China.</location>
<contexts>
<context position="9293" citStr="Klein and Manning, 2001" startWordPosition="1556" endWordPosition="1559">ch difficulty is the central problem of this paper; we illustrate this problem in Section 4 and resolve it in Section 5. 1535 2.3 Hypergraph Search of Zhao et al. (2013) The worst time complexity of BFS in Sagae and Lavie (2006) is exponential. For dependency parsing, Zhao et al. (2013) reduce it to polynomial by converting the search graph into a hypergraph by using the state merging technique of Huang and Sagae (2010). This hypergraph search is the basis of our parser, so we will briefly review it here. The algorithm is closely related to agendabased best-first parsing algorithms for PCFGs (Klein and Manning, 2001; Pauls and Klein, 2009). As in those algorithms, it maintains two data structures: a chart C that preserves processed states as well as a priority queue (agenda) Q. The difference is in the basic items processed in C and Q. In PCFG parsing, they are spans. Each span abstracts many derivations on that span and the chart maps a span to the best (lowest cost) derivation found so far. In shift-reduce parsing, the basic items are not spans but states, i.e., partial representations of the stack.3 We denote p = (i, j, sd...s0) where si is the i-th top subtree on the stack and s0 spans i to j. We ext</context>
</contexts>
<marker>Klein, Manning, 2001</marker>
<rawString>Dan Klein and Christopher D. Manning. 2001. Parsing and Hypergraphs. In Proceedings of the Seventh International Workshop on Parsing Technologies (IWPT-2001), 17-19 October 2001, Beijing, China.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>A* Parsing: Fast Exact Viterbi Parse Selection.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03,</booktitle>
<pages>40--47</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="26292" citStr="Klein and Manning, 2003" startWordPosition="4631" endWordPosition="4634">e include this feature by memorizNP DT NN PP IN 1539 ing the previously applied rule for each span (subtree). This is a bit costly, because it means we have to preserve labels of the left and right children for each node, which lead to an additional |G|2 factor of complexity. However, we will see that this problem can be alleviated by our heuristic cost functions in A* search described below. 5.2 A* Search We now explain our A* search, another key technique for speeding up our search. To our knowledge, this is the first work to successfully apply A* search to shift-reduce parsing. A* parsing (Klein and Manning, 2003a) modifies the calculation of priority σ(pi) for state pi. In BFS, it is basically the prefix cost, the sum of every local cost (Section 3.1), which we denote as βpi: �βpi = (φ(aj, pj−1) + δ). 1&lt;j&lt;i In A* parsing, σ(pi) = βpi + h(pi) where h(pi) is a heuristic cost. βpi corresponds to the Viterbi inside cost of PCFG parsing (Klein and Manning, 2003a) while h(pi) is the Viterbi outside cost, an approximation of the cost for the future best path (action sequence) from pi. h(pi) must be a lower bound of the true Viterbi outside cost. In PCFG parsing, this is often achieved with a technique calle</context>
<context position="28521" citStr="Klein and Manning (2003" startWordPosition="5049" endWordPosition="5052">ally. a o s1.c o s1.ft θ θGP θLF SH o VP o NN 10.53 -5.82 -5.82 SH o SBAR o NN 1.98 -5.82 -5.82 SH o NP o NN -5.82 -5.82 -5.82 � � � SH o VP o DT 3.25 1.12 -5.82 SH o SBAR o DT 1.12 1.12 -5.82 SH o NP o DT 1.98 1.12 -5.82 � � � Table 3: Example of our feature projection. θGP is a weight vector with the GP, which collapses every c. θLF is with the LF, which collapses all elements in Table 4. s1.c s1.ft s1.fw s1.bt s1.bw s1.len s1.shape s1.rule s0.rule Table 4: List of feature elements ignored in the LF. Grammar Projection (GP) Our first projection borrows the idea from the filter projection of Klein and Manning (2003a), in which the grammar symbols (nonterminals) are collapsed into a single label X. Our projection, however, does not collapse all the labels into X; instead, we utilize constituent labels in level 2 from Charniak et al. (2006), in which labels that tend to be head, such as S or VP are collapsed into HP and others are collapsed into MP. θG in Table 3 is an example of how feature weights are relaxed with this projection. Here we show each feature as a tuple including action name (a). Let πGP be a feature projection function: e.g., ((a o s1.c o s1.ft) = (SH o VP o NN)) ~�1rGP ((a o s1.c o s1.ft</context>
<context position="36157" citStr="Klein and Manning, 2003" startWordPosition="6407" endWordPosition="6410">arge margin (Figure 6). Identifying the source of this performance change is beyond the scope of this paper, but we believe this is an important question for future parsing research. For example, it is interesting to see whether there is any structural advantage for shiftreduce over CKY by comparing two systems with exactly the same feature set. As shown in Section 4, the previous optimal parser on shift-reduce (Sagae and Lavie, 2006) was not so strong because of the locality of the model. Other optimal parsing systems are often based on relatively simple PCFGs, such as unlexicalized grammar (Klein and Manning, 2003b) or factored lexicalized grammar (Klein and Manning, 2003c) in which A* heuristics from the unlexicalized grammar guide search. However, those systems are not state-of-the-art probably due to the limited context captured with a simple PCFG. A recent trend has thus been extending the context of each rule (Petrov and Klein, 2007; Socher et al., 2013), but the resulting complex grammars make exact search intractable. In our system, the main source of information comes from spans as in CRF parsing. This is cheap yet strong, and leads to a fast and accurate parsing system with optimality. Concurr</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003a. A* Parsing: Fast Exact Viterbi Parse Selection. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology - Volume 1, NAACL ’03, pages 40–47, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Accurate Unlexicalized Parsing.</title>
<date>2003</date>
<booktitle>In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>423--430</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sapporo, Japan,</location>
<contexts>
<context position="26292" citStr="Klein and Manning, 2003" startWordPosition="4631" endWordPosition="4634">e include this feature by memorizNP DT NN PP IN 1539 ing the previously applied rule for each span (subtree). This is a bit costly, because it means we have to preserve labels of the left and right children for each node, which lead to an additional |G|2 factor of complexity. However, we will see that this problem can be alleviated by our heuristic cost functions in A* search described below. 5.2 A* Search We now explain our A* search, another key technique for speeding up our search. To our knowledge, this is the first work to successfully apply A* search to shift-reduce parsing. A* parsing (Klein and Manning, 2003a) modifies the calculation of priority σ(pi) for state pi. In BFS, it is basically the prefix cost, the sum of every local cost (Section 3.1), which we denote as βpi: �βpi = (φ(aj, pj−1) + δ). 1&lt;j&lt;i In A* parsing, σ(pi) = βpi + h(pi) where h(pi) is a heuristic cost. βpi corresponds to the Viterbi inside cost of PCFG parsing (Klein and Manning, 2003a) while h(pi) is the Viterbi outside cost, an approximation of the cost for the future best path (action sequence) from pi. h(pi) must be a lower bound of the true Viterbi outside cost. In PCFG parsing, this is often achieved with a technique calle</context>
<context position="28521" citStr="Klein and Manning (2003" startWordPosition="5049" endWordPosition="5052">ally. a o s1.c o s1.ft θ θGP θLF SH o VP o NN 10.53 -5.82 -5.82 SH o SBAR o NN 1.98 -5.82 -5.82 SH o NP o NN -5.82 -5.82 -5.82 � � � SH o VP o DT 3.25 1.12 -5.82 SH o SBAR o DT 1.12 1.12 -5.82 SH o NP o DT 1.98 1.12 -5.82 � � � Table 3: Example of our feature projection. θGP is a weight vector with the GP, which collapses every c. θLF is with the LF, which collapses all elements in Table 4. s1.c s1.ft s1.fw s1.bt s1.bw s1.len s1.shape s1.rule s0.rule Table 4: List of feature elements ignored in the LF. Grammar Projection (GP) Our first projection borrows the idea from the filter projection of Klein and Manning (2003a), in which the grammar symbols (nonterminals) are collapsed into a single label X. Our projection, however, does not collapse all the labels into X; instead, we utilize constituent labels in level 2 from Charniak et al. (2006), in which labels that tend to be head, such as S or VP are collapsed into HP and others are collapsed into MP. θG in Table 3 is an example of how feature weights are relaxed with this projection. Here we show each feature as a tuple including action name (a). Let πGP be a feature projection function: e.g., ((a o s1.c o s1.ft) = (SH o VP o NN)) ~�1rGP ((a o s1.c o s1.ft</context>
<context position="36157" citStr="Klein and Manning, 2003" startWordPosition="6407" endWordPosition="6410">arge margin (Figure 6). Identifying the source of this performance change is beyond the scope of this paper, but we believe this is an important question for future parsing research. For example, it is interesting to see whether there is any structural advantage for shiftreduce over CKY by comparing two systems with exactly the same feature set. As shown in Section 4, the previous optimal parser on shift-reduce (Sagae and Lavie, 2006) was not so strong because of the locality of the model. Other optimal parsing systems are often based on relatively simple PCFGs, such as unlexicalized grammar (Klein and Manning, 2003b) or factored lexicalized grammar (Klein and Manning, 2003c) in which A* heuristics from the unlexicalized grammar guide search. However, those systems are not state-of-the-art probably due to the limited context captured with a simple PCFG. A recent trend has thus been extending the context of each rule (Petrov and Klein, 2007; Socher et al., 2013), but the resulting complex grammars make exact search intractable. In our system, the main source of information comes from spans as in CRF parsing. This is cheap yet strong, and leads to a fast and accurate parsing system with optimality. Concurr</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003b. Accurate Unlexicalized Parsing. In Proceedings of the 41st Annual Meeting of the Association for Computational Linguistics, pages 423–430, Sapporo, Japan, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dan Klein</author>
<author>Christopher D Manning</author>
</authors>
<title>Factored A* Search for Models over Sequences and Trees.</title>
<date>2003</date>
<booktitle>In IJCAI-03, Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence,</booktitle>
<pages>1246--1251</pages>
<location>Acapulco, Mexico,</location>
<contexts>
<context position="26292" citStr="Klein and Manning, 2003" startWordPosition="4631" endWordPosition="4634">e include this feature by memorizNP DT NN PP IN 1539 ing the previously applied rule for each span (subtree). This is a bit costly, because it means we have to preserve labels of the left and right children for each node, which lead to an additional |G|2 factor of complexity. However, we will see that this problem can be alleviated by our heuristic cost functions in A* search described below. 5.2 A* Search We now explain our A* search, another key technique for speeding up our search. To our knowledge, this is the first work to successfully apply A* search to shift-reduce parsing. A* parsing (Klein and Manning, 2003a) modifies the calculation of priority σ(pi) for state pi. In BFS, it is basically the prefix cost, the sum of every local cost (Section 3.1), which we denote as βpi: �βpi = (φ(aj, pj−1) + δ). 1&lt;j&lt;i In A* parsing, σ(pi) = βpi + h(pi) where h(pi) is a heuristic cost. βpi corresponds to the Viterbi inside cost of PCFG parsing (Klein and Manning, 2003a) while h(pi) is the Viterbi outside cost, an approximation of the cost for the future best path (action sequence) from pi. h(pi) must be a lower bound of the true Viterbi outside cost. In PCFG parsing, this is often achieved with a technique calle</context>
<context position="28521" citStr="Klein and Manning (2003" startWordPosition="5049" endWordPosition="5052">ally. a o s1.c o s1.ft θ θGP θLF SH o VP o NN 10.53 -5.82 -5.82 SH o SBAR o NN 1.98 -5.82 -5.82 SH o NP o NN -5.82 -5.82 -5.82 � � � SH o VP o DT 3.25 1.12 -5.82 SH o SBAR o DT 1.12 1.12 -5.82 SH o NP o DT 1.98 1.12 -5.82 � � � Table 3: Example of our feature projection. θGP is a weight vector with the GP, which collapses every c. θLF is with the LF, which collapses all elements in Table 4. s1.c s1.ft s1.fw s1.bt s1.bw s1.len s1.shape s1.rule s0.rule Table 4: List of feature elements ignored in the LF. Grammar Projection (GP) Our first projection borrows the idea from the filter projection of Klein and Manning (2003a), in which the grammar symbols (nonterminals) are collapsed into a single label X. Our projection, however, does not collapse all the labels into X; instead, we utilize constituent labels in level 2 from Charniak et al. (2006), in which labels that tend to be head, such as S or VP are collapsed into HP and others are collapsed into MP. θG in Table 3 is an example of how feature weights are relaxed with this projection. Here we show each feature as a tuple including action name (a). Let πGP be a feature projection function: e.g., ((a o s1.c o s1.ft) = (SH o VP o NN)) ~�1rGP ((a o s1.c o s1.ft</context>
<context position="36157" citStr="Klein and Manning, 2003" startWordPosition="6407" endWordPosition="6410">arge margin (Figure 6). Identifying the source of this performance change is beyond the scope of this paper, but we believe this is an important question for future parsing research. For example, it is interesting to see whether there is any structural advantage for shiftreduce over CKY by comparing two systems with exactly the same feature set. As shown in Section 4, the previous optimal parser on shift-reduce (Sagae and Lavie, 2006) was not so strong because of the locality of the model. Other optimal parsing systems are often based on relatively simple PCFGs, such as unlexicalized grammar (Klein and Manning, 2003b) or factored lexicalized grammar (Klein and Manning, 2003c) in which A* heuristics from the unlexicalized grammar guide search. However, those systems are not state-of-the-art probably due to the limited context captured with a simple PCFG. A recent trend has thus been extending the context of each rule (Petrov and Klein, 2007; Socher et al., 2013), but the resulting complex grammars make exact search intractable. In our system, the main source of information comes from spans as in CRF parsing. This is cheap yet strong, and leads to a fast and accurate parsing system with optimality. Concurr</context>
</contexts>
<marker>Klein, Manning, 2003</marker>
<rawString>Dan Klein and Christopher D. Manning. 2003c. Factored A* Search for Models over Sequences and Trees. In IJCAI-03, Proceedings of the Eighteenth International Joint Conference on Artificial Intelligence, Acapulco, Mexico, August 9-15, 2003, pages 1246–1251.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marco Kuhlmann</author>
<author>Carlos G´omez-Rodr´ıguez</author>
<author>Giorgio Satta</author>
</authors>
<title>Dynamic Programming Algorithms for Transition-Based Dependency Parsers.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies,</booktitle>
<pages>673--682</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Portland, Oregon, USA,</location>
<marker>Kuhlmann, G´omez-Rodr´ıguez, Satta, 2011</marker>
<rawString>Marco Kuhlmann, Carlos G´omez-Rodr´ıguez, and Giorgio Satta. 2011. Dynamic Programming Algorithms for Transition-Based Dependency Parsers. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies, pages 673–682, Portland, Oregon, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mitchell P Marcus</author>
<author>Beatrice Santorini</author>
<author>Mary Ann Marcinkiewicz</author>
</authors>
<title>Building a Large Annotated Corpus of English: The Penn Treebank.</title>
<date>1993</date>
<booktitle>COMPUTATIONAL LINGUISTICS,</booktitle>
<pages>19--2</pages>
<contexts>
<context position="19215" citStr="Marcus et al., 1993" startWordPosition="3340" endWordPosition="3343">ituent Parsing This section evaluates the empirical performance of our best-first constituent parser that we built in the previous section. As mentioned in Section 2.2, the previous empirical success of best-first shiftreduce parsers might be due to the sparsity property of the MaxEnt model, which may not hold true in the structured perceptron. We investigate the validity of this assumption by comparing two systems, a locally trained MaxEnt model and a globally trained structured perceptron. Setting We follow the standard practice and train each model on section 2-21 of the WSJ Penn Treebank (Marcus et al., 1993), which is binarized using the algorithm in Zhang and Clark (2009) with the head rule of Collins (1999). We report the F1 scores for the development set of section 22. The Stanford POS tagger is used for part-ofspeech tagging.6 We used the EVALB program to evaluate parsing performance.7 Every experiment reported here was performed on hardware 6http://nlp.stanford.edu/software/tagger.shtml 7http://nlp.cs.nyu.edu/evalb Figure 2: Comparison of the average number of the processed states of the structured perceptron with those of the MaxEnt model. equipped with an Intel Corei5 2.5GHz processor and </context>
</contexts>
<marker>Marcus, Santorini, Marcinkiewicz, 1993</marker>
<rawString>Mitchell P. Marcus, Beatrice Santorini, and Mary Ann Marcinkiewicz. 1993. Building a Large Annotated Corpus of English: The Penn Treebank. COMPUTATIONAL LINGUISTICS, 19(2):313–330.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David McClosky</author>
<author>Eugene Charniak</author>
<author>Mark Johnson</author>
</authors>
<title>Reranking and Self-Training for Parser Adaptation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>337--344</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="34318" citStr="McClosky et al., 2006" startWordPosition="6098" endWordPosition="6101">.5 89.3 0.7 External/Reranking Charniak (2005) 91.2 91.8 91.5 2.1 McClosky (2006) 92.2 92.6 92.4 1.2 Zhu (2013) +semi 91.1 91.5 91.3 47.6 Table 6: The final results for section 23 of the Penn Treebank. The systems with † are reported by authors running on different hardware. We divide baseline state-of-the-art systems into three categories: shift-reduce systems (Sagae and Lavie, 2005; Sagae and Lavie, 2006; Zhu et al., 2013), other chart-based systems (Petrov and Klein, 2007; Socher et al., 2013), and the systems with external semi supervised features or reranking (Charniak and Johnson, 2005; McClosky et al., 2006; Zhu et al., 2013). 2013). The score with the non-DP beam size = 16 and Z&amp;C (89.1 F1) is the same as that reported in their paper (the features are the same). Final Experiment Table 6 compares our parsing system with those of previous studies. When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system outperforms all other systems including the Berkeley parser (Petrov and Klein, 2007) and the Stanford parser (Socher et al., 2013) in terms of F1. The parsing systems with external features or reranking outperform our system. However, it</context>
</contexts>
<marker>McClosky, Charniak, Johnson, 2006</marker>
<rawString>David McClosky, Eugene Charniak, and Mark Johnson. 2006. Reranking and Self-Training for Parser Adaptation. In Proceedings of the 21st International Conference on Computational Linguistics and 44th Annual Meeting of the Association for Computational Linguistics, pages 337–344, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Haitao Mi</author>
<author>Liang Huang</author>
</authors>
<title>Shift-Reduce Constituency Parsing with Dynamic Programming and POS Tag Lattice.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference on the North American Chapter of the Association for Computational Linguistics Human Language Technologies,</booktitle>
<location>Denver, Colorado,</location>
<contexts>
<context position="16016" citStr="Mi and Huang, 2015" startWordPosition="2768" endWordPosition="2771">ny unary chains as long as those in the training corpus by collapsing a chain into one rule. We preprocess the corpus in this way along with binarization (See Section 4). Note that this system is quite similar to the transition system for dependency parsing. The only changes are that we have several varieties of shift and reduce actions. This modification also makes it easy to apply an algorithm developed for dependency parsing to constituent parsing, such as dynamic programming with beam search (Huang and Sagae, 2010), which has not been applied into constituent parsing until quite recently (Mi and Huang, 2015) (See Section 7). Algorithm 1 BFS for Constituent Parsing; Only differences from Zhao et al. (2013) 1: procedure SHIFT(x, Q) 2: TRYADD(sh(x), Q) 3: for y E shu(x) do 4: TRYADD(y, Q) 5: procedure REDUCE(A, B, Q) 6: for (x, y) E A x B do 7: for z E re(x, y) U reu(x, y) do 8: TRYADD(z, Q) 3.2 BFS with Dynamic Programming Now applying BFS of Zhao et al. (2013) for dependency parsing into constituent parsing is not hard. Figure 1 shows the deductive system of dynamic programming, which is much similar to that in dependency parsing. One important change is that we include a cost for a shift (SH or S</context>
<context position="36798" citStr="Mi and Huang (2015)" startWordPosition="6512" endWordPosition="6515">ized grammar (Klein and Manning, 2003c) in which A* heuristics from the unlexicalized grammar guide search. However, those systems are not state-of-the-art probably due to the limited context captured with a simple PCFG. A recent trend has thus been extending the context of each rule (Petrov and Klein, 2007; Socher et al., 2013), but the resulting complex grammars make exact search intractable. In our system, the main source of information comes from spans as in CRF parsing. This is cheap yet strong, and leads to a fast and accurate parsing system with optimality. Concurrently with this work, Mi and Huang (2015) have developed another dynamic programming for constituent shift-reduce parsing by keeping the step size for a sentence to 4n − 2, instead of 2n, with an un-unary (stay) action. Their final score is 90.8 F1 on WSJ. Though they only experiment with beam-search, it is possible to build BFS with their transition system as well. 8 Conclusions To date, all practical shift-reduce parsers have relied on approximate search, which suffers from search errors but also allows to utilize unlimited features. The main result of this paper is to show another possibility of shift-reduce by proceeding in an op</context>
</contexts>
<marker>Mi, Huang, 2015</marker>
<rawString>Haitao Mi and Liang Huang. 2015. Shift-Reduce Constituency Parsing with Dynamic Programming and POS Tag Lattice. In Proceedings of the 2015 Conference on the North American Chapter of the Association for Computational Linguistics Human Language Technologies, Denver, Colorado, May. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
</authors>
<title>Algorithms for Deterministic Incremental Dependency Parsing.</title>
<date>2008</date>
<journal>Computational Linguistics,</journal>
<volume>34</volume>
<issue>4</issue>
<contexts>
<context position="4570" citStr="Nivre, 2008" startWordPosition="727" endWordPosition="728">ational Joint Conference on Natural Language Processing, pages 1534–1544, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics which changes the current state into the new one. For example, SHIFT pops the front word from the queue and pushes it onto the stack, while REDUCE(X) combines the top two elements on the stack into their parent.2 For example, if the top two elements on the stack are DT and NN, REDUCE(NP) combines these by applying the CFG rule NP —* DT NN. Unary Action The actions above are essentially the same as those in shift-reduce dependency parsing (Nivre, 2008), but a special action for constituent parsing UNARY(X) complicates the system and search. For example, if the top element on the stack is NN, UNARY(NP) changes it to NP by applying the rule NP —* NN. In particular, this causes inconsistency in the numbers of actions between derivations (Zhu et al., 2013), which makes it hard to apply the existing best first search for dependency grammar to our system. We revisit this problem in Section 3.1. Model The model of a shift-reduce parser gives a score to each derivation, i.e., an action sequence a = (a1, · · · , a|a|), in which each ai is a shift or</context>
<context position="22919" citStr="Nivre, 2008" startWordPosition="3973" endWordPosition="3974">ases when we add new atomic features to each state. For example, if we lexicalize this model by adding features that depend on the head indices of s0 and/or s1, it increases to O(n6 &apos; |G |&apos; |N|) since we have to maintain three head indices of A, B, and C. This is why Sagae and Lavie’s features are too expensive for our system; they rely on head indices of s0, s1, s2, s3, the left and right children of s0 and s1, and so on, leading prohibitively huge complexity. Historically speaking, the success of shift-reduce approach in constituent parsing has been led by its success in dependency parsing (Nivre, 2008), in which the head is the primary element, and we suspect this is the reason why the current constituent shift-reduce parsers mainly rely on deeper stack elements and their heads. The features we propose here are extracted from fundamentally different parts from these recent trends. Figure 4 explains how we extract atomic features from a state and Table 2 shows the full list of feature templates. Our system is unlexicalized; NP NNP NNP . ... a subsidiary of ITT Corp . 4 5 6 7 8 9 10 Figure 4: Atomic features of our system largely come from the span of a constituency. For each span (s0 and s1)</context>
</contexts>
<marker>Nivre, 2008</marker>
<rawString>Joakim Nivre. 2008. Algorithms for Deterministic Incremental Dependency Parsing. Computational Linguistics, 34(4):513–553.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Pauls</author>
<author>Dan Klein</author>
</authors>
<title>Hierarchical Search for Parsing.</title>
<date>2009</date>
<booktitle>In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics,</booktitle>
<pages>557--565</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Boulder, Colorado,</location>
<contexts>
<context position="9317" citStr="Pauls and Klein, 2009" startWordPosition="1560" endWordPosition="1563">ral problem of this paper; we illustrate this problem in Section 4 and resolve it in Section 5. 1535 2.3 Hypergraph Search of Zhao et al. (2013) The worst time complexity of BFS in Sagae and Lavie (2006) is exponential. For dependency parsing, Zhao et al. (2013) reduce it to polynomial by converting the search graph into a hypergraph by using the state merging technique of Huang and Sagae (2010). This hypergraph search is the basis of our parser, so we will briefly review it here. The algorithm is closely related to agendabased best-first parsing algorithms for PCFGs (Klein and Manning, 2001; Pauls and Klein, 2009). As in those algorithms, it maintains two data structures: a chart C that preserves processed states as well as a priority queue (agenda) Q. The difference is in the basic items processed in C and Q. In PCFG parsing, they are spans. Each span abstracts many derivations on that span and the chart maps a span to the best (lowest cost) derivation found so far. In shift-reduce parsing, the basic items are not spans but states, i.e., partial representations of the stack.3 We denote p = (i, j, sd...s0) where si is the i-th top subtree on the stack and s0 spans i to j. We extract features from sd...</context>
<context position="27647" citStr="Pauls and Klein, 2009" startWordPosition="4876" endWordPosition="4879">e wr* = minrEG:1r(r)=r* wr, where π(r) is a projection function which returns the set of rules that correspond to r in G*. In feature-based shift-reduce parsing, a rule weight corresponds to the sum of feature weights for an action a, that is, φ(a, pi) = θTf(a, pi). We calculate h(pi) with a relaxed feature function φ*(a, pi), which always returns a lower bound: φ*(a,pi) = θ*Tf(a,ci) G θTf(a,pi) = φ(a, pi). Note that we only have to modify the weight vector. If a relaxed weight satisfies θ*(k) G θ(k) for all k, that projection is correct. Our A* parsing is essentially hierarchical A* parsing (Pauls and Klein, 2009), and we calculate a heuristic cost h(p) on the fly using another chart for the relaxed space when a new state p is pushed into the priority queue. Below we introduce two different projection methods, which are orthogonal and later combined hierarchically. a o s1.c o s1.ft θ θGP θLF SH o VP o NN 10.53 -5.82 -5.82 SH o SBAR o NN 1.98 -5.82 -5.82 SH o NP o NN -5.82 -5.82 -5.82 � � � SH o VP o DT 3.25 1.12 -5.82 SH o SBAR o DT 1.12 1.12 -5.82 SH o NP o DT 1.98 1.12 -5.82 � � � Table 3: Example of our feature projection. θGP is a weight vector with the GP, which collapses every c. θLF is with the </context>
<context position="30650" citStr="Pauls and Klein, 2009" startWordPosition="5442" endWordPosition="5445">nts in Table 4 are selected so that all bold elements in Figure 4 would be eliminated; the complexity is O(n3 · |G |· |N|). In practice, this is still expensive. However, we note that the effects of these two heuristics are complementary: The LF reduces complexity to a cubic time bound, while the GP greatly reduces the size of grammar |G|; We combine these two ideas below. Hierarchical Projection (HP) The basic idea of this combined projection is to use the heuristics given by the GP to lead search of the LF. This is similar to the hierarchical A* for PCFGs with multilevel symbol refinements (Pauls and Klein, 2009). The difference is that their hierarchy is on the grammar symbols while our projection targets are features. When a state p is created, its heuristic score h(p) is calculated with the LF, which requires search for the outside cost in the space of the LF, but its worst time complexity is cubic. The GP is used to guide this search. For each state pLF in the space of the LF, the GP calculates the heuristic score. We will see that this combination works quite well in practice in the next section. 6 Experiment We build our final system by combining the ideas in Section 5 and the system in Section </context>
</contexts>
<marker>Pauls, Klein, 2009</marker>
<rawString>Adam Pauls and Dan Klein. 2009. Hierarchical Search for Parsing. In Proceedings of Human Language Technologies: The 2009 Annual Conference of the North American Chapter of the Association for Computational Linguistics, pages 557–565, Boulder, Colorado, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Slav Petrov</author>
<author>Dan Klein</author>
</authors>
<title>Improved Inference for Unlexicalized Parsing. In Human Language Technologies</title>
<date>2007</date>
<booktitle>The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference,</booktitle>
<pages>404--411</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Rochester, New York,</location>
<contexts>
<context position="1217" citStr="Petrov and Klein, 2007" startWordPosition="188" endWordPosition="191">onents: a scoring model for a tree and a search algorithm. In shift-reduce parsing, the focus of most previous studies has been the former, typically by enriching feature templates, while the search quality has often been taken less seriously. For example, the current state-of-the-art parsers for constituency (Zhu et al., 2013; Wang and Xue, 2014) and dependency (Bohnet et al., 2013) both employ beam search with a constant beam size, which may suffer from severe search errors. This is contrary to ordinary PCFG parsing which, while it often uses some approximations, has nearly optimal quality (Petrov and Klein, 2007). In this paper, we instead investigate the question of whether we can obtain a practical shift-reduce parser with state-of-the-art accuracy by focusing on optimal search quality like PCFG parsing. We base our system on best-first search for shiftreduce parsing formulated in Zhao et al. (2013), but it differs from their approach in two points. First, we focus on constituent parsing while they use dependency grammar. Second, and more crucially, they use a locally trained MaxEnt model, which is simple but not strong, while we explore 1The open source software of our system is available at https:</context>
<context position="34176" citStr="Petrov and Klein, 2007" startWordPosition="6075" endWordPosition="6078">n (A*) 90.9 91.2 91.1 13.6 Other (closed) Berkeley (2007) 90.1 90.3 90.2 6.1 Stanford (2013) (RNN) 90.3 90.7 90.5 3.3 Hall (2014) (CRF) 89.0 89.5 89.3 0.7 External/Reranking Charniak (2005) 91.2 91.8 91.5 2.1 McClosky (2006) 92.2 92.6 92.4 1.2 Zhu (2013) +semi 91.1 91.5 91.3 47.6 Table 6: The final results for section 23 of the Penn Treebank. The systems with † are reported by authors running on different hardware. We divide baseline state-of-the-art systems into three categories: shift-reduce systems (Sagae and Lavie, 2005; Sagae and Lavie, 2006; Zhu et al., 2013), other chart-based systems (Petrov and Klein, 2007; Socher et al., 2013), and the systems with external semi supervised features or reranking (Charniak and Johnson, 2005; McClosky et al., 2006; Zhu et al., 2013). 2013). The score with the non-DP beam size = 16 and Z&amp;C (89.1 F1) is the same as that reported in their paper (the features are the same). Final Experiment Table 6 compares our parsing system with those of previous studies. When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system outperforms all other systems including the Berkeley parser (Petrov and Klein, 2007) and the St</context>
<context position="36487" citStr="Petrov and Klein, 2007" startWordPosition="6460" endWordPosition="6463">ame feature set. As shown in Section 4, the previous optimal parser on shift-reduce (Sagae and Lavie, 2006) was not so strong because of the locality of the model. Other optimal parsing systems are often based on relatively simple PCFGs, such as unlexicalized grammar (Klein and Manning, 2003b) or factored lexicalized grammar (Klein and Manning, 2003c) in which A* heuristics from the unlexicalized grammar guide search. However, those systems are not state-of-the-art probably due to the limited context captured with a simple PCFG. A recent trend has thus been extending the context of each rule (Petrov and Klein, 2007; Socher et al., 2013), but the resulting complex grammars make exact search intractable. In our system, the main source of information comes from spans as in CRF parsing. This is cheap yet strong, and leads to a fast and accurate parsing system with optimality. Concurrently with this work, Mi and Huang (2015) have developed another dynamic programming for constituent shift-reduce parsing by keeping the step size for a sentence to 4n − 2, instead of 2n, with an un-unary (stay) action. Their final score is 90.8 F1 on WSJ. Though they only experiment with beam-search, it is possible to build BFS</context>
</contexts>
<marker>Petrov, Klein, 2007</marker>
<rawString>Slav Petrov and Dan Klein. 2007. Improved Inference for Unlexicalized Parsing. In Human Language Technologies 2007: The Conference of the North American Chapter of the Association for Computational Linguistics; Proceedings of the Main Conference, pages 404–411, Rochester, New York, April. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<date>2005</date>
<booktitle>Proceedings of the Ninth International Workshop on Parsing Technology, chapter A Classifier-Based Parser with Linear Run-Time Complexity,</booktitle>
<pages>125--132</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="34083" citStr="Sagae and Lavie, 2005" startWordPosition="6060" endWordPosition="6063">.1 87.8 87.9 2.2 Zhu (2013) (Z&amp;C) 90.2 90.7 90.4 93.4 Span (b=64, DP) 90.2 90.6 90.4 8.4 Span (A*) 90.9 91.2 91.1 13.6 Other (closed) Berkeley (2007) 90.1 90.3 90.2 6.1 Stanford (2013) (RNN) 90.3 90.7 90.5 3.3 Hall (2014) (CRF) 89.0 89.5 89.3 0.7 External/Reranking Charniak (2005) 91.2 91.8 91.5 2.1 McClosky (2006) 92.2 92.6 92.4 1.2 Zhu (2013) +semi 91.1 91.5 91.3 47.6 Table 6: The final results for section 23 of the Penn Treebank. The systems with † are reported by authors running on different hardware. We divide baseline state-of-the-art systems into three categories: shift-reduce systems (Sagae and Lavie, 2005; Sagae and Lavie, 2006; Zhu et al., 2013), other chart-based systems (Petrov and Klein, 2007; Socher et al., 2013), and the systems with external semi supervised features or reranking (Charniak and Johnson, 2005; McClosky et al., 2006; Zhu et al., 2013). 2013). The score with the non-DP beam size = 16 and Z&amp;C (89.1 F1) is the same as that reported in their paper (the features are the same). Final Experiment Table 6 compares our parsing system with those of previous studies. When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system ou</context>
</contexts>
<marker>Sagae, Lavie, 2005</marker>
<rawString>Kenji Sagae and Alon Lavie, 2005. Proceedings of the Ninth International Workshop on Parsing Technology, chapter A Classifier-Based Parser with Linear Run-Time Complexity, pages 125–132. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Alon Lavie</author>
</authors>
<title>A Best-First Probabilistic Shift-Reduce Parser.</title>
<date>2006</date>
<booktitle>In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions,</booktitle>
<pages>691--698</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sydney, Australia,</location>
<contexts>
<context position="7203" citStr="Sagae and Lavie (2006)" startWordPosition="1198" endWordPosition="1201">mation is hard, and the common practice is to rely on well-known heuristics such as an early update with beam search (Collins and Roark, 2004). We are not aware of any previous study that succeeded in training a structured perceptron for parsing without approximation. We will show how this becomes possible in Section 3. 2.2 Previous Best-First Shift-Reduce Parsing The basic idea behind best-first search (BFS) for shift-reduce parsing is assuming each parser state as a node on a graph and then searching for the minimal cost path from a start state (node) to the final state. This is the idea of Sagae and Lavie (2006), and it was later refined by Zhao et al. (2013). BFS gives a priority to each state, and a state with the highest priority (lowest cost) is always processed first. BFS guarantees that the first found goal is the best (optimality) if the superiority condition is satisfied: a state never has a lower cost than the costs of its previous states. Though the found parse is guaranteed to be optimal, in practice, current BFS-based systems are not stronger than other systems with approximate search (Zhu et al., 2013; Wang and Xue, 2014) since all existing systems are based on the MaxEnt model. With thi</context>
<context position="8898" citStr="Sagae and Lavie (2006)" startWordPosition="1490" endWordPosition="1493">bution over subsequent actions in the MaxEnt model. In other words, BFS is very efficient when only a few actions have dominant probabilities in each step, and the MaxEnt model facilitates this with its exponential operation (2). Unfortunately, this is not the case in our global structured perceptron because the score of each action is just the sum of the feature weights. Resolving this search difficulty is the central problem of this paper; we illustrate this problem in Section 4 and resolve it in Section 5. 1535 2.3 Hypergraph Search of Zhao et al. (2013) The worst time complexity of BFS in Sagae and Lavie (2006) is exponential. For dependency parsing, Zhao et al. (2013) reduce it to polynomial by converting the search graph into a hypergraph by using the state merging technique of Huang and Sagae (2010). This hypergraph search is the basis of our parser, so we will briefly review it here. The algorithm is closely related to agendabased best-first parsing algorithms for PCFGs (Klein and Manning, 2001; Pauls and Klein, 2009). As in those algorithms, it maintains two data structures: a chart C that preserves processed states as well as a priority queue (agenda) Q. The difference is in the basic items pr</context>
<context position="19895" citStr="Sagae and Lavie (2006)" startWordPosition="3443" endWordPosition="3446">k (2009) with the head rule of Collins (1999). We report the F1 scores for the development set of section 22. The Stanford POS tagger is used for part-ofspeech tagging.6 We used the EVALB program to evaluate parsing performance.7 Every experiment reported here was performed on hardware 6http://nlp.stanford.edu/software/tagger.shtml 7http://nlp.cs.nyu.edu/evalb Figure 2: Comparison of the average number of the processed states of the structured perceptron with those of the MaxEnt model. equipped with an Intel Corei5 2.5GHz processor and 16GB of RAM. Feature We borrow the feature templates from Sagae and Lavie (2006). However, we found the full feature templates make training and decoding of the structured perceptron much slower, and instead developed simplified templates by removing some, e.g., that access to the child information on the second top node on the stack.8 Result Table 1 summarizes the results that indicate our assumption is true. The structured perceptron has the best score even though we restrict the features. However, its parsing speed is much slower than that of the local MaxEnt model. To see the difference in search behaviors between the two models, Figure 2 plots the number of processed</context>
<context position="21497" citStr="Sagae and Lavie (2006)" startWordPosition="3715" endWordPosition="3718"> features are no longer state-ofthe-art. For example, Zhu et al. (2013) report higher scores by using beam search with much richer feature templates, though, as we have examined, it seems implausible to apply such features to our system. In the following, we find a practical solution for improving both parse accuracy and search efficiency in our system. We will see that our new features not only make BFS tractable, but also lead to comparable or even superior accuracy relative to the current mainstream features. When 8The other features that we removed are features 9–14 defined in Figure 1 of Sagae and Lavie (2006). 1538 Figure 3: A snippet of the hypergraph for the system that simulates a simple PCFG. p is the popped state, which is being expanded with a state of its left states L(p) using a reduce rule. it is combined with A* search, the speed reaches a practical level. 5 Improving Optimal Search Efficiency 5.1 Span Features The worst time complexity of hypergraph search for shift-reduce parsing can be analyzed with the deduction rule of the reduce step. Figure 3 shows an example. In this case, the time complexity is O(n3 &apos; |G |&apos; |N|) since there are three indices (i, j, k) and four nonterminals (A, B</context>
<context position="34106" citStr="Sagae and Lavie, 2006" startWordPosition="6064" endWordPosition="6067">013) (Z&amp;C) 90.2 90.7 90.4 93.4 Span (b=64, DP) 90.2 90.6 90.4 8.4 Span (A*) 90.9 91.2 91.1 13.6 Other (closed) Berkeley (2007) 90.1 90.3 90.2 6.1 Stanford (2013) (RNN) 90.3 90.7 90.5 3.3 Hall (2014) (CRF) 89.0 89.5 89.3 0.7 External/Reranking Charniak (2005) 91.2 91.8 91.5 2.1 McClosky (2006) 92.2 92.6 92.4 1.2 Zhu (2013) +semi 91.1 91.5 91.3 47.6 Table 6: The final results for section 23 of the Penn Treebank. The systems with † are reported by authors running on different hardware. We divide baseline state-of-the-art systems into three categories: shift-reduce systems (Sagae and Lavie, 2005; Sagae and Lavie, 2006; Zhu et al., 2013), other chart-based systems (Petrov and Klein, 2007; Socher et al., 2013), and the systems with external semi supervised features or reranking (Charniak and Johnson, 2005; McClosky et al., 2006; Zhu et al., 2013). 2013). The score with the non-DP beam size = 16 and Z&amp;C (89.1 F1) is the same as that reported in their paper (the features are the same). Final Experiment Table 6 compares our parsing system with those of previous studies. When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system outperforms all other sys</context>
<context position="35972" citStr="Sagae and Lavie, 2006" startWordPosition="6376" endWordPosition="6379">l et al., 2014) because our features basically come from two nodes on the stack and their spans. From this viewpoint, it is interesting to see that our system outperforms theirs by a large margin (Figure 6). Identifying the source of this performance change is beyond the scope of this paper, but we believe this is an important question for future parsing research. For example, it is interesting to see whether there is any structural advantage for shiftreduce over CKY by comparing two systems with exactly the same feature set. As shown in Section 4, the previous optimal parser on shift-reduce (Sagae and Lavie, 2006) was not so strong because of the locality of the model. Other optimal parsing systems are often based on relatively simple PCFGs, such as unlexicalized grammar (Klein and Manning, 2003b) or factored lexicalized grammar (Klein and Manning, 2003c) in which A* heuristics from the unlexicalized grammar guide search. However, those systems are not state-of-the-art probably due to the limited context captured with a simple PCFG. A recent trend has thus been extending the context of each rule (Petrov and Klein, 2007; Socher et al., 2013), but the resulting complex grammars make exact search intracta</context>
</contexts>
<marker>Sagae, Lavie, 2006</marker>
<rawString>Kenji Sagae and Alon Lavie. 2006. A Best-First Probabilistic Shift-Reduce Parser. In Proceedings of the COLING/ACL 2006 Main Conference Poster Sessions, pages 691–698, Sydney, Australia, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Socher</author>
<author>John Bauer</author>
<author>Christopher D Manning</author>
<author>Ng Andrew Y</author>
</authors>
<title>Parsing with Compositional Vector Grammars.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>455--465</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="34198" citStr="Socher et al., 2013" startWordPosition="6079" endWordPosition="6082">.6 Other (closed) Berkeley (2007) 90.1 90.3 90.2 6.1 Stanford (2013) (RNN) 90.3 90.7 90.5 3.3 Hall (2014) (CRF) 89.0 89.5 89.3 0.7 External/Reranking Charniak (2005) 91.2 91.8 91.5 2.1 McClosky (2006) 92.2 92.6 92.4 1.2 Zhu (2013) +semi 91.1 91.5 91.3 47.6 Table 6: The final results for section 23 of the Penn Treebank. The systems with † are reported by authors running on different hardware. We divide baseline state-of-the-art systems into three categories: shift-reduce systems (Sagae and Lavie, 2005; Sagae and Lavie, 2006; Zhu et al., 2013), other chart-based systems (Petrov and Klein, 2007; Socher et al., 2013), and the systems with external semi supervised features or reranking (Charniak and Johnson, 2005; McClosky et al., 2006; Zhu et al., 2013). 2013). The score with the non-DP beam size = 16 and Z&amp;C (89.1 F1) is the same as that reported in their paper (the features are the same). Final Experiment Table 6 compares our parsing system with those of previous studies. When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system outperforms all other systems including the Berkeley parser (Petrov and Klein, 2007) and the Stanford parser (Socher </context>
<context position="36509" citStr="Socher et al., 2013" startWordPosition="6464" endWordPosition="6467">n in Section 4, the previous optimal parser on shift-reduce (Sagae and Lavie, 2006) was not so strong because of the locality of the model. Other optimal parsing systems are often based on relatively simple PCFGs, such as unlexicalized grammar (Klein and Manning, 2003b) or factored lexicalized grammar (Klein and Manning, 2003c) in which A* heuristics from the unlexicalized grammar guide search. However, those systems are not state-of-the-art probably due to the limited context captured with a simple PCFG. A recent trend has thus been extending the context of each rule (Petrov and Klein, 2007; Socher et al., 2013), but the resulting complex grammars make exact search intractable. In our system, the main source of information comes from spans as in CRF parsing. This is cheap yet strong, and leads to a fast and accurate parsing system with optimality. Concurrently with this work, Mi and Huang (2015) have developed another dynamic programming for constituent shift-reduce parsing by keeping the step size for a sentence to 4n − 2, instead of 2n, with an un-unary (stay) action. Their final score is 90.8 F1 on WSJ. Though they only experiment with beam-search, it is possible to build BFS with their transition</context>
</contexts>
<marker>Socher, Bauer, Manning, Y, 2013</marker>
<rawString>Richard Socher, John Bauer, Christopher D. Manning, and Ng Andrew Y. 2013. Parsing with Compositional Vector Grammars. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 455–465, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiguo Wang</author>
<author>Nianwen Xue</author>
</authors>
<title>Joint POS Tagging and Transition-based Constituent Parsing in Chinese with Non-local Features.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>733--742</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="943" citStr="Wang and Xue, 2014" startWordPosition="142" endWordPosition="145"> that facilitate state merging of dynamic programming and A* search. Our system achieves 91.1 F1 on a standard English experiment, a level which cannot be reached by other beam-based systems even with large beam sizes.1 1 Introduction A parsing system comprises two components: a scoring model for a tree and a search algorithm. In shift-reduce parsing, the focus of most previous studies has been the former, typically by enriching feature templates, while the search quality has often been taken less seriously. For example, the current state-of-the-art parsers for constituency (Zhu et al., 2013; Wang and Xue, 2014) and dependency (Bohnet et al., 2013) both employ beam search with a constant beam size, which may suffer from severe search errors. This is contrary to ordinary PCFG parsing which, while it often uses some approximations, has nearly optimal quality (Petrov and Klein, 2007). In this paper, we instead investigate the question of whether we can obtain a practical shift-reduce parser with state-of-the-art accuracy by focusing on optimal search quality like PCFG parsing. We base our system on best-first search for shiftreduce parsing formulated in Zhao et al. (2013), but it differs from their appr</context>
<context position="7736" citStr="Wang and Xue, 2014" startWordPosition="1293" endWordPosition="1296">om a start state (node) to the final state. This is the idea of Sagae and Lavie (2006), and it was later refined by Zhao et al. (2013). BFS gives a priority to each state, and a state with the highest priority (lowest cost) is always processed first. BFS guarantees that the first found goal is the best (optimality) if the superiority condition is satisfied: a state never has a lower cost than the costs of its previous states. Though the found parse is guaranteed to be optimal, in practice, current BFS-based systems are not stronger than other systems with approximate search (Zhu et al., 2013; Wang and Xue, 2014) since all existing systems are based on the MaxEnt model. With this model, the speriority can easily be accomplished by using the negative log of (2), which is always positive and becomes smaller with higher probability. We focus instead on the structured perceptron, but achieving superiority with this model is not trivial. We resolve this problem in Section 3.1. In addition to the mathematical convenience, the MaxEnt model itself helps search. Sagae and Lavie ascribe the empirical success of their BFS to the sparseness of the distribution over subsequent actions in the MaxEnt model. In other</context>
</contexts>
<marker>Wang, Xue, 2014</marker>
<rawString>Zhiguo Wang and Nianwen Xue. 2014. Joint POS Tagging and Transition-based Constituent Parsing in Chinese with Non-local Features. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 733–742, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yue Zhang</author>
<author>Stephen Clark</author>
</authors>
<title>Transition-Based Parsing of the Chinese Treebank using a Global Discriminative Model.</title>
<date>2009</date>
<booktitle>In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09),</booktitle>
<pages>162--171</pages>
<location>Paris, France,</location>
<contexts>
<context position="3555" citStr="Zhang and Clark (2009)" startWordPosition="560" endWordPosition="563">er is to demonstrate the effectiveness and the practicality of optimal search for shift-reduce parsing, especially when combined with appropriate features and efficient search. In English Penn Treebank experiments, our parser achieves an F1 score of 91.1 on test set at a speed of 13.6 sentences per second. This score is in excess of that of a beam-based system with larger beam size and same speed. 2 Background and Related Work 2.1 Shift-Reduce Constituent Parsing We first introduce the shift-reduce algorithm for constituent structures. For space reasons, our exposition is rather informal; See Zhang and Clark (2009) for details. A shift-reduce parser parses a sentence through transitions between states, each of which consists of two data structures of a stack and a queue. The stack preserves intermediate parse results, while the queue saves unprocessed tokens. At each step, a parser selects an action, 1534 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, pages 1534–1544, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics which changes the current state into the</context>
<context position="19281" citStr="Zhang and Clark (2009)" startWordPosition="3351" endWordPosition="3354">of our best-first constituent parser that we built in the previous section. As mentioned in Section 2.2, the previous empirical success of best-first shiftreduce parsers might be due to the sparsity property of the MaxEnt model, which may not hold true in the structured perceptron. We investigate the validity of this assumption by comparing two systems, a locally trained MaxEnt model and a globally trained structured perceptron. Setting We follow the standard practice and train each model on section 2-21 of the WSJ Penn Treebank (Marcus et al., 1993), which is binarized using the algorithm in Zhang and Clark (2009) with the head rule of Collins (1999). We report the F1 scores for the development set of section 22. The Stanford POS tagger is used for part-ofspeech tagging.6 We used the EVALB program to evaluate parsing performance.7 Every experiment reported here was performed on hardware 6http://nlp.stanford.edu/software/tagger.shtml 7http://nlp.cs.nyu.edu/evalb Figure 2: Comparison of the average number of the processed states of the structured perceptron with those of the MaxEnt model. equipped with an Intel Corei5 2.5GHz processor and 16GB of RAM. Feature We borrow the feature templates from Sagae an</context>
<context position="32147" citStr="Zhang and Clark (2009)" startWordPosition="5728" endWordPosition="5731">s the effects of A* heuristics. In terms of search quality, the LF is better; it prunes 92.5% of states compared to naive BFS, while the GP prunes 75%. However, the LF takes more time to calculate 0 20 40 60 Sentence length Figure 6: Comparison of parsing times between A* and beam search (with DP). Feaure Z&amp;C feature set Span (this work) DP ✓ ✓ F1 F1 Sent./s. F1 F1 Sent./s. b=16 89.1 90.1 34.6 88.6 89.9 31.9 b=32 89.6 89.9 20.0 89.3 90.2 17.0 b=64 89.7 90.2 10.6 89.6 90.2 9.1 A* - - - - 90.7 13.6 BFS - - - - 90.7 1.1 Table 5: Results for the Penn Treebank development set. Z&amp;C = feature set of Zhang and Clark (2009). The speeds of non-DP and DP are the same, so we omit them from the comparison. heuristics than the GP. The HP combines the advantages of both, achieving the best result. Accuracy and Speed The F1 scores for the development set are summarized in Table 5. We can see that the systems with our new feature (span) perform surprisingly well, at a competitive level with the more expensive features of Zhang and Clark (2009) (Z&amp;C). This is particularly true with DP; it sometimes outperforms Z&amp;C, probably because our simple features facilitate state merging of DP, which expands search space. However, o</context>
</contexts>
<marker>Zhang, Clark, 2009</marker>
<rawString>Yue Zhang and Stephen Clark. 2009. Transition-Based Parsing of the Chinese Treebank using a Global Discriminative Model. In Proceedings of the 11th International Conference on Parsing Technologies (IWPT’09), pages 162–171, Paris, France, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kai Zhao</author>
<author>James Cross</author>
<author>Liang Huang</author>
</authors>
<title>Optimal Incremental Parsing via Best-First Dynamic Programming.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>758--768</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="1511" citStr="Zhao et al. (2013)" startWordPosition="234" endWordPosition="237">onstituency (Zhu et al., 2013; Wang and Xue, 2014) and dependency (Bohnet et al., 2013) both employ beam search with a constant beam size, which may suffer from severe search errors. This is contrary to ordinary PCFG parsing which, while it often uses some approximations, has nearly optimal quality (Petrov and Klein, 2007). In this paper, we instead investigate the question of whether we can obtain a practical shift-reduce parser with state-of-the-art accuracy by focusing on optimal search quality like PCFG parsing. We base our system on best-first search for shiftreduce parsing formulated in Zhao et al. (2013), but it differs from their approach in two points. First, we focus on constituent parsing while they use dependency grammar. Second, and more crucially, they use a locally trained MaxEnt model, which is simple but not strong, while we explore 1The open source software of our system is available at https://github.com/mynlp/optsr. Hiroshi Noji and Yusuke Miyao National Institute of Informatics, The Graduate University for Advanced Studies {noji,yusuke}@nii.ac.jp a structured perceptron, the current state-of-the-art in shift-reduce parsing (Zhu et al., 2013). As we will see, this model change ma</context>
<context position="7251" citStr="Zhao et al. (2013)" startWordPosition="1208" endWordPosition="1211">n well-known heuristics such as an early update with beam search (Collins and Roark, 2004). We are not aware of any previous study that succeeded in training a structured perceptron for parsing without approximation. We will show how this becomes possible in Section 3. 2.2 Previous Best-First Shift-Reduce Parsing The basic idea behind best-first search (BFS) for shift-reduce parsing is assuming each parser state as a node on a graph and then searching for the minimal cost path from a start state (node) to the final state. This is the idea of Sagae and Lavie (2006), and it was later refined by Zhao et al. (2013). BFS gives a priority to each state, and a state with the highest priority (lowest cost) is always processed first. BFS guarantees that the first found goal is the best (optimality) if the superiority condition is satisfied: a state never has a lower cost than the costs of its previous states. Though the found parse is guaranteed to be optimal, in practice, current BFS-based systems are not stronger than other systems with approximate search (Zhu et al., 2013; Wang and Xue, 2014) since all existing systems are based on the MaxEnt model. With this model, the speriority can easily be accomplish</context>
<context position="8839" citStr="Zhao et al. (2013)" startWordPosition="1479" endWordPosition="1482">al success of their BFS to the sparseness of the distribution over subsequent actions in the MaxEnt model. In other words, BFS is very efficient when only a few actions have dominant probabilities in each step, and the MaxEnt model facilitates this with its exponential operation (2). Unfortunately, this is not the case in our global structured perceptron because the score of each action is just the sum of the feature weights. Resolving this search difficulty is the central problem of this paper; we illustrate this problem in Section 4 and resolve it in Section 5. 1535 2.3 Hypergraph Search of Zhao et al. (2013) The worst time complexity of BFS in Sagae and Lavie (2006) is exponential. For dependency parsing, Zhao et al. (2013) reduce it to polynomial by converting the search graph into a hypergraph by using the state merging technique of Huang and Sagae (2010). This hypergraph search is the basis of our parser, so we will briefly review it here. The algorithm is closely related to agendabased best-first parsing algorithms for PCFGs (Klein and Manning, 2001; Pauls and Klein, 2009). As in those algorithms, it maintains two data structures: a chart C that preserves processed states as well as a priorit</context>
<context position="11119" citStr="Zhao et al. (2013)" startWordPosition="1893" endWordPosition="1896"> to pop the best (top) state p from the queue, push it into the chart, and then enqueue every state that can be obtained by a reduce action between p and other states in the chart or a shift action from p. The left states L(p) and right states R(p) are important concepts. L(p) is a set of states in the chart, with which p can reduce from the right side. Formally, L((i, j, sd...s0)) = pp {(h,i,s�d...s�0)|∀k E [1,d],fk(s�k−1) = fk(sk)}, where fk(·) returns atomic features on the k-th top node. See Figure 4 for how they look like in constituent parsing. R(p) is defined similarly; p can 3Although Zhao et al. (2013) explained that the items in Q are derivations (not states), we can implement Q as a set of states by keeping backpointers in a starndard way. reduce q E R(p) from the left side. When p is popped, it searches for every L(p) and R(p) in the chart and tries to expand the current derivation. The priority for each state is a pair (c, v). c is the prefix cost that is the total cost to reach that state, while v is the inside cost, a cost to build the top node s0. The top state in the queue has the lowest prefix cost, or the lowest inside cost if the two prefix costs are the same. 3 Best-First Shift-</context>
<context position="16115" citStr="Zhao et al. (2013)" startWordPosition="2784" endWordPosition="2787">rocess the corpus in this way along with binarization (See Section 4). Note that this system is quite similar to the transition system for dependency parsing. The only changes are that we have several varieties of shift and reduce actions. This modification also makes it easy to apply an algorithm developed for dependency parsing to constituent parsing, such as dynamic programming with beam search (Huang and Sagae, 2010), which has not been applied into constituent parsing until quite recently (Mi and Huang, 2015) (See Section 7). Algorithm 1 BFS for Constituent Parsing; Only differences from Zhao et al. (2013) 1: procedure SHIFT(x, Q) 2: TRYADD(sh(x), Q) 3: for y E shu(x) do 4: TRYADD(y, Q) 5: procedure REDUCE(A, B, Q) 6: for (x, y) E A x B do 7: for z E re(x, y) U reu(x, y) do 8: TRYADD(z, Q) 3.2 BFS with Dynamic Programming Now applying BFS of Zhao et al. (2013) for dependency parsing into constituent parsing is not hard. Figure 1 shows the deductive system of dynamic programming, which is much similar to that in dependency parsing. One important change is that we include a cost for a shift (SH or SHU) action in the prefix cost in a shift step, not a reduce step as in Zhao et al. (2013), since it</context>
</contexts>
<marker>Zhao, Cross, Huang, 2013</marker>
<rawString>Kai Zhao, James Cross, and Liang Huang. 2013. Optimal Incremental Parsing via Best-First Dynamic Programming. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages 758–768, Seattle, Washington, USA, October. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Muhua Zhu</author>
<author>Yue Zhang</author>
<author>Wenliang Chen</author>
<author>Min Zhang</author>
<author>Jingbo Zhu</author>
</authors>
<title>Fast and Accurate ShiftReduce Constituent Parsing.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers),</booktitle>
<pages>434--443</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Sofia, Bulgaria,</location>
<contexts>
<context position="922" citStr="Zhu et al., 2013" startWordPosition="138" endWordPosition="141"> feature templates that facilitate state merging of dynamic programming and A* search. Our system achieves 91.1 F1 on a standard English experiment, a level which cannot be reached by other beam-based systems even with large beam sizes.1 1 Introduction A parsing system comprises two components: a scoring model for a tree and a search algorithm. In shift-reduce parsing, the focus of most previous studies has been the former, typically by enriching feature templates, while the search quality has often been taken less seriously. For example, the current state-of-the-art parsers for constituency (Zhu et al., 2013; Wang and Xue, 2014) and dependency (Bohnet et al., 2013) both employ beam search with a constant beam size, which may suffer from severe search errors. This is contrary to ordinary PCFG parsing which, while it often uses some approximations, has nearly optimal quality (Petrov and Klein, 2007). In this paper, we instead investigate the question of whether we can obtain a practical shift-reduce parser with state-of-the-art accuracy by focusing on optimal search quality like PCFG parsing. We base our system on best-first search for shiftreduce parsing formulated in Zhao et al. (2013), but it di</context>
<context position="4876" citStr="Zhu et al., 2013" startWordPosition="780" endWordPosition="783">CE(X) combines the top two elements on the stack into their parent.2 For example, if the top two elements on the stack are DT and NN, REDUCE(NP) combines these by applying the CFG rule NP —* DT NN. Unary Action The actions above are essentially the same as those in shift-reduce dependency parsing (Nivre, 2008), but a special action for constituent parsing UNARY(X) complicates the system and search. For example, if the top element on the stack is NN, UNARY(NP) changes it to NP by applying the rule NP —* NN. In particular, this causes inconsistency in the numbers of actions between derivations (Zhu et al., 2013), which makes it hard to apply the existing best first search for dependency grammar to our system. We revisit this problem in Section 3.1. Model The model of a shift-reduce parser gives a score to each derivation, i.e., an action sequence a = (a1, · · · , a|a|), in which each ai is a shift or reduce action. Let p = (p1, · · · , p|a|) be the sequence of states, where pi is the state after applying ai to pi−1. p0 is the initial state for input sentence w. Then, the score for a derivation Φ(a) is calculated as the total score of every action: Φ(a) = � φ(ai,pi−1). (1) 1&lt;i&lt;|a| There are two well-k</context>
<context position="7715" citStr="Zhu et al., 2013" startWordPosition="1289" endWordPosition="1292">nimal cost path from a start state (node) to the final state. This is the idea of Sagae and Lavie (2006), and it was later refined by Zhao et al. (2013). BFS gives a priority to each state, and a state with the highest priority (lowest cost) is always processed first. BFS guarantees that the first found goal is the best (optimality) if the superiority condition is satisfied: a state never has a lower cost than the costs of its previous states. Though the found parse is guaranteed to be optimal, in practice, current BFS-based systems are not stronger than other systems with approximate search (Zhu et al., 2013; Wang and Xue, 2014) since all existing systems are based on the MaxEnt model. With this model, the speriority can easily be accomplished by using the negative log of (2), which is always positive and becomes smaller with higher probability. We focus instead on the structured perceptron, but achieving superiority with this model is not trivial. We resolve this problem in Section 3.1. In addition to the mathematical convenience, the MaxEnt model itself helps search. Sagae and Lavie ascribe the empirical success of their BFS to the sparseness of the distribution over subsequent actions in the M</context>
<context position="14746" citStr="Zhu et al., 2013" startWordPosition="2543" endWordPosition="2546"> X) q E G(p) Figure 1: The deductive system of our best-first shift-reduce constituent parsing explaining how the prefix cost and inside cost are calculated. FIN is omitted. |on the stack means an append operation and a(b) means a subtree a —* b. tj is the POS tag of j-th token while wj is the surface form. ca(p) is the cost for an action a of which features are extracted from p. Each ca(p) implicitly includes an offset δ. actions for each derivation, which means that the scores of two final states may contain different offset values. The existing modification to alleviate this inconsistency (Zhu et al., 2013) cannot be applied here because it is designed for beam search. We instead develop a new transition system, in which the number of actions to reach the final state is always 2n (n is the length of sentence). The basic idea is merging a unary action into each shift or reduce action. Our system uses five actions: • SH: original shift action; • SHU(X): shift a node, then immediately apply a unary rule to that node; • RE(X): original reduce action; • REU(Y, X): do reduce to X first, then immediately apply an unary rule Y —* X to it; • FIN: finish the process. Though the system cannot perform conse</context>
<context position="20946" citStr="Zhu et al. (2013)" startWordPosition="3620" endWordPosition="3623">ing speed is much slower than that of the local MaxEnt model. To see the difference in search behaviors between the two models, Figure 2 plots the number of processed (popped) states during search. Discussion This result may seem somewhat depressing. We have devised a new method that enables optimal search for the structured perceptron, but it cannot handle even modestly large feature templates. As we will see below, the time complexity of the system depends on the used features. We have tried features from Sagae and Lavie (2006), but their features are no longer state-ofthe-art. For example, Zhu et al. (2013) report higher scores by using beam search with much richer feature templates, though, as we have examined, it seems implausible to apply such features to our system. In the following, we find a practical solution for improving both parse accuracy and search efficiency in our system. We will see that our new features not only make BFS tractable, but also lead to comparable or even superior accuracy relative to the current mainstream features. When 8The other features that we removed are features 9–14 defined in Figure 1 of Sagae and Lavie (2006). 1538 Figure 3: A snippet of the hypergraph for </context>
<context position="34125" citStr="Zhu et al., 2013" startWordPosition="6068" endWordPosition="6071">.4 93.4 Span (b=64, DP) 90.2 90.6 90.4 8.4 Span (A*) 90.9 91.2 91.1 13.6 Other (closed) Berkeley (2007) 90.1 90.3 90.2 6.1 Stanford (2013) (RNN) 90.3 90.7 90.5 3.3 Hall (2014) (CRF) 89.0 89.5 89.3 0.7 External/Reranking Charniak (2005) 91.2 91.8 91.5 2.1 McClosky (2006) 92.2 92.6 92.4 1.2 Zhu (2013) +semi 91.1 91.5 91.3 47.6 Table 6: The final results for section 23 of the Penn Treebank. The systems with † are reported by authors running on different hardware. We divide baseline state-of-the-art systems into three categories: shift-reduce systems (Sagae and Lavie, 2005; Sagae and Lavie, 2006; Zhu et al., 2013), other chart-based systems (Petrov and Klein, 2007; Socher et al., 2013), and the systems with external semi supervised features or reranking (Charniak and Johnson, 2005; McClosky et al., 2006; Zhu et al., 2013). 2013). The score with the non-DP beam size = 16 and Z&amp;C (89.1 F1) is the same as that reported in their paper (the features are the same). Final Experiment Table 6 compares our parsing system with those of previous studies. When we look at closed settings, where no external resource other than the training Penn Treebank is used, our system outperforms all other systems including the </context>
</contexts>
<marker>Zhu, Zhang, Chen, Zhang, Zhu, 2013</marker>
<rawString>Muhua Zhu, Yue Zhang, Wenliang Chen, Min Zhang, and Jingbo Zhu. 2013. Fast and Accurate ShiftReduce Constituent Parsing. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (Volume 1: Long Papers), pages 434–443, Sofia, Bulgaria, August. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>