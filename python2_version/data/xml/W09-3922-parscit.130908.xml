<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.028352">
<title confidence="0.998388">
Automatic Generation of Information State Update Dialogue Systems that
Dynamically Create Voice XML, as Demonstrated on the iPhone
</title>
<author confidence="0.989229">
Helen Hastie, Xingkun Liu and Oliver Lemon
</author>
<affiliation confidence="0.9812345">
School of Informatics
University of Edinburgh
</affiliation>
<email confidence="0.998548">
{hhastie,xliu4,olemon}@inf.ed.ac.uk
</email>
<sectionHeader confidence="0.99389" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998517375">
We demonstrate DUDE&apos; (Dialogue
and Understanding Development En-
vironment), a prototype development
environment that automatically generates
dialogue systems from business-user
resources and databases. These generated
spoken dialogue systems (SDS) are then
deployed on an industry standard Voice
XML platform. Specifically, the deployed
system works by dynamically generating
context-sensitive Voice XML pages. The
dialogue move of each page is determined
in real time by the dialogue manager,
which is an Information State Update
engine. Firstly, we will demonstrate the
development environment which includes
automatic generation of speech recogni-
tion grammars for robust interpretation of
spontaneous speech, and uses the appli-
cation database to generate lexical entries
and grammar rules. A simple graphical
interface allows users (i.e. developers) to
easily and quickly create and the modify
SDS without the need for expensive
service providers. Secondly, we will
demonstrate the deployed system which
enables participants to call up and speak
to the SDS recently created. We will also
show a pre-built application running on
the iPhone and Google Android phone for
searching for places such as restaurants,
hotels and museums.
</bodyText>
<subsectionHeader confidence="0.956179">
&apos;Patent Pending
</subsectionHeader>
<sectionHeader confidence="0.975812" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999759416666667">
With the advent of new mobile platforms such as
the iPhone and Google Android, there is a need for
a new way to interact with applications and search
for information on the web. Google Voice Search
is one such example. However, we believe that
this simple “one-shot” search using speech recog-
nition is not optimal for the user. A service that
allows the user to have a dialogue via their phone
opens up a wider set of possibilities. For exam-
ple, the user may be visiting a foreign city and
would like to have a discussion about the types
of restaurants, their cuisine, their price-range and
even ask for recommendations from the system or
their friends on social networking sites. The Di-
alogue Understanding Development Environment
or DUDE makes this possible by providing a flex-
ible, natural, mixed initiative dialogue using an in-
formation state update dialogue engine (Bos et al.,
2003).
Currently, if a company wishes to deploy such
a spoken dialogue system, they have to employ
a costly service provider with a long turn around
time for any changes to the system, even minor
ones such as a special promotion offer. In addi-
tion, there is steep competition on application sites
such as Google Market Place and Apple App Store
which are populated with very cheap applications.
DUDE’s Development Environment takes existing
business-user resources and databases and auto-
matically generates the dialogue system. This re-
duces development time and, therefore, costs and
opens up the technology to a wider user-base. In
addition, the DUDE environment is so easy to use
that it gives the control back into the business-user
and away from independent services providers.
In this paper, we describe the architecture and
</bodyText>
<subsubsectionHeader confidence="0.791352">
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 148–151,
</subsubsectionHeader>
<affiliation confidence="0.947749">
Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics
</affiliation>
<page confidence="0.999026">
148
</page>
<bodyText confidence="0.999892666666667">
technology of the DUDE Development Environ-
ment and then discuss how the deployed system
works on a mobile platform.
</bodyText>
<sectionHeader confidence="0.984928" genericHeader="method">
2 The DUDE Development Environment
</sectionHeader>
<bodyText confidence="0.999887071428572">
Figure 1 shows the DUDE Development Envi-
ronment architecture whereby the main algorithm
takes the business-user resources and databases as
input and uses these to automatically generate the
spoken dialogue system which includes a Voice
XML generator. Advantages of using business-
user resources such as Business Process Mod-
els (BPM) (Williams, 1967) include the fact that
graphical interfaces and authoring environments
are widely available (e.g. Eclipse). In addition,
business-user resources can contain a lot of addi-
tional information as well as call flow including
context, multi-media and multiple customer inter-
actions.
</bodyText>
<subsectionHeader confidence="0.998317">
2.1 Spoken Dialogue System Generation
</subsectionHeader>
<bodyText confidence="0.999756194029851">
Many sophisticated research systems are devel-
oped for specific applications and cannot be eas-
ily transferred to another, even very similar task or
domain. The problem of components being do-
main specific is especially prevalent in the core
area of dialogue management. For example MIT’s
Pegasus and Mercury systems (Seneff, 2002) have
dialogue managers (DM) that use approximately
350 domain-specific hand-coded rules each. The
sheer amount of labour required to construct sys-
tems prevents them from being more widely and
rapidly deployed. We present a solution whereby
BPMs and related authoring tools are used to spec-
ify domain-specific dialogue interactions which
are combined with domain-general dialogue man-
agers. Specifically, the DM consults the BPM to
determine what task-based steps to take next, such
as asking for price range after establishing pre-
ferred cuisine type. General aspects of dialogue,
such as confirmation and clarification strategies,
are handled by the domain-general DM. Values
for constraints on transitions and branching in the
BPM, for example “present insurance offer if the
user is business-class”, are compiled into domain-
specific parts of the Information State. XML for-
mat is used for BPMs, and they are compiled into
finite state machines consulted by the spoken dia-
logue system. The domain-general dialogue man-
ager was mostly abstracted from the TALK system
(Lemon et al., 2006).
Using DUDE, developers do not have to write
a single line of grammar code. There are three
types of grammars: (1) a core grammar, (2) a
grammar generated from the database and BPM,
and (3) dynamically generated grammars created
during the dialogue. The core grammar (1) was
developed to cover basic information-seeking in-
teractions. In addition (2), the system com-
piles relevant database entries and their proper-
ties into the appropriate “slot-filling” parts of a
SRGS GRXML (Speech Recognition Grammar
Specification) grammar for each specific BPM
node. Task level grammars are used to allow a
level of mixed initiative, for example, if the sys-
tem asks “what type of cuisine?” the user can
reply with cuisine and also any other slot type,
such as, “cheap Italian”. The dynamically gen-
erated grammars (3), such as for restaurants cur-
rently being recommended, minimizes grammar
size and makes the system more efficient. In ad-
dition to the above-mentioned grammars, devel-
opers are able to provide task spotter phrases and
synonyms reflecting how users might respond by
using the DUDE Development Environment. If
these are not already covered by the existing gram-
mar, DUDE automatically generates rules to cover
them.
The generated SRGS GRXML grammars are
used to populate the Voice XML pages and conse-
quently used by the Voice XML Platform Speech
recogniser. In this case, we deploy our system to
the Voxeo Platform (http://www.voxeo.com). As
well as the W3C standard SRGS GRXML, DUDE
is able to generate alternative grammar specifica-
tions such as SRGS ABNF (Augmented Backus-
Naur Form), JSGF ABNF (Java Speech Grammar
Format) and Nuance’s GSL (Grammar Specifica-
</bodyText>
<figureCaption confidence="0.999876">
Figure 1: The DUDE Architecture
</figureCaption>
<page confidence="0.989049">
149
</page>
<figureCaption confidence="0.7855755">
Figure 2: Example: using the DUDE Development Environment to define spotter phrases and other
information for the different BPM tasks
</figureCaption>
<bodyText confidence="0.460115">
tion Language).
</bodyText>
<subsectionHeader confidence="0.972639">
2.2 The Development Environment
</subsectionHeader>
<bodyText confidence="0.988296268292683">
As mentioned above, the DUDE Development En-
vironment can be used to define system prompts
and add task spotter phrases and synonyms to the
grammars. Figure 2 shows the GUI with the BPM
on the left hand side and the properties pane for
the restaurants task on the right hand side. In this
pane the developer can define the system prompt,
the information to be presented to the user and the
spotter phrases. Here the developer is associating
the phrases “restaurants, restaurant, somewhere to
eat....” with the restaurant task. This means that
if the user says “I want somewhere to eat”, the
restaurant part of the BPM will be triggered. Note
that multi-word phrases may also be defined. The
defined spotters are automatically compiled into
the grammar for parsing and speech recognition.
By default all the lexical entries for answer-types
for the subtasks will already be present as spotter
phrases. DUDE checks for possible ambiguities,
for example if “pizza’ is a spotter for both cui-
sine type for a restaurant task and food type for a
shopping task, the system uses a clarification sub-
dialogue to resolve them at runtime.
Figure 3 shows the developer specifying the re-
quired linguistic information to automate the cui-
sine subtask of the restaurants task. Here the de-
veloper specifies the system prompt “What type
of cuisine do you want?” and a phrase for im-
plicit confirmation of provided values, e.g. “a [X]
restaurant”, where [X] is a variable that will be
replaced with the semantics of the speech recogni-
tion hypothesis for the user input. The developer
also specifies here the answer type that will resolve
the system prompt. There are predefined answer-
types extracted from the databases, and the devel-
oper can select and/or edit these, adding phrases
and synonyms. In addition, they have the ability
to define their own answer-types.
Figure 3: Example: using the DUDE Develop-
ment Environment to define prompts, answer sets,
and database mappings for the cuisine subtask
</bodyText>
<page confidence="0.996553">
150
</page>
<sectionHeader confidence="0.894689" genericHeader="method">
3 Deployment of the Generated Spoken
Dialogue System
</sectionHeader>
<bodyText confidence="0.95772396">
The second part of the demonstration shows
a pre-built multimodal application running on
the iPhone (http://www.apple.com) and Google
Android phone (http://code.google.com//android).
This application allows the user to have a dialogue
about places of interest using The List website
(http://www.list.co.uk). Figure 4 shows screen-
shots of the iPhone, firstly with The List home-
page and then a page with content on Bar Roma,
an “italian restaurant in Edinburgh” as requested
by the user through spoken dialogue.
Figure 4: DUDE-generated iPhone List Applica-
tion pushing relevant web content
Figure 5 shows the architecture of this system
whereby the DUDE server runs the spoken dia-
logue system (as outputted from the DUDE Devel-
opment Environment). This system dynamically
generates Voice XML pages whose dialogue move
and grammar is determined by the Information
State Update Dialogue Model. These Voice XML
pages are sent in real time to the Voice XML plat-
form (in our case Voxeo) which the user talks to by
placing a regular phone call. In addition, DUDE
communicates the relevant URL via a server con-
nection.
</bodyText>
<sectionHeader confidence="0.999325" genericHeader="evaluation">
4 Summary
</sectionHeader>
<bodyText confidence="0.996632428571428">
This paper describes a demonstration of the
DUDE Development Environment and its result-
ing spoken dialogue systems as deployed on a mo-
bile phone, specifically the iPhone and Google
Android. With the emergence of web-enabled
smart-phones, a new and innovative interactive
method is needed that combines web-surfing and
</bodyText>
<figureCaption confidence="0.565109">
Figure 5: Architecture of deployed DUDE Appli-
cation on a mobile phone (e.g. the iPhone)
</figureCaption>
<bodyText confidence="0.997153">
dialogue in order to get the user exactly the infor-
mation required in real time.
</bodyText>
<sectionHeader confidence="0.999323" genericHeader="conclusions">
5 Acknowledgement
</sectionHeader>
<bodyText confidence="0.99721475">
This project is funded by a Scottish Enterprise
Proof of Concept Grant (project number 8-ELM-
004). We gratefully acknowledge The List for giv-
ing us data for our prototype application.
</bodyText>
<sectionHeader confidence="0.999049" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999913894736842">
Johan Bos, Ewan Klein, Oliver Lemon, and Tetsushi
Oka. 2003. DIPPER: Description and Formalisa-
tion of an Information-State Update Dialogue Sys-
tem Architecture. In 4th SIGdial Workshop on Dis-
course and Dialogue, pages 115–124, Sapporo.
Adam Cheyer and David Martin. 2001. The Open
Agent Architecture. Journal of Autonomous Agents
and Multi-Agent Systems, 4(1/2):143–148.
Oliver Lemon, Kallirroi Georgila, James Henderson,
and Matthew Stuttle. 2006. An ISU dialogue sys-
tem exhibiting reinforcement learning of dialogue
policies: generic slot-filling in the TALK in-car sys-
tem. In Proceedings of EACL, pages 119–122.
Stephanie Seneff. 2002. Response Planning and Gen-
eration in the Mercury Flight Reservation System.
Computer Speech and Language, 16.
S Williams. 1967. Business process modeling im-
proves administrative control. Automation, pages
44–50.
</reference>
<page confidence="0.998351">
151
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.934891">
<title confidence="0.976895">Automatic Generation of Information State Update Dialogue Systems Dynamically Create Voice XML, as Demonstrated on the iPhone</title>
<author confidence="0.999279">Helen Hastie</author>
<author confidence="0.999279">Xingkun Liu</author>
<author confidence="0.999279">Oliver</author>
<affiliation confidence="0.997118">School of University of</affiliation>
<abstract confidence="0.999872727272727">demonstrate and Understanding Development Environment), a prototype development environment that automatically generates dialogue systems from business-user resources and databases. These generated spoken dialogue systems (SDS) are then deployed on an industry standard Voice XML platform. Specifically, the deployed system works by dynamically generating context-sensitive Voice XML pages. The dialogue move of each page is determined in real time by the dialogue manager, which is an Information State Update engine. Firstly, we will demonstrate the development environment which includes automatic generation of speech recognition grammars for robust interpretation of spontaneous speech, and uses the application database to generate lexical entries and grammar rules. A simple graphical interface allows users (i.e. developers) to easily and quickly create and the modify SDS without the need for expensive service providers. Secondly, we will demonstrate the deployed system which enables participants to call up and speak to the SDS recently created. We will also show a pre-built application running on the iPhone and Google Android phone for searching for places such as restaurants, hotels and museums.</abstract>
<intro confidence="0.99004">Pending</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Johan Bos</author>
<author>Ewan Klein</author>
<author>Oliver Lemon</author>
<author>Tetsushi Oka</author>
</authors>
<title>DIPPER: Description and Formalisation of an Information-State Update Dialogue System Architecture.</title>
<date>2003</date>
<booktitle>In 4th SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>115--124</pages>
<location>Sapporo.</location>
<contexts>
<context position="2416" citStr="Bos et al., 2003" startWordPosition="362" endWordPosition="365">ch using speech recognition is not optimal for the user. A service that allows the user to have a dialogue via their phone opens up a wider set of possibilities. For example, the user may be visiting a foreign city and would like to have a discussion about the types of restaurants, their cuisine, their price-range and even ask for recommendations from the system or their friends on social networking sites. The Dialogue Understanding Development Environment or DUDE makes this possible by providing a flexible, natural, mixed initiative dialogue using an information state update dialogue engine (Bos et al., 2003). Currently, if a company wishes to deploy such a spoken dialogue system, they have to employ a costly service provider with a long turn around time for any changes to the system, even minor ones such as a special promotion offer. In addition, there is steep competition on application sites such as Google Market Place and Apple App Store which are populated with very cheap applications. DUDE’s Development Environment takes existing business-user resources and databases and automatically generates the dialogue system. This reduces development time and, therefore, costs and opens up the technolo</context>
</contexts>
<marker>Bos, Klein, Lemon, Oka, 2003</marker>
<rawString>Johan Bos, Ewan Klein, Oliver Lemon, and Tetsushi Oka. 2003. DIPPER: Description and Formalisation of an Information-State Update Dialogue System Architecture. In 4th SIGdial Workshop on Discourse and Dialogue, pages 115–124, Sapporo.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adam Cheyer</author>
<author>David Martin</author>
</authors>
<title>The Open Agent Architecture.</title>
<date>2001</date>
<journal>Journal of Autonomous Agents and Multi-Agent Systems,</journal>
<pages>4--1</pages>
<marker>Cheyer, Martin, 2001</marker>
<rawString>Adam Cheyer and David Martin. 2001. The Open Agent Architecture. Journal of Autonomous Agents and Multi-Agent Systems, 4(1/2):143–148.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Oliver Lemon</author>
<author>Kallirroi Georgila</author>
<author>James Henderson</author>
<author>Matthew Stuttle</author>
</authors>
<title>An ISU dialogue system exhibiting reinforcement learning of dialogue policies: generic slot-filling in the TALK in-car system.</title>
<date>2006</date>
<booktitle>In Proceedings of EACL,</booktitle>
<pages>119--122</pages>
<contexts>
<context position="5695" citStr="Lemon et al., 2006" startWordPosition="865" endWordPosition="868">take next, such as asking for price range after establishing preferred cuisine type. General aspects of dialogue, such as confirmation and clarification strategies, are handled by the domain-general DM. Values for constraints on transitions and branching in the BPM, for example “present insurance offer if the user is business-class”, are compiled into domainspecific parts of the Information State. XML format is used for BPMs, and they are compiled into finite state machines consulted by the spoken dialogue system. The domain-general dialogue manager was mostly abstracted from the TALK system (Lemon et al., 2006). Using DUDE, developers do not have to write a single line of grammar code. There are three types of grammars: (1) a core grammar, (2) a grammar generated from the database and BPM, and (3) dynamically generated grammars created during the dialogue. The core grammar (1) was developed to cover basic information-seeking interactions. In addition (2), the system compiles relevant database entries and their properties into the appropriate “slot-filling” parts of a SRGS GRXML (Speech Recognition Grammar Specification) grammar for each specific BPM node. Task level grammars are used to allow a leve</context>
</contexts>
<marker>Lemon, Georgila, Henderson, Stuttle, 2006</marker>
<rawString>Oliver Lemon, Kallirroi Georgila, James Henderson, and Matthew Stuttle. 2006. An ISU dialogue system exhibiting reinforcement learning of dialogue policies: generic slot-filling in the TALK in-car system. In Proceedings of EACL, pages 119–122.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephanie Seneff</author>
</authors>
<title>Response Planning and Generation in the Mercury Flight Reservation System.</title>
<date>2002</date>
<journal>Computer Speech and Language,</journal>
<volume>16</volume>
<contexts>
<context position="4610" citStr="Seneff, 2002" startWordPosition="700" endWordPosition="701">al interfaces and authoring environments are widely available (e.g. Eclipse). In addition, business-user resources can contain a lot of additional information as well as call flow including context, multi-media and multiple customer interactions. 2.1 Spoken Dialogue System Generation Many sophisticated research systems are developed for specific applications and cannot be easily transferred to another, even very similar task or domain. The problem of components being domain specific is especially prevalent in the core area of dialogue management. For example MIT’s Pegasus and Mercury systems (Seneff, 2002) have dialogue managers (DM) that use approximately 350 domain-specific hand-coded rules each. The sheer amount of labour required to construct systems prevents them from being more widely and rapidly deployed. We present a solution whereby BPMs and related authoring tools are used to specify domain-specific dialogue interactions which are combined with domain-general dialogue managers. Specifically, the DM consults the BPM to determine what task-based steps to take next, such as asking for price range after establishing preferred cuisine type. General aspects of dialogue, such as confirmation</context>
</contexts>
<marker>Seneff, 2002</marker>
<rawString>Stephanie Seneff. 2002. Response Planning and Generation in the Mercury Flight Reservation System. Computer Speech and Language, 16.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S Williams</author>
</authors>
<title>Business process modeling improves administrative control.</title>
<date>1967</date>
<journal>Automation,</journal>
<pages>44--50</pages>
<contexts>
<context position="3967" citStr="Williams, 1967" startWordPosition="605" endWordPosition="606">ages 148–151, Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics 148 technology of the DUDE Development Environment and then discuss how the deployed system works on a mobile platform. 2 The DUDE Development Environment Figure 1 shows the DUDE Development Environment architecture whereby the main algorithm takes the business-user resources and databases as input and uses these to automatically generate the spoken dialogue system which includes a Voice XML generator. Advantages of using businessuser resources such as Business Process Models (BPM) (Williams, 1967) include the fact that graphical interfaces and authoring environments are widely available (e.g. Eclipse). In addition, business-user resources can contain a lot of additional information as well as call flow including context, multi-media and multiple customer interactions. 2.1 Spoken Dialogue System Generation Many sophisticated research systems are developed for specific applications and cannot be easily transferred to another, even very similar task or domain. The problem of components being domain specific is especially prevalent in the core area of dialogue management. For example MIT’s</context>
</contexts>
<marker>Williams, 1967</marker>
<rawString>S Williams. 1967. Business process modeling improves administrative control. Automation, pages 44–50.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>