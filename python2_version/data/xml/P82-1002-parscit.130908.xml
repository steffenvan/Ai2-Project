<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005374">
<title confidence="0.565014">
LINGUISTIC AND COMPUTATIONAL SEMANTICS*
</title>
<author confidence="0.776242">
Brian Cantwell Smith
</author>
<affiliation confidence="0.442179">
XEROX Palo Alto Research Center
3333 Coyote Hill Road, Palo Alto, CA 94304
</affiliation>
<sectionHeader confidence="0.574125" genericHeader="abstract">
ABSTRACT
</sectionHeader>
<bodyText confidence="0.999992265060241">
We argue that because the very concept of computation rests on
notions of interpretation, the semantics of natural languages and the
semantics of computational formalisms are in the deepest sense the
same subject. The attempt to use computational formalisms in aid of
an explanation of natural language semantics, therefore, is an
enterprise that must be undertaken with particular care. We describe
a framework for semantical analysis that we have used in the
computational realm, and suggest that it may serve to underwrite
computationally-oriented linguistic sen.antics as well. The major
feature of this framework is the explicit recognition of both the
declarative and the procedural import of meaningful expressions; we
argue that whereas these two viewpoints have traditionally been
taken as alternative, any comprehensive semantical theory must
account for how both aspects of an expression contribute to its
overall significance.
We have argued elsewherel that the distinguishing mark of
those objects and processes we call computational has to do with
attributed semantics: we humans find computational processes
coherent exactly because we attach semantical significance to their
behaviour, ingredients, and so forth. Put another way, computers,
on our view, are those devices that we understand by deploying our
linguistic faculties. For example, the reason that a calculator is a
computer, but a car is not, is that we take the ingredients of the
calculator to be symbolic (standing, in this particular case, for
numbers and functions and so forth), and understand the interactions
and organisation of the calculator in terms of that interpretation (this
part divides, this part represents the sum, and so on). Even though
by and large we are able to produce an explanation of the behaviour
that does not rest on external semantic attribution (this is the
formality condition mentioned by Fodor, Haugeland, and others2),
we nonetheless speak, when we use computational terms, in terms of
this semantics. These semantical concepts rest at the foundations of
the discipline: the particular organisations that computers have —
their computational raison d&apos;être — emerge not only from their
mechanical structure but also from their semantic interpretability.
Similarly, the terms of art employed in computer science — program,
compiler, implementation, interpreter, and so forth — will ultimately
be definable only with reference to this attributed semantics; they
will not, on our view, ever be found reducible to non-semantical
p red icates.3
This is a ramifying and problematic position, which we cannot
defend here.4 We may simply note, however, the overwhelming
evidence in favour of a semantical approach manifested by everyday
computational language. Even the simple view of computer science
as the study of symbol manipulation5 reveals this bias. Equally
telling is the fact that programming languages are called languages.
In addition, language-derived concepts like name and reference and
semantics permeate computational jargon (to say nothing of
interpreter, value, variable, memory, expression, identifier and so on)
— a fact that would be hard to explain if semantics were not
crucially involved. It is not just that in discussing computation we
use language; rather, in discussing computation we use words that
suggest that we are also talking about linguistic phenomena.
The question we will focus on in this paper, very briefly, is
this: if computational artefacts are fundamentally linguistic, and if,
therefore, it is appropriate to analyse them in terms of formal
theories of semantics (it is apparent that this is a widely held view),
then what is the proper relationship between the so-called
computational semantics that results, and more standard linguistic
semantics (the discipline that studies people and their natural
languages: how we mean, and what we are talking about, and all of,
that good stuff)? And furthermore, what is it to use computational
models to explain natural language semantics, if the computational
models are themselves in need of semantical analysis? On the face
of it, there would seem to be a certain complexity that should be
sorted out.
In answering these questions we will argue approximately as
follows: in the limit computational semantics and linguistic semantics
will coincide, at least in underlying conception, if not in surface
detail (for example some issues, like ambiguity, may arise in one case
and not in the other). Unfortunately, however, as presently used in
computer science the term &amp;quot;semantics&amp;quot; is given such an operational
cast that it distracts attention. from the human attribution of
significance to computational structures.6 In contrast, the most
successful models of natural language semantics, embodied for
example in standard model theories and even in Montague&apos;s
program, have concentrated almost exclusively on referential or
denotational aspects of declarative sentences. Judging only by
surface use, in other words, computational semantics and linguistic
semantics appear almost orthogonal in concern, even though they are
of course similar in style (for example they both use meta-theoretic
mathematical techniques — functional composition, and so forth —
to recursively specify the semantics of complex expressions from a
</bodyText>
<page confidence="0.995146">
9
</page>
<bodyText confidence="0.99203035">
given set of primitive atoms and formation rules). It is striking,
however, to observe two facts. First, computational semantics is
being pushed (by people and by need) more and more towards
declarative or referential issues. Second, natural language semantics,
particularly in computationally-based studies, is focusing more and
more on pragmatic questions of use and psychological import. Since
computational linguistics operates under the computational
hypothesis of mind, psychological issues are assumed to be modelled
by a field of computational structures and the state of a processor
running over them; thus these linguistic concerns with &amp;quot;use&amp;quot; connect
naturally with the &amp;quot;operational&amp;quot; flavour of standard programming
language semantics. It seems not implausible, therefore — we betray
our caution with the double negative — that a unifying framework
might be developed.
It will be the intent of this paper to present a specific, if
preliminary, proposal for such a framework. First, however, some
introductory comments. In a general sense of the term, semantics
can be taken as the study of the relationship between entities or
phenomena in a syntactic domain s and corresponding entities in a
semantic domain D, as pictured in the following diagram.
tv
Syntactic Domain S Semantic Domain D
We call the function mapping elements from the first domain into
elements of the second an interpretation function (to be sharply
distinguished7 from what in computer science is called an interpreter,
which is a different beast altogether). Note that the question of
whether an element is syntactic or semantic is a function of the point
of view; the syntactic domain for one interpretation function can
readily be the semantic domain of another (and a semantic domain
may of course include its own syntactic domain).
Not all relationships, of course, count as semantical; the
&amp;quot;grandmother&amp;quot; relationship fits into the picture just sketched, but
stakes no claim on being semantical. Though it has often been
discussed what constraints on such a relationship characterise
genuinely semantical ones (compositionality or recursive
specifiability, and a certain kind of formal character to the syntactic
domain, are among those typically mentioned), we will not pursue
such questions here. Rather, we will complicate our diagram as
follows, so as to enable us to characterise a rather large class of
computational and linguistic formalisms:
</bodyText>
<equation confidence="0.5845534">
Notation N2
0
Structure S2
‘vv
Designation DI
</equation>
<bodyText confidence="0.99972771875">
Ali and N2 are intended to be notational or communicational
expressions, in some externally observable and consensually
established medium of interaction, st ab strings of characters,
streams of words, or sequences of display images on a computer
terminal. The relationship e is an interpretation function mapping
notations into internal elements of some process over which the
primary semantical and processing regimens are defined. In first-
order logic, s, and s, would be something like abstract derivation
tree types of first-order formulae; if the diagram were applied to the
human mind, under the hypothesis of a formally encoded mentalese,
s„ and s, would be tokens of internal mentalese, and e would be the
function computed by the &amp;quot;linguistic&amp;quot; faculty (on a view such as that
of Fodor8). In adopting these terms we mean to be speaking very
generally; thus we mean to avoid, for example, any claim that tokens
of English are internalised (a term we will use for e) into
recognisable tokens of mentalese.. In particular, the proper account
of e for humans could well simply describe how the field of
mentalese structures, in some configuration, is transformed into some
other configuration, upon being presented with a particular English
sentence; this would still count, on our view, as a theory of e.
In contrast, is the interpretation function that makes explicit
the standard denotational significance of linguistic terms, relating, we
may presume, expressions in $ to the world of discourse. The
relationship between my mental token for T. S. Eliot, for example,
and the poet himself, would be formulated as part of 4). Again, we
speak very broadly; ti) is intended to manifest what, paradigmatically,
expressions are about, however that might best be formulated (ti
includes for example the interpretation functions of standard model
theories). *, in contrast, relates some internal structures or states to
others — one can imagine it specifically as the formally computed
derivability relationship in a logic, as the function computed by the
primitive language processor in a computational machine (i.e., as
Lisp&apos;s EVAL), Of more generally as the function that relates one
configuration of a field of symbols to another, in terms of the
modifications engendered by some internal processor computing over
those states. (to and are named, for mnemonic convenience, by
analogy with philosophy and psychology, since a study of is a study
of the relationship between expressions and the world — since
philosophy takes you &amp;quot;out of your mind&amp;quot;, so to speak — whereas a
study of 4. is a study of the internal relationships between symbols,
all of which, in contrast, are &amp;quot;within the head&amp;quot; of the person or
machine.)
Some simple comments. First, N1, Nt, St, 52, Di, and o, need
not all necessarily be distinct: in a case where s, is a self-referential
designator, for example, D, would be the same as s1; similarly, in a
case where computed a function that was designation-preserving,
then Di and 02 would be identical. Secondly, we need not take a
stand on which of and 4) has a prior claim to being the semantics
of s,. In standard logic, * (i.e., derivability: i—) is a relationship, but
is far from a function, and there is little tendency to think of it as
semantical; a study of 4, is called proof theory. In computational
systems, on the other hand, is typically much more constrained,
and is also, by and large, analysed mathematically in terms of
functions and so forth, in a manner much more like standard model
theories. Although in this author&apos;s view it seems a little far-fetched
to call the internal relationships (the &amp;quot;use&amp;quot; of a symbol) semantical,
it is nonetheless true that we are interested in characterising both,
and it is unnecesary to express a preference. For discussion, we will
refer to ou* &amp;quot;-semantics of a symbol or expression as its declarative
import, and refer to its *-semantics as its procedural consequence.
We have heard it said in other quarters that &amp;quot;procedural&amp;quot; and
&amp;quot;declarative&amp;quot; theories of semantics are contenders;9 to the extent that
we have been able to make sense of these notions, it appears that we
need both.
</bodyText>
<figure confidence="0.848816666666667">
Notation Ni
Structure SI
Designation 02
</figure>
<page confidence="0.964739">
10
</page>
<bodyText confidence="0.999974456896552">
It is possible to use this diagram to characterise a variety of
standard formal systems. In the standard models of the X-calculus,
for example, the designation function d) takes ?-expressions onto
functions; the procedural regimen 4,, usually consisting of a- and p-
roductions, can be shown to be 43-preserving. Similarly, if in a
standard predicate logic we take 4) to be (the inverse of the)
satisfaction relationship, with each element of $ being a sentence or
set of sentences, and elements of o being those possible worlds in
which those sentences are true, and similarly take * as the
derivability relationship, then soundness and completeness can be
expressed as the equation •P(S1,52) [oi c D2 1. As for all formal
systems (these presumably subsume the computational ones), it is
crucial that 4, be specifiable independent of d). The X-calculus and
predicate logic systems, furthermore, have no notion of a processor
with state; thus the appropriate * involves what we may call local
procedural consequence, relating a simple symbol or set of symbols
to another set. In a more complex computational circumstance, as
we will see below, it is appropriate to characterise a more complex
fru procedural consequence involving not only simple expressions,
but fuller encodings of the state of various aspects of the
computational machine (for example, at least environments and
continuations in the typical computational case&amp;quot;).
An important consequence of the analysis illustrated in the
last figure is that it enables one to ask a question not typically asked
ir computer science, about the (0-) semantic character of the
function computed by %P. Note that questions about soundness and
completeness in logic are exactly questions of this type. In separate
research,11 we have shown, by subjecting it to this kind of analysis,
that computational formalisms can be usefully analysed in these
terms as well. In particular, we demonstrated that the universally
axepted LISP evaluation protocol is semantically confused, in the
following sense: sometimes it preserves (1, (i.e. 41(&apos;P(S)) = d)(s)), and
sometimes it embodies (I) (i.e., *(s) = d)(s)). The traditional LISP
notion of evaluation, in other words, conflates simplification and
reference relationships, to its peril (in that report we propose some
LISP dialects in which these two are kept strictly separate). The
current moral, however, is merely that our approach allows the
question of the semantical import of •P to be asked.
As well as considering LISP, we may use our diagram to
caaracterise the various linguistically oriented projects carried on
under the banner of &amp;quot;semantics&amp;quot;. Model theories and formal
theories of language (we include Tarski and Montague in one sweep)
have concentrated primarily on 4). Natural language semantics in
some quarters12 focuses on e — on the translation into an internal
medium — although the question of what aspects of a given
sentence must be preserved in such a translation are of course of
concern (no translator could ignore the salient properties, semantical
and otherwise, of the target language, be it mentalese or predicate
logic, since the endeavour would otherwise be without constraint).
Lewis (for one) has argued that the project of articulating o — an
endeavour he calls markerese semantics — cannot really be called
semantics at al1,13 since it is essentially a translation relationship,
Ithough it is worth noting that e in computational formalisms is not
z lways trivial, and a case can at least be made that many superficial
aspects of natural language use, such as the resolution of indexicals,
may be resolved at this stage (if for example you say 1 am warm
then I may internalise your use of the first person pronoun into my
internal name for you).
Those artificial intelligence researchers working in knowledge
representation, perhaps without too much distortion, can be divided
into two groups: a) those whose primary semantical allegiance is to
d), and who (perhaps as a consequence) typically use an encoding of
first-order logic as •their representation language, and b) those who
concern themselves primarily with *, and who therefore (legitimately
enough) reject logic as even suggestive (4, in logic — derivability —
is a relatively unconstrained relationship, for one thing; secondly, the
relationship between the entailment relationship, to which
derivability is a hopeful approximation, and the proper &amp;quot;*&amp;quot; of
rational belief revision, is at least a matter of debate14).
Programming language semantics, for reasons that can at least
be explored, if not wholly explained, have focused primarily on *,
although in ways that tend to confuse it with d). Except for PROLOG,
which borrows its (lb straight from a subset of first-order logic, and
the LISPS mentioned earlier,15 we have never seen a semantical
account of a programming language that gave independent accounts
of ell and qt. There are complexities, furthermore, in knowing just
what the proper treatment of general languages should be. In a
separate paper&amp;quot; we argue that the notion program is inherently
defined as a set of expressions whose (4,-) semantic domain includes
data structures (and set-theoretic entities built up over them). In
other words, in a computational process that deals with finance, say,
the general data structures will likely designate individuals and
money and relationships among them, but the terms in that part of
the process called a program will not designate these people and
their money, but will instead designazz the data structures that
designate people and money (plus of course relationships and
functions over those data structures). Even on a declarative view like
ours, in other words, the appropriate semantic domain for programs
is built up over data structures — a situation strikingly like the
standard semantical accounts that take abstract records or locations
or whatever as elements of the otherwise mathematical domain for
programming language semantics. It may be that this fact that all
base terms in programs are meta-syntactic that has spawned the
confusion between operations and reference in the computational
setting.
Although the details of a general story remain to be worked
out, the LISP case mentioned earlier is instructive, by way of
suggestion as to how a more complete computational theory of
language semantics might go. In particular, because of the context
relativity and non-local effects that can emerge from processing a
LISP expression, 4, is not specifiable in a strict compositional way. 4,
— when taken to include the broadest possible notion that maps
entire configurations of the field of symbols and of the processor
itself onto other configurations and states — is of course recursively
specifiable (the same fact, in essence, as saying that LISP is a
deterministic formal calculus). A pure characterisation of * without
a concomitant account of 4), however, is unmotivated — as empty as
a specification of a derivability relationship would be for a calculus
for which no semantics had been given. Of more interest is the
ability to specify what we call a general significance function z, that
recursively specifies * and €1) together (this is what we were able to
do for LISP). In particular, given any expression sl, any
configuration of the rest of the symbols, and any state of the
processor, the function £ will specify the configuration and state that
would result (i.e., it will specify the use of so, and also the
relationship to the world that the whole signifies. For example,
</bodyText>
<page confidence="0.996235">
11
</page>
<bodyText confidence="0.995873181818182">
given a LISP expression of the form (+ 1 (PROG (S(TO A 2) A)), 2
would specify that the whole expression designated the number
three, that it would return the numeral &amp;quot;3&amp;quot;, and that the machine
would be left in a state in which the binding of the variable A was
changed to the numeral &amp;quot;2&amp;quot;. A modest result; what is important is
merely a) that both declarative import and procedural significance
must be reconstructed in order to tell a full story about LISP; and b)
that they must be formulated together.
Rather than pursue this view in detail, it is helpful to set out
several points that emerge from analyses developed within this
framework:
</bodyText>
<listItem confidence="0.928175833333333">
a. In most programming languages, 0 can be specified
compositionally and independently of 41 or sP — this amounts
to a formal statement of Fodor&apos;s modularity thesis for
language.17 In the case of formal systems, e is often context
free and compositional, but not always (reader macros can
render it opaque, or at least intensional, and some languages
</listItem>
<bodyText confidence="0.981814646464647">
such as ALGOL are apparently context-sensitive). It is
noteworthy, however, that there have been computational
languages for which 0 could not be specified indepently of
— a fact that is often stated as the fact that the programming
language &amp;quot;cannot be parsed except at runtime&amp;quot; (rEco and the
first versions of smarms had this character).
b. Since LISP is computational, it follows that a full account of
its * can be specified independent of (); this is in essence the
formality condition. It is important to bring out, however,
that a local version of * will typically not be compositional in
a modern computational formalism, even though such locality
holds in purely extensional context-free side-effect free
languages such as the A-calculus.
C. It is widely agreed that * does not uniquely determine s (this
is the &amp;quot;psychology narrowly construed&amp;quot; and the concomitant
methodological solipsism of Putnam and Fodor and others18).
However this fact is compatible with our foundational claim
that computational systems are distinguished in virtue of
having some version of 4) as part of their characterisation. A
very similar point can be made for logic; although any given
logic can (presumably) be given a mathematically-specified
model theory, that theory doesn&apos;t typically tie down what is
often called the standard model or interpretation — the
interpretation that we use. This fact does not release us,
however, from positing as a candidate logic only a formalism
that humans can interpret.
d. The declarative interpretation 41 cannot be wholly determined
independent of 4,, except in purely declarative languages (such
as the A-calculus and logic and so forth). This is to say that
without some account of the effect on the processor of one
fragment of a whole linguistic structure, it may be impossible
to say what that processor will take another fragment as
designating. The use of stro in LISP is an example; natural
language instances will be explored, below.
This last point needs a word of explanation. It is of course possible
to specify in mathematical terms without any explicit mention of a
*-like function; the approach we use in LISP defines both and 41
in terms of the overarching function 2 mentioned above, and we
could of course simply define 4) without defining * at all. Our
point, rather, is that any successful definition of will effectively
have to do the work of *, more or less explicitly, either by defining
some identifiable relationship, or else by embedding that relationship
within the meta-theoretic machinery. We are arguing, in other
words, only that the subject we intend 4, to cover must be treated in
some fashion or other.
What is perhaps surprising about all of this machinery is that
it must be brought to bear on a purely procedural language — all
three relationships (0, 4,, and sP) figure crucially in an account even
of LISP. We are not suggesting that LISP iS like natural languages:
to point out just one crucial difference, there is no way in LISP or in
any other programming language (except PROLOG) CO say anything,
whereas the ability to say things is clearly a foundational aspect of
any human language. The problem in the procedural languages is
one of what we may call assertional force; although it is possible to
construct a sentence-like expression with a clear declarative semantics
(such as some equivalent of &amp;quot;x 3&amp;quot;), one cannot use it in such a
way as to actually mean it — so as to have it carry any assertional
weight. For example, it is trivial to set some variable x to 3, or to
ask whether x is 3, but there is no way to state that x is 3. It should
be admitted, however, that computational languages bearing
assertional force are under considerable current investigation. This
general interest is probably one of the reasons for PROLOG&apos;S emergent
popularity; other computational systems with an explicit declarative
character include for example specification languages, data base
models, constraint languages, and knowledge representation
languages in A.I. We can only assume that the appropriate
semantics for all of these formalisms will align even more closely
with an illuminating semantics for natural language.
What does all of this have to do with natural language, and
with computational linguistics? The essential point is this: if this
characterisation of formal systems is tenable, and if the techniques of
standard programming language semantics can be fit into this mould,
then it may be possible to combine those approaches with the
techniques of programming language semantics and of logic and
model theories, to construct complex and interacting accounts of
and of (D. To take just one example, the techniques that are used to
construct mathematical accounts of environments and continuations
might be brought to bear on the issue of dealing with the complex
circumstances involving discourse models, theories of focus in
dealing with anaphora, and so on; both cases involve an attempt to
construct a recursively specifiable account of non-local interactions
among disparate fragments of a composite text. But the
contributions can proceed in the other direction as well: even from a
very simple application of this framework to this circumstance of
LISP, for example, we have been able to show how an accepted
computational notion fails to cohere with our attributed linguistically
based understanding, involving us in a major reconstruction of LISP&apos;S
foundations. The similarities are striking.
Our claim, in sum, is that similar phenomena occur in
programming languages and natural languages, and that each
discipline could benefit from the semantical techniques developed in
the other. Some examples of these similar phenomena will help to
motivate this view. The first is the issue ^ tt% appropriate use of
noun phrases: as well as employing a noun phrase in a standard
e position, natural language semantics has concerned itself
with more difficult cases such as intensional contexts (as in the
underlined designator in I didn&apos;t know The Big Apple was an island.
where the co-designating term New York cannot be substituted
without changing the meaning), the so-called attributive/referential
</bodyText>
<page confidence="0.997194">
12
</page>
<bodyText confidence="0.999807931623932">
distinction of Donellani° (the difference, roughly, between using a
noun phrase like &amp;quot;the man with a martini&amp;quot; to inform you that
someone is drinking a martini, as opposed to a situation where one
uses the hearer&apos;s belief or assumption that someone is drinking a
martini to refer to him), and so on. Another example different from
either of these is provided by the underlined term in For the next 20
!ears let&apos;s restrict the president&apos;s salary to $20,000, on the reading in
which after Reagan is defeated he is allowed to earn as much as he
pleases, but his successor comes under our constraint. The analagous
computational cases include for example the use of an expression
like (the formal analog of) make the sixth array element be 10 (i.e.,
: to). where we mean not that the current sixth element
should be 10 (the current sixth array element might at the moment
be 9, and 9 can&apos;t be 10), but rather that we would like the
description &amp;quot;the sixth array element&amp;quot; to refer to 10 (so-called &amp;quot;L-
values&amp;quot;, analogous to MACLISP&apos;S SETF construct). Or, to take a
different case, suppose we say set a&apos; to the sixth array element (i.e., x
am), where we mean not that x should be set to the current
sixth array element, but that it should always be equal to that
element (stated computationally this might be phrased as saying that
should track A(6); stated linguistically we might say that x should
mean &amp;quot;the sixth array element&amp;quot;). Although this is not a standard
type of assignment, the new constraint languages provide exactly
such facilities, and macros (classic computational intensional
operators) can be used in more traditional languages for such
purposes. Or, for a final example, consider the standard decimation:
INTEGER x, in which the term &amp;quot;x&amp;quot; refers neither to the variable itself
(variables are variables, not numbers), nor to its current designation,
but rather to whatever will satisfy the description &amp;quot;the value of x&amp;quot; at
any point in the course of a computation. All in all, we cannot
ignore the attempt on the computationalists&apos; part to provide complex
mechanisms so strikingly similar to the complex ways we use noun
phrases in English.
A very different sort of lingusitic phenomenon that occurs in
both programming languages and in natural language are what we
might call &amp;quot;premature exits&amp;quot;: cases where the processing of a local
fragment aborts the standard interpretation of an encompassing
discourse. If for example I say to you I was walking down the street
that leads to the house that Mary&apos;s aunt used to ... forget it; I was
taking a walk, then the &amp;quot;forget it&amp;quot; must be used to discard the
analysis of some amount of the previous sentence. The grammatical
structure of the subsequent phrase determines how much has been
discarded, of course; the sentence would still be comprehensible if
the phrase &amp;quot;an old house I like&amp;quot; followed the &amp;quot;forget it&amp;quot;. We are
not accustomed to semantical theories that deal with phenomena like
this, of course, but it is clear that any serious attempt to model real
language understanding will have to face them. Our present point is
merely that continuations20 enable computational formalisms to deal
exactly with the computational analogs of this: so-called escape
operators like MACLISP&apos;S THROW and CATCH and QUIT.
In addition, a full semantics of language will want to deal
with such sentences as If by 7flustrated&amp;quot; you mean what I think, then
she was certainly flustrated. The proper treatment of the first clause
in this sentence will presumably involve lots of &amp;quot;*&amp;quot; sorts of
considerations: its contribution to the remainder of the sentence has
more to do with the mental states of speaker and hearer than with
the world being describe by the presumed conversation. Once again,
the overarching computational hypothesis suggests that the way these
psychological effects must be modelled is in terms of alterations in
the state of an internal process running over a field of computational
structures.
As well as these specific examples, a couple of more general
morals can be drawn, important in that they speak directly to styles
of practice that we see in the literature. The first concerns the
suggestion, apparently of some currency, that we reject the notion of
logical form, and &amp;quot;do semantics directly&amp;quot; in a computational model.
On our account this is a mistake, pure and simple: to buy into the
computational framework is to believe that the ingredients in any
computational process are inherently linguistic, in need of
interpretation. Thus they too will need semantics; the internalisation
of English into a computer (0) is a translation relationship (in the
sense of preserving 43, presumably) — even if it is wildly contextual,
and even if the internal language is very different in structure from
the structure of English. It has sometimes been informally
suggested, in an analogous vein, that Montague semantics cannot be
taken seriously computationally, because the models that Montague
proposes are &amp;quot;too big&amp;quot; — how could you possibly carry these infinite
functions around in your head, we are asked to wonder. But of
course this argument comits a use/mention mistake: the only valid
computational reading of Montague would mean that mentalse (s)
would consist of designators of the functions Montague proposes,
and those designators can of course be a few short formulae,
It is another consequence of our view that any semanticist
who proposes some kind of &amp;quot;mental structure&amp;quot; in his or her account
of language is commited to providing an interpretation of that
structure. Consider for example a proposal that posits a notion of
&amp;quot;focus&amp;quot; for a discourse fragment. Such a focus might be viewed as a
(possibly abstract) entity in the world, or as a element of
computational structure playing such-and-such role in the
behavioural model of language understanding. It might seem that
these are alternative accounts: what our view insists is that an
interpretation of the latter must give it a designation (0); thus there
would be a computational structure (being biased, we will call it the
focus-designator), and a designation (that we call the focus-itself).
The complete account of focus would have to specify both of these
(either directly, or else by relying on the generic declarative
semantics to mediate between them), and also tell a story about how
the focus-designator plays a causal role (4,) in engendering the
proper behaviour in the computational model of language
understanding.
There is one final problem to be considered: what it is to
design an internal formalism s (the task, we may presume, of anyone
designing a knowledge representation language). Since, on our view,
we must have a semantics, we have the option either of having the
semantics informally described (or, even worse, tacitly assumed), or
else we can present an explicit account, either by defining such a
story ourselves or by borrowing from someone else. If the LISP case
can be taken as suggestive, a purely declarative model theory will be
inadequate to handle the sorts of comptuational interactions that
programming languages have required (and there is no a priori
reason to assume that successful computational models for natural
language will be found that are simpler than the programming
languages the community has found necessary for the modest sorts
of tasks computers are presently able to perform). However it is also
reasonable to expect that no direct analog to programming language
semantics will suffice, since they have to date been so concerned
with purely procedural (behavioural) consequence. It seems at least
</bodyText>
<page confidence="0.996749">
13
</page>
<bodyText confidence="0.999532108695652">
reasonable to suppose that a general interpretation function, of the
sort mentioned earlier, may be required.
Consider for example the KLONE language presented by
Brachman et aL21 Although no semantics for KLONE has been
presented, either procedural or declarative, its proponents have
worked both in investigating the e-simantics (how to translate
English into (LONE), and in developing an informal account of the
procedural aspects. Curiously, recent directions in that project would
suggest that its authors expect to be able to provide a &amp;quot;declarative-
only&amp;quot; account of Kum semantics (i.e., expect to be able to present
an account of II independent of si), in spite of our foregoing
remarks. Our only comment is to remark that independence of
procedural consequence is not a pre-requisite to an adequate
semantics; the two can be recursively specifiable together; thus this
apparent position is stronger than formally necessary - which makes
it perhaps of considerable interest.
In sum, we claim that any semantical account of either natural
language or computational language must specify e, 1,, and 41; if any
are left out, the account is not complete. We deny, furthermore, that
there is any fundamental distinction to be drawn between so-called
procedural languages (of which LISP is the paradigmatic example in
A.I.) and other more declarative languages (encodings of logic, or
representation languages). We deny as well, contrary to at least
some popular belief, the view that a mathematically well-specified
semantics for a candidate &amp;quot;mentalese&amp;quot; must be satisfied by giving an
independently specified declarative semantics (as would be possible
for an encoding of logic, for example). The designers of xat,22 for
example, for principled reasons denied the possibility of giving a
semantics independent of the procedures in which the KRL structures
participated; our simple account of LISP has at least suggested that
such an approach could be pursued on a mathematically sound
footing. Note however, in spite of our endorsement of what might
be called a procedural semantics, that this in no way frees one from
from giving a declarative semantics as well; procedural semantics and
declarative semantics are two pieces of a total story; they are not
alternatives.
6. The term &amp;quot;semantics&amp;quot; is only one of a large collection of terms,
unfortunately, that are technical terms in computer science and
in the attendant cognitive disciplines (including logic, philosophy
of language, linguistics, and psychology), with different
meanings and different connotations. Reference, interpretation,
memory, and value are just a few examples of the others. It is
our view that in spite of the fact that semantical vocabulary is
used in different ways, the fields are both semantical in
fundamentally the same ways: a unification of terminology
would only be for the best.
</bodyText>
<reference confidence="0.952887545454545">
7. An example of the phenomenon noted in footnote 6.
8. Fodor (forthcoming)
9. Woods (1981)
10. For a discussion of continuations see Gordon (1979), Steele and
Sussman (1978), and Smith (1982a); the formal device is
developed in Strachey &amp; Wadsworth (1974).
11. Smith (1982a).
12. A classic example is Katz and Postal (1964), but much of the
recent A.I. research in natural language in A.I. can be viewed in
this light.
13. Lewis (1972).
14. Israel (1980).
15. For a discussion of PROLOG see Clocksin &amp; Mellish (1981); the
LISPS are described in Smith (1982a).
16. Smith (forthcoming).
17. Fodor (forthcoming).
18. The term &amp;quot;methodological solipsism&amp;quot; is from Putnam (1975); see
also Fodor (1980).
19. Donnellan (1966).
20. See note 10, above.
21. Brachman (1979).
22. Bobrow and Winograd (1977).
</reference>
<sectionHeader confidence="0.975166" genericHeader="keywords">
REFERENCES
NOTES
</sectionHeader>
<bodyText confidence="0.95901">
I am grateful to Barbara Grosz and Hector Levesque for their
comments on an earlier draft of this short paper, and to Jane
</bodyText>
<reference confidence="0.988601">
Robinson for her original suggestion that it be written.
1. Smith (1982b)
2. Fodor (1978), Fodor (1980), Haugeland (forthcoming)
3. At least until the day arrives - if ever - when a successful
psychology of language is presented wherein all of human
semanticity is explained in non-semantical terms.
4. Problematic because it defines computation in a manner that is
derivative on mind (in that language is fundamentally a mental
phenomenon), thus dashing the hope that computational
psyly will offer a release from the semantic irreducibility
of previous accounts of human cognition. Though we state this
position and explore some of its consequences in Smith (1982b),
a considerably fuller treatment will be provided in Smith
(forthcoming).
5. See for example Newell (1980)
Bobrow, Daniel G., and Winograd, Terry, &amp;quot;An Overview of KRL: A
Knowledge Representation Language&amp;quot;, Cognitive Science 1 pp. 3-
46, 1977.
Brachman, Ronald, &amp;quot;On. the Epistemological Status of Semantic
Networks&amp;quot;, in Findler, Nicholas V. (ed.), Associative Networks:
Representation and Use of Knowledge by Computers, New York:
Academic Press, 1979.
Clocksin, W. F., and Mellish, C. S., Programming in Prolog, Berlin:
Springer-Verlag, 1981.
Donnellan, K., &amp;quot;Reference and Definite Descriptions&amp;quot;, Philosophical
Review 75:3 (1966) pp. 281-304; reprinted in Rosenberg and
Travis (eds.), Readings in the Philosophy of Language, Prentice-
Hall, 1971.
Fodor, Jerry, &amp;quot;Tom Swill and his Procedural Grandmother&amp;quot;,
Cognition 6, 1978; reprinted in Fodor (1981).
, &amp;quot;Methodological Solipsism Considered as a Research
Strategy in Cognitive Psychology&amp;quot;, The Behavioral and Brain
Sciences, 3:1 (1980) pp. 63-73; reprinted in Haugeland (ed.),
Mind Design, Cambridge: Bradford, 1981, and in Fodor (1981).
</reference>
<page confidence="0.984201">
14
</page>
<reference confidence="0.999639194444444">
Israel, David, &amp;quot;What&apos;s Wrong with Non-Monotonic Logic?&amp;quot;,
Proceedings of the First Annual Conference of the American
Association for Artificial Intelligence, Stanford, California, 1980,
pp. 99-101.
Katz, Jerrold, and Postal, Paul, An Integrated Theory of Linguistic
Descriptions, Cambridge: M.I.T. Press, 1964.
Lewis, David, &amp;quot;General Semantics&amp;quot;, in Davidson and Harman (eds.),
Semantics of Natural Langauges, Dordrecht, Holland: D. Reidel,
1972, pp. 169-218.
Newell, Allen, &amp;quot;Physical Symbol Systems&amp;quot;, Cognitive Science 4, pp.
135-183, 1980.
Putnam, Hilary, &amp;quot;The meaning of &apos;meaning&apos;&amp;quot;, in Putnam, Hilary,
Mind Language and Reality, Cambridge, U.K.: Cambridge
University Press, 1975.
Smith, Brian C., Reflection and Semantics in. a Procedural Language,
Laboratory for Computer Science Report LCS-TR-272, M.I.T.,
Cambridge, Mass., 1982 (a).
— , &amp;quot;Semantic Attribution and the Formality Condition&amp;quot;,
presented at the Eighth Annual Meeting of the Society for
Philosophy and Psychology, London, Ontario, Canada, May 13-
16, 1982 (b).
, The Computational Metaphor, Cambridge: Bradford
(forthcoming).
Steele, Guy, and Sussman, Gerald J., &amp;quot;The Art of the Interpreter, or
the Modularity Complex (parts Zero, One, and Two)&amp;quot;, M.I.T.
Artificial Intelligence Laboratory Memo AIM-453, Cambridge,
Mass, 1978.
Strachey, C., and Wadsworth, C. P., &amp;quot;Continuations — a
Mathematical Semantics for Handling Full Jumps&amp;quot;, PRG-11,
Programming Research Group, University of Oxford, 1974.
Woods, William A., &amp;quot;Procedural Semantics as a Theory of Meaning&amp;quot;,
Report No. 4627, Bolt Beranek and Newman, 50 Moulton St,
Cambridge, Mass., 02138; reprinted in Joshi, A., Sag, I., and
Webber, B., Computational Aspects of Linguistic Structures and
Discourse Settings, Cambridge, U.K.: Cambridge University
Press, 1982.
</reference>
<page confidence="0.997926">
15
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.002820">
<title confidence="0.999619">AND COMPUTATIONAL</title>
<author confidence="0.99988">Brian Cantwell Smith</author>
<affiliation confidence="0.999817">XEROX Palo Alto Research Center</affiliation>
<address confidence="0.999694">3333 Coyote Hill Road, Palo Alto, CA 94304</address>
<abstract confidence="0.997108708754211">We argue that because the very concept of computation rests on notions of interpretation, the semantics of natural languages and the semantics of computational formalisms are in the deepest sense the same subject. The attempt to use computational formalisms in aid of an explanation of natural language semantics, therefore, is an enterprise that must be undertaken with particular care. We describe a framework for semantical analysis that we have used in the computational realm, and suggest that it may serve to underwrite computationally-oriented linguistic sen.antics as well. The major feature of this framework is the explicit recognition of both the declarative and the procedural import of meaningful expressions; we argue that whereas these two viewpoints have traditionally been taken as alternative, any comprehensive semantical theory must account for how both aspects of an expression contribute to its overall significance. We have argued elsewherel that the distinguishing mark of objects and processes we call to do with semantics:we humans find computational processes coherent exactly because we attach semantical significance to their behaviour, ingredients, and so forth. Put another way, computers, our view, are those devices that we understand by our faculties. example, the reason that a calculator is a computer, but a car is not, is that we take the ingredients of the to be in this particular case, for numbers and functions and so forth), and understand the interactions and organisation of the calculator in terms of that interpretation (this part the sum, so on). Even though by and large we are able to produce an explanation of the behaviour that does not rest on external semantic attribution (this is the condition by Fodor, Haugeland, and we nonetheless speak, when we use computational terms, in terms of this semantics. These semantical concepts rest at the foundations of the discipline: the particular organisations that computers have — computational d&apos;être — not only from their mechanical structure but also from their semantic interpretability. the terms of art employed in computer science — implementation, interpreter, so forth — will ultimately be definable only with reference to this attributed semantics; they will not, on our view, ever be found reducible to non-semantical red This is a ramifying and problematic position, which we cannot We may simply note, however, the overwhelming evidence in favour of a semantical approach manifested by everyday computational language. Even the simple view of computer science the study of reveals this bias. Equally is the fact that programming languages are called addition, language-derived concepts like computational jargon (to say nothing of value, variable, memory, expression, identifier so on) — a fact that would be hard to explain if semantics were not crucially involved. It is not just that in discussing computation we rather, in discussing computation we use words that that we are also talking phenomena. The question we will focus on in this paper, very briefly, is this: if computational artefacts are fundamentally linguistic, and if, therefore, it is appropriate to analyse them in terms of formal theories of semantics (it is apparent that this is a widely held view), then what is the proper relationship between the so-called that results, and more standard semantics (the discipline that studies people and their natural languages: how we mean, and what we are talking about, and all of, good stuff)? And furthermore, what is it to to language semantics, if the computational models are themselves in need of semantical analysis? On the face of it, there would seem to be a certain complexity that should be sorted out. In answering these questions we will argue approximately as follows: in the limit computational semantics and linguistic semantics will coincide, at least in underlying conception, if not in surface detail (for example some issues, like ambiguity, may arise in one case and not in the other). Unfortunately, however, as presently used in computer science the term &amp;quot;semantics&amp;quot; is given such an operational that it distracts from the human attribution of to computational In contrast, the most successful models of natural language semantics, embodied for example in standard model theories and even in Montague&apos;s have concentrated almost exclusively on of declarative sentences. Judging only by surface use, in other words, computational semantics and linguistic appear almost orthogonal in though they are course similar in example they both use meta-theoretic mathematical techniques — functional composition, and so forth — to recursively specify the semantics of complex expressions from a 9 given set of primitive atoms and formation rules). It is striking, however, to observe two facts. First, computational semantics is being pushed (by people and by need) more and more towards declarative or referential issues. Second, natural language semantics, particularly in computationally-based studies, is focusing more and more on pragmatic questions of use and psychological import. Since computational linguistics operates under the computational hypothesis of mind, psychological issues are assumed to be modelled by a field of computational structures and the state of a processor running over them; thus these linguistic concerns with &amp;quot;use&amp;quot; connect naturally with the &amp;quot;operational&amp;quot; flavour of standard programming language semantics. It seems not implausible, therefore — we betray our caution with the double negative — that a unifying framework might be developed. It will be the intent of this paper to present a specific, if preliminary, proposal for such a framework. First, however, some comments. In a general sense of the term, taken as the study of the relationship between entities or in a domain s corresponding entities in domain pictured in the following diagram. tv Domain S Domain D We call the function mapping elements from the first domain into of the second an function(to be sharply from what in computer science is called an is a different beast altogether). Note that question of whether an element is syntactic or semantic is a function of the point of view; the syntactic domain for one interpretation function can readily be the semantic domain of another (and a semantic domain may of course include its own syntactic domain). Not all relationships, of course, count as semantical; the &amp;quot;grandmother&amp;quot; relationship fits into the picture just sketched, but stakes no claim on being semantical. Though it has often been discussed what constraints on such a relationship characterise genuinely semantical ones (compositionality or recursive specifiability, and a certain kind of formal character to the syntactic domain, are among those typically mentioned), we will not pursue such questions here. Rather, we will complicate our diagram as follows, so as to enable us to characterise a rather large class of computational and linguistic formalisms: Notation N2 0 Structure S2 Designation DI and intended to be in externally observable and consensually established medium of interaction, st ab strings of characters, streams of words, or sequences of display images on a computer terminal. The relationship e is an interpretation function mapping into elements some process over which the semantical and processing regimens are defined. In firstorder logic, s, and s, would be something like abstract derivation tree types of first-order formulae; if the diagram were applied to the human mind, under the hypothesis of a formally encoded mentalese, s„ and s, would be tokens of internal mentalese, and e would be the function computed by the &amp;quot;linguistic&amp;quot; faculty (on a view such as that In adopting these terms we mean to be speaking very thus we mean to avoid, for example, any claim that English are internalised(a term we will use for e) into recognisable tokens of mentalese.. In particular, the proper account humans could well simply describe how the field of mentalese structures, in some configuration, is transformed into some other configuration, upon being presented with a particular English sentence; this would still count, on our view, as a theory of e. In contrast, is the interpretation function that makes explicit the standard denotational significance of linguistic terms, relating, we presume, expressions in the world of discourse. The relationship between my mental token for T. S. Eliot, for example, and the poet himself, would be formulated as part of 4). Again, we speak very broadly; ti) is intended to manifest what, paradigmatically, are that might best be formulated (ti includes for example the interpretation functions of standard model theories). *, in contrast, relates some internal structures or states to others — one can imagine it specifically as the formally computed derivability relationship in a logic, as the function computed by the primitive language processor in a computational machine (i.e., as Of generally as the function that relates one configuration of a field of symbols to another, in terms of the modifications engendered by some internal processor computing over those states. (to and are named, for mnemonic convenience, by with a study of is a study of the relationship between expressions and the world — since philosophy takes you &amp;quot;out of your mind&amp;quot;, so to speak — whereas a of a study of the internal relationships between symbols, all of which, in contrast, are &amp;quot;within the head&amp;quot; of the person or machine.) simple comments. First, St, o, need not all necessarily be distinct: in a case where s, is a self-referential for example, D, would be the same as similarly, in a where computed a function that was and would be identical. Secondly, we need not take a on which of and 4) has a prior claim to being semantics of s,. In standard logic, * (i.e., derivability: i—) is a relationship, but is far from a function, and there is little tendency to think of it as study of is called In computational systems, on the other hand, is typically much more constrained, and is also, by and large, analysed mathematically in terms of functions and so forth, in a manner much more like standard model theories. Although in this author&apos;s view it seems a little far-fetched call the internal relationships (the &amp;quot;use&amp;quot; of a symbol) it is nonetheless true that we are interested in characterising both, and it is unnecesary to express a preference. For discussion, we will to ou* &amp;quot;-semantics of a symbol or expression as its import,and to its *-semantics as its consequence. We have heard it said in other quarters that &amp;quot;procedural&amp;quot; and theories of semantics are to the extent that we have been able to make sense of these notions, it appears that we need both. Notation Ni Structure SI Designation 02 10 It is possible to use this diagram to characterise a variety of standard formal systems. In the standard models of the X-calculus, for example, the designation function d) takes ?-expressions onto the procedural regimen usually consisting of aand pcan be shown to be if in a predicate logic we take be (the inverse of the) relationship, with each element of a sentence or set of sentences, and elements of o being those possible worlds in which those sentences are true, and similarly take * as the derivability relationship, then soundness and completeness can be as the equation c 1. for all formal systems (these presumably subsume the computational ones), it is that be specifiable independent of d). The X-calculus and predicate logic systems, furthermore, have no notion of a processor state; thus the appropriate * involves what we may call consequence,relating a simple symbol or set of symbols to another set. In a more complex computational circumstance, as we will see below, it is appropriate to characterise a more complex consequenceinvolving not only simple expressions, but fuller encodings of the state of various aspects of the computational machine (for example, at least environments and continuations in the typical computational case&amp;quot;). An important consequence of the analysis illustrated in the last figure is that it enables one to ask a question not typically asked computer science, about the (0-) the computed by that questions about soundness and completeness in logic are exactly questions of this type. In separate we have shown, by subjecting it to this kind of analysis, that computational formalisms can be usefully analysed in these terms as well. In particular, we demonstrated that the universally is semantically confused, in the sense: sometimes it (i.e. = and it *(s) = d)(s)). The traditional of evaluation, in other words, conflates to its peril (in that report we propose some in which these two are kept strictly separate). The current moral, however, is merely that our approach allows the of the semantical import of be asked. well as considering may use our diagram to caaracterise the various linguistically oriented projects carried on under the banner of &amp;quot;semantics&amp;quot;. Model theories and formal theories of language (we include Tarski and Montague in one sweep) have concentrated primarily on 4). Natural language semantics in focuses on e — on the translation into an internal medium — although the question of what aspects of a given sentence must be preserved in such a translation are of course of concern (no translator could ignore the salient properties, semantical and otherwise, of the target language, be it mentalese or predicate logic, since the endeavour would otherwise be without constraint). Lewis (for one) has argued that the project of articulating o — an he calls — cannot really be called at since it is essentially a translation relationship, Ithough it is worth noting that e in computational formalisms is not z lways trivial, and a case can at least be made that many superficial aspects of natural language use, such as the resolution of indexicals, be resolved at this stage (if for example you say am warm I may internalise your use of the first person pronoun into internal name for you). Those artificial intelligence researchers working in knowledge representation, perhaps without too much distortion, can be divided into two groups: a) those whose primary semantical allegiance is to d), and who (perhaps as a consequence) typically use an encoding of first-order logic as •their representation language, and b) those who concern themselves primarily with *, and who therefore (legitimately reject logic as even suggestive in logic — derivability — is a relatively unconstrained relationship, for one thing; secondly, the relationship between the entailment relationship, to which derivability is a hopeful approximation, and the proper &amp;quot;*&amp;quot; of belief revision, is at least a matter of Programming language semantics, for reasons that can at least be explored, if not wholly explained, have focused primarily on *, in ways that tend to confuse it with d). Except for borrows its from a subset of first-order logic, and we have never seen a semantical of a programming language that gave are complexities, furthermore, in knowing just what the proper treatment of general languages should be. In a paper&amp;quot; we argue that the notion inherently as a set of expressions whose semantic domain includes structures set-theoretic entities built up over them). In other words, in a computational process that deals with finance, say, structures will likely designate individuals and money and relationships among them, but the terms in that part of process called a not designate these people and money, but will instead designazz data structures that people money of course relationships and over those data structures). Even on a like ours, in other words, the appropriate semantic domain for programs is built up over data structures — a situation strikingly like the standard semantical accounts that take abstract records or locations or whatever as elements of the otherwise mathematical domain for programming language semantics. It may be that this fact that all terms in programs are has spawned the confusion between operations and reference in the computational setting. Although the details of a general story remain to be worked the mentioned earlier is instructive, by way of suggestion as to how a more complete computational theory of language semantics might go. In particular, because of the context relativity and non-local effects that can emerge from processing a is not specifiable in a strict compositional way. — when taken to include the broadest possible notion that maps entire configurations of the field of symbols and of the processor itself onto other configurations and states — is of course recursively (the same fact, in essence, as saying that a formal calculus). A pure characterisation of * a concomitant account of 4), however, is unmotivated — as empty as a specification of a derivability relationship would be for a calculus for which no semantics had been given. Of more interest is the to specify what we call a significance functionz, specifies * and (this is what we were able to for LISP). In particular, given any expression any configuration of the rest of the symbols, and any state of the the function specify the configuration and state that result (i.e., it will specify the so, and also the relationship to the world that the whole signifies. For example, 11 a of the form (+ 1 (S(TO 2) A)), would specify that the whole expression designated the number three, that it would return the numeral &amp;quot;3&amp;quot;, and that the machine would be left in a state in which the binding of the variable A was changed to the numeral &amp;quot;2&amp;quot;. A modest result; what is important is a) that import and procedural significance be reconstructed in order to tell a full story about b) that they must be formulated together. Rather than pursue this view in detail, it is helpful to set out several points that emerge from analyses developed within this framework: a. In most programming languages, 0 can be specified and independently of — amounts a formal statement of Fodor&apos;s for In the case of e is often context and compositional, but not always macros render it opaque, or at least intensional, and some languages as apparently context-sensitive). It is noteworthy, however, that there have been computational languages for which 0 could not be specified indepently of — a fact that is often stated as the fact that the programming language &amp;quot;cannot be parsed except at runtime&amp;quot; (rEco and the first versions of smarms had this character). Since computational, it follows that a of its * can be specified independent of (); this is in essence the formality condition. It is important to bring out, however, a of * will typically not be compositional in a modern computational formalism, even though such locality holds in purely extensional context-free side-effect free languages such as the A-calculus. C. It is widely agreed that * does not uniquely determine s (this is the &amp;quot;psychology narrowly construed&amp;quot; and the concomitant solipsism of Putnam and Fodor and However this fact is compatible with our foundational claim that computational systems are distinguished in virtue of of 4) as part of their characterisation. A similar point can be made for logic; although any logic can (presumably) be given a mathematically-specified model theory, that theory doesn&apos;t typically tie down what is called the or interpretation — the interpretation that we use. This fact does not release us, however, from positing as a candidate logic only a formalism that humans can interpret. The declarative interpretation cannot be wholly determined of except in purely declarative languages (such as the A-calculus and logic and so forth). This is to say that without some account of the effect on the processor of one fragment of a whole linguistic structure, it may be impossible to say what that processor will take another fragment as The use of stro in an example; natural language instances will be explored, below. This last point needs a word of explanation. It is of course possible to specify in mathematical terms without any explicit mention of a function; the approach we use in both and 41 in terms of the overarching function 2 mentioned above, and we could of course simply define 4) without defining * at all. Our point, rather, is that any successful definition of will effectively have to do the work of *, more or less explicitly, either by defining some identifiable relationship, or else by embedding that relationship within the meta-theoretic machinery. We are arguing, in other only that the intend to cover must be treated in some fashion or other. What is perhaps surprising about all of this machinery is that must be brought to bear on a purely procedural language — relationships sP) figure crucially in an account even are not suggesting that iS languages: point out just one crucial difference, there is no way in in other programming language (except CO whereas the ability to say things is clearly a foundational aspect of any human language. The problem in the procedural languages is of what we may call force;although it is possible to construct a sentence-like expression with a clear declarative semantics (such as some equivalent of &amp;quot;x 3&amp;quot;), one cannot use it in such a way as to actually mean it — so as to have it carry any assertional For example, it is trivial to set some variable x 3, to whether x is there is no way to state x is should be admitted, however, that computational languages bearing assertional force are under considerable current investigation. This interest is probably one of the reasons for popularity; other computational systems with an explicit declarative character include for example specification languages, data base models, constraint languages, and knowledge representation languages in A.I. We can only assume that the appropriate semantics for all of these formalisms will align even more closely with an illuminating semantics for natural language. What does all of this have to do with natural language, and computational linguistics? The essential point is this: characterisation of formal systems is tenable, and if the techniques of standard programming language semantics can be fit into this mould, then it may be possible to combine those approaches with the techniques of programming language semantics and of logic and model theories, to construct complex and interacting accounts of and of (D. To take just one example, the techniques that are used to construct mathematical accounts of environments and continuations might be brought to bear on the issue of dealing with the complex circumstances involving discourse models, theories of focus in dealing with anaphora, and so on; both cases involve an attempt to construct a recursively specifiable account of non-local interactions among disparate fragments of a composite text. But the contributions can proceed in the other direction as well: even from a very simple application of this framework to this circumstance of example, we have been able to show how an accepted computational notion fails to cohere with our attributed linguistically understanding, involving us in a major reconstruction of foundations. The similarities are striking. Our claim, in sum, is that similar phenomena occur in programming languages and natural languages, and that each discipline could benefit from the semantical techniques developed in the other. Some examples of these similar phenomena will help to motivate this view. The first is the issue ^ tt% appropriate use of noun phrases: as well as employing a noun phrase in a standard e position, natural language semantics has concerned itself more difficult cases such as contexts in the designator in didn&apos;t know Big Applewas an island. the co-designating term York be substituted changing the meaning), the so-called 12 of (the difference, roughly, between using a noun phrase like &amp;quot;the man with a martini&amp;quot; to inform you that someone is drinking a martini, as opposed to a situation where one uses the hearer&apos;s belief or assumption that someone is drinking a martini to refer to him), and so on. Another example different from of these is provided by the underlined term in the next 20 let&apos;s restrict president&apos;ssalary to $20,000, the reading in which after Reagan is defeated he is allowed to earn as much as he pleases, but his successor comes under our constraint. The analagous computational cases include for example the use of an expression (the formal analog of) the sixth array element be 10 : to). where we mean not that the current sixth element should be 10 (the current sixth array element might at the moment be 9, and 9 can&apos;t be 10), but rather that we would like the description &amp;quot;the sixth array element&amp;quot; to refer to 10 (so-called &amp;quot;Lanalogous to SETF Or, to take a case, suppose we say a&apos; to the sixth array element (i.e., am), where we mean not that x should be set to the current array element, but that it should equal to that (stated computationally this might be phrased as saying track linguistically we might say that x should sixth array element&amp;quot;). Although this is not a standard type of assignment, the new constraint languages provide exactly such facilities, and macros (classic computational intensional operators) can be used in more traditional languages for such purposes. Or, for a final example, consider the standard decimation: in which the term &amp;quot;x&amp;quot; refers neither to the variable are numbers), nor to its current designation, but rather to whatever will satisfy the description &amp;quot;the value of x&amp;quot; at any point in the course of a computation. All in all, we cannot ignore the attempt on the computationalists&apos; part to provide complex mechanisms so strikingly similar to the complex ways we use noun phrases in English. A very different sort of lingusitic phenomenon that occurs in both programming languages and in natural language are what we might call &amp;quot;premature exits&amp;quot;: cases where the processing of a local standard interpretation of an encompassing If for example I say to you was walking down the street that leads to the house that Mary&apos;s aunt used to ... forget it; I was a walk, the &amp;quot;forget it&amp;quot; must be used to discard the analysis of some amount of the previous sentence. The grammatical structure of the subsequent phrase determines how much has been discarded, of course; the sentence would still be comprehensible if the phrase &amp;quot;an old house I like&amp;quot; followed the &amp;quot;forget it&amp;quot;. We are not accustomed to semantical theories that deal with phenomena like this, of course, but it is clear that any serious attempt to model real language understanding will have to face them. Our present point is that enable computational formalisms to deal with the computational analogs of this: so-called THROW In addition, a full semantics of language will want to deal such sentences as by 7flustrated&amp;quot; you mean what I think, then was certainly flustrated. proper treatment of the first clause this sentence will presumably involve lots of &amp;quot;*&amp;quot; of considerations: its contribution to the remainder of the sentence has more to do with the mental states of speaker and hearer than with the world being describe by the presumed conversation. Once again, overarching computational hypothesis suggests that the way psychological effects must be modelled is in terms of alterations in the state of an internal process running over a field of computational structures. As well as these specific examples, a couple of more general morals can be drawn, important in that they speak directly to styles of practice that we see in the literature. The first concerns the suggestion, apparently of some currency, that we reject the notion of logical form, and &amp;quot;do semantics directly&amp;quot; in a computational model. On our account this is a mistake, pure and simple: to buy into the computational framework is to believe that the ingredients in any computational process are inherently linguistic, in need of interpretation. Thus they too will need semantics; the internalisation of English into a computer (0) is a translation relationship (in the sense of preserving 43, presumably) — even if it is wildly contextual, and even if the internal language is very different in structure from the structure of English. It has sometimes been informally suggested, in an analogous vein, that Montague semantics cannot be taken seriously computationally, because the models that Montague proposes are &amp;quot;too big&amp;quot; — how could you possibly carry these infinite functions around in your head, we are asked to wonder. But of course this argument comits a use/mention mistake: the only valid reading of Montague would mean that mentalse consist of the functions Montague proposes, and those designators can of course be a few short formulae, It is another consequence of our view that any semanticist who proposes some kind of &amp;quot;mental structure&amp;quot; in his or her account of language is commited to providing an interpretation of that structure. Consider for example a proposal that posits a notion of &amp;quot;focus&amp;quot; for a discourse fragment. Such a focus might be viewed as a (possibly abstract) entity in the world, or as a element of computational structure playing such-and-such role in the behavioural model of language understanding. It might seem that these are alternative accounts: what our view insists is that an the latter must give it a designation (0); thus there be a computational structure (being biased, we will call it a designation (that we call the complete account of focus have to specify both of these (either directly, or else by relying on the generic declarative semantics to mediate between them), and also tell a story about how focus-designator plays a causal role in engendering the proper behaviour in the computational model of language understanding. There is one final problem to be considered: what it is to an internal formalism task, we may presume, of anyone designing a knowledge representation language). Since, on our view, must have a semantics, we have the option either of having semantics informally described (or, even worse, tacitly assumed), or we can present an explicit account, either by defining a story ourselves or by borrowing from someone else. If the LISP case can be taken as suggestive, a purely declarative model theory will be inadequate to handle the sorts of comptuational interactions that languages have required (and there is no priori reason to assume that successful computational models for natural will be found that are the programming languages the community has found necessary for the modest sorts of tasks computers are presently able to perform). However it is also reasonable to expect that no direct analog to programming language semantics will suffice, since they have to date been so concerned with purely procedural (behavioural) consequence. It seems at least 13 reasonable to suppose that a general interpretation function, of the sort mentioned earlier, may be required. for example the presented by Although no semantics for been presented, either procedural or declarative, its proponents have worked both in investigating the e-simantics (how to translate into in developing an informal account of the procedural aspects. Curiously, recent directions in that project would suggest that its authors expect to be able to provide a &amp;quot;declarativeaccount of (i.e., expect to be able to present account of of spite of our foregoing Our only comment is to remark that procedural consequence is not a pre-requisite to an adequate semantics; the two can be recursively specifiable together; thus this apparent position is stronger than formally necessary which makes it perhaps of considerable interest. sum, we claim that any semantical account of language must specify and any are left out, the account is not complete. We deny, furthermore, that there is any fundamental distinction to be drawn between so-called languages (of which the paradigmatic example in A.I.) and other more declarative languages (encodings of logic, or representation languages). We deny as well, contrary to at least some popular belief, the view that a mathematically well-specified semantics for a candidate &amp;quot;mentalese&amp;quot; must be satisfied by giving an specified (as would be possible an encoding of logic, for example). The designers of for example, for principled reasons denied the possibility of giving a independent of the procedures in which the our simple account of at least suggested that such an approach could be pursued on a mathematically sound footing. Note however, in spite of our endorsement of what might called semantics, this in no way frees one from giving a declarative semantics as well; semantics semantics are pieces of a total story; they are not alternatives. 6. The term &amp;quot;semantics&amp;quot; is only one of a large collection of terms, unfortunately, that are technical terms in computer science and in the attendant cognitive disciplines (including logic, philosophy of language, linguistics, and psychology), with different and different connotations. interpretation, are a few examples of the others. It is our view that in spite of the fact that semantical vocabulary is in the fields are both semantical in the a unification of terminology would only be for the best.</abstract>
<note confidence="0.916971448275862">7. An example of the phenomenon noted in footnote 6. 8. Fodor (forthcoming) 9. Woods (1981) 10. For a discussion of continuations see Gordon (1979), Steele and Sussman (1978), and Smith (1982a); the formal device is developed in Strachey &amp; Wadsworth (1974). 11. Smith (1982a). 12. A classic example is Katz and Postal (1964), but much of the recent A.I. research in natural language in A.I. can be viewed in this light. 13. Lewis (1972). 14. Israel (1980). For a discussion of Clocksin &amp; Mellish (1981); the described in Smith (1982a). 16. Smith (forthcoming). 17. Fodor (forthcoming). 18. The term &amp;quot;methodological solipsism&amp;quot; is from Putnam (1975); see also Fodor (1980). 19. Donnellan (1966). 20. See note 10, above. 21. Brachman (1979). 22. Bobrow and Winograd (1977). REFERENCES NOTES I am grateful to Barbara Grosz and Hector Levesque for their comments on an earlier draft of this short paper, and to Jane Robinson for her original suggestion that it be written. 1. Smith (1982b) 2. Fodor (1978), Fodor (1980), Haugeland (forthcoming)</note>
<abstract confidence="0.985365181818182">At least until the day arrives - when a successful of language is presented wherein human semanticity is explained in non-semantical terms. 4. Problematic because it defines computation in a manner that is derivative on mind (in that language is fundamentally a mental phenomenon), thus dashing the hope that computational psyly will offer a release from the semantic irreducibility of previous accounts of human cognition. Though we state this and explore its consequences in Smith (1982b), a considerably fuller treatment will be provided in Smith (forthcoming).</abstract>
<note confidence="0.923217655172414">5. See for example Newell (1980) Bobrow, Daniel G., and Winograd, Terry, &amp;quot;An Overview of KRL: A Representation Language&amp;quot;, Science pp. 3- 46, 1977. Ronald, the Epistemological Status of Semantic in Findler, Nicholas V. (ed.), Networks: and Use of Knowledge by Computers, York: Academic Press, 1979. W. F., and Mellish, C. S., in Prolog, Springer-Verlag, 1981. K., &amp;quot;Reference and Definite Descriptions&amp;quot;, (1966) pp. 281-304; reprinted in Rosenberg and (eds.), in the Philosophy of Language, Prentice- Hall, 1971. Fodor, Jerry, &amp;quot;Tom Swill and his Procedural Grandmother&amp;quot;, 1978; reprinted in Fodor (1981). , &amp;quot;Methodological Solipsism Considered as a Research in Cognitive Psychology&amp;quot;, Behavioral and Brain (1980) pp. 63-73; reprinted in Haugeland (ed.), Design, Bradford, 1981, and in Fodor (1981). 14 Israel, David, &amp;quot;What&apos;s Wrong with Non-Monotonic Logic?&amp;quot;, Proceedings of the First Annual Conference of the American Association for Artificial Intelligence, Stanford, California, 1980, pp. 99-101. Jerrold, and Postal, Paul, Integrated Theory of Linguistic M.I.T. Press, 1964. Lewis, David, &amp;quot;General Semantics&amp;quot;, in Davidson and Harman (eds.), of Natural Langauges, Holland: D. Reidel, 1972, pp. 169-218. Allen, &amp;quot;Physical Symbol Systems&amp;quot;, Science pp. 135-183, 1980. Putnam, Hilary, &amp;quot;The meaning of &apos;meaning&apos;&amp;quot;, in Putnam, Hilary, Language and Reality, U.K.: Cambridge University Press, 1975. Brian C., and Semantics in. a Procedural Language, Laboratory for Computer Science Report LCS-TR-272, M.I.T., Cambridge, Mass., 1982 (a). — , &amp;quot;Semantic Attribution and the Formality Condition&amp;quot;, presented at the Eighth Annual Meeting of the Society for Philosophy and Psychology, London, Ontario, Canada, May 13- 16, 1982 (b). The Computational Metaphor, Bradford (forthcoming). Steele, Guy, and Sussman, Gerald J., &amp;quot;The Art of the Interpreter, or the Modularity Complex (parts Zero, One, and Two)&amp;quot;, M.I.T. Artificial Intelligence Laboratory Memo AIM-453, Cambridge, Mass, 1978. Strachey, C., and Wadsworth, C. P., &amp;quot;Continuations — a Mathematical Semantics for Handling Full Jumps&amp;quot;, PRG-11, Programming Research Group, University of Oxford, 1974. Woods, William A., &amp;quot;Procedural Semantics as a Theory of Meaning&amp;quot;, Report No. 4627, Bolt Beranek and Newman, 50 Moulton St, Cambridge, Mass., 02138; reprinted in Joshi, A., Sag, I., and B., Aspects of Linguistic Structures and Settings, U.K.: Cambridge University Press, 1982. 15</note>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>An example of the phenomenon noted in footnote 6.</title>
<marker>7.</marker>
<rawString>An example of the phenomenon noted in footnote 6.</rawString>
</citation>
<citation valid="false">
<note>Fodor (forthcoming)</note>
<marker>8.</marker>
<rawString>Fodor (forthcoming)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Woods</author>
</authors>
<date>1981</date>
<marker>9.</marker>
<rawString>Woods (1981)</rawString>
</citation>
<citation valid="true">
<title>For a discussion of continuations see Gordon</title>
<date>1979</date>
<publisher>Wadsworth</publisher>
<marker>10.</marker>
<rawString>For a discussion of continuations see Gordon (1979), Steele and Sussman (1978), and Smith (1982a); the formal device is developed in Strachey &amp; Wadsworth (1974).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Smith</author>
</authors>
<date>1982</date>
<marker>11.</marker>
<rawString>Smith (1982a).</rawString>
</citation>
<citation valid="true">
<title>A classic example is Katz and Postal</title>
<date>1964</date>
<note>research in natural language in A.I. can be viewed in this light.</note>
<marker>12.</marker>
<rawString>A classic example is Katz and Postal (1964), but much of the recent A.I. research in natural language in A.I. can be viewed in this light.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lewis</author>
</authors>
<date>1972</date>
<marker>13.</marker>
<rawString>Lewis (1972).</rawString>
</citation>
<citation valid="false">
<date>1980</date>
<marker>14.</marker>
<rawString>Israel (1980).</rawString>
</citation>
<citation valid="true">
<title>For a discussion of PROLOG see</title>
<date>1981</date>
<journal>Clocksin &amp; Mellish</journal>
<marker>15.</marker>
<rawString>For a discussion of PROLOG see Clocksin &amp; Mellish (1981); the LISPS are described in Smith (1982a).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Smith</author>
</authors>
<marker>16.</marker>
<rawString>Smith (forthcoming).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Fodor</author>
</authors>
<marker>17.</marker>
<rawString>Fodor (forthcoming).</rawString>
</citation>
<citation valid="true">
<title>The term &amp;quot;methodological solipsism&amp;quot; is from Putnam</title>
<date>1975</date>
<marker>18.</marker>
<rawString>The term &amp;quot;methodological solipsism&amp;quot; is from Putnam (1975); see also Fodor (1980).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Donnellan</author>
</authors>
<date>1966</date>
<marker>19.</marker>
<rawString>Donnellan (1966).</rawString>
</citation>
<citation valid="false">
<note>See note 10, above.</note>
<marker>20.</marker>
<rawString>See note 10, above.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brachman</author>
</authors>
<date>1979</date>
<marker>21.</marker>
<rawString>Brachman (1979).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bobrow</author>
<author>Winograd</author>
</authors>
<title>Robinson for her original suggestion that it be written.</title>
<date>1977</date>
<marker>22.</marker>
<rawString>Bobrow and Winograd (1977). Robinson for her original suggestion that it be written.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Smith</author>
</authors>
<date>1982</date>
<marker>1.</marker>
<rawString>Smith (1982b)</rawString>
</citation>
<citation valid="true">
<authors>
<author>Fodor</author>
</authors>
<date>1978</date>
<location>Fodor</location>
<note>Haugeland (forthcoming)</note>
<marker>2.</marker>
<rawString>Fodor (1978), Fodor (1980), Haugeland (forthcoming)</rawString>
</citation>
<citation valid="false">
<title>At least until the day arrives - if ever - when a successful psychology of language is presented wherein all of human semanticity is explained in non-semantical terms.</title>
<marker>3.</marker>
<rawString>At least until the day arrives - if ever - when a successful psychology of language is presented wherein all of human semanticity is explained in non-semantical terms.</rawString>
</citation>
<citation valid="false">
<title>Problematic because it defines computation in a manner that is derivative on mind (in that language is fundamentally a mental phenomenon), thus dashing the hope that computational psyly will offer a release from the semantic irreducibility of previous accounts of human cognition. Though we state this position and explore some of its consequences in Smith (1982b), a considerably fuller treatment will be provided in Smith (forthcoming).</title>
<marker>4.</marker>
<rawString>Problematic because it defines computation in a manner that is derivative on mind (in that language is fundamentally a mental phenomenon), thus dashing the hope that computational psyly will offer a release from the semantic irreducibility of previous accounts of human cognition. Though we state this position and explore some of its consequences in Smith (1982b), a considerably fuller treatment will be provided in Smith (forthcoming).</rawString>
</citation>
<citation valid="false">
<authors>
<author>Daniel G Bobrow</author>
<author>Terry Winograd</author>
</authors>
<title>See for example Newell</title>
<date>1980</date>
<journal>Cognitive Science</journal>
<booktitle>Mind Design,</booktitle>
<tech>PRG-11,</tech>
<volume>1</volume>
<pages>3--46</pages>
<editor>in Findler, Nicholas V. (ed.),</editor>
<publisher>Academic Press,</publisher>
<institution>Programming Research Group, University of Oxford,</institution>
<location>New York:</location>
<note>02138; reprinted in</note>
<marker>5.</marker>
<rawString>See for example Newell (1980) Bobrow, Daniel G., and Winograd, Terry, &amp;quot;An Overview of KRL: A Knowledge Representation Language&amp;quot;, Cognitive Science 1 pp. 3-46, 1977. Brachman, Ronald, &amp;quot;On. the Epistemological Status of Semantic Networks&amp;quot;, in Findler, Nicholas V. (ed.), Associative Networks: Representation and Use of Knowledge by Computers, New York: Academic Press, 1979. Clocksin, W. F., and Mellish, C. S., Programming in Prolog, Berlin: Springer-Verlag, 1981. Donnellan, K., &amp;quot;Reference and Definite Descriptions&amp;quot;, Philosophical Review 75:3 (1966) pp. 281-304; reprinted in Rosenberg and Travis (eds.), Readings in the Philosophy of Language, PrenticeHall, 1971. Fodor, Jerry, &amp;quot;Tom Swill and his Procedural Grandmother&amp;quot;, Cognition 6, 1978; reprinted in Fodor (1981). , &amp;quot;Methodological Solipsism Considered as a Research Strategy in Cognitive Psychology&amp;quot;, The Behavioral and Brain Sciences, 3:1 (1980) pp. 63-73; reprinted in Haugeland (ed.), Mind Design, Cambridge: Bradford, 1981, and in Fodor (1981). Israel, David, &amp;quot;What&apos;s Wrong with Non-Monotonic Logic?&amp;quot;, Proceedings of the First Annual Conference of the American Association for Artificial Intelligence, Stanford, California, 1980, pp. 99-101. Katz, Jerrold, and Postal, Paul, An Integrated Theory of Linguistic Descriptions, Cambridge: M.I.T. Press, 1964. Lewis, David, &amp;quot;General Semantics&amp;quot;, in Davidson and Harman (eds.), Semantics of Natural Langauges, Dordrecht, Holland: D. Reidel, 1972, pp. 169-218. Newell, Allen, &amp;quot;Physical Symbol Systems&amp;quot;, Cognitive Science 4, pp. 135-183, 1980. Putnam, Hilary, &amp;quot;The meaning of &apos;meaning&apos;&amp;quot;, in Putnam, Hilary, Mind Language and Reality, Cambridge, U.K.: Cambridge University Press, 1975. Smith, Brian C., Reflection and Semantics in. a Procedural Language, Laboratory for Computer Science Report LCS-TR-272, M.I.T., Cambridge, Mass., 1982 (a). — , &amp;quot;Semantic Attribution and the Formality Condition&amp;quot;, presented at the Eighth Annual Meeting of the Society for Philosophy and Psychology, London, Ontario, Canada, May 13-16, 1982 (b). , The Computational Metaphor, Cambridge: Bradford (forthcoming). Steele, Guy, and Sussman, Gerald J., &amp;quot;The Art of the Interpreter, or the Modularity Complex (parts Zero, One, and Two)&amp;quot;, M.I.T. Artificial Intelligence Laboratory Memo AIM-453, Cambridge, Mass, 1978. Strachey, C., and Wadsworth, C. P., &amp;quot;Continuations — a Mathematical Semantics for Handling Full Jumps&amp;quot;, PRG-11, Programming Research Group, University of Oxford, 1974. Woods, William A., &amp;quot;Procedural Semantics as a Theory of Meaning&amp;quot;, Report No. 4627, Bolt Beranek and Newman, 50 Moulton St, Cambridge, Mass., 02138; reprinted in Joshi, A., Sag, I., and Webber, B., Computational Aspects of Linguistic Structures and Discourse Settings, Cambridge, U.K.: Cambridge University Press, 1982.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>