<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.005846">
<title confidence="0.998152">
An Information-theoretic Approach for Argument Interpretation
</title>
<author confidence="0.987869">
Sarah George and Ingrid Zukerman
</author>
<affiliation confidence="0.994231">
School of Computer Science and Software Engineering
Monash University
</affiliation>
<address confidence="0.691757">
Clayton, VICTORIA 3800, AUSTRALIA
</address>
<email confidence="0.99973">
email: {sarahg,ingrid}@csse.monash.edu.au
</email>
<sectionHeader confidence="0.995653" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.998978846153846">
We describe an information-theoretic
argument-interpretation mechanism em-
bedded in an interactive system. Our
mechanism receives as input an argument
entered through a web interface. It gener-
ates candidate interpretations in terms of
its underlying knowledge representation –
a Bayesian network, and applies the Mini-
mum Message Length principle to select
the best candidate. The results of our
preliminary evaluations are encouraging,
with the system generally producing plau-
sible interpretations of users’ arguments.
</bodyText>
<keyword confidence="0.868299">
Keywords: Minimum message length, discourse in-
terpretation, Bayesian networks.
</keyword>
<sectionHeader confidence="0.999718" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.998569117647059">
Discourse interpretation is an essential component
of any dialogue system. However, most interactive
systems developed to date afford users limited op-
portunities to express their views. The discourse in-
terpretation mechanism described in this paper con-
stitutes a step towards solving this problem.
This research builds on our previous work on
BIAS – a Bayesian Interactive Argumentation Sys-
tem which uses Bayesian networks (BNs) (Pearl,
1988) as its knowledge representation and reason-
ing formalism. BIAS is designed to be a complete
argumentation system which will eventually engage
in unrestricted interactions with users. However, in
this paper, we focus on its discourse interpretation
mechanism and the impact of attentional focus on
the interpretation process.
The contributions of this paper are as follows.
</bodyText>
<listItem confidence="0.883484111111111">
1. We incorporate attentional focus into the
discourse-interpretation formalism described in
(Zukerman and George, 2002), which uses the
Minimum Message Length (MML) Principle
(Wallace and Boulton, 1968) to evaluate candi-
date discourse interpretations.
2. We investigate a web-based argumentation facil-
ity for the detective game described in (Zuker-
man, 2001).
</listItem>
<bodyText confidence="0.999881666666667">
In the following section, we describe our detec-
tive game, and discuss our knowledge representa-
tion. Next, we outline the argument interpretation
process. In Section 4, we provide an overview of our
Minimum Message Length approach to discourse
interpretation, and describe how attentional focus is
incorporated into this formalism. The results of our
evaluation are reported in Section 5. We then discuss
related research, followed by concluding remarks.
</bodyText>
<sectionHeader confidence="0.993803" genericHeader="method">
2 Detective Game
</sectionHeader>
<bodyText confidence="0.999943555555556">
As for the system described in (Zukerman, 2001),
our experimental set up takes the form of a game
where the user and the system are partners in solv-
ing a murder mystery, and neither the user nor the
system is omniscient. That is, they have access only
to information they can find out by investigating the
murder. However, our current set up differs from
that of our previous work in that the user is a ju-
nior detective, and the system is a desk-bound boss,
</bodyText>
<figure confidence="0.888278">
(a) Screen shot of Mr Body’s bedroom (b) Detective Gir’s notebook
</figure>
<figureCaption confidence="0.999843">
Figure 1: Sample screen of the WWW interface and Detective’s Notebook
</figureCaption>
<bodyText confidence="0.999964791666667">
who knows only what the user tells him. Thus,
the user does all the leg-work, navigating through
a virtual crime scene, making observations and in-
terviewing witnesses, and reports periodically to the
boss. These reports consist of successively evolv-
ing arguments for the main suspect’s guilt or inno-
cence. Further, the user has limited resources, i.e.,
time and money, which are depleted as the investi-
gation progresses. To win the game, the user must
build a cogent argument regarding the guilt or inno-
cence of the main suspect prior to exhausting his/her
resources.
In order to evaluate the discourse interpretation
capabilities of the system, in this paper we restrict
the users’ interaction with the system to a single
round. That is, a user reads the initial police report,
optionally explores the virtual scenario, and then
presents an argument to his/her boss. The system
interprets the argument, and presents its interpreta-
tion back to the user for validation. The results of
this validation are discussed in our evaluation (Sec-
tion 5). In the future, the boss will present counter-
arguments, point out flaws in the user’s argument or
make suggestions regarding further investigations.
</bodyText>
<subsectionHeader confidence="0.997485">
2.1 Playing the game – initial interaction
</subsectionHeader>
<bodyText confidence="0.975719333333333">
The game starts with the presentation of a police re-
port that describes the preliminaries of the case for
a particular scenario. The following police report is
presented for the scenario used in this paper.
Yesterday, Mr Body was found dead in his
bedroom. Fatal bullet wounds were found in
Mr Body’s chest.
Broken glass was found inside the bedroom
window. A gun was found in the garden out-
side the house, andfingerprints were found on
the gun.
Fresh footprints were found near the house,
and some peculiar indentations were ob-
served in the ground. Also, blue car paint was
scraped on the letter box.
After reading the police report, the user may nav-
igate through a virtual space to gather additional in-
formation (Figure 1(a) shows a screen shot of the
victim’s bedroom). The user may record informa-
tion s/he considers interesting in his/her Notebook
(Figure 1(b)), which is consulted by the user dur-
ing the argument construction process. Upon com-
pletion of his/her investigation, the user builds an
argument composed of a sequence of implications
leading from evidence to the argument goal. Each
implication is composed of one or more antecedents
and consequents. In the current implementation, the
antecedents and consequents are obtained by copy-
ing propositions from a drop-down menu into slots
in the argument-construction interface.&apos; Figure 2
shows a screen-shot of the argument-construction
interface, and an argument built by a particular user
&apos;An alternative version of our system accepts free-form Nat-
ural Language (NL) input for antecedents and consequents.
However, in our current version this capability has been re-
placed with a web-based interface.
</bodyText>
<figureCaption confidence="0.99796">
Figure 2: Argument-construction screen and user’s argument
</figureCaption>
<bodyText confidence="0.999962166666667">
after she has read the police report, seen the news-
paper and spoken to the forensic experts. Figure 3
shows the interpretation generated by BIAS for the
argument in Figure 2. In it the system fills in propo-
sitions and relations where the user has made infer-
ential leaps, and points out its beliefs and the user’s.
</bodyText>
<subsectionHeader confidence="0.998658">
2.2 Domain representation
</subsectionHeader>
<bodyText confidence="0.993523684210526">
The domain propositions and the relationships be-
tween them are represented by means of a Bayesian
network (BN) (Pearl, 1988). Each BN in the sys-
tem can support a variety of scenarios, depending
on the instantiation of the evidence nodes. The
murder mystery used for this paper is represented
by means of an 85-node BN (similar to that used
in (Zukerman, 2001)). Figure 4 shows a portion
of this BN: the evidence nodes are boxed, and the
goal node – GmurderedB – is circled. The five evi-
dence nodes mentioned in the police report are bold-
faced and shaded, the two evidence nodes obtained
by the user in her investigation are boldfaced and
dark shaded ([BayesianTimes Reports B Took G’s Girl-
friend] and [Forensics Match G’s Fingerprints]), and the
evidence nodes employed by the user in her argu-
ment have white text. The nodes corresponding to
the consequents in the user’s argument are boldfaced
([G Has Means], [G Has Motive] and [G Murdered B]).
</bodyText>
<sectionHeader confidence="0.979772" genericHeader="method">
3 Proposing Interpretations
</sectionHeader>
<bodyText confidence="0.999685115384615">
BIAS generates interpretations of the user’s argu-
ment in terms of its own beliefs and inferences,
which may differ from those in the user’s argu-
ment. This may require adding propositions and
relations to the argument structure proposed by the
user, deleting relations from the user’s argument, or
postulating degrees of belief in the propositions in
the user’s argument which differ from those stated
by the user.
Our system generates candidate interpretations
for an argument by finding different ways of con-
necting the propositions in the argument – each vari-
ant being a candidate interpretation. This is done by
(1) connecting the nodes in the argument, (2) remov-
ing superfluous nodes, and (3) building connected
sub-graphs of the resultant graph.
Connecting nodes. This is done by retrieving from
the domain BN neighbouring nodes to the nodes
mentioned in the user’s argument (each proposition
accessible through the argumentation interface cor-
responds to a node in the domain BN). BIAS then
retrieves the neighbours’ neighbours, and so on for
a few iterations. These retrieved neighbours are in-
ferred nodes. This process of retrieving neighbours
enables us to model “inferential leaps”, i.e., connec-
tions made by a user between two nodes that are not
</bodyText>
<figureCaption confidence="0.991364">
Figure 3: BIAS’ interpretation of the user’s argument
</figureCaption>
<figure confidence="0.999569742424243">
G’sCarWasHere
Last Week
B Seduced
Forensic
ForensicMatch
G’s Girlfriend
Reliable
BulletsWith
FoundGun
Bullets
BKilled
ByGun
G Visited B
GAndBEnemies
Last Week
BWasMurdered
GHasMotive
GandBargued
Last Week
MurderWeapon
Gun Found
In Garden
GHasMeans
FiredByG
GMurderedB
Fingerprints
NbourHeard
BIsDead
argument
Last Week
Found on Gun
FoundGun
AvToGOnly
Forensic Match
BKilled From
GInGardenAt
G’s Fingerprints
Outside Window
TimeOfDeath
GAtWindow
TimeOfDeath11
WindowBroken
From Outside
LadderAt
Window
Forensic Say
DeathTime11
OnePerson
G’s ladder
InGarden AtWindow
Forensic
Reliable
Fingerprints
Fingerprints FoundGun GHasOpportunity
On Found Gun FiredByG
BelongToG
FoundGunIs
MurderWeapon
FoundGun
RegisteredToG
Bullets Wounds
Found InB’sBody
B’sBodyFound
In Bedroom
Bayesian Times Reports
B Took G’s Girlfriend
</figure>
<figureCaption confidence="0.999991">
Figure 4: Interpretation of the user’s argument and partial BN
</figureCaption>
<bodyText confidence="0.999970222222222">
adjacent in the domain BN. As a result of this pro-
cess, mentioned nodes that are separated by a few
inferred nodes in the domain BN will now be con-
nected, but mentioned nodes that are far apart will
remain unconnected. If upon completion of this pro-
cess, a proposition in the user’s argument is still un-
connected, the system will have failed to find an in-
terpretation (in the future, the user will be asked to
fill this gap).
Removing superfluous nodes. This is done by
marginalizing out nodes that are not on a path be-
tween an evidence node and the goal node.
Building sub-graphs. BIAS derives all the interpre-
tations of an argument by computing combinations
of paths which produce connected graphs that incor-
porate the nodes mentioned by the user.
The Bayesian subnets generated in this manner
are candidate interpretations of a user’s argument in
terms of BIAS’ domain knowledge. However, these
subnets alone do not always yield the beliefs stated
by the user, as the user may have taken into account
implicit assumptions that influence his/her beliefs.
For instance, the argument in Figure 2 posits a belief
of A Little Likely in Mr Green’s guilt, while Bayesian
propagation from the available evidence yields a be-
lief of A Little Unlikely. This discrepancy may be at-
tributed to the user’s lack of consideration of Mr
Green’s opportunity to murder Mr Body (her argu-
ment includes only means and motive), an erroneous
assessment of Mr Green’s opportunity, or an assess-
ment of the impact of opportunity on guilt which dif-
fers from BIAS’. In the future, our mechanism will
consider the first two factors for neighbouring nodes
of an interpretation (the third factor involves learn-
ing a user’s Conditional Probability Tables – a task
that is outside the scope of this project).
</bodyText>
<sectionHeader confidence="0.947239" genericHeader="method">
4 Selecting an Interpretation
</sectionHeader>
<bodyText confidence="0.99997525">
In this section we present the Minimum Message
Length criterion, describe its use for argument in-
terpretation, and show how attentional focus is in-
corporated into our MML model.
</bodyText>
<subsectionHeader confidence="0.940367">
4.1 NNL Encoding
</subsectionHeader>
<bodyText confidence="0.999884928571429">
MML (Wallace and Boulton, 1968) is a model se-
lection criterion (used to select between candidate
models that explain observed data). The MML cri-
terion implements Occam’s Razor, which may be
stated as follows: “If you have two theories which
both explain the observed facts, then you should
use the simplest until more evidence comes along”
(the same idea is embodied in Einstein’s aphorism
“Make everything as simple as possible, but not sim-
pler”). This criterion balances data fit with model
complexity. That is, the best model should fit the
data well and it should be simple. In probabilistic
terms, given data D, the MML criterion selects the
model M with the highest posterior probability.
</bodyText>
<equation confidence="0.998999">
Pr(D&amp;M)
argmaxMPr(M|D) =
Pr(D)
Pr(M) x Pr(D|M)
=
Pr(D)
</equation>
<bodyText confidence="0.999964375">
(the constant denominator can be ignored when se-
lecting the highest-probability model.)
An optimal encoding for an event E with
probability Pr(E) has message length ML(E) =
−log2 Pr(E) (in bits). Hence, in information the-
oretic terms, the MML criterion selects the model
M which yields the shortest message that transmits
the model and the data.
</bodyText>
<equation confidence="0.995418">
argminMML(D&amp;M) = ML(M) + ML(D|M)
</equation>
<bodyText confidence="0.999912166666667">
The message for the data and the model is composed
of two parts: the first part transmits the model, and
the second part transmits instructions for recover-
ing the data from the model. The model for which
ML(D&amp;M) is minimal is the model with the high-
est posterior probability.
</bodyText>
<subsectionHeader confidence="0.978959">
4.2 Evaluating Interpretations
</subsectionHeader>
<bodyText confidence="0.999934444444445">
The problem of selecting an interpretation for a
user’s argument among candidate interpretations
may be viewed as a model selection problem, where
the argument is the data, and the interpretation is
the model. Let Arg be a graphical representation
of an argument (with antecedents pointing to con-
sequents), and SysInt an interpretation generated by
our system. Thus, we are looking for the SysInt
which yields the shortest message length for
</bodyText>
<equation confidence="0.99697">
ML(Arg&amp;SysInt) = ML(SysInt) + ML(Arg|SysInt)
</equation>
<bodyText confidence="0.994238333333333">
The first part of the message describes the inter-
pretation, and the second part describes how to re-
construct the argument from the interpretation. The
</bodyText>
<figure confidence="0.686526">
SysIntA SysIntB
</figure>
<figureCaption confidence="0.999329">
Figure 5: Interpretation of a simple argument
</figureCaption>
<figure confidence="0.995702846153846">
Mr Green had the opportunity
to kill Mr Body
Mr Green’s ladder was outside the window
Mr Green was in the garden at the time of death
G’s Ladder At Window
G AtWindow
G had Opportunity to Murder B
G InGardenAtTimeOfDeath
B Killed From Outside Window
G’s Ladder At Window
Ladder Outside Window
G had Opportunity to Murder B
G InGardenAtTimeOfDeath
</figure>
<bodyText confidence="0.996192454545454">
expectation from using the MML criterion is that in
finding an interpretation that yields the shortest mes-
sage for an NL argument (i.e., the interpretation with
the highest posterior probability), we will have pro-
duced a plausible interpretation, which hopefully is
the intended interpretation. This interpretation is de-
termined by comparing the message length of the
candidate interpretations, which are obtained as de-
scribed in Section 3.
Since domain propositions (rather than NL sen-
tences) are used to construct an argument, Arg can
be directly obtained from the input.2 SysInt is then
derived from Arg by using the links and nodes in
the domain BN to connect the propositions in the ar-
gument (Section 3). When the underlying represen-
tation has several ways of connecting between the
nodes in Arg, then more than one candidate SysInt is
generated (each candidate has at least one inferred
node that does not appear in the other candidates).
This is the case for the simple argument in Figure 5,
which is composed of two antecedents and one con-
sequent. This argument has two interpretations (the
portion of the domain BN from which the interpre-
tations are extracted appears at the bottom of Fig-
ure 4). The inferred nodes for the two interpretations
in Figure 5 are [G At Window] for SysIntA, and [Lad-
der Outside Window] and [B Killed From Outside Window]
for SysIntB; the inferred links are drawn with dashed
lines (the nodes in Arg are shaded, and the links are
curved).
After candidate interpretations have been postu-
lated, the MML criterion is applied to select the best
interpretation, i.e., the interpretation with the short-
</bodyText>
<footnote confidence="0.987496666666667">
2This is not the case in the version of the system which takes
NL input, since there may be more than one proposition that is
a reasonable interpretation for a sentence in an argument.
</footnote>
<bodyText confidence="0.997925833333333">
est message. The calculation of the message length
takes into account the following factors: (1) the size
of an interpretation, and (2) the structural and belief
similarity between the interpretation and the argu-
ment. These factors influence the components of the
message length as follows.
</bodyText>
<listItem confidence="0.985468">
• ML(SysInt) represents the probability of SysInt.
According to the MML principle, concise in-
terpretations (in terms of number of nodes and
links) are more probable than more verbose in-
terpretations.
• ML(Arg|SysInt) represents the probability that a
user uttered Arg when s/he intended SysInt. This
probability depends on the structural similarity
between SysInt and Arg (in terms of the nodes
</listItem>
<bodyText confidence="0.962544263157895">
and links that appear in Arg and SysInt), and on
the similarity between the beliefs in the nodes in
Arg and the corresponding nodes in SysInt (the
beliefs in the nodes in SysInt are obtained by per-
forming Bayesian propagation through SysInt;
thus, different SysInts may yield different beliefs
in the consequents of an argument). According
to this component, interpretations that are more
similar to Arg are more probable (i.e., yield a
shorter message) than interpretations that are less
similar to Arg.
Table 1 summarizes the effect of these factors on
the message length for SysIntA and SysIntB (Fig-
ure 5). SysIntA is simpler than SysIntB, thus yield-
ing a shorter message length for the first component
of the message. SysIntA is structurally more simi-
lar to Arg than SysIntB, yielding a shorter message
length for this aspect of Arg|SysIntA (SysIntA dif-
fers from Arg by 1 node and 3 links, while SysIntB
</bodyText>
<tableCaption confidence="0.99929">
Table 1: Message length comparison of two interpretations
</tableCaption>
<table confidence="0.99634225">
ML of Factor SysIntA SysIntB Shortest ML
SysInt Size 4 nodes, 3 links 5 nodes, 4 links SysIntA
Arg|SysInt Structural similarity 1 node, 3 links difference 2 nodes, 4 links difference SysIntA
Belief similarity less similar more similar SysIntB
</table>
<bodyText confidence="0.9972644375">
differs from Arg by 2 nodes and 4 links3). In this
example, we assume that the belief in [G had Op-
portunity to Murder B] in SysIntB is stronger than that
in SysIntA, and hence closer to the asserted conse-
quent of the argument in Figure 5. This yields a
shorter message length for the belief component of
ML(Arg|SysIntB). However, this is not sufficient
to overcome the shorter message length of SysIntA
due to structural similarity and conciseness. Thus,
although both interpretations of the argument are
reasonable, SysIntA is the preferred interpretation.
As seen in this example, the MML criterion
weighs possibly conflicting considerations during
discourse interpretation, e.g., a verbose interpreta-
tion that is similar to a user’s argument is preferred
to a more concise interpretation that is dissimilar.
</bodyText>
<subsectionHeader confidence="0.999895">
4.3 Modeling Attentional Focus
</subsectionHeader>
<bodyText confidence="0.999833">
The above-presented interpretation process assumes
that all inferred propositions are equally likely to be
included in a user’s argument. However, this is not
necessarily the case. We posit that a user is more
likely to imply (inside an inferential leap) proposi-
tions previously seen by him/her than propositions
s/he has never encountered. In this case, the length
of the part of the message which conveys SysInt
should not only depend on the size of the interpre-
tation (in terms of number of nodes and links), but
also on the probability that the user will employ in
his/her argument the nodes in that interpretation.
We have modeled the probability that a user will
include a proposition in his/her argument as a func-
tion of the proposition’s presence in the user’s focus
of attention. Attentional focus in turn was modeled
by means of an activation level which depends on
</bodyText>
<footnote confidence="0.998527">
3There are 2 links in SysIntA that are not in Arg, and 1 link
in Arg that is not in SysIntA (total 3 links difference). A similar
calculation is performed for SysIntB.
</footnote>
<bodyText confidence="0.7036202">
the following factors:4
• the type of access of a proposition, e.g., whether
the proposition was copied from the menu or
seen when exploring the scenario; and
• the passage of time, i.e., the longer the time
elapsed since the last access to the proposition,
the lower its level of activation.
These factors were combined as follows to ex-
press the probability that a proposition will be in-
cluded in an argument:
</bodyText>
<equation confidence="0.95838075">
n
Pr(Prop) a AccessTypez(Prop) x
z=1
[CurTime − TimeStmpz + 1]−b
</equation>
<bodyText confidence="0.995874473684211">
where n is the number of times the proposition was
accessed, AccessType is a score that reflects the man-
ner in which the proposition was accessed, b = 1 is
an empirically determined exponent, CurTime is the
current time, and TimeStmpz is the time of the ith
access. According to this formula, when a propo-
sition is accessed, activation is added to the current
accumulated (and decayed) activation. That is, there
is a spike in the level of activation of the proposition,
which starts decaying from that point again.
To illustrate the effect of attentional focus on the
argument interpretation process, let us reconsider
the sample argument in Figure 5, and let us assume
that [G At Window] was never seen by the user, while
[Ladder Outside Window] and [B Killed From Outside
Window] were seen recently. In this case, a high prob-
ability for these two propositions may overcome the
factors in favour of SysIntA, thereby making SysIntB
the preferred interpretation.
</bodyText>
<footnote confidence="0.7564685">
4Other factors, such as intrinsic salience of a proposition,
have not been modeled at present.
</footnote>
<sectionHeader confidence="0.98504" genericHeader="method">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999952135135135">
The system was evaluated in two modes: (1) auto-
matic and (2) user based.
Our automatic evaluation, described in (Zuker-
man and George, 2002), consisted of having the sys-
tem interpret noisy versions of its own arguments.
These arguments were generated from different sub-
nets of its domain BN, and they were distorted by
changing the beliefs in the nodes, and inserting and
deleting nodes and arcs. All these distortions were
performed on BNs of different sizes (3, 5, 7 and 9
arcs). Our measure of performance was the edit-
distance between the original BN used to generate
an argument, and the BN produced as the inter-
pretation of this argument. BIAS produced an in-
terpretation in 86% of the 5400 trials. In 75% of
the 5400 cases, the generated interpretations had an
edit-distance of 3 or less from the original BN (e.g.,
the interpretation differed from the original argu-
ment by one node and two links), and in 50% of
the cases, the interpretations matched perfectly the
original BN.
A preliminary user-based evaluation was per-
formed with 10 computer-literate staff and students
from our University. Our evaluation was conducted
as follows. We introduced the users to our system,
and explained its aims. We then encouraged them
to explore the scenario, and when they were ready,
they built an argument using the interface shown in
Figure 2. BIAS then generated an interpretation of
the argument, presenting it as shown in Figure 3.
The users were asked to assess BIAS’ interpreta-
tion under two conditions: before and after seeing
a diagram of the domain BN. In the initial assess-
ment, the users were asked to give BIAS’ interpre-
tation a score between 1 (Very UNreasonable) and 5
(Very Reasonable), and to optionally provide further
comments. In the second assessment, the users were
given the complete diagram for the partial BN shown
in Figure 4, and were asked to re-assess BIAS’ in-
terpretation in light of this domain knowledge. They
were also asked to trace their preferred interpretation
on the diagram (on paper).
Our users found the system somewhat daunting,
and indicated that the interface for entering an ar-
gument was inconvenient. We believe that this was
partly due to their lack of familiarity with the avail-
able domain propositions. That is, the users were
faced with 85 new propositions, which they had to
read in order to determine which one(s) they could
use to express what they had in mind. Nonetheless,
the users managed to construct arguments, which
ranged in size from 2 propositions to 26, and gave a
generally favourable assessment of BIAS’ interpre-
tations. Overall the average score of BIAS’ inter-
pretations was 4 before seeing the BN diagram and
4.25 after seeing the diagram. This indicates that un-
derstanding the constraints imposed by a system’s
domain knowledge may influence users’ ability to
interact with the system.
The main lessons learned from this preliminary
evaluation pertain to two aspects: (1) the interface,
and (2) the use of BNs for discourse understanding.
In order to improve the usability of the interface, we
will integrate it with BIAS’ NL module. It is envis-
aged that a solution combining menus and NL input
will yield the best results. Our evaluation also cor-
roborates the insights from Section 3 regarding the
difficulties of taking into account users’ assumptions
during the argument interpretation process. How-
ever, the results of our evaluation are encouraging
with respect to the use of the MML principle for the
selection of interpretations. In the future, we pro-
pose to conduct a more rigorous evaluation with ad-
ditional users to confirm these results.
</bodyText>
<sectionHeader confidence="0.999733" genericHeader="method">
6 Related Research
</sectionHeader>
<bodyText confidence="0.999972181818182">
Our research builds on work described in (Zuker-
man, 2001; Zukerman and George, 2002), which in-
tegrates plan recognition for discourse understand-
ing with BNs. Zukerman (2001) used a domain
model and user model represented as a BN, together
with linguistic and attentional information, to infer
a user’s goal from a single-proposition rejoinder to
a system-generated argument. However, the com-
bination of these knowledge sources was based on
heuristics. Zukerman and George (2002) developed
the initial probabilistic model for applying the MML
principle to argument interpretation. Here we extend
this model to include attentional focus, integrate it
into an interactive interpretation system, and evalu-
ate it with users.
The MML principle (Wallace and Boulton,
1968) is a model-selection technique which
applies information-theoretic criteria to trade
data fit against model complexity. MML has
been used in a variety of applications, sev-
eral of which are listed in http://www.csse.
monash.edu.au/dld/Snob.application.papers.
In this paper, we demonstrate the applicability of
MML to a high-level NL task.
BNs have been used in several systems that per-
form plan recognition, e.g., (Charniak and Gold-
man, 1993; Gertner et al., 1998; Horvitz and Paek,
1999). Charniak and Goldman’s system (Charniak
and Goldman, 1993) handled complex narratives,
using a BN and marker passing for plan recognition.
It automatically built and incrementally extended a
BN from propositions read in a story, so that the
BN represented hypotheses that became plausible
as the story unfolded. Marker passing was used to
restrict the nodes included in the BN. In contrast,
we use domain knowledge to constrain our under-
standing of the propositions in a user’s argument,
and apply the MML principle to select a plausible
interpretation. Gertner et al. (1998) used a BN to
represent the solution of a physics problem. After
observing an action performed by a student, their
system (Andes) postulated candidate interpretations
(like BIAS’ SysInt), each hypothesizing subsequent
actions. Unlike Andes, BIAS is presented with a
complete argument. Hence, it must also consider the
fit between all the argument propositions and the in-
terpretation (Arg|SysInt). Finally, the system devel-
oped by Horvitz and Paek (1999) handled short di-
alogue contributions, and used BNs at different lev-
els of an abstraction hierarchy to infer a user’s goal
in information-seeking interactions with a Bayesian
Receptionist. In addition, they employed decision-
theoretic strategies to guide the progress of the di-
alogue. We expect to use such strategies when our
system engages in a full dialogue with users.
</bodyText>
<sectionHeader confidence="0.99926" genericHeader="conclusions">
7 Conclusion
</sectionHeader>
<bodyText confidence="0.999981769230769">
We have offered a mechanism based on the MML
principle that generates interpretations of extended
arguments in the context of a BN. The MML prin-
ciple provides a theoretically sound framework for
weighing possibly conflicting considerations during
discourse interpretation. This framework enables
us to represent structural discrepancies between the
underlying, detailed domain representation and the
more sparse arguments produced by people (which
typically contain inferential leaps). The results of
our formative evaluation are encouraging, support-
ing the application of the MML principle for argu-
ment interpretation.
</bodyText>
<sectionHeader confidence="0.997056" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.82504675">
This research was supported in part by Australian
Research Council grant A49927212. The authors
thanks Charles Twardy on insightful comments re-
garding MML.
</bodyText>
<sectionHeader confidence="0.985258" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999760793103448">
Eugene Charniak and Robert P. Goldman. 1993. A
Bayesian model of plan recognition. Artificial Intel-
ligence, 64(1):50–56.
Abigail Gertner, Cristina Conati, and Kurt VanLehn.
1998. Procedural help in Andes: Generating hints us-
ing a Bayesian network student model. In AAAI98 –
Proceedings of the Fifteenth National Conference on
Artificial Intelligence, pages 106–111, Madison, Wis-
consin.
Eric Horvitz and Tim Paek. 1999. A computational ar-
chitecture for conversation. In UM99 – Proceedings of
the Seventh International Conference on User Model-
ing, pages 201–210, Banff, Canada.
Judea Pearl. 1988. Probabilistic Reasoning in Intelligent
Systems. Morgan Kaufmann Publishers, San Mateo,
California.
C.S. Wallace and D.M. Boulton. 1968. An informa-
tion measure for classification. The Computer Jour-
nal, 11:185–194.
Ingrid Zukerman and Sarah George. 2002. A Minimum
Message Length approach for argument interpretation.
In Proceedings of the Third SIGdial Workshop on Dis-
course and Dialogue, pages 211–220, Philadelphia,
Pennsylvania.
Ingrid Zukerman. 2001. An integrated approach for gen-
erating arguments and rebuttals and understanding re-
joinders. In UM01 – Proceedings of the Eighth Inter-
national Conference on User Modeling, pages 84–94,
Sonthofen, Germany.
</reference>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.548951">
<title confidence="0.999649">An Information-theoretic Approach for Argument Interpretation</title>
<author confidence="0.992962">George</author>
<affiliation confidence="0.857596">School of Computer Science and Software Monash</affiliation>
<address confidence="0.992216">Clayton, VICTORIA 3800,</address>
<abstract confidence="0.984735">We describe an information-theoretic argument-interpretation mechanism embedded in an interactive system. Our mechanism receives as input an argument entered through a web interface. It generates candidate interpretations in terms of its underlying knowledge representation – a Bayesian network, and applies the Minimum Message Length principle to select the best candidate. The results of our preliminary evaluations are encouraging, with the system generally producing plausible interpretations of users’ arguments. message length, discourse interpretation, Bayesian networks.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Eugene Charniak</author>
<author>Robert P Goldman</author>
</authors>
<title>A Bayesian model of plan recognition.</title>
<date>1993</date>
<journal>Artificial Intelligence,</journal>
<volume>64</volume>
<issue>1</issue>
<contexts>
<context position="26028" citStr="Charniak and Goldman, 1993" startWordPosition="4193" endWordPosition="4197">re we extend this model to include attentional focus, integrate it into an interactive interpretation system, and evaluate it with users. The MML principle (Wallace and Boulton, 1968) is a model-selection technique which applies information-theoretic criteria to trade data fit against model complexity. MML has been used in a variety of applications, several of which are listed in http://www.csse. monash.edu.au/dld/Snob.application.papers. In this paper, we demonstrate the applicability of MML to a high-level NL task. BNs have been used in several systems that perform plan recognition, e.g., (Charniak and Goldman, 1993; Gertner et al., 1998; Horvitz and Paek, 1999). Charniak and Goldman’s system (Charniak and Goldman, 1993) handled complex narratives, using a BN and marker passing for plan recognition. It automatically built and incrementally extended a BN from propositions read in a story, so that the BN represented hypotheses that became plausible as the story unfolded. Marker passing was used to restrict the nodes included in the BN. In contrast, we use domain knowledge to constrain our understanding of the propositions in a user’s argument, and apply the MML principle to select a plausible interpretatio</context>
</contexts>
<marker>Charniak, Goldman, 1993</marker>
<rawString>Eugene Charniak and Robert P. Goldman. 1993. A Bayesian model of plan recognition. Artificial Intelligence, 64(1):50–56.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Abigail Gertner</author>
<author>Cristina Conati</author>
<author>Kurt VanLehn</author>
</authors>
<title>Procedural help in Andes: Generating hints using a Bayesian network student model.</title>
<date>1998</date>
<booktitle>In AAAI98 – Proceedings of the Fifteenth National Conference on Artificial Intelligence,</booktitle>
<pages>106--111</pages>
<location>Madison, Wisconsin.</location>
<contexts>
<context position="26050" citStr="Gertner et al., 1998" startWordPosition="4198" endWordPosition="4201">nclude attentional focus, integrate it into an interactive interpretation system, and evaluate it with users. The MML principle (Wallace and Boulton, 1968) is a model-selection technique which applies information-theoretic criteria to trade data fit against model complexity. MML has been used in a variety of applications, several of which are listed in http://www.csse. monash.edu.au/dld/Snob.application.papers. In this paper, we demonstrate the applicability of MML to a high-level NL task. BNs have been used in several systems that perform plan recognition, e.g., (Charniak and Goldman, 1993; Gertner et al., 1998; Horvitz and Paek, 1999). Charniak and Goldman’s system (Charniak and Goldman, 1993) handled complex narratives, using a BN and marker passing for plan recognition. It automatically built and incrementally extended a BN from propositions read in a story, so that the BN represented hypotheses that became plausible as the story unfolded. Marker passing was used to restrict the nodes included in the BN. In contrast, we use domain knowledge to constrain our understanding of the propositions in a user’s argument, and apply the MML principle to select a plausible interpretation. Gertner et al. (199</context>
</contexts>
<marker>Gertner, Conati, VanLehn, 1998</marker>
<rawString>Abigail Gertner, Cristina Conati, and Kurt VanLehn. 1998. Procedural help in Andes: Generating hints using a Bayesian network student model. In AAAI98 – Proceedings of the Fifteenth National Conference on Artificial Intelligence, pages 106–111, Madison, Wisconsin.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric Horvitz</author>
<author>Tim Paek</author>
</authors>
<title>A computational architecture for conversation.</title>
<date>1999</date>
<booktitle>In UM99 – Proceedings of the Seventh International Conference on User Modeling,</booktitle>
<pages>201--210</pages>
<location>Banff, Canada.</location>
<contexts>
<context position="26075" citStr="Horvitz and Paek, 1999" startWordPosition="4202" endWordPosition="4205">us, integrate it into an interactive interpretation system, and evaluate it with users. The MML principle (Wallace and Boulton, 1968) is a model-selection technique which applies information-theoretic criteria to trade data fit against model complexity. MML has been used in a variety of applications, several of which are listed in http://www.csse. monash.edu.au/dld/Snob.application.papers. In this paper, we demonstrate the applicability of MML to a high-level NL task. BNs have been used in several systems that perform plan recognition, e.g., (Charniak and Goldman, 1993; Gertner et al., 1998; Horvitz and Paek, 1999). Charniak and Goldman’s system (Charniak and Goldman, 1993) handled complex narratives, using a BN and marker passing for plan recognition. It automatically built and incrementally extended a BN from propositions read in a story, so that the BN represented hypotheses that became plausible as the story unfolded. Marker passing was used to restrict the nodes included in the BN. In contrast, we use domain knowledge to constrain our understanding of the propositions in a user’s argument, and apply the MML principle to select a plausible interpretation. Gertner et al. (1998) used a BN to represent</context>
</contexts>
<marker>Horvitz, Paek, 1999</marker>
<rawString>Eric Horvitz and Tim Paek. 1999. A computational architecture for conversation. In UM99 – Proceedings of the Seventh International Conference on User Modeling, pages 201–210, Banff, Canada.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Judea Pearl</author>
</authors>
<title>Probabilistic Reasoning in Intelligent Systems.</title>
<date>1988</date>
<publisher>Morgan Kaufmann Publishers,</publisher>
<location>San Mateo, California.</location>
<contexts>
<context position="1304" citStr="Pearl, 1988" startWordPosition="174" endWordPosition="175">e system generally producing plausible interpretations of users’ arguments. Keywords: Minimum message length, discourse interpretation, Bayesian networks. 1 Introduction Discourse interpretation is an essential component of any dialogue system. However, most interactive systems developed to date afford users limited opportunities to express their views. The discourse interpretation mechanism described in this paper constitutes a step towards solving this problem. This research builds on our previous work on BIAS – a Bayesian Interactive Argumentation System which uses Bayesian networks (BNs) (Pearl, 1988) as its knowledge representation and reasoning formalism. BIAS is designed to be a complete argumentation system which will eventually engage in unrestricted interactions with users. However, in this paper, we focus on its discourse interpretation mechanism and the impact of attentional focus on the interpretation process. The contributions of this paper are as follows. 1. We incorporate attentional focus into the discourse-interpretation formalism described in (Zukerman and George, 2002), which uses the Minimum Message Length (MML) Principle (Wallace and Boulton, 1968) to evaluate candidate d</context>
<context position="6524" citStr="Pearl, 1988" startWordPosition="1011" endWordPosition="1012">er, in our current version this capability has been replaced with a web-based interface. Figure 2: Argument-construction screen and user’s argument after she has read the police report, seen the newspaper and spoken to the forensic experts. Figure 3 shows the interpretation generated by BIAS for the argument in Figure 2. In it the system fills in propositions and relations where the user has made inferential leaps, and points out its beliefs and the user’s. 2.2 Domain representation The domain propositions and the relationships between them are represented by means of a Bayesian network (BN) (Pearl, 1988). Each BN in the system can support a variety of scenarios, depending on the instantiation of the evidence nodes. The murder mystery used for this paper is represented by means of an 85-node BN (similar to that used in (Zukerman, 2001)). Figure 4 shows a portion of this BN: the evidence nodes are boxed, and the goal node – GmurderedB – is circled. The five evidence nodes mentioned in the police report are boldfaced and shaded, the two evidence nodes obtained by the user in her investigation are boldfaced and dark shaded ([BayesianTimes Reports B Took G’s Girlfriend] and [Forensics Match G’s Fi</context>
</contexts>
<marker>Pearl, 1988</marker>
<rawString>Judea Pearl. 1988. Probabilistic Reasoning in Intelligent Systems. Morgan Kaufmann Publishers, San Mateo, California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C S Wallace</author>
<author>D M Boulton</author>
</authors>
<title>An information measure for classification.</title>
<date>1968</date>
<journal>The Computer Journal,</journal>
<pages>11--185</pages>
<contexts>
<context position="1880" citStr="Wallace and Boulton, 1968" startWordPosition="254" endWordPosition="257">m which uses Bayesian networks (BNs) (Pearl, 1988) as its knowledge representation and reasoning formalism. BIAS is designed to be a complete argumentation system which will eventually engage in unrestricted interactions with users. However, in this paper, we focus on its discourse interpretation mechanism and the impact of attentional focus on the interpretation process. The contributions of this paper are as follows. 1. We incorporate attentional focus into the discourse-interpretation formalism described in (Zukerman and George, 2002), which uses the Minimum Message Length (MML) Principle (Wallace and Boulton, 1968) to evaluate candidate discourse interpretations. 2. We investigate a web-based argumentation facility for the detective game described in (Zukerman, 2001). In the following section, we describe our detective game, and discuss our knowledge representation. Next, we outline the argument interpretation process. In Section 4, we provide an overview of our Minimum Message Length approach to discourse interpretation, and describe how attentional focus is incorporated into this formalism. The results of our evaluation are reported in Section 5. We then discuss related research, followed by concludin</context>
<context position="11594" citStr="Wallace and Boulton, 1968" startWordPosition="1820" endWordPosition="1823">an erroneous assessment of Mr Green’s opportunity, or an assessment of the impact of opportunity on guilt which differs from BIAS’. In the future, our mechanism will consider the first two factors for neighbouring nodes of an interpretation (the third factor involves learning a user’s Conditional Probability Tables – a task that is outside the scope of this project). 4 Selecting an Interpretation In this section we present the Minimum Message Length criterion, describe its use for argument interpretation, and show how attentional focus is incorporated into our MML model. 4.1 NNL Encoding MML (Wallace and Boulton, 1968) is a model selection criterion (used to select between candidate models that explain observed data). The MML criterion implements Occam’s Razor, which may be stated as follows: “If you have two theories which both explain the observed facts, then you should use the simplest until more evidence comes along” (the same idea is embodied in Einstein’s aphorism “Make everything as simple as possible, but not simpler”). This criterion balances data fit with model complexity. That is, the best model should fit the data well and it should be simple. In probabilistic terms, given data D, the MML criter</context>
<context position="25585" citStr="Wallace and Boulton, 1968" startWordPosition="4129" endWordPosition="4132">standing with BNs. Zukerman (2001) used a domain model and user model represented as a BN, together with linguistic and attentional information, to infer a user’s goal from a single-proposition rejoinder to a system-generated argument. However, the combination of these knowledge sources was based on heuristics. Zukerman and George (2002) developed the initial probabilistic model for applying the MML principle to argument interpretation. Here we extend this model to include attentional focus, integrate it into an interactive interpretation system, and evaluate it with users. The MML principle (Wallace and Boulton, 1968) is a model-selection technique which applies information-theoretic criteria to trade data fit against model complexity. MML has been used in a variety of applications, several of which are listed in http://www.csse. monash.edu.au/dld/Snob.application.papers. In this paper, we demonstrate the applicability of MML to a high-level NL task. BNs have been used in several systems that perform plan recognition, e.g., (Charniak and Goldman, 1993; Gertner et al., 1998; Horvitz and Paek, 1999). Charniak and Goldman’s system (Charniak and Goldman, 1993) handled complex narratives, using a BN and marker</context>
</contexts>
<marker>Wallace, Boulton, 1968</marker>
<rawString>C.S. Wallace and D.M. Boulton. 1968. An information measure for classification. The Computer Journal, 11:185–194.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingrid Zukerman</author>
<author>Sarah George</author>
</authors>
<title>A Minimum Message Length approach for argument interpretation.</title>
<date>2002</date>
<booktitle>In Proceedings of the Third SIGdial Workshop on Discourse and Dialogue,</booktitle>
<pages>211--220</pages>
<location>Philadelphia, Pennsylvania.</location>
<contexts>
<context position="1797" citStr="Zukerman and George, 2002" startWordPosition="242" endWordPosition="245">ch builds on our previous work on BIAS – a Bayesian Interactive Argumentation System which uses Bayesian networks (BNs) (Pearl, 1988) as its knowledge representation and reasoning formalism. BIAS is designed to be a complete argumentation system which will eventually engage in unrestricted interactions with users. However, in this paper, we focus on its discourse interpretation mechanism and the impact of attentional focus on the interpretation process. The contributions of this paper are as follows. 1. We incorporate attentional focus into the discourse-interpretation formalism described in (Zukerman and George, 2002), which uses the Minimum Message Length (MML) Principle (Wallace and Boulton, 1968) to evaluate candidate discourse interpretations. 2. We investigate a web-based argumentation facility for the detective game described in (Zukerman, 2001). In the following section, we describe our detective game, and discuss our knowledge representation. Next, we outline the argument interpretation process. In Section 4, we provide an overview of our Minimum Message Length approach to discourse interpretation, and describe how attentional focus is incorporated into this formalism. The results of our evaluation</context>
<context position="21329" citStr="Zukerman and George, 2002" startWordPosition="3431" endWordPosition="3435">retation process, let us reconsider the sample argument in Figure 5, and let us assume that [G At Window] was never seen by the user, while [Ladder Outside Window] and [B Killed From Outside Window] were seen recently. In this case, a high probability for these two propositions may overcome the factors in favour of SysIntA, thereby making SysIntB the preferred interpretation. 4Other factors, such as intrinsic salience of a proposition, have not been modeled at present. 5 Evaluation The system was evaluated in two modes: (1) automatic and (2) user based. Our automatic evaluation, described in (Zukerman and George, 2002), consisted of having the system interpret noisy versions of its own arguments. These arguments were generated from different subnets of its domain BN, and they were distorted by changing the beliefs in the nodes, and inserting and deleting nodes and arcs. All these distortions were performed on BNs of different sizes (3, 5, 7 and 9 arcs). Our measure of performance was the editdistance between the original BN used to generate an argument, and the BN produced as the interpretation of this argument. BIAS produced an interpretation in 86% of the 5400 trials. In 75% of the 5400 cases, the generat</context>
<context position="24904" citStr="Zukerman and George, 2002" startWordPosition="4028" endWordPosition="4031"> module. It is envisaged that a solution combining menus and NL input will yield the best results. Our evaluation also corroborates the insights from Section 3 regarding the difficulties of taking into account users’ assumptions during the argument interpretation process. However, the results of our evaluation are encouraging with respect to the use of the MML principle for the selection of interpretations. In the future, we propose to conduct a more rigorous evaluation with additional users to confirm these results. 6 Related Research Our research builds on work described in (Zukerman, 2001; Zukerman and George, 2002), which integrates plan recognition for discourse understanding with BNs. Zukerman (2001) used a domain model and user model represented as a BN, together with linguistic and attentional information, to infer a user’s goal from a single-proposition rejoinder to a system-generated argument. However, the combination of these knowledge sources was based on heuristics. Zukerman and George (2002) developed the initial probabilistic model for applying the MML principle to argument interpretation. Here we extend this model to include attentional focus, integrate it into an interactive interpretation </context>
</contexts>
<marker>Zukerman, George, 2002</marker>
<rawString>Ingrid Zukerman and Sarah George. 2002. A Minimum Message Length approach for argument interpretation. In Proceedings of the Third SIGdial Workshop on Discourse and Dialogue, pages 211–220, Philadelphia, Pennsylvania.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ingrid Zukerman</author>
</authors>
<title>An integrated approach for generating arguments and rebuttals and understanding rejoinders.</title>
<date>2001</date>
<booktitle>In UM01 – Proceedings of the Eighth International Conference on User Modeling,</booktitle>
<pages>84--94</pages>
<location>Sonthofen, Germany.</location>
<contexts>
<context position="2035" citStr="Zukerman, 2001" startWordPosition="278" endWordPosition="280">ch will eventually engage in unrestricted interactions with users. However, in this paper, we focus on its discourse interpretation mechanism and the impact of attentional focus on the interpretation process. The contributions of this paper are as follows. 1. We incorporate attentional focus into the discourse-interpretation formalism described in (Zukerman and George, 2002), which uses the Minimum Message Length (MML) Principle (Wallace and Boulton, 1968) to evaluate candidate discourse interpretations. 2. We investigate a web-based argumentation facility for the detective game described in (Zukerman, 2001). In the following section, we describe our detective game, and discuss our knowledge representation. Next, we outline the argument interpretation process. In Section 4, we provide an overview of our Minimum Message Length approach to discourse interpretation, and describe how attentional focus is incorporated into this formalism. The results of our evaluation are reported in Section 5. We then discuss related research, followed by concluding remarks. 2 Detective Game As for the system described in (Zukerman, 2001), our experimental set up takes the form of a game where the user and the system</context>
<context position="6759" citStr="Zukerman, 2001" startWordPosition="1053" endWordPosition="1054">experts. Figure 3 shows the interpretation generated by BIAS for the argument in Figure 2. In it the system fills in propositions and relations where the user has made inferential leaps, and points out its beliefs and the user’s. 2.2 Domain representation The domain propositions and the relationships between them are represented by means of a Bayesian network (BN) (Pearl, 1988). Each BN in the system can support a variety of scenarios, depending on the instantiation of the evidence nodes. The murder mystery used for this paper is represented by means of an 85-node BN (similar to that used in (Zukerman, 2001)). Figure 4 shows a portion of this BN: the evidence nodes are boxed, and the goal node – GmurderedB – is circled. The five evidence nodes mentioned in the police report are boldfaced and shaded, the two evidence nodes obtained by the user in her investigation are boldfaced and dark shaded ([BayesianTimes Reports B Took G’s Girlfriend] and [Forensics Match G’s Fingerprints]), and the evidence nodes employed by the user in her argument have white text. The nodes corresponding to the consequents in the user’s argument are boldfaced ([G Has Means], [G Has Motive] and [G Murdered B]). 3 Proposing </context>
<context position="24876" citStr="Zukerman, 2001" startWordPosition="4025" endWordPosition="4027">it with BIAS’ NL module. It is envisaged that a solution combining menus and NL input will yield the best results. Our evaluation also corroborates the insights from Section 3 regarding the difficulties of taking into account users’ assumptions during the argument interpretation process. However, the results of our evaluation are encouraging with respect to the use of the MML principle for the selection of interpretations. In the future, we propose to conduct a more rigorous evaluation with additional users to confirm these results. 6 Related Research Our research builds on work described in (Zukerman, 2001; Zukerman and George, 2002), which integrates plan recognition for discourse understanding with BNs. Zukerman (2001) used a domain model and user model represented as a BN, together with linguistic and attentional information, to infer a user’s goal from a single-proposition rejoinder to a system-generated argument. However, the combination of these knowledge sources was based on heuristics. Zukerman and George (2002) developed the initial probabilistic model for applying the MML principle to argument interpretation. Here we extend this model to include attentional focus, integrate it into an</context>
</contexts>
<marker>Zukerman, 2001</marker>
<rawString>Ingrid Zukerman. 2001. An integrated approach for generating arguments and rebuttals and understanding rejoinders. In UM01 – Proceedings of the Eighth International Conference on User Modeling, pages 84–94, Sonthofen, Germany.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>