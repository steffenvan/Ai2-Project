<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.124108">
<title confidence="0.986667">
DERIUNLP: A Context Based Approach to Automatic Keyphrase
Extraction
</title>
<author confidence="0.992765">
Georgeta Bordea
</author>
<affiliation confidence="0.998155">
Unit for Natural Language Processing
Digital Enterprise Research Institute
National University of Ireland, Galway
</affiliation>
<email confidence="0.996433">
georgeta.bordea@deri.org
</email>
<author confidence="0.992682">
Paul Buitelaar
</author>
<affiliation confidence="0.998172333333333">
Unit for Natural Language Processing
Digital Enterprise Research Institute
National University of Ireland, Galway
</affiliation>
<email confidence="0.993463">
paul.buitelaar@deri.org
</email>
<sectionHeader confidence="0.993805" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999661666666667">
The DERI UNLP team participated in the
SemEval 2010 Task #5 with an unsuper-
vised system that automatically extracts
keyphrases from scientific articles. Our
approach does not only consider a general
description of a term to select keyphrase
candidates but also context information in
the form of “skill types”. Even though
our system analyses only a limited set of
candidates, it is still able to outperform
baseline unsupervised and supervised ap-
proaches.
</bodyText>
<sectionHeader confidence="0.998799" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999908742857143">
Keyphrases provide users overwhelmed by the
richness of information currently available with
useful insight into document content but at the
same time they are a valuable input for a variety of
NLP applications such as summarization, cluster-
ing and searching. The SemEval 2010 competition
included a task targeting the Automatic Keyphrase
Extraction from Scientific Articles (Kim et al.,
2010). Given a set of scientific articles partic-
ipants are required to assign to each document
keyphrases extracted from text.
We participated in this task with an unsuper-
vised approach for keyphrase extraction that does
not only consider a general description of a term
to select candidates but also takes into consider-
ation context information. The larger context of
our work is the extraction of expertise topics for
Expertise Mining (Bordea, 2010).
Expertise Mining is the task of automatically
extracting expertise topics and expertise profiles
from a collection of documents. Even though the
Expertise Mining task and the Keyphrase Extrac-
tion task are essentially different, it is important
to assess the keyphraseness of extracted expertise
topics, i.e., their ability to represent the content
of a document. Here we will report only relevant
findings for the Keyphrase Extraction task, focus-
ing on the overlapping aspects of the two afore-
mentioned tasks.
After giving an overview of related work in sec-
tion 2 we introduce skill types and present our can-
didate selection method in section 3. Section 4 de-
scribes the features used for ranking and filtering
the candidate keyphrases and Section 5 presents
our results before we conclude in Section 6.
</bodyText>
<sectionHeader confidence="0.999782" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999953733333333">
The current methods for keyphrase extraction can
be categorized in supervised and unsupervised ap-
proaches. Typically any keyphrase extraction sys-
tem works in two stages. In the first stage a gen-
eral set of candidates is selected by extracting the
tokens of a text. In the second stage unsupervised
approaches combine a set of features in a rank to
select the most important keyphrases and super-
vised approaches use a training corpus to learn a
keyphrase extraction model.
Mihalcea and Tarau (2004) propose an unsuper-
vised approach that considers single tokens as ver-
tices of a graph and co-occurrence relations be-
tween tokens as edges. Candidates are ranked us-
ing PageRank and adjacent keywords are merged
into keyphrases in a post-processing step. The
frequency of noun phrase heads is exploited by
Barker and Cornacchia (2000), using noun phrases
as candidates and ranking them based on term fre-
quency and term length.
Kea is a supervised system that uses all n-grams
of a certain length, a Naive Bayes classifier and
tf-idf and position features (Frank et al., 1999).
Turney (2000) introduces Extractor, a supervised
system that selects stems and stemmed n-grams
as candidates and tunes its parameters (mainly re-
lated to frequency, position, length) with a ge-
netic algorithm. Hulth (2004) experiments with
three types of candidate terms (i.e., n-grams, noun
phrase chunks and part-of-speech tagged words
</bodyText>
<page confidence="0.984611">
146
</page>
<bodyText confidence="0.954942727272727">
Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 146–149,
Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics
that match a set of patterns) and constructs classi-
fiers by rule induction using features such as term
frequency, collection frequency, relative position
and PoS tags.
The candidate selection method is the main dif-
ference between our approach and previous work.
We did not use only a general description of a term
to select candidates, but we also took into consid-
eration context information.
</bodyText>
<sectionHeader confidence="0.880065" genericHeader="method">
3 The Skill Types Candidate Selection
Method
</sectionHeader>
<bodyText confidence="0.9971754">
Skill types are important domain words that are
general enough to be used in different subfields
and that reflect theoretical or practical expertise.
Consider for instance the following extracts from
scientific articles:
</bodyText>
<construct confidence="0.846751">
...analysis of historical trends...
...duplicate photo detection algorithm ...
...approach for data assimilation...
...methodology for reservoir characterization...
</construct>
<bodyText confidence="0.999941035714286">
In all four examples the expertise topic (e.g.,
“historical trends”, “duplicate photo detection al-
gorithm”, “data assimilation”, “reservoir charac-
terization”) is introduced by a skill type (e.g.,
“analysis”, “algorithm”, “approach”, “methodol-
ogy”). Some of these skill types are valid for
any scientific area (e.g. “approach”, “method”,
“analysis”, “solution”) but we can also identify
domain specific skill types, e.g., for computer
science “implementation”, “algorithm”, “develop-
ment”, “framework”, for physics “proof”, “prin-
ciples”, “explanation” and for chemistry “law”,
“composition”, “mechanism”, “reaction”, “struc-
ture”.
Our system is based on the GATE natural lan-
guage processing framework (Cunningham et al.,
2002) and it uses the ANNIE IE system included
in the standard GATE distribution for text tok-
enization, sentence splitting and part-of-speech
tagging. The GATE processing pipeline is de-
picted in Figure 1, where the light grey boxes em-
body components available as part of the GATE
framework whereas the dark grey boxes represent
components implemented as part of our system.
We manually extract a set of 81 single word skill
types for the Computer Science field by analysing
word frequencies for topics from the ACM classi-
fication system1. The skill types that appear most
</bodyText>
<footnote confidence="0.9749795">
1ACM classification system: http://www.acm.
org/about/class/
</footnote>
<figureCaption confidence="0.999598">
Figure 1: GATE Processing Pipeline
</figureCaption>
<bodyText confidence="0.999901777777778">
frequently in keyphrases given in the training set
are “system”, “model” and “information”. The
Skill Types Gazetteer adds annotations for skill
types and then the JAPE Transducer uses regular
expressions to annotate candidates.
We rely on a syntactic description of a term to
discover candidate keyphrases that appear in the
right context of a skill type or that include a skill
type. The syntactic pattern for a term is defined
by a sequence of part-of-speech tags, mainly a
noun phrase. We consider that a noun phrase is a
head noun accompanied by a set of modifiers (i.e
nouns, adjectives) that includes proper nouns, car-
dinal numbers (e.g., “P2P systems”) and gerunds
(e.g., “ontology mapping”, “data mining”). Terms
that contain the preposition “of” (e.g., “quality of
service”) or the conjunction “and” (e.g., “search
and rescue”) were also allowed.
</bodyText>
<sectionHeader confidence="0.980932" genericHeader="method">
4 Ranking and Filtering
</sectionHeader>
<bodyText confidence="0.999968">
For the ranking stage we use several features al-
ready proposed in the literature such as length of
a keyphrase, tf-idf and position. We also take into
consideration the collection frequency in the con-
text of a skill type.
Ranking. Longer candidates in terms of
number of words are ranked higher, because they
are more descriptive. Keyphrases that appear
more frequently with a skill type in the collection
of documents are also ranked higher. Therefore
we define the rank for a topic as:
</bodyText>
<page confidence="0.990554">
147
</page>
<table confidence="0.999821666666667">
Method 5P 5R 5F 10P 10R 10F 15P 15R 15F
TF-IDF 22 7.5 11.19 17.7 12.07 14.35 14.93 15.28 15.1
NB 21.4 7.3 10.89 17.3 11.8 14.03 14.53 14.87 14.7
ME 21.4 7.3 10.89 17.3 11.8 14.03 14.53 14.87 14.7
DERIUNLP 27.4 9.35 13.94 23 15.69 18.65 22 22.51 22.25
DUB 15.83 5.13 7.75 13.40 8.68 10.54 13.33 12.96 13.14
</table>
<tableCaption confidence="0.985539">
Table 1: Baseline and DERIUNLP Performance aver Combined Keywords
</tableCaption>
<table confidence="0.9999016">
System 5P 5R 5F 10P 10R 10F 15P 15R 15F
Best 39.0 13.3 19.8 32.0 21.8 26.0 27.2 27.8 27.5
Average 29.6 10.1 15 26.1 17.8 21.2 21.9 22.4 22.2
Worst 9.4 3.2 4.8 5.9 4.0 4.8 5.3 5.4 5.3
DERIUNLP 27.4 9.4 13.9 23.0 15.7 18.7 22.0 22.5 22.3
</table>
<tableCaption confidence="0.999137">
Table 2: Performance over Combined Keywords
</tableCaption>
<equation confidence="0.758978">
Ri,j = Tni * Fni * tfidfi,j
</equation>
<bodyText confidence="0.999594477272727">
Where Ri is the rank for the candidate i and the
document j, Tni is the normalized number of to-
kens (number of tokens divided by the maximum
number of tokens for a keyphrase), Fni is the nor-
malized collection frequency of the candidate in
the context of a skill type (collection frequency di-
vided by the maximum collection frequency), and
tfidfi is the TF-IDF for candidate i and topic j
(computed based on extracted topics not based on
all words).
Filtering. Several approaches (Paukkeri et al.,
2008; Tomokiyo and Hurst, 2003) use a reference
corpus for keyphrase extraction. We decided to
use the documents available on the Web as a ref-
erence corpus, therefore we use an external web
search engine to filter out the candidates that are
too general from the final result set. If a candi-
date has more than 109 hits on the web it is too
general to be included in the final result set. A lot
of noise is introduced by general combination of
words that could appear in any document. We re-
move candidates longer than eight words and we
ignore keyphrases that have one letter words or
that include non-alphanumerical characters.
Acronyms. Acronyms usually replace long
or frequently referenced terms. Results are im-
proved by analysing acronyms (Krulwich and
Burkey, 1996) because most of the times the ex-
panded acronym is reported as a keyphrase, not the
acronym and because our rank is sensitive to the
number of words in a keyphrase. We consider the
length of an acronym to be the same as the length
of its expansion and we report only the expansion
as a keyphrase.
Position. The candidates that appear in the title
or the introduction of a document are more likely
to be relevant for the document. We divide each
document in 10 sections relative to document size
and we increase the ranks for keyphrases first men-
tioned in one of these sections (200% increase for
the first section, 100% increase for the second sec-
tion and 25% for the third section). Candidates
with a first appearance in the last section of a doc-
ument are penalised by 25%.
</bodyText>
<sectionHeader confidence="0.997091" genericHeader="evaluation">
5 Evaluation
</sectionHeader>
<bodyText confidence="0.999954806451613">
The SemEval task organizers provided two sets
of scientific articles, a set of 144 documents for
training and a set of 100 documents for test-
ing. No information was provided about the sci-
entific domain of the articles but at least some
of them are from Computer Science. The av-
erage length of the articles is between 6 and
8 pages including tables and pictures. Three
sets of answers were provided: author-assigned
keyphrases, reader-assigned keyphrases and com-
bined keyphrases (combination of the first two
sets). The participants were asked to assign a num-
ber of exactly 15 keyphrases per document.
All reader-assigned keyphrases are extracted
from the papers, whereas some of the author-
assigned keyphrases do not occur explicitly in the
text. Two alternations of keyphrase are accepted:
A of B / B A and A’s B. In case that the seman-
tics changes due to the alternation, the alternation
is not included in the answer set. The traditional
evaluation metric was followed, matching the ex-
tracted keyphrases with the keyphrases in the an-
swer sets and calculating precision, recall and F-
score. In both tables the column labels start with a
number which stands for the top 5, 10 or 15 candi-
dates. The characters P, R, F mean micro-averaged
precision, recall and F-scores. For baselines, 1, 2,
3 grams were used as candidates and TF-IDF as
features.
In Table 1 the keyphrases extracted by our sys-
tem are compared with keyphrases extracted by
</bodyText>
<page confidence="0.996255">
148
</page>
<bodyText confidence="0.9999788">
an unsupervised method that ranks the candidates
based on TF-IDF scores and two supervised meth-
ods using Naive Bayes (NB) and maximum en-
tropy(ME) in WEKA2. Our performance is well
above the baseline in all cases.
To show the contribution of skill types we in-
cluded the results for a baseline version of our
system (DUB) that does not rank the candidates
using the normalized collection frequency in the
context of a skill type Fnz but the overall collec-
tion frequency (i.e., the number of occurrences of
a keyphrase in the corpus). The significantly in-
creased results compared to our baseline version
show the effectiveness of skill types for keyphrase
candidate ranking.
Table 2 presents our results in comparison with
results of other participants. Even though our sys-
tem considers in the first stage a significantly lim-
ited set of candidates the results are very close to
the average results of other participants. Our sys-
tem performed 8th best out of 19 participants for
top 15 keyphrases, 10th best for top 10 keyphrases
and 13th best for top 5 keyphrases, which indicates
that our approach could be improved by using a
more sophisticated ranking method.
</bodyText>
<sectionHeader confidence="0.999538" genericHeader="conclusions">
6 Conclusions
</sectionHeader>
<bodyText confidence="0.99964447826087">
In this paper we have reported the performance
of an unsupervised approach for keyphrase extrac-
tion that does not only consider a general descrip-
tion of a term to select keyphrase candidates but
also takes into consideration context information.
The method proposed here uses term extraction
techniques (the syntactic description of a term),
classical keyword extraction techniques(TF-IDF,
length, position) and contextual evidence (skill
types).
We argued that so called “skill types” (e.g.,
“methods”, “approach”, “analysis”) are a useful
instrument for selecting keyphrases from a doc-
ument. Another novel aspect of this approach is
using the collection of documents available on the
Web (i.e., number of hits for a keyphrase) instead
of a reference corpus. It would be interesting to
evaluate the individual contributions of skill types
for Keyphrase Extraction by adding them as a fea-
ture in a classical system like KEA.
Future work will include an algorithm for auto-
matic extraction of skill types for a domain and an
analysis of the performance of each skill type.
</bodyText>
<footnote confidence="0.9459515">
2WEKA:http://www.cs.waikato.ac.nz/ml/
weka/
</footnote>
<sectionHeader confidence="0.838797" genericHeader="acknowledgments">
7 Aknowledgements
</sectionHeader>
<bodyText confidence="0.5479515">
This work is supported by Science Foundation Ire-
land under Grant No. SFI/08/CE/I1380 (Lion-2).
</bodyText>
<sectionHeader confidence="0.972726" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.9997296875">
Ken Barker and Nadia Cornacchia. 2000. Using Noun
Phrase Heads to Extract Document Keyphrases. In
Canadian Conference on AI, pages 40–52. Springer.
Georgeta Bordea. 2010. Concept Extraction Applied
to the Task of Expert Finding. In Extended Semantic
Web Conference 2010, PhD Symposium. Springer.
H. Cunningham, D. Maynard, K. Bontcheva, and
V. Tablan. 2002. GATE: A Framework and Graph-
ical Development Environment for Robust NLP
Tools and Applications. In Proceedings of the 40th
Anniversary Meeting of the Association for Compu-
tational Linguistics.
Eibe Frank, Gordon W Paynter, Ian H Witten, Carl
Gutwin, and Craig G Nevill-Manning. 1999.
Domain-Specific Keyphrase Extraction. In Pro-
ceedings of the 16th International Joint Conference
on Aritfiicial Intelligence, pages 668–673.
Anette Hulth. 2004. Enhancing Linguistically Ori-
ented Automatic Keyword Extraction. In Proceed-
ings of HLT/NAACL: Short Papers, pages 17–20.
Su Nam Kim, Alyona Medelyan, Min-Yen Kan, and
Timothy Baldwin. 2010. SemEval-2010 Task 5:
Automatic Keyphrase Extraction from Scientific Ar-
ticles. In Proceedings of the ACL 2010 Workshop on
Evaluation Exercises on Semantic Evaluation (Se-
mEval 2010).
Bruce Krulwich and Chad Burkey. 1996. Learn-
ing user information interests through extraction of
semantically significant phrases. In Proc. AAAI
Spring Symp. Machine Learning in Information Ac-
cess, Menlo Park, Calif. Amer. Assoc. for Artificial
Intelligence.
Rada Mihalcea and Paul Tarau. 2004. Textrank:
Bringing order into texts. In Proceedings of the
Conference on Empirical Methods in Natural Lan-
guage Processing, pages 404–411.
Mari-Sanna Paukkeri, Ilari T. Nieminen, Polla Matti,
and Timo Honkela. 2008. A Language-Independent
Approach to Keyphrase Extraction and Evaluation.
In Coling 2008 Posters, number August, pages 83–
86.
Takashi Tomokiyo and Matthew Hurst. 2003. A Lan-
guage Model Approach to Keyphrase Extraction. In
Proceedings of the ACL 2003 work- shop on Multi-
word expressions, pages 33–40.
Peter D Turney. 2000. Learning algorithms for
keyphrase extraction. Information Retrieval, 2:303–
336.
</reference>
<page confidence="0.99897">
149
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.635603">
<title confidence="0.996086">DERIUNLP: A Context Based Approach to Automatic Keyphrase Extraction</title>
<author confidence="0.993294">Georgeta Bordea</author>
<affiliation confidence="0.956381333333333">Unit for Natural Language Processing Digital Enterprise Research Institute National University of Ireland, Galway</affiliation>
<email confidence="0.992135">georgeta.bordea@deri.org</email>
<author confidence="0.998436">Paul Buitelaar</author>
<affiliation confidence="0.959751333333333">Unit for Natural Language Processing Digital Enterprise Research Institute National University of Ireland, Galway</affiliation>
<email confidence="0.993669">paul.buitelaar@deri.org</email>
<abstract confidence="0.988203">The DERI UNLP team participated in the SemEval 2010 Task #5 with an unsupervised system that automatically extracts keyphrases from scientific articles. Our approach does not only consider a general description of a term to select keyphrase candidates but also context information in the form of “skill types”. Even though our system analyses only a limited set of candidates, it is still able to outperform baseline unsupervised and supervised approaches.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Ken Barker</author>
<author>Nadia Cornacchia</author>
</authors>
<title>Using Noun Phrase Heads to Extract Document Keyphrases.</title>
<date>2000</date>
<booktitle>In Canadian Conference on AI,</booktitle>
<pages>40--52</pages>
<publisher>Springer.</publisher>
<contexts>
<context position="3345" citStr="Barker and Cornacchia (2000)" startWordPosition="511" endWordPosition="514">et of candidates is selected by extracting the tokens of a text. In the second stage unsupervised approaches combine a set of features in a rank to select the most important keyphrases and supervised approaches use a training corpus to learn a keyphrase extraction model. Mihalcea and Tarau (2004) propose an unsupervised approach that considers single tokens as vertices of a graph and co-occurrence relations between tokens as edges. Candidates are ranked using PageRank and adjacent keywords are merged into keyphrases in a post-processing step. The frequency of noun phrase heads is exploited by Barker and Cornacchia (2000), using noun phrases as candidates and ranking them based on term frequency and term length. Kea is a supervised system that uses all n-grams of a certain length, a Naive Bayes classifier and tf-idf and position features (Frank et al., 1999). Turney (2000) introduces Extractor, a supervised system that selects stems and stemmed n-grams as candidates and tunes its parameters (mainly related to frequency, position, length) with a genetic algorithm. Hulth (2004) experiments with three types of candidate terms (i.e., n-grams, noun phrase chunks and part-of-speech tagged words 146 Proceedings of th</context>
</contexts>
<marker>Barker, Cornacchia, 2000</marker>
<rawString>Ken Barker and Nadia Cornacchia. 2000. Using Noun Phrase Heads to Extract Document Keyphrases. In Canadian Conference on AI, pages 40–52. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Georgeta Bordea</author>
</authors>
<title>Concept Extraction Applied to the Task of Expert Finding.</title>
<date>2010</date>
<booktitle>In Extended Semantic Web Conference 2010, PhD Symposium.</booktitle>
<publisher>Springer.</publisher>
<contexts>
<context position="1697" citStr="Bordea, 2010" startWordPosition="246" endWordPosition="247">zation, clustering and searching. The SemEval 2010 competition included a task targeting the Automatic Keyphrase Extraction from Scientific Articles (Kim et al., 2010). Given a set of scientific articles participants are required to assign to each document keyphrases extracted from text. We participated in this task with an unsupervised approach for keyphrase extraction that does not only consider a general description of a term to select candidates but also takes into consideration context information. The larger context of our work is the extraction of expertise topics for Expertise Mining (Bordea, 2010). Expertise Mining is the task of automatically extracting expertise topics and expertise profiles from a collection of documents. Even though the Expertise Mining task and the Keyphrase Extraction task are essentially different, it is important to assess the keyphraseness of extracted expertise topics, i.e., their ability to represent the content of a document. Here we will report only relevant findings for the Keyphrase Extraction task, focusing on the overlapping aspects of the two aforementioned tasks. After giving an overview of related work in section 2 we introduce skill types and prese</context>
</contexts>
<marker>Bordea, 2010</marker>
<rawString>Georgeta Bordea. 2010. Concept Extraction Applied to the Task of Expert Finding. In Extended Semantic Web Conference 2010, PhD Symposium. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>H Cunningham</author>
<author>D Maynard</author>
<author>K Bontcheva</author>
<author>V Tablan</author>
</authors>
<title>GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications.</title>
<date>2002</date>
<booktitle>In Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics.</booktitle>
<contexts>
<context position="5653" citStr="Cunningham et al., 2002" startWordPosition="843" endWordPosition="846">orithm”, “data assimilation”, “reservoir characterization”) is introduced by a skill type (e.g., “analysis”, “algorithm”, “approach”, “methodology”). Some of these skill types are valid for any scientific area (e.g. “approach”, “method”, “analysis”, “solution”) but we can also identify domain specific skill types, e.g., for computer science “implementation”, “algorithm”, “development”, “framework”, for physics “proof”, “principles”, “explanation” and for chemistry “law”, “composition”, “mechanism”, “reaction”, “structure”. Our system is based on the GATE natural language processing framework (Cunningham et al., 2002) and it uses the ANNIE IE system included in the standard GATE distribution for text tokenization, sentence splitting and part-of-speech tagging. The GATE processing pipeline is depicted in Figure 1, where the light grey boxes embody components available as part of the GATE framework whereas the dark grey boxes represent components implemented as part of our system. We manually extract a set of 81 single word skill types for the Computer Science field by analysing word frequencies for topics from the ACM classification system1. The skill types that appear most 1ACM classification system: http:</context>
</contexts>
<marker>Cunningham, Maynard, Bontcheva, Tablan, 2002</marker>
<rawString>H. Cunningham, D. Maynard, K. Bontcheva, and V. Tablan. 2002. GATE: A Framework and Graphical Development Environment for Robust NLP Tools and Applications. In Proceedings of the 40th Anniversary Meeting of the Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eibe Frank</author>
<author>Gordon W Paynter</author>
<author>Ian H Witten</author>
<author>Carl Gutwin</author>
<author>Craig G Nevill-Manning</author>
</authors>
<title>Domain-Specific Keyphrase Extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the 16th International Joint Conference on Aritfiicial Intelligence,</booktitle>
<pages>668--673</pages>
<contexts>
<context position="3586" citStr="Frank et al., 1999" startWordPosition="553" endWordPosition="556">ase extraction model. Mihalcea and Tarau (2004) propose an unsupervised approach that considers single tokens as vertices of a graph and co-occurrence relations between tokens as edges. Candidates are ranked using PageRank and adjacent keywords are merged into keyphrases in a post-processing step. The frequency of noun phrase heads is exploited by Barker and Cornacchia (2000), using noun phrases as candidates and ranking them based on term frequency and term length. Kea is a supervised system that uses all n-grams of a certain length, a Naive Bayes classifier and tf-idf and position features (Frank et al., 1999). Turney (2000) introduces Extractor, a supervised system that selects stems and stemmed n-grams as candidates and tunes its parameters (mainly related to frequency, position, length) with a genetic algorithm. Hulth (2004) experiments with three types of candidate terms (i.e., n-grams, noun phrase chunks and part-of-speech tagged words 146 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 146–149, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics that match a set of patterns) and constructs classifiers by rule induction using</context>
</contexts>
<marker>Frank, Paynter, Witten, Gutwin, Nevill-Manning, 1999</marker>
<rawString>Eibe Frank, Gordon W Paynter, Ian H Witten, Carl Gutwin, and Craig G Nevill-Manning. 1999. Domain-Specific Keyphrase Extraction. In Proceedings of the 16th International Joint Conference on Aritfiicial Intelligence, pages 668–673.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anette Hulth</author>
</authors>
<title>Enhancing Linguistically Oriented Automatic Keyword Extraction.</title>
<date>2004</date>
<booktitle>In Proceedings of HLT/NAACL: Short Papers,</booktitle>
<pages>17--20</pages>
<contexts>
<context position="3808" citStr="Hulth (2004)" startWordPosition="588" endWordPosition="589">jacent keywords are merged into keyphrases in a post-processing step. The frequency of noun phrase heads is exploited by Barker and Cornacchia (2000), using noun phrases as candidates and ranking them based on term frequency and term length. Kea is a supervised system that uses all n-grams of a certain length, a Naive Bayes classifier and tf-idf and position features (Frank et al., 1999). Turney (2000) introduces Extractor, a supervised system that selects stems and stemmed n-grams as candidates and tunes its parameters (mainly related to frequency, position, length) with a genetic algorithm. Hulth (2004) experiments with three types of candidate terms (i.e., n-grams, noun phrase chunks and part-of-speech tagged words 146 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 146–149, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics that match a set of patterns) and constructs classifiers by rule induction using features such as term frequency, collection frequency, relative position and PoS tags. The candidate selection method is the main difference between our approach and previous work. We did not use only a general descriptio</context>
</contexts>
<marker>Hulth, 2004</marker>
<rawString>Anette Hulth. 2004. Enhancing Linguistically Oriented Automatic Keyword Extraction. In Proceedings of HLT/NAACL: Short Papers, pages 17–20.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Su Nam Kim</author>
<author>Alyona Medelyan</author>
<author>Min-Yen Kan</author>
<author>Timothy Baldwin</author>
</authors>
<title>SemEval-2010 Task 5: Automatic Keyphrase Extraction from Scientific Articles.</title>
<date>2010</date>
<booktitle>In Proceedings of the ACL 2010 Workshop on Evaluation Exercises on Semantic Evaluation (SemEval</booktitle>
<contexts>
<context position="1251" citStr="Kim et al., 2010" startWordPosition="173" endWordPosition="176">tes but also context information in the form of “skill types”. Even though our system analyses only a limited set of candidates, it is still able to outperform baseline unsupervised and supervised approaches. 1 Introduction Keyphrases provide users overwhelmed by the richness of information currently available with useful insight into document content but at the same time they are a valuable input for a variety of NLP applications such as summarization, clustering and searching. The SemEval 2010 competition included a task targeting the Automatic Keyphrase Extraction from Scientific Articles (Kim et al., 2010). Given a set of scientific articles participants are required to assign to each document keyphrases extracted from text. We participated in this task with an unsupervised approach for keyphrase extraction that does not only consider a general description of a term to select candidates but also takes into consideration context information. The larger context of our work is the extraction of expertise topics for Expertise Mining (Bordea, 2010). Expertise Mining is the task of automatically extracting expertise topics and expertise profiles from a collection of documents. Even though the Experti</context>
</contexts>
<marker>Kim, Medelyan, Kan, Baldwin, 2010</marker>
<rawString>Su Nam Kim, Alyona Medelyan, Min-Yen Kan, and Timothy Baldwin. 2010. SemEval-2010 Task 5: Automatic Keyphrase Extraction from Scientific Articles. In Proceedings of the ACL 2010 Workshop on Evaluation Exercises on Semantic Evaluation (SemEval 2010).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bruce Krulwich</author>
<author>Chad Burkey</author>
</authors>
<title>Learning user information interests through extraction of semantically significant phrases.</title>
<date>1996</date>
<booktitle>In Proc. AAAI Spring Symp. Machine Learning in Information Access, Menlo Park, Calif. Amer. Assoc. for Artificial Intelligence.</booktitle>
<contexts>
<context position="9636" citStr="Krulwich and Burkey, 1996" startWordPosition="1523" endWordPosition="1526">ence corpus, therefore we use an external web search engine to filter out the candidates that are too general from the final result set. If a candidate has more than 109 hits on the web it is too general to be included in the final result set. A lot of noise is introduced by general combination of words that could appear in any document. We remove candidates longer than eight words and we ignore keyphrases that have one letter words or that include non-alphanumerical characters. Acronyms. Acronyms usually replace long or frequently referenced terms. Results are improved by analysing acronyms (Krulwich and Burkey, 1996) because most of the times the expanded acronym is reported as a keyphrase, not the acronym and because our rank is sensitive to the number of words in a keyphrase. We consider the length of an acronym to be the same as the length of its expansion and we report only the expansion as a keyphrase. Position. The candidates that appear in the title or the introduction of a document are more likely to be relevant for the document. We divide each document in 10 sections relative to document size and we increase the ranks for keyphrases first mentioned in one of these sections (200% increase for the </context>
</contexts>
<marker>Krulwich, Burkey, 1996</marker>
<rawString>Bruce Krulwich and Chad Burkey. 1996. Learning user information interests through extraction of semantically significant phrases. In Proc. AAAI Spring Symp. Machine Learning in Information Access, Menlo Park, Calif. Amer. Assoc. for Artificial Intelligence.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>Textrank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>404--411</pages>
<contexts>
<context position="3014" citStr="Mihalcea and Tarau (2004)" startWordPosition="458" endWordPosition="461">nking and filtering the candidate keyphrases and Section 5 presents our results before we conclude in Section 6. 2 Related Work The current methods for keyphrase extraction can be categorized in supervised and unsupervised approaches. Typically any keyphrase extraction system works in two stages. In the first stage a general set of candidates is selected by extracting the tokens of a text. In the second stage unsupervised approaches combine a set of features in a rank to select the most important keyphrases and supervised approaches use a training corpus to learn a keyphrase extraction model. Mihalcea and Tarau (2004) propose an unsupervised approach that considers single tokens as vertices of a graph and co-occurrence relations between tokens as edges. Candidates are ranked using PageRank and adjacent keywords are merged into keyphrases in a post-processing step. The frequency of noun phrase heads is exploited by Barker and Cornacchia (2000), using noun phrases as candidates and ranking them based on term frequency and term length. Kea is a supervised system that uses all n-grams of a certain length, a Naive Bayes classifier and tf-idf and position features (Frank et al., 1999). Turney (2000) introduces E</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. Textrank: Bringing order into texts. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 404–411.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Mari-Sanna Paukkeri</author>
<author>Ilari T Nieminen</author>
<author>Polla Matti</author>
<author>Timo Honkela</author>
</authors>
<title>A Language-Independent Approach to Keyphrase Extraction and Evaluation. In Coling</title>
<date>2008</date>
<pages>83--86</pages>
<contexts>
<context position="8870" citStr="Paukkeri et al., 2008" startWordPosition="1392" endWordPosition="1395">NLP 27.4 9.4 13.9 23.0 15.7 18.7 22.0 22.5 22.3 Table 2: Performance over Combined Keywords Ri,j = Tni * Fni * tfidfi,j Where Ri is the rank for the candidate i and the document j, Tni is the normalized number of tokens (number of tokens divided by the maximum number of tokens for a keyphrase), Fni is the normalized collection frequency of the candidate in the context of a skill type (collection frequency divided by the maximum collection frequency), and tfidfi is the TF-IDF for candidate i and topic j (computed based on extracted topics not based on all words). Filtering. Several approaches (Paukkeri et al., 2008; Tomokiyo and Hurst, 2003) use a reference corpus for keyphrase extraction. We decided to use the documents available on the Web as a reference corpus, therefore we use an external web search engine to filter out the candidates that are too general from the final result set. If a candidate has more than 109 hits on the web it is too general to be included in the final result set. A lot of noise is introduced by general combination of words that could appear in any document. We remove candidates longer than eight words and we ignore keyphrases that have one letter words or that include non-alp</context>
</contexts>
<marker>Paukkeri, Nieminen, Matti, Honkela, 2008</marker>
<rawString>Mari-Sanna Paukkeri, Ilari T. Nieminen, Polla Matti, and Timo Honkela. 2008. A Language-Independent Approach to Keyphrase Extraction and Evaluation. In Coling 2008 Posters, number August, pages 83– 86.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Takashi Tomokiyo</author>
<author>Matthew Hurst</author>
</authors>
<title>A Language Model Approach to Keyphrase Extraction.</title>
<date>2003</date>
<booktitle>In Proceedings of the ACL</booktitle>
<pages>33--40</pages>
<contexts>
<context position="8897" citStr="Tomokiyo and Hurst, 2003" startWordPosition="1396" endWordPosition="1399">15.7 18.7 22.0 22.5 22.3 Table 2: Performance over Combined Keywords Ri,j = Tni * Fni * tfidfi,j Where Ri is the rank for the candidate i and the document j, Tni is the normalized number of tokens (number of tokens divided by the maximum number of tokens for a keyphrase), Fni is the normalized collection frequency of the candidate in the context of a skill type (collection frequency divided by the maximum collection frequency), and tfidfi is the TF-IDF for candidate i and topic j (computed based on extracted topics not based on all words). Filtering. Several approaches (Paukkeri et al., 2008; Tomokiyo and Hurst, 2003) use a reference corpus for keyphrase extraction. We decided to use the documents available on the Web as a reference corpus, therefore we use an external web search engine to filter out the candidates that are too general from the final result set. If a candidate has more than 109 hits on the web it is too general to be included in the final result set. A lot of noise is introduced by general combination of words that could appear in any document. We remove candidates longer than eight words and we ignore keyphrases that have one letter words or that include non-alphanumerical characters. Acr</context>
</contexts>
<marker>Tomokiyo, Hurst, 2003</marker>
<rawString>Takashi Tomokiyo and Matthew Hurst. 2003. A Language Model Approach to Keyphrase Extraction. In Proceedings of the ACL 2003 work- shop on Multiword expressions, pages 33–40.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Learning algorithms for keyphrase extraction. Information Retrieval,</title>
<date>2000</date>
<pages>2--303</pages>
<contexts>
<context position="3601" citStr="Turney (2000)" startWordPosition="557" endWordPosition="558"> Mihalcea and Tarau (2004) propose an unsupervised approach that considers single tokens as vertices of a graph and co-occurrence relations between tokens as edges. Candidates are ranked using PageRank and adjacent keywords are merged into keyphrases in a post-processing step. The frequency of noun phrase heads is exploited by Barker and Cornacchia (2000), using noun phrases as candidates and ranking them based on term frequency and term length. Kea is a supervised system that uses all n-grams of a certain length, a Naive Bayes classifier and tf-idf and position features (Frank et al., 1999). Turney (2000) introduces Extractor, a supervised system that selects stems and stemmed n-grams as candidates and tunes its parameters (mainly related to frequency, position, length) with a genetic algorithm. Hulth (2004) experiments with three types of candidate terms (i.e., n-grams, noun phrase chunks and part-of-speech tagged words 146 Proceedings of the 5th International Workshop on Semantic Evaluation, ACL 2010, pages 146–149, Uppsala, Sweden, 15-16 July 2010. c�2010 Association for Computational Linguistics that match a set of patterns) and constructs classifiers by rule induction using features such </context>
</contexts>
<marker>Turney, 2000</marker>
<rawString>Peter D Turney. 2000. Learning algorithms for keyphrase extraction. Information Retrieval, 2:303– 336.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>