<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000832">
<title confidence="0.979116">
Automatic Keyword Extraction on Twitter
</title>
<author confidence="0.9964695">
Luis Marujo1,2,3, Wang Ling1,2,3, Isabel Trancoso2,3, Chris Dyer1, Alan W. Black1,
Anatole Gershman1, David Martins de Matos2,3, Jo˜ao P. Neto2,3, and Jaime Carbonell1
</author>
<affiliation confidence="0.984794">
1 Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA, USA
</affiliation>
<address confidence="0.604026">
2 Instituto Superior T´ecnico, Universidade de Lisboa, Lisbon, Portugal;
3 INESC-ID, Lisbon, Portugal
</address>
<email confidence="0.768222">
{luis.marujo,wang.ling,isabel.trancoso,david.matos,joao.neto}@inesc-id.pt
{cdyer,awb,anatoleg,jgc}@cs.cmu.edu,
</email>
<sectionHeader confidence="0.997353" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999952266666667">
In this paper, we build a corpus of tweets
from Twitter annotated with keywords us-
ing crowdsourcing methods. We iden-
tify key differences between this domain
and the work performed on other domains,
such as news, which makes existing ap-
proaches for automatic keyword extraction
not generalize well on Twitter datasets.
These datasets include the small amount of
content in each tweet, the frequent usage
of lexical variants and the high variance of
the cardinality of keywords present in each
tweet. We propose methods for addressing
these issues, which leads to solid improve-
ments on this dataset for this task.
</bodyText>
<sectionHeader confidence="0.999518" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999563609756098">
Keywords are frequently used in many occasions
as indicators of important information contained
in documents. These can be used by human read-
ers to search for their desired documents, but also
in many Natural Language Processing (NLP) ap-
plications, such as Text Summarization (Pal et al.,
2013), Text Categorization (¨Ozg¨ur et al., 2005),
Information Retrieval (Marujo et al., 2011a; Yang
and Nyberg, 2015) and Question Answering (Liu
and Nyberg, 2013). Many automatic frame-
works for extracting keywords have been pro-
posed (Riloff and Lehnert, 1994; Witten et al.,
1999; Turney, 2000; Medelyan et al., 2010; Lit-
vak and Last, 2008). These systems were built for
more formal domains, such as news data or Web
data, where the content is still produced in a con-
trolled fashion.
The emergence of social media environments,
such as Twitter and Facebook, has created a frame-
work for more casual data to be posted online.
These messages tend to be shorter than web pages,
especially on Twitter, where the content has to be
limited to 140 characters. The language is also
more casual with many messages containing or-
thographical errors, slang (e.g., cday), abbrevia-
tions among domain specific artifacts. In many ap-
plications, that existing datasets and models tend
to perform significantly worse on these domains,
namely in Part-of-Speech (POS) Tagging (Gim-
pel et al., 2011), Machine Translation (Jelh et al.,
2012; Ling et al., 2013), Named Entity Recogni-
tion (Ritter et al., 2011; Liu et al., 2013), Infor-
mation Retrieval (Efron, 2011) and Summariza-
tion (Duan et al., 2012; Chang et al., 2013).
As automatic keyword extraction plays an im-
portant role in many NLP tasks, building an accu-
rate extractor for the Twitter domain is a valuable
asset in many of these applications. In this pa-
per, we propose an automatic keyword extraction
system for this end and our contributions are the
following ones:
</bodyText>
<listItem confidence="0.96586275">
1. Provide a annotated keyword annotated
dataset consisting of 1827 tweets. These
tweets are obtained from (Gimpel et al.,
2011), and also contain POS annotations.
2. Improve a state-of-the-art keyword extraction
system (Marujo et al., 2011b; Marujo et al.,
2013) for this domain by learning additional
features in an unsupervised fashion.
</listItem>
<bodyText confidence="0.999797166666667">
The paper is organized as follows: Section 2
describes the related work; Section 3 presents the
annotation process; Section 4 details the architec-
ture of our keyword extraction system; Section 5
presents experiments using our models and we
conclude in Section 6.
</bodyText>
<page confidence="0.863016">
637
</page>
<bodyText confidence="0.277121666666667">
Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics
and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 637–643,
Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics
</bodyText>
<sectionHeader confidence="0.999579" genericHeader="related work">
2 Related Work
</sectionHeader>
<bodyText confidence="0.999834914285714">
Both supervised and unsupervised approaches
have been explored to perform key word extrac-
tion. Most of the automatic keyword/keyphrase
extraction methods proposed for social media
data, such as tweets, are unsupervised meth-
ods (Wu et al., 2010; Zhao et al., 2011;
Bellaachia and Al-Dhelaan, 2012). However,
the TF-IDF across different methods remains
a strong unsupervised baseline (Hasan and Ng,
2010). These methods include adaptations to
the PageRank method (Brin and Page, 1998) in-
cluding TextRank (Mihalcea and Tarau, 2004),
LexRank (Erkan and Radev, 2004), and Topic
PageRank (Liu et al., 2010).
Supervised keyword extraction methods for-
malize this problem as a binary classification prob-
lem of two steps (Riloff and Lehnert, 1994; Wit-
ten et al., 1999; Turney, 2000; Medelyan et al.,
2010; Wang and Li, 2011): candidate generation
and filtering of the phrases selected before. MAUI
toolkit-indexer (Medelyan et al., 2010), an im-
proved version of the KEA (Witten et al., 1999)
toolkit including new set of features and more ro-
bust classifier, remains the state-of-the-art system
in the news domain (Marujo et al., 2012).
To the best of our knowledge, only (Li et
al., 2010) used a supervised keyword extraction
framework (based on KEA) with additional fea-
tures, such as POS tags to performed keyword ex-
traction on Facebook posts. However, at that time
Facebook status updates or posts did not contained
either hashtags or user mentions. The size of Face-
book posts is frequently longer than tweets and has
less abbreviations since it is not limited by number
of character as in tweets.
</bodyText>
<sectionHeader confidence="0.998577" genericHeader="method">
3 Dataset
</sectionHeader>
<bodyText confidence="0.999776272727273">
The dataset 1 contains 1827 tweets, which are POS
tagged in (Gimpel et al., 2011). We used Ama-
zon Mechanical turk, an crowdsourcing market,
to recruit eleven annotators to identify keywords
in each tweet. Each annotator highlighted words
that he would consider a keyword. No specific
instructions about what words can be keywords
(e.g., “urls are not keywords”), as we wish to learn
what users find important in a tweet. It is also
acceptable for tweets to not contain keywords, as
some tweets simply do not contain important in-
</bodyText>
<footnote confidence="0.976909">
1The corpus is submitted as supplementary material.
</footnote>
<bodyText confidence="0.999742833333333">
formation (e.g., retweet). The annotations of each
annotator are combined by selecting keywords that
are chosen by at least three annotators. We also di-
vided the 1827 tweets into 1000 training samples,
327 development samples and 500 test samples,
using the splits as in (Gimpel et al., 2011).
</bodyText>
<sectionHeader confidence="0.990527" genericHeader="method">
4 Automatic Keyword Extraction
</sectionHeader>
<bodyText confidence="0.9999936875">
There are many methods that have been proposed
for keyword extraction. TF-IDF is one of the sim-
plest approaches for this end (Salton et al., 1975).
The k words with the highest TF-IDF value are
chosen as keywords, where k is optimized on the
development set. This works quite well in text
documents, such as news articles, as we wish to
find terms that occur frequently within that docu-
ment, but are not common in the other documents
in that domain. However, we found that this ap-
proach does not work well in Twitter as tweets
tend to be short and generally most terms occur
only once, including their keywords. This means
that the term frequency component is not very in-
formative as the TF-IDF measure will simply ben-
efit words that rarely occur, as these have a very
low inverse document frequency component.
A strong baseline for Automatic Key-
word Extraction is the MAUI toolkit-indexer
toolkit (Medelyan et al., 2010). The system
extracts a list of candidate keywords from a
document and trains a decision tree over a large
set of hand engineered features, also including
TF-IDF, in order to predict the correct keywords
on the training set. Once trained, the toolkit
extracts a list of keyword candidates from a tweet
and returns a ranked list of candidates. The top k
keywords are selected as answers. The parameter
k is maximized on the development set.
From this point, we present two extensions to
the MAUI system to address many challenges
found in this domain.
</bodyText>
<subsectionHeader confidence="0.998285">
4.1 Unsupervised Feature Extraction
</subsectionHeader>
<bodyText confidence="0.999965333333333">
The first problem is the existence of many lexical
variants in Twitter (e.g., “cats vs. catz”). While
variants tend to have the same meaning as their
standardized form, the proposed model does not
have this information and will not be able to gen-
eralize properly. For instance, if the term ”John” is
labelled as keyword in the training set, the model
would not be able to extract ”Jooohn” as keyword
as it is in a different word form. One way to ad-
</bodyText>
<page confidence="0.994087">
638
</page>
<bodyText confidence="0.999354636363636">
dress this would be using a normalization system
either built using hand engineered rules (Gouws
et al., 2011) or trained using labelled data (Han
and Baldwin, 2011; Chrupała, 2014). However,
these systems are generally limited as these need
supervision and cannot scale to new data or data
in other languages. Instead, we will used unsu-
pervised methods that leverage large amounts of
unannotated data. We used two popular methods
for this purpose: Brown Clustering and Continu-
ous Word Vectors.
</bodyText>
<subsectionHeader confidence="0.582446">
4.1.1 Brown Clustering
</subsectionHeader>
<bodyText confidence="0.999937789473684">
It has been shown in (Owoputi et al., 2013) that
Brown clusters are effective for clustering lexi-
cal variants. The algorithm attempts to find a
clusters distribution to maximize the likelihood
of each cluster predicting the next one, under the
HMM assumption. Thus, words ”yes”, ”yep” and
”yesss” are generally inserted into the same clus-
ter as these tend occur in similar contexts. It also
builds an hierarchical structure of clusters. For in-
stance, the clusters 11001 and 11010, share the
first three nodes in the hierarchically 110. Sharing
more tree nodes tends to translate into better sim-
ilarity between words within the clusters. Thus,
a word a 11001 cluster is simultaneously in clus-
ters 1, 11, 110, 1100 and 11001, and a feature
can be extracted for each cluster. In our experi-
ments, we used the dataset with 1,000 Brown clus-
ters made available by Owoputi et al. (Owoputi et
al., 2013)2.
</bodyText>
<subsectionHeader confidence="0.705982">
4.1.2 Continuous Word Vectors
</subsectionHeader>
<bodyText confidence="0.999861538461539">
Word representations learned from neural lan-
guage models are another way to learn more gen-
eralizable features for words (Collobert et al.,
2011; Huang et al., 2012). In these models, a
hidden layer is defined that maps words into a
continuous vector. The parameters of this hidden
layer are estimated by maximizing a goal func-
tion, such as the likelihood of each word predict-
ing surrounding words (Mikolov et al., 2013; Ling
et al., 2015). In our work, we used the structured
skip-ngram goal function proposed in (Ling et al.,
2015) and for each word we extracted its respec-
tive word vector as features.
</bodyText>
<subsectionHeader confidence="0.996518">
4.2 Keyword Length Prediction
</subsectionHeader>
<bodyText confidence="0.999859">
The second problem is the high variance in terms
of number of keywords per tweet. In larger doc-
</bodyText>
<footnote confidence="0.39949">
2http://www.ark.cs.cmu.edu/TweetNLP/clusters/50mpaths2
</footnote>
<bodyText confidence="0.999963151515151">
uments, such as a news article, contain approx-
imately 3-5 keywords, so extracting 3 keywords
per document is a reasonable option. However,
this would not work in Twitter, since the number
of keywords can be arbitrary small. In fact, many
tweets contain less than three words, in which case
the extractor would simply extract all words as
keywords, which would be incorrect. One alter-
native is to choose a ratio between the number of
words and number of keywords. That is, we define
the number of keywords in a tweet as the ratio be-
tween number of words in the tweet and k, which
is maximized on the development set. That is, if
we set k = 3, then we extract one keyword for
every three words.
Finally, a better approach is to learn a model to
predict the number of keywords using the training
set. Thus, we introduced a model that attempts
to predict the number of keywords in each tweet
based on a set of features. This is done using lin-
ear regression, which extracts a feature set from an
input tweet fl,..., f,,, and returns y, the expected
number of keywords in the tweet. As features we
selected the number of words in the input tweet
with the intuition that the number of keywords
tends to depend on the size of the tweet. Further-
more, (2) we count the number of function words
and non-function words in the tweet, emphasizing
the fact that some types of words tend to contribute
more to the number of keywords in the tweet. The
same is done for (3) hashtags and at mentions. Fi-
nally, (4) we also count the number of words in
each cluster using the trained Brown clusters.
</bodyText>
<sectionHeader confidence="0.999788" genericHeader="evaluation">
5 Experiments
</sectionHeader>
<bodyText confidence="0.99984825">
Experiments are performed on the annotated
dataset using the train, development and test splits
defined in Section 3. As baselines, we reported
results using a TF-IDF, the default MAUI toolkit,
and our own implementation of (Li et al., 2010)
framework. In all cases the IDF component was
computed over a collection of 52 million tweets.
Results are reported on rows 1 and 2 in Table 1,
respectively. The parameter k (column Nr. Key-
words) defines the number of keywords extracted
for each tweet and is maximized on the devel-
opment set. Evaluation is performed using F-
measure (column F1), where the precision (col-
umn P) is defined as the ratio of extracted key-
words that are correct and the number of ex-
tracted keywords, and the recall (column R) is de-
</bodyText>
<page confidence="0.992284">
639
</page>
<table confidence="0.996532444444445">
Dev Test
System Nr. Keywords P R F1 P R F1
1 TF-IDF 15 19.31 83.58 29.97 20.21 85.17 31.16
2 (Li et al., 2010) 4 48.81 50.05 49.42 51.78 50.92 51.35
3 MAUI (Default) 4 51.31 52.47 51.88 53.97 53.15 53.56
4 MAUI (Word Vectors) 4 52.70 53.50 53.10 55.80 54.45 55.12
5 MAUI (Brown) 4 68.08 74.11 70.97 71.95 75.01 73.45
6 MAUI (Brown+Word Vectors) 4 68.46 75.05 71.61 72.05 75.16 73.57
7 MAUI (Trained on News) 4 49.12 49.71 49.41 52.40 51.19 51.79
</table>
<tableCaption confidence="0.959196">
Table 1: F-measure, precision and recall results on the Twitter keyword dataset using different feature
sets.
</tableCaption>
<table confidence="0.85385725">
Dev Test
1 Fixed 4 68.46 75.05 71.61 72.05 75.16 73.57
2 Ratio N//3 65.70 82.69 73.22 69.48 83.8 75.97
3 Regression y + k 67.55 80.9 73.62 71.81 82.55 76.81
</table>
<tableCaption confidence="0.956859">
Table 2: F-measure, precision and recall results on the Twitter keyword dataset using different keyword
selection methods.
</tableCaption>
<figure confidence="0.872642">
Selection
Nr. Keywords
P
R
F1
P
R
F1
</figure>
<bodyText confidence="0.996643448275862">
fined as the ratio between the number of keywords
correctly extracted and the total number of key-
words in the dataset. We can see that the TF-
IDF, which tends to be a strong baseline for key-
word/keyphrase extraction (Hasan and Ng, 2010),
yields poor results. In fact, the best value for k is
15, which means that the system simply retrieves
all words as keywords in order to maximize re-
call. This is because most keywords only occur
once3, which makes the TF component not very
informative. On the other hand, the MAUI base-
line performs significantly better, this is because of
the usage of many hand engineered features using
lists of words and Wikipedia, rather than simply
relying on word counts.
Next, we introduce features learnt using an un-
supervised setup, namely, word vectors and brown
clusters in rows 3 and 4, respectively. These were
trained on the same 52 million tweets used for
computing the IDF component. Due to the large
size of the vocabulary, word types with less than
40 occurrences were removed. We observe that
while both features yield improvements over the
baseline model in row 2, the improvements ob-
tained using Brown clustering are far more sig-
nificant. Combining both features yields slightly
higher results, reported on row 5. Finally, we also
test training the system with all features on an out-
36856 out of 7045 keywords are singletons
of-domain keyword extraction corpus composed
by news documents (Marujo et al., 2012). Results
are reported on row 6, where we can observe a sig-
nificant domain mismatch problem between these
two domains as results drop significantly.
We explored different methods for choosing the
number of keywords to be extracted in Table 2.
The simplest way is choosing a fixed number of
keywords k and tune this value in the development
set. Next, we can also define the number of key-
words as the ratio Nk , where N is the number of
words in the tweet, and k is the parameter that we
wish to optimize. Finally, the number of keywords
can also be estimated using a linear regressor as
y = f1w1, ..., fnwn, where fi, ..., fn denote the
feature set and wi, ..., wn are the parameters of the
model trained on the training set. Once the model
is trained, the number of keywords selected for
each tweet is defined as y + k, where k is inserted
to adjust y to maximize F-measure on the devel-
opment set. Results using the best system using
Brown clusters and word vectors are described in
Table 2. We can observe that defining the number
of keywords as a fraction of the number of words
in the tweet, yields better results (row 2) yields
better overall results than fixing the number of ex-
tracted keywords (row 1). Finally, training a pre-
dictor for the number of keywords yields further
improvements (row 3) over a simple ratio of the
</bodyText>
<page confidence="0.967438">
640
</page>
<figure confidence="0.513186666666667">
number of input words. scratch. The Journal of Machine Learning Re-
search, 12.
6 Conclusions
</figure>
<bodyText confidence="0.999789833333333">
In this work, we built a corpus of tweets annotated
with keywords, which was used to built and evalu-
ate a system to automatically extract keywords on
Twitter. A baseline system is defined using exist-
ing methods applied to our dataset and improve-
ment significantly using unsupervised feature ex-
traction methods. Furthermore, an additional com-
ponent to predict the number of keywords in a
tweet is also built. In future work, we plan to
use the keyword extraction to perform numerous
NLP tasks on the Twitter domain, such as Docu-
ment Summarization.
</bodyText>
<sectionHeader confidence="0.996632" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.999982166666667">
This work was partially supported by Fundac¸˜ao
para a Ciˆencia e Tecnologia (FCT) through the
grants CMUP-EPB/TIC/0026/2013, SFRH/BD/
51157/2010, and the Carnegie Mellon Portugal
Program. The authors also wish to thank the
anonymous reviewers for their helpful comments.
</bodyText>
<sectionHeader confidence="0.993183" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.995626775">
Abdelghani Bellaachia and Mohammed Al-Dhelaan.
2012. Ne-rank: A novel graph-based keyphrase ex-
traction in twitter. In Proceedings of the The 2012
IEEE/WIC/ACM International Joint Conferences on
Web Intelligence and Intelligent Agent Technology -
Volume 01, WI-IAT ’12, pages 372–379, Washing-
ton, DC, USA. IEEE Computer Society.
Sergey Brin and Lawrence Page. 1998. The anatomy
of a large-scale hypertextual Web search engine.
Computer Networks and ISDN Systems, 30:107–
117.
Yi Chang, Xuanhui Wang, Qiaozhu Mei, and Yan Liu.
2013. Towards twitter context summarization with
user influence models. In Proceedings of the Sixth
ACM International Conference on Web Search and
Data Mining, WSDM ’13, pages 527–536, New
York, NY, USA. ACM.
Grzegorz Chrupała. 2014. Normalizing tweets with
edit scripts and recurrent neural embeddings. In
Proceedings of the 52nd Annual Meeting of the As-
sociation for Computational Linguistics (Volume 2:
Short Papers), pages 680–686, Baltimore, Mary-
land, June. Association for Computational Linguis-
tics.
Ronan Collobert, Jason Weston, L´eon Bottou, Michael
Karlen, Koray Kavukcuoglu, and Pavel Kuksa.
2011. Natural language processing (almost) from
Yajuan Duan, Zhumin Chen, Furu Wei, Ming Zhou,
and Heung-Yeung Shum. 2012. Twitter topic sum-
marization by ranking tweets using social influence
and content quality. In Proceedings of COLING
2012, pages 763–780. The COLING 2012 Organiz-
ing Committee.
Miles Efron. 2011. Information search and re-
trieval in microblogs. J. Am. Soc. Inf. Sci. Technol.,
62(6):996–1008, June.
G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank:
Graph-based Centrality as Salience in Text Summa-
rization. Journal of Artificial Intelligence Research,
22:457–479.
Kevin Gimpel, Nathan Schneider, Brendan O’Connor,
Dipanjan Das, Daniel Mills, Jacob Eisenstein,
Michael Heilman, Dani Yogatama, Jeffrey Flanigan,
and Noah A. Smith. 2011. Part-of-speech tagging
for twitter: annotation, features, and experiments. In
Proceedings of the 49th Annual Meeting of the Asso-
ciation for Computational Linguistics: Human Lan-
guage Technologies: short papers - Volume 2, HLT
’11, Stroudsburg, PA, USA. Association for Compu-
tational Linguistics.
Stephan Gouws, Dirk Hovy, and Donald Metzler.
2011. Unsupervised mining of lexical variants from
noisy text. In Proceedings of the First Workshop
on Unsupervised Learning in NLP, EMNLP ’11,
pages 82–90, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Bo Han and Timothy Baldwin. 2011. Lexical normal-
isation of short text messages: Makn sens a #twit-
ter. In Proceedings of the 49th Annual Meeting of
the Association for Computational Linguistics: Hu-
man Language Technologies - Volume 1, HLT ’11,
pages 368–378, Stroudsburg, PA, USA. Association
for Computational Linguistics.
Kazi Saidul Hasan and Vincent Ng. 2010. V.: Conun-
drums in unsupervised keyphrase extraction: Mak-
ing sense of the state-of-the-art. In In: COLING,
pages 365–373.
Eric H Huang, Richard Socher, Christopher D Man-
ning, and Andrew Y Ng. 2012. Improving word
representations via global context and multiple word
prototypes. In Proceedings of the 50th Annual Meet-
ing of the Association for Computational Linguis-
tics: Long Papers-Volume 1, pages 873–882. Asso-
ciation for Computational Linguistics.
Laura Jelh, Felix Hiebel, and Stefan Riezler. 2012.
Twitter translation using translation-based cross-
lingual retrieval. In Proceedings of the Sev-
enth Workshop on Statistical Machine Translation,
Montr´eal, Canada, June. Association for Computa-
tional Linguistics.
</reference>
<page confidence="0.991771">
641
</page>
<reference confidence="0.994350756756756">
Zhenhui Li, Ding Zhou, Yun-Fang Juan, and Jiawei
Han. 2010. Keyword extraction for social snippets.
In Proceedings of the 19th International Conference
on World Wide Web, WWW ’10, pages 1143–1144,
New York, NY, USA. ACM.
Wang Ling, Guang Xiang, Chris Dyer, Alan Black, and
Isabel Trancoso. 2013. Microblogs as parallel cor-
pora. In Proceedings of the 51st Annual Meeting
on Association for Computational Linguistics, ACL
’13. Association for Computational Linguistics.
Wang Ling, Chris Dyer, Alan Black, and Isabel
Trancoso. 2015. Two/too simple adaptations of
word2vec for syntax problems. In Proceedings of
the 2015 Conference of the North American Chap-
ter of the Association for Computational Linguis-
tics: Human Language Technologies. Association
for Computational Linguistics.
Marina Litvak and Mark Last. 2008. Graph-based
keyword extraction for single-document summariza-
tion. In Proceedings of the Workshop on Multi-
source Multilingual Information Extraction and
Summarization, MMIES ’08, pages 17–24, Strouds-
burg, PA, USA. Association for Computational Lin-
guistics.
Rui Liu and Eric Nyberg. 2013. A phased ranking
model for question answering. In Proceedings of the
22Nd ACM International Conference on Informa-
tion &amp; Knowledge Management, CIKM ’13, pages
79–88, New York, NY, USA. ACM.
Zhiyuan Liu, Wenyi Huang, Yabin Zheng, and
Maosong Sun. 2010. Automatic keyphrase extrac-
tion via topic decomposition. In Proceedings of the
2010 Conference on Empirical Methods in Natural
Language Processing, EMNLP ’10, pages 366–376,
Stroudsburg, PA, USA. Association for Computa-
tional Linguistics.
Xiaohua Liu, Furu Wei, Shaodian Zhang, and Ming
Zhou. 2013. Named entity recognition for tweets.
ACM Transactions on Intelligent Systems and Tech-
nology (TIST), 4(1):3.
Lu´ıs Marujo, Miguel Bugalho, Jo˜ao P. Neto, Anatole
Gershman, and Jaime Carbonell. 2011a. Hourly
traffic prediction of news stories. In Proceedings of
the 3rd International Workshop on Context- Aware
Recommender Systems held as part of the 5th ACM
RecSys Conference, October.
Lu´ıs Marujo, M´arcio Viveiros, and Jo˜ao P. Neto.
2011b. Keyphrase Cloud Generation of Broadcast
News. In Proceedings of the 12th Annual Con-
ference of the International Speech Communication
Association (INTERSPEECH 2011). ISCA, Septem-
ber.
Lu´ıs Marujo, Anatole Gershman, Jaime Carbonell,
Robert Frederking, and Jo˜ao P. Neto. 2012. Super-
vised topical key phrase extraction of news stories
using crowdsourcing, light filtering and co-reference
normalization. In Proceedings of the 8th Interna-
tional Conference on Language Resources and Eval-
uation (LREC 2012).
Lu´ıs Marujo, Ricardo Ribeiro, David Martins
de Matos, Jo˜ao Paulo Neto, Anatole Gershman, and
Jaime G. Carbonell. 2013. Key phrase extraction
of lightly filtered broadcast news. In Proceedings of
the 15th International Conference on Text, Speech
and Dialogue (TSD).
Olena Medelyan, Vye Perrone, and Ian H. Witten.
2010. Subject metadata support powered by maui.
In Jane Hunter, Carl Lagoze, C. Lee Giles, and
Yuan-Fang Li, editors, JCDL, pages 407–408. ACM.
Rada Mihalcea and Paul Tarau. 2004. Textrank:
Bringing order into texts. In Dekang Lin and Dekai
Wu, editors, Proceedings of EMNLP 2004, pages
404–411, Barcelona, Spain, July. Association for
Computational Linguistics.
Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Cor-
rado, and Jeff Dean. 2013. Distributed representa-
tions of words and phrases and their compositional-
ity. In Advances in Neural Information Processing
Systems, pages 3111–3119.
Olutobi Owoputi, Brendan O’Connor, Chris Dyer,
Kevin Gimpel, Nathan Schneider, and Noah A
Smith. 2013. Improved part-of-speech tagging for
online conversational text with word clusters. In
HLT-NAACL, pages 380–390.
Arzucan ¨Ozg¨ur, Levent ¨Ozg¨ur, and Tunga G¨ung¨or.
2005. Text categorization with class-based and
corpus-based keyword selection. In Proceedings
of the 20th International Conference on Computer
and Information Sciences, ISCIS’05, pages 606–
615, Berlin, Heidelberg. Springer-Verlag.
Alok Ranjan Pal, Projjwal Kumar Maiti, and Diganta
Saha. 2013. An approach to automatic text summa-
rization using simplified lesk algorithm and word-
net. International Journal of Control Theory &amp;
Computer Modeling, 3.
Ellen Riloff and Wendy Lehnert. 1994. Information
extraction as a basis for high-precision text classifi-
cation. ACM Transactions on Information Systems
(TOIS), 12(3):296–333, July.
Alan Ritter, Sam Clark, Oren Etzioni, et al. 2011.
Named entity recognition in tweets: an experimental
study. In Proceedings of the Conference on Empiri-
cal Methods in Natural Language Processing, pages
1524–1534. Association for Computational Linguis-
tics.
G. Salton, A. Wong, and C. S. Yang. 1975. A Vector
Space Model for Automatic Indexing. Communica-
tions of the ACM, 18(11):613–620.
Peter D. Turney. 2000. Learning algorithms
for keyphrase extraction. Information Retrieval,
2(4):303–336.
</reference>
<page confidence="0.977099">
642
</page>
<reference confidence="0.999148515151515">
Chen Wang and Sujian Li. 2011. Corankbayes:
Bayesian learning to rank under the co-training
framework and its application in keyphrase extrac-
tion. In Proceedings of the 20th ACM International
Conference on Information and Knowledge Man-
agement, CIKM ’11, pages 2241–2244, New York,
NY, USA. ACM.
Ian H. Witten, Gordon W. Paynter, Eibe Frank, Carl
Gutwin, and Craig G. Nevill-Manning. 1999. Kea:
practical automatic keyphrase extraction. In Pro-
ceedings of the 4th ACM conference on Digital li-
braries, DL ’99, pages 254–255, New York, NY,
USA. ACM.
Wei Wu, Bin Zhang, and Mari Ostendorf. 2010. Au-
tomatic generation of personalized annotation tags
for twitter users. In Human Language Technologies:
The 2010 Annual Conference of the North American
Chapter of the Association for Computational Lin-
guistics, HLT ’10, pages 689–692, Stroudsburg, PA,
USA. Association for Computational Linguistics.
Zi Yang and Eric Nyberg. 2015. Leveraging proce-
dural knowledge base for task-oriented search. In
Proceedings of the 38th international ACM SIGIR
conference on Research &amp; development in informa-
tion retrieval. ACM.
Wayne Xin Zhao, Jing Jiang, Jing He, Yang Song,
Palakorn Achananuparp, Ee-Peng Lim, and Xiaom-
ing Li. 2011. Topical keyphrase extraction from
twitter. In Proceedings of the 49th Annual Meet-
ing of the Association for Computational Linguis-
tics: Human Language Technologies - Volume 1,
HLT ’11, pages 379–388, Stroudsburg, PA, USA.
Association for Computational Linguistics.
</reference>
<page confidence="0.999167">
643
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.349870">
<title confidence="0.999283">Automatic Keyword Extraction on Twitter</title>
<author confidence="0.845945">Wang Isabel Chris Alan W David Martins de_P</author>
<author confidence="0.845945">Jaime</author>
<affiliation confidence="0.802008">1Language Technologies Institute, Carnegie Mellon University, Pittsburgh, PA,</affiliation>
<address confidence="0.795095">2Instituto Superior T´ecnico, Universidade de Lisboa, Lisbon, 3INESC-ID, Lisbon,</address>
<abstract confidence="0.9976744375">In this paper, we build a corpus of tweets from Twitter annotated with keywords using crowdsourcing methods. We identify key differences between this domain and the work performed on other domains, such as news, which makes existing approaches for automatic keyword extraction not generalize well on Twitter datasets. These datasets include the small amount of content in each tweet, the frequent usage of lexical variants and the high variance of the cardinality of keywords present in each tweet. We propose methods for addressing these issues, which leads to solid improvements on this dataset for this task.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Abdelghani Bellaachia</author>
<author>Mohammed Al-Dhelaan</author>
</authors>
<title>Ne-rank: A novel graph-based keyphrase extraction in twitter.</title>
<date>2012</date>
<booktitle>In Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology -Volume 01, WI-IAT ’12,</booktitle>
<pages>372--379</pages>
<publisher>IEEE Computer Society.</publisher>
<location>Washington, DC, USA.</location>
<contexts>
<context position="4227" citStr="Bellaachia and Al-Dhelaan, 2012" startWordPosition="641" endWordPosition="644">our models and we conclude in Section 6. 637 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 637–643, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 2 Related Work Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-</context>
</contexts>
<marker>Bellaachia, Al-Dhelaan, 2012</marker>
<rawString>Abdelghani Bellaachia and Mohammed Al-Dhelaan. 2012. Ne-rank: A novel graph-based keyphrase extraction in twitter. In Proceedings of the The 2012 IEEE/WIC/ACM International Joint Conferences on Web Intelligence and Intelligent Agent Technology -Volume 01, WI-IAT ’12, pages 372–379, Washington, DC, USA. IEEE Computer Society.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sergey Brin</author>
<author>Lawrence Page</author>
</authors>
<title>The anatomy of a large-scale hypertextual Web search engine.</title>
<date>1998</date>
<journal>Computer Networks and ISDN Systems,</journal>
<volume>30</volume>
<pages>117</pages>
<contexts>
<context position="4413" citStr="Brin and Page, 1998" startWordPosition="668" endWordPosition="671">ocessing (Short Papers), pages 637–643, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 2 Related Work Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art syste</context>
</contexts>
<marker>Brin, Page, 1998</marker>
<rawString>Sergey Brin and Lawrence Page. 1998. The anatomy of a large-scale hypertextual Web search engine. Computer Networks and ISDN Systems, 30:107– 117.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yi Chang</author>
<author>Xuanhui Wang</author>
<author>Qiaozhu Mei</author>
<author>Yan Liu</author>
</authors>
<title>Towards twitter context summarization with user influence models.</title>
<date>2013</date>
<booktitle>In Proceedings of the Sixth ACM International Conference on Web Search and Data Mining, WSDM ’13,</booktitle>
<pages>527--536</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="2727" citStr="Chang et al., 2013" startWordPosition="411" endWordPosition="414">ecially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations. 2. Improve a state-of-the-art keyword extraction system (Marujo et al., 2011b; Marujo et al., 2013) for this domain by learning ad</context>
</contexts>
<marker>Chang, Wang, Mei, Liu, 2013</marker>
<rawString>Yi Chang, Xuanhui Wang, Qiaozhu Mei, and Yan Liu. 2013. Towards twitter context summarization with user influence models. In Proceedings of the Sixth ACM International Conference on Web Search and Data Mining, WSDM ’13, pages 527–536, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Grzegorz Chrupała</author>
</authors>
<title>Normalizing tweets with edit scripts and recurrent neural embeddings.</title>
<date>2014</date>
<booktitle>In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers),</booktitle>
<pages>680--686</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Baltimore, Maryland,</location>
<contexts>
<context position="8577" citStr="Chrupała, 2014" startWordPosition="1375" endWordPosition="1376">is the existence of many lexical variants in Twitter (e.g., “cats vs. catz”). While variants tend to have the same meaning as their standardized form, the proposed model does not have this information and will not be able to generalize properly. For instance, if the term ”John” is labelled as keyword in the training set, the model would not be able to extract ”Jooohn” as keyword as it is in a different word form. One way to ad638 dress this would be using a normalization system either built using hand engineered rules (Gouws et al., 2011) or trained using labelled data (Han and Baldwin, 2011; Chrupała, 2014). However, these systems are generally limited as these need supervision and cannot scale to new data or data in other languages. Instead, we will used unsupervised methods that leverage large amounts of unannotated data. We used two popular methods for this purpose: Brown Clustering and Continuous Word Vectors. 4.1.1 Brown Clustering It has been shown in (Owoputi et al., 2013) that Brown clusters are effective for clustering lexical variants. The algorithm attempts to find a clusters distribution to maximize the likelihood of each cluster predicting the next one, under the HMM assumption. Thu</context>
</contexts>
<marker>Chrupała, 2014</marker>
<rawString>Grzegorz Chrupała. 2014. Normalizing tweets with edit scripts and recurrent neural embeddings. In Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers), pages 680–686, Baltimore, Maryland, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan Collobert</author>
<author>Jason Weston</author>
<author>L´eon Bottou</author>
<author>Michael Karlen</author>
<author>Koray Kavukcuoglu</author>
<author>Pavel Kuksa</author>
</authors>
<title>Natural language processing (almost) from</title>
<date>2011</date>
<contexts>
<context position="9984" citStr="Collobert et al., 2011" startWordPosition="1606" endWordPosition="1609">e, the clusters 11001 and 11010, share the first three nodes in the hierarchically 110. Sharing more tree nodes tends to translate into better similarity between words within the clusters. Thus, a word a 11001 cluster is simultaneously in clusters 1, 11, 110, 1100 and 11001, and a feature can be extracted for each cluster. In our experiments, we used the dataset with 1,000 Brown clusters made available by Owoputi et al. (Owoputi et al., 2013)2. 4.1.2 Continuous Word Vectors Word representations learned from neural language models are another way to learn more generalizable features for words (Collobert et al., 2011; Huang et al., 2012). In these models, a hidden layer is defined that maps words into a continuous vector. The parameters of this hidden layer are estimated by maximizing a goal function, such as the likelihood of each word predicting surrounding words (Mikolov et al., 2013; Ling et al., 2015). In our work, we used the structured skip-ngram goal function proposed in (Ling et al., 2015) and for each word we extracted its respective word vector as features. 4.2 Keyword Length Prediction The second problem is the high variance in terms of number of keywords per tweet. In larger doc2http://www.ar</context>
</contexts>
<marker>Collobert, Weston, Bottou, Karlen, Kavukcuoglu, Kuksa, 2011</marker>
<rawString>Ronan Collobert, Jason Weston, L´eon Bottou, Michael Karlen, Koray Kavukcuoglu, and Pavel Kuksa. 2011. Natural language processing (almost) from</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yajuan Duan</author>
<author>Zhumin Chen</author>
<author>Furu Wei</author>
<author>Ming Zhou</author>
<author>Heung-Yeung Shum</author>
</authors>
<title>Twitter topic summarization by ranking tweets using social influence and content quality.</title>
<date>2012</date>
<booktitle>In Proceedings of COLING 2012,</booktitle>
<pages>763--780</pages>
<contexts>
<context position="2706" citStr="Duan et al., 2012" startWordPosition="407" endWordPosition="410">than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations. 2. Improve a state-of-the-art keyword extraction system (Marujo et al., 2011b; Marujo et al., 2013) for this </context>
</contexts>
<marker>Duan, Chen, Wei, Zhou, Shum, 2012</marker>
<rawString>Yajuan Duan, Zhumin Chen, Furu Wei, Ming Zhou, and Heung-Yeung Shum. 2012. Twitter topic summarization by ranking tweets using social influence and content quality. In Proceedings of COLING 2012, pages 763–780. The COLING 2012 Organizing Committee.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miles Efron</author>
</authors>
<title>Information search and retrieval in microblogs.</title>
<date>2011</date>
<journal>J. Am. Soc. Inf. Sci. Technol.,</journal>
<volume>62</volume>
<issue>6</issue>
<contexts>
<context position="2669" citStr="Efron, 2011" startWordPosition="402" endWordPosition="403">ese messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations. 2. Improve a state-of-the-art keyword extraction system (Marujo et al., </context>
</contexts>
<marker>Efron, 2011</marker>
<rawString>Miles Efron. 2011. Information search and retrieval in microblogs. J. Am. Soc. Inf. Sci. Technol., 62(6):996–1008, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G¨unes¸ Erkan</author>
<author>Dragomir R Radev</author>
</authors>
<title>LexRank: Graph-based Centrality as Salience in Text Summarization.</title>
<date>2004</date>
<journal>Journal of Artificial Intelligence Research,</journal>
<pages>22--457</pages>
<contexts>
<context position="4492" citStr="Erkan and Radev, 2004" startWordPosition="680" endWordPosition="683">015 Association for Computational Linguistics 2 Related Work Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only </context>
</contexts>
<marker>Erkan, Radev, 2004</marker>
<rawString>G¨unes¸ Erkan and Dragomir R. Radev. 2004. LexRank: Graph-based Centrality as Salience in Text Summarization. Journal of Artificial Intelligence Research, 22:457–479.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Brendan O’Connor</author>
<author>Dipanjan Das</author>
<author>Daniel Mills</author>
<author>Jacob Eisenstein</author>
<author>Michael Heilman</author>
<author>Dani Yogatama</author>
<author>Jeffrey Flanigan</author>
<author>Noah A Smith</author>
</authors>
<title>Part-of-speech tagging for twitter: annotation, features, and experiments.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<marker>Gimpel, Schneider, O’Connor, Das, Mills, Eisenstein, Heilman, Yogatama, Flanigan, Smith, 2011</marker>
<rawString>Kevin Gimpel, Nathan Schneider, Brendan O’Connor, Dipanjan Das, Daniel Mills, Jacob Eisenstein, Michael Heilman, Dani Yogatama, Jeffrey Flanigan, and Noah A. Smith. 2011. Part-of-speech tagging for twitter: annotation, features, and experiments. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies: short papers - Volume 2, HLT ’11, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Gouws</author>
<author>Dirk Hovy</author>
<author>Donald Metzler</author>
</authors>
<title>Unsupervised mining of lexical variants from noisy text.</title>
<date>2011</date>
<booktitle>In Proceedings of the First Workshop on Unsupervised Learning in NLP, EMNLP ’11,</booktitle>
<pages>82--90</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8506" citStr="Gouws et al., 2011" startWordPosition="1362" endWordPosition="1365">ound in this domain. 4.1 Unsupervised Feature Extraction The first problem is the existence of many lexical variants in Twitter (e.g., “cats vs. catz”). While variants tend to have the same meaning as their standardized form, the proposed model does not have this information and will not be able to generalize properly. For instance, if the term ”John” is labelled as keyword in the training set, the model would not be able to extract ”Jooohn” as keyword as it is in a different word form. One way to ad638 dress this would be using a normalization system either built using hand engineered rules (Gouws et al., 2011) or trained using labelled data (Han and Baldwin, 2011; Chrupała, 2014). However, these systems are generally limited as these need supervision and cannot scale to new data or data in other languages. Instead, we will used unsupervised methods that leverage large amounts of unannotated data. We used two popular methods for this purpose: Brown Clustering and Continuous Word Vectors. 4.1.1 Brown Clustering It has been shown in (Owoputi et al., 2013) that Brown clusters are effective for clustering lexical variants. The algorithm attempts to find a clusters distribution to maximize the likelihood</context>
</contexts>
<marker>Gouws, Hovy, Metzler, 2011</marker>
<rawString>Stephan Gouws, Dirk Hovy, and Donald Metzler. 2011. Unsupervised mining of lexical variants from noisy text. In Proceedings of the First Workshop on Unsupervised Learning in NLP, EMNLP ’11, pages 82–90, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bo Han</author>
<author>Timothy Baldwin</author>
</authors>
<title>Lexical normalisation of short text messages: Makn sens a #twitter.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>368--378</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="8560" citStr="Han and Baldwin, 2011" startWordPosition="1371" endWordPosition="1374">tion The first problem is the existence of many lexical variants in Twitter (e.g., “cats vs. catz”). While variants tend to have the same meaning as their standardized form, the proposed model does not have this information and will not be able to generalize properly. For instance, if the term ”John” is labelled as keyword in the training set, the model would not be able to extract ”Jooohn” as keyword as it is in a different word form. One way to ad638 dress this would be using a normalization system either built using hand engineered rules (Gouws et al., 2011) or trained using labelled data (Han and Baldwin, 2011; Chrupała, 2014). However, these systems are generally limited as these need supervision and cannot scale to new data or data in other languages. Instead, we will used unsupervised methods that leverage large amounts of unannotated data. We used two popular methods for this purpose: Brown Clustering and Continuous Word Vectors. 4.1.1 Brown Clustering It has been shown in (Owoputi et al., 2013) that Brown clusters are effective for clustering lexical variants. The algorithm attempts to find a clusters distribution to maximize the likelihood of each cluster predicting the next one, under the HM</context>
</contexts>
<marker>Han, Baldwin, 2011</marker>
<rawString>Bo Han and Timothy Baldwin. 2011. Lexical normalisation of short text messages: Makn sens a #twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 368–378, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kazi Saidul Hasan</author>
<author>Vincent Ng</author>
</authors>
<title>V.: Conundrums in unsupervised keyphrase extraction: Making sense of the state-of-the-art. In In:</title>
<date>2010</date>
<booktitle>COLING,</booktitle>
<pages>365--373</pages>
<contexts>
<context position="4333" citStr="Hasan and Ng, 2010" startWordPosition="656" endWordPosition="659">l Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 637–643, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 2 Related Work Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including ne</context>
<context position="14080" citStr="Hasan and Ng, 2010" startWordPosition="2336" endWordPosition="2339">sults on the Twitter keyword dataset using different feature sets. Dev Test 1 Fixed 4 68.46 75.05 71.61 72.05 75.16 73.57 2 Ratio N//3 65.70 82.69 73.22 69.48 83.8 75.97 3 Regression y + k 67.55 80.9 73.62 71.81 82.55 76.81 Table 2: F-measure, precision and recall results on the Twitter keyword dataset using different keyword selection methods. Selection Nr. Keywords P R F1 P R F1 fined as the ratio between the number of keywords correctly extracted and the total number of keywords in the dataset. We can see that the TFIDF, which tends to be a strong baseline for keyword/keyphrase extraction (Hasan and Ng, 2010), yields poor results. In fact, the best value for k is 15, which means that the system simply retrieves all words as keywords in order to maximize recall. This is because most keywords only occur once3, which makes the TF component not very informative. On the other hand, the MAUI baseline performs significantly better, this is because of the usage of many hand engineered features using lists of words and Wikipedia, rather than simply relying on word counts. Next, we introduce features learnt using an unsupervised setup, namely, word vectors and brown clusters in rows 3 and 4, respectively. T</context>
</contexts>
<marker>Hasan, Ng, 2010</marker>
<rawString>Kazi Saidul Hasan and Vincent Ng. 2010. V.: Conundrums in unsupervised keyphrase extraction: Making sense of the state-of-the-art. In In: COLING, pages 365–373.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Eric H Huang</author>
<author>Richard Socher</author>
<author>Christopher D Manning</author>
<author>Andrew Y Ng</author>
</authors>
<title>Improving word representations via global context and multiple word prototypes.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,</booktitle>
<pages>873--882</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="10005" citStr="Huang et al., 2012" startWordPosition="1610" endWordPosition="1613">d 11010, share the first three nodes in the hierarchically 110. Sharing more tree nodes tends to translate into better similarity between words within the clusters. Thus, a word a 11001 cluster is simultaneously in clusters 1, 11, 110, 1100 and 11001, and a feature can be extracted for each cluster. In our experiments, we used the dataset with 1,000 Brown clusters made available by Owoputi et al. (Owoputi et al., 2013)2. 4.1.2 Continuous Word Vectors Word representations learned from neural language models are another way to learn more generalizable features for words (Collobert et al., 2011; Huang et al., 2012). In these models, a hidden layer is defined that maps words into a continuous vector. The parameters of this hidden layer are estimated by maximizing a goal function, such as the likelihood of each word predicting surrounding words (Mikolov et al., 2013; Ling et al., 2015). In our work, we used the structured skip-ngram goal function proposed in (Ling et al., 2015) and for each word we extracted its respective word vector as features. 4.2 Keyword Length Prediction The second problem is the high variance in terms of number of keywords per tweet. In larger doc2http://www.ark.cs.cmu.edu/TweetNLP</context>
</contexts>
<marker>Huang, Socher, Manning, Ng, 2012</marker>
<rawString>Eric H Huang, Richard Socher, Christopher D Manning, and Andrew Y Ng. 2012. Improving word representations via global context and multiple word prototypes. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1, pages 873–882. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Laura Jelh</author>
<author>Felix Hiebel</author>
<author>Stefan Riezler</author>
</authors>
<title>Twitter translation using translation-based crosslingual retrieval.</title>
<date>2012</date>
<booktitle>In Proceedings of the Seventh Workshop on Statistical Machine Translation,</booktitle>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Montr´eal, Canada,</location>
<contexts>
<context position="2546" citStr="Jelh et al., 2012" startWordPosition="379" endWordPosition="382">of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpe</context>
</contexts>
<marker>Jelh, Hiebel, Riezler, 2012</marker>
<rawString>Laura Jelh, Felix Hiebel, and Stefan Riezler. 2012. Twitter translation using translation-based crosslingual retrieval. In Proceedings of the Seventh Workshop on Statistical Machine Translation, Montr´eal, Canada, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhenhui Li</author>
<author>Ding Zhou</author>
<author>Yun-Fang Juan</author>
<author>Jiawei Han</author>
</authors>
<title>Keyword extraction for social snippets.</title>
<date>2010</date>
<booktitle>In Proceedings of the 19th International Conference on World Wide Web, WWW ’10,</booktitle>
<pages>1143--1144</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="5109" citStr="Li et al., 2010" startWordPosition="783" endWordPosition="786"> and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised keyword extraction framework (based on KEA) with additional features, such as POS tags to performed keyword extraction on Facebook posts. However, at that time Facebook status updates or posts did not contained either hashtags or user mentions. The size of Facebook posts is frequently longer than tweets and has less abbreviations since it is not limited by number of character as in tweets. 3 Dataset The dataset 1 contains 1827 tweets, which are POS tagged in (Gimpel et al., 2011). We used Amazon Mechanical turk, an crowdsourcing market, to recruit eleven annotators to identi</context>
<context position="12459" citStr="Li et al., 2010" startWordPosition="2041" endWordPosition="2044">the tweet. Furthermore, (2) we count the number of function words and non-function words in the tweet, emphasizing the fact that some types of words tend to contribute more to the number of keywords in the tweet. The same is done for (3) hashtags and at mentions. Finally, (4) we also count the number of words in each cluster using the trained Brown clusters. 5 Experiments Experiments are performed on the annotated dataset using the train, development and test splits defined in Section 3. As baselines, we reported results using a TF-IDF, the default MAUI toolkit, and our own implementation of (Li et al., 2010) framework. In all cases the IDF component was computed over a collection of 52 million tweets. Results are reported on rows 1 and 2 in Table 1, respectively. The parameter k (column Nr. Keywords) defines the number of keywords extracted for each tweet and is maximized on the development set. Evaluation is performed using Fmeasure (column F1), where the precision (column P) is defined as the ratio of extracted keywords that are correct and the number of extracted keywords, and the recall (column R) is de639 Dev Test System Nr. Keywords P R F1 P R F1 1 TF-IDF 15 19.31 83.58 29.97 20.21 85.17 31</context>
</contexts>
<marker>Li, Zhou, Juan, Han, 2010</marker>
<rawString>Zhenhui Li, Ding Zhou, Yun-Fang Juan, and Jiawei Han. 2010. Keyword extraction for social snippets. In Proceedings of the 19th International Conference on World Wide Web, WWW ’10, pages 1143–1144, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wang Ling</author>
<author>Guang Xiang</author>
<author>Chris Dyer</author>
<author>Alan Black</author>
<author>Isabel Trancoso</author>
</authors>
<title>Microblogs as parallel corpora.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting on Association for Computational Linguistics, ACL ’13. Association for Computational Linguistics.</booktitle>
<contexts>
<context position="2566" citStr="Ling et al., 2013" startWordPosition="383" endWordPosition="386">ironments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and</context>
</contexts>
<marker>Ling, Xiang, Dyer, Black, Trancoso, 2013</marker>
<rawString>Wang Ling, Guang Xiang, Chris Dyer, Alan Black, and Isabel Trancoso. 2013. Microblogs as parallel corpora. In Proceedings of the 51st Annual Meeting on Association for Computational Linguistics, ACL ’13. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wang Ling</author>
<author>Chris Dyer</author>
<author>Alan Black</author>
<author>Isabel Trancoso</author>
</authors>
<title>Two/too simple adaptations of word2vec for syntax problems.</title>
<date>2015</date>
<booktitle>In Proceedings of the 2015 Conference of the North American Chapter of the Association</booktitle>
<contexts>
<context position="10279" citStr="Ling et al., 2015" startWordPosition="1658" endWordPosition="1661">tracted for each cluster. In our experiments, we used the dataset with 1,000 Brown clusters made available by Owoputi et al. (Owoputi et al., 2013)2. 4.1.2 Continuous Word Vectors Word representations learned from neural language models are another way to learn more generalizable features for words (Collobert et al., 2011; Huang et al., 2012). In these models, a hidden layer is defined that maps words into a continuous vector. The parameters of this hidden layer are estimated by maximizing a goal function, such as the likelihood of each word predicting surrounding words (Mikolov et al., 2013; Ling et al., 2015). In our work, we used the structured skip-ngram goal function proposed in (Ling et al., 2015) and for each word we extracted its respective word vector as features. 4.2 Keyword Length Prediction The second problem is the high variance in terms of number of keywords per tweet. In larger doc2http://www.ark.cs.cmu.edu/TweetNLP/clusters/50mpaths2 uments, such as a news article, contain approximately 3-5 keywords, so extracting 3 keywords per document is a reasonable option. However, this would not work in Twitter, since the number of keywords can be arbitrary small. In fact, many tweets contain l</context>
</contexts>
<marker>Ling, Dyer, Black, Trancoso, 2015</marker>
<rawString>Wang Ling, Chris Dyer, Alan Black, and Isabel Trancoso. 2015. Two/too simple adaptations of word2vec for syntax problems. In Proceedings of the 2015 Conference of the North American Chapter of the Association for Computational Linguistics: Human Language Technologies. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marina Litvak</author>
<author>Mark Last</author>
</authors>
<title>Graph-based keyword extraction for single-document summarization.</title>
<date>2008</date>
<booktitle>In Proceedings of the Workshop on Multisource Multilingual Information Extraction and Summarization, MMIES ’08,</booktitle>
<pages>17--24</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="1771" citStr="Litvak and Last, 2008" startWordPosition="251" endWordPosition="255">are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing</context>
</contexts>
<marker>Litvak, Last, 2008</marker>
<rawString>Marina Litvak and Mark Last. 2008. Graph-based keyword extraction for single-document summarization. In Proceedings of the Workshop on Multisource Multilingual Information Extraction and Summarization, MMIES ’08, pages 17–24, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rui Liu</author>
<author>Eric Nyberg</author>
</authors>
<title>A phased ranking model for question answering.</title>
<date>2013</date>
<booktitle>In Proceedings of the 22Nd ACM International Conference on Information &amp; Knowledge Management, CIKM ’13,</booktitle>
<pages>79--88</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1593" citStr="Liu and Nyberg, 2013" startWordPosition="222" endWordPosition="225">lity of keywords present in each tweet. We propose methods for addressing these issues, which leads to solid improvements on this dataset for this task. 1 Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The langua</context>
</contexts>
<marker>Liu, Nyberg, 2013</marker>
<rawString>Rui Liu and Eric Nyberg. 2013. A phased ranking model for question answering. In Proceedings of the 22Nd ACM International Conference on Information &amp; Knowledge Management, CIKM ’13, pages 79–88, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhiyuan Liu</author>
<author>Wenyi Huang</author>
<author>Yabin Zheng</author>
<author>Maosong Sun</author>
</authors>
<title>Automatic keyphrase extraction via topic decomposition.</title>
<date>2010</date>
<booktitle>In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10,</booktitle>
<pages>366--376</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4531" citStr="Liu et al., 2010" startWordPosition="687" endWordPosition="690">s 2 Related Work Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised key</context>
</contexts>
<marker>Liu, Huang, Zheng, Sun, 2010</marker>
<rawString>Zhiyuan Liu, Wenyi Huang, Yabin Zheng, and Maosong Sun. 2010. Automatic keyphrase extraction via topic decomposition. In Proceedings of the 2010 Conference on Empirical Methods in Natural Language Processing, EMNLP ’10, pages 366–376, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Xiaohua Liu</author>
<author>Furu Wei</author>
<author>Shaodian Zhang</author>
<author>Ming Zhou</author>
</authors>
<title>Named entity recognition for tweets.</title>
<date>2013</date>
<booktitle>ACM Transactions on Intelligent Systems and Technology (TIST),</booktitle>
<pages>4--1</pages>
<contexts>
<context position="2632" citStr="Liu et al., 2013" startWordPosition="395" endWordPosition="398">r more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations. 2. Improve a state-of-the-art keywo</context>
</contexts>
<marker>Liu, Wei, Zhang, Zhou, 2013</marker>
<rawString>Xiaohua Liu, Furu Wei, Shaodian Zhang, and Ming Zhou. 2013. Named entity recognition for tweets. ACM Transactions on Intelligent Systems and Technology (TIST), 4(1):3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu´ıs Marujo</author>
<author>Miguel Bugalho</author>
<author>Jo˜ao P Neto</author>
<author>Anatole Gershman</author>
<author>Jaime Carbonell</author>
</authors>
<title>Hourly traffic prediction of news stories.</title>
<date>2011</date>
<booktitle>In Proceedings of the 3rd International Workshop on Context- Aware Recommender Systems held as part of the 5th ACM RecSys Conference,</booktitle>
<contexts>
<context position="1522" citStr="Marujo et al., 2011" startWordPosition="211" endWordPosition="214">equent usage of lexical variants and the high variance of the cardinality of keywords present in each tweet. We propose methods for addressing these issues, which leads to solid improvements on this dataset for this task. 1 Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twi</context>
<context position="3273" citStr="Marujo et al., 2011" startWordPosition="499" endWordPosition="502">l (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations. 2. Improve a state-of-the-art keyword extraction system (Marujo et al., 2011b; Marujo et al., 2013) for this domain by learning additional features in an unsupervised fashion. The paper is organized as follows: Section 2 describes the related work; Section 3 presents the annotation process; Section 4 details the architecture of our keyword extraction system; Section 5 presents experiments using our models and we conclude in Section 6. 637 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 637–643, Beijing, China, July 26-31, 2015. c�2015</context>
</contexts>
<marker>Marujo, Bugalho, Neto, Gershman, Carbonell, 2011</marker>
<rawString>Lu´ıs Marujo, Miguel Bugalho, Jo˜ao P. Neto, Anatole Gershman, and Jaime Carbonell. 2011a. Hourly traffic prediction of news stories. In Proceedings of the 3rd International Workshop on Context- Aware Recommender Systems held as part of the 5th ACM RecSys Conference, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu´ıs Marujo</author>
<author>M´arcio Viveiros</author>
<author>Jo˜ao P Neto</author>
</authors>
<title>Keyphrase Cloud Generation of Broadcast News.</title>
<date>2011</date>
<booktitle>In Proceedings of the 12th Annual Conference of the International Speech Communication Association (INTERSPEECH 2011). ISCA,</booktitle>
<contexts>
<context position="1522" citStr="Marujo et al., 2011" startWordPosition="211" endWordPosition="214">equent usage of lexical variants and the high variance of the cardinality of keywords present in each tweet. We propose methods for addressing these issues, which leads to solid improvements on this dataset for this task. 1 Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twi</context>
<context position="3273" citStr="Marujo et al., 2011" startWordPosition="499" endWordPosition="502">l (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations. 2. Improve a state-of-the-art keyword extraction system (Marujo et al., 2011b; Marujo et al., 2013) for this domain by learning additional features in an unsupervised fashion. The paper is organized as follows: Section 2 describes the related work; Section 3 presents the annotation process; Section 4 details the architecture of our keyword extraction system; Section 5 presents experiments using our models and we conclude in Section 6. 637 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 637–643, Beijing, China, July 26-31, 2015. c�2015</context>
</contexts>
<marker>Marujo, Viveiros, Neto, 2011</marker>
<rawString>Lu´ıs Marujo, M´arcio Viveiros, and Jo˜ao P. Neto. 2011b. Keyphrase Cloud Generation of Broadcast News. In Proceedings of the 12th Annual Conference of the International Speech Communication Association (INTERSPEECH 2011). ISCA, September.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu´ıs Marujo</author>
<author>Anatole Gershman</author>
<author>Jaime Carbonell</author>
<author>Robert Frederking</author>
<author>Jo˜ao P Neto</author>
</authors>
<title>Supervised topical key phrase extraction of news stories using crowdsourcing, light filtering and co-reference normalization.</title>
<date>2012</date>
<booktitle>In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC</booktitle>
<contexts>
<context position="5055" citStr="Marujo et al., 2012" startWordPosition="772" endWordPosition="775">ihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised keyword extraction framework (based on KEA) with additional features, such as POS tags to performed keyword extraction on Facebook posts. However, at that time Facebook status updates or posts did not contained either hashtags or user mentions. The size of Facebook posts is frequently longer than tweets and has less abbreviations since it is not limited by number of character as in tweets. 3 Dataset The dataset 1 contains 1827 tweets, which are POS tagged in (Gimpel et al., 2011). We used Amazon Mechanical turk, an crowds</context>
<context position="15296" citStr="Marujo et al., 2012" startWordPosition="2540" endWordPosition="2543">y. These were trained on the same 52 million tweets used for computing the IDF component. Due to the large size of the vocabulary, word types with less than 40 occurrences were removed. We observe that while both features yield improvements over the baseline model in row 2, the improvements obtained using Brown clustering are far more significant. Combining both features yields slightly higher results, reported on row 5. Finally, we also test training the system with all features on an out36856 out of 7045 keywords are singletons of-domain keyword extraction corpus composed by news documents (Marujo et al., 2012). Results are reported on row 6, where we can observe a significant domain mismatch problem between these two domains as results drop significantly. We explored different methods for choosing the number of keywords to be extracted in Table 2. The simplest way is choosing a fixed number of keywords k and tune this value in the development set. Next, we can also define the number of keywords as the ratio Nk , where N is the number of words in the tweet, and k is the parameter that we wish to optimize. Finally, the number of keywords can also be estimated using a linear regressor as y = f1w1, ...</context>
</contexts>
<marker>Marujo, Gershman, Carbonell, Frederking, Neto, 2012</marker>
<rawString>Lu´ıs Marujo, Anatole Gershman, Jaime Carbonell, Robert Frederking, and Jo˜ao P. Neto. 2012. Supervised topical key phrase extraction of news stories using crowdsourcing, light filtering and co-reference normalization. In Proceedings of the 8th International Conference on Language Resources and Evaluation (LREC 2012).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Lu´ıs Marujo</author>
<author>Ricardo Ribeiro</author>
<author>David Martins de Matos</author>
<author>Jo˜ao Paulo Neto</author>
<author>Anatole Gershman</author>
<author>Jaime G Carbonell</author>
</authors>
<title>Key phrase extraction of lightly filtered broadcast news.</title>
<date>2013</date>
<booktitle>In Proceedings of the 15th International Conference on Text, Speech and Dialogue (TSD).</booktitle>
<marker>Marujo, Ribeiro, de Matos, Neto, Gershman, Carbonell, 2013</marker>
<rawString>Lu´ıs Marujo, Ricardo Ribeiro, David Martins de Matos, Jo˜ao Paulo Neto, Anatole Gershman, and Jaime G. Carbonell. 2013. Key phrase extraction of lightly filtered broadcast news. In Proceedings of the 15th International Conference on Text, Speech and Dialogue (TSD).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olena Medelyan</author>
<author>Vye Perrone</author>
<author>Ian H Witten</author>
</authors>
<title>Subject metadata support powered by maui.</title>
<date>2010</date>
<pages>407--408</pages>
<editor>In Jane Hunter, Carl Lagoze, C. Lee Giles, and Yuan-Fang Li, editors, JCDL,</editor>
<publisher>ACM.</publisher>
<contexts>
<context position="1747" citStr="Medelyan et al., 2010" startWordPosition="247" endWordPosition="250"> Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many app</context>
<context position="4725" citStr="Medelyan et al., 2010" startWordPosition="719" endWordPosition="722"> media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised keyword extraction framework (based on KEA) with additional features, such as POS tags to performed keyword extraction on Facebook posts. However, at that time Facebook status updates or posts did </context>
<context position="7357" citStr="Medelyan et al., 2010" startWordPosition="1163" endWordPosition="1166"> such as news articles, as we wish to find terms that occur frequently within that document, but are not common in the other documents in that domain. However, we found that this approach does not work well in Twitter as tweets tend to be short and generally most terms occur only once, including their keywords. This means that the term frequency component is not very informative as the TF-IDF measure will simply benefit words that rarely occur, as these have a very low inverse document frequency component. A strong baseline for Automatic Keyword Extraction is the MAUI toolkit-indexer toolkit (Medelyan et al., 2010). The system extracts a list of candidate keywords from a document and trains a decision tree over a large set of hand engineered features, also including TF-IDF, in order to predict the correct keywords on the training set. Once trained, the toolkit extracts a list of keyword candidates from a tweet and returns a ranked list of candidates. The top k keywords are selected as answers. The parameter k is maximized on the development set. From this point, we present two extensions to the MAUI system to address many challenges found in this domain. 4.1 Unsupervised Feature Extraction The first pro</context>
</contexts>
<marker>Medelyan, Perrone, Witten, 2010</marker>
<rawString>Olena Medelyan, Vye Perrone, and Ian H. Witten. 2010. Subject metadata support powered by maui. In Jane Hunter, Carl Lagoze, C. Lee Giles, and Yuan-Fang Li, editors, JCDL, pages 407–408. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rada Mihalcea</author>
<author>Paul Tarau</author>
</authors>
<title>Textrank: Bringing order into texts.</title>
<date>2004</date>
<booktitle>In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004,</booktitle>
<pages>404--411</pages>
<publisher>Association for Computational Linguistics.</publisher>
<location>Barcelona, Spain,</location>
<contexts>
<context position="4459" citStr="Mihalcea and Tarau, 2004" startWordPosition="675" endWordPosition="678">eijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 2 Related Work Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To</context>
</contexts>
<marker>Mihalcea, Tarau, 2004</marker>
<rawString>Rada Mihalcea and Paul Tarau. 2004. Textrank: Bringing order into texts. In Dekang Lin and Dekai Wu, editors, Proceedings of EMNLP 2004, pages 404–411, Barcelona, Spain, July. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tomas Mikolov</author>
<author>Ilya Sutskever</author>
<author>Kai Chen</author>
<author>Greg S Corrado</author>
<author>Jeff Dean</author>
</authors>
<title>Distributed representations of words and phrases and their compositionality.</title>
<date>2013</date>
<booktitle>In Advances in Neural Information Processing Systems,</booktitle>
<pages>3111--3119</pages>
<contexts>
<context position="10259" citStr="Mikolov et al., 2013" startWordPosition="1654" endWordPosition="1657">nd a feature can be extracted for each cluster. In our experiments, we used the dataset with 1,000 Brown clusters made available by Owoputi et al. (Owoputi et al., 2013)2. 4.1.2 Continuous Word Vectors Word representations learned from neural language models are another way to learn more generalizable features for words (Collobert et al., 2011; Huang et al., 2012). In these models, a hidden layer is defined that maps words into a continuous vector. The parameters of this hidden layer are estimated by maximizing a goal function, such as the likelihood of each word predicting surrounding words (Mikolov et al., 2013; Ling et al., 2015). In our work, we used the structured skip-ngram goal function proposed in (Ling et al., 2015) and for each word we extracted its respective word vector as features. 4.2 Keyword Length Prediction The second problem is the high variance in terms of number of keywords per tweet. In larger doc2http://www.ark.cs.cmu.edu/TweetNLP/clusters/50mpaths2 uments, such as a news article, contain approximately 3-5 keywords, so extracting 3 keywords per document is a reasonable option. However, this would not work in Twitter, since the number of keywords can be arbitrary small. In fact, m</context>
</contexts>
<marker>Mikolov, Sutskever, Chen, Corrado, Dean, 2013</marker>
<rawString>Tomas Mikolov, Ilya Sutskever, Kai Chen, Greg S Corrado, and Jeff Dean. 2013. Distributed representations of words and phrases and their compositionality. In Advances in Neural Information Processing Systems, pages 3111–3119.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Olutobi Owoputi</author>
<author>Brendan O’Connor</author>
<author>Chris Dyer</author>
<author>Kevin Gimpel</author>
<author>Nathan Schneider</author>
<author>Noah A Smith</author>
</authors>
<title>Improved part-of-speech tagging for online conversational text with word clusters.</title>
<date>2013</date>
<booktitle>In HLT-NAACL,</booktitle>
<pages>380--390</pages>
<marker>Owoputi, O’Connor, Dyer, Gimpel, Schneider, Smith, 2013</marker>
<rawString>Olutobi Owoputi, Brendan O’Connor, Chris Dyer, Kevin Gimpel, Nathan Schneider, and Noah A Smith. 2013. Improved part-of-speech tagging for online conversational text with word clusters. In HLT-NAACL, pages 380–390.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Arzucan ¨Ozg¨ur</author>
<author>Levent ¨Ozg¨ur</author>
<author>Tunga G¨ung¨or</author>
</authors>
<title>Text categorization with class-based and corpus-based keyword selection.</title>
<date>2005</date>
<booktitle>In Proceedings of the 20th International Conference on Computer and Information Sciences, ISCIS’05,</booktitle>
<pages>606--615</pages>
<publisher>Springer-Verlag.</publisher>
<location>Berlin, Heidelberg.</location>
<marker>¨Ozg¨ur, ¨Ozg¨ur, G¨ung¨or, 2005</marker>
<rawString>Arzucan ¨Ozg¨ur, Levent ¨Ozg¨ur, and Tunga G¨ung¨or. 2005. Text categorization with class-based and corpus-based keyword selection. In Proceedings of the 20th International Conference on Computer and Information Sciences, ISCIS’05, pages 606– 615, Berlin, Heidelberg. Springer-Verlag.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alok Ranjan Pal</author>
<author>Projjwal Kumar Maiti</author>
<author>Diganta Saha</author>
</authors>
<title>An approach to automatic text summarization using simplified lesk algorithm and wordnet.</title>
<date>2013</date>
<journal>International Journal of Control Theory &amp; Computer Modeling,</journal>
<volume>3</volume>
<contexts>
<context position="1434" citStr="Pal et al., 2013" startWordPosition="199" endWordPosition="202">ter datasets. These datasets include the small amount of content in each tweet, the frequent usage of lexical variants and the high variance of the cardinality of keywords present in each tweet. We propose methods for addressing these issues, which leads to solid improvements on this dataset for this task. 1 Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data </context>
</contexts>
<marker>Pal, Maiti, Saha, 2013</marker>
<rawString>Alok Ranjan Pal, Projjwal Kumar Maiti, and Diganta Saha. 2013. An approach to automatic text summarization using simplified lesk algorithm and wordnet. International Journal of Control Theory &amp; Computer Modeling, 3.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ellen Riloff</author>
<author>Wendy Lehnert</author>
</authors>
<title>Information extraction as a basis for high-precision text classification.</title>
<date>1994</date>
<journal>ACM Transactions on Information Systems (TOIS),</journal>
<volume>12</volume>
<issue>3</issue>
<contexts>
<context position="1689" citStr="Riloff and Lehnert, 1994" startWordPosition="237" endWordPosition="240"> leads to solid improvements on this dataset for this task. 1 Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), </context>
<context position="4667" citStr="Riloff and Lehnert, 1994" startWordPosition="708" endWordPosition="711">atic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised keyword extraction framework (based on KEA) with additional features, such as POS tags to performed keyword extraction on Facebook posts. H</context>
</contexts>
<marker>Riloff, Lehnert, 1994</marker>
<rawString>Ellen Riloff and Wendy Lehnert. 1994. Information extraction as a basis for high-precision text classification. ACM Transactions on Information Systems (TOIS), 12(3):296–333, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Alan Ritter</author>
<author>Sam Clark</author>
<author>Oren Etzioni</author>
</authors>
<title>Named entity recognition in tweets: an experimental study.</title>
<date>2011</date>
<booktitle>In Proceedings of the Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1524--1534</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<contexts>
<context position="2613" citStr="Ritter et al., 2011" startWordPosition="391" endWordPosition="394">reated a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific artifacts. In many applications, that existing datasets and models tend to perform significantly worse on these domains, namely in Part-of-Speech (POS) Tagging (Gimpel et al., 2011), Machine Translation (Jelh et al., 2012; Ling et al., 2013), Named Entity Recognition (Ritter et al., 2011; Liu et al., 2013), Information Retrieval (Efron, 2011) and Summarization (Duan et al., 2012; Chang et al., 2013). As automatic keyword extraction plays an important role in many NLP tasks, building an accurate extractor for the Twitter domain is a valuable asset in many of these applications. In this paper, we propose an automatic keyword extraction system for this end and our contributions are the following ones: 1. Provide a annotated keyword annotated dataset consisting of 1827 tweets. These tweets are obtained from (Gimpel et al., 2011), and also contain POS annotations. 2. Improve a sta</context>
</contexts>
<marker>Ritter, Clark, Etzioni, 2011</marker>
<rawString>Alan Ritter, Sam Clark, Oren Etzioni, et al. 2011. Named entity recognition in tweets: an experimental study. In Proceedings of the Conference on Empirical Methods in Natural Language Processing, pages 1524–1534. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>G Salton</author>
<author>A Wong</author>
<author>C S Yang</author>
</authors>
<title>A Vector Space Model for Automatic Indexing.</title>
<date>1975</date>
<journal>Communications of the ACM,</journal>
<volume>18</volume>
<issue>11</issue>
<contexts>
<context position="6582" citStr="Salton et al., 1975" startWordPosition="1028" endWordPosition="1031"> acceptable for tweets to not contain keywords, as some tweets simply do not contain important in1The corpus is submitted as supplementary material. formation (e.g., retweet). The annotations of each annotator are combined by selecting keywords that are chosen by at least three annotators. We also divided the 1827 tweets into 1000 training samples, 327 development samples and 500 test samples, using the splits as in (Gimpel et al., 2011). 4 Automatic Keyword Extraction There are many methods that have been proposed for keyword extraction. TF-IDF is one of the simplest approaches for this end (Salton et al., 1975). The k words with the highest TF-IDF value are chosen as keywords, where k is optimized on the development set. This works quite well in text documents, such as news articles, as we wish to find terms that occur frequently within that document, but are not common in the other documents in that domain. However, we found that this approach does not work well in Twitter as tweets tend to be short and generally most terms occur only once, including their keywords. This means that the term frequency component is not very informative as the TF-IDF measure will simply benefit words that rarely occur</context>
</contexts>
<marker>Salton, Wong, Yang, 1975</marker>
<rawString>G. Salton, A. Wong, and C. S. Yang. 1975. A Vector Space Model for Automatic Indexing. Communications of the ACM, 18(11):613–620.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Peter D Turney</author>
</authors>
<title>Learning algorithms for keyphrase extraction.</title>
<date>2000</date>
<journal>Information Retrieval,</journal>
<volume>2</volume>
<issue>4</issue>
<contexts>
<context position="1724" citStr="Turney, 2000" startWordPosition="245" endWordPosition="246">r this task. 1 Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among domain specific</context>
<context position="4702" citStr="Turney, 2000" startWordPosition="717" endWordPosition="718">sed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised keyword extraction framework (based on KEA) with additional features, such as POS tags to performed keyword extraction on Facebook posts. However, at that time Facebook statu</context>
</contexts>
<marker>Turney, 2000</marker>
<rawString>Peter D. Turney. 2000. Learning algorithms for keyphrase extraction. Information Retrieval, 2(4):303–336.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Chen Wang</author>
<author>Sujian Li</author>
</authors>
<title>Corankbayes: Bayesian learning to rank under the co-training framework and its application in keyphrase extraction.</title>
<date>2011</date>
<booktitle>In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM ’11,</booktitle>
<pages>2241--2244</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="4745" citStr="Wang and Li, 2011" startWordPosition="723" endWordPosition="726">eets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised keyword extraction framework (based on KEA) with additional features, such as POS tags to performed keyword extraction on Facebook posts. However, at that time Facebook status updates or posts did not contained either</context>
</contexts>
<marker>Wang, Li, 2011</marker>
<rawString>Chen Wang and Sujian Li. 2011. Corankbayes: Bayesian learning to rank under the co-training framework and its application in keyphrase extraction. In Proceedings of the 20th ACM International Conference on Information and Knowledge Management, CIKM ’11, pages 2241–2244, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ian H Witten</author>
<author>Gordon W Paynter</author>
<author>Eibe Frank</author>
<author>Carl Gutwin</author>
<author>Craig G Nevill-Manning</author>
</authors>
<title>Kea: practical automatic keyphrase extraction.</title>
<date>1999</date>
<booktitle>In Proceedings of the 4th ACM conference on Digital libraries, DL ’99,</booktitle>
<pages>254--255</pages>
<publisher>ACM.</publisher>
<location>New York, NY, USA.</location>
<contexts>
<context position="1710" citStr="Witten et al., 1999" startWordPosition="241" endWordPosition="244">ts on this dataset for this task. 1 Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content has to be limited to 140 characters. The language is also more casual with many messages containing orthographical errors, slang (e.g., cday), abbreviations among d</context>
<context position="4688" citStr="Witten et al., 1999" startWordPosition="712" endWordPosition="716">raction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phrases selected before. MAUI toolkit-indexer (Medelyan et al., 2010), an improved version of the KEA (Witten et al., 1999) toolkit including new set of features and more robust classifier, remains the state-of-the-art system in the news domain (Marujo et al., 2012). To the best of our knowledge, only (Li et al., 2010) used a supervised keyword extraction framework (based on KEA) with additional features, such as POS tags to performed keyword extraction on Facebook posts. However, at that time </context>
</contexts>
<marker>Witten, Paynter, Frank, Gutwin, Nevill-Manning, 1999</marker>
<rawString>Ian H. Witten, Gordon W. Paynter, Eibe Frank, Carl Gutwin, and Craig G. Nevill-Manning. 1999. Kea: practical automatic keyphrase extraction. In Proceedings of the 4th ACM conference on Digital libraries, DL ’99, pages 254–255, New York, NY, USA. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wei Wu</author>
<author>Bin Zhang</author>
<author>Mari Ostendorf</author>
</authors>
<title>Automatic generation of personalized annotation tags for twitter users. In Human Language Technologies: The</title>
<date>2010</date>
<booktitle>Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10,</booktitle>
<pages>689--692</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4174" citStr="Wu et al., 2010" startWordPosition="633" endWordPosition="636">ection 5 presents experiments using our models and we conclude in Section 6. 637 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 637–643, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 2 Related Work Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and fi</context>
</contexts>
<marker>Wu, Zhang, Ostendorf, 2010</marker>
<rawString>Wei Wu, Bin Zhang, and Mari Ostendorf. 2010. Automatic generation of personalized annotation tags for twitter users. In Human Language Technologies: The 2010 Annual Conference of the North American Chapter of the Association for Computational Linguistics, HLT ’10, pages 689–692, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zi Yang</author>
<author>Eric Nyberg</author>
</authors>
<title>Leveraging procedural knowledge base for task-oriented search.</title>
<date>2015</date>
<booktitle>In Proceedings of the 38th international ACM SIGIR conference on Research &amp; development in information retrieval.</booktitle>
<publisher>ACM.</publisher>
<contexts>
<context position="1547" citStr="Yang and Nyberg, 2015" startWordPosition="215" endWordPosition="218">l variants and the high variance of the cardinality of keywords present in each tweet. We propose methods for addressing these issues, which leads to solid improvements on this dataset for this task. 1 Introduction Keywords are frequently used in many occasions as indicators of important information contained in documents. These can be used by human readers to search for their desired documents, but also in many Natural Language Processing (NLP) applications, such as Text Summarization (Pal et al., 2013), Text Categorization (¨Ozg¨ur et al., 2005), Information Retrieval (Marujo et al., 2011a; Yang and Nyberg, 2015) and Question Answering (Liu and Nyberg, 2013). Many automatic frameworks for extracting keywords have been proposed (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Litvak and Last, 2008). These systems were built for more formal domains, such as news data or Web data, where the content is still produced in a controlled fashion. The emergence of social media environments, such as Twitter and Facebook, has created a framework for more casual data to be posted online. These messages tend to be shorter than web pages, especially on Twitter, where the content h</context>
</contexts>
<marker>Yang, Nyberg, 2015</marker>
<rawString>Zi Yang and Eric Nyberg. 2015. Leveraging procedural knowledge base for task-oriented search. In Proceedings of the 38th international ACM SIGIR conference on Research &amp; development in information retrieval. ACM.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Wayne Xin Zhao</author>
<author>Jing Jiang</author>
<author>Jing He</author>
</authors>
<title>Yang Song, Palakorn Achananuparp, Ee-Peng Lim, and Xiaoming Li.</title>
<date>2011</date>
<booktitle>In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11,</booktitle>
<pages>379--388</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="4193" citStr="Zhao et al., 2011" startWordPosition="637" endWordPosition="640"> experiments using our models and we conclude in Section 6. 637 Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Short Papers), pages 637–643, Beijing, China, July 26-31, 2015. c�2015 Association for Computational Linguistics 2 Related Work Both supervised and unsupervised approaches have been explored to perform key word extraction. Most of the automatic keyword/keyphrase extraction methods proposed for social media data, such as tweets, are unsupervised methods (Wu et al., 2010; Zhao et al., 2011; Bellaachia and Al-Dhelaan, 2012). However, the TF-IDF across different methods remains a strong unsupervised baseline (Hasan and Ng, 2010). These methods include adaptations to the PageRank method (Brin and Page, 1998) including TextRank (Mihalcea and Tarau, 2004), LexRank (Erkan and Radev, 2004), and Topic PageRank (Liu et al., 2010). Supervised keyword extraction methods formalize this problem as a binary classification problem of two steps (Riloff and Lehnert, 1994; Witten et al., 1999; Turney, 2000; Medelyan et al., 2010; Wang and Li, 2011): candidate generation and filtering of the phra</context>
</contexts>
<marker>Zhao, Jiang, He, 2011</marker>
<rawString>Wayne Xin Zhao, Jing Jiang, Jing He, Yang Song, Palakorn Achananuparp, Ee-Peng Lim, and Xiaoming Li. 2011. Topical keyphrase extraction from twitter. In Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies - Volume 1, HLT ’11, pages 379–388, Stroudsburg, PA, USA. Association for Computational Linguistics.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>