<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000000">
<title confidence="0.99815">
Enhancing Grammatical Cohesion:
Generating Transitional Expressions for SMT
</title>
<author confidence="0.997489">
Mei Tu Yu Zhou Chengqing Zong
</author>
<affiliation confidence="0.984011666666667">
National Laboratory of Pattern Recognition,
Institute of Automation,
Chinese Academy of Sciences
</affiliation>
<email confidence="0.993368">
{mtu,yzhou,cqzong}@nlpr.ia.ac.cn
</email>
<sectionHeader confidence="0.982714" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999713208333333">
Transitional expressions provide glue that
holds ideas together in a text and enhance the
logical organization, which together help im-
prove readability of a text. However, in most
current statistical machine translation (SMT)
systems, the outputs of compound-complex
sentences still lack proper transitional expres-
sions. As a result, the translations are often
hard to read and understand. To address this
issue, we propose two novel models to en-
courage generating such transitional expres-
sions by introducing the source compound-
complex sentence structure (CSS). Our models
include a CSS-based translation model, which
generates new CSS-based translation rules,
and a generative transfer model, which en-
courages producing transitional expressions
during decoding. The two models are integrat-
ed into a hierarchical phrase-based translation
system to evaluate their effectiveness. The ex-
perimental results show that significant im-
provements are achieved on various test data
meanwhile the translations are more cohesive
and smooth.
</bodyText>
<sectionHeader confidence="0.995153" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999971071428571">
During the last decade, great progress has been
made on statistical machine translation (SMT)
models. However, these translations still suffer
from poor readability, especially translations of
compound-complex sentences. One of the main
reasons may be that most existing models con-
centrate more on producing well-translated local
sentence fragments, but largely ignore global
cohesion between the fragments. Generally, co-
hesion, including lexical and grammatical cohe-
sion, contributes much to the understandability
and smoothness of a text.
Recently, researchers have begun addressing
the lexical cohesion of SMT (Gong et al., 2011;
Xiao et al., 2011; Wong and Kit, 2012; Xiong,
2013). These efforts focus mainly on the co-
occurrence of lexical items in a similar environ-
ment. Grammatical cohesion1 (Halliday and Has-
san, 1976) in SMT has been little mentioned in
previous work. Translations without grammatical
cohesion is hard to read, mostly due to loss of
cohesive and transitional expressions between
two sentence fragments. Thus, generating transi-
tional expressions is necessary for achieving
grammatical cohesion. However, it is not easy to
produce such transitional expressions in SMT.
As an example, consider the Chinese-to-English
translation in Figure 1.
</bodyText>
<subsectionHeader confidence="0.629708">
Source Chinese sentence:
</subsectionHeader>
<bodyText confidence="0.507083">
Although reduce pollution of calls continue , public
</bodyText>
<figure confidence="0.758068555555556">
RX 0-VU ,12 [N* Z;ff -Z&apos;# E AVO
growing angry , pollution still become more worse
7 ,13 [/&amp;&amp; 1151hH *X 49 OV# .14
already , more show environment protection of urgent .
[�� �� N� 49 �� �� ,11 [ ��
Target English golden translation:
Despite frequent calls for cutting pollution, and
which increasingly shows the urgency of environmental
protection.
</figure>
<figureCaption confidence="0.85234275">
growing public anger, the problem has only got worse,
Figure 1: An example of Chinese-to-English transla-
tion. The English translation sentence has three transi-
tional phrases: Despite, and, which.
</figureCaption>
<bodyText confidence="0.998447">
There are 4 sub-sentences separated by com-
mas in the Chinese sentence. We have tried to
translate the Chinese sentence using many well-
</bodyText>
<note confidence="0.736936571428571">
1 Grammatical cohesion can make relations among sentenc-
es more explicit. There are various grammatically cohesive
devices (reference, substitution ellipsis and conjunction)
that tie fragments together in a cohesive way.
850
Proceedings of the 52nd Annual Meeting of the Association for Computational Linguistics, pages 850–860,
Baltimore, Maryland, USA, June 23-25 2014. c�2014 Association for Computational Linguistics
</note>
<bodyText confidence="0.988474214285714">
There are 11 common types of functional rela-
tionships 2 annotated in the Tsinghua Chinese
Treebank (Zhou, 2004).
Under the annotation scheme of the Tsinghua
Chinese Treebank, the Chinese sentence of ex-
ample in Figure 1 is represented as the tree
shown in Figure 2. In this example, each sub-
sentence is an eu. eu1 and eu2 are combined with
a parallel relationship, followed by eu3 with an
adversative relationship. eu1, eu2, and eu3 form a
large semantic span3, connected with eu4 by a
consequence relationship. All of the eus are or-
ganized into various functional relationships and
finally form a hierarchical tree.
</bodyText>
<figure confidence="0.581666">
consequence-[(1,3),(4,4)]
</figure>
<figureCaption confidence="0.99002">
Figure 2: The compound-complex sentence
</figureCaption>
<bodyText confidence="0.957506409090909">
structure of the Chinese sentence in Figure 1.
Formally, given a compound-complex sen-
tence structure (CSS), each node in the CSS can
be represented as a tuple
R—[(s„el),...(sr,er),...,(s,,e,)] . represents the
relationship, which has children. For each
child of , a pair records its start and end
eus. For example, adversative-[(1,2), (3,3)J in
Figure 2 means that two children are controlled
by the relationship adversative, and the left child
consists of eu1 and eu2, while the right child con-
tains only eu3.
CSS has much in common with Rhetorical
Structure (Mann and Thompson, 1988) in Eng-
lish, which also describe the semantic relation
between discourse units. But the Rhetorical
Structure involves much richer relations on the
document-level, and little corpus is open for
Chinese.
In the following, we will describe in detail
how to utilize such CSS information for model-
ling in SMT.
</bodyText>
<equation confidence="0.998182375">
parallel-[(1,1), (2,2)]
r5W ��
V5� �
nfiN TW&amp;quot;r ,
eu1 eu2
V53� XIA
Vff 3E
Wr T ,
eu3
AR 8 L
�� �
��� �
eu4
i`A F1WT
tffj� ,
adversative-[(1,2),(3,3)]
</equation>
<bodyText confidence="0.999956795454546">
known online translators, but find that it is very
difficult to generate the target transitional ex-
pressions, especially when there is no explicit
connective word in the source sentence, such as
generating “and ” and “which” in Figure 1.
Fortunately, the functional relationships be-
tween two neighboring source sub-sentences
provide us with a good perspective and the inspi-
ration to generate those transitional phrases. Fig-
ure 1 shows that the first and the second Chinese
sub-sentences form a parallel relation. Thus,
even though there is no distinct connective word
at the beginning of the second source sub-
sentence, a good translator is still able to insert or
generate an “and” as a connection word to make
the target translation more cohesive.
Based on the above analysis, this paper focus-
es on the target grammatical cohesion in SMT to
make the translation more understandable, espe-
cially for languages with great difference in lin-
guistic structure like Chinese and English. To the
best of our knowledge, our work is the first at-
tempt to generate target transitional expressions
for SMT grammatical cohesion by introducing
the functional relationships of source sentences.
In this work, we propose two models. One is a
new translation model that is utilized to generate
new translation rules combined with the infor-
mation of source functional relationships. The
other is a generative transfer model that encour-
ages producing transitional phrases during de-
coding. Our experimental results on Chinese-to-
English translation demonstrate that the transla-
tion readability is greatly improved by introduc-
ing the cohesive information.
The remainder of the paper is organized as
follows. In Section 2, we describe the functional
relationships of Chinese compound-complex sen-
tences. In Section 3, we present our models and
show how to integrate the models into an SMT
system. Our experimental results are reported in
Section 4. A survey of related work is conducted
in Section 5, and we conclude our work and out-
line the future work in Section 6.
</bodyText>
<sectionHeader confidence="0.569741" genericHeader="method">
2 Chinese Compound-Complex Sen-
tence Structure
</sectionHeader>
<bodyText confidence="0.9997234">
To acquire the functional relationships of a Chi-
nese compound-complex sentence, Zhou (2004)
proposed a well-annotated scheme to build the
Compound-complex Sentence Structure (CSS).
The structure explicitly shows the minimal se-
mantic spans, called elementary units (eus), and
also depicts the hierarchical relations among eus.
2 They are parallel, consequence, progressive, alternative,
causal, purpose, hypothesis, condition, adversative, expla-
nation, and flowing relationships.
</bodyText>
<page confidence="0.7588305">
3 A semantic span can include one or more eus.
851
</page>
<sectionHeader confidence="0.988107" genericHeader="method">
3 Modelling
</sectionHeader>
<bodyText confidence="0.935742375">
Our purpose is to enhance the grammatical cohe-
sion by exploiting the source CSS information.
Therefore, theoretically, the conditional probabil-
ity of a target translation es conditioned on the
source CSS-based tree ft is given by ,
and the final translation is obtained with the
following formula:
Following Och and Ney (2002), our model is
framed as a log-linear model:
where is a feature with weight . Then,
the best translation is:
Our models make use of CSS with two strate-
gies:
1) CSS-based translation model: following
formula (1), we obtain the cohesion information
by modifying the translation rules with their
probabilities based on word align-
ments between the source CSS-tree and the tar-
get string;
2) CSS-based transfer model: following
formula (3), we introduce a transfer score to en-
courage the decoder to generate transitional
words and phrases; the score is utilized as an ad-
ditional feature in the log-linear model.
</bodyText>
<subsectionHeader confidence="0.998136">
3.1 CSS-based Translation Model
</subsectionHeader>
<bodyText confidence="0.999958111111111">
For the existing translation models, the entire
training process is conducted at the lexical or
syntactic level without grammatically cohesive
information. As a result, it is difficult to utilize
such cohesive information during decoding. In-
stead, we reserve the cohesive information in the
training process by converting the original source
sentence into tagged-flattened CSS and then per-
form word alignment and extract the translation
rules from the bilingual flattened source CSS and
the target string.
As introduced in Section 2, a CSS consists of
nodes, and a node can be represented as a tuple
. In this represen-
tation, the relationship R is the most important
factor because different relationships directly
reflect different cohesive expressions. In addition,
the children’s positions always play a strong role
in choosing cohesive expressions because transi-
tional expressions vary for children with differ-
ent positions. For example, when translating the
last child of a parallel relation, we always use
word “and” as the transitional expression seen in
Figure 3, but we will not use it for the first child
of a parallel relation. Therefore, in the training
process we just keep the information of relation-
ships and children’s positions when converting
</bodyText>
<figure confidence="0.96557625">
parallel
尽管 减轻 污染 的 呼声 不断 , 公众 日渐 愤怒 ,
Despite frequent calls for cutting pollution , and growing public anger ,
(a)
&lt;Parallel @B&gt; 尽管 减轻 污染 的 呼声 不断 , &lt;Parallel @E&gt; 公众 日渐 愤怒 ,
Despite frequent calls for cutting pollution , and growing public anger ,
Original hierarchical rules:
Modified hierarchical rules:
</figure>
<figureCaption confidence="0.989863">
Figure 3: An example of modifying translation rules. @B means the current structure information
comes from the first child, and @E means from the last child.
</figureCaption>
<page confidence="0.530824">
852
</page>
<bodyText confidence="0.999709833333333">
the source CSS to a tagged-flattened string.
Considering that the absolute position (index
of the eu, such as 1, 2, 3) is somehow sparse in
the corpus, we employ the relative position in-
stead. B (Beginning) represents the first child of
a relationship, E (End) means the last child of a
relationship, and M (Middle) represents all the
middle children.
Under this agreement, the original Chinese
CSS-based tree will be converted to a new
tagged-flattened string. Note the converting ex-
ample from Figure 3(a) to Figure 3(b): node par-
allel-[(1,1), (2,2)I (see Figure 2) is converted to
a flat string. Its first child is represented as &lt;par-
allel, @B&gt; with the semantic span, while the last
child is &lt;parallel, @E&gt; with the corresponding
semantic span.
We then perform word alignment on the modi-
fied bilingual sentences, and extract the new
translation rules based on the new alignment, as
shown in Figure 3(b) to Figure 3(c). Now the
newly extracted rule “&lt;parallel, @E &gt; [XI H渐
  and growing [XI ” is tagged with cohesive in-
formation. Thus, if the similar relationship paral-
lel occurs in the test source sentence, this type of
rule is more likely to be chosen to generate the
cohesive word “and” during decoding because it
is more discriminating than the original rules ([XI
abilities of the new translation rules are calculat-
ed following (Chiang, 2005).
</bodyText>
<subsectionHeader confidence="0.999753">
3.2 CSS-based Transfer model
</subsectionHeader>
<bodyText confidence="0.996275575757576">
In general, according to formula (3), the transla-
tion quality based on the log-linear model is re-
lated tightly with the features chosen. Most trans-
lation systems adopt the features from a transla-
tion model, a language model, and sometimes a
reordering model. To give a bonus to generating
cohesive expressions during decoding, we have
designed a special additional feature. The addi-
tional feature is represented as a probability cal-
culated by a transfer model.
Given the source CSS information, we want
our transfer model to predict the most possible
cohesive expressions. For example, given two
semantic spans with a parallel relationship and
many translation candidates, our transfer model
is expected to assign higher scores to those with
transitional expressions such as “and” or “as well
as
Let w = wo, w1,...wn represent the transitional
expressions observed in the target string. Our
transfer model can be represented as a condition-
al probability:
By deriving each node of the CSS, we can
obtain a factored formula:
where is the transitional expression produced
by the child of the node of the CSS. is
the relationship type of the node. For thejrh
child in the node, is its relative position
(B, M or E) introduced in Section 3.1.
The process of training this transfer model and
smoothing is similar to the process of training a
language model. We obtain the factored transfer
probability as follows,
</bodyText>
<equation confidence="0.990441285714286">
P (  |, )
w ij i j
R RP
n
P(w0  |11�_,RPj)P(wk  |w0k1,Ri,RPj) (6)
k

</equation>
<bodyText confidence="0.9950865">
where
Following (Bilmes and Kirchhoff, 2003), the
conditional probabilities in
formula (6) are estimated in the same way as a
factored language model, which has the ad-
vantage of easily incorporating various linguistic
information.
Considering that commonly appears at the
beginning of the target translation of a source
semantic span such as “which ...”, namely, the
left-frontier phrases, we focus only on the left-
frontier phrases when training this model. Note
that if there exists a target word before a left
frontier, and this word is aligned to N ULL, we
will expand the left frontier to this word. The
expansion process will be repeated until there is
no such word. For example, if we take the CSS
and the alignment in Figure 3(a) for training, the
left frontier of the second child will be expanded
from “growing” to “and”. In addition, taking the
tri-gram left-frontier phrase for example, we can
obtain a training sample such as wlj = and grow-
ing public, R =parallel, RP = E.
By learning such probabilities for different
transitional expressions conditioned on different
relationships, we are able to capture the inner
connection between the source CSS and the pro-
jected target cohesive phrases. Thus, during de-
coding, if we add the probability generated by
the transfer model of P(w I CSS) as a feature in
</bodyText>
<equation confidence="0.3302505">
1
853
</equation>
<bodyText confidence="0.9239655">
formula (3), it will certainly contribute to select-
ing more cohesive candidates.
spans combined by elementary units are certainly
subject to the integrity assumption.
</bodyText>
<subsectionHeader confidence="0.992304">
3.3 Elementary-Unit Cohesion Constraint
</subsectionHeader>
<bodyText confidence="0.999994423076923">
As mentioned in Section 3.2, in the transfer
model, the transitional phrases are expected to
occur at the left frontier of a projected span on
target side. In fact, this depends on the assump-
tion that the projected translations of any two
disjoint source semantic spans are also disjoint to
keep their own semantic integrity. We call this
assumption the integrity assumption. This as-
sumption is intuitive and supported by statistics.
After analyzing 1,007 golden aligned Chinese-
English sentence-pairs, we find that approxi-
mately 90% of the pairs comply with the as-
sumption. However, in real automatically aligned
noisy data, the ratio of complying pairs reduces
to 71%4. Two projected translations that violate
the integrity assumption may mutually overlap,
which causes our confusion on where to extract
the transitional phrases. In this case, extracted
transitional phrases are likely to be wrong.
To increase the chance of extracting correct
transitional phrases, the alignment results must
be modified to reduce the impact of incorrect
alignment. We propose a dynamic cleaning
method to ensure that the most expressive transi-
tional phrases fall in the accessible extraction
range before training the transfer model.
</bodyText>
<subsubsectionHeader confidence="0.377687">
3.3.1 EUC and non-EUC
</subsubsectionHeader>
<bodyText confidence="0.978345705882353">
As we have defined in Section 2, the minimal
semantic span is called elementary unit (eu). If
the source eu and its projected target span com-
ply with the integrity assumption, we say that
such an eu and its projected span have Elemen-
tary-Unit-Cohesion (EUC). We define EUC
formally as follows.
Given two elementary units euA and euB ,
and their projected target spans PSA and psB
bound by the word alignment, the alignment
complies with EUC only if there is no overlap
between psA and psB . Otherwise, the alignment
is called non-EUC. The common EUC and non-
EUC cases are illustrated in Figure 4.
EUC is the basic case for the integrity as-
sumption. For the best cases, the elementary
units comply with EUC, and thus the semantic
</bodyText>
<figure confidence="0.9798899">
4 The aligning tool is GIZA++ with 5 iterations of Model 1,
5 iterations of HMM, and 10 iterations of Model 4. The
GIZA++ code can be downloaded from
https://code.google.com/p/giza-pp/
euA euB euA euB
psA psB psB psA
(a) mono EUC case (b) swap EUC case
euA euB
psA psB
(c) non-EUC case
</figure>
<figureCaption confidence="0.4439195">
Figure.4 The schematic diagram of EUC cases
and non-EUC case.
</figureCaption>
<subsectionHeader confidence="0.766202">
3.3.2 A Dynamic Cleaning Method
</subsectionHeader>
<bodyText confidence="0.9968399375">
An intuitive method to clean the alignment re-
sults is to drop off the noisy word-to-word links
that cause non-EUC. Considering that the drop-
ping process is a post-editing method for the
original alignment obtained by a state-of-the-art
aligner such as GIZA++, we do not expect over-
deleting. Therefore, we tend to take a relatively
conservative strategy to minimize the deleting
operation.
Given a sentence-pair (f, e), suppose that
f = { fo,..., f ,..., fI} is divided into M elemen-
tary units U={uo,...,um,...,umI , and a has I
words, that is, e= {eo,...,e,,,...,el } . If A is the
word alignment of (f, e), then the goal is to con-
struct the maximum subset under the
condition that is the word alignment with the
constraint of EU. The search process can be de-
scribed as the pseudo code in Figure 5.
In Figure 5, we scan each target word and each
source eu to assign each word to a unique eu un-
der the EUC constraint with the lowest cost.
Function cost(n,m) in line 6 computes the
counts of deleted links that force the target
word to align only to words in the range of the
mth eu. For example, if the target word is
aligned to the , , and word in
source side, while the word belongs to u.,
and the and words belong to
u„2 , then cost(n, u� ) = 2 , and cost(n, u,, ) =1 .
In line 6, Score[n][m] saves a list of scores, each
score computed by adding the current cost(n, m)
with the history score of each list of Score[n-1].
</bodyText>
<page confidence="0.760258">
854
</page>
<bodyText confidence="0.999779666666667">
Before the next iteration, the bad branches are
pruned, as seen in line 5. We adopt the following
two ways to prune:
</bodyText>
<listItem confidence="0.8930923125">
(1) EUC constraint: if the current link violates
EUC alignment, delete it.
(2) Keep the hypothesis with a fixed maximum
size to avoid too large a searching space.
//Pseudo code for dynamic cleaning
1: Score [I+1][M]= { [0] }I .m /* initialize
cumulative cost score chart*/
2: Path [M]=[[]] /*initialize tracking path*/
3: for n = :{ /* scan target words*/
4: for :{ /*scan source U set */
5: PrunePath();
/* prune invalid path and high-cost path*/
6: Score[n][m]=GetScore(Score[n-1], cost(n, m))
/*compute current cumulative cost score by previ-
ous score and current cost*/
7: SaveCurrentPath(Path[m]);
</listItem>
<figure confidence="0.76980275">
/*add current index to Path*/
8: }//endm
9:}//endn
10: OptimalPath = ;
</figure>
<figureCaption confidence="0.973067">
Figure 5. The pseudo code of dynamic cleaning
method.
</figureCaption>
<sectionHeader confidence="0.997375" genericHeader="method">
4 Experiments
</sectionHeader>
<subsectionHeader confidence="0.996998">
4.1 Experimental Setup
</subsectionHeader>
<bodyText confidence="0.999200071428571">
To obtain the CSSs of Chinese sentences, we use
the Chinese parser proposed in (Tu et al., 2013a).
Their parser first segments the compound-
complex sentence into a series of elementary
units, and then builds structure of the hierarchical
relationships among these elementary units.
Their parser was reported to achieve an F-score
for elementary unit segmentation of approxi-
mately 0.89. The progressive, causal, and condi-
tion terms of functional relationships can be rec-
ognized with precisions of 0.86, 0.8, and 0.75,
respectively, while others, such as purpose, par-
allel, and flowing, achieve only 0.5, 0.59 and
0.62, respectively.
The translation experiments have been con-
ducted in the Chinese-to-English direction. The
bilingual training data for translation model and
CSS-based transfer model is FBIS corpus with
approximately 7.1 million Chinese words and 9.2
million English words. We obtain the word
alignment with the grow-diag-final-and strategy
with GIZA++. Before training the CSS-based
transfer model, the alignment for transfer model
is modified by our dynamic cleaning method.
During the cleaning process, the maximum size
of hypothesis is limited to 5. A 5-gram language
model is trained with SRILM5 on the combina-
tion of the Xinhua portion of the English Giga-
word corpus combined with the English part of
FBIS. For tuning and testing, we use NIST03
evaluation data as the development set.
NIST04/05/06, CWMT08-Development 6 and
CWMT08-Evaluation data are used for testing
under the measure metric of BLEU-4 (Papineni
et al. 2002) with the shortest length penalty.
Table 1 shows how the CSS is distributed in
all testing sets. According to the statistics in Ta-
ble 1, we see that CSS is really widely distribut-
ed in the NIST and CWMT corpora, which im-
plies that the translation quality may benefit sub-
stantially from the CSS information, if it is well
considered in SMT.
</bodyText>
<table confidence="0.999313666666667">
Total CSS Ratio(%)
NIST04 1,788 1,307 73.1
NIST05 1,082 849 78.5
NIST06 1,000 745 74.5
CWMT08-Dev. 1,006 818 81.3
CWMT08-Eval. 1,006 818 81.3
</table>
<tableCaption confidence="0.99207">
Table 1. The numbers of sentences and the
</tableCaption>
<bodyText confidence="0.77865825">
CSS ratios of all sentences. CWMT08-Dev. is
short for CWMT08 Development data and
CWMT08-Eval. is CWMT08 Evaluation da-
ta.
</bodyText>
<subsectionHeader confidence="0.976041">
4.2 Extracted Transitional Expressions
</subsectionHeader>
<bodyText confidence="0.999875214285714">
Eleven types of Chinese functional relationships
and their English left-frontier phrases (tri-gram)
learned by our transfer model are given in Table
2.
The results in Table 2 show that some left-
frontier phrases reflect the source functional rela-
tionship well, especially for those with better
precision of relationship recognition, such as
progressive, causal and condition. Conversely,
lower precision of relationship recognition may
weaken the learning ability of the transfer model.
For example, noisy left-frontier phrases are easi-
ly generated under relationships such as parallel
and purpose.
</bodyText>
<figure confidence="0.7825225">
5 http://www.speech.sri.com/projects/srilm/
6 The China Workshop on Machine Translation
855
Relation Left-frontier phrases (tri-gram)
</figure>
<bodyText confidence="0.991202421052632">
parallel as well as; at the same; ...
progressive but will also; in addition to;...
causal therefore , the; for this reason; as a
result; because it is; so it is;...
condition as long as; only when the...
hypothesis if we do; if it is; if the us; ...
alternative regardless of whether;...
purpose it is necessary;
further promote the ;...
explanation that is ,; the first is; first is the;...
adversative however , the ; but it is; ...
flowing this is a; which is an; ...
consequence so that the; to ensure that...
Table 2. Chinese functional relations and their
corresponding English left-frontier phrases
learned by our transfer model. The noun phrases
starting with a definite / indefinite word are fil-
tered because they are unlikely to be the transi-
tional phrases.
</bodyText>
<subsectionHeader confidence="0.977895">
4.3 Results on SMT with Different Strategies
</subsectionHeader>
<bodyText confidence="0.999979418604651">
For this work, we use an in-house decoder to
build the SMT baseline; it combines the hierar-
chical phrase-based translation model (Chiang,
2005; Chiang, 2007) with the BTG (Wu, 1996)
reordering model (Xiong et al., 2006; Zens and
Ney, 2006; He et al., 2010).
To test the effectiveness of the proposed mod-
els, we have compared the translation quality of
different integration strategies. First, we adopted
only the tagged-flattened rules in the hierarchical
translation system. Next, we added the log prob-
ability generated by the transfer model as a fea-
ture into the baseline features. The baseline fea-
tures include bi-directional phrase translation
probabilities, bi-directional lexical translation
probabilities, the BTG re-ordering features, and
the language model feature. The tri-gram left-
frontier phrase was adopted in the experiment.
Then the probability generated by the transfer
model with EUC constraint is added. Finally, we
incorporated the tagged-flattened rules and the
additional transfer model feature together.
Table 3 shows the results of these different in-
tegrated strategies. In Table 3, almost all BLEU
scores are improved, no matter what strategy is
used. In particular, the best performance marked
in bold is as high as 1.24, 0.94, and 0.82 BLEU
points, respectively, over the baseline system on
NIST04, CWMT08 Development, and CWMT08
Evaluation data. The strategy of “TFS+ Flat-
tened Rule” is the most stable. Meanwhile the
“Flattened Rule” achieves better performance
than “TFS”. The merits of “Flattened Rule” are
two-fold: 1) In training process, the new word
alignment upon modified sentence pairs can
align transitional expressions to flattened CSS
tags; 2) In decoding process, the CSS-based rules
are more discriminating than the original rules,
which is more flexible than “TFS”. From the
table, we cannot conclude that the EUC con-
straint will certainly promote translation quality,
but the transfer model performs better with the
constraint on most testing sets.
</bodyText>
<subsectionHeader confidence="0.989331">
4.4 Analysis of Different Effects of Different
I-grams
</subsectionHeader>
<bodyText confidence="0.999441">
As mentioned in Section 4.3, we have noted the
effectiveness of tri-gram transfer model, which
means in formula (7). In fact, the lengths of
common transitional expressions vary from one
word to several words. To evaluate the effects of
different n-grams for our proposed transfer mod-
el, we compared the uni-/bi-/tri-gram transfer
models in SMT, and illustrate the results in Fig-
</bodyText>
<table confidence="0.999659666666667">
NIST04 NIST05 NIST06 CWMT08’s CWMT08’s
Dev. Eval.
Baseline 33.42 31.99 33.88 26.14 23.88
+Flattened Rule 34.54** 32.32 34.58** 26.79** 24.70**
+TFS (without EUC) 33.93** 32.04 34.40* 26.44 24.58**
+TFS 33.84** 32.63* 34.15 27.08** 24.65**
+TFS+ Flattened Rule 34.66** 32.54 34.52** 26.87** 24.49**
+ Flattened Rule: only use the tagged-flattened translation rules
+ TFS: only use the transfer model score as an additional feature (based on 3-gramtransitional phrase)
+ TFS + Flattened Rule: both are used
*: value with * means that it is significantly better than the baseline with p&lt;0.05
**: value with ** means that it is significantly better than the baseline with p&lt;0.01
</table>
<tableCaption confidence="0.997652">
Table 3. BLEU scores of the testing sets with different integrating strategies
</tableCaption>
<page confidence="0.88951">
856
</page>
<bodyText confidence="0.99783125">
ure 6. In this experiment, the CSS-based transla-
tion rules and the CSS-based transfer model are
both incorporated. Considering time and compu-
ting resources, in the rest of our paper, our analy-
sis is conducted on NIST05 and NIST06.
We choose in this experiment for
that the common English transitional expressions
are primarily conjunctions, most of which are
less than 4 words. Results in Figure 6 show that
the uni-gram and tri-gram transitional expres-
sions seem more fitting for our transfer model.
One possible reason is that uni-gram or tri-gram
conjunctions are more utilized in an English text.
In a conjunction expression list proposed by
(Williams, 1983) which summarizes the differ-
ent kinds of conjunctions based on the work of
Halliday and Hassan (1976), we obtain the statis-
tical results on uni-/bi-/tri-gram expressions,
which are about 52.1%/16.9%/23.9% respective-
ly.
</bodyText>
<figure confidence="0.937491142857143">
BLEU
35
Uni-gram
Bi-gram
Tri-gram
30
NIST05 NIST06 Testing Set
</figure>
<figureCaption confidence="0.788588">
Figure 6. Different translation qualities along
</figureCaption>
<bodyText confidence="0.77445">
with different n-grams for transfer model.
</bodyText>
<subsectionHeader confidence="0.988912">
4.5 Experiments on Big Training Data
</subsectionHeader>
<bodyText confidence="0.9999205">
To further evaluate the effectiveness of the pro-
posed models, we also conducted an experiment
on a larger set of bilingual training data from the
LDC corpus7 for translation model and transfer
model. The training corpus contains 2.1M sen-
tence pairs with approximately 27.7M Chinese
words and 31.9M English words. All the other
settings were the same as the SMT experiments
of sub-section 4.3. The final BLEU scores on
NIST05 and NIST06 are given in Table 4.
The results in Table 4 further verify the effec-
tiveness of our proposed models. The best per-
formance with bold marking scored as high as
0.83 and 0.64 BLEU points, respectively over the
</bodyText>
<note confidence="0.832323666666667">
7 LDC category number: LDC2000T50, DC2002E18,
LDC2003E07, LDC2004T07, LDC2005T06, LDC2002L27,
LDC2005T10 and LDC2005T34.
</note>
<table confidence="0.962914375">
baseline system on NIST05 and NIST06 evalua-
tion data.
NIST05 NIST06
Baseline 35.20 35.52
+Flattened Rule 36.03** 36.10*
+TFS 35.56* 36.04*
+TFS +Flattened Rule 36.02** 36.16**
+ Flattened Rule: only use the tagged-flattened transla-
tion rules
+ TFS: only use the transfer model score as an addi-
tional feature (3-gram transitional phrase)
+ TFS + Flattened Rule: both are used
*: value with * means that it is significantly better than
the baseline with p&lt;0.05
**: value with ** means that it is significantly better
than the baseline with p&lt;0.01
</table>
<tableCaption confidence="0.860035">
Table 4. BLEU scores on the large-scale training
data.
</tableCaption>
<subsectionHeader confidence="0.994627">
4.6 Translation Examples
</subsectionHeader>
<bodyText confidence="0.999949384615385">
Two SMT examples of Chinese-to-English are
given in Table 5. We observe that compared to
the baseline, our approach has obvious ad-
vantages on translating the implicit relations, due
to generating translational expressions on target
side. Moreover, with the transitional expressions,
cohesion of the entire translation improves. No-
tably, the transitional expressions in this work
like “including, there are, the core of which” are
not linguistic conjunctions. We would like to call
them “generalized” conjunctions, because they
tie semantic fragments together, analogously to
linguistic conjunctions.
</bodyText>
<sectionHeader confidence="0.999618" genericHeader="method">
5 Related Work
</sectionHeader>
<bodyText confidence="0.999960055555556">
Improving cohesion for complex sentences or
discourse translation has attracted much attention
in recent years. Such research efforts can be
roughly divided into two groups: 1) research on
lexical cohesion, which mainly contributes to the
selection of generated target words; 2) efforts to
improve the grammatical cohesion, such as dis-
ambiguation of references and connectives.
In lexical cohesion work, (Gong et al., 2011;
Xiao et al., 2011; Wong and Kit, 2012) built dis-
course-based models to ensure lexical cohesion
or consistency. In (Xiong et al., 2013a), three
different features were designed to capture the
lexical cohesion for document-level machine
translation. (Xiong et al., 2013b) incorporated
lexical-chain-based models (Morris and Hirst,
1991) into machine translation. They generated
the target lexical chains based on the source
</bodyText>
<page confidence="0.7406675">
34
33
32
31
</page>
<table confidence="0.948814">
857
Source 过去三年中,已有三对染色体完成排序, 包括第二十对、第二十一对和第二十二 对 。
Reference In the past three years, the sequencing of three chromosomes has been completed, including
chromosomes 20 , 21 , and 22 .
Baseline In the past three years , now has three terms of the completion of the chromosomes , 20 , 21
and 22 .
Improved In the past three years , there are three chromosomes to accomplish , including 20 , 21 and
22 .
Source 上述主张构成了一个中国原则的基本涵义,核心是维护中国的主权和领土完整。
Reference The above-mentioned propositions constitute the basic connotation of this one-china principle
with safeguarding china &apos; s sovereignty and territorial integrity as its core .
Baseline The above-mentioned propositions constitute the basic meaning of the one-china principle is
the core of safeguard china &apos; s sovereignty and territorial integrity .
Improved The above-mentioned propositions constitute the basic meaning of the one-china principle ,
the core of which is to safeguard china &apos; s sovereignty and territorial integrity .
</table>
<tableCaption confidence="0.998348">
Table 5. Examples of baseline and the improved system outputs.
</tableCaption>
<bodyText confidence="0.99989021875">
chains via maximum entropy classifiers, and
used the target chains to work on the word selec-
tion.
Limited work has been conducted on gram-
matical cohesion. (Marcu et al., 2000) designed a
discourse structure transfer module, but it fo-
cused on converting the semantic structure rather
than actual translation. (Tu et al., 2013b) provid-
ed a Rhetorical-Structure-Theory-based tree-to-
string translation method for complex sentences
with explicit relations inspired by (Marcu et al.,
2000), but their models worked only for explicit
functional relations, and they were concerned
mainly with the translation integrity of semantic
span rather than cohesion. (Meyer and Popescu-
Belis, 2012) used sense-labeled discourse con-
nectives for machine translation from English to
French. They added the labels assigned to con-
nectives as an additional input to an SMT system,
but their experimental results show that the im-
provements under the evaluation metric of BLEU
were not significant. (Nagard and Koehn, 2010)
addresses the problems of reference or anaphora
resolution inspired by work of Mitkov et al.
(1995).
To the best of our knowledge, our work is the
first attempt to exploit the source functional rela-
tionship to generate the target transitional ex-
pressions for grammatical cohesion, and we have
successfully incorporated the proposed models
into an SMT system with significant improve-
ment of BLEU metrics.
</bodyText>
<sectionHeader confidence="0.998617" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.99998716">
In this paper, we focus on capturing cohesion
information to enhance the grammatical cohesion
of machine translation. By taking the source CSS
into consideration, we build bridges to connect
the source functional relationships in CSS to tar-
get transitional expressions; such a process is
very similar to human translating.
Our contributions can be summarized as: 1)
the new translation rules are more discriminative
and sensitive to cohesive information by convert-
ing the source string into a CSS-based tagged-
flattened string; 2) the new additional features
embedded in the log-linear model can encourage
the decoder to produce transitional expressions.
The experimental results show that significant
improvements have been achieved on various
test data, meanwhile the translations are more
cohesive and smooth, which together demon-
strate the effectiveness of our proposed models.
In the future, we will extend our methods to
other translation models, such as the syntax-
based model, to study how to further improve the
performance of SMT systems. Besides, more
language pairs with various linguistic structures
will be taken into consideration.
</bodyText>
<sectionHeader confidence="0.945729" genericHeader="acknowledgments">
Acknowledgement
</sectionHeader>
<bodyText confidence="0.9994848">
We would like to thank Jiajun Zhang for provid-
ing the BTG-based hierarchical decoder. The
research work has been partially funded by the
Natural Science Foundation of China under
Grant No. 61333018, the Hi-Tech Research and
Development Program (“863” Program) of China
under Grant No. 2012AA011101, and also
the Key Project of Knowledge Innovation Pro-
gram of Chinese Academy of Sciences under
Grant No. KGZD-EW-501 as well.
</bodyText>
<page confidence="0.857474">
858
</page>
<sectionHeader confidence="0.951904" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.994493898148148">
Jeff A. Bilmes and Katrin Kirchhoff. Factored lan-
guage models and generalized parallel backoff. In
Proceedings of the 2003 Conference of the North
American Chapter of the Association for Compu-
tational Linguistics on Human Language Technol-
ogy: companion volume of the Proceedings of
HLT-NAACL 2003--short papers-Volume 2: 4-6.
David Chiang. 2005. A hierarchical phrase-based
model for statistical machine translation. In Pro-
ceedings of the 43rd Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 263–
270.
David Chiang. 2007. Hierarchical phrase-based
translation. Computational Linguistics, pages
33(2):201–228.
Zhengxian Gong, Min Zhang, and Guodong Zhou.
Cache-based document-level statistical machine
translation, 2011, Edinburgh, Scotland, UK. In
Proceedings of the 2011 Conference on Empirical
Methods in Natural Language Processing, pages
909–919.
Liane Guillou. 2013. Analysing lexical consistency in
translation. In Proceedings of the Workshop on
Discourse in Machine Translation, pages 10–18,
Sofia
Michael A.K. Halliday, Hasan R. Cohesion in English.
1976. London: Longman.
Zhongjun He, Yao Meng, and Hao Yu. 2010b. Maxi-
mum Entropy Based Phrase Reordering for Hier-
archical Phrase-based Translation. In Proc. of the
Conf. on Empirical Methods for Natural Language
Processing (EMNLP), pages 555–563.
Annie Louis and Ani Nenkova. 2012. A coherence
model based on syntactic patterns. In Proceedings
of the 2012 Joint Conference on Empirical Meth-
ods in Natural Language Processing and Computa-
tional Natural Language Learning, pages 1157–
1168, Jeju Island, Korea, July.
William C Mann and Sandra A Thompson. 1988.
Rhetorical structure theory: Toward a functional
theory of text organization. Text, 8(3):243–281.
Ruslan Mitkov, Sung-Kwon Choi, and Randall Sharp.
1995. Anaphora resolution in Machine Transla-
tion. In Proceedings of the Sixth International
Conference on Theoretical and Methodological Is-
sues in Machine Translation.
Thomas Meyer and Andrei Popescu-Belis. Using
sense-labeled discourse connectives for statistical
machine translation, 2012, In Proceedings of the
Joint Workshop on Exploiting Synergies between
Information Retrieval and Machine Translation
(ESIRMT) and Hybrid Approaches to Machine
Translation (HyTra), pages:129-138.
Jane Morris and Graeme Hirst. 1991. Lexical cohe-
sion computed by thesaural relations as an indica-
tor of the structure of text. Comput. Linguist.,
17(1):21–48, March.
Ronan L Nagard and Philipp Koehn. 2010, Aiding
pronoun translation with co-reference resolution,
In proceedings of the Joint Fifth Workshop on Sta-
tistical Machine Translation and MetricsMATR,
pages 252-261.
Franz J Och and Hermann Ney. 2002. Discriminative
training and maximum entropy models for statisti-
cal machine translation. In Proc. of ACL, pages
295–302.
Kishore Papineni, Salim Roukos, Todd Ward, et al.
2002, BLEU: a method for automatic evaluation
of machine translation. In proceedings of the 40th
annual meeting on association for computational
linguistics. pages: 311-318.
Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni
Miltsakaki, Livio Robaldo, Aravind Joshi, and
Bonnie Webber. 2008. The Penn Discourse Tree-
bank 2.0. In Proceedings of the 6th International
Conference on Language Resources and Evalua-
tion (LREC 2008).
Williams Ray. Teaching the Recognition of Cohesive
Ties in Reading a Foreign, 1983. Reading in a
foreign language, 1(1), pages: 35-52.
Radu Soricut and Daniel Marcu. 2003. Sentence level
discourse parsing using syntactic and lexical in-
formation. In Proceedings of the 2003 Conference
of the North American Chapter of the Association
for Computational Linguistics on Human Lan-
guage Technology-Volume 1, pages 149–156.
Mei Tu, Yu Zhou, and Chengqing Zong. 2013a, A
Novel Translation Framework Based on Rhetori-
cal Structure Theory. In Proceedings of the 51st
Annual Meeting of the Association for Computa-
tional Linguistics, short paper, Sofia, Bulgaria,
pages 370–374.
Mei Tu, Yu Zhou, Chengqing Zong. 2013b, Automat-
ically Parsing Chinese Discourse Based on Maxi-
mum Entropy. In The 2nd Conference on Natural
Language Processing &amp; Chinese Computing.
Ashish Vaswani, Liang Huang and David Chiang,
Huang L, Chiang D. 2012, Smaller alignment
models for better translations: unsupervised word
alignment with the l 0-norm. In Proceedings of the
50th Annual Meeting of the Association for Com-
putational Linguistics: Long Papers-Volume
1,pages 311-319.
Tong Xiao, Jingbo Zhu, Shujie Yao, and Hao Zhang.
Document-level consistency verification in ma-
chine translation. September 2011, Xiamen, China.
In Proceedings of the 2011 MT summit XIII, pag-
es 131–138.
</reference>
<page confidence="0.691589">
859
</page>
<reference confidence="0.9994025">
Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maxi-
mum entropy based phrase reordering model for
statistical machine translation. In Proceedings of
the 44th Annual Meeting of the Association for
Computational Linguistics, pages 521–528.
Deyi Xiong, Guosheng Ben, Min Zhang, Yajuan Lv,
and Qun Liu. 2013 (a). Modeling lexical cohesion
for document-level machine translation. In Pro-
ceedings of the Twenty-Third International Joint
Conference on Artificial Intelligence (IJCAI-13),
Beijing, China, August.
Deyi Xiong, Ding Yang, Min Zhang and Chew Lim
Tan, 2013 (b). Lexical Chain Based Cohesion
Models for Document-Level Statistical Machine
Translation. In Proceedings of the 2013 Confer-
ence on Empirical Methods in Natural Language
Processing, pages: 1563-1573.
Richard Zens and Hermann Ney. 2006. Discrimina-
tive reordering models for statistical machine
translation. In Proceedings of theWorkshop on
Statistical Machine Translation, pages 55–63.
Qiang Zhou, 2004, Annotation Scheme for Chinese
Treebank, Journal of Chinese Information Pro-
cessing, 18(4): 1-8.
</reference>
<page confidence="0.901026">
860
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.679096">
<title confidence="0.999558">Enhancing Grammatical Generating Transitional Expressions for SMT</title>
<author confidence="0.988432">Mei Tu Yu Zhou Chengqing Zong</author>
<affiliation confidence="0.944917333333333">National Laboratory of Pattern Institute of Automation, Chinese Academy of Sciences</affiliation>
<email confidence="0.81428">mtu@nlpr.ia.ac.cn</email>
<email confidence="0.81428">yzhou@nlpr.ia.ac.cn</email>
<email confidence="0.81428">cqzong@nlpr.ia.ac.cn</email>
<abstract confidence="0.99930212">Transitional expressions provide glue that holds ideas together in a text and enhance the logical organization, which together help improve readability of a text. However, in most current statistical machine translation (SMT) systems, the outputs of compound-complex sentences still lack proper transitional expressions. As a result, the translations are often hard to read and understand. To address this issue, we propose two novel models to encourage generating such transitional expressions by introducing the source compoundcomplex sentence structure (CSS). Our models include a CSS-based translation model, which generates new CSS-based translation rules, and a generative transfer model, which encourages producing transitional expressions during decoding. The two models are integrated into a hierarchical phrase-based translation system to evaluate their effectiveness. The experimental results show that significant improvements are achieved on various test data meanwhile the translations are more cohesive and smooth.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<authors>
<author>Grant No</author>
</authors>
<note>KGZD-EW-501 as well.</note>
<marker>No, </marker>
<rawString>Grant No. KGZD-EW-501 as well.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Jeff A Bilmes</author>
<author>Katrin Kirchhoff</author>
</authors>
<title>Factored language models and generalized parallel backoff.</title>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: companion volume of the Proceedings of HLT-NAACL 2003--short</booktitle>
<volume>2</volume>
<pages>4--6</pages>
<marker>Bilmes, Kirchhoff, </marker>
<rawString>Jeff A. Bilmes and Katrin Kirchhoff. Factored language models and generalized parallel backoff. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology: companion volume of the Proceedings of HLT-NAACL 2003--short papers-Volume 2: 4-6.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>A hierarchical phrase-based model for statistical machine translation.</title>
<date>2005</date>
<booktitle>In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>263--270</pages>
<contexts>
<context position="12124" citStr="Chiang, 2005" startWordPosition="1899" endWordPosition="1900">mantic span. We then perform word alignment on the modified bilingual sentences, and extract the new translation rules based on the new alignment, as shown in Figure 3(b) to Figure 3(c). Now the newly extracted rule “&lt;parallel, @E &gt; [XI H渐 and growing [XI ” is tagged with cohesive information. Thus, if the similar relationship parallel occurs in the test source sentence, this type of rule is more likely to be chosen to generate the cohesive word “and” during decoding because it is more discriminating than the original rules ([XI abilities of the new translation rules are calculated following (Chiang, 2005). 3.2 CSS-based Transfer model In general, according to formula (3), the translation quality based on the log-linear model is related tightly with the features chosen. Most translation systems adopt the features from a translation model, a language model, and sometimes a reordering model. To give a bonus to generating cohesive expressions during decoding, we have designed a special additional feature. The additional feature is represented as a probability calculated by a transfer model. Given the source CSS information, we want our transfer model to predict the most possible cohesive expressio</context>
<context position="23735" citStr="Chiang, 2005" startWordPosition="3827" endWordPosition="3828">nation that is ,; the first is; first is the;... adversative however , the ; but it is; ... flowing this is a; which is an; ... consequence so that the; to ensure that... Table 2. Chinese functional relations and their corresponding English left-frontier phrases learned by our transfer model. The noun phrases starting with a definite / indefinite word are filtered because they are unlikely to be the transitional phrases. 4.3 Results on SMT with Different Strategies For this work, we use an in-house decoder to build the SMT baseline; it combines the hierarchical phrase-based translation model (Chiang, 2005; Chiang, 2007) with the BTG (Wu, 1996) reordering model (Xiong et al., 2006; Zens and Ney, 2006; He et al., 2010). To test the effectiveness of the proposed models, we have compared the translation quality of different integration strategies. First, we adopted only the tagged-flattened rules in the hierarchical translation system. Next, we added the log probability generated by the transfer model as a feature into the baseline features. The baseline features include bi-directional phrase translation probabilities, bi-directional lexical translation probabilities, the BTG re-ordering features,</context>
</contexts>
<marker>Chiang, 2005</marker>
<rawString>David Chiang. 2005. A hierarchical phrase-based model for statistical machine translation. In Proceedings of the 43rd Annual Meeting of the Association for Computational Linguistics, pages 263– 270.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
</authors>
<title>Hierarchical phrase-based translation.</title>
<date>2007</date>
<journal>Computational Linguistics,</journal>
<pages>33--2</pages>
<contexts>
<context position="23750" citStr="Chiang, 2007" startWordPosition="3829" endWordPosition="3830"> ,; the first is; first is the;... adversative however , the ; but it is; ... flowing this is a; which is an; ... consequence so that the; to ensure that... Table 2. Chinese functional relations and their corresponding English left-frontier phrases learned by our transfer model. The noun phrases starting with a definite / indefinite word are filtered because they are unlikely to be the transitional phrases. 4.3 Results on SMT with Different Strategies For this work, we use an in-house decoder to build the SMT baseline; it combines the hierarchical phrase-based translation model (Chiang, 2005; Chiang, 2007) with the BTG (Wu, 1996) reordering model (Xiong et al., 2006; Zens and Ney, 2006; He et al., 2010). To test the effectiveness of the proposed models, we have compared the translation quality of different integration strategies. First, we adopted only the tagged-flattened rules in the hierarchical translation system. Next, we added the log probability generated by the transfer model as a feature into the baseline features. The baseline features include bi-directional phrase translation probabilities, bi-directional lexical translation probabilities, the BTG re-ordering features, and the langua</context>
</contexts>
<marker>Chiang, 2007</marker>
<rawString>David Chiang. 2007. Hierarchical phrase-based translation. Computational Linguistics, pages 33(2):201–228.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhengxian Gong</author>
<author>Min Zhang</author>
<author>Guodong Zhou</author>
</authors>
<title>Cache-based document-level statistical machine translation,</title>
<date>2011</date>
<booktitle>In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>909--919</pages>
<location>Edinburgh, Scotland, UK.</location>
<contexts>
<context position="1921" citStr="Gong et al., 2011" startWordPosition="263" endWordPosition="266">t decade, great progress has been made on statistical machine translation (SMT) models. However, these translations still suffer from poor readability, especially translations of compound-complex sentences. One of the main reasons may be that most existing models concentrate more on producing well-translated local sentence fragments, but largely ignore global cohesion between the fragments. Generally, cohesion, including lexical and grammatical cohesion, contributes much to the understandability and smoothness of a text. Recently, researchers have begun addressing the lexical cohesion of SMT (Gong et al., 2011; Xiao et al., 2011; Wong and Kit, 2012; Xiong, 2013). These efforts focus mainly on the cooccurrence of lexical items in a similar environment. Grammatical cohesion1 (Halliday and Hassan, 1976) in SMT has been little mentioned in previous work. Translations without grammatical cohesion is hard to read, mostly due to loss of cohesive and transitional expressions between two sentence fragments. Thus, generating transitional expressions is necessary for achieving grammatical cohesion. However, it is not easy to produce such transitional expressions in SMT. As an example, consider the Chinese-to-</context>
<context position="30277" citStr="Gong et al., 2011" startWordPosition="4838" endWordPosition="4841">hich” are not linguistic conjunctions. We would like to call them “generalized” conjunctions, because they tie semantic fragments together, analogously to linguistic conjunctions. 5 Related Work Improving cohesion for complex sentences or discourse translation has attracted much attention in recent years. Such research efforts can be roughly divided into two groups: 1) research on lexical cohesion, which mainly contributes to the selection of generated target words; 2) efforts to improve the grammatical cohesion, such as disambiguation of references and connectives. In lexical cohesion work, (Gong et al., 2011; Xiao et al., 2011; Wong and Kit, 2012) built discourse-based models to ensure lexical cohesion or consistency. In (Xiong et al., 2013a), three different features were designed to capture the lexical cohesion for document-level machine translation. (Xiong et al., 2013b) incorporated lexical-chain-based models (Morris and Hirst, 1991) into machine translation. They generated the target lexical chains based on the source 34 33 32 31 857 Source 过去三年中,已有三对染色体完成排序, 包括第二十对、第二十一对和第二十二 对 。 Reference In the past three years, the sequencing of three chromosomes has been completed, including chromosomes</context>
</contexts>
<marker>Gong, Zhang, Zhou, 2011</marker>
<rawString>Zhengxian Gong, Min Zhang, and Guodong Zhou. Cache-based document-level statistical machine translation, 2011, Edinburgh, Scotland, UK. In Proceedings of the 2011 Conference on Empirical Methods in Natural Language Processing, pages 909–919.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liane Guillou</author>
</authors>
<title>Analysing lexical consistency in translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Workshop on Discourse in Machine Translation,</booktitle>
<pages>10--18</pages>
<location>Sofia</location>
<marker>Guillou, 2013</marker>
<rawString>Liane Guillou. 2013. Analysing lexical consistency in translation. In Proceedings of the Workshop on Discourse in Machine Translation, pages 10–18, Sofia</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael A K Halliday</author>
<author>R Hasan</author>
</authors>
<title>Cohesion in English.</title>
<date>1976</date>
<publisher>Longman.</publisher>
<location>London:</location>
<marker>Halliday, Hasan, 1976</marker>
<rawString>Michael A.K. Halliday, Hasan R. Cohesion in English. 1976. London: Longman.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Zhongjun He</author>
<author>Yao Meng</author>
<author>Hao Yu</author>
</authors>
<title>Maximum Entropy Based Phrase Reordering for Hierarchical Phrase-based Translation.</title>
<date>2010</date>
<booktitle>In Proc. of the Conf. on Empirical Methods for Natural Language Processing (EMNLP),</booktitle>
<pages>555--563</pages>
<contexts>
<context position="23849" citStr="He et al., 2010" startWordPosition="3846" endWordPosition="3849"> which is an; ... consequence so that the; to ensure that... Table 2. Chinese functional relations and their corresponding English left-frontier phrases learned by our transfer model. The noun phrases starting with a definite / indefinite word are filtered because they are unlikely to be the transitional phrases. 4.3 Results on SMT with Different Strategies For this work, we use an in-house decoder to build the SMT baseline; it combines the hierarchical phrase-based translation model (Chiang, 2005; Chiang, 2007) with the BTG (Wu, 1996) reordering model (Xiong et al., 2006; Zens and Ney, 2006; He et al., 2010). To test the effectiveness of the proposed models, we have compared the translation quality of different integration strategies. First, we adopted only the tagged-flattened rules in the hierarchical translation system. Next, we added the log probability generated by the transfer model as a feature into the baseline features. The baseline features include bi-directional phrase translation probabilities, bi-directional lexical translation probabilities, the BTG re-ordering features, and the language model feature. The tri-gram leftfrontier phrase was adopted in the experiment. Then the probabil</context>
</contexts>
<marker>He, Meng, Yu, 2010</marker>
<rawString>Zhongjun He, Yao Meng, and Hao Yu. 2010b. Maximum Entropy Based Phrase Reordering for Hierarchical Phrase-based Translation. In Proc. of the Conf. on Empirical Methods for Natural Language Processing (EMNLP), pages 555–563.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Annie Louis</author>
<author>Ani Nenkova</author>
</authors>
<title>A coherence model based on syntactic patterns.</title>
<date>2012</date>
<booktitle>In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning,</booktitle>
<pages>1157--1168</pages>
<location>Jeju Island, Korea,</location>
<marker>Louis, Nenkova, 2012</marker>
<rawString>Annie Louis and Ani Nenkova. 2012. A coherence model based on syntactic patterns. In Proceedings of the 2012 Joint Conference on Empirical Methods in Natural Language Processing and Computational Natural Language Learning, pages 1157– 1168, Jeju Island, Korea, July.</rawString>
</citation>
<citation valid="true">
<authors>
<author>William C Mann</author>
<author>Sandra A Thompson</author>
</authors>
<title>Rhetorical structure theory: Toward a functional theory of text organization.</title>
<date>1988</date>
<tech>Text, 8(3):243–281.</tech>
<contexts>
<context position="4997" citStr="Mann and Thompson, 1988" startWordPosition="742" endWordPosition="745">igure 2: The compound-complex sentence structure of the Chinese sentence in Figure 1. Formally, given a compound-complex sentence structure (CSS), each node in the CSS can be represented as a tuple R—[(s„el),...(sr,er),...,(s,,e,)] . represents the relationship, which has children. For each child of , a pair records its start and end eus. For example, adversative-[(1,2), (3,3)J in Figure 2 means that two children are controlled by the relationship adversative, and the left child consists of eu1 and eu2, while the right child contains only eu3. CSS has much in common with Rhetorical Structure (Mann and Thompson, 1988) in English, which also describe the semantic relation between discourse units. But the Rhetorical Structure involves much richer relations on the document-level, and little corpus is open for Chinese. In the following, we will describe in detail how to utilize such CSS information for modelling in SMT. parallel-[(1,1), (2,2)] r5W �� V5� � nfiN TW&amp;quot;r , eu1 eu2 V53� XIA Vff 3E Wr T , eu3 AR 8 L �� � ��� � eu4 i`A F1WT tffj� , adversative-[(1,2),(3,3)] known online translators, but find that it is very difficult to generate the target transitional expressions, especially when there is no explicit</context>
</contexts>
<marker>Mann, Thompson, 1988</marker>
<rawString>William C Mann and Sandra A Thompson. 1988. Rhetorical structure theory: Toward a functional theory of text organization. Text, 8(3):243–281.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ruslan Mitkov</author>
<author>Sung-Kwon Choi</author>
<author>Randall Sharp</author>
</authors>
<title>Anaphora resolution in Machine Translation.</title>
<date>1995</date>
<booktitle>In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation.</booktitle>
<contexts>
<context position="32858" citStr="Mitkov et al. (1995)" startWordPosition="5235" endWordPosition="5238"> 2000), but their models worked only for explicit functional relations, and they were concerned mainly with the translation integrity of semantic span rather than cohesion. (Meyer and PopescuBelis, 2012) used sense-labeled discourse connectives for machine translation from English to French. They added the labels assigned to connectives as an additional input to an SMT system, but their experimental results show that the improvements under the evaluation metric of BLEU were not significant. (Nagard and Koehn, 2010) addresses the problems of reference or anaphora resolution inspired by work of Mitkov et al. (1995). To the best of our knowledge, our work is the first attempt to exploit the source functional relationship to generate the target transitional expressions for grammatical cohesion, and we have successfully incorporated the proposed models into an SMT system with significant improvement of BLEU metrics. 6 Conclusion In this paper, we focus on capturing cohesion information to enhance the grammatical cohesion of machine translation. By taking the source CSS into consideration, we build bridges to connect the source functional relationships in CSS to target transitional expressions; such a proce</context>
</contexts>
<marker>Mitkov, Choi, Sharp, 1995</marker>
<rawString>Ruslan Mitkov, Sung-Kwon Choi, and Randall Sharp. 1995. Anaphora resolution in Machine Translation. In Proceedings of the Sixth International Conference on Theoretical and Methodological Issues in Machine Translation.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Thomas Meyer</author>
<author>Andrei Popescu-Belis</author>
</authors>
<title>Using sense-labeled discourse connectives for statistical machine translation,</title>
<date>2012</date>
<booktitle>In Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation (ESIRMT) and Hybrid Approaches to Machine Translation (HyTra),</booktitle>
<pages>129--138</pages>
<marker>Meyer, Popescu-Belis, 2012</marker>
<rawString>Thomas Meyer and Andrei Popescu-Belis. Using sense-labeled discourse connectives for statistical machine translation, 2012, In Proceedings of the Joint Workshop on Exploiting Synergies between Information Retrieval and Machine Translation (ESIRMT) and Hybrid Approaches to Machine Translation (HyTra), pages:129-138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jane Morris</author>
<author>Graeme Hirst</author>
</authors>
<title>Lexical cohesion computed by thesaural relations as an indicator of the structure of text.</title>
<date>1991</date>
<journal>Comput. Linguist.,</journal>
<volume>17</volume>
<issue>1</issue>
<contexts>
<context position="30613" citStr="Morris and Hirst, 1991" startWordPosition="4886" endWordPosition="4889">an be roughly divided into two groups: 1) research on lexical cohesion, which mainly contributes to the selection of generated target words; 2) efforts to improve the grammatical cohesion, such as disambiguation of references and connectives. In lexical cohesion work, (Gong et al., 2011; Xiao et al., 2011; Wong and Kit, 2012) built discourse-based models to ensure lexical cohesion or consistency. In (Xiong et al., 2013a), three different features were designed to capture the lexical cohesion for document-level machine translation. (Xiong et al., 2013b) incorporated lexical-chain-based models (Morris and Hirst, 1991) into machine translation. They generated the target lexical chains based on the source 34 33 32 31 857 Source 过去三年中,已有三对染色体完成排序, 包括第二十对、第二十一对和第二十二 对 。 Reference In the past three years, the sequencing of three chromosomes has been completed, including chromosomes 20 , 21 , and 22 . Baseline In the past three years , now has three terms of the completion of the chromosomes , 20 , 21 and 22 . Improved In the past three years , there are three chromosomes to accomplish , including 20 , 21 and 22 . Source 上述主张构成了一个中国原则的基本涵义,核心是维护中国的主权和领土完整。 Reference The above-mentioned propositions constitute th</context>
</contexts>
<marker>Morris, Hirst, 1991</marker>
<rawString>Jane Morris and Graeme Hirst. 1991. Lexical cohesion computed by thesaural relations as an indicator of the structure of text. Comput. Linguist., 17(1):21–48, March.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ronan L Nagard</author>
<author>Philipp Koehn</author>
</authors>
<title>Aiding pronoun translation with co-reference resolution,</title>
<date>2010</date>
<booktitle>In proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR,</booktitle>
<pages>252--261</pages>
<contexts>
<context position="32758" citStr="Nagard and Koehn, 2010" startWordPosition="5219" endWordPosition="5222">ee-tostring translation method for complex sentences with explicit relations inspired by (Marcu et al., 2000), but their models worked only for explicit functional relations, and they were concerned mainly with the translation integrity of semantic span rather than cohesion. (Meyer and PopescuBelis, 2012) used sense-labeled discourse connectives for machine translation from English to French. They added the labels assigned to connectives as an additional input to an SMT system, but their experimental results show that the improvements under the evaluation metric of BLEU were not significant. (Nagard and Koehn, 2010) addresses the problems of reference or anaphora resolution inspired by work of Mitkov et al. (1995). To the best of our knowledge, our work is the first attempt to exploit the source functional relationship to generate the target transitional expressions for grammatical cohesion, and we have successfully incorporated the proposed models into an SMT system with significant improvement of BLEU metrics. 6 Conclusion In this paper, we focus on capturing cohesion information to enhance the grammatical cohesion of machine translation. By taking the source CSS into consideration, we build bridges to</context>
</contexts>
<marker>Nagard, Koehn, 2010</marker>
<rawString>Ronan L Nagard and Philipp Koehn. 2010, Aiding pronoun translation with co-reference resolution, In proceedings of the Joint Fifth Workshop on Statistical Machine Translation and MetricsMATR, pages 252-261.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Franz J Och</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative training and maximum entropy models for statistical machine translation.</title>
<date>2002</date>
<booktitle>In Proc. of ACL,</booktitle>
<pages>295--302</pages>
<contexts>
<context position="8408" citStr="Och and Ney (2002)" startWordPosition="1284" endWordPosition="1287">mentary units (eus), and also depicts the hierarchical relations among eus. 2 They are parallel, consequence, progressive, alternative, causal, purpose, hypothesis, condition, adversative, explanation, and flowing relationships. 3 A semantic span can include one or more eus. 851 3 Modelling Our purpose is to enhance the grammatical cohesion by exploiting the source CSS information. Therefore, theoretically, the conditional probability of a target translation es conditioned on the source CSS-based tree ft is given by , and the final translation is obtained with the following formula: Following Och and Ney (2002), our model is framed as a log-linear model: where is a feature with weight . Then, the best translation is: Our models make use of CSS with two strategies: 1) CSS-based translation model: following formula (1), we obtain the cohesion information by modifying the translation rules with their probabilities based on word alignments between the source CSS-tree and the target string; 2) CSS-based transfer model: following formula (3), we introduce a transfer score to encourage the decoder to generate transitional words and phrases; the score is utilized as an additional feature in the log-linear m</context>
</contexts>
<marker>Och, Ney, 2002</marker>
<rawString>Franz J Och and Hermann Ney. 2002. Discriminative training and maximum entropy models for statistical machine translation. In Proc. of ACL, pages 295–302.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kishore Papineni</author>
<author>Salim Roukos</author>
<author>Todd Ward</author>
</authors>
<title>BLEU: a method for automatic evaluation of machine translation.</title>
<date>2002</date>
<booktitle>In proceedings of the 40th</booktitle>
<pages>311--318</pages>
<contexts>
<context position="21362" citStr="Papineni et al. 2002" startWordPosition="3445" endWordPosition="3448">e grow-diag-final-and strategy with GIZA++. Before training the CSS-based transfer model, the alignment for transfer model is modified by our dynamic cleaning method. During the cleaning process, the maximum size of hypothesis is limited to 5. A 5-gram language model is trained with SRILM5 on the combination of the Xinhua portion of the English Gigaword corpus combined with the English part of FBIS. For tuning and testing, we use NIST03 evaluation data as the development set. NIST04/05/06, CWMT08-Development 6 and CWMT08-Evaluation data are used for testing under the measure metric of BLEU-4 (Papineni et al. 2002) with the shortest length penalty. Table 1 shows how the CSS is distributed in all testing sets. According to the statistics in Table 1, we see that CSS is really widely distributed in the NIST and CWMT corpora, which implies that the translation quality may benefit substantially from the CSS information, if it is well considered in SMT. Total CSS Ratio(%) NIST04 1,788 1,307 73.1 NIST05 1,082 849 78.5 NIST06 1,000 745 74.5 CWMT08-Dev. 1,006 818 81.3 CWMT08-Eval. 1,006 818 81.3 Table 1. The numbers of sentences and the CSS ratios of all sentences. CWMT08-Dev. is short for CWMT08 Development dat</context>
</contexts>
<marker>Papineni, Roukos, Ward, 2002</marker>
<rawString>Kishore Papineni, Salim Roukos, Todd Ward, et al. 2002, BLEU: a method for automatic evaluation of machine translation. In proceedings of the 40th annual meeting on association for computational linguistics. pages: 311-318.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rashmi Prasad</author>
<author>Nikhil Dinesh</author>
<author>Alan Lee</author>
<author>Eleni Miltsakaki</author>
<author>Livio Robaldo</author>
<author>Aravind Joshi</author>
<author>Bonnie Webber</author>
</authors>
<title>The Penn Discourse Treebank 2.0.</title>
<date>2008</date>
<booktitle>In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC</booktitle>
<marker>Prasad, Dinesh, Lee, Miltsakaki, Robaldo, Joshi, Webber, 2008</marker>
<rawString>Rashmi Prasad, Nikhil Dinesh, Alan Lee, Eleni Miltsakaki, Livio Robaldo, Aravind Joshi, and Bonnie Webber. 2008. The Penn Discourse Treebank 2.0. In Proceedings of the 6th International Conference on Language Resources and Evaluation (LREC 2008).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Williams Ray</author>
</authors>
<title>Teaching the Recognition of Cohesive Ties in Reading a Foreign,</title>
<date>1983</date>
<volume>1</volume>
<issue>1</issue>
<pages>35--52</pages>
<marker>Ray, 1983</marker>
<rawString>Williams Ray. Teaching the Recognition of Cohesive Ties in Reading a Foreign, 1983. Reading in a foreign language, 1(1), pages: 35-52.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Radu Soricut</author>
<author>Daniel Marcu</author>
</authors>
<title>Sentence level discourse parsing using syntactic and lexical information.</title>
<date>2003</date>
<booktitle>In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume</booktitle>
<volume>1</volume>
<pages>149--156</pages>
<marker>Soricut, Marcu, 2003</marker>
<rawString>Radu Soricut and Daniel Marcu. 2003. Sentence level discourse parsing using syntactic and lexical information. In Proceedings of the 2003 Conference of the North American Chapter of the Association for Computational Linguistics on Human Language Technology-Volume 1, pages 149–156.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mei Tu</author>
<author>Yu Zhou</author>
<author>Chengqing Zong</author>
</authors>
<title>2013a, A Novel Translation Framework Based on Rhetorical Structure Theory.</title>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, short paper,</booktitle>
<pages>370--374</pages>
<location>Sofia, Bulgaria,</location>
<marker>Tu, Zhou, Zong, </marker>
<rawString>Mei Tu, Yu Zhou, and Chengqing Zong. 2013a, A Novel Translation Framework Based on Rhetorical Structure Theory. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics, short paper, Sofia, Bulgaria, pages 370–374.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Mei Tu</author>
<author>Yu Zhou</author>
</authors>
<title>Chengqing Zong. 2013b, Automatically Parsing Chinese Discourse Based on Maximum Entropy.</title>
<booktitle>In The 2nd Conference on Natural Language Processing &amp; Chinese Computing.</booktitle>
<marker>Tu, Zhou, </marker>
<rawString>Mei Tu, Yu Zhou, Chengqing Zong. 2013b, Automatically Parsing Chinese Discourse Based on Maximum Entropy. In The 2nd Conference on Natural Language Processing &amp; Chinese Computing.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ashish Vaswani</author>
<author>Liang Huang</author>
<author>David Chiang</author>
<author>L Huang</author>
<author>D Chiang</author>
</authors>
<title>Smaller alignment models for better translations: unsupervised word alignment with the l 0-norm.</title>
<date>2012</date>
<booktitle>In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,pages</booktitle>
<pages>311--319</pages>
<marker>Vaswani, Huang, Chiang, Huang, Chiang, 2012</marker>
<rawString>Ashish Vaswani, Liang Huang and David Chiang, Huang L, Chiang D. 2012, Smaller alignment models for better translations: unsupervised word alignment with the l 0-norm. In Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1,pages 311-319.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Tong Xiao</author>
<author>Jingbo Zhu</author>
<author>Shujie Yao</author>
<author>Hao Zhang</author>
</authors>
<title>Document-level consistency verification</title>
<booktitle>in maIn Proceedings of the 2011 MT summit XIII,</booktitle>
<pages>131--138</pages>
<marker>Xiao, Zhu, Yao, Zhang, </marker>
<rawString>Tong Xiao, Jingbo Zhu, Shujie Yao, and Hao Zhang. Document-level consistency verification in maIn Proceedings of the 2011 MT summit XIII, pages 131–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Qun Liu</author>
<author>Shouxun Lin</author>
</authors>
<title>Maximum entropy based phrase reordering model for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>521--528</pages>
<contexts>
<context position="23811" citStr="Xiong et al., 2006" startWordPosition="3838" endWordPosition="3841"> the ; but it is; ... flowing this is a; which is an; ... consequence so that the; to ensure that... Table 2. Chinese functional relations and their corresponding English left-frontier phrases learned by our transfer model. The noun phrases starting with a definite / indefinite word are filtered because they are unlikely to be the transitional phrases. 4.3 Results on SMT with Different Strategies For this work, we use an in-house decoder to build the SMT baseline; it combines the hierarchical phrase-based translation model (Chiang, 2005; Chiang, 2007) with the BTG (Wu, 1996) reordering model (Xiong et al., 2006; Zens and Ney, 2006; He et al., 2010). To test the effectiveness of the proposed models, we have compared the translation quality of different integration strategies. First, we adopted only the tagged-flattened rules in the hierarchical translation system. Next, we added the log probability generated by the transfer model as a feature into the baseline features. The baseline features include bi-directional phrase translation probabilities, bi-directional lexical translation probabilities, the BTG re-ordering features, and the language model feature. The tri-gram leftfrontier phrase was adopte</context>
</contexts>
<marker>Xiong, Liu, Lin, 2006</marker>
<rawString>Deyi Xiong, Qun Liu, and Shouxun Lin. 2006. Maximum entropy based phrase reordering model for statistical machine translation. In Proceedings of the 44th Annual Meeting of the Association for Computational Linguistics, pages 521–528.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Guosheng Ben</author>
<author>Min Zhang</author>
<author>Yajuan Lv</author>
<author>Qun Liu</author>
</authors>
<title>(a). Modeling lexical cohesion for document-level machine translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI-13),</booktitle>
<location>Beijing, China,</location>
<contexts>
<context position="30412" citStr="Xiong et al., 2013" startWordPosition="4861" endWordPosition="4864">ther, analogously to linguistic conjunctions. 5 Related Work Improving cohesion for complex sentences or discourse translation has attracted much attention in recent years. Such research efforts can be roughly divided into two groups: 1) research on lexical cohesion, which mainly contributes to the selection of generated target words; 2) efforts to improve the grammatical cohesion, such as disambiguation of references and connectives. In lexical cohesion work, (Gong et al., 2011; Xiao et al., 2011; Wong and Kit, 2012) built discourse-based models to ensure lexical cohesion or consistency. In (Xiong et al., 2013a), three different features were designed to capture the lexical cohesion for document-level machine translation. (Xiong et al., 2013b) incorporated lexical-chain-based models (Morris and Hirst, 1991) into machine translation. They generated the target lexical chains based on the source 34 33 32 31 857 Source 过去三年中,已有三对染色体完成排序, 包括第二十对、第二十一对和第二十二 对 。 Reference In the past three years, the sequencing of three chromosomes has been completed, including chromosomes 20 , 21 , and 22 . Baseline In the past three years , now has three terms of the completion of the chromosomes , 20 , 21 and 22 . Impr</context>
</contexts>
<marker>Xiong, Ben, Zhang, Lv, Liu, 2013</marker>
<rawString>Deyi Xiong, Guosheng Ben, Min Zhang, Yajuan Lv, and Qun Liu. 2013 (a). Modeling lexical cohesion for document-level machine translation. In Proceedings of the Twenty-Third International Joint Conference on Artificial Intelligence (IJCAI-13), Beijing, China, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Deyi Xiong</author>
<author>Ding Yang</author>
<author>Min Zhang</author>
<author>Chew Lim Tan</author>
</authors>
<title>(b). Lexical Chain Based Cohesion Models for Document-Level Statistical Machine Translation.</title>
<date>2013</date>
<booktitle>In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing,</booktitle>
<pages>1563--1573</pages>
<contexts>
<context position="30412" citStr="Xiong et al., 2013" startWordPosition="4861" endWordPosition="4864">ther, analogously to linguistic conjunctions. 5 Related Work Improving cohesion for complex sentences or discourse translation has attracted much attention in recent years. Such research efforts can be roughly divided into two groups: 1) research on lexical cohesion, which mainly contributes to the selection of generated target words; 2) efforts to improve the grammatical cohesion, such as disambiguation of references and connectives. In lexical cohesion work, (Gong et al., 2011; Xiao et al., 2011; Wong and Kit, 2012) built discourse-based models to ensure lexical cohesion or consistency. In (Xiong et al., 2013a), three different features were designed to capture the lexical cohesion for document-level machine translation. (Xiong et al., 2013b) incorporated lexical-chain-based models (Morris and Hirst, 1991) into machine translation. They generated the target lexical chains based on the source 34 33 32 31 857 Source 过去三年中,已有三对染色体完成排序, 包括第二十对、第二十一对和第二十二 对 。 Reference In the past three years, the sequencing of three chromosomes has been completed, including chromosomes 20 , 21 , and 22 . Baseline In the past three years , now has three terms of the completion of the chromosomes , 20 , 21 and 22 . Impr</context>
</contexts>
<marker>Xiong, Yang, Zhang, Tan, 2013</marker>
<rawString>Deyi Xiong, Ding Yang, Min Zhang and Chew Lim Tan, 2013 (b). Lexical Chain Based Cohesion Models for Document-Level Statistical Machine Translation. In Proceedings of the 2013 Conference on Empirical Methods in Natural Language Processing, pages: 1563-1573.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Richard Zens</author>
<author>Hermann Ney</author>
</authors>
<title>Discriminative reordering models for statistical machine translation.</title>
<date>2006</date>
<booktitle>In Proceedings of theWorkshop on Statistical Machine Translation,</booktitle>
<pages>55--63</pages>
<contexts>
<context position="23831" citStr="Zens and Ney, 2006" startWordPosition="3842" endWordPosition="3845">. flowing this is a; which is an; ... consequence so that the; to ensure that... Table 2. Chinese functional relations and their corresponding English left-frontier phrases learned by our transfer model. The noun phrases starting with a definite / indefinite word are filtered because they are unlikely to be the transitional phrases. 4.3 Results on SMT with Different Strategies For this work, we use an in-house decoder to build the SMT baseline; it combines the hierarchical phrase-based translation model (Chiang, 2005; Chiang, 2007) with the BTG (Wu, 1996) reordering model (Xiong et al., 2006; Zens and Ney, 2006; He et al., 2010). To test the effectiveness of the proposed models, we have compared the translation quality of different integration strategies. First, we adopted only the tagged-flattened rules in the hierarchical translation system. Next, we added the log probability generated by the transfer model as a feature into the baseline features. The baseline features include bi-directional phrase translation probabilities, bi-directional lexical translation probabilities, the BTG re-ordering features, and the language model feature. The tri-gram leftfrontier phrase was adopted in the experiment.</context>
</contexts>
<marker>Zens, Ney, 2006</marker>
<rawString>Richard Zens and Hermann Ney. 2006. Discriminative reordering models for statistical machine translation. In Proceedings of theWorkshop on Statistical Machine Translation, pages 55–63.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>