<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000005">
<title confidence="0.843957">
Not a simple yes or no: Uncertainty in indirect answers
</title>
<author confidence="0.631759">
Marie-Catherine de Marneffe, Scott Grimm and Christopher Potts
</author>
<affiliation confidence="0.7379165">
Linguistics Department
Stanford University
</affiliation>
<address confidence="0.910188">
Stanford, CA 94305
</address>
<email confidence="0.997269">
imcdm,sgrimm,cgpottsl@stanford.edu
</email>
<sectionHeader confidence="0.993846" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999939038461538">
There is a long history of using logic to
model the interpretation of indirect speech
acts. Classical logical inference, how-
ever, is unable to deal with the combina-
tions of disparate, conflicting, uncertain
evidence that shape such speech acts in
discourse. We propose to address this by
combining logical inference with proba-
bilistic methods. We focus on responses
to polar questions with the following prop-
erty: they are neither yes nor no, but
they convey information that can be used
to infer such an answer with some de-
gree of confidence, though often not with
enough confidence to count as resolving.
We present a novel corpus study and asso-
ciated typology that aims to situate these
responses in the broader class of indirect
question–answer pairs (IQAPs). We then
model the different types of IQAPs using
Markov logic networks, which combine
first-order logic with probabilities, empha-
sizing the ways in which this approach al-
lows us to model inferential uncertainty
about both the context of utterance and in-
tended meanings.
</bodyText>
<sectionHeader confidence="0.999334" genericHeader="keywords">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999752190476191">
Clark (1979), Perrault and Allen (1980), and Allen
and Perrault (1980) study indirect speech acts,
identifying a wide range of factors that govern how
speakers convey their intended messages and how
hearers seek to uncover those messages. Prior dis-
course conditions, the relationship between the lit-
eral meaning and the common ground, and spe-
cific lexical, constructional, and intonational cues
all play a role. Green and Carberry (1992, 1994)
provide an extensive computational model that in-
terprets and generates indirect answers to polar
questions. Their model focuses on inferring cat-
egorical answers, making use of discourse plans
and coherence relations.
This paper extends such work by recasting the
problem in terms of probabilistic modeling. We
focus on the interpretation of indirect answers
where the respondent does not answer with yes or
no, but rather gives information that can be used
by the hearer to infer such an answer only with
some degree of certainty, as in (1).
</bodyText>
<listItem confidence="0.5080005">
(1) A: Is Sue at work?
B: She is sick with the flu.
</listItem>
<bodyText confidence="0.999789857142857">
In this case, whether one can move from the re-
sponse to a yes or no is uncertain. Based on typical
assumptions about work and illness, A might take
B’s response as indicating that Sue is at home, but
B’s response could be taken differently depending
on Sue’s character — B could be reproaching Sue
for her workaholic tendencies, which risk infect-
ing the office, or B could be admiring Sue’s stead-
fast character. What A actually concludes about
B’s indirect reply will be based on some combi-
nation of this disparate, partially conflicting, un-
certain evidence. The plan and logical inference
model of Green and Carberry falters in the face of
such collections of uncertain evidence. However,
natural dialogues are often interpreted in the midst
of uncertain and conflicting signals. We therefore
propose to enrich a logical inference model with
probabilistic methods to deal with such cases.
This study addresses the phenomenon of indi-
rect question–answer pairs (IQAP), such as in (1),
from both empirical and engineering perspectives.
</bodyText>
<note confidence="0.710126">
Proceedings of SIGDIAL 2009: the 10th Annual Meeting of the Special Interest Group in Discourse and Dialogue, pages 136–143,
</note>
<affiliation confidence="0.662623">
Queen Mary University of London, September 2009. c�2009 Association for Computational Linguistics
</affiliation>
<page confidence="0.999001">
136
</page>
<bodyText confidence="0.999986454545455">
First, we undertake a corpus study of polar ques-
tions in dialogue to gather naturally occurring in-
stances and to determine how pervasive indirect
answers that indicate uncertainty are in a natu-
ral setting (section 2). From this empirical base,
we provide a classification of IQAPs which makes
a new distinction between fully- and partially-
resolving answers (section 3). We then show how
inference in Markov logic networks can success-
fully model the reasoning involved in both types
of IQAPs (section 4).
</bodyText>
<sectionHeader confidence="0.862625" genericHeader="introduction">
2 Corpus study
</sectionHeader>
<bodyText confidence="0.943142029411765">
Previous corpus studies looked at how pervasive
indirect answers to yes/no questions are in dia-
logue. Stenstr¨om (1984) analyzed 25 face-to-face
and telephone conversations and found that 13%
of answers to polar questions do not contain an
explicit yes or no term. In a task dialogue, Hockey
et al. (1997) found 38% of the responses were
IQAPs. (This higher percentage might reflect the
genre difference in the corpora used: task dialogue
vs. casual conversations.) These studies, how-
ever, were not concerned with how confidently one
could infer a yes or no from the response given.
We therefore conducted a corpus study to ana-
lyze the types of indirect answers. We used the
Switchboard Dialog Act Corpus (Jurafsky et al.,
1997) which has been annotated for approximately
60 basic dialog acts, clustered into 42 tags. We
are concerned only with direct yes/no questions,
and not with indirect ones such as “May I remind
you to take out the garbage?” (Clark, 1979; Per-
rault and Allen, 1980). From 200 5-minute con-
versations, we extracted yes/no questions (tagged
“qy”) and their answers, but discarded tag ques-
tions as well as disjunctive questions, such as in
(2), since these do not necessarily call for a yes
or no response. We also did not take into account
questions that were lost in the dialogue, nor ques-
tions that did not really require an answer (3). This
yielded a total of 623 yes/no questions.
(2) [sw 0018 4082]
A: Do you, by mistakes, do you mean just
like honest mistakes
A: or do you think they are deliberate sorts
of things?
</bodyText>
<listItem confidence="0.8105555">
B: Uh, I think both.
(3) [sw 0070 3435]
A: How do you feel about your game?
A: I guess that’s a good question?
B: Uh, well, I mean I’m not a serious
golfer at all.
</listItem>
<bodyText confidence="0.993894740740741">
To identify indirect answers, we looked at the
answer tags. The distribution of answers is given
in Table 1. We collapsed the tags into 6 categories.
Category I contains direct yes/no answers as well
as “agree” answers (e.g., That’s exactly it.). Cate-
gory II includes statement–opinion and statement-
non-opinion: e.g., I think it’s great, Me I’m in the
legal department, respectively. Affirmative non-
yes answers and negative non-no answers form
category III. Other answers such as I don’t know
are in category IV. In category V, we put utterances
that avoid answering the question: by holding (I’m
drawing a blank), by returning the question — wh-
question or rhetorical question (Who would steal
a newspaper?) — or by using a backchannel in
question form (Is that right?). Finally, category
VI contains dispreferred answers (Schegloff et al.,
1977; Pomerantz, 1984).
We hypothesized that the phenomenon we are
studying would appear in categories II, III and VI.
However, some of the “na/ng” answers are dis-
guised yes/no answers, such as Right, I think so,
or Not really, and as such do not interest us. In the
case of “sv/sd” and “nd” answers, many answers
include reformulation, question avoidance (see 4),
or a change of framing (5). All these cases are not
really at issue for the question we are addressing.
</bodyText>
<listItem confidence="0.928563538461538">
(4) [sw 0177 2759]
A: Have you ever been drug tested?
B: Um, that’s a good question.
(5) [sw 0046 4316]
A: Is he the guy wants to, like, deregulate
heroin, or something?
B: Well, what he wants to do is take all the
money that, uh, he gets for drug
enforcement and use it for, uh, drug
education.
A: Uh-huh.
B: And basically, just, just attack the
problem at the demand side.
</listItem>
<page confidence="0.988802">
137
</page>
<table confidence="0.5718185625">
Definition
I yes/no answers
II statements
III affirmative/negative non-yes/no answers
IV other answers
V avoid answering
VI dispreferred answers
Total
Tag Total
ny/nn/aa 341
sv/sd 143
na/ng 91
no 21
ˆh/qw/qh/bh 18
nd 9
623
</table>
<tableCaption confidence="0.965252">
Table 1: Distribution of answer tags to yes/no questions.
</tableCaption>
<bodyText confidence="0.9871353">
(6) [sw 0046 4316]
A: That was also civil?
B: The other case was just traffic, and you
know, it was seat belt law.
We examined by hand all yes/no questions for
IQAPs and found 88 examples (such as (6), and
(7)–(11)), which constitutes thus 14% of the total
answers to direct yes/no questions, a figure simi-
lar to those of Stenstr¨om (1984). The next section
introduces our classification of answers.
</bodyText>
<sectionHeader confidence="0.88732" genericHeader="method">
3 Typology of indirect answers
</sectionHeader>
<bodyText confidence="0.999946192307692">
We can adduce the general space of IQAPs from
the data assembled in section 2 (see also Bolinger,
1978; Clark, 1979). One point of departure is that,
in cooperative dialogues, a response to a ques-
tion counts as an answer only when some relation
holds between the content of the response and the
semantic desiderata of the question. This is suc-
cinctly formulated in the relation IQAP proposed
by Asher and Lascarides (2003), p. 403:
IQAP(α,Q) holds only if there is a true
direct answer p to the question Qα�, and
the questioner can infer p from Q0� in
the utterance context.
The apparent emphasis on truth can be set aside
for present purposes; Asher and Lascarides’s no-
tions of truth are heavily relativized to the current
discourse conditions. This principle hints at two
dimensions of IQAPs which must be considered,
and upon which we can establish a classification:
(i) the type of answer which the proffered response
provides, and (ii) the basis on which the inferences
are performed. The typology established here ad-
heres to this, distinguishing between fully- and
partially-resolving answers as well as between the
types of knowledge used in the inference (logical,
linguistic, common ground/world).
</bodyText>
<subsectionHeader confidence="0.999233">
3.1 Fully-resolving responses
</subsectionHeader>
<bodyText confidence="0.9916315">
An indirect answer can fully resolve a question
by conveying information that stands in an inclu-
sion relation to the direct answer: if q C_ p (or
gyp), then updating with the response q also re-
solves the question with p (or gyp), assuming the
questioner knows that the inclusion relation holds
between q and p. The inclusion relation can be
based on logical relations, as in (7), where the re-
sponse is an “over-answer”, i.e., a response where
more information is given than is strictly neces-
sary to resolve the question. Hearers supply more
information than strictly asked for when they rec-
ognize that the speaker’s intentions are more gen-
eral than the question posed might suggest. In (7),
the most plausible intention behind the query is
to know more about B’s family. The hearer can
also identify the speaker’s plan and any necessary
information for its completion, which he then pro-
vides (Allen and Perrault, 1980).
(7) [sw 0001 4325]
A: Do you have kids?
B: I have three.
While logical relations between the content of
the question and the response suffice to treat exam-
ples such as (7), other over-answers often require
substantial amounts of linguistic and/or world-
knowledge to allow the inference to go through,
as in (8) and (9).
</bodyText>
<listItem confidence="0.9189645">
(8) [sw 0069 3144]
A: Was that good?
B: Hysterical. We laughed so hard.
(9) [sw 0057 3506]
A: Is it in Dallas?
B: Uh, it’s in Lewisville.
</listItem>
<page confidence="0.99466">
138
</page>
<bodyText confidence="0.9999693">
In the case of (8), a system must recognize
that hysterical is semantically stronger than good.
Similarly, to recognize the implicit no of (9), a sys-
tem must recognize that Lewisville is a distinct
location from Dallas, rather than, say, contained
in Dallas, and it must include more general con-
straints as well (e.g., an entity cannot be in two
physical locations at once). Once the necessary
knowledge is in place, however, the inferences are
properly licensed.
</bodyText>
<subsectionHeader confidence="0.999735">
3.2 Partially-resolving responses
</subsectionHeader>
<bodyText confidence="0.960743285714286">
A second class of IQAPs, where the content of
the answer itself does not fully resolve the ques-
tion, known as partially-resolved questions (Groe-
nendijk and Stokhof, 1984; Zeevat, 1994; Roberts,
1996; van Rooy, 2003), is less straightforward.
One instance is shown in (10), where the gradable
adjective little is the source of difficulty.
(10) [sw 0160 3467]
A: Are they [your kids] little?
B: I have a seven-year-old and a
ten-year-old.
A: Yeah, they’re pretty young.
The response, while an answer, does not, in and
of itself, resolve whether the children should be
considered little. The predicate little is a grad-
able adjective, which inherently possesses a de-
gree of vagueness: such adjectives contextually
vary in truth conditions and admit borderline cases
(Kennedy, 2007). In the case of little, while some
children are clearly little, e.g., ages 2–3, and some
clearly are not, e.g., ages 14–15, there is another
class in between for which it is difficult to as-
sess whether little can be truthfully ascribed to
them. Due to the slippery nature of these predi-
cates, there is no hard-and-fast way to resolve such
questions in all cases. In (10), it is the questioner
who resolves the question by accepting the infor-
mation proffered in the response as sufficient to
count as little.
The dialogue in (11) shows a second example of
an answer which is not fully-resolving, and inten-
tionally so.
(11) [sw 0103 4074]
A: Did he raise him [the cat] or
something1?
</bodyText>
<footnote confidence="0.903809">
1The disjunct or something may indicate that A is open
</footnote>
<bodyText confidence="0.999946078947368">
B: We bought the cat for him and so he’s
been the one that you know spent the
most time with him.
Speaker B quibbles with whether the relation
his son has to the cat is one of raising, instead cit-
ing two attributes that go along with, but do not
determine, raising. Raising an animal is a com-
posite relation, which typically includes the rela-
tions owning and spending time with. However,
satisfying these two sub-relations does not strictly
entail satisfying the raising relation as well. It
is not obvious whether a system would be mis-
taken in attributing a fully positive response to the
question, although it is certainly a partially posi-
tive response. Similarly, it seems that attributing
a negative response would be misguided, though
the answer is partly negative. The rest of the dia-
logue does not determine whether A considers this
equivalent to raising, and the dialogue proceeds
happily without this resolution.
The preceding examples have primarily hinged
upon conventionalized linguistic knowledge, viz.
what it means to raise X or for X to be little. A
further class of partially-resolving answers relies
on knowledge present in the common ground. Our
initial example (1) illustrates a situation where dif-
ferent resolutions of the question were possible de-
pending on the respondent’s intentions: no if sym-
pathetic, yes if reproachful or admiring.
The relationship between the response and
question is not secured by any objective world
facts or conventionalized meaning, but rather
is variable — contingent on specialized world
knowledge concerning the dialogue participants
and their beliefs. Resolving such IQAPs positively
or negatively is achieved only at the cost of a de-
gree of uncertainty: for resolution occurs against
the backdrop of a set of defeasible assumptions.
</bodyText>
<subsectionHeader confidence="0.973907">
3.3 IQAP classification
</subsectionHeader>
<bodyText confidence="0.999908375">
Table 2 is a cross-classification of the examples
discussed by whether the responses are fully- or
partially-resolving answers and by the types of
knowledge used in the inference (logical, linguis-
tic, world). It gives, for each category, the counts
of examples we found in the corpus. The partially-
resolved class contains more than a third of the an-
swers.
</bodyText>
<footnote confidence="0.79301425">
to hearing about alternatives to raise. We abstract away from
this issue for present purposes and treat the more general case
by assuming A’s contribution is simply equivalent to “Did he
raise him?”
</footnote>
<page confidence="0.986499">
139
</page>
<table confidence="0.994826">
Logic Linguistic World Total
Fully-Resolved 27 (Ex. 7) 18 (Ex. 8) 11 (Ex. 9) 56
Partially-Resolved – 20 (Ex. 10;11) 12 (Ex. 1) 32
</table>
<tableCaption confidence="0.99935">
Table 2: Classification of IQAPs by knowledge type and resolvedness: counts and examples.
</tableCaption>
<bodyText confidence="0.9999385">
The examples given in (7)–(9) are fully resolv-
able via inferences grounded in logical relations,
linguistic convention or objective facts: the an-
swer provides enough information to fully resolve
the question, and the modeling challenge is secur-
ing and making available the correct information.
The partially-resolved pairs are, however, qualita-
tively different. They involve a degree of uncer-
tainty that classical inference models do not ac-
commodate in a natural way.
</bodyText>
<sectionHeader confidence="0.987899" genericHeader="method">
4 Towards modeling IQAP resolution
</sectionHeader>
<bodyText confidence="0.999935230769231">
To model the reasoning involved in all types of
IQAPs, we can use a relational representation, but
we need to be able to deal with uncertainty, as
highlighted in section 3. Markov logic networks
(MLNs; Richardson and Domingos, 2006) exactly
suit these needs: they allow rich inferential reason-
ing on relations by combining the power of first-
order logic and probabilities to cope with uncer-
tainty. A logical knowledge-base is a set of hard
constraints on the set of possible worlds (set of
constants and grounded predicates). In Markov
logic, the constraints are “soft”: when a world vi-
olates a relation, it becomes less probable, but not
impossible. A Markov logic network encodes a
set of weighted first-order logic constraints, such
that a higher weight implies a stronger constraint.
Given constants in the world, the MLN creates a
network of grounded predicates which applies the
constraints to these constants. The network con-
tains one feature fj for each possible grounding of
each constraint, with a value of 1 if the grounded
constraint is true, and 0 otherwise. The probability
of a world x is thus defined in terms of the con-
straints j satisfied by that world and the weights w
associated with each constraint (Z being the parti-
tion function):
</bodyText>
<equation confidence="0.979509333333333">
1 �
P (X = x) = Z
j
</equation>
<bodyText confidence="0.999662363636364">
In practice, we use the Alchemy implemen-
tation of Markov logic networks (Kok et al.,
2009). Weights on the relations can be hand-set
or learned. Currently, we use weights set by hand,
which suffices to demonstrate that an MLN han-
dles the pragmatic reasoning we want to model,
but ultimately we would like to learn the weights.
In this section, we show by means of a few
examples how MLNs give a simple and elegant
way of modeling the reasoning involved in both
partially- and fully-resolved IQAPs.
</bodyText>
<subsectionHeader confidence="0.825331">
4.1 Fully-resolved IQAPs
</subsectionHeader>
<bodyText confidence="0.981118357142857">
While the use of MLNs is motivated by partially-
resolved IQAPs, to develop the intuitions behind
MLNs, we show how they model fully-resolved
cases, such as in (9). We define two distinct places,
Dallas and Lewisville, a relation linking a per-
son to a place, and the fact that person K is in
Lewisville. We also add the general constraint that
an individual can be in only one place at a time,
to which we assign a very high weight. Markov
logic allows for infinite weights, which Alchemy
denotes by a closing period. We also assume that
there is another person L, whose location is un-
known.
Constants and facts:
</bodyText>
<equation confidence="0.97030725">
Place = {Dallas, Lewisville}
Person = {K,L}
BeIn(Person,Place)
BeIn(K,Lewisville)
</equation>
<sectionHeader confidence="0.365311" genericHeader="method">
Constraints:
</sectionHeader>
<bodyText confidence="0.956494142857143">
// “If you are in one place, you are not in another.”
(BeIn(x,y) n (y != z)) =�- !BeIn(x,z).
Figure 1 represents the grounded Markov network
obtained by applying the constraint to the con-
stants K, L, Dallas and Lewisville. The graph
contains a node for each predicate grounding, and
an arc between each pair of nodes that appear to-
gether in some grounding of the constraint. Given
that input, the MLN samples over possible worlds,
and infers probabilities for the predicate BeIn,
based on the constraints satisfied by each world
and their weights. The MLN returns a very low
probability for K being in Dallas, meaning that the
answer to the question Is it in Dallas? is no:
</bodyText>
<equation confidence="0.690607">
BeIn(K,Dallas): 4.9995e-05
wjfj(x)
</equation>
<page confidence="0.802045">
140
</page>
<figure confidence="0.996057666666667">
BeIn(K, Dallas) BeIn(K, Lewisville)
BeIn(L, Dallas)
BeIn(L, Lewisville)
</figure>
<figureCaption confidence="0.9935285">
Figure 1: Grounded Markov network obtained by applying the constraints to the constants K, L, Dallas
and Lewisville.
</figureCaption>
<bodyText confidence="0.9993445">
Since no information about L’s location has been
given, the probabilities of L being in Dallas or
Lewisville will be equal and low (0.3), which is
exactly what one would hope for. The probabili-
ties returned for each location will depend on the
number of locations specified in the input.
</bodyText>
<subsectionHeader confidence="0.969499">
4.2 Partially-resolved IQAPs
</subsectionHeader>
<bodyText confidence="0.999347307692308">
To model partially-resolved IQAPs appropriately,
we need probabilities, since such IQAPs feature
reasoning patterns that involve uncertainty. We
now show how we can handle three examples of
partially-resolved IQAPs.
Gradable adjectives. Example (10) is a bor-
derline case of gradable adjectives: the question
bears on the predicate be little for two children of
ages 7 and 10. We first define the constants and
facts about the world, which take into account the
relations under consideration, “BeLittle(X)” and
“Age(X, i)”, and specify which individuals we are
talking about, K and L, as well as their ages.
</bodyText>
<sectionHeader confidence="0.740481" genericHeader="method">
Constants and facts:
</sectionHeader>
<equation confidence="0.988284666666667">
age = {0 ...120}
Person = {K, L}
Age(Person,age)
BeLittle(Person)
Age(K,7)
Age(L,10)
</equation>
<bodyText confidence="0.9999495">
The relation between age and being little involves
some uncertainty, which we can model using a lo-
gistic curve. We assume that a 12-year-old child
lies in the vague region for determining “little-
ness” and therefore 12 will be used as the center
of the logistic curve.
</bodyText>
<sectionHeader confidence="0.748096" genericHeader="method">
Constraints:
</sectionHeader>
<bodyText confidence="0.647792">
// “If you are under 12, you are little.”
</bodyText>
<listItem confidence="0.755087">
1.0 (Age(x,y) ∧ y &lt; 12) ⇒ BeLittle(x)
// “If you are above 12, you are not little.”
1.0 (Age(x,y) ∧ y &gt; 12) ⇒ !BeLittle(x)
</listItem>
<bodyText confidence="0.996143205882353">
// The constraint below links two instances of Be-
Little.
(Age(x,u) ∧ Age(y,v) ∧ v&gt;u ∧ BeLittle(y)) ⇒ Be-
Little(x).
Asking the network about K being little and L
being little, we obtain the following results, which
lead us to conclude that K and L are indeed little
with a reasonably high degree of confidence, and
that the indirect answer to the question is heavily
biased towards yes.
BeLittle(K): 0.92
BeLittle(L): 0.68
If we now change the facts, and say that K and L
are respectively 12 and 16 years old (instead of 7
and 10), we see an appropriate change in the prob-
abilities:
BeLittle(K): 0.58
BeLittle(L): 0.16
L, the 16-year-old, is certainly not to be consid-
ered “little” anymore, whereas the situation is less
clear-cut for K, the 12-year-old (who lies in the
vague region of “littleness” that we assumed).
Ideally, we would have information about the
speaker’s beliefs, which we could use to update
the constraints’ weights. Absent such information,
we could use general knowledge from the Web to
learn appropriate weights. In this specific case, we
could find age ranges appearing with “little kids”
in data, and fit the logistic curve to these.
This probabilistic model adapts well to cases
where categorical beliefs fit uneasily: for border-
line cases of vague predicates (whose interpreta-
tion varies by participant), there is no determinis-
tic yes or no answer.
</bodyText>
<page confidence="0.996607">
141
</page>
<bodyText confidence="0.999871">
Composite relations. In example (11), we want
to know whether the speaker’s son raised the cat
inasmuch as he owned and spent time with him.
We noted that raise is a composite relation, which
entails simpler relations, in this case spend time
with and own, although satisfying any one of the
simpler relations does not suffice to guarantee the
truth of raise itself. We model the constants, facts,
and constraints as follows:
</bodyText>
<sectionHeader confidence="0.44745" genericHeader="evaluation">
Constants and Facts:
</sectionHeader>
<figure confidence="0.962492769230769">
Person = {K}
Animal = {Cat}
Raise(Person,Animal)
SpendTime(Person,Animal)
Own(Person,Animal)
SpendTime(K,Cat)
Own(K,Cat)
Constraints:
// “If you spend time with an animal, you help
raise it.”
1.0 SpendTime(x,y) =�- Raise(x,y)
// “If you own an animal, you help raise it.”
1.0 Own(x,y) =�- Raise(x,y)
</figure>
<bodyText confidence="0.989078625">
The weights on the relations reflect how central we
judge them to be in defining raise. For simplicity,
here we let the weights be identical. Clearly, the
greater number of relevant relations a pair of en-
tities fulfills, the greater the probability that the
composite relation holds of them. Considering
two scenarios helps illustrate this. First, suppose,
as in the example, that both relations hold. We will
then have a good indication that by owning and
spending time with the cat, the son helped raise
him:
Raise(K,Cat): 0.88
Second, suppose that the example is different in
that only one of the relations holds, for instance,
that the son only spent time with the cat, but did
not own it, and accordingly the facts in the net-
work do not contain Own(K,Cat). The probability
that the son raised the cat decreases:
Raise(K,Cat): 0.78
Again this can easily be adapted depending on the
centrality of the simpler relations to the composite
relation, as well as on the world-knowledge con-
cerning the (un)certainty of the constraints.
Speaker beliefs and common ground knowl-
edge. The constructed question–answer pair
given in (1), concerning whether Sue is at work,
demonstrated that how an indirect answer is mod-
eled depends on different and uncertain evidence.
The following constraints are intended to capture
some background assumptions about how we re-
gard working, being sick, and the connections be-
tween those properties:
</bodyText>
<equation confidence="0.942664636363636">
// “If you are sick, you are not coming to work.”
Sick(x) =�- !AtWork(x)
// “If you are hardworking, you are at work.”
HardWorking(x) =�- AtWork(x)
// “If you are malicious and sick, you come to
work.”
(Malicious(x) n Sick(x)) =�- AtWork(x)
// “If you are at work and sick, you are malicious
or thoughtless.”
(AtWork(x) n Sick(x)) =�- (Malicious(x) V
Thoughtless(x))
</equation>
<bodyText confidence="0.999961454545454">
These constraints provide different answers about
Sue being at work depending on how they are
weighted, even while the facts remain the same
in each instance. If the first constraint is heavily
weighted, we get a high probability for Sue not
being at work, whereas if we evenly weight all the
constraints, Sue’s quality of being a hard-worker
dramatically raises the probability that she is at
work. Thus, MLNs permit modeling inferences
that hinge upon highly variable common ground
and speaker beliefs.
Besides offering an accurate treatment of fully-
resolved inferences, MLNs have the ability to deal
with degrees of certitude. This power is required
if one wants an adequate model of the reasoning
involved in partially-resolved inferences. Indeed,
for the successful modeling of such inferences, it
is essential to have a mechanism for adding facts
about the world that are accepted to various de-
grees, rather than categorically, as well as for up-
dating these facts with speakers’ beliefs if such in-
formation is available.
</bodyText>
<sectionHeader confidence="0.999634" genericHeader="conclusions">
5 Conclusions
</sectionHeader>
<bodyText confidence="0.999962">
We have provided an empirical analysis and ini-
tial treatment of indirect answers to polar ques-
tions. The empirical analysis led to a catego-
rization of IQAPs according to whether their an-
swers are fully- or partially-resolving and accord-
ing to the types of knowledge used in resolving
</bodyText>
<page confidence="0.993794">
142
</page>
<bodyText confidence="0.999960857142857">
the question by inference (logical, linguistic, com-
mon ground/world). The partially-resolving indi-
rect answers injected a degree of uncertainty into
the resolution of the predicate at issue in the ques-
tion. Such examples highlight the limits of tradi-
tional logical inference and call for probabilistic
methods. We therefore modeled these exchanges
with Markov logic networks, which combine the
power of first-order logic and probabilities. As
a result, we were able to provide a robust model
of question–answer resolution in dialogue, one
which can assimilate information which is not cat-
egorical, but rather known only to a degree of cer-
titude.
</bodyText>
<sectionHeader confidence="0.997642" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.9810384">
We thank Christopher Davis, Dan Jurafsky, and
Christopher D. Manning for their insightful com-
ments on earlier drafts of this paper. We also thank
Karen Shiells for her help with the data collection
and Markov logic.
</bodyText>
<sectionHeader confidence="0.997529" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999723951219512">
James F. Allen and C. Raymond Perrault. 1980. Ana-
lyzing intention in utterances. Artificial Intelligence,
15:143–178.
Nicholas Asher and Alex Lascarides. 2003. Logics of
Conversation. Cambridge University Press, Cam-
bridge.
Dwight Bolinger. 1978. Yes–no questions are not al-
ternative questions. In Henry Hiz, editor, Questions,
pages 87–105. D. Reidel Publishing Company, Dor-
drecht, Holland.
Herbert H. Clark. 1979. Responding to indirect speech
acts. Cognitive Psychology, 11:430–477.
Nancy Green and Sandra Carberry. 1992. Conver-
sational implicatures in indirect replies. In Pro-
ceedings of the 30th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 64–
71, Newark, Delaware, USA, June. Association for
Computational Linguistics.
Nancy Green and Sandra Carberry. 1994. A hybrid
reasoning model for indirect answers. In Proceed-
ings of the 32nd Annual Meeting of the Association
for Computational Linguistics, pages 58–65, Las
Cruces, New Mexico, USA, June. Association for
Computational Linguistics.
Jeroen Groenendijk and Martin Stokhof. 1984. Studies
in the Semantics of Questions and the Pragmatics of
Answers. Ph.D. thesis, University of Amsterdam.
Beth Ann Hockey, Deborah Rossen-Knill, Beverly
Spejewski, Matthew Stone, and Stephen Isard.
1997. Can you predict answers to Y/N questions?
Yes, No and Stuff. In Proceedings of Eurospeech
1997.
Daniel Jurafsky, Elizabeth Shriberg, and Debra Bi-
asca. 1997. Switchboard SWBD-DAMSL shallow-
discourse-function annotation coders manual, draft
13. Technical Report 97-02, University of Colorado,
Boulder Institute of Cognitive Science.
Christopher Kennedy. 2007. Vagueness and grammar:
The semantics of relative and absolute gradable ad-
jectives. Linguistics and Philosophy, 30(1):1–45.
Stanley Kok, Marc Sumner, Matthew Richardson,
Parag Singla, Hoifung Poon, Daniel Lowd, Jue
Wang, and Pedro Domingos. 2009. The Alchemy
system for statistical relational AI. Technical report,
Department of Computer Science and Engineering,
University of Washington, Seattle, WA.
C. Raymond Perrault and James F. Allen. 1980. A
plan-based analysis of indirect speech acts. Amer-
ican Journal of Computational Linguistics, 6(3-
4):167–182.
Anita M. Pomerantz. 1984. Agreeing and dis-
agreeing with assessment: Some features of pre-
ferred/dispreferred turn shapes. In J. M. Atkinson
and J. Heritage, editors, Structure of Social Action:
Studies in Conversation Analysis. Cambridge Uni-
versity Press.
Matt Richardson and Pedro Domingos. 2006. Markov
logic networks. Machine Learning, 62(1-2):107–
136.
Craige Roberts. 1996. Information structure: To-
wards an integrated formal theory of pragmatics. In
Jae Hak Yoon and Andreas Kathol, editors, OSU
Working Papers in Linguistics, volume 49: Papers
in Semantics, pages 91–136. The Ohio State Uni-
versity Department of Linguistics, Columbus, OH.
Revised 1998.
Robert van Rooy. 2003. Questioning to resolve
decision problems. Linguistics and Philosophy,
26(6):727–763.
Emanuel A. Schegloff, Gail Jefferson, and Harvey
Sacks. 1977. The preference for self-correction
in the organization of repair in conversation. Lan-
guage, 53:361–382.
Anna-Brita Stenstr¨om. 1984. Questions and re-
sponses in English conversation. In Claes Schaar
and Jan Svartvik, editors, Lund Studies in English
68, Malm¨o Sweden. CWK Gleerup.
Henk Zeevat. 1994. Questions and exhaustivity in up-
date semantics. In Harry Bunt, Reinhard Muskens,
and Gerrit Rentier, editors, Proceedings of the In-
ternational Workshop on Computational Semantics,
pages 211–221. ITK, Tilburg.
</reference>
<page confidence="0.999131">
143
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.380964">
<title confidence="0.988719">Not a simple yes or no: Uncertainty in indirect answers</title>
<author confidence="0.958034">Scott Grimm de_Marneffe</author>
<affiliation confidence="0.692444">Linguistics Stanford</affiliation>
<address confidence="0.843898">Stanford, CA</address>
<email confidence="0.99528">imcdm,sgrimm,cgpottsl@stanford.edu</email>
<abstract confidence="0.99726137037037">There is a long history of using logic to model the interpretation of indirect speech acts. Classical logical inference, however, is unable to deal with the combinations of disparate, conflicting, uncertain evidence that shape such speech acts in discourse. We propose to address this by combining logical inference with probabilistic methods. We focus on responses to polar questions with the following propthey are neither but they convey information that can be used to infer such an answer with some degree of confidence, though often not with enough confidence to count as resolving. We present a novel corpus study and associated typology that aims to situate these responses in the broader class of indirect question–answer pairs (IQAPs). We then model the different types of IQAPs using Markov logic networks, which combine first-order logic with probabilities, emphasizing the ways in which this approach allows us to model inferential uncertainty about both the context of utterance and intended meanings.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>James F Allen</author>
<author>C Raymond Perrault</author>
</authors>
<title>Analyzing intention in utterances.</title>
<date>1980</date>
<journal>Artificial Intelligence,</journal>
<pages>15--143</pages>
<contexts>
<context position="1344" citStr="Allen and Perrault (1980)" startWordPosition="205" endWordPosition="208">er such an answer with some degree of confidence, though often not with enough confidence to count as resolving. We present a novel corpus study and associated typology that aims to situate these responses in the broader class of indirect question–answer pairs (IQAPs). We then model the different types of IQAPs using Markov logic networks, which combine first-order logic with probabilities, emphasizing the ways in which this approach allows us to model inferential uncertainty about both the context of utterance and intended meanings. 1 Introduction Clark (1979), Perrault and Allen (1980), and Allen and Perrault (1980) study indirect speech acts, identifying a wide range of factors that govern how speakers convey their intended messages and how hearers seek to uncover those messages. Prior discourse conditions, the relationship between the literal meaning and the common ground, and specific lexical, constructional, and intonational cues all play a role. Green and Carberry (1992, 1994) provide an extensive computational model that interprets and generates indirect answers to polar questions. Their model focuses on inferring categorical answers, making use of discourse plans and coherence relations. This pape</context>
<context position="10354" citStr="Allen and Perrault, 1980" startWordPosition="1723" endWordPosition="1726"> between q and p. The inclusion relation can be based on logical relations, as in (7), where the response is an “over-answer”, i.e., a response where more information is given than is strictly necessary to resolve the question. Hearers supply more information than strictly asked for when they recognize that the speaker’s intentions are more general than the question posed might suggest. In (7), the most plausible intention behind the query is to know more about B’s family. The hearer can also identify the speaker’s plan and any necessary information for its completion, which he then provides (Allen and Perrault, 1980). (7) [sw 0001 4325] A: Do you have kids? B: I have three. While logical relations between the content of the question and the response suffice to treat examples such as (7), other over-answers often require substantial amounts of linguistic and/or worldknowledge to allow the inference to go through, as in (8) and (9). (8) [sw 0069 3144] A: Was that good? B: Hysterical. We laughed so hard. (9) [sw 0057 3506] A: Is it in Dallas? B: Uh, it’s in Lewisville. 138 In the case of (8), a system must recognize that hysterical is semantically stronger than good. Similarly, to recognize the implicit no o</context>
</contexts>
<marker>Allen, Perrault, 1980</marker>
<rawString>James F. Allen and C. Raymond Perrault. 1980. Analyzing intention in utterances. Artificial Intelligence, 15:143–178.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nicholas Asher</author>
<author>Alex Lascarides</author>
</authors>
<title>Logics of Conversation.</title>
<date>2003</date>
<publisher>Cambridge University Press,</publisher>
<location>Cambridge.</location>
<contexts>
<context position="8621" citStr="Asher and Lascarides (2003)" startWordPosition="1436" endWordPosition="1439">stitutes thus 14% of the total answers to direct yes/no questions, a figure similar to those of Stenstr¨om (1984). The next section introduces our classification of answers. 3 Typology of indirect answers We can adduce the general space of IQAPs from the data assembled in section 2 (see also Bolinger, 1978; Clark, 1979). One point of departure is that, in cooperative dialogues, a response to a question counts as an answer only when some relation holds between the content of the response and the semantic desiderata of the question. This is succinctly formulated in the relation IQAP proposed by Asher and Lascarides (2003), p. 403: IQAP(α,Q) holds only if there is a true direct answer p to the question Qα�, and the questioner can infer p from Q0� in the utterance context. The apparent emphasis on truth can be set aside for present purposes; Asher and Lascarides’s notions of truth are heavily relativized to the current discourse conditions. This principle hints at two dimensions of IQAPs which must be considered, and upon which we can establish a classification: (i) the type of answer which the proffered response provides, and (ii) the basis on which the inferences are performed. The typology established here ad</context>
</contexts>
<marker>Asher, Lascarides, 2003</marker>
<rawString>Nicholas Asher and Alex Lascarides. 2003. Logics of Conversation. Cambridge University Press, Cambridge.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dwight Bolinger</author>
</authors>
<title>Yes–no questions are not alternative questions.</title>
<date>1978</date>
<pages>87--105</pages>
<editor>In Henry Hiz, editor, Questions,</editor>
<publisher>Publishing Company,</publisher>
<location>Dordrecht, Holland.</location>
<contexts>
<context position="8301" citStr="Bolinger, 1978" startWordPosition="1384" endWordPosition="1385">h/qw/qh/bh 18 nd 9 623 Table 1: Distribution of answer tags to yes/no questions. (6) [sw 0046 4316] A: That was also civil? B: The other case was just traffic, and you know, it was seat belt law. We examined by hand all yes/no questions for IQAPs and found 88 examples (such as (6), and (7)–(11)), which constitutes thus 14% of the total answers to direct yes/no questions, a figure similar to those of Stenstr¨om (1984). The next section introduces our classification of answers. 3 Typology of indirect answers We can adduce the general space of IQAPs from the data assembled in section 2 (see also Bolinger, 1978; Clark, 1979). One point of departure is that, in cooperative dialogues, a response to a question counts as an answer only when some relation holds between the content of the response and the semantic desiderata of the question. This is succinctly formulated in the relation IQAP proposed by Asher and Lascarides (2003), p. 403: IQAP(α,Q) holds only if there is a true direct answer p to the question Qα�, and the questioner can infer p from Q0� in the utterance context. The apparent emphasis on truth can be set aside for present purposes; Asher and Lascarides’s notions of truth are heavily relat</context>
</contexts>
<marker>Bolinger, 1978</marker>
<rawString>Dwight Bolinger. 1978. Yes–no questions are not alternative questions. In Henry Hiz, editor, Questions, pages 87–105. D. Reidel Publishing Company, Dordrecht, Holland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Herbert H Clark</author>
</authors>
<title>Responding to indirect speech acts. Cognitive Psychology,</title>
<date>1979</date>
<pages>11--430</pages>
<contexts>
<context position="1286" citStr="Clark (1979)" startWordPosition="198" endWordPosition="199">ey convey information that can be used to infer such an answer with some degree of confidence, though often not with enough confidence to count as resolving. We present a novel corpus study and associated typology that aims to situate these responses in the broader class of indirect question–answer pairs (IQAPs). We then model the different types of IQAPs using Markov logic networks, which combine first-order logic with probabilities, emphasizing the ways in which this approach allows us to model inferential uncertainty about both the context of utterance and intended meanings. 1 Introduction Clark (1979), Perrault and Allen (1980), and Allen and Perrault (1980) study indirect speech acts, identifying a wide range of factors that govern how speakers convey their intended messages and how hearers seek to uncover those messages. Prior discourse conditions, the relationship between the literal meaning and the common ground, and specific lexical, constructional, and intonational cues all play a role. Green and Carberry (1992, 1994) provide an extensive computational model that interprets and generates indirect answers to polar questions. Their model focuses on inferring categorical answers, making</context>
<context position="5053" citStr="Clark, 1979" startWordPosition="812" endWordPosition="813"> higher percentage might reflect the genre difference in the corpora used: task dialogue vs. casual conversations.) These studies, however, were not concerned with how confidently one could infer a yes or no from the response given. We therefore conducted a corpus study to analyze the types of indirect answers. We used the Switchboard Dialog Act Corpus (Jurafsky et al., 1997) which has been annotated for approximately 60 basic dialog acts, clustered into 42 tags. We are concerned only with direct yes/no questions, and not with indirect ones such as “May I remind you to take out the garbage?” (Clark, 1979; Perrault and Allen, 1980). From 200 5-minute conversations, we extracted yes/no questions (tagged “qy”) and their answers, but discarded tag questions as well as disjunctive questions, such as in (2), since these do not necessarily call for a yes or no response. We also did not take into account questions that were lost in the dialogue, nor questions that did not really require an answer (3). This yielded a total of 623 yes/no questions. (2) [sw 0018 4082] A: Do you, by mistakes, do you mean just like honest mistakes A: or do you think they are deliberate sorts of things? B: Uh, I think both</context>
<context position="8315" citStr="Clark, 1979" startWordPosition="1386" endWordPosition="1387"> 9 623 Table 1: Distribution of answer tags to yes/no questions. (6) [sw 0046 4316] A: That was also civil? B: The other case was just traffic, and you know, it was seat belt law. We examined by hand all yes/no questions for IQAPs and found 88 examples (such as (6), and (7)–(11)), which constitutes thus 14% of the total answers to direct yes/no questions, a figure similar to those of Stenstr¨om (1984). The next section introduces our classification of answers. 3 Typology of indirect answers We can adduce the general space of IQAPs from the data assembled in section 2 (see also Bolinger, 1978; Clark, 1979). One point of departure is that, in cooperative dialogues, a response to a question counts as an answer only when some relation holds between the content of the response and the semantic desiderata of the question. This is succinctly formulated in the relation IQAP proposed by Asher and Lascarides (2003), p. 403: IQAP(α,Q) holds only if there is a true direct answer p to the question Qα�, and the questioner can infer p from Q0� in the utterance context. The apparent emphasis on truth can be set aside for present purposes; Asher and Lascarides’s notions of truth are heavily relativized to the </context>
</contexts>
<marker>Clark, 1979</marker>
<rawString>Herbert H. Clark. 1979. Responding to indirect speech acts. Cognitive Psychology, 11:430–477.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Green</author>
<author>Sandra Carberry</author>
</authors>
<title>Conversational implicatures in indirect replies.</title>
<date>1992</date>
<booktitle>In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>64--71</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Newark, Delaware, USA,</location>
<contexts>
<context position="1710" citStr="Green and Carberry (1992" startWordPosition="262" endWordPosition="265"> logic with probabilities, emphasizing the ways in which this approach allows us to model inferential uncertainty about both the context of utterance and intended meanings. 1 Introduction Clark (1979), Perrault and Allen (1980), and Allen and Perrault (1980) study indirect speech acts, identifying a wide range of factors that govern how speakers convey their intended messages and how hearers seek to uncover those messages. Prior discourse conditions, the relationship between the literal meaning and the common ground, and specific lexical, constructional, and intonational cues all play a role. Green and Carberry (1992, 1994) provide an extensive computational model that interprets and generates indirect answers to polar questions. Their model focuses on inferring categorical answers, making use of discourse plans and coherence relations. This paper extends such work by recasting the problem in terms of probabilistic modeling. We focus on the interpretation of indirect answers where the respondent does not answer with yes or no, but rather gives information that can be used by the hearer to infer such an answer only with some degree of certainty, as in (1). (1) A: Is Sue at work? B: She is sick with the flu</context>
</contexts>
<marker>Green, Carberry, 1992</marker>
<rawString>Nancy Green and Sandra Carberry. 1992. Conversational implicatures in indirect replies. In Proceedings of the 30th Annual Meeting of the Association for Computational Linguistics, pages 64– 71, Newark, Delaware, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Nancy Green</author>
<author>Sandra Carberry</author>
</authors>
<title>A hybrid reasoning model for indirect answers.</title>
<date>1994</date>
<booktitle>In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>58--65</pages>
<publisher>Association</publisher>
<institution>for Computational Linguistics.</institution>
<location>Las Cruces, New Mexico, USA,</location>
<marker>Green, Carberry, 1994</marker>
<rawString>Nancy Green and Sandra Carberry. 1994. A hybrid reasoning model for indirect answers. In Proceedings of the 32nd Annual Meeting of the Association for Computational Linguistics, pages 58–65, Las Cruces, New Mexico, USA, June. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jeroen Groenendijk</author>
<author>Martin Stokhof</author>
</authors>
<date>1984</date>
<booktitle>Studies in the Semantics of Questions and the Pragmatics of Answers. Ph.D. thesis,</booktitle>
<institution>University of Amsterdam.</institution>
<contexts>
<context position="11484" citStr="Groenendijk and Stokhof, 1984" startWordPosition="1915" endWordPosition="1919">gnize that hysterical is semantically stronger than good. Similarly, to recognize the implicit no of (9), a system must recognize that Lewisville is a distinct location from Dallas, rather than, say, contained in Dallas, and it must include more general constraints as well (e.g., an entity cannot be in two physical locations at once). Once the necessary knowledge is in place, however, the inferences are properly licensed. 3.2 Partially-resolving responses A second class of IQAPs, where the content of the answer itself does not fully resolve the question, known as partially-resolved questions (Groenendijk and Stokhof, 1984; Zeevat, 1994; Roberts, 1996; van Rooy, 2003), is less straightforward. One instance is shown in (10), where the gradable adjective little is the source of difficulty. (10) [sw 0160 3467] A: Are they [your kids] little? B: I have a seven-year-old and a ten-year-old. A: Yeah, they’re pretty young. The response, while an answer, does not, in and of itself, resolve whether the children should be considered little. The predicate little is a gradable adjective, which inherently possesses a degree of vagueness: such adjectives contextually vary in truth conditions and admit borderline cases (Kenned</context>
</contexts>
<marker>Groenendijk, Stokhof, 1984</marker>
<rawString>Jeroen Groenendijk and Martin Stokhof. 1984. Studies in the Semantics of Questions and the Pragmatics of Answers. Ph.D. thesis, University of Amsterdam.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Beth Ann Hockey</author>
<author>Deborah Rossen-Knill</author>
<author>Beverly Spejewski</author>
<author>Matthew Stone</author>
<author>Stephen Isard</author>
</authors>
<title>Can you predict answers to Y/N questions? Yes, No and Stuff.</title>
<date>1997</date>
<booktitle>In Proceedings of Eurospeech</booktitle>
<contexts>
<context position="4397" citStr="Hockey et al. (1997)" startWordPosition="700" endWordPosition="703"> (section 2). From this empirical base, we provide a classification of IQAPs which makes a new distinction between fully- and partiallyresolving answers (section 3). We then show how inference in Markov logic networks can successfully model the reasoning involved in both types of IQAPs (section 4). 2 Corpus study Previous corpus studies looked at how pervasive indirect answers to yes/no questions are in dialogue. Stenstr¨om (1984) analyzed 25 face-to-face and telephone conversations and found that 13% of answers to polar questions do not contain an explicit yes or no term. In a task dialogue, Hockey et al. (1997) found 38% of the responses were IQAPs. (This higher percentage might reflect the genre difference in the corpora used: task dialogue vs. casual conversations.) These studies, however, were not concerned with how confidently one could infer a yes or no from the response given. We therefore conducted a corpus study to analyze the types of indirect answers. We used the Switchboard Dialog Act Corpus (Jurafsky et al., 1997) which has been annotated for approximately 60 basic dialog acts, clustered into 42 tags. We are concerned only with direct yes/no questions, and not with indirect ones such as </context>
</contexts>
<marker>Hockey, Rossen-Knill, Spejewski, Stone, Isard, 1997</marker>
<rawString>Beth Ann Hockey, Deborah Rossen-Knill, Beverly Spejewski, Matthew Stone, and Stephen Isard. 1997. Can you predict answers to Y/N questions? Yes, No and Stuff. In Proceedings of Eurospeech 1997.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel Jurafsky</author>
<author>Elizabeth Shriberg</author>
<author>Debra Biasca</author>
</authors>
<title>Switchboard SWBD-DAMSL shallowdiscourse-function annotation coders manual, draft 13.</title>
<date>1997</date>
<tech>Technical Report 97-02,</tech>
<institution>University of Colorado, Boulder Institute of Cognitive Science.</institution>
<contexts>
<context position="4820" citStr="Jurafsky et al., 1997" startWordPosition="770" endWordPosition="773">str¨om (1984) analyzed 25 face-to-face and telephone conversations and found that 13% of answers to polar questions do not contain an explicit yes or no term. In a task dialogue, Hockey et al. (1997) found 38% of the responses were IQAPs. (This higher percentage might reflect the genre difference in the corpora used: task dialogue vs. casual conversations.) These studies, however, were not concerned with how confidently one could infer a yes or no from the response given. We therefore conducted a corpus study to analyze the types of indirect answers. We used the Switchboard Dialog Act Corpus (Jurafsky et al., 1997) which has been annotated for approximately 60 basic dialog acts, clustered into 42 tags. We are concerned only with direct yes/no questions, and not with indirect ones such as “May I remind you to take out the garbage?” (Clark, 1979; Perrault and Allen, 1980). From 200 5-minute conversations, we extracted yes/no questions (tagged “qy”) and their answers, but discarded tag questions as well as disjunctive questions, such as in (2), since these do not necessarily call for a yes or no response. We also did not take into account questions that were lost in the dialogue, nor questions that did not</context>
</contexts>
<marker>Jurafsky, Shriberg, Biasca, 1997</marker>
<rawString>Daniel Jurafsky, Elizabeth Shriberg, and Debra Biasca. 1997. Switchboard SWBD-DAMSL shallowdiscourse-function annotation coders manual, draft 13. Technical Report 97-02, University of Colorado, Boulder Institute of Cognitive Science.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Christopher Kennedy</author>
</authors>
<title>Vagueness and grammar: The semantics of relative and absolute gradable adjectives.</title>
<date>2007</date>
<journal>Linguistics and Philosophy,</journal>
<volume>30</volume>
<issue>1</issue>
<contexts>
<context position="12092" citStr="Kennedy, 2007" startWordPosition="2015" endWordPosition="2016">, 1984; Zeevat, 1994; Roberts, 1996; van Rooy, 2003), is less straightforward. One instance is shown in (10), where the gradable adjective little is the source of difficulty. (10) [sw 0160 3467] A: Are they [your kids] little? B: I have a seven-year-old and a ten-year-old. A: Yeah, they’re pretty young. The response, while an answer, does not, in and of itself, resolve whether the children should be considered little. The predicate little is a gradable adjective, which inherently possesses a degree of vagueness: such adjectives contextually vary in truth conditions and admit borderline cases (Kennedy, 2007). In the case of little, while some children are clearly little, e.g., ages 2–3, and some clearly are not, e.g., ages 14–15, there is another class in between for which it is difficult to assess whether little can be truthfully ascribed to them. Due to the slippery nature of these predicates, there is no hard-and-fast way to resolve such questions in all cases. In (10), it is the questioner who resolves the question by accepting the information proffered in the response as sufficient to count as little. The dialogue in (11) shows a second example of an answer which is not fully-resolving, and </context>
</contexts>
<marker>Kennedy, 2007</marker>
<rawString>Christopher Kennedy. 2007. Vagueness and grammar: The semantics of relative and absolute gradable adjectives. Linguistics and Philosophy, 30(1):1–45.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stanley Kok</author>
<author>Marc Sumner</author>
<author>Matthew Richardson</author>
<author>Parag Singla</author>
<author>Hoifung Poon</author>
<author>Daniel Lowd</author>
<author>Jue Wang</author>
<author>Pedro Domingos</author>
</authors>
<title>The Alchemy system for statistical relational AI.</title>
<date>2009</date>
<tech>Technical report,</tech>
<institution>Department of Computer Science and Engineering, University of Washington,</institution>
<location>Seattle, WA.</location>
<contexts>
<context position="17289" citStr="Kok et al., 2009" startWordPosition="2880" endWordPosition="2883">r weight implies a stronger constraint. Given constants in the world, the MLN creates a network of grounded predicates which applies the constraints to these constants. The network contains one feature fj for each possible grounding of each constraint, with a value of 1 if the grounded constraint is true, and 0 otherwise. The probability of a world x is thus defined in terms of the constraints j satisfied by that world and the weights w associated with each constraint (Z being the partition function): 1 � P (X = x) = Z j In practice, we use the Alchemy implementation of Markov logic networks (Kok et al., 2009). Weights on the relations can be hand-set or learned. Currently, we use weights set by hand, which suffices to demonstrate that an MLN handles the pragmatic reasoning we want to model, but ultimately we would like to learn the weights. In this section, we show by means of a few examples how MLNs give a simple and elegant way of modeling the reasoning involved in both partially- and fully-resolved IQAPs. 4.1 Fully-resolved IQAPs While the use of MLNs is motivated by partiallyresolved IQAPs, to develop the intuitions behind MLNs, we show how they model fully-resolved cases, such as in (9). We d</context>
</contexts>
<marker>Kok, Sumner, Richardson, Singla, Poon, Lowd, Wang, Domingos, 2009</marker>
<rawString>Stanley Kok, Marc Sumner, Matthew Richardson, Parag Singla, Hoifung Poon, Daniel Lowd, Jue Wang, and Pedro Domingos. 2009. The Alchemy system for statistical relational AI. Technical report, Department of Computer Science and Engineering, University of Washington, Seattle, WA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>C Raymond Perrault</author>
<author>James F Allen</author>
</authors>
<title>A plan-based analysis of indirect speech acts.</title>
<date>1980</date>
<journal>American Journal of Computational Linguistics,</journal>
<pages>6--3</pages>
<contexts>
<context position="1313" citStr="Perrault and Allen (1980)" startWordPosition="200" endWordPosition="203">rmation that can be used to infer such an answer with some degree of confidence, though often not with enough confidence to count as resolving. We present a novel corpus study and associated typology that aims to situate these responses in the broader class of indirect question–answer pairs (IQAPs). We then model the different types of IQAPs using Markov logic networks, which combine first-order logic with probabilities, emphasizing the ways in which this approach allows us to model inferential uncertainty about both the context of utterance and intended meanings. 1 Introduction Clark (1979), Perrault and Allen (1980), and Allen and Perrault (1980) study indirect speech acts, identifying a wide range of factors that govern how speakers convey their intended messages and how hearers seek to uncover those messages. Prior discourse conditions, the relationship between the literal meaning and the common ground, and specific lexical, constructional, and intonational cues all play a role. Green and Carberry (1992, 1994) provide an extensive computational model that interprets and generates indirect answers to polar questions. Their model focuses on inferring categorical answers, making use of discourse plans and</context>
<context position="5080" citStr="Perrault and Allen, 1980" startWordPosition="814" endWordPosition="818">ntage might reflect the genre difference in the corpora used: task dialogue vs. casual conversations.) These studies, however, were not concerned with how confidently one could infer a yes or no from the response given. We therefore conducted a corpus study to analyze the types of indirect answers. We used the Switchboard Dialog Act Corpus (Jurafsky et al., 1997) which has been annotated for approximately 60 basic dialog acts, clustered into 42 tags. We are concerned only with direct yes/no questions, and not with indirect ones such as “May I remind you to take out the garbage?” (Clark, 1979; Perrault and Allen, 1980). From 200 5-minute conversations, we extracted yes/no questions (tagged “qy”) and their answers, but discarded tag questions as well as disjunctive questions, such as in (2), since these do not necessarily call for a yes or no response. We also did not take into account questions that were lost in the dialogue, nor questions that did not really require an answer (3). This yielded a total of 623 yes/no questions. (2) [sw 0018 4082] A: Do you, by mistakes, do you mean just like honest mistakes A: or do you think they are deliberate sorts of things? B: Uh, I think both. (3) [sw 0070 3435] A: How</context>
</contexts>
<marker>Perrault, Allen, 1980</marker>
<rawString>C. Raymond Perrault and James F. Allen. 1980. A plan-based analysis of indirect speech acts. American Journal of Computational Linguistics, 6(3-4):167–182.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anita M Pomerantz</author>
</authors>
<title>Agreeing and disagreeing with assessment: Some features of preferred/dispreferred turn shapes.</title>
<date>1984</date>
<booktitle>Structure of Social Action: Studies in Conversation Analysis.</booktitle>
<editor>In J. M. Atkinson and J. Heritage, editors,</editor>
<publisher>Cambridge University Press.</publisher>
<contexts>
<context position="6661" citStr="Pomerantz, 1984" startWordPosition="1092" endWordPosition="1093">Category II includes statement–opinion and statementnon-opinion: e.g., I think it’s great, Me I’m in the legal department, respectively. Affirmative nonyes answers and negative non-no answers form category III. Other answers such as I don’t know are in category IV. In category V, we put utterances that avoid answering the question: by holding (I’m drawing a blank), by returning the question — whquestion or rhetorical question (Who would steal a newspaper?) — or by using a backchannel in question form (Is that right?). Finally, category VI contains dispreferred answers (Schegloff et al., 1977; Pomerantz, 1984). We hypothesized that the phenomenon we are studying would appear in categories II, III and VI. However, some of the “na/ng” answers are disguised yes/no answers, such as Right, I think so, or Not really, and as such do not interest us. In the case of “sv/sd” and “nd” answers, many answers include reformulation, question avoidance (see 4), or a change of framing (5). All these cases are not really at issue for the question we are addressing. (4) [sw 0177 2759] A: Have you ever been drug tested? B: Um, that’s a good question. (5) [sw 0046 4316] A: Is he the guy wants to, like, deregulate heroi</context>
</contexts>
<marker>Pomerantz, 1984</marker>
<rawString>Anita M. Pomerantz. 1984. Agreeing and disagreeing with assessment: Some features of preferred/dispreferred turn shapes. In J. M. Atkinson and J. Heritage, editors, Structure of Social Action: Studies in Conversation Analysis. Cambridge University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Matt Richardson</author>
<author>Pedro Domingos</author>
</authors>
<title>Markov logic networks.</title>
<date>2006</date>
<booktitle>Machine Learning,</booktitle>
<pages>62--1</pages>
<contexts>
<context position="16157" citStr="Richardson and Domingos, 2006" startWordPosition="2683" endWordPosition="2686">ic convention or objective facts: the answer provides enough information to fully resolve the question, and the modeling challenge is securing and making available the correct information. The partially-resolved pairs are, however, qualitatively different. They involve a degree of uncertainty that classical inference models do not accommodate in a natural way. 4 Towards modeling IQAP resolution To model the reasoning involved in all types of IQAPs, we can use a relational representation, but we need to be able to deal with uncertainty, as highlighted in section 3. Markov logic networks (MLNs; Richardson and Domingos, 2006) exactly suit these needs: they allow rich inferential reasoning on relations by combining the power of firstorder logic and probabilities to cope with uncertainty. A logical knowledge-base is a set of hard constraints on the set of possible worlds (set of constants and grounded predicates). In Markov logic, the constraints are “soft”: when a world violates a relation, it becomes less probable, but not impossible. A Markov logic network encodes a set of weighted first-order logic constraints, such that a higher weight implies a stronger constraint. Given constants in the world, the MLN creates</context>
</contexts>
<marker>Richardson, Domingos, 2006</marker>
<rawString>Matt Richardson and Pedro Domingos. 2006. Markov logic networks. Machine Learning, 62(1-2):107– 136.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Craige Roberts</author>
</authors>
<title>Information structure: Towards an integrated formal theory of pragmatics.</title>
<date>1996</date>
<booktitle>OSU Working Papers in Linguistics, volume 49: Papers in Semantics,</booktitle>
<pages>91--136</pages>
<editor>In Jae Hak Yoon and Andreas Kathol, editors,</editor>
<institution>The Ohio State University Department of Linguistics,</institution>
<location>Columbus, OH. Revised</location>
<contexts>
<context position="11513" citStr="Roberts, 1996" startWordPosition="1922" endWordPosition="1923">r than good. Similarly, to recognize the implicit no of (9), a system must recognize that Lewisville is a distinct location from Dallas, rather than, say, contained in Dallas, and it must include more general constraints as well (e.g., an entity cannot be in two physical locations at once). Once the necessary knowledge is in place, however, the inferences are properly licensed. 3.2 Partially-resolving responses A second class of IQAPs, where the content of the answer itself does not fully resolve the question, known as partially-resolved questions (Groenendijk and Stokhof, 1984; Zeevat, 1994; Roberts, 1996; van Rooy, 2003), is less straightforward. One instance is shown in (10), where the gradable adjective little is the source of difficulty. (10) [sw 0160 3467] A: Are they [your kids] little? B: I have a seven-year-old and a ten-year-old. A: Yeah, they’re pretty young. The response, while an answer, does not, in and of itself, resolve whether the children should be considered little. The predicate little is a gradable adjective, which inherently possesses a degree of vagueness: such adjectives contextually vary in truth conditions and admit borderline cases (Kennedy, 2007). In the case of litt</context>
</contexts>
<marker>Roberts, 1996</marker>
<rawString>Craige Roberts. 1996. Information structure: Towards an integrated formal theory of pragmatics. In Jae Hak Yoon and Andreas Kathol, editors, OSU Working Papers in Linguistics, volume 49: Papers in Semantics, pages 91–136. The Ohio State University Department of Linguistics, Columbus, OH. Revised 1998.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Robert van Rooy</author>
</authors>
<title>Questioning to resolve decision problems.</title>
<date>2003</date>
<journal>Linguistics and Philosophy,</journal>
<volume>26</volume>
<issue>6</issue>
<marker>van Rooy, 2003</marker>
<rawString>Robert van Rooy. 2003. Questioning to resolve decision problems. Linguistics and Philosophy, 26(6):727–763.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Emanuel A Schegloff</author>
<author>Gail Jefferson</author>
<author>Harvey Sacks</author>
</authors>
<title>The preference for self-correction in the organization of repair in conversation.</title>
<date>1977</date>
<journal>Language,</journal>
<pages>53--361</pages>
<contexts>
<context position="6643" citStr="Schegloff et al., 1977" startWordPosition="1088" endWordPosition="1091">., That’s exactly it.). Category II includes statement–opinion and statementnon-opinion: e.g., I think it’s great, Me I’m in the legal department, respectively. Affirmative nonyes answers and negative non-no answers form category III. Other answers such as I don’t know are in category IV. In category V, we put utterances that avoid answering the question: by holding (I’m drawing a blank), by returning the question — whquestion or rhetorical question (Who would steal a newspaper?) — or by using a backchannel in question form (Is that right?). Finally, category VI contains dispreferred answers (Schegloff et al., 1977; Pomerantz, 1984). We hypothesized that the phenomenon we are studying would appear in categories II, III and VI. However, some of the “na/ng” answers are disguised yes/no answers, such as Right, I think so, or Not really, and as such do not interest us. In the case of “sv/sd” and “nd” answers, many answers include reformulation, question avoidance (see 4), or a change of framing (5). All these cases are not really at issue for the question we are addressing. (4) [sw 0177 2759] A: Have you ever been drug tested? B: Um, that’s a good question. (5) [sw 0046 4316] A: Is he the guy wants to, like</context>
</contexts>
<marker>Schegloff, Jefferson, Sacks, 1977</marker>
<rawString>Emanuel A. Schegloff, Gail Jefferson, and Harvey Sacks. 1977. The preference for self-correction in the organization of repair in conversation. Language, 53:361–382.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anna-Brita Stenstr¨om</author>
</authors>
<title>Questions and responses in English conversation.</title>
<date>1984</date>
<booktitle>In Claes Schaar and Jan Svartvik, editors, Lund Studies in English 68, Malm¨o Sweden. CWK Gleerup.</booktitle>
<marker>Stenstr¨om, 1984</marker>
<rawString>Anna-Brita Stenstr¨om. 1984. Questions and responses in English conversation. In Claes Schaar and Jan Svartvik, editors, Lund Studies in English 68, Malm¨o Sweden. CWK Gleerup.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Henk Zeevat</author>
</authors>
<title>Questions and exhaustivity in update semantics.</title>
<date>1994</date>
<booktitle>Proceedings of the International Workshop on Computational Semantics,</booktitle>
<pages>211--221</pages>
<editor>In Harry Bunt, Reinhard Muskens, and Gerrit Rentier, editors,</editor>
<publisher>ITK,</publisher>
<location>Tilburg.</location>
<contexts>
<context position="11498" citStr="Zeevat, 1994" startWordPosition="1920" endWordPosition="1921">ically stronger than good. Similarly, to recognize the implicit no of (9), a system must recognize that Lewisville is a distinct location from Dallas, rather than, say, contained in Dallas, and it must include more general constraints as well (e.g., an entity cannot be in two physical locations at once). Once the necessary knowledge is in place, however, the inferences are properly licensed. 3.2 Partially-resolving responses A second class of IQAPs, where the content of the answer itself does not fully resolve the question, known as partially-resolved questions (Groenendijk and Stokhof, 1984; Zeevat, 1994; Roberts, 1996; van Rooy, 2003), is less straightforward. One instance is shown in (10), where the gradable adjective little is the source of difficulty. (10) [sw 0160 3467] A: Are they [your kids] little? B: I have a seven-year-old and a ten-year-old. A: Yeah, they’re pretty young. The response, while an answer, does not, in and of itself, resolve whether the children should be considered little. The predicate little is a gradable adjective, which inherently possesses a degree of vagueness: such adjectives contextually vary in truth conditions and admit borderline cases (Kennedy, 2007). In t</context>
</contexts>
<marker>Zeevat, 1994</marker>
<rawString>Henk Zeevat. 1994. Questions and exhaustivity in update semantics. In Harry Bunt, Reinhard Muskens, and Gerrit Rentier, editors, Proceedings of the International Workshop on Computational Semantics, pages 211–221. ITK, Tilburg.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>