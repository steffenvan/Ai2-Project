<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.004229">
<title confidence="0.989081">
Two stage constraint based hybrid approach to free word order lan-
guage dependency parsing
</title>
<author confidence="0.986954">
Akshar Bharati, Samar Husain, Dipti Misra and Rajeev Sangal
</author>
<affiliation confidence="0.983376">
Language Technologies Research Centre, IIIT-Hyderabad, India
</affiliation>
<email confidence="0.97138">
{samar, dipti, sangal}@mail.iiit.ac.in
</email>
<sectionHeader confidence="0.993449" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.999913466666667">
The paper describes the overall design of a
new two stage constraint based hybrid ap-
proach to dependency parsing. We define
the two stages and show how different
grammatical construct are parsed at appro-
priate stages. This division leads to selec-
tive identification and resolution of specif-
ic dependency relations at the two stages.
Furthermore, we show how the use of
hard constraints and soft constraints helps
us build an efficient and robust hybrid
parser. Finally, we evaluate the imple-
mented parser on Hindi and compare the
results with that of two data driven depen-
dency parsers.
</bodyText>
<sectionHeader confidence="0.9988" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.999914913043478">
Due to the availability of annotated corpora for
various languages since the past decade, data
driven parsing has proved to be immensely suc-
cessful. Unlike English, however, most of the
parsers for morphologically rich free word order
(MoR-FWO) languages (such as Czech, Turkish,
Hindi, etc.) have adopted the dependency gram-
matical framework. It is well known that for
MoR-FWO languages, dependency framework
provides ease of linguistic analysis and is much
better suited to account for their various struc-
tures (Shieber, 1975; Mel&apos;Cuk, 1988; Bharati et
al., 1995). The state of the art parsing accuracy
for many MoR-FWO languages is still low com-
pared to that of English. Parsing experiments
(Nivre et al., 2007; Hall et al., 2007) for these
languages have pointed towards various reasons
for this low performance. For Hindi1, (a) difficul-
ty in extracting relevant linguistic cues, (b) non-
projectivity, (c) lack of explicit cues, (d) long
distance dependencies, (e) complex linguistic
phenomena, and (f) less corpus size, have been
suggested (Bharati et al., 2008) for low perfor-
</bodyText>
<footnote confidence="0.809791">
1 Hindi is a verb final language with free word order and
a rich case marking system. It is one of the official lan-
guages of India, and is spoken by ~800 million people.
</footnote>
<bodyText confidence="0.999980076923077">
mance. The approach proposed in this paper
shows how one can minimize these adverse ef-
fects and argues that a hybrid approach can prove
to be a better option to parsing such languages.
There have been, in the past, many attempts to
parsing using constraint based approaches. Some
recent works include (Debusmann et al., 2004;
Schröder, 2002; Bharati et al., 1993).
The paper describes the overall design of a
new two stage constraint based hybrid approach
to dependency parsing. We define the two stages
and show how different grammatical construct
are parsed at appropriate stages. This division
leads to selective identification and resolution of
specific dependency relations at two different
stages. Furthermore, we show how the use of
hard constraints (H-constraints) and soft con-
straints (S-constraints) helps us build an efficient
and robust hybrid parser. Specifically, H-con-
straints incorporate the knowledge base of the
language and S-constraints are weights corre-
sponding to various constraints. These weights
are automatically learnt from an annotated tree-
bank. Finally, we evaluate the implemented pars-
er on Hindi and compare the results with that of
two data driven dependency parsers.
</bodyText>
<sectionHeader confidence="0.86962" genericHeader="method">
2 Two Stage Parsing
</sectionHeader>
<bodyText confidence="0.9999904">
The parser tries to analyze the given input sen-
tence, which has already been POS tagged and
chunked2, in 2 stages; it first tries to extract intra-
clausal3 dependency relations. These relations
generally correspond to the argument structure of
the verb, noun-noun genitive relation, infinitive-
verb relation, infinitive-noun relation, adjective-
noun, adverb-verb relations, etc. In the 2nd stage
it then tries to handle more complex relations
such as conjuncts, relative clause, etc. What this
</bodyText>
<footnote confidence="0.323972625">
2 A chunk is a set of adjacent words which are in depen-
dency relation with each other, and are connected to the
rest of the words by a single incoming arc. The parser
marks relations between the head of the chunks (inter-
chunk relations); this is done to avoid local details and
can be thought as a device for modularity.
3 A clause is a group of word such that the group con-
tains a single finite verb chunk.
</footnote>
<page confidence="0.961128">
77
</page>
<bodyText confidence="0.99007964516129">
Proceedings of the 11th International Conference on Parsing Technologies (IWPT), pages 77–80,
Paris, October 2009. c�2009 Association for Computational Linguistics
essentially means is a 2-stage resolution of de-
pendencies, where the parser selectively resolves
the dependencies of various lexical heads at their
appropriate stage, for example verbs in the 1st
stage and conjuncts and inter-verb relations in
the 2nd stage. The key ideas of the proposed lay-
ered architecture are: (1) There are two layers
stages, (2) the 1st stage handles intra-clausal rela-
tions, and the 2nd stage handles inter-clausal rela-
tions, (3) the output of each layer is a linguisti-
cally valid partial parse that becomes, if neces-
sary, the input to the next layer, and (4) the out-
put of the final layer is the desired full parse.
By following the above approach we are able
to get 4-fold advantage, (1) Each layer in effect
does linguistically valid partial parsing, (2) by di-
viding the labels into different functional sets
(intra-clausal and inter-clausal) we localize the
dependencies that need to be identified, hence
the problem of long distance dependencies is
minimizes, (3) by attacking the problem in a
modular way, i.e. handling only individual claus-
es at 1st stage, we reduce non-projective struc-
tures significantly, and (4) the two stage con-
straint based approach can easily capture com-
plex linguistic cues that are difficult to learn via
the data-driven parsers. We’ll revisit these points
in Section 5. The 1st stage output for example 1 is
shown in figure 1 (a).
</bodyText>
<equation confidence="0.473316">
Eg. 1: mai ghar gayaa kyomki mai
’I’ ’home’ ’went’ ’because’ ’I’
bimaar thaa
’sick’ ‘was’
</equation>
<bodyText confidence="0.835205">
‘I went home because I was sick’
</bodyText>
<figureCaption confidence="0.608365">
Figure 1. Eg 1 (a): 1st stage output, (b): 2nd stage
final parse
</figureCaption>
<bodyText confidence="0.99998125">
In figure 1a, the parsed matrix clause subtree
‘mai ghar gayaa’ and the subordinate clause are
attached to _ROOT_. The subordinating conjunct
‘kyomki’ is also seen attached to the _ROOT_.
_ROOT_ ensures that the parse we get after each
stage is connected and takes all the analyzed 1st
stage sub-trees along with unprocessed nodes as
its children. The dependency tree thus obtained
in the 1st stage is partial, but linguistically sound.
Later in the 2nd stage the relationship between
various clauses are identified. The 2nd stage parse
for the above sentences is also shown in figure
1b. Note that under normal conditions the 2nd
stage does not modify the parse sub-trees ob-
tained from the 1st stage, it only establishes the
relations between the clauses.
</bodyText>
<sectionHeader confidence="0.982731" genericHeader="method">
3 Hard and Soft Constraints
</sectionHeader>
<bodyText confidence="0.999955052631579">
Both 1st and 2nd stage described in the previ-
ous section use linguistically motivated con-
straints. These hard constraints (H-constraints)
reflect that aspect of the grammar that in general
cannot be broken. H-constraints comprise of lex-
ical and structural knowledge of the language.
The H-constraints are converted into integer pro-
gramming problem and solved (Bharati et al.,
1995). The solution(s) is/are valid parse(s). The
soft constraints (S-constraints) on the other hand
are learnt as weights from an annotated treebank.
They reflect various preferences that a language
has towards various linguistic phenomena. They
are used to prioritize the parses and select the
best parse. Both H &amp; S constraints reflect the lin-
guistic realities of the language and together can
be thought as the grammar of a language. Figure
2 shows the overall design of the proposed parser
schematically.
</bodyText>
<subsectionHeader confidence="0.996869">
3.1 Hard Constraints
</subsectionHeader>
<bodyText confidence="0.99991247826087">
The core language knowledge being currently
considered that cannot be broken without the
sentence being called ungrammatical is named
H-constraints. There can be multiple parses
which can satisfy these H-constraints. This indi-
cates the ambiguity in the sentence if only the
limited knowledge base is considered. Stated an-
other way, H-constraints are insufficient to re-
strict multiple analysis of a given sentence and
that more knowledge (semantics, other prefer-
ences, etc.) is required to curtain the ambiguities.
Moreover, we know that many sentences are syn-
tactically ambiguous unless one uses some prag-
matic knowledge, etc. For all such constructions
there are multiple parses. As described earlier,
H-constraints are used during intra-clausal (1st
stage) and inter-clausal (2nd stage) analysis (cf.
Figure 2). They are used to form a constraint
graph which is converted into integer program-
ming equalities (or inequalities). These are then
solved to get the final solution graph(s). Some of
the H-constraints are: (1) Structural constraints
(ensuring the solution graph to be a tree,
</bodyText>
<page confidence="0.998021">
78
</page>
<figureCaption confidence="0.998825">
Figure 2. Overall parser design
</figureCaption>
<bodyText confidence="0.958021">
removing implausible language specific ungram-
matical structures, etc.), (2) Lexicon (linguistic
demands of various heads), and (3) Other lexi-
cal constraints (some language specific charac-
teristics), etc.
</bodyText>
<subsectionHeader confidence="0.999176">
3.2 Soft Constraints
</subsectionHeader>
<bodyText confidence="0.996130074074074">
The S-constraints on the other hand are the con-
straints which can be broken, and are used in the
language as preferences. These are used during
the prioritization stage. Unlike the H-constraints
that are derived from a knowledge base and are
used to form a constraint graph, S-constraints
have weights assigned to them. These weights
are automatically learnt using a manually anno-
tated dependency treebank. The tree with the
maximum overall score is the best parse. Some
such S-constraints are, (1) Order of the argu-
ments, (2) Relative position of arguments w.r.t.
the verb, (3) Agreement principle, (4) Alignment
of prominence scale, and (5) Structural prefer-
ences/General graph properties (mild non-pro-
jectivity, valency, dominance, etc.), etc.
unlabeled attachments (UA), label (L) and la-
beled attachment (LA) accuracy. In Table 1,
CBP’ shows the performance of the system when
a basic prioritizer is used, while CBP” shows it
for the best parse that is available in the first 25
parses. CBP gives the accuracy when the 1st
parse is selected. We show CBP” to show that a
good parse is available in as few as the first 25
parses and that once the prioritizer is further im-
proved the overall performance will easily cross
CBP”.
</bodyText>
<table confidence="0.999451333333333">
UA LA L
CBP 86.1 63 65
CBP’ 87.69 69.67 72.39
CBP” 90.1 75 76.9
MST 87.8 70.4 72.3
Malt 86.6 68.0 70.6
</table>
<tableCaption confidence="0.7898">
Table 1. Parser Evaluation
5 Observations
</tableCaption>
<sectionHeader confidence="0.98827" genericHeader="evaluation">
4 Evaluation
</sectionHeader>
<bodyText confidence="0.964228461538462">
Malt Parser (version 0.4) (Nivre et al., 2007), and
MST Parser (version 0.4b) (McDonald et al.,
2005) have been tuned for Hindi by Bharati et al.
(2008). Parsers were trained on a subset of a Hin-
di Treebank (Begum et al., 2008a). We use the
same experimental setup (parameters, features,
etc.) used by them and compare the results of the
two data driven parsers with that of the proposed
constraint based hybrid parser (CBP) on the
same dataset4 in terms of
4 For details on the corpus type, annotation scheme,
tagset, etc. see Begum et al. (2008a).
The initial results show that the proposed parser
performs better than the state-of-the-art data
driven Hindi parsers. There are various reasons
why we think that the proposed approach is bet-
ter suited to parsing MoR-FWO. (1) Complex
linguistic cues can easily be encoded as part of
various constraints. For example, it has been
shown by Bharati et al. (2008) that, for Hindi,
complex agreement patterns, though present in
the data, are not being learnt by data driven
parsers. Such patterns along with other idiosyn-
cratic language properties can be easily incorpo-
rated as constraints, (2) Making clauses as basic
parsing unit drastically reduces non-projective
</bodyText>
<page confidence="0.996575">
79
</page>
<bodyText confidence="0.999884945945946">
sentences. Experiments in parsing MoR-FOW
have shown that such non-projective sentences
impede parser performances (Bharati et al., 2008;
Hall et al., 2007). Note that there will still remain
some intra-clausal non-projective structures in
the 1st stage, but they will be short distance de-
pendencies, (3) Use of H-constraints and S-con-
straints together reflect the grammar of a lan-
guage. The rules in the form of H-constraints are
complemented by the weights of S-constraints
learnt from the annotated corpus, (4) 2 stage
parsing lends itself seamlessly to parsing com-
plex sentences by modularizing the task of over-
all parsing, (5) the problem of label bias (Bharati
et al., 2008) faced by the data driven Hindi
parsers for some cases does not arise here as con-
textually similar entities are disambiguated by
tapping in hard to learn features, (6) Use of
clauses as basic parsing units reduces the search
space at both the stages, (7) Parsing closely relat-
ed languages will become easy.
The performance of our parser is affected due
to the following reasons, (a) Small lexicon (lin-
guistic demands of various heads): The total
number of such demand frames which the parser
currently uses is very low. There are a total of
around 300 frames, which have been divided into
20 verb classes (Begum et al., 2008b). As the
coverage of this lexicon increases, the efficiency
will automatically increase. (b) Unhandled con-
structions: The parser still doesn’t handle some
constructions, such as the case when a conjunct
takes another conjunct as its dependent, and (c)
Prioritization mistakes: As stated earlier the pri-
oritizer being used is basic and is still being im-
proved. The overall performance will increase
with the improvement of the prioritizer.
</bodyText>
<sectionHeader confidence="0.999257" genericHeader="conclusions">
6 Conclusion
</sectionHeader>
<bodyText confidence="0.999482653846154">
In this paper we proposed a new two stage con-
straint based hybrid approach to dependency
parsing. We showed how by modularizing the
task of overall parsing into 2 stages we can over-
come many problems faced by data driven pars-
ing. We showed how in the 1st stage only intra-
clausal dependencies are handled and later in the
2nd stage the inter-clausal dependencies are iden-
tified. We also briefly described the use of H-
constraints and S-constraints. We argued that
such constraints complement each other in get-
ting the best parse and that together they repre-
sent the grammar of the language. We evaluated
our system for Hindi with two data driven
parsers. Initial results show that the proposed
parser performs better than those parsers. Finally,
we argued why the proposed hybrid approach is
better suited to handle the challenges posed by
MoR-FWO and gave few pointers as how we can
further improve our performance.
The proposed parser is still being improved at
various fronts. To begin with a prioritization
mechanism has to be improved. We need to en-
rich the verb frame lexicon along with handling
some unhandled constructions. This will be taken
up as immediate future work.
</bodyText>
<sectionHeader confidence="0.999191" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.999439894736842">
R. Begum, S. Husain, A. Dhwaj, D. Sharma, L. Bai,
and R. Sangal. 2008a. Dependency annotation
scheme for Indian languages. Proc. of IJCNLP08.
R. Begum, S. Husain, D. Sharma and L. Bai. 2008b.
Developing Verb Frames in Hindi. Proc. of
LREC08.
A. Bharati, S. Husain, B. Ambati, S. Jain, D. Sharma
and R. Sangal. 2008. Two Semantic features make
all the difference in Parsing accuracy. Proc. of
ICON-08.
A. Bharati and R. Sangal. 1993. Parsing Free Word
Order Languages in the Paninian Framework.
Proc. of ACL: 93.
A. Bharati, V. Chaitanya and R. Sangal. 1995. Natu-
ral Language Processing: A Paninian Perspective,
Prentice-Hall of India, New Delhi.
R. Debusmann, D. Duchier and G. Kruijff. 2004. Ex-
tensible dependency grammar: A new methodolo-
gy. Proceedings of the Workshop on Recent Ad-
vances in Dependency Grammar, pp. 78–85.
J. Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi,
M. Nilsson and M. Saers. 2007. Single Malt or
Blended? A Study in Multilingual Parser Optimiza-
tion. Proc. of EMNLP-CoNLL shared task 2007.
R. McDonald, F. Pereira, K. Ribarov, and J. Hajic.
2005. Non-projective dependency parsing using
spanning tree algorithms. Proc. of HLT/EMNLP.
I. A. Mel&apos;Cuk. 1988. Dependency Syntax: Theory and
Practice, State University Press of New York.
J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S.
Kübler, S. Marinov and E Marsi. 2007. MaltParser:
A language-independent system for data-driven de-
pendency parsing. NLE.
S. M. Shieber. 1985. Evidence against the context-
freeness of natural language. In Linguistics and
Philosophy, p. 8, 334–343.
I. Schröder. 2002. Natural Language Parsing with
Graded Constraints. PhD thesis, Hamburg Univ.
</reference>
<page confidence="0.998207">
80
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.312613">
<title confidence="0.759209">stage constraint based hybrid approach to free word order guage dependency parsing</title>
<author confidence="0.537127">Akshar Bharati</author>
<author confidence="0.537127">Samar Husain</author>
<author confidence="0.537127">Dipti Misra</author>
<author confidence="0.537127">Rajeev</author>
<affiliation confidence="0.519741">Language Technologies Research Centre, IIIT-Hyderabad,</affiliation>
<email confidence="0.714094">samar@mail.iiit.ac.in</email>
<email confidence="0.714094">dipti@mail.iiit.ac.in</email>
<email confidence="0.714094">sangal@mail.iiit.ac.in</email>
<abstract confidence="0.9954823125">The paper describes the overall design of a new two stage constraint based hybrid approach to dependency parsing. We define the two stages and show how different grammatical construct are parsed at appropriate stages. This division leads to selective identification and resolution of specific dependency relations at the two stages. Furthermore, we show how the use of hard constraints and soft constraints helps us build an efficient and robust hybrid parser. Finally, we evaluate the implemented parser on Hindi and compare the results with that of two data driven dependency parsers.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>R Begum</author>
<author>S Husain</author>
<author>A Dhwaj</author>
<author>D Sharma</author>
<author>L Bai</author>
<author>R Sangal</author>
</authors>
<title>Dependency annotation scheme for Indian languages.</title>
<date>2008</date>
<booktitle>Proc. of IJCNLP08.</booktitle>
<contexts>
<context position="10628" citStr="Begum et al., 2008" startWordPosition="1713" endWordPosition="1716">gives the accuracy when the 1st parse is selected. We show CBP” to show that a good parse is available in as few as the first 25 parses and that once the prioritizer is further improved the overall performance will easily cross CBP”. UA LA L CBP 86.1 63 65 CBP’ 87.69 69.67 72.39 CBP” 90.1 75 76.9 MST 87.8 70.4 72.3 Malt 86.6 68.0 70.6 Table 1. Parser Evaluation 5 Observations 4 Evaluation Malt Parser (version 0.4) (Nivre et al., 2007), and MST Parser (version 0.4b) (McDonald et al., 2005) have been tuned for Hindi by Bharati et al. (2008). Parsers were trained on a subset of a Hindi Treebank (Begum et al., 2008a). We use the same experimental setup (parameters, features, etc.) used by them and compare the results of the two data driven parsers with that of the proposed constraint based hybrid parser (CBP) on the same dataset4 in terms of 4 For details on the corpus type, annotation scheme, tagset, etc. see Begum et al. (2008a). The initial results show that the proposed parser performs better than the state-of-the-art data driven Hindi parsers. There are various reasons why we think that the proposed approach is better suited to parsing MoR-FWO. (1) Complex linguistic cues can easily be encoded as p</context>
<context position="12921" citStr="Begum et al., 2008" startWordPosition="2090" endWordPosition="2093"> by the data driven Hindi parsers for some cases does not arise here as contextually similar entities are disambiguated by tapping in hard to learn features, (6) Use of clauses as basic parsing units reduces the search space at both the stages, (7) Parsing closely related languages will become easy. The performance of our parser is affected due to the following reasons, (a) Small lexicon (linguistic demands of various heads): The total number of such demand frames which the parser currently uses is very low. There are a total of around 300 frames, which have been divided into 20 verb classes (Begum et al., 2008b). As the coverage of this lexicon increases, the efficiency will automatically increase. (b) Unhandled constructions: The parser still doesn’t handle some constructions, such as the case when a conjunct takes another conjunct as its dependent, and (c) Prioritization mistakes: As stated earlier the prioritizer being used is basic and is still being improved. The overall performance will increase with the improvement of the prioritizer. 6 Conclusion In this paper we proposed a new two stage constraint based hybrid approach to dependency parsing. We showed how by modularizing the task of overal</context>
</contexts>
<marker>Begum, Husain, Dhwaj, Sharma, Bai, Sangal, 2008</marker>
<rawString>R. Begum, S. Husain, A. Dhwaj, D. Sharma, L. Bai, and R. Sangal. 2008a. Dependency annotation scheme for Indian languages. Proc. of IJCNLP08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Begum</author>
<author>S Husain</author>
<author>D Sharma</author>
<author>L Bai</author>
</authors>
<date>2008</date>
<booktitle>Developing Verb Frames in Hindi. Proc. of LREC08.</booktitle>
<contexts>
<context position="10628" citStr="Begum et al., 2008" startWordPosition="1713" endWordPosition="1716">gives the accuracy when the 1st parse is selected. We show CBP” to show that a good parse is available in as few as the first 25 parses and that once the prioritizer is further improved the overall performance will easily cross CBP”. UA LA L CBP 86.1 63 65 CBP’ 87.69 69.67 72.39 CBP” 90.1 75 76.9 MST 87.8 70.4 72.3 Malt 86.6 68.0 70.6 Table 1. Parser Evaluation 5 Observations 4 Evaluation Malt Parser (version 0.4) (Nivre et al., 2007), and MST Parser (version 0.4b) (McDonald et al., 2005) have been tuned for Hindi by Bharati et al. (2008). Parsers were trained on a subset of a Hindi Treebank (Begum et al., 2008a). We use the same experimental setup (parameters, features, etc.) used by them and compare the results of the two data driven parsers with that of the proposed constraint based hybrid parser (CBP) on the same dataset4 in terms of 4 For details on the corpus type, annotation scheme, tagset, etc. see Begum et al. (2008a). The initial results show that the proposed parser performs better than the state-of-the-art data driven Hindi parsers. There are various reasons why we think that the proposed approach is better suited to parsing MoR-FWO. (1) Complex linguistic cues can easily be encoded as p</context>
<context position="12921" citStr="Begum et al., 2008" startWordPosition="2090" endWordPosition="2093"> by the data driven Hindi parsers for some cases does not arise here as contextually similar entities are disambiguated by tapping in hard to learn features, (6) Use of clauses as basic parsing units reduces the search space at both the stages, (7) Parsing closely related languages will become easy. The performance of our parser is affected due to the following reasons, (a) Small lexicon (linguistic demands of various heads): The total number of such demand frames which the parser currently uses is very low. There are a total of around 300 frames, which have been divided into 20 verb classes (Begum et al., 2008b). As the coverage of this lexicon increases, the efficiency will automatically increase. (b) Unhandled constructions: The parser still doesn’t handle some constructions, such as the case when a conjunct takes another conjunct as its dependent, and (c) Prioritization mistakes: As stated earlier the prioritizer being used is basic and is still being improved. The overall performance will increase with the improvement of the prioritizer. 6 Conclusion In this paper we proposed a new two stage constraint based hybrid approach to dependency parsing. We showed how by modularizing the task of overal</context>
</contexts>
<marker>Begum, Husain, Sharma, Bai, 2008</marker>
<rawString>R. Begum, S. Husain, D. Sharma and L. Bai. 2008b. Developing Verb Frames in Hindi. Proc. of LREC08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>S Husain</author>
<author>B Ambati</author>
<author>S Jain</author>
<author>D Sharma</author>
<author>R Sangal</author>
</authors>
<title>Two Semantic features make all the difference in Parsing accuracy.</title>
<date>2008</date>
<booktitle>Proc. of ICON-08.</booktitle>
<contexts>
<context position="1927" citStr="Bharati et al., 2008" startWordPosition="295" endWordPosition="298">s and is much better suited to account for their various structures (Shieber, 1975; Mel&apos;Cuk, 1988; Bharati et al., 1995). The state of the art parsing accuracy for many MoR-FWO languages is still low compared to that of English. Parsing experiments (Nivre et al., 2007; Hall et al., 2007) for these languages have pointed towards various reasons for this low performance. For Hindi1, (a) difficulty in extracting relevant linguistic cues, (b) nonprojectivity, (c) lack of explicit cues, (d) long distance dependencies, (e) complex linguistic phenomena, and (f) less corpus size, have been suggested (Bharati et al., 2008) for low perfor1 Hindi is a verb final language with free word order and a rich case marking system. It is one of the official languages of India, and is spoken by ~800 million people. mance. The approach proposed in this paper shows how one can minimize these adverse effects and argues that a hybrid approach can prove to be a better option to parsing such languages. There have been, in the past, many attempts to parsing using constraint based approaches. Some recent works include (Debusmann et al., 2004; Schröder, 2002; Bharati et al., 1993). The paper describes the overall design of a new tw</context>
<context position="10554" citStr="Bharati et al. (2008)" startWordPosition="1698" endWordPosition="1701">P” shows it for the best parse that is available in the first 25 parses. CBP gives the accuracy when the 1st parse is selected. We show CBP” to show that a good parse is available in as few as the first 25 parses and that once the prioritizer is further improved the overall performance will easily cross CBP”. UA LA L CBP 86.1 63 65 CBP’ 87.69 69.67 72.39 CBP” 90.1 75 76.9 MST 87.8 70.4 72.3 Malt 86.6 68.0 70.6 Table 1. Parser Evaluation 5 Observations 4 Evaluation Malt Parser (version 0.4) (Nivre et al., 2007), and MST Parser (version 0.4b) (McDonald et al., 2005) have been tuned for Hindi by Bharati et al. (2008). Parsers were trained on a subset of a Hindi Treebank (Begum et al., 2008a). We use the same experimental setup (parameters, features, etc.) used by them and compare the results of the two data driven parsers with that of the proposed constraint based hybrid parser (CBP) on the same dataset4 in terms of 4 For details on the corpus type, annotation scheme, tagset, etc. see Begum et al. (2008a). The initial results show that the proposed parser performs better than the state-of-the-art data driven Hindi parsers. There are various reasons why we think that the proposed approach is better suited </context>
<context position="12297" citStr="Bharati et al., 2008" startWordPosition="1981" endWordPosition="1984">uch non-projective sentences impede parser performances (Bharati et al., 2008; Hall et al., 2007). Note that there will still remain some intra-clausal non-projective structures in the 1st stage, but they will be short distance dependencies, (3) Use of H-constraints and S-constraints together reflect the grammar of a language. The rules in the form of H-constraints are complemented by the weights of S-constraints learnt from the annotated corpus, (4) 2 stage parsing lends itself seamlessly to parsing complex sentences by modularizing the task of overall parsing, (5) the problem of label bias (Bharati et al., 2008) faced by the data driven Hindi parsers for some cases does not arise here as contextually similar entities are disambiguated by tapping in hard to learn features, (6) Use of clauses as basic parsing units reduces the search space at both the stages, (7) Parsing closely related languages will become easy. The performance of our parser is affected due to the following reasons, (a) Small lexicon (linguistic demands of various heads): The total number of such demand frames which the parser currently uses is very low. There are a total of around 300 frames, which have been divided into 20 verb cla</context>
</contexts>
<marker>Bharati, Husain, Ambati, Jain, Sharma, Sangal, 2008</marker>
<rawString>A. Bharati, S. Husain, B. Ambati, S. Jain, D. Sharma and R. Sangal. 2008. Two Semantic features make all the difference in Parsing accuracy. Proc. of ICON-08.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>R Sangal</author>
</authors>
<title>Parsing Free Word Order Languages in the Paninian Framework.</title>
<date>1993</date>
<booktitle>Proc. of ACL:</booktitle>
<pages>93</pages>
<marker>Bharati, Sangal, 1993</marker>
<rawString>A. Bharati and R. Sangal. 1993. Parsing Free Word Order Languages in the Paninian Framework. Proc. of ACL: 93.</rawString>
</citation>
<citation valid="true">
<authors>
<author>A Bharati</author>
<author>V Chaitanya</author>
<author>R Sangal</author>
</authors>
<title>Natural Language Processing: A Paninian Perspective, Prentice-Hall of India,</title>
<date>1995</date>
<location>New Delhi.</location>
<contexts>
<context position="1426" citStr="Bharati et al., 1995" startWordPosition="215" endWordPosition="218">t of two data driven dependency parsers. 1 Introduction Due to the availability of annotated corpora for various languages since the past decade, data driven parsing has proved to be immensely successful. Unlike English, however, most of the parsers for morphologically rich free word order (MoR-FWO) languages (such as Czech, Turkish, Hindi, etc.) have adopted the dependency grammatical framework. It is well known that for MoR-FWO languages, dependency framework provides ease of linguistic analysis and is much better suited to account for their various structures (Shieber, 1975; Mel&apos;Cuk, 1988; Bharati et al., 1995). The state of the art parsing accuracy for many MoR-FWO languages is still low compared to that of English. Parsing experiments (Nivre et al., 2007; Hall et al., 2007) for these languages have pointed towards various reasons for this low performance. For Hindi1, (a) difficulty in extracting relevant linguistic cues, (b) nonprojectivity, (c) lack of explicit cues, (d) long distance dependencies, (e) complex linguistic phenomena, and (f) less corpus size, have been suggested (Bharati et al., 2008) for low perfor1 Hindi is a verb final language with free word order and a rich case marking system</context>
<context position="7141" citStr="Bharati et al., 1995" startWordPosition="1152" endWordPosition="1155">above sentences is also shown in figure 1b. Note that under normal conditions the 2nd stage does not modify the parse sub-trees obtained from the 1st stage, it only establishes the relations between the clauses. 3 Hard and Soft Constraints Both 1st and 2nd stage described in the previous section use linguistically motivated constraints. These hard constraints (H-constraints) reflect that aspect of the grammar that in general cannot be broken. H-constraints comprise of lexical and structural knowledge of the language. The H-constraints are converted into integer programming problem and solved (Bharati et al., 1995). The solution(s) is/are valid parse(s). The soft constraints (S-constraints) on the other hand are learnt as weights from an annotated treebank. They reflect various preferences that a language has towards various linguistic phenomena. They are used to prioritize the parses and select the best parse. Both H &amp; S constraints reflect the linguistic realities of the language and together can be thought as the grammar of a language. Figure 2 shows the overall design of the proposed parser schematically. 3.1 Hard Constraints The core language knowledge being currently considered that cannot be brok</context>
</contexts>
<marker>Bharati, Chaitanya, Sangal, 1995</marker>
<rawString>A. Bharati, V. Chaitanya and R. Sangal. 1995. Natural Language Processing: A Paninian Perspective, Prentice-Hall of India, New Delhi.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R Debusmann</author>
<author>D Duchier</author>
<author>G Kruijff</author>
</authors>
<title>Extensible dependency grammar: A new methodology.</title>
<date>2004</date>
<booktitle>Proceedings of the Workshop on Recent Advances in Dependency Grammar,</booktitle>
<pages>78--85</pages>
<contexts>
<context position="2436" citStr="Debusmann et al., 2004" startWordPosition="387" endWordPosition="390">endencies, (e) complex linguistic phenomena, and (f) less corpus size, have been suggested (Bharati et al., 2008) for low perfor1 Hindi is a verb final language with free word order and a rich case marking system. It is one of the official languages of India, and is spoken by ~800 million people. mance. The approach proposed in this paper shows how one can minimize these adverse effects and argues that a hybrid approach can prove to be a better option to parsing such languages. There have been, in the past, many attempts to parsing using constraint based approaches. Some recent works include (Debusmann et al., 2004; Schröder, 2002; Bharati et al., 1993). The paper describes the overall design of a new two stage constraint based hybrid approach to dependency parsing. We define the two stages and show how different grammatical construct are parsed at appropriate stages. This division leads to selective identification and resolution of specific dependency relations at two different stages. Furthermore, we show how the use of hard constraints (H-constraints) and soft constraints (S-constraints) helps us build an efficient and robust hybrid parser. Specifically, H-constraints incorporate the knowledge base o</context>
</contexts>
<marker>Debusmann, Duchier, Kruijff, 2004</marker>
<rawString>R. Debusmann, D. Duchier and G. Kruijff. 2004. Extensible dependency grammar: A new methodology. Proceedings of the Workshop on Recent Advances in Dependency Grammar, pp. 78–85.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Hall</author>
<author>J Nilsson</author>
<author>J Nivre</author>
<author>G Eryigit</author>
<author>B Megyesi</author>
<author>M Nilsson</author>
<author>M Saers</author>
</authors>
<title>Single Malt or Blended? A Study in Multilingual Parser Optimization.</title>
<date>2007</date>
<booktitle>Proc. of EMNLP-CoNLL shared task</booktitle>
<contexts>
<context position="1594" citStr="Hall et al., 2007" startWordPosition="245" endWordPosition="248">roved to be immensely successful. Unlike English, however, most of the parsers for morphologically rich free word order (MoR-FWO) languages (such as Czech, Turkish, Hindi, etc.) have adopted the dependency grammatical framework. It is well known that for MoR-FWO languages, dependency framework provides ease of linguistic analysis and is much better suited to account for their various structures (Shieber, 1975; Mel&apos;Cuk, 1988; Bharati et al., 1995). The state of the art parsing accuracy for many MoR-FWO languages is still low compared to that of English. Parsing experiments (Nivre et al., 2007; Hall et al., 2007) for these languages have pointed towards various reasons for this low performance. For Hindi1, (a) difficulty in extracting relevant linguistic cues, (b) nonprojectivity, (c) lack of explicit cues, (d) long distance dependencies, (e) complex linguistic phenomena, and (f) less corpus size, have been suggested (Bharati et al., 2008) for low perfor1 Hindi is a verb final language with free word order and a rich case marking system. It is one of the official languages of India, and is spoken by ~800 million people. mance. The approach proposed in this paper shows how one can minimize these advers</context>
<context position="11773" citStr="Hall et al., 2007" startWordPosition="1895" endWordPosition="1898">o parsing MoR-FWO. (1) Complex linguistic cues can easily be encoded as part of various constraints. For example, it has been shown by Bharati et al. (2008) that, for Hindi, complex agreement patterns, though present in the data, are not being learnt by data driven parsers. Such patterns along with other idiosyncratic language properties can be easily incorporated as constraints, (2) Making clauses as basic parsing unit drastically reduces non-projective 79 sentences. Experiments in parsing MoR-FOW have shown that such non-projective sentences impede parser performances (Bharati et al., 2008; Hall et al., 2007). Note that there will still remain some intra-clausal non-projective structures in the 1st stage, but they will be short distance dependencies, (3) Use of H-constraints and S-constraints together reflect the grammar of a language. The rules in the form of H-constraints are complemented by the weights of S-constraints learnt from the annotated corpus, (4) 2 stage parsing lends itself seamlessly to parsing complex sentences by modularizing the task of overall parsing, (5) the problem of label bias (Bharati et al., 2008) faced by the data driven Hindi parsers for some cases does not arise here a</context>
</contexts>
<marker>Hall, Nilsson, Nivre, Eryigit, Megyesi, Nilsson, Saers, 2007</marker>
<rawString>J. Hall, J. Nilsson, J. Nivre, G. Eryigit, B. Megyesi, M. Nilsson and M. Saers. 2007. Single Malt or Blended? A Study in Multilingual Parser Optimization. Proc. of EMNLP-CoNLL shared task 2007.</rawString>
</citation>
<citation valid="true">
<authors>
<author>R McDonald</author>
<author>F Pereira</author>
<author>K Ribarov</author>
<author>J Hajic</author>
</authors>
<title>Non-projective dependency parsing using spanning tree algorithms.</title>
<date>2005</date>
<booktitle>Proc. of HLT/EMNLP.</booktitle>
<contexts>
<context position="10503" citStr="McDonald et al., 2005" startWordPosition="1688" endWordPosition="1691">he system when a basic prioritizer is used, while CBP” shows it for the best parse that is available in the first 25 parses. CBP gives the accuracy when the 1st parse is selected. We show CBP” to show that a good parse is available in as few as the first 25 parses and that once the prioritizer is further improved the overall performance will easily cross CBP”. UA LA L CBP 86.1 63 65 CBP’ 87.69 69.67 72.39 CBP” 90.1 75 76.9 MST 87.8 70.4 72.3 Malt 86.6 68.0 70.6 Table 1. Parser Evaluation 5 Observations 4 Evaluation Malt Parser (version 0.4) (Nivre et al., 2007), and MST Parser (version 0.4b) (McDonald et al., 2005) have been tuned for Hindi by Bharati et al. (2008). Parsers were trained on a subset of a Hindi Treebank (Begum et al., 2008a). We use the same experimental setup (parameters, features, etc.) used by them and compare the results of the two data driven parsers with that of the proposed constraint based hybrid parser (CBP) on the same dataset4 in terms of 4 For details on the corpus type, annotation scheme, tagset, etc. see Begum et al. (2008a). The initial results show that the proposed parser performs better than the state-of-the-art data driven Hindi parsers. There are various reasons why we</context>
</contexts>
<marker>McDonald, Pereira, Ribarov, Hajic, 2005</marker>
<rawString>R. McDonald, F. Pereira, K. Ribarov, and J. Hajic. 2005. Non-projective dependency parsing using spanning tree algorithms. Proc. of HLT/EMNLP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I A Mel&apos;Cuk</author>
</authors>
<title>Dependency Syntax: Theory and Practice,</title>
<date>1988</date>
<publisher>State University Press of</publisher>
<location>New York.</location>
<contexts>
<context position="1403" citStr="Mel&apos;Cuk, 1988" startWordPosition="213" endWordPosition="214">esults with that of two data driven dependency parsers. 1 Introduction Due to the availability of annotated corpora for various languages since the past decade, data driven parsing has proved to be immensely successful. Unlike English, however, most of the parsers for morphologically rich free word order (MoR-FWO) languages (such as Czech, Turkish, Hindi, etc.) have adopted the dependency grammatical framework. It is well known that for MoR-FWO languages, dependency framework provides ease of linguistic analysis and is much better suited to account for their various structures (Shieber, 1975; Mel&apos;Cuk, 1988; Bharati et al., 1995). The state of the art parsing accuracy for many MoR-FWO languages is still low compared to that of English. Parsing experiments (Nivre et al., 2007; Hall et al., 2007) for these languages have pointed towards various reasons for this low performance. For Hindi1, (a) difficulty in extracting relevant linguistic cues, (b) nonprojectivity, (c) lack of explicit cues, (d) long distance dependencies, (e) complex linguistic phenomena, and (f) less corpus size, have been suggested (Bharati et al., 2008) for low perfor1 Hindi is a verb final language with free word order and a r</context>
</contexts>
<marker>Mel&apos;Cuk, 1988</marker>
<rawString>I. A. Mel&apos;Cuk. 1988. Dependency Syntax: Theory and Practice, State University Press of New York.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Nivre</author>
<author>J Hall</author>
<author>J Nilsson</author>
<author>A Chanev</author>
<author>G Eryigit</author>
<author>S Kübler</author>
<author>S Marinov</author>
<author>E Marsi</author>
</authors>
<title>MaltParser: A language-independent system for data-driven dependency parsing.</title>
<date>2007</date>
<publisher>NLE.</publisher>
<contexts>
<context position="1574" citStr="Nivre et al., 2007" startWordPosition="241" endWordPosition="244">driven parsing has proved to be immensely successful. Unlike English, however, most of the parsers for morphologically rich free word order (MoR-FWO) languages (such as Czech, Turkish, Hindi, etc.) have adopted the dependency grammatical framework. It is well known that for MoR-FWO languages, dependency framework provides ease of linguistic analysis and is much better suited to account for their various structures (Shieber, 1975; Mel&apos;Cuk, 1988; Bharati et al., 1995). The state of the art parsing accuracy for many MoR-FWO languages is still low compared to that of English. Parsing experiments (Nivre et al., 2007; Hall et al., 2007) for these languages have pointed towards various reasons for this low performance. For Hindi1, (a) difficulty in extracting relevant linguistic cues, (b) nonprojectivity, (c) lack of explicit cues, (d) long distance dependencies, (e) complex linguistic phenomena, and (f) less corpus size, have been suggested (Bharati et al., 2008) for low perfor1 Hindi is a verb final language with free word order and a rich case marking system. It is one of the official languages of India, and is spoken by ~800 million people. mance. The approach proposed in this paper shows how one can m</context>
<context position="10448" citStr="Nivre et al., 2007" startWordPosition="1679" endWordPosition="1682">ccuracy. In Table 1, CBP’ shows the performance of the system when a basic prioritizer is used, while CBP” shows it for the best parse that is available in the first 25 parses. CBP gives the accuracy when the 1st parse is selected. We show CBP” to show that a good parse is available in as few as the first 25 parses and that once the prioritizer is further improved the overall performance will easily cross CBP”. UA LA L CBP 86.1 63 65 CBP’ 87.69 69.67 72.39 CBP” 90.1 75 76.9 MST 87.8 70.4 72.3 Malt 86.6 68.0 70.6 Table 1. Parser Evaluation 5 Observations 4 Evaluation Malt Parser (version 0.4) (Nivre et al., 2007), and MST Parser (version 0.4b) (McDonald et al., 2005) have been tuned for Hindi by Bharati et al. (2008). Parsers were trained on a subset of a Hindi Treebank (Begum et al., 2008a). We use the same experimental setup (parameters, features, etc.) used by them and compare the results of the two data driven parsers with that of the proposed constraint based hybrid parser (CBP) on the same dataset4 in terms of 4 For details on the corpus type, annotation scheme, tagset, etc. see Begum et al. (2008a). The initial results show that the proposed parser performs better than the state-of-the-art data</context>
</contexts>
<marker>Nivre, Hall, Nilsson, Chanev, Eryigit, Kübler, Marinov, Marsi, 2007</marker>
<rawString>J. Nivre, J. Hall, J. Nilsson, A. Chanev, G. Eryigit, S. Kübler, S. Marinov and E Marsi. 2007. MaltParser: A language-independent system for data-driven dependency parsing. NLE.</rawString>
</citation>
<citation valid="true">
<authors>
<author>S M Shieber</author>
</authors>
<title>Evidence against the contextfreeness of natural language.</title>
<date>1985</date>
<booktitle>In Linguistics and Philosophy,</booktitle>
<pages>8--334</pages>
<marker>Shieber, 1985</marker>
<rawString>S. M. Shieber. 1985. Evidence against the contextfreeness of natural language. In Linguistics and Philosophy, p. 8, 334–343.</rawString>
</citation>
<citation valid="true">
<authors>
<author>I Schröder</author>
</authors>
<title>Natural Language Parsing with Graded Constraints.</title>
<date>2002</date>
<tech>PhD thesis,</tech>
<institution>Hamburg Univ.</institution>
<contexts>
<context position="2452" citStr="Schröder, 2002" startWordPosition="391" endWordPosition="392">inguistic phenomena, and (f) less corpus size, have been suggested (Bharati et al., 2008) for low perfor1 Hindi is a verb final language with free word order and a rich case marking system. It is one of the official languages of India, and is spoken by ~800 million people. mance. The approach proposed in this paper shows how one can minimize these adverse effects and argues that a hybrid approach can prove to be a better option to parsing such languages. There have been, in the past, many attempts to parsing using constraint based approaches. Some recent works include (Debusmann et al., 2004; Schröder, 2002; Bharati et al., 1993). The paper describes the overall design of a new two stage constraint based hybrid approach to dependency parsing. We define the two stages and show how different grammatical construct are parsed at appropriate stages. This division leads to selective identification and resolution of specific dependency relations at two different stages. Furthermore, we show how the use of hard constraints (H-constraints) and soft constraints (S-constraints) helps us build an efficient and robust hybrid parser. Specifically, H-constraints incorporate the knowledge base of the language a</context>
</contexts>
<marker>Schröder, 2002</marker>
<rawString>I. Schröder. 2002. Natural Language Parsing with Graded Constraints. PhD thesis, Hamburg Univ.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>