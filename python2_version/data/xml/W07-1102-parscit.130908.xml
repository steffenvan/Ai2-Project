<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.000824">
<title confidence="0.9988555">
Distinguishing Subtypes of Multiword Expressions Using
Linguistically-Motivated Statistical Measures
</title>
<author confidence="0.982305">
Afsaneh Fazly
</author>
<affiliation confidence="0.905759333333333">
Department of Computer Science
University of Toronto
Toronto, Canada
</affiliation>
<email confidence="0.994202">
afsaneh@cs.toronto.edu
</email>
<author confidence="0.988016">
Suzanne Stevenson
</author>
<affiliation confidence="0.905512666666667">
Department of Computer Science
University of Toronto
Toronto, Canada
</affiliation>
<email confidence="0.997383">
suzanne@cs.toronto.edu
</email>
<sectionHeader confidence="0.998594" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.9999886">
We identify several classes of multiword ex-
pressions that each require a different encod-
ing in a (computational) lexicon, as well as
a different treatment within a computational
system. We examine linguistic properties
pertaining to the degree of semantic idiosyn-
crasy of these classes of expressions. Ac-
cordingly, we propose statistical measures to
quantify each property, and use the measures
to automatically distinguish the classes.
</bodyText>
<sectionHeader confidence="0.991474" genericHeader="keywords">
1 Motivation
</sectionHeader>
<bodyText confidence="0.999619218181819">
Multiword expressions (MWEs) are widely used in
written language as well as in colloquial speech. An
MWE is composed of two or more words that to-
gether form a single unit of meaning, e.g., frying pan,
take a stroll, and kick the bucket. Most MWEs behave
like any phrase composed of multiple words, e.g.,
their components may be separated, as in She took a
relaxing stroll along the beach. Nonetheless, MWEs
are distinct from multiword phrases because they in-
volve some degree of semantic idiosyncrasy, i.e., the
overall meaning of an MWE diverges from the com-
bined contribution of its constituent parts. Because of
their frequency and their peculiar behaviour, MWEs
pose a great challenge to the creation of natural lan-
guage processing (NLP) systems (Sag et al., 2002).
NLP applications, such as semantic parsing and ma-
chine translation should not only identify MWEs, but
also should know how to treat them when they are
encountered.
Semantic idiosyncrasy is a matter of degree (Nun-
berg et al., 1994). The idiom shoot the breeze is
largely idiosyncratic, because its meaning (“to chat”)
does not have much to do with the meaning of shoot
or breeze. MWEs such as give a try (“try”) and make
a decision (“decide”) are semantically less idiosyn-
cratic (more predictable). These are MWEs because
the overall meaning of the expression diverges from
the combined meanings of the constituents. Nonethe-
less, there is some degree of predictability in their
meanings that makes them distinct from idioms. In
these, the complement of the verb (here, a noun) de-
termines the primary meaning of the overall expres-
sion. This class of expressions is referred to as light
verb constructions (LVCs) in the linguistics literature
(Miyamoto, 2000; Butt, 2003).
Clearly, a computational system should distinguish
idioms and LVCs, both from each other, and from
similar-on-the-surface (literal) phrases such as shoot
the bird and give a present. Idioms are largely id-
iosyncratic; a computational lexicographer thus may
decide to list idioms such as shoot the breeze in a lex-
icon along with their idiomatic meanings. In contrast,
the meaning of MWEs such as make a decision can
be largely predicted, given that they are LVCs. Ta-
ble 1 shows the different underlying semantic struc-
ture of a sentence containing an idiom (shoot the
breeze) and a sentence containing an LVC (give a
try). As can be seen, such MWEs should also be
treated differently when translated into another lan-
guage. Note that in contrast to a literal combination,
such as shoot the bird, for idioms and LVCs, the num-
ber of arguments expressed syntactically may differ
from the number of the semantic participants.
Many NLP applications also need to distinguish
another group of MWEs that are less idiosyncratic
</bodyText>
<page confidence="0.970561">
9
</page>
<note confidence="0.88772425">
Proceedings of the Workshop on A Broader Perspective on Multiword Expressions, pages 9–16,
Prague, June 2007. c�2007 Association for Computational Linguistics
Class English sentence Semantic representation French translation
Literal Jill and Tim shot the bird. (event/SHOOT Jill et Tim ont abattu l’oiseau.
</note>
<figure confidence="0.975702111111111">
:agent (“Jill n Tim”) Jill and Tim shot down the bird.
:theme (“bird”))
Abstract Jill makes a living singing in pubs. (event/EARN-MONEY Jill gagne sa vie en chantant dans des bars.
:agent (“Jill”)) Jill makes a living by singing in the pubs.
LVC Jill gave the lasagna a try. (event/TRY Jill a essay´e le lasagne.
:agent (“Jill”) Jill tried the lasagna.
:theme (“lasagna”))
Idiom Jill and Tim shot the breeze. (event/CHAT Jill et Tim ont bavard´e.
:agent (“Jill n Tim”)) Jill and Tim chatted.
</figure>
<tableCaption confidence="0.99579">
Table 1: Sample English MWEs and their translation in French.
</tableCaption>
<bodyText confidence="0.999918916666667">
than idioms and LVCs, but more so than literal com-
binations. Examples include give confidence and
make a living. These are idiosyncratic because the
meaning of the verb is a metaphorical (abstract)
extension of its basic physical semantics. More-
over, they often take on certain connotations be-
yond the compositional combination of their con-
stituent meanings. They thus exhibit behaviour of-
ten attributed to collocations, e.g., they appear with
greater frequency than semantically similar combina-
tions. For example, searching on Google, we found
much higher frequency for give confidence compared
to grant confidence. As can be seen in Table 1, an ab-
stract combination such as make a living, although
largely compositional, may not translate word-for-
word. Rather, it should be translated taking into ac-
count that the verb has a metaphorical meaning, dif-
ferent from its basic semantics.
Here, we focus on a particular class of English
MWEs that are formed from the combination of a
verb with a noun in its direct object position, re-
ferred to as verb+noun combinations. Specifically,
we provide a framework for identifying members of
the following semantic classes of verb+noun combi-
nations: (i) literal phrases (LIT), (ii) abstract combi-
nations (ABS), (iii) light verb constructions (LVC),
and (iv) idiomatic combinations (IDM). Section 2
elaborates on the linguistic properties related to the
differences in the degree of semantic idiosyncrasy
observed in members of the above four classes. In
Section 3, we propose statistical measures for quan-
tifying each of these properties, and use them as fea-
tures for type classification of verb+noun combina-
tions. Section 4 and Section 5 present an evaluation
of our proposed measures. Section 6 discusses the
related studies, and Section 7 concludes the paper.
</bodyText>
<sectionHeader confidence="0.930775" genericHeader="introduction">
2 Semantic Idiosyncrasy: Linguistic
Properties
</sectionHeader>
<bodyText confidence="0.99937725">
Linguists and lexicographers often attribute certain
characteristics to semantically idiosyncratic expres-
sions. Some of the widely-known properties are in-
stitutionalization, lexicosyntactic fixedness, and non-
compositionality (Cowie, 1981; Gibbs and Nayak,
1989; Moon, 1998). The following paragraphs elab-
orate on each property, as well as on its relevance to
the identification of the classes under study.
Institutionalization is the process through which a
combination of words becomes recognized and ac-
cepted as a semantic unit involving some degree of
semantic idiosyncrasy. IDMs, LVCs, and ABS com-
binations are institutionalized to some extent.
Lexicosyntactic fixedness refers to some degree of
lexical and syntactic restrictiveness in a semantically
idiosyncratic expression. An expression is lexically
fixed if the substitution of a semantically similar
word for any of its constituents does not preserve its
original meaning (e.g., compare spill the beans and
spread the beans). In contrast to LIT and ABS com-
binations, IDMs and LVCs are expected to exhibit
lexical fixedness to some extent.
An expression is syntactically fixed if it cannot un-
dergo syntactic variations and at the same time retain
its original semantic interpretation. IDMs and LVCs
are known to show strong preferences for the syn-
tactic patterns they appear in (Cacciari and Tabossi,
1993; Brinton and Akimoto, 1999). E.g., compare
</bodyText>
<page confidence="0.996965">
10
</page>
<bodyText confidence="0.999911225">
Joe gave a groan with ?A groan was given by Joe,
and Tim kicked the bucket with *Tim kicked the buck-
ets (in the idiom reading). Nonetheless, the type and
degree of syntactic fixedness in LVCs and IDMs are
different. For example, most LVCs prefer the pattern
in which the noun is introduced by the indefinite arti-
cle a (as in give a try and make a decision), whereas
this is not the case with IDMs (e.g., shoot the breeze
and kick the bucket). IDMs and LVCs may also ex-
hibit preferences with respect to adjectival modifica-
tion of their noun constituent. LVCs are expected to
appear both with and without an adjectival modifier,
as in give a (loud) groan and make a (wise) decision.
IDMs, on the other hand, mostly appear either with
an adjective, as in keep an open mind (cf. ?keep a
mind), or without, as in shoot the breeze (cf. ?shoot
the fun breeze).
Non-compositionality refers to the situation where
the meaning of a word combination deviates from
the meaning emerging from a word-by-word inter-
pretation of it. IDMs are largely non-compositional,
whereas LVCs are semi-compositional since their
meaning can be mainly predicted from the noun con-
stituent. ABS and LIT combinations are expected to
be largely compositional.
None of the above-mentioned properties are suffi-
cient criteria by themselves for determining which
semantic class a given verb+noun combination be-
longs to. Moreover, semantic properties of the con-
stituents of a combination are also known to be rele-
vant for determining its class (Uchiyama et al., 2005).
Verbs may exhibit strong preferences for appearing
in MWEs from a particular class, e.g., give, take and
make commonly form LVCs. The semantic category
of the noun is also relevant to the type of MWE, e.g.,
the noun constituent of an LVC is often a predicative
one. We hypothesize that if we look at evidence from
all these different sources, we will find members of
the same class to be reasonably similar, and members
of different classes to be notably different.
</bodyText>
<sectionHeader confidence="0.994565" genericHeader="method">
3 Statistical Measures of Semantic
Idiosyncrasy
</sectionHeader>
<bodyText confidence="0.9999335">
This section introduces measures for quantifying the
properties of idiosyncratic MWEs, mentioned in the
previous section. The measures will be used as fea-
tures in a classification task (see Sections 4–5).
</bodyText>
<subsectionHeader confidence="0.9995">
3.1 Measuring Institutionalization
</subsectionHeader>
<bodyText confidence="0.999679">
Corpus-based approaches often assess the degree of
institutionalization of an expression by the frequency
with which it occurs. Raw frequencies drawn from
a corpus are not reliable on their own, hence asso-
ciation measures such as pointwise mutual informa-
tion (PMI) are also used in many NLP applications
(Church et al., 1991). PMI of a verb+noun combina-
tion �v, n&gt;- is defined as:
</bodyText>
<equation confidence="0.991698">
P(v, n)
PMI (v, n) = � log P(v) P(n)
f (*, *)f (v, n)
� log f (v, *) f (*, n) (1)
</equation>
<bodyText confidence="0.999363">
where all frequency counts are calculated over
verb–object pairs in a corpus. We use both frequency
and PMI of a verb+noun combination to measure its
degree of institutionalization. We refer to this group
of measures as INST.
</bodyText>
<subsectionHeader confidence="0.999828">
3.2 Measuring Fixedness
</subsectionHeader>
<bodyText confidence="0.995390625">
To measure fixedness, we use statistical measures of
lexical, syntactic, and overall fixedness that we have
developed in a previous study (Fazly and Stevenson,
2006), as well as some new measures we introduce
here. The following paragraphs give a brief descrip-
tion of each.
Fixednessle7C quantifies the degree of lexical fixed-
ness of the target combination, �v, n&gt;-, by compar-
ing its strength of association (measured by PMI)
with those of its lexical variants. Like Lin (1999),
we generate lexical variants of the target automati-
cally by replacing either the verb or the noun con-
stituent by a semantically similar word from the
automatically-built thesaurus of Lin (1998). We then
use a standard statistic, the z-score, to calculate
Fixednessle�:
</bodyText>
<equation confidence="0.8410925">
Fixednessle�(v, n) �= (2)
std
</equation>
<bodyText confidence="0.9508445">
where PMI is the mean and std the standard devia-
tion over the PMI of the target and all its variants.
Fixedness��n quantifies the degree of syntactic
fixedness of the target combination, by comparing
its behaviour in text with the behaviour of a typical
verb–object, both defined as probability distributions
over a predefined set of patterns. We use a stan-
dard information-theoretic measure, relative entropy,
</bodyText>
<equation confidence="0.800764">
PMI(v, n) − PMI
</equation>
<page confidence="0.949368">
11
</page>
<bodyText confidence="0.837799666666667">
v det:NULL n99 v det:NULL np`
v det:a/an n99
v det:the n99 v det:the np`
v det:DEM n99 v det:DEM np`
v det:POSS n99 v det:POSS np`
v det:OTHER nsg,p` det:ANY n9g,p` be vpassive
</bodyText>
<tableCaption confidence="0.89088">
Table 2: Patterns for syntactic fixedness measure.
</tableCaption>
<bodyText confidence="0.972403">
to calculate the divergence between the two distribu-
tions as follows:
</bodyText>
<equation confidence="0.994857833333333">
Fixednesssyn (v, n)
= D(P(pt|v, n)  ||P(pt))
�
P(ptk |v, n)
P(ptk |v, n) log (3)
P(ptk)
</equation>
<bodyText confidence="0.999955555555555">
where P is the set of patterns (shown in Table 2)
known to be relevant to syntactic fixedness in LVCs
and IDMs. P(pt |v, n) represents the syntactic be-
haviour of the target, and P(pt) represents the typical
syntactic behaviour over all verb–object pairs.
Fixednesssyn does not show which syntactic pat-
tern the target prefers the most. We thus use an addi-
tional measure, Patterndom, to determine the domi-
nant pattern for the target:
</bodyText>
<equation confidence="0.960606">
Patterndom(v, n) = � argmax f (v, n, ptk) (4)
ptk EP
</equation>
<bodyText confidence="0.999702">
In addition to the individual measures of fixedness,
we use Fixednessoverall, which quantifies the degree
of overall fixedness of the target:
</bodyText>
<equation confidence="0.98596675">
Fixednessoverall (v, n)
= a Fixednesssyn (v, n)
�
+ (1 − a) Fixednesslex (v, n) (5)
</equation>
<bodyText confidence="0.973308428571429">
where a weights the relative contribution of lexi-
cal and syntactic fixedness in predicting semantic id-
iosyncrasy.
Fixednessadj quantifies the degree of fixedness
of the target combination with respect to adjectival
modification of the noun constituent. It is similar to
the syntactic fixedness measure, except here there are
only two patterns that mark the presence or absence
of an adjectival modifier preceding the noun:
Fixednessadj(v, n) =� D(P(ai|v, n)  ||P(ai)) (6)
where ai E {present, absent}. Fixednessadj does
not determine which pattern of modification the tar-
get combination prefers most. We thus add another
measure—the odds of modification—to capture this:
</bodyText>
<equation confidence="0.998906">
P(ai =present|v, n)
Oddsadj(v, n) = � P(ai = absent|v, n) (7)
</equation>
<bodyText confidence="0.99942">
Overall, we use six measures related to fixedness;
we refer to the group as FIXD.
</bodyText>
<subsectionHeader confidence="0.999654">
3.3 Measuring Compositionality
</subsectionHeader>
<bodyText confidence="0.99994385">
Compositionality of an expression is often approxi-
mated by comparing the “context” of the expression
with the contexts of its constituents. We measure
the degree of compositionality of a target verb+noun
combination, t =≺v, n≻, in a similar fashion.
We take the context of the target (t) and each of its
constituents (v and n) to be a vector of the frequency
of nouns cooccurring with it within a window of ±5
words. We then measure the “similarity” between the
target and each of its constituents, Simdist (t, v) and
Simdist (t, n), using the cosine measure.1
Recall that an LVC can be roughly paraphrased by
a verb that is morphologically related to its noun con-
stituent, e.g., to make a decision nearly means to de-
cide. For each target t, we thus add a third measure,
Simdist (t, rv), where rv is a verb morphologically
related to the noun constituent of t, and is automati-
cally extracted from WordNet (Fellbaum, 1998).2
We use abbreviation COMP to refer to the group of
measures related to compositionality.
</bodyText>
<subsectionHeader confidence="0.965424">
3.4 The Constituents
</subsectionHeader>
<bodyText confidence="0.872944714285714">
Recall that semantic properties of the constituents of
a verb+noun combination are expected to be relevant
to its semantic class. We thus add two simple fea-
ture groups: (i) the verb itself (VERB); and (ii) the
semantic category of the noun according to WordNet
(NSEM). We take the semantic category of a noun to
be the ancestor of its first sense in the hypernym hier-
archy of WordNet 2.1, cut at the level of the children
1Our preliminary experiments on development data from Fa-
zly and Stevenson (2006) revealed that the cosine measure and a
window size of f5 words resulted in the best performance.
2If no such verb exists, Simdigt (t, rv) is set to zero. If more
than one verb exist, we choose the one that is identical to the
noun or the one that is shorter in length.
</bodyText>
<equation confidence="0.597513">
=
ptk EP
</equation>
<page confidence="0.952073">
12
</page>
<bodyText confidence="0.988985">
of ENTITY (which will include PHYSICAL ENTITY
and ABSTRACT ENTITY).3
</bodyText>
<sectionHeader confidence="0.99975" genericHeader="method">
4 Experimental Setup
</sectionHeader>
<subsectionHeader confidence="0.99826">
4.1 Corpus and Experimental Expressions
</subsectionHeader>
<bodyText confidence="0.997463842105263">
We use the British National Corpus (BNC),4 auto-
matically parsed using the Collins parser (Collins,
1999), and further processed with TGrep2.5 We
select our potential experimental expressions from
pairs of verb and direct object that have a minimum
frequency of 25 in the BNC and that involve one
of a predefined list of basic (transitive) verbs. Ba-
sic verbs, which in their literal uses refer to states or
acts central to human experience (e.g., give and put),
commonly form MWEs in combination with their di-
rect object argument (Cowie et al., 1983). We use 12
such verbs ranked highly according to the number of
different nouns they appear with in the BNC. Here
are the verbs in alphabetical order:
bring, find, get, give, hold, keep, lose, make, put, see, set, take
To guarantee that the final set of expressions con-
tains pairs from all four classes, we pseudo-randomly
select them from the initial list of pairs extracted from
the BNC as explained above. To ensure the inclusion
of IDMs, we consult two idioms dictionaries (Cowie
et al., 1983; Seaton and Macaulay, 2002). To en-
sure we include LVCs, we select pairs in which the
noun has a morphologically related verb according
to WordNet. We also select pairs whose noun is not
morphologically related to any verb to ensure the in-
clusion of LIT combinations.
This selection process resulted in 632 pairs, re-
duced to 563 after annotation (see Section 4.2 for
details on annotation). Out of these, 148 are LIT,
196 are ABS, 102 are LVC, and 117 are IDM. We
randomly choose 102 pairs from each class as our
final experimental expressions. We then pseudo-
randomly divide these into training (TRAIN), devel-
opment (DEV), and test (TEST) data sets, so that each
set has an equal number of pairs from each class. In
addition, we ensure that pairs with the same verb that
belong to the same class are divided equally among
the three sets. Our final TRAIN, DEV, and TEST sets
</bodyText>
<footnote confidence="0.999306">
3Experiments on development data show that looking at all
senses of a noun degrades performance.
4http://www.natcorp.ox.ac.uk.
5http://tedlab.mit.edu/—dr/Tgrep2.
</footnote>
<construct confidence="0.303098">
contain 240, 84, and 84 pairs, respectively.
</construct>
<subsectionHeader confidence="0.96234">
4.2 Human Judgments
</subsectionHeader>
<bodyText confidence="0.999970620689655">
We asked four native speakers of English with suf-
ficient linguistic background to annotate our exper-
imental expressions. The annotation task was ex-
pected to be time-consuming, hence it was not feasi-
ble for all the judges to annotate all the expressions.
Instead, we asked one judge to be our primary anno-
tator, PA henceforth. (PA is an author of this paper,
but the other three judges are not.)
First, PA annotated all the 632 expressions selected
as described in Section 4.1, and removed 69 of them
that could be potential sources of disagreement for
various reasons (e.g., if an expression was unfamil-
iar or was likely to be part of a larger phrase). Next,
we divided the remaining 563 pairs into three equal-
sized sets, and gave each set to one of the other
judges to annotate. The judges were given a com-
prehensive guide for the task, in which the classes
were defined solely in terms of their semantic prop-
erties. Since expressions were annotated out of con-
text (type-based), we asked the judges to annotate the
predominant meaning of each expression.
We use the annotations of PA as our gold standard
for evaluation, but use the annotations of the others
to measure inter-annotator agreement. The observed
agreement (po) between PA and each of the other
three annotators are 79.8%, 72.2%, and 67%, respec-
tively. The kappa (r.) scores are .72, .62, and .56.
The reasonably high agreement scores confirm that
the classes are coherent and linguistically plausible.
</bodyText>
<subsectionHeader confidence="0.999921">
4.3 Classification Strategy and Features
</subsectionHeader>
<bodyText confidence="0.999993166666667">
We use the decision tree induction system C5.0 as
our machine learning software, and the measures pro-
posed in Section 3 as features in our classification ex-
periments.6 We explore the relevance of each feature
group in the overall classification, as well as in iden-
tifying members of each individual class.
</bodyText>
<sectionHeader confidence="0.997856" genericHeader="evaluation">
5 Experimental Results
</sectionHeader>
<bodyText confidence="0.998176">
We performed experiments on DEV to find features
most relevant for classification. These experiments
</bodyText>
<footnote confidence="0.988479">
6Experiments on DEV using a Support Vector Machine algo-
rithm produced poorer results; we thus do not report them.
</footnote>
<page confidence="0.999522">
13
</page>
<bodyText confidence="0.999941090909091">
revealed that removing SimdiA (t, v) resulted in bet-
ter performance. This is not surprising given that ba-
sic verbs are highly polysemous, and hence the distri-
butional context of a basic verb may not correspond
to any particular sense of it. We thus remove this
feature (from COMP) in experiments on TEST. Re-
sults presented here are on the TEST set; those on the
DEV set have similar trends. Here, we first look at the
overall performance of classification in Section 5.1.
Section 5.2 presents the results of classification for
the individual classes.
</bodyText>
<subsectionHeader confidence="0.988414">
5.1 Overall Classification Performance
</subsectionHeader>
<bodyText confidence="0.997520514285714">
Table 3 presents the results of classification—in
terms of average accuracy (%Acc) and relative er-
ror reduction (%RER)—for the individual feature
groups, as well as for all groups combined. The base-
line (chance) accuracy is 25% since we have four
equal-sized classes in TEST. As can be seen, INST
features yield the lowest overall accuracy, around
36%, with a relative error reduction of only 14%
over the baseline. This shows that institutionaliza-
tion, although relevant, is not sufficient for distin-
guishing among different levels of semantic idiosyn-
crasy. Interestingly, FIXD features achieve the high-
est accuracy, 50%, with a relative error reduction of
33%, showing that fixedness is a salient aspect of se-
mantic idiosyncrasy. COMP features achieve reason-
ably good accuracy, around 40%, though still notably
lower than the accuracy of FIXD features. This is es-
pecially interesting since much previous research has
focused solely on the non-compositionality of MWEs
to identify them (McCarthy et al., 2003; Baldwin et
al., 2003; Bannard et al., 2003). Our results confirm
the relevance of this property, while at the same time
revealing its insufficiency. Interestingly, features re-
lated to the semantic properties of the constituents,
VERB and NSEM, overall perform comparably to the
compositionality features. However, a closer look at
their performance on the individual classes (see Sec-
tion 5.2) reveals that, unlike COMP, they are mainly
good at identifying items from certain classes. As
hypothesized, we achieve the highest performance,
an accuracy of 58% and a relative error reduction of
44%, when we combine all features.
Table 4 displays classification performance, when
we use all the feature groups except one. These re-
sults are more or less consistent with those in Ta-
</bodyText>
<table confidence="0.989964571428572">
Only the features in group %Acc (%RER)
INST 35.7 (14.3)
FIXD 50 (33.3)
COMP 40.5 (20.7)
VERB 42.9 (23.9)
NSEM 39.3 (19.1)
ALL 58.3 (44.4)
</table>
<tableCaption confidence="0.84478">
Table 3: Accuracy (%Acc) and relative error reduction
(%RER) over TEST pairs, for the individual feature groups, and
for all features combined.
</tableCaption>
<table confidence="0.9998">
All features except those in group %Acc (%RER)
INST 53.6 (38.1)
FIXD 47.6 (30.1)
COMP 56 (41.3)
VERB 48.8 (31.7)
NSEM 46.4 (28.5)
ALL 58.3 (44.4)
</table>
<tableCaption confidence="0.995114">
Table 4: Accuracy (%Acc) and relative error reduction
(%RER) over TEST pairs, removing one feature group at a time.
</tableCaption>
<bodyText confidence="0.999944352941177">
ble 3 above, except some differences which we dis-
cuss below. Removing FIXD features results in a
drastic decrease in performance (10.7%), while the
removal of INST and COMP features cause much
smaller drops in performance (4.7% and 2.3%, re-
spectively). Here again, we can see that features re-
lated to the semantics of the verb and the noun are
salient features. Removing either of these results
in a substantial decrease in performance—9.5% and
11.9%, respectively—which is comparable to the de-
crease resulting from removing FIXD features. This
is an interesting observation, since VERB and NSEM
features, on their own, do not perform nearly as well
as FIXD features. It is thus necessary to futher in-
vestigate the performance of these groups on larger
data sets with more variability in the verb and noun
constituents of the expressions.
</bodyText>
<subsectionHeader confidence="0.999713">
5.2 Performance on Individual Classes
</subsectionHeader>
<bodyText confidence="0.999565444444444">
We now look at the performance of the feature
groups, both separately and combined, on the indi-
vidual classes. For each combination of class and
feature group, the F-measures of classification are
given in Table 5, with the two highest F-measures
for each class shown in boldface.7 These results
show that the combination of all feature groups yields
the best or the second-best performance on all four
classes. (In fact, in only one case is the performance
</bodyText>
<footnote confidence="0.962802">
7Our F-measure gives equal weights to precision and recall.
</footnote>
<page confidence="0.995587">
14
</page>
<table confidence="0.972263833333333">
Only the features in group
Class INST FIXD COMP VERB NSEM ALL
LIT .48 .42 .51 .54 .57 .60
ABS .40 .32 .17 .27 .49 .46
LVC .21 .58 .47 .55 - .68
IDM .33 .67 .42 0 - .56
</table>
<tableCaption confidence="0.9741795">
Table 5: F-measures on TEST pairs, for individual feature
groups and all features combined.
</tableCaption>
<table confidence="0.9998455">
ANNOTATOR1 ANNOTATOR2 ANNOTATORS
Class %po r, %po r, %po K
LIT 93.6 .83 88.3 .67 91.4 .78
ABS 83 .63 76.6 .46 78 .52
LVC 91 .71 83 .54 87.7 .61
IDM 92 .73 87.2 .63 87.2 .59
</table>
<tableCaption confidence="0.989666">
Table 6: Per-class observed agreement and kappa score be-
tween PA and each of the three annotators.
</tableCaption>
<bodyText confidence="0.999700551724138">
of ALL features notably smaller than the best perfor-
mance achieved by a single feature group.)
Looking at the performance of ALL features, we
can see that we get reasonably high F-measure for
all classes, except for ABS. The relatively low values
of po and r. on this class, as shown in Table 6, suggest
that this class was also the hardest to annotate. It is
possible that members of this class share properties
with other classes. The extremely poor performance
of the COMP features on ABS also reflects that per-
haps members of this class are not coherent in terms
of their degree of compositionality (e.g, compare give
confidence and make a living). In the future, we need
to incorporate more coherent membership criteria for
this class into our annotation procedure.
According to Table 5, the most relevant feature
group for identifying members of the LIT and ABS
classes is NSEM. This is expected since NSEM is a bi-
nary feature determining whether the noun is a PHYS-
ICAL ENTITY or an ABSTRACT ENTITY.8 Among
other feature groups, INST features also perform rea-
sonably well on both these classes. The most relevant
feature group for LVC and IDM is FIXD. (Note that
for IDM, the performance of this group is notably
higher than ALL). On the other hand, INST features
have a very poor performance on these classes, rein-
forcing that IDMs and LVCs may not necessarily ap-
pear with significantly high frequency of occurrence
in a given corpus. Fixedness features thus prove to be
</bodyText>
<footnote confidence="0.7449975">
8Since this is a binary feature, it can only distinguish two
classes. In the future, we need to include more semantic classes.
</footnote>
<bodyText confidence="0.97854">
particularly important for the identification of highly
idiosyncratic MWEs, such as LVCs and IDMs.
</bodyText>
<sectionHeader confidence="0.999963" genericHeader="related work">
6 Related Work
</sectionHeader>
<bodyText confidence="0.999980558139535">
Much recent work on classifying MWEs focuses on
determining different levels of compositionality in
verb+particle combinations using a measure of distri-
butional similarity (McCarthy et al., 2003; Baldwin
et al., 2003; Bannard et al., 2003). Another group of
research attempts to classify a particular MWE sub-
type, such as verb-particle constructions (VPCs) or
LVCs, according to some fine-grained semantic crite-
ria (Wanner, 2004; Uchiyama et al., 2005; Cook and
Stevenson, 2006). Here, we distinguish subtypes of
MWEs that are defined according to coarse-grained
distinctions in their degree of semantic idiosyncrasy.
Wermter and Hahn (2004) recognize the impor-
tance of distinguishing MWE subtypes that are sim-
ilar to our four classes, but only focus on separat-
ing MWEs as one single class from literal combina-
tions. For this, they use a measure that draws on the
limited modifiability of MWEs, in addition to their
expected high frequency. Krenn and Evert (2001)
attempt to separate German idioms, LVCs, and lit-
eral phrases (of the form verb+prepositional phrase).
They treat LVCs and idioms as institutionalized ex-
pressions, and use frequency and several association
measures, such as PMI, for the task. The main goal
of their work is to find which association measures
are particularly suited for identifying which of these
classes. Here, we look at properties of MWEs other
than their institutionalization (the latter we quantify
using an association measure).
The work most similar to ours is that of Venkata-
pathy and Joshi (2005). They propose a minimally-
supervised classification schema that incorporates a
variety of features to group verb+noun combinations
according to their level of compositionality. Their
work has the advantage of requiring only a small
amount of manually-labeled training data. However,
their classes are defined on the basis of composition-
ality only. Here, we consider classes that are linguis-
tically salient, and moreover need special treatment
within a computational system. Our work is also dif-
ferent in that it brings in a new group of features, the
fixedness measures, which prove to be very effective
in identifying particular classes of MWEs.
</bodyText>
<page confidence="0.996995">
15
</page>
<sectionHeader confidence="0.999542" genericHeader="conclusions">
7 Conclusions
</sectionHeader>
<bodyText confidence="0.999988142857143">
We have provided an analysis of the important char-
acteristics pertaining to the semantic idiosyncrasy of
MWEs. We have also elaborated on the relation-
ship between these properties and four linguistically-
motivated classes of verb+noun combinations, falling
on a continuum from less to more semantically id-
iosyncratic. On the basis of such analysis, we
have developed statistical, corpus-based measures
that quantify each of these properties. Our results
confirm that these measures are effective in type clas-
sification of the MWEs under study. Our class-
based results look into the interaction between the
measures (each capturing a property of MWEs) and
the classes (which are defined in terms of seman-
tic idiosyncrasy). Based on this, we can see which
measures—or properties they relate to—are most or
least relevant for identifying each particular class of
verb+noun combinations. We are currently expand-
ing this work to investigate the use of similar mea-
sures in token classification of verb+noun combina-
tions in context.
</bodyText>
<sectionHeader confidence="0.998198" genericHeader="acknowledgments">
Acknowledgements
</sectionHeader>
<bodyText confidence="0.998269333333333">
We thank Eric Joanis for providing us with NP-head extraction
software. We thank Saif Mohammad for the CooccurrenceMa-
trix and the DistributionalDistance packages.
</bodyText>
<sectionHeader confidence="0.999517" genericHeader="references">
References
</sectionHeader>
<reference confidence="0.99990388607595">
Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and
Dominic Widdows. 2003. An empirical model of mul-
tiword expression decomposability. In Proc. of ACL-
SIGLEX Wkshp. on Multiword Expressions, 89–96.
Colin Bannard, Timothy Baldwin, and Alex Lascarides.
2003. A statistical approach to the semantics of verb-
particles. In Proc. of ACL-SIGLEX Wkshp. on Multi-
word Expressions, 65–72.
Laurel J. Brinton and Minoji Akimoto, eds. 1999. Col-
locational and Idiomatic Aspects of Composite Predi-
cates in the History ofEnglish. John Benjamins.
Miriam Butt. 2003. The light verb jungle. Workshop on
Multi-Verb Constructions.
Cristina Cacciari and Patrizia Tabossi, eds. 1993. Idioms:
Processing, Structure, and Interpretation. Lawrence
Erlbaum Associates, Publishers.
Kenneth Church, William Gale, Patrick Hanks, and Don-
ald Hindle. 1991. Using statistics in lexical analysis.
In Uri Zernik, editor, Lexical Acquisition: Exploiting
On-Line Resources to Build a Lexicon, 115–164.
Michael Collins. 1999. Head-Driven Statistical Models
for Natural Language Parsing. Ph.D. thesis, UPenn.
Paul Cook and Suzanne Stevenson. 2006. Classifying
particle semantics in English verb-particle construc-
tions. In Proc. of COLING-ACL’06 Wkshp. on Multi-
word Expressions, 45–53.
Anthony P. Cowie, Ronald Mackin, and Isabel R. McCaig.
1983. Oxford Dictionary of Current Idiomatic English,
volume 2. OUP.
Anthony P. Cowie. 1981. The treatment of collocations
and idioms in learner’s dictionaries. Applied Linguis-
tics, II(3):223–235.
Afsaneh Fazly and Suzanne Stevenson. 2006. Automat-
ically constructing a lexicon of verb phrase idiomatic
combinations. In Proc. ofEACL’06, 337–344.
Christiane Fellbaum, editor. 1998. WordNet, An Elec-
tronic Lexical Database. MIT Press.
Raymond W., Jr. Gibbs and Nandini P. Nayak. 1989. Psy-
chololinguistic studies on the syntactic behaviour of id-
ioms. Cognitive Psychology, 21:100–138.
Brigitte Krenn and Stefan Evert. 2001. Can we do bet-
ter than frequency? A case study on extracting PP-verb
collocations. In Proc. of ACL’01 Wkshp. on Colloca-
tions, 39–46.
Dekang Lin. 1998. Automatic retrieval and clustering of
similar words. In Proc. of COLING-ACL’98, 768–774.
Dekang Lin. 1999. Automatic identification of non-
compositional phrases. In Proc. ofACL’99, 317–324.
Diana McCarthy, Bill Keller, and John Carroll. 2003.
Detecting a continuum of compositionality in phrasal
verbs. In Proc. ofACL-SIGLEX Wkshp. on Multiword
Expressions, 73–80.
Tadao Miyamoto. 2000. The Light Verb Construction
in Japanese: the Role of the Verbal Noun. John Ben-
jamins.
Rosamund Moon. 1998. Fixed Expressions and Idioms in
English: A Corpus-Based Approach. Oxford Univer-
sity Press.
Geoffrey Nunberg, Ivan A. Sag, and Thomas Wasow.
1994. Idioms. Language, 70(3):491–538.
Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copes-
take, and Dan Flickinger. 2002. Multiword expres-
sions: A pain in the neck for NLP. In Proc. of CI-
CLing’02, 1–15.
Maggie Seaton and Alison Macaulay, eds. 2002. Collins
COBUILD Idioms Dictionary. HarperCollins.
Kiyoko Uchiyama, Timothy Baldwin, and Shun Ishizaki.
2005. Disambiguating Japanese compound verbs.
Computer Speech and Language, 19:497–512.
Sriram Venkatapathy and Aravind Joshi. 2005. Measur-
ing the relative compositionality of verb-noun (V-N)
collocations by integrating features. In Proc. of HLT-
EMNLP’05, 899–906.
Leo Wanner. 2004. Towards automatic fine-grained se-
mantic classification of verb-noun collocations. Natu-
ral Language Engineering, 10(2):95–143.
Joachim Wermter and Udo Hahn. 2004. Collocation ex-
traction based on modifiability statistics. In Proc. of
COLING’04, 980–986.
</reference>
<page confidence="0.998699">
16
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.010078">
<title confidence="0.9870295">Distinguishing Subtypes of Multiword Expressions Linguistically-Motivated Statistical Measures</title>
<author confidence="0.903008">Afsaneh</author>
<affiliation confidence="0.862003666666667">Department of Computer University of Toronto,</affiliation>
<email confidence="0.999515">afsaneh@cs.toronto.edu</email>
<author confidence="0.919419">Suzanne</author>
<affiliation confidence="0.875503666666667">Department of Computer University of Toronto,</affiliation>
<email confidence="0.999902">suzanne@cs.toronto.edu</email>
<abstract confidence="0.997427131921825">We identify several classes of multiword expressions that each require a different encoding in a (computational) lexicon, as well as a different treatment within a computational system. We examine linguistic properties pertaining to the degree of semantic idiosyncrasy of these classes of expressions. Accordingly, we propose statistical measures to quantify each property, and use the measures to automatically distinguish the classes. 1 Motivation Multiword expressions (MWEs) are widely used in written language as well as in colloquial speech. An MWE is composed of two or more words that toform a single unit of meaning, e.g., a and the Most MWEs behave like any phrase composed of multiple words, e.g., components may be separated, as in took a stroll along the Nonetheless, MWEs are distinct from multiword phrases because they involve some degree of semantic idiosyncrasy, i.e., the overall meaning of an MWE diverges from the combined contribution of its constituent parts. Because of their frequency and their peculiar behaviour, MWEs pose a great challenge to the creation of natural language processing (NLP) systems (Sag et al., 2002). NLP applications, such as semantic parsing and machine translation should not only identify MWEs, but also should know how to treat them when they are encountered. Semantic idiosyncrasy is a matter of degree (Nunet al., 1994). The idiom the breeze largely idiosyncratic, because its meaning (“to chat”) not have much to do with the meaning of MWEs such as a try and decision are semantically less idiosyncratic (more predictable). These are MWEs because the overall meaning of the expression diverges from the combined meanings of the constituents. Nonetheless, there is some degree of predictability in their meanings that makes them distinct from idioms. In these, the complement of the verb (here, a noun) determines the primary meaning of the overall expression. This class of expressions is referred to as light verb constructions (LVCs) in the linguistics literature (Miyamoto, 2000; Butt, 2003). Clearly, a computational system should distinguish idioms and LVCs, both from each other, and from (literal) phrases such as bird a Idioms are largely idiosyncratic; a computational lexicographer thus may to list idioms such as the breeze a lexicon along with their idiomatic meanings. In contrast, meaning of MWEs such as a decision be largely predicted, given that they are LVCs. Table 1 shows the different underlying semantic strucof a sentence containing an idiom the and a sentence containing an LVC a As can be seen, such MWEs should also be treated differently when translated into another language. Note that in contrast to a literal combination, as the for idioms and LVCs, the number of arguments expressed syntactically may differ from the number of the semantic participants. Many NLP applications also need to distinguish another group of MWEs that are less idiosyncratic 9 of the Workshop on A Broader Perspective on Multiword pages 9–16, June 2007. Association for Computational Linguistics Class English sentence Semantic representation French translation and Tim shotthe bird. et Tim ont abattul’oiseau. and Tim shot down the bird. makes a living singing in pubs. gagne sa vie en chantant dans des bars. makes a living by singing in the pubs. gavethe lasagna a try. a essay´e le lasagne. tried the and Tim the breeze. et Tim ont bavard´e. and Tim chatted. 1: English MWEs and their translation in French. than idioms and LVCs, but more so than literal com- Examples include confidence a These are idiosyncratic because the meaning of the verb is a metaphorical (abstract) extension of its basic physical semantics. Moreover, they often take on certain connotations beyond the compositional combination of their constituent meanings. They thus exhibit behaviour often attributed to collocations, e.g., they appear with greater frequency than semantically similar combinations. For example, searching on Google, we found higher frequency for confidence As can be seen in Table 1, an abcombination such as a although largely compositional, may not translate word-forword. Rather, it should be translated taking into account that the verb has a metaphorical meaning, different from its basic semantics. Here, we focus on a particular class of English MWEs that are formed from the combination of a verb with a noun in its direct object position, referred to as verb+noun combinations. Specifically, we provide a framework for identifying members of the following semantic classes of verb+noun combinations: (i) literal phrases (LIT), (ii) abstract combinations (ABS), (iii) light verb constructions (LVC), and (iv) idiomatic combinations (IDM). Section 2 elaborates on the linguistic properties related to the differences in the degree of semantic idiosyncrasy observed in members of the above four classes. In Section 3, we propose statistical measures for quantifying each of these properties, and use them as features for type classification of verb+noun combinations. Section 4 and Section 5 present an evaluation of our proposed measures. Section 6 discusses the related studies, and Section 7 concludes the paper. 2 Semantic Idiosyncrasy: Linguistic Properties Linguists and lexicographers often attribute certain characteristics to semantically idiosyncratic expressions. Some of the widely-known properties are institutionalization, lexicosyntactic fixedness, and noncompositionality (Cowie, 1981; Gibbs and Nayak, 1989; Moon, 1998). The following paragraphs elaborate on each property, as well as on its relevance to the identification of the classes under study. the process through which a combination of words becomes recognized and accepted as a semantic unit involving some degree of semantic idiosyncrasy. IDMs, LVCs, and ABS combinations are institutionalized to some extent. fixedness to some degree of lexical and syntactic restrictiveness in a semantically idiosyncratic expression. An expression is lexically fixed if the substitution of a semantically similar word for any of its constituents does not preserve its meaning (e.g., compare the beans the In contrast to LIT and ABS combinations, IDMs and LVCs are expected to exhibit lexical fixedness to some extent. An expression is syntactically fixed if it cannot undergo syntactic variations and at the same time retain its original semantic interpretation. IDMs and LVCs are known to show strong preferences for the syntactic patterns they appear in (Cacciari and Tabossi, 1993; Brinton and Akimoto, 1999). E.g., compare 10 gave a groan groan was given by kicked the bucket kicked the buckthe idiom reading). Nonetheless, the type and degree of syntactic fixedness in LVCs and IDMs are different. For example, most LVCs prefer the pattern in which the noun is introduced by the indefinite artiin a try a whereas is not the case with IDMs (e.g., the breeze the IDMs and LVCs may also exhibit preferences with respect to adjectival modification of their noun constituent. LVCs are expected to appear both with and without an adjectival modifier, in a (loud) groan a (wise) IDMs, on the other hand, mostly appear either with adjective, as in an open mind a or without, as in the breeze fun to the situation where the meaning of a word combination deviates from the meaning emerging from a word-by-word interpretation of it. IDMs are largely non-compositional, whereas LVCs are semi-compositional since their meaning can be mainly predicted from the noun constituent. ABS and LIT combinations are expected to be largely compositional. None of the above-mentioned properties are sufficient criteria by themselves for determining which semantic class a given verb+noun combination belongs to. Moreover, semantic properties of the constituents of a combination are also known to be relevant for determining its class (Uchiyama et al., 2005). Verbs may exhibit strong preferences for appearing MWEs from a particular class, e.g., form LVCs. The semantic category of the noun is also relevant to the type of MWE, e.g., the noun constituent of an LVC is often a predicative one. We hypothesize that if we look at evidence from all these different sources, we will find members of the same class to be reasonably similar, and members of different classes to be notably different. 3 Statistical Measures of Semantic Idiosyncrasy This section introduces measures for quantifying the properties of idiosyncratic MWEs, mentioned in the previous section. The measures will be used as features in a classification task (see Sections 4–5). 3.1 Measuring Institutionalization Corpus-based approaches often assess the degree of institutionalization of an expression by the frequency with which it occurs. Raw frequencies drawn from a corpus are not reliable on their own, hence association measures such as pointwise mutual information (PMI) are also used in many NLP applications (Church et al., 1991). PMI of a verb+noun combinadefined as: = f where all frequency counts are calculated over verb–object pairs in a corpus. We use both frequency and PMI of a verb+noun combination to measure its degree of institutionalization. We refer to this group measures as 3.2 Measuring Fixedness To measure fixedness, we use statistical measures of lexical, syntactic, and overall fixedness that we have developed in a previous study (Fazly and Stevenson, 2006), as well as some new measures we introduce here. The following paragraphs give a brief description of each. quantifies the degree of lexical fixedof the target combination, by comparing its strength of association (measured by PMI) with those of its lexical variants. Like Lin (1999), we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by a semantically similar word from the automatically-built thesaurus of Lin (1998). We then a standard statistic, the to calculate std the mean and standard deviation over the PMI of the target and all its variants. quantifies the degree of syntactic fixedness of the target combination, by comparing its behaviour in text with the behaviour of a typical verb–object, both defined as probability distributions over a predefined set of patterns. We use a standard information-theoretic measure, relative entropy, 11 v v v v v v v v v v be 2: for syntactic fixedness measure. calculate the divergence between the two distributions as follows: � log the set of patterns (shown in Table 2) known to be relevant to syntactic fixedness in LVCs IDMs. the syntactic beof the target, and the typical syntactic behaviour over all verb–object pairs. does not show which syntactic pattern the target prefers the most. We thus use an addimeasure, to determine the dominant pattern for the target: = In addition to the individual measures of fixedness, use which quantifies the degree of overall fixedness of the target: � (1 the relative contribution of lexical and syntactic fixedness in predicting semantic idiosyncrasy. the degree of fixedness of the target combination with respect to adjectival modification of the noun constituent. It is similar to the syntactic fixedness measure, except here there are only two patterns that mark the presence or absence of an adjectival modifier preceding the noun: not determine which pattern of modification the target combination prefers most. We thus add another measure—the odds of modification—to capture this: = Overall, we use six measures related to fixedness; refer to the group as 3.3 Measuring Compositionality Compositionality of an expression is often approximated by comparing the “context” of the expression with the contexts of its constituents. We measure the degree of compositionality of a target verb+noun in a similar fashion. take the context of the target and each of its to be a vector of the frequency nouns cooccurring with it within a window of words. We then measure the “similarity” between the and each of its constituents, using the Recall that an LVC can be roughly paraphrased by a verb that is morphologically related to its noun cone.g., make a decision means de- For each target we thus add a third measure, where a verb morphologically to the noun constituent of and is automatiextracted from WordNet (Fellbaum, use abbreviation refer to the group of measures related to compositionality. 3.4 The Constituents Recall that semantic properties of the constituents of a verb+noun combination are expected to be relevant to its semantic class. We thus add two simple feagroups: (i) the verb itself and (ii) the semantic category of the noun according to WordNet We take the semantic category of a noun to be the ancestor of its first sense in the hypernym hierarchy of WordNet 2.1, cut at the level of the children preliminary experiments on development data from Faand Stevenson (2006) revealed that the and a size of resulted in the best performance. no such verb exists, set to zero. If more than one verb exist, we choose the one that is identical to the noun or the one that is shorter in length. = 12 will include ENTITY 4 Experimental Setup 4.1 Corpus and Experimental Expressions use the British National Corpus automatically parsed using the Collins parser (Collins, and further processed with We select our potential experimental expressions from pairs of verb and direct object that have a minimum of the BNC and that involve one of a predefined list of basic (transitive) verbs. Basic verbs, which in their literal uses refer to states or central to human experience (e.g., commonly form MWEs in combination with their diobject argument (Cowie et al., 1983). We use such verbs ranked highly according to the number of different nouns they appear with in the BNC. Here are the verbs in alphabetical order: bring, find, get, give, hold, keep, lose, make, put, see, set, take To guarantee that the final set of expressions contains pairs from all four classes, we pseudo-randomly select them from the initial list of pairs extracted from the BNC as explained above. To ensure the inclusion of IDMs, we consult two idioms dictionaries (Cowie et al., 1983; Seaton and Macaulay, 2002). To ensure we include LVCs, we select pairs in which the noun has a morphologically related verb according to WordNet. We also select pairs whose noun is not morphologically related to any verb to ensure the inclusion of LIT combinations. selection process resulted in reto annotation (see Section 4.2 for on annotation). Out of these, LIT, ABS, LVC, and IDM. We choose from each class as our final experimental expressions. We then pseudodivide these into training develand test data sets, so that each set has an equal number of pairs from each class. In addition, we ensure that pairs with the same verb that belong to the same class are divided equally among three sets. Our final and on development data show that looking at all senses of a noun degrades performance. and respectively. 4.2 Human Judgments We asked four native speakers of English with sufficient linguistic background to annotate our experimental expressions. The annotation task was expected to be time-consuming, hence it was not feasible for all the judges to annotate all the expressions. Instead, we asked one judge to be our primary annoan author of this paper, but the other three judges are not.) all the selected described in Section 4.1, and removed them that could be potential sources of disagreement for various reasons (e.g., if an expression was unfamiliar or was likely to be part of a larger phrase). Next, divided the remaining into three equalsized sets, and gave each set to one of the other judges to annotate. The judges were given a comprehensive guide for the task, in which the classes were defined solely in terms of their semantic properties. Since expressions were annotated out of context (type-based), we asked the judges to annotate the predominant meaning of each expression. use the annotations of our gold standard for evaluation, but use the annotations of the others to measure inter-annotator agreement. The observed between each of the other annotators are and respec- The kappa scores are and The reasonably high agreement scores confirm that the classes are coherent and linguistically plausible. 4.3 Classification Strategy and Features We use the decision tree induction system C5.0 as our machine learning software, and the measures proposed in Section 3 as features in our classification ex- We explore the relevance of each feature group in the overall classification, as well as in identifying members of each individual class. 5 Experimental Results performed experiments on find features most relevant for classification. These experiments on a Support Vector Machine algorithm produced poorer results; we thus do not report them. 13 that removing in better performance. This is not surprising given that basic verbs are highly polysemous, and hence the distributional context of a basic verb may not correspond to any particular sense of it. We thus remove this (from in experiments on Represented here are on the those on the have similar trends. Here, we first look at the overall performance of classification in Section 5.1. Section 5.2 presents the results of classification for the individual classes. 5.1 Overall Classification Performance Table 3 presents the results of classification—in of average accuracy and relative erreduction the individual feature groups, as well as for all groups combined. The base- (chance) accuracy is we have four classes in As can be seen, features yield the lowest overall accuracy, around with a relative error reduction of only over the baseline. This shows that institutionalization, although relevant, is not sufficient for distinguishing among different levels of semantic idiosyn- Interestingly, achieve the highaccuracy, with a relative error reduction of showing that fixedness is a salient aspect of seidiosyncrasy. achieve reasongood accuracy, around though still notably than the accuracy of This is especially interesting since much previous research has focused solely on the non-compositionality of MWEs to identify them (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Our results confirm the relevance of this property, while at the same time revealing its insufficiency. Interestingly, features related to the semantic properties of the constituents, overall perform comparably to the compositionality features. However, a closer look at their performance on the individual classes (see Sec- 5.2) reveals that, unlike they are mainly good at identifying items from certain classes. As hypothesized, we achieve the highest performance, accuracy of a relative error reduction of when we combine all features. Table 4 displays classification performance, when we use all the feature groups except one. These reare more or less consistent with those in Ta- Only the features in group INST 35.7 (14.3) FIXD 50 (33.3) COMP 40.5 (20.7) VERB 42.9 (23.9) NSEM 39.3 (19.1) ALL 58.3 3: and relative error reduction over for the individual feature groups, and for all features combined. All features except those in group INST 53.6 (38.1) FIXD 47.6 (30.1) COMP 56 (41.3) VERB 48.8 (31.7) NSEM 46.4 (28.5) ALL 58.3 4: and relative error reduction over removing one feature group at a time. ble 3 above, except some differences which we disbelow. Removing results in a decrease in performance while the of cause much drops in performance respectively). Here again, we can see that features related to the semantics of the verb and the noun are salient features. Removing either of these results a substantial decrease in respectively—which is comparable to the deresulting from removing This an interesting observation, since features, on their own, do not perform nearly as well It is thus necessary to futher investigate the performance of these groups on larger data sets with more variability in the verb and noun constituents of the expressions. 5.2 Performance on Individual Classes We now look at the performance of the feature groups, both separately and combined, on the individual classes. For each combination of class and group, the of classification are in Table 5, with the two highest each class shown in These results show that the combination of all feature groups yields the best or the second-best performance on all four classes. (In fact, in only one case is the performance gives equal weights to precision and recall. 14 Only the features in group Class INST FIXD COMP VERB NSEM ALL LIT .48 .42 .51 .54 .57 .60 ABS .40 .32 .17 .27 .49 .46 LVC .21 .58 .47 .55 - .68 IDM .33 .67 .42 0 - .56 5: on for individual feature groups and all features combined. Class r, r, K LIT 93.6 .83 88.3 .67 91.4 .78 ABS 83 .63 76.6 .46 78 .52 LVC 91 .71 83 .54 87.7 .61 IDM 92 .73 87.2 .63 87.2 .59 6: observed agreement and kappa score beeach of the three annotators. notably smaller than the best performance achieved by a single feature group.) at the performance of we see that we get reasonably high for all classes, except for ABS. The relatively low values and this class, as shown in Table 6, suggest that this class was also the hardest to annotate. It is possible that members of this class share properties with other classes. The extremely poor performance the on ABS also reflects that perhaps members of this class are not coherent in terms their degree of compositionality (e.g, compare a In the future, we need to incorporate more coherent membership criteria for this class into our annotation procedure. According to Table 5, the most relevant feature group for identifying members of the LIT and ABS is This is expected since a bifeature determining whether the noun is a ENTITY an Among feature groups, also perform reasonably well on both these classes. The most relevant group for LVC and IDM is (Note that for IDM, the performance of this group is notably than On the other hand, have a very poor performance on these classes, reinforcing that IDMs and LVCs may not necessarily appear with significantly high frequency of occurrence in a given corpus. Fixedness features thus prove to be this is a binary feature, it can only distinguish two classes. In the future, we need to include more semantic classes. particularly important for the identification of highly idiosyncratic MWEs, such as LVCs and IDMs. 6 Related Work Much recent work on classifying MWEs focuses on determining different levels of compositionality in verb+particle combinations using a measure of distributional similarity (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from literal combinations. For this, they use a measure that draws on the limited modifiability of MWEs, in addition to their expected high frequency. Krenn and Evert (2001) attempt to separate German idioms, LVCs, and literal phrases (of the form verb+prepositional phrase). They treat LVCs and idioms as institutionalized expressions, and use frequency and several association measures, such as PMI, for the task. The main goal of their work is to find which association measures are particularly suited for identifying which of these classes. Here, we look at properties of MWEs other than their institutionalization (the latter we quantify using an association measure). The work most similar to ours is that of Venkatapathy and Joshi (2005). They propose a minimallysupervised classification schema that incorporates a variety of features to group verb+noun combinations according to their level of compositionality. Their work has the advantage of requiring only a small amount of manually-labeled training data. However, their classes are defined on the basis of compositionality only. Here, we consider classes that are linguistically salient, and moreover need special treatment within a computational system. Our work is also different in that it brings in a new group of features, the fixedness measures, which prove to be very effective in identifying particular classes of MWEs. 15 7 Conclusions We have provided an analysis of the important characteristics pertaining to the semantic idiosyncrasy of MWEs. We have also elaborated on the relationship between these properties and four linguisticallymotivated classes of verb+noun combinations, falling on a continuum from less to more semantically idiosyncratic. On the basis of such analysis, we have developed statistical, corpus-based measures that quantify each of these properties. Our results confirm that these measures are effective in type classification of the MWEs under study. Our classbased results look into the interaction between the measures (each capturing a property of MWEs) and the classes (which are defined in terms of semantic idiosyncrasy). Based on this, we can see which measures—or properties they relate to—are most or least relevant for identifying each particular class of verb+noun combinations. We are currently expanding this work to investigate the use of similar measures in token classification of verb+noun combinations in context. Acknowledgements We thank Eric Joanis for providing us with NP-head extraction software. We thank Saif Mohammad for the CooccurrenceMatrix and the DistributionalDistance packages.</abstract>
<title confidence="0.547551">References</title>
<author confidence="0.547984">Timothy Baldwin</author>
<author confidence="0.547984">Colin Bannard</author>
<author confidence="0.547984">Takaaki Tanaka</author>
<note confidence="0.963604550724637">Dominic Widdows. 2003. An empirical model of mulexpression decomposability. In of ACL- Wkshp. on Multiword 89–96. Colin Bannard, Timothy Baldwin, and Alex Lascarides. 2003. A statistical approach to the semantics of verb- In of ACL-SIGLEX Wkshp. on Multi- 65–72. J. Brinton and Minoji Akimoto, eds. 1999. Collocational and Idiomatic Aspects of Composite Prediin the History John Benjamins. Miriam Butt. 2003. The light verb jungle. Workshop on Multi-Verb Constructions. Cacciari and Patrizia Tabossi, eds. 1993. Structure, and Lawrence Erlbaum Associates, Publishers. Kenneth Church, William Gale, Patrick Hanks, and Donald Hindle. 1991. Using statistics in lexical analysis. Uri Zernik, editor, Acquisition: Exploiting Resources to Build a 115–164. Collins. 1999. Statistical Models Natural Language Ph.D. thesis, UPenn. Paul Cook and Suzanne Stevenson. 2006. Classifying particle semantics in English verb-particle construc- In of COLING-ACL’06 Wkshp. on Multi- 45–53. Anthony P. Cowie, Ronald Mackin, and Isabel R. McCaig. Dictionary of Current Idiomatic volume 2. OUP. Anthony P. Cowie. 1981. The treatment of collocations idioms in learner’s dictionaries. Linguis- II(3):223–235. Afsaneh Fazly and Suzanne Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic In 337–344. Fellbaum, editor. 1998. An Elec- Lexical MIT Press. Raymond W., Jr. Gibbs and Nandini P. Nayak. 1989. Psychololinguistic studies on the syntactic behaviour of id- 21:100–138. Brigitte Krenn and Stefan Evert. 2001. Can we do better than frequency? A case study on extracting PP-verb In of ACL’01 Wkshp. on Colloca- 39–46. Dekang Lin. 1998. Automatic retrieval and clustering of words. In of 768–774. Dekang Lin. 1999. Automatic identification of nonphrases. In 317–324. Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a continuum of compositionality in phrasal In ofACL-SIGLEX Wkshp. on Multiword 73–80. Miyamoto. 2000. Light Verb Construction Japanese: the Role of the Verbal John Benjamins. Moon. 1998. Expressions and Idioms in A Corpus-Based Oxford University Press. Geoffrey Nunberg, Ivan A. Sag, and Thomas Wasow. Idioms. 70(3):491–538. Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expres- A pain in the neck for NLP. In of CI- 1–15. Seaton and Alison Macaulay, eds. 2002. Idioms HarperCollins. Kiyoko Uchiyama, Timothy Baldwin, and Shun Ishizaki. 2005. Disambiguating Japanese compound verbs. Speech and 19:497–512. Sriram Venkatapathy and Aravind Joshi. 2005. Measur-</note>
<abstract confidence="0.840879888888889">ing the relative compositionality of verb-noun (V-N) by integrating features. In of HLT- 899–906. Leo Wanner. 2004. Towards automatic fine-grained seclassification of verb-noun collocations. Natu- Language 10(2):95–143. Joachim Wermter and Udo Hahn. 2004. Collocation exbased on modifiability statistics. In of 980–986.</abstract>
<intro confidence="0.70843">16</intro>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="true">
<authors>
<author>Timothy Baldwin</author>
<author>Colin Bannard</author>
<author>Takaaki Tanaka</author>
<author>Dominic Widdows</author>
</authors>
<title>An empirical model of multiword expression decomposability.</title>
<date>2003</date>
<booktitle>In Proc. of ACLSIGLEX Wkshp. on Multiword Expressions,</booktitle>
<pages>89--96</pages>
<contexts>
<context position="21570" citStr="Baldwin et al., 2003" startWordPosition="3519" endWordPosition="3522">ine. This shows that institutionalization, although relevant, is not sufficient for distinguishing among different levels of semantic idiosyncrasy. Interestingly, FIXD features achieve the highest accuracy, 50%, with a relative error reduction of 33%, showing that fixedness is a salient aspect of semantic idiosyncrasy. COMP features achieve reasonably good accuracy, around 40%, though still notably lower than the accuracy of FIXD features. This is especially interesting since much previous research has focused solely on the non-compositionality of MWEs to identify them (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Our results confirm the relevance of this property, while at the same time revealing its insufficiency. Interestingly, features related to the semantic properties of the constituents, VERB and NSEM, overall perform comparably to the compositionality features. However, a closer look at their performance on the individual classes (see Section 5.2) reveals that, unlike COMP, they are mainly good at identifying items from certain classes. As hypothesized, we achieve the highest performance, an accuracy of 58% and a relative error reduction of 44%, when we combine all featu</context>
<context position="26734" citStr="Baldwin et al., 2003" startWordPosition="4395" endWordPosition="4398">, reinforcing that IDMs and LVCs may not necessarily appear with significantly high frequency of occurrence in a given corpus. Fixedness features thus prove to be 8Since this is a binary feature, it can only distinguish two classes. In the future, we need to include more semantic classes. particularly important for the identification of highly idiosyncratic MWEs, such as LVCs and IDMs. 6 Related Work Much recent work on classifying MWEs focuses on determining different levels of compositionality in verb+particle combinations using a measure of distributional similarity (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from literal combinations.</context>
</contexts>
<marker>Baldwin, Bannard, Tanaka, Widdows, 2003</marker>
<rawString>Timothy Baldwin, Colin Bannard, Takaaki Tanaka, and Dominic Widdows. 2003. An empirical model of multiword expression decomposability. In Proc. of ACLSIGLEX Wkshp. on Multiword Expressions, 89–96.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Colin Bannard</author>
<author>Timothy Baldwin</author>
<author>Alex Lascarides</author>
</authors>
<title>A statistical approach to the semantics of verbparticles.</title>
<date>2003</date>
<booktitle>In Proc. of ACL-SIGLEX Wkshp. on Multiword Expressions,</booktitle>
<pages>65--72</pages>
<contexts>
<context position="21593" citStr="Bannard et al., 2003" startWordPosition="3523" endWordPosition="3526">nstitutionalization, although relevant, is not sufficient for distinguishing among different levels of semantic idiosyncrasy. Interestingly, FIXD features achieve the highest accuracy, 50%, with a relative error reduction of 33%, showing that fixedness is a salient aspect of semantic idiosyncrasy. COMP features achieve reasonably good accuracy, around 40%, though still notably lower than the accuracy of FIXD features. This is especially interesting since much previous research has focused solely on the non-compositionality of MWEs to identify them (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Our results confirm the relevance of this property, while at the same time revealing its insufficiency. Interestingly, features related to the semantic properties of the constituents, VERB and NSEM, overall perform comparably to the compositionality features. However, a closer look at their performance on the individual classes (see Section 5.2) reveals that, unlike COMP, they are mainly good at identifying items from certain classes. As hypothesized, we achieve the highest performance, an accuracy of 58% and a relative error reduction of 44%, when we combine all features. Table 4 displays c</context>
<context position="26757" citStr="Bannard et al., 2003" startWordPosition="4399" endWordPosition="4402">s and LVCs may not necessarily appear with significantly high frequency of occurrence in a given corpus. Fixedness features thus prove to be 8Since this is a binary feature, it can only distinguish two classes. In the future, we need to include more semantic classes. particularly important for the identification of highly idiosyncratic MWEs, such as LVCs and IDMs. 6 Related Work Much recent work on classifying MWEs focuses on determining different levels of compositionality in verb+particle combinations using a measure of distributional similarity (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from literal combinations. For this, they use a m</context>
</contexts>
<marker>Bannard, Baldwin, Lascarides, 2003</marker>
<rawString>Colin Bannard, Timothy Baldwin, and Alex Lascarides. 2003. A statistical approach to the semantics of verbparticles. In Proc. of ACL-SIGLEX Wkshp. on Multiword Expressions, 65–72.</rawString>
</citation>
<citation valid="true">
<authors>
<author>J Laurel</author>
</authors>
<title>Brinton and Minoji Akimoto,</title>
<date>1999</date>
<booktitle>Collocational and Idiomatic Aspects of Composite Predicates in the History ofEnglish. John Benjamins.</booktitle>
<location>eds.</location>
<marker>Laurel, 1999</marker>
<rawString>Laurel J. Brinton and Minoji Akimoto, eds. 1999. Collocational and Idiomatic Aspects of Composite Predicates in the History ofEnglish. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Miriam Butt</author>
</authors>
<title>The light verb jungle. Workshop on Multi-Verb Constructions.</title>
<date>2003</date>
<contexts>
<context position="2514" citStr="Butt, 2003" startWordPosition="387" endWordPosition="388">g of shoot or breeze. MWEs such as give a try (“try”) and make a decision (“decide”) are semantically less idiosyncratic (more predictable). These are MWEs because the overall meaning of the expression diverges from the combined meanings of the constituents. Nonetheless, there is some degree of predictability in their meanings that makes them distinct from idioms. In these, the complement of the verb (here, a noun) determines the primary meaning of the overall expression. This class of expressions is referred to as light verb constructions (LVCs) in the linguistics literature (Miyamoto, 2000; Butt, 2003). Clearly, a computational system should distinguish idioms and LVCs, both from each other, and from similar-on-the-surface (literal) phrases such as shoot the bird and give a present. Idioms are largely idiosyncratic; a computational lexicographer thus may decide to list idioms such as shoot the breeze in a lexicon along with their idiomatic meanings. In contrast, the meaning of MWEs such as make a decision can be largely predicted, given that they are LVCs. Table 1 shows the different underlying semantic structure of a sentence containing an idiom (shoot the breeze) and a sentence containing</context>
</contexts>
<marker>Butt, 2003</marker>
<rawString>Miriam Butt. 2003. The light verb jungle. Workshop on Multi-Verb Constructions.</rawString>
</citation>
<citation valid="true">
<date>1993</date>
<booktitle>Idioms: Processing, Structure, and Interpretation. Lawrence Erlbaum Associates,</booktitle>
<editor>Cristina Cacciari and Patrizia Tabossi, eds.</editor>
<publisher>Publishers.</publisher>
<marker>1993</marker>
<rawString>Cristina Cacciari and Patrizia Tabossi, eds. 1993. Idioms: Processing, Structure, and Interpretation. Lawrence Erlbaum Associates, Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenneth Church</author>
<author>William Gale</author>
<author>Patrick Hanks</author>
<author>Donald Hindle</author>
</authors>
<title>Using statistics in lexical analysis.</title>
<date>1991</date>
<booktitle>In Uri Zernik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon,</booktitle>
<pages>115--164</pages>
<contexts>
<context position="10264" citStr="Church et al., 1991" startWordPosition="1622" endWordPosition="1625">erent. 3 Statistical Measures of Semantic Idiosyncrasy This section introduces measures for quantifying the properties of idiosyncratic MWEs, mentioned in the previous section. The measures will be used as features in a classification task (see Sections 4–5). 3.1 Measuring Institutionalization Corpus-based approaches often assess the degree of institutionalization of an expression by the frequency with which it occurs. Raw frequencies drawn from a corpus are not reliable on their own, hence association measures such as pointwise mutual information (PMI) are also used in many NLP applications (Church et al., 1991). PMI of a verb+noun combination �v, n&gt;- is defined as: P(v, n) PMI (v, n) = � log P(v) P(n) f (*, *)f (v, n) � log f (v, *) f (*, n) (1) where all frequency counts are calculated over verb–object pairs in a corpus. We use both frequency and PMI of a verb+noun combination to measure its degree of institutionalization. We refer to this group of measures as INST. 3.2 Measuring Fixedness To measure fixedness, we use statistical measures of lexical, syntactic, and overall fixedness that we have developed in a previous study (Fazly and Stevenson, 2006), as well as some new measures we introduce her</context>
</contexts>
<marker>Church, Gale, Hanks, Hindle, 1991</marker>
<rawString>Kenneth Church, William Gale, Patrick Hanks, and Donald Hindle. 1991. Using statistics in lexical analysis. In Uri Zernik, editor, Lexical Acquisition: Exploiting On-Line Resources to Build a Lexicon, 115–164.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Michael Collins</author>
</authors>
<title>Head-Driven Statistical Models for Natural Language Parsing.</title>
<date>1999</date>
<tech>Ph.D. thesis, UPenn.</tech>
<contexts>
<context position="15852" citStr="Collins, 1999" startWordPosition="2574" endWordPosition="2575">l of the children 1Our preliminary experiments on development data from Fazly and Stevenson (2006) revealed that the cosine measure and a window size of f5 words resulted in the best performance. 2If no such verb exists, Simdigt (t, rv) is set to zero. If more than one verb exist, we choose the one that is identical to the noun or the one that is shorter in length. = ptk EP 12 of ENTITY (which will include PHYSICAL ENTITY and ABSTRACT ENTITY).3 4 Experimental Setup 4.1 Corpus and Experimental Expressions We use the British National Corpus (BNC),4 automatically parsed using the Collins parser (Collins, 1999), and further processed with TGrep2.5 We select our potential experimental expressions from pairs of verb and direct object that have a minimum frequency of 25 in the BNC and that involve one of a predefined list of basic (transitive) verbs. Basic verbs, which in their literal uses refer to states or acts central to human experience (e.g., give and put), commonly form MWEs in combination with their direct object argument (Cowie et al., 1983). We use 12 such verbs ranked highly according to the number of different nouns they appear with in the BNC. Here are the verbs in alphabetical order: brin</context>
</contexts>
<marker>Collins, 1999</marker>
<rawString>Michael Collins. 1999. Head-Driven Statistical Models for Natural Language Parsing. Ph.D. thesis, UPenn.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Paul Cook</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Classifying particle semantics in English verb-particle constructions.</title>
<date>2006</date>
<booktitle>In Proc. of COLING-ACL’06 Wkshp. on Multiword Expressions,</booktitle>
<pages>45--53</pages>
<contexts>
<context position="26996" citStr="Cook and Stevenson, 2006" startWordPosition="4435" endWordPosition="4438">o include more semantic classes. particularly important for the identification of highly idiosyncratic MWEs, such as LVCs and IDMs. 6 Related Work Much recent work on classifying MWEs focuses on determining different levels of compositionality in verb+particle combinations using a measure of distributional similarity (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from literal combinations. For this, they use a measure that draws on the limited modifiability of MWEs, in addition to their expected high frequency. Krenn and Evert (2001) attempt to separate German idioms, LVCs, and literal phrases (of the form verb+prepositional phrase). They treat L</context>
</contexts>
<marker>Cook, Stevenson, 2006</marker>
<rawString>Paul Cook and Suzanne Stevenson. 2006. Classifying particle semantics in English verb-particle constructions. In Proc. of COLING-ACL’06 Wkshp. on Multiword Expressions, 45–53.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony P Cowie</author>
<author>Ronald Mackin</author>
<author>Isabel R McCaig</author>
</authors>
<date>1983</date>
<journal>Oxford Dictionary of Current Idiomatic English,</journal>
<volume>2</volume>
<publisher>OUP.</publisher>
<contexts>
<context position="16297" citStr="Cowie et al., 1983" startWordPosition="2648" endWordPosition="2651">NTITY).3 4 Experimental Setup 4.1 Corpus and Experimental Expressions We use the British National Corpus (BNC),4 automatically parsed using the Collins parser (Collins, 1999), and further processed with TGrep2.5 We select our potential experimental expressions from pairs of verb and direct object that have a minimum frequency of 25 in the BNC and that involve one of a predefined list of basic (transitive) verbs. Basic verbs, which in their literal uses refer to states or acts central to human experience (e.g., give and put), commonly form MWEs in combination with their direct object argument (Cowie et al., 1983). We use 12 such verbs ranked highly according to the number of different nouns they appear with in the BNC. Here are the verbs in alphabetical order: bring, find, get, give, hold, keep, lose, make, put, see, set, take To guarantee that the final set of expressions contains pairs from all four classes, we pseudo-randomly select them from the initial list of pairs extracted from the BNC as explained above. To ensure the inclusion of IDMs, we consult two idioms dictionaries (Cowie et al., 1983; Seaton and Macaulay, 2002). To ensure we include LVCs, we select pairs in which the noun has a morphol</context>
</contexts>
<marker>Cowie, Mackin, McCaig, 1983</marker>
<rawString>Anthony P. Cowie, Ronald Mackin, and Isabel R. McCaig. 1983. Oxford Dictionary of Current Idiomatic English, volume 2. OUP.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anthony P Cowie</author>
</authors>
<title>The treatment of collocations and idioms in learner’s dictionaries. Applied Linguistics,</title>
<date>1981</date>
<contexts>
<context position="6480" citStr="Cowie, 1981" startWordPosition="1008" endWordPosition="1009"> four classes. In Section 3, we propose statistical measures for quantifying each of these properties, and use them as features for type classification of verb+noun combinations. Section 4 and Section 5 present an evaluation of our proposed measures. Section 6 discusses the related studies, and Section 7 concludes the paper. 2 Semantic Idiosyncrasy: Linguistic Properties Linguists and lexicographers often attribute certain characteristics to semantically idiosyncratic expressions. Some of the widely-known properties are institutionalization, lexicosyntactic fixedness, and noncompositionality (Cowie, 1981; Gibbs and Nayak, 1989; Moon, 1998). The following paragraphs elaborate on each property, as well as on its relevance to the identification of the classes under study. Institutionalization is the process through which a combination of words becomes recognized and accepted as a semantic unit involving some degree of semantic idiosyncrasy. IDMs, LVCs, and ABS combinations are institutionalized to some extent. Lexicosyntactic fixedness refers to some degree of lexical and syntactic restrictiveness in a semantically idiosyncratic expression. An expression is lexically fixed if the substitution of</context>
</contexts>
<marker>Cowie, 1981</marker>
<rawString>Anthony P. Cowie. 1981. The treatment of collocations and idioms in learner’s dictionaries. Applied Linguistics, II(3):223–235.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Afsaneh Fazly</author>
<author>Suzanne Stevenson</author>
</authors>
<title>Automatically constructing a lexicon of verb phrase idiomatic combinations.</title>
<date>2006</date>
<booktitle>In Proc. ofEACL’06,</booktitle>
<pages>337--344</pages>
<contexts>
<context position="10817" citStr="Fazly and Stevenson, 2006" startWordPosition="1722" endWordPosition="1725">mation (PMI) are also used in many NLP applications (Church et al., 1991). PMI of a verb+noun combination �v, n&gt;- is defined as: P(v, n) PMI (v, n) = � log P(v) P(n) f (*, *)f (v, n) � log f (v, *) f (*, n) (1) where all frequency counts are calculated over verb–object pairs in a corpus. We use both frequency and PMI of a verb+noun combination to measure its degree of institutionalization. We refer to this group of measures as INST. 3.2 Measuring Fixedness To measure fixedness, we use statistical measures of lexical, syntactic, and overall fixedness that we have developed in a previous study (Fazly and Stevenson, 2006), as well as some new measures we introduce here. The following paragraphs give a brief description of each. Fixednessle7C quantifies the degree of lexical fixedness of the target combination, �v, n&gt;-, by comparing its strength of association (measured by PMI) with those of its lexical variants. Like Lin (1999), we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by a semantically similar word from the automatically-built thesaurus of Lin (1998). We then use a standard statistic, the z-score, to calculate Fixednessle�: Fixednessle�(v, n</context>
<context position="15336" citStr="Fazly and Stevenson (2006)" startWordPosition="2480" endWordPosition="2484">lbaum, 1998).2 We use abbreviation COMP to refer to the group of measures related to compositionality. 3.4 The Constituents Recall that semantic properties of the constituents of a verb+noun combination are expected to be relevant to its semantic class. We thus add two simple feature groups: (i) the verb itself (VERB); and (ii) the semantic category of the noun according to WordNet (NSEM). We take the semantic category of a noun to be the ancestor of its first sense in the hypernym hierarchy of WordNet 2.1, cut at the level of the children 1Our preliminary experiments on development data from Fazly and Stevenson (2006) revealed that the cosine measure and a window size of f5 words resulted in the best performance. 2If no such verb exists, Simdigt (t, rv) is set to zero. If more than one verb exist, we choose the one that is identical to the noun or the one that is shorter in length. = ptk EP 12 of ENTITY (which will include PHYSICAL ENTITY and ABSTRACT ENTITY).3 4 Experimental Setup 4.1 Corpus and Experimental Expressions We use the British National Corpus (BNC),4 automatically parsed using the Collins parser (Collins, 1999), and further processed with TGrep2.5 We select our potential experimental expressio</context>
</contexts>
<marker>Fazly, Stevenson, 2006</marker>
<rawString>Afsaneh Fazly and Suzanne Stevenson. 2006. Automatically constructing a lexicon of verb phrase idiomatic combinations. In Proc. ofEACL’06, 337–344.</rawString>
</citation>
<citation valid="true">
<title>WordNet, An Electronic Lexical Database.</title>
<date>1998</date>
<editor>Christiane Fellbaum, editor.</editor>
<publisher>MIT Press.</publisher>
<contexts>
<context position="11324" citStr="(1998)" startWordPosition="1808" endWordPosition="1808">actic, and overall fixedness that we have developed in a previous study (Fazly and Stevenson, 2006), as well as some new measures we introduce here. The following paragraphs give a brief description of each. Fixednessle7C quantifies the degree of lexical fixedness of the target combination, �v, n&gt;-, by comparing its strength of association (measured by PMI) with those of its lexical variants. Like Lin (1999), we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by a semantically similar word from the automatically-built thesaurus of Lin (1998). We then use a standard statistic, the z-score, to calculate Fixednessle�: Fixednessle�(v, n) �= (2) std where PMI is the mean and std the standard deviation over the PMI of the target and all its variants. Fixedness��n quantifies the degree of syntactic fixedness of the target combination, by comparing its behaviour in text with the behaviour of a typical verb–object, both defined as probability distributions over a predefined set of patterns. We use a standard information-theoretic measure, relative entropy, PMI(v, n) − PMI 11 v det:NULL n99 v det:NULL np` v det:a/an n99 v det:the n99 v det</context>
</contexts>
<marker>1998</marker>
<rawString>Christiane Fellbaum, editor. 1998. WordNet, An Electronic Lexical Database. MIT Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Gibbs</author>
<author>Nandini P Nayak</author>
</authors>
<title>Psychololinguistic studies on the syntactic behaviour of idioms.</title>
<date>1989</date>
<pages>21--100</pages>
<publisher>Cognitive Psychology,</publisher>
<contexts>
<context position="6503" citStr="Gibbs and Nayak, 1989" startWordPosition="1010" endWordPosition="1013">. In Section 3, we propose statistical measures for quantifying each of these properties, and use them as features for type classification of verb+noun combinations. Section 4 and Section 5 present an evaluation of our proposed measures. Section 6 discusses the related studies, and Section 7 concludes the paper. 2 Semantic Idiosyncrasy: Linguistic Properties Linguists and lexicographers often attribute certain characteristics to semantically idiosyncratic expressions. Some of the widely-known properties are institutionalization, lexicosyntactic fixedness, and noncompositionality (Cowie, 1981; Gibbs and Nayak, 1989; Moon, 1998). The following paragraphs elaborate on each property, as well as on its relevance to the identification of the classes under study. Institutionalization is the process through which a combination of words becomes recognized and accepted as a semantic unit involving some degree of semantic idiosyncrasy. IDMs, LVCs, and ABS combinations are institutionalized to some extent. Lexicosyntactic fixedness refers to some degree of lexical and syntactic restrictiveness in a semantically idiosyncratic expression. An expression is lexically fixed if the substitution of a semantically similar</context>
</contexts>
<marker>Gibbs, Nayak, 1989</marker>
<rawString>Raymond W., Jr. Gibbs and Nandini P. Nayak. 1989. Psychololinguistic studies on the syntactic behaviour of idioms. Cognitive Psychology, 21:100–138.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Brigitte Krenn</author>
<author>Stefan Evert</author>
</authors>
<title>Can we do better than frequency? A case study on extracting PP-verb collocations.</title>
<date>2001</date>
<booktitle>In Proc. of ACL’01 Wkshp. on Collocations,</booktitle>
<pages>39--46</pages>
<contexts>
<context position="27481" citStr="Krenn and Evert (2001)" startWordPosition="4514" endWordPosition="4517">ructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from literal combinations. For this, they use a measure that draws on the limited modifiability of MWEs, in addition to their expected high frequency. Krenn and Evert (2001) attempt to separate German idioms, LVCs, and literal phrases (of the form verb+prepositional phrase). They treat LVCs and idioms as institutionalized expressions, and use frequency and several association measures, such as PMI, for the task. The main goal of their work is to find which association measures are particularly suited for identifying which of these classes. Here, we look at properties of MWEs other than their institutionalization (the latter we quantify using an association measure). The work most similar to ours is that of Venkatapathy and Joshi (2005). They propose a minimallysu</context>
</contexts>
<marker>Krenn, Evert, 2001</marker>
<rawString>Brigitte Krenn and Stefan Evert. 2001. Can we do better than frequency? A case study on extracting PP-verb collocations. In Proc. of ACL’01 Wkshp. on Collocations, 39–46.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic retrieval and clustering of similar words.</title>
<date>1998</date>
<booktitle>In Proc. of COLING-ACL’98,</booktitle>
<pages>768--774</pages>
<contexts>
<context position="11324" citStr="Lin (1998)" startWordPosition="1807" endWordPosition="1808">syntactic, and overall fixedness that we have developed in a previous study (Fazly and Stevenson, 2006), as well as some new measures we introduce here. The following paragraphs give a brief description of each. Fixednessle7C quantifies the degree of lexical fixedness of the target combination, �v, n&gt;-, by comparing its strength of association (measured by PMI) with those of its lexical variants. Like Lin (1999), we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by a semantically similar word from the automatically-built thesaurus of Lin (1998). We then use a standard statistic, the z-score, to calculate Fixednessle�: Fixednessle�(v, n) �= (2) std where PMI is the mean and std the standard deviation over the PMI of the target and all its variants. Fixedness��n quantifies the degree of syntactic fixedness of the target combination, by comparing its behaviour in text with the behaviour of a typical verb–object, both defined as probability distributions over a predefined set of patterns. We use a standard information-theoretic measure, relative entropy, PMI(v, n) − PMI 11 v det:NULL n99 v det:NULL np` v det:a/an n99 v det:the n99 v det</context>
</contexts>
<marker>Lin, 1998</marker>
<rawString>Dekang Lin. 1998. Automatic retrieval and clustering of similar words. In Proc. of COLING-ACL’98, 768–774.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Dekang Lin</author>
</authors>
<title>Automatic identification of noncompositional phrases.</title>
<date>1999</date>
<booktitle>In Proc. ofACL’99,</booktitle>
<pages>317--324</pages>
<contexts>
<context position="11129" citStr="Lin (1999)" startWordPosition="1776" endWordPosition="1777">+noun combination to measure its degree of institutionalization. We refer to this group of measures as INST. 3.2 Measuring Fixedness To measure fixedness, we use statistical measures of lexical, syntactic, and overall fixedness that we have developed in a previous study (Fazly and Stevenson, 2006), as well as some new measures we introduce here. The following paragraphs give a brief description of each. Fixednessle7C quantifies the degree of lexical fixedness of the target combination, �v, n&gt;-, by comparing its strength of association (measured by PMI) with those of its lexical variants. Like Lin (1999), we generate lexical variants of the target automatically by replacing either the verb or the noun constituent by a semantically similar word from the automatically-built thesaurus of Lin (1998). We then use a standard statistic, the z-score, to calculate Fixednessle�: Fixednessle�(v, n) �= (2) std where PMI is the mean and std the standard deviation over the PMI of the target and all its variants. Fixedness��n quantifies the degree of syntactic fixedness of the target combination, by comparing its behaviour in text with the behaviour of a typical verb–object, both defined as probability dist</context>
</contexts>
<marker>Lin, 1999</marker>
<rawString>Dekang Lin. 1999. Automatic identification of noncompositional phrases. In Proc. ofACL’99, 317–324.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Diana McCarthy</author>
<author>Bill Keller</author>
<author>John Carroll</author>
</authors>
<title>Detecting a continuum of compositionality in phrasal verbs.</title>
<date>2003</date>
<booktitle>In Proc. ofACL-SIGLEX Wkshp. on Multiword Expressions,</booktitle>
<pages>73--80</pages>
<contexts>
<context position="21548" citStr="McCarthy et al., 2003" startWordPosition="3515" endWordPosition="3518">only 14% over the baseline. This shows that institutionalization, although relevant, is not sufficient for distinguishing among different levels of semantic idiosyncrasy. Interestingly, FIXD features achieve the highest accuracy, 50%, with a relative error reduction of 33%, showing that fixedness is a salient aspect of semantic idiosyncrasy. COMP features achieve reasonably good accuracy, around 40%, though still notably lower than the accuracy of FIXD features. This is especially interesting since much previous research has focused solely on the non-compositionality of MWEs to identify them (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Our results confirm the relevance of this property, while at the same time revealing its insufficiency. Interestingly, features related to the semantic properties of the constituents, VERB and NSEM, overall perform comparably to the compositionality features. However, a closer look at their performance on the individual classes (see Section 5.2) reveals that, unlike COMP, they are mainly good at identifying items from certain classes. As hypothesized, we achieve the highest performance, an accuracy of 58% and a relative error reduction of 44%, whe</context>
<context position="26712" citStr="McCarthy et al., 2003" startWordPosition="4391" endWordPosition="4394">rmance on these classes, reinforcing that IDMs and LVCs may not necessarily appear with significantly high frequency of occurrence in a given corpus. Fixedness features thus prove to be 8Since this is a binary feature, it can only distinguish two classes. In the future, we need to include more semantic classes. particularly important for the identification of highly idiosyncratic MWEs, such as LVCs and IDMs. 6 Related Work Much recent work on classifying MWEs focuses on determining different levels of compositionality in verb+particle combinations using a measure of distributional similarity (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from</context>
</contexts>
<marker>McCarthy, Keller, Carroll, 2003</marker>
<rawString>Diana McCarthy, Bill Keller, and John Carroll. 2003. Detecting a continuum of compositionality in phrasal verbs. In Proc. ofACL-SIGLEX Wkshp. on Multiword Expressions, 73–80.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Tadao Miyamoto</author>
</authors>
<title>The Light Verb Construction in Japanese: the Role of the Verbal Noun.</title>
<date>2000</date>
<publisher>John Benjamins.</publisher>
<contexts>
<context position="2501" citStr="Miyamoto, 2000" startWordPosition="385" endWordPosition="386"> with the meaning of shoot or breeze. MWEs such as give a try (“try”) and make a decision (“decide”) are semantically less idiosyncratic (more predictable). These are MWEs because the overall meaning of the expression diverges from the combined meanings of the constituents. Nonetheless, there is some degree of predictability in their meanings that makes them distinct from idioms. In these, the complement of the verb (here, a noun) determines the primary meaning of the overall expression. This class of expressions is referred to as light verb constructions (LVCs) in the linguistics literature (Miyamoto, 2000; Butt, 2003). Clearly, a computational system should distinguish idioms and LVCs, both from each other, and from similar-on-the-surface (literal) phrases such as shoot the bird and give a present. Idioms are largely idiosyncratic; a computational lexicographer thus may decide to list idioms such as shoot the breeze in a lexicon along with their idiomatic meanings. In contrast, the meaning of MWEs such as make a decision can be largely predicted, given that they are LVCs. Table 1 shows the different underlying semantic structure of a sentence containing an idiom (shoot the breeze) and a senten</context>
</contexts>
<marker>Miyamoto, 2000</marker>
<rawString>Tadao Miyamoto. 2000. The Light Verb Construction in Japanese: the Role of the Verbal Noun. John Benjamins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Rosamund Moon</author>
</authors>
<title>Fixed Expressions and Idioms in English: A Corpus-Based Approach.</title>
<date>1998</date>
<publisher>Oxford University Press.</publisher>
<contexts>
<context position="6516" citStr="Moon, 1998" startWordPosition="1014" endWordPosition="1015">ose statistical measures for quantifying each of these properties, and use them as features for type classification of verb+noun combinations. Section 4 and Section 5 present an evaluation of our proposed measures. Section 6 discusses the related studies, and Section 7 concludes the paper. 2 Semantic Idiosyncrasy: Linguistic Properties Linguists and lexicographers often attribute certain characteristics to semantically idiosyncratic expressions. Some of the widely-known properties are institutionalization, lexicosyntactic fixedness, and noncompositionality (Cowie, 1981; Gibbs and Nayak, 1989; Moon, 1998). The following paragraphs elaborate on each property, as well as on its relevance to the identification of the classes under study. Institutionalization is the process through which a combination of words becomes recognized and accepted as a semantic unit involving some degree of semantic idiosyncrasy. IDMs, LVCs, and ABS combinations are institutionalized to some extent. Lexicosyntactic fixedness refers to some degree of lexical and syntactic restrictiveness in a semantically idiosyncratic expression. An expression is lexically fixed if the substitution of a semantically similar word for any</context>
</contexts>
<marker>Moon, 1998</marker>
<rawString>Rosamund Moon. 1998. Fixed Expressions and Idioms in English: A Corpus-Based Approach. Oxford University Press.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Nunberg</author>
<author>Ivan A Sag</author>
<author>Thomas Wasow</author>
</authors>
<date>1994</date>
<journal>Idioms. Language,</journal>
<volume>70</volume>
<issue>3</issue>
<contexts>
<context position="1776" citStr="Nunberg et al., 1994" startWordPosition="264" endWordPosition="268">he beach. Nonetheless, MWEs are distinct from multiword phrases because they involve some degree of semantic idiosyncrasy, i.e., the overall meaning of an MWE diverges from the combined contribution of its constituent parts. Because of their frequency and their peculiar behaviour, MWEs pose a great challenge to the creation of natural language processing (NLP) systems (Sag et al., 2002). NLP applications, such as semantic parsing and machine translation should not only identify MWEs, but also should know how to treat them when they are encountered. Semantic idiosyncrasy is a matter of degree (Nunberg et al., 1994). The idiom shoot the breeze is largely idiosyncratic, because its meaning (“to chat”) does not have much to do with the meaning of shoot or breeze. MWEs such as give a try (“try”) and make a decision (“decide”) are semantically less idiosyncratic (more predictable). These are MWEs because the overall meaning of the expression diverges from the combined meanings of the constituents. Nonetheless, there is some degree of predictability in their meanings that makes them distinct from idioms. In these, the complement of the verb (here, a noun) determines the primary meaning of the overall expressi</context>
</contexts>
<marker>Nunberg, Sag, Wasow, 1994</marker>
<rawString>Geoffrey Nunberg, Ivan A. Sag, and Thomas Wasow. 1994. Idioms. Language, 70(3):491–538.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Ivan A Sag</author>
<author>Timothy Baldwin</author>
<author>Francis Bond</author>
<author>Ann Copestake</author>
<author>Dan Flickinger</author>
</authors>
<title>Multiword expressions: A pain in the neck for NLP.</title>
<date>2002</date>
<booktitle>In Proc. of CICLing’02,</booktitle>
<pages>1--15</pages>
<contexts>
<context position="1544" citStr="Sag et al., 2002" startWordPosition="226" endWordPosition="229"> form a single unit of meaning, e.g., frying pan, take a stroll, and kick the bucket. Most MWEs behave like any phrase composed of multiple words, e.g., their components may be separated, as in She took a relaxing stroll along the beach. Nonetheless, MWEs are distinct from multiword phrases because they involve some degree of semantic idiosyncrasy, i.e., the overall meaning of an MWE diverges from the combined contribution of its constituent parts. Because of their frequency and their peculiar behaviour, MWEs pose a great challenge to the creation of natural language processing (NLP) systems (Sag et al., 2002). NLP applications, such as semantic parsing and machine translation should not only identify MWEs, but also should know how to treat them when they are encountered. Semantic idiosyncrasy is a matter of degree (Nunberg et al., 1994). The idiom shoot the breeze is largely idiosyncratic, because its meaning (“to chat”) does not have much to do with the meaning of shoot or breeze. MWEs such as give a try (“try”) and make a decision (“decide”) are semantically less idiosyncratic (more predictable). These are MWEs because the overall meaning of the expression diverges from the combined meanings of </context>
</contexts>
<marker>Sag, Baldwin, Bond, Copestake, Flickinger, 2002</marker>
<rawString>Ivan A. Sag, Timothy Baldwin, Francis Bond, Ann Copestake, and Dan Flickinger. 2002. Multiword expressions: A pain in the neck for NLP. In Proc. of CICLing’02, 1–15.</rawString>
</citation>
<citation valid="true">
<date>2002</date>
<booktitle>Collins COBUILD Idioms Dictionary.</booktitle>
<editor>Maggie Seaton and Alison Macaulay, eds.</editor>
<publisher>HarperCollins.</publisher>
<marker>2002</marker>
<rawString>Maggie Seaton and Alison Macaulay, eds. 2002. Collins COBUILD Idioms Dictionary. HarperCollins.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kiyoko Uchiyama</author>
<author>Timothy Baldwin</author>
<author>Shun Ishizaki</author>
</authors>
<title>Disambiguating Japanese compound verbs. Computer Speech and Language,</title>
<date>2005</date>
<contexts>
<context position="9183" citStr="Uchiyama et al., 2005" startWordPosition="1449" endWordPosition="1452">he meaning of a word combination deviates from the meaning emerging from a word-by-word interpretation of it. IDMs are largely non-compositional, whereas LVCs are semi-compositional since their meaning can be mainly predicted from the noun constituent. ABS and LIT combinations are expected to be largely compositional. None of the above-mentioned properties are sufficient criteria by themselves for determining which semantic class a given verb+noun combination belongs to. Moreover, semantic properties of the constituents of a combination are also known to be relevant for determining its class (Uchiyama et al., 2005). Verbs may exhibit strong preferences for appearing in MWEs from a particular class, e.g., give, take and make commonly form LVCs. The semantic category of the noun is also relevant to the type of MWE, e.g., the noun constituent of an LVC is often a predicative one. We hypothesize that if we look at evidence from all these different sources, we will find members of the same class to be reasonably similar, and members of different classes to be notably different. 3 Statistical Measures of Semantic Idiosyncrasy This section introduces measures for quantifying the properties of idiosyncratic MWE</context>
<context position="26969" citStr="Uchiyama et al., 2005" startWordPosition="4431" endWordPosition="4434">n the future, we need to include more semantic classes. particularly important for the identification of highly idiosyncratic MWEs, such as LVCs and IDMs. 6 Related Work Much recent work on classifying MWEs focuses on determining different levels of compositionality in verb+particle combinations using a measure of distributional similarity (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from literal combinations. For this, they use a measure that draws on the limited modifiability of MWEs, in addition to their expected high frequency. Krenn and Evert (2001) attempt to separate German idioms, LVCs, and literal phrases (of the form verb+preposit</context>
</contexts>
<marker>Uchiyama, Baldwin, Ishizaki, 2005</marker>
<rawString>Kiyoko Uchiyama, Timothy Baldwin, and Shun Ishizaki. 2005. Disambiguating Japanese compound verbs. Computer Speech and Language, 19:497–512.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sriram Venkatapathy</author>
<author>Aravind Joshi</author>
</authors>
<title>Measuring the relative compositionality of verb-noun (V-N) collocations by integrating features.</title>
<date>2005</date>
<booktitle>In Proc. of HLTEMNLP’05,</booktitle>
<pages>899--906</pages>
<contexts>
<context position="28053" citStr="Venkatapathy and Joshi (2005)" startWordPosition="4604" endWordPosition="4608"> to their expected high frequency. Krenn and Evert (2001) attempt to separate German idioms, LVCs, and literal phrases (of the form verb+prepositional phrase). They treat LVCs and idioms as institutionalized expressions, and use frequency and several association measures, such as PMI, for the task. The main goal of their work is to find which association measures are particularly suited for identifying which of these classes. Here, we look at properties of MWEs other than their institutionalization (the latter we quantify using an association measure). The work most similar to ours is that of Venkatapathy and Joshi (2005). They propose a minimallysupervised classification schema that incorporates a variety of features to group verb+noun combinations according to their level of compositionality. Their work has the advantage of requiring only a small amount of manually-labeled training data. However, their classes are defined on the basis of compositionality only. Here, we consider classes that are linguistically salient, and moreover need special treatment within a computational system. Our work is also different in that it brings in a new group of features, the fixedness measures, which prove to be very effect</context>
</contexts>
<marker>Venkatapathy, Joshi, 2005</marker>
<rawString>Sriram Venkatapathy and Aravind Joshi. 2005. Measuring the relative compositionality of verb-noun (V-N) collocations by integrating features. In Proc. of HLTEMNLP’05, 899–906.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Leo Wanner</author>
</authors>
<title>Towards automatic fine-grained semantic classification of verb-noun collocations.</title>
<date>2004</date>
<journal>Natural Language Engineering,</journal>
<volume>10</volume>
<issue>2</issue>
<contexts>
<context position="26946" citStr="Wanner, 2004" startWordPosition="4429" endWordPosition="4430">two classes. In the future, we need to include more semantic classes. particularly important for the identification of highly idiosyncratic MWEs, such as LVCs and IDMs. 6 Related Work Much recent work on classifying MWEs focuses on determining different levels of compositionality in verb+particle combinations using a measure of distributional similarity (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from literal combinations. For this, they use a measure that draws on the limited modifiability of MWEs, in addition to their expected high frequency. Krenn and Evert (2001) attempt to separate German idioms, LVCs, and literal phrases (of</context>
</contexts>
<marker>Wanner, 2004</marker>
<rawString>Leo Wanner. 2004. Towards automatic fine-grained semantic classification of verb-noun collocations. Natural Language Engineering, 10(2):95–143.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wermter</author>
<author>Udo Hahn</author>
</authors>
<title>Collocation extraction based on modifiability statistics.</title>
<date>2004</date>
<booktitle>In Proc. of COLING’04,</booktitle>
<pages>980--986</pages>
<contexts>
<context position="27159" citStr="Wermter and Hahn (2004)" startWordPosition="4458" endWordPosition="4461">n classifying MWEs focuses on determining different levels of compositionality in verb+particle combinations using a measure of distributional similarity (McCarthy et al., 2003; Baldwin et al., 2003; Bannard et al., 2003). Another group of research attempts to classify a particular MWE subtype, such as verb-particle constructions (VPCs) or LVCs, according to some fine-grained semantic criteria (Wanner, 2004; Uchiyama et al., 2005; Cook and Stevenson, 2006). Here, we distinguish subtypes of MWEs that are defined according to coarse-grained distinctions in their degree of semantic idiosyncrasy. Wermter and Hahn (2004) recognize the importance of distinguishing MWE subtypes that are similar to our four classes, but only focus on separating MWEs as one single class from literal combinations. For this, they use a measure that draws on the limited modifiability of MWEs, in addition to their expected high frequency. Krenn and Evert (2001) attempt to separate German idioms, LVCs, and literal phrases (of the form verb+prepositional phrase). They treat LVCs and idioms as institutionalized expressions, and use frequency and several association measures, such as PMI, for the task. The main goal of their work is to f</context>
</contexts>
<marker>Wermter, Hahn, 2004</marker>
<rawString>Joachim Wermter and Udo Hahn. 2004. Collocation extraction based on modifiability statistics. In Proc. of COLING’04, 980–986.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>