<?xml version="1.0" encoding="UTF-8"?>
<algorithms version="110505">
<algorithm name="SectLabel" version="110505">
<variant no="0" confidence="0.009843">
<title confidence="0.993668">
Alpage: Transition-based Semantic Graph Parsing with Syntactic
Features
</title>
<author confidence="0.859525">
Corentin Ribeyre* ◦ Eric Villemonte dela Clergerie* Djamé Seddah* *
</author>
<note confidence="0.342821">
*Alpage, INRIA
◦Univ Paris Diderot, Sorbonne Paris Cité
* Université Paris Sorbonne
</note>
<email confidence="0.988951">
firstname.lastname@inria.fr
</email>
<sectionHeader confidence="0.99366" genericHeader="abstract">
Abstract
</sectionHeader>
<bodyText confidence="0.997989230769231">
This paper describes the systems deployed
by the ALPAGE team to participate to the
SemEval-2014 Task on Broad-Coverage
Semantic Dependency Parsing. We de-
veloped two transition-based dependency
parsers with extended sets of actions to
handle non-planar acyclic graphs. For the
open track, we worked over two orthog-
onal axes – lexical and syntactic – in or-
der to provide our models with lexical and
syntactic features such as word clusters,
lemmas and tree fragments of different
types.
</bodyText>
<sectionHeader confidence="0.998801" genericHeader="introduction">
1 Introduction
</sectionHeader>
<bodyText confidence="0.976904826086957">
In recent years, we have seen the emergence
of semantic parsing, relying on various tech-
niques ranging from graph grammars (Chiang et
al., 2013) to transitions-based dependency parsers
(Sagae and Tsujii, 2008). Assuming that obtain-
ing predicate argument structures is a necessary
goal to move from syntax to accurate surface se-
mantics, the question of the representation of such
structures arises. Regardless of the annotation
scheme that should be used, one of the main is-
sues of semantic representation is the construction
of graph structures, that are inherently harder to
generate than the classical tree structures.
In that aspect, the shared task’s proposal (Oepen
et al., 2014), to evaluate different syntactic-
semantic schemes (Ivanova et al., 2012; Hajic et
al., 2006; Miyao and Tsujii, 2004) could not ar-
rive at a more timely moment when state-of-the-art
surface syntactic parsers regularly reach, or cross,
a 90% labeled dependency recovery plateau for a
This work is licensed under a Creative Commons At-
tribution 4.0 International Licence. Page numbers and pro-
ceedings footer are added by the organisers. Licence details:
http://creativecommons.org/licenses/by/4.0/.
wide range of languages (Nivre et al., 2007a; Sed-
dah et al., 2013).
The two systems we present both extend
transition-based parsers in order to be able to gen-
erate acyclic dependency graphs. The first one
follows the standard greedy search mechanism of
(Nivre et al., 2007b), while the second one fol-
lows a slightly more global search strategy (Huang
and Sagae, 2010; Goldberg et al., 2013) by rely-
ing on dynamic programming techniques. In addi-
tion to building graphs directly, the main original-
ity of our work lies in the use of different kinds of
syntactic features, showing that using syntax for
pure deep semantic parsing improves global per-
formance by more than two points.
Although not state-of-the-art, our systems per-
form very honorably compared with other single
systems in this shared task and pave quite an in-
teresting way for further work. In the remainder
of this paper, we present the parsers and their ex-
tensions for building graphs; we then present our
syntactic features and discuss our results.
</bodyText>
<sectionHeader confidence="0.989643" genericHeader="method">
2 Systems Description
</sectionHeader>
<bodyText confidence="0.999846529411765">
Shift-reduce transition-based parsers essentially
rely on configurations formed of a stack and a
buffer, with stack transitions used to go from a
configuration to the next one, until reaching a fi-
nal configuration. Following Kübler et al. (2009),
we define a configuration by c = (σ, β, A) where
σ denotes a stack of words wi, β a buffer of
words, and A a set of dependency arcs of the form
(wi, r, wj), with wi the head, wj the dependent,
and r a label in some set R.
However, despite their overall similarities,
transition-based systems may differ on many as-
pects, such as the exact definition of the configura-
tions, the set of transitions extracted from the con-
figurations, the way the search space is explored
(at parsing and training time), the set of features,
the way the transition weights are learned and ap-
</bodyText>
<page confidence="0.996441">
97
</page>
<note confidence="0.721609">
Proceedings of the 8th International Workshop on Semantic Evaluation (SemEval 2014), pages 97–103,
Dublin, Ireland, August 23-24, 2014.
</note>
<construct confidence="0.936354875">
(σ, wi|β, A) (σ|wi, β, A) (shift) BOTH
(σ|wj|wi,β, A) (σ|wi,β, A U (wi, r, wj)) (left-reduce) S&amp;T PARSER
(σ|wj|wi,β, A) (σ|wj,β, A U (wj, r, wi)) (right-reduce) S&amp;T PARSER
(σ|wj|wi,β, A) (σ|wj|wi,β, A U (wi, r, wj)) (left-attach) BOTH
(σ|wj|wi,β, A) (σ|wj, wi|β, A U (wj, r, wi) (right-attach) BOTH
(σ|wi, β, A) (σ, β, A) (pop0) BOTH
(σ|wj|wi,β, A) (σ|wi, β, A) (pop1) DYALOG-SR
(σ|wj|wi,β, A) (σ|wi|wj,β, A) (swap) DYALOG-SR
</construct>
<figureCaption confidence="0.995947">
Figure 1: An extended set of transitions for building dependency graphs.
</figureCaption>
<bodyText confidence="0.99765747826087">
plied, etc.
For various reasons, we started our experiments
with two rather different transition-based parsers,
which have finally converged on several aspects.
In particular, the main convergence concerns the
set of transitions needed to parse the three pro-
posed annotation schemes. To be able to attach
zero, one, or more heads to a word, it is necessary
to clearly dissociate the addition of a dependency
from the reduction of a word (i.e. its removal from
the stack). Following Sagae and Tsujii (2008), as
shown in Figure 1, beside the usual shift and re-
duce transitions of the arc-standard strategy, we
introduced the new left and right attach actions for
adding new dependencies (while keeping the de-
pendent on the stack) and two reduce pop0 and
pop1 actions to remove a word from the stack af-
ter attachement of its dependents. All transitions
adding an edge should also satisfy the condition
that the new edge does not create a cycle or mul-
tiple edges between the same pair of nodes. It is
worth noting that the pop actions may also be used
to remove words with no heads.
</bodyText>
<subsectionHeader confidence="0.99321">
2.1 Sagae &amp; Tsujii’s DAG Parser
</subsectionHeader>
<bodyText confidence="0.999758217391304">
Our first parsing system is a partial rewrite, with
several extensions, of the Sagae and Tsujii (2008)
DAG parser (henceforth S&amp;T PARSER). We mod-
ified it to handle dependency graphs, in particu-
lar non-governed words using pop0 transitions.
This new transition removes the topmost stack el-
ement when all its dependents have been attached
(through attach or reduce transitions). Thus, we
can handle partially connected graphs, since a
word can be discarded when it has no incoming
arc.
We used two different learning algorithms:
(i) the averaged perceptron because of its good
balance between training time and performance
(Daume, 2006), (ii) the logistic regression model
(maximum entropy (Ratnaparkhi, 1997)). For the
latter, we used the truncated gradient optimiza-
tion (Langford et al., 2009), implemented in Clas-
sias (Okazaki, 2009), in order to estimate the pa-
rameters. These algorithms have been used inter-
changeably to test their performance in terms of F-
score. But the difference was negligeable in gen-
eral.
</bodyText>
<subsectionHeader confidence="0.994218">
2.2 DYALOG-SR
</subsectionHeader>
<bodyText confidence="0.999991583333334">
Our second parsing system is DYALOG-SR
(Villemonte De La Clergerie, 2013), which has
been developed to participate to the SPMRL’13
shared task. Coded on top of tabular logic
programming system DYALOG, it implements
a transition-based parser relying on dynamic
programming techniques, beams, and an aver-
aged structured perceptron, following ideas from
(Huang and Sagae, 2010; Goldberg et al., 2013).
It was initially designed to follow an arc-
standard parsing strategy, relying on shift and
left/right reduce transitions. To deal with depen-
dency graphs and non governed words, we first
added the two attach transitions and the pop0
transition. But because there exist some overlap
between the reduce and attach transitions leading
to some spurious ambiguities, we finally decided
to remove the left/right reduce transitions and to
complete with the pop1 transition. In order to
handle some cases of non-projectivty with mini-
mal modifications of the system, we also added
a swap transition. The parsing strategy is now
closer to the arc-eager one, with an oracle sug-
gesting to attach as soon as possible.
</bodyText>
<subsectionHeader confidence="0.997849">
2.3 Tree Approximations
</subsectionHeader>
<bodyText confidence="0.999984875">
In order to stack several dependency parsers, we
needed to transform our graphs into trees. We re-
port here the algorithms we used.
The first one uses a simple strategy. For nodes
with multiple incoming edges, we keep the longest
incoming edge. Singleton nodes (with no head)
are attached with a _void_-labeled edge (by
decreasing priority) to the immediately adjacent
</bodyText>
<page confidence="0.947657">
98
</page>
<equation confidence="0.98133775">
Wordσ1 Lemmaσ1 POSσ1
leftPOSσ1 rightPOSσ1 leftLabelσ1
rightLabelσ1 Wordσ2 Lemmaσ2
POSσ2 leftPOSσ2 rightPOSσ2
leftLabelσ2 rightLabelσ2 Wordσ3
POSσ3 Wordβ1 Lemmaβ1
POSβ1 Wordβ2 Lemmaβ2
POSβ2 POSβ3 a d12 di1
</equation>
<tableCaption confidence="0.974969">
Table 1: Baseline features for S&amp;T PARSER.
</tableCaption>
<bodyText confidence="0.999724230769231">
node N, or the virtual root node (token 0). This
strategy already improves over the baseline, pro-
vided by the task organisers, on the PCEDT by 5
points.
The second algorithm tries to preserve more
edges: when it is possible, the deletion of a re-
entrant edge is replaced by reversing its direction
and changing its label l into &lt;l. We do this for
nodes with no incoming edges by reversing the
longest edge only if this action does not create cy-
cles. The number of labels increases, but many
more edges are kept, leading to better results on
DM and PAS corpora.
</bodyText>
<sectionHeader confidence="0.974407" genericHeader="method">
3 Feature Engineering
</sectionHeader>
<subsectionHeader confidence="0.997508">
3.1 Closed Track
</subsectionHeader>
<bodyText confidence="0.999978677966102">
For S&amp;T PARSER we define Wordβi (resp.
Lemmaβi and POSβi) as the word (resp. lemma
and part-of-speech) at position i in the queue. The
same goes for Qi, which is the position i in the
stack. Let di,j be the distance between Wordσi
and Wordσj. We also define dz,j, the distance be-
tween Wordβi and Wordσj. In addition, we define
leftPOSσi (resp. leftLabelσi) the part-of-speech
(resp. the label if any) of the word immediately
at the left handside of Qi, and the same goes for
rightPOSσi (resp. rightLabelσi). Finally, a is the
previous predicted action by the parser. Table 1
reports our baseline features.
For DYALOG-SR we have the following lexi-
cal features lex, lemma, cat, and morphosyn-
tactic mstag. They apply to next unread word
(*T, say lemmaT), the three next lookahead
words (*T2 to *T4), and (when present) to the
3 stack elements (*0 to *2), their two leftmost
and rightmost children (before b[01]*[012]
and after a[01]*[012]). We have dependency
features such as the labels of the two leftmost
and rightmost edges ([ab][01]label[012]),
the left and right valency (number of depen-
dency, [ab]v[012]) and domains (set of de-
pendency labels, [ab]d[012]). Finally, we
have 3 (discretized) distance features between the
next word and the stack elements (delta[01])
and between the two topmost stack elements
(delta01). Most feature values are atomic (ei-
ther numerical or symbolic), but they can also be
(recursively) a list of values, for instance for the
mstag and domain features. For dealing with
graphs, features were added about the incoming
edges to the 3 topmost stack elements, similar to
valency (ngov[012]) and domain (gov[012]).
For the PCEDT scheme, because of the high num-
ber of dependency labels, the 30 most unfrequent
ones were replaced by a generic label when used
as feature value.
Besides, for the PCEDT and DM corpora, static
and dynamic guiding features have been tried
for DYALOG-SR, provided by MATE (Bohnet,
2010) (trained on versions of these corpora pro-
jected to trees, using a 10-fold cross valida-
tion). The two static features mate _alabel and
mate distance are attached to ech token h,
indicating the label and the relative distance to its
governor d (if any). At runtime, dynamic features
are also added relative to the current configuration:
if a semantic dependency (h, l, d) has been pre-
dicted by MATE, and the topmost 2 stack elements
are either (h, d) or (d, h), a feature suggesting a
left or right attachment for l is added.
We did the same for S&amp;T PARSER, except that
we used a simple but efficient hack: instead of
keeping the labels predicted by our parser, we re-
placed them by MATE predictions whenever it was
possible.
</bodyText>
<subsectionHeader confidence="0.99838">
3.2 Open Track
</subsectionHeader>
<bodyText confidence="0.999901933333333">
For this track, we combined the previously de-
scribed features (but the MATE-related ones) with
various lexical and syntactic features, our intu-
ition being that syntax and semantic are inter-
dependent, and that syntactic features should
therefore help semantic parsing. In particular, we
have considered the following bits of information.
Unsupervized Brown clusters To reduce lexi-
cal sparsity, we extracted 1,000 clusters from the
BNC (Leech, 1992) preprocessed following Wag-
ner et al. (2007). We extended them with capi-
talization, digit features and 3 letters suffix signa-
tures, leading to a vocabulary size reduced by half.
Constituent tree fragments They were part of
the companion data provided by the organizers.
</bodyText>
<page confidence="0.993897">
99
</page>
<bodyText confidence="0.99953285">
They consist of fragments of the syntactic trees
and can be used either as enhanced parts of speech
or as features.
Spinal elementary trees A full set of parses was
reconstructed from the tree fragments. Then we
extracted a spine grammar (Seddah, 2010), us-
ing the head percolation table of the Bikel (2002)
parser, slightly modified to avoid determiners to be
marked as head in some configurations.
Predicted MATE dependencies Also provided
in the companion data, they consist in the parses
built by the MATE parsers, trained on the Stanford
dependency version of the PTB. We combined the
labels with a distance S = t − h where t is the
token number and h the head number.
Constituent head paths Inspired by Björkelund
et al. (2013), we used the MATE dependencies to
extract the shortest path between a token and its
lexical head and included the path length (in terms
of traversed nodes) as feature.
</bodyText>
<table confidence="0.99856">
Tree frag. MATE labels+δ Spines trees Head Paths
Train 648 1305 637 27,670
Dev 272 742 265 3,320
Test 273 731 268 2,389
</table>
<tableCaption confidence="0.988991">
Table 2: Syntactic features statistics.
</tableCaption>
<sectionHeader confidence="0.998124" genericHeader="evaluation">
4 Results and Discussion
</sectionHeader>
<bodyText confidence="0.999352636363636">
We present here the results on section 21 (test set)1
for both systems. We report in Table 3, the differ-
ent runs we submitted for the final evaluation of
the shared task. We also report improvements be-
tween the two tracks.
Both systems show relatively close F-measures,
with correct results on every corpus. If we com-
pare the results more precisely, we observe that in
general, DYALOG-SR tends to behave better for
the unlabeled metrics. Its main weakness is on
MRS scheme, for both tracks.2
</bodyText>
<footnote confidence="0.9256994">
1Dev set results are available online at
http://goo.gl/w3XcpW.
2The main and still unexplained problem of DYALOG-
SR was that using larger beams has no impact, and often a
negative one, when using the attach and pop transitions. Ex-
</footnote>
<bodyText confidence="0.9759244375">
cept for PAS and PCEDT where a beam of size 4 worked
best for the open track, all other results were obtained for
beams of size 1. This situation is in total contradiction with
the large impact of beam previously observed for the arc stan-
dard strategy during the SPMRL’13 shared task and during
experiments led on the French TreeBank (Abeillé et al., 2003)
(FTB). Late experiments on the FTB using the attach and
pop actions (but delaying attachments as long as possible) has
On the other hand, it is worth noting that syn-
tactic features greatly improve semantic parsing.
In fact, we report in Figure 2(a) the improvement
of the five most frequent labels and, in Figure 2(b),
the five best improved labels with a frequency over
0.5% in the training set, which represent 95% of
the edges in the DM Corpus. As we can see, syn-
tactic information allow the systems to perform
better on coordination structures and to reduce am-
biguity between modifiers and verbal arguments
(such as the ARG3 label).
We observed the same behaviour on the PAS
corpus, which contains also predicate-argument
structures. For PCEDT, the results show that syn-
tactic features give only small improvements, but
the corpus is harder because of a large set of labels
and is closer to syntactic structures than the two
others.
Of course, we only scratched the surface with
our experiments and we plan to further investigate
the impact of syntactic information during seman-
tic parsing. We especially plan to explore the deep
parsing of French, thanks to the recent release of
the Deep Sequoia Treebank (Candito et al., 2014).
</bodyText>
<sectionHeader confidence="0.996531" genericHeader="conclusions">
5 Conclusion
</sectionHeader>
<bodyText confidence="0.999936846153846">
In this paper, we presented our results on the task
8 of the SemEval-2014 Task on Broad-Coverage
Semantic Dependency Parsing. Even though the
results do not reach state-of-the-art, they compare
favorably with other single systems and show that
syntactic features can be efficiently used for se-
mantic parsing.
In future work, we will continue to investigate
this idea, by combining with more complex sys-
tems and more efficient machine learning tech-
niques, we are convinced that we can come closer
to state of the art results. and that syntax is the key
for better semantic parsing.
</bodyText>
<sectionHeader confidence="0.984403" genericHeader="acknowledgments">
Acknowledgments
</sectionHeader>
<bodyText confidence="0.999846333333333">
We warmly thank Kenji Sagae for making his
parser’s code available and kindly answering our
questions.
</bodyText>
<sectionHeader confidence="0.960683" genericHeader="references">
References
</sectionHeader>
<subsectionHeader confidence="0.628445">
Anne Abeillé, Lionel Clément, and François Toussenel.
2003. Building a Treebank for French. In Treebanks
</subsectionHeader>
<bodyText confidence="0.947940666666667">
confirmed a problem with beams, even if less visible. We are
still investigating why the use of the attach transitions and/or
of the pop transitions seems to be incompatible with beams.
</bodyText>
<page confidence="0.89365">
100
</page>
<table confidence="0.999901923076923">
Closed track Open track
PCEDT LF OF PCEDT LF OF
PEKING - BEST 76.28 89.19 PRIBERAM - BEST 77.90 89.03
S&amp;T PARSER b5 67.83 80.86 S&amp;T PARSER b5 69.20 +1.37 82.68 +1.86
DYALOG-SR b1 67.81 81.23 DYALOG-SR b4 69.58 +1.77 84.80 +3.77
DM (MRS) DM (MRS)
PEKING - BEST 89.40 90.82 PRIBERAM - BEST 89.16 90.32
S&amp;T PARSER b5 78.44 80.88 S&amp;T PARSER b5 81.46 +3.02 83.68 +2.80
DYALOG-SR b1 78.32 81.85 DYALOG-SR b1 79.71 +1.39 81.97 +0.12
PAS (ENJU) PAS (ENJU)
PEKING - BEST 92.04 93.13 PRIBERAM - BEST 91.76 92.81
S&amp;T PARSER b5 82.44 84.41 S&amp;T PARSER b5 84.97 +2.53 86.64 +2.23
DYALOG-SR b1 84.16 86.09 DYALOG-SR b4 85.58 +1.42 86.98 +0.87
</table>
<tableCaption confidence="0.999955">
Table 3: Results on section 21 (test) of the PTB for closed and open track.
</tableCaption>
<figure confidence="0.981998">
(b) the 5 best improved labels (edges frequency above 0.5 % in the training set)
</figure>
<figureCaption confidence="0.902713">
Figure 2: Improvement with syntactic features for DM (test) corpus.
</figureCaption>
<figure confidence="0.994481431818182">
(numbers indicate edge frequency in training set)
60 70 80 90 100
F-score S&amp;T PARSER (%)
60 70 80 90 100
F-score DYALOG-SR (%)
(a) the 5 most frequent labels
20 40 60 80 100
F-score S&amp;T PARSER (%)
20 40 60 80 100
F-score DYALOG-SR (%)
poss
BV
compound
ARG2
ARG1
With Syntax
No Syntax
poss
BV
compound
ARG2
ARG1
24.5%
40.2%
11.7%
2.4%
11.0%
With Syntax
No Syntax
conj
appos
ARG3
loc
-and-c
conj
appos
ARG3
loc
-and-c
0.6%
1.3%
1.5%
2.1%
0.8%
</figure>
<page confidence="0.975931">
101
</page>
<reference confidence="0.998158609090909">
: Building and Using Parsed Corpora, pages 165–
188. Springer.
Daniel M. Bikel. 2002. Design of a multi-lingual,
parallel-processing statistical parsing engine. In
Proceedings of the second international conference
on Human Language Technology Research, pages
178–182. Morgan Kaufmann Publishers Inc. San
Francisco, CA, USA.
Anders Björkelund, Ozlem Cetinoglu, Richárd Farkas,
Thomas Mueller, and Wolfgang Seeker. 2013.
(re)ranking meets morphosyntax: State-of-the-art
results from the SPMRL 2013 shared task. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 135–
145, Seattle, Washington, USA, October.
Bernd Bohnet. 2010. Very high accuracy and fast de-
pendency parsing is not a contradiction. In Proceed-
ings of the 23rd International Conference on Com-
putational Linguistics, COLING ’10, pages 89–97,
Stroudsburg, PA, USA.
Marie Candito, Guy Perrier, Bruno Guillaume,
Corentin Ribeyre, Karën Fort, Djamé Seddah, and
Éric De La Clergerie. 2014. Deep Syntax Anno-
tation of the Sequoia French Treebank. In Interna-
tional Conference on Language Resources and Eval-
uation (LREC), Reykjavik, Islande, May.
David Chiang, Jacob Andreas, Daniel Bauer,
Karl Moritz Hermann, Bevan Jones, and Kevin
Knight. 2013. Parsing graphs with hyperedge
replacement grammars. In Proceedings of the 51st
Meeting of the ACL.
Harold Charles Daume. 2006. Practical structured
learning techniques for natural language process-
ing. Ph.D. thesis, University of Southern California.
Yoav Goldberg, Kai Zhao, and Liang Huang. 2013.
Efficient implementation of beam-search incremen-
tal parsers. In Proceedings of the 51st Annual Meet-
ing of the Association for Computational Linguistics
(ACL), Sophia, Bulgaria, August.
Jan Hajic, Jarmila Panevová, Eva Hajicová, Petr
Sgall, Petr Pajas, Jan Štepánek, Jiˇrí Havelka,
Marie Mikulová, Zdenek Zabokrtsk`y, and
Magda Ševcıková Razımová. 2006. Prague
dependency treebank 2.0. CD-ROM, Linguistic
Data Consortium, LDC Catalog No.: LDC2006T01,
Philadelphia, 98.
Liang Huang and Kenji Sagae. 2010. Dynamic pro-
gramming for linear-time incremental parsing. In
Proceedings of the 48th Annual Meeting of the Asso-
ciation for Computational Linguistics, pages 1077–
1086. Association for Computational Linguistics.
Angelina Ivanova, Stephan Oepen, Lilja Øvrelid, and
Dan Flickinger. 2012. Who did what to whom?:
A contrastive study of syntacto-semantic dependen-
cies. In Proceedings of the sixth linguistic annota-
tion workshop, pages 2–11.
Sandra Kübler, Ryan McDonald, and Joakim Nivre.
2009. Dependency Parsing. Morgan and Claypool
Publishers.
John Langford, Lihong Li, and Tong Zhang. 2009.
Sparse online learning via truncated gradient. Jour-
nal of Machine Learning Research, 10(777-801):65.
Geoffrey Leech. 1992. 100 million words of English:
the British National Corpus. Language Research,
28(1):1–13.
Yusuke Miyao and Jun’ichi Tsujii. 2004. Deep
Linguistic Analysis for the Accurate Identification
of Predicate-Argument Relations. In Proceedings
of the 18th International Conference on Compu-
tational Linguistics (COLING 2004), pages 1392–
1397, Geneva, Switzerland.
Joakim Nivre, Johan Hall, Sandra Kübler, Ryan Mc-
Donald, Jens Nilsson, Sebastian Riedel, and Deniz
Yuret. 2007a. The CoNLL 2007 shared task on
dependency parsing. In Proceedings of the CoNLL
Shared Task Session of EMNLP-CoNLL 2007, pages
915–932, Prague, Czech Republic, June.
Joakim Nivre, Johan Hall, Jens Nilsson, Atanas
Chanev, Gül¸sen Eryiˇgit, Sandra Kübler, Svetoslav
Marinov, and Erwin Marsi. 2007b. MaltParser:
A language-independent system for data-driven de-
pendency parsing. Natural Language Engineering,
13(2):95–135.
Stephan Oepen, Marco Kuhlmann, Yusuke Miyao,
Daniel Zeman, Dan Flickinger, Jan Hajiˇc, Angelina
Ivanova, and Yi Zhang. 2014. SemEval 2014 Task
8: Broad-coverage semantic dependency parsing. In
Proceedings of the 8th International Workshop on
Semantic Evaluation, Dublin, Ireland.
Naoaki Okazaki. 2009. Classias: A collection of ma-
chine learning algorithms for classification.
Adwait Ratnaparkhi. 1997. A simple introduction to
maximum entropy models for natural language pro-
cessing. IRCS Technical Reports Series, page 81.
Kenji Sagae and Jun’ichi Tsujii. 2008. Shift-reduce
dependency DAG parsing. In Proceedings of the
22nd International Conference on Computational
Linguistics (Coling 2008), pages 753–760, Manch-
ester, UK, August. Coling 2008 Organizing Com-
mittee.
Djamé Seddah, Reut Tsarfaty, Sandra Kübler, Marie
Candito, Jinho D. Choi, Richárd Farkas, Jen-
nifer Foster, Iakes Goenaga, Koldo Gojenola Gal-
letebeitia, Yoav Goldberg, Spence Green, Nizar
Habash, Marco Kuhlmann, Wolfgang Maier, Joakim
Nivre, Adam Przepiórkowski, Ryan Roth, Wolfgang
Seeker, Yannick Versley, Veronika Vincze, Marcin
Woli´nski, Alina Wróblewska, and Éric Villemonte
De La Clergerie. 2013. Overview of the SPMRL
2013 shared task: A cross-framework evaluation of
</reference>
<page confidence="0.978291">
102
</page>
<reference confidence="0.997035571428571">
parsing morphologically rich languages. In Pro-
ceedings of the Fourth Workshop on Statistical Pars-
ing of Morphologically-Rich Languages, pages 146–
182, Seattle, Washington, USA, October.
Djamé Seddah. 2010. Exploring the spinal-stig
model for parsing french. In Proceedings of the
Seventh conference on International Language Re-
sources and Evaluation (LREC’10), Valletta, Malta,
may. European Language Resources Association
(ELRA).
Éric Villemonte De La Clergerie. 2013. Exploring
beam-based shift-reduce dependency parsing with
DyALog: Results from the SPMRL 2013 shared
task. In 4th Workshop on Statistical Parsing of Mor-
phologically Rich Languages (SPMRL’2013), Seat-
tle, États-Unis.
Joachim Wagner, Djamé Seddah, Jennifer Foster, and
Josef Van Genabith. 2007. C-structures and F-
structures for the British National Corpus. In Pro-
ceedings of the Twelfth International Lexical Func-
tional Grammar Conference. Citeseer.
</reference>
<page confidence="0.999299">
103
</page>
</variant>
</algorithm>
<algorithm name="ParsHed" version="110505">
<variant no="0" confidence="0.342873">
<title confidence="0.7323665">Alpage: Transition-based Semantic Graph Parsing with Syntactic Features Villemonte dela Djamé Paris Diderot, Sorbonne Paris</title>
<author confidence="0.493009">Paris Sorbonne</author>
<email confidence="0.990211">firstname.lastname@inria.fr</email>
<abstract confidence="0.994963857142857">This paper describes the systems deployed the to participate to the SemEval-2014 Task on Broad-Coverage Dependency We developed two transition-based dependency parsers with extended sets of actions to handle non-planar acyclic graphs. For the open track, we worked over two orthogonal axes – lexical and syntactic – in order to provide our models with lexical and syntactic features such as word clusters, lemmas and tree fragments of different types.</abstract>
</variant>
</algorithm>
<algorithm name="ParsCit" version="110505">
<citationList>
<citation valid="false">
<title>Building and Using Parsed Corpora,</title>
<pages>165--188</pages>
<publisher>Springer.</publisher>
<marker></marker>
<rawString>: Building and Using Parsed Corpora, pages 165– 188. Springer.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Daniel M Bikel</author>
</authors>
<title>Design of a multi-lingual, parallel-processing statistical parsing engine.</title>
<date>2002</date>
<booktitle>In Proceedings of the second international conference on Human Language Technology Research,</booktitle>
<pages>178--182</pages>
<publisher>Morgan Kaufmann Publishers Inc.</publisher>
<location>San Francisco, CA, USA.</location>
<contexts>
<context position="12617" citStr="Bikel (2002)" startWordPosition="2059" endWordPosition="2060">usters from the BNC (Leech, 1992) preprocessed following Wagner et al. (2007). We extended them with capitalization, digit features and 3 letters suffix signatures, leading to a vocabulary size reduced by half. Constituent tree fragments They were part of the companion data provided by the organizers. 99 They consist of fragments of the syntactic trees and can be used either as enhanced parts of speech or as features. Spinal elementary trees A full set of parses was reconstructed from the tree fragments. Then we extracted a spine grammar (Seddah, 2010), using the head percolation table of the Bikel (2002) parser, slightly modified to avoid determiners to be marked as head in some configurations. Predicted MATE dependencies Also provided in the companion data, they consist in the parses built by the MATE parsers, trained on the Stanford dependency version of the PTB. We combined the labels with a distance S = t − h where t is the token number and h the head number. Constituent head paths Inspired by Björkelund et al. (2013), we used the MATE dependencies to extract the shortest path between a token and its lexical head and included the path length (in terms of traversed nodes) as feature. Tree </context>
</contexts>
<marker>Bikel, 2002</marker>
<rawString>Daniel M. Bikel. 2002. Design of a multi-lingual, parallel-processing statistical parsing engine. In Proceedings of the second international conference on Human Language Technology Research, pages 178–182. Morgan Kaufmann Publishers Inc. San Francisco, CA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Anders Björkelund</author>
<author>Ozlem Cetinoglu</author>
<author>Richárd Farkas</author>
<author>Thomas Mueller</author>
<author>Wolfgang Seeker</author>
</authors>
<title>(re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task.</title>
<date>2013</date>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>135--145</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="13043" citStr="Björkelund et al. (2013)" startWordPosition="2131" endWordPosition="2134">atures. Spinal elementary trees A full set of parses was reconstructed from the tree fragments. Then we extracted a spine grammar (Seddah, 2010), using the head percolation table of the Bikel (2002) parser, slightly modified to avoid determiners to be marked as head in some configurations. Predicted MATE dependencies Also provided in the companion data, they consist in the parses built by the MATE parsers, trained on the Stanford dependency version of the PTB. We combined the labels with a distance S = t − h where t is the token number and h the head number. Constituent head paths Inspired by Björkelund et al. (2013), we used the MATE dependencies to extract the shortest path between a token and its lexical head and included the path length (in terms of traversed nodes) as feature. Tree frag. MATE labels+δ Spines trees Head Paths Train 648 1305 637 27,670 Dev 272 742 265 3,320 Test 273 731 268 2,389 Table 2: Syntactic features statistics. 4 Results and Discussion We present here the results on section 21 (test set)1 for both systems. We report in Table 3, the different runs we submitted for the final evaluation of the shared task. We also report improvements between the two tracks. Both systems show relat</context>
</contexts>
<marker>Björkelund, Cetinoglu, Farkas, Mueller, Seeker, 2013</marker>
<rawString>Anders Björkelund, Ozlem Cetinoglu, Richárd Farkas, Thomas Mueller, and Wolfgang Seeker. 2013. (re)ranking meets morphosyntax: State-of-the-art results from the SPMRL 2013 shared task. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 135– 145, Seattle, Washington, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Bernd Bohnet</author>
</authors>
<title>Very high accuracy and fast dependency parsing is not a contradiction.</title>
<date>2010</date>
<booktitle>In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10,</booktitle>
<pages>89--97</pages>
<location>Stroudsburg, PA, USA.</location>
<contexts>
<context position="10852" citStr="Bohnet, 2010" startWordPosition="1762" endWordPosition="1763">feature values are atomic (either numerical or symbolic), but they can also be (recursively) a list of values, for instance for the mstag and domain features. For dealing with graphs, features were added about the incoming edges to the 3 topmost stack elements, similar to valency (ngov[012]) and domain (gov[012]). For the PCEDT scheme, because of the high number of dependency labels, the 30 most unfrequent ones were replaced by a generic label when used as feature value. Besides, for the PCEDT and DM corpora, static and dynamic guiding features have been tried for DYALOG-SR, provided by MATE (Bohnet, 2010) (trained on versions of these corpora projected to trees, using a 10-fold cross validation). The two static features mate _alabel and mate distance are attached to ech token h, indicating the label and the relative distance to its governor d (if any). At runtime, dynamic features are also added relative to the current configuration: if a semantic dependency (h, l, d) has been predicted by MATE, and the topmost 2 stack elements are either (h, d) or (d, h), a feature suggesting a left or right attachment for l is added. We did the same for S&amp;T PARSER, except that we used a simple but efficient </context>
</contexts>
<marker>Bohnet, 2010</marker>
<rawString>Bernd Bohnet. 2010. Very high accuracy and fast dependency parsing is not a contradiction. In Proceedings of the 23rd International Conference on Computational Linguistics, COLING ’10, pages 89–97, Stroudsburg, PA, USA.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Marie Candito</author>
<author>Guy Perrier</author>
<author>Bruno Guillaume</author>
</authors>
<title>Corentin Ribeyre, Karën Fort, Djamé Seddah, and Éric De La Clergerie.</title>
<date>2014</date>
<booktitle>In International Conference on Language Resources and Evaluation (LREC),</booktitle>
<location>Reykjavik, Islande,</location>
<contexts>
<context position="15708" citStr="Candito et al., 2014" startWordPosition="2587" endWordPosition="2590">such as the ARG3 label). We observed the same behaviour on the PAS corpus, which contains also predicate-argument structures. For PCEDT, the results show that syntactic features give only small improvements, but the corpus is harder because of a large set of labels and is closer to syntactic structures than the two others. Of course, we only scratched the surface with our experiments and we plan to further investigate the impact of syntactic information during semantic parsing. We especially plan to explore the deep parsing of French, thanks to the recent release of the Deep Sequoia Treebank (Candito et al., 2014). 5 Conclusion In this paper, we presented our results on the task 8 of the SemEval-2014 Task on Broad-Coverage Semantic Dependency Parsing. Even though the results do not reach state-of-the-art, they compare favorably with other single systems and show that syntactic features can be efficiently used for semantic parsing. In future work, we will continue to investigate this idea, by combining with more complex systems and more efficient machine learning techniques, we are convinced that we can come closer to state of the art results. and that syntax is the key for better semantic parsing. Ackn</context>
</contexts>
<marker>Candito, Perrier, Guillaume, 2014</marker>
<rawString>Marie Candito, Guy Perrier, Bruno Guillaume, Corentin Ribeyre, Karën Fort, Djamé Seddah, and Éric De La Clergerie. 2014. Deep Syntax Annotation of the Sequoia French Treebank. In International Conference on Language Resources and Evaluation (LREC), Reykjavik, Islande, May.</rawString>
</citation>
<citation valid="true">
<authors>
<author>David Chiang</author>
<author>Jacob Andreas</author>
<author>Daniel Bauer</author>
<author>Karl Moritz Hermann</author>
<author>Bevan Jones</author>
<author>Kevin Knight</author>
</authors>
<title>Parsing graphs with hyperedge replacement grammars.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Meeting of the ACL.</booktitle>
<contexts>
<context position="905" citStr="Chiang et al., 2013" startWordPosition="131" endWordPosition="134"> systems deployed by the ALPAGE team to participate to the SemEval-2014 Task on Broad-Coverage Semantic Dependency Parsing. We developed two transition-based dependency parsers with extended sets of actions to handle non-planar acyclic graphs. For the open track, we worked over two orthogonal axes – lexical and syntactic – in order to provide our models with lexical and syntactic features such as word clusters, lemmas and tree fragments of different types. 1 Introduction In recent years, we have seen the emergence of semantic parsing, relying on various techniques ranging from graph grammars (Chiang et al., 2013) to transitions-based dependency parsers (Sagae and Tsujii, 2008). Assuming that obtaining predicate argument structures is a necessary goal to move from syntax to accurate surface semantics, the question of the representation of such structures arises. Regardless of the annotation scheme that should be used, one of the main issues of semantic representation is the construction of graph structures, that are inherently harder to generate than the classical tree structures. In that aspect, the shared task’s proposal (Oepen et al., 2014), to evaluate different syntacticsemantic schemes (Ivanova e</context>
</contexts>
<marker>Chiang, Andreas, Bauer, Hermann, Jones, Knight, 2013</marker>
<rawString>David Chiang, Jacob Andreas, Daniel Bauer, Karl Moritz Hermann, Bevan Jones, and Kevin Knight. 2013. Parsing graphs with hyperedge replacement grammars. In Proceedings of the 51st Meeting of the ACL.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Harold Charles Daume</author>
</authors>
<title>Practical structured learning techniques for natural language processing.</title>
<date>2006</date>
<tech>Ph.D. thesis,</tech>
<institution>University of Southern California.</institution>
<contexts>
<context position="6173" citStr="Daume, 2006" startWordPosition="1001" endWordPosition="1002">em is a partial rewrite, with several extensions, of the Sagae and Tsujii (2008) DAG parser (henceforth S&amp;T PARSER). We modified it to handle dependency graphs, in particular non-governed words using pop0 transitions. This new transition removes the topmost stack element when all its dependents have been attached (through attach or reduce transitions). Thus, we can handle partially connected graphs, since a word can be discarded when it has no incoming arc. We used two different learning algorithms: (i) the averaged perceptron because of its good balance between training time and performance (Daume, 2006), (ii) the logistic regression model (maximum entropy (Ratnaparkhi, 1997)). For the latter, we used the truncated gradient optimization (Langford et al., 2009), implemented in Classias (Okazaki, 2009), in order to estimate the parameters. These algorithms have been used interchangeably to test their performance in terms of Fscore. But the difference was negligeable in general. 2.2 DYALOG-SR Our second parsing system is DYALOG-SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL’13 shared task. Coded on top of tabular logic programming system DYALOG, it im</context>
</contexts>
<marker>Daume, 2006</marker>
<rawString>Harold Charles Daume. 2006. Practical structured learning techniques for natural language processing. Ph.D. thesis, University of Southern California.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yoav Goldberg</author>
<author>Kai Zhao</author>
<author>Liang Huang</author>
</authors>
<title>Efficient implementation of beam-search incremental parsers.</title>
<date>2013</date>
<booktitle>In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL),</booktitle>
<location>Sophia, Bulgaria,</location>
<contexts>
<context position="2329" citStr="Goldberg et al., 2013" startWordPosition="352" endWordPosition="355">very plateau for a This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs. The first one follows the standard greedy search mechanism of (Nivre et al., 2007b), while the second one follows a slightly more global search strategy (Huang and Sagae, 2010; Goldberg et al., 2013) by relying on dynamic programming techniques. In addition to building graphs directly, the main originality of our work lies in the use of different kinds of syntactic features, showing that using syntax for pure deep semantic parsing improves global performance by more than two points. Although not state-of-the-art, our systems perform very honorably compared with other single systems in this shared task and pave quite an interesting way for further work. In the remainder of this paper, we present the parsers and their extensions for building graphs; we then present our syntactic features an</context>
<context position="6964" citStr="Goldberg et al., 2013" startWordPosition="1120" endWordPosition="1123">ted in Classias (Okazaki, 2009), in order to estimate the parameters. These algorithms have been used interchangeably to test their performance in terms of Fscore. But the difference was negligeable in general. 2.2 DYALOG-SR Our second parsing system is DYALOG-SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL’13 shared task. Coded on top of tabular logic programming system DYALOG, it implements a transition-based parser relying on dynamic programming techniques, beams, and an averaged structured perceptron, following ideas from (Huang and Sagae, 2010; Goldberg et al., 2013). It was initially designed to follow an arcstandard parsing strategy, relying on shift and left/right reduce transitions. To deal with dependency graphs and non governed words, we first added the two attach transitions and the pop0 transition. But because there exist some overlap between the reduce and attach transitions leading to some spurious ambiguities, we finally decided to remove the left/right reduce transitions and to complete with the pop1 transition. In order to handle some cases of non-projectivty with minimal modifications of the system, we also added a swap transition. The parsi</context>
</contexts>
<marker>Goldberg, Zhao, Huang, 2013</marker>
<rawString>Yoav Goldberg, Kai Zhao, and Liang Huang. 2013. Efficient implementation of beam-search incremental parsers. In Proceedings of the 51st Annual Meeting of the Association for Computational Linguistics (ACL), Sophia, Bulgaria, August.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Jan Hajic</author>
<author>Jarmila Panevová</author>
<author>Eva Hajicová</author>
<author>Petr Sgall</author>
<author>Petr Pajas</author>
<author>Jan Štepánek</author>
<author>Jiˇrí Havelka</author>
<author>Marie Mikulová</author>
<author>Zdenek Zabokrtsk`y</author>
<author>Magda Ševcıková Razımová</author>
</authors>
<date>2006</date>
<booktitle>Prague dependency treebank 2.0. CD-ROM, Linguistic Data Consortium, LDC Catalog No.: LDC2006T01,</booktitle>
<location>Philadelphia,</location>
<marker>Hajic, Panevová, Hajicová, Sgall, Pajas, Štepánek, Havelka, Mikulová, Zabokrtsk`y, Razımová, 2006</marker>
<rawString>Jan Hajic, Jarmila Panevová, Eva Hajicová, Petr Sgall, Petr Pajas, Jan Štepánek, Jiˇrí Havelka, Marie Mikulová, Zdenek Zabokrtsk`y, and Magda Ševcıková Razımová. 2006. Prague dependency treebank 2.0. CD-ROM, Linguistic Data Consortium, LDC Catalog No.: LDC2006T01, Philadelphia, 98.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Liang Huang</author>
<author>Kenji Sagae</author>
</authors>
<title>Dynamic programming for linear-time incremental parsing.</title>
<date>2010</date>
<booktitle>In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics,</booktitle>
<pages>1077--1086</pages>
<institution>Association for Computational Linguistics.</institution>
<contexts>
<context position="2305" citStr="Huang and Sagae, 2010" startWordPosition="348" endWordPosition="351">labeled dependency recovery plateau for a This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs. The first one follows the standard greedy search mechanism of (Nivre et al., 2007b), while the second one follows a slightly more global search strategy (Huang and Sagae, 2010; Goldberg et al., 2013) by relying on dynamic programming techniques. In addition to building graphs directly, the main originality of our work lies in the use of different kinds of syntactic features, showing that using syntax for pure deep semantic parsing improves global performance by more than two points. Although not state-of-the-art, our systems perform very honorably compared with other single systems in this shared task and pave quite an interesting way for further work. In the remainder of this paper, we present the parsers and their extensions for building graphs; we then present o</context>
<context position="6940" citStr="Huang and Sagae, 2010" startWordPosition="1116" endWordPosition="1119">et al., 2009), implemented in Classias (Okazaki, 2009), in order to estimate the parameters. These algorithms have been used interchangeably to test their performance in terms of Fscore. But the difference was negligeable in general. 2.2 DYALOG-SR Our second parsing system is DYALOG-SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL’13 shared task. Coded on top of tabular logic programming system DYALOG, it implements a transition-based parser relying on dynamic programming techniques, beams, and an averaged structured perceptron, following ideas from (Huang and Sagae, 2010; Goldberg et al., 2013). It was initially designed to follow an arcstandard parsing strategy, relying on shift and left/right reduce transitions. To deal with dependency graphs and non governed words, we first added the two attach transitions and the pop0 transition. But because there exist some overlap between the reduce and attach transitions leading to some spurious ambiguities, we finally decided to remove the left/right reduce transitions and to complete with the pop1 transition. In order to handle some cases of non-projectivty with minimal modifications of the system, we also added a sw</context>
</contexts>
<marker>Huang, Sagae, 2010</marker>
<rawString>Liang Huang and Kenji Sagae. 2010. Dynamic programming for linear-time incremental parsing. In Proceedings of the 48th Annual Meeting of the Association for Computational Linguistics, pages 1077– 1086. Association for Computational Linguistics.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Angelina Ivanova</author>
<author>Stephan Oepen</author>
<author>Lilja Øvrelid</author>
<author>Dan Flickinger</author>
</authors>
<title>Who did what to whom?: A contrastive study of syntacto-semantic dependencies.</title>
<date>2012</date>
<booktitle>In Proceedings of the sixth linguistic annotation workshop,</booktitle>
<pages>2--11</pages>
<contexts>
<context position="1516" citStr="Ivanova et al., 2012" startWordPosition="224" endWordPosition="227">l., 2013) to transitions-based dependency parsers (Sagae and Tsujii, 2008). Assuming that obtaining predicate argument structures is a necessary goal to move from syntax to accurate surface semantics, the question of the representation of such structures arises. Regardless of the annotation scheme that should be used, one of the main issues of semantic representation is the construction of graph structures, that are inherently harder to generate than the classical tree structures. In that aspect, the shared task’s proposal (Oepen et al., 2014), to evaluate different syntacticsemantic schemes (Ivanova et al., 2012; Hajic et al., 2006; Miyao and Tsujii, 2004) could not arrive at a more timely moment when state-of-the-art surface syntactic parsers regularly reach, or cross, a 90% labeled dependency recovery plateau for a This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic depen</context>
</contexts>
<marker>Ivanova, Oepen, Øvrelid, Flickinger, 2012</marker>
<rawString>Angelina Ivanova, Stephan Oepen, Lilja Øvrelid, and Dan Flickinger. 2012. Who did what to whom?: A contrastive study of syntacto-semantic dependencies. In Proceedings of the sixth linguistic annotation workshop, pages 2–11.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Sandra Kübler</author>
<author>Ryan McDonald</author>
<author>Joakim Nivre</author>
</authors>
<title>Dependency Parsing.</title>
<date>2009</date>
<publisher>Morgan and Claypool Publishers.</publisher>
<contexts>
<context position="3219" citStr="Kübler et al. (2009)" startWordPosition="497" endWordPosition="500">e than two points. Although not state-of-the-art, our systems perform very honorably compared with other single systems in this shared task and pave quite an interesting way for further work. In the remainder of this paper, we present the parsers and their extensions for building graphs; we then present our syntactic features and discuss our results. 2 Systems Description Shift-reduce transition-based parsers essentially rely on configurations formed of a stack and a buffer, with stack transitions used to go from a configuration to the next one, until reaching a final configuration. Following Kübler et al. (2009), we define a configuration by c = (σ, β, A) where σ denotes a stack of words wi, β a buffer of words, and A a set of dependency arcs of the form (wi, r, wj), with wi the head, wj the dependent, and r a label in some set R. However, despite their overall similarities, transition-based systems may differ on many aspects, such as the exact definition of the configurations, the set of transitions extracted from the configurations, the way the search space is explored (at parsing and training time), the set of features, the way the transition weights are learned and ap97 Proceedings of the 8th Int</context>
</contexts>
<marker>Kübler, McDonald, Nivre, 2009</marker>
<rawString>Sandra Kübler, Ryan McDonald, and Joakim Nivre. 2009. Dependency Parsing. Morgan and Claypool Publishers.</rawString>
</citation>
<citation valid="true">
<authors>
<author>John Langford</author>
<author>Lihong Li</author>
<author>Tong Zhang</author>
</authors>
<title>Sparse online learning via truncated gradient.</title>
<date>2009</date>
<journal>Journal of Machine Learning Research,</journal>
<pages>10--777</pages>
<contexts>
<context position="6332" citStr="Langford et al., 2009" startWordPosition="1022" endWordPosition="1025">ncy graphs, in particular non-governed words using pop0 transitions. This new transition removes the topmost stack element when all its dependents have been attached (through attach or reduce transitions). Thus, we can handle partially connected graphs, since a word can be discarded when it has no incoming arc. We used two different learning algorithms: (i) the averaged perceptron because of its good balance between training time and performance (Daume, 2006), (ii) the logistic regression model (maximum entropy (Ratnaparkhi, 1997)). For the latter, we used the truncated gradient optimization (Langford et al., 2009), implemented in Classias (Okazaki, 2009), in order to estimate the parameters. These algorithms have been used interchangeably to test their performance in terms of Fscore. But the difference was negligeable in general. 2.2 DYALOG-SR Our second parsing system is DYALOG-SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL’13 shared task. Coded on top of tabular logic programming system DYALOG, it implements a transition-based parser relying on dynamic programming techniques, beams, and an averaged structured perceptron, following ideas from (Huang and Sag</context>
</contexts>
<marker>Langford, Li, Zhang, 2009</marker>
<rawString>John Langford, Lihong Li, and Tong Zhang. 2009. Sparse online learning via truncated gradient. Journal of Machine Learning Research, 10(777-801):65.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Geoffrey Leech</author>
</authors>
<title>100 million words of English:</title>
<date>1992</date>
<journal>the British National Corpus. Language Research,</journal>
<volume>28</volume>
<issue>1</issue>
<contexts>
<context position="12038" citStr="Leech, 1992" startWordPosition="1962" endWordPosition="1963">ed a simple but efficient hack: instead of keeping the labels predicted by our parser, we replaced them by MATE predictions whenever it was possible. 3.2 Open Track For this track, we combined the previously described features (but the MATE-related ones) with various lexical and syntactic features, our intuition being that syntax and semantic are interdependent, and that syntactic features should therefore help semantic parsing. In particular, we have considered the following bits of information. Unsupervized Brown clusters To reduce lexical sparsity, we extracted 1,000 clusters from the BNC (Leech, 1992) preprocessed following Wagner et al. (2007). We extended them with capitalization, digit features and 3 letters suffix signatures, leading to a vocabulary size reduced by half. Constituent tree fragments They were part of the companion data provided by the organizers. 99 They consist of fragments of the syntactic trees and can be used either as enhanced parts of speech or as features. Spinal elementary trees A full set of parses was reconstructed from the tree fragments. Then we extracted a spine grammar (Seddah, 2010), using the head percolation table of the Bikel (2002) parser, slightly mod</context>
</contexts>
<marker>Leech, 1992</marker>
<rawString>Geoffrey Leech. 1992. 100 million words of English: the British National Corpus. Language Research, 28(1):1–13.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Yusuke Miyao</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Deep Linguistic Analysis for the Accurate Identification of Predicate-Argument Relations.</title>
<date>2004</date>
<booktitle>In Proceedings of the 18th International Conference on Computational Linguistics (COLING 2004),</booktitle>
<pages>1392--1397</pages>
<location>Geneva, Switzerland.</location>
<contexts>
<context position="1561" citStr="Miyao and Tsujii, 2004" startWordPosition="232" endWordPosition="235">parsers (Sagae and Tsujii, 2008). Assuming that obtaining predicate argument structures is a necessary goal to move from syntax to accurate surface semantics, the question of the representation of such structures arises. Regardless of the annotation scheme that should be used, one of the main issues of semantic representation is the construction of graph structures, that are inherently harder to generate than the classical tree structures. In that aspect, the shared task’s proposal (Oepen et al., 2014), to evaluate different syntacticsemantic schemes (Ivanova et al., 2012; Hajic et al., 2006; Miyao and Tsujii, 2004) could not arrive at a more timely moment when state-of-the-art surface syntactic parsers regularly reach, or cross, a 90% labeled dependency recovery plateau for a This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs. The first one follows the stand</context>
</contexts>
<marker>Miyao, Tsujii, 2004</marker>
<rawString>Yusuke Miyao and Jun’ichi Tsujii. 2004. Deep Linguistic Analysis for the Accurate Identification of Predicate-Argument Relations. In Proceedings of the 18th International Conference on Computational Linguistics (COLING 2004), pages 1392– 1397, Geneva, Switzerland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Sandra Kübler</author>
<author>Ryan McDonald</author>
<author>Jens Nilsson</author>
<author>Sebastian Riedel</author>
<author>Deniz Yuret</author>
</authors>
<title>shared task on dependency parsing.</title>
<date>2007</date>
<journal>The CoNLL</journal>
<booktitle>In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007,</booktitle>
<pages>915--932</pages>
<location>Prague, Czech Republic,</location>
<contexts>
<context position="1982" citStr="Nivre et al., 2007" startWordPosition="293" endWordPosition="296"> tree structures. In that aspect, the shared task’s proposal (Oepen et al., 2014), to evaluate different syntacticsemantic schemes (Ivanova et al., 2012; Hajic et al., 2006; Miyao and Tsujii, 2004) could not arrive at a more timely moment when state-of-the-art surface syntactic parsers regularly reach, or cross, a 90% labeled dependency recovery plateau for a This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs. The first one follows the standard greedy search mechanism of (Nivre et al., 2007b), while the second one follows a slightly more global search strategy (Huang and Sagae, 2010; Goldberg et al., 2013) by relying on dynamic programming techniques. In addition to building graphs directly, the main originality of our work lies in the use of different kinds of syntactic features, showing that using syntax for pure deep semantic parsing improves global p</context>
</contexts>
<marker>Nivre, Hall, Kübler, McDonald, Nilsson, Riedel, Yuret, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Sandra Kübler, Ryan McDonald, Jens Nilsson, Sebastian Riedel, and Deniz Yuret. 2007a. The CoNLL 2007 shared task on dependency parsing. In Proceedings of the CoNLL Shared Task Session of EMNLP-CoNLL 2007, pages 915–932, Prague, Czech Republic, June.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joakim Nivre</author>
<author>Johan Hall</author>
<author>Jens Nilsson</author>
</authors>
<title>Atanas Chanev, Gül¸sen Eryiˇgit, Sandra Kübler, Svetoslav Marinov, and Erwin Marsi.</title>
<date>2007</date>
<journal>Natural Language Engineering,</journal>
<volume>13</volume>
<issue>2</issue>
<contexts>
<context position="1982" citStr="Nivre et al., 2007" startWordPosition="293" endWordPosition="296"> tree structures. In that aspect, the shared task’s proposal (Oepen et al., 2014), to evaluate different syntacticsemantic schemes (Ivanova et al., 2012; Hajic et al., 2006; Miyao and Tsujii, 2004) could not arrive at a more timely moment when state-of-the-art surface syntactic parsers regularly reach, or cross, a 90% labeled dependency recovery plateau for a This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs. The first one follows the standard greedy search mechanism of (Nivre et al., 2007b), while the second one follows a slightly more global search strategy (Huang and Sagae, 2010; Goldberg et al., 2013) by relying on dynamic programming techniques. In addition to building graphs directly, the main originality of our work lies in the use of different kinds of syntactic features, showing that using syntax for pure deep semantic parsing improves global p</context>
</contexts>
<marker>Nivre, Hall, Nilsson, 2007</marker>
<rawString>Joakim Nivre, Johan Hall, Jens Nilsson, Atanas Chanev, Gül¸sen Eryiˇgit, Sandra Kübler, Svetoslav Marinov, and Erwin Marsi. 2007b. MaltParser: A language-independent system for data-driven dependency parsing. Natural Language Engineering, 13(2):95–135.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Stephan Oepen</author>
<author>Marco Kuhlmann</author>
<author>Yusuke Miyao</author>
<author>Daniel Zeman</author>
<author>Dan Flickinger</author>
<author>Jan Hajiˇc</author>
<author>Angelina Ivanova</author>
<author>Yi Zhang</author>
</authors>
<title>Task 8: Broad-coverage semantic dependency parsing.</title>
<date>2014</date>
<booktitle>In Proceedings of the 8th International Workshop on Semantic Evaluation,</booktitle>
<location>Dublin, Ireland.</location>
<note>SemEval</note>
<marker>Oepen, Kuhlmann, Miyao, Zeman, Flickinger, Hajiˇc, Ivanova, Zhang, 2014</marker>
<rawString>Stephan Oepen, Marco Kuhlmann, Yusuke Miyao, Daniel Zeman, Dan Flickinger, Jan Hajiˇc, Angelina Ivanova, and Yi Zhang. 2014. SemEval 2014 Task 8: Broad-coverage semantic dependency parsing. In Proceedings of the 8th International Workshop on Semantic Evaluation, Dublin, Ireland.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Naoaki Okazaki</author>
</authors>
<title>Classias: A collection of machine learning algorithms for classification.</title>
<date>2009</date>
<contexts>
<context position="6373" citStr="Okazaki, 2009" startWordPosition="1030" endWordPosition="1031">g pop0 transitions. This new transition removes the topmost stack element when all its dependents have been attached (through attach or reduce transitions). Thus, we can handle partially connected graphs, since a word can be discarded when it has no incoming arc. We used two different learning algorithms: (i) the averaged perceptron because of its good balance between training time and performance (Daume, 2006), (ii) the logistic regression model (maximum entropy (Ratnaparkhi, 1997)). For the latter, we used the truncated gradient optimization (Langford et al., 2009), implemented in Classias (Okazaki, 2009), in order to estimate the parameters. These algorithms have been used interchangeably to test their performance in terms of Fscore. But the difference was negligeable in general. 2.2 DYALOG-SR Our second parsing system is DYALOG-SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL’13 shared task. Coded on top of tabular logic programming system DYALOG, it implements a transition-based parser relying on dynamic programming techniques, beams, and an averaged structured perceptron, following ideas from (Huang and Sagae, 2010; Goldberg et al., 2013). It was </context>
</contexts>
<marker>Okazaki, 2009</marker>
<rawString>Naoaki Okazaki. 2009. Classias: A collection of machine learning algorithms for classification.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Adwait Ratnaparkhi</author>
</authors>
<title>A simple introduction to maximum entropy models for natural language processing.</title>
<date>1997</date>
<booktitle>IRCS Technical Reports Series,</booktitle>
<pages>81</pages>
<contexts>
<context position="6246" citStr="Ratnaparkhi, 1997" startWordPosition="1010" endWordPosition="1011">Tsujii (2008) DAG parser (henceforth S&amp;T PARSER). We modified it to handle dependency graphs, in particular non-governed words using pop0 transitions. This new transition removes the topmost stack element when all its dependents have been attached (through attach or reduce transitions). Thus, we can handle partially connected graphs, since a word can be discarded when it has no incoming arc. We used two different learning algorithms: (i) the averaged perceptron because of its good balance between training time and performance (Daume, 2006), (ii) the logistic regression model (maximum entropy (Ratnaparkhi, 1997)). For the latter, we used the truncated gradient optimization (Langford et al., 2009), implemented in Classias (Okazaki, 2009), in order to estimate the parameters. These algorithms have been used interchangeably to test their performance in terms of Fscore. But the difference was negligeable in general. 2.2 DYALOG-SR Our second parsing system is DYALOG-SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL’13 shared task. Coded on top of tabular logic programming system DYALOG, it implements a transition-based parser relying on dynamic programming techniq</context>
</contexts>
<marker>Ratnaparkhi, 1997</marker>
<rawString>Adwait Ratnaparkhi. 1997. A simple introduction to maximum entropy models for natural language processing. IRCS Technical Reports Series, page 81.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Kenji Sagae</author>
<author>Jun’ichi Tsujii</author>
</authors>
<title>Shift-reduce dependency DAG parsing.</title>
<date>2008</date>
<journal>Organizing Committee.</journal>
<booktitle>In Proceedings of the 22nd International Conference on Computational Linguistics (Coling</booktitle>
<pages>753--760</pages>
<location>Manchester, UK,</location>
<contexts>
<context position="970" citStr="Sagae and Tsujii, 2008" startWordPosition="139" endWordPosition="142">Eval-2014 Task on Broad-Coverage Semantic Dependency Parsing. We developed two transition-based dependency parsers with extended sets of actions to handle non-planar acyclic graphs. For the open track, we worked over two orthogonal axes – lexical and syntactic – in order to provide our models with lexical and syntactic features such as word clusters, lemmas and tree fragments of different types. 1 Introduction In recent years, we have seen the emergence of semantic parsing, relying on various techniques ranging from graph grammars (Chiang et al., 2013) to transitions-based dependency parsers (Sagae and Tsujii, 2008). Assuming that obtaining predicate argument structures is a necessary goal to move from syntax to accurate surface semantics, the question of the representation of such structures arises. Regardless of the annotation scheme that should be used, one of the main issues of semantic representation is the construction of graph structures, that are inherently harder to generate than the classical tree structures. In that aspect, the shared task’s proposal (Oepen et al., 2014), to evaluate different syntacticsemantic schemes (Ivanova et al., 2012; Hajic et al., 2006; Miyao and Tsujii, 2004) could no</context>
<context position="4933" citStr="Sagae and Tsujii (2008)" startWordPosition="788" endWordPosition="791">|wj|wi,β, A) (σ|wi|wj,β, A) (swap) DYALOG-SR Figure 1: An extended set of transitions for building dependency graphs. plied, etc. For various reasons, we started our experiments with two rather different transition-based parsers, which have finally converged on several aspects. In particular, the main convergence concerns the set of transitions needed to parse the three proposed annotation schemes. To be able to attach zero, one, or more heads to a word, it is necessary to clearly dissociate the addition of a dependency from the reduction of a word (i.e. its removal from the stack). Following Sagae and Tsujii (2008), as shown in Figure 1, beside the usual shift and reduce transitions of the arc-standard strategy, we introduced the new left and right attach actions for adding new dependencies (while keeping the dependent on the stack) and two reduce pop0 and pop1 actions to remove a word from the stack after attachement of its dependents. All transitions adding an edge should also satisfy the condition that the new edge does not create a cycle or multiple edges between the same pair of nodes. It is worth noting that the pop actions may also be used to remove words with no heads. 2.1 Sagae &amp; Tsujii’s DAG P</context>
</contexts>
<marker>Sagae, Tsujii, 2008</marker>
<rawString>Kenji Sagae and Jun’ichi Tsujii. 2008. Shift-reduce dependency DAG parsing. In Proceedings of the 22nd International Conference on Computational Linguistics (Coling 2008), pages 753–760, Manchester, UK, August. Coling 2008 Organizing Committee.</rawString>
</citation>
<citation valid="false">
<authors>
<author>Djamé Seddah</author>
<author>Reut Tsarfaty</author>
<author>Sandra Kübler</author>
<author>Marie Candito</author>
<author>Jinho D Choi</author>
<author>Richárd Farkas</author>
<author>Jennifer Foster</author>
</authors>
<title>Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepiórkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wróblewska, and Éric Villemonte De La Clergerie.</title>
<date>2013</date>
<journal>Overview of the SPMRL</journal>
<booktitle>In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages,</booktitle>
<pages>146--182</pages>
<location>Seattle, Washington, USA,</location>
<contexts>
<context position="2005" citStr="Seddah et al., 2013" startWordPosition="297" endWordPosition="301">that aspect, the shared task’s proposal (Oepen et al., 2014), to evaluate different syntacticsemantic schemes (Ivanova et al., 2012; Hajic et al., 2006; Miyao and Tsujii, 2004) could not arrive at a more timely moment when state-of-the-art surface syntactic parsers regularly reach, or cross, a 90% labeled dependency recovery plateau for a This work is licensed under a Creative Commons Attribution 4.0 International Licence. Page numbers and proceedings footer are added by the organisers. Licence details: http://creativecommons.org/licenses/by/4.0/. wide range of languages (Nivre et al., 2007a; Seddah et al., 2013). The two systems we present both extend transition-based parsers in order to be able to generate acyclic dependency graphs. The first one follows the standard greedy search mechanism of (Nivre et al., 2007b), while the second one follows a slightly more global search strategy (Huang and Sagae, 2010; Goldberg et al., 2013) by relying on dynamic programming techniques. In addition to building graphs directly, the main originality of our work lies in the use of different kinds of syntactic features, showing that using syntax for pure deep semantic parsing improves global performance by more than</context>
</contexts>
<marker>Seddah, Tsarfaty, Kübler, Candito, Choi, Farkas, Foster, 2013</marker>
<rawString>Djamé Seddah, Reut Tsarfaty, Sandra Kübler, Marie Candito, Jinho D. Choi, Richárd Farkas, Jennifer Foster, Iakes Goenaga, Koldo Gojenola Galletebeitia, Yoav Goldberg, Spence Green, Nizar Habash, Marco Kuhlmann, Wolfgang Maier, Joakim Nivre, Adam Przepiórkowski, Ryan Roth, Wolfgang Seeker, Yannick Versley, Veronika Vincze, Marcin Woli´nski, Alina Wróblewska, and Éric Villemonte De La Clergerie. 2013. Overview of the SPMRL 2013 shared task: A cross-framework evaluation of parsing morphologically rich languages. In Proceedings of the Fourth Workshop on Statistical Parsing of Morphologically-Rich Languages, pages 146– 182, Seattle, Washington, USA, October.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Djamé Seddah</author>
</authors>
<title>Exploring the spinal-stig model for parsing french.</title>
<date>2010</date>
<journal>European Language Resources Association (ELRA).</journal>
<booktitle>In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10),</booktitle>
<location>Valletta, Malta,</location>
<contexts>
<context position="12563" citStr="Seddah, 2010" startWordPosition="2049" endWordPosition="2050">sters To reduce lexical sparsity, we extracted 1,000 clusters from the BNC (Leech, 1992) preprocessed following Wagner et al. (2007). We extended them with capitalization, digit features and 3 letters suffix signatures, leading to a vocabulary size reduced by half. Constituent tree fragments They were part of the companion data provided by the organizers. 99 They consist of fragments of the syntactic trees and can be used either as enhanced parts of speech or as features. Spinal elementary trees A full set of parses was reconstructed from the tree fragments. Then we extracted a spine grammar (Seddah, 2010), using the head percolation table of the Bikel (2002) parser, slightly modified to avoid determiners to be marked as head in some configurations. Predicted MATE dependencies Also provided in the companion data, they consist in the parses built by the MATE parsers, trained on the Stanford dependency version of the PTB. We combined the labels with a distance S = t − h where t is the token number and h the head number. Constituent head paths Inspired by Björkelund et al. (2013), we used the MATE dependencies to extract the shortest path between a token and its lexical head and included the path </context>
</contexts>
<marker>Seddah, 2010</marker>
<rawString>Djamé Seddah. 2010. Exploring the spinal-stig model for parsing french. In Proceedings of the Seventh conference on International Language Resources and Evaluation (LREC’10), Valletta, Malta, may. European Language Resources Association (ELRA).</rawString>
</citation>
<citation valid="true">
<authors>
<author>Éric Villemonte De La Clergerie</author>
</authors>
<title>Exploring beam-based shift-reduce dependency parsing with DyALog: Results from the SPMRL 2013 shared task.</title>
<date>2013</date>
<booktitle>In 4th Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL’2013),</booktitle>
<location>Seattle, États-Unis.</location>
<contexts>
<context position="6640" citStr="Clergerie, 2013" startWordPosition="1074" endWordPosition="1075">e used two different learning algorithms: (i) the averaged perceptron because of its good balance between training time and performance (Daume, 2006), (ii) the logistic regression model (maximum entropy (Ratnaparkhi, 1997)). For the latter, we used the truncated gradient optimization (Langford et al., 2009), implemented in Classias (Okazaki, 2009), in order to estimate the parameters. These algorithms have been used interchangeably to test their performance in terms of Fscore. But the difference was negligeable in general. 2.2 DYALOG-SR Our second parsing system is DYALOG-SR (Villemonte De La Clergerie, 2013), which has been developed to participate to the SPMRL’13 shared task. Coded on top of tabular logic programming system DYALOG, it implements a transition-based parser relying on dynamic programming techniques, beams, and an averaged structured perceptron, following ideas from (Huang and Sagae, 2010; Goldberg et al., 2013). It was initially designed to follow an arcstandard parsing strategy, relying on shift and left/right reduce transitions. To deal with dependency graphs and non governed words, we first added the two attach transitions and the pop0 transition. But because there exist some ov</context>
</contexts>
<marker>Clergerie, 2013</marker>
<rawString>Éric Villemonte De La Clergerie. 2013. Exploring beam-based shift-reduce dependency parsing with DyALog: Results from the SPMRL 2013 shared task. In 4th Workshop on Statistical Parsing of Morphologically Rich Languages (SPMRL’2013), Seattle, États-Unis.</rawString>
</citation>
<citation valid="true">
<authors>
<author>Joachim Wagner</author>
<author>Djamé Seddah</author>
<author>Jennifer Foster</author>
<author>Josef Van Genabith</author>
</authors>
<title>C-structures and Fstructures for the British National Corpus.</title>
<date>2007</date>
<booktitle>In Proceedings of the Twelfth International Lexical Functional Grammar Conference. Citeseer.</booktitle>
<marker>Wagner, Seddah, Foster, Van Genabith, 2007</marker>
<rawString>Joachim Wagner, Djamé Seddah, Jennifer Foster, and Josef Van Genabith. 2007. C-structures and Fstructures for the British National Corpus. In Proceedings of the Twelfth International Lexical Functional Grammar Conference. Citeseer.</rawString>
</citation>
</citationList>
</algorithm>
</algorithms>